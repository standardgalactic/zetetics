BAYESIAN PROGRAMMING
Pierre Bessière
Juan-Manuel Ahuactzin
Kamel Mekhnacha
Emmanuel Mazer
Contact:
Pierre.Bessiere@imag.fr
Juan-Manuel.Ahuactzin@inrialpes.fr

Bayesian Programming
Page 2

Page 3
To the late Edward T. Jaynes 
for his doubts about certitudes 
and for his certitudes about probabilities

Bayesian Programming
Page 4

Page 5
Table of content
1 
Introduction 11
1.1. Probability an alternative to logic 11
1.2. A need for a new computing paradigm 15
1.3. A need for a new modeling methodology 15
1.4. A need for new inference algorithms 19
1.5. A need for a new programming language and new hardware 21
1.6. A place for numerous controversies 22
2
Basic Concepts 25
2.1. Variable 26
2.2. Probability 26
2.3. The normalization postulate 26
2.4. Conditional probability 27
2.5. Variable conjunction 28
2.6. The conjunction postulate (Bayes theorem) 28
2.7. Syllogisms 29
2.8. The marginalization rule 30
2.9. Joint distribution and questions 31
2.10. Decomposition 33
2.11. Parametric forms 34
2.12. Identification 35
2.13. Specification = Variables + Decomposition + Parametric Forms 36
2.14. Description = Specification + Identification 36
2.15. Question 36
2.16. Bayesian program = Description + Question 38
2.17. Results 39
3
Incompleteness and Uncertainty 45
3.1. The "beam in the bin" investigation 45
3.2. Observing a water treatment unit 48
3.2.1. The elementary water treatment unit 49
3.2.2. Experimentation and uncertainty 53
3.3. Lessons, comments and notes 56
3.3.1. The effect of incompleteness 56
3.3.2. The effect of inaccuracy 56
3.3.3. Not taking into account the effect of ignored variables may lead to wrong decisions 57
3.3.4. From incompleteness to uncertainty 58
4
Description = Specification + Identification 61
4.1. Pushing objects and following contours 62
4.1.1. The Khepera robot 62
4.1.2. Pushing objects 64
4.1.3. Following contours 68
4.2. Description of a water treatment unit 71
4.2.1. Specification 71
4.2.2. Identification 74
4.2.3. Results 75
4.3. Lessons, comments and notes 75
4.3.1. Description = Specification + Identification 75
4.3.2. Specification = Variables + Decomposition + Forms 76
4.3.3. Learning is a means to transform incompleteness into uncertainty 77

Bayesian Programming
Page 6
5
The Importance of Conditional Independence 79
5.1. Water treatment center Bayesian model (continuation) 79
5.2. Description of the water treatment center 80
5.2.1. Specification 81
5.2.2. Identification 84
5.3. Lessons, comments and notes 85
5.3.1. Independence versus conditional independence 85
5.3.2. The importance of conditional independence 87
6
Bayesian Program = Description + Question 89
6.1. Water treatment center Bayesian model (end) 90
6.2. Forward simulation of a single unit 90
6.2.1. Question 90
6.2.2. Results 93
6.3. Forward simulation of the water treatment center 93
6.3.1. Question 93
6.3.2. Results 96
6.4. Control of the water treatment center 97
6.4.1. Question (1) 97
6.4.2. Result (1) 97
6.4.3. Question (2) 98
6.4.4. Result (2) 99
6.5. Diagnosis 101
6.5.1. Question 101
6.5.2. Results 102
6.6. Lessons, comments and notes 104
6.6.1. Bayesian Program = Description + Question 104
6.6.2. The essence of Bayesian inference 105
6.6.3. No inverse or direct problem 106
6.6.4. No ill-posed problem 107
7
Information fusion and inverse programming 109
7.1. Fusion of information in ADAS systems 110
7.1.1. Statement of the problem 110
7.1.2. Bayesian Program 110
7.1.3. Results 110
7.2. Programming and training video games avatars 110
7.2.1. Statement of the problem 110
7.2.2. Bayesian Program 111
7.2.3. Results 111
7.3. Lessons, comments and notes 111
7.3.1. Information fusion 111
7.3.2. Coherence fusion 111
7.3.3. Inverse programming 111
8
Calling Bayesian Subroutines 113
8.1. Exemple 1 114
8.1.1. Statement of the problem 114
8.1.2. Bayesian Program 114
8.1.3. Results 114
8.2. Evaluation of operational risk 114
8.2.1. Statement of the problem 114
8.2.2. Bayesian Program 114
8.2.3. Results 114
8.3. Lessons, comments and notes 114

Page 7
8.3.1. Calling subroutines 114
8.3.2. Hierarchies of description 114
9
Bayesian program mixture 117
9.1. Homing Behavior 118
9.1.1. Statement of the problem 118
9.1.2. Bayesian Program 118
9.1.3. Results 118
9.2. Heating forecast 118
9.2.1. Statement of the problem 118
9.2.2. Bayesian Program 118
9.2.3. Results 118
9.3. Lessons, comments and notes 118
9.3.1. Bayesian program combination 118
9.3.2. A probabilistic "if - then- else" 118
10
Bayesian filters 121
10.1. Markov localization 122
10.1.1. Statement of the problem 122
10.1.2. Bayesian Program 122
10.1.3. Results 122
10.2. ??? 122
10.2.1. Statement of the problem 122
10.2.2. Bayesian Program 122
10.2.3. Results 122
10.3. Lessons, comments and notes 122
10.3.1. $$$ 122
11
Using functions 123
11.1. ADD dice 124
11.1.1. Statement of the problem 124
11.1.2. Bayesian Program 124
11.1.3. Results 124
11.2. CAD system 124
11.2.1. Statement of the problem 124
11.2.2. Bayesian Program 124
11.2.3. Results 124
11.3. Lessons, comments and notes 124
12
Bayesian Programming Formalism 125
12.1. How simple! How subtle! 125
12.2. Logical propositions 126
12.3. Probability of a proposition 126
12.4. Normalization and conjunction postulates 126
12.5. Disjunction rule for propositions 127
12.6. Discrete variables 127
12.7. Variable conjunction 128
12.8. Probability on variables 128
12.9. Conjunction rule for variables 128
12.10. Normalization rule for variables 129
12.11. Marginalization rule 129
12.12. Bayesian program 130
12.13. Description 130
12.14. Specification 131
12.15. Questions 132

Bayesian Programming
Page 8
12.16. Inference 132
13
Bayesian Models Revisited 135
13.1. General purpose probabilistic models 136
13.1.1. Graphical models and Bayesian networks 136
13.1.2. Recursive Bayesian estimation: Bayesian filters, Hidden Markov Models, Kalman filters and farticle 
filters 139
13.1.3. Mixture models 144
13.1.4. Maximum entropy approaches 147
13.2. Problem-oriented probabilistic models 149
13.2.1. Sensor fusion 149
13.2.2. Classification 151
13.2.3. Pattern recognition 152
13.2.4. Sequence recognition 152
13.2.5. Markov localization 153
13.2.6. Markov decision processes 154
13.2.7. Bayesian models in life science 156
13.3. Summary 157
14
Bayesian Inference Algorithms Revisited 159
14.1. Stating the problem 159
14.2. Symbolic computation 162
14.2.1. Exact symbolic computation 162
14.2.2. Approxiamate symbolic computation 176
14.3. Numerical computation 177
14.3.1. Searching the modes in high-dimensional spaces 177
14.3.2. Marginalization (integration) in high-dimensional spaces 183
15
Bayesian Learning Revisited 189
15.1. Problematic 189
15.1.1. How to identify (learn) the value of the free parameters? 190
15.1.2. How to compare different probabilistic models (specifications)? 192
15.1.3. How to find interesting decompositions and associated parametric forms? 193
15.1.4. How to find the pertinent variables to model a phenomenon? 194
15.2. Expectation - Maximization (EM) 194
15.2.1. EM and bayesian networks 195
15.2.2. EM and Mixture Models 195
15.2.3. EM and HMM: The Baum-Welch Algorithm 195
15.3. Problem Oriented Models 197
15.4. Learning Structure of Bayesian Networks 198
15.5. Bayesian Evolution? 199
16
Frequently Asked Question and
Frequently Argued Matter 201
16.1. APPLICATIONS OF BAYESIAN PROGRAMMING (WHAT ARE?) 201
16.2. BAYES, THOMAS (WHO IS?) 202
16.3. BAYESIAN DECISION THEORY (WHAT IS?) 202
16.4. BIAS VERSUS VARIANCE DILEMMA 202
16.5. Computation complexity of Bayesian Inference 202
16.6. Cox theorem (What is?) 202
16.7. DECOMPOSITION 202
16.8. DESCRIPTION 202
16.9. DISJUNCTION RULE AS AN AXIOM (WHY DON'T YOU TAKE?) 202
16.10. DRAW VERSUS BEST 202
16.11. FORMS 202

Page 9
16.12. FREQUENTIST VERSUS NON-FREQUENTIST 202
16.13. FUZZY LOGIC VERSUS BAYESIAN INFERENCE 202
16.14. HUMAN (ARE THEY BAYESIAN?) 202
16.15. IDENTIFICATION 202
16.16. Incompleteness irreducibility 202
16.17. JAYNES, ED. T. (WHO IS?) 203
16.18. KOLMOGOROV (WHO IS?) 203
16.19. KOLMOGOROV'S AXIOMATIC (WHY DON'T WE NEED?) 203
16.20. LAPLACE, MARQUIS SIMON DE (WHO IS?) 203
16.21. LAPLACE'S SUCCESSION LAW CONTROVERSY 203
16.22. Maximum entropy principle justifications 203
16.23. MIND PROJECTION FALLACY (WHAT IS?) 203
16.24. Noise or ignorance? 203
16.25. PERFECT DICE (WHAT IS?) 203
16.26. PHYSICAL CAUSALITY VERSUS LOGICAL CAUSALITY 203
16.27. PROSCRIPTIVE PROGRAMMING 203
16.28. SPECIFICATION 203
16.29. Subjectivism vs objectivism controversy 203
16.30. VARIABLE 203
17
Bibliography 205

Bayesian Programming
Page 10

Page 11
 1 
Introduction
The most incomprehensible thing about the world is that it is comprehen-
sible
Albert Einstein
1.1
Probability an alternative to logic
Computers have brought a new dimension to modeling. A model, once translated into a
program and run on a computer, may be used to understand, measure, simulate, mimic,
optimize, predict, and control. During the last fifty years science, industry, finance, med-
icine, entertainment, transport, and communication have been completely transformed by
this revolution.
However, models and programs suffer from a fundamental flaw: incompleteness. Any
model of a real phenomenon is incomplete. Hidden variables, not taken into account in
the model, influence the phenomenon. The effect of the hidden variables is that the model
and the phenomenon never have the exact same behaviors. Uncertainty is the direct and
unavoidable consequence of incompleteness. A model may not foresee exactly the future

Bayesian Programming
Page 12
observations of a phenomenon, as these observations are biased by the hidden variables,
and may not predict  the consequences of its decisions exactly.
Computing a cost price to decide on a sell price may seem a purely arithmetic opera-
tion consisting of adding elementary costs. However, often these elementary costs may
not be known exactly. For instance, a part’s cost may be biased by exchange rates, pro-
duction cost may be biased by the number of orders and transportation costs may be
biased by the period of the year. Exchange rates, the number of orders, and the period of
the year when unknown, are hidden variables, which induce uncertainty in the computa-
tion of the cost price.
Analyzing the content of an email to filter spam is a difficult task, because no word or
combination of words can give you an absolute certitude about the nature of the email. At
most, the presence of certain words is a strong clue that an email is a spam. It may never
be a conclusive proof, because the context may completely change its meaning. For
instance, if one of your friends is forwarding you a spam for discussion about the spam
phenomenon, its whole content is suddenly not spam any longer. A linguistic model of
spam is irremediably incomplete because of this boundless contextual information. Fil-
tering spam is not hopeless and some very efficient solution exists, but the perfect result
is a chimera.
Machine control and dysfunction diagnosis is very important to industry. However,
the dream of building a complete model of a machine and all its possible failures is an
illusion. One should recall the first "bug" of the computer era: the moth located in relay
70 panel F of the Harvard Mark II computer. Once again, it does not mean that control
and diagnosis is hopeless, it only means that models of these machines should take into
account their own incompleteness and the resulting uncertainty.
In 1781, Sir William Herschell discovered Uranus, the seventh planet of the solar sys-
tem. In 1846, Johann Galle observed for the first time, Neptune, the eighth planet. In the
meantime, both Urbain Leverrier, a French astronomer, and John Adams, an English one,
became interested in the "uncertain" trajectory of Uranus. The planet was not following
exactly the trajectory that Newton’s theory of gravitation predicted. They both came to
the conclusion that these irregularities should be the result of a hidden variable not taken
into account by the model: the existence of an eighth planet. They even went much fur-
ther, finding the most probable position of this eighth planet. The Berlin observatory
received Leverrier’s prediction on September 23, 1846 and Galle observed Neptune the

Introduction
Page 13
very same day!
Logic is both the mathematical foundation of rational reasoning and the fundamental
principle of present day computing. However, logic, by essence, is restricted to problems
where information is both complete and certain. An alternative mathematical framework
and an alternative computing framework are both needed to deal with incompleteness and
uncertainty.
Probability theory is this alternative mathematical framework. It is a model of rational
reasoning in the presence of incompleteness and uncertainty. It is an extension of logic
where both certain and uncertain information have their places. 
James C. Maxwell stated this point synthetically:
The actual science of logic is conversant at present only with things either
certain, impossible, or entirely doubtful, none of which (fortunately) we
have to reason on. Therefore the true logic for this world is the calculus of
Probabilities, which takes account of the magnitude of the probability
which is, or ought to be, in a reasonable man's mind.
James C. Maxwell; quote in "Probability Theory - The Logic of Science"
by Edward T. Jaynes (Jaynes, 2003)
Considering probability as a model of reasoning is called the subjectivist or Bayesian
approach. It is opposed to the objectivist approach, which considers probability as a model
of the world. This opposition is not only an epistemological controversy; it has many fun-
damental and practical consequences1. 
To model reasoning, you must take into account the preliminary knowledge of the sub-
ject who is doing the reasoning. This preliminary knowledge plays the same role as the
axioms in logic. Starting from different preliminary knowledge may lead to different con-
clusions. Starting from wrong preliminary knowledge will lead to wrong conclusions
even with perfectly correct reasoning. Reaching wrong conclusions following correct
reasoning proves that the preliminary knowledge was wrong, offers the opportunity to
correct it and eventually leads you to learning. Incompleteness is simply the irreducible
gap between the preliminary knowledge and the phenomenon and uncertainty is a direct
1.
See “Subjectivism vs objectivism controversy”, page 203

Bayesian Programming
Page 14
and measurable consequence of this imperfection.
In contrast, modeling the world by denying the existence of a "subject" and conse-
quently rejecting preliminary knowledge leads to complicated situations and apparent
paradoxes. This rejection implies that if the conclusions are wrong, either the reasoning
could be wrong or the data could be aberrant, leaving no room for improvement or learn-
ing. Incompleteness does not mean anything without preliminary knowledge, and uncer-
tainty and noise must be mysterious properties of the physical world.
The objectivist school has been dominant during the 20th century, but the subjectivist
approach has a history as long as probability itself. It can be traced back to Jakob Ber-
noulli in 1713:
Uncertainty is not in things but in our head: uncertainty is a lack of
knowledge.
Jakob Bernoulli, Ars Conjectandi (Bernouilli, 1713);
to the Marquis Simon de Laplace1, one century later, in 1812:
Probability theory is nothing but common sense reduced to calculation.
Simon de Laplace, Théorie Analytique des Probabilités (Laplace, 1812)
to the already quoted James C. Maxwell in 1850 and to the visionary Henri Poincaré
in 1902:
Randomness is just the measure of our ignorance.
To undertake any probability calculation, and even for this calculation to
have a meaning, we have to admit, as a starting point, an hypothesis or a
convention, that always comprises a certain amount of arbitrariness. In
the choice of this convention, we can be guided only by the principle of
sufficient reason.
From this point of view, every sciences would just be unconscious appli-
cations of the calculus of probabilities. Condemning this calculus would
1.
See “LAPLACE, MARQUIS SIMON DE (WHO IS?)”, page 203

Introduction
Page 15
be condemning the whole science.
Henri Poincaré, La science et l’hypothèse (Poincaré, 1902)
and finally, by Edward T. Jaynes1 in his book Probability theory: the logic of science
(Jaynes, 2003) where he brilliantly presents the subjectivist alternative and sets clearly
and simply the basis of the approach:
By inference we mean simply: deductive reasoning whenever enough
information is at hand to permit it; inductive or probabilistic reasoning
when - as is almost invariably the case in real problems - all the necessary
information is not available. Thus the topic of "Probability as Logic" is
the optimal processing of uncertain and incomplete knowledge.
Edward T. Jaynes, Probability Theory: The Logic of Science (Jaynes,
2003)
1.2
A need for a new computing paradigm
Bayesian probability theory is clearly the sought mathematical alternative to logic2.
However, we want working solutions to incomplete and uncertain problems. Conse-
quently, we require an alternative computing framework based on Bayesian probabilities. 
To create such a complete computing Bayesian framework, we reqire a new modeling
methodology to build probabilistic models, we require new inference algorithms to auto-
mate probabilistic calculus, we require new programming languages to implement these
models on computers, and finally, we will eventually require new hardware to run these
Bayesian programs efficiently. 
The ultimate goal is a Bayesian computer. The purpose of this book is to describe the
current first steps in this direction.
1.3
A need for a new modeling methodology
The existence of a systematic and generic method to build models is a sine qua non
requirement for the success of a modeling and computing paradigm. This is why algo-
1.
See “JAYNES, ED. T. (WHO IS?)”, page 203
2.
See “Cox theorem (What is?)”, page 202

Bayesian Programming
Page 16
rithms are taught in the basic course of computer science giving students the basic and
necessary methods to develop classical programs. Such a systematic and generic method
exists within the Bayesian framework. Moreover, this method is very simple even if it is
atypical and a bit worrisome at the beginning.
The purpose of Chapters 2 to 11 is to present this new modeling methodology. The
presentation is intended for the general public and does not suppose any prerequisites
other than a basic fundation in mathematics. Its purpose is to introduce the fundamental
concepts, to present the novelty and interest of the approach, and to initiate the reader to
the subtle art of Bayesian modeling. Numerous simple examples of applications are pre-
sented in different fields such as $$$ medicine, robotics, finance, and process control.
Chapter 2 gently introduces the basic concepts of Bayesian Programming. We start with a
simple example of a Bayesian spam filter that helps you dispose of junk emails. Commer-
cially available software is based on a similar approach.
The problem is very easy to formulate. We want to classify texts (email) in one of two
categories either "spam" or "to consider". The only information we have to classify the
emails is their content: a set of words.
The classifier should furthermore be able to adapt to its user and to learn from experi-
ence. Starting from an initial standard setting, the classifier should modify its internal
parameters when the choice of the user does not correspond to its own decision. It will
hence adapt to a user’s criteria to choose between "spam" and "not-spam". It will improve
its results as it analyzes increasingly classified emails.
The goal of Chapter 3 is to explore thoroughly the concept of incompleteness with a very
simple physical experiment called the "beam in the bin" experiment. We demonstrate
how incompleteness is the source of uncertainty by using a second, more elaborate exper-
iment involving a model of a water treatment center.
Two sources of uncertainty are shown: the existence of hidden variables and the inac-
curacy of measures. The effects of both are quantified. We also demonstrate that ignoring
incompleteness may lead to certain but definitely wrong decisions. Finally, we explain
how learning transforms incompleteness into uncertainty and how probabilistic inference
leads to informed decision despite this uncertainty.
In Chapter 4 we present in some detail the fundamental notion of description. A descrip-

Introduction
Page 17
tion is the probabilistic model of a given phenomenon. It is obtained after two phases of
development: first, a specification phase where the programmer expresses his own knowl-
edge about the modeled phenomenon in probabilistic terms; and second, an identification
phase where this starting probabilistic canvas is refined by learning from data. Descrip-
tions are the basic elements that are used, combined, composed, manipulated, computed,
compiled, and questioned in different ways to build Bayesian programs.
The specification itself is obtained in three phases. First, programmers must choose
the pertinent variables. Second, in a decomposition phase they must express the joint prob-
ability on the selected variables as a product of simpler distributions. Finally, they must
choose a parametric form for each of these distributions.
These three phases are depicted by: (i) a robotic example where a small mobile robot
is taught how to push, avoid, and circle small objects and (ii) a continuation of the water
treatment center instance where the corresponding description is illustrated.
Two "equations" may summarize the content of this chapter: "Description = Specifi-
cation + Identification" and "Specification = Variables + Decomposition + Forms".
In Chapter 5 the notions of independence and conditional independence are introduced.
We demonstrate the importance of conditional independence in actually solving and com-
puting complex probabilistic problems.
The water treatment center instance is further developed to exemplify these central
concepts.
The water treatment center instance is completed in Chapter 6. The probabilistic descrip-
tion of this process (built in Chapters 4 and 5) is used to solve different problems: predic-
tion of the output, choice of the best control strategy, and diagnosis of failures. This
shows that multiple questions may be asked of the same description to solve very differ-
ent problems. This clear separation between the model and its use is a very important fea-
ture of Bayesian Programming.
This chapter completes the introduction and definition of a Bayesian program, which
is made of both a description and a question: "Bayesian Program = Description + Ques-
tion". 
The essence of the critical computational difficulties of Bayesian inference is pre-
sented but, per contra, we explain that in Bayesian modeling there are neither "ill posed
problems" nor opposition between "direct" and "inverse" problems. Within the Bayesian

Bayesian Programming
Page 18
framework, any inverse problem has an evident theoretical solution, but this solution may
be very costly to compute.
Chapters 2 to 6 present the concept of the Bayesian program. Chapters 8 to 13 are used to
show how to combine elementary Bayesian programs to build more complex ones. Some
analogies are stressed between this probabilistic mechanism and the corresponding algo-
rithmic ones, for instance the use of subroutines or conditional and case operators.
For instance, Chapter 8  shows how Bayesian subroutines can be called within Bayesian
programs. As for in classical programming, subroutines are a major means to build com-
plex models from simpler ones, using them as elementary bricks. We can create a hierar-
chy of probabilistic descriptions resulting from either a top-down analysis or a bottom-up
elaboration.
A financial analysis example is used to exemplify this concept. $$$more to come
when Chapter 7 will be written$$$.
Chapter 9 introduces the Bayesian program combination. Using both a simple robotic
example and a more elaborate natural risk analysis problem we show how to combine dif-
ferent Bayesian programs with the help of a choice variable. If known with certainty, this
choice variable would act as a switch between the different models. In that case this
model acts as an "if-then-else" or a case statement. If the choice variable is not known
with certainty, we then obtain the probabilistic equivalent of these conditional construc-
tors.
In Chapter 7 we investigate how to sequence Bayesian programs. Inverse programming is
proposed as a potentially efficient solution. It consists of expressing independently the
conditional probabilities of the conditions knowing the action. Even in atypical cases,
this modeling method appears to be convenient and generic. Furthermore it leads to very
easy learning schemes.
The inverse programming concept is exemplified with a video game application. We
address the problem of real-time reactive selection of elementary behaviors for an agent
playing a first person shooter game. We show how Bayesian Programming leads to a
more condensed and easier formalization than a finite state machine. We also demon-
strate that using this technique it is easy to implement learning by imitation in a fully
transparent way for the player.

Introduction
Page 19
Chapter 10 approaches the topic of Bayesian program iteration. Recursive Bayesian esti-
mation and more specifically Bayesian filtering are presented as the main tools to imple-
ment iteration.
An Advanced Driver Assistance System (ADAS) application is presented as an exam-
ple. The goal of ADAS systems is largely to automate driving by assisting and eventually
replacing the human driver in some tasks. 
Chapter 11 explains how to combine probabilistic inference and algebraic operations. A
very simple example of computing a cost price for container chartering is presented. The
global cost price is the sum of sub costs, some of which can only be known approxi-
mately. We show how the probability distribution on the global cost may be derived from
the different probability distributions on the subcosts.
Bayesian Programming may be intimately combined with classical programming. It is
possible to incorporate Bayesian computation within classical programs. Moreover, it is
also possible to use classical programming within Bayesian programs. Indeed, there are
different ways to call functions inside Bayesian programs, and these are presented in
Chapter 11.
A Computer Aided Design (CAD) application is used to demostrate this functionality.
1.4
A need for new inference algorithms
A modeling methodology is not sufficient to run Bayesian programs. We also require an
efficient Bayesian inference engine to automate the probabilistic calculus. This assumes
we have a collection of inference algorithms adapted and tuned to more or less specific
models and a software architecture to combine them in a coherent and unique tool.
Numerous such Bayesian inference algorithms have been proposed in the litterature.
The purpose of this book is not to present this different computing technique and its asso-
ciated models once more. Instead, we offer a synthesis of this work and a number of bib-
liographic references for those who would like more detail on these subjects.
The purpose of Chapter 12 is to present Bayesian Programming formally. It may seem
weird to present the formalism near the end of the book and after all the examples. We
have made this choice to help comprehension and favor intuition without sacrificing
rigor. Anyone can check after reading this chapter that all the examples and programs

Bayesian Programming
Page 20
presented beforehand comply with the formalism.
The goal of Chapter 13 is to revisit the main existing Bayesian models. We use the Baye-
sian Programming formalism to present them systematically. This is a good way to be
precise and concise and it also simplifies their comparison.
We chose to divide the different probabilistic models into two categories, the general
purpose probabilistic models and the problem oriented probabilistic models. 
In the general purpose category, the modeling choices are made independently of any
specific knowledge about the modeled phenomenon. Most commonly these choices are
essentially made to keep inferences tractable. However, the technical simplifications of
these models may be compatible with large classes of problems and consequently may
have numerous applications. Among others, we are restating in the Bayesian Program-
ming (BP) formalism Bayesian Networks (BN), Dynamic Bayesian Networks (DBN),
Hidden Markov Models (HMM), Kalman filters, and mixture models.
In the problem oriented category, on the contrary, the modeling choices and simplifi-
cations are decided according to some specific knowledge about the modeled phenome-
non. These choices could eventually lead to very poor models from a computational point
of view. However, most of the time problem dependent knowledge, such as conditional
independence between variables, leads to very important and effective simplifications
and computational improvements. 
Chapter 16 surveys the main available general purpose algorithms for Bayesian infer-
ence.  
It is well known that general Bayesian inference is a very difficult problem, which
may be practically intractable. Exact inference has been proved to be NP-hard (Cooper,
1990) as has the general problem of approximate inference (Dagum & Luby, 1993). 
Numerous heuristics and restrictions to the generality of possible inferences have
been proposed to achieve admissible computation time. The purpose of this chapter is to
make a short review of these heuristics and techniques.
Before starting to crunch numbers, it is usually possible (and wise) to make some
symbolic computations to reduce the amount of  numerical computation required. The
first section of this chapter presents the different possibilities. We will see that these sym-
bolic computations can be either exact or approximate.
Once simplified, the expression obtained must be numerically evaluated. In a few

Introduction
Page 21
cases exact (exhaustive) computation may be possible thanks to the previous symbolic
simplification, but most of the time, even with the simplifications, only approximate cal-
culations are possible. The second section of this chapter describes the main algorithms
to do so.
Finally, Chapter 15 surveys the different learning algorithms. The best known ones are
rapidly recalled and restated in Bayesian Programming terms. $$$More to come when
Chapter 18 has been written$$$.
1.5
A need for a new programming language and new hardware
A modeling methodology and new inference algorithms are not sufficient to make these
models operational. We also require new programming languages to implement them on
classical computers and, eventually, new specialized hardware architectures to run these
programs efficiently. 
However captivating these topics may be, we chose not to deal with them in this
book.
Concerning new programming languages, this book comes with a companion website
(Bayesian-Programming.org) where such a programming language called ProBT® is pro-
vided under a free license restricted to noncommercial uses. 
ProBT® is a C++ multi-platform professional library used to automate probabilistic
calculus. The ProBT® library has two main components: (i) a friendly Application Pro-
gram Interface (API) for building Bayesian models and (ii) a high-performance Bayesian
Inference Engine (BIE) allowing the entire probability calculus to be executed exactly  or
approximately. 
ProBT® comes with its complete documentation and numerous examples,  including
those used in this book. Utilization of the library requires some computer science profi-
ciency, which is not required from the readers of this book. This companion website is a
plus but is not necessary in the comprehension of this book.
It is too early to be clear about new hardware dedicated to probabilistic inference, and the
book is already too long to make room for one more topic!
However, we would like to stress that 25 years ago, no one dared to dream about
graphical computers. Today, no one dares to sell a computer without a graphical display

Bayesian Programming
Page 22
with millions of pixels able to present realtime 3D animations or to play high quality
movies thanks to specific hardware that makes such a marvel feasible.
We are convinced that 25 years from now, the ability to treat incomplete and uncertain
data will be as inescapable for computers as graphical abilities are today. We hope that
you will also be convinced of this at the end of this book. Consequently, we will require
specific hardware to face the huge computing burden that some Bayesian inference prob-
lems may generate.
Many possible directions of research may be envisioned to develop such new hard-
ware. Some, especially promising, are inspired by biology. Indeed, some researchers are
currently exploring the hypothesis that the central nervous system (CNS) could be a
probabilistic machine either at the level of individual neurons or assemblies of neurons.
Feedback from these studies could provide inspiration for this necessary hardware.
1.6
A place for numerous controversies
We believe that Bayesian modeling is an elegant matter that can be presented simply,
intuitively, and with mathematical rigor. We hope that we succeed in doing so in this
book. However, the subjectivist approach to probability has been and still is a subject of
countless controversies.
Some questions must be asked, discussed, and answered, such as: the role of decision
theory; the dilemma of bias versus variance; the computational complexity of Bayesian
inference; the frequentist versus nonfrequentist argument; fuzzy logic versus the probabi-
listic treatment of uncertainty; physical causality versus logical causality; and last but not
least, the subjectivist versus objectivist epistemological conception of probability itself.
To make the main exposition as clear and simple as possible, none of these controver-
sies, historical notes, epistemological debates, and tricky technical questions are dis-
cussed in the body of the book. We have made the didactic choice to develop all these
questions in a special annex entitled "FAQ and FAM" (Frequently Asked Questions and
Frequently Argued Matters).
This annex is organized as a collection of "record cards", four pages long at most,
presented in alphabetical order. Cross references to these subjects are included in the
main text for readers interested in going further than a simple presentation of the princi-
ples of Bayesian modeling.

Introduction
Page 23

Bayesian Programming
Page 24

Page 25
 2
Basic Concepts
Far better an approximate answer to the right question which is often
vague, than an exact answer to the wrong question which can always be
made precise.
John W. Tuckey
The purpose of this chapter is to gently introduce the basic concepts of Bayesian Pro-
gramming. These concepts will be extensively used and developed in Chapters 4 to 13
and they will be revisited, summarized and formally defined in Chapter 12.
We start with a simple example of Bayesian spam filtering, which helps to eliminate
junk emails. Commercially available software is based on a similar approach.
The problem is very easy to formulate. We want to classify texts (email) into one of
two categories either “nonspam” or “spam”. The only information we can use to classify
the emails is their content: a set of words. 
The classifier should furthermore be able to adapt to its user and to learn from experi-
ence. Starting from an initial standard setting, the classifier should modify its internal
parameters when user disagrees with its own decision. It will hence adapt to users’ crite-

Bayesian Programming
Page 26
ria to choose between “nonspam” and “spam”. It will improve its results as it encounters
increasingly classified emails. The classifier uses an 
 word dictionary. Each email will
be classified according to the presence or absence of each of the words in the dictionary.
2.1
Variable
The variables necessary to write this program are the following:
1. 
1: a binary variable, false if the email is not spam and true otherwise.
2. 
: N binary variables. 
 is true if the 
 word of the dictionary
is present in the text.
These N + 1 binary variables sum up all the information we have about an email.
2.2
Probability
A variable can have one and only one value at a given time, so the value of 
 is either
2 or 
, as the email may either be spam or not.
However, this value may be unknown. Unknown does not mean that you do not have
any information concerning 
. For instance, you may know that the average rate of
nonspam email is 25%. This information may be formalized, writing:
1. 
, which stands for “the probability that an email is not
spam is 25%”
2. 
2.3
The normalization postulate
According to our hypothesis, an email is either interesting to read or spam. It means that
it cannot be both but it is necessarily one of them. This implies that:
1.
Variables will be denoted by their name in italics with initial capital.
2.
Variable values will be denoted by their name in roman, in lowercase.
N
Spam
W0 W1 ... WN
1
–
,
,
,
Wn
n
th
Spam
true
false
Spam
P
Spam
false
=
[
]
(
)
0,25
=
P
Spam
true
=
[
]
(
)
0,75
=

Basic Concepts
Page 27
(2.1)
This property is true for any discrete variable (not only for binary ones) and conse-
quently the probability distribution on a given variable 
 should necessarily be normal-
ized:
(2.2)
For the sake of simplicity, we will use the following notation 
(2.3)
2.4
Conditional probability
We may be interested in the probability that a given variable assumes a value based on
some information. This is called a conditional probability.
For instance, we may be interested in the probability that a given word appears in
spam: 
. The sign "
" separates the variables into two sets:
on the right are the variables with values known with certainty, on the left the probed
variables.
This notation may be generalized as: 
, which stands for the
probability distribution on 
 knowing that the email is spam. This distribution is
defined by two probabilities corresponding to the two possible values of 
. For
instance:
1. 
2. 
Analogously to Expression (2.3) we have that for any two variables 
 and 
(2.4)
P
Spam
false
=
[
]
(
)
P
Spam
true
=
[
]
(
)
+
1,0
=
X
P
X
x
=
[
]
(
)
x
X
!!
1,0
=
P X
( )
X!
1,0
=
P
Wj
true
=
[
]| Spam
true
=
[
]
(
)
|
P Wj| Spam
true
=
[
]
(
)
Wj
Wj
P
Wj
false
=
[
]| Spam
true
=
[
]
(
)
0,9996
=
P
Wj
true
=
[
]| Spam
true
=
[
]
(
)
0,0004
=
X
Y
P X
Y
 |
(
)
X!
1,0
=

Bayesian Programming
Page 28
Consequently, 
.
2.5
Variable conjunction
We may also be interested in the probability of the conjunction of two variables:
.
, the conjunction of the two variables 
 and 
, is a new variable that
can take four different values:
(2.5)
This may be generalized as the conjunction of an arbitrary number of variables. For
instance, in the sequel, we will be very interested in the joint probability distribution of
the conjunction of N + 1 variables:
(2.6)
2.6
The conjunction postulate (Bayes theorem)
The probability of a conjunction of two variables 
 and 
 may be computed according to
the Conjunction Rule:
(2.7)
This rule is betterl known under the form of the so called Bayes theorem:
(2.8)
However, we prefer the first form, which clearly states that it is a means of computing
the probability of a conjunction of variables according to both the probabilities of these
variables and their relative conditional probabilities.
For instance, we have:
P Wj| Spam
true
=
[
]
(
)
Wj
!
1,0
=
P Spam
Wj
"
(
)
Spam
Wj
"
Spam
Wj
false false
,
(
)
false true
,
(
)
true false
,
(
)
true true
,
(
)
,
,
,
{
}
P Spam
W0
...
Wj
...
WN
1
–
"
"
"
"
"
(
)
X
Y
P X
Y
"
(
)
P X
( )
P Y|X
(
)
×
=
P Y
( )
P X|Y
(
)
×
=
P X|Y
(
)
P X
( )
P Y|X
(
)
×
P Y
( )
---------------------------------------
=

Basic Concepts
Page 29
(2.9)
2.7
Syllogisms
It is very important to acquire a clear intuitive feeling of what a conditional probability
and the Conjunction Rule mean. A first step toward this understanding may be to restate
the classical logical syllogisms in their probabilistic forms.
Let us first recall the two logical syllogisms:
1. Modus Ponens: 
1
if a is true and if a implies b then b is true
2. Modus Tollens: 
if b is false and if a implies b then a is false
For instance, if a stands for "n may be divided by 9" and b stands for "n may be
divided by 3", we know that 
, and we have:
1. Modus Ponens: If "n may be divided by 9" then "n may be divided by 3".
2. Modus Tollens: if "n may be divided by 3" is false then "n may be divided by 9" is
also false.
Using probabilities, we may state:
1. Modus Ponens: 
, which means that knowing that a is true then we
may be sure that b is true.
2. Modus Tollens: 
, which means that knowing that b is false then we
may be sure that a is false. 
1.
Logical propositions will be denoted by name in italics, in lowercase.
P
Spam
true
=
[
]
Wj
true
=
[
]
"
(
)
P
Spam
true
=
[
]
(
)
P
Wj
true
=
[
]| Spam
true
=
[
]
(
)
×
=
0,75
0,0004
×
=
0,0003
=
P
Wj
true
=
[
]
(
)
P
Spam
true
=
[
]| Wj
true
=
[
]
(
)
×
=
a
a
b
"
[
]
"
b
#
b
¬
a
b
"
[
]
"
a
¬
#
a
b
"
P b|a
(
)
1
=
P
a
¬ |
b
¬
(
)
1
=

 may be derived from 
, using the normalization and
conjunction postulates:
However, using probabilities we may go further than with logic:
1. From 
, using normalization and conjunction postulates we may
derive1 that 
, which means that if we know that b is true, the proba-
bility that a is true is higher than it would be if we knew nothing about b.
Obviously, the probability that "n may be divided by 9" is higher if you do know
that "n may be divided by 3" than if you do not. This very common reasoning
which is beyond the scope of pure logic but is very simple in the Bayesian frame-
work.
2. From 
, using the normalization and conjunction postulates we may
derive2 that 
, which means that if we know that a is false the
probability that b is false is less than it would be if we knew nothing about a.
The probability that "n may be divided by 3" is less if you know that n may not be
divided by 9 than if you do not know anything about n.
2.8
The marginalization rule
A very useful rule, called the marginalization rule, may be derived from the normaliza-
tion and conjunction postulates. This rule states:
from (2.3)
from (2.8)
from (2.3)
because 
1.
This derivation is a good exercise. The solution may be found in the chapter 12  at §
2.
This derivation is a good exercise. The solution may be found in the chapter $$$ at § $$$
P
a
¬ |
b
¬
(
)
1
=
P b|a
(
)
1
=
P
a
¬ |
b
¬
(
) = 1,0
P a|
b
¬
(
)
–
= 1,0
P
b
¬ |a
(
)
P a
( )
×
P
b
¬
(
)
----------------------------------------
–
= 1,0
1
P b|a
(
)
–
(
)
P a
( )
×
P
b
¬
(
)
--------------------------------------------------
–
= 1,0
P b|a
(
)
1,0
=
P b|a
(
)
1
=
P a|b
(
)
P a
( )
$
P b|a
(
)
1
=
P
b
¬ |
a
¬
(
)
P
b
¬
(
)
%

Basic Concepts
Page 31
(2.10)
It may be derived as follows:
(2.11)
2.9
Joint distribution and questions
The joint distribution on a set of two variables 
 and 
 is the distribution on their con-
junction:
. If you know the joint distribution, then you know everything you may
want to know about the variables. Indeed, using the conjunction and marginalization
rules you have:
1. 
2. 
3. 
4. 
This is of course also true for a joint distribution on more than two variables.
For our spam instance, if you know the joint distribution:
from (2.7)
from (2.4)
P X
Y
"
(
)
X
!
P Y
( )
=
P X
Y
"
(
)
X
!
=
P Y
( )
P X|Y
(
)
×
X
!
= P Y
( )
P X|Y
(
)
X
!
×
= P Y
( )
X
Y
P X
Y
"
(
)
P Y
( )
P X
Y
"
(
)
X
!
=
P X
( )
P X
Y
"
(
)
Y
!
=
P Y|X
(
)
P X
Y
"
(
)
P X
Y
"
(
)
Y
!
----------------------------
=
P X|Y
(
)
P X
Y
"
(
)
P X
Y
"
(
)
X
!
----------------------------
=

Bayesian Programming
Page 32
(2.12)
you can compute any of 
 possible questions that you can imagine on
this set of N + 1 variables.
A question is defined by partitionning a set of variables in three subsets: the searched
variables (on the left of the conditioning bar), the known variables (on the right of the
conditioning bar) and the free variables. The searched variables set must not be empty.
Examples of these questions are:
1. 
, the joint distribution itself;
2. 
, 
the a priori probability to be spam;
3. 
, 
the a priori probability for the 
 word of the dictionary to appear;
4. 
the probability for the 
, word to appear, knowing that the text is a spam;
5. 
the probability for the email to be spam knowing that the 
 word appears in the
text;
6. 
P Spam
W0
...
Wj
...
WN
1
–
"
"
"
"
"
(
)
3
N
1
+
(
)
2
N
1
+
(
)
–
P Spam
W0
...
Wj
...
WN
1
–
"
"
"
"
"
(
)
P Spam
(
)
P Spam
W0
...
Wj
...
WN
1
–
"
"
"
"
"
(
)
W0
...
Wj
...
WN
1
–
"
"
"
"
!
=
P Wj
(
)
P Spam
W0
...
Wj
...
WN
1
–
"
"
"
"
"
(
)
Spam
W0
...
Wj
1
–
Wj
1
+
...
WN
1
–
"
"
"
"
"
"
!
=
j
th
P Wj
Spam
true
=
[
]
 |
(
)
P Spam
W0
...
Wj
...
WN
1
–
"
"
"
"
"
(
)
W1
...
Wj
1
–
Wj
1
+
...
WN
"
"
"
"
"
!
P Spam
W0
...
Wj
...
WN
1
–
"
"
"
"
"
(
)
W1
...
WN
"
"
!
---------------------------------------------------------------------------------------------------------------------------------------------------------------
=
j
th
P Spam
Wj
true
=
[
]
 |
(
)
P Spam
W0
...
Wj
...
WN
1
–
"
"
"
"
"
(
)
W0
...
Wj
1
–
Wj
1
+
...
WN
1
–
"
"
"
"
"
!
P Spam
W0
...
Wj
...
WN
1
–
"
"
"
"
"
(
)
Spam
W0
...
Wj
1
–
Wj
1
+
...
WN
1
–
"
"
"
"
"
"
!
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
=
j
th
P Spam
W0
 |
...
Wj
...
WN
1
–
"
"
"
"
(
)
P Spam
W0
...
Wj
...
WN
1
–
"
"
"
"
"
(
)
P Spam
W0
...
Wj
...
WN
1
–
"
"
"
"
"
(
)
Spam
!
--------------------------------------------------------------------------------------------------------
=

Basic Concepts
Page 33
finally, the most interesting one, the probability that the email is spam knowing for
all N words in the dictionary if they are present or not in the text.
2.10
Decomposition
The key challenge for a Bayesian programmer is to specify a way to compute the joint
distribution that has the three main qualities of being a good model, easy to compute and
easy to identify.
This is done using a decomposition that restates the joint distribution as a product of
simpler distributions.
Starting from the joint distribution and applying recursively the conjunction rule we
obtain:
(2.13)
This is an exact mathematical expression.
We simplify it drastically by assuming that the probability of appearance of a word
knowing the nature of the text (spam or not) is independent of the appearance of the other
words. For instance, we assume that:
(2.14)
We finally obtain:
(2.15)
Figure 2.1 shows the graphical model of this expression. 
Observe that the assumption of independence between words is clearly not com-
pletely true. For instance, it completely neglects that the appearance of pairs of words
may be more significant than isolated appearances. However, as subjectivists, we assume
this hypothesis and may develop the model and the associated inferences to test how reli-
able it is.
P Spam
W0
...
Wj
...
WN
1
–
"
"
"
"
"
(
)
P Spam
(
)
P W0
Spam
 |
(
)
×
P W1
Spam
W0
"
 |
(
)
×
=
.
...
×
P WN
1
–
Spam
W0
...
Wj
...
WN
2
–
"
"
"
"
"
 |
(
)
×
P W1
Spam
W0
"
 |
(
)
P W1
Spam
 |
(
)
=
P Spam
W0
...
Wj
...
WN
1
–
"
"
"
"
"
(
)
P Spam
(
)
P Wi
Spam
 |
(
)
i
0
=
N
1
–
&
×
=

Bayesian Programming
Page 34
2.11
Parametric forms
To be able to compute the joint distribution, we must now specify the N + 1 distributions
appearing in the decomposition.
We already specified 
 in Section 2.2:
•
:
°
°
Each of the N forms 
 must in turn be specified. The first idea is to sim-
ply count the number of times the 
 word of the dictionary appears in both spam and
nonspam. This would naively lead to histograms:
•
:
°
°
where, 
 stands for the number of appearances of the 
 word in nonspam emails
and 
 stands for the total number nonspam emails. Similarly, 
 stands for the number of
appearences of the 
 word in spam emails and 
 stands for the total number of spam
emails.
Figure 2.1: The graphical model of the Bayesian spam filter.
P Spam
(
)
P Spam
(
)
P
Spam
false
=
[
]
(
)
0,25
=
P
Spam
true
=
[
]
(
)
0,75
=
P Wi
Spam
 |
(
)
i
th
P Wi
Spam
 |
(
)
P
Wi
true
=
[
]
Spam
false
=
[
]
 |
(
)
nf
i
nf
----
=
P
Wi
true
=
[
]
Spam
true
=
[
]
 |
(
)
nt
i
nt
----
=
nf
i
i
th
nf
nt
i
i
th
nt

Basic Concepts
Page 35
The drawback of histograms is that when no observation has been made, the probabil-
ities are null. For instance, if the 
 word has never been observed in spam then:
(2.16)
A very strong assumption indeed, which says that what has not yet been observed is
impossible! Consequently, we prefer to assume that the parametric forms 
are Laplace succession laws rather than histograms:
•
:
°
°
where 
 stands for the number of possible values of variable 
. Here,
 as 
 is a binary variable.
If the 
 word has never been observed in spam then:
(2.17)
which tends toward zero when 
 tends toward infinity but never equals zero. An
event not yet observed is not completely impossible, even if it becomes very improbable
if it has never been observed in a long series of experiments.
2.12
Identification
The N forms 
 are not yet completely specified because the 2N + 2 parame-
ters 
, 
, 
 and 
 have no values.
The identification of these parameters could be done either by batch processing of a
series of classified emails or by an incremental updating of the parameters using the
user’s classification of the email as they arrive.
i
th
P
Wi
true
=
[
]
Spam
true
=
[
]
 |
(
)
0,0
=
P Wi
Spam
 |
(
)
P Wi
Spam
 |
(
)
P
Wi
true
=
[
]
Spam
false
=
[
]
 |
(
)
1
n
+
f
i
CARD Wi
(
)
n
+
f
-------------------------------------
=
P
Wi
true
=
[
]
Spam
true
=
[
]
 |
(
)
1
n
+
t
i
CARD Wi
(
)
n
+
t
-------------------------------------
=
CARD Wi
(
)
Wi
CARD Wi
(
)
2
=
Wi
i
th
P
Wi
true
=
[
]
Spam
true
=
[
]
 |
(
)
1
2
n
+
t
-------------
=
nt
P Wi
Spam
 |
(
)
nf
i
0 2 ... N
1
–
, ,
,
=
nt
i
0 2 ... N
1
–
, ,
,
=
nf
nt

Bayesian Programming
Page 36
Both methods could be combined: the system could start with initial standard values
of these parameters issued from a generic database, then some incremental learning cus-
tomizes the classifier to each individual user.
2.13
Specification = Variables + Decomposition + Parametric Forms
We call specification the part of the Bayesian program specified by the programmer. This
part is always made of the same three subparts:
1. Variables: the choice of the relevant variables for the problem.
2. Decomposition: the expression of the joint probability distribution as the product of
simpler distributions.
3. Parametric Forms: the choice of the mathematical functions forms of each of these
distributions.
2.14
Description = Specification + Identification
We call the description the probabilistic model of our problem. The description is the joint
probability distribution on the relevant variables. It is completely specified when the
eventual free parameters of the specification are given values after an identification phase.
2.15
Question
Once you have a description (a way to compute the joint distribution), it is possible to ask
any questions, as we saw in § 2.9.
For instance, after some simplification, the answers to our six questions are:
1. 
 
By definition, the joint distribution is equal to the decomposition.
2. 
 
as 
 appears as such in the decomposition.
P Spam
W0
...
Wj
...
WN
1
–
"
"
"
"
"
(
)
P Spam
(
)
P Wi
Spam
 |
(
)
i
0
=
N
1
–
&
×
=
P Spam
(
)
P Spam
(
)
=
P Spam
(
)

Basic Concepts
Page 37
3. 
 
the a priori probability for the 
 word of the dictionary to appear, which gives
4. 
as the probability for the 
 word to appear knowing that the text is spam, as spec-
ified in the description.
5. 
the probability for the email to be spam knowing that the 
 word appears in the
text.
6. 
The denominator appears to be a normalization constant. To eliminate it when
deciding if we are dealing with spam, an easy trick is to compute the ratio:
P Wj
(
)
P Spam
(
)
P Wj
Spam
 |
(
)
×
Spam
!
=
j
th
P
Wj
true
=
[
]
(
)
0,25
1
n
+
f
j
2
n
+
f
-------------
×
#
$
%
&
'
(
0,75
1
n
+
t
j
2
n
+
t
-------------
×
#
$
%
&
'
(
+
=
P Wj
Spam
true
=
[
]
 |
(
)
1
n
+
t
j
2
n
+
t
-------------
=
j
th
P Spam
Wj
true
=
[
]
 |
(
)
P Spam
(
)
P
Wj
true
=
[
]
Spam
 |
(
)
×
P Spam
(
)
P
Wj
true
=
[
]
Spam
 |
(
)
×
Spam
!
------------------------------------------------------------------------------------------------
=
j
th
P Spam
W0
 |
...
Wj
...
WN
1
–
"
"
"
"
(
)
P Spam
(
)
P Wi
Spam
 |
(
)
i
0
=
N
1
&
×
P Spam
(
)
P Wi
Spam
 |
(
)
i
0
=
N
1
–
&
×
Spam
!
-------------------------------------------------------------------------------------
=
P
Spam
true
=
[
]
W0
 |
...
Wj
...
WN
1
–
"
"
"
"
(
)
P
Spam
false
=
[
]
W0
 |
...
Wj
...
WN
1
–
"
"
"
"
(
)
---------------------------------------------------------------------------------------------------------------------
P
Spam
true
=
[
]
(
)
P Wi
Spam
true
=
[
]
 |
(
)
i
0
=
N
1
–
&
×
P
Spam
false
=
[
]
(
)
P Wi
Spam
false
=
[
]
 |
(
)
i
0
=
N
1
–
&
×
-------------------------------------------------------------------------------------------------------------------------
=

Bayesian Programming
Page 38
This computation is faster and easier because requires only 2N products. 
2.16
Bayesian program = Description + Question
Finally, a Bayesian program will always have the following simple structure:
(2.18)
The Bayesian spam filter program is completely defined by:
Program Pr
(
)
Description Ds
(
)
Specification Sp
(
)
Variables Va
(
)
Decomposition Dc
(
)
Forms Fo
(
)
)
*
*
+
*
*
,
Identification Id
(
)
)
*
*
*
*
+
*
*
*
*
,
Question Qu
(
)
)
*
*
*
*
*
*
+
*
*
*
*
*
*
,

Basic Concepts
Page 39
(2.19)
2.17
Results 
If we consider a spam filter with an 
 word dictionary, then any given email contains one
and only one of the 
 possible subsets of the dictionary. Here we restrict our spam filter
Word 
0
fortune
0
375
1
next
125
0
2
programming
250
0
3
money
0
750
4
you
125
375
Table 2.1: Hiistogram derived from an analysis of 1000 emails. The values 
 and 
 denote the number of emails that contained the 
 word in 
nonspam and spam emails respectively.
Pr
Ds
Sp
Va
Spam W0 W2 ... WN
1
–
,
,
,
,
#
Dc
P Spam
W0
...
Wj
...
WN
1
–
"
"
"
"
"
(
)
P Spam
(
)
P Wi
Spam
 |
(
)
i
1
=
N
&
×
=
)
*
*
+
*
*
,
#
Fo
P Spam
(
)
P
Spam
false
=
[
]
(
)
0,25
=
P
Spam
true
=
[
]
(
)
0,75
=
)
+
,
#
P Wi|Spam
(
)
P
Wi
false
=
[
]
Spam
false
=
[
]
 |
(
)
1
1
n
+
f
i
2
nf
+
-------------
–
=
P
Wi
true
=
[
]
Spam
false
=
[
]
 |
(
)
1
n
+
f
i
2
nf
+
-------------
=
P
Wi
false
=
[
]
Spam
true
=
[
]
 |
(
)
1
1
n
+
t
i
2
n
+
t
-------------
–
=
P
Wi
true
=
[
]
Spam
true
=
[
]
 |
(
)
1
n
+
t
i
2
n
+
t
-------------
=
)
*
*
*
*
*
*
*
*
*
*
+
*
*
*
*
*
*
*
*
*
*
,
#
)
*
*
*
*
*
*
*
*
*
*
*
*
*
+
*
*
*
*
*
*
*
*
*
*
*
*
*
,
#
)
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
+
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
,
Id
Parameters learned from instances
#
)
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
+
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
,
Qu
P Spam
W0
 |
...
Wj
...
WN
1
–
"
"
"
"
(
)
#
)
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
+
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
,
i
i
nf
i
nt
i
nf
i
nt
i
i
th
N
2
N

Bayesian Programming
Page 40
to a five word dictionary so that we can analyze the 
 subsets.
 Assume that a set of 1000 emails is used in the identification phase and that the
resulting numbers of nonspams and spam emails are 250 and 750 respectively. Assume
also that the resulting histogram tables for 
 and 
 are those shown in Table 2.1. The
2
5
32
=
nf
i
nt
i

Basic Concepts
Page 41
computed distribution 
 is given in Table 2.2. We can now give all the possi-
bilities of classification for an email and the probability of its being spam (Table 2.3). 
0
0.996032
0.00396825
0.5
0.5
1
0.5
0.5
0.99867
0.00132979
2
0.00396825
0.996032
0.99867
0.00132979
3
0.996032
0.00396825
0.00132979
0.99867
4
0.5
0.5
0.5
0.5
Table 2.2: The resulting distribution 
 from Table 2.1.
Subset
fortune
next
programming
money
you
1
0.497351
0.502649
2
0.497351
0.502649
3
5.24907e-06
0.999995
4
5.24907e-06
0.999995
5
0.999995
5.36149e-06
6
0.999995
5.36149e-06
7
0.497351
0.502649
8
0.497351
0.502649
9
0.998656
0.00134393
10
0.998656
0.00134393
11
0.00392659
0.996073
12
0.00392659
0.996073
13
0.99999999
7.13918e-09
14
0.99999999
7.13918e-09
15
0.998656
0.00134393
16
0.998656
0.00134393
Table 2.3: The distribution 
.
i
P Wi
Spam
false
=
 |
(
)
P Wi
Spam
true
=
 |
(
)
Wi
false
=
Wi
true
=
Wi
false
=
Wi
true
=
P Wi
Spam
 |
(
)
P Wi
Spam
 |
(
)
W0
W1
W2
W3
W4
P Spam
W0
W1
W2
W3
W4
"
"
"
"
 |
(
)
Spam
false
=
Spam
true
=
false
false
false
false
false
false
false
false
false
true
false
false
false
true
false
false
false
false
true
true
false
false
true
false
false
false
false
true
false
true
false
false
true
true
false
false
false
true
true
true
false
true
false
false
false
false
true
false
false
true
false
true
false
true
false
false
true
false
true
true
false
true
true
false
false
false
true
true
false
true
false
true
true
true
false
false
true
true
true
true
P Spam
W0
W1
W2
W3
W4
"
"
"
"
 |
(
)

Bayesian Programming
Page 42
Observe the distribution 
 on Table 2.2, the word, "you", provides no
information at all, because it contributes of two uniform distributions. Consequently, the
value of 
 does not change anything in 
.  Observe
the probability values of subsets 1-2, 3-4, 5-6, etc.
In effect, a single word can provide much, little or no information when classifying an
email. For example, consider subset number 11 (
). Subsets 3, 12, 15, and
27 are within a distance 1 from this set. Adding or erasing a single word from set 11 has
17
0.00392659
0.996073
18
0.00392659
0.996073
19
2.09127e-08
0.99999999
20
2.09127e-08
0.99999999
21
0.998656
0.00134393
22
0.998656
0.00134393
23
0.00392659
0.996073
24
0.00392659
0.996073
25
0.747506
0.252494
26
0.747506
0.252494
27
1.57052e-05
0.999984
28
1.57052e-05
0.999984
29
0.999998
1.79193e-06
30
0.999998
1.79193e-06
31
0.747506
0.252494
32
0.747506
0.252494
Subset
fortune
next
programming
money
you
Table 2.3: The distribution 
.
W0
W1
W2
W3
W4
P Spam
W0
W1
W2
W3
W4
"
"
"
"
 |
(
)
Spam
false
=
Spam
true
=
P Spam
W0
W1
W2
W3
W4
"
"
"
"
 |
(
)
true
false
false
false
false
true
false
false
false
true
true
false
false
true
false
true
false
false
true
true
true
false
true
false
false
true
false
true
false
true
true
false
true
true
false
true
false
true
true
true
true
true
false
false
false
true
true
false
false
true
true
true
false
true
false
true
true
false
true
true
true
true
true
false
false
true
true
true
false
true
true
true
true
true
false
true
true
true
true
true
P W4
Spam
 |
(
)
W4
P Spam
W0
W1
W2
W3
W4
"
"
"
"
 |
(
)
next money
,
{
}

Basic Concepts
Page 43
different effects on the spam probability computation (Table 2.4). 
Subset 
number
Subset
3
5.24907e-06
0.999995
11
0.00392659
0.996073
12
0.00392659
0.996073
15
0.998656
0.00134393
27
1.57052e-05
0.999984
Table 2.4: Adding or subtracting a single word from subset 11 can change the probability of an email 
being spam gretly  (set 15), a little (sets 3 and 27), or not at all (set 12). 
P Spam
W1
W2
W3
W4
W5
"
"
"
"
 |
(
)
Spam
false
=
Spam
true
=
money
{
}
next money
,
{
}
next money you
,
,
{
}
next,programming,money
{
}
fortune,next,money
{
}

Bayesian Programming
Page 44

Page 45
 3
Incompleteness and 
Uncertainty
A very small cause which escapes our notice determines a considerable
effect that we cannot fail to see, and then we say that the effect is due to
chance. 
H. Poincare $$$
The goal of this chapter is twofold: (i) to present the concept of incompleteness and (ii) to
demonstrate how incompleteness is the source of uncertainty. Two experiments explore
these two topics. The first one is a very simple physical experiment called the "beam in
the bin", the second one is a model for a water treatment unit.
3.1
The "beam in the bin" investigation
In this section, we present the "beam in the bin" experiment. This experiment is based on
the simplest sensory-motor device interacting with the simplest real physical environ-

Bayesian Programming
Page 46
ment we could imagine. The goal of this extreme simplicity is to demonstrate that even in
these conditions it is impossible to build a complete model of such an interaction: there is
no way to get rid of hidden variables. Hidden variables are ignored by the model and con-
sequently some (or all) model predictions may not be in accord with the real results. A
"real" (i.e. not formal) phenomenon and its model never have the exact same behavior
because of incompleteness.
In the following we describe the "beam in the bin" experimental set-up (Figure 3.1.).
The environment consists of a green plastic bin in which a halogen lamp is fixed. The
lamp light up the inside of the bin, where multiple reflections occur.
The sensory-motor device consists of a photoelectric cell suspended from a vertical
metal bar that can turn around the vertical axis. Consequently, the photoelectric cell can
rotate through 360° and we can control its position 
 in increments of 5°. 
We can also read the output of the photoelectric cell 
, which has discrete values 
in the range from 0 (no light) to 2047 (saturation).
The experimental protocol is as follows: we rotate the photoelectric cell, exploring 72
different positions (360 degrees by 5 degree increments) and collect the corresponding
light reading for each position. Each position is measured 100 times. Using these 7200
measures, we build the histogram of the reading presented in Figure 3.2 and Figure 3.3.
For each possible position and each possible reading, the number of times it has been
observed is recorded.
Figure 3.1: The "beam in the bin" experimental set-up. A photoelectric cell explores 72 different 
positions around a vertical axis measuring the reflected beam of a lamp. Both the cell and the light 
are placed inside a bin.
Vertical rotational axis
Photoelectric cell
'
(
(

Incompleteness and Uncertainty
Page 47
This histogram has a quite obvious interpretation. The main peak corresponds to the
angular position where the cell is facing the light (angular position of 210°). The second-
ary peak corresponds to the opposite direction (30°) where the cell is facing the main
reflection.
However, if we pay more attention to this data then some curious features appear. 
Starting facing the light, turning left or right should not make any difference. The
setup has a symmetry of revolution around the vertical axis and there is apparently noth-
ing to break it. Consequently, the measured values of 
 should be symmetrical around
the axis of lighting (
), but this is obviously not the case. 
Trying to explain this absence of symmetry, the first idea is to check the position and
inclination of the vertical axis. If it were not perfectly centered and vertical, the symme-
try would be broken. Careful verifications of both position and inclination proved that
they are both correct.
The next idea that comes to mind is that there may be other sources of light (for
Figure 3.2: Histogram of the light readings 
 according to angular orientation 
.
Figure 3.3: The density plot of the histogram on Figure 3.2. Light colors show less frequent values.
(
'
000
200
400
600
800
2000
0
50
100
150
200
250
300
350
(
'
210°
=

Bayesian Programming
Page 48
example lamps, neons, or windows) around the bin that break the symmetry. This possi-
bility is rather unlikely, as the halogen lamp is very powerful and very close to the photo-
electric cell. Nevertheless, we check for this hypothesis by repeating the experiment with
a black curtain over the bin. The asymmetry is still there.
Pursuing the investigation, we then check for dust on the inside wall of the bin. The
bin is clean and glossy.
Much more complicated, we then check the quality of the angular control. Indeed, the
vertical axis is controlled by an industrial robotic arm connected to a real-time control
processor, itself the slave of a workstation. A complicated setup is required in order to
use only one degree of freedom: the rotation of the robot’s wrist. We arrange a complete
new experiment to verify that when ordered to go to a given 
, the correct angular posi-
tion is actually reached. We then discover a bug in one of the low-level control programs
of the wrist. Some of the angles are not reached with the required accuracy. This robot
had been used for years without anyone noticing this bug. However, this is not yet suffi-
cient to explain the asymmetry of the data.
Finally, we suspect the photoelectric cell. Once again, we arrange a new experiment
to test the cell. We then discover that it suffers ome hysteresis: the reading at time t is not
independent of the previous ones. When the cell comes from a brighter zone, the reading
is biased toward higher values. When collecting the data, to spend less time, we explore
the  values in sequence, going from 0° to 360°. These two facts explain  the asymetry at
least partly: after each bright area there is a plateau of high readings because of the hys-
teresis of the cell.
However, that is not completely the end of the story. By looking even more carefully
at the data you may notice that it seems that in some areas there are two peaks rather than
a single one (see Figure 3.4).  We cannot find the exact reason for this but we remember
that this data was collected in two runs on two different days. Certainly, some conditions
such as temperature, humidity, and noice changed between the two runs and this may
explain the sligt shift. Again, a "real" phenomenon and its model never have the exact
same behavior because of incompleteness.
3.2
Observing a water treatment unit 
The uncertainty of a phenomenon has two causes: (i) inaccuracies in the model and (ii)
ignored variables. In this section, we demostrate this fact by a second experiment: the
'
'

Incompleteness and Uncertainty
Page 49
water treatment unit. This experiment consists of two stages. In the first stage, we
describe the complete model of the water treatment unit, giving all the variables and func-
tions involved in the model. In the second stage, we pretend that some of the variables
and functions of the model are not disponible. In other words, we generate a synthetic
incompleteness of our model. The goal is to show the consequences of this incomplete-
ness and to present a first step towards Bayesian modeling.
3.2.1
The elementary water treatment unit
We now describe the complete model of the water treatment unit. Figure 3.5 is a sche-
matic representation. The unit takes two water streams as inputs with respective water
Figure 3.4: A zoom on the reading and orientation density plot presented on Figure 3.3 reveals that 
in some areas two peaks exist for the same orientation. Light colors are less frequent values.
Figure 3.5: The treatment unit receives two water streams of quality 
 and 
 and generates an 
output stream of quality 
. The resulting quality depends on  
,  
, two unknown variables 
 
and 
, and a control variable 
. An operator regulates 
, while the value of 
 is estimated by a 
sensor variable 
.
1350
1400
1450
1500
1550
1600
80
100
120
140
160
180
200
M1
I0
I1
O
I0
I1
H
F
C
C
F
S

Bayesian Programming
Page 50
qualities 
 and 
. Two different streams are used because partly purified water is recy-
cled to dilute the more polluted stream, to facilitate its decontamination. 
The unit produces an output stream of quality 
.
The internal functioning state of the water treatment unit is described by the variable
. This variable 
 quantifies the efficiency of the unit but is not directly measurable. For
instance, as the sandboxes becomes more loaded with contaminants the purification
becomes less and less efficient and the value of 
 becomes lower and lower.
A sensor  helps to estimate the efficiency 
 of the unit.
A controller 
 is used to regulate and optimize 
, the quality of the water in the out-
put stream. 
Finally, some external factor 
 may disturb the operation of the unit. For instance,
this external factor could be the temperature or humidity of the air.
For didactic purposes, we consider that these seven variables may each take 11 differ-
ent integer values ranging from 0 to 10. The value 0 is the worst value for 
, 
, 
, and
, and 10 is the best.
When all variables have their nominal values, the ideal quality 
 of the output stream
is given by the equation:
(3.1)
Where 
 is the integer part of x. 
The value of 
 never exceeds the value 
, reached when the unit is in perfect con-
dition, with
(3.2)
The external factor 
 may reduce the ideal quality 
 and the control 
 may try to
compensate for this disturbance or the bad condition of the treatment unit because of 
.
Consequently, the output quality 
 is obtained according to the following equations:
I0
I1
O
F
F
F
S
F
C
O
H
I0
I1
F
O
Q
Q
INT
I0
I1
F
+
+
3
-------------------------
#
$
'
(
=
INT x
( )
Q
O*
O*
INT
I0
I1
10
+
+
3
---------------------------
#
$
'
(
=
H
Q
C
F
O

Incompleteness and Uncertainty
Page 51
(3.3)
(3.4)
We consider the example of a unit directly connected to the sewer: 
.
When 
 (no control) and 
 (no disturbance), Figure 3.6 gives the value
of the quality 
 according to 
, (
).
When the state of operation is not optimal (
 different from 10), it is possible to com-
pensate using 
. However, if we over-control, then it may happen that the output deteri-
orates. For instance, if  
, the outputs obtained for the
different values of 
 are shown in Figure 3.7.
The operation of the unit may be degraded by 
. For instance, if
, the output obtained for the different values of 
 are
shown in Figure 3.8.
Finally, the value of the sensor  depends on 
 and 
 as follows:
Figure 3.6: The output 
 as a function of the functioning state 
 with inputs, control and external 
factor fixed to:
.
)
INT
I0
I1
F
C
H
–
+
+
+
3
----------------------------------------------
#
$
'
(
=
O
)
if 0
)
O*
%
%
(
)
2O*
)
–
(
) if )
O*
>
(
)
0
otherwise
)
*
*
*
+
*
*
*
,
=
I0
2
=
[
]
I1
8
=
[
]
,
C
0
=
[
]
H
0
=
[
]
O
F
O*
6
=
0
1
2
3
4
5
6
7
Output (O)
2
4
6
8
10
Functioning state (F)
O
F
I0
2
=
[
]
I1
8
=
[
]
C
0
=
[
]
H
0
=
[
]
"
"
"
F
C
I0
2
=
[
]
I1
8
=
[
]
F
8
=
[
]
H
0
=
[
]
,
,
,
C
H
I0
2
=
[
]
I1
8
=
[
]
F
8
=
[
]
C
0
=
[
]
,
,
,
H
S
I0
F

Bayesian Programming
Page 52
(3.5)
The outputs of  in the 121 possible situations for 
 and 
 are shown in Figure 3.9.
Note that,  if we know 
, 
, 
, 
, and 
, we know with certainty the values of both 
and 
. At this stage, our water treatment unit is a completely deterministic process. Con-
sequently, a complete model can be constructed. 
Now consider what happens if we ignore the exact equations that rule the water treat-
Figure 3.7: The output 
 as a function of control 
 with inputs, functioning state and external 
factor fixed to: 
.
Figure 3.8: The output 
 as a function of the external factor 
 with inputs, functioning state and 
control fixed to: 
.
0
1
2
3
4
5
6
7
Output (O)
2
4
6
8
10
Control (C)
O
C
I0
2
=
[
]
I1
8
=
[
]
F
8
=
[
]
H
0
=
[
]
,
,
,
0
1
2
3
4
5
6
7
Output (O)
2
4
6
8
10
External Factor (H)
O
H
I0
2
=
[
]
I1
8
=
[
]
F
8
=
[
]
C
0
=
[
]
,
,
,
S
INT
I0
F
+
2
--------------
#
$
'
(
=
S
I0
F
I0 I1 F H
C
S
O

Incompleteness and Uncertainty
Page 53
ment unit and, of course, the existence of the external factor 
. The starting point for
constructing our own model is limited to knowing the existence of the variables  
,
,
, , 
, and 
, and that the value of  
 on 
 and that of  depends on
.
What do we need to do now? Observe the behavior of the water treatment unit, in par-
ticular the quality of the output stream 
, for different values of 
, as well
as the sensor value 
 for different values of 
 (remember that 
 cannot be observed).
During these observations you will note that there are different situations in which uncer-
tainty appears. The goal of the following section is to discuss this uncertainty.
3.2.2
Experimentation and uncertainty
 Uncertainty on 
 because of inaccuracy of the sensor 
A given value of  corresponds to several possible values of 
 and 
.  For instance,
seven pairs of values of 
 correspond to 
 in Figure 3.9. 
Worse tha this, even knowing 
 and S, two values of 
 are possible most of the time
(see Figure 3.10). This fact will introduce some noise in the prediction of 
.
To illustrate this effect let us first experiment with 
: the operation of the water
treatment unit is not disturbed. For 
, we can explore the differ-
ent possible values of the output 
 when 
 varies. However, as 
 is not directly observ-
able, we can only collect data concerning 
 and 
. These data are presented on Figure
3.11.
For some  it is possible to predict exactly the output 
:
Figure 3.9: The sensor 
 as a function of input 
 and functioning state 
.
0
1
2
3
4
5
6
7
8
9
10
Input (I0)
0
2
4
6
8 10
Functioning state (F0)
0
1
2
3
4
5
6
7
8
9
10
Sensor (S0)
S
I0
F
H
I0
I1 F S
C
O
O
I0
I1
S
C
"
"
"
S
I0
F
"
O
I0
I1
S
C
"
"
"
S
I0
F
O
S
S
I0
F
I0
F
"
S
1
=
[
]
I0
F
O
H
0
=
I0
2
=
[
]
I1
8
=
[
]
C
2
=
[
]
,
,
O
F
F
S
O
S
O

Bayesian Programming
Page 54
1. 
2. 
3. 
4. 
Figure 3.10: The sensor reading 
 as a function of the functioning sate 
when the input 
.
Figure 3.11: Histogram of the observed sensor state 
 and the output 
when the inputs, the control and the external factor are fixed to 
 and the internal function 
 is generated randomly with 
a uniform distribution.
0
1
2
3
4
5
6
Sensor (S)
2
4
6
8
10
Functioning state (F)
S
F
I0
2
=
[
]
0
2
4
6
8
10
Output (O)
0
2
4
6
8
10
Sensor (S)
0
400
800
1200
1600
Frequency
S
O
I0
2
=
[
]
I1
8
=
[
]
C
2
=
[
]
H
0
=
[
]
,
,
,
F
S
1
=
[
]
O
4
=
[
]
"
S
3
=
[
]
O
5
=
[
]
"
S
4
=
[
]
O
6
=
[
]
"
S
6
=
[
]
O
5
=
[
]
"

Incompleteness and Uncertainty
Page 55
For some other values of  it is not possible to predict the potput  
 with certainty:
1. If 
, then 
 may take the value either four or five, with a slightly higher
probability for four. Indeed, when 
, then 
 may be either two or three (see
Figure 3.10) and, 
 will, respectively, be either four or five.
2. If 
, then 
 may take the value either five or six, with a slightly lower prob-
ability for five. When 
, 
 may be either eight or nine.
Some uncertainty appears here because of the inaccuracy of the sensor , which may
return the same reading for two different situations.
Uncertainty because of the ignored variable 
Let us now do the same experiment for a disturbed process (value of 
 drawn at random
from the 11 possible values). Of course, we obtain different results with more uncertainty
due to the effect on the output of the hidden variable
. The obtained data when
 is presented on Figure 3.12. 
In contrast with our previous experiment, this time no the value of 
 is sufficient to
infer the value of 
 exactly. 
Figure 3.12: Two views of the histogram of the observed sensor state 
 and the output 
when the inputs and the control are set to 
 and the values of the 
external factor and the internal functioning 
 are generated randomly with an uniform 
distribution. 
S
O
S
2
=
[
]
O
S
2
=
[
]
F
O
S
5
=
[
]
O
S
5
=
[
] F
S
H
H
H
I0
2
=
[
]
I1
8
=
[
]
C
2
=
[
]
"
"
0
2
4
6
8
10
Output (O)
0
2
4
6
8
10
Sensor (S)
0
100
200
300
400
500
600
Frequency
0
2
4
6
8
10
Output (O)
0
2
4
6
8
10
Sensor (S)
0
100
200
300
400
500
600
Frequency
S
O
I0
2
=
[
]
I1
8
=
[
]
C
2
=
[
]
,
,
H
F
"
S
O

Bayesian Programming
Page 56
The dispersion of the observations is the direct translation of the effect of 
. Taking
into account the effect of hidden variables such as 
 and even measuring their impor-
tance is one of the major challenges that Bayesian Programming must face. This is not an
easy task when you are not even aware of the nature and number of these hidden vari-
ables! 
3.3
Lessons, comments and notes
3.3.1
The effect of incompleteness
We assume that any model of a "real" (i.e. not formal) phenomenon is incomplete. There
are always some hidden variables, not taken into account in the model, that influence the
phenomenon. Furthermore, this incompleteness is irreducible: for any physical phenome-
non, there is no way to build an exact model with no hidden variables1. 
The effect of these hidden variables is that the model and the phenomenon never have
exactly reproducible behavior. Uncertainty appears as a direct consequence of this incom-
pleteness. Indeed, the model may not completely take into account the data and may not
predict exactly the behavior of the phenomenon2.
For instance, in the above example, the influence of the hidden variable 
, makes it
impossible to predict with certainty the output 
 given the inputs 
 and 
, the reading
of the sensor , and the control 
.
3.3.2
The effect of inaccuracy
The above example also demonstrates that there is another source of uncertainty: the
inaccuracy of the sensors.
By inaccuracy, we mean that a given sensor may read the same value for different
underlying situations. Here, the same reading on  may correspond to different values of
.
 is not a hidden variable as it is taken into account by the model. However, 
 can-
not be measured directly and exactly. The values of 
 can only be inferred indirectly
through the sensor  and they cannot be inferred with certainty.
It may be seen as a weak version of incompleteness, where a variable is not completely
1.
See FAQ/FAM 16.16 "Incompleteness irreducibility", page 202 for further discussion of that matter.
2.
See FAQ/FAM 16.24 "Noise or ignorance?", page 203 for more information on this subject.
H
H
H
O
I0
I1
S
C
S
F
F
F
F
S

Incompleteness and Uncertainty
Page 57
hidden but is only partially known and accessible. Even though it is weak, this incom-
pleteness still generates uncertainty.
3.3.3
Not taking into account the effect of ignored variables may lead to wrong deci-
sions
Once the effects of the irreducible incompleteness of models eare recognized, a program-
mer must deal with them either ignoring them and using the incomplete models, or trying
to take incompleteness into account using a probabilistic model. 
Using a probabilistic model clearly appears to be the better choice as it will always
lead to better decisions, based on more information than the nonprobabilistic one.
For instance, a  nonprobabilistic model of our production unit, not taking into account the
variable 
 would be, for instance1:
(3.6)
(3.7)
(3.8)
It would lead to false predictions of the output 
 and, consequently, to wrong control
decision on 
 to optimize this output.
For 
instance, 
scanning 
the 
11 
different 
possible 
values 
for 
 
when
 and consequently 
 the above model predicts that indif-
ferently for  
, 
, and 
, 
 will take its optimal value: six (see Fig-
ure 3.7).
The observations depict a somewhat different and more complicated "reality" as
shown in Figure 3.13. 
1.
Note the absence of 
H
H
)
INT
I0
I1
F
C
+
+
+
3
-----------------------------------
#
$
'
(
=
O
)
if 0
)
O*
%
%
(
)
2O*
)
–
(
) if )
O*
>
(
)
0
otherwise
)
*
*
*
+
*
*
*
,
=
S
INT
I0
F
+
2
--------------
#
$
'
(
=
O
C
C
I0
2
=
[
]
I1
8
=
[
]
F
8
=
[
]
,
,
S
5
=
[
]
C
0
=
[
]
C
1
=
[
]
C
2
=
[
]
O

Bayesian Programming
Page 58
The choice of 
 to optimize 
 is now more complicated but also more informed.
The adequate choice of 
 to produce the optimal output 
 is now, with nearly
equivalent probabilities, to select a value of 
 greater than or equal to two. Indeed, this
is completely different choice from when the "exact" model is used!
3.3.4
From incompleteness to uncertainty
Any program that models a real phenomenon must face a central difficulty: how should it
use an incomplete model of the phenomenon to reason, decide, and act efficiently? 
Definition 3.1  The purpose of Bayesian Programming is precisely to tackle this prob-
lem with a well-established formal theory: probability calculus. The sequel of this
book will try to explain how to do this.
In the Bayesian Programming approach, the programmer does not propose an exact
model but rather expresses a probabilistic canvas in the specification phase. This proba-
bilistic canvas gives some hints about what observations are expected. The specification
is not a fixed and rigid model purporting completeness. Rather, it is a framework, with
open parameters, waiting to be shaped by the experimental data. Learning is the means of
setting these parameters. The resulting probabilistic descriptions come from both: (i) the
views of the programmer and (ii) the physical specifics of each phenomenon. Even the
influence of the hidden variables is taken into account and quantified; the more important
their effects, the more noisy the data, and the more uncertain the resulting descriptions.
Figure 3.13: The output 
 as a function of the controller 
 when the inputs and the internal 
functioning are fixed to 
.
0
2
4
6
8
10
Output (O)
0
2
4
6
8
10
Control (C)
0
100
200
300
400
500
Frequency
O
C
I0
2
=
[
]
I1
8
=
[
]
F
8
=
[
]
,
,
C
O
C
O
6
=
[
]
C

Incompleteness and Uncertainty
Page 59
The theoretical foundations of Bayesian Programming may be summed up by Figure
3.14.
The first step in Figure 3.14 transforms the irreducible incompleteness into uncer-
tainty. Starting from the specification and the experimental data, learning builds proba-
bility distributions.
The maximum entropy principle is the theoretical foundation of this first step. Given
some specifications and some data, the probability distribution that maximizes the
entropy is the distribution that best represents the combined specification and data.
Entropy gives a precise, mathematical and quantifiable meaning to the quality of a distri-
bution1. 
Two extreme examples may help to understand what occurs:
•
Suppose that we are studying a formal phenomenon. There may not be any hidden
variables. A complete model may be proposed. The phenomenon and the model
could be identical. For instance, this would be the case if we take the equations of
Section  as the model of the phenomenon described in that same section. If we
select this model as the specification, any data set will lead to a description made
of Diracs. There is no uncertainty; any question may be answered either by true or
Figure 3.14: Theoretical foundation.
1.
See FAQ/FAM 16.22 "Maximum entropy principle justifications", page 203 for justifications for the use of the maximum
entropy principle.
Incompletness
Maximum Entropy
Principle
-* pi ln(pi)
Preliminary Knowledge
+
Experimental Data
=
Probability Distributions
Uncertainty
Decision
P(a b |+) = P(a |+)P(b |a +)=P(b |+)P(a |b +)
P(¬a |+)+P(¬a |+) = 1 
Bayesian Inference

Bayesian Programming
Page 60
false. Logic appears as a special case of the Bayesian approach in that particular
context (see Cox, 1979).
•
At the opposite extreme, suppose that the specification consists of very poor
hypotheses about the modeled phenomenon, for instance, by ignoring 
 and also
the inputs 
 and 
 in a model of the above process. Learning will only lead to
flat distributions, containing no information. No relevant decisions can be made,
only completely random ones.
Hopefully, most common cases are somewhere  between these two extremes. Specifi-
cation, even imperfect and incomplete, is relevant and provides interesting hints about
the observed phenomenon. The resulting descriptions are neither Diracs nor uniform dis-
tributions. They give no certitudes, although they provide a mean of taking the best pos-
sible decision according to the available information. This is the case here when the only
hidden variable is 
.
The second step in Figure 3.14 consists of reasoning with the probability distributions
obtained by the first step.
To do so, we only require the two basic rules of Bayesian inference presented in
Chapter 2. These two rules are to Bayesian inference what the resolution principle is to
logical reasoning (see Robinson, 1965; Robinson, 1979; Robinson & Sibert, 1983a; Rob-
inson & Sibert, 1983b). These inferences may be as complex and subtle as those usually
achieved with logical inference tools, as will be demonstrated in the different examples
presented in the sequel of this book.
H
I0
I1
H

Page 61
 4
Description = Specification 
+ Identification
The scientific methodolgy forbids us to have an opinion on questions
which we do not understand, on questions which we do not know how to
put clearly. Before anything else, we must know how to state problems. In
science problems do not appear spontaneously. This "sens of problem" is
precisely what characterize a true scientific mind. For such a mind, any
knowledge is an answer to a question. Without a question there cannot be
scientific knowledge. Nothing is obvious. Nothing is given. Everything is
built.1
Gaston Bachelard, La formation de l’esprit scientifique
1.
L'esprit scientifique nous interdit d'avoir une opinion sur des questions que nous ne comprenons pas, sur des questions que
nous ne savons pas poser clairement. Avant tout, il faut savoir poser les problemes. Et quoi qu'on dise, dans la vie scientifique,
les problemes ne se posent d'eux-memes.C'est precisement ce "sens du probleme" qui donne la marque du veritable esprit sci-
entifique. Pour un esprit scientifique, toute connaissance est une réponse a une question. S'il n'y a pas eu de question, il ne peut
y avoir connaissance scientifique. Rien ne va de soi. Rien n'est donne. Tout est construit. (Bachelard, 1938)

Bayesian Programming
Page 62
In this chapter, we come back to the fundamental notion of description. A description is a
probabilistic model of a given phenomenon. It is obtained after two phases of develop-
ment:
1. A specification phase where the programmer expresses in probabilistic terms his
own knowledge about the modelled phenomenon.
2. An identification phase where this starting probabilistic canvas is refined by learn-
ing from data.
Descriptions are the basic elements that are used, combined, composed, manipulated,
computed, compiled, and questioned in different ways to build Bayesian programs.
4.1
Pushing objects and following contours
To introduce this notion of description we present two very simple robotic experiments
where we want a small mobile robot named Khepera either to push objects or to follow
their contours.
4.1.1
The Khepera robot
Khepera is a two-wheeled mobile robot, 57 millimeters in diameter and 29 milimeters in
height, with a total weight of 80 grams (see Figure 4.1). It was designed at EPFL1 and is
commercialized by K-Team2.
The robot is equipped with eight light sensors (six in front and two behind), which
takes values between 0 and 511 in inverse relation to light intensity, stored in variables
 (see Figure 4.2).
These eight sensors can also be used as infrared proximeters, taking values between 0
and 1023 in inverse relation to the distance from the obstacle, stored in variables
 (see Figure 4.2).
The robot is controlled by the rotation speeds of its left and right wheels, stored in
variables 
 and 
, respectively.
From these 18 basic sensory and motor variables, we derive two new sensory vari-
ables (
 and 
) and one new motor variable (
). They are described below:
1.
Ecole Polytechnique Fédérale de Lausanne (Switzerland)
2.
http://www.K-team.com/
L0 ... L7
,
,
Px0 ... Px7
,
,
Ml
Mr
Dir
Prox
Rot

Description = Specification + Identification
Page 63
•
 is a variable that approximately corresponds to the bearing of the closest
obstacle (see Figure 4.2). It takes values between -10 (obstacle to the left of the
robot) and +10 (obstacle to the right of the robot), and is defined as follows:
Figure 4.1: The Khepera mobile robot.
Figure 4.2: The sensory-motor variables of the Khepera robot.
Vrot
Dir = +10
Dir = !10
Prox
7
1
2
3
4
5
6
Dir =0
Dir
8
!
+
Dir

Bayesian Programming
Page 64
(4.1)
•
 is a variable that approximately corresponds to the proximity of the closest
obstacle (see Figure 4.2). It takes values between 0 (obstacle a long way from the
robot) and 15 (obstacle very close to the robot), and is defined as follows:
(4.2)
•
The robot is piloted solely by its rotation speed (the translation speed is fixed). It
receives motor commands from the 
 variable, calculated from the difference
between the rotation speeds of the left and right wheels. 
 takes on values
between -10 (fastest to the left) and +10 (fastest to the right).
4.1.2
Pushing objects
The goal of the first experiment is to teach the robot how to push objects.
First, in a specification phase, the programmer specifies his knowledge about this
behavior in probabilistic terms.
Then, in a learning phase (identification), we drive the robot with a joystick to push
objects. During that phase, the robot collects, every tenth of a second, both the values of
its sensory variables and the values of its motor variables (determined by the joystick
position). These data set are then used to identify the free parameters of the parametric
forms.
Finally, in a restitution phase, the robot must reproduce the behavior it has just
learned. Every tenth of a second it decides the values of its motor variables, knowing the
values of its sensory variables and the internal representation of the task (the descrip-
tion).
Specification
Having defined our goal, we describe the three steps necessary to define the preliminary
knowledge.
1. Chose the pertinent variables
Dir
FLOOR
90 Px5
Px0
–
(
)
45 Px4
Px1
–
(
)
5 Px3
Px2
–
(
)
+
+
9 1
Px0
Px1
Px2
Px3
Px4
Px5
+
+
+
+
+
+
(
)
--------------------------------------------------------------------------------------------------------------------
#
$
%
&
'
(
=
Prox
Prox
FLOOR
MAX Px0 Px1 Px2 Px3 Px4 Px5
,
,
,
,
,
(
)
64
---------------------------------------------------------------------------------------
#
$
'
(
=
Rot
Rot

Description = Specification + Identification
Page 65
2. Decompose the joint distribution
3. Define the parametric forms
Variables
First, the programmer specifies which variables are pertinent for the task.
To push objects it is necessary to have an idea of the position of the objects relative to
the robot. The front proximeters provide this information. However, we chose to summa-
rize the information from these six proximeters by the two variables 
 and 
.
We also chose to set the translation speed to a constant and to operate the robot by its
rotation speed 
. 
These three variables are all we require to push obstacles. Their definitions are sum-
marized up as follows:
(4.3)
Decomposition
In the second specification step, we give a decomposition of the joint probability
 as a product of simpler terms.
(4.4)
This equality simply results from the application of the conjunction rule (2.5).
Forms
To be able to compute the joint distribution, we must finally assign parametric forms to
each of the terms appearing in the decomposition:
(4.5)
We have no a priori information about the direction or distance of the obstacles.
Dir
Prox
Rot
Dir
10
–
... 10
,
,
{
}
!
CARD Dir
(
)
21
=
,
Prox
0 ... 15
,
,
{
}
!
CARD Prox
(
)
16
=
,
Rot
10
–
... 10
,
,
{
}
!
CARD Rot
(
)
21
=
,
Dir
Prox
Rot
"
"
(
)
P
Dir
Prox
Rot
"
"
(
)
P
Dir
Prox
"
(
)
P
Rot
Dir
Prox
"
 |
(
)
P
×
=
Dir
Prox
"
(
)
P
UNIFORM
,
Rot
Dir
Prox
"
 |
(
)
P
B µ Dir Prox
,
(
) - Dir Prox
,
(
)
,
(
)
,

Bayesian Programming
Page 66
Hence, 
  is a uniform distribution, with all directions and proximities hav-
ing the same probability. As we have 
 different possible values for 
 we
get:
(4.6)
For each sensory situation, we believe that there is one and only one rotation speed
(
) that should be preferred. The distribution 
 is thus unimodal.
However, depending of the situation, the decision to be made for 
 may be more or less
certain. This is presumed by assigning a Bell-shaped1 parametric form to
. For each possible position of the object relative to the robot we
have a bell-shaped distribution. Consequently, we have 
 bell-shaped distri-
butions and we have 
 free parameters: 
 means and 
 standard
deviations.
Identification
To set the values of these free parameters we drive the robot with a joystick (see Movie
12), and collect a set of data.
Every tenth of a second, we obtain the value of 
 and 
 from the  proximeters
and the value of 
 from the joystick. Let us call the particular set of data corresponding
to this experiment 
. A datum collected at time  is a triplet 
. Dur-
ing the 
 seconds of learning, 
 such triplets are recorded.
From the collection 
 of such data, it is very simple to compute the correspond-
ing values of the free parameters. We first sort the data in  
 groups, each correspond-
ing to a given position of the object and then compute the mean and standard deviation of
 for each of these groups. There are only 
 triplets for 
 groups.
Moreover, these 
 triplets are concentrated around some particular positions often
observed when pushing obstacles. Consequently, it may often happen that a given posi-
tion never occurs and that no data is collected for this particular situation. In that case,
we set the corresponding mean to zero and the standard deviation to 10. The  bell-shaped
distribution is then flat, close to a uniform distribution.
1.
Bell-shaped distributions are distributions on discrete variables that have a Gaussian shape. They are noted with the 
symbol and defined by their mean and standard deviation as regular Gaussian on continuous variables.
2.
Movie 1 at http://bayesian-programming.org/book/movies
Dir
Prox
"
(
)
P
21
16
×
Dir
Prox
"
dir
prox
"
(
)
P
1
21
16
×
------------------
1
336
---------
=
=
Rot
Rot
Dir
Prox
"
 |
(
)
P
Rot
B
Rot
Dir
Prox
"
 |
(
)
P
21
16
×
336
=
2
21
16
×
×
772
=
336
336
Dir
Prox
Rot
.-push
t
rot
t dir
t prox
t
,
,
(
)
30
300
.-push
336
Rot
300
336
300

Description = Specification + Identification
Page 67
Figure 4.3 presents three of the 336 curves. The first one corresponds to an obstacle
very close to the left (
), and shows that the robot should turn to
the left rapidly with average uncertainty. The second one corresponds to an obstacle right
in front and in contact (
), and shows that the robot should go
straight with very low uncertainty. Finally, the last one shows an unobserved situation
where the uncertainty is maximal.
Results
To render the pushing obstacle behavior just learned, a decision on 
 is made every
tenth of a second according to the following algorithm.
1. The sensors are read and the values of 
 and 
 are computed
2. The corresponding distribution 
 is selected from the 
 dis-
tributions stored in memory.
3. A value  
 is drawn at random according to this distribution and sent to the
motors.
Figure 4.3: 
 when pushing objects for different situations.
 Dir=–10, Prox=13
Dir=0, Prox=15
Dir=3,Prox=0
0
0.1
0.2
0.3
0.4
Probability
–8
–6
–4
–2
0
2
4
6
8
10
Rot
Rot
Dir
Prox
"
 |
(
)
P
Dir
10
–
=
[
]
Prox
13
=
[
]
,
Dir
0
=
[
]
Prox
15
=
[
]
,
Rot
dir
t
prox
t
Rot
prox
t
dir
t
"
 |
(
)
P
336
rot
t

Bayesian Programming
Page 68
As shown in Movie 11, the Khepera learns how to push obstacles in 30 seconds. It
learns the particular dependency, corresponding to this specific behavior, between the
sensory variables 
 and 
, and the motor variable 
.
This dependency is largely independent of the particular characteristics of the objects
(such as weight, color, balance, or nature). Therefore, as shown in Movie 22, the robot is
also able to push different objects. This, of course, is only true within certain limits. For
instance, the robot will not be able to push an object if it is too heavy.
4.1.3
Following contours
The goal of the second experiment is to teach the robot how to follow the contour of an
object.
We will follow the same steps as in the previous experiment: first, a specification
phase, then an identification phase where we also drive the robot with a joystick but this
time to follow the contours.
We keep the exact same specification, changing only the data to be learned. The
resulting description is however completely different: following contours of objects
instead of pushing them.
Specification
Variables
To follow the contours, we must know where the object is situated relative to the robot.
This is defined by the variables 
 and 
, as in the previous experiment. We must
also pilot the robot using its rotation speed with the variable 
. The required variables
are thus exactly the same as previously:
(4.7)
Decomposition
The decomposition does not change either:
1.
Movie 1 at http://bayesian-programming.org/book/movies
2.
Movie 2 at http://bayesian-programming.org/book/movies
Dir
Prox
Rot
Dir
Prox
Rot
Dir
10
–
… 10
,
,
{
}
!
CARD Dir
(
)
21
=
,
Prox
0 … 15
,
,
{
}
!
CARD Prox
(
)
16
=
,
Rot
10
–
… 10
,
,
{
}
!
CARD Rot
(
)
21
=
,

Description = Specification + Identification
Page 69
(4.8)
Forms
Finally, the parametric forms are also the same:
(4.9)
We still have no idea of the possible position of the object relative to the robot and we
still believe that for a given sensory situation, there is one, and only one, rotation speed
that should be preferred.
Identification
In contrast, the learned data are completely different, because we are driving the robot to
do some contour following (see Movie 31). The learning process is the same but the data
set, called 
, is completely different.
The collection 
 of data leads to completely different values of the 
 means
and standard deviation of the bell-shaped distributions. This clearly appears in the fol-
lowing distributions presented for the same relative positions of the object and the robot
as in the previous experiment:
•
Figure 4.4 shows the two distributions obtained after learning for both experi-
ments (pushing objects and following contours) when the object is close to the left
(
). When pushing, the robot turns left to face the object;
on the contrary, when following, the robot goes straight bordering the object.
•
Figure 4.5 shows the two distributions obtained after learning for both experi-
ments (pushing objects and following contours) when the object is in contact right
in front of the robot (
). When pushing, the robot goes
straight. On the contrary, when following, the robot turns to the right to have the
1.
Movie 3 at http://bayesian-programming.org/book/movies
Dir
Prox
Rot
"
"
(
)
P
Dir
Prox
"
(
)
P
Rot
Dir
Prox
"
 |
(
)
P
×
=
Dir
Prox
"
(
)
P
UNIFORM
,
Rot
Dir
Prox
"
 |
(
)
P
B µ Prox Dir
,
(
) - Prox Dir
,
(
)
,
(
)
,
.-follow
.-follow
336
Dir
10
–
=
[
]
Prox
13
=
[
]
,
Dir
0
=
[
]
Prox
15
=
[
]
,

Bayesian Programming
Page 70
object on its left. However, the uncertainty is large in this last case.
Results
The restitution process is also the same, but as the bell-shaped distributiond are different,
Figure 4.4: 
when pushing objects and when following contours.
Figure 4.5: 
when pushing objects and when following contours.
Following
Pushing
0
0.1
0.2
0.3
0.4
Probability
–8
–6
–4
–2
0
2
4
6
8
10
Rot
Rot
Dir
10
–
=
[
]
Prox
13
=
[
]
"
 |
(
)
P
Pushing
Following
0
0.1
0.2
0.3
0.4
Probability
–8
–6
–4
–2
0
2
4
6
8
10
Rot
Rot
Dir
0
=
[
]
Prox
15
=
[
]
"
 |
(
)
P

Description = Specification + Identification
Page 71
the resulting behavior is completely different, as demonstrated by Movie 3.
It should be noted that one turn around the object is enough to learn the contour fol-
lowing behavior.
4.2
Description of a water treatment unit
Let us return to the previous example of a water treatment unit, and try to build the
description of this process.
4.2.1
Specification
Variables
Following our Bayesian Programming methodology, the first step in building this
description is to choose the pertinent variables.
The variables to be used by our Bayesian model are obviously the following:
(4.10)
where every of this variables has a cardinality of 11. Of course 
 is missing.
Decomposition
Using the conjunction postulate (2.7) iteratively, we can write that the joint probability
distribution on the six variables is equal to:
(4.11)
This is an exact mathematical expression.
The designer knows more about the process than this exact form. For instance, he or
she knows that:
1. The qualities of the two input streams 
 and 
 are independent:
I0 I1 F S C O
,
,
, ,
,
0 ... 10
,
,
{
}
!
H
I0
I1
F
S
C
O
"
"
"
"
"
(
)
P
I0
(
)
P
I1|I0
(
)
P
F|I0
I1
"
(
)
P
S|I0
I1
F
"
"
(
)
P
×
×
×
=
.
C|I0
I1
F
S
"
"
"
(
)
P
×
O|I0
I1
F
S
C
"
"
"
"
(
)
P
×
I0
I1

Bayesian Programming
Page 72
(4.12)
2. The state of operation of the unit is independent of both entries:
(4.13)
3. The reading of the sensor depends only on 
 and 
. It does not depend on 
.
(4.14)
4. The control 
 may not be established without knowing the desired output 
. Con-
sequently, as long as 
 is unknown, 
 is independent of the entries and of the
state of operation.
(4.15)
A few more thoughts may be necessary about this simplification, which is rather
subtle. If you do know the desired output 
, the control 
 will obviously depend
on the entries, the state of operation and the reading of the sensor. However, if you
do not know the objective, could you think of any reason to condition the control
 on these variables? If you do not know where you want to go, do you have any
good reason to choose a specific direction, even knowing the map and where you
are?
5. The output 
 depends on 
, 
, 
, 
, and 
. However, because of the presence
of the sensor, there is some redundancy between 
, 
 and . If you know 
 and
, then obviously knowing 
 does not bring any new information. This could be
used to state: 
. Knowing 
 and
, there is still some uncertainty about 
 (see Figures 3.9 & 3.10). However, as the
value of 
 is not directly accessible for learning, we may consider as a first
approximation that knowing 
 and , 
 may be neglected:
I0|I1
(
)
P
I0
(
)
P
=
F|I0
I1
"
(
)
P
F
( )
P
=
I0
F
I1
S|I0
I1
F
"
"
(
)
P
S|I0
F
"
(
)
P
=
C
O
O
C
C|I0
I1
F
S
"
"
"
(
)
P
C
(
)
P
=
O
C
C
O
I0
I1
F
S
C
I0
F
S
I0
F
S
O|I0
I1
F
S
C
"
"
"
"
(
)
P
O|I0
I1
F
C
"
"
"
(
)
P
=
I0
S
F
F
I0
S
F

Description = Specification + Identification
Page 73
(4.16)
Finally, the decomposition of the joint probability will be specified as:
(4.17)
We see here a first example of the "art of decomposing" a joint distribution.
The decomposition is a means to compute the joint distribution and, consequently,
answer all possible questions. This decomposition has the following qualities:
•
It is a better model than the basic joint distribution, because we add some useful
knowledge through points 1 to 5 above.
•
It is easier to compute than the basic joint distribution, because instead of working
in a six-dimensional space, we will do the calculation in spaces of smaller dimen-
sion (see Chapter 5 for more on this).
•
It is easier (or at least possible) to identify. The simplification of point 5 has been
made for that purpose.
Forms
To finish the specification task, we must still specify the parametric forms of the distribu-
tion appearing in the decomposition:
Figure 4.6: The graphical model of Expression (4.17), a water treatment unit. 
O|I0
I1
F
S
C
"
"
"
"
(
)
P
O|I0
I1
S
C
"
"
"
(
)
P
=
I0
I1
F
C
S
O
"
"
"
"
"
(
)
P
I0
(
)
P
I1
(
)
P
F
( )
P
×
S
I0
F
"
 |
(
)
P
×
C
(
)
P
×
O
I0
I1
S
C
"
"
"
 |
(
)
P
×
×
=

Bayesian Programming
Page 74
1. We have no a priori information on the entries 
 and 
:
(4.18)
2. Neider do we have any a priori information on 
:
(4.19)
3. We know an exact model of the sensor :
(4.20)
Where:
 
(4.21)
is a Dirac distribution with probability one if and only if:
 
.
(4.22)
4. Not knowing the desired output 
, all possible controls are equally probable:
(4.23)
5. Finally, each of the 
 distributions 
(one for each possible value of 
) is defined as a histogram on the 11
possible values of 
.
4.2.2
Identification
After the specification phase, we end up with 
 distributions with 11 free parameters
each. Thus we have 
 free parameters to identify.
To do this we will run the simulator described in Chapter 3, drawing at random with
I0
I1
I0
(
)
P
UNIFORM
,
I1
(
)
P
UNIFORM
,
F
F
( )
P
UNIFORM
,
S
S
I0
F
"
 |
(
)
P
.
INT
I0
F
+
2
--------------
#
$
'
(
I0
F
"
(
)
,
.
INT
I0
F
+
2
--------------
#
$
'
(
S
INT
I0
F
+
2
--------------
#
$
'
(
=
O
C
(
)
P
UNIFORM
,
11
4
11
11
×
11
×
11
×
=
O
I0
I1
S
C
"
"
"
 |
(
)
P
I0
I1
S
C
"
"
"
O
11
4
11
5
161051
=

Description = Specification + Identification
Page 75
uniform distributions 
, 
, 
, 
 and 
. For each of these draws (for instance, 
 of
them), we compute the corresponding values of the sensor 
 and the output 
. We then
update the 
 histograms according to the values of 
, 
, , 
, and 
.
4.2.3
Results
Such histograms have already been presented in previous chapters, for instance, in Figure
3.12 reproduced below as Figure 4.7 may be seen as a collection of 11 of these histograms
 when 
 and 
 varies. Note that now
probability values are indicated rather than the number of observations. Consequently,
the values have been normalized along each line. This operation changes the relative
dimension of these lines.
The complete description of the elementary water treatment unit is made of 
 histo-
grams, 
 times as much data as in Figure 4.7.
4.3
Lessons, comments and notes
4.3.1
Description = Specification + Identification
Descriptions are the basic elements that are used, combined, composed, manipulated,
computed, compiled, and questioned in different ways to build Bayesian programs.
A description is the probabilistic model of the observed phenomenon.
Figure 4.7: Two views of the collection of distributions represented by 
. The 11 values of 
  (0 to 10) generate the same 
number of distributions.
I0
I1
F
H
C
10
7
S
O
11
4
I0 I1
S
C
O
0
2
4
6
8
10
Output (O)
0
2
4
6
8
10
Sensor (S)
0
100
200
300
400
500
600
Frequency
0
2
4
6
8
10
Output (O)
0
2
4
6
8
10
Sensor (S)
0
100
200
300
400
500
600
Frequency
O
I0
2
=
[
]
I1
8
=
[
]
S
C
2
=
[
]
"
"
"
 |
(
)
P
S
O
I0
I1
S
C
"
"
"
 |
(
)
P
I0
2
=
[
]
I1
8
=
[
]
C
2
=
[
]
,
,
S
11
4
11
3

Bayesian Programming
Page 76
As such, it results from both the a priori knowledge of the programmer about this phe-
nomenon1 and from the experimental data.
The programmer’s a priori knowledge is expressed in a first phase called the specifi-
cation phase (see below, § 4.3.2). The experimental data are taken into account during an
identification (or learning) phase where the free parameters of the specification are given
their values.
The two robotics experiments describe above (pushing and following contours) prove
the importance of this identification phase. For a given specification but different experi-
mental data, you can obtain completely different descriptions (i.e. different models of the
phenomenon).
4.3.2
Specification = Variables + Decomposition + Forms
The knowledge of the programmer is always expressed the same way:
1. Choose the pertinent variables.
2. Decompose the joint distribution.
3. Define the parametric forms.
This strict and simple methodology and framework for the expression of the prelimi-
nary knowledge of the programmer presents several fundamental advantages:
1. It is a programming baseline that guides any development of a Bayesian program.
2. It compels the programmer to express all available knowledge using this formal-
ism, thus forcing a rigorous modeling process
3. It warrants that no piece of knowledge stays implicit. Everything that is known
about the phenomenon is expressed within this formalism. Nothing is hidden else-
where in any other piece of code of the program.
4. It is a formal and unambiguous common language to describe models. It could be
used very efficiently to discuss and compare different models.
1.
We adopt here an unambiguous subjectivist epistemological position about probability. Explanation about the fundamental
controversy opposing objectivism and subjectivism may be found in the FAQ/FAM 16.29 "Subjectivism vs objectivism contro-
versy", page 203.

Description = Specification + Identification
Page 77
5. As will be seen in the sequel, this formalism is generic and may be used to express
a huge variety of models. Although simple, it offers a very strong power of expres-
sion.
4.3.3
Learning is a means to transform incompleteness into uncertainty
Descriptions are probabilistic models of a phenomenon. Descriptions are not complete.
They do not escape the incompleteness curse of any nonprobabilistic model. For instance,
the description of the elementary water treatment unit does not take into account the vari-
able 
 which stays hidden.
However, because of learning, the influence of 
 is nevertheless taken into account,
as its effect on the phenomenon has been captured in the values of the histograms.
Learning is a means to transform incompleteness (the effect of hidden variables) into
uncertainty. The magic of this transformation is that after incompleteness has been trans-
formed into uncertainty (probability distributions), then it is possible to reason with these
distributions.
Furthermore, learning is also a means to estimate the importance of the hidden vari-
able and consequently the quality of the model (description). If learning leads to flat dis-
tributions, it means that the neglected variables play a very important role and that the
model should be improved. On the oteh hand, if learning leads to very informative (low
entropy) distributions, then it confirms the quality of the model and the secondary influ-
ence of the hidden variables.
H
H

Bayesian Programming
Page 78

Page 79
 5
The Importance of 
Conditional Independence
What we call chance is, and may only be, the ignored cause of known
effect1.
Voltaire, Dictionaire Philosophique
The goal of this chapter is both to explain the notion of conditional independence and to
demonstrate its importance in actually solving and computing complex problems.
5.1
Water treatment center Bayesian model (continuation)
In this chapter, we complete the construction of the Bayesian model for the water treat-
ment center.
The complete process consists of four single units. Similarly, the complete Bayesian
1.Ce que nous appelons le hasard n'est, et ne peut être, que la cause ignorée d'un effet connu.

Bayesian Programming
Page 80
model is made of the four single models specified and identified in the previous chapter.
Putting these four models together presupposes some strong structural knowledge that
can be translated into conditional independence hypotheses. 
Figure 5.1 presents the functioning diagram of the water treatment center.
Units M0 and M1 take the same inputs 
 and 
. They respectively produce 
 and 
 as outputs, which in turn are used as inputs by M2. M3 takes 
 and 
 as inputs, and
finally produces 
 as output.
The four water treatment units have four internal states (respectively 
, 
, 
, and
), four sensors (respectively 
, 
, 
, and 
), four controllers (respectively 
,
, 
, and 
), and may all be perturbed by some external factor (respectively 
,
, 
, and 
).
The production of each of these units is governed by equations (3.3) and (3.4).
The sensors take their value according to equation (3.5).
5.2
Description of the water treatment center
As in the previous chapter, to build the Bayesian model of the whole plant, we assume
that 
, 
, 
, and 
 are hidden variables not known by the designer.
Figure 5.1: A complete water treatment center.
I0
I1
O0
O1
I3
O2
O3
F0 F1 F2
F3
S0
S1
S2
S3
C0
C1
C2
C3
H0
H1
H2
H3
H0
H1
H2
H3

The Importance of Conditional Independence
Page 81
5.2.1
Specification
Variables
There are now 19 variables in our global Bayesian model:
(5.1)
each of these variables has a cardinality equals to 11.
Decomposition
Using the conjunction postulate (2.5) iteratively as in the previous chapter it is possible to
write the joint probability on the 19 variables as:
(5.2)
This is an exact mathematical formula where we tried to regroup variables as they
appeared in the four different units. 
Although it is exact, this formula should obviously be further simplified! This can be
done by using some additional knowledge:
1. The functioning of unit M1 depends on its entries 
 and 
, but is obviously inde-
pendent of entry 
 and of the operation of unit M0 (specified by variables 
, 
,
, and 
). This leads to:
(5.3)
2. Operation of M2 obviously depends on the operation of M0 and M1, which pro-
duce its inputs. For instance, changing 
 will change 
, which in turn will
I0 I1 I3 F0 F1 F2 F3 S0 S1 S2 S3 C0 C1 C2 C3 O0 O1 O2 O3
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
,
0 ... 10
,
,
{
}
!
I0
I1
I3
F0
...
O2
O3
"
"
"
"
"
"
(
)
P
I0
I1
I3
"
"
(
)
P
=
.
F0
S0
C0
O0
"
"
"
I0
I1
I3
"
"
(
)
P
×
.
F1
S1
C1
O1
"
"
"
|I0
I1
I3
F0
S0
C0
O0
"
"
"
"
"
"
(
)
P
×
.
F2
S2
C2
O2
"
"
"
|I0
I1
I3
F0
S0
C0
O0
F1
S1
C1
O1
"
"
"
"
"
"
"
"
"
"
(
)
P
×
.
F3
S3
C3
O3
"
"
"
|I0
I1
I3
F0
S0
C0
O0
F1
S1
C1
O1
"
"
"
"
"
"
"
F2
S2
C2
O2
"
"
"
"
"
"
"
(
)
P
×
I0
I1
I3
F0 S0
C0
O0
F1
S1
C1
O1
"
"
"
|I0
I1
I3
F0
S0
C0
O0
"
"
"
"
"
"
(
)
P
F1
S1
C1
O1
"
"
"
|I0
I1
"
(
)
P
=
C0
O0

Bayesian Programming
Page 82
change 
, 
, and eventually 
. Apparently, M2 depends on all the previous
variables except 
 and the only obvious simplification concerns 
:
 
 
(5.4)
However, if we know the value of 
, then we do not care anymore about the val-
ues of 
, 
, 
, 
, and 
, which all influence the operation of M3 only by
means of the output 
. Similarly, if we know the value of 
, then we do not
care anymore about the values of 
, 
, and 
. This is called conditional inde-
pendence between variables and is a main tool to build interesting and efficient
description. 
One should be very careful that conditional independence has nothing in common
with independence. The variable 
 depends on 
 (
), but is
conditionally independent of 
 if 
 is known (
).
See § 5.3.1 in the sequel for further discussion of this point. This finally leads to:
(5.5)
3. For the same kind of reasons, we find:
(5.6)
At this stage, we have the following decomposition:
S2
O2
C2
I3
I3
F2
S2
C2
O2
"
"
"
|I0
I1
I3
F0
S0
C0
O0
F1
S1
C1
O1
"
"
"
"
"
"
"
"
"
"
(
)
P
F2
S2
C2
O2
"
"
"
|I0
I1
F0
S0
C0
O0
F1
S1
C1
O1
"
"
"
"
"
"
"
"
"
(
)
P
=
O0
I0
I1
F0
S0
C0
O0
O1
F1
S1
C1
S2
C0
S2|C0
(
)
P
S2
(
)
P
/
C0
O0
S2|C0
O0
"
(
)
P
S2|O0
(
)
P
=
F2
S2
C2
O2
"
"
"
|I0
I1
F0
S0
C0
O0
F1
S1
C1
O1
"
"
"
"
"
"
"
"
"
(
)
P
F2
S2
C2
O2
"
"
"
|O0
O1
"
(
)
P
=
F2
S3
C3
O3
"
"
"
|I0
I1
I3
F2
F0
S0
C0
O0
F1
S1
C1
O1
F2
S2
C2
O2
"
"
"
"
"
"
"
"
"
"
"
"
"
"
"
(
)
P
F3
S3
C3
O3
"
"
"
|I3
O2
"
(
)
P
=

The Importance of Conditional Independence
Page 83
(5.7)
Using the same kind of assumptions as in the previous chapter, we may further sim-
plify this expression, stating that:
4. Concerning M0:
(5.8)
5. Concerning M1:
(5.9)
6. Concerning M2:
(5.10)
7. Concerning M3:
(5.11)
I0
I1
I3
F0
...
O2
O3
"
"
"
"
"
"
(
)
P
I0
I1
I3
"
"
(
)
P
=
.
F0
S0
C0
O0
"
"
"
|I0
I1
"
(
)
P
×
.
F1
S1
C1
O1
"
"
"
|I0
I1
"
(
)
P
×
.
F2
S2
C2
O2
"
"
"
|O0
O1
"
(
)
P
×
.
F3
S3
C3
O3
"
"
"
|I3
O2
"
(
)
P
×
F0
S0
C0
O0
"
"
"
|I0
I1
"
(
)
P
F0
(
)
P
S0|I0
F0
"
(
)
P
×
C0
(
)
P
×
O0|I0
I1
S0
C0
"
"
"
(
)
P
×
=
F1
S1
C1
O1
"
"
"
|I0
I1
"
(
)
P
F1
(
)
P
S1|I0
F1
"
(
)
P
×
C1
(
)
P
×
O1|I0
I1
S1
C1
"
"
"
(
)
P
×
=
F2
S2
C2
O2
"
"
"
|O0
O1
"
(
)
P
F2
(
)
P
S2|O0
F2
"
(
)
P
×
C2
(
)
P
×
O2|O0
O1
S2
C2
"
"
"
(
)
P
×
=
F3
S3
C3
O3
"
"
"
|I3
O2
"
(
)
P
F3
(
)
P
S3|I3
F3
"
(
)
P
×
C3
(
)
P
×
O3|I3
O2
S3
C3
"
"
"
(
)
P
×
=

Bayesian Programming
Page 84
After some reordering, we obtain the following final decomposition:
(5.12)
Forms
The distributions 
, 
, 
, 
, 
,
,
, 
, 
,
, and 
 are all assumed to be uniform distributions.
, 
, 
, and 
s are all Dirac
distributions.
Finally, the four distributions relating the output to the inputs, the sensor, and the con-
trol are all specified as histograms, as in the previous chapter.
5.2.2
Identification
We have now four series of 
 histograms to identify (
 free parameters).
In a real control and diagnosis problem, the four production units, even though they
are identical, would most probably function slightly differently (because of incomplete-
ness and some other hidden variables besides 
). In that case, the best thing to do would
be to perform four different identification campaigns to take these small differences into
account by learning.
In this didactic example, as the four units are simulated and formal, they really are
perfectly identical (there are no possible hidden variables in our formal model as speci-
fied by equations (3.3), (3.4) and (3.5)). Consequently, we use the exact same histogram
for the four units as was identified in the previous chapter.
I0
I1
I3
F0
...
O2
O3
"
"
"
"
"
"
(
)
P
I0
(
)
P
I1
(
)
P
×
I3
(
)
P
×
=
.
F0
(
)
P
F1
(
)
P
×
F2
(
)
P
×
F3
(
)
P
×
×
.
C0
(
)
P
C1
(
)
P
×
C2
(
)
P
×
C3
(
)
P
×
×
.
S0|I0
F0
"
(
)
P
S1|I0
F1
"
(
)
P
×
S2|O0
F2
"
(
)
P
S3|I3
F3
"
(
)
P
×
×
×
.
O0|I0
I1
S0
C0
"
"
"
(
)
P
O1|I0
I1
S1
C1
"
"
"
(
)
P
O2|O0
O1
S2
C2
"
"
"
(
)
P
O3|I3
O2
S3
C3
"
"
"
(
)
P
×
×
×
×
I0
(
)
P
I1
(
)
P
I3
(
)
P
F0
(
)
P
F1
(
)
P
F2
(
)
P
F3
(
)
P
C0
(
)
P
C1
(
)
P
C2
(
)
P
C3
(
)
P
S0|I0
F0
"
(
)
P
S1|I0
F1
"
(
)
P
S2|O0
F2
"
(
)
P
S3|I3
F3
"
(
)
P
11
4
11
5
H

The Importance of Conditional Independence
Page 85
5.3
Lessons, comments and notes
5.3.1
Independence versus conditional independence
To build this Bayesian model of our water treatment center we intensively used indepen-
dence between variables and overall conditional independence between variables. Let us
return briefly to these two concepts, which should not be confused.
Two variables 
 and 
 are independent from one another if and only if
 which is logically equivalent because of the conjunction postu-
late to 
 and of course also to 
.
Two variables 
 and 
 are independent conditionally to a third one 
 if and only if
, which is also logically equivalent because of the con-
junction postulate to 
 and to 
.
However, two variables may be independent but not conditionally independent to a
third one. Two variables may also be conditionally independent but not independent.
For the first case, in our example, for production unit M0, 
 the first entry, and 
 the
internal state, are independent but are not conditionally independent knowing 
 the
reading of the sensor. For 
 and 
 Figure 5.3 shows the corresponding proba-
Figure 5.2: The graphical model of the joint distribution on Expression (5.12), the water treatment 
center shown in Figure 5.1.
X
Y
P X
Y
"
(
)
P X
( )
P Y
( )
×
=
P X|Y
(
)
P X
( )
=
P Y|X
(
)
P Y
( )
=
X
Y
Z
P X
Y|Z
"
(
)
P X|Z
(
)
P Y|Z
(
)
×
=
P X|Y
Z
"
(
)
P X|Z
(
)
=
P Y|X
Z
"
(
)
P Y|Z
(
)
=
I0
F0
S0
I0
5
=
S0
6
=

Bayesian Programming
Page 86
bilities:
This is a very common situation where the two causes of a phenomenon are indepen-
dent but are conditionally dependent on one another, knowing their common consequence
(see Figure 5.3). Otherwise, no sensor measuring several factors would be of any use.
For the second case, as already said, 
 depends on 
 (
) but is condi-
tionally independent of 
 if 
 is known (
). For 
and 
 Figure 5.5
Figure 5.3: The distributions 
, 
, 
 and 
. Note that 
 but 
.
Figure 5.4: Two independent causes for the same phenomenon.
P(F0 | IO=5)
P(F0)
P(F0 | I0=5 S0=6)
P(FO | SO=6)
0
2
4
6
8
10
Unit 0 efficiency (F0)
0
0.1
0.2
0.3
0.4
0.5
Frequency
P F0|I0
(
) P F0
(
) P F0|I0
S0
"
(
)
P F0|S0
(
)
P F0|I0
(
)
P F0
(
)
=
P F0|I0
S0
"
(
)
P F0|S0
(
)
/
I0
F0
S0
S2
C0
S2|C0
(
)
P
S2
(
)
P
/
C0
O0
S2|C0
O0
"
(
)
P
S2|O0
(
)
P
=
C0
10
=
O0
5
=

The Importance of Conditional Independence
Page 87
This is also a very common situation where there is a causal chain between three vari-
ables (see Figure 5.6).
5.3.2
The importance of conditional independence
This kind of conditional independence is of great importance for Bayesian Programming
for two main reasons:
1. It expresses crucial designer’s knowledge.
2. It makes the computation tractable by breaking the curse of dimensionality.
For any model of any phenomenon, knowing what matters with, what does not influence
what and, most importantly, what bias could be neglected compared to another one is fun-
damental knowledge. 
A model where everything depends on everything else is a very poor model, indeed.
In probabilistic terms, such a model would be a joint distribution on all the relevant vari-
ables coded as a huge table containing the probabilities of all the possible cases. 
In our example, simple as it is, it would be a table containing the 
 probability val-
Figure 5.5: Two views of the distributions
, 
, 
, and 
. Note that 
 but 
.
Figure 5.6: Causal chain.
- P(S2 | CO=10)
- P(S2)
- P(S2 | C0=10 O0=5)
- P(S2 | O0=5)
0
2
4
6
8
10
Sensor 2 (S2)
0
0.04
0.08
0.12
0.16
0.2
Probability
P(S2 | CO=10)   -
P(S2)   -
P(S2 | C0=10 O0=5)   -
P(S2 | O0=5)   -
0
2
4
6
8
10
Sensor 2 (S2)
0
0.04
0.08
0.12
0.16
0.2
Probability
S2|C0
(
)
P
S2
(
)
P
S2|C0
O0
"
(
)
P
S2|O0
(
)
P
S2|C0
(
)
P
S2
(
)
P
/
S2|C0
O0
"
(
)
P
S2|O0
(
)
P
=
S2
C0
O0
2
63

Bayesian Programming
Page 88
ues necessary for the joint distribution 
 on our 19 vari-
ables that take 11 values each:
(5.13)
Such a table would encode all the necessary information, but in a very poor manner.
Hopefully, a model does not usually code the joint distribution in this way but rather
uses a decomposition and the associated conditional independencies to express the
knowledge in a structured and formal way.
The probabilistic model of the production models as expressed by equation:
(5.14)
only requires 
 probability values to encode the joint distribution:
(5.15)
Thanks to conditional independence the curse of dimensionality has been broken! 
What has been shown to be true here for the required memory space is also true for
the complexity of inferences. Conditional independence is the principal tool to keep the
calculation tractable. Tractability of Bayesian inference computation is of course a major
concern as it has been proved NP-hard (Cooper, 1990). This subject will be developed in
chapter 16 which reviews the main algorithms for Bayesian inference and is summed up
in the FAQ/FAM 16.5 "Computation complexity of Bayesian Inference", page 202.
I0
I1
I3
F0
...
O2
O3
"
"
"
"
"
"
(
)
P
11
19
2
63
0
I0
I1
I3
F0
...
O2
O3
"
"
"
"
"
"
(
)
P
I0
(
)
P
I1
(
)
P
×
I3
(
)
P
×
=
.
F0
(
)
P
F1
(
)
P
×
F2
(
)
P
×
F3
(
)
P
×
×
.
C0
(
)
P
C1
(
)
P
×
C2
(
)
P
×
C3
(
)
P
×
×
.
S0|I0
F0
"
(
)
P
S1|I0
F1
"
(
)
P
×
S2
O0
F2
"
"
(
)
P
S3|I3
F3
"
(
)
P
×
×
×
.
O0|I0
I1
S0
C0
"
"
"
(
)
P
01|I0
I1
S1
C1
"
"
"
(
)
P
O2|O0
O1
S2
C2
"
"
"
(
)
P
O3|I3
O2
S3
C3
"
"
"
(
)
P
×
×
×
×
2
18
11
11
×
(
)
11
3
4
×
(
)
11
5
4
×
(
)
+
+
2
18
0

Page 89
 6
Bayesian Program = 
Description + Question
Far better an approximate answer to the right question which is often
vague, than an exact answer to the wrong question which can always be
made precise
John W. Tukey
In the two previous chapters, we built a description (Bayesian model) of our water treat-
ment center.
In this chapter, we use this description to solve different problems: prediction of the
output, choice of the best control strategy, and diagnosis of failures. This shows that mul-
tiple questions may be asked to the same description to solve very different problems.
This clear separation between the model and its use is a very important feature of Baye-
sian Programming.

Bayesian Programming
Page 90
6.1
Water treatment center Bayesian model (end)
Let us first recall the present model of the process:
(6.1)
Quite a simple model indeed, thanks to our knowledge of this process, even if it took
some time to make all its subtleties explicit!
However the question is still unspecified. Specifying and answering different possible
questions is the purpose of the sequel of this chapter.
6.2
Forward simulation of a single unit
We first want to predict the output of a single unit (for instance M0) knowing its inputs,
sensor reading, and control, or some of these values.
6.2.1
Question
For instance, we may look for the value of 
 knowing the values of 
, 
, 
, and 
.
The corresponding question will be:
,
(6.2)
which can be computed directly as it appears in the decomposition.
Pr
Ds
Sp
Va
I0 I1 ... O3
,
,
,
#
Dc
I0
I1
I3
F0
...
O2
O3
"
"
"
"
"
"
(
)
P
I0
(
)
P
I1
(
)
P
×
I3
(
)
P
×
=
.
F0
(
)
P
F1
(
)
P
×
F2
(
)
P
×
F3
(
)
P
×
×
.
C0
(
)
P
C1
(
)
P
×
C2
(
)
P
×
C3
(
)
P
×
×
.
S0|I0
F0
"
(
)
P
...
×
S3|I3
F3
"
(
)
P
×
×
.
O0|I0
I1
S0
C0
"
"
"
(
)
P
...
×
O3|I3
02
S3
C3
"
"
"
(
)
P
×
×
#
Fo
I0
(
) ...
C3
(
)
P
UNIFORM
,
,
,
P
S0|I0
FO
"
(
) ...
S3|I3
F3
"
(
)
P
DIRAC
,
,
,
P
O0|I0
I1
S0
C0
"
"
"
(
) ...
O3|I3
O2
S3
C3
"
"
"
(
)
P
HISTOGRAM
,
,
,
P
)
*
*
+
*
*
,
#
)
*
*
*
*
*
*
*
*
*
*
*
*
*
+
*
*
*
*
*
*
*
*
*
*
*
*
*
,
Id
)
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
+
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
,
Qu
?
#
)
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
+
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
,
O0
I0
I1 S0
C0
O0|i0
i1
s0
c0
"
"
"
(
)
P

Bayesian Program = Description + Question
Page 91
This last statement can be verified by performing the corresponding computation on
the joint probability distribution to check that the right simplifications occur. This com-
putation can be broken down into different steps:
1. Application of the marginalization rule (2.10) by summing on all the missing (free)
variables:
(6.3)
2. Application of the conjunction postulate (2.7):
(6.4)
3. Factorization of 
, which is a normalization constant, as 
, 
,
, and 
 are known values:
(6.5)
4. Replacement of the joint distribution by its decomposition:
O0|i0
i1
s0
c0
"
"
"
(
)
P
O0
I3
F0
F1
F2
F3
C1
C2
C3
S1
S2
S3
O1
O2
O3
"
"
"
"
"
"
"
"
"
"
"
"
"
|i0
i1
s0
c0
"
"
"
"
(
)
P
I3
F0
F1
F2
F3
"
"
"
C1
C2
C3
"
"
S1
S2
S3
"
"
O1
O2
O3
"
"
!
=
O0|i0
i1
s0
c0
"
"
"
(
)
P
O0
I3
F0
F1
F2
F3
C1
C2
C3
S1
S2
S3
O1
O2
O3
i0
i1
s0
c0
"
"
"
"
"
"
"
"
"
"
"
"
"
"
"
"
"
"
(
)
P
i0
i1
s0
c0
"
"
"
(
)
P
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
I3
F0
F1
F2
F3
"
"
"
C1
C2
C3
"
"
S1
S2
S3
"
"
O1
O2
O3
"
"
!
=
i0
i1
s0
c0
"
"
"
(
)
P
i0
i1
s0
c0
O0|i0
i1
s0
c0
"
"
"
(
)
P
1
*---
O0
I3
...
c0
"
"
"
(
)
P
I3
F0
F1
F2
F3
"
"
"
C1
C2
C3
"
"
S1
S2
S3
"
"
O1
O2
O3
"
"
!
×
=

Bayesian Programming
Page 92
(6.6)
5.  Reorganization and factorization of the sums:
(6.7)
6. Application of the normalization postulate (2.2), which completely simplifies the
three inner sums:
(6.8)
7. Replacement of 
 by its decomposition (equation 5.9):
(6.9)
8. Finally, application of the normalization postulate and simplification of 
:
O0|i0
i1
s0
c0
"
"
"
(
)
P
1
*---
i0
i1
I3
"
"
(
)
P
.
F0
s0
c0
O0
"
"
"
|i0
i1
"
(
)
P
×
.
F1
S1
C1
O1
"
"
"
|i0
i1
"
(
)
P
×
.
F2
S2
C2
O2
"
"
"
|O0
O1
"
(
)
P
×
.
F3
S3
C3
O3
"
"
"
|I3
O2
"
(
)
P
×
I3
F0
F1
F2
F3
"
"
"
C1
C2
C3
"
"
S1
S2
S3
"
"
O1
O2
O3
"
"
!
×
=
O0|i0
i1
s0
c0
"
"
"
(
)
P
1
*---
F0
s0
c0
O0
"
"
"
|i0
i1
"
(
)
P
.
F1
S1
C1
O1
"
"
"
|i0
i1
"
(
)
P
.
F2
S2
C2
O2
"
"
"
|O0
O1
"
(
)
P
.
F3
S3
C3
O3
"
"
"
|I3
O2
"
(
)
P
.
i0
i1
I3
"
"
(
)
P
×
F3
S3
C3
O3
I3
"
"
"
"
!
×
F2
S2
C2
O2
"
"
"
!
×
F1
S1
C1
O1
"
"
"
!
×
F0
!
×
=
O0|i0
i1
s0
c0
"
"
"
(
)
P
1
*---
F0
s0
c0
O0
"
"
"
|i0
i1
"
(
)
P
i0
i1
"
(
)
P
×
F0
!
×
=
F0
s0
c0
O0
"
"
"
|i0
i1
"
(
)
P
O0|i0
i1
s0
c0
"
"
"
(
)
P
1
*---
F0
(
)
P
s0|i0
F0
"
(
)
P
×
c0
(
)
P
×
O0|i0
i1
s0
c0
"
"
"
(
)
P
i0
i1
"
(
)
P
×
×
F0
!
×
=
*

Bayesian Program = Description + Question
Page 93
(6.10)
The corresponding Bayesian program is:
(6.11)
6.2.2
Results
The corresponding results have already been presented, in Chapter 4 for
. See Figure 4.7.
6.3
Forward simulation of the water treatment center
6.3.1
Question
We may now want to predict the output 
 of the whole water treatment center, knowing
the three inputs 
, 
, and 
, the four sensor readings 
, 
, 
, and 
, and the four
control values 
, 
, 
, and 
. The corresponding question is:
(6.12)
This may be computed with the following computation steps:
1. Utilization of the marginalization rule (2.9):
O0|i0
i1
s0
c0
"
"
"
(
)
P
O0|i0
i1
s0
c0
"
"
"
(
)
P
=
Pr
Ds
Sp
Va
I0 I1 ... O3
,
,
,
#
Dc
I0
I1
I3
F0
...
O2
O3
"
"
"
"
"
"
(
)
P
I0
(
)
P
I1
(
)
P
×
I3
(
)
P
×
=
.
F0
(
)
P
F1
(
)
P
×
F2
(
)
P
×
F3
(
)
P
×
×
.
C0
(
)
P
C1
(
)
P
×
C2
(
)
P
×
C3
(
)
P
×
×
.
S0|I0
F0
"
(
)
P
...
×
S3|I3
F3
"
(
)
P
×
×
.
O0|I0
I1
S0
C0
"
"
"
(
)
P
...
×
O3|I3
O2
S3
C3
"
"
"
(
)
P
×
×
#
Fo
I0
(
) ...
C3
(
)
P
UNIFORM
,
,
,
P
S0|I0
F0
"
(
) ...
S3|I3
F3
"
(
)
P
DIRAC
,
,
,
P
O0|I0
I1
S0
C0
"
"
"
(
) ...
O3|I3
O2
S3
C3
"
"
"
(
)
P
HISTOGRAM
,
,
,
P
)
*
*
+
*
*
,
#
)
*
*
*
*
*
*
*
*
*
*
*
*
*
+
*
*
*
*
*
*
*
*
*
*
*
*
*
,
Id
)
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
+
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
,
Qu
O0|i0
i1
s0
c0
"
"
"
(
)
P
O0|i0
i1
s0
c0
"
"
"
(
)
P
=
#
)
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
+
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
,
I0
2
=
[
]
I1
8
=
[
]
C
2
=
[
]
,
,
O3
I0
I1
I3
S0
S1
S2
S3
C0 C1 C2
C3
O3|i0
i1
i3
s0
s1
s2
s3
c0
c1
c2
c3
"
"
"
"
"
"
"
"
"
"
(
)
P

Bayesian Programming
Page 94
(6.13)
where we sum over all the free (
) variables
that are neither searched (
) nor known
 (
).
Equation 6.13 may then be rewritten as:
(6.14)
2. Utilization of the conjunction rule (2.5):
(6.15)
or more succinctly:
(6.16)
As 
the 
entries, 
the 
sensors, 
and 
the 
controllers 
have 
known 
values,
 is a constant, which by convention
we name 
. We obtain:
,
(6.17)
which is equivalent to:
O3|i0
i1
i3
s0
s1
s2
s3
c0
c1
c2
c3
"
"
"
"
"
"
"
"
"
"
(
)
P
O3
F0
F1
F2
F3
O0
O1
O2
"
"
"
"
"
"
"
|i0
i1
i2
s0
s1
s2
s3
c0
c1
c2
c3
"
"
"
"
"
"
"
"
"
"
(
)
P
F0
F1
F2
F3
"
"
"
O0
O1
O2
"
"
!
=
Free
F0
F1
F2
F3
O0
O1
O2
"
"
"
"
"
"
,
Searched
O3
,
Known
I0
,
I1
I3
S0
S1
S2
S3
C0
C1
C2
C3
"
"
"
"
"
"
"
"
"
"
Searched|Known
(
)
P
Searched
Free
"
|Known
(
)
P
Free
!
=
O3|i0
i1
i3
s0
s1
s2
s3
c0
c1
c2
c3
"
"
"
"
"
"
"
"
"
"
(
)
P
O3
F0
F1
F2
F3
O0
O1
O2
i0
i1
i3
s0
s1
s2
s3
c0
c1
c2
c3
"
"
"
"
"
"
"
"
"
"
"
"
"
"
"
"
"
"
(
)
P
i0
i1
i3
s0
s1
s2
s3
c0
c1
c2
c3
"
"
"
"
"
"
"
"
"
"
(
)
P
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
F0
...
O2
"
"
!
=
Searched|Known
(
)
P
Searched
Free
Known
"
"
(
)
P
Known
(
)
P
------------------------------------------------------------------------
Free
!
=
i0
i1
i3
s0
s1
s2
s3
c0
c1
c2
c3
"
"
"
"
"
"
"
"
"
"
(
)
P
*
O3|i0
i1
i3
s0
s1
s2
s3
c0
c1
c2
c3
"
"
"
"
"
"
"
"
"
"
(
)
P
1
*---
O3
F0
...
O2
i0
...
c3
"
"
"
"
"
"
(
)
P
F0
...
O2
"
"
!
×
=

Bayesian Program = Description + Question
Page 95
(6.18)
From the normalization rule (2.2) we have:
(6.19)
We indeed see that, indeed, 
 is a normalization constant equal to:
(6.20)
It is clear that whatever choice is made for 
, 
, and 
 we have:
(6.21)
3. Returning to Equation (6.17) we can replace the joint probability distribution
 by its decomposition, give us:
(6.22)
4. Uniform distributions can be further simplified by incorporating them in the nor-
malization constant to yield:
Searched|Known
(
)
P
1
*---
Searched
Free
Known
"
"
(
)
P
Free
!
×
=
O3|i0
i1
i3
s0
s1
s2
s3
c0
c1
c2
c3
"
"
"
"
"
"
"
"
"
"
(
)
P
O3
!
1
=
*
*
O3
F0
...
O2
i0
...
c3
"
"
"
"
"
"
P
F0
...
O2
"
"
!
O3
!
=
Searched
Known
Free
*
Searched
Free
Known
"
"
(
)
P
Free
!
Searched
!
=
O3
F0
...
O2
i0
...
c3
"
"
"
"
"
"
(
)
P
O3|i0
i1
i3
s0
s1
s2
s3
c0
c1
c2
c3
"
"
"
"
"
"
"
"
"
"
(
)
P
1
*---
i0
(
)
P
i1
(
)
P
×
i2
(
)
P
×
.
F0
(
)
P
F1
(
)
P
×
F2
(
)
P
×
F3
(
)
P
×
×
.
c0
(
)
P
c1
(
)
P
×
c2
(
)
P
×
c3
(
)
P
×
×
.
s0|i0
F0
"
(
)
P
...
×
s3|i3
F3
"
(
)
P
×
×
.
O0|i0
i1
s0
c0
"
"
"
(
)
P
...
×
O3|i3
O2
s3
c3
"
"
"
(
)
P
×
×
F0
...
O2
"
"
!
×
=

Bayesian Programming
Page 96
(6.23)
5. Finally, after some clever reordering of the sums to minimize the amount of com-
putation1, we obtain:
(6.24)
6.3.2
Results
Some of the results obtained for the forward simulation of the water treatment center are
presented in Figure 6.1.
For the same three inputs, with the same four sensor readings but with three different
kinds of control we obtain completely different forecasts for the output. 
This three curves show clearly that with these specific inputs and readings, an average
1.
This use of reordering to minimize computation will be developed later, especially in Chapter 17
Figure 6.1: 
 with 
,
 and three different 
controls:
 (left), 
 (middle), and 
 
(right).
O3|i0
i1
i3
s0
s1
s2
s3
c0
c1
c2
c3
"
"
"
"
"
"
"
"
"
"
(
)
P
1
*---
s0|i0
F0
"
(
)
P
...
×
s3|i2
F3
"
(
)
P
×
.
O0|i0
i1
s0
c0
"
"
"
(
)
P
...
×
O3|i3
O2
s3
c3
"
"
"
(
)
P
×
×
F0
F1
F2
F3
"
"
"
O0
O1
O2
"
"
!
×
=
O3|i0
i1
i3
s0
s1
s2
s3
c0
c1
c2
c3
"
"
"
"
"
"
"
"
"
"
(
)
P
1
*---
O0|i0
i1
s0
c0
"
"
"
(
)
P
.
s2|O0
F2
"
(
)
P
F2!
×
.
O1|i0
i1
s1
c1
"
"
"
(
)
P
.
O2|O0
O1
s2
c2
"
"
"
(
)
P
O3|i3
O2
s3
c3
"
"
"
(
)
P
×
[
]
O2!
×
O1
!
×
O0
!
×
=
0
0.1
0.2
0.3
0.4
0.5
0.6
Probability
2
3
4
5
6
7
8
9
10
Output O3
0
0.1
0.2
0.3
0.4
0.5
0.6
Probability
2
3
4
5
6
7
8
9
10
Output O3
0
0.1
0.2
0.3
0.4
0.5
0.6
Probability
2
3
4
5
6
7
8
9
10
Output O3
O3|i0
i1
i3
s0
s1
s2
s3
c0
c1
c2
c3
"
"
"
"
"
"
"
"
"
"
(
)
P
i0
2
=
(
)
i1
8
=
(
)
i2
10
=
(
)
,
,
s0
5
=
(
)
s1
5
=
(
)
s2
7
=
(
)
s3
9
=
(
)
,
,
,
c0
c1
c2
c3
0
=
=
=
=
(
)
c0
c1
c2
c3
5
=
=
=
=
(
)
c0
c1
c2
c3
10
=
=
=
=
(
)

Bayesian Program = Description + Question
Page 97
control 
, is more efficient than no control 
,
or an overstated control 
.
6.4
Control of the water treatment center 
Forecasting the output 
, as in the previous section, is certainly a valuable tool to
choose an appropriate control policy for the water treatment center. 
However, there are 
 such possible different policies. Testing all of them,
one after another, would not be very practical.
Bayesian Programming endeavors to offer a direct solution to the control problem
when asked the question 
.
6.4.1
Question (1)
After symbolic simplification and computation, the answer obtained to this question is:
(6.25)
which is basically the same expression as for the forecast of the output (see Equation
(6.24) in the previous section), except that the controls are searched this time instead of
being known (note the changes between the two equations between uppercase and lower-
case notation for the variables).
6.4.2
Result (1)
If we fix 
, the most probable control is 
.
However, the 100 best choices are very close to this best one, both in terms of proba-
bility and in terms of choice of the selected values. This means that the water treatment
process is robust and that the sensivity of the solution is low.
c0
c1
c2
c3
5
=
=
=
=
(
)
c0
c1
c2
c3
0
=
=
=
=
(
)
c0
c1
c2
c3
10
=
=
=
=
(
)
O3
11
4
14,641
=
C0
C1
C2
C3
"
"
"
|i0
i1
i2
s0
s1
s2
s3
O3
"
"
"
"
"
"
"
(
)
P
C0
C1
C2
C3
"
"
"
|i0
i1
i3
s0
s1
s2
s3
O3
"
"
"
"
"
"
"
(
)
P
1
*---
O0|i0
i1
s0
C0
"
"
"
(
)
P
.
s2|O0
F2
"
(
)
P
F2!
×
.
O1|i0
i1
s1
C1
"
"
"
(
)
P
.
O2|O0
O1
s2
C2
"
"
"
(
)
P
O3|i3
O2
s3
C3
"
"
"
(
)
P
×
[
]
O2
!
×
O1
!
×
O0
!
×
=
O3
9
=
C0
6
=
[
]
C1
6
=
[
]
C2
4
=
[
]
C3
9
=
[
]
,
,
,

Bayesian Programming
Page 98
The 
 forecast for this control choice is presented in Figure 6.2. It shows that even
if this is the best control choice, the probability of obtainig 
 is only 3%. This sug-
gest that searching the controls to find 
 may still not be the best question. Indeed
the present question could lead to a control choice that ensures the highest probability for
, but at the price of very high probabilities for much worse outputs.
6.4.3
Question (2)
We might rather, for instance, search for the best control strategy to ensure that 
.
Let us, for example, analyze the cases where 
. That is, we need to
compute
Figure 6.2: 
 for 
, 
, and 
.
O3
0
0.1
0.2
0.3
0.4
0.5
0.6
Probability
4
5
6
7
8
9
10
Output O3
O3|i0
i1
i3
s0
s1
s2
s3
c0
c1
c2
c3
"
"
"
"
"
"
"
"
"
"
(
)
P
i0
2
=
(
)
i1
8
=
(
)
i3
10
=
(
)
,
,
s0
5
=
(
)
s1
5
=
(
)
s2
7
=
(
)
s3
9
=
(
)
,
,
,
C0
6
=
[
]
C1
6
=
[
]
C2
4
=
[
]
C3
9
=
[
]
,
,
,
O3
9
=
O3
9
=
O3
9
=
O3
o3
$
o3
4 5 6 7 8 9
, , , , ,
{
}
!

Bayesian Program = Description + Question
Page 99
(6.26)
6.4.4
Result (2)
The resulting control values that maximize the probability of holding the constraint 
are shown in Table 6.1. Note that, as you may have expected, the best control values for
maximizing the probability of obtainnig 
 are exactly the same as those in the pre-
vious question where we fixed 
. This because the probability of 
 is zero. 
The distribution of 
 for the
different control values in Table 6.1 are shown below (Table 6.2) and they are depicted
Constraint
Control values maximizing the probability of hol-
ding the constraint.
Table 6.1: The control values  in the right column maximize the probability of holding the 
constraint  in the left column for 
 when 
  and 
.
C0
C1
C2
C3
"
"
"
|i0
i1
i3
s0
s1
s2
s3
O3
o3
$
"
"
"
"
"
"
"
(
)
P
1
*---
O0|i0
i1
s0
C0
"
"
"
(
)
P
.
s2|O0
F2
"
(
)
P
F2!
×
.
O1|i0
i1
s1
C1
"
"
"
(
)
P
.
O2|O0
O1
s2
C2
"
"
"
(
)
P
O3|i3
O2
s3
C3
"
"
"
(
)
P
O3
o3
$!
×
O2
!
×
O1
!
×
O0
!
×
=
O3
o3
$
O3
9
$
O3
9
=
O3
10
=
O3
4
$
14
C0
5
=
[
]
C1
10
=
[
]
C2
10
=
[
]
C3
9
=
[
]
,
,
,
=
O3
5
$
15
C0
5
=
[
]
C1
10
=
[
]
C2
10
=
[
]
C3
7
=
[
]
,
,
,
=
O3
6
$
16
C0
5
=
[
]
C1
7
=
[
]
C2
6
=
[
]
C3
7
=
[
]
,
,
,
=
O3
7
$
17
C0
5
=
[
]
C1
6
=
[
]
C2
5
=
[
]
C3
6
=
[
]
,
,
,
=
O3
8
$
18
C0
5
=
[
]
C1
6
=
[
]
C2
4
=
[
]
C3
6
=
[
]
,
,
,
=
O3
9
$
19
C0
6
=
[
]
C1
6
=
[
]
C2
4
=
[
]
C3
9
=
[
]
,
,
,
=
O3|i0
i1
i3
s0
s1
s2
s3
c0
c1
c2
c3
"
"
"
"
"
"
"
"
"
"
(
)
P
i0
2
=
(
)
i1
8
=
(
)
i3
10
=
(
)
,
,
s0
5
=
(
)
s1
5
=
(
)
s2
7
=
(
)
s3
9
=
(
)
,
,
,
O3|i0
i1
i3
s0
s1
s2
s3
c0
c1
c2
c3
"
"
"
"
"
"
"
"
"
"
(
)
P

Bayesian Programming
Page 100
graphically in Figure 6.3.
Note that, the constraints 
, 
, and 
  (control values 
, 
, and
) give better results than the constraint 
: there is no risk of obtaining 
.
The minimal output quality that we can obtain is six.  This takes us to an additional ques-
tion: what are the control values that maximize the expected value of 
? 
The expected value of a variable 
 is given by
 
(6.27)
By computing the expected value of the distributions in Table 6.2 it is possible to
show that the control values  
, 
, and 
 are a better option than 
. Furthermore, if
we 
maximize 
the 
expectancy 
over
 
with 
the 
fixed 
values
, 
 and over the space
 we obtain 
 with a resulting
expected value of 7.20079.
Control
0
1
2
3
4
5
6
7
8
9
10
0.0
0.0
0.0
0.0
0.0220845
0.0934247
0.253027
0.367386
0.242291
0.0217872
0.0
0.0
0.0
0.0
0.0
0.0
0.038257
0.2363
0.45947
0.24463
0.021329
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.18121
0.49079
0.29897
0.02900
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.165783
0.503557
0.30025
0.0304099
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.167165
0.502017
0.300179
0.0306388
0.0
0.0
0.0
0.0
0.0
0.0
0.0624419
0.237629
0.37178
0.29711
0.0310389
0.0
Table 6.2: Probability distributions of 
 for the different control values (
) that maximize the probability 
of holding the constraints on Table 6.1.
O3|i0
i1
i3
s0
s1
s2
s3
c0
c1
c2
c3
"
"
"
"
"
"
"
"
"
"
(
)
P
O3
14
15
16
17
18
19
O3
1i
O3
6
$
O3
7
$
O3
8
$
16 17
18
O3
9
$
O3
5
=
O3
X
E X
( )
xP x
( )
x
X
!!
=
16 17
18
19
O3|i0
i1
i3
s0
s1
s2
s3
c0
c1
c2
c3
"
"
"
"
"
"
"
"
"
"
(
)
P
i0
2
=
(
)
i1
8
=
(
)
i3
10
=
(
)
,
,
s0
5
=
(
)
s1
5
=
(
)
s2
7
=
(
)
s3
9
=
(
)
,
,
,
c0
c1
c2
c3
"
"
"
1*
C0
2
=
[
]
C1
6
=
[
]
C2
5
=
[
]
C3
6
=
[
]
,
,
,
=

Bayesian Program = Description + Question
Page 101
6.5
Diagnosis
We may also use our Bayesian model to diagnose failures.
Let us suppose that the output 
 is only seven. This means that at least one of the
four units is poor working condition. We want to identify these defective units so we can
fix them.
6.5.1
Question
The question is: "what is going wrong?". We must look for the values of 
, 
, 
, and
, knowing the entries, the sensor values, the control, and the final output.
The corresponding question is:
(6.28)
which, after simplification, resolves to:
Figure 6.3: The probability distribution 
 when 
, 
, and variable control values 
(
) are represented by  
 to 
 . These control values permit us to maximize the 
probability of holding the constraints in Talbe 6.1.
0
0.1
0.2
0.3
0.4
0.5
0.6
Probability
4
5
6
7
8
9
10
Output O3
14
0
0.1
0.2
0.3
0.4
0.5
0.6
Probability
4
5
6
7
8
9
10
Output O3
15
0
0.1
0.2
0.3
0.4
0.5
0.6
Probability
4
5
6
7
8
9
10
Output O3
16
0
0.1
0.2
0.3
0.4
0.5
0.6
Probability
4
5
6
7
8
9
10
Output O3
17
0
0.1
0.2
0.3
0.4
0.5
0.6
Probability
4
5
6
7
8
9
10
Output O3
18
0
0.1
0.2
0.3
0.4
0.5
0.6
Probability
4
5
6
7
8
9
10
Output O3
19
O3|i0
i1
i3
s0
s1
s2
s3
c0
c1
c2
c3
"
"
"
"
"
"
"
"
"
"
(
)
P
i0
2
=
(
)
i1
8
=
(
)
i3
10
=
(
)
,
,
s0
5
=
(
)
s1
5
=
(
)
s2
7
=
(
)
s3
9
=
(
)
,
,
,
c0
c1
c2
c3
"
"
"
14
19
O3
F0 F1 F2
F3
F0
F1
F2
F3
"
"
"
|i0
i1
i3
s0
s1
s2
s3
c0
c1
c2
c3
o3
"
"
"
"
"
"
"
"
"
"
"
(
)
P

Bayesian Programming
Page 102
(6.29)
6.5.2
Results
For 
, the usual entries 
, sensor readings equal to
, and controls all set to five, we require only 32 possi-
ble solutions, as presented in Table 6.3.
F0
F1
F2
F3
"
"
"
|i0
i1
i2
s0
s1
s2
s3
c0
c1
c2
c3
o3
"
"
"
"
"
"
"
"
"
"
"
(
)
P
s0|i0
F0
"
(
)
P
s1|i0
F1
"
(
)
P
×
s3|i2
F3
"
(
)
P
×
=
.
s2|O0
F2
"
(
)
P
.
O0|i0
i1
s0
c0
"
"
"
(
)
P
×
.
O1|i0
i1
s1
c1
"
"
"
(
)
P
.
O2|O0
O1
s2
c2
"
"
"
(
)
P
.
o3|i2
O2
s3
c3
"
"
"
(
)
P
×
O2
!
×
O1
!
×
O0
!
×
O3
7
=
i0
2
=
(
)
i1
8
=
(
)
i3
10
=
(
)
,
,
s0
5
=
(
)
s1
5
=
(
)
s2
4
=
(
)
s3
9
=
(
)
,
,
,

Bayesian Program = Description + Question
Page 103
These results show clearly that the defective unit is M2, with a most probable value of
three for 
.
This can be confirmed by computing separately the probabilities for each of the four
variables 
, 
, 
, and 
. 
, 
, and 
 are found to have a 50% chance of being
either eight or nine. In contrast, the probability distribution for 
 is given in Figure 6.4 and
gives 
 as the most probable value. 
8
8
2
8
0.016836
8
8
2
9
0.016836
8
8
3
8
0.051063
8
8
3
9
0.051063
8
8
4
8
0.045664
8
8
4
9
0.045664
8
8
5
8
0.011437
8
8
5
9
0.011437
8
9
2
8
0.016836
8
9
2
9
0.016836
8
9
3
8
0.051063
8
9
3
9
0.051063
8
9
4
8
0.045664
8
9
4
9
0.045664
8
9
5
8
0.011437
8
9
5
9
0.011437
9
8
2
8
0.016836
9
8
2
9
0.016836
9
8
3
8
0.051063
9
8
3
9
0.051063
9
8
4
8
0.045664
9
8
4
9
0.045664
9
8
5
8
0.011437
9
8
5
9
0.011437
9
9
2
8
0.016836
9
9
2
9
0.016836
9
9
3
8
0.051063
9
9
3
9
0.051063
9
9
4
8
0.045664
9
9
4
9
0.045664
9
9
5
8
0.011437
9
9
5
9
0.011437
Table 6.3: Results of diagnostic.
F0
F1
F2
F3
F2
F0
F1
F2
F3
F0
F1
F3
F2
F2
3
=

Bayesian Programming
Page 104
6.6
Lessons, comments and notes
6.6.1
Bayesian Program = Description + Question
A Bayesian program consists of two parts: a description, which is the probabilistic model
of the observed phenomenon, and a question used to interrogate this model.
Any partition of the set of relevant variables in three subsets: the set of searched vari-
ables (which should not be empty), the set of known variables, and the complementary
set of free variables, defines a valid question.
If we call 
 the conjunction of variables of the searched set, 
 the con-
junction of variables with known values, and 
 the conjunction of variables in the
complementary set, a question corresponds to the bundle of distributions:
,
(6.30)
one distribution:
(6.31)
for each possible value 
 of the 
 variable.
This may be summarized by the equation: "Bayesian Program = Description + Ques-
tion".
Figure 6.4: 
.
0
0.1
0.2
0.3
0.4
0.5
Probability
0
1
2
3
4
5
6
7
8
9
10
Efficiency F2
F2|i0
i1
i2
s0
s1
s2
s3
c0
c1
c2
c3
o3
"
"
"
"
"
"
"
"
"
"
"
(
)
P
Searched
Known
Free
Searched|Known
(
)
P
Searched|knowni
(
)
P
knowni
Known

Bayesian Program = Description + Question
Page 105
6.6.2
The essence of Bayesian inference
The essence of Bayesian inference is to be able to compute 
.
This computation is always made by applying the same steps:
1. Utilization of the marginalization rule (2.9):
(6.32)
2. Utilization of the conjunction rule (2.5):
(6.33)
3. Replacement of 
 by a normalization constant:
(6.34)
As the decomposition gives us a means to compute the joint distribution
 as a product of simpler distributions, we are always able to
compute the wanted distribution.
However, the number of possible values for the variable 
 may be huge.
Exhaustive and explicit computation of 
 is then impossible. It  must
be either approximated, sampled, or used to find most probable values. In any of these
three cases, the regions of interest in the searched space are the areas of high probability,
which most often cover a tiny portion of the whole space. The fundamental problem is to
find them, which is a very difficult optimization problem, indeed.
Worse, 
for 
each 
single 
value 
 
of 
, 
to 
compute
, we need to sum on 
 (see Equation 6.34). The number of pos-
sible values for 
 may also be huge and the integration problem itself may be a heavy
Searched|knowni
(
)
P
Searched|knowni
(
)
P
Searched
Free
"
|knowni
(
)
P
Free
!
=
Searched|knowni
(
)
P
Searched
Free
knowni
"
"
(
)
P
knowni
(
)
P
-------------------------------------------------------------------------
Free
!
=
Known
(
)
P
Searched|knowni
(
)
P
1
*---
Searched
Free
knowni
"
"
(
)
P
Free
!
×
=
Searched
Free
knowni
"
"
(
)
P
Searched
Searched|knowni
(
)
P
searchedj
Searched
searchedj|knowni
(
)
P
Free
Free

Bayesian Programming
Page 106
computational burden. An approximation of the sum must be made, which means that it
must effectively be computed on a sample of the whole space. Where should we sample?
Obviously, to find a good estimation of the sum we should sample in areas where the
probability of 
 is high. This is yet another optimization
problem where we must search the high-probability areas of a distribution.
All the algorithmics of Bayesian inference try to deal with these two optimization
problems using various methods. A survey of these algorithms will be presented in Chap-
ter 14. The particular solutions used in ProBT® will be described in Chapter 17.
6.6.3
No inverse or direct problem
When using a functional model defined as:
(6.35)
computing 
 knowing 
 is a direct problem. A search for 
 knowing 
 is an inverse
problem.
Most of the time, the direct problem is easy to solve, as we know the function 
.
Often the inverse one is very difficult because 
, the inverse function, is at best
unknown and even, sometimes, nonanalitic.
Unfortunately, most of the time also, the inverse problem is much more interesting
than the direct one. For instance, if 
 is the function that predicts the performance of a
racing yacht, based on a knowledge of her characteristics, what is really of interest is to
find the characteristics that ensures the best performance.
When using a probabilistic model defined as:
(6.36)
the difference between direct and inverse problems vanishes.
In the joint distribution, indeed, all the variables play the exact same mathematical
role. Whatever the decomposition, any of the variables can in turn, in different questions,
be considered as either searched, known, or free. There is no difference in the nature of
the computation to calculate either 
 or 
.
However, even if any question can be asked of the probabilistic model, we stressed in
the previous section that some of them can be time and resource consuming to answer.
searchedj
Free
knowni
"
"
(
)
P
X
Y
( )
F
=
X
Y
Y
X
F
F
1
–
F
X
Y
"
(
)
P
X
Y
 |
(
)
P
Y
X
 |
(
)
P

Bayesian Program = Description + Question
Page 107
There may be no more direct or inverse problems, but there are still some difficult prob-
lems characterized by either a huge integration space (
), or a huge search space
(
), or both. 
6.6.4
No ill-posed problem
When using functional models, inverse problems, even when they are solvable, may be
ill-posed in the sense that 
 may have several solutions.
This is a very common situation in control problems, for instance, if you are given
some values of the control variables, you can predict the outputs exactly, but if you are
given the goal, you have numerous control solutions to achieve it.
In these cases, functional models do not have enough information to give you any hint
to help you choose between the different 
 satisfying 
.
In contrast, 
 gives much more information, because it allows you to find the rel-
ative probabilities of the different solutions.
Free
Searched
Y
F
1
–
X
( )
=
Y
Y
F
1
–
X
( )
=
Y
X
 |
(
)
P

Bayesian Programming
Page 108

Page 109
 7
Information fusion and 
inverse programming
$$$
$$$

Bayesian Programming
Page 110
7.1
Fusion of information in ADAS systems
7.1.1
Statement of the problem
7.1.2
Bayesian Program
Specification
Variables
Decomposition
Forms
Identification
Question
Bayesian Program
7.1.3
Results
7.2
Programming and training video games avatars
7.2.1
Statement of the problem
The video game industry has became during the last decade one of the most important
field of the entertainment business. 
As for any other kind of industry, productivity is a constant concern for the game
developers. From the scriptwiter conceiving the story to the computer network engineer
solving the communication and servers problems a lot of different professions are inv-
loved and huge team have to work together to produce a new game. For instance, video
games make a great use of bots, kind of virtual robots present in the game, which popu-
late the virtual worlds and interact with the players. These bots $$$ 

Information fusion and inverse programming
Page 111
7.2.2
Bayesian Program
Specification
Variables
Decomposition
Forms
Identification
Question
Bayesian Program
7.2.3
Results
7.3
Lessons, comments and notes
7.3.1
Information fusion
7.3.2
Coherence fusion
7.3.3
Inverse programming
The simplest way to sequence instructions or sub-programs within a program is to write
them one after another. When the execution of an instruction or sub-program is complete,
the computer proceeds to the next one. This mechanism supposes, first, that this sequenc-
ing is not biased by any external conditions and, second, that the end of the execution of
an instruction or a sub-program is known without any uncertainty.
If the sequencing is biased by external condition, either a simple "if-then-else" or "case"
mechanism is used (see Chapter 9) or, alternatively, a more sophisticated mechanism
based on finite state automata. In both cases, this still supposes that both the external
conditions and the end of execution are known with certainty.
Inverse programming is proposed to select sub-program sequencing when either the
external conditions or the end of execution may be uncertain.
The simple ideas supporting inverse programming are: (i) to express the probability
of external conditions knowing which sub-program or action is executed, (ii) to consider
that these conditions are independent of one another knowing the action, and (iii) to

Bayesian Programming
Page 112
decide which sub-program to execute by deciding which action is the most probable,
knowing the external conditions.
This sequencing mechanism has several very important qualities:
•
It takes uncertainty into account;
•
It requires very little memory compared to finite state automata;
•
It is very efficient from a computing time point of view;
•
It is very simple to specify;
•
It offers easy upgrades when introducing either new conditions or new sub-pro-
grams;
•
Finally, it leads to descriptions that can easily be learned from examples.
The only potential drawback of this approach is that the fundamental hypothesis that
conditions are independent of one another knowing the action is far from completely sat-
isfied in many practical cases. However, different applications of inverse programming
have proved that, even though it is partially false, this hypothesis leads to satisfactory
behavior. Furthermore, this hypothesis could be relaxed if necessary. This could be done
by expressing in the decomposition some dependencies between the conditions, if they
are really required.

Page 113
 8
Calling Bayesian Subroutines
$$$
The pupose of this chapter is to exhibit a first way to combine descriptions with one
another in order to incrementaly build more and more complicated and sophisticated
probabilistic models. This is obtained by including in the decomposition, calls to Baye-
sian subroutines. We show that it is hence possible to construct hierachies of probabilistic
models.

Bayesian Programming
Page 114
8.1
Exemple 1
8.1.1
Statement of the problem
8.1.2
Bayesian Program
Specification
Variables
Decomposition
Forms
Identification
Question
Bayesian Program
8.1.3
Results
8.2
Evaluation of operational risk
8.2.1
Statement of the problem
8.2.2
Bayesian Program
Specification
Variables
Decomposition
Forms
Identification
Question
Bayesian Program
8.2.3
Results
8.3
Lessons, comments and notes
8.3.1
Calling subroutines
8.3.2
Hierarchies of description

Calling Bayesian Subroutines
Page 115

Bayesian Programming
Page 116

Page 117
 9
Bayesian program mixture
$$$
$$$

Bayesian Programming
Page 118
9.1
Homing Behavior
9.1.1
Statement of the problem
9.1.2
Bayesian Program
Specification
Variables
Decomposition
Forms
Identification
Question
Bayesian Program
9.1.3
Results
9.2
Heating forecast
9.2.1
Statement of the problem
9.2.2
Bayesian Program
Specification
Variables
Decomposition
Forms
Identification
Question
Bayesian Program
9.2.3
Results
9.3
Lessons, comments and notes
9.3.1
Bayesian program combination
9.3.2
A probabilistic "if - then- else"

Bayesian program mixture
Page 119

Bayesian Programming
Page 120

Page 121
 10
Bayesian filters
$$$
$$$

Bayesian Programming
Page 122
10.1
Markov localization
10.1.1
Statement of the problem
10.1.2
Bayesian Program
Specification
Variables
Decomposition
Forms
Identification
Question
Bayesian Program
10.1.3
Results
10.2
???
10.2.1
Statement of the problem
10.2.2
Bayesian Program
Specification
Variables
Decomposition
Forms
Identification
Question
Bayesian Program
10.2.3
Results
10.3
Lessons, comments and notes
10.3.1
$$$

Page 123
 11
Using functions
$$$
$$$

Bayesian Programming
Page 124
11.1
ADD dice
11.1.1
Statement of the problem
11.1.2
Bayesian Program
Specification
Variables
Decomposition
Forms
Identification
Question
Bayesian Program
11.1.3
Results
11.2
CAD system
11.2.1
Statement of the problem
11.2.2
Bayesian Program
Specification
Variables
Decomposition
Forms
Identification
Question
Bayesian Program
11.2.3
Results
11.3
Lessons, comments and notes
Using functions

Page 125
 12
Bayesian Programming 
Formalism
$$$
$$$
12.1
How simple! How subtle!
The purpose of this chapter is to present Bayesian Programming formally and to demon-
strate that it is very simple and very clear but, nevertheless very powerful and very sub-
tle. Probability is an extension of logic, as mathematically sane and simple as logic, but
with more expressive power than logic.
It may seemed unusual to present the formalism at the end of the book. We have done
this to help comprehension and to assist intuition without sacrificing rigor. After reading
this chapter, anyone can check that all the examples and programs presented earlier com-
ply with the formalism.

Bayesian Programming
Page 126
12.2
Logical propositions
The first concept we use is the usual notion of logical proposition. Propositions are
denoted by lowercase names. Propositions may be composed to obtain new proposition
using the usual logical operators: 
, denoting the conjunction of propositions 
 and
, 
 their disjunction, and 
, the negation of proposition .
12.3
Probability of a proposition
To be able to deal with uncertainty, we attach probabilities to propositions. 
We consider that, to assign a probability to a proposition , it is necessary to have at
least some preliminary knowledge, summed up by a proposition 
. Consequently, the
probability of a proposition  is always conditioned, at least, by 
. For each different ,
 is an application that assigns to each proposition 
 a unique real value
 in the interval 
.
Of course, we are interested in reasoning about the probabilities of conjunctions, dis-
junctions, and negations of propositions, denoted, respectively, by 
,
 and 
.
We are also interested in the probability of proposition  conditioned by both the pre-
liminary knowledge 
 and some other proposition . This is denoted 
.
12.4
Normalization and conjunction postulates
Probabilistic reasoning requires only two basic rules:
1. - The conjunction rule, which gives the probability of a conjunction of proposi-
tions.
(12.1)
2. - The normalization rule, which states that the sum of the probabilities of  and 
is one.
(12.2)
In this book, we take these two rules as postulates1.
a
b
"
a
b
a
b
2
a
¬
a
a
+
a
+
+
.
+
 |
(
)
P
a
a
+
 |
(
)
P
0 1
,
[
]
a
b
"
+
 |
(
)
P
a
b
2
+
 |
(
)
P
a
¬
+
 |
(
)
P
a
+
b
a
b
+
"
 |
(
)
P
a
b
"
+
 |
(
)
P
a
+
 |
(
)
P
b
a
+
"
 |
(
)
P
×
=
b
+
 |
(
)
P
a
b
+
"
 |
(
)
P
×
=
a
a
¬
a
+
 |
(
)
P
a
¬
+
 |
(
)
P
+
1
=

Bayesian Programming Formalism
Page 127
As in logic, where the resolution principle (Robinson, 1965; Robinson, 1979) is suffi-
cient to solve any inference problem, in discrete probabilities, these two rules (12.1 &
12.2) are sufficient for any computation. Indeed, we may derive all the other necessary
inference rules from these two.
12.5
Disjunction rule for propositions
For instance, the rule concerning the disjunction of propositions:
(12.3)
may be derived as follows:
(12.4)
12.6
Discrete variables
The notion of discrete variable is the second concept we require. Variables are denoted by
names starting with one uppercase letter.
By definition, a discrete variable 
 is a set of logical propositions 
, such that these
propositions are mutually exclusive (for all 
 with 
, 
 is false) and exhaustive
(at least one of the propositions 
 is true). 
 means «variable 
 takes its 
 value».
 denotes the cardinality of the set 
 (the number of propositions 
).
1.For sources giving justifications of these two rules, see FAQ/FAM 16.6 "Cox theorem (What is?)", page 202.
a
b
2
+
 |
(
)
P
a
+
 |
(
)
P
b
+
 |
(
)
P
a
b
"
+
 |
(
)
P
–
+
=
a
b
2
+
 |
(
)
P
1
a
¬
b
¬
"
+
 |
(
)
P
–
(
)
=
1
a
¬
+
 |
(
)
P
b
¬
a
¬
+
"
 |
(
)
P
×
–
=
1
a
¬
+
 |
(
)
P
1
b
a
¬
+
"
 |
(
)
P
–
(
)
×
–
=
a
+
 |
(
)
P
a
¬
b
"
+
 |
(
)
P
+
=
a
+
 |
(
)
P
b
+
 |
(
)
P
a
¬
b
+
"
 |
(
)
P
×
+
=
a
+
 |
(
)
P
b
+
 |
(
)
P
1
a
b
+
"
 |
(
)
P
–
(
)
×
+
=
a
+
 |
(
)
P
b
+
 |
(
)
P
a
b
"
+
 |
(
)
P
–
+
=
X
xi
i j,
i
j
/
xi
xj
"
xi
xi
X
i
th
CARD X
( )
X
xi

Bayesian Programming
Page 128
12.7
Variable conjunction
The conjunction of two variables 
 and 
, denoted 
, is defined as the set of
 propositions 
. 
 is a set of mutually exclusive and
exhaustive logical propositions. As such, it is a new variable1. 
Of course, the conjunction of 
 variables is also a variable and, as such, it may be
renamed at any time and considered as a unique variable in the sequel.
12.8
Probability on variables
For simplicity and clarity, we also use probabilistic formulas with variables appearing
instead of propositions. 
By convention, each time a variable 
 appears in a probabilistic formula 
, it
should be understood as 
. 
For instance, given three variables 
, 
, and 
:
 
(12.5)
stands for:
(12.6)
12.9
Conjunction rule for variables
(12.7)
According to our convention for probabilistic formulas including variables, this may
be restated as:
1. In contrast, the disjunction of two variables, defined as the set of propositions 
, is not a variable. These prop-
ositions are not mutually exclusive.
X
Y
X
Y
"
CARD X
( )
CARD Y
( )
×
xi
yj
"
X
Y
"
xi
yj
2
n
X
3 X
( )
xi
4
X
!
3 xi
(
)
,
X Y
Z
X
Y
"
Z
+
"
 |
(
)
P
X
Z
+
5
 |
(
)
P
=
xi
4
X
!
yj
4
Y
!
zk
4
Z
!
,
,
xi
yj
"
zk
+
"
 |
(
)
P
xi
zk
+
"
 |
(
)
P
=
X
Y
"
+
 |
(
)
P
X
+
 |
(
)
P
Y
X
+
"
 |
(
)
P
×
=
Y
+
 |
(
)
P
X
Y
+
"
 |
(
)
P
×
=

Bayesian Programming Formalism
Page 129
(12.8)
which may be directly deduced from the conjunction rule for propositions (12.1).
12.10
Normalization rule for variables
(12.9)
The normalization rule may obviously be derived as follows:
(12.10)
where the first equality derives from the normalization rule for propositions (12.2),
the second from the exhaustiveness of propositions 
, and the third from both the appli-
cation of Equation (12.3) and the mutual exclusivity of propositions 
.
12.11
Marginalization rule
(12.11)
The marginalization rule is derived by the successive application of the conjunction
rule (12.7) and the normalization rule (12.9):
xi
4
X
!
yj
Y
!
4
,
xi
yj
"
+
 |
(
)
P
xi
+
 |
(
)
P
yj
xi
+
"
 |
(
)
P
×
=
yj
+
 |
(
)
P
xi
yj
+
"
 |
(
)
P
×
=
X
+
 |
(
)
P
X!
1
=
1
x1
+
 |
(
)
P
x1
¬
+
 |
(
)
P
+
=
x1
+
 |
(
)
P
x2
...
xCARD X
( )
2
2
+
 |
(
)
P
+
=
x1
+
 |
(
)
P
x2
+
 |
(
)
P
...
xCARD X
( )
+
 |
(
)
P
+
+
+
=
xi
+
 |
(
)
P
xi
X
!!
=
xi
xi
X
Y
"
+
 |
(
)
P
X!
Y
+
 |
(
)
P
=

Bayesian Programming
Page 130
(12.12)
12.12
Bayesian program
We define a Bayesian program as a mean of specifying a family of probability distribu-
tions.  
The constituent elements of a Bayesian program are presented in Figure 12.1:
•
A program is constructed from a description and a question.
•
A description is constructed using some specification (
) as given by the pro-
grammer and an identification or learning process for the parameters not com-
pletely specified by the specification, using a data set ( ). 
•
A specification is constructed from a set of pertinent variables, a decomposition,
and a set of forms. 
•
Forms are either parametric forms or Bayesian programs.
12.13
Description
The purpose of a description is to specify an effective method of computing a joint distri-
bution on a set of variables 
 given a set of experimental data  and some
specification 
. This joint distribution is denoted as: 
.
Figure 12.1: Structure of a Bayesian program
X
Y
"
+
 |
(
)
P
X!
Y
+
 |
(
)
P
X
Y
+
"
 |
(
)
P
×
X!
=
Y
+
 |
(
)
P
X
Y
+
"
 |
(
)
P
X!
×
=
Y
+
|
(
)
P
=
Pr
Ds
Sp +
( )
Dc
Fo
Parametric Forms 
Bayesian Programs
)
+
,
)
*
*
*
+
*
*
*
,
Id .
( )
)
*
*
*
*
*
+
*
*
*
*
*
*
*
*
*
*
*
+
*
*
*
*
*
*
+
.
X1 X2 … Xn
,
,
,
{
}
.
+
X1
X2
…
Xn
"
"
"
.
+
"
 |
(
)
P

Bayesian Programming Formalism
Page 131
12.14
Specification
To specify preliminary knowledge, the programmer must undertake the following: 
1. Define the set of relevant variables 
 on which the joint distribution
is defined.
2. Decompose the joint distribution:
Given a partition of 
 into 
 subsets, we define 
 variables
, each corresponding to one of these subsets. 
Each variable 
 is obtained as the conjunction of the variables 
belonging to the subset . The conjunction rule (12.7) leads to:
(12.13)
Conditional independence hypotheses then allow further simplifications. A condi-
tional independence hypothesis for variable 
 is defined by picking some variables
 among the variables appearing in conjunction 
, calling 
 the
conjunction of these chosen variables and setting:
(12.14)
We then obtain:
(12.15)
Such a simplification of the joint distribution as a product of simpler distributions is
called a decomposition.
This ensures that each variable appears at most once on the left of a conditioning
bar, which is the necessary and sufficient condition to write mathematically valid
decompositions.
X1 X2 … Xn
,
,
,
{
}
X1 X2 … Xn
,
,
,
{
}
k
k
L1 … Lk
,
,
Li
Xi1 Xi2 …
,
,
{
}
i
X1
X2
…
Xn
"
"
"
.
+
"
 |
(
)
P
L1
.
+
"
 |
(
)
P
L2
L1
.
+
"
"
 |
(
)
P
…
×
Lk
Lk
1
–
…
L2
L1
.
+
"
"
"
"
"
 |
(
)
P
×
×
=
Li
Xj
Li
1
–
…
L2
L1
"
"
"
Ri
Li
Li
1
–
…
L2
L1
.
+
"
"
"
"
"
 |
(
)
P
Li
Ri
.
+
"
"
 |
(
)
P
=
X1
X2
…
Xn
"
"
"
.
+
"
 |
(
)
P
L1
.
+
"
 |
(
)
P
L2
R2
.
+
"
"
 |
(
)
P
L3
R3
.
+
"
"
 |
(
)
P
×
…
×
Lk
Rk
.
+
"
"
 |
(
)
P
×
×
=

Bayesian Programming
Page 132
3. Define the forms:
Each distribution 
 appearing in the product is then associated
with either a parametric form (i.e., a function 
) or another Bayesian program.
In general, 
 is a vector of parameters that may depend on 
 or  or both. Learning
takes place when some of these parameters are computed using the data set .
12.15
Questions
Given a description (i.e., 
), a question is obtained by parti-
tioning 
 into three sets: the searched variables, the known variables, and
the free variables. 
We define the variables 
, 
 and 
 as the conjunction of the vari-
ables belonging to these sets. We define a question as the distribution:
. 
(12.16)
12.16
Inference
Given the joint distribution 
, it is always possible to com-
pute any possible question, using the following general inference:
Li
Ri
.
+
"
"
 |
(
)
P
fµ Li
(
)
µ
Ri
.
.
X1
X2
…
Xn
"
"
"
.
+
"
 |
(
)
P
X1 X2 … Xn
,
,
,
{
}
Searched
Known
Free
Searched
known
.
+
"
"
 |
(
)
P
X1
X2
…
Xn
"
"
"
.
+
"
 |
(
)
P

Bayesian Programming Formalism
Page 133
(12.17)
where the first equality results from the marginalization rule (12.11), the second
results from the product rule (12.7) and the third corresponds to a second application of
the marginalization rule. The denominator appears to be a normalization term. Conse-
quently, by convention, we will replace it by 
.
Theoretically, this allows us to solve any Bayesian inference problem. In practice,
however, the cost of computing exhaustively and exactly  
is too great in most cases. Chapter 14 reviews and explains the main techniques and algo-
rithms to deal with this inference problem.
Before that, Chapter 13 is revisiting the main Bayesian models using the present for-
malism.
Searched
known
.
+
"
"
 |
(
)
P
Searched
Free
"
known
.
+
"
"
 |
(
)
P
Free
!
=
Searched
Free
known
"
"
.
+
"
 |
(
)
P
Free
!
Known
.
+
"
 |
(
)
P
----------------------------------------------------------------------------------------------------
=
Searched
Free
known
"
"
.
+
"
 |
(
)
P
Free
!
Searched
Free
known
"
"
.
+
"
 |
(
)
P
Searched
Free
!
--------------------------------------------------------------------------------------------------------------
=
1
*---
Searched
Free
known
"
"
.
+
"
 |
(
)
P
!
×
=
*
Searched
known
.
+
"
"
 |
(
)
P

Bayesian Programming
Page 134

Page 135
 13
Bayesian Models Revisited
$$$
The goal of this section is to present the main probabilistic models currently used for
conception and development.
We systematically use the Bayesian Programming formalism to present these models,
because it is precise and concise, and it simplifies their comparison.
We mainly concentrate on the definition of these models. Discussions about inference
and computation are postponed to Chapter 14 and discussions about learning and identifi-
cation are postponed to Chapter 15.
We chose to divide the different probabilistic models into two categories: the general
purpose probabilistic models and the problem-oriented probabilistic models. 
In the first category, the modeling choices are made independently of any specific
knowledge about the modeled phenomenon. Most of the time, these choices are essen-
tially made to keep the inference tractable. However, the technical simplifications of
these models may be compatible with large classes of problems and consequently may
have numerous applications.
In the second category, on the contrary, the modeling choices and simplifications are

Bayesian Programming
Page 136
decided according to some specific knowledge about the modeled phenomenon. These
choices could eventually lead to very poor models from a computational wiewpoint.
However, most of the time, problem-dependent knowledge such as conditional indepen-
dence between variables, leads to very significant and effective simplifications and com-
putational improvements. 
13.1
General purpose probabilistic models
13.1.1
Graphical models and Bayesian networks
Bayesian networks
Bayesian networks (BNs), first introduced by Judea Pearl (Pearl, 1988), have emerged as
a primary method for dealing with probabilistic and uncertain information. They are the
result of the marriage between the theory of probabilities and the theory of graphs. 
BNs are defined by the following Bayesian program: 
(13.1)
•
The pertinent variables are not constrained and have no specific semantics.
•
The decomposition, on the contrary, is specific: it is a product of distributions with
one and only one variable 
 conditioned by a conjunction of other variables 
,
Pr
Ds
Sp
Va
X1 ... XN
,
,
Dc
X1
...
XN
"
"
(
)
P
Xi
Ri
 |
(
)
P
i
1
=
N
&
=
Fo
Any
)
*
*
*
*
*
*
*
+
*
*
*
*
*
*
*
,
Id
)
*
*
*
*
*
*
*
*
*
+
*
*
*
*
*
*
*
*
*
,
Qu
Xi
Known
 |
(
)
P
)
*
*
*
*
*
*
*
*
*
*
*
*
+
*
*
*
*
*
*
*
*
*
*
*
*
,
Xi
Ri

Bayesian Models Revisited
Page 137
called its parents. An obvious bijection exists between joint probability distribu-
tions defined by such decompositions and directed acyclic graphs (DAG): nodes are
associated with variables, and oriented edges are associated with conditional
dependencies. Using graphs in probabilistic models leads to an efficient way to
define hypotheses over a set of variables, an economic representation of joint
probability distribution, and, most importantly, an easy and efficient way to per-
form probabilistic inference (see Chapter 14).
•
The parametric forms are not constrained but they are very often restricted to
probability tables.
•
Very efficient inference techniques have been developed to answer questions
, however, some difficulties appear with more general questions
(see Chapter 14).
Readings on Bayesian networks and graphical models should start with the following
introductory textbooks: Probabilistic Reasoning in Intelligent Systems : Networks of Plausi-
ble Inference (Pearl, 1988), Graphical Models  (Lauritzen, 1996), Learning in Graphical
Models (Jordan, 1998) and Graphical Models for Machine Learning and Digital Communica-
tion  (Frey, 1998).
Dynamical Bayesian networks 
To deal with time and to model stochastic processes, the framework of BNs has been
extended to dynamic Bayesian networks (DBNs) (see Dean & Kanazawa, 1989). Given a
graph representing the structural knowledge at time t, supposing this structure to be time-
invariant and time to be discrete, the resulting DBN is the repetition of the first structure
from a start time to a final time. Each part at time t in the final graph is named a time
slice.
They are defined by the following Bayesian program:
 
(13.2)
Xi
known
 |
(
)
P

Bayesian Programming
Page 138
•
 is a conjunction of variables taken in the set 
.
It means that 
 depends only on its parents at time  (
), as in a reg-
ular BN and on some variables from the previous time slice (
).
•
 defines a graph for a time slice and all time slices are identical
when the time index t is changing.
•
A DBN as a whole, "unrolled" over time, may be considered as a large regular BN.
Consequently the usual inference techniques applicable to BNs are still valid for
such "unrolled" DBNs.
The best introduction, survey and starting point on DBNs is the Ph.D. thesis of K.
Murphy, Dynamic Bayesian Networks: Representation, Inference and Learning (Murphy,
2002).
Pr
Ds
Sp
Va
X1
0 ... XN
0 ... X1
T ... XN
T
,
,
,
,
,
,
Dc
X1
0
...
XN
T
"
"
(
)
P
X1
0
...
XN
0
"
"
(
)
P
Xi
t
Ri
t
 |
(
)
P
i
1
=
N
&
t
0
=
T
&
×
=
Fo
Any
)
*
*
*
*
*
*
*
*
+
*
*
*
*
*
*
*
*
,
Id
)
*
*
*
*
*
*
*
*
*
*
+
*
*
*
*
*
*
*
*
*
*
,
Qu
Xi
T
known
 |
(
)
P
)
*
*
*
*
*
*
*
*
*
*
*
*
*
+
*
*
*
*
*
*
*
*
*
*
*
*
*
,
Ri
t
X1
t ... Xi
1
–
t
,
,
)
-
+
.
,
/
X1
t
1
–
... XN
t
1
–
,
,
)
-
+
.
,
/
6
Xi
t
t
X1
t ... Xi
1
–
t
,
,
)
-
+
.
,
/
X1
t
1
–
... XN
t
1
–
,
,
)
-
+
.
,
/
Xi
t
Ri
t
 |
(
)
P
i
1
=
N
&

Bayesian Models Revisited
Page 139
13.1.2
Recursive Bayesian estimation: Bayesian filters, Hidden Markov Models, Kal-
man filters and farticle filters
Recursive Bayesian estimation: Bayesian filtering, prediction and smoothing
Recursive Bayesian estimation is the generic name for a very large applied class of prob-
abilistic models of time series. 
They are defined by the following Bayesian program:
(13.3)
•
Variables 
 are a time series of state variables considered on a time hori-
zon ranging from 0 to 
. Variables 
 are a time series of observation vari-
ables on the same horizon.
•
The decomposition is based: 
°
on 
, called the system model, transition model or dynamic model,
which formalizes the transition from the state at time i - 1 to the state at time i;
Pr
Ds
Sp
Va
S
0 ... S
T O
0 ... O
T
,
,
,
,
,
Dc
S
0
...
S
T
O
0
...
O
T
"
"
"
"
"
(
)
P
S
0
(
)
P
O
0
S
0
 |
(
)
P
S
i
S
i
1
–
 |
(
)
P
O
i
S
i
 |
(
)
P
×
[
]
i
1
=
T
&
×
×
=
Fo
S
0
(
)
P
S
i
S
i
1
–
 |
(
)
P
O
i
S
i
 |
(
)
P
)
*
*
*
*
*
*
*
*
*
*
*
+
*
*
*
*
*
*
*
*
*
*
*
,
Id
)
*
*
*
*
*
*
*
*
*
*
*
*
*
+
*
*
*
*
*
*
*
*
*
*
*
*
*
,
Qu
S
t
k
+
O
0
...
O
t
"
"
 |
(
)
P
k
0
=
(
)
Filtering
,
k
0
>
(
)
Prediction
,
k
0
<
(
)
Smoothing
,
)
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
+
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
,
S
0 ... S
T
,
,
T
O
0 ... O
T
,
,
S
i
S
i
1
–
 |
(
)
P

Bayesian Programming
Page 140
°
on 
, called the observation model, which expresses what can be
observed at time i when the system is in state 
, 
°
and on a prior 
 over states at time 0.
•
The question usually asked of these models is 
: what is the
probability distribution for the state at time t + k knowing the observations from
instant 0 to t? The most common case is Bayesian filtering where 
, which
means that one searches for the present state, knowing the past observations. How-
ever it is also possible to do prediction 
, where one tries to extrapolate a
future state from past observations, or to do smoothing 
, where one tries to
recover a past state from observations made either before or after that instant.
However, some more complicated questions may also be asked (see the later sec-
tion on HMM).
Bayesian filters 
 have a very interesting recursive property, which contributes
greatly to their attractiveness. 
 may be computed simply from
 with the following formula:
(13.4)
The derivation is the following:
O
i
S
i
 |
(
)
P
S
i
S
0
(
)
P
S
t
k
+
O
0
...
O
t
"
"
 |
(
)
P
k
0
=
k
0
>
(
)
k
0
<
(
)
k
0
=
(
)
S
t
O
0
...
O
t
"
"
 |
(
)
P
S
t
1
–
O
0
...
O
t
1
–
"
"
 |
(
)
P
S
t
O
0
...
O
t
"
"
 |
(
)
P
O
t
S
t
 |
(
)
P
S
t
S
t
1
–
 |
(
)
P
S
t
1
–
O
0
...
O
t
1
–
"
"
 |
(
)
P
×
[
]
S
t
1
–!
×
=

Bayesian Models Revisited
Page 141
(13.5)
Another interesting aspect of this equation is to consider that there are two phases, a
prediction phase and an estimation phase:
•
During the prediction phase, the state is predicted using the dynamic model and
the estimation of the state at the previous moment
(13.6)
•
During the estimation phase, the prediction is either confirmed or invalidated
S
0
...
S
T
O
0
...
O
T
"
"
"
"
"
(
)
P
O
0
...
O
t
"
"
(
)
P
-----------------------------------------------------------------------------
O
t
1
+
... O
T
,
,
S
t
1
+
... S
T
,
,
!
S
0 ... S
t
1
–
,
,
!
=
S
0
(
)
P
O
0
S
0
 |
(
)
P
S
i
S
i
1
–
 |
(
)
P
O
i
S
i
 |
(
)
P
×
[
]
i
1
=
T
&
×
×
O
0
...
O
t
"
"
(
)
P
------------------------------------------------------------------------------------------------------------------------------------------
O
t
1
+
... O
T
,
,
S
t
1
+
... S
T
,
,
!
S
0 ... S
t
1
–
,
,
!
=
S
0
(
)
P
O
0
S
0
 |
(
)
P
S
i
S
i
1
–
 |
(
)
P
O
i
S
i
 |
(
)
P
×
[
]
i
1
=
t
&
×
×
O
0
...
O
t
"
"
(
)
P
------------------------------------------------------------------------------------------------------------------------------------------
.
S
j
S
j
1
–
 |
(
)
P
O
j
S
j
 |
(
)
P
×
[
]
j
t
1
+
=
T
&
O
t
1
+
... O
T
,
,
S
t
1
+
... S
T
,
,
!
×
S
0 ... S
t
1
–
,
,
!
=
S
0
(
)
P
O
0
S
0
 |
(
)
P
S
i
S
i
1
–
 |
(
)
P
O
i
S
i
 |
(
)
P
×
[
]
i
2
=
t
&
×
×
O
0
...
O
t
"
"
(
)
P
------------------------------------------------------------------------------------------------------------------------------------------
S
0 ... S
t
1
–
,
,
!
=
O
t
S
t
 |
(
)
P
S
t
S
t
1
–
 |
(
)
P
S
0
(
)
P
O
0
S
0
 |
(
)
P
S
i
S
i
1
–
 |
(
)
P
O
i
S
i
 |
(
)
P
×
[
]
i
2
=
t
1
–
&
×
×
O
0
...
O
t
1
–
"
"
(
)
P
------------------------------------------------------------------------------------------------------------------------------------------
S
0 ... S
t
2
–
,
,
!
×
S
t
1
–!
×
=
O
t
S
t
 |
(
)
P
S
t
S
t
1
–
 |
(
)
P
S
t
1
–
O
0
...
O
t
1
–
"
"
 |
(
)
P
×
[
]
!
×
=
S
t
O
0
...
O
t
1
–
"
"
 |
(
)
P
S
t
S
t
1
–
 |
(
)
P
S
t
1
–
O
0
...
O
t
1
–
"
"
 |
(
)
P
×
[
]
S
t
1
–!
=

Bayesian Programming
Page 142
using the observation
(13.7)
Prediction 
 and smoothing 
 do not lead to such neat simplifications and
tend to produce large sums that may represent a huge computational burden.
Hidden Markov Models
Hidden Markov Models (HMMs) are a very popular specialization of Bayesian filters.
They are defined by the following Bayesian program:
(13.8)
•
Variables are treated as discrete.
•
The transition model 
 and the observation models 
 are
both specified using probability matrices.
•
The 
question 
most 
frequently 
asked 
of 
HMMs 
is
S
t
O
0
...
O
t
"
"
 |
(
)
P
O
t
S
t
 |
(
)
P
S
t
O
0
...
O
t
1
–
"
"
 |
(
)
P
×
=
k
0
>
(
)
k
0
<
(
)
Pr
Ds
Sp
Va
S
0 ... S
t O
0 ... O
t
,
,
,
,
,
Dc
S
0
...
S
t
O
0
...
O
t
"
"
"
"
"
(
)
P
S
0
(
)
P
O
0
S
0
 |
(
)
P
S
i
S
i
1
–
 |
(
)
P
O
i
S
i
 |
(
)
P
×
[
]
i
1
=
t
&
×
×
=
Fo
S
0
(
)
P
Matrix
,
S
i
S
i
1
–
 |
(
)
P
Matrix
,
O
i
S
i
 |
(
)
P
Matrix
,
)
*
*
*
*
*
*
*
*
*
*
*
+
*
*
*
*
*
*
*
*
*
*
*
,
Id
)
*
*
*
*
*
*
*
*
*
*
*
*
*
+
*
*
*
*
*
*
*
*
*
*
*
*
*
,
Qu
MAX
S
1
S
2
...
S
t
1
–
"
"
"
S
1
S
2
...
S
t
1
–
"
"
"
S
t
O
0
...
O
t
"
"
"
 |
(
)
P
[
]
)
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
+
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
,
S
i
S
i
1
–
 |
(
)
P
O
i
S
i
 |
(
)
P

Bayesian Models Revisited
Page 143
: what is the most
probable series of states that leads to the present state, knowing the past observa-
tions?1
This particular question may be answered with a specific and very efficient algorithm
called the Viterbi algorithm, which is presented in Chapter 14.
A specific learning algorithm called the Baum-Welch algorithm has also been devel-
oped for HMMs (see Chapter 15)
A good introduction to HMMs is Rabiner’s tutorial (Rabiner, 1989). 
Kalman filters
The very well-known Kalman filters (Kalman, 1960) are another specialization of Baye-
sian filters. 
They are defined by the following Bayesian program:
(13.9)
•
Variables are continuous.
1.
A comon example of application of HMM models is automatic speech recognition. The states are either words or phonems
and one wants to recognize the most probable sequence of states (the sentence) corresponding to the observations (the heard
frequencies).
MAXS
1
S
2
...
S
t
1
–
"
"
"
S
1
S
2
...
S
t
1
–
"
"
"
S
t
O
0
...
O
t
"
"
"
 |
(
)
P
[
]
Pr
Ds
Sp
Va
S
0 ... S
t O
0 ... O
t
,
,
,
,
,
Dc
S
0
...
S
t
O
0
...
O
t
"
"
"
"
"
(
)
P
S
0
(
)
P
O
0
S
0
 |
(
)
P
S
i
S
i
1
–
 |
(
)
P
O
i
S
i
 |
(
)
P
×
[
]
i
1
=
t
&
×
×
=
Fo
S
0
(
)
P
G S
0 µ -
,
,
(
)
,
S
i
S
i
1
–
 |
(
)
P
G S
i A
S
i
1
–
•
Q
,
,
(
)
,
O
i
S
i
 |
(
)
P
G O
i H
S
i
•
R
,
,
(
)
,
)
*
*
*
*
*
*
*
*
*
*
*
+
*
*
*
*
*
*
*
*
*
*
*
,
Id
)
*
*
*
*
*
*
*
*
*
*
*
*
*
+
*
*
*
*
*
*
*
*
*
*
*
*
*
,
Qu
S
t
O
0
...
O
t
"
"
 |
(
)
P
)
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
+
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
,

Bayesian Programming
Page 144
•
The transition model 
 and the observation model 
 are both
specified using Gaussian laws with means that are linear functions of the condi-
tioning variables.
With these hypotheses, and using the recursive formula (13.4), it is possible to solve
the inference problem analytically to answer the usual 
 question.
This leads to an extremely efficient algorithm, which explains the popularity of Kalman
filters and the number of their everyday applications.1
When there are no obvious linear transition and observation models, it is still often
possible, using a first-order Taylor’s expansion, to treat these models as locally linear.
This generalization is commonly called extended Kalman filters.
A good tutorial by Welch and Bishop may be found on the Web (Welch & Bishop,
1997). For a more complete mathematical presentation, one should refer to a report by
Barker et al. (Barker, Brown & Martin, 1994), but these are only two sources from the vast
literature on this subject.
Particle filters
The fashionable particle filters may also be seen as a specific implementation of Baye-
sian filters. 
The distribution 
 is approximated by a set of N particles
having weights proportional to their probabilities. The recursive equation (13.4) is then
used 
to 
inspire 
a 
dynamic 
process 
that 
produces 
an 
approximation 
of
. The principle of this dynamic process is that the particles are first
moved according to the transition model 
, then their weights are updated
according to the observation model 
.
Arulampalam’s tutorial gives a good overview of this (Arulampalam et al., 2001).
13.1.3
Mixture models
Mixture models try to approximate a distribution on a set of variables 
 by
adding up (mixing) a set of simple distributions. 
1.
A very popular application of Kalman filter is the GPS (Global Positionning System). The recursive evaluation of the posi-
tion explains why the precision is poor when you turn on your GPS and improves rapidely after a while. The dynamic model
takes into account the previous position and speed to predict the future position (equation 13.6), when the observation model
confirms (or invalidates) this position knowing the signal coming from the satelites (equation 13.7).
S
i
S
i
1
–
 |
(
)
P
O
i
S
i
 |
(
)
P
S
t
O
0
...
O
t
"
"
 |
(
)
P
S
t
1
–
O
0
...
O
t
1
–
"
"
 |
(
)
P
S
t
O
0
...
O
t
"
"
 |
(
)
P
S
t
S
t
1
–
 |
(
)
P
O
t
S
t
 |
(
)
P
X1 ... XN
,
,
{
}

Bayesian Models Revisited
Page 145
The most popular mixture models are Gaussian mixtures where the component distri-
butions are Gaussian. However, the component distributions may be of any nature, for
instance logistic or Poisson distributions. In the sequel, for simplicity, we will consider
only Gaussian mixtures.
Such a mixture is usually defined as follows:
(13.10)
It should be noticed that this is not a valid Bayesian program. In particular, the
decomposition does not have the right form:
 
 
(13.11)
It is, however, a very popular and convenient way to specify distributions
, 
especially 
when 
the 
types 
of 
the 
component 
distributions
 are chosen to ensure efficient analytical solutions to some of the
inference problems. 
Furthermore, it is possible to specify such a mixture as a correct Bayesian program by
adding one model selection variable 
 to the previous definition: 
Pr
Ds
Sp
Va
X1 ... XN
,
,
Dc
X1
...
XN
"
"
(
)
P
)i
P X1
...
XN
"
"
+i
 |
(
)
×
[
]
i
1
=
M
!
=
Fo
P X1
...
XN
"
"
+i
 |
(
)
G X1
...
XN
"
"
µi -i
,
,
(
)
,
)
*
*
*
*
*
*
*
*
+
*
*
*
*
*
*
*
*
,
Id
)
*
*
*
*
*
*
*
*
*
*
+
*
*
*
*
*
*
*
*
*
*
,
Qu
)
*
*
*
*
*
*
*
*
*
*
*
*
+
*
*
*
*
*
*
*
*
*
*
*
*
,
X1
...
XN
"
"
(
)
P
L
1
.
+
"
 |
(
)
P
L
i
R
i
.
+
"
"
 |
(
)
P
i
2
=
M
&
×
=
X1
...
XN
"
"
(
)
P
P X1
...
XN
"
"
+i
 |
(
)
H

Bayesian Programming
Page 146
(13.12)
•
 is a discrete variable, taking 
 values. 
 is used as a selection variable. Know-
ing the value of 
, we suppose that the joint distribution is reduced to one of its
component distributions:
 
(13.13)
•
In these simple and common mixture models, 
, the mixing variable is assumed
to be independent of the other variables. We saw in Chapter 9 a discussion of more
elaborate mixing models where 
 depends on some of the other variables. This is
also the case in expert mixture models, as described by Jordan (see Jordan &
Jacobs, 1994 and Meila & Jordan, 1996)
•
Identification is a crucial step for these models, when the values of 
 and
the parameters 
 of the component distributions are searched to
find the best possible fit between the observed data and the joint distribution. This
is usually done using the EM algorithm or some of its variants (see Chapter 15).
•
The questions asked of the joint distribution are of the form 
Pr
Ds
Sp
Va
X1 ... XN H
,
,
,
Dc
X1
...
XN
H
"
"
"
+
 |
(
)
P
H
+
 |
(
)
P
X1
...
XN
"
"
H
+
"
 |
(
)
P
×
=
Fo
H
+
 |
(
)
P
Table
,
X1
...
XN
"
"
H
i
=
[
]
+
"
 |
(
)
P
P X1
...
XN
"
"
+i
 |
(
)
G X1
...
XN
"
"
µi -i
,
,
(
)
=
=
)
*
*
*
*
*
*
*
*
*
+
*
*
*
*
*
*
*
*
*
,
Id
H
+
 |
(
)
P
)
*
*
*
*
*
*
*
*
*
*
*
*
+
*
*
*
*
*
*
*
*
*
*
*
*
,
Qu
Searched
known
 |
(
)
P
X1
...
XN
H
"
"
"
(
)
P
H!
=
H
i
=
[
]
+
 |
(
)
P
P X1
...
XN
"
"
+i
 |
(
)
×
[
]
i
1
=
M
!
=
)
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
+
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
,
H
M
H
H
X1
...
XN
"
"
H
i
=
[
]
+
"
 |
(
)
P
P X1
...
XN
"
"
+i
 |
(
)
=
H
H
H
+
 |
(
)
P
µ1 ... µM -1 ... -M
,
,
,
,
,
Searched
known
 |
(
)
P

Bayesian Models Revisited
Page 147
where 
 and 
 are conjunctions of some of the 
. The
parameters 
 of the component distributions are known,
but the selection variable 
 is unknown, as it always stays hidden. Consequently,
solving the question assumes a summation for the possible value of 
, and we
finally retrieve the usual mixture form:
(13.14)
A reference on mixture models is McLachlan’s book Finite Mixture Models
(McLachlan & Deep, 2000). 
13.1.4
Maximum entropy approaches 
Maximum entropy approaches play a very important role in physical applications. The
late E.T. Jaynes, in his regrettably unfinished book (Jaynes, 2003), gives a wonderful pre-
sentation of them as well as a fascinating apologia for the subjectivist epistemology of
probabilities.
The maximum entropy models may be described by the following Bayesian program:
Searched
Known
X1 ... XN
,
,
µ1
...
µM
-1
...
-M
"
"
"
"
"
H
H
Searched
known
 |
(
)
P
H
i
=
[
]
+
 |
(
)
P
P X1
...
XN
"
"
+i
 |
(
)
×
[
]
i
1
=
M
!
=

Bayesian Programming
Page 148
(13.15)
•
The variables 
 are not constrained.
•
The decomposition is made of a product of exponential distributions
 where each 
 is called an observable function. An observable
function may be any real function on the space defined by 
, such that
its expectation may be computed:
 
(13.16)
•
The constraints on the problem are usually expressed by 
 real values 
 called
levels of constraint, which impose the condition 
.
These levels of constraint may either be arbitrary values fixed a priori by the pro-
grammer, or the results of experimental observation. In this latter case, the levels of
constraint are equal to the observed mean values of the observable functions on the
data set. The constraint then imposed on the distribution is that the expectations of
the observable functions according to the distribution should be equal to the means
of these observable functions.
Pr
Ds
Sp
Va
X1 ... XN
,
,
Dc
X1
...
XN
"
"
(
)
P
e
7i
fi
×
X1
...
XN
"
"
(
)
[
]
–
[
]
i
0
=
M
&
=
e
7i
fi
×
X1
...
XN
"
"
(
)
[
]
i
0
=
M
!
–
=
Fo
f0
1
=
f1 ... fM  M observable functions
,
,
)
*
*
*
*
*
*
*
*
*
*
+
*
*
*
*
*
*
*
*
*
*
,
Id
71 ... 7M
,
,
{
}
)
*
*
*
*
*
*
*
*
*
*
*
*
*
+
*
*
*
*
*
*
*
*
*
*
*
*
*
,
Qu
Searched
Known
 |
(
)
P
)
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
+
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
,
X1 ... XN
,
,
e
7i
fi
×
X1
...
XN
"
"
(
)
[
]
–
fi
X1
...
XN
"
"
fi X1
...
XN
"
"
(
)
0
1
X1
...
XN
"
"
(
)
P
fi X1
...
XN
"
"
(
)
×
[
]
X1
...
XN
"
"
!
=
M
Fi
fi X1
...
XN
"
"
(
)
0
1
Fi
=

Bayesian Models Revisited
Page 149
•
The identification problem is, then, knowing the level of constraint 
, to find the
Lagrange multipliers 
 that maximize the entropy of the distribution
.
The maximum entropy approach is a very general and powerful way to represent
probabilistic models and to explain what is going on when one wants to identify the
parameters of a distribution, choose its form, or even compare models. Unfortunately,
finding the values of the Lagrange multipliers 
 can be very difficult.
A sound introduction is of course Jaynes’ book Probability Theory - The Logic of
Science (Jaynes, 2003). Other references are the edited proceedings of the regular MaxEnt
conferences, which cover both theory and applications (see  Levine & Tribus, 1979; Erickson
& Smith, 1988a; Erickson & Smith, 1988b; Kapur & Kesavan, 1992; Smith & Grandy, 1985;
Mohammad-Djafari & Demoment, 1992 and Mohammad-Djafari, 2000).
13.2
Problem-oriented probabilistic models
13.2.1
Sensor fusion 
Sensor fusion is a very common and crucial problem for both living systems and artifacts.
The problem is as follows: given a phenomenon and some sensors, how can we derive
information on the phenomenon by combining the information from the different sen-
sors?
The most common and simple Bayesian modeling for sensor fusion is the following:
Fi
7i
X1
...
XN
"
"
(
)
P
7i

Bayesian Programming
Page 150
(13.17)
•
 is the variable used to describe the phenomenon, when 
 are the vari-
ables encoding the readings of the sensors.
•
The decomposition:
 
 
(13.18)
may seem peculiar, as the readings of the different sensors are obviously not inde-
pendent from one another. The exact meaning of this equation is that the phenome-
non 
 is considered to be the main reason for the contingency of the readings.
Consequently, it is stated that knowing 
, the readings 
 are independent. 
 is the
cause of the readings and, knowing the cause, the consequences are independent.
Indeed, this is a very strong hypothesis, far from always being satisfied. However, it
very often gives satisfactory results and has the main advantage of considerably
reducing the complexity of the computation.
•
The distributions 
 are called sensor models. Indeed, these distributions
encode the way a given sensor responds to the observed phenomenon. When deal-
ing with industrial sensors, this is the kind of information directly provided by the
Pr
Ds
Sp
Va
3 S1 ... SN
,
,
,
Dc
3
S1
...
SN
"
"
"
(
)
P
3
(
)
P
Si
3
 |
(
)
P
i
1
=
N
&
×
=
Fo
Any
)
*
*
*
*
*
*
*
+
*
*
*
*
*
*
*
,
Id
)
*
*
*
*
*
*
*
*
*
+
*
*
*
*
*
*
*
*
*
,
Qu
3
S1
...
SN
"
"
 |
(
)
P
1
Z
---
3
(
)
P
Si
3
 |
(
)
P
i
1
=
N
&
×
×
=
Searched
Known
 |
(
)
P
)
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
+
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
,
3
S1 ... SN
,
,
{
}
3
S1
...
SN
"
"
"
(
)
P
3
(
)
P
Si
3
 |
(
)
P
i
1
=
N
&
×
=
3
3
Si
3
Si
3
 |
(
)
P

Bayesian Models Revisited
Page 151
device manufacturer. However, these distributions may also be identified very eas-
ily by experiment. 
•
The most common question asked of this fusion model is 
. It
should be noticed that this is an inverse question. The capacity to answer such
inverse questions easily is one of the main advantages of probabilistic mode
ling. This is not the only possible question: any question may be asked of this kind
of model, and the decomposition generally leads to tractable computations. For
instance:
°
  makes the fusion of two
single sensors. It simplifies neatly as the product of the two corresponding sen-
sor models.
°
 tries to
measure the coherence between the readings of three sensors and may be used
to diagnose the failure of the kth sensor.
13.2.2
Classification
The classification problem may be seen as the same as the sensor fusion problem just
described. Usually, the problem is called a classification problem when the possible value
for 
 is limited to a small number of classes and it is called a sensor fusion problem
when 
 can be interpreted as a "measure".
A slightly more subtle definition of classification uses one more variable. In this
model, not only is there the variable 
, used to merge the information, but there is 
,
used to classify the situation. 
 has far less values than 
 and it is possible to specify
, which, for each class makes the possible values of 
 explicit. Answering the
classification question 
 supposes a summation over the different val-
ues of 
.
The Bayesian program then obtained is as follows:
3
S1
...
SN
"
"
 |
(
)
P
3
Si
Sj
"
 |
(
)
P
1
Z---
3
(
)
P
Si
3
 |
(
)
P
Sj
3
 |
(
)
P
×
×
×
=
Sk
3
Si
Sj
"
"
 |
(
)
P
1
Z---
3
(
)
P
Si
3
 |
(
)
P
Sj
3
 |
(
)
P
Sk
3
 |
(
)
P
×
×
×
×
=
3
3
3
C
C
3
3
C
 |
(
)
P
3
C
S1
...
SN
"
"
 |
(
)
P
3

Bayesian Programming
Page 152
(13.19)
13.2.3
Pattern recognition
Pattern recognition is another form of the same problem as the two preceding ones. How-
ever, it is called recognition because the emphasis is put on deciding a given value for 
rather than finding the distribution 
.
Consequently, the pattern recognition community usually does not make a clear sepa-
ration between the probabilistic inference part of the reasoning and the decision part,
using a utility function. Both are considered as a single and integrated decision process.
The best reference work on pattern recognition is still Duda’s book Pattern Classifica-
tion and Scene Analysis (Duda & Hart, 1973).
13.2.4
Sequence recognition
The problem is to recognize a sequence of states knowing a sequence of observations
and, possibly, a final state.
In Section 13.1.2 we presented Hidden Markov Models (HMMs) as a special case of
Bayesian filters. These HMMs have been specially designed for sequence recognition,
which 
is 
why 
the 
most 
common 
question 
asked 
of 
these 
models 
is
 (see Equation 13.8). That is also why the Vit-
Pr
Ds
Sp
Va
C 3 S1 ... SN
,
,
,
,
Dc
C
3
S1
...
SN
"
"
"
"
(
)
P
C
(
)
P
3
C
 |
(
)
P
×
Si
3
 |
(
)
P
i
1
=
N
&
×
=
Fo
Any
)
*
*
*
*
*
*
*
+
*
*
*
*
*
*
*
,
Id
)
*
*
*
*
*
*
*
*
*
+
*
*
*
*
*
*
*
*
*
,
Qu
C
S1
...
SN
"
"
 |
(
)
P
1
Z---
C
( )
P
3
C
 |
(
)
P
×
Si
3
 |
(
)
P
i
1
=
N
&
×
3!
×
=
)
*
*
*
*
*
*
*
*
*
*
*
*
*
*
+
*
*
*
*
*
*
*
*
*
*
*
*
*
*
,
C
C
S1
...
SN
"
"
 |
(
)
P
S
1
S
2
...
S
t
1
–
"
"
"
S
t
O
0
...
O
t
"
"
"
 |
(
)
P

Bayesian Models Revisited
Page 153
erbi algorithm, a specialized inference algorithm, has been conceived to answer this spe-
cific question (see Chapter 14).
13.2.5
Markov localization 
Another possible variation of the Bayesian filter formalism is to add a control variable 
to the system. This extension is sometimes called an input-output HMM (Bengio & Fras-
coni, 1995, Cacciatore & Nowlan, 1994, Ghahramani, 2001, Meila & Jordan, 1996). How-
ever, in the field of robotics, it has received more attention under the name of Markov
localization (Burgard et al., 1996, Thrun, Burgard & Fox, 1998). In this field, such an exten-
sion is natural, as the robot can observe its state by sensors, but can also influence its
state via motor commands. 
Starting from a Bayesian filter structure, the control variable is used to refine the tran-
sition model 
 of the Bayesian filter into 
, which is then
called the action model. The rest of the Bayesian filter is unchanged. The Bayesian pro-
gram then obtained is as follows:
(13.20)
The 
resulting 
model 
is 
used 
to 
answer 
the 
question
, which estimates the state of the robot, given past
actions and observations. When this state represents the position of the robot in its envi-
A
S
i
S
i
1
–
 |
(
)
P
S
i
S
i
1
–
A
i
1
–
"
 |
(
)
P
Pr
Ds
Sp
Va
S
0 ... S
t A
0 ... A
t
1
–
O
0 ... O
t
,
,
,
,
,
,
,
,
Dc
S
0
...
S
t
A
0
...
A
t
1
–
"
"
"
"
"
(
)
P
S
0
(
)
P
O
0
S
0
 |
(
)
P
×
A
i
1
–
(
)
P
S
i
S
i
1
–
A
i
1
–
"
 |
(
)
P
O
i
S
i
 |
(
)
P
×
×
[
]
i
1
=
t
&
×
=
Fo
Tables
)
*
*
*
*
*
*
*
*
*
+
*
*
*
*
*
*
*
*
*
,
Id
)
*
*
*
*
*
*
*
*
*
*
*
+
*
*
*
*
*
*
*
*
*
*
*
,
Qu
S
t
A
0
...
A
t
1
–
O
0
...
O
t
"
"
"
"
"
 |
(
)
P
1
Z---
A
t
1
–
(
)
P
×
O
t
S
t
 |
(
)
P
×
S
t
S
t
1
–
A
t
1
–
"
 |
(
)
P
S
t
1
–
A
0
...
A
t
2
–
O
0
...
O
t
1
–
"
"
"
"
"
 |
(
)
P
×
[
]
S
t
1
–!
×
=
)
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
+
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
,
S
t
A
0
...
A
t
1
–
O
0
...
O
t
"
"
"
"
"
 |
(
)
P

Bayesian Programming
Page 154
ronment, this amounts to localization. 
A reference for Markov localization and its use in robotics is Thrun’s survey Probabi-
listic Algorithms in Robotics (Thrun, 2000).
13.2.6
Markov decision processes
Partially observable Markov decision processes (POMDPs)
POMDPs are used to model a robot that must plan and execute a sequence of actions.
Formally, POMDPs use the same probabilistic model as Markov localization except
that they are enriched by the definition of a reward (and/or cost) function. 
This reward function 
 models those states that are good for the robot, and which
actions are costly. In the most general notation, it is therefore a function that associates,
for each state-action couple a real-valued number: 
. 
The reward function also helps to drivr the planning process. Indeed, the aim of this
process is to find an optimal plan in the sense that it maximizes a certain measure based
on the reward function. This measure is most frequently the expected discounted cumula-
tive reward:
 
(13.21)
where  is a discount factor (less than 1), 
 is the reward obtained at time t, and 
is the mathematical expectation. Given this measure, the goal of the planning process is
to find an optimal mapping from probability distributions over states to actions (a policy).
This planning process, which leads to intractable computation, is sometimes approxi-
mated using iterative algorithms called policy iteration or value iteration. These algo-
rithms start with random policies, and improve them at each step until some numerical
convergence criterion is met. Unfortunately, state-of-the-art implementations of these
algorithms still cannot cope with state spaces of more than 100 states (Pineau & Thrun,
2002).
An introduction to POMDPs is provided by Kaelbling et al. (Kaelbling, Littman & Cas-
sandra, 1998).
R
R S
i
A
i
"
8
#
,
9
t
R
t
×
t
0
=
:
!
0
1
9
R
t
.0 1

Bayesian Models Revisited
Page 155
Markov decision process
Another approach for tackling the intractability of the planning problem in POMDPs is to
suppose that the robot knows what state it is in. The state becomes observable, therefore
the observation variable and model are no longer needed; the resulting formalism is
called a (fully observable) MDP, and is summarized by the following Bayesian program:
(13.22)
•
The variables are: 
 a temporal sequence of states and 
 a
temporal sequence of actions.
•
The decomposition makes a first-order Markov assumption by specifying that the
state at time t depends on the state at time t - 1 and also on the action taken at time
t - 1.
•
 is usually represented by a matrix and is called the "transition
matrix" of the model.
•
The question addressed to the MDP is:
Pr
Ds
Sp
Va
S
0 ... S
t A
0 ... A
t
1
–
,
,
,
,
,
Dc
S
0
...
S
t
A
0
...
A
t
1
–
"
"
"
"
"
(
)
P
S
0
(
)
P
A
i
1
–
(
)
P
S
i
S
i
1
–
A
i
1
–
"
 |
(
)
P
×
[
]
i
1
=
t
&
×
=
Fo
Tables
)
*
*
*
*
*
*
*
+
*
*
*
*
*
*
*
,
Id
)
*
*
*
*
*
*
*
*
*
+
*
*
*
*
*
*
*
*
*
,
Qu
A
0
...
A
t
1
–
"
"
S
t
S
0
"
 |
(
)
P
)
*
*
*
*
*
*
*
*
*
*
*
*
+
*
*
*
*
*
*
*
*
*
*
*
*
,
S
0 ... S
t
,
,
{
}
A
0 ... A
t
1
–
,
,
{
}
S
i
S
i
1
–
A
i
1
–
"
 |
(
)
P

Bayesian Programming
Page 156
(13.23)
What is the sequence of actions required to go from state 
 to state 
?
MDPs can cope with planning in state-spaces bigger than POMDPs, but are still limited
to some hundreds of states. Therefore, recently many research efforts have been aimed
toward hierarchical decomposition of the planning and modeling problems in MDPs,
especially in robotics, where the full observability hypothesis makes their practical use
difficult (Hauskrecht et al., 1998; Lane & Kaelbling, 2001; Pineau & Thrun, 2002 & Diard,
2003).  
A complete review of POMDPs and MDPs by Boutilier et al. (Boutilier, Dean &
Hanks, 1999) is an interesting complement.
13.2.7
Bayesian models in life science
Finally, in life science and especially in neuroscience and psychology, the application of
Bayesian models is quickly becoming widespread. 
The main questions of interest are the following:
•
At the microscopic level, is there any evidence that a neuron or an assembly of
neurons may be performing Bayesian inference and learning?
•
At a macroscopic level, can we explain the results of psychophysical experiments
with Bayesian models, respecting the constraints of physiology?
There is significant literature on these subjects. The paper entitled The exploitation of
regularities in the environment by the brain (Barlow, 2001) gives an interesting historical
perspective of these questions. The following books offer an initial overview of this liter-
ature: Perception as Bayesian Inference (Knill & Richards, 1996), The Mind’s Arrows: Bayes
Nets and Graphical Causal Models in Psychology (Glymour, 2001), Graphical Models: Foun-
dations of Neural Computation (Jordan & Sejnowski, 2001), Theoretical Neuroscience
(Dayan & Abbott, 2001), Probabilistic Models of the Brain (Poincaré, H (1902) La science et
l'hypothèse; Originally published in 1902, éditions de la Bohème, Rueil-Malmaison,
FranceRao, Olshausen & Lewicki, 2002),  and Decisions, Uncertainty, and the Brain: The Sci-
ence of Neuroeconomics (Glimcher, 2003).
A
0
...
A
t
1
–
"
"
S
t
S
0
"
 |
(
)
P
S
0
S
t

Bayesian Models Revisited
Page 157
13.3
Summary
The main hierarchical relationships between these primary models are outlined in Figure
13.1 below. The more general models appear on the left, whith the more specific on the
right. An arrow connects a model to one of its specializations. 
Figure 13.1: Hierarchical interdependencies between principal Bayesian models.

Bayesian Programming
Page 158

Page 159
 14
Bayesian Inference 
Algorithms Revisited
$$$
$$$
14.1
Stating the problem
Given the joint distribution:
(14.1)
it is always possible to compute any possible question 
 using
the following general inference:
X1
X2
…
Xn
"
"
"
(
)
P
L1
(
)
P
L2
R2
 |
(
)
P
L3
R3
 |
(
)
P
×
…
×
Lk
Rk
 |
(
)
P
×
×
=
Searched
known
 |
(
)
P

Bayesian Programming
Page 160
(14.2)
where the first equality results from the marginalization rule (12.11), the second
results from the conjunction rule (12.7), and the third corresponds to a second application
of the marginalization rule. The denominator appears to be a normalization term. Conse-
quently, by convention, we will replace it with 
. Finally, it is possible to replace the
joint distribution by its decomposition (12.15).
It is well known that general Bayesian inference is a very difficult problem, which
may be practically intractable. Exact inference has been proved to be NP-hard (Cooper,
1990), as has the general problem of approximate inference (Dagum & Luby, 1993). 
Numerous heuristics and restrictions to the generality of the possible inferences have
been proposed to achieve admissible computation time. The purpose of this chapter is to
provide a short review of these heuristics and techniques.
Before starting to crunch any numbers, it is usually possible (and wise) to make some
symbolic computations to reduce the amount of numerical computation required.
The problem can be stated very simply. How can we modify the expression:
 
(14.3)
to produce a new expression requiring less computation that gives the same result or a
Free
!
Searched
Free
known
"
"
(
)
P
Free
!
known
(
)
P
--------------------------------------------------------------------------------
=
Searched
Free
known
"
"
(
)
P
Free
!
Searched
Free
known
"
"
(
)
P
Free
!
Searched
!
-------------------------------------------------------------------------------------------------------
=
1
*---
Searched
Free
known
"
"
(
)
P
Free
!
×
=
1
*---
L1
(
)
P
Li
Ri
 |
(
)
P
k
&
×
!
×
=
*
1
*---
L1
(
)
P
Li
Ri
 |
(
)
P
i
2
=
k
&
×
Free
!
×

Bayesian Inference Algorithms Revisited
Page 161
good approximation to it? 
Section 14.2 presents the different possibilities. We will see that these symbolic com-
putations can be either exact (Section 14.2.1) or approximate (Section 14.2.2), in which
case they lead to an expression that, while not mathematically equal to Equation (14.3),
should be close enough.
Once simplified, the expression obtained to compute 
 must be eval-
uated numerically.
In a few cases, exact (exhaustive) computation may be possible, thanks to the previ-
ous symbolic simplification, but normally, even with the simplifications, only approxi-
mate calculation is possible. Section 14.3 describes the main algorithms used.
Two main problems must be solved: searching the modes in a high-dimensional
space, and marginalizing in a high-dimensional space.
Because 
 may be a conjunction of numerous variables, each of them possibly
having many values or even being continuous, it is seldom possible to compute exhaus-
tively 
 and find the absolute most probable value for 
. One
may then decide either to build an approximate representation of this distribution or to
directly sample from this distribution. In both cases, the challenge is to find the modes
of:
(14.4)
(on the search space defined by 
), where most of the probability density is
concentrated. This may be very difficult, as most of the probability may be concentrated
in very small subspaces of the whole search space. Searching the modes of a distribution
in a high-dimensional space will be the subject of Section 14.3.1.
The situation is even worse, as computing the value of 
 for a
given value of 
 (a single point of the search space of the preceding paragraph) is
by itself a difficult problem. Indeed, it requires marginalizing the joint distribution on the
space defined by 
. 
 (like 
) may be a conjunction of numerous vari-
ables, each of them possibly having many values or even being continuous. Conse-
quently, the sum should also be either approximated or sampled. The challenge is then to
find the modes of
Searched
known
 |
(
)
P
Searched
Searched
known
 |
(
)
P
Searched
Searched
known
 |
(
)
P
L1
(
)
P
Li
Ri
 |
(
)
P
i
2
=
k
&
×
Free
!
0
Searched
Searched
known
 |
(
)
P
Searched
Free
Free
Searched

Bayesian Programming
Page 162
 
 
(14.5)
(on the search space defined by 
), where most of the probability density is con-
centrated and which mostly contribute to the sum. Finally, marginalizing in a high-
dimensional space appears to be a very similar problem to searching the modes in a high
-dimensional space. This appears clearly in Section 14.3.2, which briefly deals with mar-
ginalization.
14.2
Symbolic computation
In this section, we give an overview of the principal techniques to simplify the calcula-
tion needed either to evaluate 
, or to find the most probable value
for 
, or to draw values for 
 according to this distribution.
The goal is to perform symbolic computation on the expression
(14.6)
to obtain another expression to compute the same result with far fewer elementary
operations (sum and product). It is called symbolic computation because this can be done
independently of the possible numerical values of the considered variables.
We will present these different algorithms as pure and simple algebraic manipulations
of Expression (14.6) above, even if most of them have been historically proposed from
different points of view (especially in the form of manipulation of graphs and message
passing along their arcs).
14.2.1
Exact symbolic computation
We first restrict our analysis to mathematically exact symbolic computation that lead to a
simplified expression mathematically equivalent to the starting one.
Question-specific symbolic computation
It is seldom possible to solve analytically the question  
. Most of
the time, the integral in Expression (14.6) has no explicit solution.
However, this is possible for Kalman filters as defined by the Bayesian program
L1
(
)
P
Li
Ri
 |
(
)
P
i
2
=
k
&
×
Free
Searched
known
 |
(
)
P
Searched
Searched
1
*---
L1
(
)
P
Li
Ri
 |
(
)
P
i
2
=
k
&
×
Free
!
×
Searched
known
 |
(
)
P

Bayesian Inference Algorithms Revisited
Page 163
(13.9). This explains their popularity and their importance in applications. Indeed, once
analytically solved, the answer to the question may be computed very efficiently.
Question-dependent symbolic computation
We first take an example to introduce the different possible simplifications.
This example is defined by the following decomposition (14.7) of a joint distribution
of nine variables:
(14.7)
corresponding to the Bayesian net defined in Figure 14.1:
Take, 
for 
instance, 
the 
question 
 
where 
,
, and 
. We know that:
Figure 14.1: The Bayesian network corresponding to the joint distribution in (14.7).
X1
X2
…
X9
"
"
"
(
)
P
X1
(
)
P
X2
X1
 |
(
)
P
X3
X1
 |
(
)
P
X4
X2
 |
(
)
P
X5
X2
 |
(
)
P
×
×
×
×
=
.
X6
X3
 |
(
)
P
X7
X3
 |
(
)
P
X8
X6
 |
(
)
P
X9
X6
 |
(
)
P
×
×
×
×
X1
x5
x7
"
 |
(
)
P
Searched
X
=
1
known
x5
x7
"
=
Free
X2
X3
X4
X6
X8
X9
"
"
"
"
"
=

Bayesian Programming
Page 164
(14.8)
If each of the variables 
 may take 10 different possible values, then evaluating
Expression (14.8) for a given value of  
 requires 
 elementary operations.
To reduce this number, we can first reorder the different summations the following
way:
(14.9)
and we see that 
 vanishes as it sums to one. We obtain:
(14.10)
This same simplification can also be applied to the sums on 
, 
, and 
 to yield:
(14.11)
Evaluating Expression (14.11) requires 
 elementary operations. Eliminating
the parts of the global sum that sum to one is indeed a very efficient simplification.
However, rearranging further the order of the sums in (14.11) may lead to more gains.
First, 
 may be factorized out of the sum:
X1
x5
x7
"
 |
(
)
P
X1
(
)
P
X2
X1
 |
(
)
P
X3
X1
 |
(
)
P
X4
X2
 |
(
)
P
x5
X2
 |
(
)
P
×
×
×
×
.
X6
X3
 |
(
)
P
x7
X3
 |
(
)
P
X8
X6
 |
(
)
P
X9
X6
 |
(
)
P
×
×
×
×
X2
X3
X4
"
"
X6
X8
X9
"
"
!
=
Xi
X1
9
10
6
×
X1
x5
x7
"
 |
(
)
P
X1
(
)
P
X2
X1
 |
(
)
P
X3
X1
 |
(
)
P
x5
X2
 |
(
)
P
x7
X3
 |
(
)
P
×
×
×
×
X4
X2
 |
(
)
P
X6
X3
 |
(
)
P
X8
X6
 |
(
)
P
X9
X6
 |
(
)
P
[
]
X9
!
×
X8
!
×
X6
!
×
X4
!
X2
X3
"!
=
X9
X6
 |
(
)
P
[
]
X9
!
X1
x5
x7
"
 |
(
)
P
X1
(
)
P
X2
X1
 |
(
)
P
X3
X1
 |
(
)
P
x5
X2
 |
(
)
P
x7
X3
 |
(
)
P
×
×
×
×
X4
X2
 |
(
)
P
X6
X3
 |
(
)
P
X8
X6
 |
(
)
P
[
]
X8
!
×
X6
!
×
X4
!
X2
X3
"!
=
X8
X6
X4
X1
X5
X7
"
 |
(
)
P
X1
(
)
P
X2
X1
 |
(
)
P
X3
X1
 |
(
)
P
x5
X2
 |
(
)
P
x7
X3
 |
(
)
P
×
×
×
×
[
]
X2
X3
"!
=
5
10
2
×
X1
(
)
P

Bayesian Inference Algorithms Revisited
Page 165
(14.12)
Then, the sum on 
 and 
 can be split, leading to:
(14.13)
and as 
 is only a function of 
, it can be factored out
of the sum on 
, to finally have:
(14.14)
Evaluating Expression (14.14) requires 
 elementary operations, five
orders of magnitude less than that required for the initial expression to perform the exact
same calculation!
Other questions lead to similar symbolic simplifications. For instance, for the question
, we have:
(14.15)
which can be simplified into:
X1
x5
x7
"
 |
(
)
P
X1
(
)
P
X2
X1
 |
(
)
P
X3
X1
 |
(
)
P
x5
X2
 |
(
)
P
x7
X3
 |
(
)
P
×
×
×
[
]
X2
X3
"!
×
=
X2
X3
X1
x5
x7
"
 |
(
)
P
X1
(
)
P
X2
X1
 |
(
)
P
x5
X2
 |
(
)
P
X3
X1
 |
(
)
P
x7
X3
 |
(
)
P
×
[
]
X3
!
×
×
X2
!
×
=
X3
X1
 |
(
)
P
x7
X3
 |
(
)
P
×
[
]
X3
!
X1
X2
X1
x5
x7
"
 |
(
)
P
X1
(
)
P
X3
X1
 |
(
)
P
x7
X3
 |
(
)
P
×
[
]
X3
!
X2
X1
 |
(
)
P
x5
X2
 |
(
)
P
×
[
]
X2
!
×
×
=
19
19
2
+
+
40
=
X2
x5
x7
"
 |
(
)
P
X2
x5
x7
"
 |
(
)
P
X1
(
)
P
X2
X1
 |
(
)
P
X3
X1
 |
(
)
P
X4
X2
 |
(
)
P
x5
X2
 |
(
)
P
×
×
×
×
.
X6
X3
 |
(
)
P
x7
X3
 |
(
)
P
X8
X6
 |
(
)
P
X9
X6
 |
(
)
P
×
×
×
×
X1
X3
X4
"
"
X6
X8
X9
"
"
!
=

Bayesian Programming
Page 166
(14.16)
However, the final simplification step is not similar to the simplification of
 because 
 depends on 
 and consequently
cannot be factored out of the sum on 
.
Evaluating expression (14.16) requires 
 elementary opera-
tions, compared with the 
 necessary for Expression (14.15).
To perform these symbolic simplifications, it is only necessary to apply two fundamental
rules: the distributive law and the normalization rule (12.9).
Simplification of
 
(14.17)
may be done in three steps:
1. Eliminate distributions that sum to one: When a term 
 appears in the sum,
if all the variables appearing in 
 are summed and none of them appears in any of
the other 
, then 
 sums to one and vanishes out of the global sum. Of
course, the list of summed variables, initialized to 
, must then be updated by
removing the variables of 
. This process can be recursively applied until no
more terms of the product can be removed. It leads to an expression of the form:
(14.18)
where 
. An example of this was given in Equations (14.9) and
(14.10).
2. Factorize: Each term of the remaining product 
, where all the vari-
X2
x5
x7
"
 |
(
)
P
x5
X2
 |
(
)
P
X1
(
)
P
X2
X1
 |
(
)
P
×
X3
X1
 |
(
)
P
x7
X3
 |
(
)
P
×
[
]
X3
!
×
X1
!
×
=
X1
x5
x7
"
 |
(
)
P
X3
X1
 |
(
)
P
x7
X3
 |
(
)
P
×
[
]
X3
!
X1
X1
21
10
×
(
)
9
1
+
+
220
=
9
10
6
×
Searched
known
 |
(
)
P
1
*---
L1
(
)
P
Li
Ri
 |
(
)
P
i
2
=
k
&
×
Free
!
×
=
Li
Ri
 |
(
)
P
Li
Rj
Li
Ri
 |
(
)
P
Free
Li
Searched
known
 |
(
)
P
1
*---
Lj
Rj
 |
(
)
P
j&
Summed
!
×
=
Summed
Free
;
Lj
Rj
 |
(
)
P
j&

Bayesian Inference Algorithms Revisited
Page 167
ables are either 
 or 
 is independent of the variables appearing in
, and consequently it can be factored out of the sum. We then obtain a
new expression of the form:
(14.19)
An example of this factorization was given in Equation (14.12).
3. Order the sums cleverly: Finally, the last type of simplification that can be made is
to reorder the sums of 
, to minimize the number of operations
required. This third step is much more complicated than the two previous ones:
finding the optimal ordering is indeed NP-hard (Arnborg et al. 87). Only heuristics
can be proposed but they are useful even if they do not find the optimal ordering.
Any ordering helps to break the exponential complexity of the computation of the
sum.
Numerous algorithms have been proposed to deal with these simplifications. Among the
most interesting or most well known are the SPI1 algorithm (Shachter, D’Ambrosio & Del
Favero, 1990; Li & D’Ambrosio, 1994), the variable elimination family (Zhang & Poole,
1994; Zhang & Poole, 1996), the bucket elimination family of algorithms (Dechter, 1996,
Dechter & Rish, 1997), the Query-DAG framework (Darwiche & Provan, 1997), the general
distributive law algorithm (Aji & McEliece, 2000) and the SRA2 algorithm
($$$Mekhnacha2005$$$).
Question-independent symbolic computation
Instead of trying to simplify only:
(14.20)
we can try to simplify a family of such questions.
1.
Symbolic Probabilistic Inference
2.
Successive Restriction Algorithm
Searched
Known
Summed
Searched
known
 |
(
)
P
1
*---
Lk
Rk
 |
(
)
P
k&
Ll
Rl
 |
(
)
P
l&
Summed
!
×
×
=
Ll
Rl
 |
(
)
P
l&
Summed
!
Searched
known
 |
(
)
P
1
*---
L1
(
)
P
Li
Ri
 |
(
)
P
i
2
=
k
&
×
Free
!
×
=

Bayesian Programming
Page 168
For instance, in Bayesian nets, where all the 
 of the decomposition are restricted to
a single variable (13.1) it may be interesting to apply symbolic computation to minimize
globally the number of numerical operations required for the family of questions:
(14.21)
Each of these questions is called a belief. The given value of 
 is called the evi-
dence.
We return to the example of the previous section. The family of interesting questions
is:
(14.22)
Using the simplification scheme of the previous section for each of these seven ques-
tions, we obtain:
Li
X1
known
 |
(
)
P
X2
known
 |
(
)
P
...
XN
known
 |
(
)
P
)
-
*
*
*
*
*
*
*
*
+
.
*
*
*
*
*
*
*
*
,
/
known
X1
x5
x7
"
 |
(
)
P
X2
x5
x7
"
 |
(
)
P
X3
x5
x7
"
 |
(
)
P
X4
x5
x7
"
 |
(
)
P
X6
x5
x7
"
 |
(
)
P
X8
x5
x7
"
 |
(
)
P
X9
x5
x7
"
 |
(
)
P
)
-
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
+
.
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
,
/

Bayesian Inference Algorithms Revisited
Page 169
(14.23)
(14.24)
(14.25)
(14.26)
(14.27)
(14.28)
(14.29)
X1
x5
x7
"
 |
(
)
P
X1
(
)
P
X3
X1
 |
(
)
P
x7
X3
 |
(
)
P
×
[
]
X3
!
X2
X1
 |
(
)
P
x5
X2
 |
(
)
P
×
[
]
X2
!
×
×
=
X2
x5
x7
"
 |
(
)
P
x5
X2
 |
(
)
P
X1
(
)
P
X2
X1
 |
(
)
P
×
X3
X1
 |
(
)
P
x7
X3
 |
(
)
P
×
[
]
X3
!
×
X1
!
×
=
X3
x5
x7
"
 |
(
)
P
x7
X3
 |
(
)
P
X1
(
)
P
X3
X1
 |
(
)
P
X2
X1
 |
(
)
P
x5
X2
 |
(
)
P
×
[
]
X2
!
×
×
X1
!
×
=
X4
x5
x7
"
 |
(
)
P
X4
X2
 |
(
)
P
.
x5
X2
 |
(
)
P
X1
(
)
P
X2
X1
 |
(
)
P
×
X3
X1
 |
(
)
P
x7
X3
 |
(
)
P
×
[
]
X3
!
×
X1
!
×
×
X2
!
=
X6
x5
x7
"
 |
(
)
P
X6
X3
 |
(
)
P
.
x7
X3
 |
(
)
P
X1
(
)
P
X3
X1
 |
(
)
P
X2
X1
 |
(
)
P
x5
X2
 |
(
)
P
×
[
]
X2
!
×
×
X1
!
×
×
X3
!
=
X8
x5
x7
"
 |
(
)
P
X8
X6
 |
(
)
P
X6
X3
 |
(
)
P
×
.
x7
X3
 |
(
)
P
X1
(
)
P
X3
X1
 |
(
)
P
X2
X1
 |
(
)
P
x5
X2
 |
(
)
P
×
[
]
X2
!
×
×
X1
!
×
×
X6
!
=
X9
x5
x7
"
 |
(
)
P
X9
X6
 |
(
)
P
X6
X3
 |
(
)
P
×
.
x7
X3
 |
(
)
P
X1
(
)
P
X3
X1
 |
(
)
P
X2
X1
 |
(
)
P
x5
X2
 |
(
)
P
×
[
]
X2
!
×
×
X1
!
×
×
X6
!
=

Bayesian Programming
Page 170
These 7 expression shares many terms. To minimize the number of elementary numer-
ical operations, they should not be computed several times but only once. This implies an
obvious order in these computations:
•
Step 0: First, 
 and 
, which appear everywhere and can be
computed immediately.
•
Step 1: Then 
 and 
 can
be computed directly.
•
Step 2: In the third step, the first belief 
 can be evaluated:
(14.30)
•
Step 3: Then the two questions 
 and 
 can be
solved:
(14.31)
(14.32)
•
Step 4: The next two expressions 
 and 
, can be
deduced directly from the two previous ones as:
x5
X2
 |
(
)
P
x7
X3
 |
(
)
P
X2
X1
 |
(
)
P
x5
X2
 |
(
)
P
×
[
]
X2
!
X3
X1
 |
(
)
P
x7
X3
 |
(
)
P
×
[
]
X3
!
X1
x5
x7
"
 |
(
)
P
X1
x5
x7
"
 |
(
)
P
X1
(
)
P
X3
X1
 |
(
)
P
x7
X3
 |
(
)
P
×
[
]
X3
!
X2
X1
 |
(
)
P
x5
X2
 |
(
)
P
×
[
]
X2
!
×
×
=
X2
x5
x7
"
 |
(
)
P
X3
x5
x7
"
 |
(
)
P
X2
x5
x7
"
 |
(
)
P
x5
X2
 |
(
)
P
X2
X1
 |
(
)
P
X1
x5
x7
"
 |
(
)
P
X2
X1
 |
(
)
P
x5
X2
 |
(
)
P
×
[
]
X2
!
---------------------------------------------------------------------------
×
X1
!
×
=
X3
x5
x7
"
 |
(
)
P
x7
X3
 |
(
)
P
X3
X1
 |
(
)
P
X1
x5
x7
"
 |
(
)
P
X3
X1
 |
(
)
P
x7
X3
 |
(
)
P
×
[
]
X3
!
---------------------------------------------------------------------------
×
X1
!
×
=
X4
x5
x7
"
 |
(
)
P
X6
x5
x7
"
 |
(
)
P

Bayesian Inference Algorithms Revisited
Page 171
(14.33)
(14.34)
•
Step 5: Finally, the last two questions can be computed:
(14.35)
(14.36)
This order of computation may be interpreted as a message-passing algorithm in the
Bayesian net (see Figure 14.2 below). 
Figure 14.2: The order of computation described by steps 1 to 6 (above) may be interpreted as a 
message-passing algorithm in the Bayesian net.
X4
x5
x7
"
 |
(
)
P
X4
X2
 |
(
)
P
X2
x5
x7
"
 |
(
)
P
×
[
]
X2
!
=
X6
x5
x7
"
 |
(
)
P
X6
X3
 |
(
)
P
X3
x5
x7
"
 |
(
)
P
×
[
]
X3
!
=
X8
x5
x7
"
 |
(
)
P
X8
X6
 |
(
)
P
X6
x5
x7
"
 |
(
)
P
×
[
]
X6
!
=
X9
x5
x7
"
 |
(
)
P
X9
X6
 |
(
)
P
X6
x5
x7
"
 |
(
)
P
×
[
]
X6
!
=

Bayesian Programming
Page 172
This algorithm was simultaneously and independently proposed by Judea Pearl
($$$Pearl86$$$ and Pearl, 1988) under the name of Belief Propagation, and by Lauritzen
and Spiegelhalter (Spiegelhalter, 1986; Lauritzen & Spiegehalter, 1988; Lauritzen, 1996) as
the Sum-Product algorithm. 
When the graph associated with the Bayesian network has no undirected cycles1, it is
always possible to find this ordering, ensuring that each sub-expression is evaluated once
and only once. 
On the other hand, when the graph of the Bayesian net has some undirected cycles the sit-
uation is trickier and such a clever ordering of the computation may not be found.
For instance, let us modify the above example by adding a dependency between 
and 
. We then obtain the new decomposition:
(14.37)
which corresponds to the graph of Figure 14.3 below.
Applying the simplification rules to the different questions, we obtain:
1. it is either a tree or a polytree
Figure 14.3: The Bayesian network corresponding to the joint distribution in (14.37).
X2
X3
X1
X2
…
X9
"
"
"
(
)
P
X1
(
)
P
X2
X1
 |
(
)
P
X3
X2
X
"
1
 |
(
)
P
X4
X2
 |
(
)
P
X5
X2
 |
(
)
P
×
×
×
×
=
.
X6
X3
 |
(
)
P
X7
X3
 |
(
)
P
X8
X6
 |
(
)
P
X9
X6
 |
(
)
P
×
×
×
×

Bayesian Inference Algorithms Revisited
Page 173
(14.38)
(14.39)
(14.40)
The four other cases are unchanged relative to these three (see (14.33), (14.34), (14.35)
and (14.36)).
Obviously, the different elements appearing in these three expressions may not be
neatly separated as in the previous case. The conjunction of variables 
 must
be considered as a whole: they form a new variable 
. The decomposi-
tion (14.37) becomes:
(14.41)
This corresponds to the graph in Figure 14.4 below, which has a tree structure:
We have recreated the previous case, where the message-passing algorithms may be
applied. However, this has not eliminated our troubles completely, because to compute
, 
, and 
, we shall now require marginal-
ization of the distribution 
:
X1
x5
x7
"
 |
(
)
P
X1
(
)
P
X2
X1
 |
(
)
P
X3
X2
X
"
1
 |
(
)
P
x5
X2
 |
(
)
P
×
×
x7
X3
 |
(
)
P
×
[
]
X2
X3
"!
×
=
X2
x5
x7
"
 |
(
)
P
x5
X2
 |
(
)
P
X1
(
)
P
X2
X1
 |
(
)
P
X3
X2
X
"
1
 |
(
)
P
×
×
x7
X3
 |
(
)
P
×
[
]
X1
X3
"!
×
=
X3
x5
x7
"
 |
(
)
P
x7
X3
 |
(
)
P
X1
(
)
P
X2
X1
 |
(
)
P
X3
X2
X
"
1
 |
(
)
P
x5
X2
 |
(
)
P
×
×
×
[
]
X1
X2
"!
×
=
X1
X2
X3
"
"
A
X1
X2
X3
"
"
=
X1
X2
…
X9
"
"
"
(
)
P
A
( )
P
X4
A
 |
(
)
P
X5
A
 |
(
)
P
×
×
=
.
X6
A
 |
(
)
P
X7
A
 |
(
)
P
X8
X6
 |
(
)
P
X9
X6
 |
(
)
P
×
×
×
×
X1
x5
x7
"
 |
(
)
P
X2
x5
x7
"
 |
(
)
P
X3
x5
x7
"
 |
(
)
P
A
x5
x7
"
 |
(
)
P

Bayesian Programming
Page 174
(14.42)
(14.43)
(14.44)
Indeed, the computation of these sums may be very expensive. 
The junction tree algorithm, also often called JLO after its inventors (see Jensen, Lauritzen
& Olesen, 1990), searches for such a decomposition and implements the corresponding
computation to solve 
. 
The main idea of the junction tree algorithm is to convert the Bayesian network into a
tree by clustering the nodes together. After building this tree of clusters, inference can be
done efficiently by the single message-passing algorithm. 
All the details of this popular algorithm may be found in the textbooks concerning
graphical models cited previously (see Section 13.1.1) and also in Jensen’s book (Jensen,
1996). 
It is very important to note that this JLO algorithm may lead to very poor simplifica-
tion, as, in some cases, the required marginalizations may be very expensive. The cost of
these marginalizations grows exponentially with the number of variables in the conjunc-
tions being considered.
Figure 14.4: The Bayesian network resulting from the introdction of a new variable 
 in the Bayesian network shown in Figure 14.3.
A
X1
X2
X3
"
"
=
X1
x5
x7
"
 |
(
)
P
A
x5
x7
"
 |
(
)
P
X2
X3
"!
=
X2
x5
x7
"
 |
(
)
P
A
x5
x7
"
 |
(
)
P
X1
X3
"!
=
X3
x5
x7
"
 |
(
)
P
A
x5
x7
"
 |
(
)
P
X1
X2
"!
=
Xi
Known
 |
(
)
P

Bayesian Inference Algorithms Revisited
Page 175
Historically, another solution was proposed by Pearl (Pearl, 1988) to deal with graph with
undirected cycles. It is called the cut-set algorithm. The principle of the cut-set algorithm
is to break the cycles by fixing the values of some of the variables in these cycles and
computing in turn the different questions for these different possible values. 
When there are no 
 variables and if we are interested in the most probable value of
, the usual equation:
(14.45)
is transformed into:
(14.46)
The distributive law applies to the couple 
 in the same way as it applies to
the couple 
. Consequently, most of the previous simplifications are still valid
with this new couple of operator. 
The sum-product algorithm becomes the max-product algorithm, or more commonly,
the min-sum algorithm, as it may be further transformed by operating on the inverse of the
logarithm. 
It is also known as the Viterbi algorithm and it is particularly used with HMMs. to find
the most probable series of states that leads to the present state, knowing the past obser-
vations as stated in Bayesian program (13.8). In that case, we have:
(14.47)
(14.48)
(14.49)
and the question is:
Free
Searched
Searched
known
 |
(
)
P
1
*---
L1
(
)
P
Li
Ri
 |
(
)
P
i
2
=
k
&
×
Free
!
×
=
MAXSearched
Searched
known
 |
(
)
P
(
)
1
*---
MAXSearched
L1
(
)
P
Li
Ri
 |
(
)
P
i
2
=
k
&
×
×
=
MAX
.
&
,
(
)
.
!
.
&
,
(
)
Searched
S
1
S
2
...
S
t
1
–
"
"
"
=
known
s
t
o
0
...
o
t
"
"
"
=
Free
<
=

Bayesian Programming
Page 176
(14.50)
14.2.2
Approxiamate symbolic computation
Often, the exact symbolic simplification methods described previously are not sufficient.
We must then use approximate symbolic simplifications that lead to mathematical
expressions that approach the values of  
.
Variational methods
The key to variational methods is to convert a probabilistic inference problem into an
optimization problem. In this way, the standard tools of constrained optimization can be
used to solve the inference problem. The idea is to replace a joint distribution
 (represented by an acyclic graph in the case of a Bayesian net )
by an approximation 
, and to compute the Kullback-Leibler divergence between the
two distributions.
To do that, we consider the energy of a configuration 
 defined by:
(14.51)
and the variational free energy (or Kullback-Leibler distance) as:
(14.52)
This distance is minimized when  
.
Of course, minimizing 
 is as difficult as the original inference problem. However,
by considering a different family of 
, we obtain a different approximation of 
 and
as a consequence, different variational methods.
For example, if one restricts oneself to the family of factorized independent distribu-
tions:
 
 
(14.53)
the variational method boils down to the mean field approximation. Minimizing
 is greatly simplified using the acyclic graph structure of 
.
MAX
S
1
S
2
...
S
t
1
–
"
"
"
S
1
S
2
...
S
t
1
–
"
"
"
s
t
o
0
...
o
t
"
"
"
 |
(
)
P
[
]
Searched
known
 |
(
)
P
X
( )
P
X1
...
XN
"
"
(
)
P
=
Q X
( )
X
E X
( )
X
( )
P
(
)
log
–
Z
( )
log
–
=
F Q P
,
(
)
Q X
( )
Q X
( )
X
( )
P
-------------
#
$
'
(
log
×
X!
Z
( )
log
–
=
X
( )
P
Q X
( )
=
F
Q X
( )
F
Q X
( )
Qi Xi
(
)
i
1
=
N
&
=
F Q P
,
(
)
X
( )
P

Bayesian Inference Algorithms Revisited
Page 177
A general introduction to variational methods may be found in two introductory texts
by Jordan (Jordan et al., 1999; Jordan & Weiss, 2002). Interesting refinements are described
in Yedidia’s paper (Yedidia, Freeman & Weiss, 2002).
Helmotz Machine
$$$more to come$$$
14.3
Numerical computation
Once the symbolic simplifications are complete, we must finally do the numerical com-
putation of the simplified expression.
14.3.1
Searching the modes in high-dimensional spaces
The central problem to solve is to try to find the mode of the simplified expression in a
very high-dimensional space. This is indeed a classical optimization problem, where
classical optimization methods can be applied. 
However, we must choose to either sample points from the expression or to build an
explicit, even approximate representation of the distribution that can be saved in memory
and used again later.
Distribution sampling methods
Direct sampling methods
In some cases, it is possible, when disposing of a uniform random generator, to use a
transformation function to sample a given distribution 
 (see Rubinstein, 1981). 
One of the more important transformation functions is the Box-Muller transformation
(Box & Muller, 1958). This transformation allows us to generate a set of random numbers
from a one-dimensional normal distribution using another set of random numbers gener-
ated by a uniform random generator.
Sampling a multi-dimensional normal distribution 
 is also possi-
ble by diagonalizing the variance matrix 
. By diagonalization, the major axes (eigen-
vectors) obtained define a new coordinate system (in which the components are
independent). Therefore, the problem is reduced to drawing each component indepen-
dently from 
 one-dimensional normal distributions having, for each component, the
X
( )
P
X
( )
P
G X µ -
,
,
(
)
=
*
D

Bayesian Programming
Page 178
eigenvalue 
 as variance. The vector obtained, 
, is then rewrit-
ten in the original coordinate system by multiplying it by the transpose of the eigenmatrix
to obtain the sample vector 
.
When disposing (analytically or numerically) of the repartition function 
 corre-
sponding to a target distribution 
:
(14.54)
the problem of sampling 
 is reduced to the problem of inverting the repartition func-
tion 
. Drawing a sample point from 
 requires:
1. drawing a uniform random value 
;
2. calculating the drawn point as 
.
In the general case, analytical forms of the repartition function 
 and its inverse
are not available. Explicitly computing the repartition function 
 and inverting it
numerically is possible for low-dimensional spaces. It is usually impossible in practice
for high-dimensional cases.
Monte Carlo methods
Monte Carlo methods group together several different methods for sampling in high-
dimensional spaces. In this section, we present some of the most popular variants: impor-
tance sampling, rejection sampling, Metropolis sampling, and Gibbs sampling.
Two excellent starting points on Monte Carlo methods are the tutorials by Neal (Neal,
1993) and MacKay (MacKay, 1996).
Importance sampling
Suppose we are interested in sampling a distribution 
 for which no direct sampling
method is available and that we are able to evaluate this distribution for each point 
 of
the state space.
Suppose also that we have a simpler distribution 
 (called the proposal distribu-
tion) that we can also evaluate for each point 
 and for which a direct sampling method
is available.
vi
x
Diag
x1
Diag ... xD
Diag
,
,
[
]
=
x
x1 ... xD
,
,
[
]
=
F X
( )
f X
( )
F X
( )
f i( ) id
:
–
X
2
=
f X
( )
F X
( )
f X
( )
u
0 1
,
[
]
!
x
F
1
–
u
( )
=
F X
( )
F X
( )
X
( )
P
xi
Q X
( )
xi

Bayesian Inference Algorithms Revisited
Page 179
Using importance sampling to sample 
 consists of generating 
 pairs
 where the points 
 are drawn from 
 and where:
(14.55)
This sampling method is especially useful for Monte Carlo importance sampling inte-
gration method (see also Section 16.5.2).
Rejection sampling
Suppose we are interested in sampling a distribution 
 for which no direct sampling
method is available and that we are able to evaluate this distribution for each point 
 of
the state space.
 Suppose also that we have a simpler distribution 
 that we can evaluate for each
point 
, for which a direct sampling method is available, and that the distribution
respects the constraint:
(14.56)
Using rejection sampling to draw a point of 
 consists of drawing a point 
 from
 and accepting it with a probability of:
(14.57)
The complete procedure is then:
1. Draw a candidate point 
 from 
;
2. Evaluate 
;
3. Generate a uniform random value 
;
4. Either accept the point 
 if 
, or reject this point and draw another one.
It is clear that this rejection sampling will be efficient if the distribution 
 is a
X
( )
P
N
x1 11
,
(
) ...
xN 1N
,
(
)
,
,
{
}
xi
Q X
( )
1i
xi
(
)
P
Q xi
(
)
--------------
=
X
( )
P
xi
Q X
( )
xi
c
=
x
4
c
Q x
( )
×
x
( )
P
>
[
]
,
,
X
( )
P
xi
Q X
( )
c
Q xi
(
)
×
xi
(
)
P
----------------------
xi
Q X
( )
c
Q xi
(
)
×
u
0 c
Q xi
(
)
×
,
[
]
!
xi
xi
(
)
P
u
>
Q X
( )

Bayesian Programming
Page 180
good approximation of 
. Otherwise, the rejection rate will be very important.
Metropolis sampling
Previous methods using a proposal distribution perform well if 
 is a good approxi-
mation of 
. For complex problems in high-dimensional spaces, it is difficult to find
such a distribution.
The Metropolis algorithm (Metropolis et al., 1953) uses a Markovian process in which a
sequence of states 
 is generated. The new state 
 depends on the previous one 
.
This algorithm is an example of Markov Chain Monte Carlo (MCMC) methods. 
Instead of using a single proposal distribution 
, the Metropolis algorithm uses a
proposal distribution 
, which depends on the current state 
. This distribution
can be a simple distribution (a normal distribution having 
 as the mean value, for exam-
ple).
Suppose the current state is 
. A candidate 
 is generated from 
. To accept
or reject this candidate we must compute:
(14.58)
If 
 then 
 is accepted. Otherwise, it is accepted with probability a. If 
 is
accepted, we set 
. If 
 is rejected, then we set 
.
A frequent choice for the proposal distribution 
 is to choose a symmetrical
distribution (a normal distribution having 
 as the mean value, for example). Then:
 
 
(14.59)
and we obtain:
(14.60)
One drawback of MCMC techniques is that we must generally wait for the chain to
reach equilibrium. This can take a long time, and it is sometimes difficult to tell when it
happens.
X
( )
P
Q X
( )
X
( )
P
x
t
x
t
x
t
1
–
Q X
( )
Q Xi X
t
,
(
)
x
t
x
t
x
t
xi
Q Xi X
t
,
(
)
a
xi
(
)
P
Q xi x
t
,
(
)
×
x
t
(
)
P
Q x
t xi
,
(
)
×
-----------------------------------------
=
a
1
>
xi
xi
x
t
1
+
xi
=
xi
x
t
1
+
x
t
=
Q Xi X
t
,
(
)
x
t
Q xi x
t
,
(
)
Q x
t xi
,
(
)
---------------------
1
=
a
xi
(
)
P
x
t
(
)
P
-------------
=

Bayesian Inference Algorithms Revisited
Page 181
Gibbs sampling
Gibbs sampling, also known as the heatbath method, is another example of a Markov
Chain Monte Carlo sampling technique. It has come into prominence only recently with
the works of Geman and Smith (Geman & Geman, 1984 and  Smith & Roberts, 1993). It is
a method for sampling from distributions over at least two dimensions, and can be
viewed as a Metropolis method in which the proposal distribution 
 is defined in
terms of the conditional distributions of the joint distribution 
. It is assumed that
while 
 is too complex to draw samples from directly, its conditional distributions
 are tractable. 
In the general case of a system of 
 variables, a single iteration involves sampling
one variable at a time:
(14.61)
Building an explicit representation of the distribution
Representation using a sample set of points
Suppose we are interested in building an explicit representation of a given D-dimensional
distribution 
.
The simplest representation one can imagine is to encode 
 as a sample set of 
points:
(14.62)
This kind of representation, although simple, can be very useful if this distribution is
used in a sampling process directly or indirectly.
We say that 
 is used directly in a sampling process if the problem consists of
drawing a set of 
 points 
.
We say that 
 is used indirectly in a sampling process if the problem consists of
Q X
( )
X
( )
P
X
( )
P
Xi
X1
...
Xi
1
–
Xi
1
+
...
XN
"
"
"
"
"
 |
(
)
P
N
x1
t
1
+
X1
x2
t
...
xN
t
"
"
 |
(
)
P
>
x2
t
1
+
X2
x1
t
x3
t
...
xN
t
"
"
"
 |
(
)
P
>
...
xN
t
1
+
XN
x1
t
...
xN
1
–
t
"
"
 |
(
)
P
>
X
( )
P
X
( )
P
N
X
( )
P
x1 ... xN
,
,
{
}
,
X
( )
P
M
x1 ... xN
,
,
{
}
X
( )
P

Bayesian Programming
Page 182
estimating a distribution 
 as an integral on the 
 space using a Monte Carlo
method:
(14.63)
Drawing a point directly from 
 consists of drawing uniformly an integer value 
between one and 
, and returning the corresponding point in the set 
. This
process may be iterated 
 times to obtain 
 points.
If 
 is used indirectly, then 
 may be estimated using a Monte Carlo integra-
tion method (see Section 14.3.2):
(14.64)
This kind of representation can easily be improved by encoding 
 as a sample set of
 couples instead of 
 points:
(14.65)
where the 
 are weight values, proportional to 
.
This kind of representation is especially used for particle filters (see Section 13.1.2).
When 
 is used for estimating a sum, we obtain:
(14.66)
Both kinds of representation clearly suffer from important limitations:
•
It is obviously very difficult to represent huge high-dimensional spaces with a rea-
sonable number of points.
•
It is very difficult to place the points at the modes where they are significant.
•
It is clear that these methods of representation are unable to make generalization in
Y
( )
P
X
Y
( )
P
X
( )
P
Y
X
 |
(
)
P
×
X!
=
X
( )
P
i
N
x1 ... xN
,
,
{
}
M
M
X
( )
P
Y
( )
P
Y
( )
P
1
N----
Y
X
xi
=
[
]
 |
(
)
P
i
1
=
N
!
×
?
X
( )
P
N
N
X
( )
P
x1 11
,
(
) ...
xN 1N
,
(
)
,
,
{
}
,
1i
xi
(
)
P
X
( )
P
Y
( )
P
1i
Y
X
xi
=
[
]
 |
(
)
P
×
[
]
i
1
=
N
!
1i
i
1
=
N
!
------------------------------------------------------------------
?

Bayesian Inference Algorithms Revisited
Page 183
the neighborhood of the points of the sample set 
, and can only be evaluated
for these points.
Multi-Resolution Binary Tree
Unlike the preceding representations, a Multi-Resolution Binary Tree (MRBT) is an
explicit representation having a capacity for generalization. Using an MRBT, we can
compute, for all points , the probability value 
.
The main idea of MRBTs is that high-probability regions of the distribution 
should be represented with high resolution, while low-probability regions may be repre-
sented with low resolution.
An 
MRBT 
is 
built 
incrementally 
by 
inserting 
 
pairs
. This set of pairs is generated using an exter-
nal process such as a genetic algorithm or a Metropolis sampler.
When inserting a given pair 
, the binary tree is updated so that the
resolution of the region including the point 
 is increased by splitting the corresponding
node on one dimension. 
The built MRBT can be used to find the probability value of any given point  (i.e. to
compute 
) by searching (using dichotomy) for the leaf node corresponding to
 and returning its probability value. 
To draw a point from the distribution 
, we also use dichotomy to draw a leaf
node. Starting from the root node, we choose to go to its first or second child according to
their respective total probability values. This procedure is iterated until a leaf node is
reached. Having this leaf node, drawing a value  from 
 consists of a uniform draw
in the region encoded by this leaf.
More details on MRBT implementation and use can be found in a patent protecting this
method (Bessière, 2002) and also in (Bellot & Bessière, 2003).
14.3.2
Marginalization (integration) in high-dimensional spaces
Integral calculus is the basis of Bayesian inference. Unfortunately, analytic methods for
integral evaluation seem very limited in real-world applications, where integrands may
have complex shapes and integrations spaces may have very high dimensionality.
Domain subdivision-based methods (such as trapezoidal or Simpson methods) are
X
( )
P
x
X
x
=
[
]
(
)
P
X
( )
P
N
x1
X
x1
=
[
]
(
)
P
,
(
) ...
xN
X
xN
=
[
]
(
)
P
,
(
)
,
,
{
}
xi
X
xi
=
[
]
(
)
P
,
(
)
xi
x
X
x
=
[
]
(
)
P
x
X
( )
P
x
X
( )
P

Bayesian Programming
Page 184
deterministic numerical techniques often used for numerical integration in low-dimen-
sional spaces. However, these techniques are poorly adapted for high-dimensional cases.
These techniques will not be discussed further but you should be aware of them. Good
sources for such techniques are the numerical recipes (Press et al., 1992) and a book by
Davis (Davis & Rabinowitz, 1975). 
Monte Carlo methods (MC) are powerful stochastic simulation techniques that may
be applied to solve optimization and numerical integration problems in large-dimensional
spaces.  Since their introduction in the physics literature in the 1950s, Monte Carlo meth-
ods have been at the center of the recent Bayesian revolution in applied statistics and
related fields.
Analytical integration
Analytical solutions to integration problems are available in well-catalogued instances in
which the integrands have particular shapes. Gradshteyn’s book (Gradshteyn & Ryzhik,
1980) is a useful and standard reference on these methods.
In probabilistic inference, the best-known and most interesting particular case is when
the integrand is a product of generalized normals (Dirac delta functions and Gaussians)
and when the model is linear or can be linearized (variance matrices are small enough). If
we have to compute the integral:
,
(14.67)
where:
•
•
then we obtain the analytical solution:
,
(14.68)
where 
 is a constant matrix (or a Jacobian in a linearized model) and 
 is its trans-
pose. 
I Y
( )
X
( )
P
Y
X
 |
(
)
P
×
X
d
D
×
:
–
:
2
=
X
( )
P
G X µX *X
,
,
(
)
=
Y
X
 |
(
)
P
G Y A
X
•
*Y
,
,
(
)
=
I Y
( )
G Y
A
µX
•
[
]
A
*X
•
A
T
•
*Y
+
[
]
,
,
(
)
=
A
A
T

Bayesian Inference Algorithms Revisited
Page 185
This analytical resolution of the integral is used extensively in, for example, eKalman
filters (see Section 13.1.2), and explains their practical success.
Monte Carlo methods for numerical integration
The aim of Monte Carlo methods is to approximate efficiently the D-dimensional integral
(where D can be very large):
(14.69)
We assume that 
 is a D-dimensional vector with real or discrete components, or a
combination. We use the symbol 
 as a generalized integration operator for both real
integrals (over real components) and sums (over discrete components). 
Assuming that we cannot visit every single location 
 in the state (integration) space,
the simplest solution for estimating the integral (14.69) is to uniformly sample the inte-
gration space 
 and then estimate  by 
:
(14.70)
High-dimensional probability distributions are often concentrated on a small region 
of the state (integration) space 
, known as its typical set. For example, if the space 
contains a large number of roughly independent variables, then the volume 
 of the
region 
 is given by:
 
(14.71)
where 
 is the Shannon entropy (see MacKay, 1996):
(14.72)
The number 
 of points drawn uniformly for the state (integration) space 
 must be
sufficiently large to cover the region 
 containing most of the probability mass of 
:
I
X
( )
P
Q X
( )
X
d
D
×
×
2
=
X
...
2
xi
X
I
I
)
I
1
N----
xi
(
)
P
Q xi
(
)
×
i
1
=
N
!
×
=
)
T
X
X
T
T
T
2
H
X
( )
P
(
)
?
H
X
( )
P
(
)
H
X
( )
P
(
)
X
( )
P
X
( )
P
(
)
log
×
X!
–
=
N
X
T
x
( )
P

Bayesian Programming
Page 186
(14.73)
where 
 is the volume of the state space. This makes the exploration of the state
space using uniform sampling very expensive in the general case.
Instead of exploring the integration space uniformly, Monte Carlo methods try to use
the information provided by the distribution 
 to explore this space more efficiently.
The main idea of these techniques is to approximate the integral  by estimating the
expectation of the function 
 under the distribution 
:
(14.74)
Clearly, if we are able to generate a set of points (vectors) 
 from 
, the
expectation of 
 is . In addition, as the number of samples 
 increases, the variance of
the estimator 
 will decrease as 
 where 
 is the variance of 
:
(14.75)
 and 
 is the expectation of 
.
This result is an important property of Monte Carlo methods: the accuracy of Monte
Carlo estimates is independent of the dimensionality of the integration space.
Neal (Neal, 1993) offers a good survey of Monte Carlo sampling techniques.
Simple (or perfect) Monte Carlo integration
Suppose we are able to obtain a set of samples 
 from the distribution 
.
We can use these samples to find the estimator:
(14.76)
The perfect Monte Carlo method assumes the capacity to sample the distribution
 efficiently. This is possible when 
 is a standard and simple distribution with a
direct sampling method, or a product of standard distributions on which direct sampling
is possible using the Gibbs algorithm. 
For instance, if 
 where 
 is a uni-
N
X
T
----------
0
X
X
( )
P
I
Q X
( )
X
( )
P
I
X
( )
P
Q X
( )
X
d
D
×
×
2
Q X
( )
0
1
=
=
x1 ... xN
,
,
{
}
X
( )
P
I
)
I
N
I
)
-
2 N

-
2
Q
-
2
X
( )
P
Q X
( )
Q
–
(
)
x
d
D
×
×
2
=
)
Q
)
Q
x1 ... xN
,
,
{
}
X
( )
P
I
1
N----
Q xi
(
)
i
1
=
N
!
×
=
)
X
( )
P
X
( )
P
X
( )
P
X1
X2
"
(
)
P
X1
(
)
P
X2
X1
 |
(
)
P
×
=
=
X1
(
)
P

Bayesian Inference Algorithms Revisited
Page 187
form distribution and 
 is a normal distribution having 
 as mean and a fixed
value as variance, then drawing a point 
 consists of:
•
drawing 
 from 
 (i.e. uniformly on the possible values).
•
drawing 
 from the normal distribution 
.
Importance sampling Monte Carlo integration
Suppose now that we are unable to generate sample points directly from the distribution
 but only from a simpler distribution 
 called the sampling distribution.
Using importance sampling, a set of 
 points is generated from 
. If these sam-
ple points were generated from 
, we could estimate  using Equation (14.76). How-
ever, as these points have been generated from 
 and not from 
, the values of 
for which 
 is greater than 
 will be over-represented and the values for which
 is less than 
 will be under-represented. To take into account this problem,
importance sampling introduces weights:
(14.77)
These weights are used to define the importance of each point in the estimator:
(14.78)
This method of integration is used especially in particle filters.
X2
X1
 |
(
)
P
X1
x
t
x1
t x2
t
,
(
)
=
x1
t
X1
(
)
P
x2
t
X2
X1
x1
t
=
[
]
 |
(
)
P
X
( )
P
Q X
( )
N
Q X
( )
X
( )
P
I
Q X
( )
X
( )
P
X
Q X
( )
X
( )
P
Q X
( )
X
( )
P
1i
xi
(
)
P
Q xi
(
)
--------------
=
I
1
1i
i
1
=
N
!
---------------
1i
Q xi
(
)
×
[
]
i
1
=
N
!
×
=
)

Bayesian Programming
Page 188

Page 189
 15
Bayesian Learning Revisited
$$$
$$$
15.1
Problematic
A Bayesian program has the following structure:
(15.1)
In section 3 we showed that most probabilistic models can be specified using this for-
malism. In section 4 we presented how to automate computation of such programs. At
Ds
?Preliminary knowledge? +
( )
X
X1
...
XN
"
"
=
Dc
X1
...
XN
"
"
.
+
"
 |
(
)
P
Li
Ri
.
"
"
 |
(
P
i
1
=
M
&
=
Fo
Li
Ri
.
+
"
"
 |
(
)
P
F7i
i
L
i
(
)
=
)
*
*
*
*
*
*
*
*
+
*
*
*
*
*
*
*
Data
.
( )
*
*
*
*
*
*
*
*
*
*
+
*
*
*
*
*
*
*
*

Bayesian Programming
Page 190
this point, the reader should be convinced of the interest of such probabilistic models for
both solving important engineering problems and for building interesting models of cog-
nition.
However, an important question has still to be answered: where do the Bayesian pro-
grams come from? From the engineering point of view this question is: is there a method-
ology to develop Bayesian programs? From the scientific point of view this question
could be translated as: is there any natural process that could explain the apparition of
probabilistic models in the brains of living beings? The purpose of this 5th section is to
review the different aspects of these questions.
The global question (where do the Bayesian programs come from?) can be divided into
sub-questions, which can be answered separately and can be made mathematically pre-
cise:
1. How to identify (learn) the value of the free parameters?
2. How to compare different probabilistic models (specifications)?
3. How to find interesting decompositions and associated parametric forms?
4. How to find the pertinent variables to model a phenomenon?
15.1.1
How to identify (learn) the value of the free parameters?
Given some specification  (consisting of the pertinent variables, the decomposition of
the joint distribution and the parametric forms), and given some data set , one wants to
identify the values of the free parameters that best take into account the data.
It is always possible to make the free parameters appear as an explicit variable 
 of
the model:
+
.
@

Bayesian Learning Revisited
Page 191
(15.2)
•
 represents the free parameters of the i-th form and 
 the set of all these free
parameters.
•
The goal of the parameters is to sum up what has been learned from the data. Con-
sequently:
°
The parameters depend on the data: 
°
Knowing the parameters, the distributions does not depend any more on the
data:
(15.3)
Therefore, there is a Bayesian formulation of the parameter identification problem:
(15.4)
•
 is a collection of  data . Each datum is a collection of values for the variables
Ds
?Preliminary knowledge? +
( )
X
X1
...
XN
"
"
=
@
@1
...
@M
"
"
=
Dc
X1
...
XN
@1
...
@M
"
"
"
"
"
.
+
"
 |
(
P
@
.
+
"
 |
(
)
P
Li
Ri
@i
"
"
 |
(
P
i
2
=
M
&
×
=
Fo
L
i
R
i
@i
+
"
"
 |
(
)
P
F7i
i
L
i
(
)
=
)
*
*
*
*
*
*
*
*
*
*
*
*
+
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
+
*
*
*
*
*
*
*
*
*
*
*
@i
@
@
.
+
"
 |
(
)
P
Li
Ri
@i
.
+
"
"
"
 |
(
)
P
Li
Ri
@i
+
"
"
 |
(
)
P
=
Ds
?Preliminary knowledge? +
( )
A
X
1
...
X
P
"
"
=
@
@1
...
@M
"
"
=
Dc
A
@
"
+
 |
(
)
P
@
+
 |
(
)
P
A
@
 |
(
P
×
=
Fo
A
@
+
"
 |
(
)
P
X
k
@
+
"
 |
(
)
P
k
1
=
P
&
=
)
*
*
*
*
*
*
*
*
*
*
+
*
*
*
*
*
*
*
*
Data .
( )
)
*
*
*
*
*
*
*
*
*
*
*
*
+
*
*
*
*
*
*
*
*
*
*
.
P
x
j

Bayesian Programming
Page 192
. For example, a datum  is given by 
. 
•
Each datum, knowing the model  and the values of the parameters , are consid-
ered to be independent from one another:
 
(15.5)
Learning or identifying the free parameters consist in answering the question
: What is the most probable value of the parameters knowing a given data set
? The answer to this question is obtained by:
(15.6)
Most often, 
 is supposed to be uniform. Maximizing 
 thus reduces
to the maximization of the likelihood 
. However, one may very well use strong
priors on the values of the parameters.
The difficulty of this problem is that the parameter space may be huge and exploring
it to find the most probable value may be untractable.
15.1.2
How to compare different probabilistic models (specifications)?
Given two models 
 and 
, each one corresponding to a given Bayesian specification,
and given some data set , we want to choose the model which best fits the data.
As for the search of the parameters, there is also a Bayesian formulation of this prob-
lem, by having the different models appear as different values of a variable 
:
X1
...
XN
"
"
x
j
x
j
X1
x
j 1
=
[
]
...
XN
x
j N
=
[
]
"
"
=
+
@
A
@
+
"
 |
(
)
P
X
k
@
+
"
 |
(
)
P
k
1
=
P
&
=
@
.
+
"
 |
(
)
P
.
@
.
+
"
 |
(
)
P
@
+
 |
(
)
P
.
@
+
"
 |
(
)
P
×
A
+
 |
(
)
P
----------------------------------------------------------------
=
1
*---
@
+
 |
(
)
P
×
.
@
+
"
 |
(
)
P
×
=
1
*
---
@
+
 |
(
)
P
×
x
k
@
+
"
 |
(
)
P
k
1
=
P
&
×
=
@
+
 |
(
)
P
@
.
+
"
 |
(
)
P
.
@
+
"
 |
(
)
P
+1
+2
.
B

Bayesian Learning Revisited
Page 193
(15.7)
•
 is the preliminary knowledge common to both models. For instance, usually
both models share at least the same pertinent variables.
The question to be answered is 
: the relative probability of the 2 models.
The answer to this question is given by:
(15.8)
Comparing 2 models, one usually tries to compute their relative probabilities:
(15.9)
This expression is most often very easy and fast to compute.
15.1.3
How to find interesting decompositions and associated parametric forms?
Given a set of pertinent variables, given a class of possible decompositions and of possi-
ble parametric forms, and given a data set , we want to select the best model in the class
of possible ones.
This is basically is the same problem than the preceeding one, but extended to a large
number of models (all the possible models of the class). We want here to find the most
probable value of 
 with the probability of 
 given as above by:
Ds
?Preliminary knowledge? +
( )
A
X
1
...
X
P
"
"
=
Dc
A
B
"
+'
 |
(
)
P
B
+'
 |
(
)
P
A
B "
 |
(
P
×
=
Fo
A
B
+1
=
[
]
+'
"
 |
(
)
P
X
k
+1 "
 |
(
P
k
1
=
P
&
=
A
B
+2
=
[
]
+'
"
 |
(
)
P
X
k
+2 "
 |
(
P
k
1
=
P
&
=
)
*
*
*
*
*
*
*
*
*
*
*
*
+
*
*
*
*
*
*
*
*
*
Data .
( )
)
*
*
*
*
*
*
*
*
*
*
*
*
*
*
+
*
*
*
*
*
*
*
*
*
*
*
+'
B
.
+
"
 |
(
)
P
B
.
+
"
 |
(
)
P
B
+'
 |
(
)
P
.
B
+'
"
 |
(
)
P
×
=
+2
.
+
"
 |
(
)
P
-----------------------------------
+2
+'
 |
(
)
P
.
+2
+'
"
 |
(
)
P
×
---------------------------------------------------------------------
=
+1
+'
 |
(
)
P
+2
+'
 |
(
)
P
---------------------------
X
k
+1
+'
"
 |
(
)
P
k
1
=
P
&
X
k
+2
+'
"
 |
(
)
P
P
&
--------------------------------------------------
×
=
.
B
B

Bayesian Programming
Page 194
(15.10)
This problem may be very difficult to solve as the number of possible models may be
huge.
15.1.4
How to find the pertinent variables to model a phenomenon?
Finally, the most difficult problem of the four is to search for the pertinent variables in a
given class of possible variables. It is the most difficult simply because the size of the
search space is even larger than in the previous problem.
It is possible to give a bayesian formulation of this fourth problem, but this formula-
tion is far too complicated to be presented here.
Let us now review some known algorithms and method that deal with one or several of
the four preceeding questions.
15.2
Expectation - Maximization (EM)
The EM algorithm (Expectation-Maximization) (see Dempster, Laird & Rubin, 1977) is a
general-purpose algorithm used to answer the first question: How to identify (learn) the
value of the free parameters?
It is used in a wide variety of situations best described as incomplete-data problems.
The idea behind the EM algorithm is intuitive and natural and it has been formulated and
applied to a variety of problems. The EM algorithm can be applied either in incomplete-
data situations where data are missing, distributions are truncated, observations are cen-
sored or grouped, or in situation where the incompleteness of data is not natural or evi-
dent.
The basic idea of the EM algorithm is to associate with the given incomplete-data
problem, a complete-data problem for which ML estimation is computationally more
tractable. The complete-data problem may yield a closed-form solution to the maximum
likelihood estimate (MLE). The EM algorithm consists in reformulating the problem in
terms of this more easily solved complete-data problem. It establishes a relationship
between the likelihoods of these two problems, and exploits the simpler MLE computa-
tion of the complete-data problem, during the M-step of the iterative computing algo-
rithm.
B
.
+
"
 |
(
)
P
B
+'
 |
(
)
P
.
B
+'
"
 |
(
)
P
×
=

Bayesian Learning Revisited
Page 195
Usually, the E-step consists in producing data for the complete-data problem, using
the observed data set of the incomplete-data problem and the current value of the param-
eters, so that the simpler M-step computation can be applied to this completed data set.
During the E-step, it is precisely the log-likelihood of the data which is produced, and, as
it is partly based on unobservable data, it is replaced by its conditional expectation given
the observed data. Starting from suitable initial parameters values, E and M steps are iter-
atively repeated until convergence.
15.2.1
EM and bayesian networks
In Bayesian networks (see section 3.1.1), the EM algorithm is used to answer the first
question: how to identify (learn) the value of the free parameters? The searched parame-
ters are the values of the probabilty tables associated with the vertices and edges of the
network.
When some nodes are hidden, the EM algorithm is used to find a locally optimal
MLE. In the E-step, we compute the expected values of hidden nodes, given observed
data. This is done by using an inference algorithm (for instance JLO), and then we treat
these expected values as though they were observed. The M step is carried out by using
the expected values of the hidden nodes as if they were observed. The solution is to com-
pute the frequency of the values for each node until the difference between the new distri-
bution and the older one is less than an arbitrary threshold.
15.2.2
EM and Mixture Models
EM is the most common algorithm used to identify the parameters of Mixture Models
(see section 3.1.3).
For instance, for Gaussain mixtures, it is used to find where the gaussian kernels
should be set and the values of their covariance matrices.
Numerous variants of EM have been developed in the context of mixture models. A
synthesis may be found in The EM Algorithm and Extensions by McLachlan (McLachlan &
Krishnam, 1997). 
15.2.3
EM and HMM: The Baum-Welch Algorithm
The learning of the models in HMM (see section 3.1.2) is performed by the Baum-Welch
algorithm, a specialized version of the EM algorithm, using the maximum likelihood esti-

Bayesian Programming
Page 196
mation criteria that determines the best model's parameters according to the set of data. 
Intuitively, this algorithm counts the number of occurrences of each transition
between the states and the number of occurrences of each observation in a given state in
the training data. Each count is weighted by the probability of the alignment (state, obser-
vation). 
Since many state sequences may generate a given output sequence, the probability
that a HMM  generates a sequence 
 is given by the sum over all state sequences
(i.e, the marginal density of output sequences). 
To avoid the combinatorial explosion, a recursive computation similar to the Viterbi
algorithm can be used to evaluate the above sum. The forward probability 
 is :
(15.11)
This probability represents the probability of ending at time t in state  and generating
output 
 using all possible state sequences in between. 
The Markov assumption allows the recursive computation of the forward probability
as :
(15.12)
This computation is similar to Viterbi decoding except that a summation is used
instead of a maximum.
Another useful quantity is the backward function 
, defined as the probability of
starting at time t in state  and generating output 
, using all possible state
sequences in between:
 
(15.13)
The Markov assumption allows the recursive computation of the backward probabil-
ity as :
7
o
0 ... o
t
,
,
{
}
)
t i( )
( )
[
]
(
)
S
0
...
S
t
1
–
S
t
i
=
[
]
o
0
...
o
t
"
"
"
"
"
"
(
)
P
S
0
...
S
t
1
–
"
"
!
=
S
0
(
)
P
o
0
S
0
 |
(
)
P
S
i
S
i
1
–
 |
(
)
P
o
i
S
i
 |
(
)
P
×
[
]
t
&
×
×
!
=
i
o
0 ... o
t
,
,
{
}
)
t
1
+
j( )
)
t i( )
S
t
1
+
j
=
[
]
S
t
i
=
[
]
 |
(
)
P
o
t
1
+
S
t
1
+
j
=
[
]
 |
(
)
P
×
×
[
]
i
1
=
N
!
=
C
t i( )
i
o
t
1
+
... o
T
,
,
{
}
C
t i( )
o
t
1
+
...
o
T
S
t
i
=
[
]
"
"
"
(
)
P
=

Bayesian Learning Revisited
Page 197
(15.14)
To describe the procedure for reestimation of HMM parameters, we first define  
as the posterior probability that the stochastic process accomplishes the transition
,  assuming the whole sequence of observations:
(15.15)
We deduce:
(15.16)
Finally, we define 
 as the posterior probability that the process is in the state  at
time :
(15.17)
Therefore, the maximum likelihood (ML) estimate of the parameters of the HMM is:
(15.18)
See Rabiner’s paper for details (Rabiner & Juang, 1986).
15.3
Problem Oriented Models
In problem oriented models, answering the first question is usually very easy. Indeed, the
variables, the decomposition and the parametric forms have been chosen with 3 main
C
t i( )
C
t
1
+
j( )
S
t
1
+
j
=
[
]
S
t
i
=
[
]
 |
(
)
P
o
t
1
+
S
t
1
+
j
=
[
]
 |
(
)
P
×
×
[
]
j
1
=
N
!
=
D
t i j,
(
)
S
t
i
=
[
]
S
t
1
+
j
=
[
]
#
D
t i j,
(
)
S
t
i
=
[
]
S
t
1
+
j
=
[
]
"
o
0
...
o
T
"
"
 |
(
)
P
=
D
t i j,
(
)
) i( )
S
j
=
[
]
S
i
=
[
]
 |
(
)
P
o
S
j
=
[
]
 |
(
)
P
C
j( )
×
×
×
o
0
...
o
T
"
"
(
)
P
---------------------------------------------------------------------------------------------------------------------------------------------------------------------
=
)
t i( )
S
t
1
+
j
=
[
]
S
t
i
=
[
]
 |
(
)
P
o
t
1
+
S
t
1
+
j
=
[
]
 |
(
)
P
C
t
1
+
j( )
×
×
×
)
t i( )
S
t
1
+
j
=
[
]
S
t
i
=
[
]
 |
(
)
P
o
t
1
+
S
t
1
+
j
=
[
]
 |
(
)
P
C
t
1
+
j( )
×
×
×
[
]
N
!
N
!
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
=
9
t i( )
i
t
9
t i( )
D
t i j,
(
)
j
1
=
N
!
=
S
t
1
+
j
=
[
]
S
t
i
=
[
]
 |
(
)
P
D
t i j,
(
)
t
0
=
T
!
9
t i( )
t
0
=
T
!
--------------------------
=
O
t
k
=
[
]
S
t
i
=
[
]
 |
(
)
P
9
t i( )
t
0
=
O
t
k
=
T
!
t
T
-------------------------
=

Bayesian Programming
Page 198
desiderata in mind:
1. Build a valid model of the observed phenomenon.
2. Build a simple enough model so that inference is kept tractable. 
3. Build a model so that the free parameters can easily be identified.
For instance, in the sensor fusion models (see section 3.2.1), the sensor models
 are very often Gaussian distributions. In that case, given 
 couples of values
, correponding to  observations, it is trivial to compute the means and
standard deviations for each gaussian. 
More details on this may be found in Lebeltel’s Ph.D. thesis (Lebeltel, 1999) and more
elaborate learning methods of this kind in Diard’s Masters and Ph.D. thesis (Diard & Leb-
eltel, 1999 & Diard, 2003).
15.4
Learning Structure of Bayesian Networks
When learning the structure of a Bayesian network, one tries to solve question 3. Indeed,
the problem is to find the best BN decomposition (i.e. the best graph structure).
Two main techniques are used to deal with this problem:
•
Greedy hill-climbing: this algorithm starts from one (or several) random network
and then "hill-climbs", by choosing iteratively a better network among its neigh-
bours.
•
MCMC Model Composition: This algorithm uses a Metropolis-Hastings algorithm
(see section 4.3.2) to search the models using the acceptance rate:
(15.19)
as in equation [50].
Starting points to this subject are Heckerman’s tutorial (Heckerman, 1995) and Bun-
time’s one (Buntime, 1996). More details on MCMC methods may be found in 2 other
papers (Murphy, 2001 &  Friedman & Koller, 2000).
Si
3
 |
(
)
P
N
s
0 i
3
0
,
(
) ...
s
N i
3
N
,
(
)
,
,
{
}
N
a
+i
.
+
"
 |
(
)
P
+
t
.
+
"
 |
(
)
P
----------------------------------
=

Bayesian Learning Revisited
Page 199
15.5
Bayesian Evolution?
Let us finish with some long term and very exciting perspectives. 
If we admit that living systems are doing Bayesian inference and learning, then there
must exist some natural processes, which have been answering and are still answering
our 4 questions.
1. How to identify (learn) the value of the free parameters?
2. How to compare different probabilistic models (specifications)?
3. How to find interesting decompositions and associated parametric forms?
4. How to find the pertinent variables to model a phenomenon?
A tantalising answer is to say that natural evolution provided living beings with both the
pertinent variables and the adequate decomposition and parametric forms. The pertinent
variables may have been obtained by selecting the sensors and actuators in order to sup-
ply vital information. The decomposition would correspond to the structure of the ner-
vous system, which basically expresses dependencies and conditional independencies
between variables. The parametric forms can be seen as the information processing units
implemented by neurons and assembly of neurons.
Given this apparatus, correponding to the preliminary knowledge, each individual in
its lifetime can answer the first question by experimenting and learning the values of the
free parameters of its nervous system.
We plan, in BIBA, to explore this possibility, by using evolutionary techniques to answer
questions 2, 3 and 4. Some preliminary work has been already done in GRAVIR on that
subject.
To the best of our knowledge, only Zhang (see its publications at http://bi.snu.ac.kr/
Publications/pub_ei.html#BEA) really tried to explore the same path. However, our bib-
liographical study on this subject is not completed yet and we may have missed important
works. It will be pursued next months.

Bayesian Programming
Page 200

Page 201
 16
Frequently Asked Question 
and
Frequently Argued Matter
16.1
APPLICATIONS OF BAYESIAN PROGRAMMING (WHAT 

Bayesian Programming
Page 202
ARE?)
16.2
BAYES, THOMAS (WHO IS?)
16.3
BAYESIAN DECISION THEORY (WHAT IS?)
16.4
BIAS VERSUS VARIANCE DILEMMA
16.5
Computation complexity of Bayesian Inference
16.6
Cox theorem (What is?)
16.7
DECOMPOSITION
16.8
DESCRIPTION
16.9
DISJUNCTION RULE AS AN AXIOM (WHY DON'T YOU 
TAKE?)
16.10
DRAW VERSUS BEST
16.11
FORMS
16.12
FREQUENTIST VERSUS NON-FREQUENTIST
16.13
FUZZY LOGIC VERSUS BAYESIAN INFERENCE
16.14
HUMAN (ARE THEY BAYESIAN?)
16.15
IDENTIFICATION
16.16
Incompleteness irreducibility
$$$

Frequently Asked Question and Frequently Argued Mat-
Page 203
16.17
JAYNES, ED. T. (WHO IS?)
16.18
KOLMOGOROV (WHO IS?)
16.19
KOLMOGOROV'S AXIOMATIC (WHY DON'T WE NEED?)
16.20
LAPLACE, MARQUIS SIMON DE (WHO IS?)
16.21
LAPLACE'S SUCCESSION LAW CONTROVERSY
16.22
Maximum entropy principle justifications
16.23
MIND PROJECTION FALLACY (WHAT IS?)
16.24
Noise or ignorance?
16.25
PERFECT DICE (WHAT IS?)
16.26
PHYSICAL CAUSALITY VERSUS LOGICAL CAUSALITY
16.27
PROSCRIPTIVE PROGRAMMING
16.28
SPECIFICATION
16.29
Subjectivism vs objectivism controversy
16.30
VARIABLE

Bayesian Programming
Page 204

Page 205
 17
Bibliography
Aji S. M. and McEliece R. J. ; (2000) ; The Generalized Distributive Law ; IEEE Trans. Infor-
mation Theory, Vol. 46, No. 2 
Arnborg, S., Corneil, D. G., & Proskurowski, A.; (1987);. Complexity of finding embedding in
a k-tree; SIAM J. Alg. Disc. Meth., 8(2), 277–284.
Bachelard, G. ; (1938) La formation de l'esprit scientifique : Contribution a une psychanalyse
de la connaissance objective ; Librairie philosophique J. Vrin, Paris, France
Barlow, H.; (2001); The exploitation of regularities in the environment by the brain; Behviou-
ral and Brain Science (BBS); 24 (4): 602-607.
Bellot, D. & Bessière, P.; (2003); Approximate Discrete Probability Distribution Representa-
tion using a Multi-ResolutionBinary Tree; Proc. International Conference on Tools for
Artificial Intelligence - ICTAI 2003, Sacramento, California, USA, November 3-5
Bernouilli, J. (1713) Ars Conjectandi
Cooper, G. ; (1990) ; The computational complexity of probabilistic inference using Bayesian
belief networks ; Artificial Intelligence, Vol. 42, pp. 393-405
www-ksl.stanford.edu/KSL_Abstracts/KSL-90-34.html

Bayesian Programming
Page 206
Darwiche, A. and Provan, G. ; (1997) ; Query DAGs: A Practical Paradigm for Implementing
Belief-Network Inference ; Journal of Artificial Intelligence Research (JAIR), Vol. 6, pp.
147-176
Dayan, P. & Abbott, L.F.; (2001); Theoretical Neuroscience: Computational and Mathematical
Modeling of Neural Systems; MIT Press
Dechter, R.; (1996); Bucket elimination: A unifying framework for probabilistic inference. In
E. Horvits and F. Jensen (Ed.), Proc. Twelthth Conf. on Uncertainty in Artificial Intelli-
gence, pp. 211–219 Portland, Oregon.
Dechter, R. and Rish, I.; (1997); A scheme for approximating probabilistic inference; in Pro-
ceedings of Uncertainty in Artificial Intelligence (UAI97), pages 132-141
Forney, G.D. ; (1973) ; The Viterbi Algorithm ; IEEE Transactions, Vol. 61, p. 268-278
Glimcher, P.; (2003); Decisions, Uncertainty, and the Brain: The Science of Neuroeconomics;
MIT Press
Glymour, C.; (2001); The Mind's Arrows: Bayes Nets and Graphical Causal Models in Psy-
chology; MIT Press
Jaynes, E.T.  (2003) Probability theory - The logic of science; Cambridge University Press
Jordan, M. & Sejnowski, T.; (2001); Graphical Models: Foundations of Neural Computation;
MIT Press
Kaminka, G., Veloso, M., Scheffer, S., Solito, C., Adobatti, R., Marshall, A., Scholer, A. &
Tejada, S. (2002) GameBots: a flexible test bed for multiagent team research; Communica-
tion of the ACM, Volume 45, Issue 1, Pages 43-45
Knill, D. & Richards, W.; (1996); Perception as Bayesian inference; Cambridge University
Press
Laplace S. (1812) Théorie analytique des probabilités; Edition Veuve Courcier, Paris, France
Lauritzen, S. & Spiegelhalter, D. ; (1988) ; Local computations with probabilities on graphical
structures and their application to expert systems ; Journal of the Royal Statistical Society
B ; Vol. 50, pp. 157-224
Lauritzen, S. L. ; (1996) ; Graphical Models ; Oxford University Press
Li, Z., & D’Ambrosio, B.; (1994); Efficient inference in Bayes networks as a combinatorial
optimization problem. International Journal of Approximate Reasoning, 11(1), 55–81.

Bibliography
Page 207
Pearl,  J. (1988)  Probabilistic reasoning in intelligent systems : Networks of plausible infer-
ence ; Morgan Kaufmann Publishers ; San Mateo, California, USA
Poincaré, H (1902) La science et l'hypothèse; Originally published in 1902, éditions de la
Bohème, Rueil-Malmaison, FranceRao, R., Olshausen, B. and Lewicki, M.; (2002); Proba-
bilistic Models of the Brain: Perception and Neural Function; MIT Press
Shachter, R. D., D’Ambrosio, B. D., & Del Favero, B. D.; (1990); Symbolic probabilistic infe-
rence in belief networks. In Proc. 8th National Conference on Artificial Intelligence, pp.
126–131 Boston.MIT Press.
Spiegelhalter, D.J.; (1986); Probabilistic reasoning in predictive expert systems, in: L.N. Kanal
and J.F. Lemmer (eds.),  Uncertainty in Artificial Intelligence, North-Holland, Amsterdam,
pp. 47 -- 67.
Woodcock, S. (2001) Game AI: The state of the industry; Game Developer Magazine
Zhang, N. L., & Poole, D.; (1994); A simple approach to Bayesian network computations. In
Proc. of the Tenth Canadian Conference on Artificial Intelligence, pp. 171–178.
Zhang, N.L. and Poole, D. ; (1996) ; Exploiting Causal Independence in Bayesian Network
Inference ; Journal of Artificial Intelligence Research (JAIR), Vol. 5, pp. 301-328

Bayesian Programming
Page 208

