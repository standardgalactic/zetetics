arXiv:2111.14293v1  [math.CT]  29 Nov 2021
A category theory framework for Bayesian
learning
Kotaro Kamiya & John Welliaveetil ∗
SyntheticGestalt Ltd
{k.kamiya, j.welliaveetil}@syntheticgestalt.com
Abstract
Inspired by the foundational works in [7] and [3], we introduce a cate-
gorical framework to formalize Bayesian inference and learning. The two
key ideas at play here are the notions of Bayesian inversions and the func-
tor GL as constructed in [3, §2.1]. We ﬁnd that Bayesian learning is the
simplest case of the learning paradigm described in [3]. We then obtain
categorical formulations of batch and sequential Bayes updates while also
verifying that the two coincide in a speciﬁc example.
Contents
1
Introduction
2
2
Preliminaries
5
2.1
Bayesian Inference . . . . . . . . . . . . . . . . . . . . . . . . . .
5
2.2
Bayesian inversions and PS
. . . . . . . . . . . . . . . . . . . . .
7
2.2.1
The category PS . . . . . . . . . . . . . . . . . . . . . . .
10
2.3
The Para construction . . . . . . . . . . . . . . . . . . . . . . . .
11
3
Bayes Learn
12
3.1
Inducing the M-actegory structure
. . . . . . . . . . . . . . . .
12
3.2
Bayes Learn . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
16
3.2.1
The functor Stat . . . . . . . . . . . . . . . . . . . . . . .
17
3.2.2
The Grothendieck Lens
. . . . . . . . . . . . . . . . . . .
17
3.2.3
The functor R . . . . . . . . . . . . . . . . . . . . . . . .
17
3.2.4
The functor BayesLearn . . . . . . . . . . . . . . . . . . .
18
3.3
Bayes Learning algorithm . . . . . . . . . . . . . . . . . . . . . .
19
4
Bayes updates
21
4.1
Sequential updates . . . . . . . . . . . . . . . . . . . . . . . . . .
21
4.2
Batch updates
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
24
∗Authors have equal contribution.
1

1
Introduction
A standard problem in Machine learning is to understand the relationship be-
tween two variables or random vectors. Suppose x is a random vector and y
is a random variable dependent on x. The additive model assumes that there
exists a function f such that
y = f(x) + ǫ
where ǫ is a random variable with mean 0. Our goal then reduces to estimating
the function f. To this end, we consider a parametrized family of functions
{fθ}θ∈P where P is the parameter space and by means of a learning algorithm
and a training data set, we traverse P to ﬁnd a candidate that we believe will
provide a reasonable approximation to the true function f. Several theoreti-
cal results underpin the validity of this approach - for instance the Universal
Approximation Theorem.
A formulation of the above framework within Category theory was achieved
in the foundational work of Fong, Spivak and Tuyeras [7]. In this paper, the
authors introduce the category Learn whose objects are sets and a morphism
from A to B in Learn consists of the following data.
A parameter set M,
an implementation I : M × A →B, an update function u: M × A × B →M
and a request function r: M × A × B →A. In related work, the authors of
[3], develop a more general theory by introducing the notion of a Cartesian
Reverse Diﬀerential category (cf. [3, §2.2]). Associated to a CRDC - C, they
construct the analog of the category Learn as a composite of the Para and
Lens constructions (cf. [3, §2.1, 2.3]). In this setting, the learning algorithm
will be a functor of type Para(C) →Para(Lens(C)). Our goal in this paper is
to employ both these approaches to develop a categorical framework to discuss
Bayesian learning.
While the approach outlined above to model the relationship between two
random variables is eﬀective, in real world situations, it is often the case that
there is no such function f.
Given the noisy nature of the data, it is more
reasonable to model the conditional probability p(y|x) i.e. to ask the question
- ’Given x, what is the probability that we have y ?’.
As before, we model the conditional probability using a parametrized family
of distributions - p(y|x; θ). However in contrast to our approach from before,
we assume that θ is a random variable and strive to obtain a distribution over
θ that agrees with the given training data. More precisely, we choose a prior
distribution q(θ) on θ and update this prior to obtain the posterior distribution
on θ. As opposed to gradient based approaches to learning, Bayesian machine
learning updates the prior distribution on θ by exploiting Bayes Theorem. The
posterior distribution is deﬁned upto normalizing constant by the formula
p(θ|y, x) ∝p(y|x, θ)q(θ|x).
There is considerable ﬂexibility in this approach in that we can use the posterior
to obtain point estimates of the parameter θ via the MAP estimate and perform
inference by integrating over the entire distribution. We continue this discussion
in greater detail in §2.1 where we illustrate the essential features of Bayesian
learning in the classical context using a simple example.
Our goal in this paper is to introduce a framework within category theory
that allows us to formalize this set up. We draw on the theory already developed
2

in [8], [9] and [2]. While we proceed as in [3] by associating to a parametrized
function a morphism in a generalized lens category which allows for the back-
ward transmission of information, an important observation is that the Bayes
Learning framework simpliﬁes the situation drastically. This is essentially due
to the fact that with the correct setup, Bayesian inversion is a well deﬁned dag-
ger functor and the functor Cop →Cat responsible for deﬁning the generalized
lens breaks down. We interpret this to mean that Bayes Learning is the sim-
plest form of learning that adheres to the framework discussed in [3]. See also
Remark 3.10.
The work of Cho and Jacobs in [2] and Fritz in [8] introduces the notion
of Markov categories as a suitable framework within which one can discuss
ideas from Probability theory such as Bayesian inversion, disintegration, join-
tiﬁcation, conditionalization... Hence, let C be a Markov category. We use the
categories FinStoch and Stoch (cf. Example 2.3) as guiding examples for the
theory we develop. Roughly speaking, the category FinStoch has ﬁnite sets as
objects and Markov kernels as morphisms between them while the objects of
Stoch are measurable spaces and morphisms f : X →Y imply for every x ∈X,
a probability distribution p(·|x) on Y . Central to this paper is the notion of
Bayesian inversion which in the context of FinStoch with reference to a mor-
phism p: X →Y corresponds to calculating the conditional p(X|y) for y ∈Y
using Bayes theorem to obtain a morphism p† : Y →X. Note that the inversion
which is a map Y →X is not necessarily unique and in the case of FinStoch
does not even always exist. To get around this issue, ﬁrstly we restrict our
attention to those Markov categories C which always admit Bayesian inversion.
Secondly, we make use of the symmetric monoidal category ProbStoch(C) which
was introduced ﬁrst by Cho and Jacobs in [2, §5] as the category of couplings or
equivalently the category whose objects coincide with those of the slice category
I ↓C and morphisms are obtained by quotienting with respect to the relation of
almost sure equality. Henceforth, we write PS(C) in place of ProbStoch(C) for
ease of notation. As a consequence of our assumption on C, Bayesian inversion
is a well deﬁned dagger functor on PS(C). A more detailed explanation can be
found in §2.2.
We can interpret the set-up in §2.1, as a parametrized function in a suitable
Kleisli category. In general, we assume that the category C is equipped with
the structure of an M-actegory where M is symmetric monoidal. We would
like to make use of the ParaM construction from [1] which generalizes [7]. For
reasons explained above, we work with the category PS(C) and in Lemma 3.3,
we show that PS(C) has the structure of an PS(M)-actegory provided we impose
certain technical assumptions on M and its action on C. We simplify notation
henceforth and write PS in place of PS.
Our deﬁnition of the functor BayesLearn in Section §3 is inspired in large
part by [3]. The key to the construction of a gradient based learner in [3] is a
functor
GL: Para(E) →Para(Lens(E))
where we require that E is a Cartesian reverse diﬀerential category. To fully
describe the learning mechanism, the authors introduce update and error end-
ofunctors on Para(E). These three pieces when employed in unison and for
appropriate choices of the update and displacement maps, can describe a wide
range of optimization algorithms ([3, §3.4]).
3

When adapting the framework of [3] to describe Bayes learning, we see im-
mediately that we must work with a more general notion of Lens as in [9]. To
this end, we proceed as in [9, Deﬁnition 3.1] by introducing a functor
Stat: PS(C)op →Cat
with which we deﬁne the associated Grothendieck lens LensStat. As Bayesian
inversion is a well deﬁned dagger functor, we deduce the existence of a well
deﬁned functor
R: PS(C) →LensStat.
It follows that we have a functor
ParaPS(M)(R): ParaPS(M)(PS(C)) →ParaPS(M)(LensStat).
We refer to the functor ParaPS(M)(R) as the BayesLearn functor.
It cap-
tures the essential features of the Bayes learning algorithm. Indeed, given a
parametrized morphism X →Y with a state on X, after choosing a prior state
on the parameter object P, we obtain a morphism in PS(C) i.e. a morphism
f : (M, πM) ⊙(X, πX) →(Y, πY ).
By construction, the induced morphism
BayesLearn(f): ((M ⊙X, πM ⊙πX), (M ⊙X, πM ⊙πX)) →((Y, πY ), (Y, πY ))
is given by a pair of morphisms
f : (M ⊙X, πM ⊙πX) →(Y, πY )
in the forward direction and
f † : (Y, πY ) →(M ⊙X, πM ⊙πX)
in the backwards direction by Bayesian inversion. This provides a rough de-
scription of the Bayesian learning procedure which we elaborate on in §3 and
§3.3 where we also give a formulation for the Bayes predictive density.
The classical formulation of Bayesian learning enables one to update a given
prior distribution on a parameter space using a training data set and Bayesian
inversion.
In §4, we provide a category theoretic formulation of this phe-
nomenon. Central to the discussion will be the notion of a training set. To
capture the notion of a single training instance, we restrict our attention to
those Markov categories which are of the form Kl(P) where P : D →D is a
symmetric monoidal monad on a symmetric monoidal category D. In this con-
text, we introduce the notion of an elementary point of an object X in C (cf.
Deﬁnition 4.2). In the case of FinStoch or Stoch, these correspond to states
on X which concentrate at a point x ∈X. We show that there are two ways
one can update the prior. As before, let us suppose we have a model i.e. a
morphism f : M ⊙X →Y in C. In addition we are given a prior distribution
πM,0 on M and a state πX : I →X. Via Bayesian inversion with respect to
πM,0 ⊙πX and after conditionalizing, we get a channel f †
joint,0 : X ⊗Y →M.
The precise details can be found in §3. Let
T := [(x1 ⊗y1), . . . , (xn ⊗yn)]
4

be a list of elementary points (cf. Deﬁnition 4.2) belonging to X ⊗Y . To obtain
the posterior, we can proceed sequentially i.e. we update the prior πM,0 by the
composition I
δx1 ⊗δy1
−−−−−→X ⊗Y →M to get a state πM,1 on M. Note that x1
corresponds to a morphism ID →X and δx1 is the image of this map in C. We
then implement the inversion procedure with respect to πM,1 to get an updated
channel X ⊗Y →M and continue as before. Repeating the above step to run
through the training data set will end with a state πM,n on M which in the case
of FinStoch deﬁnes a distribution on M which we call the posterior.
In a similar fashion, we can also deﬁne batch updates associated to the
training set T. To do so, we work with the space Z := X⊗Y and set Zn := ⊗nZ.
A channel f : M →Z naturally gives us a channel M →Zn by the composition
M
copyn
M
−−−−→⊗nM
⊗nf
−−−→Zn.
Here we abuse notation and write copyn
M for the composition
M
copyM
−−−−→M ⊗M
id⊗copyM
−−−−−−−→M ⊗M ⊗M . . .
id⊗...⊗copyM
−−−−−−−−−→⊗nM.
Note that the map M →Z is obtained naturally from the model f : M ⊙X →Y
via the composition
M ⊙I
id⊙πX
−−−−→M ⊗X
f⊗id
−−−→Y ⊗X ≃X ⊗Y.
The Bayesian inversion with respect to πM,0 implies a channel Zn →M. The
composition
I
(δx1 ⊗δy1 )⊗...⊗(δxn⊗δyn)
−−−−−−−−−−−−−−−−−→Zn →M
deﬁnes a state on M which we refer to as the batch update with respect to T
and denote πM,T.
It is natural in this setting to ask if there is a relationship between the se-
quential and batch updates or what hypothesis we must impose on C to ensure
that they are equal. We leave this question open to further investigation and
show that the two are equal in the case of FinStoch (cf. Examples 4.5 and 4.4).
String diagrams: In this paper, we orient our string diagrams from top to
bottom and display monoidal product as moving from left to right. All string
diagrams have been made using DisCoPy [4].
2
Preliminaries
2.1
Bayesian Inference
Our goal in this section is to give a high level overview of the approach Bayesian
learning takes in modelling the relationship between random variables of inter-
est. We use the lecture [11] as a reference to the material in this section.
Let us illustrate the approach with an example. Let x = (x1, . . . , xn) be a
random vector and y be a random variable. We assume that y is related to x
via the equation
y = f(x) + ǫ
5

where ǫ is normally distributed with mean 0 and variance σ2 and f(x) := βT x
where β ∈Rn.
For simplicity, we assume that the quantity σ is a known
constant.
Let us suppose we are given a training set T := {(x1, y1), . . . , (xN, yN)}.
One can divide the Bayesian approach into two parts. As outlined in the intro-
duction we treat β as a random variable and choose a prior distribution which
encodes our pre-conceived beliefs about β. Then using the set T, we update the
distribution on β to get its posterior distribution by applying Bayes’ rule. The
posterior distribution can then be used to obtain point estimates of β.
Let us assume an improper prior on β i.e. q(β) = 1. Applying Bayes’ rule
gives
p(β|T) ∝p(T|β)q(β)
Observe that our assumption on the nature of the underlying data implies that
p(y|x) is normally distributed with mean βT x and variance σ2. Assuming that
the training data is independent, we get
p(T|β) ∝
Y
i
p(yi|β, xi)q(β).
We assumed above that the distribution on x is known and hence in eﬀect we
condition every random variable with respect to x. Hence,
p(T|β) =
1
(2π)
N
2 σN exp(−
P
i(yi −βT xi)2
2σ2
)
and
p(β|T) =
1
(2π)
N
2 σN exp(−
P
i(yi −βT xi)2
2σ2
)
In this manner, we have updated the prior distribution on β in accordance
with the given data. We now sketch how one might perform inference. Let
x∗be a data point that does not necessarily belong to the training set T. We
would like to ﬁnd p(y∗|x∗, T). We outline two ways on how to proceed.
1. Let
βMAP := argmaxβp(β|T)
This is called the maximum a posteriori estimate of the parameter β. It
represents a single best guess for the parameter given the training data.
We then set
p(y∗|x∗, T) := p(y∗|x∗, βMAP).
Observe that in the context of our ongoing example, βMAP coincides with
βOLS - the ordinary least squares estimate.
2. While the MAP estimate of β represents a suitable guess for the parameter,
when performing inference we can do better by leveraging our knowledge
of the entire posterior distribution. The true Bayesian way is to integrate
over the posterior distribution β i.e.
p(y∗|x∗, T) :=
Z
p(y∗|x∗, β)p(β|T)dβ.
6

In practice, owing to the intractability of the integral above due to the fact
that the posterior distribution is not likely analytic a possible solution is to
proceed by employing a suitable approximation strategy. See for instance
[5] or [6].
Remark 2.1. Observe that the posterior distribution on β with regards to the
training set T can also be obtained by sequential updates. This is due to the
following phenomenon. Suppose T can be split into two training sets T1 and
T2 where T1 := {(x1, y1), . . . , (xr, yr)} and T2 := {(xr+1, yr+1), . . . , (xN, yN)}.
Let q1 be the posterior distribution p(β|T1) on β obtained by updating the prior
q. Likewise, let q2 be the posterior distribution on β obtained by updating the
prior q1 using the dataset T2. A simple calculation shows that the distribution
q2 coincides with the posterior obtained by updating q using the entire dataset
T. In §4, we formulate a categorical version of the above observation.
2.2
Bayesian inversions and PS
The theory of Markov categories provides a categorical framework within which
we can discuss and formalize notions from Probability theory. We use the no-
tation and conventions introduced in [8]. Note that this notion of Markov cat-
egories coincides with that of aﬃne CD-categories as introduced by Cho and
Jacobs in [2].
Deﬁnition 2.2. A Markov category is a semicartesian symmetric monoidal
category (C, I, ⊗) in which every object X is equipped with the structure of
a commutative internal comonoid. We denote the comultiplication and counit
maps by
copyX : X →X ⊗X
and
delX : X →I
respectively and require that they satisfy certain natural conditions (cf.
[8,
Deﬁnition 2.1]).
The deﬁnition above suggest that one can think of a morphism πX : I →X
in a Markov category C as a probability distribution on X. We refer to πX as
deﬁning a state on X. Likewise, a morphism f : X →Y in C will be called a
channel.
For the remainder of this section we ﬁx a Markov category C.
Example 2.3. We introduce two examples which we will continue to make
reference to throughout the course of the paper.
1. We deﬁne the category FinStoch to be the category of ﬁnite sets with
channels. A morphism f : X →Y in FinStoch is given by a morphism of
sets f : X →Dist(Y ) where Dist(Y ) is the set of probability distributions
on Y i.e.
Dist(Y ) =
n
ω: Y →[0, 1]|
X
y∈Y
ω(y) = 1
o
.
Given a set X, we deﬁne copyX to be the map that sends an element
x ∈X to the distribution on X × X which takes the value 1 at (x, x) and
7

0 everywhere else. The terminal object I is the set with a single element
i.e. I = {∗} and as a consequence we can identify Dist(I) with I. We
deﬁne delX to be the map that sends every element x ∈X to ∗. Lastly,
given morphisms f : X →Y and g : Y →Z, we deﬁne the composition
f; g : X →Z to be such that for every x ∈X,
(f; g)(x)(z) :=
X
y∈Y
g(y)(z)f(x)(y).
Observe that Dist deﬁnes an endofunctor on the category of Finite sets.
One can check without diﬃculty that it is in fact a commutative monad.
It follows that FinStoch coincides with the Kleisli category Kl(Dist).
2. To deal with distributions whose supports are not necessarily ﬁnite, we
introduce Stoch whose objects are measurable spaces i.e. tuples of the
form (X, ΣX) where X is a set and ΣX is a well deﬁned σ-algebra on X.
Recall that the category of measurable spaces is endowed with a natural
symmetric monoidal structure given by
(X, ΣX) ⊗(Y, ΣY ) := (X × Y, ΣX ⊗ΣY )
where ΣX ⊗ΣY corresponds to the σ-algebra generated by subsets of the
form U × V where U ∈ΣX and V ∈ΣY .
A morphism (X, ΣX) →(Y, ΣY ) in Stoch is given by a map
f : X × ΣY →[0, 1]
such that for every S ∈ΣX, the map f(S, ): X →[0, 1] is measurable.
Furthermore, we ask that for every x, f( , x): ΣY →[0, 1] is a well de-
ﬁned probability measure. One checks that Stoch is a symmetric monoidal
category whose monoidal structure is inherited from the category of mea-
surable spaces. The unit object I is the pair ({∗}, {{∗}, ∅}).
As before, we must deﬁne copy and delete morphisms as well as specify
how to compose morphisms in Stoch.
We do not deﬁne del as this is
obvious from the deﬁnition of I. Given (X, ΣX) ∈Ob(Stoch), we deﬁne
copyX : (X × X) × ΣX×X →[0, 1]
as the map that sends a pair (S, x) to 1 if (x, x) ∈S and 0 otherwise.
Lastly, given morphisms f : (X, ΣX) →(Y, ΣY ) and g : (Y, ΣY ) →(Z, ΣZ),
we deﬁne f; g to be the map X × ΣZ →[0, 1] to be given by
(S, x) 7→
Z
g(S, y)f(dy, x)
where we abuse notation and write f(x) for the measure ΣY →[0, 1] given
by T 7→f(T, x).
Deﬁnition 2.4. Let πX⊗Y : I →X ⊗Y be a joint state. A disintegration of
πX⊗Y will be a pair consisting of a channel f : X →Y and a state πX : I →X
8

such that the following string diagrams are equal.
X
Y
πX⊗Y
=
X
X
X
Y
πX
f
(1)
If every joint state admits a disintegration then we say that the category C
admits conditional distributions.
Likewise, given a pair f : X →Y and ψ: I →X, we can easily deﬁne a state
on X × Y via the following string diagram.
X
X
X
Y
ψ
f
We refer to this as the jointiﬁcation of f and ψ.
We will require a more general version of conditionalization which permits
us to consider joint distributions parametrized by another object.
Deﬁnition 2.5. Let C be a Markov category. We say that C has conditionals
if for every morphism s: A →X ⊗Y , there is t: X ⊗A →Y such that we have
the following equality of string diagrams.
A
X
Y
s
=
A
A
A
X
Y
X
X
Y
s
t
(2)
Remark 2.6.
In the case of FinStoch, we see that a state πX×Y : I →X × Y
corresponds to a probability distribution on X × Y . Furthermore, a disinte-
gration of πX×Y is given by the conditional distribution associated to the joint
distribution as well as the state πX : I →X obtained by marginalizing y in
πX×Y . We deﬁne the conditional distribution c: X →Y explicitly by setting
c(x)(y) := πX×Y (x, y)
πX(x)
9

if πX(x) is not zero and in the event that πX(x) = 0, we set c(x)( ) to be any
distribution on Y .
Another category which admits conditionals is the category BorelStoch which
is a subcategory of the category Stoch whose objects are standard Borel spaces.
Observe from the explicit calculation above that the disintegration of a joint
distribution is not necessarily unique. This leads us to the following deﬁnition.
Deﬁnition 2.7. Let πX : I →X be a state on an object X ∈Ob(C). Let
f, g : X →Y be morphisms in C. We say that f is almost surely equal to g with
respect to πX or f ∼πX−a.s g if the following string diagrams coincide.
πX
f
=
πX
g
Observe that if πX×Y : I →X×Y is a state and πX : I →X is the associated
marginal then if f, g : X →Y are channels such that (f, πX) and (g, πX) are
both disintegrations with respect to πX×Y then f is πX-almost surely equal to
g.
Deﬁnition 2.8. Let πX : I →X be a state on an object X ∈Ob(C). Let
f : X →Y be a channel.
The Bayesian inversion of f with respect to πX
is a channel f †
πX : Y →X such that we have the following equality of string
diagrams. We say that C admits Bayesian inversions if for every state πX : I →
X and f : X →Y we have a Bayesian inversion f †
πX : Y →X.
Note that we can rephrase the deﬁnition above in terms of disintegrations as
follows. Indeed, if c and πX are as in the deﬁnition then the Bayesian inversion
c†
πX can be obtained by disintegrating the joint distribution πX×Y : I →Y × X
obtained by swapping the integration of the pair (c, πX).
Remark 2.9. As for disintegrations, we see that Bayesian inversions are not
necessarily unique.
However, if c1, c2 are Bayesian inversions of a channel
c: X →Y with respect to a state πX : I →X then c1 is almost surely equal to
c2.
2.2.1
The category PS
A crucial requirement of our set up that allows us to deﬁne the BayesLearn
functor similar to the Gradient learn functor from [3] is that Bayesian inversions
must compose strictly. To this end, we must move away from working with
equivalence classes of almost surely equal morphisms with respect to a given
state and instead use the category PS (cf. [8, Deﬁnition 13.8]).
Deﬁnition 2.10. Suppose that C is causal (cf.[8, Deﬁnition 11.31]).
Then
the category ProbStoch(C) is deﬁned as follows. The objects of ProbStoch(C)
consist of pairs (X, πX) where X ∈Ob(C) and πX : I →X is a state on X.
A morphism in ProbStoch(C) between objects (X, πX) and (Y, πY ) consists of
10

a map f : X →Y in C satisfying πX; f = πY modulo πX-a.s. equality, with
composition inherited from C i.e.
ProbStoch(C)(X, Y ) := {f ∈C(X, Y )|πX; f = πY }/∼πX−a.s
As mentioned in the introduction, we write PS in place of ProbStoch for
ease of notation.
Remark 2.11. Note that the categories Stoch and FinStoch are both causal. It
is important to observe that if a category admits conditionals then it is causal.
However the converse is not true (cf. [8, 11.34, 11.35]).
Remark 2.12. Recall from [8, Proposition 13.9(a)] that if C is causal then
PS(C) is symmetric monoidal. In this case, the unit object is given by the pair
(I, ι) where ι: I →I is the identity map in C.
2.3
The Para construction
Recall that our goal is to understand conditional distributions between random
variables or morphisms in a Markov category that satisﬁes certain constraints.
In this setting, we model a conditional distribution p(y|x) using a parametric
function f(x; θ) while our learning algorithm updates θ using the given training
set. The notion of parametrized function has a natural formulation in category
theory which we call Para which was ﬁrst introduced in [7]. We use the more
generalized version of this construction which can be found in [1].
Observe
that the type of the parameter θ need not coincide with that of the variable.
To ensure that this observation is preserved in the categorical formulation, we
make use of the notion of actegories.
Deﬁnition 2.13. Let (M, J, ⋆) be a symmetric monoidal category and let C be
a category.
1. We say that C is an M-actegory if we have a strong monoidal functor
Φ: M →End(C) where End(C) is the category of endofunctors on C for
which the monoidal product is given by composition. Given M ∈Ob(M)
and X ∈C, we write M ⊙X := Φ(M)(X).
2. We say that C is a symmetric monoidal M-actegory if in addition to being
an M-actegory C is endowed with natural isomorphisms
κM,X,Y : M ⊙(X ⊗Y ) ≃X ⊗(M ⊙Y )
satisfying coherence laws reminiscent of the laws of a costrong comonad.
Remark 2.14.
Part (2) of Deﬁnition 2.13 is from [1, §2.1 Deﬁnition 4]. As in
this reference, we point out that if (C, I, ⊗) is a symmetric monoidal (M, J, ⋆)-
actegory then we have natural isomorphisms
αM,X,Y : M ⊙(X ⊗Y ) ≃(M ⊙X) ⊗Y
and
ιM,N,X,Y : (M ⋆N) ⊙(X ⊗Y ) ≃(M ⊙X) ⊗(N ⊙Y )
which are called the mixed associator and the mixed interchanger respectively.
11

Deﬁnition 2.15. [1, §Deﬁnition 2] Let M be a symmetric monoidal category
and let C be an M-actegory. The bicategory ParaM(C) is deﬁned as follows.
• Ob(ParaM(C)) := Ob(C).
• A 1-cell f : X →Y in ParaM(C) consists of a pair (P, φ) where P ∈
Ob(M) and φ: P ⊙X →Y is a morphism in C.
• Let (P, φ) ∈ParaM(C)(X, Y ) and (Q, ψ) ∈ParaM(C)(Y, Z). The com-
position (P, φ); (Q, ψ) is the map in C
Q ⊙(P ⊙X) →Z
given by
Q ⊙(P ⊙X)
φ−→Q ⊙Y
ψ−→Z
• Let (P, φ), (Q, ψ) ∈ParaM(C)(X, Y ). A 2-cell α: (P, φ) →(Q, ψ) is given
by a morphism α′ : Q →P such that the following diagram commutes.
Q ⊙X
P ⊙X
Y
α′⊙idX
ψ
φ
• The identity and composition in the category ParaM(C)(X, Y ) are inher-
ited from the identity and composition in M.
By [1, Proposition 3, §2], ParaM( ) deﬁnes a pseudo-monad on the category
M −Mod of M-actegories. In particular, if we have a functor
F : C →D
we get an associated functor
ParaM(F): ParaM(C) →ParaM(D)
We make use of this fact when we deﬁne the BayesLearn functor in §3.
3
Bayes Learn
In this section we outline the construction of the functor BayesLearn which
aims to capture the essential features of Bayesian learning. However in order
for us to discuss these results, we require certain preliminary ideas which allow
us to better understand the actegory structure on PS(C) where C is a Markov
category.
3.1
Inducing the M-actegory structure
While we work with the ﬂexibility provided by ParaM, we must be careful to
ensure that the categories to which we apply ParaM( ) are endowed with the
structure of an M-actegory. To this end, we must make certain modiﬁcations
to the category M itself as we would ﬁrstly like to ensure that parameter spaces
have a well deﬁned prior associated to them.
12

Remark 3.1.
It follows directly from the deﬁnition of an actegory that if
r: M →N in M and f : X →Y in C then the following diagram commutes.
M ⊙X
M ⊙Y
N ⊙X
N ⊙Y
M⊙f
r⊙X
r⊙Y
N⊙f
where the vertical morphisms are due to the natural transformation between
the functors M ⊙
and N ⊙
induced by the morphism M →N. We write
f ⊙g to denote the composition M ⊙X →M ⊙Y →N ⊙Y or equivalently
M ⊙X →N ⊙X →N ⊙Y .
The following technical condition is required in the proof of Lemma 3.3.
Deﬁnition 3.2. Let (M, J, ⋆) and (C, I, ⊗) be Markov categories and let C be
a symmetric monoidal M-actegory (cf. Deﬁnition 2.13). We say that C is in
agreement with M if for every P ∈M and X ∈C, the following diagram is
commutative and natural in both P and X.
P ⊙X
(P ⋆P) ⊙(X ⊗X)
P ⊙X
(P ⊙X) ⊗(P ⊙X)
copyP ⊙copyX
ιP,P,X,X
copyP ⊙X
where ιP,P,X,X is the mixed interchanger as introduced in 2.14.
Recall from 2.1, that a categorical formulation of Bayesian learning must
capture the notion of state on the parameter as well as a means to update it
via Bayesian inversion. It is hence natural under these circumstances to utilize
PS(M) as the category of parameters. A brief discussion of the PS construction
was made in 2.2.1.
Lemma 3.3. Let (M, J, ⋆) be a causal Markov category and (C, I, ⊗) be a
Markov category that is in agreement with M. The category PS(C) is a PS(M)-
actegory.
Proof. Let (P, πP ) ∈Ob(PS(C)). We deﬁne an endofunctor
(P, πP ) ⊙: PS(C) →PS(C)
as follows. Firstly, let (X, πX) be an object in PS(C). We set (P, πP ) ⊙(X, πX)
to be the pair
I
∼
−→J ⊙I
πP ⊙πX
−−−−−→P ⊙X
where the ﬁrst isomorphism is due to the M-actegory structure on C. Observe
that the composition above coincides with
I
∼
−→J ⊙I
πP ⊙id
−−−−→P ⊙I
id⊙πX
−−−−→P ⊙X.
(3)
13

We check that (P, πP ) ⊙
deﬁnes a functor. Suppose f : (X, πX) →(Y, πY ) in
PS(C). The morphism πY : I →Y coincides with the composition I
πX
−−→X
˜f−→Y
where ˜f is a representative of the equivalence class of f in C. Applying P ⊙
gives
P ⊙I
id⊙πX
−−−−→P ⊙X
id⊗˜f
−−−→P ⊙Y.
Hence we get a sequence of morphisms
I
∼
−→J ⊙I
πP ⊙id
−−−−→P ⊙I
id⊙πX
−−−−→P ⊙X
id⊙˜
f
−−−→P ⊙Y.
(4)
Using the observation in Equation (3) and the fact that πX; ˜f = πY , we deduce
that Equation (4) coincides with (P, πP ) ⊙(Y, πY ). We have thus shown that
we have a map
(P, πP ) ⊙˜f : (P, πP ) ⊙(X, πX) →(P, πP ) ⊙(Y, πY )
in PS(C). Note that we must show that the map (P, πP ) ⊙(X, πX) →(P, πP ) ⊙
(Y, πY ) we have deﬁned above is independent of our choice of ˜f. Hence we verify
that if h, g : X →Y are morphisms in C such that h ∼πX−a.s g then (P, πP ) ⊙
h ∼πP ⊙πX−a.s (P, πP ) ⊙g. Since h ∼πX−a.s g, we get that the compositions
A := I →X →X ⊗X
h⊗id
−−−→Y ⊗X
and
B := I →X →X ⊗X
g⊗id
−−−→Y ⊗X
coincide. Consider the sequence
C := J
πP
−−→P
copyP
−−−−→P ⊗P
id
−→P ⊗P
in M. Since A = B, we see that C ⊙A = C ⊙B. However, this implies that
I →P ⊙X
copyP ⊙copyX
−−−−−−−−−→(P ⋆P) ⊙(X ⊗X)
id⊙(h⊗id)
−−−−−−→(P ⋆P) ⊙(Y ⊗X)
coincides with
I →P ⊙X
copyP ⊙copyX
−−−−−−−−−→(P ⋆P) ⊙(X ⊗X)
id⊙(g⊗id)
−−−−−−→(P ⋆P) ⊙(Y ⊗X).
It follows that
I →P ⊙X
copyP ⊙X
−−−−−−→(P ⊙X) ⊗(P ⊙X)
(P ⊙h)⊗id
−−−−−−→(P ⊙Y ) ⊗(P ⊙X)
coincides with
I →P ⊙X
copyP ⊙X
−−−−−−→(P ⊙X) ⊗(P ⊙X)
(P ⊙g)⊗id
−−−−−−→(P ⊙Y ) ⊗(P ⊙X).
This is a consequence of the naturality of the agreement (cf. Deﬁnition 3.2) and
mixed interchanger morphisms (cf. Remark 2.14). This veriﬁes that (P, πP ) ⊙
f ∼πP ⊙πX−a.s (P, πP )⊙g. One checks without diﬃculty that (P, πP )⊙respects
composition of morphisms, identities and that
(P, πP ) ⊙: PS(C) →PS(C).
14

is indeed a well deﬁned functor. Furthermore, using the notation from Remark
2.12, (J, ι) ⊙
coincides with the identity on PS(C) and we have a natural
isomorphism idPS(C)
∼
−→(J, ι) ⊙
which is induced by the isomorphism idC
∼
−→
J ⊙.
Lastly, let (P, πP ), (Q, πQ) ∈PS(M) and (X, πX) ∈PS(C). Since we have a
strong monoidal functor P ⊙(Q⊙)
∼
−→(P ⋆Q)⊙, we deduce that the following
diagram is commutative.
I
J ⊙I
J ⊙(J ⊙I)
P ⊙(Q ⊙X)
I
J ⊙I
(J ⋆J) ⊙I
(P ⋆Q) ⊙X.
∼
∼
πP ⊙(πQ⊙πX)
∼
∼
(πP ⋆πQ)⊙πX
We deduce from this and similar such arguments that we have an isomorphism
(P, πP ) ⊙((Q, πQ) ⊙)
∼
−→((P, πP ) ⋆(Q, πQ)) ⊙
making the functor
PS(M) →End(PS(C))
given by
(P, πP ) 7→(P, πP ) ⊙
a strong monoidal functor. This concludes the proof.
Lemma 3.4. Let (A, I, ⊗) and (M, J, ⋆) be symmetric monoidal categories such
that A is an M-actegory. Let
S : Aop →M −Mod
be a functor which takes values in the category of M-actegories. We suppose
that S satisﬁes the following property.
1. There exists an M-actegory B such that for every X ∈Ob(A), S(X) = B.
2. For every M ∈Ob(M), X, Y ∈Ob(A), f ∈A(X, Y ), A ∈Ob(S(X)) and
B ∈Ob(S(Y )), we have that
M ⊙S(f)(B) = S(M ⊙f)(M ⊙B)
The Grothendieck lens LensS is then an M-actegory.
Note that in the statement of the above lemma, condition (2) only makes
sense if we have condition (1).
Proof. Recall that the objects of LensS are tuples of the form (X, A) where X
is an object in A and A ∈Ob(S(X)). Given M ∈Ob(M), we deﬁne
M ⊙(X, A) := (M ⊙X, M ⊙A).
We show that M ⊙
deﬁnes an endofunctor on LensS. Let f : (X, A) →(Y, B)
be given by a pair of morphisms f : X →Y and a map f ∗: S(f)(B) →A. We
deﬁne
M ⊙f : M ⊙(X, A) →M ⊙(Y, B)
15

in LensS as follows. Since M is a M-actegory, we have a morphism
M ⊙f : M ⊙X →M ⊙Y
and a morphism
M ⊙f ∗: M ⊙S(f)(B) →M ⊙A.
We apply the assumption on S to get
M ⊙f ∗: S(M ⊙f)(M ⊙B) →M ⊙A.
The pair (M ⊙f, M ⊙f ∗) deﬁnes a morphism M ⊙(X, A) →M ⊙(Y, B) in
LensS. Clearly, M ⊙
preserves identities. One checks without diﬃculty that
M ⊙
respects compositions as well. We have thus shown that M ⊙
deﬁnes
an endofunctor on LensS.
It remains to show that the morphism M →End(LensS) is a strong monoidal
functor. Firstly, using that A is a M-actegory and for every X ∈Ob(A), S(X)
is a M-actegory, we deduce that if J is the unit object of M then J ⊙
is
naturally isomorphic to the identity endofunctor. In a similar fashion, given
N, M ∈Ob(M) and (X, A) in LensS we verify that we have a natural isomor-
phism of endofunctors
N ⊙(M ⊙(X, A))
∼
−→(N ⋆M) ⊙(X, A).
This concludes the proof.
3.2
Bayes Learn
Let C be a Markov category which admits conditionals. Note that this is equiv-
alent to saying that C admits Bayesian inversions. Since Bayesian inversions in
general are deﬁned up to an equivalence relation, we restrict our attention to
the category PS(C) (cf.§2.2.1). In fact, in this case, Bayesian inversion deﬁned a
symmetric monoidal dagger functor on PS(C) in the sense of dagger categories.
We refer the reader to [8, Remark 13.10].
Recall from [3], the basis of the gradient learning functor GL comes from a
functor
R: C →Lens(C)
where in this case C is a Cartesian reverse diﬀerential category. In our situation,
we can mirror this construction via the mechanism of Bayesian inversion and
the notion of generalized lenses. We proceed below in greater detail.
As above, our goal is to deﬁne a functor
R: PS(C) →LensF
where LensF is the F-lens associated to a functor
PS(C)op →Cat
(cf. [10]).
16

3.2.1
The functor Stat
We deﬁne the functor
Stat: PS(C)op →Cat
as follows. Given X ∈Ob(PS(C)), let
Stat(X) := PS(C).
Given a map f : X →Y in PS(C), the natural transformation F(Y ) →F(X) is
the identity functor.
Remark 3.5. Observe that our deﬁnition of Stat coincides with the deﬁnition
of Stat from [9]. Indeed, since C is Markov, the unit I is a terminal object and
hence there is a unique state ι: I →I. We simplify notation as above and write
I in place of (I, ι). PS(C)(I, (X, πX)) hence consists of a single element corre-
sponding to the state πX. If X ∈PS(C) and (A, πA), (B, πB) ∈Ob(Stat(X))
then a morphism f : (A, πA) →(B, πB) in Stat(X) coincides with a morphism
of sets
PS(C)(I, (X, πX)) →PS(C)((A, πA), (B, πB))
since PS(C)(I, (X, πX)) is the singleton set. This is precisely how Stat is deﬁned
in [9].
3.2.2
The Grothendieck Lens
Let LensStat be the lens associated to the functor Stat as introduced in [10,
§3.1]. More precisely, we have that
• The objects of the category LensStat are pairs ((X, πX), (A, πA)) where
(X, πX) ∈PS(C) and (A, πA) ∈Stat(X).
• A morphism φ: ((X, πX), (A, πA)) →((Y, πY ), (B, πB)) is given by a mor-
phism (X, πX) →(Y, πY ) in PS(C) and a morphism (B, πB) →(A, πA) in
Stat(X) = PS(C).
One checks that this is a well deﬁned category and is an instance of the Grothendieck
construction as in [10, §3.1].
Remark 3.6. The category LensStat simpliﬁes considerably in our situation.
LensStat ≃PS(C) × PS(C)op
3.2.3
The functor R
We deﬁne the functor
R: PS(C) →LensStat
as follows.
• Given (X, πX) ∈PS(C), we set R((X, πX)) := ((X, πX), (X, πX)).
• If f : (X, πX) →(Y, πY ) is a morphism in PS(C) then the map
R(f): ((X, πX), (X, πX)) →((Y, πY ), (Y, πY ))
in LensStat is deﬁned to be the pair (f, f †
πX) where f †
πX is the Bayesian
inversion of f with respect to the state πX on X. Note that this simpliﬁ-
cation is a consequence of our discussion above.
17

Proposition 3.7. The functor R is well deﬁned.
Proof. We must essentially verify that R behaves well with regards to compo-
sition. This is a consequence of the fact that in the category PS(C), Bayesian
inversions are unique and their composition is indeed well deﬁned.
3.2.4
The functor BayesLearn
Let M and C be Markov categories with M causal. To deﬁne BayesLearn, we
now specialize to the case where C is a symmetric monoidal M-actegory which
in addition is in agreement with M.
Since M is causal, PS(M) is a well deﬁned symmetric monoidal category. By
Lemmas 3.3 and 3.4, the categories PS(C) and LensStat are PS(M)-actegories.
Recall from Section 2.3 that ParaPS(M)( ) is a well deﬁned functor which when
applied to R gives a functor
ParaPS(M)(R): ParaPS(M)(PS(C)) →ParaPS(M)(LensStat)
Recall that if (P, J, ⋆) is a symmetric monoidal category then a P-actegory
A admits a canonical functor jP,A : A →ParaP(A) given by A 7→J ⊙A. Note
that jP,A is the unit for the pseudo-monad deﬁned by ParaP(·). We thus have
a diagram
C
PS(C)
LensStat
Para(PS(C))
Para(LensStat)
R
jPS(M),C
jPS(M),LensStat
ParaPS(M)(R)
Deﬁnition 3.8. We deﬁne
BayesLearn := ParaPS(M)(R).
Remark 3.9. Observe that the BayesLearn functor in §3.2.4 does not have an
update or displacement endofunctor as the Gradient learning functor from [3,
§3.5]. This is due to the relatively simpliﬁed nature of Bayesian learning where
parameter updates correspond to obtaining the posterior distribution using the
prior and the likelihood and not as a result of optimizing with respect to a loss
function. Equivalently, in the categorical setting, Bayesian inversion provides
an update rule without recourse to a displacement or error endofunctor.
Remark 3.10. Note that when we contrast the Bayesian learning framework
described above with the gradient learning framework described in [3], we see
that Bayesian learning is considerably simpler. By using the Grothendieck lens
in place of the standard Lens construction and ProbStoch(C) in place of C,
the existence of Bayesian inversion as a dagger functor implies the breakdown
of the functor Stat resulting in the simpliﬁed form of LensStat as described in
Remark 3.6. In addition, the absence of error and update endofunctors further
distinguishes the Bayes Learning framework. In this sense, we believe Bayesian
learning to be the simplest case of the categorical learning as described in [3].
18

Remark 3.11. Lemma 3.4 provides PS(C) with the structure of a PS(M)-
actegory. However, by deﬁning Stat for the category M which we denote StatM,
we also get that
LensStatM ≃PS(M) × PS(M)op.
Hence LensStatC in fact has the structure of LensStatM-actegory. Since we are
interested only in the BayesLearn functor and in particular its image, we do not
concern ourselves with this more general action of LensStatM.
Note also that we can endow PS(C) with the structure of LensStatPS(M)-
actegory via the projection
LensStatM →PS(M).
This implies that we can also view LensStatC as a LensStatM-actegory in line
with the theory from [1].
3.3
Bayes Learning algorithm
We now detail the Bayes Learning algorithm in our current setup. We preserve
our assumptions on C and M from the previous section. We are given training
data which consists of objects XT and YT in C and a joint distribution ωT : I →
XT ⊗YT . We would like to perform inference for objects X∗and Y∗in C. We
are also provided with states πX∗: I →X∗and πXT : I →XT where πXT is
obtained by marginalizing ωT . Note that in practice XT = X∗and YT = Y∗We
proceed as follows.
1. We model the given data by choosing a function f : XT →YT in ParaM(C).
This corresponds to a morphism f : M ⊙XT →YT . We assume that model
satisﬁes a technical assumption which we precise in (2). We assume we
have a similar model applicable for the inference data i.e. f∗: M ⊙X∗→
Y∗.
2. The morphism f descends to give a morphism in the category PS(C)
as follows. Firstly, we endow M with a prior distribution i.e.
a state
πM : J →M. The morphism πM ⊙πXT : I ≃J ⊙I →M ⊙XT deﬁnes
a state on M ⊙XT . By composing with f we obtain a state on YT i.e.
a morphism πYT := (πM ⊙πXT ); f : I →YT . We assume that the model
f and the prior πM were chosen so as to guarantee that πYT coincides
with the marginal distribution on YT from ωT . The equivalence class of f
deﬁnes a morphism (M, πM) ⊙(XT , πXT ) →(YT , πYT ). Equivalently, we
have a map in ParaPS(M)(PS(C)).
3. By construction,
BayesLearn(f) := (f, f †)
is a morphism in ParaPS(M)(LensStat) between objects ((XT , πXT ), (XT , πXT ))
and ((YT , πYT ), (YT , πYT )). Let
f † : (YT , πYT ) →(M, πM) ⊙(XT , πXT )
denote the corresponding inversion.
19

4. Recall that in §2.1, we outlined how to leverage the posterior distribution
to make predictions. This can be formalized in a categorical setting as
follows. Consider the composition
(YT , πYT ) ⊗(X∗, πX∗)
f †⊗id
−−−−→((M, πM) ⊙(XT , πXT )) ⊗(X∗, πX∗)
≃(XT , πXT ) ⊗((M, πM) ⊙(X∗, πX∗))
The isomorphism above is obtained by composing the isomorphisms
((M, πM) ⊙(XT , πXT )) ⊗(X∗, πX∗)
(i)
≃(((M, πM) ⊙I) ⊗(XT , πXT )) ⊗(X∗, πX∗)
(ii)
≃((XT , πXT ) ⊗((M, πM) ⊙I)) ⊗(X∗, πX∗)
(iii)
≃(XT , πXT ) ⊗(((M, πM) ⊙I) ⊗(X∗, πX∗))
(iv)
≃(XT , πXT ) ⊗((M, πM) ⊙(X∗, πX∗))
where (i) is due to the mixed associator, (ii) is because of the swap isomor-
phism, (iii) is a consequence of the associative property of the monoidal
product and (iv) is obtained by applying the mixed associator again.
We conditionalize the morphsim to get a morphism
(XT , πXT ) ⊗(YT , πYT ) ⊗(X∗, πX∗) →(M, πM) ⊙(X∗, πX∗)
By composing on the right by f∗, we get
(XT , πXT ) ⊗(YT , πYT ) ⊗(X∗, πX∗) →(Y∗, πY∗).
This is the Bayes predictive distribution.
By pre-composing with the
state πXT ⊗πYT , we get a map (X∗, πX∗) →(Y∗, πY∗).
We call this
the full predictive distribution obtained by averaging out the predictive
distributions as they vary over diﬀerent instances of the training data.
Example 3.12. Let us work within the category BorelStoch which is the sub-
category of Stoch from Example 2.3. We make this restriction because Borel-
Stoch admits conditionals. In BorelStoch, we can view a morphism f : A →B
as deﬁning a conditional distribution p(b|a).
Let X and Y be Borel spaces. Our training data consists of a list T :=
[(x1, y1), . . . , (xn, yn)] of points in List(X ×Y ). To align with our notation from
§3.3, we write XT and YT to be copies of X and Y and endow XT × YT with
the empirical distribution obtained from T. Our goal is to obtain an estimate
of the conditional probability p(y∗|x∗) for general points x∗∈X∗and y∗∈Y∗.
As for the training set, let X∗and Y∗be copies of X and Y respectively which
we use for inference.
As outlined in §3.3 and §2.1, we model the given data via a parametrized
function of the form f : P ×XT →YT where P ∈BorelStoch. We endow P with
a prior distribution i.e. a state πP : I →P where I = {∗} is the unit object. We
must update the prior p to get the posterior distribution. This is accomplished
via the Bayesian inversion f † : YT →P × XT . Note that f † is not unique. By
20

conditionalizing, we get a map XT × YT →P in BorelStoch which deﬁnes the
posterior.
In this case, the Bayes predictive density as described in §3.3 is given by
p(y∗|x∗, T ) =
Z
P
p(y∗|P, x∗, T )p(P|x∗, T ).
This is a consequence of how compositions are deﬁned in Stoch i.e. via the
Chapman-Kolmogorov equation cf. §2.3.
4
Bayes updates
While Section 3.3 describes the Bayes Learning algorithm, we observe that it
does not provide a mechanism by which we can update the prior on the pa-
rameter space. Recall, via Bayesian inversion we obtain a channel (XT , πXT ) ⊗
(YT , πYT ) →(M, πM). However, in practice, when working in a suitable sub-
category of Stoch or in FinSet, we are given a training set
T := {(x1, y1), . . . , (xn, yn)}
which we use to obtain the posterior distribution on M. Our goal in this section
is to translate this into the categorical framework we have developed so far.
In the case of Stoch, we can represent a data point (x, y) ∈XT × YT as
the product of a pair of morphisms I →XT and I →YT mapping ∗to the
probability measures that concentrate at the points x and y respectively. We
use δx,δy respectively to denote these maps. Given a channel c: X × Y →M in
Stoch, we deﬁne a state on M via the composition
I →I × I
δx1×δy1
−−−−−→X × Y
c−→M.
This eﬀectively deﬁnes the posterior on M given the training set T1 where T1 :=
{(x1, y1)}. The natural question to ask in this setting is how to sequentially
update the posterior to achieve the required update over the entire training
dataset and if one can also achieve such an update all at once. We outline a
possible solution in what follows.
For the remainder of this section we work with a Markov category (C, I, ⊗)
such that C = Kl(P) where P : D →D is a symmetric monoidal monad on
the symmetric monoidal category (D, ID, ∗). Furthermore, we suppose that C
admits conditionals. As before, let (M, J, ⋆) be a symmetric monoidal category
such that C is a symmetric monoidal M-actegory.
We are given a model i.e. a morphism f : M ⊙X →Y in C where we think
of M ∈Ob(M) as the parameter space and f models a true morphism X →Y .
We suppose as before that we are provided with a state πX : I →X and a prior
πM,0 : J →M. Lastly, we abuse notation and write M in place of M ⊙I when
necessary. Note a prior πM : J →M implies a prior πM ⊙id: J ⊙I →M ⊙I
which we also refer to as πM.
4.1
Sequential updates
Recall from Deﬁnition 2.4 that the state πX and the channel f give us a mor-
phism
fjoint: M ⊙I →X ⊗Y
(5)
21

in C. Since C admits conditionals, it also admits Bayesian inversions. Hence,
we get a morphism
f †
joint : Z →M ⊙I
with respect to the prior state πM,0 on M where Z := X ⊗Y .
Note that f †
joint is not unique. In the previous section, we got around this
issue by working in the category PS(C). However, if we want to update the
state on M sequentially then this corresponds to sequentially updating objects
in PS(M) which will then require us to update the model f or more precisely its
image in PS(C). Instead, we introduce Deﬁnition 4.1 to ensure that the updated
priors remain well deﬁned.
Recall that C = Kl(P) where P is a monad on the symmetric monoidal
category (D, ID, ∗). Since P is a monad, we have a family of maps ηX : X →
P(X) for every X ∈Ob(D). Given a map a: X →Y in D, let η(a) denote its
image in C i.e. the composition X
a−→Y
ηY
−−→P(Y ).
Deﬁnition 4.1. Let f : X →Y be a morphism in C and πX : I →X be a state
on X. Let y: ID →Y be a morphism in D. We say that the Bayesian inverse
of f is uniquely deﬁned at y if for any morphisms g, h: Y →X in C such that
g ∼πX−a.s h and g is a Bayesian inversion of f then η(y); g = η(y); h.
We refer to the morphism y that appears in the deﬁnition above as an
elementary point of the object Y . A precise deﬁnition is as follows.
Deﬁnition 4.2. Let Y be an object of C. By an elementary point of Y we
mean a morphism y: ID →Y in D. We use δy to denote the image of y in C
i.e. δy := η(y).
Example 4.3. We provide an example of Deﬁnition 4.1. Recall from Example
2.3, the category FinStoch. Note that FinStoch = Kl(Dist) where Dist: FinSet →
Finset is a symmetric monoidal monad on the symmetric monoidal category Fin-
Set whose objects are ﬁnite sets and morphisms are functions of sets. Let X
be a ﬁnite set, πX : I →X be a state on X and f : X →Y be a morphism
in FinStoch. By deﬁnition, πX corresponds to a probability distribution pX on
X while f deﬁnes a conditional distribution. Let y0 : I →Y be a morphism
in FinSet. It follows that y0 is uniquely determined by a point in Y which we
abuse notation for and call y0 as well. The Bayesian inversion g : Y →X is
deﬁned by
g(y)(x) =
f(x)(y)pX(x)
P
x′∈X f(x′)(y)pX(x′)
if P
x′∈X f(x′)(y)pX(x′) ̸= 0 and if y is such that P
x′∈X f(x′)(y)pX(x′) = 0
then g(y) can be any probability distribution on X. Thus we see in this situation
that the Bayesian inversion g is uniquely deﬁned at y0 if and only if
X
x′∈X
f(x′)(y0)pX(x′) ̸= 0.
In the case of the category Stoch, things are more complicated since it is not
always true that a Bayesian inversion exists. However, in certain cases where we
are working with subspaces of R and both state and channel are deﬁned using
density functions then a similar calculation as above can be performed (cf.[2,
Example 3.9]).
22

Let T := [x1 ⊗y1, . . . , xn ⊗yn] be a list of n elementary points of X ⊗Y
where for every i, zi := xi ⊗yi satisﬁes a property to be speciﬁed below. We
begin with a prior πM,0 on the parameter object M. Let us suppose that we
have obtained the i-th sequential update i.e. a state πM,i on M. We deﬁne
πM,i+1 as follows. By taking the Bayesian inversion of fjoint with respect to
πM,i, we get
f †
joint,i : X ⊗Y →M.
The state πM,i+1 on X ⊗Y is given by the composition
I
δxi+1 ⊗δyi+1
−−−−−−−−→X ⊗Y
f †
joint,i
−−−−→M
and we suppose that the point zi+1 is such that f †
joint,i is unique at zi+1.
Example 4.4. Let us demonstrate the sequential update procedure in the cat-
egory FinStoch acting on itself. As above, we are given model f : M × X →Y
where M, X and Y are ﬁnite sets and f is a morphism in FinStoch. This in-
duces a function fjoint : M →Z where Z := X × Y . Let us assume we are give
a training set
T := [(x1, y1), (x2, y2)]
and a prior state πM,0 on M. In this context, this means a probability distri-
bution on M. Let zi := (xi, yi).
1. For i = 1, we have that for m ∈M and z ∈Z,
f †
joint,0(z)(m)πZ,0(z) = fjoint(m)(z)πM,0(m)
where for z ∈Z,
πZ,0(z) =
X
m∈M
fjoint(m′)(z)πM,0(m′).
Recall our assumption that πZ,0(z1) ̸= 0. We update the prior by setting
πM,1(m) := f †
joint,0(z1)(m).
2. Likewise, for i = 2,
f †
joint,1(z)(m)πZ,1(z) = fjoint(m)(z)πM,1(m)
where for z ∈Z,
πZ,1(z) =
X
m∈M
fjoint(m′)(z)πM,1(m′).
Expanding using (1),
f †
joint,1(z2)(m) ∝fjoint(m)(z2)fjoint(m)(z1)πM,0(m)
We update the prior by setting π2(m) := f †
joint,1(z2)(m).
23

4.2
Batch updates
To obtain an update of the prior all at once, we work with an object built from
X ⊗Y but whose points correspond to datasets of a speciﬁed cardinality.
Let n ∈N and we set
Zn := ⊗n(X ⊗Y ).
The model f induces a morphism
f n
joint: M →Zn
deﬁned as the composition
M
⊗ncopyM
−−−−−−→⊗nM
⊗nfjoint
−−−−−→Zn.
As before, let T := [x1 ⊗y1, . . . , xn ⊗yn] be a list of n elementary points of
X ⊗Y . The list T deﬁnes an elementary point of Zn. Indeed, we set zT to be
the composition
ID
⊗ncopyID
−−−−−−−→⊗nID
z1⊗...⊗zn
−−−−−−→Zn
where as before zi = xi ⊗yi. We suppose T is such that the Bayesian inversion
of f n
joint is uniquely deﬁned at zT. The batch update of the prior πM,0 with
respect to T is given by the composition
I
δzT
−−→Z
(f n
joint)†
−−−−−→M
where (f n
joint)† is a Bayesian inversion of f n
joint with respect to the prior πM,0.
Let πM,T : I →M denote this updated prior.
We can ask the following question. Under what conditions, can we ensure
that πM,n = πM,T where πM,n is as deﬁned at the end of §4.1 for T.
Example 4.5. Let us continue our discussion as in Example 4.4 using the
category FinStoch. As in 4.4, we are given a model f : M ×X →Y where M, X
and Y are ﬁnite sets and f is a morphism in FinStoch, a training set
T := {(x1, y1), (x2, y2)}
and a prior state πM,0 on M. Let zi := (xi, yi) and zT := (z1, z2). We import
notation from 4.4.
It follows that
Z2 = (X × Y )2
and
f 2
joint : M →Z2.
Hence, we get that
(f 2
joint)† : Z2 →M.
For m ∈M and w ∈Z2,
(f 2
joint)†(w)(m) ∝f 2
joint(m)(w)πM,0(m).
We set
πM,T(m) := (f 2
joint)†((z1, z2))(m)
for m ∈M and hence
πM,T(m) ∝fjoint(m)(z2)fjoint(m)(z1)πM,0(m)
since by deﬁnition, f 2
joint(m)((a, b)) = fjoint(m)(a)fjoint(m)(b).
24

Remark 4.6. Observe from examples 4.4 and 4.5 that the sequential Bayes
update and batch update coincide. This begs the following question. What
conditions can we impose to relate the sequential and batch updates in the
general setting of the category C used throughout this section.
References
[1] Matteo Capucci, Bruno Gavranovi´c, Jules Hedges, and Eigil Fjeldgren
Rischel. Towards foundations of categorical cybernetics, 2021.
[2] Kenta Cho and Bart Jacobs.
Disintegration and bayesian inversion
via string diagrams.
Mathematical Structures in Computer Science,
29(7):938?971, 2019.
[3] G. S. H. Cruttwell, Bruno Gavranovic, Neil Ghani, Paul Wilson, and Ver-
sion 1 Fabio Zanasi. Categorical foundations of gradient-based learning,
2021.
[4] Giovanni de Felice, Alexis Toumi, and Bob Coecke. Discopy: Monoidal cat-
egories in python. Electronic Proceedings in Theoretical Computer Science,
333:183’
¨A`ı197, Feb 2021.
[5] Michael Evans and Tim B. Swartz. Methods for approximating integrals
in statistics with special emphasis on bayesian integration problems. Sta-
tistical Science, 10:254–272, 1995.
[6] Anita C. Faul and Michael E. Tipping. A variational approach to robust
regression. In Georg Dorﬀner, Horst Bischof, and Kurt Hornik, editors, Ar-
tiﬁcial Neural Networks — ICANN 2001, pages 95–102, Berlin, Heidelberg,
2001. Springer Berlin Heidelberg.
[7] Brendan Fong, David I. Spivak, and R´emy Tuy´eras. Backprop as functor:
A compositional perspective on supervised learning, 2019.
[8] Tobias Fritz. A synthetic approach to markov kernels, conditional inde-
pendence and theorems on suﬃcient statistics. Advances in Mathematics,
370:107239, 2020.
[9] Toby St. Clere Smithe. Bayesian updates compose optically, 2020.
[10] David I. Spivak. Generalized lens categories via functors Cop →Cat, 2020.
[11] ME Tipping. Bayesian inference: An introduction to principles and practice
in machine learning. pages 41–62, 01 2004.
25

