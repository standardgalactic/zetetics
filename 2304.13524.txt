TOWARDS REPLICATED ALGORITHMS
Iztok Fister Jr., Iztok Fister
Faculty of Electrical Engineering and Computer Science
University of Maribor
Slovenia
{iztok.fister1, iztok.fister}um.si
ABSTRACT
The main deﬁciency of the algorithms running on digital computers nowadays is their inability to
change themselves during the execution. In line with this, the paper introduces the so-called replicated
algorithms, inspired by the concept of developing a human brain. Similar to the human brain, where
the process of thinking is strongly parallel, replicated algorithms, incorporated into a population, are
also capable of replicating themselves and solving problems in parallel. They operate as a model for
mapping the known input to a known output. In our preliminary study, these algorithms are built as
sequences of arithmetic operators, applied for calculating arithmetic expressions, while their behavior
showed that they can operate in the condition of open-ended evolution.
Keywords replicated algorithms · human brain · open-ended evolution
1
Introduction
Phanta Rhei is probably one of the most important quotes in philosophy that was coined by Heraclitus. The term
Phanta Rhei is translated commonly as everything ﬂows, i.e. everything is changing, nothing is static. It can easily be
translated into different aspects of the universe, e.g. humans are changing through time; different material becomes
tired, even if we talk about steel. Everything in the universe is changing.
The concept of Phanta Rhei also opens the possibilities to think about the concept of computer programs. Nowadays,
computer programs run on digital computers, and are governed according to von Neuman architecture [1]. The
architecture divides the program into an algorithm and data, that are both stored into the primary memory during the
program’s execution. The algorithm consists of a sequence of program instructions capable of manipulating data, and
it is more or less considered as static pieces of source codes that are either compiled to machine code, or interpreted
by an interpreter and then executed. The main ingredients of the algorithm do not changing themselves during the
execution [2]. Actually, this lays unchanged into the primary memory and the developer is the only driving force for
making changes, ﬁxing bugs, making upgrades, or providing patches.
Human’s behavior is determined by their genetic information encoded into a genotype as a sequence of DNA [3].
Although the genetic code is unique for all living beings, an expression of genotype (i.e., phenotype) determining the
characteristics (i.e., traits) of a human depends on the conditions of the environment [4]. Moreover, more variants of the
genetic programs, based on the same genetic code, solve the same problem in parallel, while the thinking process in
the human brain decides what is the most proper for themselves according to its experiences [5]. Finally, the genetic
code is also robust on changes of the environment. This means that this must be resistant to conditions of open-ended
evolution, i.e., part of an artiﬁcial life, that searches for conditions where evolving systems never settle into a single
stable equilibrium [6].
The objective of this paper is to introduce the concept of the so-called replicated algorithms, capable of solving the
same problem in parallel. These algorithms are represented as a sequence of building blocks (similar to DNA) enabling
mapping of the known input to the known output data. Thus, the building blocks represent clues how to manage input
data to produce output, while the sequence encodes an algorithm. Moreover, the input and output data can be modiﬁed
dynamically during the execution of the algorithms by a user, while they need to be adapted to these modiﬁcations
arXiv:2304.13524v1  [cs.NE]  31 Mar 2023

Towards replicated algorithms
automatically. The replicated algorithms combined into a population are capable of being (self-)replicated, according to
rules based on some intelligent control similar to the process necessary for developing a human brain [7].
As a test-bed for veriﬁcation of the concept, searching for a population of algorithms was selected for solving simple
arithmetic expressions that are represented in preﬁx notation with a known input, and the corresponding result as the
output, where the algorithms are presented as a sequence of arithmetic operators for addition, subtraction, multiplication,
and integer division. An evolutionary algorithm was developed for an intelligent control that works on the population
of algorithms that replicate themselves using predeﬁned variation operators taken from evolutionary computation [8].
The preliminary results of the experimental study showed that the proposed replicated algorithms can operate in the
conditions of open-ended evolution [9] as well.
The main contributions of this paper are as follows:
• proposing a new concept of replicated algorithms,
• showing the bottlenecks of a paradigm "program = algorithm + data structure",
• evaluating the proposed concept in conditions of open-ended evolution.
2
Basic information
This section reviews background information needed for understanding the topics that follow.
2.1
Developing a human brain
The inspiration behind the introduction of the replicated algorithms is found in the operation of the human brain,
where a behavior of a particular human is described by a corresponding brain structure. The brain structure prescribes
how neurons are connected between each other, while developing the brain is governed by genes, i.e., a sequence of
nucleotides in DNA representing the basic units of heredity. However, the genes do not represent any blueprint for
structuring the brain, but are carriers of algorithmic information (i.e., intelligent control) for their development.
Indeed, two theories about developing brain exists, as follow [10]:
• predetermined:
Genes →Brainstructure →Brainfunction →Experience,
• probabilistic:
Genes ↔Brainstructure ↔Brainfunction ↔Experience,
The ﬁrst theory asserts that genes dictate the structure of the brain, which enables speciﬁc functions and thus determines
the kind of experience. According to the second theory, the experience can be inﬂuenced by the brain structure and
expression of genes, and vice versa. This means that the same genetic program in the same environment would not
produce an exact copy of behavior. For instance, identical twins have the similar, but not identical brains, and, indeed,
react differently in the same situation in the environment [11].
2.2
Epigenetic
The genetic code prescribes how to translate information encoded within DNA molecules into proteins. This code is
unique for all living beings. Although the translation of the code is ﬁxed, the expression of this is highly dynamic [11].
Indeed, the expression of the genetic code is inﬂuenced by the environment. The phenomenon is also termed as
epigenetic [12].
In general, the static genetic program may have a different expression. In the sense of computer programs, there are
many algorithm’s variants for how to transform the input data into the output. Usually, in computer theory, these are
distinguished according to their efﬁciency in the sense of time and space [13].
2.3
Artiﬁcial life
Artiﬁcial life refers to a scientiﬁc ﬁeld concerned with the strategy of artiﬁcial systems that mimics or manifests the
property of living systems during the long-term evolution [14]. Interest in this domain has increased with moving
the nature-inspired algorithms into the hardware [15]. This process was raised by the emergence of domains, like
Evolutionary Robotics (ER) and Swarm Robotics (SR). Both domains deal with the problems of how to avoid a loss of
population diversity that leads the evolutionary search process to get stuck into the local optima, and, consequently,
terminate this prematurely [16].
2

Towards replicated algorithms
3
Concept of replicated algorithms
A modeling problem, solved in the preliminary study, can be deﬁned formally as follows: Let a set of building blocks for
creating a universal algorithm and a mapping input data into output I 7→O be deﬁned. Then, the task of the modeling is
to ﬁnd a population of such algorithms that would be able to solve a given problem (i.e., I 7→O) in each moment, could
be adapted to new conditions of an environment, and, thus, resist the conditions of open-ended evolution. An inspiration
for the design of such a population was found in challenges of the Origin-Of-Life (OOL), asserting that living cells can
self-replicate, which, in turn, self-replicate the self-replicator, ad inﬁnitum [17]. Thereby, the concept of self-replication
is widened to the concept of replication, where the computer algorithm can replicate itself, the copies of which could
replicate themselves, and so on. In the sense of EC, the concept of self-replication is closer to asexual mutation as an
origin of the new algorithm, while the concept replication is broader, and refers to the bi-sexual crossover as well as
asexual mutation.
The design of the replicated algorithms is based on an intelligent control that controls a population of algorithms
capable of replicating themselves by using the variation operators (i.e., crossover and mutation), and thus enables them
to operate in conditions of open-ended evolution. In summary, the intelligent control is implemented as an evolutionary
algorithm working on population of individuals represented as variable sized sequences of steps, in which the given
problem can be solved.
Indeed, the characteristics of the replicated algorithms are as follows:
• each individual is represented as a variable sequence of building blocks similar to the genetic code,
• the knowledge is inherited from the sequences of building blocks,
• program is an independent unit, standalone, able to be ported to different machines,
• they are able to operate in conditions of open-ended evolution.
The concept of the replicated algorithms is illustrated in Fig. 1, from which it can be seen that the intelligent control
Figure 1: Concept of replicated algorithms.
controls a population of algorithms presented as a variable sized sequence of building blocks (i.e., clues) transforming
the known input data to the known output. Thus, the population of algorithms acts as a feed-back system, where the
ﬁtness function of each algorithm is presented as an error value measuring the difference between the desired output
and effective result of this.
4
Experiments and results
The goal of the experimental work was to show that the replicated algorithms are capable of solving real-world problems.
Furthermore, these algorithms can be replicated during the execution and thus evolve from the simple organization far
away from the given goal (i.e., the proper result) toward a complex organization capable of achieving this goal. Using
intelligent control, the population of algorithms is capable to resist in conditions of open-ended evolution as well.
In our preliminary study, the task of the intelligent control was to build an algorithm able to calculate the exact value of
an arithmetical expression from the operands entered as an input. Obviously, the algorithm consists of a sequence of
simple operators, like addition, subtraction, multiplication, and division that are represented in postﬁx notation, where
operator appears after the operands. The main advantage of this representation is implicit to considering the parentheses,
which leads to a faster calculation.
3

Towards replicated algorithms
The Evolutionary Control Algorithm (ECA) played the role of the intelligent control. Two population models were
employed by the ECA: a generational, and a steady-state [8]. The former exchanges the whole population with the
best individuals between the original and the mating pool populations, while the latter exchanges only the part of the
original population, i.e., the generational gap. In the last model, the algorithm can also be changed in the case that the
new formed individual from the mating pool is worse than the original one according to their ﬁtness value (i.e., the
non-elitist selection). Consequently, the non-elitist selection prevents the evolution process from getting stuck into the
local optima, and thus creates conditions for open-ended evolution.
The other parameters of the ECA were set during the experiments as illustrated in Table 2, where Dinit limits the
maximum algorithm’s size in the initial population, normally, determined randomly in the interval [1, Dinit], Np
presents the population size, nGen the maximum number of generations, pmut the probability of mutation, and the
generation gap 1/10, denoting that one of Np = 10 individuals in the steady-state model will be changed using the
crossover operator in each generation. However, the crossover probability pc is set to one, if the generational population
model is selected. In both cases, the one-point crossover is employed on variable-sized individuals. In a generational
Table 1: Evolutionary control algorithm setting.
Parameter
Symbol
Value
Maximum initial algorithm’s size
Dinit
10
Population size
Np
10
Generation number
nGen
1,000,000
Mutation probability
pm
0.1
Generational gap (Steady-state)
λ/Np
1/10
Crossover probability (Generational)
pc
1.0
population model, the elitist selection is employed, where the best between the trial and target individual survives into
the next generation. Let us mention that the set of input operands was deﬁned as I = {10, 20, 30} and the result as
O = {100}.
The results of the ECA using the generational population model and the elitist selection are illustrated in Table 2, from
Table 2: The results of the ECA using generational population model and elitist selection.
Nr.
Program
Fitness
1
∗10 10
0
2
∗10 10
0
3
∗10 10
0
4
∗10 10
0
5
∗10 10
0
6
∗10 10
0
7
∗10 10
0
8
∗10 10
0
9
∗10 10
0
10
∗10 10
0
which it can be seen that the population of algorithms converged fast to the optimal expression written in the inﬁx
notation as follows:
10 ∗10 = 100.
(1)
In contrast, the results of the ECA using the steady-state population model and non-elitist selection, as depicted in
Table 3, did not converge to the same optimal algorithm, but the ECA maintained the population of different algorithms
obtaining, almost in each independent run, the proper solution. This population shows that the ECA using the steady
state model and non-elitist selection can also persist in conditions of open-ended evolution.
Two examples of terms in population of programs maintained by the ECA are illustrated in Fig. 2, where the ﬁgure
is divided into two diagrams, and both diagrams consist of input operands, the algorithm for transforming the input
operands to the output result represented as numbers within squares, and the algorithm represented as a sequence of
circles with corresponding arithmetic operators. The diagram in Fig. 2(a) depicts the optimal program (Eq. 1), while
the diagram in Fig. 2(b) shows an example of the arithmetic expression that produces the proper result in open-ended
evolution.
4

Towards replicated algorithms
Table 3: The results of the ECA using the steady-state population model and non-elitist selection.
Nr.
Program
Fitness
1
+/20 30/ ∗−30 20 10/ ∗20 30 10
99
2
+/ ∗30 30 10 −30 20
0
3
+/ ∗30 20 10/ ∗20 20 10
0
4
+/20 30/ ∗∗10 20 10 20
0
5
+// ∗30 30 10/10 10 10
0
6
+// ∗30 30 10/ + 20 30/ ∗30 10 10 −30 20
0
7
+/ ∗30 30 10 −30 20 30 10 10
0
8
+//30 10 10/ ∗∗10 20 10 20
0
9
+// ∗30 30 10/ + 20 30 30 10
0
10
+//30 10 10/ ∗∗10 10 30 30
0
(a) Term 1.
(b) Term 2.
Figure 2: Two samples of terms from a population of programs.
4.1
Discussion
The results of the experiments showed that the population of replicated algorithms can solve problems in parallel.
Interestingly, the population of replicated algorithms under ECA using the generational population model converged to
the optimal algorithm (Eq. 1) in the sense of calculation without any external selection pressure. On the other hand,
the same population under ECA using the steady-state population model maintained high population diversity in most
independent runs. Thereby, two behaviors can be observed, i.e., the population either converges toward the optimal
solution, or starts to oscillate between the population members, and thus created conditions for open-ended evolution.
As a result, the necessary conditions for open-ended evolution, as observed in our study, can be reviewed as follows:
• the small population-size,
• the variable-sized representation of individuals,
• the steady-state population model.
The von Neumann architecture supposes that the algorithm loaded into memory stays unchanged during the execution,
and it can be changed only when the current instance of the program terminates, and the new version is made and
loaded into the primary memory again. The replicated algorithms, solving the problems in parallel, could be adapted to
the new condition of environment automatically.
However, two drawbacks may be connected with the current version: (1) the ﬁxed population size, and (2) external
intelligent control introduced by the ECA. Fortunately, both issues could be solved by changing the population members
into intelligent agents, while the intelligent control might be transferred from ECA to the intelligent multi-agent system.
5
Conclusion
This study introduces the concept of replicated algorithms capable of solving modeling problems in parallel. They work
under the control of an intelligent control (in our case ECA) that transforms the known input data into the proper results.
Thus, the algorithms in the population are presented as a sequence of orders, and each of them usually represents a
different solution to the problem. The results of the experiments by constructing the algorithm for controlling arithmetic
expressions showed that some conﬁgurations of them can also be employed in conditions of open-ended evolution.
Primarily, the potential directions for the future work are obviously eliminating the exposed drawbacks. This means that,
at ﬁrst, the central intelligent control should be distributed between the intelligent agents capable of making decisions
5

Towards replicated algorithms
based on local information only. Then, the multi-agent system should be implemented with a variable number of agents.
Secondly, conditions for open-ended evolution might also be discovered in detail.
References
[1] J. von Neumann. First draft of a report on the edvac. IEEE Annals of the History of Computing, 15(4):27–75,
1993.
[2] Herbert L. Roitblat. Algorithms Are Not Enough: Creating General Artiﬁcial Intelligence. The MIT Press, 10
2020.
[3] Simon Farrell and Stephan Lewandowsky. Computational Modeling of Cognition and Behavior. Cambridge
University Press, 2018.
[4] Thomas Bäck. Evolutionary algorithms in theory and practice - evolution strategies, evolutionary programming,
genetic algorithms. Oxford University Press, 1996.
[5] M.W. Eysenck and M.T. Keane. Cognitive Psychology: A Student’s Handbook. Taylor & Francis Group, 2019.
[6] Norman Packard, Mark A. Bedau, Alastair Channon, Takashi Ikegami, Steen Rasmussen, Kenneth Stanley, and
Tim Taylor. Open-Ended Evolution and Open-Endedness: Editorial Introduction to the Open-Ended Evolution I
Special Issue. Artiﬁcial Life, 25(1):1–3, 04 2019.
[7] P.R. Hiesinger. The Self-Assembling Brain: How Neural Networks Grow Smarter. Princeton University Press,
2021.
[8] A. E. Eiben and James E. Smith. Introduction to Evolutionary Computing. Springer Publishing Company,
Incorporated, 2nd edition, 2015.
[9] Michael Lynch. The evolution of genetic networks by non-adaptive processes. Nature Reviews Genetics,
8:803–813, 2007.
[10] G. Gottlieb. Individual Development and Evolution: The Genesis of Novel Behavior. Taylor & Francis, 2001.
[11] J. Ward. The Student’s Guide to Cognitive Neuroscience. Taylor & Francis, 2020.
[12] Adrian Bird. Perceptions of epigenetics. Nature, 447(7143):396–398, 2007.
[13] M.R. Garey and D.S. Johnson. Computers and Intractability: A Guide to the Theory of NP-completeness.
Mathematical Sciences Series. Freeman, 1979.
[14] C. Adami. Introduction to Artiﬁcial Life. Springer, 1998.
[15] A. E. Eiben and James E. Smith. From evolutionary computation to the evolution of things. Nature, 521:476–482,
2015.
[16] Stephane Doncieux, Alban Laﬂaquière, and Alexandre Coninx. Novelty search: A theoretical perspective. In
Proceedings of the Genetic and Evolutionary Computation Conference, GECCO ’19, page 99–106, New York,
NY, USA, 2019. Association for Computing Machinery.
[17] T.Y. Lo, P.K. Chien, and E.H. Anderson. Evolution and Intelligent Design in a Nutshell. Discovery Institute Press,
2020.
6

