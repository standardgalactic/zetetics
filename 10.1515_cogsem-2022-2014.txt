Andreas Larsson*, Karin Stolpe and Marlene Johansson Falck
Analysing the elements of a scene – An
integrative approach to metaphor
identiﬁcation in a naturalistic setting
https://doi.org/10.1515/cogsem-2022-2014
Published online November 28, 2022
Abstract: This paper addresses the challenges of exploring metaphor use in a
naturalistic environment. We employed an integrative approach to the analysis
of metaphor in video-recorded classroom observations of a teacher lecturing on
computer programming. The approach involved applying the Procedure for Iden-
tifying Metaphorical Scenes (PIMS) and the Metaphor Identiﬁcation Guidelines for
Gesture (MIG-G) both individually and jointly. Our analysis of the data shows that
the teacher primarily uses metaphors that evoke experiences of manipulating
physical objects while using his hands to add spatiality to these ‘objects’. Further-
more, it indicates that speciﬁc gestures may serve as ’anchoring-points’ for larger
scenes, enabling the speaker to form a scene in which to place smaller concepts.
Throughout the analysis, our integrative approach to metaphor analysis provided
opportunities to both support and refute results from each of the procedures
employed. Moreover, the PIMS procedure has both served as an efﬁcient tool for
identifyingcentralconceptsofa scene and a way to validate theresults ofthegesture
analysis. We suggest that this integrative approach to metaphor may be used to
provide clues about the embodied motivation of a metaphor at an individual level.
Keywords: classroom observation; gesture analysis; metaphor analysis; MIG-G;
PIMS; technology education
1 Introduction
This paper deals with an analysis of the metaphors in video data collected during
a programming lecture where a teacher explains how to ‘investigate’ data that
*Corresponding author: Andreas Larsson, Department of Behavioural Science and Learning (IBL),
Linköping University, Linköping, Sweden, E-mail: andreas.b.larsson@liu.se
Karin Stolpe, Department of Behavioural Science and Learning (IBL), Linköping University,
Linköping, Sweden, E-mail: Karin.stolpe@liu.se
Marlene Johansson Falck, Department of Language Studies, Umeå University, Umeå, Sweden,
E-mail: marlene.johansson.falck@umu.se
Cognitive Semiotics 2022; 15(2): 223–248

is received from a database. Exploring gestures in naturalistic environments such
as these poses several theoretical and methodological challenges for researchers
(see e.g., Cienki 2009). Not only is teaching a demanding task in which teachers
create opportunities for students to learn. Classrooms are highly complex envi-
ronments in which teachers and students interact with each other in unexpected
ways, and the topics discussed may be quite abstract. In the lecture sequence that
we analysed, the teacher (here called Lennie) went back and forth between
describing programming language (i.e., symbols and relationships visible on the
computer screen) in a very direct manner using conventionalised terms or
speaking about programming concepts in a more abstract way. Occasionally, it
was not clear which of these two aspects of programming he was focussing on.
Complex environments such as classrooms require novel ways of analysing
metaphorical understandings reflected in speech and gesture in vivo. The fact that
someone uses a common metaphoric expression does not necessarily mean that a
metaphor is activated (Low 2008). Moreover, what may be considered as a ‘bad
metaphor’ in relation to an abstract phenomenon may still enhance students’
learning (Haglund 2017). Although numerous studies have investigated embodied
metaphors manifested in manual gesture (Cienki and Müller 2008, 2008;
Mittelberg and Waugh 2009; Solomon et al. 2020), and metaphors reﬂected in
spoken language (Boström 2018; Cameron 2008), few studies have displayed a
clear focus on speaker’s metaphoric understanding of concepts reﬂected in lin-
guistic constructions and gestures.
To address the challenges involved in identifying metaphors reflected in
complex naturalistic settings such as these, and to better reflect the view that
metaphors are inherently multimodal (Müller 2007; Müller and Tag 2010), we
suggest an integrative approach to metaphor identiﬁcationthat combines the results
of two metaphor identiﬁcation procedures. The ﬁrst, the Procedure for Identifying
Metaphorical Scenes (PIMS), focusses on the metaphors reﬂected in language and
evoked by linguistic expressions in discourse (Johansson Falck and Okonski 2022,
accepted). The second, Metaphor Identiﬁcation Guidelines for Gesture (MIG-G)
(Cienki 2016), focusses on the metaphors in gestures. The aim of the study is to
design, evaluate, and suggest a dynamic, multimodal, and integrative approach to
metaphor identiﬁcation that can be applied in a complex naturalistic setting such as
a classroom. The procedures are applied individually as well as jointly to explore
their strengths, weaknesses, and how they may inform and strengthen each other.
More generally, the results of the analysis are used to discuss what may be
learned about how metaphors are used in a naturalistic environment and the
224
Larsson et al.

theoretical implications thereof. In our application of the integrative approach to
the classroom context the teacher was found to use a large number of co-speech
gestures (previously reported in Larsson and Stolpe (2019, 2022), and Larsson et al.
(2021). Hence, our observations – in addition to increasing empirical evidence
that both teachers and students employ gestures while speaking about abstract
phenomena (e.g., Dreyfus et al. 2015; Solomon et al. 2020; Solvang and Haglund
2021; Tang et al. 2022) – substantiate the claim that both words and gestures are
important elements in human communication and should therefore be analysed
together (Müller 2007).
2 An integrative approach to metaphor
identification
In order to foreground metaphoricity (i.e., a scalar value that involves doubleness
in experience and underlies metaphor (see e.g., Jensen and Greve 2019)), Müller
and Tag (2010) suggest a merge between a Cognitive Linguistics take on metaphor
with a sequential analytical approach to conversational interactions, drawing
upon the dynamic nature of metaphor (Müller 2009). Their suggested methodology
“offers a way to empirically determine whether the metaphoricity of a given verbal
or gestural metaphorical expression has been activated for a given speaker and
sometimes also for a given listener at a speciﬁc moment in time” (Müller and Tag
2010: 22). Consequently, elucidating these activation ques may be a way to
determine the degree of metaphoricity of what is sometimes referred to as sleeping
metaphors, which are “always available as an optional processing strategy”
(Kemmerer 2005) as long as the metaphorical expressions are still transparent
(Müller 2009) or have transparent elements (Johansson Falck and Okonski 2022,
accepted). Activation cues from other modalities are highly useful indicators that
these sleeping metaphors have also been activated by the speaker using the
constructions:
If a metaphor is expressed in speech and gesture at the same moment in time, or if a
verbo-pictorial metaphor is constructed by a writer, then this is very likely based on the
activation of a mental representation spreading through [motivated links such as sound
resemblance, exemplar memory, sensory memory, and contextual information].
(Müller 2009: 197)
Analysing the elements of a scene
225

We argue that the term sleeping metaphor – much like the term metaphoricity –
should be understood in a dynamic way, spanning a continuum that ranges from
‘deep sleep’ to ‘almost wide awake’ metaphor.
When combining the above, the following emerges (Figure 1): If a speaker uses
either a highly conventionalised literal expression in a given context (e.g., looking
up while waving hello when someone is entering the room), or a likewise
conventional gesture that stands for the same concept (e.g., waving one hand),
then no metaphors have been activated during the event. However, if the speaker
uses a verbal metaphor and/or a metaphor in gesture, a sleeping metaphor has
been activated, that is, it has become a waking metaphor. Thus, by combining a
method for identifying verbal metaphors (PIMS) and metaphors in gestures
(MIG-G), we get indications from two different modalities if, and to what extent a
sleeping metaphor has been activated by a speaker. Furthermore, if a speaker uses a
word with a high degree of metaphoricity, it will probably be accompanied by a
relatively conventional gesture, and vice versa. In this sense, the gesture will
provide a tangible element (a gestural version of a source domain) to the metaphor
(Larsson et al. 2021).
Figure 1: An overview of the correlation between conventionality in gesture and conventionality
in speech.
226
Larsson et al.

3 Methodology
3.1 Metaphor in language
In a Cognitive Linguistics view, language is similarly a matter of conceptualisation
(i.e., cognitive processing). Linguistic expressions reﬂect our thinking and “are not
meaningful in and of themselves, but only through the access they afford to
different stores of knowledge that allow us to make sense of them” (Langacker
1987). Similarly, verbal metaphors are conceptual in nature and linked to speakers’
experiences of the speciﬁc concepts that they represent by the lexical items that
they use (Johansson Falck accepted). Just like gestures, they display varying de-
grees of metaphoricity, which may vary from sleeping (i.e., inactive) to waking
(i.e., active) in relation to both speaker and context (Müller 2009). Consequently,
activated metaphoricity can only be determined at an individual level, where a
speaker’s interaction with the situation in which they are located including with
the affordances of the environment (Gibson 2015) plays a pivotal role for estab-
lishing the metaphoricity of a verbal metaphor.
3.1.1 Identifying metaphor in language using PIMS
The PIMS procedure (Johansson Falck and Okonski 2022, accepted) is based on
the Cognitive Linguistics premise that linguistic meaning is equal to complex
conceptualisations (Langacker 2002, 2010), is embodied (Gibbs 2006), and is
simulation based (Bergen 2012). The focus in PIMS is on the mental scenes reﬂected
and evoked by linguistic constructions in context and on the experiences coded by
these constructions. The concepts or scenes evoked by linguistic constructions
are considered non-metaphorical if they can only be directly understood, and
metaphorical if they can be understood by means of another type of experience.
For instance, the relation evoked by the phrase ladle soup into bowls represents a
spatial real-world ‘into’ relation that can only be directly understood as such. It is
non-metaphorical. The phrase the desire to drive and date shift into gear, by way of
contrast, evokes an abstract ‘into’ relation, which can be understood by means
of our experiences of real-world ‘into’ relations and of shifting vehicles into gear
(Johansson Falck and Okonski accepted).
The focus on the concepts or scenes evoked by linguistic construction rather
than on the meanings of pre-defined lexical units is an important distinction
between PIMS and previously established metaphor identification procedures
Analysing the elements of a scene
227

such as MIP and MIPVU (Johansson Falck and Okonski 2022). This means that
experiences that can be metaphorically understood are in focus, rather than meta-
phorical meanings of words (or predeﬁned lexical units). However, the focus on
conceptualisation does not automatically mean that the metaphorical scenes
identiﬁed in applications of PIMS were activated by the speaker. Rather, it means
that their metaphoricity is transparent enough to have been potentially meta-
phorical to the speaker. To establish that online activation on the part of the
speaker was really involved (i.e., that a sleeping metaphor was waking) several
activation indicators or cues must be identiﬁed (Müller 2009).
The first step of PIMS involves establishing the scenes and elements to be
included in the analysis (Johansson Falck and Okonski 2022, accepted). We
decided that all linguistic constructions in the transcript would be analysed and
that we would proceed concept by concept evoking the linguistic constructions in
the transcript. Linguistic constructions (including multiword units) that designate
one referent in the text (i.e. one entity, action, or relationship) as well as classical
idioms (e.g., pop the question) and other polyword units would be considered
one unit (Johansson Falck and Okonski 2022). Next, the transcript was read to
establish an understanding of the context. Finally, elements (i.e. concepts
evoked by the transcript) that could only be directly understood were marked as
non-metaphorical, and those that could be understood by means of another type
of experience as metaphorical. Elements that were established as ambiguous
between these two options were marked as ambiguous.
3.2 Metaphor in gesture
According to McNeill (1985), gestures can be explored by relating the form of a
speaker’s hand (e.g. the form of a cup) to a speciﬁc concept addressed (e.g. a
substance). They are part of a cognitive representation that forms a metaphor for
an abstract concept together with speech:
[C]ombining a spoken sentence and its concurrent gesture into a single observation gives two
simultaneous views of the same process, an effect comparable to triangulation in vision.
(McNeill 1985: 350)
Building on McNeill’s work, scholars have argued that gestures play an important
role in human communication (e.g., Cuccio and Fontana 2017; Hostetter and
Alibali 2008; Mittelberg 2018) and could – just like verbal metaphors – be
228
Larsson et al.

considered windows into people’s minds (Cienki and Müller 2008; McNeill 1992).
Some scholars suggest that gesture and speech should be seen as the result of a
fully integrated multi-modal system (see e.g., Cowley 2009), and hence explored
as such (Cuccio and Fontana 2017; Jensen and Greve 2019; Müller 2009). Conse-
quently, metaphor is no longer a matter of written or spoken language alone, but
rather a general principle that should be considered fundamentally multi-modal
(Cienki and Müller 2008).
Speakers’ gestures can add imagery and spatial properties to spoken language
(McNeill 2008). They may also add dynamic features to spoken language or
emphasise certain concepts in a sentence. However, gestures are not metaphors
per se. They are rather representations of part-whole relationships – metonymies –
between hands and concept where the form and motion of the hand stands for
something else (e.g., Cienki 2009). Consequently, analysing gestures is not a
question of deciding whether a gesture is a metaphor or not. Rather it is a question
of determining to what extent a given gesture is used as a metaphor by the speaker.
To an extent, gestures can be understood – much like with verbal metaphors – in
terms of convention. Some gestures are either very image-like, agreed upon, or
conventionalised (e.g., a thumbs-up to signal that something is ‘good’), while
others have close to no apparent meaning (e.g., a circular motion with the hand).
Somewhere in between lies, for example the gestural version of the ontological
container metaphor (i.e. one or both hands shaped like a container); a gesture that
has metaphorical qualities but needs to be accompanied with additional verbal
information in order to be meaningful or vice versa (Cienki 2016).
3.2.1 Identifying metaphors in gestures using MIG-G
MIG-G, was developed as a set of ‘guidelines’ for analysing metaphor in gesture
rather than as a procedure, with the goal to increase replicability; or at least to
guide the researcher to consider factors that might otherwise be overlooked (Cienki
2016). The guidelines involve identifying any physical resemblance between a
concept (a potential target domain) and a physical referent (a potential source
domain). If such a resemblance between gestural and speech behaviour can be
identiﬁed, the gesture can be regarded as being used as a metaphor in the speciﬁc
context in question (Cienki 2016).
According to Cienki, it is hard to “do justice to the reality of the phenomenon of
speakers’ gesture” (Cienki 2016: 135). MIG-G focuses on the observation of gestural
behaviour in context, from which the researcher can interpret what concepts
Analysing the elements of a scene
229

the spatio-motoric forms of the gestures represent (Cienki 2016). The fact that
the researcher makes an interpretation of the gesture, combined with the
multifunctionality of gestures, and individual styles between speakers, makes
gesture analysis potentially unreliable as a research method. However, the
guidelines suggested by Cienki “can help guide researchers in considering factors
in their coding that they might not have otherwise considered” (p. 137).
The first step of our application of MIG-G concerns establishing central events
to include in the analysis. This was done partly in relation to the context of the
lecture (e.g. specific programming concepts), recurring gestural behaviour, or
gestures identified in previous literature (e.g. the hand shaped as a cup standing
for a cup (Cienki and Müller 2008) or the hand holding an object standing for data
(Authors-a)). Secondly, each gesture was notated in relation to form (e.g. the shape
of the hand, the location of hands and palms in relation to the body, the height of
the gesture), the motion of the gesture, as well as initiation phase and the
post-stroke hold of the gesture. Thirdly, all verbal concepts in close temporal
proximity to the central gestures (potential target-domains of the gesture) were
noted. Finally, any physical resemblances between gesture (potential source-
domain for the gesture) and concept were identiﬁed. If such resemblance was
identiﬁed, the gesture was considered used as a metaphor.
4 Analysis
4.1 The data for the study
Video-recorded classroom observations from a Swedish upper secondary classroom
were analysed. The data were collected using two tripod-mounted cameras to ensure
that the teacher’s gestures and speech were captured without disturbing the lecture,
but also to avoid the teacher being distracted by the camera. The teacher had not been
given any specific instructions before the study and had not been provided with any
details regarding the focus of the study. During the lecture, the students were either
seated around a conference table adjacent to the white board, or next to individual
workstations positioned along the walls of the classroom. In the short clip analysed
here, students were seated at their workstations facing the wall and focussing on their
screens. While doing so, they all had access to a screencast showing Lennie’s
programming activities during the lecture. Prior to the study, Lennie and his students
had provided their informed written consent to participate in the study. Furthermore,
Lennie had provided permission to publish unfiltered images for scientific use.
230
Larsson et al.

4.2 Analytical approach
Three short excerpts from Lennie’s lecture were analysed to find out how each
metaphor identification procedure can be used to either support or refute decisions
based on the other procedure (RQ1). The three clips reflect a short sequence where
Lennie explains the programming concept att borra sig ner i ett objekt (‘to drill
down into an object’). According to Lennie, the expression drill can be seen as
either a technical term that is analogous to investigating the information content of
an object, or the structure of an object. The concept is framed within an assignment
where the students are supposed to write a program that receives data from a
database, cut the data into smaller pieces, and publish selected parts on a website.
The program should be constructed in a general way so that it can be used
repeatedly, and in other settings.
Our analysis was performed in three stages. First, PIMS was applied to identify
metaphorical scenes reflected in the linguistic constructions in the transcript of
the lecture. PIMS may also be applied to the analysis of spoken discourse and
information from clips considered as background information to the decisions
made. However, because at this initial stage we wanted to ﬁrst establish what
could be learned from the verbal information alone, we started by applying PIMS to
the transcript. Second, MIG-G was performed to identify representational gestures
used as metaphors. Third, the video sequences were compared and discussed
based on both analyses, until consensus among the researchers was reached.1
5 Results
In the following sections, we present the analysis in the order it was performed
with three subsections where (1) metaphor in language (i.e., the results of the PIMS
procedure), (2) metaphor in gesture (the results of the MIG-G procedure), and (3)
metaphor in language and gesture (the combination of the methods) are described
separately.2
1 Based on our experiences of similar studies (e.g., Larsson & Stolpe 2022; Larsson et al. 2021), the
order in which this is done, is of little or no importance. For the purpose of this study, however, we
chose to ﬁrst explore how the use of MIG-G would inform the use of PIMS, while later combining the
two for a joint analysis.
2 As the data only reﬂects the teacher’s action, we have not – in contrast to for example Müller
(2019) – made any assumptions about how the students’ reactions affect Lennie’s behaviour (and
vice versa). We are, however, aware that this may affect the analysis.
Analysing the elements of a scene
231

5.1 Clip 1
5.1.1 Metaphor in language
In the first clip, Lennie has started to introduce how to explore packages of data
received from a database. To do so, he has developed a function that performs the
procedure by what he refers to as ‘walking’ inside, what is called, a response-
object. As seen in the excerpt, the procedure is performed at (code lines) 12, 13, 14,
and 15.
Our application of PIMS to the transcript of clip 1 (Table 1) shows that går
(‘walks’), responsobjektet (‘the response object’) and objektet (‘the object’) evoke
elements that can be metaphorically understood by means of another experience.
In this context, går does not evoke real-world physical motion that can only be
understood as such, but ‘a programming action’ that can be understood by
means of our experiences of ‘walking’. Similarly, responsobjektet (‘the response
object’) and objektet (‘the object’) here evoke programming concepts that can be
metaphorically understood by means of our experiences of real-world physical
objects (ABSTRACT PROGRAMMING CONCEPTS ARE REAL-WORLD PHYSICAL
OBJECTS).
The phrases från hela (‘from the whole’) and ner till resultatdelen (‘down to the
results section’) are potentially metaphorical, but this cannot be established
without information from the video. If Lennie uses them in reference to relation-
ships and entities on the computer screen that can only be directly understood as
such, they represent concepts that can be literally understood. If he uses them in
reference to abstract relations and concepts that he is thinking about while
conceptualising programming and that can be understood by means of spatial
relations and real-world physical entities (MAKING PROGRESS FROM A WHOLE
ABSTRACT PROGRAMMING CONCEPT IS WALKING FROM A REAL-WORLD
PHYSICAL CONCEPT and PROCEEDING DOWN TO AN ABSTRACT PROGRAM-
MING CONCEPT IS WALKING DOWN TO A REAL-WORLD PHYSICAL SECTION),
they are metaphorical. Based on information from the transcript alone, they are
ambiguous.
5.1.2 Metaphor in gesture
We identified three subsections that are central for further exploring the gestures
(Figures 2–5) in our application of MIG-G to Clip 1. In the ﬁrst subsection, Lennie
lowers his arm while saying från (from). The gesture has a physical resemblance
with something that literally moves from one place to another in the real world and
232
Larsson et al.

Table : Word-by-word alignment and the results of the PIMS procedure performed on Clip .
Det
är
det
jag
gör
… på
… på
,
,
,
.
På
dom
raderna
That
is
what
I
do
… on
… on
,
,
,
.
On
those
rows
‘That is what I do, at, at , , , . On those rows’
Subsection A
Subsection B
Subsection C
så
går
jag
från
hela
responsobjektet,
ner
till
resultatdelen
i
objektet
so
walk
I
from
the whole
response object
down
to
the results section
in
the object
‘So, I go from the whole response object down to the results section in the object’
PIMS suggests:
‘That is what I do … at … at … [lines] , , , and . On those lines, I walk from the whole response object down to the
results section in the object.’
Analysing the elements of a scene
233

consequently appears to be used as a metaphor for går från (walks from). However,
since Lennie looks at the screen while performing the downward motion, the
gesture more likely refers to the code that is visible on the screen. It should thus be
seen as a pointing gesture rather than a metaphoric gesture.
In the second subsection, Lennie performs a circular, forward motion with his
right hand. The gesture starts shoulder-high and ends with an open-hand
Figure 3: Lennie is pointing at the
code that is discussed in Clips 1–3. The
image on the screen shows a
screencast from Lennie’s own
computer.
Figure 2: Lennie performs a downward
motion with his left hand while looking
at the computer screen.
234
Larsson et al.

positioned just below the chest. Here too, the downward motion could be seen as a
physical referent to [går från] hela … ner till ([walk from] … down to). But since
Lennie is still looking at the screen, we take the gesture to refer to the screen and to
bear no physical resemblance to the code on display (Figure 3). For this reason, it
was not considered a metaphor. However, the post-stroke hold – the right hand
Figure 5: Lennie performing a small forward, circular gesture landing as if he is holding an
object.
Figure 4: Lennie performing a forward, circular gesture with his left hand, landing his hand as if
he were holding an object.
Analysing the elements of a scene
235

shaped as a cup – could be seen as a physical referent to the programming concept
of responsobjektet (‘the response object’). We argue that this gesture is used as a
metaphor which could be summarised as ABSTRACT PROGRAMMING CONCEPTS
ARE REAL-WORLD PHYSICAL OBJECTS.
In the third section of Clip 1, Lennie performs a circular, forward gesture with
his right hand, starting from a chest-high position and ending at approximately the
same height as the starting position (Figure 4). The post-stroke hold is again
shaped as if Lennie was holding a physical object in his hand.We argue that the
gesture is used as a physical referent of resultatdelen i objektet (‘the results section
in the object’) (Figure 5), hence, ABSTRACT PROGRAMMING CONCEPTS ARE
REAL-WORLD PHYSICAL OBJECTS.
5.1.3 Metaphor in language and gesture
When compared, our applications of PIMS (Johansson Falck and Okonski 2022,
accepted) and MIG-G (Cienki 2016) suggest that the teacher indeed has abstract
programming concepts in mind when talking about responsobjektet (‘the response
object’) and objektet (‘the object’) and that the concepts are metaphorically
understood as real-world physical objects. Similarly, he appears to understand
resultatdelen (‘the result section’) by means of his experiences of a physical object.
Moreover, because Lennie discusses relations between abstract concepts rather
than spatial relations between entities that we can observe on a computer screen,
the phrases från (’from’), hela (‘the whole’) and i (‘in’) are necessarily abstract too.
They evoke abstract relations that we can metaphorically understand by means
of our experiences of the spatial relations and concepts that the constructions
may also refer to. The results of PIMS are here conﬁrmed and strengthened by
the application of MIG-G. Furthermore, MIG-G provides clues as to how Lennie
envisions the spatial relations that are evoked in this clip. Our application of MIG-G
has provided us with the necessary information to determine that the constructions
från hela (‘from the whole’) and ner till resultatdelen (‘down to’ the results section)
can either be understood literally whenLennie refers to the screen (as in subsection 1)
or as representations of spatial relations between real-world physical objects
(as in subsections 2 and 3). The screen (For a screencast of the code, please consult
Figure 3) appears to afford thinking about the objects and relations on the screen
in non-metaphorical ways and taking the focus off the screen to afford
conceptualising the concepts and relations that they represent. We conclude
that there are still elements in this excerpt that will remain inconclusive after
applications of PIMS and MIG-G to this clip (Table 2).
236
Larsson et al.

5.2 Clip 2
5.2.1 Metaphor in language
As seen in Clip 1, exploring the data-package seems to be related to moving in a
downwards direction. How far down is determined by the programmer. In the
syntax, an underdel (‘sub-part’ lit. ‘under part’) is deﬁned using full stops [.]
(e.g. name.surname.age represents a [generic] data package comprising infor-
mation about a person’s name, surname, and age – all underdelar (‘sub-parts’) of a
larger objekt (‘object’)).
The word objektet (the object) recurs in Clip 2 (Table 3). Here too it evokes an
abstract concept that can be metaphorically understood by means of another type
of experience (a real-world physical object). The linguistic constructions underdel
(‘sub-part’ lit. ‘under part’), ner till (‘down to’), and i (‘in’) evoke concepts and
relations that may be metaphorical, but this is not possible to establish based on
information from the transcript alone. They are metaphorical if the teacher uses
them to refer to abstract concepts and relations that can be understood by means of
real-world objects and relations, but literal if he uses them in reference to parts and
relations that can be observed on the computer screen.
5.2.2 Metaphor in gesture
As in Clip 1, the word objektet (‘the object’) is accompanied by a gesture in which
Lennie is holding an imaginary object (Figure 6). This strengthens our interpre-
tation that he uses this word in reference to a real-world concept that he simulates
Table : The combined results of the PIMS and MIG-G analyses of Clip . While PIMS suggests that
‘from the whole’ should be determined as inconclusive, MIG-G suggests that the gesture in
close proximity to the whole is an indication that Lennie understands the response object as a
real-world physical object. A similar ambiguity regarding ‘down to the result part’ is also solved by
the application of MIG-G, where the latter gesture is determined as referring to a physical object.
PIMS
suggests:
‘That is what I do … at … at … [lines] , , , and . On those lines, I walk
from the whole response object down to the result part in the object.’
MIG-G
suggests:
‘That is what I do … at … at … [lines] , , , and . On those lines, I walk
from the whole response object down to the result part in the object.’
Analysing the elements of a scene
237

in his gestures. Similarly, when saying en underdel i objektet (‘a sub-part in the
object’), Lennie performs a gesture where he places his palms facing each other,
ﬁngers slightly up, chest-high, as if he were holding something. Next, he looks at
the screen (for a screencast of the code, please consult Figure 3) and lowers his
hands slightly, while increasing the distance between his hands. This gesture
shows two types of resemblances with the construction underdel (‘sub-part’): 1) as
a smaller part of the initial object, i.e. as a physical referent for a real-world
physical object, or 2) as a representation of the way an underdel (‘sub-part’) is
indicated on the screen. Either way, our application of MIG-G to this scene suggests
that the construction underdel (‘sub-part’) is metaphorically understood as a
subsection of a physical object.
The gesture corresponding to the construction ner till (‘down to’) seems to refer
to the screen and is not used as a metaphor. However, present on the screen is a
‘full stop’ [.] and the word ‘name’. Lennie’s gesture can here be seen as a referent to
the entities on the display. At the end of the clip, he turns his hand and shapes it
into what can be interpreted as a container or a conﬁned area while saying i
underdelen (‘in the sub-part’) (Figure 7). We take the gesture to have a dual nature
that enacts both physical relations between concepts and a physical referent of the
concept underdel (‘underpart’).
Table : Word-by-word alignment and the result of the PIMS procedure performed on Clip .
Subsection A
Subsection B …
Det
vill
säga
en
underdel
i
objektet
ner
till
en
viss
punkt
i
That
will
say
one
under
part
in
the object
down
to
a
speciﬁc
point
in
‘That is, a sub-part in the object … down to a speciﬁc point in’
… Subsection B
underdelen,
ner
till
ett
visst
namn
i
underdelen
the underpart,
down
to
a
speciﬁc
name
in
the under part
‘down to a speciﬁc part of the sub-part, down to a speciﬁc name in the sub-part’
PIMS Suggests
‘That is, a sub-part in the object down to a spe-
ciﬁc part of the sub-part, down to a speciﬁc name
in the sub-part’
238
Larsson et al.

5.2.3 Metaphor in language and gesture
Taken together, our applications of both procedures show that not only the
concept evoked by objektet (’the object’) but also those concepts evoked by
underdel(en) (‘the sub-part’), punkt (period) and namn (name) are metaphorically
understood. The ﬁrst two instances of these terms designate abstract concepts that
can be understood by means of our experiences of real-world physical parts,
periods, and relations. However, Lennie’s third and fourth uses of these terms refer
to entities that are displayed on the screen, that is, to a section of an object that
Figure 7: Lennie, seemingly referring to the computer screen, uses his left hand as a constraint
for a confined area. During the sequence Lennie is facing the students.
Figure 6: Lennie performing a gesture landing as if he were holding an object between his
hands. At the end of the sequence, Lennie turns his attention towards the computer screen.
Analysing the elements of a scene
239

contains information about a person’s name, to underdel(en) (‘the sub-part’) and
namn (name). MIG-G has here provided information about how the physical parts
of the program relate to each other (Table 4). Furthermore, it shows that Lennie
uses metaphorical gestures, even though he is facing the screen rather than the
students.
5.3 Clip 3
5.3.1 Metaphor in language
Several linguistic constructions in the transcript of Clip 3 evoke concepts that can
be metaphorically understood by means of another type of experience (Table 5).
The phrase borra (drill) here refers to the action needed to get to the data that the
teacher wants, but may, in other contexts, refer to the act of ‘drilling’ or ‘boring’
through something. Because the action evoked here can be understood by means
of real-world drilling through something to reach something else, it is marked as
metaphorical. The constructions ner (‘down’) djupare och djupare (‘deeper and
deeper’) till (‘to’) provide information on the direction of the motion involved in
the metaphorical drilling. The prepositions ner (down’) and till (‘to’) suggest that
the metaphorical drilling involves downward motion the way real-world spatial
relations do, and the construction djupare och djupare (‘deeper and deeper’)
suggests that it goes deeper and deeper. From the ﬁnal verb ha (‘have’) we learn
that the drilling takes the programmer deeper and deeper to the data that he wants
to obtain like we do when we obtain real world objects in the real world. Because ha
(‘have’) can be understood by means of this other type of experience it is marked as
metaphorical.
Table : The combined results of the PIMS and MIG-G analyses of Clip . While PIMS suggests that
‘sub-part’, ‘down to’, and ‘position’ should be determined as inconclusive, MIG-G concludes that
all these elements are understood in relation to real world physical objects.
PIMS suggests ‘That is, a sub-part in the object down to a speciﬁc position of the sub-part, down
to a speciﬁc name in the sub-part’
MIG-G
suggests
‘That is, a sub-part in the object down to a speciﬁc position of the sub-part, down
to a speciﬁc name in the sub-part’
240
Larsson et al.

Table : Word-by-word alignment and the result of the PIMS-procedure performed on Clip .
Så
jag
kan
alltså
borra
mig
ner
, djupare
och
djupare
till
[inaudible]
So
I
can
in other words
drill
myself
down
deeper
and
deeper
to
[inaudible]
‘In other words, I can drill myself down, deeper and deeper ‘til [inaudible]’
den
data
jag
vill
ha
the
data
I
want
have
‘the data I would like to have’
PIMS suggests
‘In other words, I can drill myself down, deeper and deeper ‘til [inaudible] the data I would like to have’
Analysing the elements of a scene
241

5.3.2 Metaphor in gesture
From a programming perspective, the central concept in this clip is borra
(‘drilling’). When applying MIG-G to the corresponding gesture, there is no
resemblance between the way Lennie positions his hands and the diagonal,
downward motion (Figure 8). Consequently, the gesture is not used as a metaphor
in this case. Furthermore, our application of MIG-G reveals more of the spatial
relations between the abstract programming concepts. For example, there is a
resemblance between the downward motion of the gesture and the verbal
construction ner (‘down’), which corresponds well with djupare och djupare
(‘deeper and deeper’).
5.3.3 Metaphor in language and gesture
Taken together, our identification of metaphors reflected in language and in
gesture substantiates the interpretation that the programmer’s ‘drilling deeper and
deeper down to the data that he wants to have’ is metaphorically understood. He is
not literally drilling himself down into real-world materials, but to the abstract
concept of the data that he wants to obtain. This was evident from our application
of PIMS alone and strengthened by our application of MIG-G. In addition, our
application of PIMS suggests that all Lennie’s gestures correspond to programming
concepts rather than on-screen representations or conventional language. In this
way PIMS provided useful information to the gesture analysis. Here, Lennie’s
hands reflect metonymic relations between gestures and programming concepts,
Figure 8: Lennie performing a diagonal (downward, to the left) motion using both his hands. The
gesture sequence is performed in three stages (pictures a, b and c).
242
Larsson et al.

thus adding an additional modality to the source domain of the metaphor
ABSTRACT PROGRAMMING CONCEPTS ARE REAL-WORLD PHYSICAL OBJECTS.
This adds more spatiality to the programming concepts and builds a top-to-bottom
hierarchy that is reflected in for example the word underdel (‘sub-part’) and gå ner i
(‘walk down in’).
However, based on our applications of PIMS and MIG-G, it would also be
possible to regard Lennie’s gestures as references to the metaphor ABSTRACT
PROGRAMMING CONCEPTS ARE REAL-WORLD PHYSICAL OBJECTS. Here, his
hands would be holding, thus simulating the metaphoric action of holding a
real-world physical object (HOLDING A PHYSICAL OBJECT FOR HOLDING AN
ABSTRACT PROGRAMMING CONCEPT). Furthermore, the direction of the motion
would refer to the direction of the code lines on the screen (DIRECTION OF HANDS
FOR LINES) and the number of ‘stops’ would refer to the number of levels that one
is able to borra sig ner till (‘drill down to’) (POSITION OF HANDS FOR LEVEL,
POSITION OF HANDS FOR SUB-PART) (Table 6).
6 Methodological discussion
As both PIMS and MIG-G are based on a basic understanding of a scene or an event,
rather than the composing details thereof, the procedures are complementary
from a methodological perspective. Furthermore, as both procedures promote a
non-binary understanding of metaphor, they also complement each other from a
theoretical standpoint. Nevertheless, both procedures have their strengths and
weaknesses: For example, MIG-G is hard to apply on a small data set. Here, PIMS
can be of use since many insights about the context of a gesture can be gained from
a linguistic analysis of a short event. However, as MIG-G is an efﬁcient way to
Table : The combined results of the PIMS and the MIG-G analyses of Clip . Here, the results of
the PIMS procedure have informed the MIG-G procedure, resulting in a suggested consensus in the
analysis.
PIMS suggests ‘In other words, I can drill myself down, deeper and deeper ‘til [inaudible] the data
I would like to have’
MIG-G
suggests
‘In other words, I can drill myself down, deeper and deeper ‘til [inaudible] the data
I would like to have’
Analysing the elements of a scene
243

identify a speaker’s seminal gestures and thus also to gain an understanding
of central concepts in a context, it provides useful information to applications
of PIMS. This shows that our integrative approach to multi-modal metaphor
identiﬁcation can help the researcher focus on ‘the right’ events early in the
process, rather than looking for needles in a giant haystack.
This means that a combination of PIMS and MIG-G provides the researcher
with a richer set of activation cues (Müller 2009) to identify sleeping or waking
metaphors, the cognitive elements of a scene, in real-life settings in general.
Adding the PIMS procedure as a complement for studying gestures provides the
researcher with (1) a ﬂexible and efﬁcient tool for identifying the central metaphors
of a scene, (2) a quick and systematic procedure to validate the MIG-G procedure,
and (3) a systematic strategy for handling vast amounts of data. In the same way,
MIG-G can be used to support an analysis of verbal data, as the MIG-G-procedure
provides clues on what concepts a speciﬁc word refers to or reveals for example
strong spatial relations between the different elements of a scene. Furthermore,
gestures may be seen as simulations of metaphors; they can provide clues about
motivations of metaphor at an individual level. To the best of our knowledge, this is
not possible within any other methodological framework.
7 Conclusions and theoretical implications
of the study
The integrative approach to multi-modal metaphor identification tested here is a
fruitful way to address the challenges of gaining understanding of metaphor
performance in a natural environment, i.e. identifying metaphors in the real world.
Gaining an understanding of the larger concepts of a scene by using MIG-G largely
improves the quality of the PIMS-results, while the less coarse analysis of PIMS
improves the understanding of the small nuances of an individual’s gestures in a
naturalistic environment. The metaphors reflected in Lennie’s gestures in the
above cases show that he primarily uses language that evokes experiences of
manipulating physical objects, while using his hands to add spatiality to those
‘objects’.
Our results indicate that some gestures (e.g., holding an ‘object’ in his hand)
may serve as anchor points that ground a whole scene (Brandt 2016; Mittelberg
2018), or as subtle hints that may help students interpret the textual information
present on the screen. From an analytical perspective, this means that the
researcher has a lot to gain (e.g., swiftly determining central scenes during a data
collection) from identifying these gestures, but it also indicates that a speaker’s
244
Larsson et al.

gestural behaviour serves an important function when it comes to communicating
basic concepts within a scene instead of relying on words only. As the gestures
generally co-occur with the words, we argue that this is an indication that
metaphor in gestures and language are reﬂections of the same cognitive pro-
cesses (Cuccio and Fontana 2017) and that metaphor is multimodal to its nature.
Furthermore, as many of the gestures are re-enactments of elements present in the
scene evoked by his words, these processes can be viewed as a result of embodied
simulation processes (Gibbs Jr 2006; Gibbs and Matlock 2008; Mittelberg 2018)).
Accordingly, some of Lennie’s gestures may be understood as an input space for a
conceptual blend (Coulson and Cánovas 2009; Dreyfus et al. 2015). Consequently,
gesture analysis, just like the analysis of verbal data, plays a pivotal role for our
understanding of cognition (cf., Hostetter and Alibali 2008).
As expected from the literature reviewed for this paper (e.g., Dreyfus et al.
2015; Manches et al. 2020; Müller 2019; Solomon et al. 2020) (Cienki and Müller
2008), our analysis indicates that the functions of Lennie’s gestures vary with the
situations in which they occur and with the affordances of the environment
(Chu and Kita 2016; Masson-Carro et al. 2016; Masson-Carro et al. 2020). The same
gesture can represent different concepts depending on whether Lennie looks at the
computer screen or elsewhere in the classroom. From an analytical perspective,
this means that an integrative approach to multimodal metaphor may increase the
possibilities for the researcher to explore the cognitive aspects of an individual’s
interaction with the environment. Furthermore, it implies that artefacts such as
computer screens have agency on how we understand and communicate
programming concepts (cf. Gibson 2015). Moreover, the study shows that Lennie
activates a richer set of metaphors when he talks to the class than when he refers to
the computer screen. While facing the students (who are positioned with their
backs towards Lennie), he enacts his unique understanding of programming
concepts in the form of embodied and multimodal metaphors (Gibbs 2019), and
while facing the screen he merely refers to what is there to be seen. By analysing the
metaphors reﬂected in his language and gestures, we have taken one more step
towards systematically revealing the components that underpin a teacher’s speech
and gestures in a classroom. Yet despite the integrated approach, there were
relations between elements that we were not able to fully understand. Untangling
these issues is an interesting prospect for future research.
References
Bergen, Benjamin. 2012. Louder than words: The new science of how the mind makes meaning.
New York: Basic Books.
Analysing the elements of a scene
245

Boström, Per. 2018. Det här är ju dött tåg liksom: En studie av metaforer för ROMANTISK KÄRLEK
i talad svenska. [”This is like a dead train”: a study of metaphors for ROMANTIC LOVE in
spoken Swedish]. Umeå: Umeå University.
Brandt, Per Aage. 2016. Deixis – a semiotic mystery: Enunciation and reference. Cognitive
Semiotics 9(1). 1–10.
Cameron, Lynne. 2008. Metaphor and talk. In Raymond W. Gibbs (ed.), The Cambridge handbook
of metaphor and thought, 197–211. New York: Cambridge University Press.
Chu, Mingyan & Sotaro Kita. 2016. Co-thought and co-speech gestures are generated by the same
action generation process. Journal of Experimental Psychology: Learning, Memory, and
Cognition 42(2). 257–270.
Cienki, Alan. 2009. Conceptual Metaphor Theory in light of research on speakers’ gestures.
Cognitive Semiotics 5(1–2). 349–366.
Cienki, Alan. 2016. Analysing metaphor in gesture: A set of metaphor identiﬁcation guidelines for
gesture (MIG-G). In Semino Elena & Zsóﬁa Demjén (eds.), The Routledge handbook of
metaphor and language, 149–165. Abingdon: Routledge.
Cienki, Alan & Cornelia Müller (eds.). 2008. Metaphor and gesture. Amsterdam: John Benjamins
Publishing Company.
Cienki, Alan & Cornelia Müller. 2008. Metaphor, gesture, and thought. In Raymond Gibbs (ed.),
The Cambridge handbook of metaphor and thought, 483–501. New York: Cambridge
University Press.
Coulson, Seana & Cristobal Pagán Cánovas. 2009. Understanding timelines: Conceptual
metaphor and conceptual integration. Cognitive Semiotics 5(1–2). 198–219.
Cowley, Stephen. 2009. Language ﬂow: Opening the subject. Cognitive Semiotics 4(Suppl).
63–91.
Cuccio, Valentina & Sabina Fontana. 2017. Embodied Simulation and metaphorical gestures.
Metaphor in communication, science and education, 77–91. Berlin: De Gruyter Mouton.
Dreyfus, Benjamin, Ayush Gupta & Edward Redish. 2015. Applying conceptual blending to model
coordinated use of multiple ontological metaphors. International Journal of Science
Education 37(5–6). 812–838.
Gibbs, Raymond. 2006. Metaphor interpretation as embodied simulation. Mind & Language 21(3).
434–458.
Gibbs, Raymond. 2006. Embodiment and cognitive science. Cambridge: Cambridge University
Press.
Gibbs, Raymond. 2019. Metaphor as dynamical – ecological performance. Metaphor and Symbol
34(1). 33–44.
Gibbs, Raymond & Teenie Matlock. 2008. Metaphor, imagination, and simulation psycholinguistic
evidence. In Raymond W. Gibbs (ed.), The Cambridge handbook of metaphor and thought,
161–176. Cambridge: Cambridge University Press.
Gibson, James. 2015. The ecological approach to visual perception: Classic edition. New York:
Psychology Press.
Haglund, Jesper. 2017. Good use of a ‘bad’ metaphor. Science & Education 26(3). 205–214.
Hostetter, Autumn & Martha Alibali. 2008. Visible embodiment: Gestures as simulated action.
Psychonomic Bulletin & Review 15(3). 495–514.
Johansson Falck, Marlene. accepted. Lexico-encyclopedic conceptual (LEC) metaphors. In
T. L. Fuyin (ed.), Handbook of cognitive semantics. Brill.
246
Larsson et al.

Johansson Falck, Marlene & Lacey Okonski. 2022. Procedure for identifying metaphorical scenes
(PIMS): A cognitive linguistics approach to bridge theory and practice. Cognitive Semantics
8(2). 294–322.
Johansson Falck, Marlene & Lacey Okonski. accepted. Procedure for identifying metaphorical
scenes (PIMS): The case of spatial and abstract relations. Metaphor and Symbol.
Jensen, Thomas Wiben & Linda Greve. 2019. Ecological cognition and metaphor. Metaphor and
Symbol 34(1). 1–16.
Kemmerer, David. 2005. The spatial and temporal meanings of English prepositions can be
independently impaired. Neuropsychologia (43). 797–806. https://doi.org/10.1016/j.
neuropsychologia.2004.06.025.
Langacker, Ronald. 1987. Foundations of Cognitive Grammar: Theoretical prerequisites. Stanford:
Stanford University Press.
Langacker, Ronald. 2002. Concept, image, and symbol: The cognitive basis of grammar. Berlin:
Walter de Gruyter Inc.
Langacker, Ronald. 2010. Cognitive grammar. In Dirk Geeraerts & Cuyckens Hubert (eds.), The
Oxford handbook of cognitive linguistics. Oxford: Oxford University Press.
Larsson, Andreas & Karin Stolpe. 2019. Talking code or typing code – unpacking the metaphorical
structures in the programming classroom. Paper presented at the ESERA2019. Bologna, Italy.
Larsson, Andreas & Karin Stolpe. 2022. Hands on programming: Teachers’ use of metaphors in
gesture and speech make abstract concepts tangible. International Journal of Technology
and Design Education. https://doi.org/10.1007/s10798-022-09755-0.
Larsson, Andreas, Karin Stolpe & Marlene Johansson Falck. 2021. A Teacher’s Hands on
Programming: How orientations of gestures provide concrete dimensions to abstract
thoughts. In Paper presented at the 14th conference of the European Science Education
Research Association (ESERA 2021), Braga, Portugal, 30 August to September 3.
Low, Graham. 2008. Metaphor and education. In Raymond Gibbs (ed.), The Cambridge handbook
of metaphor and thought, 212–231. New York: Cambridge University Press.
Manches, Andrew, Peter McKenna, Gnanathusharan Rajendran & Judy Robertson. 2020.
Identifying embodied metaphors for computing education. Computers in Human Behavior
105. 105859.
Masson-Carro, Ingrid, Goudbeek Martijn & Krahmer Emiel. 2016. Can you handle this? The impact
of object affordances on how co-speech gestures are produced. Language, Cognition and
Neuroscience 31(3). 430–440.
Masson-Carro, Ingrid, Martijn Goudbeek & Emiel Krahmer. 2020. What triggers a gesture?
Exploring affordance compatibility effects in representational gesture production. Journal of
Experimental Psychology: Human Perception and Performance 46(10). 1164–1182.
McNeil, David. 1985. So you think gestures are nonverbal? Psychological Review 92(3). 350.
McNeill, David. 1992. Hand and mind: What gestures reveal about thought. Chicago: University of
Chicago Press.
McNeill, David. 2008. Gesture and thought. Chicago: University of Chicago press.
Mittelberg, Irene. 2018. Gestures as image schemas and force gestalts: A dynamic systems
approach augmented with motion-capture data analyses. Cognitive Semiotics 11(1).
20180002.
Mittelberg, Irene & Linda Waugh. 2009. Metonymy ﬁrst, metaphor second: A cognitivesemiotic
approach to multimodal ﬁgures of thought in co-speech gesture. In Charles J. Forceville &
Eduardo Urios-Aparisi (eds.), Multimodal metaphor, 329–358. Berlin: De Gruyter Mouton.
Analysing the elements of a scene
247

Müller, Cornelia. 2007. A dynamic view of metaphor, gesture and thought. In Susan Duncan,
Justine Cassell & Elena Levy (eds.), Gesture and the dynamic dimension of language,
109–116. Amsterdam/Philadelphia: John Benjamins Publishing Company.
Müller, Cornelia. 2009. Metaphors dead and alive, sleeping and waking: A dynamic view. Chicago:
University of Chicago Press.
Müller, Cornelia. 2019. Metaphorizing as embodied interactivity: What gesturing and ﬁlm viewing
can tell us about an ecological view on metaphor. Metaphor and Symbol 34(1). 61–79.
Müller, Cornelia & Susanne Tag. 2010. The dynamics of metaphor. Foregrounding and activation of
metaphoricity in conversational interaction. Cognitive Semiotics 10(6). 85–120.
Solomon, Amber, Miyeon Bae, Betsy DiSalvo & Mark Guzdial. 2020. Embodied representations in
computing education: How gesture, embodied language, and tool use support teaching
recursion. In Melissa Gresalﬁ& Ilana Seidel Horn (eds.), The interdisciplinarity of the learning
sciences, 14th international conference of the learning sciences (ICLS) 2020, vol. 4,
2133–2140. Nashville, Tennessee: International Society of the Learning Sciences.
Solvang, Lorena & Jesper Haglund. 2021. Learning with friction – students’ gestures and
enactment in relation to a GeoGebra simulation. Research in Science Education 52.
1659–1675.
Tang, Kok-Sing, Fredrik Jeppsson, Kristina Danielsson & Ewa Bergh Nestlog. 2022. Affordances of
physical objects as a material mode of representation: A social semiotics perspective of
hands-on meaning-making. International Journal of Science Education 44(2). 179–200.
248
Larsson et al.

