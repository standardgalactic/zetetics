Simple steps are all you need: Frank-Wolfe
and generalized self-concordant functions
Alejandro Carderera
ALEJANDRO.CARDERERA@GATECH.EDU
Department of Industrial and Systems Engineering
Georgia Institute of Technology
Atlanta, USA
Mathieu Besançon
BESANCON@ZIB.DE
Zuse Institute Berlin
Berlin, Germany
Sebastian Pokutta
POKUTTA@ZIB.DE
Institute of Mathematics
Zuse Institute Berlin and Technische Universität Berlin
Berlin, Germany
Abstract
Generalized self-concordance is a key property present in the objective function of many important
learning problems. We establish the convergence rate of a simple Frank-Wolfe variant that uses the
open-loop step size strategy 𝛾𝑡= 2/(𝑡+ 2), obtaining a O(1/𝑡) convergence rate for this class of
functions in terms of primal gap and Frank-Wolfe gap, where 𝑡is the iteration count. This avoids the
use of second-order information or the need to estimate local smoothness parameters of previous
work. We also show improved convergence rates for various common cases, e.g., when the feasible
region under consideration is uniformly convex or polyhedral.
1. Introduction
Constrained convex optimization is the cornerstone of many machine learning problems. We consider
such problems, formulated as:
min
x∈X 𝑓(x),
(1.1)
where 𝑓: ℝ𝑛→ℝ∪{+∞} is a generalized self-concordant function and X ⊆ℝ𝑛is a compact convex
set. When computing projections onto the feasible regions as required in, e.g., projected gradient
descent, is prohibitive, Frank-Wolfe (FW) [Frank & Wolfe, 1956] algorithms (a.k.a. Conditional Gradi-
ents (CG) [Levitin & Polyak, 1966]) are often the algorithm of choice, relying on Linear Minimization
Oracles (LMO) at each iteration to solve Problem (1.1). The analysis of their convergence often relies
on the assumption that the gradient is Lipschitz-continuous. This assumption does not necessarily
hold for generalized self-concordant functions, an important class of functions for which the growth
can be unbounded.
1.1 Related work
In the classical analysis of Newton’s method, when the Hessian of 𝑓is assumed to be Lipschitz
continuous and the function is strongly convex, one arrives at a convergence rate for the algorithm
that depends on the Euclidean structure of ℝ𝑛, despite the fact that the algorithm is afﬁne-invariant.
This motivated the introduction of self-concordant functions in Nesterov & Nemirovskii [1994],
functions for which the third derivative is bounded by the second-order derivative, with which one
1
arXiv:2105.13913v1  [math.OC]  28 May 2021

can obtain an afﬁne-invariant convergence rate for the aforementioned algorithm. More importantly,
many of the barrier functions used in interior-point methods are self-concordant, which extended the
use of polynomial-time interior point methods to many settings of interest.
Self-concordant functions have received strong interest in recent years due to the attractive properties
that they allow to prove for many statistical estimation settings [Marteau-Ferey et al., 2019, Ostrovskii
& Bach, 2021]. The original deﬁnition of self-concordance has been expanded and generalized since
its inception, as many objective functions of interest have self-concordant-like properties without
satisfying the strict deﬁnition of self-concordance. For example, the logistic loss function used in
logistic regression is not strictly self-concordant, but it ﬁts into a class of pseudo-self-concordant
functions, which allows one to obtain similar properties and bounds as those obtained for self-
concordant functions [Bach et al., 2010]. This was also the case in Ostrovskii & Bach [2021] and
Tran-Dinh et al. [2015], in which more general properties of these pseudo-self-concordant functions
were established. This was fully formalized in Sun & Tran-Dinh [2019], in which the concept of
generalized-self concordant functions was introduced, along with key bounds, properties, and variants
of Newton methods for the unconstrained setting which make use of this property.
Most algorithms that aim to solve Problem (1.1) assume access to second-order information, as
this often allows the algorithms to make monotonous progress, remain inside the domain of 𝑓,
and often, converge quadratically when close enough to the optimum. Recently, several lines of
work have focused on using Frank-Wolfe algorithm variants to solve these types of problems in the
projection-free setting, for example constructing second-order approximations to a self-concordant
𝑓using ﬁrst and second order information, and minimizing these approximations over X using
the Frank-Wolfe algorithm [Liu et al., 2020]. Other approaches, such as the ones presented in
Dvurechensky et al. [2020a] (later extended in Dvurechensky et al. [2020b]), apply the Frank-Wolfe
algorithm to a generalized self-concordant 𝑓, using ﬁrst and second-order information about the
function to guarantee that the step sizes are so that the iterates do not leave the domain of 𝑓, and
monotonous progress is made. An additional FW variant in that work, in the spirit of Garber & Hazan
[2016], utilizes ﬁrst and second order information about 𝑓, along with a Local Linear Optimization
Oracle for X, to obtain a linear convergence rate in primal gap over polytopes given in inequality
description. The last algorithm presented in Dvurechensky et al. [2020b], the only one that does not
use second-order information, uses the FW algorithm with the backtracking line search of Pedregosa
et al. [2020] to estimate local smoothness parameters at a given iterate. Other specialized FW
algorithms have been developed for speciﬁc problems involving generalized self-concordant functions,
such as the FW variant developed for marginal inference with concave maximization [Krishnan et al.,
2015], or the variant developed in Zhao & Freund [2020] for 𝜃-homogeneous barrier functions, a
subset of standard self-concordant functions.
1.2 Contribution (see also Table 1)
Simple FW for generalized self-concordant functions.
We show that a small variation of the
original Frank-Wolfe algorithm [Frank & Wolfe, 1956] with an open-loop step size of the form
𝛾𝑡= 2/(𝑡+ 2), where 𝑡is the iteration count is all that is needed to achieve a convergence rate of
O(1/𝑡) in primal gap; this also answers an open question posed in Dvurechensky et al. [2020b]. Our
variation ensures monotonous progress while employing an open-loop strategy which, together with
the iterates being convex combinations, ensures that we do not leave the domain of 𝑓. In contrast
to other methods that depend on either a line search or second-order information, our variant uses
only ﬁrst-order information and a domain oracle for 𝑓(x). The assumption of the latter oracle is very
mild and was also implicitly assumed in the ﬁrst-order algorithm in Dvurechensky et al. [2020b].
As such, our iterations are much cheaper than those in previous work, while essentially achieving
the same convergence rates in the general case of Problem (1.1). Moreover, our variant relying on
2

the open-loop step size 𝛾𝑡= 2/(𝑡+ 2) is adaptive, i.e., does not need to estimate local smoothness
parameters and it allows to establish a convergence rate of O(1/𝑡) for the Frank-Wolfe gap as well.
Algorithm
Convergence
Reference
1st-order /
Requirements
Primal gap
FW gap
LS free?
FW-GSC
O(1/𝜀)
-
[1, Alg.2]
 / 
-
B-FW
O(1/𝜀)
-
[1, Alg.3]
 / 
DO
FW-LLOO
O(log 1/𝜀)
-
[1, Alg.5]
 / 
polyh. X, LLOO
M-FW
O(1/𝜀)
O(1/𝜀)
This work
 / 
DO
B-AFW
O(log 1/𝜀)
O(log 1/𝜀)
This work
 / 
polyh. X, DO
Table 1: Convergence results for Problem 1.1 in the literature to achieve an 𝜀-optimal solution, in
terms of number of iterations. We denote Dvurechensky et al. [2020b] using [1], line search
by LS, domain oracle by DO, and local linear optimization oracle by LLOO.
Faster rates in common special cases.
We also obtain improved convergence rates when the
optimum is contained in the interior of X ∩dom( 𝑓), or when the set X is uniformly or strongly
convex, using the backtracking line search of Pedregosa et al. [2020]. We also show that the Away-
Step Frank-Wolfe algorithm [Lacoste-Julien & Jaggi, 2015, Wolfe, 1970] can use the aforementioned
line search to achieve linear rates over polytopes.
Numerical experiments.
We provide numerical experiments that showcase the performance of
the algorithms on generalized self-concordant objectives to complement the theoretical results. In
particular, they highlight that the simple step size strategy we propose is competitive with and
sometimes outperforms other variants on many instances.
1.3 Preliminaries and Notation
We denote the (potentially non-unique) minimizer of Problem (1.1) by x∗and we denote the primal
gap and the Frank-Wolfe gap at x ∈X as ℎ(x)
def= 𝑓(x) −𝑓(x∗) and 𝑔(x)
def= maxv∈X ⟨∇𝑓(x), x −v⟩,
respectively. We use ∥·∥, ∥·∥𝐻, and ⟨·, ·⟩to denote the Euclidean norm, the matrix norm induced by a
symmetric positive deﬁnite matrix 𝐻∈ℝ𝑛×𝑛, and the Euclidean inner product, respectively. We denote
the diameter of X as 𝐷
def= maxx,y∈X ∥x −y∥. Given a non-empty set X ⊂ℝ𝑛we refer to its boundary
as Bd(X) and to its interior as Int (X). We denote the probability simplex of dimension 𝑛by Δ𝑛and
the domain of 𝑓, as dom( 𝑓)
def= {x ∈ℝ𝑛, 𝑓(x) < +∞}. Given a compact convex set C ⊆dom( 𝑓) we
denote 𝐿C
𝑓=
max
u∈C,d∈ℝ𝑛∥d∥2
∇2 𝑓(u) /∥d∥2
2 and 𝜇C
𝑓=
min
u∈C,d∈ℝ𝑛∥d∥2
∇2 𝑓(u) /∥d∥2
2. We assume access to:
1. Domain Oracle (DO): Given x ∈X, return true if x ∈dom( 𝑓), false otherwise.
2. First-Order Oracle (FOO): Given x ∈dom( 𝑓), return ∇𝑓(x).
3. Linear Minimization Oracle (LMO): Given d ∈ℝ𝑛, return argminx∈X ⟨x, d⟩.
The FOO and LMO oracles are standard in the FW literature and the DO oracle is motivated by the
properties of generalized self-concordant functions. It is reasonable to assume the availability of
such oracles: following the deﬁnition of the function codomain, one could simply evaluate 𝑓at x
and assert 𝑓(x) < +∞. In many cases, testing the membership of x ∈dom( 𝑓) is computationally less
demanding than the function evaluation.
3

Remark 1.1. Access to a domain oracle is a mild assumption, that was also implicitly assumed in
one of the three FW-variants presented in Dvurechensky et al. [2020b] when computing the step size
according to the strategy from Pedregosa et al. [2020]; see Line 3 in Algorithm 3. The remaining two
variants ensure that x ∈dom( 𝑓) by using second-order information about 𝑓, which we explicitly do
not rely on.
The following example motivates the use of Frank-Wolfe algorithms in the context of generalized
self-concordant functions. We present more examples in the computational results.
Example 1.2 (Intersection of a convex set with a polytope). Consider Problem (1.1) where X = P∩C,
P is a polytope over which we can minimize a linear function efﬁciently, and C is a convex compact
set for which one can easily build a barrier function.
-1.5
0.0
1.5
3.0
4.5
4.5
6.0
7.5
x∗
P
C
(a) Plot of 𝑓(x).
2.0
4.0
6.0
8.0
x∗
P
C
(b) Plot of 𝑓(x) + 𝜇′ΦC(x).
-0.5
0.0
0.5
1.0
2.0
4.0
6.0
8.0
x∗
P
C
(c) Plot of 𝑓(x) + 𝜇ΦC(x).
Figure 1: Minimizing 𝑓(x) over P ∩C, versus minimizing the sum of 𝑓(x) and ΦC(x) over P for two
different penalty values 𝜇′ and 𝜇such that 𝜇′ ≫𝜇.
Solving a linear optimization problem over X may be extremely expensive. In light of this, we can
incorporate C into the optimization problem through the use of a barrier penalty in the objective
function, minimizing instead 𝑓(x) + 𝜇ΦC(x) where ΦC(x) is a log-barrier function for C and 𝜇is a
parameter controlling the penalization for points closer to Bd(C). The reformulation of the problem
is illustrated in Figure 1. Note that if the original objective function is generalized self-concordant, so
is the new objective function. We assume that computing the gradient of 𝑓(x) + 𝜇ΦC(x) is roughly
as expensive as computing the gradient for 𝑓(x) and solving an LP over P is inexpensive relative
to solving an LP over P ∩C. The 𝜇parameter can be driven down to 0 after a solution converges
in a warm-starting procedure similar to interior-point methods, ensuring convergence to the true
optimum.
An additional advantage of this transformation of the problem is the solution structure. Running
Frank-Wolfe on the set P ∩C could potentially select a large number of extremal points from Bd(C)
if C is non-polyhedral. In contrast, P has a ﬁnite number of vertices, a small subset of which will be
selected throughout the optimization procedure. The same solution as that of the original problem
can thus be constructed as a convex combination of a small number of vertices of P, improving
sparsity and interpretability in many applications.
The following deﬁnition formalizes the setting of Problem (1.1).
Deﬁnition 1.3 (Generalized self-concordant function). Let 𝑓∈𝐶3 (dom( 𝑓)) be a closed convex
function with dom( 𝑓) ⊆ℝ𝑛open. Then 𝑓is (𝑀, 𝜈) generalized self-concordant if:
|

𝐷3 𝑓(x)[w]u, u

| ≤𝑀∥u∥2
∇2 𝑓(x) ∥w∥𝜈−2
∇2 𝑓(x) ∥w∥3−𝜈
2
,
for any x ∈dom( 𝑓) and u, w ∈ℝ𝑛, where 𝐷3 𝑓(x)[w] = lim
𝛼→0 𝛼−1  ∇2 𝑓(x + 𝛼w) −∇2 𝑓(x).
4

2. Frank-Wolfe Convergence Guarantees
Algorithm 1 Monotonous Frank-Wolfe (M-FW)
Input: Point x0 ∈X ∩dom( 𝑓), function 𝑓
Output: Iterates x1, . . . ∈X
1: for 𝑡= 0 to . . . do
2:
v𝑡←argminv∈X ⟨∇𝑓(x𝑡), v⟩
3:
𝛾𝑡←2/(𝑡+ 2)
4:
x𝑡+1 ←x𝑡+ 𝛾𝑡(v𝑡−x𝑡)
5:
if x𝑡+1 ∉dom( 𝑓) or 𝑓(x𝑡+1) > 𝑓(x𝑡) then
6:
x𝑡+1 ←x𝑡
We establish convergence rates for a Frank-
Wolfe variant with an open-loop step size
strategy on generalized self-concordant
functions. The Monotonous Frank-Wolfe (M-
FW) algorithm presented in Algorithm 1 is a
rather simple, but powerful modiﬁcation of
the standard Frank-Wolfe algorithm, with
the only difference that before taking a step,
we verify if x𝑡+ 𝛾𝑡(v𝑡−x𝑡) ∈dom( 𝑓), and
if so, we check whether moving to the next
iterate provides primal progress. Note, that
the open-loop step size rule 2/(𝑡+ 2) does
not guarantee monotonous primal progress for the vanilla Frank-Wolfe algorithm in general. If either
of these two checks fails, we simply do not move: the algorithm sets x𝑡+1 = x𝑡in Line 6 of Algorithm 1.
As customary, we assume short-circuit evaluation of the logical conditions in Algorithm 1, i.e., if the
ﬁrst condition in Line 5 is true, then the second condition is not even checked, and the algorithm
directly goes to Line 6. This minor modiﬁcation of the vanilla Frank-Wolfe algorithm enables us to use
the monotonicity of the iterates in the proofs to come, at the expense of one extra function evaluation
per iteration. In order to lower bound the progress per iteration we use Proposition 2.1.
Proposition 2.1. (C.f., [Sun & Tran-Dinh, 2019, Proposition 10]) Given a (𝑀, 𝜈) generalized self-
concordant function, then for 𝜈≥2, we have that:
𝑓(y) −𝑓(x) −⟨∇𝑓(x), y −x⟩≤𝜔𝜈(𝑑𝜈(x −y)) ∥y −x∥2
∇2 𝑓(x) ,
(2.1)
where the inequality holds if and only if 𝑑𝜈(x, y) < 1 for 𝜈> 2, and we have that,
𝑑𝜈(x, y)
def=
(
𝑀∥y −x∥
if 𝜈= 2
( 𝜈
2 −1)𝑀∥y −x∥3−𝜈∥y −x∥𝜈−2
∇2 𝑓(x)
if 𝜈> 2,
where:
𝜔𝜈(𝜏)
def=


𝑒𝜏−𝜏−1
𝜏2
if 𝜈= 2
−𝜏−ln(1−𝜏)
𝜏2
if 𝜈= 3
(1−𝜏)ln(1−𝜏)+𝜏
𝜏2
if 𝜈= 4

𝜈−2
4−𝜈

1
𝜏
h
𝜈−2
2(3−𝜈)𝜏

(1 −𝜏)
2(3−𝜈)
2−𝜈
−1

−1
i
otherwise.
The inequality shown in Equation (2.1) is very similar to the one that we would obtain if the gradient
of 𝑓were Lipschitz continuous, however, while the Lipschitz continuity of the gradient leads to an
inequality that holds globally for all x, y ∈dom( 𝑓), the inequality in Equation (2.1) only holds for
𝑑𝜈(x, y) < 1. Moreover, there are two other important differences, the norm used in Equation (2.1) is
now the norm deﬁned by the Hessian at x𝑡instead of the ℓ2 norm, and the term multiplying the norm
is 𝜔𝜈(𝑑𝜈(x, y)) instead of 1/2. We deal with the latter issue by bounding 𝜔𝜈(𝑑𝜈(x, y)) with a constant
that depends on 𝜈for any x, y ∈dom( 𝑓) such that 𝑑𝜈(x, y) ≤1/2, as shown in Remark 2.2.
Remark 2.2. As 𝑑𝜔𝜈(𝜏)/𝑑𝜏> 0 for 𝜏< 1 and 𝜈≥2, then 𝜔𝜈(𝜏) ≤𝜔𝜈(1/2) for 𝜏≤1/2.
Due to the fact that we use a simple step size 𝛾𝑡= 2/(𝑡+ 2), that we make monotonous progress, and
we ensure that the iterates are inside dom( 𝑓), careful accounting allows us to bound the number of
iterations until 𝑑𝜈(x𝑡, x𝑡+ 𝛾𝑡(v𝑡−x𝑡)) ≤1/2. Before formalizing the convergence rate we ﬁrst review
a lemma that we will need in the proof.
5

Lemma 2.3. (C.f., [Sun & Tran-Dinh, 2019, Proposition 7]) Let 𝑓be a generalized self concordant
function with 𝜈> 2. If 𝑑𝜈(x, y) < 1 and x ∈dom( 𝑓) then y ∈dom( 𝑓). For the case 𝜈= 2 we have that
dom( 𝑓) = ℝ𝑛.
Putting all these things together allows us to obtain a convergence rate for Algorithm 1.
Theorem 2.4. Suppose X is a compact convex set and 𝑓is a (𝑀, 𝜈) generalized self-concordant function
with 𝜈≥2. Then the Monotonous Frank-Wolfe algorithm (Algorithm 1) satisﬁes:
ℎ(x𝑡) ≤4(𝑇𝜈+ 1)
𝑡+ 1
max
n
ℎ(x0), 𝐿L0
𝑓𝐷2𝜔𝜈(1/2)
o
.
(2.2)
for 𝑡≥𝑇𝜈, where 𝐿L0
𝑓
=
max
u∈L0,d∈ℝ𝑛∥d∥2
∇2 𝑓(u) /∥d∥2
2 and 𝑇𝜈is deﬁned as:
𝑇𝜈
def=
(
⌈4𝑀𝐷⌉−2
if 𝜈= 2
l
2𝑀𝐷(𝐿L0
𝑓)𝜈/2−1(𝜈−2)
m
−2
otherwise.
(2.3)
Otherwise it holds that ℎ(x𝑡) ≤ℎ(x0) for 𝑡< 𝑇𝜈.
Proof. Consider the compact set L0
def= {x ∈dom( 𝑓) ∩X | 𝑓(x) ≤𝑓(x0)}. As the algorithm makes
monotonous progress and moves towards points such that x𝑡∈dom( 𝑓), then x𝑡∈L0 for 𝑡≥
0. This allows us to claim, in a similar fashion as is done in Dvurechensky et al. [2020b], that
∥x𝑡−v𝑡∥2
∇2 𝑓(x𝑡) ≤𝐿L0
𝑓𝐷2. We then deﬁne 𝑇𝜈as in Equation (2.3). Note that for 𝑡≥𝑇𝜈we have that
𝑑(x𝑡, x𝑡+ 𝛾𝑡(v𝑡−x𝑡)) ≤1/2, and so as x𝑡∈dom( 𝑓) we will have x𝑡+ 𝛾𝑡(v𝑡−x𝑡) ∈dom( 𝑓) for 𝑡≥𝑇𝜈,
by application of Lemma 2.3. This means that the non-zero step size 𝛾𝑡will automatically ensure that
x𝑡+ 𝛾𝑡(v𝑡−x𝑡) ∈dom( 𝑓) in Line 5 of Algorithm 1. Moreover, it allows us to use the upper bound on
the Bregman divergence between points x𝑡and x𝑡+ 𝛾𝑡(v𝑡−x𝑡) in Proposition 2.1, which holds for
𝑑(x𝑡, x𝑡+ 𝛾𝑡(v𝑡−x𝑡)) < 1. With this we can estimate the primal progress we can guarantee for 𝑡≥𝑇𝜈
if we move from x𝑡to x𝑡+ 𝛾𝑡(v𝑡−x𝑡):
ℎ(x𝑡+ 𝛾𝑡(v𝑡−x𝑡)) ≤ℎ(x𝑡) −𝛾𝑡𝑔(x𝑡) + 𝛾2
𝑡𝜔𝜈(𝑑𝜈(x𝑡, x𝑡+ 𝛾𝑡(v𝑡−x𝑡))) ∥v𝑡−x𝑡∥2
∇2 𝑓(x𝑡)
≤ℎ(x𝑡) (1 −𝛾𝑡) + 𝛾2
𝑡𝐿L0
𝑓𝐷2𝜔𝜈(1/2),
where the second inequality follows from the upper bound on the primal gap via the Frank-Wolfe
gap 𝑔(x𝑡), the application of Remark 2.2 as for 𝑡≥𝑇𝜈we have that 𝑑𝜈(x𝑡, x𝑡+ 𝛾𝑡(v𝑡−x𝑡)) ≤1/2, and
from the fact that x𝑡∈L0 for all 𝑡≥0. With the previous chain of inequalities we can bound the
primal progress for 𝑡≥𝑇𝜈as
ℎ(x𝑡) −ℎ(x𝑡+ 𝛾𝑡(v𝑡−x𝑡)) ≥𝛾𝑡ℎ(x𝑡) −𝛾2
𝑡𝐿L0
𝑓𝐷2𝜔𝜈(1/2).
(2.4)
From these facts we can prove the convergence rate shown in Equation (2.2) by induction. The base
case 𝑡= 𝑇𝜈holds trivially by the fact that using monotonicity we have that ℎ(x𝑇𝜈) ≤ℎ(x0). Assuming
the claim is true for some 𝑡≥𝑇𝜈we distinguish two cases.
Case 𝛾𝑡ℎ(x𝑡) −𝛾2
𝑡𝐿L0
𝑓𝐷2𝜔𝜈(1/2) > 0: Focusing on the ﬁrst case, we can plug the previous inequality
into Equation (2.4) to ﬁnd that 𝛾𝑡guarantees primal progress, that is, ℎ(x𝑡) > ℎ(x𝑡+ 𝛾𝑡(v𝑡−x𝑡))
with the step size 𝛾𝑡, and so we know that we will not go into Line 6 of Algorithm 1, and we have
that ℎ(x𝑡+1) = ℎ(x𝑡+ 𝛾𝑡(v𝑡−x𝑡)). Thus using the induction hypothesis and plugging in the expression
for 𝛾𝑡= 2/(𝑡+ 2) into Equation (2.4) we have:
ℎ(x𝑡+1) ≤4 max
n
ℎ(x0), 𝐿L0
𝑓𝐷2𝜔𝜈(1/2)
o 
(𝑇𝜈+ 1)𝑡
(𝑡+ 1)(𝑡+ 2) +
1
(𝑡+ 2)2

≤4(𝑇𝜈+ 1)
𝑡+ 2
max
n
ℎ(x0), 𝐿L0
𝑓𝐷2𝜔𝜈(1/2)
o
,
6

where we use that (𝑇𝜈+ 1)𝑡/(𝑡+ 1) + 1/(𝑡+ 2) ≤𝑇𝜈+ 1 for all 𝑡≥0 and any 𝑡≥𝑇𝜈.
Case 𝛾𝑡ℎ(x𝑡) −𝛾2
𝑡𝐿L0
𝑓𝐷2𝜔𝜈(1/2) ≤0:
In this case, we cannot guarantee that the step size 𝛾𝑡
provides primal progress by plugging into Equation (2.4), and so we cannot guarantee if a step size
of 𝛾𝑡will be accepted and we will have x𝑡+1 = x𝑡+ 𝛾𝑡(v𝑡−x𝑡), or we will simply have x𝑡+1 = x𝑡,
that is, we may go into Line 6 of Algorithm 1. Nevertheless, if we reorganize the expression
𝛾𝑡ℎ(x𝑡) −𝛾2
𝑡𝐿L0
𝑓𝐷2𝜔𝜈(1/2) ≤0, by monotonicity we will have that:
ℎ(x𝑡+1) ≤ℎ(x𝑡) ≤
2
𝑡+ 2 𝐿L0
𝑓𝐷2𝜔𝜈(1/2) ≤4(𝑇𝜈+ 1)
𝑡+ 2
max
n
ℎ(x0), 𝐿L0
𝑓𝐷2𝜔𝜈(1/2)
o
.
Where the last inequality holds as 2 ≤4(𝑇𝜈+ 1) for any 𝑇𝜈≥0.
□
Remark 2.5. In the case where 𝜈= 2 we can easily bound the primal gap ℎ(x1), as in this setting
dom( 𝑓) = ℝ𝑛, which leads to ℎ(x1) ≤𝐿X
𝑓𝐷2 from Equation (2.4), regardless of if we set x1 = x0 or
x1 = v0. Moreover, as the upper bound on the Bregman divergence holds for 𝜈= 2 regardless of the
value of 𝑑2(x, y), we can modify the proof of Theorem 2.4 to obtain a convergence rate of the form
ℎ(x𝑡) ≤2/(𝑡+ 1)𝐿X
𝑓𝐷2𝑤2(𝑀𝐷) for 𝑡≥1, which is reminiscient of the O(𝐿X
𝑓𝐷2/𝑡) rate of the original
Frank-Wolfe algorithm for the smooth and convex case.
Note that in the proof of Theorem 2.4 we explicitly use the progress bound from generalized
self-concordance as opposed to the progress bound that arises from 𝐿L0
𝑓-smoothness, as there is
no straightforward way to bound the number of iterations until the latter progress bound holds
indeﬁnitely for all x𝑡+ 𝛾𝑡(v𝑡−x𝑡), while there is a straightforward criterion on 𝛾𝑡that allows us to
ensure that the former holds from some point onward (see Remark A.1 for more details). Furthermore,
with this simple step size we can also prove a convergence rate for the Frank-Wolfe gap, as shown in
Theorem 2.6 (see Theorem A.2 in Appendix for the proof).
Theorem 2.6. Suppose X is a compact convex set and 𝑓is a (𝑀, 𝜈) generalized self-concordant function
with 𝜈≥2. Then if the Monotonous Frank-Wolfe algorithm (Algorithm 1) is run for 𝑇≥𝑇𝜈+ 6 iterations,
we will have that min
1≤𝑡≤𝑇𝑔(x𝑡) ≤O(1/𝑇).
2.1 Improved convergence guarantees
Algorithm
2
(Monotonous)
Frank-Wolfe
with
Backtrack of Pedregosa et al. [2020]
Input: x0 ∈X ∩dom( 𝑓), function 𝑓, estimate 𝐿−1
Output: Iterates x1, . . . ∈X
1: for 𝑡= 0 to . . . do
2:
v𝑡←argminv∈X ⟨∇𝑓(x𝑡), v⟩
3:
𝛾𝑡, 𝐿𝑡←Backtrack( 𝑓, x𝑡, v𝑡−x𝑡, 𝐿𝑡−1, 1)
4:
x𝑡+1 ←x𝑡+ 𝛾𝑡(v𝑡−x𝑡)
We will now establish improved con-
vergence rates for various special cases.
We ﬁrst focus on the assumption that
x∗∈Int (X ∩dom( 𝑓)), obtaining improved
rates when we use the FW algorithm cou-
pled with the adaptive step size strategy
from Pedregosa et al. [2020] (see Algo-
rithm 3).
The analysis in this case is reminiscent of
the analysis of Guélat & Marcotte [1986],
and is a reasonable assumption if for exam-
ple Bd(X) ⊈dom( 𝑓), and Int (X) ⊆dom( 𝑓). We can upper bound the value of 𝐿𝑡for 𝑡≥0 by
˜𝐿
def= max{𝜏𝐿L0
𝑓, 𝐿−1}, where 𝜏> 1 is the backtracking parameter and 𝐿−1 is the initial smoothness
estimate in Algorithm 3.
7

Algorithm 3 Backtrack( 𝑓, x, d, ∇𝑓(x), 𝐿𝑡−1, 𝛾max) (line search of Pedregosa et al. [2020])
Input: Point x ∈X ∩dom( 𝑓), d ∈ℝ𝑛, function 𝑓, gradient ∇𝑓(x), estimate 𝐿𝑡−1, step 𝛾max
Output: 𝛾, 𝑀
1: Choose 𝜏> 1, 𝜂≤1 and 𝑀∈[𝜂𝐿𝑡−1, 𝐿𝑡−1]
2: 𝛾= min{−⟨∇𝑓(x), d⟩/(𝑀∥d∥2), 𝛾max}
3: while 𝑓(x + 𝛾d) −𝑓(x) > 𝑀𝛾2
2
∥d∥2 + 𝛾⟨∇𝑓(x), d⟩and x + 𝛾d ∈dom( 𝑓) do
4:
𝑀= 𝜏𝑀
5:
𝛾= min{−⟨∇𝑓(x), d⟩/(𝑀∥d∥2), 𝛾max}
Theorem 2.7. Let 𝑓be a (𝑀, 𝜈) generalized self-concordant function with 𝜈≥2 and let dom( 𝑓) not
contain straight lines. Furthermore, we denote by 𝑟> 0 the largest value such that B(x∗, 𝑟) ⊆X∩dom( 𝑓).
Then the Frank-Wolfe algorithm with Backtrack (Algorithm 2) achieves a convergence rate for 𝑡≥1 of:
ℎ(x𝑡) ≤ℎ(x0) ©­
«
1 −
𝜇L0
𝑓
2˜𝐿
 𝑟
𝐷
2ª®
¬
𝑡
.
The assumption that dom( 𝑓) does not contain straight lines in Theorem 2.7 is related to the Hessian
being positive deﬁnite over dom( 𝑓) (see the proof in the Appendix in Theorem A.5). Note that this
is a very mild assumption as we can simply modify the function with a very small ℓ2 regularizer, as
e.g., in Nesterov [2012]. Next, we recall the deﬁnition of uniformly convex sets, used in Kerdreux
et al. [2021], which will allow us to to obtain improved convergence rates for the FW algorithm over
uniformly convex feasible regions.
Deﬁnition 2.8 ((𝜅, 𝑞)-uniformly convex set). Given two positive numbers 𝜅and 𝑞, we say the set
X ⊆ℝ𝑛is (𝜅, 𝑞)-uniformly convex with respect to a norm ∥·∥if for any x, y ∈X, 0 ≤𝛾≤1, and z ∈ℝ𝑛
with ∥z∥= 1 we have that y + 𝛾(x −y) + 𝛾(1 −𝛾) · 𝜅∥x −y∥𝑞z ∈X.
Theorem 2.9. Suppose X is a compact (𝜅, 𝑞)-strongly convex set and 𝑓is a (𝑀, 𝜈) generalized self-
concordant function with 𝜈≥2. Furthermore, assume that minx∈X ∥∇𝑓(x)∥≥𝐶> 0. Then the
Frank-Wolfe algorithm with Backtrack (Algorithm 2) achieves a convergence rate of:
ℎ𝑡≤


ℎ(x0)

1 −1
2 min
n
1, 𝜅𝐶
˜𝐿
o𝑡
if 𝑞= 2
ℎ(x0)
2𝑡
if 𝑞> 2, 1 ≤𝑡≤𝑡0
˜𝐿𝑞/(𝑞−2)/(𝜅𝐶)2/(𝑞−2)
(1+(𝑞−2) (𝑡−𝑡0)/(2𝑞))𝑞/(𝑞−2) = O  𝑡−𝑞/(𝑞−2)
if 𝑞> 2, 𝑡> 𝑡0,
for 𝑡≥1, where 𝑡0 = max
n
1,
j
log1/2

( ˜𝐿𝑞/(𝜅𝐶)2)1/(𝑞−2)
ℎ(x0)
ko
.
However, in the general case we cannot assume that the norm of the gradient is bounded away from
zero over X. We deal with the general case in Theorem 2.10
Theorem 2.10. Suppose X is a compact (𝜅, 𝑞)-strongly convex set and 𝑓is a (𝑀, 𝜈) generalized self-
concordant function with 𝜈≥2 for which the domain does not contain straight lines. Then the
Frank-Wolfe algorithm with Backtrack (Algorithm 2) results in a convergence rate:
ℎ𝑡≤


ℎ(x0)
2𝑡
if 1 ≤𝑡≤𝑡0
( ˜𝐿𝑞/(𝜅2𝜇
L0
𝑓))1/(𝑞−1)
(1+(𝑞−1) (𝑡−𝑡0)/(2𝑞))𝑞/(𝑞−1) = O  𝑡−𝑞/(𝑞−1)
if 𝑡> 𝑡0,
for 𝑡≥1, where 𝑡0 = max

1,

log1/2

( ˜𝐿𝑞/(𝜅2𝜇
L0
𝑓))1/(𝑞−1)
ℎ(x0)

.
8

Remark 2.11. Contrary to previous claims, there is no obstacle for the Away-step Frank-Wolfe (AFW)
algorithm [Guélat & Marcotte, 1986, Lacoste-Julien & Jaggi, 2015] together with the step size
strategy in Algorithm 3 to obtain a linear convergence rate in primal and Frank-Wolfe gap when X is
a polytope and 𝑓is generalized self-concordant. This is not surprising, as 𝑓is strongly convex and
smooth over L0 if dom( 𝑓) does not contain straight lines, and monotonicity ensures the feasibility of
the iterates. We leave the analysis for this case to Appendix B, and the formal convergence statement
to Theorem B.2 and B.3.
3. Computational experiments
We showcase the performance of the Monotonous Frank-Wolfe algorithm (M-FW), the second-order
step size and the LLOO algorithm from Dvurechensky et al. [2020b] (GSC-FW and LLOO) and the
Frank-Wolfe and the Away-Step Frank-Wolfe algorithm with the backtracking stepsize of Pedregosa
et al. [2020], denoted by B-FW and B-AFW respectively. All experiments are carried out in Julia
using the FrankWolfe.jl package [Besançon et al., 2021], available under the MIT license and the
examples considered extend the ones presented in Dvurechensky et al. [2020b] and Liu et al. [2020].
We also use the vanilla FW algorithm denoted by FW, which is simply Algorithm 1 without Lines 5
and 6 using the traditional 𝛾𝑡= 2/(𝑡+ 2) open-loop step size rule. Note that there are no formal
convergence guarantees for this algorithm when applied to Problem (1.1). Details on the experiments
setup, data and remarks on the considered problems are provided in Appendix C. All ﬁgures show
the evolution of the ℎ(x𝑡) and 𝑔(x𝑡) against time and number of iterations with a log-log scale.
As in Dvurechensky et al. [2020b] we implemented the LLOO based variant only for the portfolio
optimization instance over the probability simplex; for the other examples the oracle implementation
was less straightforward due to the estimation of parameters.
As can be seen in all experiments, the Monotonous Frank-Wolfe algorithm is very competitive,
outperforming previously proposed variants in both in progress per iteration and time. The only other
algorithm that is sometimes faster is the Away-Step Frank-Wolfe variant as detailed in Remark 2.11,
which however depends on an active set, and can induce up to a quadratic overhead, making iterations
progressively more expensive; this can be also observed in our experiments as the advantage in time
is much less pronounced than in iterations.
Portfolio optimization. We consider 𝑓(x) = −Í𝑝
𝑡=1 log(⟨r𝑡, x⟩), where 𝑝denotes the number of
periods and X = Δ𝑛. The results are shown in Figure 2.
Signal recovery with KL divergence. We apply the aforementioned algorithms to the recovery
of a sparse signal from a noisy linear image using the Kullback-Leibler divergence, expressed as
𝑓(x) = 𝐷(𝑊x, y) = Í𝑁
𝑖=1
n
⟨w𝑖, x⟩log

⟨w𝑖,x⟩
𝑦𝑖

−⟨w𝑖, x⟩+ 𝑦𝑖
o
, where w𝑖is the 𝑖th row of a matrix 𝑊. In
order to promote sparsity and enforce nonnegativity of the solution, we use the unit simplex of radius
𝑅as the feasible set X = {x ∈ℝ𝑑
+, ∥x∥1 ≤𝑅}. The results are shown in Figure 3. We used the same
𝑀= 1 choice for the second-order method as in Dvurechensky et al. [2020b] for comparison; its
admissibility is unknown (see Remark C.1).
Logistic regression. We consider a logistic regression task with a design matrix with rows a𝑖∈ℝ𝑛
with 1 ≤𝑖≤𝑁and a vector y ∈{−1, 1}𝑁and formulate the problem with elastic net regularization,
in a similar fashion as is done in Liu et al. [2020], with 𝑓(x) = 1/𝑁Í𝑁
𝑖=1 log(1 + exp(−𝑦𝑖⟨x, a𝑖⟩)) +
𝜇/2 ∥x∥2, where 𝜇is a regularization parameter and X is the ℓ1 ball of radius 𝜌. The results can be
seen in Figure 4 and Appendix C.
Birkhoff polytope. All previously considered applications have in common a feasible region possess-
ing computationally inexpensive LMOs (probability/unit simplex and ℓ1 norm ball). Additionally, each
vertex returned from the LMO is highly sparse with at most one non-zero element. To complement
9

the results, we consider the logistic regression problem over the Birkhoff polytope, where the LMO
call uses the Hungarian method and is not as inexpensive as in the other examples. The results are
shown in Figure 5.
100
101
102
103
Iteration
10−10
10−6
10−2
ℎ(x푡)
10−1
101
103
Time [s]
100
101
102
103
Iteration
10−5
10−3
10−1
101
푔(x푡)
10−1
101
103
Time [s]
M-FW
FW
B-FW
B-AFW
GSC-FW
LLOO
Figure 2: Portfolio Optimization: LLOO and GSC-FW perform similarly to FW on a per-iteration basis
but the iterations are computationally more expensive. B-AFW is the fastest method both in
terms iteration and runtime, followed by M-FW which is the only other method to terminate
with the speciﬁed dual gap tolerance.
100
101
102
103
Iteration
10−3
100
103
ℎ(x푡)
10−1
101
103
Time [s]
100
101
102
103
Iteration
101
103
105
푔(x푡)
10−1
101
103
Time [s]
M-FW
FW
B-FW
B-AFW
GSC-FW
Figure 3: Signal Recovery: B-AFW signiﬁcantly outperforms all other methods. FW and B-FW perform
similarly in dual gap progress and converge slower than M-FW. In terms of primal gap
progress, M-FW and FW perform similarly and outperform B-FW.
100
102
104
Iteration
10−11
10−8
10−5
10−2
ℎ(x푡)
10−1
101
103
Time [s]
100
102
104
Iteration
10−6
10−4
10−2
100
푔(x푡)
M-FW
FW
B-FW
B-AFW
GSC-FW
10−1
101
103
Time [s]
Figure 4: Logistic Regression: This instance shows that although simple in essence, M-FW can
outperform other methods including B-AFW in terms of convergence. The primal and dual
gaps for B-FW and GSC-FW converge at similar rates against iteration count.
10

100
102
104
Iteration
10−11
10−7
10−3
101
ℎ(x푡)
10−1
101
Time [s]
100
102
104
Iteration
10−6
10−4
10−2
100
푔(x푡)
10−1
101
Time [s]
M-FW
FW
B-FW
B-AFW
GSC-FW
Figure 5: Birkhoff Polytope: B-AFW is the fastest-converging method for all measures. However, the
dual gap reaches a plateau due to numerical issues above the termination threshold, unlike
M-FW which reaches the dual gap tolerance. GSC-FW is run for 1000 iterations only given
the longer runtime. Its slow progress is likely due to numerical instabilities in the Hessian
computation which do not occur in ﬁrst-order methods.
Acknowledgements
Research reported in this paper was partially supported through the Research Campus Modal funded
by the German Federal Ministry of Education and Research (fund numbers 05M14ZAM,05M20ZBM)
and the Deutsche Forschungsgemeinschaft (DFG) through the DFG Cluster of Excellence MATH+.
11

References
Bach, F. et al. Self-concordant analysis for logistic regression. Electronic Journal of Statistics, 4:
384–414, 2010.
Besançon, M., Carderera, A., and Pokutta, S. FrankWolfe.jl: a high-performance and ﬂexible toolbox
for Frank-Wolfe algorithms and conditional gradients. arXiv preprint arXiv:2104.06675, 2021.
Csiszar, I. et al. Why least squares and maximum entropy? An axiomatic approach to inference for
linear inverse problems. The annals of statistics, 19(4):2032–2066, 1991.
Dvurechensky, P., Ostroukhov, P., Saﬁn, K., Shtern, S., and Staudigl, M. Self-concordant analysis of
Frank-Wolfe algorithms. In Proceedings of the 37th International Conference on Machine Learning,
pp. 2814–2824. PMLR, 2020a.
Dvurechensky, P., Saﬁn, K., Shtern, S., and Staudigl, M. Generalized self-concordant analysis of
Frank-Wolfe algorithms. arXiv preprint arXiv:2010.01009, 2020b.
Frank, M. and Wolfe, P. An algorithm for quadratic programming. Naval research logistics quarterly, 3
(1-2):95–110, 1956.
Garber, D. and Hazan, E.
A linearly convergent variant of the conditional gradient algorithm
under strong convexity, with applications to online and stochastic optimization. SIAM Journal on
Optimization, 26(3):1493–1528, 2016.
Guélat, J. and Marcotte, P. Some comments on Wolfe’s ‘away step’. Mathematical Programming, 35
(1):110–119, 1986.
Jaggi, M. Revisiting Frank-Wolfe: Projection-free sparse convex optimization. In Proceedings of the
30th International Conference on Machine Learning, pp. 427–435. PMLR, 2013.
Kerdreux, T., d’Aspremont, A., and Pokutta, S. Restarting Frank-Wolfe. In Proceedings of the 22nd
International Conference on Artiﬁcial Intelligence and Statistics, pp. 1275–1283. PMLR, 2019.
Kerdreux, T., d’Aspremont, A., and Pokutta, S. Projection-free optimization on uniformly convex sets.
In Proceedings of the 24th International Conference on Artiﬁcial Intelligence and Statistics, pp. 19–27.
PMLR, 2021.
Krishnan, R. G., Lacoste-Julien, S., and Sontag, D. Barrier Frank-Wolfe for Marginal Inference. In
Proceedings of the 28th Conference in Neural Information Processing Systems. PMLR, 2015.
Lacoste-Julien, S. and Jaggi, M. On the global linear convergence of Frank-Wolfe optimization
variants. In Proceedings of the 29th Conference on Neural Information Processing Systems, pp.
566–575. PMLR, 2015.
Levitin, E. S. and Polyak, B. T. Constrained minimization methods. USSR Computational Mathematics
and Mathematical Physics, 6(5):1–50, 1966.
Liu, D., Cevher, V., and Tran-Dinh, Q. A Newton Frank-Wolfe method for constrained self-concordant
minimization. arXiv preprint arXiv:2002.07003, 2020.
Marron, J. S., Todd, M. J., and Ahn, J. Distance-weighted discrimination. Journal of the American
Statistical Association, 102(480):1267–1271, 2007.
Marteau-Ferey, U., Ostrovskii, D., Bach, F., and Rudi, A.
Beyond least-squares: Fast rates for
regularized empirical risk minimization through self-concordance. In Proceedings of the 32nd
Conference on Learning Theory, pp. 2294–2340. PMLR, 2019.
12

Nesterov, Y. How to make the gradients small. Optima. Mathematical Optimization Society Newsletter,
(88):10–11, 2012.
Nesterov, Y. and Nemirovskii, A. Interior-point polynomial algorithms in convex programming. SIAM,
1994.
Nesterov, Y. et al. Lectures on convex optimization, volume 137. Springer, 2018.
Ostrovskii, D. M. and Bach, F. Finite-sample analysis of M-estimators using self-concordance. Electronic
Journal of Statistics, 15(1):326–391, 2021.
Pedregosa, F., Negiar, G., Askari, A., and Jaggi, M. Linearly convergent Frank–Wolfe with backtracking
line-search. In Proceedings of the 23rd International Conference on Artiﬁcial Intelligence and Statistics.
PMLR, 2020.
Sun, T. and Tran-Dinh, Q. Generalized self-concordant functions: a recipe for Newton-type methods.
Mathematical Programming, 178(1):145–213, 2019.
Temlyakov, V. Greedy approximation in convex optimization. Constructive Approximation, 41(2):
269–296, 2015.
Tran-Dinh, Q., Li, Y.-H., and Cevher, V. Composite convex minimization involving self-concordant-like
cost functions. In Modelling, Computation and Optimization in Information Systems and Management
Sciences, pp. 155–168. Springer, 2015.
Wolfe, P. Convergence theory in nonlinear programming. In Integer and Nonlinear Programming, pp.
1–36. North-Holland, Amsterdam, 1970.
Zhao, R. and Freund, R. M. Analysis of the Frank-Wolfe method for logarithmically-homogeneous
barriers, with an extension. arXiv preprint arXiv:2010.08999, 2020.
13

Simple steps are all you need: Frank-Wolfe
and generalized self-concordant functions
Supplementary material
Outline.
The appendix of the paper is organized as follows:
• Section A presents the full convergence proof of the Frank-Wolfe gap for the Monotonous Frank-
Wolfe algorithm, and improved convergence bounds when using the Frank-Wolfe algorithm with
the step size strategy of Pedregosa et al. [2020] when the optimum is contained in the interior of
X ∩dom( 𝑓), or when the feasible region is strongly convex.
• Section B reviews the Away-step Frank-Wolfe algorithm [Guélat & Marcotte, 1986, Lacoste-Julien
& Jaggi, 2015], and shows how using the step size strategy of Pedregosa et al. [2020] one can
show a linear convergence in primal gap and in Frank-Wolfe gap when the feasible region is a
polytope.
• Section C presents additional information about the experimental section of the paper.
Appendix A. Monotonous Frank-Wolfe
This appendix contains the theoretical proofs that have not been included in the main body of the
paper due to space constraints, as well as several remarks of interest. We start off with a remark
regarding the convergence proof in Theorem 2.4, and continue by showing that the Monotonous
Frank-Wolfe algorithm (restated for convenience in Algorithm 4) not only contracts the primal gap at
a rate of O(1/𝑡) where 𝑡is the iteration count, but also ensures that the minimum of the Frank-Wolfe
gap over the run of the algorithm is bounded by O(1/𝑡) from above.
Algorithm 4 Monotonous Frank-Wolfe (M-FW)
Input: Point x0 ∈X ∩dom( 𝑓), function 𝑓
Output: Iterates x1, . . . ∈X
1: for 𝑡= 0 to . . . do
2:
v𝑡←argminv∈X ⟨∇𝑓(x𝑡), v⟩
3:
𝛾𝑡←2/(𝑡+ 2)
4:
x𝑡+1 ←x𝑡+ 𝛾𝑡(v𝑡−x𝑡)
5:
if x𝑡+1 ∉dom( 𝑓) or 𝑓(x𝑡+1) > 𝑓(x𝑡) then
6:
x𝑡+1 ←x𝑡
Remark A.1 (Regarding the proof of Theorem 2.4). One of the quantities that we have used in the
proof of Theorem 2.4 is 𝐿L0
𝑓. Note that the function 𝑓is 𝐿L0
𝑓-smooth over L0. One could wonder then
why we have bothered to use the bounds on the Bregman divergence in Proposition 2.1 for a (𝑀, 𝜈)-
generalized self-concordant function, instead of simply using the bounds from the 𝐿L0
𝑓-smoothness
of 𝑓over L0. The reason is that the upper bound on the Bregman divergence in Proposition 2.1
applies for any x, y ∈dom( 𝑓) such that 𝑑𝜈(x, y) < 1, and we can easily bound the number of
iterations 𝑇𝜈it takes for the step size 𝛾𝑡= 2/(𝑡+ 2) to verify both x𝑡, x𝑡+ 𝛾𝑡(v𝑡−x𝑡) ∈dom( 𝑓)
and 𝑑𝜈(x𝑡, x𝑡+ 𝛾𝑡(v𝑡−x𝑡)) < 1 for 𝑡≥𝑇𝜈. However, in order to apply the bounds on the Bregman
divergence we need x𝑡, x𝑡+𝛾𝑡(v𝑡−x𝑡) ∈L0, and while it is easy to show by monotonicity that x𝑡∈L0,
14

there is no straightforward way to prove that for some ˜𝑇𝜈we have that x𝑡+ 𝛾𝑡(v𝑡−x𝑡) ∈L0 for all
𝑡≥˜𝑇𝜈.
A.1 Convergence of the Frank-Wolfe gap for the Monotonous Frank-Wolfe
algorithm
In this section of the appendix we show that when running the Monotonous Frank-Wolfe algorithm
(Algorithm 1) the minimum of the Frank-Wolfe gap over the run of the algorithm converges at a
rate of O(1/𝑡). The idea of the proof is very similar to the one in Jaggi [2013]. In a nutshell, as the
primal progress per iteration is directly related to the step size times the Frank-Wolfe gap, we know
that the Frank-Wolfe gap cannot remain indeﬁnitely above a given value, as otherwise we would
obtain a large amount of primal progress, which would make the primal gap become negative. This
is formalized in Theorem A.2.
Theorem A.2. Suppose X is a compact convex set and 𝑓is a (𝑀, 𝜈) generalized self-concordant function
with 𝜈≥2. Then if the Monotonous Frank-Wolfe algorithm (Algorithm 1) is run for 𝑇≥𝑇𝜈+ 6 iterations,
we will have that:
min
1≤𝑡≤𝑇𝑔(x𝑡) ≤O(1/𝑇),
where 𝑇𝜈is deﬁned as:
𝑇𝜈
def=
(
⌈4𝑀𝐷⌉−2
if 𝜈= 2
l
2𝑀𝐷(𝐿L0
𝑓)𝜈/2−1(𝜈−2)
m
−2
otherwise.
(A.1)
Proof. In order to prove the claim, we focus on the iterations 𝑇𝜈+ ⌈(𝑇−𝑇𝜈)/3⌉−2 ≤𝑡≤𝑇−2,
where 𝑇𝜈is deﬁned in Equation (A.1). Note that as we assume that 𝑇≥𝑇𝜈+ 6, we know that
𝑇𝜈≤𝑇𝜈+ ⌈(𝑇−𝑇𝜈)/3⌉−2, and so for iterations 𝑇𝜈+ ⌈(𝑇−𝑇𝜈)/3⌉−2 ≤𝑡≤𝑇−2 we know that
𝑑𝜈(x𝑡, x𝑡+1) ≤1/2, and so:
ℎ(x𝑡+1) ≤ℎ(x𝑡) −𝛾𝑡𝑔(x𝑡) + 𝛾2
𝑡𝐿L0
𝑓𝐷2𝜔𝜈(1/2).
(A.2)
In a very similar fashion as was done in the proof of Theorem 2.4, we divide the proof into two
different cases.
Case −𝛾𝑡𝑔(x𝑡) + 𝛾2
𝑡𝐿L0
𝑓𝐷2𝜔𝜈(1/2) ≥0 for some 𝑇𝜈+ ⌈(𝑇−𝑇𝜈)/3⌉−2 ≤𝑡≤𝑇−2: Reordering the
inequality above we therefore know that there exists a 𝑇𝜈+ ⌈(𝑇−𝑇𝜈)/3⌉−2 ≤𝐾≤𝑇−2 such that:
𝑔(x𝐾) ≤
2
2 + 𝐾𝐿L0
𝑓𝐷2𝜔𝜈(1/2)
≤
2
𝑇𝜈+ ⌈(𝑇−𝑇𝜈)/3⌉𝐿L0
𝑓𝐷2𝜔𝜈(1/2)
=
6
2𝑇𝜈+ 𝑇𝐿L0
𝑓𝐷2𝜔𝜈(1/2),
where the second inequality follows from the fact that 𝑇𝜈+ ⌈(𝑇−𝑇𝜈)/3⌉−2 ≤𝐾. This leads to
min
1≤𝑡≤𝑇𝑔(x𝑡) ≤𝑔(x𝐾) ≤
6
2𝑇𝜈+𝑇𝐿L0
𝑓𝐷2𝜔𝜈(1/2).
Case −𝛾𝑡𝑔(x𝑡)+𝛾2
𝑡𝐿L0
𝑓𝐷2𝜔𝜈(1/2) < 0 for all 𝑇𝜈+𝑇𝜈+⌈(𝑇−𝑇𝜈)/3⌉−2 ≤𝑡≤𝑇−2: Using the inequality
above and plugging into Equation (A.2) allows us to conclude that all steps 𝑇𝜈+𝑇𝜈+ ⌈(𝑇−𝑇𝜈)/3⌉−2 ≤
𝑡≤𝑇−2 will produce primal progress using the step size 𝛾𝑡, and so as we know that x𝑡+1 ∈dom( 𝑓)
by Lemma 2.3, then for all 𝑇𝜈+ ⌈(𝑇−𝑇𝜈)/3⌉−2 ≤𝑡≤𝑇−2 we will take a non-zero step size
determined by 𝛾𝑡, as x𝑡+ 𝛾𝑡(v𝑡−x𝑡) ∈dom( 𝑓) and 𝑓(x𝑡+ 𝛾𝑡(v𝑡−x𝑡)) < 𝑓(x𝑡) in Line 5 of Algorithm 1.
15

Consequently, summing up Equation (A.2) from 𝑡min
def= 𝑇𝜈+ ⌈(𝑇−𝑇𝜈)/3⌉−2 to 𝑡max
def= 𝑇−2 we have
that:
ℎ(x𝑡max+1) ≤ℎ x𝑡min
 −
𝑡max
∑︁
𝑡=𝑡min
𝛾𝑡𝑔(x𝑡) + 𝐿L0
𝑓𝐷2𝜔𝜈(1/2)
𝑡max
∑︁
𝑡=𝑡min
𝛾2
𝑡
(A.3)
≤ℎ x𝑡min
 −2
min
𝑡min ≤𝑡≤𝑡max 𝑔(x𝑡)
𝑡max
∑︁
𝑡=𝑡min
1
2 + 𝑖+ 4𝐿L0
𝑓𝐷2𝜔𝜈(1/2)
𝑡max
∑︁
𝑡=𝑡min
1
(2 + 𝑡)2
(A.4)
≤ℎ x𝑡min
 −2 min
1≤𝑡≤𝑇𝑔(x𝑡) 𝑡max −𝑡min + 1
2 + 𝑡max
+ 4𝐿L0
𝑓𝐷2𝜔𝜈(1/2) 𝑡max −𝑡min + 1
(2 + 𝑡min)2
(A.5)
≤4
 𝑇𝜈+ 1
𝑡min + 1 + 𝑡max −𝑡min + 1
(2 + 𝑡min)2

max
n
ℎ(x0), 𝐿L0
𝑓𝐷2𝜔𝜈(1/2)
o
(A.6)
−2 min
1≤𝑡≤𝑇𝑔(x𝑡) 𝑡max −𝑡min + 1
2 + 𝑡max
.
(A.7)
Note that Equation A.4 stems from the fact that min𝑡min ≤𝑡≤𝑡max 𝑔(x𝑡) ≤𝑔(x𝑡) for any 𝑡min ≤𝑡≤𝑡max,
and from plugging 𝛾𝑡= 2/(2+𝑡), and Equation A.5 follows from the fact that −1/(2+𝑡) ≤−1/(2+𝑡max)
and 1/(2 + 𝑡) ≤1/(2 + 𝑡min) for all 𝑡min ≤𝑡≤𝑡max. The last inequality, Equation (A.6) and (A.7) arises
from plugging in the upper bound on the primal gap ℎ(x𝑡min) from Theorem 2.4 and collecting terms.
If we plug in the speciﬁc values of 𝑡max and 𝑡min this leads to:
ℎ(x𝑇−2) ≤12

𝑇𝜈+ 1
2𝑇𝜈+ 𝑇−3 + 2𝑇−2𝑇𝜈+ 3
(2𝑇𝜈+ 𝑇)2

max
n
ℎ(x0), 𝐿L0
𝑓𝐷2𝜔𝜈(1/2)
o
(A.8)
−2
3 min
1≤𝑡≤𝑇𝑔(x𝑡)𝑇−𝑇𝜈
𝑇
.
(A.9)
We establish our claim using proof by contradiction. Assume that:
min
1≤𝑡≤𝑇𝑔(x𝑡) >
18𝑇
𝑇−𝑇𝜈

𝑇𝜈+ 1
2𝑇𝜈+ 𝑇−3 + 2𝑇−2𝑇𝜈+ 3
(2𝑇𝜈+ 𝑇)2

max
n
ℎ(x0), 𝐿L0
𝑓𝐷2𝜔𝜈(1/2)
o
.
Then by plugging into the bound in Equation (A.9) we have that ℎ(x𝑇−2) < 0, which is the desired
contradiction, as the primal gap cannot be negative. Therefore we must have that:
min
1≤𝑖≤𝑇𝑔(x𝑖) ≤
18𝑇
𝑇−𝑇𝜈

𝑇𝜈+ 1
2𝑇𝜈+ 𝑇−3 + 2𝑇−2𝑇𝜈+ 3
(2𝑇𝜈+ 𝑇)2

max
n
ℎ(x0), 𝐿L0
𝑓𝐷2𝜔𝜈(1/2)
o
= O(1/𝑇).
This completes the proof.
□
A.2 Improved convergence bounds
We focus on two different settings to obtain improved convergence rates, in the ﬁrst we assume that
x∗∈Int (X ∩dom( 𝑓)) (Section A.2.1), and in the second we assume that X is strongly or uniformly
convex (Section A.2.2). In this section we focus on the combination of a slightly modiﬁed Frank-Wolfe
algorithm with the adaptive line search technique of Pedregosa et al. [2020] (shown for reference in
Algorithm 5 and 6). This is the same algorithm used in Dvurechensky et al. [2020b], however we
show improved convergence rates in several settings of interest.
16

Algorithm 5 Monotonous Frank-Wolfe with the adaptive step size of Pedregosa et al. [2020]
Input: Point x0 ∈X ∩dom( 𝑓), function 𝑓, initial smoothness estimate 𝐿−1
Output: Iterates x1, . . . ∈X
1: for 𝑡= 0 to . . . do
2:
v𝑡←argminv∈X ⟨∇𝑓(x𝑡), v⟩
3:
𝛾𝑡, 𝐿𝑡←Backtrack( 𝑓, x𝑡, v𝑡−x𝑡, 𝐿𝑡−1, 1)
4:
x𝑡+1 ←x𝑡+ 𝛾𝑡(v𝑡−x𝑡)
Algorithm 6 Backtrack( 𝑓, x, d, 𝐿𝑡−1, 𝛾max) (line search of Pedregosa et al. [2020])
Input: Point x ∈X ∩dom( 𝑓), v ∈ℝ𝑛, function 𝑓, estimate 𝐿𝑡−1, step size 𝛾max
Output: 𝛾, 𝑀
1: Choose 𝜏> 1, 𝜂≤1 and 𝑀∈[𝜂𝐿𝑡−1, 𝐿𝑡−1]
2: 𝛾= min{−⟨∇𝑓(x), d⟩/(𝑀∥d∥2), 𝛾max}
3: while 𝑓(x + 𝛾d) −𝑓(x) > 𝑀𝛾2
2
∥d∥2 + 𝛾⟨∇𝑓(x), d⟩and x + 𝛾d ∈dom( 𝑓) do
4:
𝑀= 𝜏𝑀
5:
𝛾= min{−⟨∇𝑓(x), d⟩/(𝑀∥d∥2), 𝛾max}
A.2.1 OPTIMUM CONTAINED IN THE INTERIOR
Before proving the main theoretical results of this section we ﬁrst review some auxiliary results that
allow us to prove the linear convergence in this setting.
Theorem A.3. (C.f., [Nesterov et al., 2018, Theorem 5.1.6]) Let 𝑓be generalized self-concordant and
dom( 𝑓) not contain straight lines, then the Hessian ∇2 𝑓(x) is non-degenerate at all points x ∈dom( 𝑓).
Note that the assumption that dom( 𝑓) not contain straight lines is without loss of generality as we
can simply modify the function outside of our compact convex feasible region so that it holds.
Proposition A.4. (C.f., Guélat & Marcotte [1986]) If there exists an 𝑟> 0 such that B(x∗, 𝑟) ⊆
X ∩dom( 𝑓), then for all x ∈X ∩dom( 𝑓) we have that:
𝑔(x)
∥x −v∥≥𝑟
𝐷∥∇𝑓(x)∥≥𝑟
𝐷
⟨∇𝑓(x), x −x∗⟩
∥x −x∗∥
,
where v = argmin
y∈X
⟨∇𝑓(x), y⟩and 𝑔(x) is the Frank-Wolfe gap.
With these tools at hand, we have that the Frank-Wolfe algorithm with the backtracking step size
strategy converges at a linear rate.
Theorem A.5. Let 𝑓be a (𝑀, 𝜈) generalized self-concordant function with 𝜈≥2 and let dom( 𝑓) not
contain straight lines. Furthermore, we denote by 𝑟> 0 the largest value such that B(x∗, 𝑟) ⊆X∩dom( 𝑓).
Then the Frank-Wolfe algorithm (Algorithm 5) with the backtracking strategy of Pedregosa et al. [2020]
results in a convergence:
ℎ(x𝑡) ≤ℎ(x0) ©­
«
1 −
𝜇L0
𝑓
2˜𝐿
 𝑟
𝐷
2ª®
¬
𝑡
,
for 𝑡≥1, where ˜𝐿
def= max{𝜏𝐿L0
𝑓, 𝐿−1}, 𝜏> 1 is the backtracking parameter, 𝐿−1 is the initial smoothness
estimate in Algorithm 6, 𝜇L0
𝑓
=
min
u∈L0,d∈ℝ𝑛∥d∥2
∇2 𝑓(u) /∥d∥2
2 and 𝐿L0
𝑓
=
max
u∈L0,d∈ℝ𝑛∥d∥2
∇2 𝑓(u) /∥d∥2
2.
17

Proof. Consider the compact set L0
def= {x ∈dom( 𝑓) ∩X | 𝑓(x) ≤𝑓(x0)}. As the backtracking line
search makes monotonous primal progress, we know that for 𝑡≥0 we will have that x𝑡∈L0.
Consequently we can deﬁne 𝜇L0
𝑓
= minu∈L0,d∈ℝ𝑛∥d∥2
∇2 𝑓(u) /∥d∥2
2. As by our assumption dom( 𝑓) does
not contain any straight lines we know that for all x ∈dom( 𝑓) the Hessian is non-degenerate, and
therefore 𝜇L0
𝑓
> 0. This allows us to claim that for any x, y ∈L0 we have that:
𝑓(x) −𝑓(y) −⟨∇𝑓(y), x −y⟩≥
𝜇L0
𝑓
2
∥x −y∥2 .
(A.10)
The backtracking line search in Algorithm 6 will either output a point 𝛾𝑡= 1 or 𝛾𝑡< 1. In any
case, Algorithm 6 will ﬁnd and output a smoothness estimate 𝐿𝑡and a step size 𝛾𝑡such that for
x𝑡+1 = x𝑡+ 𝛾𝑡(v𝑡−x𝑡) we have that:
𝑓(x𝑡+1) −𝑓(x𝑡) ≤𝐿𝑡𝛾2
𝑡
2
∥x𝑡−v𝑡∥2 −𝛾𝑡𝑔(x𝑡).
(A.11)
In the case where 𝛾𝑡= 1 we know by observing Line 5 of Algorithm 6 that 𝑔(x𝑡) ≥𝐿𝑡∥x𝑡−v𝑡∥2,
and so plugging into Equation (A.11) we arrive at ℎ(x𝑡+1) ≤ℎ(x𝑡)/2. In the case where 𝛾𝑡=
𝑔(x𝑡)/(𝐿𝑡∥x𝑡−v𝑡∥2) < 1, we have that 𝑔(x𝑡) < 𝐿𝑡∥x𝑡−v𝑡∥2, which leads to ℎ(x𝑡+1) ≤ℎ(x𝑘) −
𝑔(x𝑡)2/(2𝐿𝑡∥x𝑡−v𝑡∥2), when plugging the expression for the step size in the progress bound in
Equation A.11. In this last case where 𝛾𝑡< 1 we have the following contraction for the primal gap:
ℎ(x𝑡) −ℎ(x𝑡+1) ≥
𝑔(x𝑡)2
2𝐿𝑡∥x𝑡−v𝑡∥2
≥𝑟2
𝐷2
∥∇𝑓(x𝑡)∥2
2𝐿𝑡
≥
𝜇L0
𝑓
˜𝐿
𝑟2
𝐷2 ℎ(x𝑡),
where we have used the inequality that involves the central term and the leftmost term in Proposi-
tion A.4, and the last inequality stems from the bound ℎ(x𝑡) ≤∥∇𝑓(x𝑡)∥2 /(2𝜇L0
𝑓) for 𝜇L0
𝑓-strongly
convex functions. Putting the above bounds together we have that:
ℎ(x𝑡+1) ≤ℎ(x𝑡) ©­
«
1 −1
2 min


1,
𝜇L0
𝑓
˜𝐿
 𝑟
𝐷
2

ª®
¬
≤ℎ(x𝑡) ©­
«
1 −
𝜇L0
𝑓
2˜𝐿
 𝑟
𝐷
2ª®
¬
,
which completes the proof.
□
The previous bound depends on the largest positive 𝑟such that B(x∗, 𝑟) ⊆X ∩dom( 𝑓), which can be
arbitrarily small. Note also that the previous proof uses the lower bound of the Bregman divergence
from the 𝜇L0
𝑓-strong convexity of the function over L0 to obtain linear convergence. Note that
this bound is local, and is only of use because the step size strategy of Algorithm 6 automatically
ensures that if x𝑡∈L0 and d𝑡is a direction of descent, then x𝑡+ 𝛾𝑡d𝑡∈L0. This is in contrast with
Algorithm 4, in which the step size 𝛾𝑡= 2/(2 + 1) did not automatically ensure monotonicity in primal
gap, and this had to be enforced by setting x𝑡+1 = x𝑡if 𝑓(x𝑡+ 𝛾𝑡d𝑡) > 𝑓(x𝑡), where d𝑡= v𝑡−x𝑡. If
we were to have used the lower bound on the Bregman divergence from Sun & Tran-Dinh [2019,
Proposition 10] in the proof, which states that:
𝑓(y) −𝑓(x) −⟨∇𝑓(x), y −x⟩≥𝜔𝜈(−𝑑𝜈(x −y)) ∥y −x∥2
∇2 𝑓(x) ,
18

for any x, y ∈dom( 𝑓) and any 𝜈≥2, we would have arrived at a bound that holds over all dom( 𝑓).
However, in order to arrive at a usable bound, and armed only with the knowledge that the Hessian
is non-degenerate if dom( 𝑓) does not contain straight lines, and that x, y ∈L0, we would have had
to write:
𝜔𝜈(−𝑑𝜈(x −y)) ∥x −y∥2
∇2 𝑓(y) ≥𝜇L0
𝑓𝜔𝜈(−𝑑𝜈(x −y)) ∥x −y∥2 ,
where the inequality follows from the deﬁnition of 𝜇L0
𝑓. It is easy to see that as 𝑑𝜔𝜈(𝜏)/𝑑𝜏> 0 by
Remark 2.2, we have that 1/2 = 𝜔𝜈(0) ≥𝜔𝜈(−𝑑𝜈(x −y)). This results in a bound:
𝑓(y) −𝑓(x) −⟨∇𝑓(x), y −x⟩≥𝜇L0
𝑓𝜔𝜈(−𝑑𝜈(x −y)) ∥x −y∥2 .
(A.12)
When we compare the bounds on Equation (A.10) and (A.12), we can see that the bound from 𝜇L0
𝑓-
strong convexity is tighter than the bound from the properties of (𝑀, 𝜈)-generalized self-concordant
functions, albeit local. This is the reason why we have used the former bound in the proof of
Theorem A.5.
A.2.2 STRONGLY CONVEX OR UNIFORMLY CONVEX SETS
In order to prove convergence rate results for the case where the feasible region is (𝜅, 𝑝)-strongly
convex, we ﬁrst review the deﬁnition of the (𝜅, 𝑝)-strong convexity of a set (see Deﬁnition A.6), as
well as a useful lemma that allows us to go from contractions to convergence rates.
Deﬁnition A.6 ((𝜅, 𝑞)-uniformly convex set). Given two positive numbers 𝜅and 𝑞, we say the set
X ⊆ℝ𝑛is (𝜅, 𝑞)-uniformly convex with respect to a norm ∥·∥if for any x, y ∈X, 0 ≤𝛾≤1, and z ∈ℝ𝑛
with ∥z∥= 1 we have that:
y + 𝛾(x −y) + 𝛾(1 −𝛾) · 𝜅∥x −y∥𝑞z ∈X.
The previous deﬁnition allows us to obtain a scaling inequality very similar to the one shown in
Theorem A.4, which is key to proving the following convergence rates, and can be implicitly found in
Kerdreux et al. [2021] and Garber & Hazan [2016].
Proposition A.7. Let X ⊆ℝ𝑛be (𝜅, 𝑞)-uniformly convex, then for all x ∈X:
𝑔(x)
∥x −v∥𝑞≥𝜅∥∇𝑓(x)∥,
where v = argminu∈X ⟨∇𝑓(x), u⟩, and 𝑔(x) is the Frank-Wolfe gap.
The next lemma that will be presented is an extension of the one used in Kerdreux et al. [2021,
Lemma A.1] (see also Temlyakov [2015]), and allows us to go from per iteration contractions to
convergence rates.
Lemma A.8. We denote a sequence of nonnegative numbers by {ℎ𝑡}𝑡. Let 𝑐0, 𝑐1, 𝑐2 and 𝛼be positive
numbers such that 𝑐1 < 1, ℎ1 ≤𝑐0 and ℎ𝑡−ℎ𝑡+1 ≥ℎ𝑡min{𝑐1, 𝑐2ℎ𝛼
𝑡} for 𝑡≥1, then:
ℎ𝑡≤
(
𝑐0 (1 −𝑐1)𝑡−1
if 1 ≤𝑡≤𝑡0
(𝑐1/𝑐2)1/𝛼
(1+𝑐1 𝛼(𝑡−𝑡0))1/𝛼= O  𝑡−1/𝛼
otherwise.
where
𝑡0
def= max

1,

log1−𝑐1
 (𝑐1/𝑐2)1/𝛼
𝑐0

.
19

This allows us to conveniently transform the per iteration contractions to convergence rates. Moving
on to the proof of the convergence rate.
Theorem A.9. Suppose X is a compact (𝜅, 𝑞)-strongly convex set and 𝑓is a (𝑀, 𝜈) generalized self-
concordant function with 𝜈≥2. Furthermore, assume that minx∈X ∥∇𝑓(x)∥≥𝐶. Then the Frank-Wolfe
algorithm with Backtrack (Algorithm 5) results in a convergence:
ℎ𝑡≤


ℎ(x0)

1 −1
2 min
n
1, 𝜅𝐶
˜𝐿
o𝑡
if 𝑞= 2
ℎ(x0)
2𝑡
if 𝑞> 2, 1 ≤𝑡≤𝑡0
( ˜𝐿𝑞/(𝜅𝐶)2)1/(𝑞−2)
(1+(𝑞−2) (𝑡−𝑡0)/(2𝑞))𝑞/(𝑞−2) = O  𝑡−𝑞/(𝑞−2)
if 𝑞> 2, 𝑡> 𝑡0,
for 𝑡≥1, where:
𝑡0 = max

1,

log1/2
 (˜𝐿𝑞/(𝜅𝐶)2)1/(𝑞−2)
ℎ(x0)

.
and ˜𝐿
def= max{𝜏𝐿L0
𝑓, 𝐿−1}, where 𝜏> 1 is the backtracking parameter, 𝐿−1 is the initial smoothness
estimate in Algorithm 6, and 𝐿L0
𝑓
=
max
u∈L0,d∈ℝ𝑛∥d∥2
∇2 𝑓(u) /∥d∥2
2.
Proof. At iteration 𝑡the backtracking line search strategy ﬁnds through successive function evaluations
a 𝐿𝑡> 0 such that:
ℎ(x𝑡+1) ≤ℎ(x𝑡) −𝛾𝑡𝑔(x𝑡) + 𝐿𝑡𝛾2
𝑡
2
∥x𝑡−v𝑡∥2 .
Finding the 𝛾𝑡that maximizes the right-hand side of the previous inequality leads to 𝛾𝑡= min{1, 𝑔(x𝑡)/(𝐿𝑡∥x𝑡−v𝑡∥2)},
which is the step size ultimately taken by the algorithm at iteration 𝑡. Note that if 𝛾𝑡= 1 this means
that 𝑔(x𝑡) ≥𝐿𝑡∥x𝑡−v𝑡∥2, which when plugged into the inequality above leads to ℎ(x𝑡+1) ≤ℎ(x𝑡)/2.
Conversely, for 𝛾𝑡< 1 we have that ℎ(x𝑡+1) ≤ℎ(x𝑡) −𝑔(x𝑡)2/(2𝐿𝑡∥x𝑡−v𝑡∥2). Focusing on this case
and using the bounds 𝑔(x𝑡) ≥ℎ(x𝑡) and 𝑔(x𝑡) ≥𝜅∥∇𝑓(x𝑡)∥∥x𝑡−v𝑡∥𝑞from Proposition A.7 leads to:
ℎ(x𝑡+1) ≤ℎ(x𝑡) −ℎ(x𝑡)2−2/𝑞(𝜅∥∇𝑓(x𝑡)∥)2/𝑞
2𝐿𝑡
(A.13)
≤ℎ(x𝑡) −ℎ(x𝑡)2−2/𝑞(𝜅𝐶)2/𝑞
2˜𝐿
,
(A.14)
where the last inequality simply comes from the bound on the gradient norm, and the fact that 𝐿𝑡≤˜𝐿,
for ˜𝐿
def= max{𝜏𝐿L0
𝑓, 𝐿−1}, where 𝜏> 1 is the backtracking parameter and 𝐿−1 is the initial smoothness
estimate in Algorithm 6. Reordering this expression and putting together the two cases we have that:
ℎ(x𝑡) −ℎ(x𝑡+1) ≥ℎ(x𝑡) min
(
1
2, (𝜅𝐶)2/𝑞
2˜𝐿
ℎ(x𝑡)1−2/𝑞
)
.
For the case where 𝑞= 2 we get a linear contraction in primal gap. Using Lemma A.8 to go from a
contraction to a convergence rate for 𝑞> 2 we have that:
ℎ𝑡≤


ℎ(x0)

1 −1
2 min
n
1, 𝜅𝐶
˜𝐿
o𝑡
if 𝑞= 2
ℎ(x0)
2𝑡
if 𝑞> 2, 1 ≤𝑡≤𝑡0
( ˜𝐿𝑞/(𝜅𝐶)2)1/(𝑞−2)
(1+(𝑞−2) (𝑡−𝑡0)/(2𝑞))𝑞/(𝑞−2) = O  𝑡−𝑞/(𝑞−2)
if 𝑞> 2, 𝑡> 𝑡0,
20

for 𝑡≥1, where:
𝑡0 = max

1,

log1/2
 (˜𝐿𝑞/(𝜅𝐶)2)1/(𝑞−2)
ℎ(x0)

,
which completes the proof.
□
Lastly, we deal with the general case in which the norm of the gradient is not bounded away from
zero in X.
Theorem A.10. Suppose X is a compact (𝜅, 𝑞)-strongly convex set and 𝑓is a (𝑀, 𝜈) generalized self-
concordant function with 𝜈≥2 for which domain does not contain straight lines. Then the Frank-Wolfe
algorithm with Backtrack (Algorithm 5) results in a convergence:
ℎ𝑡≤


ℎ(x0)
2𝑡
if 1 ≤𝑡≤𝑡0
( ˜𝐿𝑞/(𝜅2𝜇
L0
𝑓))1/(𝑞−1)
(1+(𝑞−1) (𝑡−𝑡0)/(2𝑞))𝑞/(𝑞−1) = O  𝑡−𝑞/(𝑞−1)
if 𝑡> 𝑡0,
for 𝑡≥1, where:
𝑡0 = max


1,

log1/2
©­
«
(˜𝐿𝑞/(𝜅2𝜇L0
𝑓))1/(𝑞−1)
ℎ(x0)
ª®
¬



.
and ˜𝐿
def= max{𝜏𝐿L0
𝑓, 𝐿−1}, where 𝜏> 1 is the backtracking parameter, 𝐿−1 is the initial smoothness esti-
mate in Algorithm 6, 𝜇L0
𝑓
= minu∈L0,d∈ℝ𝑛∥d∥2
∇2 𝑓(u) /∥d∥2
2 and 𝐿L0
𝑓
= maxu∈L0,d∈ℝ𝑛∥d∥2
∇2 𝑓(u) /∥d∥2
2.
Proof. Consider the compact set L0
def= {x ∈dom( 𝑓) ∩X | 𝑓(x) ≤𝑓(x0)}. As the algorithm makes
monotonous primal progress we have that x𝑡∈L0 for 𝑡≥0. The proof proceeds very similarly as
before, except for the fact that now we have to bound ∥∇𝑓(x𝑡)∥using 𝜇L0
𝑓-strong convexity for points
x𝑡, x𝑡+ 𝛾𝑡(v𝑡−x𝑡) ∈L0. Continuing from Equation (A.13) for the case where 𝛾𝑡< 1 and using the
fact that ℎ(x𝑡) ≤∥∇𝑓(x𝑡)∥2 /(2𝜇L0
𝑓) we have that:
ℎ(x𝑡+1) ≤ℎ(x𝑡) −ℎ(x𝑡)2−2/𝑞(𝜅∥∇𝑓(x𝑡)∥)2/𝑞
2𝐿𝑡
≤ℎ(x𝑡) −ℎ(x𝑡)2−1/𝑞𝜅2/𝑞(𝜇L0
𝑓)1/𝑞21/𝑞−1
˜𝐿
,
where we have also used the bound 𝐿𝑡≤˜𝐿in the last equation. This leads us to a contraction,
together with the case where 𝛾𝑡= 1, which is unchanged from the previous proofs, of the form:
ℎ(x𝑡) −ℎ(x𝑡+1) ≥ℎ(x𝑡) min


1
2,
𝜅2/𝑞(𝜇L0
𝑓)1/𝑞21/𝑞−1
˜𝐿
ℎ(x𝑡)1−1/𝑞

.
Using again Lemma A.8 to go from a contraction to a convergence rate for 𝑞> 2 we have that:
ℎ𝑡≤


ℎ(x0)
2𝑡
if 1 ≤𝑡≤𝑡0
( ˜𝐿𝑞/(𝜅2𝜇
L0
𝑓))1/(𝑞−1)
(1+(𝑞−1) (𝑡−𝑡0)/(2𝑞))𝑞/(𝑞−1) = O  𝑡−𝑞/(𝑞−1)
if 𝑡> 𝑡0,
for 𝑡≥1, where:
𝑡0 = max


1,

log1/2
©­
«
(˜𝐿𝑞/(𝜅2𝜇L0
𝑓))1/(𝑞−1)
ℎ(x0)
ª®
¬



,
which completes the proof.
□
21

Appendix B. Away-step Frank-Wolfe
When the domain X is a polytope, one can obtain linear convergence in primal gap for a generalized-
self concordant function using the well known Away-step Frank-Wolfe (AFW) algorithm [Guélat &
Marcotte, 1986, Lacoste-Julien & Jaggi, 2015] with the adaptive step size of Pedregosa et al. [2020],
shown in Algorithm 7. We use S𝑡to denote the active set at iteration 𝑡, that is, the set of vertices of
the polytope that gives rise to x𝑡as a convex combination with positive weights. We can see that the
algorithm either chooses to perform what is know as a Frank-Wolfe step in Line 6 of Algorithm 7 if
the Frank-Wolfe gap 𝑔(x) is greater than the away gap ⟨∇𝑓(x𝑡), a𝑡−x𝑡⟩or an Away-step in Line 8 of
Algorithm 7 otherwise.
Algorithm 7 Away-step Frank-Wolfe with the step size of Pedregosa et al. [2020]
Input: Point x0 ∈X ∩dom( 𝑓), function 𝑓, initial smoothness estimate 𝐿−1
Output: Iterates x1, . . . ∈X
1: S0 ←{x0}, λ0 ←{1}
2: for 𝑡= 0 to . . . do
3:
v𝑡←argminv∈X ⟨∇𝑓(x𝑡) , v⟩
4:
a𝑡←argmaxv∈S𝑡⟨∇𝑓(x𝑡) , v⟩
5:
if ⟨∇𝑓(x𝑡), x𝑡−v𝑡⟩≥⟨∇𝑓(x𝑡), a𝑡−x𝑡⟩then
6:
d𝑡←v𝑡−x𝑡, 𝛾max ←1
7:
else
8:
d𝑡←x𝑡−a𝑡, 𝛾max ←λ𝑡(a𝑡)/(1 −λ𝑡(a𝑡))
9:
𝛾𝑡, 𝐿𝑡←Backtrack( 𝑓, x𝑡, d𝑡, ∇𝑓(x𝑡), 𝐿𝑡−1, 𝛾max)
10:
x𝑡+1 ←x𝑡+ 𝛾𝑡d𝑡
11:
Update S𝑡and λ𝑡to S𝑡+1 and λ𝑡+1
The proof of linear convergence follows closely from Pedregosa et al. [2020] and Lacoste-Julien &
Jaggi [2015], with the only difference that we need to take into consideration that the function is
generalized self-concordant as opposed to smooth and strongly convex. One of the key inequalities
used in the proof is a scaling inequality from Lacoste-Julien & Jaggi [2015] very similar to the one
shown in Proposition A.4 and Proposition A.7, which we state next:
Proposition B.1. Let X ⊆ℝ𝑛be a polytope, and denote by S the set of vertices of the polytope X that
gives rise to x ∈X as a convex combination with positive weights, then for all y ∈X:
⟨∇𝑓(x), a −v⟩≥𝛿⟨∇𝑓(x), x −y⟩
∥x −y∥
,
where v = argminu∈X ⟨∇𝑓(x), u⟩, a = argmaxu∈S ⟨∇𝑓(x), u⟩, and 𝛿> 0 is the pyramidal width of X.
Theorem B.2. Suppose X is a polytope and 𝑓is a (𝑀, 𝜈) generalized self-concordant function with 𝜈≥2
for which the domain does not contain straight lines. Then the Away-step Frank-Wolfe (AFW) algorithm
with Backtrack (Algorithm 7) results in a convergence:
ℎ(x𝑡) ≤ℎ(x0) ©­
«
1 −
𝜇L0
𝑓
4˜𝐿
 𝛿
𝐷
2ª®
¬
⌈(𝑡−1)/2⌉
,
where 𝛿is the pyramidal width of the polytope X, ˜𝐿
def= max{𝜏𝐿L0
𝑓, 𝐿−1}, 𝜏> 1 is the backtracking
parameter, 𝐿−1 is the initial smoothness estimate in Algorithm 6, 𝜇L0
𝑓
=
min
u∈L0,d∈ℝ𝑛∥d∥2
∇2 𝑓(u) /∥d∥2
2 and
𝐿L0
𝑓
=
max
u∈L0,d∈ℝ𝑛∥d∥2
∇2 𝑓(u) /∥d∥2
2.
22

Proof. Proceeding very similarly as in the proof of Theorem A.5, we have that as the backtracking
line search makes monotonous primal progress, we know that for 𝑡≥0 we will have that x𝑡∈L0.
As the function is 𝜇L0
𝑓-strongly convex over L0, we can use the appropriate inequalities from strong
convexity in the progress bounds. Using this aforementioned property, together with the scaling
inequality of Proposition B.1 results in:
𝑓(x𝑡) −𝑓(x∗) ≤⟨∇𝑓(x𝑡), x𝑡−x∗⟩
2𝜇L0
𝑓
∥x𝑡−x∗∥2
(B.1)
≤⟨∇𝑓(x𝑡), a𝑡−v𝑡⟩2
2𝜇L0
𝑓𝛿2
(B.2)
= (⟨∇𝑓(x𝑡), a𝑡−x𝑡⟩+ ⟨∇𝑓(x𝑡), x𝑡−v𝑡⟩)2
2𝜇L0
𝑓𝛿2
,
(B.3)
where the ﬁrst inequality comes from the 𝜇L0
𝑓-strong convexity over L0, and the second inequality
comes from applying Proposition B.1 with y = x∗. Note that if the Frank-Wolfe step is chosen
in Line 6, then −⟨∇𝑓(x𝑡), d𝑡⟩= ⟨∇𝑓(x𝑡), x𝑡−v𝑡⟩≥⟨∇𝑓(x𝑡), a𝑡−x𝑡⟩, otherwise, if an away step is
chosen in Line 8, then ⟨∇𝑓(x𝑡), x𝑡−v𝑡⟩< ⟨∇𝑓(x𝑡), a𝑡−x𝑡⟩= −⟨∇𝑓(x𝑡), d𝑡⟩, in any case, plugging
into Equation (B.3) we have that:
ℎ(x𝑡) = 𝑓(x𝑡) −𝑓(x∗) ≤2 ⟨∇𝑓(x𝑡), d𝑡⟩2
𝜇L0
𝑓𝛿2
.
(B.4)
Note that using a similar reasoning, as ⟨∇𝑓(x𝑡), x𝑡−v𝑡⟩= 𝑔(x𝑡), in both cases it holds that:
ℎ(x𝑡) ≤𝑔(x𝑡) ≤−⟨∇𝑓(x𝑡), d𝑡⟩.
(B.5)
As in the preceding proofs, the backtracking line search in Algorithm 6 will either output a point
𝛾𝑡= 𝛾max or 𝛾𝑡< 𝛾max. In any case, and regardless of if a Frank-Wolfe step (Line 6) or an away step
(Line 8) is chosen, Algorithm 6 will ﬁnd and output a smoothness estimate 𝐿𝑡and a step size 𝛾𝑡such
that:
ℎ(x𝑡+1) −ℎ(x𝑡) ≤𝐿𝑡𝛾2
𝑡
2
∥d𝑡∥2 + 𝛾𝑡⟨∇𝑓(x𝑡), d𝑡⟩.
(B.6)
As before, we will have two different cases. If 𝛾𝑡= 𝛾max we know by observing Line 5 of Algorithm 6
that −⟨∇𝑓(x𝑡), d𝑡⟩≥𝛾max𝐿𝑡∥d𝑡∥2, and so plugging into Equation (B.6) we arrive at ℎ(x𝑡+1) −ℎ(x𝑡) ≤
⟨∇𝑓(x𝑡), d𝑡⟩𝛾max/2. In the case where 𝛾𝑡< 𝛾max, we have that −⟨∇𝑓(x𝑡), d𝑡⟩< 𝛾max𝐿𝑡∥d𝑡∥2 and
𝛾𝑡= −⟨∇𝑓(x𝑡), d𝑡⟩/(𝐿𝑡∥d𝑡∥2), and so plugging into Equation (B.6) we arrive at ℎ(x𝑡+1) −ℎ(x𝑡) ≤
−⟨∇𝑓(x𝑡), d𝑡⟩2 /(2𝐿𝑡∥d𝑡∥2). In any case, we can rewrite Equation (B.6) as:
ℎ(x𝑡) −ℎ(x𝑡+1) ≥min
(
−⟨∇𝑓(x𝑡), d𝑡⟩𝛾max
2
, ⟨∇𝑓(x𝑡), d𝑡⟩2
2𝐿𝑡∥d𝑡∥2
)
.
(B.7)
We can now use the inequality in Equation (B.4) to bound the second term in the minimization
component of Equation (B.7), and Equation (B.5) to bound the ﬁrst term. This leads to:
ℎ(x𝑡) −ℎ(x𝑡+1) ≥ℎ(x𝑡) min


𝛾max
2
,
𝜇L0
𝑓𝛿2
4𝐿𝑡∥d𝑡∥2


(B.8)
≥ℎ(x𝑡) min


𝛾max
2
,
𝜇L0
𝑓𝛿2
4˜𝐿𝐷2


.
(B.9)
23

where in the last inequality we have used ∥𝑑𝑡∥≤𝐷and 𝐿𝑡≤˜𝐿for all 𝑡. It remains to bound 𝛾max
away from zero to obtain the linear convergence bound. For Frank-Wolfe steps we immediately have
𝛾max = 1, but for away steps there is no straightforward way of bounding 𝛾max away from zero. One
of the key insights from Lacoste-Julien & Jaggi [2015] is that instead of bounding 𝛾max away from
zero for all steps up to iteration 𝑡, we can instead bound the number of away steps with a step size
𝛾𝑡= 𝛾max up to iteration 𝑡, which are steps that reduce the cardinality of the active set S𝑡and satisfy
ℎ(x𝑡) ≤ℎ(x𝑡+1). This leads us to consider only the progress provided by the remaining steps, which
are away steps with 𝛾𝑡< 𝛾max, and Frank-Wolfe steps. For a number of steps 𝑡, only at most half of
these steps could have been away steps with 𝛾𝑡= 𝛾max, as we cannot drop more vertices from the
active set than the number of vertices we could have potentially picked up with Frank-Wolfe steps.
For the remaining ⌈(𝑡−1)/2⌉steps we know that ℎ(x𝑡) −ℎ(x𝑡+1) ≥ℎ(x𝑡)𝜇L0
𝑓𝛿2/(4˜𝐿𝐷2). Therefore
we have that the primal gap satisﬁes:
ℎ(x𝑡) ≤ℎ(x0) ©­
«
1 −
𝜇L0
𝑓𝛿2
4˜𝐿𝐷2
ª®
¬
⌈(𝑡−1)/2⌉
.
This completes the proof.
□
We can make use of the proof of convergence in primal gap to prove linear convergence in Frank-Wolfe
gap. In order to do so, we recall a quantity formally deﬁned in Kerdreux et al. [2019] but already
implicitly used earlier in Lacoste-Julien & Jaggi [2015] as:
𝑤(x𝑡, S𝑡)
def=
max
u∈S𝑡,v∈X ⟨∇𝑓(x𝑡), u −v⟩
= max
u∈S𝑡
⟨∇𝑓(x𝑡), u −x𝑡⟩+ max
v∈X ⟨∇𝑓(x𝑡), x𝑡−v⟩
= max
u∈S𝑡
⟨∇𝑓(x𝑡), u −x𝑡⟩+ 𝑔(x𝑡).
Note that as the ﬁrst term, the so-called away gap in the previous equation is positive and hence
𝑤(x𝑡, S𝑡) provides an upper bound on the Frank-Wolfe gap.
Theorem B.3. Suppose X is a polytope and 𝑓is a (𝑀, 𝜈) generalized self-concordant function with
𝜈≥2 for which the domain does not contain straight lines. Then the Away-step Frank-Wolfe (AFW)
algorithm with Backtrack (Algorithm 7) contracts the Frank-Wolfe gap linearly, i.e., min1≤𝑡≤𝑇𝑔(x𝑡) ≤𝜀
after 𝑇= O(log 1/𝜀) iterations.
Proof. Note that the condition in Line 5 of Algorithm 7 means that regardless of if we chose to
perform an away step of a Frank-Wolfe step, we have that −2 ⟨∇𝑓(x𝑡), d𝑡⟩≥⟨∇𝑓(x𝑡), x𝑡−v𝑡⟩+
⟨∇𝑓(x𝑡), a𝑡−x𝑡⟩= 𝑤(x𝑡, S𝑡). On the other hand, we also have that ℎ(x𝑡) −ℎ(x𝑡+1) ≤ℎ(x𝑡). Plugging
these bounds into the right-hand side and the left hand side of Equation B.7 in Theorem B.2, and
using the fact that ∥d𝑡∥≤𝐷we have that:
min
 𝑤(x𝑡, S𝑡)𝛾max
4
, 𝑤(x𝑡, S𝑡)2
8𝐿𝑡𝐷2

≤ℎ(x𝑡) ≤ℎ(x0) ©­
«
1 −
𝜇L0
𝑓
4˜𝐿
 𝛿
𝐷
2ª®
¬
⌈(𝑡−1)/2⌉
,
where the second inequality follows from the convergence bound on the primal gap from Theorem B.2.
Considering the steps that are not away steps with 𝛾𝑡= 𝛾max as in the proof of Theorem B.2, leads us
to:
𝑔(x𝑡) ≤𝑤(x𝑡, S𝑡) ≤4ℎ(x0) max


1,
√︄
˜𝐿𝐷2
2ℎ(x0)


©­
«
1 −
𝜇L0
𝑓
4˜𝐿
 𝛿
𝐷
2ª®
¬
⌊(𝑡−1)/4⌋
.
□
24

Appendix C. Remarks and supplementary information on the experimental
section
We ran all experiments on a server with 8 Intel Xeon 3.50GHz CPUs and 31GB RAM. All computations
are run in single-threaded mode using Julia 1.6.0 with the FrankWolfe.jl package. We provide the
full details of the experiments carried out in the paper:
Portfolio optimization.
We consider 𝑓(x) = −Í𝑝
𝑡=1 log(⟨r𝑡, x⟩), where 𝑝denotes the number of
periods and X = Δ𝑛. The results are shown in Figure 2. We use the revenue data r𝑡from Dvurechensky
et al. [2020b] and add instances generated in a similar fashion from independent Normal random
entries with 1000, 2000, and 5000 dimensions, and from a Log-normal distribution with (𝜇= 0.0, 𝜎=
0.5).
Signal recovery with KL divergence.
We apply the aforementioned algorithms to the recovery
of a sparse signal from a noisy linear image using the Kullback-Leibler divergence. Given a linear
map 𝑊, we assume a signal y is generated by y = 𝑊x0 + 𝜀, where x0 is assumed to be a sparse
unknown input signal and 𝜀is a random error. Assuming 𝑊and y are entrywise positive, and that the
signal to recover should also be entrywise positive, the minimizer of the KL divergence (or Kullback’s
I-divergence [Csiszar et al., 1991]) can be used as an estimator for x0. The KL divergence between the
resulting output signals is expressed as 𝑓(x) = 𝐷(𝑊x, y) = Í𝑁
𝑖=1
n
⟨w𝑖, x⟩log

⟨w𝑖,x⟩
𝑦𝑖

−⟨w𝑖, x⟩+ 𝑦𝑖
o
,
where w𝑖is the 𝑖th row of 𝑊. In order to promote sparsity and enforce nonnegativity of the solution,
we use the unit simplex of radius 𝑅as the feasible set X = {x ∈ℝ𝑑
+, ∥x∥1 ≤𝑅}. The results are
shown in Figure 3. We used the same 𝑀= 1 choice for the second-order method as in Dvurechensky
et al. [2020b] for comparison; whether this choice is admissible is unknown (see Remark C.1). We
generate input signals x0 with 30% non-zeros elements following an exponential distribution of mean
𝜆= 1. The entries of 𝑊are generated from a folded Normal distribution built from absolute values of
Gaussian random numbers with standard deviation 5 and mean 0. The additive noise is generated
from a Gaussian centered distribution with a standard deviation equal to a fraction of the standard
deviation of 𝑊x0.
Logistic regression.
One of the motivating examples for the development of a theory of generalized
self-concordant function is the logistic regression problem, as it does not match the deﬁnition of a
standard self-concordant function but shares many of its characteristics. We consider a design matrix
with rows a𝑖∈ℝ𝑛with 1 ≤𝑖≤𝑁and a vector y ∈{−1, 1}𝑁and formulate a logistic regression
problem with elastic net regularization, in a similar fashion as is done in Liu et al. [2020], with
𝑓(x) = 1/𝑁Í𝑁
𝑖=1 log(1 + exp(−𝑦𝑖⟨x, a𝑖⟩)) + 𝜇/2 ∥x∥2, and X is the ℓ1 ball of radius 𝜌, where 𝜇and 𝜌
are two regularization parameters. The logistic regression loss is generalized self-concordant with
𝜈= 2. The results can be seen in Figure 4 and expanded in Appendix C. We use the a1a-a9a datasets
from the LIBSVM classiﬁcation data.
Birkhoff polytope.
All applications previously considered all have in common a constraint set
possessing computationally inexpensive LMOs (probability or unit simplex and ℓ1 norm ball). Addi-
tionally, each vertex returned from the LMO is highly sparse with at most one non-zero element. To
complement the results we consider a problem over the Birkhoff polytope, the polytope of doubly
stochastic matrices, where the LMO is implemented through the Hungarian algorithm, and is not
as inexpensive as in the other examples considered. We use a quadratic regularization parameter
𝜇= 100/√𝑛where 𝑛is the number of samples.
Remark C.1. Note that Proposition 2 in Sun & Tran-Dinh [2019], which deals with the composition of
generalized self-concordant functions with afﬁne maps, does not apply to the KL divergence objective
25

function, reproduced here for reference:
𝑓(x) = 𝐷(𝑊x, y) =
𝑁
∑︁
𝑖=1

⟨w𝑖, x⟩log
 ⟨w𝑖, x⟩
𝑦𝑖

−⟨w𝑖, x⟩+ 𝑦𝑖

.
Furthermore, the objective function is strongly convex if and only if rank(𝑊) ≥𝑛, where 𝑛is the
dimension of the problem.
Proof. [Sun & Tran-Dinh, 2019, Proposition 2] establishes certain conditions under which the
composition of a generalized self-concordant function with an afﬁne map results in a generalized
self-concordant function. The objective is of the form:
𝑁
∑︁
𝑖=1
𝜙𝑖(⟨w𝑖, x⟩)
with
𝜙𝑖(𝑡) = 𝑡log
 𝑡
𝑦𝑖

−𝑡+ 𝑦𝑖= 𝑡log 𝑡−𝑡log 𝑦𝑖−𝑡+ 𝑦𝑖.
Note that generalized self-concordant functions are closed under addition, and so we only focus on
the individual terms in the sum. As ﬁrst-order terms are (0, 𝜈)-generalized self-concordant for any
𝜈> 0, then we know that the composition of these ﬁrst-order terms with an afﬁne map results in a
generalized self-concordant function Sun & Tran-Dinh [2019, Proposition 2]. We therefore focus on
the entropy function 𝑡log 𝑡which is (1, 4) generalized self-concordant. The conditions which ensure
that the composition of a (𝑀, 𝜈)-generalized self-concordant function with an afﬁne map 𝑥↦→𝐴𝑥
results in a generalized self-concordant function requires in the case 𝜈> 3 that 𝜆𝑚𝑖𝑛(𝐴𝑇𝐴) > 0 [Sun &
Tran-Dinh, 2019, Proposition 2]. In the case of the KL divergence objective, 𝐴= w𝑇
𝑖and 𝐴𝑇𝐴= w𝑖w𝑇
𝑖
is an outer product with only one positive eigenvalue, and 0 of multiplicity 𝑛−1. Therefore we cannot
guarantee that the function 𝜙𝑖(⟨w𝑖, x⟩) is generalized self-concordant by application of Proposition 2
in Sun & Tran-Dinh [2019].
Alternatively, in order to try to show that the function is generalized self-concordant we could consider
𝑓(x) := 𝑔(𝑊x). Assuming rank(𝑊) ≥𝑛, then 𝑊𝑇𝑊is positive deﬁnite, and only the generalized
self-concordance of 𝑔is left to prove.
𝑔(z) =
𝑁
∑︁
𝑖=1
𝜙𝑖(z𝑖).
Each term z ↦→𝜙𝑖(z𝑖) = 𝜙𝑖(e𝑇
𝑖z) with e𝑖the 𝑖th standard basis vector is the composition of a
generalized self-concordant function composed with a rank-one afﬁne transformation, this raises the
same issues encountered in the paragraph above.
Regarding the strong-convexity of the objective function, we can express the gradient and the Hessian
of the function as:
∇𝑓(x) =
𝑁
∑︁
𝑖=1
w𝑖(log ⟨w𝑖, x⟩−log 𝑦𝑖)
∇2 𝑓(x) =
𝑁
∑︁
𝑖=1
w𝑖w𝑇
𝑖
⟨w𝑖, x⟩,
which is the sum of 𝑁outer products, each corresponding to a single eigenvector w𝑖. If rank(𝑊) ≥𝑛,
the Hessian is deﬁnite positive and the objective is strongly convex. Otherwise, it possesses zero as
an eigenvalue regardless of x, and the function Hessian is positive semi-deﬁnite.
□
26

Strong convexity parameter for the LLOO.
The LLOO procedure explicitly requires a strong
convexity parameter 𝜎𝑓of the objective function, an underestimator of 𝜆𝑚𝑖𝑛(∇2 𝑓(x)) over X. For the
portfolio optimization problem, the Hessian is a sum of rank-one terms:
∇2 𝑓(x) =
∑︁
𝑡
r𝑡r𝑇
𝑡
⟨r𝑡, x⟩.
The only non-zero eigenvalue associated with each 𝑡term is bounded below over X by:
∥r𝑡∥2
maxx∈X ⟨r𝑡, x⟩2 =
∥r𝑡∥2
max{maxx∈X ⟨r𝑡, x⟩, −minx∈X ⟨r𝑡, x⟩}2 .
The denominator can be solved by two calls to the LMO, and we will denote it by 𝛽𝑡for the 𝑡th term.
Each summation term contributes positively to one of the eigenvalues of the Hessian matrix, an
underestimator of the the strong convexity parameter is then given by:
𝜆𝑚𝑖𝑛
 ∑︁
𝑡
r𝑡r𝑇
𝑡
𝛽𝑡
!
.
The second-order method GSC-FW has been implemented with an in-place Hessian matrix updated
at each iteration, following the implementation of Dvurechensky et al. [2020b]. The Hessian
computation nonetheless adds signiﬁcant cost in the runtime of each iteration, even if the local
norm and other quadratic expressions

∇2 𝑓(x)y, z
 can be computed allocation-free. A potential
improvement for future work would be to represent Hessian matrices as functional linear operators
mapping any y to ∇2 𝑓(x)y.
Monotonous step size: the numerical case.
The computational experiments highlighted that the
Monotonous Frank-Wolfe performs well in terms of iteration count and time against other Frank-Wolfe
and Away-step Frank-Wolfe variants. Another advantage of a simple step size computation procedure
is its numerical stability. On some instances, an ill-conditioned gradient can lead to a plateau of the
primal and/or dual progress. Even worse, some step-size strategies do not guarantee monotonicity
and can result in the primal value increasing over some iterations. The numerical issue that causes
this phenomenon is illustrated by running the methods of the FrankWolfe.jl package over the same
instance using 64-bits ﬂoating-point numbers and Julia BigFloat types (which support arithmetic in
arbitrary precision to remove numerical issues).
100
101
102
103
Iteration
10−11
10−7
10−3
101
ℎ(x푡)
10−2
100
Time [s]
100
101
102
103
Iteration
10−5
10−3
10−1
101
푔(x푡)
10−2
100
Time [s]
M-FW
FW
B-FW
B-AFW
Figure 6: Ill-conditioned portfolio optimization problem solved using ﬂoating-point arithmetic.
On Figure 6, we observe a plateau of the dual gap for both M-FW and B-AFW. The primal value however
worsens after the iteration where B-AFW reaches its dual gap plateau. In contrast, M-FW reaches a
plateau in both primal and dual gap at a certain iteration. Note that the primal value at the point
where the plateau is hit is already below √𝜀ﬂoat64, the square root of the machine precision. The same
instance and methods operating in arbitrary precision arithmetic are presented Figure 7. Instead
of reaching a plateau or deteriorating, B-AFW closes the dual gap tolerance and terminates before
27

100
101
102
103
Iteration
10−11
10−7
10−3
101
ℎ(x푡)
100
101
102
103
Time [s]
100
101
102
103
Iteration
10−6
10−4
10−2
100
푔(x푡)
100
101
102
103
Time [s]
M-FW
FW
B-FW
B-AFW
Figure 7: Ill-conditioned portfolio optimization problem solved using arbitrary precision.
other methods. Although this observation (made on several instances of the portfolio optimization
problem) only impacts ill-conditioned problems, it suggests M-FW may be a good candidate for a
numerically robust default implementation of Frank-Wolfe algorithms.
Function domain in the constraints
One of the arguments used to motivate the construction of FW
algorithms for standard and generalized self-concordant minimization in prior work is the difﬁculty
of handling objective functions with implicitly deﬁned domains. We make several observations that
highlight the relevance of this issue and justify the assumption of the availability of a Domain Oracle
for dom( 𝑓). In the portfolio optimization example, all revenue vectors are assumed positive, r𝑡∈ℝ𝑛
++
and x ∈Δ𝑛, it follows that all feasible points lie in dom( 𝑓). More generally ,for the logarithm of an
afﬁne function, verifying that a candidate x lies in dom( 𝑓) consists of a single afﬁne transformation
and element-wise comparison 𝐴x + b > ℝ𝑚
++.
In the inverse covariance estimation problem, the information on dom( 𝑓) can be added to the
constraints by imposing mat(x) ∈𝕊𝑛
+, yielding a semi-deﬁnite optimization problem. The domain
oracle consists of the computation of the smallest eigenvalue, which needs to be positive.
We can also modify the feasible region of the signal retrieval application using the KL divergence,
resulting in a new feasible region X′ so that Int (X′) ⊂dom( 𝑓). The objective is of the form:
𝑓(𝜃) =
∑︁
𝑖
⟨w𝑖, 𝜃⟩log
 ⟨w𝑖, 𝜃⟩
𝑦𝑖

−⟨w𝑖, 𝜃⟩
where the data 𝑊and 𝑦are assumed to be entrywise positive, thus dom( 𝑓) = {𝑥∈ℝ𝑛
+, 𝑥≠0}.
Therefore we can deﬁne the set X′ as the unit simplex. The domain of each function involved in the
sum in 𝑓has an open domain (0, +∞).
However, the positivity assumption on all these components could be relaxed. Without the positivity
assumption on 𝑊, the Domain Oracle would consist of verifying:
⟨w𝑖, 𝜃⟩> 0 ∀𝑖.
(C.1)
This veriﬁcation can however be simpliﬁed by a preprocessing step if the number of data points is
large by ﬁnding the minimal set of supporting hyperplanes in the polyhedral cone (C.1), which we
can ﬁnd by solving the following linear problem:
max
𝜏,𝜃𝜏
(C.2a)
s.t. 𝜏≤⟨w𝑖, 𝜃⟩∀𝑖(𝜆𝑖)
(C.2b)
∥𝜃∥1 ≤𝑅,
(C.2c)
where 𝜆𝑖is the dual variable associated with the 𝑖th inner product constraint. If the optimal solution
of Problem (C.2a) is 0, the original problem is infeasible and the cone deﬁned by (C.1) is empty.
Otherwise the optimal 𝜃will lie in the intersection of the closure of the polyhedral cone and the
28

ℓ1 norm ball. Furthermore, the support of 𝜆provides us with the non-redundant inequalities of
the cone. Let ˆ𝑊be the matrix formed with the rows w𝑖such that 𝜆𝑖> 0, then the Domain Oracle
can be simpliﬁed to the veriﬁcation that ˆ𝑊𝜃∈ℝ𝑛
++. The Distance Weighted Discrimination (DWT)
model also considered in Dvurechensky et al. [2020b] was initially presented in Marron et al. [2007],
the denominator of each sum element 𝜉𝑖is initially constrained to be nonnegative, which makes
Int (X) ⊆dom( 𝑓) hold. Even without this additional constraint, the nonnegativity of all 𝜉𝑖can be
ensured with a minimum set of linear constraints in a fashion similar to the signal retrieval application,
thus simplifying the Domain Oracle.
29

100
101
102
103
Iteration
10−10
10−6
10−2
ℎ(x푡)
10−1
101
103
Time [s]
100
101
102
103
Iteration
10−5
10−3
10−1
101
푔(x푡)
10−1
101
103
Time [s]
M-FW
FW
B-FW
B-AFW
GSC-FW
LLOO
Figure 8: Portfolio Optimization: Convergence of ℎ(x𝑡) and 𝑔(x𝑡) vs. 𝑡and wall-clock time.
30

100
101
102
103
Iteration
10−11
10−7
10−3
101
ℎ(x푡)
10−2
100
Time [s]
100
101
102
103
Iteration
10−5
10−3
10−1
101
푔(x푡)
10−2
100
Time [s]
M-FW
FW
B-FW
B-AFW
Figure 9: Portfolio Optimization: Convergence of ℎ(x𝑡) and 𝑔(x𝑡) vs. 𝑡and wall-clock time.
31

100
101
102
103
Iteration
10−11
10−7
10−3
101
ℎ(x푡)
100
101
102
103
Time [s]
100
101
102
103
Iteration
10−6
10−4
10−2
100
푔(x푡)
100
101
102
103
Time [s]
M-FW
FW
B-FW
B-AFW
Figure 10: Portfolio Optimization: Convergence of ℎ(x𝑡) and 𝑔(x𝑡) vs. 𝑡and wall-clock time.
32

100
101
102
103
Iteration
10−3
100
103
ℎ(x푡)
10−1
101
103
Time [s]
100
101
102
103
Iteration
101
103
105
푔(x푡)
10−1
101
103
Time [s]
M-FW
FW
B-FW
B-AFW
GSC-FW
Figure 11: Signal Recovery: Convergence of ℎ(x𝑡) and 𝑔(x𝑡) vs. 𝑡and wall-clock time.
33

100
102
104
Iteration
10−11
10−8
10−5
10−2
ℎ(x푡)
10−1
101
103
Time [s]
100
102
104
Iteration
10−6
10−4
10−2
100
푔(x푡)
M-FW
FW
B-FW
B-AFW
GSC-FW
10−1
101
103
Time [s]
Figure 12: Logistic Regression: Convergence of ℎ(x𝑡) and 𝑔(x𝑡) vs. 𝑡and wall-clock time for the
a4a LIBSVM dataset.
34

100
102
104
Iteration
10−11
10−7
10−3
ℎ(x푡)
10−1
100
101
102
Time [s]
100
102
104
Iteration
10−6
10−4
10−2
100
푔(x푡)
10−1
100
101
102
Time [s]
FW
M-FW
B-FW
B-AFW
Figure 13: Logistic Regression: Convergence of ℎ(x𝑡) and 𝑔(x𝑡) vs. 𝑡and wall-clock time for the
a8a LIBSVM dataset.
35

100
102
104
Iteration
10−11
10−7
10−3
101
ℎ(x푡)
10−1
101
Time [s]
100
102
104
Iteration
10−6
10−4
10−2
100
푔(x푡)
10−1
101
Time [s]
M-FW
FW
B-FW
B-AFW
GSC-FW
Figure 14: Birkhoff Polytope: Convergence of ℎ(x𝑡) and 𝑔(x𝑡) vs. 𝑡and wall-clock time.
36

