Open Ended Intelligence
The individuation of Intelligent Agents
David Weinbaum (Weaver) (space9weaver@gmail.com)
Viktoras Veitas (vveitas@gmail.com)
The Global Brain Institute, VUB
May, 2015
Artiﬁcial General Intelligence (AGI) is a ﬁeld of research aiming to distill the principles
of intelligence that operate independently of a speciﬁc problem domain or a predeﬁned
context and utilize these principles in order to synthesize systems capable of performing
any intellectual task a human being is capable of and eventually go beyond that. While
“narrow” artiﬁcial intelligence that focuses on solving speciﬁc problems such as speech
recognition, text comprehension, visual pattern recognition, robotic motion, etc. has shown
quite a few impressive breakthroughs lately, understanding general intelligence remains
elusive.
In this paper we oﬀer a novel theoretical approach to understanding general intelligence.
We start with a brief introduction of the current conceptual approach. Our critique exposes
a number of serious limitations that are traced back to the ontological roots of the concept of
intelligence. We then propose a paradigm shift from intelligence perceived as a competence
of individual agents deﬁned in relation to an a priori given problem domain or a goal, to
intelligence perceived as a formative process of self-organization by which intelligent agents
are individuated. We call this process open-ended intelligence. This paradigmatic shift
signiﬁcantly extends the concept of intelligence beyond its current conventional deﬁnitions
and overcomes the diﬃculties exposed in the critique.
Open-ended intelligence is developed as an abstraction of the process of cognitive devel-
opment so its application can be extended to general agents and systems. We introduce and
discuss three facets of the idea: the philosophical concept of individuation, sense-making
– the bringing forth of a world of objects and relations, and the individuation of general
cognitive agents in the light of the enactive approach to cognition and assemblage theory.
We study these in order to establish in what sense formative individuating processes are
indeed intelligent and why they are open-ended.
We further show how open-ended intelligence can be framed in terms of a distributed,
self-organizing network of interacting elements (i.e. a complex adaptive system) and how
such a process is scalable. The framework highlights an important relation between coor-
dination and intelligence and a new understanding of values. We conclude with a number
of questions for future research.
Keywords: intelligence, cognition, individuation, assemblage, self-organization, sense-
making, coordination, enaction
1
arXiv:1505.06366v2  [cs.AI]  12 Jun 2015

1 Introduction – Intelligence and networks
We live in the age of networks: ecological networks, biological networks, digital networks,
logistic networks, knowledge networks, social networks and so on. It is an age of plurality,
of diversity and above all, of interconnectedness. The internet, the most prominent actual
exemplar of these concepts, is not only transforming the way we live and interact in the
everyday, but furthermore has engendered a powerful image in our minds – the image of
the network. This image has already a strong grasp over both the way we reason and our
imagination. In that, it sets the horizons of possible invention (Hui and Halpin, 2013).
Deploying networks as an explanatory platform for cognition and intelligent behavior
is an established practice in computational neuroscience (Edelman and Tononi, 2000;
Tononi, 2008), general cognitive science (Bechtel and Abrahamsen, 2002) and other
ﬁelds. The relations between the network concept and intelligence are many and strong.
Primary of which is the fact that brains, the most advanced intelligent machines we know
about as of today, are vast networks of interconnected neurons. The ﬁeld of “narrow”
artiﬁcial intelligence (AI) that focuses on goal-speciﬁc kinds of intelligence such as speech
recognition, text comprehension, visual pattern recognition, robotic motion, etc. has
known quite a few impressive breakthroughs lately. The highly competent AI agents
developed today rely heavily on vast networks of artiﬁcial neurons. Their construction
is inspired by biological brains and their competences begin to rival those of humans in
addressing speciﬁc problems.
The ﬁeld of Artiﬁcial General Intelligence (AGI) is much more ambitious in com-
parison. It aims to distill the principles of intelligence that operate independently of a
speciﬁc problem domain or a predeﬁned context and utilize these principles to synthesize
machines capable of performing any intellectual task a human being is capable of and
eventually go beyond that. There is no doubt that the network concept holds powerful
keys to understanding general intelligence and to the vision of building AGI agents. The
goal of this paper is to examine, from a philosophical perspective, the conceptual foun-
dations of intelligence and their emergence in the dynamics of distributed, disparate,
interconnected structures1.
The following section brieﬂy introduces the current conceptual approach to General
Intelligence and criticizes it. We expose a number of implicit hidden assumptions that
the deﬁnition of AGI is based upon. These assumptions place a priori conceptual limits
on how ‘general’ general intelligence can be. Section 3 is a philosophical exploration of
the ontological roots of intelligence and presents the theory of individuation, providing
an alternative concept of intelligence as a process and not as a given competence. This
novel approach overcomes the diﬃculties exposed in section 2 and signiﬁcantly extends
the concept beyond the deﬁnition in 2.1. As the title of the paper suggests, the term
open-ended intelligence will be used to describe intelligence as a process. In a nutshell,
intelligence is the process of bringing forth a world of objects and their relations, or in
other words, a continuous process of sense-making. Section 4 discusses how the process of
1The allusion to the internet has already captured the popular imagination. Many believe that one day
in the foreseeable future the internet, will ‘awaken’ and become a conscious aware super-intelligent
entity. Some even claim that this is already happening.
2

individuation is applied to cognition as an ongoing sense-making activity. An important
theoretical bridge is made between the concept of individuation and sense-making as an
actual process of cognitive development. It is in the cognitive development of systems that
open-ended intelligence is manifested. Here, by constructing a descriptive framework of
the individuation of cognition, we study the various facets and implications of applying
our approach and in what sense the formative individuating processes discussed are
considered intelligent. We conclude with a list of open questions and issues for further
research.
2 Conceptual problems with General Intelligence
2.1 Deﬁnition of General Intelligence
Intelligence is a diﬃcult concept to deﬁne, especially in its general, context-independent
sense. Many diﬀerent context-bound deﬁnitions do exist however in diverse disciplines
such as psychology, philosophy of mind, engineering, computer science, cognitive science
and more. It is far from simple, if at all possible, to reach a common-ground deﬁnition
that transcends the epistemological barriers between disciplines. Legg and Hutter (2007)
have compiled the most comprehensive collection to date of deﬁnitions of intelligence.
A shorter review of various representative examples of such deﬁnitions can be found in
(Legg, 2008). Based on this broad review and their attempt to found a formal theoretical
approach to general intelligence, Hutter and Legg have distilled the following deﬁnition:
Intelligence measures an agent’s ability to achieve goals in a wide range of
environments. (ibid., p. 6)
This deﬁnition tries to capture the broadest possible consideration of goals and oper-
ating environments. Goertzel (2012) uses a slightly diﬀerent version emphasizing the
pragmatic real-world “ability to achieve complex goals in complex environments”, some-
thing that is somewhat lost in Hutter’s AIXI all-encompassing design (Hutter, 2005).
Still, from a foundational point of view, these two versions are in agreement. It would
therefore be a good starting point to expose the problematic nature of such deﬁnition.
2.2 Criticism of the deﬁnition
Figure 1 depicts a scheme of the agent–environment model that is the basis for the
above deﬁnition. The story that goes with the scheme is that the agent, based on a ﬂow
of observations it receives from the environment, engages in a ﬂow of actions made to
achieve an optimized ﬂow of rewards. The intelligence of the agent is a measure of its
competence to match actions to observations such that it will achieve high rewards in
a variety of diverse environments. With this deﬁnition a few presumptions are already
clearly apparent:
The agent environment distinction – The ﬁrst strong assumption is that the agent is
clearly distinct from its environment. It has a well deﬁned contour across which
3

Environment
Observations
Rewards
Actions
Agent
Figure 1: Agent - Environment relations
it interacts with the environment. Additionally, the contour implicitly deﬁnes the
kinds of interaction that can take place between the agent and the environment.
The environment – The status of the environment is problematic in two aspects: ﬁrst,
due to the hidden assumption about the a priori givenness of the environment
and second, due to the assumption about its observer independent status.
In
Hutter’s AIXI model (Hutter, 2005), Solomonoﬀ-Levin universal prior distribu-
tion (Solomonoﬀ, 1964a; Solomonoﬀ, 1964b; Legg, 2008) is a minimal knowledge
predictor of the environment’s behavior in the most general case. It incorporates
both Epicurus’ principle and the principle of Occam’s razor (Legg, 2008, chap 2.)
and describes the agent’s best guess given its initial ignorance regarding the envi-
ronment. Using the universal prior as a basis, the agent can reliably induce the
future distribution of behaviors of the environment as more data on its behavior
becomes available. But the subject matter of universal induction is only the agent’s
knowledge of the environment. The universal prior and the method of Bayesian
induction assume an a priori given environment with an observer independent
status. Induction, therefore, only means the eﬀective reduction of the observer’s
ignorance regarding the environment. Moreover, the actions of the agent can only
aﬀect the environment within its already given deﬁnitional constraints. The agent
cannot change the environment – only discover its behavior and respond. Agent-
environment reﬂexivity, which is so apparent in actual systems, is either highly
ambiguous or entirely left out.
Goal driven reward – Clearly the environment does not ‘give’ rewards, as it is sometimes
implied by considering it as an agent, only that certain states of the environment
are more favorable than others relative to the agent’s goals and in the context
of its current internal state. For the deﬁnition of intelligence to be operative, it
must therefore involve yet another presumption, namely, that the agent possesses
a clearly deﬁned goal (or a set of goals) that maps values to both internal and
environment states. In its actions, the agent attempts to move the environment
4

from its current given state to the state that is most favorable in terms of rewards
given the dynamic context of its internal state.
The agent’s capacities – It is further implied that the agent is somehow structured by
past interactions with the environment (knowledge) and has a computing capacity
that aﬀords the matching of actions to observations and the evaluation of rewards
relative to its goals in the context of its state. This is of course a robust common
sense assumption but as argued about the environment, presuming an agent en-
dowed with a priori given general capacities, leaves a lot out of the equation. After
all, intelligent agents do not spontaneously appear ready-made in some purely con-
ceptual space. Some evolutionary process is necessarily involved and must not be
overlooked.
All the presumptions listed here appeal strongly to common sense and frame the concept
of intelligence in a reasonable and pragmatic manner.
However, they also limit the
generality of the concept in a few profound ways:
• Processes of diﬀerentiation and boundary formation that determine the agent–
environment distinctions are excluded. Such processes that can be broadly cate-
gorized as processes of self-organization can be gradual and possibly express intel-
ligence of a kind that is not considered by the deﬁnition in 2.1.
• Processes that are not clearly deﬁned a priori in terms of their goals and derived
values are excluded. Deﬁning a goal to be achieved is actually deﬁning a problem
to be solved. An intelligence that is constrained by an already given goal or a set
of well deﬁned goals can hardly represent the ultimate generality of intelligence.
In order to overcome this inherent partiality imposed by deﬁned goals, suppose we
could come up with a concept of a ‘universal goal’ not dissimilar from the universal
prior that generalizes the environment. Clearly, this will result in an absurdity since
every actual sequence of actions the agent might come up with in order to achieve a
subset of this universal goal, will be detrimental to another complementary subset.
Deﬁning a goal is a symmetry-breaking event that creates for the agent a unique
perspective regarding its relations with the environment. Only on the basis of such a
perspective can the agent possibly operate intelligently. But again, similar to the
formation of agent–environment distinctions, the determination of a perspective
that brings forth clear goals does not necessarily happen all at once. It might well
take place in a gradual and unique process of determination which involves a kind
of intelligence that the above deﬁnition is entirely overlooking.
The intelligent
agent characterized in ﬁgure 1 is indeed a problem solver; still, it is argued that
general intelligence never starts with solving a problem but much earlier – in the
formation or identiﬁcation of the problems to be solved.
• There is an unwarranted implicit asymmetry between the agent and the envi-
ronment. While the agent is profoundly changeable by the environment i.e. it
accumulates knowledge through learning and adaptation, the environment is only
5

changeable within the limits of its givenness ( i.e. the actual yet unknown distribu-
tion of events it brings forth in the course of interacting). Such conceptualization
excludes environments that are populated by other intelligent agents. The reason
is that such intelligent agent(s), being part of the environment, may have a distri-
bution of responses that cannot be determined or inferred in advance, at least not
without some prior knowledge of their goals. In short, the deﬁnition in 2.1 does
not consider cases of reﬂexivity where, for example, two (or more) agents interact
without any a priori knowledge of each others’ goals and where such goals and their
consequent behaviors emerge and consolidate in the course of interaction. If we
consider that an agent’s goals are set by an ongoing uniquely evolving perspective,
it might be worthwhile considering an environment of co-evolving quasi-determined
agents where the manifested intelligence profoundly departs from the presumptions
made by the above deﬁnition2.
In the light of these points of critique, it is clear that the currently accepted deﬁnition of
general intelligence covers only a well characterized kind of intelligence but neglects the
more profound and less easy to deﬁne process of the emergence of intelligence, or what
we call open-ended intelligence. The diﬃculty lies of course in the a priori assumptions
one is willing to give up. The less assumptions one commits to, the more diﬃcult it is
to make the concept concrete and formal. Wittgenstein famously said that whereof one
cannot speak (clearly), thereof one must be silent. But then how can we explain babies
learning to talk whereof initially nothing they say can be said to be clear? But still they
do! Similarly, what is intelligence prior to anything intelligible?
3 The ontological roots of intelligence
To try to answer this question, we need to reexamine a few deeply rooted axioms and
explore the less charted conceptual grounds of how intelligence arises in the ontological
sense. In other words, an attempt is made to reduce to the minimum the number of
assumptions that constrain the concept. This is how we arrive at the concept of open-
ended intelligence. As we will shortly show, it is a non-conventional concept; one that
can never be spoken of clearly, but is not condemned to silence. The ﬂuid and generative
character of open-ended intelligence precedes and complements to the well established
concept of intelligence that we criticize. Without such a complementary approach, it
seems that a truly General AI is bound to remain beyond the reach of understanding.
3.1 The ontological “chicken and egg” problem
Much of how one thinks about anything including intelligence is already encoded in one
or more of the major philosophical theories that shape human thought. These thought
systems usually make explicit some set of ontological axioms of what is given prior to
any thought or idea, and from there they proceed to derive all that can be thought or
made sense of. Let us see how it works in the case of the deﬁnition of intelligence. The
2This is possibly what Goertzel means in his emphasis on complex environments in the deﬁnition.
6

deﬁnition begins with a realist empiricist view that can be summarized in two seemingly
simple assumptions:
Realism – Posits that the whole of existence has an observer independent status. In our
case it means that the environment exists independently of the agent interacting
with it.
Its structure and dynamics might be unknown to the agent but they
nevertheless exist. Also, the agent’s actions aﬀect the environment only within the
constraints of its independent givenness.
Empiricism – Following Hume, posits that all sense-making and consequently all knowl-
edge and intelligent behavior must derive from sense experience. In our case it
means that for intelligence to manifest, it is necessary for the agent to inter-
act/observe with its environment because only via interactions/observations can
it learn what is necessary to achieve its goals 3.
But already here there is a diﬃculty reminiscent of the chicken and egg problem: what
comes ﬁrst, experience or the subject of experience? In Deleuze’s discussion of the human
image of thought (Deleuze, 1994, pp. 129-168), the subject of sense experience, in our
case the agent, cannot be an a priori given as it is implied by the empiricist position.
It must be somehow constituted in the course of sense-making. But this seems to be
impossible because if we give up a subject a priori to experience itself, who or what is
there to experience in the ﬁrst place? This is indeed the major point of Kant’s critique
of Hume’s empiricism. The Kantian position necessitates a transcendental subject in
possession of transcendental categories (such as space and time) antecedent to what is
given in experience in order to make sense of experience. But Kant’s approach is not
without its own diﬃculties. It must assume that certain mental categories precede any
actual thought and any manifestation of intelligence. It is like saying that some form
of primal intelligence must be inherent in the agent prior to any interaction. But what
would possibly be the origin of such primal intelligence that transcends experience?
Clearly, the idea of general intelligence expressed by the deﬁnition in 2.1 follows Kant in
assuming that the agent possesses certain capacities and goals prior to any observation or
action. Here we face a second diﬃculty: how general is our agent’s “general intelligence”
if it must be constrained by a priori categories that shape its observations and goals that
assign values to them? Our thinking about intelligence seems therefore to be constrained
by abstract patterns that shape conventional thinking itself. These patterns, collectively
termed by Deleuze ‘the image of thought’, draw implicit limits on intelligence itself.
How can we overcome this diﬃculty and reach a conception of an open-ended intel-
ligence? Following Deleuze (Deleuze, 1994; Weinbaum, 2014), we should neither try to
ﬁgure how the objects of experience produce subjects (Hume’s empiricism), nor how
the subjects of experience produce their objects (Kant’s transcendental categories). In-
stead, Deleuze proposes what he calls transcendental empiricism, a novel and seemingly
paradoxical construction that aﬃrms both Hume’s and Kant’s positions by redeﬁning
them. The position of transcendental empiricism starts with much fewer assumptions.
3observations can be entirely passive but interactions are necessary in order to observe the eﬀects of
the agent’s actions on the environment
7

It assumes neither subjects nor objects and instead of trying to ﬁgure how they might
produce each other, it examines how both subjects and objects can be produced out of
a ﬁeld that initially does not assume either. Without delving more than necessary into
the highly complex philosophical construction that is required here, we can start seeing
where it leads in our case: giving up the a priori givens in our thinking, namely, the
agent, the environment, the distinction between them, the implied observations and ac-
tions that are made possible by such a distinction and ﬁnally the goal and its associated
mapping of rewards. This might seem, at ﬁrst sight, as if nothing is left to build upon
and this clearly makes no sense. But here is exactly the point to stop and consider: if
there is no sense, how is one to make sense out of a non-sense situation where no agents
or objects can be identiﬁed to begin with? In other words, and here is the conceptual
leap that needs to be taken, while the deﬁnition we started with in 2.1 is answering the
question “what does it mean to be intelligent?”, here the focus is on a prior question:
“what does it mean to become intelligent?”. Becoming intelligent is precisely this pro-
cess of sense-making that precedes clear distinctions and goals and bring those forth.
In order to see how is it possible at all, a novel and non-conventional set of concepts is
required.
3.2 Individuals and individuation
One of the most profound characteristics of the conventional system of thought humans
use to make sense with is its focus on individuals. This focus has its roots in Greek
philosophy and particularly in the metaphysics of Aristotle, which describes a world
made of individual beings with an identity that is given as a set of stable properties and
qualities. Aristotle’s principle of the excluded middle ensures that an individual cannot
possess a certain property while simultaneously not possess it. Hence, the identity of
individuals, according to the Aristotelian theory, is unambiguously deﬁned.
Understanding the nature of individuals clariﬁes the general nature of deﬁnitions such
as the one we use to deﬁne intelligence: deﬁnitions are made to delineate individuals.
Most signiﬁcantly, the focus on individuals also conditions the way one accounts for
their genesis. To put it brieﬂy, if individuals are the primary ontological elements of
anything existing, the genesis of individuals is merely the manner by which one individual
transitions into another one.
Everything starts and ends with individuals while the
becoming of individuals – what happens in-between – is secondary at best (Weinbaum,
2014). In order to make intelligence deﬁnable, therefore, we must make assumptions
whose sole function is to comply with what the conventional system of thought dictates,
namely, positing already formed individuals on the basis of which we can safely continue
to develop further individual concepts and theories.
Attempting to understand intelligence prior to such assumptions, we need a shift
of perspective from individuals as the primary elements that occupy our investigation
to how they come into being in the ﬁrst place, in other words, to their individuation.
Individuation is the formation or becoming of individuals.
It is a primal formative
activity whereas boundaries and distinctions arise without assuming any individual(s)
that precede(s) them. The nature of distinctions and boundaries is subtle; inasmuch
8

as they separate subject from object, ﬁgure from background, and one individual from
another, they must also connect that which they separate. A boundary, therefore, is not
only known by the separation it establishes but also by the interactions and relations it
facilitates.
This shift of perspective constitutes an alternative system of thought.
Gilbert Si-
mondon, the father of the theory of individuation (Simondon, 2005) encourages us to
understand the individual from the perspective of the process of individuation. For him,
the individual is a metastable phase within a continuous process of transformation and
is always impregnated with not yet actualized and not yet known potentialities of being:
“Individuation must therefore be thought of as a partial and relative res-
olution manifested in a system that contains latent potentials and harbors a
certain incompatibility within itself, an incompatibility due at once to forces
in tension as well as to the impossibility of interaction between terms of
extremely disparate dimensions.” (Simondon, 1992).
According to Simondon, an individual is not anymore the rigid well deﬁned Aristotelian
element endowed with ultimately given properties, but rather a plastic entity, an on-
going becoming. The relatively stable state of individuals is punctuated by periods of
transformation whereas individuals may radically change or disintegrate. Every such
period reconﬁgures the inner tensions active within the individual and the manner by
which they will determine future stable phases and transformations.
3.3 The condition of individuation
Three descriptive terms stand out in Simondon’s development of the concept of individ-
uation: metastability, intensity and incompatibility. These are in fact overlapping facets
of the ﬁeld of individuation. Imagine for example a system of two (or more) human
agents in disagreement having an argument. As long as they both continue to engage
with each other and haven’t reached an agreement, the situation of their engagement is
metastable. There are unrealized potentials of change in their relations. One of them
may suddenly understand the other better and change her mind. Also the opposite can
happen: the diﬀerences between them can grow and reach a point of crisis. The system
may move both towards or away from stability in a manner which is not entirely pre-
dictable and depends on numerous factors. But as long as the argument continues, as
long as the system is metastable, there is a motion of change. Individuation in this sense
is reminiscent of the concept of self-organization in dynamic systems both in its reference
to metastability and in the emergence of structure in a process of relaxing a system of
tensions/potentials. But while self-organization commonly describes the convergence of
trajectories towards attractors within an already conﬁgured state-space, individuation
does not assume such an a priori conﬁguration. Simondon’s notion of metastability
is not conﬁned to describing trajectories of movement among local minima within an
already given landscape of potentials; metastability also involves possible transforma-
tions of the landscape itself (e.g. the number of the involved variables and the relations
between them).
9

Individuation takes place as long as the system has not reached a ﬁnal stability/relaxation
and exhausted all its potential for change. But in fact ﬁnal stability is merely an ideal-
ization because it requires a closed system that either does not interact with its environ-
ment, or is not distinct from its environment (i.e. in thermodynamic equilibrium with
its environment). Open systems like living organisms or whole ecosystems maintain a far
from equilibrium state (Prigogine and Stengers, 1984), and are in a motion of continuous
individuation never reaching permanent stability.
The motion of individuation is driven by what can be called intensive diﬀerences, or in
short, intensities. By intensity we mean here a general term for energetic diﬀerences that
drive structural and state changes in a system (see, Weinbaum (2014); DeLanda (2013,
chap 2)). In the example above, the driving intensities are the interlocutors’ desire to
each hold to her own convictions and persuade the other to change his. This desire is
a force that drives and animates the interaction. Intensities can either dissipate as the
system changes, or they can also become too strong for the system to contain and thus
bring about the disintegration of the system. Applied to our example, in both cases the
activity of arguing will tend to cease. If the interlocutors manage to agree on a certain
point, intensities are relaxed and their relations gain additional consensual structure
(understanding). But if, on the contrary, they discover that their diﬀerences are even
deeper than they initially thought, intensities increase and may ﬁnd their expression
in the manner the argument is conducted e.g. it becomes heated, or even escalates to
physical violence, which is not anymore an argument. Generally, intensities are corre-
lated to the measure of metastability and level of structural changes taking place in the
system. Low intensities are associated with relatively more stable dynamics while high
intensities are associated with volatile dynamics and swift structural changes.
Last but not least is the third term – incompatibility. Only situations of incompati-
bility bring forth intensities that drive processes of individuation. Incompatibility arises
from what we may call the problematic – the situation where interacting elements of a
system pose problems to each other that require resolution. The engagement of predator
and prey is an exemplar of a problematic situation of incompatibility. In the argument
example above, thinking diﬀerently about a situation that requires from the agents a
joint coordinated action is an example of a problematic situation. The diﬀerences in
perspective between the agents must be resolved at least to a degree that allows the
necessary joint action. Disparity is an extreme case of the problematic where the se-
mantics of the signs exchanged between agents/elements in a system is not established
or ambiguous. The agents lack a common ground of basic coordination/understanding
to even facilitate their engagement (e.g.
they do not speak the same language).
In
such cases, individuation must also mean the emergence of a coordinated exchange of
signals (is this strong hug a gesture of friendship or a covert threat?). It is important
to note that the individuation of systems in general always starts from a situation of
disparity. It takes place in the course of gradually establishing a coordinated exchange
of signals among gradually diﬀerentiating elements that together (distinct signals and
elements)bring forth a system. In other words, both elements and the relations among
them are simultaneously individuated. Furthermore, individuation never brings forth
an individual in a vacuum but rather an individual-milieu dyad. This dyad contains
10

both a system of distinctions and a system of relations. The individual and its milieu
reciprocally determine each other as they develop as a system greater than the individual
(Simondon, 2009).
3.4 Transduction – the mechanism of individuation
What happens in individuation? In the example of arguing persons, the involved agents
are continuously aﬀecting and being aﬀected by each other.
In the course of their
interactions some (but not necessarily all) of the disparities and problems are resolved
and result in a new consensual structure that they will support together in the future.
This is how the system is individuated and gains an identity of its own based on the
established coherency achieved between the agents. It is important to note that at any
instance the system constituted of the agents and their relations includes both consensual
positions that form its individuated aspect (because they can be identiﬁed and deﬁned
for the entire system), and elements of unresolved incompatibility that may drive future
engagements leading either to extended coherency or the destabilization of the already
established consensus. What may seem to an external observer as a stable and coherent
system, always harbors internal intensities and instabilities that threaten to radically
change it or even break it apart. These latter elements, termed preindividual, are intrinsic
to all individuals and are the inner intensities that drive future individuation.
The outcome of the interaction between two or more incompatible agents is hardly
predictable since it is not guided by a priori individuated overarching principles or
mechanisms. In other words, the outcomes of such interactions can neither be deduced
from an already individuated setup, nor can they be induced from a generalized model
based on previous similar instances because incompatibilities are inherently singular and
unrepeatable. The methods of deduction and induction therefore cannot be applied to
individuation (ibid., p 12). Prior to, and in the course of the actual interaction, the out-
come is said to be determinable but not yet determined. Determination necessitates the
actual localized and contextualized interaction where the participating elements recipro-
cally determine behavioral and structural aspects of each other. This kind of interactions
constitutes the mechanism by which individuation takes place as a sequence of progres-
sive determinations and is called in short transduction.
Transduction is an abstract
mechanism that may receive its speciﬁc actual description per context or operational
domain. It can be physical,biological, cognitive, social or other according to the agents
and interactions involved.
The most important aspect revealed in transduction is the progressive co-determination
of structure and behavior. Transduction can be seen as a chain of operations Oi on struc-
tures Sj: S1 →O1 →S2 →O2 →S3 →... (Combes and LaMarre, 2013, pp. 14-15).
Every operation is a conversion of one structure into another, while every structure me-
diates between one operation and another. Each structure in the chain constrains the
operations that can immediately follow. Each operation, in its turn, can transform the
previous structure into a limited number of new structures. Every intermediate structure
is a partial resolution of incompatibility but it is driven away from its relative stability as
long as the remaining unresolved tensions are not exhausted. Initially, the series of oper-
11

ations or structures can be quite random. As the transductive process progresses, certain
structures and operations may become more frequent than others or even repetitive. As
the sets of structures and operations become mutually bounded, even temporarily, an
individuated entity arises which may either further consolidate or eventually disintegrate
(this is further discussed in 4.3). A more concrete example of a transductive process is
the propagation of a computation in self-transforming programs: executed code and the
data are analogous to operation and structure. However, the program code itself is also
accessible as data that is progressively modiﬁed to produce (in principle) inexhaustible
variety and innovation. Code redeﬁnes the data and data further redeﬁnes the code in a
chain of operations. The analogy helps to understand how operation and structure are
reciprocally determining expressions of the transductive process.
3.5 Assemblages - from Individuation to Individuals
Understanding individuation, is understanding how individuals are constructed from
sets or populations of disparate and heterogeneous elements.
The monolithic stable
character of individuals is given up and instead we see metastable and often troublesome
constructions that can be deﬁned and identiﬁed but only as provisional stations in an
incessant process of transformation.
These constructions are called assemblages – a
concept developed by by Deleuze and Guattari (1987) and further extended by De Landa
(2006)4. Assemblages are networks of interacting heterogeneous individuals where each
individual is an assemblage too (for elaboration on the stratiﬁcation of assemblages see
4.2).
Assemblages carry with them an intrinsic though metastable individuality; an
individuality that does not depend on an external observer but only on the relations
that have been stabilized among their disparate elements.
When we observe a system of any kind, be it a physical object, an organism, a tech-
nological artifact or a social system, as observers we form with the object of observation
a new assemblage. Both observer and observed and the relations between them undergo
a transductive process of individuation where disparities are resolved and coherent rela-
tions are established. These come to constitute knowledge – an individuated knowledge.
The individuation of knowledge is the process already mentioned in subsection 3.1 where
both the subject and object of knowledge reciprocally determine each other without one
having a privileged ontological status over the other.
Replacing the individual with individuation as the primary ontological element exposes
a hierarchy of creative processes across many scales. When we examine an individual,
we need to identify which are the elements relevant to its individuation. For example,
to say that a living organism is made of atoms does not expose anything interesting
about the organism’s individuation. An individual organism individuates from a lump
of identical cells originating from a single cell in a developmental context (egg, womb,
or a cell membrane in case of unicellular organisms). An individual species individuates
in an evolutionary context (ecology). In the case of social animals, further individuation
4A short introduction to assemblage theory can be found in:
http://wikis.la.utexas.edu/theory/page/assemblage-theory.
12

takes place in a social context. Every such context can be given as a population of
heterogeneous and disparate elements from which individuals and their milieu co-emerge.
Individuals as assemblages comes to mean that the assembled elements can be said to
be characterized by a) identifying properties that deﬁne them as the individuals that they
are (and subject therefore to their own individuation) and b) capacities to interact – to
aﬀect and be aﬀected by other elements (De Landa, 2006, chap 1). While every element
has a more or less ﬁxed and independent set of properties, the set of its interactive
capacities is open and inexhaustible because it depends on the actual relations that
each element forms with other elements.
Since there is no limit to the number and
kind of relations, the set of capacities to interact is open-ended and non-deterministic.
What becomes determined in transduction are the actual capacities manifested in the
interactions of the various elements involved in the process.
This is why the actual
interaction is necessary for the determination and why the resulting relations cannot be
predicted a priori. Once disparate elements come into (partially) coordinated relations
they give rise to an assemblage – a new individual with more or less stable properties
and capacities5. Critical to the concept of assemblage is the semi-autonomous status
of their constituting elements and their contingent relations. Even in a radical example
such as an organism or even a living cell where the integration between the constituting
elements seems to be very tight, the relations between organs are not a result of a
logical necessity but rather contingently obligatory (ibid., p 12). This is why tissues can
spontaneously become cancerous and individual organs can be taken out and replaced
by artiﬁcial organs such as bionic limbs, artiﬁcial kidneys, hearts, joints, retinas etc. to
form cyborgian assemblages.
To summarize, transduction and assemblage are both aspects of individuation. While
transduction describes the dynamical aspect, assemblages frame the structural aspect.
Together they form a conceptual framework that allows the investigation of the indi-
viduation of intelligent agents free of the assumptions reviewed in subsection 2.2. An
interesting reﬂection arises from the distinction between properties and capacities: since
the conventional approach to general intelligence conceives it as a deﬁnable property of
an agent or a system, there is a certain inherent ﬁniteness in its very conception. In
contrast, the complementary approach to general intelligence proposed here conceives
general intelligence as a capacity. As such, it is open-ended and involves indeﬁnite and
a priori unknown factors depending on contingent interactions. In other words, a cre-
ative aspect that goes beyond goal-oriented, utility-optimizing activity, is intrinsic to the
open-ended intelligence that manifests itself in individuation.
4 Intelligence in the individuation of cognition
From the perspective developed here, it is interesting to regard every individual – the
product of individuation – as a solution to a problem whose formulation is not initially
given and can only be implied from the solution (i.e. the individual). As was already
5Capacities also mean capacities to be destroyed. Certain interactions can amplify the internal unsettled
intensities within an individual to the eﬀect of its disintegration.
13

mentioned, individuation is a resolution of a problematic situation by means of pro-
gressive determination. What is meant by “a problematic situation” is a state of aﬀairs
that is unstable, non-organized, whose elements lack deﬁnite boundaries and coordinated
interactions and therefore does not give itself to any systematic description.
In contrast to the deﬁnition given in 2.1, where the starting point is a well formed
problem to which a solution is being sought, in individuation the endpoint i.e.
the
individual, is a well formed solution to a ‘problem’ that is initially unformed and therefore
can only be implied ‘backwards’ from the solution. Following this line of thought, we
do not depart in any radical sense from the understanding of intelligence as a general
capacity of solving problems. Our thesis is that the formative processes that bring forth
individuals as ‘solutions’ to problems that are initially unformed, are manifesting an
open-ended kind of intelligence which is qualitatively diﬀerent and complementary to
the one deﬁned in 2.1.
Furthermore, the designator ‘general’ in general intelligence must relate to a process
where a problematic situation is initially unformed (i.e. determinable but not deter-
mined) but involves intensities that mobilize the bringing forth of individuals as ‘solu-
tions’. The most signiﬁcant example that comes to mind here is the process of natural
evolution. Every living organism manifests a set of behaviors that realize highly opti-
mized solutions to problems that become apparent only while observing the interactions
of the organism in its environment. Organisms therefore are undeniably intelligent. But
what about the evolutionary formative processes that give rise to the outstanding ‘so-
lutions’ that living organisms are? We argue that they are intelligent precisely in the
complementary sense we propose here and in this profound sense deserve, more than
anything else, the designation of General Intelligence.
To this point, the theory of individuation has a very broad scope as it relates to
individuals in general and not necessarily to what is conventionally considered intelligent
systems or intelligent agents. From a philosophical perspective, general systems whether
natural like galaxies, stars, rivers, chemical compounds, weather systems etc., or artiﬁcial
such as tools, machines, buildings, wars, mathematical computations etc. are individuals
in the course of individuation that possess an intrinsic and identiﬁable (though in most
cases limited) manifestation of intelligence. Our interest however is not in the limited
and already consolidated manifestations of intelligence but in those manifestations which
are, at least in principle, open-ended i.e. in the process of becoming intelligent. In the
following we develop the idea that the individuation of cognitive systems, where cognition
is understood in its broadest possible sense, is by deﬁnition a process manifesting open-
ended intelligence.
4.1 Cognition as sense-making
The phenomenon of cognition is deﬁnitely complex, multifaceted and gives itself to
quite a few diverse deﬁnitions.
Still, in a somewhat naive approach, the activity of
cognition is naturally associated with certain situations when there is an agent operating
in its environment, and whose operation can be described as an ongoing problem-solving
activity. In other words, the roots of cognition is always a problematic situation, an
14

incompatibility, full of tensions, that exists between the agent and its environment and
that needs resolution somehow. This also lends the impression that a cognitive agent
is always involved in some purposeful activity, that is, resolving an immediate (or a
forethought) problem. This is also the straight-forward manner by which cognition is
associated with intelligence.
Here, we turn full circle to the beginning of our inquiry: how is it that this setup
of agents, environments and their dynamic problematic relations emerge in the ﬁrst
place? Even while writing (or reading) these words, we make use of sensible objects
that are already, at least partially, formed. Perhaps they are vague and require further
determination to become clearer; some may change the meaning (sense) in which they are
understood; others may just emerge in the ﬂow of thought or disappear; and yet others
may merge or diverge. Crossing this, often unseen, boundary between the unknown and
the known, the unformed and the formed is what we may call sense-making. Sense-
making is the bringing forth of a world of distinctions, objects and entities and the
relations among them.
Even primary distinctions such as ‘objective – subjective’ or
‘physical – mental’ are part of sense-making.
A relatively new appearance on the stage of cognitive science, the so called enactive
cognition approach, regards sense-making as the primary activity of cognition. The term
‘enactive’, synonymous with ‘actively bringing forth’, makes its ﬁrst appearance in the
context of cognition in the book “The embodied Mind” (Varela, Thompson, and Rosch,
1992) and has been since then the subject of many developments and debates (Stew-
art, Gapenne, and Di Paolo, 2010; Thompson, 2007; Di Paolo, 2006; De Jaegher and
Di Paolo, 2007). The enactive theory of cognition incorporates the idea of individuation
rather naturally as it asserts cognition to be an ongoing formative process, sensible and
meaningful (value related), taking place in the co-determining interactions of agent and
environment (Di Paolo, Rohde, and De Jaegher, 2010). Still, being based on the earlier
works of Maturana and Varela on autopoiesis and the biological basis of cognition (Mat-
urana and Varela, 1987; Maturana and Varela, 1980), the theory asserts the necessity of
an autonomous and relatively stable identity to cognition:
A guiding idea of the enactive approach is that any adequate account
of how the body can either be or instantiate a cognitive system must take
account of this fact that the body is self-individuating. This point brings us
to the principal concept that diﬀerentiates enactivism from other embodied
approaches to the mind - the concept of autonomy. (Di Paolo and Thompson,
2014)
And in (Di Paolo, Rohde, and De Jaegher, 2010) the necessity is made speciﬁc to sense-
making:
[...] By saying that a system is self-constituted, we mean that its dynamics
generate and sustain an identity. An identity is generated whenever a pre-
carious network of dynamical processes becomes operationally closed. [...]
Already implied in the notion of interactive autonomy is the realization that
organisms cast a web of signiﬁcance on their world. [...] This establishes a
15

perspective on the world with its own normativity[.] [...] Exchanges with the
world are thus inherently signiﬁcant for the agent, and this is the deﬁnitional
property of a cognitive system: the creation and appreciation of meaning or
sense-making, in short. [...] [S]ense-making is, at its root, the evaluation of
the consequences of interaction for the conservation of an identity. (Di Paolo,
Rohde, and De Jaegher, 2010, pp. 38-39,45)
In contrast, we argue that the broader understanding of sense-making as the individ-
uation of cognition itself, precedes the existence of already individuated autonomous
identities and is actually a necessary condition to their becoming. Only that at this pre-
individuated stage there is still no one for whom sense is being made. It is only a habit of
thought to assume the preexistence of the sense-making-agent to the sensible (see 3.1).
Di Paolo et al. are nevertheless aware of the metastability involved in the processes that
constitute cognition by mentioning precarious networks of dynamic processes becoming
operationally closed, but they do miss the deeper meaning of becoming as a process and
therefore treat closure as an ideal point that delineates the existence of the individual in
time, and that only from such a point and on sense-making is made possible. This is an
important point because it frees intelligence from being conceptually subjugated to the
persistence of a preexisting identity. The sensible, we argue, precedes the individual and
facilitates its becoming but in itself is not necessarily biased towards the conservation
of any identity. In sense-making, both integration and disintegration play a signiﬁcant
role.
To summarize, the manifestation of open-ended intelligence in cognition is the bringing
forth of a complex world via the activity of sense-making. The concept of sense-making
captures two distinct meanings: the ﬁrst is synonymous with cognition as a concrete
capacity, the second, with the individuation of cognition as intrinsic to cognition itself.
The latter meaning of sense-making is the one corresponding to the acquisition and
expansion of concrete cognitive capacities (i.e. intelligence expansion) and it also gen-
eralizes the concept of cognitive development beyond its psychological context (Piaget,
2013).
4.2 A descriptive model of the individuation of cognition
To describe the process of individuation of cognition in more concrete terms, we consider
a heterogeneous and diverse population P of individual elements each with its deﬁning
properties and capacities to aﬀect and be aﬀected that depend on contingent interac-
tions with other elements of the population. By ‘heterogeneous’ we mean a population
of individuals with diﬀerent sets of properties whereas by ‘diverse’ we mean that there
is variability in the expressions of at least some of the properties. An obvious example
would be a population of organisms within an ecology: The population is heterogeneous
because there are many species and it is diverse because speciﬁc properties have variabil-
ity in expression within a specie and across species. The formation of new individuals
within heterogeneous and diverse populations of interacting elements is at the core of our
model. It highlights the distributed nature of individuation and the kind of intelligence
that is thus brought forth.
16

As already described in 3.5, individuals are actually individuated assemblages. For
reasons that will become clear shortly, we assign the population we start with to a
stratum P. Stratum P implies two additional populations (i.e. strata) with which it
holds hierarchical relations:
1. Lower in the hierarchy is the population of all the individuals that participate as
components in assemblages that constitute the individuals in stratum P. We mark
it Psub for being the substratum of P.
2. Higher in the hierarchy is the population of all the individuals whose assemblages
are constituted from individuals in stratum P. We mark it Psup for being a super-
stratum of P.
Figure 2: Relationship between strata in the model: S consists of P, S +1 consisting of Psup is the superstratum
and S −1 consisting of Psub is the substratum. Ps denotes the population of agents at stratum S.
Solid circles denote the individual agents at any stratum. Dashed lined circles denote assemblages
at any stratum e.g. – As at the center of the ﬁgure, denotes a super-agent that emerges from the
interactions of agents in S. Assemblages at stratum S are the individuated agents of stratum S + 1.
This hierarchical relation of assemblages unfolds recursively both upwards and down-
wards where each level is the substratum of the level above it. Lower levels are populated
by successively simpler elements and higher levels are populated by successively more
complex elements so diﬀerent levels in this hierarchy are of a diﬀerent scale of complex-
ity6.
This simple scheme allows us to describe the transductive mechanism operating at
stratum P from two distinct perspectives: a) Psub provides the ‘raw material’ perspective
for the processes in P in terms of already individuated elements that are given7 and
b) Psup provides the ‘product’ perspective for the processes in P in terms of the individual
objects that are individuated in P. Stratum P, therefore, is a ﬁeld of individuation where
individual elements from Psub get assembled by the actual interactions taking place in
6The scaling is not only structural but also temporal. Changes at diﬀerent scales do not occur at the
same frequency, also the stability of elements varies with complexity.
7The designation ‘given’ here is a simpliﬁcation made for clarity. In fact the elements in Psub are never
fully individuated and are aﬀected by interactions taking place in its two adjacent strata as well.
17

P to produce the higher level individual elements in Psup. The assemblages that emerge
in P are products of a sense-making process taking place in P and therefore can be said
to become sensible in P.
The individuals operating at each strata can be broadly deﬁned as agents consider-
ing their capacities to aﬀect and be aﬀected. Speciﬁcally, in our model, the individuals
described at each stratum are cognitive agents whereas their capacities grow in com-
plexity across strata from the most primitive distinctions and actions at lower strata to
highly complex sense-making activities at the higher strata. Even so, at this level of
description, we do not have to assume agents with intrinsic values or goals that require
a certain level of autonomy as discussed above in 4.1. We only need to require that
minimally some of the capacities to aﬀect are also within what is possibly aﬀected by
interactions with other agents. In other words, the agents’ behaviors are, at least to a
minimal extent, aﬀected by their interactions. This requirement comes to ensure that
some individuation can take place. Clearly, if the agents’ capacities to aﬀect had been
entirely independent from their capacities to be aﬀected (and vice-versa), they could not
change one in relation to the other and therefore no transductive process would have
been possible in such case.
In summary, we introduce two distinct kinds of relation among agents; horizontal and
vertical. Horizontal relations are internal to each stratum and describe the actual inter-
actions that bring forth individuation. The vertical relations are across adjacent strata
and describe hierarchies of individual objects diﬀering in complexity and their upward
and downward eﬀects. While conceptually the individuation of elements at any stratum
follows the same transductive mechanism, the actual mechanisms are context dependent
and can be vastly diﬀerent; the resolution of disparities between neurons, for example,
is nothing like the resolution of disparities between goals, needs and constraints in the
mind of a single human individual, and is nothing like the resolution of disparities be-
tween humans or between social organizations constituted of humans and their artifacts.
Nevertheless, the guiding principle of individuation and its self-similarity across strata
introduces a general model of cognition that is scalable and open-ended.
There is no end, in principle, to the possible expansion of intelligence via the emergence
of new strata of individuation. Whenever a population of cognitive functions/objects
emerges with enough diversity and heterogeneity to become the substratum of novel
individuations, a higher stratum of cognition can potentially emerge. The emergence
of a population of a new kind of individual (e.g.
new species in macro evolution, a
new kind of explanations allowed by a novel theory, mobile devices, applications of
deep learning algorithms etc.) can be thought of as a phase transition event in sense-
making where certain kinds of assemblage that were rarely present before, if at all,
suddenly become ubiquitous, diverse and heterogeneous. When such an event takes place
it can often be associated with a new method or set of methods of resolving problematic
situations and coordinating elements into wholes that could not be integrated before.
Phase transitions in sense-making is possibly the underlying driving principle behind
metasystem-transitions – a theory of the evolution of complexity in general systems
(Turchin and Frentz, 1977; Turchin, 1995; Heylighen, 2000).
18

4.3 Phases of sense-making
Actual sense-making is a continuous process of integration and disintegration of discrete
individuals taking place in a network of agents and their interactions. In the context
of cognition, sense-making is synonymous with individuation. It is important to note
that in our general approach to cognition there is no a priori subject who ‘makes sense’.
Both subjects and objects, agents and their environments co-emerge in the course of
sense-making. For clarity of description, a few phases can be identiﬁed in the process,
given that this deconstruction into phases is largely didactic.
Preindividual boundary formation
The spontaneous emergence of an agent-environment dyad from a random network of
interactions can be thought of as the formation of a boundary that distinguishes a
subset of agents in population P from all the rest. Boundary formation corresponds to
self-organization in the broadest sense. Once there is a boundary, interactions across
the boundary also gain a distinctive signiﬁcance in the sense that now the set of all
possible interactions can be further categorized in relation to the boundary, i.e. those
interactions across the boundary and all the rest. Therefore, the formation of a boundary
is equivalent to symmetry breaking over the population of agents and their interactions.
Initially, boundaries that arise are not ﬁxated and possess no tendency to persist.
Nevertheless boundaries can persist, for a while, even without actively resisting change
if they are not perturbed. How is the spontaneous formation of boundaries possible?
Without specifying the exact nature of the interactions that are responsible for that,
we can assume that in a network of interacting agents, there will exist a non-uniform
distribution of interactions over the population. There will be subsets of agents that
spontaneously aﬀect each other more strongly or frequently than they are aﬀected by
the rest of the agents of the population. Observing such a network for long enough and
drawing a map of the density of interactions, one would, in most cases, ﬁnd regions of
higher density of aﬀective interactions (i.e. interactions that change the state of the
participating agents) compared to their surroundings. This non-uniformity of aﬀective
interactions can be further quantiﬁed in information theoretic terms following the con-
cept of information integration developed by Guilio Tononi (Tononi, 2004; Tononi, 2008;
Edelman and Tononi, 2000) in the context of computational neuroscience. A simpliﬁed
mathematical development of the concept can be found in Appendix A.
The information integration of a set of interacting agents is a relative measure of how
strongly their states have become mutually correlated in comparison to their correla-
tion with the rest of the environment. In our case, information integration is used as
a clustering criterion that singles out from the population P subsets of agents that are
signiﬁcantly more integrated in the sense of aﬀecting each others’ states. The infor-
mation integration of groups of agents requires no a priori assumptions regarding their
dynamics. In other words, informational integrated clusters can contingently arise and
spontaneously persist for a while. But this contingent arising is suﬃcient to initiate a
process of individuation eventually bringing forth order out of disorder.
19

Information integration is a necessary indication to boundary formation but is not
a suﬃcient condition to individuation.
What seems to be necessary for boundaries
to consolidate and persist is an additional element of regularity or repetition in the
interactions.
This element is perhaps best reﬂected in Deleuze’s introduction to the
English translation of his book on Hume’s empiricism:
We start with atomic parts, but these atomic parts have transitions, pas-
sages, “tendencies”, which circulate from one to another. These tendencies
give rise to habits. Isn’t this the answer to the question “what are we?” We
are habits, nothing but habits[.](Deleuze, 1991, p. x)
At this very primal phase of boundary formation we are interested in what would be
minimally suﬃcient to make contingent boundaries more distinct and persistent and
by that drive individuation further. In our model, interactions take place with some
initial probability distribution, and this leads to an initial distribution of information
integration. The missing element can be understood as a kind of a cybernetic mechanism
that reinforces diﬀerences in information integration, that is, integrated clusters of agents
will tend to increase the probability of future interactions (and subsequent correlations
in state) within the cluster in proportion to the present degree of integration. In other
words, similar to Hebbian learning (Hebb, 1968), agents that are already correlated to
some extent will tend to increase their correlating interactions whereas the frequency of
other interactions will relatively decrease.
The reinforcement of the frequency of interactions is a general and simple conceptu-
alization of the ‘habit forming’ tendency. With such a tendency, not only do boundaries
form spontaneously but they will tend to become more distinct once formed. Various
speciﬁc reinforcement mechanisms are possible; the reinforcement can depend (positively
or negatively) on the kind of interactions and the content of the information being ex-
changed between agents, but at the moment, we are only interested in the conceptual
framing of a model of individuation with minimal assumptions. With this additional
cybernetic element, the activity taking place within the network at any moment T in-
ﬂuences the future structure of the network at times t > T as it makes certain links
stronger than others. Also, the interacting agents gradually co-determine their future
interactions. These two eﬀects are the deﬁnitional marks of a transductive process going
on, as we have seen in 3.4.
Closures,autonomy and identity
The phase of sense-making that corresponds to already formed individuals is character-
ized by the emergence of special types of dynamic structures called operational closures.
Operational closure is a central concept in the enactive approach to cognition and is
the basis of the so-called self-constituted or autonomous systems with identity that were
already mentioned in 4.1:
An identity is generated whenever a precarious network of dynamical pro-
cesses becomes operationally closed. A system is operationally closed if, for
20

any given process P that forms part of the system (1) we can ﬁnd among
its enabling conditions other processes that make up the system, and (2) we
can ﬁnd other processes in the system that depend on P. This means that
at some level of description, the conditions that sustain any given process
in such a network always include those conditions provided by the operation
of the other processes in the network, and that the result of their global ac-
tivity is an identiﬁable unity in the same domain or level of description (it
does not, of course, mean that the system is isolated from interactions with
the environment). Autonomy as operational closure is intended to describe
self-generated identities at many possible levels (Di Paolo, Rohde, and De
Jaegher, 2010, p. 38).
Implicit in this deﬁnition are a few important points. First, certain capacities of the
agents (processes) involved gain signiﬁcance as they become enabling conditions to the
operation of other agents. The generality of aﬀecting and being aﬀected is further de-
termined here because it speciﬁes how certain agents aﬀect or are aﬀected by others.
Conceptually this implies a certain level of compatibility among the agents involved and
therefore it means that for operational closures to arise, certain compatibilities among
the participating agents must be present. These compatibilities provide a common de-
scriptive ground that allows the various heterogeneous agents and their interactions to
be described, at least in part, within the same level of description. Second, closures im-
ply the existence of closed loops of interactions (i.e. topological determinations) among
the participating agents and additionally the recurrence of certain sequences of speciﬁc
interactions (i.e. behavioral determinations). Third, the use of the term ‘precarious
network’ hints that the autonomous construction is pretty fragile. If even one of its
constituent agents does not fulﬁll its function, the whole construct might disintegrate.
At least we can expect a signiﬁcant and abrupt modiﬁcation of identity in such cases.
But the precariousness aspect is essential for the enactive approach as it ensures that the
preservation of identity must somehow be an activity and not merely an inert property
of the system. This is how a cognitive system is distinguished (see p. 15).
Undoubtedly operational closures with distinct intrinsic characteristics and that “fol-
low laws set up by their own activity”(ibid., p. 37) are what we normally consider as
individuals. The continuity of self-generated identity becomes the basis of a perspective
an autonomous system has on its environment and a unique principle of sense-making
subjugated to that identity and its persistence as a prime directive. Interactions across
and within the boundary gain relevance and value in relation to this directive. But once
the concept of identity and its continuity take root, individuation seems to have reached
its end as the autonomous system will tend to resist further changes, or in other words,
to exhaust its metastablity and reach a stable regime of its dynamics where it can regu-
late its interactions with the environment. To somewhat soften this apparent rigidity of
autonomous constructs Di Paolo (2006) proposes what he calls a system’s viability set as
the set of external perturbations and internal structural changes an autonomous identity
can withstand without disintegration. We take this idea a deﬁnitive step further.
21

Can there be a third phase of sense-making that incorporates both dynamic boundary
formation and operational closures? We argue that not only does such a phase exist but
that it is the case in the majority of actual phenomena. More often than not individuals
are not rigidly ﬁxed, but rather have continuously individuating ﬂuid identities. Speciﬁ-
cally, cognition as the activity of sense-making is never a stable set of competences that
have exhausted all its potential for transformation, but is rather undergoing a continuous
process of development8.
Fluid identities
The idea of ﬂuid identities is a modiﬁcation of the enactive approach to cognition based
on replacing individuals with individuation. The requirement of precariousness at the
basis of an autonomous structure can be relaxed in the following important manner: that
operational closures need to be maintained continuously means that critically the very
property of closure is maintained but it does not necessarily mean that it is exactly the
same closure that is maintained. A closure C can be maintained as a series of individual
closures C1, C2, C3, ..., Ci, ... that share among them some or most of their constituent
agents but still signiﬁcantly diﬀer from each other. The precariousness can therefore be
said to be maintained as a global property but is not locally maintained. The ordered
set [Ci] as a whole is then considered an individuating object with a ﬂuid identity in the
sense that it preserves most (but not all) of its invariant operational properties across
short periods of time (e.g. while changing from Ci to Ci+1), but there is also a slow drift
of these properties such that after a long time and many consecutive transformations
(e.g. changing from Ci to Ci+k, k ≫1) the said object has possibly become radically dif-
ferent from how it began. How is this possible? Conceptually, we already saw in 3.5 that
individuals are assemblages whose constituting components are themselves independent
individuals that aﬀect and are aﬀected by each other. Components can be plugged into
and out of the assemblage without losing their individuality (because their individual-
ity does not depend on the interactions but rather on their intrinsic properties). Fluid
identity is in fact the only proper description of an assemblage or a continuously indi-
viduating agent. They may lose or gain components in the course of their interactions.
Some of these interactions may bring forth operational closures that did not exist be-
fore, others may disrupt already existing closures, and yet others may only replace one
conﬁguration of closure with another, possibly causing temporary but not fatal gaps in
existing closures. All these movements are possible within assemblages and do actually
happen all the time all around. That we tend to see the world in terms of stable identi-
ties is only an habit. Stable identities arising from strict operational closures are special
cases of ﬂuid identities where an assemblage has become (almost) crystallized or is just
changing very slowly compared to its surroundings.
8Development generally means increase in intelligence in correlation to the complexity of situations and
objects the system can make sense of. But the process is not necessarily monotonous; disintegration
of already integrated structures can take place as well in the course of development. For example,
when a theory is being replaced by a diﬀerent, better theory that can explain and cohere more
observations.
22

The phases of sense-making, from preindividual boundary formation, through ﬂuid
identities to autonomous closures, form in fact a single continuum of change that spans
from ultimate disparity (disorder) to highly organized cognitive agents. Enclosures de-
ﬁned by information integration are preindividual and are characterized by a majority of
contingent interactions over coordinated ones. Enclosures deﬁned by operational closures
are capable of sustaining an identity and are characterized by a majority of coordinated
interactions over contingent ones.
On the thick borderline between these, exist ﬂuid identities that are manifestations
of more or less balanced proportions between coordinated and contingent interactions.
These are volatile entities whose deﬁning characteristics change across time.
These
may radically change their closure construct or even temporarily lose the strict closure
property altogether without losing their overall distinctiveness from their environment
in the long run. From the perspective of open-ended intelligence these are the more
interesting situations where new sense objects may arise out of no-sense but in association
with previously established sense objects. This borderline seem to be where intelligence
expands.
4.4 The resolution of disparity
As we have already mentioned earlier, the nature of intelligence intrinsic to individua-
tion processes is associated with the resolution of disparity and problematic situations
in a population of interacting agents, i.e.
achieving higher degrees of compatibility.
Compatibility is a general concept that distinguishes between ordered and disordered
relations, structural, dynamic or both within the population of agents. Two agents are
incompatible or disparate if their behaviors are entirely independent from each other.
In interactions taking place between disparate agents, each will present for the other
a source of unintelligible noise. No correlated or coordinated exchange of signals takes
place in such a case. Consequently, the behavior of one agent cannot be inferred from
observing the other. Collections of disparate agents do not constitute systems as yet.
They require an exhaustive description of all the unique agents and behaviors. A system
arises from a collection of agents only when some degree of compatibility is achieved
between its member elements. Systems can have a more compact compressed descrip-
tions (relative to their disparate initial state) because compatibility means a degree of
regularity, similarity and recursion in structure and dynamics. The integration function
I(P) deﬁned by equation 4 in Appendix A can be considered as a simpliﬁed general
measure of compatibility.
But compatibility thus understood cannot be the only factor necessary to qualify intel-
ligence. A system with a highly compressed description would mean that its components
are so highly compatible that it becomes redundant in terms of its properties and ca-
pacities (I(P), accordingly, will be large). We need therefore to deﬁne a second factor
we call operational complexity. Qualitatively, the operational complexity of a population
P of interacting agents is the degree to which the overall system’s states are diﬀerenti-
ated. In other words, how many distinct behaviors it can present. A simpliﬁed measure
of operational complexity OC(P) can be given in information theoretic terms and is
23

developed in Appendix B.
Clearly, a disparate collection of agents achieves the highest operational complexity
since the states of all the agents are independent. But this extreme situation is actually
not very intelligent (i.e. it is stupid). As each element operates on its own the emergence
of collectively integrated informational states is impossible. In terms of sense-making,
ultimate disparity indicates no boundary formation at all while ultimate integration
indicates a redundant object with few or no inner states (i.e. no interesting behavior).
A measure of the intelligence embedded in the dynamics of an assemblage of interacting
agents must therefore consider a balanced combination of both information integration
and operational complexity. Based on the mathematical derivations in appendices A
and B, a measure of the open-ended intelligence operating in P can be expressed as a
function of both the compatibility measure I(P) and the operational complexity OC(P):
Intt(P) = F(It(P), OCt(P))
(1)
The subscript t here indicates that this measure is time dependent. It changes in the
course of individuation and does not necessarily achieve maximal values in relatively
stable individuals.
This conceptual formula helps to establish that the resolution of
disparities and problematic situations is not captured only by achieving compatibility
between the disparate components.
The open-ended intelligence intrinsic to the for-
mation of an assemblage is correlated to both its inner compatibility and operational
complexity. Compatibility only reﬂects a degree of integration existing in a collection
of interacting agents; it does not indicate how such integration is achieved. In order to
resolve disparity and achieve compatibility, agents must coordinate their interactions.
Open-ended intelligence in individuating processes can therefore be associated with the
coordination achieved by initially distributed disparate agents in the course of their in-
teractions.
Coordination is what happens among agents that aﬀect each other in a
non-random manner but still maintain a signiﬁcant degree of distinctiveness in their
milieu. Whereas distinctiveness here means that an agent’s behavior is not redundant
and cannot be entirely given in terms of other agents’ behaviors. Intt(P) approximates
therefore the degree of coordination in an assemblage as it captures the evolution of both
integration and inner distinctiveness of an assemblage. Mechanisms of coordination are
therefore foundational to our approach and are further discussed next.
4.5 Coordination
We understand coordination as the reciprocal regulation of behavior given in terms of ex-
changing matter, energy or information among interacting agents, or, between an agent
and its environment. In the latter case, the very distinction of agent – environment
already involves a basic level of coordination. Looking deeper into the nature of interac-
tions among agents at a single stratum P we need to further understand the mechanisms
by which populations of agents reduce disparity and incompatibility and progressively
individuate towards integrated and coordinated higher-level individuals. These mecha-
24

nisms were already mentioned brieﬂy in 4.3 as ‘habit forming’9. Such mechanisms, we
learn, are local and distributed over the population but need to be capable of achieving
eﬀects of global consequences.
Two major categories of mechanisms can be identiﬁed according to the aspect of the
system that they aﬀect10: a) topology modifying mechanisms and b) behavior modifying
mechanisms.
Topology modifying mechanisms manipulate the relative frequencies of
interactions among agents depending on their particular nature. The principle common
to such mechanisms is that interactions that contribute to compatibility and coordination
will tend to increase in frequency while those contributing to incompatibility will tend to
be suppressed. The global topology of the network changes as links between compatible
agents will become stronger while links between incompatible agents will become weaker
or disappear.
As a simple example, consider a group of people speaking a number of diﬀerent lan-
guages. When interacting, people will tend to communicate with interlocutors speaking
the same language and communication attempts with interlocutors who speak other
languages will quickly become infrequent. Also, if there is no choice, people will seek
those who speak a language that is similar to theirs and shares some limited vocab-
ulary. Another very well known example is Hebbian learning in networks of neurons
where synapses strengthen in correlation to synchronous ﬁring of neurons before and af-
ter their synaptic connection (Hebb, 1968). The local modiﬁcations of topology achieve
eventually global eﬀects.
The signiﬁcance of topology modifying mechanisms is that interactions taking place
over the network cause the modiﬁcation of the structure of the network. Note also that
the topological structure shaped by interactions further aﬀects the future ﬂow of inter-
actions and therefore future global behaviors. By that, topology modifying mechanisms
realize a transductive process, as discussed in 3.4.
The second category of mechanisms have to do with behavior modiﬁcation. Agents can
overcome their initial mutual incompatibility and become coordinated by constraining
their own or each others’ set of possible behaviors depending on their interactions11. In
other words, they reciprocally determine or select each others’ behaviors and by doing
that they bring forth mutual relevance and coordination.
Mutual modiﬁcation of behavior requires direct or indirect reﬂexivity among agents.
If agent A aﬀects the behavior of agent B, but is not aﬀected, directly or indirectly, by
the modiﬁcations of behavior it has initiated, there is no real sense in speaking about
9The tendency to form habits or repeating patterns of interaction is philosophically profound. It seem
to indicate an ontological bias towards coordination over disparity, and more generally, of order
over disorder.
This goes back to transcendental empiricism being our point of departure.
The
co-emergence of observer and observed necessarily reﬂects an intrinsic bias (though temporary and
local) towards order over disorder, otherwise neither observers nor observations could possibly emerge.
Order, therefore is both self-evident and self-generative and so is the intelligence manifesting in it.
10The distinction made here is clear only in the context of a single stratum but is much less apparent
considering multiple strata as topological changes in one stratum lead to behavioral changes in the
stratum above it.
11For an early fascinating account of the idea of self-organization in the sense described here, see (Ashby,
1962).
25

progressive resolution of disparity. Even in the case that the eﬀects of A on B have
reduced the incompatibility between B and another agent C, with no feedback to A
of this reduction, the inﬂuence of A is only contingent and no recurrent pattern can
emerge. If however some degree of reﬂexivity does exist, the exchange can eventually
reach a relatively stable and recurrent set of interactions among the participant agents
and an operational closure may emerge12.
Two observations can be made here. The ﬁrst is that achieving coordination is pri-
marily a cybernetic13 selective process that involves feedback. The second conclusion
is somewhat more complex; in order to participate in a coordinated assemblage, agents
need to be reciprocally sensitive to the states of each other. We can see now why Intt(P)
corresponds approximately to higher degrees of coordination, but we can also see the
limitation of Intt(P), since it does not necessarily indicate the bi-directional information
exchanges that are necessary to establish recurrent patterns. Supporting these observa-
tions is Edelman’s discussion and research of re-entrant neural circuits (Edelman, 1987;
Edelman and Gally, 2013; Tononi, Sporns, and Edelman, 1992).
The regulation of interactions whether by constraining the network topology or the
actual behavior of the agents can be thought of as a meta capacity of agents because
they not only aﬀect and are aﬀected by other agents but can also regulate the manner
by which they aﬀect and are aﬀected. According to Di Paolo, Rohde, and De Jaegher
(2010, p. 39), the diﬀerence between structural coupling of an agent with its environment
(or other agents) and the regulation of this coupling is the deﬁnitional property of a
cognitive system.
But such regulation is not designed.
It gradually emerges in the
course of interactions that are at least initially contingent. Therefore, we do not see
merit in drawing sharp lines between systems that are cognitive and systems that are
not when it is evident in many if not all cases that sense-making, the mark of cognition,
is a matter of a gradual continuous process of individuation.
In summary, the underlying processes of sense-making can be understood in cybernetic
terms. These are mutually selective processes distributed over populations of interact-
ing agents. They ‘explore’ and spontaneously ‘discover’ novel coordinated interactions
among the participating agents. A new sense consolidates however only when such ‘dis-
covered’ coordinated interactions become recurrent (‘forming a habit’). The tendency
towards the formation of recurrent patterns of interactions is not given a priori. It is
itself an outcome of individuation as certain coordinated interactions contingently form
operational closures or ﬂuid identities that resist change to a greater or lesser degree.
If there was absolutely no such tendency, there could be no coordination, no individual
objects or persistent relations between objects, just disorder.
12All forms of conditioning including self-conditioning belong to this category as they establish correla-
tions between an agent’s input and output signals.
13The cybernetic nature of individuation was already discussed in 4.3 but here it is introduced in the
more speciﬁc context of our model.
26

4.6 Perspective and value
The concept of value occupies a primary place in the discourse about the nature of in-
telligence. In 2.1, the ability of an agent to achieve goals is mediated by maximizing
rewards. The combination of a goal and environment create for the intelligent agent a
perspective by which all situations whether internal or external, and all agent – environ-
ment interactions, gain signiﬁcance in terms of how they reﬂect on the achievement of
the goal. Values can be generally described as the quantitative measures of signiﬁcance
and the dynamics of values guide the actions of the agent. In his analysis of intelligent
agents Legg (2008) writes:
[...]
We deﬁne an additional communication channel with the simplest
possible semantics: a signal that indicates how good the agent’s current
situation is. We will call this signal the reward. The agent simply has to
maximize the amount of reward it receives, which is a function of the goal.
In a complex setting the agent might be rewarded for winning a game or
solving a puzzle. If the agent is to succeed in its environment, that is, receive
a lot of reward, it must learn about the structure of the environment and in
particular what it needs to do in order to get reward. (ibid., p 72)
Traditionally, intelligence is measured in terms of ﬁnding ways to maximize the reward
(value) for various environments and goals. Of course, the value function itself may be
subject to changes in time and additionally, strategies that consider short-term or long-
term maximum rewards might be profoundly diﬀerent. Still, as the commonly accepted
concept of intelligence is understood, the manipulation of measurable value by the agent
is what intelligence is all about and therefore value must be a given (see also 2.2).
The enactive theory of cognition follows a similar approach but with two important
diﬀerences: a) speciﬁc values are not a priori given but are self-generated by an opera-
tional closure and characterize an autonomous identity: “Sense making: Already implied
in the notion of interactive autonomy is the realization that organisms cast a web of sig-
niﬁcance on their world.”(Di Paolo, Rohde, and De Jaegher, 2010, p. 39)(see also 4.3),
and b) the preservation of identity is the prime value of autonomous systems: “For enac-
tivism, value is simply an aspect of all sense-making, as sense-making is, at its root, the
evaluation of the consequences of interaction for the conservation of an identity.”(ibid.,
p. 45). Indeed according to enactivism, speciﬁc value functions are not given, but there
is a primal value which is the conservation of identity. Di Paolo et al. later deﬁne value
as “[ ] the extent to which a situation aﬀects the viability of a self-sustaining and pre-
carious network of processes that generates an identity.” (ibid., p.48), which makes it
even clearer that there is an a priori value in place. In both approaches, value guides
behavior but is also a limit. Once achieved or maximized, the potential of the agent for
further exploration is exhausted.
Though we accept that values are intrinsic to sense-making, we do not agree that
values must precede any intelligent activity or sense-making in order to guide them;
nor that they are necessarily preceded by the establishment of an autonomous identity.
Rather, values are products of an ongoing individuation. Emerging values in the process
27

of individuation carry their own problematic as they are initially non-coherent or even
conﬂicting. A good example of the individuation of value is the negotiation over the
price of a certain good in a marketplace. If the market is big enough, and the good
is oﬀered by a few vendors, the price of the same good can be negotiated in many
places by diﬀerent agents and reach signiﬁcantly diﬀerent values. However, information
exchanged among buyers and sellers over the whole market will eventually minimize or
eliminate the variation in the price14. When in the course of individuation, values become
relatively invariant, they become the characteristics of stable individuals. The eﬀective
regulation of such values by individuals can then be understood as the preservation of
identity. Values can designate a certain relation or set of relations (e.g. body temperature
relative to the environment, the skin color of a chameleon etc) between an agent and
its environment. When such value becomes regulated and therefore relatively stable, it
guides general categories of behaviors such as adaptation (i.e. the modiﬁcation of internal
structure in response to perturbations), or niche construction (i.e. the modiﬁcation of
the structure of the environment in response to perturbations). The development of
behaviors that belong to these categories are well accounted for by the conventional
conception of intelligence.
Regulated values, by deﬁnition, resist change.
Therefore it is easy to understand
why they are associated with identity. Identity is nothing more than a set of variables
being kept within a certain range of values. Identity and values therefore co-deﬁne each
other. Values in the course of individuation, in contrast, cannot be said to characterize
an identity. In fact, they cannot be conventionally identiﬁed as values at all. In the
preindividual state there are no values, only proto-values.
In the multi-strata model of individuation we describe in 4.2, every stratum individu-
ates its own set of values that also reﬂect the diﬀerent identities of agents that emerge in
that stratum. The individuation of agents in any stratum S, however, does not depend
only on horizontal interactions within that stratum.
The relations of every stratum
with its substratum Ssub and superstratum Ssup is mediated by values that emerge in
these neighboring strata. The substratum Ssub provides the component elements that
constitute the assemblages in S. Inasmuch as these elements are more or less stable
individuals, they have characteristic values that resist changes and perturbations that
may be caused by interactions in S. In other words, the values that emerged at the
substratum Ssub are selective (i.e. constraining) in regard to the interactions possible
in S. In a similar manner, individuations that take place on the superstratum Ssup will
tend to regulate the individuations on S by preferring certain interactions over others.
For example, if an agent produced in S is frequently involved in assemblages emerging
in Ssup, this will have a biasing eﬀect on the distribution of agents within the population
of agents in S. Changing the distribution of agents in the population exerts certain con-
straints as well as allowing certain degrees of freedom on the interactions taking place
in S.
14Such processes of individuation can become extremely complex. This example also demonstrates that
considering a single price for a good is often a gross oversimpliﬁcation. Prices of goods undergo an
individuation process that is never exhausted especially if demand and supply are distributed and
ﬂuctuating.
28

In summary, individuation at every stratum is subject to both bottom-up and top-
down inﬂuences that are mediated by the values in neighboring strata. Individuation at
multiple simultaneous levels involves both evolutionary (bottom-up) and developmen-
tal (top-down) organization.
For example: a human organism in a social context is
exposed to systems of individuating pressures that in turn aﬀect biological parameters
(e.g. stress) that aﬀect the individuation of speciﬁc organs that in turn aﬀect the in-
dividuation of cell populations and individual cells. A cell may produce a mutation,
undergo destabilization of its genetic operations as a result, and turn into a cancerous
cell that is as stable as an healthy cell. This may disrupt a tissue or a whole organ
and aﬀect the performance of the aﬀected human in her social context (e.g. disabil-
ity and need for medical care). The division into strata reﬂected in our model is not
an artiﬁcial construction though. It derives from the fact that complex individuation
processes spontaneously produce an hierarchy of individuated entities because low-level
simple assemblages are more probable (and therefore faster) to integrate into coordi-
nated wholes than complex assemblages. This results in the emergence of a stratiﬁed
process of individuation. See (Simon, 1962) for further discussion of this eﬀect.
5 A non-concluding conclusion
Cognitive science and artiﬁcial intelligence research have made very impressive advances,
in understanding and practically implementing systems with a wide range of intelligent
capacities. Yet, most of the current theoretical thinking about intelligence and cognition
is still limited to a problem solving dogma, as argued in 2.1-2.2. In this paper we go be-
yond the identiﬁable cognitive competences that can be readily associated with speciﬁc
problems or problem domains. We lay down philosophical and theoretical foundations
to how intelligent systems such as brains, whole organisms, social entities and other
organizations develop and scale.
We shift the focus of investigation from intelligent
agents as individual products to the intelligence intrinsic to their process of produc-
tion i.e. their individuation – what we call open-ended intelligence. We propose that
such an approach provides important insights as to what diﬀerentiates intelligence that
is open-ended and truly general from other goal oriented and therefore limited types
of intelligence. By that, we oﬀer a signiﬁcant extension to the conceptualization and
understanding of intelligence.
The principle distilled from this investigation is that Open-ended Intelligence is a pro-
cess where a distributed population of interacting heterogeneous agents achieves progres-
sively higher levels of coordination. In coordination here we mean the local resolution of
disparities by means of reciprocal determination that brings forth new individuals in the
form of integrated groups of agents (assemblages) that exchange meaningful information
and spontaneously diﬀerentiate (dynamically and structurally) from their surrounding
milieu. This kind of intelligence is truly general in the sense that it is not directed or
limited by an a priori given goal or challenge. Moreover, it is intrinsically and indeﬁ-
nitely scalable, at least from a theoretical point of view. We see open-ended intelligence
manifesting all around us and and at many scales; primarily in the evolution of life,
29

in the phylogenetic and ontogenetic organization of brains, in life-long cognitive devel-
opment and sense-making and in the self-organization of complex systems from slime
molds, fungi, and bee hives to human sociotechnological entities.
Interestingly, open-ended generative intelligence is reﬂexively involved in the very
process of describing it here in the individuation of concepts, models and perspectives
explored above. And these, we learn, are always a work in progress. We conclude this
paper therefore by highlighting problems and disparities in the form of a few challenging
open questions that stimulate further research and may drive further individuation.
Measuring open-ended intelligence – The goal-oriented approach to General Intelli-
gence is particularly successful in providing a simple and reliable measure of ﬁtness
or success that can be directly associated with the level of intelligence an agent
presents. In our case however, measurement is much less obvious. In order to
have a better grasp of the dynamics of intelligent individuating processes, more
rigorous measures of individuation need to be developed. Because of the unique
nature of individuation as a determining process it is not entirely clear whether or
not it can be generally quantiﬁed. Our point of departure for measurement is the
concept of information integration that was developed by Tononi (2004; 2008) in
a neuroscientiﬁc context as a possible explanation of consciousness. We use this
concept in a somewhat diﬀerent and more general way to quantify individuation.
Measures based on information integration derive only from the probabilistic prop-
erties of the exchanged signals (appendices A and B sketches preliminary steps in
that direction). While this might be suﬃcient for low level agents such as neu-
rons, or similarly simple agents, they do not capture the full signiﬁcance of aﬀect
between more complex interacting elements (e.g. human decision makers) in the
general case. This must necessarily involve a notion of the meaning embedded in
the exchanged signals (i.e. what diﬀerence do they make for the agents). In other
words, information integration is not suﬃcient to express the manner by which el-
ements within an assemblage actually aﬀect and are aﬀected by each other. They
merely reﬂect that such aﬀective relations are taking place and to what extent. In
order to quantify open-ended intelligence, a measure must be developed to reﬂect
the degree of coordination achieved within a population of agents at each stage
of individuation. Additionally, a measure needs to be developed to estimate rel-
ative stability and resilience of already formed individuals within a population.
Such measure(s) will allow us to better understand and monitor the dynamics of
individuation, turning points, disruptive elements and more.
Value systems and stratiﬁed individuation – Of special interest is to investigate the in-
dividuation of values. Values represent consolidated goals and are therefore highly
signiﬁcant in understanding the evolution of intelligent competences and sense-
making. Values are signals that guide distinction mechanisms thus enabling adap-
tation and learning. In our understanding, values also mediate between diﬀerent
strata of individuation. The individuation of values seems to be an important key
to further understand the individuation of intelligent systems across strata.
30

Towards a generative model – One of the more diﬃcult and interesting challenges is
to implement a simulation model of open-ended intelligence based on the concepts
explored in this paper. Such an implementation will serve both theoretical and
practical ends. It will help to better understand individuation and the transduction
mechanism and it will help to understand or even discover general coordination
mechanisms. It will help to appreciate the potential and limitations of scalability,
and whether truly open-ended systems are practically possible and under what
conditions. Importantly, it may also become a platform for speciﬁc applications.
Understanding coordination – We see the individuation of coordination as the mani-
festation of open-ended intelligence. One of the focuses of future research would
be to investigate individuation processes in the light of the kinds of coordination
they bring forth. For example: synchronization is a very basic type of coordination
having to do with the timing of activities and recurrent patterns of interaction.
The phenomena of resonance is instrumental to understanding how agents that are
initially not synchronized (i.e. disparate in the temporal sense) can gradually syn-
chronize their interactions. Another important topic is to investigate the relations
between the individuation of coordination within stratum and across strata.
Potential for application – Observing individual systems, we are often able to see in
retrospect that the system evolved to address a speciﬁc problem (e.g. eyes, ﬂowers,
wings, courts, money, transportation systems, the Internet etc.). But it is very
diﬃcult, if at all possible, to foresee what ﬁnal purpose or goal a system might fulﬁll
while it is individuating, when it is not a system as yet and the interactions among
its prospective future components carry only marginally meaningful information.
Open-ended intelligence therefore seems to be inherently unpredictable as to its
ﬁnal products and as a result diﬃcult to be harnessed towards a useful purpose. It
will be interesting to investigate the possible practical applications of individuating
processes and whether they can be guided (Prokopenko, 2009). Of interest is also
the hybridization of goal oriented and individuating approaches to achieve highly
ﬂuid intelligent systems.
References
Ashby, W.R. (1962). “Principles of the self-organizing system”. In: Principles of Self-
Orga- nization: Transactions of the University of Illinois Symposium. Ed. by H Von
Foerster and G.W. Zopf Jr. London: Pergamon Press, pp. 255–278.
Bechtel, W. and A.A. Abrahamsen (2002). Connectionism and the mind: Parallel pro-
cessing, dynamics, and evolution in networks. Wiley-Blackwell.
Combes, Muriel and Thomas LaMarre (2013). Gilbert Simondon and the Philosophy of
the Transindividual. Duke Univ Press.
De Jaegher, Hanne and Ezequiel Di Paolo (2007). “Participatory sense-making”. In:
Phenomenology and the cognitive sciences 6.4, pp. 485–507.
31

De Landa, M. (2006). A new philosophy of society: Assemblage theory and social com-
plexity. Continuum Intl Pub Group.
DeLanda, Manuel (2013). Intensive science and virtual philosophy. A&C Black.
Deleuze, Gilles (1991). Empiricism and subjectivity: an essay on Hume’s theory of human
nature. Columbia University Press.
—
(1994). Diﬀerence and repetition, trans. Paul Patton. New York: Columbia Univer-
sity Press.
Deleuze, Gilles and Flix Guattari (1987). “A thousand plateaux”. In: Trans. Brian Mas-
sumi. Minnesota: University of Minnesota Press.
Di Paolo, Ezequiel (Apr. 2006). “Autopoiesis, Adaptivity, Teleology, Agency”. en. In:
Phenomenology and the Cognitive Sciences 4.4, pp. 429–452. issn: 1568-7759, 1572-
8676. doi: 10.1007/s11097-005-9002-y.
Di Paolo, Ezequiel and Evan Thompson (2014). “The Enactive Approach”. In: The
Routledge handbook of embodied cognition. Ed. by Lawrance Shapiro. Routledge.
Di Paolo, Ezequiel A., Marieke Rohde, and Hanneke De Jaegher (2010). “Horizons for
the enactive mind: Values, social interaction, and play”. In: Enaction: Towards a
new paradigm for cognitive science, pp. 33–87.
Edelman, Gerald M. and Joseph A. Gally (Aug. 2013). “Reentry: a key mechanism
for integration of brain function”. In: Frontiers in Integrative Neuroscience 7. issn:
1662-5145. doi: 10.3389/fnint.2013.00063.
Edelman, Gerald M. and Giulio Tononi (2000). A universe of consciousness: How matter
becomes imagination. Basic Books.
Edelman, G.M. (1987). Neural Darwinism: The theory of neuronal group selection. Basic
Books.
Goertzel, Ben (2012). CogPrime: An Integrative Architecture for Embodied Artiﬁcial
General Intelligence. Wiki.
Hebb, D. (1968). The Organization of Behavior. Wiley, New York.
Heylighen, Francis (Sept. 2000). “Evolutionary Transitions: How Do Levels of Complex-
ity Emerge”. In: Complexity 6.1, pp. 53–57. issn: 1099-0526. doi: 10.1002/1099-
0526(200009/10)6:1<53::AID-CPLX1008>3.0.CO;2-O.
Hui, Yuk and Harry Halpin (2013). “Collective individuation: the future of the social
web”. In: The Unlike Us Reader, pp. 103–116.
Hutter, Marcus (2005). Universal artiﬁcial intelligence: Sequential decisions based on
algorithmic probability. Springer Science & Business Media.
Legg, Shane (2008). “Machine super intelligence”. PhD thesis. University of Lugano.
Legg, Shane and Marcus Hutter (2007). “A Collection of Deﬁnitions of Intelligence”. In:
Advances in Artiﬁcial General Intelligence: Concepts, Archtectures and Algorithms.
Ed. by Ben Goertzel and Pei Wang. IOS Press.
Maturana, Humberto and Francisco Varela (1980). Autopoiesis and cognition: The real-
ization of the living. Vol. 42. Springer.
—
(1987). The tree of knowledge: The biological roots of human understanding. New
Science Library/Shambhala Publications.
Piaget, Jean (2013). Principles of Genetic Epistemology: Selected Works. Vol. 7. Rout-
ledge.
32

Prigogine, Ilya and Isabelle Stengers (1984). Order out of chaos: Man’s new dialogue
with nature. Bantam books New York.
Prokopenko, Mikhail (2009). “Guided self-organization”. In: 00038.
Simon, H.A. (1962). “The architecture of complexity”. In: Proceedings of the American
philosophical society 106.6, pp. 467–482.
Simondon, Gilbert (1992). “The genesis of the individual”. In: Incorporations 6, pp. 296–
319.
—
(Nov. 2005). L’individuation
la lumire des notions de forme et d’information.
Franais. Grenoble: Editions Jrme Millon. isbn: 9782841371815.
—
(2009). “The position of the problem of ontogenesis”. In: Parrhesia 7, pp. 4–16.
Solomonoﬀ, Ray J. (1964a). “A formal theory of inductive inference. Part I”. In: Infor-
mation and control 7.1, pp. 1–22.
—
(1964b). “A formal theory of inductive inference. Part II”. In: Information and
control 7.1, pp. 224–254.
Stewart, John Robert, Olivier Gapenne, and Ezequiel A. Di Paolo (2010). Enaction:
Toward a new paradigm for cognitive science. MIT Press.
Thompson, Evan (2007). Mind in life: Biology, phenomenology, and the sciences of mind.
Harvard University Press.
Tononi, G. (2008). “Consciousness as integrated information: a provisional manifesto”.
In: The Biological Bulletin 215.3, pp. 216–242.
Tononi, Giulio (Nov. 2004). “An information integration theory of consciousness”. In:
BMC Neuroscience 5.1, p. 42. issn: 1471-2202. doi: 10.1186/1471-2202-5-42.
Tononi, Giullo, Olaf Sporns, and Gerald M. Edelman (1992). “Reentry and the problem
of integrating multiple cortical areas: simulation of dynamic integration in the visual
system”. In: Cerebral Cortex 2.4, pp. 310–335.
Turchin, Valentin F. (1995). “A dialogue on metasystem transition”. In:
Turchin, Valentin Fedorovich and Brand Frentz (1977). The phenomenon of science.
Columbia University Press New York.
Varela, Francisco J., Evan Thompson, and Francisco J. Rosch (1992). The embodied
mind: Cognitive science and human experience. MIT press.
Weinbaum, David R. (Sept. 2014). “Complexity and the Philosophy of Becoming”.
In: Foundations of Science, pp. 1–40. issn: 1233-1821, 1572-8471. doi: 10.1007/
s10699-014-9370-2.
33

Appendix A
Information integration as a measure of boundary formation in a population
of interacting agents
Given a population P of pi interconnected agents, where i ∈[1, .., N], we wish to quantify
how much they aﬀect and are aﬀected by each other. In information theoretic terminol-
ogy, each agent pi can either change its state independently of all other agents in P, or
its state may depend on the states of other agents in P, or even be entirely determined
by the states of other agents. The mutual information between two agents pi, pj is given
by the formula:
MI(pi, pj) = H(pi) −H(pi/pj) = H(pj) −H(pj/pi)
(2)
= H(pi) + H(pj) −H(pi, pj)
(3)
Where H(x) is the entropy involved in the state of agent x. If pi and pj are indepen-
dent, H(pi, pj) = H(pi)+H(pj) and then MI(pi, pj) would be 0. The mutual information
would be maximum in the case that the state of one agent is fully determined by the
other. In this case the mutual information will be equal to min(H(pi), H(pj)).
For a set of agents pi in P the integration of the whole set would be given by the sum
of the entropies of the independent agents pi minus the entropy of the joint set P:
I(P) =
k
X
i=1
H(pi) −H(P)
(4)
In order to compare the degree of integration within a subset of agents to the integra-
tion between the said subset and the rest of the population, we divide the population of
agents P into two subgroups of diﬀering sizes: Xk
i and its complement P −Xk
i , where
k is the number of agents in the subset X. The mutual information between Xk
i and its
complement is:
MI(Xk
i , P −Xk
i ) = H(Xk
i ) + H(P −Xk
i ) −H(P)
(5)
Formula 5 measures the statistical dependence between a chosen subset i of k agents
and the rest of the population. The Cluster Index CI of the subset Xk
i will therefore be
given by:
CI(Xk
i ) = I(Xk
i )/MI(Xk
i , P −Xk
i )
(6)
CI measures the degree of distinctiveness of a subset of agents in P compared to the
whole population in terms of information exchange15. For CI ≤1 there is no signiﬁcant
distinctiveness while a subset with CI ≫1 indicates a distinct integrated cluster. A
threshold on CI can therefore be used to formally describe more or less integrated
assemblages.
15Note that these are only simpliﬁed formulas that do not take into account the diﬀerent sizes of subsets.
34

Appendix B
The operational complexity of a system of interacting agents in a population
A simpliﬁed general measure of operational complexity can be given in terms of the av-
erage mutual information of subsets of P. Let P be a population of size M. Assume that
P is isolated so its inner states are self produced. We divide P into two complementary
subsets Xk
j and P −Xk
j of respective sizes k and M −k. The index j, enumerates all
possible subsets of size k out of X. The operational complexity OC(P) of population P
can be given by:
OC(P) =
M/2
X
k=1
< MI(Xk
j , P −Xk
j ) >
(7)
where the mutual information is averaged on all subsets of size k. Subsets of very small
size will contribute very little to OC(P), while subsets of sizes in the vicinity of M/2 will
contribute the most complexity. Remarkably, OC(P) measure of complexity is based
only on the extent to which subsets of the population aﬀect each other and the statistical
properties of the signals that agents within the population exchange. OC(P) therefore
does not rely on an arbitrary measure of complexity imposed from outside the cluster.
35

