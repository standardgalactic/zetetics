Odysseus Makridis
Symbolic Logic 
PALGRAVE PHILOSOPHY TODAY

Palgrave Philosophy Today
Series Editor
Vittorio Bufacchi 
Philosophy
University College Cork Philosophy
Cork, Ireland

The Palgrave Philosophy Today series provides concise introductions to all the 
major areas of philosophy currently being taught in philosophy departments 
around the world. Each book gives a state-of-the-art informed assessment of a 
key area of philosophical study. In addition, each title in the series offers a distinct 
interpretation from an outstanding scholar who is closely involved with current 
work in the field. Books in the series provide students and teachers with not only a 
succinct introduction to the topic, with the essential information necessary to 
understand it and the literature being discussed, but also a demanding and engaging 
entry into the subject.
More information about this series at  
http://www.palgrave.com/gp/series/14672 

Odysseus Makridis
Symbolic Logic

ISBN 978-3-030-67395-6        ISBN 978-3-030-67396-3  (eBook)
https://doi.org/10.1007/978-3-030-67396-3
© The Editor(s) (if applicable) and The Author(s), under exclusive licence to Springer Nature 
Switzerland AG 2022
This work is subject to copyright. All rights are solely and exclusively licensed by the Publisher, whether 
the whole or part of the material is concerned, specifically the rights of translation, reprinting, reuse of 
illustrations, recitation, broadcasting, reproduction on microfilms or in any other physical way, and 
transmission or information storage and retrieval, electronic adaptation, computer software, or by similar 
or dissimilar methodology now known or hereafter developed.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this publication 
does not imply, even in the absence of a specific statement, that such names are exempt from the relevant 
protective laws and regulations and therefore free for general use.
The publisher, the authors and the editors are safe to assume that the advice and information in this book 
are believed to be true and accurate at the date of publication. Neither the publisher nor the authors or the 
editors give a warranty, expressed or implied, with respect to the material contained herein or for any 
errors or omissions that may have been made. The publisher remains neutral with regard to jurisdictional 
claims in published maps and institutional affiliations.
Cover image © Science Photo Library / Alamy Stock Photo, Image ID: RAGKPW
This Palgrave Macmillan imprint is published by the registered company Springer Nature Switzerland AG.
The registered company address is: Gewerbestrasse 11, 6330 Cham, Switzerland
Odysseus Makridis
Literature, Languages, and Philosophy
Fairleigh Dickinson University
Madison, NJ, USA

v
Contents
	1	
What Logic Studies����������������������������������������������������������������������������������      1
	2	
Concepts of Deductive Reasoning����������������������������������������������������������    57
	3	
Formal Logic of Sentences, Sentential Logic (also called Sentential  
Logic and Statement Logic)��������������������������������������������������������������������    81
	4	
Sentential Logic Languages ∑����������������������������������������������������������������  115
	5	
Formal Predicate Logic (also called First-­Order Logic) ∏����������������  289
	6	
Translations from English into ∏πφ= (also called Symbolizations, 
Formalizations)����������������������������������������������������������������������������������������  331
	7	
Semantic Models for ∏: ∏⧉����������������������������������������������������������������  351
	8	
Proof-Theoretical System for Predicate Logic: ∏πφ=���������������������������  373
	9	
Definite Descriptions: ∏πφ=⍳��������������������������������������������������������������������  397
	10	 Basics of Set Theory��������������������������������������������������������������������������������  405
Glossary ������������������������������������������������������������������������������������������������������������  459
References����������������������������������������������������������������������������������������������������������  481
Index������������������������������������������������������������������������������������������������������������������  485

1
© The Author(s), under exclusive license to Springer Nature 
Switzerland AG 2022
O. Makridis, Symbolic Logic, Palgrave Philosophy Today, 
https://doi.org/10.1007/978-3-030-67396-3_1
Chapter 1
What Logic Studies
To preempt misunderstanding, we start with enumerating some common usages of 
the word “logic,” which are not relevant to our present task.
	1.	 By “logic” we do not mean prudence – as the word is used in the sentence “it is 
not logical to make this investment.”
	2.	 We don’t mean by “logic” an assessment of what works and what doesn’t work 
when making decisions or developing effective strategies, as in the sentence 
“everyone has her own logic when it comes to what needs to be done.” More 
broadly, we don’t have in mind any practical, strategic, efficiency-related or 
pragmatic subject.
	3.	 We don’t use the word “logic” to refer to value assessment – as in the sentence, 
“the logic of the natives compels them to value a supposed afterlife more highly 
than the present life.” There are no moral connotations attaching to the meaning 
of “logic” as we use it. The use of the word in the sentence “logic works differ-
ently across different cultures” may often refer to the value systems of the cul-
tures, but this is not the sense of the word “logic” we will busy ourselves about.
	4.	 Nor is the word “logic” referring to characteristics or the internal mechanics of 
certain institutional arrangements and established practices – as in the sentence 
“the logic of the Constitution dictates separation of powers.”
By “logic” we mean the study of certain characteristic properties which are – as 
one would expect – themselves logical properties. Evidently, we have not provided 
a definition yet since we need to specify what we mean by “logical properties.” This 
will be done shortly. Alternatively, we may speak of logic as the study of logical 
consequence – which is the structural relationship between the premises and the 
conclusion of a logically correct argument (with the intuitive notion of “correct-
ness” as it applies in this field requiring appropriate elucidation). Another definition 
we may venture defines logic as the study of logical truths. This definition too 
requires a prior definition of the concept of the term “logical truth,” which will be 
undertaken shortly.

2
To give a definition of logic promptly, without navigating through related con-
cepts, we can say something like this: Logic is the study of what works and what 
does not work in reasoning. This definition is ambiguous and vague because it talks 
about what “works” without specifying the criteria for relevant success (or the 
degree to which results are considered successful) and it also uses the concept “rea-
soning” which seems to be synonymous with “logic.”
We can do better: Logic is the study of correct reasoning. Now, we still use in our 
definition the concept of reasoning but we have added “correct” which has an intui-
tive appeal about it. We are signaling already, significantly, that reasoning can be 
correct or incorrect: the criteria are not a matter of subjective evaluation, preference 
or taste, or provided by communal or institutional practices. The concept of correct-
ness definitionally implies the availability of relevant standards by reference to 
which correctness is assessed. The word “reasoning”, although we have not defined 
it, also has some initial intuitive resonance. We can get more precise: evaluation of 
proofs is – not the only one but – a major subject of Logic. We can define Logic as 
the study of proofs (and of other subjects, to be specified). Many texts stake the defi-
nition of the basic concept on the role arguments play in logic. An urgent clarifica-
tion is in order: “argument”, as logicians use the term, does not mean anything about 
disagreement or any activity of “arguing” in the sense of fighting or even in the 
sense of debating. We will have a lot to say about this term but it can safely be 
thought of as having something to do with proving, with proofs and with construct-
ing proofs. When we think of proofs, intuitively, we should think of “proving,” 
“supporting” or “making inferences” to conclusions from given assumptions. 
Without training in the study of Logic, we cannot depend on our common sense to 
figure out if proofs are “correct” in the sense that the connection between premises 
and conclusions is sufficiently effective (in the appropriate sense) so that the proof 
“works,” is “correct” or is “acceptable.”
It is crucial to specify that the inferences to conclusion and the correctness and 
acceptability we are talking about are not psychological notions! It may well be that 
the word “inference” has psychological connotations and is, as such, dubious in the 
present context but there is logic practice of using this word and, accordingly, so 
will we.
An incorrect proof is one that should not be accepted – even if we don’t realize 
that there is lack of proper support from the premises for the conclusion. We do not 
acquire, either by natural intuitions or even by scholastic training in various sub-
jects, the skills needed to assess proofs; instead, there is an imperative to study this 
subject. It is promising, however, that this study is possible as a systematic 
endeavor – and, in fact, it is one of the ancient disciplines – and has exploded in 
modern times thanks to certain developments in areas of Mathematics: this study, 
broadly, is what we call Logic.
The importance of engaging in this subject can be seen from reflecting on obser-
vations like this: if we wrongly accept conclusions that do not follow from the prem-
ises in given proofs, then we add as new “truths” claims that may well be false: 
learning and progress are undermined and we risk catastrophic setbacks to our 
quest for increasing the stock of knowledge. The immense advancement of the 
1  What Logic Studies

3
human species is critically dependent on throwing out conclusions that have been 
drawn incorrectly and retaining conclusions that have been proved correctly by 
proofs that “work” or are correct. Even though this assessment does not come natu-
rally and is – as it turns out – an inherently technical matter, correct evaluation of 
proofs is vital, and rather overlooked in educational settings, because it is the accre-
tion of added truths, drawn as conclusions, that makes the characteristically expo-
nential progress in knowledge possible.
A last preliminary remark is that the standards of what counts as a correct proof 
depend on what kind of proof it is – what kind of logic is at play: reasoning comes 
in two varieties – we cannot discern any deeper reason as to why it is exactly two 
varieties – which are Deductive Logic and Inductive Logic. Deductive arguments 
are judged differently – they are, by their nature, different from – inductive argu-
ments. We devote no space to the examination of Inductive Logic in this text as the 
business of formal or symbolic logic – and the field in which mathematical instru-
ments are available in logic – is Deductive Logic. In either case – whether it be 
deductive or inductive – a proof (or, as we will call it, technically, an argument) has 
premises from which a conclusion is derived and the claim is presented that, as we 
may say colloquially, the conclusion “follows from” the premises or is correctly 
proven from the premises or is sufficiently supported by the premises. There is a 
common tendency to regard the collection of the premises in a proof as “evidence” 
and this is also referred to as “the facts” but meaningful sentences do not have to be 
factual or descriptive. A sentence like “all people are equal before the law” is not a 
descriptive sentence if it states the principle (not the legal fact); we take it, of course, 
to be a meaningful sentence. Accordingly, the word “evidence” should not be used 
in the context of focused technical study of proofs.
In addition to the study of proofs, technically called “arguments,” logic also stud-
ies such logical properties as consistency, which is a property of a collection of 
meaningful sentences taken all together, and the logical status of a meaningful sen-
tence, which refers to whether a sentence is a necessary truth or necessary falsehood 
or logically indeterminate. We will be examining these notions in detail in the pres-
ent text.
Sometimes the term “logic” is used to refer to a logical system or structure rather 
than to the study of proofs or of logical characteristics and related subjects. If we ask 
the question about what constitutes a logical system, we can define such a system in 
different ways that parallel the definitions we gave above: a logical system (or, a 
“logic”, not in the sense of studying logic but in the sense of a “logic” as a structure) 
can thus be defined on the basis of its so-called consequence relation (also, logical 
consequence relation) or as a collection of all its logical truths or as a system that 
generates proven theses out of a small number of given postulates (or axioms) and 
with the assistance of implementing specified rules. It is a deep philosophic matter 
whether we should define logic, or a logical system, one way or another, but this 
will not concern us in the present text. To remove any ambiguity, we point out that 
in this text logic refers to the study, not to a system or structure but, at the same time, 
we can say that we are engaged in logic as the study of logics-as-systems. The sys-
tems we investigate are limited to the basic logics (in the sense of “system” or 
1  What Logic Studies

4
structure): thus, we will study the standard sentential and standard predicate (or 
first-order) logic but we do not have the space to undertake further excursions that 
would transfer us to such areas as the terrain of modal logics or alternative non-­
standard logics, with the exception of forays we will be taking into what is known 
as Intuitionistic Logic. Nor are we at liberty to indulge in explorations of fascinating 
problems in the philosophic themes and problems associated with the philosophy of 
logic, except availing ourselves of opportunities that arise occasionally – including 
selected exercises that accompany sections.
Based on the preceding remarks, there is some remaining ambiguity – which 
cannot be tolerated in the study of any subject, let alone in one so technically pre-
cise – between: logic understood, on the one hand, as a formal (mathematically 
facilitated) study of logical structures or forms and other abstract objects (which 
may or may not be mathematical, regardless as to whether such objects are thought 
to exist independently of the human mind thinking about them); and, on the other 
hand, as a motivated investigation of the rules of reasoning as these rules govern, 
and normatively constrain, actual transaction in reasoning (possibly dictated by the 
workings of linguistic conventions.) This distinction parallels that between pure and 
applied geometry – a parallelism that has been drawn many times and has been 
subjected to multiple critiques. Although geometry too was once considered moti-
vated by the imperatives of investigating and managing understanding of the actual 
physical world, we should rather think of the subject of geometry as the study of 
abstract structures and associated abstract objects while, on the other hand, the 
claim that there is a fit between a geometrical system and the physical universe is an 
empirical matter.
According to the pluralistic view of logic, there is no one correct logic; this 
seems to be at variance with the case of geometry, for which it appears that – what-
ever the “correct” geometry of the physical universe may be, there has to be one 
such applicable geometry; on the other hand, the “correctness” of the applicable 
logic may be dependent on the area of application. Nevertheless, a parallel consid-
eration emerges in the case of geometry: for instance, certain tasks are better carried 
out by application of the classical Euclidean geometry whereas other tasks require 
a non-Euclidean geometry for dispatch. Nor is this a pragmatic issue since deeper 
considerations about justifying such fitting applications arise. Our purpose is not to 
discourse on the parallels, and arguable disanalogies between geometry and logic, 
but to elucidate certain difficult observations about logic, which we need to raise 
even at the preliminary level. The moral of the story is that a distinction can be 
drawn between Abstract or Pure Logic (understood as the mathematical examina-
tion of the relevant abstract objects) and Applied Logic (which is not “pure” in the 
sense defined but can be subjected to considerations or desiderata about the proper 
fit between the mathematical or formal system and the intended area of application.) 
For our current purposes, a bulk of what we examine is inevitably instigated by 
applicability considerations – with recurrent references to linguistic operations and 
the normative requirements of reasoning as encoded in linguistic operations. But 
when we turn to the exploration of properties of the formal systems (the formal 
languages and their specified grammars, the devices that are constructed and 
1  What Logic Studies

5
implemented for decision procedures, then we will be engaged in transactions that 
evoke the meaning of logic as the study of abstract objects. (Certainly, there is also 
a meaning of “logic” that denotes those abstract structures themselves rather than 
their study but it is trusted that the overall context makes it clear that we are inter-
ested in the study.)
Another technical and longstanding dispute has existed as to whether logic 
should be studying logical truths (a notion that has some initial intuitive appeal) or 
such relations, which involve truth and falsehood, as validity of arguments and con-
sistency or satisfiability. The final verdict may have emerged in support of the latter. 
Earlier in this section, we referred to the notion of logical consequence: there is 
sufficiently broad agreement that this is the proper notion for logic to study. Indeed, 
if one adopts the pluralist view according to which there is no universally and abso-
lutely correct logic, the plurality of abstract structures to be studied as multiple 
logics are variably and correspondingly, and adequately, characterized by their spe-
cific relations of logical consequence. In fact, there are non-standard logics – alter-
native logics to the standard logic – which lack logical truths (because they include 
a truth value whose assignment to the individual components of sentences results, 
given the definitions of the logical operations, in an overall value for the whole for-
mula, which is not a species of truth.) Nevertheless, such logics still have character-
istic logical consequence relations, and could not fail to have such relations if they 
are to be accepted as logical systems at all. The logical consequence relation obtains 
between what we call in everyday parlance the premises and the conclusion of an 
argument or proof. This is not a technically precise definition but only a preliminary 
stab at appealing to basic intuitions and practices. In the technical sense, the prem-
ises constitute sentences that are members of sets (more precisely, multisets because 
repetition or multiple instances of a sentence are allowed and can be eliminated by 
specific rules;) the conclusion is usually one sentence but it can also be a set of sen-
tences. The key notion to note is this: the relation that we call logical consequence 
is about preservation or transmission of truth between or from the premises and the 
conclusion. As we will be repeating ad nauseam, this relation obtains (and, consider 
the parallel notion of validity of a deductive argument) if and only if: given that all 
premises are true, it is logically impossible for the conclusion to be false (or for all 
the conclusions to be false in case of multiple consequences.) We see that a variety 
of logical concepts are involved in this: logical possibility and impossibility, truth as 
a logical value to which meaningful sentences refer, and the decisive notion of pres-
ervation of truth in the sense that, as it is often put in introductory texts, the truth of 
the premises logically ensures or necessitates the truth of the conclusion in a valid 
deductive argument. We will devote systematic and, as needed, repeated attention to 
all these elements, beginning with intuitive presentations and progressively ascend-
ing to more technical and precise constructions.
The present text is technical and aims to introduce Logic as the systematic 
endeavor of studying the subject to a beginner. It is difficult to attain a poised and 
stable balance between explaining too much and not explaining enough when pre-
senting the subject  – while aiming for pedagogical effectiveness as well as for 
required accuracy and completeness. In this text, we tolerate repetitions – motivated 
1  What Logic Studies

6
by a method we may use to facilitate learning – even though this is to be frowned 
upon in many obvious ways: but our objective is pedagogical and repetition serves 
a purpose in enabling and consolidating learning.
Something else that we should point out, and then bracket it, is this: we could 
think of our tasks as consisting in learning how to systematically manipulate sym-
bolic resources; we can also think of making our symbolic systems be “interpreted” 
or equipped with a discourse about meaningful things that are being talked about. 
The first approach we can call syntactical and we can also call it procedural or 
proof-theoretical. Both approaches take positions as to how logical meaning is 
defined but the syntactical approaches posit that the proper understanding of the 
subject consists in tracing the manner in which symbolic resources are permissibly 
managed. The nature of the game is to move symbolic items around and to attain 
certain objectives specified by the setup of the game. The second approach we men-
tioned can be called semantic because, in that approach, we are able to talk about 
things (although those things are also abstract) in such a way that an attached narra-
tive we have available allows us to evaluate appropriate entities as true or false. In 
the semantic approach, we deploy truth values that we take as the proper logical 
meanings and as the abstract items to which meaningful sentences refer. There is no 
point in this text arguing as to which approach gets it “right.” Fortunately, in the case 
of the standard logic of sentences, the two approaches harmonize so that the results 
we can accomplish in the one type of game are provably guaranteed to match the 
parallel results attained by using the other method. There are profound philosophic 
issues about this but we will not pursue those in this text.
To gain a firmer grip on this distinction, think of the following: if we think that 
our study of logic will be about meanings of sentences – as we have in the lan-
guage – which are true or false, this is the semantic approach. This is usually the 
impression gained through introductory books. Interestingly, however, there is 
ineluctably, and beneficially, a unit in introductory textbooks that is called usually 
“natural deduction” or “proof method” or something along those lines – and this fits 
into the syntactic approach which is like a game that pushes symbols around in 
accordance with rules. Accordingly, when we learn truth tables in following chap-
ters, we are in the territory of the semantic approach and when we study a variety of 
proof methods we are in the realm of the proof-theoretic approach. In the remarks 
that follow, we do not dwell on this distinction; but it should be understood that 
when words like “true” and “false” are used, that is a semantic approach – and, 
intuitively, true and false presuppose speaking of certain things rather than thinking 
that our game is moving symbols around (although, of course, we do push symbols 
around in both approaches.) On the other hand, a proof-theoretic approach should 
not speak of true and false but, instead, it uses such concepts as “given premises” 
and “assumed premises”, line-derivation, and rule-application; instead of validity 
(which, as we will find out, is defined by using the concepts of true and false and is, 
therefore, a semantic category), the proof-theoretic approach speaks of derivability; 
logical truths are on the semantic side while the proof-theoretic side has to speak of 
theses or theorems.
1  What Logic Studies

7
The logical characteristics  – studied by logic and characterizing logical sys-
tems – include validity of argument forms, consistency of collections of sentences, 
and the logical status of the meanings of meaningful sentences. There are deep 
underlying connections running through these concepts. The logical status of a sen-
tence (more properly, the meaning expressed by a sentence that can be correctly 
used in making an assertion) can be one of three kinds: a logical truth, a logical 
falsehood, or neither (and we will have special terms to use in each case). As you 
progress in your studies, you should at some point be able to explain how validity 
of argument forms is related to consistency/inconsistency and to the status of being 
a logical truth. These logical properties are abstract but assessing them is a practical 
and essential matter, urgent for the assessment of everyday claims and arguments; it 
is crucial for correct reasoning. Without studying Logic in a sustained and system-
atic way, we lack the requisite trained skills for evaluating whether the reasoning we 
are presented with – or our own reasoning – is correct or not. It can be shown experi-
mentally that positive accomplishments in learning and erudite expertise do not 
fortify us against logical error.
The study of Logic is a fundamental task – in the sense also that it is, not only 
significant, but foundational. By this we mean that one should study Logic regard-
less of what subject one may be an expert on: when experts draw conclusions, even 
if it is within their own field of expertise, they are arriving at a sentence – the con-
clusion – that is new and not already known; this new sentence, the derived conclu-
sion, is presumably to be accepted as true on the basis of the premises or assumptions 
that have been used. If it were otherwise, if this sentence were considered known 
and established in the field of expertise, then we would not need to obtain this sen-
tence as a conclusion of a proof (argument). But, if this is a new sentence, even to 
the expert, then it is not known or ensured by the available expertise; the expert is 
now to succeed or fail as the inference to the conclusion is “correct” or not – and 
this is the task of Logic to evaluate. Thus, the expert, surprisingly perhaps, is acting 
as an agent who makes logical inferences – not covered by the expertise – and 
knowledge and skills honed within the field of expertise do not ensure that the 
expert will also prove to be an adept logician. It is clear, then, that in the foundations 
of all learning we find Logic. One would expect that the study of Logic should be 
mandated and universal, given the high stakes, but this is not the case. Even though 
the study of Logic looms as an indispensable task that cannot be replaced by some 
other training, the difficulties can also be formidable. It was relatively late in the 
western tradition, when Aristotle emerged as the originator of the systematic study 
of Logic: this rather ominous delay alerts us to the fact that there is something elu-
sive and even counterintuitive lurking in this subject – especially in the case of the 
species of reasoning known as deductive.
Validity, consistency and logical truth-falsehood are terms we will need to study 
systematically. In terms of common sense, we can think of an argument as a struc-
tured proof, with a conclusion inferred from the premises or assumptions that are 
given. Attention is needed because the term “argument” is technical and not to be 
confused in its meaning with other senses of the word “argument”: the logician’s 
argument is not an act, it is not a contest or a fight or a disputation: it is an abstract 
1  What Logic Studies

8
item, a proof that has a completed structure which has to include at least one prem-
ise and one conclusion. It is unusual to examine argument structures with more than 
one conclusion – but it should be pointed out that there is no technical difficulty in 
doing that. An initial difficulty in the study of deductive logic consists in this: try to 
think of an argument as an instance in which a pattern is exemplified (or instanti-
ated) in the way in which enforcement of the rule “three-strikes and you are out” is 
always a particular and concrete exemplification of this rule of baseball (with the 
rule itself never concretely available to us, and with only its specific enforcement-­
applications available to us.) The correctness of a deductive argument (called tech-
nically “validity”) depends completely, sufficiently, and exhaustively on this 
instantiated pattern, which logicians are wont to call “argument form.” The surprise 
is that the content of what is being talked about in the argument plays role in the 
assessment of the validity. This is an immediate and early difficulty that we should 
be ready to confront.
When we make arguments in language, those are understood to be arguments in 
accordance with the definition we have given. Strictly speaking, in Symbolic or 
Formal Logic, we are not directly examining everyday arguments delivered by lin-
guistic means. The catch is this: if arguments in language are deductive (with the 
same definition of deductive argument applied always), then the logical validity of 
this argument is a matter of whether this argument has a valid argument form or 
pattern. Our study of logic attends to the study of those patterns. We are fortunate in 
modern times to have mathematical instruments available to us – something that 
was denied to Aristotle and to subsequent generations of logicians in the western 
tradition. It is not our present concern to go over historical details about what revo-
lutionary developments in Mathematics made this possible. From a practical point 
of view, the speaker or writer who has made a deductive argument is – whether she 
or he knows it or not – playing a game over which the rules of deductive reasoning 
have binding force; assessment of the “correctness” or validity of the argument 
according to those rules is an objective matter. Whether a given argument is invalid – 
because it has an invalid pattern, an invalid argument form – is a matter of normative 
significance: an invalid argument is bad, wrong, incorrect, to be rejected – not in a 
moral sense of “bad”, of course, but it is still normative in the sense that we are deal-
ing with binding and correcting valuations and orders like “you should not accept.” 
It is comforting to know that subjective views or cultural variations are not grounds 
for raising objections or imposing conditions on logical assessment: it is better to 
think of our activity as similar to the linguistic activity that involves judgments and 
assessments of correct-incorrect grammar. Of course, languages vary across the 
world, but to show that the logic is also different would require a specific examina-
tion of what forms are valid and it is not something to accept instantly. Even if logic 
were to vary across different linguistic groups (which we can put aside), still, within 
each relevant community the logic would be compelling, ordering, and not a matter 
that is left to subjective evaluation. I can be rightly corrected for wrong grammar 
and the normative aspect is that I should, obviously, also enforce correct grammar. 
There are objective and binding (“ordering”) rules that constrain and guide and 
whose violations constitute corrigible (correctable) offenses. Notice that, if some 
1  What Logic Studies

9
other idiom or local variation of the language encloses a different grammar, I still 
cannot plead that it is all subjective – it is not, and, in that other localized context 
where the grammar is different, I will be corrected and rightly so. What happens 
with an invalid argument is somewhat like the example of the correct grammar. But 
it is vital to realize – without receiving a proof at this point – that the grammar of a 
language does not help us see how the logic works. Even if trained thoroughly in the 
grammatical details, we cannot depend on the grammar to determine validity of an 
argument. Thus, once again, we reach the ineluctable realization that logic needs to 
be studied as a distinct subject.
In some languages, the premises of an argument are called expressly “assump-
tions”. A point to notice and keep in mind is that an argument does not guarantee 
that the premises are true. Nor does the logical correctness – validity – of a deduc-
tive argument depend on whether the premises are actually true. This seems surpris-
ing to beginning students. This is also related to the other point we will have to 
grasp: in deductive logic, argument validity is not a matter of content or of what is 
being talked about. It is a matter of form. Inductive logic – which we do not study 
in the present text – does not have this dependence on logical pattern or form; in 
Inductive Logic, content evaluation from a logical point of view arises as a relevant 
evaluative issue but in Deductive Logic, think of what we do in evaluating argu-
ments as a matter of assessing a relation (the relation or connection between all the 
premises taken together and the conclusion) regardless of the content. For instance, 
Jill is the daughter of Mary and Jackie is the daughter of Jill: our attention is focused 
now on the relation “daughter-of.” If we go on and replace the used names in the 
above examples with other names, claiming always the relation of daughter-of, we 
can proceed – but the variability of the content depending on what names are used, 
whom we are talking about, is not our business insofar as we are strictly interested 
in the relation daughter-of. For instance, we might notice that, as a relation, daugh-
ter-­of is not transitive: the daughter of the daughter of x is not the daughter of x (she 
is the grand-daughter of x!) This is important for us in investigating the relation we 
denote by “daughter-of.” But content (whose daughter we are talking about) is not 
important in the study of logic. The content does not affect the logical characteris-
tics of the relation (like transitivity, in the preceding example.)
Let us return to the concept of argument and, bearing the above in mind, let us 
think of an argument as a relation between: a) the premises (all of them taken 
together conjunctively – connected by “and”, each premise to the next and to the 
next all the way to the end); and b) the conclusion. The claim in presenting an argu-
ment is that this relation works. The technical term in assessing the premises-­
conclusion relation as logically correct in deductive reasoning is validity. A 
deductive argument is valid if and only if it has a valid argument-form (a pattern, 
structure, with more to say about this.) An argument form is valid if and only if: 
if all the premises are true, then the conclusion is necessarily true. (This is the 
case of a deductive argument; for an inductive argument, the connection between 
premises and conclusions is a matter of probability – and, thus, a matter of relative 
strength and not a matter of logically guaranteeing that the conclusion is true if the 
premises are true. But in that case too, of inductive arguments, the object of our 
1  What Logic Studies

10
inquiry is again a relation between all the premises taken together and the conclu-
sion. This is key!) The deductive argument form – exemplified by a given argu-
ment – is valid if and only if: the truth of the premises guarantees the truth of the 
conclusion (notice the relation between premises and conclusion and notice the role 
played by what we may call “truth preservation.”) We can say this in other ways, 
and we will have opportunities to continue presenting this central concept: in a 
valid argument form, it is logically impossible to have all the premises true and 
the conclusion false. We need to alert ourselves that, in the definition of validity, we 
are using some concepts that are themselves inherently difficult to grasp: we speak 
of if-then – if the premises are all true, then the conclusion is logically guaranteed 
to be true in a valid argument form. We also speak of “logical necessity” and “logi-
cal possibility:” it is logically necessary in a valid argument, and only in a valid 
argument, that, if the premises are true then the conclusion is necessarily true. It 
is logically impossible in a valid argument that we can have all the premises true 
but (and) a false conclusion. Sometimes, it can be put as follows: in a valid argu-
ment, if the premises are true, then the conclusion is necessarily true. This, however, 
is not a proper way of putting it because the conclusion of a valid deductive argu-
ment does not have to be a logical truth (a logically necessarily true sentence.) 
Sentences that are logically indeterminate or, as we say, logically contingent (they 
are possibly true and, in other contexts, possibly false), may well be conclusions of 
valid deductive arguments.
A last preliminary point to make is this. Occasionally, a definition that is given of 
the concept of deductive argument is: an argument whose premises provide absolute 
(logically necessary) support for the conclusion. This, however, prevents drawing a 
distinction between valid and invalid deductive arguments. You will notice that this 
last definition, given about deductive arguments, is the same as the definition we 
gave earlier of valid deductive arguments. If we adopt this as the definition of a 
deductive argument as such, then we accept that all deductive arguments are valid 
and that invalid arguments are not properly to be considered as arguments at all. 
This is an unorthodox view and we bypass it after we have briefly mentioned it.
The concept of argument is related to the concept of implication (and it is an 
implication we state when we state an “if-then” sentence, which can be called an 
implicative sentence.) The untrained person faces difficulties when it comes to 
grasping the meaning of and assessing “if-then” sentences. The notion of inference 
studied by Logic – logical inference – is not psychological: we are not interested in 
subjective actions or impressions pertaining to drawing inferences from given 
assumptions. It is an objective matter as to whether an inference is correct or incor-
rect. Similarly, for assessing whether a collection of sentences – a theory, we may 
call it – is consistent or holds together logically, we need to know if it is logically 
possible for all the given sentences (and those that can be correctly inferred from the 
given sentences) to be true together. Lastly, whether a sentence expresses a logical 
truth or a logical falsehood – or neither – is a matter that transcends our daily intu-
itions and requires systematic inquiry to learn. Surveying again the terms we have 
already brought up so far: try to appreciate the kind of difficulty we will be facing. 
We have mentioned terms that are not familiar from everyday discourse. We have 
1  What Logic Studies

11
also intimated that something like the validity or correctness of a proof or com-
pleted inference is actually a relation – between given premises/assumptions and the 
conclusion that is claimed to be following form those premises. A concept like 
“relation” is also one that is not immediately transparent to our intuitions. Also, 
speaking of consistency as the logical possibility that all given sentences are true 
together – we need to grasp in this case another concept which is rather difficult and 
not immediately accessible to our common sense (the concept of “logical possibil-
ity.”) Lastly, we have also intimated already that logical truth, and logical falsehood, 
are concepts that cannot be understood based on our raw abilities to use “true” and 
“false” in everyday conversations.
We can think of a language like English as having a logic, or many logics per-
haps, embedded in it; in the same way that there is a structured and regulative gram-
mar for every language, it is also the case that there is a logical grammar. In older 
times, it was said that there is something called Reason and this is what Logic ulti-
mately investigates; or, perhaps, there is a certain way in which the mind works and 
logic has that subject as its subject matter. For even more ancient thinkers, like the 
father of logic, Aristotle, there is an ultimate foundation in the way nature is consti-
tuted, which determines how logic itself works. Aristotle would state logical laws 
fist by referring to how things are and can possibly be, by nature, but he would then 
proceed to provide additional formulations of the logical law. Aristotle understood 
something about deductive reasoning, which is one of the causes of difficulty in a 
course in Logic. Aristotle’s references to nature can be omitted without harm to his 
logical studies. The updated version of what the objects studied by logic are talks 
about how language itself works. Any “natural” language has many words and 
expressions – which we can call logic-words – whose meanings determine the logic 
of the language. Some students of logic think that the deeper foundation of those 
meanings lies in the logical rules that allow us to accept a logic-word in a sentence 
and also to remove it from a sentence. Whether the buck stops with the meanings of 
words or with the rules that govern their usage in language, this whole issue is 
clearly an objective matter. There is no room here for declamations to the effect that 
it “depends” on what someone thinks subjectively. The parallelism to linguistic 
grammar helps to bring this out. In the same way a language has a grammar, it also 
has a logical grammar. The two do not cooperate, so to speak: the linguistic gram-
mar does not necessarily help us see clearly what the logical grammar is. If you 
reflect on this, you can appreciate, again, how urgent it is to study Logic. But is it is 
hard subject; you should be prepared for that.
It would be surprising to proponents of older philosophic schools that language 
plays such a role in determining the logic; this is a subject of interest to philosophy 
and philosophy of logic and we don’t need to dwell on it longer. What you should 
pay attention to is that logic is an objective matter – and you can draw the compari-
son to grammar to see that. There is something normative – something that gives us 
orders and regulates how we ought to think – in logic. In the same way that it is 
wrong, incorrect, to violate the grammar – this ought to be trivially obvious – it is 
also objectively wrong to commit logical errors. Thus, it does not depend on opinion 
if the logic of an argument is correct or a theory is free of logical pathologies like 
1  What Logic Studies

12
inconsistency. We cannot say that different people have different logics – this is 
nonsensical unless the word “logic” is used in some other sense but we are not inter-
ested in that.
Logic is not an easy subject to study. Evolutionary advantages have been con-
ferred on us all over long biological millennia but those advantages do not include 
facility to study logic. Apparently, our biological ancestors benefited from a propen-
sity toward fight and flight, for instance, but they did not survive and reproduce 
thanks to being able to make logical inferences with facility. Fleeing when perceiv-
ing danger might have been unnecessary in most cases – an inference might have 
shown that there is no need to flee – but the flight strategy worked also for those 
fateful and crucial situations in which survival was at stake. Thus, we are commonly 
prone to anxiety conditions but logic is a hard subject for the considerable majority 
of students.
We will not be studying language in this course; we will be constructing artificial 
or formal languages and we will be working with them. Of course, the motivation 
may well be to fathom the logic of the language but this is an incidental matter: the 
formal systems we construct are what we study and if such systems “get it right” 
what the logic of language is, then that is an extra bonus. It is like geometry: 
Einstein’s physics uses a different geometry, not the classical Euclidean one; this 
does not undermine the Euclidean geometry itself but only shows that the geometry 
of our universe is not Euclidean after all. Similarly, if our formal system does not 
match the logic or logics of our language, that is a limitation on the usefulness or 
applicability of our formal system but not an invalidation of this system. As you will 
find out, we will be translating English sentences into our formal languages and we 
will be working with those translations toward determining logical characteristics. 
It is a sound assumption that significant fragments of language have logics that are 
captured by the formal systems we study in this course. The benefit, then, consists 
in having tools – apparatus – that allows us to figure out if certain logical character-
istics obtain or not. We will see now what these characteristics are – which also 
shows us what subjects are studied by Logic. We should make it clear that the appli-
cation of formal techniques is possible only for deductive reasoning and this is our 
demarcated territory in this text.
As we embark on our exploration of our subject, let us make clear, in a prelimi-
nary way, how we are using certain terms. We speak of sentences a lot in this text. 
By “sentence” we mean, to be precise, the meaning that is expressed by a grammati-
cally articulated sentence of a language like English. Notice that in the preceding … 
sentence I wrote, the word “sentence” occurs twice with two different meanings. 
Our sense of “sentence” is different from that of the grammatical definition of “sen-
tence.” To simplify things, let us focus on the word “meaning”, of which we should 
have some intuitive notion to begin with. The sentences of logic are the meanings. 
Much fuss is made, philosophically, about the status of such meanings: what kinds 
of things are we talking about? Do such things exist independently of being thought? 
We are not interested in such issues, given our present interests. We need to clarify, 
though, that “meaning” is understood here to be the kind of thing – whatever thing 
it is  – that is capable of being true or false. We say that meanings have truth 
1  What Logic Studies

13
values – true or false. Nothing else has truth value. Thus, since we are using the 
word “sentence” indifferently and to stand for meaning, it is correct to say that what 
we are talking about as sentences are the only things that can be true or false. It 
would be more precise to distinguish the grammatically articulated sentences from 
the meanings. We simplify by ignoring this distinction – but it should be understood 
that there is such a distinction. You can think of this in the following way: to express 
the same meaning, we can use many different written or spoken, grammatically cor-
rect, sentences. We can even translate a sentence to another language. The original 
sentence and the one that translates that original sentence are both expressing the 
same meaning: one meaning, two sentences. Accordingly, we can see that sentences 
and meanings are not the same thing!
Our sentences are true or false; they are the only things we admit as capable of 
being true or false; they have to be either true or false; they cannot fail to be true or 
false; and they cannot be both true and false. Strictly, what was just said applies to 
the meanings (while the sentences ought to be regarded as being grammatically cor-
rect or incorrect.) Our decision to speak of sentences in a broad way blurs this dis-
tinction. It is unfortunate that we need to go over this ground – creating what comes 
across as confusion in the process – but there are certain serious philosophic dis-
putes and issues in the background. For our purposes here, let it be stressed that our 
sentences are capable of being true or false and this is the key notion we need to 
retain. A few other details should be added. Our sentences are considered to have 
packed in them sufficient content – not obvious to the naked eye, so to speak – that 
ensures that whatever truth value (true or false) they take, it is not variable! We will 
use an example to explicate this.
I am driving to work.
This apparent sentence has the ambiguous pronoun in it, “I,” and also its verb-­
ending “-ing” alludes to a temporal context in which this is supposed to be happen-
ing. If different persons uttered this sentence, it can be true in some cases and false 
in other cases. Depending on what time contexts, and place-context and other pos-
sible contextual elements, this could be a true or a false sentence. But we cannot 
tolerate such variability depending on context. We have to have sentences whose 
meanings are settled: whether true or false, it doesn’t matter in this case, but we 
have to insist on our sentence units not having truth values (true or false) which are 
variable depending on how we specify who utters the sentence or contextual cir-
cumstances surrounding such utterance. Thus, our sentences are like the following – 
to continue with the same example as above:
I, −---(name) --- drive to work ---at such and such a time and date ----…
We leave open spaces also to indicate that every possible contextual or other vari-
able circumstances are specified precisely. Our sentences are either true or false: it 
is not true in some contexts and false in other contexts. We need to undertake all 
this, complicated-sounding, ado for technical reasons. This is how our formal tools, 
given how they are constructed, can be used properly.
Every meaningful sentence of a language like English can be used to make an 
assertion. What is asserted is the meaning of the sentence, which we may call “state-
ment.” An open-ended number of sentences can be used to assert the same meaning 
1  What Logic Studies

14
or express the same statement. Conversely, a meaning or statement can be expressed 
by any one of an open-ended number of sentences all of which can be used to make 
the same meaning. Think of translating a sentence into a foreign language: the ini-
tial sentence and its translation convey or make or assert the same meaning even 
though they are sentences of different languages. The meaning is separate from the 
sentence; the sentence is used to express the meaning. The sentence can be gram-
matically correct and yet fail to assert a meaning – it can be meaningless, in other 
words. From the standpoint of the basic logic of statements, a meaning can be true 
or false; nothing else can be true or false. Every statement can be true or false; it 
cannot be both true and false in the same context of use (it cannot be true and false, 
since we have a fixed context as we have seen); it has to be either true or false (it 
cannot be true neither true nor false insofar as it is an assertable meaning.)
1.1  General Characteristics of Logic
There are controversies surrounding tendentious claims about what characterizes 
logic but the list of overall candidate attributes is not long. There is even a view that 
argues against the exceptionalist status of logic that emerges from the following 
comments. For our current purposes, what follows is merely a compendious presen-
tation of certain characteristics that have been commonly claimed for logic. By 
“logic” we are referring not to the enterprise of studying the subject but to the sub-
ject itself.
	 1.	 Universality: Regardless of linguistic application, regardless of what subject is 
being talked about, regardless of what discipline is pursued, the logic is the 
same. An argument cannot be valid when used in mathematics while an argu-
ment with the same logical form is invalid in literary criticism. It is not the case 
that there is one logic for one subject of discourse but another for some other 
area of studies or discourse. On the other hand, however, complications may 
arise under certain circumstances: for instance, one eligible approach to avoid-
ing an overly complicated presentation of Quantum Physics requires that we 
adopt an alternative, non-classical logic (a logic for which a certain distributive 
law does not hold): this seems to suggest that the subject matter may play a role 
in fixing the logic. It could be argued that the logic of Quantum Physics is non-­
classical, which, again, intimates a certain sense of dependence of logic on 
subject. Another challenge arises from a view that regards logic as dependent 
on natural language with the prospect arising of variable logics matching differ-
ent natural languages or fragments of languages. Added insult is raised by such 
challenges in that logic not only lacks universality, on such views but it is also 
ultimately an empirical and factually discoverable enterprise. Such views are at 
odds with the classical and standard view of what logic is, according to which 
logic is universal across languages and subjects as well as a priori or not empiri-
cally based (on which more follows.) Nevertheless, our focus for determining 
1  What Logic Studies

15
what logic is ought to exclude the motivation for selecting a formal logical 
system. If, for instance, a Quantum Logic is adopted, then it is that logic that 
should be thought of as being in force and this notion should be held in isolation 
from competing claims about different domains that may generate different 
selections of formal logical systems. Given this last remark, universality is 
weakened and preserved rather in a negative sense: whatever the logic is, it is 
absurd to claim that a competing logic also holds.
	 2.	 Topic-Neutrality: The validity of arguments, the definitions of the logic-words 
or connectives, and assessments of consistency of theories are independent 
entirely of the subject matter. For instance, all sentences of the pattern “X and 
Y” are true if the statements X and Y are both true regardless of what sentences 
are put in for X and Y, and, therefore, regardless of what the contents or specific 
subjects of those statements are. This characteristic overlaps with the preceding 
one as we characterized it above. We may confine universality to the claim that 
logic is the same across languages, so that it is actually presupposed for any 
meaningful linguistic system including the case of natural languages. In that 
case, topic neutrality can be seen as specifically the claim that the choice of 
subject matter can have no impact on, and indeed it presupposes, the universal 
logic that is at work in the production of meaning in all cases.
	 3.	 Precedence: Another characteristic of logic is that its study takes precedence to 
any project of reasoning or linguistic activity in the sense that it is presupposed 
as a check on the correctness of any meaningful linguistic or theoretical action. 
The restrictions imposed by logic, so that statements can be accepted as proven 
or views accepted as consistent, are prior to, and constrain, any generation of 
meaning. We can say that logic is pre-theoretical and also that, on this basis, it 
cannot be scientific: logic is not science but presupposed by science; but no sci-
ence can take precedence or be prior to all sciences and, therefore, logic is not 
a science on account of its characteristic of precedence. This view was advanced 
by Ludwig Wittgenstein in his Tractatus Logico-Philosophicus. As Aristotle 
observed in ancient times, students of all subjects ought to be first versed in 
logic which is, then, one of the foundational disciplines along with the study of 
reading and writing. The medieval curriculum of studies observed this founda-
tional pedagogical requirement in its imposition of an obligatory curriculum 
called “the trivium” (three subjects, consisting in reading, writing and logic.)
	 4.	 Normativity: Logic enforces standards of correctness which are binding and 
objective. For instance, an invalid argument is “incorrect”, as the intuitive 
notion has it, and this means that one should refrain from accepting, at least 
under the assumption that one is rational. More strongly, accepting an invalid 
argument as valid, to continue with the same example, would be wrong under 
any rational construction and its continuous acceptance would betoken not only 
irrationality but would also constitute an act that is absurd and cannot be 
defended.
	 5.	 Non-Self-Referentiality: Because logic is pre-theoretical, constraining any 
meaning-generating, a surprising corollary is that logic cannot speak about 
itself in any substantive way: logic cannot subject itself to revisions, for 
1.1  General Characteristics of Logic

16
instance, on pain of generating contradictions. This does not mean that we can-
not study logical systems in a metalanguage, so that we can canvass a whole 
array of structural characteristics of logical systems and even detect anomalies, 
which is precisely what metalogic does. The point, rather, is that the correctness 
of the logical rules we use in the metalanguage, as we investigate logical sys-
tems, is presupposed and, because of that, it is not open to revision by means of 
its own resources.
	 6.	 Truth-Preservativeness: The standard logic has two truth values, true and false. 
In a more general way, a logic has semantic values (which can be thought of as 
ways of being meaningful), as constructed semantically, and a distinction must 
be imposed on those values: the distinction is between so-called designated and 
non-designated value-types. For the standard logic, which has two values or is 
bivalent, the value we call true is the one that is designated. Because there is 
only one non-designated value, the false, this logic is elegantly symmetrical, 
and has a defined connective of negation that seems intuitively appealing: thus, 
if not true, a meaningful sentence has to be false and vice versa; if not valid, an 
argument has to be invalid and vice versa. There are no degrees admitted in the 
attributions of values. Characteristic logical properties, like validity, are defined 
to be preserving the designated value, which is the true in the case of the stan-
dard logic. This means that a valid argument form cannot possibly have any 
instances with all premises true and a false conclusion. In other words, the truth 
of the premises, stipulated as true, must be necessarily “preserved” by the con-
clusion or, to put it differently, if all the premises are true then the conclusion 
must necessarily be true. There are alternative views about what may be pre-
served from premises to conclusion so that the argument form is regarded as 
valid but the view of truth-preservation is the standard one. In terms of the rela-
tion of logical consequence: if all the sentences in the set of premises are true 
(taken conjunctively, or conjoined with “and”, so that the compound statement 
so produced is true), then the conclusion is true and this is a matter of logical 
necessity. The broader notion for logical consequence is preservation of desig-
nated value (with designated values being thought of as representing ways of 
being true) but for the standard bivalent logic, this amounts exactly to preserva-
tion of the truth value true.
	 7.	 Formality: It is an inexorable staple of textbook presentations that deductive 
logic is a matter of logical form. The sentence “it rains and it does not rain at 
such-and-such a place and at-such-and-such a time” is a contradiction because 
any sentence of the logical form “X and not-X”, with X as placeholder or vari-
able for any meaningful sentence, is false for any logically possible assignment 
of truth values to the ultimate individual components (the atomic sentences) of 
the compound sentence. Similarly, argument validity is a matter of logical form 
which is aptly called in that case argument form: arguments are valid/invalid if 
and only if they are instances (they instantiate or betoken) argument forms 
which are valid in the sense that they can have no instances with all premises 
true and a false conclusion. Presentation of any instance of an argument form 
with all premises true and a false conclusion, which is a called a ­counterexample 
1  What Logic Studies

17
to the proffered argument form, invalidates or shows or establishes invalidity 
for the argument form itself. The only fixed parts of logical forms – the parts 
that are not variables – are the logical components. The logical connectives 
themselves may be said to correspond to logic-words in the natural language. 
Aristotle had detected this profound and foundational characteristic of deduc-
tive logic, the dependence of logical characteristics on the pattern or form, and 
this may well account for his credentials as the originator of the systematic 
study of logic in the western tradition. The Greek word used by Aristotle means 
“shape” or “figure” and it is etymologically the ancestor of the technical term 
“schema” that is deployed when we speak of rules for derivations – understood 
as recipes to be followed for sanctioning transitions to new generated lines in 
derivations. The metaphysical status of such forms – what kinds of things we 
are dealing with – is rather vexed but we can disregard it and simply note that 
logical characteristics, in deductive logic, depend exclusively and exhaustively 
on logical form. Anything that does not depend on form is a non-logical char-
acteristic and it is regarded as such (for instance, the predicate symbols of pred-
icate logic are appropriately called sometimes “non-logical constants.”)
	 8.	 Triviality and Vacuity: Logical truths contain – and can contain - no information 
about the empirical realm of facts. The meanings of the logical words determine 
that a logical truth is necessarily true regardless of any empirical context. Such 
logic-words – represented through what we call logical connectives – do not 
have empirical referents: we can see readily that a logic-word like “not” cannot 
have anything in the world to refer to. Because of this lack of informational 
content, a logical truth, or a logical falsehood, cannot be used to differentiate or 
effectively describe any specific logically possible case or state of affairs. Such 
are necessarily true, or necessarily false, and, as such, they are true, or false, in 
every meaningfully conceivable or logically possible state of affairs. A surpris-
ing corollary, observed by Ludwig Wittgenstein in his celebrated Tractatus, is 
that logical formulas cannot be used properly to provide statements about how 
to apply rules in moving from one line to another line in a proof. This result was 
anticipated by the famous author Lewis Carroll who, in his article “What the 
Tortoise Said to Achilles,” noticed that an infinite regress would result if state-
ments sanctioning rules were themselves made lines of proofs (with every such 
line requiring an additional line that would sanction it.) Wittgenstein considered 
this strange fact about logic to be indicative of the constitutively symbolic char-
acter of logic: the enterprise of logic consists, deep down, in a game of moves 
applied to items (symbols in the formal enterprise of logic), which are governed 
by non-conventional but self-validating rules; as a game, logic is learned 
through playing. (The fertile use of game analogies was originated by 
Wittgenstein too but after he had completed his Tractatus, but we expropriate it 
anyway to make this point.)
	 9.	 Generality: Differing from the characteristic of universality, generality has to 
do not with transcending linguistic or disciplinary boundaries but with the sta-
bility of logical applications across the open-ended range of actions. Any token 
of a statement that asserts a logical truth is also a carrier for asserting a logical 
1.1  General Characteristics of Logic

18
truth, and so on indefinitely. No contextual considerations – including prag-
matic, empirical, motivated considerations – can have an effect on logical prop-
erties. A valid argument cannot cease to be valid because it would be preferable 
if it were not valid; nothing can count as a sufficient reason for claiming invalid-
ity for an argument that is valid.
	10.	 Logical Necessity: The characterization of modalities, like necessity and pos-
sibility, has been a significant task since the dawn of the study of logic. 
Metaphysical subtleties aside, deductive logical truths hold as a matter of logi-
cal necessity, as we may say. In every logically possible context logical truths 
are characterized by the semantic predicate of being true. Deductive proofs in 
which the conclusion is correctly derived from the given premises are, likewise, 
correct regardless of context. And the same applies for all logical properties. We 
may think of an open-ended array of the logically possible cases – understood 
semantically as completely and consistently describable states of affairs – and 
arranged in such a way that logically necessary truths in any one state of affairs 
are true in every state of affairs: this arrangement gives us a rough notion of 
what we mean by the claim that deductive logical properties are characteristi-
cally necessary – in the logical sense of necessity. Logically indeterminate sen-
tences, which are true in some and false in some other states, are the ones that 
could be used as labels, so to speak, to mark different states as such. The logical 
truths and logical falsehoods, on the other hand, cannot be so used. Reflecting 
on this, we observe, once again, that deductive logic is not an empirical affair – 
it cannot be made to correspond to informational inputs – and the characteristic 
of logical necessity of the logical attributes means that logical, meaning is 
defined and preserved regardless of empirical describable matters. On the other 
hand, this is as it ought to be: we could hardly consider a statement as logically 
necessary if its characterization as true or false were dependent on empirical or 
motivational factors.
	11.	 Non-Representationality: If we repair to the view that the logic is determined 
by the meanings of its logic-words or connectives (which is not immune to 
controversy but which will do for our present purposes), we may detect readily 
that such special words – like “not” and “and” and “at least one of a certain 
kind” – do not have and cannot have referents that we can become acquainted 
with in empirical reality. Nothing in the world corresponds to such words; if we 
tried to construct hieroglyphic-like, specifically designed symbols that are 
meant to present images of the things in the world, we would come to grief 
when we try to find what physical object it is that corresponds to a word like 
“not”. To be sure, we run into a similar issue with relations between things – 
how do we depict the relation of siblinghood, for instance, in addition to depict-
ing the related siblings? Indeed, the challenge of representationality for logical 
words cuts more deeply: unlike the relationships between things, the logic-­
words do not operate on objects or even on events. If that were the case, we 
would meet the old presumed conundrum about “negative facts” or perhaps 
“non-facts” that are facts and are presumably needed in order to account for 
sentences whose meaning is false: since “not” can reverse the truth value of a 
1  What Logic Studies

19
true sentence to false, we would need an even more convoluted and absurd 
ontology, allowing for the erasure of facts in addition to the alleged factive sta-
tus of non-facts that underlie falsehoods, to deal with such a matter. Ridding 
ourselves of such misleading and perplexing conceits, we may as well settle for 
the abstract character of the things on which logical connectives operate: such 
things are the truth values, true and false, themselves. Gottlob Frege, the 
German mathematician and originator of modern logic in some crucial respects, 
was the first to see this; although the maneuver – stipulating truth values as the 
referents of meanings – lacks initial intuitive appeal, it effectively preempts 
those hoary ancient philosophic perplexities and also fits neatly the widely 
accepted characterization of logic as a non-empirical endeavor.
	12.	 Non-Metaphysical: We accept that there is no need for speculation about kinds 
of objects to which the discipline of logic is addressed. When semantics is pro-
vided for logical systems, stipulations about the kinds of things that are being 
talked about are needed; in that case, the enterprise is not one of discovery or 
aiming to make defeasible claims about the world; indeed, what happens is to 
check if a semantics is available in the sense that we can provide a make-believe 
story that is free of inconsistency. Unlike Aristotle who considered the founda-
tion of logic to be metaphysical – grounded ultimately, and sanctioned, by the 
way the totality of things is structured and how it functions – the modern view 
is that it is a confusion of categories to pair logic with metaphysical inquiries.
	13.	 Incorrigibility or Lack of Empirical Foundation: Given that deductive logic is 
not empirically grounded, it is a remarkable characteristic of logic that it cannot 
be corrected: it is nonsensical to anticipate that perhaps what logic prescribes 
could, after all, turn out not to be the case.
	14.	 Perspicuity, Ambiguity and Vagueness: When we construct formal systems for 
the study of logic, we ensure that the symbolic resources we use, equipped with 
a recursive and systematic grammar, can only be used properly in ways that 
render all the relevant properties perspicuous (upon proper examination) and 
preclude emergence of ambiguity or vagueness: ambiguity arises when more 
than one interpretations are plausibly available to the competent practitioner; 
the grammatical arrangements and demarcation of the formal language prevent 
this from ever occurring. Ambiguous symbolic expressions have to be consid-
ered as nonsensical – not amenable to eking out meaning from them. Vagueness 
arises when the boundaries of inclusion of an object within a category are pen-
umbral: if there is a specifiable degree to which any acceptable object has the 
categorial characteristic, then we have vagueness. Concepts may indeed be 
vague, although it would be far-fetched to consider every concept as being 
vague. Although there are so-called “fuzzy logics” for the analysis of vague 
notions, the standard logic is conditioned by the foundational acceptance that 
inclusion is not vague. This means that the standard logic, as we will have 
opportunities to discover, draws significantly on the classical theory of sets, 
which is “sharp” or “crisp” and not vague or fuzzy; this means that for any item, 
it can be determined whether it is a member of a given set or not absolutely 
(either it is or it is not) and not as a matter of degree on the interval [0, 1].
1.1  General Characteristics of Logic

20
	15.	 Non-Psychological: Logic is emphatically not a subjective matter or a matter of 
opinion. The parallel case of linguistic meanings can be deployed to show how 
this is the case. If words had subjectively attached meanings, the medium of 
language could not serve as a mode of communication; but it does serve this 
purpose, and so it follows that the meanings of words are like currency bills 
whose denominations are to be considered as settled so that they can be used 
meaningfully and effectively in transaction. But logic is not psychological in a 
broader sense: logic is not a matter of mental generation that is specific or con-
fined perhaps to a community or even a species: the point is, rather, that any 
species (aliens and what not) would have to have logic if the species has a mind 
that is capable of reasoning.
	16.	 Aprioricity: This is an epistemic category – about knowing and believing and 
correctly believing – but it is regarded commonly as a deep characteristic of 
logic: the truth of a sentence is known a priori if it is not provided and cannot 
be corrected (is not corrigible) by any empirical arrangements or discoveries. It 
is considered that the whole of mathematics is known a priori. Witnessing a 
third item of the same kind time and again when two items of the same kind are 
put together would not instruct us to revise our knowledge about one and one 
adding up to two instead of to three; the mathematical belief that one plus one 
add up to two is empirically incorrigible. Similarly, logic is considered to be a 
priori. The match between aprioricity and logical necessity, however, can be 
challenged: it can be proven, by using what seem to be unobjectionable logical 
laws, that any two names that refer to the same object do so as a matter of logi-
cal necessity – in other words, identity is logically strong: nevertheless, that this 
is a matter of co-reference may be discovered historically (and, therefore, is not 
a priori) as the case has been with the names “morning star” and “evening star” 
which were traditionally taken as referring to distinct celestial objects but it 
turned out that the presumed objects were actually one and the same, the planet 
Venus. (On the side of the apriori, the German philosopher Immanuel Kant had 
argued famously that there are truths that are not logically necessary but are, 
nevertheless, known a priori. We may also think of the statement “I exist” 
which, uttered in the first person, is surely known a priori but this is not a logi-
cally necessary statement.)
	17.	 Non-circular: We will find that we provide recursive definitions of logical con-
nectives, like for instance the one that corresponds to the linguistic logic term 
“and” – by seemingly presupposing that we already know the meaning of “and,” 
which is what we are defining. This sounds like an embarrassingly defective 
definitional practice: it seems that the definition is circular. For instance, we 
may define the logical connective symbol for conjunction (assuming for now 
that the symbol is “^”) as: “p ^ q” is true if and only p is true and q is true. But 
“and” appears in the definiendum as well as in the definiens of the definition. 
And yet, we have not run into circularity. We can use a metaphor to explain how 
this works. Similar metaphors are found in the history of modern logic, used by 
such luminaries as Gottlob Frege and Hans Reichenbach. Consider how we 
may construct a precise instrument for microscopic examination: we “see” 
1  What Logic Studies

21
­precisely the characteristics that are visible in the smaller scale; although we 
presuppose “seeing” as an activity, the “seeing” we are constructing is specifi-
cally attuned to bringing out with systematic precision the elements we are 
interested in. Differences recorded in the broadly accessible target make impacts 
on the specifically addressed area within which our vision is trained by means 
of the calibrated instruments. Although metaphors are tricky, and should not be 
accepted in the stead of definitions, our tentative metaphor given above tries to 
showcase why we are not wading into circularity when we define our connec-
tives, in spite of appearances to the contrary.
1.2  Logical Meaning, Logic-Words and Logical Form
Aristotle, who is considered the originator of the systematic study of Logic, thought 
that the nature of things consisting in the self-subsisting, organized and eternal 
totality of what exists, provides the ground or foundation for logic. Aristotle would 
define a logical law – for instance, that no meaningful sentence can be both true and 
false – in metaphysical terms: “nothing can both have and not have a certain prop-
erty in the same respects.” It sounds as if the philosopher speaks of how things work 
in nature – with “nature” taken in a broad sense, so as to include the totality of 
things, possibly including objects that are not physically concrete. Aristotle would 
also go on to add non-naturalistic versions of the logical laws but his opening pre-
sentation would be like the one given above – which, incidentally, is known as the 
logical law of non-contradiction. This naturalistic view seems wrong, though.
A similar error affected the erstwhile development of geometry: it was thought, 
rather intuitively but inappropriately as it turns out, that the postulates of geometry 
are justified by the physical geometry of the universe as it is. Nevertheless, the fact, 
if it so happened, that a physics with an entirely different type of geometry turned 
out to be the one we adopt would not mean that our initial geometry was defective 
in itself: it would only show, as an empirical matter, that the geometry we thought 
was the “natural” geometry is not the geometry of the universe after all. This does 
not prove that anything in the geometry is wrong: provided that we take the postu-
lates of the geometry to be self-justifying, every statement in the geometry is not 
simply true – but, rather, logically necessarily true. This shows that our geometry is 
never dependent on empirical, verifiable and falsifiable, considerations. Although 
there are marked differences between logic and geometry, the parallel can be used 
illustratively to make the point that it is a fundamental error to think that deductive 
logic is dependent for its verification on empirical considerations. Certainly, the 
purpose of investigating and systematizing the logic of a language may motivate the 
study of logic but the formal systems of logic are independent of linguistic facts; it 
may turn out that a given formal logic may fail to hit the mark with respect to how 
the logic or logics of a given linguistic idiom.
Another analogy we can draw is to a game. The rules of a game must be given so 
that the game can be played: the rules are not up for grabs. If we are to ask a referee, 
1.2  Logical Meaning, Logic-Words and Logical Form

22
we would not be asking for an opinion as to whether the rules are indeed the rules 
of the game; at most, we may ask for a list of the rules and certainly dispute factual 
elements in cases of applications of the rules. Even though the rules have been 
forged historically, we can ignore this background, for our present purposes, and 
consider the game as an independent and self-sustaining arrangement. In that sense, 
dependence on empirically verifiable developments, when it comes to ascertaining 
what the rules of the game are, would make it impossible to actually play the game: 
we couldn’t make sure what rules to apply as we would be tracking the develop-
ments that may affect the rules. This, however, discloses an additional problem: 
even as we track developments that might fix evolved rules for our game, we would 
still have to know what we would be able to count as acceptable rules of the game 
that emerge in the developmental process. This means that we cannot actually carry 
out this enterprise: we need to have the rules set so that these rules are insulated 
from empirical effects. This story illustrates quite appositely how logic is in a way 
predetermined, known independently of experience in the sense that it is incorrigi-
ble or cannot be corrected or set right by appealing to empirical factors.
It is also poignant that logic is prior to actual transactions in the sense that we 
have to be able to apply rules of reasoning already if we are to reason about what is 
acceptable and what is not. This point seems to apply broadly, including also the 
logics that are presented in natural languages. For instance, quite clearly, we cannot 
both accept and not accept some putative rule X: but this means that we are already 
committed to the logical law of non-contradiction – the one Aristotle was found to 
be presenting, albeit initially in a naturalistic formulation: we cannot accept both a 
rule X and a rule whose acceptance would logically entail that X is not applicable.
The view of meaning reflected in the preceding comments is called extensional-
ist: we take meaning to be determined by what the word refers to, or what the word 
has as its referent or denotatum. Such referents are considered, adequately for the 
examination of logical properties, to be the truth values of sentences: whether sen-
tences are true or false. We do not take a meaningful sentence to be receiving its 
meaning by reference to facts or states of affairs. If we adopted a view that takes 
meanings to be collections of facts, those would have to be the facts relative to 
which the sentence is true: we would have to make sure that all other facts are also 
included in the comprehensive collection of relevant states of affairs to ensure that 
there are no inconsistencies: this is like saying that a sentence would be given mean-
ing by means of all the scenes in a story, in which the sentence is included or asserted 
as true. It seems, then, that truth value (true-false) takes conceptual precedence over 
any way in which we would define meaning by using references to facts: this is 
because, consistency as a logical concept is defined by means of having the con-
cepts of true and false available to us in the first place.
The meaning or referent of a meaningful sentence is thus taken to be truth value 
(true or false.) This may seem like a narrow view: sentences that have different 
meanings based on content can be, nevertheless, true or false together in all possible 
contexts: we say that such sentences are mutually equivalent (or equipollent in 
older, now rather forgotten, terminology). Equivalence may be relative to context – 
for instance, it might be relative to actuality: “the earth has one moon” and “the 
1  What Logic Studies

23
earth’s sun is bright” are both true, and as such equivalent, but this is relative to the 
actual state of affairs and not because of any logical relations between the contents 
of the two sentences. A consistent alternative story is possible in which one of the 
two preceding sentences is true while the other is false. Logical relations, like equiv-
alence, should hold across all logically possible cases and not only contingently on 
what happens to be the actual case, which is after all only one logically possible 
case. But sentences like “a triangle has three angles” and “a rectangle has four 
angles” are equivalent in a stronger sense: no meaningful story can be presented in 
which either one of them is false. And yet, these sentences are not true by virtue of 
logic but only as a matter of how words like “triangle” and “angle” are defined. We 
do not expect that such words would be logic-words or that these words would mat-
ter when it comes to the determination of logic. But let us think, instead, of “it is not 
the case that it is raining and not raining” and “it is not the case that we have class 
and we do not have class.” Observe that these sentences must be true – not as a mat-
ter of psychological impression but as a matter of logic – and must be true, or neces-
sarily true, in every logically possible context. The relevant words, whose meaning 
fixes the truth value as true, are “not” and “and.” These sentences are necessarily 
logically equivalent – they have the same truth value (true) in every logically pos-
sible context. Once again, the content of the sentences does not matter: one is about 
raining and the other about having class. In a deeper sense, of course, they are not 
about such things but about the meanings of the logic-words – “and” and “not.” The 
rest – the content – simply does not matter.
Abstracting from content – disregarding content and treating only true and false 
as referents for meaning – may seem to be narrowing our scope impermissibly, but 
this is not the case. We should think of the maneuver that assigns truth values as the 
referents of meaningful sentences to be cutting through an infinite array of linguistic 
idioms in order to circumscribe only what all those idioms have in common as logi-
cal properties. Based on this, “a triangle has three angles” is logically independent 
from “a bachelor is unmarried” even though they are both true always in every logi-
cally possible story but what we discern as their logically significant relationship 
(that they are necessarily equivalent) is a matter simply of their both being true in 
every possible case. As we see again, true and false are the “players” in this game. 
These two sentences are necessarily true not because of logic-words but because of 
defined meanings of words like “triangle” and “angle,” which are not logic-words. 
We see, however, that their equivalence is, again, not a matter of context as they 
have to be true in every context. A story about a context – a world or state of affairs – 
in which these two sentences are not both true would be nonsensical.
Having adopted the view that logical meaning is a matter of extensionality, which 
means that meaning is fixed by reference, we have apparently rejected another plau-
sible way of settling the concept of meaning: according to such an alternative view, 
meaning can be considered to consist in sense or connotation as distinguished from 
reference which is also called denotation. The notion of sense is about the content 
of meaningful sentences rather than the more refined distillation that leaves us with 
truth value as the meaning of a sentence. An example, a famous one, highlighting 
the distinction between sense and reference is about names: the extensionalist view 
1.2  Logical Meaning, Logic-Words and Logical Form

24
also takes names to be defined by their referent. Thus, names are not characterized 
in their meanings by any properties of the thing that is named but only serve as 
conventional and arbitrary labels or tags for tracking an object: the meaning of the 
name is, accordingly, provided fully by the referent (the item that is labeled by the 
name.) The names “morning star” and “evening star” happen to refer to the same 
celestial object, Venus, but their linguistically generated senses as non-logical words 
were in variance from each other, with the “morning star” endowed with the sense 
“the first star visible in the morning” and “evening star” having the sense “the last 
star visible at night.” While the variable senses of the words give rise to, and explain, 
such phenomena as having wrong beliefs about stars and how such beliefs are cor-
rected over time, from a strictly logical point of view beliefs and even knowledge of 
non-logical subjects is not relevant to the determination of logical properties. Thus, 
it turns out that the logical identity of the two names, “morning star” and “evening 
star,” is a matter of logical necessity (since they have the same referent which is, of 
course, self-identical) even though the fact that they do have this same referent was 
discovered empirically: sense belongs to the realm of facts but denotation or refer-
ence has to do with logical properties (like identity understood as co-reference.) 
This is a neat framework; there are difficulties and complications lurking but we 
bypass them for our present introductory purposes. Having said all this, we should 
also point out that ascent to logics that investigate intensional notions – as distin-
guished from extensional notions – would be needed for taking into account context-­
sensitive shifts of meaning which seem to be required for transcending extensionality. 
These are controversial subjects, which we cannot delve into in detail in this text.
Importantly, we also abstract from context in fixing the logical meaning of a 
meaningful sentence: a meaningful sentence has a referent – a truth-value, true or 
false – which is not variably depending on any dynamic context (such as the passage 
of time or the change of place or the accrual of information or the shifting of indexi-
cal pointing to this or that item.) A clever trick that ensures this is to consider all 
elastic contexts as embedded in a conceptual (but not stated) continuation of the 
sentence: for instance, “Socrates is happy” is understood as “Socrates is happy and 
such-and-such a place and at such-and-such a time, etc.” where “etc.” is meant to 
encompass any conceivable dynamic context whose variable influence may have an 
impact on the truth value of the sentence. Notice that it does not matter whether the 
sentence is true or false but that its truth value, if indicated, is immutable. This strat-
egy – consisting in implicitly embedding notionally in the sentence what is known 
as the “ceteris paribus” (“all things being equal”) clause – ensures that we can con-
sistently take as the referent of a meaningful sentence its truth value (true or false, 
not both and not neither.) Whatever price we pay for this adjustment is something 
we will not bother about for now; on certain occasions, we will be able to comment 
on ramifications of this stipulation.
The meaning of a meaningful sentence is, strictly speaking, a separate thing from 
the carrier-sentence but it is not important for our purposes to inquire into what kind 
of thing this meaning of a meaningful sentence is. Aristotle would not appreciate 
this avowed indifference to metaphysical considerations and he would also insist on 
including in our logical studies something else we have deliberately excluded – the 
1  What Logic Studies

25
concept of the “truthmaker,” which refers to what it is that makes true sentences true 
(and, somewhat puzzlingly, what makes false sentences false by failing to be or 
occur.) But we are not interested in truthmaking conditions, as we have remarked 
rather emphatically, and we will find out that our systematic study can proceed 
completely and successfully without ever needing to undertake an examination of 
what makes true sentences true and what makes them false. This important observa-
tion goes together with another point we repeat often in this text: deductive logic is 
not at all related to empirical (factual, descriptive, etc.) issues about the actual 
world: it is all about logical structure or pattern of our schematic formulas and sym-
bolic arrangements – hence, it has nothing to do with whether statements make 
actually true or false sentences. Related to all this is the emphasis, which can be 
discerned in definitions of concepts, on logical necessity and logical possibility – 
and not on actuality as such. Unfortunately, logical-modal concepts like logical 
necessity and logical possibility can be recalcitrant to our untrained intuitions but 
we will need to overcome such difficulties cautiously and systematically.
We can agree with Aristotle that only meaningful sentences are properly avail-
able for laying-down-as-true or correctly asserting. Moreover, we set up our basic 
logic so that any meaningful sentence (more precisely, the meaning of the sentence) 
can have one of two semantic characterizations: true or false. But we also add that 
no meaningful sentence can be neither true nor false and no meaningful sentence 
can be both true and false. This move is, so to speak, Aristotelian but, unlike 
Aristotle, we do not claim that we have sanctioning by the way things are or by the 
way nature works. We may even say that this is an arbitrary move – we just lay 
foundations for a logic-game; we could have played a different game but the game 
we are playing is motivated by an interest in the study of the logic of languages like 
those people speak around the world. A simplified but direct way of saying this is: 
rather than start with nature, as Aristotle thought we ought to do, we begin with see-
ing logic as conventionally embedded in linguistic constructions. But, notice that 
we are not studying the logic of language but an instrument that may or may not 
work in applications. Aristotle could see this maneuver by being reminded of the 
Euclidean geometry, which he knew, but even then there is something that might be 
surprising for him in what follows: Euclidean geometry is its own internally con-
structed, perfectly complete and self-standing system regardless as to whether the 
geometry of our universe is or is not Euclidean – it turns out that it is not, in relativ-
istic physics, but this does not undermine the Euclidean geometry, it only estab-
lishes that there are limitations to its applicability.
In terms of logical status, a sentence can be characterized as one of the following 
(and, of course, we are talking not necessarily of simple sentences but also of com-
pound sentences that are made by simple sentences): a logical truth (or tautology), 
a logical falsehood (or contradiction) and a logical contingency (or logically inde-
terminate or logically indefinite sentence.) We are repeatedly examining these con-
cepts in this text – with the repetition serving learning objectives. We stipulate that 
a simple (single, atomic) sentence that we symbolize in our formal system cannot 
be a logical truth or logical falsehood. Of course, a sentence like “a triangle has 
three angles” has to count as true necessarily (although not logically necessarily, but 
1.2  Logical Meaning, Logic-Words and Logical Form

26
as so-called analytically true), but we would have to tinker with providing a special 
lexicon to allow our symbols to stand for different logical status; instead, our stipu-
lation – remember – is that any sentence can be true or false, not neither and not 
both, and we codify this and show it at the level of the ultimate atomic components 
of our symbolic expressions (formulas) that can be used to translate linguistically 
meaningful sentences.
But something else happens too: the sentence “a triangle has three angles” is, as 
we call it, analytic and true (with more to say on this in 1.4.) The meanings of the 
words in this sentence suffice to establish a fixed determination that the sentence is 
true. But these words, which matter and adequately allow determination of truth 
value (true or false) are not logic-words; they are non-logical words like “triangle” 
and “three” and “angle.” Instead, a sentence like “either it is raining or it is not rain-
ing” is logically necessarily true: the meanings of words that matter in this case to 
fix the truth value of this sentence as logically necessarily true are the logic-words 
“either-or” and “not.” It would be news to Aristotle that the logical characteristics 
we are studying are to be taken as ultimately based on what happen to be the speci-
fied definitions of special words, the logic-words like “not,” “and,” “either-or,” and 
other such words (but not all logic-words can be studied through sentential logic, as 
we will see.) In textbooks, the standard way of explaining how we draw such a dis-
tinction between the kind of sentence we called analytic but not logically true and 
the logically true sentence is by saying that we are dealing with logical forms in 
deductive logic: while the logical form of “either it is raining or it is not raining” is 
the form of a logical truth – “either X or not-X” for any sentence plugged in for the 
variable X – the sentence “a triangle has three angles” has the logical form X – and 
remember that we have postulated (properly, it turns out) that atomic sentences – 
symbolized so that they have the logical form “X”) can be possibly true and possi-
bly false (one or the other, not both, but not necessarily true or necessarily false.) 
The approach that uses “logical form” to make the case is different from the 
approach that traces this all ultimately to the meanings of logic-words: we can have 
the first without having the second. We do not enter into philosophic issues or 
details, given our given purposes. We continue with this theme in 1.4 but, for now, 
we may glance at some seminal points.
•	 “Either X or not-X” is the logical form of a tautology or logical truth.
◦◦
“X and not-X” is the logical form of a contradiction or logical falsehood.
◦◦
“If X, then X” is the logical form of a logical truth.
◦◦
“Only if X, then X” is the logical form of a logical truth.
◦◦
“X if and only if not-X” is the logical form of a logical falsehood.
◦◦
Etc…
▪▪
The negation of a logical form of a logical truth is a logical form of a logi-
cal falsehood – and the other way around.
•	 This means that any compound sentence that has the form “either X or not-X” is 
a logical truth. And the same for compound sentences that have the logical forms 
of logical truths or falsehoods – they are themselves, respectively, logical truths 
or logical falsehoods.
1  What Logic Studies

27
◦◦
If a logical form is not a logical truth or a logical falsehood, then it has to be 
logically indefinite or logically indeterminate (also called logically contin-
gent.) [For the sake of simplicity, we call now the logical forms themselves by 
the status – for instance, “logical truth” – instead of using the more cumber-
some expression “the logical form of a logical truth.”]
◦◦
There are exactly three possibilities for a logical form: logical truth form, 
logical falsehood form, logical contingency form.
▪▪
No logical form can be more than one of the above.
▪▪
Every logical form has to be one of the above.
▪▪
We can call the characterization of a form, as above, the logical status of 
the form.
▪▪
Any sentence that has (shows, exemplifies, instantiates) a logical form has 
the same logical status as the logical form it has.
▪▪
Every meaningful sentence has to have a logical form.
•	 Any two logical forms that have the same logical status have the same logi-
cal meaning: we can say that they are logically equivalent (we don’t use 
terms like “equal” or “identical” but “equivalent” which will be studied 
elaborately in subsequent sections. The key is what we mean by “logical 
meaning” – and this is something we dwell on extensively in this text.)
◦◦
A logical truth is a sentence that is logically necessarily true: it is a matter of 
logical form that this is the case (or, further, we trace this to the meanings of 
the logical words in the sentence, which are indicated in the form.)
◦◦
A sentence that has the logical form of a logical truth is logically necessarily 
true: This means, preliminarily, that for every logically possible way or com-
bination of making its component sentences true or false, in any combination 
whatsoever, the sentence is always true. (But, notice that “when” here is not a 
temporal matter: it is a matter of logical possibilities defined as assignments 
of true/false values to all the component sentences of a compound sentence.)
◦◦
A sentence that has the logical form of a logical false is logically necessarily 
false: This means, preliminarily, that for every logically possible way or com-
bination of making its component sentences true or false, in any combination 
whatsoever, the sentence is always false.
◦◦
A sentence that has the logical form of a logical contingency is logically pos-
sibly true and, for other assignments of true/false to its components, logically 
possibly false: This means, preliminarily, that there is at least one logically 
possible way or combination of making its component sentences true or false, 
for the compound sentence to be true; and there is at least one logically pos-
sible combination of making the components true/false so that the whole sen-
tence is made false. In any combination whatsoever, the sentence is always true.
▪▪
X and not-X – form of a logical contradiction
•	 make X true: True and not-True = True and False = False
•	 make X false: False and not-False = False and True = False
1.2  Logical Meaning, Logic-Words and Logical Form

28
•	 The above is an intuitive example. We depend on the meanings of 
“not” and “and:” “not” turns True to False and False to True; “and” 
sentences are True only if both connected components are True, and 
they are False in every other case. Make sure that you have absorbed 
these definitions in our example above.
•	 It turns out that, for every assignment of truth-values to the compo-
nents (here, one component, X), the compound sentence is False: 
hence, this form represents a logical falsehood or logical 
contradiction.
•	 The fixed words, and only the fixed words, in the logical form are the logic-­
words. The other symbols in the logical form are placeholders, hence variables, 
for plugging in any meaningful sentences.
◦◦
X and not -X
◦◦
Either X or not -X [“either-or” taken as one phrase – it is a grammatical 
	
accident that the “either” and the “or” are separated in linguistic notation. The 
same comment applies to the expression “if-then” of the subsequent example.]
◦◦
If  X, then  X
◦◦
The logical forms as we present them and talk about them are here are pre-
sented in a symbolically enhanced (but not formally constructed or system-
atic) metalanguage. We do not introduce symbols for the logic-words at this 
point, but we could also do that if we wanted. The formal language we will 
build subsequently will have its own symbols: it will be rigidly constructed 
and implemented, without offering such license as we seem to be taking 
within the metalanguage (and, of course, the metalanguage also includes 
English, or rather, some fragment of English in accordance with our discur-
sive needs.)
•	 A logical form should be thought of as a recipe or figure-like instruction-­
schematic for how to make instances of the form – which is done by plugging in 
any sentences in the places occupied by the variables.
1.2.1  Exercises
	 1.	 Plug in any meaningful English sentences for the variables (capital letters from 
{X, Y, Z, W}) in the given logical sentence-forms to generate instances of 
those forms.
	
a.	 If X, then not-X.
	
b.	 Unless X, then either Z or not-Z.
	
c.	 Neither X, nor Y.
	
d.	 If X and Y, then either not-Z or W.
	
e.	 It is not the case that X implies Y.
	
f.	 Only if X, Y or Z.
1  What Logic Studies

29
	
g.	 If it is the case that necessarily X or not-X, then it is the case that necessarily 
X or actually Y.
Does it matter what specific sentences we put in the variable places? Why or 
why not?
	 2.	 In the preceding exercise, circle the logic-words. Notice that the sentential logic 
we will be studying can “see” – has symbols and specified ways for managing – 
some but not all of these logic-words. Still, we can circle the logic-words in the 
preceding exercise. How can we do that?
	 3.	 We can mark the place in the represented logical form with some other metalin-
guistic symbol: for instance, we can use different types of lines-symbols com-
pounds (let’s say from {___, −--, ===, |||}). Return to exercise 1 and 
systematically use these lines symbols to express the forms. What do we mean 
by “systematic”? Why doesn’t it matter what symbols we use to mark the places 
of the variables in the logical form?
	 4.	 Are the circled words in the following sentences logic-words or not? (Some are 
and some are not. Which ones are and which ones are not logic-words?)
	
a.	 If  a triangle has three angles, then  a rectangle has four angles.
	
b.	 It is not  the case that a rectangle has two  angles.
	
c.	 It will always be the case  that a triangle has three angles.
	
d.	 It is not  the case that if  it rains then  it snows.
	
e.	 If  it is possible  that God exists , then  it is necessary  that God exists .
	
f.	 It is possible   that aliens exist , but  it is also possible  that they do not  exist .
	
g.	 Only if  it rains and  pours is the game cancelled.
	 5.	 The meanings of logic-words are defined by reference to true and false: for 
example, the meaning of “not” is: it reverses the truth value (true, false / T, F) 
of a sentence – if applied to a true sentence the result is a false sentence and if 
it is applied on a false sentence the result is a true sentence. The definition com-
prises the entire schedule (collection, agglomerate, nexus) of the cases/value-­
assignments: {T-F, F-T}. Can you tell what the meanings are of the following 
logic-words? Find the logic-words embedded in forms. They are, as we know 
by now, the fixed parts of the forms. For the binary logic-words (the ones that 
connect two sentences) the nexus of all possible combinations of truth-value 
assignments are: {TT, TF, FT, FF}. For instance, the meaning of “and” can be 
represented as follows: {TT=>T, TF=>F, FT=>F, FF=>F}. This should be obvi-
ous: a compound sentence with “and” as the logic-word connecting the indi-
vidual sentences, is true only in the case in which both connected sentences are 
true; it is false in every other case. Try to write the meanings of the logic-words 
given below. Another way of saying this is: try to give the truth conditions of the 
logic-words given below. The meanings of the logic-words are their truth condi-
tions. Can you explain this in some detail?
	
a.	 Both X and Y. [Is the meaning different from the meaning of “and”? Notice 
that we are talking about the logical meaning, not linguistic uses that serve 
various purposes in language: the logical meaning is the truth-conditions, as 
we have explained.]
1.2  Logical Meaning, Logic-Words and Logical Form

30
	
b.	 Either X or Y. [ALARM: is it possible to answer this challenge without 
removing a fatal ambiguity about what we mean by “either-or?” Can you 
figure out what the two possible meanings of “either-or” are? Move to the 
next two questions.]
	
c.	 Either X or Y or both.
	
d.	 Either X or Y but not both.
	
e.	 Neither X nor Y.
	
f.	 Not-X and not-Y. [Is the meaning of this expression different from that of 
the preceding expression or are they the same?)
	
g.	 Only if X, Y.
	
h.	 Not-not-X. [of course, “not” is a unary logic-word, not a binary one: it 
applies on one sentence-meaning; in this case, the second occurrence of 
“not” is applied first; a compound sentence results; the second occurrence of 
“not” is then applied on that compound sentence.)
	 6.	 The following sentence-forms have logic-words that cannot be defined simply 
by their truth-conditions as with the preceding examples. Consider the one 
given example and attempt the same analysis for the rest.
	
a.	 It is logically necessary that X.
Since “logically necessary” is unary, it operates on one sentence. Let us dis-
tinguish, as before, the two cases: T and F (true and false.) We regard any 
true sentence, and any false sentence, as an available candidate to place for 
X as we distinguish cases. For logical analysis, as a matter of logical mean-
ing, all true sentences (and all false sentences) have the same meaning. This 
seems unnatural but see that this is true-false game. It is not about content. 
This theme will be elaborated repeatedly and is important although not 
immediately obvious. But think of the truth-conditions that define logical 
meaning, as we have learned by now. Any sentence of the logical form 
“X-and-Y” has the same truth conditions with every other sentence of the 
same form: therefore, they all have the same logical meaning regardless of 
the content of these sentences. For X in the example we are considering, we 
can put any true (false) sentence. Now something happens. For some true 
sentences, the result is a true sentence but for other true sentences the result 
is a false sentence. The same for inserting instances of false sentences. Let us 
see how.
It is logically necessary that a triangle has three angles. [T => T] :[true sen-
tence put in, the resulting compound sentence is also true].
It is logically necessary that the capital of the US is Washington. [T=>F] [It is 
not a matter of logical necessity; it is not analytically true, based on the 
meanings of the words; it is just a matter of actual historical fact but it is logi-
cally possible that it could have been otherwise: you can write a logically 
possible story in which some other city, not Washington, is chosen to serve 
as the capital of the US; this story does not describe the actual world but it 
does describe some world that is logically possible; it is a consistent story.]
1  What Logic Studies

31
We don’t know how we can give truth conditions in such a case even though 
“necessarily” is a logic-word too. We say that a logic-word like “necessarily” 
is not truth-functional. You will learn more about this in due time. Now try to 
give an analysis for why each of the logic-words in the sentences given below 
is not truth-functional.
	
b.	 It is logically possible that X. [It might be easier to do by plugging in 
instances of false sentences for X.]
	
c.	 X is true before Y is true.
	
d.	 It is morally obligatory that X.
	
e.	 It is known that X.
	
f.	 It is believed that Y.
	 7.	 Words like “all” and “at least one” are also logic-words but it is difficult to see 
how we may talk of truth conditions in explicating their meanings.
But here is an idea. “All” has some meaning-connection with “and” and “at 
least one” is related to “either or”. But there is a catch. We have to specify the 
universe of things we talk about and to ensure that this universe of things does 
not have an infinite number of things in it. How would we express conjunctions 
or disjunctions of infinite number of sentences?
	
a.	 Express the sentence “All persons are students” over a universe or domain 
{John, Mary} so as to bring out the connection in logical meaning between 
“all” and “and” – so that the truth-conditions for “and” are made to do the 
work for expressing the truth conditions for “all.”
	
b.	 Now express the sentence “At least one person is a student” over the same 
universe, {Mary, John}, so as to bring out the meaning-connection between 
“at least one” and “either X or Y or both.”
	 8.	 Consider the sentence: “Mary is a student.” Are there any logic-words in this 
sentence? Defend your answer.
	 9.	 The logical form of a sentence (for instance, “X and Y” being the logical form 
of “It is Sunday today and there is a football game today”) is not informative 
about the world of experience, empirical reality, facts. Explain what this means.
	10.	 If the sentence X is true, then it has to be true that “X or Y or both X and Y.” This 
is because, X being true, indeed at least one of X and Y is true: so, “either X or 
Y or both” is true. We have a relationship between “X” and “either X or Y” 
which, as we will learn, is a relation of implication: “X” implies “X or Y.” It is 
logically impossible for “X” to be true and “either X or Y or both” to be false. 
The first logical form is related to the second logical form so that the first 
implies the other in the sense we have indicated. Does it matter that in language 
we would not see the point of inferring “either X or Y or both” from “X?”
	11.	 Can any word expressing a property or attribute be a logic-word? (Consider 
predicating anything of anyone: for instance, “Schlup is a student” or “Tara is a 
teacher.” Can such a sentence be logically necessary? Or it is logically 
­contingent, which means that it is logically possible for it to be true but also 
1.2  Logical Meaning, Logic-Words and Logical Form

32
logically possible for it to be false – regardless of what may actually be the case 
if your predications are matched to names of actual entities?)
	12.	 Is the phrase “is identical with” a logic-word or is it not? (Interestingly, “is 
identical with” is like a predicate, which we considered in our preceding exer-
cise, if we conceive broadly of a predicate so that it can be applied to more than 
one object – such predicates may be called relational predicates. But consider 
also that the principle by which we state that “everything is identical to itself”, 
which we may call the principle of self-identity, has to be a logical principle.)
1.3  Sentences and Meanings
When we study logical meaning, we regard sentences as grammatical entities whose 
structure, as established through the conventions of language, may or may not con-
tain meaning. Indeed, surprising as it may sound at first, grammatically correct sen-
tences of a natural language like English, or of any language, may be meaningless. 
We make an immediate stipulation: logical meaning is a matter of truth-value; a 
sentence is meaningful if and only if it expresses (states, declares, asserts) a mean-
ing that can be either true or false, cannot be both true and false and cannot be 
neither true nor false. Nothing else is to be accepted as logically meaningful. It is 
apparent, then, that it is the meaning of the sentence that is capable of having a truth 
value (being true or being false) since, as we have indicated, grammatically proper 
sentences may be meaningless. Moreover, we can have an open-ended number of 
sentences – physically betokened in writing or stated by means of utterance – all of 
which have the same meaning or make the same statement. We may even translate 
from one language to another, overlooking for our purposes puzzles that may arise 
in the context of translation: then, two sentences that are betokened by physical 
items (written or uttered) in different languages are, nonetheless, taken properly as 
having the same meaning. Clearly, a sentence and its meaning are two different 
notions: in logic, we focus our attention to the logical meaning of a sentence and not 
to the sentence itself. A sentence can be grammatically well-constructed or ill-­
constructed but the meaning of a sentence can be true or false.
A meaningful sentence is often called declaratory (which means that, insofar as 
it is meaningful, such a sentence can be properly used to make or state a meaning, 
to “declare,” or to assert – and rightly assert in case the meaning is true.) Terms used 
to refer to the meaning of a sentence include “proposition” and “statement” but in 
this text we use specifically the term “sentence” and we trust that the context and the 
prior stipulative commitment we have imposed suffice to prevent and remove ambi-
guity. We avoid other terms for referring to the meaning of a sentence in order to 
preempt any metaphysical entanglements as to what kinds of entities or objects we 
might have in mind by using a term like “proposition.” There is some philosophic 
controversy around the metaphysical commitments implied by distinguishing the 
proposition from the sentence. Or, one may ask, what is the relationship exactly 
between the sentence and the meaning it expresses? In the latter case, many 
1  What Logic Studies

33
metaphors have been tried (like comparing the sentence to a vehicle and the mean-
ing to what is carried by the vehicle) but such metaphors are regularly found want-
ing. Although the debates arising from such profound philosophic inquiries are 
fascinating and intrinsically worth perusing for their depth and challenges they pose 
to the human mind, this is not the proper place for engaging in such issues. It is to 
be understood from now on that “sentence” serves the purpose in this text of refer-
ring to the meaning of a grammatical sentence, which can only be true or false; we 
are not referring to the grammatically formed concatenations of symbols we have 
write in language or to the succession of phonemes that constitute spoken units. 
Whenever “sentence” is also used when discussing grammatical sentences, context 
removes ambiguity.
When we study Formal Logic, we construct formal languages of symbols and 
impose by formal stipulation on such languages specified grammatical conventions: 
the term “sentence” could be emerging again, ambiguously, as a candidate for using 
to refer to the properly formed symbolic expressions of our formal language. 
Instead, we opt for the term “formula” in that case: a formula is a symbolic expres-
sion, understood to be referring to nothing specifically and to be a constructed 
aggregate of symbols. Such a formula, or symbolic expression, may be well-formed 
within a specific formal language if it is constructed in accordance with the gram-
matical (also called syntactical) rules of that formal language. Otherwise, the for-
mula is not well formed; we can say that it is ill-formed. An ill-formed formula is 
ill-formed relative to a specified formal language and its grammatical rules: the 
specified formal language cannot “read” the ill-formed formula given the formula’s 
relatively ungrammatical construction. There may or may not be another formal 
language for which the given formula is readable because it is, relative to that other 
formal language, a well-formed formula. This is not our concern, however, since we 
are exclusively focused on operating within the grammatical conventions of our 
given formal language. There are significant advantages we gain by using formal 
languages. This will all be explained and experienced in due time.
The above remarks adumbrate an early hint about the interesting relationship 
between meaning and symbolic notations. Significantly, in deductive logic, we are 
speaking of logical meaning, which is not the same as the meaning-content of sen-
tences. This is a surprise, perhaps a stumbling block to grasping what the enterprise 
of logical study is all about. As we will learn, the empirically verifiable – descrip-
tive, factual, contingent – content of meaningful sentences is not our business in the 
study of deductive logic. An intuitive illustration of what is afoot can be attempted: 
take the sentence “Rob is President.” We should say, properly – although we might 
omit such pedantic precision if we can trust that it is all understood – that the mean-
ing of this sentence can be true or false. Whether it is true or false is not for logic to 
analyze: it is a factual matter, more narrowly a historical issue. Logic scans this 
sentence, or, properly, the meaning of this sentence as a possibly-true-possibly-­
false-unit-of meaning. From the standpoint of logical analysis, what matters is that 
this is a meaningful sentence – hence the meaning can be true or false. This is not a 
sentence (meaning) that is necessarily true or necessarily false. It is a logically con-
tingent or indeterminate sentence (using “sentence”, as we have arranged, to mean 
1.3  Sentences and Meanings

34
“meaning.”) A sentence like “it is raining here and now but it is not raining right 
here and now” is a sentence that is logically necessarily false! This sentence is com-
pound or complex: it is made of two single or atomic sentences that are connected 
by “and” and one of the two conjuncts is operated-on by “not.” These are logic-
words, as we will explain in due detail later on. “Not” placed in front of a true sen-
tence brings about that we now get a false sentence and the other way round. Since 
it interacts with true-false to alter logical meaning (to turn true to false and false to 
true), “not” is a logic-word. “And” is also a logic-word: in this case the available 
possibilities are four – these are the combinations or true-false for the two sentences 
which are connected with “and.”
Let us continue with our illustrative example. For logical analysis purposes, 
“Rob is President” is not about the factual, descriptive, confirmable empirical con-
tent: it is possibly-true-possibly-true-unit: by unit we mean the smallest possible 
grammatical and representable unit that can hold or carry logical meaning, which is 
the meaning of a single or atomic sentence. A good question is: how do we know 
and how do we determine that this is an atomic sentence? Let’s say at this point that 
there are no logic-words – like “not” or “and.” Moreover, it is relevant indeed that 
we are not at this point equipped to “look” inside the meaning and into its composite 
parts. We take the whole sentence as a block, so to speak.
Interestingly, a sentence like “Mara is President” is also a possibly-true-possibly-­
false-unit for our purposes of logical analysis. There is a dramatic difference in 
content between the two sentences but this does not matter for logic. We are not 
contending that it does not matter as such; only that it is not relevant to what logic 
is bent on examining. Let us explain this. We can see intuitively, hopefully, that 
logic should analyze and correctly determine such matters as: how two sentences 
are related in proving one from the other or in having them both consistently 
included in a theory or viewpoint. Given one sentence, does the other “follow”, as 
we may say in everyday parlance? In our case, the answer is negative. Neither sen-
tence implies the other. That Rob is President does not imply that Mara is President; 
nor does it work the other way round. You might actually think that either sentence 
implies the negation of the other – if Mara is President, then it cannot be the case 
that Rob is President. But you are assuming that there is exactly one President. This 
may be true and it is actually the case for familiar political systems that mandate a 
singular executive; but from the standpoint of logic, it is, again, possibly true and 
possibly false; it is not a matter of logic how the institutional machinery of govern-
ment is set out. You would have to add as an assumption that “there is exactly one 
President” and then, indeed, lo and behold, you should be able to prove that either 
one of our initially given sentences implies the negation of the other.
When we speak of implication, what we mean, precisely speaking, is this: A 
implies B if and only if it is logically impossible that A is true and B is false. We will 
see this again later in this text, time and again. Notice how our increasingly more 
precise definitions of the concept of implication are built with the concepts of true 
and false. This is the key to grasping why our “game” is a game with true and false 
(at least, in one way of presenting what logic does  – keeping away from the 
1  What Logic Studies

35
manipulation of symbols, which is something we will be speaking of as well, and 
for now just talking about logical meaning.)
Let us also inquire as to whether the two given sentences can be included together 
in an opinion or view or description that is not logically inconsistent. For a collec-
tion of sentences (which is a theory, a view, an opinion, a given description, and so 
on) to be inconsistent is explosive: the theory or view needs to be revised and, if not 
possible to revise it, it should be abandoned. It is easy to realize that “inconsistent” 
is a negative quality: indeed, as a logical characteristic, inconsistency is a character-
istic of a collection of sentences: the definition is that, a collection of sentences is 
inconsistent if and only if not all the given sentences can be true together. Since the 
theory or view posits all the sentences (and, therefore, presents them as all true), this 
is nonsensical: if the sentences cannot all be possibly true together, then the theore-
tician or reasoning agent has an explosively absurd collection! Notice that we don’t 
have to be aware of this: subjectively, one might be convinced that her or his theory 
or opinion suffers from no anomalies of logical meaning – but inconsistency is 
objectively a logical anomaly regardless of psychological awareness of the issue. 
The two sentences we started with in our example are indeed consistent. They are 
both possibly true and possibly false (but, of course, not true-and-false together.) 
This gives us exactly four mathematically possible combinations for two sentences: 
true/true, true/false, false/true, false/false. One of the possible combinations is true/
true. This suffices because, by the definition we gave, there is one logically possible 
case in which both sentences are together true: so, they can be or they possibly are 
true together. In our actual world, on the other hand, this might not be the case! Our 
actual world might correspond to the true/false combination, for instance. But this 
does not affect the consistency characterization. Your theory is still logically consis-
tent even if it is inaccurate or wrong as a description of the actual state of affairs. 
Our actual world is only one logically possible world. To the historian, the actual 
world matters but not so to the logician because – so to speak – logic examines 
properties that, if they obtain, they apply in all logically possible cases.
Of course, it is bad to be inaccurate or to fail to hit the factual mark, but this is a 
different matter and it is not the business of logic. On the other hand, an inconsistent 
position or view cannot be true (cannot characterize or obtain) in any possible state 
of affairs whatsoever! The logical characteristic of inconsistency, if we may venture 
a metaphor, stands at the gate as an austere constraining force: if we fail in this logi-
cal requirement, nothing matters: your inconsistent theory is doomed initially: it 
loses and no further steps about ascertaining what may be the case in the world 
makes any difference. Of course, there is a way to obtain consistency – by removing 
at least one sentence from your theory – but let us further presume that your theory 
is considered finished and completed – not to be touched. It is logically impossible 
for all your theory’s sentences to be true together, if it is inconsistent. Therefore, 
there is no logically possible case that can be described by your theory. (Notice an 
interesting feature of the way we just put it: are we letting some independent meta-
physical entity – “the describable case” – to be the primary concept? We should not 
think this way; rather, it is a concept like consistency that takes precedence. If the 
description of a presumed case is inconsistent, then there is no such case to describe! 
Asserting the contrary commits us to logical absurdity.)
1.3  Sentences and Meanings

36
It ought to be obvious by now that logic has a certain generality and foundational 
character about it: logic compels assessment of any and all theories: any theory has 
to be consistent, regardless of what the subject matter is, or, otherwise, it is an 
absurd no-theory.
Mara is
President
Logically Possible Worlds
and
Mara is
President
Rob is
President
Rob is
President
 
Let us return to our running example. If we were to add the assumption that there 
is exactly one President, then we have three, not the initial two, sentences. Try to see 
that this new viewpoint, comprising all three sentences, is inconsistent! They cannot 
all be true together. Of course, we could withdraw the last sentence and we are back 
to a consistent set of sentences; or we could withdraw one of the other two sentences 
to obtain a consistent set. Try to practice this. But the three sentences together form 
an inconsistent collection of sentences.
Let us symbolize the sentence “Rob is President” by “R” and “Mara is President” 
by “M.” Now, suppose that we interpret our symbols R and M so that they have dif-
ferent contents. Nothing changes about the comments we made above: both sen-
tences are capable of being true and of being false (but not true and false in the same 
case); it follows that they are mutually consistent – there is at least one combination 
of them both being true. Now, we saw that the introduction of an additional assump-
tion, “there is exactly one President,” unsettles matters as it generates a new and 
inconsistent collection of sentences. Let us symbolize, “there is exactly one 
President” by “P.” As we said, however, we cannot turn to logical analysis to be 
informed about a regulation as to how many presidents there may be. We can think 
of this in the following way: surely, it is logically meaningful to have a stipulation 
that exactly one president ought to be allowed but it is also logically meaningful that 
two presidents be allowed, and so on. You could have one world in which the rule is 
that one president is allowed, or mandated; another world in which two presidents 
are allowed or mandated; and so on. These are all logically possible worlds. Our 
actual state of affairs or possible world is just one of all the possible worlds. Logic 
has generality: it ought to apply to all possible worlds. If we labeled each possible 
world by “1” or “2” and so on, reflecting how many presidents are mandated for the 
system, those labels would characterize such worlds. Instead, we might as well use 
our sentences  – “exactly one president is allowed”, “exactly two presidents are 
1  What Logic Studies

37
allowed,” and so on. But the logical characteristics ought to be generally applica-
ble – not confined to any specific possible world but applicable for all possible 
worlds. It follows that we cannot logical truths (or logical falsehoods for the matter) 
to label worlds.
Given R and M, if we add P, we cannot detect any inconsistency. We need a more 
fine-grained logical structure. Symbolizing the restriction that compels having 
exactly one president by a single sentence symbol P does not show us sufficient 
detail of logical structure. We could take this added sentence symbol, P, and use it 
to label some random logically possible world. We don’t see the inconsistency. Our 
task becomes how to express this restriction by showing more structural detail in 
our representation of the restriction. Here is what we can do: we can represent the 
restriction by “M if and only if not-R” (or “not-M if and only if R.”) Indeed, the 
restriction is logically equivalent (it is true/false under the same logical conditions) 
with the suggested expressions. What we mean by logical conditions is this: the 
whole collection of true-false values, which we get by assigning true and false to the 
symbols for all possible combinations. This may seem like a forced trick but it let us 
assess what has happened: we have discovered that we can have a perspicuous nota-
tional way of expressing logical structure, so that the logical properties can be eval-
uated. At the same time, we have pressed that logical characteristics must be 
invariable across any logically possible cases or states of affairs or possible worlds. 
The restriction we added is not itself a logical postulate: we may think of it rather as 
an extra-logical meaning postulate (i.e., as a postulate that is not about logical 
meaning but about “meaning” in the common sense that includes non-logical con-
tent of sentences. Once the restriction is added, however, logic again is inexorably 
put to the task of checking for consistency.)
Let us examine, in brief, how the addition of the restriction, expressed so that 
sufficiently fine-grained logical structure is shown, results in an inconsistent triad of 
sentences. We cannot have any logically possible world in which all three sentences 
are true together. Such a world would be notionally understood as a logically impos-
sible or absurd world. We show below the possibilities. (We have been using this 
heuristic device of “possible worlds” without, as before, entering into metaphysical 
issues as to what kinds of objects we may have in mind to make sense of such 
“worlds.”)
Logically Possible Worlds
There is
exactly one
President
There is exactly
one President
---
Mara is
President
There is
exactly one
President
------
Rob is
President
 
1.3  Sentences and Meanings

38
1.3.1  Meaning and Truth Conditions
The standard sentential logic we will be studying is founded on certain elementary 
assumptions. The justification for the application of formal apparatus to the analysis 
of arguments and claims in language is that the assumptions at the foundation of the 
logical system are adequate to a correct analysis and do not lead to unwarranted 
conclusions about how the logic of the language works. It is always important, how-
ever, to bear in mind that the formal system itself cannot be incorrect or wrong as 
such: it is only with respect to a specific range of presumed applications that the 
question can arise as to whether the formal system is adequate to the intended task 
of application.
Meaning, or we should say more precisely logical meaning, is taken as a matter 
of what we call truth conditions: the meaning of a meaningful or declaratory sen-
tence – a sentence that could be logically-justifiably asserted if it were true – is 
considered to be the nexus of the conditions or cases or logically definable possible 
states in which this meaning is true. Notice how we are dependent on modal notions 
like “possible” and counterfactual notions like “if it were the case, then it would be 
the case.” Moreover, the notion of “state” or “case” must be defined specifically. To 
do so, we note that the character of the logic is, as we say, compositional: the mean-
ings of the whole depend on the meanings of the parts: if the meanings of the parts, 
ultimately of the atomic or individual sentences, are specified, then the meanings of 
composites and ultimately of the whole sentence are precisely and uniquely deter-
mined. This is the case for sentential logic – when we don’t have symbols for com-
ponents of the sentences themselves and we treat meaningful sentences as block-like 
units that are unanalyzable. Accordingly, a case or option or possible state (or inter-
pretation or valuation) is a systematic assignment of truth values to all the types of 
atomic or individual sentence variables in a sentential formula: the truth conditions 
for the sentence expressed by a formula is the map or nexus of all such mathemati-
cally definable assignments for all types of sentential variables (with multiple 
occurrences of the same sentential variable in the formula receiving the same truth 
value on each assignment). This agglomerate constitutes the truth conditions for the 
formula. It is also notable that we rely on assignments of truth values to symbols 
and computational determination of the truth value of the whole composite formula 
(whose syntactical formation is precisely regulated by the formal grammar of our 
symbolic language.) Now, in a semantic fashion, talking about meaning, we need 
objects of which we can speak.
The metaphysical character of such objects does not raise any concern, or so we 
stipulate and this allows us to bypass, for purposes of constructing the system, all 
kinds of riddles about such notions as truth or possibility. The standard view is that 
a logic system should have compositionality of meaning as we characterized it with 
respect to truth conditions; any lapse in compositionality ought to be addressed 
appropriately when we move to extensions like that of predicate logic. The exten-
sional view requires, in its semantic version, that there are objects that can serve as 
1  What Logic Studies

39
referents or denotata for purposes of meaning; such abstract objects are not to be 
understood as incurring any ontological debts. Metaphysical considerations may be 
set aside as irrelevant to our present purposes of logical study. The reference to 
objects plays a formally mandated and circumscribed role – as in a case of counting 
on a plausible narrative to enable us to make sense and track our systematic enun-
ciations but without attaching any relevant significance to whether our posited 
things actually exist or not. For our semantic purposes in sentential logic, the refer-
ents of the meanings of sentences are truth values – true or false, not both true and 
false and not neither true nor false.
There is an alternative philosophic view, which comes with significant recom-
mending credentials, according to which logical meaning is not a matter of truth 
conditions but, rather, it is generated by the rules under which logic-words are cor-
rectly asserted in a language. Since we are bent on the project of studying moti-
vated logical or formal languages, we need to know how this alternative view is 
presented in the context of formal logical analysis: when we turn to the study of 
what we call natural deduction methods for proofs, we will witness how rules are 
laid down for manipulating introductions and eliminations of the symbols for the 
connectives of the logical languages. According to an influential view, the logical 
meaning of a logic-word, or a connective of the formal system, is determined by 
the rule that governs the introduction of the symbol for the connective. To return to 
the linguistic setting: a competent speaker of a language like English will accept as 
correct assertion of a sentence with form “X and Y” only if both X and Y are cor-
rectly assertable. Accordingly, the meaning of “and” is established inherently not 
by the conditions under which “X and Y” is true and false but by the conditions 
under which “X and Y” is rightly assertable: although assertability seems related to 
truth, the point is that “and” is introduced in the sentence that is to be correctly 
accepted in language under the proper conditions. There are also rules that manage 
the elimination of connective symbols – or of logic-words in the linguistic setting. 
For instance, X is accepted if it has been asserted that “X and Y”, and so is Y: this 
means that the rule for the elimination of “and” is such that each one of the con-
joined sentences are accepted in assertion once the sentence “X and Y” has been 
laid down. We will not pursue this philosophically deep subject in any detail in the 
present context.
Let us start with the truth conditions that are stipulated for the atomic or indi-
vidual sentence, which is taken as the absolutely minimal unit in which meaning 
can fit or by which meaning can be expressed. The nexus of mathematically possi-
ble value assignments, on the stipulation that we have exactly two truth values, true 
and false, is: true or false, not both, and not neither. Thus, there is a restriction on 
those value assignments since we do not allow both values to be assigned and we do 
not allow that neither value is to be assigned. We have also said that these are exactly 
(all and only) the available mathematically possible options, under the restricting 
stipulation, but we should keep in mind that the issue about how logic is different 
from mathematics is not trivial. The options can be characterized as logical in the 
1.3  Sentences and Meanings

40
sense that we have applied the restrictions indicated. Pressed on what objects are 
referred to or denoted by meanings of declaratory sentences we stipulate that those 
objects are the truth values. Once again, we shrug off any metaphysical queries 
about the nature of such abstract objects.
Based on what we have investigated, the meaning of a logic-word like “not” – 
called connective, even though it does not connect two sentences in this case – is 
characterized completely as a matter of truth conditions: for any formula, its nega-
tion is false when the formula is true and it is true when the formula is false. This 
is all, it is sufficient and there is no other possible case. Remarkably, we cannot 
find anything in nature or in any narrative we could construct about naturally 
occurring or descriptive states of affairs, to which we could point as the referent 
of “not.” We might speak of dogs and cats and we could characterize symbolically 
those entities by constructing symbols that represent ostensibly the natural appear-
ance of the cats and dogs in the natural world but we cannot effect this for a logic-
word like “not.” Accordingly, our semantics is not, and should not be, like what 
we may devise when we deal with the subject matter of a natural science. This, 
again, is eminently satisfactory in a sense, because logic ought to have a certain 
character of generality and precedence (in the sense that it is presupposed as being 
in place before and so that we can engage in any science or any discipline): logic 
should not be dependent on naturalized objects and we are content that our account 
of how the formal system is constructed and how we can speak of it capture some-
thing about the character of logic. It is also notable that there is something about 
our enterprise that seems rightly reducible to operations with symbols. Such sym-
bolic notation affords us perspicuous views and ensures that ambiguity cannot 
arise but there is something more to it: the generality of logic – the overall appli-
cability of logic that seems to be self-justifying in a way – can be explained by 
taking the logical formalism to be something of a “game” with symbols. We can 
certainly motivate different such games on the basis of claims that we “get it 
right” when it comes to how the logic of the language works, for instance, but a 
game in and of itself is closed off and it should sound wrong to ask for a higher 
justification of a game as such. This is fascinating as it shows us that there could 
well be many logics that can be constructed, with the question of correctness not 
arising; but it can also happen that a given formal logical system can be held up to 
external criteria of applicability with respect to a specified linguistic target. As for 
the question regarding “where the logic of the language comes from”, this has 
been a challenging philosophical issue. One option is to consider this as a brute 
fact arising from what the definitions of the logic-words in a given language hap-
pen to be. This would suggest that the logic of language is a matter of arbitrary 
convention – a prospect that is anathema to the traditional view that logic is abso-
lutely binding across universal boundaries and not something that can emerge 
variably in different contexts.
1  What Logic Studies

41
1.3.2  Exercises
	1.	 If we consider the logical meaning to be a matter of truth conditions, we must 
define the logical meaning of “and” as the nexus of the following outputs of true/
false for all the possible combinations of true and false to the two connected 
sentences (since “and” is binary, which means that it connects always two sen-
tences.) The possible combinations are: true-true, true-false, false-true, false-­
false. Other recipes for presenting all, and only, the combinations of true-false 
assignments can be devised as well. For “and” the truth conditions are collec-
tively taken as: and(true-true)=true, and(true-false)=false, and(false-true)=false, 
and(false-false)=false. This ought to be obvious: the compound statement is true 
only if both connected (simple of compound) statements are true; in all other 
possible cases, the compound and- statement is false. After all, “X and Y” can be 
paraphrases as “both X and Y.” Now state the truth conditions for “either-or.” 
This is tricky: first, we need to remove an ambiguity. There are two meanings of 
the English “either-or:” one meaning for “either X or Y” is “one or both of X and 
Y” and the other meaning is “exactly one of X and Y, one of X and Y but not 
both.” Can you state the truth conditions for both these meanings? The first is 
called inclusive and the second is called exclusive either-or.
	2.	 Is it easy to define the truth conditions for if-then? We will soon examine in 
depth the concept of logical argument and we will discuss validity of deductive 
arguments. We will define an invalid deductive argument pattern as one that can 
possibly have instances with all premises true and a false conclusion. In other 
words, failure of the conclusion to preserve the truth of the premises is the key. 
Suppose that we have one premise and one conclusion: X, therefore Y. The argu-
ment form (as indicated by the presence of variables X and Y), is invalid if and 
only if there is any possible assignment of truth values (true and false) to all the 
individual sentences in X and Y (which may be compound) so that X is true and 
Y is false. Now consider that we want to have the following principle as appli-
cable in the case of our standard logic: “X, therefore Y” is valid if and only if “if 
X then Y” is true for any possible assignment of true-false values to the indi-
vidual sentences of X and Y; “X, therefore Y” is invalid if and only if “if X then 
Y” is false when X is true and Y is false. Can we use this to define “if-then” 
based on its truth conditions? Consider what truth value we should give to “if X 
then Y” when X is true and Y is false. But also consider, perhaps surprisingly, 
that when X is false and when Y is true, in every such case, “X, therefore Y” 
cannot be invalid: we do not have X as true and F as false.
	3.	 Considering that logical meaning is compositional, how can we determine the 
truth conditions of compound sentences? For instance, what are the truth condi-
tions for “X and Y and Z” and of “(either X or Y but not both) and X”?
	4.	 Let us return to how we define “and” in terms of the truth conditions for “X and 
Y” with X and Y being any individual sentences whose meanings are understood 
as true/false. Why shouldn’t we define “and” by taking X and Y to be possibly 
1.3  Sentences and Meanings

42
compound sentences? As a clue, consider what happens if we have “X and (X or 
Y)”? Do the outcomes (in terms of true and false) agree with the outcomes for 
“X and Y” across all the possible assignments of true/false to the individual sen-
tences X and Y?
1.4  Arguments
First, we need to define the term “argument” as used in Logic. The term does not 
have the common meaning of “disputation” or of the “act or process of engaging in 
a debate or dispute. An argument is a collection of meaningful sentences, one of 
which, called conclusion, is presumed to be supported by all the others taken 
together (conjunctively, or understood as being joined by “and”.) Strictly speaking, 
an argument is a collection of the meanings (called statements or propositions). 
Many texts use the term “proposition” instead of “sentence” but, as we have already 
hinted, other logicians are rather spooked by the kind of thing a proposition would 
be. Another commonly encountered term is “statement.” We can ignore such issues 
here, but we need to notice certain things:
	A.	 An argument is like a proof. Think of a proof, completely laid out, with prem-
ises (also called assumptions) and the conclusion. The pretense is that the con-
clusion follows from all the premises. But what if it doesn’t? This is one of the 
subjects Logic, and only Logic, studies. How do we evaluate arguments? What 
makes an argument “correct?” By “correct” we mean that IF the premises of the 
argument are true, then the conclusion ought to be accepted as true. This “ought” 
is not moral, it is not pragmatic (as in “you ought to take such and such a route 
if you want to get to the city faster.”) It is a logical “ought.” We can think of an 
argument, then, as a relation: between the premises and the conclusion. A state-
ment by itself cannot be an argument. A collection of sentences, which may be 
thought of as a theory, cannot be an argument: there has to be a conclusion, to 
have an argument. The argument in the sense used by logicians comprises the 
premises and the conclusion and the assessment of the argument evaluates the 
relation between the premises (all the premises, or, we can say, the set of prem-
ises) and the conclusion. In common parlance, we may say, with idiomatic flare: 
the conclusion follows the premises; the premises support the conclusion. Given 
the premises as true, the assessment of the correctness of an argument regards 
whether the conclusion is true. We can also think of this as a matter of truth 
preservation: given, hypothetically, that the premises are true, is the conclusion 
true too?
	B.	 As we are working with only two logical possibilities – true and false – for 
sentences (or, better, for the meanings of sentences), we can grasp intuitively 
that the one of the two values, the true, is the “winning” one. Technically, this is 
called designation: the value true is the designated value. The conclusion is the 
new sentence – the one that presumably follows or is proven by the given prem-
1  What Logic Studies

43
ises. We must be able to ascertain that the conclusion has this winning semantic 
(meaning-related) characteristic of truth – IF the premises are taken as being 
true, THEN the conclusion also has this designated value of being true, and the 
whole relation (between all the premises and the conclusion) is logically 
necessary.
	C.	 The notion of “if-then”, which we are clearly using here, causes grief to begin-
ning students. Caution is needed. Notice, again, that the laying of the premises 
as true (thus, having the winning semantic characteristic of being true), is taken 
as given regardless as to whether the premises are “in fact” or actually true; it is 
simply laid down that they are all true and then the evaluative issue arises as to 
whether the conclusion is also true on the assumption that all the premises are 
true. The crucial issue is whether, on the assumption of having all true premises, 
the conclusion (the new, inferred, and presumably proven) sentence is also true. 
We can say that what we are assessing, then, is truth preservation
	D.	 We could be playing this game to see if some other winning characteristic 
(something other than truth) is preserved. Regardless of that, we need to under-
score, once again, that, if we let the premises have it, as given, we must deter-
mine whether the conclusion also has this winning characteristic. Note that we 
take true, and false, to be characteristics only of (meanings of) sentences and of 
nothing else. (Of course, the sentences that can be true or false have to be mean-
ingful sentences. Conversely, if a sentence is meaningful, we take this to be a 
matter of that sentence’s having the characteristic of being true or false – having 
a truth value, as we say.)
	E.	 The standards for the evaluation of the correctness of the argument – if the argu-
ment is “good” and “ought” to be accepted – depend on whether the argument 
is deductive or inductive. In the case of inductive arguments, the preservation of 
truth by the conclusion – IF the premises are true – is a matter of probability. We 
cannot offer any deeper grounds as to why logic – and argument types – come 
in two varieties (deductive and inductive.) This is a brute fact. (There is a view 
that there is a third type of argument, called Abductive, or Inference to the Best 
Explanation, but that will not occupy us here.)
	F.	 Only arguments have conclusions. If you hear that a conclusion is mentioned, 
you are certain that you are dealing with an argument. (Of course, we leave out 
other, easily distinguishable senses of the word “conclusion,” as in “the story 
had a happy conclusion.”) Anything that is said to have a conclusion is an argu-
ment for our purposes. And, of course, the other way round, there can be no 
argument that does not have a conclusion.
	G.	 The conclusion is a new sentence that we don’t have a default right to include in 
our body of knowledge. Assuming that we have the premises as true, the conclu-
sion then is new to us: should we accept it? Is it true, based on the truth of all 
the premises? This is the key. It is vastly important for the development of 
human knowledge that we incorporate conclusions we can correctly draw from 
premises we accept as true. We need to know, then, if the conclusion indeed is 
supported by the premises. This means, for deductive arguments: Is the conclu-
sion definitely (logically necessarily) true, if the premises are true? You need to 
1.4  Arguments

44
work on these concepts: the average person has difficulties with concepts like 
“if-then” and “necessarily”: notice how we have been using these notions to 
define what a deductive argument is.
	H.	 Intuitively, we can say that, in an acceptable argument, the premises support the 
conclusion or the conclusion follows from the premises. A more precise way of 
saying what this means, as we already indicated, has to do with whether the 
truth of all the premises is preserved in the conclusion. But, for inductive argu-
ments, it is a matter of degree of probability or relative strength of likelihood 
that the conclusion is true given that the premises are true. In the present text we 
study only deductive logic.
	 I.	 We will not consider cases in which there may be no premises – that does not 
seem to make sense in the case of exploring linguistic arguments. (Keep in 
mind, however, that in 4.4, when we study natural deduction systems, you will 
be confronted with an arrangement that asks us to think of no-premises proofs. 
This can be deferred until then but, briefly, a no-premises proof can be elegantly 
considered as proving a logical truth in the sense that nothing is needed to prove 
a logical truth – a sentence that is true in all logically possible cases. We may 
say that a logical truth can be thought of as being provable from the empty col-
lection of premises.)
	 J.	 We will be considering only cases in which an argument has only one suggested 
conclusion. Although it is feasible to handle a concept of “argument” in which 
more than one conclusions are suggested to be following from the premises, we 
will not be engaging in studying such species. It is suggested, or propounded, 
that conclusions follow from premises, because, until we evaluate whether the 
argument is good or correct, or not, we do not know that! Any argument – to be 
an argument – comes with a collection of premises and one conclusion; we 
should better say, a suggested conclusion since the argument might not be cor-
rect or “good” after all!
	K.	 The issue as to whether the argument should be accepted is an objective matter; 
it is not a subjective or opinion-based evaluation. It is not a psychological 
assessment at all! We have here, rather, something like what happens with the 
grammar of a language – in which case we are not at liberty to make subjective 
judgments as to what is correct or incorrect. We can even speak here of the logi-
cal grammar of a language. When we study logic, applying your investigations 
to linguistic arguments, we are examining the logical grammar of the language. 
We can say this! Based on this, we can see by analogy that the evaluation is not 
a matter of opinion. You should also remember that the linguistic grammar is 
not guaranteed to help us with evaluating the logical grammar of given argu-
ments. In fact, the linguistic grammar can be misleading when it comes to 
assessing the logical grammar. For instance: “John and Mary are students” is a 
single sentence grammatically; it has a complex subject but it is grammatically 
single. When, however, we delve into the logical grammar of this sentence, we 
spot a word that, as we will learn, is a logic-word: “and.” This logic-word joins 
two single sentences. Thus, from a logical-grammar point of view, the sentence 
is not a single sentence but a compound or complex sentence: “John is a student 
1  What Logic Studies

45
and Mary is a student.” We are not being fussy in doing this. There is a good 
reason. As a compound sentence, this sentence has a logical meaning that 
depends on the logical meanings of its parts. The parts are themselves the single 
sentences “John is a student” and “Mary is a student.” We have decomposed the 
given sentence: even though grammatically single, we have found it to be logi-
cally complex and we have identified the parts; no further decomposition is 
possible. The whole sentence is TRUE or FALSE only based on whether the 
single sentences we have produced are the right combination of true and false. 
If you think about “and”, you should have no difficulty realizing that an and-­
sentence (a complex sentence made of two sentences that are joined by “and”) 
is true only when both joined sentences are true; it is false in every other pos-
sible case (and those other possible cases are true-false, false-true, and false-­
false.) This is the logical analysis of the sentence we have been examining – but, 
remember, from a grammatical point of view, this was just a single sentence.
	L.	 It is nonsense to say that “this argument is not good for you but it is good for 
me.” Compare how it sounds to say that “this might be wrong grammar but it is 
correct grammar for me.” People are confused sometimes about this: whether I 
think that an argument is good – even if I am fully convinced - is not relevant to 
whether the argument is indeed correct. I could be wrong. The impressions I 
have are a psychological matter but the logic of a language depends ultimately 
on the meanings of certain special words of the language – the LOGIC-WORDS 
of the language, like “not” and “either-or” and “and” and “all,” and such words. 
We can see, again, that this is an objective matter: Meanings in language are 
fixed; otherwise, we would not be able to use language for communication. 
Meanings may change over time, or from one dialect to another, but do not let 
this impress you: they are fixed again immediately as soon as they have changed! 
Meanings are like denomination of currencies: if your ten-dollar bill is liable to 
be rightly interpreted as a five-dollar bill by someone else (or as a twenty-dollar 
bill by yet someone else, and so on), then we do not have a currency that we can 
use for transactions. If you start making calculations in your mind about how 
you can make claims about that five-dollar bill, so that you can make money out 
of the transaction, then, notice what you are doing: you are actually treating the 
currency denomination as fixed! (“I could make money if I convinced him or 
her that this is a five-dollar bill.” But this commits me to accepting it as a one-­
dollar bill.)
	M.	 You should also take to heart that we cannot depend on intuitions or hunches to 
evaluate arguments; and, unfortunately, it is not the case that the more we 
advance in studying various subjects, the better we become in evaluating argu-
ments. This is not the case. Well-educated people do not do well, without prepa-
ration, in logic tests, as can be demonstrated time and again. Students preparing 
for the Law School Admission Test, a logic test, need to attend to the subject 
regardless of what brilliant achievements they may have had in the course of 
their studies.
	N.	 Repeat until memorizing, and make sure you grasp what this prompts us to do 
and why it is important: Given that all the premises are true, is the conclusion 
1.4  Arguments

46
also necessarily true? This is the good or correct deductive argument test: we 
say then that the argument is valid.
	O.	 In the species of reasoning called deductive, preservation of truth must be abso-
lute or not at all: either it is possible that all the premises are true and the conclu-
sion false (in which case the argument is invalid); or there is no logical possibility 
that all the premises are true and the conclusion false (in which case the argu-
ment passes the logical test, as it were, and is considered valid.)
	 P.	 In the species of reasoning we call inductive, truth preservation is a matter of 
probability: assessment of this type of argument seeks to discern, informally, 
the probabilistic degree to which the conclusion might be true if it is given that 
all the premises are true. Inductive arguments are not to be classified as valid or 
invalid but as relatively strong or weak depending on an imprecise but defensi-
ble estimate as to whether there is a sufficiently high probability that the conclu-
sion is true if it is given that all the premises are true.
	Q.	 It is hard but vital to learn that invalidity is a matter of possibly having all the 
premises true and the conclusion false. Here we are speaking of deductive argu-
ments. How can we detect this easily? The term “valid” applies only to charac-
terize “correct” deductive arguments. The word “correct” is rather sloppy, 
although it has an initial intuitive appeal. “Valid” is the official term we are 
using – for deductive arguments. What does it mean to say that it is not possible 
for a valid argument to have all premises true and a false conclusion? To grasp 
this we need now to speak of logical form – and we are prepared to do this since 
we have examined the concept of logical form already.
	R.	 A deductive argument in language exemplifies a logical form – an argument 
form. If it doesn’t, it is not a deductive argument. Inductive arguments do not 
have characteristic forms. What makes our given argument valid is that its form 
is valid; if the form is invalid the argument we have is also invalid. The possibil-
ity of having all premises true and a false conclusion is understood if we think 
about the argument form: is it possible for this form to have all premises true 
and a false conclusion? That is sufficient to make the form invalid: in that case, 
our argument is also invalid even if it happens to have all premises true and 
conclusion true: we say that this is an accident; nothing has been proven cor-
rectly because this argument can possibly have all premises true and the conclu-
sion false. You should commit this to memory – but you need to understand it 
first! Notice that there is a difficult key concept in our definition: logical possi-
bility. This is not intuitive and you will need to appreciate that. Concentrate on 
learning the concepts presented here, fully accepting – without being irked – 
that you will need to dig into this subject further. Take this for a suspense ride. 
But if you have not learned the definition of the concepts, the difficulties will 
turn cumulative.
	S.	 An instance of an argument form, with all premises true and the conclusion 
false is called a counterexample to the given argument form. Thus, we can 
define invalidity as the logical possibility that there is a counterexample to the 
argument form; we can define validity as the logical impossibility that there can 
be a counterexample to the argument form.
1  What Logic Studies

47
Example
You might think that this is a good argument. It is not! It is invalid! The sentences 
are all true. This sounds good; but we are dealing with an argument: there is a con-
clusion that is drawn, presumably, on the basis of the premises. What matters here 
is if the argument is valid – not invalid: This means, CAN the argument form have 
all true premises and a false conclusion? In that case, our argument – having that 
form – is invalid! You realize, of course, that this is not easy to figure out. But let us 
extract the argument form of our argument; and, then, we will show that there can 
be an example of this form with all true premises and false conclusion: that suffices 
to condemn our given argument! It has an invalid form. It is invalid – we don’t care 
if the premises and the conclusion are all true: we cannot say that the conclusion can 
be inferred or drawn validly (correctly) from the premises.
FORM of our given argument
How have we extracted the argument form? We have isolated the logic-words. 
Assuming that we are dealing with Sentential Logic, the logic-words are “not” and 
“either-or.” This is one of the two senses of “either-or” – the one called inclusive: 
one or the other of the two connected sentences has to be true but both can be true 
as well. What is left, besides the logic-phrases, are individual or simple sentences. 
We just need to mark the place they are holding – we need to use a variable. Any 
symbols we can agree on can be used as variables. Here is our key. Also, we use as 
an imposed meta-symbol “” to mark the place where the conclusion is inserted.
In this way we have found the argument form of our given argument. An open-­
ended number of arguments (it doesn’t matter if and when and how they are or 
might be made) have this argument form. If there is any such argument with all true 
	1.	 not->>>
	2.	 Either not-=== or not->>>
	3.	 ⇒ not-===
KEY: >>>: Tijuana is in the United States. / ===: Quebec is in the United States.
	1.	 Tijuana is not in the United States.
	2.	 Either Quebec is not in the United States or Tijuana is not in the 
United States.
	3.	 Therefore, from 1 and 2, we conclude: Quebec is not in the United States.
1.4  Arguments

48
premises and false conclusion (a counterexample), that establishes that this argu-
ment form – and, hence, our argument – is invalid. Luckily, you will not have to 
ransack your brains trying to come up with counterexamples – although that is a 
respectable way to pass time and it becomes easier when one keeps practicing. We 
will study in this text systematic and correct methods for determining validity and 
invalidity of given argument forms.
 
We plugged the sentences in for the variables of the argument form. In this way, we 
get instances (also called tokens, examples, and instantiations) of the sentence-­forms. 
The overall instance is an instance of the argument form. We see now that our argu-
ment – instantiating the argument form – has all true premises and a false conclusion. 
Remember our definition of counterexample. This is a counterexample to the form: it 
is an instance of the argument form and it has all its premises true and its conclusion 
false. Therefore, the argument form has at least one counterexample. We conclude that 
the argument form is invalid.
Let us look again closely: The counterexample has true premises. The first sen-
tence is true. The second sentence is true too: remember that, for this meaning of 
“either-or,” it is sufficient if one of the connected sentences is true – which happens to 
be the case. But the conclusion is false!
Now we have seen an example of the form, in which all the premises are true and 
the conclusion is false. This is a counterexample to our given argument form. Since it 
has a counterexample, the argument form is invalid. Our initially given argument is 
invalid – it is not good and not to be accepted, regardless of whether its invalidity had 
been initially detected or not! Notice, again, that our given argument has all premises 
and the conclusion true; but that does not matter. Make sure that you understand why. 
The only condemning possible case is one in which some instance of the argument 
form would have all its premises true and the conclusion false.
Let us substitute into the variables: 
>>>: New York is in Canada./. 
===:Phoenix is in Arizona.
1  What Logic Studies

49
1.5  Consistency
We will revisit this concept in 2.2. We return to these fundamental concepts again 
and again as we try to solidify understanding.
Two or more statements are consistent taken together if and only if it is possible 
for all of them to be true together. Let us give the definition in different ways, high-
lighting certain central issue. Two or more statements are consistent as a collection 
if and only if it is logically possible for them to be together true. We will need to 
elaborate on the concept of logical possibility that figures prominently in this defini-
tion. Notably, consistency is a characteristic or property of collections of statements. 
At a minimum, it is a characteristic of two statements – a pair or doublet of state-
ments. Every statement that is not a contradiction or logical falsehood is consistent 
with itself: in that case too, we have a pair comprised of the statement and itself. 
When taking together as a pair a statement whose truth value is assigned as true and 
the same statement: the pair comprising the true statement and itself is consistent in 
accordance with our definition since we have clearly a case in which both members 
of the pair are true. Accordingly, we can say that every statement that is not a logical 
falsehood is self-consistent.
If we have two or more statements, consistency is a characteristic of the collec-
tion of all of them – as we have emphasized. There are some tricky issues to pay 
attention to. It suffices, by the definition of consistency, that it is logically possible 
for all the statements to be true together. But the concept of logical possibility may 
seem elusive and we need to elaborate on this. Let us start by drawing attention to a 
common error regarding logical possibility. When we contemplate a statement that 
is “definitely” true – in the sense that it is considered verified beyond doubt, estab-
lished, generally accepted, well-known to be true – then we might think that such a 
statement cannot be possible be false – but this does not follow. “The earth has a 
moon” is actually true – definitely true, verifiably true, etc. – but it is logically pos-
sible that this statement can be false: logically, it could be that the statement made 
by the sentence “the earth has a moon” is false. A narrative, an alternative story, we 
can tell in which the earth has no moon is logically possible. Such a story can be 
understood – but attention is needed in that we are not referring to psychological 
comprehension or even proper knowledge but we only mean that such a narrative 
would not commit us to any logical error by its claim that the earth has no moon. It 
is important that the meaning of the words “earth” and “moon” do not necessitate 
that the statement “the earth has a moon” is true. When we use the words “earth” 
and “moon” in our alternative story to state that “the earth has no moon” we are not 
stating something like “the earth, which by definition has a moon, has no moon.” (It 
is actually rather controversial if “the earth” should be referring “rigidly” to the 
specific planet, which does have one moon. But we disregard for our current pur-
poses this rather sophisticated philosophic controversy about how names designate.)
Here is a contrasting example. The statement “a triangle has four angles” cannot 
be logically possibly true. It is logically necessarily false. In an alternative story, the 
sentence “the triangles had four angles in that alien world” is logically nonsensical: 
1.5  Consistency

50
it is stated or asserted – since it is included in the collection of declarative sentences 
that constitute the story; but it is logically necessarily false; therefore, it cannot be 
rightly asserted as true – and yet it is! Let us see how we can show that the sentence 
cannot be asserted as true. The meaning is that “triangles” which by definition have 
three angles are said to “have four angles.” It is like saying “a three-angled object is 
four-angled.” It follows, absurdly, that: 3 = 4. But it is a matter of logical necessity 
(like every mathematical statement is) that 3 ≠ 4. It is like stating that the triangle 
does and does not have three angles: it does by definition but it is also stated that it 
does not! Or, we can think of this as taking one statement – “the triangle has three 
angles” – and making it both true and false. But this is prohibited by the basic rule 
of the sentential logic which dictates that one of the values true and false be assigned 
to any meaningful sentence. We take it that the logic of the language observes this 
rule too.
Now that we have some preliminary insight on the subject of logical possibility, 
we can return to our definition of consistency. Two statements can be both false in 
actuality but that does not mean that they are not consistent. The definition of con-
sistency requires that there is a logically possible context (like an alternative but 
logical story) in which they can both be true. For instance, “the sun is purple” and 
the “grass is blue” are both actually false but we can make them true in an alterna-
tive narrative: both statements are not logically false, they are just actually false. 
Actuality is special of course but it is important now to understand that actuality is 
not privileged from a logical point of view: the actual world is one of an infinite 
number of logically possible worlds, as the German philosopher Leibniz put it. We 
don’t think of those worlds as being physically or concretely available or present – 
whether we can or cannot travel to them. These are abstract objects that we use to 
assist our understanding and modeling of logical concepts. Think of the device of 
alternative narratives we presented above.
1.6  Logical Truths/Falsehoods and Analytic Sentences
An Analytic Sentence is a sentence that can be correctly determined to be true or 
false based only on the meanings of either logical or non-logical words in the sen-
tence. Recall what we studied above regarding logic-words. Logical Truths/
Falsehoods, on the other hand, are sentences, which can be determined as true or 
false based only on the meanings of the logic-words in them. Thus, analytic truths 
include logical truths; but the opposite is not the case. A logical truth is also an ana-
lytical truth but a truth can be analytic without being logical. This happens when the 
non-logical words in the meaning of the sentence determine it as being true or false; 
then the sentence is analytic (and analytic-true or analytic-false) but it is not a logi-
cal truth or a logical falsehood because its truth value (true or false) is not deter-
mined by virtue of the logic-words in the sentences. We give examples now to 
illustrate the distinction.
1  What Logic Studies

51
3
3 No triangle has four angles. Analytic and True: the meanings of the words that 
are boxed sufficiently determine the truth value of this sentence (true in this 
case.) These words are non-logical. As we state repeatedly in this text, the logic-­
words are those whose definitions necessarily involve references to their truth 
conditions: the truth values they assume under assignments of truth values to the 
individual parts; for instance, “not” is defined as reversing true to false and false 
to true –the truth conditions for “not” comprise “not-true = false and not-false = 
true. On the other hand, a word like “triangle” is not definable in terms of out-
comes from truth-value assignments. Thus, “triangle” is a non-logical word. We 
can call the statement made by this sentence syntactically analytic, and it is true 
too. A logical truth, on the other hand, is necessarily true by virtue of the mean-
ings of the logical words in it. Such a statement can be called semantically or 
formally analytic. Similar comments apply in drawing a distinction between 
­syntactically analytic false and semantically-formally analytic false statements. 
An example of a semantically analytic false statement is the one expressed by the 
sentence “it is raining and it is not raining” whereas a syntactically analytic false 
statement is expressed by the sentence “a triangle has five angles.”
3
3 If a triangle has four angles, then a triangle has four angles. In this case, we have 
a logical truth. This is an implicative sentence – an if-then sentence. As such, it 
has an antecedent and a consequent – the antecedent is the sentence that follows 
“if” and the consequent is the sentence that follows “then.” Both antecedent and 
consequent – which are the same in this case – are false, of course. You might at 
first find it strange that this is a necessarily true sentence – a logical truth. This 
sentence, however, does not state that a triangle has four angles: it states that if 
that is the case, then, trivially, it is the case! Focusing on the words that make this 
sentence a logical truth, we place them in boxes: in this case, the phrase “if-then” 
is the phrase responsible for this. It is a logic-word. If we extract its logical form, 
we have “if p, then p.” Any sentence that is an instance of this logical form is a 
logical truth. In deductive reasoning, as we have been emphasizing, the determi-
nation of meaning is not based on conveying and assessing empirical information 
but on the structure or form of the sentence. A form is like a shape or figure. Try 
to think of “if p, then p” as figure-like. Perhaps, we can analogize to a cookie 
cutter which imposes a shape; it is not important at all what material goes into the 
cookie cutter insofar as we insist on the shape that our product must have. At 
what we take to be a deeper level, we have said that the reason why this logical 
form is a logical truth has to do with the meanings of the logical words – in this 
case, “if-then.”
3
3 Either a triangle has four angles or a rectangle has three angles. In this case, we 
have an analytic false statement but not a logical falsehood. The logical form is 
“either p or q,” which is not a logical form of a logical truth and it is not a logical 
form of a logical falsehood. If both disjuncts (as we call the combined sentences 
in an “either-or” statement) are false, the form is false; but if at least one disjunct 
is true, then the form is true: thus, this logical form can possibly be true and can 
possibly be false (not both together, of course, but for different assignment of 
truth values to its parts.) Now, turning to the meanings of the non-logical words 
1.6  Logical Truths/Falsehoods and Analytic Sentences

52
in our given sentence: both disjuncts are indeed false and, so, the whole sentence 
has to be false. It is the meanings of the non-logical words (boxed above) which 
determine this sentence to be analytic false.
3
3 If it rains on Monday, then it rains on that Monday: this is a logical truth; but If 
it rains on Monday, then it will also rain on Tuesday, is not a logical truth (its 
logical form is “if p, then q”) and it is not an analytic sentence (it is not analytic 
true and it is not analytic false.) The meanings of the non-logical words in the 
sentence do not settle whether it is true or false. It is logically possible that it is 
true and it is logically possible that it is false. Do no pay attention as to whether 
it is likely or not for this sentence to be true: deductive-reasoning properties are 
like a light that is either on or off: we cannot have degrees or a spectrum. A sen-
tence is determined to be analytic or not analytic: we cannot have degrees of 
analyticity. Similarly, a logical form is or is not a logical truth – it cannot be a 
logical truth, or fail to be a logical truth, to some degree.
Both analytic and logical sentences are not informative in relation to how the 
world works or events that happen. (We could say that they are informative about 
the meanings of the words that make them necessarily true but notice that knowing 
those meanings is presupposed and not to be left to extracting from assessing the 
sentences.) They are not empirically confirmable or disconfirmable. Knowing how 
to play the game of language is sufficient for the competent user to figure out if such 
a sentence is true or false. This invites reflection, again, as to how deductive logic 
does not deal with the realm of experience. Notice the examples given below. It is 
important to realize and remember that: analytic and logical truths are logically 
necessarily (true or false, whatever they are.) This means that it is not logically pos-
sible to make them false – if they are true – or true – if they are false.
Analytic Sentences - examples 
	1.	 A triangle has three angles. == Necessarily true/It cannot be made false.
	2.	 A triangle has four angles. == Necessarily false/It cannot be made true.
	3.	 A dog is an animal. == Necessarily true/It cannot be made false.
	4.	 A table is a piece of furniture. == Necessarily true/It cannot be made false.
	5.	 Brown is not a color. == Necessarily false/It cannot be made true.
	6.	 Not being able to see, he was blind. == Necessarily true/It cannot be made false.
	7.	 Consciousness consists in having mental states. == Necessarily true/It cannot be 
made false.
At this point, you realize that analytic sentences cannot be disputed; if a debate 
or dissension arise around them, that shows confusion; the disagreement is not gen-
uine but rather it is a pseudo-disagreement. The debaters might not realize this. 
They are still confused regarding what they are doing.
To lay down an analytic truth false or an analytic falsehood as true commits logi-
cal nonsense or absurdity. This is not a psychological or subjective assessment. The 
meanings of the words are objective in a language; if they change over time, dynam-
ically and organically, they still are rendered fixed in their new meanings; this is 
how language works: if meanings were up for grabs, we could not use language as 
1  What Logic Studies

53
a currency for communication. Because analytic sentences are decidable – whether 
they are true or false – based only on the meanings of the words in them, it follows 
that their status – true or false – is not negotiable.
Examples of Nonsensical Usage and Interesting Cases 
	1.	 Triangles had four angles on that strange planet. == Nonsense; it is not a matter 
of creative ingenuity; of course, standard meanings of “triangle” and “angles” 
and “four” are assumed.
	2.	 She woke up and conversed with us but without regaining consciousness. == 
Nonsense.
	3.	 If you can see nobody, you must have really good eyesight. == Nonsense; 
“nobody” is not a name.
	4.	 The moon is not earth’s satellite. == Nonsense.
	5.	 A miracle happened since it is so rare for someone in his condition to survive. == 
This is interesting: if the definition of “miracle” we are working with is “viola-
tion of the lawlike regularities of nature,” so that no physical explanation is avail-
able in the case of a genuine miracle, then this has to be false by definition and 
cannot be stated. Is it possible to work with a different definition of “miracle?” 
Context is important in this case.
	6.	 Abstract objects do no occupy space. == Is it part of the definition of “object” 
that “it is located in space”? The answer is negative; we have meaningful usages 
of phrases like “abstract object.” This is not nonsense! There is a famous philo-
sophic view, thanks to Immanuel Kant, that there are sentences – like “an object 
is in space” – which, although not analytic, are known with absolute certainty or 
a priori. Notice, however, that we are keeping these matters separate: knowledge 
issues we don’t mix with logical assessments. This is an advanced subject but it 
is worth whetting an appetite for it.
	7.	 The square root of four is a beggar. == Violation of the defined meanings of 
words; this is what Aristotle called a “category mistake.” It is another matter if 
there is some interpretative key by which the sentence above is found to have 
another meaning; on its face this is a nonsensical sentence.
Logical truths/falsehoods are decidable as being true or false based only on the 
meanings of the logic-words in the sentence. They are also necessarily true or 
false – whatever they are – and these truth values cannot be reversed without com-
mitting nonsense. We have spoken of logic-words already in this text. We will offer 
now examples of logical truths and falsehoods. In another part of this text we will 
also have the terms tautology (for logical truth) and contradiction (for logical false-
hood.) Logical truths and falsehoods can be considered analytic: the meanings of 
words in them – the logic-words – are responsible for rendering them necessarily 
true or false. To deny or negate a logical truth or affirm a logical falsehoods is to 
commit nonsense. That is why stating a contradiction is nonsensical: a logical con-
tradiction is necessarily false (because of the meanings of “not” and “and”) and 
cannot be rightly or properly affirmed or assented. Thus, to lay it down as presum-
ably true is a nonsensical move in the language game. It is not straightforward 
1.6  Logical Truths/Falsehoods and Analytic Sentences

54
always to determine that we are dealing with logical truths or logical falsehoods. 
Who would ever imagine that the following is a logical truth? Observe how mind-­
bogglingly difficult it is to follow what the meaning of this sentence is.
If, assuming that if we assume that it rains then the game is canceled, it fol-
lows that it rains, then, it definitely rains.
What about this? This is a logical contradiction – thanks to the standard mean-
ings of “if then” and “not” and the inclusive sense of “either or.”
Even though it is the case that either it doesn’t rain or the game is canceled, 
still it might rain without the game being canceled.
It might seem that these are convoluted, rather unnatural, sentences when it 
comes to the way people speak; but these are only examples and we can easily run 
into logical forms that are those of logical truths and logical falsehoods, without this 
being detected. People have special difficulties with double negations, with “if 
then,” with “either or” of which there are actually two meanings – to mention only 
a few examples; when it comes to logic-words whose behavior we don’t study in 
this text, there are severe difficulties for the average user of the language when it 
comes to modal concepts like those of necessity and possibility.
Examples of Logical Truths and Logical Falsehoods 
	1.	 Even though someone came to class, no one came to class. == Necessarily false/
It cannot be made true.
	2.	 It is raining and it is not raining. == Necessarily false/It cannot be made true.
	3.	 Either it is raining or the game is canceled but it is not the case that it is neither 
raining nor the game is canceled. == Necessarily false/It cannot be made true.
	4.	 Given that, if it is raining then it is not raining, then it is not raining. == 
Necessarily true/It cannot be made false.
	5.	 Since Mary students, then there is at least one student. == Necessarily true/It 
cannot be made false.
	6.	 Because it is possible for someone to go to Australia, there is someone who can 
possibly go to Australia. == It seems that this is not a logically true sentence, unless 
you are dealing with a context in which the things you have are fixed or increase in 
number without any dropping out. This is a modal-logic issue which will not detain 
us here. Note that words like “necessarily” and “possibly” are indeed logic-words 
although the study of their logical behavior is beyond our present scope.
	7.	 John and Jack are the same person, but John is a student and Jack is not. == 
Necessarily true/It cannot be made false. You are not excited by this, but it is an 
interesting observation that identity – which in logic is treated as reference-of-­
names-to-the-same-entity – is a logical word! Notice, on the other hand, that 
other uses of the verb “to be” are not logical words. For instance,
Mary is a student.
is not an analytic or a logical sentence.
1  What Logic Studies

55
Sentences that are not analytic are called synthetic. Specifically in the case of logi-
cal truths and falsehoods, sentences that are neither logical truths nor logical false-
hoods are called logical contingencies, logically indeterminate or logically indefinite 
sentences. This is, again, a matter of the meanings of the words in them: based on 
those meanings, we cannot determine if the sentence is true or false; recourse to the 
realm of events – how the world works – is needed. Examples follow of synthetic 
sentences and also of logically contingent or indeterminate sentences. These are the 
informative sentences of language. We say that a synthetic sentence or – if it is a mat-
ter of the logic-words – a contingent sentence can possibly be true and can possibly be 
false; of course, no sentence can be both true and false in the same context; but, pos-
sibly means in some alternative case that we can conceive. Think of the central circle 
as the standpoint from which you make the evaluation as to true-false; the other circles 
are logical alternatives: it doesn’t matter that they are not the actual state of affairs; all 
that it matters is that they are logically possibly. We can think of them as consistent 
stories that can be told – exhaustively about all things. Although our actual world and 
its narrative are privileged in some ways, that does not matter for the study of logic. 
The actual state is only one logically possible state.
Logically necessary sentences must have the same truth values (true or false) in 
every logically possible state. Synthetic sentences and contingencies, on the other 
hand, can possibly be true and can possibly be false – although not both true and 
false in the same state, because that would be nonsensical as we have learned.
1.6.1  Exercises
	1.	 It is not true that the earth has more than one moons. Is it, however, a matter of 
logical necessity that this is so? On the basis of this reflection, also answer if the 
sentence “the earth has two moons” is a tautology, a contradiction or logically 
indefinite (a logical contingency) which can be logically possibly true and logi-
cally possibly false.
	2.	 Are the following sentences expressing statements that are syntactically or 
semantically-formally analytic or synthetic?
	a.	 If the triangle has three angles, then the triangle has three angles.
	b.	 If the triangle has three angles, then it does not have four angles.
	c.	 Either the triangle has three angles or the triangle does not have three angles.
	d.	 If all triangles have three angles then it is not the case that some triangles do not 
have three angles.
	e.	 If every triangle has three angles and there is a triangle in the room, then there is 
something in the room that has three angles.
	f.	 Some triangles have two angles.
	g.	 Any geometrical figure that does not have three angles is not a triangle.
	h.	 Any geometrical figure that has two angles cannot possibly be a triangle.
	i.	 No triangles have more than three angles.
1.6  Logical Truths/Falsehoods and Analytic Sentences

56
	j.	 It cannot be the case that some triangle both does and does not have three angles.
	 3.	 What is wrong with the view that someone’s arguments may be valid for that 
person but not for some other person?
	 4.	 Why is it not important for assessing arguments whether those arguments are 
actually or in fact persuasive in conversation?
	 5.	 Can a work of fiction about alien worlds be inconsistent without, nevertheless, 
being meaningless? Can such a work be meaningless, as mandated by the 
objects it describes, and yet be regarded as meaningful insofar as it is descrip-
tive of an alien and incomprehensible world?
	 6.	 If the premises of an argument form are all logical falsehoods (contradictions), 
then we cannot have any instance of this argument form in which all the prem-
ises are true and the conclusion is false: therefore, this argument form has to be 
accepted as valid. Do you agree? Discuss. Is it different if only one of the prem-
ises is a logical falsehood? What about the case in which the conclusion of the 
argument form is a logical truth?
	 7.	 Do the observations in the preceding exercise apply in the cases in which the 
premises and/or conclusion are not semantically analytic (logical truths or logi-
cal falsehoods) but are, instead, syntactically analytic? Discuss.
	 8.	 Shouldn’t “no triangle has four angles” be validly deducible from “all angles 
have three angles?” But here we are dealing with meanings of non-logical 
words (like “triangle”) and, hence, with syntactic analytic truths: not with for-
mal truths. We should not expect this proof to go through in logic. Isn’t this a 
problem? If not, why not? Discuss.
	 9.	 When we detect inconsistencies in stories, we still do not grant logical permis-
sion to derive any conclusion whatsoever. But, given the definitions of the con-
cepts we have presented, inconsistent premises with any conclusion whatsoever 
must be accepted as valid. (Why is this? See preceding exercise.) It would be a 
different kind of logic in which this inferential license is blocked. Is this a prob-
lem for the standard logic? Discuss.
	10.	 We say that logical truths/falsehoods are true/false regardless of context. 
Argument forms that are valid are likewise valid regardless of context. What 
does this mean? How is it related to the characterization of deductive logic as a 
non-­empirical enterprise? Can we define “logically necessary” and “logically 
possible” by reference to a concept of context (understood as a complete and 
consistent description of a logically possible state of affairs)?
1  What Logic Studies

57
© The Author(s), under exclusive license to Springer Nature 
Switzerland AG 2022
O. Makridis, Symbolic Logic, Palgrave Philosophy Today, 
https://doi.org/10.1007/978-3-030-67396-3_2
Chapter 2
Concepts of Deductive Reasoning
Reasoning comes in two varieties – inductive and deductive. There is a view that 
there is a third case – inference to the best explanation, which is dubbed Abductive 
Reasoning. We will disregard that here. When it comes to applying mathematical 
tools we have available to study logic, we can only pursue deductive reasoning by 
formal means (mathematized formal, systematic methods.) The rest of our text is, 
accordingly, devoted to deductive logic.
Logic specializes in evaluating arguments – among other things – and we need to 
determine correctly if a given argument is deductive or inductive in order to evaluate 
if it is a “good” argument or not: different standards apply in the two cases. Think 
of an argument as a proof. Logicians use the term “argument” and this is the word 
we will be deploying as the relevant technical term. As a first step, think about what 
a proof is. Do not think of the act of putting a proof down. Do not think of whether 
the proof is in fact accepted – people could be wrong in thinking that the proof 
works or not. Concentrate on thinking of the proof as the entirety of the lines you 
would have if you could see this proof from the premises to, and including the con-
clusion. This is a collection of meaningful sentences. We can say that the collection 
of meanings, one of which is the conclusion that is drawn, constitutes the proof; the 
meanings are so encompassed as to relate all the premises taken together to the 
conclusion those premises are supposed to be proving. Let us make an effort to see 
this as a relation between the sentences (or meanings) that are given (the premises) 
and the conclusion that is supposed to be derived from those premises. (Having 
elaborated on this issue, we use “sentence” and “meaning” interchangeably and 
trust that there is no ambiguity or confusion.) The crucial question is: does this 
proof work? Is it successful in proving what it is supposed to be proving?
In mathematics, you always get proofs, informally – which means that you don’t 
get information about what rules of inference license or justify moving from lines to 
the next lines and all the way to the conclusion. Not only in mathematics but in 
everyday life too and certainly in the various fields of studying and when debates 
are carried out and theories or claims are supported – we are constantly subjected to 

58
proofs. Parts of the proof may be missing and presumed to be obvious or to be fig-
ured out by the competent reasoner. The proofs may be inductive or deductive. (In 
mathematics, you should know, all proofs are always deductive.) The rational per-
son should not accept claims, which can be challenged, without proofs.
Well, this could be debated when it comes to certain contexts: for instance, 
should you demand sufficient proof that the team you play for will win, if they have 
been losing for very long, before you commit your efforts to it? Or is there an over-
riding moral obligation to contribute to the team spirit and serve your team even if, 
as a reasonable person, you should draw the conclusion that your team is bound to 
lose again? In general, however, the right principle to abide by can be agreed to be 
this: the rational person should not accept challengeable claims without sufficient 
proof. We need to be able to assess proofs – but this is something that you will be 
taught only in a class like this!)
When we say that a proof, or an argument, is “good” or not, we are not being 
precise. There is an intuitive notion of an argument’s goodness: by argument we 
mean, always in this text, not an act of disputation or disagreement but a collection 
of sentences one of which is presented as a conclusion that “follows” from the other 
sentences – the premises. The word “follows” is itself imprecise and needs to be 
defined; moreover, different concepts are at work in the inductive and in the deduc-
tive case and these should be disentangled. The intuitive notion can be said to con-
sist also in that the premises “support” the conclusion so that, given the premises, 
we can “correctly” have the conclusion – which is a new sentence that we are then 
entitled to and which we can “have” and add to our stock of knowledge only if it is 
properly supported by the given premises. It is not a subjective matter if the argu-
ment is “good” or not. This is another reason why “good” is not only imprecise but 
also potentially misleading because it is not a matter of what seems good or feels 
good. A better word is “correct,” which we also used above in this series of attempted 
explications. This is still imprecise but we are getting closer. Final observation that 
is due in this paragraph is that, when we say that we are “entitled” to the conclusion, 
given the premises, we don’t have in mind a moral matter or something that is a 
moral claim or right. Everything has to do, rather, with reasoning; not perceiving, 
feeling, morally being entitled to.
To define this notion of correctness of a deductive argument, we also need the 
concepts of logical necessity and logical possibility. They seem to be prior to our 
concept of “correctness” of an argument – which we will be calling “validity” in the 
case of deductive arguments. A valid argument cannot possibly have all its premises 
true and a false conclusion (note the use of “possibly”); or, a valid argument that has 
all true premises must have its conclusion true as a matter of logical necessity (here, 
the concept of “necessity” is used.) We can draw on these observations for defining 
the concept of argument validity but it is then a good idea first to work on the con-
cepts of logical necessity and logical possibility, which are themselves not readily 
accessible to intuitions.
Think how you might be able to tell alternative stories – not necessarily confin-
ing yourself to actual descriptions of events but also creating descriptions of worlds 
that are not actual or real but they are, nevertheless, possible in a logical sense. 
2  Concepts of Deductive Reasoning

59
There are nuances to this, which we should bring out. A world like that – which we 
call a logically possible world – is obtained through its description; this description 
should be consistent (and this is a concept that you will study in this text); it is also 
supposed to be a full description (having all conceivable sentences as either true or 
false – whatever they happen to be in this logically possible world.) This seems like 
an unattainable enterprise but you don’t need to worry about this in the present con-
text: we are using this device to help us understand some elusive concepts like “logi-
cally possible.”
Here is the catch: Can you make a sentence true in any logically possible world? 
If yes, this is a logically possible sentence. If not, it is a logically impossible sen-
tence. The same can be done with false. Do you have to make a sentence true in 
every logically possible world? If yes, it is logically necessary; if not, it is not logi-
cally necessary.
 
2  Concepts of Deductive Reasoning

60
 
Now we can explicate the concept of deductive validity by using such concepts 
as necessity and possibility in addition to our fundamental concepts of true and false.
2.1  Argument Validity
A deductive argument that is rightly acceptable is called valid. This is a technical 
term which we will learn. Only deductive arguments can be valid. As we have men-
tioned, inductive arguments can be relatively strong or weak. Validity, on the other 
hand, is a characteristic only of deductive arguments and, in the standard logic, it is 
not a matter of degree or relative strength or probability. A deductive argument that 
is not rightly acceptable – it not valid – is called invalid. We only have the options 
that a deductive argument is valid or invalid. There is no other option. Thus, if not 
valid, a deductive argument is invalid. If not invalid, it is valid. Every deductive 
argument has to be one or the other – valid or invalid; it cannot be both; it cannot be 
neither. This is like the case of a light switch that can either be on or off; it cannot 
be both on and off (this is a nonsensical suggestion); and it cannot be on or off by 
degrees (as in the case of a dimming light-mechanism.)
A deductive argument has a characteristic form, which is called an Argument 
Form. It is this form, the argument form, which is actually characterized as valid or 
invalid. The argument itself is valid or invalid depending on whether its form is, 
respectively, valid or invalid. The argument we might be presented with is an 
instance or token of its argument form. We can say that the argument exemplifies, 
instantiates, or betokens its characterizing argument form, and we will not speculate 
2  Concepts of Deductive Reasoning

61
about what kind of thing such a form is although we can safely commit to regarding 
argument forms as abstract things.
We will now show examples of how deductive arguments exemplify argument 
forms. We start with a given argument in language (it has to be an argument, of 
course); then we box its logic-words; those are fixed, cannot be removed, they char-
acterize the logical form; next, we replace everything else by lines (which serve as 
variables) so that the same kind of line is used for the same sentence. We separate 
the conclusion from the premises by means of some metalinguistic symbol: we 
choose to use the metalinguistic symbol “/..” for this purpose. We are, thus, left with 
the argument form. This is certainly not the only way to write out an argument form. 
The argument form is something of a pattern or structure. It is this that determines 
whether the argument we are given is valid or not. The given argument is called an 
instance (or instantiation) of the argument form. We label the argument “A1” and its 
argument form “FORM1”. The logic-words in FORM1 are “if-then” and “not.” The 
first of these logic-words needs two sentences to connect while the second, “not”, 
works always on one sentence. 
Notice the variables, in this case symbolized by line-types. There is something 
figure-like about this. The variables hold the place for symbols for sentences – any 
pairs of sentences – to be placed in. We could use letter symbols for the variables. It 
is not important what we use, but, of course, for the sake of consistency, we should 
specify the symbols of a language and use only those symbols.
Looking back again at the preceding example, we can offer some additional 
observations. The logical form of the argument – aptly called argument form – was 
presented. The fixed words – not replaced by variables – are the logic-words “if-­
then” and “not.” If we consider the given argument and how it matches the form, we 
may reformulate it as follows. This does not come across as good idiomatic English 
but we are extracting here is not the surface linguistic grammar but the logical gram-
mar of the argument. 
A1
If  it rained, then the game was canceled. The game was not canceled. 
Therefore, it did not  rain.
⇒
If  ---, then ___. Not ___. /.. Not ---.
FORM1.
If  (it rains at-such-and-such-a-time-at-such-and-such-a-place, etc.), then  
(the game is canceled at-such-and-such-a-time-at-such-and-such-a-place, etc.). 
not -(the game is canceled at-such-and-such-atime-at-such-and-such-a-place, 
etc.). Therefore, not -(it rains at-such-and-such-a-time-at-such-and-such-a-
place, etc.).
2.1  Argument Validity

62
Since “if-then” is one compact logic-phrase, we may want to spell out in the fol-
lowing fashion. Once again, this is not good idiomatic English but it shows us more 
perspicuously the argument form. 
You might wonder as to why we specify context-elements like space and time (and 
the “etc.” clause alludes to specifying all other relevant contextual elements.) Our 
logic requires that we fix all those elements: we presume them included in the senten-
tial content. We create, in this way, what are called “eternal sentences.” This is because 
our logic works in such a way that we cannot track how truth values (true – false) 
change across dynamically shifting contexts. For instance, if our sentence is “the 
game is canceled”, then this sentence – or, rather, its meaning – is true when, indeed, 
the game is canceled and it is false otherwise. If, however, we are dealing with a sen-
tence like “the game is canceled at such-and-such a time” we can see that this sentence 
is true or it is false forever. We stipulate that we are dealing with such context-free 
sentences. This is a detail for purposes of an introductory text but we mention it for the 
sake of completeness. Notice also how this also reinforces the point we keep repeat-
ing – that our formal logical systems do not record empirical or factual occurrences. 
But something else is also at stake: as mentioned, we do not have the mechanisms we 
would need to track how truth values (true – false) change across changing contexts. 
This, however, does not interfere with the success of our logical formalism when it 
comes to achieving the purposes we set for it. As you will find out, such purposes 
include checking correctly if an argument form is valid or invalid. Roughly, this means 
correctness or incorrectness of the deductive argument, but we need to define the 
terms precisely. Insofar as we can translate arguments from English into our formal 
language so that we capture their argument forms, then we can check if those argu-
ments are valid or invalid. This is a significant feat.
Here are other examples, all of them in sentential logic. This means that we only 
“see” logic-words for which we will have symbols in sentential logic: these are 
symbols for what we call connectives. These are logic-words  – their meanings 
depend on how they interact with true and false. For instance, “not” is defined as the 
part of language that changes true to false and false to true. This is its meaning. It is 
a logic-word. The same is the case for “and”, “either-or,” and many other words – 
not all of which we can list here. Any expression whose meaning changes when the 
truth values (true-false) of its atomic variable parts change is a connective. In 
If -then  [(it rains at-such-and-such-a-time-at-such-and-such-a-place, 
etc.), (the game is canceled at-suchand-such-a-time-at-such-and-such-a-
place, etc.)].
Not -(the game is canceled at-such-and-such-atime-at-such-and-such-a-
place, etc.).
Therefore, 
not -(it rains at-such-and-such-a-time-atsuch-and-such-a-
place, etc.).
2  Concepts of Deductive Reasoning

63
predicate logic, we will also have symbols for logic-words like “every” and “some” 
and we will also be able to symbolize names and logical predicates.
A2.
Either the treasure is to the left or it is to the right. It is not to the left. Therefore, 
it is to the right.
⇒ Either  the treasure is to the left or  it is to the right. It is not  to the left. 
Therefore, it is to the right.
⇒
Either  --- or  ___. not  ---. /.. ___.
FORM2.
We have said that an argument is valid if and only if its argument form is valid. 
This is the same with all the following.
If the argument is valid, then it has a valid argument form.
If the argument has a valid form, then it is valid.
If the argument does not have a valid form, then it is not valid (it is invalid.)
If the argument is not valid (it is invalid), then it has an invalid argument form.
It is not possible that the argument has a valid form and is invalid.
It is not possible that the argument is valid and has an invalid argument form.
A3.
Either it rains or it doesn’t rain. If it rains, then the game is canceled. If it doesn’t 
rain, then we lose. So, either the game is canceled or we lose.
⇒ Either  it rains or  it does not  rain. If  it rains, then  the game is can-
celed. If  it does not  rain, then  we lose. So, either  the game is canceled or  
we lose.
⇒
Either  --- or  not  ---. If  ---, then  ___. If  not  ---, then  <<<. So, either  
___ or  <<<.  FORM3.
Notice that we alter the grammar of the sentences – and we do this while we are 
capturing the logical grammar or logical form. In the next example, working with 
the same argument still, we show more perspicuously how we proceed as follows:
A3
Either it rains or it doesn’t rain. If it rains, then the game is canceled. If it doesn’t 
rain, then we lose. So, either the game is canceled or we lose.
⇒
Either (it rains) or not (it rains). If (it rains), then (the game is canceled.)
If not (it rains), then (we lose.) /.. Either (the game is canceled) or (we lose).
Now we can legislate replacements of the bracketed sentences by variables.
It rains: ---.
The game is canceled: ___.
We lose: <<<.
2.1  Argument Validity

64
Thus, we get:
Either  --- or  not ---. If  ---, then  ___.
If  not  ---, then  <<<. /.. Either  ___ or  <<<.
What do you think of this variation of our game of how to extract the argu-
ment form?
Either Or(it rains, not (it rains)). If Then(it rains, the game is canceled).
If Then(not(it rains), we lose).
So, Either Or(the game is canceled, we lose.)
⇒
Either Or(−--, not ---). If Then(−--, ___).
If Then(not(−--), <<<).
So, Either Or(___, <<<.)
The argument forms have variables replacing content-specific sentences. 
Variables are placeholders – they show the formulaic space where symbols of a 
certain kind can be inserted. For instance, 
For all x, all y and all z(x  + y  = z )
2
2
2  –
with x and y standing for the sizes of any right-angle sides and z standing for the 
size of the hypotenuse of the same triangle. The letters are variables.
Now, back to our argument forms. The variables hold the place for sentence 
symbols. This shows us that deductive argument validity has nothing to do with the 
content of what is being discussed. All that matters is the meanings of the logical 
parts – and those are the fixed words that do not get replaced by variables in the 
argument forms.
Now, we proceed to defining validity.   
  
Argument Validity.
Argument Form: P1, … Pn ⊢ C ========= Premises –Conclusion.
[Definition] Valid Argument Form.
It is not logically possible (it is logically impossible) for any instance of 
the form to have all the premises true and the conclusion false.
If the premises are all true in any instance of the form, then as a matter of 
logical necessity the conclusion has to be true too.
[Definition] Invalid Argument Form P1, … Pn ⊬ C.
It is logically possible for an instance of the form to have all true premises 
and a false conclusion.
It is not logically necessary that every instance of the form has to have a 
true conclusion if it has all its premises true.
2  Concepts of Deductive Reasoning

65
A valid argument form cannot possibly have an instance with all true premises 
and a false conclusion. When it comes to arguments in the language, which are 
instances of valid argument forms, we might still find that their premises are not all 
true. Does this mean that something has gone wrong with our conceptualization of 
validity? Not really. But this is one of the matters that puzzle and distract beginners; 
to counteract this predicament, we need to rivet our attention to this standard issue 
of introductory logic.
COUNTEREXAMPLE.
[Definition] An instance of an argument form with all true premises and 
false conclusion.
An argument form is invalid if and only if it has at least one 
counterexample.
[“If and only if” is an if-then that goes in both directions: accordingly, the 
above can be read:
If an argument form is invalid, then it has at least one counterexample; and, 
if an argument form has at least one counterexample, then it is invalid.]
Examples.
(FORM1) If P then Q, not-P ⊢ not-Q.
Instance 1 of FORM1: If you are from the US, then you are from the coun-
try exactly south of Canada. You are not from the US. ⇒ You are not from the 
country exactly south of Canada.
In Instance 1 we have all true premises and true conclusion. But this does 
not establish that FORM1 is valid. Remember, it takes even one 
COUNTEREXAMPLE (an instance of the form with all true premises and 
false conclusion) to establish invalidity.
Instance 2 of FORM1: If you are from New York, then you are from the 
US. You are not from New York. ⇒ You are not from the US.
--This instance (Instance 2) is a COUNTEREXAMPLE to FORM1. WHY?
Because, here we can make all the premises true – think about it – and we 
can also make the conclusion false! (The person we refer as “you” in this 
could be from another US State.)
2.1  Argument Validity

66
1. If the United States is south of France,
Then the United States is north of Germany.
2. The United States is south of France.
/.. Therefore, the United States is north of Germany.
Here we have all the premises as false; the conclusion is false too. But the argu-
ment is an instance of a valid argument form, shown as follows. 
If  P, then  Q; P ⊢ Q.
The point is this: IF the premises are all true, then it is logically impossible for the 
conclusion to be false. If it were true that the United States is south of France – and if 
it were also true that being south of France entails being north of Germany – then it 
would be logically necessary that the United States be north of Germany. Clearly, this 
is an alternative world, not our actual world. But, from the point of view of deductive 
relations, it is irrelevant what happens in any particular world – including our actual 
world which is, after all, one of an open-ended number of logically possible worlds. 
This is a good opportunity to contemplate on how deductive reasoning is not depen-
dent on empirical considerations – or on any empirically discoverable details about 
what happens in any world. This independence of deductive argument validity from 
empirical matters is also in evidence in that you can put any sentences in for the vari-
ables: regardless of the content of those sentences, the argument form yields valid 
arguments (if the form is valid) and invalid arguments (if the form is invalid) because 
the argument form is determined as valid or invalid singly by the meanings of the 
logic-words in it – which, in the preceding example, is the phrase “if-then.”
Now, the alternative world in which all the above odd (from our actual stand-
point) geographical configurations happen is itself not our actual world but it is a 
logically possible world. Think of such an alternative world. Look again into the 
example. In this world, let us focus on the premises and accept them as true. Build 
this world on the basis of the given premises. The map of this world has the United 
States being south of France and north of Germany. This makes the premises true. 
The conditional or implicative sentence (“if the United States is south of France, 
then it is north of Germany) is made true: both antecedent and consequent are true 
and this makes a conditional sentence true. The other premise is “the United States 
is south of France.” Now, we examine the conclusion: “The United States is north 
of Germany.” Look at your alternative-world map. There is NO way to make the 
conclusion true. The conclusion has to be true; it is logically necessarily the case 
that the conclusion is true given that the premises are true. It is not logically possible 
for the conclusion to be false while the premises are all true. Thus, this is a valid 
argument. It does not matter that our instance of the argument form has premises 
and conclusion describing some alternative world; this is irrelevant to assessing 
validity or other deductive-reasoning properties.
We may speculate as to whether we can actually have nonsensical sentences 
instantiating the variables in a valid argument form and still declare the resulting 
argument to be valid. Let us consider, again, the valid argument form of the preced-
ing example: 
2  Concepts of Deductive Reasoning

67
If  P, then  Q; P ⊢ Q.
The pattern is characteristically present if we instantiate P by “gobblegobble 
drug blodigoggle” and Q by “drack druck garg”. We have:
If gobblegobble drug blodigoggle, then drack druck garg. Gobblegobble drug 
blodigoggle. Therefore, drack druck garg.
Validity is a matter of pattern – argument form. Whether the premises are even 
true does not matter, as we have examined and explained. But do the premises and 
conclusion have to be meaningful – capable of being true or false? Given our defini-
tions of concepts, it seems so. The semantic definition of validity we have been 
working with includes the notions of true and false as truth values; it follows, then, 
that we are stipulating that the exemplars of argument forms are meanings (the only 
kinds of thing that can be true or false.) It does appear, on the other hand, that the 
argument form itself, as a figure-like or shape-like pattern, is discernible and the 
game of matching instances with forms can be played regardless as to whether we 
have meaningful sentences or not. It would require a different approach to setting up 
our definitions of concepts, though, to work with such a game: for one, “true” and 
“false” should not be included in the definitions of the relevant concepts. It is an 
interesting question if we can proceed along alternative lines (without the concepts 
of true and false but with other appropriate concepts) in defining some concepts that 
can then be shown to match our semantic concepts (which use true and false in their 
definitions.)
Another way of defining validity: An argument form is valid if and only if the 
truth of the premises provides absolute support – or guarantees, or necessitates – 
the conclusion. The support we are talking about is logical – it is not a matter of 
what you might perceive or what opinion you could form subjectively.
Here is yet another way of defining validity – of course, we are defining the same 
concept even by using alternative ways: An argument form is valid if and only if the 
truth of the premises is necessarily preserved in the conclusion. This sounds some-
what unnatural in ordinary English but think of the truth of the premises (if the 
premises are all true) in terms of a metaphor: you have the ball in your hands (this 
is “all the premises.”) It does not matter if this factually the case; assume it! Dropping 
the ball (going to a false conclusion even when all the premises are true, when you 
have the ball in your hands) – this means that you lose the game: invalidity. True 
must be preserved for validity. IF the premises are all true, then the conclusion must 
be true. There are some difficult concepts here that you need to pay attention to. 
Words like “necessarily” and “possibly” and “must” are not easy to process; and 
such words do appear in our definitions. The point is that if you kept finding your-
self in a case in which you happen to have the ball (truth of all the premises) then, 
no matter how many times this is repeated, you don’t drop the ball (the conclusion 
is also true): this is a winner! This is a valid argument. If there is any possibility that 
you have the ball (all the premises are true) but you drop it (the conclusion is false), 
then this is an invalid argument – a loser. It does not matter how often this happens; 
2.1  Argument Validity

68
even once is bad enough. Thus, we can say things like “a valid argument guarantees 
support for the conclusion” or “a valid argument’s premises provide absolute sup-
port for the conclusion.”
Notice that you cannot tell, based on intuitions or hunches or by using some skill 
you have naturally or from previous studies, whether an argument is valid or not or 
whether an argument’s form is valid or not. Invalid forms can have misleading 
instances that may come across as being valid. We are misled by psychology but 
logic and psychology do not go together. It is not inherently something about the 
form to be capable of being instantiated by “misleading” instances: we are misled 
by subjective and broadly psychological factors. The instances of a valid argument 
form are all necessarily valid.
It should not be surprising that truth and falsehood play this role in the definition 
of argument validity. The conclusion of an argument is something new. It has to be 
a new, previously unknown to us, sentence. If we do not need to derive it, it is not a 
conclusion. When knowledge expands, this happens by drawing conclusions too. 
The conclusions are not in the stock of knowledge we have had so far. This also 
means that any expert draws conclusions not as an expert in her field but by per-
forming a logical operation. The new sentence, which we did not have until we drew 
it from premises, is the conclusion: it is unacceptable, incorrect, to be avoided that 
we draw a conclusion that can be false even if our premises are true. You need to 
note that the expression “if-then” in the preceding sentence is also one of those 
expressions that give trouble and cause confusions. We are not saying that the prem-
ises have to be true: we are saying that if the premises are true, then the conclusion 
has to be true as a matter of logical necessity for the argument to be valid.
To lose the game is to be facing the possibility (mere possibility) that your 
conclusion may be false even though all the premises are true. This is invalidity. 
Technically, as we have presented it, an instance of the given argument form with 
all true premises and a false conclusion is called a counterexample to the given 
form. We can then give yet more definitions of our concepts: An argument form is 
valid if and only if it has no counterexample. An argument form is invalid if it has 
any counterexample. We showed a counterexample to a given argument form 
above but, in this text, we will not be working with attempts to conjure up coun-
terexamples to given forms. We will have mechanical procedures in sentential 
logic, which we can apply or implement to determine if there is a counterexample 
or not. We will be able to specify this counterexample. This is the case for two 
methods we will study – the truth table and the tree method. Once our implemen-
tation of the method yields a counterexample, we determine that we have an 
invalid argument. If the method yields no counterexample, we determine the given 
argument form to be valid.
Let us see some examples of argument forms, with the logic-words in them, 
boxed. We see examples of valid and of invalid argument forms. Of course, we can-
not produce an exhaustive list.
2  Concepts of Deductive Reasoning

69
Valid Argument Forms. 
Invalid Argument Forms. 
It is important to note that the standard logic of sentences cannot handle certain 
linguistic logic-words which require more advanced logics to accommodate a study 
of their logical behavior. Such logic-words are called non-truth-functional. We are 
ready to reveal a secret about what is happening here. The basic sentential logic is 
If  P, then  Q. P. ⊢ Q.
If  P, then  Q. Not -Q. ⊢ Not -P.
If  P, then  Q. ⊢ If  not -Q, then  not -P.
Either  P or  Q. Not -P. ⊢ Q.
Either  P or  Q. Not -Q. ⊢ Not -P.
Either  P or  Q. If  P, then  R. If  Q, then  R. ⊢ R.
If  P, then  Q. If  Q, then R. ⊢ If  P, then  R.
P and  Q. ⊢ P.
P and  Q. ⊢ Q.
P and  Q. ⊢ Either  P or  Q.
If P, then  If  Q then  R. ⊢ If  P- and -Q, then  R.
If  P- and -Q, then  R.⊢ If P, then  If  Q then  R.
It is not  that it is not  that P. ⊢ P.
If  P, then  Q. If  not -P, then  Q. ⊢ Q.
If  P, then  Q. If  P, then  not -Q. ⊢ Not -P.
If  P, then  Q and  not  Q. ⊢ Not -P.
Not  (P and  Q). ⊢ Either  not -P or  not -Q.
Not  ( either  P or  Q). ⊢ Neither  A nor  B. ( Not -A and  not -B.)
If  P, then  Q.  Not -P. ⊬ Not -Q.
If  P, then  Q. Q. ⊬ P.
Either  P or Q. P. ⊬ Q.
Either  P or Q. ⊬ P.
Either  P or Q. ⊬ Q.
Not  both  P and  Q. ⊬ Not -P.
Not  both  P and  Q. ⊬ Not -Q.
If  P, then  Q. ⊬ If  Q, then  P.
2.1  Argument Validity

70
truth-functional, as we say. This means that its symbols refer to functions – believe 
it or not. The values that are inputs to those functions are true and false – and we call 
them truth values. The foremost characteristic of a function is that it takes inputs 
from a specified set to yield an output that is unique. The emphasis we need to place 
here is on “unique.” Consider the following examples of functions – shown in an 
informal fashion to cultivate intuitions. (For details on Set Theory and Functions, 
see chapter 9.)
•	 ℊ+(2, 3) = 5 [This is the familiar algebraic function called addition: it has to be 
defined as taking inputs from a set, the Domain of the function, and the specified 
output for each pair of inputs belongs to a set called the Range of the function; 
this is a binary function, which means that it always has to take two inputs. Let 
us specify the domain as D(ℊ+) = ℕ, the set of natural numbers; the range is, then, 
R(ℊ+) = ℕ, also the set of natural numbers. It is crucial that the output in each case 
is a unique member of the range.]
•	 Examples of mappings, as we call them, which are not functions! This is because 
the outputs are not always unique for all specified inputs or inputs pairs! son(x) 
=? —one might have more than one sons…
daughter(x) =?
teacher(x) =?
student(x) =?
•	 Here are more examples of functions, from the domain ℕ to the range ℕ. Some 
are unary and some are binary or even ternary functions (defined as having, 
respectively, one or two inputs.) The output is always one and, as we have already 
stressed, it has to be unique if the specified mapping is to be functional.ℊ1(x) = 
(x + 2)2.
ℊ2(x) = 2x + 4x2.
ℊ3(x, y)= √(x + y)3.
ℊ4(x, y) = x/y2.
ℊ5(x, y, z) = x/(y + (x +y)2).
We can go back to the language to see how we spot the logic-words that can be 
interpreted through truth-functional connectives in some idiom of formal logic. The 
special logic-words we have been regarding as fixed in the logical forms are defined 
basically in terms of true and false. This is their meaning. For instance, the meaning 
of “not” is: what turns true to false and false to true. The same for all the others: they 
are defined by the conditions under which the whole sentence is true – given the 
values of its ultimate simple components. And, conversely, if any phrase has a 
meaning that is based on truth conditions, that is a logic-word that is truth-­functional; 
rest assured that we express this word with our basic symbolic resources if we 
develop some sophistication in the study of formal logic.
Non-truth-functional words cannot be defined only by true-false. For instance, 
you can find sentences that are true but, historically, the first was true before the 
other; then, you can also find true sentences but, this time, they were historically 
true so that the second was true before the first. Try to understand what is happen-
ing here.  
2  Concepts of Deductive Reasoning

71
It is easy to see this. Here is the significance of this. From the standpoint of 
deductive reasoning, meaning is a matter of true and false. Rather, ignore the con-
tent and see how both sentences are true. Thus, we have:
BEFORE(True, True) is True (in the first case) but also BEFORE(True, True) is 
also False (in the second case.) This means that functionality breaks down: while we 
have the same specified inputs (<True, True>), yet we do not have a unique output: 
in one case we have True and in the other case we have False. Thus, “before” cannot 
be expressed by a truth-functional operator. 
Here are examples of non-truth-functional logic-words – indicated by a deletion 
while the truth-functional words are boxed as it was done in earlier examples. 
(S1) Ronald Reagan is a President of the United States. TRUE.
(S2) Barak Obama is a President of the United States. TRUE.
BEFORE(S1, S2): TRUE.
BEFORE(S2, S1): FALSE.
Since both S1 and S2 are TRUE, we have:
BEFORE(TRUE, TRUE) = TRUE.
and BEFORE(TRUE, TRUE) = FALSE.
BEFORE(True, True) = True or False.
Necessarily, if  P then  Q.
It is generally believed that P.
It is possibly not  the case that Q.
Either  it is always the case that P, or  it is not  necessarily the case that Q.
It is morally obligatory that P.
It is known that P.
It is P before Q.
It is P after Q.
It will be true that P in the future.
It has always been true that P.
It is P specifically at location x.
It is physically impossible that light does not  bend around massive 
objects.
NOTE: because “not” is within the scope of “physically impossible”, we 
could express it at all.
2.1  Argument Validity

72
2.1.1  Exercises
	1.	 Extract the argument forms of the given arguments. Take the steps shown above – 
box in the logic-words and proceed to the extraction of the form.
	
a.	 Either it rains or the game is not canceled. But the game must be canceled. 
Therefore, it is not raining.
[Attention: “must” is a logic-word but not one that can be scanned by the basic 
sentential logic. This is what we explained above under “non-truth-functional 
words.”]
	
b.	 Since it rains, the game is canceled but we do not go home. [The word “since” 
has the logical, not the temporal sense.]
	
c.	 If you need to go there fast, you should take route X, but if you don’t care 
about how fast you get there, then it doesn’t matter how you travel there.
	
d.	 If the game is cancelled, it must have rained. Therefore, if it did not rain, then 
the game was not cancelled.
	
e.	 If it rains and the ball floats in a puddle of water, then the game is cancelled. 
Therefore, if it rains, then if the ball floats in a puddle of water then the game 
is cancelled.
	
f.	 If it rains, then the game is cancelled. Therefore, if it rains and the players are 
drenched, then the game is cancelled.
	2.	 Produce instances in English of the given argument forms.
	
a.	 If X but not-Y, then Z. Therefore, if not-Z, then either not-X or Y.
	
b.	 X and not-Y, but if not-Y then Z. Therefore, Z.
	
c.	 If X and Y. Therefore, Y or Z.
	
d.	 Either X or Y, but not both X and Y; and not-X. Therefore, Y.
	
e.	 It is not true that if X then not-Y. Therefore, Y.
	
f.	 It is not the case that it is not the case that X. Therefore, X or Y.
2.2  Consistency
Another property we study in logic is that of consistency. This is a characteristic of 
a collection of sentences. It could be a theory we are talking about – a theory is a 
collection of sentences. A theory that is inconsistent has to be modified or aban-
doned. As with validity and invalidity, we have exactly two options here too: a col-
lection of sentences is consistent or it is inconsistent; it cannot be both; it has to be 
one or the other. Consistency is not a matter of degree – at least not in the case of 
the standard logic.  
2  Concepts of Deductive Reasoning

73
Suppose that we have sentences in our theory, which are symbolized as follows. 
The enclosing boxes show logically possible worlds and each such world is symbol-
ized by “@j” with the subscript being a positive number.
We use “{“and “}” to enclose members of a set and we separate the members of 
a set by commas. The set of sentences we have is: {Δ, Θ, Ξ}. This set is consistent 
insofar as there is at least one logically possible world in which all the sentences are 
true there. We have, let’s say, eight logically possible worlds; in two of them, all 
sentences are true there; that is sufficient to determine that the set of sentences is 
consistent.
@1: in this world none of the given sentences is true. Notice that this does not 
condemn our set to being inconsistent. We need at least one logically possible world 
in which all the sentences are true there. Focus on this to understand how “possibly” 
works: at-least-one-state suffices to establish logical possibility. Some texts use the 
term “satisfiability” for a set of sentences that can possibly be true together. 
(Parenthetically, and for the sake of completeness, let us point out that this is not the 
same as the concept of “possible worlds” used in modeling modal logics: ours is 
merely a pedagogical device.) 
A collection of sentences is consistent if and only if it is logically possible 
for all of them to be true together. Another way of saying this: A collection of 
sentences is consistent if and only if it is logically possible that the conjunc-
tion of the sentences is true. (Conjunction as a logic-term means that we join 
the sentences with “and.” We can join as many sentences as we like with 
“and” – we are joining two at a time and then the compound sentence that is 
generated in this way is joined with the next sentence, and so on. Conjunction 
so defined has a pleasant property you should try to get used to: the compound 
sentence that is a conjunction-sentence is true if and only if all the conjoined 
sentences are true. “If and only if” means that the implication – if-then – goes 
in both directions.)
Accordingly, a collection of sentences is inconsistent if and only if it is not 
logically possible for all of them to be true together; it is not logically possible 
for their conjunction to be true.
Δ Θ
Θ
@2: the sentences Δ and Θ are true in this possible world. 
2.2  Consistency

74
@8
We can think of these worlds as being presented through their exhaustive descrip-
tions; notice that we are only laying down conceptual tools to facilitate our understand-
ing and we do not need to enter into specific details (for instance, it should be also 
understood that any sentence whatsoever is either true or false in every possible world 
for this way of modeling to be used in certain applications but this does not concern us.)
Since there is at least one logically consistent – logically possible – narrative we 
can present with all the sentences in the narrative, this means by definition that the 
theory composed of these sentences is logically consistent. The narrative would be 
about logically possible world @6: that is the one world in which all the given sen-
tences are true there. It doesn’t matter if the narrative for logically possible world @6, 
where all the sentences are true together, describes our actual world; all that matter is 
that it depicts some logically possible world. Perhaps, as an example, given the depic-
tions we have, our actual world is @7. None of the given sentences are true there! But 
this is a matter of empirical discovery and not of concern to deductive logic.
Here are instances or interpretations for the three sentences of our example that 
show this kind of case – they are not true at all in our actual world but there is a 
world, even if an alternative one, where they are all true together. It is not important 
that this alternative world is alien or fantastic from the standpoint of how nature 
works or how historical events have transpired. All that matters is the logical pos-
sibility that the sentences are all true together.
Θ
@3 
@4 
@5 
@6 
@7 
Ξ
Θ Ξ
Δ Θ Ξ.
Θ
2  Concepts of Deductive Reasoning

75
Interpretation(Δ): Pegasus, the flying horse, is a horse.
Interpretation(Θ): Jasmine rides the Pegasus every morning.
Interpretation(Ξ): Pegasus feeds on fire.
The following interpretations for the sentences, however, yield an inconsis-
tent set.
Interpretation(Δ): A triangle has four angles.
Interpretation(Θ): Jason studies geometry.
Interpretation(Ξ): Jasmine studies history.
It is bad enough that one sentence, as interpreted, sentence Δ, cannot be true ever 
because the meanings of its words makes it always false. This is an analytic and 
false sentence, based on the terminology we acquired in 1.4. Thus, it cannot be true 
ever, and, hence, it cannot be true together with the other two sentences; therefore, 
this set of sentences is not consistent (it is not logically possible for all of the sen-
tences in the set to be true together.)
2.2.1  Exercises
	1.	 Answer the following questions, trying to be as analytic and detailed as possible in 
your answer by using the useful strategy of referring to truth-in-possible-worlds:
	
a.	 Suppose that a set of sentences is logically inconsistent. Does it have to be 
that they are all false in every logically possible world?
	
b.	 Can an inconsistent set of sentences include logical truths (sentences that are 
necessarily true – true in every logically possible world)?
	
c.	 Can a consistent set of sentences include logical falsehoods or contradictions 
(sentences that are false in every logically possible world)?
	
d.	 If we form a pair of a sentence with itself, is this pair consistent or inconsis-
tent? Can you justify your response in terms of the possible-worlds narrative?
	
e.	 If we form a pair of a sentence and its negation, is this pair consistent or 
inconsistent? Can you justify your response in terms of the possible-worlds 
narrative?
	
f.	 Is a pair of two contingent sentences consistent or inconsistent?
	
g.	 If two sentences imply each other, we say that they are mutually equivalent. 
Suppose that we have two equivalent sentences. One set of sentences is con-
sistent and contains one of those equivalent sentences but not the other. What 
happens if we replace that one sentence of the set by its equivalent? Does the 
set remain consistent or does it become inconsistent?
	
h.	 If we can prove a logical contradiction from a consistent set of sentences, it 
shows that the set is inconsistent. Why is that? Can you account for your 
response in terms of the possible-worlds narrative? <As a clue, start: “if we 
can prove a sentence from a consistent set of sentences, that means that the 
provable sentence has to be true in every possible world in which the set-­
sentences are all true….” Now, you will have to end up showing that our set 
cannot be consistent in spite of the assumption we just made  – that it is 
consistent.>
2.3  Logical Status of a Sentence

76
	
i.	 If some sentences are all false in some logically possible world, why doesn’t 
that mean that the sentences cannot be consistent?
	
j.	 If we define logical necessity as the logical impossibility of being false, then 
how we can state a definition of logical consistency by using “necessary” 
instead of “possible?” <* This is hard: try starting by stating “a set of sen-
tences is consistent if and only if it is not logically necessary for them to be 
all ---.” Should you now refer to some or to all possible worlds? The difficulty 
in this has to do with the lack of familiarity we have when it comes to dealing 
with the concepts of necessity and possibility: notice that we have reduced 
these concepts and their relations to the concepts of “all” and “some” with 
these quantifiers used over logically possible world. Now the problem reap-
pears in a way because the conceptual relationship of “all” and “some” is also 
challenging. Focus on thinking how: “all” is the same in logical meaning with 
“not-some-not” and “some” is the same with “not-all-not.” >
2.3  Logical Status of a Sentence
A sentence has a characteristic logical status because of the logical form which the 
sentence shows or, as we can also say, instantiates or exemplifies or betokens. We 
should not think that we have to deal with any thorny metaphysical issues about 
what kinds of things those forms are. Having studied argument validity and consis-
tency, we noticed already that those characteristics were also a matter of form. It all 
seems to come back to logical form in deductive logic. An alternative – not incom-
patible – way of thinking about the deeper structural reasons for the logical charac-
teristics that are deductive is to say that the meanings of the logic-words confer 
these characteristics. Let us examine sentences, with a view to discerning their char-
acteristic logical status in each case, under both available approaches – the form-­
approach and the logic-word-approach.
Let us isolate the fixed words, which are the logic-words.
(Δ) If the players riot, then the game is over.
(Θ) If the spectators leave, then the spectators leave.
(Ξ) If the game is over, then the game is not over.
(Δ) If  the players riot, then  the game is over.
(Θ) If  the spectators leave, then  the spectators leave.
(Ξ) If  the game is over, then  the game is not  over.
2  Concepts of Deductive Reasoning

77
The logic-word is “if-then” in all three sentences. The logical form is an impli-
cational/conditional or if-then logical form. Any sentences could be substituted for 
the sentences connected by the if-then connective logic-word; essentially, these sen-
tences occupy placeholders – indeed they can be thought of as being entered in the 
place-holding open spaces that represent variables. But we cannot ignore, of course, 
repeated sentences: we are still dealing with non-fixed, variable place-­holding 
shapes but those have to be the same variables: this means that, once again, any 
sentence whatsoever can go in to fill the place of the variable but for each occur-
rence of the same variable the same sentence – whatever that sentence is – should 
be put in. Let us now “see” the logical forms. And, notice, how we have connected 
the logic-word approach with the logical form approach. As we execute the extrac-
tion of the form, we may first showcase the “shape” or form more closely by bypass-
ing grammatical peculiarities of the natural language, English in this case, in the 
following way. This way of putting things may well seem ungrammatical but we are 
actually getting now closer to isolating the logical form, which we can subsequently 
present as a shape by using as variables different types of lines. 
In one of the forms we also have an occurrence of “not” as a logic-word. Having 
arranged the representations of the sentences in this fashion, we have indeed iso-
lated the logic-words. To extract the logical forms is straightforward; but this will 
also create a problem: it may seem counterintuitive that the logic-words are in front 
of the variables they join. This is so in the case of the binary logic-words, which 
connect two variables. Not so with the unary logic-words, which operate or affect 
one variable at a time. The reasons why this seems counterintuitive may be because 
we are used to the linguistic grammar or even because we may detect, even without 
training, some affinity with arithmetical operations and there is a convention of 
using notation that places the binary operator symbols in between (as in writing “1 
+ 2” instead of “+(1, 2)”.) Whatever the reasons are, we will have to back down and 
reconfigure our representation of the shape, the logical form. 
Finally, we arrive at the logical forms written in a certain way (and we detect here 
the role played by extraneous issues like conventions and possibly psychological or 
habitually trained tendencies that may dictate why one convention rather than 
(Δ) If, then  (the players riot, the game is over)
(Θ) If, then the spectators leave, the spectators leave)
(Ξ) If, then (the game is over, not  (the game is over))
(FORM1-Δ) If, then  (__________, −-----)
(FORM1-Θ) If, then __________, ___________)
(FORM1-Ξ) If, then (____________, not  (____________))
2.3  Logical Status of a Sentence

78
another is adopted.) But we should be trying to cultivate trained intuitions as well 
by focusing on the forms as they are now showcased. (There is a structural element 
that we cannot get around, however: the “not” logic-word cannot be inserted into the 
sentential structure. This seems obvious; it should also alert us to the fact that we 
symbolize individual sentences as “blocks” or units or, as we should properly say, 
as unanalyzed sentential atoms. We do not have symbolic resources in the sentential 
logic to allow us to symbolize internal logically significant parts of sentences. This, 
however, changes when we move to predicate logic.) 
One of the forms (the form of sentence Θ) is true for any possible assignment of 
truth values to the individual or atomic component sentences. This type of sentence 
has the logical form whose logical status is that of a so-called tautology; other terms 
we can use are logical truth or necessary truth. The other two sentences have logical 
forms that have a logical status we call indeterminate or indefinite or contingent (or 
the logical status of a contingency.) This means that in some logically possible 
cases, the sentence is true and in some logically possible cases, the sentence is false. 
These are logically possible cases we are talking about. For instance, the sentence 
“the earth has exactly one moon” is indeed such a sentence. Its logical form in sen-
tential logic is that of a single line (if we stick still to the convention of representing 
the logical shape of an individual sentence by a line-type.) It is fundamental to the 
setup of deductive logic that an individual sentence can be logically possibly true 
and can be logically possible false – although not true and false in the same logically 
possible case.
It might seem odd at first that the sentence “the earth has exactly one moon” is a 
logically indeterminate (contingent) sentence  – it has a logically indeterminate 
structure or form. But the error in changing at this comes from mistaking actuality 
(factual actuality, historical given, or anything that is empirically settled) for logi-
cally necessary. The sentence “the earth has exactly one moon” is not logically 
necessary. It is certainly logically possible – it is not a logical contradiction, a sen-
tence whose logical form is false in every logically possible case, like the sentence 
“the earth has one moon and the earth does not have one moon” for instance. But 
this sentence can be false – it is logically possible that it be false: its form dictates 
this and here is how we can make sense of this. An alternative state of affairs can be 
constructed in which the sentence is false; this is not the actual state of affairs but it 
is still a logically possible state of affairs. That it is not actual is not a matter of 
deductive logic. Another way of seeing this is as follows: we could give a full 
description of this alternative state of affairs – in which it is false that the earth as 
exactly one moon – without running into logical nonsense or logical absurdity. But 
(FORM2-Δ) If  _________, then  ------.
(FORM2-Θ) If  _________, then  _________.
(FORM2-Ξ) If  _________, then  not  _________.
2  Concepts of Deductive Reasoning

79
if we try to give a full description of the presumed state of affairs in which “the earth 
has one moon and the earth does not have one moon,” we present a logically impos-
sible or nonsensical state of affairs. The problem with this nonsensical state is not 
our psychological limitations or any epistemic (knowledge-related) deficits we may 
have: the problem is logically. We can trace it back to the form (the form “______ 
and not-______” has the status of a logical contradiction.) Or we can also say that 
this is because of the meanings of the logic-words “and” and “not.”
In addition to the logical statuses of tautology (logical truth, necessary truth) and 
logical contingency (indeterminate, indefinite status) we also have, of course, the 
logical status of a contradiction (logical falsehood, necessary falsehood, logical 
impossibility.) Some texts may be using the terms “validity” and “invalidity” respec-
tively for “logical truth” and “logical falsehood” but, of course, caution is needed to 
distinguish this terminology clearly from the parallel terms of “valid” and “invalid” 
applied to characterize forms of arguments. The concepts of argument validity and 
of consistency apply to characterizations of sets or collections of forms of sentences 
but the logical status of a sentences, examined in the present section, applies strictly 
to the case of the logical forms of sentences. Furthermore, an argument which has 
to be either valid or invalid is different conceptually from the concept of a mere set 
of sentence forms, which has to be either consistent or inconsistent; as we ought to 
know by now, an argument form is indeed a collection of sentence forms but with 
one of those sentence forms (the putative conclusion) as distinguished; on the other 
hand, a mere collection of sentence forms (which is consistent or inconsistent) has 
no conclusion-sentence form in it. It is a common error to confuse applications of 
these terms.
Finally, a sentence like “an angle has three angles” is, as we say, analytically 
true (we can say also that it is semantically analytically true and even, although 
rather confusedly, necessarily true but not logically necessarily true) but it is not 
true by virtue of its logical forms; it is necessarily true because of the meanings of 
its non-­logical words (like “triangle” and “angle”.) Thus, the inference from “d is 
a triangle” to “d has three angles” is not a logically valid inference: it has to be 
accepted, of course, on grounds of what we may call analyticity but it should not 
be expected that this is a matter of argument validity because the inference in this 
case does not depend on logical form and does not go through because of the 
meanings of logical words but thanks to the meanings of the non-logical words in 
the sentences. A sentence that is not analytically true or analytically false, is called 
synthetic.
2.3.1  Exercises
	1.	 Can a meaning expressed by a meaningful sentence be both logically necessarily 
true and logically necessarily false?
	2.	 Can a meaning expressed by a meaningful sentence be neither true nor false – for 
the standard approach to logic?
2  Concepts of Deductive Reasoning

80
	3.	 Characterize the following sentences in terms of the meanings they express: are 
they tautologies (logically true), contradictions (logically false), logically indefi-
nite (possibly true, possibly false), analytic true, analytic false, or synthetic?
	
a.	 Planet X has two moons.
	
b.	 Either planet X has two moons or it has three moons.
	
c.	 Either planet X has two moons or it does not have two moons.
	
d.	 If planet X has two moons, then it has two moons.
	
e.	 Planet X has two moons but it does not have two moons.
	
f.	 Planet X has two moons but it does not have three moons.
	
g.	 Given that planet X has two moons, the earth does not have as many moons 
as planet X does.
	
h.	 The celestial body named Morning Star is the same as that named Evening Star.
	
i.	 If neither planet has two moons, then both planets cannot have four moons.
2  Concepts of Deductive Reasoning

81
© The Author(s), under exclusive license to Springer Nature 
Switzerland AG 2022
O. Makridis, Symbolic Logic, Palgrave Philosophy Today, 
https://doi.org/10.1007/978-3-030-67396-3_3
Chapter 3
Formal Logic of Sentences, Sentential 
Logic (also called Sentential Logic 
and Statement Logic)
We embark now on the enterprise of constructing a formal or symbolic language – 
the first one with more to be constructed subsequently – so that we can make avail-
able symbolic resources for the purpose of studying logical characteristics like 
validity of argument forms, consistency, logical status of sentential forms (if they 
are tautologies or contradictions or indeterminate.) When we discussed the defini-
tion of logic in the opening sections we noted that there is ambiguity about this 
word. One way of thinking about what logic is refers to this project of constructing 
and applying symbolic languages. We might think initially that the motivation actu-
ating this project is to study the logic of a natural language like English. Interestingly, 
though, such a motivation ought to be separated radically from the how we are to 
think about a formal idiom. The symbolic language – which is a formal idiom within 
a family of languages for the specific logic, in this case the standard sentential 
logic – ought to stand by itself; failure of application with respect to the logic of a 
natural language like English would not prove that there is something amiss or 
defective about the formal language; it would only show that there is simply a fail-
ure in application. The formal language should be so constructed that, even without 
assigning meanings to its symbols, it can still be executed exactly in accordance 
with the formal syntactical specifications that enter into the language’s 
construction.
A formal language can itself be studied with rigor and precision. This is a remark-
able characteristic that we expect to find in the realm of mathematics: the study of 
mathematical systems, which has been called Metamathematics, is itself mathemat-
ically rigorous and indeed amenable to the characteristic methods and stipulations 
that apply in the case of mathematics. This is not the case for other areas of study. 
For instance, the study of historical theories, with a view to examining historio-
graphic methodology and other theoretical issues, is not itself like the immediate 
subject matter of the study of history. Our logical languages are subject to metalogi-
cal or metatheoretical analysis and examination in the way that this happens in 
mathematics. This is not to suggest that there are no differences between logic and 

82
mathematics although the topic of the relationship between the two falls outside the 
scope of our present interests.
One could construct many formal systems that serve as logical languages. There 
may be matching motivating considerations. For instance, in a famous case in the 
history of logic, the motivating claim that statements about future events should be 
assigned a third truth value (understood as neither true nor false but indeterminate) 
gave rise to the construction of a motivated formal system for a three-valued logic. 
As a formal language, with its symbolic grammar and stipulated operations, such a 
language would not be controversial: in fact, such languages with multiple values 
have been used to investigate and determine whether axioms (of axiomatically 
defined logical systems) are independent (which means that the axiom, which is 
independent, cannot be proved by the other axioms of the system.) Controversies 
can arise only when it comes to interpreting the languages, and also with respect to 
applicability and (in the case of non-standard multivalent formal languages) about 
the philosophic implications of such constructions regarding the concept of truth as 
such. In our present text, we do no venture into alternative or non-standard logics 
with more than the two values, true and false.
Without delving into minutiae about such matters, no matter how fascinating 
they may be to the student of philosophic logic, we continue now for our purposes 
with the construction of our formal language for sentential logic. This is a language 
for the standard, also called classical or orthodox, sentential logic. You can easily 
find many such formal languages; indeed, any book you may study in logic, which 
addresses the standard logic, would have to be deploying a formal language for the 
standard sentential logic: all such formal languages (including the one we present 
below and even languages not yet constructed for this purpose) should be thought of 
as notational variants of each other – as idioms. They are members of the same fam-
ily of idioms which together comprise a formal language. If the rules of grammar 
are themselves different, we should then be dealing with different dialects. What is 
important is that these languages are not different “logics” (in the sense of “logic” 
that refers to formal language); they are like different idioms, all of which belong to 
the same language.
3.1  Formal Languages: Variations, Extensions, 
and Deviations
Before we enter into the first formal symbolic language we will construct, we lay 
out some terminology. A formal language or symbolic language for a formal sys-
tem, like the one we are about to construct under the name ∑, is understood to be 
like an idiom in an open-ended array of variations that can be constructed for the 
same type of logic: such variations have different symbolic resources and grammars 
or syntactical regulations about how the symbols are to be arranged notationally; 
possibly, the symbols and grammatical rules can be overlapping although that 
3  Formal Logic of Sentences, Sentential Logic (also called Sentential Logic…

83
should be regarded conceptually as a matter of coincidence and possibly instigated 
by convenient choices or historical accidents. Yet, all so-called variations of sym-
bolic languages, let us say in a set {ℭ/ ℭ is an idiom of ℒ}, are formal systems for 
the same logic – for example, the standard bivalent (two-valued) sentential logic, 
ℒsent, within which our collection of formal languages ∑ is about to be constructed: 
so, we have (using the standard set-theoretic symbol “∈” for inclusion or being a 
member of a set): ∑∈ ℒsent.
The so-called type of a formal symbolic system that is a calculus, like the one of 
the standard sentential logic or logic of the truth functions, is characterized by the 
value-set (the set of numbers or values over which the functions of the system are 
defined); and the collection of the functions of the system as specified through the 
arities or degrees of those functions (the number of inputs each function takes). The 
formal system is an abstract object, a mathematical object constructed precisely and 
systematically: this can also be studied with a view to investigating its own charac-
teristic properties. In our language ∑, the connective symbols are defined over a set 
of truth values, {T, F}.
An extension of formal system is constructed when we add symbols and specify 
systematic grammatical regulations for such additional symbols (for connectives, 
non-extensional operators, quantifiers, and so on). Thus, the predicate or first-order 
logic we study, as a system of formal languages called ∏, are themselves idioms or 
members of the family of predicate logics which are themselves extensions of the 
standard sentential logic; accordingly, our own formal languages ∏ are extensions 
of the languages ∑.
Other approaches to the construction of extensions of the standard logic ∑ could 
be undertaken in building modal logics, for instance, but this is something we do not 
have space to do in this text. The predicate logics themselves can be so extended 
into modal predicate (or modal quantificational) formal languages  – generating 
interesting challenges to the student of logic, but which, again, we do not examine 
in the present text. When an extension of a variation of a formal language in a family 
ℒ (for instance, the family of standard two-valued logics) is constructed, the mean-
ings of the connective symbols (which are also called logical symbols of the formal 
language) are not redefined. This is essential because the character of a formal lan-
guage – inherited by any of the idioms that constitute the symbolic languages in the 
family – is established by the definitions of the meanings (also called interpreta-
tions) of the connective symbols. A change in the number of members in the set of 
the logic’s truth values (which automatically alters the meanings of the connective 
symbols) and/or a redefinition of the meanings of the connective symbols estab-
lishes a deviation from the family ℒ, generating an idiom from an altogether differ-
ent family of logic. We do not examine such alternative formal languages in general 
in this text, which is dedicated to the presentation of standard logic languages, with 
the exception of pedagogical and philosophical references we make, recurrently and 
as the need arises, to a species of logic called Intuitionistic (which is not an exten-
sion but a deviation relative to the standard sentential logic.)
3.1  Formal Languages: Variations, Extensions, and Deviations

84
3.2  Grammar of our Formal Language of Sentential 
Logic: ∑
We now lay out the formal grammar of our language ∑. Our formal language has 
symbols in it. Nothing that is not officially included as a symbol is recognized. The 
symbols themselves have names. A symbol is supposed to be denoting something – 
referring to something. Symbols do not refer to real things that can be accessible 
empirically. The referents are abstract objects, and we will assign names to those 
objects. The language ∑ must have a grammar or syntax if it is to be a proper lan-
guage, and we supply the needed symbolic amenities along with a strictly specified 
grammar and syntactical rules. You should think of this setup as a game for how to 
use and move around and concatenate (put next to each other) all those symbolic 
resources you are given in the formal language.
Finally, we will also have symbols made available not for ∑ but in what we call the 
Metalanguage of ∑: ℳ(∑). This is a made-up language but it is really English (well, 
as much of English as we need) plus some symbols we make available for our conve-
nience. We show those symbols below. It should be understood that the metalinguistic 
symbols are not official in the way the symbols of ∑ are and are considered to have a 
flexible and convenient grammatical regulation. We can use, as we should say, copies 
of the symbols of ∑ in ℳ(∑). It is all a matter of convenience. The formal language 
itself and the Metalanguage are different languages, and one of them only is the official 
formal language – that is ∑, which logicians call the Object Language (while ℳ(∑) is 
the Metalanguage for ∑.) Why do we need ℳ(∑)? We need it to talk about ∑.
The discovery of the use of variables has been one of the most significant break-
throughs in the history of Mathematics, and of Logic. It seems impossible to grasp 
the fundamentals of deductive reasoning without also discerning some principle 
that can lead naturally to the discovery of variables. The prospect of making prog-
ress in a systematic study of reasoning depends strongly on using variables for sev-
eral reasons, among which we can mention the following: brevity of expression can 
be achieved, avoiding clutter and making it possible to develop and study theoretical 
claims and proofs; representations can be rendered perspicuously – in a fashion that 
is easy to survey and work with; and, finally, use of variables facilitates understand-
ing and respecting certain fundamental and foundational distinctions in deductive 
reasoning. For example, if you try to express the following equations without using 
variables, you will end up using an unwieldy, long and obscuring mode of speaking.
(x + y)2 = (x2 + y2 + 2xy)
With the use of variables – which will become available to us when we turn to 
the study of predicate logic – the formulation becomes: “for all x and all y from a 
certain universe of things – numbers – the square of the sum of x and y is equal to 
the sum of the sum of the square roots of x and y and double the product of x and 
y.” This is a cumbersomely cluttered expression. By using variables, we can actually 
just write out the equation as we did above. Notice that variables are like blanks that 
can be filled in correctly by symbols that have been established to refer to the appro-
priate kind of thing. Although this seems odd, only because it is unfamiliar, consider 
the preceding equation written as:
3  Formal Logic of Sentences, Sentential Logic (also called Sentential Logic…

85
(−- + __)2 = (−-2 + __2 + 2-- __)
Thus, we can say that variables are placeholders. In addition to the variable sym-
bols, there are in the preceding example symbols for the function of addition (cor-
responding, roughly, to a connective symbol of a formal logical system); there are 
also numerals, symbols for numbers (which, notably, appear as fixed symbols); 
lastly, we have the parentheses but here we have to pull back and stress that the 
parentheses are not logical symbols and are only used for the sake of convenient 
arrangement of the symbolic juxtapositions. The parentheses, also called auxiliary 
symbols, are used, after some pre-established grammatical convention, to ensure 
that we avoid ambiguity in the reading or scanning of the symbolic expression. For 
instance, we could stipulate grammatically that some other convention, instead of 
the use of parentheses, is to be followed in order to indicate that the sum – and not 
only the variable to the right of the sum symbol – is raised to the second power. 
Examples of such devices are the following. Can you tell how they work?
9
9 -- + __: 2 = −-2 + __2 + 2-- __
9
9 -- +2 __ = −-2 + __2 + 2-- __
9
9 2+ −-__ = ++−-2__22--__
Now we proceed to lay out our formal language resources.  
∑
Symbol, Name of Symbol, and What the Symbol Refers to
	
Sentences	
Connectives: Symbol, Name of the Symbol, and Name of the Connective
~: Name of the Symbol: Tilde; Name of the Connective: Negation
∙: Name of the Symbol: Dot; Name of the Connective: Conjunction
∨: Name of the Symbol: Wedge; Name of the Connective: Inclusive Disjunction
⊃: Name of the Symbol: Horseshoe; Name of the Connective: Conditional / 
Implication
≡: Name of the Symbol: Triple Bar; Name of the Connective: Biconditional / 
Equivalence
(,): Left and Right Parentheses [also called Auxiliary Symbols]
---The tilde is the only Monadic or Unary or One-Place connective symbol. 
All the other connective symbols are Binary or Dyadic or Two-Place.
Compare operation symbols in basic arithmetic:
- 3: the name of the operation symbol is “minus” and it is monadic/unary/
one-place.
2 + 3: the name of the operation symbol is “plus” and it is binary/dyadic/two-­
place. The same is the case for the operation symbols {x, ∸}.
{p, q, r, …, p1, p2, …}: Name: Simple/Atomic/Individual  
Variables; Referent: 	

Meanings of 
Sentences
{A, B, C, …, A1, …}: Name: Translation Atomic  
Variables; Referent: Linguistic	

Meanings of  
Translated 
English
3.2  Grammar of our Formal Language of Sentential Logic: ∑

86
ℳ(∑).
φ, ψ, …, φ1, … are metalinguistic variables.
We use these variables to talk about well-formed formulas of ∑. We can 
bring into our metalanguage symbols from the Object Language ∑, but, actu-
ally, we don’t have a symbol like what we are looking for. We need these 
metavariable symbols to allow us to talk about any well-formed formulas – 
not only simple but also compound formulas.
When we refer to symbols from ∑, we place them within special metalin-
guistic symbols that are called “corners:” “⌜” and “⌝” . When we use and talk 
about metalinguistic symbols, we don’t need such corners. That is because 
those are functioning like names already within our metalanguage.
When we don’t use but, instead, talk about or mention symbols we place 
quotation marks around them – but for symbols from the Object Language ∑ 
we use corners as we have said.
We now present the Grammar of our formal language. Notice that we present 
the grammar of ∑ in ℳ(∑).
GRAMMAR of ∑.
Grammatically correct symbolic expressions are called well-formed for-
mulas. The abbreviation we use for “well-formed formula” is wff and, for the 
plural, wffs.
      
The grammar is an arbitrary syntactical arrangement that is given. We 
don’t guess about how it works. It is something that can be implemented auto-
matically, without thinking about meanings of the symbols.
Only the given symbols can be used. Any expression that has symbols not 
in the language is not recognizable. Any expression that violates the grammar 
of the formal language is also unrecognizable. If it is unrecognizable, that 
means that it is nonsense – if you think of yourself as being programmed 
systematically to scan this formal language, then any symbol not in the lan-
guage does not scan; any string of symbols, which is not in accordance with 
the specified grammar, also does not scan.
Now, we specify the grammar of ∑. The way this is done is called recur-
sion; the definitions of the wffs are recursive. Notice that this recursive defini-
tion is provided in the metalanguage of our formal language – not in ∑ but in 
ℳ(∑). There are symbols in this metalanguage, which are not in the object 
(continued)
3  Formal Logic of Sentences, Sentential Logic (also called Sentential Logic…

87
(continued)
language ∑. This is the case for the Greek lower-case letters {φ, ψ, …, φi, …, 
ψj, …} – allowed to have subscripts from the positive integers. We need these 
special symbols to talk about wffs; such wffs may or may not be atomic for-
mulas – the atomic formulas are the simple or atomic letters we have made 
available in our formal grammar. Certainly, once we specify our grammar, we 
will be making it possible for compound symbolic expressions (not atomic) 
to be well-formed – to be wffs. Accordingly, when we want to indicate that 
we are speaking of any wff – not necessarily an atomic letter – we need some 
metalinguistic symbol to say that! For this purpose, we use the lower-case 
Greek letters specified above.
1.  p, q, …, p1, …, q1,… are well-formed formulas.
2.  If φ is well-formed, then ⌜ ~ φ ⌝ is well-formed.
3.  If φ and ψ are well-formed, then the following are well-formed:
4.  ⌜ φ ∙ ψ, ⌜ φ ∨ ψ ⌝, ⌜ φ ⊃ ψ ⌝, ⌜ φ ≡ ψ ⌝.
5.  Parentheses are to be used, as auxiliary symbols  – only to prevent  
ambiguity.
6.  ==Nothing else is accepted as well-formed. [This is called the Closure 
Clause.]
Consider the use of symbols in simple arithmetic:
2 + 3: the operation symbol, plus, symbolizing addition, is placed between 
the numerals. This is called infix notation. Notice that we are also using the 
infix notation – for the binary connective symbols. For the unary connective 
symbol, the tilde, we are using the prefix notation: the connective symbol is 
placed in front. This actually happens in familiar arithmetical symbolization 
for the minus-symbol.
We need a name for the items on which the connective symbols are applied: 
let us use the term input and, in the plural, “inputs.”
•	 Simplifications for our Symbolization:
	1.	 We do not need to use parentheses to enclose the entire wff. Such paren-
theses are called external or outer parentheses. In other words, we are 
stipulating that we may dispense with – omit, not use – outer parentheses. 
We can do this – we can call it a “liberalization” of our still be able to 
figure out what the boundaries of the whole wff are. If we ran into uncer-
tainty about this, we would have to use the parentheses.
	2.	 Another simplification has to do with formulas in which the connective sym-
bols {∨, ∙, ≡} are involved; it applies only to these connective symbols and 
(continued)
3.2  Grammar of our Formal Language of Sentential Logic: ∑

88
•	 We do not write “(A)” or “~ (A)”; this is clearly not allowed by our grammar. 
The prohibition is consistent with the regulation we have laid down: we only use 
parentheses for the purpose of preventing and removing ambiguity and no ambi-
guity arises in the case of individual letter symbols. Of course, we could have 
legislated the use of parentheses in a more permissive fashion, and it is possible 
to find texts in which parentheses are placed around atomic variable letters. 
(continued)
	 	 not to {⊃}. This simplification also related to the use of parentheses – on 
which we will have more to say later. We may omit parentheses as follows:
•	 ⌜p ∨ (q ∨ r) ⌝ and ⌜(p ∨ q) ∨ r⌝ can be written as ⌜p ∨ q ∨ r⌝
•	 ⌜p ∙ (q ∙ r) ⌝ and ⌜(p ∙ q) ∙ r⌝ can be written as ⌜p ∙ q ∙ r⌝
•	 ⌜p ≡ (q ≡ r) ⌝ and ⌜(p ≡ q) ≡ r⌝ can be written as ⌜p ≡ q ≡ r⌝
In other words, we may omit parentheses when we have iterations of these 
three connective symbols. An explanation of this is due. The two expressions 
we see, in each case, with the parentheses left in place are mutually equiva-
lent: they have the same logical meaning with each other. “Logical meaning” 
is a technical term, you should remember. It means that – for the SAME true/
false values for the atomic letters in the two wffs, the whole wffs obtain the 
same true/false value. Because logical meaning is truth value for assignments 
for truth values to the parts, this means that they have the same logical mean-
ing. Therefore, we can move the parentheses any way we want – we can go 
from the one symbolic expression to the other symbolic expression (we are 
talking about the expressions with the parentheses still left in them.) But, if 
the movement of parentheses has no impact on logical meaning, we don’t 
need to use parentheses at all! As you will soon find out, parentheses are used 
only for the purpose of distinguishing which one of different meanings is 
expressed. Doing this is to prevent ambiguity. You can see in the grammatical 
instructions that the purpose of parentheses is said to be to prevent ambiguity. 
But we don’t have ambiguity since the meanings are the same no matter how 
the parentheses are placed.
We say that the connective symbols {∙, ∨, ≡} have the property of associa-
tivity. What this means is more or less what has been explained about what 
happens when the parentheses are shifted as indicated above. You might find 
this complicated but, to facilitate understanding, consider the following 
examples from simple arithmetic.
•	 1 + (2 + 3) = (1 + 2) + 3	
=> ⌜1 + 2 + 3⌝ is not ambiguous
•	 1 ⤬ (2 ⤬ 3) = (1 ⤬ 2) ⤬ 3	
 => ⌜1 ⤬ 2 ⤬ 3⌝ is not ambiguous
3  Formal Logic of Sentences, Sentential Logic (also called Sentential Logic…

89
Clearly, the grammatical conventions we adopt do not have to be guided by any 
overarching consideration. A grammar – also called syntax in this context – can 
be thought of as a layout of rules that regulate the manipulation of the specified 
symbolic resources of the formal language.
We may reflect briefly on the reasons we do not need parentheses around indi-
vidual (atomic) variable letters. ⌜A,⌝ for example, is unambiguous and, hence, 
⌜(A)⌝ is not needed. (The use of the so-called Quine corners, “⌜” and “⌝”, is to 
enclose symbolic expressions from the object language ∑, which are mentioned 
rather than used when appearing in our metalanguage.) Any atomic letter, like ⌜A⌝ 
for instance, is not bound to itself by means of any connective symbol, hence we do 
not need parentheses: this is an interesting concept we need to grasp now – the con-
cept of “binding” – in order to have a deeper understanding of how the connection 
between removing ambiguity (disambiguating) and using parentheses works.. Let 
us show  – in our metalanguage  – the binding of connective symbols to non-­
connectives expressions by using “↪” and “↩”. We place what is bound by the 
connective symbol within boxes. In our grammar, as we have stipulated, the unary 
connective symbol is written in prefix notation and the binary connective symbols 
are placed in between the connected symbolic expressions (or, in infix notation.) 
Notice the consequences for how the binding diagrams below look.
•	 (p ∨ q) ⊃ (s ∙ ~ t)
○
○binding(⊃): (p ∨ q) ↩⊃↪ (s ∙ ~ t)
○
○binding(∨): ( p ↩∨↪ q ) ⊃ (s ∙ ~ t)
○
○binding(∙): (p ∨ q) ⊃ (s ↩∙↪ ~ t  )
○
○binding(~): (p ∨ q) ⊃ (s ∙ ~↪ t  )
Now we consider a different symbolic expression from the one of the preced-
ing example: this well-formed formula we consider next has different placements 
of parentheses; the binding attachments of connectives to sub-expressions of the 
formula are different; this formula does not have the same logical meaning – 
when interpreted within a system with truth values – as the preceding one. Once 
again, the diagram presented below appeals to intuitions. We have four connec-
tive symbols in this formula – as we had in the one of the preceding example – 
and we analyze, diagrammatically, the binding forces of the connective symbols, 
one by one. The binding for each connective consists in the symbols that are 
controlled by the symbol. It is important to notice that we do not attach any hier-
archical ranking to the binding strengths. All binary connective symbols are 
treated as equal in terms of binding and it is only the symbols’ placements in the 
formula that determine the bindings (or, as we will call them soon, the scopes.) 
We will try to understand why parentheses are needed because of this equality of 
binding forces. (Also to notice, the fact that our grammar legislates that the tilde 
is placed in front, in prefix notational position, has consequences too, as we will 
explain.)
3.2  Grammar of our Formal Language of Sentential Logic: ∑

90
•	 p ∨ (q ⊃ (s ∙ ~ t)): p ∨ (q ⊃ (s ∙ ~ t))
○
○binding(∨): p ↩∨↪ (q ⊃ (s ∙ ~ t))
○
○binding(⊃): p ∨ (  q ↩⊃↪ (s ∙ ~ t) )
○
○binding(∙): p ∨ (q ⊃ (s ↩∙↪ ~ t ))
○
○binding(~): p ∨ (q ⊃ (s ∙ ~↪ t ))
Without appropriately placed parentheses, the following symbolic expression is 
not a well-formed formula. It could be one or the other of the formulas of the pre-
ceding two examples. Notice how binding uncertainties are related to – and illus-
trate the – ambiguity. This uncertainty is not a psychological matter, of course, but 
it is a structural defect in the writing of the ambiguous symbolic expression relative 
to the grammar we have stipulated. (To be sure, there are grammars, with conven-
tions different from the ones we have stipulated, for which, grammars, this follow-
ing expression can be read, is not ambiguous.) But for our grammar this symbolic 
expression is ambiguous; it cannot possibly be “scanned.” Compare the different 
possibilities for binding – scope – that we obtain: we cannot reasonably decide 
which one of the two possibilities applies – hence, we have ambiguity. Not every 
connective symbol suffers from ambiguity, of course, as you can see. But some 
symbols (two in this case) present this defect – ambiguity of scope, which is a con-
sequence of the fact that we have not made arrangements for the binding strength of 
the symbols to be more or less - all symbols have the same “right” to binding, so to 
speak. We indicate the ambiguous connective symbol (in this metalinguistic presen-
tation) by a “?” superscript and we show the available options, between which we 
do not know how to decide based on our grammatical conventions. There can be two 
or more options of “reading” the connective’s binding to engender ambiguity (in our 
example we have two options, which is the minimum number of options to have 
ambiguity.)
•	 p ∨ q ⊃ (s ∙ ~ t)
○
○p ∨ q ⊃ (s ∙ ~↪ t)	
	
==not ambiguous, there is only one option
○
○p ∨ q ⊃ (s ↩∙↪ ~ t)		
==not ambiguous, there is only one option
○
○p ∨ q ⊃? (s ∙ ~ t)	
	
==ambiguous: two options (shown below)
•	 p ∨ q ↩⊃↪ (s ∙ ~ t)
•	 p ∨ q ↩⊃↪ (s ∙ ~ t)
○
○p ∨? q ⊃ (s ∙ ~ t)	
	
==ambiguous: two options (shown below)
•	 p ↩∨↪ q ⊃ (s ∙ ~ t)
•	 p ↩∨↪ q ⊃ (s ∙ ~ t)
Notice that, depending on what is bound by a connective, other connectives may 
have to “adjust” accordingly for what those other connectives bound. In our exam-
ple, the does not suffer from ambiguity thanks to the placement of parentheses. 
Without the extant parentheses symbols, we would have more disambiguating 
options – more possible well-formed formulas as options. It is also remarkable that 
the tilde cannot be ambiguous. There is a reason for this. Notice that the equality of 
binding forces we talked about applies to the binary connective symbols. When it 
comes to the tilde, on the other hand, it is understood to be bound rigidly to the well-­
formed formula that immediately follows it. Since an atomic variable letter by itself 
is a well-formed formula, this applies also in the case of the tilde placed in front of 
3  Formal Logic of Sentences, Sentential Logic (also called Sentential Logic…

91
an atomic letter. To indicate rigid attachment (meaning that the binding is only, or 
exactly, to what follows to the right, we use the metalinguistic symbol “⤠”. 
•	 ~⤠ p ∙ q
○
○NEVER to be read: ~↪ p ∙ q
○
○Hence, NOT to be read: ~ (p ∙ q)
○
○Therefore, no ambiguity between:
•	 ~ p ∙ q	 	
and
•	 ~ (p ∙ q)
•	 Accordingly, we don’t need: ~ (p) ∙ q
•	 To indicate that the tilde binds more than the following atomic letter, we 
MUST use parentheses:
•	 ~ (p ∙ q)
There are grammars in which differential strength of binding attachments are 
stipulated for the various binary connective symbols; this makes it possible to spare 
parentheses, to use fewer parentheses, without incurring ambiguity. There is also a 
so-called Polish notation, which places binary connective symbols in a prefix nota-
tion – not in infix placements, as we have done – and which has no need for paren-
theses at all. We give brief examples of what may happen when such grammars are 
available but you may skip the text within the following box.
Suppose that we stipulate that ⌜∨⌝ and ⌜∙⌝ bind more strongly than ⌜⊃⌝ 
and ⌜≡⌝. The convention for the binding by the tilde remains as we have 
arranged it. Stronger binding means attachment to what follows rather than to 
outlying symbols. Notice how we may save parentheses, without risking 
ambiguity, in some cases (although it is not possible to avoid parentheses 
altogether.) Remember that we show rigid binding or stronger biding by “⤠”, 
and by “⤟” to the left, while we now indicate looser binding by “↩” and 
“↪”. Using these adjusted symbols, notice that the tilde is rigidly attached 
(only to the right, since it is a unary symbol.)
==	
(p ⤟∨⤠ q) ↩⊃↪ (s ⤟∙⤠ ~⤠ t)
We may omit parentheses without ambiguity:
==	
p ⤟∨⤠ q ↩⊃↪ s ⤟∙⤠ ~⤠ t	
	
==hence, we can write:
==	
p ∨ q ⊃ s ∙ ~ t
But, the following needs parentheses:
==	
p ∨ (q ⊃ (s ∙ ~ t))
Without parentheses, the expression is automatically the well-formed formula 
of the preceding example. Notice how the hierarchically differential binding 
strengths can be still represented accurately – but the wedge, now, attaches rigidly 
to the entire within-parentheses expression to its right (since this is the intention.)
==	
p ⤟∨⤠ (q ↩⊃↪ (s ⤟∙⤠ ~⤠ t))
(continued)
3.2  Grammar of our Formal Language of Sentential Logic: ∑

92
∑⤠
∑
p ≡ ~ t ∨ q
~ p ⊃ ~ q ∙ ~ r
~ t ∨ ~ q ⊃ s ∨ ~ q
p ≡ (~ t ∨ q)
~ p ⊃ (~ q ∙ ~ r)
(~ t ∨ ~ q) ⊃ (s ∨ ~ q)
(continued)
Other examples from this grammar, which is different from ours, and 
which we may dub as “∑⤠”. Next to each well-formed formula of ∑⤠ we 
show the grammatically correct formula of our language ∑ that represents the 
same sentential form.
The following expressions, however, are ill-formed also in ∑⤠: parenthe-
ses are needed for disambiguation, as shown to the right of each formula. 
There are two possibilities in each case – two disambiguating well-formed 
formulas, whereas the given one is not a well-formed formula because it suf-
fers from ambiguity. The problem here is that the ambiguously used connec-
tive symbols bind equally; because of this, there are more than one possible 
binding arrangements. Obviously, we could make additional grammatical 
stipulations (for instance, that, in case of threatening ambiguity, the binding 
for two equally strong connective symbols is “to the right” – or “to the left” 
for that matter. Compare with the grammatically correct expressions (well-
formed formulas of ∑, given on the last column to the right. ∑⤠ still econo-
mizes on the use of parentheses, in certain cases, compared to ∑.
∑⤠ ambiguous
∑⤠-unambiguous
∑
p ≡ t ⊃ q
p ⊃ q ⊃ ~ r
t ⊃ q ⊃ s ∨ ~ q
p ≡ (t ⊃ q)
(p ≡ t) ⊃ q
p ⊃ (q ⊃ ~ r)
(p ⊃ q) ⊃ ~ r
t ⊃ (q ⊃ s ∨ ~ q)
(t ⊃ q) ⊃ s ∨ ~ q
p ≡ (t ⊃ q)
(p ≡ t) ⊃ q
p ⊃ (q ⊃ ~ r)
(p ⊃ q) ⊃ ~ r
t ⊃ (q ⊃ (s ∨ ~ q))
(t ⊃ q) ⊃ (s ∨ ~ q)
•	 It is notable that a grammatically correct or well-formed formula of ∑ has to have 
equal numbers of left and right parentheses. This includes the (degenerate) case 
in which there are no parentheses because, again, the numbers are both equal to 
zero and, therefore, equal to each other. We could prove rigorously that every 
well-formed formula of ∑ must have equal numbers of left and right parentheses. 
We dispense with such proofs in this introductory text. When we check for cor-
rectness of a given symbolic expression, in ∑, we must check if the numbers of 
3  Formal Logic of Sentences, Sentential Logic (also called Sentential Logic…

93
left and right parentheses are equal; if not, the given symbolic expression must be 
declared to be not well-formed, not grammatically correct, ill-­formed: such an 
expression does not “scan;” we cannot read it, it is meaningless, in ∑.
We refer to connectives in the following section. Strictly speaking, the term con-
nectives should be used when we provide a semantics for our formal system; this is 
done when the definitions are given over the set of truth values {T, F}. A more 
appropriate term for uninterpreted connectives is “operators:” the interpretations of 
the operators, given by defining those operators over the truth values {T, F}, as we 
do in 4.3, furnish us the connectives. We disregard this and refer to connective sym-
bols throughout: we do this to avoid a distracting transition from the term “opera-
tors” to the term “connectives”.
3.2.1  Scope of a Connective Symbol and the Major 
Connective Symbol
Let us start by discussing a concept called the scope of the connective symbol. This 
concept plays a significant role in many of the operations we will need to attend to. 
Consider the following symbolic expression, which is a well-formed formula (wff).
φ1 = p ⊃ q
This is well-formed; it is a wff (well-formed formula) of ∑. The only connective 
symbol is what we have called the horseshoe. This is a binary connective symbol; it 
must have two input symbols – and it does. In this case the input symbols are atomic 
sentential variables. Our grammar has set it that atomic sentential variables are well-­
formed. The connective symbol, which is the horseshoe in this case, is in the infix 
position (it is between the two joined atomic variables.) This is all well-formed. We 
say that the two input symbols are within the scope of the connective symbol. We 
can write this as follows. I am using the set-brackets, again, even though we have 
not studied Set-Theoretical concepts yet. (But you can find Set Theory covered in 
chapter 11.) It is useful to know that a set – in this case a collection of symbols as 
members – is defined as a collection of items such that for any given item we can 
tell if this item is or is not in the set. We say that a set has members or elements. We 
don’t repeat a member symbol more than once. We can define the empty set, a set 
with no members at all, which is usually symbolized as “∅”. We use “{” and “}” to 
enclose the symbols that name the members of the set.
Scope(⊃) = {p, q}
If we were to query about the scope of ⌜∨⌝ in the given formula, we would have 
to say that this is the empty set. (Can you tell why there is only one empty set?)
Scope(∨) = ∅
3.2  Grammar of our Formal Language of Sentential Logic: ∑

94
Now, we are given a formula with more than one connective symbol. We will be 
discussing the use of parentheses in the next section; for now, you are just treated to 
scanning wffs (well-formed formulas) with parentheses.
φ2 = ~ (p ⊃ q)
Consider the scopes of the two connective symbols in the given wff.
Scope(~) = {p, ⊃, q}; Scope(⊃) = {p, q}.
We consider within the scope of a connective symbol all the symbols that are 
regulated by the symbol – not including parentheses. The symbol itself is not within 
its own scope. This is important. In the second given wff, the scope of ⌜~⌝ is larger 
than the scope of ⌜⊃⌝. This means, straightforwardly, that there are more symbols 
within the scope of ⌜~⌝ than within the scope of ⌜⊃⌝. It is also noteworthy that ⌜⊃⌝ 
falls within the scope of ⌜~⌝. In the first case, of course, we only have one connec-
tive and the issue of relative scope does not arise.
Consider examples from language:
S1: If it rains, then the game is canceled.
S2: It is not the case that if it rains, then the game is canceled.
The first sentence, S1, expressed an implication or conditional – an if-then mean-
ing. The second sentence, however, expresses a negation – a not-meaning. They 
actually contradict each other: they cannot be both true together. Let us pay atten-
tion to S1 and S2. In S1 the logic-word with the largest scope is the if-then word. In 
S2, the logic-word with the largest scope is the not-word. The connective symbol 
with the largest scope is called the major principal connective symbol. A great deal 
of confusion happens in language because of misunderstandings regarding the 
scopes of the logic-words. The sentence S1 is an instance (it has the logical form) of 
⌜p ⊃ q⌝. The sentence S2 has the logical form (is an instance) of ⌜~ (p ⊃ q)⌝.
We could have iterations of the same symbol. To mark and distinguish their 
scopes – since they are instances of the same symbol but they are distinct! We speak 
of first, second, etc., occurrence of a connective symbol. We mark the occurrences 
counting from left to right. (Nothing essential depends on this: we could agree to 
count from right to left. Whatever convention we pick, however, we have to stick to 
it!) We can study the following example.
φ3 = (p ⊃ q) ⊃ r.
Scope(⊃1) = {p, q}, Scope(⊃2) = {p, ⊃1, q, r}.
The scope of the second occurrence of the horseshoe is larger than the scope of 
the first occurrence of the horseshoe.
φ4 = p ⊃ (q ⊃ r)
Scope(⊃1) = {p, ⊃2, q, r}; Scope(⊃2) = {q, r}.
3  Formal Logic of Sentences, Sentential Logic (also called Sentential Logic…

95
The formula φ3 has a different meaning from the formula φ4. Although they both 
have two occurrences of the horseshoe, the scopes are different; in the second for-
mula, the first occurrence has a larger scope than the second occurrence. It was the 
other way round in the first formula.
We will provide more examples in 4.1.1. For now, let us tackle a wff with many 
connectives symbols. This might seem formidable but we don’t have to alter any-
thing we have said so far to deal with a case like this. For the sake of convenience, 
we are superimposing metalinguistic symbols  – superscripts to mark the occur-
rences of connectives – on the formula. Note first that the given wff has five connec-
tive symbols. We mark occurrences of the same symbol from left to right. We then 
track carefully what lies within the scope of each connective symbol.
The major connective symbol of a grammatically well-formed formula of ∑ is 
the connective symbol that has the largest scope. This connective symbol is also 
called principal connective symbol. It is impossible for more than one connective 
symbol to have equally large scopes which, scopes, are larger than the scope of 
every other connective in the formula: in other words, it is impossible to have two 
major connective symbols in a form.
* This can be proven rigorously by means of a method called Mathematical 
Induction on the length or construction of the well-formed formula. Specifically, 
this is an application of the metatheoretical proof method known as Weak 
Mathematical Induction. It is a consequence of the grammatical arrangements we 
have made and, fundamentally, of the fact that our construction has been given 
recursively, instructing us how to build more complex formulas from simpler for-
mulas. Mathematical Induction is applied as follows in this case. We trust that this 
can supply an example illustrating this metalinguistic proof method without dis-
cussing the theory of the method in this context.
•	 We consider as basis case the case n = 0, where n is the number of connective 
symbols in the well-formed formula. The property we are aiming to prove is that 
there is exactly one major connective symbol. For our proof to succeed we must 
be able to show that applies in the basis case of n = 0. It does, in a vacuous sense, 
because the atomic variable has no connective symbol, for n = 0, and, so, there 
are no more than one major connectives (since there is not even one!)
φ5 = ~ (p ⊃ (~ q ⊃ ~ t))
Imposition of Superscripts to Mark Multiple Occurrences.
φ5 = ~1 (p ⊃1 (~2 q ⊃2 ~3 t))
Scope(~1) = {p, ⊃1, ~2, q, ⊃2, ~3, t}
Scope(~2) = {q}
Scope(~3) = {t}
Scope(⊃1) = {p, ~2, q, ⊃, ~3, t}
Scope(⊃2) = {~2, q, ~3, t}
3.2  Grammar of our Formal Language of Sentential Logic: ∑

96
•	 Next, to establish possession of the target property by all well-formed formulas, 
we proceed as follows: we make an Inductive Hypothesis: that for number of 
connective n > 0, a well-formed formula possesses the property – which is the 
existence of exactly one major connective symbol. To show that all well-formed 
formulas possess this property we must now be able to prove that every formula 
with number of connective symbols equal to n + 1 has the property on the basis 
of the Inductive Hypothesis that this this is the case for every well-formed for-
mula with n connectives.
•	 Suppose we have two well-formed formulas, φ and ψ, each with n connective 
symbols, for each of which, by the Inductive Hypothesis it is the case that it has 
exactly one connective symbol. We have certain grammatically constrained 
options for combining the formulas with connective symbols:
•	 We can place a tilde in front of φ: ~ φ. Now the major connective symbol is 
the tilde: there is only one major connective symbol since the major connec-
tive symbol of φ is no longer the major connective symbol of ~ φ. (The same 
case can be made in the same fashion for placing the tilde in front of ψ, fol-
lowing our grammatically legislated prefix notation for the tilde.)
•	 To connect the formulas, we can also place some binary connective symbol in 
between them, following the convention of infix notation we have legislated 
grammatically for our formal language. Now, this binary symbol becomes the 
only, and exactly one, major connective symbol.
•	 There are no other grammatically available options for constructing complex 
formulas beyond the case of n-connective-symbols formulas.
•	 Accordingly,we have proven that every well-formed formula possesses this 
property, since we have established this to be the case for: n = 0; and we have 
proven it for n + 1 on the assumption that it is the case for every well-formed 
formula whose number of connectives is n. *
Having learned how to determine the scopes of connective symbols, we are in a 
position to identify the major connective symbol (MCS) of any given well-formed 
formula; based on the result we proved, only one such, and exactly one such, major 
connective symbol is present in every formula. We examine certain cases as exam-
ples. Common errors are committed by beginners – and we may point such cases 
out – even though the subject is quite straightforward.
•	 ~ ~ p	
The first occurrence of the tilde is 
the MCS.
•	 ~ (~ p ∨ q)	
The first occurrence of the tilde, out-
side the parenthesis, is the MCS.
•	 ~ ((s ∙ t) ≡ (u ⊃ v))	
The tilde is the MCS.
•	 ~ p ≡ (~ (q ≡ s) ∨ (t ∙ ~ u))	
The first occurrence of the triple bar 
is the MCS.
•	 (p1 ⊃ (p2 ⊃ (p3 ⊃ (p4 ⊃ p5))))	
The first occurrence of the horseshoe 
is the MCS.
•	 ((((p1 ⊃ p2) ⊃ p3) ⊃ p4) ⊃ p5)	
The last occurrence of the horseshoe 
is the MCS.
3  Formal Logic of Sentences, Sentential Logic (also called Sentential Logic…

97
•	 ((p ⊃ q) ⊃ (s ⊃ t)) ⊃ ((u ⊃ v) ⊃ (w ⊃ z))	
The third occurrence of the horse-
shoe is the MCS.
•	 ~ ~ ~ ~ ~ p	
The first occurrence of the tilde is 
the MCS.
3.2.2  Use of Parentheses
We need also to understand why and how parentheses are used in this formal gram-
mar. The instructions we are given in our grammar (also called syntactical instruc-
tions) only tell us to use parentheses to prevent ambiguity – and the instruction is to 
use parentheses only for this purpose (which we may also call “disambiguation.”) 
We will start by discussing this matter.
p ∨ q ∙ r
The above symbolic expression has symbols that are available in the grammar of 
∑. It only has such symbols. The connectives symbols in this expression are {⊃, ∙}. 
But this symbolic string is not well-formed. It lacks parentheses and  – what is 
equally important – without parentheses, it is ambiguous. What we mean by ambi-
guity is this: We have ambiguity when the competent reader cannot figure out which 
one meaning is meant out of a plurality (two or more) of possible meanings. In this 
case, there are two possibilities and, without parentheses, we can’t tell which one of 
the two is presented!
Possibility 1: p ∨ (q ∙ r)
Possibility 2: (p ∨ q) ∙ r
These two symbolic strings do not express the same meaning. If they did, there 
would be no problem. The first wff captures the logical form of an inclusive disjunc-
tion – an either-or-and/or-both-meaning. The second, however, captures the logical 
form of a conjunction – an and-meaning. These are different logical meanings: they 
do not have always the same truth values (true/false) when the same truth values are 
assigned to their atomic parts. For the and-meaning to be true, both the joined sen-
tences must be true; but the either-or-and/or-both-meaning can be true even if only 
of its joined sentences is true.
The first logical form has the wedge as the connective symbol with the widest or 
largest scope; but, in the second form, the dot has the largest scope. The first is an 
inclusive disjunction whereas the second is a conjunction.
3.2  Grammar of our Formal Language of Sentential Logic: ∑

98
To give a linguistic example, the first is the form of:
S1: Either it rains, or the game is canceled and we go home.
The second is the logical form of:
S2: Either it rains or the game is canceled, and we go home.
Notice the placement of commas – although the linguistic grammar is not a reli-
able guide for discerning the logical grammar of a sentence (you should always keep 
in mind.) In this case, the placement of commas disambiguates but it cannot be 
guaranteed that punctuation can always be used for disambiguation. In this example, 
reflect on how the two sentences are stating different logical meanings. S2 can be 
true only if “we go home” is true. But S1 can be true if “we go home” is not true but 
“it rains” is true. Reflect on this. By definition, ambiguity arises when more than one 
meanings are plausible and we cannot tell which one is intended. In formal lan-
guages like ∑, the grammatically correct formulas show clearly – perspicuously – 
what logical meaning is expressed, without ambiguity ever being allowed to arise.
We understand an ambiguous formula to be one that, on account of lacking ade-
quate placement of parentheses, can be read in more than one ways. It is important 
to realize, though, that no reading can be carried out within our formal language. 
The ambiguous formula is nonsensical – which means that it cannot “scan” or it 
cannot be processed in accordance with the stipulated grammar. Because our activi-
ties are strictly specified and constrained by the grammatical regulations we have, 
this means that an ambiguous formula is not well-formed. Formulas like the ones 
below are not in our formal language ∑. We are regarding them and talking about 
them in our metalanguage ℳ(∑). We can then carry out available disambiguations, 
executing this activity also in ℳ(∑) which is reinforced with tokens of the symbols 
we have stipulated for our formal language ∑. (We may even add more specified 
symbols to our ℳ(∑), by the way.)
•	 We establish a convention that there is no need to place the entire formula within 
parentheses. In other words, we do no need to indicate the boundaries of the 
formula by using outer parentheses. The reason we can make this convenient 
liberalization of our grammar is important and we will also state it as a more 
general principle: there is no danger of ambiguity resulting from omitting outer 
parentheses.
•	 In general: we may omit outer parentheses when there is no danger of ambiguity 
resulting from such omission.
•	 Now we make a stronger stipulation: We use parentheses only when omitting 
them would result in ambiguity. Accordingly, we don’t need to use parentheses, 
and we should not use parentheses, when there is no risk of ambiguity.
•	 Next, we establish more liberalizing conventions. These relaxations of our gram-
matical restrictions are called “liberalizing” because they allow us to omit sym-
bols or “auxiliary” support. (The parentheses are called “auxiliary symbols.”) We 
cannot arbitrarily decide what liberalizing conventions we may wish to imple-
ment. Such liberalizations have to be justifiable – as we did above in stating that 
parentheses may be omitted when no ambiguity results from such omissions. 
And the liberalizations must be stated clearly and precisely.
3  Formal Logic of Sentences, Sentential Logic (also called Sentential Logic…

99
•	 When we have uninterrupted successions of formulas connected by one of ⌜ 
∨⌝ or ⌜ ∙ ⌝ or ⌜ ≡⌝, then we can omit parentheses around the conjoined formu-
las. There is a reason why this is feasible without incurring ambiguity. We will 
explain the reason but, first, we show how it works.
•	 ⌜ (p ∨ q) ∨ r ⌝ can be written as ⌜ p ∨ q ∨ r ⌝
•	 ⌜ p ∨ (q ∨ r) ⌝ can be written as ⌜ p ∨ q ∨ r ⌝
•	 ⌜ ((−--) ∨ (___)) ∨ (===) can be written as (−--) ∨ (___) ∨ (===)
•	 the parentheses in bold can be omitted
The same is applied for formulas that have, in the place of ⌜∨⌝ above, either ⌜∙⌝ 
or ⌜≡⌝. It has to be the same symbol, not a combination of symbols, for this to be 
permissible. It follows that the following omission of parentheses is wrong!
•	 (p ∙ t) ∙ (s ∨ q)      p ∙ t ∙ s ∨ q      WRONG!
The reason for this is that inclusive disjunction, conjunction, and material impli-
cation have the characteristic property which is called association. The material 
implication connective which is symbolized by the horseshoe does not have this 
property; hence, it is wrong to remove parentheses under similar circumstances. We 
explain now what we mean by associativity or association as a property (and the 
property itself is called “associative.”)
•	 Compare the case of the familiar arithmetical operations of addition and multi-
plication. They are associative too.
•	 a + (b + c) = (a + b) + c
•	 a ⨯ (b ⨯ c) = (a ⨯ b) ⨯ c
•	 This means that the output is the same regardless of the order in which we 
carry out the operation. The results obtained from carrying out the opera-
tions in both cases are equal to each other. Or, using our terminology of 
scopes, we can think of what is in the scope of each occurrence of the 
operation sign in any one of the two available different ways. We should 
think of this property of association as permitting the shifting of parenthe-
ses either way, from the two placements you see above. But, if the outcome 
is not affected by shifting parentheses in either of the available ways, then 
we might as well omit them.
•	 Because of this we can as well write: a + b + c.
•	 Because multiplication is also associative, we can write: a ⨯ b ⨯ c.
•	 In our parallel case of our symbols of ∑, we can omit parentheses around 
successive formulas that are joined by the symbols for inclusive disjunc-
tion, conjunction, and material equivalence. The logical meaning is not 
affected regardless of which available option we take for the scope of each 
occurrence of the symbol. (Logical meaning is the collection of all the 
outputs we receive for all the possible assignments of values from {T, F} 
to the inputs. You may notice that equivalence of logical meaning corre-
sponds to the equation of the arithmetical formulas above. But to explore a 
more expansive view of this see chapter 9.)
3.2  Grammar of our Formal Language of Sentential Logic: ∑

100
•	 ⌜φ ∨ ψ ∨ χ⌝	 is well-formed.
•	 ⌜φ ∙ ψ ∙ χ⌝ is well-formed.
•	 ⌜φ ≡ ψ ≡ χ⌝ is well-formed.
•	 ⌜φ ⊃ ψ ⊃ χ⌝ is not well-formed: the connective of material implication does not 
have the property of association: the two possible placements of parentheses 
yield formulas that do not have the same logical meaning.
•	 ⌜φ ⊃ (ψ ⊃ χ)⌝ does not have the same logical meaning with ⌜(φ ⊃ ψ) ⊃ χ⌝
One more observation we need to make is this: obviously, we could always ques-
tion if the tilde applies to only the first succeeding symbol or to more than one suc-
ceeding symbol, if there are more such symbols. Does this mean that we should 
regard formulas with tildes as needing disambiguations? Or, perhaps, should we 
stipulate, as it has been done in some texts, that we use parentheses to enclose the 
symbols in the scope of the tilde even if the scope of the tilde has only one symbol 
in its scope? This latter option would compel us to regard as well-formed formula 
⌜~ (p)⌝ instead of ⌜~ p⌝. Instead, we have in our grammar that no parenthesis is 
required in the case in which only one symbol is in the scope of the tilde; this also 
compels us to take at face value that the scope of the tilde has been correctly indi-
cated as applying to the one symbol that succeeds it: we do not raise questions about 
that and, instead, assume that no such error has been committed.
•	 p ⊃ q ≡ t
•	 Disambiguations:	
(p ⊃ q) ≡ t	
\\	
p ⊃ (q ≡ t)
•	 p ∨ ~ q ∙ r
•	 Disambiguations:	
p ∨ (~ q ∙ r)	
\\	
(p ∨ ~ q) ∙ r
•	 ~ ~ p ⊃ p ≡ ~ q
•	 Disambiguations: 	 ~ ~ p ⊃ (p ≡ ~ q)	
\\	
(~ ~ p ⊃ p) ≡ ~ q
•	 ~ (p ≡ q ∨ s ⊃ t)
•	 Disambiguations:	
~ ((p ≡ q) ∨ (s ⊃ t))	
\\	
~ (((p ≡ q) ∨ s) ⊃ t)
•	 ~ (p ≡ (q ∨ (s ⊃ t)))	
	
\\	
~ (p ≡ ((q ∨ s) ⊃ t))
Another way in which absence of parentheses can result in an ill-formed (not 
well-formed) formula is when the number of left and the number of right parenthe-
ses do not match. For a formula to be well-formed, the number of left parentheses 
must be equal to the number of right parentheses in the formula. We must check to 
make sure that this is the case. If it is not the case, the formula is not well-formed. 
The following formulas are not well-formed formulas of ∑ because the numbers of 
left and right parentheses do not match.
•	 ~ p ∙ ~ (q ≡ (~ r ⊃ s)))
•	 p ∨ (q ⊃ ~ (s ∨ t)
•	 ~ (~ p ≡ (p ⊃ (q ⊃ ~ s))
•	 ~ (r ⊃ (p ∨ q)) ∙ ~ (s ∨ ~ t))
3  Formal Logic of Sentences, Sentential Logic (also called Sentential Logic…

101
No other symbols besides the ones that have been stipulated by GRAMMAR(∑) 
are recognized in ∑. We can present, compendiously, this grammar by the follow-
ing conventional means:
GRAMMAR(∑): p, p1, …, q, …/A, A1, …, B, …/~/∙/∨/⊃/≡/(/).
3.2.3  Well-Formedness
So far we have presented our symbols and specified the correct grammar for our 
formal language. Here we make some observations about the symbolic expressions 
of our formal language.
Parentheses have been presented as so-called syncategorematic symbols: what 
this means is that parentheses, as auxiliary symbols, cannot stand by themselves; 
they are not given syntactical standing for themselves but they must be used in con-
catenations with other symbols in strict accordance with the grammatical conven-
tions that are to be specified. The same will be the case with the connective symbols.
A symbolic expression or formula φ (with the symbol being metalinguistic, 
referring to a not necessarily atomic formula) is well-formed  relative to our formal 
grammar if and only if it is constructed in accordance with the stipulated grammati-
cal conventions of our formal language.
It is possible to conduct mathematically rigorous investigations and to prove 
claims about formal properties of well-formed formulas of our formal language. We 
will not dwell on this topic extensively but it is important that we sketch briefly how 
such proofs are carried out. As an example, we will prove that any well-formed 
formula (wff) of ∑ must have the same number of left and right parentheses.
The approach is based on what is called Mathematical Induction; specifically, 
our proof is by mathematical induction on the length or construction of the well-­
formed formula of ∑. The underpinning claim for the validity of this method can be 
understood as follows: if we are dealing with a systematically constructed series of 
formal entities (which are built in a systematic fashion according to a specified 
rule), then we can proceed to establish that all these entities possess certain proper-
ties, even if the series is infinite, in the following way. First we need to show that the 
basic or initiating element or entity (the base-case) possesses the property F about 
which we claim that all the elements possess. Next, we take what is called the 
Induction Step. We make an assumption: that up to the nth element, all the elements 
possess the property F. On the basis of this assumption, we have to show that the 
element following the nth element, the (n+1)th element, also possesses the property 
F. The logical rule of inference that is at work in this argument is called Modus 
Ponens: if x is true and also “if x then y” is true, then y must be true. The proof step 
we are required to present – from n to n+1 – along with the initial proof, which we 
are also required to present, that the first element possesses the property F, carries 
us along. We may present this all as follows:
•	 α has property ℱ
•	 for any n, so that ℱ(n), we prove that it follows that ℱ(n+1)
3.2  Grammar of our Formal Language of Sentential Logic: ∑

102
•	 therefore, since ℱ(α), it follows, by Modus Ponens, that ℱ(α+1)
•	 Given that ℱ(α+1), and given, as we have shown, that “if ℱ(n) then ℱ(n+1) for 
any n, then, by Modus Ponens again, we have that ℱ(α+1+1) = ℱ(α+2)
•	 and so on to ℱ(α+3), …
We apply this proof method now to show that the numbers of left and right paren-
theses must be the same for any well-formed formula of ∑. Identification of the 
base-case can be tricky sometimes but in our case we take the atomic variable, 
which is well-formed, as the base.
•	 Base: #) (p) = #((p) = 0	 [According to our grammatical stipulations we dispense 
with parentheses for the atomic variable: we have zero left and zero right 
­parentheses, which of course means that the numbers of left and right parenthe-
ses are equal.]
•	 Induction Assumption: we assume that: #) (φ) = #((φ) and #) (ψ) = #((ψ) = 0
•	 [the well-formed formulas φ and ψ are assumed to have the property of equal 
numbers of left and right parentheses.]
•	 Induction Step: Now we must distinguish and enumerate all grammatically pos-
sible ways of combining formulas to construct formulas of the next degree of 
complexity (moving from n to n+1 in terms of complexity with the relevant cri-
terion of complexity understood to be the number of connective symbols in the 
formula: hence, the method is also called Induction on the Number of Connectives; 
this is dictated by the fact that our construction of the formal series is, in our case, 
specified grammatically and this means that we apply connective symbols, prefix 
for the unary connective and infix for the binary connective symbols, to build 
well-formed formulas from given well-formed formulas.)
•	 case ~: #) (~ φ) = #) (φ) + 1 and #((~ φ) = #((φ) + 1	[placing the tilde in front of a 
well-formed formula, in prefix notation according to our grammatical stipula-
tions, compels placement of the formula within parentheses: therefore, one left 
and one right parenthesis is added to the number of parentheses of the given 
formula.] Therefore, we have:
	1.	 1. #) (φ) = #((φ)	
[this has been given by the induction assumption]
It follows that:
	2.	 #) (φ) + 1= #((φ) + 1
	3.	 3. #) (~ φ) = #) (φ) + 1 and #((~ φ) = #((φ) + 1	
	
[we showed this]
	4.	 4. #) (~ φ) = #((~ φ)	
	
[from 2 and 3]
•	 case * (where “*” is any one of the binary connective symbols):
•	 We have, by the induction assumption:
•	 #) (φ) = #((φ) and #) (ψ) = #((ψ).
•	 Given the grammatical conventions we have in our formal language, concatena-
tion of two well-formed formulas by means of infix interposition of some binary 
connective symbol requires placement of each formula within one left and one 
right parenthesis, which means that two left and two right parentheses are added 
3  Formal Logic of Sentences, Sentential Logic (also called Sentential Logic…

103
to the numbers of parentheses of the given formulas; since those numbers are 
equal, by the induction assumption, it follows that the resulting well-formed for-
mula also has equal numbers of left and right parentheses.
•	 (1) #) (φ * ψ) = #) (φ) + 1 + #) (ψ) + 1 = #) (φ) + #) (ψ) + 2.
•	 (2) #((φ * ψ) = #((φ) + 1 + #((ψ) + 1 = #((φ) + #((ψ) + 2.
•	 We have, by the induction hypothesis:
•	 (3) #) (φ) = #((φ) = k.
•	 (4) #) (ψ) = #((ψ) = m.
•	 It follows that:
•	 (5) #) (φ * ψ) = #) (φ) + #) (ψ) + 2 = k + m + 2.
•	 (6) #((φ * ψ) = #((φ) + #((ψ) + 2 = k + m + 2.
•	 Therefore, from (5) and (6):
•	 (7) #) (φ * ψ) = #((φ * ψ)
3.2.4  The Polish Notation
Next we catch a glimpse of a notation, called “Polish,” which does not need 
parentheses at all without risking ambiguous expressions on account of this. 
The Polish formal grammar is not popular anymore and is not to be found in 
any but older texts of logic, but continues to enjoy prominence in computer 
languages. This formal notation not only affords us a parsimonious use of 
parentheses but, in addition, it also allows for great transparency or perspicu-
ity as to the scopes of the various connective symbols. This notation uses only 
prefix notation for all connective symbols including both unary and binary. 
Let us roll out the stipulations for symbolization and show examples of imple-
mentation within a symbolic idiom we may label “∑POLISH”. We can legislate 
any connective symbols we wish but let us preserve the flavor of the original 
Polish notation, in which capital letters are used for the various connectives as 
shown below. We show diagrammatically how the automatic binding works in 
this grammar and we also show the corresponding well-formed formulas 
expressing the same form in ∑.
3.2  Grammar of our Formal Language of Sentential Logic: ∑

104
∑POLISH
∑
Np
Apq
Kpq
Cpq
Epq
Examples
NApq
CpCst
NAqKst
~ p
p ∨ q
p ∙ q
p ⊃ q
p ≡ q
Examples: ~ (p ∨ q)
p ⊃ (s ⊃ t)
~ (q ∨ (s ∙ t))
We are able to study, metalogically, the characteristics of this formal lan-
guage by using certain devices: in order to determine that a given symbolic 
expression is a well-formed formula of this notation or not, we examine as 
follows – after we have defined two concepts.
=== Weights of connective symbols: (p) = (q) = … = 0; (N) = 1; (A) = (K) 
= (C) = (E) = 2.
=== Weight of an expression: (φ):: the sum total of the weights of all the 
symbols.
A formula of ∑POLISH is well-formed if and only if the following two condi-
tions are met:
•	 λ(φ) = (φ) + 1
•	 (Ϭ(φ)) ≤ (φ)	 	
for all subsegments of φ
•	 Examples:
•	 NAqKstp 	 	
	
== not well-formed: violates conditions
•	 λ(NAqKstp) = 7 ≠ (NAqKstp) + 1 = 5 + 1 = 6
---Example: (CpCst) = (C) + (p) + (C) + (s) + (t) =.
= 2 + 0 + 2 + 0 + 0 = 4.
=== Lengths of well-formed expressions: λ(φ):: the total number of 
symbols.
---Example: λ(NaqKst) = 6.
=== Subsegment of a well-formed formula: Ϭ(φ):: the set of all possible 
sequences of symbols in the formula from the left to the right.
---Examples: φ = NApq.
Ϭ(φ) = {N, NA, NAp, NApq}
3  Formal Logic of Sentences, Sentential Logic (also called Sentential Logic…

105
3.2.5  Exercises
	 1.	 We have seen how to present the rules of grammatical formation for our formal 
language ∑ in a way that is called recursive or inductive. We state, in a sym-
bolically enhanced metalanguage, the conditions for possession of the property 
of well-formedness by the ancestral symbolic items: these are the atomic vari-
ables which are declared well-formed, as we have seen. Subsequently, we spec-
ify how this property, of well-formedness, is inherited by means of manipulations 
of symbols. In this mode of definition, we avoid circularity too. It is notable that 
we can do this for other formal characteristics in the following way. We specify 
the output, which has to be unique or functional, for the base case which is the 
atomic variable; subsequently, we define the specified (always unique or func-
tional) outputs for the cases of all the connective symbols. For example, regard-
ing the number of parentheses (and incorporating the liberalized grammatical 
condition that permits omission of parentheses when no ambiguity arises), we 
have for the function 𝑓 assigning integers to the symbol-inputs as shown below. 
This way of defining the function is also called recursive.
𝑓(p) = 0.
𝑓(~ φ) = 𝑓(φ).
𝑓(φ * ψ) = 𝑓(φ) + 𝑓(ψ)/ * ∈ {∙, ∨, ⊃, ≡}.
Now given recursive definitions of the functions for the following formal 
attributes:
	
a.	 number of atomic variables in the well-formed formula
	
b.	 number of connective symbols in the well-formed formula
	
c.	 number of binary connective symbols in a well-formed formula
	
d.	 maximal connective depth of a well-formed formula, where maximal con-
nective depth is defined as the number of connective symbols within the 
scope of the connective symbol that has the greatest number of such connec-
tive symbols nested within its scope (e.g. marking occurrences of the con-
nective symbols from left to right:  (~ p ∨ (~ p ∙ ~ ~ q))) = max( (~1), (∨), (
~2), (∙), (~3), (~4)) = max(0, 4, 1, 0) = 4)
	 2.	 We have constructed a formal grammar for our language ∑ and we have used a 
symbolically reinforced metalanguage ℳ(∑) using its resources to speak about 
∑. Which of the following expressions are in ∑ and which expressions are in 
ℳ(∑)? Can an expression be a member of neither ∑ nor of ℳ(∑)?
	
a.	 ⌜ p ∨ p ~⌝ is not a member of the set of well-formed formulas of ∑.
	
b.	 ⌜ p⌝ implies ⌜ p ∨ q⌝.
	
c.	 ~ p ≡ ~ (~ p ≡ ~ ~ p)
	
d.	 ⌜ p ≡ q⌝ and ⌜(p ⊃ q) ∙ (q ⊃ p)⌝ are mutual logical equivalents.
	
e.	 ℾ!#$%#
	
f.	 ~ ~ ~ (p ⊃ (p ⊃ ~ ~ p))
	
g.	 p ≡ ~ (q ⊃ (~ q ∙ ~ s
3.2  Grammar of our Formal Language of Sentential Logic: ∑

106
	
h.	 The number of left parentheses of a well-formed formula of our language is 
equal to its number of right parentheses. Therefore, if the numbers of left 
and right parentheses of a symbolic expression are not equal to each other, 
then that symbolic expression is not a well-formed formula of our language.
	
i.	 ∑ ⊢ ~ (p ∙ ~ p)
	 3.	 We would never confuse talking about New York the city with the name of 
New York, “New York,” which has collectively seven letters while it is nonsen-
sical to speak of the city itself having letters. The situation, however, is tricky 
when we speak in the metalanguage of a formal language about the symbols of 
that formal language. A standard distinction drawn in rather advanced texts is 
between use and mention of formal symbols. Quotation marks ought to be used 
when the word is not used but mentioned: another way of putting this is that 
when the word is mentioned, the within-quotations word has as its referent a 
word, not an object; when the word is deployed so that it is used, then its refer-
ent is an object. If a word is specifically defined as being a name, quotation 
marks are not needed: we write, “if another name for “Mary” is “Maria,” then 
Maria is the same person as Mary.” In the following examples, determine if the 
underlined word is used or mentioned – and, if mentioned, it requires quota-
tion marks.
	
a.	 According to one theory, Socrates means “he who holds life in his hands.”
	
b.	 There are five letters in Plato.
	
c.	 Socrates was the teacher of Plato.
	
d.	 Hesperus is the same star as Phosphorus, which is Venus.
	
e.	 No one knew that Slew was a nickname of Slugman, but Slew and Slugman 
were actually the same person.
	
f.	 Aardvark is a small nocturnal animal that lives in Africa and aardvark is also 
the first word in the dictionary of the English language.
	
g.	 The person known as Clemens is no other than the person known as Twain. 
Therefore, Twain is the same person as Clemens.
	
h.	 Given that John’s last name is Slight, the identified missing person is 
John Slight.
	
i.	 Macedonia has been renamed as North Macedonia.
	
j.	 The following is not a valid inference! Place quotation marks as appropriate 
and discuss the problem with this inference. Giant was so named because of 
his size; but Giant is the same person as Stump. Therefore, Stump was so 
named because of his size.
	
k.	 Even though ½ = ¼ yet the denominator of ¼ is divisible by 4 but the denom-
inator of ½ is not! – It is not conventional to place quotation marks in this 
type of mathematical expression, but discuss how the apparent error of 
thinking that this is paradoxical is related to the subject of the distinction 
between use and mention.
	 4.	 Which of the following symbolic expressions are well-formed formulas of ∑ 
and which are not? Refer to the rules of our formal language to justify your 
3  Formal Logic of Sentences, Sentential Logic (also called Sentential Logic…

107
answer. Keep in mind that we have liberalized our grammatical conventions: 
parentheses are needed only when omitting them would result in ambiguity. 
Accordingly, successive uninterrupted disjunction, conjunction and equiva-
lence symbols do not need parentheses. We also allow omission of outer paren-
theses (although we cannot regard it as an error to include such.) We have 
provided for one type of parentheses, not supplementing this type of symbol 
(which is called auxiliary symbol) with other kinds of brackets, which could 
perhaps make the formulas “easier on the eye.” We have not supplied any addi-
tional regulations that could assist in saving parentheses (something that was 
once common practice, and required quite some time and effort to get used to.) 
Finally, we have allowed for subscripts for individual variables, from the posi-
tive integers, although we might not have much of an opportunity to use this 
convention in this text.
	
a.	 ∑p ≡ ~ (~ p ⊃ q)
	
b.	 ~ (p)
	
c.	 ~ ~ ~ ~ p
	
d.	 p ⊃ (p ⊃ (p ⊃ ~ p))
	
e.	 (p ⇒ q) ≡ ~ (q ⇒ p)
	
f.	 (p21 ∙ p33) ≡ (~ q ∨ (~ q2 ∨ (p6 ⊃ q)))
	
g.	 ∨pq ≡ ∨qp
	
h.	 ~ (p ⊃ ~ q) ⊃ ~ (p ∨ (q ∙ ~ s))))
	
i.	 p ⊃ q. ⊃. ~ (s ≡ t)
	
j.	 p ∨ ~ q ∙ ~ s
	
k.	 s1 ∨ s2 ∨ s
	
l.	 p ∙ p ∙ p ∙ ~ p
	 5.	 Rewrite the following well-formed formulas of ∑ as well-formed formulas in 
the Polish notation ∑POLISH. Revisit this exercise after the next section on pars-
ing trees for well-formed formulas.
	
a.	 ~ (p ∙ ~ p)
	
b.	 p ⊃ (q ⊃ p)
	
c.	 (p ∙ p) ≡ (q ⊃ q)
	
d.	 (p ∨ (q ∙ r)) ≡ ((p ∨ q) ∙ (p ∨ r))
	
e.	 (p ⊃ ~ p) ⊃ ~ (p ∨ ~ ~ p)
	
f.	 (~ ~ p ≡ p) ≡ ((p ⊃ q) ⊃ (~ p ∨ q))
	
g.	 (p ⊃ (q ⊃ r)) ≡ ((p ∙ q) ⊃ r)
	
h.	 ~ (p ∨ ~ q) ⊃ (q ∙ ~ p)
	
i.	 ~ (~ (p ⊃ (q ⊃ ~ p)))
	 6.	 Disambiguate the given ambiguous formulas by using parentheses to write out 
all possible well-formed formulas; express all possibilities (all disambiguations 
or disambiguating formulas.) Not all formulas are ambiguous. There may be 
more than one disambiguating formulas. Remember that the tilde attaches 
unambiguously to an individual letter. Also, keep in mind that the wedge, dot 
3.2  Grammar of our Formal Language of Sentential Logic: ∑

108
and triple bar denote transitive connectives (as we have explained) and no need 
arises to disambiguate if only such connective symbols are involved.
	
a.	 p ∨ q ∙ r
	
b.	 (p ∨ q) ∙ r
	
c.	 p ∨ (q ∙ r)
	
d.	 p ≡ ~ q ∨ r
	
e.	 p ⊃ q ⊃ r
	
f.	 ~ p ∨ q ⊃ r
	
g.	 t ≡ r ≡ s
	
h.	 p ∙ ~ s ⊃ t
	
i.	 q ∨ r ∨ s
	
j.	 ~ (p ∙ q) ∨ r ≡ s
	
k.	 p ≡ p ∙ ~ q ⊃ r
	
l.	 p ∨ s ⊃ s ∨ t
	 7.	 Provide the translations into ∑ of the following symbolic expressions which 
are well-formed in ∑POLISH.
	
a.	 NNCpq
	
b.	 CpCqp
	
c.	 CKpCpqq
	
d.	 NCKpCpqNp
	
e.	 CNApqKNpNq
	
f.	 CpCpCpCpp
	
g.	 EApKqrKApqApr
	
h.	 CCpCpqKpq
	
i.	 EKCpqCqpKEpqEqp
	 8.	 The following symbolic expressions are not well-formed in ∑ because they are 
ambiguous. Disambiguate – which means that you should provide all the differ-
ent well-formed, unambiguous, formulas which can be produced from each one 
of the given expressions.
	
a.	 p ⊃ s ∨ t
	
b.	 ~ p ⊃ s ∨ t
	
c.	 p ⊃ q ⊃ p
	
d.	 ~ p ∨ ~ (q ⊃ s ≡ t)
	
e.	 ~ p ⊃ q ⊃ ~ q
	
f.	 p ∨ q ∨ s ∙ t ⊃ ~ p
	
g.	 (p ⊃ q ∨ s) ⊃ (q ⊃ p ⊃ s)
	 9.	 Why are the following symbolic expressions unambiguous well-formed formu-
las, and so not in need of disambiguation?
	
a.	 ~ p ⊃ q
	
b.	 p ∨ ~ q ∨ ~ s
	
c.	 q ∙ s ∙ r ∙ t
3  Formal Logic of Sentences, Sentential Logic (also called Sentential Logic…

109
	
d.	 (~ p ∙ q) ≡ ~ (~ q ∙ r) ≡ ~ (q ⊃ t)
	
e.	 ~ ~ p ⊃ ~ ~ p
	
f.	 ~ q ∨ ~ ~ q ∨ ~ ~ ~ q
	10.	 Indicate the scopes of all the connective symbols and determine which is the 
major connective symbol of each of the following well-formed formulas.
	
a.	 ~ ~ ~ p
	
b.	 (p ≡ ~ q) ≡ ~ (~ q ⊃ ~ ~ p)
	
c.	 p ∨ ((q ∨ r) ∨ s)
	
d.	 ~ ~ ~ p ≡ ~ p
	
e.	 ~ p ≡ ~ (p ⊃ (q ⊃ p))
	
f.	 (p ∨ (q ∙ r)) ≡ ((p ∨ q) ∙ (p ∨ r))
	
g.	 p ∨ ((q ∙ r) ≡ ((p ∨ q) ∙ (p ∨ r)))
	
h.	 p ⊃ (p ⊃ (p ⊃ (p ⊃ p)))
	
i.	 (((p ⊃ p) ⊃ p) ⊃ p) ⊃ p
	
j.	 ~ (p ⊃ ~ (p ⊃ ~ (p ⊃ ~ p)))
	
k.	 ~ ((p ⊃ q) ⊃ ~ (p ⊃ ~ q))
3.3  Parsing Trees of Well-Formed Formulas of ∑: ℑ(∑)
Now that we have mastered the grammar of ∑, we can use a diagrammatic method, 
called the Parsing Tree of a well-formed formula (ℑ(∑)), to carve a wff of ∑ starting 
with the largest-scope symbol and proceeding until we have obtained all the atomic 
letters in the formula. Although we don’t discuss metalogical characteristics of for-
mal systems in this text, the parsing tree can assist us in consolidating our grasp and 
facility with manipulating the formal grammar; it will also help us obtain the sub-
formulas of a given wff (well-formed formula); and, finally, it prepares us for deal-
ing with other diagrammatic arrangements  – like the semantic trees we will be 
studying in 4.7.
A tree is actually a systematically constructed abstract mathematical object that 
can be studied rigorously; but we are not interested in such advanced explorations. 
We have to adjust, however, to speaking precisely about certain items on the tree 
and we need to use specific terms to do this. The tree has a root; that is where the 
given formula is placed. We say that the root is labeled by the formula. Unlike natu-
ral trees, this mathematical diagram has its root at the top. The branches issue from 
the root; from each branch, more branches can be issued; when we trace a branch 
from the top and its attached branches all the way to the bottom, we are tracing what 
we call a path. We need to know when the tree has reached the bottom or end – when 
it has terminated. The terminus is at the bottom – while the root is, as we indicated, 
at the top. Termination happens only when we don’t have any formulas left besides 
atomic letters. Thus, we can say that the terminal nodes are exactly those labeled by 
atomic variable letters.
3.3  Parsing Trees of Well-Formed Formulas of ∑: ℑ(∑)

110
We also need to know how we proceed, given the root of the tree, to take actions 
so as to originate the branches. We need rules for this. In the case of the parsing tree, 
these rules are simply connective-symbol rules: for each connective symbol we find 
in the given formula, we remove it and, underneath, we branch and label the subse-
quent nodes with the subformulas that remain after removal of the connective-­
symbol. We call the part of the tree labeled by this remaining formula a node. We 
start removing connective symbols beginning with the largest-scope connective 
symbol and proceeding with removing narrower-scope connective symbols. Thus, 
what we learned in preceding section regarding scopes is presupposed and put to 
work in this section.
As we have seen, a tree has nodes, in addition to root and branches and their 
constituted paths. The nodes at the very bottom, all marked by atomic letters, are 
called terminal nodes. We can consider the rules that instruct us how to proceed to 
be like recipes for how to draw a parsing tree: they are, themselves, shape-like or 
schematic recipe-trees giving us instructions about how to proceed.
We begin with the rule for the only monadic connective symbol we have in our 
formal language – the rule for the negation symbol: the ~-Rule. As we have done 
before, we use φ to represent any wff (not necessarily atomic.) Note how we name 
the rule we are applying (“~−R”) to the right of the downward arrow.
~ φ
⇓~R
The tilde rule is a monadic-connective rule: the tilde is, obviously, a monadic-­
connective symbol. Removing the tilde, the rule leaves what is left from the for-
mula, which is φ. What is left is put on the node that is branched underneath. We can 
now guess, correctly, that the other rules – all of them for the remaining binary 
connective symbols, have two branches issuing – one to the left and the other to the 
right: this is because removal of the binary connective symbol leaves the two for-
mula-parts that are connected by the binary connective symbol. We can show the 
rules – the recipes, also called schemata – for the binary connective symbols.
φ ∙ ψ
φ ∨ ψ
φ ⊃ ψ
φ ≡ ψ
⇙⇘ ∙R
⇙⇘ ∨R
⇙⇘ ⊃R
⇙⇘ ≡R
φ   ψ
φ   ψ
φ   ψ
φ   ψ
As an example, let us study an example of some random wff, given to us, on 
which we will apply the parsing tree rules. To mark that we have reached a terminal 
node, we place the symbol “⊙” underneath the terminal node.
φ
3  Formal Logic of Sentences, Sentential Logic (also called Sentential Logic…

111
 
We have completed the parsing tree ℑ(~ (~ p ≡ ~ (~ q ⊃ (s ∨ t)))) for the given 
formula. We have reached the terminal nodes: only atomic letters remain at the ter-
minal nodes (marked underneath them, each by “⊙”); it is not possible, of course, 
to apply rules on the atomic letters since the rules are for connective symbols. Let 
us review the above parsing tree. The top box is the root and it contains – it is 
labeled by – the given wff (well-formed formula). The largest-scope connective 
symbol is the first occurrence of the tilde. We apply the ~R and we branch vertically 
down to the second box which is a node. The largest-scope connective symbol in 
this node is the binary connective triple bar – the first occurrence of this symbol. We 
apply the rule for this connective; because it is a binary connective symbol, we have 
now two branches splitting with one branch to the left and one branch to the right. 
We continue by applying connective rules in the same way until we reach the termi-
nal nodes.
Let’s see now how we trace the paths in the above parsing tree. This is a helpful 
exercise in anticipation of other tree types, which we will be using in subsequent sec-
tions. To show the paths, assisting by means of visual recognition as we try to grasp 
the concept, we characterize each path by showing the nodes in the path. The root 
belongs to every path. This should make sense, as you think about it and survey the 
diagram of the parsing tree. To show the paths, we reproduce the parsing tree and 
place superscripts to the nodes: counting from left to right, we use superscripts from 
the positive integers. You should expect that paths may share branches – in other 
words, a branch may belong to more than one path; and, as we have already pointed 
out, the root belongs to every path. The terminal nodes, on the other hand, are not 
shared: each terminal node belongs to one and only one path. To show that the root 
belongs to all the paths, we place on it all the superscripts. Overall, there are 4 distinct 
paths in this parsing tree. Similarly, we place more than one superscripts, as needed, 
to show all the paths to which a node belongs. Check the symbol “⊙”: this indicates 
that exactly above it the path has terminated; the branch you find there is terminal and 
the node (marked by some atomic letter) is terminal. Starting with noting the terminal 
nodes, check what superscript number each such node is given: then, follow upwards 
to trace the path by including every node that has this superscript. Let us practice this.
3.3  Parsing Trees of Well-Formed Formulas of ∑: ℑ(∑)

112
 
Here are the paths of this parsing tree. We are placing the formulas belonging to 
each path within set-brackets.
Path1: {~ (~ p ≡ ~ (~ q ≡ (s ∨ t))), ~ p ≡ (~ q ≡ (s ∨ t)), ~ p, p}.
Path2: {~ (~ p ≡ ~ (~ q ≡ (s ∨ t))), ~ p ≡ (~ q ≡ (s ∨ t)), ~ q ≡ (s ∨ t), ~ q, q}.
Path3: {~ (~ p ≡ ~ (~ q ≡ (s ∨ t))), ~ p ≡ (~ q ≡ (s ∨ t)), ~ q ≡ (s ∨ t}, s ∨ t, s}.
Path4: {~ (~ p ≡ ~ (~ q ≡ (s ∨ t))), ~ p ≡ (~ q ≡ (s ∨ t)), ~ q ≡ (s ∨ t}, s ∨ t, t}.
Finally, we will show how we can extract all the subformulas of the given well-­
formed formula from the parsing tree. Simply, we take all the formulas that mark the 
nodes – all the nodes – and they all constitute subformulas of the given formula. 
This includes the formula in the root: in other words, the formula itself is considered 
to be one of its subformulas. If more than one nodes have the same formula, we 
don’t repeat it; we include it once in the set of subformulas.
Using the set notation, we have:
SUBFORMULAS(~ (~ p ≡ ~ (~ q ⊃ (s ∨ t)))) =
= {~ (~ p ≡ ~ (~ q ⊃ (s ∨ t))), ~ p ≡ ~ (~ q ⊃ (s ∨ t)), ~ p, ~ q ≡ (s ∨ t), p, ~ q, s 
∨ t, q, s, t}.
We close by remarking that every well-formed formula of ∑ has a unique parsing 
tree. We could prove this by using a metalogical proof method, called Mathematical 
Induction on the construction of the well-formed formula. We can also call the pars-
ing trees by the name of “decomposition trees.” We can then make the assertion that 
every well-formed formula of ∑ has a unique decomposition tree. If any two pre-
sumed well-formed formulas of ∑ has the same parsing or decomposition tree, it 
turns out after all that we are dealing not with two but with one well-­formed formula.
3.3.1  Extracting the Polish Notation of the Formula 
from the Parsing Tree
An interesting procedure we can report on, related to the parsing tree system we 
have devised, ℑ(∑), allows us to extract the Polish notation for the formula by read-
ing the formula’s parsing tree in the appropriate fashion. We begin from top left: we 
3  Formal Logic of Sentences, Sentential Logic (also called Sentential Logic…

113
write the first connective symbol we find moving downwards; similarly with the 
next connective symbol moving downwards on the left branch, if any; we disregard 
compound formulas but we do write atomic variable symbols; we move to the next 
branch to the right and we operate in the same fashion from top to bottom; we move 
to the next branch to the right and we proceed in the same fashion; when we reach 
nodes where branches are split to left and right, we read, again, from left and from 
top to bottom;… and so on until we come to the terminus at the rightmost bottom 
point of the rightmost branch of the parsing tree. Let us apply this procedure to the 
example provided above: writing informally first we produce an expression and 
then we can translate into ∑POLISH as we presented this formal idiom in the preced-
ing section. The formula we extract can be read straightforwardly based on the 
procedure we have specified, formidable though it seems to be. The effort we are 
expending in negotiating translations into the Polish notation may seem idle as a 
pastime but there are many classics of logic, which use this notation; moreover, one 
meets this notation in many fields in which symbolic languages are constructed. 
Although at first hard to muster, the Polish notation presents decided advantages in 
showing the structure of the formula (in terms of its major connective and scopes of 
connectives) perspicuously once one becomes attuned to this formal idiom; but the 
most impressive advantage consists in that no parentheses are needed for this nota-
tion – and this can economize significantly in symbolic resources when it comes to 
implementations of formal languages. On the other hand, it may be claimed that this 
notation is not intuitively appealing, but it can be questioned if this is not a result of 
lacking familiarity with this formalism.
~ (~ p ≡ ~ (~ q ≡ (s ∨ t))) ↠	
~≡~p≡~q∨st ↠	 NENpENqAst
3.3.2  Exercises
	1.	 Answer the following questions:
	
a.	 Why do we need to determine the major connective symbol (the largest-scope 
connective symbol) before we can begin our construction of a given formula’s 
parsing tree?
	
b.	 How can we extract the subformulas of a given well-formed formula (wff) 
from its parsing tree?
	
c.	 In sentential logic, the truth value (true-false) of the entire formula depends 
on – and can be determined from – the truth values of the individual letters in 
the formula. In 4.4, we will study details of this under “computations.” Here 
is a preview of the underlying concepts. Suppose that you are given the posi-
tive integers 2 and 3 and are asked to carry out a computation. You can’t do 
that unless you are told what operation you are supposed to carry out. Let’s 
specify addition as the operation. Then, you can compute that the addition of 
2 and 3 yields 5 as output. In sentential logic we are not computing by apply-
ing operations like addition or multiplication: our operations are, instead, 
3  Formal Logic of Sentences, Sentential Logic (also called Sentential Logic…

114
specified by our connectives. And what about the values or numbers with 
which we are to carry out the computations? In sentential logic, we have 
exactly two values: true and false. It might seem strange that we are comput-
ing with anything other than numbers; suppose, then, that we could be using 
1 and 0. The point is that the definitions of our connectives will allow us to 
determine uniquely what output we get for any specified inputs. If you think 
that we are playing an unusual algebraic game deep down – that’s fine! Why 
do you think that we cannot construct alternative algebras? We can! As an 
example, roughly speaking: suppose we compute as follows: True and True is 
True; True and False is False; and so on. Note that the connectives are the 
operators and the values we are computing with are true and false. Using all 
this information, can you explain why we need rules for connective symbols 
in order to construct a parsing tree? Why do we “carve” our well-formed 
formulas around connective symbols? Why do we start with the largest-scope 
connective symbol?
	2.	 Construct the parsing tree for each of the well-formed formulas given below. 
After you have finished constructing the parsing tree present all the subformulas 
of the given formula.
	
a.	 p ⊃ (q ⊃ p)
	
b.	 (p ⊃ (q ⊃ r)) ⊃ ((p ⊃ q) ⊃ (p ⊃ r))
	
c.	 (p ⊃ (p ⊃ p)) ⊃ p
	
d.	 ~ (~ p ∙ ~ ~ p)
	
e.	 p ⊃ (q ≡ (p ∙ q))
	
f.	 ~ ~ ~ p ∙ ~ (p ⊃ ~ q)
	
g.	 (p ∨ ~ q) ≡ ~ (~ p ∙ q)
	
h.	 (p ⊃ ~ q) ⊃ (q ⊃ ~ p)
	
i.	 ((p ⊃ q) ∨ (q ⊃ p)) ⊃ ~ (p ∙ ~ p)
	3.	 Extract the Polish notation formulas for the formulas of the preceding exercise 
by reading the parsing tree of the formula in the appropriate fashion.
3  Formal Logic of Sentences, Sentential Logic (also called Sentential Logic…

115
© The Author(s), under exclusive license to Springer Nature 
Switzerland AG 2022
O. Makridis, Symbolic Logic, Palgrave Philosophy Today, 
https://doi.org/10.1007/978-3-030-67396-3_4
Chapter 4
Sentential Logic Languages ∑
Our formal language ∑ has symbols for several connectives. The symbols denote or 
refer to functions which we call truth functions: this means that their inputs and out-
puts are from the set of truth values, {T, F}. The connectives of ∑ are to be defined, 
as we say, over {T, F}. Truth values are semantic elements; they provide a semantic 
base – considering that logical meaning is a matter of truth value in deductive logic. 
When we come to the study of the semantic system of truth tables, or to any use of 
truth tables, we will see how meaning-­narratives are to be constructed; this is also 
called modelling  – and, as we said above, this is characteristic of the semantic 
approach. Indeed, we will be using the truth tables to define our connectives. This is 
a staple of Logic textbooks. We will also present another, algebraic-looking, mode of 
definition of the connectives. The alternative definitions betray an underlying alge-
braic infrastructure of the standard sentential logic. We can say, more precisely, that 
a semantic formal language of sentential logic interprets systematically a special 
algebra that has two numbers only and operations defined over those two numbers: 
this is the famed Boolean algebra, which has found other important interpretations in 
Set Theory, computer language programming, and electronic circuit designing to 
mention a few celebrated examples.
4.1  Definitions of the Connectives by an Equational Method
The connectives of ∑ are defined over the two truth values, true and false, respec-
tively symbolized by “T” and “F.” The rules for our formal language are:
•	 There are exactly two truth values, true and false, T and F. This means that there 
can be neither more nor fewer truth values.
•	 T and F are so related that T is not F and F is not T. This sounds trivial but the 
point is that we do not allow degrees of being T or F and we do not allow 

116
­definitions that relate sentential variables to T and F (in which case we could 
relate sentential variables to both or to neither T and F.) Sentential logic has an 
on-off switch character about it: it is either T or F; it cannot be both and it cannot 
be neither.
•	 Of the two truth values, T and F, T is the “winning” value (more broadly called 
“designated”) and F is the “losing” (anti-designated) value. Alternative logics can 
be constructed (which would also be truth-functional), whose base of truth values 
contains more than the classical two truth values; one or more of those truth val-
ues ought to be designated, with the rest being anti-designated. Such alternatives, 
not pursued in this text, can be motivated philosophically by various relevant con-
siderations; there is controversy surrounding such constructions and what they 
stand for exactly. We may think of those alternative logics as admitting possibly 
more than one ways of being true, and possibly more than one ways of being false, 
while the classical or standard logic restricts the ways of being true and the ways 
of being false to the minimal case. The standard logic of two values could emerge 
as a special case of the alternatives but, something that is easy to miss, the logical 
meanings (of the values themselves and of the defined connectives) are altered by 
default when an alternative, many-valued, logic is constructed.
•	 Every sentential variable has to be assigned one or the other of T and F.
•	 No sentential variable can fail to take one or the other of the two values.
•	 No sentential variable can be assigned both T and F.
•	 We are ultimately interested in systematic assignments of T and F to all of the 
individual variables (or atoms) of well-formed formulas. The truth table will 
assist us in grasping this fundamental concept, on which we will be expatiating 
further. We are interested in the totality of all possible truth-value assignments 
(valuations or also called interpretations) to the atomic variables (and, by com-
putation, the resulting truth values for the entire formula for each case of valua-
tion of the atomic variables). The definitions of the connectives are also stipulated 
for such totalities. As a ready approximation, and convenient example, we may 
consider this: the logical meaning, or definition, of the negation connective is 
understood to consist not just in its operation that turns true to false but rather to 
consist in the totality of cases: turning true to false and turning false to true. In 
the language of functions, the underlying truth function of the negation connec-
tive is not defined as a partial function (which would be the case in defining the 
function only for one of the two available value-inputs.)
It is a foundational principle that the connectives receive their meanings from 
what we call their truth conditions. This is not a familiar concept and we need to 
concentrate in order to understand it. Do not seek parallels in familiar experiences 
as this is an abstract subject and it might even have certain unintuitive aspects to it. 
If we try to take our clues from language, we can venture a certain gloss that might 
be helpful. A language like English has certain logic-words in it, like “not” and 
“and” and, in fact, two different meanings of “either-or.” Such words are defined not 
by means of their reference to some object (like “John” is defined by the person it 
names or “bird” is defined so that its symbol could even be a hieroglyphic symbolic 
4  Sentential Logic Languages ∑

117
representation that looks like a bird – conventionally laid down, even though it is 
still a symbol.) When it comes to a word like “not,” which is a logic-word, what 
object does it refer to? Could we fix a symbol for it that looks, and is agreed conven-
tionally to represent, some object? It seems that we cannot do that. Well, the defini-
tion of the meaning of “not” fixes that what is to be symbolized is the operation that 
turns true to false and false to true. We just intimated that the definition of “not” is 
given by its truth conditions: there are two possible cases for “not” – only two, 
because “not” operates always on one sentence which it negates. One case is T and 
the other is F. For binary logic-words, their truth conditions require that we take all 
the possible cases (assignments of truth values to the atomic components or inputs) 
and present the fixed result (what truth value, T or F, is yielded for each case.) 
Bearing the above in mind, we can proceed to the definitions of the connectives. We 
approach this task first by means of our alternative method, reserving the truth table 
definitions for later.
definition(~) /~ T = F/~ F = T/.
For binary connective symbols, we need specification of all the logically possible 
(and mathematically available) combinations of truth values (true and false) for the 
two components. There is a mathematical formula that allows to determine always 
and with precision and accuracy how many such combinations are logically possi-
ble: if the number of the inputs is n, then the logically possible combinations of truth 
value assignments to the inputs is 2n. Thus,
•	 n = 1 (unary, monadic connective symbols): number of logically possible truth-­
value assignments: 2n = 21 = 2.
•	 n = 2 (binary, dyadic connective symbols): number of possible truth-value assign-
ments to the atomic variables: 2n = 22 = 4. We will need a systematic method for 
determining how we can produce all and only the possible combinations so that 
we do not miss any and do not include unavailable combinations while we also 
ensure that we do not redundantly repeat any combinations more than once. We 
will see how this can be done.
•	 n = 3 (ternary, triadic connective symbols): number of possible truth-value 
assignments to the atomic variables: 2n = 23 = 8. We don’t have any such connec-
tives in our formal language ∑.
•	 General case: n: (nary or n-place connective symbols): number of possible truth-­
value assignments to the atomic variables: 2n.
Let us take the case in which we seek to determine all the logically possible 
combinations of T and F as inputs for binary connective symbols. We can draw a 
matrix as shown below.
2n = 22 = 4
T
F
T
<T, T>
<T, F>
F
<F, T>
<F, F>
4.1  Definitions of the Connectives by an Equational Method

118
DEFINITIONS
This chart shows us all the mathematically available combinations. The input-­
combinations are represented within special brackets, “<” and “>”. There is a reason 
for this: the order in which the symbols are written matters! These are ordered pairs: 
for instance, the ordered pair <T, F> has the value T as left member and the value F 
as right member; this is not the same as the ordered pair <F, T> for which F is the 
left member and T is the right member. We need to write all of the ordered pairs; 
each ordered pair expresses a possible combination of truth values; we must include 
all the possible ordered pairs or combinations. There are more than one recipes for 
how to do this correctly but we shall stipulate starting from the northwestern corner 
of the inputs and moving east and then south-southwest and east again, as shown in 
the above chart by the use of arrows. Accordingly, we have:
<T, T>, <T, F>, <F, T>, <F, F>.
This is our currently established order for presenting all the mathematically pos-
sible combinations of values assigned to two variables. When we use truth tables to 
give definitions of our connective symbols, we will present the recipe in another way.
We give now the definitions of the connective symbols. We are doing this in the 
metalanguage of our formal language, ℳ(∑). The symbol “=” we use is metalin-
guistic and is used in the way that is familiar from algebraic equations. This should 
not be confused with the use of the same symbol – accidentally, as it were – when 
we study predicate logic. In the formal language of predicate logic, this symbol 
stands for identity (of the objects that are referred to) and not for equality.
We can make certain observations about these definitions, which, incidentally, 
should assist with solidifying understanding and memorization of the connectives’ 
meanings.
•	 The tilde, symbolizing negation, reverses the truth value, from T to F and 
from F to T.
•	 The dot, symbolizing conjunction, is true only when both its inputs are true; it is 
false in every other case; it is false in every case in which even only one input is 
false (and, of course, also when both inputs are false.)
•	 The wedge, symbolizing inclusive disjunction, is false only when both inputs are 
false; it is true in every other case; it is true in every case in which even only one 
input is true (and also, of course, when both inputs are true.)
•	 The horseshoe, symbolizing implication or the conditional, is false only when the 
first input or input-to-the-left (called antecedent) is true and the second input (called 
•	 ~ T = F /~ F = T
•	 T ∙ T = T / T ∙ F =F / F ∙ T = F/ F ∙ F = F
•	 T ∨ T = T/ T ∨ F = T/ F ∨ T = T / F ∨ F = F
•	 T ⊃ T = T/ T ⊃ F = F/ F ⊃ T = T/ F ⊃ F = T
•	 T ≡ T = T/ T ≡ F = F/ F ≡ T = F/ F ≡ F = T
4  Sentential Logic Languages ∑

119
consequent) is false; it is true in every other case; it is true in every case in which the 
antecedent is false regardless of the truth value of the consequent; it is true in every 
case in which the consequent is true regardless of the truth value of the antecedent.
•	 The triple bar, symbolizing equivalence or the biconditional, is true in the cases 
in which both inputs have the same truth value (regardless if this is T or F); it is 
false on every other case; it is false in every case in which the inputs have differ-
ent truth values.
Accordingly, we could provide the definitions as follows, using the metalinguis-
tic symbol “| |” to indicate the truth value of any well-formed formula of ∑ (symbol-
izing such formulas by φ andψ):
•	 |~φ | = T when |φ| = F; |~φ| = F otherwise.
•	 |φ ∙ ψ| = T only when |φ| = |ψ| = T; |φ ∙ ψ| = F otherwise.
•	 |φ ∨ ψ| = T when either |φ| = T or |ψ| = T; |φ ∨ ψ| = F otherwise.
•	 |φ ⊃ ψ| = F only when |φ| = T and |ψ| = F; |φ ⊃ ψ| = T otherwise;
•	 Equivalently, |φ⊃ ψ | = T when either | ~ φ| = T or |ψ| = T; it is false otherwise.
•	 |φ ≡ ψ| = T only when |φ| = |ψ|; |φ ≡ ψ| = F otherwise or when |φ| ≠ |ψ|.
4.1.1  Definition of Connectives by the Truth Table Method
Another way that is available, and standard, for defining our connectives is the truth-
table method. We implement this approach through a formal idiom, ∑⊞, which we 
set up formally in 4.3. This is the place, however, for presenting truth tables for the 
first time since we need this device to define our connectives. The truth table is a 
popular device that is used in formal logic; it works for sentential logic only (with an 
exception for application under certain adjustments that restrict models in predicate 
logic.) We will present the truth table device in gradual constructive steps. We should 
bear in mind that we will move to the subject of computations with truth values in 
4.2. We will then find out that the truth table for one or more well-­formed formulas 
of our formal language also requires computations across each one of its rows.
A truth table has rows and columns. We have a precise way for determining the 
number of rows of our truth table, depending on the number of types of atomic 
variables (atomic letters, atoms) in the well-formed formulas for which the truth 
table is constructed. Notice that we are speaking of types, not occurrences, of atomic 
variables. We should speak, more precisely, of occurrences of tokens of the types. 
We start by illustrating this important conceptual distinction.
We may first use linguistic examples. In linguistic grammar, this is interesting 
only for purposes of correct spelling – but also for theoretical grammatical analyses. 
In the formal grammar we have for a language like our ∑, there are specific rea-
sons – like the one given presently – as to why this matters.
•	 “Essential:” two occurrences of the type ‘e’ and two occurrences of the type ‘s’; 
one occurrence of the types ‘n,’ ‘t,’ ‘i,’ ‘a,’ and ‘l.’ Thus, there are 9 letters but 6 
types of letters with two of them occurring twice and the rest occurring once.
•	 “Quality:” one occurrence of each of the types. There are 7 letters and 7 types of 
letters in the word.
4.1  Definitions of the Connectives by an Equational Method

120
•	 “Aardvark:” three occurrences of ‘a,’ two occurrences of ‘r,’ and one occurrence 
of each of ‘d,’ ‘v,’ and ‘k.’ Thus, the number of letters in the word is 8 but the 
number of types is 5.
Now we turn to our formal language ∑.
•	 ~ p ⊃ ~ ~ p	
There are two occurrences of ⌜p⌝ but only one type with two 
occurrences. There are altogether 6 symbols: four are connective symbols with 
three occurrences of ⌜~⌝ and one occurrence of ⌜⊃⌝. (We apply our conceptual 
distinction between types and occurrences of tokens also for the other symbols 
in our formal grammar.) When it comes to atomic variables (atomic letters), we 
have two atomic letters but only one type of atomic letters.
•	 ~ (p ∨ ~ q)  There are two types of atomic letter, with one occurrence for each. 
The total number of atomic letters is 2; the total number of types of atomic letters 
is also 2.
•	 ~ ~ ~ p  There is one occurrence of one type of atomic letter. We have one 
atomic letter in the formula; also, one type of atomic letter.
•	 (p ∨ ~ (p ≡ t)) ≡ ~ (t ∙ (~ q ∨ (r ≡ ~ t))): In this well-formed formula (wff), we 
have 7 atomic letters; we have 4 types (⌜p⌝, ⌜q⌝, ⌜r⌝, ⌜t⌝); we have two occur-
rences of tokens of ⌜p⌝ and three occurrences of tokens of ⌜t⌝.
Now that the distinction is clear, let us lay down precisely the recipe for how to 
calculate the number of rows in a truth table we construct. Our truth table may be 
for one or for more well-formed formulas. We take stock of all the well-formed 
formulas we are given, for which we are about to construct a truth table. We count 
the types of atomic letters we have. If the number of types for all the formulas is n, 
then the number of rows of our truth table has to be 2n. This is the general case, 
which we can now apply through specific examples.
•	 ~ (p ⊃ ~ (q ⊃ (~ r ⊃ s))): we have 4 atomic letters and 4 letter-types (one occur-
rence of a token of each); the truth table for this wff (well-formed formula) must 
have 24 = 2 x 2 x 2 x 2 = 16 rows.
•	 {(p ∨ (q ∙ r)), (p ∨ q) ∙ (p ∨ r)}: for the two formulas in the set we have 7 atomic 
letters but 3 types: the truth table for this wff must have 23 = 8 rows.
•	 {p ⊃ (q ⊃ ~ p), ~ p ∨ ~ q, p ≡ (q ∨ ~ (p ⊃ ~ ~ p))}: for all the given formulas, we 
have exactly two types of letters, ⌜p⌝ and ⌜q⌝. The complete truth table for these 
formulas must have 22 = 4 rows.
The number of columns is easy to determine. Each atomic letter type has a dedi-
cated column; each formula also has a dedicated column. We start from the left with 
the atomic letter columns. When we will be constructing truth tables to examine 
argument forms, all the premises and the one conclusion formula are counted as 
separate.
The top of the table – not counted itself as a row even though it runs parallel to 
the rows – has the atomic letter types and the given formula or formulas. If we have 
one formula, for instance ⌜p ⊃ (q ≡ p)⌝, we begin from the top as follows. In the 
truth table below, we show clearly the rows and the columns but in future cases the 
drawing may not be as clear because we trust that, once we have become used to 
4  Sentential Logic Languages ∑

121
working with truth tables, we can always figure out the detours of the rows and 
columns. We have added here an extra row at the bottom, as a metalinguistic gadget, 
for the purpose of explicitly pointing and identifying each row. This last, extra row 
is not, officially speaking, a row of the truth table itself. The top row is also to be 
thought of as not a proper row. This top row has the symbols of the atomic variables 
or letters and the formula for which the truth table is constructed. We see that each 
column is labeled by some symbol. For instance, column 1 is labeled by ⌜p⌝ while 
column 6 is labeled by the connective symbol ⌜≡⌝. We indicate that we are not 
showing all columns – that there are missing columns – by “⋮”. The particular truth 
table we construct is considered as an instance of the characteristic truth table for 
the given formula which is ⌜p ⊃ (q ≡ p)⌝. Because we have n = 2 for the number of 
the types of atomic variables in the formula, we can calculate that the number of all 
mathematically possible combinations of truth value assignments to the atomic 
variables is 4. This is 22. We are able to generalize this observation. If n is the num-
ber of atomic variable types, then the number of possible assignments of truth val-
ues, which is the same as the number of rows of the formula’s truth table, is 2n.
Rows p
q
(p
⊃
(q
≡
p))
1
⋮
⋮
⋮
n
Atomic 
letter
Atomic 
letter
Main Connective 
Symbol of the given wff
1st 
column
2nd 
column
3rd 
column
4th
column
5th 
column
6th 
column
7th 
column
We have 22 = 4 rows in the completed truth table we are designing. This is 
because we have two letter types. Each letter type has a column underneath it. The 
common practice is to assign one column for each formula but we have subdivided 
this formula in a certain way. The reason for this will become evident in 4.5 where 
we learn how to use the truth table method for certain purposes. In our amended 
construction of columns: each atomic letter (not letter type but occurrence) takes a 
column; every connective symbol takes a dedicated column; parentheses are not 
given columns.
The rows for the atomic letters will have to be filled in so that all the logically 
possible combinations, and only those combinations, of the truth values are given to 
the atomic letters. We have a recipe for this. We start from the last atomic letter to 
the right and underneath it we write <T, F, T, F> vertically so that these truth values 
correspond to the rows <1, 2, 3, 4>. For the next atomic letter to the left, we match 
the rows <1, 2, 3, 4> with <T, T, F, F>. We are done in this case because we have 
exactly two types of atomic letters. If we had to continue, we would move to the 
next atomic letter to the left and iterate, vertically, 4 Ts and 4 Fs. If we had more 
letters, we would move to a vertical iteration of 8 Ts’ and 8 Fs; and so on, every time 
doubling the Ts’ and Fs’ iterations. We show examples of completed columns for 
the types of atomic letters. We will see in 4.5 how we fill in the other parts of the 
truth table.
4.1  Definitions of the Connectives by an Equational Method

122
Two Atoms.
p
q
1
T
T
2
T
F
3
F
T
4
F
F
Three Atoms.
p
q
r
1
T
T
T
2
T
T
F
3
T
F
T
4
T
F
F
5
F
T
T
6
F
T
F
7
F
F
T
8
F
F
F
Once again, we see that the number of all possible assignments of truth values to 
the variables is 2n, where n = 3 in this case; therefore, the number of rows too is 23 
= 8. The truth table shows all mathematically available combinations of assign-
ments of truth values to the atomic variables or letters. There are no more possible 
assignments of truth values to the atomic variables besides the ones shown on the 
properly constructed truth table.
Now we are ready to use the truth table construction device for defining our con-
nective symbols. We will continue with a discussion of this definition, in which we 
make references to the truth table itself in order to analyze the definition we have 
provided. We start with the tilde.
p
~ p
1
T
F T
2
F
T F
Since the tilde is a monadic connective symbol, we need a one-atom truth table. 
We have two rows as determined by the formula 21 = 2. We write the vertical itera-
tion as <T, F> for the rows <1, 2>. We impose additional graphic design on our truth 
table; we can do this for the sake of facilitating the presentation and absorption of 
lessons. Notice that we have boxed and highlighted the definition of the tilde. These 
truth values are given to the tilde – and, hence, to the whole symbolic expression ⌜~ 
p⌝ since the tilde is the main connective symbol of this expression. We need to make 
certain remarks.
The truth table is like a map of all mathematically possible assignments of truth 
values that can be given to the atomic components of the formula. In this case, there 
4  Sentential Logic Languages ∑

123
is only atomic letter – only one component. The only two logically possible cases 
are that this atomic component is true or it is false. Row 1 and Row 2 represent these 
two distinct possibilities. There can be no row mixing 1 and 2. Rows 1 and 2 are like 
two separate cases or states. The atomic component has to be in one or the other 
state; it cannot possibly be in both states and it cannot possibly fail to be in any one 
of the states. We can even use the truth value of each state to label or mark or 
describe the state: thus, state 1 (row 1) is characterized by the value true for our 
atomic letter (recalling the symbol we use for value, |p| = T); state 2 is characterized 
by |p|= F.  We notice that meaning  – which characterizes the logically possible 
states – is a matter of truth value (true and false) and nothing else. This is an impor-
tant lesson to always keep in mind. In state (row) 1, the value of ⌜~ p⌝ is false 
because ⌜p⌝ is true. We know this by definition of the tilde symbol. In state 2 (row 
2), the value of ⌜~ p⌝ is true because ⌜p⌝ is false. Nothing has been left out. There 
is no other logically possible state. These are all the logically possible cases or 
states. Notice how the definition we have just given, using the truth table method, 
harmonizes with our earlier definition.
•	 Row 1: |p| = T ⇒ |~ p| = F.
•	 Row 2: |p| = F ⇒ |~ p| = T.
Except for the tilde, all the other connective symbols we have in our formal lan-
guage ∑ are for binary connectives. Accordingly, we will need a two-atoms truth 
table to define each of them. We compact all these truth tables – as if we were given 
a number of well-formed formulas for which we constructed one truth table.
p
q
(p
∙
q),
(p
∨
q),
(p
⊃
q),
(p
≡
q)
1
T
T
T
T
T
T
T
T
T
T
T
T
T
T
2
T
F
T
F
F
T
T
F
T
F
F
T
F
F
3
F
T
F
F
T
F
T
T
F
T
T
F
F
T
4
F
F
F
F
F
F
F
F
F
T
F
F
T
F
We have exactly four rows. Make sure that you understand this part by now. Each 
row represents one of the logically possible states or cases. There are no other logi-
cally possible cases. Each case is determined by an assignment of truth values 
(true – false) to the atomic components or atomic letters: we have two types of let-
ters in the case of binary connective and, therefore, we have four rows in the truth 
table: this means that there are exactly four logically possible cases or assignments 
of truth values to the atomic letters. For each case, the truth table fixes the definition 
of the connective symbol; in this way, the connective symbol is defined altogether: 
the definition of the connective is given as a matter of truth conditions: what truth 
value the connective symbol takes when the truth values of its atomic letters is 
specified. Once again, let us see how the definitions provided by the truth table 
above harmonize with the definitions given by our earlier method.
•	 Row 1: |p| = T and |q| = T ⇒ | p ∙ q| = T.
•	 Row 2: |p| = T and |q| = F ⇒ | p ∙ q| = F.
•	 Row 3: |p| = F and |q| = T ⇒ | p ∙ q| = F.
4.1  Definitions of the Connectives by an Equational Method

124
•	 Row 4: |p| = F and |q| = F ⇒ | p ∙ q| = F.
•	 Row 1: |p| = T and |q| = T ⇒ | p ∨ q| = T.
•	 Row 2: |p| = T and |q| = F ⇒ | p ∨ q| = T.
•	 Row 3: |p| = F and |q| = T ⇒ | p ∨ q| = T.
•	 Row 4: |p| = F and |q| = F ⇒ | p ∨ q| = F.
•	 Row 1: |p| = T and |q| = T ⇒ | p ⊃ q| = T.
•	 Row 2: |p| = T and |q| = F ⇒ | p ⊃ q| = F.
•	 Row 3: |p| = F and |q| = T ⇒ | p ⊃ q| = T.
•	 Row 4: |p| = F and |q| = F ⇒ | p ⊃ q| = T.
•	 Row 1: |p| = T and |q| = T ⇒ | p ≡ q| = T.
•	 Row 2: |p| = T and |q| = F ⇒ | p ≡ q| = F.
•	 Row 3: |p| = F and |q| = T ⇒ | p ≡ q| = F.
•	 Row 4: |p| = F and |q| = F ⇒ | p ≡ q| = T.
There are more unary and binary connectives that are definable in sentential 
logic; we only have symbols for a few of them. We can determine mathematically 
that there are 4 definable unary and 16 definable binary connectives in the standard, 
two-valued sentential logic.
4.1.2  Semantic Analysis
Logic studies the characteristic logical relation known as logical consequence. A 
conclusion-set of sentential formulas {ψ1, …, ψk} follows by logical consequence 
from a given premise-set of sentential formulas {φ1, …, φn} if and only if (iff) it is 
logically impossible to provide any interpretation (assignment of truth values, T and 
F, to the atomic or individual variable letters in all the formulas) such that all the 
premise-set formulas are true and the each of the conclusion-set formulas is false. 
All the formulas in the premise set are regarded as being taken jointly and the con-
clusion-set formulas are considered to be joined by inclusive disjunction. In com-
mon practice the conclusion-set is restricted to what is known in set theory as a 
singleton: a one-member set. In other words, the convention is to study arguments 
with only one conclusion but the theoretical conceptualization is broader.
Since we are speaking of true and false, truth values, and their assignments, we 
are signaling that we are undertaking a semantic approach to the logic. “Semantic” 
usually means “related to or about meaning” and we note that logical meaning is 
taken as a matter of true and false. The semantic approach to the study of logic 
requires that a referent be specified for attribution of meaning (what we are talking 
about in the sense of the thing that be substituted for x if x the thing we are talking 
about): we say, then, that the meanings of sentences (commonly called “proposi-
tions” or “statements”, but sometimes also, rather ambiguously, “sentences”) refer 
to (have as referents or denotata) truth values. What kinds of objects True and False 
are does not trouble us; austere metaphysical impositions can be altogether disre-
garded and our project does not lose coherence or efficacy of presentation.
4  Sentential Logic Languages ∑

125
The metalinguistic symbol, called turnstile, and written as “⊢” symbolizes logi-
cal consequence. Intuitively, the formulas to the left are the premises and the for-
mula to the right is the conclusion of an argument that is valid if and only if the 
relation of logical consequence obtains as noted. The symbol of converse turnstile 
is also available: “⊣” is used to indicate that logical consequence obtains from right 
to left. We realize that if logical consequence obtains in both directions, then the 
formulas in the two sides are related by the relation of logical equivalence: this is 
the characteristic relation of identity of logical meaning.
φ ⊣⊢ ψ.
In this case φ and ψ are logically equivalent, which means:
	1.	 φ and ψ imply each other
	2.	 φ and ψ are the logical consequence of each other
	3.	 φ and ψ have the same truth values for all interpretations (value assignments of 
T and F, true and false, to their atomic variable letters)
	4.	 It is logically impossible for φ to be true/false while ψ is false/true
	5.	 the formula constructed by joining φ and ψ with the logical equivalence symbol 
is a tautology, which can be conceptualized as a zero-premises conclusion (a 
conclusion that can be derived from the empty set of premises, or from any 
premise-set whatsoever)
	6.	 the converse is also the case: if the sentence formula that joins φ and ψ with the 
equivalence symbol is a tautology, then φ and ψ are logically equivalent:
φ ⊣⊢ ψ iff ⊢ φ ≡ ψ.
Also, based on the observations we have made:
φ ⊣⊢ ψ iff ⊢ (φ ⊃ ψ) ∙ (ψ ⊃ φ).
φ ⊣⊢ ψ iff ⊢ (φ ∙ ψ) ∨ (~ φ ∙ ~ ψ)
	7.	 φ and ψ can be inter-substituted for each other (not necessarily for all occur-
rences) in some formula χ without changing the truth value of χ
If φ ⊣⊢ ψ, then ⊢ χ(… φ …) iff ⊢(… ψ…).
If χ is a logical truth or tautology (a zero-premises conclusion), then it remains 
a tautology if occurrences of φ are replaced by occurrences (tokens) of ψ, not 
necessarily systematically throughout, and vice versa (if occurrences of ψ are 
replaced by occurrences (tokens) of φ).
For the case of one-direction logical consequence, from φ to ψ, the correspond-
ing logical truth or tautology (the zero-premise formula) is the implication formula 
with φ as antecedent and ψ as consequent. We can write this, which is known as the 
Deduction Theorem, as follows:
•	 φ ⊢ ψ iff ⊢ φ ⊃ ψ
Returning to our initial presentation of logical consequence, with multiple prem-
ises and possibly (and although not usually) multiple conclusions, we have:
•	 φ1, … φn ⊢ ψ1, … ψk iff ⊢ (φ1 ∙ … ∙ φn) ⊃ (ψ1 ∨ … ∨ ψk)iff ⊢ ~ ((φ1 ∙ … ∙ φn) ∙ 
~ (ψ1 ∨ … ∨ ψk)) iff ⊢ ~ ((φ1 ∙ … ∙ φn) ∙ ~ ψ1 ∙ … ∙ ~ ψk).
4.1  Definitions of the Connectives by an Equational Method

126
We can study logical consequence by using a metalanguage which is any needed 
fragment of a language like English and fortified with tokens of the symbols we 
have in our formal language. This allows us to present a semantic analysis of pre-
sented claims about logical consequence – and about other logical notions which 
can even be systematically connected to logical consequence. Our effective results 
should be matching exactly the results we reach by using such methods as the truth 
table, which we will study in subsequent chapter. And, conversely, results obtained 
by the truth table method about validity of argument forms should be exactly match-
ing the results we obtain through our sustained semantic analysis. We draw on the 
meanings the logical connectives, which we have defined semantically, and on other 
notions we have available to us in order to proceed with our analysis. Let us scan a 
compendious enumeration of cardinal semantic notions we have in our compass:
•	 There are two truth values, T and F, and no sentence (precisely, meaning of sen-
tence) can be both T and F or neither T or F;
•	 The connectives of the logical language are defined over the truth value set {T, F};
•	 Logical consequence is, as it has been defined: for the single-conclusion case, 
which is the standard one, a conclusion ψ is validly implied by the premise-set { 
φ1, …, φn} if and only if it is logically impossible (there is no interpretation, no 
value assignment of T/F combinations to the atomic variables of all the formulas, 
no semantic case, no logically possible state of affairs) in which all the premises 
are T and the conclusion is F;
•	 The logic of our metalanguage, in which we carry out our semantic analysis, is 
presumed standard: bivalent (exactly two truth values, with the stipulations about 
assignment of those truth values as presented above), and with logical truths as 
standardly accepted;
•	 We may define consistency or (pedantically and rather more accurately, since 
this is semantic analysis) joint satisfiability of formulas (or of a set of formulas) 
in the standard way: the formulas that are members of the set {φ1, … φn} are 
logically consistent or jointly satisfiable if and only if there is at least one 
­truth-­value assignment to the atomic variable letters (interpretation, case, logi-
cally possible state of affairs), for which all the formulas in the set are true;
•	 We define as usual the notions of logical truth (tautology, sometimes called 
validity), logical falsehood (contradiction), and logical contingency (logically 
indeterminate or logically indefinite formula): a logical truth is a sentence for-
mula that is true for every logically possible value assignment; a logical false-
hood is a sentence formula that is false for every logically possible value 
assignment; and a contingency is a sentence formula that is true for at least one 
logically possible assignment of values and is false for at least one logically pos-
sible assignment of values;
•	 The Deduction Theorem, as presented above, is valid in the standard sentential 
logic: We will be able to prove this in our metalanguage by means of semantic 
analysis; generally, we make no claim that the principles enumerated in the pres-
ent list are independent – in the sense of not being provable from other principles 
in the list;
4  Sentential Logic Languages ∑

127
•	 A set or premises { φ1, …, φn} validly implies (has as logical consequence) ψ if 
and only if the set formed by (the union of)the set of all the members of the 
premise set and the member of {~ ψ} is inconsistent: indeed, it is a core compo-
nent of the notion of implication in general that it is impossible to have all prem-
ises true and a false conclusion; hence, the premises, taken as true, and the 
negation of the conclusion cannot be all true together under any value assign-
ment, which means that they are, taken together, inconsistent; this is also prov-
able, and, indeed, as an example of how semantic analysis proceeds, we have just 
provided the proof;
•	 Another provable thesis or principle is that tautologies or logical truths (and, 
hence, also negations of logical falsehoods or contradictions) are provable from 
no premises or from the empty set of premises: indeed, since there is no logically 
possible case in which a logical truth can be false, it follows that there can be no 
value assignment for which the premises of any set are true and the tautological 
conclusion is false: hence, a logical truth is provable from any set and, by exten-
sion, by the empty set of premises; alternatively, we may regard this case as a 
degenerate case, as we may say, of the notion of logical consequence.
As an example of how to apply semantic analysis, we will prove the Deduction 
Theorem. This is a characteristic principle, sometimes referred to as the Deduction 
Axiom although we will be treating it here as a provable theorem: it is characteristic 
in the sense that there are alternative logics for which this principle is not valid. To 
grasp the implications of this: let us assume that a logic lacks tautologies: this can 
be the case if there are more than two truth values in the logic, with a third value that 
expresses an additional way of being false, so that there are two ways of being false: 
in such a logical system, depending also on the way the connectives are defined, a 
value assignment is always possible that bestows this third value on all the atomic 
variables of any formula, so that the formula assumes a value that is a species of 
false. Since this is possible for every formula, there is no formula that can be a logi-
cal truth. To provide a motivation for envisioning implementation of such an unorth-
odox logic, let us consider for instance decision to split the false values between the 
standard false (which is then reinterpreted as “definitely false”) and an additional 
so-called anti-­designated value that is interpreted semantically as “logically absurd” 
which can be thought of as a species of false in the sense that assignment of this 
value to a sentence cannot designate the sentence as true or necessarily true. Now, 
let us have the connectives defined so that any sentence that has at least one absurd 
component is valuated as absurd: this makes sense as a motivation since logical 
absurdity arguably has this contaminating quality: we cannot understand what is 
being talked about if absurdity is involved even in minimal fashion. In such a logic, 
we run into the characteristic predicament we outlined above: no sentence is a logi-
cal truth (necessary truth, tautology) because we can always assign the value inde-
terminate to at least one component; then the whole sentence is valuated as absurd. 
Therefore, we cannot possibly have any sentential formula in this logic, which 
receives the value true for all logically possible value assignments: we cannot pos-
sibly have logical truths. Accordingly, implicational formulas of the form φ ⊃ ψ 
4.1  Definitions of the Connectives by an Equational Method

128
cannot be tautologies either. Nevertheless, since this is a logic, after all, it must have 
a definable and characterizing logical consequence relation! This means that we 
have cases in which φ ⊢ ψ obtains and yet ⊢ φ ⊃ ψ does not obtain. It is clear, then, 
that the Deduction Theorem fails in this case as a principle and we would be wrong 
to try to formalize this logic by positing a Deduction Axiom.
Although alternative logics, whose semantic implementations are controversial, 
lie beyond our scope, our brief excursion above disillusions us about any notions 
that the Deduction Theorem necessarily obtains in any conceivable logical system. 
Of course, this is so if one allows for a pluralistic view of logic. If one were to fol-
low in the footsteps of Aristotle, and many other including many modern logicians, 
one might disavow such profligate proliferation of logics and insist that there is one 
correct logic. One could even attempt to make the case that failure of the Deduction 
Theorem is itself a criterion for disqualifying a formalism as logic. Note that a for-
mulation of such a logical system cannot be itself subjected to criticism; it is always 
legitimate as a mathematical structure and it can be studied extensively in the area 
of Metalogic; what is controversial is whether a plausible or acceptable semantic 
construction that matches such a formal system ought to be admitted.
	1.	 To prove the Deduction Theorem, we need to proceed from each side of the iff 
(if and only if) to the other (from right to left and from left to right, in any order), 
since this is a claim about logical equivalence and, as we know, logical equiva-
lence is logical implication that proceeds in both directions. Specifically, we 
want to prove:
φ ⊢ ψ iff ⊢ φ ⊃ ψ.
Accordingly, our proof must have two parts, or subproofs:
If φ ⊢ ψ, then ⊢ φ ⊃ ψ; and.
if ⊢ φ ⊃ ψ, then φ ⊢ ψ.
	2.	 We use, in this informal format of semantical-analytical proof construction, the 
method, which we will also study formally in our natural deduction systems 
later, known as Proof by Contradiction (and also identified historically by the 
Latin name Reductio ad Absurdum, which we may abbreviate as “RAA.”) This 
is a powerful proof method, abundantly present in mathematical proofs – to the 
extent that more than half or the mathematics we have would need to be given up 
if, for some reason or other, this method were rejected (which is the case for a 
school of thought known as Mathematical Intuitionism.) In application of the 
RAA method, we stipulate as a provisional assumption the negation of the pur-
ported conclusion we are supposed to derive; then we seek to prove validly that 
a contradiction (logical absurdity) follows; if we prove a contradiction from the 
premises and from the provisionally added assumed or posited premise which is 
the negated conclusion, then we can lay down the conclusion we were supposed 
to prove; at this point, upon obtaining success, the provisional assumption (the 
negated conclusion we posited) is, as we say, discharged: it is an assumed burden 
to be using an assumption that has not been authorized as self-validating: our 
proof cannot terminate without getting rid of this burden, and the proof of the 
absurdity shows, we claim, that this assumption cannot be accepted: hence, it is 
4  Sentential Logic Languages ∑

129
rejected. In terms of implication, we can put this more perspicuously indeed: we 
may posit an assumed premise χ in a proof but we cannot complete the proof by 
right without somehow discharging this assumption that was not given but only 
provisionally added. If we can prove ψ validly, then we have: given that χ, it 
must be that ψ. This means that χ ⊃ ψ is a logical or necessary truth (notice the 
Deduction Theorem at work, but we have said that our metalogical language is 
already equipped with the standard logic.) Now χ has been discharged because 
our claim is not that we have χ but only that, given χ then ψ, or that it is neces-
sarily the case that if χ then ψ. To return to the Reductio: given provisionally, 
assuming or positing, χ, then if we prove logical absurdity (which is standardly 
symbolized by “⊥” or upside-down “⊤” which symbolizes usually the constant 
“true”), it follows that it is necessarily the case that: if χ then ⊥. Now, it is quite 
plausible and arguably intuitive to define “not-χ” as “if χ, then absurdity.” In this 
way we have: positing χ and validly proving ⊥, we may infer correctly that χ ⊃ 
⊥ which is equivalent with ~ χ. Interestingly, if our initial posit is a negated sen-
tential formula, let’s say ~ χ, then this proof sequence will yield, if successful, ~ 
~ χ; but this is logically equivalent with χ (in the standard logic.)
•	 First Subproof:
	1.	 Assume that
φ ⊢ ψ.
We will prove that.
⊢ φ ⊃ ψ
	2.	 We posit as an assumption (for reductio, as we can say), that it is not the case 
that ⊢ φ ⊃ ψ
	3.	 From 2: since it is not the case that the implicational sentential formula with φ 
as antecedent and ψ as consequent is a tautology or necessary truth, then there 
must be at least one interpretation (valuation, value assignment) for which φ is 
true and ψ is false; we know this from the definition of the implication connec-
tive and surveying the truth table (which is a correct procedure for defining the 
connectives of our logic) shows that the only interpretation or case in which this 
implicational formula is false is when φ is assigned the value true and ψ is 
assigned the value false.
	4.	 Since there is an interpretation for which φ is true and ψ is false (as we have 
from 3), it follows that the logical consequence from φ to ψ does not obtain; this 
is because the definition of logical consequence constrains us to accept that, if 
logical consequence from φ to ψ obtains, then there is no logically possible 
interpretation or valuation for which φ is true and ψ is false. Hence,it is not the 
case that φ ⊢ ψ.
	5.	 But from 1 we have that
φ ⊢ ψ
	6.	 Hence, from 4 and 5, we have logical absurdity.
	7.	 We have, therefore, by reductio proven that
⊢ φ ⊃ ψ.
•	 The second subproof proceeds in parallel fashion.
4.1  Definitions of the Connectives by an Equational Method

130
	1.	 Assume that
⊢ φ ⊃ ψ.
We will prove that.
φ ⊢ ψ
	2.	 We posit as an assumption (for reductio, as we can say), that it is not the case that
φ ⊢ ψ
	3.	 From 2: since it is not the case that logical consequence from φ to ψ obtains, 
there must exist at least one interpretation or valuation for which φ is true and ψ 
is false.
	4.	 Since there is an interpretation for which φ is true and ψ is false (as we have 
from 3), it follows that the implicative formula with φ as antecedent and ψ as 
consequence is not a tautology; this is because the definition of the connective of 
logical implication constrains us to accept as tautologous only implications for 
which there is no interpretation that assigns true to φ and false to ψ. Hence,it is 
not the case that ⊢ φ ⊃ ψ
	5.	 But from 1 we have that
⊢ φ ⊃ ψ
	6.	 Hence, from 4 and 5, we have logical absurdity.
	7.	 We have, therefore, by reductio proven that
φ ⊢ ψ.
•	 Having proven that the implication holds in both directions, we have shown that:
•	 φ ⊢ ψ iff ⊢ φ ⊃ ψ.
4.1.3  Exercises
	1.	 The number of definable connectives for any degree or arity is mathematically 
computable. If the arity (the number of inputs for the connective) is n, then the 
number of mathematically definable n-ary connectives is: 22n . How many unary 
connective symbols are definable? How many binary and how many ternary con-
nective symbols are definable?
	2.	 Provide definitions of all the mathematically possible unary connectives. We use 
the truth table method for defining connectives. We will need to make symbols 
available since we only have provided symbols for one unary and four binary 
connectives. After you have defined the definable connectives by means of the 
truth table method, do so also by means of the algebraic method we have 
provided.
For the unary connectives: the only connective symbol we have is the nega-
tion symbol: by definition, negation reverses the truth value of the input (from 
true to false and from false to true.) Fill in the rows of the truth table below to 
define the other unary connective symbols bearing in mind that the id connective 
yields the same output as the input in each case, the ⊤ connective yields the fixed 
4  Sentential Logic Languages ∑

131
output true for every input and the connective ⊥ returns the fixed output value 
false for every input.
p
~ p
idp
⊤p
⊥p
1
T
F
2
F
T
	3.	 Define all the mathematically definable binary connectives of the two-valued 
sentential logic. To expedite this task, let us revisit the case of unary connectives, 
which we treated in the preceding exercise, and approach the objective in a dif-
ferent way. There are exactly two truth values, {T, F}, over which the truth func-
tions are defined. For unary truth functions, there are exactly two possible 
outputs for inputs that are received from {T, F}. We look into all the possible 
combinations we have available in terms of accepting, “A,” and rejecting, “R,” 
the input value; the possible combinations are: AA, RR, AR, RA. Thus, we have 
the following table of all the logically possible combinations:
truth values for the atomic variable input
Accept 
Accept
Reject 
Reject
Accept 
Reject
Reject 
Accept
T
T
F
T
F
F
F
T
T
F
id p
~ p
⊤1 p
⊥1 p
Now continue for the case of the definable binary connectives. There are sixteen of 
them. Use the symbols from {∙, ∨, ⊃, ≡, ≢, 1, 2, ~1, ~2, ⊂, ⊅, ⊄, ⊤, ⊥, ↓, |}, 
­taking into considerations that the familiar symbols in this set have been already 
assigned to the connectives in our constructed formal logic and based on the fol-
lowing considerations.
	a.	 ≢: this symbol connotes disequivalence (also called exclusive disjunction):
	b.	 ⊂: this symbol connotes converse implication:
	c.	 ⊅: this symbol connotes negated implication:
	d.	 ⊄: this symbol connotes negated converse implication:
	e.	 |: this symbol connotes the Sheffer connective (also called NAND and alternate 
negation) and is called the Sheffer Stroke:
	f.	 ↓: this symbol is called the Peirce Arrow or the Quine Arrow or Quine Dagger 
and connotes the connective usually called Peirce connective, NOR or joint 
negation:
	g.	 1: the connective connoted by this symbol returns the same truth value as the 
truth value of the first input (which is p in our table.) We don’t find names for this 
often. It is a pseudo-binary function: can you tell why if you are given the infor-
mation that a pseudo-n-ary connective is one whose truth table definition has 
exactly the same outputs for any input with a connective of lower arity?
4.1  Definitions of the Connectives by an Equational Method

132
	h.	 2: this connective symbol connotes the connective that returns the negation of 
the second input (which is q for the format we have been using).
	i.	 ~1: this connective symbol connotes the connective that returns as output the 
negation of the first input.
	j.	 ~2: this connective symbol returns as output the negation of the second input.
	k.	 ⊤: this connective symbol connotes the connective that yields fixedly the truth 
value true for all input combinations.
	l.	 ⊥: this connective symbol connotes the connectives that yields the fixed value of 
false for all possible combinations of input values.
	4.	 Continuing from the preceding exercise, try to name all the symbols. Respect the 
names we have already provided for the symbols we have defined formally in 
our symbolic language. Why is it important to have names for the symbols? How 
are the symbols different from the connectives themselves?
	a.	 Next, for each of the defined connectives, construct sentences of English which 
are compounded by having two simple sentences joined by means of the connec-
tive. Take as your first sentence “it is raining” and as your second sentence “the 
game is cancelled.” For instance, for implication: “if it is raining, then the game 
is cancelled.”
	b.	 How would you characterize the compounds with the fixed-value connectives as 
their main connective?
	c.	 Next, discuss if we can defend the choices we have made from the 16 available 
connectives for presumably capturing the logical behavior of inclusive “either 
or,” and “and.”
	d.	 What about implication – the connective we presume to be matching the logical 
behavior of “if-then” in language? Did we have other choices? Why should we 
reject those other choices? Are there any problems you detect with the claim that 
our implication connective indeed captures the logical behavior of the “if-then” 
of language?
	e.	 Which connective matches the linguistic exclusive “either or” (meaning that one 
but exactly one of two options must be chosen)?
	5.	 Our officially constructed formal language has connective symbols from the set 
{~, ∙, ∨, ⊃, ≡}. It is good news that this set of connectives is what we call func-
tionally complete: we can define any mathematically definable connective (not 
only unary and binary but of any arity) by using appropriate combinations of 
iterations of the connective symbols we have. We can also examine this by means 
of the truth table definitions of connectives. For instance, the triple bar can be 
defined by using formulas that have only symbols from {∙, ⊃}. We show this 
below. We have not yet studied how to use truth tables for computing truth val-
ues; as an exercise in figuring out how this is done, mark how the connectives 
have been defined and follow the computations starting from lesser-scope con-
nectives and ending up with the value of the major-scope connective which is 
also the value of the whole compound expression. Then notice if we have the 
same values for every row for two formulas: that means that they are logically 
4  Sentential Logic Languages ∑

133
equivalent; they have the same logical meaning and they are indeed, for this 
reason, interdefinable. All this should allow you to observe how the formula with 
the triple bar – which has been our truth table definition of this connective sym-
bol – is indeed interchangeable with the formula that uses only the conjunction 
and implication symbols. This shows interdefinability.
p
q
(p ⊃ q) ∙ (q ⊃ p)
p ≡ q
1
T
T
T   T   T
T
2
T
F
F   F   T
F
3
F
T
T   F   F
F
4
F
F
T   T   T
T
You might now realize that we actually have more connective symbols than we 
need to have in order to be able to define all the mathematically definable connec-
tives of two-valued sentential language of any arity. After all, we just established 
that we do not need the triple bar symbol, although our formulas would become 
more cumbersome and perhaps less intuitive to write out. This means that we could 
have fewer connectives (but not any which ones we choose) and still be able to 
define all the mathematically definable connectives of the two-valued sentential 
language.
	a.	 Use the truth table to show that the following sets are themselves functionally 
complete: {~, ∨}, {~, ∙}, {~, ⊃}. Take into account the following equivalences:
(p ∨ q) ≡ ~ (~ p ∙ ~ q)
(p ∙ q) ≡ ~ (~ p ∨ ~ q)
(p ⊃ q) ≡ (~ p ∨ q) ≡ ~ (p ∙ ~ q)
	b.	 For any given set ℾ, if we can use only its symbols to define all the connective 
symbols in {~, ∙, ∨}, we can declare that ℾ is functionally complete. This is 
because the set {~, ∙, ∨} is itself functionally complete. As a clue: consider how 
we use the truth table to define connectives: consider that, across each row, the 
atomic variables can take truth values true or false (and, thus, we can have, for 
instance, ⌜~ p⌝ and ⌜q⌝ if ⌜p⌝ is true and ⌜q⌝ is false on the row.) Next consider 
that the connective can also be defined as the disjunction of the conjunctions of 
the atomic variables of all rows in which the connective is defined as true. (For 
instance: ⌜p ⊃ q⌝ can be defined as the disjunction of the conjunctions: ⌜p ∙ q⌝, 
⌜~ p ∙ q⌝, ⌜~ p ∙ q⌝.) Prove that if any set of connectives (with one or more mem-
bers) can be used to define the connectives in {~, ∙, ∨}, then this set of connec-
tives is functionally complete.
	c.	 From the 16 definable binary connectives we examined in preceding exercise, we 
have the thrilling result that two binary connectives are just by themselves suffi-
cient for defining every definable connective of the two-valued logic. The one-­
member sets are {|} and {↓} - the Sheffer Stroke and the Peirce Arrow. Show 
how each one of these connectives can define all the members of the set {~, ∙, 
∨} – thus (per preceding section of this exercise), each of these connectives is 
functionally complete. Continue to define the other binary connectives by means 
4.1  Definitions of the Connectives by an Equational Method

134
of the Sheffer Stroke and Peirce Arrow. Do the same for the definable unary 
connectives.
	6.	 There are two different meanings of “either or” or disjunction: inclusive and 
exclusive. Two formulas are inclusive disjuncts of each other if and only if they 
cannot be false together but they can be true together. Check the definition of the 
inclusive disjunction symbol we have provided to verify that it agrees with the 
way we presented it above in this exercise. Show that this is the case. Two for-
mulas are exclusive disjuncts of each other when exactly one of them is true 
(which is equivalent to saying that one is true and only one is true, etc.…) We do 
not have a symbol for the exclusive disjunction in our formal system. Let us use 
the symbol “≢”.
	a.	 Construct the truth table for ≢.
	b.	 Construct the truth table for the negation of the equivalence symbol: ~ ≡. What 
observation can you make in comparing to the truth table for ≢? Comment 
on this.
	c.	 Prove by means of semantic analysis that the following is a logical truth of the 
two-valued logic: ⌜(p ≡ q) ∨ (q ≡ r) ∨ (p ≡ r)⌝. Comment on this fact. Does the 
fact that the logic has exactly two truth values play a role? What role does the 
number of different atomic variable letters play?
	d.	 In natural languages like English, and most languages, there is an ambiguous 
expression, “either or,” for both inclusive and exclusive disjunction. How can the 
competent user of the natural language discern between the two? Why can’t we 
allow for a similarly ambiguous symbol in our formal language? Do you have an 
opinion as to which of the two uses of “either or” is more common in English?
	e.	 The linguistic phrase “exactly one of Shack, Slack, and Stack came to the party” 
appears to require translating by means of the exclusive disjunction symbol (for 
symbols with subscripts translating the atomic sentences):
S1 ≢ S2 ≢ S3.
Are we allowed to dispense with parentheses here without incurring ambigu-
ity? To answer this, construct the truth table to determine if exclusive disjunction 
is associative, which means that:
((S1 ≢ S2) ≢ S3) ≡ (S1 ≢ (S2 ≢ S3))
If this is so, the placement of parentheses does not affect the logical meaning 
(true or false as the value of the compound expression), and we can dispense 
with parentheses without incurring ambiguity.
But, now comes a surprise. It is wrong to translate by using the exclusive 
disjunction symbol: why is that? Check the truth table again. Show why the 
translation fails to capture the meaning “exactly one of … came to the party.”
Next, construct the truth table defining a ternary (triadic, three-place) connec-
tive symbol that does the job. Let us use the symbol “!1” for this symbol and 
notice how we conveniently shift to implementing a prefix notation (placing the 
connective symbol in the front, and in this case we also place the atomic vari-
ables within parentheses.)
4  Sentential Logic Languages ∑

135
p
q
p ≢ q
T
T
?
T
F
?
F
T
?
F
F
?
p1
p2
p3
(p1 ≢ p2) ≢ p3
(p1 ≢ p2) ≢ p3
!1(p1, p2, p3)
T
T
T
?
?
?
T
T
F
?
?
?
T
F
T
?
?
?
T
F
F
?
?
?
F
T
T
?
?
?
F
T
F
?
?
?
F
F
T
?
?
?
F
F
F
?
?
?
	7.	 Our semantic connectives (defined over the set of truth values {T, F} and so 
called semantic) interpret, as we say, functions of the Boolean algebra. A func-
tion compels an operation by which a number of inputs (depending on the arity 
of the function) are entered and the given definition of the function is applied to 
yield a unique specified output. For instance, in the case of the standard arith-
metical operation of addition, +(5, 7) = 12. The function is not the operation 
itself, you should note. It is the abstract ordered n-tuple, a relation: for instance, 
|+| = {<<x, y>, z> / z = x+y}. Now that we can count on some rudimentary 
understanding of how to perform operations, let us consider the definition of a 
reverse operation. Given that x+y = z, a reverse operation of addition can be 
defined as    such that: x+y = z if and only if z    y = x. Yes, this operation 
is definable and is the familiar arithmetical subtraction. We will now consider if 
it is possible to define reverse operations for the operations that are interpreted 
by our logical connectives.
Considering the case of inclusive disjunction. The reverse operation, if defin-
able, must correspond to some definable truth function (interpreted by a logical 
connective.) Let us assume that. We require that:
(p ∨ q) ≡ r if and only if (r    q) ≡ p
	a.	 Take p and q to be both true, T. Plug in the values and continue. You are using the 
known definitions of the symbols for inclusive disjunction and equivalence to 
compute outputs. Because the metalinguistic clauses are connected by “if and 
only if (iff)”, it is understood that you have to end up with the same truth values 
on both sides of the “iff.” Let us make both sides T. They have to be both true if 
either one is. For p and q, we assign T to both. Continue with the computations: 
you seek basically to determine the value of r. Show that a logical absurdity 
results, which proves that there is no definable reverse operation for the operation 
corresponding to the inclusive disjunction symbol.
(p ∨ q) ≡ r if and only if (r    q) ≡ p.
4.1  Definitions of the Connectives by an Equational Method

136
	b.	 Do the same for the operations corresponding to the other connective symbols of 
our system, except for the equivalence symbol.
	c.	 Follow similar steps to show that reverse operations are definable for the opera-
tions which we have interpreted through the logical connectives of equivalence 
and (from previous exercise) exclusive disjunction (or disequivalence, negated 
equivalence.)
	8.	 In our metalanguage for ∑, prove the following by means of semantical analysis.
	a.	 φ ⊃ ψ, φ ⊢ ψ
	b.	 φ ⊃ ψ, ~ ψ ⊢ ~ φ
	c.	 φ ⊃ ψ, ψ ⊃ χ ⊢ φ ⊃ χ
	d.	 φ ⊢ φ ∨ ψ
	e.	 ~ φ ⊢ φ ⊃ ψ
	f.	 ψ ⊢ φ ⊃ ψ
	g.	 φ ≡ ψ ⊣⊢ ~ (φ ≡ ~ ψ)
	h.	 (φ ⊃ ψ) ⊃ φ ⊢ φ
	i.	 φ ⊃ ψ ⊣⊢ ~ φ ∨ ψ
	j.	 ~ (φ ⊃ ψ) ⊣⊢ φ ∙ ~ ψ
	9.	 If we can find truth values for the atomic variable letters, for which the premises 
of the logical consequence relation are all true and the conclusion is false, this 
suffices to show that the logical consequence instance under consideration fails. 
We have basically provided a model or interpretation (the assignments of truth 
values to the individual variable letters) for which the considered instance of 
logical consequence fails. Why is this sufficient? Next, provide interpretations to 
show that the given instances of logical consequence all fail in the standard sen-
tential logic.
	a.	 φ ∨ ψ ⊢ φ ∙ ψ
	b.	 φ ⊃ ψ, ~ φ ⊢ ~ ψ
	c.	 (φ ⊃ ψ) ⊃ ψ ⊢ ψ
	d.	 φ ⊃ ψ ⊢ ψ ⊃ φ
	e.	 ~ φ ∨ ψ ⊢ ψ ⊃ φ
	f.	 χ ⊃ (φ ⊃ ψ) ⊢ ψ ⊃ (φ ⊃ χ)
	g.	 φ ⊃ ψ ⊢ ~ (φ ⊃ ~ ψ)
	h.	 φ ≡ ψ ⊢ ~ (~ φ ∙ ~ ψ)
	i.	 ~ (φ ≡ ψ) ⊢ ~ (ψ ∙ φ)
	j.	 χ ∨ (φ ∙ ψ) ⊢ χ
4.2  Computation of Truth Values of Well-Formed 
Formulas of ∑
It is a fundamental characteristic of formal languages for the standard sentential 
logic that they are computational: we say that they are characterized by composi-
tionality, which means that if the truth values (which are the logical meanings) of 
4  Sentential Logic Languages ∑

137
the atomic components of any well-formed formula are given, then the truth value 
of that formula can be determined by computational means. This is in evidence 
already, given the way we have defined the connectives. If we think of the connec-
tives as giving directions about how to carry out computational operations, then, we 
can inspect how the computation can be carried out for specified truth values of the 
components. We need a guarantee that the computational operations always come to 
an end, or terminate: we have such a guarantee although we are not proving that 
here. It is important that we realize how those operations are to be carried out in a 
specific order: we must end with calculating the truth value of the connective sym-
bol that has the largest scope. (We covered scopes and identification of the major 
connective in 4.1.a to be prepared for this development.) The largest-scope connec-
tive symbol receives a truth value – for a specified assignment of truth values to the 
atomic letters – and this truth value is the truth value of the whole formula.
We can see how this works, familiarly, in basic arithmetic; or, as we should say 
more precisely, for the definitions of the operators of that arithmetic and having, in 
our example, as such operators the familiar addition and multiplication defined as 
usual over the natural numbers:
x = 1
y = 3
z = 5
We can compute the value of the entire expression – which is written out in 
proper formal grammar – for the assigned values of the atomic variables. We use 
vertical bars, metalinguistically in this context, to indicate value. The values of the 
atomic variables are from the natural numbers and, note, the value of the expression 
is also a natural number.
|(x + y) ⨯ (y + z)|x=1, y=3, z=5 = |(1 + 3) ⨯ (3 + 5)| = |4 ⨯ 8| = 32
First we computed the value of the addition symbols, which have smaller scopes 
than the major operator which is, in this case, the multiplication symbol. It is not 
important whether we start with the addition symbol that is leftmost, or the other 
way round. We could have specified this as part of a systematic process but it is not 
important for us to do this because the outcome would not be affected. But we must 
definitely compute smaller-scope operators first and proceed in increasing order of 
scope-size and we must always terminate the computation with determining the 
value of the major operator of the formula. In the arithmetical example, the multi-
plication sign is the symbol of the major operator (the largest-scope) operator of the 
given expression. Now we show an example for our formal language of sentential 
logic in order to begin to cultivate some familiarity with the process. We use one of 
the methods we will be presenting. Preferences may vary; this might not turn out to 
be your preferred method of computing truth values of formulas. All the methods 
that are made available are guaranteed to reach the same – correct – result for every 
case in which the same truth values are assigned to the atomic variables.
|(p ≡ ~ q) ⊃ ~ (~ p ≡ q)|p = T, q = F = |(T ≡ ~ F) ⊃ ~ (~ T ≡ F)| =?
To proceed, we must know the definitions of the connectives. We must begin 
with the smallest-scope connective symbols – the tildes in this case – and proceed 
to the computation of the truth value of the two occurrences of the triple bar (it is 
not important in what order, from left to right or from right to left); and we must end 
4.2  Computation of Truth Values of Well-Formed Formulas of ∑

138
with the computation of the truth value of the major connective symbol of the for-
mula, which is the one and only occurrence of the horseshoe. The superscript num-
bers show the order of computation, starting with 1. We can affix the numeral 1 to 
both tildes, indicating in this way that the order in which we carry out these two 
computations is immaterial as it does not affect the outcome.
|(T ≡2 ~1 F) ⊃3 ~ (~1 T ≡2 F)| = |(T ≡ T) ⊃ (F ≡ F)| = |T ⊃ T| = T.
4.2.1  Computation by a Quasi-Algebraic Method
When the truth values (true – false) of the atomic (individual or simple) letters of a 
well-formed formula of ∑ are known, then the truth value of the entire well-formed 
formula can be determined. We compute with truth values, true and false, which 
sounds odd but this is nothing to be concerned about. This is not the algebra you are 
familiar with. There is an underlying algebra – a special algebra with only two num-
bers, historically considered as members of the set {1, 0} – and the operations of 
this algebra are defined over the set of its numbers {1, 0}. This sounds like what we 
say when we assert that the connectives we have in ∑ are defined over the values 
{T, F}. The notion of computationality applies here for reasons we will examine 
briefly. To begin with, we need to overcome the initial sense of oddity attaching to 
using words like “computation.” Let us see an example of a computation with truth 
values, based on the definitions of the connectives we have provided. We are using 
the algebraic method we set up in 4.3.a but, as we will soon find out, the truth table 
can also be used for writing out computations. Moreover, as we will see, we can also 
use diagrams – somewhat like the parsing trees of 4.2 – which we can call Semantic 
Computation Trees to carry out computations. As we know, the truth value of a for-
mula is the truth value of its major connective symbol.
Given the following formula and specified truth values for its component atoms, 
determine the formula’s truth value.
•	 φ = (p ≡ ~ (q ⊃ (~ q ∙ ~ p)))
•	 |p| = T/|q| = F/
	1.	 We plug in the truth values for the atomic letters.
	2.	 φ = (T ≡ ~ (F ⊃ (~ F ∙ ~ T)))
	3.	 Now we perform the computations. We need to begin with smallest-scope 
connective symbols and move to larger-scope and ultimately to the major-
scope symbol whose truth value establishes the truth value of the formula 
itself. Let us mark the connective symbols, to distinguish occurrences from 
left to right, and, next, let us determine scopes. The scope of each symbol is 
the collection or set of the symbols it controls (not counting parentheses, 
which are simply auxiliary symbols.) Some connective symbols occur only 
once; it is superfluous to mark them with superscripts when we seek to deter-
mine occurrences. We also mark occurrences of the atomic letters.
4  Sentential Logic Languages ∑

139
	4.	 p 1 ≡ ~ 1 (q 1 ⊃ (~ 2 q 2 ∙ ~ 3 p 2))
	5.	 Scope(≡) = {p 1, ~ 1, q 1, ⊃, ~ 2, q 2, ∙, ~ 3, p 2}/
Scope(~ 1) = {q 1, ⊃, ~ 2, q 2, ~ 3, p 2}/.
Scope(⊃) = {q 1, ~ 2, q 2, ∙, ~ 3, p 2}/.
Scope(~ 2) = {q 2}/.
Scope(∙) = {~ 2, q 2, ~ 3, p 2}/.
Scope(~ 3) = {p 2}/
	6.	 Clearly, the triple bar has the largest scope. We start from smallest-scope con-
nectives and, progressively, moving to larger-scope connective symbols we 
terminate with computation of the truth value of the triple bar. The two con-
nective symbols with only one letter in their scope are the second and third 
occurrence of the tilde: it does not matter which one we compute first. We 
start with those and move to the computation for the next connective symbol 
which, in our case, is the dot: its scope has four symbols in it; next is the first 
occurrence of the tilde with six symbols in its scope; and we end with the 
triple bar which has in its scope nine symbols.
	7.	 T ≡ ~ (F ⊃ (~ F ∙ ~ T)) =
T ≡ ~ (F ⊃ (~ F ∙ F)) =
T ≡ ~ (F ⊃ (T ∙ F)) =
T ≡ ~ (F ⊃ F) =
T ≡ ~ T =
T ≡ F =
F
We have computed the truth value of the given wff (well-formed formula) for the 
specified truth values of the atomic letters. Let us show the above computation 
schedule of steps with the computation that is executed in every step being placed 
within a box.
T ≡ ~ (F ⊃ (~ F ∙ ~ T)) =
T ≡ ~ (F ⊃ (~ F ∙ F)) =
T ≡ ~ (F ⊃ (T ∙ F)) =
T ≡ ~ (F ⊃ F) =
T ≡ ~ T =
T ≡ F =
F
We can write our result synoptically as follows. Remember that we are using the 
metalinguistic symbol “||” for truth value of a formula or atomic letter.
•	 If |p| = T and |q| = F, then |(p ≡ ~ (q ⊃ (~ q ∙ ~ p)))| = F.
This is an outstanding, and characterizing, feature of the standard sentential 
logic: it is characterized by compositionality of logical meaning (which is truth 
value): if the truth values of the atomic component letters are known, then the truth 
value of the formula can always be determined with strict precision. This is the 
result of the fact that we have only functional connectives: our connectives are 
defined in such a way that the output they are set to give is always unique for any 
specified combination of inputs. Another factor that allows computationality is the 
4.2  Computation of Truth Values of Well-Formed Formulas of ∑

140
fact – which can be proven – that we can never have an infinite number of symbols 
in any well-formed formula of a language like ∑.
4.2.2  Computation by a Diagrammatic Method: Semantic 
Computation Trees
We retain the same example as in the preceding section. We will now learn how to 
carry out computations of truth values of well-formed formulas by using a diagram-
matic approach. It is to be understood that these computations – as in this and in the 
preceding section – are carried out in our metalanguage.
We saw in a preceding section, 4.2, how we can construct a parsing tree. That 
type of tree is dedicated to decomposing the syntactic or grammatical structure of a 
well-formed formula of our formal language Σ. The computational diagram we will 
be constructing now can also be thought of as a tree; we may as well call this a 
semantic tree since we are applying it to computing truth values (and, as we see time 
and again, truth values are logical meanings in the standard sentential logic we are 
studying.)
The rules for the semantic computation trees are shown schematically by the fol-
lowing shapes. The rules are named by the symbols of the connectives written next 
to the arrow (for the rules applying to the tilde) or between the arrows (for the rules 
applying to the binary connective symbols). The rules are themselves schemata – 
figures – of semantic computation trees. The case of the conditional/implication 
deserves special attention: F is computed only when the antecedent (left) is T and 
the consequent (right) is F.
~ T	
~ F	
T ∙ T	
T ∙ F	
F ∙ T	
F ∙ F
      ⇓~	
⇓~	
⇘ ∙ ⇙	
⇘ ∙ ⇙	
⇘ ∙ ⇙	
 ⇘ ∙ ⇙
      F	
T	
T	
 F	
 F	
 F
T ∨ T	
T ∨ F	
F ∨ T 	
F ∨ F
⇘ ∨ ⇙	
⇘ ∨ ⇙ 	
⇘ ∨ ⇙	
⇘ ∨ ⇙
  T	
 T	
 T	
 F
T ≡ T	
T ≡ F	
F ≡ T	
F ≡ F
⇘ ≡ ⇙	
⇘ ≡ ⇙	
⇘ ≡ ⇙	
⇘ ≡ ⇙
   T	
F	
F	
T
To make computations, at the top of our semantic computation tree we place the 
given well-formed formula. The space that is labeled by this formula we call the root 
of the semantic computation tree. Notice that, unlike the case of natural trees, the 
root is actually at the top. We continue with plugging in the values and then we carry 
out computations beginning from smaller-scope connectives and continuing until 
ultimately we end up with the truth value of the largest-scope connective symbol (the 
main connective symbol), which is the same as the truth value of the given formula. 
4  Sentential Logic Languages ∑

141
We indicate what rule we have applied by using the name of the rule next to the 
arrow (for unary connectives) and between the arrows (for binary connectives.)
4.2.3  Computation Under Incomplete Information
It may be possible to compute the truth value of a compound (or complex) formula 
of ∑ even when we have only partial or incomplete information about the truth 
values of the component atomic variables of the formula. We can have no guaran-
tees that this is feasible; but it is possible that we might be able to carry on and finish 
the computations. We might be able to proceed with the computations because there 
is one only possible truth value in every possible case, as in the following example 
(for which we use the computation method of 4.4.a.) The given values are symbol-
ized, as before, in our metalanguage, by the vertical bars on each side. Our given 
information is incomplete; there is at least one atomic variable for which we are not 
given an assigned, specified truth value.
|p| = T, |q| = F, |r| =? .
|q ⊃ r| =?
Plugging in the provided information, we have:
|F ⊃ _| =?
We are able to finish this computation, in spite of the absence of information 
about the truth value of ⌜r⌝. If we examine carefully our definition of ⌜⊃⌝, we will 
see that, in every case in which the antecedent receives the truth value F, the impli-
cational formula receives the truth value T. (We have to make sure that we remem-
ber the terms: antecedent is the formula to the left of the horseshoe and consequent 
is the formula to the right of the horseshoe. The whole formula, with the horseshoes 
as its main connective symbol, is called implicational.) Let us see the cases in which 
the antecedent receives F as truth value. We highlight those, and only those cases.
•	 T ⊃ T = T/ T ⊃ F = F/ F ⊃ T = T/ F ⊃ F = T
Since in both cases the output is T, when the antecedent is F, then, in this case, 
the truth value of the implicational formula does not depend on the truth value of the 
consequent. Even if we don’t know the consequent value, it is necessarily the case 
that the implicational formula receives T as its truth value. Taking advantage of our 
algebraic notation, we can write this as follows, in our metalanguage:
|F ⊃ φ| = T
We write φ to indicate that the consequent does not have to be an atomic vari-
able – it can be compound.
4.2  Computation of Truth Values of Well-Formed Formulas of ∑

142
Sustained study of the definition of the horseshoe will reveal that we have another 
case in which the output is determined regardless of complete information: in every 
possible case in which the consequent has the truth value T, the whole formula 
receives the truth value T regardless of the truth value of the antecedent.
•	 |φ ⊃ T| = T
•	 |F ⊃ φ| = T
•	 |T ∨ φ| = |φ ∨ T| = T
•	 |F ∙ φ| = |φ ∙ F| = F
We can also show cases in which we are unable to complete the computation 
when we lack information about the assigned truth values of certain atomic vari-
ables. We can, again, examine the definitions of our connectives to ascertain that 
this is the case. For instance, if one conjunct is true (one, either one, of the joined 
formulas by using the dot to join them), then we cannot determine what the truth 
value of the whole formula is: there is one possible case in which the whole formula 
is T and there is another possible case in which the whole formula is F. Let us see 
what those cases are.
|T ∙ φ| =? ⇒ if |φ| = T, then |T ∙ φ| = T ∙ T = T.
|T ∙ φ| =? ⇒ if |φ| = F, then |T ∙ φ| = T ∙ F = F.
The same for:
|φ ∙ T| =? ⇒ if |φ| = T, then |φ ∙ T| = T ∙ T = T.
|φ ∙ T| =? ⇒ if |φ| = F, then |φ ∙ T| = F ∙ T = F.
Let us now inspect a list of such cases, in which incomplete information about 
the assigned truth values makes it impossible to finish the computations.
•	 |φ ⊃ F| =?
•	 |T ⊃ φ| =?
•	 |F ∨ φ| = |φ ∨ F| =?
•	 |φ ∙ T| = |T ∙ φ| =?
•	 T ⊃ T = T / T ⊃ F = F/ F ⊃ T = T/ F ⊃ F = T
|φ ⊃ T| = T.
We wonder now what examination of the definitions of other connectives may 
show, to allow us to complete computations even with incomplete information about 
the assigned truth values of the atomic variables. It is straightforward to inspect the 
definitions (by any method we have used) to attest to the following results, which 
we show below. We also include the results we have already discussed.
4  Sentential Logic Languages ∑

143
We can actually provide equations – which are not going to be helpful with the 
computations, as we have indicated – that relate compound formulas under incom-
plete information with the truth values of variables. Here is an example, for the case 
examined above, in which we know that the truth value of one conjunct is true but we 
do not know the truth value of the other conjunct. In that case, it is the truth value of 
the unknown conjunct that determines the output: if the unknown conjunct receives T, 
then the whole formula receives T; if the unknown conjunct receives F, then the whole 
formula receives F: thus, the truth value of the whole formula is equal to the truth 
value of the unknown conjunct. Clearly, this means, again, that we cannot compute. 
Let us see certain equations in which we have an established relation between the truth 
value of the whole formula and the truth values of atomic components.
•	 |T ⊃ φ| = |φ|
•	 |φ ⊃ F| = |~ φ|
•	 |φ ∨ F| = |F ∨ φ| = φ
•	 |φ ∙ T| = |T ∙ φ| = φ
•	 |φ ⊃ ~ φ| = ~ φ
•	 | φ ∨ (φ ∙ ψ)| = | φ ∙ (φ ∨ ψ)| = φ
Finally, we need to take into account the case in which, even under incomplete 
information about the truth value of the component atoms, we may be able to estab-
lish that the given formula is a tautology – in which case it receives the truth value 
T regardless of any, and for all, truth values of its atomic components – or a contra-
diction – in which case the formula has to receive the value F regardless of the truth 
values of its atomic components. Clearly, this problem is related to the challenge of 
determining the logical status of a well-formed formula (if it is a tautology, a con-
tradiction, or a contingency, which we learned how to do by applying the truth table 
method in 4.5.) We may still provide some characteristic equations of tautologies 
and contradictions, although it is not possible to provide an exhaustive list.
We must also keep in mind that the negation of a tautology is always a contradic-
tion, and the negation of a contradiction is a tautology.
•	 |φ ⊃ φ| = T
•	 |φ ∨ ~ φ| = |~ φ ∨ φ| = T
•	 |φ ≡ φ| = T
•	 |φ ≡ ~ φ| = |~ φ ≡ φ| = F
•	 |φ ∙ ~ φ| = |~ φ ∙ φ| = F
•	 |φ ⊃ (ψ ⊃ φ)| = T
•	 |(φ ⊃ ψ) ≡ ~ (φ ∙ ~ ψ)| = T
•	 |~ (φ ∨ ψ) ≡ (~ φ ∙ ~ ψ)| = T
•	 |~ (φ ∙ ψ) ≡ (~ φ ∨ ~ ψ)| = T
•	 |(φ ⊃ ψ) ≡ (~ ψ ⊃ ~ φ)| = T
4.2  Computation of Truth Values of Well-Formed Formulas of ∑

144
4.2.4  Computation by Truth Tables
In case of incomplete information, if it is impossible to determine the truth value of 
the compound formula, we may add assignments of truth values to the unknown 
variable or variables, essentially constructing rows of what we will come to study as 
the truth table for the given formula. In 4.5, we introduce the truth table mechanism 
but we will now have an early glimpse. We use an example. Although we will turn 
to a systematic examination of the truth-tabular systematization in a subsequent sec-
tion, we recall that we have already used the mechanism in 4.3.b as a method of 
defining the connectives of our formal system. As an initial exercise, with a view to 
training by stages and also in order to acquire some deeper affinity for the truth-­
tabular method, we consider a special case: trying to compute the truth value pos-
sibilities of a given formula under incomplete information. We take the opportunity, 
once again, to marvel how the standard sentential logic is compositional: this is a 
remarkable metalogical property, deeply characterizing of this logic, not to be 
expected when we move to something like relational predicate logic in subsequent 
chapters. What this means is that the truth value of a well-formed formula of the 
sentential logic can be computed (precisely determined) for every case in which the 
truth values of the component atomic (individual) variables are known. The issue is 
not epistemic (about how and what we know): the point is that the logical meaning 
(which is the truth value in the case of sentential formula) is fully determined by 
means of computation from the truth values of the atomic variables of the formula. 
We need to think, now, that there are many different combinations of ways in which 
truth values, true and false, can be assigned to the atomic component variables of a 
formula. The number of such combinations is itself computable and it is 2n, where 
n is the number of atomic variables of the formula. Each such assignment of truth 
values represents a logical possibility (logically possible case, logically possible 
interpretation, modeling – these are ways in which we can find this concept named 
in texts.) The entirety of such assignments represents the truth conditions of the 
formula. If the formula turns out to be true for all such possible cases, then the for-
mula expresses a logical truth; it expresses a logical contradiction if it is false for 
every logically possible case; the only remaining third category – that some value 
assignments to the component atoms make the formula true and some make it 
false – is what we call an indeterminate-indefinite formula or, also called, a logical 
contingency.
When we do not have information about the truth values of all the component 
atomic variables, we may or may not be able to compute the truth value of the for-
mula. It may also happen that the information about the truth values of the atomic 
variables accrues gradually. This does not refer to a deep logical characteristic; it is 
rather an empirical matter how this information is received; but the issue shows how 
versatile a computational instrument like the truth table can be in application even 
in such a case in which we have gradual feeding of information. As we compute the 
truth value of a formula for specific assignments of truth values for the atomic vari-
able components of the formula, we are essentially determining – if possible – the 
4  Sentential Logic Languages ∑

145
truth value of the formula for one logically possible case. For a truth table, each 
logically possible case is represented or modeled by a horizontal row (or, simply, 
row, since by definition the rows are the horizontal lines.) The columns of the truth 
table, on the other hand, are labeled, as we say, by the atomic variables and by the 
formula or formulas for which the truth table is constructed.
•	 We are given valuations (truth-value assignments) for the atomic components 
(ultimate components which are the atomic variables or letters) of a given well-­
formed formula φ. But we are not given value assignments for all the component 
atomic letters. We are asked to determine, if possible, the truth value of the given 
formula.
•	 |p| = |q| = |r| = T
•	 |s| = F
•	 |t| =?
•	 φ = ~ ((p ∨ ~ (q ≡ ~ s)) ⊃ (~ t ∙ r))
•	 We “plug in” the given truth values and place a question-mark sign under 
the unknown atomic variable. We are conducting this activity in our meta-
language, ℳ(∑). We advance in stages (labeling them by using numbers 
from {1, 2, …} in the column under the “φ=” column. The labeling will 
allow us to make precise references to the stages of this process when we 
provide commentary.
φ=
~
((p
∨
~
(q
≡
~
s))
⊃
(~
t
∙
r))
1
T
T
F
T
T
T
F
?
T
2
T
T
F
T
T
T
F
?
T
3
T
T
F
T
T
T
F
?
T
4
T
T
F
T
T
T
F
?
T
5
T
T
F
T
T
T
F
?
T
6a
T
T
F
T
T
T
F
?
T
6b
T
T
F
T
T
T
F
?
T
•	 Analysis of the Stages:
•	 1: we insert the given truth values under the variable symbols.
•	 2: we compute the value of the third (from the left) occurrence of the tilde: 
this is the smallest-scope occurrence of the tilde.
•	 3: we can now compute the value of the (only) occurrence of the triple bar, 
since we know by now the truth values of the two component letters con-
nected with the triple-bar symbol.
•	 4: we compute the value of the second occurrence of the tilde; this is possible 
since we know by now the value of the triple bar (which is under the scope of 
the second tilde.)
4.2  Computation of Truth Values of Well-Formed Formulas of ∑

146
•	 5: we compute the value of the (only occurrence of the) wedge since we know 
by now both values of the formulas connected by the wedge.
•	 here, we have reached the limit of what we can possibly compute on the basis 
of the given information: accordingly, we add two rows, for the two logically 
possible truth values of the unknown atomic letter; the information of all the 
other values for the symbols remains the same, and, so, we repeat it across 
each of the rows we have now created.
•	 6a and 6b show the two rows we need to generate by assigning the two logi-
cally possible truth values to the unknown variable.
•	 Now, we have the following partial (elliptic) truth table to construct. Across 
each row, which is considered as logically independent from the other row, 
we carry on with computations in the same fashion we have been doing so 
far. We place within boxes the new valuations we determine across each 
row after we have assigned the possible values to the variable whose value 
we are not given. When we finish the truth table, we reflect on the results. 
We see that our given formula may possibly take the value T and may also 
take the value F (in the other row.) Thus, there is no unique or determinate 
truth value that the given formula has in the absence of specification about 
the value of the unknown variable. We carry on with the computations, as 
before. This time, each stage has operations carried out on two rows – the 
two rows we have constructed, one for each logically possible assignable 
value of the unknown letter.
φ=
~
((p
∨
~
(q
≡
~
s))
⊃
(~
t
∙
r))
1
T
T
F
T
T
T
F
F
T
T
T
T
F
T
T
T
F
T
F
T
φ=
~
((p
∨
~
(q
≡
~
s))
⊃
(~
t
∙
r))
2
T
T
F
T
T
T
F
F
T
F
T
T
T
F
T
T
T
F
T
F
T
T
φ=
~
((p
∨
~
(q
≡
~
s))
⊃
(~
t
∙
r))
3
T
T
F
T
T
T
F
F
F
T
F
T
T
T
F
T
T
T
F
T
T
F
T
T
φ=
~
((p
∨
~
(q
≡
~
s))
⊃
(~
t
∙
r))
4
T
T
T
F
T
T
T
F
F
F
T
F
T
F
T
T
F
T
T
T
F
T
T
F
T
T
This can be regarded as a demonstration of the incomputability of the formula 
under information-restrictions: it is shown that the formula may take the value T (in 
at least one row) and may take the value F (in at least one other row of the truth 
4  Sentential Logic Languages ∑

147
table); therefore, there is no unique or determinate truth value for the formula and 
this is sufficient to characterize the formula as indeterminate under the constraint of 
the given information (which, as we have indicated, is elliptic or incomplete.) 
Obviously, in the case of logical truths and logical falsehoods the formula must be 
considered computable even under incomplete information about the values of the 
components or under no information at all: this is because, by definition, a tautology 
has the value T for every possible assignment of truth values to the atomic compo-
nents and a contradiction takes F for every possible assignment of truth values to the 
atomic components. This is the case if we do not recognize that we are dealing with 
a formula that expresses the logical form of a logical truth or logical falsehood. 
These properties are certainly independent of our subjective reactions or any psy-
chological dispositions.
4.2.5  Exercises
	1.	 Given the truth values for the atomic variables, we can compute the truth values 
of the compound well-formed formulas that are given. This remarkable charac-
teristic of the standard sentential logic is called Computationality of Meaning. 
Implement all the methods we have presented (quasi-algebraic, computation 
trees, truth tables) to determine the truth values of the compound well-formed 
formulas for the values (metalinguistically symbolized by “||”) of the atomic 
variable letters.
|p| = T, |q| = T, |r| = F, |s| = F, |t| = F.
	a.	 |~ ~ (p ≡ q) ≡ ~ (s ≡ t))| =?
	b.	 |~ (p ∙ ~ q) ∨ (~ r ∨ ~ s ∨ t)| =?
	c.	 |~ ~ (p ⊃ (q ⊃ (r ⊃ (s ⊃ t))))| =?
	d.	 |((p ∙ t) ∨ (q ∙ s)) ≡ ~ (p ⊃ (s ⊃ t))| =?
	e.	 |(p ⊃ ~ t) ≡ (s ⊃ ~ q)| =?
	f.	 |((p ⊃ (q ∙ t)) ⊃ ~ ~ ~ r) ≡ s| =?
	g.	 |(q ∨ (r ∙ s)) ⊃ ((q ∨ r) ⊃ (q ∙ s))| =?
	h.	 |(p ≡ (q ≡ t)) ≡ ~ ((r ≡ s) ≡ ~ t)| =?
	i.	 |(~ (r ∙ s) ∨ ~ (s ∙ t)) ⊃ ((s ∨ t) ∨ ~ (p ∙ q))| =?
	j.	 |(p ∙ q ∙ ~ r ∙ ~ s) ≡ ~ (p ∨ ~ q ∨ s ∨ ~ t)| =?
	2.	 We may be able to determine the truth value of a compound well-formed for-
mula when we know the truth values of only some of the atomic variable letters. 
In the cases in which this is possible, determine the truth values for the given 
symbolic expressions.
|p| = F, |q| = F, |r| = T, |s| = T; |x| =?, |y| =? .
	a.	 |~ (x ∙ y) ⊃ (~ (r ∙ s) ⊃ (p ∨ q))| =?
	b.	 |(x ∨ s) ≡ ~ (y ∙ q)| =?
	c.	 |(x ≡ y) ∙ (p ∙ (q ⊃ r))| =?
	d.	 |(x ⊃ p) ∨ (s ⊃ y)| =?
4.2  Computation of Truth Values of Well-Formed Formulas of ∑

148
	e.	 |((p ≡ r) ∙ (q ≡ s)) ⊃ ~ (x ≡ ~ y)| =?
	f.	 |(x ∨ y) ≡ ((x ∙ y) ⊃ ~ (p ⊃ q))| =?
	g.	 |~ (p ∨ ~ t) ⊃ (x ⊃ (y ⊃ s))| =?
	h.	 |~ ((p ∨ t) ∨ (p ∨ t)) ⊃ ((y ⊃ (y ⊃ x)) ≡ ~ (x ∙ y))| =?
	i.	 |~ (x ≡ ~ (y ≡ (q ≡ s))| =?
	3.	 Even under incomplete information about the truth values of the atomic variable 
letters of a given compound formula, we might still be able to determine the 
formula’s truth value by using the truth table method to assign possible cases of 
assignments of truth values to the variables whose truth values we do not know. 
Use this approach to determine, if you can, the truth values for the following 
formulas under the incomplete information you are given.
|x| =?, |y| =? .
	a.	 |x ⊃ (y ⊃ x)| =?
	b.	 |~ ((x ⊃ y) ∙ ~ (x ⊃ y))| =?
	c.	 |((x ⊃ y) ⊃ x) ⊃ x)| =?
	d.	 |~ x ⊃ (y ∨ ~ x)| =?
	e.	 |(x ≡ y) ≡ ~ (x ≡ y)| =?
	f.	 |(y ⊃ (y ⊃ x))| =?
	g.	 |~ (y ⊃ (y ⊃ ~ y))| =?
	h.	 |(x ≡ (x ∨ y)) ≡ (y ≡ (y ∨ x)))| =?
	i.	 |(x ⊃ ~ y) ⊃ (y ⊃ ~ x)| =?
4.3  A System of Truth Tables for ∑: ∑⊞
Our formal language ∑, whose grammar we laid out in 3.1, is now adapted for 
implementation of a truth table system. This is one familiar and inexorable subject 
that you always meet in introductory Logic texts. The type of formal system known 
as Truth Table – possibly named so by Ludwig Wittgenstein, a twentieth-century 
philosophic prodigy – is what we call a decision procedure: this means that this type 
of system, implemented through some formal language like our ∑⊞, affords us a 
mechanical procedure that is provably guaranteed to terminate in a manageable 
number of steps and allow us to reach a result regarding whether an argument form 
is valid or invalid, whether a set of formulas is consistent or inconsistent, and 
whether a given formula has a logical property like being a tautology or a contradic-
tion or a contingency. This type of decision procedure – it is not the only one – is 
available for the basic sentential logic we are studying at this point: it can no longer 
be used in the full complement of the logic we call predicate, which we will study 
in chapter 5. Of couse, it is assumed that the ideal user of the truth table method is 
competent and knows how to implement the system: as always, an individual’s pos-
sible incompetence in using the formal system is not relevant to assessing the sys-
tem’s decisional efficiency.
4  Sentential Logic Languages ∑

149
We have already discussed the truth table method because we deployed it as one 
of the methods available for defining our formal system’s connectives. We can con-
struct the truth table for one given formula φ, which we designate as ∑⊞(φ). Every 
well-formed formula has a unique truth table; any well-formed formulas φ and ψ 
that have the same truth tables are equivalent: we will have to specify what we take 
as “same truth tables.” We can construct the truth table – also unique – for a set of 
well-formed formulas, {φ1, φ2, …, φn}: ∑⊞({φ1, φ2, …, φn}). If we are given an 
argument form, we can construct the unique truth table for that argument form: 
∑⊞({φ1, φ2, …, φn}/..ψ). See how we place the premises of the argument form 
within the set brackets and we use the metalinguistic symbol “/..” to separate the 
proffered conclusion of the argument form.
Let us take the case of the truth table for one well-formed formula φ first. It is 
crucial that we identify the number of types of atomic letters (also called individual 
or single variables) in the formula. For instance:
•	 ⌜(p ∨ ~ p) ≡ ~ p⌝ has only one type of atom, ⌜p⌝, and three occurrences of this 
type; we would mark the occurrences, as first and second and third, from left 
to right.
•	 ⌜~ (p ∨ ~ (s ∙ t))⌝ has three different types of atomic letter, each one occurring 
exactly once.
•	 ⌜t ⊃ (r ⊃ ~ (q ⊃ (s ∨ ~ (p ∙ ~ t)))⌝ has five types of atomic letter, with ⌜t⌝ occur-
ring twice while every one of {p, q, r, s} occurs exactly once.
We call the degree of a well-formed formula (wff) the number of types of letters 
occurring in it. Thus, in our preceding examples, the first wff is of degree 1; the 
second is of degree 3; the third is of degree 5. If we have more than one formulas, 
the truth table we construct is determined by the degree of the wff with the larg-
est degree.
If the degree of the formula – or of the largest-degree formula – is n, our truth 
table must have 2n rows. A truth table has rows and columns. The columns are one 
for each of the atomic letter types and one for each of the well-formed formulas. 
The number of rows, as we indicated, is 2n, where n is the number of types of atomic 
letters. Thus, revisiting our preceding examples: the truth table for the first formula 
has 2 columns (one for its letter type, ⌜p⌝, and one for the formula itself); the truth 
table for this formula has 21 = 2 rows since the number of letter types n = 1. We show 
this truth table below. We are not filling out the truth table entries for the formula 
itself; we only show the columns (each one marked at the top) and the rows (marked 
underneath the atomic letter type of the formula.) The symbols we use to mark, and 
indicate, rows and columns, are metalinguistic and are added for visual and learning 
facilitation.
Columns ⇀
1
2
Rows
⇃
p
(p ∨ ~ p) ≡ ~ p
1
2
T
F
4.3  A System of Truth Tables for ∑: ∑⊞

150
We could be writing the rows – or labeling them, if you will – with F for the first 
row and T for the second row. Nothing depends on this but we must establish a 
consistent procedure to follow systematically and we opt for legislating that, for one 
letter type, we write from top to bottom as <T, F>. Note that it is not arbitrary that 
we use “<” and “>” as symbols to enclose the truth values: this means that the order 
matters; this pair is an ordered pair, as we call it. We specify that the first symbol to 
the left is the top truth value, for row 1, and the second symbol of truth value, for 
row 2, is the second one we write. To complete the truth table, we have to carry out 
and complete the computations across each row: we use the truth values, for the 
atomic letters, in that row. Each row is like its own independent case: this is a logi-
cally possible assignment of truth values to the atomic letters. Mark that each inde-
pendent row (not affected by assignments in any other row) is a unique assignment 
of truth values to the atomic letters. Moreover, the truth table shows all the logically 
possible assignments of truth value combinations to the atomic letters. Every row is 
such an assignment. Thus, the rows show all, and only, the logically possible assign-
ments of truth values to the atomic letters of the formula. When we fill out the truth 
table by carrying out and completing the computations across each row, we end up 
showing, for the complete truth table, all the possible truth values the formula can 
take. This will show us automatically if the formula is a logical truth or tautology: 
that is the case, and only the case, when the formula is true for every row. We can 
take this to mean that the formula takes the truth value true for every logically pos-
sible case: hence, it is a logical truth. If the formula takes the truth value false in 
every row, then it is false for every logically possible case (every logically possible 
assignment of truth values to the atomic components), then it is a logical falsehood 
or a contradiction. And the last remaining case is when the formula is true in some 
rows and false in other rows; that formula is called contingent – or a contingent or, 
also, it can be called, logically indefinite or logically indeterminate.
Thus, the truth table is made possible because of the computational character of 
the basic sentential logic: given the truth values of the atomic letters (the ultimate 
atomic components), the truth value of the whole formula can be computed and 
determined uniquely; this is done across each row (for each logically possible case 
of assignments of truth values to the atomic components.) The truth table is like a 
map of all the logically possible cases. All such logically possible cases are shown; 
only the logically possible cases are shown. Thus, each row shows a logically pos-
sible case – which is also called in the literature a valuation or an interpretation (and, 
of course, we can call it a truth value assignment.) Let us fill in to complete the truth 
table of the preceding example. We box in the truth values of the formula (which, as 
we know from our study of computations, are the truth values of the main connec-
tive symbols.) We subdivide the columns and number all of them, so we can specify 
the order in which we carry out the operations. We can say that we generate sub-­
columns in this way. We do this for illustrative purposes.
1
2
3
4
5
6
7
8
p
(p
∨
~
p)
≡
~
p
1
2
T
F
T
F
T
T
F
T
T
F
F
T
F
T
T
F
4  Sentential Logic Languages ∑

151
	1.	 Column 1: this is the column for the atomic letter type of our formula. Underneath, 
for the two rows and from top to bottom, we write the truth values: <T, F>, 
which, as we have explained, means T for the top row and F for the next row 
from top to bottom.
	2.	 Column 2: Now we are in our formula; we repeat the values for ⌜p⌝ for each row: 
we can say that we plug in, across each row, the truth value of ⌜p⌝ for that row. 
We will do this also in rows 5 and 8.
	3.	 Column 3: this is the wedge column. But we have first to make the computations 
for the tilde in column 4. The tilde in column 4 has smaller scope than the wedge 
in column 3.
	4.	 Column 4: this is the column for the first occurrence of the tilde. Its scope has 
only in it the second occurrence of ⌜p⌝ in our formula. We do the computations. 
Next, we go to column 3 to make the computations for the wedge.
	5.	 Column 5: we plug in the values for ⌜p⌝ across each row.
	6.	 Column 6: This is the triple bar column. This is the major or largest-scope connec-
tive symbol of the formula. This is where we end in our computations. The truth 
values underneath this symbol are the truth values of the formula for each row.
	7.	 This is the column for the second occurrence of the tilde in our formula. It has in 
its scope only the third occurrence of ⌜p⌝ in the formula. We compute this before 
we can compute the triple bar column. It does not matter if we compute this 
before we compute column 4 or the other way round.
The order in which we carry out plugging truth values and carrying out computa-
tions is as follows: we begin with the rightmost column of the columns for the atomic 
variable letter: from top to bottom we alternate Ts and Fs; the number has to be even 
of course since, as we have intimated, the number of rows of a truth table is a power 
of 2 and specifically it is determined as 2n where n is the number of distinct types of 
atomic letters in the given formula. We then move to the next column to the left and 
from top to bottom we alternate 2 Ts and 2 Fs; once again, since the number of rows 
is a power of 2, the number of rows this being even, we have an even number of com-
binations to enter. For the next column to the left, from top to bottom, we alternate 4 
Ts and 4 F’s; and so on. This is not the only possible recipe (see if you can determine 
other plausible orders): 2 (plugging in values of the atomic letter) but, at any rate, it is 
the one we implement in this text. This is the general mode and it is, as such, appli-
cable regardless of the number of letter types in the formula. We examined the case of 
a formula with one letter type above. Next we examine a case in which we have two 
types of atomic letters; Accordingly, the number of rows has to be 22 = 4, since the 
number of types of atomic letters is 2. as we have specified, from top to bottom, for 
the right-most letter we wrote: <T, F, T, F>; then we move to the next atomic letter to 
the left and, from top to bottom, we write: <T, T, F, F>. We could have implemented a 
different recipe but this is the one we will apply consistently; it is guaranteed to give 
us all the possible combination of assignments of truth values, without repetitions. If 
we read the truth value assignment across each row, now we read from left to right 
and, thus, we have for the first row <T, T>, for the second row <T, F>, for the third row 
<F, T>, and for the fourth row <F, F>. Study the truth table below.
4.3  A System of Truth Tables for ∑: ∑⊞

152
<T, T, F, F>
<T, F, T, F>
p
q
<T, T>
<T, F>
<F, T>
<F, F>
T
T
F
F
T
F
T
F
For any well-formed formula φ of the formal language ∑ it is possible to con-
struct its characteristic truth table, ⊞(φ). Truth tables for distinct formulas φ and φ 
are considered equivalent if and only if the two truth tables agree on the truth values 
for every row. It is provable that the truth tables agree if and only if the formulas 
themselves are logically equivalent, which means that they have the same truth val-
ues for every possible truth value assignment to their atomic letters. Since every row 
of a truth table shows a logically possible case or logically possible assignment of 
truth values to the atomic variable letters, it follows straightforwardly that formula 
equivalence means equivalence of the formulas’ truth tables in the sense that we 
defined above.
The truth table is a decision procedure for determining such logical properties as 
validity of argument forms, status (tautology, contradiction, contingency) of senten-
tial formulas, relations of members of pairs of sentential formulas (equivalence, 
implication, and other relations), consistency of sets of sentential formulas, and 
there are more applications of the truth table, which we will not have the opportu-
nity to cover in the present text. The truth table can be used also as a dynamic instru-
ment for recording shifting and adjustable information: as new information is 
entered, relevant rows of the truth table can be deleted to accommodate this accru-
ing information. We will not have the opportunity of covering this here but it is 
worth taking notice.
The truth table is an efficient decision procedure: it is provable that the truth table 
for any finite number of formulas terminates in the sense that it comes to completion 
within a finite number of steps (although, soon with the number of atomic variables 
increasing, the number of rows grows exponentially); a programmed machine can 
in principle carry the operations, which further means that the truth table makes 
available a mechanical procedure for decision. It is also provable that, as an efficient 
procedure, the truth table reaches the correct results with respect to the tasks to 
which it is appointed.
The truth table represents all the logically possible combinations of assignments 
of truth values to the atomic variable letters of the given formulas. Each row repre-
sents a logically possible assignment of truth values to the atomic variable letters. 
Other terms we can deploy to refer to this are as follows: each row provides a logi-
cally possible case, interpretation, state of affairs, modeling valuation. The truth 
table represents all and only the logically possible valuations. Each row represents 
such a valuation. Each row – each logically possible case – is considered indepen-
dent from all the other rows or valuations; this reflects that the notion of logical 
meaning that is taken as basic in this logic is one that does not shift dynamically 
depending on context. If the truth value on any one row depended on the truth values 
4  Sentential Logic Languages ∑

153
on any other rows, that would mean that the contextual variation of valuations along 
different contexts would have an effect on defining the value of a formula: in this 
way we could model such notions as “necessarily” and “possibly” but such so-­
called modal notions fall outside the scope of the basic sentential logic.
It is notable, however, that such notions as “logically possible” and “logically 
necessary” and “logically impossible” and so on play a role in our definitions of 
such core notions as argument validity; we say that an argument form is invalid if it 
is logically possible to have an instantiation with all premises true and a false con-
clusion. This concept of logical possibility is left rather obscure, which should not 
be tolerated in a strictly formal and precise an enterprise. It so happens that, for the 
specific purposes of the basic and standard sentential logic, the rows of the truth 
table represent exactly the logical possibilities we are talking about. A row repre-
sents a logical possibility. Thus, it is logically possible for a set of sentential formu-
las to be consistent or jointly satisfiable, as we will see, if and only if there is at least 
one row across which all the formulas are true in their constructible truth table. The 
official definition is that the formulas are consistent if and only if they can possibly 
be true together – and, as we can see, this is expressible strictly and accurately in 
terms of the rows of the truth table. To examine another example, we can say that a 
formula has a logical form that is a tautology or necessary or logical truth if and 
only if its truth table has (is labeled, we might say, by) true in every one of the for-
mula’s rows: again, the rows represent all the logical possibilities and the totality of 
those logical possibilities characterizes logical necessity (or, we can this of it also as 
being the case that it is logically impossible for the formula to be false since there is 
no row on which it receives the truth value false.)
4.3.1  Application of the Truth Table as a Decision Procedure: 
Validity, Logical Status of Sentences, 
Consistency, Relations
	1.	 One application of the truth tables decision procedure is to check validity of 
argument forms: invalidity is determined when there is at least one line with all 
premises true and conclusion false; this line gives us a counterexample to the 
argument form we are considering. If this happens (if all premises are true and 
the conclusion false in a line or row), then we have a counterexample to the argu-
ment form and the argument form is invalid. Our logic has a pleasing symmetry 
about it: if not true, the value is false and vice versa; if not invalid, the argument 
form is valid and vice versa. If the truth table does not generate any counterex-
ample (if there is no line with all the premises being true and the conclusion 
being false), then the argument is not invalid and, therefore, it is valid. We can 
also state how the procedure works for checking argument validity directly: for 
all the rows for which all the premises are true, the conclusion is also true. Key 
issue to pay attention to are: all the premises have to be true in order to check 
4.3  A System of Truth Tables for ∑: ∑⊞

154
whether the conclusion is also true. This suggests that rows in which we have 
false premises, or even some false premises, are not interesting to us when we 
check for validity. We will take advantage of this when we present shortcuts for 
the decision process.
We show an example below. The symbol “/..” is used to set off the conclusion 
of the given argument form. Commas may be used to separate the premises, if 
the argument form has more than one premises.
∑⊞((p ⊃ q) ⊃ p /.. p).
1
2
3
4
5
1
p
q
(p ⊃ q) ⊃ p
/.. p
<PREMISE, CONCLUSION>
2
T
T
  T T T T T
T
<T, T>
3
T
F
  T F F T T
T
<T, T>
4
F
T
  F T T F F
F
<F. F>
5
F
F
  F T F F F
F
<F, F>
There is no counterexample-row. The truth values of the premise and the conclu-
sion on the same row are shown informally by means of an auxiliary column that 
has been added (column 5). There is no row across which all the premises are true 
(in this case, the one premise is true) and the conclusion is false. Therefore, the 
argument is valid.
	2.	 Another application of truth tables is for determining the status of a formula: if 
it is a tautology (all rows true), a contradiction (all rows false), or a contingency 
(in some rows the formula checks true and in some rows it checks false.) Other 
words for tautology are: validity, necessary truth, syntactically or formally ana-
lytic true sentence, logical truth, trivial truth. Such truths are not informative; 
they reflect how we have defined the key logical terms: “and”, “not”, “either/or”, 
“if-then”, “if and only if”. A formula is a contradiction if it checks false in every 
row. Other words for this: invalidity, logical or necessary falsehood. Making 
statement that have the logical form of a contradiction amounts to speaking non-
sense or committing logical absurdity whether one realizes this or not!
We construct the truth table for the given formula, ∑⊞(φ). We examine the 
truth values the formula takes in all the rows: these represent all the logical pos-
sibilities or logically possible cases. Our given formula is a tautology if and only 
if it has the truth value true, T, on every row. Given that the truth table method is 
to be trusted (as it is indeed), we establish that this is a necessarily true sentence: 
notice how we are able to map – so to speak – all logical possibilities by means 
of the truth table: the rows represent all the logically possible cases, and there are 
no other logically possible cases. Accordingly, we can capture the notions of 
logical possibility and logical necessity, which can be elusive to the untrained 
mind: each row represents a logically possible case; if the formula takes the truth 
value true in all rows, then it is necessarily true. If the formula takes the truth 
value false, F, in every row of its truth table, then it is logically necessarily false: 
it is called a contradiction; other terms in the literature include: logical false-
4  Sentential Logic Languages ∑

155
hood, necessary falsehood, syntactically or grammatically analytic false 
­sentence, trivial falsehood. The only remaining possibility as to the logical status 
of a given formula, as determined by the truth table method, is that the formula 
has both true and false truth values on its rows; the number of such occurrences 
is not important. Such a formula is called logical contingent or a contingency 
and other names are: indefinite and indeterminate. Such a formula is logically 
possible true and logically possible false but, of course, not jointly true and false 
(which is prohibited by the semantics of our logic): we discern this perspicu-
ously in that there can be no row on which the formula takes both T and F (this 
is rendered impossible by the appropriate arrangements we have applied in con-
structing the method); but the formula is possibly true (i.e. true on at least one 
row) and possibly false (false on at least one row.)
	3.	 The truth tables method is also applicable to determine whether a given set of 
sentential formulas is consistent: we construct the truth table of the given formu-
las, ∑⊞(φ1,…, φn): the formulas taken jointly are, or the set of the formulas is, 
consistent if and only if there is at least one row in which all the formulas check 
as true. If this is not the case, if not a single line or row exists on which all the 
formulas take the truth value true, then the set of formulas is inconsistent.
Consistency is a characteristic applying to two (a pair) or more formulas 
taken together. We can regard the collection as a theory, a comprehensive opin-
ion, an entire novel... Inconsistency cannot be detected always and, if it occurs, 
it means that the overall theory is pretty much useless as it stands - it perpetrates 
logical absurdity! The term joint satisfiability is used sometimes instead of the 
term consistency. The sentential formulas, under assessment, are jointly satisfi-
able if and only if they can all be true together: by reference to the truth table, 
this means that the given formulas are jointly satisfiable if and only if there is at 
least one row of their constructed truth table, across which (row) they are all true. 
This term may be preferred because matters of truth value (true and false) can be 
said to accord with the concept for which we use the term satisfaction: a formula 
is satisfied by a truth value assignment if and only if the formula is true for this 
assignment. A set of formulas is satisfiable if and only if there is a truth value 
assignment (a row of the truth table) on which all the formulas are computed or 
determined as being true. Truth as a truth value satisfies, as we say according to 
the terminology. On the other hand, consistency, as a term of choice, could be 
reserved for the kind of systematic analysis (to be presented in subsequent chap-
ter) that examines constructed derivations or proofs and focuses on syntactic 
methods. This distinction between “satisfiability” and “consistency” is not usu-
ally observed, however, as most textbooks are wont to use “consistency” when 
applying the truth table method. We will stick with “consistency” even as we 
have intimated that a more precise and refined terminology would preferably use 
“joint satisfiability.”
	4.	 We can finally apply the Truth Table method to determine how any two formulas, 
any pair of formulas, are related to each other.
a) A pair of sentential formulas, φ and ψ, is consistent if and only if the truth 
table of the two formulas, (∑⊞(φ, ψ)), has at least one row across which both 
4.3  A System of Truth Tables for ∑: ∑⊞

156
formulas are true (receive T as the truth value.) Of course, this definition is a 
special case (for n = 2) of the examination of the consistency of a set of any 
number n of formulas, which we presented above. A pair of formulas is inconsis-
tent if and only if it is not consistent – in other words, if there is no row of 
∑⊞(φ, ψ) across which both formulas receive the truth value T.
b) A formula φ implies formula ψ in one direction (one-directional implica-
tion or one-directional conditional), if and only if the truth table ∑⊞(φ, ψ) has 
no row in which φ checks as T and ψ checks as F.
It is possible, of course, that φ implies ψ but ψ does not imply φ. The implica-
tion ψ ⊃ φ is called the converse of the implication φ ⊃ ψ. Therefore, conversion 
(claiming that the converse of a tautological implication is itself necessarily true) 
is an invalid inference to make in general. In the special case, which we will 
examine below, in which φ and ψ are logically equivalent, both implication and 
converse are necessarily true.
Assume that φ and ψ are related so that φ implies ψ. There is a definable 
binary connective symbol of our logic, #, for which the formula φ # ψ is a tautol-
ogy. Given the definitions of the connective symbols, we can show that this con-
nective symbol is no other than the horseshoe (material implication or conditional 
symbol.) Since φ implies ψ, from the definition we have given we know that 
there is no row in which φ is true and ψ is false. We need to cross that row out. 
We inspect the truth table to see that, given the crossing out, indeed, the implica-
tional formula is a tautology.
φ
ψ
φ ⊃ ψ
T
T
  T
T
F
  F
F
T
  T
F
F
  T
c) Two formulas φ and ψ are logically equivalent (materially logically equiva-
lent) if and only if the truth table ∑⊞(φ, ψ) has the same truth values (both T or 
both F) for every row of the truth table: this means that φ implies ψ and also ψ 
implies φ. In this case, and only in this case, we can say that not only does φ imply 
ψ but also, conversely, ψ implies φ.
Assume that φ and ψ are related so that φ and ψ are logically equivalent with 
each other. There is a definable binary connective symbol of our logic, #, for which 
the formula φ # ψ is a tautology. Given the definitions of the connective symbols, 
we can show that this connective symbol is no other than the triple bar (material or 
logical equivalence symbol.) Since φ and ψ are logically equivalent, from the defi-
nition we have given we know that there is no row in which φ and ψ take opposite 
truth values. We need to cross out any row in which φ and ψ take opposite values (φ 
is true and ψ false or φ is false and ψ is true.) We inspect the truth table to see that, 
given the crossing-out, indeed, the implicational formula is a tautology.
4  Sentential Logic Languages ∑

157
φ
ψ
φ ≡ ψ
T
T
  T
T
F
  F
F
T
  F
F
F
  T
d) Another relation between sentential formulas φ and ψ, which is not discussed 
often but we should know about it since we study logic, has different names: exclu-
sive disjunction, logical (or material) disequivalence. Two formulas φ and ψ are 
mutually disequivalent or they are related by exclusive disjunction (they are mutual 
exclusive disjuncts) if and only if the truth table ∑⊞(φ, ψ) shows the formulas 
obtaining opposite truth values (if one is true, the other is false, and the other way 
around.) We can recognize this as the relation of exclusive disjunction or exclusive 
either-or: this sense of either-or means that definitely one of the two formulas is true 
but both cannot be true; so, either φ is true and ψ is false or ψ is true and then φ is 
false. Exactly one of the formulas is true. We can construct the truth table for this 
relation. We notice that this truth table has entries for all its rows, which negate the 
truth values for the truth table for logical equivalence. Hence, it turns out that exclu-
sive disjunction for this standard logic is the same as negation of logical equivalence 
(and for this reason another term that is used for this relation is “disequivalence.”) 
But there is more: this relation is also the relation of mutual contradictoriness: φ and 
ψ are mutual contradictories, which makes sense since they take opposite truth val-
ues in every row (in every logical possibility.
Assume that φ and ψ are mutual disjuncts (mutually disequivalent, mutual con-
tradictories.) There is a definable binary connective symbol of our logic, #, for 
which the formula φ # ψ is a tautology. We do not have a symbol for this in our 
formal language. Let us add the symbol “≢” for this connective. We can name it the 
disequivalence symbol (or cancelled tribar.) Analysis of the truth table ∑⊞(φ, ψ) 
shows how this happens. In this case, given the definition of disequivalence, we 
need to cross out the rows in which the formulas have the same truth values (they 
are both true or they are both false.) The formula that is constructed by joining φ and 
ψ by the disequivalence symbol is, then, a tautology after the crossing out has been 
effectuated.
φ
ψ
φ ≢ ψ
T
T
  F
T
F
  T
F
T
  T
F
F
  F
e) Two formulas φ and ψ are mutual contraries (related by the relation of contra-
riety) if and only if their truth table ∑⊞(φ, ψ) shows no row in which they are true 
together but there is at least one row in which they are false together. The formulas 
can be false together but they cannot be true together.
4.3  A System of Truth Tables for ∑: ∑⊞

158
Assume that φ and ψ are mutual contraries. There is a definable binary connec-
tive symbol of our logic, #, for which the formula φ # ψ is a tautology. We do not 
have this connective symbol in our formal language: we add it as “|”. The formula 
φ | ψ is logically equivalent with the formula ~ (φ ∙ ψ) (negated conjunction). After 
crossing out rows, based on the definition of contrariety, the formula φ | ψ is shown 
to be a tautology.
φ
ψ
(φ | ψ) ≡ ~ (φ ∙ ψ)
T
T
  F
T
F
  T
F
T
  T
F
F
  T
(f) Two formulas φ and ψ are called mutual subcontraries (or related by the rela-
tion of subcontrariety) if and only if the truth table ∑⊞(φ, ψ) has no rows across 
which they are both false; the formulas can be true together but they cannot be false 
together.
Assume that φ and ψ are related so that φ and ψ are mutual subcontraries. There 
is a definable binary connective symbol of our logic, #, for which the formula φ # ψ 
is a tautology. Given the definitions of the connective symbols, we can show that 
this connective symbol is no other than the wedge or vel (the inclusive disjunction 
symbol.) We inspect the truth table to see that, given the crossing-out, indeed, the 
implicational formula is a tautology.
φ
ψ
φ ∨ ψ
T
T
     T
T
F
     T
F
T
     T
F
F
     F
4.3.2  Partial Truth Table: ∑⊞p
For the short truth table method: we start by making all the premises true and the 
conclusion false. In this way we are trying to construct a counterexample (see 
above.) We then proceed with computations. As soon as we have values for indi-
vidual letters we plug them in. If we succeed, we have a counterexample: this means 
that the logical form is invalid. If we fail, the argument form is valid: we fail if we 
run into logical impossibility or absurdity, which means that we find ourselves 
assigning both T and F to the same symbol!
Example: Check the validity of the argument form [((p ⊃ q) ∙ (∼ p ⊃ q)) /.. q], 
by using the partial and short truth table methods.First, we apply the full truth table 
method to determine validity of the given argument form.
4  Sentential Logic Languages ∑

159
The premise is: (p ⊃ q) ∙ (∼ p ⊃ q). The conclusion is: q.
∑⊞ (p ⊃ q, ~ p ⊃ q /.. q).
p
q
(p
⊃
q)
∙
(∼p
⊃
q)
/.. q
T
T
F
F
T
F
T
F
T
T
F
F
T
F
T
T
T
F
T
F
T
F
F
F
F T
F T
T F
T F
T
T
F
F
T
T
F
F
T
F
T
F
There is no row with T for the premise and F for the conclusion. It follows that 
there is no counterexample. The argument form is not invalid; it is valid.
Since invalidity is established only when we have a counterexample-row (for 
which all premises are true and the conclusion false), a shortcut strategy called 
Partial Truth Table is available: we begin with the column of the conclusion; we 
then restrict our attention only to those rows for which the conclusion is false; no 
other row can possibly yield a counterexample (which, as we know, is any row that 
has all premises as true and the conclusion as false): and, if we do not have a coun-
terexample, we must determine the argument form to be valid.
p
q
(p
⊃
q)
∙
(∼p
⊃
q)
/.. q
T
T
F
F
T
F
T
F
T
F
F
T
F
F
F
F
F T
T F
T
F
T
F
F
F
Additionally, we can make the partial truth table approach even more abbrevi-
ated and still be able to determine the correct answer as to validity. In the preceding 
example, we could have stopped on the second row as soon as find a false premise: 
since a counterexample is a row with all premises true and a false conclusion, it fol-
lows that this row cannot yield a counterexample since it has even one false premise.
In general, the partial truth table approach, as an informal strategic method for 
pursuing a shortcut, recommends: determine the truth values from top to bottom for 
the column of the conclusion of the argument form; determine the truth values of the 
premises only for the rows for which the conclusion is false; you do not need to 
continue with any one of these rows if you determine that a premise has a false 
conclusion; survey the final result upon completion based on the recommendations: 
the argument form is invalid if and only if there is any row with all the premises true 
and the conclusion false.
There are some obvious strategies for a partial truth table approach in the cases 
of determining consistency of a set of formulas or the logical status of a given for-
mula or relations between formulas by application of the truth table method. For the 
case of consistency: as soon as a row is determined to have all the formulas true, we 
may discontinue the decision procedure: it is sufficient to characterize the given set 
of formulas as consistent since, by definition, a set of formulas is consistent if and 
only if there is at least one row across which all the formulas receive the truth 
value true.
4.3  A System of Truth Tables for ∑: ∑⊞

160
We can discontinue the process as soon as we have a row on which the formula 
is true and another row on which the formula is false: we may then correctly char-
acterize the formula as contingent (logically indeterminate or logically indefinite.) 
In the case of checking for a tautology or a contradiction, having one row on which 
the formula is true and another row on which the formula is false also establishes 
that the formula is not a tautology and it is not a contradiction; it is, instead, a con-
tingency. These characterizations of logical status are jointly exhaustive (there are 
no other characterizations besides these) and pairwise mutually exclusive (if the 
formula has any one of these types of logical status, then it cannot have any of the 
other types of logical status.) If we are continuing to determine that the formula is 
true/false on consecutive rows from top to bottom, as we are trying to determine if 
the formula is a tautology/contradiction, then we have to continue unless a row is 
evaluated to have the truth value of the formula as false/true.
4.3.3  Short Truth Table Method (Quick Computation 
Method): ∑⊞𝑠
The method of the short truth table or also called quick computation method draws 
on the principle that informs the type of proof that is known by the Latin name 
reductio ad absurdum. Assuming a claim, we prove that this claim is false by deriv-
ing from this claim, and from other unreservedly accepted true premises, a contra-
diction. Assertions of any sentence and also of this sentence’s negation constitutes a 
contradiction. We reason about our steps in implementing the short truth table in our 
metalanguage. The point is, in this so-called negative approach, to show that our 
given argument form is valid by ending up deriving a contradiction upon making the 
initial assumption that our given argument form is invalid. Since there are exactly 
two logical possibilities – that an argument form is valid or it is invalid and it cannot 
be neither and it cannot be both – showing that the argument form is not invalid 
means that it is valid. We have the advantage of knowing, from the definition of 
invalidity, that our given argument form is invalid if and only if it has an instance in 
which all its premises are true and its conclusion is false: in terms of the truth table 
approach, this means that there is at least one row of the argument form’s truth table, 
on which all the premises take T and the conclusion takes F. This row is what we 
presume to reproduce in our opening move – our gambit. We make all premises true 
and the conclusion false. We then proceed to make computations as we have learned 
to do. What is relevant in this case is especially the prospect of making computa-
tions of truth values when we have incomplete information about the truth values of 
the atomic variables. We will examine details soon. If the endeavor succeeds, we 
essentially end up with constructing a row in which all the premises are true and the 
conclusion is false – and this is a counterexample that is sufficient to establish inva-
lidity of our given argument form. If, however, we end up deriving a contradiction, 
this proves definitively that no counterexample can be produced: after all, we made 
4  Sentential Logic Languages ∑

161
no special stipulations about what we were attempting as we were simply trying to 
produce any counterexample whatsoever. But if no counterexample can be pro-
duced, that establishes that our given argument form is invalid. Now we check in 
some detail what the various steps of this procedure are.
•	 The first step in the short truth table method consists in assigning T to all the 
premises and F to the conclusion of the given argument form. As we know, this 
truth value assignment is carried out by taking the value of the major operators 
of the formulas to be T or F respectively. A moment’s thought should disclose 
that this truth value assignment is a pretense aiming at constructing a counterex-
ample to the argument form. The availability of at least one counterexample (by 
definition, a truth value assignment that makes all the argument form’s premises 
true and the conclusion false) establishes unconditionally that the argument form 
is invalid. It is crucial for the effectiveness of the short truth table method that a 
counterexample is determined to be available if and only if indeed the argument 
form is invalid (if and only if such a counterexample is indeed available.) 
Therefore, it is key to the effectiveness of the short truth table method that we are 
able to determine without running into any open-ended or ambiguous results 
whether the attempt to produce a CEX (counterexample) fails. We can spell out 
already at this point how failure to produce a CEX is checked determinedly in the 
implementation of the short truth table method: when completed for all the 
atomic sentential variables in the argument form, the truth value assignment that 
is posited as giving us a CEX assigns both values (T and F) to at least one atomic 
variable. This means that we can stop as soon as this happens. The proof princi-
ple upon which we draw in this method is the same as the one driving the famous 
proof procedure known, in Latin, as reductio ad absurdum or proof by contradic-
tion (or, also, as indirect proof method.) One crucial assumption is posited or 
presumed while all other steps in the proof are executed in strict accordance with 
the formal rules in our proof system. If a logical absurdity results, then the ini-
tially posited assumption is the only one that can be rejected - which means in the 
semantics of classical or bivalent sentential logic that the posited assumption 
needs to be negated. Since the assumption we start with in the short truth table 
method is that a counterexample is available, the determination that we reach 
logical absurdity entails that the assumption that a CEX exists against our given 
form is to be denied. Therefore, since there is no CEX to it, the given argument 
form must be valid.
•	 After all the premises have been assigned T and the conclusion F, we continue 
with the computational task of determining truth values for all the symbols in the 
form, all the way to the atomic variables. At this point we might run into delays. 
For instance, if ⌜∨⌝ receives a T (some inclusive disjunction in the argument 
form is true under the truth value assignment we are filling out), this yields not 
one or two but three alternatives: as we know from the truth table for the connec-
tive of inclusive disjunction, there are three logically possible alternative setups 
for all of which the truth function (inclusive disjunction) is computed as 
T. Clearly, we do not want to make this our first step after the initial values 
4.3  A System of Truth Tables for ∑: ∑⊞

162
assignments. We might indeed have other options. For instance, some conjunc-
tion might have received a T as a result of the opening assignment: this means 
that both conjuncts must be assigned Ts, since this is the only way for conjunc-
tion to take the truth value T. Perhaps the conjuncts are themselves atomic sen-
tential letters, which means that we are ready to proceed to another step.
•	 As soon as truth values of atomic sentential letters (atoms) become available, we 
plug them in, as it were, into all the places where the same letters appear in the 
argument form. Essentially, what we are attempting to do in this procedure is 
reproduce one single row of the complete truth table by means of which we can 
check validity of the given argument form. Across this row, the atomic sentential 
letters have fixed truth value assignments. We pretend, of course, that this one 
row is a counterexample (not necessarily the only one but it takes even one avail-
able CEX to establish that the given argument form is invalid.) The preponderant 
issue is whether we will be successful in this endeavor or not.
•	 There are exactly two possible outcomes which are mutually exclusive (precisely 
one or the other is guaranteed to eventuate upon completion of the procedure 
which is itself guaranteed to terminate within time that is sufficient for comput-
ability purposes.)
One possibility is that we are able to complete the full truth value assignment all 
the way down to the atomic letters. In this case, all the symbols in the argument 
form (except for the auxiliary symbols, the parentheses, of course) have received a 
unique truth value. In this fashion, we have successfully reproduced a row of the 
truth table for the given argument form, across which all the premises are true and 
the conclusion is false. This means that we have established that at least one coun-
terexample to the argument form is available and, hence, the argument form is 
invalid.
The other possibility is that some symbol will receive not a unique truth value 
but - the only other possible alternative - both truth values T and F. As soon as this 
happens we may terminate the procedure and determine that no counterexample to 
the given argument form is available. In bivalent standard logic, logical consequence 
may or may not obtain and there is no other alternative. It is like dealing with a light 
switch that can only be on or off without any other combinations or gradations avail-
able. Hence, failure to establish even one counterexample - rather, proof that there 
is no counterexample - entails that the argument form is not invalid and, therefore, 
it is valid.
We show below how cases are determined based on initial truth value assign-
ments to the various sentential connectives. We should always keep in mind the 
shortcuts we presented when studying computations with truth values.
•	 F ⊃ φ and φ ⊃ T receive T regardless of the value of φ.
•	 T ∨ φ and φ ∨ T always receive T regardless of the value of φ.
•	 F · φ and φ · F always receive F regardless of the value of φ.
•	 φ ⊃ φ and φ ≡ φ receive T regardless of the truth value of φ.
•	 ~ (φ ≡ φ) and ~ φ ≡ φ and φ ≡ ~ φ receive F regardless of the value of φ.
4  Sentential Logic Languages ∑

163
•	 φ ⊃ ~ φ is logically equivalent to ~ φ and, so, its truth value cannot be deter-
mined if the truth value of φ is not given.
•	 All tautologies receive T and all contradictions receive F regardless of the values 
of the variables in them: the logical status – tautologousness or contradictori-
ness – can be determined by the truth table or short truth table procedure: thus, 
we have reached the limit of available shortcuts we can use.
As an example, we may consider the following case.
(p ⊃ q) ⊃ p ⊨∑⊞? p.
1. (p ⊃ q) ⊃ p ⊨ p.
T 	
 F
We begin by making the single premise true and the 
conclusion false.
2. (p ⊃ q) ⊃ p ⊨ p.
F    ?   T F   F
We plug in the truth value for ⌜p⌝ across the whole line. 
The value of the atomic variable, which we have dis-
covered, has to be the same across: remember that we 
are pretending to be constructing some putative row 
that is a counterexample to the given argument form: 
this is one row, across, and, as such, it has the same value assignment for each of the 
atomic variables. Once we have discovered the truth value of an atomic variable, our 
labor is facilitated significantly as we can put this value for all occurrences of this 
atomic variable. Indeed, the contradiction we may reach, if the argument form is 
valid and no counterexample can be constructed, would be in the form of assigning 
both truth values, T and F, to the same variable or connective symbol – which is 
logically absurd given the rules of the “game” in our standard logic, by value assign-
ments and computed values are set to be exactly one of T or F and cannot be both.
Since ⌜p⌝ obtains the truth value F across our row, the first implication symbol 
receives T. This follows from the definition we have given for the truth function we 
have called material implication and we noted it in our computational shortcuts. 
Now, we notice something about the second occurrence of the implication symbol 
(which is the major operator symbol in our premise.) The antecedent of this implica-
tion has received T and the consequent has received as truth value F. This compels 
the third step:
3. (p ⊃ q) ⊃ p ⊨ p.
F T T     F   F
     F
     x
We note that we have reached a state of affairs that is 
logically impossible: we have been compelled to assign 
both T and F to the same symbol! Therefore, our attempt 
to reconstruct any counterexample (or counterexample-
row of the truth table) has resulted in logical absurdity. 
From this it follows that no counterexample to this 
counterargument form can be constructed. This, of 
course, means that the given argument form is valid.
4.3  A System of Truth Tables for ∑: ∑⊞

164
4.3.4  Referring to the Truth Table to Prove Metalogical Theses
Suppose that we want to prove, informally, that the negation of a tautology is a con-
tradiction and the negation of a contradiction is a tautology. We can do this by mak-
ing appropriate and relevant references to our familiar method of the truth table. We 
will show this and some other examples and will include more such theses that can 
be argued for by making references to the truth table as exercises. We use the set-­
theoretic symbol “∈” to symbolize inclusion (being a member of a set) and we work 
informally within our metalanguage as we argue in support of the various metalogi-
cal theses we examine. Given that the truth table is a faithful method – it provably 
reaches the correct results – our theses carry weight within the broader analysis of 
the standard sentential logic.
•	 φ ∈ TAUTOLOGIES(∑⊞) if and only if ~ φ ∈ CONTRADICTIONS(∑⊞).
•	 Because this is an “if and only if” thesis, we need to prove both directions: impli-
cation from left to right and implication from right to left.
•	 a) Assume that φ ∈ TAUT(∑⊞). This means that in every row of the truth table 
∑⊞ (φ), the formula receives the truth value true, T. Now, we construct the truth 
table of the negation of the given formula, ∑⊞(~ φ). Since the negation of T is 
F, false, all the rows of the new truth table will obtain F as the formula’s truth 
value. Hence, the formula, ~ φ, takes the truth value false in every row: therefore, 
it is a contradiction: ~ φ ∈ CONTR(∑⊞). This shows that the negation of any 
tautology is a contradiction.
•	 b) Assume that ~ φ ∈ CONTR(∑⊞). This means that the truth table of the for-
mula, ∑⊞(~ φ), determines the formula to be receiving the truth value F, false, 
for every row. The truth values, F in every row, are for the main connective sym-
bol, which is the negation symbol. Given the definition of negation by the truth 
table, it must be the case that the formula φ, which is negated in every row, has 
the truth value T, true. (The negation symbol turns T to F and F to T, by defini-
tion.) Therefore, φ has the truth value T in every row. Were we to construct the 
truth table for φ, the formula would have to take T as its truth value for every row. 
Therefore, φ is a tautology: φ ∈ TAUT(∑⊞). We have shown that the negation 
of a contradiction is a tautology.
•	 φ ⊃ ψ ∈ TAUTOLOGIES(∑⊞) if φ is a contradiction.
•	 It is given that φ, the antecedent of the implicational or conditional formula φ ⊃ 
ψ, is a logical contradiction. This means that in the truth table for the implica-
tional formula, ∑⊞(φ ⊃ ψ), the truth value for φ is false in every row. Given the 
definition of the implication symbol (horseshoe), the implication must take the 
truth value true, T, in every row: because, by the definition of the horseshoe, we 
have F only when the antecedent is T and the consequent is F – and there is no 
such row in this case. Therefore, the implication is a tautology. This shows that 
an implication with a contradiction as antecedent is a tautology. This is called 
sometimes a vacuous implication – an implication that is tautological on account 
of its antecedent being true.
4  Sentential Logic Languages ∑

165
•	 The logical status of φ ∨ ψ cannot be decided in general if it is given that both φ 
and ψ are logically indeterminate.
•	 We assume that two formulas, φ and ψ, are both contingencies (logically inde-
terminate or logically indefinite.) This means that the truth tables for these for-
mulas, ∑⊞(φ) and ∑⊞(ψ), have for the formulas rows in which the formulas 
take T and rows in which the formulas take F as their truth value. Now, we merge 
the truth tables to construct the truth table ∑⊞(φ, ψ). Since we do not have any 
information about the locations of the Ts and Fs for the formulas (we don’t know 
in what row numbers we have the different truth values), we cannot determine if 
there are rows in the new truth table, in which T and T align. Let us construct the 
truth table ∑⊞(φ ∨ ψ): given that, as we indicated, we do not know how the 
truth values of the two formulas align, we cannot determine if there is at least one 
row in which they are both true: this is what we need for the inclusive disjunction 
of the two formulas, φ ∨ ψ, to be true. For any specified pair of formulas <φ, ψ>, 
the truth table will yield a unique and correct result as to the logical status of φ ∨ 
ψ; but no general thesis can be formulated about the logical status of the inclu-
sive disjunction of two logically contingent formulas.
4.3.5  Range of a Well-Formed Formula 
and Logical Consequence
The term “range” was coined, in the sense we will use it, by Rudolf Carnap; it is 
usually omitted from textbooks these days but it is useful for certain theoretical 
purposes.
We have not studied set theory at this point (see chapter 10) but we need for now 
only a basic fixing of some metalinguistic notation for our purposes. A set is an 
abstract entity – we don’t worry about its metaphysical status – that is a collection 
of objects of any kind. Obviously, we need symbols to refer to those objects and it 
is those symbols we place within set-brackets, “{” and “}”, to indicate inclusion as 
members of a set. It is understood, however, that the members of the set are the enti-
ties and not the symbols. The order in which the member-symbols are written is 
irrelevant and repeating a symbol more than once does not add anything and so this 
is prohibited.
Looking at a preceding example, consider the following set which we call the 
range of the well-formed formula for which we constructed the truth table. We sym-
bolize the “range” by “𝓇” and we enclose the formula within parentheses as shown 
in the example below. The information below announces that the formula, whose 
range we are determining, receives the truth value T, true, for exactly the truth val-
ues, of <p, q> as shown. Checking the truth table for the formula, we establish that 
the formula is true only in one row, in which both atomic variables are true. In the 
ordered pair, enclosed within “< >”, the leftmost variable is as in the truth table we 
4.3  A System of Truth Tables for ∑: ∑⊞

166
are using; and so on for the variables to the right. Since we have two atomic vari-
ables in our formula, the values are for <p, q>.
𝓇((p ⊃ q) ∙ (∼ p ⊃ q)) = {<T, T>}
The members of the range are ordered pairs. We use “<” and “>” for enclosure of 
the members of an ordered pair. Unlike in the case of sets, the order in which the 
members of ordered pairs are written matters. It is easy to discern that we write the 
ordered pairs with the value of the left-most individual variable first and the variable 
to the right as second member of the ordered pair. The definition of a range of a 
formula is: The range of the formula includes all and only the assignments of truth 
values to the atomic variables of the formula, for which, assignments, the formula 
is true.
Depending on the number of distinct types of atomic variable (letter) in the for-
mula, we can determine the range as a set of ordered n-tuples: restricting our interest 
to the case of formulas with two distinct atomic variable letters, we speak of ordered 
duplets or ordered pairs. The range, as a set, is a subset of what is called the Cartesian 
product of the truth value set by itself. The Cartesian product of two sets A and B is 
the set whose members are all the ordered pairs such that the first member of each 
pair is a member of A and the second member is a member of B. To generate the 
Cartesian product of a set by itself, we form the set of all the constructible ordered 
pairs that have first and second member from the given set. Consider how this is to 
be done for the Cartesian product of the set of truth values.
𝓥2 = {T, F}
𝓥2 x 𝓥2
T
F
T
F
<T, T>
<F, T>
<T, F>
<F, F>
The range of a formula 𝛗 with two distinct atomic variable types is a subset of 
the Cartesian product of the values-set by itself. A set X is a subset of a set Y if and 
only if all members of X are members of Y. (Y may or may not have additional 
members.) The relation of subsethood is symbolized by “⊆”. We show what all this 
means below.
•	 𝓥2 = {T, F}
•	 𝓥2 x 𝓥2 = {T, F} x {T, F} = {<T, T>, <T, F>, <F, T>, <F, F>}
•	 𝓇(𝛗) ⊆ 𝓥2 x 𝓥2
Let us now see something remarkable. First, we assess the range of the well-­
formed formula made of the atomic variable ⌜q⌝ which is the conclusion of the 
given argument form.
𝓇(q) = {<T, T>, <F, T>}
We know that the argument form is valid. In our metalanguage we can use the 
turnstile symbol, “⊨”, to show validity of argument forms in the following sense: 
what is to the left of the turnstile – the premises – are taken conjunctively (although 
shown to be separated by commas); the conclusion is to the right of the turnstile; the 
4  Sentential Logic Languages ∑

167
turnstile shown as such (not canceled as in “⊭”) indicates that the premises taken 
conjunctively imply the conclusion. Thus, as we say, the relation of logical conse-
quence obtains. We can think of a logic as the collection of all its cases of logical 
consequence. Thus, continuing with our example, we have:
(p ⊃ q) ∙ (∼ p ⊃ q) ⊨ q
Now we examine the range-sets of the two formulas and we see that they are 
related in a certain way: the first (the premise-range) is a subset of the second (the 
conclusion-range). A set X is a subset of a set Y if and only if all members of X are 
members of Y. (Y may or may not have additional members.) The relation of subset-
hood is symbolized by “⊆”. Thus, we have:
𝓇((p ⊃ q) ∙ (∼ p ⊃ q)) = {<T, T>} ⊆ 𝓇(q) = {<T, T>, <F, T>}
This observation reflects a general result that – as we can prove – applies in the 
case of logical consequence of sentential logic: A premise implies a conclusion if 
and only if the range-set of the premise is a subset of the range-set of the conclusion.
In the case of more than one premises, we need to form a new set which is called 
the intersection of the range-sets of the premises. The intersection or overlap of two 
sets X and Y, symbolized by “⋂”, is the set that has as members exactly the mem-
bers which X and Y both share or have in common. Logical consequence obtains if 
and only if the intersection of the range-sets of the premises is a subset of the range-­
set of the conclusion. We see now an example of assessing valid logical conse-
quence in a case with more than one premises. It is straightforward to refer to the 
truth tables of the premises and conclusion to ascertain that the range-sets are as 
presented below. (One premise is ⌜p ⊃ q⌝ which is true, as know, for all value 
assignment except for <T, F>; the other premise is ⌜p⌝ and the conclusion is ⌜q⌝.)
•	 p ⊃ q, p ⊨ q
•	 𝓇(p ⊃ q) = {<T, T>, <F, T>, <F, F>}
•	 𝓇(p) = {<T, T>, <T, F>}
•	 𝓇(q) = {<T, T>, <F, T>}
•	 𝓇(p ⊃ q) ⋂ 𝓇(p) = {<T, T>}
•	 𝓇(p ⊃ q) ⋂ 𝓇(p) = {<T, T>} ⊆ 𝓇(q) = {<T, T>, <F, T>}
The concept of the range of a well-formed formula can be further put to good use 
in making observations about deductive reasoning and about the characterization or 
logical classification of statements. It so happens that the more members there are 
in the range of a formula 𝛗 the less informative is the statement 𝜮 interpreted by 
that formula 𝛗. Let us consider the case in which the range of a formula 𝛗 is the 
same as the Cartesian product 𝓥2 x 𝓥2. The statement that is interpreted by such a 
formula is a tautology since it receives the truth value True for all possible assign-
ments of truth values to its atomic components. No information is conveyed by this 
statement. To understand this, let us consider each row of the familiar truth table to 
be modeling a logically possible state of affairs. The truth table shows all logically 
possible states of affairs for the basic statement logic we are examining. A tautology 
is true in every row – in every logically possible state of affairs. Now let us consider 
4.3  A System of Truth Tables for ∑: ∑⊞

168
that we can use a well-formed formula of our formal language to label a state of 
affairs if this formula makes a statement uniquely true at that state of affairs. A tau-
tology cannot label any state of affairs. The same is the case, of course, with a logi-
cal contradiction which is a logical falsehood – as the tautology is a logical truth. 
Such statements cannot convey information – cannot characterize – any empirically 
distinguishable case or state of affairs.
When it comes to logically contingent or indeterminate statements, their ranges 
(more precisely, the ranges of their corresponding formulas) can be actually ranked 
in terms of comparative content. But, we will see now that this is not informative but 
logical content. The more members there are in the range of a formula 𝛗, the less 
content can be packed into its matching statement 𝜮. Notice that our deductive-­
reasoning concept of range is still not about how to actually engage in conveying 
informational content: we merely record relative or comparative receptivity of logi-
cally contingent statements with respect to conveying information. The logical char-
acterization is simply of being a logically contingent statement rather than how such 
a statement can be deployed in language to express informative content. The deduc-
tive notion that matters is that of logical consequence which, as we saw, is related to 
relative range: premises whose overlapping range is a subset of some formula 𝛗 
have 𝛗 as logical consequence if they are taken conjunctively. The relation that we 
examine in this way, calling it logical consequence, makes the trivial case that less 
content has as valid conclusion a more informative content insofar as there is no 
chance, in such a case, of having any logical content in the premises which has been 
left out in the conclusion. But what is crucial here is that we are speaking not of 
empirically verifiable content but of logical content. By logical content we mean 
truth conditions – the systematic assignments of truth values to the atomic compo-
nents of a formula, for which that formula takes the value True (in the semantic 
interpretation.) Thus, the range shows the truth conditions of a formula (more pre-
cisely, of the statement that interprets that formula.) Validity can, then, be under-
stood as a matter of proceeding to more inclusive range – including the trivial case 
in which the ascent is to equally informative content. The only case that is excluded – 
and is taken to signal invalidity of logical consequence – is the case in which we go 
from more to less logically informative content.
There are some corollaries we should note: The disregard for empirical content, 
which is deeply characteristic of deductive logic, entails that we cannot impose a 
requirement – in this formalist layout – that premises and conclusion must share 
relevant content between them. (The challenge for formal logic in this respect is to 
find some systematic device that might respect a formal requirement of shared con-
tent without resorting to restrictions that affect non-logical meaning. The results of 
such efforts, falling under the heading of Relevantist Logic, fall outside our cur-
rent scope.)
Here is an example of a valid logical consequence in which a new atomic vari-
able appears in the conclusion. In semantic terms, this means that a statement has as 
valid logical consequence the inclusive disjunction of this statement and any state-
ment whatsoever. A term that is used for such an apparent anomaly is paralogism. 
We find this term especially used in connection with the definition of the 
4  Sentential Logic Languages ∑

169
implication or conditional connective in the standard sentential logic; nevertheless, 
the case of inclusive disjunction – with the valid rule of “addition” allowing intro-
duction of an altogether new variable letter, has also received ample attention in the 
literature. It should be emphasized, however, that there is nothing inherently anoma-
lous in this case – the anomaly is apparent, not genuine. The meanings of the con-
nectives, as defined, characterize the formal logic that has been constructed and this 
result follows correctly within this logic. This establishes that no internal flaw has 
been discovered. The result can be criticized only in a context in which someone 
would insist that this connective captures the logical behavior of the linguistic 
phrase “either-or” in all possible circumstances.
p
q
p
p ∨ q
T
T
T
   T
T
F
T
   T
F
T
F
   T
F
F
F
   F
𝓇(p) = {<T, T>, <T, F>} ⊆ 𝓇(p ∨ q) = {<T, T>, <T, F>, <F, T>}
4.3.6  Exercises
	1.	 Determine if the following claims are true or false and refer to the truth table to 
provide analytical and detailed justifications for your answers:
	a.	 Two contradictions can be mutually consistent.
	b.	 A tautology implies a contradiction.
	c.	 An inconsistent set of premises implies validly any conclusion whatsoever.
	d.	 Two contradictions are mutually equivalent.
	e.	 A tautology and a contingency are mutually consistent.
	f.	 A contradiction is equivalent with itself.
	g.	 Two logical contingencies cannot be mutually equivalent.
	h.	 A contingency can possibly imply another contingency.
	i.	 The inclusive disjunction of a contradiction and a tautology is a logical 
contingency.
	j.	 An argument form with all contingent premises and a contingent conclusion 
cannot be invalid.
	k.	 An inclusive disjunction of two contingencies cannot be a tautology.
	2.	 Refer to the truth table to justify your answer to the following claims (which may 
be true or false.)
	a.	 If a logical contingency implies another logical contingency, then the two 
contingencies have to be logically equivalent.
4.3  A System of Truth Tables for ∑: ∑⊞

170
	b.	 The conjunction of two logical contingencies implies validly their inclusive 
disjunction.
	c.	 Two contingencies joined by the logical equivalence connective symbol form 
a formula that has to be a contingency.
	d.	 If two logical contingencies are mutually equivalent, then their conjunction 
has to be a logical contingency.
	e.	 Implication by a formula of its negation is equivalent with the formula itself.
	3.	 Draw on your understanding of the truth table approach to the semantics of the 
standard sentential logic to justify the following claims.
	a.	 Unlike inductive arguments, which can be weakened by addition of appropri-
ate premises (so that the conclusion is then less likely to be true if all the 
premises are true), deductive arguments cannot be weakened by addition of 
premises: this means that if a deductive argument form is valid, we cannot 
obtain an invalid argument form by adding premises:
if φ, ψ ⊨ χ, then it is not possible that φ, ζ, …, ψ ⊭ χ
	b.	 Invalid argument forms may yield valid argument forms by addition of appro-
priate formulas as premises:
possibly, φ, ψ ⊭ χ but φ, ψ, ζ ⊨ χ
	c.	 φ ∨ ψ cannot be a contradiction if and only if ⊨ φ ≡ ψ
	d.	 We can define a concept of the zeroary connective (a connective symbol that 
has zero input truth values) but we cannot use the truth table for providing a 
definition of such a connective.
	4.	 How are the following pairs of formulas related? Are they consistent? Mutual 
equivalents? Does the first imply or the second? Does the second imply the first? 
Are they mutually disequivalent (exclusive disjuncts of each other)? Are they 
mutual contraries? Are they mutual subcontraries? Refer to the truth table to 
justify your answers.
	a.	 ⌜p ⊃ q⌝ and ⌜p · ~ q⌝
	b.	 ⌜p⌝ and ⌜p ∨ q⌝
	c.	 ⌜p ≡ q⌝ and ⌜p ≡ ~ q⌝
	d.	 ⌜~ p · q⌝ and ⌜~ (q ⊃ p)⌝
	e.	 ⌜~ (p ∨ (q ⊃ r))⌝ and ⌜q ∨ r⌝
	f.	 ⌜~ p⌝ and ⌜p ⊃ (q ⊃ ~ (q ⊃ q))⌝
	g.	 ⌜p ⊃ (q · r)⌝ and ⌜p ⊃ q⌝
	h.	 ⌜p ⊃ q⌝ and ⌜(p · r) ⊃ q⌝
	5.	 Use the truth table method to determine if the given argument forms are valid or 
invalid. If invalid, supply the counterexamples values (defined as the truth value 
assignments to the atomic variable letters, for which all the premises are true and 
the conclusion is false.)
	a.	 (p ⊃ q) ⊃ (~ p ⊃ q), ~ (p ∙ q) ⊨ ∑⊞ q ⊃ p
4  Sentential Logic Languages ∑

171
	b.	 (p ⊃ q) ⊃ p, ~ p⊨ ∑⊞ p ⊃ (~ q ⊃ ~ p)
	c.	 (p ⊃ q) ⊃ (q ⊃ p), ~ p ⊨ ∑⊞ ~ q
	d.	 ~ (p ∨ q), q ⊃ p ⊨ ∑⊞ q
	e.	 ~ (p ∙ q), ~ p ≡ q ⊨ ∑⊞ p ∨ ~ q
	f.	 p ≡ (p ≡ ~ p) ⊨ ∑⊞ (p ⊃ q) ⊃ q
	g.	 p ⊃ (q ⊃ r), p ∨ q ⊨ ∑⊞ (p ∙ q) ⊃ r
	h.	 p ∨ (q ∙ r), ~ p, r ⊨ ∑⊞ p ⊃ (q ⊃ r)
	i.	 ~ q ⊃ (~ q ⊃ ~ (q ⊃ p)) ⊨ ∑⊞ ~ p ∙ q
	j.	 p ⊃ (q ⊃ ~ p) ~ (((p ⊃ q) ⊃ p) ⊃ p) ⊨ ∑⊞ r
	k.	 (p ⊃ q) ⊃ p, ~ q ∨ ~ p ⊨ ∑⊞ p ∨ r
	6.	 Use the truth table system we have constructed to determine whether the given 
well-formed formulas are tautologies, contradictions or contingencies.
	a.	 ⊨∑⊞ (p ⊃ (q ⊃ r)) ⊃ ((p ⊃ q) ⊃ (p ⊃ r))
	b.	 ⊨∑⊞ (~ p ⊃ ~ q) ⊃ (q ⊃ p)
	c.	 ⊨∑⊞ (p ⊃ q) ⊃ ~ (p ⊃ ~ q)
	d.	 ⊨ ∑⊞ ~ ((p ⊃ q) ⊃ ((q ⊃ r) ⊃ (p ⊃ r)))
	e.	 ⊨ ∑⊞ (p ⊃ q) ⊃ ((p ∙ s) ⊃ q)
	f.	 ⊨ ∑⊞ (p ⊃ q) ⊃ ((p ∨ s) ⊃ q)
	g.	 ⊨ ∑⊞ ~ (p ⊃ (q ≡ ~ p)) ∨ (~ p ∨ q)
	h.	 ⊨ ∑⊞ (((~ p ⊃ p) ∙ (q ⊃ p)) ⊃ ~ q) ⊃ ~ (q ⊃ q)
	i.	 ⊨ ∑⊞ (p ≡ (q ≡ r)) ≡ ((p ≡ q) ≡ r)
	j.	 ⊨ ∑⊞ (p ≡ ~ q) ≡ (p ≡ q)
	k.	 ⊨ ∑⊞ (p ⊃ ~ (q ∨ r)) ⊃ ((p ∙ q) ⊃ ~ r)
	7.	 Use the truth table method to determine if the given sets of sentences are consis-
tent or inconsistent.
	a.	 ⊨∑⊞ {~ p, ~ p ⊃ p, q ≡ p}
	b.	 ⊨∑⊞ {~ (p ⊃ q), p ⊃ q, ~ q ⊃ p}
	c.	 ⊨∑⊞ {p ⊃ q, p ⊃ (q ∨ r), ~ p}
	d.	 ⊨∑⊞ {(p ⊃ q) ⊃ p, ~ p ⊃ p}
	e.	 ⊨∑⊞ {~ (p ≡ q), (p ∨ q) ∙ ~ (p ∙ q)}
	f.	 ⊨∑⊞ {s ⊃ t, ~ s ⊃ t, t ⊃ ~ (s ∙ q), ~ q}
	g.	 ⊨∑⊞ {~ p ≡ ~ q, ~ (p ⊃ q), ~ (q ⊃ p)}
	h.	 ⊨∑⊞ {p ∨ (~ q ⊃ p), p ⊃ q, q}
	i.	 ⊨∑⊞ {~ ~ p, q ⊃ (p ∨ r), p ⊃ ~ q, q}
	j.	 ⊨∑⊞ {~ (p ∨ (q ⊃ ~ q)), ~ p ≡ q}
	k.	 ⊨∑⊞ {~ (p ≡ ~ (q ≡ r)), ~ (~ (p ≡ q) ≡ ~ r)}
	8.	 Use the truth table system to determine what logical relations obtain between the 
formulas that are given as ordered pairs. Possible relations: the first implies the 
second, the second implies the first, they imply each other (they are mutually 
equivalent), neither implies the other, they are consistent or inconsistent with 
each other, they are mutual contraries, mutual subcontraries, or exclusive dis-
juncts of each other. It is possible certainly that more than one relations obtain.
4.3  A System of Truth Tables for ∑: ∑⊞

172
	a.	 ⊨∑⊞ <~ (p ∨ q), p ⊃ ~ q>
	b.	 ⊨∑⊞ <(p ⊃ q) ⊃ q, p)>
	c.	 ⊨∑⊞ <p ⊃ q, p · ~ q>
	d.	 ⊨∑⊞ <(p ∨ q) · (p ⊃ r) · (q ⊃ r), r>
	e.	 ⊨∑⊞ <(p ⊃ q) ∨ (q ⊃ p), (p ≡ p) · (q ≡ q)>
	f.	 ⊨∑⊞ <p ≡ q, ~ p ≡ q>
	g.	 ⊨∑⊞ <p ≡ q, (p · ~ q) ∨ (~ p · q)>
	h.	 ⊨∑⊞ <~ p ⊃ q, ~ (~ q ⊃ p)>
	i.	 ⊨∑⊞ <(p ≡ q) ≡ (~ p ≡ p), ~ (q ≡ p)>
	j.	 ⊨∑⊞ <p ⊃ q, (r ⊃ p) ⊃ (r ⊃ q)>
	k.	 ⊨∑⊞ <(q ⊃ r) ⊃ (p ⊃ r), p ⊃ q>
	 9.	 Use the partial truth tables system to do the preceding exercises.
	10.	 What errors are committed in the following sequences of short-truth-table 
assignments and computations?
	a.	 ~ (p ⊃ q) ⊨? p.
1. premise T; conclusion F
2. |p|: F; |q|: F
3. |~ (p ⊃ q)| = T
//counterexample: <p, q> = <F, F>
	b.	 ((p ⊃ q) ⊃ q) ⊃ p ⊨? p.
1. premise T; conclusion F.
2. |(p ⊃ q) ⊃ q| = T
3. |((p ⊃ q) ⊃ q) ⊃ p| = F
4. premise is T and F
x
	11.	 Use the short truth table (quick computation) method to do the exercises in 8.
	12.	  •
	a.	 Why do we render the conclusion false for purposes of processing a short 
truth table approach to the determination of validity of argument forms?
	b.	 Does this mean that arguments with false conclusions must be invalid?
	c.	 Why do we count on failure of the short truth table process to declare the 
argument form valid  – and what do we mean technically by “failure” in 
this case?
	d.	 How can we adapt the short truth table method to check for consistency of a 
given set of sentences?
	e.	 How can we adapt the method to determine the logical status of a formula (if 
it is a tautology, a contradiction or a contingency?) Can we check if a formula 
is a contingency by only one application of the method?
	13.	 •
	a.	 What is the range of a logical contradiction?
4  Sentential Logic Languages ∑

173
	b.	 What is the range of a tautology?
	c.	 Using the concept of range, show that a contradiction validly implies any 
sentential formula and a tautology is validly implied by any sentential for-
mula. Understand that you need to use certain set-theoretic concepts as pre-
sented in the text. Chapter 10 expands on those themes.
	d.	 “We have class today” validly implies “either we have class today or the 
moon is made of cheese.” Clearly, there is no gain in increasing knowledge of 
how the world works from this logical phenomenon. Explain why this is not 
a problem, and cannot constitute grounds for a critique of logical conse-
quence: use the concept of range in your analysis.
	e.	 Given your prior understanding of theoretical concepts in logic, pursued 
throughout the earlier chapters, do you find the notion of range to be having 
any impact on your intuitive grasp of the relevant issues? If not, why do you 
think this is the case?
4.4  A System of Natural Deduction (Proof Method) 
for ∑: ∑∎
The type of proof system we examine in this section is not semantic: it does not 
work with assigning truth values (true and false) and with building models (as seen 
in the rows of the truth table system, which can be thought of as representing logi-
cally possible states or cases.) The meanings of the critical components of the for-
mal language, the connectives, are not construed semantically by assigned as 
referents truth values (true or false.) We have no interpretations (semantic interpre-
tations or valuations) to assign to the atomic and molecular components of senten-
tial formulas. There is no narrative, for instance, about logically possible states of 
affairs represented by truthtabular rows, and no stipulation of abstract objects that 
can sustain accompanying narratives. A prominent school of thought considers the 
approach we are examining in this chapter as the proper way for constructing logi-
cal languages. Tasks of analyzing and investigating logic are also cast in a new light 
as a result of opting for this approach with deep metalogical lessons accruing – but 
this lies beyond the scope of our current inquiry. The approach that we will examine 
next is called proof-theoretical. It enforces construction of proofs which are under-
stood as abstract collections of formally arranged (properly shaped) derived (proven) 
lines effectuating the final derivation of the conclusion from the given premise-­
lines. There are different varieties of natural deduction or proof-theoretic systems; 
we will two types. The term “natural deduction” is used rather promiscuously across 
the board of such systems although the original coinage of the term applies to a 
specific type of proof-theoretic systems.
Since the proof-theoretic approach has to accommodate the fundamental desid-
eratum of defining the logical connectives, the question immediately arises as to 
how this is to be done. The semantic approach, as we have seen, uses valuations or 
assignments of truth values (true and false for the standard bivalent logic) and 
defines the meanings of the connectives in terms of truth conditions. The by now 
4.4  A System of Natural Deduction (Proof Method) for ∑: ∑⊞

174
familiar truth table is one such semantic instrument for definition of the connectives. 
The proof-theoretic approach has a different view of how the meanings of the con-
nectives are to be defined, and this view has profound philosophical implications. 
The proof-theoretical approach does not depend on truth valuations for its pro-
nouncements on such fundamental subjects as what constitutes a correct argument 
(accordingly, the term “valid” is semantic and not proof-theoretical), under what 
conditions a sentence is trivially assertable (called “tautology” or “necessary truth” 
on the semantic approach), or how a set of sentences are jointly assertable (“jointly 
satisfiable” is the semantic term but “consistent” can be used more broadly.) 
Assertability is itself rather a semantic concept, if taken to mean that only true state-
ments are right assertable. The proof-theoretic view sees the semantically valid 
argument forms as proofs in which the conclusion line is correctly derivable from 
the premise lines; it views the tautologies of the semantic approach as lines that are 
self-justifying or trivially correct and can be laid down or added to a proof as lines 
and also as derivable without any premises whatsoever; and it views sets of consis-
tent sentences as lines that can be all laid down together without absurdity being 
derivable from these lines.
What we need to do next is to explain how correctness is understood on the 
proof-theoretical approach. Moving from lines to a new derived line correctly is the 
mechanism for proof-theoretical analysis. It so happens that this question, of cor-
rectness, is intrinsically entwined with the other remaining topic we need to present: 
how does the proof-theoretical approach define the connectives – given that it does 
not define them in terms of truth conditions or valuation assignments (of true and 
false) to the atomic components of the formulas?
The proof-theoretic definitions of the connectives are given by means of the cor-
rect rules that can be used in proof-constructions to regulate two derivational 
activities:
	1.	 how formulas with a connective (as main connective symbol) are to be derived 
justifiably on the basis of given lines: these are known as the introduction rules 
for the connectives; and
	2.	 how formulas with a connective as main connective symbol can be used (possi-
bly with other lines) to justify deriving a new line: these are known as the elimi-
nations rules for the connectives.
There are different views about this. One view, embraced by the originator of this 
school of thought, Gerhard Gentzen, is that only the introduction rules are the ones 
that fix the meanings of the connective while the elimination rules only draw out 
(and should be only drawing out, normally) what is already packed, in terms of 
meaning, in the given line with the connective as its main connective symbol. 
Another view is that the elimination rules are the ones that determine the connec-
tive’s meaning and there is a view that both the introduction and elimination rules 
set the meanings for the connectives.
In the proof theoretic approach, we construct proofs, line by line, starting with 
given premises and deriving new lines with the proposed conclusion as the last or 
terminal derived line; each new added line needs to be justified by appealing to one 
of the rules we have in our inferential system. We can have only correct rules (whose 
4  Sentential Logic Languages ∑

175
validity can be verified by applying our familiar truth table method). The term 
“validity” is semantic, of course, while “correct” is broader. We detect a relationship 
between the proof-theoretic and the semantic approaches, which we will have the 
opportunity to bring up again: there is a perfect match, harmony, between the 
semantic and the proof-theoretic approaches: every valid argument form (checked 
by a proven reliable semantic mechanism like the truth table) has to correspond to a 
proof that successfully derives the conclusion from the premises of this argument 
form; and vice versa, every correctly constructible proof or derivation of conclusion 
from premises must match a decision of validity for the truth table check of the cor-
responding argument form.
In applying derivation rules we generate instances of the given rules: this is like 
applying a “shape” or a recipe that instructs us how to proceed when we have given 
material that fits the “shape” or rule we are given. In the proof-theoretic approach – 
in contrast to the truth-tabular method  – we apply rules to derive lines and, as 
already noted emphatically, we do not speak of assignments of truth values to vari-
ables. Because of this line-by-line progression, this proof system has something 
“natural” about it. Everyday arguments, and academically constructed proofs, pro-
ceed in this fashion, issuing from given assumptions that are accepted and aiming at 
deriving a putative solution. In everyday linguistic usage, but also in academic and 
scholarly contexts, such deductive proofs are not constructed systematically; check-
ing if the proofs are valid (or, we might say, correctly constructible) is not done, 
with possibly dire consequences since proofs that don’t work might be accepted on 
the basis of psychological or subjective convictions that “the proof is good.”
In our systematic construction of proofs or derivations, we begin with given 
assumptions or premises and derive each line by applying our system’s given deri-
vation rules on lines that are already available in the sequence of proof lines (written 
vertically, starting from the top): each line must be justified as based on some previ-
ous line or lines and by means of some correct derivation-rule that has been used. 
We proceed in this way to the derivation of the proposed conclusion. When we find 
proofs in other contexts, we don’t see justifications of such derivations given; in 
fact, in everyday linguistics contexts, premises might be missing, not articulated and 
supposed to be implied. Even in Mathematics, the proofs are informal in the sense 
that we are not shown the justifications (the derivation rules that are used and the 
lines on which the rules have been applied). Such proofs are informal but ours will 
have justifications written next to each line.
Unlike the truth table and the tree systems, this proof method is not mechanical: 
if we cannot construct a proof, then we will not have a way of knowing that there is 
no possible way of constructing such a proof: it could be that our abilities have 
failed us even though a proof is constructible in principle. With the truth table and 
tree methods, subjecting invalid argument forms to the methods yields counterex-
amples – as you can ascertain by referring to the presentations of those methods. 
This is not the case with Natural Deduction. We cannot construct counterexamples 
to suggested argument forms that are not correct. We are avoiding the word “valid-
ity” here because “valid” is a characterization of argument forms in the semantic 
methods (those methods that we studied in formal languages with true-false truth 
values in them.) The Natural Deduction method, on the other hand, is 
4.4  A System of Natural Deduction (Proof Method) for ∑: ∑⊞

176
proof-­theoretic; it is not semantic and this means that in this method we just manip-
ulate symbols according to rules; we cannot build models in a Natural 
Deduction method.
Here is what we mean by model: think of the truth table and its rows; we have 
remarked repeatedly that each row represents a logical possibility for the mean-
ings – which are defined in terms of true and false for the individual letters. Each 
such logical possibility can be thought of as a logically possible world or state of 
affairs. In this way, we are modeling. In a Natural Deduction proof, on the other 
hand, we use derivation rules like recipes: by using such rules we derive new lines 
from given and already derived lines and, in so doing, we follow the rules in the 
same way we would be following a recipe step by step. We have no story to tell – as 
in the truth table where the rows can be thought of as logically possible worlds.
As already indicated, in the case the standard sentential logic, the proof-­
theoretical and the semantic approaches harmonize perfectly. Let us think of the 
semantic side (where we have the truth tables in the case of the sentential logic) as 
capturing what should be provable. The proof-theoretic side presents what is proce-
durally (proof-theoretically) derivable. The harmony between the two sides can, 
then, be accounted for in a manner that sounds quite natural: what should be prov-
able in the kind of logic we have is derivable by means of available formal proof-­
procedures. Considering, as by default, the truth table method to be yielding correct 
results (about what should be provable), we can ascertain that any constructible 
proof corresponds to an argument form that is determined valid by the truthtabular 
test; and, conversely, every valid argument form (as checked by the truth table) cor-
responds to a constructible proof in the proof-theoretic method. It might be objected 
that we have shown preference to the truth table approach, making it the ultimate 
arbiter of correctness, but such a choice can be defended (in ways that lie beyond 
our scope) without privileging one approach (semantic or proof-theoretic) over the 
other. It is not to be taken for granted that this works for all logics. It does work in 
the case of the standard sentential logic.
To give a few more details: the proof-theoretic side can be thought of as compel-
ling us to undertake syntactical procedures: manipulation of symbols according to 
grammatical rules and by applying certain figure-like schemata (recipes) which are 
the system’s derivation rules. In this approach, the underlying definitions of our 
connectives in the system are set by the rules that are given for managing how to 
introduce and remove any such connective symbol. Some logicians think that this 
gets it right what logic is about. A semantic system, on the other hand, allows us to 
present narratives: as we can do with the truth table whose rows can be thought of 
as representing logically possible cases for assignments of truth values (true and 
false, which are, again, semantic meanings that are used in defining the connectives 
themselves.) The narratives we can construct semantically are themselves abstract – 
they don’t correspond to empirical matters but to abstractions. Some interesting 
terminology can be given in this context: the semantic models interpret the formal 
proof-theoretic systems; the semantic models provide interpretations or valuations 
or value assignments or cases or assignments of meanings according to a signature; 
what are interpreted in this way are the items of the syntactically constructed sys-
tems. When we have complete harmony between the two sides – as the case is with 
the standard sentential logic – that means that we always find an interpretation of 
4  Sentential Logic Languages ∑

177
any formula of the proof system (we can use, for instance, the truth table to check 
that what is provable is also valid on the semantic side); and what checks as a valid 
argument form in the truth table system can always be proven in the proof-theoretic 
system. When we move from the proof-theoretic system to the semantic system suc-
cessfully, we say that the system is sound: only what should be provable is derivable 
(or, if we can derive it then we can model it.) When we have success in moving from 
the semantic to the proof system, we say that the logic is complete: what should be 
provable (what can be modeled) is indeed constructible by means of formal deriva-
tions in the proof system. Logicians are most interested in proving such metalogical 
results but our current purposes do not permit any details about this subject.
Our proof system, which we call ∑∎, has rule-schemata. These are like recipes 
about how to proceed when we have certain lines in order to produce new line or 
lines. The rules are for the different connectives. (We should strictly be using differ-
ent terms but, for convenience, we stick to our own terminology.) We use the same 
grammar as we have used before. We will have to present the rule-recipes in a meta-
language; so, different symbols will be used for those rules-schemata. We equip our 
system with more rules than we need; this is to make the proofs easier. Some of the 
rules we include could be given up without losing any proofs we are able to pro-
duce; but, as mentioned, we pack our system to redundancy in order to make the 
proofs easier. We will proceed connective by connective laying down the appropri-
ate rules. Eventually, we will graduate to rules that allow something remarkable to 
happen – we will explain what that is and we call it replacement. As we proceed, we 
will give examples of proofs that can be constructed only on the basis of the rule or 
rules we have so far.
Every proof will be composed of lines. To the left we write the number of each 
line (with numerals labeling the lines), starting with 1 and continuing sequentially. 
A line can have on it a premise, a line derived from premises and/or from other 
lines, and finally – when the proof terminates – the conclusion. To the right of each 
line we write the justification: this comprises the name of the rule that has been 
applied and the numbers of the lines (one or more lines) on which the rule has been 
applied. In some systems of natural deduction, allowance is made for entering a 
self-justifying line (some theorem or already proven conclusion of a proof) but our 
constructed systems do not include this amenity. It is a neat feature that premises 
themselves are considered self-justifying. The justification for a premise is written 
as “Premise” or “P.” We will also have so-called Assumed Premises or, written in 
justification, as “AP.” The catch is that an AP is like a debt we have: the proof cannot 
end without paying off or discharging the AP. The rules we will learn will also 
specify how APs can be discharged.
Here is an example of what a natural deduction derivation looks like: 
Prove: p ∨ (q · r), ~ p ⊢ q.
1. p ∨ q	
	
P
2. ~ p		
	
P
⋮
n. q	 	
	
rule^(line#, ⋯, line*)
4.4  A System of Natural Deduction (Proof Method) for ∑: ∑⊞

178
4.4.1  Grammar of ∑∎
The grammar for the natural deduction system is borrowed from ∑. Compendiously, 
the grammar can be presented as follows, understood as the collection of formal 
rules that exhaustively and exclusively determine what is acceptable as a well-­
formed formula of the system (wff). The symbols from basic set theory (which we 
cover appropriately in a separate chapter) are “∊” for inclusion in a set (which is the 
set of well-formed formulas of ∑∎, WFF(∑∎)). The metalinguistic symbol “” is 
used to represent any wff of the system, not necessarily an atomic variable letter but 
possibly a compound formula.
•	 pi, …, qj, … ∊ WFF(∑∎)
•	 --this is the set of atomic (individual, single) variable letters or atoms which is a 
so-called denumerable or countable set, which means that this set can be put in 
one-to-one correspondence with the set of the natural numbers; the subscripts are 
allowed but not required, up to denumerable infinity.
•	 p, q, …, pi, … ∊ WFF(∑∎)        i ∊ {x: x is a positive integer}
•	 If φ ∊ WFF(∑∎), then ~ φ ∊ WFF(∑∎)
•	 If φ1 ∊ WFF(∑∎) and φ2 ∊ WFF(∑∎), then φ1 ∙ φ2 ∊ WFF(∑∎)
•	 If φ1 ∊ WFF(∑∎) and φ2 ∊ WFF(∑∎), then φ1 ∨ φ2 ∊ WFF(∑∎)
•	 If φ1 ∊ WFF(∑∎) and φ2 ∊ WFF(∑∎), then φ1 ⊃ φ2 ∊ WFF(∑∎)
•	 If φ1 ∊ WFF(∑∎) and φ2 ∊ WFF(∑∎), then φ1 ≡ φ2 ∊ WFF(∑∎)
•	 Noting else is a member of the set WFF(∑∎)
The notational amenities for a formal system for natural deduction like the one 
we will be studying include also informal, metalinguistic expressions from a liber-
ally extracted open-ended fragment of the English enhanced with tokens of the con-
nective symbols we are using in the formal system. The justification lines are 
regarded as metalinguistic. Numerals are used to label each line of the derivation (or 
constructed proof) and justification lines are extended to the right of the formal 
derivation-line: the justification line must provide the name of the derivation rule 
that has been used and the numerals of the lines (or numeral of the line) on which 
the rule was applied to sanction derivation of the current line. Given premises are 
indicated as such (perhaps written as “premise” or “P” or with no indication even) 
and are regarded as self-justifying. Assumed premises or assumptions (also indi-
cated informally in the justification line) are not self-justifying and the act of posit-
ing such a premise incurs a debt that has to be discharged before the proof can be 
considered to have terminated permissibly. Because these expressions are presented 
metalinguistically and, in that sense, informally, the apparent sloppiness in legislat-
ing strict notational restrictions is innocuous.
4  Sentential Logic Languages ∑

179
Rules for ⌜∙⌝: Conjunction and Simplification
The two rules for the dot are intuitively straightforward to justify on the basis of 
expectations about the logical behavior of the connective that matches the logic-­
word “and” of language. The first one allows us to put together two sentences that 
have been both asserted, given to us or posited, as true, by conjoining them; given 
the definition of “and”, the justification is easy to grasp: if two statements are true, 
then the statement constructed by joining them with “and” in between has to be true 
too. This rule is called conjunction. Thus, this is a conjunction or dot-rule – its spe-
cific name being rather unfortunate because this is not, of course, the only rule we 
have for the conjunction. For instance, you are told: “It is raining today.” You are 
also told that “the game is canceled today.” This allows you correctly to derive the 
new sentence, “It is raining today and the game is canceled today.”
Regardless of the matching with the logical behavior of the linguistic “and,” this 
is one of our rules. The derivation or proof (or Natural Deduction) system we are 
constructing stands on its own. Speaking theoretically, the proper way to think of 
such a system is as follows: there are recipe-like rules – which can be presented in 
a figure-like or shape-like fashion and are called schemata (in the plural, with the 
singular word being “schema.”) A rule schema is like a recipe that gives instructions 
about how to proceed; the instructions are to be followed strictly, without any devia-
tion whatsoever. What may seem intuitively obvious is irrelevant and no licenses are 
to be permitted or taken in the application of a rule; the application has to be so that 
the instance you generate in applying the rule can be matched to the shape the rule 
schema dictates. Trying to think of the rules-schemata as shapes is a beneficial first 
step in orienting yourself to the enterprise of constructing proofs in Natural 
Deduction (or in what is also called a proof-theoretic or derivation system.)
The dot will also have another rule, called Simplification, which can be justified by 
appealing to the logical behavior of the logic-word “and” of language. We should 
make it clear, however, that such justificatory appeals do not affect the legitimacy of 
the derivation system which stands on its own. Some other remarks are in order at this 
point. The proof-theoretic or Natural Deduction system is an alternative approach to 
doing logic besides the truth-tabular approach which is called Semantic. The truth 
tables defined the connectives of our standard logic in terms of inputs-­outputs with 
inputs being combinations of truth values from {T, F} and with the output being a 
truth value also from {T, F}. The proof-theoretic approach we are following in this 
chapter, on the other hand, understands the connectives to be definable by means of 
the rules schemata we will be presenting. The two approaches to logic – the proof-
theoretic and the semantic – harmonize completely in the case of the standard senten-
tial logic. Every valid argument form, so checked by the truth-­table method, is 
derivable in the proof-theoretic system as a proof that has as premises the premises of 
the argument form and has as conclusion the conclusion of the argument form. 
(Strictly speaking, we have mappings of the formulas across the two systems and we 
can speak of interpretations of the sentential formulas by means of proof-theoretic 
system formulas and the other way around.) In the opposite direction, for every deriv-
able proof in the proof-theoretic system, we can construct an argument form with the 
4.4  A System of Natural Deduction (Proof Method) for ∑: ∑⊞

180
same premises and conclusion (precisely speaking, interpretations of the premise- 
and conclusion-formulas) and verify by the truth table method that the argument form 
is valid. (Strictly speaking, “interpretation” should be used only we go from the 
proof-theoretic to the semantic direction.) Thus, semantic validity of arguments and 
proof-theoretic derivability match or harmonize fully in the sense we have explained.
We will now represent the schemata we have in our system. We do not make any 
pretense to having independent rules: a rule is independent when it cannot be 
derived from other rules that we have in the system. From the standpoint of elegance 
and for examining certain metalogical characteristics, we would be interested in 
having perhaps as few rules as possible and making sure all our rules are indepen-
dent in the sense that no one of our rules can be derived from the other rules in the 
system. But proofs would be difficult to construct in such a system. When more 
rules are added to the system, proofs become easier to construct.
As a schema (recipe) the rule Conjunction is represented like this. The name of 
this rule is “Conjunction.” Because we prefer to use abbreviations, we show also the 
abbreviated name of the rule: “Conj.”
k. □.
⋮
l. △.
⋮
n. □ ∙ △    Conj(k, l)
This recipe shows that, given the sentences (possibly compound sentences) at 
lines labeled k and l, we may – not necessarily right away – apply the rule for · 
called Conjunction by generating at some subsequent line, n, the formula that joins 
the formulas at k and at l by the dot. We are allowed to introduce the dot, as it were. 
The justification line is written to the right, as “Conj(k, l)”, and it instructs us to 
write metalinguistically that the rule named “conjunction” has been applied to the 
lines labeled by k and l to generate the line labeled by n, in which we have the gener-
ated conjunctive formula.
The order in which the lines are written in the justification does not matter. The 
justification lines are presumed to be written out in our metalanguage which is freed 
from schematic conventions. The top-to-bottom order in which the shapes are written 
does matter, however. Compare the following presentation of the Conjunction schema.
k. △.
⋮
l. □.
⋮
n. △ ∙ □      Conj(k, l)      Conj(l, k)
4  Sentential Logic Languages ∑

181
As we see, the order in which the conjuncts in the generated formula are written 
does not matter.
There are other ways in which the schema can be presented. We show some such 
presentation options.
□, △ /.. □ ∙ △                Conj
□
△
□ ∙ △.
Let us see now examples of substitutions of well-formed formulas for the sche-
matic variables (box and triangle.) The substitutions are of wffs into the schematic 
rule – the recipe. These are instances of application of the rule Conjunction.
1. ~ (p ∨ q) ≡ ~ q
2. (p ⊃ ~ q) ⊃ ~ ~ p
3. (~ (p ∨ q) ≡ ~ q) ∙ ((p ⊃ ~ q) ⊃ ~ ~ p)	 	
Conj(1, 2)
CORRECT.
1. ~ p
2. (s ≡ ~ t) ∨ ~ p
3. ~ p ∙ ((s ≡ ~ t) ∨ ~ p)		
	
	
Conj(1, 2)
	
	
	
	
CORRECT.
1. p ∙ q
2. q
3. p ∙ q	
	
	
Conj(1, 2)
	
	
WRONG!
3. (p ∙ q) ∙ q	
	
Conj(1, 2)
	
	
RIGHT!
1. ~ ~ p
2. ~ p ∙ ~ q
3. ~ ~ p ∙ (~ p ∙ ~ q)	
Conj(1, 2)
	
	
RIGHT!
4. ~ ~ p ∙ ~ p ∙ ~ q	
	
Conj(1, 2)
	
	
WRONG!
1. p
2. p ∙ p	
Conj(1, 1)
The last example requires commentary. Definitely, this should be a derivable 
sequence of lines. We can check on the semantic side, by using the truth table deci-
sion procedure, that the conclusion validly follows from the premise. Therefore, 
under the strict requirement for harmony between the semantic side and the proof-­
theoretic side for the standard sentential logic, this proof should be properly 
4.4  A System of Natural Deduction (Proof Method) for ∑: ∑⊞

182
constructible. Moreover, we can apply our informed intuitions, which, incidentally, 
is supposed to be more readily available to the user of proof-theoretic approaches. 
The derivation of the conclusion line must, therefore, be sanctioned. Can we justify 
that? We can say that we have here an instance of a trivial inference which is a one-
line inference (although the Conj rule requires two lines to be applied): in that case, 
we should write the line label, 1, only once following the name of the justifying rule 
(“Conj.”) Alternatively, we may say that conjoining a line with itself is a plausible 
notion and, so, the triviality of the case consists precisely in joining a line with itself 
(as a degenerate case of joining a line with another line.) There is one more option. 
We can use a rule called “Reiteration” or “Repetition” and use this rule in the proof 
as shown below. In some other variants of natural deduction, a distinction may be 
drawn between a Repetition rule and a Reiteration rule but, for our present purposes 
in the system we are utilizing, we can use the names interchangeably. This rule may 
seem as devoid of deeper logical significance but this is not the case: there are alter-
native, non-standard, logics which can be built by withholding a repetition rule!
1. p
2. p	 	
Rep(1)
2. p ∙ p	
Conj(1, 2)
Next we turn to the other rule for the dot, which is called Simplification and 
symbolized as “--S” or “S--” when we write justification lines in proofs; we will see 
how we determine which name ought to be written. This rule schema has two parts, 
one for Left Simplification (written as “--S”) and one as Right Simplification (writ-
ten as “S--.”) The sub-schemata are presented below. Notice that the left-­
simplification sub-schema allows us to extract – and write as a new line – the left 
conjunct of the formula on which the rule is applied and the right-simplification rule 
permits extraction of the right conjunct.
k. □ ∙ △
⋮
l. □            --S(k)
⋮
n. △          S--(k)
□ ∙ △ /.. □  --S
□ ∙ △ /.. △    S--
□ ∙ △              --S
□
□ ∙ △              --S
△
4  Sentential Logic Languages ∑

183
Examples are now given.
1. ~ (p ∨ ~ (q ∙ ~ r)) ∙ ~ ~ t
2. ~ ~ t	
	
	
	
S--(1)
1. (s ⊃ (t ⊃ s)) ∙ ~ (s ⊃ (s ⊃ t))
2. s ⊃ (t ⊃ s)	 	
	
	
--S(1)
1. p ∙ (q ∙ r)
2. q	 	
	
	
	
--S(1)
	
WRONG!
3. q ∙ r	
	
	
	
S--(1)
4. q	 	
	
	
	
--S(3)
1. p ∙ q
2. p	 	
--S(1)
3. q	 	
S--(1)
4. q ∙ p	
Conj(2, 3)
	
WRONG!
5. p ∙ q	
Conj(2, 3)
1. p ∙ q
2. q	 	
S--(1)
3. p	 	
--S(1)
4. q ∙ p	
Conj(2, 3)
Rules for ⌜⊃⌝: Modus Ponens, Modus Tollens, Hypothetical Syllogism, 
Conditional Proof
The rules for the horseshoe – hence, for material implication – are as given by the 
following schemata. Abbreviated names for the rules are MP for Modus Ponens, 
MT for Modus Tollens and HS for Hypothetical Syllogism.
The material conditional (or material implication) connective of the standard 
sentential logic is unsatisfactory if our purpose is to define a connective that models 
the logical behavior of the linguistic phrase “if-then.” This selection is necessitated 
by the setup of resources that become available when we construct a two-valued 
logical system that has the features of the standard sentential logic – such features 
as compositionality, for instance, which means that the logical meanings, under-
stood as truth values, of the compound formula can be determined precisely and 
uniquely when the truth values of all the constituent atomic variables are given. In a 
logical system like this, there are exactly sixteen mathematically definable binary 
connectives. Our choice of a suitable implication connective would have to be con-
fined to this group of sixteen available connectives since “if-then” connects two 
molecular components (the antecedent and the consequent, as we call them.) Once 
connectives have been selected from the group of sixteen binaries (for instance, the 
inevitable choice of the binary connectives for conjunction, the two types of dis-
junction and equivalence), we have the remaining binary connectives available. 
Many more are eliminated as choices (for instance, the connective with constant or 
fixed output the value true, and the connective with fixed output false.) Moreover, 
4.4  A System of Natural Deduction (Proof Method) for ∑: ∑⊞

184
we have certain expectations about the characteristics of our implication connec-
tive – although, alas, we will not be able to meet all those explanations. Continuing 
with this process, it can be shown that the binary connective that we regard as mate-
rial implication is the most suitable available binary connective. If one were to insist 
that this is indeed, always and of necessity, the conditional or if-then of language, 
that would lead to so-called paralogisms. As we know from the study of the truth-­
tabular definition of the implication connective, a false antecedent, or a true conse-
quent, automatically result in a true conditional statement. In natural language, the 
logical behavior of if-then does not sanction these kinds of implication – called, 
respectively, vacuous (when the antecedent is false) and trivial (when the conse-
quent is true.) Only in certain rhetorical expressions, do we obtain vacuity as a mode 
of logical behavior of the implication. For instance, if one were to say “if you pass 
this course, I am from Mars,” the point that is pressed rhetorically is that the ante-
cedent is false; hence, even if the consequent is so obviously false, still the condi-
tional statement is true! Outside of such specific cases of rhetorical speech, we 
would regard false antecedent (or true consequent) as insufficient to render the con-
ditional statement true. The Natural Deduction system we make available has deri-
vation rules for this paralogistic conditional of the standard sentential logic. We 
should expect, and we will not be disappointed in our expectation, that we will be 
able to make the following derivations in our system once we have all the derivation 
rules we need for this purpose. Reflecting on these sequents – or derivation sequents, 
representing valid argument forms – we discern the paralogistic behavior of our 
conditional. The first sequent derives any consequence from a necessarily false 
premise (a logical contradiction) and the second derives a necessarily true conclu-
sion (a tautology) from any premise whatsoever.
Another marked feature that is missing is a relevant or so-called relevantist con-
nection between the set of premises and the conclusion – since, apparently, there are 
atomic variable letters not shared between the premises-set and the conclusion. You 
should expect a rule for inclusive disjunction, in the following section, to also pres-
ent a standard instance of lack of relevance in the sense we just specified. There are 
non-standard or alternative logics that attempt to define connectives and have deri-
vation rules for such connectives in such a way that relevance is observed.
•	 p ∙ ~ p /.. q
•	 q /.. p ∨ ~ p
•	 ~ p /.. p ⊃ q
•	 q /.. p ⊃ q
We present the derivation rules. When we introduce, in subsequent section, the 
method called Conditional Proof method, we will realize in that case, again, that we 
are basically dealing with a derivation recipe that is based on the features of our 
conditional. We present alternative “shapes” for the rules of the connective symbols; 
we do this to train and facilitate discernment.
4  Sentential Logic Languages ∑

185
k. □ ⊃ △
⋮
l. □
⋮
n. △        MP(k, l)
Modus Ponens.
□ ⊃ △, □ /.. △              MP
Modus Tollens.
k. □ ⊃ △
⋮
l. ~ △
⋮
n. ~ □      MT(k, l)
□ ⊃ △, ~ △ /.. ~ □          MP
□ ⊃ △
□           MP
△
□ ⊃ △
~ △        MT
  ~ □
Hypothetical Syllogism.
k. □ ⊃ △
⋮
l. △ ⊃ ○
⋮
n. □ ⊃ ○    HS(k, l)
4.4  A System of Natural Deduction (Proof Method) for ∑: ∑⊞

186
□ ⊃ △.
△ ⊃ ○	
	
HS
□ ⊃ ○.
□ ⊃ △, △ ⊃ ○ /.. □ ⊃ ○          HS
Examples of applications of these rules are given below.
	1.	 ~ (p ≡ q) ⊃ ~ (q ∨ ~ r)
	2.	 ~ (p ≡ q)
	3.	 ~ (q ∨ ~ r)	
	
	
MP(1, 2)
	1.	 (p ∙ (q ∨ r)) ⊃ ~ t
	2.	 t
	3.	 ~ (p ∙ (q ∨ r))	 	
	
WRONG!
We need ⌜~ ~ t⌝ to derive ⌜~ (p ∙ (q ∨ r))⌝.
	1.	 ~ ~ (p ∨ ~ p) ⊃ (r ∙ t)
	2.	 p ∨ ~ p
	3.	 r ∙ t	 	
	
	
WRONG!
We need ⌜p ∨ ~ p⌝ to derive ⌜r ∙ t⌝.
	1.	 (w ⊃ ~ (w ⊃ u)) ⊃ ~ (w ⊃ u)
	2.	 ~ (w ⊃ u) ⊃ u
	3.	 (w ⊃ ~ (w ⊃ u)) ⊃ u	
	
	
HS(1, 2)
	1.	 p ⊃ (q ⊃ (p ⊃ ~ q))	
	
	
P1
	2.	 ~ q	 	
	
	
	
P2
	3.	 (q ⊃ (p ⊃ ~ q)) ⊃ q	
	
	
P3
	4.	 p ⊃ q		
	
	
	
HS(1, 3)
	5.	 ~ p	 	
	
	
	
MT(2, 4)
An Additional Rule for ⌜⊃⌝: Conditional Proof Method
A proof-theoretic method that is a staple of textbook presentations is called 
Conditional Proof and it is fundamentally a schema for the implication connec-
tive. This is actually the basic rule schema that is available for introducing the 
horseshoe in the sense that the final line sanctioned by application of this sche-
matic rule is covered by a formula in which the horseshoe appears for the first 
time (in the schema) and it appears as the main connective symbol. Executing 
4  Sentential Logic Languages ∑

187
this rule compels us to posit an assumed premise φ; by using this and other lines 
we have available (initially as given premises), we proceed to derive ψ. At that 
point we may discharge the assumed premise φ (which means that we have paid 
our debt for the assumption, to speak metaphorically) but, to do this, we are con-
strained to make one specific move: we introduce φ ⊃ ψ as the next line; this 
discharges the assumed premise and, indeed, the proof cannot be terminated 
without effecting such a discharge since the assumed premise φ was not given to 
us but we only posited it on our own. We can appeal to linguistic practice to jus-
tify this rule: if under the assumption that φ we can prove validly that ψ, with the 
proof process completed and with every line of the proof justified properly, so 
that the proof retains truth across all the lines, then we have proven that “if φ, 
then ψ” is a logical truth or tautology (and, as such, can be asserted.) This works 
out neatly in the case of the standard sentential logic we have been studying: we 
can say, using a common term in the bibliography, that the standard sentential 
logic is characterized by the Deduction Theorem (using “⇒” as metalinguistic 
symbol for “---a valid proof process proves___”):
•	 Deduction Theorem:	
 If φ ⇒ ψ, then ⇒ φ ⊃ ψ (or φ ⊃ ψ is a tautology)
At a deeper level, there is a contentious point raised that this schematic rule 
shows us what the meaning of “if-then” is: according to this view, the way in 
which implication can be introduced properly, and is in practice warranted and 
accepted in speech, as a result of positing a premise and then “collecting” it 
establishes the meaning of “if-then.” Contrast this with the fact that, in an earlier 
section, we defined the implication connective by using the truth table: that is 
the semantic way of defining the meaning of an implication connective whereas 
what we have done in this section is the proof-theoretic approach to the 
definition.
It should be kept in mind that not all logical systems or formal languages have 
the Deduction Theorem as characteristic or valid in them but our standard sentential 
logic has it. Dealing with Conditional Proof (CP), we have introduced a new notion: 
positing an assumed premise that needs to be discharged. We defer further examina-
tion of this procedural resource to 4.7.d because we will need it in the context of 
discussing a rule for the wedge as well. Positing and discharging assumptions will 
also appear in 4.7.e when the rules for the tilde are presented.
Rules for ⌜∨⌝: Disjunctive Syllogism, Addition, Constructive Dilemma
The three rules for the wedge are Disjunctive Syllogism, abbreviated as DS (with 
two sub-schemata, −-DS and DS--), Addition (Add, with two sub-schemata, −-Add 
and Add--) and Constructive Dilemma (CD.) The abundance of rules, including rule 
sub-schemata, has the purpose of making proofs easier to construct.
4.4  A System of Natural Deduction (Proof Method) for ∑: ∑⊞

188
Disjunctive Syllogism.
   k. □ ∨ △
   ⋮
    l. ~ □
   ⋮
n. △      DS--(k, l)
   ⋮
    q. ~ △.
    ⋮
             u. □    --    DS(k, q)
□ ∨ △.
~ □	 	
--DS
△
□ ∨ △.
~ △	 	
DS--
□
□ ∨ △, ~ □ /.. △      DS--
□ ∨ △, ~ △ /.. □       --DS
Depending on whether we seek to obtain the right or left disjunct, by application 
of Disjunctive Syllogism, we need to execute, respectively, the right (DS--) or left 
DS (−-DS) rule. Similar remarks apply for the Addition-rule: the left sub-schema 
permits introduction of disjunct to the left of the given formula and the right sub-­
schema permits introduction of disjunct to the right of the given formula.
Addition.
k. □
⋮
l. △ ∨ □     --Add(k)
⋮
n. □ ∨ △      Add--(k)
□ /.. △ ∨ □          --Add
□ /.. □ ∨ △          Add--
4  Sentential Logic Languages ∑

189
□ ∨ △
□ ⊃ ○
△ ⊃ ◊      CD
○ ∨ ◊
Examples of applications of these rules are given below.
	
1.	 ~ (w ⊃ (q ⊃ (u ∨ v)))
	
2.	 ~ (w ⊃ (q ⊃ (u ∨ v))) ∨ (p ≡ ~ (p ≡ q))        Add(1)
	
1.	 r ∨ (r ⊃ t)    P
	
2.	 r ⊃ t           P
	
3.	 (r ⊃ t) ⊃ q   P
	
4.	 t ∨ q                            CD(1, 2, 3)
	
1.	 (r ⊃ (r ∨ t)) ∨ w	
	
  P1
	
2.	 r ∨ s	
	
	
  P2
	
3.	 ~ s	
	
	
  P3
	
4.	 ~ w	
	
	
  P4
	
5.	 w ⊃ (r ∨ t)	
	
  P5/..(r ∨ t) ∨ w
	
6.	 r			
	
	
  DS(2, 3)
	
7.	 r ⊃ (r ∨ t)		
	
  DS(1, 4)
	
8.	 r ∨ t	
	
	
  MP(6, 7)
	
9.	 r ∨ t	
	
	
  CD(5, 7, 8)
	 10.	 (r ∨ t) ∨ w	
	
  Add(9)
                      □          --Add
                      △ ∨ □.
Constructive Dilemma.
k. □ ∨ △
⋮
l. □ ⊃ ○
⋮
m. △ ⊃ ◊.
⋮
○ ∨ ◊        CD(k, l, m)
□ ∨ △, □ ⊃ ○, △ ⊃ ◊ /.. ○ ∨ ◊            CD
4.4  A System of Natural Deduction (Proof Method) for ∑: ∑∎

190
Incurring and Discharging Assumptions: CD+ and CP
Now we present two proof methods that proceed in a different fashion from what we 
have presented so far. The schema for the first derivation method is called CD+ and 
is different in its operational details from CD. The CD+ method, unlike CD, requests 
that premises are posited or incurred, as we say. A posited premise can also be called 
assumption – if we agree that the word “assumption” is not also to be used to refer 
to a premise that is given. The difference between given premises and posited prem-
ises/assumptions is clear: given premises do not need to be justified, they are con-
sidered as self-justifying, they may be used in the course of the proof and the proof 
can terminate without any further moves that are related to the given premises. 
Incurred or posited premises, on the other hand, are not given and, so, they do not 
provide an automatic justification that backs them up. Posited assumptions are 
available to use but, because no sanction or justification has been given for them, the 
proof cannot terminate without first executing certain required actions regarding 
those posited premises; such actions have, then, to be included in the schema as 
well. For the proof to terminate, when we have incurred or posited premises, we 
have first to discharge those premises. The schema, accordingly, shows how we can 
discharge the posited premise or premise so that we can terminate the proof (or 
subproof, segment of the proof that is carried out based on the rule.) Imagination is 
not required; the schematic shapes show us how the discharge is accomplished. Let 
us, first, consider and briefly discuss the CD+ schema. The posited premises receive 
a superscript “minus” next to their characterizing number and, once the discharge of 
such a premise has been attained, we repeat the premise and number with a super-
script of “zero”. These lines are metalinguistic and are written from top-down as 
justification lines. The premises that are given do not need superscripted minuses 
because they are self-justifying; nor do they need discharge (replacement of the 
minus superscript by the zero superscript.)
k. □ ∨ △          k
⋮
l. □                 l⎺
⋮
m. △                m⎺
⋮
n. □ ⊃ ◊.
⋮
o. △ ⊃ ○.
⋮
x. ◊ ∨ ○            CD(k, l0, m0, n, o)
4  Sentential Logic Languages ∑

191
The procedure is as follows: given an inclusive disjunction as premise, we posit 
the disjuncts of the given premise: each disjunct is incurred as a posited premise, as 
a debt or charge we are carrying, and its justification line receives the characteristic 
minus-superscript. If we can successfully derive lines in which the disjuncts are 
antecedents of conditional formulas, then we can apply our rule CD+ to derive the 
inclusive-disjunctive formula of the consequents of the two conditional lines. The 
application of the rule to derive this final line discharges all the debts we have 
incurred for positing the two posited premises. This is a discharging rule, in other 
words. What the medieval logicians called “arguing by cases” is represented in this 
rule. If we are given that “either X or Y” and can prove, by provisionally assuming 
X and Y, that X implies Z and Y implies W, then we can derive the inclusive disjunc-
tion of Z and W and the premises we posited can be justifiably discharged.
	1.	 (p ⊃ q) ∨ (p ⊃ ~ q)	
	
P1
	2.	 p	
	
	
	
P2/.. q ∨ ~ q
	3.	 p ⊃ q		
	
	
3⎺
	4.	 p ⊃ ~ q	
	
	
4⎺
	5.	 q	
	
	
	
MP(2, 3)
	6.	 ~ q	 	
	
	
MP(2, 4)
	7.	 q ∨ ~ q	
	
	
CD0(1, 30, 40, 5, 6)
The second type of proof method that utilizes in its schematics assumed premises 
(which have to be discharged before termination of the proof) is called Conditional 
Proof (CP) and it is a staple of textbooks of sentential logic. (One remaining method 
with assumed and discharged assumptions will be called Indirect Proof and that 
method is related to the rules for the negation connective.) To execute a conditional 
proof, or perhaps a subproof or segment of an encompassing proof, we posit any 
formula φ, with the superscript minus, as before, attached to the number of the 
assumed premise when we write the justification line. Insofar as we may derive any 
formula ψ so that our posited premise φ is the only one premise that is used and not 
given, then we can derive a conclusion ψ and discharge φ by writing ⌜φ ⊃ ψ⌝. It 
might appear that this method can be used only when other, given, premises are also 
available but note an example of a derivation below, in which there are no other 
premises besides the posited premise. We can think of Conditional Proof as related 
to the conditional connective and can be thought of as a license for introducing the 
connective symbol (the horseshoe). There is a philosophic significance we may 
attach to this approach: arguably, linguistic usage works in such a way that to extract 
the meaning of the logical “if-then” phrase, this is what we need to do: posit an 
assumption φ provisionally (which is to be warranted or accepted as true but only 
posited or granted as a debt, so to speak); if we can then derive a conclusion ψ using 
our posited premise as the only unwarranted provisional premise, we must have 
license to state – not φ but – “if φ, then ψ.” The essential point is that this is the way 
the meaning of “if-then” is defined. Philosophically, a school of thought contends 
that definitions of logical connectives are forthcoming in this way – by means of 
how a connective’s introduction would be accepted – and not in the semantic method 
which models definitions in terms of true and false (like the truth table we used in 
4.4  A System of Natural Deduction (Proof Method) for ∑: ∑∎

192
preceding section to define connectives.) We might now seek the schema that can be 
understood as the elimination schema for the conditional connective: if we think 
about this, Modus Ponens, which we introduced earlier as a rule schema for the 
conditional, fits that role: given the conditional “if φ, then ψ” and also given that φ, 
we have license to conclude that ψ. Thus, the conditional, which we find in one of 
the premises, is eliminated.
The Constructive Dilemma schema may be thought, similarly, as elimination of 
the inclusive disjunction connective while Addition is the schema for the introduc-
tion of the inclusive disjunction connective. We could have constructed a minimalist 
system – with no rules that can be derived from other rules – and so that the rules 
are introduction and elimination rules: such a system would be more difficult to use 
for constructing proofs but it clearly has theoretical significance and it would also 
show us how we may construct our standard sentential logic as distinguished from 
other logics (some of which can prove less than our standard logic can prove): alter-
native logics would differ in the rules they have from the standard logic. (For such 
a system see 4.7.4.a).
Next, we present the schema for the conditional proof (CP) rule. This rule also 
works with positing an assumed premise, which means that we incur a debt, if we 
may use such a metaphor; the application of the rule CP discharges the debt – dis-
charges the assumed or posited premise – and this makes it possible that the proof 
can be terminated (not necessarily right away.)
k. □                k ⎺
⋮
l. △                (… k ⎺ …)
m. □ ⊃ △            CP(k0 – m-1)
We may posit assumptions at any point in a proof but the termination of the proof 
depends strictly on discharging those posited assumptions. Note how the justifica-
tion line that discharges the incurred charge, by reverting the superscript to zero, is 
written as follows: the rule CP is applied on the lines from the line of the posited 
premise to the line immediately preceding the line after which the discharge is pos-
sible. We stipulate that the discharges happen in a reverse order from that in which 
they were introduced. We show this schematically as follows:
k. □        k ⎺
⋮
l. △        l⎺
⋮
(continued)
4  Sentential Logic Languages ∑

193
Another rule that is usually unstated but applied nevertheless is that we may 
repeat any line a second time – and a third time and so on. We can call this rule 
Repetition (Rep) or Reiteration (Reit). Application of this rule is not needed usually 
but let us consider a proof like the first one shown below which depends on the 
Repetition rule and also utilizes conditional proof (and, interestingly, does not uti-
lize any given, but only posited, premises.)
	1.	 p 	
	
1 ⎺
	2.	 q	
	
2 ⎺
	3.	 p	
	
Rep(1)
	4.	 q ⊃ p		
CP(20–3)
	5.	 p ⊃ (q ⊃ p)	
CP(10–4)
We may think now together of CD+ and CP and discern how there is a way of 
combining the two in appropriate fashion, as shown in the following derivation 
schema that can be considered as an optional alternative to the CD+ schema we 
presented earlier. Accordingly, this alternative schema requires a different labeling 
and, to observe this, we call it “CD+cp.” It is intellectually rewarding to try to justify 
this alternative schema which will require appealing both to the original CD+ 
and to CP.
m. ○.
⋮
n. ◊.
o. △ ⊃ ○            CP (l0 – n)
⋮
x. □ ⊃ ◊              CD(k0 – m)
(continued)
k. □ ∨ △              k
⋮
l. □                  l⎺
⋮
m. △                  m⎺
⋮
n. ◊                     (…, l ⎺, …)
⋮
o. ○                     (…, m ⎺,…)
⋮
x. ◊ ∨ ○                 CD+cp(k, l0, m0, n, o)
4.4  A System of Natural Deduction (Proof Method) for ∑: ∑∎

194
We may show the dependence of CD+cp on both CD+ and CP by means of the 
following analytical breakdown that shows deployment of both of those rule sche-
mata. A difference we discern when we spell out the analytical presentation of the 
schema below is that the latest method discharges the posited premises by using the 
CP rule essentially.
k. □ ∨ △             k
⋮
l. □                l⎺
⋮
m. △              m⎺
⋮
n. ◊                 (…, k ⎺,…)
⋮
o. ○                 (…, l ⎺,…)
⋮
w. □ ⊃ ◊             (k0 – w-1)
⋮
u. △ ⊃ ○            (l0 – u-1)
⋮
x. ◊ ∨ ○              
  CD(k, l, m, n, o)
Applicability of the rule Rep comes to light in the following derivation of a thesis 
of the standard sentential logic. In this case we derive a thesis (which matches a 
necessary truth or tautology formula if we move over to the truth table system and 
“translate” our formula there, so we can check by applying the truth table method.) 
The thesis can be called self-implication. We need to depend on a posited premise 
and this premise needs to be discharged appropriately by application of the CP rule, 
as we show below. Without a rule for reiteration of a line-formula, like Rep, we 
would have to make a different stipulation: we would have to allow the CP rule to 
discharge in a fashion we may call “degenerate” (no moral connotations, of course), 
so that given any formula we can then treat it as a zero-lines CP-derivation. A rule 
like Rep is not trivial from a broader metalogical point of view because there are 
alternative, non-standards, logics whose derivation systems can be obtained by 
tweaking a system like the one we have here so that the Rep rule is banned explicitly.
	1.	 p         1−
	2.	 p       Rep(1)
	3.	 p ⊃ p  CP(10–2)
4  Sentential Logic Languages ∑

195
We present another example next.
	 1.	 p ∨ ~ p       
 P1
	 2.	 p ⊃ q       P2
	 3.	 q ⊃ (p ⊃ q)  P3/.. ~ p ∨ q
	 4.	 p ⊃ (p ⊃ q)  HS(2, 3)
	 5.	 ~ p          5 ⎺
	 6.	 p          6 ⎺
	 7.	 q          MP(2, 6)
	 8.	 ~ p          Rep(5)
	 9.	 ~ p ⊃ ~ p      CP(50–8)
	10.	 p ⊃ q         CP(60–7)
	11.	 ~ p ∨ q       CD+cp(1, 9, 10)
Rules for ⌜~⌝: Indirect Proof Method (IP) and Double Negation (DN)
The negation rules include yet another schema that utilizes posited premises that 
need to be discharged before the derivation process can terminate. The discharging 
method is called Indirect Proof (IP) – also called Proof by Contradiction. We posit 
a premise φ and derive a contradiction of the general form ψ ∙ ~ ψ with φ as the only 
premise that is not given but posited: we have license, then, to derive ~ φ while 
discharging φ. This is a tremendously powerful proof method; forfeiting it or disal-
lowing its use would result in being left with less than half of our mathematics 
results. There are philosophic objections to this proof method but we will not dis-
cuss those here. The proof may be applied on a negated premise, ~ φ. In that case, 
derivation of a contradiction licenses derivation of ~ ~ φ and discharge of the pos-
ited assumption φ. Notably, we do not yet have a rule that permits deriving φ from 
~ ~ φ. Such a rule is needed and it will be part of our system. We can think of this 
rule as our rule for elimination of the tilde while the indirect proof schema can be 
thought of as our rule schema for introduction of the tilde. The use of a schema for 
removal of the double negation (DN) as our negation-elimination schema breaks a 
certain subtle symmetry between introduction and elimination rules for the negation 
symbol – something that does not happen with the introduction and elimination 
rules for the conditional and for the disjunction connective. Alternatively, we could 
label this as the double-negation elimination rule. That would not change anything 
regarding the metatheoretical significance of adding this rule. A logic that does not 
have this rule, although it has all the other rules we have presented, would be a dif-
ferent logic from the standard system we are studying. This, of course, applies gen-
erally for omitting rules that are indispensable for characterization of the logic but 
the ado about this specific mention is that there is a popular alternative logic, called 
Intuitionist or Intuitionistic, which lacks the double negation elimination rule. To 
ascend from that logic to our standard logic we can add the rule for eliminating the 
double tilde symbol; there are other ways, additions of other “classical” rules, that 
can also obtain the same result. It is interesting that, up to the point of discussing the 
4.4  A System of Natural Deduction (Proof Method) for ∑: ∑∎

196
negation rules, the natural deduction setup we have constructed would not allow us 
to differentiate between the classical and the intuitionistic logic, but, as soon as we 
arrive at the negation rules, we have the opportunity of stopping short of allowing 
for the double negation elimination rule and in this way we have drawn the line 
around what is a system for intuitionistic logic. We will not dwell on this matter 
further here but we mention in passing that, remarkably, if we withhold the rule for 
removal of the double negation – while keeping all the other introduction and elimi-
nation rules – we have a different logic, not the standard sentential logic but an 
alternative and non-standard logic called Intuitionistic Logic.
It is also crucial to underscore that the rule for the elimination of double negation 
has a feature that we have not seen yet in any rule: it works in both directions, so to 
speak. From ~ ~ φ we may derive φ but also, conversely, from φ we can derive ~ ~ 
φ. Conversion – deriving ψ ⊃ φ from φ ⊃ ψ is illegitimate or invalid but in cases in 
which two formulas φ and ψ are logically equivalent, φ and ψ are mutually inter-
derivable. We learned about equivalence as a relation between sentential formulas 
and, upon examining that relation, we noted that two mutually equivalent formulas 
imply each other. Rule schemata like Double Negation are Equivalence Schemata 
(also called Equivalential Schemata and, for a reason that will become clear soon, 
Replacement Schemata.) Thus, we are building now a bridge to the next family of 
derivation rules schemata, which are replacement schemata: such schemata not only 
work in both derivational directions, as we explained, but also allow us to replace 
any part of a formula in a proof line by its equivalent formula.
k. □                 k ⎺
⋮
l. ◊ ∙ ~ ◊.
m. ~ □              IP(k0 – l)
=======================.
k. ~ □                k ⎺
⋮
l. ◊ ∙ ~ ◊.
m. ~ ~ □              IP(k0 – l)
========================.
k. ~ ~ □.
⋮
l. □                   DN(k)
Here is a remarkable proof that derives the conclusion of the formula that 
expresses the fundamental law of excluded middle (that any sentential variable may 
take either true or false as its truth value.) Note its dependence on IP, Add, and also 
4  Sentential Logic Languages ∑

197
on DN. A logical system that lacks DN cannot derive this conclusion but this may 
actually be desirable insofar as the philosophic motivation for such an alternative 
system may be rejecting excluded middle.
(For example, suppose that you regard not-φ as meaning “there is no proof that 
assuming φ implies a contradiction – for some appropriate sense of “implies.”” This 
is a different meaning of “not” from the standard one that is modeled in our truth-­
table definition of the negation connective. In such a case, not-not-φ should not 
license an inference to φ. It might be the case that we have a proof that not-φ leads 
to a contradiction but that does not mean that we have proof of φ itself. Absence of 
the double negation rule blocks the inference to φ or not-φ, but let see how this too 
is desirable on the basis of a motivation that regards φ as a matter of proof-that- φ 
and not-φ as a matter of proof that a contradiction can be derived from φ: φ-or-not- 
φ means, on this approach, that either a proof of φ or a proof of not-φ (in the sense 
we specified above) is always available – or should be considered as in-principle 
available) for any φ. This, however, may not be the case! Suddenly, it seems sensi-
ble that we would want excluded middle – taking φ-or-not-φ to be a logical truth – 
to be failing! This is so if we take truth and falsehood to be rightly dependable on 
available proof-constructions in the sense we explained above.)
	1.	 ~ (p ∨ ~ p)	
	
	
1 ⎺
	2.	 p	
	
	
	
2 ⎺
	3.	 p ∨ ~ p	
	
	
Add(2)
	4.	 ~ (p ∨ ~ p) ∙ (p ∨ ~ p)	 	
Conj(1, 3)
	5.	 ~ p	 	
	
	
IP(20 - 4)
	6.	 p ∨ ~ p	
	
	
Add(5)
	7.	 ~ (p ∨ ~ p) ∙ (p ∨ ~ p)	 	
Conj(1, 6)
	8.	 ~ ~ (p ∨ ~ p)	 	
IP(10–7)
	9.	 p ∨ ~ p	
	
DN(8)
Replacement (Two-Directional, Equivalence, Equivalential) Rules
The following collection of rule schemata have certain extraordinary characteristics 
that facilitate proof procedures considerably: these rules permit derivation in both 
directions – in contrast to rules we have examined so far, which only permit one-­
directional derivation, as we have seen. The two sides to the rule schema, each 
permitting derivation of the other side, show an equivalence relation between the 
two parts: if we were to apply our familiar truth table method and check the (transla-
tions of the formulas into a truth table symbolic system), then we would find always 
that the two formulas are equivalent to each other: therefore, they also imply each 
other. Alternatively, if we placed between those formulas the triple bar symbol and 
checked by the truth table method the resulting equivalential formula, that formula 
would always be determined to be a tautology of the sentential logic. Because of 
this equivalential relation, we have a remarkable amenity made available to us: 
these rules permit replacement of any segment of a well-formed formula on any line 
of the derivation by its equivalent (as found on the other side of the rule schema). 
4.4  A System of Natural Deduction (Proof Method) for ∑: ∑∎

198
This is because the standard sentential logic we are studying is characterized by a 
law, which is called the Law of Extensionality (or Principle of Extensionality or 
Leibniz’s Law or Law of the Inter-Substitutivity of Equivalents.) We can present 
this law in our metalanguage using the symbols “⊢” and “⊣” to indicate valid infer-
ence (to the right and to the left, respectively, and, in cases of equivalence, in both 
directions using the symbol “⊣⊢”). Note how we may express this law in more than 
one ways, all of which state the same law of course. When there are no formulas as 
premises to the left of the symbol (called turnstile), that means that the formula to 
the right is derivable even without premises! This, in fact, tells us that the formula 
to the right is a tautology (no premises are needed for it to be derived…)
•	 Law of Extensionality
•	 φ (… ψ …) ⊣⊢ φ(… χ …) if and only if ψ ⊣⊢ χ
•	 φ (… ψ …) ⊣⊢ φ(… χ …) if and only if ⊢ ψ ≡ χ
We show examples of how we may use replacement rules before we present all 
the replacement rules schemata themselves. One of those schemata, called Double 
Negation (DN), is presented schematically, to begin with. In this case, we will be 
using the metalinguistic symbol “⇌” to indicate that the derivability license pro-
ceeds in both directions (we may derive what is to the right from what is to the left 
and what is to the left from what is to the right of the symbol.) We show instances 
of applications of the respective derivation-rules schemata.
•	 ~ ~ □ ⇌ □
•	 1. ~ ~ (p ≡ ~ q)
•	 2. p ≡ q                  DN(1)
•	 3. ~ ~ (p ≡ q)              DN(2)
•	 1. (t ∨ u) ⊃ ~ ~ q
•	 2. (t ∨ u) ⊃ q                DN(1)
•	 3. ~ ~ (t ∨ u) ⊃ q             DN(2)
•	 4. ~ ~ (t ∨ u) ⊃ ~ ~ q        DN(3)
•	 5. (t ∨ u) ⊃ ~ ~ ~ ~ q        DN(1)
•	 6. (t ∨ u) ⊃ ~ ~ q           DN(5)
There is redundancy in our collection of replacement schemata: many are not 
independent, which means that they we can derive them by using other rules which 
we have in our system. Proofs become facilitated when more rules, including redun-
dant rules, are made available. We now present the derivation schemata of the equiv-
alence or replacement rules. We give more than one names for some of the rules, 
considering that such alternative names appear in the relevant literature. We indicate 
in each case the abbreviator label by which we can refer to the rule schema when we 
write the justification lines of derivations. The metalinguistic symbol “⊣⊢” indi-
cates that the schematic application may proceed in either one of the two possible 
directions. This symbol is called “double turnstile” and, if used metalinguistically, 
to indicate logical consequence (what conclusions follow from what collections of 
premises), it shows instances of correct derivation in our formal system. Another 
4  Sentential Logic Languages ∑

199
metalinguistic symbol we have made available to indicate the two-ways directional-
ity of the equivalence rules schemata is “⇌”.
•	
~ ~ □ ⊣⊢ □                      Double Negation (Double Negation  
Elimination)                           
DN
•	
□ ∨ ◊ ⊣⊢ ◊ ∨ □               Commutation(∨) (Commutativity(∨))        Comm(∨)
•	
□ ∙ ◊ ⊣⊢ ◊ ∙ □                 Commutation(∙) (Commutativity(∙))         Comm(∙)
•	
□ ∨ (◊ ∨ △) ⊣⊢ (□ ∨) ◊ ∨△  Association(∨) (Associativity(∨))            Assoc(∨)
•	
□ ∙ (◊ ∙ △) ⊣⊢ (□ ∙ ◊) ∙ △     Association(∙) (Associativity(∙))          Assoc(∙)
•	
□ ∨ ◊ ∙ △ ⊣⊢ □ ∨ ◊ ∙ □ ∨ △    Distribution(∨/∙) (Distributivity(∨/∙))       Distr(∨/∙)
•	
□ ∙ ◊ ∨ △ ⊣⊢ □ ∙ ◊ ∨ □ ∙ △  Distribution(∙/∨) (Distributivity(∙/∨))       Distr(∙/∨)
•	
~ (□ ∨ ◊) ⊣⊢ ~ □ ∙ ~ ◊        DeMorgan Laws(~/∨) (Distribution(~/∨))  DeM(~/∨)
•	
~ (□ ∨ ◊) ⊣⊢ ~ □ ∙ ~ ◊        DeMorgan Laws(~/∙) (Distribution(~/∙))   DeM(~/∙)
•	
□ ∨ □ ⊣⊢ □                  Idempotence(∨) (Tautology)              Idemp(∨)
•	
□ ∙ □ ⊣⊢ □                   Idempotence(∙) (Tautology)               Idemp(∙)
•	
□ ⊃ ◊ ⊣⊢ ~ □ ∨ ◊               Material Implication, Conditional  
Exchange                              
CE
•	
□ ⊃ (◊ ⊃ △)⊣⊢ (□ ∙ ◊) ⊃△     Importation-Exportation                 Import- 
Export
•	
□ ≡ ◊ ⊣⊢ (□ ⊃ ◊) ∙ (◊ ⊃ □)   Material Equivalence, Material  
Biconditional                            
Equiv  
ME
By means of examples, we will see, next, how we can derive propounded conclu-
sions from given premises by applying our derivation rules as needed. It should be 
pointed out that the requested conclusion may be derivable from the given premises 
in more than one way – by means of application of different combinations of rules 
and/or different sequential orders for the application of rules. We do not insist on 
placing a premium on shorter proof sequences. It should also be the case that there 
are no redundant premises – no given premises that, in the end, are not needed for 
the construction of the proof – but textbook examples and exercises may actually 
violate such a restriction. Another issue to mention, again, is that our rules are not 
necessarily independent: this means that it might be possible to derive an instance 
of what is an application of one of our rules by using other given rules in our system: 
notice that this means that we do not really need this rule, we can dispense with this 
non-independent or derivable rule. Nevertheless, proofs are easier to construct when 
we have an abundance, and, indeed, redundancy of rules.
Surely, the following ought to be derivable – or, a proof sequence ought to be 
constructible for the following trivial derivation. Any sentence ought to entail itself, 
trivially. Our system should allow us to effectuate this derivation. We do not want to 
make the case metalinguistically; we rather expect to be able to derive the indicated 
conclusion from the premise, which happens to be the same as the conclusion. The 
rule we have called Reiteration or Repetition is needed here. Since we have this 
rule, we may apply it on the assumption-line, and the second that is immediately 
yielded furnishes us the requested conclusion. The justification lines are presumed 
4.4  A System of Natural Deduction (Proof Method) for ∑: ∑∎

200
written in our metalanguage; we can enhance with symbols, and we may use “⊣” 
(converse turnstile) as our appointed symbol that indicate successful termination of 
the proof.
•	 p ⊢ p
	
1.	 p  P/.. p
	
2.	 p  Reit (1)	⊣
The apparent difficulty with the following proof sequence consists in that we 
need to discern the relevance of applying two rules that are elusive, not easy to think 
of applying, for the beginner: the Import-Export rules and, in some step in the proof 
construction, the Hypothetical Syllogism (HS) rule. Commencing with this proof, 
with no specific strategy available to assist us, we may think of what rule we can 
possibly implement to initiate an opening move (generation of a new line that can 
be justified from the given lines and by appealing to one of the rules.) Because there 
seems to be no other available move, we might actually be helped in this case: since 
we have conjunctions as antecedents, the rule that we may find applicable as we 
scan the available rules is the Import-Export rule: we can apply this rule twice, 
which we do before we search for some other opportunity for subsequent applica-
tion of one of our rules. This seems to be tantamount to searching in the dark but this 
is not an accurate characterization of what we do. The example does, however, 
underscore that practice is indispensable when working with this proof method: pat-
terns become more readily discernable, mere experimentation with applications 
recedes, after we have practiced derivations assiduously. Interestingly, in this exam-
ple, a strategy we will learn subsequently  – about how to reverse-engineer the 
proof – does not appear to be working.
•	 (p ∙ w) ⊃ t, (t ∙ q) ⊃ r, p ⊢ (w ∙ q) ⊃ r
	
1.	 (p ∙ w) ⊃ t     P
	
2.	 (t ∙ q) ⊃ r      P
	
3.	 p           P/.. (w ∙ q) ⊃ r
	
4.	 p ⊃ (w ⊃ t)  Import-Export (1)
	
5.	 t ⊃ (q ⊃ r)      Import-Export(2)
	
6.	 w ⊃ t         MP(3, 4)
	
7.	 w ⊃ (q ⊃ r)  HS(5, 6)
	
8.	 (w ∙ q) ⊃ r     Import-Export(7)	
	
⊣
The following derivation seems to be requesting something odd. An analysis 
shows that the single provided premise translates into our proof-theoretical system 
a tautology of sentential logic (as we can ascertain or verify by using the truth table 
method.) But from a tautology we should be able to derive validly only another 
tautology. Indeed, the requested conclusion is also – translated into a semantic or 
truth-tabular system – tautologous. We examine an example like this to illustrate 
that our method is schematic, not concerned with evaluations but restricted with 
abandon to the application of rules; also, we are interested in the power of our proof-­
method: this method is guaranteed to be missing no rule that would be needed to 
4  Sentential Logic Languages ∑

201
execute a proof-sequence that corresponds to a valid argument form. In other words, 
there is no validly derivable conclusion from given premises, which cannot be 
derived by using our rules. It is interesting to note how we may carry out a deriva-
tion like the one below. If we include the Indirect Proof Method (IP) in our system, 
as we have done, the derivation is actually rather uncomplicated. A lesson in this is 
that IP tends to produce derivations that are apparently easier to construct and it also 
seems to be readily applicable for the solution of derivation tasks that seem extraor-
dinarily difficult. In this case, the premises are not even used! We might actually 
wonder about how such a method, almost appearing as a cheating act, can be justi-
fied in a deeper sense. The fact of the matter of the matter is that there are philo-
sophic objections to the use of the IP method, but such objections are raised by a 
specific school of thought in mathematics, known as Mathematical Intuitionism. 
That school has its own version of Indirect Proof but this rule that we have learned 
is considered inapplicable. Such an objection is not arbitrary. There is something 
non-constructive about the indirect method: rather than show that we can provide 
the mathematical items that are needed step by step, instead we sidestep that. We 
can think of this in the following way: although in sentential logic, we don’ t have 
symbols for denotation of objects, think of the following principle and how it goes 
together with our Indirect Proof Method: any object you can stipulate, you may 
accept it as existing if your stipulation does not lead to an absurdity. If you reject 
this permissive way of thinking about availability of mathematical objects, you see 
Indirect Proof as a wrong rule to have. But if there is a system that does not contain 
as valid this Indirect Proof method, that has to be a system of an alternative logic – it 
cannot be a system or idiom of our standard sentential logic. The definition of the 
connective negation in such an alternative system has to be different (and the same 
is the case for the inclusive disjunction connective.) The derivation rules for nega-
tion in that system would have to be different: indeed, you would not be able to 
guess this but the Double Negation Elimination rule is not valid in a Mathematical-­
Intuitionistic system (for which our Indirect Proof is invalid too.) Mathematical 
Intuitionists object to the Double Negation rule, which we have of course, insofar as 
the direction of this rule goes from the double negation to the elimination of the 
double negation symbols. (The objection is not for the rule as it proceeds from the 
variable to the doubly negated variable, but this rule of Double Negation that we 
have is, as we know, a Replacement or Equivalent rule: it has to be valid in both 
direction, if it is the classical rule of our standard sentential logic.) There is a philo-
sophic justification which Intuitionists can adduce in rejecting Double Negation 
Elimination: not-not-X should not sanction an inference to X! Why not? If you take 
the meaning of “not” to be “not-provable-in-principle” or “not-verifiable-in-­
principle” (with “true” and “false” also defined as verifiable and verifiable-that-not), 
then you can see a justification for the requested failure of Double Negation 
Elimination: not being able to verify that X is unverifiable does not mean that we 
must necessarily be able to verify that X.
•	 (p ≡ q) ≡ (~ p ≡ ~ q) ⊢ t ∨ ~ t
	
1.	 (p ≡ q) ≡ (~ p ≡ ~ q)	
P/.. t ∨ ~ t
4.4  A System of Natural Deduction (Proof Method) for ∑: ∑∎

202
	
2.	 ~ (t ∨ ~ t)	 	
	
2⎺
	
3.	 ~ t ∙ ~ ~ t	 	
	
DeM(2)
	
4.	 ~ ~ (t ∨ ~ t)	
	
	
IP(20–3)
	
5.	 t ∨ ~ t	
	
	
	
ND(4)	 	
⊣
We might wonder if we could possibly liberalize our system’s restrictions by 
making available self-justifying lines (automatically justified, insertable at any 
point in the proof sequence): these would be formulas that translate tautologies of 
the sentential logic (which we can check for their logical status by using the truth 
table method.) From a theoretical point of view, this is like a “cheat” since our sys-
tem is not supposed to smuggle in extraneous results. If something this were permit-
ted, it would be a nod to mere convenience and a dilution of our project. A better 
case can be made for allowing insertion, as self-justifying lines, of formulas that 
have already been proven by means of derivation procedure. This could shorten 
proofs, perhaps make the proofs easier in other ways; obviously, one would have to 
be keeping track of previous endeavors.
Strategies and Patterns in Derivations
Certain patterns of derivational sequences of lines emerge as the student of a proof 
system like ∑∎ accumulates experience in constructing derivations. We cannot 
claim that an exhaustive list can be presented. Natural deduction proof systems do 
not lend themselves to a mechanical mode of implementation – like the truth table 
or a tree system (which we will have the opportunity to examine in subsequent sec-
tion.) Ingenuity on the part of the human who wields the rules in implementation is 
needed. It is fortunate, however, that strategically interesting patterns can be dis-
cerned and we venture to show such derivation patterns by means of examples. It 
should be kept in mind, as well, that more than one proofs can often be constructed 
in deriving the requested conclusion from the given premises (or with only assumed 
premises, in proving a thesis.) Although we may speak of elegance or economy, as 
criteria inclining toward preferring a proof with fewer proof lines over one with 
more proof lines; or we may scoff at the prospect of having a proof with redundant 
premises or other lines, there are no formal restrictions that are placed on which 
proof counts among several proofs, all of which derive the conclusion from what is 
given by means of applications of correct rules in the system. It should be kept in 
mind, however, that only the rules in the system are to be used – for any derivation 
system. It would be possible to be adding to our rules on the basis of what we prove, 
in this way expanding the system and saving ourselves the effort of having to repeat 
a derivation we have already carried out as fragment within a new proof. Nevertheless, 
we need to ponder over some issues in this regard: Is a formal proof system to be 
considered as a historically evolving agglomerate of proofs? There is a school of 
thought, Mathematical Intuitionism, which supports on philosophical grounds a 
temporally anchored view of truth, so that true is understood as actually proven by 
4  Sentential Logic Languages ∑

203
certain specified derivational means. We do not enter into such philosophical debates 
in this context. The standard view is that theses are provable forever, so to speak, 
regardless as to whether they are in fact proven or not. Our formal system is present 
in its entirety (we do not need to torture ourselves speculating about the kind of 
entity such a system may or what kinds of things it deals with); on this account, we 
eke out the proofs as we compile the lines from an eternally subsisting systematic 
aggregate. We may still defend a practice that would allow us to add schematic 
instances of theses as readily available lines to be used in proofs; the justification 
would not be based on an evolution of our system, and the fact of our discovery of 
such theses would have to be regarded as irrelevant to their correctness.
NEGATED MATERIAL IMPLICATION
•	 ~ (□ ⊃ ◊) ⊢ □ ∙ ~ ◊
	1.	 ~ (p ⊃ q)	
	
1
	2.	 ~ (~ p ∨ q)	
	
CE(1)
	3.	 ~ ~ p ∙ ~ q	
	
DeM(~/∨)(2)
	4.	 p ∙ ~ q	
	
	
DN(3)
IMPLYING SELF-NEGATION
•	 □ ⊃ ~ □ ⊢ ~ □
	1.	 p ⊃ ~ p	
	
1
	2.	 ~ p ∨ ~ p	
	
CE(1)
	3.	 ~ p	 	
	
Idemp(∨)(2)
STRENGTHENING OF THE ANTECEDENT
	1.	 □ ⊃ ◊ ⊢ (□ ∙ △) ⊃ ◊
	1.	 p ⊃ q		
	
1
	2.	 ~ p ∨ q	
	
CE(1)
	3.	 ~ r ∨ (~ p ∨ q)	Add(2)
	4.	 (~ r ∨ ~ p) ∨ q	Assoc(∨)(3)
	5.	 ~ (r ∙ p) ∨ q	
	
DeM(~/∙)(4)
	6.	 ~ (p ∙ r) ∨ q	
	
Comm(∙)(5)
	7.	 (p ∙ r) ⊃ q	
	
CE(6)
	1.	 (p ∙ r) ⊃ q	
	
	
conclusion
	2.	 ~ (p ∙ r) ∨ q	
	
	
CE(1)
	3.	 (~ p ∨ ~ r) ∨ q		
DeM(~/∙)(2)
	4.	 (~ r ∨ ~ p) ∨ q		
Comm(∨)(3)
At this point we wish to derive, working backwards toward the given premise, 
anything close to ⌜p ⊃ q⌝ which is exactly the given premise. Knowing that we can 
use CE again, we continue:
	5.	 ~ r ∨ (~ p ∨ q)		
Assoc(∨)(4)
	6.	 ~ r ∨ (p ⊃ q)	 	
	
CE(5)
4.4  A System of Natural Deduction (Proof Method) for ∑: ∑∎

204
We ought to think at this point that we can derive line 6 from the given premise 
by addition: there is no other way, as we have indicated, for introducing a new letter 
symbol. We marvel that the derivation sequence we have engineered, starting from 
the conclusion and working backwards, is like the proof we constructed above but 
with the lines turned upside down. The symmetry breaks at line 6 of the reverse 
(conclusion-premise) derivation sequence. Of course, addition is not a replacement 
or equivalential rule; it is correct to apply only in one direction. This accounts for 
the break of symmetry we have come upon. Up to this point, in our conclusion-­
premise sequence, we have been applying replacement rules which are reversible. A 
move we can insert at this point, which may seem complicated but possesses some 
degree of elegance, is to insert the new letter that the conclusion of the requested 
proof sequence contains. Because of the irreversibility of this move, we bracket the 
line of the insertion of the missing letter (missing from the given premise); we also 
bracket any subsequent line that depends on any other bracketed line. Thus, we may 
continue. We have completed our reverse derivation once we have produced the line 
with the given premise.
	7.	 [r]	
	
	
[insertion of novel letter]
	8.	 [~ ~ r]	
	
	
[DN(7)]
	9.	 [p ⊃ q]	
	
	
[DS(6, 8)]
Now we have the proof we produced earlier if we turn this reverse derivation 
upside down and remove all bracketed lines (except for the premise line.)
WEAKENING OF THE CONSEQUENT
•	 □ ⊃ ◊ ⊢ □ ⊃ (◊ ∨ △)
	1.	 p ⊃ q		
	
1
	2.	 ~ p ∨ q	
	
CE(1)
	3.	 (~ p ∨ q) ∨ r	 	
Add(2)
	4.	 ~ p ∨ (q ∨ r)	 	
Assoc(∨)(3)
	5.	 p ⊃ (q ∨ r)	
	
CE(4)
EXPLOSION
•	 □ ∙ ~ □ ⊢ ◊
	1.	 p ∙ ~ p              1
	2.	 ~ q                  2−
	3.	 ~ ~ q                IP(2–3, 20)
	4.	 q                  DN(3)
EXPANSION
•	 ◊ ⊢ □ ∨ ~ □
	1.	 p	
	
	
1
	2.	 ~ (q ∨ ~ q)	
	
2−
	3.	 ~ q ∙ ~ ~ q	
	
DeM(~/∨)(2)
	4.	 ~ q ∙ q	
	
	
DN(3)
4  Sentential Logic Languages ∑

205
	5.	 q ∙ ~ q	
	
	
Comm(∙)(4)
	6.	 ~ ~ (q ∨ ~ q)	 	
IP(2–5. 20)
	7.	 q ∨ ~ q	
	
DN(6)
The implementation of the commutative rule on line 4 is needed because the 
shape of the indirect proof rule as we have legislated it in our system has the negated 
formula to the right and not to the left; we could have provided a liberalized schema 
for this rule to forestall the need for such a maneuver, of course, but, we need to 
apply the rules exactly as they are given – and this is a good opportunity to clarify 
this matter in action.
SIMPLIFICATION OF ANTECEDENT
•	 (□ ∙ ◊) ⊃ △ ⊢ (□ ⊃ △) ∨ (◊ ⊃ △)
	 1.	 (p ∙ q) ⊃ r	
	
	
1
	 2.	 ~ (p ∙ q) ∨ r	 	
	
CE(1)
	 3.	 (~ p ∨ ~ q) ∨ r	
	
DeM(~/∙)(2)
	 4.	 (~ p ∨ ~ q) ∨ (r ∨ r)	
	
Idemp(∨)(3)
	 5.	 ((~ p ∨ ~ q) ∨ r) ∨ r	
	
Assoc(∨)(4)
	 6.	 (~ p ∨ (~ q ∨ r)) ∨ r	
	
Assoc(∨)(5)
	 7.	 (~ p ∨ (r ∨ ~ q)) ∨ r	
	
Comm(∨)(6)
	 8.	 ((~ p ∨ r) ∨ ~ q) ∨ r	
	
Assoc(∨)(7)
	 9.	 ((p ⊃ q) ∨ ~ q) ∨ r	
	
CE(8)
	10.	 (p ⊃ r) ∨ (~ q ∨ r)	
	
Assoc(∨)(9)
	11.	 (p ⊃ r) ∨ (q ⊃ r)	
	
CE(10)
The proliferation of tedious moves in this proof cannot escape attention but the 
example illustrates how the shapes of the rules, as they have been established in the 
system that is in use, dictate how to move and no permission exists to disregard this 
or depend on some extraneous intuitions or licenses. Although we have liberalized 
the conventions about use of parentheses around disjunction and conjunction sym-
bols, we may also use parentheses: this is not prohibited; the placement of parenthe-
ses is reintroduced conveniently to guide and highlight the shifts of letters and their 
relative locations as the proof unfolds line by line by applying the relevant rules of 
derivation.
Exercises
	1.	 Answer the following questions:
	a.	 Why can’t we construct counterexamples to incorrect argument forms by using 
a Natural Deduction method?
	b.	 What do we mean by saying that a derivation rule schema in a Natural Deduction 
system is like a recipe?
	c.	 Can we use our familiar truth table to attest that all our derivation rules are cor-
rect? (Notice, for the sake of precision, that we are basically translating into the 
4.5  Other Natural Deduction Systems

206
truth table system in order to check: the truth table system is semantic, because 
it works with true-false truth values, whereas our Natural Deduction system is a 
proof-system. We can check validity with the truth table system.)
	d.	 Why is it that failure to construct a proof for a given argument form does not 
establish that the given argument form is not correct?
	2.	 Prove that the following instances of logical consequence are valid in the 
system ∑∎.
	a.	 SIMPLIFICATION OF ANTECEDENT
(□ ∨ ◊) ⊃ △ ⊢ (~ □ ⊃ △) ∙ (◊ ⊃ △)
	b.	 SIMPLIFICATION OF CONSEQUENT
□ ⊃ (◊ ∙ △) ⊢ (□ ⊃ ◊) ∙ (□ ⊃ △).
□ ⊃ (◊ ∨ △) ⊢ (□ ⊃ ◊) ∨ (□ ⊃ △)
	c.	 NESTED IMPLICATIONS
(□ ⊃ ◊) ⊃ △ ⊢ (~ □ ⊃ △) ∙ (◊ ⊃ △)
(□ ⊃ ◊) ⊃ □ ⊢ ~ □ ⊃ ◊
	d.	 COMBINING IMPLICATIONS
(□ ⊃ ◊) ∙ (△ ⊃ ○) ⊢ (□ ∙ △) ⊃ (◊ ∙ ○)
	e.	 SELF-DISTRIBUTION OF IMPLICATION
□ ⊃ (◊ ⊃ △) ⊢ (□ ⊃ ◊) ⊃ (□ ⊃ △)
	f.	 SWITCHING ANTECEDENTS
□ ⊃ (◊ ⊃ △) ⊢ ◊ ⊃ (□ ⊃ △)
	3.	 Construct proofs in ∑∎, deriving the conclusion from the given premises.
	a.	 (p ⊃ q) ⊃ p ⊢∑∎ p
	b.	 p ⊃ q, ~ p ⊃ q ⊢∑∎ q ∨ s
	c.	 p ⊃ q, p ⊃ ~ q ⊢∑∎ p ⊃ s
	d.	 p ≡ q, q ≡ r ⊢∑∎ p ≡ r
	e.	 ((p ⊃ r) ⊃ (q ⊃ r)) ⊃ s, q ⊃ p ⊢∑∎ s
	f.	 p ⊃ r, q ⊃ r, p ∨ q ⊢∑∎ ~ r ⊃ q
	g.	 p ≡ q, ~ p, ~ r ⊃ q, s ⊃ r ⊢∑∎ s ⊃ r
	h.	 (p ∙ q) ⊃ s, t ∨ w, t ⊃ ~ s, s ⊃ ~ w, q ⊢∑∎ ~ p
	i.	 (p ∙ q) ⊃ s, q ⊢∑∎ p ⊃ s
	j.	 ~ (p ⊃ (q ⊃ ~ p)), p ⊃ (q ⊃ t), ~ t ∨ s ⊢∑∎ s
	k.	 r ≡ (t ⊃ w), ~ (t ∨ r), r ⊃ (s ∨ t), ~ s ⊢∑∎ t
	4.	 A logical thesis – which is semantically conceptualized as a logical truth or what 
we called also a tautology – can be defined as a formula that is derivable from 
the empty set of premises. Can we adapt our system ∑∎ to determine if a given 
formula has the status of being a thesis? Why or why not? Can we use the proof 
4  Sentential Logic Languages ∑

207
by contradiction or indirect proof method to determine if a given formula is a 
thesis? How?
	5.	 In studying the indirect proof approach, we learned how to derive a contradiction 
from a given set of premises. If all we are given is a set of formulas – no desig-
nated conclusion – and we can construct a proof that derives a contradiction 
from those formulas, this establishes that the given set of formulas is what we 
have semantically defined as inconsistent. Based on this, determine in ∑∎ 
whether the given sets of formulas are inconsistent.
	 l.	 ⊢∑∎? {p ⊃ q, q ⊃ r, p, ~ r}
	m.	 ⊢∑∎? {p ≡ q, ~ p ≡ q}
	n.	 ⊢∑∎? {(p ⊃ q) ⊃ p, ~ q, p ⊃ q}
	o.	 ⊢∑∎? {s ∨ t, w ⊃ ~ s, w ⊃ ~ t, ~ w ⊃ w}
	p.	 ⊢∑∎? {~ p ∨ t, t ≡ (p ∨ q), p ∨ t, ~ q, ~ p}
	q.	 ⊢∑∎? {p ⊃ (q ⊃ (p ⊃ q)), ~ q ⊃ (q ⊃ (p ⊃ q))}
	 r.	 ⊢∑∎? {~ ~ p, q ⊃ (p ∨ r), p ⊃ ~ q, q}
	s.	 ⊢∑∎? {~ (p ∨ (q ⊃ ~ q)), ~ p ≡ q}
4.5  Other Natural Deduction Systems
4.5.1  Fitch-Type Natural Deduction System: ∑||
We legislate that the same grammar is to be used as with the system of natural 
deduction we have already studied. The grammar of the formal system regulates 
how symbolic expressions are formed so that they are characterized as well-formed 
or correct, with no other concatenations of symbols accepted as grammatically cor-
rect or well-formed. We number each line of the proof by the use of numerals from 
the positive integers and we write all the way to the right of each line the justifica-
tion for the derivation of line, which can also be thought of as an account of what 
bestows a “right” to obtain the written line by derivational means in our system. All 
these expressions are spelled out in our enhanced metalanguage for the constructed 
system, in the present case the metalanguage being (∑||), which is an open-ended 
and conveniently adapted fragment of English reinforced with tokens of the connec-
tive symbols we use in the official grammar.
For the system ∑||, we add one more symbol, which is the so-called absurdity 
symbol: ⏊. We should not say that this symbol is properly to be regulated since it is 
considered as an indication of logical absurdity or nonsense. We could think of this 
as an exclamation symbol that marks a derivation line to indicate that something has 
gone wrong from a logical point of view. Yet, we are marking a line this way, 
because, as we will see, the rules for the connective symbols enter into interplays 
with the appearance and removal of this symbol. We could, by convention, even 
present rules for this symbol – the symbol of absurdity – but this can also be frowned 
upon on the basis that this symbol shows us that logical nonsense has accrued into 
4.5  Other Natural Deduction Systems

208
our proof lines. Corresponding to a semantic system of sentential logic, like the one 
we used for truth tables, we can think of this symbol, ⏊, as denoting (we can speak 
of denoting or referring in semantic terms) a sentence whose truth value is fixedly 
false: the false sentence, and, of course, any sentence whose truth value is false 
constantly (a logical contradiction) is logically equivalent (has the same logical 
meaning) with our “false sentence” which is denoted by the absurdity symbol.
•	 p, q, …, pi, … ∊ WFF(∑∎)	
	
i ∊ {x: x is a positive integer}
•	 If φ ∊ WFF(∑||), then ~ φ ∊ WFF(∑||)
•	 If φ1 ∊ WFF(∑||) and φ2 ∊ WFF(∑||), then φ1 ∙ φ2 ∊ WFF(∑||)
•	 If φ1 ∊ WFF(∑||) and φ2 ∊ WFF(∑||), then φ1 ∨ φ2 ∊ WFF(∑||)
•	 If φ1 ∊ WFF(∑||) and φ2 ∊ WFF(∑||), then φ1 ⊃ φ2 ∊ WFF(∑||)
•	 If φ1 ∊ WFF(∑||) and φ2 ∊ WFF(∑||), then φ1 ≡ φ2 ∊ WFF(∑||)
•	 ⏊ ∊ WFF(∑||)
•	 Nothing else is a member of the set WFF(∑||) -- <closure clause>
The Fitch-style proof system utilizes vertical lines, placed next to the numeral 
labeling each line and the formal symbolic expression on the proof-line. New verti-
cal lines can be drawn to the right to mark the spot where a posited assumed premise 
or assumption is entered; this generates a subproof which is territorially marked, 
and pictorially indicated, by the vertical lines to the left. We have already borne wit-
ness to the significant role played by assumed premises and the machinery needed 
for discharging any such assumed premises before the proof can terminate: the 
Fitch-style proof shows visibly when such an assumed premise is laid down by the 
vertical line to the left; and this vertical line cannot be the main or initial vertical line 
(which is mandatory for any proof) that has been drawn next to the numeral that 
labels the opening line. Thus, we have a main body of proof, always, which is ter-
ritorially bound by the leftmost vertical line and is continuous and uninterrupted to 
the end of the proof (the terminating or final line with the target conclusion for-
mula.) Vertical lines drawn appropriately to the right mark the assumed premises 
that are entered and they bound the subproofs that are generated accordingly. Since 
we can start a subproof within a subproof (or, we can lay down an assumed premise 
before another assumed premise has been discharged), this means that we can 
always move to the right and draw a new vertical line that indicates a new assumed 
premise being laid down and a new subproof initiated accordingly. There are strict 
regulations, or constraints, on how the assumed are discharged, and in what order 
they are to be discharged; also, there are appropriate regulations managing how 
lines within subproofs are to be made available to other subproof areas and to the 
main proof area. Since the visual line-markers are entrusted with the role of indicat-
ing assumptions and subproofs, the Fitch-notation dispenses with justification lines 
that indicate that a premise or assumed premise has been entered. The premise or 
premises are flanked to the left by the leftmost line while assumed premises, and 
4  Sentential Logic Languages ∑

209
their generated subproofs, are flanked by inner vertical lines. The outlay shows per-
spicuously how subproofs are nested within the main body of the proof and how one 
subproof is nested within the other. Discontinuation of the vertical line for a sub-
proof is exacted when the assumed premise or premises are to be discharged; for 
this purpose, the next line is written in the body of proof to left (which may be a 
return to the main proof area or to a prior subproof whose assumption has not been 
discharged yet.) The Fitch-style notation does require justification lines spelling out 
the name of the rule that has been applied and the numerals labeling the lines on 
which the rule has been applied. As an example, here is what a proof looks like.
We construct our system ∑|| in an austere way: we supply only rules that cannot 
be dispensed with if the system is to be able to construct proofs for all, and only, the 
argument forms that are determined to be valid in the semantic approach we fol-
lowed when we applied the truth table decision procedure. Because the truth table 
method is known to have this characteristic of checking as valid all and only the 
argument forms that should be accepted as “correct” in the standard sentential logic, 
we can repair to the familiar truthtabular approach to use as our guide. It is to be 
understood that, in so doing, we are translating back and forth because the natural 
deduction or proof-theoretical approach is not a semantic approach – it does not 
deal with truth values and it does not build corresponding narratives to give referen-
tial meanings to its items. Of course, the tediousness and ultimately cumbersome 
excess of indicating systematically how we move back and forth between semanti-
cal and proof-theoretic system militates against showing this operation in detail. We 
can use some metalinguistic notation to make plain the correspondence between the 
truth table system and a natural deduction proof system like the one we are building 
now. By “⊩” we symbolize, metalinguistically, the relation of logical consequence 
for the truth table system: what is to the left of the semantic turnstile symbol is 
understood to be a set of formulas which are the premises of the argument form to 
be examined by means of our truth table procedure. To the right of the turnstile, is 
the solitary conclusion formula (since our systems do not deal with multiple-­
conclusions argument forms or proofs, although this is actually feasible.) The proof-­
theoretical logical consequence, likewise, has a set of the given premises to the left 
and the conclusion that is proven by means of a constructed proof to the right of the 
turnstile which is in this case symbolized by “⊢”. Now, we can write out in our 
metalanguage certain expressions that track the relationship we have been referring 
to, and we can elaborate on what is presented. The set theoretic notation uses left 
and right set-brackets for inclusion of the members of the set (of premises.) We keep 
the symbols of formulas the same as a matter of liberal convenience but recall how 
we spoke above of translating back and forth to go from the truth table system ∑⊞ 
to the proof-theoretic system ∑||.
•	 {𝓐1, ..., 𝓐n} ⊩ 𝓒 	
if and only if (iff) 	
{𝓐1, …, 𝓐n} ⊢ 𝓒
•	 <The semantic and proof-theoretic systems should match, which means: there is 
a way to construct a proof in the ⊢−system from the premises {𝓐1, .., 𝓐n} and 
with conclusion 𝓒, if and only if there is a successful check by the truthtabular 
method in the ⊩−system that the argument form with premises {𝓐1, .., 𝓐n} and 
conclusion 𝓒 is valid.
4.5  Other Natural Deduction Systems

210
•	 If every constructed proof in the ⊢−system is matched by a successful validity 
check in the ⊩−system, we say that the ⊢−system is sound; if every valid argu-
ment form, as checked in the ⊩−system, has a constructible proof in the ⊢−sys-
tem, then we say that the ⊢−system is complete.>
•	 𝓐1 ∙ … ∙ 𝓐n ⊩ 𝓒 	
	
iff	
	
	
𝓐1 ∙ ... ∙ 𝓐n ⊢ 𝓒
•	 <The premises are considered to be taken conjunctively: they are all presumed 
true, hence their conjunction is true, semantically speaking: then, as we know, 
validity, a semantic concept, is defined as: it is logically necessary that if all the 
premises are true, then the conclusion is also true (or, it is logically impossible 
that all the premises are true and the conclusion is false.) Proof-theoretically, all 
the given premises are indisputable or self-sustaining (self-justifying); given that 
this is the case, then the conclusion can be obtained as supported or justified by 
means of appropriate proof-steps or lines that are derived, each of which lines is 
justified. But, more narrowly: if we are given as premise the conjunction of all of 
{𝓐1, .., 𝓐n}, then the conclusion 𝓒 can be obtained: to see this, consider that 
there has to be a rule that allows us to derive all of the premises in {𝓐1, .., 𝓐n} 
from a given premise that is the conjunction of these formulas in the premises-­
set. Indeed, this is the rule we called “simplification” in the natural deduction 
system ∑∎, applying the rule serially and as many times as needed. The rule for 
this ∑|| will be appropriately called elimination of the conjunction symbol 
because in the system ∑|| we will have introduction and elimination rules for the 
connective symbols.
•	 ⊩ 𝓒 		
iff	
	
⊢ 𝓒
•	 <A formula that is proven without any premises in our natural deduction system 
corresponds to what we defined as a tautology in the semantic truthtabular sys-
tem. We may indeed think of a tautology – a necessary or logical truth – as a 
sentence that, since it is logically necessarily true, can be accepted without proof: 
hence, although this may sound somewhat forced or unnatural, we may say that 
it can be the conclusion of a no-premises argument form that is valid. In fact, we 
can reason on the basis of the truth table that any argument, with any premises 
whatsoever, has to be valid if its conclusion is a tautology. Taking one step fur-
ther, we say that we may as well remove premises and forcing ourselves to think 
of a notion of a no-premises argument form, we still must have a valid no-­
premises argument form if the conclusion is a tautology. This, of course, is justi-
fied insofar as it is impossible in this case to have all premises true and a false 
conclusion (since the conclusion, being a tautology, cannot possibly be false.) 
Moving to the proof-theoretic system, this means that the system should make 
possible construction of proofs for corresponding tautologies of the semantic 
system, so that no given premises are needed to derive the conclusion line.
•	 Reflecting on what we have said about the use of vertical lines – and also on what 
we generally know about natural deduction systems – it is possible indeed to 
construct a proof without given premises: we would have, however, to posit 
assumed premise or premises, which is something we can certainly do.
4  Sentential Logic Languages ∑

211
•	 In the Fitch-style system, a constructed proof for a thesis – as we call what cor-
responds to a semantic tautology – will have a main body of proof area with no 
given premises whatsoever; there will have to be at least one or possible more 
vertical lines to the right generating subproofs; when all the assumed premises 
have been discharged appropriately and, so, the subproofs have all been 
­completed, then the thesis is written in the main body of the proof . This should 
be the only line written in the main proof area. In this fashion, we have con-
structed a no-premises proof for the thesis.>.
The Fitch-style notational system may look like the example below. Vertical lines 
are used, placed next to the numeral that labels every line of the proof and he proof 
lines themselves; additionally, it is mandated that vertical lines are drawn to the left 
of every subproof that is generated by an assumed premise. Other methods can be 
conjured up to mark the assumptions, and to indicate the discharge of an assumed 
premise, but the Fitch style notational method surrenders this function to a visual 
presentation that pushes vertical lines to the right for each subproof. Because of the 
reliance on the visual representation, there is no need to enter characterizations of 
premises and assumed premises, or to mark that discharge of assumed premises has 
taken place, on the justification line. At any rate, the justification lines, like the 
numerals, are not officially elements of the formal notation and are considered as 
being transacted in the metalinguistic idiom we allow ourselves to have. This also 
means that any adjustments to such conventions would not constitute a violation of 
formal grammar.
The vertical lines are presumed continuous from top to bottom even as our nota-
tional convention shows them as segments of lines drawn to the left of each proof 
line. We may use superscripts in front of subproof lines because some rules require 
that two subproofs be generated before we can complete and discharge. We will be 
using given assumptions (or given premises) as well as assumed premises or posited 
assumptions which we lay down: the Fitch-style representation indicates this visu-
ally; although visual, this is not a psychologically flexible notational facility but a 
strictly enforced regulation that is dictated by our formal requirements. We notice 
that there are vertical strokes from top to bottom, extending from the first to the very 
last line of the proof (or, better we should call it, derivation.) The left-most column 
of such vertical strokes or lines encompasses or marks the territory of the main deri-
vation. Since this is the left-most array of vertical strokes, we may as well say that 
the entire derivation is encompassed in this way. But the additional license we are 
given is to generate subderivations or subproofs; these are generated by laying out 
an assumed or posited premise; the subderivation that is generated in this way is 
also marked, territorially, by its own vertical strokes, from the top to the bottom of 
the subderivation: these vertical strokes are to the right (which is inevitable since all 
the way to the left we have the main proof body marking lines that are essentially 
placed next to the numerals by which we label the lines of the whole proof.) As we 
will see, there are strict rules as to how a subderivation is considered to be com-
pleted, so that we can return to the body of proof outside (and, thus, to the left) of 
the completed subderivation. It is also remarkable  – and absolutely 
4.5  Other Natural Deduction Systems

212
indispensable – that we be allowed to generate subderivations within subderivations 
with the same regulations applying as to how to complete each subderivation. 
Unless an inner (or nested) subderivation is completed we cannot return to a deriva-
tion or subderivation to the left. There are, however, some rules we will be using, 
which require two subderivations, the one below the other; in that case, completion 
is understood to encompass both those subderivations. There will be specific rules 
about how all this is effectuated. When a subproof or subderivation is completed, we 
say that the assumed premise that generated it has been discharged. Premises and 
assumed premises are underlined so that they can be marked out visually as well. A 
Fitch-­style proof schema can be indicated as below:
A proof in ∑|| is the sequence of lines populated with formulas written in accor-
dance with the grammar of the formal system and such that every line is other an 
axiom (whose schema we will provide) or derived from an axiom by application of 
one of the rules (either structural or connective rule.) We produce the lines from top 
to bottom and we label each line with a numeral from the positive integers while to 
the right of each line we supply metalinguistically the justification by showing the 
name of the rule applied and the line or lines on which the rule has been applied.
PROOF: ∑||(𝓐1, .., 𝓐n ⊢ 𝓒)
	 1.	 | 𝓐1
	 2.	 |∶
	 3.	 | 𝓐n
	 4.	 |	
1| 𝓑1
	 5.	 |	
|∶
	 6.	 |	
2|𝓑k
	 7.	 |	
|∶
	 8.	 |∶
	 9.	 |	
|𝓑l
	10.	 |	
|∶
	11.	 |	
|	
|𝓑i
	12.	 |	
|	
|∶
	13.	 |	
| 𝓑j
	14.	 | 𝓒m
	15.	 |∶
	16.	 | 𝓒
The given premises are to the right of the leftmost vertical line which marks the 
main-proof area. It is within this area of the main proof body that we have to termi-
nate when we derive the indicated conclusion 𝓒. Subproof lines are to the right: 
each one is initiated by an assumed premise. It is possible that we need a subproof 
4  Sentential Logic Languages ∑

213
within a subproof; again, we move to the right and generate the subproof by means 
of the assumed premise that is needed. The rules will guide us about how to dis-
charge the assumed premises and complete the corresponding subproofs. A crucial 
restriction is that we cannot terminate a subproof before we have terminated all its 
internal subproofs. Another way of putting it: the latest generated subproof has to be 
completed before the preceding subproof is completed. Ultimately, no subproofs 
can be left without completion before we come to the end of the main proof. It is 
possible, however, to be returning to the main body of the proof before other sub-
proofs are generated subsequently. There are also vital restrictions that are needed 
to regulate how lines can be moved from the main proof to subproofs and within 
subproofs in all possible combinations – what such moves are permissible and what 
moves are prohibited. If the requisite restrictions are disregarded, we would face the 
calamity of being able to prove, from given premises or with no premises, conclu-
sions or theses that are not valid or tautologies in the corresponding semantic sys-
tem: in other words, we would be able to construct proofs for what should not be 
provable! Indeed, one way to tweak the system, by imposing the appropriate restric-
tions, and to justify such restrictions, is by showing that something that should not 
be provable can be proven without the restriction. Such proofs are called categori-
cal proofs.
To summarize the types of regulated procedural moves that are allowed in 
this game:
	1.	 vertical lines (strokes) to mark lines of proofs and subproofs (subderivations);
	2.	 laying down assumed or posited premises to generate subproofs;
	3.	 underlining of premises and assumed premises;
	4.	 nesting or subordinating (to the right) the vertical lines for the subderivations 
(with no limits as to nesting subderivations within subderivations);
	5.	 completing subderivations to return to the superordinate subderivation (or to the 
main body of the proof) in the reverse order in which the subderivations were 
generated;
	6.	 discharging the assumed premises that generate the subderivations by complet-
ing those subderivations (by means of applying the appropriate rule);
	7.	 terminating the proof or derivation (always in the main body) with the line of the 
conclusion-formula;
	8.	 deriving categorical conclusion lines which, as we will see, are no-premise con-
clusions: in such proofs, only subordinate derivations are used.
Our system ∑|| will have the rules, all and only the rules, that are sufficient for 
accomplishing the task of harmonizing with the semantic system and, thus (given 
that this relation is transitive) with the characteristic logical consequence relation of 
the standard logic of sentences. This means that proofs are more difficult to con-
struct in ∑||. The system can be conveniently liberalized by addition of other rules, 
which is something one could do as a pastime. Our present purpose is to build a 
proof system that is more austere, as we indicated already, and allows us to see more 
clearly some of the deeper theoretical features that characterize the classical senten-
tial logic. The system we construct next, a sequence system, will also show us per-
spicuously such features – although, for the purist and, frankly, for the systematic 
4.5  Other Natural Deduction Systems

214
student of logic and metalogical analysis – a sequent calculus notation written in 
tree-like form, which we will only show briefly, is preferred. Of course, depending 
on the purposes of the investigation into logical systems and their interconnections, 
other approaches may be preferable: for instance, an axiomatic system (axiomatiz-
ing sentential logic) is preferred insofar as it simplifies the task of showing this 
connection of harmony or matching to the logical consequence relation of the stan-
dard sentential logic; but an axiomatic system lays a heavy hand indeed on the stu-
dent, making construction of proofs, based only on the available axiom schemata 
and on usually one or two rules, a formidably difficult affair indeed. We will show 
how metalogical results can be obtained for the sequent system we construct in the 
next section.
For our present system, we use introduction and elimination rules for the connec-
tive symbols. There is a philosophic view that the meanings of the logical connec-
tives (sometimes called “logical constants” in texts) are properly defined, not by 
truth conditions as shown through use of a method like the truth table, but by means 
of the rules that properly authorize introduction and elimination of the connective 
symbol. The introduction rule for a connective, generally let’s say symbolized by 
“#”, sanctions or regulates when a line can be derived with the formula that has the 
connective symbol # as its main symbol. For elimination rules, such a rule, for # 
let’s say, regulates how a line can be derived from other lines in at least one of which 
there is a formula with # as its main symbol. Opinions differ as to whether the mean-
ings of the connectives are to be understood as properly defined by both the intro-
duction and elimination rules, only by the introduction rules, or only by the 
elimination rules. We will not dwell on such matters in the present text.
Reiteration Rule/ Repetition Rule.
This rule is not always included in presentations of natural deduction systems; 
sometimes, its presentation is deferred. Yet, without this rule, by explicitly banning 
application of this rule, we would be constructing a sublogic of the standard senten-
tial logic – a deduction system for a logic that can prove less than what is provable 
in the standard sentential logic.
The Reiteration rule (Reit) dictates that formulas from the main body of the proof 
are to be made available within subproofs and also formulas from subproofs are to 
be made available to other subproofs only when those are nested subproofs within 
the subproof from which the formula is rendered available. It is prohibited that a line 
found only within a subproof be reiterated after the subproof has been terminated.
m.	
| 𝓐
∶	
| ∶
n. 	
| ∶	
	
|𝓑1
∶ 	
| ∶	
	
| ∶
u.	
| ∶	
	
|𝓐	
	
Reit m
∶	
| ∶	
	
|∶
z.	
| ∶	
	
|𝓑k
(continued)
4  Sentential Logic Languages ∑

215
We may add a rule called “Repetition” and indicated by “Rep” in the justification 
line: this rule allows rewrite of a formula within the same proof or subproof area. A 
rule like this ought to be distinguished from Reiteration because there are restric-
tions that we need to apply to Reiteration, as we will have a chance to find out, but 
the Repetition rule needs no restrictions or any tweaking to prevent proofs of invalid 
argument forms from succeeding.
∶	
| ∶	
	
|∶	
|𝓑2
∶	
| ∶	
	
|∶	
|∶
∶	
| ∶	
	
|∶	
|𝓑k	
Reit z
∶	
| ∶	
	
|∶	
|∶
∶	
| ∶	
	
|∶ 	
|∶
v.	
| 𝓒
(continued)
m.	
| 𝓐
∶	
| ∶
n. 	
| ∶	
	
|𝓑1
∶ 	
| ∶	
	
| ∶
u.	
| ∶	
	
|𝓑k
∶	
| ∶	
	
|∶
z.	
| ∶	
	
|𝓑k	
	
Rep u
∶	
| ∶	
	
|∶
x.	
| 𝓐	
	
	
	
Rep m
v.	
| 𝓒
It may be questioned why we would even or ever need a repetition rule like the 
one indicated but this will surface as an issue when we consider construction of the 
proof of the thesis of self-implication, ⌜p ⊃ p⌝, (which ought to be provable cer-
tainly). We cannot attend to the details before we have legislated the rule for intro-
duction of the implication symbol.
∙-Rules.
The introduction rule for the conjunction connective should naturally sanction 
deriving a formula with the conjunction symbol as its main connective symbol only 
when both conjunct formulas have been given. We could point to linguistic actions 
to motivate adoption of this rule – although our proof-theoretic “game” ought to be 
understood as self-standing. The competent speaker understands the meaning of 
“and” to be such that she will permit correct assertion of “φ and ψ” only if it is cor-
rect to assert φ and also it is correct to assert ψ. Notice that the order of assertions 
4.5  Other Natural Deduction Systems

216
of φ and ψ does not matter; what matters is that both are regarded as correctly 
assertable. We will be able to prove that conjunction is commutative by using our 
rules for this connective. In doing so, we see clearly that the order in which the 
conjunct formulas are given is not important; the two conjuncts can be joined by 
means of the conjunction symbol according to the rule for conjunction introduction, 
“∙I”. This and all the rules we lay down can be justified by moving over to the 
semantic system of the truth table and checking that argument forms that have as 
premises the rule’s given formulas (translated, of course, into the truthtabular sys-
tem) and have as conclusion the rule’s derived formula are valid. Indeed, reasoning 
semantically, if φ is true and ψ is true, it is a matter of logical necessity that “φ and 
ψ” is true, it cannot be false; if “φ and ψ” could be false, then, by definition of the 
connective conjunction, at least one of φ and ψ ought to be false: but this logically 
impossible in this case since we are given that φ is true and ψ is true. Notice that, in 
so reasoning, we are using a method called reductio ad absurdum (proof by contra-
diction, indirect proof). This is a classically valid rule of inference, but it is not valid 
for other logics like one called intuitionistic. Of course, we are setting up a classical 
sentential logic system here, so we don’t need to worry about this. The rules will 
always be given by means of schemata: figures, shapes, which ought to be thought 
of as instructions or recipes about how to proceed and, maybe, as something like 
cookie cutter shapes that are betokened by the actual parts of the constructed proofs. 
The rule schemata are presented in the metalanguage – hence, different symbols, 
metalinguistic symbols, are used in writing the rules.
m.	
| 𝓐
∶	
| ∶
n. 	
| 𝓑
∶ 	
| ∶
| 𝓐 ∙ 𝓑	
	
∙I m, n
m.	
| 𝓑
∶	
| ∶
n. 	
| 𝓐
∶ 	
| ∶
| 𝓐 ∙ 𝓑	
	
∙I m, n
We indicate that the order does not matter, as we explained above. Strictly speak-
ing, we do not need to show this as it is implicit in the instructions that comprise 
the rule.
The elimination rule for the conjunction symbol, “∙E”, authorizes deriving any 
one, and both, of the conjuncts of the given conjunction formula. The linguistic 
4  Sentential Logic Languages ∑

217
motivation and the semantic, truth-tabular justification can be given in the same vein 
as above.
m.	
| 𝓐 ∙ 𝓑
∶	
| ∶
n.	
| 𝓐	
	
∙E m
We can say that the elimination rule for conjunction has two parts in it or we 
could stipulate two rule schemata separately, one designated as the left- and the 
other as the right-elimination rule. We opt to consider this as one rule with two parts 
and we dispense with a requirement for showing whether the elimination is from the 
left or from the right of the conjunction symbol.
Now, as an example, we show that conjunction is commutative. Strictly speak-
ing, to show that we have to construct the derivation in both directions, from ⌜ p ∙ 
q⌝ to ⌜q ∙ p⌝ and from ⌜q ∙ p⌝ to ⌜p ∙ q⌝. Note the so-called Quine brackets we use 
here, since we are mentioning our symbols in this metalanguage we are deploying. 
The proof in the opposite direction goes through similarly. We keep in mind that, 
after we have laid down our rules for the equivalence or biconditional symbol, we 
can also prove commutativity of conjunction by constructing a proof for ⌜(p ∙ q) ≡ 
(q ∙ p)⌝.
∑||(p ∙ q ⊢ q ∙ p)
	1.	 |p ∙ q
	2.	 |p	
	
∙E 1
	3.	 |q	
	
∙E 1
	4.	 |q ∙ p		
∙I 2, 3
∨-Rules.
The rules for the inclusive disjunction symbol, as expected, are of the introduc-
tion and elimination variety. The elimination variety for the vel or wedge (as we 
may refer to the symbol name) is the only elimination rule we have, which dis-
charges assumptions. This breaks a certain symmetry since all the other rules that 
can be used to discharge assumed premises (and require positing of such assumed 
premises for their application) are introduction rules. As we will, for instance, the 
introduction rule for the implication symbol mandates that the antecedent of the 
conditional we aim to derive (φ in φ ⊃ ψ) be laid down as an assumed premise: after 
the line with ψ has been derived, we may invoke the rule for implication 
m.	
| 𝓐 ∙ 𝓑
∶	
| ∶
n.	
| 𝓑	
	
∙E m
4.5  Other Natural Deduction Systems

218
introduction to derive the φ ⊃ ψ while in this way we are considered to be discharg-
ing the assumed premise (paying the debt we have incurred, logically speaking.) A 
moment’s thought should disclose that this has considerable intuitive appeal – pro-
vided certain common pitfalls that arise when we think of if-then statements are 
avoided. Notice also that we allow ourselves, rather informally, to be speaking of 
rules for the symbols and for rules for disjunction or implication and so on. Strictly 
speaking, we regard our game as one in which we manipulate symbolic resources. 
This has been explained already but it is human-all-too-human to wax rather care-
less and it is to be expected that all manners of speaking are to be met with across 
various texts, or within the same text for that matter.
The introduction rule for the (inclusive) disjunction symbol comes across as too 
permissive and rather counterintuitive. Of course, there is no question that it is a 
correct rule for the standard sentential logic and translation into the symbolic 
resources of the truth table system and application of the truth table would show that 
the corresponding argument form (matching the rule we are discussing) checks as 
valid. The introduction rule sanctions derivation from φ of a line with inclusive 
disjunction of φ with any formula. This may sound wrong: “any formula” appears 
to be breaking some intuitively appealing restriction of relevance. Any formula, not 
related to φ, can be derived. Our logic, however, is not, as we say, relevantist. It does 
not observe relevantist constraints. We ought to be diligent also in specifying what 
we mean by relevance. We know well by now that logic is not an empirically based 
enterprise; it is incorrigible (cannot be rectified or corrected) in the face of empirical 
evidence or factual information; it simply draws out the consequences that follow 
from the meanings of logical words and phrases. Moreover, logic transcends the 
subject matter and it is presupposed by any discipline or enterprise. If by relevance 
we have in mind an appeal to some thematic connection of subject or empirically 
verifiable link, we would be wrong in this. But, certainly, we might think that we are 
justified in asking for relevance at the level of the formulas themselves: introduction 
of new atomic variables, for instance, might strike us as unwarranted for some deep, 
even if hard to express, reason. It looks as if resources were introduced, which have 
not been provided for or being purchased: this is a metaphor, of course, but we find 
also that, in adding and subtracting, for instance, we also observe necessary con-
straint on how available symbolic resources are to be used. Matters become worse 
if we can use this irrelevantist introduction rule to prove formulas that seem to fur-
ther compound the problem: for instance, a formula whose translation tell us that 
from a contradiction we can prove anything. We should keep in mind, however, that 
such formulas may be provable without this rule: still, the formulas are irrelevantist 
as well and this suggests that indeed our basic logic lacks a characteristic of relevan-
tism that we can define appropriately. It may be asked why this is not considered a 
problem. The answer is this: insofar as we are able to prove exactly and only the 
theses that we should be proving, we consider this all to be unproblematic. In other 
words, what matter is that we have a correct characterization of the relation of logi-
cal consequence that we need to have for the standard logic. This seems to be push-
ing the debate to another level: what if we can charge, indeed, that there are provable 
theses, by availing of this rule, which should not be theses? But notice that our 
4  Sentential Logic Languages ∑

219
appeal, not just as a matter of convenience but because we have metalogical proof 
that this is the case – is to the truth-tabular method, if we are so inclined. And our 
natural deduction system, with the irrelevantist rules and all, harmonizes with the 
truth table system. It follows from this that, indeed, this logic does not observe rel-
evantist constraints, defined accordingly, but its defense will have to stand or fall by 
appealing to the ability of the logical systems constructed for this logic to prove 
what they ought to. If the controversy arises, it has to be carried out at a higher, 
philosophically motivated level.
We could mandate, of course, certain relevantist restrictions: for instance, that no 
formula can be derived from φ unless it shares with φ atomic variables. We can try 
different variations of this, and we should because we might still end up, with the 
revised rules, proving theses that we regard as irrelevantist. All this is interesting but 
we must point out that by imposing such constraints we would have entered already 
into the territory of alternative, non-classical logics, and this is something we cannot 
do here.
Here is the schema or shape giving the recipe for the introduction rule for the 
disjunction symbol: it has two parts to it. Perhaps we should regard this is two rules, 
one for left-introduction and one for right-introduction of the symbol. We bypass so 
tedious a request here, as it is customary to do. But we do so with a guilty con-
science because, as we have indicated so often, these are shapes or figures (“sche-
mata”) and they are not to be regarded as amenable to intuitive elaboration or 
proximate application.
m.	
| 𝓐
∶	
| ∶
n.	
| 𝓐 ∨ 𝓑	
	
∨I m
m.	
| 𝓐
∶	
| ∶
u.	
| 𝓑 ∨ 𝓐	
	
∨I m
We could also present the schema as follows. In any case, there is a left and a 
right variant, depending on whether the added formula is to the left or to the right of 
the given formula.
m.	
| 𝓐
∶	
| ∶
u.	
| 𝓐 ∨ 𝓑	
	
∨I m
m.	
| 𝓑
∶	
| ∶
u.	
|𝓐 ∨ 𝓑		
∨I m
4.5  Other Natural Deduction Systems

220
Even though it is a permissive or liberal rule – if by this we mean that any for-
mula can be joined to the given formula by the disjunction rule – still the rule does 
not engender any anomalies for the logical system, which would be a problem. 
Without getting into too many details, let us explain what is at stake. Arthur Prior, 
aiming at a philosophic attack on the claim that the meanings of connectives are 
defined by their introduction and/or elimination rules, coined a connective for which 
he provided the following rules. He called this connective “tonk” and let us symbol-
ize it by “τ”. The problem, as we will see, is that a connective like tonk trivializes 
the whole system in the sense that anything is provable from anything: this is beyond 
irrelevance in that it is an entirely open-ended license to derive whatever from what-
ever (not necessarily in one step, but that is not important.) We will then argue that 
our inclusive disjunction introduction rule does not work like a tonk-like connective.
m.	
| 𝓐
∶	
| ∶
u.	
| 𝓐 τ 𝓑		
τI m
m.	
|𝓐 τ 𝓑
∶	
| ∶
u.	
| 𝓑	
	
	
τE m
And yet, the tonk connective rules seem legitimately drawn. In fact, its introduc-
tion rule, as you should notice, is like that for our disjunction connective while its 
elimination rule is like that of our standard conjunction connective. But we cannot 
simply ban this combination by arguing that rules should be kept separate: after all, 
we will see that the rules of the equivalence connective are organically connected 
with those for the implication connective. Still, something is fundamentally wrong. 
We can prove anything form anything, as we said, and here is how, as it ought to be 
evident from inspection of the rules.
	1.	 | p
	2.	 | p τ q               τI 1
	3.	 | q                   τE 2
The point is that, surely, this is a would-be connective whose meaning is nonsen-
sical: if introduction and elimination rules were sufficient for defining the meanings 
of connectives, we would have, as a consequence, absurdity. Since we cannot, by 
definition, have absurdity, it follows that connectives are not properly definable by 
means of their introduction and elimination rules. One way to respond to this pro-
found challenge raised by Prior is by showing that the tonk symbol does not corre-
spond to any genuine connective because its presented rules violate some reasonable 
and basic requirement which all proper connectives ought to obey. One such require-
ment is so-called conservativity, and we will briefly define this constraint on the 
definitions of connectives by means of rules; tonk violates conservativity but our 
inclusive disjunction connective, as defined by its rules, does not.
4  Sentential Logic Languages ∑

221
A connective (or, better, a presumed or putative or suggested connective, which 
turns out not to be properly so characterized) is conservative if and only if its inclu-
sion in a formal proof system makes possible deriving theses with other connectives 
as the main symbols, which could not be derived before this novel presumed con-
nective was brought into the system. Here is an example of a thesis that has as its 
main connective symbol not the tonk and which is derivable if the tonk is accepted 
in the system, and which, thesis, could not be derived before. Of course, this pseudo-
thesis is not correctly derivable in the standard logic.
	1.	 | p ∙ q/.. r ∙ s
	2.	 | p	
	
∙E 1
	3.	 | p τ r		
τI 2
	4.	 | r	
	
τE 3
	5.	 | p τ s	
	
τI 2
	6.	 | s	
	
τE 5
	7.	 | r ∙ s		
∙I 4, 6
Of course, this is not provable for the conjunction symbol in the standard logic that 
is not enhanced with the tonk symbol and its anomalous rules. Now, we have to give 
our word that our inclusive disjunction symbol does not run into such travails ending 
up in violation of conservativity. But it is not that one should take this on faith: we 
have indicated time and again that a system like the one we are constructing is har-
monious with (proves all and only the theses of) the standard logic: no fewer and no 
more. We don’t prove this metalogical theorem here, but we will briefly showcase a 
metalogical proof for the sequent system we construct and use in subsequent section.
Next, we need to turn to the elimination rules for the inclusive disjunction sym-
bol. WE can justify that this is a correct rule, as always, by using the truth table. In 
prose, we may appeal to the use of a famous logical rule, used throughout the ages 
and known often by the name “arguing by cases.” Given that it is “φ or ψ”, then if 
χ can be proven both from φ and also from ψ, we must conclude that χ. This sug-
gests that we will need not one but two subproofs: one generated by each of the 
disjuncts, φ and ψ: the χ-line has to be derived within each subproof; then, we con-
sider this as sufficient to discharge the assumed premises, φ and ψ, and, coming 
outside of both subproofs (written one on top of the other), we can write χ as we 
invoke the disjunction-elimination rule.
m.	
| 𝓐 ∨ 𝓑
∶	
| ∶
n.	
| 	
	
1|𝓐
| ∶	
	
|∶
u.	
|	
	
|𝓒
v.	
|	
	
2| 𝓑
∶	
| ∶	
	
|∶
w.	
|	
	
|𝓒
z.	
| 𝓒	
	
	
	
∨E m, n-u, v-w
4.5  Other Natural Deduction Systems

222
The formula that corresponds to the law of excluded middle, ⌜p ∨ ~ p⌝, cannot 
be derived yet based on the rules we have. We will need to have at our disposal the 
rules for negation and, as we will see, not only the introduction and elimination 
rules for negation but more than that. As we will recount subsequently, there are 
deep logical-philosophical issues involved in this. We are, however, already in a 
position to prove theses that express such properties of inclusive disjunction as com-
mutativity and associativity and we show such proofs below, opting for the com-
mutativity proof while we leave the associativity proof as an exercise.
∑||(p ∨ q ⊢ q ∨ p)
	1.	 | p ∨ q
	2.	 |	
	
1| p
	3.	 |	
	
| q ∨ p	 	
∨I 2
	4.	 |	
	
2| q
	5.	 |	
	
| q ∨ p	 	
∨I 4
	6.	 |q ∨ p 	
	
	
	
∨E 1, 2–3, 4–5
The logical consequence (indicated metalinguistically by the turnstile symbol) 
also proceeds in the opposite direction. We can prove, in the same way, that ⌜p ∨ q⌝ 
is derivable from ⌜q ∨ p⌝. This is as it ought to be because, by characterizing the 
disjunction as commutative, we are asserting that the two sides of the formula are 
logically equivalent (or, as we should put it in the context of a proof-theoretic sys-
tem, they are inter-derivable.)
⊃-Rules.
The introduction rule for the implication (or conditional) symbol is a subproof-­
based rule. Let us recall that φ is called the antecedent and ψ is called the consequent 
of the implicational formula φ ⊃ ψ. The antecedent of the target implicational for-
mula (which is to be derived by means of the rule ⊃I) must be laid down as an 
assumed premise, in this way generating a subproof or subderivation: after the con-
sequent has been derived within the subproof, the rule for introduction of the impli-
cation symbol compels us to exit the subproof, which is considered completed, and 
we may now derive φ ⊃ ψ. The assumed premise, the antecedent φ, is discharged 
properly by application of the rule. This is also evident in saying that the subproof is 
completed – because no such declaration can be made in cases in which the assumed 
premise has not been discharged. The intuitive justification of this rule seems quite 
irresistible, provided we think in focused fashion about implication – because every-
day linguistic practices and possible psychological biases may be prejudicing the 
way we tend to think about if-then statements. For instance, although it ought to be 
clear that the antecedent is not given as true when a conditional statement is given as 
true, it may be that a competent user of the language could be assuming that the 
antecedent is also given. But there is no warrant for making such an assumption. For 
some reason, the implication rules may not be as crystal clear as we might be tempted 
to claim in laying down these rules – for introduction and elimination of implica-
tion – but, once we turn our undivided attention to the subject, we should be able to 
4  Sentential Logic Languages ∑

223
find the rules obvious. So, if on the assumption that φ is true then ψ is true, it follows 
that “if φ then ψ,” although, of course, this does not license us to think that φ is true 
or ψ is true: it is the if-then statement that has to be true. Of course, for our formal 
purposes, the justification can also be obtained by repairing to the truthtabular system 
and checking the definition of the implication connective. We are ready, then, to pres-
ent the schema or shape of the introduction rule for the implication connective.
m.	
|	
	
| 𝓐
∶	
| ∶
n. 	
| 	
	
| 𝓑
∶ 	
| ∶
u.	
| 𝓐 ⊃ 𝓑	
	
	
⊃ I m- n
The justification line indicated that the subproof extended from lines labeled m 
(on which the assumed premise was posited) through line n. The subproof has to be 
nested: we cannot start in the main body of the proof, since the rule works only with 
subproof and completion of the subproof as we can see. Of course, the nested sub-
proof we generate by laying down the assumed premise can be within another 
nested subproof.
The elimination rule for the implication connective is a staple of symbolic logic. 
The Latin name for this rule, which we used in earlier section for a different natural 
deduction system, is Modus Ponens. The rule sanctions that we may derive the con-
sequent of a given implication insofar as its antecedent is also given. The corre-
sponding argument form we may check by means of the truth table system checks 
valid, for sure. Accordingly, the elimination rule schema for the implication connec-
tive symbol is as follows.
m.	
| 𝓐 ⊃ 𝓑
∶	
| ∶
n. 	
| 𝓐
∶ 	
| ∶
u.	
| 𝓑	
	
⊃E m, n
m.	
| 𝓐
∶	
| ∶
n. 	
| 𝓐 ⊃ 𝓑
∶ 	
| ∶
u.	
| 𝓑	
	
⊃E m, n
4.5  Other Natural Deduction Systems

224
Let us consider how we may derive the thesis ⌜p ⊃ p⌝. This is a proof constructed 
for what would correspond to a tautology formula in the truth table. This is a no-­
premises proof, which makes sense when we think of a logical truth as being, in a 
natural deduction system, derivable from no premises (even from the empty set of 
premises.) Although not a natural way of speaking, there is elegance in this way of 
thinking about the truths of logic. Apparently, we have to rely on rules that work 
with assumed premises (and discharge such premises for completion of the sub-
proof) in order to be able to construct proofs for no-premises formulas. It is in this 
juncture that we have the opportunity to reflect on the use of the rule of repetition, 
although it could be so arranged that we do not need that rule to effectuate the deri-
vation successfully.
∑||(⊢ p ⊃ p)
	1.	 |	
	
|p
	2.	 |	
	
|p	
Rep 1
	3.	 | p ⊃ p	
	
	
⊃I 1–2
Alternatively, we could accept, and give reasons to support, what we may call 
degenerate discharge of the posited assumption (which, of course, would only apply 
in this type of case, when the posited assumption is “collected” or discharged by 
itself.) We may argue that, laying down a formula as an assumption, and thus initiat-
ing a subderivation, we already have the formula in the subproof (obviously) and, 
therefore, we are within our derivational rights, so to speak, to complete the subde-
rivation by using the introduction rule for the implication symbol. The catch is that 
introduction of the conditional symbol requires a subderivation and return to the 
main body once the subderivation has been completed (thereby discharging the 
assumed premise). Since we have placed the formula within the subderivation, we 
may sanction as a way of completing the subderivation the introduction of the con-
ditional symbol connecting the assumed (now discharged) premise with itself. In 
this way we dispense with use of the rule of repetition. The proof looks like this:
	1.	 |	
	
|p
	2.	 | p ⊃ p	
	
	
	
⊃I 1–1
It may seem odd but the lines on which the introduction rule was applied should 
include the assumption line and the line of the consequent of the derived implica-
tion: accordingly, another way of justifying this construction is by saying that the 
antecedent (the assumed premise) line and the consequent line coincide or are iden-
tical in this case. Still, since our rule schema (as a recipe or shape) requires the 
subderivation lines as inclusive of the assumed premise as well as the consequent 
line, we write the lines for the justification “1–1” instead of “1” even though it is 
only the line labeled by the numeral 1 that is included in the subderivation: we sim-
ply follow the rule schema. It is important, of course, that we can make the case that 
the introduction rule has been applied correctly for completion of the subproof and 
discharging of the assumed premise.
4  Sentential Logic Languages ∑

225
Implication is neither commutative nor associative. Some properties that obtain 
include expansion, the corresponding proof given below. Other properties of impli-
cations cannot have proofs constructed for them yet, before we have also presented 
the rules for negation.
∑||(⊢ p ⊃ (q ⊃ p))
	1.	 |	
	
| p
	2.	 |	
	
|	
	
| q
	3.	 |	
	
|	
	
| p	
	
	
Reit 1
	4.	 | 	
	
| q ⊃ p	 	
	
	
	
⊃I 2–3
	5.	 | p ⊃ (q ⊃ p)	 	
	
	
	
	
⊃I 1–4
≡-Rules.
The logical meaning of the equivalence connective captures the sense of the lin-
guistic expression “if and only if” as we find this expression especially in textbooks 
of mathematical subjects (although, alas, also used, rather ambiguously with a dif-
ferent meaning in everyday linguistic usage, often to place emphasis on simple 
implication and, so, meaning something like “it must be true that if p then q.”) As 
we expatiated in the truthtabular presentation, and as it is obvious from the truth-
tabular definition of the connective, φ ≡ ψ is true if and only if (here, we can see the 
technical use of this expression at work) φ and ψ have the same truth values for 
every possible assignment of truth values to the components of the equivalence 
(biconditional.) This is the semantic presentation (based on truth values, hence logi-
cal meaning) but now we are contemplating introduction and elimination rules for 
this connective symbol for a proof-theoretic setting. But we ought to know that two 
formulas φ and ψ are equivalent (which means that the formula φ ≡ ψ expresses a 
logical truth or tautology) if and only if the two formulas imply each other. Given 
that we have already produced the rules for the implication connective symbol, we 
can draw on that to present, and justify, the rules for introduction and elimination of 
the equivalence symbol (the triple bar.)
Proofs for deriving a target formula with the equivalence symbol as the main 
connective symbol tend to be tedious: understandably, we need two serially con-
structed subderivations (arranged in vertical fashion, not nested within each other): 
from the assumption that φ, we need to derive the line with ψ; and then for the 
assumption that ψ (generating the second required subproof) we need to derive φ. 
As we know, this means that both φ implies ψ and ψ implies φ since we can apply 
the ⊃I rule (twice) to effectuate these derivations. Then we can conjoin the two 
derived implicative formula. Our rule could be set like this but we can simplify, 
sparing the steps of deriving the two implicative formulas and the step in which the 
two are conjoined by conjunction. Still, our rule has to require two subderivations: 
both need to be completed and, then, and only then, we may come outside of the 
(pair of the two) subderivations and produce the equivalential formula we are aim-
ing for. We have seen a rule that requires two (vertically arranged) subderivations, 
both of which are completed simultaneously, in the case of the elimination rule for 
inclusive disjunction.
4.5  Other Natural Deduction Systems

226
The elimination rule for the equivalence symbol also depends in its inception on 
how the elimination rule for the implication works. Given the definition of logical 
equivalence, we expect that, given φ ≡ ψ and φ, we may derive ψ (as we may do by 
application of the ⊃E rule) and also that, given φ ≡ ψ and ψ, we may derive φ (also 
by means of the ⊃E rule.) Thus, we expect that the ≡E rule has two parts (something 
we also found in the cases of the ∙E rule and the ∨I rule.)
m.	
|	
1| 𝓐
∶	
| ∶	
|∶
n.	
|	
| 𝓑
u. 	
|	
2| 𝓑
∶ 	
| ∶	
|∶
v.	
|	
| 𝓐
z.	
| 𝓐 ≡ 𝓑	
	
≡I m-n, u-v
m.	
| 𝓐 ≡ 𝓑
∶	
| ∶
n. 	
| 𝓐
∶ 	
| ∶
u.	
| 𝓑	
	
≡E m, n
m.	
| 𝓐 ≡ 𝓑
∶	
| ∶
n. 	
| 𝓑
∶ 	
| ∶
u.	
| 𝓐	
	
≡E m, n
Of course, the vertical order in which the given premises are presented does not 
matter. There is also a left-right factor here (as the case was for ∙E and ∨I). The rule 
schema can also be given as follows:
m.	
| 𝓐
∶	
| ∶
n. 	
| 𝓐 ≡ 𝓑
∶ 	
| ∶
u.	
| 𝓑	
	
≡E m, n
m.	
| 𝓑
∶	
| ∶
(continued)
4  Sentential Logic Languages ∑

227
As an example, we may derive the proof that corresponds to the metalogical 
characterization of logical equivalence as commutative. It is also associative: we 
can construct that proof too, left as an exercise, which is tedious but effective on the 
basis of the rules we have provided so far. We would then have to show also that the 
logical consequence relation obtains in the opposite direction as well, which, deri-
vation, we can construct in similar fashion. Certainly, we can also derive the no-­
premises formula ⌜(p ≡ q) ≡ (q ≡ p)⌝. We just need the introduction and elimination 
rules for the equivalence connective symbol.
∑||(p ≡ q ⊢ q ≡ p)
	1.	 | p ≡ q
	2.	 |	
	
1| q
	3.	 |	
	
| p ≡ q	 	
Reit 1
	4.	 |	
	
| p	
	
≡E 2, 3
	5.	 |	
	
2| p
	6.	 |	
	
| p ≡ q	 	
Reit 1
	7.	 |	
	
| q	
	
≡E 5, 6
	8.	 | q ≡ p	
	
	
	
≡I 2–4, 5–7
~-Rules.
The negation rules occupy a distinguished place, from a metalogical point of view. 
We would notice that the negation rules assortment breaks the symmetry with the 
other rules we have legislated so far: we need more than an introduction and an elimi-
nation rule for negation if we are to attain full deductive strength for the standard 
logic: this means that if we are to be able to construct proofs for all semantically valid 
argument forms (which we may verify as valid by the truth table method decision 
method), then we will need to go beyond having a pair of introduction and elimina-
tion rules for the negation connective. There are options as to what rules to add but 
we most definitely need more than introduction and elimination rules for negation.
n. 	
| 𝓐 ≡𝓑
∶ 	
| ∶
u.	
| 𝓐	
	
≡E m, n
m.	
| 𝓐
∶	
|
n. 	
| 𝓑 ≡ 𝓐	
≡E m, n
∶	
|
u. 	
| 𝓑
m.	
| 𝓑
∶	
|
n.	
| 𝓑 ≡ 𝓐
∶	
|
u.	
| 𝓐	
	
≡E m, n
(continued)
4.5  Other Natural Deduction Systems

228
As we indicated, we must have a natural deduction system that can prove every-
thing that should be provable: this target can be characterized by shifting back to the 
truth table method, which we have already investigated, and determining what argu-
ment forms are valid. All such argument forms, translated into the natural deduction 
system, should have constructible proofs for the conclusions, and from the given 
premises, of the proofs. The converse ought also to be the case: any proof we can 
construct in the natural deduction system should correspond to an argument form 
that tests valid by application of the trusted truth table decision procedure. We can-
not settle for anything less. In our Fitch-style proof system we aim to have a parsi-
monious collection of rules, as few as needed and no rules that can be proven from 
other rules. To this effect, we have proceeded so far by assembling introduction and 
elimination rules but, as we have anticipated, negation will pose a different chal-
lenge. This indicates a deeper underlying issue about our classical logic: if we 
attempt to finish the system by deploying an introduction and an elimination rule for 
the negation connective symbol (with the assistance, usually, of a symbol for logical 
absurdity), then we do not have all the rules we need to be able to construct all the 
proofs we ought to be able to construct. But we will have erected a formal system 
for natural deduction for minimal logic, a sublogic of the classical logic everything 
that is provable in this minimal logic is provable in the standard logic but the con-
verse does not hold. Next, we will add a rule that may at first seem too permissive – 
to be called EFQ, after the Latin “ex falso quodlibet” or “from absurdity anything 
may be proven”, and also called “explosion” in texts. At this point, we have reached 
a natural deduction system for a popular, philosophically motivated, logic called 
intuitionist or intuitionistic. But we do not have a system for the standard sentential 
logic: characteristically, we are not able to derive in this system from double nega-
tion of a formula X the formula X itself. Of course, we could then add a rule for 
double negation elimination and that addresses our problem: we ascend to the full 
strength of the standard sentential logic. There are other ways we can proceed to 
pass to the final step – other rules we can add to round up our building of the classi-
cal logic, including even some rule schema for implication rather than for negation. 
If we try to construct proofs corresponding to these rules, which we need to add, we 
would find that we are frustrated in our efforts: specifically, we may find that we are 
stuck in being unable to eliminate double negation. And, indeed, we cannot prove 
elimination of double negation by using all the other rules we had in our system, 
including the introduction and elimination rules for negation. Of course, we need a 
rule that permits such elimination – of double negation – and we cannot rely on 
what may seem “natural” or obvious: this is never done; the rules that are given to 
us within the formal system is all we have and such rule – accurately, rule schemata 
or rule shapes – are like cookie cutters, to indulge in a metaphor, that we implement 
as we construct instantiations in the actual construction of proofs.
The lesson is that the observed symmetry (with pairs of introduction and elimina-
tion rules for the connective symbols) is broken when it comes to the negation sym-
bol. This is not accidental. We have briefly followed the travails of building layers of 
logical systems, from the minimal logic before we move to the negation symbols, 
and then on to intuitionistic logic when we add to the introduction and elimination 
4  Sentential Logic Languages ∑

229
rules for negation the rule we called EFQ (ex falso quodlibet, which permits deriva-
tion of any formula whatsoever from the absurdity symbol that we have in the sys-
tem. In intuitionistic logic, as we intimated, we cannot derive elimination of double 
negation. We cannot construct proofs corresponding to many other classically valid 
argument forms or tautologies (as can be checked by use of the truth table.) There are 
philosophic reasons, which motivate a defense of intuitionistic logic, that make elim-
ination of double negation inadmissible.: In intuitionistic thinking, the concept of 
truth is to defined so that “X is true” if and only if “there is a constructed proof of X,” 
with certain other strings attached. The game changes, so to speak. The fundamental 
notions, like truth, are defined differently. This reflects a certain way of thinking 
about mathematical truth – and also, extrapolated to linguistic matters, an anti-realist 
or constructivist view that requires that truth can be assigned only for what is proce-
durally verifiable or at least in principle verifiable.. The meanings of the connectives 
are also different in this logic given the fundamental reshuffling of deep notions like 
that of truth. “X is false” ought to be defined, on the basis of this way of thinking, as 
“a proof is constructed by means of which an assumption of X can be transformed 
into a proof of logical absurdity – which is a derivation of the absurdity line in the 
proof.” Now, given these alternative concepts of truth and falsity, it may not be the 
case that it is not the case that X and yet it is not the case that X: reading back into 
the intuitionistic concepts, this means: it may be the case that “there is no construc-
tive proof that there is no constructive proof that not-X” and yet this does not entitle 
us to infer that “there is a constructive proof that X.” In other words, double negation 
elimination ought to fail given these underlying and propelling philosophic motiva-
tions – and the same applies to the law of excluded middle which also fails for intu-
itionistic logic: it is not necessarily the case that either X or not-X has to be true since 
it may be that there is no proof that X and there is no proof that not-X: hence, both 
X and not-X can be false (in the intuitionistic sense of “false.”)
Following this logical-philosophic interlude, we may now lay down the negation 
rules. We will allow ourselves the luxury of excess rules at this point: we will show 
all the various rules that, as mentioned above, transition us to the classical logic. 
First, the elimination and introduction rules for the negation connective are given.
m.	
| 𝓐
∶	
| ∶
n. 	
| ~ 𝓐
∶ 	
| ∶
u. 	
| ⏊	
~E m, n
The elimination rule for negation requires interplay with the absurdity symbol. 
This symbol, included in our grammar, can be thought of, if we repair to the 
semantic view, as denoting a sentence whose fixed or constant truth value is false: 
such a sentence is logically equivalent with a logical contradiction or the negation 
of a tautology, and so on. Alternatively, the absurdity symbol can be thought of as 
4.5  Other Natural Deduction Systems

230
the truth value of connective that interprets a constant function (of any arity) 
whose fixed truth value is false. We have not defined such connectives through our 
use of the truth table but we are able to do so. Such a connective – for instance, a 
binary connective – is one that takes the truth value false as output for every pos-
sible combination of inputs (or, on every row of the defining truth table). Notice, 
however, that we opt for considering the absurdity symbol as denoting the false 
sentence, we are essentially treating is as a sentence: this is not a connective but 
we can conceptually think of it as a degenerate or zero-place, zeroary connective. 
But we cannot use the truth table to define such a zeroary connective: we cannot 
have atomic variables specified as inputs. There are metalogical implications to 
all such moves we may take but discussing all this lies beyond our present scope. 
Finally, we may think of the absurdity symbol as an exclamation mark, a symbol 
for expressing that something has gone wrong in our proof construction but with-
out taking this to mean that our proof has to be abandoned. No matter how we 
think of the absurdity symbol, it is arguable that we should not have introduction 
and elimination rules for this symbol since we might find it hard to account for 
what exactly we are doing laying down rules for a symbol that denotes a logically 
absurd state of affairs – thinking semantically or in terms of true and false. Some 
texts, however, may actually lay down introduction and elimination rules for the 
upside-down T symbol: in that case, our rule above would have to be an introduc-
tion rule for the absurdity symbol with negation rules adapted accordingly. This 
can also be defended: if we think of our proof-theoretic system as one with rules 
that govern the manipulation of symbols in building lines upon lines, then we 
don’t need to account for our game with symbols by means of any narrative in 
which true and false claims can be presented. All we have is a game with rules 
about how to move symbols and move on. In that case, we may as well legislate 
rules for the absurdity symbol as well. We opt for not doing this and we continue 
with the negation rules now that we have elaborated on this needed upside-down 
T symbol of our system.
m.	
| 	
	
|𝓐
∶	
| ∶	
	
| ∶
n. 	
| 	
	
|⏊
u.∶ 	 | ~ 𝓐 	
	
	
~I m-n
The negation-introduction rule is a rule with subproof generated by laying down 
the assumption or assumed formula 𝓐 whose negation. ~ 𝓐, is to be derived: 
insofar as we derive the absurdity symbol within the subproof, the assumption is 
considered discharged, the subproof is completed and we return to the main body 
of the proof: the ~-I rule permit us to write the negation of the assumed formula 𝓐, 
~ 𝓐. This is yet another introduction rule that contains in its shape a subproof: we 
4  Sentential Logic Languages ∑

231
have seen this for the introduction rules for implication and for equivalence. The 
only elimination rule we have found to require subproofs (two of them) is the 
elimination rule for the inclusive disjunction connective. (The equivalence intro-
duction rule also requires two subproofs.) The rationale for the negation introduc-
tion rule can be readily provided; at any rate, shifting to the truthtabular system, we 
may ascertain easily the validity of the matching argument form: notice how we 
must render this argument form: the premise ought to be the implication “if 𝓐, 
then 𝓑 and not-𝓑” and the conclusion is ~ 𝓐. (Mark also that, indeed, the license 
for writing down the absurdity symbol, which we do not have in the truthtabular 
system, is by having 𝓑 and also not-𝓑 and from this, of course, we have “𝓑 and 
not-𝓑.”)
As of now, we have the minimal logic, as we explained above. With the rules we 
have so far, we cannot prove “𝓐 or not- 𝓐”, an expression of what seems to be a 
fundamental logical law, called Excluded Middle. We can be astute in constructing 
a proof to this effect but our efforts are bound to be stymied as we will see. We are 
able, however, to prove the formula corresponding to another seminal law of logic 
(at least, thinking classically), which is the law of non-contradiction, “not (𝓐 and 
not-𝓐).” Of course, the semantical correspondents of these expressions are tautolo-
gies or logically necessary truths: we know that we can construct such proofs in our 
natural deduction system by having no given premises and by utilizing only appro-
priately selected assumed premises. (Thus, a tautology, translated into our natural 
deduction system, is provable by means of a no-premises proof.)
	1.	 |	
	
| p ∙ ~ p
	2.	 |	
	
| p	
	
∙E 1
	3.	 |	
	
| ~ p	
	
∙E 1
	4.	 |	
	
| ⏊	
	
~E 2, 3
	5.	 | ~ (p ∙ ~ p)	
	
	
~I 1–4
But our effort to construct a proof for the excluded middle formula will stop 
short of terminating. We will be left unable to eliminate the double negation! The 
following fragment of a proof is not easy to conceive: it uses astutely the amenities 
we have thanks to the rule for introduction of disjunction. We also utilize another 
power we have: we can always generate a subproof within a subproof. We can make 
formulas available within the subproof of the subproof, by reiterating. Every sub-
proof has to be completed appropriately, by using a fitting rule. The latest generated 
subproof has to be completed first. We cannot use any formulas from subproofs that 
have been completed already in subsequent derivations of lines. Given all this, we 
proceed as shown below. The aim is to end up with the absurdity symbol so that we 
can then prove our target formula once we have started with its negation. But we 
don’t have a rule for eliminating double negation at this point. Nor do we have a rule 
that allows us to derive 𝓐 in the main body of the proof if we have been able to 
derive the absurdity symbol within a subproof for ~ 𝓐. It follows that we cannot 
finish the proof. But with either one of the rules mentioned we would be able to 
complete the proof.
4.5  Other Natural Deduction Systems

232
∑||(⊢ ~ ~ (p ∨ ~ p))
	1.	 |	
	
| ~ (p ∨ ~ p)
	2.	 |	
	
| 	
	
| p
	3.	 |	
	
|	
	
| p ∨ ~ p		
∨I 2
	4.	 |	
	
|	
	
| ~ (p ∨ ~ p)	
	
Reit 1
	5.	 |	
	
|	
	
| ⏊	
	
	
~I 3, 4
	6.	 |	
	
| ~ p	
	
	
	
	
~I 2–5
	7.	 |	
	
| p ∨ ~ p		
	
	
∨I 6
	8.	 |	
	
| ⏊	
	
	
	
	
~E 1, 7
	9.	 | ~ ~ (p ∨ ~ p)		
	
	
	
~I 1–8
We have correctly constructed a proof of ⌜~ ~ (p ∨ ~ p)⌝ from no premises (the 
empty premises-set.) But a proof of ⌜p ∨ ~ p⌝ is eluding us.
At this point, we may add either one of the rules we need; we will allow inclusion 
of both rules. But we also need another rule, the rule we will EFQ (ex falso quodli-
bet, or Explosion.)With this rule, we move from the minimal logic to the logic we 
called intuitionistic but we do not have full strength of the standard sentential logic 
yet – and, to that end, we will move to the addition of one, or both, of the other rules 
to complete our natural deduction system for standard logic.
m.	
| ⏊
∶	
| ∶
n. 	
| 𝓐	
	
EFQ m
Could we avail ourselves of this rule to prove the excluded middle formula, 
which we were unable to do above? This is not possible, alas. We may consider the 
following tempting proof which, however, has a fateful error which we should be 
able to spot.
	1.	 |	
	
| ~ (p ∨ ~ p)
	2.	 |	
	
| 	
	
| p
	3.	 |	
	
|	
	
| p ∨ ~ p		
∨I 2
	4.	 |	
	
|	
	
| ~ (p ∨ ~ p)	
	
Reit 1
	5.	 |	
	
|	
	
| ⏊	
	
	
~I 3, 4
	6.	 |	
	
| ~ p	
	
	
	
	
~I 2–5
	7.	 |	
	
| p ∨ ~ p		
	
	
∨I 6
	8.	 |	
	
| ⏊	
	
	
	
	
~E 1, 7
	9.	 |	
	
| p ∨ ~ p		
	
	
EFQ 8
4  Sentential Logic Languages ∑

233
This proof, however, has not terminated! The assumed premise on line, which 
generated a subproof, has not been discharged. Generally, use of the EFQ rule will 
not discharge an assumed premise, as it is obvious, and is not useful when subproofs 
are contained in the proof. The above non-proof has no given premises, as we know, 
and has a subproof generated by the assumption on line 1: but without discharging 
this assumption, the proof cannot be completed, it cannot terminate. Indeed, we are 
unable to move back to the main body of the proof (since we have not applied a rule 
that discharges the assumption and completes the subproof): without moving to the 
main body of the proof, we can inspect visually that we have not brought the proof 
to a proper termination. It follows that we have not proven anything; a fortiori, we 
have not proven what we set out to prove either.
We continue with the rules either one of which will allow us to complete our 
proof. Each of these rules can be justified by using the other rule: so, we don’t need 
both rules but we allow ourselves to have them both.
m.	
| ~ ~ 𝓐
∶	
| ∶
n. 	
| 𝓐	
	
DNE
The name for this rule is double negation elimination, abbreviated as DNE.
This rule is called reductio ad absurdum and abbreviated as RAA. This is the 
classical reductio rule and, as expected on the basis of everything we have said, it is 
not valid in the intuitionistic logic. This rule along with the negation-introduction 
rule we laid down above regulate what we may call a proof-type called proof by 
contradiction or indirect proof.
Let us see how application of either of these rules will allow termination of our 
proof for the excluded middle formula.
m.	
| 	
	
|~ 𝓐
∶	
| ∶	
	
| ∶
n. 	
| 	
	
|⏊
∶ 	
| ∶
u.	
| 𝓐	
	
	
RAA m, n
4.5  Other Natural Deduction Systems

234
∑|| ⊢ p ∨ ~ p
	 1.	 |	
	
| ~ (p ∨ ~ p)
	 2.	 |	
	
| 	
	
| p
	 3.	 |	
	
|	
	
| p ∨ ~ p		
∨I 2
	 4.	 |	
	
|	
	
| ~ (p ∨ ~ p)	
	
Reit 1
	 5.	 |	
	
|	
	
| ⏊	
	
	
~I 3, 4
	 6.	 |	
	
| ~ p	
	
	
	
	
~I 2–5
	 7.	 |	
	
| p ∨ ~ p		
	
	
∨I 6
	 8.	 |	
	
| ⏊	
	
	
	
	
~E 1, 7
	 9.	 | ~ ~ (p ∨ ~ p)	
	
	
	
	
~I 1–8
	10.	 | p ∨ ~ p	
	
	
	
	
	
DNE 9
	1.	 |	
	
| ~ (p ∨ ~ p)
	2.	 |	
	
| 	
	
| p
	3.	 |	
	
|	
	
| p ∨ ~ p		
∨I 2
	4.	 |	
	
|	
	
| ~ (p ∨ ~ p)	
	
Reit 1
	5.	 |	
	
|	
	
| ⏊	
	
	
~I 3, 4
	6.	 |	
	
| ~ p	
	
	
	
	
~I 2–5
	7.	 |	
	
| p ∨ ~ p		
	
	
∨I 6
	8.	 |	
	
| ⏊	
	
	
	
	
~E 1, 7
	9.	 | p ∨ ~ p	
	
	
	
	
	
RAA 1–8
Let us avail ourselves of the opportunity to show what other rules we may have 
added to gain full deductive strength for the standard sentential logic.
•	 We could add as no-premises rule, allowing us to introduce at any point as given 
premise, the excluded middle formula itself!
∶ 	
| ∶
n.	
| 𝓐 ∨ ~ 𝓐	
	
tnd
tertium non datur (a third case, besides true and false, is not allowed!)
•	 We could add the following rule, with two subproofs generated by the assump-
tions 𝓐 and not-𝓐. If, in both subproofs 𝓑 is derived, then we may derive 𝓑 in 
the main proof body while considering the assumptions as discharged and the 
subproofs terminated. We can see that the standard rule for disjunction elimina-
tion is appealed to in this case but, in addition, it is assumed that there are indeed 
exactly two cases, 𝓐 and not-𝓐, which points to the rule we considered previ-
ously and which is precisely the excluded middle formula.
4  Sentential Logic Languages ∑

235
•	 Interestingly, this is a rule for implication which can also be added to give us the 
full standard logic natural deduction system. It does not have an intuitive appeal 
but it is classical valid as can be shown by conducting a truthtabular check.
∶	
| ∶
m. | 
1| 𝓐
∶ 	
| ∶	
| ∶
n.	
|	
| 𝓑
u.	
|	
2| ~ 𝓐
∶	
|	
| ∶
v.	
|	
| 𝓑
z.	
| 𝓑	
	
	
Dil m-n, u-v	
	
Dilemma
∶	
| ∶
n. 	
| 𝓐 ⊃ 𝓑
∶ 	
| ∶	
| ∶
u.	
|	
| 𝓐
v.	
| 𝓐 	
	
PR n-u	 	
Peirce’s Rule (Peirce’s Law)
Here are examples of proofs in ∑||.
∑||(p ⊃ q, ~ p ⊃ q ⊢ q)
	 1.	 |p ⊃ q
	 2.	 |~ p ⊃ q
	 3.	 |p ∨ ~ p                            /.. q
	 4.	                
1|p
	 5.	                 |p ⊃ q            Reit 1
	 6.	                 |q               ⊃E 4, 5
	 7.	                
2|~ p
	 8.	                 |~ p ⊃ q Reit 2
	 9.	                 |q               ⊃E 7,8
	10.	 |q                               ∨E 3, 4–6, 7–9
A proof that may cause anguish to the novice, because of the multiple nested 
subproofs it requires, is the following.
4.5  Other Natural Deduction Systems

236
∑||: (p ⊃ q) ⊃ q ⊢ ~ p ⊃ q
	 1.	 | (p ⊃ q) ⊃ q
	 2.	 |	
	
	
| ~ p
	 3.	 |	
	
	
|	
	
| p
	 4.	 |	
	
	
|	
	
|~ p	
	
Reit 2
	 5.	 |	
	
	
|	
	
|⏊	
	
~E 3, 4
	 6.	 |	
	
	
|	
	
|q	
	
EFQ 5
	 7.	 |	
	
	
| p ⊃ q	 	
	
	
⊃I 3–6
	 8.	 |	
	
	
| (p ⊃ q) ⊃ q	
	
	
Reit 1
	 9.	 |	
	
	
|q	
	
	
	
⊃E 7, 8
	10.	 | ~ p ⊃ q	
	
	
	
	
	
⊃I 2–9
As another example of a long proof, we proffer:
∑|| ~ (p ⊃ q) ⊢ p ∙ ~ q
	 1.	 | ~ (p ⊃ q)
	 2.	 |	
	
| ~ p
	 3.	 |	
	
|	
	
| p
	 4.	 |	
	
|	
	
|~ p	
	
Reit 2
	 5.	 |	
	
|	
	
| ⏊	
	
~ E 3, 4
	 6.	 |	
	
|	
	
| q	
	
EFQ 5
	 7.	 |	
	
| p ⊃ q	 	
	
	
⊃I 3–6
	 8.	 |	
	
| ~ (p ⊃ q)	
	
	
Reit 1
	 9.	 |	
	
| ⏊	
	
	
	
~E 7, 8
	10.	 |~ ~ p	
	
	
	
	
	
~I 2–9
	11.	 | p	 	
	
	
	
	
DN 10
	12.	 |	
	
| q
	13.	 |	
	
| 	
	
| p
	14.	 |	
	
|	
	
|q	
	
Reit 12
	15.	 |	
	
| p ⊃ q	 	
	
	
⊃I 13–14
	16.	 |	
	
|~ (p ⊃ q)	
	
	
Reit 1
	17.	 |	
	
| ⏊	
	
	
	
~E 15, 16
	18.	 | ~ q		
	
	
	
	
~I 12–17
	19.	 | p ∙ ~ q	
	
	
	
	
∙I 11, 18
4.5.a.0 Common Errors and Strategies for ∑||
•	 Forgetting to apply the ∨I rule is common, arguably because of the apparently 
counterintuitive character of the rule (on account of its disregard for any relevant 
thematic connection between what has been obtained and the formula that is 
added or entered by using the ∨I rule.)
•	 A common error is to make available from a completed subproof a formula that 
had been derived within that subproof; such formula is not available after the 
4  Sentential Logic Languages ∑

237
subproof has been completed. Using this rule would allow us to prove classically 
invalid formulas.
•	 Γ ⊢ φ ⊃ ψ:: 	 obviously, we need to start a subproof with assumed premise φ 
(possibly with additional nested subproofs) and complete by invoking (applying) 
the ⊃I rule.
•	 Γ ⊢ ~ φ::	
we generate subproof by positing φ as assumed premise (possibly 
with additional nested subproofs); the completion has to be done with applica-
tion of the ~I rule.
•	 Γ ⊢ φ::	
we generate subproof by positing ~ φ as assumed premise (pos-
sibly with additional nested subproofs); we complete by applying the RAA rule 
or DN if we have first applied the ~ I rule.
•	 Often, a subordinate proof proceeds to the application of the rule EFQ after the 
absurdity symbol has been derived: this is needed when we require first deriva-
tion of an implication formula: what we posited as assumed premise becomes the 
antecedent of the implicational formula and what we derive from EFQ is the 
consequent of the implicational formula; often, this implicational formula, which 
has been derived in this way, stands in contradiction with another formula we 
already have: this subsequent occurrence of the contradiction symbol may then 
be used to apply ~I.
•	 Γ ⊢ φ ≡ ψ::	
two subordinate proofs are needed: from assumed premise φ, the 
line with ψ must be derived for the first subproof; and, for the second subproof, 
φ must be derived from the assumed premise ψ.
•	 If we have a line with inclusive disjunction, we need, again, two subproofs in 
parallel (but written one under the other in the vertical arrangement of the Fitch-­
style system), both of which need to be completed with application of the 
rule for ∨E.
•	 Thinking ahead, as we may say, is always a good idea.
4.5.b Consistency Check in ∑||.
The question arises naturally if a proof-theoretic system like ∑|| can be deployed 
appropriately to investigate whether a collection of sentences is consistent, which 
means, by definition, that it is logically possible that all the given sentences are true 
jointly. In the semantic or modeling approach afforded us through the truth table 
method, we can check if at least one row of the truth table for the given formulas has 
them all receive the truth value true; that row represents a logical possibility and the 
test of consistency determines that the sentences are consistent if there is at least one 
row with all the formulas true across it. But the prospect of using a proof-theoretic 
method raises a different challenge. Proof-theoretic systems cannot be outfitted to 
be used as mechanical decision procedures whose termination will automatically 
show the result or failure to obtain the targeted result – so that a counterexample can 
even be constructed upon termination of the procedure by marking the truth values 
for the atomic variables that make all premises true and the conclusion false (check-
ing for invalidity). A natural deduction system cannot guide to the mechanical 
extraction of a counterexample, for instance. Nevertheless, there is a way that we 
can check for characteristics other than provability of a thesis (which corresponds to 
validity of the argument form in the matching semantical system.) Similarly, the 
4.5  Other Natural Deduction Systems

238
proof-theoretic system cannot show consistency: it cannot provide us with a model 
(nor would we expect a model, since this is a proof-theoretic approach) or with a 
method for checking that a given set of sentences is consistent. To show consistency, 
we may create an interpretation – or modeling, assigning truth values to all the 
atomic variables, so that all the sentential formulas are true on the interpretation – 
but the proof-theoretic system cannot offer us this. Nevertheless, we can use a sys-
tem like ∑∎ to establish that a given collection of sentential formulas is inconsistent. 
This is how we can do this.
A set of well-formed formulas {φ1, …, φn} is inconsistent if a proof can be con-
structed with the formulas as given premises and with the absurdity symbol as cor-
rectly derived conclusion. As we know, the ~E rule yields derivation of the absurdity 
line symbol; so, we expect that the proof, if it can be correctly constructed, would 
be culminating in application of this rule. Failure to find such a proof, of course, 
does not show that the formulas are consistent: it could be a failure to construct the 
proof; no counterexample is to be extracted from the open-ended sequence of proof 
lines. Success, however, determines that the given set of formulas is indeed incon-
sistent. As an example, we may have the following. Note how we express, metalin-
guistically, the fact that the formulas that are given, taken jointly, are inconsistent: 
absurdity can be derived from them.
∑|| p, p ⊃ q, p ⊃ ~ q ⊢ ⏊
	1.	 | p
	2.	 | p ⊃ q
	3.	 | p ⊃ ~ q
	4.	 | q	
	
⊃ E(1, 2)
	5.	 | ~ q	 	
⊃E(1, 3)
	6.	 | ⏊	 	
~E(4, 5)
Interestingly, and as we should be able to discern, validity and inconsistency are 
conceptually interconnected. A proof with premises {φ1, …, φn} and conclusion ψ 
is also a proof that the collection of formulas comprising the premises and the nega-
tion of the conclusion, {φ1, …, φn, ~ ψ}, is inconsistent. Moreover, given an incon-
sistent set of formulas {φ1, …, φi, …, φn}, the negation of any one of these formulas, 
~ φi, is provable from the rest. Indeed, we could elevated as our proof-theoretical 
process for determining inconsistency the following: a given set of formulas {φ1, …, 
φn} is inconsistent if the negation of any one of the formulas is provable from 
the rest.
To use a proof-theoretic system like ∑|| for determining the logical status of a 
given formula (if it is, as we would call it in the semantics of sentential logic, a 
tautology or a contradiction or a contingency), we need to reflect on our target first. 
A given formula φ is a tautology – which we should call a thesis or theorem in 
proof-theoretical nomenclature – if we can derive the absurdity symbol from its 
negation; φ is a contradiction, of which we should say that it is not provable in our 
system (although its negation is), if we can derive the absurdity symbol from it. 
Determination of the status of logical contingency, on the other hand, requires 
4  Sentential Logic Languages ∑

239
modeling: we ought to show that there is at least one interpretation that satisfies the 
formula (as in the truth table case of the truth value true occurring on at least one 
row) and there is at least one interpretation that satisfies the negation of the formula.
4.5.i Intuitionistic versus Classical Logic.
We examined, in the preceding section, how we can build our natural deduction 
system so that it is sufficient for the purposes of proving formulas that are (semanti-
cally) valid for a logic called Intuitionistic. This was the case when we allowed 
ourselves introduction and elimination rules for the connective symbols in {~, ∙, ∨, 
⊃, ≡}, where by negation rules we deployed the rules we called ~I and ~ E, which 
were schematically shaped with inclusion of the symbol, which we have in our 
symbolic resources, for absurdity,” ⏊.” The rule we called ex false quodlibet was 
allowed too for convenience: it is derivable from the other rules, it is not as we say 
independent, and it is intuitionistically a correct rule. At that point, we do not have 
all the rules we would need – even parsimoniously, not allowing derivable rules but 
only independent rules – to obtain the strength of the classical logic: in other words, 
what we have, which is an intuitionistic proof-theoretic system, cannot prove clas-
sically valid (and hence provable or derivable) formulas. We then saw what ways 
there are available for ascending, as we might say, to classical logic or to obtaining 
classical strength. We can see now how, indeed, the rules we added correspond to 
proofs we cannot construct within our intuitionistic proof-theoretic system, which 
we will call here ∑||ⅈ, with rules {∙I, ∙E, ∨I, ∨E, ⊃I, ⊃E, ≡I, ≡E, ~I, ~E, efq}.
Given that many classically provable formulas are not provable in ∑||ⅈ, we have 
the immediate corollary that the connectives have different meanings – on the addi-
tional assumption that the meanings of the connectives are given proof-theoretically 
by means of introduction and elimination rules or some combination of such rules. 
Intuitionistic logic is motivated philosophically by views that do not accord with 
basic assumptions on which the classical logic is based. The initial impetus origi-
nated from the philosophy of mathematics by the Dutch mathematician Brouwer 
but expansion of the scope of motivating this logic has been offered by Michael 
Dummett to encompass linguistic application. Intuitionists define truth as depen-
dent conceptually on the availability of means for checking or verifying or proving, 
and so they see proof as time-dependent in a certain sense (although without turning 
logic into an empirical science, which would be wrong.) For the intuitionist, “it is 
true that φ” means “there is a constructed available proof or effective verification 
method for deriving or showing that φ.” The meaning of negation is straightly dif-
ferentiated from the classical meaning. Now, “it is not the case that φ” means, intu-
itionistically, that “there is a constructed proof or effective verification method for 
showing that φ is false or for refuting φ.” Accordingly, the intuitionistic meaning of 
“not” becomes like “if-then”: “not-φ” means “there is an available constructed 
proof or effective verification procedure such that, if φ is proven true then we have 
a proof of absurdity.” Or, we may put it, there is a constructed and effective method 
for deriving absurdity from the assumed premise that φ – which highlights our 
felicitous inclusion in our formal system of the symbol for absurdity. It is right, of 
course, that we would be defining negation on the basis of the derivation of the 
absurdity symbol and not by deriving “φ and not-φ” since “not” would then be 
4.5  Other Natural Deduction Systems

240
presupposed. In our rules, though, we have as our rule for elimination of negation, 
which yields the line with the symbol for absurdity, that we should obtain both φ 
and not-φ. This is not a problem given that our schematic rules are presented in a 
recursive way: we just play the game in this way, step by step. But as we talk about 
what is happening, we may still seem to have a problem. We can adduce, however, 
that absurdity is definable notionally in many ways, not necessarily depending on a 
prior concept of negation: for instance, we could define absurdity by taking a neces-
sarily true sentence as being false!
The intuitionist can also speak of in-principle constructability of an effective 
proof procedure but this should be understood to mean that the effective means for 
constructing the proof are presently available, not that the proof is somehow avail-
able and waits to be discovered. The intuitionist is actuated by a deep antagonism to 
the school of thought known as Platonic Realism, which accepts that there are mind-­
independent abstract objects (it follows that this view is Realist) and there are to-be-­
discovered truths about objects: this is the case for mathematical objects, but also 
for concepts. The intuitionist, on the other hand, has a conceptualist or mentalist 
view: the human mind constructs, rather than discovers eternally available, proofs. 
Accordingly, the objects over which we speak ought to be effectively constructible: 
this has profound implications for how we are to think about proofs and claims that 
have to do with members of infinite series. Like Aristotle, in antiquity, who took 
infinity to be an unactualized possible, the intuitionist bans claims about members 
of infinite series, which, claims, cannot be constructively and effectively shown.
The intuitionistic dependence of truth on an available proof means that there is a 
tense or temporal element that is entwined with the notion of intuitionistic truth. 
This does not mean, however, that logic is to be treated, in revisionist fashion, as an 
empirical science. First, once a proof is constructed it is retained forevermore and 
this indicates that we are not dealing with discovery of empirical or factual matters. 
Second, the construction of the proof itself shows that this is indeed a truth that, as 
conclusion of a constructed proof, is not dependent on factual developments that 
can verify or falsify the claim; the verification is entirely dependent on the construc-
tion of a proof and not on any factual heuristics. Third, even though lack of proof for 
φ enjoins us from assigning the truth value true to φ, this does not mean that we may 
consider φ to be not-true or false; recall, of course, that the meaning of “not” is not 
the same as the classical one and, as this case demonstrates, not being true does not 
mean that a sentence is false. Instead, before being proven, φ is considered without 
truth value (but, let us note, this does not mean that φ has a third, non-classical truth 
value but it is, rather, truth-value-less.)
It is a fascinating exercise, which we will forego however, to provide intuitionis-
tic justifications about the theses that we can, and for those that we should be able 
to, prove in intuitionistic logic. What we can do, however, is to give a (certainly 
non-exhaustive) list of theses of intuitionistic logic (which have to be classical the-
ses as well) and also of theses that can be proven in classical logic but not in intu-
itionistic logic. Our preceding study of rules for natural deduction has provided 
sufficient information as to what rules we may and may not apply in constructing an 
intuitionistic, as opposed to a classical, systematic proof. We should be able in prin-
ciple to verify that, as we construct a classical proof for φ (or from φ from premises 
4  Sentential Logic Languages ∑

241
{ψ1, …, ψn}), which is not intuitionistically available, we are always using some of 
the rules that we have seen to be incorrect for intuitionistic logic. And, of course, as 
we try to construct proofs corresponding to some of those intuitionistically unavail-
able rules, we should find ourselves having to use a rule like DNE or RAA (which, 
as we have indicated, are not intuitionistically correct.)
Before we play around with such derivations (intuitionistic versus classical), we 
briefly allow ourselves an excursion into the truth-table system, calling the intu-
itionistic truth table system ∑⊞ⅈ, as distinguished from the classical ∑⊞. We are 
able to provide a mechanical way for checking if an argument form is intuitionisti-
cally valid or not for the limited case that includes the truth-tabular definitions of the 
connectives. First we show the familiar definitions of the connectives in ∑⊞; next, 
we show how, in ∑⊞ⅈ, we make appropriate replacements of symbols: there is a 
systematic strategy in that we replace formulas on the rows by themselves if the 
truth value is true and we replace them by their negations if the truth value is false. 
What we see, then, in checking the pairs of the <∑⊞, ∑ⅈ> truth tables is this: the 
arguments forms that have as premises the formulas in the columns for the atomic 
variables and have as conclusions that formulas in the other columns are all intu-
itionistically valid!
∑⊞
p
q
p ∙ q
p ∨ q
p ⊃ q
p ≡ q
T
T
   T
    T
    T
    T
T
F
   F
    T
    F
    F
F
T
   F
    T
    T
    F
F
F
   F
    F
    T
    T
∑⊞ⅈ	=== replacements of formulas for truth values (φ/T and ~ φ/F): valid argu-
ment forms in the added column (with “⊩” as the symbol for intuitionistic logical 
consequence). The case of the equivalential formulas can be approached accordingly.
p
q
p ∙ q
p ∨ q
p ⊃ q
intuitionistically valid argument forms
p
q
p ∙ q
p ∨ q
p ⊃ q
p, q ⊩ p ∙ q
p, q ⊩ p ∨ q
p, q ⊩ p ⊃ q
p
~ q
~ (p ∙ q)
p ∨ q
~ (p ⊃ q)
p, ~ q ⊩ ~ (p ∙ q)
p, ~ q ⊩ p ∨ q
p, ~ q ⊩ ~ (p ⊃ q)
~ p
q
~ (p ∙ q)
p ∨ q
p ⊃ q
~ p, q ⊩ ~ (p ∙ q)
~ p, q ⊩ p ∨ q
~ p, q ⊩ p ⊃ q
~ p
~ q
~ (p ∙ q)
~ (p ∨ q)
p ⊃ q
~ p, ~ q ⊩ ~ (p ∙ q)
~ p, ~ q ⊩ ~ (p ∨ q)
~ p, ~ q ⊩ ~ (p ⊃ q)
The law of excluded middle is not provable intuitionistically, nor should it be: 
given the definition of truth as constructed-proof, it is possible that neither φ nor its 
negation are true for the intuitionist insofar as there is no available constructed proof 
4.5  Other Natural Deduction Systems

242
of φ and also there is no available constructed proof of the negation of φ – which 
can indeed be the case as we see palpably in the case of mathematical conjectures 
that have not yet been decided one way or another, to bring up one example. Thus, 
for an intuitionistic Fitch system, ∑ⅈ:
∑ⅈ ⊬ p ∨ ~ p
As we saw above, to prove the formula corresponding to the law of excluded 
middle we need to use either the classical rule of RAA or the double negation elimi-
nation rule, DN, but neither rule is valid intuitionistically. Indeed, double negation 
fails intuitionistically (in the direction of elimination of the double elimination) 
since it is possible to have no proof that there is no proof of φ without having proof 
of φ: saying it in another way, it is possible to have proof that it is absurd to consider 
that we can derive absurdity from assuming that we have a proof of φ and yet have 
no proof of φ. This convoluted way of putting it brings to our attention that intu-
itionistic negation is better understood as: ~ φ means that a proof of φ can be con-
verted into a derived line of ⏊ (the absurdity symbol), and, so, we can also say, 
not-φ means that, if φ then ⏊ by the intuitionistic standards of proof-theoretic deri-
vation. In this sense, negation is dependent on implication for the intuitionist. The 
definition of not- φ as “if φ, then absurdity (necessary falsehood)” works classically 
as well but the classical notion of implication is different from the intuitionistic.
Let us recall what rules of derivation can be added to the set of rules, which is 
sufficient for constructing a proof system for intuitionistic logic, to ascend to classi-
cal logic. We will show these rules schemata – shapes – in a different way here. The 
rules, from which we can choose to add any one in order to effectively move from 
intuitionistic to classical logic, are: double negation elimination (DN), the classical 
rule of reductio ad absurdum (RAA), constructive dilemma (CD), Peirce’s Law (PL) 
and Tarski’s Law (TL). The first two are negation rules, the next is an inclusive dis-
junction-negation rule and the last two are implicational rules. In the new way of 
presenting the rule schemata, we draw a line over the formula that is assumed and 
needs to be discharged for the subproof to be completed effectively: the superscript 
labels the “debt” of the assumed premise and when the discharge is effectuated by 
means of applying the appropriate rule, a superscript with the same label is drawn 
next to the name of the rule to indicate that the discharge has been effective. In this 
way, we show an alternative presentation of rules for this type of proof system – and, 
by extension, for the kind of proof system itself that can be constructed in this way: 
in other words, there are feasible alternatives one could pursue to build a proof sys-
tem and showing greater variety of such possibilities may stimulate the imagination.
•	 DN
n. 	
	
~ ~ φ
∶
n+m. 	
	
φ	
DL(n)
4  Sentential Logic Languages ∑

243
•	 RAA
n.             ~ϕ i
∶
n+m.        ⏊
∶
n+m+k.      φ         RAAi(n-n+m)
n.               


 ~
i
∶
n+m.               ϕ i
∶
n+m+k.             ψ
∶
n+m+k+l.           ~ϕ i
∶
n+m+k+l+u.         ψ
∶
n+m+k+l+u+v.       ψ      CDi(n, n+m=n+m+k, n+m+k+l=n+m+k+l+u)
•	 CD
•	 PL
n.            


1
∶
n+m.           φ
∶
n+m+k.         φ            PL1(n-n+m)
4.5  Other Natural Deduction Systems

244
•	 TL
n.                  


i
∶
n+m.               χ
∶
n+m+k.              ϕ i
∶
n+m+k+l.            χ
∶
n+m+k+l+u.          χ      TLi(n-n+m, n+m+k-n+m+k+l)
An interesting exercise is to construct a classical proof for a thesis, or a classical 
derivation of a conclusion from given premises, and mark if any rules of inference 
are used, which are not intuitionistically valid: this means that the thesis or the deri-
vation is not intuitionistically valid. Here are some instances of logical conse-
quences which are not intuitionistically valid although they are classically valid. 
And here is another example of tolerable sloppiness, which is not uncommon to find 
in texts. As we continue indicating invalid instances of logical consequence in intu-
itionistic logic, we should be using different symbols for connectives; because these 
are presumed to be the intuitionistically defined connective symbols; for the classi-
cal definitions, with which we have been dealing in our formal languages, these are 
all valid instances of logical consequence. We may pretend that, as a matter of 
uncanny coincidence, the symbols are the same even though the logic, for which 
these instances of logical consequence are invalid, is not the standard logic but the 
intuitionistic one. The same observations apply for cases in which we show instances 
of logical consequence that are also intuitionistically valid: the symbols are for intu-
itionistic connectives. Moreover, we are showing such instances in a liberally 
enhanced metalanguage that is permitted to use tokens of symbols.
As a general observation, we have: argument forms tend to be intuitionistically 
valid, as well as classically valid, when the conclusion, or the consequent of impli-
cational formulas in conclusions, are negated formulas; as can be inspected, this is 
markedly the case for the various instances of contraposition and also for applica-
tion of reductio (which is, accordingly and as expected, not the same as the classical 
reductio.) Many classically valid instances of logical consequence which are also 
valid conversely (so that we have essentially logical equivalence) may be found to 
be intuitionistically valid in only one direction – and specifically in the direction in 
which the conclusion is some negated formula (for instance, from φ to ~ ~ φ is 
intuitionistically valid but the converse, which is classically valid, is not intuitionis-
tically valid.) It lies beyond our present scope to elaborate on justifications, as we 
have already mentioned, but we can give again an instructive example: the 
4  Sentential Logic Languages ∑

245
intuitionistic meaning of implication is defined as actual availability of a proof that 
converts a proof of the antecedent to a proof of the consequent of the implication; 
so, it might be possible to convert a proof of φ to a proof of ψ or χ and yet it might 
also be impossible to convert a proof of φ to a proof of ψ and also impossible to 
convert a proof of φ to a proof of χ: hence, the inference from φ ⊃ (ψ ∨ χ) to ((φ ⊃ 
ψ) ∨ (φ ⊃ χ)), which is classically valid, should be intuitionistically invalid – and 
indeed it is.
•	 ~ ~ p ⊬∑ⅈ p
•	 ⊬∑ⅈ p ∨ ~ p
•	 (p ⊃ q) ⊃ p ⊬∑ⅈ p
•	 ⊬∑ⅈ ((p ⊃ q) ⊃ p) ⊃ p
•	 ~ p ⊃ q ⊬∑ⅈ ~ q ⊃ p
•	 ~ q ⊃ ~ p ⊬∑ⅈ p ⊃ q
•	 ~ p ⊃ q, ~ p ⊃ ~ q ⊬∑ⅈ p
•	 p ⊃ q ⊬∑ⅈ ~ p ∨ q
•	 ~ (~ p ∨ ~ q) ⊬∑ⅈ p ∙ q
•	 ~ (~ p ∙ ~ q) ⊬∑ⅈ p ∨ q
•	 p ⊃ (q ∨ r) ⊬∑ⅈ (p ⊃ q) ∨ (p ⊃ r)
The following, however, are intuitionistically valid.
•	 p ⊢∑ⅈ ~ ~ p
•	 ~ p ⊢∑ⅈ ~ ~ ~ p
•	 ~ ~ ~ p ⊢∑ⅈ ~ p
•	 ⊢∑ⅈ ~ ~ (p ∨ ~ p)
•	 p ⊃ q ⊢∑ⅈ ~ q ⊃ ~ p
•	 p ⊃ ~ q ⊢∑ⅈ q ⊃ ~ p
•	 ~ p ∨ p ⊢∑ⅈ ~ ~ p ⊃ p
•	 p ⊃ q, p ⊃ ~ q ⊢∑ⅈ ~ p
•	 ~ p ⊃ q, ~ p ⊃ ~ q ⊢∑ⅈ ~ ~ p
•	 ~ p ∨ q ⊢∑ⅈ p ⊃ q
•	 p ⊃ q ⊢∑ⅈ ~ (p ∙ ~ q)
•	 ~ (p ∙ ~ q) ⊢∑ⅈ p ⊃ q
•	 ~ (p ∙ q) ⊢∑ⅈ p ⊃ ~ ~ q
•	 p ⊃ ~ ~ q ⊢∑ⅈ ~ (p ∙ q)
•	 ~ (p ⊃ q) ⊢∑ⅈ ~ ~ p ∙ ~ q
•	 p ∙ ~ q ⊢∑ⅈ ~ (p ⊃ q)
•	 ~ ~ (p ⊃ q) ⊢∑ⅈ ~ (p ∙ ~ q)
•	 ~ (p ∨ q) ⊢∑ⅈ ~ p ∙ ~ q
•	 ~ p ∙ ~ q ⊢∑ⅈ ~ (p ∨ q)
•	 ~ (p ∙ q) ⊢∑ⅈ ~ p ∨ ~ q
•	 ~ p ∨ ~ q ⊢∑ⅈ ~ (p ∙ q)
•	 Generally:
•	 If ∑|| ⊢ φ, then ⊢∑ⅈ ~ ~ φ
•	 If ∑|| ⊢ ~ φ. then ⊢∑ⅈ ~ φ
•	 If ∑|| ⊢ ~ (φ ∙ ψ). then ⊢∑ⅈ ~ (φ ∙ ψ)
4.5  Other Natural Deduction Systems

246
4.5. Exercises
	1.	 Construct proofs in ∑|| for the exercises in 4.4.2.e.
	2.	 Construct the requested proofs in ∑||.
	a.	 p ⊃ q, q ⊃ r ⊢∑|| p ⊃ r
	b.	 p ∨ q ⊢∑|| q ∨ p
	c.	 (p ∙ q) ∙ r ⊢∑|| p ∙ (q ∙ r)
	d.	 (p ≡ q) ≡ r ⊢∑|| p ≡ (q ≡ r)
	e.	 ~ (p ∨ q) ⊢∑|| ~ p ∙ ~ q
	 f.	 p ⊃ q ⊢∑|| ~ q ⊃ ~ p
	g.	 (p ∙ q) ⊃ r ⊢∑|| p ⊃ (q ⊃ r)
	h.	 p ⊃ (q ⊃ r) ⊢∑|| (p ∙ q) ⊃ r
	 i.	 p ∨ (q ∙ r) ⊢∑|| (p ∨ q) ∙ (p ∨ r)
	 j.	 (p ⊃ q) ∙ (p ⊃ r) ⊢∑|| p ⊃ (q ∙ r)
	k.	 q ⊃ p, r ⊃ p ⊢∑|| (q ∨ r) ⊃ p
	 l.	 (q ∨ r) ⊃ p ⊢∑|| (q ⊃ p) ∨ (r ⊃ p)
	m.	 p ≡ ~ q ⊢∑|| ~ p ≡ q
	3.	 We can construct proofs deriving theses proof-theoretically in ∑|| from no prem-
ises. This can be done for implicational theses (formulas that are theses, semanti-
cally tautologies, and which have the implication connective symbols as their 
main connective symbol.) But we can also construct proofs for any theses, by 
using the negation of the given formula. How is this to be done? Having 
answered, attend to constructing proofs for the following theses.
	a.	 ⊢∑|| ~ (p ∨ ~ p) ⊃ ⏊
	b.	 ⊢∑|| (p ⊃ p) ⊃ ((p ⊃ p) ⊃ (p ⊃ p))
	c.	 ⊢∑|| p ⊃ (q ⊃ (p ∙ q))
	d.	 ⊢∑|| (p ⊃ (q ⊃ r)) ⊃ ((p ⊃ q) ⊃ (p ⊃ r))
	e.	 ⊢∑|| ~ (p ∙ q) ≡ (~ p ∨ ~ q)
	 f.	 ⊢∑|| (p ⊃ q) ⊃ (~ q ⊃ ~ p)
	g.	 ⊢∑|| (((p ⊃ q) ⊃ q) ∙ (q ⊃ p)) ⊃ p
	h.	 ⊢∑|| (p ⊃ q) ⊃ ((r ⊃ p) ⊃ (r ⊃ q))
	 i.	 ⊢∑|| ((p ⊃ q) ∙ (p ⊃ r)) ⊃ (p ⊃ (q ∙ r))
	 j.	 ⊢∑|| p ⊃ ((p ⊃ q) ⊃ q)
	k.	 ⊢∑|| p ≡ (p ∙ p)
	 l.	 ⊢∑|| p ≡ (p ∨ p)
	m.	 ⊢∑|| ((p ∨ q) ∙ ~ p) ⊃ q
	n.	 ⊢∑|| (p ∙ (q ∨ r)) ≡ ((p ∙ q) ∨ (p ∙ r))
	o.	 ⊢∑|| ((p ∨ q) ∙ (p ⊃ r) ∙ (q ⊃ s)) ⊃ (r ∨ s)
	4.	 Construct proofs for the following theses, all of which are considered paralogis-
tic: they are all logically necessary truths (tautologies) of the standard sentential 
logic, as can be verified by their translation into the formal language of the truth 
table system and application of the truth-tabular check; it can be argued, how-
ever, that the intuitions of the competent user of language reject these are neces-
sary truths. Even though there is nothing paradoxical – and cannot be – about 
4  Sentential Logic Languages ∑

247
these theses, since they are trivially valid on the basis of the defined meanings of 
the connectives of the standard logic, the point is that the theses are paralogis-
tic – as explained in the preceding sentences. How do we construct proofs in the 
Fitch-style system for theses? As you construct the proofs for each thesis, note 
the rules that you use and discuss whether removing some rule, and thereby 
making proof of the thesis fail, can be recommended; examine the rule itself, 
how it is justified, and the consequences of removing the rule. Realize that the 
justification of the rule provided by the truth table cannot be renegotiated unless 
you are ready to accept redefinitions of the connectives; this, of course, would 
change the logic you are dealing with.
	a.	 ∑||⊢ ~ p ⊃ (p ⊃ q)
	b.	 ∑||⊢ q ⊃ (p ⊃ q)
	c.	 ∑||⊢ (p ⊃ q) ∨ (q ⊃ p)
	d.	 ∑||⊢ (p ⊃ q) ∨ (p ⊃ ~ q)
	e.	 ∑||⊢ (p ∙ ~ p) ⊃ q
	f.	 ∑||⊢ p ⊃ (q ∨ ~ q)
	g.	 ∑||⊢ (p ≡ q) ∨ (q ≡ r) ∨ (p ≡ r)
	h.	 ∑||⊢ (p ⊃ q) ≡ (~ p ∨ q)
	5.	 Construct proofs in ∑|| for the instances of logical consequence that were pre-
sented in 4.5.i as intuitionistically valid; mark that no rules that are not intuition-
istically valid are needed to effectively construct the proofs.
	6.	 Now construct proofs in ∑|| for the intuitionistically invalid instances of logical 
consequence from 4.5.i and identify the rules that are not intuitionistically valid, 
but are classically valid, and are needed for the effective construction of the proof.
	7.	 Construct proofs in ∑|| to determine if the given sets of formulas are consistent. 
Does failure to construct the proper derivation sequence establish that the given 
set is inconsistent?
	a.	 ⊢∑||{p, p ⊃ q, ~ q}
	b.	 ⊢∑||{(p ⊃ p) ⊃ q, ~ q}
	c.	 ⊢∑||{(p ⊃ p) ⊃ p, ~ p}
	d.	 ⊢∑||{p ⊃ q, p ⊃ r, p, ~ q ∨ ~ r}
	e.	 ⊢∑||{p ⊃ ~ q, q, p}
	f.	 ⊢∑||{p ⊃ r, q ⊃ r, p ∨ q, ~ r}
	g.	 ⊢∑||{(q ∨ r) ⊃ p, q, ~ p}
	h.	 ⊢∑||{(p ∙ q) ∨ (p ∙ r), ~ q ∙ ~ r}
4.6. A Sequent System for Natural Deduction: ∑⇒.
Our symbolic idiom for a sequent-type natural deduction system, designated as 
∑⇒, retains the symbolic resources and grammatical arrangements we have been 
implementing for all our ∑ systems. We ought to reiterate that these are different 
symbolic languages and we should really regard the overlapping notation and gram-
mar as a felicitous coincidence that happens to be convenient.
Our set of connective symbols is from {~, ∙, ∨, ⊃, ≡}. Here we simplify matters 
by dispensing with the triple bar but keeping in mind that we can, and we will as an 
4.5  Other Natural Deduction Systems

248
exercise, work out rules for the equivalence connective symbol. The grammar of 
well-formed formulas is as before. The sequents are written with use of the added 
symbol of an arrow, “⇒”, which separates a left from a right side (left and right to 
the arrow symbol.) This is significant as we will explain. We can have multiple well-­
formed formulas on either and/or both sides of the arrow. In our metalinguistic pre-
sentation of the rule-schemata (the recipes of “cookie cutter” shapes that instruct us 
to carry out the legislated maneuvers for this game of derivation), we indicate col-
lections of well-formed formulas by using capital Greek letters, while we use small 
Greek letters from {φ, ψ, …, φi, …} for the formulas that are manipulated in accor-
dance with the connectives-rules. As always, subscripts are from the countable set of 
the positive integers (this set is countable because its member, albeit in an infinite 
series, can be put in one-to-one correspondence with the natural numbers.) We need 
connectives rules, of course, but we will also require so-called structural rules. Such 
rules dictate the manner of permissible manipulations of formulas on the two sides 
of the sequence arrow symbol, including permissible additions and removals of for-
mulas and exchange or permutation of positions of the formulas. This is not an idle 
matter or a bow to convenience: disallowing a structural rule may well mean that a 
different logic – not the standard sentential logic – is obtained as we will have an 
opportunity to find out when we briefly discuss issues pertaining to the distinction 
between standard and intuitionistic logic – a subject that we pursued in the preced-
ing section and which serves as an opportunity for us to sketch, roughly, how alter-
native logics can be obtained based on changes in the rules of the derivation game.
We will find out that only introduction rules are provided for the connectives. 
This may seem odd, as we have been habituated to having both introduction and 
elimination rules for connectives in the type of natural deduction proof system we 
pursued in earlier section. There is a systematic fashion in which we may match 
some of the introduction rules in ∑⇒ to corresponding elimination rules in the 
previously constructed system ∑||, which can be undertaken as an exercise. As for 
the philosophic question about how this type of rule constitutes the meaning of a 
connective, we defer a deeper discussion of this intricate subject.
A sequent has the general schematic form:
φ, Γ, Δ, Γ ⇒ Θ, Λ, Λ, ψ.
We indicate that repetition of formulas is not excluded, which further means that 
structural transformational rules are needed to remove redundant formulas, if that 
be allowed, or, for that matter, to permit reiteration of formulas (since it is permitted 
to have multiple occurrences of formulas as we show.) The formulas that are the 
targets for the connective rules are placed outside, which means all the way to the 
left for the left side of the arrow and all the way to the right for the right side of the 
arrow. To move such formulas inside, we will need structural rules. The schematic 
shapes are, as always, figure-like or  – as the ancient etymology of the word 
4  Sentential Logic Languages ∑

249
suggests – schematic: the moves that are permissible are shown in the schemata and 
all those, and only those authorized maneuvers are permitted.
It is permitted that either side of the sequent can be empty. But the reading of the 
empty side is different in each case: left-side emptiness indicates the empty set of 
premises (if we may speak in terms of premise-conclusion nomenclature.) Thus, we 
can also have:
⇒ ψ
This can be read as: the formula ψ is provable from the empty set of premises 
which we recognize as referring to what we know semantically as a tautology or 
logical truth  – and we have also covered in natural deduction as a no-premise 
conclusion.
The right-side empty space indicates what we would characterize as logical 
absurdity in semantic terms. Considering this, we notice that if we move ψ in the 
left-empty sequent to the right side, we should have:
~ ψ ⇒.
If ψ represents, semantically interpreted, a tautology when it is to the right of a left-
empty sequent, then its move to the left should be prefixed with the negation symbol. 
We can explain this: while a tautology, semantically speaking, is implied even by the 
empty set of premises, a contradiction implies logical absurdity insofar as by absurdity 
we understand the formula that has as its constant truth value falsehood. And, of 
course, the negation of a tautology is a contradiction, and vice versa, as we know. This 
move to the left shows us already what the rule for left-­introduction of the negation 
symbol should be in our system – and this expectation will not be disappointed.
Another observation we can make – which we could stipulate, but we can also 
prove from the other stipulations as to rules, which we will be making, is this: the 
formulas to the left of the arrow are to be considered as being joined by conjunction 
while the formulas to the right of the arrow are to be considered as being joined by 
inclusive disjunction. Accordingly, we have:
φ1, φ2, Γ, Δ ⇒ Θ, Λ, ψ1, ψ2	
is the same as	
	
φ1 ∙ φ2, Γ, Δ ⇒ Θ, 
Λ, ψ1 ∨ ψ2
A proof in ∑⇒ is the sequence of lines populated with formulas written in 
accordance with the grammar of the formal system and such that every line is other 
an axiom (whose schema we will provide) or derived from an axiom by application 
of one of the rules (either structural or connective rule.) We produce the lines from 
top to bottom and we label each line with a numeral from the positive integers while 
to the right of each line we supply metalinguistically the justification by showing 
the name of the rule applied and the line or lines on which the rule has been applied. 
In this fashion, we follow the conventions we used for ∑||. It is more usual to follow 
a different figurative arrangement which is, for certain purposes of metalogical anal-
ysis, more perspicuous (but also appears more cluttered and may even seem rather 
counterintuitive in certain respects.) We will briefly show incidentally how this 
alternative, which is encountered very frequently in texts.
4.5  Other Natural Deduction Systems

250
The axiom-schema for our system, which is called the rule of assumptions, RA, 
is as follows:
φ ⇒ φ          RA
An instance of the RA shape is always the opening gambit of a proof. An instance 
of the RA can always be added as a line and as needed. No justification is needed 
for this line. We may say that this is a self-justifying line. We should not think of an 
instance of RA as a sentence token but as an instance of a shape that we implement 
in making moves. This is generally the case with the lines of a derivation.
The rule of assumptions, as presented schematically, is liberalized: we could 
present the rule only for atomic variables. It is available, however, though tedious, 
to show that we can justify on this basis the liberalized rule of assumptions. For 
instance, we may consider the following, which draws on a strict RA for atomic 
variables to establish that such a rule can be sanctioned for a negated atomic for-
mula. We use negation rules which we have not yet presented: it is an interesting 
intuitive exposure to check if you consider the negation rule, left and right, as being 
what you might have expected.
	1.	 p ⇒ p	
	
RA-atoms
	2.	 ~ p, p ⇒ p	
~L 1
	3.	 ~ p ⇒ ~ p	
~R 2
We begin with the structural rules for ∑⇒. Each rule has a name and, as with the 
connectives rules, the capital letters “R” and “L” are used to indicate whether the 
rule-mandated maneuver is applied with a result, respectively, on the right or the left 
side of the arrow.
Thinning or Weakening.
Left.
m.	
Γ ⇒ Θ, ψ
∶
m+n. 	
φ, Γ ⇒ Θ, ψ	
WL m
Thinning or Weakening.
Right.
m.	
φ, Γ ⇒ Θ
∶
m+n. 	
φ, Γ ⇒ Θ, ψ	
WR m
4  Sentential Logic Languages ∑

251
Formulas can be added, either to the left or to the right. The standard logic does 
not observe restrictions about relevance in the interconnections of formulas, as we 
had the opportunity to observe especially when discussing the rule of introduction 
for the disjunction connective in the case of the ∑|| system. Any formulas can be 
introduced, left or right, in a sequent. The justification can be extracted from consid-
ering, as it was mentioned earlier, that the formulas to the left are regarded as joined 
by conjunction and the formulas to the right are considered to be joined by inclusive 
disjunction: if a formula is derivable from a set of formulas, then addition of any 
formula in the left does not affect the efficacy of the derivation (since ψ is derived 
from the sequence of formulas, it has been derived already regardless of adding an 
extra formula and this addition does not change anything); on the right, since the 
formulas are taken disjunctively, we may justify the addition of any formula in a 
sequent in the same way we accounted for the inferential rule we called introduction 
of disjunction in the ∑|| system (and which we called Addition in the initial natural 
deduction system we constructed.) We can also provide the justifications thinking of 
premises, to the left and conclusions, disjunctively, to the right.
Another structural rule is what we call Exchange or Permutation, and this rule too 
has a left and a right version. The order in which the formulas are written, to the left 
or the right, does not matter and, accordingly, the order can be altered liberally and at 
will by moving the formulas any way it is desired: the justification, keeping in mind 
the conjunctive connection to the left and the disjunctive connection to the right, can 
be given by appealing to the following fact, which we know by now: both conjunc-
tion and inclusive disjunction are commutative (which means that logical meaning, if 
we speak semantically, is the same when the order of joined formulas is altered.)
Exchange or Permutation.
Left.
m.	
φ, ψ, Γ ⇒ Θ
∶
m+n. 	
ψ, φ, Γ ⇒ Θ	
EL m
Exchange or Permutation.
Right.
m.	
Γ ⇒ Θ, φ, ψ
∶
m+n.	
Γ ⇒ Θ, ψ, φ	
ER m
The next rule we can justify by referring to the fact that both conjunction and 
inclusive disjunction are characterized by the property, which gives its name to a 
rule we used in the first natural deduction system we constructed: Idempotence. 
This allows reiterated occurrences of the same formula to be removed as desired. 
The corresponding rule in our present system is called Contraction and, again, it has 
a left and a right version.
4.5  Other Natural Deduction Systems

252
The final structural rule is based on the characterizing property of classical impli-
cation, which gives its name to the rule we called Hypothetical Syllogism in the 
initial natural deduction system we constructed. As we survey the schematic for this 
rule, which is called Cut, we can discern this property of implication, which is also 
called sometimes transitivity. Interestingly, there are no left and right versions for 
this rule. The rule essentially connects a left and a right side with the same formula 
and “cuts” this formula out. It can be shown, although it lies beyond our present 
scope, that any derivation in a formal system like the one we are constructing, in 
which cut is used at some move, can be reshaped as an alternative proof of the same 
sequent without use of the cut rule.
Contraction.
Left.
m.    φ, φ, Γ ⇒ Θ
∶
m+n.  φ, Γ ⇒ Θ       CL m
Contraction.
Right.
m.     Γ ⇒ Θ, φ, φ
∶
m+n.  Γ ⇒ Θ, φ       CR m
Cut
k.	
φ, Γ ⇒ Θ
∶
l.	
Δ ⇒ Λ, φ
∶
m.	
Γ, Δ ⇒ Θ, Λ	
Cut k, l
Next we move to the rules for the rules for the connectives, with each connective 
having a left-introduction and right-introduction rule depending on whether the out-
come of the rule application is the generation of the formula with the connective 
symbol as it main symbol on the left or the right of the arrow. Some rules have more 
than one parts (as we saw in the case of the ∑|| system as well) related to the left/
right placement of the connected formulas (for binary symbol rules.)
4  Sentential Logic Languages ∑

253
~−rules.
left.
m.	
Γ ⇒ Δ, φ
∶
n.	
~ φ, Γ ⇒ Δ	
~L m
right.
m.	
φ, Γ ⇒ Δ
∶
n.	
Γ ⇒ Δ, ~ φ	
~R m
∙−rules.
left.
m.	
φ, Γ ⇒ Δ
∶
n.	
φ ∙ ψ, Γ ⇒ Δ	
∙L m
m.	
φ, Γ ⇒ Δ
∶
n.	
ψ ∙ φ, Γ ⇒ Δ	
∙L m
right.
k.	
Γ ⇒ Θ, φ
∶
l.	
Δ ⇒ Λ, ψ
∶
m.	
Γ, Δ ⇒ Θ, Λ, φ ∙ ψ	 	
∙R k, l
∶
n.	
Γ, Δ ⇒ Θ, Λ, ψ ∙ φ	 	
∙R k, l
∨−rules.
left.
k.	
φ, Γ ⇒ Θ
∶
l.	
ψ, Δ ⇒ Λ
∶
m.	
φ ∨ ψ, Γ, Δ ⇒ Θ, Λ	 	
∨L k, l
∶
n.	
ψ ∨ φ, Γ, Δ ⇒ Θ, Λ	 	
∨L k, l
(continued)
4.5  Other Natural Deduction Systems

254
right.
m.	
Γ ⇒ Δ, φ
∶
n.	
Γ ⇒ Δ, φ ∨ ψ	
	
∨R m
∶
u.	
Γ ⇒ Δ, ψ ∨ φ	
	
∨R m
⊃−rules.
left.
k.	
ψ, Γ ⇒ Θ
∶
l.	
Δ ⇒ Λ, φ
∶
m.	
Γ, Δ, φ ⊃ ψ ⇒ Θ, Λ	 	
⊃L k, l
right.
k.	
φ, Γ ⇒ Δ, ψ
∶
l.	
Γ ⇒ Δ, φ ⊃ ψ	
	
⊃R k, l
(continued)
We will now construct examples of proofs or derivations in ∑⇒.
∑⇒: (p ⊃ q) ⊃ p ⊢ p
	 1.	 p ⇒ p	
	
	
	
	
RA
	 2.	 p ⊃ q ⇒ p ⊃ q	
	
	
	
RA
	 3.	 ~ p ⇒ ~ p	
	
	
	
RA
	 4.	 p ⊃ q, (p ⊃ q) ⊃ p ⇒ p	
	
⊃L 1, 2
	 5.	 ~ p ⇒ ~ p, q	 	
	
	
WR 3
	 6.	 ~ ~ p, ~ p ⇒ q	
	
	
~L 5
	 7.	 ~ p, p ⇒	
	
	
	
~L 1
	 8.	 p ⇒ ~ ~ p	
	
	
	
~R 7
	 9.	 p, ~ p ⇒ q, q		
	
	
Cut 6, 8
	10.	 p, ~ p ⇒ q	
	
	
	
CR 9
	11.	 ~ p ⇒ p ⊃ q	 	
	
	
⊃R 10
	12.	 ~ p, (p ⊃ q) ⊃ p ⇒ p	 	
	
Cut 4, 11
	13.	 (p ⊃ q) ⊃ p ⇒ p, ~ ~ p		
~R 12
	14.	 ⇒ p, ~ p	
	
	
	
~R 1
	15.	 ~ ~ p ⇒ p	
	
	
	
~L 14
	16.	 (p ⊃ q) ⊃ p ⇒ p, p	
	
	
Cut 13, 15
	17.	 (p ⊃ q) ⊃ p ⇒ p	
	
	
CR 16
4  Sentential Logic Languages ∑

255
This remarkably, although unnervingly long, sequent-proof derivation of the for-
mula corresponding to Peirce’s law is instructive in a significant respect. We know 
from previous sections that this formula is not intuitionistically valid. We note, then, 
how it is derived in the above sequence of lines: one of the rules that is needed for 
the derivation (in this derivation, needed to be applied twice) is contraction. If this 
rule is not accepted, we have the intuitionistic case: the rule cannot be derived. But 
we also note that we derive in this proof another intuitionistically invalid sequent – 
on line 15, permitting inference to a variable from the double negation of that vari-
able. This derivation takes place by iterated moves of the letter, applying negation 
rules (~L and ~R.) Blocking this inference, in the intuitionistic logic which has 
strength that is lesser than the strength of the classical logic, requires disallowing an 
iterated move in which the negation introduction rule (left and right) is applied 
twice in succession. This is an example of how we can investigate what tweaks in 
the rules are needed to obtain logic of a specific relative strength (when by “strength” 
we mean how much the logic can prove relative to another specified logic – in this 
case, with the intuitionistic logic proving less than the classical logic does.)
As another example we present the following derivation in ∑⇒.∑⇒: ~ p ∨ 
q ⊢ p ⊃ q
	1.	 ~ p ⇒ ~ p	
	
RA
	2.	 q ⇒ q	
	
	
RA
	3.	 p ⇒ p	
	
	
RA
	4.	 ~ p ∨ q ⇒ ~ p, q	
∨L 1, 2
	5.	 ~ ~ p, ~ p ∨ q ⇒ q	
~L 4
	6.	 ~ p, p ⇒	
	
~L 3
	7.	 p ⇒ ~ ~ p	
	
~R 6
	8.	 p, ~ p ∨ q ⇒ q		
Cut 5, 7
	9.	 ~ p ∨ q ⇒ p ⊃ q	
⊃R 8
There are no substitution/replacement rules in a sequent-type system of deriva-
tion like ∑⇒: ⌜p⌝ cannot be substituted for its equivalent ⌜~ ~ p⌝. The derivation 
has to be carried out and cut is used to make a sort of bridge. We could institute a 
formal practice that permits using instances of already derived sequents as theorems 
that are to be added as lines in a derivation. A sequent system like ∑⇒ may appear 
unwieldy and even lacking in certain intuitive graces but the payoff for implement-
ing such a system is significant in terms of extracting and facilitating proofs in meta-
logical theory, which lie beyond our current scope.
4.6. Exercises
	1.	 Prove the theorem that matches a valid deduction rule, which we have encoun-
tered as the rule of contraposition in the system we constructed in earlier chapter. 
Fill in the missing proof lines while you are furnished with the justification lines 
in the derivation. The labeling of the proof lines is actuated by using the numeral-­
parenthesis format.
	1)	 p ⇒ p	
	
	
RA
	2)	 q ⇒ q	
	
	
RA
4.5  Other Natural Deduction Systems

256
	3)	 _____, ____ ⇒ __	
	
⊃L 1, 2
	4)	 p, p ⊃ q ⇒ q	 	
EL 3
	5)	 ______ ⇒ ___, ___	
~R 4
	6)	 ____, _____ ⇒ ___	
~L 5
	7)	 p ⊃ q ⇒ ~ q ⊃ ~ p	
⊃R 6
	2.	 Fill in missing steps, either supplying names of rules and/or lines on the justifica-
tion lines or supplying formulas on the derivation lines or both, in the following 
sequent derivations in ∑⇒. The labeling of the proof lines is actuated by using 
the numeral-parenthesis format.
	1)	 p ⇒ p	
	
	
	
RA
	2)	 q ⇒ q	
	
	
	
RA
	3)	 p ⊃ q, p ⇒ q	 	
	
____ 1, 2
	4)	 p, p ⊃ q ⇒ q	 	
	
EL ___
	5)	 p ∨ q, p ⊃ q ⇒ q	
	
____ 2, 4
	6)	 p ∨ q ⇒ ________	
	
⊃R 5
	1)	 p ⇒ p	
	
	
	
______
	2)	 q ⇒ q	
	
	
	
______
	3)	 r ⇒ r		
	
	
______
	4)	 p ⊃ r, p ⇒ r	
	
	
⊃L ____
	5)	 q ⊃ r, q ⇒ r	
	
	
____ 2, 3
	6)	 p, p ⊃ r ⇒ r	
	
	
EL ____
	7)	 q, q ⊃ r ⇒ r	
	
	
___ 5
	8)	 p ∨ q, ______, _____ ⇒ r 	
∨L 6, 7
	3.	 Why are we compelled to use structural rules, like Exchange (also called 
Permutation), left and/or right, in carrying out the preceding derivations?
	4.	 Devise left and right rules for the equivalence connective ⌜≡⌝ thus enhancing 
∑⇒ to ∑⇒≡.
	5.	 Can we prove empty-premises sequents in ∑⇒? Notice that in moving formulas 
from one side of the arrow symbol to the other we may indeed derive lines with 
no formulas (the empty sequence of formulas to the left). Consider the following 
derivation and fill in what is missing. What is the characterization of a derivable 
no-premises sequent? What is the semantic characteristic of the corresponding 
translated formula in a truth-table system?
	1)	 p ⇒ p	
	
	
	
RA
	2)	 p ⇒ p ∨ ~ p	
	
	
___ 1
	3)	 ⇒ p ∨ ~ p, ~ p
	4)	 ⇒ ~ p, p ∨ ~ p		
___ 3
	5)	 ⇒ p ∨ ~ p, p ∨ ~ p	
	
∨R ____
	6)	 ⇒ p ∨ ~ p	
	
	
___ 5
	a.	 What rule was used to derive the final line in the derivation?
	b.	 Recall that in the alternative logic we have briefly studied, which is called intu-
itionistic logic, this should not be a derivable sequent: what does this tell you 
about what rule may be unavailable in a sequent derivation system for intuition-
istic logic?
4  Sentential Logic Languages ∑

257
	6.	 We ought to be able to derive in ∑⇒ theses that are considered paralogistic – 
although not paradoxical – in the sense that their semantic interpretations appear 
to fall short of capturing the meanings of the corresponding linguistic logic-­
words: for instance, we have Explosion (a contradiction implies anything) and 
expansion (a logical truth is implied by anything.) The theses are not paradoxi-
cal: this cannot happen since the rules allow for correct derivation. They are, as 
we have indicated, paralogistic in the above specified sense. We derive these 
theses below; fill in the justification lines.
	1)	 p ⇒ p
	2)	 p ⇒ p, q
	3)	 p ∙ ~ p ⇒ q
	1)	 p ⇒ p
	2)	 q, p ⇒ p
	3)	 q ⇒ p, ~ p
	4)	 q ⇒ p ∨ ~ p, ~ p
	5)	 q ⇒ ~ p, p ∨ ~ p
	6)	 q ⇒ p ∨ ~ p, p ∨ ~ p
	7)	 q ⇒ p ∨ ~ p
	a.	 What rules may we reject to block valid derivation of these theses?
	b.	 Would the resulting derivation system be in the same family of systems of the 
standard sentential logic? Or does the logic change?
	c.	 Do you think that we would we be able to prevent any and all paralogistic theses 
by rejecting derivation rules?
	7.	 Construct the requested derivations of sequents in ∑⇒.
	a.	 q ⊃ (p ⊃ r) ⊢∑⇒ p ⊃ (q ⊃ r)
	b.	 p ∨ q ⊢∑⇒ q ∨ p
	c.	 (p ⊃ q) ⊃ p ⊢∑⇒ p
	d.	 p ∨ (q ∙ r) ⊢∑⇒ p ∨ q, p ∨ r
	e.	 p ⊃ q, q ⊃ r ⊢∑⇒ p ⊃ r
	f.	 p ⊃ (q ⊃ r) ⊢∑⇒ (p ∙ q) ⊃ r
	g.	 ~ (p ∨ q) ⊢∑⇒ ~ p ∙ ~ q
	h.	 ~ p ∙ ~ q ⊢∑⇒ ~ (p ∨ q)
	i.	 p ⊃ q, p ⊃ ~ q ⊢∑⇒ ~ p
	j.	 p ⊃ q ⊢∑⇒ (p ∙ r) ⊃ q
A Tree System for ∑: ∑↙↓↘
The Tree System is a decision procedure for sentential logic: we can use it 
mechanically to determine validity or invalidity of argument forms, consistency of 
sets of formulas and whether a given formula is a contradiction, a tautology or a 
contingency. After our Natural Deduction system in the preceding sections, we are 
now back to deploying a semantic or modeling device. This is in evidence when we 
detect truth values, true and false, in the formalism. A model assigns specific objects 
to the symbols of the formal language; accordingly, a narrative can be provided, 
4.5  Other Natural Deduction Systems

258
even if the objects are themselves abstract and rather removed from ordinary intu-
itions. Although the availability of a narrative may seem as an impressive accom-
modation for an appeal to intuitions, at first glimpse, the point is rather that semantic 
approaches work with assignments of meanings rather than with procedural manip-
ulations that are managed by means of applications of rules. The true and the false – 
the two truth values of the standard logic – are to be thought of as the referents or 
denotata of the meanings of sentences that are assertoric (would be asserted cor-
rectly if true) or, as they are usually called, declarative. The broader notion, how-
ever, is that of designated value  – accompanied ineluctably by the notion of 
anti-designated value. This information is omitted from standard introductory text-
books; in the case of the standard – also called “classical” logic – the omission does 
not subtract anything that is needed for comprehension of the involved notions and 
mechanics of the formal system. A deeper understanding of logic, however, and 
especially the prospect of further embarking on the study of alternative (unortho-
dox, non-standard) logics, require indispensably that we deal with the notions of 
designation and anti-designation.
Briefly, a designated value can be thought of as the “winning” value for the deter-
mination of what is to be preserved when we speak of validity: compare, based on 
everything we have been studying, that the deductive notion of validity is preserva-
tion of truth. There are alternative views on what is to be preserved but we bypass 
such views for our present purposes. A valid argument is basically one with a valid 
argument form, as we know, and a valid argument form is one in which truth is 
preserved, as we have learned, in the sense that it is logically impossible to have all 
true premises and a false conclusion in any instantiation of the form. Also, the con-
cept of tautology or logical truth, as we have learned by now, means that there is no 
logical possibility of assigning truth values to the individual components of the 
sentence so that the formula is not true – or, it is true for every logically possible 
truth-value assignment (case, option, interpretation, or, indeed, also called model-
ing.) The designated value is the true in the standard logic. There may be initial 
bafflement as to what else may be conceivable but there are alternative logics – 
motivated even by specific considerations in various fields of inquiry – which have 
more than one designated truth value. Designated truth values may be thought of as 
species of being true – if the notion of more than one way of being true can be com-
prehended. If this appears puzzling, consider, to mention only one example, how, as 
we have discovered, in the classical or standard logic, inconsistent premises imply 
any conclusion whatsoever (since such premises can never be all true on any simul-
taneous truth-value assignment, and, hence, by the definition of validity, the argu-
ment has to be valid since it is impossible to have all premises true!) But it runs 
against rudimentary experiences that contradictions in the body of a narrative, a 
theory or a story sanction inference to any conclusion whatsoever. One way to 
develop an alternative logic that blocks such inferences utilizes more than two truth 
values and such truth values have to be distributed between designated and anti-­
designated. The designated can be considered as species of true and the anti-­
designated as species of false.
4  Sentential Logic Languages ∑

259
In our tree language, cultivating a habit that would come handy if one continues 
with studies of non-standard logics, we will use the symbols of “+” for designation 
and “-” for anti-designation. Of course, the true is the only designated truth value 
and the false is the only anti-designated truth value. It is particularly neat – and 
inevitable – that the only designated and only anti-designated value of the classical 
language are disequivalent with each other. This raises a claim – albeit a controver-
sial one – that notoriously recalcitrant languages known as “liar-sentences” should 
not be considered as receiving either one of these classical truth values. A sentence 
like that (for instance, “someone who always lies admits that he lies”) are true if 
false and false if true: hence, they are true if and only if they are false. This has given 
rise to a disturbing challenge since time immemorial – since hoary antiquity. One 
solution – not accepted by everyone – is that such sentences receive a designated 
species of value which is not the classical true. Indeed, since such sentences seem 
to be declaratory, they would have a designated truth value but this value should not 
be considered as the classical true – for reasons intimated above. Hence, we con-
front here a case in which another species of true – or, we could say, another desig-
nated truth value – besides the classical true is in the logic. This logic, of course, is 
an alternative to the classical or standard bivalent logic. And, it is important to 
remark, the meaning of true in this alternative language is no longer what it was in 
the classical language: now, “true” means something like “only true” or “entirely 
true” whereas the other designated truth value may be thought of as meaning “both 
true and false but assertable.”
Formal Language and Mechanics for ∑↙↓↘
We use the same grammar as in ∑. We will be constructing something called a tree 
or semantic tree. This is a semantic procedure because it allows us to build models 
of logical possibilities related to valuations of the individual letters: a valuation is an 
assignment of true or false. In the truth table, which we have studied already, we 
discerned the logical possibilities by looking into rows: every row represents a logi-
cally possible assignment of truth values (true/false) to the individual variables – the 
letters. Here, in the semantic tree method, we will have paths: starting with the top, 
which is the root, where we place the given formula or formulas, we build down-
wards; depending on what rule we are applying, we build vertical branches or split-
ting branches downwards; in this way we construct paths from top to bottom until 
the whole tree-building process comes to an end. We will learn how to do this. Every 
path of a tree represents a logical possibility; but there is also a chance that some 
path closes, as we say; a closed path represents a logical impossibility (a nonsensi-
cal or absurd state.) An absurd path is one in which any individual variable symbol 
(or, in a liberalized version, any formula) receives both the designated and anti-­
designated value. (This works in alternative logics too.) Thus, the absurd state is 
considered as closed or logically impossible.
Here is an idea on which the tree method is based. Let us think of a formula that 
has as its main connective symbol the dot: this means that we are dealing with a 
4.5  Other Natural Deduction Systems

260
conjunction. This is what we are given: this is the root of our tree. We consider every 
formula on every line of the tree as designated or true. Thus, we have in the root a 
conjunction as true. We can go back to the truth table method to verify that a con-
junction is true if and only if both conjunct formulas are true. “If and only if” means 
an “if-then” that goes in both directions. We may restate what we have just pre-
sented as follows: if a conjunction is true, then both conjuncts have to be true; and, 
conversely, if the two conjuncts are both true, then the conjunction must be true too. 
We list the two conjuncts vertically underneath the conjunction at the root. In other 
words, we legislate that “true and true” is represented as a vertical path with the two 
true formulas written the one on top of the other. We connect the root with the con-
juncts written beneath it by means of a vertical arrow. The designations, of which 
we spoke in the opening section of this chapter, are placed to the right of each well-­
formed formula. This is shown below.
If we have an inclusive disjunction, which means that the main connective sym-
bol is the wedge, we know, and can check by using the truth table method, that the 
whole formula is true if and only if either one or the other of the two disjuncts is 
true: if ⌜p ∨ q⌝ is true then either ⌜p⌝ or ⌜q⌝ is true; and, conversely, if either ⌜p⌝ or 
⌜q⌝ is true, then ⌜p ∨ q⌝ is true. To represent this we legislate that we append two 
splitting branches underneath the given disjunctive formula. We can think of this as 
representing one logically possible case or situation to the left and the other to the 
right. This works but we cannot get into technical details to justify it. There is an 
intuitive appeal to this – although it wouldn’t matter anyway, since we learn such 
mechanical procedures as a matter of manipulating symbols. To connect the root 
with the two splitting branches, we need a left-leaning and a right-leaning arrow.
We can build a tree for one or more formulas. If we are checking consistency of 
a set of formulas, then we will have to build the tree for all those formulas; we place 
them in the root of the tree. They are all designated as true. The challenge is to see, 
upon completion of the tree, if any path remains open: this means that there is a 
logically possible assignment of truth values to the atomic variables such that the 
p ∙ q +.
↓
p +
q +
p ∨ q +.
↙ ↘
p + q +.
4  Sentential Logic Languages ∑

261
formulas are all true (designated.) The open path records this logical possibility. At 
least one path must be open for the verdict of consistency to be proffered. If we are 
checking validity of a given argument form, we will need to build the tree for the 
following formulas: the premises and the negation of the conclusion. We designated 
all premises and anti-designate the conclusion. If any path remains open, this means 
that there is logically possible truth-value assignment to the atomic variables, such 
that all the premises are true and the conclusion is false (this is how we have con-
structed the check.) This, however, means that there is a counterexample: the assign-
ment that makes all premises true and the conclusion false is called a counterexample, 
as we have already learned in previous chapters. This means that the argument form 
that is under examination is thus shown to be invalid. Indeed, it is significant that 
this method generates the counterexamples, if any such are available. Another way 
of thinking about the validity check by the tree method is this: an invalid argument 
is one in which the premises are consistent with the negation of the conclusion. See 
above how we represented the check of consistency. If at least one path remains 
open in the validity check, this means that the premises (all of which we designate) 
are consistent with the negation of the conclusion (which we anti-designate.) Hence, 
the argument form is invalid. We can also use this tree method to check if one given 
formula is a contradiction; in that case we construct the tree for that one given for-
mula. If no path remains open upon termination of the tree construction, that means 
that the given formula is a logical contradiction. To check if a given formula is a 
tautology or contingency, we need to do a little more; we will discuss that.
Suppose that we have two formulas, one conjunctive and one inclusive-­
disjunctive. Having seen the above examples, let us discuss this rudimentary 
construction. 
This constitutes the root of our tree. The formulas will have to be given to you. 
Our tree will show us all the logical possibilities for the given formulas to be all true. 
Remember, any formula on a tree is recorded as true. An important lesson: if there 
is a tilde in front of a formula, then the whole – negated – formula is true: therefore, 
the formula that is negated is recorded as false. You might need to concentrate on 
grasping this and making sure that you are familiar and comfortable with this. In our 
given tree above, we will work on the conjunction and on the inclusive disjunction. 
Regardless of the order in which the root-formulas are given, it is a good strategy to 
first do the vertical branches and subsequently apply the splitting branches. Students 
often ask if this is crucial and decisive – in the sense that violating this instruction 
changes the results: it does not change the results; this is only a strategic tip meant 
to prevent too much cluttering with proliferating branches and multiple paths all 
over. Try now to learn and retain another important instruction. When we work on a 
p ∙ q +.
p ∨ q +.
4.5  Other Natural Deduction Systems

262
formula, the information in this formula will have to go underneath every path that 
is still available.
Here is what our tree for the formulas given above looks like.
We don’t object to repeating the same information, if it comes to that; in fact, we 
cannot prevent it and should not want to: this tree-method is mechanical. As you 
will find out, we apply rules blindly. You may be able to discern that we are applying 
some rules – in our example so far, one rule for conjunction and another rule for 
inclusive disjunction.
What if we worked on the disjunction symbol first? This is what our resulting 
tree would look like.
In both cases, we have the same recording of logical possibilities. The tree shows 
us the logically possible cases in which the given formulas are all true. By cases we 
mean: assignments of truth values (true or false) to the ultimate individual variable 
letters. Let us read this information up the paths of the tree above. The two paths, 
from top to bottom, are:
<p ∙ q, p ∨ q, p, p> and <p ∙ q, p ∨ q, q, q>.
The root, and possibly other lines, are shared by more than one path. In the first 
tree we constructed above, when we first operated on the conjunction, the paths were:
<p ∙ q, p ∨ q, p, q, p> and <p ∙ q, p ∨ q, p, q, q>.
In that case, both the root and <p, q> are shared by both paths. It is important to 
become comfortable with this diagrammatic setup and to be able to discern the 
paths of a tree.
p ∙ q +.
p ∨ q +.
↙↘
p + q +.
↓ 	
↓
p + 	  q +
p ∙ q +.
p ∨ q +.
↓
p +
q +
↙↘
p + q +.
4  Sentential Logic Languages ∑

263
We will show now another example of what a finished tree for a given formula 
looks like. You will not be able to understand this but look at the explanations given 
at the margin to alert yourself as to what you need to learn.
We are given the formula:
We will construct the tree for this formula, ∑↙↓↘ (~ (p ∨ ~ (q ∙ r))). But, 
remember, we can construct the tree for more than one formulas. The capital letter 
“R” denotes a rule; the label for the rule is given by the entire metalinguistic sym-
bolic arrangement with “R” suffixed at the end. Following the label for the rule that 
has been applied, within parentheses, we include the numerals labeling the lines on 
which the rule has been applied. The designation symbol “plus” and the anti-­
designation symbol “minus” are considered as applied on the entire well-formed 
formula to the left.
~ (p ∨ ~ (q ∙ r)).
	1.	 ~ (p ∨ ~ (q ∙ r)) +	
	
Root
↓
	2.	 p ∨ ~ (q ∙ r)) -	
	
~+R (1)
↓
	3.	 p -	
	
	
	
∨−R (2)
	4.	 ~ (q ∙ r) -	
	
	
∨−R (2)
↓
	5.	 q ∙ r +	
	
	
~−R (4)
↓
	6.	 q +	 	
	
	
∙+R (5)
	7.	 r +	 	
	
	
∙+R (5)
For instance, reading the above: we obtained line 2 by applying the rule ~+ on 
line 1. Designating the given formula is at the root of the tree. The formula has the 
tilde as the main connective symbol: designating a tilde-formula means that we omit 
the tilde and anti-designate the remaining formula: this is because negating true is 
false, as we know.
Line 3 comes from application of ∨−R on line 1. Apparently, this rule will 
instruct us to produce vertical branches and two of them indeed. Negating a disjunc-
tion yields two negated formulas which correspond to the disjuncts of the formula 
that is negated: we have encountered this law of the standard logic as one of the 
instances of the DeMorgan Law. Line 4 was obtained from application of the same 
rule on the same line – this is the other negated disjunct. Line 5 is obtained from line 
4: anti-designating negation yields a designated formula: indeed, negation of nega-
tion cancels – the double negation is eliminable, which a crucial characteristic of the 
4.5  Other Natural Deduction Systems

264
standard logic and if this rule to eliminate double negation is withdrawn, we gener-
ate an entirely different logic. Lines 5 and 7 are obtained from application of the 
pertinent rule for designated conjunction: this is perhaps the most intuitively appeal-
ing and straightforward rule; if the conjunction is designated – true – then it is logi-
cally necessary that both conjuncts are designated – true. The only assignment of 
truth values to the conjuncts that yields true for the conjunction is the assignment of 
true to both the conjuncts. This rule tends to persist throughout a gamut of alterna-
tive logics: it seems, in other words, that conjunction tends to be a rather classically 
behaving connective.
Beginning with the setup of our formal system, we have first to specify the struc-
tural arrangements we make for this tree procedure. We have already said that we 
put the given formula or formulas at the top and in what is considered to be the root 
of the tree. The formulas are designated at the root; an exception is the conclusion 
formula, if we are checking an argument form: the conclusion formula must be anti-­
designated. Also, to check if a given formula is a tautology: we anti-designate it; 
remembering that a contradiction is the negation of a tautology, we anti-designate to 
check for the status of tautology; we designate to check for the status of contradic-
tion. This requires attention and reflection to grasp the mechanics and the justifica-
tion. The closure of all paths of the true for a given formula means that the formula 
is a contradiction: no logically possible assignment of truth values is available for 
making this formula true (hence the designation at the root). Other ways of saying 
this are: the formula is not satisfiable since all the paths of its tree are closed (and 
closure is generated when some individual variable receives both designated and 
anti-designated value on the path.)
In addition to structural instructions about how to commence, with construction 
of the root, we move next to structural instructions about how to proceed: we have 
said that we proceed by applying connectives rules, which we will have to learn. We 
need rules for designated and for anti-designated connectives. We also accept that 
some rules are vertical – generating branches downwards or vertically – and other 
rules are horizontal or splitting – generating a branch to the left and a branch to 
the right.
Finally, we need to know when the tree process is considered to have come to an 
end. Here is the Termination Instruction: a tree is considered to be finished (ended, 
completed, terminated, saturated) only when we have no more connectives rules to 
apply and the formulas we have at the terminal lines are individual or atomic vari-
ables (letters, variable letter) that are either designated or anti-designated. Looking 
at the tree above, it is indeed completed: we happen to have only one vertical path 
(because the rules we had to apply were all vertical) and we have ended with desig-
nated and anti-designated letters; moreover, we have no more designated or anti-­
designated connectives rules to apply. Therefore, the tree has been completed or 
terminated or finished. The single path of the tree is open: no letter is both desig-
nated and anti-designated. Hence, the tree checks or verifies the given formula as 
being satisfiable. It is not a contradiction. We don’t infer, though, that it is a tautol-
ogy. For that check, we would have to anti-designate the formula and construct the 
tree for that anti-designated formula: if it remains open, that verifies that the 
4  Sentential Logic Languages ∑

265
negation of the given formula is not a contradiction either: hence, the formula is 
what we have called a logical contingency (logically contingent formula, logically 
indeterminate, or logically indefinite formula.)
An important structural instruction has to do with determining if a path of a com-
pleted tree is open or close. A path is closed if and only if a designated letter and the 
same letter anti-designated appear on the path. A path is open if and only if it is not 
closed. A tree is closed if and only if all its paths are closed. A tree is open if and 
only if at least one path is open.
Now we can continue with the designated connectives and anti-designated con-
nectives rules. These rules of the system are to be thought of as recipes that instruct 
you how to proceed. We are providing the rules in a “metalanguage”, not in our 
officially adopted formal language. Hence, we are using variable symbols that are 
not in our formal language. Those variable symbols (a box and a diamond) stand for 
any formula, possibly a complex or compound formula. We need to be careful about 
how substitutions into the rules work. This is an initial obstacle that proves to be a 
stumbling block for learners. When we apply the recipe given by a rule, we have to 
be very careful to figure out what goes in for the box and what goes in for the dia-
mond. Example will follow.
Connectives Rules for ∑↙↓↘.
Rules for Connectives.
Vertical Rules	                      Branching (Splitting) Rules
~+rule.
~ □ +.
↓
□ –
~−rule.
~ □ –.
↓
□ +
∙+rule 	
	
	
	
	
∨+rule
□ ∙ ◊ +	
	
	
	
	
□ ∨ ◊ +
↓	
	
	
	
	
	
 ↙ ↘
□ +	 	
	
	
	
	
□ + ◊ +
◊ +
∨−rule	
	
	
	
	
∙−rule
□ ∨ ◊ -	
	
	
	
	
□ ∙ ◊ -
↓	
	
	
	
	
	
↙ ↘
□ -	 	
	
	
	
	
 □ - ◊ -
◊ -
(continued)
4.5  Other Natural Deduction Systems

266
The above are all the connectives-rules we have for the Tree Method. Other rules 
(structural rules) for the Tree Method include: closure – when any designated indi-
vidual variable and the same variable anti-designated are on the same path of a tree 
(following paths from top to bottom), then we consider that path closed. A closed 
path represents a logically impossible assignment of truth values (interpretation, 
valuation, option, case, or modeling.) (Obviously, this path is impossible because it 
records an individual variable – for instance, p – as both true and false!) A tree that 
has all its paths closed is considered to be a closed tree. We indicate closure by plac-
ing the symbol “⊠” underneath the last or terminal node of the closed path. If a tree 
has at least one open (non-closed) path, it is considered to be an open or satisfied 
tree. A completed open path may be indicated by placing underneath the symbol “⊕”.
Termination of a tree is accomplished only when all connectives-rules that can be 
applied have been applied and we have terminal nodes of the tree that are marked 
only by individual variables and negated individual variables. It can be proven that 
all sentential logic trees terminate – no infinite paths in any tree. In higher logics, we 
do run into the issue of possibly getting infinite trees.
The tree method can be used to determine validity/invalidity of argument forms, 
consistency/inconsistency of sets of formulas, and the status of a given formula (if 
it is a tautology, a contradiction, or a contingency.) The tree method, used correctly, 
is guaranteed to give us the right results for the standard sentential logic.
4.7.1 Validity Test by the Tree Method.
To determine if a given argument form is valid by using the tree method:
	1.	 We place the premises at the root of the tree as designated formulas.
	2.	 We add the conclusion formula to the root as anti-designated and add it to the 
premises at the root of the tree.
⊃−rule	
	
	
	
	
⊃+rule
□ ⊃ ◊ -	
	 □ ⊃ ◊ +
↓	
	  ↙ ↘
□ +	
	 □ - ◊ +
◊ -
	
≡+rule
	
□ ≡ ◊ +
	
    ↙ ↘
	
 □ + □ -
	
◊ + ◊ -
	
≡−rule
	
□ ≡ ◊ -
	
   ↙ ↘
	
□ + □ -
	
◊ - ◊ +
(continued)
4  Sentential Logic Languages ∑

267
	3.	 We apply connectives rules to construct the tree for the set of formulas we have 
at the root (the designated premises and the anti-designated conclusion.)
	4.	 We complete the tree: the tree terminates.
	5.	 We inspect the tree. If there is any open path, that path gives us a counterexample 
to the argument form: the given argument form is invalid. To have a counterex-
ample means: there are assignments of truth values to the individual letters of the 
given formulas, for which all the premises are true and the conclusion is false. If 
we read the information up the open path, we find those truth values. Clearly, this 
is a counterexample: Since we made all the premises true (designated) and the 
conclusion false (anti-designated), we have shown that this is possible – we have 
an open path, which shows logical possibility that all the formulas are true (and 
those formulas are the premises and the negated conclusion – hence, we can pos-
sibly have all true premises and false conclusion!) To have a counterexample is 
to have an invalid argument form. We can also say that having an open path (at 
least one, one or more, even one) shows that the argument form is invalid.
	6.	 If all the paths are closed – no paths are open – we say that the tree itself closed. 
This shows that the given argument form is valid: closed tree (all paths closed!) 
shows validity. To justify this: the closing of all the paths shows that there is no 
logical possibility for having all the formulas at the root being true: this means 
that we cannot have all the premises and the negated conclusion being true 
together. Think about it: this means that there is no logical possibility that we 
have all premises true and the conclusion false.
	7.	 Summing up: open tree (at least one path open) shows invalidity; closed tree (all 
paths closed, no path open) shows validity.
4.7.2 Consistency Test by the Tree Method.
The consistency test by implementation of the tree method requires applying all 
the relevant rules for the connectives to the point of saturation (which means that no 
connective symbols are left on which rules can be applied.) Speaking of consis-
tency, and bearing in mind that this is a property of sets of formulas, we can spell 
out the criteria for consistency in terms of the tree of the formulas in the set: the set 
is consistent if and only if there is at least one open path in the completed (saturated) 
tree. The existence of an open path means that there is an assignment of truth values 
to the atomic variables of the given formulas (which label the nodes at the root of 
the tree), for which all the formulas are true. Given that we continue until comple-
tion of the tree, this means that we end with the atomic variables, whether desig-
nated or anti-designated: for those truth values assigned to the occurrences of the 
atomic variables (as indicated, true for designation and false for anti-designation), 
the given formulas are all true. In other words, there is a logical possibility, charted 
by any open path upon completion, that all the formulas in the set are true, which we 
recognize as defining logical consistency in accordance with the definition of this 
concept we have been using repeatedly.
4.7.3 Status Test by the Tree Method.
By logical status we mean if a given formula is a tautology, a contradiction or a 
contingency. 
4.5  Other Natural Deduction Systems

268
We have to figure out, then, how to check for the status of being a tautology or a 
logical contingency. Let’s lay out the mechanism for checking if the given formula 
is a tautology. 
	1.	 We complete the tree for the given formula, which is at the root of the tree 
and designated if we are checking for the status of contradiction; or anti-
designated if we are checking for the status of tautologousness. A status 
test is always for just one given formula.
	2.	 If, upon termination of the tree for a designated formula, there is at least 
one open path (if the tree is not closed), we cannot determine if the for-
mula is a tautology or a contingency. But we know that it is not a 
contradiction.
	3.	 If the tree is closed for a designated formula (all the paths are closed, no 
path is open), then we determine that the given formula is a 
contradiction.
	1.	 We anti-designate the given formula. We place the anti-designated for-
mula at the root of the tree.
	2.	 We complete the tree.
	3.	 If the tree is open, we cannot determine if the formula is a contradiction or 
a contingency. But we do know that it is not a tautology.
	4.	 If the tree is closed (all the paths are closed, no path is open), then we 
establish that the given formula is a tautology. If the tree of the anti-desig-
nated formula is closed, then the given formula is a tautology. This is 
because there is no satisfying path for the given formula: since the formula 
is signed as anti-designated, this means that there is no value assignment 
for which the formula can be false; hence, it is a tautology – for every logi-
cally possible valuation, the formula receives the only other value – besides 
false – which is true.
To check if a given formula is a logical contingency, we have to undergo the 
entire process: we have to check the designated formula itself and then we have to 
check the same formula anti-designated. If the formula-tree closes, then the formula 
is a contradiction. We don’t need to proceed any further. If not, we construct the tree 
for the negated formula: if that closes, then we determine that the given formula is 
a tautology. We don’t need to proceed any further. If not, then we determine the 
given formula to be a contingency. It is neither a tautology nor a contradiction: there 
is no other possible logical status left. It has to be a contingency. Summarizing, the 
logical contingency check is as follows: 
4  Sentential Logic Languages ∑

269
In the example below, we can see that no double-negation rule is needed. 
Applying the rules for designated and anti-designated tilde, we generate the elimi-
nation of the double tilde symbols as shown below.
	1.	 ~ ~ p +
↓
	2.	 ~ p –		
~−R (1)
↓
	3.	 p +	 	
~−R (2)
This is how we can use the tree system to prove: ∑↙↓↘(~ ~ p /.. p)
	1.	 ~ ~ p +	
Premise/.. p
	2.	 p -	
	
Negated Conclusion
↓
	3.	 ~ p –		
~−R (1)
↓
	4.	 p +	 	
~−R (2)
⊠
4.7. Exercises
	1.	 Determine if the following well-formed sentential formula is or is not a contra-
diction. Draw the tree of the formula on the back of the page as it was done in 
the preceding example. Then determine if the formula is a contradiction or not.
~ (p ≡ p)
⇙                     ⇘
We place the formula at the root of the tree as designated.
⇓
We complete the tree for the formula.
The tree closes. 
The tree does not close.
⇓
⇓
The formula is a contradiction.        We anti-designate the formula  
      and place it at the root.
⇓
We complete the tree for the  
formula.
⇙
⇘
The tree closes. 
⇓
⇓
The formula is a tautology. 
The formula is a contradiction.
The tree does not close.
The formula is a contingency.
4.5  Other Natural Deduction Systems

270
	2.	 Determine if the following argument form is valid or invalid. Draw the tree on 
the back of the page, as it was done in the preceding example. Then determine if 
the argument form is valid or invalid.
~ (p ∨ q), ~ p ⊃ s /.. s ∨ t
	3.	 Finish the tree below and determine if the given set of sentential formulas is 
consistent. Also write on the margin the explanation where the question mark is 
placed. [A set of sentential formulas is consistent if and only if their tree is not 
closed – or has at least one open path.]
	1.	 ~ (p ⊃ q)
	2.	 p ≡ ~ q
	3.	 ~ q
↓	 	
	
	
⊃rule applied to line 1
	4.	 p
	5.	 ~ q
↙ 	
↘?
	4.	 Which of the tree paths are closed? Place a “⊠” symbol underneath each closed 
path – where the question marks are placed.
	1.	 ~ ~ p
	2.	 ~ ~ ~ ~ p
	3.	 ~ (p ∨ (p ⊃ p)) ∨ ((p ⊃ p) ⊃ ~ p)
↓
	4.	 p
↓
	5.	 ~ ~ p
↓
	6.	 p
↙ 	
	
	
↘
	7.	 ~ (p ⊃ (p ⊃ p))	
7a. ((p ⊃ p) ⊃ ~ p)
↓	 	
	
	
↙ 	
↘
	8.	 p	
	
	
8a. ~ (p ⊃ p) 8b. ~ p
~ (p ⊃ p)	
	
 	
 ↓?
↓
	 9.	 p	
	
	
9a. p
	10.	 ~ p	 	
	
10a. ~ p
??
	 5.	 Determine whether the following well-formed formulas of sentential logic tau-
tologies, contradictions or contingencies.
	a.	 ⊩∑↙↓↘? ~ (((p ⊃ q) ⊃ p) ⊃ p)
	b.	 ⊩∑↙↓↘? (~ p ⊃ q) ⊃ (~ q ⊃ p)
	c.	 ⊩∑↙↓↘? ((p ⊃ q) ∨ (q ⊃ p)) ≡ ~ ((p ∨ q) ≡ ~ (~ p · ~ q))
	d.	 ⊩∑↙↓↘? ((p ≡ q) ≡ r) ≡ (~ p ≡ (~ q ≡ r))
	e.	 ⊩∑↙↓↘? (p ⊃ (q ⊃ r)) ⊃ (~ p ⊃ (r ⊃ ~ q))
	f.	 ⊩∑↙↓↘? (p ⊃ (p ∨ q)) ⊃ (p ⊃ (~ q ⊃ p))
4  Sentential Logic Languages ∑

271
	g.	 ⊩∑↙↓↘? (p ⊃ ~ q) ⊃ ~ (p ⊃ ~ ~ q)
	h.	 ⊩∑↙↓↘? ((p · q) ⊃ r) ≡ ~ (q ⊃ (p ⊃ r))
	i.	 ⊩∑↙↓↘? ~ (p ≡ q) ≡ ((p ∨ q) · (p ⊃ q))
	6.	 Determine if the following argument forms are valid or invalid.
	a.	 (p ⊃ q) ⊃ p ⊩∑↙↓↘? p
	b.	 (p ⊃ q) ⊃ r, q ⊩∑↙↓↘? r
	c.	 (p ⊃ q) ⊃ r⊩∑↙↓↘? (q ⊃ r) ∨ (r ⊃ (q ⊃ r))
	d.	 (p ⊃ q) ⊃ q ⊩∑↙↓↘? p ∨ ((p ⊃ q) ⊃ p)
	e.	 p ⊃ (p ⊃ (q ⊃ p)) ⊩∑↙↓↘? q ⊃ (q ⊃ (~ q ⊃ p))
	f.	 p ≡ q, p ≡ ~ q ⊩∑↙↓↘? ~ (p ≡ q)
	g.	 ~ (p ≡ q), ~ (q ≡ r) ⊩∑↙↓↘? ~ (p ≡ r)
	h.	 p ⊃ q, ~ q ⊃ r ⊩∑↙↓↘? (p · r) ⊃ q
	i.	 p ⊃ (q ∨ r), ~ q ⊩∑↙↓↘? (p ⊃ r) ∨ (p ⊃ q)
	7.	 Explain how we can use the tree system as a decision procedure for determining 
whether a given set of formulas is consistent or inconsistent and then apply to the 
following given sets of formulas. Supply systematic truth value assignments to 
the atomic variables of the formulas, which satisfy all the formulas, for the sets 
that are determined to be consistent.
	a.	 ⊩∑↙↓↘? {p ⊃ r, p, q, ~ r}
	b.	 ⊩∑↙↓↘? {p ⊃ (~ q ⊃ ~ p), (p ⊃ ~ q) ∨ (p ⊃ q)}
	c.	 ⊩∑↙↓↘? {p ⊃ q, ~ p ⊃ q, q ⊃ ~ p, q ⊃ p}
	d.	 ⊩∑↙↓↘? {(p · ~ q) ∨ (~ p · q) ∨ (q · ~ r) ∨ (~q · r) ∨ (p · ~ r) ∨ (~ p · r),
(p ∨ q ∨ r) · (~ p ∨ ~ q ∨ ~ r)}
	e.	 ⊩∑↙↓↘? {~ (p ⊃ (q ⊃ ~ p)), q ⊃ (~ q ⊃ p), ~ p ⊃ (p ⊃ q)}
	f.	 ⊩∑↙↓↘? {u ⊃ (t ⊃ (~ u ⊃ ~ t)), u ≡ (t · u), (t ∨ (u ⊃ t)) ⊃ (~ u ≡ t)}
	g.	 ⊩∑↙↓↘? {((p ≡ p) ∨ r) ⊃ s, (p ≡ q) ∨ r, ~ s}
	8.	 Construct proofs in ∑|| for the exercises in 4.3.e and 4.4.2.e.
4.5.2  Translations from English into ∑ (also called 
Formalizations, Symbolizations)
Translations of meanings of sentences of a language like English into a formal lan-
guage are to be undertaken for the purpose of facilitating logical analysis. The well-­
formed formulas produced by the translation (also called symbolization and 
formalization) show the logical form of the translated meaning transparently, with-
out ambiguity or superfluous display of logically insignificant elements. Since the 
translation is carried out into a specific formal idiom, only symbols that are avail-
able in this formal idiom can be used: this means that the logical form we discern 
from translating may actually be insufficiently detailed – it may be lacking display 
of logically significant characteristics of the logical form of the translated meaning. 
4.5  Other Natural Deduction Systems

272
For instance, translating into a formal language for sentential logic will not yield 
symbolic characterization of logically important internal parts of sentences: the 
translation can only be of, as we call them, unanalyzed sentences. For instance, 
“Socrates is wise” can only be translated by some atomic (individual, single) vari-
able (which, as stipulated by our grammar, is any capital letter possibly with a sub-
script from the positive integers.) If the validity of an argument form depends on the 
role played by internal parts of sentences, our translation will not allow us to discern 
this: From “Socrates is wise” we ought to derive a valid inference to the conclusion 
“at least one person is wise” but the argument form symbolized in sentential logic 
is as below (with the key “S” for “Socrates is wise” and “A” for “at least one person 
is wise”), and this is not a valid argument form since it may well take interpretations 
with a true premise and a false conclusion:
S /.. A
The translation is undertaken, accordingly, bearing in mind that its effectiveness 
is directly dependent on the available stock of symbolic resources in the formal 
language. Insofar as our purposes are proportioned to this availability (by restricting 
ourselves to the analysis of logical characteristics that can be fully assessed within 
sentential logic), then we reap the benefits of unambiguous and perspicuous 
symbolization.
We will carry out translations into our metalanguage ℳ(∑), which means that 
we have available to us the symbolic resources of ∑ in addition to fitting fragments 
of English. We use capital letters, possibly with subscripts from the positive inte-
gers, to translate the meanings of declarative assertoric sentences of English; we 
have symbols for connectives and parentheses as auxiliary symbols that must be 
used for ensuring that no ambiguous reading of the formula is possible and may not 
be used when no such risk exists. A treacherous enterprise is to determine what parts 
of the logical structure of a sentence are truth-functional: this means that such ele-
ments match symbolic resources available within sentential logic – while non-truth-­
functional elements cannot be translated and the situation is as if the formalism we 
have in sentential logic cannot “see” such parts. Indeed, we have some rough sur-
mising we can make as to how our connectives can be matched with logic-words 
and logic-phrases in language (like “not,” “either-or,” “if-then,” and “if and only if”) 
but we should be able to translate any truth-functional linguistic item. To do this, we 
bear in mind:
	1.	 A connective symbol may be correctly matched to more than one logical phrases 
in language. All that matters is: the truth conditions under which sentences with 
such logical phrases are true/false. By conditions we mean assignments of true/
false (truth values) to the atomic sentences that are combined. For instance, the 
binary connective that we use for conjunction has the following truth conditions: 
the complex sentence generated by conjoining two sentences (for instance, ⌜A ∙ 
B⌝) is true if both components (⌜A⌝ and ⌜B⌝) are true; it is false in every other 
case, for every other combination of assignments of true/false to the components 
(with such combinations being true/false, false/true and false/false.) Any logical 
phrase in the language that shows this logical behavior can be correctly trans-
4  Sentential Logic Languages ∑

273
lated, and must be translated, by the symbol dot. Such logical phrases abound. 
For instance, “however” connects the sentence that contains this expression with 
the previous sentence so that the complex of the two sentences is true only if 
both are true and it is false in every other possible case. This shows that “how-
ever” behaves as a logical phrase in the same manner in which “and” behaves. 
The aspect of contrast that is created rhetorically by means of using “however” – 
which, contrast, is not generated by using “and” – is significant but not in such a 
way that it can affect the logical characteristics (at least, the truthfuctional logi-
cal characteristics) of the compound sentence.
	2.	 In our sentential formal language, we may combine formulas by placing connec-
tive symbols in grammatically appropriate places in order to generate further 
compound or complex formulas – and this may continue on and on. We take 
advantage of this to symbolize such truth-functional logical phrases as “not 
both” or “neither---nor.” There are definable truth-functional connectives in the 
sentential logic that can be chosen, which directly match the logical behaviors of 
the above phrases. We show below how we can define them by using the truth-­
tabular method. But these logical connectives (although truth-functionally defin-
able) are not available in our formal language: hence, we must use combinations 
of the symbols we do have in order to carry out the translation. We show how we 
can do this.
NOT-BOTH.
p
q
p
|
q
symbol “|” for the “not-both” connective: this connective is 
known as the Sheffer Stroke
T
T
F
F
T
F
T
F
F
T
T
T
if both ⌜p⌝ and ⌜q⌝ are true: NO
since not both components are true: YES
since not both components are true: YES
since not both components are true: YES
NEITHER-NOR (not-p and not-q).
p
q
p
↓
q
symbol “↓” for the “neither-nor” connective: this connective is 
known as the Peirce Arrow
T
T
F
F
T
F
T
F
F
F
F
T
since both ⌜p⌝ and ⌜q⌝ are true: NO
since one of the components is true: NO
since one of the components is true: NO
since both components are false: YES
Not having the symbols {|, ↓} in our stock of symbols, we have to translate “not 
both” and “neither-nor” periphrastically  – by using combinations of available 
symbols:
•	 Not both p and q: ~ (p ∙ q)
•	 Neither p nor q: ~ p ∙ ~ q
4.5  Other Natural Deduction Systems

274
Another interesting case is that of the exclusive “either-or.” The “either-or” we 
have matches the inclusive sense of the “either-or” of language: the exclusive sense 
“either p or q” compels that exactly one of the combined sentences is true: one or 
the other is definitely true but both cannot be true (a choice is made!) We show, 
again, the truth table that defines the available (mathematically definable) connec-
tive that matches the exclusive “either-or” and subsequently we show periphrastic 
translation schemata for rendering “either-or”, which use combinations only of our 
available symbolic resources.
EXCLUSIVE EITHER-OR.
p
q
p
≢
q
symbol “≢” for the exclusive “either-or” connective: this 
connective is known by names such as Disequivalence and 
Boolean Addition
T
T
F
F
T
F
T
F
F
T
T
T
if both ⌜p⌝ and ⌜q⌝ are true: NO
since one component is true but not both components are true: 
YES
since one component is true but not both components are true: 
YES
since both components are false: NO
Either p or q but not both:
•	 (p ∨ q) ∙ ~ (p ∙ q)
•	 (p ∙ ~ q) ∨ (~ p ∙ q)
•	 (p ∨ q) ∙ (~ p ∨ ~ q)
Use of Parentheses
•	 It is crucial to use parentheses to prevent any ambiguity from arising in reading 
the formula that renders the translation. Ambiguity is a common linguistic phe-
nomenon: it may be used creatively but it represents a logical pathology. 
Ambiguity arises when more than one meanings can be assigned to a sentence by 
the competent user of language and it is not evident which one of the meanings 
is intended by the presenter of the sentence.
•	 Parentheses (the auxiliary symbols that are available in our formal grammar) 
are to be used to prevent ambiguity. They may not be used for any other rea-
son – which means that, if no risk of ambiguity arises, parentheses may be 
omitted. Some formal grammars legislate conventions for the purpose of 
economizing on the use of parentheses but we will not do this here.
•	 Consider the formula, ⌜ A ⊃ B ∨ C⌝: this has the following possible logical 
meanings, which are not mutually equivalent. More precisely, the logical 
forms exemplified by the two possible translations below are not logically 
equivalent to each other. To be logically equivalent, two formulas must 
4  Sentential Logic Languages ∑

275
take exactly the same value (true or false) as output for all assignments of 
true/false to their component individual sentence-variables. This is not the 
case in this example; therefore, there are two distinct logical senses and it 
is not clear which one is presented. Both translations must, then, be given: 
this is what we have called “disambiguation.”
•	 A ⊃ (B ∨ C)
•	 (A ⊃ B) ∨ C
•	 We don’t write ⌜~ (A) ⌝: there is no ambiguity arising from this omission. 
Notably, we must also say that we consider the tilde to be “binding” more 
closely than any other connective symbol. To understand what this means 
consider:
•	 ⌜~ A ∨ B ⌝ cannot be confused with ⌜ ~ (A ∨ B)⌝ because the scope of the 
tilde is always taken as the individual variable symbol that follows (unless 
parentheses are used to enclose symbols and “make them like one.”)
•	 We may omit external or outside parentheses since no risk of ambiguity arises 
from this.
•	 Inclusive Disjunction, Conjunction and Equivalence (Biconditional) are tran-
sitive (have the transitive property.) This has consequences for how we can 
liberalize our symbolic conventions. To see what we mean by transitivity (or 
the transitive property), let us consider that the familiar addition and multipli-
cation of standard arithmetic are transitive and this means that we may omit 
parentheses without confusion as to the scope of each operation symbol. Let 
us consider:
•	 1 + (2 + 3) = (1 + 2) + 3 = 1 + 2 + 3
•	 1⨯(2 ⨯ 3) = (1 ⨯ 2) ⨯ 3 = 1⨯ 2 ⨯ 3
•	 Transitivity can be thought of, itself, as a parentheses-shifting license. 
Omission of parentheses can then be practiced without engendering ambi-
guity. Accordingly, we may omit parentheses for formulas that have as 
main symbols the wedge, the dot or the triple bar (but not the horseshoe 
because material implication is not transitive!) Notice that, in our logic, the 
equality symbol is replaced by the symbol for equivalence 
(biconditional.)
•	 (A ∨ (B ∨ C)) ≡ ((A ∨ B) ∨ C) ≡ (A ∨ B ∨ C)
•	 (A ∙ (B ∙ C)) ≡ ((A ∙ B) ∙ C) ≡ (A ∙ B ∙ C)
•	 (A ≡ (B ≡ C)) ≡ ((A ≡ B) ≡ C) ≡ (A ≡ B ≡ C)
•	 If a sentence of English, which is offered for symbolic translation, is ambigu-
ous, then we must enforce disambiguation: this means that we are compelled 
to offer all possible formal translations as alternatives without committing to 
any one of those renderings.
•	 The number of right parentheses must be equal to the number of left parenthe-
ses in any well-formed formula of ℳ(∑). Conversely, any formula or sym-
4.5  Other Natural Deduction Systems

276
bolic expression that lacks this characteristic is to be considered not 
well-formed – or ill-formed – and cannot be “scanned” or is tantamount to 
nonsense.
Nontruthfuctional Logical Phrases
•	 We lack resources for translating the following non-truth-functional expressions. 
This is not an exhaustive list. In all these cases, we don’t have a symbol for the 
non-truth-functional operator and, so, we have to translate by some single vari-
able letter, ⌜P⌝. This applies in the cases also in which the non-truth-functional 
phrase is not unary!
•	 necessarily A
•	 possibly A
•	 probably A
•	 it is morally obligatory that A
•	 it is morally permissible that A
•	 it is morally forbidden that A
•	 it is legally forbidden that A – etc.…
•	 it was true once in the past that A
•	 it has been always true that A
•	 it will sometime in the future be true that A
•	 it will forevermore be true that A
•	 A was true before B was true – this too has to be translated by a single 
variable letter
•	 A being true necessitates that B be true - this too has to be translated by a 
single variable letter
•	 Etc…
•	 To see more deeply what we mean by non-truth-functional let us consider an 
attempt to provide truth-functional definitions, by using truth tables, for some 
non-truth-functional operators: these attempts are going to fail badly and we 
explain why.
A
B
Any triangle has three angles.
The capital of the US is Washington, DC..
TRUE
TRUE
NECESSARILY TRUE
NOT NECESSARILY TRUE
There are logical-philosophical disputes, and fascinating debates, about how 
exactly to define logical necessity and possibility but let us try: the meaning of a 
declarative sentence is logically necessary if and only if it is true or false (it obtains 
its truth value) on the basis only of the meanings of words in it (including logic-
words and phrases, like “not” and “and,” and non-logical words like “triangle” and 
“angle.” Thus, logical necessity is, on this approach, analyticity (a concept we elab-
orated on in 1.4.) Logical truths are logically necessarily true and so are analytically 
true meanings like the meaning of the sentence “a triangle has three angles.” What 
is significant for our present examination is that the meaning of the sentence “the 
4  Sentential Logic Languages ∑

277
capital of the US is Washington, DC” is not determined as true or false either by the 
meanings of the logic-words in it (or by virtue of its logical form, we might also 
say), or by the meanings of its non-logical words like “capital” and the names 
“Washington, DC” or “US.” Intuitively, we can think of alternative histories in 
which some other city had been established as the capital of the US. It is not a matter 
of logical necessity that Washington, DC, should be the capital. Special attention is 
needed at this point because people show a marked and instinctive attachment to 
what is actual – taking it also as “necessary” but this species is not logical necessity 
since the sentence, in our example, could logically be false (even if in an alternative 
story of possible world) and thus is not logically necessarily false. We should think 
for our purposes of actuality as one among an open number of logical possibilities. 
Now we can see the consequences of this distinction for our current purpose of 
discussing truth-functionality. We continue to work with the sentences we have 
symbolized by “A” and “B.”
A
B
Any triangle has three angles.
The capital of the US is Washington, DC.
TRUE
TRUE
NECESSARILY TRUE
⇓
NOT NECESSARILY TRUE
⇓
assuming that “necessarily” can be captured by 
some function whose symbol is “∟”
assuming that “necessarily” can be captured by 
some function whose symbol is “∟”
A       ∟A
    T      T
A       ∟A
     T       F
In one case, applying the operator symbol we should expect an output “T” since 
it is the case that the meaning is necessarily true while also being true; but in the 
other case, while true, the meaning is not necessarily true and, so, we must place “F” 
for the output of the operator symbol.
If we take the negations of these sentences: they are false but, again as before, the 
negation of the (meaning of the) triangle-sentence is necessarily false whereas the 
negation of the meaning of the sentence about the capital of the US is not necessar-
ily false (for the same reasons that have been given.)
If we, then, try to construct the truth-tabular definition of the presumed truth-­
functional operator for logical necessity, we run into an absurd result as shown below:
p
q
T
F
T/F  ?
T/F  ?
Under the assumption that our operator is truth-functional, there is, by definition, 
the expectation that a unique output is definable for every specified input from the 
set {T, F}. Hence, we run into absurdity since we need to assign both T and F! It 
follows that “logically necessarily” is not truth-functional. See below examples that 
show why “before” is not a truth-functional binary connective.
4.5  Other Natural Deduction Systems

278
A
B
Ronald Reagan is President of the US in the 
period ----.
Bill Clinton is President of the US for the 
period ---.
TRUE
TRUE
A before B
A before B
TRUE
⇓
FALSE
⇓
assuming that “before” can be captured by 
some function whose symbol is “β”
⇓
assuming that “before” can be captured by 
some function whose symbol is “β”
⇓
A β B = T β T = T
B β A = T β T = F
In one case, when the inputs are <T, T>, the output is <T> but in the other case 
when, again, the inputs are <T, T> the output is <F>. All that matters from the truth-­
functional point of view is the specification of the truth values that are inputs in the 
definition of the connective; according to this, we cannot establish a unique or truth-­
functionally specific output.
•	 It is interesting that, if we attempt to translate what seem like negated sentences, 
with the negation inside the scope of a non-truth-functional logic-word, we 
should not treat this as a negation after all. For instance, an example like “it is 
necessarily not the case that a triangle have two angles” presents a sentence with 
the “not” logical-particle inside the scope of “necessarily” which is not a truth-­
functional word, as we have explained. The meaning of this sentence is not logi-
cally equivalent with “it not necessarily the case that a triangle have two angles”; 
it is logically equivalent with the meaning of “it is not possible that a triangle 
have three angles” with “possibly” also being a non-truth-functional logical 
word. We must, then, translate by using a variable letter – not a negated vari-
able letter.
•	 We cannot give an exhaustive list of non-truth-functional words but we may 
indicate some characteristic cases in a tentative list:
4  Sentential Logic Languages ∑

279
(continued)
Non-truth-functional 
Logic-words [placed inside 
metalinguistic box-symbols]
Metalinguistic 
Symbolizations of 
the Non-truth-­
functional (NTF) 
Operator
{cannot be 
translated into our 
symbolic resources}
∑−translations
[The key that is used is obvious – but 
do not think that we determine our 
translation by just omitting the NTF 
operator symbol: what we do is 
straightforward translating into our 
symbols from ∑: it is a coincidence, 
let’s say, that we use the same symbols 
in some instances.]
It is logically possible that God 
exists.
It is logically possible that God 
exists only if the definition of 
the concept “God” does not 
entail logical absurdity.
If there is a valid and sound 
proof, with no empirical 
premises, that God exists, then 
it is logically necessary that 
God exists.
◊ G
◊ G ⊃ ~ A
P ⊃ □ G
G
G ⊃ ~ A
@We catch an early glimpse of how to 
translate “only if”, which is, of course, 
truth-functional
P ⊃ G
““notice that we don’t regard the 
conjunctive clauses (regarding valid 
proof, sound proof, etc.) to be 
logically distinct sentences: that would 
mean that there are possibly distinct 
proofs one of which is valid, one is 
sound, etc.…
“The moon is green” entails 
that “at least one thing is 
green.”
□ (G ⊃ A)
E
+interestingly, our horseshoe symbol 
is not a good candidate for translating 
“entails” or “rigorously proves” or 
“necessitates drawing a conclusion….”
There was once a great deluge.
Statement A is logically 
necessarily true if and only if it 
has always been true and is now 
true and will always be true. 
(The Diodorean definition of 
logical necessity as a semantic 
property – objectionable.)
𝑃 D
□ A ≡ (𝐻 A ∙ @ A ∙ 
𝑊 A)
𝑃
A ≡ (H ∙ N ∙ W)
It is logically indeterminate 
whether A is true and it is 
logically indeterminate whether 
false.
⍋A ∙ ⍋~ A
I1 ∙ I2
It is legally forbidden to steal.
It is morally permissible to ask 
for help.
It is morally obligatory not to 
torture animals.
𝑓S
<H>m
[~ T]m
S
P
O
*the negation is within the scope of 
the NTF operator
4.5  Other Natural Deduction Systems

280
It is not morally permissible to 
torture animals.
~ <T>m
~ P
** here we have the option of “seeing” 
the negation because the negation is 
not within the scope of a NTF operator
It is probable that you draw an 
ace.
You might draw an ace.
𝑝A
𝑝A
A
A
The earth shook before the 
building fell.
The building feel after the dog 
hauled.
E β F
F 𝛼 D
B
A
Sadly, we had to leave.
𝜍⫪L
S
It is physically impossible for a 
body to move with a speed that 
exceed the speed-of-light 
constant.
~ ◊pM
I
~ P
^We have the option of translating 
with one sentence or by negating the 
symbol for the sentence “a body 
moves with ….” Since we need to 
specify in our key what the negated 
sentence is (notice that “any” changes 
to “some”), we might compel the 
single-sentence translation.
4.5.3  Simple and Compound Sentences
This is an appropriate juncture for approaching a subject that is vital for translat-
ing into a formal language like ∑. We need to be able to recognize whether we 
are expressing through our translation a simple (individual, single, atomic) state-
ment or a complex (compound) one. Based on what we have already presented, 
a meaning expressed by a sentence could be compound under the proviso that 
non-truth-­functional parts are regarded but, if we have to ignore the non-truth-
functional items because we lack the symbolic resources, then we may have a 
simple statement that we are translating. Recognizing whether a meaning 
expressed by an English sentence is, for our purposes, simple of compound is a 
task that is, clearly, indispensable and is part of the activity of symbolic transla-
tion. Here are examples.
(continued)
4  Sentential Logic Languages ∑

281
Sentence
# TF logic-words: 
italicized. /
NTF logic-words: 
boxed-in.
Simple or 
Compound?
Analysis of Logical Structure
Truth-functionality: Whether the compound 
statement is true or false depends strictly and 
systematically on the values (true/false) of the 
component-simple sentences.
It is known without 
depending on 
experience that 
everything is 
identical with itself.
Simple
NTF logic-word: “it is known without depending 
on experience.”
Although Mary is a 
good student, John 
is not.
Compound
“Although” has the same logical sense as “and”: the 
compound sentence is true or false depending on 
the truth values of the component sentences in the 
same ways exactly in both cases (for “and” and for 
“although.”)
No one lied.
It is not the case 
that someone lied.
Simple
Alternatively:
Compound – 
negating “someone 
lied.”
We do not have symbolic resources for representing 
internal parts of statements: we can only translate 
unanalyzed meanings.
The meaning of the sentence we are given is a 
negation of “someone lied”: if we specify in our 
key that we have the statement “someone lied” then 
we can regard the given sentence as compound.
John and Mary are 
students.
Mary and John 
perform a comedy 
act.
Compound
Simple
*the point is, in usual 
contexts, that they 
perform together, not 
separately!
John is a student and Mary is a student.
Mary-and-John perform a comedy act.
$there may be a definable modal (non-truth-­
functional) operator whose definition we can 
motivated by this example: in that case, 
symbolizing the NTF operator by “⍟”:
J ⍟ M
Socrates is unwise.
Simple
This is not the negation of “Socrates is wise:” the 
sentence expresses attribution of an intrinsic 
characteristic; on the other hand, it could be true 
that “Socrates is wise” is false sometimes without it 
being also true that “Socrates is unwise” as a matter 
of a systematic characterization.
Batman can not fly.
It is not physically 
possible that 
Batman flies.
Simple
Even though negating “Batman can fly” we have a 
TF negation-connective, we should not regard this 
as compound (a negation) for the same reason as in 
the preceding example.
It is possible that 
there is no life in 
Alpha Centauri.
Simple
Even though we have a TF negation word, this 
word is within the scope of the NTF logic-word 
“possible” (which, by the way, is ambiguous, as 
stated, between denoting physical or logical 
possibility.)
Before she goes to 
bed, Mary brushes 
her teeth.
Mary brushes her 
teeth and goes to 
bed.
Simple
Simple
“Before” is NTF: we may symbolize 
metalinguistically, using a symbol as in the 
preceding section. [Teeth brushed (T) before going 
to bed (B).]
T β B
In the second example, “and” means “before” in 
most contexts: it is NTF even though the English 
word is “and” in this case too.
4  Sentential Logic Languages ∑

282
Observations Regarding the Negation Symbol
•	 Obviously, English sentence contain the negation-particle internally, in various 
positions as in: “we don’t have school” or “it will not be warm tomorrow.” From 
a logical point of view, negation is applied to the entire meaning that is negated 
or logically denied: “it not the case that ---“, with the negated sentence symbol 
placed in the placeholder-variable place occupied by the dashes. This should not 
cause any confusion in translation. It is significant that negations are, therefore, 
compound and not atomic (simple) formulas from a logical standpoint.
•	 When a “negative” quality is attributed to some entity, this is not to be taken as a 
logical negation. The sentence “Socrates is fearless” should not be taken as the 
negation of the sentence “Socrates is fearful.” In other cases, this might not be so 
obvious but the point remains that negative qualities – called “negative” in a dif-
ferent sense from “negative” applying to logical negation – are attributed as such. 
It may be possible that someone lacks a quality like “unlikable” without having 
the quality “likable” either (reaction to this individual may be judged as a matter 
of indifference.) Therefore, once again, we should be translating such cases with 
negations of sentences.
4.5.4  Observations Regarding the Disjunction Symbol
There are two different senses carried by the single expression “either-or” in most 
languages: there is the inclusive disjunction sense (for which, at least one of the 
conjoined sentences must be true and both may be true too) and the exclusive dis-
junction sentence (for which one of the conjoined sentences must be true but not 
both can be true – a choice is demanded, or exactly one of the conjoined sentences 
is true.) Context in linguistic presentations may remove ambiguity as to which 
sense – inclusive or exclusive – is intended. We show schemata for translations and, 
to rouse interest, schemata for logically equivalent expressions (although, it should 
be noted, translations should track the logical form of the stated meaning as closely 
as possible.)
•	 Inclusive: p ∨ q, ~ (~ p ∙ ~ q), ~ p ⊃ q, ~ q ⊃ p
•	 Exclusive: (p ∨ q) ∙ ~ (p ∙ q), (~ p ∙ q) ∨ (p ∙ ~ q), (p ∨ q) ∙ (~ p ∨ ~ q), ~ (p ≡ q), 
~ ((p ⊃ q) ∙ (q ⊃ p))
Observations Regarding the Horseshoe Symbol
•	 Our symbolic resource for material implication, the horseshoe, is not satisfactory 
for translating the “if-then” of language in its usual senses but it should be con-
sidered adequate insofar as our purposes for using our formal instrument are 
clearly circumscribed.
•	 A ⊃ B
•	 ⌜ A⌝ occupies the antecedent position and ⌜B ⌝ occupies the consequent posi-
tion: we need to become accustomed to using “antecedent” and “consequent” 
respectively for the formulas to the left and right of the horseshoe symbol.
4  Sentential Logic Languages ∑

283
•	 ⌜A ⌝ expresses the sufficient condition for ⌜B ⌝ to be true. This is a logically suf-
ficient condition – it is not about what causes or “makes” what to happen. The 
point is that if ⌜A ⌝ is true and the conditional ⌜A ⊃ B ⌝ is true, then ⌜B ⌝ cannot 
be false – has to be true as a matter of logical necessity.
•	 ⌜B ⌝ expresses the necessary condition for ⌜ A⌝ to be true, something that is 
expressed in legalistic and other formal idioms by the phrase “but for B, A would 
not have happened.” Again, this is not about cause-effect or any other empirically 
verified connection; it is a matter of the logical relation between the meanings 
expressed by ⌜ A⌝ and ⌜B. ⌝ To grasp this thoroughly, let us consider the 
following.
•	 (A ⊃ B) ≡ ~ (A ∙ ~ B)
•	 The two expressions are logically equivalent, above. If it is the case that ⌜ A⌝ 
implies ⌜B ⌝, then it not logically possible that ⌜A ⌝ is true and ⌜B ⌝ is false. 
Now, we can focus and understand the necessary condition theme better.
•	 As an example, let us consider:
•	 But for the dropping for the package, the explosion would not have happened. =
•	 The dropping of the package is the necessary condition for the explosion. Thus, 
the symbol for “dropping the package” (specified as “D” in our key) must be 
placed after the horseshoe and the symbol (specified as “E”) for “the explosion 
happened” must be placed before the horseshoe. We need to remember that the 
variable expressing the necessary condition is always after the horseshoe and the 
variable expressing the sufficient condition is always placed before the horseshoe.
•	 E ⊃ D
•	 If explosion, then dropping.
•	 The necessary condition is expressed by the symbol in the consequent position. 
The conditional statement is equivalent with the following negation:
•	 ~ (E ∙ ~ D)
•	 It is not logically possible for explosion and not-dropping-­package: hence, but 
for the dropping of the package, no explosion. Consider also the following for-
mula that is logically equivalent with the given conditional (this is called the 
contrapositive of the given conditional), which makes perspicuous the logical 
relation: no-dropping-no-explosion.
•	 ~ D ⊃ ~ E
•	 In language, the necessary condition is introduced sometimes by “only if.” It is 
crucial to remember that “only if” introduces the consequent of the implicative 
statement!
Note the following important directives for translating logical phrases of 
English – including “if-then,” “only if” and “if and only if” sentences, and including 
the troublesome “unless” sentences:
•	 If A, then B: A ⊃ B
•	 A, if B: B ⊃ A
•	 A, only if B: A ⊃ B
•	 Only if A, B: B ⊃ A
•	 A is the sufficient condition for B to be true: A ⊃ B
4  Sentential Logic Languages ∑

284
•	 A is the necessary condition for B to be true: B ⊃ A
•	 Provided that A, B: A ⊃ B
•	 Given that A, B: A ⊃ B
•	 It must be A if B: A ⊃ B
•	 Insofar as A, then B: A ⊃ B
•	 DISTINGUISH: A if and only if B: A ≡ B
•	 “if and only if” is not used in common language; this phrase may be used for 
emphasizing the strength of conviction in “if A, then B”; it is a staple phrase 
in textbooks and it is used to present definitions or connections between sen-
tences both of which depend for their meaning only on defined concepts: for 
instance,
•	 A triangle has three triangles if and only if its angles add up to 3600.
•	 A and B; both A and B, A, but B; A, however B: A, on the other hand B, A, nev-
ertheless B, etc.: A ∙ B
•	 Neither A nor B: ~ A ∙ ~ B
•	 Not both A and B: ~ (A ∙ B)
•	 Either A or B, but not both: (A ∨ B) ∙ ~ (A ∙ B)
•	 A unless B:
•	 This is a recalcitrant translation, albeit a staple in introductory logic textbooks. 
Here we run against the limitations imposed on us by the truth-­functional char-
acter of our logical formalism and by the meaning-relationships that are estab-
lished by the definitions of our connectives. Thus, ⌜ A ∨ B⌝ is logically 
equivalent with ⌜ ~ B ⊃ A⌝ which seems to be a fair candidate for translating 
“A, unless B” as “if not-B, then A.” Hence, we may accept ⌜ A ∨ B⌝ even 
though, it is immediately obvious from the definition of the inclusive disjunc-
tion that the whole sentence is true even if both ⌜ A⌝ and ⌜B ⌝ are true – which 
is not intended by making the statement “A unless B.” Depending on context, 
we make exercise discretion in translating – sometimes rendering the phrase 
by formulas that are logically equivalent not to inclusive disjunction but to 
what is known as contrariety (“not both A and B”) or exclusive disjunction (“A 
or B but not both”). Candidates for translating “A unless B” are shown below:
•	 B ⊃ ~ A
•	 ~ B ⊃ A
•	 A ∨ B
•	 ~ (A ∙ B)
•	 (A ∨ B) ∙ ~ (A ∙ B)
4  Sentential Logic Languages ∑

285
Exercises
	1.	 Which of the following sentences express truth-functionally simple, and which 
express truth-functionally compound, statements? Pay attention to the task of 
identifying the main connective of the statement.
	
a.	 If an argument form is valid, then it cannot have instances in which all the 
premises are true and the conclusion is false.
	
b.	 It is a matter of logical necessity that everything is identical with itself.
	
c.	 Unless unemployment drops, the president risks not being reelected.
	
d.	 Neither did it rain, nor did it snow.
	
e.	 The thunder is heard after the lightning is seen.
	
f.	 It is not permissible to drive faster even it is true that everyone else is.
	
g.	 It is not legal to exceed the speed limit.
	
h.	 Those who don’t try don’t succeed.
	
i.	 Only those who try succeed.
	
j.	 It is known that some succeed without trying.
	2.	 We use capital letters, uninterpreted in terms of linguistic statements. Provide 
well-formed formulas that show the connective symbols needed for the form. 
Subsequent to doing this, try your own interpretations for the capital letters in 
your form. As usual, watch out for non-truth-functional expressions. Of course, 
some of the argument forms can be contradictions or tautologies.
	
a.	 A only if neither B nor C.
	
b.	 Only if A, B.
	
c.	 A, but also B, even though it is not the case that not-C.
	
d.	 If A, then it is also A even provided that B.
	
e.	 If not-A, then, if not B not-C.
	
f.	 Provided that A, then B provided that C.
	
g.	 It should be that if not-A then not-B.
	
h.	 If, given A it follows that B, then it should be that given not-A it follows 
that not-B.
	
i.	 If X but not-Y, then Z if and only if W, but not-W if not-X.
	
j.	 The sufficient condition for B to be a necessary condition for C is A.
	
k.	 If D, then it ought to be known that D.
	
l.	 If it is not proven definitely that A, then it is not the case that A.
	
m.	 A or B but not both.
	3.	 Given the provided key, translate back into English the given well-formed sym-
bolic expressions. Attempt as much as you can to render eventually in English 
that sounds competently grammatical. For example, you could render ⌜ A ∙ B ∙ 
C ∙ D ∙ E⌝ by “everyone comes to the party.” Is it always possible to avoid lin-
guistic awkwardness in rendering the expressions? Why, do you think, that is the 
case? Consider, also, as a separate exercise rendering by using the expression 
“only if” even though the logic of this expression may not be easily grasped by 
logically untrained users of the language.
4  Sentential Logic Languages ∑

286
Key:
--A: Aston comes to the party.
--B: Brenda comes to the party.
--C: Clara comes to the party.
--D: Dwayne comes to the party.
--E: Electra comes to the party.
	
a.	 A ∙ B ∙ ~ C ∙ D ∙ ~ E
	
b.	 ((A ∨ B) ∙ ~ (A ∙ B)) ⊃ ((C ∨ E) ∙ ~ (C ∙ E))
	
c.	 (A ∙ B ∙ C ∙ D ∙ E) ≡ ~ (~ A ∨ ~ B ∨ ~ C ∨ ~ D ∨ ~ E)
	
d.	 (A ∙ ~ C) ⊃ (B ≡ (D ∙ E))
	
e.	 (A ⊃ ~ B) ∙ (B ⊃ ~ C) ∙ (C ⊃ ~ A)
	
f.	 (D ∨ E) ⊃ ((~ A ∙ ~ B) ∙ (C ⊃ ~ E))
	
g.	 ~ (A ∨ B) ∨ ~ (C ∙ E)
	
h.	 (A ∙ (C ⊃ E)) ⊃ (~ B ⊃ ~ D)
	
i.	 (D ⊃ ~ B) ∙ (A ⊃ ~ C)
	
j.	 ~ (A ∙ E) ∙ ((B ∨ C) ∙ ~ (B ∙ C)) ∙ (D ⊃ A)
	
k.	 (~ C ∙ ~ E) ⊃ ~ (A ∙ B)
	
l.	 ~ D ⊃ (A ⊃ (B ⊃ C))
	4.	 Provide translations into our symbolic language ∑. Specify your own key or 
non-logical lexicon (symbols, from capital letters, for the statements.)
	
a.	 Build it and they will come.
	
b.	 The only option for avoiding bankruptcy so that we can overcome our present 
difficulties is to adopt exactly one of the options of either borrowing or laying 
off personnel.
	
c.	 The only option for avoiding bankruptcy and overcoming our present diffi-
culties is to adopt exactly one of the options of either borrowing or laying off 
personnel.
	
d.	 Even if we fail, we don’t fail.
	
e.	 Cline and Slane are friends [of each other].
	
f.	 Cline is Slane’s friend but Slane has no friends.
	
g.	 If you lose the queen but you don’t lose both knights, you don’t have to forfeit 
the game.
	
h.	 If premise 1 and premise 2 are both true but the conclusion can be false, then 
the argument is not valid.
	
i.	 To go to work, you must take route A after you have taken route B.
	
j.	 Slack is unhappy only if he is contradicted.
	5.	 Provide translations into our symbolic language ∑ by using the provided inter-
pretative key. It is understood that the meanings are stated for relevantly speci-
fied locations and time-periods: the statements are not affected, in other words, 
by variations in contexts. Note also that “it rains” and “it is raining” are trans-
lated by the same letter because the translated meaning is: “it rains at---- and 
during___.” Pay attention to the differences in meaning between “if-then,” “---
only if___” and “--- if and only if___.” Also pay attention to the placement of 
4  Sentential Logic Languages ∑

287
“if”: what follows “if” is the antecedent no matter where in the English sentence 
the “if” is found; but what follows “only if” is the consequent of the conditional 
(implicative) statement. Some sentences may be expressing truth-functionally 
simple statements: in such a case, use capital letter “X.”
•	 It rains: R
•	 The game is canceled: C
•	 The rules of the game dictate cancellation: D
•	 The ball floats in rain-water: F
•	 We get to go home: H
•	 Our team wins: W
	
a.	 If the ball floats in rain-water, then the game ought to be canceled.
	
b.	 If it rains but the ball does not float in rain-water, then the rules of the game 
do not dictate cancellation.
	
c.	 The game was cancelled after it rained.
	
d.	 If it does not rain, then the game is not canceled.
	
e.	 The game is canceled if and only if it rains.
	
f.	 The ball does not float in rain-water but it is raining.
	
g.	 We get to go home only if the game is canceled.
	
h.	 Unless the game is canceled, we don’t get to go home. (If the game is not 
canceled, then we don’t get to go home.)
	
i.	 Our team wins only if the game is not canceled.
	
j.	 Our team wins if the rules of the game do not dictate cancellation.
	
k.	 Raining is not a sufficient condition for game cancellation or for going home. 
(It is not the case that (if it is raining, then (the game is canceled or we get to 
go home.)))
4  Sentential Logic Languages ∑

289
© The Author(s), under exclusive license to Springer Nature 
Switzerland AG 2022
O. Makridis, Symbolic Logic, Palgrave Philosophy Today, 
https://doi.org/10.1007/978-3-030-67396-3_5
Chapter 5
Formal Predicate Logic (also called 
First-­Order Logic) ∏
The construction of predicate logic systems constitutes a dramatic advance over the 
categorical logic that available for millennia, based on Aristotle’s seminal achieve-
ment. Modern predicate logic solves the ancient problem of the expressibility, and 
consequent investigation, of relations. The n-ary predicate symbols of modern pred-
icate logic allow formalization of, correspondingly, n-ary relations – a feat that had 
eluded ancient logicians. It is relevant that modern predicate logic bypasses meta-
physical considerations that bewildered thinkers and students of logic and were 
deemed fundamental challenges that confronted even the systematic arrangement of 
a logical apparatus. Of course, the mathematical amenities that are available to the 
modern logician eluded the pioneers and practitioners of premodern logic. The 
modern predicate logic treats, as it ought to do, predicate symbols as non-logical 
symbols (also called, especially in older texts, non-logical constants.) This is appro-
priate: considering the formal character of deductive logic  – its aloofness from 
content-­related meaning and its dependence on formal structures – there ought to be 
no dependence on the meanings of predicates which can be attributed to objects 
arbitrarily and variably – and, thus, present as liable to the type of discovery and 
verification that characterize empirical endeavors. Let it be understood that a logical 
predicate – not to be confused with the grammatical term – corresponds to verb-­
phrases of language. For instance, consider the following meaningful sentence of 
English: “Schmuck runs and laughs.” Even though the grammatical predicate is 
complex, the sentence is simple: nevertheless, from a logical standpoint, the mean-
ing of the sentence is compound because the abstract conditions under which the 
meaning is true require, for the meaning of the sentence to be true, that both 
“Schmuck runs” is true and “Schmuck laughs” is true. Thus, the logic-word “and”, 
which is modeled by our familiar conjunction connective of sentential logic, does 
indeed carve the sentence so that we have a compound sentence. Indeed, logic-­
words are invariable – which is essential for the machinery that allows us to extract 
the logical form of a given sentence (or, more correctly, of its declarative meaning.) 
The “and” ought to be fixed in the logical form of the sentence: the predicates are 

290
non-logical, however, and the symbols to be grammatically stipulated in our formal-
ism ought to be non-logical symbols – which is the case. Notably, if we run across 
a sentence like “Schlum is clever”, we regard the logical predicate – never minding 
how this sounds in properly idiomatic English – as “Schlum clevers”: hence, as we 
have already intimated, the logical predicate matches what we may regard in lin-
guistic grammar as a verb-phrase.
It was thought once, even by Leibniz, that all meaningful sentences must have 
the grammatical form subject-predicate, and that this is somehow dictated actually 
by logical considerations. This would actually spell trouble because a sentence like 
“there are exactly three objects in the room” does not appear to have the subject-­
predicate form even though it is certainly meaningful and as such capable of being 
true or false. We might be tempted to consider the state of the room as the subject 
and to predicate of which predicates that represent the first and the second and the 
third object but this extravagance runs us into other difficulties. There is no need to 
be worried, though: with the addition of identity, predicate logic can formalize the 
meaning of this sentence even as the sentence apparently does not have a grammati-
cal subject-predicate form. Indeed, the addition of identity – which is treated, as we 
will see, as a logical symbol rather than as a non-logical predicate symbol – makes 
feasible symbolization of numerical statements. Since these are mathematical state-
ments – not characteristically logical (disregarding a now rather discredited pro-
gram called Logicism, which viewed mathematics as ultimately derivable in its 
entirety from logic), our extension by adding identity will be still conservative: it 
will not add to our system’s logical consequence any new logical (as distinguished 
from numerical) valid forms.
5.1  Grammar of our Formal Language of Predicate 
Logic: ∏
The formal language we will construct for Predicate Logic is an extension of ∑, 
which is the formal language we built and used for Sentential Logic. To extend, we 
retain the symbols – the symbolic resources – of ∑ and add more symbolic resources 
that furnish expressive power beyond our erstwhile capabilities. The addition of 
symbolic resources makes possible the formalization of arguments which sentential 
translation represents as invalid in spite of a strong sense that some of those argu-
ments ought to be determined as valid in whatever logical system claims to “get it 
right.” If we conceptualize logic as a mathematical investigation of formal lan-
guages, then we ought to regard the system as incorrigible (it cannot be corrected or 
amended) by appealing to extraneous considerations. Nevertheless, we also have 
available a notion of logic as a motivated formal enterprise which is categorically 
constructed so that it represents correctly a pre-formal relation of logical conse-
quence (relating formally the conjunctions of premises to their supported conclu-
sions): this relation of logical consequence is understood to be emanating from an 
5  Formal Predicate Logic (also called First-Order Logic) ∏

291
independent realm – either of reason, as it was traditionally envisioned or from the 
embedded transactions that are made possible through application of language. The 
added symbolic resources that extend sentential to predicate logic are such as to 
give ourselves greater expressive power, so that we can translate the internal parts of 
English sentences – names, pronouns, verb-phrases, and quantificational locutions. 
Regardless of our pressing translating interests, the gain in formal power is signifi-
cant and valuable in itself in affording us a more expressive formal system.
There is a trade-off, unfortunately, between expressive power (more symbols – 
more expressive power) and the effectiveness of computational devices applied to 
make decisions (as we did in ∑) about validity and other such logical properties. In 
other words, the more we gain in expressive power the more we lose in terms of how 
we can devise methods that follow mechanical and computational processes to 
reach decisions about validity and all those other properties which Logic studies. 
This is an advanced subject and we will not pursue it here. Many students of Logic 
consider Predicate Logic to be absolutely required as the least we should have. A 
historical reason for this is that the language of Mathematics cannot be translated 
into a Sentential Logic idiom; although it is questionable if it can be rendered by a 
Predicate Logic idiom, at least we are getting much closer to having adequate 
expressive resources when we rise up to Predicate Logic. Let us see, now, how we 
can execute this ascent: retaining all the symbolic resources, and the grammar, of 
∑, we will build, on top of that, the formal language ∏ as an idiom of Predicate Logic.
Now, much as we are intent on avoiding complications for our introductory pur-
poses, we should make an effort to see something important. ∏ is comprised of two 
formal idioms; for the sake of simplifying, we might combine both of them. One, 
which we can call ∏μ, has the kind of symbols we will call monadic or unary one-­
place predicate symbols; it does not have many-place or n-ary or polyadic predicate 
symbols. The other idiom, ∏ρ, retains ∏μ and adds what we will call many-place 
or n-ary (or polyadic) predicate symbols. We then continue with adding symbols for 
what we will call functions and a symbol for identity, “=”, to end up with ∏ρ=. 
When we speak of ∏ without qualifications, we will have in mind the complete 
∏ρ=. Even though we do not pursue theoretical (metalogical) considerations in this 
text, we should observe that our collection of formal languages includes more than 
one species. From a deeper standpoint, there are things that ∏μ can do in terms of 
reaching decisions, which ∏ρ and ∏ρ= cannot do. Consistently with what we indi-
cated in the first paragraph above, as we gain expressive power (and are able to also 
make more detailed-structured translations), we lose in terms of decision-making 
automatism.
Let us see again what stock of symbols we have in ∑ and in the metalanguage of 
∑, ℳ(∑), before we extend, first, to ∏μ. The metalanguages of our predicate idi-
oms, ℳ(∏μ), and so on, retain ℳ(∑) and also make available to us to use the addi-
tional symbolic resources that we obtain in predicate logic. As always, in a 
metalanguage, we have access to English – we only use a fragment of English, as 
we need, of course.
GRAMMAR(∑):: p, p1, …, q, … /~/∙/∨/⊃/≡/)/(.
GRAMMAR (ℳ(∑)):: φ, φ1, …, ψ, … /as in ∑/English fragment.
5.1  Grammar of our Formal Language of Predicate Logic: ∏

292
To remind ourselves of the terms we use: we have atomic (also called simple and 
individual) variables (or variable symbols or letters); we have symbols for the con-
nectives in our formal language; and we have parentheses to be used as auxiliary 
symbols only for the purpose of preventing and removing ambiguity and for no 
other reason.
The regulations we have laid down for how to form strings of symbols are still in 
force. Thus, we have:
•	 If a symbolic expression φ is well-formed (a well-formed formula or wff), then
•	 ~ φ is also a wff.
•	 If symbolic expressions φ and ψ are wffs so are: φ ∙ ψ, φ ∨ ψ, φ ⊃ ψ, φ ≡ ψ.
•	 Parentheses are used only to prevent and remove ambiguity.
•	 Nothing else is admitted in ∑ as well-formed; any symbolic string not observing 
the above grammatical regulations is not a wff of ∑ and cannot be read.
Some texts do not retain the individual variables of sentential logic. After all, 
since we will now have symbols that allow us to express internal parts of sentences, 
we may not need to symbolize a sentence as a whole. For our purposes, this is not 
important and we might as well retain the atomic sentential variables.
Now we are ready to add symbols for ∏μ. Subsequently, in section 5.3, we 
expand to the full idiom ∏ρ=. To begin with, we need symbols for two kinds of 
terms, predicate letters (also called predicate constants and non-logical constants), 
and two kinds of symbols for quantification that are called quantifier symbols. Our 
formal idiom stands on its own but, for assisting comprehension, we will see how 
these symbols can be matched with internal parts of sentences of a language like 
English. As always, we are not talking about the grammatical structure of the lan-
guage but about its logical structure. We need to pay attention to every detail and not 
make any assumptions based on how the English grammar itself works.
Let us take an English sentence like the one expressed in (S). We are really talk-
ing about the meaning expressed by this written sentence.
(S) John is a student.
To symbolize this sentence for the purpose of investigating its logical structure, 
we need a type of symbol that allows us to symbolize names like “John.” We con-
sider such proper names to be like labels or tags that pin down the item or entity we 
are referring to; we are labeling the entity or item. The meaning of a name, for us, 
is simply the object or entity it refers to; nothing else. This might not accord with 
other intuitions you may have about the meanings of names but it is important to 
realize that logical meanings, in the basic logical systems we are studying, are con-
sidered to be the referents of the symbols – the things referred to. This condition 
makes out logics extensional – as they are called. This is how we treat proper names 
for formal predicate logic purposes: a name’s meaning is the thing to which the 
name refers. (We take sentential symbols to refer to truth value, True or False. We 
will find out soon what referents we assign for predicate symbols. The variables of 
predicate logic do not have referents in the system we are constructing.) We will use 
small letters from the English alphabet for names. This is one kind of term we will 
have but, recall from above, we need two kinds of terms. You will soon find out what 
5  Formal Predicate Logic (also called First-Order Logic) ∏

293
the other type of term is. The names will be called within our formal language indi-
vidual constants. The other kind of term – the one without referents – is called 
individual variable. It might be unfortunate that we have so many different terms but 
you need to focus on learning and retaining them.
It is also apparent, from our example, that we need some type of symbol to 
express the property of being-a-student which is attributed to the person named 
John in the sentence. This type of symbol we will call predicate constant or logical 
predicate constant or predicate symbol or predicate letter or non-logical constant. 
This is the time to explain that logical predicates – what our predicate letters refer 
to – are not the same as the grammatical species known as “predicate.” A kind of 
magic has to happen here – and this has widespread implications. We don’t have use 
for the verb “to be” (“is” in the sentence we are using as an example); we make it 
disappear or, better, we reveal that this verb does not play a role in the logical struc-
ture of the meaning of the sentence. This applies to the use of “to be” as a copula or 
connective tissue, as in the given example. The only meaning of the verb “to be” 
which we will express is the one that means identity: when we get to the grammar 
of ∏ρ=, we will introduce a symbol for it and we will then explain what we mean 
by “identity”.
This disappearance of “to be” is significant. Many philosophic riddles in the his-
tory of thought have depended intrusively and recurrently on what seem to be con-
fusions around meanings of the verb “to be.” Modern logic takes the view that a 
sentence like the one in (S) expresses the following meaning (which does not sound 
idiomatically acceptable as English but, remember, this is the logical and not the 
surface-linguistic grammar we are talking about.)
(S)-LOGIC:: John students.
In our stipulated grammar, we will be placing the predicate symbol before the 
variable symbol: Thus, it is as if we are writing “Students John.” If we think in terms 
of mathematical functions, consider “Student(John)” and then proceed to make a 
convenient arrangement that allows you to drop the parentheses around the 
name “John.”
Thus, our logical predicates are like verbs really, and we also have to think of 
those verbs as not depending on a use of “to be.” Remember this in order to retain a 
firm grasp of how we scan the meanings of meaningful English sentences for 
formal-­logical purposes.
There is a good reason why predicate symbols are sometimes called non-logical 
constants or non-logical symbols. We can explain this simply although a good deal 
of ingenuity and theoretical subtleties are hiding behind it. A good way to think of 
a logical concept is by taking such a concept to be invariable – we cannot make it 
change – by changing the context (for instance, a story we tell or factual and empiri-
cal matters that are introduced.) All our connectives in sentential logic are logical 
concepts; regardless of what narrative we might concoct, the meanings of “not” and 
“and” and the rest are not affected; they remain the same exactly. But, now, let us 
consider the concept of the logical predicate “student.” We could make up a narra-
tive – a possible option or possible state or a model, if you will – in which John is a 
student; we could also make up another story in which the same entity named John 
5.1  Grammar of our Formal Language of Predicate Logic: ∏

294
is not a student. Thus, in the first story “student” as a concept includes the entity 
named John; but the same concept, “student,” changes, as it does not include the 
entity named John in the second story. Thus, this concept, the logical predicate, 
shifts along with contexts; it is not invariable; it is not a logical but a non-­
logical notion.
In the reflections we just introduced, something else deserves attention: it seems 
that the meaning of a logical predicate is, for formal logic, the collection or set of 
things/entities that we put in it when we build a model. In one context or model, the 
meaning of “student” included the person named John but in the other model it did 
not. We have seen so far that names have as meanings the items/entities they refer to 
within specified models; logical predicates have as meanings the collections of 
things from some model, which have the indicated property. It is noticeable that the 
models we are talking about have to be defined in terms of some non-empty set of 
things (which we take to be in the model); this is called the domain or universe of 
discourse of the model. Additionally, the model requires, for its proper construction, 
a valuation that assigns names (individual constants) to all the objects in the domain 
and sets of domain-objects to each predicate constant. (We will see later what hap-
pens in the case of predicates that are n-ary. The logical predicate “is-a-student” is 
monadic or, as we can also call it, unary or one-place.)
As an example of a model, we have:
𝔐 =<ⅅ, ||>.
ⅅ = {○, △, ▭}.
The model is defined as an abstract, mathematical structure: it has a 
domain, symbolized by “ⅅ” and an assignment of values (also called valua-
tion, interpretation, or signature), symbolized by “||”. We enclose these two 
within “<” and “>” to indicate that this is a so-called ordered pair (whose 
meaning you can study under Set Theory.
The values or valuations are: objects for the individual constants (the 
names); and sets of objects from the domain for the predicate constants.
We symbolize: Tx: x is a triangle; Cx: x is a circle; Rx: x is a Rectangle; 
Fx: x is a two-dimensional geometrical figure. Study the following informa-
tion about our model. This is the juncture to start familiarizing yourself with 
this method of modeling information in the language of the predicate logic.
•	 |a| = ○
•	 |b| = △
•	 |c| = ▭
•	 |T| = {△}
•	 |C| = {○}
•	 |R| = {▭}
•	 |F| = {△, ○, ▭}
5  Formal Predicate Logic (also called First-Order Logic) ∏

295
The meanings (values, valuations, referents) assigned to individual con-
stants are objects from the domain; the meanings (values, valuations, refer-
ents) assigned to predicate symbols are sets of objects from the domain. The 
meanings or values of predicate constants or predicate symbols are also called 
extensions.
Taking stock of the information provided by this model, we can determine, 
even by informal inspection, whether certain given sentences are true or false 
in the model. Truth and falsehood – which are the logical meanings we are 
working with – are, thus, relativized to the model, as we say. It is a matter of 
which model we are dealing with: this is the case with the sentences we have 
called logically contingent. Of course, logical truths (tautologies) and logical 
falsehoods (contradictions) should come out as, respectively, true and false in 
every constructible model. Or, to state this the other way round, only formulas 
that come out as evaluated true in every possible model are tautologies; and 
only formulas that come out as evaluated false in every possible model are 
contradictions. Notice also that a sentence like “a triangle is a two-dimen-
sional geometrical figure” should not come as true in every model! This sen-
tence is necessarily true (analytic) but this is so because of the meanings of 
the non-logical words (“triangle”, “angles”) in it; it is not true by virtue of its 
logical form. We could build some model in which our key for that model 
gives a set to the predicate symbol for “triangle” so that the triangles in the 
model are not members of the set for “two-dimensional geometrical figure.” 
This is what we should expect, anyway: the words or phrases “triangle” and 
“geometrical figure” and so on are non-logical words! In contrast, “every-
thing is F or not-F” for any key and in any possible model should be true – it 
is a logical truth. This is due to the meanings of the logical words “not” and 
“everything.”
Now, we could impose extra-logical restrictions on our models: we could 
make what are called meaning stipulations and legislate or dictate that the 
meaning of “triangle” (the set for the predicate symbol “triangle”) is a subset 
of the set (logical meaning) of the predicate symbol for “two-dimensional 
geometrical figure.” A set A is a subset of a set B if and only if all members of 
A have to be members of B. This is the case in our model given above for the 
set that gives us the meaning of “triangle:” it is a subset of the set that gives 
us the meaning for “two-dimensional geometrical figure.” But this is some-
thing we chose to do. We could have implemented a different key.
For the model given above, let us see if we can determine whether the fol-
lowing sentences are true or false in the model.
•	 The object denoted by ⌜ a ⌝ is a circle.	
True
•	 There is at least one circle.	
True
•	 Everything is a cicle.	
False
•	 The object denoted by ⌜b⌝ is a circle.	
False
5.1  Grammar of our Formal Language of Predicate Logic: ∏

296
We still need one other type of term – besides individual constants – and two 
types of quantifier. We will work toward the right direction by reflecting first on  
the quantifier symbols we need. We continue by using another example to assist  
our thinking.
(S′) All students are hard-working.
We should have symbolic resources to express a word like “all.” This type of 
symbol will be one of the two quantifier symbols; this one will be called the univer-
sal quantifier symbol. This is an internal-structure logic-word in a sentence. It is not 
a monadic connective. It is not a non-truth-functional connective. We will see that it 
can be analyzed as a connective – as an “and” – but that will be something we will 
do later (and it applies only if the model we are playing with has a finite number of 
things in it.) As it is, we can see that “all” is an internal part that we must render in 
our formal language.
Standard predicate logic only allows symbols for two types of quantifiers: the 
universal, which we have already presented, and the so-called existential quantifier. 
Attention is needed here because the standard predicate logic’s existential quantifier 
symbol refers to “some” in a special meaning: “at least one.” In the standard predi-
cate logic, we do not have quantifier symbols for other quantifier expressions of the 
language – like “a few,” “many,” “most,” “exactly five,” and so on. Other logics can 
handle such expressions but not our basic predicate logic, which is also the classical 
or standard predicate logic, of which our formal language ∏ is an idiom.
We are only left with one more type of symbol: a symbol for a type of term 
besides the other type of term we have seen already – the individual constant. The 
remaining type of term is called individual variable. To understand how this works, 
we need to do something you might not expect. We need to look into the conven-
tions we follow in order to construct the formal grammar of a language like ∏. You 
cannot second-guess this; you will need to be open to what follows and to absorb the 
constructive details step by step.
•	 Everything is a 2D geometrical figure.	
True
•	 Either the object denoted by ⌜ c ⌝ is a circle or the  
object denoted by ⌜ a ⌝ is a rectangle. 	
False
•	 Nothing is a triangle.	
False
•	 Everything that is a triangle is also a circle.	
False
•	 Everything that is a triangle is a 2D geometrical figure.	
True
•	 If ⌜c ⌝ denotes a triangle, then ⌜ a⌝ denotes a triangle. 	
True
[This is true because the antecedent is false: our definition of the horseshoe 
has been carried over from sentential logic: notice how a sentence with horse-
shoe as the main connective symbol is true if the antecedent is valuated as 
false: this is called vacuous implication.]
5  Formal Predicate Logic (also called First-Order Logic) ∏

297
Grammatical considerations for our formal language dictate that our individual 
variables are like ambiguous pronouns of a language like English. This might seem 
odd: we don’t tolerate ambiguity in a formal language, and, indeed, we will not end 
up having ambiguity! The reason that we start with this notion of an ambiguous 
pronoun has to do with how we build up our symbolic grammar: it should all come 
together in the end and you should be able to see what has happened; but you need 
to follow all the details patiently. This ambiguous pronoun notion is actually our 
own concoction: in a language like English, we can have an ambiguous pronoun 
(“he,” “she,” “it” with the possibility that more than one items might be referred to) 
but the context could well remove ambiguity. This might not always be possible, of 
course. But we would hope that it is – that we can remove the ambiguity: “he wants 
an excuse not to take the exam” is disambiguated in a context when we point to a 
student or when we have it from the context that some student has just acted in a 
specific way, so that this must be the referent of “he.” A logician’s ambiguous pro-
noun, on the other hand, is deliberately or systematically ambiguous: it is con-
structed as such and it is doomed, so to speak, to be ambiguous. It cannot be 
disambiguated. You will see why this is done.
For individual variables, the convention is to use small letters starting from “x” 
and continuing to the end of the alphabet; like with the all the other symbols, we 
may use subscripts from the positive integers. The small letters from the alphabet 
(possibly with subscripts) that are before “x” are reserved to be used as symbols for 
individual constants (the names.) Now, we need to learn something important.
(S″) x is a student.
This is a systematically ambiguous sentence: the ambiguity cannot be removed 
by determining the referent of “x.” This is as a matter of grammatical construction; 
this is how we build our grammar. But inherently ambiguous sentences are not 
meaningful for our formal logic purposes. Thus, (S″) is a grammatically structured 
sentence (viewed as a string of linguistic symbols) that always, systematically fails 
to express a meaning! Therefore, it is not the kind of thing that can be true or false. 
There is no remedy for this. We will be calling such sentences open sentences or 
sentential functions. Such a string of symbols cannot possibly be true or false; it 
cannot have a truth value. Notice, however, that we consider the concatenation of a 
predicate symbol with an individual variable (for instance, “Fx”) to be grammati-
cally correct or a well-formed formula; it is grammatically a well-formed formula, 
or wff of ∏, but it does not express a meaningful sentence. We can say that gram-
mar and logical meaning do not necessarily coincide in predicate logic. (This did 
not happen in sentential logic. Can you tell?) Let see now why we take this trouble.
There are two ways in which (S″) can be turned into a meaningful sentence – one 
that can be true or can be false and, thus, be a logical sentence, expressing meaning, 
that we can work with in formal logic. One way is to replace the ⌜x⌝ by some name. 
For instance:
(S″) x is a student ⇒ [John/x] ⇒ (S) John is a student
5.1  Grammar of our Formal Language of Predicate Logic: ∏

298
We obtain (S) from (S″) by replacing the individual variable by an individual 
constant. (Strictly speaking, we are using linguistic resources, not our own formal 
resources of ∏, here; but we are allowing ourselves to do this for the sake of expli-
cating our terminology.) The sentence in (S) does express a meaning. It has a name 
in it, not an ambiguous pronoun. Let us see how logical meaning works. Remember 
that our logical predicates are like verbs, so our sentence is “John students” and we 
will do well to consider it as:
Students(John)
The meanings are referential, as we have explained. The meaning of a name is 
the thing that is referred to by the name; the meaning of the logical predicate is the 
set of things from a given domain, which have the property indicated by the logical 
predicate. Thus, we need a model with a domain to be able to discuss meaning. Let 
us specify a model with valuation assignments. The person named John has to be in 
the domain: we will need some symbol, inevitably, to put inside the domain; let’s 
indicate our person, to be named “John”, by “≬”. Let us symbolize the property of 
being-a-student by “S”.
•	 𝔐 = < ⅅ = {≬}, ||>
•	 |j| = ≬
•	 |S| = {≬}
Now, we are ready for a crucial observation. Notice how we determine the logi-
cal meaning (true of false) of the sentence “John is a sentence:” it has to be deter-
mined within some model – like the model we have built for the sake of our example. 
Pay attention how the meaning of the sentence (which a truth value, true or false) is 
dependent uniquely on the valuations or meanings, in the model, of the other com-
ponents. We indicate this dependence, in our metalanguage, by “ℱ”.
•	 Meaning(John is a student) = ℱ(Meaning(John), Meaning(students))
•	 Meaning(John) = ≬ / Meaning(Student) = {≬}
•	 We have: Meaning(John is a student) = True, if and only if
•	 Meaning(John) belongs as member to Meaning(Student).
•	 Now we check: indeed, the Meaning(John) = ≬ is a member of.
•	 Meaning(Student) = {≬}:
•	 Therefore, Meaning(John is a student) = True.
So far we obtained a sentence from “x is a student” by replacing ⌜x⌝ uniformly 
by a name. (We have only once occurrence of ⌜x⌝; if we had more occurrences, we 
would have to make uniform replacements of ⌜x⌝ by the same name.) Another way 
to move from the non-sentence in (S″: “x is a student”) to a sentence is by quantify-
ing over “student:” we can use a universal or an existential quantifier. Thus:
(S″) x is a student ⇒ (S″’) Every x is a student = everyone is a student
We can also quantify by means of the existential quantifier:
5  Formal Predicate Logic (also called First-Order Logic) ∏

299
(S″) x is a student ⇒ (S″“’) Some x (at least one x) is a student
If you check the model we built above, with John in the domain of the model and 
specification of the meaning (valuation or extension) of the logical predicate is-a-­
student, you can ascertain intuitively that both the universally quantified sentence 
and the existentially quantified sentence are true in this model. Reflect that we are 
at liberty to construct some other model in which these sentences are not true. This 
is as it ought to be. We want only logical truths (or tautologies) to be true in every 
model we can possibly construct. But a sentence like “John is a student” is a contin-
gent sentence and should not come off true in every possible model we can con-
struct. (Of course, contradictions or logical falsehoods should also come out as false 
in every logically possible model we can construct.)
(S″: “x is a student”) is not a logical sentence, it is what we have called an open 
sentence, but all the conversions we have shown produced logical sentences. 
Replacing the variable ⌜x⌝ by a name produces a sentence; also quantifying either 
universally or existentially produces a sentence. This grammatical approach to con-
structing our strings of symbols accounts for the unexpected convention of treating 
individual variables as lacking reference (or, which is the same for us, lacking 
meaning.) We start with the open sentence (no references, hence no meanings, for 
the individual variables) and we replace variables by constants (names) or we quan-
tify (or we combine both) in order to generate sentences.
Let us take an example from mathematics.
(T) x plus y equals y plus x
This is not the way we should be expressing ourselves. Unless ⌜x⌝ and ⌜y⌝ are 
specific names, referring to items, we do not have a meaningful sentence. In ordi-
nary practice, we don’t bother about the details but here is the conversion to mean-
ingful sentences we have been talking about. Indeed, it is to be presumed that the 
above sentence (T) really means (T’) below.
(T’) For every x and for every y, x plus y equals y plus x
Now we have a meaningful sentence, obtained by means of universal quantifica-
tion: no individual variables are left without some quantifier managing them.
It is time to learn some other terminology: an individual variable that is not 
within the scope of a quantifier is called free (or unbound.) When we have any such 
variable, a free variable, we have an open sentence – a logically meaningless sen-
tence. To have a meaningful sentence that can be true or false, it must be the case 
that all individual variables are within the scope of some quantifier – are bound by 
some quantifier. We will examine the issue of quantifier-scope soon. Variables that 
are bound are called – you would expect – bound (or not free.) For a sentence to be 
logically meaningful, all its individual variables must be bound.
5.1  Grammar of our Formal Language of Predicate Logic: ∏

300
The above comments cover the terminology of our formal language and explain 
how the construction works and why we need the symbols and the syntactical-­
formation arrangements we impose on those symbols. You should memorize the 
names of the concepts we have introduced along with their definitions and, patiently, 
you should also pay attention to and reflect on the various subtle points that have 
been made about all these notions. In summary, these are the resources we need to 
provide symbols for:
TERMS: individual constants and individual variables.
PREDICATE LETTERS.
 QUANTIFIER SYMBOLS: All, At-Least-One (“Some” understood to mean “at 
least one.”)
Notice how we parse our linguistic examples given below. Although this seems 
like a lot of trouble at present, it is very useful to tune in to this parsing. We use the 
examples to indicate this and we practice as well. It will save a lot of trouble later 
on if you can get used to this parsing now.
Linguistic Examples - Parsing.
John and Mary are students ⇒ student(John and Mary) ⇒.
student(John) 	
	
and 	
	
student(Mary).
predicate name 	 	
connective	
predicate name
If Mary is a student, then there is at least one student ⇒.
If-then (student(Mary),   at least one x [such that]  student(x)).
connective    predicate name    existential quantifier    predicate variable
Every student is happy ⇒ All x(if x is a student, then x is happy) ⇒.
All x 	
	
	
(if-then	        (student(x), 	 	
happy(x)).
universal quantifier  connective  predicate variable  predicate variable
Notice that we have placed sometimes “if-then” in the front; this helps make a 
point but our grammar from ∑ does not allow prefix notation for binary connec-
tives; we should rather should expect to see the if-then placed in between the sen-
tences that it connects. Proceed to the examples and exercises to practice this topic 
before you return for the formal grammar of ∏μ. As a rule of thumb, “all F are G” 
expressions are implicative or conditional: “for all x, if x is an F, then x is a G.” 
Expressions of the form “some F are G” are conjunctive: “there is at least one x, 
such that x is a F and x is a G.”
5  Formal Predicate Logic (also called First-Order Logic) ∏

301
5.1.1  Exercises
	1.	 Determine if the statements expressed by the given sentences below are single or 
compound. Your understanding of what we called parsing in the preceding sec-
tion is relevant to this purpose. Also realize, however, that depending on context, 
parsing may be disallowed. For instance, if Gee and Lee perform as a pair, then 
“Gee and Lee performed” is not equivalent in meaning to “Gee performed and 
Lee performed” but it is a single statement. In our earlier study of the standard 
sentential logic, we discussed truth-functionality: non-truth-functional logic-­
words are not visible to the formal resources of the standard logic (the sentential 
as well as its extension that is the predicate logic we are examining): conse-
quently, if the main logic-word is non-truth-functional, we have a simple state-
ment. Negations, certainly, are logically compound statements since the 
truth-functional negation word is a logic-word. Some of the statements are mul-
tiply quantified, something we will examine systematically in subsequent sec-
tions; it is, however, rather straightforward to examine such statements keeping 
in mind that we take a statement like “a hates b” to mean that the pair comprised 
of a and b, <a, b>, in the left-to-right direction, is a member of the set of all pairs 
such that the first hate the second.
	
a.	 If everyone is corrupt, then Schmuck is corrupt.
	
b.	 If everyone comes to the party, then we need more food.
	
c.	 Myrtle and Electra are married to each other.
	
d.	 Agamemnon is the king of Nowhere.
	
e.	 It is possible that someone will land on Mars someday.
	
f.	 It is possible that someone will land on Mars someday but it is not possible 
that someone now alive will land on Mars someday.
	
g.	 No one came to the party.
	
h.	 It is not the case that if the building is built then clients will come.
	
i.	 If no one is happy then someone or other must be unhappy.
	
j.	 Everyone likes someone.
	2.	 Identify the underlined words as connectives, individual constants, variables, 
predicate constants or quantifier phrases.
	
a.	 Everyone is a student.
	
b.	 Everyone is a student.
	
c.	 Either John is a student or Mary is a student.
	
d.	 Either John is a student or Mary is a student.
	
e.	 Either John is a student or Mary is a student.
	3.	 Parse the following English sentences, so as to show the logical structure of their 
meanings. Specifically, pay attention as to whether the sentences are: conjunc-
tions, implicative sentences, disjunctions, quantified sentences, simple unana-
lyzed sentences (possibly due to the presence of non-truth-functional logic-words, 
which we discussed already in the context of translations into our formal idiom 
5.2  Monadic Predicate Logic: The Formal Language ∏μ

302
for sentential logic. Some sentences may be multiply quantified, for which we 
will develop grammatical conventions in subsequent section. A multiply quanti-
fied sentence has quantifiers within the scopes of other quantifiers (like “every-
one likes everyone” which can be characterized in terms of logical pattern as 
“for every x and every y, x likes y”.)
	
a.	 If everyone is saved, then everyone is happy.
	
b.	 Everyone who is saved is happy.
	
c.	 Either everyone is happy or no one is.
	
d.	 Because everyone is happy, everyone is saved.
	
e.	 Someone is happy since everyone is happy.
	
f.	 It is a matter of logical necessity that it cannot be that everyone is happy and 
someone is not happy.
	
g.	 There is someone is who is loved by everyone else.
	
h.	 There is a unique king of France who is not bald.
5.2  Monadic Predicate Logic: The Formal Language ∏μ
We start with the formal language ∏μ which is like a formal idiom of the Monadic 
Predicate Logic (also called Monadic First-Order Logic.) We will subsequently 
extend this to the full formal logic idiom ∏ which is the Polyadic or Relational 
Predicate Logic (also called Polyadic or Relational First-Order Logic) with Identity. 
We could even add symbols for functions to ∏ but we defer this for more advanced 
texts. Our first and more limited idiom of predicate logic has only predicate symbols 
that are monadic – hence, the title of this logic. This system has certain metalogical 
characteristics that are no longer available when we rise to the relational predicate 
logic system. A predicate symbol is monadic (also called unary and one-place) if it 
is accompanied only by one variable or individual constant. Based on what we 
recounted in the preceding section, accompanied by an unbound variable, a predi-
cate symbol fails to symbolize a meaningful sentence and constitutes what we called 
an open sentence or sentential function; if it is followed by an individual constant, 
it can symbolize a meaningful sentence. Let us check linguistic examples:
x is a student. [open sentence]
y is a teacher. [open sentence]
John is a teacher. [meaningful sentence]
Mary is a student. [meaningful sentence]
Every x is such that x is a student. [x-variable bound – meaningful sentence]
At least one x is such that x is a teacher. [x-variable bound – meaningful.
sentence].
The predicates are monadic because they are applied on one variable or constant. 
It was one of the most decisive and brilliant insights in the history of logic that we 
could also symbolize relations if we use predicate symbols that can take more than 
one variables or constants. Once again, variables that are not bound by quantifiers 
condemn the whole expression to the status of an open sentence. For example.
5  Formal Predicate Logic (also called First-Order Logic) ∏

303
x is the student of y. [open sentence – binary predicate]
Sue is the teacher of Alf. [meaningful sentence – binary or dyadic predicate].
Every student has at least one teacher. [bound variables – meaningful.
sentence].
x is between y and z. [open sentence – ternary or triadic predicate].
Sue gave a book to Alf. [meaningful sentence – ternary predicate].
Everyone gave something to someone. [bound variables – ternary predicate.
– meaningful sentence].
Here are the relevant terms we need to retain:
Predicates:: 
We need to have symbols for individual variables, individual constants, logical 
predicate symbols (only monadic predicate symbols in ∏μ), and the two quantifier 
phrases we use in the standard predicate logic (“all” and “at least one.”) We will now 
be presenting the symbols and the syntactical arrangements about how we can con-
catenate such symbols properly. Additional fuss is in order in the case of predicate 
logic. The notion of well-formedness (the attribute of grammatically and syntacti-
cally correct formulas) does not coincide with the concept of interpreting formulas 
as meaningful sentences. This means that we can have well-formed formulas which 
cannot be interpreted as sentences. This has to do with the issue we took pains to 
present above: the individual variable symbols of predicate logic correspond seman-
tically to deliberately ambiguous pronouns. Such variables have to be bound by 
some quantifier or replaced by some individual constant; otherwise, the formula in 
which they appear unbound (or free) are not available as sentential formulas; but we 
do accept them as well-formed. We have called such formulas open sentences. Thus, 
we can say that open sentences are well-formed even though they cannot represent 
sentences. Our symbolic arrangements and our syntax permit us – indeed, require 
us – to include formulas with free variables as well-formed but such formulas can-
not be understood as sentential formulas. We will offer examples of this; now is the 
time to pay attention to this matter and grasp it.
We begin with the grammar and syntactical arrangements for ∏μ. We will con-
tinue in subsequent section with ∏ρ= which is our formal idiom for polyadic or 
relational predicate logic. The observations about free and bound variables apply to 
the case of all the predicate systems, which collectively comprise what we call the 
formal language ∏. Since the formal language ∑ for sentential logic is included, 
and now extended with added symbolic resources, we incorporate into our presenta-
tion the grammar of ∑, which we presented 4.1.     
Unary/Monadic/One-Place; Binary/Dyadic/Two-Place; Ternary/Triadic/
Three-Place, …
…, n-ary/n-place.
5.2  Monadic Predicate Logic: The Formal Language ∏μ

304
∑
Symbol	
 Name of the Symbol 	
 What the Symbol Refers to
Symbol            Name of the Symbol         
    What the Symbol Refers to
~	
Tilde	
Negation
∙	
Dot	
Conjunction
∨	
Wedge	
 Inclusive Disjunction
⊃	
Horseshoe	
 Conditional / Implication
≡	
Triple Bar	
Biconditional / Equivalence
(,)	
Parentheses [also called Auxiliary Symbols]
---The tilde is the only Monadic or Unary or One-Place connective symbol. 
All the other connective symbols are Binary or Dyadic or Two-Place.
∏μ
Symbol	 	
Name of the Symbol What the Symbol Refers to
TERMS.
{x, y, z, …, x1, …}       Individual Variables/Variables      non-referring
{a, b, …, t, …, a1, …}  Individual Constants/Constants    objects/entities
Even though ⌜p⌝ and such symbols may appear both among the sentential 
variables and the individual constant variables, there is no risk of ambiguity 
given the syntactical conventions we have stipulated. The same applies for 
using the terms “individual variables” in both the case of sentential individual 
variables and the individual variables of predicate logic: context removes the 
ambiguity. Strictly speaking, we should be thinking of such symbols as being 
different and only accidentally “looking the same.”
{p, q, r, …, 
p1, p2, …}
Simple/Atomic/
Individual 
Variables/ Atoms
Meanings of Sentences 
(True or False)
{A, B, 
C, …, A1, …}
Linguistic Meanings 
Variables
Meanings of English 
Sentences 
Translated Into ∑
CONNECTIVES
(continued)
5  Formal Predicate Logic (also called First-Order Logic) ∏

305
PREDICATE SYMBOLS/PREDICATE CONSTANTS/NON-LOGICAL 
CONSTANTS.
{A, B, …, A1, …}.
In the semantic approach we will present, the referents of predicate letters 
are sets. This might seem surprising, although, strictly speaking, you cannot 
at this point form any justified notions about this if you have not studied set 
theory. We will actually have to study elementary set theory in order to pur-
sue our semantics for Predicate Logic in subsequent section.
Although the symbols, again, look like those for translating meanings of 
declarative sentences of English into the sentential logic, the different syntacti-
cal stipulations remove ambiguity as to what is the case. The syntax for our 
predicate letters will stipulate, as we will soon see, that the capital letter be 
accompanied by one variable or constant symbol (in the case of monadic predi-
cate logic.) Certainly, this is not the case for sentential logic which does not 
have symbols for representing internal parts of sentences like logical predi-
cates. Although ∑ is retained and extended by ∏μ, the need to impose new 
syntactical arrangements for ∏μ means that we do not run into ambiguity when 
we use same-looking symbols for different purposes.
QUANTIFIERS/QUANTIFIER SYMBOLS.
∀: Universal Quantifier/Universal Quantifier Symbol.
∃: Existential Quantifier/Existential Quantifier Symbol.
The issue as to what the referents of these quantifiers are is rather compli-
cated and a subject for advanced, and bold, logical investigations. In linguistic 
terms, so-­called determiners – captured to some extent by our quantifiers – 
may be found to represent higher-order entities. Our predicate logic is – and is 
also called – first-­order; let’s say that this means that it has quantifiers only for 
individual variables (or, properly speaking, quantifiers over individual vari-
ables.) We will not have quantifier symbols that allow us to quantify over 
predicate symbols. If we had such quantifier symbols – quantifying over our 
first-order predicates – we would be rising up to what is called second-order 
logic. In such a logic, we would have symbols to translate, for instance, “red 
is a bright color,” where “bright” is a property of properties like colors. We 
don’t have such resources in our first-order predicate language.
Notice that we do not have quantifier symbols for such linguistic quantifica-
tional expressions as “few,” “most,” “many,” “exactly a half,” and so on. We will 
be able to translate under the assumption that nothing is lost for the purposes of 
logic by ignoring such non-accessible quantifying phrases. Nevertheless, some-
thing might be lost sometimes. For instance, the following argument, which 
ought to be valid for sure, cannot be translated into our predicate idiom in such 
a way as to be checked as valid: “Either one is a student or one is a teacher in 
this gathering. Half are teachers. Therefore, half are students in this gathering.” 
In that case, we ought to know our limitations… But the blame does not belong 
to our logical formal system. It simply cannot do what it lacks symbols for!
5.2  Monadic Predicate Logic: The Formal Language ∏μ

306
ℳ(∑) == ℳ(∏μ).
φ, ψ, …, φ1, …
We are now addressing our metalanguage. We incorporate the metalan-
guage of ∑. We use these variables to talk about well-formed formulas of ∑. 
But, in the case of our metalanguage for our predicate idiom, ℳ(∏μ), these 
metalinguistic variables no longer have to be talking about simple or com-
pound sentences. The possibility of free variables, about which we have been 
talking profusely, pushes us in this direction. The metalinguistic variables we 
see above refer to well-formed formulas of ∏μ. As we have already intimated, 
well-formedness and sentential formula go apart in the case of predicate logic. 
It may be that a well-formed formula, let’s call it φ, has one or more free vari-
ables in it. In that case, we are not talking about a sentential variable; just about 
a well-formed formula. A standard expression we use is: “x is free in φ.”
You may have noticed, incidentally, that we don’t use the corner symbols 
(“⌝” and “⌜”) when we mention metalinguistic variables. This is because such 
variables are by design presented to be as names. That is not the case for the 
symbols of our proper constructed formal language – which is the so-called 
Object Language. We can show the difference by an example.
Mary is her name. [This is fine, without any quotation marks.]
“Mary” has four letters. [Here we absolutely must have the quotation 
marks. Consider the nonsensical implications of “Mary has four letters” if we 
are trying to say something about the writing of Mary’s name.]
Accordingly: when we refer to symbols from ∏μ, we place them within 
special metalinguistic symbols that are called “corners:” “⌜” and “⌝”. When 
we use and talk about metalinguistic symbols, we don’t need such corners. 
That is because those are functioning like names already within our 
metalanguage.
When we don’t use but, instead, talk about or mention symbols we place 
quotation marks around them – but for symbols from the Object Language 
∏μ we use corners as we have said.
Next, we need to present the Grammar – or, more precisely speaking the 
SYNTAX of ∏μ. We retain the Syntax of ∑, which we might repeat 
summarily.
Applications of the proper syntax – and nothing but applications of the 
proper syntax – yield well-formed formulas (wffs) of ∏μ. We can think of the 
collection, or set, of all wffs of ∏μ as the set named WFF(∏μ) and we indi-
cate, metalinguistically, that a formula belongs to that set by the symbol “∊”. 
So, “φ ∊ WFF(∏μ)” means that the formula φ is a member of the set of well-
formed formulas of ∏μ; this is a long way of saying that our formula is well-
formed, is a wff, given the grammar and syntax of ∏μ.
5  Formal Predicate Logic (also called First-Order Logic) ∏

307
The use of positive integers as available subscripts gives us up to a size of infinity 
that is called denumerable or countable. It sounds odd to be speaking of different 
sizes of infinity but a size means here the possibility of setting a one-to-one corre-
spondence with the positive integers – no matter if this matching never ends. This is 
an advanced subject for us and we can only provide fleeting glimpses.
We will now play with manipulating symbols in the proper fashion, as mandated by 
the grammar and syntactical conventions in ∏μ. Increasing familiarity with the proper 
grammar of our constructed formal language is a key presupposition for the ability to 
continue with any other task we will executing in this text. There are subtle issues and 
tempting errors for beginners. It is not possible to anticipate all such possible distortive 
influences, but we will try. An important concept is that of the scope of the quantifier 
symbol. We have already dealt with the notion of the scope of a connective symbol 
(4.1). You can check a subsequent section on parsing trees for wffs of ∏. The whole 
language, or cluster of languages, will be including relational predicate symbols and 
the identity sign. In all cases, our quantifier symbols are each followed by a single 
variable; we don’t have symbols for multiply quantifying quantifiers (which is possi-
ble but not part of the standard predicate logic.) Scope discernment comes into play 
with the phenomenon of nesting quantifier symbols: this refers to the case in which 
one or more quantifier symbols are within the scope of some other quantifier.
Let us begin with the rather cryptic remarks regarding the syntactical relation-
ship between a quantifier symbol and the formula that follows it. We will proceed 
by steps.
Fx: this is a wff even though it cannot be interpreted as a sentence. It is an open 
sentence.
∏μ:: SYNTAX
•	 pi
•	 if φ ∊ WFF(∏μ), then ~ φ ∊ WFF(∏μ)
•	 if φ and ψ ∊ WFF(∏μ), then
•	 φ ∙ ψ ∊ WFF(∏μ),
•	 φ ∨ ψ ∊ WFF(∏μ)
•	 φ ⊃ ψ ∊ WFF(∏μ)
•	 φ ≡ ψ ∊ WFF(∏μ)
•	 Ax, Bx, …, A1x, … ∊ WFF(∏μ)
•	 Aa, Ab, …, Ba, …, A1a, … ∊ WFF(∏μ)
•	 ∀x ∊ WFF(∏μ)
•	 ∃x ∊ WFF(∏μ)
•	 ∀xφ ∊ WFF(∏μ) insofar as x is free in φ -- see below for explanation
•	 ∃xφ ∊ WFF(∏μ) insofar as x is free in φ -- see below for explanation
•	 Nothing else belongs to WFF(∏μ).
5.2  Monadic Predicate Logic: The Formal Language ∏μ

308
∀xFx, ∃xFx: these are wffs and they can also be interpreted as sentences.
How did we proceed from the first wff to the quantified wffs?
Consider ⌜Fx⌝ as our φ:
Now, notice that ⌜x⌝ is free in φ: it is not within the scope of any quantifier sym-
bol; it is not bound by any quantifier symbol.
Next: we bind the free variable (in this case, the only variable and, importantly, 
the only free variable):
∀xFx
∃xFx
The only free variable has been bound; it has been brought within the scope of 
some quantifier symbol whose variable letter is the same as the initially free variable 
letter. Now we have no free variables. But, remember, even if there are free vari-
ables, the formula can still be a wff.
Let us now show more examples of binding, and also examples of non-binding 
which result in wffs that cannot be interpreted as sentences. Moreover, we begin to 
see failures of syntactical correctness due to violations of our syntactical stipula-
tions. A symbolic expression that is not a wff is ill-formed or not well-formed and 
it cannot be scanned by the user of the formal system – it is like what gibberish is in 
the context of a spoken language.
Fx ∨ ~ Fx ⇒ 	
∀x(Fx ∨ ~ Fx)
Fx ⊃ Fy ⇒ 	
∃xFx ⊃ ∃yFy
Fx ≡ Gy ⇒	
∃xFx ≡ ∀yGy
p ⊃ Fx ⇒	
∀x(p ⊃ Fx)	
-- we have not forbidden this quantification.
∀x(∃xFx ≡ ∀yGy)	 	
-- not a wff: ⌜x⌝ is not free in ⌜Fx⌝!
∀x∃yFx	
	
-- not a wff: ⌜x⌝ is not free in ⌜Fx⌝!
Fx ∙ Gx⇒	
∃xFx ∙ Gx	
-- partial binding.
We offer a few examples.
Examples of well-formed formulas that are open sentences. Consider that even 
one unbound variable renders the formula an open sentence. Of course, individual 
constants do not receive binding: they are semantically understood as referring to 
some discrete individual object or entity. It is a common error for beginners to take 
the case of individual constants as similar to that of individual variables when it 
comes to quantification: but the two cases are drastically distinct. The individual 
constants stand as they are in the formula – cannot be bound – and no quantifier can 
be allowed to bind individual constants. We indicate the free variables within set 
brackets for each formula. If we have more than one free variables of the same type 
of letter, then we use superscripts to mark occurrences counting from left to right.
•	 Fx ≡ ~ Fx	
== free: {x1, x2}
•	 Gz ∨ ∃x(Ft ⊃ Gx)	
== free: {z}
•	 (Fa ⊃ ~ ~ Fa) ⊃ (~ Fx ⊃ ~ ~ ~ Fx)	
== free: {x1, x2}
•	 ∀x(Fx ∨ ∃y(Fy ∨ Gz))	
== free: {z}
•	 ~ Tu ∙ ∀w(K21y ⊃ ∃z(Kt ∨ (Lw ∙ Fz)))	
== free: {u, y}
•	 ∃x(Fx ∨ Rx) ⊃ ~ ∀y(Fy ∙ ~ Gx)	
== free: {x3}
•	 ~ ∀w ~ ∀z ~ ∃y(Ft ≡ ~ (Fy ∙ ~ Lw ∙ ~ ~ Gz)) ∙ Lu	
== free: {u}
•	 Fa ≡ ~ ∃x (~ Fa ⊃ (Fx ∙ Gy))	
== free: {y}
5  Formal Predicate Logic (also called First-Order Logic) ∏

309
Examples of well-formed formulas that are not open sentences:
•	 ∃xFx ⊃ Ft
•	 ∀x(Fx ⊃ Gx) ⊃ (∀xFx ⊃ ∃yGy)
•	 ~ ∃x ~ Fx ≡ ∀xFx
•	 ~ ∀x(Fx ∨ Gx)
•	 (∃xFx ⊃ p) ≡ ∀x(~ p ⊃ ~ Fx)
•	 ∀w(Fw ≡ Gs)
•	 La11 ⊃ ~ ∀z(Lz ⊃ ~ ∃u(Lu ∨ ~ Gt))
•	 ~ (~ Ft ∙ Gt) ≡ ~∃x
Examples of symbolic expressions that are not wffs of ∏μ, with explanation.
5.3  # Standard Logic and Existential Commitment
The Aristotelian logic of categorical syllogisms was built on exactly four types of 
first-order sentences, which have been traditionally symbolized, metalinguistically, 
by the letters A, I, E, and O. We can translate these sentential schemata into our 
first-­order symbolic language – and, to be precise, the translation (indicated below, 
metalinguistically, by “↝”) is into our enhanced metalanguage for ∏μ which has 
tokens of our symbols for quantifiers, variables, constants or names, and predicate 
letter symbols.
•	 A: All S are P; All(S, P) 	
↝ 	
∀x(Sx ⊃ Px)
•	 I: Some S are P; Some(S, P) 	
↝ 	
∃x(Sx ∙ Px)
•	 E: No S are P; E(S, P) 	
↝	
~ ∃x(Sx ∙ Px)
•	 O: Some S are non-P; O(S, P)	
↝	
∃x(Sx ∙ ~ Px)
The system constructed by Aristotle assumed that every class (what we regard as 
logical predicate) has members; no empty classes are to be contemplated. Perhaps, 
one would appeal to a linguistically based commonsensical assumption: if we were 
told that “all of the Myrmidons are soldiers” we would consider the utterance of the 
statement to be committing to the existence of at least one Myrmidon. On the other 
hand, “all unicorns have horns” strikes us as pointing in the opposite direction, of 
discountenancing existence of any such entities, of which, nevertheless, we want to 
predicate that they have horns. The technical issue is that Aristotelian logic cannot 
determine argument forms to be valid unless this existential presumption, to the 
effect that there are no empty predicate classes, is posited. Our predicate logic sys-
tem, on the other hand, as an idiom in the family of modern predicate logic lan-
guages, allows for empty predicate classes. We will see that the semantics of 
predicate logic uses sets – collections of items that are discrete – that interpret our 
predicate symbol letters: accordingly, the predicate “student” defined strictly for 
some specified domain or universe of discourse is interpreted semantically as the set 
of all the members of the specified domain, which are students. An empty set is 
definable, as a set with no members whatsoever. If no students exist in our specified 
5.3  # Standard Logic and Existential Commitment

310
domain, then we say that the predicate “being-student” is interpreted in this domain 
by the empty set. Notwithstanding the technical flavor of this, there is some intuitive 
basis to which we may appeal in supporting this setup. It is important that our 
semantics is, in this way, extensional: logical meanings are understood as given by 
what they refer to. The names or constants of our language refer to objects in our 
domain and the predicate letters are taken to be referring to sets as indicated above. 
Aristotle did not have this semantic machinery at his disposal. The modern logic of 
predicates commits us, then, to having a non-empty specified domain but possibly 
empty predicate sets. Another benefit, if it can be considered as such, is that thorny 
traditional issues of existence are set aside: it appears now as ill-conceived and mis-
leading to be pondering over questions of existence when it comes to transactions in 
logic: notice that the copula-use of the verb “to be” disappears as unnecessary and 
redundant (the logical predicate “being-student” which we may write as “student” 
absorbs the copula, so “John is a student” can be captured by “Student(John).” The 
other, perennially challenging, use of “to be”, in the sense of “exists”, is also treated 
in a specific way now that we have selected our meaning-apparatus: this may also 
sound open to challenges and controversial, but what happens with our predicate 
semantics is that the quantifiers, all and some, applied over a specified domain, 
generate existential commitment in a straightforward way that is not open to second-­
guessing. Given that the domain is populated by members (it cannot be empty, as we 
said), existential privileges are conferred by fiat, as it were, to those members. This 
might sound arbitrary but the idea is this: from the point of view of logic, what 
exists and what does not exist are not proper subjects of inquiry; those are, rather, 
empirical questions but deductive logic is not based on factual or empirical investi-
gation. We may consider, for example, a sentence like “Centaurs exist”: although 
the reference is to some fantastic entity, the quest for ascertaining existence of such 
entities or not is not the business of logic. This means that we may construct a 
domain with members, some of which are members of the “Centaur” set. This does 
not mean that the empirical question as to whether such creatures exist has been 
settled in the affirmative: we simply have a narrative with Centaurs in it. But we 
should not worry that this can affect our logical analysis: we can always construct a 
different narrative, a different model, in which the set of Centaurs is empty. This is 
as it should be since it is a factual and not a logical question as to whether Centaurs 
exist. Of course, this applies to other entities, of which we are certain that they exist. 
For instance, we may build a model with a domain and predicate interpretations so 
that the set of humans is empty. It is not true that there are no humans but it is not 
logically necessary that humans exist! It is, sadly, logically possible that there are 
no humans.
Aristotle’s assumption that the predicates commit to existence, which our mod-
ern logic abandons, means that there are argument forms that are valid in the 
Aristotelian system but which can check as valid for our modern predicate logic 
only if we add, as extra-logical meaning-postulates, that such-and-such kinds of 
things indeed exist. If we check the sentential types on which the Aristotelian logic 
is based, A-sentences imply I-sentences and E-sentences imply O-sentences. This, 
however, fails in modern logic – unless we stipulate for the S-predicates in the types 
5  Formal Predicate Logic (also called First-Order Logic) ∏

311
that they are instantiated (that there is at least on S-thing or that the S-class is not 
empty.) We may say, then, that, given the way the modern logic of quantifiers (pred-
icate logic) is set up, we can show that this addition of existential commitment for 
the predicates is needed to render those inferences valid.
Let us try the case of A-I implication. Assume that the A-sentence is true: all S 
are P. Now we check if we can make the I-sentence false without running into logi-
cal absurdity: if that is the case, then, we have a counterexample to the A-I conver-
sion claim, which is valid for Aristotelian logic but not for the modern logical 
semantics. Let us assume then that it is false that: some S are P. If this sentence is 
false, then its negation must be true: not(some S are P.) The negation of “some S are 
P” is logically equivalent with “all S are not-P.” Both the A sentence and the nega-
tion of the I sentence are universally quantified: this means that they are true of any 
object in our domain. Let us take any chance object of our domain, and call it “t.” 
We have: it is true that “if t is S then t is P” (notice that universally quantified state-
ment is indeed if-then or implicational statements: “all F are G” says indeed that 
“for any x, if x is F, then x is G.”) For the negation of the I-statement, we have: “if t 
is S, then t is not-P.” Let us take stock of what we have so far:
	1.	 A: all S are P.
	2.	 not-I: not(some S are P.)
	3.	 not-I: all S are not-P. (2: converting not-all to some-not)
	4.	 A – applied for any object named t: if t is S, then t is P. (1: t)
	5.	 not-I – applied for any object, and so, for our object named t: if t is S, then t 
is not-P.
	6.	 from 5, by the classical rule we know as contraposition, and also by applying 
double negation elimination: if t is P, then t is not-S.
	7.	 from 4 and 6 by the classical rule we know as hypothetical syllogism or transitiv-
ity: if t is S, then t is not-S.
	8.	 from 7: in standard logic this is equivalent with the following (which we can 
derive by applying the rule we studied in natural deduction by the name “condi-
tional exchange” and then apply the rule we know as Idempotence): not-S.
If this argument is valid, then we ought to have ended with a logical absurdity. 
The final line we derive has the statement that there are no things that are S. Clearly, 
if this has to be false (if there can be no classes with no members), we have shown 
this to be a valid argument. If, on the other hand, we may have empty classes, as the 
case is in modern logic, then there is no logical absurdity in claiming that there are 
no things in the domain that are S: the S-set is empty. We have no absurdity in that 
case, and we have produced a counterexample (or, better, a counter-model) to the 
argument we have been examining. We see, then, plainly, that we can bring modern 
logic in alignment with Aristotelian logic, in this particular case of the validity of 
the A-I conversion, only by stipulating that any chance predicate letter S, interpreted 
by a set, cannot be empty.
Having examined this issue regarding existential commitments, we need to notice 
also that, when it comes to existential claims about existing entities, modern logic, or 
at least the standard version we are presenting, makes a commitment to existence of 
5.3  # Standard Logic and Existential Commitment

312
all the entities that are being talked about. Although predicate-sets can be empty, the 
entities in the domain that are being talked about are taken to definitely exist. 
Although we have not formally introduced symbols and semantic accommodations 
for identity yet, (which we will do as we extend from ∏μ to ∏ρ=), we can informally 
make some sense, here in our metalinguistic ruminations, of the following symbolic 
expression which checks as a necessary or logical truth of the standard predicate 
logic (with relational symbols and with the identity symbol added.)
∀x∃y(x = y).
We read this: for all things named x (referring to objects in our specified domain, 
which we must always have as given), there is at least one thing named y such that x 
and y co-refer (refer to one and the same thing in the domain.) If we think of what this 
is saying, we have: anything you can name refers to some object in the domain, which 
exists. Accordingly, existential claims, as we have already intimated, are simply man-
aged by quantificational claims that range over the given domain: and by placing 
something in the given domain, we are committed to its existence. We will try to 
prove, informally, this claim. We may also make another deep observation about our 
formal language: even though it is an old and profoundly significant philosophic claim 
that there is no logical predicate “exists” we will see that this can be circumvented. 
Immanuel Kant criticized the famous ontological argument purporting to prove God’s 
existence (due to Anselm of Canterbury) by pointing out that “exists” is not a logical 
predicate; this means that when predicates are defined, whether the things that have 
the predicate predicated of them exist or not does not do anything to the definition of 
the concept. If you have the definition of the concept “triangle of the Euclidean geom-
etry,” for instance, then whether anything existent has this predicate predicated of it 
does not matter. It turns out that, in modern relativistic physics, there are no Euclidean 
triangles (which are supposed to have 0 degree of curvature) in existence in the uni-
verse. Nevertheless, your grasp of the concept “Euclidean triangle” is not affected by 
this cancellation of existential claims at all. And if it turned out (very unlikely but logi-
cally possible) that Euclidean triangles exist, after all, that too would not change any-
thing for the definition of this predicate. This is what Kant had in mind in claiming 
that existence is not a logical predicate. (Because Anselm’s ontological argument for 
the existence of God treats existence as a predicate attaching to, and detachable from, 
things, it is said to fail. Short of this flaw, the ontological argument is perplexing: it 
should fail because it derives an existential, hence empirical, claim as a conclusion in 
a deductive argument that uses only logical premises and definitions: hence, the exis-
tential claim about God’s existence emerges as a necessary truth if the argument is 
sound – but no existential claim can be a necessary or non-empirical truth! It is hard 
to tell what is wrong with this argument, however, unless Kant’s critique is accepted.) 
It turns out, however, that the expression we studied above can show us a way to 
define a logical existential predicate: we can say of a thing named t that it has the 
existence-­predicate if and only if:
∃x(x = t).
5  Formal Predicate Logic (also called First-Order Logic) ∏

313
i.e. there is at least one thing named x such that x and t co-refer or refer to the 
same thing: in other words, something exists such that the thing named t refers to 
that thing. The standard modern predicate logic dispenses this existential privilege 
to everything we have in our domain. We can remedy this in different ways but this 
would generate a different, non-standard predicate logic within a family of systems 
that are called collectively Free Logic languages.
Let us try to prove, informally, that everything we talk about (everything we give 
a name to in the domain) in the standard predicate logic exists. And, let us keep in 
mind, we need to name or label all our objects in the domain. A name too is under-
stood as a labeling device here: whether one thinks that this is the right theory of 
what a name is or not, a name has meaning referentially – the meaning of a name is 
simply the thing that is named by the name. This is in alignment with the strictly 
extensionalist character of this logic – in that this logic treats meaning as a matter of 
what is being referred to or denoted, and not as a matter of what is connotatively 
associated with the sentential part.
Let us assume, to see if we can reach logical absurdity, the negation of what we 
are trying to prove. We see below, step by step, how we may proceed:
	1.	 ~ ∀x∃y(x = y)		
negation of the existential-commitment statement
	2.	 ∃x∀y(x ≠y)	
	
 from 1: converting quantifiers to each other and negating 
identity: there is something named x such that, nothing 
in the domain has a name so that they refer to the same 
thing: in other words, there is some name for a non-exis-
tent thing.
	3.	 ∀y(t ≠ y)	
	
from 2: call the thing we are talking about by the name t.
	4.	 t ≠ t	 	
	
 from 3: but for “all” we can be talking of any object 
whatsoever: so, why not the one we named t? But now 
we have reached logical absurdity: whatever we may 
think of identity, it is surely logical absurd that the thing 
referred to by the name it is not … identical with itself.
Having reached a logical absurdity, we must determine the claim that was negated 
as being a logical truth: basically, everything in the domain exists or, more precisely 
and in detail, everything we have a name for in the domain refers to an existent 
object. This proof would fail to issue in logical absurdity if we did not allow passage 
from a universal statement (line 3) to an instantiation (what we get in line 4 when 
we claim that the thing named t can be said to exemplify the universal claim.) It 
sounds, though, that this cannot be done: if we have a universal claim, then this 
claim must surely apply for every object in the domain – and so, in the expression 
with any name that names some object in the domain. Nevertheless, we could indeed 
stipulate that, because not all things that are being talked about should be taken as 
existing, we do not permit such instantiation at liberty: we could demand that only 
if a thing is indeed existent we can use a name to refer to it. To move from line 3 to 
line 4 we would be requiring an express statement that a thing named by t indeed 
exists. Of course, this would not be a standard logic idiom – it would be some spe-
cies of what is called Free Logic. On the other hand, think what you will of this, our 
5.4  Expanding ∏μ to ∏ρ=/∏μπφ=: Polyadic (or Relational) Predicate Logic…

314
standard logic has a machinery attached to it, which makes conferral of existence 
automatic for everything that is being talked about. It follows, then, that, in this 
standard logic, it is absurd to say of anything that it does not exist – and it is redun-
dant to say of anything that it exists. This seems to add support to the Kantian claim 
that existence is not a logical predicate but we realize that this is rather a feature of 
a specific formal-logical apparatus like the one we have at our disposal in the stan-
dard predicate logic.
5.4  Expanding ∏μ to ∏ρ=/∏μπφ=: Polyadic (or Relational) 
Predicate Logic with Function Symbols 
and the Identity Symbol
We will now add symbols, and make appropriate arrangements for grammatical 
formation, to expand our monadic logic system ∏μ to a formal idiom for what we 
call Polyadic or Relational Predicate Logic (∏ρ=) with function symbols and the 
identity symbol. From a metalogical point of view, this is a radical extension because 
we now lose certain desirable features of the monadic logic – when it comes to 
reaching effective decisions about logical properties. We do not engage in analytical 
presentation of any such issues. Let us keep in mind that Predicate Logic is also 
called First-Order Logic and, especially in older texts, Quantification Theory. 
Showing more detail, we can designated relational or polyadic logic (with function 
symbols and identity) as ∏πφ=. We concentrate on the grammar of ∏πφ=, our formal 
language for Relational Predicate Logic with functions and identity; in subsequent 
section, we will learn how to construct models for predicate logic.
It was a brilliant stroke of ingenuity in the history of logic that detected an option 
of managing the formal study of relations by means of logical predicates. Relations 
had presented formidable challenges to metaphysical thinkers of antiquity. The 
study of the logic of relations eluded Aristotle and baffled scores of astute logicians 
of later periods. The insight that allows us to treat relations by means of the formal 
processing of special predicate symbols can now be explained. Notice that the pred-
icate symbols we have included in our grammar so far are monadic (also called 
unary and one-place) predicate symbols. A monadic predicate symbol must be 
accompanied, as dictated by our grammar, by one term: this can be a variable – in 
which case we have a sentential function, not a meaningful sentence representa-
tion – or it can be accompanied by an individual constant – in which case we have 
a sentence that can express a meaning and, when we construct models, can be true 
or false.
The following are well-formed formulas, although the first is not a sentence but 
a sentential function:
Fx, Fa
5  Formal Predicate Logic (also called First-Order Logic) ∏

315
Other symbolizations you might come across in texts are as follows:
F(x), F(a), f(x), f(a), …
The variables and the constants are called TERMS.  The predicate symbol is 
accompanied, then, as we can say, by one term symbol. This can be called the 
input – sometimes also called the argument of the predicate. It is confusing to use 
the word “argument” here and we will avoid it. We can indicate the arity or degree 
of the predicate symbol by using an appropriate superscript from the set of integers. 
Of course, monadic predicate symbols have arity or degree 1. This can be indicated 
perspicuously as shown below although, to avoid clutter, it can be omitted since no 
ambiguity results from such an omission. We may also use subscripts for our predi-
cate symbols, as allowed by our grammar. The subscripts are taken from the set of 
positive integers.
F1x, F1a, G1
1x, G1
1a, …
We might wonder if we should consider the case of 0 as a superscript, which 
would characterize a zero-degree or zeroary predicate symbol. Technically, the 
answer is affirmative: a zero-ary predicate symbol is just a symbol for a sentence like 
the kind we dealt with in sentential logic when we did not have symbols to represent 
the internal logical components of sentences. Also a compound well-­formed formula 
of sentential logic can be, technically, characterized as a zeroary predicate symbol – a 
predicate symbol that does not take any inputs and, symbolically, not accompanied 
by some individual constant symbol that does not actually function as an input. For 
instance, we can have the following. We will not be dealing with such cases in our 
text but it is worthwhile mentioning the case of the zeroary predicate.
p ≡ F0
1a, ~ (p ∨ ~ (s ∙ ~ t)) ≡ F0
2a, …
When we ascend to arity or degree >1, we have a relational predicate symbol. We 
consider the general case to be that of an n-ary predicate (or n-place predicate). For 
illustration, we can check cases of binary (dyadic, two-place, degree-2) predicate 
symbols. Again, we may use subscripts and we can also apply superscripts that 
indicate the arity or degree, although we may also omit such superscripts since no 
ambiguity results from this. The binary predicate symbol has to be accompanied by 
two input symbols (variables or individual constants or a combination.) If we don’t 
have binding quantifiers for the terms accompanying the predicate, we can have a 
sentence only if the binary predicate symbol is accompanied by two individual con-
stants: in all other cases, we have open sentences since we have free (unbound) 
variables.
•	 Rab, R2ab	
sentence
•	 Rxy, R2xy	
sentential function (or, open sentence): x and y are free!
•	 Rax	 	
sentential function: x is free!
5.4  Expanding ∏μ to ∏ρ=/∏μπφ=: Polyadic (or Relational) Predicate Logic…

316
•	 Ryb	 	
sentential function: y is free!
•	 ∃xRxt	
sentence: x is bound by ∃; t is a constant (no binding needed.)
•	 ∃x∃yRxy	
sentence: both x and y are bound.
•	 ∀x∃yRxy	
sentence: both variables are bound.
•	 ∀zRzy	
sentential function: y is free!
We are getting some basic insights before we proceed to specify formally the 
grammar for ∏πφ=. This grammar retains all the conventions we established for the 
grammar of the monadic predicate logic and obtains, added to it, syntactical con-
ventions for the n-ary predicates. We allow capital letters for predicate symbols 
regardless of the arity. This is not creating confusion because, in well-formed for-
mulas, the number of term symbols accompanying the predicate symbol shows per-
spicuously the arity of the predicate symbol itself. Of course, we retain the option 
of using superscripts, from the positive integers, to show arity of a predicate sym-
bol; as we have indicated, we may or may not use this, optionally, because there is 
no ambiguity resulting from omitting superscripts.
•	 PREDICATE SYMBOLS n>1 = {A, B, …, R, S, …, R1, …}
•	 Rxy ∊ WFF(∏πφ=)	
[wff: well-formed formula; “∊” denotes membership. 
Think of the set of all well-formed formulas of the formal system, symbolized by 
“wff”: the symbol “∊” denotes membership in that set.]
•	 Rab ∊ WFF(∏πφ=)
•	 Rx1x2…xn ∊ WFF(∏πφ=)
•	 Rx1a2…xn ∊ WFF(∏πφ=)
•	 Rx1x2…an ∊ WFF(∏πφ=)
•	 Ra1a2…xn ∊ WFF(∏πφ=)
•	 Ra1a2…an ∊ WFF(∏πφ=)
•	 ∀x1∀x2… ∀xnRx1x2…xn ∊ WFF(∏πφ=)
•	 ∀x1∃x2… ∀xnRx1x2…xn ∊ WFF(∏πφ=)
•	 ∀x1∃x2… ∃xnRx1x2…xn ∊ WFF(∏πφ=)
•	 ∃x1∃x2… ∀xnRx1x2…xn ∊ WFF(∏πφ=)
•	 ∃x1∃x2… ∃xnRx1x2…xn ∊ WFF(∏πφ=)
•	 ∀x1∀x3… ∀xnRx1a2x3…xn ∊ WFF(∏πφ=)
•	 ⋯
The point is that well-formed formulas may have free variables, in which case we 
have sentential functions for reasons we explained above. Sentence formulas do not 
have any free or unbound variables. There has to be some way of writing, in our 
metalanguage, the recipe for forming well-formed formulas, and, indeed, there is:
•	 given that ⌜Rx1…xn⌝ ∊ WFF(∏πφ=), then if φ ∊ WFF(∏πφ=), 
then ℚx1…ℚxnφ ∊ WFF(∏πφ=).
where ℚ is either ⌜∀⌝ or ⌜∃⌝ and the variables in φ are free, so that they become 
bound by application of the quantifiers.
This tells us that we may prefix any number of quantifier symbols accompanied 
by the appropriate binding variable symbols in front of a wff which is specified as 
5  Formal Predicate Logic (also called First-Order Logic) ∏

317
being formed by concatenation of the predicate symbol and variable symbols. The 
formula to which quantifiers may be attached is called the matrix of the formula. As 
we have pointed out, this is also a wff (well-formed formula) insofar as it is formed 
correctly according to our grammatical instructions. By following this recipe for 
formation, we are able to avoid what we call vacuous quantification, examples of 
which are shown below:
∀x∀y∀zRxyy, ∃x∀yRxx, ∀z∃wRww, ∃x∃y∃zRyy, ∃x∃y∃zRxy,…
The vacuity consists in that some quantifier symbol (always understood to be 
accompanied by a variable) fails to bind any variable in the matrix formula to which 
it is attached. See if you can identify those failures. Notice that we consider matrices 
with unbound variables to be well-formed but when it comes to formulas with 
redundant – vacuous – quantifiers, they are considered ill-formed or grammatically 
incorrect.
Intuitions and linguistic illustrations begin to fail us when we ascend beyond the 
third degree or arity for relational predicates. When we seek examples for degree or 
arity 2, we have:
x loves y, x hates y, x is a sibling of y, x is a parent of y, x sits next to y, …
For three-place predicates (relational predicates of arity or degree 3), we may 
refer to the following examples:
x is between y and z, x gives y to z, x explains y to z, x is added to y to 
yield z, …
It becomes harder to find examples of relational predicates of degree or arity 4.
x gives y to z because of w, x asks y to give z to w, …
It is to be understood that the grammar we specify for ∏πφ= and the symbolic 
resources we are managing by means of this grammar are simply squiggles – speci-
fied symbolic shapes that are manipulated in a strictly specified grammatical fash-
ion. We are appealing to linguistic interpretations for illustrative purposes. When we 
take to building models for (∏πφ=), as we already intimated when we caught a 
glimpse of the process above, then we can formally fashion interpretations of our 
grammatical symbols so that predicate symbols are interpreted by linguistic rela-
tions, constants are interpreted by names, and so on.
We still have to add function symbols, and also the identity symbol, to our gram-
mar. To arrive at the point where we can construct narratives – models – for inter-
pretations of these symbols, we have to wait for the section on semantic models. 
The main issue is that we have a separation between grammatical manipulation of 
symbolic resources, which is what we lay down at first, and the semantic or meaning-­
based approach: in the latter case too, of course, we use the formal symbolic 
5.4  Expanding ∏μ to ∏ρ=/∏μπφ=: Polyadic (or Relational) Predicate Logic…

318
resources of our formal language but we also model so that we are able, coherently, 
to speak of meaningful sentences which can be true or false (within some specified 
model.) For as long as we are addressing the grammatical side of our formal setup, 
we speak, instead, not of meaning (or truth and falsehood) but of well-formedness 
(proper or correct grammatical or syntactical formation according to our specified 
formal grammar.)
•	 FUNCTION SYMBOLS = {f, g, h, …, f1, …}
•	 fx ∊ WFF(∏πφ=)
•	 fxy ∊ WFF(∏πφ=)
•	 fa ∊ WFF(∏πφ=)
•	 fax ∊ WFF(∏πφ=)
•	 fxb ∊ WFF(∏πφ=)
•	 fx1x2…xn ∊ WFF(∏πφ=)
•	 fa1x2…xn ∊ WFF(∏πφ=)
•	 fa1a2…xn ∊ WFF(∏πφ=)
•	 fa1a2…an ∊ WFF(∏πφ=)
•	 ⋯
We can see that function symbols have degrees or arity, like predicate symbols. 
A function symbol is accompanied by constants and/or variables. We can use super-
scripts to indicate the arity of the function but this is unnecessary as we can tell the 
degree of the function by counting the number of constants/variables that accom-
pany the function symbol. Those symbols of constants/variables are called inputs of 
the function. We could, but we don’t, symbolize as follows:
f(x), f(a), …
You might be familiar with functional notation from Mathematics. Notice how 
we can have unary functions, binary functions, and so on to n-ary functions. (We 
always take the arity to be finite.) We omit from our symbolization the parentheses 
to avoid clutter. We also have the option, as with predicate symbols, of using super-
scripts to indicate degree but we may as well dispense with such superscripts 
because there is no ambiguity: the number of symbols accompanying the function 
symbol, in well-formed formulas, shows the degree of the function symbol itself.
•	 unary (also called monadic, one-place, singulary) functions: fx, gy, ha, fa, 
gb, gz, …
•	 binary (also called dyadic, two-place) functions: fxx, fxy, gzw, fab, gcc, 
hxa, fby…
•	 nary (also called n-place) functions: fx1x2…xn, fa1…xn, fa1a2…xn, …
Considering our selection of symbols for functions, and to avoid clashes, we 
must withdraw those symbols from the stock of symbols for constants. Thus,
TERMS::CONSTANTS = {a, b, c, …, a1, …} – {f, g, h, …, f1, …}
5  Formal Predicate Logic (also called First-Order Logic) ∏

319
Let us point out – and insist that this be committed to memory – that function 
symbols are TERMS, like the individual constants and the variables. Like the con-
stants, and unlike the variables, function symbols that are accompanied by constants 
and/or bound variables have referents: they refer, in the modeling we will be doing, 
to specified objects in the domain. This means that function symbols that are accom-
panied by constants and/or bound variables can be parts of meaningful sentences. If, 
however, we have any free variables accompanying the function symbol, then the 
formula must be a sentential function. To obtain an intuitive grasp of how our func-
tion symbols will work in our semantic modeling, let us consider linguistic exam-
ples in which we find what we will model as functions:
•	 father of___	
	
monadic function
•	 mother of___	 	
monadic function
•	 sum of __ and ---	
binary or dyadic or degree-2 function
•	 father of John	 	
--the function has a name as input: this is a term that 
refers to someone.
•	 The sentence “the father of John is Bill” is meaningful. This alerts us that we will 
need a symbol for identity, which symbol we will be adding to our grammar 
shortly. Notice that “is” in this sentence stands for the use of the verb “to be” in 
the sense of identity.
•	 In contrast: “the father of x is y” is a sentential function. We have identity here 
too but the input, and the variable with which we identify the function, are 
unbound variables.
•	 “Someone is the father of Bill” is a sentence: we read, “there is an x, such that x 
is the father of Bill.” Here the variable ⌜x⌝ is bound by the existential quantifier. 
Hence, we have a sentence – not a sentential function.
Finally, we add the identity symbol. We anticipated its need by means of the 
linguistic illustrations we deployed. In predicate logic, we mean by identity between 
two terms that the two terms co-refer or refer to the same (identical) object in the 
domain of our model. Of course, we first introduce the identity symbol syntactically 
and specify its grammar, as we have been doing with our symbols. Looking ahead 
to the semantic modeling, let us repeat again that identity of two terms means that 
the two terms name or pick out exactly one and the same object in the domain. Thus, 
identity has to be understood as a binary relation that relates two terms. You might 
wonder as to why we make a special arrangement for an identity symbol instead of 
treating the matter by using a dedicated binary predicate symbol. For instance, we 
could be specifying our grammar as follows:
Ixy, Iab, Ibx, Iax, …
The binary predicate symbol ⌜I⌝, or any other predicate symbol accompanied by 
two terms, could do the trick. Nevertheless, there is a good reason why we do not 
manage identity by means of a relational predicate. Any predicate (unary or n-ary) 
is a non-logical constant. We have already pointed this out and here is, again, what 
we mean by this. We have said that a predicate is to be interpreted or valuated, in a 
5.4  Expanding ∏μ to ∏ρ=/∏μπφ=: Polyadic (or Relational) Predicate Logic…

320
model, as referring to the set of all the domain-objects that have the property repre-
sented by the predicate. Thus, the semantics of a binary identity-predicate would 
make the symbol refer, and have as meaning, the set of all pairs of things that are 
identical with each other. Now, for any predicate – it being a non-logical constant – 
we should always be able to build some other model in which the set of the predicate 
has different members; we can make one model in which the predicate set has all the 
member of the domain in it and we can make another model in which this predicate 
has the empty set as its referent. For instance, take the predicate “human”: we can 
make a model in which we have all humans – thus the set for “human” is the entire 
domain; but we can also make – why not? – Another model in which there are no 
humans, so the set that is the referent for “human” in that model is the empty set (the 
set without members.) This applies for the case of every model, and for any arity of 
predicate. There is a world – a narrative, a model – in which Jack loves Jill and there 
is another perfectly fine (coherent, consistent, logically possible) narrative or model 
in which it is not true that Jack loves Jill. Thus, the binary predicate “love” can have 
the pair <Jack, Jill> as member in one model but not have this pair in it in some 
other model. But, when it comes to identity, we notice that something different hap-
pens. In every model, the pair of any object with itself (let’s say, the pair <≬, ≬>, for 
any object ≬) has to be in the identity-set! This shows us that identity does not 
behave like a non-logical constant: unlike non-logical constants, an identity set 
would have to have those pairs made of objects and themselves – for all the objects.
Approached in a different way, we can say that we actually have logical truths 
about identity. For instance, “everything is identical with itself” is a logical truth; it 
must be, if anything is. But this is not what happens with non-logical or predicate 
constants: take any predicate, or relational predicate, and you should never expect 
to find a logical truth depending on the meaning of that predicate. For instance, 
“Jack loves Jill” cannot be a logical truth. Even if it is true, actually true, and even 
if the two members of the pair swear to eternal devotion to each other, this is not a 
truth of logic! Sad to say, it is logically possible that “Jack loves Jill” is not true: an 
alternative logical possibility, a model or possible narrative exists, can be con-
structed, in which it is not the case that Jack loves Jill.
The symbol for identity we will use is “=”. We read this as “identity” and not as 
“equality.” We don’t have a notion of equality in our symbolic language. We are not 
engaged in using algebraic means. Even though we might be used to calling “=” the 
equality sign, it is for us in predicate logic the identity sign. We use infix notation, 
which means that we place the identity sign between the related terms (the identified 
terms which are related, and can be called relata.)
•	 λ = μ ∊ WFF(∏πφ=)
where λ and μ ∊ TERMS = {x, y, z, …, x1, …, a, b, …, a1, …, fx, fa, …, f1x, …}.
Notice that the terms include the functions. Thus, the identity symbol can relate 
function symbols. To use a linguistic illustration, “the mother of John is the mother 
of Mary.” An identity formula represents, semantically, a sentence if there are no 
free variables related. In other cases, the formula represents a sentential function. 
Thus, “someone is the father of Jill” is a sentence (but notice that we don’t know 
5  Formal Predicate Logic (also called First-Order Logic) ∏

321
how to symbolize this yet, although we can reflect already that the “is” in this sen-
tence has the meaning of identity: “there is an x, such that x is identical with the 
father of Jill.”) Here are examples:
•	 a = b	
sentence; the constants ⌜a⌝ and ⌜b⌝ refer to the same object.
•	 x = y	
sentential function.
•	 x = a	
sentential function – free variable x.
•	 ∀x∀y(x = y)	
sentence: everything is identical with everything.
•	 ∃x(x = x)	
sentence: something is identical with itself.
•	 ∃x(x = b)	
sentence: something is (identical with) the object referred 
to by b.
•	 ha = hb	
 sentence: if ⌜hx⌝ stands for “mother of x” then this means that 
the mother of the entity referred to by ⌜a⌝ is the same as the 
mother of the entity referred to by ⌜b⌝.
•	 ∀x∃y(hx = hy)	 sentence: everyone’s mother is someone’s mother.
•	 ∃x(fx = j)	
 sentence: someone’s father is John. (In better idiomatic English: 
“John is someone’s father.” Strictly speaking, if we are scan-
ning our grammar without regard for English idiomaticity, we 
can say: “there is at least one x, such that the father of x is iden-
tical with the person denoted or referred to by the name ‘John’.”)
We can compose function symbols in many ways. Consider, matching linguistic 
examples with symbolizations (retaining our key of symbolization as in the preced-
ing examples):
•	 The father of the father of John: ffj
•	 The father of the mother of Mary: fhm
•	 The mother of the mother of someone is Mary: ∃x(hhx = m)
•	 We can formalize “the grandmother of Mary” in two different ways, by using 
functional symbols (adding “h1” for “grandmother”): ⌜h1m⌝ or ⌜hhm⌝
•	 The mother of Mary is related by the R-relation to the father of John: Rhmfj
•	 The mother of the father of the mother of John: hfhj
Whatever we can formalize or symbolize by use of function symbols we can also 
formalize by the use of relational predicate symbols – and the other way round. This 
can be done provided that there exists a unique y to which x is R-related: in that 
case, and only in that case, ⌜fx = y⌝ can replace ⌜Rxy⌝. It is interesting to note what 
happens to the arity and degree of the symbols. Let us attempt this. We use the trans-
lation key: “Fxy” and “Mxy” as predicate symbols for “x is the father of y” and “x 
is the mother of y” respectively. We retain in this key, “fx” and “hx” as, respectively, 
function symbols for “father of x” and “mother of x.” We can tell that we are dealing 
either with predicate symbols or with functional symbols. The predicate letters are 
capital letters and the functional symbols are small letters from the part of the alpha-
bet in the set {f, g, h, …}. We have stipulated all this in our official symbolic 
5.4  Expanding ∏μ to ∏ρ=/∏μπφ=: Polyadic (or Relational) Predicate Logic…

322
grammar. The number of accompanying term symbols shows us the arity of the 
predicate symbol or the degree of the functional symbol.
•	 Mary is the mother of John: Mjm
•	 Mary is the mother of John: hj = m
We can show the arity and degree by superscripts. We have indicated that we can 
dispense with such symbols but we are also at liberty to introduce them for some 
purpose.
•	 Mary is the mother of John: M2jm
•	 Mary is the mother of John: h1j = m
We notice that the arity of the predicate, n is related to the degree of the function, 
d, by means of the formula:
n = d + 1
We also mark the use of the identity sign, which is needed when the functional 
symbol is used. We now proceed to show more examples of relational-predicate 
versus functional-symbol formalization.
•	 There is someone who is John’s father: ∃xFxj
•	 There is someone who is John’s father: ∃x(fj = x)
•	 Mary is John’s mother: Mjm
•	 Mary is John’s mother: hj = m
•	 John has no mother: ~ ∃xMxj
•	 John has no mother: ~ ∃x(mj = x)
•	 Everyone who has a mother also has a father: ∀x(∃yMyx ⊃ ∃zFzx)
•	 Everyone who has a mother also has a father: ∀x(∃y(mx = y) ⊃ ∃z(fx = z))
Our well-formed formulas can look daunting to the uninitiated and unpracticed 
eye. Many texts use parentheses within which they enclose the term symbols (sym-
bols for variables, constants, functions and also the symbols for the inputs of func-
tions  – all these are term symbols.) We dispense in our grammar with such 
parentheses; our facility for tracking what term symbols accompany what symbols 
can develop as a result of concentration and practice; we allow ourselves, according 
to our grammatical arrangements, to use superscripts from the natural numbers to 
show arities of predicate symbols and of function symbols. Using those superscripts 
facilitates learning and practice in the grammar and recognition of the composi-
tional parts of the formulas: of course, prolonger practice should allow us to dis-
pense with the use of superscripts without running astray in keeping track of what 
symbols go with what symbols in the well-formed formulas. For now, we will work 
on examples patiently in order to make clear how this grammar works. It is to be 
kept in mind, as well, that the grammatical accommodations and arrangements that 
were laid down for the grammar of our sentential formal idiom we learned are still 
in effect: after all, our predicate logic formal systems have been extending, as we 
say, the sentential formal language.
5  Formal Predicate Logic (also called First-Order Logic) ∏

323
•	 f3xab  - the superscript indicates that the function is ternary or three-­place; three 
input symbols are needed for well-formedness; one is a variable symbol (this is 
allowed by the grammar), and the other two are individual constant symbols; 
although this formula cannot be interpreted semantically as a sentential formula, 
it is still well-formed; let us concentrate on understanding why semantic inter-
pretation as a sentential formula is not available: this is because this is an open 
sentence or sentential function insofar as it has a free (unbound) formula. But 
now compare the following example of a well-formed formula that is also avail-
able to be semantically interpreted as a sentential formula.
•	 ∃xf2xa  - if we take a semantic reading, we have: at least one x is f-related to the 
item named ⌜a⌝. In a more concrete interpretation, if ⌜fxy⌝ stands for “x is the 
father of y”, then we have: at least one person is the father of the person named 
⌜a⌝. Of course, exactly one person can be the father of someone. It is also true 
that at least one person (the weaker statement) is the father of someone named 
insofar as the right person is indicated. We are not interested, actually, in empiri-
cal confirmations – something that we will continue to stress and explicate, espe-
cially when we turn to the working out of semantic models. If the semantic 
interpretation turns a false sentence  – relative to some specified context or 
model – that is irrelevant for our discussion of how the grammar works.
•	 ∀x∀y∃zR3f2axg2ayz  - the predicate symbol is ternary or three-place: three 
accompanying terms are needed; one is the binary function ⌜f⌝ which is appro-
priately accompanied by two input symbols, ⌜a⌝ and ⌜x⌝, both of which are, 
appropriately terms (remember, terms include variables, constants and functions 
and, certainly, also inputs of functions); the second accompanying term that is 
input to the predicate symbol, is another binary function symbol, ⌜g⌝, which is 
itself, appropriately, accompanied by two input symbols, ⌜a⌝ and ⌜y⌝; the final 
input symbol to the ternary predicate symbol is the variable ⌜z⌝. All the formulas 
are bound – no variable is free: hence, in terms of characterizing this formula as 
an open sentence of sentential formula – it is a sentential formula.
•	 P1f1x ⊃ ~ R2ag2f1aa  - this is an open sentence since there are unbound variables but 
it is also a well-formed formula; the main connective symbol is the horseshoe; we 
can think of quantifier symbols themselves as being aligned with connectives 
(assuming that we interpret our formulas semantically over finite domains); if the 
largest-scope symbol is a quantifier symbol, that certainly supersedes connective 
symbols; or, to put it otherwise, connective symbols can be within the scope of some 
quantifier symbol; but in the present formula, the largest-­scope symbol is a connec-
tive symbol and that should be remembered because ignoring it can lead to errors 
when it comes to applications of rule sin proof-systems. Notice that the predicate 
symbol in the antecedent (to the left of the horseshoe) is monadic: it is accompanied 
by one term, a function symbol that is itself monadic and has one symbol (a vari-
able) as its input; the consequent – to the right of the horseshoe – we have a binary 
predicate symbol accompanied by two term symbols: ⌜a⌝, a constant symbol, and a 
binary function symbol ⌜g⌝ which has two symbols as inputs – the monadic func-
tion ⌜f⌝ with input ⌜a⌝ and, as second input symbol to ⌜g⌝ the constant symbol ⌜a⌝. 
Anticipating our parsing or decomposing diagraming of the next section, let us 
show perspicuously how this grammatical arrangement of symbols works: 
5.5  Parsing Trees of Well-Formed Formulas of ∏πφ=: ℑ(∏πφ=)

324
•	 Regarding the identity symbol, we take it to be binding more strongly than other 
symbols: this allows us to dispense with parentheses; notice that we have essen-
tially adopted such a convention for the negation symbol. We don’t write,
•	 ~ (p).
•	 but
•	 ~ p
•	 But we need,
•	 ~ (p ⊃ q).
•	 because.
•	 ~ p ⊃ q.
•	 has the negation sign bound strongly to the first following atomic variable.
•	 Compare similarly:
•	 a = b ⊃ ∃x∃y(x = y).
•	 instead of writing (although it would not count as an error to write):
•	 (a = b) ⊃ ∃x∃y(x = y)
•	 We observe the same convention for the symbol “≠” which we conveniently 
incorporate in our symbolic notation.
5.5  Parsing Trees of Well-Formed Formulas of ∏πφ=: ℑ(∏πφ=)
As we did for well-formed formulas of our sentential logic idiom, we also subject 
well-formed formulas of ∏ρ= to a parsing or decomposition by means of a tree-­
based procedure. The parsing gives us decomposition of the well-formed formula ψ 
into all the subformulas of ψ (including ψ itself which is a degenerate case, meaning 
that every formulas is its own subformula in a sense.)
The rules for the parsing tree, which we legislated for the connective symbols of 
the sentential logic in 4.2, are transferred here; we add parsing rules for the new 
○
○P1f1x ⊃ ~ R2ag2f1aa
⇙⇘ 
P1f1x	
~ R2ag2f 1aa
⇙⇓	
 ⇙ ⇘
P1 f1x	
~	
R2a	
g2f	
1aa.
⇙⇘	
⇙      ⇓     ⇘
f1 x	
	
R2 a	 g2	
f1a     a
	
⇙      ⇓     ⇘
	
	
	
g2	
f1a a
	
	
⇙⇘
	
	
	
	
f1 a
5  Formal Predicate Logic (also called First-Order Logic) ∏

325
symbols we have in the predicate logic idiom. Our predicate logic language has 
extended our sentential logic idiom and, accordingly, we have had additional forma-
tion rules introduced on top of those we were implementing in the sentential logic 
idiom. We repeat, for convenience, the decomposition rules of the sentential logic 
and then we show the schematic (figure-like) representations of the rules for the 
symbols that have been added to obtain ∏ρ=. Since we have the option of using 
superscripts to mark the arity of predicate and function symbols, we may as well 
take advantage of this at will: doing so facilitates visual recognition of arity and also 
assists in ascertaining that the formation of the given formula is grammatically cor-
rect; finally, the parsing process may also be facilitated (although practice should 
allow one to dispense with such visual assistance.)
 
The quantifier rule leaves a formula in which the variable of the quantifier is left 
unbound or free; given the formation rules we have legislated in our formal gram-
mar, this is expected because the quantifier symbol is presumed, for grammatical 
correctness, to be attached to a formula in which the quantifier’s accompanying 
variable is free. Notice, though, that variables other than the one that is attached to 
the quantifier symbol may or may not be free: as we know, we count a formula that 
has free variables as well-formed (although it is not a sentential formula but what 
we have called an open sentence or sentential function.)
We continue the decomposition at a level below that of well-formed subformu-
las; this means, that we break predicate symbols away from their accompanying 
term (variable or constant) symbols; we do the same with function symbols. 
Because of this, our determination of the set of subformulas of the given formula 
will require focused attention to extract from the information of the parsing tree. 
We use the metalinguistic symbols “Φn” and “ℊn” for predicate and function sym-
bols of n arity. Also we use “λ” for term variable (which can be a variable or a 
constant symbol.)
5.5  Parsing Trees of Well-Formed Formulas of ∏πφ=: ℑ(∏πφ=)

326
 
The subformulas we extract from the parsing tree do not include, of course, the iso-
lated symbols for predicates, functions, variables and constants since these are not, by 
themselves, grammatically correct or well-formed formulas of our formal system. The 
benefits we gain from parsing beyond subformulas have to do with tracking the arities 
of predicate and function symbols and matching with the number of accompanying 
term symbols (terms include the variables, the constants and the function symbols.)
5.5.1  Exercises
	1.	 Which of the following symbolic expressions are well-formed formulas of ∏μ? 
Realize that formulas can be well-formed even without all variables being 
bound – in other words, even without expressing a statement that is capable of 
being true or false. Grammar and semantic assignment of meanings come apart 
in the grammar of predicate logic.
	
a.	 ~ ∃xFa
	
b.	 ~ ~ p ⊃ ∃xGx
	
c.	 ~ ~ (∀xFx ⊃ ∀x(Gx ∨ Hx))
	
d.	 ∀yRz
	
e.	 ∃x∃xRxx
	
f.	 ∀x∀y∃R(x ≠y ⊃ Rxy)
	
g.	 ~ δ ≡ ∀x(Fx ≡ Gx)
	
h.	 ∃xFx ⊃ ∃yFy
	
i.	 Fx ∨ ∀y(Ay ⊃ Bz)
	
j.	 ∃x(Fx ∨ Gx) ⊃ (AxFx ⊃ ~ ∀yGy)
	
k.	 ∀x(Fx ⊃ Gx) ⊃ (∀xFx ⊃ ∃xFx)
	
l.	 ∀cFc ∨ ~ ∃yFy
	
m.	 ∀x(Fx ∨ ~ Gy)
	2.	 Identify the bound and unbound (free) variables in the following well-formed 
formulas of ∏μ.
	
a.	 ∀xFx ≡ Gx
	
b.	 ∃x(Fx ∨ ~ Gx)
	
c.	 Fx ∨ ~ ∀xGx
	
d.	 ∀x∃y((Fx ∙ Gx) ⊃ Hy)
5  Formal Predicate Logic (also called First-Order Logic) ∏

327
	
e.	 ∀x(Fx ⊃ ∀y(Fy ⊃ Gw))
	
f.	 (∀xFx ≡ ∀yFy) ⊃ ∀z(Fz ∨ ~ Fz)
	
g.	 ~ (Ha ∙ Hb) ⊃ ∃x(~ Gx ≡ ~ Fx)
	
h.	 Fa ⊃ ∃x(Fx ∨ Hy)
	
i.	 ∃x(Fa ⊃ ∃y(Fx ∨ ~ Fy))
	3.	 Identify the arity of the predicate symbols and function symbols of ∏πφ=.
	
a.	 Rxy
	
b.	 Saxyz
	
c.	 Rafxfyw
	
d.	 Sxyfxfx
	
e.	 fa
	
f.	 gcd
	
g.	 fhahbhc
	
h.	 Rxygab
	4.	 Which of the following symbolic expressions are well-formed formulas of ∏πφ=? 
Remember that open sentences, not expressing statements, can still be well-­
formed formulas of ∏πφ=.
	
a.	 ~ Rab ⊃ ∃c∃d ~ Rcd
	
b.	 ∃xφ ∨ ~ ∀x ~ Fx
	
c.	 fa = fab
	
d.	 Rab = Rba
	
e.	 gab ⊃ ∃x∃ygxy
	
f.	 Fa ↠ ~ ~ ∃xFx
	
g.	 ~ ((∀xFx ⊃ ∃yFy) ⊃ (∃yFy ⊃∀yFy)
	
h.	 ∀x∃yRxy ⊃ ∃y∀xRxy
	
i.	 ∀x∀y(x = y ≡ y = x)
	
j.	 Rfxgy ⊃ x = y
	
k.	 ∃x(Rfxa ⊃ a = b) ⊃ ∃y(Rfya ⊃ a = b)
	
l.	 ∀x∀y∃z(Rxyz ≡ ∃u(Rxyu ≡ Rxuy))
	
m.	 ∃u∃w(Rwu ⊃ (Ruw ⊃ Ruuw))
	
n.	 ∀x∀yRab ⊃ Rab
	5.	 Identify the bound and unbound (free) variables, if there are such, in the follow-
ing well-formed formulas of ∏πφ=?
	
a.	 ∃x(fb = x) ⊃ Fxb
	
b.	 ∀x∃y(x ≠ y ∙ Lxy)
	
c.	 ~ ∃yRxy ∨ ∀ySyy
	
d.	 gax = gab ⊃ x = b
	
e.	 Rfafb ≡ ∃x∃y(x ≠ y ∙ fx = a ∙ fy = b)
	
f.	 ~ ∀wRzw ⊃ ∃z ~ Rzw
	
g.	 ∃x∃y∃z((Rxyz ∙ Rzyx) ⊃ (Rxab ∨ Raxb ∨ Rbax))
	
h.	 Qxaw ⊃ ∃y∀zQyaz
	
i.	 (x = y ∙ y = z) ⊃ ∃u∃v((u = v) ∙ (v = u))
5.5  Parsing Trees of Well-Formed Formulas of ∏πφ=: ℑ(∏πφ=)

328
	6.	 Bind all free variables by appropriate quantifier symbol to generate statement-­
expressing formulas from the given open sentences. Is there more than one way 
to do this in each case?
	
a.	 ∀x∀y∃zRxyz ⊃ Rabx
	
b.	 ∀x(Rxx ≡ (Rxy ∨ Ryx))
	
c.	 (fb = x) ⊃ (Rab ⊃ (fa = x))
	
d.	 ∀x(Rxy ∨Ryx ∨ x = y)
	
e.	 ∃x(Rxy ≡ Ryx)
	
f.	 Fa ⊃ (Rax ∨ Rxa)
	
g.	 ((Rxy ∙ Ryz) ⊃ Rxz)
	7.	 Draw parsing syntactic (grammar) trees for the following given well-formed for-
mulas of ∏πφ=.
	
a.	 ~ ∃x∃yRxy ⊃ ∀x∀y ~ Rxy
	
b.	 ∀x∀y∀z((Rxy ∙ ~ Ryx) ⊃ y ≠ x)
	
c.	 ∃x∃y(x = y ⊃ (Rxy ≡ ~ Ryx))
	
d.	 ∃x∀y((Rxy ≡ x = y) ∙ x = fa)
	
e.	 ∀x∀y(Lxy ⊃ (x = y ⊃ ~ ∃z(z ≠ y ∙ Lyz)))
	
f.	 Fa ≡ ~ ∃x(x = fa ∨ Rax)
	8.	 Recalling what we studied in 3.2.a, we know that we can render the given well-­
formed formula into its Polish formal notation based on the appropriate tree of 
the parsing tree. The connective symbols in the Polish notation are, as we may 
recall, from {N, K, A, C, E} and we supplement with, respectively, the universal 
and existential quantifier symbols from {Π, Σ}, and treating identity as a binary 
predicate (Ixy) while retaining the function symbols as we have them, to extend 
to the formal system ΠPOLISH. Study the given example and then draw parsing 
trees for the given formulas and render into the Polish notation.
        ⇙⇘⊃R
∃y∀xRyx	
∀x∃yRyx
⇓∃R	
⇓∀R
∀xRyx	
∃yRyx
⇓∀R	
⇓∃R
Ryx	
Ryx
⇙⇓⇘RedR	 ⇙⇓⇘PredR
R y x	
R y x
∃y∀xRyx ⊃ ∀x∃yRyx.
5  Formal Predicate Logic (also called First-Order Logic) ∏

329
Reading the symbols for which rules are applied, from left and exhausting 
vertically before we move to the right, we have first a Polish notation that uses, 
metalinguistically, our symbols; subsequently we render into the proper Polish 
notation.
⊃∃y∀xRyx∀x∃yRyx	⤇	
CΣxΠxRyxΠxΣyRyx
Next, discover the Polish notation for the given formulas below.
	
a.	 ∀x∀yRxy ⊃ ∃x∃yRxy
	
b.	 ∃x∀y(Fy ≡ y = x)
	
c.	 ∃x∃y(fx = y ≡ fy = x)
	
d.	 Rab ⊃ ~ ∀x∀y(Rxy ∨ Ryx ∨ x = y)
	
e.	 ∀x∃yRxy ⊃ (∃xRxx ⊃ ∃y∀xRxy)
	
f.	 ~ ∀x∃yRxy ≡ ∃x∀y ~ Rxy
5  Formal Predicate Logic (also called First-Order Logic) ∏

331
© The Author(s), under exclusive license to Springer Nature 
Switzerland AG 2022
O. Makridis, Symbolic Logic, Palgrave Philosophy Today, 
https://doi.org/10.1007/978-3-030-67396-3_6
Chapter 6
Translations from English into ∏πφ= (also 
called Symbolizations, Formalizations)
We translate the meanings of sentences of English into our formal symbolic lan-
guage ∏πφ=. The symbolic resources we have at our disposal, regulated by the gram-
mar we have instituted, can be shown compendiously:
The symbolic language of predicate logic (also called first-order logic or quanti-
fication theory) is minimally adequate for translating statements from the language 
of mathematics and, historically, this is a factor that motivated the development of 
this formalism. Nevertheless, translations  of completely descriptive statements of 
certain mathematical laws may well require a higher-order language, which allows 
for quantification over predicate variables: we do not study higher-order logics in 
the present text.
We have available: the symbols for the standard connectives; predicate symbols 
of any arity; variable symbols, possibly with subscripts from the denumerable set of 
positive integers; individual constant symbols also with subscripts as needed; the 
quantifier symbols; the identity symbols; and function symbols with subscripts as 
needed. We may omit superscripts that indicate arity. We also have the auxiliary 
symbols of parentheses to sue only to prevent ambiguity of the formulas.
The observations for translation into sentential logic, which we studied in earlier 
chapter, still apply, of course, since the connective symbols of predicate logic are 
the same as those of sentential logic – the predicate logic extends the sentential 
logic. We need next to turn to the intricate subject of providing guidance for how to 
symbolize (formalize, translate) into ∏πφ=.
GRAMMAR(∏πφ=): Aj/Ak, …, Fi,Gl,…/xm, …/aj, …/{~,., ∨, ⊃, ≡}/{∀, ∃}/
{=}/fj,…//(/).

332
6.1  # Tips for Translation (Symbolization, Formalization)
•	 The structure of the sentence that is translated should be preserved as much as 
possible. For instance, the translation of “no one is a student” should not be ren-
dered formally by means of a formula whose direct reading is “everyone is not a 
student” even though the two sentences are logically equivalent.
•	 As we know, non-truth-functional logic-words cannot be rendered by the sym-
bolic and grammatical resources of the standard logic: this continues to be case.
•	 A natural language like English does not necessarily show its logical structure: 
the formal structure or logical form must be extracted. For instance, “a student 
who does not know logic is lost” is a universally, not an existentially, quantified 
statement in spite of the use of the indefinite article which, in this case, connotes 
universal quantification: the meaning is that every student who has the attribute 
of not knowing logic is a student who has the attribute of being lost. But the 
sentence “the student who does not know logic is a student who is lost” is also 
universally quantified: the definite article in this sentence does not function as a 
definite description indicator but as connoting universal quantification.
•	 We prefer translations that show the structure of the translated sentence in greater 
depth. We show examples.
	1.	 (S1) Everyone who is a student and is at the door will be admitted.
a. Key: Dx: x is a student at the door.
Ax: x is admitted.
∀x(Dx ⊃ Ax)
b. Deeper Structure/Universal Domain: Key: Sx: x is a student;
Dx: x is at the door;
Ax: x is admitted.
∀x((Sx. Dx) ⊃ Ax)
2. (S2) Anyone who is a father has some child.
This case offers us the options of using a relational predicate symbol or a 
function symbol to render “x is the father of y.” The use of the function symbol 
commits us, of course, to the fact, in the model we are using, that there exists an 
x-related entity y which is unique: this entity y is the value of the function for the 
input x. We may wonder if it makes any difference from the standpoint of struc-
tural depth that is captured by the translation. But there are some other possibili-
ties too that allow us to consider which one of our relative options we should adopt.
a. Key: Fx: x is a father.
Cxy: x is child of y.
∀x(Fx ⊃ ∃yCyx) or ∀x∃y(Fx ⊃ Cyx)
b. Key: f(x) = the father of x.
c(x) = the child of x.
∀x(∃y(x = fy) ⊃ ∃z(z = cx)
If we are wondering as to which one we should prefer between b and c: for 
most purposes, it should not make any difference.
6  Translations from English into ∏πφ= (also called Symbolizations…

333
(3) (S3) A student is sitting on a bench.
Sx: x is a student.
Txy: x is sitting on y.
Bx: x is a bench.
Ox: x is sitting on a bench.
a. ∃x(Sx ∙ Ox)
b. ∃x(Sx ∙ ∃y(By ∙ ∀z(Bz ⊃ z = y) ∙ Txy))
Translation b shows deeper structure. The domain is allowed to have both stu-
dents and benches and this requires use of predicate symbols for specification. The 
implication is that there is a specific bench on which the student is sitting and this 
must be shown too.
•	 A general observation is that the matrices of “all F are G” statements are trans-
lated as implicational and the matrices of all “some F are G” statements are 
translated as conjunctive. For a statement,
•	 Qx(Fx … Gx).
•	 the part following the quantifier symbol is the matrix. Accordingly, we have:
•	 All F are G:: ∀x(Fx ⊃ Gx)
•	 Some F are G:: ∃x(Fx ∙ Gx)
•	 We can examine why it would be wrong to do otherwise. Let us assume that we 
have a model or structure, with two members in its domain, both of which mem-
bers are named, and we have also interpretations for (value assignments, assign-
ments of members from the domain to) the two predicate non-logical constants.
•	 𝔐 = <ⅅ = {①, ②}, |a| =①, |b| = ②, |F| = {a}, |G| = {a}>.
•	 We can express the universally quantifications as conjunctions and existential 
quantifications as inclusive disjunctions in the case of a model like this, with a 
finite number of members.
•	 ∀xφ ≡ (φ[a/x] ∙ φ[b/x]).
•	 ∃xφ ≡ (φ[a/x] ∨ φ[b/x]).
•	 Let us assume that we opt for translations rendering “all F are G” as a conjunc-
tion and “some F are G” as an implication.
•	 ∀x(Fx ∙ Gx) ≡ ((Fa ∙ Ga) ∙ (Fa ∙ Gb) ∙ (Fb ∙ Ga) ∙ (Fb ∙ Gb)) ≡ (Fa ∙ Fb ∙ Ga ∙ Gb).
•	 We see, however, that in our constructed model it is not the case that the object 
named by b is an F or a G, and yet it is the case all objects that are F (which is the 
object named by a) are also G!
•	 For the case of “some F are G,” we can survey accordingly what consequences 
we incur if we render the translation of the matrix of the statement as an 
implication.
6.1  # Tips for Translation (Symbolization, Formalization)

334
•	 We construct a different model. In this model, none of the domain’s objects is an 
F. There is nothing that is both an F and G.
•	 𝔐 = <ⅅ = {①, ②}, |a| =①, |b| = ②, |F| = ∅, |G| = {a}>.
•	 Now we carry out the proposed translation.
•	 ∃x(Fx ⊃ Gx) ≡ ((Fa ⊃ Ga) ∨ (Fa ⊃ Gb) ∨ (Fb ⊃ Ga) ∨ (Fb ⊃ Gb)) ≡ (~ Fa ∨ Ga 
∨ ~ Fa ∨ Gb ∨ ~ Fb ∨ Ga ∨ ~ Fb ∨ Gb) ≡ (~ Fa ∨ ~ Fb ∨ Ga ∨ Gb).
•	 This, however, would mean that that “some F are G” is true, since we have in our 
inclusive disjunction at least one true disjunct (b is a G): and yet, as we inspect 
the given model, we establish that there are no Fs and, therefore, there are no 
objects in the domain that are both F and G. In general, the mistake of translating 
“some Fs are Gs” is exposed as consisting in that a false antecedent (which we 
get in the case an object is not in the extension of a predicate) makes the implica-
tion false (this is something to know, and this is a case we may call vacuous 
implication): but, in that case, objects that simply lack an attribute, let’s say F, 
can be said to have both this attribute F and another attribute, let’s call it G in the 
general case. This is, of course, absurd.
•	 Although this is not pursued in textbook presentations anymore, we should real-
ize that we are able to use the resources of predicate logic in order to symbolize 
temporal references – insofar as the temporal phrases do not generate referen-
tially opaque contexts in the specific linguistic usage we are targeting for transla-
tion. For example, the proposition expressed by the sentence “there will be a sea 
battle tomorrow” has a non-truth-functional phrase in “there will be___” which 
we could not render by means of any truth-functional connective in sentential 
logic. None of the four mathematically available unary truth-functional connec-
tives can be used. Given the resources of predicate logic, we still have only truth-­
functional connectives at our disposal. We can, however, remove restrictions on 
the domain and construct predicate symbols for moments and temporal relations. 
We can even opt for detail, risking cumbersome expressivity, as in the following 
translation. The wide availability of tense logics, which are extensions of the 
truth-functional logic, and the fact that we can show greater structural depth of 
the form by using such logics, are the reasons why using predicate logic for 
translating temporal statements has fallen rather out of fashion.
(S1) There will be a sea battle tomorrow.
There is a moment x and there is a moment y and x is tomorrow and y is tomor-
row and x is before y and a sea battle starts at x and ends at y.
∃x∃y(Mx. My. Tx. Ty. Bxy. ∃z(Bz. Szx. Ezy))
The predicate symbols that share “B” are disambiguated because one is unary 
and the other binary.
We can give more examples in which temporal references are rendered 
symbolically.
(S2) It never rains in the plain in Spain.
KeyL Tx: x is time period;
6  Translations from English into ∏πφ= (also called Symbolizations…

335
Pxy: x is a plain in country y;
Rxy: it rains at place x at time period y;
s: Spain.
~ ∃x(Tx. ∃y(Pys. Ryx))
(S2) Only when it rains do the flowers thrive.
Key: Fx: x is a flower;
Tx: x is a time period;
Vxy: x thrives over period y;
Rx: it rains at x (x is rainy).
As we know from the translation of sentential logic, “only” introduces the neces-
sary condition and is, in translation, placed after the conditional or implicative sym-
bol. We can also show logically equivalent formulas and we can translate back into 
English. The golden rule is to opt for the translation that is closer to the structural 
arrangements of logical particles in the sentences we are translating (which is the 
first formula in the left.)
∀x∀y((Fx. Ty. Vxy) ⊃ Ry) ≡ ∀x∀y(Fx ⊃ (Ty ⊃ (Vxy ⊃ Ry))) ≡
~ ∃x ~ ∃y(Fx. Ty. Vxy. ~ Ry) ≡ …
•	 We do not have symbolic resources in ∏πφ= for the formalization of adverbial 
modifiers. We need to interpret predicate letters in such a way that the adverbial, 
or any other type of modifier, is compacted into the logical predicate. For 
instance, “John walks fast” has to be translated by means of a key that contains a 
predicate letter, for instance, “W” such that “Wx” is interpreted as “x walks fast.” 
Notice that we should do not symbolize separately “x walks” and “x is fast” and 
then use conjunction to join two sentences. Whether John is generally fast or not 
is a different matter: it is just that he walks fast that we need to render by means 
of a translation. In other words, “John walks fast” cannot be translated faith-
fully as:
Wj. Fj
[for the key: Wx: x walks; Fx: x is fast.]
This translation does not have the same truth conditions with the proposition of 
the given sentence because it is possible that John has the characteristics attaching 
to a person who is fast only when he walks; so, the conjunctive statement could be 
false when we aim at translating a proposition that is true.
•	 We have no symbols and no grammatical arrangements for predicate symbols of 
higher order. As an example, “bright” can be predicated of “color:” noting that “x 
is a color” shows us that “being-a-color” is a first-order predicate, we discern that 
“being-bright” is a predicate that can be predicated of a first-order predicate: this 
means that “being-bright” is a second-order predicate. This can continue to 
higher orders but we soon lose intuitive traction. Moreover, in higher-order log-
ics, we have quantifier symbols that allow expression of quantification over 
higher-order predicates; for instance: in “some colors are bright” the existential 
quantifier ranges over the first-order predicate color. And we have names for 
6.1  # Tips for Translation (Symbolization, Formalization)

336
predicates too, as well as having relational higher-order predicates like “x is 
brighter than y”. Higher-order logics are recalcitrant with respect to certain met-
alogical results and this generates prejudice among certain logicians toward 
them, but this topic lies beyond our scope here.
•	 Lacking the symbolic resources of higher-order logics means that we cannot 
translate directly propositions like the one expressed by the sentence “some col-
ors are brighter than other colors” with “brighter” being a property of properties 
and, as such, requiring second-order predicate letters – and quantifiers over our 
first-order predicate letters. Using the resources of first-order logic, which we 
have at our disposal, we will have to make do but we ought to bear in mind that 
argument forms that are valid when translated into higher order predicate sys-
tems may be invalid in their first-order predicate translations. We experienced 
this limitation with respect to translation into the resources of sentential logic as 
distinguished from translation into predicate logic.
To continue with our example, we wonder how we may translate the proposition 
of the sentence:
(S) Some colors are brighter than other colors.
Key: Cx: x is a color; Bxy: x is brighter than y.
∃x(Cx. ∃y(Cy. Bxy))
Because it expresses an empirical claim, the proposition should be logically 
indeterminate – neither a tautology nor a contradiction. This is the case with the 
formula we use to translate the proposition. We cannot, however, validly infer from 
this proposition that there is a property such that some things have it so that they are 
brighter than other things which also have this property. The reason we cannot 
extract this intuitively valid inference is due to the limitations of our symbolic 
resources: we lack higher-order predicate symbols and related grammatical accom-
modations, as we have explained.
•	 Clearly, we also lack resources for translating modals like “necessarily” and 
“possibly” and also modal expressions like “it is obligatory that___”; and, as we 
have already indicated, we lack tense operator symbols for expressions like “it 
will be the case that___” and “it has always been the case that___.” Once again, 
an argument that is valid – and we would expect to be valid – may check as 
invalid when translated into our symbolic resources whereas translation into a 
modal symbolic language would show that the argument is valid indeed. We 
wonder if we can compact modal claims by means of our first-order predicate 
logic resources.
•	 (SModal) It is necessarily true that triangles have three angles.
The non-truth-functional modifier “necessarily” cannot be translated. There is a 
good question here as to whether we should translate with the full panoply of sym-
bolic means made available in predicate logic – so that we have for an evident 
choice of interpretative key:
6  Translations from English into ∏πφ= (also called Symbolizations…

337
(Tr1) ∀x(Tx ⊃ Ax)
This seems advisable. We should bear in mind, however, that ambiguities that 
may surround the issue of the scope of the modal cannot be disambiguated by using 
the resources of predicate logic. In this case, it appears from context that “necessar-
ily” has in its scope the entire statement “all triangles have three angles.” This is an 
analytic statement that is true by virtue of the meanings of its non-logical words. It 
is not a formal logical truth; it is not necessarily true by virtue of its logical form. 
Modal logic would not show otherwise. If the statement is – which in this case does 
not appear to be – “all triangles are necessarily three-angled”, then we wonder if and 
how we can render this in predicate logic symbolic resources. We should not 
attempt. Accordingly, interplays and logical relations involving the shifts of modal 
operators cannot be formalized and cannot be investigated in predicate logic.
6.1.1  Multiply Quantified Statements
We have a bounty of symbolic resources in ∏πφ=, which allows us to formalize 
(translate, symbolize) internal parts of sentences. We still lack symbols for non-­
truth-­functional expressions of the language and we do not have symbols for attri-
butes that characterize attributes: We do not have symbols for logical predicates 
corresponding to attributes like “bright” which is a characteristic of colors; while, 
on the other hand, “color” is itself the kind of attribute – expressible as a first-order 
logical predicate – for which we do have symbols in ∏πφ=. As we do not venture into 
the arduous task of studying modal logics or higher-order logics, we must make do 
with the resources of our predicate logic which is also called first-order logic – 
which distinguishes it from higher-order logics, as it ought to be plain by now. The 
grammatical conventions for have been settled and the next step is to examine how 
we may translate. Since we have expanded the monadic logic language, with which 
we started, into a language for polyadic (also called relational) logic, and we have 
further added function symbols and the identity symbol, which take us to ∏πφ=, we 
are ready to embark on the task of arranging deployment of all these convenient 
symbolic resources for the task of translation. We always want to show the logical 
structure of the meaning or statement expressed by the sentence, which we are 
translating. Insofar as our translation preserves logically relevant characteristics 
(like validity of arguments, the logical status of a sentential meaning as to whether 
it is a tautology or a contradiction or a logically contingent statement, or consistency 
of a theory comprised of sentences) – then our task is accomplished. Of course, the 
lack of resources for symbolizing higher-order predicates and non-truth-functional 
expressions takes a toll in that we could well end up losing logical characteristics 
whose preservation would require use of those other symbolic resources.
In translating, we need to specify the domain (also called universe of discourse) 
over which our quantifiers (universal and existential) range. If the domain, for 
instance, is comprised both of human persons and of books, the translation of the 
6.1  # Tips for Translation (Symbolization, Formalization)

338
sentence “Someone gave someone else a book” compels us to deploy predicate 
symbols for “person” and for “book.” If, on the other hand, we have a restricted 
domain, as we call it, so that only the students of a certain specified class are mem-
bers of the domain, then “everyone like someone,” speaking of this domain with 
students, does not require defining a predicate symbol for “student.” There are other 
possible technical adjustments  – like having different collections of quantifiers, 
with one quantifier type ranging only over students, for instance, while another 
quantifier type ranges only over books – but we do no pursue such alternatives here.
Beginning with monadic predicates, we show examples and we comment as 
needed. We use always basic set-theoretic symbols (but see the concluding chapter 
on elements of set theory.) The domain is a set: a collection of any objects (not nec-
essarily related in any systematic way), which is completely characterized by the 
members it has; whose members are discrete and identifiable items and so that it is 
always in principle possible to determine if any given item is or is not a member of 
our set. We can define a set, with members enclosed within the characteristic set 
brackets, by enumerating all the members but we can also express a condition that 
anything must fulfill to be a member of the set (if this happens to be the case for a 
specific set.) We can even go over the members of the set recursively and indicate 
that each object is a member of the set. We cannot place the objects inside the set 
brackets, of course, and so we rely on symbols again for representing the members. 
We need names for every member of the set that is the domain and we use, based on 
our grammatical accommodations, individual constants, which we specify, to name 
each member of the domain set. It may be possible to make statements about mem-
bers of a domain, which are not named. For instance, our domain could be the set of 
even numbers: this set has a cardinality (number of members) which is infinite but 
countable as we say: each one of its members can be put into a one-to-one corre-
spondence with a member of the set of natural numbers which is used to do the 
counting. Even without naming each member of our domain of even numbers, we 
can translate quantified statements such as “every even number has a successor” or 
“no even number is an odd number.” But to translate statements about specific num-
bers, we need names for the individuals.
It is assumed that we have the ability to translate into the standard sentential 
logic, based on the study of preceding chapter (4.8). The relevant information and 
strategies, and constraints, that apply for translations of the logic-words of the lan-
guage into connective symbols of our formal language, as they were presented for 
sentential logic, are carried over and still apply for our predicate logic language.
In our translation examples, the meanings we translate do not have to constitute 
a consistent narrative about the domain. We are only engaged in translating.
•	 D = {x / x is a person in the fictive state of Lilliputia}
Key:
Bx: x is benevolent.
Ex: x is evil.
Sx: x is student.
Tx: x is teacher.
6  Translations from English into ∏πφ= (also called Symbolizations…

339
Wx: x is wise.
Vx: x is a visitor to Lilliputia.
	 1.	 Every resident of Lilliputia is either benevolent or evil and cannot be both. ↝ 
∀x(Rx ⊃ ((Bx ∨ Ex) ∙ ~ (Bx ∙ Ex)))
	 2.	 All teachers in Lilliputia are neither benevolent nor evil but they are wise.
↝ ∀x(Tx ⊃ (~ Bx ∙ ~ Ex ∙ Wx))
	 3.	 Some students are wise only if they are evil. (We can agree to omit “in Lilliputia” 
since the context has been set in this respect. We may also take it, in continuing 
from the remark in the preceding example, that, unless otherwise stated in 
explicit way, the statements are about the residents of Lilliputia; this allows us 
to dispense with the disambiguation we did in the preceding example.)
↝ ∃x(Sx ⊃ Ex)
	 4.	 If no one is both student and teacher, then no one is benevolent unless they 
are wise.
↝ ~ ∃x(Sx ∙ Tx) ⊃ ~ ∃x(Bx ∙ ~ Wx)
	 5.	 All students are teachers if and only if no teachers are evil.
↝ ∀x(Sx ⊃ Tx) ≡ ~ ∃x(Tx ∙ Ex)
	 6.	 Since no teacher is evil, then either all students are not wise or some teachers 
are both wise and benevolent. (Here, we need to make a judgment as to whether 
the disjunction is inclusive or exclusive. The English expression “either-or” is 
inherently ambiguous as to between the two senses. The meaning here is rather 
garbled, to test our translational skills, but it appears that a minimal condition 
for drawing a distinction is established by the disjunction and, if this is the case, 
we may take it to be inclusive disjunction.)
↝ ~ ∃x(Tx ∙ Ex) ⊃ (∀x(Sx ⊃ ~ Wx) ∨ ∃x(Tx ∙ Wx ∙ Bx))
	 7.	 Some visitors are evil but only benevolent visitors can be teachers in Lilliputia.
↝ ∃x(Vx ∙ Ex) ∙ ∀x((Vx ∙ Tx) ⊃ Bx)
	 8.	 No one can be both a visitor and a student if they are evil and vice versa.
↝ ∀x(Ex ⊃ ~ (Vx ∙ Sx)) ∙ ∀x((Vx ∙ Sx) ⊃ ~ Ex)
	 9.	 Every person in Lilliputia is either green or red and cannot be both.
	10.	 Those who love only things do not love people.
	11.	 In Lilliputia, every red person get whatever they like
We are ready next to move to the task of translating relational statements and 
also statements whose precise translation, within the limits of our symbolic 
resources, require also use of symbols for functions and for identity. We consider 
the symbol ⌜≠⌝ as part of our symbolic language, inter-substitutable with ⌜~ (x = 
y)⌝. We also omit parentheses around the equation and inequation symbolic 
expressions trusting that no ambiguity can result from this as to scopes. It is nota-
ble that predicate symbols can be used to effectuate translations that can be car-
ried out with function symbols (provided that there exists a unique y that is 
R-related to x), and the other way round. The predicate symbol has to be of arity 
n + 1 if the function symbol that can be used for the translation (rendering the 
same meaning) is of arity n. We add the symbol “∃!” for uniquely quantifying 
6.1  # Tips for Translation (Symbolization, Formalization)

340
existential quantifier (and we will learn in subsequent section how to develop this 
symbol.) For instance,
∃!xF2xy 	
	
↝ x is the father of y
corresponds to:
f1x = y	
↝ y is the father of x
•	 Tram is the father of Sam (with “t” and “s” as the individual constants or names 
for Tram and Sam respectively):
↝	
∃!x(Fxs ∙ x = t) 	 or 	
↝ fs = t
•	 D = {x / persons and objects in the fictitious city of Lilliputia}
Key:
Gx: x is a green person of Lilliputia.
Rx: x is a red person of Lilliputia.
Tx: x is a thing.
Lxy: x likes y.
Gxyz: x gives to y z.
fx: the father of x.
mx: the mother of x.
Fxy: x is the father of y.
Mxy: x is the mother of y.
Lxy: x loves y.
Kxy: x likes y.
u: Urutaga.
w: Watataga.
	 1.	 Every person likes at least some thing. ↝ ∀x∃y((Px ∙ Ty) ⊃ Lxy)
Consider that we can have, equivalently, the following. Standard sentential 
logic shows these as logically equivalent expressions (as we may attest by refer-
ring to the rule we called Exportation-Importation in a natural deduction system 
we constructed).
↝ ∀x∃y(Px ⊃ (Ty ⊃ Lxy)).
Consider also the following. Indeed, there are rules we can specify, as we will 
see, as to how to move quantifiers in and out of scopes of connective symbols. 
This move is legitimate – the expressions are logically equivalent.
∀x∃y(Px ⊃ ∃y(Ty ∙ Lxy)).
We will be showing such alternative renderings below but there is always an 
imperative to opt for the translation that shows more closely the structure of the 
logical meaning of the English sentence we are translating.
	 2.	 Every person likes some other person but there is no person who is liked by 
everyone other than himself or herself. ↝
∀x(Px ⊃ ∃y(Py ∙ y ≠ x ∙ Lxy)) ∙ ~ ∃x(Px ∙ ∀y(Py ⊃ (y ≠ x ⊃ Lyx)))
	 3.	 A person gives another person a thing, only if he or she likes that other person. 
↝ ∀x∀y((Px ∙ Py ∙ x ≠ y ∙ ∃z(Ty ∙ Gxyz)) ⊃ Lxy)
6  Translations from English into ∏πφ= (also called Symbolizations…

341
	 4.	 No green person likes himself or herself if there is not some red person whom 
he or she also likes. ↝
~ ∃x((Px ∙ Gx ∙ Lxx) ∙ ~ ∃y(Py ∙ Ry ∙ Lxy)).
∀x((Px ∙ Gx ∙ Lxx) ⊃ ∃y(Py ∙ Ry ∙ Lxy)).
∀x(~ ∃y(Py ∙ Ry ∙ Lxy) ⊃ ((Px ∙ Gx) ⊃ ~ Lxx))
	 5.	 If there is at least one red person who likes all green persons, then there is at 
least one green person who likes all red persons. ↝
∃x(Px ∙ Rx ∙ ∀y((Py ∙ Gy) ⊃ Lxy)) ⊃ ∃x(Px ∙ Gx ∙ ∀y((Py ∙ Ry) ⊃ Lxy)).
The sentence “If there is a red person who likes all green persons, then there is 
a least one green person who likes all red persons” would be conveying mean-
ing in ambiguous fashion: it is not clear if “some” or “at least one” is meant, or, 
if, instead, “exactly one” or “one specific person” is meant. And we also have 
all the combinations for taking “a” to be “at least one” for one part of the sen-
tence and “exactly a specific one” for the other part of the sentence. We would 
then disambiguate: this means that we present all the possible translations but it 
is linguistic context, possibly not accessible to us, that would have to be used in 
picking which one of the possible translations should be applied. In the next 
section we learn how to translate expressions involving a uniquely specified 
entity – and, indeed, also numerical expressions like “at most two” or “exactly 
four” and so on.
	 6.	 No one likes those who don’t like themselves. ↝
~ ∃x(Px ∙ ∃y(Py ∙ ~ Lyy ∙ Lxy)).
Notice that it is not specified if this applies also in the case of the same person 
or in the first person: meaning that no one likes himself or herself, either, insofar 
as they don’t like themselves; this sounds trivially true and, if it were to be 
excluded, “unless it is about themselves”, we would be expressing a contradic-
tion: “no one likes those who don’t like themselves, unless it is about them-
selves” which in that case would mean that they both like and do not like 
themselves. Translatability is another matter, however; the meaning would be 
still translatable. As translated above, the meaning that is rendered does not 
exclude the first-person case. Otherwise, we ought to render as follows:
~ ∃x(Px ∙ ∃y(Py ∙ y ≠ x ∙ ~ Lyy ∙ Lxy))
	 7.	 Green persons do not like their mothers while red persons do not like their 
fathers. ↝
∀x((Px ∙ Gx) ⊃ ~ Lxmx) ∙ ∀x((Px ∙ Rx) ⊃ ~ Lfx)
	 8.	 No one gives the same thing to their father and mother. ↝
∀x∀y∀z((Px ∙ Ty ∙ Gxyfx) ⊃ ((Tz ∙ Gxzmx) ⊃ z ≠ y)
	 9.	 Red persons do not like red things if and only if green persons give only red 
things to green persons. ↝
∀x(((Px ∙ Rx) ⊃ ~ ∃y(Ty ∙ Ry ∙ Lxy)) ≡ ∀x∀y∀z((Px ∙ Gx ∙ Py ∙ Gy ∙ Tz) ⊃ 
(Gxyz ⊃ Rz))
	10.	 Urutaga likes no one but Watataga but Watataga likes no one but Watataga. ↝ 
∀x(Lux ≡ x = w) ∙ ∀x(Lwx ≡ x =w)
	11.	 Those who love only things do not love people.
↝ ∀x((Px ∙ ∀y(Lxy ⊃ Ty)) ⊃ ~ ∃z(Pz ∙ Lxz)).
6.1  # Tips for Translation (Symbolization, Formalization)

342
↝ ∀x((Px ⊃ (∀y(Lxy ⊃ Ty) ⊃ ~ ∃z(Pz ∙ Lxz))
	12.	 Watataga is loved by all, and only by, green people even though Watataga is a 
red person.
↝ ∀x((Px ∙ Lxw) ≡ (Px ∙ Gx) ∙ Rw.
↝ ∀x(((Px ∙ Gx) ⊃ Lxw) ∙ (Lxw ⊃ (Px ∙ Gx))) ∙ Rw
	13.	 If any red person likes any green person, then some green people who like 
themselves like Urutaga.
↝ ∃x((Px ∙ Rx) ∙ ∃y(Py ∙ Gy ∙ Lxy)) ⊃ ∃x(Px ∙ Gx ∙ Lxx ∙ Lxu)
	14.	 Watataga likes Urutaga but Urutaga likes no one but himself.
↝ Kwu ∙ ∀x(Kux ≡ x = u)
	15.	 Urutaga gives things to those he loves insofar as they are not red people.
↝ ∀x((Px ∙ ~ Rx) ⊃ ∃y(Ty ∙ Guyx)).
↝ ∀x(Px ⊃ (~ Rx ⊃ ∃y(Ty ∙ Guyx))
	16.	 Every red person except Watataga is liked by red people.
	17.	 No one is one his or her own mother in Lilliputia.
↝ ~ ∃x(Px ∙ (Mxx ∨ Fxx)).
↝ ~ ∃x(Px ∙ (mx = x ∨ fx = x)).
↝ ∀x(Px ⊃ (~ Mxx ∙ ~ Fxx)).
↝ ∀x(Px ⊃ (mx ≠ x ∙ fx ≠ x)).
↝ ∀x∀y((Px ∙ (y = mx ∨ y = fx)) ⊃ (y ≠ x)).
6.1.2  Quantifier Extractions and Relettering
We can lay down systematic rules for how to move quantifier symbols in and out of 
parentheses and nested scopes of other quantifier symbols as well as how to reletter 
quantifier variables while we do so, all the while generating logically equivalent 
formulas. It is provable that these shifts result in generation of symbolic formulas 
that are logically equivalent with ones that are so transformed. There are decision 
procedures that require implementation of such shifts, although we do not study 
such methods in the present text. With respect to translating, and having as available 
alternative translations other formulas that are logically equivalent with one another, 
we can seize the opportunity to show how quantifier symbols can be moved – and 
also, specifically, how they can be extracted from and inserted within parentheses 
and how relettering can be also be carried out at the same time. Let us continue with 
translating English sentences that constitute discourse about the model we used for 
our preceding examples; we do this to motivate the present subject of showing rules 
of quantifier symbol extraction-insertion and relettering. The most rigid type of 
relettering assigns different variables to each quantifier symbol, respecting the vari-
ables that are bound accordingly. At this point, however, any pretenses of a transla-
tion to appealing to our intuitions (assuming some basic training in translations, of 
6  Translations from English into ∏πφ= (also called Symbolizations…

343
course) seems to dissipate. The relettering is useful for certain decision procedures, 
which, as already indicated, we do not pursue in this text.
	18.	 Red people love their parents only if green people do not.
↝ ∀x∀y((Px ∙ Rx ∙ Py ∙ Fyx) ⊃ Lxy) ⊃ ∀x∀y((Px ∙ Gx ∙ Py ∙ Fyx) ⊃ ~ Lxy).
↝ ∃x∃y∀z∀w(((Px ∙ Rx ∙ Py ∙ Fyx) ⊃ Lxy) ⊃ ((Pz ∙ Gz ∙ Pw ∙ Fwz) ⊃ ~ Lzw))
	19.	 If anyone likes his father, Watanaga does.
↝ ∃x(Px ∙ Kxfx) ⊃ Kwfx.
↝ ∀x((Px ∙ Kxfx) ⊃ Kwfx)
•	 ∀x(φ ∙ ψ) ≡ (∀xφ ∙ ∀xψ) [x is free in φ and in ψ before bound by the quantifiers]
•	 ∃x(φ ∨ ψ) ≡ (∃xφ ∨ ∃xψ) [x is free in φ and in ψ before bound by the quantifiers]
•	 ∀x(φ ∨ ψ) ≡ (∀xφ ∨ ψ) [x is free in φ but not in ψ before bound by the quantifiers]
•	 ∀x(φ ∨ ψ) ≡ (φ ∨ ∀xψ) [x is free in ψ but not in φ before bound by the quantifiers]
•	 ∃x(φ ∙ ψ) ≡ (∃xφ ∙ ψ) [x is free in φ but not in ψ before bound by the quantifiers]
•	 ∃x(φ ∙ ψ) ≡ (φ ∙ ∃xψ) [x is free in ψ but not in φ before bound by the quantifiers]
•	 (∃xφ ⊃ ψ) ≡ ∀x(φ ⊃ ψ) [x is free in φ before bound by the quantifiers]
•	 (∀xφ ⊃ ψ) ≡ ∃x(φ ⊃ ψ) [x is free in φ before bound by the quantifiers]
•	 (φ ⊃ ∀xψ) ≡ ∀x(φ ⊃ ψ) [x is free in ψ before bound by the quantifiers]
•	 (φ ⊃ ∃xψ) ≡ ∃x(φ ⊃ ψ) [x is free in ψ before bound by the quantifiers]
6.1.3  Translations of Numerical Statements 
and Definite Descriptions
The symbolic resources and grammatical arrangements we have at our disposal 
allow us to symbolize numerical statements, as we will now see. We also keep in 
mind that there are certain quantificational statements that we cannot express – for 
the same reasons, having to do with what our formal apparatus and resources allow 
us to do. Let us start with what we cannot express before we move on to the sym-
bolizations (formalizations) of numerical statements.
We cannot express:
	1.	 There are just a few students in this class. A quantifier can be constructed with 
appropriately stipulated semantic conditions, so that we can formalize such a 
statement, but we do not have the resources in our system to do this. If we think 
in set-theoretical terms (with elements of set theory presented in the last chap-
ter), we may think of the cardinality or cardinal number of the domain of a model 
(the number of members of the domain of the model.) We could then stipulate 
definitionally that “a few x are F” means that the extension of the predicate F, 
which is the predicate-set or set with the members of the domain that are F, has 
cardinality that is less than half of the cardinality of the domain (or some other 
number as related to the cardinality of the domain.) Similar semantic devices can 
be engineered to deal with other, subsequently mentioned, statements that we 
6.1  # Tips for Translation (Symbolization, Formalization)

344
cannot translate. Our formal system does not allow for construction of such 
quantifiers.
	2.	 There are many students in this class. There may well be some ambiguity in the 
expressions that ordinarily use “many”, depending on context to remove ambi-
guity as to whether this is meant to assert that a significant number of students 
exist or to deny a contextually based claim that very few students exist. In either 
case, the symbolic expressivity that we need to have at our disposal requires that 
we have defined non-standard quantifier symbols. This can be done – by using 
set-theoretic concepts in our semantics – but such devices are not available to a 
formal idiom like ours, within the standard first-order logic of quantifiers.
	3.	 Half of the residents of Patatonia are brave. If we have access to a metalinguistic 
set-theoretic apparatus, we can specify that the semantics of such an expression 
requires for truth that the extension of the brave-predicate has as cardinality 
(number of members) exactly one half of the number that is the cardinality of the 
semantic model’s domain. Such a maneuver would define a quantifier – indeed, 
generalized to any predicate symbol, the definition would be setting the seman-
tics for the quantifier symbol for one-half. Nevertheless, the standard predicate 
logic does not have access to such resources.
	4.	 More than enough students volunteered to make the trip financially feasible. We 
would have to implement semantic definitions for the appropriate quantifier 
symbol. Since formal languages do not permit or tolerate ambiguity or – in the 
case of the standard logic – vagueness, the inherently vague (and contextually 
ambiguous) “more than enough” would have to be fixed by specifying what 
counts as “more than enough.” For instance, one possible way for defining such 
a quantifier could be: the sentence “more than enough F are G is true if and only 
if the intersection or overlapping of the sets that are the semantic values or exten-
sions of F and G in a model has cardinality (number of members) that exceeds n, 
where n is a constant number.” The number n can be expressed as a ratio of some 
number m over the number that is the cardinality of the domain of the model. 
Obviously, considerations are entering in all this, which appear extra-logical but 
the formalism, once settled, is to be deployed systematically and so that the 
results we reach by applying it are not liable to instability. We can say that what-
ever pragmatic or contextually specified considerations enter into the fixing of 
the values of the numbers we referred to above, are mere motivations for the 
formal system but the system itself, once constructed, stands on its own. The 
standard predicate logic does not permit construction of such unorthodox quanti-
fier symbols.
	5.	 There are some students – so that it is implied that there are also some people 
who are not students. We cannot have as valid inference, in our system, from 
“there are some students” to “there are also some who are not students.” The 
meaning of “some” is, as we know by now, “there is at least one” and it is pos-
sible that both “there are some students” and “everyone is a student” which then 
excludes the possibility that “there are no students.” Of course, we could define, 
alternatively and in some non-standard logic, a quantifier symbol for “some” 
(not the same meaning as our quantifier symbol for “some”), so that the infer-
6  Translations from English into ∏πφ= (also called Symbolizations…

345
ence from “there are some students” to “there are some who are not students” 
would go through, in the specified semantics of that system, as valid.
	6.	 If being brave is virtuous and Sama is brave, then there is at least one virtue that 
someone has. This would require the resources of second-order logic, which 
permits quantification over predicates. We may paraphrase to translate into our 
formal language but the resulting formula would not be a logical truth even 
though statement seems to be logically (necessarily, trivially) true. This should 
not be surprising. Ascending from the standard sentential logic to the extension 
that is the standard predicate logic, as we have done in this text, we similarly 
faced the prospect of argument forms that ought to check as valid but whose 
symbolic expressions in sentential logic are not valid – although, when rendered 
with the symbolic resources made available in predicate logic, they do indeed 
come out as valid. Second-order logic has been studied extensively and would be 
covered in a more advanced text. There are certain metalogical results about 
second order logic, which are problematic, but this lies beyond our current scope.
Translations of Numerical Statements.
In addition to our cache of symbolic resources, which we make liberally avail-
able to metalinguistic uses, we will need some novel metalinguistic symbolic nota-
tion to present generalizations of translations of numerical statements to the case of 
n objects. We introduce this convenient notation here before we proceed.
•	
i
n

1
 i =(φ1 ∙ … ∙ φn)
•	
i j
j
n
x
,
(



1
i
i ≠ xj)) = (x1 ≠ x2 ∙ x1 ≠ x3 ∙ … ∙ xn-1 ≠ xn)
•	
i
n

1
 i = φ1 ∨ … ∨ φn
•	
i j
i j
n
,
(



1
 i * λj) = (λ1 * λ2) ∙ (λ1 * λ3) ∙ … ∙ (λ2 * λ3) ∙ … ∙ (λn-1 * λn) / [* ∊ {=, ≠}]
•	
i j
i j
n
,
(



1
 i * λj) = (λ1 * λ2) ∨ (λ1 * λ3) ∨ … ∨ (λ2 * λ3) ∨ … ∨ (λn-1 * λn) / [* ∊ {=, ≠}]
Numerical Translations:
•	 There is at least one F: ∃xFx
•	 There are at least two Fs: ∃x∃y(Fx ∙ Fy ∙ x ≠ y) ≡ ∃x1∃x2(Fx1 ∙ Fx2 ∙ x1 ≠ x2) ≡ 
∃x1∃x2(
i
Fx

1
2
i ∙ 
i j
j
x
,
(



1
2
i
i ≠ xj))
•	 There are at least n Fs: ∃x1…∃xn(
i
n
F

1
i ∙ 
i j
j
n
x
,
(



1
i
i ≠ xj)))
6.1  # Tips for Translation (Symbolization, Formalization)

346
•	 There is at most one F: ∀x∀y((Fx ∙ Fy) ⊃ y = x) ≡ ∀x1∀x2((Fx1 ∙ Fx2) ⊃ x2 = x1) 
≡ ∀x1∀x2(
i
Fx

 

1
2 1 1
i ⊃ 
i
j
x
,
(


 

1
2 1 1
j i
j = xi))	
[of course: 
i
j
x
,
(


 

1
2 1 1
j i
j = xi) = (x2 = x1)]
•	 There are at most two Fs: ∀x∀y∀z((Fx ∙ Fy ∙ Fz) ⊃ (z = y ∨ z = x)) ≡ ∀x1∀x2∀x3((Fx1 
∙ Fx2 ∙ Fx3) ⊃ (x3 = x1 ∨ x3 = x2)) ≡ ∀x1∀x2∀x3(
i
F

1
3
xi ⊃ 
i j
x
,
(


 

1
3 2 1
j i
j = xi))
•	 There are at most n Fs: ∀x1…∀xn(
i
n
F

1
xi ⊃ 
i j
n
x
,
(




1
1
j i
j = xi))
•	 There is exactly one F: there is at least one F and at most one F:
•	 ∃x∀y((Fy ≡ y = x) ∙ Fx) ≡ ∃x1∀x2((Fx2 ≡ x2 = x1) ∙ Fx1)
•	 There are exactly two Fs: ∃x∃y∀z((Fz ≡ (z = x ∨ z = y)) ∙ Fx ∙ Fy) ≡ ∃x1∃x2∀x3((Fx3 
≡ (x3 = x1 ∨ x3 = x2)) ∙ Fx1 ∙ Fx2) ≡ ∃x1∃x2∀x3((Fx3 ≡ 
i j
x
,
(

 
 

1
3
3 2 1
j
i
j = xi)) ∙ 
i
F

1
2
xi)
•	 There are exactly n Fs: ∃x1∃x2…∀xn+1((Fxn+1 ≡ 
i j
n
x
,
(

 


1
1
j n i
j = xi)) ∙ 
i
n
F

1
xi)
We will be treating definite descriptions separately in chapter 9 on account of the 
historic significance and logical-philosophic issues surrounding this topic. We will 
be querying the issue of non-denoting definite descriptions more specifically in the 
context of that presentation. We are able, however, as it is, to symbolize meanings 
of sentences in which assertions are made predicating attributes of some unique 
referent. We can see how to symbolize such sentences with our symbolic resources.
•	 Let us metalinguistically allow for symbolizing “the F”, meaning “the unique 
thing such that this thing has the attribute F”, as “δF”. We also allow ourselves 
the indulgence of another metalinguistic enhancement: we use an exclamation 
mark accompanying the existential quantifier to indicate “there is exactly one 
unique F”, thus symbolizing by “∃!xFx”.
•	 There is a unique F; the F, δF: ∃!xFx ≡ ∃x∀y((Fy ≡ y = x) ∙ Fx)
•	 [another way of symbolizing “there is a unique F.”]: ∃!xFx ≡ ∃x(Fx ∙ ∀y(Fy 
⊃ y = x))
•	 δF is G: ∃!x(Fx ∙ Gx) ≡ ∃x∀y((Fy ≡ y = x) ∙ Fx ∙ Gx)
•	 Some x is R-related to δF:
•	 δF is R-related to some y:
•	 δF is R-related to δG:
•	 δ-best-F is a G:
•	 δ-best-F is the entity denoted by t:
•	 δ-best-F is the f (function symbol) of the entity denoted by t:
6  Translations from English into ∏πφ= (also called Symbolizations…

347
6.1.4  Exercises
	1.	 Determine if the following statements are: universally quantified, existentially 
quantified, inclusive disjunctions, conjunctions, implications, equivalences, or 
none of the above (being simple statements due to the controlling presence of 
non-truth-functional expressions.)
	
a.	 Cats are mammals.
	
b.	 No cat is an insect.
	
c.	 The students are hard-working but the teachers are not satisfied.
	
d.	 No one can know the secret and live.
	
e.	 If anyone likes Jack, it is not Mary.
	
f.	 Those who like someone else like themselves.
	
g.	 It is not permitted for anyone to leave this room.
	
h.	 It is logically necessary that either everyone is brave or no one is.
	
i.	 To be the teacher of Aristotle is to be Plato.
	
j.	 There exists a ghost in the castle.
	
k.	 The king of France is bald.
	2.	 Categorize the following as terms (names or functions), predicates (indicating 
also the arity or degree of the predicate), open sentences, sentential formulas, 
none of the above.
	
a.	 the father of Electra
	
b.	 the mother of the father of Electra
	
c.	 Electra
	
d.	 next to Electra
	
e.	 between Electra and her father
	
f.	 the man next to Electra
	
g.	 x is the father of Electra
	
h.	 Someone is Electra’s father.
	
i.	 no x is F
	
j.	 no x
	
k.	 better than
	
l.	 The sum of two even numbers is an even number.
	
m.	 Everyone likes y
	
n.	 Everyone likes someone other than themselves.
	
o.	 someone else
	
p.	 Either everyone wins or no one wins.
	
q.	 identical with
	
r.	 x likes mathematics
	
s.	 Electra likes mathematics more than she likes literature.
	3.	 Why are the following statements ambiguous? What are the possible disambigu-
ations (expressions, each of which is not ambiguous and is a plausible rendering 
of the given statement)?
6.1  # Tips for Translation (Symbolization, Formalization)

348
	
a.	 Everyone likes someone.
	
b.	 Anyone likes someone.
	
c.	 You can fool some people some of the times.
	
d.	 The trooper is brave.
	
e.	 (From Aristotle): Someone is not writing while writing. [This sophistical 
expression, memorialized by Aristotle, is ambiguous. Someone who is capa-
ble of writing is not writing now; hence, the sophist argues, it is possible for 
someone not to be writing even though he writes. How did we end up with 
nonsense? Disambiguation is needed: two different formulas are to be used to 
render the translations of two different meanings which are indeed different 
because quantifier symbols have different scopes. We do not have symbols 
for “possibly.” Recall our earlier discussions of non-truth-functional expres-
sions. Attempt disambiguating by using symbols for predicates “person” and 
“time moment”. The ambiguity stems from the fact that there are different 
ways in which the quantifier symbols are given scopes. In one case, you 
should have a logical contradiction, but no so in the other disambiguation. 
Intuitively: it is nonsensical to claim, “someone is writing and not writing at 
the same time” but it is not nonsensical to claim that “someone is not writing 
now but is writing at some other instance of time.”)
	4.	 Translate the statements expressed by the following English sentences into well-­
formed formulas of our symbolic language ∏πφ=.
Key: Px: x is a person; Cx: x is a country; Rx: x is a royal, x is royalty; Kxy: 
x is king of y; Qxy: x is the queen of y; Sxy: x sees y; qx: the queen of x; kx: the 
king of x; a: Alice; u: Utopia.
Attempt translations both by using the function symbol for “king of Utopia” 
and the predicate symbol “Kxy”: what additional symbolic subformulas are 
needed, taking into consideration that there is uniquely (exactly) one such king?
	
a.	 Either you are royalty or you are not. (“You” connotes, colloquially, to any-
one, everyone.)
	
b.	 Either everyone is royalty or everyone is not royalty.
	
c.	 Everyone is royalty if anyone is.
	
d.	 Anyone is royalty if everyone is.
	
e.	 If anyone is royalty, then the king of Utopia is.
	
f.	 If everyone is royalty, then the king of Utopia is.
	
g.	 The king of Utopia sees nobody.
	
h.	 If Alice sees nobody, then the king of Utopia does not see anybody.
	
i.	 If anyone sees Alice, then the queen of Utopia sees Alice.
	
j.	 There are countries whose king is not the king of Utopia.
	
k.	 There is some specific country that is not Utopia and whose king is not the 
king of Utopia.
	
l.	 There is one and only king in any country.
	
m.	 Any country that has a queen has no king and vice versa.
	
n.	 Although Alice sees the king, the king does not see Alice.
6  Translations from English into ∏πφ= (also called Symbolizations…

349
	
o.	 If there is any country that has both a king and a queen, then Utopia is not 
that country.
	
p.	 Alice sees the queen of Utopia but the queen of Utopia sees only the king 
of Utopia.
	
q.	 There is at most one queen of utopia.
	
r.	 There are exactly two people whom Alice sees.
	
s.	 There are at least three countries that have no king or queen.
	
t.	 Royals admire only themselves.
	
u.	 Royals admire none but themselves.
	
v.	 No royal is the king or the queen of every country.
	
w.	 Everyone except for the king of Utopia can see anyone.
	
x.	 Anyone but the king of Utopia can see everyone.
	
y.	 Only the king of Utopia does not see anyone but Alice.
	
z.	 The king of Utopia is the only royal of any country, who sees Alice.
	5.	 Translate into English the following well-formed formulas of ∏πφ=. Of course, it 
is not presumed that the statements made by the symbolic expressions are 
always true.
Key: j: Jocasta; o: Oedipus; a: Antigone; fx: the father of x; mx: the mother of 
x; Mxy: x is mother of y; Fxy: x is father of y.
	
a.	 ∀x∀y∀z(Fyx ⊃ ~ Myx)
	
b.	 ∃x∀y(x ≠ y ∙ Myx)
	
c.	 ∀x∃yFyx
	
d.	 ∃x∃y(fx = y ∨ fy = x)
	
e.	 ~ ∃x(x = mx) ⊃ ~ ∃x(x = fx)
	
f.	 ∃y∀x∃w∀u((Mxy ≡ x = y) ∙ (Fuw ≡ u = w))
	
g.	 ∀x∃y∀z((Fzy ≡ z = y) ∙ Fyx)
	
h.	 ~ ∃x∃y∃z(mx = y ∙ mx = z ∙ y ≠ z)
	
i.	 ∀x∀y∀z((fx = y ∙ fx = z) ⊃ y = z)
	
j.	 ∀x∀y(y = mx ⊃ y ≠ x)
	
k.	 fa = o ∙ ma = j
	
l.	 Mjo ∙ Mja ∙ Foa
	
m.	 ∃x∃y∃z((x = my ∙ y = mz ∙ x = mz) ∙ x = j ∙ y = o ∙ z = a)
	
n.	 ∃x∀y((mfy = my ≡ y = x) ∙ x = a)
6.1  # Tips for Translation (Symbolization, Formalization)

351
© The Author(s), under exclusive license to Springer Nature 
Switzerland AG 2022
O. Makridis, Symbolic Logic, Palgrave Philosophy Today, 
https://doi.org/10.1007/978-3-030-67396-3_7
Chapter 7
Semantic Models for ∏: ∏⧉
We retain the grammatical resources we have made available for formal languages 
of predicate logic (first-order logic), ∏, and implement those resources, with the 
grammar we have legislated, as the semantic formal system ∏⧉. We will pursue 
two different approaches for reasons that are soon to become revealed. Let us recall, 
from the earlier section introducing predicate logic, that a semantic model is an 
abstract structure that comprises an non-empty domain, also called universe of dis-
course, which may or may not be finite; and a function (meaning that it assigns 
unique outputs to inputs), which has different names you may come across in the 
literature: valuation, interpretation, signature, value-assignment, semantic valua-
tion. This function we symbolize by “||” and other symbols used in texts include:
σ, 𝑣, 𝔣.
Let us remark, then, that the semantics of predicate logic is carried out by means 
of models. It may be asked whether it makes sense to speak in this way with respect 
to the basic sentential logic. The answer is affirmative: a model encapsulates a logical 
option that we can construct and make sense of on the basis of objects that we spec-
ify, so we can talk about it in a meaningful way. Attention is needed, though: this is 
not, and should not be, an empirically constituted or factually verifiable construction. 
The game is composed as an abstract enterprise and we may use it of course to build 
narrative about items that seem to reflect empirically or factually recognizable 
affairs – but it is important to grasp that our items are abstract, they are constructed 
entirely from scratch and the availability of things to talk about tracks whether we 
can meaningfully carry out this discourse with meanings (semantics) understood, 
again, on the basis of what has been constructed. The possible expression of items 
and issues that seem familiar from actual experience, if it arises, is only an auxiliary 
aid that may facilitate the enterprise we are carrying out; but this enterprise itself is 
settled exclusively by means of the formal devices we use and cannot depend or be 
liable to be checked by reference to any concrete or actual conditions. To return to the 
case of the sentential logic: our familiar truth table method, which has provided the 

352
semantics for the standard sentential logic, can be thought of as a modeling. The 
symbols we have in sentential logic are rather uncomplicated: sentential variables are 
thought as being assigned meaning (hence, the semantics again), as it is done with 
modeling: and, notice, the meanings (or interpretations) are not, of course, actual or 
factual events or objects, but they are truth values (of which we have exactly two in 
the standard sentential logic – true and false.) Each row of the truth table can be 
thought of as modeling exactly one specific state of affairs or logical possibility (but 
notice again that the appeal to intuitions in a phrase like “state of affairs” is only an 
incidental assistance to our imagination whereas the things were are talking about are 
abstract.) Certain conditions are imposed, which the student of logic would need to 
investigate closely as a greater degree of precise and focused analysis is provided: for 
instance, it is important that each row of the truth table (each logical possibility, logi-
cally possible option or case, interpretation, valuation, value assignment, logically 
possible state of affairs) is independent of every other row; the entire schedule (map, 
collection) of the rows establishes all and only the logically possible value assign-
ments to the atomic sentential variables; and so on. This is what an analysis on the 
basis of the semantic modeling is like in the case of sentential logic. But in the case 
of predicate logic, the plot thickens.
In predicate logic we have added symbolic resources and these new formal ame-
nities must be managed semantically. A marked contrast to the case of the unex-
tended sentential logic is that compositionality of logical meaning is not available in 
a trivial way anymore: by compositionality of meaning (certainly, a semantic cate-
gory since we are talking about logical meaning) we are referring to the character-
istic of the sentential logic by which the logical meaning (which is the truth value) 
of a compound sentential formula is precisely and uniquely (functionally) determin-
able if the logical meanings (truth values) of the atomic variables in the formula are 
given. The meanings of the atomic variables themselves are set by fiat (laid down, 
legislated) as being either the true of the false truth value. We may think of the set 
with members true and false as the domain of our model, with all constructible enti-
ties (sentential formulas) as being one or the other. But in the case of predicate logic, 
we have quantified expressions like:
∀xφ, ∃xφ	
	
== with variable x free in φ
Removing the quantifier, we have now variable x free in the symbolic expression 
φ, which we call the matrix of the quantifier (when the quantifier symbol is attached.) 
We know, however, that the remaining symbolic expression, φ, is not a sentence: it 
does not have a semantic referent (a logical meaning, which is true or false as the 
case was of course also in sentential logic): this expression is, rather, as we have 
called it, an open sentence or a sentential function. It is like a sentence of language 
(speaking only analogically, of course), in which there are pronouns and are such 
that no contextual information can be used to specify what the referents are for these 
pronouns. The pronouns are systematically ambiguous (the grammar of our predi-
cate logic formalism dictates this), and, accordingly, there can be no meaning (true 
or false) assigned to the grammatical sentence. Although it may be well-formed 
grammatically, the open sentence has no logical meaning. It follows, then, that, in 
7  Semantic Models for ∏: ∏⧉

353
the case of predicate logic, we lack the ready computational facility – semantic 
compositionality – that allowed determination of the meaning (truth value) of the 
sentential formula on the basis of the meanings (truth values) of its component parts 
(atomic variables.) A different approach is needed. Let us now return to the begin-
ning and lay down the basics for predicate-logic models. The model has a non-­
empty domain, not necessarily finite, and a function that uniquely assigns to symbols 
their logical meanings (also called interpretations, valuations, signature.)
𝔐 = <ⅅ, ||>.
The domain of the model has to have at least one member; empty domains are 
not allowed, by foundational stipulation, in the standard predicate logic semantics. 
An alternative approach to predicate logic, within a family of logics known as Free 
Logic (logic free of existential presuppositions) permits empty domains. A common 
approach to constructing such a logic is to construct models with a pair of domains 
(inner and outer domain, as they are usually called), with one domain comprising all 
and only the objects that are considered as actually existing while the other domain 
has as members the things that are not deemed to be actually existing (perhaps fic-
tive or mythical entities.) But in the standard approach to predicate logic, which we 
are following, an empty domain is disallowed to begin with. This alerts us to the fact 
that a translation of “nothing exists” into our formal language would have to be 
checked as a logical falsehood. Or, “every named thing exists” must be a logical 
truth. Moreover, we must name objects – on the first approach we undertake but also 
on the second approach we follow below temporary assignments of variables as 
names of objects are rendered available by stipulation. Therefore, the impression is 
created based on this that our standard logic makes it a matter of logic that every-
thing exists is necessarily true and nothing exists is necessarily false. This may be 
thought of as a serious defect since it is rather an empirical, not a logical, matter 
whether things exist or not. On the other hand, the commitment to this position 
about existence can be hailed as a success for the reason that it removes from the 
territory of logical analysis issues that are metaphysical and have proven histori-
cally perplexing and vexing: it is like saying that “let whatever your theory commits 
to be granted existence;” in that case, the metaphysical issue is displaced on the task 
of examining if theories are good or not – and, in this case, assuming that scientific 
theories pass the proper tests as to what a good theory is, then we let science replace 
idle metaphysical speculation. Nevertheless, there may well be lingering doubts 
about all this and, after all, the development of alternative predicate logics, men-
tioned already, is motivated at least in part by deep philosophical considerations as 
to how the standard logic handles existential commitment. Another related subject 
is this: there is a view, due to Immanuel Kant, that existence is not a logical predi-
cate. Of course, we will not argue otherwise: the only predicate that is treated as 
logical is the binary relational predicate of identity. Now, Kant’s point is that exis-
tence as a predicate that can be predicated of concepts is idle notionally – it does not 
add or take anything away from the concept whose characterization is provided 
exclusively and exhaustively by definition. If you know what is meant by the con-
cepts “dollar” and the “five” then the statement “five dollars” is not affected by 
7  Semantic Models for ∏: ∏⧉

354
whether someone does or does not have five dollars in her pocket. Or, if you con-
sider the concept of a Euclidean triangle, provided definitionally in the Euclidean 
geometry, nothing changes about what we mean by “Euclidean triangle” when it 
turns out, as it has turned out, that no such things exist in the universe (since the 
geometry of relativistic physics is most assuredly non-Euclidean and we take rela-
tivistic theory to be the “correct” physics of our universe.) There is a famous proof 
of God’s existence, known as Anselm’s ontological argument, that purports to prove 
the existence God, defined as that entity than which nothing greater can be con-
ceived to exist. The proof is provocative, for better or worse, in that it concludes to 
an empirical statement (existential statement) but there is not a single empirical 
premise in the proof itself! And yet, it is not easy to find where the mistake is in the 
proof. But the proof does treat existence as a logical predicate, in the above-­
mentioned sense in which this is defined by Kant: hence, we have the mistake. 
Notice now, on the basis of what was said above about our predicate logic, that for 
our predicate logic, with its prohibition of empty domain and assignment of mean-
ings (names) to entities, “everything exists” is trivially true (a logical truth) and 
“nothing exists” is trivially false (a logical contradiction.) This seems to corroborate 
Kant’s view but, it should be pointed out, we might actually be misled in so thinking 
because what we are rediscovering in this way may well be just our choice of logical 
formalism. Can we really claim a heuristic (discovery-related) success for our pred-
icate logic? Can a logic have such characteristics? These are deep questions and we 
cannot pursue them here but let us see briefly how we can show that existence is 
granted automatically, trivially, to everything we are talking about.
	1.	 ~ ∀x∃y(x = y)	
-- we assume, for proof by contradiction, that it is not the 
case that for every x there is at least one y whose name co-refers with x (in other 
words, that everything is, in meaning, identical with the meaning of an existent 
thing – meanings are referents…)
	2.	 ∃x∀y ~ (x = y)	
-- we convert, as we examine in detail in other sections: the 
quantifiers are inter-convertible: accordingly, we have: there is some x such that 
for all y, it is not the case that the names of x and y co-refer.
	3.	 ∀y ~ (t = y)	
-- we give a specific name to the y, since it is some specific 
thing: this constant, t, is what we call an eigenparameter; it has to be new, 
and it is.
	4.	 ~ (t = t)	
-- since we are now dealing with universal quantification, 
in line 3, we can choose any name whatsoever; we choose t again; this is what 
we obtain, which is surely absurd since it negates a fundamental law, which we 
regard as a logical law, the law of self-identity: we have proven, by indirect proof 
or proof by contradiction (reductio) that everything exists…
	5.	 ∀x∃y(x = y)
The valuation function assigns logical meanings to the symbols, specified as fol-
lows. We will pursue two alternative options, for the second one of which all terms 
(including individual variables) are assigned referents with the variables receiving 
temporary referents. In general, we leave this option out at first, considering 
7  Semantic Models for ∏: ∏⧉

355
assignment of logical meanings for the fixed-meaning terms: individual constants 
(names), and function symbols. The logical meaning of a fixed term is its referent or 
denotatum: this is the object of the domain to which the fixed term symbol refers. 
Since this is a functional attribution (the interpretation assignment is a function), 
every name has a unique referent. Two or more names may still name the same 
object of the domain (each one is functionally or uniquely assigned but they name 
the same object). In that case, the names are identical: identity is defined as co-ref-
erence. A great deal depends on whether all the objects of the domain are named: 
this is the first approach we will pursue. Of course, this may not be possible if we 
have in the domain more objects that we can provide names for. The second approach 
we will implement will address this case, and it is in this option that we will need to 
supplement with an additional interpretation function, which makes temporary 
assignments of objects from the domain to the individual variables (while the attri-
butions to the fixed term symbols continue to be dispatched by means of the stan-
dard interpretation function.)
The logical meanings of predicate symbols (referents) assigned by means of the 
interpretation function are indeed sets. A set is a collection of objects – any objects, 
insofar as they are discrete and specified – and so that for any object we can deter-
mine if it is a member of the set or not. Another set-theoretic concept we need is that 
of an ordered n-tuple. (See the final chapter for extensive presentation of elements 
of set theory.) An ordered pair (for n=2), symbolized by “<x, y>” with x and y as 
members, is a collection of objects in which the order of placement from left to right 
is rigid. For instance, if the predicate (relational predicate, two-place or binary pred-
icate) is for “x is larger than y” over the domain of natural numbers, then <2, 1> is 
a member of the predicate-set (called predicate-extension) but <1, 2> is not. If we 
depend on the mere set-theoretic inclusion notation, using set-brackets to include 
the members, we may write {1, 2} or {2, 1} indifferently but we cannot indicate the 
imposed order of being-larger-than. (We may think of <2, 1> as {{2, 1}, 1}, for 
reasons we address in the last chapter, in which we go over basics of set theory.) For 
predicate symbols of arity n in general, the extension of the predicate is the set of 
the ordered n-tuples. Another concept we need is that of the power set of a set: the 
power set of a set is the set of all the sets that are subsets of the set. As for subset-
hood: a set X is subset of a set Y if and only if all the members of X are members of 
Y. It may be that Y has members not in X, in which case the subsethood relation is 
called proper subsethood. The empty set (symbolized by “∅”) is subset of every set. 
For instance, the power set of Z = {1, 2}, is ℘(Z) = {∅, {1}, {2}, {1, 2}}.
Also, a Cartesian product of a set by itself is defined as the set with members the 
ordered n-tuples that have members the members of the set in all possible combina-
tions: for instance, the Cartesian product of a set Z = {1, 2}, by itself is: Z x Z = Z2 
= {<1, 1>, <1, 2>, <2, 1>, <2, 2>}.
It is important that the members of the predicate extension (or the members of 
the n-tuples in the extension) are the objects of the domain; they are not the names 
such objects are given. The same applies in the case of the referents (meanings) of 
7  Semantic Models for ∏: ∏⧉

356
terms: the referent, what is named, is certainly the object in the domain. Since we 
cannot place objects in sets notationally, we find ourselves in the position of having 
to use symbols, separate from the names, for representing the domain objects 
themselves.
•	 ℳ=<ⅅ, ||>
•	 ||: CONSTANTS = {a, b, …, ai, …} ↦ ⅅ
•	 ||: FUNCTION SYMBOLS = {f1
1, …, g1
k, …, fn
i, …} x ⅅn ↦ ⅅ
•	 ||: PREDICATE SYMBOLS = {A1
1, …, A1 n, …, An
1, …} ↦ ℘(ⅅn):: ⅅn = ⅅ x … 
x ⅅ:: n times)
•	 ||: SENTENCES ↦ {T, F}
As an example, we may consider the case (model) represented as follows:
9
9 ℳ=<ⅅ = {⦅, ⦆}, ||>
9
9 ||: CONSTANTS = {l, r} ↦ {⦅, ⦆}:: |l| = ⦅, |r| = ⦆.
9
9 ||: FUNCTION SYMBOLS = {f, g} x ⅅ1 ↦ {⦅, ⦆}:: f(⦅) = ⦆, g(⦆) = ⦅.
9
9 ||: PREDICATE SYMBOLS = {L, R} ↦ ⅅ2:: |L| = {< ⦅, ⦆>}, |R| = {⦆, ⦅}.
We remark that the model is remarkably abstracted from any recognizable nar-
rative although one could be provided to assist imagination and intuitive grasp. It 
is crucial that the formal character of the model as structure is particularly high-
lighted by the fact that nothing is gained, except psychologically perhaps, by 
tending to more concrete narratives to accompany the model. In the present case, 
a discourse could be constructed to guide the investigator of the model in a pal-
pable fashion: for instance, the objects could be said to be left-looking and right-
looking mirrors, with names as “l” and “r”; the function symbols can be interpreted 
(using a different term “interpretation”, rather confusedly, since we do have an 
interpretation or valuation for any model) as “to the left of” and “to the right of” 
(with the conditions of existence and uniqueness of the output satisfied in this case 
for the definition of the function symbols to be meaningful in the model); finally, 
the binary predicate symbols can be concretized further as “to the left of” and “to 
the right of.” For this narrative, even topographical attributions are made (regard-
ing the relative placement of the mirrors and not only their presumed inherent 
charactersistics as left- and right-­looking.) The impression may be gained that we 
have a modeling that is in some ways more reliable for purposes of study but this 
is an entirely unsubstantiated surmise: it may be only a matter of facilitating the 
psychology of examination, appealing to intuitions and providing related (possi-
bly pedagogically helpful) amenities but nothing changes for the mechanics of 
using semantic models in this way. We will be using the example we have con-
structed in subsequent analysis.
We will next examine the two distinguished cases: one in which every member 
of the model’s domain is named (possibly by more than one co-denoting names or 
constants) and the case in which no such assumption is made and an alternative 
modeling approach, initially conceived in a certain version by Alfred Tarski, is 
implemented. The truth conditions will be specifically laid out for each case.
7  Semantic Models for ∏: ∏⧉

357
7.1  ∞ Countermodels with Infinite Domains, ∏⧉∞
Unlike the case of sentential logic, the semantics for predicate logic cannot preclude 
cases in which we produce an infinite countermodel – a model in which one or more 
formulas φ, φ1, …, φn are false (thus showing that φ is not a logical truth or that the 
set {φ1, …, φn} is inconsistent) or an argument form has true premises and false 
conclusion (showing that the argument form is invalid.) The availability of infinite 
domains for models alerts us to the fact that, unlike with sentential logic, we cannot 
rely generally on applying some mechanical decision procedure (like the truth table) 
that can be executed by programming arrangements and is guaranteed to terminate 
within a finite number of steps. We may need to rely on producing a countermodel 
in refuting claims but, as we have hinted, we run also into the prospect of counter-
models with infinite domains. We examine as an example the claim that we can 
prove that relation that is characterized by seriality also has to be characterized by 
symmetry; this is not a valid inference as we can show by configuring a counter-
model but, as we will see, the countermodel may well have an infinite domain.
•	 A relation R is serial iff: ∀x∃yRxy
•	 A relation R is symmetric iff: ∀x∀y(Rxy ⊃ Ryx)
	 1.	 ∀x∃yRxy	
	
	
	
	
Assumption
	 2.	 ~ ∀x∀y(Rxy ⊃ Ryx)	 	
	
	
Negation of the conclusion – 
for reductio, but it will turn 
out to be unsuccessful show-
ing invalidity
	 3.	 ∃x∃y(Rxy ∙ ~ Ryx)	
	
	
	
Converting the quantifiers 
and negating implication (2)
	 4.	 Ra1a2 ∙ ~ Ra2a1	
	
	
	
Instantiating the existential 
quantifiers—new constants 
for instantiation of existen-
tial 
quantifier 
symbols 
(which are called eigenpa-
rameters) (3)
	 5.	 ∃yRa1y	
	
	
	
	
Universal instantiation (1): 
we continue by saturating 
which means that we instan-
tiate for each eigeneparame-
ter we have so far: the 
removal of quantifier sym-
bols is undertaken from left 
to right
	 6.	 ∃yRa2y	
	
	
	
	
Universal instantiation (1)
7.1  ∞ Countermodels with Infinite Domains, ∏⧉∞

358
	 7.	 Ra1a3	
	
	
	
	
Instantiation of the existen-
tial quantifier symbol – new 
eigenparameter (5)
	 8.	 Ra2a4	
	
	
	
	
Instantiation of the existen-
tial quantifier (6)
	 9.	 Ra1a5 	
	
	
	
	
Instantiation of the existen-
tial quantifier symbol – new 
eigenparameter (5)
	10.	 Ra1a6	
	
	
	
	
Instantiation of the existen-
tial 		
	
	
	
	
quantifier symbol  – new 
eigenparameter (5)
	11.	 ∶
	12.	 Ra2an	
	
	
	
	
Instantiation of the existen-
tial 		
	
	
	
	
quantifier symbol  – new 
eigenparameter (6)
	13.	 Ra2an+1	
	
	
	
	
Instantiation of the existen-
tial quantifier symbol – new 
eigenparameter (6)
	14.	 ∶
The informal succession of proof lines does not terminate. The countermodel has 
an infinite domain. We may also produce a countermodel by reflecting on the prop-
erties that are presented and then opting to start with an infinite set – like the natural 
numbers ℕ = {0, 1, 2, 3, …} – and inducing an interpretation such that the extension 
of R is the same as some binary relation over the natural numbers, which is serial 
but not symmetric. The relation of succession (such that Rxy if and only if y = x + 
1) is serial indeed but it is not symmetrical. We can have an infinite-domain coun-
termodel for the given argument form as shown:
ℳ=<ⅅ = ℕ, |R| = {<x, y> / x ∈ ℕ, y ∈ ℕ and y = x + 1}>.
7.1.1  Domains with All Named Objects: ∏⧉⌹
•	 𝔐 =<ⅅ, ||>
We have a semantic model with a non-empty domain and the interpretation func-
tion (signature, valuation, value assignment.) Our transactions are carried out, with 
generous symbolic enhancements of our metalinguistic resources, in the predicate 
logic language ∏⧉⌹ for models with all named domain objects. Since the model-
ing is the instrumentality we employ for semantic purposes – related to logical 
meaning, and hence true and false – we need to present precisely and conspicuously 
what the truth conditions are and we do this by recursive definition. Logical mean-
ing is a matter of true or false, truth value, for sentential formulas as the case was in 
sentential logic in which the sentential formulas are unanalyzed (as we have no 
symbolic resources for representing internal components of a sentence.) The 
7  Semantic Models for ∏: ∏⧉

359
meanings of individual constants and function symbols are objects of the domain 
and the meanings of the predicate symbols are presented by means of sets. We also 
have the identity symbol as a logical symbol and this must be included in our seman-
tic conditions (truth conditions.) We will be using metalinguistic variables in our 
symbolically enhanced fragment of English that provides the metalanguage for our 
system ∏⧉: ℳ(∏⧉). After we lay out the truth conditions we return to the exam-
ple of the previous section to test our semantic definitions. The logical consequence 
relation for the logical system as modeled by a model 𝔐 is symbolized metalinguis-
tically by “⊩𝔐, σ” or “𝔐, σ⊩” as we include a symbol for the valuation or assign-
ment, which we symbolize metalinguistically by “σ” (with the symbol “g” instead 
being quite common in the literature.) Accordingly, the subscripts for model and 
value assignment are placed on the interpretation function as well. If context pre-
vents any ambiguity as to such matters, however, the model and signature metalin-
guistic symbols may be omitted without incurring any risk of ambiguity.
We say that a model and value assignment in the model satisfy the formulas to 
the right of the turnstile. Thus, we coordinate satisfaction conditions (or satisfaction 
constraints) with the semantics of valuation or value assignments.
Truth Conditions for Semantic Model – case of model with all named objects
•	 𝔐, σ⊩ φ 	
if and only if (iff)	
|φ|𝔐, σ = T ∈ {T, F}/ φ ∈ 
SENTENCES
•	 𝔐, σ⊩ ~ φ	
iff	
|~ φ| = T iff |φ|𝔐, σ = F/ φ ∈ 
SENTENCES
•	 𝔐, σ⊩ φ1 ∙ φ2	
iff 	
|φ1 ∙ φ2| = T iff |φ1|𝔐, σ = |φ2|𝔐, σ = T
•	 / φi ∈ SENTENCES
•	 𝔐, σ⊩ φ1 ∨ φ2	
iff	
|φ1 ∨ φ2| = T iff |φ1|𝔐, σ = T or 
|φ2|𝔐, σ = T
•	 /φi ∈ SENTENCES
•	 𝔐, σ⊩φ1 ⊃ φ2	
iff	
|φ1 ⊃ φ2| = T iff |φ1|𝔐, σ = F or 
|φ2|𝔐, σ = T
•	 /φi ∈ SENTENCES
•	 𝔐, σ⊩φ1 ≡ φ2	
iff	
|φ1 ≡ φ2| = T iff |φ1|𝔐, σ = |φ2|𝔐, σ
•	 / φi ∈ SENTENCES
•	 𝔐, σ⊩ Φnλ1λ2…λn 	
iff	
<|λ1|𝔐, σ, |λ2|𝔐, σ, …, |λn|𝔐, σ> ∈ 
|Φn|𝔐, σ
•	 / Φn ∈ PREDICATES, λi ∈ CONSTANTS or FUNCTION SYMBOLS
•	 𝔐, σ⊩ ∃υΦυ	
iff	
|λj|𝔐, σ ∈ |Φn|𝔐, σ
for at least one ○ ∈ ⅅ, such that |λi|𝔐, σ = ○.
/ λj ∈ CONSTANTS or FUNCTION SYMBOLS
•	 𝔐, σ⊩ ∀υΦυ	
iff	
|λj|𝔐, σ ∈ |Φn|𝔐, σ
for all ○ ∈ ⅅ, such that |λi|𝔐, σ = ○.
/ λj ∈ CONSTANTS or FUNCTION SYMBOLS
•	 𝔐, σ⊩ 𝔣λ1…λn = λn+1	
iff	
|λn+1|𝔐, σ = ○ such that: |λ1|𝔐, σ = 
○1, …, |λn|𝔐, σ = ○n, and |λn+1|𝔐, σ = ○n+1; |𝔣|𝔐, σ: <○1, …, ○n> ↦ ○n+1
7.1  ∞ Countermodels with Infinite Domains, ∏⧉∞

360
•	 / 𝔣 ∈ FUNCTION SYMBOLS, ○i ∈ ⅅ, λi ∈ CONSTANTS/ constraint: ○n+1 
exists and is unique
•	 𝔐, σ⊩ λ1 = λ2		
	
iff	
|λ1|𝔐, σ = ○1 ∈ ⅅ and |λ2|𝔐, σ = ○2 ∈ ⅅ
•	 / λ1. 2 ∈ CONSTANTS or FUNCTION SYMBOLS.
Elaboration:
•	 The truth conditions for the connectives are as in sentential logic, which is 
straightforward since the predicate logic extends the sentential logic. Since the 
referents of sentences are truth values, true and false for the standard logic, the 
definitions of the connective symbols have been given in terms of their truth 
conditions, something we examined perspicuously and in an intuitive way when 
we provided the truth-tabular definition. The connectives clauses given above by 
means of recursive definitions recapitulate what we have in the sentential logic. 
For instance, the negation of a formula is true if and only if the formula is false. 
The collection of the two logically possible truth cases
•	 (valuations or assignments of truth values) constitute the modeling for the sen-
tential connective of negation. The specific clauses for predicate logic begin fur-
ther down, with the definition of the semantic conditions for the predicate 
symbols.
•	 A model and value assignment in the model satisfy a predicate of n degree (n-ary 
predicate symbol) if and only if the denotata of the terms accompanying the 
predicate symbol are all members, in the proper order, of the extension of the 
predicate in the model. For instance, given a key assigning to “Bxyz” the mean-
ing “x is between y and z” the referents (or denotata) of the constant symbols 
<|a|, |b|, |c|> are presented in the right order by means of the ordered triplet and 
⌜Babc⌝ is satisfied if and only the value of ⌜Babc⌝ is true which, by the semantic 
conditions, is true if and only if the triplet ⌜<|a|𝔐, σ, |b|𝔐, σ, |c|𝔐, σ>⌝ is a member 
of the extension in the model of the predicate, ⌜|B| 𝔐, σ⌝.
•	 A model and value assignment satisfy the existentially quantified formula ⌜ ∃υ 
Φn… υ…⌝ if only if there is at least one object in the domain, which we may 
symbolize as “○”, such that this object is a member of the extension of the predi-
cate in the model: for at least one constant symbol (name) λ such that the value 
(referent, denotatum) of this constant in the model is the object ○, ⌜ Φn…λ...⌝ is 
true in the model. We may designate by “○λ” the object denoted or named by λ 
for the sake of notational convenience  – and if more than one constants are 
assigned by the interpretation function to name the object, we may symbolize by 
“○...λ…”.
•	 A model and value assignment satisfy the universally quantified formula ⌜ ∀υ 
Φn… υ…⌝ if only if all objects in the domain are members of the extension of the 
predicate in the model: for all constant symbols, or for any constant symbol 
(name) λ whatsoever, such that the value (referent, denotatum) of this constant in 
the model is any object ○ of the domain, ⌜ Φn…λ...⌝ is true in the model.
7  Semantic Models for ∏: ∏⧉

361
•	 A model and value assignment in the model satisfy identity of an n-ary function 
symbol accompanied by constants with a constant symbol λ if and only if the 
object assigned by the ordered n-tuple of objects denoted by the constants by the 
function is the same as the object denoted by λ. The restriction is that an existent 
and unique object is assigned by the function to any n-tuple of objects as inputs. 
It is important to avoid a common mistake: the function symbol does not have a 
truth value as a referent: it is a term symbol. Note that we have provided truth 
conditions for the identity of the function symbol with a unique constant symbol 
(name) from the domain of the model.
•	 The identity formula for any two constants is satisfied in a model and value 
assignment if and only if the constants have the same domain object as their 
referent or denotatum.
As an example, we consider the model we set up earlier.
9
9 ℳ=<ⅅ = {⦅, ⦆}, ||>
9
9 ||: CONSTANTS = {l, r} ↦ {⦅, ⦆}::
9
9 |l| = ⦅.
9
9 |r| = ⦆.
9
9 ||: FUNCTION SYMBOLS = {f, g} x ⅅ1 ↦ {⦅, ⦆}::
9
9 f(⦅) = ⦆.
9
9 g(⦆) = ⦅
9
9 ||: PREDICATE SYMBOLS = {L, R} ↦ ⅅ2::
9
9 |L| = {< ⦅, ⦆>}.
9
9 |R| = {<⦆, ⦅>}.
We determine the truth value of certain presented formulas in the model. Unless 
these are logical truths or logical falsehoods, the formulas can obtain different truth 
values in different models and, indeed, a type of semantic exercise is available, 
which requires building a model in which a given, logically contingent, formula is 
true or false, as specified. Note below the steps we unfold, obeying the definitions 
of the semantic conditions that have been laid down. As we move in implementing 
the semantic conditions for the removal of quantifier symbols in nested-quantifier 
formulas, we move from inside to outside (or from right to left.)
•	 𝔐, σ⊩ ∃x∀yLxy iff
•	 |∃x∀yLxy|𝔐, σ = T iff
•	 |∃xLxa|𝔐, σ =T for all objects ○a ∈ ⅅ, such that |a| = ○a iff
•	 |Lab|𝔐, σ = T for some object ○a and for all objects ○b ∈ ⅅ
Now that we have determined the outlook of the semantic conditions for valida-
tion of the formula (for the formula to be true in the given model for some valua-
tion), we work backwards, as shown below, to confirm or disconfirm whether the 
semantic conditions are satisfied. We check each one of the objects in the domain 
and see if it is L-related to all the objects of the domain (including itself): because 
the formula has the existential quantifier as its outmost symbol and with the 
7.1  ∞ Countermodels with Infinite Domains, ∏⧉∞

362
universal quantifier symbol as nested in, the conditions for truth are satisfied if at 
least one of the objects is L-related to all the objects in the domain.
•	 ⦅: |Lll|𝔐, σ = F 		
because <⦅, ⦅> ∉ |L|𝔐, σ 	
--
the ordered pair with the two occurrences of the object denoted by l is not mem-
ber of the extension of L in the model.
|Llr|𝔐, σ = T 	
	
because <⦅, ⦆> ∈ |L|𝔐, σ	
--
the ordered pair with members the objects denoted by l and r is a member of the 
extension of L in the model.
|∀xLlx|𝔐, σ = F because one of the two cases for this objects fails satisfaction. 
Notice how we can develop the given formula in a certain way (expressing the uni-
versal quantification as conjunction and the existential quantification as inclusive 
disjunction over this domain with finite number of members. This development is 
correct in any such model.
|∃x∀yLxy| = |∃x(Lxl ∙ Lxr)| = |(Lll ∙ Llr) ∨ (Lrl ∙ Lrr)|.
So far we have established that:
|Lll ∙ Llr|𝔐, σ = |F ∙ T|𝔐, σ = F.
We repeat the same procedure for the other object, which is denoted by the inter-
pretation function of the model by “r”.
•	 ⦆: |Lrl|𝔐, σ = F	 	
because <⦆, ⦅> ∉ |L|𝔐, σ
•	 |Lrr|𝔐, σ = F	
	
because <⦆, ⦆> ∉ |L|𝔐, σ
•	 Returning to the developed expression of the given multiply quantified formula:
•	 |Lrl ∙ Lrr|𝔐, σ = = |F ∙ F|𝔐, σ = F.
•	 Already, we had:
•	 |Lll ∙ Llr|𝔐, σ = |F ∙ T|𝔐, σ = F.
•	 Putting together, we have:
•	 |∃x∀yLxy| = |∃x(Lxl ∙ Lxr)| = |(Lll ∙ Llr) ∨ (Lrl ∙ Lrr)| 𝔐, σ = |F ∨ F|𝔐, σ = F.
7.1.2  # Prenex Formulas
The formula that was examined in the preceding example presents all nested quanti-
fier symbols (quantifier symbols within the scope of other quantifier symbols) in a 
special type of form that is called prenex form. Examination of the truth values of 
formulas in given models is facilitated significantly by first converting given formu-
las into equivalent expressions of the formulas in prenex form.
A prenex form of a well-formed formula φ is an equivalent well-formed formula 
ψ with all quantifiers pulled up in the front (with the remaining part of the formula 
as the matrix.) The pulling of the quantifier symbols to the front so as to generate a 
7  Semantic Models for ∏: ∏⧉

363
prenex form of the given formula is feasible by using certain rules, which we will 
examine. In the course of executing the shifts, we may reletter the variables.
The equivalences that permit shifts of quantifier symbols for the construction of 
the equivalent prenex form of a given formula are presented below. The list includes 
related information we were compelled to present in the section on translations, in 
which case challenges also arise, understandably, regarding the rendering of multi-
ply quantified formulas with nested quantifier symbols.
•	 ∀x(φ ∙ ψ) ≡ (∀xφ ∙ ∀xψ) [x is free in φ and in ψ before bound by the quantifiers]
•	 ∃x(φ ∨ ψ) ≡ (∃xφ ∨ ∃xψ) [x is free in φ and in ψ before bound by the quantifiers]
•	 ∀x(φ ∨ ψ) ≡ (∀xφ ∨ ψ) [x is free in φ but not in ψ before bound by the quantifiers]
•	 ∀x(φ ∨ ψ) ≡ (φ ∨ ∀xψ) [x is free in ψ but not in φ before bound by the quantifiers]
•	 ∃x(φ ∙ ψ) ≡ (∃xφ ∙ ψ) [x is free in φ but not in ψ before bound by the quantifiers]
•	 ∃x(φ ∙ ψ) ≡ (φ ∙ ∃xψ) [x is free in ψ but not in φ before bound by the quantifiers]
•	 (∃xφ ⊃ ψ) ≡ ∀x(φ ⊃ ψ) [x is free in φ before bound by the quantifiers]
•	 (∀xφ ⊃ ψ) ≡ ∃x(φ ⊃ ψ) [x is free in φ before bound by the quantifiers]
•	 (φ ⊃ ∀xψ) ≡ ∀x(φ ⊃ ψ) [x is free in ψ before bound by the quantifiers]
•	 (φ ⊃ ∃xψ) ≡ ∃x(φ ⊃ ψ) [x is free in ψ before bound by the quantifiers]
We can approach this as a matter of first converting implications to inclusive 
disjunctions and then observing the following distributive equivalences regarding 
quantifier symbols distributing over disjunctions and conjunctions. Subsequently, 
we can convert back to implicational formulas. We should find that we obtain the 
results above. First we show how conversions to and from implicational formulas 
and inclusive disjunction formulas can be executed.
(φ ⊃ ψ) ≡ (~ φ ∨ ψ)
___(∃xψ ∨ ∃xφ) ≡ ___∃x(ψ ∨ φ)
___(∀xφ ·· ∀xψ) ≡ ___∀x(φ · ψ)
For example:
(∀xFx ⊃ ∃xGx) ≡ (~ ∀xFx ∨ ∃xGx) ≡ (∃x ~ Fx ∨ ∃xGx)
≡ ∃x∃y(~ Fx ∨ Gy) ≡ ∃x∃y(Fx ⊃ Gy).
We could reach the same result following straightforwardly the rules for the 
implication symbol given above.
(∀xFx ⊃ ∃xGx) ≡ ∃x∃y(Fx ⊃ Gy)
As examples of conversions to prenex form, we offer:
	1.	 ∀y(∃xRxy ⊃ ∃zRzy) ≡ ∀y∀x(Rxy ⊃ ∃zRzy) ≡
∀y∀x∃z(Rxy ⊃ Rzy)
	2.	 ∀x∀yRxy ⊃ ∀z(∃wRzw ∨ Rzz) ≡
∃x∃y(Rxy ⊃ ∀z(∃wRzw ∨ Rzz)) ≡
∃x∃y(Rxy ⊃ ∀z∃w(Rzw ∨ Rzz)) ≡
∃x∃y∀z∃w(Rxy ⊃ (Rzw ∨ Rzz))
7.1  ∞ Countermodels with Infinite Domains, ∏⧉∞

364
7.1.3  Domains with Unnamed Objects: ∏⧉⌻
We have neatly treated the semantics of predicate logic, providing models, for the 
case in which all objects in the model’s domain are named. We did this in the formal 
system ∏⧉⌹ but now we move laterally – as we do not change anything about the 
symbolic resources and grammatical arrangements – to the system ∏⧉⌻, allow-
ing that not all objects in the domain have names. We cannot relax the other assump-
tion, that the domain cannot be empty, without transporting ourselves to a different 
area of alternative predicate logics, which we do not address in this text (barring 
some fleeting references to Free Logic); but we must confront the pressing need of 
handling the case in which not all objects of the domain are named. There may be 
more objects than there are names. Indeed, nothing should prevent us from applying 
this remarkable type of formal system, which has sufficient expressive power to 
translate mathematical statements, to narratives (models, indeed) in which the 
domain is the set of natural numbers, for instance. Moreover, we cannot have 
decomposition of formulas as we enjoy in sentential logic: removing quantifier 
symbols, we are left with what we have called open sentences which do not have 
truth values as referents (which is to say that they do not have logical meanings, 
although, of course, they are grammatically correct – rather like sentences of a lan-
guage, which are systematically constructed with pronouns that are irremediably 
ambiguous, having no possible referent and, hence, unable to contribute toward 
determining a truth value for the composite sentence.) The stipulation as to the nam-
ing of all objects ensures that all open sentence formulas can be converted to sen-
tences by substitutions of individual constants that name objects of the domain. This 
stratagem, however, only obscures the fact that there is no compositional truth-
functional structure to the syntactically formed sentences (which are open sentences 
before they have quantifiers attached to bind the free variable letters.) Our present 
task, accordingly, is to face the dire necessity of dealing with the semantic disposi-
tion of formulas without counting on having sufficiently available constant letters to 
use. This requires a strategic breakthrough in our thinking, and the standard approach 
is due initially to Alfred Tarski, although the system used is not exactly what Tarski 
deployed. Indeed, there is wide open variety across textbooks in the specific treat-
ment of this type of model, but the essential ideas are the same.
To make a long story short, the key tactic that instigates the approach of generat-
ing series of assignments for the variables (and for the constants, which have to be 
fixed for all series, of course.) The catch is this: how can we assign meanings – 
objects from the domain – to the variables since the variables are taken by construc-
tion to be non-referring (meaningless) symbols? The response, making the 
breakthrough possible, is this: we assign temporary referents (objects of the domain, 
which confer then temporary meaning to the variables.) We may analogize to the 
case of a natural language, and specifically to the case in which variation of context 
may specifically assign meanings to pronouns like “he” or “she” or “it.” What is 
needed is to deal with such open-ended assignments, which are transient but preci-
fied or specifically constructed, in a systematic way. The sophisticated approach to 
7  Semantic Models for ∏: ∏⧉

365
doing this requires that we have assignment-variants. This concept is defined as a 
presumed complete assignment of objects from the domain to all terms (including 
variables), so that the assignment is functional (exactly one unique object is 
assigned), and so that the model’s fixed assignments to constants and functions are 
respected, and also so that any two variants differ from each other in at most one 
pairing of term with object.
Our model has to be equipped now with an additional function (the assignments, 
including the temporary assignments, have to be always functional in the sense that 
exactly one unique object from the domain is assigned for each input – and this is 
so for the temporary assignment variants as well.) We use the metalinguistic symbol 
“|| ||” for the temporary assignment function. Symbolizing as before terms in general 
by “λi”, we have the following for the meanings (values) of the terms:
•	 |λ| = ○λ ∈ ⅅ	
if λ ∈ CONSTANTS ⊆ TERMS
•	 |λ| = ○λ ∈ ⅅ	
if λ ∈ FUNCTIONS ⊆ TERMS, provided that the object exists 
and is unique
•	 |λ| = ||λ|| ∈ ⅅ	
if λ ∈ VARIABLES ⊆ TERMS
If the term is a constant, it has a settled referent (also called denotatum), which 
is its logical meaning. In each temporary assignment-variant, the referent of the 
constant is fixed. Function symbols, which are also terms as we know, have an exis-
tent and unique referent-object in the domain, and this is also settled across 
assignment-­variants. But the big change comes with the stipulation that variables 
are given temporary assignments, matched in each assignment-variant with some 
object in the domain. Let us also introduce the requisite subscripts to the value sym-
bols (for model and assignment) to present the above completely and to express 
some interesting observations:
•	 |λ|𝔐, σ = ○λ ∈ ⅅ	
if λ ∈ CONSTANTS
•	 ||λ||𝔐, σ = |λ|𝔐, σ	
if λ ∈ CONSTANTS
•	 |λ|𝔐, σ = ○λ ∈ ⅅ	
if λ ∈ FUNCTIONS / provided that the object exists 
and is unique
•	 |λ|𝔐, σ = ||λ||𝔐, σ(λ) =○ ∈ ⅅ	
if λ ∈ VARIABLES ⊆ TERMS
As an example of two serially constructed variants of assignments, let us exam-
ine the following.
ℳ = <ⅅ, ||, || ||>.
ⅅ = {①, ②, ③}
|a|𝔐, σ = ①
|b|𝔐, σ = ②
|f(①)| 𝔐, σ = ②
There is no name for the object of the domain, which is represented by the 
enclosed alphanumerical three. We regard variants of assignments σ1, σ2 and so on. 
We will return to this model for practice later, after we have specified the semantics 
for models with unnamed objects. Notice how the variants respect the fixed values 
for the constant and function symbols. Given the definition of the concept, any two 
7.1  ∞ Countermodels with Infinite Domains, ∏⧉∞

366
variants differ from each other in at most one matching between terms (including 
for three variables) and domain objects. When we say that the variation is for at 
most one pairing, this implies that we can have two variants that are identical as well.
σ1:	
σ1(a) = ①, σ1(b) = ②, σ1(f(①) = ②, σ1(x) = ②, σ1(y) = ②, σ1(z) = ①
σ2: 	 σ2(a) = ①, σ2(b) = ②, σ2(f(①) = ②, σ2(x) = ②, σ2(y) = ②, σ2(z) = ②
σ3: 	 σ3(a) = ①, σ3(b) = ②, σ3(f(①) = ②, σ3(x) = ②, σ3(y) = ②, σ3(z) = ③
σ4:	
σ4(a) = ①, σ4(b) = ②, σ4(f(①) = ②, σ4(x) = ②, σ4(y) = ②, σ4(z) = ①
We can now provide the semantics for models with domains that have unnamed 
objects; we cast in bold the clauses of the recursive definitions, which are altered to 
accommodate the new case by using the temporary assignments variant method.
Truth Conditions for Semantic Model – case of model with unnamed objects
•	 𝔐, σ⊩ φ 	
if and only if (iff)	
|φ|𝔐, σ = T ∈ {T, F}/ φ ∈ 
SENTENCES
•	 𝔐, σ⊩ ~ φ	
iff	
|~ φ| = T iff |φ|𝔐, σ = F/ φ ∈ SENTENCES
•	 𝔐, σ⊩ φ1 ∙ φ2	
iff 	
|φ1 ∙ φ2| = T iff |φ1|𝔐, σ = |φ2|𝔐, σ = T
•	 / φi ∈ SENTENCES
•	 𝔐, σ⊩ φ1 ∨ φ2	
iff	
|φ1 ∨ φ2| = T iff |φ1|𝔐, σ = T or |φ2|𝔐, σ = T
•	 /φi ∈ SENTENCES
•	 𝔐, σ⊩φ1 ⊃ φ2	
iff	
|φ1 ⊃ φ2| = T iff |φ1|𝔐, σ = F or |φ2|𝔐, σ = T
•	 /φi ∈ SENTENCES
•	 𝔐, σ⊩φ1 ≡ φ2	
iff	
|φ1 ≡ φ2| = T iff |φ1|𝔐, σ = |φ2|𝔐, σ
•	 / φi ∈ SENTENCES
•	 𝔐, σ⊩ Φnλ1λ2…λn 	
iff	
<||λ1||𝔐, σ, ||λ2||𝔐, σ, …, ||λn||𝔐, σ> ∈ |Φn|𝔐, σ
•	 / 
Φn 
∈ 
PREDICATES, 
λi 
∈ 
VARIABLES, 
CONSTANTS 
or 
FUNCTION SYMBOLS
•	 𝔐, σ⊩ ∃υΦυ	
iff	
||λj||𝔐, σ ∈ |Φn|𝔐, σ for at least one ○ ∈ ⅅ, 
such that ||λi||𝔐, σ = ○/ λj ∈ VARIABLES, CONSTANTS or FUNCTION SYMBOLS
•	 𝔐, σ⊩ ∀υΦυ	
iff	
||λj||𝔐, σ ∈ |Φn|𝔐, σ for all ○ ∈ ⅅ, such 
that ||λi||𝔐, σ = ○
•	 / λj ∈ VARIABLES, CONSTANTS or FUNCTION SYMBOLS
•	 𝔐, σ⊩ 𝔣λ1…λn = λn+1	
iff	
|λn+1|𝔐, σ = ○ such that: |λ1|𝔐, σ = ○1, …, 
|λn|𝔐, σ = ○n, and |λn+1|𝔐, σ = ○n+1; |𝔣|𝔐, σ: <○1, …, ○n> ↦ ○n+1
•	 / 𝔣 ∈ FUNCTION SYMBOLS, ○i ∈ ⅅ, λi ∈ CONSTANTS/ constraint: ○n+1 
exists and is unique
•	 𝔐, σ⊩ λ1 = λ2	
iff	
||λ1||𝔐, σ = ○ ∈ ⅅ and ||λ2||𝔐, σ = ○ ∈ ⅅ
•	 / λi=1, 2 ∈ VARIABLES, CONSTANTS, FUNCTIONS.
We can see the semantics in action for an example with a model that does not 
have names for its objects.
ℳ = <ⅅ, ||, || ||>.
ⅅ = {①, ②, ③}
|f(①)| 𝔐, σ = ②
|F| 𝔐, σ = {①, ③}
|R|𝔐, σ = {<②, ②>, <③, ③>}
7  Semantic Models for ∏: ∏⧉

367
We determine the truth values in this model of certain formulas.
•	 |∃xRfxfx|𝔐, σ =?
•	 (a) ||x|| 𝔐, σ = ① ⇒ ||fx||𝔐, σ(x) = ① = |fx|𝔐, σ = ② ⇒ <||fx||𝔐, σ, ||fx||𝔐, σ> = <②, ②> ∈ 
|R|𝔐, σ ⇒ ||Rfxfx||𝔐, σ = T.
•	 (b) ||x||𝔐, σ = ② ⇒ ||fx||𝔐, σ(x) = ② ≠ |fx|𝔐, σ = ② ⇒ ||fx||𝔐, σ(x) = ② = undefined.
•	 (c) ||x||𝔐, σ = ③ ⇒ ||fx||𝔐, σ(x) = ③ ≠ |fx|𝔐, σ = ② ||fx||𝔐, σ(x) = ③ = undefined.
•	 Because we are dealing with a function symbol: we have a settled referent (logi-
cal meaning) in the model: the function is partial, it is not defined for all the 
members of the domain; accordingly, the temporary assignment variants must 
respect this. Now we turn to determining the truth value of the given formula. 
Based on the semantics, we have:
•	 |∃xRfxfx|𝔐, σ = T because ||<||fx||𝔐, σ, ||fx||𝔐, σ>||𝔐, σ ∈ |R|𝔐, σ for at least one ○ (= 
①) ∈ ⅅ, such that ||λi||𝔐, σ = ○.
•	 |∃x∃y(Fx ⊃ Ryx)|𝔐, σ =?
•	 (a) ||x||𝔐, σ = ①, ||y||𝔐, σ = ①.
•	 ⇒ <||x||>𝔐, σ(x) = ① ∈ |F|𝔐, σ ⇒ ||Fx||𝔐, σ(x) = ① = T.
•	 ⇒ <||y||𝔐, σ(y) = ①, ||x||𝔐, σ(x) = ①> ∉ |R|𝔐, σ(x) = ①, σ(y) = ① ⇒||Ryx||𝔐, σ(x) = ①, σ(y) = ① = F.
•	 ⇒ ||Fx ⊃ Ryx||𝔐, σ(x) = ①, σ(y) = ① = ||T ⊃ F||𝔐, σ(x) = ①, σ(y) = ① = F.
•	 We can be strategic in choosing variants, based on inspection of the model. We 
may, for instance, proceed with the following variant. We observe that not every 
member of the domain belongs to the extension of the predicate F. Specifically, 
the object represented by the enclosed aphanumerical two is not a member of the 
extension of the predicate F. The antecedent of the formula that is the matrix of 
the given quantified formula could, then, be false for some appropriate selection. 
In that case, however, we can have vacuous truth (when the antecedent of an 
implicational formula is false, the formula is true regardless of the truth value of 
the consequent as we know from basic sentential logic.) We may, then, proceed 
to another variant as follows:
•	 (b) 	 ||x||𝔐, σ = ②, ||y||𝔐, σ = ①
•	 ⇒ <||x||>𝔐, σ(x) = ② ∉ |F|𝔐, σ ⇒ ||Fx||𝔐, σ(x) = ② = F.
•	 ⇒ <||y||𝔐, σ(y) = ①, ||x||𝔐, σ(x) = ②> ∉ |R|𝔐, σ(x) = ②, σ(y) = ① ⇒||Ryx||𝔐, σ(x) = ②, σ(y) = ① = F.
•	 ⇒ ||Fx ⊃ Ryx||𝔐, σ(x) = ②, σ(y) = ① = ||F ⊃ F||𝔐, σ(x) = ②, σ(y) = ① = T.
•	 So, we have:
•	 ||∃y(Fx ⊃ Ryx)||𝔐, σ(x) = ② = T.
•	 because ||Fx ⊃ Ryx||𝔐, σ(x) = ② = T for at least one variant with ||y|| = ① ∈ ⅅ.
7.1  ∞ Countermodels with Infinite Domains, ∏⧉∞

368
•	 There is, moreover, at least one temporary assignment variant for x, such that:
•	 ||∃y(Fx ⊃ Ryx)||𝔐, σ(x) = ② = T.
•	 Accordingly, we have determined for this model:
•	 |∃y(Fx ⊃ Ryx)|𝔐, σ = T.
7.1.4  Exercises
	1.	 Determine the values of the formulas within the given models in ∏⧉. The 
domain objects are all named. Generally, when it is not otherwise specified, 
∏⧉ is to be understood as comprising the narrower case of named-­
objects models.
	2.	 We construct a model in which a binary relational predicate R is both serial and 
transitivity. Notice the complementary graphical representation of the extension 
of the binary relation R. Constructibility of such a model shows that the two 
properties of relations (seriality and transitivity) are consistent with each other. 
We use the approach as in the case of unnamed objects, making temporary 
assignments to individual variables. Fill in the details as indicated.
Seriality: ∀x∃yRxy.
Transitivity: ∀x∀y∀z((Rxy ∙ Ryz) ⊃ Rxz).
𝔐 = <ⅅ = {○, ◻, ♢}, |R| = {<⎔, ◻>, <◻, ♢>, <♢, ♢>}>.
⎔⟶◻⟶♢⟲
	
a.	 First we show that R is serial. We make each possible assignment to x (assign-
ing an object in the domain) and it suffices to show that for each such assign-
ment of an object # there is at least one temporary assignment to y such that:
|| ∃yRxy||𝔐, σ(x) = # = T /.
for ○ being any object in the model’s domain.
	 I.	 ||x||𝔐, σ = ○
	
i.	 ||y||𝔐, σ = ○ ⤇
<||x||𝔐, σ(x) = ○, ||y||𝔐, σ(y) = ○ > ∉ |R|𝔐.
⤇ ||Rxy||𝔐, σ(x) = ○, σ(y) = ○ = F
	
ii.	 ||y||𝔐, σ = ____ ⤇ <_____, _____> ∈ |R|𝔐
⤇||Rxy||________ = _______
	
iii.	 ||y||𝔐, σ = ____ ⤇ <_____, _____> ∉ |R|𝔐
⤇||Rxy||________ = _______.
Decision: ||x||𝔐, σ = ○.
⤇ || ∃yRxy||𝔐, σ(x) = ○ = _____
	II.	 ||x||𝔐, σ = ◻ ⤇ ---
Decision: ||∃yRxy||𝔐, σ(x) = ◻ = ___
	III.	 ||x||𝔐, σ = ○ ⤇ ---
Decision: || ∃yRxy||𝔐, σ(x) = ♢ = ___
Decision: |∀x∃yRxy|𝔐 =?
7  Semantic Models for ∏: ∏⧉

369
	
b.	 Next, show that R is transitive. For each possible temporary assignment to x, 
we must show that each possible subsequent assignment to y is true. We 
assign, of course, ____________ to the variables by way of temporary 
assignments.
	
c.	 Did you show that R is both serial and transitive? Why does this suffice to 
show that a relation can consistently have both properties?
	
d.	 Does this suffice to show that having either property implies that the relation 
must also have the other property? What would we have to do to investigate 
such entailments?
	
e.	 Construct a model to show that reflexivity and non-seriality are mutually 
inconsistent properties of relations: it is not logically possible for a relation 
to be characterized by both properties. You are essentially asked to show that 
any model in which R is reflexive is a model in which R has to be serial. This 
suffices to show inconsistency. But also construct a model in which a rela-
tion R is serial but not reflexive.
Seriality: ∀x∃yRxy.
Reflexivity: ∀xRxx
	3.	 Construct countermodels for the given formulas in ∏⧉⌹. Attempt construc-
tion of models starting with the minimal cardinal number of the domain (which 
cannot be zero, but it is one) and ascend to larger cardinal number for the domain 
as needed.
	
a.	 ⊮∃xFx
	
b.	 ⊮∀x(Fx ⊃ Gx)
	
c.	 ⊮∀x∀y(Lxy ∙ ~ Lyx)
	
d.	 ⊮∃x∀yRyx ∙ ∃x∀y ~ Ryx
	
e.	 ⊮∃x∀y(Fy ≡ x = y)
	
f.	 ⊮∀x(x = a ⊃ a = f(x))
	
g.	 ⊮ ∃x∃y(Rfxfy ⊃ Rfyfx)
	4.	 Construct countermodels for the given argument forms in ∏⧉⌹.
	
a.	 ∀x(Fx ⊃ Gx), ∀x(Fx ⊃ Hx) ⊮∀x(Gx ⊃ Hx)
	
b.	 ∀x(Fx ⊃ Gx), ∃x(Gx ∙ Hx) ⊮ ∃x(Fx ∙ Hx)
	
c.	 ∀x(Fx ⊃ Gx), Ga ⊮ ∃xFx
	
d.	 ∀x∀y(x = y ∨ Rxy ∨ Ryx) ⊮ ∀xRxx
	
e.	 Rab, Rba ⊮ ∀x∀y(Rxy ∨ Ryx)
	
f.	 ∀x∀y(Rxy ⊃ Ryx), x∃yRxy ⊮ ∀xRxx
	
g.	 a = fb, Rab ⊮ Rbfb
	5.	 Construct metalogical proofs in ∏⧉⌹ (model with all named objects) and in 
∏⧉⌻ (model without all named objects) for the given formulas.
	
a.	 ∀x(Fx ⊃ Gx), ∀x(Fx ⊃ ~ Gx) ⊩ ∃x ~ Fx
	
b.	 Fa, ~ Fb ⊩ a ≠ b
	
c.	 Fa, ∀x(x = a ⊃ Gx) ⊩ ∃x(Fx ∙ Gx)
7.1  ∞ Countermodels with Infinite Domains, ∏⧉∞

370
	
d.	 a = b, ~ Rab ⊩ ~ ∀xRxx
	
e.	 ∃xFx, fa = b, Rba ⊩ ∃xRfaa
	
f.	 ∃y∀xRyx ⊩ ∀x∃yRyx
	
g.	 ∀x∀yRxy ⊩ ∀xRxx
	
h.	 ∀x(Fx ∨ ~ Fx) ⊩ ∀x∃y(x = y)
	6.	 Construct models that satisfy the given formulas in ∏⧉⌹ (models in which the 
formulas are true). Does this prove that the formula is a logical truth? What step 
ought to be taken subsequent to constructing a satisfying model to determine if 
the formula is or is not a logical truth?
	
a.	 ⊩ ∀x(Fx ⊃ Gx) ⊃ ∀xFx
	
b.	 ⊩ ∀xFx ⊃ Rab
	
c.	 ⊩ ∀xFx ⊃ ∃yRay
	
d.	 ⊩ (∀x(Fx ⊃ Gx) ∙ ∃x ~ Fx) ⊃ ∃x ~ Gx
	
e.	 ⊩ (∃xFx ∙ ∃xGx) ⊃ ∃x(Fx ∙ Gx)
	
f.	 ⊩ ~ ∃x(Fx ∙ Gx) ⊃ (∃x(~ Fx ∙ Hx) ∙ ∃x(Gx ∙ Hx))
	
g.	 ⊩ ∃xRfafbx ≡∀x∀y∀zRxyz
	
h.	 ⊩ ∀x∀y(x = y ⊃ (Rxy ∨ Ryx))
	7.	 Construct satisfying models for the given sets of formulas in ∏⧉⌹. Does suc-
cessful construction of such a model prove that the given set is consistent?
	
a.	 ⊩ {∀x∀yRxy, ∀x∀y(Rxy ⊃ ~ Ryx)}
	
b.	 ⊩ {∀x∀y∀z((Rxy ∙ Ryz) ⊃ Rxz), ∀x∀y((Rxy ∙ Ryx) ⊃ x = y)}
	
c.	 ⊩ {∀x ~ Rxx, ∀x∀y∀z((Rxy ∙ Ryz) ⊃ Rxz)}
	
d.	 ⊩ {Rfafb, ∃x∃y(Rxy ⊃ ((x ≠ fa) ∙(x ≠ fb))))}
	
e.	 ⊩ {~ ∃xFx, ∀xFx ≡ Rab}
	
f.	 ⊩ {∀x∀y((Fx ∙ Fy) ⊃ x = y), ∃x∀y(Fy ≡ x = y), ∃x∃yRxy}
	
g.	 ⊩ {Rab, Rbb, ~ ∃x∀yRxy}
	
h.	 ⊩ {∀x∀y∀z((Rxy ∙ Ryz) ⊃ Rxz), ∃xRxx, ∃x∀yRxy}
	8.	 Extract the prenex forms of the given well-formed formulas of ∏⧉.
Apply relettering when pulling quantifier symbols to the front, as indicated.
	
a.	 ∀x(Fx ∨ ∃yFy)
	
b.	 ∃yFy ⊃ ∀xDx
	
c.	 ∃x(Fx ∙ ∀y(Fy ⊃ y = x))
	
d.	 ∀xFx ≡ ∀xGx	
[consider: (φ ≡ ψ) ≡ ((φ ⊃ ψ) ∙ (ψ ⊃ φ))]
	
e.	 ∀z(∃xRxz ⊃ ∃wRzw)
	
f.	 ∃x(∃yGyx ⊃ ∀zRxz)
	
g.	 ∀xFx ∨ ∀y(fy = a)
	9.	 Construction of models gives us a means for checking if any one of a given num-
ber of formulas is, as we call it, independent of the others: this means that the 
specified formula φ cannot be proven by all the other formulas that are given. 
This is crucial in establishing that an axiom, from a given set of axioms, is inde-
pendent and, hence, indispensable in the axiomatization of a system. The way to 
7  Semantic Models for ∏: ∏⧉

371
prove independence of φ from, for instance, {ψ, χ, ζ} consists in constructing a 
model in which all of {ψ, χ, ζ} are true but φ is false. Given the definition of the 
concept of validity, we establish in this way that φ is indeed independent of the 
rest (it cannot be proven from them.) It is thus proven that IND[φ, {ψ, χ, ζ}]. 
Construct models to prove independence as requested below.
	
a.	 Independence of transitivity from weak connectivity (these are properties of 
relations):
IND[∀x∀y∀z((Rxy ∙ Ryz) ⊃ Rxz), {∀x∀y(Rxy ∨ Ryx)}]
	
b.	 Independence of seriality from transitivity:
IND[∀x∃yRxy, {∀x∀y∀z((Rxy ∙ Ryz) ⊃ Rxz)}]
	
c.	 Independence of asymmetry from transitivity:
IND[∀x∀y((Rxy ∙ Ryx) ⊃ x = y), {∀x∀y∀z((Rxy ∙ Ryz) ⊃ Rxz)}]
	
d.	 Independence of reflexivity from transitivity:
IND[∀xRxx, {∀x∀y∀z((Rxy ∙ Ryz) ⊃ Rxz)}]
	
e.	 Independence of the Euclidean property from non-identical seriality:
IND(∀x∀y∀z[(Rxy ∙ Rxz) ⊃ Ryz, {∀x∃y(x ≠ y ∙ Rxy)}].
7.1  ∞ Countermodels with Infinite Domains, ∏⧉∞

373
© The Author(s), under exclusive license to Springer Nature 
Switzerland AG 2022
O. Makridis, Symbolic Logic, Palgrave Philosophy Today, 
https://doi.org/10.1007/978-3-030-67396-3_8
Chapter 8
Proof-Theoretical System for Predicate 
Logic: ∏πφ=
KeyWords  Proof-Theoretical System for Predicate LogicRestrictions for Predicate 
Logic Proof-Theoretical SystemTree System for Predicate LogicIntuitionistic Logic.
8.1  A System of Natural Deduction for ∏πφ=: ∏πφ=∎
To obtain a formal proof-theoretic system for natural deduction, we may extend any one 
of the formal systems we deployed for sentential logic. To avoid expansive use of space 
in this text, we present a system that extends ∑∎ with appropriate additions of symbolic 
resources and regulative schematic rules for derivation, so that we generate ∏πφ=∎. The 
Fitch-style proof-theoretic system for natural language, ∑||, which we have also con-
structed can be expanded accordingly – and the same is the case for the sequent system.
First, we lay out the symbols and grammatical arrangements for well-­formedness 
(what counts as a well-formed or grammatically correct formula in the system) for 
∏πφ=∎, adding to the preexisting resources and applying the syntactical arrange-
ments to the newly introduced symbols.
•	 p, q, …, pi, … ∊ WFF(∏πφ=∎)	
	
i ∊ {x: x is a positive integer}
•	 If φ ∊ WFF(∏πφ=∎), then ~ φ ∊ WFF(∏πφ=∎)
•	 If φ1 ∊ WFF(∏πφ=∎) and φ2 ∊ WFF(∏πφ=∎), then φ1 ∙ φ2 ∊ WFF(∏πφ=∎)
•	 If φ1 ∊ WFF(∏πφ=∎) and φ2 ∊ WFF(∏πφ=∎), then φ1 ∨ φ2 ∊ WFF(∏πφ=∎)
•	 If φ1 ∊ WFF(∏πφ=∎) and φ2 ∊ WFF(∏πφ=∎), then φ1 ⊃ φ2 ∊ WFF(∏πφ=∎)
•	 If φ1 ∊ WFF(∏πφ=∎) and φ2 ∊ WFF(∏πφ=∎), then φ1 ≡ φ2 ∊ WFF(∏πφ=∎)
•	 Fjλ1… λn ∊ WFF(∏πφ=∎) / λ1, …, λn ∊ TERMS(∏πφ=∎), Fj ∊ 
PREDICATES(∏πφ=∎)
(continued)

374
All the derivation rule schemata of ∑∎ are included in the proof-theoretic system 
∏πφ=∎; rules for the added symbols. The predicate symbols are non-logical constants; 
constraining them with postulates as to how specific such symbols may be manipu-
lated would constitute an extra-logical maneuver. Notably, and as it ought to be 
expected, there can be no replacement of predicate symbols by other predicate sym-
bols. Thinking in terms of the semantics (models) for predicate logic, we can appreci-
ate that the extension of a predicate (the members of the set that defines the meaning 
of the predicate symbol in the model) is a non-logical happenstance: another model 
can be constructed by open-ended license, in which separate model the same predi-
cate symbol can be given a different extension. Of course, since what we are dealing 
with is predicate or first-order logic (and not second-order logic), we have no quanti-
fication symbols over predicate symbols; semantically speaking, we cannot produce 
a model, for instance, for inferring that “at least one color is bright” from “green is a 
bright color.” It follows, again, that we cannot produce predicate symbols – any more 
than we can inter-substitute them. The quantifier symbols are the logical symbols that 
have been added. Moreover, the identity symbol is distinguished as a logical symbol: 
it may be noticed that identity could be understood as a binary or two-place relation; 
but the identity symbol is the only relational symbol whose regulated schematic man-
agement is not a matter of extra-logical stipulation but it is considered that we are 
actually dealing with a logical symbol for which we must provide schematic rules. If 
we think of a finite domain, we can define the universal quantifier symbol as a con-
junction (with all x F as logically equivalent with the conjunction of Fλi for each term 
λi which semantically thinking represents the name of a member of the domain. 
Similarly, the existential quantifier can be defined as an inclusive disjunction of Fλi 
for each term λi. Given this, the quantifier symbols are determinately related and can 
inter-converted: this is obvious once we apply the DeMorgan Laws, which we have 
included in their expressions as rule schemata in ∑∎ and by extension in ∏πφ=∎:
•	 ∀xFx ≡ (Fa ∙ … ∙ Fm) ≡ ~ (~ Fa ∨ … ∨ ~ Fm) ≡ ~ ∃x ~ Fx
•	 ~ ∀xFx ≡ ~ (Fa ∙ … ∙ Fm) ≡ (~ Fa ∨ … ∨ ~ Fm) ≡ ∃x ~ Fx
•	 ~ ∃xFx ≡ ~ (Fa ∨ … ∨ Fm) ≡ (~ Fa ∙ … ∙ ~ Fm) ≡ ∀x ~ Fx
•	 ∃xFx ≡ (Fa ∨ … ∨ Fm) ≡ ~ (~ Fa ∙ … ∙ ~ Fm) ≡ ∀xFx
This observation suggests adding schematic rules for the interconvertibility 
(exchange, interchange) of the quantifier symbols, as a matter of convenience even 
though our other rules for derivation ought to be sufficient for deriving the conver-
sion instances.
We provide the terms of introduction and elimination of the quantifier symbols. 
This hints at the mechanics of the Fitch-like system we examined as ∑||, which can 
(continued)
•	 If φ ∊ WFF(∏πφ=∎), then ∀uφ ∊ WFF(∏πφ=∎) / u ∊ VARIABLES(∏πφ=∎)
•	 If φ ∊ WFF(∏πφ=∎), then ∃uφ ∊ WFF(∏πφ=∎) / u ∊ VARIABLES(∏πφ=∎)
•	 If λi ∊ TERMS(∏πφ=∎) and λj ∊ WFF(∏πφ=∎), then λi = λj ∊ WFF(∏πφ=∎)
•	 fjλ1… λn ∊ WFF(∏πφ=∎) / λ1, …, λn ∊ TERMS(∏πφ=∎), fj ∊ TERMS(∏πφ=∎)
•	 Nothing else is a member of the set WFF(∏πφ=∎) -- <closure clause>
8  Proof-Theoretical System for Predicate Logic: ∏πφ=

375
be extended as ∏πφ=||. Other nomenclature names available to us are “generaliza-
tion” and “instantiation.” We indicate those terms as well while we lay down the 
rule schemata. We will subsequently address appropriate restrictions that must be in 
place, including restrictions that regulate the order in which quantifier symbols may 
be introduced and elimination when the quantifier symbols are nested – quantifier 
symbols lie within the scope or scopes of other quantifier symbol or symbols.
8.1.1  ∃I: Rule for Introduction of the Existential Quantifier 
Symbol (Existential Generalization) 
The same rule, for which important constraints apply, as we will specify, can also 
be presented with a shape that presents a well formed formula and regulates how the 
existential quantifier symbol may be attached to it: the variable x of the quantifier 
∃x is to replace uniformly an individual constant letter in the formula. 
The definability of the existential quantifier in terms of inclusive disjunction over 
a finite domain allows us to justify this rule as follows considering a domain {b1, …, 
bn}. We use the familiar proof-theoretical rule of Addition.
	1.	 Fbi	
	
	
	
1      bi ∊ {b1, …, bn}
	2.	 Fb1 ∨ Fbi	
	
	
Add(1)
	3.	 …
	4.	 Fb1 ∨ … ∨ Fbi ∨ … ∨ Fbn	
Add(3)
	5.	 ∃xFx		
	
	
definition(∃)(4)
Constraints:
	1.	 the variable letter that replaces the term letter must replace uniformly all occur-
rences of the term letter;
	2.	 no other quantifier symbol should be binding the term letter.
Failure to observe the restrictions would permit derivations that correspond to 
arguments forms for which we can make the case readily that they are invalid (in 
their semantic interpretation.) This tweaking of derivation rules by looking askance 
k. ℱ…λ…	
	
λ ∊ CONSTANTS / ℱ ∊ PREDICATES
⋮
n. ∃x…ℱx…	 	
	
	
	
 ∃I(k)
k. □	 	
	
occurrence of constant letter λ in □
⋮
n. ∃x□ [x/λ]	 	
	
	
∃I(k)
8.1  A System of Natural Deduction for ∏πφ=: ∏πφ=∎

376
at what incorrect derivations may be allowed to go through is common in the case 
of constructing formal systems for predicate logic. This is not a deviation from the 
abstractly general and non-empirical character of deductive logic: the consider-
ations that enter into the rules are formal, they are not related to any putative mean-
ings for non-logical symbols like predicate symbols, but they are dictated, instead, 
by considerations of validity that themselves follow from observing the meanings of 
logical symbols. We note an additional rule that we need to have available to use, 
which follows from the grammatical arrangements for our formal system. This rule 
regulates removal of reiterated quantifier symbols that are rendered vacuous (failing 
to bind letters that are free before they are bound.) We designate this rule by “QQ” 
where “Q” is a universal or existential quantifier symbol.
	1.	 Laa 	 	
	
1
	2.	 ∃xLax	
	
∃I(1)	
== ERROR – violation of constraint 1
	3.	 ∃x∃yLyx	
	
∃I(2)	
== this must be wrong!
We should not be able to infer from “Federico likes himself” that “someone likes 
someone” which include the possibility not only that someone likes himself or her-
self but also that someone likes someone else (which we have no license to infer 
from the given premise that is only about someone liking himself or herself.)
	1.	 Rab	 	
	
1
	2.	 ∃xRax	
	
∃I(1)
	3.	 ∃x∃xRxx	
	
∃I(2)	
==ERROR! – violation of constraint 2
	4.	 ∃xRxx	
	
∃∃(3)	
==! -- this is certainly wrong!
	5.	 ∃y∃xRyx	
	
∃I(2)	
== CORRECT – constraint 2 is observed
We should not be able to infer, for example, from “Sue is to the left of Sam” that 
“something is to its own left.”
8.1.2  ∀I: Rule for Introduction of the Universal Quantifier 
Symbol (Universal Generalization)
The basic idea is that the constant that is to be uniformly replaced by the quanti-
fier variable is random: if we have proof or asserted verification that F is true of an 
object that has not been selected for any reason whatsoever but is any random item – 
and is presumed specifically to be any item – then we may correctly infer that F is 
true of any object: hence, we can introduce the universal quantifier symbol.
The definability of the universal quantifier in terms of conjunction over a finite 
domain allows us to justify this rule as follows considering a domain {b1, …, bn}. 
k. ℱ…λ…	
λ ∊ CONSTANTS and λ is a random constant letter
⋮
n. ∀xℱ…x… [x/λ]	
	
	
	
	
∀I(k)
8  Proof-Theoretical System for Predicate Logic: ∏πφ=

377
We use the familiar rule we have in our natural deduction system, which we have 
named Conjunction.
	1.	 Fbi	
1	
generic constant symbol: it could be any constant symbol
	2.	 Fb1	
2	
since it can be any constant symbol
	3.	 …
	4.	 Fbn	
	
	
n+1
	5.	 Fb1 ∙ … ∙ Fbn	
	
∙I(2, …, n+1)
	6.	 ∀xFx	
	
	
definition(∀)(5)
Alternatively, the schema may be as follows – with both schematic shapes sanc-
tioning the same derivations as correct.
Constraints:
	1.	 the letter λ that is replaced by the variable in ∀x does not occur free in any line 
of the proof, on which ℱ… λ… depends.
	2.	 every occurrence of λ in ℱ… λ… must be replaced uniformly by the vari-
able in ∀x.
8.1.3  ∀E: Rule for Elimination of the Universal Quantifier 
Symbol (Universal Instantiation)
The definability of the universal quantifier in terms of conjunction over a finite 
domain allows us to justify this rule as follows considering a domain {b1, …, bn}. 
The rule we need to use is simplification.
	1.	 ∀xFx		
	
	
1
	2.	 Fb1 ∙ … ∙ Fbn	 	
	
definition(∀)(1)
	3.	 Fbi	
	
	
	
S(2)	
	
-- any bi ∊ (b1, …, bn)
k. □	 	
	
occurrence of random constant letter λ in □
⋮
n. ∀x□	
[x/λ]	
	
	
	
	
     ∀I(k)
k. ∀xℱ…x…
⋮
n. ℱ…λ…	
[λ/x]	
	
 ∀E(k)	 λ is any constant letter
8.1  A System of Natural Deduction for ∏πφ=: ∏πφ=∎

378
Alternatively, we can present as the schema for ∀E: 
Constraints:
	1.	 every occurrence of the variable in ∀xℱ…x… must be replaced uniformly by the 
same letter in ℱ… λ….
Violation of the restriction would permit for erroneous derivations to go through.
	1.	 ∀xLxx
	2.	 Lab	 	
∀E(1) WRONG! [violation of restriction 1]
Certainly, we should not be able to infer from “all people like themselves” that 
“Abe likes Beth.”
8.1.4  ∃E: Rule for Elimination of the Existential Quantifier 
Symbol (Existential Generalization)
The definability of the existential quantifier in terms of inclusive disjunction over 
a finite domain allows us to justify a rule as follows considering a domain {b1, …, 
bn}. Here we will need to draw on the proof-theoretic rule of constructive dilemma 
or, as we called it in the Fitch-style system, disjunction elimination. This depen-
dence suggests that there is another way of presenting the schema for elimination of 
the existential quantifier symbol, which is to be found in many texts. We present this 
alternative schematization although we do not implement it in our system.
	 1.	 ∃xFx	
	
	
	
1
	 2.	 Fb1 ∨ … ∨ Fbn	
	
	
definition(∃)(1)
	 3.	 Fb1	 	
	
	
	
3−
	 4.	 …
	 5.	 □
	 6.	 Fb2
k. ∀x□.
⋮
n. □	 [λ/x]	
	
	
∀E(k)	
λ is any term letter
k. ∃xℱ…x…
⋮
n. ℱ… λ… [λ/x]	
	
	
 ∃E(k)	 λ is a new letter
8  Proof-Theoretical System for Predicate Logic: ∏πφ=

379
	 7.	 …
	 8.	 □
	 9.	 …
	10.	 Fbn	 	
	
	
	
10−
	11.	 …
	12.	 □
	13.	 □	 	
	
	
	
∨E(2, 3–5, 6–8, …, 10–12) 
As with the implementation of the rule for elimination of the inclusive disjunc-
tion symbol in the Fitch-style proof-theoretic system we studied, subordinate proofs 
are arranged for each of the formulas of the predicate letter along with each of the 
constant letters, since, by definition, the existential quantifier symbol is taken as a 
finite inclusive disjunction. Each subproof yields, when completed, a formula; the 
outcome of the derivation, by application of the elimination rule, is the formula that 
has accrued in the subproofs. The completion of the derivation means that, by appli-
cation of the elimination rule, the assumed premised for all the subproofs are dis-
charged. Adopting this as our rule for elimination of the existential quantifier symbol 
results in more cumbersome derivations but it benefits from showcasing the deep 
theoretical affinity with the derivation rule for the corresponding logical connec-
tive – inclusive disjunction. If, as an exercise, the extension of the Fitch-like system 
we have constructed is undertaken, it would be elegant and appropriate to adopt this 
schematic shape for the rule for elimination of the existential quantifier symbol. 
Instead, we opt for the less elaborate schema we presented above. As a justification, 
by reference to rules for the logical connective of inclusive disjunction, we may 
appeal to the rule we included in the formal system for natural deduction, which we 
call Disjunctive Syllogism.
k. ∃xℱx.
k+1. ℱλ1 ∨ ℱλ2 ∨ … ∨ ℱλn
⋮
	
| ℱλ1	
λ is a constant letter
	
| ⋮
	
| □
	
| ℱλ2
	
| ⋮
	
| □
	
| ⋮
	
| ℱλn.
	
| ⋮
	
| □
n. □	
	
∃E(k, −--)
8.1  A System of Natural Deduction for ∏πφ=: ∏πφ=∎

380
	1.	 ∃xFx		
	
	
	
1
	2.	 Fb1 ∨ Fb2 ∨ … ∨ Fbi ∨ … ∨ Fbn		
definition(∃)(1) == at least one is true
	3.	 ~ Fbi		
	
	
 	
3 == presuming verification for bi
	4.	 Fb1 ∨ Fb2 ∨ … ∨ Fbn ∨ Fbi	
	
Assoc(∨)n-i(3)
	5.	 Fb1 ∨ Fb2 ∨ … ∨ Fbn	
	
	
DS(4, 5)
	6.	 …
	7.	 Fbj	
	
	
	
	
DS(…)
Let us analyze this proof. This is a schematic proof sketch and should be properly 
written – even if pedantically – with metalinguistic symbols. On line 4, we indicate 
that multiple applications of association (with the accompanying parentheses, not 
shown, used for grouping and indications of shifting) and subsequently we apply 
the rule of Disjunctive Syllogism. This continues for all disjuncts that are verifiably 
false until one disjunct remains. The point is not to privilege an irrelevant epistemic 
test about what we know verifiably about the disjuncts. The point is rather to show 
how at least one disjunct is true as other disjuncts may turn out to be false. The affin-
ity with rules for inclusive disjunction is evident in the crucial application of the DS 
rule. Since this is not about verification, the disjunct that is presumed true at the end 
(as being at least one disjunct that is true) has to be understood as being a specific 
but unknown disjunct. This consideration dictates the specific constraint on applica-
tion of this rule: that the constant letter that is used for implementation of the rule 
for elimination of the existential quantification symbol is a new symbol, not in the 
proof up at that point.
It is philosophically important that, in proceeding in this fashion, we consider 
this rule to yield at least one true disjunct regardless as to whether our constructive 
proof-theoretic arrangements can specify the disjunct or present specific conditions 
under which this disjunct could be verified as being true: this is a deep characteristic 
of the standard logic (and the standard predicate logic), which would have to be 
absent from an alternative logic – one like the logic we have called Intuitionistic as 
we have briefly examined it – which understands commitments to asserting as true 
to depend strictly on the actual availability of a constructive method for producing 
and verifying the formula that is said to be true.
Alternatively, the schema may be as follows – with both schematic shapes sanc-
tioning the same derivations as correct.
Constraints:
	1.	 the letter that is introduced can be distinguished by use of a technical name, 
found in the literature sometimes, as an eigenparameter: it is a new letter that 
k. ∃x□.
⋮
n. □	 [λ/x]	
	
	
∃E(k)	
	
λ is a new term letter
8  Proof-Theoretical System for Predicate Logic: ∏πφ=

381
does not occur on any line of the proof; in the justification line, the introduction 
of the eigeneparameter can be marked by use of a superscript “ℇ” on the term 
letter that is the new or eigenparameter letter.
	2.	 the replacement of the variable letter by the eigenparameter letter is uniform 
throughout the formula that is the matrix of the existential quantifier symbol.
8.1.5  # Restrictions for Introduction and Elimination 
of Nested Quantifier Symbols
•	 Baseline Restriction: Uniform Replacement: It is understood, in accordance with 
the rules that have been laid out for the basic arrangements for introduction and 
elimination rules, that all variables letters are uniformly replaced with a constant 
letter upon elimination and similarly for introduction the same variable letter 
replaces all occurrences of the removed constant letter.
•	 Restriction 1: Quantifier symbols are eliminated from left to right – or from outer 
to inner scope, or from broader to narrower scope.
•	 Failure to observe this rule would permit the following pseudo-proof to be com-
pleted and presumed correct: definitely, however, the argument form that would 
be validated – in the corresponding semantic system – cannot be valid: for exam-
ple, we should not be able to infer from “everyone like someone” that “someone 
likes himself or herself”.
	1.	 ∀x∃yLxy	
	
	
1
	2.	 ∀xLxa	
	
	
∃E(1)==ERROR!== violation of restriction 1
	3.	 Laa	 	
	
	
∀E(2)
	4.	 ∃xLxx	
	
	
∃I(3)
There are no other errors in the preceding spurious proof – so considered because 
of the error in the derivation of line 2. The error consists in violation of the ­restriction 
we have imposed: the elimination of quantifier symbols commences from the right 
or from the narrower scope quantifier symbol for this formula with nested quantifier 
symbols. The next line is correctly derived: the variable for the existential quantifier 
elimination, which is the eigenparameter, can be used for the elimination of the 
universal quantifier symbol; finally, derivation of the last line is also correct since 
we apply the existential quantifier symbol introduction (not the universal quantifier 
symbol introduction, since the constant, which is an eigenparameter, was obtained 
by existential quantifier symbol elimination.) Thus, the only error, resulting in deri-
vation of a conclusion that is not correctly derivable, is in deriving line 2.
Let us notice that no similar error results in proceeding from inner to outer or 
from narrower to broader scope in the elimination of quantifier symbols. What is 
derived here is not objectionable: from “someone likes everyone” we indeed expect 
to derive “someone likes himself or herself” since some person – at least one – who 
likes everyone ought also to like herself or himself.
8.1  A System of Natural Deduction for ∏πφ=: ∏πφ=∎

382
	1.	 ∃x∀yLxy	
	
1
	2.	 ∀yLay	
	
∃E(1)
	3.	 Laa	 	
	
∀E(2)
	4.	 ∃xLxx	
	
∃I(3)
Returning to the initial example, of the pseudoproof, and executing the moves 
without violations of restrictions, we arrive at a conclusion that ought to be correctly 
derivable: given that “everyone like someone” we should be able to infer correctly 
that “someone loves herself or himself” only on the additional assumption that there 
is exactly one person in the discourse (which is provided by the second given prem-
ise that states that all names or constant letters co-refer.)
	1.	 ∀x∃yLxy	
	
1
	2.	 ∀x∀y(x = y)	
	
2
	3.	 ∃yLay	
	
∀E(2)
	4.	 Lab	 	
	
∃E(3)	
--CORRECT—an eigenparameter (new con-
stant letter) is used for elimination of the existential quantifier symbol
	5.	 ∀y(a = y)	
	
∀E(4)
	6.	 a = b		
	
∀E(5)
	7.	 Laa	 	
	
=E(4, 6)
	8.	 ∃xLxx	
	
∃I(7)
Ö
Ö Restriction 2: Quantifier symbols are introduced from right to left.
Ö
Ö Restriction 3: Banning Vacuous Quantification: We enforce a restriction that also 
made sense when we contemplated and structured the syntactical or grammatical 
setup for a predicate logic system. We ban vacuous quantification in a broad 
sense, defined as: a) having a quantifier symbol that has no variable to bind, or b) 
as a (vacuously) iterated quantifier attempting to re-bind a variable that is bound 
by another quantifier of the same kind (universal or existential.) Given this 
exception, the following proof is blocked, as it should be.
Ö
Ö Restriction 4: Main-Connective Restriction. Regardless as to whether we treat 
quantifiers as connectives or not – based on considerations about the cardinality 
of the domain, if it is finite or not – we impose a restriction that is worth institu-
tionalizing. We set it as a restriction, which we call the Main-Connective 
Restriction. This prohibits making replacements of variables bound by quantifi-
ers when the formula has a main connective other than the quantifier (assuming 
that we are thinking of the quantifier as a connective.) A corollary of this restric-
tion, which also imposes a relevant restriction: no elimination of quantifier sym-
bol is permitted when the quantifier symbol does not have in its scope all the 
occurrences of the variable of the quantifier symbol. (For instance: in ⌜∀xFx ⊃ 
∃xGx⌝ elimination can lead to the pseudo-derivation (incorrect derivation) of 
⌜∀xFx ⊃ Ga⌝, succeeded by ⌜Fa ⊃ Ga⌝ and then ⌜∃x(Fx ⊃ Gx)⌝: this is patently 
incorrect as we can see from an interpreted instantiation: from “if everyone is 
saved, then there is a savior” we could infer that “there is someone who, if he or 
she is saved then he or she is a savior.”
8  Proof-Theoretical System for Predicate Logic: ∏πφ=

383
Ö
Ö Restriction 5: For consecutively iterated or nested existential quantifier symbols 
that are introduced, different variable symbols must be attached to the introduced 
existential quantifiers.
Ö
Ö Restriction 6: New Constant Trumps Arbitrary Constant. If the same constant 
variable is available in the proof both as arbitrary and new, it is to be considered 
as new for purposes of making further moves in the proof process. This dual 
availability of the same constant letter can easily happen. For instance, existen-
tial quantifier elimination could yield a new constant, λ, and that same constant 
can subsequently be obtained by applying universal quantifier elimination. This 
is permissible since the new constant is certainly one of the names labeling some 
object in the domain; by eliminating the universal quantifier, we may use any 
constant or name – this is what “arbitrary” means in this context – and, so, we 
can use λ. Nevertheless, the character of the constant λ, so to speak, is stamped 
by the mode of its generation, which makes it a new constant. This means, for 
instance, that we cannot appeal to the presence of λ to introduce a universal 
quantifier: even though λ has also been generated by universal elimination, it 
remains “genetically” the case that its character is that of a new constant  – 
because “new trumps arbitrary” – and it cannot be appealed to for introduction of 
universal quantification.
Semantically speaking, let us consider the following example. Every student 
takes classes – which we read in our formalism as “for everything, if it is a student, 
then it takes classes.” Jill is student. The name “Jill” corresponds in a linguistic 
context to what we designate as a new constant. We can infer validly, by elimination 
of the universal quantifier, that if Jill is a student, then she takes classes. And we 
have the premise according to which Jill is a student. Therefore, it is a valid infer-
ence to make that “Jill takes classes.” If we could generalize, by treating “Jill” as an 
arbitrary name, we would derive “everyone takes classes”, which is clearly an 
invalid inference. We can, however, validly infer that “at least one person take 
classes” because introduction of the existential quantifier is sanctioned on the basis 
of a new constant (like the name “Jill” in our example.) (We have been assuming 
throughout restricted domain to persons.)
Ö
Ö Restriction 7: We always treat a given constant as a new letter or eigenparameter. 
We impose a restriction to the effect that any given constant in a formula is to be 
treated not as arbitrary but as new. Indeed, we should not be able to infer validly 
from “Jill is a student” to “everyone is a student;” if we treated the name “Jill” is 
arbitrary, however, nothing could prevent an inference to the universally quanti-
fied statement given the rules we have presented.
Failure to observe this restriction is in evidence in the following fallacious proof.
	1.	 ∀x(Fx ⊃ Gx)	 P
	2.	 Fa	
	
P/.. ∀xGx
	3.	 Fa	
	
3−	
 – positing as arbitrary letter for CP 
WRONG! [violation of Restriction 7]
	4.	 Fa ⊃ Ga	
	
∀E(1)
8.1  A System of Natural Deduction for ∏πφ=: ∏πφ=∎

384
	5.	 Ga	
	
Modus Ponens (3, 4)
	6.	 ∀xGx	
	
∀I(5)
	7.	 Fa ⊃ ∀xGx	
CP(30–6)
Ö
Ö Conditional Proof (CP) Restriction. Any posited formula (or assumed premise) 
has to contain what is considered a new constant or eigenparameter; not an arbi-
trary constant letter setting up for introduction of universal quantifier symbol.
Otherwise, the following fallacious proof of a presumed tautology (empty-­
premise set sequent) would have to be accepted.
1. Fa	
1−	
WRONG! [violation of CP Restriction]
2. ∀xFx	
∀I(1)
3. Fa ⊃ ∀xFx	 CP(10–2)
It is certainly wrong to infer, for instance, that everyone is a philosopher from the 
premise that states that Anaximander is a philosopher.
8.1.6  Rules for Interchange of the Quantifier Symbols 
(Replacement Rule) 
8.1.7  =I: Rule for Introduction of the Identity Symbol
The identity symbol is treated as a distinguished logical symbol, notwithstanding 
the apparent conceptual affinity of identity with a binary predicate. Unlike any other 
predicate symbol, the identity symbol is regulated by logical rules; it is not available 
to management by rules that, if implemented, would have to be extra-logical postu-
lates about meaning. We can actually start with this last point in justifying this 
exceptionalist treatment of identity. Since proof-theoretical philosophical-logical 
considerations take the meanings of logical symbols to be defined by their deriva-
tional rules, we can make the case that the rules for the identity symbol are them-
selves logical and, therefore, the symbol itself is a logical symbol.
The introduction rule for the identity symbol allows that a line can be inserted at 
any point in a proof, expressing that any term symbol is identical with itself. The 
term symbols ought to be specifically constant or function symbols. For variable 
symbols, joining an occurrence of a variable with another occurrence of the same 
variable by infixing the identity symbol in between would produce an open sen-
tence; on the other hand, binding the variable to produce a sentence would mean 
∀x□ ⊣⊢~ ∃x ~ □	
	
	
∀~∃~
~ ∀x□ ⊣⊢ ∃x ~ □	
	
	
~∀∃~
~ ∃x□ ⊣⊢∀x ~ □	
	
	
~∃∀~
∃x□ ⊣⊢ ~ ∀x ~ □ 	
	
	
∃~∀~
8  Proof-Theoretical System for Predicate Logic: ∏πφ=

385
that we allow ⌜∀x(x = x)⌝ as insertable by the identity introduction rule. This for-
mula, however, is derivable from the identity rule, as restricted to constant and func-
tion symbols, and by subsequent application of the ∀I rule: for any random constant 
or function symbol, we can use the identity introduction rule and then use ∀I since 
the randomness of the constant or function letter allows use of ∀I as we know. The 
rule is not applied on any line; the line is insertable at any point: as a self-justifying 
line, this is akin to a given premise and this is, accordingly, indicated in the justifica-
tion line by marking the line numeral, as we do with given premises in this formal 
system.  
8.1.8  =E: Rule for Elimination of the Identity Symbol
The elimination rule for the identity symbol gives as a schematic shape that is like 
one for inter-substitutivity of equivalents: indeed, since the meaning of a constant or 
function symbol (to think semantically for a moment) is the referent of the symbol, 
identity of the symbols means that we have the same referent and, hence, the same 
logical meaning. For the elimination rule for the identity symbol, the rule schema 
permits replacement of any letter by any other letter that is identical with the given 
letter within the matrix of a predicate symbol or a function symbol. Accordingly, 
alternative rule schemata can be presented, both of which result in the same results 
in implementation on proofs.  
8.1.9  Rules for Function Symbols
Function symbols are terms in the predicate logic system. They are not logical sym-
bols and the rules that can be provided for management of this symbolic resource 
capitalize on the type of symbol this is (given that it is a fixed matter what type of 
symbol the function symbol is); and on how identity, which is a logical symbol, 
⋮
n. λ = λ	
	
=I n 	
 λ is a constant or function symbol
k. λi = λj	
	
	
λi, λi are constant or function letters
⋮
n. ℱ…λi…
n+1.	 ℱ…λj…		
=E(k, n)
⋮
u. ℱ…λj…
u+1.	 ℱ…λi…		
=E(k, u)
8.1  A System of Natural Deduction for ∏πφ=: ∏πφ=∎

386
applies – in which case the identity rules that have been provided ought to be suffi-
cient already for regulation of how to play with function symbols but the related, 
and redundant, function rule may be provided anyway for the sake of convenience. 
Regarding the type of the symbol, rules for elimination and introduction may be 
provided in such a way as to respect the function symbol’s type as a term (and spe-
cifically a constant) but also, importantly, to place appropriate constraints that 
observe that functional symbols require, by definition, unique outputs for specified 
inputs: since it is a term, the function symbol may be eliminated as replaced by a 
unique constant symbol: accordingly, the constant symbol used to replace the func-
tion symbol must be new, not occurring at any point in the proof and not available 
subsequently except for universal instantiations (eliminations.) The introduction 
rule for a function symbol ought to be so established as to stipulate that the function 
symbol may replace an individual constant under the proviso that the constant 
occurs uniquely in all relational predicate symbols in which it occurs along with 
other term symbols. Since the existential assumption is trivial for constant terms in 
the standard predicate logic, we do no need to impose an existential constraint in 
addition to the uniqueness constraint.
Accordingly, applications of universal and existential elimination rules with 
matrices that are formulas with function symbols ought to be treated as compound 
quantifier-function rules. 
provided that λ is unique or identical with any other terms for which the function 
symbol is also substitutable.
Failure to observe the uniqueness constraint results in error as illustrated by the 
following pseudo-proof in which presumably we have a derivation from “every-
thing is the origin of b” to the putative conclusion “b is the origin of everything.” If 
we symbolize and attempt to carry out the proof by using relational predicate sym-
bols, the proof does not go through, as it should not. But the pseudo-proof provided 
below succeeds, erroneously, because it fails to observe the uniqueness constraint. 
In the first pseudo-proof, this is in evidence in failing to identify all the constants 
with one other, as it ought to be done considering that they are all presented as out-
puts of the same function. In the second pseudo-proof, which is by indirect proof or 
reductio, the violation is in evidence in that as shown by the fact that more than one 
applications of elimination of the function symbol take place instantiating to differ-
ent constant terms (of which it is not stipulated that they are equal to one another.) 
k. □	
	
	
fλ1…λm occurs in □
⋮
l. □ [λn / fλ1…λm]	
	
	
	
	
fE
provided that λn is identical with the output and unique.
k. □	
	
	
	
	
λn occurs in □
⋮
l. □ [fλ1…λm / λn]	
	
	
fI
8  Proof-Theoretical System for Predicate Logic: ∏πφ=

387
Note, based on how we have discussed formalization of uniqueness, we determine 
the correct application of the universal quantifier introduction rule in the presence 
of the function symbol.
1st Pseudo-Proof
	1.	∀x(x = fb)	
1
	2.	b = fb	
∀E(1)
	3.	∀x(b = fx)	
∀I(2)	
ERROR!
	4.	∀x((b = fx) ⊃ ∀y((y = fx) ≡ (y = x)))	
∀I-fI(2)	
CORRECT
2nd Pseudo-Proof
	1.	∀x(x = fb)	
1
	2.	~ ∀x(b = fx)	
2−
	3.	∃x ~ (b = fx)	
~∀∃~(2)
	4.	∃x(b ≠ fx)	
≠/~=(3)
	5.	b ≠ fc	
∃E(4)
	6.	b = fb	
∀E(1)
	7.	fc = fb	
∀E(1)	
ERROR! –
	8.	b = fc	
=E(6, 7)
	9.	∀x(b = fx)	
RAA(2–8)	
!
	10.	(fc = fb) ≡ (fc = b)	
∀E(1)	
CORRECT
8.1.10  Intuitionistic versus Classical Predicate Logic
Although we cannot expatiate on this interesting subject, we can still briefly draw 
contrasts between intuitionistic versus classical sentential logic, as we did in earlier 
section with respect to sentential logic. Predicate logics extend sentential logics; 
accordingly, the meanings of the connective symbols for intuitionistic logic are the 
same as those for intuitionistic sentential logic. The crucial question that arises is 
how intuitionistic quantifier symbols definitions are to differ from the correspond-
ing ones for the classical predicate logic. Intuitionistic logic understands truth as 
constructive actual verification by means of an available proof: this means that, if 
for instance we are dealing with an infinite domain like that of the natural numbers, 
we may have a proof that it is not the case that all numbers possess property F and 
yet be unable to produce a specific case in which we prove that some number lacks 
this property F: therefore, the inference from ~ ∀xφ to ∃x ~ φ should not be intu-
itionistically valid, and it is not; this gives us a flavor of the stunning disagreements 
between classical and intuitionistic logic – because, certainly and as we have seen, 
the above inference is classically valid. As another example, before we proceed to 
enumerate instances of intuitionistically valid and intuitionistically invalid infer-
ence schemata, we may consider this: It may be possible to convert a proof of ψ to 
a proof of ∃xφ for some specific number in an infinite set, like that of the natural 
numbers; and yet, we may be unable to construct a proof that converts a proof of ψ 
8.1  A System of Natural Deduction for ∏πφ=: ∏πφ=∎

388
to a proof of φ for any specific number: this means that the inference from ψ ⊃ ∃xφ 
to ∃x(ψ ⊃ φ) is intuitionistically invalid (although the converse is intuitionistically 
valid.) This inference is, of course, classically valid and it is one of the schemata we 
rely on to produce prenex formulas as we explained earlier. A corollary is that a 
process of extracting a prenex formula that is equivalent with any given well-formed 
formula is not generally available in intuitionistic logic.
•	 ~ ∀x ~ Fx ⊬∑ⅈ ∃xFx
•	 ⊬∑ⅈ ∀x(Fx ∨ ~ Fx)
•	 ~ ∀xFx ⊬∑ⅈ ∃x ~ Fx
•	 ~ ∀x ~ Fx ⊬∑ⅈ ∃xFx
The following are intuitionistically valid instances of logical consequence.
9
9 ∀xFx ⊢∑ⅈ ~ ∃x ~ Fx
9
9 ∀xFx ⊢∑ⅈ ∃xFx
9
9 ∀x ~ Fx ⊢∑ⅈ ~ ∃xFx
9
9 ∀x ~ Fx ⊢∑ⅈ ∃x ~ Fx
9
9 ∃x ~ Fx ⊢∑ⅈ ~ ∀xFx
9
9 ∃xFx ⊢∑ⅈ ~ ∀x ~ Fx
9
9 ∃x(Fx ⊃ φ) ⊢∑ⅈ ∀xFx ⊃ φ	
--the converse inference does not hold
9
9 ∃x(φ ⊃ Fx) ⊢∑ⅈ φ ⊃ ∃xFx	
--the converse inference does not hold
9
9 ∀xFx ∨ φ ⊢∑ⅈ ∀x(Fx ∨ φ)	
--the converse inference does not hold
9
9 -- [the following inferences are valid in both directions in ∑ⅈ]
9
9 ∃x(Fx ∙ φ) ⊣⊢ ∃xFx ∙ φ
9
9 ∀x(Fx ∙ φ) ⊣⊢ ∀xFx ∙ φ
9
9 ∃x(Fx ∨ φ) ⊣⊢ ∃xFx ∨ φ
9
9 ∀x(Fx ⊃ φ) ⊣⊢ ∃xFx ⊃ φ
9
9 ∀x(φ ⊃ Fx) ⊣⊢ φ ⊃ ∀xFx
8.1.11  Exercises
	1.	 Are the following derivations of lines correct or incorrect? Discuss. What rule 
is presumably to be applied and is the rule applied correctly or not?
P1	 ∀x∃y(Rxy ∙ Sxy)	
P
	P2	 ∃y(Ray ∙ Sby)
	P1	 ∀x∀y(Rxy ⊃ Ryx)	
P
	P2	 ∀y(Ray ⊃ Raa)
	P3	 Rab ⊃ Raa
	P4	 ∀y(Ryb ⊃ Ryy)
	P5	 ∀y∃x(Ryx ⊃ Ryy)
	P1	 ∃x∃yRxy	
P
	P2	 ∃x∃ySxy	
P
8  Proof-Theoretical System for Predicate Logic: ∏πφ=

389
	P3	 ∃yRay
	P4	 Rab
	P5	 ∃ySay
	P6	 Sab
	P7	 Rab ∙ Sab
	P8	 ∃y(Ray ∙ Say)
	P9	 ∃x∃y(Rxy ∙ Sxy)
	P1	 Rab	
	P
	P2	 ∃yRyy
	P1	 ∃xRafx	
	P
	P2	 Rafa
	P3	 ∃xRxfx
	P1	 ∃x∃yRxy	
P
	P2	 ∃yRay
	P3	 Rab
	P4	 ∃xRax
	P5	 ∃y∃xRyx
	P1	 Fab ⊃ ∀xFax	
	P
	P2	 Fab ⊃ Faa
	P3	 Fab ⊃ ∀xFxx
	2.	 Identify and discuss the errors in the following pseudo-proofs. Also give 
instances of the invalid inferences that correspond to the pseudoproof. For 
example, for the first pseudo-proof below: There is at least one student; there-
fore, everyone is a student. (!)
	P1	 ∃xFx	
P
	P2	 Fa	
∃E(1) – ae (a is an eigenparameter)
	P3	 ∀xFx	
∀I(2)
	P1	 ∃xFx ∙ ∃xGx	
P
	P2	 ∃xFx	
∙E(1)
	P3	 ∃xGx	
∙E(1)
	P4	 Fa	
∃E(2) - ae
	P5	 Ga	
∃E(3) - ae
	P6	 Fa ∙ Ga	
∙I(4, 5)
	P7	 ∃x(Fx ∙ Gx)	
∃I(6)
	P1	 ∀x∃y(x ≠ y)	
P
	P2	 ∀x(x ≠ a)	
∃E(1) - ae
	P3	 a ≠ a	
∀E(2) – a
	P4	 ∃x(x ≠ x)	
∃I(3)
	P1	 ∀x(Fx ∨ Gx)	
P
	P2	 Fa ∨ Ga	
∀E(1)
	P3	 Fa ∨ ∀xGx	
∀I(2)
	P4	 ∀xFx ∨ ∀xGx	
∀I(3)
8.1  A System of Natural Deduction for ∏πφ=: ∏πφ=∎

390
	P1	 ∀xRxx	
P
	P2	 Raa	
∀E(1)
	P3	 ∀yRay	
∀I(2)
	P4	 ∀x∀yRxy	
∀I(3)
	3.	 Construct proofs in ∏πφ=∎ for the given argument forms.
	
a.	 ∀xFx ⊢ ∏πφ=∎ ∀yFy
	
b.	 ∀xFx ∨ ∀xGx ⊢ ∏πφ=∎ ∀x(Fx ∨ Gx)
	
c.	 ∃x(Fx ∙ ~ Gx), ∀x(Gx ∨ Hx) ⊢ ∏πφ=∎ ∃x(Fx ∙ ~ Hx)
	
d.	 ∀x∀y(Rxy ∨ Ryx)⊢ ∏πφ=∎ ∀xRxx
	
e.	 a = b, b = c ⊢ ∏πφ=∎ a = c
	
f.	 ∀x(x = fb), ∀xRxx ⊢ ∏πφ=∎ fbb ∙ bfb
	
g.	 ∃x∀yByx ⊢ ∏πφ=∎ ∀y∃xByx
	
h.	 ∃x∃yRxy ⊢ ∏πφ=∎ ∃y∃xRxy
	
i.	 ∀x(Fx ⊃ Gx)⊢ ∏πφ=∎ ∃xFx ⊃ ∃xGx
	
j.	 ∀x∃y∀zRxyz ⊢ ∏πφ=∎ ∀x∀z∃yRxyz
	
k.	 ∀x(Ffx ⊃ x = a) ⊢ ∏πφ=∎ ∃xFfx
	
l.	 ~ ∃x∀yRxy ⊢ ∏πφ=∎ ∀x∃y ~ Rxy
	
m.	 ∃x(∀y(Fy ⊃ x = y) ∙ Fx)⊢ ∏πφ=∎ ∃x∀y(Fy ≡ x = y)
	4.	 Construct proofs in ∏πφ=∎ for the given empty-premise argument forms (hence, 
proofs of theses.)
	
a.	 ⊩∏πφ=∎ ∀x(Fx ⊃ Gx) ⊃ (∀xFx ⊃ ∀xGx)
	
b.	 ⊩∏πφ=∎ ∀xFx ⊃ ∀yFy
	
c.	 ⊩∏πφ=∎ ∀xFx ⊃ ∃yFy
	
d.	 ⊩∏πφ=∎ (∀x(Fx ⊃ Gx) ∙ ∃xFx) ⊃ ∃xGx
	
e.	 ⊩∏πφ=∎ ∃x(Fx ∙ Gx) ⊃ (∃xFx ∙ ∃xGx)
	
f.	 ⊩∏πφ=∎ ~ ∃x(Fx ∙ Gx) ⊃ (∃x(~ Fx ∙ Hx) ∙ ∃x(Gx ∙ Hx))
	5.	 Recalling the parallel task for the mechanics of constructing natural deduction 
proofs in sentential logic, discuss how ∏πφ=∎ can be deployed to determine con-
sistency of a set of given formulas of predicate logic. Then determine, if possi-
ble, consistency of the given formulas.
	
a.	 ⊩∏πφ=∎ {}
8.2  A Tree System for Polyadic Predicate 
Logic: ∏ρ=↙↓↘
The formal system ∑↙↓↘ was presented in earlier chapter as a decision procedure 
for sentential logic. We extend that system and adopt the grammar of ∏πφ=∎ to gen-
erate ∏ρ=↙↓↘ with the addition of rules for the quantifier symbols and identity. 
The predicate logic trees may be non-terminating if there is an infinite number of 
available letters for implementing the rule for the universal quantifier symbol. 
8  Proof-Theoretical System for Predicate Logic: ∏πφ=

391
Unlike the sentential logic tree system, which can be proven in metalogical analysis 
to be a correct decision procedure that harmonizes with the truth table system in 
terms of determining the same logical properties for the same formulas, the predi-
cate logic tree can be effective only if restricted to fragments of the predicate logic 
language. We cannot enter into details about this subject in the present text.
The rules of ∑↙↓↘ are retained. Familiarity with that system is presupposed 
before continuing with the present section. Briefly we recall that we use plus and 
minus signs to designate and anti-designate formulas. Rules for the connective sym-
bols are provided, some of which rules are splitting while others are vertical. The 
basic structural rules regulate how the implementation of the tree procedure begins, 
proceeds and terminates properly. Because of the operation of the splitting or 
branching rules, a tree may have branches issuing downward from the root which is 
placed at the top; branches that are connected downward to other branches form 
paths. The tree is completed or terminated when no more rules can be applied to 
it – except for the prospect of non-terminating trees which arises for the first time in 
the case of predicate logic. An open path of a terminated tree indicates that all the 
formulas along the path can be true together: accordingly, the formulas at the root 
of the tree are co-satisfiable or consistent as a set, and this suggests the decision 
procedure for checking consistency. A closed path is one that has a terminal closed 
branch: closure occurs when any formula appears both as designated and as anti-­
designated on the same path. Closure may be executed immediately or deferred 
depending on whether the rule is liberalized accordingly. A closed path indicates a 
logically impossible state of affairs when we consider the value assignments to the 
atomic variables of the formulas on the path as comprising what we may regard as 
states of affairs or logical possibilities. If the root of the tree is labelled by formulas, 
closure of all the paths of the terminated tree shows that the set of formulas, for 
which the tree has been constructed, is inconsistent. If the root is labeled by one 
formula, the formula is a contradiction if, and only if, all the paths of its completed 
tree are closed. The check for the logical status of tautology requires placing at the 
root of the tree the negation of the given formula: since tautologies are the negations 
of contradictions, the closed tree (a tree with all paths closed when it is terminated) 
shows that the formula that has been negated is a tautology. A contingency is a for-
mula that has neither its tree nor the tree for its negation closed. The validity check 
through the tree method requires negating the presented conclusion and attaching it 
to the premises of the argument form to constitute the root of the tree: the argument 
form is valid if and only if the tree with the premises and negated conclusion at the 
root is closed: since all paths are closed, there is no logically possible case or value 
assignment to the atomic variables, for which all the premises are true and the con-
clusion is false – which matches precisely our standard and familiar definition of 
validity of argument form. Checks for determining relations between formulas can 
be devised accordingly.
All the above conceptual and mechanical specifications are preserved and all we 
need to do is to add the rules for the quantifier symbols and for the identity symbol – 
both for designated and anti-designated formulas.
8.2  A Tree System for Polyadic Predicate Logic: ∏ρ=↙↓↘

392
Specifically, closure is effectuated for any branch that has any formula □ as both 
designated and antidesignated. Invalid argument forms are correctly determined by 
the tree system: any open branch in the completed tree for the validity check records 
the truth values of the atomic variables (true for designated and false for antidesig-
nated) and the values (referents) of terms for which there is a counterexample (bet-
ter, a countermodel) to the given argument form: we may see, by a slight abuse of 
terminology and for the sake of convenience, that an open path is a counterexample 
to the given argument form. It is provable, although we will not prove it here, that 
any argument form that is checked as invalid by the tree method is invalid by the 
truth table method and any valid argument by the tree method is determined as valid 
(all paths of the completed tree are closed) when checked by the tree method.
An eigenparameter is a new letter, not on the tree up to the point of generation of 
this new letter and not to be used again for designated existential rule implementa-
tion; but it can be used for designated universal rule implementation from this point 
on. The anti-designated existential rule may be understood by thinking of the man-
ner of interconvertibility between existential and universal quantifier symbols, 
which we have already learned. Negating an existentially quantified formula with 
matrix □ yields equivalently a universally quantified formula with matrix the nega-
tion of □. Parallel reflections apply in the case of the negated universally quantified 
formulas which yield equivalently existentially quantified formulas with the 
­negations of the initial matrices as matrices of the new formula. It may seem gratu-
itous and needlessly elaborate to be learning the rules with designation and antides-
ignation instead of maintaining a straightforward approach but the reason for this 
presentation is to prepare a persistent student of logic who may continue into the 
investigation of non-standard logics, trees systems for which require designation 
and antidesignation of formulas to be constructed.
k. ∃x□ +
⋮
n. □ + [λ/x]	 	
∃+(k) λ is a new letter (eigenparameter)
----------------------------------------------------------------------------------------.
k. ∃x□ −
⋮
n. □ − [λ/x]	 	
∃−(k) 	  λ is any letter
----------------------------------------------------------------------------------------.
k. ∀x□ +
⋮
n. □ + [λ/x]	 	
∀+(k) 	  λ is any letter
----------------------------------------------------------------------------------------.
k. ∀x□ −
⋮
n. □ [λ/x]	
	
∀−(k) λ is a new letter (eigenparameter)
8  Proof-Theoretical System for Predicate Logic: ∏πφ=

393
Next we lay down the rule schemata for the identity symbol. We use designation 
and anti-designation again. The designated rule allows for intersubstitutivity of the 
identicals into any matrices of quantified formulas. The antidesignated formula, 
antidesignating self-identity, is a closure formula: the branch is closed when the 
self-identity formula receives antidesignation. We likewise need designation and 
antidesignations rules for the symbol of negated identity, “≠”, which we have made 
available in our grammar. 
Here is how we can prove that identity has the commutative and transitive 
properties.
	1.	 a = b +	
Premise		
/.. b = a
	2.	 b = a −	
Negated Conclusion
↓
	3.	 a = a –	
=+(1, 2)		
== b/a in (2), given (1), according to the rule =+
↓
	4.	 a ≠ a +	
≠+(3)
⊠
	1.	 a = b +	
Premise
	2.	 b = c +	
Premise		
/.. a =c
	3.	 a = c −	
Negated Conclusion
	4.	 a = c +	
=+(1, 2)
⊠
Function symbols are treated as constant letter symbols with the added proviso 
that formulas expressing existence and uniqueness of the function output is granted 
and have to be explicitly appended to the tree. This makes the use of functional 
symbols rather complicated and engenders certain tricky conditions that create 
opportunities for errors and for spurious proofs to go through – as we examined in 
some detail when dealing with the natural deduction system for polyadic logic in 
preceding section.
k. λ1 = λ2 +.
⋮
l. □
⋮
n. □ [λ1/λ2]	
	
	
	
=+(k, l)
⋮
u. □ [λ1/λ2]	
 	
	
	
 =+(k, l)
----------------------------------------------------------------------------------------.
	
	
	
k. λ = λ −.
	
	
	
⋮
	
	
	
l. λ ≠ λ + 	
 =−
	
	
	
⊠	
	
≠+
8.2  A Tree System for Polyadic Predicate Logic: ∏ρ=↙↓↘

394
Regulations for the order of nested quantifier symbol eliminations are also 
needed. Eliminations proceed from outside, or from the quantifier symbols with 
broader scope, toward inner, or narrower scope, quantifier symbols. We check that 
application of our tree system checks correctly a valid quantifier shift (as exempli-
fied in the derivation from “there is at least one person who likes everyone” to 
“everyone is liked by at least one person”); and the system also checks as invalid the 
illicit universal/existential quantifier symbol switch (as exemplified in the derivation 
from “everyone likes at least one person” to “there is at least one person who is liked 
by everyone.”) We present the tree for the second, illicit quantifier symbol shift, 
producing a countermodel. We leave the other tree construction as an exercise.
	1.	 ∀x∃yLxy +	
Premise/.. ∃y∀xLxy
	2.	 ∃y∀xLxy −	
Negated Conclusion
↓
	3.	 ∃yLay +	
∀+(1)
↓
	4.	 Lab +	
	
∃+(3)
↓
	5.	 ∀xLxb −	
∃−(2)
↓
	6.	 Lcb −	
	
∀−(5)
⊕                ==the only path remains open – providing a countermodel
The countermodel can be read off the open path of the tree for the argument form 
expressing an illicit quantifier symbol switch. We use the metalinguistic symbolic 
conventions we have introduced earlier to indicate the countermodel. The tree we 
have constructed is not saturated – we have not instantiated the universal quantifier 
symbol for all constant letters. To produce the countermodel, we take into consider-
ation the information in the premises and in the conclusion and accordingly produce 
extensions of the predicate symbol. The countermodel is for a three-member 
domain. From the tree open path we read that the ordered pair of the objects named 
by a and b belongs to the extension of the predicate symbol whereas the order pair 
of the objects named by c and b does not. We supply more information for the coun-
termodel as it is fit.
𝔐 = <ⅅ = {①, ②, ③}, ||>.
|a| = ①.
|b| = ②.
|c| = ③.
|L| = {<①, ②>, <②, ③>, <③, ①>}.
Every object is related to at least one object but there is no object to which all 
objects are related. Reading off the open path of the tree <①, ②> belongs to the 
extension of R and <③, ②> does not.
Notably, we do not need rules of the introduction and elimination variety: the 
type of tree we are implementing, known as negation tree, requires negation of 
­formulas (negation of conclusion for validity check, negation of the formula for 
tautology check); accordingly, to examine the validity of the argument form to 
8  Proof-Theoretical System for Predicate Logic: ∏πφ=

395
which we may appeal to justify existential quantification symbol introduction, we 
have a tree as follows:
	1.	 Fa +	 	
Premise/.. ∃xFx
	2.	 ∃xFx −	
Negated Conclusion
↓
	3.	 Fa −		
∃−(1)
⊠
8.2.1  Exercises
	1.	 Determine by use of the ∏ρ=↙↓↘ tree system whether the following argument 
forms are valid or invalid. Can we determine invalidity by this method? Can we 
extract the countermodel values (truth values of atomic formulas, referents of 
individual constants, extensions of predicate symbols) by this method?
	
a.	 ∀xFx, ∃xGx ⊢ ∏ρ=↙↓↘ ∃x(Fx ∙ Gx)
	
b.	 ∀x(Fx ⊃ Gx), ∃x ~ Gx ⊢ ∏ρ=↙↓↘ ∀x ~ Gx
	
c.	 ∃x(x = fx), ∀xRfxx ⊢ ∏ρ=↙↓↘ ~ ∃xRxx ⊃ ~ ∃xfx
	
d.	 ∃x∀y(y = x ≡ x = x) ⊢ ∏ρ=↙↓↘ ∀x∃y(y = x ≡ x = x)
	
e.	 ∃x(Fx ∨ ~ Fx) ⊢ ∏ρ=↙↓↘ ∀xFx ∨ ∀x ~ Fx
	
f.	 ∃xFx ∙ ∃xGx⊢ ∏ρ=↙↓↘ ∃x(Fx ∙ Gx)
	
g.	 ∃x∃yRxy ⊃ ∃y∃xRxy, ∀x∀y(Rxy ⊃ (x = y ∨ fx = fy)), ∀x∃y(fxy ≡ Rxy) ⊢ 
∏ρ=↙↓↘ ∃x∃y(Rfxfy ∨ Rxy)
	
h.	 ~ ∃x∀yRyx, ∃x∃y(~ Rxy ⊃ x = y) ⊢ ∏ρ=↙↓↘ ∃x ~ Rxx
	2.	 Determine by use of the ∏ρ=↙↓↘ system if the given formulas are tautologies, 
contradictions or contingencies. Can we depend on one procedure to make a 
determination of logical contingency? If a formula has the status of contingency, 
can we use this method to determine values (truth values, referents, extensions) 
for which we could design a satisfying model for the formula – a model in which 
the given formula is satisfied or takes the truth value true?
	
a.	 ⊢ ∏ρ=↙↓↘ ∀x(Fx ⊃ Gx) ⊃ (∀xFx ⊃ ∀xGx)
	
b.	 ⊢ ∏ρ=↙↓↘ (∃xFx ∙ ∃xGx) ⊃ ∃x(Fx ∨ Gx)
	
c.	 ⊢ ∏ρ=↙↓↘ ∃x∀yRxy ∙ ∃y∀x ~ Rxy
	
d.	 ⊢ ∏ρ=↙↓↘ ∃x∃y(Rxy ≡ x = y) ≡ ∃y∃x(Ryx ≡ x = y)
	
e.	 ⊢ ∏ρ=↙↓↘ ∃x(fxa ∙ Fax) ⊃ ∃y(fya ∙ (y = a ⊃ ∃wFww))
	
f.	 ⊢ ∏ρ=↙↓↘ ∀xRxx ⊃ ∀x∃y(x ≠ y ∙ Rxy)
	
g.	 ⊢ ∏ρ=↙↓↘ (∀xRxx ∙ ∀x∀y(Rxy ⊃ Ryx)) ⊃ (∀x∀y∀z((Rxy ∙ Ryz) ⊃ Rxz) ⊃ 
∀x∀y(Rxy ∙ Ryx))
	
h.	 ⊢ ∏ρ=↙↓↘ ∀x∀y∀z((Rxy ∙ Rxz) ⊃ Ryz) ∙ ∃x∃y(Rxy ∙ ~ Ryx)
	
i.	 ⊢ ∏ρ=↙↓↘ (fab ⊃ ∃x∃y(fxy ≡ x = y)) ⊃ a = b
8.2  A Tree System for Polyadic Predicate Logic: ∏ρ=↙↓↘

396
	3.	 Determine by implementation of the ∏ρ=↙↓↘ system if the given sets of formu-
las are consistent or inconsistent? If consistent, can we use this method to deter-
mine values (truth values, referents, extensions) for which we could design a 
countermodel – a model in which all the given formulas are satisfied or take the 
truth value true?
	
a.	 ⊢ ∏ρ=↙↓↘ {∀x∀y((Rxy ∙ Ryx) ⊃ x = y), ∀x∀y(Rxy ⊃ ~ Ryx)}
	
b.	 ⊢ ∏ρ=↙↓↘ {∀x∀y(Rxy ⊃ ∃zRyz), ∀xRxx, ∀x∀y(Rxy ∙ Ryz ∙ ~ Rxz)}
	
c.	 ⊢ ∏ρ=↙↓↘ {∃xRxx, ∃x∃y(Rxy ∙ Ryx), ∀x∀y∀z((Rxy ∙ Ryz) ⊃ ~ Rxz)}
	
d.	 ⊢ ∏ρ=↙↓↘ {∃x(Rxfa ⊃ fa = x), Rfafb, fa ≠ fb, Rab}
	
e.	 ⊢ ∏ρ=↙↓↘ {∀x∃yBxy, ∃y∀xBxy}
	
f.	 ⊢ ∏ρ=↙↓↘ {∃x∃y∃z((Rxy ∨ Ryz ∨ Rxz) ∙ ~ (Rxy ∙ Ryz ∙ Rxz)), ∀x∀y ~ (Rxy 
∙ Ryx), ∀x∀y∀z((Rxy ∙ ~ Rxz) ⊃ ~ Ryz)}
	
g.	 ⊢ ∏ρ=↙↓↘ {~ ∃xRxx, ~ ∃x∃y(Rxy ∙ Ryx), ∀x∀y((Rxy ∙ Ryx) ⊃ x = y)}
	4.	 Implement the system ∏ρ=↙↓↘ to determine validity or invalidity of the argu-
ment forms in the exercises in 8.1.e. How can ∏ρ=↙↓↘ be adapted to determine 
if a given formula expresses a logical truth? Apply to the exercises in 8.1.e with 
empty-premise argument forms.
8  Proof-Theoretical System for Predicate Logic: ∏πφ=

397
© The Author(s), under exclusive license to Springer Nature 
Switzerland AG 2022
O. Makridis, Symbolic Logic, Palgrave Philosophy Today, 
https://doi.org/10.1007/978-3-030-67396-3_9
Chapter 9
Definite Descriptions: ∏πφ=⍳
KeyWords  Definite DescriptionsRussellian Definite DescriptionsRegimentation.
We expand the grammar of our symbolic language ∏πφ= with addition of a sym-
bol, “⍳”, whose syntactical management will be regulated accordingly, adding to the 
well-formed formulas of ∏πφ= which is extended to ∏πφ=⍳. In the symbolic idiom we 
generate in this way we will discuss the subject, a perennial staple of logic dis-
course, regarding how we are to express definite descriptions in predicate logic. The 
claim that we will examine is actually stronger: the resources of predicate logic are 
put into effect to express the proper underlying logical structure of definite descrip-
tions whereas the linguistic grammar, and possibly the common intuitions of com-
petent users of the language, are easily misled, without the ministrations of formal 
logic, about what this logical structure is. Bertrand Russell, in the landmark work of 
modern logic, Principia Mathematica, which he co-authored with Alfred North 
Whitehead, initiated a view about definite descriptions that has been touted as a 
seminal example of a case in which formalist regimentation (proper expression of a 
linguistic phrase by means of formal resources available through the language of a 
logical system) captures the proper logical structure of meanings while reliance on 
linguistic grammar in such cases is misleading. The implications of this presumed 
success are far-reaching: there is a view that unwarranted reliance, in misleading 
cases, on linguistic grammar is the single most devastating source, historically, of 
confusion that leads to the generation and endless toil spent in elaboration of what 
are actually spurious problems, pseudo-puzzles and traditionally befuddling quests 
for philosophic answers to non-existent problems. A similar case can be made about 
confusions that, arguably, stem from misappropriation or misunderstandings that 
have to do with linguistic usage – but our present topic, as we have noted, “corrects” 
language by using the formal resources of logic to express correctly the logical 
structures of meanings.
Our target is what are known as definite descriptions. Russell also included 
proper names, which he considered as expressible correctly in terms of definite 

398
descriptions. This view originated with the German logician and one of the founders 
of modern logic, Gottlob Frege, who opted for taking the meaning of a name to 
consist in its extensionalist dimension – a logical predicate that can be predicated of 
the entity that is referred to, and, as we know by now, with the predicate being 
extensionally defined as the set of entities that are members of the set that is the 
denotation or logical meaning of the predicate: with the additional constraint, in the 
case of a name, or of a definite description, that the set is a singleton – meaning that 
it has exactly one member. Thus, to use the classical example deployed by Frege 
himself, the name “Aristotle” should be fixed through its extensional meaning as 
“the teacher of Alexander the Great” with the predicate “the teacher of Alexander 
the Great” denoted (not connoted) as the singleton set with the entity in question as 
the set’s only member. Interestingly, it might be objected that the name “Aristotle” 
could also be fixed extensionally as “the student of Plato” and in many other ways 
(including by using combinations of predicates), which shows dependency on vari-
able context and, as such, falls outside the scope of the standard extensional logic. 
The response to this is twofold: for one, the dependence on context is a so-called 
pragmatic matter that is not properly handled through the resources of formal logic; 
we may compare, for instance, the manner in which we approach logical predicates 
as essentially non-logical symbols in the sense that the extensions of predicates are 
semantically open to endless possibilities across constructions of models; this does 
not vitiate the logical project because no logical truths can ever be provable depend-
ing on the incidental assignments of extensions to the predicates in specific models. 
Similarly, names are to be understood as model-dependent in the logical construc-
tions within the formal system but this has no bearing, as it should not have any 
bearing, on the characteristics of the logic (such as the collection of logical truths 
provable in the logic or the relation of logical consequence that characterizes the 
logic.) The second point to make is that names, and the definite descriptions to 
which we will turn next, are incomplete terms for a reason that will soon become 
visible.
A definite description is generated by making a unique attribution of a predicate 
to an entity. We may render also, keeping in mind natural language, “the F,” when 
the context makes it precisely given that this a unique F. The definite article is usu-
ally deployed to indicate uniqueness in natural language but, as always, there are 
other usages as well. Sometimes, it means “all” as in “the soldier can know no fear.” 
The standard textbook example of a definite description case, from Russell’s work, 
speaks of “the present King of France.” The sentence that is queried, as to its truth 
value, is: “the present King of France is bald.” Russell’s view is that “the present 
King of France” is not to be treated as a logical constant but to be treated instead in 
regimentational fashion: it has to be rendered in quantificational language as “there 
is a unique entity, such that it is the present King of France.” We may not see imme-
diately how to express uniqueness but this apparent challenge is easily circumvented 
because the symbolic resources we have at our disposal in predicate logic allow us 
to express uniqueness claims like this. The main thrust is that this regimentational 
rendering of the definite description is the correct approach to capturing the logical 
meaning of this linguistic component, and also this is the right way for representing 
9  Definite Descriptions: ∏πφ=⍳

399
the logical structure of any meaning conveyed by any meaningful sentence that has 
in it definite descriptions. Reliance on linguistic grammatical structure is fatally 
misleading. It appears indeed that we should rather treat a definite description like 
the one in our example as a name, but this is wrong according to Russell. There also 
seems to be a poignant challenge that would arise if we attempted to treat the defi-
nite description as a name: there is no referent, we want to say, since there is no 
“present” King of France. Of course, we could construct semantically a model in 
which the name would have a referent in the specified domain but, as we have 
already indicated, this is a pragmatic issue: it is as crucial that we can always con-
struct a model in which the definite description does not refer – and, indeed, this is 
always possible for any definite description. There seems to be problem about this: 
what should we say that the truth value of the sentence is when we are dealing with 
a non-referring or non-denoting definite description?
There is, however, a way around this particular issue but the solution, initially 
contemplated by Frege himself, comes across as ad hoc and, some might say, 
“unnatural” although this is a rather vague way of speaking for our purposes. We 
could specify that one distinct and, inevitably unique, element of our domain is 
what we may call the “nullary object.” Any non-referring constant in our domain 
would then be stipulated as having this nullary entity as its referent and in our 
semantics we would accordingly mandate that the sentence with such a constant has 
to be false. Bivalence dictates this approach since we only have as truth value true 
and false and we ought to refrain, for obvious reasons, from assigning the truth 
value true to a sentence that contains a non-referring term. Of course, this may be 
philosophically contentious but the formal resources that would be required to 
accommodate, for instance, a view that such sentences are neither true nor false are 
simply not available in our formalism. The discussion can then be pushed to another 
level, as a logical-philosophical discussion, about the aptness and limitations of the 
standard bivalent logic, or about the motivations for choosing a logic or, indeed, it 
could be seen as an opportunity to discuss the overarching issue about possible 
motivations and supports for alternative or non-classical logics. As it is, the stipula-
tion of a nullary object fixes our problem but this solution is one of the most unpop-
ular fixes ever considered. But Russell’s theory of definite descriptions does not 
originate from a perceived difficulty with handling such expressions as names; his 
point, rather is that the deep structure of definite descriptions is quantificational and 
ought to be represented through regimentation in the language of predicate lan-
guage rather than regarded as names. When this is done, as we will see, opportuni-
ties arise for disambiguating with respect to scope of the quantifier – which has to 
be used in rendering definite descriptions in Russell’s theory – but this may be pre-
sented as an additional benefit of the approach in that we now have additional 
opportunities for detecting and removing such logically anomalous interferences as 
arise from ambiguity of scope, which are otherwise undetected and can cause con-
fusion in ordinary discourse. Objections have been raised against Russell’s view of 
definite descriptions, having to do with the role played by existential presupposi-
tions in assigning truth values to claims about entities but such matters tend to be 
either pragmatic  – to be relegated to analysis of linguistic usage rather than 
9  Definite Descriptions: ∏πφ=⍳

400
incorporated in the study of logic – or motivational for adopting alternative logics 
that contain more than two truth values in their formal setup.
We add to our grammar the formation rule for the new symbol. As we see, the 
symbol is attached to a variable letter to form an incomplete pair (as in the case of 
quantifier-plus-variable) and the whole is attached to the predicate-symbol-plus-­
variable. We add to our grammar, in our extended formal language ∏πφ=⍳, stipulating 
that the following as well-formed formula.
•	 ⍳xFx ∊ WFF(∏πφ=⍳)
We can also formalize meanings of statements like the ones in the following 
examples.
•	 The unique F is a G: G⍳xFx
•	 b is the name of the unique F: ⍳xFx = b
•	 the f (function symbol) of the unique F is R-related to the unique G: Rf⍳xFx⍳xGx
From the standpoint of semantics, we can briefly indicate how the ⍳-quantified 
symbolic expressions are to be treated. A symbolic expression of the form generally 
⍳λφ where λ is free in φ before it is bound by the iota-quantifier belongs to the terms 
of the interpretation or signature of a first-order model over a domain: 𝔐 = <ⅅ, ||>: 
⍳λφ ∊ TERMS(ℳ). The symbol has a unique referent that is a member of the domain 
of the model. The truth conditions can then be defined accordingly for the model 
and for assignments generally σ. Opting for the second of the two approaches we 
used for configuring the semantics of predicate logic – the approach for accommo-
dating unnamed domain entities – and using “||λ||” to symbolize temporary referents 
for variable λ, which are entities in the domain, for sequences of variable-­
assignments, we have:
•	 |ψ⍳λφ|ℳ, σ = T	
if and only if (iff)	
|ψ|ℳ, σ(⍳λφ) = ℯ
||λ|| = T
	
for unique ℯ ∊ ⅅ(ℳ)
We may use the most famous example in the literature, the one used by Bertrand 
Russell himself in his seminal article on definite descriptions, to check our semantic 
arrangements and in order to outline and appreciate Russell’s regimentation 
approach and also so that we can confront certain interesting problems that arise.
Key: Bx: x is bald/Kx: x is the present King of France (it could be symbolized as 
binary predicate symbol, with “f” the name for France: Kxf).
•	 (S) 	 	
	
	
The present King of France is bald.
•	 (Formalization[∏πφ=⍳](S))	
B⍳xKx
•	 (Semantic Analysis: S)	 	
|B⍳xKx|ℳ, σ = T iff <|⍳xKx|ℳ, σ> = <ℯ ||⍳xKx ||>∊ |B|
The challenge we face stems from the prospect of dealing with a non-denoting 
definite description: if there is no entity ℯ in the model’s domain ⅅ, which can be the 
temporary referent (and, given the definitions, the settled reference in any sequential 
assignment) of the iota-quantified expression ⌜⍳xKx⌝ which is a term as we have 
indicated. In this case, our semantics compel us in a direction that is not permitted 
9  Definite Descriptions: ∏πφ=⍳

401
formally in the family of logics within which we are operating: the truth value of the 
sentence ⌜B⍳xKx⌝ in the model would have to be unassignable or indeterminate, 
neither one of the truth values true and false. This, however, cannot be contem-
plated. Every meaningful sentence is to take exactly one truth value from the set of 
truth values {T, F}; otherwise, it cannot be a meaningful sentence, and yet, our 
sentence ought to register as carrying meaning and as being amenable to our seman-
tic analysis. If we constructed a deviation, a formal system with an added third truth 
value (for indeterminate) and accordingly presented connective symbols that are 
defined differently from the way they are defined in ∏πφ=⍳, we could also attempt a 
different management of this subject; this option is also unavailable, however, since 
we are working strictly within the confines of our standard bivalent logic. Two solu-
tions we can briefly examine, both of which render the truth value as false in the 
case of a non-denoting or non-referring definite description sentence (when there is 
no referent in the domain of the model for the term formed for the presumably 
uniquely referring expression.) One approach (the Frege approach) tinkers with the 
semantics of our language and the other approach (the Russell or regimentation 
approach) radically pushes for the systematic elimination of the iota-quantified 
symbolic expressions.
	1.	 Frege’s solution, to which we alluded earlier and dismissed as possibly ad hoc 
and unintuitive, enhances our semantic arrangements in a certain way: a special 
object, the nullary or nil object, symbolized by “⓪”, is added to each domain; 
every non-referring term is taken as referring to this nothing-object with talk 
about “nothing” managed systematically in the semantics, so that sentences with 
terms referring to this non-object object are defined as being false. Frege thought 
that this tinkering can be justified because it is a limitation of natural language 
that it would permit grammatical constructions of names that do not refer; in the 
perspicuous symbolic notation, in which ambiguity cannot be tolerated, the 
absent referent must be rendered explicit: this does not mean that we would com-
mit ourselves to a nonsensical way of speaking, in our semantics presented in 
our metalanguage, about a thing that is and is not a thing; instead, the mysterious 
thing is demystified by the services of the always explicatory and perspicuous 
specifications of our formal language and its semantics and is treated as an hon-
orary object (as member of the things we are talking about) but such references 
are rewarded – so to speak – with giving the expression the truth value false. In 
this way, the truth values do the work and no mystification about an elusive 
object need arise since the mechanism for including such an object in the domain 
is merely by systematically managed stipulation. Given the Fregean stipulation, 
we have that the statement “the present King of France is bald” is false since the 
referent of the term “the present King of France” is the nullary object of the 
domain. Thus, the nullary object, symbolized by “⓪”, is the referent of ⌜⍳xKx⌝ 
and the symbolic expression, the formula, that contains this term has to take the 
truth value false.
|B⍳xKx|ℳ, σ = F 	
iff 	
<|⍳xKx|ℳ, σ> = <⓪ ||⍳xKx ||>
9  Definite Descriptions: ∏πφ=⍳

402
	2.	 In Russell’s famous, and still controversial, solution, we are made eliminate 
iota-­quantified symbolic expressions systematically – purging them from our 
semantics. Russell’s claim is that definite descriptions are not terms, are not 
names, and the fact that linguistic grammar treats them as names is a poignant 
and instructive example of how the grammar of the natural language can com-
pletely miss the mark and be not only uninstructive but outright misleading 
about the underlying logical grammar of the meaning conveyed by the sentence. 
What Russell’s approach enforces, then, is a reformulation, a regimentation of 
the expression with the definite description in it, so that definite descriptions, 
not to be treated as names or term, are spelled out by means of a specifically 
available formal translation. We show this below, regarding the elimination as a 
species of redefinition. When we studied translations into, we examined how 
definite ­descriptions are to be rendered formally in ∏πφ=. Since Russell rede-
fines, or defines away, definite descriptions (so that they are not names), the 
resources of predicate logic are available to accommodate this request in the 
way we have already examined. Sometimes the symbol “∃!” can be added to 
indicate uniqueness of reference.
B⍳xKx ≝ ∃!x(Kx ∙ Bx) ≡ ∃x(Kx ∙ ∀y(Ky ⊃ y = x) ∙ Bx) ≡ ∃x(∀y(Ky ≡ y = 
x) ∙ Bx).
Thus, in the regimented form into which the definite description is translated 
on Russell’s approach, there is an existential component (that at least one such 
entity exists in the domain) and the uniqueness component (that any other entity 
that putatively would have the crucial characteristic is exactly the entity we are 
talking about, so that any names assigned to it would be co-referring.) If the 
descriptive sentence is non-referring or non-denoting, then the existential compo-
nent gives us the truth value false on the interpretation we construct over the rel-
evant model.
Finally, an issue that arose around this subject to occupy Russell’s attention sepa-
rately after the initial article had been published has to do with a looming ambiguity 
that has to be forestalled by all means. Let us consider the following sentence, 
which is ambiguous between two different plausible interpretations as stated. The 
ambiguity is associated with different possible placements of the negation: one pos-
sibility is that negation has broad scope and the other possible option is that nega-
tion has narrow scope. The regimentations or formal translations must be provided 
accordingly for purposes of disambiguation.
•	 (-S)	
The present King of France is not bald.
•	 (disambiguation1(-S))	
It is not the case that there is a present King of 
France who is bald.
•	 (disambiguation2(-S))	
There is a present King of France who is not bald.
•	 (d1(-S): broad scope(~))	
	
	
~ ∃x(∀y(Ky ≡ y =x) ∙ Bx)
•	 (d2(-S): narrow scope(~))	
	
	
∃x(∀y(Ky ≡ y =x) ∙ ~ Bx)
9  Definite Descriptions: ∏πφ=⍳

403
9.1  Exercises
	1.	 The symbols from {x, y, z, u, v, w, …, x1, …}, with subscripts from the countable 
natural numbers, have been legislated in our formal grammars for predicate logic 
to be used for individual variables. Yet, ⌜⍳x⌝ accompanied by an open predicate 
letter (predicate letter with individual variable matching the symbol in ⌜⍳x⌝, is 
not an individual variable although it is of course a term. What kind of term is it? 
How do you explain this?
	2.	 What is Frege’s solution to the problem of characterizing definite descriptions, 
and specifically non-denoting definite descriptions? Discuss this suggested solu-
tion. Compare to Russell’s response and discuss further. Are there pros and cons 
to both?
	3.	 Let us introduce symbol “E!” defined as follows:
E!xFx ≝ ∃x(x = a ∙ Fx).
Does this symbolize unique existence? Do we need this in a formal system of the 
standard predicate logic? (Recall and discuss the existential commitments gener-
ated automatically in the standard predicate logic.) How is this symbol different 
from the symbol, we have also introduced, ⌜∃!⌝?
	4.	 Discuss a proposal that we treat non-denoting definite descriptions as having no 
truth value: they are not true and they are not false.
	
a.	 Distinguish two different cases: that non-denoting definite descriptions do 
not have any truth value whatsoever; and, an entirely different approach, they 
do have a truth value but this truth value is not “seen” by the standard logic: 
it is the truth value “neither true nor false.”
	
b.	 What is the different between the two cases?
	
c.	 What does it mean to compel a revision of logic in order to treat non-denoting 
definite descriptions as having a non-standard third value? (Recalling an ear-
lier discussion in this text, the formal system with the three truth values is not 
an extension of but a deviation from the standard logic.)
	
d.	 Write out truth table definitions of the connective symbols for a language 
with the three truth values, {T, N, F}. Surely, there is not just one way to do 
this but define the truth connectives as you justifying your choices. (For 
instance, the negation of N should be also N; N and N should yield N; 
and so on.)
	
e.	 Are the connective in your three-value logic the same as the standard 
connectives?
	
f.	 What happens in assessing Russell’s famous example about the bald king in 
this three-valued system?
	
g.	 Discuss objections. Discuss also the broader implications for logic of the 
acceptability of motivating formal systems with more than the standard two 
truth values.
9.1  Exercises

404
	
h.	 Returning to the proposal to treat non-denoting definite descriptions as hav-
ing no truth value (not a third truth value but no truth value whatsoever): 
discuss this proposal.
	
i.	 Do you think that competent users of natural language would have some ini-
tial intuitive preference in favor of any one of the approaches we have seen: 
the Russellian, the Fregean, the no-value, and the third-value approaches?
	5.	 Let us consider the following symbolic expression:
G⍳xFx
	
a.	 What is the meaning of this expression?
	
b.	 Prove that this implies existence of the-F.
	
c.	 Discuss. Can you think of examples in language, in which the characteriza-
tion of a uniquely characterized entity should not commit us to an assertion 
that such an entity indeed exists?
	6.	 Now let us consider the symbolic expression.
F⍳xFx
	
a.	 What is the meaning of this expression?
	
b.	 Would you expect this to be a logical truth of the standard predicate logic?
	
c.	 Check to determine if this is or is not a logical truth of the standard predicate 
logic, and discuss the result.
9  Definite Descriptions: ∏πφ=⍳

405
© The Author(s), under exclusive license to Springer Nature 
Switzerland AG 2022
O. Makridis, Symbolic Logic, Palgrave Philosophy Today, 
https://doi.org/10.1007/978-3-030-67396-3_10
Chapter 10
Basics of Set Theory
KeyWords  Set TheoryParadoxes of Set TheorySubsetPower SetCardinalityOrdered 
PairCartesian ProductSet-Theoretic OperationsComplementUnionIntersectionZer
melo-­Fraenkel Systematization of Set TheoryRelationsFunctions.
Sets, as defined theoretically, provide one of the most important mathematical tools 
available for use in various fields of mathematics. The use of sets is foundational in 
mathematics, which made the discovery of certain paradoxes surrounding the con-
cept and construction of sets troublesome. The theory of sets has been systematized 
by means of laying down certain intuitively acceptable truths  – the Zermelo-
Fraenkel Theory of Sets – but there are certain purported claims about sets which 
are controversial. There are alternative systems of axioms for set theory but our 
present purpose is introductory and we allow ourselves to glean insights from the 
canvass of set-theoretical systems for the purpose of gaining basic insights. The 
relationship between Logic and the deployment of set-theoretic means is also an 
interesting one. We have used set-theoretical concepts in the body of our text but in 
this chapter we catch a glimpse of the fundamentals of set theory as a branch of 
mathematics. We take the opportunity to investigate certain concepts in the theory 
and to show how set-theoretic operations are defined and carried out. The celebrated 
Boolean algebra has an interpretation in the standard sentential logic, with the truth 
functions we have studied interpreting matching Boolean functions (defined over a 
set of two elements.). Another interpretation of the Boolean algebra finds applica-
tion in Set Theory whose operations (set-theoretic operations) also interpret match-
ing Boolean functions. The set-theoretic interpretation has been shown, by 
I. M. Stone, to be adequately characteristic of the algebra, which draws attention 
again to the theoretical importance of set theory. As we embark on the study of set 
theory, we should keep in mind how set-theoretic operations, which we will define, 
correspond to truth functions (connectives) which we have defined in the context of 
studying sentential logic. (A precise way of saying that is that set theoretic opera-
tions have the same matching Boolean functions with sentential connectives.)

406
10.1  Definitions: Set, Membership, Distinguished Types 
of Sets; Ways of Defining Sets; Theoretical Issues 
About Sets
We have to define the concept of a set first. We could rely on an intuitive sense and 
present a “set” as a collection of any objects regardless as to how those objects are 
related. Offering a more systematic definition, we define a set as follows: A set is a 
collection of discrete objects of any kind, regardless as to whether those objects are 
related to each other or not, under the only proviso that for any given item u and a 
specified set x it is possible to determine whether the item labeled (denoted, referred 
to by) u is in x or not. It follows from this definition also that a set is completely 
characterized by the objects that are included in it. A set is a collection of objects, 
not of the symbols we will be using to refer to such objects. As we will see, sets 
themselves can be members of sets. After all, we take sets to be objects without 
belaboring any concerns about what kinds of objects they are. This shows that the 
view of what counts as an object – the metaphysics we employ – is quite permissive. 
We can regard sets themselves as abstract objects without bothering about the meta-
physical implications of this position.
An alternative view, due to von Neumann and not much in use, reserves the term 
“set” only for collections that share all their members with a specified larger set; all 
other collections are called “classes.” On this view, and for the nomenclature that is 
developed for this purpose, there are properly so-called ultimate classes which are 
not subsets of any other classes. We will disregard this view here.
We say that a set has members or elements. The notion of belonging to a set is 
fundamental and the symbol we use is “∈” while we symbolize sets by variables 
from the set {x, y, z, …, xi, …}, where i is a positive integer or natural number. The 
stock of our variables is, accordingly, countable or denumerable (the infinitarian 
size of the natural numbers.) In texts, capital letters are used to symbolize sets quite 
often but we use small variable letters also permitting ourselves quantification over 
such variables by using the formal language of predicate logic which we developed 
in chapters 5–8. We can use small letters from the earlier part of the English alpha-
bet, {a, b, …}, possibly with subscripts from the positive integers, as variables 
denoting distinguished elements of sets. Our notational symbolizations are pre-
sented in a metalanguage  – not a formally constructed idiom but a convenient 
assortment of English words and symbols that enrich the metalanguage. The sym-
bolic expressions that enrich our metalanguage are constructed grammatically in 
accordance with the conventions we established for predicate logic.
For the sake of providing more detail, we point out that quantifying over set-­
variables, as we do in our metalanguage, generates a higher-order logic as a proper 
logical formal system: we are not presenting such a logic – properly called second-­
order logic - but we are simply employing first-order logic variables for a metalin-
guistic presentation of set-theoretical statements. Incidentally, we catch a glimpse in 
all this of the fact that set theory is not the same as logic; set theory is used as an 
instrument in the construction of logical formalisms but it is a different species. This 
10  Basics of Set Theory

407
is appealing from a broader, philosophical standpoint as well because there ought to 
be some conceptual distinctions between logical things and mathematical things. At 
the same time, the dependence on logic is significant and for our purposes we con-
sider that we have available to us, in the metalanguage, the symbols for our predi-
cate logic system of preceding chapters. The formal grammar is also imported from 
those earlier sections.
The variable symbols, small English letters beginning with x and possibly with 
subscripts from the positive integers, are used indifferently for sets and members of 
sets. This compels us to identify devices for distinguishing between referents that 
are member-sets and those that are members of sets without being themselves sets. 
This task will be addressed later, and it affords us an opportunity for subtle concep-
tual refinements. The two notions – set and member of a set - are different notions 
and we also expect context to remove the ambiguity as to whether set or a member 
of a set is symbolized. As already indicated, sets themselves can be members of 
sets; but members of sets do not have to be sets – they can be objects other than sets. 
In fact, there is no restriction as to what kinds of objects can be considered as mem-
bers of sets. We become aware, again, of the fact that metaphysical considerations 
are precluded from the foundational construction of our intuitively based set theory. 
The set of flying dragons is, thus, definable as a set. Inquiries as to existence, which 
bedeviled traditional philosophy, are preempted: existence is treated as membership 
in a set; the question as to whether something really exists is rightly set aside as a 
non-logical matter. Moreover, we can detect a conceptual switch – from existence 
as a traditional metaphysical notion to set membership – which basically removes 
reliance on metaphysical inquiry and, in this way, allows us to ignore traditional 
puzzles that have arisen over millennia around existence. Conversely, many hoary 
puzzles as to existence can be shown to stem from logical error; but we cannot enter 
into this subject in the present context.
A set has members or elements: these are the objects specified as being contained 
in the set, not the symbols that are used to denote or refer to those objects. It is obvi-
ous that we cannot use objects notationally for the symbolization of members of 
sets. Even if we could put some conveniently small object within an instance of the 
symbolic representation of the set, we would run into the problem that we cannot 
have this same object in more than one place so we can include it also in some other 
instance of symbolizing the same set.
The set brackets, “{“and “}”, are used for enclosure of the symbols of the set 
members. We spell out formulas in a symbolically enriched metalanguage with the 
added symbols and their grammar borrowed from our predicate logic formalism of 
chapters 5–8. In the construction of a predicate logic system, we notice that the rela-
tion of belonging essentially replaces the grammatical notion of a thing “being” 
something or “having” a property: instead of saying that the object named by t has 
the property symbolized by “F”, we are conceptually compelled to think of the 
object named by t as being a member of the set of all objects that have the F-property. 
Thus, membership replaces one of the notions associated with the logically trouble-
some verb “to be” not only with respect to existential assertions but also when it 
comes to predication of attributes. Notably, existence itself is not understood as a 
10.1  Definitions: Set, Membership, Distinguished Types of Sets; Ways of Defining…

408
logical predicate or class: it is, instead, conceived as membership. Logical predi-
cates, on the other hand, are conceived as sets; it follows that membership in the set 
(which we called the “extension” of the predicate in our semantic study of predicate 
logic) is logical predication.
Our concept of set observes a principle that is called Extensionality. According 
to the Principle of Extensionality, two sets are equal if and only if all their members 
are shared and neither has any member that the other does not have. Since a set is 
adequately and exhaustively characterized by its members, it follows that any two 
sets that have exactly the same members are the same set. This makes our theory run 
smoothly but it does run afoul of some intuitive notions we have about properties, 
which take us beyond extensionality. To understand what this is all about, think 
about the set that has as members all players of a team and about the set that has as 
members all female members of a class. If it so happens that all the female members 
of the class are exactly the members of the team – it so happens that all the players 
are in the class and all the female members of the class are all the players of the 
team – then the sets of the team players and of the female students of the class are 
equal to each other. If we are defining properties extensionally – as we do in the 
formalism of predicate logic  – then we cannot distinguish these two concepts 
because their sets are equal to each other; the problem is that we do take those prop-
erties – female student of a class and member of a team – to be distinct but our 
formal apparatus does not allow us to express this difference. Let us think of this as 
the price we pay for Extensionality. We will not dwell here on the philosophic or 
even on the logical implications of this limitation.
An extensionalist notion is what are known in the history of philosophy as the 
principles of Identity of Indiscernables and the Indiscernability of Identicals. These 
two principles are credited to the German philosopher Leibniz. Using the language 
of predicate logic (and drawing on the symbolic enhancement of our metalanguage), 
we may present those principles as follows. We notice that the use of quantifiers 
binding all occurrences of variables means that the definitions are given by means 
of declarative sentences. It happens, however, that definitions of set-theoretic con-
cepts are often given by using what we called open sentences: unbound variables 
denoting sets are used. The symbol “∈” denotes membership in a set. Since we are 
using the same variables for sets and non-set members of sets, we rely on the con-
text to remove ambiguity.
•	 Identity of Indiscernables 	
	
∀x∀y(∀z(z ∈ x ≡ z ∈ y) ⊃ x = y)
•	 Indiscernability of Identicals	
	
∀x∀y(x = y ⊃ ∀z(z ∈ x ≡ z ∈ y))
•	 Extensionality		
	
	
∀x∀y(∀z(z ∈ x ≡ z ∈ y) ≡ x = y)
¾
¾ x = y if and only if ∀u((u ∈ x ⊃ u ∈ y) ∙ (u ∈ y ⊃ u ∈ x)) ---- which is the 
same as:
¾
¾ x = y if and only if ∀u(u ∈ x ≡ u ∈ y)
We read the above definition, provided in our enriched metalanguage, as: x is the 
same set as y (for any x and any y sets) if and only if for all u, u is a member of x if 
and only if y is a member of y. Notably, “x is the same set as y” would be an open 
10  Basics of Set Theory

409
sentence in our predicate logic notation, since these are two free variables. It is 
standard in mathematical textbooks to present definitions in this fashion.
Let us recall that sets can be members of sets. Sets of sets can be members of 
sets, and so on. The building of sets can go on like this. Notice, however, that, offi-
cially, we cannot speak yet of infinite sets and we will need to make appropriate 
stipulations legislating that infinite sets are indeed constructible insofar as such sets 
can be said to exist in the appropriate sense. As we will see, there is an empty set 
which is a set with no members whatsoever. The symbol used to refer to the empty 
(also called Null or Nullary Set) is “∅”. (Other symbols in the literature are “{}” 
and, in older texts “Λ” or “0”.) Only one such set can exist since there is only one 
way of having no members: if we proposed that some other empty set exists besides 
the first empty set we have, then the presumed two sets would have exactly the same 
sets – none! – And, therefore, by Extensionality, they would be the same set. Thus, 
no second empty set can exist; therefore, only one empty set exists. Another type of 
set we define is the universal set, which we symbolize by “ω”. As we will see, this 
set is not to be considered as the set of absolutely everything but rather as a specified 
set of all the contextually relevant objects. This set could be infinite, of course: we 
could be talking about the set of natural numbers, for instance.
We can show set by step that can only be one empty set.
	 1.	 ∅ ≠ ∅1	
(assuming a second empty set)
	 2.	 ∃x(x ∈ ∅1 ∧ x ∉ ∅)	
(charged assumption, for reductio 1)
	 3.	 ∀x(x ∈ 𝛀 ⊃ x ∉ ∅)	
(by definition of the empty set)
	 4.	 ∀x(x ∈ 𝛀 ⊃ x ∉ ∅1)	
(by definition of the empty set)
	 5.	 t ∈ ∅1 ∧ t ∉ ∅	
(existential instantiation for random t 2)
	 6.	 t ∈ ∅1 	
(Conjunction Elimination 5)
	 7.	 t ∉ ∅	
(Conjunction Elimination 5)
	 8.	 t ∈ ω ⊃ t ∉ ∅	
(Universal Instantiation 3)
	 9.	 t ∈ ω ⊃ t ∉ ∅1	
(Universal Instantiation 4)
	10.	 t ∈ ω 	
(Fundamental Stipulation for all members)
	11.	 t ∉ ∅1	
(Conditional Elimination 9, 10)
	12.	 ⊥	
(Absurdity 6, 11– reductio success!)
	13.	 ~ ∃x(x ∈ ∅1 ∧ x ∉ ∅)	
(reductio)
	14.	 ∀x(x ∈ ∅1 ⊃ x ∈ ∅)	
(Exchange of Quantifiers and Conditional 
Exchange Rule)
---The proof can be repeated in the opposite direction, proving:
∀x(x ∈ ∅ ⊃ x ∈ ∅1)
Thus,
∀x(x ∈ ∅1 ≡ x ∈ ∅)
Therefore,
∅1 = ∅
To ensure that our intuitively based theory does indeed permit constructability of 
the empty set we need an axiom that stipulates the existence of such a set and such 
an axiom is indeed included among those of the Zermelo-Fraenkel theory. We will 
briefly scan some of those axioms.
10.1  Definitions: Set, Membership, Distinguished Types of Sets; Ways of Defining…

410
Other comments we may make preliminarily are: the order with which the sym-
bols of the set members is written is unimportant. This does not apply to a special 
category which we will call ordered n-tuples, which we will introduce below; but it 
does apply to sets: accordingly, you could rewrite a set by altering the order of the 
symbols of its members and you would still have a symbolization of the same set.
{1, 2, 3} = {1, 3, 2} = {2, 1, 3} = {2, 3, 1} = {3, 1, 2} = {3, 2, 1}.
Additionally, each symbol may be written only once.
{1, 2, 2} = {1, 1, 2} = … = {1, 2}.
The familiar equality sign “=” is used in our metalanguage to symbolize equality 
of sets – which, by the Principle of Extensionality, means that the two sets share all 
their members – and it is also used to define a set by means of enumerating, within 
the set brackets, the symbols of all its members. Context removes ambiguity. There 
is another subtle issue here worth mentioning briefly. Does the symbol for the set 
represent the set symbolically or does it name the set? It is the former; to name the 
set we should use a special notation – known as the lambda-notation. For instance,
x = {a, b, c}
is a symbolic representation of the set with members named by the letters 
whereas the name of this set is,
λx.((x = a) ∨ (x = b) ∨ (x = c))
Let us see examples of sets and of membership, which is a binary relationship 
symbolized by “∈”. We may also use “∉” as the symbol indicating non-­membership. 
Alternatively, we could indicate non-membership by negating a sentence indicating 
membership. This reminds us that we allow ourselves metalinguistic usage of the 
whole gamut of symbols we have constructed for our formal languages: {~, ∨, ∙, ⊃, 
≡, ∀, ∃}. It is not the symbol but the object that we take as being a member of a set 
or not; to indicate the value of the symbol – the thing to which the symbol refers – 
we use “| |” placing within the parallel vertical bars the symbol: this means that the 
object denoted or referred to by the symbol is a member of the set or not.

 x = {1, 3, 5} 	
|3| ∈ x, |2| ∉ x	
-- relative to a universal set {1, 2, 
3, 4, 5}

 y = {▭, △, ◊, ○}	 |△| ∈ y, |♦| ∉ y	 -- to be precise, we must have some 
universal set that has as member the object symbolized by “♦”. We will also 
see, however, that we will not permitting construction of a universal set in the 
absolute sense – no set of all things whatsoever! This is done to prevent set-­
theoretical paradoxes from arising. Hence, we can only speak of a relatively 
universal set, similarly as we defined a universe or domain of discourse when 
we studied predicate logic.

 z = {{♠}, {♡}}	
-- indeed, sets can be members of sets! – {♡} ∈ z; notice 
that |♡| ∉ z: the set is a member of the set y, not the object.

 w = {∅, {∅}}	
-- the empty is a member of w; the set with the empty set 
as its only member is also a member of w; these are two distinct sets, of 
course: the empty set has no members but the set with the empty set as its 
members does have a member.
10  Basics of Set Theory

411

 To indicate that objects are elements of a specified set, we consider this as a 
matter of inclusive disjunction: for instance, in the case of a two-member set, 
by definition, set membership is represented as “either x belongs to set s, or y 
belongs to set s, or both.” For the general case, we have:

 s = {x, y, z, …} if and only if x ∈ s or y ∈ s or z ∈ s, or …

 (Of course, inclusive disjunction is a binary connective, as we know: so, the 
successive outputs of inclusive disjunctions are then inclusively disjoined 
from the subsequent statement.)
We can define a set in three different ways. The one we have been relying on up 
to this point is the method we call Definition by Enumeration. We simply include 
within the set symbols “{” and “}” all the specified symbols referring to the objects-­
members of the set. We do not include a symbol more than once. It is understood 
certainly that all the member symbols are included but it might be thought that this 
presents insuperable problems for enumeration in the case of infinite sets – like, for 
instance, the positive integers. This is not so as the following example shows:
I+ = {1, 2, 3, …}
The three-periods symbol is used to indicate the continuation of the member list. 
Of course, what we have within the set brackets are numerals or specified symbols 
for the numbers but the members of the set are the numbers. It is obviously not an 
objection in set theoretical terms that a set may have an infinite number of members. 
We do accommodate infinite sets in our theory. What is not permitted is that there is 
vagueness as to whether any specified item is or is not a member of a given set. 
Thus, in the case of infinite sets too there is no vagueness as to whether, for instance 
the number denoted by the numeral “15” is a member of the set of positive integers 
or not. We note the absence of vagueness as to membership as follows: it is never a 
matter of degree whether an object is a member of a given set: either the object is or 
it is not a member of the set; it cannot be that “it sort of is a member;” it cannot be 
that the object is a member “to a degree x;” the object is a member absolutely or, if 
that is the case, it is not a member of the set absolutely. In applications, this means 
that a set like that of “tall people” has a sharply defined membership: we cannot 
hesitate as to whether someone who is 5 feet and 6 inches is or is not a member of 
the set; we must decide and either include such an object or exclude it from the set.
Another way of defining a set is the so-called Definition by Abstraction. Because 
of the discovery of paradoxes affecting set theory, abstraction is sometimes sub-
jected to restrictions. We will explain in due time but let us first show an example of 
a set defined by abstraction.
I+ = {x / x is a positive integer}
Sometimes this is symbolized:
I+ = {x: x is a positive integer}
Obviously,
I+ = {x / x is a positive integer} = {1, 2, 3, …}
This brings the first two methods of set definition together. We can write this out 
appealing to basic intuitions even though, notably, we have not officially defined 
equality of sets yet. Thus, abstraction is used to define a set by characterizing 
10.1  Definitions: Set, Membership, Distinguished Types of Sets; Ways of Defining…

412
unambiguously and without vagueness what property is exemplified by all, and 
only, the members of the set. Because of our principle of Extensionality – that a set 
is completely and adequately characterized by its members – we may run into the 
counterintuitive consequences we noted in our preceding example. For instance, we 
can have:

 FEMALE STUDENTS in CLASS X = = {x / x is a female student in class 
X} = {Mary, Jane, Dolores}

 HONORS STUDENTS in CLASS X = {x / x is an Honors student in class 
X} = {Mary, Jane, Dolores}

 It follows that: FEMALE STUDENTS in CLASS X = HONORS 
STUDENT in CLASS X

 Of course, the notions of the two properties – being a female student in a 
class and being an Honors student in that class – are distinct but we cannot 
capture that extensionally.
By a theoretical postulate, needed for constructing Set Theory, a set is definable 
for any meaningful property or attribute: this is called the Postulate of Specification 
and we can use our predicate logic resources to represent it metalinguistically as 
follows. Notice, however, that we cannot quantify over properties. We have:
•	 Postulate of Specification
For any meaningful property F, there is a definable set S, such that: S = 
{x / Fx}.
Finally, a set can be defined by Recursion or recursively. This is done we explic-
itly characterize or specify the items that are members of a set. For instance:
 If x is a geometric triangle, then x is a member of y.
 If x is a geometric square, then x is a member of y.
 If x is a geometric circle, then x is a member of y.
 Nothing else is a member of y. This defines the set y. (This last statement 
is called the Closure Clause.)
A theoretical issue that arises has to do with application of our notation to the 
designation of terms in a model theory like the one we used in our study of predicate 
logic. Since the variables from {x, y, …, x1, …} are used indifferently for members 
of sets as well as for sets, we might want to make appropriate accommodations for 
distinguishing the special case in which the referent is a term rather than a set. There 
are various possibilities.
•	 We can legislate that it is nonsensical to speak of membership in a term – 
which is, indeed, not a set. Metalinguistically, we indicate this as follows – 
with “⊥” as our symbol for logical nonsense (understood as an unassertable 
logical falsehood). This rule demarcates the terms from the sets. We notice 
also, in passing, the remarkable extent of our formal dependence on the notion 
of inclusion or membership in a set: this binary relation is elevated to a dis-
tinct place in our set-­theoretic formal language. It appears that we are able to 
10  Basics of Set Theory

413
construct our theoretical apparatus by using the specialized symbol of this 
relation in our formal language. Nevertheless, this is not a logical concept 
because it does not remain invariant across different models of the predicate 
logic: we may indeed assign different members to the same set across differ-
ent models.
○
○((x ∈ y) ∙ (y ∈ TERMS)) ⊃ ⊥
 If we preclude quantification over sets, we can symbolize our rule as 
follows – considering that only individual variables or terms are per-
missibly quantifiable:
 ((x ∈ y) ∙ ∃z(z = y)) ⊃ ⊥
•	 Another strategy we can devise to take us out of our predicament is this: if we 
are dealing with a term y, then inclusion in y is ruled to be a matter of identity 
of terms – y is identical with what is claimed to be its member. In the case in 
which it is denied that x is a member of y, with y being a term, then our rule 
entails that x and y are not identical. Thus, on this strategy, membership in a 
term is treated as identity of terms.
○
○((x ∈ y) ∙ (y ∈ TERMS)) ⊃ (x = y)
○
○((x ∉ y) ∙ (y ∈ TERMS)) ⊃ (x ≠ y)
Because it is always the case that x = x, we have:
(x ∈ TERMS) ⊃ (x ∈ x)
•	 The final strategy we may pursue rules that the term y, to which x is said to 
belong as member, is a term indeed (denying this would be nonsensical) and 
it is the sole member of the (singleton, one-member) set x.
○
○((x ∈ y) ∙ (y ∈ TERMS)) ⊃ x = {y}
 So, we have: (x ∈ TERMS) ⊃ (((x ∈ x) ⊃ (x = {x})) ⊃ ⊥)
Before we proceed, we may now define formally our distinguished types of set – 
the empty set and the universal set. Notice how this is done: by specifying, via 
abstraction, an absurd property which characterizes membership in the empty set 
(i.e. nothing can be a member, since nothing can possibly have this property) and 
characterizing membership in the universal set by means of a tautology or logi-
cal truth.
•	 ∅ = {x/ x ≠ x}
•	 ω = {x / x = x}
Set equality is what is called an equivalence relation: this is defined as a relation 
that is characterized by reflexivity, symmetry and transitivity. Equivalence relations 
have profound mathematical significance: applied to a given set, an equivalence 
relation partitions – as we say – the set into so-called equivalence classes. To grasp 
the significance of this, we may think of any equivalence relation as being conceptu-
ally akin (like a relative of) the identity relation: objects that are related by means of 
an equivalence relation are treated like the same with respect to some specified 
characteristic. This is ensured by the fact that the relation is reflexive, symmetric 
10.1  Definitions: Set, Membership, Distinguished Types of Sets; Ways of Defining…

414
and transitive. For instance, if we are treating similarity as an equivalence relation, 
all similar objects are placed in one class while dissimilar objects are placed in 
another. The equivalence class – which can be called also equivalence class modulo 
similarity – contains all the “same” objects, which are to be treated indifferently 
insofar as we are interested in picking some object from that class of similar objects. 
It might be that similarity is not transitive: can it be that an object x is similar with 
an object y but not necessarily with objects with which y is similar? Can similarity 
be attenuated? These are theoretical concerns; but insofar as similarity is regarded 
for specific purposes as transitive, then it is an equivalence relation and, as such, it 
can partition the given set on which it is applied.
•	 Reflexivity	
∀xRxx
•	 Symmetry 	
∀x∀y(Rxy ⊃ Ryx)
•	 Transitivity 	
∀x∀y∀z((Rxy ∙ Ryz) ⊃ Rxz)
We can ascertain that inequality is not an equivalence relation: it is not reflexive 
to being with, and it is not transitive either (for example, 2 is not equal with 3 and 3 
is not equal with 2 but 2 is equal with 2.) Being perpendicular is not an equivalence 
relation: it is not reflexive and it is not transitive, although it is symmetric. The rela-
tion less-or-equal is an equivalence: this relation is like the relation of subsethood or 
inclusion, which we study in the following section. The relation of being a member 
of a set is not an equivalence, and the same applies in the case of the not-being-a-­
member relation. We will attend to these in the exercises.
We will briefly return to this concept after we have defined other relevant set-­
theoretic concepts.
10.1.1  Exercises
	1.	 Justify your answers.
	
a.	 Can any object be a member of a set?
	
b.	 Is it always possible to determine, for a given set and a given object, if the 
object is a member of the set?
	
c.	 Can a set itself be a member of a set?
	
d.	 Can a set with set as a member, if that is possible, be a member of a set?
	
e.	 Can there be a set S such that, even if you know all of its members you still 
cannot define S?
	2.	 By definition, a set has to have discrete members, whose enumeration is suffi-
cient for the construction of the set; it must always be possible to tell if any 
specified object is or is not a member of a given set. What is the case, then, for 
purporting to define sets by abstraction, such that the property of the set-­members 
is logically absurd? Consider an example below and provide additional exam-
ples. Are such sets definable?
⋏ = {x/ x is both a circle and a square}
10  Basics of Set Theory

415
	3.	 Provide examples of pairs of sets which are equal with each other even though 
they are defined (by abstraction) by means of different properties. In what sense 
do such sets capture the meaning of the properties? Can we explain why they are 
equal even though they are defined by means of different properties? Why isn’t 
this a concern when it comes to the study of predicate logic?
	4.	 Determine if the denoted objects are members of the given sets or not. The val-
ues of the symbols, should be notationally indicated by the use of “| |”: those 
values are the denoted objects. (For instance, |2| denotes the number two.) 
­Nevertheless, bowing to standard notational conventions, we omit the vertical 
bar symbols.
[“∈?” as a metalinguistic symbol in this exercise asks the question about 
membership.]
	
a.	 2 [∈?] {x/ x is a natural number}
	
b.	 3 [∈?] {{3}, 1, 2, 3}
	
c.	 4 [∈?] {1, 2, 3, {4}}
	
d.	 5 [∈?] {x/ either x is 2, or x is 5}
	
e.	 φ [∈?] {ψ, χ}
	
f.	 ▭ [∈?] {△, ▭, ◊}
	
g.	 ↭ [∈?] {↫, ↬}
	
h.	 {∅} [∈?] {∅}
	
i.	 {∅} [∈?] {{∅}}
	
j.	 {{∅}} [∈?] {∅}
	
k.	 ∅ [∈?] ∅
	
l.	 ∅ [∈?] {∅}
	5.	 Define the following sets, given in extensional or enumeration definition, by 
abstraction and by recursion.
	
a.	 s1 = {1, a, 2, b}
	
b.	 s2 = {1, 2, …}
	
c.	 s3 = {2, 4, 8, 16, 32, …}
	
d.	 s4 = {□, ▭, △, ◊, ○}
	
e.	 s5 = {True, False}
	
f.	 s6 = {(,)}
	
g.	 s7 = {w, x, y, z}
	
h.	 s8 = {{∅}}
	
i.	 s9 = {∅}
	
j.	 s10 = {1, {1}}
	
k.	 s11 = ∅
	
l.	 s12 = {∅}
	6.	 Define the following sets, given by abstraction, by enumeration and by recursion.
	
a.	 s1 = {x/ x is a natural number}
	
b.	 s2 = {x/ x is a vowel of the English alphabet}
	
c.	 s3 = {x/ x is an object in front of you as you are reading this}
10.1  Definitions: Set, Membership, Distinguished Types of Sets; Ways of Defining…

416
	
d.	 s4 = {x/ x is the first President of the United States}
	
e.	 s5 = {x/ x is either a positive integer less than 10 or an odd integer greater than 
10 and less than 15}
	
f.	 s6 = {x/ x is both a natural number and an even number}
	
g.	 s7 = {x/ x is both a natural number and it is not an even number}
	
h.	 s8 = {x/ x = x}
	
i.	 s9 = {x/ x is a green object within your field of vision now}
	
j.	 s10 = {x/ x is a letter in the English alphabet not in the Chinese alphabet}
	7.	 Check, again, the following definitions of the empty and (contextually specified) 
universal set and consider alternative ways of defining those sets.
∅ = {x/ x ≠ x}.
ω = {x/ x = x}
	8.	 Prove that being-parallel, applied to a set of Euclidean lines, is an equivalence 
relation.
	9.	 Determine whether, and show that, the following relations (applied on appropri-
ate sets) are or are not equivalence relations:
	
a.	 equality
	
b.	 inequality
	
c.	 being-in-love-with
	
d.	 being-a-sibling-of
	
e.	 being-a-mother-of
	
f.	 less than
	
g.	 being a member of a set
	
h.	 not being a member of a set
	
i.	 having the same number of members
10.2  Subsethood, Power Set, Cardinality
A concept we need to define is that of subsethood. Other words used for this notion 
are “containment” and “inclusion.” A set can be a subset of another set, including of 
itself. Objects cannot be subsets of sets; only sets can be subsets of sets. Objects are 
members of sets, not subsets of sets. Subsethood is a relation between sets. We may 
wonder about constructability of a scheme by which a set can be a member of itself. 
This appears feasible notionally: since we have permitted abstraction as a method 
for defining a set, and we have invoked a postulate of specification, the only catch is 
whether self-inclusion or self-membership is a meaningful concept: and it seems 
that it is. Nevertheless, self-membership, and the inevitably definable parallel notion 
of lacking self-membership, land us into notorious set-theoretical paradoxes. We 
will attend to a brief examination of this topic subsequently. We could, indeed, and 
we might as well, block by fiat construction of a set that has itself as a member. The 
theoretical challenge remains, however, and we will see how it arises. It is more 
complicated, and beyond our present scope, to describe and discuss proposed 
10  Basics of Set Theory

417
solutions to the paradoxes of self-inclusion. Apparently, our legislative ban on self-­
inclusion may also count as a solution – but it has something forced about it since 
we are not outlawing abstraction as a method of defining a set and the concept itself 
of self-inclusion seems to be rather meaningful. We can even think of examples of 
sets that are members of themselves, as well as of other sets that are not members of 
themselves.
We may appeal to the problems presented by self-inclusion to discuss briefly 
another marked feature of Set Theory. We do not consider the option of an unquali-
fiedly or generally universal set. The universal set must be specified but this specifi-
cation is considered relative to given contextual purposes. Additional 
accommodations may be made for relatively restricted and unrestricted sets (for 
instance, taking the set of all physical objects as unrestricted and the set of humans 
as restricted) but under no circumstances do we permit ourselves stipulation of a set 
of everything. Such a set would have to be understood as including itself, leading to 
set-theoretical paradoxes.
A related, narrower, concept is that of proper subsethood. If not specified, it is to 
be assumed that general – not necessarily proper – subsethood is meant. At any rate, 
different symbols are used with “⊆” deployed to symbolize general subsethood and 
“⊂” used for the narrower relation of proper subsethood. We will now define these 
fundamental concepts of Set Theory and we will use for this purpose both English 
sentences and the predicate logic symbolism we have learned – since our metalan-
guage is enriched with the appropriate symbol.
Notice that, in defining the general notion of subset, nothing is said about y hav-
ing any additional members besides those that are in x. It may or may not. Of course, 
this means that every set is a subset of itself. All its members are, trivially, members 
of … itself. Also the empty set is a subset of every set. Let us try to see why: con-
sider the meaning of the sentence, “if t is a member of the empty set, then t is a 
member of some set – any set – x.” But the empty set has no members! Thus, the 
9
9 A set x is a subset of a set y if and only if all members of x are members of 
y; or – which is the same – if there is no member of x which is not in y.
9
9 A set x is a proper subset of a set y if and only if all members of x are 
members of y (which means that x is generally a subset of y) and, in addi-
tion, there is at least one member of y that is not a member of x.
○
○x ⊆ y ≡ ∀z(z ∈ x ⊃ z ∈ y) ≡ ~ ∃z(z ∈ x ∙ z ∉ y)
○
○If a set x is a subset of a set y, then we say that y is the superset of x. 
We may stipulate symbols for this too: x ⊆ y ≡ y ⊇ x
○
○x ⊂ y ≡ ∀z((z ∈ x ⊃ z ∈ y) ∙ ∃w(w ∈ y ∙ w ∉ x))
○
○A proper superset can be defined and symbolized analogously to the 
case of the general superset.
10.2  Subsethood, Power Set, Cardinality

418
antecedent of this sentence, “t is a member of the empty set” is necessarily false 
(because of the definition of the empty set.) If you recall the connective of material 
implication we studied in sentential logic, you must recall that when the antecedent 
is false then the implication statement is (vacuously) true. This is what happens in 
this case. The sentence above about the empty set being a subset of any set x is 
always true because its antecedent is false.
9
9 A set x is a proper subset of a set y if and only if all members of x are mem-
bers of y and there is at least one member of y that is not a member of x.
○
○x ⊂ y ≡ ∀z((z ∈ x ⊃ z ∈ y) ∙ ∃u(u ∈ y ∙ u ∉ x))
It follows from the definition of proper subsethood that no set can be a proper 
subset of itself. Also, regarding the empty set, it is a proper subset of every non-
empty set but it is generally a subset – not a proper subset – of itself. Another obser-
vation worth stressing is that membership – being a member or element of a set – is 
a distinct concept from subsethood (also called containment.) A set can be both a 
member and a subset of a given set – as we know by now, sets can indeed be mem-
bers. But these are two different characterizations of that set – one characteristic it 
has is being a member and the other is being a subset. The key is that a member of 
a set is an item that is in the set (and the set is nothing but the collection of its mem-
bers); whereas a set can be a subset of some set (possibly itself) if it meets the defi-
nitional criteria we presented above. We show certain illustrating examples.
•	 x = {0, {0}}	 y = {0}	
0 ∈ x, 0 ∈ y, {0} ⊆ x, {0} ∈ x, y ⊆ x, y ⊂ x
•	 x = ∅	
y = {∅}	
∅ ∈ y, ∅ ⊆ x, ∅ ⊆ y, ∅ ⊂ y
According to the so-called Trichotomy Principle, for any sets x and y, exactly 
one of three possible relationships is possible and one of them must be the case: x is 
a proper subset of y, y is a proper subset of x, or x and y are the same set.
∀x∀y((x ⊂ y) ∨ (y ⊂ x) ∨ (x = y))
We need to make certain that we grasp thoroughly the notional difference 
between membership and subsethood. A set has members which can be objects and 
can also be sets. A set has subsets and is also a subset of other sets (which can be 
called the supersets of the given set.) We show examples to consolidate 
understanding.
¾
¾ x = {1, 2, 3}
○
○1 ∈ x, 2 ∈ x, 3 ∈ x.
○
○{1} ⊂ x; {2} ⊂ x; {3} ⊂ x; {1, 2} ⊂ x; {1, 3} ⊂ x; {1, 2, 3} ⊆ x; ∅ ⊂ x.
¾
¾ This example has a set with sets as members. Notice again the distinction 
between being a member of the given set and being a subset of the given set.
¾
¾ y = {∅, {1}, {2}}
○
○∅ ∈ y; {1} ∈ y; {2} ∈ y.
○
○1 ∉ y; 2 ∉ y. ---- the sets are members, not the members of the 
member-sets.
○
○{∅} ⊆ y; {{1}} ⊆ y; {{2}} ⊆ y; {∅, {1}} ⊆ y; etc..
10  Basics of Set Theory

419
○
○∅ ⊆ y --- the empty set is a subset of any set. In this case, the empty set 
happens also to be a member of the set y. The set with the empty set as 
member is a subset of y. This example illustrates the distinction between 
membership and subsethood neatly.
¾
¾ The set that has as members all, and only, the subsets of a given set x is called 
the power set of x and is symbolized by “℘(x)”. The set x itself, and the empty 
set, are also members of the power set since they are subsets of x.
¾
¾ Example: x = {⫯, ⫰}
¾
¾ ℘(x) = {{⫯, ⫰}, {⫯}, {⫰}, ∅}
¾
¾ ℘({1}) = {∅, {1}}
¾
¾ ℘(∅) = {∅}
¾
¾ ℘({∅}) = {∅, {∅}}
The number of objects a set has is called the Cardinality of the set. If the cardi-
nality of a set x is n, then the cardinality of its power set ℘(x) is 2n.
10.2.1  Exercises
	 1.	 Prove that every set is a subset of the universal set.
	 2.	 Is any set a proper set of the universal set? Justify your answer.
	 3.	 Is any set a proper subset of the empty set? Justify your answer.
	 4.	 Can a set be a subset of itself? Can a set be a proper subset of itself? Justify your 
answers.
	 5.	 Given the following sets, which are subsets of which? Which are proper subsets 
of which?
	
a.	 ω = {1, 2, 3}
	
b.	 s1 = {1, 2}
	
c.	 s2 = {1, 2, 3}
	
d.	 s3 = {1, 3}
	
e.	 s4 = {2, 3}
	
f.	 s5 = {3}
	
g.	 s6 = ∅
	
h.	 s7 = {∅}
	 6.	 Answer the following questions:
	
a.	 {1, 2} [∈?] {1, 2, 3}
	
b.	 {1, 2} [∈?] {1, {1, 2}, {1, 2, 3}}
	
c.	 ∅ [∈?] {1, 2}
	
d.	 ∅ [∈?] {∅}
	
e.	 ∅ [∈?] {{∅}}
	
f.	 {1, 2} [⊆?] {1, 2, {1, 2}}
	
g.	 {1, 2} [⊆?] {{1}, {2}}
10.2  Subsethood, Power Set, Cardinality

420
	
h.	 {1, 2} [⊆?] {{1, 2}}
	
i.	 {1, 2} [∈?] ℘({1, 2, 3})
	
j.	 {1} [⊆?] ℘({1, 2})
	
k.	 ∅ [⊆?] ∅
	
l.	 ∅ [⊆?] {∅}
	
m.	 ∅ [∈?] ℘({∅})
	
n.	 ∅ [⊆?] ℘(∅)
	 7.	 Construct all the subsets of the given sets. Which of these are proper sets? 
Construct also the power set of each of the given sets.
	
a.	 s1 = {1, 2, 3, 4}
	
b.	 s2 = {1, {1}}
	
c.	 s3 = {1}
	 8.	 Answer the following questions pertaining to the given sets.
s1 = {1, {1}, 2}.
s2 = {{1, 2}, 1, 2}.
s3 = {1, 2}.
s4 = {1, {2}}
	
a.	 1 [∈?] s1
	
b.	 1 [∈?] s2
	
c.	 1 [∈?] s3
	
d.	 1 [∈?] s4
	
e.	 {1, 2} [⊆?] s1
	
f.	 {1} [⊆?] s3
	
g.	 {{2}} [⊆?] s4
	
h.	 To which sets does ∅ belong as a member?
	
i.	 To which sets does 2 belong as a member?
	
j.	 To which sets does {1} belong as a member?
	
k.	 To which sets does {2} belong as a member?
	
l.	 Of which sets is {1} a subset?
	
m.	 Of which sets is {1, 2} a proper subset/
	 9.	 Answer the questions pertaining to the two given sets.
s1 = {1, {1}, 2, {2}}.
s2 = {1, {2}}
	
a.	 Is s1 a member of s2? Is s2 a member of s1?
	
b.	 Is s1 a subset of s2 Is s2 a subset of s1?
	
c.	 Is s1 a proper subset of s2 Is s2 a proper subset of s1?
	10.	 Of which of the following sets is the empty set a member? Of which of the fol-
lowing sets is the empty a subset? Of which of the following sets is the empty 
set a proper subset? Answer the same questions for the set that has the empty set 
as its member.
s1 = ∅.
10  Basics of Set Theory

421
s1 = {∅}.
s1 = {{∅}}.
s1 = {∅, {∅}}.
s1 = {∅, {∅}, {{∅}}}
	11.	 Construct examples to show that it is possible for three sets x, y and z that:
	
a.	 x ∈ y, y ∈ z, x ∉ z
	
b.	 x ∈ y, y ⊆ z, x ∉ z
	
c.	 x ⊆ y, y ∈ z, x ⊈ z
	
d.	 x ∈ y, y = z, x ⊈ z
	12.	 Is subsethood an equivalence relation? Justify your answer.
	13.	 Can we define a relation of non-subsethood, presumably symbolized by “⊈”? 
What would it be defined, if it is definable? What about a relation of 
­non-proper-­subsethood, presumably symbolized by “⊄”? If such relations are 
definable, are they equivalence relations or not?
10.3  Ordered Pairs and Cartesian Products
9
9 We define an ordered pair as a collection of elements or members from a speci-
fied domain, arranged so that the order in which they are arranged is taken into 
account when writing the symbols that denote the members. We use “<” and “>” 
to enclose the symbols, separated by commas, and written in specifically charac-
terized order from left to right. For instance, if we want to represent the relation-
ship of larger as “x is larger than y”, this is the set of all pairs such that <x, y> 
where x symbolizes the object that is larger than the object symbolized by y.
○
○The notion of an ordered collection is generalized to n items, in which case 
the ordered collection is called an n-tuple. The case of only one item is degen-
erate but it is definable. For instance, if we speak of a relational predicate like 
“x is to the left of y” and define the set as {<x, y> / x is to the left of y}, then, 
by parity, we can symbolizer a monadic predicate extension set as, for 
instance, {<x> / x is a triangle}.
○
○The order in which member symbols are written in a set does not matter but 
for ordered pairs – and for ordered n-tuples in general – the order matters as 
we have seen. Let us notice now what this means for defining the notion of the 
equality of two ordered pairs. 
 An ordered pair <x, y> can be written as, and is considered identical 
with, the set: {{x}, {x, y}}.
 It can also be written as: <x, y> = {x, {x, y}}}
Intuitively, we can account for this set-theoretic arrangement, by consid-
ering a specified order, from left to right, of two distinguished objects 
denoted by “a” and “b” respectively.
 <x, y> = <u, v> if and only if x = u and y = v.
10.3  Ordered Pairs and Cartesian Products

422
a 
 b
One arrangement that can accommodate a notational convention for show-
ing order is by considering how many objects are to the left of each object 
(including the object itself in the tally): thus, to the left of the object denoted 
by “a” we have nothing; in the case of the object denoted by “b” we have 
both objects covered as we move to the left. Thus,
•	 left-a: {a}
•	 left-b: {a, b}
•	 ORDER(a, b) = {{a}, {a, b}}
•	 We may also write, as previously: {a, {a, b}}
•	 We can show that the condition laid down for determining equality of 
pairs is satisfied in this way. This is crucial for showing that this is a 
permissible notational arrangement.
•	 <x, y> = <u, v>	
Assumption
•	 x = u and y = v	
By definition of ordered pair 1
•	 {x} = {y}	
By definition of set equality 2
•	 {u} = {v}	
By definition of set equality 2
•	 {x, y} = {u, v}	
By def. of set equality	 3, 4
•	 {{x}, {x, y}} = {{u}, {u, v}}	 Def. set equality	
3, 4, 5
•	 Proceeding in the opposite direction, from bottom to top, we have:
•	 {{x}, {x, y}} = {{u}, {u, v}}	 Assumption
•	 {x} = {u}	
By definition of set equality 1
•	 {x, y} = {u, v}	
By def. Set equal. 1
•	 x = u	
By def. Set. equal. 2
•	 y = v	
By def. Set equal. 2, 3, 4
•	 <x, y> = <u, v>	
By definition of ordered pair 4, 5
As a corollary we have:
○
○<x, x> = {x, {x}}
○
○<x, x> ≠ <x>
○
○<x, y, y> ≠ <x, y>
9
9 In the case of an ordered triplet, we have:
○
○<x, y, z> = <<x, y>, z>
○
○Generalizing to the case of the ordered n-tuple, we have:
 <x1, …, xn> = {{x1}, {x1, x2}, …, {x1, x2, …, xn}}
9
9 We define as the Cartesian Product of two sets x and y, symbolized as “x ⤬ y”, 
the set of all definable ordered pairs such that the first member of each pair is 
from set x and the second member of each pair is from set y, taken in all possible 
combinations. Let us examine an example:
 x ⤬ y = {<u, w> / (u ∈ x) ∙ (w ∈ y)}
○
○{1, 2} ⤬ {a, b, c} = {<1, a>, <1, b>, <2, a>, <2, b>, <1, c>, <2, c>}
○
○Notice that, {a, b, c} ⤬ {1, 2} = {<a, 1>, <a, 2>, <b, 1>, <b, 2>, <c, 1>, 
<c, 2>} ≠ {1, 2} ⤬ {a, b, c}
10  Basics of Set Theory

423
○
○Of course, we can determine the Cartesian product of a set x by itself, 
which we write either as x ⤬ x or as x2. For instance:
○
○{△, ◊, ○} ⤬ {△, ◊, ○} = {<△, △>, <△, ◊>, <△, ○>, <◊, △>, 
<◊, ◊>, <◊, ○>, <○, △>, <○, ◊>, <○, ○>}.
We can generalize to the case of defining a n-ary Cartesian Product but, for our cur-
rent purposes, we will be confining ourselves to examination of binary relations only.
•	 y1 ⤬ y2 ⤬ … ⤬ yn = {<u, …, u> / (u1 ∈ y1) ∙ … ∙ (un ∈ yn)}
•	 Additionally, we have:
•	 ∅ ⤬ x = x ⤬ ∅ = ∅
•	 If x = ∅ or y = ∅, then x ⤬ y = y ⤬ x = ∅
•	 Generally:
•	 x ⤬ y ≠ y ⤬ x	
The Cartesian Product operation is not commutative
•	 If x ⊆ z and y ⊆ w, then (x ⤬ y) ⊆ (z ⤬ w)
•	 The converse obtains only if x ⤬ y ≠ ∅.
10.3.1  Exercises
	1.	 Are the following true or false?
	
a.	 <1, 2> = <2, 1>
	
b.	 <0, 1> = {{1, 0}, 1}
	
c.	 <∅, x> = {{∅}, {x}}
	
d.	 <x, ∅> = {{x}, {x, ∅}}
	
e.	 <x, y> ∈ {{x, y}, {x}}
	
f.	 <x, y> ⊆ {{x, y}, {x}}
	
g.	 {1, 2} ∈ <1, 2>
	
h.	 {{1}} ⊆ <1, 2>
	
i.	 {{1}} ∈ <1, 2>>
	2.	 Given the following sets, determine the requested Cartesian products.
s = {1, 2}.
t = {3, 4}.
u = {∅, {∅}}
	
a.	 s ⤬ t
	
b.	 s ⤬ s
	
c.	 u ⤬ u
	
d.	 t ⤬ s
	
e.	 u ⤬ t
	
f.	 u ⤬ s
10.3  Ordered Pairs and Cartesian Products

424
	3.	 Prove the following:
If x ⊆ z and y ⊆ w, then (x ⤬ y) ⊆ (z ⤬ w).
Conversely, (if (x ⤬ y) ⊆ (z ⤬ w), then x ⊆ z and y ⊆ w), but only if x 
⤬ y ≠ ∅.
	4.	 If the cardinality (number of members) of x is m and the cardinality of y is n, 
then what is the cardinality of x ⤬ y, and what is the cardinality of y ⤬ x? What 
is generally the cardinality of u ⤬ u if the cardinality of u is k?
	5.	 Why is it, generally, the case that x ⤬ y ≠ y ⤬ x? Find examples in which it so 
happens that s ⤬ t = t ⤬ s.
10.4  Set-Theoretic Operations
We can now define operations on set or, as we call them, set-theoretic operations. 
These operations are interpretations of corresponding functions of the standard 
Boolean algebra: the same is the case, as we have pointed out already, for the truth 
functions or connectives that are defined in the classical sentential logic we have 
studied. It is an interesting exercise to attempt to match set-theoretic operations with 
their corresponding sentential connectives which are also interpretations of the 
same Boolean functions; the connectives are defined with inputs from the product 
of the set of truth values {T, F} by itself ({T, F} ⤬ … ⤬ {T, F}) and with outputs 
from the set of truth values {T, F} as range. The product of the set of truth values by 
itself is taken n times when we speak generally of a connective of arity or degree n. 
For our familiar cases of unary functions the domain is just the set {T, F} and for the 
binary functions the domain is {T, F} ⤬ {T, F}. In the case of binary set-theoretic 
operations, the domain is Cartesian product of the set of the given sets and the range 
is the set of the given sets.
We continue with defining certain set-theoretical operations. One unary opera-
tion is defined and the rest are binary operations. The unary operation is called 
Complementation and symbolized by a “c” as superscript to the set symbol. (Other 
symbolizations include a prime as superscript on the set symbol and a straight line 
on top of the set symbol.)
OPERATION SYMBOLS = {c, −, ∪, ∩, ⊖}
9
9 Monadic operations are from the power set of the universal set to the power 
set of the universal set (meaning that the single input of the operation is a 
subset of the universal set and outputs are also subsets of the universal set.)
○
○℘(ω) ↦ ℘(ω)
9
9 Binary operations are from the Cartesian product of the power set of the uni-
versal set by itself to the power set of the universal set (meaning that inputs 
are subsets of the universal set and outputs are subsets of the universal set .) 
The generalized case of n-place operations is defined accordingly.
○
○(℘(ω) ⤬ ℘(ω)) ↦ ℘(ω)
10  Basics of Set Theory

425
9
9 The unary (or monadic) set-theoretic operation of complementation of set 
𝒳 is defined as taking as input the set x and yielding as output the set of all 
members of the specified universal set ω, which are not members of x. This 
set, of all and only the members of ω that are not members of x, is called 
the complement of x and symbolized with a “c” superscript. (Other sym-
bolizations in the literature include: “ x ” and “x’”.)
9
9 A set xc is the Complement of the set x if and only if its members are not 
members of x.
○
○xc ≝ {y/ y ∉ x}
 A moment’s worth of reflection will show that something more is 
needed for definition of the complementation operation. We need to 
know relative to what overarching collection of objects we deter-
mine whether an object is or is not in x. In other words, we need to 
establish a universe or universal set relative to which complementa-
tion is defined. It is understood in set-­theoretic discourse that a uni-
versal set, which we will symbolize as “ω”, is specified in every case. 
We do not expect the universal case to be specified as the same in all 
cases – or regardless of specific cases – because that would lead to 
contradictions as we would might have to include objects in the uni-
verse for certain applications, which are presumed excluded for 
other applications.
 We can now define complementation as follows:
•	 xc ≝ {y/ y ∈ ω ∙ y ∉ x}
○
○Examples:
 ω = {w/ w is a positive integer}, x = {w/ w is a positive 
integer and even} – xc = {w/ w is a positive integer and odd}
 ω = {□, ▭, △, ◊, ○}, y = {▭, □} -- yc = {○, ◊, △}
 x = ∅	
--- xc = ω (whatever the universal set is!)
 ∅c = ω
 ωc = ∅
 (xc)c = xcc = x	
	
Involution Property
•	 The Difference (also Relative Difference) between sets x and y, symbolized as “x 
− y”, is defined as the set z which contains as members all and only the members 
of x which are not members of y.
○
○x – y ≝ {z/ z ∈ x ∙ z ∉ y}
 The unary operation of complement we defined earlier can now be con-
ceptualized as the relative or binary complementation operation so that,
•	 xc = ω – x
Still, it is to be noted that complementation is a unary operation whereas 
difference or relative complementation is a binary operation.
The complement of a set x is the difference of that set from the universal 
set: we can call this Absolute Difference.
10.4  Set-Theoretic Operations

426
If the two sets x and y have no members in common or if the first set has 
no members that are not in the second set, then the difference between x 
and y is the set x. Obviously, if the first set is the empty set, then the dif-
ference is the empty set. The difference of a set y from the universal set 
always yields the same set as the complement of y. The difference 
between any set x and the empty set is the set x.
•	 Examples:
○
○x = {1, 2, 3}, y = {{1}, {2}, 3} -- x – y = {1, 2}
○
○x = {a, 1, {1}}, y = {{1}, a} -- x – y = {1}
○
○x – y ≠ y – x -- in the preceding example, y – x = ∅
○
○x = {a, b}, y = {1, 2}	
-- x – y = ∅
○
○x = ω, y = ω	
-- x – y = ∅
○
○x = ∅, y = ∅	
 -- x – y = ∅
○
○x = ∅, y = {1, 2, 3, …}	
 -- x – y = ∅
○
○x = {1, 2, 3, …}, y = ∅	
 -- x – y = {1, 2, 3, …}
9
9 The next binary operation we define is called Union of sets x and y and 
symbolized as “x ∪ y”: the union of sets x and y is the set z which contains 
as its members all the members of x and all the members of y: but notice 
how we are to express this (showing in this way the correspondence 
between the set-theoretic operation of union and the sentential connective 
inclusive disjunction, both of which are interpretations of the same Boolean 
function.) A set z is the union of sets x and y if and only if for any member 
of z, it is either a member of x or a member of y or both.
 x ∪ y ≝ {z/ z ∈ x ∨ z ∈ y}	 -- inclusive disjunction, symbolized 
by the wedge, means “either one or the other or both.”
 The union of the universal set with any set yields the universal set.
 The union of the empty set with any set x yields the set x. [Notice 
that we are speaking of the union both as the operation and as the 
result of the operation: we trust that the ambiguity is removed on 
the basis of the context; if we were bulding a strict formal lan-
guage, we would have to be taking pains to occlude such sources 
of ambiguity.]
 The union of any set with itself is the set itself. After all, the cor-
responding sentential connective of inclusive disjunction has the 
property we have called idempotence in other sections of this text: 
the same ought to be expected for the set-theoretic operation that 
interprets the associated Boolean function.
○
○Examples:
 x = {1, 2}, y = {a, b}	 -- x ∪ y = {1, 2, a, b}
 x = {△, ◊}, y = {○, △}	
 -- x ∪ y = {△, ○, ◊}
 x = {w/ w is an even positive integer}, y = {w/ w is an odd 
positive integer}	
-- x ∪ y = {w/ w is either an odd or an 
even positive integer} = I+
 x = ω, y = {□, ▭}	
-- x ∪ y = ω (regardless of what the 
universal set is!)
10  Basics of Set Theory

427
9
9 The next binary operation we define is called Intersection or Overlap of 
sets x and y and symbolized as “x ∩ y”: the intersection of sets x and y is 
the set z which contains as its members exactly the members which are 
common to, or shared by, x and y: but notice how we are to express this 
(showing in this way the correspondence between the set-theoretic opera-
tion of intersection and the sentential connective conjunction, both of 
which are interpretations of the same Boolean function – the Boolean mul-
tiplication.) A set z is the intersection of sets x and y if and only if for any 
member of z, it is both a member of x and a member of y.
 x ∩ y ≝ {z/ z ∈ x ∙ z ∈ y}	
-- conjunction, symbolized by the dot, 
means “both.”
 The intersection of the universal set with any set x yields the set x.
 The intersection of the empty set with any set x yields the empty set.
 The intersction of any set with itself is the set itself. After all, the cor-
responding sentential connective of conjunction has the property we 
have called idempotence in other sections of this text: the same ought to 
be expected for the set-theoretic operation that interprets the associated 
Boolean function.
 If two sets have no common or shared members, then their intersection 
is the empty set.
○
○Examples:
 x = {1, 2}, y = {a, b}	
-- x ∩ y = ∅
 x = {△, ◊}, y = {○, △}	
-- x ∩ y = {△}
 x = {w/ w is an even positive integer}, y = {w/ w is an odd posi-
tive integer}	
-- x ∩ y = {w/ w is both an 
odd and an even positive integer} = ∅
 x = ω, y = {□, ▭}	
-- x ∩ y = {□, ▭}
Boolean 
Properties 
of 
the 
Set-Theoretic 
Operations 
Complement, Union and Intersection – taken together with the 
Universal Set and the Empty Set
○
○∅c = ω	
	
Complement of the Empty Set
○
○ωc = ∅	
	
Complement of the Universal Set
○
○(xc)c = x	
	
Involution Property
○
○x ∪ y = y ∪ x	
	
Commutative Property ∪
○
○x ∩ y = y ∩ x	
	
Commutative Property ∩
○
○(x ∪ y) ∪ z = x ∪ (y ∪ z)	
Associative Property ∪
○
○x ∩ (y ∩ z) = (x ∩ y) ∩ z	
Associative Property ∩
○
○x ∪ x = x	
	
	
Idempotent Property ∪
○
○x ∩ x = x	
	
	
Idempotent Property ∩
○
○(x ∩ y)c = xc ∪ yc	
	
DeMorgan Property
○
○(x ∪ y)c = xc ∩ yc	
	
DeMorgan Property
(continued)
10.4  Set-Theoretic Operations

428
 The operations of union and intersection of two sets are so-called 
mutual duals – each other’s dual. The concept of duality comes up sys-
tematically in the study of Boolean algebra and its interpretations – with 
Set Theory being an area of fertile application of Boolean algebra. We 
have a phenomenon of duality of certain notions when we can inter-
change such notions throughout and systematically and having as a 
result an expression that is also true insofar as the initial sentence was 
true. In the definitions of logical concepts, and insofar as such logic-
words can be studied by means of Boolean logic, interchanging system-
atically “either/or” and “both” along with “true” and “false” results in a 
true statement insofar as the initial statement was true.
 For instance, “p or not-p is true” yields “p and not-p is false:” we inter-
changed “either-or” and “and” along with “true” and false” and the ini-
tial logical law yielded again a logical law. Notice that “not” is not 
changed with anything (“not” is its own self-dual, as we say.) This is an 
amenity that is to our significant advantage because, once we are in pos-
session, having proved or determined, a logical law, we can automati-
cally obtain the dual law (the dual statement, which is guaranteed to be 
a law.) We say that we dualize and, in so doing, we obtain another law 
(the dual law) from a given law.
 In set theory, dualization requires interchanging “union” and “intersec-
tion” and of the symbols for the empty set and the universal set, while 
the complement is its own dual.
 We can also show certain characteristic equations of the set-theoretic 
system and we note how systematic interchanges of the symbols “∪” 
and “∩” along with the symbols for the empty and universal set, which 
are the zero and the unit of the theory, “∅” and “ω”, generate valid 
equations from valid equations (in other words, both duals are valid).
 We see, for instance, that the union of a set and its complement is the 
universal set. We italicize the terms that are subject to interchange on 
the basis of duality. The dual is also valid: The intersection of a set and 
its complement is the empty set. The dual of intersection is union – and 
(continued)
○
○x ∩ (y ∪ z) = (x ∩ y) ∪ (x ∩ z)	
Distributive Property 
(intersection over union)
○
○x ∪ (y ∩ z) = (x ∪ y) ∩ (x ∪ z)	
Distributive Property 
(union over intersection)
○
○x ∩ (x ∪ y) = x ∪ (x ∩ y) = x	 Absorptive Property
○
○x ∪ ∅ = ∅ ∪ x = x	 	
Neutral Element ∪
○
○x ∩ ω = ω ∩ x = x	
	
Neutral Element ∩
○
○x ∪ ω = ω ∪ x = ω	
	
Universal Set with ∪
○
○x ∩ ∅ = ∅ ∩ x = ∅	 	
Empty Set with ∩
○
○x ∪ xc = ω	 	
	
Excluded Middle
○
○x ∩ xc = ∅	 	
	
Non-Contradiction
10  Basics of Set Theory

429
vice versa, since duality is a symmetric notion. The dual of the universal 
is the empty set, and vice versa. One of the equations explicates the 
characteristic property of distributivity – and, by duality, we have both 
distributivity of union over intersection and of intersection over union. 
Or, notice the interchange of universal with empty in: the complement 
of the universal is the empty set and, by duality, the complement of the 
empty set is the universal set. (As indicated above, the complement is 
its own dual or it is self-dual, as we say: we can think of being inter-
changed degenerately, if we wish…) Also, the universal set serves as a 
unit and the empty set serves as a zero for the corresponding equations: 
the union of a set x with the empty set yields the set x; the intersection 
of a set x with the universal set yields the set x. We detect duality here 
too. And so on…
○
○x ∪ xc = xc ∪ x = ω	 [dual]	
	
x ∩ xc = xc ∩ x = ∅
○
○ωc = ∅	
	
	
[dual]	
	
 ∅c = ω
○
○x ∪ ∅ = ∅ ∪ x = x	 [dual]	
	
x ∩ ω = ω ∩ x = x
○
○x ∪ ω = ω ∪ x = ω	
[dual]	
	
x ∩ ∅ = ∅ ∩ x = ∅
○
○(x ∪ y)c = xc ∩ yc	
[dual]	
	
(x ∩ y)c = xc ∪ yc
○
○x ∪ (y ∩ z) = (x ∪ y) ∩ (x ∪ z) [dual]
○
○x ∩ (y ∪ z) = (x ∩ y) ∪ (x ∩ z).
9
9 Another binary operation is the one called Symmetric Difference, symbolized by 
“⊖” (or sometimes by “⊕”, by “+”, or by “△”), and corresponding to the sen-
tential connective of disequivalence (usually omitted from textbook presenta-
tions): these are interpretations of the associated Boolean operation which in 
chapter 9 we called addition modulo-2. (In the context of the sentential logic, 
which also serves, as we know by now, as an interpretation or model of the 
Boolean algebra, the Boolean function can also be interpreted as negated equiva-
lence and as a matter of linguistic rendering it corresponds to the exclusive 
either-or of a natural language like English.)
○
○The symmetric difference of sets x and y is the set z which is the union of the 
difference of y from x and of the difference of x from y: otherwise, but equiva-
lently defined, the symmetric difference of x and y is the set z which is the 
union of the intersection of x and of the complement of y and of the intersec-
tion of the complement of x and of y. Another way of defining symmetric 
difference  – equivalently and perhaps more easily comprehensible at first 
glance – is as the set of the members of x and y, which are in the union of x 
and y but not in the intersection of x and y.
 x ⊖ y ≝ (x ∩ yc) ∪ (xc ∩ y) = (x − y) ∪ (y − x) = (x ∪ y) − (x ∩ y)
 The dual of the symmetric difference is equality of sets! This gives us 
another way, by duality, for defining set equality:
•	 x = y ≝ (x ∪ yc) ∩ (xc ∪ y)
•	 The symmetric difference of any set and itself is the empty set.
10.4  Set-Theoretic Operations

430
○
○x ⊖ x = (x ∩ xc) ∪ (xc ∩ x) = ∅ ∪ ∅ = ∅
○
○One of the definitions of symmetric difference requires specification 
of the universal set, since the complements of the sets are in the 
­definition: if we are using the definition based on the differences of 
the sets x and y, then we take as universal set the union of the set 
x and y.
 Examples:
 x = {1, 2}, y = {1, 2, 3}	
 -- x ⊖ y = (x − y) ∪ (y − x) = ∅ ∪ {3} = {3}
 x = y = {a, b}	
	
-- x ⊖ y = ∅
 x = ω, y = ∅	
	
-- ω ⊖ ∅ = (ω ∩ ∅c) ∪ (ωc ∩ ∅) = (ω ∩ ω) ∪ 
(∅ ∩ ∅) = ω ∪ ∅ = ω
○
○x ⊖ y ≝ (x – y) ∪ (y – x)
 x ⊖ y = y ⊖ x	
Commutative Property of Symm. Diff.
 x ⊖ (y ⊖ z) = (x ⊖ y) ⊖ z	
Associative Property of Symm. Diff.
 x ⊖ x = ∅	
Symmetric Self-Difference
 x ⊖ ∅ = ∅ ⊖ x = x	
The Empty Set as Neutral Element for 
Symmetric Difference (SD)
 x ⊖ ω = ω ⊖ x = xc	
Complementation defined in terms of SD
 x = y if and only if x ⊖ y = ∅	
Equality and Symmetric Difference
 x ⊖ y ⊖ z = 0 if and only if x = y ⊖ z if and only if y = x ⊖ z if and only 
if z = x ⊖ y	
Equations with SD
 x ∪ y = x ⊖ y ⊖ (x ∩ y)	
Union Defined in Terms of SD and 
Intersection
 x ⊖ y = (x ∩ yc) ∪ (xc ∩ y) = (x − y) ∪ (y − x) =
 (x ∪ y) − (x ∩ y)	
Alternative Definitions of SD
Relationships between Symmetric Difference and other Set-Theoretic Operations
¾
¾ x ∩ (y ⊖ z) = (x ∩ y) ⊖ (x ∩ z)
9
9 There is a deep relationship between subsethood and the set-theoretic operations 
we have defined. The following expressions are all true (presented as open sen-
tence, with unbounded variables.) 
9
9 Distributive Interactions involving Set-Theoretic Operations and Cartesian 
Products
(x – y) – z = (x – z) – (y – z)
(x ∪ y) ⤬ s = (x ⤬ s) ∪ (y ⤬ s)
(x ∩ y) ⤬ (s ∩ t) = (x ⤬ s) ∩ (y ⤬ t)
(x – y) ⤬ s = (x ⤬ s) – (y ⤬ s)
x ⊆ y.
x ∩ yc = ∅.
xc ∪ y = ω.
x ∩ y = x.
x ∪ y = y.
yc ⊆ xc.
10  Basics of Set Theory

431
To prove equations, we may take advantage of the following equations:
x – y = x ∩ yc
x ⊖ y = (x ∩ yc) ∪ (xc ∩ y) = (x − y) ∪ (y − x) = (x ∪ y) − (x ∩ y)
¾
¾ A concept we examined in 10.1 can be addressed again briefly now. We defined 
as an equivalence relation one that is reflexive, symmetric and transitive. We 
study relations systematically in 10.7, but, having examined set-theoretic opera-
tions, we can add more information about equivalence relations.
9
9 The partition of a universal set by means of an equivalence relation is to congru-
ence classes which are mutually exclusive (pairwise disjoint or having the empty 
set as their intersection) and jointly exhaustive (having the universal set as their 
union.) Another term used instead of partition is decomposition.
9
9 Conversely, any partition or decomposition is characterized by a definable equiv-
alence relation. Note the definition of decomposition: a set of sets 𝑋 is a decom-
position of a given non-empty set 𝑌 if and only if the members of 𝑋 are mutually 
exhaustive (any two have the empty set as their intersection) and jointly exhaus-
tive with respect to 𝑌 (all of them have 𝑌 as their union.) Therefore, a decomposi-
tion is always induced by an equivalence relation (a relation that is reflexive, 
symmetric, and transitive):
○
○Condition for Reflexivity of relation 𝜌: ∀x(x ∈ Ω ⊃ 𝜌xx)
○
○Condition for Symmetry of relation 𝜌: ∀x∀y((x ∈ Ω ∧ y ∈ Ω) ⊃ (𝜌xy ⊃ 𝜌yx))
○
○Condition for Transitivity of relation 𝜌: ∀x∀y∀z((x ∈ Ω ∧ y ∈ Ω ∧ z ∈ Ω) ⊃ 
((𝜌xy ∧ 𝜌yz) ⊃ 𝜌xz))
For example, we define the concept of equality-modulo-2 over the set of positive 
integers including zero, Z+0, as follows, with the minus-symbol denoting the 
familiar arithmetical subtraction:
 0 ~2 2 given that 2–2 = 0 = 2 k, k = 0 ∈ Z+0
 1 ~2 3
 2 ~2 2 ~2 0
 3 ~2 1
 4 ~2 2 ~2 0
 etc.….
•	 ~2 is an equivalence relation:
○
○∀x(x ∈ Z+0 ⊃ x ~2 x)
○
○∀x∀y((x ∈ Z+0 ∧ y ∈ Z+0) ⊃ (x ~2 y ⊃ y ~2 x))
○
○∀x∀y∀z((x ∈ Z+0 ∧ y ∈ Z+0 ∧ z ∈ Z+0) ⊃ ((x ~2 y ∧ y ~2 z) ⊃ 
x ~2 z))
○
○~2 induces a partition on. Z+0, which can be represented as:
•	 Z+0 = {[0], [1]}
 ∀x(x ∈ Z+0 ⊃ (x ∈ [0] ∨ x ∈ [1]))
 Z+0 = [0] ∪ [1]
 [0] ∩ [1] = ∅
x = y(modulo 2) or x ~2 y if and only if x – y = 2 k, k ∈ Z+0
10.4  Set-Theoretic Operations

432
10.4.1  Examples
We show examples of how to prove claims about set-theoretic operations. We note 
the correspondences to sentential connectives which allow us to define by abstrac-
tion the operations: union corresponding to inclusive disjunction, intersection to 
conjunction, complementation to negation; relative difference of y from x corre-
sponds to the intersection of x with the complement of y; symmetric difference 
corresponds to the sentential connective called exclusive disjunction or disequiva-
lence and has been defined so that the symmetric difference between x and y is 
equivalent with the union of the conjunction of xyc and the conjunction xcy.
For the proofs, we take advantage of the properties of the sentential connectives – 
for instance, Idempotence of inclusive disjunction and of conjunction, commutative 
and associative properties, double negation, DeMorgan properties, and so on. It is 
always assumed that the elements are members of the universal set: this is implied 
and not showed but a more strictly formulated proof would show that the random 
member defining a set is assumed to be a member of the specified universal set.
	1.	 Proof of the claim that the union of a set x and itself is equal to the set x.
x ∪ x = {y/ y ∈ (x ∪ x)} = {y/ y ∈ x ∨ y ∈ x} = {y/ y ∈ x} = x
	2.	 Proof of the claim that the complement of the union of x and y is equal to the 
conjunction of the complement of x and the complement of y.
(x ∪ y)c = {u/ u ∈ (x ∪ y)c} = {u/ ~ u ∈ (x ∪ y)} = {u/ ~ (u ∈ x ∨ u ∈ y)} = 
{u/ ~ u ∈ x ∙ ~ u ∈ y} = {u/ u ∉ x ∙ u ∉ y} = {u/ u ∉ x} ∙ {u/ u ∉ y} = xc ∩ yc
	3.	 Proof of the claim that the relative difference of x and y (y from x) is equal to the 
intersection of x and of the complement of y.
x – y = {u/ u ∈ x ∙ u ∉ y} = {u/ u ∈ x} ∩ {u/ y ∉ y} = x ∩ yc
	4.	 Proof of: x – (y – x) = x. We use what we have already proven in 3. We also use 
the DeMorgan equation, distributivity of intersection over union, involution and 
the absorptive property.
x – (y – x) = x – (y ∩ xc) = x ∩ (y ∩ xc)c = x ∩ (yc ∪ xcc) = x ∩ (yc ∪ x) = x.
	5.	 Prove that, if x ∩ y ≠ ∅, then x – y ⊂ x.
It is a good idea to use contraposition: if we can prove the contrapositive of the 
given conditional proposition, then we have proven what is requested. Moreover, we 
can always, in the context of using informal proofs along these lines, apply the 
method we have studied as Indirect Proof method (which is also known as Proof by 
Contradiction and by the Latin term reductio ad absurdum.) We start with the con-
trapositive and proceed with the proof as follows:
	1.	 If x – y ⊄ x, then x ∩ y = ∅
	2.	 or, if x – y ⊇ x, then x ∩ y = ∅
	3.	 x – y ⊇ x if and only if x – y ⊃ x or x – y = x (by definition of superset)
	4.	 it is not possible that x – y ⊃ x (by definition of difference and superset)
	5.	 x – y = x (from 3 and 4)
	6.	 No common elements for x and y (by definition of difference)
	7.	 x ∩ y = ∅ (from 6 and by definitions of intersection and empty set)
10  Basics of Set Theory

433
10.4.2  Exercises
	 1.	 For the given sets, carry out the specified set-theoretic operations.
ω = {1, 2, 3, 4}.
x = {1, 2, 3}.
y = {3, 4}.
s = {1, 4}.
t = {2, 3}
	
a.	 x ∪ (s ∩ t)
	
b.	 x ∪ yc
	
c.	 (x ∪ y)c ∩ sc
	
d.	 (s ∩ t) ∪ (xc ∪ yc)
	
e.	 (x ∪ y) – (s ∩ t)
	
f.	 (y ∩ t)c ∪ (x ∪ s)c
	
g.	 (s ∩ (y ∪ t))c
	
h.	 (x – yc) ∩ y
	
i.	 (x ∪ (yc – x)) ⊖ (s ∪ t)
	
j.	 xc ⊖ (y ∪ (s ∩ t))
	 2.	 Carry out the specified set-theoretic operations.
	
a.	 ∅c ∪ {∅}
	
b.	 {{∅}} ∩ {∅}
	
c.	 ∅ ⊖ ∅
	
d.	 {∅} – ∅
	
e.	 ω ⊖ ∅
	
f.	 ({∅} ∩ ∅)c ∪ (∅ ∪ {∅})
	 3.	 Prove that the intersection of a set x and the empty set is the empty set.
	 4.	 Prove that the intersection of a set x and the universal set is the universal set.
	 5.	 Prove that the intersection of a set x and the empty set is the set x.
	 6.	 Prove that the union of a set x and the universal set is the universal set.
	 7.	 Prove the distributive laws for union and intersection.
	 8.	 What are the answers? Justify.
	
a.	 ∅ – ∅ =?
	
b.	 x – ∅ =?
	
c.	 ∅ ∩ {∅} =?
	
d.	 ∅ ∪ {∅} =?
	
e.	 {∅} ⊖ x =?
	
f.	 {∅} – ∅ =?
	
g.	 {∅, ∅} – {{∅}} =?
10.4  Set-Theoretic Operations

434
	 9.	 Does relative difference distribute over union? In other words, is either of the 
following true? What about the case of distribution of relative difference over 
intersection?
x – (y ∪ z) = (x – y) ∪ (x – z).
x – (y ∩ z) = (x – y) ∩ (x – z)
	10.	 Prove the following inclusions. For an inclusion of x in y, we have the conditions:
x ⊆ y if and only if xyc = ∅, iff x ∪ y = y, iff x ∩ y = y, iff xc ∪ y = ω.
	
a.	 x – y ⊆ x
	
b.	 x – (y ∪ z) ⊆ x –(y ∩ z)
	
c.	 (x ∩ y) – z ⊆ (x ∪ y) – z
	11.	 Proper inclusion can be defined as:
x ⊂ y if and only if (x ⊆ y ∙ x ≠ y).
Prove the following.
	
a.	 If x ⊂ y, then ~ (y ⊆ x)
	
b.	 ~ (x ⊂ x)
	
c.	 If x ⊂ y and y ⊂ z, then x ⊂ z
	
d.	 If (x ∩ y) ⊂ x, then x ≠ y
	
e.	 If x ∩ y ≠ ∅, then (x – y) ⊂ x
	12.	 Prove the following equations. Some of them involve the Cartesian product, 
whose definition was given, and about which properties were proven, in the 
preceding section.
	
a.	 (xc)c = x
	
b.	 ωc = ∅
	
c.	 x ∪ (y ∩ z) = (x ∪ y) ∩ (x ∪ z)
	
d.	 x ⊖ y = y ⊖ x
	
e.	 x – (x – y) = x ∩ y
	
f.	 (x – y) – x = ∅
	
g.	 (x – y) – y = x – y
	
h.	 x ∩ (y ⊖ z) = (x ∩ y) ⊖ (x ∩ z)
	
i.	 (x – y) – z = (x – y) – (x – z)
	
j.	 (x ∪ y) ⤬ s = (x ⤬ s) ∪ (y ⤬ s)
	
k.	 (x ∩ y) ⤬ (s ∩ t) = (x ⤬ s) ∩ (y ⤬ t)
	
l.	 (x – y) ⤬ s = (x ⤬ s) – (y ⤬ s)
	
m.	 (x ∩ y) ∪ z = x ∩ (y ∪ z) if and only if z ⊆ x (z ∩ xc = ∅)
	13.	 Use the Boolean equations to simplify the following expressions. Eliminate all 
but the symbols for complementation, union and intersection as you proceed. 
Also ensure that complementation is applied only to atomic variables. (What 
you obtain at the end of a successful transformation is called a normal form.) 
Because union and intersection are associative, we can omit parentheses when 
we have successive union or intersection symbols, since no ambiguity results. 
For example, we may write
10  Basics of Set Theory

435
x ∪ y ∪ z
instead of.
(x ∪ y) ∪ z
	
a.	 x ∪ (xc ∩ y)
	
b.	 xc ∩ (x ∪ y)
	
c.	 (x ∪ y)c ∪ (xc ∩ yc)
	
d.	 (x ∩ yc) ∪ (x ∩ y)
	
e.	 (x ∩ yc) – (yc ∩ (x – y))
	
f.	 (xc ∩ y ∩ zc)c ∪ (x ∩ y ∩ z)c
10.5  The Zermelo-Fraenkel Systematization of Set Theory

 Let us take stock of what has been stipulated, adding as needed more stipulations 
that are foundational. The Zermelo-Fraenkel theory axioms, which often appear 
in advanced textbooks, make such stipulations on the basis of intuitive notions 
about sets. You will notice that the existence – which is constructability – of 
certain types of sets is stipulated axiomatically; of course, we think that we can 
appeal to intuitions in order to justify such stipulations (as, for instance, in the 
case of the existence of an empty set which is by definition the set without any 
members.) Some of the other existential stipulations might strike you as unnec-
essary but this is only because you have not yet embarked on a sustained study 
of set theory. In the course of presenting some of these stipulations, you will also 
become familiar with some of the definable set-theoretic operations – but there 
are more to be defined later. A detail we should mention is that some of the axi-
oms might be deducible from other axioms - which means that they are not inde-
pendent, as we say – but this theoretical refinement is of no concern given our 
present purposes.

 Sets are abstract objects, definable by the methods we have indicated: enumera-
tion, abstraction, and recursion.

 The members of a set need not be related to each other.

 For any specified object whatsoever, it is possible in principle to determine 
whether this object is or is not a member of a defined set.

 An object can only either be or not be a member of a given set: the notion of 
vague membership – degrees of being a member – is not understood in this the-
ory! The law of sentential logic we have examined as the Law of Excluded 
Middle has in this context a set-theoretic expression:
○
○∀x∀y(x ∈ y ∨ x ∉ y)

 Any object, including a set, can be a member of a set. But a restriction on this 
follows.

 A set cannot be a member of itself. This restricts the preceding postulate so that 
now we have to say that any member, except for the set itself, can be a member 
of a set.
10.5  The Zermelo-Fraenkel Systematization of Set Theory

436
○
○∀x(x ∉ x)
○
○Another way of stating the restriction is this: for any set x, which is not the 
empty set, any member of any of its members cannot be a member of the set x.
 ∀x(x ≠ ∅ ⊃ ∃y(y ∈ x · ∀z(z ∈ y ⊃ z ∉ x))
Axiom of Foundation
 This restriction blocks a foundational paradox, known as the Russell 
Paradox; discovery of this paradox undermined ambitious projects in the 
history of mathematics, whose completion depended on using a reliable, 
paradox-free set theory. The Russell paradox is generated once we admit 
that we can use abstraction – which is intuitively admissible as a method 
for defining sets – and we define by abstraction a set whose members are, 
by definition, sets that are not members of themselves. Self-membership is 
itself an apparently well-behaved notion: for instance, the book that com-
prises as texts the texts of all books – regardless of the practical difficulties 
of constructing it – is conceivable and this book is conceptually a member 
of itself (the book of all books.) Abstraction allows us to capitalize imme-
diately on conceivability in order to claim that such a set can be defined. 
The problem, however, emerges once we similarly start by defining the set 
of all sets that are not members of themselves and then ascend to another 
step, which appears perfectly legitimate – of constructing the power set of 
this set, which is the set of all sets that are not members of themselves. 
Then, we come across the infamous paradox: if the statement “the set of all 
sets that are not members of themselves is a member of itself” is true then 
it follows from that this statement is also false because having the property 
“not being a member of itself” entails that the set is not a member! But it 
is essential also that we can proceed in the contrary direction: if the state-
ment “the set of all sets that are not members of themselves is a member of 
itself” is false, then it is true since, after all, our set is said to have the 
property of not being a member of itself. The problem then is: our state-
ment, which we can symbolize metalinguistically as “⋌”, is false if it is 
true; and it is true if it is false: but this logical equivalence of a true with a 
false statement is unacceptable since we have exactly two distinct truth 
values (true and false.) There are proposed solutions, which are controver-
sial and discussed extensively. You may guess from the last sentence in 
characterizing the problem that one such solution assigns to the problem-
atic statement a non-classical truth value (something other than true or 
false, and something that is still to be accepted semantically as a value.)
•	 ⋏ = {x / x ∉ x}
○
○⋌: x ∈ x ⇒ x ∈ {x / x ∉ x} ⇒ x ∉ x ⇒ ~ ⋌
○
○~ ⋌: x ∉ x ⇒ x ∉ {x / x ∉ x} ⇒ x ∈ x ⇒ ~ ~ ⋌ ⇒ ⋌
•	 ((⋌ ⊃ ~ ⋌) ∙ (~ ⋌ ⊃ ⋌)) ≡ (⋌ ≡ ~ ⋌) [!]
 Another method that is available for preventing the mischief 
caused by paradoxical self-referential cases of abstraction is 
10  Basics of Set Theory

437
due to the celebrated mathematician von Neumann. This 
approach enforces a sharp distinction between characterizing a 
property like self-membership and the property of being a 
member of some set. Thus, the appropriate way of expressing 
by abstraction lack of self-membership as a property (which, 
as we have seen, engenders the paradoxical outcome), is this: 
“the set of all x, such that there is some y so that x is a member 
of y and x is not a member of itself.” In this fashion, the 
abstraction characterization differentiates between the defin-
ing fact about being-a-­member of some set, on the one hand, 
and having the troublesome property of non-self-membership, 
on the other. We can spell this out in the predicate-logic nota-
tion we have been using in our metalanguage, using as symbol 
of this type of set ⋏:
 ⋏ = {x / ∃y(y ∈ x ∙ x ∉ x)}
 Let us see how the previously problematic sentence denoted by ⋌ is 
to be interpreted in this modeling of our situation:
•	 ⋌: x ∈ x ⇒ x ∈ {x / ∃y(x ∈ y ∙ x ∉ x)} ⇒
(x ∈ x ≡ (∃y(x ∈ y) ∙ x ∉ x)) ≡ ⊥.
We allow ourselves the symbol “⊥” for the constant or fixed-
value sentence, with false as its fixed truth value. In other words, 
we now obtain a sentence that is logically equivalent with the 
false-sentence  – or, is logically necessarily false based on the 
adjustment we have made to the definition of abstraction by 
imposing the membership restriction presented above. Thus, 
we have:
(x ∈ x ≡ (∃y(x ∈ y) ∙ x ∉ x)) ≡ ⊥ ⇒
~ ∃y(x ∈ y) ≡ ∀y(x ∉ y).
A consequence of our restriction  – and the way in which the 
recalcitrant property is allowed – is that such a set cannot be a 
member of any set.

 The order with which the symbols for the members of the set are written is ines-
sential for the representation of the set.

 Two sets are identical if and only if all members of either one are members of 
the other.
○
○∀x∀y(x = y ≡ ∀z(z ∈ x ≡ z ∈ y))	
Axiom of Extensionality

 A set without any objects, the empty set, exists. It is provable that this set is 
unique: only one empty set exists.
○
○∃x∀y(y ∉ x) ≡ ∃x ~ ∃y(y ∈ x)	
--- Existence of the Empty Set
 ∃x∀y(∀z(z ∉ y) ≡ y = x)	 --- Uniqueness of the Empty Set

 Given any set x and any relation Rj, such that members of x are members in the 
definition of the relation Rj, a set exists (can be constructed) that has as members 
all such relations Rj.	
	
--- Axiom of Replacement

 Given any two sets x and y, a set z can be constructed (exists) such that the sets 
x and y are members of z.
10.5  The Zermelo-Fraenkel Systematization of Set Theory

438
○
○∀x∀y∃z∀w(w ∈ z ≡ (w = x ∨ w = y))	 --- Axiom of Pairing

 Given any set x, a set y can be constructed (exists) such that every member of a 
member of x is a member of y.
○
○∀x∀y∃z∀w(w ∈ z ≡ ∃u(u ∈ y ∙ y ∈ x))	--- Axiom of Union
 The set so formed is called the Union Set of x: ∪(x).
•	 Example: x = {∅, {∅}, {1}, {1, 2}}
○
○∪(x) = {∅, 1, 2}

 Given a set x, a set y can be constructed (exists) whose members are exactly the 
subsets of x. As we have seen, this is called the power set of x.
○
○∀x∃y∀z(z ∈ y ≡ z ⊆ x)	
--- Existence of the Power Set

 Given any sets x and y, a set z can be constructed (exists) such that all and only 
shared members of x and y are members of z. This, of course, is the principle that 
permits construction of intersections of sets. A similar principle – indeed, the 
dual – can be defined for the existence of the set that is the union of two given sets.

 An infinite set is guaranteed to be constructible by means of the following stipu-
lated method: there exists a set x which contains as member the empty set and for 
any set y that is a member of x, y ∪ {y} is also a member of x.
○
○∃x(∅ ∈ x ∙ ∀y(y ∈ x ⊃ (y ∪ {y}) ∈ x))	Principle of Infinity
 Let us examine an application of this principle toward a representation of 
positive integers, whose set is, of course, infinite.
•	 0 ≝ ∅ - permitted by the Existence of the Empty Set
•	 1 ≝ {0} = {∅} - permitted by the Axiom of Infinity (PI)
•	 2 ≝ {0, 1} = {∅, {∅}} – PI
•	 …
•	 n + 1 = {0, 1, 2, …, n}
•	 …
A controversial axiom, which some mathematicians would have added to the 
basic theory, is the so-called Axiom of Choice. This axiomatic principle becomes 
automatically available to the theory if the Law of Excluded Middle is included: the 
Law of Excluded Middle postulates that there are exactly two values, distinct from 
each other (which in the familiar semantic interpretation are True and False), and, 
additionally, that every valuation or value-assignment for any recognized formula of 
the system receives one or the other of these two values. This unexpected affinity 
between the Axiom of Choice and the Law of Excluded Middle alerts us to an inter-
esting theoretical issue: a school of thought in Mathematics, called Mathematical 
Intuitionism, accepts only as truths statements that can be proven by means of a 
procedure that is in-principle constructible. Thus, the proof of “p or q” should 
depend strictly on having available a proof of either p or q. But notice that “p or 
not-p” as a logical truth is held to be available regardless as to whether there is an 
available procedure, even in principle, for proving p or one for proving not-p. A 
pertinent example is that of conjectures, in which case we do not have a proof of a 
statement that we might have reasons for expecting to be true; nor do we have a 
proof that it is not true (a proof of its negation.) In that case, and in spite of the fact 
that we cannot prove either p or not-p, the Law of Excluded Middle bids us accept 
10  Basics of Set Theory

439
that “p or not-p” is nevertheless true as a matter of logic. A philosophical objection 
that can be raised is that this commitment to the availability of the proof of either p 
or not-p, regardless of whether either one of p or not-p can be proven, reflects a view 
that there is a mind-independent objective realm of mathematical entities. The 
opposition, however, the Intuitionist view of Mathematics, rejects that our access to 
an independent realm of entities is at stake and instead takes the position that we can 
only properly have what we can construct by proper means of proof. This commit-
ment leads to the rejection of Excluded Middle. As mentioned above, accepting 
Excluded Middle as a principle makes possible to support the Axiom of Choice, 
which we are about to present briefly. This is not a coincidence because the Axiom 
of Choice itself is rejected by the Intuitionistic School because this axiom also com-
mits us to accepting certain infinitarian constructions as available regardless of 
whether we can have a procedural access to such structures.
According to the Axiom of Choice, given any collection of sets which are pair-
wise disjoint (any two of them have no members in common), it is possible to con-
struct a set that has as members exactly one of the members of each one of the given 
sets. This axiom stipulates, in other words, that such a set exists or can be con-
structed. There is no problem, as usual, when it comes to finitary constructions but, 
as indicated above, the suspicions and theoretical disputations are triggered in the 
face of reflecting on possibly infinite set-constructions.
As examples of showing what the Axiom of Choice stipulates we may consider 
the following. Of course, the shown sets we construct are not the only ones that can 
be constructed. What is needed that one and only one – hence, exactly one – mem-
ber of each given set is included in the constructed set.
•	 {1, 2}, {∅}, {a, b}	
	=> {1, a}
•	 {△, ◊, ○}, {↘, ↙}, {a}, {x}	 	
=> {△, ↘, a, x}
•	 {◊}, {△,↘}, {○, ↘, ↙}	
	
=> {◊, ↘}	
-- notice, it is possible 
to include the same member which two different given sets happen to share; it 
still the case that exactly one member of each given set is included.
•	 {{∅}}, {↘}, {↙}	
	=> {∅, ↘, ↙}	
-- the empty set, having no 
members whatsoever, gives us no members for inclusion; but the set with the 
empty set as member does have a member, which is the empty set and may be 
included; also, if only one member is in a given set, that member must be included 
in the set we construct. See the following example, also, in which we have a set 
of a set with the empty set as member.
•	 {{{∅}}}, {△, ◊, ○}	
	=> {{∅}, ◊}
10.6  Use of Truth Tables in Set Theory
In chapter 4, we examined a system, ∑, for implementation of truth tables for sen-
tential logic. Truth tables can be applied for the definition of the set-theoretic opera-
tions we have examined in this Appendix. The relevant notion needed for the 
10.5  The Zermelo-Fraenkel Systematization of Set Theory

440
definitions is that of being-a-member of a set, which we have symbolized by “∈” 
while our symbols for sets and members of sets are from {x, y, z, w, u, v, …, xi, …}/i 
is a positive integer. We start by using a truth table for the definition of the unary 
operation of complement (or set complementation.) (Notice that there is ambiguity 
as to whether we are referring to the set that is the complement of a given set or to 
the operation of determining the complement of a set, symbolized as “xc”. Context 
removes this ambiguity.) The truth-tabular definition of the complement of a set x 
presents a map of all logically possible combinations of membership of any object 
whatsoever with respect to the set x. There are exactly two logical possibilities: any 
object either is or is not a member of the set x. This applies in the case of any set, 
and of any specified object, and it is the expression in set theory of the fundamental 
logical law of bivalence (specifying the existence of exactly two values, which 
means true and false in the case of sentential logic and, in the case of our set-­
theoretic setup, it means membership or no-membership with respect to a set.) This 
is called the Law of Excluded Middle (a term with archaic flavor, literally meaning 
that no third possibility or option is to be allowed.) If we think back to how we used 
truth tables in sentential logic, placing atomic sentential variables in the top left row 
and truth value symbols (from {T, F}) underneath, we can consider the rows of the 
truth table below to be labeled as followed: the top left row is labeled by the atomic 
sentential variable interpreted as “there is a set x” and the two rows under that as “a 
specified object is a member of x” and its negation, “the specified object is not a 
member of x.” The symbols, respectively, “∈” and “∉”, could be understood to 
stand for those atomic propositions – or, rather, for the atomic proposition stating 
membership of a specified object and for its negation. This shows how membership 
in set theory plays the key role in defining operations, as truth value did in the case 
of sentential logic.
x
xc
∈ 
∉
∉ 
∈
logical possibility 1: the specified object is a member of x. ⇒ it is not a member of the 
complement. Logical possibility 2: the specified object is not a member of x. ⇒ it is a 
member of the complement.
We can use truth tables, constructed again by deploying the membership and 
non-membership symbols, to define by truth-tabular means the other, binary, set-­
theoretic operations we have introduced. All logically possible combinations are 
represented and the convention applied here is, starting with the rows from top 
to bottom:
 the specified element belongs to the first set and belongs to the second set;
 the specified element belongs to the first set and does not belong to the second set;
 the specified element does not belong to the first set and belongs to the second set;
 the specified element does not belong to the first set and does not belong to the 
second set;
 since this is a random, not specialized, item that we are discussing, we can sub-
stitute the expression “for all x, such that---.”
10  Basics of Set Theory

441
○
○Thus, for the third row and for the definition of the set-theoretic union of sets 
x and y, we have, as appropriate: the specified object belongs to the union of 
x and y if and only if either it does not belong to the first and it belongs to the 
second. Notice the parallel to the sentential connective of inclusive disjunc-
tion, which has the same truth table for its definition once we replace: the set 
variables by sentential variables, the symbols for membership and non-­
membership with T and F respectively, and the symbol of inclusive disjunc-
tion for the symbol of set-theoretic union.
○
○The Boolean function interpreted as material implication and symbolized by 
the horseshoe is of no interest in the set-theoretic interpretation of Boolean 
algebra. We can, of course define the set-theoretic interpretation, which we do 
below but there is no standard symbolization of this set-theoretic operation 
because it lacks significance.
○
○On the other hand, the relative difference of sets is theoretically significant 
while the corresponding sentential connective is usually missing from 
textbooks.
compare: p 
∨ q
compare: p 
∙ q
compare: (p ∙ ~ q) 
≡ (p ⊅ q)
compare: ~ (p ≡ q) 
≡ (p ≢ q)
compare: p 
⊃ q
x
y
x ∪ y
x ∩ y
x – y
x ⊖ y
xc ∪ y = (x ∩ 
yc)c
∈ ∈ 
∉ ∉
∈ ∉ 
∈ ∉
∈ ∈ ∈ ∉
∈ ∉ ∉ ∉
∉ ∈ ∉ ∉
∉ ∈ ∈ ∉
∈ ∉ ∈ ∈
10.6.1  Exercises
	1.	 Taking into account that
x ⊆ y if and only if x ∩ yc = ∅.
use the truth table method to determine whether the following are true or 
false, and answer the given questions.
	
a.	 x ⊆ (x ∪ y)
	
b.	 (x ∪ y) ⊆ y
	
c.	 (x ∩ (x ∩ yc)c) ⊆ y
	
d.	 xc ∩ (x ∪ y) = x ∪ yc
	
e.	 If x ⊆ y, then (x ∩ z) ⊆ y
	
f.	 If x = y, then x ⊖ y = x
	
g.	 x – y = x ∪ yc
	
h.	 If x ⊆ y and x ⊆ yc, then x = ∅
	
i.	 Define “x ≈ y” as “(x ∩ y) ∪ (xc ∩ yc)”. This is the equivalence operator. Is it 
the complement of the symmetric difference?
	
j.	 (x ∪ y)c ≈ xc ∩ yc
10.6  Use of Truth Tables in Set Theory

442
10.7  Relations and Functions; Inverses and Relative 
Products of Relations; Converses, Inverses 
and Compositions of Functions
9
9 Having defined such seminal set-theoretic concepts as ordered n-tuples (includ-
ing the special case of doublets or pairs) and Cartesian products, we now proceed 
to apply set theory for the important purpose of defining relations and, then, on 
the basis of the definition of the concept of relation, we define the concept of 
function. An intuitive understanding of what a relation is ought to be immedi-
ately available but the systematic definition of the notion is secured by deploying 
the tools of set theory. A relation can obtain between at least two objects. 
Although an n-ary relation is readily definable, the most common case is that of 
binary relations. We can think of a relation as a subset (not necessarily proper) of 
a Cartesian product. An n-ary or n-place relation is a subset (not necessarily 
proper) of an n-ary Cartesian Product.
 𝓡n ⊆ 𝓐1 ⤬ … ⤬ 𝓐n
 n = 2: 𝓡 ⊆ 𝓐 ⤬ 𝓐
9
9 A binary relation 𝓡 is defined set-theoretically as a set of ordered pairs, with the 
first member of a pair being a member of some set 𝓐 and the second pair being 
a member of some set 𝓑. Thus, the relation, so defined, is a subset (not neces-
sarily proper) of the Cartesian product 𝓐 ⤬ 𝓑. The value of the relation is the 
set of ordered pairs and parallel bars, left and right “|”, may be used to indicate 
that. In practice, these symbols are often omitted.
○
○𝓡 ⊆ 𝓐 ⤬ 𝓑
 If a model-domain 𝕯 is given, a binary relation 𝓡 is definable in the 
model, so that 𝓐 = 𝓑 = 𝕯 and:
𝓡 ⊆ 𝕯 ⤬ 𝕯 = 𝕯2
•	 We say that a relation R is from the domain 𝕯(R) to the range 𝓡(R). This can be 
written:
R: 𝕯 ↦ 𝓡
𝕯𝓡
A relation is into when not all members of 𝓡 are included in some ordered pair 
in the set defining the relation. A relation is onto when all members of 𝓡 are 
included in some ordered pair in the set defining the relation.
Note the following, pertaining to the unique case in which the domain of a rela-
tion is the empty set:
	
∅ ↦ S means that S = {∅}
or, 	
S∅ = {∅}
9
9 Trivially, an object can be related to itself: but in this case too, we speak of two 
presumed objects, which happen to be the same object related to each other and, 
so, the relation is binary. In fact, the identity relation, which is binary, can be 
regarded as the universal relation since every object ought to be presumed identi-
cal with itself. This is taken as a logical relation even if it sounds superficially 
10  Basics of Set Theory

443
that this is a matter of how things happen to be characterized in experience. On 
the other hand, a monadic relation is definable as a degenerate case: if we hark 
back to the definition of n-tuples as ordered collections of n items, we can allow 
for the degenerate case of the one-member ordered collection which is a defin-
able, even if degenerate, notion: <x> = {x, {x}}.
9
9 For <x> = <y>, we must have: {x, {x}} = {y, {y}}, and so: x = y or {x} = {y}. 
The identity sign is fulfilling a double task to indicate the identity of the objects 
denoted by the variables as well as the identity of the sets with the objects as 
members. This is sloppy and ought to be noted and tolerated only as a matter of 
convenience while regarding the two symbols to be different (and “looking” the 
same as a matter of convenient coincidence.)
9
9 For the degenerate case, we have: <x> = <x> if and only if {x, {x}} = {x, {x}}, 
which is readily verifiable to be true based on the definition of the concept of the 
identity of sets.
9
9 Let us now move to the case of the binary relation and see how we define it set-­
theoretically. The comments here resonate with how we studied relations in the 
sections on relational or polyadic predicate logic: this is natural since the instru-
mentalities used in modern predicate logic  – following Frege’s breakthrough 
achievement in the nineteenth century – are set-theoretical. A relation R can be 
defined as the set of the ordered pairs x and y such that x is R-related to y. We 
need ordering in the collections as we can show by using an intuitively appealing 
example. If a person named “a” is the student of a person named “b”, the relation 
denoted by “S,” the ordering is <a, b> if the relation is defined “x is the student 
of y.” Again, as pointed out earlier, an open sentence is used to define the binary 
or relational predicate. The pair <a, b> belongs to the set that defines the relation 
but the pair <b, a> does not belong to the set since the person named b is not a 
student of the person named a. (Let us assume this anyway because it is not logi-
cally impossible for two different persons to be each other’s students!) Having 
studied ordered pairs, we have at our disposal what we need to provide a formal 
definition of a relation – starting with binary relations before we treat the general 
case of n-ary or n-place relations. We place within “||” the symbol of the relation 
to denote its value; the value of the relation is defined by means of a set of 
ordered pairs – in the case of a binary relation. The domain within which the 
relation is defined we symbolize by 𝕯. Now, since we have a binary relation, the 
set that provides the value of the relation is a subset of the Cartesian product 𝕯 
⤬ 𝕯. Or – which is the same thing – the set that provides the value of the relation 
is a member of the power set of 𝕯 ⤬ 𝕯. There is no absolutely universal 
domain – as we have said – in order to preclude paradoxical sets from being 
generated by abstraction. The domain is relative and a relation can be defined 
over different domains with different members. A relation can be the empty set 
in one modeling over a domain and it can have members in another modeling 
over the same domain. This is as it ought to be because relations are not logical 
notions: that a is the student of b is not a logical truth; it is a logically contingent 
or indeterminate truth. This is captured by the semantic fact that the relation 
being-a-student-of is definable set-theoretically so that it does not have to have 
10.7  Relations and Functions; Inverses and Relative Products of Relations; Converses…

444
the same members in every possible modeling. The only exception is the binary 
relation of identity which is treated as a logical notion but we will not enter into 
the interesting philosophic and logical implications here. It suffices to draw our 
attention to what has emerged from these comments: logicality or what is char-
acteristic of logical notions has to do with invariability across possible models. 
What we are studying here overlaps with the lessons of chapter 5, as it ought to 
be the case.
○
○|R| = {<x, y> / x is R-related to y} ⊆ 𝕯 ⤬ 𝕯
○
○|R| ∈ ℘(𝕯)36
 For example, we can set model 𝔐 = <𝕯, ||>. The metalinguistic positing 
of the model itself uses an ordered pair, by the way, with the domain as first 
member and the valuation (also called interpretation and signature) as sec-
ond member of the pair. Valuations must be provided for the symbols of the 
model: objects of the domain and predicates understood as sets of pairs are 
the values of the symbols which, as we know from chapter 5, are individual 
constants and predicate symbol letters. We can think of monadic predicates 
as degenerate relations (thus, as sets of one-member pairs) and, of course, 
we define binary relational predicates, and so on, as sets of ordered 
n-tuples. In our example, we have one monadic and one binary predi-
cate symbol.
𝕯 = {⊲, ⊳}.
|a| = ⊲.
|b| = ⊳.
|F| = {<⊲>, <⊳>} ⊆ 𝕯.
|R| = {<⊲, ⊳>, <⊳, ⊲>} ⊆ 𝕯 x 𝕯.
The binary relation is obviously symmetric. For every pair <x, y> that is a 
member of the relation, <y, x> is also a member. The relation is not reflex-
ive: <x, x> is not a member for all x in the domain.
We can use the language of predicate logic to write out formulas that can 
then be evaluated as true or false insofar as the formulas do not have any 
free variables in them. Here are some examples of such formulas, whose 
assessment as to truth value is left as an exercise.
Rbb
Rab
Fa ⊃ ~ Rbb
∃xRbx
∃x∀y(Rxy ≡ ~ Fy)
Notably, for every member of the domain, either it is a member of a 
monadic predicate or not. There are no indeterminate cases and we no 
degrees of membership are allowed – in fact, the notion of degree of mem-
bership is nonsensical, being undefined, in this context. The set theory that 
is being utilized is the classical theory, also called Crisp or Sharp; it is not 
of a more recent variety called Fuzzy Set Theory which permits degrees of 
set membership.
10  Basics of Set Theory

445
9
9 An n-place relation can be defined as a set of ordered n-tuples from a specified 
domain 𝕯. An n-place or n-ary relation, as a set, is a subset of the nth Cartesian 
product of the domain by itself, symbolized as 𝕯 x …[n]… x 𝕯 = 𝕯n.
It becomes increasingly difficult to obtain empirical examples of n-place rela-
tions but a readily available example of a ternary relation is x-between-y-and-z. 
Here is an example, in which we also show how can diagrammatic presentations 
of models can be used. Based on the information in the diagram, we can write out 
the set-theoretic representation of the value of the model’s defined ternary rela-
tion symbolized by R.
ℳ = <𝕯 = {⋆, ⋇, ⋕, ⌖}, ||>
|a| = ⋆
|b| = ⋇
|c| = ⋕
|d| = ⌖
___________⋇_______________⋕_____________⋆______________
⌖___________
|R| = {<⋇, ⋕, ⋆>, <⋕, ⋆, ⌖>, <⋆, ⋕, ⋇>, <⌖, ⋆, ⋕>}
Are the following true or false in the model?
Rcdb
Racb
∃xRaxc
∀x∀y(Rxay ∨ ~ Rybx)
Assuming that R3 is a ternary relation, we can define it by abstraction as follows:
|R3| = {<x, y, z> = <<x, y>, z> / z is-R-related to <x, y>}
For instance, the sum of two numbers can be represented as a ternary relation:
|S| = {<x, y, z> / z = x + y} = {<<x, y>, z> / z is the sum of (x, y)}
9
9 Generally, an n-ary relation R has a domain 𝕯 and a range 𝓡, defined as 
follows:
9
9 𝕯(R) = {x1, …, xn-1/ <x1, …, xn-1> ∈ 𝕯n and <x1, …, xn-1, xn> ∈ R for some xn}
9
9 𝓡(R) = {xn/<x1, …, xn-1, xn> ∈ R for some ordered n-tuple <x1, …, xn-1> ∈ 𝕯n}
9
9 R: 𝕯n ↦ 𝓡
9
9 An n-ary relation is also called a mapping, map, projection, or transformation 
from the Cartesian product 𝕯n to 𝓡.
Binary relations have pronounced theoretical interest. Examples of binary rela-
tions follow. The lesson is that a relation can be defined as a set of ordered 
n-tuples (pairs or couples in the case of binary relations.)
A relation can be one-many (1-m), which means that, for binary relations as an 
example, more a member of the domain can be mapped onto more than one 
members of the range. This relation cannot represent a function – which is the 
concept that follows.
R1: {1, 2} ↦ {1, 2, 3}: R1 = {<1, 2>, <2, 3>, <1, 3>}.
R2: {a, b, c} ↦ {1, 2, 3}: R2 = {<a, 1>, <b, 1>, <c, 2>, <c, 3>}.
10.7  Relations and Functions; Inverses and Relative Products of Relations; Converses…

446
¾
¾ We will now define the inverse of a given relation R, symbolized as “R−1”. An 
other symbol that is found in the bibliography is “Ř.” This concept is definable 
specifically for relations and we restrict it to binary relations. Other terms in the 
bibliography are “reverse,” “converse” and “transpose” of a given relation R. If 
the given relation R is defined as,
R = {<x, y> / Rxy}
then,
R−1 = {<y, x> / Ryx}
This means that the order of the members of the ordered pairs defining the relation 
R is reversed for all pairs to yield the inverse of R. Clearly, in the case of the identity 
relation, for instance, the reverse of the relation of identity is the same as the relation 
itself. More generally, this is the case for relations that are symmetric  – which 
means, by definition, that the pair <b, a> is a member of the symmetric relation R 
for every <a, b> pair that is a member of R. The domains and ranges of a relation 
and its inverse can be discussed in some detail.
If a given relation 𝓡 is defined as subset of the Cartesian product 𝓐 ⤬ 𝓑, then 
𝓡−1 must be defined as a subset of the Cartesian product 𝓑 ⤬ 𝓐. Of course, if 𝓐 
= 𝓑 = 𝕯, then both 𝕽 and 𝕽−1 are defined as subsets of 𝕯 ⤬ 𝕯.
Examples of determining the inverse of a given relation are shown:
 S1 = {<1, 1>, <2, 1>, <2, 2>, <3, 2>}
○
○S1
−1 = {<1, 1>, <1, 2>, <2, 2>, <2, 3>}
 S2 = {<a, 1>, <b, 1>, <c, 1>}
○
○S2
−1 = {<1, a>, <1, b>, <1, c>}
 R< = {<x, y> / x, y ∈ Integers and x < y}
○
○<−1 = {<y, x> / x, y ∈ Integers and x < y} = {<x, y> / x, y ∈ Integers and x 
> y} = R>
 R1 = {<∅, ω>, <ω, ∅>}
○
○R1
−1 = {<ω, ∅>, <∅, ω>} = R1
 R2 = {<△, ◊>, <○, ♡>, <□, ▭>}
○
○R2
−1 = {<◊, △>, <♡, ○>, <▭, □>}
 Generally, R ≠ R−1.
 (R−1)−1 = R	
-- It is interesting to consider how this can be proven.
¾
¾ Next, we define the set-theoretic notion, specifically for relations, that we call 
relative product or composition of two given relations. We restrict this to the case 
of binary relations. Given two relations R and S, the relative product of these 
relations is a relation symbolized by R | S, defined as follows (using, as we have 
been doing so far, the symbols from our formal language of predicate logic with 
those symbols enhancing our metalanguage in the present context):
○
○R | S = {<x, y> / ∃z(<x, z> ∈ |R| ∙ <z, y> ∈ |S|)} = {<x, y> / ∃z(Rxz ∙ Rzy)}
To state this in prose, the relative product of two given relations R and S is a 
relation which is a set of ordered pairs that are composed as follows: the first 
member of each pair, x, is from R and the second member, y, is from S only if 
10  Basics of Set Theory

447
there is some member z such that <x, z> is a member of R and <z, y> is a 
member of S.
If a given relation 𝓡 is defined as subset of the Cartesian product 𝓐 ⤬ 𝓑 and a 
given relation 𝓢 is defined as a subset of the Cartesian product 𝓒 ⤬ 𝓓, then the 
relative product 𝓡 ⤬ 𝓢 must be definable as a subset of the Cartesian prod-
uct 𝓐 ⤬ 𝓓.
Examples of determining the relative product of given relations are shown below. 
Needless to say, it is possible that the relative product is the empty set. It is notable 
that the operation of constructing the relative product is not commutative but it is 
associative. The degenerate case of the relative product of a relation R and itself is 
the relation R. (We omit the vertical bars, “|” and “|,” for the set-theoretic definition 
of a relation.)
 R = {<1, 1>, <2, 1>, <2, 2>, <3, 2>}
 S = {<1, 3>, <2, 3>, <3, 1>}
R | S = {<1, 3>, <2, 3>, <3, 3>}.
Since <1, 1> ∈ R and <1, 3> ∈ S (note the bold type used for illustrative pur-
poses), it follows that <1, 3> ∈ R | S.
We do not expect generally the relative product S | R to be equal to R | S.
S | R = {<1, 2>, <2, 2>, <3, 2>}
We can also determine the relative product of a relation and the inverse of some 
relation, and the inverse of a relative product of two given relations – and so on. 
We show examples with R and S defined as above.
R−1 = {<1, 1>, <1, 2>, <2, 2>, <2, 3>}
S−1 = {<3, 1>, <3, 2>, <1, 3>}
R−1 | S−1 = {<1, 3>, <2, 1>, <2, 2>}
(R | S)−1 = {<3, 1>, <3, 2>, <3, 3>}
¾
¾ Set-theoretic operations, many of which were defined in 11.4, can be adapted 
notionally to the case of defining operations on relations: we continue to restrict 
our attention to binary relations.
Thus, for instance, the relative difference of two relations R and S is defined – 
analogously to the set-theoretic operation of the relative difference of two speci-
fied sets – as follows:
R ~ S = {<x, y> / <x, y> ∈ R ∙ <x, y> ∉ S}
Similarly, union and intersection of binary relations can be defined.
R ∪ S = {<x, y> / (<x, y> ∈ R) ∨ (<x, y> ∈ S)}
R ∩ S = {<x, y> / (<x, y>) ∈ R ∙ (<x, y> ∈ S)}
For example, using the previous examples’ R and S defined relations:
R ~ S = R 	 If R ∩ S = ∅, then R ~ S = R
R ∪ S = {<1, 1>, <2, 1>, <2, 2>, <3, 2>, <1, 3>, <2, 3>, <3, 3>}
R ∩ S = ∅
(R ∩ S)−1 = ∅
(R ~ S)−1 = R−1
(R | S) ∪ R = {<1, 3>, <2, 3>, <3, 3>} ∪ {<1, 1>, <2, 1>, <2, 2>, <3, 2>} = = 
{<1, 3>, <2, 3>, <3, 3>, <1, 1>, <2, 1>, <2, 2>, <3, 2>}
10.7  Relations and Functions; Inverses and Relative Products of Relations; Converses…

448
¾
¾ Generally:
○
○R | S ≠ S | R
○
○Q | (R | S) = (Q | R) | S
○
○(Q | R)−1 = R−1 | Q−1
10.7.1  Characteristics of Relations
Relations have characteristic properties, which we now define. All members x are 
presumed to be members of the domain of the relation.
9
9 A relation ρ is reflexive if and only if:
∀xρxx
9
9 A relation ρ is irreflexive iff:
∀x ~ ρxx
9
9 A relation ρ is non-reflexive iff:
∃x ~ ρxx
9
9 A relation ρ is symmetric iff:
∀x∀y(ρxy ⊃ ρyx)
9
9 A relation ρ is asymmetric iff:
∀x∀y(ρxy ⊃ ~ ρyx)
9
9 A relation ρ is non-symmetric iff:
∃x∃y ~ ρxy
9
9 A relation ρ is anti-symmetric iff:
∀x∀y((ρxy · ρyx) ⊃ x = y)
9
9 A relation ρ is transitive iff:
∀x∀y∀z((ρxy · ρyz) ⊃ ρxz)
9
9 A relation ρ is non-transitive iff:
∃x∃y∃z(ρxy · ρyz · ~ ρxz)
9
9 A relation ρ is intransitive iff:
∀x∀y∀z((ρxy · ρyz) ⊃ ~ ρxz)
9
9 A relation ρ is serial iff:
∀x∃yρxy
9
9 A relation ρ is weakly connected iff:
∀x∀y(x ≠ y ⊃ (ρxy ∨ ρyx))
9
9 A relation ρ is strongly connected iff:
∀x∀y(ρxy ∨ ρyx)
9
9 A relation ρ is dense iff:
∀x∀y(ρxy ⊃ ∃z(ρxz · ρzy)).
Depending on what characterizing properties they have, relations impose certain 
types of ordering on sets on which they are applied. Since these are seminal con-
cepts in the study of Logic, and of various branches of Mathematics, we give the 
definitions:
9
9 A relation is a quasi-ordering if it is reflexive and transitive.
10  Basics of Set Theory

449
9
9 A relation is a partial ordering if it is reflexive, antisymmetric, and transitive. 
Examples: ≤, ⊆
9
9 A relation is a simple ordering if it is reflexive, antisymmetric, transitive and con-
nected. [⊆ is not a simple ordering since it is not strongly connected: it is possi-
ble for two sets x and y to be such that x is not a subset of y and y is not a subset 
of x, without being equal.]
9
9 A relation is a strict partial ordering if it is antisymmetric and transitive. 
Example: <, ⊂
9
9 A relation is a weak ordering if it is transitive and strongly connected.
9
9 The equivalence relation, of which we have already spoken, is reflexive, sym-
metric and transitive.
10.7.2  Functions
¾
¾ A function can be defined by using set-theoretic concepts and specifically by 
using the concept of relation we have examined. Let us consider first unary func-
tions – these are the functions with exactly one input from a specified domain of 
elements 𝕯. The set of the outputs which the function yields for the inputs con-
stitute the set called the range or counter-domain of the function, 𝕽. This is the 
case in which the function is, as we say, onto 𝕽: this means that all members of 
the range of the function (also called counterdomain and image) serve as outputs 
for some input from the specified domain of the function, 𝕯.
¾
¾ A function with domain 𝕯 and range 𝓡 is one-to-one, 1–1, if and only if a 
unique output from the range is assigned to each input and not two identical 
outputs are assigned to the same input. We can write this as follows:
f: 1–1:: if and only if:
f(x1) = f(x2) implies x1 = x2.
x1 ≠ x2 implies f(x1) ≠ f(x2)
•	 Given a domain 𝓓 of function ƒ, 𝓓(ƒ), and range 𝓡(ƒ), the unary (single-input) 
function ƒ is definable as the set | ƒ | of ordered pairs <x, y> such that y = ƒ(x) 
and for every <x, z> ∈ | ƒ |, then y = z. This means that the second member of 
each pair must be uniquely matched with the first pair. (This does not apply in 
reverse. The same second members of pairs can be matched with the same first 
members. In that case, the function is not 1–1, one-to-one, but insofar as the 
second member is in every case unique we have a definable function.)
•	 Every function is a relation, as it follows directly from the definition. But not 
every relation is a function. Here are examples of relations that cannot define 
functions because of the violation of the definitional requirement that the second 
members of pairs are uniquely matched with first members.
○
○R = {<a, 1>, <b, 2>, <a, 2>}
○
○S = {<①, □>, <①, ▭>, <②, △>, <③, ◊>}
○
○L = {<1, 1>, <1, 2>}
10.7  Relations and Functions; Inverses and Relative Products of Relations; Converses…

450
 The following relations are functions; the same inputs are matched to the 
same output but this does not matter insofar as there is no more than one 
output matched to the same input.
•	 A = {<①, ▭>, <②, ▭>}
•	 B = {<1, 2>, <2, 2>, <3, 1>}
•	 C = {<1, a>, <2, b>, <3, c>, <4, a>}
¾
¾ We can define a function as a relation between the input and the output only in 
those cases in which there is a uniquely assigned output for each specified input 
(member of the function’s domain.) The relation that defines a function is repre-
sented as an ordered pair of the input and the uniquely determined outputs. For 
instance, having the set of positive integers as domain and range:
○
○ƒ(x) = x + 2:: 𝕯 = I+; 𝕽 = I+.
•	 ƒ(x) = {<x, ƒ(x)> /x ∈ I+, ƒ(x) ∈ I+, and ƒ(x) = x + 2}
•	 Thus, the function is defined from domain to range: ƒ: I+ ↦ I+
•	 The output has to be unique for each specified input. This follows from the 
definition of function, which we have given. In our example, the output is 
uniquely determined. But contrast the following case, with domain and 
range identified with the set of integers.
○
○ƒ#(x) = √x
 For instance: x = 1 ⇒ ƒ#(x) = √1 =… +1 or – 1!
○
○Binary functions can be represented analogously as ternary relations 
with the functional output of two inputs being the third member of the 
ordered triplet; for instance:
○
○ƒ(x, y) = {<<x, y>, ƒ(x, y)> / x, y ∈ {0, 1}, and ƒ(x, y) = xy} = {<<0, 
0>, 0>, <<1, 0>, 0>, <<0, 1>, 0>, <<0, 0>, 0>}
○
○In general, the degree of the function is lowered by one compared to the 
degree of the relation that represents the function.
○
○Notice that the domain of the binary relation is the Cartesian product of 
the domain by itself, 𝕯 ⤬ 𝕯, and generally for an n-place relation the 
domain is the nth Cartesian product of the domain by itself.)
○
○ƒ1: 𝕯 ↦ 𝕽
○
○ƒ2: 𝕯 ⤬ 𝕯 ↦ 𝕽
○
○ƒn: 𝕯 ⤬ 𝕯 ⤬ … ⤬ 𝕯 ↦ 𝕽
 The range is the same as the domain. This is desirable in many cases 
and we observe that in this case the outputs of all the operations are 
in the domain itself. Moreover, all the operations are carried out and 
their outputs are in the domain: we say in that case that the domain 
is closed under the given operation – in the present example, this is 
the multiplicative operation and 𝕯 = {1, 0} is closed under the mul-
tiplicative operation as defined. Of course, we could have defined a 
different multiplicative operation, under which the domain is not 
closed – which means that some output from applying the operation 
to the domain members is not in the domain itself. Then we would 
have: 𝕯 ⤬ 𝕯 ↦ 𝕽 ≠ 𝕯
10  Basics of Set Theory

451

 We need to draw a fundamental disambiguating distinction between a function 
and the value a function takes for specified values of its inputs. (The value of an 
input is also called in the bibliography, confusingly, “argument of the function.”)
○
○Clearly, we have defined a function as a relation or set of ordered pairs. But 
we also may find identifying references to a function ƒ by such representa-
tions as, for instance:
 ƒ(x) = x + 1
This is certainly wrong because, for example:
ƒ = {<1, 2>, <2, 3>, <3, 4>}.
is a set but.
ƒ(x) = x + 1.
is the value assigned by the function to the output for every member x of the 
specified domain of the function.
To ensure that ambiguity does not arise, we need to establish some convention by 
means of which we can name the function itself – as distinguished from the repre-
sentations of valuations of the functions for specified values of its available inputs. 
For the purpose of naming a function, an elegant formal device of naming is avail-
able which was invented by Alonzo Church and is known as lambda-abstraction or 
lambda-notation (with “lambda” referring to the Greek small word “λ” which is 
used in the notation.
To show how this symbolic device is deployed to name a function, continuing 
with the preceding example, we have as follows. It must be understood that the 
lambda-symbol, accompanied by the variable symbol, is used in the symbolic gram-
mar in the same way that we used quantifiers in the formal language of predicate 
logic. The lambda-variable symbol binds the variables and only the variables that 
are tokens of the variable accompanying the lambda-symbol.
λx(x + 1)
We can specify an input symbol, thus applying the function for a specified input 
and value. We do this, and carry out the computations, as shown in the following 
example.
λx(x + 1)(2) = 2 + 1 = 3
We can also use multiple lambda-quantifiers and specify input values. The use of 
parentheses is crucial: to remove parentheses by applying the input values we start 
from inside and work our way outwards. We show various examples, highlighting 
different possible cases of usage of this notation.
λxλy(x + y + 2)(1, 2) = 1 + 2 + 2 = 5
λx(λy(x2 + y2)(3))(4) = λx(x2 + 32)(4) = 42 + 32 = 16 + 9 = 25
λy((4 ⤬ y) + w)(3) = (4 ⤬ 3) + w = 12 + w
¾
¾ We now define the inverse of a function, which we will symbolize by “ƒ−1” when 
the symbol of the functional operation is “ƒ”. Having explained why a relation 
may or may not be defining a function (depending on whether the output, as 
defined, is unique for every given input value), we must now face a consequence 
that affects the inversion of a given functional operation. There is no question 
that the inverse of the relation that defines a function, R(ƒ), will be a relation – in 
10.7  Relations and Functions; Inverses and Relative Products of Relations; Converses…

452
fact, it has to be the inverse of the relation, and so it has to be R−1(ƒ). But it is not 
guaranteed that this relation, R−1(ƒ), can define a function: it may or may not 
have a uniquely defined output (second member of each ordered pair) for each 
specified input (first member of each ordered pair.) (Strictly speaking, we should 
reserve “input” and “ouput” terms only for functions and not use them cavalierly 
including also cases in which we might not have a relation that defines a func-
tion. We could speak of “alleged input” and “alleged output” perhaps.) Because 
of this divergence between inverses of relations and inverses of functions, we 
require two different concepts and two different corresponding symbols: we call 
the converse of a function ƒ the relation R−1(ƒ) which may or may not be a func-
tion. We reserve the term “inverse” for the case in which the converse of a func-
tion is a relation that defines a function. The symbol for the converse of a function 
is “ƒ⏜” and the symbol for the inverse of a function is “ƒ−1”.
○
○Here is an example: ƒ(x) = x2 𝕯 = I
 ƒ⏜(x) = √x
•	 For example: <2, 4> ∈ ƒ
○
○<4, 2> ∈ ƒ⏜ and <4, − 2> ∈ ƒ⏜
 It may be queried whether we could pick one of the two ordered 
pairs of the function ƒ⏜, and repeat this arbitrarily for every case 
in which there are more than one outputs or second members of 
ordered pairs: in this way, we define one of the available inverses 
of the function ƒ. This expedient is often used in Mathematics 
textbooks. Of course, more than one inverses of ƒ are definable in 
this way and it is arbitrary which one is to be regarded as the 
inverse of ƒ. In other words, ƒ lacks a uniquely definable inverse.
¾
¾ We now turn to the task of determining the inverse of a given function. The pro-
cess we will present may or may not result in a function but, in either case, we 
are able to ascertain whether a function is definable. The reason for this open-­
ended prospect is the same as what was discussed above: the converse relation 
R−1(ƒ) of the relation R(ƒ) that defines function ƒ is always definable but this 
relation, R−1(ƒ), may or may not be itself defining of a function.
○
○ƒ(x) = 2x + 4
 To find the inverse, if such exists, we take advantage of the following prov-
able equation relating a function to its converse. (Note that we speak of 
“converse” because this equation is satisfied even when the converse of the 
function is not itself a function. We may put it this way: this equation is 
satisfied regarding the relation between a function and its converse for all 
values of the functions. The converse – being a broader notion that that of 
the inverse – may or may not itself be a function.
•	 ƒ(ƒ⏜(x)) = x
10  Basics of Set Theory

453
Thus, we have to solve the following equation in our given example. We sim-
ply plug in “ƒ⏜(x)” for “x” in a token of the equation and determine the value 
of ƒ(x) at ƒ⏜(x).
ƒ(ƒ⏜(x)) = 2ƒ⏜(x) + 4 = x 	 	
⇒
2ƒ⏜(x) = x – 4	
	
	
	
⇒
ƒ⏜(x) = ½(x – 4) = ½x – 4/2 = ½x – 2.
Because the converse is a function – thus, the converse is an inverse – we 
may write:
ƒ−1(x) = ½x – 2
•	 ƒ(x) = x2
○
○ƒ(ƒ⏜(x)) = (ƒ⏜(x))2 = x	
⇒
ƒ⏜(x) = ∓√x.
Having negative and positive numbers in our domain entails that both the nega-
tive and positive values of the square root are second members of the ordered pairs 
for the corresponding first members. Thus, for instance, we have:
<4, − 2> ∈ƒ⏜ and <4, + 2> ∈ ƒ⏜
since both (− 2)2 = 4 and (+ 2)2 = 4.
The converse is not an inverse. Our method worked in determining the converse 
but it took additional discrimination on our part to determine that a function is not 
definable by inversion of the relation that defines the given function ƒ.
¾
¾ Given two functions ƒ1 and ƒ2 we will now define as composition of ƒ1 and ƒ2 a 
function g which, as the composite of ƒ1 and ƒ2 is symbolized as “ƒ2 ∘ ƒ1” or 
“ƒ2(ƒ1(x))” or “(ƒ1 ∘ ƒ2)(x)”. We know by now how we can define a function as a 
set of ordered pairs. Applying this notion, we define the composition function as 
the set of ordered pairs:
9
9 ƒ2(ƒ1(x)) = {<ƒ1(x), y> / y = ƒ2(ƒ1(x)), ƒ1(x) ∈ 𝕽(ƒ1) = 𝕯(ƒ2(ƒ1(x))) and y 
∈ 𝕽(ƒ2)}
○
○Harking back to our examination of ordered pairs and relations, above, we 
may recall the concept of the operation, defined there, of generating the rela-
tive product of two given relations R and S. Clearly, we have to keep in mind 
that not all relations define functions. For relations that do define functions, 
composition of functions (or functional composition) is defined analogously 
to the generation of the relational relative product. But there is a catch. If we 
are to use the relative-product symbol, “|” to indicate functional composition, 
we have the following:
 ƒ1(ƒ2(x)) = ƒ2 | ƒ1
This is not friendly to intuitions and we prefer not to make use of this notation. 
Instead, another way of symbolizing the operation of functional composition is 
as follows:
 ƒ1(ƒ2(x)) = (ƒ1 ∘ ƒ2)(x)
(To facilitate mental agility in thinking about functional composition, notice that, in 
the following remarks we reverse and speak of functional composition (ƒ2 ∘ ƒ1)(x) 
instead of (ƒ1 ∘ ƒ2)(x).)
10.7  Relations and Functions; Inverses and Relative Products of Relations; Converses…

454
If domain and range for the two compounded functions are, respectively, 𝕯(ƒ1) and 
𝕽(ƒ1) and 𝕯(ƒ2) and 𝕽(ƒ2), the domain of the composite function 𝕯(ƒ2(ƒ1(x))) = 
𝕽(ƒ1) and the range of the composition function 𝕽(ƒ2(ƒ1(x))) = 𝕽(ƒ2). Thus, we can 
symbolize the so-called mapping – another term we can use for a domain-to-­range 
function definition – as follows:
The composition of the negation function and the inclusive-disjunction func-
tion – as interpreted in a Boolean algebra – yields the function that interprets the 
Pierce Arrow function (symbolized by “↓”). Notice that we can and in this case 
indeed do have a composition of a unary with a binary function: the output of the 
binary function is treated as input for the unary function: this is possible, under the 
constraint we noted above, insofar as the range of the binary function is identical 
with the domain of the composing unary function. Indeed, the range of a binary 
function in the Boolean algebra is the set of values {1, 0} – while its domain is the 
Cartesian product {1, 0} ⤬ {1, 0} since this is a binary function. In the third exam-
ple below, notice how binary functions are composed.
•	 ƒ(x) = 2x	
g(x) = x + 1	
𝕯(ƒ) = 𝕽(g) = Integers
ƒ(g(x)) = ƒ(x + 1) = 2(x + 1) = 2x + 2.
g(ƒ(x)) = g(2x) = 2x + 1	
-- in general, ƒ ∘ g ≠ g ∘ f
•	 ƒ~(x) = x + 1
ƒ∨(x, y) = xy + x + y.
(ƒ~) = (ƒ∨) = {1, 0}, (ƒ∨) = {1, 0} ⤬ {1, 0}.
ƒ~(ƒ∨(x, y)) = ƒ~(xy + x + y) = xy + x + y + 1 = ƒ↓(x, y)
•	 ƒ∙(x, y) = xy
ƒ|(x, y) = xy + 1.
ƒ⊃(x, y) = xy + x + 1.
(ƒ∙) = (ƒ|) = 𝕯(ƒ⊃) = {1, 0}
(ƒ∙) = (ƒ|) = 𝕽(ƒ⊃) = {1, 0} ⤬ {1, 0}
ƒ⊃(ƒ|(x, y), ƒ∙(x, y)) = ƒ⊃(xy + 1, xy) = (xy + 1)xy + xy + 1 + 1 = xy + xy + xy 
+ 2 = xy + 0 = xy.
The semantic interpretation can be shown in the formal idiom we used in the 
chapters on sentential logic:
 ((p | q) ⊃ (p ∙ q)) ≡ (p ∙ q)
9
9 We can represent a constraint under which a function ƒ is definable by a relation 
R(ƒ) by showing how R(ƒ) and its inverse relation R−1(ƒ) are connected. If this 
constraint is satisfied, then the relation defines a function. We also need to define 
a relation called Identity, and symbolized by “I”, defined on the given universal 
domain, such that:
○
○I = {<x, y> / x = y}
The constraint is as follows:
 R−1 | R ⊆ I
•	 Let us examine this for the following cases:
○
○𝕯 = {1, 2, 3, 4}
10  Basics of Set Theory

455
R(ƒ) = {<1, 2>, <2, 3>, <3, 4>, <4, 4>} 	
[ƒ ∈ Functions]
R−1(ƒ) = {<2, 1>, <3, 2>, <4, 3>, <4, 4>}.
R−1 | R = {<2, 2>, <3, 3>, <4, 4>} ⊆ I = {<1, 1>, <2, 2>, <3, 3>, <4, 4>}.
R(ƒ1) = {<1, 2>, <2, 3>, <3, 3>, <4, 3>, <4, 2>}.
[ƒ1 ∉ Fuctions].
R−1(ƒ1) = {<2, 1>, <3, 2>, <3, 3>, <3, 4>, <2, 4>}
R−1 | R = {<2, 2>, <3, 3>, <3, 2>} ⊈ I
9
9 Functional composition is associative. Thus, we have:
We can apply our knowledge of composition of relations to show that:
(f/g)/h = (f/g)/h.
Then, we have:
(f/g)/h = h(g(f(x)) = h ∘ (g ∘ f)
(h ∘ g) ∘ f = f/(g/h)
Therefore,
h ∘ (g ∘ f) = (h ∘ g) ∘ f.
9
9 Given functions g and h, we can determine the function ƒ, such that:
g ∘ ƒ = h.
An example can show how we proceed:
g(x) = 2x.
h(x) = 3x + 1.
(g ∘ ƒ)(x) = g(ƒ(x)) = 2ƒ(x) = h(x) = 3x + 1.
From which we have:
ƒ(x) = ½ (3x + 1).
9
9 The case is more complicated, but can be solved, when we need to determine the 
function ƒ for which:
ƒ ∘ g = h.
We retain the functions of the preceding example.
g(x) = 2x.
h(x) = 3x + 1.
We reason as follows: We know that, for any function φ,
φ(φ−1(x)) = x
We have also shown that functional composition is associative. Based on the 
above observations, we have:
ƒ(x) = ƒ(g(g−1(x))) = ƒ ∘ (g ∘ g−1) = (ƒ ∘ g) ∘ g−1 = h ∘ g−1
This result suggests an algorithmic approach to discovering the solution. First, we 
determine the inverse of g and then we compose g−1 with h: the result is function ƒ.
In our given example, we have:
g(g−1(x)) = 2 g−1(x) = x	
Therefore: g−1(x) = ½ x
g−1 ∘ h = g−1(h(x)) = ½ (3x + 1) = ƒ(x)
10.7  Relations and Functions; Inverses and Relative Products of Relations; Converses…

456
10.7.3  Exercises
	 1.	 Considering as an example that the relation “being-a-sibling-of” is irreflexive, 
symmetrical, and transitive but not connected in the domain of “people”, iden-
tify the characteristic properties of the following relations:
	
a.	 being-the-mother-of
	
b.	 being-the-sister-of
	
c.	 being-identical-with	
[natural numbers]
	
d.	 being-equal-with	 [natural numbers]
	
e.	 being-perpendicular [Euclidean lines]
	
f.	 being-dissimilar-with
	
g.	 being-in-love-with
	
h.	 being-a-friend-with
	
i.	 being-a-member-of-the-same-team-with	
[domain: students of a college]
	
j.	 being-parallel-with	[domain: Euclidean lines]
	
k.	 being-married-to	 [domain: people in a monogamous society]
	 2.	 For each of the following relations, defined as set, identify the domain and 
range. Which relations are into? Which are onto?
	
a.	 R1 = {<1, 2>, <1, 3>, <2, 3>, <2, 4>}
	
b.	 R2 = {<a, 1>, <b, 2>, <c, 3>}
	
c.	 R3 = {<∅, {∅}>, <{∅}, ∅>}
	
d.	 R4 = {<□, ▭>, <△, ▭>, <◊, ○>, <□, ○>}
	
e.	 R5 = {<a, b>, <b, c>, <c, d>, <d, a>}
	
f.	 R6 = {<john, mary>, <carlos, maria>, <carl, jason>}
	
g.	 R7 = {<0, 2>, <2, 0>, <3, 0>, <1, 1>}
	 3.	 Which of the following relations are reflexive? Symmetric? Transitive? 
Connected?
𝕯 = {1, 2, 3, 4} ↦ 𝓡 = {1, 2, 3, 4}
	
a.	 R1 = {<1, 2>, <3, 2>, <2, 3>, <3, 3>}
	
b.	 R2 = {<1, 3>, <3, 2>, <1, 4>, <1, 2>, <3, 1>, <1, 1>, <3, 4>, <3, 3>}
	
c.	 R3 = {<1, 4>, <3, 2>, <2, 2>, <4, 1>}
	
d.	 R4 = {<1, 1>, <1, 2>, <2, 2>, <2, 3>, <3, 3>, <3, 4>, <4, 4>}
	
e.	 R5 = {<1, 4>, <2, 1>, <3, 3>, <1, 2>, <4, 1>}
	
f.	 R6 = {<1, 1>, <1, 3>, <3, 3>, <4, 2>, <2, 3>, <3, 4>}
	
g.	 R7 = {<2, 4>, <1, 2>, <3, 2>, <1, 1>}
	
h.	 R8 = {<1, 2>, <2, 3>, <3, 4>, <4, 3>, <3, 2>, <2, 1>}
	 4.	 Find the inverse of each of the relations in the preceding exercise.
	 5.	 For the relations of exercise 3, perform the following compositions:
	
a.	 R1 | (R2 | R3)
	
b.	 R4
−1 |R5
	
c.	 (R8 | R7) | (R2 | R1)
10  Basics of Set Theory

457
	
d.	 (R3 | R4)−1 | R3
	
e.	 (R7 | (R6 | R5)−1)−1
	 6.	 For the relations of exercise 3, perform the following set-theoretic operations.
	
a.	 R1 ~ R7
	
b.	 (R2 ∩ R8)
	
c.	 R5 ∪ (R4 ∩ R3)
	
d.	 R3 ∪ (R4 ⊖ R5)
	
e.	 (R6 | R7) ∩ (R4 | R3)
	 7.	 What are the characteristic properties of the following relations and what kind 
of ordering is imposed on a set by each of the following relations?
	
a.	 Identity of numbers
	
b.	 Equality of sets
	
c.	 Relative Preference for goods [what assumptions are you making?]
	
d.	 Subsethood
	
e.	 Not being a subset
	
f.	 Being the complement of
	
g.	 Being a member of a set
	
h.	 Not being the member of a set
	 8.	 For each of the given functions, determine the inverse, if it exists.
	
a.	 f(x) = x2
	
b.	 f(x) = x2	 [Specified domain: the positive integers.]
	
c.	 f(x) = x3–2
	
d.	 f(x) = 10x
	
e.	 f(x) = 
x + 2
	
f.	 f(x) = 3x + 4
	 9.	 Perform the requested compositions of functions.
f (x) = 2x2–2.
g(x) = x + 5.
h(x) = 3x3 + 1
	
a.	 f ∘ g
	
b.	 f ∘ (g ∘ h)
	
c.	 g ∘ (f ∘ h)−1
	
d.	 (f ∘ g) ∘ (g ∘ f)
	
e.	 (g ∘ f) ∘ (f ∘ g)
	
f.	 g−1 ∘ (f ∘ h−1)
	
g.	 (g ∘ h)−1
10.7  Relations and Functions; Inverses and Relative Products of Relations; Converses…

458
	10.	 Determine the requested functions, if possible.
g(x) = 4x + 2.
h(x) = 3x2
	
a.	 g ∘ f = h
	
b.	 h ∘ f = g
	
c.	 g−1 ∘ f = h
	
d.	 g ∘ f = h−1
	
e.	 f ∘ g = h
	
f.	 f ∘ h = g
10  Basics of Set Theory

459
© The Author(s), under exclusive license to Springer Nature 
Switzerland AG 2022
O. Makridis, Symbolic Logic, Palgrave Philosophy Today, 
https://doi.org/10.1007/978-3-030-67396-3
Glossary
Analytic Sentences (also see: Synthetic Sentences).  An analytic sentence of a 
language is a sentence that can be correctly determined to be true or false on the 
basis only of the defined meanings of either logical or non-logical words in the 
sentence. On the view that logical truths are themselves true because of the defi-
nitions of the meanings of the logic-words in them, the collection of analytic true 
sentences includes logical truths as well as sentences that can be determined as 
necessarily true on the basis of the meanings of their non-logical words. Analytic 
sentences can be true or false, and, as such, they are necessarily true or false (on 
some view of what logical necessity is.)
Antecedent.  In a sentence that is a condional (implication, implicative sentence), 
of the logical form “if φ, then ψ,” φ is the antecedent and ψ is the consequent.
Antisymmetry, Antisymmetric Property.  Antisymmetry is a property of a rela-
tion ρ according to which, for every pair α and β that are ρ-related, if both α is 
ρ-related to β and β is ρ-related to α, then α and β must be identical (as symbols, 
they must refer to the same object). Using symbolic resources from our first-
order formal language metalinguistically, we can indicate antisymmetry in this 
way: ∀x∀y((ρxy · ρyx) ⊃ x = y). An example of an anti-symmetric relation is: α 
is less or equal than β.
Anti-Designated Truth Value.  A truth value is anti-designated if and only if it is 
not designated. Assignment or computation of this truth value signals that the 
symbolic formula that has this value cannot be a “winning” formula (a logi-
cal truth). The anti-designated truth value of the standard two-valued (bivalent) 
sentential logic is the “false.” Thus, logical contradictions have as referent this 
anti-designated truth value (the false.) In the case of the standard sentential logic, 
the designated truth value (the “true”) and the anti-designated truth value (the 
“false”) are reversed when negation is applied (negated true is false and negated 
false is true, by definition of the connective that is called negation); this is not, 
however, necessarily the case for alternative or non-standard logical systems in 

460
which, often, there is at least one additional truth value (for example, motivated 
to mean “indeterminate”), which stays fixed when it is negated.
A Priori.  The meaning of a sentence is known a priori if it is known independently 
of empirical verification and cannot be corrected by experience. This concept 
is epistemic (related to what can be known and under what conditions it can 
be known.) For example, considering that a mathematical truth like “one plus 
one equals two” is known a priori: an experience that has putting two things 
together resulting repeatedly to experiencing one thing remaining would not be 
considered as correcting the belief that “one plus one equals two;” it would be 
incomprehensible (not in a psychological sense but as related to meaning), no 
matter how often it happens, rather than be considered as falsifying the sentence 
“one plus one equals two.” The classical view is that logic is known a priori but 
there are philosophic challenges to this view.
Argument.  As a term of logic, an argument is a proof: a collection of meaning-
ful sentences, one of which is the conclusion while the rest are the premises 
and possibly other sentences that are derived from the premises and from other 
derived sentences. In natural language, arguments are often presented enthyme-
matically – with missing premises and/or conclusion, which are to be understood 
as implied. Arguments can be deductive or inductive. A correct deductive argu-
ment is called valid: it is logically impossible for such an argument to have true 
premises and false conclusion. An inductive argument is evaluated as a matter 
of relative strength: if the premises are true, the conclusion is true to a degree of 
probability and a stronger inductive argument, relative to another weaker induc-
tive argument, is one whose conclusion (from the same true premises) is rightly 
assessed to be relatively more likely to be true.
Argument of a Function.  The input of a function is called often “the argument 
of the function.” This is one input, if the fuction is monadic or unary; an n-ary 
function must be defined with n arguments. Disambiguation is important in this 
regard since the term “argument” appears more commonly in logic as defined in 
earlier entry in this glossary.
Arity.  The arity of a function is the number of inputs of the function. The arity 
(also called degree) of a connective of a logical system is the number of inputs 
which the connective has, as defined: also, we may say, the arity or degree of 
a logical connective is the number of well-formed formulas (possibly atomic) 
which are within the scope of the connective as it is defined. A connective can 
be unary/monadic/one-place if it has one input, binary/dyadic/two-place if it has 
two inputs, and, generally, n-ary/n-adic/n-place if it has a number n of inputs for 
n ≥ 1. For n = 0, a so-called zeroary/zero-degree connective is a logical constant: 
a sentential variable that is defined as referring to a truth value (true, usually 
symbolized by “⏉”, or false, usually symbolized by “⏊”.)
Assumed Premise (also, Posited Premise)  see: Formal Proof.
Asymmetry, Asymmetric Property.  Asymmetry is a property of a relation ρ 
according to which, for every pair α and β that are ρ-related, if α is ρ-related to β, 
then β is not ρ-related to α. Using symbolic resources from our first-order formal 
language metalinguistically, we can indicate asymmetry in this way: ∀x∀y(ρxy ⊃ 
~ ρyx). An example of an asymmetric relation is: α is the parent of β.
Glossary

461
Atoms, Atomic Sentences, Atomic Sentence Variables, Atomic Sentence Letters, 
Atomic Formulas, Simple Sentence, Individual Variable.  An atom/atomic 
variable/individual variable/simple variable is the symbol for the ultimate unana-
lyzable component of a meaningful sentence. This may or may not correspond 
to the a simple or non-compound sentence of the natural language. Only truth-
functional symbols can combine sentences to form more complex sentences. (see 
Truthfunctionality) Every atom of a system of the standard logic is considered 
as being possibly true or possibly false: thus, its table of possible assignments 
of truth values (its truth table) must have 2 entries, one for the case in which 
the atom is true and one for the case in which the atom is false. No other value 
assignments are possible and it is not possible for an atom to lack truth value.
Auxiliary Symbols.  In a formal system of logic, the auxiliary (also, ancillary, syn-
categorematic) symbols that are legislated in the system’s formal grammar are 
those that are used strictly to manage matters of ambiguity: to prevent and remove 
ambiguity (availability of more than one plausible readings of the expressions). 
Auxiliary symbols are usually parentheses; different kinds of parentheses and 
brackets, and so on, may be added but only as a matter of visual effect and con-
venience of reading the symbolic expressions. There are formal grammars – like 
the Polish Grammar – which do not require auxiliary symbols to manage ambi-
guity. Such grammars mandate a prefix notation. (See: prefix notation.)
Biconditional.  One of the definable binary logical connectives of the standard for-
mal logic, usually symbolized by “≡” or “↔”, which, as defined, is true exactly 
for the cases of assignments of the same truth value to both of its component 
inputs. The corresponding logic-word in the logic of natural language is pre-
sumed to be “if and only if” (but this term has also acquired another sense in 
everyday language, used to emphasize certainty about an if-then sentence). When 
the sentence connecting two sentences by means of the biconditional is a logi-
cal truth, that means that the two connected sentences are: logically equivalent, 
materially equivalent, imply each other (as logical truths), are either both true or 
both false, have the same truth value for every logically possible assignment of 
truth values to their atomic components.
Binary.  A function or logical connective is binary if and only if it is defined to have 
exactly two inputs or, for logical connectives, to have exactly two well-formed 
formula symbols within its scope.
Bivalence.  A property of a logic, by which the logical connectives of the logic are 
defined over exactly two truth values: these are interpreted semantically as the 
true and the false. From the standpoint of constructing a formal mathematical 
treatment of the logic, it does not matter how those two values are understood 
(for instance, {1, 0} or even {a, b}) insofar as one of them is designated and 
the other is anti-designated. Alternative, non-standard, unorthodox many-valued 
logics can be constructed, whose logical connectives are defined over more than 
two truth values. Theoretically, infinite-valued logics are constructed and have 
been studied. When the number of truth values over which the connectives are 
defined changes, the meanings of the logical connectives should not be expected 
to remain the same and the classical or standard laws of logic (like Excluded 
Middle and Non-­Contradiction, for example) should not be expected to continue 
to be valid within the alternative systems.
Glossary

462
Bound Variable, Bound Variable Symbol.  In first-order/predicate logic, an indi-
vidual variable is bound if and only if it lies within the scope of a quantifier 
symbol that binds this variable. A bound variable is not free. Formulas with free 
or unbound variables are called Sentential Functions/Propositional Functions/
Open Sentences and are so constructed as to be grammatically well-formed but 
lacking in logical meaning.
Cardinality.  The number of members (also called elements) of a set. The number 
of the members of the domain set of a first-order logic model is also called the 
cardinality of the domain. The cardinality of a set can be an infinite number: see 
Countability.
Cartesian Product.  The Cartesian Product of two sets x and y, symbolized as “x ⤬ 
y”, is defined as the set of all definable ordered pairs such that the first member 
of each pair is from set x and the second member of each pair is from set y, taken 
in all possible combinations. x ⤬ y = {<u, w> / (u ∈ x) ∙ (w ∈ y)}.
Completeness.  A formal proof system Π is weakly complete with respect to a tar-
get semantic system Σ if and only if for every formula φ that is a logical truth of 
Σ there is a constructible proof sequence within system Π of φ; a formal proof 
system Π is strongly complete with respect to a target semantic system Σ if and 
only if for every instance of semantic logical consequence from {… φi …} to ψ 
in Σ, there is a constructible proof in Π from premises {… φi …} to derivation 
of the conclusion ψ. In other words, Π is complete with respect to Σ if and only 
if what should be provable (as indicated by the semantic system) can be proven 
indeed by means of a proof that is constructed in Π; or, what is not provable in Π 
is exactly and only what should not be proven. If we use metalinguistic symbols 
for logical consequence and provability, the turnstiles for Σ and Π are respec-
tively “⊢” and “⊨”, and we have:
Weak Completeness  if ⊨ ψ, then ⊢ ψ; if not⊢ ψ, then not-⊨ ψ
Strong Completeness  if {… φi …} ⊨ ψ, then {… φi …} ⊢ ψ;
if not-({… φi …} ⊢ ψ), then not({… φi …}⊨ ψ)
Soundness, on the other hand, which is usually easier to prove in metalogical 
studies of formal sytems, proceeds in the opposite direction. A formal proof system 
Π is sound with respect to a target semantic system Σ if and only if what is indeed 
provable by means of a constructible proof sequence in Π corresponds to a logical 
truth of Σ (weak soundness) or proofs that can be constructed within Π from prem-
ises to conclusion correspond to instances of logical consequence in Σ: in other 
words, what is provable in the proof system is exactly what should be proven  
based on the semantics of the logic; nothing that should not be proven is provable/
derivable. Using the same metalinguistic symbols as above, we have:
Weak Soundness  if ⊢ ψ, then ⊨ ψ; if not ⊨ ψ, then not- ⊢ ψ
Strong Soundness  if {… φi …} ⊢ ψ, then {… φi …} ⊨ ψ;
if not-({… φi …} ⊨ ψ), then not({… φi …} ⊢ ψ)
Composition of Functions.  Given two functions ƒ1 and ƒ2, the composition of ƒ1 
and ƒ2 is a function g = ƒ2(ƒ1(x)), such that the inputs of function ƒ2 are ­generated 
as outputs of function ƒ1. For example: if ƒ1(x) = 2x and ƒ2(x) = x2, then ƒ2(ƒ1(x)) 
= (2x)2 = 4x2. Self-composition of a function ƒ by itself is definable as ƒ(ƒ(x)).
Glossary

463
Composition (Relative Product) of Relations.  The composition or relative prod-
uct of two given binary relations R and S is a relation which is a set of ordered 
pairs <x, y> that are composed as follows: the first member of each pair, x, is 
from R and the second member, y, is from S only if there is some member z such 
that <x, z> is a member of R and <z, y> is a member of S.
Compositionality.  Compositionality is the property of a logical system, by which 
specification of the truth values (logical meanings) of the atomic components of 
a compound sentential formula makes possible precise and correct unique deter-
mination of the truth value (logical meaning) of the compound sentential for-
mula. The standard truthfunctional logic is characterized by compositionality but 
this characteristic is lost for predicate logic (considering the possible availability 
of infinite domains). The grammatical structuring of first-order (predicate) logic 
also permits well-formed construction of systematically ambiguous expressions 
(formulas with free variables), which are meaningless by design (and are called 
sentential functions): accordingly, grammar and semantic computationality are 
severed by design in the case of first-order logic modeling.
Conclusion.  The meaningful (declarative) sentence that is proven/derived/deduced 
in an argument is the conclusion of the argument. In the case of deductive argu-
ments: it is logically impossible for a valid (intuitively, correct) argument to have 
all its premises true and a false conclusion. In the case of inductive arguments: 
the conclusion of the argument is supported by the premises to a degree of prob-
ability or likelihood (which is not to be determined precisely): the conclusion is 
likely to be true if all the premises of an inductive argument are true; thus, induc-
tive arguments can be stronger or weaker when compared (as having the same 
premises) and an inductive argument can be sufficiently strong if the conclusion 
has a roughly significantly high likelihood of being true if all the premises are 
true or weak otherwise.
Conditional/Material Conditional.  One of the definable binary logical connec-
tives of the standard formal logic, usually symbolized by “⊃” or “→”, which, as 
defined, is false exactly for the case of assignments of truth values to its compo-
nent inputs so that its antecedent is true and its consequent is false; and it is true 
for all other possible assignments of truth values to its components. (If we have: 
“if p, then q”, then p is the antecedent and q is the consequent.)
The corresponding logic-word in the natural logic is presumed to be “if—then” 
but the conditional of the standard sentential logic falls short of capturing the logical 
behavior of “if—then” as entailment, inference, or deduction, since this so-called 
material conditional permits trivial and vacuous implication: it is true in every case 
in which the antecedent is false or the consequent is true. When the sentence con-
necting two sentences by means of the material conditional is a logical truth, that 
means that the two connected sentences are related as follows: the first logically 
(materially) implies the second; it is not possible for the first to be true and the 
­second to be false; either the first is false or the second is true (in the sense of the 
inclusive either-or.)
Conditional Proof.  A proof-theoretic method of deriving a putative conclusion 
without any given premises at all, by which a premise is laid down as assumed 
Glossary

464
or posited – generating a sub-proof or sub-derivation – and then proceeding to 
make a correct derivation: to discharge the assumed premise, the symbol of the 
conditional is introduced connecting the assumed premise with the final line of 
the subproof. Thus, assuming φ and proving ψ within the induced subproof, the 
assumed premise φ is effectively discharged (no “debt” is owed), the subproof 
is successfully terminated, and the derived line outside of the terminated sub-
proof must be written: φ ⊃ ψ. If other premises have been given, they may be 
used by being reiterated within the generated subproof.
Conjunction.  One of the definable binary logical connectives of the standard for-
mal logic, usually symbolized by “∙” or “∧” or “&” or “x”, which, as defined, 
is true exactly for the cases of assignments of the truth value true to both of its 
component inputs; and it is false for all the other possible cases of assignments 
of truths values to its components. The corresponding logic-word in the natural 
logic is presumed to be “and” and related phrases. When the sentence connecting 
two sentences by means of conjunction is a logical truth, that means that both 
connected sentences are logical truths.
Connective, Logical Connective, Connective Symbol.  A logical connective of 
the standard sentential and first-order logic is the semantic interpretation of a 
Boolean function. A logical connective of arity n has as its domain the Cartesian 
product of the classical truth values (true and false), {T, F}n, and as its range 
{T, F}. Logical connectives, as defined within a formal system of logic, may 
be motivated by an objective of capturing the logical behavior of the presumed 
matching or corresponding logic-words of a natural language (or of a theoreti-
cally privileged fragment of the natural language.) For instance, the logical con-
nective called “negation” is presumed to correspond to the logic-work “not” and 
related phrases of the language. It is not guaranteed, however, that this match 
is effective and it is not a defect of a logical system if this is not the case: it is 
simply a failure to deliver on claims of applicability of the system to the logical 
analysis of the language. It is remarkable that logical connectives do not and 
cannot have empirically discoverable objects as referents or denotata (objects 
they refer to). The connectives of the standard logic, like the logic- words of the 
language, have their meaning defined over truth values. The meanings of the 
logic-words of a language determine the logic of the language.
Connotation (also see: Denotation).  The connotation/sense/intension of a sen-
tence is distinguished in logic from its denotation/referent/extension. Given the 
extensional character of the standard logic (see related entry: Extensionality), 
logical meaning is understood to consist in the referent or denotatum of the sen-
tence, term or predicate (non-logical constant) or name. The connotation, on the 
other hand, is the robust specification of what the sentence is associated with as 
expressing when it is used. A classic example illustrating the distinction, due 
to Gottlob Frege who worked out the logically significant distinction between 
these two terms: the names “Morning Star” and “Evening Star” apparently have 
the same denotation (they both actually refer to the same celestial objet, Venus) 
but they have had markedly distinct connotations in linguistic usage (as, respec-
tively, “the first star that can be seen in the morning” and the “last star that can be 
Glossary

465
seen in the evening”); moreover, it was not known that the two names co-refer. 
Significantly, having different connotations, the names cannot be inter-substi-
tuted within referentially opaque contexts (see related entry) and, in doing so, 
preserve truth: for instance, the reasonable person knows that “the morning star 
is identical with the morning star” but she may not know indeed that “the morn-
ing star is identical with the evening star” even though “the morning star” and the 
“evening star” have the same denotation (but different connotations.) Thus, “to 
know” generates a referentially opaque context (and it cannot be studied through 
construction of a truthfuntional unary connective!)
Consequence, Logical Consequence.  Logical consequence is the characteristic 
relation between the conjunction of the premises of an argument and the conclu-
sion or the inclusive disjunction of the conclusions of the argument (if multiple 
conclusions are allowed.) A logic is characterized by its logical consequence 
relation: approached semantically (speaking of truth values, true and false, as 
logical meanings), the logic is completely and accurately characterized by the 
collection of the argument forms that are valid in this logic. An alternative char-
acterization of a logic is by means of the collections of its logical truths but 
these two characterizations may fail to coincide if the logic does not validate the 
Deduction Theorem (see related entry.)
If we use the metalinguistic symbol of the turnstile, “⊢”, to mark syntactic logi-
cal consequence, we have: φ1, …, φn ⊢ ψ1, …, ψm if and only if φ1 · … · φn ⊢ ψ1 
∨ … ∨ ψm.
This may be also represented by means of a set of premises as follows (for one 
conclusion, which is the usual case).
{φ1, …, φn} ⊢ ψ if and only if φ1 · … · φn ⊢ ψ.
The inverse turnstile, from right to left, can be used too. In the case in which logi-
cal consequence obtains in both directions, we have logical equivalence, which can 
be indicated metalinguistically as follows for the case of one-conclusion logical 
consequence: φ1, …, φn ⊣ ⊢ ψ.
Consequent  see: Antecedent.
Consistency, Logical Consistency, Consistent Set.  A set or collection of mean-
ingful sentences (a theory, description, story, etc.) is consistent if and only if all 
of the sentences can possibly be true jointly. Possibility is not the same as actual-
ity. Even if a collection of sentences cannot have all its sentences true together 
in the actual world, or in some state of affairs designated as actual, it suffices for 
consistency that it is logically possible that all the sentences are true together in 
some logically possible state of affairs (not necessarily the actual one.) Thus, the 
set {the earth has two moons, the earth has more than one moon} is logically 
consistent although actually both sentences in it are false; but there is a logi-
cally consistent (contradiction-­free) alternative story in which the two sentenes 
are both true. But the set {the earth has one moon, the earth has more than one 
moon} is not logically consistent: there is no logically possible world in which 
both sentences can be true together.
Glossary

466
Two sentences that are each other’s mutual contradictories cannot be logically 
consistent taken together; a logical contradiction makes any set in which it is 
included to be logically inconsistent; the negation of a tautology makes any set in 
which it is included to be logically inconsistent. The familiar truth table method can 
be deployed to determine if a given set of sentences is logically consistent: if at least 
one row of the truth table that is constructed for the sentences takes the truth value 
true for all the sentences, then the set is consistent. A set of sentences that is not 
consistent is inconsistent.
In an argument form: the argument form is valid if and only if the set comprised 
of its premises and the negation of its conclusion is inconsistent (it is not logically 
possible for all its premises to be true and its conclusion to be false.)
Contingency, Logical Contingency.  A meaningful sentence that can be logically 
possibly true and logically possibly false (in different contexts, not in the same 
context since the standard logic is characterized by the law of non-­contradiction: 
see related entry.) In the semantic approach to the standard sentential logic, which 
is usually undertaken by use of truth tables: a well-formed sentential formula is 
logically contingent (a contingency, a logical contingency (logically indetermi-
nate, logically indefinite) if and only if at least one of the rows of its truth table 
has the truth value true and at least one of its rows has the truth value false.
Contradiction, Logical Contradiction.  A meaningful sentence that is logically 
necessarily false and cannot be logically possibly true: in every logically pos-
sible context, this sentence is false. In the semantic approach to the standard sen-
tential logic, which is usually undertaken by use of truth tables: a well-formed 
sentential formula is a contradiction if and only if all the rows of its truth table 
have the truth value false. The contradictions are the logical falsehoods of the 
logic. Alternative logics may not agree among them on the logical falsehoods 
they have. Contradictions or contradictory sentences of the natural language 
are not informative, since they must logically be false in every possible context 
(hence, they cannot “mark” or differentiate any one context from other contexts.)
Sometimes, a distinction is drawn between a contradiction as a necessary false-
hood of sentential logic and logical falsehood as a necessary falsehood of first-
order logic.
Contradictions are rendered false (logically necessarily false) solely on the basis 
of the meanings of the defined logical connectives of the logic. Traditionally, it has 
been remarked that a contradiction is necessarily false because of its logical form. 
Given a specified logical system, its contradictions are automatically settled; it is 
not a matter of empirical discovery what contradictions a logic has.
Alternative logics – non-standard or non-classical logics – which permit more 
than the standard two truth values of true and false, may not regard every formula 
with the form of a classical logical contradiction as false or even as having an anti-­
designated truth value (see related entry): the motivating philosophical view, accord-
ing to which not all contradictions may be false or that not everything follows from 
a contradiction (which is the case in the standard logic), is called Dialethism. A 
rather unpopular view according to which all contradictions are true or take a desig-
nated truth value is called Trivialism.
Glossary

467
In the standard sentential and predicate logic: a contradiction implies anything, 
anything is validly supported by a contradiction (also by an inconsistent set of 
premises, considering that the conjunction of the inconsistent premises is equivalent 
to a contradiction); the negation of a contradiction is a tautology; the double nega-
tion of a contradiction is a contradiction; if a sentence φ implies both some sentence 
ψ and the contradictory of that sentence, not-ψ, then φ is itself a contradiction; if a 
sentence φ is implied by a sentence ψ and is implied also by the negation of ψ, not-
ψ, then the sentence φ is a tautology.
Contraposition.  Contraposition is the valid inferential rule of the standard senten-
tial logic, according to which: Given an implicative sentence (conditional sen-
tence) of the form “if p, then q”, it is a valid inference in the standard sentential 
logic that: “if not-q, then not-p.”
Contrariety.  Two sentences are related by the relation of contrariety, are mutual 
contraries, if and only if it is possible for them to be both false but it is not pos-
sible for them to be both true. By the use of the truth table method, two formulas 
φ and ψ are mutual contraries (related by the relation of contrariety) if and only if 
their truth table shows no row in which they are true together but there is at least 
one row in which they are false together. If two sentential formulas are mutual 
subcontraries they are to be joined by the symbol for the definable logical connec-
tive known as Sheffer Stroke to form a tautology (see: Functional Completeness).
Converse Implication.  Given an implicational (conditional) sentence of the form 
“if p, then q”, the converse implication relative to this sentence is: “if q, then p.” 
The rule of conversion (deriving “if q, then p” from “if p, then q”) is invalid in 
the standard sentential logic. If two sentences are mutually equivalent, and only 
in that case, can we validly derive “if q, then p” from “if p, then q” and we can 
also derive “if p, then q” from “if q, then p.”
Countable, Countability, Countable Set (also, Denumerability).  A set is called 
countable or denumerable if and only if its members can be placed in one-one 
correspondence with the members of the set of integers; or, the cardinality of 
the set is that of the set of the natural numbers. A countable set is infinite but its 
cardinality or size of infinity (also called, countable or denumerable) is the same 
as that of the set of the natural numbers. The set of real numbers, on the other 
hand, is of an uncountable or non-denumerable size of infinity. In fact, there 
is an infinite number of sizes of infinity, as the mathematician George Cantor 
showed. The symbolic resources available to a formal system of logic – such as 
the symbols for atomic variables – are stipulated as being countably infinite: this 
is achieved, for instance, by allowing for subscripts to the atomic variable letters 
but under the proviso that the subscript letter numerals are from a countable set.
Counterexample.  For sentential logic, an assignment of truth values to the atomic 
components of the premises and conclusion of an argument form, for which all 
the premises are rendered true and the conclusion is rendered false is a counterex-
ample to (a claim of validity of) the argument form. Since a deductive argument 
is valid if and only if it is logically impossible for all its premises to be true and 
its conclusion to be false, production of even one counterexample to an argument 
form establishes that the argument form (and, a fortiori, any argument that has 
that form) is invalid. Applying the method of the truth table: a counterexample 
Glossary

468
to an argument form that is being tested by the truth table is the assignment of 
truth values to the atomic components of the premises and conclusions for any 
row of the truth table across which all the premises are true and the conclusion 
is false (if such row exists.) If there is no row of the truth table for an argument 
form, for which all the premises are true and the conclusion is false, then there 
is no assignment of truth values for which all the premises of the argument form 
are true and the conclusion is false: therefore, the argument is valid (there is no 
logical possibility of constructing a counterexample to it.)
For predicate (first-order) logic, a counterexample (countermodel) to an argu-
ment form is an interpretation or valuation assigning objects from a model’s domain 
to names and function symbols, and assignment of collections of objects to predi-
cates, for which all the premises of the argument form are true and the conclusion is 
false. If a countermodel can be produced for an argument form, the argument form 
is invalid: validity of an argument form is defined as validity across all possibly 
constructed models.
Countermodel  see: Counterexample.
Counterfactuals, 
Counterfactual 
Conditionals 
(also, 
Subjunctive 
Conditionals).  A conditional or implicative statement of the natural language 
is called a counterfactual or contrary-to-fact conditional (or, grammatically, a 
subjunctive conditional) if it has a false antecedent and it is true in every state of 
affairs which is appropriately similar to our present state of evaluation with the 
difference that the antecedent is true in that alternative state. Since our standard 
sentential logic has any conditional with a false antecedent as true (vacuously 
true), it is obvious that we cannot depend on the resources of the standard logic 
for a logical analysis of counterfactuals. The machinery of more advanced log-
ics – extensions of the standard sentential and, possibly, first-order logic – are 
needed. A standard example of a counterfactual conditional statement of the nat-
ural language is: “If Oswald had not killed Kennedy, then someone else would 
have.” The implied assumption is the the antecedent is indeed false. In contrast, 
we may regard the following as a material conditional: “If Oswald did not kill 
Kennedy, then someone else did.” The meanings of the two sentences are mark-
edly different.
Decision Procedure.  A mechanical systematic process implemented within a for-
mal system, which terminates within polynomial time and by means of which 
it can be determined: for given argument forms if they are valid or invalid; for 
given formulas if they are tautologies, contradictions or contingencies; for given 
sets of formulas, if they are consistent or inconsistent; and so on. A decision pro-
cedure must terminate in a finite number of steps and effectively, correctly, and 
uniquely yield results which can be read according to specifications, for every 
application of the process. A decision procedure must produce a counterexample 
in case an argument form is invalid (in contrast, failure to derive a conclusion in 
application of a proof-theoretical method like natural deduction does not deci-
sively show that the corresponding argument form is invalid.) The standard sen-
tential logic has effective decision procedures like the truth table method, as well 
as effective tree and tableau procedures. This is not the case for the first-order 
logic (excluding fragments of the logic.)
Glossary

469
Declarative Sentence (also, Declaratory Sentence).  A sentence that is logically 
meaningful and, as such, can be possibly either true or false, not both and not 
neither (on the standard logic view.) The meaning expressed by a declarative 
sentene is often called proposition but there are philosophic reservation about 
the kind of object such a proposition may be. An infinite number of declarative 
sentences may express the same meaning.
Decomposition  see Partition.
Deduction Theorem.  A logic is characterized by the Deduction Theorem – it vali-
dates the Deduction Theorem or the Deduction Theorem is provable in a proper 
proof system for the logic – if the following is the case: when ψ is provable from 
the conjunction of premises φi, then the implicational formula with the conjunc-
tion of the premises φi as antecedent and ψ as consequent is also provable in 
the system.
Deductive Reasoning, Deductive Logic, Deductive Arguments  see: Argument.
Deductive – Inductive Distinction  see: Argument.
Denotation/Referent/Extension  see: Connotation; see: Extension.
Denumerable  see Countable.
Derivation  See: Formal Proof.
Designated Truth Value  see: Designated Truth Value.
Disequivalence, Logical Disequivalence.  Two formulas φ and ψ are mutually dis-
equivalent or they are related by exclusive disjunction (they are mutual exclusive 
disjuncts of each other) if and only if exactly one of them is true and exactly one 
of them is false. The truth table constructed for the formulas shows the formulas 
obtaining opposite truth values (if one is true, the other is false, and the other way 
around) on every row. We can recognize this as the relation of exclusive disjunc-
tion or exclusive either-or: this sense of either-or means that definitely one of the 
two formulas is true but it cannot be that both are true and it cannot be that both 
are false; so, either φ is true and ψ is false or ψ is true and φ is false.
Disjunction (Inclusive).  One of the definable binary logical connectives of the 
standard formal logic, usually symbolized by “∨” or “+”, which, as defined, is 
false exactly for the case of assignments of truth values to its component inputs 
so that both its inputs are false; and it is true for all other possible assignments of 
truth values to its components.
Natural languages are usually marked by ambiguous use of “either-or”: context 
is supposed to remove ambiguity as to whether it is the inclusive or the exclusive 
sense of “either-or” that is intended by the user of the language. (see related entry 
for exclusive disjunction: Disequivalence.)
Disjunction (Exclusive)  see: Disequivalence.
Domain of a First-Order Logic Model.  The domain of a first-order logic model is 
the set of entities or objects in the model, over which the signature of the model 
(see: interpretation) is defined. The specified domain of a model cannot be empty 
in the standard first-order logic but alternative logics permit this. The domain 
of a model can be restricted to specified objects or kinds of objects, or it can be 
unrestricted to any specific objects: in the latter case, translation of sentences of 
Glossary

470
the natural language into the symbolic language of a formal system must define 
predicate symbols for the kinds of things that are being talked about.
Domain of a Function  see: Function.
Double Negation  In the standard sentential logic, the rule of double negation is 
valid: one may infer φ from not-not- φ and may also infer not-not- φ from φ. 
This is not the case for intuitionistic logic: negation of φ is understood by intu-
itionistic logicians and mathematicians to have the meaning of “a proof of φ can 
be converted effectively by means of an in-principle constructible proof method 
into deriving a line of logical absurdity.” For intuitionistic logic, φ cannot be 
derived from not-­not-­φ (although the converse is derivable.)
Empty Domain of a First-Order Logic Model  see: Domain.
Equivalence, Logical Equivalence  see: Biconditional.
Equivalence Relation.  A relation ρ is an equivalence relation if and only if it is 
reflexive, symmetric and transitive. An equivalence relation induces a parti-
tion of a set over whose members it is defined: all members of the set, which 
are ρ-related can be considered as members of the same equivalence class. We 
may think of equivalence relations as being something like identity (all identical 
things being placed together as one thing) albeit weaker than identity (which is 
also an equivalence relation and, as such, the strongest equivalence relation.) For 
instance, under the perspective of similarity (if it is treated as an equivalence 
relation), we can justify placing all similar things within one and the same set 
(which is a subset of the given set over which this similarity relation is defined.)
Ex Falso Quodlibet.  A characteristic rule of derivation, which is valid for the stan-
dard sentential logic but also for intuitionistic logic, by which we may infer any 
sentence when we have derived the absurd sentence (which is itself derivable 
from a logical contradiction.)
Excluded Middle, The Law of Excluded Middle.  This is a classical law of logic – 
valid in the standard logic – by which: any meaningful sentence is either true 
or false; the inclusive disjunction of any formula φ and its negation, not-φ, is a 
logical truth. If a third truth value, for instance interpreted as “indeterminate”, is 
added to the standard logical system and the logical connectives are defined over 
the set of the three truth values so that the negation of indeterminate is also inde-
terminate, we have an example of a logical system in which the law of excluded 
middle fails. In a famous case from classical antiquity, Aristotle courted what 
was essentially an option like this – assigning a value of indeterminate to future 
contingents or meaningful sentences about future events, which are not rendered 
true or false before the actualization of the event – but he realized that the law of 
excluded middle would not be valid anymore and rejected the solution.
Exclusive Disjunction  see: Disjunction (Exclusive).
Existential Commitment.  In the standard first-order/predicate logic, every named 
object is presumed to exist: the machinery of the formalism, as it is set up, 
imposes a commitment to existence of all the named objects; the following is a 
logical truth of the standard first-order logic: for all x, there is a y such that x is 
identical with y. Considering that an existence-predicate is definable as “t exists 
if and only if there is an x such that x is identical with t”, we detect in the afore-
mentioned logical truth the commitment to existence of all named objects. In this 
Glossary

471
standard logic, it is nonsensical to say “such-and-such has a certain characteristic 
but it does not exist” and it is trivially true to say “if everything has such-and-such 
a characteristic, then something has this characteristic.” Alternative approaches 
to first-order logic under the category of Free Logics (see relevant entry) do not 
make this existential commitment.
Extensionality.  Extensionality is the property of a logic, by which logical mean-
ings are defined strictly in terms of what the logical terms denote or refer to 
(denotata, referents.) Thus, the logical meaning of a meaningful sentence (also 
called declarative sentence) is a truth value (true or false.) The logical meaning 
of a predicate in first-order logic is the set of all the members of the model’s 
domain, which have the indicated attribute. This is also called the extension 
of the predicate. This is distinguished from the intension of a predicate. As an 
example: if the members of the football team of a college are exactly the same 
as the members of the set of “students who received A- in the final exam for a 
specified class,” then the two meanings “being a football player in this college” 
and “received an A- for the final exam for a specified class” are extensionally the 
same. Although this departs from the commonsense view of meaning, the exten-
sional character of the (sentential and first-order) logic confers significant advan-
tages for the construction and application of the logic. There is a philosophic 
view that logic ought to be extensional – given that logic ought to be neutral in 
terms of context-variance – but this is controversial.
Another way of defning extensionality of a logical system is by means of the 
property of intersubstitutivity of logical equivalents: replacement of one or more 
occurrences of a formula ψ occurring within a formula φ by a formula χ which is 
logically equivalent to ψ, leaves the logical meaning unaltered: the resulting for-
mula has the same truth values as outputs for the same assignments of truth values 
to the atomic components of the formula as the initial (pre-substitution) formula 
had: i.e., logical equivalence is preserved; the resulting formula, following substitu-
tion, is logically equivalent to the initial formula. Symbolizing logical equivalence 
by “≡” and using “⊢” as metalinguistic symbol for logical consequence (see rele-
vant entry), we have:
If ⊢ ψ ≡ χ, then ⊢ φ(… ψ …) ≡ φ(… χ …).
For Set Theory, extensionality is in evidence as a property of the theory in that 
sets are understood as completely defined by their members or elements: so, any 
two sets with exactly the same objects are equal and can be intersubstituted within 
set-­theoretic operations without altering outcomes.
Intersubstitutivity of logically equivalent formulas fails for contexts that are ref-
erentially opaque. Such contexts are not extensional. For instance, one may know 
that Lewis Carroll is the author of Alice in Wonderland but not know that Charles 
Dodgson is the author of Alice in Wonderland, even though the two names do co-
refer (have had historically the same person as their referent and are, thus, exten-
sionally intersubstituble.)
First-Order Logic, Predicate Logic, Quantification Theory.  The extension of 
the basic sentential logic by means of adding symbols for the standard quanti-
fiers (universal and existential understood to mean “at least one___”), predicates 
(non-­logical constants), terms (individual constants or labels-names for objects 
Glossary

472
of the model’s domain), individual variables and possibly also symbols for iden-
tity and functions. There is a philosophic view that no logic below the first-order 
logic is adequate for symbolization – and this is certainly the case for symbol-
izing truths of mathematics.
Formal Language.  A language with specified symbolic resources and a legislated 
rigid grammar, constructed and applied (with translations into it from natural 
language, or formalizations): unlike natural languages, formal languages are 
austere, limited precisely to the stipulated resources and with strict implementa-
tion of the legislated grammar; accordingly, well-formed (grammatically cor-
rect) symbolic expressions of a formal language cannot exhibit ambiguity or 
superfluity.
Formal Proof.  The totality of lines that are constructed systematically and sequen-
tially by application of formal proof-theoretic rules (rules of deduction, rules of 
derivation) on lines that are already given or have been constructed: the given 
lines are called premises of the proof and the final line is called the conclusion 
of the proof; certain rules of derivation require positing assumed premises which 
must then be discharged if the proof sequence is to terminate.
Free Logic.  An alternative species of first-order/predicate logic which, unlike the 
standard predicate logic, is “free” of presuppositions regarding existence of 
everything that is denoted by some term of the logic. Free Logic does not have 
the standard rules of existential quantifier introduction or universal quantifier 
elimination: usually, universal quantifier symbols can be eliminated in vari-
ants of Free Logic only if it is also given that some individual constant denotes 
an object that exists in the domain. Free Logic also permits speaking of empty 
domains of models, which is not countenanced for the standard predicate logic. 
Consider also defining an existence-predicate as: Et ≝ ∃x(x = t).
Standard logic:
𝓢𝓛 ⊨ ∀x∃y(x = y) [everything for which there are names in the model exists].
𝓢𝓛 ⊨ ∀xFx ⊃ Fa.
But, for Free Logic:
𝓕𝓛 ⊮ ∀x∃y(x = y).
𝓕𝓛 ⊮ ∀xFx ⊃ Fa.
Free Variable (also, Unbound Variable), Free Variable Symbol.  A variable sym-
bol that does not lie within the scope of any quantifier symbol. A formula with 
free variables lacks meaning – it is called a sentential function or open sentence – 
but it is grammatically well-formed. See: Bound Variable.
Function.  A function, as an abstract mathematical object, is a relation between a 
specified input value and the unique value of the output that is generated: given 
the notion of a relation, a function ƒ is defined, then, as the set of the ordered 
pairs <x, ƒ(x)> where x is an input value from the Domain over which the func-
tion is defined and ƒ(x) is the specified output from the specified Range of the 
function (if there are restrictions imposed on the range.) The concept of partial 
function is also definable – a partial function being one for which not all mem-
bers of the domain of the function have outputs.
Glossary

473
Functional Completeness.  A metalogical characteristic of a formal system of 
logic, by which there is at least one functionally complete set of connectives of 
the system. A set of logical connectives is functionally complete if and only if 
its members can be used, by means of iterative compositions, to define all the 
mathematically definable connectives of the system.
For the standard sentential logic there are singleton sets (one-member sets) of 
logical connectives, which are functionally complete beginning at the level of arity 
2: the so-called Sheffer Stroke and Peirce Arrow can be used to define every math-
ematically definable connective of the standard logical system. Symbolizing the 
Sheffer Stroke by “|” and the Peirce Arrow by “↓”, and for symbols from {~, ⊃, ·, ∨, 
≡}, we have: p | q ≝ ~ (p · q) p ↓ q ≝ ~ (p ∨ q). Definitions of connectives can then 
be given:
~ p ≡ (p | p) ≡ (p ↓ p);
(p · q) ≡ ((p | q) | (p | q)) ≡ ((p ↓ p)↓ (q ↓ q));
(p ∨ q) ≡ ((p | p) | (q | q)) ≡ ((p ↓ q)↓ (p ↓ q));
(p ⊃ q) ≡ (~ p ∨ q);
(p ≡ q) ≡ ((p ⊃ q) · (q ⊃ p))
Functionally complete sets of the standard sentential logic include:
{~, ⊃}, {~, ·}, {~, ∨}, {|}, {↓}, {~, ·, ∨}.
A distinction is made between Weak and Strong Functional Completeness. The 
definition given above is of weak functional completeness. Strong functional com-
pleteness is the metalogical characteristic of a set of logical connectives that can 
define not only all mathematically definable connectives of the logic but also the 
so-called zeroary connectives or logical constants (see related entry.) The following 
sets are among those that are strongly functionally complete:
{⏊, ⊃}, {⏉, ⊃, ~}.
Inclusive Disjunction  see: Disjunction (Inclusive).
Inconsistency, Inconsistent Set  see: Consistency.
Indirect Proof (also, Proof by Contradiction, Reductio Ad Absurdum).  A 
proof-theoretic method of deriving a putative conclusion without any given 
premises at all, by which a premise is laid down as assumed or posited – gen-
erating a sub-proof or sub-derivation – and then proceeding to make a correct 
derivation of logical absurdity (a logical contradiction): to discharge the assumed 
premise, the symbol of negation is introduced in front of the assumed premise. 
Thus, assuming φ and proving ψ and not- ψ within the induced subproof, the 
assumed premise φ is effectively discharged (no “debt” is owed), the subproof 
is successfully terminated, and it must be written: not- φ. If other premises have 
been given, they may be usedby being reiterated within the generated subproof.
It is a characteristic of the standard logic, but not of alternative logics like the 
intuitionistic logic, that this method can also be applied for an assumed premise of 
the form “not- φ.” The discharging of the assumed premise compels writing “not-
not- φ” but this is interderivable with φ in the standard logic (but not in intuitionis-
tic logic.)
Glossary

474
The method of Indirect Proof or Reductio is used abundantly in mathematics but 
there are philosophical objections raised by the school of Mathematical-Logical 
Intuitionism which defines negation as constructibility in principle of a proof that 
“assuming φ, then a derivation of absurdity can be constructed” with the notion of 
“if φ, then ψ” understood as availiability in principle of a proof-method for convert-
ing a proof of φ to a proof of ψ: thus, Intuitionism restricts use of the reductio 
method severely and, in so doing, an intuitionist mathematician forfeits a remark-
able portion of standardly proven mathematical theorems across various fields of 
mathematics.
Individual Variable  see: Atom.
Inductive Logic, Inductive Argument  see: Argument, Deductive Logic.
Intensionality  see: Extensionality.
Interpretation, Valuation, Value Assignment, Signature.  An Interpretation/
Valuation/Value Assignment/Signature is the systematic assignment of logical 
meanings to the components of well-formed formulas of a formal logical sys-
tem. In the case of the standard sentential logic, the truth values true and false 
are assigned to the atomic components of the sentential formulas. In the case of 
First-Order/Predicate Logic, systematic assignments are specified by the signa-
ture of a model: truth values to sentences, sets of objects or of ordered n-tuples 
of the domain to predicate symbols, objects of the domain to individual constants 
and to functions (if the system is so equipped). The characteristic of extensional-
ity of the standard sentential logic means that the truth value (logical meaning) 
of any compound sentential formula can be determined precisely and uniquely 
for every possible assignment of truth values to the atomic component variables 
of the formula.
Intersubstitutivity of (Logical) Equivalents  see: Extensionality.
Intuitionistic Logic (also, Intuitionist Logic).  A non-standard logic, a weaker alter-
native to the classical logic and not a sublogic or an extension of it. Motivations 
for intuitionistic logic stem from philosophical views according to which truth 
and falsehood are definable properly on the basis of constructibility in principle 
of proofs in mathematics, or truth and falsehood in natural language are defined 
on the basis of verifiability of claims in principle. The law of excluded middle 
(see related entry) is rejected by intuionistic logic since it is possible both to lack 
proof that a sentence is true and to lack proof that the negation of this sentence is 
true. The law of non-contradiction, on the other hand, does not fail.
Irreflexivity, Irreflexive Property.  Irreflexivity is a property of a relation ρ 
according to which no object is ρ-related to itself; or, equivalently, it is the case 
for any object that it is not ρ-related to itself. Using symbolic resources from our 
first-order formal language metalinguistically, we can indicate irreflexivity in 
this way: ∀x ~ ρxx. An example of an irreflexive relation is: α is less than β: for 
any α, it is the case that α is not less than itself.
Logic-Words  see: Connectives.
Logical Consequence  see: Consequence.
Logical Contradiction  see: Contradiction.
Logical Falsehood  see: Contradiction.
Logical Truth  see: Tautology.
Glossary

475
Material Conditional, Material Implication, Material Biconditional, Material 
Equivalence (see also, Conditional, Biconditional).  The defined logical con-
nectives of the standard two-valued logic for implication (conditional) and 
equivalence (biconditional) are often called “material” to distinguish from non-
truthfunctional definable operators (in logics that extend the standard senten-
tial or first-order logic) such as the one called “strict implication.” Since the 
definable logical connective of implication, conditional, of the standard logic is 
true for every case in which the antecedent is true or the consequent is false, it 
follows that there are reasonable reservations about the claims that this connec-
tive (material conditional) captures the logical behavior of the “if-then” logic-
word of logic, or of such logical notions as “entailment” and “deducibility.” (See: 
Paralogisms) Since the connective of logical equivalence, the biconditional, is 
readily definable as the conjunction of the implications of the two connected 
components, the same remarks apply for the material biconditional.
N-ary/N-place/N-degree  A function or logical connective is  n-ary or n-place 
or n-degree if and only if it is defined to have exactly n inputs or, for logical 
connectives, to have exactly n well-formed formula symbols within its scope. 
Special cases are: unary (n = 1); binary (n = 2); ternary/triadic/three-place (n = 
3); and so on. The case of the zeroary connective (n = 0) is also definable. (see: 
Connectives.)
Natural Deduction  see: Proof-Theoretic Method.
Necessary and Sufficient Conditions.  In an implicational or conditional sentence 
of the form “if φ, then ψ,” φ is the sufficient condition for ψ to be true and ψ is 
the necessary condition for φ to be true.
Negation (also, Denial).  One of the definable unary logical connectives of the 
standard formal logic (and the one that is usually defined in formal systems), 
usually symbolized by “~” or “−” or “¬”, which, as defined, is true exactly for 
the case of assignment of false to its input and it is false exactly for the case of 
assignment of true to its input. The corresponding logic-word in the natural logic 
is presumed to be “not” and related phrases. For the standard logic, a doubly 
negated statement is logically equivalent to the initial statement but this is not 
the case for all logics, a case being that of the non-standard intuitionistic logic.
Non-Contradiction, The Law of Non-Contradiction.  This is a classical law of 
logic – valid in the standard logic – by which: any meaningful sentence cannot 
be both true and false; the conjunction of any formula φ and its negation, not-φ, 
is a logical falsehood (a logical contradiction). If a third truth value, for instance 
interpreted as “indeterminate”, is added to the standard logical system and the 
logical connectives are defined over the set of the three truth values so that the 
negation of indeterminate is also indeterminate, we have an example of a logical 
system in which the law of non-contradiction fails.
Nontruthfunctionality, Nontruthfunctional Connectives, Nontruthfunctional 
Connective Symbols  see: Truthfunctional.
Opaque Context, Referentially Opaque Context  See: Extensionality.
Open Sentence  see: Bound Variable.
Ordered Pair.  An ordered pair is defined as a collection of two elements or mem-
bers from a specified domain, arranged so that the specified order in which their 
Glossary

476
symbols are written matters when writing the symbols that denote the members. 
Unlike two-member sets, the order, from left to right, in which the symbols of 
the members of an ordered pair are written matters, so that, generally, and given 
that a ≠ b:
<a, b> ≠ <b, a>.
An ordered pair <a, b> can be written as, and is considered identical with, the set: 
{{a}, {a, b}}.
The definition is generalized to the case of ordered n-tuples:
Generalizing to the case of the ordered n-tuple, we have:
<x1, …, xn> = {{x1}, {x1, x2}, …, {x1, x2, …, xn}}.
Paralogism.  A paralogistic claim is a claim that a logical connective captures the 
logical behavior of a logic-word of the natural language when such a claim can-
not be properly supported: for instance, it is paralogistic to claim that the logi-
cal connective of material implication, the material conditional, of the standard 
sentential logic can be motivated for the study of meanings of “if-then” that 
are associated with entailment, deduction or other uses of “if-then” in natural 
language. For the material conditional, if the antecedent is false, the conditional 
sentence is true no matter what the consequent is; similarly, if the consequent 
is true, then the material conditional is true no matter what the antecedent is. 
These are often called paradoxes of material implication but they are not para-
doxes since they follow properly from the definition of the connective of material 
implication; they are, however, paralogisms if, in addition, it is claimed that this 
connective indeed corresponds to the uses of “if-then” in natural language.
Partition  see: Equivalence Relation.
Power Set.  The set that has as members all, and only, the subsets of a given set x is 
called the power set of x and is symbolized by “℘(x)”. The set x itself, and the 
empty set, are also members of the power set since they are subsets of x.
Predicate Logic  see: First-Order Logic.
Proof  see: Formal Proof.
Proof by Contradiction  see: Indirect Proof.
Proof Without Premises, Proof Without Assumptions  see: Conditional Proof.
Proof-Theoretic Method.  A proof system in which specified rules of derivation 
are applied to generate lines from given and already derived lines, in this fashion 
constructing a proof from given premises, or from no premises at all, to the con-
clusion. Unlike the semantic approach to the study of logic, the proof-theoretic 
method understands the logical connectives to be defined by means of the rules 
by which the connective symbols are managed in the proof-theoretic system. In 
the case of the standard logic, the semantic approach (for instance, the truth table 
method) and the proof-theoretic approach harmonize in the sense that whatever 
is valid as argument or tautology in the semantic approach is provable or prov-
able from no premises in the proof-theoretic approach and vice versa. See also: 
Completeness.
Proposition  see: Declarative Sentence.
Propositional Function  see: Bound Variable.
Glossary

477
Quine Corners.  Quine corners, “⌜” and “⌝”, are metalinguistic symbols used to 
enclose symbolic expressions from the object language of a formal logical sys-
tem, which are mentioned rather than used when appearing in the symbolically 
enhanced metalanguage.
Reductio Ad Absurdum  see: Indirect Proof.
Referential Opacity, Referentially Opaque Contexts  see: Extensionality, 
Denotation, Connotation.
Reflexivity, Reflexive Property.  Reflexivity is a property of a relation ρ accord-
ing to which every object is ρ-related to itself. Using symbolic resources from 
our first-order formal language metalinguistically, we can indicate reflexivity in 
this way: ∀xρxx. An example of a reflexive relation is: α is identical with β: for 
every α, it is the case that α is identical with itself. A relation like, for example, 
α-likes-β does not have to be reflexive.
Relation.  In First-Order/Predicate Logic, a relation or relational predicate is a 
predicate symbol of arity or degree two or larger.
In Set Theory: An n-place relation over a domain can be defined as a set of 
ordered n-tuples from a specified domain 𝕯. An n-place or n-ary relation, as a set, 
is a subset of the nthCartesian product of the domain by itself, symbolized as 𝕯 
x …[n]… x 𝕯 = 𝕯n.
Relative Product  see: Composition.
Relevantism, Relevantist Logic.  Relevantism is a philosophic-logical view that 
seeks to restrict logical truths (or the relation of logical consequence – what is 
validly derivable from what) by imposing the requirement that there has to be 
meaning-­content connection (relevant or relevantist conection) between prem-
ises and conclusion of valid arguments. Logics that are constructed with a view 
to observing this restriction are called Relevantist Logic. The standard logic is 
not relevantist, as evidenced by such “paralogistic” valid argument schemata as: 
p ∙ ~ p /.. q; q /.. p ∨ ~ p;.
~ p /.. p ⊃ q; q /.. p ⊃ q; p /.. p ∨ q;.
((p ⊃ q) ⊃ p) ⊃ p.
Satisfaction/Joint Satisfiability.  A set of formulas is jointly satisfiable if and only 
if there is a truth value assignment (a row of the truth table) on which all the for-
mulas are computed or determined as being true. This is a semantic concept since 
value-assignment is mentioned in the definition, with the designated truth value 
“true” being the “satisfying” value. The corresponding proof-theoretic concept is 
consistency but, in practice, the two terms are interchangeable and “consistency” 
is commonly used to characterize collections of meaningful sentences (theories) 
whose sentences can all be possibly true together.
Sentential Function/Propositional Function/Open Sentence  see: Bound 
Variable.
Soundness  see: Completeness.
Sub-Contrariety, Subcontrariety.  Two formulas φ and ψ are called mutual sub-
contraries (or related by the relation of subcontrariety) if and only if it is pos-
Glossary

478
sible for them to be both true but it is not possible for them to be both false. The 
truth table for these formulas has no rows across which they are both false; the 
formulas can be true together but they cannot be false together. If two sentential 
formulas are mutual subcontraries they are to be joined by the symbol for inclu-
sive disjunction to form a tautology.
Sub-Proof, Sub-Derivation  see: Conditional Proof.
Substitutivity of Logical Equivalents  see: Intersubstitutivity of Equivalents.
Symmetry.  Symmetry is a property of a relation ρ according to which, for every 
pair α and β that are ρ-related, if α is ρ-related to β, then β must also be ρ-related 
to α. Using symbolic resources from our first-order formal language metalinguis-
tically, we can indicate symmetry in this way: ∀x∀y(ρxy ⊃ ρyx). An example of 
a symmetric relation is: α is similar to β.
Synthetic Sentences (also see: Analytic Sentences).  A sentence of a language is 
synthetic if and only if its truth value (whether it is true or false) cannot be deter-
mined on the basis of the meanings of its logical and non-logical words. Thus, 
a synthetic sentence is not necessarily true or necessarily false: it is logically 
possibly true and logically possibly false: even if it is known to be actually true/
false, there is a consistent alternative state in which it can be made false/true. The 
informative sentences of a language are synthetic whereas analytic sentences 
(which are necessarily true/false on the basis of the defined meanings of their 
logical or non-logical words) are not informative and are trivially true/false.
Tautology, Logical Truth.  A meaningful sentence that is logically necessarily true 
and cannot be logically possibly false: in every logically possible context, this 
sentence is true. In the semantic approach to the standard sentential logic, which 
is usually undertaken by use of truth tables: a well-formed sentential formula 
is a tautology if and only if the sentence has the truth value true in all the rows 
of its truth table. The tautologies are the logical truths of the logic. Alternative 
logics may not agree on the logical truths they have. Tautologous or tautological 
sentences of the natural language are not informative, since they must logically 
be true in every possible context (hence, they cannot “mark” or differentiate any 
one context from other contexts.)
Sometimes, a distinction is drawn between a tautology as a necessary truth of 
sentential logic and logical truth as a necessary truth of first-order logic.
Tautologies are rendered true (logically necessarily true) solely on the basis of 
the meanings of the defined logical connectives of the logic. Traditionally, it has 
been remarked that a tautology is necessarily true because of logical form. Given a 
specified logical system, its tautologies are automatically settled; it is not a matter 
of empirical discovery what tautologies a logic has. Sometimes a logical system is 
defined as the collection of its tautologies; alternatively, a logical system can be 
defined by its characteristic relation of logical consequence (see related entry.) 
Nevertheles, the two ways of defining a system might fail to coincide if the charac-
terization is about an alternative, non-classical, logical system that does not validate 
the so-called Deduction Theorem (see related entry.)
Glossary

479
In the standard sentential and predicate logic: a tautology is implied by anything, 
anything validly supports a tautology; a tautology is provable from the empty set of 
premises; the negation of a tautology is a contradiction; the double negation of a 
tautology is a tautology; if a sentence φ is implied both by some sentence ψ and by 
the contradictory of that sentence, not-ψ, then φ is itself a tautology.
Tertium Non Datur.  This is a principle that restricts the truth values of a logical 
system to exactly two: standardly, the “true” and the “false.” The meaning is 
that a third truth value (an additional way of being true or being false) does not 
exist or cannot be given meaningfully. Non-standard many-valued logics do not 
observe this principle but the standard logic (both sentential and first-order logic) 
is bivalent or two-valued and, as such, it observes the principle.
Transitivity, Transitive Property.  Transitivity is a property of a relation ρ accord-
ing to which, for all objects α, β and γ, if both α is ρ-related to β and β is ρ-related 
to γ, then α must be ρ-related to γ. Using symbolic resources from our first-
order formal language metalinguistically, we can indicate transitivity in this way: 
∀x∀y∀z((ρxy · ρyz) ⊃ ρxz). Identity is a transitive relation. Being the parent 
of someone is not a transitive relation (one’s parents’ parents are grandparents, 
not parents.) It is interesting to reflect, and examine, if preference relations are 
transitive (if someone’s preference of α over β and simultaneous preference of β 
over γ entails that this person also prefers α over γ when the preference decision 
is applied to the objects denoted by α and γ).
Truth Table.  The truth table method is the most popular textbook method for con-
structing a semantics (modeling) for the standard sentential logic: constructed 
with rows and columns, the truth table can be used to define the logical connec-
tives of a logic (not only the standard two-valued logic) and can be applied to 
determine computationally whether logical forms of arguments are valid, rela-
tions among forms of sentential formulas, and the logical status of the forms 
of sentential formulas (whether a form is a tautology, a contradiction, or a 
logical contingency: see related entries.) The truth table cannot be applied for 
first-order logic or extensions of the standard logic (modal logics), except under 
far-reaching specified restrictions. The truth table can easily become untenable 
because, notwithstanding its contribution to computational facility, the number 
of required rows and columns can grow beyond manageability: if the number of 
kinds of atomic variable symbols in a formula is n, then the number of rows of 
this formula’s truth table is: 2n.
Truthfunctional 
Connective 
(also 
see: 
Extensionality, 
Denotation, 
Connotation).  A logical connective is truthfunctional if and only if the connec-
tive is defined so that specified assignments of truth values for its components/
inputs permits unique and correct determination of the truth value of its output: 
hence the name “functional.” Expressions of the natural language, like “neces-
sarily” and “possibly” (also, “probably,” “it has always been the case that___,” 
“it is morally obligatory that ____,” “it is exactly here the case that ____,” “it is 
known that___,” “it is believed that___,” etc.), are not truthfunctional: indeed, it 
happens to be true that “Washington is the capital of the US” and it is also true 
Glossary

480
(although necessarily true) that “if Washington was a general, then he was a 
general.” Taking the first sentence as input for “it is necessarily the case that___” 
yields false; but taking the second sentence as input yields true. Thus, we have 
both true and false as possible output values when the input is true. This shows 
that “it is necessarily the case that___” is not truthfunctional.
Unary/Monadic/One-Place.  A function or logical connective is unary/monadic/
one-place if and only if it is defined to have exactly one input or, for logical 
connectives, to have exactly one well-formed formula symbol within its scope.
Universe  see: Domain.
Validity, Valid Argument, Valid Argument Form.  Validity is a characteristic of 
deductive arguments that are intuitively “correct”, arguments in which the prem-
ises provide absolute, logically necessary support for the conclusion: if the prem-
ises are true in a valid deductive argument, then it is logically necessary that the 
conclusion is true; it is logically impossible that all the premises of a valid argu-
ment are true and the conclusion is false. Validity is a matter of logical form: a 
valid argument form is one that cannot possibly have instances with all premises 
true and false conclusion. A valid argument exemplifies a valid argument form 
and a valid argument form can only have valid arguments as instances.
Well-Formed Formula.  A symbolic expression that is properly or correctly con-
structed in accordance with the stipulated formal grammar of a formal language. 
If not well-formed, a symbolic expression cannot “scan,” it is nonsensical or 
meaningless within the given formal language. Only well-formed formulas can 
be used within a formal language. The grammatical rules, according to which 
formulas are well-formed, are stipulated strictly within the formal systems and 
cannot be assessed by reference to any transcendent standards. A formula which 
is not well-formed, for a given formal grammar, is considered non-well-formed 
or ill-formed. Any symbolic expression, assessed by the formal grammatical 
standards of a given formal language, can be either well-formed or ill-formed, 
and it cannot be neither or both.
Unbound Variable  see: Free Variable.
Valuation  see: Interpretation.
Zeroary Connective  see: Arity.
Glossary

481
© The Author(s), under exclusive license to Springer Nature 
Switzerland AG 2022
O. Makridis, Symbolic Logic, Palgrave Philosophy Today, 
https://doi.org/10.1007/978-3-030-67396-3
References
Adams, E. W. (1975). The Logic of Conditionals. Dordrecht: Reidel.
Allwood, J., Andersson, L., & Dahl, O. (1977). Logic in Linguistics. Cambridge: Cambridge 
University Press.
Anderson, A. R., & N. D. Belnap, J. (1975). Entailment: The Logic of Relevance and Necessity 
(Vol. 1). Princeton: Princeton University Press.
Anderson, A. R., N. D. Belnap, J., & Dunn, M. (1992). Entailment: The Logic of Relevance and 
Necessity (Vol. 2). Princeton: Princeton University Press.
Appiah, A. (1985). Assertion and Conditionals. Cambridge: Cambridge University Press.
Ayer, A. J. (1946). Language, Truth, and Logic. London: Gollancz.
Barth, E. M. (1974). The Logic of the Articles in Traditional Philosophy. Dordrecht: Reidel.
Barwise, J. (Ed.). (1977). Handbook of Mathematical Logic. Amsterdam: North-Holland.
Barwise, J., & Etchemendy, J. (1987). The Liar: An Essay on Truth and Circularity. Oxford: 
Oxford University Press.
Beall, J. C. (2010). Logic: The Basics. London: Routledge.
Bell, J., & Machover, M. (1977). A Course in Mathematical Logic. Amsterdam: North-Holland.
Bochenski, I. M. (1968). Ancient Formal Logic. Amsterdam: North-Holland.
Boole, G. (1854). The Laws of Thought. London: Macmillan.
Boolos, G., & Jeffrey, R. C. (1989). Computability and Logic (3 ed.). Cambridge: Cambridge 
University Press.
Burgess, J. P. (2009). Philosophical Logic. Princeton, NJ: Princeton University Press.
Caton, C. (Ed.). (1963). Philosophy and Ordinary Language. Urbana-Champaign, Ill: Illinois State 
University Press.
Church, A. (1956). Introduction to Mathematical Logic (Vol. 1). Princeton: Princeton 
University Press.
Cresswell, M. (1973). Logics and Languages. London: Methuen.
Dummett, M. (1981). The Interpretation of Frege’s Philosophy. London: Duckworth.
Dummett, M. (2000). Elements of Intuitionism. Oxford: Oxford University Press.
Enderton, H. B. (1972). A Mathematical Introduction to Logic. New York: Academic Press.
Englebretsen, G. (2020). Figuring It Out. Berlin: De Gruyter.
Gabbay, D.  M., & Guenther, F. (Eds.). (1983). Handbook of Philosophical Logic (Vol. 1). 
Dordrecht, Reidel.
Gabbay, D.  M., & Guenther, F. (Eds.). (1984). Handbook of Philosophical Logic (Vol. 2). 
Dordrecht: Reidel.
Gabbay, D.  M., & Guenther, F. (Eds.). (1986). Handbook of Philosophical Logic (Vol. 3). 
Dordrecht: Reidel.

482
Gabbay, D.  M., & Guenther, F. (Eds.). (1989). Handbook of Philosophical Logic (Vol. 4). 
Dordrecht: Reidel.
Gamut, L. T. (1991). Logic, Language, and Meaning (Vol. 1). Chicago: University of Chicago Press.
Geach, P. (Ed.). (1975). Logical Investigations. Oxford: Blackwell.
Geach, P. T. (1972). Logic Matters. Berkeley, CA: University of California Press.
Goble, L. (Ed.). (2001). The Blackwell Guide to Philosophical Logic. Oxford: Blackwell.
Haack, S. (1978a). Philosophy of Logics. Cambridge: Cabridge University Press.
Haack, S. (1978b). Philosophy of Logics. Cambridge: Cambridge University Press.
Heyting, A. (1956). Intuitionism. Amsterdam: North-Holland.
Horn, L. R. (1989). A Natural History of Negation. Chicago: University of Chicago Press.
Hughes, R. I. (Ed.). (1993). A Philosophical Compansion to First-Order Logic. Indianapolis, IN: 
Hackett.
Hunter, G. (1971). Metalogic. London: Macmillan.
Jackson, F. (Ed.). (1991). Conditionals. Oxford: Oxford University Press.
Jeffrfey, R. C. (1967). Formal Logic: Its Scope and Limits. New York: McGraw-Hill.
Kalish, D., & Montague, R. (1964). Logic. New York: Harcourt Brace.
Keenan, E., & Faltz, L. (1985). Boolean Semantics for Natural Languages. Dordrecht: Reidel.
Kleene, S. C. (1952). Introduction to Metamathematics. Amsterdam: North-Holland.
Kneale, M., & Kneale, W. (1962). The Development of Logic. Oxford: Oxford University Press.
Lambert, K. (Ed.). (1969). The Logical Way of Doing Things. New Haven, CT: Yale University Press.
Lambert, K. (Ed.). (1991a). Philosophical Applications of Free Logic. Oxford: Oxford 
University Press.
Lambert, K. (Ed.). (1991b). Philosophical Applications of Free Logic. Oxford: Oxford 
University Press.
Lambert, K., & Fraassen, B. C. (1972). Derivation and Counterexample. Encino, CA: Dickenson.
Lemmon, E. J. (1965). Beginning Logic. London: Methuen.
Martin, R. (Ed.). (1984). Recent Essays on Truth and the Liar Paradox. Oxford: Oxford 
University Press.
Massey, G. (1970). Understanding Symbolic Logic. London: Harper & Row.
McCall, S. (Ed.). (1967). Polish Logic: 1920–1939. Oxford: Oxford University Press.
Mill, J. S. (1979). System of Logic. London: Longmans.
Munitz, M. K. (Ed.). (1973). Logic and Ontology. New York: New York University Press.
Prawitz, D. (1965). Natural Deduction. Stockholm: Almqvist & Wiksell.
Quine, W. V. (1940). Mathenmatical Logic. Cambridge, MA: Harvard University Press.
Quine, W. V. (1952). Methods in Logic. London: Routledg & Kegan Paul.
Quine, W. V. (1953). From a Logical Point of View. Cambridge, MA: Harvard University Press.
Quine, W. V. (1970). Philosophy of Logic. Englewood Cliffs, NJ: Prentice Hall.
Read, S. (1988). Relevant Logic. Oxford: Blackwell.
Reichenbach, H. (1966). Elements of Symbolic Logic. New York: Feww Press.
Rescher, N. (1976). Plausible Reasoning. Assen: Van Gorcum.
Restall, G. (2000). An Introduction to Substructural Logic. London: Routledge.
Russell, B., & Whitehead, A. N. (1910–1913). Principia Mathematica. Cambridge: Cambridge 
University Press.
Sainsbury, M. (1991). Logical Forms. Oxford: Blackwell.
Schechter, E. (2005). Classical and Non-Classical Logics. Princeton, NJ: Princeton University Press.
Smullyan, R. (1968). First-Order Logic. Berlin: Springer.
Strawson, P. F. (1967). Introduction to Logical Theory. London: Methuen.
Suppes, F. (1957). Introduction to Logic. New York: Van Nostrand.
Tarski, A. (1965). Introduction to Logic. Oxford: Oxford University Press.
Tennant, N. (1978). Natural Logic. Edinburgh: Edinburgh University Press.
Thomason, R. (1970a). Symbolic Logic. London: Macmillan.
Thomason, R. H. (1970b). Symbolic Logic: An Introduction. London: Macmillan.
References

483
van Benthem, J., & Meulen, A. t. (Eds.). (1984). Generalized Quantifiers in Natural Language. 
Dordrecht: Foris.
van Fraassen, B. C. (1971). Formal Semantics and Logic. New York:: Macmillan.
van Heijenoort, J. (Ed.). (1967). From Frege to Gödel: A Source Book in Mathematical Logic. 
1879–1931. Cambridge, MA: Harvard University Press.
Wright, C. (Ed.). (1984). Frege: Tradtion and Influence. Oxford, Blackwell.
References

485
© The Author(s), under exclusive license to Springer Nature 
Switzerland AG 2022
O. Makridis, Symbolic Logic, Palgrave Philosophy Today, 
https://doi.org/10.1007/978-3-030-67396-3
Numbers and Symbols
∃!, 339
Π⧉, 351
Π⧉⌹, 358
Π⧉⌻, 364
Π⧉∞, 357–371
Πμ, 291, 292, 300, 302–309, 312, 
314–324, 326
Ππφ=⍳, 397
Πρ=↙↓↘, 390–396
∑, 84
Σ||ⅈ, 239
Σ⊞, 119, 148–173, 209, 241
Σ⊞p, 158–160
Σ⊞𝑠, 160–163
Σ∎, 177
Σ⇒, 247
Σ↙↓↘, 257, 265
∑POLISH, 104, 113
ℑ(Ππφ=), 324
ℑ(Σ), 109–114
ℳ(Σ), 84, 86, 98, 105, 118, 145, 272, 275, 
291, 306
A
Absorptive Property - Set Theory, 428
Abstract objects, 4, 5, 39, 40, 50, 84, 173, 240, 
406, 435
Absurdity – logical, see Nonsense, logical
Addition - Natural Deduction Rule, 187
Addition of premises to weaken argument, 170
Alternative non-standard logics, 4
Ambiguity -- not tolerated in logic, 19
Ambiguity regarding “either or” in natural 
language, 134
Analytic Sentences, 50, 459
And/or, 97
Antecedent, 51, 66, 118, 119, 125, 129, 130, 
141, 142, 163, 164, 183, 184, 205, 
217, 222–224, 237, 245, 282, 287, 
296, 323, 334, 367, 418
Anti-designated truth value, 116
Antisymmetric property of relations, 449
Applied Logic, 4
Aprioricity, as a characteristic of logic, 20
Argument - definition, 42
Argument form, 8
only deductive arguments are 
characterized by, 46
Argument of a function, 451
Aristotle, 7, 8, 11, 15, 17, 19, 21, 22, 24–26, 
53, 128, 240, 289, 309, 310, 314, 
347, 348, 398
Arities of functions - defined, 83
Assertion, 13
Assignment of truth values, 16, 38, 41, 51, 78, 
123, 124, 137, 144, 147, 150, 152, 
225, 259, 260, 264, 266, 267
Assignments for models with all named 
domain objects, 358
Assignments of truth values to the atomic 
components, 117, 150, 168
Assignment-variants in Predicate Logic 
Models without All Named 
Objects, 365
Associative Property, 427, 430
functional composition, 455
Index

486
Associativity, 88, 99, 222
Asymmetry - as a property of relations, 
371, 448
Atomic component sentences, 78
Atomic formulas, 87
Atomic letters, 87
Atomic sentences, 16
how to determine, 34
Atomic variable, 38
Auxiliary symbols, 85, 87, 98, 101, 138, 162, 
272, 274, 292, 331
Axiomatizing sentential logic, 214
Axiom of Choice, 438
B
Biconditional, 85, 304
Binary, 29, 30, 41, 70, 77, 85, 87, 89–91, 93, 
96, 102, 103, 105, 110, 111, 117, 
123, 124, 130–133, 140, 141, 
156–158, 183, 184, 230, 252, 272, 
277, 300, 303, 315, 318–320, 323, 
334, 353, 355, 356, 358, 374, 384, 
400, 410–412, 423–427, 429, 440, 
442–447, 450, 454
Bivalence, 399
Bivalent, 16, 83, 126, 161, 162, 173, 259, 
399, 401
Boolean algebra, 115, 405
Boolean functions, 405
Boolean multiplication, 427
Both true and false - not permitted in standard 
logic, 14
Bound variables, 303, 319
Branches and paths - parsing tree, 111
Branch - parsing tree, 109
Broad scope - negation, 402
Brouwer, L., 239
C
Calculus, 83, 214
Cardinality, 338, 343, 344, 382, 419, 424
Cardinal number, 343, 369
Carnap, Rudolf, 165
Carroll, L., 17
Cartesian product, 166, 167, 355, 423, 424, 
434, 442, 443, 445–447, 450, 
454, 477
Case - as value assignment, 38
Church, A., 451
Circular, definition, 20
Circularity, 20, 21, 105
Closed path, 259, 266, 270
Closed tree, 266, 267
Closure clause, 208, 374
Closure -- predicate logic tree system, 392
Closure tree, 264
Collection of logical truths - in relation to the 
definition of logic, 3
Commutative Property - Set Theory, 427
Commutativity, 217, 222
Complementation, as set-theoretic 
operation, 425
Complement of the Empty Set, 427
Complement of the Universal Set, 427
Completed parsing tree, 111
Completed tree, 391
Completeness, 177
Completeness of the Fitch-type natural 
deduction system, 210
Compositionality - as logical  
characteristic, 38
Compositionality of meaning, 38, 352
Composition of functions, 453
Composition of relations, 446
Compound sentence, 16, 26–30, 45, 73, 273, 
281, 289
Computability, 162
Computability under incomplete 
information, 147
Computational character of the basic sentential 
logic, 150
Computationality of Meaning, 147
Computations, 158, 162
Conclusion, 57, 58, 61, 64–66, 153, 158, 159, 
175, 177, 261, 266, 267
Conditional, 85, 304
Conditional Proof (CP), 183–187, 191, 384
Conjunction, 73, 162, 179, 260–262
Conjunction rule, 179
Conjuncts, 162
Connective/s, 162, 177, 259, 260
Connotation, 23
Consequent, 51, 66, 119, 125, 129, 141, 142, 
163, 164, 183, 184, 204, 222–224, 
237, 244, 245, 282, 283, 287, 289, 
323, 367
Consistency, 49
determined by a tree system, 257
determined by natural deduction, 237
determined by truth tables, 155
and joint satisfiability, 126
studied by logic, 3
Consistent pair of formulas, 155
Constructive Dilemma (CD), 187–190, 192
Index

487
Content of sentence - does not matter in 
deductive logic, 33
Content of sentences - not relevant for 
deductive logic, but relevant for 
inductive logic, 9
Context variability of truth values - not 
admitted in the standard logic, 13
Contingency, 25, 27, 55, 78, 79, 126, 143, 144, 
148, 152, 155, 160, 169, 170, 172, 
238, 257, 261, 265–268, 391, 395
determined by truth tables, 154
Contradiction, 16, 21, 22, 25–28, 49, 53–55, 
75, 78, 79, 126, 128, 143, 144, 147, 
148, 150, 152, 154, 160, 161, 163, 
164, 168–170, 172, 173, 184, 195, 
197, 207, 208, 216, 218, 229, 231, 
233, 237, 238, 249, 257, 261, 
264–269, 336, 337, 341, 348, 
354, 391
determined by truth tables, 154
Contraposition, 244, 255, 311, 432
Contrapositive, 283, 432
Contrariety, 157, 467
Converse implication, 131
Converse - not the same as the inverse in set 
theory, 453
Converse of a function, 452
Converse of a function may not be a 
function, 452
Converse of an implication, 156
Converse relation, 452
Converse turnstile, 125
Conversion, 156
Conversions to and from implications 
formulas in predicate logic, 363
Conversions to prenex form, 363
Correct logic -- is there one?, 4
Countable set, 178, 338
Counterexample, 65, 153, 158, 159, 
161–163, 267
to an argument form, 16
and argument validity, 68
defined, 46
Counterfactuals, 38
Countermodel, 357, 358, 392, 394, 396
Currency denomination - meanings of words 
in a language are like---, 45
D
Decision procedure, 5, 148, 152, 153, 159, 
209, 228, 237, 257, 271, 342, 343, 
357, 390, 391
Declarative sentence, 50, 258, 272, 276, 289, 
305, 408
Declaratory sentence, see Declarative sentence
Decomposition tree, 112
Deduction Theorem, 125, 187
Deductive arguments, 3
Deductive reasoning, 57, 66, 71
Definite descriptions, 346, 397–400, 402, 403
DeMorgan Laws - natural deduction, 199
DeMorgan Laws - predicatre logic, 374
DeMorgan Property - Set Theory, 427
Denotation, 23
Density - as a property of relations, 448
Denumerable, see Countable
Denumerable set, 178
Derivation system, see Proof-theoretic system
Designated truth value, 16, 42, 116, 127, 258, 
259, 264
Deviation from a formal language, 83
Differences between logic and geometry, 21
Discharge of an assumed in the Fitch-style 
proof method, 211
Discharge of premises, 190
Discharge of the posited assumption, 195
Discharge of the posited assumption - 
degenerate case, 224
Disequivalence, 131, 136, 157, 429, 432
exclusive disjunction, logical/material, 157
Disjunction, 97, 99, 107, 118, 124,  
134–136, 157, 158, 161, 165, 
168–170, 183, 184, 191, 192, 195, 
201, 205, 217–222, 225, 231, 234, 
237, 242, 249, 251, 262, 263, 282, 
284, 334, 339, 362, 363, 374, 375, 
378–380, 411, 426, 432, 441, 
454, 469
Disjunctive Syllogism, 187–190, 379, 380
Distributive Properties - Set Theory, 428
Domain of a function, 70, 449
Domain - predicate logic models, 294
Double negation (DN), 195–197, 201, 228, 
229, 231, 233, 242, 255, 263, 264, 
311, 432
E
E!, 403
Eigenparameter, 354, 358, 380–384,  
389, 392
Eliminations of quantifier symbols --- 
predicate logic tree system, 394
Empty domain - not allowed in the standard 
predicate logic, 353
Index

488
Empty set, 427, 428, 430, 437, 438
can be constructed in the Zermelo-Fraenkel 
Systematization, 409
definition, 309
as member of a set, 410
only one exists, 409
of premises and logical truth, 127
as referent of predicate, 320
set theory, 355
subset of every set, 417
Equality symbol in logic, 275
Equivalence, 85, 304
class, 414
class modulo similarity, 414
relation, 197, 413, 414, 416, 421,  
431, 449
Euclidean, 4, 12, 25, 312, 354, 371,  
416, 456
Euclidean geometry, 12
Evolutionary Selection and Logic, 12
Exactly n, 346
Excluded Middle, 196, 197, 222, 229, 
231–234, 241, 242, 428, 435, 
438, 440
Exclusive disjunction, 131, 157
Ex falso quodlibet, 228, 229, 232
Existential commitment, 310, 311, 353
Extensionalist View of Logic, 22
Extensionality, 23, 24, 408
Extension of a formal language, 83
Extracting theargument form, 47
Extraneous symbols in formal grammar, 101
F
Fitch-style proof system, 208
Fitch system, 242
Formal grammar, 84
Formality, as a characteristic of logic, 16
Formalization, see Translations from English 
into the Formal Language of 
Predicate Logic
Formal languages, 12
Formal logic, 4
Foundational Character of Logic, 7
Fragments of language, 12
Free Logic, 313, 353, 364
Free variable, 306
Frege, G., 19, 20, 398, 399, 401, 403, 443
Functional completeness, 132
Function - definition, 449
Fuzzy logics, 19
Fuzzy Set Theory, 444
G
Generality, as a characteristic of logic, 17
Gentzen, G., 174
Geometry, 4, 12, 21, 25, 75, 312, 354
Grammar, 86, 177
of a formal language, 86
and logical grammar, 63
H
Harmony between proof-theoretic and 
semantic, 176
Harmony between the syntactical and 
semantical approaches to logic, 6
Hieroglyphic - cannot be applied for 
symbolization of connectives, 116
Horseshoe, 85, 304
Hypothetical Syllogism, 183–186, 200, 252
I
Idempotence, 199, 251, 311, 432
Idempotent Property - Set Theory, 427
Idioms - formal languages, 82
Ill-formed formula, 33
Implication, 85, 304
in relation to the concept of argument, 10
Implicative sentence, 10
Inclusive disjunction, 161, 260–262
Inconsistency, as logical pathology, see 
Consistency
Inconsistency - determined by a tree 
system, 266
Inconsistent view - cannot be true in any 
logically possible case, 35
Incorrigibility, or lack of empirical foundation 
of logic, 19
Independence proofs, 371
Indirect Proof (IP), 161, 195
Individual sentence, see Atomic sentence
Individual Variables, 85
Inductive Arguments, 3, 9, 43, 44, 60, 170
evaluation is a matter of relative strength, 
not of validity, 9
Inductive Logic, 3, 9
Infinite trees, 266
Infix notation, 87, 89, 96, 320
Intensional notions in logic, 24
Interpretation, see Valuation; 
Value-assignments
Interpreted systems, 6
Intersection - Set Theory, 167
Intransitivity - as a property of relations, 448
Index

489
Intuitionistically invalid argument forms, 245
Intuitionistically valid argument forms, 245
Intuitionistically valid inference in predicate 
logic, 387
Intuitionistic Concept of Truth, 240
Intuitionistic connectives, 244
Intuitionistic logic, 83, 195, 196, 201, 228, 
229, 233, 239–242, 244, 248, 255, 
256, 380, 387–388, 439
Intuitionistic logical consequence, 241
Intuitionistic meaning of “not,” 239
Intuitionistic negation, 242
Intuitionistic quantifiers, 387
Intuitionistic vs. classical validity, 244
Intuitionist logic, see Intuitionistic logic
Inverse of a function, 451
how to determine, 452
related to the converse of a function, 452
Inverse of a relation, 446
Involution Property - Set Theory, 427
Irreflexivity - as a property of relations, 448
Irrelevantist rules, 218
J
Joint negation, 131
Joint satisfiability, 155
Joint satisfiability of formulas, 126
K
Kant, I., 20, 53, 312, 353, 354
L
Lambda-notation, 410, 451
Language and logic, 11
Largest scope symbol, 94
Leibniz, G. F. W., 50, 198, 290, 408
Logical consequence, 1, 5, 16, 124–130, 136, 
162, 167, 168, 173, 198, 206, 209, 
213, 214, 218, 222, 227, 241, 244, 
247, 290, 359, 388, 398
defined in terms of ranges of formulas, 167
relation - as the subject of logic, 3
Logical falsehood, see Contradiction
Logical form, recipe for making instances, 28
Logical grammar, 44
of language, 11
not shown by linguistic grammar, 332
Logically equivalent formulas, 156
Logically possible state, 38
Logical meanings as truth values, 6
Logical necessity, as a characteristic of 
logic, 18
Logical possibilities as truth value 
assignments, 27
Logical possibilities - exactly two in standard 
logic, 160
Logical status - determined by natural 
deduction, 238
Logical system - in relation to the study of 
logic, 3
Logical truth, 154
See also Tautology
Logical Truths/Falsehoods, 50
definition, 50, 459
Logic-words in language and logic, 11
M
Main connective symbol, 122, 141, 164, 174, 
186, 215, 221, 225, 246, 259, 260, 
263, 296, 323
Major connective symbol, 94
Major operator, 161, 163
Mapping, 454
Material conditional, 183
Material implication, 163
See also Material conditional
Mathematical Induction, 95, 101, 112
Mathematically possible value  
assignments, 39
Maximal connective depth, 105
Meaning postulate, 37
Metalanguage, 84
Minimal logic, 228
Modus Ponens, 101, 102, 183–186, 192, 
223, 384
Modus Tollens, 183–186
Molecular components of sentential 
formulas, 173
Mutually exclusive, 162
N
n-ary, 130, 131, 289, 291, 294, 303, 315, 316, 
318, 319, 360, 361, 423, 442, 443, 
445, 477
Naturalistic view of logic, 21
Nature and logic for Aristotle, 11
Negated converse implication, 131
Negated implication, 131
Negation, 261, 268
Neither true nor false -- definite 
descriptions, 403
Index

490
Neither true nor false -- not permitted in 
standard logic, 14
Nested quantifier symbols, 362, 363, 375, 381
Neutral Element - Set Theory, 428
Non-Contradiction, 428
Non-denoting definite descriptions, 346, 
403, 404
Non-Euclidean geometries, 354
Non-metaphysical, as a characteristic of 
logic, 19
Non-reflexivity - as a property of 
relations, 448
Non-representationality, as a characteristic of 
logic, 18
Non-self-referentiality, as a characteristic of 
logic, 15
Nonsense - logical, 45, 52, 53, 78, 86, 154, 
207, 276, 348, 412
Non-standard logics, 5, 259, 392
Non-symmetry - as a property of  
relations, 448
Non-transitivity - as a property of 
relations, 448
Nontruthfunctional, 69, 272, 276, 278, 280, 
281, 285, 296, 301, 332, 337, 
347, 348
Nontruthfunctionality, 277
NOR, 131, 273
Normative Character of Logic, 4
Normativity, as a characteristic of logic, 15
Notational variants -- formal languages, 82
n-place relation, 445, 477
Null Set, see Empty set
Numerical translations, 345
O
Object Language, 84, 306
Occurrences of tokens, 119, 120
One-directional conditional, 156
One-directional implication, 156
One-many relations, 445
One-to-one, 178, 248, 307, 338, 449
Onto relations, 442
Opaque contexts, 334
Open tree, 267
Option, as value assignment, 38
Ordered pair, 421, 475
Overlap - Set Theory, 167
P
Pairwise disjoint, 431
Paralogism, 168, 184
Parentheses, 85, 304
use in formal grammar, 97
Parsing Tree for a well-formed formula, 109
Partial Truth Table, 159
Partition, 414
Path - parsing tree, 111
Path - tree, 259
Peirce Arrow, 131, 273
Peirce’s Law, 235, 242, 255
Perspicuity, as a characteristic of logic, 19
Placeholders -- variables are, 64
Pluralistic view of logic, 4
Polyadic, 302, 314, 390–396
Posited premise, 190
Possible states of affairs, 167, 173
Possible worlds, 73
Power set, 355, 419, 420, 424, 436, 438, 
443, 476
Precedence, as a characteristic of logic, 15
Prefix notation, 87, 89, 91, 96, 102, 103, 
134, 300
Premises, 57, 58, 64–66, 153, 158, 174, 177, 
261, 266, 267
Prenex formulas, 362
Preservation of truth, 5
Principal connective symbol, see Major 
connective symbol
Principia Mathematica, 397
Proof by Contradiction, 195
Proof-theoretical approach to logic, 173
Proof-theoretic and semantic approaches, 175
Proof-theoretic approach and the truth-tabular 
approach, 175
Proof-theoretic system, 179
Proposition, 42
Propositional Variables, 161
Pseudo-binary connective, 131
Pseudo-proof, 381, 386, 389
Psychology - logic is not psychology, 20
Pure Logic, 4
Q
Quasi-ordering - as property of relations, 448
Quick computational method, 160
Quine Arrow or Quine Dagger, 131
Quine brackets, 217
Quine corners, 89, 477
R
Range of a formula – is a subset of the 
Cartesian product {T, F} x 
{T, F}, 166
Index

491
Range of a function, 449
Range of a well-formed formula, 165
Recipe-trees, 110
Recursive, definition of a function, 105
Reductio ad absurdum (RAA), 160, 161, 216, 
233, 242, 432
Referentially opaque contexts, 334
Reflexivity - as property of relations, 448
Regimentation, 397, 399–402
Reichenbach, H., 20
Relational logic, 314
Relational Predicate Logic, 302, 314
Relations between formulas, determined by 
truth tables, 155
Relative product, see Composition of relations
Relettering - Quantificational Formulas, 342
Relevantist connection, 184
Relevantist constraints, 218
Relevantist Logic, 168
Relevantist restrictions, 219
Replacement rules, 198
Restriction on truth value assignments, 39
Restrictions - extra-logical, 295
Restrictions - Fitch-style proof theory, 213
Restrictions for relevance, 251
Restrictions on introductions and eliminations 
of nested quantifier symbols, 381
Restrictions - order of elimination and 
introduction of quantifier 
symbols, 375
Reverse operation, 135
Root - tree, 259
Rules - connective symbols, parsing tree, 110
Rules of reasoning, 4
Russell, B., 397–403, 436
S
Satisfaction as a semantic concept, 155
Satisfaction in predicate logic models, 359
Schemata - Parsing Tree Connective 
Symbols, 110
Scope of connective symbol, 93
Scope of modal operator, 337
Scopes of quantifier symbols, 362
Second-order logic, 305, 345, 374, 406
Semantically or formally analytic, 51
Semantic approach to logic, 6
Semantic models - predicate logic, 351
Semantics, 161
Seriality - as a property of relations, 448
Sheffer Stroke, 131, 133, 273
Short truth table method, 160
Simple ordering - as property of relations, 449
Simplification rule, 179
Soundness, 177
Soundness of the Fitch-type natural deduction 
system, 210
Status, logical, 76
Strict partial ordering - as property of 
relations, 449
Strong connectedness - as a property of 
relations, 448
Structural rules - sequent system, 250
Structural rules - tree system, 391
Sub-Contrariety, 158, 477
Subderivation, 211–213, 222, 224
Subformulas, 324
of a given well-formed formula, 112
Subproof, 129, 190, 191, 208, 209, 211–215, 
221–225, 230, 231, 233, 236, 237, 
242, 379
Subset, 295
Subsethood, 416
Symbolization in predicate logic, see 
Translations from English into the 
Formal Language of 
Predicate Logic
Symmetry - as a property of relations, 448
Syntactical approach to logic, 6
Syntactically analytic, 51
T
Tarski, A., 242, 356, 364
Tarski’s Law (TL), 242
Tautology, 25, 26, 53, 55, 78, 79, 125–127, 
129, 130, 143, 147, 148, 150, 
152–154, 156–158, 160, 164, 
167–169, 172–174, 184, 187, 194, 
197, 198, 200, 206, 210, 211, 224, 
225, 229, 231, 238, 249, 257, 258, 
261, 264, 266–268, 336, 337, 384, 
391, 394, 413
determined by truth tables, 154
Temporal element in Intuitionistic Notion of 
Truth and Proof, 240
Temporary assignment variants - semantics of 
predicate logic, 365
Terminal nodes - tree, 110, 111, 266
Terminated tree, see Completed tree
Ternary, 70, 117, 130, 134, 303, 323, 445, 450
Tertium non datur, 234
Thesis - natural deduction system, 211
Tilde, 85, 304
Topic-neutrality, as a characteristic of logic, 15
Tractatus Logicus Philosophicus, 
Wittgenstein, 17
Index

492
Transitivity - as a property of relations, 448
Translations from English into the Formal 
Language of Predicate Logic, 12, 
108, 113, 197, 272, 274, 275, 279, 
282, 286, 291, 301, 331–333, 336, 
338, 339, 341, 342, 345, 348, 
363, 402
Translations of numerical statements, 345
Tree method, 266, 267
Triadic, 117, 134, 303
Triple Bar, 85, 304
Triviality, as a characteristic of logic, 17
Trivial Truth, 354
Trivial truth, determined by the truth 
table, 154
Truth conditions, 70, 116
defined, 38
Truth Conditions for Semantic Models with all 
named objects, 359
Truth Conditions for Semantic Model with 
unnamed objects, 366
Truth function, 161, 163
Truth preservation - is what is assessed in 
argument validity, 43
Truth-Preservativeness, as a characteristic of 
logic, 16
Truth Table for Checking Intuitionistic 
Validity, 241
Truth tables, 153, 154
Truth value and meaning, 13
Truth value assignments, 162
Turnstile, 125, 166, 167, 198, 200, 209, 
222, 359
Type of a symbolic system, 83
Types of atomic variables, 119
U
Unary, 30, 70, 85, 87, 89, 91, 102, 103, 117, 
124, 130–132, 141, 276, 291, 294, 
302, 314, 318, 319, 334, 424, 425, 
440, 449, 454
Unbound variable, 302, 308
Universality, as a characteristic of logic, 14
Universal set, 409, 410, 413, 416, 417, 
419, 424–433
Universe of discourse, see Domain - predicate 
logic models
Use and mention, 106
V
Vacuity, as a characteristic of logic, 17
Vacuous quantification, 382
Vacuous truth, 367
Vagueness and Logic, 19
Valid argument - defined, 46
Validity, 64, 65, 72, 153, 154, 158, 162, 261, 
266, 267
Valuation, 38, 129, 130, 150, 152, 174,  
259, 266, 268, 294, 298, 299, 351, 
352, 354, 356, 358, 359, 361, 
438, 444
Value-assignments, see Valuation
Variables, 63, 64, 66, 86, 181, 259, 266, 306
Variants - assignments in the Semantics of 
Predicate Logic, 365
Variations or idioms of a formal language, 82
W
Weak connectedness - as a property of 
relations, 448
Weak ordering - as property of relations, 449
Wedge, 85, 304
Well-formed formula, 101
specific to a formal language, 33
Well-formedness, 101, 105, 303, 306, 318, 
323, 373
Wff, 86
Whitehead, A. N., 397
Wittgenstein, L., 17, 148
Z
Zermelo-Fraenkel Systematization of Set 
Theory, 435
Zermelo-Fraenkel Theory of Sets, 405
Index

