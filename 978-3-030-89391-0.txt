Pietro Baroni
Christoph Benzmüller
Yì N. Wáng (Eds.)
 123
LNAI 13040
4th International Conference, CLAR 2021
Hangzhou, China, October 20–22, 2021
Proceedings
Logic and
Argumentation

Lecture Notes in Artiﬁcial Intelligence
13040
Subseries of Lecture Notes in Computer Science
Series Editors
Randy Goebel
University of Alberta, Edmonton, Canada
Yuzuru Tanaka
Hokkaido University, Sapporo, Japan
Wolfgang Wahlster
DFKI and Saarland University, Saarbrücken, Germany
Founding Editor
Jörg Siekmann
DFKI and Saarland University, Saarbrücken, Germany

More information about this subseries at http://www.springer.com/series/1244

Pietro Baroni
• Christoph Benzmüller
•
Yì N. Wáng (Eds.)
Logic and
Argumentation
4th International Conference, CLAR 2021
Hangzhou, China, October 20–22, 2021
Proceedings
123

Editors
Pietro Baroni
Department of Information Engineering
University of Brescia
Brescia, Italy
Christoph Benzmüller
Department of Mathematics
and Computer Science
Freie Universität Berlin
Berlin, Germany
Yì N. Wáng
Department of Philosophy (Zhuhai)
Sun Yat-sen University
Zhuhai, China
ISSN 0302-9743
ISSN 1611-3349
(electronic)
Lecture Notes in Artiﬁcial Intelligence
ISBN 978-3-030-89390-3
ISBN 978-3-030-89391-0
(eBook)
https://doi.org/10.1007/978-3-030-89391-0
LNCS Sublibrary: SL7 – Artiﬁcial Intelligence
© Springer Nature Switzerland AG 2021
This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part of the
material is concerned, speciﬁcally the rights of translation, reprinting, reuse of illustrations, recitation,
broadcasting, reproduction on microﬁlms or in any other physical way, and transmission or information
storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar methodology now
known or hereafter developed.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this publication
does not imply, even in the absence of a speciﬁc statement, that such names are exempt from the relevant
protective laws and regulations and therefore free for general use.
The publisher, the authors and the editors are safe to assume that the advice and information in this book are
believed to be true and accurate at the date of publication. Neither the publisher nor the authors or the editors
give a warranty, expressed or implied, with respect to the material contained herein or for any errors or
omissions that may have been made. The publisher remains neutral with regard to jurisdictional claims in
published maps and institutional afﬁliations.
This Springer imprint is published by the registered company Springer Nature Switzerland AG
The registered company address is: Gewerbestrasse 11, 6330 Cham, Switzerland

Preface
This volume collects the papers accepted for presentation at the 4th International
Conference on Logic and Argumentation (CLAR 2021).
The CLAR series started as a regional workshop hosted by Zhejiang University in
2016 and evolved through the years to become a successful international event
attracting high quality contributions worldwide. It aims at bringing together researchers
from various disciplines such as logic, formal argumentation, artiﬁcial intelligence,
philosophy, computer science, linguistics, and law.
The success of the initiative is witnessed by the substantial increase of submissions
over time: there were 11 at CLAR 2016, 16 at CLAR 2018, and 31 at CLAR 2020,
while CLAR 2021 received 58 submissions.
After a careful reviewing process, 20 submissions were accepted as regular papers
and 10 as short papers. The Program Committee of CLAR 2021 consisted of 65 top
researchers from 19 countries. Submissions were – except for some special cases –
reviewed by three Program Committee members, and attention and discussion were
devoted to controversial judgments and peculiar situations.
The topics of accepted papers nicely cover the focus of the CLAR series, including
formal models of argumentation, a variety of logic formalisms, nonmonotonic rea-
soning, dispute and dialogue systems, formal treatment of preference and support, and
applications in areas like vaccine information and processing of legal texts.
We are indebted to the following invited speakers for accepting our invitation and
for witnessing, with their talks and contributed papers, the rich diversity and vitality
of the research areas covered by the conference:
– Annette Frank (Heidelberg University, Germany): On the Need of Knowledge for
Computational Argument Analysis and Generation
– Giovanni Sartor (University of Bologna and European University Institute of
Florence, Italy): Burdens of Persuasion and Standards of Proof in Structured
Argumentation
– Ken Satoh (National Institute of Informatics, Japan): Implementation of Choice of
Jurisdiction and Law in Private International Law by PROLEG Meta-interpreter
– Guillermo R Simari (Universidad Nacional del Sur and Institute for Computer
Science and Engineering, Argentina): Focusing the Argumentative Process:
Neighborhood-based Semantics in Abstract Argumentation
– Minghui Xiong (Zhejiang University and Sun Yat-sen University, China):
Resolving the Cohenian Paradox in Judicial Probability Theory
The success of a conference depends on the contributions of many people.
First of all we thank all the authors for contributing to the conference with their hard
work and commitment.

We are also very grateful to the members of the Program Committee and the
additional reviewers for their invaluable efforts in providing high-quality reviews,
which are crucial for the quality and success of the event.
In addition, we thank Springer for their generous support in publishing this con-
ference proceedings and their sponsorship of a best paper award, and EasyChair for
their invaluable technical infrastructure that helped us organize the review and publi-
cation process.
Last but not least, we are very grateful to Zhejiang University and Zhejiang
University City College for their ﬁnancial support and local organization efforts. In
particular, we thank the main organizing team consisting of Beishui Liao, Quansheng
Yu, Huimin Dong, Shengyu Dai, Zhihong Geng, Teng Ying, and Chonghui Li for their
excellent support.
September 2021
Pietro Baroni
Christoph Benzmüller
Yì Nicholas Wáng
vi
Preface

Organization
Program Committee Chairs
Pietro Baroni
University of Brescia, Italy
Christoph Benzmüller
Freie Universität Berlin, Germany
Yì Nicholas Wáng
Sun Yat-sen University, China
Program Committee
Thomas Agotnes
University of Bergen, Norway, and Southwest
University, China
Natasha Alechina
Utrecht University, The Netherlands
Ofer Arieli
Academic College of Tel-Aviv, Israel
Pietro Baroni
University of Brescia, Italy
Christoph Benzmüller
Freie Universität Berlin, Germany
Antonis Bikakis
University College London, UK
Stefano Bistarelli
University of Perugia, Italy
Thomas Bolander
Technical University of Denmark, Denmark
Martin Caminada
Cardiff University, UK
Ilaria Canavotto
University of Amsterdam, The Netherlands
Walter Carnielli
University of Campinas, Brazil
Federico Cerutti
University of Brescia, Italy
Andrea Cohen
Universidad Nacional del Sur, Argentina
Marcos Cramer
Technische Universität Dresden, Germany
Mehdi Dastani
Utrecht University, The Netherlands
Jérémie Dauphin
University of Luxembourg, Luxembourg
Valeria de Paiva
Topos Institute, USA, and University of Birmingham,
UK
Jérôme Delobelle
Université de Paris, France
Dragan Doder
Utrecht University, The Netherlands
Huimin Dong
Sun Yat-sen University, China
Bettina Fazzinga
ICAR-CNR, University of Calabria, Italy
Raul Fervari
Universidad Nacional de Córdoba, Argentina
Rustam Galimullin
University of Bergen, Norway
Sujata Ghosh
Indian Statistical Institute, India
Massimiliano Giacomin
University of Brescia, Italy
Sebastian Gottifredi
Universidad Nacional del Sur, Argentina
Guido Governatori
CSIRO, Australia
Andreas Herzig
University of Toulouse, France
Jesse Heyninck
Technische Universität Dortmund, Germany
Fengkui Ju
Beijing Normal University, China

Marie-Christine
Lagasquie-Schiex
Paul Sabatier University, France
Hannes Leitgeb
Ludwig-Maximilians-Universität München, Germany
Bjoern Lellmann
Vienna University of Technology, Austria
Beishui Liao
Zhejiang University, China
Jieting Luo
Zhejiang University, China
Jean-Guy Mailly
Université de Paris, France
Réka Markovich
University of Luxembourg, Luxembourg
Maria Vanina Martinez
Universidad de Buenos Aires, Argentina
Sara Negri
University of Genoa, Italy
Juan Carlos Nieves
Umeå University, Sweden
Hitoshi Omori
Ruhr-Universität Bochum, Germany
Nir Oren
University of Aberdeen, UK
Xavier Parent
Vienna University of Technology, Austria
Gabriella Pigozzi
Université Paris-Dauphine, France
Nico Potyka
University of Stuttgart, Germany
Revantha Ramanayake
University of Groningen, The Netherlands
R. Ramanujam
Chennai University, India
Tjitze Rienstra
Maastricht University, The Netherlands
Olivier Roy
Universität Bayreuth, Germany
Katsuhiko Sano
Hokkaido University, Japan
Sonja Smets
University of Amsterdam, The Netherlands
Alexander Steen
University of Luxembourg, Luxembourg
Christian Strasser
Ruhr-Universität Bochum, Germany
Geoff Sutcliffe
University of Miami, USA
Carlo Taticchi
Università degli Studi di Perugia, Italy
Matthias Thimm
Universität Koblenz-Landau, Germany
Markus Ulbricht
University of Leipzig, Germany
Mauro Vallati
University of Huddersﬁeld, UK
Leon van der Torre
University of Luxembourg, Luxembourg
Fernando R.
Velázquez-Quesada
University of Bergen, Norway
Xuefeng Wen
Sun Yat-sen University, China
Emil Weydert
University of Luxembourg, Luxembourg
Stefan Woltran
Vienna University of Technology, Austria
Yì Nicholas Wáng
Sun Yat-sen University, China
Wei Xiong
Sun Yat-sen University, China
Tomoyuki Yamada
Hokkaido University, Japan
Fan Yang
University of Helsinki, Finland
Bruno Yun
University of Aberdeen, UK
viii
Organization

Additional Reviewers
Alfano, Gianvincenzo
Alviano, Mario
Antonelli, Melissa
Botnan, Magnus Bakke
Budan, Paola
Cassano, Valentin
Chikobava, Margarita
Fuenmayor, David
Karmakar, Samr
König, Matthias
Maffezioli, Paolo
Morveli Espinoza, Mariela
Pavlovic, Edi
Rapberger, Anna
Santini, Francesco
Skiba, Kenneth
Trucco, Francisco
Organization
ix

On the Need of Knowledge for Computational
Argument Analysis and Generation
(Abstract of Invited Talk)
Anette Frank
Department of Computational Linguistics, Heidelberg University, Germany
frank@cl.uni-heidelberg.de
Argumentation is deeply grounded in human society and communication. While formal
argumentation has been studied for decades in philosophy and logic, only recently,
computational argumentation has been established as a research ﬁeld in the Natural
Language Processing (NLP) community. Argumentation is a natural object of study for
NLP, since arguments are framed in natural language – be it in discourse or dialogue.
At the same time, analysing or even generating arguments computationally is a chal-
lenging goal. Humans frame arguments to deliberate issues that require careful
reﬂection and deep analysis from various views and angles. The debated issues typi-
cally involve conﬂicting interests that need to be weighted in terms of their impacts and
consequences.
In my talk I will highlight recent work on knowledge-driven computational
argument analysis conducted in the ExpLAIN project. We perform argument analysis
by integrating symbolic background knowledge with neural language processing
models and show how leveraging such knowledge enhances performance and inter-
pretability of results. We started from an empirical analysis of implicit knowledge in
argumentative texts, and developed methods to integrate such knowledge in argument
analysis tasks. Our work is the ﬁrst to show how to combine structured and latent
knowledge from pre-trained language models to perform reconstruction of implicit
knowledge for argument analysis.
I will conclude by discussing avenues for moving from analysis to generative
argumentation tasks, and the importance of knowledge for achieving these aims.

Contents
Invited Papers
Resolving the Cohenian Paradox in Judicial Probability Theory . . . . . . . . . .
3
Wenjing Du, Zihan Niu, and Minghui Xiong
Focusing the Argumentative Process: Neighborhood-Based Semantics
in Abstract Argumentation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
20
Melisa G. Escañuela Gonzalez, Maximiliano C. D. Budán,
Diego I. Martínez, Maria Laura Cobo, and Guillermo R. Simari
Burdens of Persuasion and Standards of Proof in
Structured Argumentation. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
40
Roberta Calegari and Giovanni Sartor
Implementation of Choice of Jurisdiction and Law in Private International
Law by PROLEG Meta-interpreter . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
60
Ken Satoh, Laura Giordano, and Matteo Baldoni
Full Papers
Collective Argumentation with Topological Restrictions. . . . . . . . . . . . . . . .
79
Weiwei Chen
The Choice-Preferred Semantics for Relevance-Oriented Acceptance
of Admissible Sets of Arguments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
94
Marcos Cramer and Yannick Spörl
New Weak Admissibility Semantics for Abstract Argumentation. . . . . . . . . .
112
Jérémie Dauphin, Tjitze Rienstra, and Leendert van der Torre
On Restricting the Impact of Self-attacking Arguments
in Gradual Semantics. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
127
Vivien Beuselinck, Jérôme Delobelle, and Srdjan Vesic
Flexible Dispute Derivations with Forward and Backward Arguments
for Assumption-Based Argumentation . . . . . . . . . . . . . . . . . . . . . . . . . . . .
147
Martin Diller, Sarah Alice Gaggl, and Piotr Gorczyca
Towards a General Theory of Decomposability in Abstract Argumentation. . .
169
Massimiliano Giacomin, Pietro Baroni, and Federico Cerutti

Abstract Argumentation with Qualitative Uncertainty: An Analysis in
Dynamic Logic. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
190
Andreas Herzig and Antonio Yuste-Ginel
Explanations of Non-monotonic Inference in Admissibility-Based Abstract
Argumentation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
209
Timotheus Kampik and Kristijonas Čyras
The Burden of Persuasion in Abstract Argumentation . . . . . . . . . . . . . . . . .
224
Timotheus Kampik, Dov Gabbay, and Giovanni Sartor
Handling Support Cycles and Collective Interactions in the Logical
Encoding of Higher-Order Bipolar Argumentation Frameworks. . . . . . . . . . .
244
Marie-Christine Lagasquie-Schiex
Tableau-Based Decision Procedure for Logic of Knowing-How
via Simple Plans . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
266
Yanjun Li
Integrating Individual Preferences into Collective Argumentation . . . . . . . . .
284
Chonghui Li and Beishui Liao
A Logic for Binary Classifiers and Their Explanation . . . . . . . . . . . . . . . . .
302
Xinghan Liu and Emiliano Lorini
Extension-Based Semantics for Incomplete Argumentation Frameworks . . . . .
322
Jean-Guy Mailly
Relevant Epistemic Logic with Public Announcements and Common
Knowledge. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
342
Vít Punčochář and Igor Sedlár
A Variant with the Variable-Sharing Property of Brady’s 4-Valued
Implicative Expansion BN4 of Anderson and Belnap’s Logic FDE . . . . . . . .
362
Gemma Robles
Intrinsic Argument Strength in Structured Argumentation:
A Principled Approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
377
Jeroen Paul Spaans
How Can You Resolve a Trilemma? - A Topological Approach - . . . . . . . . .
397
Kazuko Takahashi and Tamon Okubo
A Multi Attack Argumentation Framework. . . . . . . . . . . . . . . . . . . . . . . . .
417
Alexandros Vassiliades, Giorgos Flouris, Theodore Patkos,
Antonis Bikakis, Nick Bassiliades, and Dimitris Plexousakis
xiv
Contents

Towards a Sound and Complete Dialogue System
for Handling Enthymemes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
437
Andreas Xydis, Christopher Hampson, Sanjay Modgil,
and Elizabeth Black
Short Papers and Extended Abstracts
A Henkin-Style Completeness Proof for the Modal Logic S5 . . . . . . . . . . . .
459
Bruno Bentzen
Base Argumentation as an Abstraction of Deductive Argumentation . . . . . . .
468
Jinsheng Chen, Beishui Liao, and Leendert van der Torre
An Argumentative Dialogue System for COVID-19 Vaccine Information. . . .
477
Bettina Fazzinga, Andrea Galassi, and Paolo Torroni
Extractive-Abstractive Summarization of Judgment Documents Using
Multiple Attention Networks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
486
Yan Gao, Zhengtao Liu, Juan Li, Fan Guo, and Fei Xiao
A Framework for Intuitionistic Grammar Logics . . . . . . . . . . . . . . . . . . . . .
495
Tim S. Lyon
Choosing a Logic to Represent the Semantics of Natural Language. . . . . . . .
504
Adam Pease
The Placeholder View of Assumptions and the Curry–Howard
Correspondence (Extended Abstract) . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
513
Ivo Pezlar
Paranegations and the Square of Oppositions . . . . . . . . . . . . . . . . . . . . . . .
521
Mariusz Urbański and Zofia Żmójdzin
Validity Under Assumptions and Modus Ponens . . . . . . . . . . . . . . . . . . . . .
533
Xuefeng Wen
Entailments with Sentential Predicates . . . . . . . . . . . . . . . . . . . . . . . . . . . .
543
Richard Zuber
Author Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
551
Contents
xv

Invited Papers

Resolving the Cohenian Paradox
in Judicial Probability Theory
Wenjing Du1, Zihan Niu2, and Minghui Xiong3(B)
1 Wenbo College, East China University of Political Science and Law,
Shanghai, China
2178@ecupl.edu.cn
2 Institute of Logic and Cognition, Sun Yat-sen University, Guangzhou, China
niuzh@mail.sysu.edu.cn
3 Guanghua Law School, Zhejiang University, Hangzhou, China
xiongminghui@zju.edu.cn
Abstract. The Cohenian paradox is one of the main themes of judicial
probability theory and one of the core topics discussed by the new evi-
dence scholarship. To resolve this paradox, evidence scholars nowadays
have proposed various solutions, including legal probabilism, Bayesian
decision theory, and relative plausibility theory. These three solutions
can be classiﬁed into two approaches, i.e., the probabilism and the
explanationism. Among them, the former includes legal probabilism and
Bayesian decision theory, and the latter includes the relative plausibility
theory. However, the two approaches have recently begun to converge and
become more understandable to each other. For example, Welch (2020)
has recently defended and improved the relative plausibility theory by
substantially improving it with the help of Bayesian decision theory. In
this paper, by contrast, we attempt to defend the probabilistic approach
- legal probabilism and Bayesian decision theory on the basis of relative
plausibility theory.
Keywords: Cohenian paradox · Judicial probability theory · New
evidence scholarship · Legal probabilism
1
Introduction
In 1968, John Kaplan [14] published a seminal paper Decision Theory and the
Fact-ﬁnding Process, in which he discussed how some of the basic tools of deci-
sion theory could be applied to the fact-ﬁnding process in trials. It opens a
precedent for the study of theories about judicial probability. Since then there
has been rich literature that explains virtually all aspects of judicial proof, such
as relevance and probative value of evidence at the micro level, as well as the
standard of proof and the process of evidential reasoning or fact-ﬁnding, as
probabilistic, from the basic nature of relevancy through the processing of infor-
mation to the ﬁnal decision about the facts [3] And then, Jonathan Cohen [4, p.
51] systematically discusses the theories about judicial probability. However, he
c
⃝Springer Nature Switzerland AG 2021
P. Baroni et al. (Eds.): CLAR 2021, LNAI 13040, pp. 3–19, 2021.
https://doi.org/10.1007/978-3-030-89391-0_1

4
W. Du et al.
criticizes the application of probabilistic methods in judicial proofs and raises
the three critical questions: (a) But what is the nature of this juridical concept
of probability, so often and so conﬁdently employed? (b) Is it a mathematical
probability? (c) Does it conform to the mathematical calculus of probabilities
that Pascal originated? In part II of his monograph, he lists six diﬃculties for
a Pascalian account of judicial probability, i.e., the diﬃculty about conjunction,
inference upon inference, negation, proof beyond reasonable doubt, a criterion,
and corroboration and convergence. For the sake of discussion, these diﬃculties
are collectively referred to as the proof paradox [18] or the Cohenian paradox(es),
which is one of the core issues in the contemporary new evidence scholarship.
In view of the Cohenian paradox, evidence scholars have proposed diﬀerent
solutions such as legal probabilism, Bayesian decision theory and relative plausi-
bility theory [23]. Legal probabilism, whose origin can be traced back to the early
days of probability theory, for example, Niklaus Bernoulli’s dissertation De Usu
Artis Conjectandi in Iure in 1709, is a research program that relies on probability
theory to analyze, model and improve the evaluation of evidence and the pro-
cess of decision-making in trial proceedings [22]. Allen and Pardo [3] and Pardo
[16] have extended the Cohenian paradox, demonstrating the incompatibility of
Bayesian reasoning with trials, and have proposed an analytical alternative - the
relative plausibility theory - to improve the probabilistic paradigm. They argue
that judicial proof is explanatory and have proposed relative plausibility theory
based on the inference to the best explanation. During this controversy, many
scholars have criticized probabilistic methods too radically, leading to the illusion
that the probabilistic model of judicial proof is either inadequate or has little
eﬀect. As an analysis tool, probabilistic methods play a crucial role in the analy-
sis of cases and the process of fact-ﬁnding. Probabilistic methods are consistent
and normative and can avoid paradoxical conclusions and unfair verdicts.
In this paper we will respond to the Cohenian paradox and its related vari-
ants such as Blue Bus and Prisoner [18]. And then we will provide a possible
resolution. Although the Cohenian paradox contains many diﬃculties, it is not
intended or able to discuss all of them in this paper, and we will conﬁne our
discussion to the following three, i.e., the diﬃculty or problem of probability
selection, calculation or computation, and conjunction. And these diﬃculties or
problems are sometimes called paradoxes of proof [16,18].
2
The Selection Problem: Subjective vs Objective
Probability
The selection problem, also known as the probability selection problem or the
diﬃculty of selection, refers to the situation in which it is diﬃcult to choose
between subjective probability and objective probability when probability the-
ory is used for judicial proof. Judicial proof is a clear and evident declaration
or demonstration of a matter which was doubtful before, conveyed in a judicial
manner by sound arguments and other legal methods. The conviction or persua-
sion of the idea of a judge or jury, by way of the presentation of evidence, of the

Resolving the Cohenian Paradox in Judicial Probability Theory
5
fact of a truth alleged: as, to prove, is to decide or persuade that a thing does
or does not exist. Proof is the perfection of evidence, for without evidence there
is no proof; although, there may be proof which does now not amount to proof:
for example, a man is found murdered at a spot where some other had been seen
on foot but a short time before, this truth would be evidence to show that the
latter was the murderer, but, standing alone, would be very far from proof of it.
As the core of judicial proof, the standard of proof, in essence, can be loosely
deﬁned as the quantum of evidence that must be presented in a Court before a
fact can be said to exist or not exist. As the type of cases before a Court can
be classiﬁed into criminal or civil, so can the standard of proof. There is a clear
understanding that the Courts follow according to which the standard of proof
to be followed in a criminal case is that of “beyond reasonable doubt” whereas
the standard of proof changes, even lowers to the “balance of probabilities”
in cases of civil proceedings. Inferences may be deductive or inductive, but the
inference in judicial proof process primarily involves inductive, in the board, non-
demonstrative sense [17]. The standard of proof, even the criminal standard,
are recognized as inherently “probabilistic”, so he used probability theory to
understand the role played the ordinary civil and criminal standards of proof the
law’s pursuit of factual accuracy [11]. A simple way of understanding standards
of proof is in terms of degrees of probability [18], but Jonathon Cohen [4] and
new evidence scholars with relative plausibility theory, such as Ronald Allen and
Michael Pardo [17], have strongly opposed this approach. Generally speaking,
there are two main standards for proof of fact in courts: the plaintiﬀin a civil
case must prove on the balance of probability, including the preponderance of the
evidence, and clear convincing evidence, and the prosecutor in a criminal case
must prove his conclusion at a level of probability that puts it beyond reasonable
doubt. In particular, to prevail in a civil case a claimant needs only prove his
liability to a degree above 0.5. For the prosecution to succeed in a criminal case,
it needs to prove guilt to a considerably higher degree of 0.95. In addition, there
is a three-standard saying, i.e., preponderance = 0.5; clear and convincing = 0.6;
beyond a reasonable doubt = 0.9.
Probability is a branch of mathematics regarding numerical descriptions of
how probably an event is to occur, or how probable it is that a proposition is
true. When it comes to practical application, there are two primary competing
views of probability explanations. The one is that objectivists assign numbers
to describe some objective or physical state of aﬀairs. The most popular version
of objective probability is frequentist probability. The other is that subjectivists
assign numbers per subjective probability, that is, as a degree of belief. The most
famous version of subjective probability is Bayesian probability. In the theory
of judicial probability, two kinds of probability explanation exist simultaneously.
However, Allen and Pardo [1] oppose the application of probabilistic approach
to judicial proof and criticize both objective and subjective probability at the
same time. According to them, the objective probability needs to be calculated
by relative frequency or known statistical distribution data, and these data are
diﬃcult to obtain in reality. Even if the data is obtained, it may face the diﬃ-

6
W. Du et al.
culty of selecting the “reference class”. In addition, the problems in court trials
tend to focus on what happened at a particular moment, and the ﬁnal problem
rarely appears in the relative frequency of a particular type of event. The only
class that can accurately capture the “objective” value is the event itself, whose
probability is either 1 or 0 [2]. Regarding subjective probabilities, they criticize
that those prior probabilities and the likelihood values used to update the prior
probabilities can be any number and are not aﬀected by the quality or probative
value of the evidence used to prove facts in the trial. Subjective probability is
too subjective. It provides a way to maintain a consistent belief structure, but
it is not necessarily related to the accuracy of the advancing results [3].
We don’t share Allen and Pardo’s views on this. If they were right, the whole
theory of probability would be useless. Apparently, this is not true. The indis-
putable fact is that the probabilistic approach, which has been useful in almost
all areas of scientiﬁc research, is normative, mathematical, and systematic. For
example, statistical testing, conﬁdence intervals, regression, and so on are widely
used in social sciences. In addition, it permeates many aspects of philosophy. In
epistemology, philosophy of mind, and cognitive science, we see that subjective
probability functions can model the state of a particular point of view and learn-
ing can be modeled by updating these functions. Probability theory is the core
of decision theory and game theory. It also has an impact on ethics and political
philosophy. It occupies an important position in major metaphysical works such
as causality and natural laws. Probability appears many times in the conﬁrma-
tion analysis, scientiﬁc explanation, and philosophy of speciﬁc scientiﬁc theories,
such as quantum mechanics, statistical mechanics, and genetics, and can even
occupy a central position in logic, philosophy of language, and philosophy of
religion [10]. Therefore, we believe that the application of probabilistic methods
in the judicial proof process is also natural and reasonable.
In judicial proof, the probability is normally deﬁned as the degree of personal
belief in a certain proposition, which is a probabilistic explanation provided by
Bayesian theory that is both subjective and rational. Diﬀerent analysts can hold
diﬀerent initial beliefs about a certain fact. When a Bayesian formula is used,
these can be changed rationally based on new evidence. The subjective assign-
ment leads to the cognitive consensus of the belief held by the analyst. Bayesian
theory is a kind of cognitive proof theory, which claims that the condition for
asserting a proposition being proved is if and only if the probability of trusting
the proposition is high to a reasonable degree. As new evidence is continuously
obtained, the cognitive proof will change. This probability will also occur in the
corresponding change, which can be calculated and predicted according to the
Bayesian formula. The Bayesian theory also provides a robust and uniﬁed frame-
work for mixing objective statistical data and subjective factual evaluation. Even
if the probability evaluation of a speciﬁc case has a frequency data basis, it also
contains a subjective component based on personal knowledge. The “objective”
probability judgment is the judgment on whether the consistency of intersubjec-
tivity is achieved. For example, probabilistic evaluation based on knowledge of
relevant statistical data is more “objective” than probabilistic evaluation with-

Resolving the Cohenian Paradox in Judicial Probability Theory
7
out the support of relevant statistical data because rational people will think
that if relevant statistical data is known, then personal beliefs should take the
data knowledge into account. Statistical syllogism is the basis of probabilistic
reasoning and has strong objectivity, but it also contains subjective factors. Its
reasoning structure is as follows [21, pp. 21–22]:
1. The relative frequency of the property Q in the population R is γ;
2. ai is an individual in the population R (i = 1, 2, ..., n);
3. ai has, for me, the same probability of possessing property Q as any other
individual in the population R;
4. The probability, for me, that ai has the property Q is γ.
The ﬁrst two conditions examine statistical data information, which is objec-
tive, while the third condition expresses the state of the responder’s knowledge
and is subjective. The third condition can also be changed to a more subjec-
tive description. For the reasoner, ai is the same as any other individual in the
population R, and the possibility of having the property Q is the same.
It can be seen that Bayesian theory provides a uniﬁed framework for objec-
tive probability and subjective probability, which has both objective statistical
data basis and subjective rationality. Or Allen [1] said, there are two versions
of Bayesianism, an objective and subjective version. Allen and Pardo’s critique
seems to interpret the probability in the judicial proof as to either objective
or subjective [3]. The probability can only choose one of them and cannot be
integrated. This understanding is inappropriate. In a speciﬁc case, probability
can be a fusion of objective frequency and subjective belief degree. The prior
probability of some evidence or facts is reasonable for assignment with objective
probability, while others are reasonable for evaluation with subjective probabil-
ity. Here we are very glad to share the latest solution of Hunt & Mostyn [13].
They have given a solution to where the probability values come from. If the rel-
evant data can be found and the appropriate reference class can be determined,
the frequency should be calculated and assigned with objective probability. If no
reasonable data can be found, there are three methods: The ﬁrst is to adjust the
content to be proved, appropriately enlarge or reduce the reference class, and
then use objective probability assignment. The second is to make fuzzy objective
probability assignments in terms of probability range and size comparison. The
third is to assign values with subjective probability.
The diﬃculty of obtaining data is indeed a problem faced by the probabilistic
approach. However, with the development of society, advances in science and
technology, and the improvement of databases, this diﬃculty will be alleviated to
some extent. It should be noted that the digital problem exists in the judicial ﬁeld
and exists in other social sciences. In other words, this is a common phenomenon
of social science problems, but not a problem of probabilistic methods. The
probability of an event itself is either 1 or 0, which refers to the “binary” legal
principle; that is, if the judge initially believes that the probability of an event
is greater than 0.5, then the probability of the event being valid will becomes
1, and if the judge initially believes that the probability of an event is less than

8
W. Du et al.
0.5, the probability of the event being true will become 0 [2,3]. Actually, this
probabilistic method does not conﬂict with the binary legal principle. The binary
principle is reasonable to be applied to the ﬁnal probability of the event under
consideration. In the calculation stage of probabilistic reasoning, the probability
value can be continuous and should not be a binary value. Otherwise, it violates
the relevant probability principle and lead to an absurdity or injustice factual
verdict.
Allen and Pardo [3] criticize subjective probability as being too subjective
and biased. However, judicial proof is a social science issue which is subjective.
In judicial proofs, the objective facts of a case always occur before the facts
are justiﬁed. The objective facts of many cases are diﬃcult to restore to their
original appearance due to the irreversibility of time. Therefore, the facts found
by the fact-ﬁnder are legal, not necessarily objective. In a sense, a legal trial is
not concerned for the “real truth of the matte”, but for the making out of a
legally proper case [19, p. 43]. Most of legal facts themselves are subjective. The
relative plausibility theory developed by Allen and Pardo [3] as an alternative
to probabilistic methods also completely relies on the subjective evaluation of
the fact-ﬁnder. In addition, the subjective probability is not arbitrarily assigned.
It needs to be constrained by evidence, legal principles, and related probability
principles, such as the principle of probability multiplication, complementarity
axioms, and Bayesian formulas. Untested and unconstrained subjective proba-
bility assignment does not have any signiﬁcance. In fact, whether the fact-ﬁnder
evaluates the subjective probability or changes or revises the subjective proba-
bility, it should be constrained by evidence and related principles. For example,
suppose the fact-ﬁnder is evaluating the prior probability of the cause of death of
a certain deceased, and combining the case and background knowledge, proposes
three causes of death: suicide (H1), homicide (H2), and accidental death (H3).
According to the principle of probability, the probabilities of these three cases
should be taken as numbers between 0 and 1, and the sum of these probabilities
must be equal to 1. When new evidence is obtained, the probability should be
updated according to the Bayesian formula to calculate the posterior probability.
According to the rule of evidence exclusion, if a certain piece of evidence needs
to be excluded, even if the fact-ﬁnder knows the existence of the evidence, his
probability evaluation should not be changed at will.
3
The Calculation Problem: A Franklinian Solution
The calculation problem, also known as the calculation diﬃculty, which should be
called the diﬃculty of computation in the sense of computer science or artiﬁcial
intelligence, is directly related to the selection of reference classes, so it can also
be called the diﬃculty of reference class selection or the reference class problem,
which refers to deciding what data class to be used as the reference basis when
calculating the probability of a single event. Allen and Pardo [2,3] as well as
Colyvan, Reganm, and Ferson [5], have suggested the reference-class problem
plays a role in the Cohenian paradox. When evaluating the probability of a

Resolving the Cohenian Paradox in Judicial Probability Theory
9
single event, we usually ﬁrst assign the event to a reference class based on a
certain feature (attribute) and then calculate the frequency of this feature in
the reference class. This frequency is considered as the probability of the event
occurring. However, each event usually has many features, so it can belong to
many reference classes or even an inﬁnite number of reference classes. In diﬀerent
reference classes, the frequency of occurrence of a single feature is likely to be
diﬀerent, thus the probability of occurrence of the event is also diﬀerent. The
uncertainty and ambiguity of this probability lead to the so-called reference class
problem, that is, how to choose the appropriate reference class to evaluate the
probability of an event?
Probabilistic reasoning has the diﬃculty of reference class selection and
severely criticized [2,3]. They use it as a basis to oppose the use of probabilistic
methods in judicial proofs. In their paper The Problematic Value of the Mathe-
matical Model of Evidence, they cite six cases to show that there are reference
class problems in evaluating the probative value of evidence using probabilistic
methods, and then come up with the relative plausibility theory, an explanation-
ist approach, as a solution to these problems. One of these cases is called the
“blue bus hypothetical” problem. Suppose a witness saw a bus strike a car but
could not recall the color of the bus. Assume further that there are only two bus
companies: The Blue Company and the Red Company. Which company is more
likely liable for this accident? The most prevalent view in the legal literature of
the probative value of the witness’s report is that the ratio of Blue Company
buses would determine it to Red Company buses in a reference class. Suppose
the reference class is the street where the accident occurred, and suppose the
Blue Company owns 75% of the buses in the street while the Red Company
owns the remaining 25%. In that case, the Blue Company is more likely liable
for this accident. But if the reference class is the town where the accident took
place and suppose the Red Company owns 75% (and Blue the other 25%) of the
buses in the town. Now the rate reverses, the Red Company is more likely liable.
Furthermore, this would do so again if Blue owned 75% in the county and if
Red owned 75% in the state, and so on. Similar reference classes can be divided
endlessly, but we don’t know which reference class is right. This example brings
a lot of enlightenment to Allen and Pardo. First of all, the probative value of
evidence is not the likelihood ratios of a given reference class. It corresponds
to a variety of diﬀerent reference classes. Evidence has an inﬁnite number of
likelihood ratios. Choosing any one of them, we must provide an explanation
or reason, and a reasonable reason will always be found. Second, for the same
reason, the value of evidence is not the information gain (the diﬀerence between
the posterior probability and the prior probability) in the context of a given
case. Finally, various statistical data or likelihood ratios from many reference
classes are shreds of evidence, even more, complex evidence, and they need to be
understood and explained [2]. Therefore, they believe that the likelihood cannot
describe the probative value of the evidence very well, and the probability is dif-
ﬁcult to obtain in reality. Even if it is obtained, it faces the diﬃculty of selecting
the reference class.

10
W. Du et al.
The diﬃculty of reference class which exists in the ﬁeld of judicial proof, is
a universal problem because in any time of determining the probability of an
individual thing or event with a certain feature, it may involve to select a ref-
erence class. Philosophers have elaborated on the universality and arduousness
of the reference class problem, but they have not proposed solutions. Artiﬁcial
intelligence experts who study common-sense reasoning also have encountered
the reference class problem, and they also have found this problem to be tricky.
Some scholars even believe that the diﬃculty of reference class selection is inher-
ently unsolvable, and there is no principled method for determining reasonable
reference classes [6].
This article will show that the reference class problem is not only solvable, but
also has many solutions. From ancient times, the survival of human beings and
even the survival of animals need to constantly evaluate risks based on frequency.
People usually consciously or unconsciously determine the relevant reference
classes based on their own experience and knowledge to evaluate the magnitude
of the risk. In fact, we are solving the reference class problem every day in our
life. For example, when you go out, referring to past weather conditions, you
need to determine whether it will rain or not today and whether there is a risk
of being caught in the rain. When riding an elevator, it is necessary to assess the
risk of being trapped by the elevator based on the frequency of previous elevator
failures. When traveling to a certain scenic spot, you need to assess your own risk
of accidents according to the frequency of accidents in the scenic spot during the
past, and so on. To stay alive, one must evaluate a good proportion of risk well,
which is impossible if one cannot distinguish the few relevant reference classes
from the many irrelevant ones. We solve relevant reference-class problems. Surely
it is possible to say how. James Franklin [8] gives the following solution to the
reference class problem: (a) A reference class should be deﬁned by its features,
so the problem reduces to explaining the relevance of features; (b) For statistical
evidence, relevance is co-variation, for instance, a feature A is relevant to a
prediction B if A and B co-vary or are correlated), and (c) The ideal reference
class for an outcome B is the class deﬁned by the intersection of all the feature
relevant to B.
Applying Franklin’s solution, we should pay attention to the following four
points. First, we must distinguish between a set or class – the actual members
- and the features deﬁning it. For example, to evaluate the probability that the
market price of a house (denoted as A) is greater than 3 million yuan (denoted
as B), we need to ﬁnd the “similar” houses that have been sold based on the
features of house A (denoted as F). The collection of these similar houses is the
reference class to be found. The features of determining similar houses may be
the residential district (F1) where the house is located, the area size (F2), the
apartment type (F3), the ﬂoor (F4), the house age (F5), and so on. Secondly, we
must ﬁnd the correlation between the features F and the prediction or outcome
B. The relevance of the four features of the residential area, area size, house type,
and ﬂoor to the house price is co-variable. Once again, once the relevant features
of A and a prediction B are identiﬁed and determined, the relevant reference

Resolving the Cohenian Paradox in Judicial Probability Theory
11
class C is quite clear. The reference class C is composed of members similar to A
that meet all relevant features. Finally, for the reference class selected according
to Franklin’s solution, a problem may arise: too few members meet all relevant
features so that the reference class is too small to make a relevant frequency
estimate. Under normal circumstances, a relevant reference class should contain
enough members to make reliable estimates and predictions of the outcomes.
Suppose the reference class is too small or even contains only one element of
the original members. In that case, it will not support any reliable estimates
because members rarely appear in such classes. One solution is to select several
features from all relevant features to deﬁne multiple reference classes and then
weigh the rationality of each reference class and select a class from them. For
example, to predict the probability that the sales volume of book A exceeds
10,000 copies, the relevant features are the same author, the same topic, and the
same publisher. If you want to meet these three features simultaneously, then the
reference class will appear too small. We can deﬁne a reference class C1 based
on the features of “the same author,” and then deﬁne another reference class C2
based on “the same topic” and then tradeoﬀthe outcome of these two reference
classes to make a choice.
Discussing the judicial statistical evidence, the Charles Shonubi case is often
much-discussed [2,17,18].1 Regarding the dispute, in this case, scholars have
mainly focused on the issue of reference class selection. The basic facts of this
case are as follows: On December 10, 1991, Charles Shonubi, swallowed 103
balloons in the previous two days. The balloons contained a total of 427.4 g of
heroin. He was arrested after arriving at John F. Kennedy Airport from Nigeria.
The jury convicted him of drug smuggling. During the trial, the government also
conﬁrmed that Shonubi, a Nigerian citizen and a resident of the United States,
smuggled drugs from Nigeria to the United States eight times from Septem-
ber 1, 1990 to December 10, 1991. At the time of the sentencing, Judge Jack
Weinstein had to determine the amount of heroin that Shonubi had smuggled
in the past seven times based on superior evidence. This amount constituted
drug smuggling. Shonubi’s sentence was based on the total amount of smuggling
heroin eight times, not the amount of smuggling when he was arrested. During
the trial, a government expert provided an important body of evidence concern-
ing “the number of heroin seized from 177 Nigerian heroin abusers at Kennedy
Airport during Shonubi’s eight trips.” Based on this data, Judge Weinstein con-
cluded that Shonubi had smuggled 1,000 to 3,000 g of heroin during his eight
trips and sentenced him accordingly. However, Shonubi appealed this sentence
and the Second Circuit Court of Appeals vacated the sentence because the total
quantity of drugs smuggled by Shonubi had not been established by a prepon-
derance of evidence. This was partly because there was no “speciﬁc evidence”
that Shonubi smuggled the quantity of drugs on which the sentencing was based.
For this reason, the case was sent back to Judge Weinstein in the District Court
for resentencing [5].2
1 United States v. Shonubi, 895 F. Supp. 460 (E.D.N.Y. 1995).
2 United States v. Shonubi, 103 F.3d 1085 (2d Cir. 1997).

12
W. Du et al.
Allen and Pardo [2] agree that the Shonubi case dealt with the problem of
reference class selection, and do not reject the use of probabilistic reasoning. In
the Shonubi case, they point out that the problem is that there is no detailed
argumentation about the reasonable foundation of the selected reference class.
For example, why can the amount of heroin seized from 177 Nigerian heroin
users be used to predict the number of heroin smuggled by Shonubi? What
is the basis for the selection of these 177 smugglers? What is its reasonable
foundation? All need further justiﬁcation. It should not be taken for granted
that such reference classes are reasonable just because the data of these reference
classes are easily available. The Shonubi case provides a vivid example of the
importance of selecting reference classes and the necessity of demonstrating its
reasonableness.
We agree with Allen and Pardo’s point of view that in the use of probabilistic
methods in judicial proof, the choice of reference classes and the reasonableness
of the reference class needs to be justiﬁed. In fact, The Franklin’s solution is the
basis to ensure that the selected reference class is reasonable. In the Shonubi
case, if “from Nigeria, it is a drug mule, at JFK Airport, within this period,”
these four features are considered to be related to the number of smuggled drugs.
If there is no evidence that any of features available evidence are relevant, the
reference class of these 177 smugglers is reasonable.
4
The Conjunction Problem: A Probabilistic Justiﬁcation
Mathematicians have long developed what might be termed as conventional
probability theory, in which probabilities theory obey certain basic principles,
such as that the probability of proposition A ∩B, given a body of information
O, equals the probability of A, give O, times the probability of B, given A and
O. This is the multiplication principle in (conventional) probability theory. And
most people understand the basic idea of probability with respect to proposition
reﬂecting events that might recur in essentially identical form: thus, “The prob-
ability that any given ﬂip of a fair coin will land heads up is 1 in 2”. However,
Friedman [9] questions this by saying what bearing does this have on litigation.
In Cohen’s view, neither the complementary principle for negation nor the mul-
tiplication principle for conjunction applies to the central core of any forensic
proof in the Anglo-American legal systems [4, p. 2].
The diﬃculty of conjunction, also known as evidence aggregation problem,
is ﬁrst proposed by Jonathan Cohen [4, ch.5]. In most civil cases, the plaintiﬀ’s
contention consists of several component elements [4, p. 58]. The multiplication
principle for the mathematical probability of a conjunction entails that, if the
contention as a whole is to be established on the balance of mathematical prob-
ability, there must either be very few separate components in the case or most of
them must established at a very high level of probability. Since this constraint on
the complexity of civil cases is unknown to the law, the mathematical analysis
is in grave diﬃculties here.
Speciﬁcally speaking, when the facts claimed by the plaintiﬀinclude two or
more individual elements, each element must be justiﬁed to make the litigation

Resolving the Cohenian Paradox in Judicial Probability Theory
13
successful. In a traﬃc accident compensation case, for example, the car driver
is suing an insurance company because it refuses to compensate him after an
accident. The circumstances of the accident (denoted as A) and the terms of
the insurance contract (denoted as B) may both be disputed. If he succeeds
in the lawsuit, both of these elements must be justiﬁed on the basis of the
plaintiﬀ’s beneﬁt. On the contrary, as long as one elements of them has not
been successfully justiﬁed, his claims will not be fully supported. Assuming that
the “preponderance principle of evidence” of the civil proof standard can be
interpreted as the probability requirement of asserting facts greater than 0.5,
then should this requirement be applied to each element separately? Or is it
applicable to their conjunction, that is, the entire case? We believe that there are
three possible solutions for this problem. The ﬁrst solution is that the principle of
probability balance is only applicable to an individual element; that is, only the
probability of each element is required to be greater than 0.5 without considering
the probability of their conjunction. The second solution is that the principle of
probability balance is only applicable to the entire case; that is, it only requires
that the probability of all the elements is greater than 0.5, and there is no
need to examine the probability of each element. The third solution is that the
probability value of each element is required to be examined, and the combined
probability of all elements is required to be greater than 0.5. The probabilistic
method adopts the third solution. The probability of each element is examined.
However, there is no requirement for its value to be greater than 0.5. Then the
relevant probability formula is used to calculate the probability of conjunction,
and its value is required to be greater than 0.5. Based on Cohen’s analysis
[4, p. 59], assuming that C is the conjunction of elements A and B, that is,
C = A ∩B, according to the evidence provided, the fact-ﬁnder believes that
A and B are two independent elements, each of which is determined with a
probability of 0.7, then, according to the multiplication principle of probability,
P(C) = P(A)×P(B) = 0.7×0.7 = 0.49. In other words, their joint outcome can
be determined with a suﬃciently high probability since 0.7 is greater than 0.49.
Thus, although the probability of each element satisﬁes the proof standard of
the principle of probability balance, the probability of the whole case does not.
The point to require for a balance of mathematical probability seems a necessary
consequence of construing the standard in civil cases, but it seems to be a rule
that is unknown to judges and not respected by trier of fact.
Pardo and Allen [17] also mention the conjunction problem, the conjunction
paradox called by them, and question the applicability of Bayesian probability
theory in judicial proof. Most Bayesian theorists have reconstructed the proba-
bility of the standard of persuasion for the claimants’ claim to mean that, under
a preponderance of standard of 0.5 for a claim with two element, A and B,
the probability of A × B exceeds 0.5, and for a three-element claim A × B × C
must exceeds 0.5, and so on. This would mean that as the number of elements
increases, the probability needed for each element would increase as well. In
other words, for two elements, the average probability for each element must be
approximately 0.707; for three elements, 0.794; for four elements, 0.841; and so

14
W. Du et al.
on. From their point of view, it leads to some paradoxical conclusion such as the
following: the plaintiﬀin a two-element claim wins when proving each element
to 0.6 despite their conjunction probability is 0.36, and loses when proving one
element to 0.9 and the other to 0.5 and having the conjunction probability of
0.45. That is why Cohen regards this ﬁnding as paradoxical, and telling against
the application of probabilistic reasoning to a civil suit [7].
To avoid the diﬃculty of conjunction, Cohen points out that the rule of civil
suits requires the plaintiﬀto prove each element of his case on the balance of
probability [4, p. 58]. Cohen adopts the ﬁrst solution. The car driver in the
above case wins, even though the total probability (conjunctive probability) of
the entire case is less than 0.5. While opposing probabilistic methods to judicial
proofs, as mentioned earlier, Allen and Pardo [3] propose the theory of relative
plausibility as an alternative. In the relative plausibility theory, they adopt the
second solution, in which the fact-ﬁnder infers the best explanation of all the
evidence as a whole. According to the applicable proof standards, the compari-
son between the competing explanations is also carried out at the overall level to
determine the best explanation of the case. Once the best explanation is deter-
mined, we should compare the explanation with the various formal elements
required by the substantive law to see if they are included in the explanation.
If included, the explanation will be accepted, and the corresponding claim will
win. Otherwise, the explanation will be rejected, and the corresponding claim
will lose. The relative plausibility theory also avoids the emergence of the con-
junction problems.
We consider that the third solution seems to be intuitive and natural. The
ﬁrst solution simply involves examining all of the elements one by one, using
a local perspective, whereas our instinct is to evaluate the case as a whole.
The second solution, which looks at the whole case, takes a holistic view, but
ignores the individual examination of each element, making it easy to alter or
even distort evidence. Simon’s critique of this solution is that the holistic process
itself has the potential to distort verdicts. Holism does not appear from nowhere.
Rather, it is constructed via a cognitive process that entails a transformation of
the fact-ﬁnder’s mental representation of the evidence and drives the evidence
towards a more extreme view of the cases [20]. For this cognitive process, we
believe that it should be an analytic process from part to whole. The third answer
is exactly in line with this idea, examining each element in part ﬁrst, and then
evaluating the whole, while probabilistic method is an inference method based on
this cognition. In Pardo and Allen’s example mentioned earlier, the probability
of both elements in the ﬁrst case is 0.6; In the second case, the probability of
one element is 0.9 and the probability of the other is 0.5. According to the third
solution, our interpretation is that the plaintiﬀwill lose in both cases and will
not lead to a paradoxical conclusion because the probability of their conjunction
is less than 0.5, i.e., 0.36 for one and 0.45 for the other. They conclude that the
plaintiﬀwill win in the former case and lose in the latter case because he uses
the ﬁrst solution, which requires only a probability greater than 0.5 for each
element. However, in both cases, according to the third solution, the plaintiﬀ

Resolving the Cohenian Paradox in Judicial Probability Theory
15
will lose and will not produce a paradoxical conclusion because the probabilities
of their conjunction are both less than 0.5; that is, one is 0.36, and the other is
0.45.
In probability theory, according to the multiplication principle of probability,
if C = A ∩B, and A and B are not independent of each other, then P(C) =
P(A)×P(B|A) = P(B)×P(A|B). If A and B are independent each other, then
P(C) = P(A) × P(B). No matter which principle is applied, it is unlikely that
the probability of C is greater than the probability of either A or B, and usually
much less than the probability of either because a positive number greater than 0
times something less than 1 is deﬁnitely less than itself. It is correct for Allen and
Pardo to understand that for the probability of conjunctions to be greater than
0.5, the probability values of the elements must be higher. The more elements the
conjunction has, the higher its probability value is required, and correspondingly,
the more diﬃcult it is to prove. While Cohen’s intuition seems to be that it is
already very demanding to require the plaintiﬀto be satisﬁed by the court that
the probability of each element is greater than 0.5. Thus, it would be unfair to
further establish that the probability of conjunctions in the whole case is greater
than 0.5.
Although Cohen [4] and Pardo and Allen [17] have exactly recognized this
point, their mistakes are to apply this probability theory to judicial proof too
simplistically. If the terms in the judicial proof are explained more comprehen-
sively and formalized under the framework of probability theory, the conjunction
problem will disappear. In fact, Dawid [7] has shown that Cohen’s paradox and
its related variants would have evaporated if the conjunction probability had
been properly analyzed within the Pascal framework, in which he uses prior
probability and posterior probability to demonstrate the reliability of the wit-
ness. He maintains that the combination of several independent pieces of evi-
dence provides more support for the case than any of its individual evidence.
Unlike Pardo and Allen’s point of view, Dawid believes that if a case is divided
into more and more individual elements, the increase in the number of elements
will not greatly impact the overall eﬀect. If there is any impact, it will give the
claimant an advantage, even though he must determine each element with a
high probability. Dawid [7] concludes that this probabilistic analysis, correctly
performed, is in complete accord with logic and common-sense. However, in the
ﬁeld of evidence law, there are some scholars who discuss the diﬃculties of con-
junction in the theory of judicial probability, and even question the applicability
of this method. Therefore, we think it is necessary to make some responses to
their criticisms.
To apply this probabilistic approach to judicial proof, the reasoner must ﬁrst
distinguish between the concept of evidence and proposition. A proposition is
an assertion, a hypothesis, a fact to be proved, or an essential fact speciﬁed by
substantive law. Evidence is a material used to establish the facts of a case. It’s
the evidence that we’re evaluating, not the proposition. The supportive degree
of the evidence to the proposition is also called the probative value of evidence.
For the evidence E and the proposition H, the reasoner should distinguish the

16
W. Du et al.
prior probability P(H) and the posterior probability P(H|E) of the proposition
H and the likelihood of the evidence P(E|H). The likelihood is used to mea-
sure the reliability of evidence, and the likelihood ratio P(E|H)/P(E|not H) is
used to measure the probative value of evidence. In the process of probabilistic
reasoning, one must ﬁrst evaluate the prior probability of the proposition and
the likelihood of the evidence and then use probability theory to calculate the
posterior probability of the proposition. The posterior probability is not only
related to the likelihood but also the prior probability. Only prior probabil-
ities and likelihoods can be assigned to probability numbers through relevant
data or subjective experience. The posterior probabilities can only be calculated
through the Bayes formula and cannot be directly assigned. When conducting
probabilistic reasoning, people usually make three mistakes. One is to ignore
the prior probability, the other is to confuse the likelihood and the posterior
probability, and the posterior probability is directly assigned. The third is to
use the posterior probability to evaluate the probative value of evidence. In fact,
the probative value of evidence should be measured using the likelihood ratio
model.
In the context of probability, the conjunction problem can be described as
when two pieces of evidence a and b are considered at the same time, the posterior
probability of proposition C will be less than the posterior probability of C when
considering a single piece of evidence, that is, P(C|a∩b) < P(C|a), P(C|a∩b) <
P(C|b). The reason why the conjunction problem is counter-intuitive lies in
the wrong calculation process; that is, if the evidence a and b are independent
of each other, then P(C|a ∩b) = P(C|a) × P(C|b). The correct calculation
should use the Bayesian formula to evaluate the evidence. Taroni et al. [21] give
an example. Assuming that the prior probability of proposition C equals 0.5,
namely P(C) = 0.5, the posterior probability P(C|a) = P(C|b) = 0.7. When
evidence a and b are independent of each other, the Bayesian formula is used to
calculate the likelihood ratio of evidence a and b, and the two likelihood ratio are
equal to 2.33. However, the likelihood ratio of combined evidence a ∩b is equal
to 5.44, greater than their respective likelihood ratio. In addition, the posterior
probability P(C|a∩b) = 0.84, which is also greater than their respective posterior
probabilities. This example shows that as long as probabilistic reasoning is used
correctly, the probative value of conjunctive evidence can be greater than that of
its individual branch evidence. The posterior probability given the conjunctive
evidence can also be greater than the posterior probability given its branch
evidence. The conjunction problem doesn’t exist at all.
Going back to the traﬃc accident compensation case mentioned in the pre-
vious section, we think there is a lot of ambiguity in Cohen’s statement. What
is the evidence? Is 0.7 a prior probability, a posteriori probability or likelihood?
The meaning of this number is unclear. Based on intuition Cohen uses the prob-
ability multiplication principle roughly, which leads to the so-called conjunction
problem. There are at least four problems with Cohen’s proof. First, his rea-
soning process does not clearly show the corresponding evidence, and without
evidence, it is impossible to carry out formal evidential reasoning, and thus can-

Resolving the Cohenian Paradox in Judicial Probability Theory
17
not guarantee the soundness of his argumentation. Second, according to Cohen’s
description, 0.7 should be a posterior probability, but due to the lack of relevant
evidence, 0.7 is written as a prior probability, that is, P(A) = P(B) = 0.7. It
can be seen that his use of symbols seems somewhat confusing. Third, Cohen
does not explain how the posterior probability of 0.7 was calculated, nor does
he explain the related prior probability and likelihood, making the mistake of
directly assigning the posterior probability. Fourth, the probative power of evi-
dence should be evaluated by likelihood rather than a posteriori probability.
If the posterior probability is really to be used to evaluate it, then, according
to the Bayesian probability, the ratio of the posterior probability to the prior
probability needs to be evaluated, and if this ratio is greater than 1, then the
likelihood rate is greater than 1. Therefore, in our opinion, it seems that Cohen
should not compare the posterior probability 0.49 of conjunction C with the
posterior probability of element A or B, but it is meaningful to compare it with
the prior probability of C.
Assume that a and b evidence is the evidence of proposition A and B, respec-
tively, and the reliability of evidence is 70%, namely, P(a|A) = P(b|B) = 0.7.
When evidence a and b are independent of each other, proposition A and
B are independent of each other. Apparently Cohen’s ﬁnal calculation is the
posterior probability is P(a ∩b|A ∩B). It is interesting to note that by the
probability calculus, Dawid [7] ﬁnd that to make the posteriori probability
P(a|A) = P(b|B) = 0.7, the prior probability must be equal to 0.5, i.e.
P(A) = P(B) = 0.5, so the prior probability of the conjunction is: P(A ∩B) =
P(A) × P(B) = 0.25, and P(a ∩b|A ∩B) = P(a|A) × P(b|B) = 0.49. Here
we reconstruct Cohen’s reasoning by means of prior probability and a posteri-
ori probability. This is obviously not result in a paradoxical conclusion because
P(a ∩b|A ∩B)/P(A ∩B) = 0.49/0.25 = 1.96 > 1. It can be seen that the prob-
ability of the conjunctive evidence a ∩b still provides positive support for the
conjunctive proposition A ∩B, and does not reduce its probability. In addition,
Dawid [7] also ﬁnds the law that the posterior probability of conjunction varies
with its prior probability, as shown in the following table:
Table 1. Dawid on prior probability vs posterior probability
Priori probability P(A ∩B)
0.05 0.1
0.2
0.25 0.3
0.4
0.5
Posterior probability P(a ∩b|A ∩B) 0.16 0.27 0.43 0.49 0.55 0.64 0.72
As we can see from Table 1: (1) The posterior probability is always greater
than its corresponding prior probability, and its ratio is greater than 1. Conjunc-
tive evidence a ∩b still provides positive support for the conjunctive proposition
A∩B; (2) As long as the prior probability is not below 0.3, the posterior proba-
bility will be greater than 0.5, satisfying the balance principle of the probability
for the standard of proof. Therefore, in the case of 70% reliable evidence, as

18
W. Du et al.
long as the prior probability P(A ∩B) is greater than 0.3, Cohen’s so-called
conjunction problem ceases to exist.
5
Conclusion
As for the debate on the nature of judicial certiﬁcation, we believe that it is
impossible to reach a consensus and there is no ultimate winner. The relative
plausible approach, i.e. interpretivism, based on the inference to the best inter-
pretation is vague and not perfect in the normative aspect. The probabilistic app-
roach, i.e., the probabilism, based on probabilistic reasoning requires too many
probability values. These values are sometimes diﬃcult to obtain, and there is
no accepted method of probability assignment. Both of the two approaches are
not incompatible but each has its pros and cons. Because of this, we may have to
change the perspective of thinking that they are not absolutely opposed to each
other, but can be considered the complementarity of their common application
to judicial proof. In some cases, the best explanation in support of a decision
may involve an explicit probabilistic reasoning process. Lipton [15, pp. 119–120],
for example, has provided a brief exploration of the prospects for a compatibilist
view of the relationship between the probabilism and the explanationism. In
his view, it is compatible with the view that explanatory consideration helps
us to perform what is in eﬀect a Bayesian calculation and Bayesianism poses
no particular threat to the relative plausibility theory. Speciﬁcally speaking,
Bayes’ theorem provides a constraint on the rational distribution of degrees of
belief, but this is compatible with the view that explanatory considerations play
a crucial role in the evolution of those beliefs and indeed a crucial role in the
mechanism by which we attempt, with considerable but not complete success, to
meet that constraint. That is why the Bayesian and the explanationist should be
friends. According to Horwich [12], our full beliefs of degree would comply with
the laws of deductive logic, and similarly, our degrees of belief should conform
to the probability calculus. The elementary probabilistic models of degrees of
belief often contains just the right balance of accuracy and simplicity to enable
us to command a clear view of the issues and see where we were going wrong.
The probabilistic method is an important analytical tool for judicial proof, but
it is not a decisive tool. When the fact-ﬁnding process is reasonable for proba-
bility analysis, the advantages of quantitative analysis should be used rationally.
To sum up, in our view, the probabilistic approach of judicial proof is not only
self-consistent and normative, but also does not lead to paradoxical conclusions
and unfair decisions. For the most part, the Cohenian paradoxes proposed by
other schools of new evidence scholars are nothing more than misconceptions of
probability.
Acknowledgments. This work was supported by the National Oﬃce and Social Sci-
ence, P. R. China, for the project “Logical Model of Criminal Evidential Reasoning”
(19BZX138).

Resolving the Cohenian Paradox in Judicial Probability Theory
19
References
1. Allen, R.J.: The nature of juridical proof: probability as a tool in plausible rea-
soning. Int. J. Evid. Proof 21(1–2), 133–142 (2017). https://doi.org/10.1177/
1365712716674794
2. Allen, R.J., Pardo, M.S.: The problematic value of mathematical models of evi-
dence. J. Legal Stud. 36(1), 107–140 (2007)
3. Allen, R.J., Pardo, M.S.: Relative plausibility and its critics. Int. J. Evid. Proof
23(1–2), 5–59 (2019). https://doi.org/10.1177/1365712718813781
4. Cohen, L.J.: The Probable and the Provable. Clarendon Press, Oxford (1977)
5. Colyvan, M., Regan, H.M., Ferson, S.: Is it a crime to belong to a reference class.
J. Polit. Philos. 9(2), 168–181 (2001). https://doi.org/10.1111/1467-9760.00123
6. Colyvan, M., Regan, H.M.: Legal decisions and the reference class problem. Int. J.
Evid. Proof 11(4), 274–286 (2007). https://doi.org/10.1350/ijep.2007.11.4.274
7. Dawid, A.P.: The diﬃculty about conjunction. J. R. Stat. Soc. Ser. D (Stat.)
36(2/3), 91–97 (1987)
8. Franklin, J.: The objective Bayesian conceptualisation of proof and reference class
problems. Sydney Law Rev. 33(3), 545–561 (2011)
9. Friedman, R.D.: Answering the Bayesioskeptical challenge. Int. J. Evid. Proof 3(4),
276–291 (1997)
10. H´ajek, A.: Explanations of probability. The Stanford Encyclopedia of Philosophy.
Substantive revision 2019. Stanford Encyclopedia of Philosophy (2019). https://
plato.stanford.edu/archives/fall2019/entries/probability-interpret/
11. Hamer, D.: Probabilistic standards of proof, their complements and the errors that
are expected to ﬂow from them. Univ. New Engl. Law J. 1(1), 71–107 (2004)
12. Horwich, P.: Wittgensteinian bayesianism. Midwest Stud. Philos. 18(1), 62–77
(1993)
13. Hunt, I., Mostyn, J.: Probability reasoning in judicial fact-ﬁnding. Int. J. Evid.
Proof 24(1), 75–94 (2020). https://doi.org/10.1177/1365712719875753
14. Kaplan, J.: Decision theory and the fact-ﬁnding process. Stanford Law Rev. 20(6),
1065–1092 (1968)
15. Lipton, P.: Inference to the Best Explanation, 2nd edn. Routledge, Abingdon (2003)
16. Pardo, M.S.: The paradoxes of legal proof: a critical guide. Boston Univ. Law Rev.
99(1), 233–290 (2019)
17. Pardo, M.S., Allen, R.J.: Juridical proof and the best explanation. Law Philos.
27(3), 223–268 (2008). https://doi.org/10.1007/s10982-007-9016-4
18. Redmayne, M.: Exploring the proof paradoxes. Legal Theory 14(4), 281–309
(2008). https://doi.org/10.1017/S1352325208080117
19. Rescher, N.: Dialectics: A Controversy-Oriented Approach to the Theory of Knowl-
edge. State University of New York Press (1977)
20. Simon, D.: Thin empirics. Int. J. Evid. Proof 23(1–2), 82–89 (2019). https://doi.
org/10.1177/1365712718815350
21. Taroni, F., Aitken, C., Garbolino, P., Biedermann, A.: Bayesian Networks and
Probabilistic Inference in Forensic Science. Wiley, New York (2006)
22. Urbaniak, R., Di Bello, M.: Legal Probabilism. Stanford Encyclopedia of Phi-
losophy. First publshied 8 June 2021 (2021). https://plato.stanford.edu/archives/
sum2021/entries/legal-probabilism/
23. Welch, J.R.: Rebooting the new evidence scholarship. Int. J. Evid. Proof 24(4),
351–373 (2020). https://doi.org/10.1177/1365712720943329

Focusing the Argumentative Process:
Neighborhood-Based Semantics
in Abstract Argumentation
Melisa G. Esca˜nuela Gonzalez1, Maximiliano C. D. Bud´an1,3,
Diego I. Mart´ınez2,3, Maria Laura Cobo2,3, and Guillermo R. Simari2,3(B)
1 Depto. de Matem´atica, Universidad Nacional de Santiago del Estero (UNSE),
Santiago del Estero, Argentina
meliesca@unse.edu.ar, mcdb@cs.uns.edu.ar
2 Depto. de Cs. e Ing. de la Comp., Universidad Nacional del Sur (DCIC UNS),
Bah´ıa Blanca, Argentina
{dcm,mlc,grs}@cs.uns.edu.ar
3 Institute for Computer Science and Engineering (ICIC UNS–CONICET),
Bah´ıa Blanca, Argentina
Abstract. The introduction of abstract argumentation has allowed
the study of many exciting characteristics of the argumentation pro-
cess. Nevertheless, while helpful in many aspects, abstraction diminishes
the knowledge representation capabilities available to describe naturally
occurring features of argumentative dialogues. One of these elements
is the consideration of the topics involved in a discussion. In studying
dialogical processes, participants recognize that some topics are closely
related to the original issue, while others are more distant to the central
subject or simply refer to unrelated matters. Consequently, it is reason-
able to study diﬀerent argumentation semantics that consider the focus of
a discussion to evaluate acceptability. In this work, we will introduce the
necessary representational elements required to reﬂect the focus of a dis-
cussion, and we will propose an extension of the semantics for multi-topic
abstract argumentation frameworks acknowledging that every argument
has its own zone of relevance in the argumentation framework, leading to
a concept of a neighborhood of legitimate defenses. Furthermore, other
semantic elaborations are deﬁned and discussed around this structure.
1
Introduction
Abstraction is a pathway to study argumentation without acknowledging the
underlying logical structure, and thus the subject of study is centered on
semantics. Thus, arguments are treated as abstract entities linked through
interrelations between them, like support, attack, and weakening, among oth-
ers [1,4,11,17]. In this conceptual direction, Dung in [11] introduced Abstract
Argumentation Frameworks (AFs) with the top level of abstraction where argu-
ments are atomic, and a binary attack relation is deﬁned, leaving out of con-
sideration most details with the goal of studying argument interaction and the
c
⃝Springer Nature Switzerland AG 2021
P. Baroni et al. (Eds.): CLAR 2021, LNAI 13040, pp. 20–39, 2021.
https://doi.org/10.1007/978-3-030-89391-0_2

Focusing the Argumentative Process
21
possible outcomes of the argumentation process. Thus, recognizing the limits
of the bare-bones, abstract framework introduced by Dung in his foundational
work, researchers have advanced several extensions that augment the represen-
tational capabilities of the basic framework attaching additional features such
as preference, support relations, probability, and values [1,4,6,7,16,17].
Recognizing this situation, in this work, we are interested in introducing the
notion that corresponds to the topics associated with an argument. The fact
that arguments could be linked to diﬀerent topics and that these topics might or
might not be closely related to each other introduces a topological aspect over
the set of topics. Ignoring this intrinsic characteristic of dialogue may lead to
“going oﬀon a tangent” in the argumentation process; in other words, the topic
an argument addresses may allow other arguments to be used or rejected in a
particular dialogue.
In Bud´an et al. [5], a framework and its corresponding semantics in which
arguments are associated with abstract labels denoting that a piece of reasoning
may refer to diﬀerent topics in the context of argumentation was introduced.
For instance, an argument may refer to a virus pandemia, to the quarantine, and
to the welfare state, while another argument may refer to virus pandemia and
music online streaming. Although both arguments are related to one issue, the
second argument may not be as helpful while discussing health topics as the ﬁrst
argument. Thus, based on the semantic network of topics, a nearness or “prox-
imity” relation between arguments can be established, leading to a new notion
of admissibility semantics where only suﬃciently closely related arguments can
be involved in the argument defense. In this direction, an argument is considered
close enough to defend another argument if the distance between these is lower
than a particular threshold τ, and any potential defender such that its topic is
beyond τ will not be enabled as such. This is the basis of a proximity-semantics,
but the original framework has a characteristic that can be improved towards a
more realistic model. As deﬁned, the threshold is the same for all the arguments
leading to some unfair situations.
A
B
3
C
D
E
F
#quaranne
#tourism
#phobia
3
#quaranne
#tourism
#phobia
#pandemia
#pandemia
Fig. 1. Same-distance defenders under irregular network

22
M. G. Esca˜nuela Gonzalez et al.
Consider the framework of Fig. 1, where only the relevant hashtags are men-
tioned, and, for simplicity, there is only one hashtag per argument. Consider the
distance between arguments as the length of the shortest path between their
single hashtags. Here, the distance between A and C and between D and F is 3.
If the threshold of proximity for the framework is 3, both A and D are defended
by C and F, respectively. However, there seem to be more closely related topics
in the upper zone of the graph, where health issues are addressed, than around
#tourism. Since the semantic network of hashtags is not necessarily uniform, a
universal threshold may not be adequate in all cases. Here an individual thresh-
old for A may drop arguments about tourism, while a diﬀerent threshold for D
may enable all the arguments as defenders as long as they are both related to
health issues. Thus, an improvement of this model should consider variations
of distance for every piece of reasoning since the semantic network of topics, as
abstract as it is, maybe dense or sparse in diﬀerent regions or even related to
diﬀerent areas of interest.
In this work, we reﬁne the proximity semantics by deﬁning the proper defense
scope for every argument, which may vary in range among the sets of arguments.
Since the referred topics determine the associated distance in the network, an
individual threshold is required, and therefore diﬀerent sets of topics lead to
diﬀerent sets of potential defenders. Hence, in a sense, all the arguments “close”
enough to a given argument A constitute a neighborhood for A. Given that the
notion of closeness may diﬀer for every argument, the attribute of being a neigh-
bor is not universal: argument B may be a neighbor of A, but not the other way
around. This idea leads to restricted forms of acceptability of arguments, where
only defenders in the neighborhood are allowed. While in [5] a single, universal
degree of proximity is applied to the whole framework yielding an admissible
extension, here this attribute is deﬁned for every individual argument. In Fig. 1
argument C is required to be in the neighborhood of A in order to provide a
defense for A. Argument D may have a diﬀerent neighborhood, and if F is not in
it, then D has no close defense or, in other words, the defense provided by F is
not relevant for D. The previous discussion leads naturally to a novel admissible
semantics that we will address in this work.
This paper is organized as follows. In Sect. 2, the multi-topic abstract argu-
mentation frameworks are reviewed, while in Sect. 3, we introduce a set of seman-
tic notions that consider the “neighbourhoods” associated with the arguments
in the argumentation process. Finally, Sect. 4 is devoted to the related work,
concluding remarks, and further discussion.
2
Background
An argumentation framework is deﬁned as a pair composed of a set of atomic
arguments and a binary relation representing an attack relationship between
them. To determine which arguments are able to survive the conﬂict, a well-
deﬁned systematic method is needed; such formal methods to identify conﬂict
outcomes for an argumentation framework are referred to as argumentation

Focusing the Argumentative Process
23
semantics. All the well-known conceptual ideas introduced in [11] are assumed
as given, and in this work, we will limit our focus on reﬁning that framework by
considering diﬀerent metrics over a topics network aﬀecting the argumentation
discussion.
2.1
Hashtagged Argumentation Framework
We will present new forms of proximity-based semantics using hashtagged argu-
mentation frameworks [5] as a starting point because it provides the elements for
the consideration of a notion of distance. A hashtagged framework extends the
representation capability of abstract frameworks by adding the topics addressed
or referred to by the arguments. As it is usual in abstract frameworks, no ref-
erence to the underlying construction of the argument is made; however, Bud´an
et al. in [5] gives relevance to what an argument refers to, not as a linguistic
construction depending on its structure but as a whole. Topics are also treated
abstractly through labels called hashtags, denoted with the preﬁx #; that is, a
hashtag identiﬁes subjects to which the argument refers, implicitly or explicitly.
Since every argument is issued in the context of at least one subject or topic,
arguments are always associated with at least one hashtag.
Deﬁnition 1 (Hashtagged Argument). Given an argumentation framework
Φ = ⟨Args, Attacks⟩, let H be a ﬁnite non-empty set of hashtags. A hashtagged
argument structure, or, when no confusion might arise, just a hashtagged argu-
ment, is a pair ⟨A, HA⟩, where A ∈Args and HA ⊆H, |HA| > 0. Then, given
⟨A, HA⟩, it is said that A is tagged with HA. When possible, hashtagged arguments
will be succinctly denoted with the letters A, B, . . . , possibly with subscripts or
superscripts.
Michel Foucault keenly pointed out that “the frontiers of a book are never
clear-cut (...) it is a node within a network” in [12]; similarly, hashtags as top-
ics attached to arguments usually are not isolated, and they might be related
to others, leading to a semantic network of concepts. The resulting semantic
network can be represented through a graph structure as follows.
Deﬁnition 2 (Hashtag Graph). Let H be a ﬁnite set of hashtags, a hashtag
graph is a graph G = [H, E], where H is the set of vertices (hashtags) and E is
a subset of H × H that represents a set of edges between the vertices (hashtags’s
relationship) in H. When convenient, the graph G will be referred to as a hash-
cloud.
In particular, the well-known concept of a path in a graph is relevant for
the following deﬁnitions. A path is a ﬁnite or inﬁnite sequence of edges that
connects a sequence of vertices, assuming that they are all distinct from one
another. Thus, using paths, we can represent connections between topics and,
consequently, connections between arguments. Another essential component is
the notion of distance in a graph, which is closely related to paths (see [3,10,13]
for a comprehensive analysis). With these elements, not only the connections
but also the distance between arguments can be analyzed.

24
M. G. Esca˜nuela Gonzalez et al.
Deﬁnition 3 (Distance Between Hasthatgs). Let G = [H, E] be a hashtag
graph. The (geodesic) distance dG : H × H →N0 ∪{∞} between two vertices
α, β ∈H, denoted dG (α, β), is the number of edges in a shortest path connecting
them; additionally, if there is no path between α and β we say that dG (α, β) =
∞, where ∞, conventionally, represents the greatest possible distance. For all
α, β, γ ∈H, dG (·, ·) satisﬁes the following conditions:
1) dG (α, β) = 0 iﬀα = β (identity of indiscernibles),
2) dG (α, β) = dG (β, α) (symmetry), and
3) dG (α, γ) ≤dG (α, β) + dG (β, γ) (subadditivity or triangle inequality ).
From the three items above, we obtain the non-negativity or separation property
dG (α, β) ≥0.
The hashtags network is independent of the argumentation graph, as it
merely captures concepts and their semantic relations. From a knowledge repre-
sentation point of view, the topological structure G implies that the closer the
hashtags (vertices) are in the graph, the closer are the topics they stand for in
the represented domain. Thus, given a pair of hashtagged arguments, a notion
of proximity between these arguments can be induced by the distance existing
between the referred topics in the hashtagged graph G [5].
Deﬁnition 4 (Distance between Hashtagged Arguments). Given a hash-
tagged framework Ω = ⟨Φ, GΩ, dΩ⟩, where Φ = ⟨Args, Attacks⟩and GΩ =
[H, E], a distance function on Args is deﬁned as dΩ : Args×Args →N0 ∪{∞},
where for all A, B, C ∈Args, the following conditions should be satisﬁed:
1) dΩ(A, B) = 0 iﬀA = B (identity of indiscernibles),
2) dΩ(A, B) = dΩ(B, A) (symmetry), and
3) dΩ(A, C) ≤dΩ(A, B) + dΩ(B, C).
As before, the following can be obtained from the previous three.
4) dΩ(A, B) ≥0 (non-negativity or separation).
This formalization of the hashtags as a graph that represents both the topics
and their abstract connections, highlighting the distance between the argument,
will permit the examination of interesting semantic issues emerging from the
abstract notion of closeness. The following deﬁnition provides a formal frame-
work for hashtagged argumentation.
Deﬁnition 5 (Hashtagged Argumentation Framework). A hashtagged
argumentation framework Ω is represented as a 3-tuple ⟨Φ, GΩ, dΩ⟩, where
Φ = ⟨Args, Attacks⟩is an abstract argumentation framework in which Args
is a set of hashtagged arguments and Attacks is a subset of Args × Args repre-
senting an attack relation deﬁned on Args, GΩ = [H, E] is a hashtag graph, and
dΩ(·, ·) is a distance function deﬁned over Ω. The graph GΩ will be called the
hashcloud of Ω, and it will be denoted GΩ.
Given this formalization, an admissibility semantics is deﬁned in [5], that
uses the distance as a measure of relevance for defenses in the argumentation
process.

Focusing the Argumentative Process
25
2.2
Proximity-Based Semantics
The idea of argumentation-based reasoning is that an aﬃrmation is believable if
it can be defended successfully against attacking arguments. Hence, using hash-
tags is a pathway to further model proximity-based evaluations of argument
extensions to further reﬁne the abstract argumentation semantics. In particular,
proximity semantics, as deﬁned in [5] is applying the intuition that, for any argu-
ment, a closer defender is preferred over a distant one. Therefore, acceptability
for hashtagged arguments considering a threshold τ of proximity is introduced.
Under this interpretation of proximal defense, a potential defender that is beyond
the threshold will not be considered as such.
Deﬁnition 6 (Basic Proximity-based semantics). Let Ω = ⟨Φ, GΩ, dΩ⟩be
a hashtagged framework, dΩ(·, ·) be a distance function deﬁned in Ω, S ⊆Args,
and τ ∈N0 be a threshold. Then:
– A set S is said to be conﬂict free if there are no hashtagged arguments A, B ∈S
such that B attacks A (mirroring a similar deﬁnition in abstract frameworks).
– A hashtagged argument A ∈Args is τ-acceptable with respect to S when for
every argument B ∈Args that attacks A there is a hashtagged argument C ∈S
such that C attacks B and dΩ(A, C) ≤τ.
– S is said to be τ-admissible if every hashtagged argument in S is τ-acceptable
with respect to S.
– An τ-admissible set S is an τ-complete extension iﬀS contains each argument
that is τ-acceptable with respect to S.
– A set S is the τ-grounded extension of Ω iﬀS is a ⊆-minimal τ-complete
extension.
– A set S is an τ-preferred extension of Ω iﬀS is a ⊆-maximal τ-complete
extension.
Next, we present a example showing how the concepts introduced above play
a role in the argumentation formalism.
Example 1. Consider
the
hashtagged
argumentation
framework
Ω
=
⟨Φ, GΩ, dΩ⟩, graphically represented in Fig. 2, where:
H = {#α1, #α2, . . . , #α25}.
E
= {(#α1, #α2),(#α1, #α8),(#α1, #α5),(#α1, #α13),(#α2, #α4),(#α2, #α5),
(#α2, #α24),(#α3, #α6),(#α4, #α5),(#α4, #α8),(#α4, #α16),(#α4, #α17),
(#α5, #α8),(#α6, #α7),(#α6, #α20),(#α7, #α21),(#α7, #α10),(#α8, #α12),
(#α8, #α11),(#α11, #α15),(#α12, #α13),(#α15, #α18),(#α16, #α23),
(#α21, #α25),(#α21, #α22),(#α22, #α25),(#α23, #α24),
Args = {A, B, C, D, E, F, G, H, I, J}.
Attacks = {(A, B), (B, H), (C, D),(D, F),(E, J),(F, E),(H, J),(I, A)}

26
M. G. Esca˜nuela Gonzalez et al.
Fig. 2. Hashtagged argumentation framework and hashcloud for Ω
Then, consider the following non-intersection distance
dΩ(A, B) =
⎧
⎪
⎪
⎨
⎪
⎪
⎩
max(dG (α, β)) where α ∈HA\HB and β ∈HB\HA,
0
when HA = HB,
∞
if for all α ∈HAand β ∈HB,
there is no path between them.
Table 1 shows the distances between arguments, where “–” means that the dis-
tance is ∞. Consider a threshold τ = 4, we obtain the following extensions:
Table 1. Distances between the hashtagged arguments in Ω
A B C D E F G H I
J K
A 0
5
2
–
1
2
–
3
2 5 1
B
5
0
5
–
4
4
–
3
4 5 4
C 2
5
0
–
2
3
–
4
1 5 3
D –
–
–
0
–
–
–
–
– v –
E
1
4
2
–
0
2
–
2
2 5 2
F
2
4
3
–
2
0
–
3
– 5 2
G –
–
–
–
–
–
0
–
– – –
H 3
3
4
–
2
3
–
0
3 4 3
I
2
4
1
–
2
–
–
3
0 5 2
J
5
5
5
–
5
5
–
4
5 0 5
K 1
4
3
–
2
2
–
3
2 5 0
The set S1 = {I, B, G} is τ-complete extension since it contains all the argu-
ments that are defended by S1. Furthermore, S1 is a minimal set satisfying the
previous conditions, and therefore it is the τ-grounded extension of Ω. That is, on

Focusing the Argumentative Process
27
the one hand, G and I have no attacker, while I is a proper defender of B (The rea-
son is that dΩ(I, B) = 4 ≤4). On the other hand, the even attack cycle between
the arguments D and C, and K and D, limit the acceptance of other arguments
in the discussion, under a skeptical position. The set S2 = {I, B, C, K, F, G} and
S3 = {I, B, D, G} are τ-admissible and τ-complete extension since they contains
all the arguments that are defended by S2 and S3, respectively. In addition, S2
and S3 are the maximal sets verifying the previous conditions, and therefore they
are both τ-preferred extensions of Ω. Same analysis performed by the τ-grounded
extension can be made for the preferred extension.
Note that in [5] the threshold is a unique property of the whole argumen-
tation framework aﬀecting all the possible extensions. This choice means that
the same distance used to enable defenses is applied to every argument, lead-
ing to an extension that is induced by a given single threshold. As stated in
the introduction, a more reﬁned approach may consider individual thresholds
for each argument; thus, the range of defenses available for a given argument
becomes a local property of this argument. We will address this generalization
in the following sections.
3
Argument Neighborhoods: A Topological View
As we mentioned before, as a piece of reasoning, every argument addresses cer-
tain speciﬁc topics, and every topic is naturally associated with many others in
varying degrees of “closeness”. Consequently, there is an underlying perception
of distance between arguments when considering their topics. In a mathemat-
ical sense, a topological space may be intuitively described as a set of points
along with a set of neighborhoods for each point. Any metric space will also be a
topological space because, given a set, any properly speciﬁed distance function
deﬁned on it induces a topology on that set. The pair (Args, dΩ) associated with
a Hashtagged Framework Ω can be regarded as a metric space in the topology
sense, where a distance may be deﬁned.
Intuitively speaking, a neighborhood of a point p is a set of points containing
p and the points that can be reached within a given distance from p. A point p
may have several neighborhoods of diﬀerent sizes by considering diﬀerent radius
(distances). In Topology, a ball is the space bounded by a sphere. It may be
a closed ball (including the boundary points that constitute the sphere) or an
open ball (excluding them). Thus, a neighborhood associated with a point x ∈S
with radius εx is the closed ball deﬁned as
B(x; εx) = {y ∈S : distance(x, y) ≤εx}.
It is important to remark that now the property of being a “neighbor” is local
to each point since the threshold distance is not necessarily the same for every
point. Illustrating this observation, Fig. 3 depicts three diﬀerent situations.
In the ﬁrst case, points a, b, and c do not have neighbors in common. In the
second case, the neighbors of a are also neighbors of b, but no neighbor of c is
a neighbor of a or b. In the third case, a has b as a neighbor, but not the other

28
M. G. Esca˜nuela Gonzalez et al.
Fig. 3. Examples for balls and neighborhoods centering on a speciﬁc point
way around, since b does not include a in its neighborhood. Similarly, the point
c has a b as neighbor but neither a nor c are neighbors of b. These concepts are
suitable to be applied to argumentation frameworks by associating arguments
with a neighborhood as follows.
Notation: We have switched the general notation for a threshold as τ to dis-
tinguish a local threshold ε subscripted with a particular argument making the
change in perspective more apparent.
Deﬁnition 7 (Argument Neighborhood). Let Ω = ⟨Φ, GΩ, dΩ⟩be a hash-
tagged framework, dΩ(·, ·) be a distance function on the set Args, and (Args, dΩ)
be the metric space associated with the tagged framework Ω. Then, the neigh-
borhood of an argument A ∈Args with radius εA under the metric (Args, dΩ) is
deﬁned as the set
NεA
A = {X ∈Args : dΩ(A, X) ≤εA, where εA ∈N0}.
The set of neighborhoods associated with arguments in Ω will be referred as NΩ.
A neighborhood is deﬁned by a threshold that is based on a distance deﬁned
between arguments. Since several notions of distance could be introduced, we
will focus on those inﬂuenced by the topics referred to by the arguments. A
particularly interesting possibility is to consider the thresholds determined by
the hashcloud created by the hashtags attached to every argument. Various
alternatives can be advanced to deﬁne the neighborhood for an argument; for
instance, their radius, centrality degree, topics classiﬁcation, to mention just a
few. Here, our primary purpose is only to allow defenses for an argument that are
close enough to the topics represented by the set of hashtags associated with this
argument. Since these hashtags may be closely related or widely dispersed, we
need a measure of argument semantic coverage that will provide a reference about
its size –always from the semantic point of view. Considering the observation just
made, the radius and diameter appear appropriate since they are themselves a
measure of size.
Deﬁnition 8 (Hashtag Metric Concepts). Let Ω = ⟨Φ, GΩ, dΩ⟩be a hash-
tagged framework, where Φ = ⟨Args, Attacks⟩, GΩ = [H, E] is a hashtag graph,
and let dG (·, ·) be a distance deﬁned on GΩ and let I ⊆H a ﬁnite, non-empty,
subset of hashtags. Then:

Focusing the Argumentative Process
29
– The eccentricity of a hashtag α ∈I is the maximum distance to any other
hashtag in I, i.e., eccentricity(α) = maxβ∈I dG (α, β). If α ∈I is not con-
nected to any other hashtag in I its eccentricity is associated with the con-
stant ∞, which, conventionally, represents the greatest possible distance, i.e.,
eccentricity(α) = ∞.
– The radius of I is the minimum eccentricity among all hashtags in I,
i.e.,radius(I) = minα∈I eccentricity(α).
– The diameter of I is the maximum eccentricity among all hashtags in I,
i.e.,diameter(I) = maxα∈I eccentricity(α).
Note that if I contains a single element then the eccentricity, the radius,
and the diameter will be zero. These graph-based topological concepts can be
naturally extended to hashtagged arguments as follows.
Deﬁnition 9 (Hashtagged Argument Metric Concepts). Given a hash-
tagged framework Ω = ⟨Φ, GΩ, dΩ⟩, an argument A = ⟨A, HA⟩∈Args, the radius
and diameter of A is the radius and diameter of HA, respectively.
The deﬁnition above provides a helpful characterization of the inﬂuence of
an argument in the framework. It is important to remark that this inﬂuence is
evaluated according to the topics and not to the underlying linguistic structure,
which is not relevant here given our abstract approach. In Fig. 4, the radius and
diameter of every argument are shown, and the directly induced neighborhoods
are listed. In some cases, such as A, there is a diﬀerence between the neighbor-
hood induced by the radius and the one induced by the diameter; in others, such
as B and K, both neighborhoods coincide. The radius and the diameter are two
criteria for establishing areas of semantic closeness, being the latter naturally
wider than the former.
Deﬁnition 10 (Metric associated with the neighborhoods in Ω). Let
Ω = ⟨Φ, GΩ, dΩ⟩be a hashtagged framework, dΩ(·, ·) be a distance function over
the set Args, (Args, dΩ) be the metric space associated with the tagged framework
Ω, and NεΩ
Ω = {NεX
X : X ∈Args} be the set of neighborhoods associated with the
arguments of Ω. Then:
– A neighborhood NεA
A ∈NΩ is the Greatest Neighborhood iﬀthere is no NεB
B ∈
NΩ such that εB > εA. We will use Tg
Ωto denote the greatest radius associated
with the greatest neighborhood of NΩ.
– A neighborhood NεA
A ∈NΩ is the Smallest Neighborhood iﬀthere is no NεB
B ∈
NΩ such that εB ≤εA. We will use Ts
Ωto denote the smallest radius associated
with the smallest neighborhood of NΩ.
These two kinds of neighborhoods are also important to establish a con-
nection between classical abstract frameworks semantics and the previous
proximity-based extensions. In the following section, we analyze the proximity-
based semantics [5] in this new context of individual thresholds.

30
M. G. Esca˜nuela Gonzalez et al.
Fig. 4. Arguments’ neighborhoods
4
Neighborhood-Bounded Admissibility
Since each argument X has now a defense range εX related to its neighborhoods,
it is necessary to provide a notion of admissibility that considers this range. A
set of arguments is said to be admissible if every argument is acceptable with
respect to that set by using defenses inside its own neighborhood.
Deﬁnition 11 (Conﬂict-freeness, Acceptability, and Admissibility). Let
Ω = ⟨Φ, GΩ, dΩ⟩be a hashtagged framework, dΩ(·, ·) be a distance function on the
set Args, and (Args, dΩ) be the metric space associated with the tagged framework
Ω. Then:
– A set S ⊆Args is said to be conﬂict free if there is no hashtagged arguments
A, B ∈S such that B attacks A (usual notion in abstract frameworks).
– A hashtagged argument A ∈Args is η-acceptable with respect to S if for every
argument B ∈Args, if B attacks A then there is a hashtagged argument C ∈S
such that C ∈NεA
A and C attacks B.
– S is said to be η-admissible if every hashtagged argument in S is η-acceptable
with respect to S.
Under this notion of distance-bounded defense, an argument that may be a
defender according to classical acceptability may not be a defender here; however,
the quality of a set of being (classically) admissible is preserved, because, as
it will be proved later, attacks are not restricted by distance, only defenses.
Admissibility semantics is focused on the characterization of sets of arguments
that provide mutual defenses within the set. By restricting defenses within to a
particular neighborhood, we are reshaping the original notion of admissible sets
(and also changing the notion of a focused, rational position) while respecting
argument conﬂicts in the whole scenario.

Focusing the Argumentative Process
31
Proposition 1. Given Ω = ⟨Φ, GΩ, dΩ⟩, where dΩ(·, ·) is a distance function on
the set Args, and let (Args, dΩ) be the metric space associated with the tagged
framework Ω. Then: i) If A ∈Args is η-acceptable w.r.t. a set S then it is
acceptable w.r.t. S; and ii) If a set S is η-admissible then it is admissible.
Proﬀ: This demonstration follows directly from the deﬁnitions, and it will be
done in two parts:
i) If A ∈Args is η-acceptable w.r.t. a set S then it is acceptable w.r.t. S.
Suppose that A ∈Args is η-acceptable w.r.t. a set S but A ∈Args is not
acceptable w.r.t. a set S. Then, there exists a hashtagged argument B ∈Args
such that B attacks A and there not exists a hashtagged argument C ∈Args
such that C attacks B. However, A is η-acceptable w.r.t. S and then for
every attacker hashtagged argument B ∈Args there exists a defender C ∈S.
Contradiction.
ii) If a set S is η-admissible then it is admissible. Suppose that S is η-admissible
but it is not an admissible set. Then, there exists an hashtagged argument
A ∈Args such that A is not η-acceptable w.r.t. S. However, S is η-admissible.
Thus, every hashtagged argument in S is η-acceptablew.r.t. S. Furthermore,
by consequence of i) if a hashtagged argument A ∈Args is η-acceptable
w.r.t. a set S then it is acceptable w.r.t. S. Contradiction.
⊓⊔
The converses of the statements in Proposition 1 do not hold. For instance, an
argument A may be acceptable with respect to the set {B}, but not η-acceptable
if B /∈NεA
A . Therefore, an admissible set may not be η-admissible. Furthermore,
as we mentioned, these semantic notions are a reﬁned version of the semantics
proposed in Sect. 2.2. Thus, the following proposition hold.
Proposition 2. Given Ω = ⟨Φ, GΩ, dΩ⟩, where dΩ(·, ·) is a distance function on
the set Args, and let (Args, dΩ) be the metric space associated with the tagged
framework Ω, and Ts
Ω and Tg
Ω be the radius associated with the smallest and
greatest neighborhoods of NΩ, respectively; let S ⊆Args. Then: i) If A ∈Args is
ε-acceptable w.r.t. S with ε = Ts
Ω, then it is η-acceptable w.r.t. S; ii) If A ∈Args
is η-acceptable w.r.t. S then it is ε-acceptable w.r.t. S with ε = Tg
Ω; iii) If S is
ε-admissible with ε = Ts
Ω, then it is η-admissible; and iv) If S is η-admissible
then it is ε-admissible with ε = Tg
Ω.
Proﬀ: This demonstration will be done in fourth parts:
i) If A ∈Args is ε-acceptable w.r.t. a set S with ε = Ts
Ω, then it is η-acceptable
w.r.t. S. Suppose that A is ε-acceptable w.r.t. a set S but A is not η-
acceptable w.r.t. S. Then, there exists a hashtagged argument B ∈Args
such that B attacks A but there is no hashtagged argument C ∈Args such
that C attacks B verifying that C ∈NεA
A . However, A is ε-acceptable w.r.t.
S with ε = Ts
Ω. Thus, the threshold applied to obtain the acceptable set of
arguments is equal to the radius associated with the lowest neighborhood
of NΩ. Then, for every attacked hashtagged argument A ∈S there exists a
defender C ∈S such that C ∈NεA
A . Contradiction.

32
M. G. Esca˜nuela Gonzalez et al.
ii) If A ∈Args is η-acceptable w.r.t. a set S, then it is ε-acceptable w.r.t.
S with ε = Tg
Ω. Suppose that A is η-acceptable w.r.t. a set S but A is
not ε-acceptable w.r.t. a set S. Then, there exists a hashtagged argument
B ∈Args such that B attacks A and there is no hashtagged argument
C ∈Args such that C attacks B verifying that C is a defender of A. That is,
d(C, A) > ε. However, A is η-acceptable w.r.t. S. Thus, for every attacker
hashtagged argument B ∈S there exists a defender C ∈S such that C ∈NεA
A
where the radius of NεA
A is lower or equal than ε. Contradiction.
iii) If a set S is ε-admissible with ε = Ts
Ω, then it is η-admissible. Suppose
that S is ε-admissible but it is not an η-admissible set. Then, there exists
an hashtagged argument A ∈Args such that A is not η-acceptable w.r.t.
S. However, S is ε-admissible; then, every hashtagged argument in S is ε-
acceptablew.r.t. S. Furthermore, as a consequence of i), if a hashtagged
argument A ∈Args is ε-acceptable w.r.t. a set S then it is η-acceptable
w.r.t. S. Contradiction.
iv) If a set S is η-admissible then it is ε-admissible with ε = Tg
Ω. Suppose
that S is η-admissible but it is not an ε-admissible set. Then, there exists
a hashtagged argument A ∈Args such that A is not ε-acceptable w.r.t.
S. However, S is η-admissible; thus, every hashtagged argument in S is
η-acceptablew.r.t. S. Furthermore, by consequence of i) if a hashtagged
argument A ∈Args is η-acceptable w.r.t. a set S then it is ε-acceptable
w.r.t. S. Contradiction.
⊓⊔
As usual in abstract argumentation, Deﬁnition 11 leads to diﬀerent notions
providing a new proximity-based interpretation of classical admissibility. In this
version, we propose an analysis more reﬁned considering the admitted interaction
ﬁeld associated with the hashtagged arguments. This new notion allows the
analysis of the argumentation process from a new point of view, where the scope
associated with the hashtagged arguments is taken into account.
Deﬁnition 12. Given Ω = ⟨Φ, GΩ, dΩ⟩, where dΩ(·, ·) is a distance function
over the set Args, and let (Args, dΩ) be the metric space associated with the
tagged framework Ω; let S ⊆Args. Then:
– An η-admissible set S is an η-complete extension iﬀS contains each argument
that is η-acceptable with respect to S.
– Set S is the η-grounded extension of Ω iﬀS is an ⊆-minimal η-complete
extension.
– Set S is an η-preferred extension of Ω iﬀS is an ⊆-maximal η-complete
extension.
Next, we present an example to make clear these novel acceptability concepts.
Example 2. Continuing with the hashtagged argumentation framework pre-
sented in Example 1, and based on the neighborhoods associated with each
argument under the diameter dimension presented in Fig. 5, we have that: I is a
defender of B since I is a neighbor of B (the distance between I and B is 4, where

Focusing the Argumentative Process
33
Fig. 5. Balls and neighborhoods
B has a neighborhood range of 4). Furthermore, B is a defender of J since the
distance between J and B is 5 and J has a neighborhood range of 6. Thus, B is
a neighbor of J. On the other hand, C is not a defender of F since the distance
between C and F is 3, while F has a neighborhood range of 2. However, K is a
defender of F since K is a neighbor of F (the distance between K and F is 2, where
F has a neighborhood range of 2). Thus, analyzing the acceptability notions pre-
sented in Deﬁnition 11, the sets S1 = {I, B, C, K, F, J, G}, S2 = {I, B, K, F, J, G},
S3 = {I, B, C, G}, and S4 = {I, B, D, G}, and S5 = {I, B, G} are the maximal
η-admissible extensions. Furthermore, S5 is the η-grounded extension while S5 is
the η-preferred extension, under the conditions established in Deﬁnition 12.
Note that admissibility discards argument defenders who do not belong to the
neighborhood associated with the attacked argument in this proximity semantic
version. If the argument has associated topics covering a particular thematic
ﬁeld, it will be defended by those arguments that are related to the same ﬁeld.
On the other hand, an opinion cannot be defended by formulations or assertions
out of its spectrum of discussion.
As expected, if the smallest neighborhood is big enough, Dung’s admissibility
and η-admissibility coincide. Thus, the following connection will exist between
the classical and the proximity-acceptable sets of arguments.
Proposition 3. Given Ω = ⟨Φ, GΩ, dΩ⟩, where dΩ(·, ·) is a distance function on
the set Args, and let (Args, dΩ) be the metric space associated with the tagged
framework Ω. If the smallest neighborhood Ts
Ω ≥diameter(H) then it holds that
every η-{admissible, complete, grounded, preferred} extension is an {admissible,
complete, grounded, preferred} extension respectively.

34
M. G. Esca˜nuela Gonzalez et al.
Proﬀ: For the acceptability-based semantics, it is suﬃcient to prove that the
hashtagged defenders arguments in Ω are also present as defenders in the
underlying abstract argumentation framework, for the η-admissible, complete,
grounded, preferred extension. Suppose that an argument A is defended by
an argument C from the attacks of B in the underlying abstract argumenta-
tion framework, but the counterpart hashtagged argument A is not defended
in Ω by the hashtagged version of C. This means that, by Deﬁnition 11,
dΩ(A, C) ∈NεA
A (†). However, the radius associated with the smallest neighbor-
hood Ts
Ω ≥diameter(H) where diameter(H) is the maximum eccentricity of the
hashtags in H. Nevertheless, the relation (†) is not possible since diameter(H)
is the maximum of the distances to all other hashtags in H. Contradiction.
⊓⊔
In abstract argumentation, a grounded extension is the skeptical position of
acceptance, and it is unique. In our deﬁnition of proximity-based semantics, the
notion of defense is bounded to a threshold associated with each hashtagged
argument through their corresponding neighborhood. Thus, the skeptical posi-
tion is related to the set of neighborhoods associated with the metric space, and
diﬀerent sets of neighborhoods lead to diﬀerent η-grounded extensions; however,
as in classical frameworks, the extension always exists.
Proposition 4. Given Ω = ⟨Φ, GΩ, dΩ⟩, where dΩ(·, ·) is a distance function on
the set Args, and let (Args, dΩ) be the metric space associated with the tagged
framework Ω. Then, there always exists an unique η-grounded extension.
Proﬀ: In abstract argumentation the grounded extension is unique. Suppose
there were two diﬀerent sets S y S′ that are both η-grounded extensions, and
suppose A ∈S, but A ̸∈S′. This means that A is not defended in S′. Since it is
defended in S, then it must be because at least one defender C is not taken into
account in S′ due to a speciﬁc distance over the argumentation framework, and
a particular position over the neighborhoods. But this cannot be so since S′ is
also η-grounded extension, i.e., the neighborhoods deﬁned in the framework are
the same.
⊓⊔
As we said before, hashtagged argumentation frameworks are an extension
of abstract frameworks in the sense that we are considering additional elements;
thus, if hashtags information is discarded, a classical abstract framework remains.
The new proximity-based and the classical abstract semantics are related as the
following theorem establishes by showing a link between this redeﬁned proximity-
based semantics and its corresponding abstract semantics counterpart, observing
that the former is a reﬁnement of the latter.
Theorem 1. Given Ω = ⟨Φ, GΩ, dΩ⟩, where dΩ(·, ·) is a distance function on
the set Args, and let (Args, dΩ) be the metric space associated with the tagged
framework Ω. Then: i) If SΩ is η-complete extension in Ω, then there exist a
complete extension SΦ in Φ satisfying that SΩ ⊆SΦ; ii) If SΩ is η-grounded
extension in Ω, then there exist a grounded extension SΦ in Φ satisfying that
SΩ ⊆SΦ; and, iii) If SΩ is η-preferred extension in Ω, then there exist a preferred
extension SΦ in Φ satisfying that SΩ ⊆SΦ.

Focusing the Argumentative Process
35
Proﬀ: We separate the proof in three points:
i) If SΩ is η-complete extension in Ω, then there exist a complete extension
SΦ in Φ satisfying that SΩ ⊆SΦ. Suppose that SΩ is η-complete extension
in Ω, but there is no complete extension SΦ in Φ satisfying that SΩ ⊆
SΦ. Thus, there exists an η-complete extension SΩ in Ω and a complete
extension SΦ in Φ satisfying that SΩ ⊃SΦ. Then, there exists the hashtagged
argument A which is η-acceptable w.r.t. the η-admissible extension SΩ but
the underlying argument (no hashtags) A is not acceptable w.r.t.S. Thus,
A is defended by SΩ but it is not defended by S in the underlying abstract
argumentation framework. However, by Proposition 1, if A ∈Args is η-
acceptable w.r.t. a set S then it is acceptable w.r.t.S, and if a set S is
η-admissible then S is admissible. Contradiction.
ii) If SΩ is η-grounded extension in Ω, then there exist a grounded extension
SΦ in Φ satisfying that SΩ ⊆SΦ. Trivially, since because of i) if SΩ is η-
complete extension in Ω, there exist a complete extension SΦ in Φ satisfying
that SΩ ⊆SΦ. Thus, the proof of this point is a special case where SΩ is
the minimal η-complete extension in Ω and SΦ is the minimal complete
extension in Φ.
iii) If SΩ is η-preferred extension in Ω, then there exist a preferred extension
SΦ in Φ satisfying that SΩ ⊆SΦ. Trivially, since because of i) if SΩ is η-
complete extension in Ω, there exist a complete extension SΦ in Φ satisfying
that SΩ ⊆SΦ. Thus, the proof of this point is a special case where SΩ is a
maximal η-complete extension in Ω and SΦ is a maximal complete extension
in Φ where the inclusion condition is satisﬁed.
⊓⊔
Thus, the rationale of classic argumentation semantics is preserved. The addi-
tion of the concept neighborhood improves the argumentation model by intro-
ducing a new view on valid defenses for an individual argument; this idea is
compelling because it leads to a new family of semantics, possibly parameterized
with various metrics. Note that the notion of the neighborhood can be deﬁned
by considering diﬀerent metrics associated with the hashcloud. Thus, diﬀerent
conceptualizations of the notion of neighborhood clearly inﬂuence the general
outcome of the argumentation scenario. The relation of proximity between argu-
ments is now relevant for the argumentation process.
Finally, considering the intuitions presented before, the following result estab-
lishes a connection between the proximity-based semantics, the proximity-based
semantics based on the deﬁnition of neighborhood, and classical argumentation
semantics.
Theorem 2. Given Ω = ⟨Φ, GΩ, dΩ⟩, where dΩ(·, ·) is a distance function on
the set Args, let (Args, dΩ) be the metric space associated with the tagged frame-
work Ω, and Φ = ⟨Args, Attacks⟩be the underlying abstract argumentation
framework. Then:
i) If ε = Ts
Ω is the threshold associated with the smallest neighborhood of Ω, Sη
Ω
is η-complete (η-grounded, and η-preferred) extension respectively and Sε
Ω is

36
M. G. Esca˜nuela Gonzalez et al.
ε-complete (ε-grounded, and ε-preferred) extension respectively, then it holds
that Sε
Ω ⊆Sη
Ω.
ii) If ε = Tg
Ω is the threshold associated with the greatest neighborhood of Ω, Sη
Ω
is η-complete (η-grounded, and η-preferred) extension respectively and Sε
Ω is
ε-complete (ε-grounded, and ε-preferred) extension respectively, then it holds
that Sη
Ω ⊆Sε
Ω.
Proﬀ: We separate the proof in two parts, each one further divided in three
items:
i) a) If ε = Ts
Ω is the threshold associated with the smallest neighborhood of Ω,
Sη
Ω is η-complete extension and Sε
Ω is ε-complete extension, then it holds
that Sε
Ω ⊆Sη
Ω. Suppose that Sε
Ω ⊃Sη
Ω. Then, there exists an hashtagged
argument A which is τ-acceptable w.r.t. the τ-admissible extension Sε
Ω
but A is not η-acceptable w.r.t. Sη
Ω. Thus, A is defended by Sε
Ω but it is not
defended by Sη
Ω. However, by Proposition 2, if A ∈Args is ε-acceptable
w.r.t. a set Sε
Ω with ε = Ts
Ω, then it is η-acceptable, and if a set Sε
Ω is
τ-admissible then it is η-admissible. Contradiction.
b) If ε = Ts
Ω is the threshold associated with the smallest neighborhood of
Ω, Sη
Ω is η-grounded extension and Sε
Ω is ε-grounded extension, then it
holds that Sε
Ω ⊆Sη
Ω. Trivially, since by a) if Sη
Ω is η-complete extension
and Sε
Ω is ε-complete extension, then it holds that Sε
Ω ⊆Sη
Ω. Thus, the
proof of this point is a special case where Sε
Ω is the minimal τ-complete
extension in Ω and Sη
Ω is the minimal η -complete extension in Ω.
c) If ε = Ts
Ω is the threshold associated with the smallest neighborhood of
Ω, Sη
Ω is η-grounded extension and Sε
Ω is ε-grounded extension, then it
holds that Sε
Ω ⊆Sη
Ω. Trivially, since by a) if Sη
Ω is η-preferred extension
and Sε
Ω is ε-preferred extension, then it holds that Sε
Ω ⊆Sη
Ω. Thus, the
proof of this point is a special case where Sε
Ω is the maximal τ-complete
extension in Ω and Sη
Ω is the maximal η -complete extension in Ω.
ii) a) Let ε = Tg
Ω be the threshold associated with the greatest neighborhood
of Ω, Sη
Ω is η-complete extension and Sε
Ω is ε-complete extension, then it
holds Sη
Ω ⊆Sε
Ω. Suppose that Sη
Ω ⊃Sε
Ω. Then, there exists a hashtagged
argument A which is η-acceptable w.r.t. the η-admissible extension Sη
Ω but
A is not τ-acceptable w.r.t. Sτ
Ω. Thus, A is defended by Sη
Ω but it is not
defended by Sε
Ω. However, by Proposition 2, if A ∈Args is η-acceptable
w.r.t. a set Sη
Ω, then it is ε-acceptable, and if a set Sη
Ω is η-admissible then
it is ε-admissible. Contradiction.
b) If ε = Tg
Ω is the threshold associated with the smallest neighborhood of
Ω, Sη
Ω is η-grounded extension and Sε
Ω is ε-grounded extension, then it
holds that Sη
Ω ⊆Sτ
Ω. Trivially, since by a) if Sη
Ω is η-complete extension
and Sε
Ω is ε-complete extension, then it holds that Sη
Ω ⊆Sτ
Ω. Thus, the
proof of this point is a special case where Sη
Ω is the minimal η-complete
extension in Ω and Sε
Ω is the minimal ε -complete extension in Ω.
c) If ε = Tg
Ω is the threshold associated with the smallest neighborhood of
Ω, Sη
Ω is η-grounded extension and Sε
Ω is ε-grounded extension, then it

Focusing the Argumentative Process
37
holds that Sη
Ω ⊆Sε
Ω. Trivially, since by a) if Sη
Ω is η-preferred extension
and Sε
Ω is ε-preferred extension, then it holds that Sε
Ω ⊆Sη
Ω. Thus, the
proof of this point is a special case where Sη
Ω is the maximal η-complete
extension in Ω and Sε
Ω is the maximal ε-complete extension in Ω.
⊓⊔
As we postulated in the original proximity-based semantic, under this new
interpretation of “defense”, where we consider an admitted defense ﬁeld asso-
ciated with each argument, a potential defender argument maybe not be con-
sidered as such; however, the classical notion of admissibility is preserved. Note
that, in this work, we have only analyzed the defense relation in the context of
the neighborhood associated with an argument. However, this concept can be
extended to the notion of attack, which we will discuss in future work. The reason
for this decision is to stay within the spectrum of solutions originally proposed
in abstract frameworks, intending to reﬁne them. Considering the distance in
the case of the attack relation and dismissing some of these attacks introduces
a change in the argumentative process, obtaining other solutions that may be
entirely diﬀerent from the original ones. Another issue to avoid is: How can we
improve the set of acceptable arguments considering the hashtags cloud repre-
senting the map of issues concerning a speciﬁc domain? In this sense, we can
use the centrality and peripheral relations over this set of accepted arguments
to prefer the more relevant arguments over the less relevant ones.
5
Related Work and Conclusions
In the context of classical abstract argumentation frameworks, there have been
several proposals where other elements are added to the theoretical, abstract
representational structure extending the possibility of representing more charac-
teristics of the application domain. There exist approaches that provide mech-
anisms for discriminating attacks, making some of those attacks irrelevant and
ignored under speciﬁc semantics. In particular, understanding how an attack
comes into play has been the focus of a few works.
In [14], A. Hunter addresses the idea that attacks might have attached to
them some uncertainty about whether these attacks hold, i.e., some attacks
might be believed, some might be disbelieved, and some might be unknown.
The source of the uncertainty might be found in doubts that an attack holds or
because of perceived imprecision in the way arguments are expressed. The author
discusses three possible sources of uncertainty occurring in argumentation that
can be addressed by quantifying the probability of attack: Explicit uncertainty of
attack, Implicit imprecision of argument, and Incompleteness in the set premises
or the claims made by the arguments. To investigate how the attachment of prob-
ability to attacks inﬂuences the semantic analysis in the abstract framework, the
author considers a probability distribution over the spanning subgraphs of an
argumentation graph. From this distribution, the probability that a set of argu-
ments be admissible or included in an extension can be determined. Therefore,
adding probabilities to attacks in abstract argumentation frameworks leads to a

38
M. G. Esca˜nuela Gonzalez et al.
formalism where attacks might or might not be a part of the semantic analysis
choosing a direction that diﬀers from our approach.
Another proposal for making the possible consideration of attacks as eﬀec-
tive something to be pondered, D. Kontarinis et al. in [15] advances an idea in
the context of modeling online multi-agent debates involving multi-party argu-
mentation. The introduction of agents in a debate with expertise on speciﬁc
areas opens an interesting perspective: when a debate is deemed unresolved in
a “controversial” manner, calling an additional expert may be a natural way to
help make a decision. The expert then can analyze the situation from a more
informed point of view and introduce a resolution. The authors analyze diﬀerent
application domains, such as constructing interactive forums on the Web, like
DebateGraph [9]. In these systems, arguments can be represented, the attack
relation deﬁned, and additional information added. On the other hand, other
proposals (for instance, the Parmenides [8] system and IMPACT [2]) include
reasoning machinery, usually from argumentation theory, which provides a for-
mal way to decide on the acceptability of the arguments represented. However,
the conﬂicting relation between arguments presented in the debate has diﬀerent
importance levels according to the experts’ votes. Note that these experts’ famil-
iarity with the point of contention varies according to the perceived topics tied
to each argument; thus, the inﬂuence of an expert to judge an attack relation is
not global but depends on the topics under discussion.
We have oﬀered a formalization of an abstract argumentation framework
that considers a set of interrelated topics that decorate the arguments in the
framework. These topics are there to reﬂect what the arguments are addressing
and provide a supporting structure for the analysis of multi-topic argumenta-
tion; one of the contributions is examining new argumentation semantics that
consider these topics to obtain the accepted arguments. Topics are related to
each other, conﬁguring a graph structure representing that relationship; fur-
thermore, from the graph, a notion of distance between topics is introduced
naturally, which is used to study proximity-based semantics. The central aspect
of these argumentation semantics is the initial idea that an argument should be
defended by closely related arguments linked to the addressed topics. We explore
this position by deﬁning new elements such as neighborhood-bounded admissi-
ble sets. The relation between these new formalizations, the previous version
of proximity-based admissibility, and the classical admissibility semantics has
been analyzed. The addition of topics to abstract argumentation as a focusing
device suggests several directions for future work; for instance, the role of central
and peripheral arguments, in a similar sense as central and peripheral nodes in
a graph or apply information retrieval concepts to establish the importance of
arguments according to its own set of hashtags in a given hashcloud.
References
1. Bench-Capon, T.J.M.: Value-based argumentation frameworks. In: Benferhat, S.,
Giunchiglia, E. (eds.) Proceedings of NMR, pp. 443–454 (2002)

Focusing the Argumentative Process
39
2. Benn, N., Macintosh, A.: Argument visualization for eParticipation: towards a
research agenda and prototype tool. In: Tambouris, E., Macintosh, A., de Bruijn,
H. (eds.) ePart 2011. LNCS, vol. 6847, pp. 60–73. Springer, Heidelberg (2011).
https://doi.org/10.1007/978-3-642-23333-3 6
3. Buckley, F., Harary, F.: Distance in graphs. Addison-Wesley Publishing Company
Advanced Book Program, Redwood (1990)
4. Bud´an, M.C., Cobo, M.L., Martinez, D.C., Simari, G.R.: Bipolarity in temporal
argumentation frameworks. Int. J. Approx. Reason. 84, 1–22 (2017)
5. Bud´an, M.C., Cobo, M.L., Martinez, D.C., Simari, G.R.: Proximity semantics for
topic-based abstract argumentation. Inf. Sci. 508, 135–153 (2020)
6. Bud´an, M.C., Lucero, M.G., Ches˜nevar, C., Simari, G.R.: Modeling time and val-
uation in structured argumentation frameworks. Inf. Sci. 290, 22–44 (2015)
7. Bud´an, P.D., Esca˜nuela Gonzalez, M.G., Bud´an, M.C.D., Martinez, M.V., Simari,
G.R.: Similarity notions in bipolar abstract argumentation. Argument Comput.
11(1–2), 103–149 (2020)
8. Cartwright, D., Atkinson, K.: Using computational argumentation to support e-
participation. IEEE Intell. Syst. 24(5), 42–52 (2009)
9. DebateGraph. https://www.debategraph.org/
10. Deza, M.M., Deza, E.: Encyclopedia of Distances, 2nd edn. Springer, Heidelberg
(2013). https://doi.org/10.1007/978-3-642-30958-8
11. Dung, P.M.: On the acceptability of arguments and its fundamental role in non-
monotonic reasoning and logic programming and n-person games. Artif. Intell. 77,
321–357 (1995)
12. Foucault, M., Smith, A., Sheridan, A.: The Archaeology of Knowledge; And. The
Discourse on Language. Pantheon Books, Pantheon Books (1972)
13. Goddard, W., Oellermann, O.R.: Distance in graphs. In: Dehmer, M. (ed.) Struc-
tural Analysis of Complex Networks, chap. 3, pp. 49–72. Birkh¨auser Basel (2011)
14. Hunter, A.: Probabilistic qualiﬁcation of attack in abstract argumentation. Int. J.
Approx. Reason. 55(2), 607–638 (2014)
15. Kontarinis, D., Bonzon, E., Maudet, N., Moraitis, P.: Picking the right expert to
make a debate uncontroversial. In: Verheij, B., Szeider, S., Woltran, S. (eds.) Com-
putational Models of Argument - Proceedings of COMMA 2012, Austria. Frontiers
in Artiﬁcial Intelligence and Applications, vol. 245, pp. 486–497. IOS Press (2012)
16. Leite, J., Martins, J.G.: Social abstract argumentation. In: Walsh, T. (ed.) IJCAI
2011, Proceedings of the 22nd International Joint Conference on Artiﬁcial Intelli-
gence, Barcelona, pp. 2287–2292. IJCAI/AAAI (2011)
17. Visser, W., Hindriks, K.V., Jonker, C.M.: An argumentation framework for qual-
itative multi-criteria preferences. In: Modgil, S., Oren, N., Toni, F. (eds.) TAFA
2011. LNCS (LNAI), vol. 7132, pp. 85–98. Springer, Heidelberg (2012). https://
doi.org/10.1007/978-3-642-29184-5 6

Burdens of Persuasion and Standards
of Proof in Structured Argumentation
Roberta Calegari1 and Giovanni Sartor1,2(B)
1 CIRFID-Alma AI, University of Bologna, Bologna, Italy
{roberta.calegari,giovanni.sartor}@unibo.it
2 European University Institute of Florence, Fiesole, Italy
Abstract. In this paper we provide an account of the burden of persua-
sion, in the context of structured argumentation. First, burdens of proof
in legal proceedings are discussed in general, distinguishing the burdens
of production and the burdens of persuasion. Then, we focus on burdens
of persuasion, illustrating their role in civil and criminal law.
A formal model for the burden of persuasion is then deﬁned, discussed,
and used to capture the role of the burden of persuasion in adjudicating
conﬂicts between conﬂicting arguments and in determining the dialectical
status of arguments. We consider how our model can also capture adver-
sarial burdens of proof, namely, those cases in which failure to establish
an argument for a proposition burdened with persuasion entails estab-
lishing the complementary proposition.
Finally, we examine how burdens of proofs can be integrated with
standards of proof deﬁning the extent to which an argument for a propo-
sition burdened with persuasion has to be stronger than arguments to
the contrary, in order to meet the burden.
Keywords: Burden of persuasion · Argumentation · Legal reasoning ·
Standard of proof
1
Introduction
The burden of proof is a central feature of many dialectical contexts. It is partic-
ularly relevant in those domains, such as legal disputations or political debates,
in which controversial issues are discussed in order to adopt a decision (see [23]
on burdens of proof in diﬀerent dialogue types).
Generally speaking, we can say that burdens of proof distribute dialectical
responsibilities between the parties in a dialogue. In other words, when a party
has a burden of proof of a certain type relative to a claim φ, then, unless the
party provides the kinds of arguments or evidence that is required by that type
of burden, the party will lose on the claim. Losing on the burdened claim means
R. Calegari and G. Sartor have been supported by the H2020 ERC Project “Compu-
Law” (G.A. 833647).
c
⃝Springer Nature Switzerland AG 2021
P. Baroni et al. (Eds.): CLAR 2021, LNAI 13040, pp. 40–59, 2021.
https://doi.org/10.1007/978-3-030-89391-0_3

Burdens of Persuasion and Standards of Proof in Structured Argumentation
41
that, for the purpose of the dialectic interaction at stake, it will be assumed that
the claim has not been established, not even as a relevant possibility.
Burdens of proof complement the analysis of dialectical frameworks that
are provided by argumentation systems. In particular, they are important in
adversarial contexts: they facilitate the process of reaching a single outcome in
contexts of doubt and lack of information. This is obtained, we shall argue, by
ruling out (considering as unacceptable) those arguments which fail to meet any
applicable burden.
Research in AI & law has devoted a number of contributions to the formal
analysis of burdens of proof: models of defeasible legal reasoning have been crit-
icised for not taking burdens of proof into account [11], the distinction between
diﬀerent standards of proof has been addressed [5], formal accounts of burdens
of proof have been developed within models for formal argumentation [2,8,19].
However, it seems to us that a comprehensive model of burdens of proof in legal
reasoning is still missing.
In the legal domain, two types of burdens can be distinguished: the burden of
production (also called burden of providing evidence, or ‘evidential’ burden), and
the burden of persuasion [19]. This terminology is used in common law systems
[24], but the distinction is also recognised in civil law jurisdiction, possibly using
a diﬀerent terms [10]. The focus of this paper is on the burden of persuasion.
We will show how an allocation of the burden of persuasion may induce single
outcomes in contexts in which the assessment of conﬂicting arguments would,
without such an allocation, remain undecided.
Our model builds upon the approach introduced in Prakken and Sartor
[9,19,20], i.e., upon the view that burdens of persuasion complement argument
priorities in deciding conﬂicts between arguments raising incompatible claims:
unless priorities provide for a diﬀerent outcome, the argument for a claim bur-
dened with persuasion loses. This approach, however, does not address the cases
in which the burden of persuasion concerns the conclusion of a multistep argu-
ment, which is subject to undecided challenges against earlier inference steps.
We shall argue that in such cases too, the burdened argument has to be rejected:
uncertainty upon non-ﬁnal steps also entails failing to be persuasive.
The idea is related to the Carneades’ approach [7,8], according to which the
dialectical status of an argument determines whether a burden of persuasion
is satisﬁed. This approach uses diﬀerent types of premises (ordinary premises,
assumptions, and exceptions) and information about the dialectical status of
statements (stated, questioned, accepted, or rejected) to allocate burdens of
proof and assess whether they have been met.
Hence our analysis combines Prakken and Sartor’s [17,19] model with the
insight from Carneades’ [7], and takes into account the fact that the persua-
siveness of an argument, in a dialectical context, is determined not only by the
internal strength of the argument, as resulting from the strength of the inference
rules used for building the argument (according, for instance, to the last link
criterion), but also by the applicable counterarguments.
Our model originates from legal considerations and is applied to legal exam-
ples. However, the issue of the burden of proof has a signiﬁcance that goes

42
R. Calegari and G. Sartor
beyond the legal domain. It also concerns other domains – such as public dis-
course, risk management, etc. – in which evidence and arguments are needed,
and corresponding responsibilities are allocated, according to types of dialogues
and dialectical or organisational roles [22,23].
The novelty of this contribution consists of a new deﬁnition of defeat relations
involving arguments burdened with persuasion, a corresponding deﬁnition of
the criteria for labelling such argument, and a formalisation of the concept of
standards of proof.
2
Burdens of Production and Burdens of Persuasion
Following the account in Prakken and Sartor [19], we distinguish the burden of
production from the burden of persuasion. A party burdened with production
needs to provide some support for the claim he or she is advancing. More exactly,
we can say that the party has the burden of production for φ if the following
is the case: unless relevant support for φ is provided – i.e., unless an argument
for φ is presented that deserves to be taken into consideration – then φ will not
be established (even in the absence of arguments against φ). When knowledge is
represented through a set of rules and exceptions, the party interested in estab-
lishing the conclusion of a rule usually has the burden of production relative to
the elements in the rule’s antecedent, while the other party (who is interested in
preventing the derivation of the rule’s consequent) has the burden of production
relative to the exceptions to the rule (as provided in a separate exception clause
or in an unless-exception within the rule).
Meeting the burden of production for a claim φ is only a necessary condition,
and not a suﬃcient one, for establishing φ, since the produced arguments may
be defeated by counterarguments. This aspect is addressed by the burden of per-
suasion: the party looking to establish a claim burdened with persuasion needs
to provide a ‘convincing’ argument for it—that is, an argument that prevails
over arguments to the contrary to an extent that is determined by the applica-
ble standard of proof. If there is a burden of persuasion on a proposition φ, and
all arguments for φ fail to prevail over their counterarguments, then the party
concerned will lose on φ.
Let us illustrate the way in which the burden of persuasion works through
two examples, one from criminal law and one from civil law.
Burden of Persuasion in Criminal Law. In criminal law, the burden of pro-
duction is distributed between prosecution and defence, while the burden of
persuasion (in most legal systems) is always on prosecution. More exactly, in
criminal law, the burden of production falls on the prosecution relative to the
two constitutive elements of crime, namely, the criminal act (actus reus) and
the required mental state (mens rea, be it intention/recklessness or negligence),
while it falls to the defendant relative to justiﬁcations or exculpatory defences
(e.g., self-defence, state of necessity, etc.). In other words, if both actus reus and
mens rea are established, but no exculpatory evidence is provided, the decision

Burdens of Persuasion and Standards of Proof in Structured Argumentation
43
should be a criminal conviction. On the other hand, the burden of persuasion
falls on the prosecution for all determinants of criminal responsibility, including
not only for the constitutive elements of a crime but also for the absence of
justiﬁcations or exculpatory defences.
Example 1 (Criminal law example). Let us consider a case in which a woman,
Hellen, has shot and killed an intruder in her home. The applicable law consists
of (a) the rule according to which intentional killing constitutes murder, and (b)
the exception according to which there is no murder if the victim was killed in
self-defence. Assume that it has been established with certainty that Hellen shot
the intruder and that she did so intentionally. However, it remains uncertain
whether the intruder was threatening Hellen with a gun, as claimed by the
defence, or had turned back and was running away on having been discovered, as
claimed by prosecution. The burden of persuasion is on prosecution, who needs
to provide a convincing argument for murder. Since, in this case, it remains
uncertain whether there was self-defence, prosecution has failed to provide such
an argument. Therefore, the legally correct solution is that there should be no
conviction: Hellen needs to be acquitted.
Burden of Persuasion in Civil Law. In civil law, burdens of production and bur-
dens of persuasion may be allocated in diﬀerent ways. The general principle is
that the plaintiﬀonly has the burden of proof (both of production and persua-
sion) relatively to the operative facts that ground its claim, while the defendant
has the burden of proof relative to those exceptions which may prevent the opera-
tive facts from delivering their usual outcomes, such as justiﬁcations with regard
to torts, or incapability and vices of consent in contracts. However, derogations
from this principle may be established by the law, in order to take into account
various factors, such as the presumed ability of each party to provide evidence
in favour of his or her claim, the need to protect weaker parties against abuses,
etc.
In matters of civil liability, for example, it is usually the case that the plaintiﬀ,
who asks for compensation, has to prove both that the defendant caused him
harm, and that this was done intentionally or negligently. However, in certain
cases, the law establishes an inversion of the burden of proof for negligence (both
the burden of production and the burden of persuasion). This means that in order
to obtain compensation, the plaintiﬀonly has to prove that he was harmed by the
defendant. This will be suﬃcient to win the case unless the defendant provides
a convincing argument that she was diligent (not negligent).
Example 2 (Civil law example). Let us consider a case in which a doctor caused
harm to a patient by misdiagnosing his case. Assume that there is no doubt that
the doctor harmed the patient: she failed to diagnose cancer, which consequently
spread and became incurable. However, it is uncertain whether or not the doctor
followed the guidelines governing this case: it is unclear whether she prescribed all
the tests that were required by the guidelines, or whether she failed to prescribe
some tests that would have enabled cancer to be detected. Assume that, under
the applicable law, doctors are liable for any harm suﬀered by their patients,

44
R. Calegari and G. Sartor
but they can avoid liability if they show that they were diligent (not negligent)
in treating the patient, i.e., that they exercised due care. Thus, rather than the
patients having the burden of proving that doctors have been negligent (as it
should be the case according to the general principles), doctors have the burden
of proving their diligence. Let us assume that the law also says that doctors are
considered to be diligent if they followed the applicable medical guidelines. In
this case, given that the doctor has the burden of persuasion on her diligence,
and that she failed to provide a convincing argument for it, the legally correct
solution is that she should be ordered to compensate the patient.
These two examples share a common feature. In both, uncertainty remains
concerning a decisive issue, namely, the existence of self-defence in the ﬁrst exam-
ple and the doctor’s diligence in the second. However, this uncertainty does not
preclude the law from prescribing a single legal outcome in each case. This out-
come can be achieved by discarding the arguments that fail to meet the required
burden of persuasion, i.e., the prosecution’s argument for murder and the doc-
tor’s argument for her diligence, respectively.
3
Argumentation Framework
We introduce a structured argumentation framework relying on a lightweight
ASPIC+-like argumentation system [14]. For the sake of simplicity, we assume
that arguments only consist of defeasible rules, to the exclusion of strict
rules, and of some constituents of a knowledge base—such as axioms, ordinary
premises, assumptions, and issues—that can be found in the complete model
[14]. A framework based on defeasible rules is suﬃcient for our purposes and
can be extended as needed with further structures. In this section, we introduce
arguments, preferences, and defeat relations.
3.1
Defeasible Theories
As usual, by a literal we mean an atomic proposition or its negation.
Notation 31. For any literal φ, its complement is denoted by ¯φ. That is, if φ
is atom p, then ¯φ = ¬p, while if φ is ¬p, then ¯φ is p.
Literals are brought into relation through defeasible rules.
Deﬁnition 1 (Defeasible rule). A defeasible rule r has the form: ρ :
φ1, ..., φn, ∼φ′
1, ..., ∼φ′
m ⇒ψ with 0 ≤n and 0 ≤m, and where
– ρ, an atom, is the unique identiﬁer for r, denoted by N(r);
– each φ1, . . . φn, φ′
1, ..., φ′
m, ψ is a literal;
– φ1, . . . φn, ∼
φ′
1, ..., ∼
φ′
m
are
denoted
by
Antecedent(r)
and
ψ
by
Consequent(r);
– ∼φ denotes the weak negation (negation by failure) of φ: φ is an exception
that would block the application of the rule whose antecedent includes ∼φ.

Burdens of Persuasion and Standards of Proof in Structured Argumentation
45
The name of a rule can be used to specify that the named rule is applicable, and
its negation correspondingly to specify that the rule is inapplicable [13].
A superiority relation ≻is deﬁned over rules: s ≻r states that rule s prevails
over rule r.
Deﬁnition 2 (Superiority relation). A superiority relation ≻over a set
of rules Rules is an antireﬂexive and antisymmetric binary relation, i.e., ≻⊆
Rules × Rules.
A defeasible theory consists of a set of rules and a superiority relation over
the rules.
Deﬁnition 3 (Defeasible theory). A defeasible theory is a tuple ⟨Rules, ≻⟩
where Rules is a set of rules, and ≻is a superiority relation over Rules.
Given a defeasible theory, by chaining rules from the theory we can construct
arguments, as speciﬁed in the following deﬁnition; cf. [3,13,21].
Deﬁnition 4 (Argument). An argument constructed from a defeasible theory
⟨Rules, ≻⟩is a ﬁnite construct of the form: A : A1, . . . An ⇒r φ with 0 ≤n,
where
– A is the argument’s unique identiﬁer;
– A1, . . . , An are arguments constructed from the defeasible theory ⟨Rules, ≻⟩;
– φ is the conclusion of the argument, denoted by Conc(A);
– r : Conc(A1), . . . , Conc(An) ⇒φ is the top rule of A, denoted by TopRule(A).
Notation 32. Given an argument A : A1, . . . An ⇒r φ as in Deﬁnition 4,
Sub(A) denotes the set of subarguments of A, i.e., Sub(A) = Sub(A1) ∪
. . .∪Sub(An)∪{A}. DirectSub(A) denotes the direct subarguments of A, i.e.,
DirectSub(A) = {A1, . . . , An}.
We assume that preferences over arguments are deﬁned via a last-link ordering:
an argument A is preferred over another argument B if the top rule of A is
stronger than the top rule of B.
Deﬁnition 5 (Preference relation). A preference relation ≻is a binary
relation over a set of arguments A: an argument A is preferred to argument B,
denoted by A ≻B, iﬀTopRule(A) ≻TopRule(B).
3.2
Defeat with Burdens of Persuasion
Let us ﬁrst identify burdens of persuasion, i.e., those literals the proof of which
requires a convincing argument. We assume that such literals are consistent (it
cannot be the case that there is a burden of persuasion both on φ and φ).
Deﬁnition 6 (Burdens of persuasion). Let BurdPers, the set of burdens of
persuasion, be a set of literals such that if φ ∈BurdPers then φ ̸∈BurdPers.
We say that an argument A is burdened with persuasion if Conc(A) ∈BurdPers.

46
R. Calegari and G. Sartor
We now consider possible collisions between arguments, i.e., those cases in
which an argument A challenges an argument B: (a) by contradicting the con-
clusion of a B’ subargument (rebutting), or (b) by denying (the application of)
the top rule of a B’ subargument or by contradicting a weak negation in the
body of the top rule of a B’ subargument (undercutting).
Note that our notion of rebutting corresponds to the notion of successful
rebutting in [14].
Deﬁnition 7 (bp-rebut). Argument A bp-rebuts argument B iﬀ∃B′ ∈
Sub(B) such that Conc(A) = Conc(B′) and
1. Conc(A) ̸∈BurdPers, and B′ ̸≻A, or
2. Conc(A) ∈BurdPers and A ≻B′.
According to Deﬁnition 7.1, for an unburdened argument A to rebut B by con-
tradicting the latter’s subargument B′, it is suﬃcient that B′ is non-superior to
A. According to 7.2 for a burdened argument A to rebut B by contradicting B′,
it is necessary that A is superior to B′. Thus, burdens of persuasion supplement
priorities in deciding conﬂicts between arguments having opposed conclusions.
They dictate the outcome of such conﬂicts when priorities do not already deter-
mine which argument is to prevail: when two arguments contradict one another,
the one burdened with persuasion will fail to bp-rebut the other, while the latter
will succeed in bp-rebutting the ﬁrst.
Undercutting is deﬁned as usual, including both the case in which the attacker
excludes the application of the top rule of the attacked argument (by denying
the rule’s name) and the case in which it contradicts a weakly negated literal in
the body of that rule.
Deﬁnition 8 (bp-undercut). A undercuts B iﬀ∃B′ ∈Sub(B) such that:
1. Conc(A) = ¬N(r) and TopRule(B′) = r; or
2. Conc(A) = φ and ∼φ ∈Antecedent(TopRule(B′))
Finally, we have the notions of bp-defeat and strict bp-defeat that are deﬁned
on the basis of bp-rebutting and undercutting. As you can see from the deﬁnition
below the diﬀerence from the usual notion of defeat pertains to bp-rebuts.
Deﬁnition 9 (bp-defeat)
1. A bp-defeats B iﬀA bp-rebuts B or A undercuts B
2. A strictly-bp-defeats B iﬀA bp-defeats B and B does not bp-defeats A .
3.3
Example
To exemplify the notions just introduced, let us formalise Example 2 through
a set of rules. Note that we assume that evidence is provided to establish the
factual claims at issue, i.e., that the corresponding burdens of production are
satisﬁed (facts e1, e2, e3).

Burdens of Persuasion and Standards of Proof in Structured Argumentation
47
Example 3 (Civil law example: rules and arguments)
e1 : ev1
er1 : ev1 ⇒¬guidelines
e2 : ev2
er2 : ev2 ⇒guidelines
e3 : ev3
er3 : ev3 ⇒harm
r1 : ¬guidelines ⇒¬dueDiligence r2 : guidelines ⇒dueDiligence
r3 : harm, ∼dueDiligence ⇒liable
We can then build the following arguments:
A1 :⇒ev1
A2 :⇒ev2
A3 :⇒ev3
A4 : A1 ⇒¬guidelines
A5 : A2 ⇒guidelines
A6 : A3 ⇒harm
A7 : A4 ⇒¬dueDiligence A8 : A5 ⇒dueDiligence
A9 : A6 ⇒liable
If there were no burden of persuasion the defeat relation would be the fol-
lowing:
– arguments A4 and A5 defeat one another,
– A5 defeats A7,
– A4 defeats A8,
– A7 and A8 defeat one another,
– A8 strictly defeats A9.
If on the contrary, there is burden on the doctors’ diligence (dueDiligence ∈
BurdPers), then A8 fails to defeat A7, so that A7 strictly defeats A8.
4
A Labelling Semantic for Burdens of Persuasion
In this section, we show how arguments are linked through argumentation
graphs. Then, we deﬁne a labelling semantics that takes burdens of persuasion
into account.
4.1
Argumentation Graphs and Bp-Labelling
In an argumentation graph, arguments are connected according to the defeat
relation.
Deﬁnition 10 (Argumentation graph). An argumentation graph con-
structed from a defeasible theory T is a tuple ⟨A, ⇝⟩, where A is the set of
all arguments constructed from T, and ⇝is defeat relation over A.
Notation 41. Given an argumentation graph G = ⟨A, ⇝⟩, we write AG, and
⇝G to denote the graph’s arguments and attacks respectively.
Now, let us introduce the notion of the {IN, OUT, UND}-labelling of an argu-
mentation graph, where each argument in the graph is labelled IN, OUT, or UND,
depending on whether it is accepted, rejected, or undecided, respectively.

48
R. Calegari and G. Sartor
Deﬁnition 11 (Labelling). Let G be an argumentation graph. An {IN, OUT,
UND}-labelling L of G is a total function AG →{IN, OUT, UND}.
Notation 42. Given a labelling L, we write IN(L) for {A|L(A) = IN}, OUT(L)
for {A|L(A) = OUT} and UND(L) for {A|L(A) = UND}.
There are various ways to specify {IN, OUT, UND}-labelling functions [1]. For
example, they can be complete or grounded.
Deﬁnition 12. A complete {IN, OUT, UND}-labelling of an argumentation
graph G is an {IN, OUT, UND}-labelling such that ∀A ∈AG
1. A is labelled IN iﬀall defeaters of A are labelled OUT, and
2. A is labelled OUT iﬀA has a defeater which is labelled IN.
Deﬁnition 13. A grounded {IN, OUT, UND}-labelling of an argumentation
graph G is a complete {IN, OUT, UND}-labelling L of G such that IN(L) is mini-
mal.
Remark that any argument not labelled IN or OUT must be labelled UND, since
any {IN, OUT, UND}-labelling is a total function.
While common speciﬁcations of {IN, OUT, UND}-labellings deﬁne reasonable
positions [1], they do not cater for burdens of persuasion. We now introduce
the notion of bp-labelling, namely, a labelling which takes into account a set of
burdens of persuasion.
Deﬁnition 14 (bp-labelling). A bp-labelling of an argumentation graph G,
relative to a set of burdens of persuasion BurdPers, is an {IN, OUT, UND}-labelling
s.t. ∀A ∈AG with Conc(A) = φ
1. A ∈IN(L) iﬀ∀B ∈AG such that B bp-defeats A : B ∈OUT(L)
2. A ∈OUT(L) iﬀ
(a) φ ∈BurdPers and ∃B ∈AG such that
– B bp-defeats A and
– B ∈IN(L) or B ∈UND(L)
(b) φ ̸∈BurdPers and ∃B ∈AG such that
– B bp-defeats A and
– B ∈IN(L)
3. A ∈UND(L) otherwise.
Burdens of persuasion aﬀect conditions for rejection, as speciﬁed in Deﬁni-
tion 14 (2) (a). The rejection (the OUT labelling) of an argument burdened of
persuasion may be determined by any counterargument B that is accepted (IN)
or also is uncertain (UND). On the contrary, as speciﬁed in 14 (2) (b) the rejec-
tion of an argument that is not burdened with persuasion requires a defeating
counterargument B that is IN.
Note that the semantic just described does not always deliver a single
labelling. Multiple labelling may exist when arguments rebut each other, none

Burdens of Persuasion and Standards of Proof in Structured Argumentation
49
of them being burdened with persuasion. If one of these arguments is labelled IN
the other is labelled OUT and vice versa. To address such a situation, we focus
on IN-minimal labelling, i.e., on the labelling where both such arguments are
labelled UND. Let us call such a labelling a grounded bp-labelling.
Deﬁnition 15 (Grounded bp-labelling). A bp-labelling L of an argumen-
tation graph G is a grounded bp-labelling iﬀUND(L) is maximal.
Proposition 1. If BurdPers = ∅, L1 is the grounded labelling of argumentation
graph G, as deﬁned by [1] and L2 is the grounded bp-labelling of G, then IN(L1) =
IN(L2).
Proof. It is easy to see that if condition 14(1) concerning arguments burdened
with persuasion is removed from Deﬁnition 14, we obtain the deﬁnition of
grounded labelling as characterised in [1].
4.2
Examples
Let us now apply the model just introduced to some legal examples.
Example 4 (Civil law example: graphs and bp-labelling). Let us consider again
the Example 2 and the corresponding rules and arguments built in Example 3.
The argumentation graph and its grounded {IN, OUT, UND}-labelling are depicted
in Fig. 1 (left), in which all arguments are UND except arguments for undisputed
facts.
Fig. 1. Grounded {IN, OUT, UND}-labelling of Example 2 in the absence of burdens of
persuasion (left) and its bp-labelling with BurdPers = {dueDiligence, liable} (right).
The result is not satisfactory according to the law, since it does not take into
account the applicable burdens of persuasion. The doctor should have lost the
case – i.e., be found liable – since she failed to discharge her burden of proving
that she was diligent (non-negligent). The doctor’s failure results from the fact
that it remains uncertain whether she followed the guidelines. To capture this

50
R. Calegari and G. Sartor
aspect of the argument, we need to specify the burdens of persuasion. Let us
assume that (as under Italian law) we have BurdPers = {dueDiligence, liable}
(i.e., the doctor has to provide a convincing argument that she was diligent,
the patient has to provide a convincing argument for the doctor’s liability).
As the burdened doctor’s argument for dueDiligence is OUT, her liability can
be established even though it remains uncertain whether the guidelines were
followed.
□
This example shows how the model here presented allows us to deal with
the inversion of the burden of proof, i.e., a situation in which one argument A is
presented for a claim φ being burdened with persuasion, and A (or a subargument
of it) is attacked by a counterargument B, of which the conclusion ψ is also
burdened with persuasion. If no convincing argument for ψ can be found, then
the attack fails, and the uncertainty on ψ does not aﬀect the status of A. In the
example, the argument for the doctor’s due diligence fails to meet its burden of
persuasion. Consequently, it fails to defeat the argument for the doctor’s liability,
which succeeds, meeting its burden of persuasion.
Example 5 (Criminal law example: rules, graphs and bp-labelling). According to
the description in Example 1, let us consider the following rules (for simplicity’s
sake, we will not specify the evidence here, but we assume that all factual claims
are supported by evidence):
f1: ⇒killed
f2: ⇒intention
f3: ⇒threatWithWeapon
f4: ⇒¬threatWithWeapon
r1: threatWithWeapon ⇒selfDefence
r2: ¬threatWithWeapon ⇒¬selfDefence
r3: selfDefence ⇒¬murder
r4: killed, intention ⇒murder
with r3 ≻r4. We can build the following arguments:
C1 :⇒¬threatWithWeapon C2 : C1 ⇒¬selfDefence
A1 :⇒killed
B1 :⇒threatWithWeapon
A2 :⇒intention
B2 : B1 ⇒selfDefence
A3 : A1, A2 ⇒murder
B3 : B2 ⇒¬murder
In the {IN, OUT, UND}-labelling of Fig. 2 (left), all arguments are UND except for
the undisputed facts. Thus, in the absence of burdens of persuasion, we do not
obtain the legally correct answer, namely, acquittal. To obtain acquittal we need
to introduce burdens of persuasion. Prosecution has the burden of persuasion
on murder: it therefore falls to the prosecution to persuade the judge that there
was killing, that it was intentional, and that the killer did not act in self-defence.
The bp-labelling is depicted in Fig. 2 (right). The prosecution failed to meet its
burden of proving murder, i.e., its argument is not convincing, since it remains
undetermined whether there was self-defence. Therefore, murder is OUT and the
presumed killer is to be acquitted.
□

Burdens of Persuasion and Standards of Proof in Structured Argumentation
51
Fig. 2. Grounded {IN, OUT, UND}-labelling of Example 1 in the absence of burdens of
persuasion (left) and bp-labelling with the burden of persuasion BurdPers = {murder}
(right).
4.3
The Problem of Defeat Cycles
A complexity in argumentation graphs including arguments burdened of per-
suasion concerns what we may call defeat cycles, i.e., cycles of arguments that
defeat one another. Cycles of defeats have been extensively in argumentation
theory [1,4,6]. Here we just consider how the problem emerges in connection
with burdens of persuasion.
Deﬁnition 16 (Defeat cycle). A defeat cycle is a set of arguments S where
∀argument A ∈S, ∃B ∈S such that A defeats B and A is defeated by B.
Note that this deﬁnition includes, beyond the usual case of head-to-head
rebuttals, those cases in which arguments attack each other’s subarguments, or
undercut one another, as in Example 6.
Example 6 (Defeat cycle example). Let us consider the following rules, with
Conc(A1) ∈BurdPers
Rules : r1 :∼a ⇒b
r2 :∼b ⇒c
r3 :∼c ⇒a
Args :
A1 : ⇒a
A2 : ⇒b
A3 : ⇒c
It’s easy to see that A1 undercuts A2, which undercuts A3, which undercuts
A1.
Determining the status of a burdened argument included in a defeat cycle,
such as A1 in Example 6, is problematic (assuming that no argument in the cycle
is defeated by external attackers). Consider for instance the case of argument
A1 in Example 6. The argument cannot be IN, since there are no reasons for
assuming that its attacker is OUT, not it can be UND because doubt should entail
rejection for burdened arguments, not it can be OUT, since in such a case there
would be no reason for it to be in such status, as its only attacker, A3 would
be OUT as well. Among these three imperfect solutions, it seems that the second
one may be preferable, in accordance with the idea that, in the absence of a

52
R. Calegari and G. Sartor
A1
A2
A3
Fig. 3. Defeat cycle example
decisive reason to accepting it, an argument burdened with persuasion should
be rejected (Fig. 3).
In conclusion, it seems that we have two approaches to deal with such
(vicious) cycles. One approach consists in restricting the argumentation graphs
we are considering to those that do not contain defeat cycles including argu-
ments burdened with persuasion, i.e., in making this restriction a constraint on
the construction of valid argumentation graphs with burdens of persuasion. In
fact, we have not been able to ﬁnd reasonable legal examples that may include
such cycles.
The second approach consists of assuming that all arguments burdened with
persuasion, which are included in a circular bp-defeat set are OUT. More formally,
let us introduce the following deﬁnition, which is meant to capture circular defeat
sets such that no external argument rules out any argument in the cycle: all
external defeaters of burdened arguments in the set are OUT, and all external
defeaters of non-burdened arguments are OUT or UND.
Deﬁnition 17 (Protected defeat cycle). A defeat cycle S is protected in
G iﬀ∀A ∈S holds that
– if Conc(A) ∈BurdPers, then ∀B ∈AG\S such that B bp-defeats A: B ∈
OUT(L)
– if Conc(B) ̸∈BurdPers then ∀B ∈AG\S such that B strictly bp-defeats A:
B ∈OUT(L) or B ∈UND(L).
Following the idea that all burdened arguments in a protected cycle set are
OUT we can then modify Deﬁnition 14 as follows.
Deﬁnition 18 (bp-labelling with defeat cycles). A bp-labelling of an
argumentation graph G, relative to a set of burdens of persuasion BurdPers, is
an {IN, OUT, UND}-labelling s.t. ∀A ∈AG with Conc(A) = φ

Burdens of Persuasion and Standards of Proof in Structured Argumentation
53
1. A ∈IN(L) iﬀ∀B ∈AG such that B bp-defeats A : B ∈OUT(L)
2. A ∈OUT(L) iﬀ
(a) φ ∈BurdPers and
– ∃B ∈AG such that bp-defeats A and B ∈IN(L) or B ∈UND(L), or
– A ∈S such that S is a protected circular defeat set in G
or
(b) φ ̸∈BurdPers and ∃B ∈AG such that B bp-defeats A and B ∈IN(L)
3. A ∈UND(L) otherwise.
5
Adversarial Burden of Persuasion
Adversarial burdens of persuasion expand a bp-labelling approach in order to
capture those cases in which failure to meet a burden of persuasion on φ entails
that φ (φ’s complement) is established.
For instance, failure to show that the accused is guilty entails that he should
be found innocent. Similarly, the plaintiﬀ’s failure to provide a convincing argu-
ment that she has a right to compensation for a certain event entails that she has
no right to be compensated. Or the burden of providing a convincing argument
that a genetically modiﬁed crop is not harmful may entails – according to the
so-called precautionary principle – that the crop is deemed to be harmful.
Thus, an adversarial burden of persuasion on a claim φ entails not only that
arguments for φ will be OUT if they are not IN, but also that failure to establish
φ entails φ’s complement, according to a rule “r :∼φ ⇒φ”.
Example 7 (Criminal law example: adversarial bp). Let us consider again our
example concerning criminal law (Example 5). Let us assume that we add the
rule
abp1 :∼murder ⇒¬murder
This rule enables us to develop an argument for concluding that in the crimi-
nal law example above that there is no murder. This is indeed what generally
happens in criminal and other legal cases: failure to establish the prosecution’s
claim that a murder was committed or the plaintiﬀ’s claim that a compensation
is due leads to the conclusion that there was no crime or that no compensation
is due according to an argument like the following.
B4 = {} ⇒¬murder
The corresponding new argumentation graph is depicted in Fig. 4.
6
Standards of Proof
In this section, we complement burdens of proof with standards of proof. Follow-
ing the approach by [20], we model standards of proof as the required bandwidth
between competing arguments, i.e., as the extent to which one argument has to
prevail over its counterargument in order to meet the applicable burden.

54
R. Calegari and G. Sartor
Fig. 4. Criminal law example with adversarial bp.
6.1
From Priorities to Bandwidths
As with priorities, we assume that bandwidths between arguments are deter-
mined by comparing their top rules. Given that r1 ≻r2, we indicate the
bandwidth between r1 and r2 rules through a positive rational number, which
expresses the positive extent to which r1 prevails over r2, i.e., the comparative
superiority of r1 over r2. If r1 ̸≻r2 we assign 0 to the corresponding band-
width (this holds both when r2 prevails over r1 and when there is no superiority
between the two rules). Accordingly, we deﬁne the bandwidth function as follows.
Deﬁnition 19 (Bandwidth function). Let ≻be a superiority relation over
a set of rules Rules. A bandwidth assignment over ≻is a function BW which
assigns to every pair (ri, rj) ∈Rules a number as follows:
– if (ri, rj) ∈≻, then BW(ri, rj) ∈R>0
– otherwise, BW(ri, rj) = 0
Notation 61. We use ri ≻n rj as an abbreviation for BW(ri, rj) = n, i.e., to
express that rule ri prevails over rule rj to the extent n.
Note that we may want to impose some constraints over bandwidths, for
instance to require that if r1 ≻x r2 and r2 ≻y r3 then r1 ≻z r3 and z ≥max(x, y)
(or even z = x + y), but this is not needed for our purposes.
In our examples, for the sake of simplicity, we assume that bandwidths only
take values 1, 2, or 3, denoting respectively that r1 barely prevails over r2 (as
suﬃcient to meet the standard of preponderance of evidence), that it signiﬁcantly
prevails (as needed to meet the standard of clear and convincing evidence) and
that strongly prevails (as needed to meet the standard of “beyond reasonable
doubt”). Other ranges of possible values may however be considered, depending
on the standards being modelled.

Burdens of Persuasion and Standards of Proof in Structured Argumentation
55
As above, the ordering over rules is transferred to the ordering over argu-
ments: argument A is preferred to argument B to the extent x, denoted by
A ≻x B, iﬀTopRule(A) ≻x TopRule(B).
We are now in a condition to deﬁne the notion of rebutting with standard
of proof, denoted as bps-rebutting. The idea is that the conﬂict between two
arguments A and B such that A contradicts a subargument B′ ∈Sub(B) is to
be determined by the bandwidth between A and B′. We have three cases to
consider:
– There is no burden of persuasion on both A and B′. Then, as usual, A bps-
rebuts B, unless B′ is superior to A.
– There is a burden of persuasion on A. Then A bps-rebuts B′ only if it is
superior to B′ to an extent that at least reaches the applicable standard.
– There is a burden of persuasion on B. Then A bps-rebuts B unless B′ superior
to A to an extent that reaches the standard.
Deﬁnition 20 (bps-rebutting). An argument A bps-rebuts an argument B
relative to a standard S ∈R>0 iﬀ∃B′ ∈Sub(B) such that Conc(A) = Conc(B′)
1. Conc(A), Conc(B′) ̸∈BurdPers, and B′ ̸≻A
2. Conc(A) ∈BurdPers, and BW(A, B′) ≥S
or
3. Conc(B′) ∈BurdPers and BW(B′, A) ̸≥S
On this basis, we get the following deﬁnition for defeat relative to a standard
of proof (bps-defeat).
Deﬁnition 21 (bps-defeat)
– A bps-defeats B relative to standard of proof S iﬀA bps-rebuts B relatively
to S or A undercuts B
– A strictly bps-defeats B relative to standard of proof S iﬀB iﬀA bps-
defeats B relative to standard of proof S and B does not bps-defeats B relative
to standard of proof S.
We can now deﬁne the notion of bp-labelling with a standard of persuasion,
which will be denoted as bps-labelling.
Deﬁnition 22 (bps-labelling). A bps-labelling of a cycle-free argumentation
graph G, relative to a set of burdens of persuasion BurdPers and a standard of
proof S ∈R>0, is an {IN, OUT, UND}-labelling s.t. ∀A ∈AG with Conc(A) = φ.
1. A ∈IN(L) iﬀ∀B ∈AG such that B bps-defeats A: B ∈L(OUT)
2. A ∈OUT(L) iﬀ
(a) φ ∈BurdPers and ∃B ∈AG such that B bps-defeats A: B ̸∈L(OUT) or
(b) φ ̸∈BurdPers and ∃B ∈AG such that B bps-defeats A: B ∈L(IN)
3. A ∈UND(L) otherwise.
Deﬁnition 23 (Grounded bps-labelling). A bps-labelling L of an argu-
mentation graph G is a grounded bps-labelling iﬀUND(L) is maximal.

56
R. Calegari and G. Sartor
6.2
Examples
Let us now consider how diﬀerent standards of proof may aﬀect the outcome of
a dispute, by comparing a criminal case from a civil case for the compensation
of damages resulting from a crime.
Example 8 (Criminal law example with standards of proof). Let us ﬁrst provide
an example by modifying our criminal law example. In Example 5, the outcome
was no conviction for Hellen, since a doubt remains whether she acted in self-
defence, as a consequence of the doubt on whether she was threatened with a
weapon. Let us now assume that the evidence against Hellen being not being
threatened with weapons (f4 :⇒¬threatWithWeapon) prevails over the evi-
dence to the contrary (f3 :⇒threatWithWeapon), but only to a small extent
(e.g.,1), i.e., f4 ≻1 f3.
Given that the bandwidth 1 is inferior to the standard 3 for criminal law,
we get that argument C1 for ¬threatWithWeapon fails to strictly defeat B1 for
threatWithWeapon. Consequently, both arguments are UND, as a consequence,
also the argument B2 for self-defence is UND. Accordingly, the argument for A3
for murder is UND. Thus, the attempt to establish a conviction for murder fails.
The resulting bps-labelling is depicted in Fig. 5 (left).
Let us now assume that the evidence for ¬threatWithWeapon is stronger,
i.e., f4 ≻3 f3 and correspondingly C1 ≻3 B1. It is easy to see that with this
bandwidth, C1 strictly defeats B1, which is consequently OUT as also B2 and B3.
As a consequence A3 is IN and conviction for murder is successfully established.
The resulting bps-labelling is depicted in Fig. 5 (right).
Fig. 5. bps-labelling relative to the murder case in a penal suit with f4 ≻1 f3 (left)
and with f4 ≻3 f3 (right)
Example 9 (Civil law suit for damages resulting from a crime). Assume that
the issue of murder is addressed in a civil suit, where the standard of proof is
1. Moreover, let us add one further rule to our framework, namely a rule which
extends the previous example with the right to compensation:
r5 : murder ⇒compensation

Burdens of Persuasion and Standards of Proof in Structured Argumentation
57
and accordingly, with the following argument:
A4 := A3 ⇒compensation
It is easy to see that in such a case A3 would be IN, since f4 ≻1 f3 and
in civil suit the bandwidth is 1, so that also compensation for murder can be
granted (A4 would be IN). This is what happens in those legal systems in which
criminal and civil suits can be independently started for the same facts (as in
the famous O.J. Simpson case). This result is depicted in Fig. 6.
Fig. 6. bps-labelling relative to the compensation of a murder in a civil suit with
f4 ≻1 f3.
7
Conclusion
We have presented a formal model for the burden of persuasion. The model is
based on the idea that arguments burdened with persuasion have to be rejected
when there is uncertainty about them. Consequently, such arguments become
irrelevant to the argumentation framework including them: not only they fail to
be included in the set of the accepted arguments (the IN ones), but they also are
unable to aﬀect the status of the arguments they attack.
We have shown how an allocation of the burden of persuasion may lead to a
single outcome (IN arguments) in contexts in which the assessment of conﬂicting
arguments would otherwise remain undecided. We have also shown how our
model is able to address inversions of burdens of proof, namely, those cases in
which the burden shifts from one party to the other. In such cases, there is the
burden of persuasion over the conclusion of a multistep argument, and at the
same time a burden of persuasion over the conclusion of an attacker against a
subargument of that multistep argument.
We have also modelled adversarial burdens of proofs, namely, those cases in
which failure to meet a burden of proof for a claim φ entails the complementary
claim φ.

58
R. Calegari and G. Sartor
Finally, we have shown how standards of proof can be captured in our model.
This has been done by introducing the requirement that, in order to meet the
applicable standard, a burdened argument must prevail at least to a certain
extent (as speciﬁed by the standard) over the arguments to the contrary.
The model can be expanded in various ways, to capture further aspects of
legal reasoning. For instance, it can also be supplemented with argumentation
over burdens of persuasion [15,18], in a manner similar to the way in which argu-
mentation systems can be expanded to include argumentation about priorities
(see [12,16]). An open issue, that we plan to address in future research concerns
how to deal with defeat circles including burdened arguments (see Sect. 4.3).
More generally we plan to study the properties of our semantics and the con-
nection of our semantics with the standard semantics for argumentation. We
also plan to inquire about the way in which our model ﬁts into legal procedures
and enables a rational reconstruction of aspects of them. Connections with the
handling of burdens in other formalisms, such as defeasible logic [9] have to be
explored.
References
1. Baroni, P., Caminada, M., Giacomin, M.: An introduction to argumentation
semantics. Knowl. Eng. Rev. 26(4), 365–410 (2011). https://doi.org/10.1017/
S0269888911000166
2. Calegari, R., Sartor, G.: A model for the burden of persuasion in argumentation.
In: Villata, S., Haraˇsta, J., Kˇremen, P. (eds.) Legal Knowledge and Information
Systems. JURIX 2020: The Thirty-Third Annual Conference. Frontiers in Artiﬁcial
Intelligence and Applications, Brno, Czech Republic, 9–11 December 2020, vol. 334,
pp. 13–22. IOS (2020). https://doi.org/10.3233/FAIA200845
3. Caminada, M., Amgoud, L.: On the evaluation of argumentation formalisms. Artif.
Intell. 171(5–6), 286–310 (2007). https://doi.org/10.1016/j.artint.2007.02.003
4. Cramer, M., van der Torre, L.: SCF2-an argumentation semantics for rational
human judgments on argument acceptability. In: Proceedings of the 8th Workshop
on Dynamics of Knowledge and Belief (DKB-2019) and the 7th Workshop KI
& Kognition (KIK-2019) co-located with 44nd German Conference on Artiﬁcial
Intelligence (KI 2019), Kassel, Germany, 23 September 2019, pp. 24–35 (2019)
5. Farley, A.M., Freeman, K.: Burden of proof in legal argumentation. In: Proceedings
of the 5th International Conference on Artiﬁcial Intelligence and Law, Maryland,
USA, pp. 156–164. ACM (1995). https://doi.org/10.1145/222092.222227
6. Gabbay, D.: The handling of loops in argumentation networks. J. Logic Comput.
26(4), 1065–1147 (2014). https://doi.org/10.1093/logcom/exu007
7. Gordon, T.F., Prakken, H., Walton, D.: The Carneades model of argument and
burden of proof. Artif. Intell. 171(10), 875–896 (2007). https://doi.org/10.1016/j.
artint.2007.04.010
8. Gordon, T.F., Walton, D.N.: Proof burdens and standards. In: Simari, G., Rahwan,
I. (eds.) Argumentation in Artiﬁcial Intelligence, pp. 239–258. Springer, Boston
(2009). https://doi.org/10.1007/978-0-387-98197-0 12
9. Governatori, G., Sartor, G.: Burdens of proof in monological argumentation. In:
Winkels, R. (ed.) Proceeding of JURIX 2010: The Twenty-Third Annual Confer-
ence on Legal Knowledge and Information Systems, pp. 57–66. IOS (2010)

Burdens of Persuasion and Standards of Proof in Structured Argumentation
59
10. Hahn, U., Oaksford, M.: The burden of proof and its role in argumentation. Argu-
mentation 21, 36–61 (2007). https://doi.org/10.1007/s10503-007-9022-6
11. Leenes, R.E.: Burden of proof in dialogue games and Dutch civil procedure. In:
Proceedings of the 8th International Conference on Artiﬁcial Intelligence and Law,
Missouri, USA, pp. 109–18. ACM (2001). https://doi.org/10.1145/383535.383549
12. Modgil, S., Prakken, H.: Reasoning about preferences in structured extended argu-
mentation frameworks. In: Proceedings of COMMA 2010, Computational Models
of Argumentation, Italy, pp. 347–58. IOS (2010). https://doi.org/10.3233/978-1-
60750-619-5-347
13. Modgil, S., Prakken, H.: The ASPIC+ framework for structured argumenta-
tion: a tutorial. Argument Comput. 5(1), 31–62 (2014). https://doi.org/10.1080/
19462166.2013.869766
14. Prakken, H.: An abstract framework for argumentation with structured arguments.
Argument Comput. 1, 93–124 (2010). https://doi.org/10.1080/19462160903564592
15. Prakken, H., Reed, C., Walton, D.N.: Dialogues about the burden of proof. In:
Proceedings of the 10th International Conference on Artiﬁcial Intelligence and
Law, Bologna, Italy, pp. 115–124. ACM (2005). https://doi.org/10.1145/1165485.
1165503
16. Prakken, H., Sartor, G.: Rules about rules: assessing conﬂicting arguments in
legal reasoning. Artif. Intell. Law 4, 331–68 (1996). https://doi.org/10.1007/
BF00118496
17. Prakken, H., Sartor, G.: Formalising arguments about the burden of persuasion.
In: Proceedings of the 11th International Conference on Artiﬁcial Intelligence and
Law (ICAIL 2007), pp. 97–106. ACM (2007)
18. Prakken, H., Sartor, G.: Formalising arguments about the burden of persuasion.
In: 11th International Conference on Artiﬁcial Intelligence and Law, Stanford Cal-
ifornia, pp. 97–106. ACM, June 2007
19. Prakken, H., Sartor, G.: A logical analysis of burdens of proof. Legal Evidence
Proof: Stat. Stories Logic 1, 223–253 (2010)
20. Prakken, H., Sartor, G.: On modelling burdens and standards of proof in structured
argumentation. In: 24th Annual Conference on Legal Knowledge and Information
Systems, pp. 83–92. IOS (2011)
21. Vreeswijk, G.: Abstract argumentation systems. Artif. Intell. 90(1–2), 225–279
(1997). https://doi.org/10.1016/S0004-3702(96)00041-0
22. Walton, D.: Arguments from Ignorance. Pennsylvania State University Press, Penn-
sylvania (1996). https://doi.org/10.1007/978-3-319-15013-03
23. Walton, D.: Burden of Proof, Presumption and Argumentation. Cambridge Uni-
versity Press, Cambridge (2014). https://doi.org/10.1017/CBO9781107110311
24. Williams, C.: Burdens and standards in civil litigation. Sydney Law Rev. 25, 165–
188 (2003)

Implementation of Choice of Jurisdiction
and Law in Private International Law by
PROLEG Meta-interpreter
Ken Satoh1(B), Laura Giordano2, and Matteo Baldoni3
1 National Institute of Informatics, Tokyo, Japan
ksatoh@nii.ac.jp
2 Universit`a del Piemonte Orientale, Vercelli, Italy
laura.giordano@uniupo.it
3 Universit`a di Torino, Turin, Italy
baldoni@di.unito.it
Abstract. Private International law (also called Conﬂict of laws) treats
international aﬀairs which involves legal systems of multiple countries. In
the domain of private international law, choice of jurisdiction (the choice
of country whose court can have a competence to treat the aﬀairs) and
choice of law (the choice of law on which the judgement of the aﬀair
is based) are main questions. In this paper, we give an implementation
of both questions using extending PROLEG meta-interpreter. PROLEG
is our legal knowledge representation language which consists of general
rules and exceptions in one legal system. We extend PROLEG to han-
dle diﬀerent legal systems and reference of other legal systems within
reasoning about international aﬀairs.
1
Introduction
Private International law (also called Conﬂict of laws) is the body of jurispru-
dence that undertakes to reconcile a diﬀerence between the laws of diﬀerent
states or countries in a case in which a transaction or occurrence to the case
has a connection to two or more jurisdictions (in Black’s Law Dictionary, 9th
edition). In this paper, we focus on reasoning about choice of jurisdiction (the
choice of the state (or country) that should exercise jurisdiction over a case) and
choice of law (the question of which jurisdiction’s law should apply in a given
case). These two reasoning problems are practically important if a judge solves
international aﬀairs in a litigation.
For example, we would like to reason about an international matter (“Taro is
a legitimate child of Yoko” holds in Japan?), where Taro and Yoko are Japanese.
At the ﬁrst glance, there seems no problem. However, in Japan, we have the
following rule to decide “legitimacy”.
X is a legitimate child of Y if Y is married and X has a biological child
relation with Y.
c
⃝Springer Nature Switzerland AG 2021
P. Baroni et al. (Eds.): CLAR 2021, LNAI 13040, pp. 60–75, 2021.
https://doi.org/10.1007/978-3-030-89391-0_4

Implementation of Choice of Jurisdiction and Law
61
Then, we need to check the marital status of Yoko and suppose that we have
the following facts as well.
– John has a single nationality of Country1.
– John and Yoko agreed to get married and registered their marriage at Coun-
try1.
– John and Yoko have a son named Taro.
In this case, the marital status cannot be determined only by Japanese law and
is somehow related with the law of Country1. Before this, we have to decide
the Japanese court has a power of deciding the case (jurisdiction). Even if the
Japanese court has a jurisdiction, this matter cannot be answered by only con-
sidering the legislation of Japan, but requires the determination of the choice of
law which is the most suitable to solve the international aﬀairs.
To solve the above question, we formalize PIL to decide “choice of law” for
a legal issue: to determine an applicable law for an international legal matter in
one country may require to refer to another law in another country which may
result in a sequence of references of laws to diﬀerent countries. We formalize this
reasoning by a rule-based fragment of the modal language in [2], extended with
context variables, and allows the interactions among contexts to be captured,
context variables to occur within modalities and context names to be used as
predicate arguments, thus supporting a simple combination of meta-predicates
and modal constructs [3]. We then translate the formalism into a logic program
(PROLOG) which reiﬁes predicate to express legal matters with a variable to
express the country of applicable law for the international legal matters [10].
As a related research, Dung and Sartor in [6] consider the issue of deciding
the court having competence as well as the issue of establishing the legal system
according to which the court has to decide (jurisdiction). Dung and Sartor pro-
vide an analysis of private international law and propose a formal model based on
modular argumentation. Calegari [5] proposes an implementation of jurisdiction
reasoning using argument-based logic programming based on the idea of Dung
and Sartor. However, they do not consider “choice of law”. As another related
research the speciﬁcity of the rules in Conﬂict of Laws have been analyzed by
Markovich [8] in the formalism of the input/output framework [7], where such
rules assign a set of sets of norms (a legal system) to a given domain (a set of
statements).
In this paper, we present a detailed implementation of PIL reasoning based
on PROLEG [9] for choice of jurisdiction and choice of law. PROLEG is a logic
programming language for rule-based legal knowledge representation and it rep-
resents laws in the form of “general rules” and “exceptions”. This form of rep-
resentation ﬁts lawyers’ reasoning patter and therefore is for lawyers easy to
understand. In this work, we implement the choice of jurisdiction directly using
PROLEG since the choice of jurisdiction does not involve considerations of other
country’s law and therefore, it is a direct application of PROLEG. However, to
ﬁnd out which jurisdiction accepts the case, we index PROLEG with the context
of country so that we can reason about diﬀerent jurisdictions in one system. For
the choice of law, we need to extend a meta-interpreter of PROLEG written in

62
K. Satoh et al.
PROLOG so that a mechanism of choice of law for each legal conditions are
introduced.
We put the source of extended PROLOG meta-interpreter for Modular-
PROLEG with the choice of law function in the Appendix.
2
Reasoning About Jurisdiction
Since reasoning about competence in one country is done only by a domestic
law where the litigation arises, usual PROLEG reasoning can be used. However
to reason about jurisdiction for each country, we index PROLEG predicate with
countries in the form of P#C (P: atom, C:country name). We call this version
of PROLEG as Modular-PROLEG since C can be regarded as a module of
PROLEG program.
2.1
Syntax of Modular-PROLEG
A Modular-PROLEG program P is a pair of a PROLEG rulebase R and a
PROLEG factbase F.
– PROLEG rulebase consists of the following expressions; a rule and an excep-
tion.
• A rule of the form of Horn clauses:
H#C ⇐B1#C1, ..., Bn#C2.
where H#C is called a head of the rules and Bi#Ci’s is called a requisite.
• An exception is an expression of the form exception(H#C, E#C) or
exception(H, E)#C where H, E are atoms each of which is the head of
rule.
The above rule means that H#C is satisﬁed in principle if all the requi-
sites Bi#Ci are satisﬁed in each country Ci, whereas the exception means
that”H#C is not satisﬁed if E#C is satisﬁed (even if all the requisites of a
rule whose head is H#C are satisﬁed)”.
We sometimes write “H#C ⇐B1#C, ..., Bn#C.” as “(H ⇐B1, ..., Bn)#C.”
if all the referred countries are same in the head and in the body of a
rule and we write rules of “(H ⇐B1, ..., Bn)#C.” for any country C as
“(H ⇐B1, ..., Bn)# .”
– PROLEG factbase consists of the following expression:
fact(X#C).
where X#C is a prerequisite which is not any head of any rule in PROLEG
rulebase. fact(X#C) means that X is the fact in the country C.

Implementation of Choice of Jurisdiction and Law
63
2.2
Modular-PROLEG Semantics a la Answer Set Programming
Let a Modular-PROLEG program P be ⟨R, F⟩where R is a rulebase and F is a
factbase. Let M be a set of atoms of the heads of rules, H#C plus a set of facts
{F#C|fact(F#C) ∈F}. We deﬁne a set of applicable rules w.r.t. M, RM, as
follows:
{R ∈R|there is no E#C s.t. exception(head(R)#C, E#C) ∈R and E#C ∈M}.
This means that if some exception is found for a conclusion head(R)#C of a
rule R, we do not consider such rule R for derivation. The semantics of P (called
an extension of P) is given as a set of ground atoms M s.t. M = min(RM ∪
{F#C|fact(F#C) ∈F}) where min(T) is the minimum model of a set of Horn
clauses T where we regard P#C in T as an atom.
2.3
Meta Interpreter of Modular-PROLEG
Here is a meta-interpreter of Modular-PROLEG (Fig. 1. This is a non-
deterministic algorithm in that we have a select operation. If we fail at some
point in the algorithm, we assume that we backtrack to select operation and
check other alternatives. We use the same algorithm with PROLEG meta-
interpreter [9] except handling of the context of countries.
2.4
Example of Reasoning About Jurisdiction
Here is a part of Personal Status Litigation Act (LSA) in Japan. Article 3-2 of
PSLA sets the rules for when actions can be ﬁled in a Japanese court. Under the
current rules, actions can be ﬁled in a Japanese court where any of the following
applies:
–
Article 3-2(1), PSLA: The defendant is domiciled in Japan.
–
Article 3-2(7), PSLA: The plaintiﬀlives in Japan and there are special cir-
cumstances that a family court in Japan should exercise jurisdiction to deliver
equity between the parties or for due and prompt process of proceedings.
However, there is an exceptional situation of rejecting jurisdiction of Japan if
the jurisdiction in Japan harms equity between the parties or leads to undue
and delayed process of proceedings. (Article 3–5, PSLA).
Here is a PROLEG translation of the above rules and exception.
% PROLEG rules for Jurisdiction
% Personal Status Litigation Act.
(psla)
% (Article 3-2(1), PSLA)
(hasJuris(P,C) <= defendant(P,Def),domicile(Def,C))#C.
% (Article 3-2(7), PSLA)
(hasJuris(P,C) <= positive_special_circumstance(P))#C.
(positive_special_circumstance(P) <=

64
K. Satoh et al.
Fig. 1. Algorithm of Meta-Interpreter for Modular-PROLEG
defendant(P,Def),plaintiff(P,Pla),
deliver_equity(P,Def,Pla))#_.
(positive_special_circumstance(P) <=
due_and_prompt_process(P))#_.
exception(hasJuris(P,C),negative_special_circumstance(P))#C.
% (Artcile 3-5, PSLA)
(negative_special_circumstance(P) <=
defendant(P,Def),plaintiff(P,Pla),harm_equity(P,Def,Pla))#_.
(negative_special_circumstance(P) <=
undue_and_delay_process(P))#_.
Suppose that we have the following facts.
% PROLEG facts for Jurisdiction
fact(plaintiff(cp_rel(taro,john),taro)#_).
fact(domicile(taro,japan)#_).
fact(defendant(cp_rel(taro,john),john)#_).
fact(domicile(john,country1)#_).
fact(due_and_prompt_process(cp_rel(taro,john))#japan).

Implementation of Choice of Jurisdiction and Law
65
fact(harm_equity(cp_rel(taro,john),john,taro)#country1).
Here
is
the
output
trace
for
hasJuris(cp rel(taro,john),
Country)#Country in which we can reason about which country has a
competence (In this case, Japan) for the question “Taro is a child of John” (we
call this relation “cp rel between Taro and John”). For the Country1, although
we can see that the defendant John lives in Country1, there is a negative special
circumstance of having equity so the competence of the Country1 is rejected.
For Japan, since there is a positive special circumstance of having due and
prompt process, the competence of Japan is accepted.
% Reasoning about jurisdiction
Starting to prove: hasJuris(cp_rel(taro,john),_3190)#_3190
(hasJuris(cp_rel(taro,john),_3190)<=
defendant(cp_rel(taro,john),_4370),
domicile(_4370,_3190))#_3190 found.
fact(defendant(cp_rel(taro,john),john)#_3190) found.
fact(domicile(john,country1)#country1) found.
hasJuris(cp_rel(taro,john),country1)#country1 succeeded.
Exception check:negative_special_circumstance(cp_rel(taro,john))#country1
Starting to prove: negative_special_circumstance(cp_rel(taro,john))#country1
(negative_special_circumstance(cp_rel(taro,john))<=
defendant(cp_rel(taro,john),_4618),
plaintiff(cp_rel(taro,john),_4630),
harm_equity(cp_rel(taro,john),_4618,_4630))#country1 found.
fact(defendant(cp_rel(taro,john),john)#country1) found.
fact(plaintiff(cp_rel(taro,john),taro)#country1) found.
fact(harm_equity(cp_rel(taro,john),john,taro)#country1) found.
negative_special_circumstance(cp_rel(taro,john))#country1 succeeded.
Failed to deny negative_special_circumstance(cp_rel(taro,john))#country1
(hasJuris(cp_rel(taro,john),_3190)<=
positive_special_circumstance(cp_rel(taro,john)))#_3190 found.
Starting to prove: positive_special_circumstance(cp_rel(taro,john))#_3190
(positive_special_circumstance(cp_rel(taro,john))<=
defendant(cp_rel(taro,john),_4398),
plaintiff(cp_rel(taro,john),_4410),
deliver_equity(cp_rel(taro,john),_4398,_4410))#_3190 found.
fact(defendant(cp_rel(taro,john),john)#_3190) found.
fact(plaintiff(cp_rel(taro,john),taro)#_3190) found.
fact(deliver_equity(cp_rel(taro,john),john,taro)#_3190) not found.
(positive_special_circumstance(cp_rel(taro,john))<=
due_and_prompt_process(cp_rel(taro,john)))#_3190 found.
fact(due_and_prompt_process(cp_rel(taro,john))#japan) found.
positive_special_circumstance(cp_rel(taro,john))#japan succeeded.
hasJuris(cp_rel(taro,john),japan)#japan succeeded.
Exception check:negative_special_circumstance(cp_rel(taro,john))#japan
No Exception: negative_special_circumstance(cp_rel(taro,john))#japan
************** Jurisdiction OK. **************
C = japan ;

66
K. Satoh et al.
3
Reasoning About Choice of Law
We review how to reason about international aﬀairs involving choice of law
deﬁned in [3]. Given a legal matter P in one country, C, we would like to decide
whether the matter is valid in the country in the following way.
1. We decide the country X whose law is applied to decide the matter P as
follows.
(a) There should be a rule in the private international law in C which indi-
cates an applicable law in (possible another) country C′ for the matter P
in the country, C.
(b) If C′ = C, X = C.
(c) Else (C′ ̸= C), we need to again decide the country X of the applicable
law for P according to the private international law in C′ (called “envoi”
here)
(d) If we detect a loop in the “envoi” (called “renvoi” here), we set the
applicable law to the starting country of the loop. For example, if
the private international laws makes this reference of applicable law,
“A →B →C →D →B”, then we decide an applicable law for the
matter as country B.
2. We decompose the matter P into submatters according to a rule deﬁned in
the applicable law in X.
3. If a submatter is determined by a global fact and the global fact is in the fact
base, the submatter is valid.
4. Otherwise, we iterate the process above (we decide an applicable law of the
submatter and then check the submatter is valid in the applicable law).
In the following subsection, we show how to implement the above in Modular-
PROLEG for PIL with the “envoi” mechanism.
3.1
Syntax of Modular-PROLEG for PIL
A Modular-PROLEG program for PIL P is a pair of a PROLEG rulebase R and
a PROLEG factbase F.
– PROLEG rulebase consists of two parts: “choice of law” part C and substan-
tive part S. Both parts consist of rules and exceptions like Modular-PROLEG
rule base.
• In C, the head of each rules are always of the form of a special atom
envoi(P#C, AC) where P#C is a Modular-PROLEG atom and AC is a
variable whose type is a country.
• In S, we do not use envoi( , ) anywhere.
– PROLEG factbase consists of the following expression:
fact(X)#C.

Implementation of Choice of Jurisdiction and Law
67
3.2
Semantics for Modular-PROLEG for PIL
Let a Modular-PROLEG program for PIL P be ⟨R, F⟩. Let M be a set of atoms
of the heads of rules, H#C plus a set of facts {F#C|fact(F)#C ∈F}. We
deﬁne a set of applicable rules w.r.t. M, RM, as follows:
{R ∈R|there is no E#C s.t. exception(head(R)#C, E#C) ∈R and E#C ∈M}.
The semantics of P (called an extension of P) is given as a set of atoms M s.t.
M = min(RM ∪{F#C|fact(F)#C ∈F})∪
{P#C0|envoi(P, C1)#C0 ∈M, envoi(P, C2)#C1 ∈M, ..., envoi(P, Cn)#Ci ∈
M(i ≤n), and P#Ci ∈M}.
The last set is the derived augmented international aﬀairs based on the
“envoi” mechanism.
3.3
Meta-interpreter of Modular-PROLEG for PIL
The meta-interpreter of Modular-PROLEG for PIL is the meta-interpreter of
Modular-PROLEG augmented by the choice of law mechanism as follows (Figs. 2
and 3). Every time we decompose an international aﬀair into sub international
aﬀairs, we reason about choice of law which applies to each sub international
aﬀairs.
3.4
Example of Reasoning About International Aﬀairs
We show an example of reasoning about international aﬀairs, namely the ques-
tion whether “Taro is a legitimate child of Yoko” is valid in Japan? (we call this
relation “lcp rel between Taro and Yoko”).
We ﬁrstly decide which country’s law applicable to determine the above ques-
tion. Suppose that we have the following rules in Japan for choice of law for
legitimate child-parent relationship:
(lcp rel1) We use law of the home country of a parent, or
(lcp rel2) We use law of the home country of the nationality of a spouse of the
parent.
We check rule (lcp rel1), we need to decide the home country of the parent
(in this case, Yoko) and deciding the home country could be an international
aﬀair. Note that inside the process of “choice of law”, we might have a nested
reasoning of solving the international aﬀair and this deciding problem of home
country is such a nested reasoning. So we ﬁrstly need to decide which country’s
law is applied for the home country problem. Suppose that we have the following
rule for the choice of law for “home country” as follows (we assume this rule is
valid in Japan and also in Country1).
– Home country will be determined in the law in the country of the court.

68
K. Satoh et al.
Fig. 2. Algorithm of modular-PROLEG meta-interpreter for PIL
Fig. 3. Algorithm of choice of law
Since in this case, lcp rel is raised in the Japanese court, we use Japanese law
to determine the home country of the Yoko. Suppose that we have the following
substantive law for deciding the home country (we assume this rule is valid in
Japan and also in Country1).

Implementation of Choice of Jurisdiction and Law
69
– The home country is the person’s nationality, if the person has only one
nationality.
In this case, Yoko has a single nationality (Japanese) so her home country is
Japan. Then, we use the following Japanese substantive law to determine lcp rel.
– A child X and a parent Y has a legitimate child relationship if X is married
(called “mrg” here) and X and Y have a biological child-parent relation (called
“bcp rel” here).
Then, we have to determine Yoko’s marital status. To decide marital status, we
need to decide which country’s law is applicable for this. Suppose that there is
the following universal rule (valid in Japan and Country1) for “choice of law”:
– We use law of the home country of either spouse.
Suppose that we choose the law of Yoko’s home country (Japan). Suppose that
we have the following Japanese substantive law for marriage:
– A marriage relationship holds between Spouse 1 and Spouse 2 if there is an
agreement on marriage between Spouse1 and Spouse 2 and they register their
marriage in Japan.
– There is an exception for the above rule in that if divorce between Spouse 1
and Spouse 2 is made after the marriage, the marriage is no longer valid.
In this case, although there is an agreement between Yoko and John, the marriage
was registered only in Country1 (See Introduction). We cannot prove the marital
status for Yoko using Japanese law.
On the other hand, suppose that we choose the law of the home country of
Yoko’s spouse, John (Country1). Suppose that we have the following Country1’s
substantive law for marriage:
– A marriage relationship holds between Spouse 1 and Spouse 2 if there is an
agreement on marriage between Spouse1 and Spouse 2 and they register their
marriage in Country1.
– There is an exception for the above rule in that if divorce between Spouse 1
and Spouse 2 is made after the marriage, the marriage is no longer valid.
In this case, there is registration of marriage between Yoko and John in Country1
so the marriage between Yoko and John could be proved in Japan by default.
However, suppose that John and Yoko made a divorce in Country1 after the mar-
riage. In this case, the marriage between Yoko and John is not valid. Therefore,
we cannot prove mrg status between Yoko and John so lcp rel is not satisﬁed.
We show a program in Modular-PROLEG for PIL and the trace of reasoning
as follows.
% PROLEG program for Private International Law
% RC: referred country
% lcp_rel: legitimate_child_parent_relation
% mrg: marriage

70
K. Satoh et al.
% hmc: home_country
% HMC: Home_Country
% agr: agreement
% rgst: registering
% Sp: Spouse
% Chld: Child
% Prnt: Parent
% s_nat: single_nationality
% CtznList: CitizenshipList
% bcp_rel: bilogical_child_parent_relation
(envoi(lcp_rel(_,Prnt),RC) <= hmc(Prnt,RC))#_.
(envoi(lcp_rel(_,Prnt),RC) <= mrg(Prnt,PrntSp), hmc(PrntSp,RC))#japan.
(envoi(lcp_rel(_,Prnt),RC) <= mrg(PrntSp,Prnt), hmc(PrntSp,RC))#japan.
(envoi(mrg(P,S),RC) <= claim(mrg,P,S),hmc(P,RC))#_.
(envoi(mrg(P,S),RC) <= claim(mrg,P,S),hmc(S,RC))#_.
(envoi(dvrc(P,S),RC) <= claim(dvrc,P,S),hmc(P,RC))#_.
(envoi(dvrc(P,S),RC) <= claim(dvrc,P,S),hmc(S,RC))#_.
% For every country, home country rule is always each country’s rule.
(envoi(hmc(_,_),RC) <= call(RC=C))#C.
% Domestic Rules
(mrg(Sp1,Sp2) <= agr(mrg,Sp1,Sp2), rgst(mrg,Sp1,Sp2))#_.
exception(mrg(Sp1,Sp2),dvrc(Sp1,Sp2))#_. % (dvrc: divorce)
(dvrc(Sp1,Sp2) <= agr(dvrc,Sp1,Sp2), rgst(dvrc,Sp1,Sp2))#_.
(lcp_rel(Chld,Prnt) <= mrg(Prnt,_), bcp_rel(Chld,Prnt))#_.
(hmc(P,HMC) <= s_nat(P,HMC))#_.
% Substantive Facts
fact(s_nat(john,country1))#_.
fact(s_nat(yoko,japan))#_.
fact(bcp_rel(taro,john))#_.
fact(bcp_rel(taro,yoko))#_.
fact(agr(mrg,john,yoko))#_.
fact(agr(mrg,yoko,john))#_.
fact(rgst(mrg,john,yoko))#country1.
fact(rgst(mrg,yoko,john))#country1.
fact(agr(dvrc,john,yoko))#_.
fact(agr(dvrc,yoko,john))#_.
fact(rgst(dvrc,john,yoko))#country1.
fact(rgst(dvrc,yoko,john))#country1.
fact(claim(mrg,john,yoko))#_.
fact(claim(mrg,yoko,john))#_.
fact(claim(dvrc,john,yoko))#_.
fact(claim(dvrc,yoko,john))#_.
% Reasoning about international affairs
Starting to prove: lcp_rel(taro,yoko)#japan

Implementation of Choice of Jurisdiction and Law
71
% Reasoning about choice of law for lcp_rel(taro,yoko) is started.
Starting to prove: envoi(lcp_rel(taro,yoko),_9406)#japan
(envoi(lcp_rel(taro,yoko),_9406)<=
hmc(yoko,_9406))#japan found.
Starting to prove: hmc(yoko,_9406)#japan
Starting to prove: envoi(hmc(yoko,_9406),_9484)#japan
(envoi(hmc(yoko,_9406),_9484)<=
call(_9484=japan))#japan found.
envoi(hmc(yoko,_9406),japan)#japan succeeded.
Exception check: envoi(hmc(yoko,_9406),japan)#japan
No Exception:envoi(hmc(yoko,_9406),japan)#japan
applying_country_for(hmc(yoko,_9406)) found(japan)
(hmc(yoko,_9406)<=
s_nat(yoko,_9406))#japan found.
fact(s_nat(yoko,japan)#japan) found.
hmc(yoko,japan)#japan succeeded.
Exception check: hmc(yoko,japan)#japan
No Exception:hmc(yoko,japan)#japan
envoi(lcp_rel(taro,yoko),japan)#japan succeeded.
Exception check: envoi(lcp_rel(taro,yoko),japan)#japan
No Exception:envoi(lcp_rel(taro,yoko),japan)#japan
applying_country_for(lcp_rel(taro,yoko)) found(japan)
% Choice of law for lcp_rel(taro,yoko) is determined as Japan’s law.
% Substantive reasoning for lcp_rel(taro,yoko) is started
(lcp_rel(taro,yoko)<=
mrg(yoko,_9760),
bcp_rel(taro,yoko))#japan found.
Starting to prove: mrg(yoko,_9760)#japan
% Reasoning about choice of law for mrg(yoko,_9760) is started.
Starting to prove: envoi(mrg(yoko,_9760),_9826)#japan
(envoi(mrg(yoko,_9760),_9826)<=
claim(mrg,yoko,_9760),
hmc(yoko,_9826))#japan found.
fact(claim(mrg,yoko,john)#japan) found.
Starting to prove: hmc(yoko,_9826)#japan
Starting to prove: envoi(hmc(yoko,_9826),_9952)#japan
(envoi(hmc(yoko,_9826),_9952)<=
call(_9952=japan))#japan found.
envoi(hmc(yoko,_9826),japan)#japan succeeded.
Exception check: envoi(hmc(yoko,_9826),japan)#japan
No Exception:envoi(hmc(yoko,_9826),japan)#japan
applying_country_for(hmc(yoko,_9826)) found(japan)
(hmc(yoko,_9826)<=
s_nat(yoko,_9826))#japan found.
fact(s_nat(yoko,japan)#japan) found.
hmc(yoko,japan)#japan succeeded.
Exception check: hmc(yoko,japan)#japan
No Exception:hmc(yoko,japan)#japan
envoi(mrg(yoko,john),japan)#japan succeeded.
Exception check: envoi(mrg(yoko,john),japan)#japan

72
K. Satoh et al.
No Exception:envoi(mrg(yoko,john),japan)#japan
applying_country_for(mrg(yoko,john)) found(japan)
% Choice of law for mrg(yoko,john) is determined as Japan’s law.
% Substantive reasoning for mrg(yoko,john) by Japan’s law is started.
(mrg(yoko,john)<=
agr(mrg,yoko,john),
rgst(mrg,yoko,john))#japan found.
fact(agr(mrg,yoko,john)#japan) found.
fact(rgst(mrg,yoko,john)#japan) not found.
% Substantive reasoning for mrg(yoko,john) by Japan’s law is failed
%
since the condition is not satisfied.
% Another reasoning about choice of law for mrg(yoko,_9760) is started.
(envoi(mrg(yoko,_9760),_9826)<=
claim(mrg,yoko,_9760),
hmc(_9760,_9826))#japan found.
fact(claim(mrg,yoko,john)#japan) found.
Starting to prove: hmc(john,_9826)#japan
Starting to prove: envoi(hmc(john,_9826),_9952)#japan
(envoi(hmc(john,_9826),_9952)<=
call(_9952=japan))#japan found.
envoi(hmc(john,_9826),japan)#japan succeeded.
Exception check: envoi(hmc(john,_9826),japan)#japan
No Exception:envoi(hmc(john,_9826),japan)#japan
applying_country_for(hmc(john,_9826)) found(japan)
(hmc(john,_9826)<=
s_nat(john,_9826))#japan found.
fact(s_nat(john,country1)#japan) found.
hmc(john,country1)#japan succeeded.
Exception check: hmc(john,country1)#japan
No Exception:hmc(john,country1)#japan
envoi(mrg(yoko,john),country1)#japan succeeded.
Exception check: envoi(mrg(yoko,john),country1)#japan
No Exception:envoi(mrg(yoko,john),country1)#japan
applying_country_for(mrg(yoko,john)) found(country1)
% Choice of law for mrg(yoko,john) is determined as country1’s law.
% Substantive reasoning for mrg(yoko,john) by country1’s law is started
(mrg(yoko,john)<=
agr(mrg,yoko,john),
rgst(mrg,yoko,john))#country1 found.
fact(agr(mrg,yoko,john)#country1) found.
fact(rgst(mrg,yoko,john)#country1) found.
mrg(yoko,john)#country1 succeeded.
Exception check: mrg(yoko,john)#country1
Try to deny: dvrc(yoko,john)#country1
Starting to prove: dvrc(yoko,john)#country1
% Reasoning about choice of law for dvrc(yoko,john) is started.
Starting to prove: envoi(dvrc(yoko,john),_10552)#country1
(envoi(dvrc(yoko,john),_10552)<=
claim(dvrc,yoko,john),
hmc(john,_10552))#country1 found.

Implementation of Choice of Jurisdiction and Law
73
fact(claim(dvrc,yoko,john)#country1) found.
Starting to prove: hmc(john,_10552)#country1
Starting to prove: envoi(hmc(john,_10552),_10678)#country1
(envoi(hmc(john,_10552),_10678)<=
call(_10678=country1))#country1 found.
envoi(hmc(john,_10552),country1)#country1 succeeded.
Exception check: envoi(hmc(john,_10552),country1)#country1
No Exception:envoi(hmc(john,_10552),country1)#country1
applying_country_for(hmc(john,_10552)) found(country1)
(hmc(john,_10552)<=
s_nat(john,_10552))#country1 found.
fact(s_nat(john,country1)#country1) found.
hmc(john,country1)#country1 succeeded.
Exception check: hmc(john,country1)#country1
No Exception:hmc(john,country1)#country1
envoi(dvrc(yoko,john),country1)#country1 succeeded.
Exception check: envoi(dvrc(yoko,john),country1)#country1
No Exception:envoi(dvrc(yoko,john),country1)#country1
applying_country_for(dvrc(yoko,john)) found(country1)
% Choice of law for dvrc(yoko,john) is determined as country1’s law.
% Substantive reasoning for dvrc(yoko,john) by country1’s law is started
(dvrc(yoko,john)<=
agr(dvrc,yoko,john),
rgst(dvrc,yoko,john))#country1 found.
fact(agr(dvrc,yoko,john)#country1) found.
fact(rgst(dvrc,yoko,john)#country1) found.
dvrc(yoko,john)#country1 succeeded.
Exception check: dvrc(yoko,john)#country1
No Exception:dvrc(yoko,john)#country1
Failed to deny dvrc(yoko,john)#country1
% Substantive reasoning for mrg(yoko,john) by country1’s law is failed
%
since exception is found.
4
Conclusion
We give an implementation of reasoning about “choice of jurisdiction” and sub-
stantive international aﬀairs based on Modular-PROLEG which involves “choice
of law”. For future works, we would like to develop more advanced man-machine
interface to visualize reasoning process, and we would also aim at investigating
comparison with other approaches for representing reasoning in private interna-
tional law, especially in dealing with exceptions and contextual reasoning in the
literature, including Defeasible Logic [1] and the CKR (Contextualized Knowl-
edge Repositories) framework by Bozzato et al. [4].

74
K. Satoh et al.
Appendix
% Meta Interpreter for Modular-PROLEG (for PIL) program
% Top Level Goal is either
% solve(plain,P#Country) for a query of Modular-PROLEG.
% solve(pil,P#Country) for a query of Modular-PROLEG for PIL.
solve(Phase,(P,Q)#Country):-!,
solve(Phase,P#Country), solve(Phase,Q#Country).
solve(_,call(P)#_):-!,
% for built_in predicate
call(P).
solve(_,P#Country):-
is_fact(P#Country),!,
fact(P#Country).
solve(Phase,P#Country):- % This is a main part.
(Phase = pil ->
choice(P#Country,AC,[])); % For PIL, we firstly calculate choice of law.
AC = Country
% For ordinary Modular-PROLEG, we do nothing.
),
(P <= Q)#AC,
solve(Phase,Q#AC),
no_counter_argument(Phase,P#AC).
no_counter_argument(_,P#Country):-
\+exception(P,_)#Country.
no_counter_argument(Phase,P#Country):-
exception(P,R)#Country,
unsolve(Phase,R#Country).
unsolve(Phase,R#Country):-
groundize(R#Country), % We need this for correctness of NAF.
solve(Phase,R#Country),
!,
fail.
choice(_#_,C,History):-
% If renvoi happens,
member(C,History),!. % AC becomes the starting point of loop.
choice(envoi(_,_)#C,C,_):-!. % Envoi rule is always each country’s rule
choice(P#C,AC,History):-
!,
solve(pil,envoi(P,RC)#C), % We compute one step forward for choice of law.
choice(P#RC,AC,[RC|History]).
is_fact(P#_):-
\+ (P<=_)#_.
groundize((P,Q)#Country):-!, groundize(P#Country), groundize(Q#Country).
groundize(P#Country):- is_fact(P#Country),!, fact(P#Country).
groundize(P#Country):- (P <= Q)#Country, groundize(Q#Country).

Implementation of Choice of Jurisdiction and Law
75
References
1. Antoniou, G., Billington, D., Governatori, G., Maher, M.J.: Representation results
for defeasible logic. ACM Trans. Comput. Log. 2(2), 255–287 (2001). https://doi.
org/10.1145/371316.371517
2. Baldoni, M., Giordano, L., Martelli, A.: A modal extension of logic programming:
modularity, beliefs and hypothetical reasoning. J. Log. Comput. 8(5), 597–635
(1988)
3. Baldoni, M., Giordano, L., Satoh, K.: Renvoi in private international law: a formal-
ization with modal context. In: Proceedings of JURIX 2019, pp. 157–162 (2019)
4. Bozzato, L., Eiter, T., Seraﬁni, L.: Enhancing context knowledge repositories with
justiﬁable exceptions. Artif. Intell. 257, 72–126 (2018)
5. Calegari, R., Contissa, G., Pisano, G., Sartor, G., Sartor, G.: Arg-tuProlog: a
modular logic argumentation tool for PIL. In: Profeedings of JURIX 2020, pp.
265–268 (2020)
6. Dung, P.M., Sartor, G.: The modular logic of private international law. Artif. Intell.
Law 19(2–3), 233–261 (2011). https://doi.org/10.1007/s10506-011-9112-5
7. Makinson, D., van der Torre, L.: What is input/output logic? In: L¨owe, B.,
Malzkom, W., R¨asch, T. (eds.) Foundations of the Formal Sciences II. Trends in
Logic (Studia Logica Library), vol. 17, pp. 163–174. Springer, Heidelberg (2003).
https://doi.org/10.1007/978-94-017-0395-6 12
8. Markovich, R.: On the formal structure of rules in conﬂict of laws. In: Proceedings
of JURIX 2019, pp. 199–204 (2019)
9. Satoh, K., et al.: PROLEG: an implementation of the presupposed ultimate fact
theory of Japanese civil code by PROLOG technology. In: Onada, T., Bekki,
D., McCready, E. (eds.) JSAI-isAI 2010. LNCS (LNAI), vol. 6797, pp. 153–164.
Springer, Heidelberg (2011). https://doi.org/10.1007/978-3-642-25655-4 14
10. Satoh, K., Baldoni, M., Giordano, L.: Reasoning about applicable law in private
international law in logic programming. In: Proceedings of JURIX 2020, pp. 281–
285 (2020)

Full Papers

Collective Argumentation
with Topological Restrictions
Weiwei Chen(B)
Institute of Logic and Cognition and Department of Philosophy,
Sun Yat-sen University, Guangzhou, China
chenww26@mail2.sysu.edu.cn
Abstract. Collective argumentation studies how to reach a collective
decision that is acceptable to the group in a debate. I introduce the con-
cept of topological restriction to enrich collective argumentation. Topo-
logical restrictions are rational constraints assumed to be satisﬁed by
individual agents. We assume that in a debate, for every pair of argu-
ments that are being considered, every agent indicates whether the ﬁrst
one attacks the second, i.e., an agent’s argumentative stance is charac-
terized as an argumentation framework, and only argumentation frame-
works that satisfy topological restrictions are allowed. The topological
constraints we consider in this paper include acyclicity, symmetry, as
well as a newly deﬁned topological property called t-self-defense. We
show that when proﬁles of argumentation frameworks provided by agents
satisfy topological restrictions, impossibility results during aggregation
can be avoided. Furthermore, if a proﬁle is topological-restricted with
respect to t-self-defense, then the majority rule preserves admissibility
during aggregation.
Keywords: Collective argumentation · Topological restriction · Social
choice theory
1
Introduction
Abstract argumentation theory is a formalism that deals with the formaliza-
tion of argumentation. It has been applied for over twenty years to analyze
the argument justiﬁcation. When there are several agents involved in a debate,
such as juridical and parliamentary debates, they may have diﬀerent opinions
on the evaluation of the acceptability of arguments or the justiﬁcation of attacks
between arguments. Collective argumentation has been discussed extensively in
the literature of formal argumentation (see [6,7]). Among them, some are ded-
icated to investigating the aggregation of arguments [9,12,13,23], while others
study the aggregation of attacks [7,8,10,11,21].
The problem of aggregation of abstract argumentation frameworks has
received attention in the literature in the last decade or so [7,12,13,23]. On aggre-
gation rules, some study the performance of simple and straightforward rules,
such as the majority rule, quota rules, while some other study rules with high
c
⃝Springer Nature Switzerland AG 2021
P. Baroni et al. (Eds.): CLAR 2021, LNAI 13040, pp. 79–93, 2021.
https://doi.org/10.1007/978-3-030-89391-0_5

80
W. Chen
complexity, such as distance-based rules. It is worth mentioning that while diﬀer-
ent aggregation mechanisms, diﬀerent aggregation entities have been employed,
a common feature of these work is that they study the aggregation of argumen-
tation frameworks without restrictions. In other words, no restriction is imposed
on the argumentation frameworks. Each individual agent provides an arbitrary
argumentation framework that represents her argumentative stance in a debate.
In this case, we assume that for every pair of arguments that are being consid-
ered in a debate, every agent indicates whether the ﬁrst attack the second. Given
a semantic property agreed upon by the individual agents, the output may or
may not satisfy such property.
I propose the notion of topological restriction to enrich collective argumen-
tation. Topological restrictions will help us to get rid of argumentation frame-
works that are not desirable. For example, we may consider it irrational for an
individual agent to support argumentation frameworks that contain odd-length
cycles, with which an argument may indirectly attack and support another. In
this case, the acceptance status of the second argument is controversial and
we would like to avoid such controversy. In such circumstances, we can require
that agents’ argumentation frameworks satisfy acyclicity. For acyclic argumen-
tation frameworks, the acceptance status of arguments is unambiguous as the
grounded extension coincides with the unique preferred extension that is also sta-
ble. There are other topological properties that can help us avoid controversy,
such as symmetry. For symmetric argumentation frameworks, the attack-relation
is symmetric. As a consequence, every symmetric argumentation framework is
coherent (which means that every preferred extension is stable) and relatively
grounded (which means that the grounded extension is the intersection of all its
preferred extensions).
Our contribution is two-fold: ﬁrst, we introduce the notion of topological
restriction to the aggregation of argumentation frameworks and study several
topological restrictions during aggregation, including acyclicity, symmetry, and a
newly deﬁned topological property called t-self-defense. We show that with topo-
logical restrictions, impossibility results during aggregation of attack-relations
can be avoided. To be speciﬁc, there are some aggregation rules that preserve
demanding properties. Also, we show that, if a proﬁle is topological-restricted
with respect to t-self-defense, then the majority rule, a rule that is very appeal-
ing on normative grounds, as it treats all agents in a “fair” manner, preserves
admissibility during aggregation.
The remainder of the paper is organized as follows. Section 2 presents rele-
vant concepts from the theory of abstract argumentation, including some of the
fundamentals of the model of abstract argumentation and topological. Section 3
introduces our model and Sect. 4 introduces the concept of topological restric-
tion. Section 5 presents our preservation results with topological restrictions of
acyclicity and symmetry. Section 6 introduces a topological property called t-self-
defense and preservation results for admissibility with t-self-defense. Section 7
concludes the paper.

Collective Argumentation with Topological Restrictions
81
2
Argumentation Framework and Topological Property
An argumentation framework is a pair AF = ⟨Arg, ⇀⟩, in which Arg is a set
of arguments and ⇀is a set of binary relations called the attack relation built
on Arg. Given two arguments A, B ∈Arg, A ⇀B if and only if A attacks
B. Given a set of arguments Δ ⊆Arg, we say that Δ is conﬂict-free if there
are no arguments A, B ∈Arg such that A ⇀B is the case; we say that Δ
defends A ∈Arg if for every argument B ∈Arg with B ⇀A is the case, there
is an argument C ∈Δ such that C ⇀B; we say that Δ is self-defending if Δ
defends every argument in Δ; we say that Δ is admissible if Δ is conﬂict-free
and self-defending; furthermore, we say that:
– Δ is complete if Δ is admissible and every argument defended by Δ is included
in Δ.
– Δ is grounded if Δ is the minimal complete extension (w.r.t. set inclusion)
– Δ is preferred if Δ is a maximal admissible set (w.r.t. set inclusion)
– Δ is stable if Δ is conﬂict-free and attacks every argument that is not in Δ.
A semantics deﬁnes which set of arguments can be accepted, which can be
considered as a property of sets of arguments. We now present another fam-
ily of properties considered in the literature in abstract argumentation, namely
topological properties of argumentation frameworks. While topological proper-
ties of argumentation frameworks have no immediately apparent relationships
with argumentation semantics, they play an important role in the study of such
semantics. As early as in the seminal paper by Dung [16], well-foundedness has
been identiﬁed as a topological properties and has been shown that it is a suﬃ-
cient condition for agreement among grounded, preferred, and stable semantics,
namely the grounded extension is the only preferred and stable extension.
Deﬁnition 1. An argumentation framework is well-founded if and only if there
exists no inﬁnite sequence A0, A1, · · · , An of arguments such that for each i,
Ai+1 ⇀Ai is the case.
In the case of a ﬁnite argumentation framework, well-foundedness coincides with
acyclicity of the attack relation.
Deﬁnition 2. An argumentation framework AF = ⟨Arg, ⇀⟩is coherent if every
preferred extension of AF is stable.
The absence of odd-length cycles is a suﬃcient condition to ensure that the
argumentation framework is coherent, i.e., ensure that stable extensions exist
and coincide with preferred extensions.
Deﬁnition 3. An argumentation framework AF = ⟨Arg, ⇀⟩is a symmetric
argumentation framework if ⇀is symmetric, nonempty and irreﬂexive.
In other words, an argumentation framework AF = ⟨Arg, ⇀⟩is symmetric if
for any pair of argument A, B ∈Arg with A attacks B is the case, then B will
be counter-attacked by A.

82
W. Chen
Other topological properties of argumentation frameworks in the literature
include antisymmetry (i.e., the absence of mutual attack between arguments),
directionality property, introduced in [4], SCC-recursiveness property, introduced
in [5], almost determinedness property, introduced in [3], as well as limited con-
troversy introduced by Dung in his seminal work [17].
3
The Aggregation Model
Fix a set of arguments Arg as well as a set of agents N = {1, · · · , n}, suppose
that each agent provides an argumentation framework, reﬂecting her individual
views on the status of possible attacks between arguments. Thus, we are given
a proﬁle of attack-relations ⇀= (⇀1, . . . , ⇀n). Sometimes we may want to
aggregate individual argumentation frameworks to obtain a single argumenta-
tion framework that reﬂects the consensus of the group, what would be a good
method to arrive at this goal? In this paper, we focus on the method from social
choice theory, an aggregation rule is a function that maps any given proﬁle of
attack-relations into a single attack-relation F : (2Arg×Arg)n →2Arg×Arg. We use
N ⇀
att := {i ∈N | att ∈(⇀i)} to denote the set of supporters of the attack att in
proﬁle ⇀.
Now we present several intuitively desirable property of aggregation rules.
Such properties are called axioms in the literature on social choice theory [1].
All of these axioms are adapted of axioms formulated in the literature on graph
aggregation [18] and have been deﬁned in the work by Chen and Endriss [12].
Deﬁnition 4. An aggregation rule is said to be neutral if N ⇀
att = N ⇀
att′ implies
att ∈F(⇀) ⇔att′ ∈F(⇀) for all proﬁles ⇀and all attacks att, att′.
Deﬁnition 5. An aggregation rule is said to be independent if N ⇀
att = N ⇀′
att
implies att ∈F(⇀) ⇔att ∈F(⇀) for all attacks att and all proﬁles ⇀, ⇀′.
Deﬁnition 6. An aggregation rule is said to be unanimous if F(⇀) ⊇(⇀1)
∩· · · ∩(⇀n) is the case for all proﬁles ⇀= (⇀1, . . . , ⇀n).
Deﬁnition 7. An aggregation rule is said to be grounded if F(⇀) ⊆(⇀1) ∪
· · · ∪(⇀n) is the case for all proﬁles ⇀= (⇀1, . . . , ⇀n).
Thus, an aggregation rule is neutral if two attacks receive the same votes
in a proﬁle, then the acceptance status of them are the same in the outcome,
i.e., attacks are treated symmetrically; an aggregation rule is independent if the
acceptance of an attack only depends on its supporters; unanimity assumes that
if an attack is accepted by everyone, then it should be accepted in the collective
outcome; groundedness postulates that only attacks with at least one supporter
can be collective accepted.
Two special families of aggregation we consider in this paper are the quota
rules and the dictatorship rules. All of them are simple rules that are adaptations
from other parts of social choice theory, such as judgment aggregation [19] and
graph aggregation [18]. Notably, all of them are well deﬁned in [12].

Collective Argumentation with Topological Restrictions
83
Deﬁnition 8. Let q ∈{1, . . . , n}. The quota rule Fq with quota q accepts all
those attacks that are supported by at least q agents:
Fq(⇀) = {att ∈Arg × Arg | #N ⇀
att ⩾q}
The majority rule is the quota rule Fq with q = ⌈n+1
2 ⌉. Two further quota
rules are also of special interest. The unanimity rule only accepts attacks that
are supported by everyone, i.e., this is Fq with q = n. The nomination rule is
the quota rule Fq with q = 1. Despite being a somewhat extreme choice, the
nomination rule has some intuitive appeal in the context of argumentation, as
it reﬂects the idea that we should take seriously any conﬂict between arguments
raised by at least one member of the group.
Deﬁnition 9. The dictatorship rule FDi of dictator i ∈N accepts all those
attacks that are accepted by agent i:
FDi(⇀) = ⇀i
Thus, under a dictatorship, to compute the outcome, we simply copy the
attack-relation of the dictator. Intuitively speaking, dictatorships in particular,
are unattractive rules, as they unfairly exclude everyone except i from the deci-
sion process.
We consider the preservation of semantic properties of argumentation frame-
works. An AF-property P ⊆2Arg×Arg is the set of all attack-relations on Arg that
satisfy P, we denote it by P(⇀). For example, non-emptiness of the grounded
extension is a simple semantic property, an AF satisﬁes such property if there is
at least one argument that is not attacked by any argument in AF.
Deﬁnition 10 (Preservation). Fix a ﬁnite set Arg of arguments and a set
of N = {1, · · · , n} agents. Suppose that each agent provides an argumentation
framework, which reﬂects her individual views on the status of possible attacks
between arguments. An aggregation rule F is said to preserve a property P if for
every proﬁle ⇀it is the case that P(⇀i) being the case for all agents i ∈N
then P(F(⇀)).
Thus, in the case where all agents’ attack-relations satisfy P, F preserves P
if the outcome of F satisﬁes P as well. The AF-properties we will discuss in this
paper include conﬂict-freeness, admissibility, being an extension under a speciﬁc
semantics, non-emptiness of the grounded extension, and coherence. Conﬂict-
freeness is a AF-property which requires that, if for all sets Δ ⊆Arg, whenever Δ
is conﬂict-free in ⟨Arg, ⇀i⟩for all agents i ∈N, we would like that Δ is conﬂict-
free in ⟨Arg, F(⇀)⟩. If it is the case, then we say that F preserves conﬂict-
freeness. The AF-property of admissibility can be deﬁned in the same way. Being
an extension under a speciﬁc semantics require that, given a set of arguments Δ,
Δ is an extension of a given semantics in ⟨Arg, ⇀i⟩for all agents i ∈N, then Δ
is also an extension of the semantics of ⟨Arg, F(⇀)⟩. Finally, coherence is also an
attractive properties, because-if satisﬁed by an argumentation framework-they

84
W. Chen
ensure that preferred and stable extensions will coincide and result in the same
recommendations about which arguments to accept, thereby making decisions
less controversial. It is worth noting that topological properties are a special
subset of AF-properties.
4
Topological Restriction
In this section, I introduce the notion of topological restriction for the aggrega-
tion of attack-relations of argumentation frameworks. What are the intuitions
behind this notion? First, while it is easy to verify that most semantic properties
cannot be preserved by the majority rule1, we cannot get things going for any
aggregation rule that satisﬁes desirable axiomatic requirements. As an example,
we present the following impossibility theorem.
Theorem 1 (Chen and Endriss, 2019). For |Arg| ⩾5, any unanimous,
grounded, and independent aggregation rule F that preserves either complete or
preferred extensions must be a dictatorship.
To prove Theorem 1, Chen and Endriss have used a technique developed by
Endriss and Grandi for the more general framework of graph aggregation, which
in turn was inspired by the seminal work on preference aggregation of Arrow [2].
Clearly, Theorem 1 is an impossibility result. At the heart of Theorem 1 (as well
as other impossibility results), there are three types of conditions: axioms of
aggregation rules, semantic properties of argumentation frameworks, as well as
argumentation frameworks allowed to input. To cope with such negative results,
one direction is relaxing such conditions, requirements, or argumentation frame-
works allowed.
Before going any further, we recall approaches that aim to deal with impos-
sibility results in the literature on social choice theory. In the literature on judg-
ment aggregation, there is an approach that proposes to restrict the range of
agendas, namely restricting the range of agendas on which we can perform sat-
isfactorily with aggregation rules. Another approach in judgment aggregation
is domain restriction, namely restricting the proﬁles allowed to input. Intro-
duced by List [20], unidimensional alignment is a widely known way of domain
restriction. The idea of unidimensional alignment is that only proﬁles which are
unidimensionally aligned are allowed to the aggregation rule. Value restriction
is another type of domain restriction, for which the idea was ﬁrst introduced
by Sen [22] for preference aggregation and later generalized by Dietrich and
List [15] for judgment aggregation. They show that if a proﬁle is value-restricted
in the sense that for every minimal inconsistent subset X of the agenda, there
exists two formulas ϕ, ψ ∈X such that no agent accepts both ϕ and ψ, then the
outcome of the majority rule will be consistent (meaning that no p and ¬p get
accepted at the same time).
1 A notable exception is conﬂict-freeness, which can be preserved by the majority
rule [12].

Collective Argumentation with Topological Restrictions
85
Fig. 1. Example for a proﬁle with Arg = {A, B, C, D}.
Recently, Chen considers value-restriction during the aggregation of exten-
sions of AFs [10]. He assumes that individual agents choose diﬀerent extensions
when confronted with the same abstract argumentation framework and study
the preservation of properties of extensions. Chen uses a formula Γ to describe
such a property of extensions, and refers to Γ as an integrity constraint. He
shows that if for every prime implicates π of the integrity constraint Γ of a
given semantic properties, there exists two distinct literals such that no agent
rejects both, then the majority rule preserves admissible outcomes [10].
I propose to restrict the input of the aggregation rule in the sense that only
argumentation frameworks with the speciﬁc feature are allowed to the aggrega-
tion rule. In the work by Chen and Endriss in which the model is the one we
adopt in this paper, there is no restriction made to the argumentation frame-
works put forward by individual agents. While there are many argumentation
frameworks that contain undesirable features, it is very natural to restrict the
inputs to the family of argumentation frameworks without such features.
Deﬁnition 11. A proﬁle ⇀= (⇀1, . . . , ⇀n) is topological-restricted with
respect to a constraint Γ if and only if ⇀i satisﬁes Γ for all i ∈N.
Thus, given a constraint Γ which is a topological property of argumentation
frameworks, a proﬁle is topological-restricted with respect to Γ if every individ-
ual argumentation framework satisﬁes Γ. When we perform aggregation on the
proﬁle, only argumentation frameworks satisfying Γ are allowed to aggregation
rules. While most preservation results of demanding properties are negative [12],
possible results may be obtained when restrictions are imposed. Consider the fol-
lowing example:
Example 1. Let us consider an example that illustrates the preservation of
acyclicity with majority. Recall that the majority includes an attack if and only
if a majority of the individual agents do. Consider three agents for which the
ﬁrst one supports A ⇀B and B ⇀C, the second supports B ⇀C and C ⇀A,
and the third supports C ⇀A and A ⇀B. Clearly, every individual argumen-
tation framework in this proﬁle satisﬁes acyclicity. If we apply this rule to the
proﬁle shown in Fig. 1, then we obtain the argumentation framework that con-
tains three attacks A ⇀B, B ⇀C, and C ⇀A, which forms a cycle, violating
acyclicity. But if no individual agent supports A ⇀B, for example, acyclicity

86
W. Chen
will be preserved in this case. Thus, we can think that rejecting A ⇀B is a
topological restriction Γ. If a proﬁle is topological-restricted with respect to Γ,
the majority rule preserves acyclicity in this speciﬁc case.
Example 1 cares only about a speciﬁc proﬁle. We now present a proposition
which is more concrete, showing that if a proﬁle is topological-restricted with
respect to a constraint Γ, then every plausible aggregation rule preserves an
AF-property. The AF-property is the nonemptiness of the grounded extension.
Here we recall the work by Chen and Endriss, who present a preservation result
for nonemptiness of the grounded extension.
Theorem 2 (Chen and Endriss, 2019). If |Arg| ⩾n, then under any neutral
and independent aggregation rule F that preserves nonemptiness of the grounded
extension at least one agent must have veto powers.
Proposition 1. Let Γ be a topological property that requires that there is an
argument A ∈Arg that is unattacked in ⇀i for all i ∈N. Given a proﬁle
⇀= (⇀1, . . . , ⇀n) which is topological-restricted with respect to Γ, then every
aggregation rule that is grounded preserves the nonemptiness of the grounded
extension.
Proof. Let F be the aggregation rule that is grounded. Consider a proﬁle of
attack-relations ⇀= (⇀1, · · · , ⇀n). Suppose that A ∈Arg is an unattacked
argument in ⇀i for all i ∈N. Clearly, as F is grounded, i.e., F(⇀) ⊆⇀1
∪, · · · , ∪⇀n, no argument attacks A in F(⇀).
Thus, a positive result is obtained when the proﬁle is topological-restricted with
respect to a topological property that is weak and easy to satisfy. Proposition 1
provides a clue on how to overcome negative results during aggregation. In the
following section, we study more topological restrictions, including notable topo-
logical properties in the literature, such as acyclicity, symmetry, as well as t-self-
defense, a newly deﬁned topological property, and we are going to show that the
majority rule is well behaved with it.
5
Preservation Results with Topological Restrictions
In this section, we present preservation results for AF-properties with topological
restrictions. The topological restrictions include acyclicity and symmetry. Most
of our results have the following form: there is an aggregation rule preserving
an AF-property, and the AF-property coincides with the second AF-property,
if a proﬁle of argumentation frameworks whose members satisfy a topological
restriction, then the preservation result for one semantics can be extended to
another.

Collective Argumentation with Topological Restrictions
87
5.1
Acyclicity
Acyclicity is an important property of argumentation frameworks. As we have
mentioned in previous sections, if an argumentation framework is acyclic, then
it contains a single extension which is the only complete, preferred and stable
extension.
Deﬁnition 12. A proﬁle ⇀= (⇀1, · · · , ⇀n) is topological-restricted with
respect to acyclicity if ⇀i is acyclic for all i ∈N.
Thus, a proﬁle is topological-restricted with respect to acyclicity if every argu-
mentation framework in the proﬁle satisﬁes acyclicity.
Fact 3. In the case of a ﬁnite argumentation framework, well-foundedness coin-
cides with acyclicity of the attack relation.
Theorem 4 (Dung, 1995).
Every acyclic argumentation framework has
exactly one complete extension which is grounded, preferred and stable.
Proposition 2 (Chen and Endriss, 2019). The nomination rule preserves
stable extensions.
Fact 5. Every stable extension is preferred and complete.
We now present a preservation results for preferred and complete extensions
with topological restrictions. The preservation of both AF-properties has been
discussed in-depth by Chen and Endriss in [12], who show that the preservation
of extensions of either preferred or complete semantics is impossible by means
of a “simple” aggregation rule (a rule that satisﬁes three “fair” axioms), unless
the rule in use is a dictatorship.
Theorem 6 (Chen and Endriss, 2019). For |Arg| ⩾5, any unanimous,
grounded, and independent aggregation rule F that preserves either preferred or
complete extensions must be a dictatorship.
Proposition 3. For any proﬁle of attack-relations ⇀= (⇀1, · · · , ⇀n), if ⇀
is topological-restricted with respect to acyclicity, then the nomination rule pre-
serves preferred and complete extensions.
Proof. Let F be the nomination rule. Suppose that Δ ⊆Arg be the set of
arguments that is preferred or complete in ⇀i for all i ∈N. According to
Theorem 4, Δ is stable in ⇀i for all i ∈N. Thus, as F preserves stable extensions,
Δ is stable in F(⇀). By the fact that every stable extension is preferred and
complete, we get that Δ is preferred or complete in F(⇀), we are done.

88
W. Chen
5.2
Symmetry
In this section, we consider the topological restriction of symmetry.
Deﬁnition 13. An argumentation framework AF = ⟨Arg, ⇀⟩is a symmetric
argumentation framework if ⇀is symmetric, nonempty and irreﬂexive.
Before going any further, we present a result regarding the preservation of
conﬂict-freeness in [12], which shows that every plausible aggregation rule pre-
serves it.
Theorem 7 (Chen and Endriss, 2019).
Every aggregation rule F that is
grounded preserves conﬂict-freeness.
We also present a result concerning the relation between admissibility and
conﬂict-freeness in [14], which shows that admissible sets and conﬂict-free sets
coincide in symmetric argumentation frameworks.
Proposition 4 (Coste-Marquis et al., 2005).
Let AF = ⟨Arg, ⇀⟩be a
symmetric argumentation framework, a set of arguments Δ ∈Arg is admissible
if and only if it is conﬂict-free.
Deﬁnition 14. A proﬁle ⇀= (⇀1, · · · , ⇀n) is topological-restricted with
respect to symmetry if ⇀i is symmetric for all i ∈N.
With Theorem 7 and Proposition 4, we are ready to present a preservation
result for admissibility with topological restrictions.
Theorem 8. For any proﬁle of attack-relations ⇀= (⇀1, · · · , ⇀n), if ⇀is
topological-restricted with respect to symmetry, then every aggregation rule that
is grounded and neutral preserves admissibility.
Proof. Consider a proﬁle of attack-relations ⇀= (⇀1, · · · , ⇀n). Let F be an
aggregation rule that is grounded and neutral. Let Δ ⊆Arg be a set of arguments
that is admissible in ⇀i for all i ∈N. Clearly, Δ is conﬂict-free ⇀i for all i ∈N.
As F preserves conﬂict-freeness (cf. Theorem 7), we get that Δ is conﬂict-free in
F(⇀). According to neutrality of F and the fact that the proﬁle is topological-
restricted with respect to symmetry, for every pair of arguments A, B ∈Arg,
A ⇀B and B ⇀A are treated symmetrically, and they receive the same votes,
i.e., if A ⇀B get accepted by F, so does B ⇀A. Thus, F(⇀) is symmetric.
Combining with Proposition 4, we get that Δ is admissible in F(⇀), we are
done.
Proposition 5 (Coste-Marquis et al., 2005).
Every symmetric argumen-
tation framework is coherent.
Recall that coherence is a property that ensures that the stable and the
preferred semantics coincide. It is deﬁned as the AF-property of every preferred
extension being a stable extension. We say that an aggregation rule F preserves
coherence if it is the case that, whenever ⟨Arg, ⇀i⟩is coherent for all i ∈N,
then F(⇀) is coherent. Chen and Endriss [12] have shown that preservation of
coherence is impossible unless we use dictatorships.

Collective Argumentation with Topological Restrictions
89
Theorem 9 (Chen and Endriss, 2019). For |Arg | ⩾4, any unanimous,
grounded, and independent aggregation rule F that preserves coherence must be
a dictatorship.
When the proﬁle under consideration is topological-restricted with respect to
symmetry, the impossibility result can be avoided.
Proposition 6. For any proﬁle of attack-relations ⇀= (⇀1, · · · , ⇀n), if ⇀
is topological-restricted with respect to symmetry, then any aggregation rule that
is grounded and neutral preserves coherence.
Proof. Let F be an aggregation rule that is grounded and neutral. Consider a
pair of arguments A, B ∈Arg as well as the attacks A ⇀B, B ⇀A between
them. According to the fact that ⇀is a proﬁle that is topological-restricted with
respect to symmetry and the fact that F is an aggregation rule that is grounded
and neutral, we get that A ⇀B and B ⇀A receive the same votes and they
are treated symmetrically by F. Thus, if A ⇀B get accepted, then B ⇀A
get accepted as well. As a consequence, F(⇀) is a symmetric argumentation
framework. Together with Proposition 5, we get that F(⇀) is coherent.
Recall that Theorem 1 has shown that only dictatorships preserve preferred
extensions. Interestingly, with the topological restriction of symmetry, we obtain
a much more positive result.
Theorem 10. For any proﬁle of attack-relations ⇀= (⇀1, · · · , ⇀n), if ⇀is
topological-restricted with respect to symmetry, then the nomination rule pre-
serves preferred extensions.
Proof. Let F be the nomination rule. Suppose that Δ ⊆Arg is a set of arguments
that is preferred in ⇀i for all i ∈N. According to Proposition 5, Δ is stable in
⇀i for all i ∈N. Thus, as F preserves stable extensions (cf. Proposition 2), Δ
is stable in F(⇀). By the fact that every stable extension is preferred, we get
that Δ is preferred in F(⇀), we are done.
6
The Majority Rule and Topological Restrictions
In this section, we focus on the preservation of semantic properties with topo-
logical restrictions. The aggregation rule we pay particular attention to is the
majority rule. We ﬁrst show that the majority rule does not preserve admis-
sibility, a property at the heart of all classical semantics. Then, we deﬁne a
topological property, followed by a result that shows that if a proﬁle of attack-
relations is topological-restricted with respect to the property, then the majority
rule preserves admissibility during aggregation.
Example 2. Consider the proﬁle illustrated in Fig. 2, {A1, A2, A3, C} is admis-
sible in every individual’s argumentation framework, but it is not admissible
in the outcome of the majority rule. Thus, the majority rule does not preserve
admissibility.

90
W. Chen
Fig. 2. Scenarios used in Example 2.
Next, we introduce the notion of the union of attack-relations of proﬁles of
attack-relations.
Deﬁnition 15. Given a proﬁle ⇀= (⇀1, . . . , ⇀n), we denote the union of
attack-relations of ⇀by ⇀u, i.e., ⇀u = ⇀i ∪· · · ∪⇀n.
In other words, the union of attack-relations of a proﬁle if it includes those
attacks that accepted by at least one agent. For instance, in Example 2, ⇀u=
{A1 ⇀B, A2 ⇀B, A3 ⇀B, B ⇀C}.
Deﬁnition 16. Given a proﬁle of attack-relations ⇀= (⇀1, . . . , ⇀n). We say
that ⇀is topological-restricted with respect to t-self-defense if for every attack
B ⇀C ∈⇀u whose attacker B has two or more attackers in ⟨Arg, ⇀u⟩, for
every pair of attackers Ai, Aj of B no agent rejects both Ai ⇀B and Aj ⇀B.
In other words, for every attack att = B ⇀C ∈⇀u, we denote the attackers
of B by A1, · · · , Ak with k ⩾2, i.e., A1 ⇀B, · · · , Ak ⇀B ∈⇀u, there are at
least two attackers Ai and Aj of B for which no agent rejects both Ai ⇀B and
Aj ⇀B.
Theorem 11. If the number of agents is odd, then for any proﬁle of attack-
relations ⇀= (⇀1, · · · , ⇀n), if ⇀is a proﬁle that is topological-restricted with
respect to t-self-defense, then the majority rule preserves admissibility.
Proof. Assume that Δ ⊆Arg is admissible in ⇀i for all i ∈N. Let F be the
majority rule. According to Theorem 7, Δ is conﬂict-free in F(⇀). It remains to
show that Δ is self-defending in F(⇀). To arrive at this goal, we need to show
that for every argument C ∈Δ, if C is attacked by some argument B, then B
is attacked by some argument in Δ in the outcome of the majority rule.
Suppose that B ⇀C ∈F(⇀) is the case, then B ⇀C ∈⇀u. If B has only
one attacker in ⟨Arg, ⇀u⟩, and we denote it by A, then any agent who supports
B ⇀C would be required to support A ⇀B, meaning that the majority of
agents support A ⇀B. Thus, in this scenario, B ⇀C and A ⇀B receive the
same votes, which is also a majority of supports from agents. If A /∈Δ, then
Δ is not self-defending in such agents’ argumentation frameworks, contradicting
our earlier assumption. Thus, A ∈Δ, meaning that C is defended by Δ.

Collective Argumentation with Topological Restrictions
91
Fig. 3. Scenarios used in Example 3.
If B has two or more attackers in ⟨Arg, ⇀u⟩, we denote the attackers of B by
A1, · · · , Ak. According to the assumption that ⇀is topological-restricted with
respect to t-self-defense, for every pair of attackers Ai and Aj of B, no agent
rejects both Ai ⇀B and Aj ⇀B. We now show that C is defended by Δ
in F(⇀). If there are two or more arguments in A1, · · · , Ak that are included
in Δ, we take two of them and denote by Ai and Aj. Clearly, one of Ai ⇀B
and Aj ⇀B is supported by the majority of agents. Thus, A is defended by Δ
in F(⇀). If there is only one argument in A1, · · · , Ak that is included by Δ,
and we denote it by Ai. Clearly, Ai ⇀B is supported by agents who support
B ⇀C, i.e., Ai ⇀B is accepted by F, meaning that C is defended by Δ in
F(⇀) as well. For the scenario that no argument in A1, · · · , Ak that is included
in Δ, we note that this is impossible as for agents who support B ⇀C, Δ is not
self-defending in their individual argumentation frameworks.
Let us come back to Example 2, the union of attack-relations of the pro-
ﬁle ⇀u= {A1 ⇀B, A2 ⇀B, A3 ⇀B, B ⇀C}. Clearly, the proﬁle is not
topological-restricted with respect to t-self-defense as B ⇀C, whose attacker B
has three attackers, and for every pair of attackers of B in ⟨Arg, ⇀u⟩there is at
least one agent who rejects both.
Example 3. Now we consider the proﬁle illustrated in Fig. 3, in which ⇀1=
{A1 ⇀B, A2 ⇀B}, ⇀2= {A2 ⇀B, A3 ⇀B}, ⇀3= {A3 ⇀B, A1 ⇀B}
and we want to know whether {A1, A2, A3, C} is admissible if the outcome
of the majority rule. Clearly, the proﬁle is topological-restricted with respect
to t-self-defense. We can see that the union of attack-relations of the proﬁle
⇀u= {A1 ⇀B, A2 ⇀B, A3 ⇀B, B ⇀C}, and for every attack in B ⇀C, for
example, for every pair of attackers A1, A2, for example, no agent rejects both
A1 ⇀B and A2 ⇀B. While {A1, A2, A3, C} is admissible in every individual
agent’s argumentation framework, it is also admissible in the outcome of the
majority rule, as expected.

92
W. Chen
7
Conclusion
In this paper, we have studied the preservation of semantic properties during
the aggregation of argumentation frameworks with topological restrictions. The
topological restrictions we consider in this paper include acyclicity, symmetry, as
well as t-self-defense, and the semantic properties we consider include conﬂict-
freeness, admissibility, being an extension under a speciﬁc semantics, nonempti-
ness of the grounded extension and coherence. Compared to the preservation
results for several semantic properties by Chen and Endriss without restrictions
showing that only dictatorships preserve them, there are aggregation rules that
have some intuitive appeal preserve them with topological restrictions. When
the restriction under consideration is t-self-defense, we can even preserve admis-
sibility under the majority rule.
Acknowledgments. I would like to thank three anonymous reviewers of CLAR-2020
for their helpful comments. This work was supported by the China Postdoctoral Science
Foundation Grant (No. 2019M663352) and the Key Project of National Social Science
Foundation of China (No. 16AZX017).
References
1. Arrow, K.J., Sen, A.K., Suzumura, K. (eds.): Handbook of Social Choice and Wel-
fare. North-Holland (2002)
2. Arrow, K.J.: Social Choice and Individual Values, 2nd edn. Wiley, Hoboken (1963).
First edition published in 1951
3. Baroni, P., Giacomin, M.: Characterizing defeat graphs where argumentation
semantics agree. In: Proceedings of the 1st International Workshop on Argumen-
tation and Non-Monotonic Reasoning (ARGNMR07), pp. 33–48 (2007)
4. Baroni, P., Giacomin, M.: On principle-based evaluation of extension-based argu-
mentation semantics. Artif. Intell. 171(10–15), 675–700 (2007)
5. Baroni, P., Giacomin, M., Guida, G.: SCC-recursiveness: a general schema for
argumentation semantics. Artif. Intell. 168(1–2), 162–210 (2005)
6. Baumeister, D., Neugebauer, D., Rothe, J.: Collective acceptability in abstract
argumentation. J. Appl. Log. 2631(6), 1503 (2021)
7. Bodanza, G.A., Tohm´e, F.A., Auday, M.R.: Collective argumentation: a survey
of aggregation issues around argumentation frameworks. Argument Comput. 8(1),
1–34 (2017)
8. Caminada, M., Pigozzi, G.: On judgment aggregation in abstract argumentation.
J. Auton. Agents Multiagent Syst. 22(1), 64–102 (2011)
9. Chen, W.: Collective argumentation: the case of aggregating support-relations of
bipolar argumentation frameworks. In: Proceedings of the 18th Conference on The-
oretical Aspects of Rationality and Knowledge (TARK), pp. 87–102 (2021)
10. Chen, W.: Guaranteeing admissibility of abstract argumentation frameworks with
rationality and feasibility constraints. J. Log. Comput. (2021, to appear). https://
doi.org/10.1093/logcom/exab011
11. Chen, W., Endriss, U.: Aggregating alternative extensions of abstract argumenta-
tion frameworks: preservation results for quota rules. In: Proceedings of the 7th
International Conference on Computational Models of Argument (COMMA). IOS
Press (2018)

Collective Argumentation with Topological Restrictions
93
12. Chen, W., Endriss, U.: Preservation of semantic properties in collective argumen-
tation: the case of aggregating abstract argumentation frameworks. Artif. Intell.
269, 27–48 (2019)
13. Coste-Marquis, S., Devred, C., Konieczny, S., Lagasquie-Schiex, M.C., Marquis,
P.: On the merging of Dung’s argumentation systems. Artif. Intell. 171(10–15),
730–753 (2007)
14. Coste-Marquis, S., Devred, C., Marquis, P.: Symmetric argumentation frame-
works. In: Godo, L. (ed.) ECSQARU 2005. LNCS (LNAI), vol. 3571, pp. 317–328.
Springer, Heidelberg (2005). https://doi.org/10.1007/11518655 28
15. Dietrich, F., List, C.: Majority voting on restricted domains. J. Econ. Theory
145(2), 512–543 (2010)
16. Dung, P.M.: On the acceptability of arguments and its fundamental role in non-
monotonic reasoning, logic programming and n-person games. Artif. Intell. 77(2),
321–358 (1995)
17. Dung, P.M., Mancarella, P., Toni, F.: Computing ideal sceptical argumentation.
Artif. Intell. 171(10), 642–674 (2007)
18. Endriss, U., Grandi, U.: Graph aggregation. Artif. Intell. 245, 86–114 (2017)
19. Grossi, D., Pigozzi, G.: Judgment Aggregation: A Primer. Synthesis Lectures on
Artiﬁcial Intelligence and Machine Learning. Morgan & Claypool Publishers (2014)
20. List, C.: A possibility theorem on aggregation over multiple interconnected propo-
sitions. Math. Soc. Sci. 45(1), 1–13 (2003)
21. Rahwan, I., Tohm´e, F.A.: Collective argument evaluation as judgement aggrega-
tion. In: Proceedings of the 9th International Conference on Autonomous Agents
and Multiagent Systems (AAMAS), pp. 417–424. IFAAMAS (2010)
22. Sen, A.K.: A possibility theorem on majority decisions. Econometrica: J. Econo-
metric Soc. 491–499 (1966)
23. Tohm´e, F.A., Bodanza, G.A., Simari, G.R.: Aggregation of attack relations: a
social-choice theoretical analysis of defeasibility criteria. In: Hartmann, S., Kern-
Isberner, G. (eds.) FoIKS 2008. LNCS, vol. 4932, pp. 8–23. Springer, Heidelberg
(2008). https://doi.org/10.1007/978-3-540-77684-0 4

The Choice-Preferred Semantics
for Relevance-Oriented Acceptance
of Admissible Sets of Arguments
Marcos Cramer(B) and Yannick Sp¨orl
TU Dresden, Dresden, Germany
marcos.cramer@tu-dresden.de, yannick.spoerl@mailbox.tu-dresden.de
Abstract. In abstract argumentation, multiple argumentation seman-
tics for choosing sets of jointly acceptable arguments have been deﬁned.
In the principle-based approach, multiple principles have been proposed
and formalized in order to guide the choice for a semantics and the
search for new semantics. Admissibility is a central principle satisﬁed by
many semantics, including complete, stable, grounded and preferred. A
more recently introduced principle is the INRA principle, motivated by
considerations about the relevance of arguments and supported by a cog-
nitive study. This paper additionally introduces and motivates the SAF-
WOC principle in order to positively distinguish less abstention-friendly
semantics like preferred and stable from more abstention-friendly seman-
tics like grounded and complete. After observing that no existing seman-
tics satisﬁes these three principles, we deﬁne the novel choice-preferred
semantics that satisﬁes the three principles. Additionally we show that
choice-preferred satisﬁes further desirable principles like existence, direc-
tionality, SCC-recursiveness and completeness.
1
Introduction
The formal study of argumentation is an important ﬁeld of research within
AI [12]. A central focus of this ﬁeld has been the idea of Dung [9] that under
some conditions, the acceptance of arguments depends only on a so-called attack
relation among the arguments, and not on the internal structure of the argu-
ments. This approach is called abstract argumentation and the directed graph
that represents the arguments as well as the attack relation between them is
called an argumentation framework (AF). In general, whether an argument is
deemed acceptable depends on the decision about other arguments. Therefore
the basic concept in abstract argumentation is a set of arguments that can be
accepted together, called an extension. Crucially, there may be several of such
extensions, and these extensions may be incompatible. An extension-based argu-
mentation semantics takes as input an AF and produces as output a set of
extensions.
The fact that many argumentation semantics have been proposed in the liter-
ature naturally gives rise to the question how to choose between these semantics
c
⃝Springer Nature Switzerland AG 2021
P. Baroni et al. (Eds.): CLAR 2021, LNAI 13040, pp. 94–111, 2021.
https://doi.org/10.1007/978-3-030-89391-0_6

The Choice-Preferred Semantics for Relevance-Oriented Acceptance
95
for a given application as well as the question how to systematically search for
new semantics that might be even more suitable to a given application than any
of the semantics studied so far. Both of these questions are addressed by the
principle-based approach to abstract argumentation [2,13], in which semantics
are evaluated based on their satisfaction of various normatively desirable prin-
ciples. One prominent example of a principle satisﬁed by many of the widely
studied semantics is admissibility, according to which any extension should be
free of internal conﬂicts and should defend each of its arguments against all
outside attackers.
Cramer and van der Torre [7] have introduced the principle of Irrelevance
of Necessarily Rejected Arguments (INRA). Informally, INRA says that if an
argument is attacked by every extension of an AF, then deleting this argument
should not change the set of extensions. The idea here is that an argument that
is attacked by every extension would be rejected by any party in a debate, and
hence would never be brought up in a debate. Hence, it should be treated as
irrelevant to the debate, i.e. just like if it did not exist.
Cramer and van der Torre [7] deﬁned the novel SCF2 semantics, which satis-
ﬁes INRA as well as some further desirable properties, and which is additionally
supported by two empirical cognitive studies on argumentation semantics [5,6].
However, SCF2 does not satisfy admissibility. Among the widely studied seman-
tics satisfying admissibility, grounded and complete semantics satisfy INRA,
while preferred, stable and semi-stable do not.
Argumentation semantics can be broadly classiﬁed into the following two
groups depending on how they treat attack cycles of even length that are not
attacked from the outside: Some semantics, like complete, grounded, ideal and
eager, allow (or even require) that no argument is accepted from such an even
cycle, whereas other semantics, like preferred, stable, semi-stable, stage, CF2,
stage2 and SCF2 require every second argument in the cycle to be accepted.
Due to this feature, the semantics from the second class implement some form of
reasoning by cases for arguments attacked by multiple arguments from an even
cycle. While the semantics from the ﬁrst satisfy the principle Allowing Absten-
tions [13] and the semantics from the second class do not satisfy this principle,
so far no principle has been deﬁned to positively diﬀerentiate the semantcis
from the second class from the semantics of the ﬁrst class. For this purpose we
introduce and motivate the principle of Some Acceptance for Frameworks With-
out Odd Cycles (SAFWOC), which states that any argumentation framework
without odd attack cycles does not have the empty set among its extensions.
We observe that none of the widely studied argumentation semantics satis-
ﬁes the three principles Admissibility, INRA and SAFWOC. We therefore deﬁne
the new choice-preferred semantics that satisﬁes these three principles. Further-
more, we show that choice-preferred also satisﬁes existence, directionality, SCC-
recursiveness and completeness.

96
M. Cramer and Y. Sp¨orl
2
Preliminaries
In this section we deﬁne required notions from abstract argumentation theory
[1,9]. We deﬁne eleven argumentation semantics (including seven widely studied
admissibility-based semantics) as well as six principles from the literature on
principle-based argumentation [2,7,13].
Deﬁnition 1. An argumentation framework (AF) F = ⟨Ar, att⟩is a ﬁnite
directed graph in which the set Ar of vertices is considered to represent argu-
ments and the set att of edges is considered to represent the attack relation
between arguments, i.e. the relation between a counterargument and the argu-
ment that it counters.
Given an argumentation framework, we want to choose sets of arguments
for which it is rational and coherent to accept them together. Such a set of
arguments that may be accepted together is called an extension. Multiple argu-
mentation semantics have been deﬁned in the literature, i.e. multiple diﬀerent
ways of deﬁning extensions given an argumentation framework. Before we con-
sider speciﬁc argumentation semantics, we ﬁrst give a formal deﬁnition of the
notion of an argumentation semantics:
Deﬁnition 2. An argumentation semantics is a function σ that maps any AF
F = (Ar, att) to a set σ(F) ⊆2Ar. The elements of σ(F) are called σ-extensions
of F.
We usually deﬁne an argumentation semantics σ by specifying criteria which
a subset of Ar has to satisfy in order to be a σ-extension of F. In this paper we
consider the complete, grounded, preferred, semi-stable, ideal, eager, stable, stage,
CF2, stage2 and SCF2 semantics. The ﬁrst seven are based on the notion of
admissibility and are therefore called admissibility-based semantics. The last ﬁve
always choose extensions that are naive extensions, i.e. subset-maximal conﬂict-
free sets of arguments, which is why they are called naive-based semantics. Note
that the stable semantics is the only semantics that belongs to both categories
(at the price of not providing any extension at all in some scenarios). Apart
from these eleven semantics, we also deﬁne naive extensions and SCOOC-naive
extensions, as we need them for our deﬁnition of CF2 and SCF2 semantics respec-
tively.
Deﬁnition 3. An att-path is a sequence ⟨a0, . . . , an⟩of arguments where
(ai, ai+1) ∈att for 0 ≤i < n and where aj ̸= ak for 0 ≤j < k ≤n with either
j ̸= 0 or k ̸= n. An even att-cycle is an att-path ⟨a0, . . . , an⟩where a0 = an and
n is even; analogously for odd att-cycle. A simple unattacked cycle is an even or
odd cycle ⟨a0, . . . , an⟩in which ai+1 is only attacked by ai for every 1 ≤i ≤n.
Deﬁnition 4. Let F = ⟨Ar, att⟩be an AF, and let S ⊆Ar. We write F|S for
the restricted AF ⟨S, att ∩(S × S)⟩. The set S is called conﬂict-free iﬀthere are
no arguments b, c ∈S such that b attacks c (i.e. such that (b, c) ∈att). Argument

The Choice-Preferred Semantics for Relevance-Oriented Acceptance
97
a ∈Ar is defended by S iﬀfor every b ∈Ar such that b attacks a there exists
c ∈S such that c attacks b. The set S is called admissible iﬀit defends every
argument in S and there are no arguments b, c ∈S such that b attacks c. We say
that the set S attacks an argument a ∈Ar iﬀsome argument in S attacks a. We
deﬁne S+ = {a ∈Ar | S attacks a} and S−= {a ∈Ar | a attacks some b ∈S}.
We deﬁne S to be strongly complete outside odd cycles iﬀfor every argument
a ∈Ar, if no argument in {a} ∪{a}−is in an odd att-cycle and S ∩{a}−= ∅,
then a ∈S.
– S is a complete extension of F iﬀit is admissible and it contains all the
arguments it defends.
– S is a stable extension of F iﬀit is conﬂict-free and it attacks all the argu-
ments of Ar \ S.
– S is the grounded extension of F iﬀit is a subset-minimal complete extension
of F.
– S is a preferred extension of F iﬀit is a subset-maximal admissible extension
of F.
– S is a semi-stable extension of F iﬀit is an admissible extension and there
exists no admissible extension S1 such that S ∪S+ ⊂S1 ∪S+
1 .
– S is an ideal extension of F iﬀit is a subset-maximal admissible subset of
every preferred extension of F.
– S is an eager extension of F iﬀit is a subset-maximal admissible subset of
every semi-stable extension of F.
– S is a stage extension of F iﬀS is a conﬂict-free set and there exists no
conﬂict-free set S1 such that S ∪S+ ⊂S1 ∪S+
1 .
– S is a naive extension of F iﬀS is a subset-maximal conﬂict-free set.
– S is a SCOOC-naive extension iﬀS is subset-maximal among the conﬂict-free
subsets of Ar that are strongly complete outside odd cycles.
We also need the notion of skeptically accepting an argument:
Deﬁnition 5. Let F = ⟨Ar, att⟩be an AF, let σ be an argumentation semantics,
and let a ∈Ar. We say that a is skeptically accepted in F with respect to σ iﬀ
for every E ∈σ(F), a ∈E.
The idea behind CF2, stage2 and SCF2 semantics is that we partition the AF
into strongly connected components and recursively evaluate it, component by
component, using a procedure called the simpliﬁed SCC-recursive scheme. This
scheme was ﬁrst deﬁned in [3] and was ﬁrst presented as an abstract function in
the way we present it here in [7]. For deﬁning this scheme, we ﬁrst need some
auxiliary notions:
Deﬁnition 6. Let F = ⟨Ar, att⟩be an AF, and let a, b ∈Ar. We deﬁne a ∼b
iﬀeither a = b or there is an att-path from a to b and there is an att-path
from b to a. The equivalence classes under the equivalence relation ∼are called
strongly connected components (SCCs) of F. We denote the set of SCCs of F
by SCCs(F). Given S ⊆Ar, we deﬁne DF (S) := {b ∈Ar | ∃a ∈S : (a, b) ∈
att ∧a ̸∼b}.

98
M. Cramer and Y. Sp¨orl
Deﬁnition 7. Let σ be an argumentation semantics. The argumentation seman-
tics scc(σ) is deﬁned as follows. Let F = ⟨Ar, att⟩be an AF, and let S ⊆Ar.
Then S is an scc(σ)-extension of F iﬀeither
– |SCCs(F)| ≤1 and S is a σ-extension of F, or
– |SCCs(F)| > 1 and for each C ∈SCCs(F), S ∩C is an scc(σ)-extension of
F|C\DF (S).
We are now ready to present deﬁnitions of CF2 semantics [3], stage2 seman-
tics [10,11] and SCF2 semantics [7]:
Deﬁnition 8. We deﬁne CF2, stage2 and SCF2 semantics as follows:
– CF2 semantics is deﬁned to be scc(naive).
– stage2 semantics is deﬁned to be scc(stage).
– Given an AF F = ⟨Ar, att⟩, a set S ⊆Ar is called a SCF2 extension of F iﬀ
S is a scc(SCOOC-naive)-extension of F|Ar′, where Ar′ := {a ∈Ar | (a, a) /∈
att}.
We now turn towards deﬁning principles for abstract argumentation, i.e.
properties that argumentation semantics may or may not satisfy, and that have
been proposed as being desirable for some applications of abstract argumenta-
tion.
The ﬁrst principle is the admissibility principle introduced by Baroni and
Giacomin [2]. It states that for every framework, all of its extensions should be
admissible:
Deﬁnition 9. A semantics σ satisﬁes the admissibility principle iﬀfor every
AF F, every S ∈σ(F) is admissible in F.
The completeness principle is a strengthening of admissibility that requires
extensions to be complete extensions:
Deﬁnition 10. A semantics σ satisﬁes the completeness principle iﬀfor every
AF F, every S ∈σ(F) is a complete extension of F.
The principle of Irrelevance of Necessarily Rejected Arguments (INRA prin-
ciple) was introduced by Cramer and van der Torre [7]. It requires that if an
argument is attacked by every extension of an AF, then deleting this argument
should not change the set of extensions. In order to formally deﬁne the INRA
principle, we ﬁrst need to deﬁne a notation for an AF with one argument deleted:
Deﬁnition 11. Let F = ⟨Ar, att⟩be an AF and let a ∈Ar be an argument.
Then F−a denotes the restricted AF F|Ar\{a}.
Deﬁnition 12. A semantics σ satisﬁes Irrelevance of Necessarily Rejected
Arguments ( INRA) iﬀfor every AF F = ⟨Ar, att⟩and every argument a ∈Ar,
if every E ∈σ(F) attacks a, then σ(F) = σ(F−a).

The Choice-Preferred Semantics for Relevance-Oriented Acceptance
99
The idea here is that an argument that is attacked by every extension would
be rejected by any party in a debate, and hence would never be brought up in a
debate. Hence, it should be treated as irrelevant to the debate, i.e. just like if it
did not exist.
The existence principle requires that for every argumentation framework,
there exists at least one extension:
Deﬁnition 13. We say that a semantics σ satisﬁes the existence principle iﬀ
for every AF F, σ(F) ̸= ∅.
We now deﬁne the directionality principle introduced by Baroni and Gia-
comin [2]. For this, we ﬁrst need an auxiliary notion:
Deﬁnition 14. Let F = ⟨Ar, att⟩be an AF. A set U ⊆Ar is unattacked iﬀ
there exists no a ∈Ar \ U such that a attacks some b ∈U.
Deﬁnition 15. A semantics σ satisﬁes the directionality principle iﬀfor every
AF F and every unattacked set U, it holds that σ(F|U) = {E ∩U | E ∈σ(F)}.
We now deﬁne the principle of SCC-recursiveness [13]. We modify the word-
ing used by [13] a bit in order to make the deﬁnition formally more precise.
Intuitively this principle says that one can compute the extensions by ﬁrst
considering an unattacked SCC, compute the semantics on it, determine its
impact on other SCCs and then recursively continue this computation. In order
to formalize this intuition, we ﬁrst need three auxiliary deﬁnitions:
Deﬁnition 16. Given an argumentation framework F = (Ar, att) and sets
S, E
⊆
Ar, we deﬁne UF (S, E)
:=
{a ∈S
|
̸ ∃b
:
(b, a)
∈
att, b
̸∼
a and E does not attack b}.
Deﬁnition 17. A binary function BF is called a base function iﬀfor every AF
F = (Ar, att) such that |SCCs(F)| ≤1 and every set C ⊆Ar, BF(F, C) ⊆2Ar.
Deﬁnition 18. Given a base function BF, an AF F = (Ar, att) and a set C ⊆
Ar, we recursively deﬁne GF(BF, F, C) ⊆2Ar as follows: for every E ⊆Ar,
E ∈GF(BF, F, C) iﬀ
– in case |SCCs(F)| ≤1, E ∈BF(F, C),
– otherwise, for all S ∈SCCs(F), (E ∩S) ∈GF(BF, F|S\DF (E), UF (S, E)∩C).
Deﬁnition 19. A semantics σ satisﬁes the SCC-recursiveness principle iﬀthere
is a base function BF such that for every AF F = (Ar, att) we have σ(F) =
GF(BF, F, Ar).
Table 1 shows which semantics satisﬁes which principle. All results other
than those for the SCF2 row, the completeness column and the INRA column
are taken over from [13]. The SCF2 row is based on results from Cramer and
van der Torre [7], apart from the non-satisfaction of admissibility and com-
pleteness, which follows trivially from the fact that in SCF2 the 3-cycle AF

100
M. Cramer and Y. Sp¨orl
⟨{a, b, c}, {(a, b), (b, c), (c, a)}⟩has non-empty extensions {a}, {b} and {c}. For
the semantics other than SCF2, the completeness column is based on well-known
properties of those semantics. The INRA column is mostly taken over from The-
orems 1 and 2 of Cramer and van der Torre [7], with the exception of the cases
of the ideal and eager semantics. The fact that the ideal and eager semantics do
not satisfy INRA follows from the same counterexample as the one given in The-
orem 2 of Cramer and van der Torre [7] (this was pointed out by an anonymous
reviewer of this paper).
Table 1. Satisfaction of the principles deﬁned in this section by the semantics deﬁned
in this section
Admissibility
Completeness
INRA
Existence
Directionality
SCC-recursiveness
complete
✓
✓
✓
✓
✓
✓
stable
✓
✓
×
×
×
✓
grounded
✓
✓
✓
✓
✓
✓
preferred
✓
✓
×
✓
✓
✓
semi-stable
✓
✓
×
✓
×
×
ideal
✓
✓
×
✓
✓
×
eager
✓
✓
×
✓
✓
×
stage
×
×
×
✓
×
×
CF2
×
×
×
✓
✓
✓
stage2
×
×
×
✓
✓
✓
SCF2
×
×
✓
✓
✓
✓
3
A Novel Principle: SAFWOC
In this section we introduce a new principle called Some Acceptance for Frame-
works Without Odd Cycles (SAFWOC). In order to motivate this principle, let
us ﬁrst consider the argumentation framework F0 depicted in Fig. 1.
a
b
c
d
e
f
Fig. 1. Argumentation framework F0.
Here there are two preferred extensions: {a, c, f} and {b, d, f}. Note that
both of these extensions accept argument f, so that f is skeptically accepted
with respect to the preferred semantics. Intuitively, one can view the preferred

The Choice-Preferred Semantics for Relevance-Oriented Acceptance
101
semantics as coming to the conclusion f through a form of reasoning by cases:
In the 4-cycle ⟨a, b, c, d, a⟩, one has to either accept {a, c} or {b, d}. Either way,
e will be attacked by an accepted argument, so f will be defended and therefore
accepted. In this example, the stable, semi-stable, stage, CF2, stage2 and SCF2
semantics have the same extensions, so the same kind of reasoning by cases works
there.
In the grounded, ideal, eager and complete semantics, however, ∅is an exten-
sion (in grounded, ideal and eager semantics, ∅is the only extension; in com-
plete semantics the extensions are ∅together with the two preferred extensions).
Therefore f is not skeptically accepted with respect to these four semantics.
The problem here is that these semantics allow (and grounded, ideal and eager
semantics even require) that in a simple unattacked cycle like ⟨a, b, c, d, a⟩, no
argument should be accepted. This behavior of grounded and complete seman-
tics is certainly desirable for some applications, but for others it is desirable to
have at least one argument in an even cycle accepted, so that reasoning by cases
works as explained above.
Unattacked cycles of any even length will be treated similarly to the 4-cycle
in F0 in all eleven semantics considered in this paper (with some caveats in the
case of CF2; see [11]).
The fact that many argumentation semantics allow for this kind of reasoning
by cases over even cycles can be seen as a motivation for formulating a principle
that captures what these semantics have in common with respect to such reason-
ing. We want to state this principle in as general terms as possible, so ideally we
do not want to restrict ourselves just to even cycles. However, simple unattacked
odd cycles expose a diﬀerent behavior: Here no admissibility-based semantics
can accept any argument. Intuitively, simple unattacked odd cycles correspond
to paradoxical situations in which no defensible decision can be made.
Nevertheless, we can go beyond the case of even cycles: In preferred, stable,
semi-stable, stage, CF2, stage2 and SCF2 semantics, every argumentation frame-
work that does not involve any odd cycles will have at least one argument in
each extension. This motivates the introduction of the principle of Some Accep-
tance for Frameworks Without Odd Cycles (SAFWOC principle), which states
that any argumentation framework without odd attack cycles does not have the
empty set among its extensions:
Deﬁnition 20. Let F = (Ar, att) be an argumentation framework. A semantics
σ satisﬁes Some Acceptance for Frameworks Without Odd Cycles ( SAFWOC)
iﬀfor every AF F, if F contains no odd cycle then ∅/∈σ(F).
Even though the formal deﬁnition of SAFWOC is rather technical, it ulti-
mately rests on the important destinction between more skeptical semantics
without reasoning by cases like grounded, ideal, eager and complete on the one
hand and more credulous semantics with reasoning by cases like preferred, stable,
semi-stable, stage, CF2, stage2 and SCF2. In applications calling for a semantics
of the second kind, a semantics of the ﬁrst kind may be highly inappropriate.
The SAFWOC semantics is an attempt to formalize this distinction between

102
M. Cramer and Y. Sp¨orl
semantics, which has already been made informally by many people working on
abstract argumentation.
The SAFWOC principle can also be motivated by the desire to ensure that
as long as there is no paradoxical argumentation, a semantics should not support
complete absention, i.e. at least one argument should be accepted. The informal
notion of paradoxical argumentation is formalized here through the requirement
of having no odd cycles.
We now establish that preferred, stable, semi-stable, stage, CF2, stage2 and
SCF2 semantics satisfy SAFWOC, while complete, grounded, ideal and eager do
not.
Theorem 1. Preferred, stable, semi-stable, stage, CF2, stage2 and SCF2
semantics satisfy SAFWOC.
Proof. Let F = (Ar, att) be an argumentation framework such that F contains
no odd cycle. We ﬁrst show that there exists a non-empty admissible subset of
Ar.
Let S ∈SCCs(F) be an unattacked SCC of F. Choose a ∈S. Since F does
not contain any odd cycles, every element of S can be reached from a either only
through paths of even length or only through paths of odd length. Let A be the
set of all elements of S that are reachable from a through paths of even length.
Then clearly A is admissible.
Suppose for a contradiction that ∅∈preferred(F). Then ∅is subset-maximal
among the admissible sets. However, the admissible set A contradicts this max-
imality. So ∅/∈preferred(F).
A stable extension must attack all arguments not contained in it, so it cannot
be empty.
Suppose for a contradiction that ∅∈semi-stable(F). Since ∅∪∅+ = ∅, the
maximality condition in the deﬁnition of semi-stable implies that ∅is the only
admissible sets. However, the non-empty admissible set A contradicts this. So
∅/∈semi-stable(F).
Suppose for a contradiction that ∅∈stage(F). Let a ∈Ar. Since F contains
no odd cycle, it contains no self-attacks, so {a} is conﬂict-free. Furthermore,
{a} ∪{a}+ is non-empty, which is in contradiction with ∅∈stage(F) due to the
maximality condition in the deﬁnition of stage.
Suppose for a contradiction that ∅∈CF2(F). Let S be an unattacked SCC
of F. Then ∅is a naive extension of S. Given that F contains no self-attacks,
this is not possible.
Suppose for a contradiction that ∅∈stage2(F). Let S be an unattacked
SCC of F. Then ∅is a stage extension of S. Given what we showed about stage
semantics above, this is not possible.
Suppose for a contradiction that ∅∈SCF2(F). Let S be an unattacked
SCC of F. Then ∅is a SCOOC-naive extension of S. Given that F contains no
self-attacks, this is not possible.
⊓⊔
Theorem 2. Complete, grounded, ideal and eager semantics do not satisfy
SAFWOC.

The Choice-Preferred Semantics for Relevance-Oriented Acceptance
103
Proof. Consider the 2-cycle AF ⟨{a, b}, {(a, b), (b, a)}⟩. One can easily see that
∅is a complete, grounded, ideal and eager extension of this AF.
⊓⊔
4
Motivation for New Semantics
Most of the most widely studied argumentation semantics satisfy admissibility.
The same holds true for SAFWOC, as it is satisﬁed by preferred, stable, semi-
stable, stage, CF2, stage2 and SCF2 semantics. Furthermore, three very widely
studied semantics, namely preferred, stable and semi-stable, satisfy both of these
principles. For this reason it seems plausible to assume that these are principles
that are relevant to many applications of abstract argumentation.
The INRA principle has been introduced by Cramer and van der Torre [7].
They argued that this principle is plausible for determining what humans con-
sider a rational judgment on the acceptability of arguments. While some seman-
tics are known to satisfy INRA, none of the eleven semantics deﬁned in Sect. 2
satisﬁes INRA while also satisfying admissibility and SAFWOC. It seems desir-
able to ﬁll this gap by deﬁning a semantics that simultaneously satisﬁes admis-
sibility, SAFWOC and INRA.
In the next two sections, we will ﬁrst deﬁne the choice-preferred semantics
and then show that it does indeed satisfy these principles. Furthermore, we
will show that it also satisﬁes completeness, existence, directionality and SCC-
recursiveness, thus making it a semantics with multiple desirable properties.
5
Choice-Preferred Semantics
Before we formally deﬁne the choice-preferred semantics, we ﬁrst informally
explain and motivate its functioning, starting from considerations about an
example AF.
Consider the 2-3-cycle AF F1 depicted in Fig. 2. Note that here the only
preferred extension is {c}. So b is necessarily rejected, i.e. attacked by every
extension. But when we delete b, then we get a second extension, namely {a}.
Now the idea behind choice-preferred semantics is that in situations like these,
we want to ensure that b is not necessarily rejected by having the choice not to
reject b, i.e. by having an extension that does not attack b. In this case, the only
admissible set that does not attack b is the empty set, so we want the empty set
to be an extension.
More generally, we want to ensure that in any AF consisting of a single
SCC, no argument is strongly rejected. This way the INRA principle will be
trivially satisﬁed for such AFs. We then generalize this approach even further
by deﬁning the choice-preferred semantics through SCC-recursion, which will
lead to the INRA principle being satisﬁed even for AFs consisting of multiple
SCCs. In this case we can have strongly rejected arguments, but they will always
be attacked from a previous SCC, so that deleting them from the AF does not
change the SCC-recursive computation of the extensions.

104
M. Cramer and Y. Sp¨orl
a
b
c
Fig. 2. The 2-3-cycle AF F1
In order to ensure that no argument is strongly rejected in an AF consisting of
a single SCC, we allow for any argument a from the SCC to be chosen, and then
we choose a subset-maximal complete extension that does not attack a. There
always exists at least one such subset-maximal complete extension, because the
empty set is always a complete extension of the AF consisting of a single SCC.
Thus we always choose at least one extension that does not attack a, so a is not
strongly rejected.
After having given this informal motivation and explanation of the choice-
preferred semantics, we now deﬁne the semantics formally. Since we deﬁne it
through an SCC-recursion, we make use of the deﬁnition of GF(BF, F, C) from
Deﬁnition 18.
Deﬁnition 21. Let F = (Ar, att) be an AF. We deﬁne choice-preferred(F) :=
GF(BFcp, F, Ar), where the base function BFcp is deﬁned as follows: For every
E ⊆Ar, E ∈BFcp(AF, C) iﬀeither Ar = ∅and E = ∅or Ar ̸= ∅and there
is an a ∈Ar such that E is subset-maximal among the subsets of C that are
complete and do not attack a.
a
b
c
d
e
f
h
g
i
Fig. 3. A more complex argumentation framework F2
Example 1. Consider the AF F2 depicted in Fig. 3. We now explain how the
extensions of F2 can be computed in an SCC-recursive way. We start from the
initial SCC {a, b}, for which there are two extensions, {a} (because it is subset-
maximal among the complete extensions of F2|{a,b} that do not attack a) and
{b} (because it is subset-maximal among the complete extensions of F2|{a,b} that
do not attack b).

The Choice-Preferred Semantics for Relevance-Oriented Acceptance
105
– If we choose the extension {b} for the initial SCC, then c is attacked by b,
i.e. it is in the set DF2(E) of arguments that will be excluded from the AF in
the SCC-recursive computation of the semantics. Then {e} is an initial SCC,
so e will be accepted, thus excluding d and f from further consideration.
This makes {g} an initial SCC, leading to the acceptance of g, thus excluding
h from further consideration. So ﬁnally {i} becomes an inital SCC, so i is
accepted. In this way, we attain the extension {b, e, g, i}.
– If we choose the extension {a} for the initial SCC, then {c, d, e} becomes
an initial SCC. Just like we discussed before for the AF F1 from Fig. 2, we
now have two options: We can choose {e} from this SCC, or we can choose
∅. If we choose {e} we proceed analogously as in the previous case, leading
to the extension {a, e, g, i}. If we choose ∅, then we next consider the now
initial SCC {f, g, h}, noting that f is not included in the set UF2({f, g, h}, E)
of arguments that are unattacked by previous SCCs (because no accepted
argument defends it against the attack from e). From this SCC we can only
choose ∅. Finally we consider the now initial SCC {i}, noting that i is not
included in the set UF2({i}, E) (because no accepted argument defends it
against the attack from h). Since i is not in this set of arguments that are
unattacked by previous SCCs, we cannot choose i, i.e. we can only choose ∅.
This way we get the extension {a}.
Thus we see that the three choice-preferred extensions of F2 are {a}, {a, e, g, i}
and {b, e, g, i}.
6
Satisfaction of Principles
In this section we show that the choice-preferred semantics does indeed sat-
isfy the desired properties of admissibility, INRA and SAFWOC, as well as the
further principles completeness, existence, directionality and SCC-recursiveness.
We start by showing that the choice-preferred semantics satisﬁes complete-
ness.
Theorem 3. The choice-preferred semantics satisﬁes completeness.
Proof. We prove the theorem by proving through an induction over the number
of arguments in F that for any AF F = (Ar, att) and C ⊆Ar, every set in
GF(BFcp, F, C) is a complete extension of F. The base cases, in which there
is at most one argument in the AF, are trivial, because such an AF consists
of only one SCC and the base function BFcp always chooses a complete exten-
sion from an SCC. So we assume for the inductive hypothesis that the required
completeness property is satisﬁed by AFs of size less than n (i.e. with less than
n arguments). Let F = (Ar, att) be an AF of size n. If F consists of a single
SCC, then the completeness property is again satisﬁed due to the base func-
tion BFcp. So assume that |SCCs(F)| > 1. Let C ⊆Ar and let E be an ele-
ment of GF(BFcp, F, C). We need to show that E is a complete extension of
F. Since |SCCs(F)| > 1, Deﬁnition 18 ensures that for every S ∈SCCs(F),

106
M. Cramer and Y. Sp¨orl
(E ∩S) ∈GF(BFcp, F|S\DF (E), UF (S, E) ∩C). Since E ∩S has less than n
elements for every S ∈SCCs(F), the inductive hypothesis now implies that for
every S ∈SCCs(F), E ∩S is a complete extension of F|S\DF (E). Using this fact,
we will now show that E is a complete extension of F:
– Suppose for a contradiction that E is not conﬂict-free. So there are a, b ∈E
with (a, b) ∈att. Let Sb be the SCC of F that contains b. Since b ∈E ∩Sb
and E ∩Sb is a complete extension of F|Sb\DF (E), we have that a /∈Sb.
Thus b ∈DF (E). Given that b ∈(E ∩Sb), this contradicts the fact that
(E ∩Sb) ∈GF(BFcp, F|Sb\DF (E), UF (Sb, E) ∩C). Hence E is conﬂict-free.
– Suppose for a contradiction that E does not defend itself. So there are a ∈Ar
and b ∈E such that (a, b) ∈att and E does not attack a. Let Sb be the SCC
of F that contains b. Since b ∈E ∩Sb and E ∩Sb is a complete extension of
F|Sb\DF (E), a /∈Sb. Thus b /∈UF (Sb, E). Given Deﬁnition 18, this contradicts
b ∈E. Hence E defends itself.
– Suppose for a contradiction that E defends a but a /∈E. Since a /∈E, in the
SCC-recursive computation of E, a gets removed at some step either due to a
being in some DF ′(E) for some subframework F ′ of F, or due to a not being
in some UF ′(S′, E) for some subframework F ′ of F and some SCC S′ of F ′
containing a, or due to a not being in the chosen complete extension E′ of
some single-SCC subframework F ′ = (Ar′, att′) of F. The ﬁrst case cannot
occur due to the conﬂict-freeness of E. The second case cannot occur, since
E defends a. The third case cannot occur, since E′ = E ∩Ar′, so E′ defends
a against all attackers from within Ar′, so a ∈E′ by the completeness of E′.
Thus we have arrived at a contradiction. Hence a is a complete extension of
F.
⊓⊔
From this it directly follows that the choice-preferred semantics also satisﬁes
admissibility:
Theorem 4. The choice-preferred semantics satisﬁes admissibility.
Next we show that the choice-preferred semantics satisﬁes the existence prin-
ciple. For this we ﬁrst establish a lemma that ensures that the existence principle
holds on the level of a single SCC, independently of which set of arguments is
assumed to be unattacked from the outside.
Lemma 1. Let F = (Ar, att) be an AF with |SCCs(F)| = 1, and let C ⊆Ar.
Then BFcp(F, C) ̸= ∅.
Proof. If Ar = ∅, then ∅∈BFcp(F, C) by the ﬁrst disjunct in the deﬁnition of
BFcp in Deﬁnition 21.
If att = ∅, then |Ar| = 1 due to the assumption that |SCCs(F)| = 1, and
therefore Ar ∈BFcp(F, C) by Deﬁnition 21.
Now suppose Ar ̸= ∅and att ̸= ∅. Choose a ∈Ar. Then ∅is a complete
set that is a subset of C and does not attack a. Hence there exists a subset-
maximal complete set E that is a subset of C and does not attack a. Then
E ∈BFcp(F, C).
⊓⊔

The Choice-Preferred Semantics for Relevance-Oriented Acceptance
107
Due to the assumption that AFs are ﬁnite, every AF has at least one SCC
that is not attacked by any other SCC. For each AF, we ﬁx one such SCC and
call it Su
F . We can make the choice for Su
F in such a way that when U is an
unattacked set in F and Su
F ⊆U, then Su
F |U = Su
F .
The deﬁnition of choice-preferred semantics refers to an SCC-recursive com-
putation of the extensions. Intuitively this means that we can compute the exten-
sions by ﬁrst considering an unattacked SCC, choose a choice-preferred extension
from it, determine its impact on other SCCs and then recursively continue this
computation. In order to formalize this intuition, we deﬁned GF in Deﬁnition 18
based on the base function BF in line with the standard deﬁnition in the liter-
ature (e.g. [13]). However, this standard deﬁnition quantiﬁes over all SCCs and
therefore does not capture well the intuition that we can compute the extension
by starting from an unattacked SCC. In the proof of Theorem 5, we will need
to make use of this intuition. This intuition is captured by the following lemma,
which directly follows from Deﬁnition 18 and the fact that AFs are ﬁnite:
Lemma 2. Let BF be a base function, let F = (Ar, att) and let C ⊆Ar. Then
E ∈GF(BF, F, C) iﬀeither Ar = E = ∅∈BF(F, C) or the following two
properties are satisﬁed:
– E ∩Su
F ∈BF(F|Su
F , Su
F ∩C),
– (E \ Su
F ) ∈GF(BF, F|Ar\(Su
F ∪(Su
F ∩E)+), C \ (Su
F ∪(Su
F \ E+)+)).
Theorem 5. The choice-preferred semantics satisﬁes existence.
Proof. We prove the theorem by proving through an induction over the number
of arguments in F that for any AF F = (Ar, att) and C ⊆Ar, GF(BFcp, F, C) ̸=
∅.
For the base cases we assume that there is at most one argument in the AF.
Then |SCCs(F)| ≤1, so GF(BFcp, F, C) = BFcp(F, C), which is non-empty by
Lemma 1.
For the inductive step, we assume the inductive hypothesis that any AF of size
less than n satisﬁes the required property. Let F = (Ar, att) be an AF of size n
and let C ⊆Ar. If |SCCs(F)| = 1, then the required property GF(BFcp, F, C) ̸=
∅is satisﬁed based on Lemma 1, as in the base case. So assume that |SCCs(F)| >
1. By Lemma 1, there exists E ∈BFcp(F|Su
F , Su
F ∩C). By the inductive hypothe-
sis, there exists E′ ∈GF(BFcp, F|Ar\(Su
F ∪(Su
F ∩E)+), C \ (Su
F ∪(Su
F \ E+)+)). Now
we show that E ∪E′ ∈GF(BFcp, F, C). For this we use Lemma 2, establishing
the two propoerties listed in the lemma:
– By the choice of E, we know that E = (E ∪E′) ∩Su
F and that E ∈
BFcp(F|Su
F , Su
F ∩C). So (E ∪E′) ∩Su
F ∈BF(F|Su
F , Su
F ∩C), as required.
– By the choice of E′, we know that E′ = (E ∪E′) \ Su
F and that E′ ∈
GF(BFcp, F|Ar\(Su
F ∪(Su
F ∩E)+), C \ (Su
F ∪(Su
F \ E+)+)). So (E ∪E′) \ Su
F ∈
GF(BFcp, F|Ar\(Su
F ∪(Su
F ∩E)+), C \ (Su
F ∪(Su
F \ E+)+)), as required.
⊓⊔

108
M. Cramer and Y. Sp¨orl
Next we show that the choice-preferred semantics satisﬁes the directionality
principle.
Theorem 6. The choice-preferred semantics satisﬁes directionality.
Proof. Let F = (Ar, att) be an AF, and let U be an unattacked set in F.
Suppose E is a choice-preferred extension of F|U. We need to show that there
exists a choice-preferred extension E′ of F such that E = E′ ∩U. By the proof
of Theorem 5, there exists some E∗∈GF(BFcp, F|Ar\U, Ar \ (U ∪(U \ E+)+).
Deﬁne E′ := E ∪E∗. Clearly E = E′ ∩U, as required. Now one can easily see
that Deﬁnition 18 implies that E′ is a choice-preferred extension of F.
Conversely, suppose E is a choice-preferred extension of F. Now one can
easily see that Deﬁnition 18 implies that E ∩U is a choice-preferred extension of
F|U.
⊓⊔
Next we show that the choice-preferred semantics satisﬁes the INRA princi-
ple.
Theorem 7. The choice-preferred semantics satisﬁes the INRA principle.
Proof. Write σ for choice-preferred. Let F = (Ar, att) be an AF with an argument
a ∈Ar such that every extension E ∈σ(F) attacks a. By the deﬁnition of
choice-preferred we must have |SCCs(F)| > 1, because otherwise there would
be an extension that does not attack a. We can now distinguish two possible
structures of the framework F−a:
|SCCs(F−a)| = 1. Then F consists of exactly two SCCs: Ar \ {a} and {a}, oth-
erwise there would be multiple SCCs after the removal of a. Ar \ {a} attacks a,
so a can not also attack Ar \ {a}, i.e. Ar \ {a} is an unattacked set. Now INRA
follows from choice-preferred’s satisfaction of the directionality principle.
|SCCs(F−a)| > 1. We will make an induction over the number of arguments
and assume INRA for strict subframeworks of F. Further we will call Sa the
SCC in F that contains the argument a. First we will show σ(F) ⊆σ(F−a)
by showing that for every extension E in σ(F), we have E ∈σ(F−a). So
assume E ∈σ(F), i.e. E ∈GF(BFcp, F, Ar). Then for every S ∈SCCs(F),
we have (E ∩S) ∈GF(BFcp, F|S\DF (E), UF (S, E) ∩Ar). It is easy to see
that this implies (E ∩S) ∈σ(F|S\DF (E)). By the induction hypothesis, we
get that (E ∩S) ∈GF(BFcp, F|S\(DF (E)∪{a}), UF (S, E) ∩Ar) (1). To show
that E ∈σ(F−a) it remains to be shown that for every S′ ∈SCCs(F−a),
(E ∩S′) ∈σ(F−a|S′\DF−a(E)) (*).
It is important to point out that either S′ ∈SCCs(F) or S′ ⊆Sa, because
the removal of a may only change the structure of Sa, while all other SCCs in F
remain unchanged. If S′ ∈SCCs(F) then F|S′\DF−a(E) = F|S′\(DF (E)∪{a}) and
so the desired property (*) follows directly from (1).
If S′ ⊆Sa we consider both possible structures of Sa:
– |SCCs(F|Sa\(DF (E)∪{a}))| = 1.
Then the only SCC in F|Sa\(DF (E)∪{a}) is either fully contained in S′ or

The Choice-Preferred Semantics for Relevance-Oriented Acceptance
109
fully disjoint with it. In the ﬁrst case S′ = Sa \ {a}, so E ∩S′ = E ∩Sa and
F|Sa\(DF (E)∪{a}) = F−a|S′\DF−a(E) and according to (1) (*) holds. In the
second case S′ ⊆DF−a(E), while E∩S′ = ∅, which holds, as ∅is an extension
for the empty framework.
– |SCCs(F|Sa\(DF (E)∪{a}))| > 1.
For each S∗∈SCCs(F|Sa\(DF (E)∪{a})), we have that E ∩S∗is an extension
for FS∗\DF |Sa\(DF (E)∪{a}) (2). For any S′′ ∈SCCs(F|S′\DF (E)), we have that
S′′ ∈SCCs(F|Sa\(DF (E)∪{a})) because F|S′\DF (E) ⊆F|Sa\(DF (E)∪{a}) and so
S′ dissolves into SCCs that are part of the framework reduced to Sa without
a. So according to (2), E ∩S′′ is an extension for every S′′.
This concludes the proof that σ(F) ⊆σ(F−a). The proof for σ(F−a) ⊆σ(F)
works similarly.
⊓⊔
Next we show that the choice-preferred semantics satisﬁes the SAFWOC
principle.
Theorem 8. The choice-preferred semantics satisﬁes the SAFWOC principle.
Proof. Let F = (Ar, att) be an argumentation framework such that F contains
no odd cycle. Suppose for a contradiction that ∅is a choice-preferred extension
of F. Let S ∈SCCs(F) be an unattacked SCC of F. Then ∅is a choice-preferred
extension of F|S. So there must be an argument a ∈S such that ∅is a subset-
maximal complete extension of F|S that does not attack a. Since F does not
contain any odd cycles, every element of S can be reached from a either only
through paths of even length or only through paths of odd length. Let A be the
set of all elements of S that are reachable from a through paths of even length.
Then clearly A is a complete extension of F|S and A does not attack a. This
contradicts the subset-maximality of ∅.
⊓⊔
From the deﬁnition of the choice-preferred semantics, it directly follows that
the choice-preferred semantics satisﬁes SCC-recursiveness.
Theorem 9. The choice-preferred semantics satisﬁes SCC-recursiveness.
7
Conclusion and Future Work
In this paper we have considered how to combine the recently introduced INRA
principle, which ensures a relevance-oriented acceptance of arguments, with the
admissibility principle, which is satisﬁed by all the argumentation semantics that
are most widely used in applications of abstract argumentation. After noting that
the grounded, ideal, eager and complete semantics satisfy both INRA and admis-
sibility, we introduced and motivated a further principle, Some Acceptance for
Frameworks Without Odd Cycles (SAFWOC), in order to positively distinguish
less abstention-friendly semantics like preferred, stable, semi-stable, stage, CF2,
stage2 and SCF2 from more abstention-friendly semantics like grounded, ideal,
eager and complete. We then noted that no existing argumentation semantics

110
M. Cramer and Y. Sp¨orl
satisﬁes these three principles together, thus motivating the introduction of the
novel choice-preferred semantics that does satisfy all three of these principles as
well as several others.
This paper opens up several paths for future research. First, the principle-
based analysis of the choice-preferred semantics can be extended further by
considering other principles that go beyond the scope of this paper. Additionally,
the relation between choice-preferred semantics and other existing semantics
should be studied in more detail. We conjecture that every stable extension is
a choice-preferred extension, that every choice-preferred extension is a preferred
extension, and that choice-preferred semantics and semi-stable semantics are not
comparable in this way, but the proofs for these conjectures are left to future
work.
Furthermore, the complexity of reasoning tasks involving the choice-preferred
semantics should be studied. We expect the choice-preferred semantics to behave
similarly to the preferred semantics from a computational and complexity-
theoretical point of view, but this will have to be conﬁrmed in future work.
The INRA principle was originally introduced in combination with considera-
tions about empirically tested human judgments about the acceptability of argu-
ments. So this gives rise to the research question whether there are instances of
human argumentation in which the choice-preferred predicts human judgments
about the acceptability of arguments better than other existing semantics.
Dauphin, Rienstra and van der Torre [8] have introduced the semi-qualiﬁed
admissibility principle, a weakening of admissibility motivated by the notion of
weak admissibility introduced in [4]. For semi-qualiﬁed admissibility, an argu-
ment only needs to be defended against those attackers that appear in at least
one extension. This weakening of admissibility allows for the acceptance of argu-
ments attacked by odd cycles. Furthermore, they have deﬁned analogs of stan-
dard admissible argumentation semantics that satisfy semi-qualiﬁed admissibil-
ity and allow for the acceptance of arguments attacked by odd cycles. These
semantics are deﬁned through a variant of SCC-recursion. In future work, one
could similarly deﬁne an analog of the choice-preferred semantics and study its
properties.
References
1. Baroni, P., Caminada, M., Giacomin, M.: An introduction to argumentation
semantics. Knowl. Eng. Rev. 26(4), 365–410 (2011). https://doi.org/10.1017/
S0269888911000166
2. Baroni, P., Giacomin, M.: On principle-based evaluation of extension-based argu-
mentation semantics. Artif. Intell. 171(10), 675–700 (2007). https://doi.org/10.
1016/j.artint.2007.04.004
3. Baroni, P., Giacomin, M., Guida, G.: SCC-recursiveness: a general schema for
argumentation semantics. Artif. Intell. 168(1), 162–210 (2005)
4. Baumann, R., Brewka, G., Ulbricht, M.: Revisiting the foundations of abstract
argumentation-semantics based on weak admissibility and weak defense. In: Pro-
ceedings of the AAAI Conference on Artiﬁcial Intelligence, vol. 34, pp. 2742–2749
(2020)

The Choice-Preferred Semantics for Relevance-Oriented Acceptance
111
5. Cramer, M., Guillaume, M.: Empirical cognitive study on abstract argumentation
semantics. In: Frontiers in Artiﬁcial Intelligence and Applications, pp. 413–424
(2018)
6. Cramer, M., Guillaume, M.: Empirical study on human evaluation of complex
argumentation frameworks. In: Calimeri, F., Leone, N., Manna, M. (eds.) JELIA
2019. LNCS (LNAI), vol. 11468, pp. 102–115. Springer, Cham (2019). https://doi.
org/10.1007/978-3-030-19570-0 7
7. Cramer, M., van der Torre, L.: SCF2 - an argumentation semantics for rational
human judgments on argument acceptability. In: Beierle, C., Ragni, M., Stolzen-
burg, F., Thimm, M. (eds.) Proceedings of the 8th Workshop on Dynamics of
Knowledge and Belief (DKB’19) and the 7th Workshop KI & Kognition (KIK’19).
CEUR Workshop Proceedings, vol. 2445, pp. 24–35. CEUR-WS.org (2019)
8. Dauphin, J., Rienstra, T., van der Torre, L.: A principle-based analysis of weakly
admissible semantics. In: Prakken, H., Bistarelli, S., Santini, F., Taticchi, C. (eds.)
Computational Models of Argument - Proceedings of COMMA 2020, Perugia, Italy,
4–11 September 2020. Frontiers in Artiﬁcial Intelligence and Applications, vol. 326,
pp. 167–178. IOS Press (2020). https://doi.org/10.3233/FAIA200502
9. Dung, P.M.: On the acceptability of arguments and its fundamental role in non-
monotonic reasoning, logic programming and n-person games. Artif. Intell. 77(2),
321–357 (1995)
10. Dvor´ak, W., Gaggl, S.A.: Incorporating stage semantics in the SCC-recursive
schema for argumentation semantics. In: In Proceedings of the 14th International
Workshop on Non-Monotonic Reasoning (NMR 2012) (2012)
11. Dvoˇr´ak, W., Gaggl, S.A.: Stage semantics and the SCC-recursive schema for argu-
mentation semantics. J. Log. Comput. 26(4), 1149–1202 (2016). https://doi.org/
10.1093/logcom/exu006
12. Rahwan, I., Simari, G.R.: Argumentation in Artiﬁcial Intelligence, 1st edn.
Springer, Heidelberg (2009). https://doi.org/10.1007/978-0-387-98197-0
13. van der Torre, L., Vesic, S.: The principle-based approach to abstract argumenta-
tion semantics. In: Baroni, P., Gabbay, D., Giacomin, M., van der Torre, L. (eds.)
Handbook of Formal Argumentation. College Publications (2018)

New Weak Admissibility Semantics for
Abstract Argumentation
J´er´emie Dauphin1(B), Tjitze Rienstra2, and Leendert van der Torre1,3
1 University of Luxembourg, Esch-sur-Alzette, Luxembourg
{jeremie.dauphin,leon.vandertorre}@uni.lu
2 Maastricht University, Maastricht, The Netherlands
t.rienstra@maastrichtuniversity.nl
3 Zhejiang University, Hangzhou, China
Abstract. Baumann, Brewka and Ulbricht [3,4] recently introduced
weak admissibility as an alternative to Dung’s notion of admissibility [7],
and they used it to deﬁne weakly preferred, weakly complete and weakly
grounded semantics of argumentation frameworks. In earlier work, we
introduced two variants of their new semantics which we called qualiﬁed
and semi-qualiﬁed semantics. We analysed all known variants of weak
admissibility semantics with respect to some of the principles discussed in
the literature on abstract argumentation, as well as some new principles
we introduced to distinguish them all. Such a principle-based analysis
can be used not only for selecting a semantics for an application, or for
algorithmic design, but also for further research into weak admissibility
semantics. In this paper, we introduce six new kinds of semantics based
on weak admissibility, and we provide an initial principle-based analysis.
The analysis illustrates various ways in which the new semantics improve
on existing ones.
Keywords: Formal argumentation · Abstract argumentation ·
Principle-based analysis · Weak admissibility
1
Introduction
There are three classes of abstract argumentation semantics, which can be illus-
trated by their behaviour on odd- and even-length cycles. Roughly, in Dung’s
admissibility-based semantics [7], the maximal extensions may contain argu-
ments of even-length cycles but no arguments of odd-length cycles, unless the
odd-length cycle is attacked by some accepted argument. In na¨ıve-based seman-
tics like CF2 semantics [2], arguments that are only attacked by self-attacking
arguments are typically included in the extensions. In addition, odd-length
cycles and even-length cycles are treated similarly, in the sense that na¨ıve
extensions may also contain arguments from odd-length cycles. Under the weak
admissibility semantics recently introduced by Baumann, Brewka and Ulbricht
(BBU) [3,4], the extensions typically include arguments that are only attacked
c
⃝Springer Nature Switzerland AG 2021
P. Baroni et al. (Eds.): CLAR 2021, LNAI 13040, pp. 112–126, 2021.
https://doi.org/10.1007/978-3-030-89391-0_7

New Weak Admissibility Semantics for Abstract Argumentation
113
by self-attacking arguments (as in na¨ıve-based semantics), but the extensions
typically do not contain arguments from odd-length cycles (as in admissibility-
based semantics). In earlier work, we introduced two variants of BBU seman-
tics which we called qualiﬁed and semi-qualiﬁed semantics [5]. The importance
of these weak admissibility-based semantics is demonstrated by the fact that
these papers obtained best paper awards at top conferences, the ﬁrst [3] at the
17th International Conference on Principles of Knowledge Representation and
Reasoning (KR20) and the second [5] at the 8th International Conference on
Computational Models of Argument (COMMA 2020).
BBU semantics is compared to existing semantics not only in terms of their
behaviour on a few examples, but also with a more systematic principle-based
comparison [3,5]. All known variants of weak admissibility semantics have been
analysed with respect to some of the principles discussed in the literature on
abstract argumentation, as well as some new principles introduced to distinguish
them all. It has been observed that such a principle-based analysis can be used
for further research into weak admissibility semantics, for selecting a semantics
for a particular application, or for the design of algorithms. We therefore raise
the following research questions in this paper:
1. Which other semantics can be deﬁned along the lines of weak admissibility?
2. How
can
these
new
semantics
be
distinguished
from
existing
weak
admissibility-based semantics? Which principles do these new semantics
satisfy?
In this paper, we introduce six new kinds of semantics based on weak admissi-
bility, and we provide an initial principle-based analysis. The analysis illustrates
various ways in which the new semantics improve on existing ones. Let us illus-
trate these diﬀerences using the argumentation frameworks shown in Fig. 1 and
2. Table 1 lists seven kinds of complete semantics. Four are existing semantics:
Dung’s original complete semantics [7], BBU weakly complete semantics [4], and
qualiﬁed as well as semi-qualiﬁed complete semantics [5]. Three are new seman-
tics introduced in this paper: the weakly ∀-complete, the ∃-complete, and the
∀-complete semantics. Moreover, for each notion of complete semantics, there is
a corresponding notion of minimal complete (or grounded) and maximal com-
plete (or preferred) semantics, giving a total of nine new kinds of semantics.
Since some of the semantics coincide, as we show later, there are only six new
kinds of semantics.
a
b
c
d
e
a
b
c
d
e
a
b
c
d
e
Fig. 1. A two-cycle attacking a three-cycle, with ∀-complete extensions in green, the
arguments they attack in red and arguments that are neither in blue. (Color ﬁgure
online)

114
J. Dauphin et al.
a3
a2
a1
b
c
a1
a2
a3
b
c
a1
a2
a3
b
c
Fig. 2. Two connected three-cycles, with ∀-complete extensions in green, the arguments
they attack in red and arguments that are neither in blue. (Color ﬁgure online)
Table 1. Various semantics applied to the frameworks depicted in Fig. 1 and 2.
Semantics
Fig. 1 extensions Fig. 2 extensions
Complete [7]
∅, {a}, {b, d}
∅
Weakly complete [4]
{a}, {b, d}
{a1}, {b}
Qualiﬁed complete [5]
∅, {a}, {b, d}
∅
Semi-qualiﬁed complete [5] ∅, {a}, {b, d}
∅
Weakly ∀-complete
{a}, {b, d}
∅, {a1}, {b}
∃-complete
∅, {a}, {b, d}
{a1}, {b}
∀-complete
∅, {a}, {b, d}
∅, {a1}, {b}
Let us have a closer look at Table 1. Consider Fig. 1. Here, the weakly admis-
sible sets are {b, d} and {a}, {b} and ∅. The weakly complete extensions are
{b, d} and {a}. Here, ∅is not weakly complete since ∅weakly defends {d}, even
though {d} is not weakly admissible. This is one way in which our new semantics
diﬀers from BBU weakly complete semantics [3,4].
Now consider Fig. 2. Here, we also have two minimal weakly complete exten-
sions, {a1} and {b}. This is due to the fact that ∅defends a1 and b, but not both
at the same time. So it seems strange to exclude ∅as a weakly complete exten-
sion and be forced to choose either a1 or b. We see that under weakly ∀-complete
and ∀-complete semantics, this phenomenon does not occur.
To deﬁne our new semantics, we adopt the same inverted methodology as
Baumann, Brewka and Ulbricht (BBU) [3,4], in the sense that we ﬁrst deﬁne
the notion of weak admissibility, and only then the notion of defence. In our case,
we start from the notion of weak admissibility, but we deﬁne defence in a slightly
diﬀerent way. The diﬀerence is illustrated by the argumentation framework in
Fig. 1. Whereas in BBU semantics, the empty set defends {d}, thereby preventing
the empty set from being complete, that is not the case in some of our semantics.
Moreover, we distinguish between what we call some-things-considered (STC)
and all-things-considered (ATC) defence. Consider the argumentation framework
visualized in Fig. 2. In BBU semantics, ∅defends {a1} and {b}, but not their
union {a1, b}. This is an example where BBU semantics does not satisfy Dung’s
so-called fundamental lemma, which says that we can add defended arguments
in any order. For such cases, we say that the empty set STC defends {a1} and
{b}, but it does not ATC defend them.
The layout of this paper is as follows. In Sect. 2, we introduce earlier work on
weak admissibility. In Sect. 3, we introduce our new weak admissibility semantics.

New Weak Admissibility Semantics for Abstract Argumentation
115
In Sect. 4, we show which principles they satisfy. In Sect. 5, we discuss related
and future work, and conclude in Sect. 6.
2
Preliminaries
We remind the reader of the basic notions of abstract argumentation introduced
by Dung [7].
Deﬁnition 1. (Abstract argumentation and semantics). An argumenta-
tion framework (AF) is a pair F = (A, →) where A is a set of abstract argu-
ments and →is a relation of attack among them. Given a set S ⊆A, we say
that:
– S is conﬂict-free iﬀthere are no a, b ∈S such that a →b;
– y ∈A is an attacker of S iﬀ∃a ∈S such that y →a;
– S+ := {a ∈A | ∃b ∈S, b →a};
– S classically defends S′ ⊆A iﬀfor every attacker y of S′, there is a ∈S such
that a →y;
– S is admissible iﬀS is conﬂict-free and defends itself;
– S is a complete extension of F iﬀS is admissible, and for every S′ ⊇S, if
S defends S′, then S′ ⊆S.
The semantics introduced in this paper are based on the concept of weak
admissibility, as introduced by Baumann, Brewka and Ulbricht [4]. Weak admis-
sibility is based on the notion of a reduct, where one removes from the framework
a set of arguments as well as every argument it attacks.
Deﬁnition 2 (Reduct [4]). Let F = (A, →) be an AF and let E ⊆A. The
E-reduct of F is the AF F E = (E∗, →∩(E∗× E∗)), where E∗= A \ (E ∪E+).
The notion of reduct is used to deﬁne weak admissibility. When checking
whether a set is weakly admissible, one checks whether any of its attackers is
weakly admissible in the reduct.
Deﬁnition 3 (Weak admissibility [4]). Let F = (A, →) be an AF. The set
of weakly admissible sets of F is denoted as adw(F) and deﬁned by E ∈adw(F)
if and only if E is conﬂict-free and, for every attacker y of E, we have y ̸∈
∪adw(F E).
As mentioned in the introduction, the methodology is the inverse of the
methodology of Dung [7], where the concept of defence is deﬁned ﬁrst and then
used to deﬁne admissibility. In the case of weak admissibility, the notion of weak
admissibility is deﬁned ﬁrst and then used to deﬁne the notion of weak defence.
Deﬁnition 4 (Weak defence [4]). Let F = (A, →) be an AF. A set E ⊆A
weakly defends a set X ⊆A iﬀfor any attacker y of X we have:
– E attacks y, or

116
J. Dauphin et al.
– y ̸∈∪adw(F E), y ̸∈E, and X ⊆X′ ∈adw(F).
We show later in the paper that the notion of weak defence between weakly
admissible sets can be deﬁned in a manner that does not require one to recompute
any reduct. For the reader’s convenience, we provide an alternative deﬁnition
here, and show in Sect. 4 that it is equivalent.
Proposition 1. Let F = (A, →) be an AF, E ∈adw(F), X ⊇E and D = X\E.
E weakly defends X iﬀ:
1. for any attacker y of D, y ̸∈∪{Z ∈adw(F) | E ⊆Z}, and
2. there is a set X′ ⊇X such that X′ ∈adw(F).
The notions of weak admissibility and weak defence are then used to deﬁne
weakly complete, weakly grounded and weakly preferred semantics, in the same
way that in Dung’s work [7], the notions of admissibility and defence are used
to deﬁne complete, grounded and preferred semantics.
Deﬁnition 5 (Weak admissibility semantics [4]). Let F = (A, →) be an
AF and E ⊆A. We say that E is:
– a weakly complete extension of F iﬀE ∈adw(F) and for any E′ ⊇E, if E
weakly defends E′, then E′ ⊆E;
– a weakly grounded extension of F iﬀE is a ⊆-minimal weakly complete
extension of F;
– a weakly preferred extension of F iﬀE is a ⊆-maximal weakly admissible set
in F.
3
New Weak Admissibility Semantics
In this section, we present new semantics inspired by weak admissibility. The
main point is that if an argument is never accepted, then it should not prevent
other arguments from being accepted. We thus base our semantics on the notion
of weak admissibility, but revise the derived notion of defence into three variants:
weak ∀-defence, ∃-defence and ∀-defence.
For the notion of weak ∀-defence, we look at all ⊆-maximal supersets of the
extension that are weakly defended by it. If their intersection is the extension
itself, then it is defended. This allows for the fact that when lifted to a notion
of complete extensions, where the extension defends more arguments but in a
disjoint manner, we allow the extension to abstain from including any of those
arguments. We refer back to the discussion of Fig. 2 in the introduction, where
the empty set defends {a1} and {b}, but not {a1, b}. Arguments that are defended
and are compatible with all other defended arguments must, on the other hand,
still be included.
Deﬁnition 6 (Weak ∀-defence). Let F = (A, →) be an AF. A set E ⊆A
weakly ATC (all-things-considered) defends X ⊆A (E weak ∀-defends X) iﬀ
E weakly defends X, and X is a subset of the intersection of the ⊆-maximal
supersets of E that are weakly defended by E.

New Weak Admissibility Semantics for Abstract Argumentation
117
For ∃-defence, we start again from the notion of weak defence, but now change
X ⊆X′ ∈adw(F) into X ∪E ∈adw(F). Thus, for E to defend X, it is required
that E ∪X is weakly admissible, rather than some arbitrary superset of X being
weakly admissible. This avoids the case where ∅defends {d} in the AF of Fig. 1.
Deﬁnition 7 (∃-defence). Let F = (A, →) be an AF. A set E ⊆A STC (some-
things-considered) defends a set X ⊆A (E ∃-defends X) whenever, for every
attacker y of X, either E attacks y, or y ̸∈∪adw(F E) and X ∪E ∈adw(F).
For the notion of ∀-defence, we take the modiﬁcation made for weak ∀-
defence, but use the notion of ∃-defence as a base instead of weak defence.
Deﬁnition 8 (∀-defence). Let F = (A, →) be an AF. A set E ⊆A ATC (all-
things-considered) defends X ⊆A (E ∀-defends X) iﬀE ∃-defends X, and X is
a subset of the intersection of the ⊆-maximal supersets of E that are ∃-defended
by E.
We now lift these diﬀerent notions of defence to notions of admissibility, in
the same way that the classical notion of defence is lifted to provide the classical
notion of admissibility.
Deﬁnition 9 (weak ∀-admissibility). Let F = (A, →) be an AF. A set E ⊆A
is weakly ∀-admissible iﬀE is conﬂict-free and weakly ∀-defends itself.
Deﬁnition 10 (∃-admissibility). Let F = (A, →) be an AF. A set E ⊆A is
∃-admissible iﬀE is conﬂict-free and ∃-defends itself.
Deﬁnition 11 (∀-admissibility). Let F = (A, →) be an AF. A set E ⊆A is
∀-admissible iﬀE is conﬂict-free and ∀-defends itself.
It turns out that these three notions are all equivalent to weak admissibility.
We show this in Sect. 4 with Theorem 1. For this reason, in the deﬁnitions to
come, we work directly with weakly admissible sets. One should keep in mind
that while the notions of weak admissibility arising from the diﬀerent notions of
weak defence are equivalent, the notions of weak defence are all diﬀerent, and
still give rise to diﬀerent weak admissibility semantics, as we will see in the rest
of this paper.
Example 1. In Fig. 1, the weak admissible, weak ∀-admissible, ∃-admissible and
∀-admissible semantics are all the same: ∅, {b}, {d, b} and {a}. In Fig. 2, the
weakly admissible, weak ∀-admissible, ∃-admissible and ∀-admissible sets are ∅,
{b} and {a1}.
The new notions of defence can be lifted to complete and grounded semantics
in the same way as classical defence is lifted to give rise to the complete and
grounded semantics in Dung’s work [7]. Contrary to the notions of admissibility
which arise from the diﬀerent notions of defence, the diﬀerent notions of com-
plete semantics are not equivalent. The diﬀerences arise from diﬀerences in the
notions of defence. For example, some weakly admissible sets might ∃-defend

118
J. Dauphin et al.
some of their supersets, but not ∀-defend any of them, resulting in diﬀerent
complete extensions. For similar reasons, the resulting grounded semantics are
also diﬀerent.
Deﬁnition 12 (Weak ∀-complete semantics). Let F = (A, →) be an AF
and E ⊆A. We say that E is a weak ∀-complete extension of F (E ∈cow∀(F))
iﬀE ∈adw(F), and for any E′ ⊇E, if E weakly ∀-defends E′, then E′ ⊆E.
Deﬁnition 13 (∃-complete semantics). Let F = (A, →) be an AF and E ⊆
A. We say that E is an ∃-complete extension of F (E ∈co∃(F)) iﬀE ∈adw(F)
and for any E′ ⊇E, if E ∃-defends E′, then E′ ⊆E.
Deﬁnition 14 (∀-complete semantics). Let F = (A, →) be an AF and E ⊆
A. We say that E is a ∀-complete extension of F (E ∈co∀(F)) iﬀE ∈adw(F),
and for any E′ ⊇E, if E ∀-defends E′, then E′ ⊆E.
In order to illustrate the formal deﬁnitions, we provide examples of the dif-
ferent kinds of weakly complete semantics below, but remind the reader that
these are also discussed in the introduction.
Example 2 (Diﬀerence between complete extensions in Fig. 1 and 2). In Fig. 1,
the weak-complete and weak-∀-complete extensions are {d, b} and {a}. The ∃-
complete and ∀-complete extensions are ∅, {d, b} and {a}. In Fig. 2, the weak/∃-
complete extensions are {b} and {a1}. The ∀/weak-∀admissible sets are ∅, {b}
and {a1}.
These two examples are enough to show that all four kinds of semantics are
diﬀerent, since the ones that agree on the ﬁrst framework disagree on the second.
Deﬁnition 15 (Weak ∀-grounded semantics). Let F = (A, →) be an AF
and E ⊆A. We say that E is a weak ∀-grounded extension of F iﬀE is a
⊆-minimal weak ∀-complete extension of F.
Deﬁnition 16 (∃-grounded semantics). Let F = (A, →) be an AF and E ⊆
A. We say that E is an ∃-grounded extension of F iﬀE is a ⊆-minimal ∃-
complete extension of F.
Deﬁnition 17 (∀-grounded semantics). Let F = (A, →) be an AF and E ⊆
A. We say that E is a ∀-grounded extension of F iﬀE is a ⊆-minimal ∀-complete
extension of F.
Example 3. Consider Fig. 3. In the framework depicted, the weakly ∀-grounded
and ∀-grounded extension is {e}, whereas the ∃-grounded extensions are {a1, e}
and {b, e}. It is interesting to see that since d is not weakly admissible, the empty
set ∀-defends {e}. In addition, {e} is weakly admissible since in its reduct, F {e},
d is still not weakly admissible. Therefore, {e} is the ∀-grounded extension.

New Weak Admissibility Semantics for Abstract Argumentation
119
a3
a2
a1
b
c
d
e
a1
a2
a3
b
c
d
e
a1
a2
a3
b
c
d
e
Fig. 3. Two connected 3-cycles defending an argument, with ∀-complete extensions in
green, the arguments they attack in red and arguments that are neither in blue. (Color
ﬁgure online)
4
Principles
In this section, we provide a preliminary analysis of the principles satisﬁed by
these new semantics. We also provide a few properties for the diﬀerent notions
of weak defence, and explain how they are related. A complete overview of the
results obtained is shown in Table 2. For comparison, this table also includes the
qualiﬁed semantics (q-co, q-gr, q-pr) and semi-qualiﬁed semantics (sq-co, sq-pr)
discussed by Dauphin, Rienstra, and van der Torre [5]. The results for cow, prw,
grw, as well as for the various qualiﬁed and semi-qualiﬁed semantics, have been
demonstrated previously in [5], except for the result of directionality for prw,
which is taken from the work of Baumann, Brewka and Ulbricht [3].
Table 2. Principles satisﬁed by the semantics discussed in this paper
cow
prw
grw
cow∀
grw∀
co∃
gr∃
co∀
gr∀
q-co
q-gr
q-pr
sq-co
sq-pr
Abs.
×
×
×
×
×
×
×
?
?
×
✓
×
✓
×
Dir.
×
✓
×
×
×
?
?
?
?
✓
✓
✓
✓
✓
Red. adm.
✓
✓
✓
✓
✓
✓
✓
✓
✓
?
?
?
?
?
Deﬁnition 18. A semantic function σ satisﬁes the principles of:
– allowing abstention iﬀfor every AF F = (A, →), and a ∈A, if there exists
E1, E2 ∈σ(F) such that a ∈E1 and a ∈E+
2 , then there exists E3 such that
a /∈E3 ∪E+
3 ;
– directionality iﬀfor every AF F = (A, →) and unattacked set U of F we have
σ(F)↓U = σ(F↓U), where an unattacked set U of F is any set U ⊆A such that
there is no x ∈A\U and y ∈U with x →y, and σ(F)↓U = {E∩U|E ∈σ(F)},
F↓U = (U, →∩U × U).
– reduct admissibility iﬀfor every AF F = (A, →), for every E ∈σ(F), we
have ∀a ∈E, ∀b ∈A, if b →a, then b /∈∪σ(F E).
Proposition 2. cow∀, grw∀, co∃and gr∃do not satisfy the principle of allowing
abstention.

120
J. Dauphin et al.
Proof. For cow∀and grw∀, the counter-example is in Fig. 1. We have two exten-
sions for both semantics: {a} and {b, d}. There is an extension including a and
another one attacking it, but there is no extension where a is neither included
nor attacked.
The counter-example for co∃and gr∃is depicted in Fig. 4. The ∃-complete
and ∃-grounded extensions coincide, and are {b} and {a1, d}. So there is one
extension where d is included and another where d is attacked, but no extension
where neither is the case.
□
a3
a2
a1
b
c
d
a1
a2
a3
b
c
d
Fig. 4. Two connected 3-cycles where one attacks another argument. This shows the
failure of allowing abstention for co∃and gr∃.
Proposition 3. cow∀and grw∀do not satisfy the principle of directionality.
Proof. The counter-example is in Fig. 1. For both semantics, there are two exten-
sions: {a} and {b, d}. When restricted to the unattacked set {a, b}, we obtain
{{a}, {b}}. However, when applying the semantic function to this restricted
framework, we obtain weak ∀-complete extensions {∅, {a}, {b}} and weak ∀-
grounded extension {∅}, neither of which match {{a}, {b}}.
□
Conjecture 1. co∃, gr∃, co∀and gr∀satisfy the principle of directionality.
These four semantic functions handle the counter-example to directionality of
cow∀better, however it does not seem straightforward to prove that the principle
holds in general. Further research in this direction should prove fruitful.
Proposition 4. co∃, gr∃, co∀, gr∀, cow∀and grw∀all satisfy the principle of
reduct admissibility.
Proof. This follows from the fact that each of these semantic functions are based
on weak admissibility.
□
We now analyse some properties of intermediate notions such as defence and
admissible sets. An important observation is that the various notions of defence
introduced in this paper all give rise to an equivalent notion of admissible sets.
Additionally, these notions of defence are related, as described in the following
proposition:
Proposition 5. Let F = (A, →) and E, X ⊆A. If E ∀-defends X, then E ∃-
defends X. If E ∃-defends X, then E weakly defends X. If E weakly ∀-defends
X, then E weakly defends X.

New Weak Admissibility Semantics for Abstract Argumentation
121
Proof. It follows from the deﬁnition that ∀-defence implies ∃-defence, since ∃-
defence is an explicit condition of ∀-defence.
∃-defence implies weak defence follows from the fact that X ∪E ∈adw(F)
implies that there exists X′ ∈adw(F) with X ⊆X′.
It follows from the deﬁnition that weak ∀-defence implies weak defence, since
weak defence is an explicit condition of weak ∀-defence.
□
Theorem 1. Let F = (A, →) be an AF, and E ⊆A a set of arguments. The
following statements are equivalent:
1. E is weakly admissible;
2. E is ∃-admissible;
3. E is ∀-admissible;
4. E is weakly ∀-admissible.
Proof. If E is not conﬂict-free, then none of the statements hold. We therefore
only need to look at cases where E is conﬂict-free. We prove the equivalence by
showing a cycle of implications between items 1, 2 and 3, then show equivalence
between items 1 and 4.
– 1 ⇒2 (E weakly admissible implies ∃-admissible): We have to show that E
∃-defends itself. By Proposition 4.4, item 3 of [4], E weakly defends itself.
Additionally, E ∪E is weakly admissible, so E ∃-defends itself.
– 2 ⇒3 (E ∃-admissible implies ∀-admissible): We have to show that E ∀-
defends itself. E ∃-defends itself. Since E ∃-defends at least itself, it is included
in every ⊆-maximal superset of itself which it ∃-defends. Therefore, it is
included in the intersection of those sets, and so it ∀-defends itself.
– 3 ⇒1 (E ∀-admissible implies weakly admissible): E ∀-defends itself, hence E
weakly defends itself. E is also conﬂict-free since it is ∀-admissible. Therefore,
by Proposition 4.4 item 4 of [4], E is weakly admissible.
– 4 ⇒1 (E weakly ∀-admissible implies weakly admissible): E weakly ∀-defends
itself, therefore E weakly defends itself by Proposition 5. Therefore, by Propo-
sition 4.4 item 4 of [4], E is weakly admissible.
– 1 ⇒4 (E weakly admissible implies weakly ∀-admissible): E is a subset of
all its supersets, so we only have to show that E weakly defends itself. By
Proposition 4.4 item 3 of [4], E being weakly admissible implies that it weakly
defends itself. Therefore E is weakly ∀-admissible.
□
It is important to observe that the ∀-grounded extension is not always unique.
The ∃-grounded extension is not always unique either.
Proposition 6. The weak ∀-grounded and ∃-grounded extensions are not always
unique.
Proof. Consider Fig. 1. The weak ∀-grounded extensions are {a} and {b, d}. The
empty set is not weakly ∀-complete, since the only ⊆-maximal superset of itself
that it weakly defends is {d}, and therefore it weakly ∀-defends {d}, which it
does not include.

122
J. Dauphin et al.
Consider Fig. 2. The ∃-grounded extensions are {a1} and {b}. The empty
set is not ∃-complete, since it defends both {a1} and {b}, as they are weakly
admissible, and their only attacker is never admissible in the reduct by the empty
set, i.e. the original framework.
□
On the other hand, in both of the frameworks depicted in Fig. 1 and 2, the
∀-grounded extension is unique. However, it remains to be proven that this is
always the case.
Conjecture 2. The ∀-grounded extension is always unique.
We now interest ourselves in a few properties of the newly introduced notions,
in particular ∃-defence. We show that ∃-defence satisﬁes a property which is
reminiscent of the Fundamental lemma described in Dung’s work [7].
Proposition 7. (Generalisation of Theorem 3.11 from [4]) Let F = (A, →) be
an AF. Let E, X ⊆A. If E is weakly admissible and E classically defends X,
then E ∪X is weakly admissible.
Proof. Repeated applications of Theorem 3.11 from [4], since classical defence is
monotonic.
□
Proposition 8. Let F = (A, →) be an AF. If E ⊆A is weakly admissible and
∃-defends X ⊆A, then E ∪X is weakly admissible.
Proof. If E ∃-defends X, then by deﬁnition we have that for every attacker y of
X, either (1) y ̸∈∪adw(F E), y ̸∈E and X ∪E ∈adw(F), or (2) E attacks y.
If there is at least one y satisfying condition (1), we directly obtain that E ∪X
is weakly admissible. Otherwise, we obtain that every y satisﬁes condition (2),
i.e. for every attacker y of X, E attacks y. Then E classically defends X. Using
Proposition 7, it then follows that E ∪X is weakly admissible.
□
It is worth mentioning that Proposition 8 does not hold for weak defence.
That is, if a weakly admissible set E weakly defends a set X, it does not follow
that E ∪X is weakly admissible. To see why, consider Fig. 1, where ∅is weakly
admissible and weakly defends {d}, but {d} is not weakly admissible.
On the other hand, Proposition 5 implies that this result holds for ∀-defence
as well.
We now show a few more properties of ∀-complete extensions, in particular
that ⊆-maximal ∀-complete extensions coincide with weakly preferred exten-
sions.
Proposition 9. Let F = (A, →) be an AF. If E is weakly preferred, then it is
∀-complete.
Proof. Suppose E is weakly preferred. Then E is weakly admissible, and the
only superset of E that is ∀-defended by E is E itself, which implies that E
equals the intersection of the ⊆-maximal supersets of E that are ∀-defended by
E. Hence it is ∀-complete.
□

New Weak Admissibility Semantics for Abstract Argumentation
123
Proposition 10. Let F = (A, →) be an AF. If E is weakly admissible, then
there is a ∀-complete set that includes E.
Proof. Suppose E is weakly admissible. Then E is included in a weakly preferred
extension, and using Proposition 9, it follows that it is ∀-complete.
□
Proposition 11. Let F = (A, →) be an AF. If E ⊆A is a ⊆-maximal ∀-
complete extension, then E is weakly preferred.
Proof. Suppose E is a ⊆-maximal ∀-complete extension of F. Then E is weakly
admissible. Suppose E is not weakly preferred. Then there is an E′ ⊃E that
is weakly admissible. But then using Proposition 10, E′ is also included in a ∀-
complete extension that is bigger than E. This contradicts the assumption that
E is a ⊆-maximal ∀-complete extension.
□
From Propositions 9 and 11, we can deduce that the weakly preferred exten-
sions are precisely the ⊆-maximal ∀-complete extensions.
One can also provide alternative deﬁnitions for each of the notions of defence
we have introduced. The main point to consider is that for the purpose of deﬁning
a semantics, the notion of defence only really matters between a weakly admis-
sible set and its supersets. With these assumptions in place, the conditions for
defence can be reformulated.
Proposition 12 (Alternative deﬁnition from [3]). Let F = (A, →) be an
AF, E ∈adw(F), X ⊇E and D = X \ E. We have that E weakly defends X
iﬀ:
1. for any attacker y of D, y ̸∈∪adw(F E), and
2. there is a set D′ ⊇D such that D′ ∈adw(F E).
Theorem 2 (Theorem 4.1 from [3]). Let F = (A, →) be an AF and E ∈
adw(F). Suppose that E ∩E′ = ∅. Then, E′ ∈adw(F E) if and only if E ∪E′ ∈
adw(F).
From this theorem, we can infer more practical, yet equivalent conditions for
weak defence.
Proposition 13. Let F = (A, →) be an AF, E ∈adw(F), X ⊇E and D =
X \ E. The following two statements are equivalent:
1. There is a set D′ ⊇D such that D′ ∈adw(F E).
2. There is a set X′ ⊇X such that X′ ∈adw(F).
Proof.
1. ⇒2.
D′ ∈adw(F E) and E ∈adw(F), thus according to Theorem 2, E ∪D′ ∈
adw(F). So there exists such an X′, namely E ∪D′.
2. ⇒1.
X′ ⊇X such that X′ ∈adw(F). We also have E ∈adw(F), therefore by
Theorem 2, we have X′ \ E ∈adw(F E). Since D = X \ E, then D ⊆X′ \ E.
□

124
J. Dauphin et al.
Proposition 14. Let F = (A, →) be an AF, E ∈adw(F), X ⊇E and D =
X \ E such that there exists an X′ ⊇X with X′ ∈adw(F). The following two
statements are equivalent:
1. For any attacker y of D, y ̸∈∪adw(F E).
2. For any attacker y of D, y ̸∈∪{Z ∈adw(F) | E ⊆Z}.
Proof. We prove the proposition by showing the equivalence of the negation of
both items, i.e. the equivalence of the existence of an attacker y of D from either
(1.) the set ∪adw(F E) or from (2.) the set ∪{Z ∈adw(F) | E ⊆Z}.
1. ⇒2.
Suppose there exists y ∈∪adw(F E) such that y attacks D. Then, there must
be some S ∈adw(F E) such that y ∈S. By Theorem 2, E ∪S ∈adw(F).
Therefore, there exists y ∈∪{Z ∈adw(F) | E ⊆Z} with y attacks D.
2. ⇒1.
Suppose there exists y ∈∪{Z ∈adw(F) | E ⊆Z} such that y attacks D.
Then there must be Z ∈adw(F) with Z ⊇E and y ∈Z. Let S = Z \ E.
Then, according to Theorem 2, S ∈adw(F E). Suppose for a contradiction
that y ∈E. Then, X is not conﬂict-free and neither is any X′ ⊇X. There-
fore, there is no X′ ⊇X such that X′ ∈adw(F). This contradicts our initial
assumption that there exists such an X′. So y ̸∈E, and so y ∈S. Therefore
y ∈∪adw(F E).
□
From these results, we can infer an equivalent notion of weak defence where
one does not have to compute weak admissibility again when computing defence.
One only has to compute the weak admissible sets in the original framework,
and for the purpose of computing defence, computing weak admissibility in some
reducts is no longer necessary.
The notion only applies when considering weakly admissible sets and asking
which of their supersets they defend. However, this is exactly the question that
is of interest when asking whether a weakly admissible set is weakly complete.
Therefore, for the purpose of computing weakly complete extensions, this notion
is equivalent to the original deﬁnition of weak defence.
Proposition 15. Let F = (A, →) be an AF, E ∈adw(F), X ⊇E and D =
X \ E. E weakly-defends X iﬀ:
1. for any attacker y of D, y ̸∈∪{Z ∈adw(F) | E ⊆Z}, and
2. there is a set X′ ⊇X such that X′ ∈adw(F).
The same can be done for the newly introduced notion of ∃-defence.
Proposition 16. Let F = (A, →) be an AF, E ∈adw(F), X ⊇E and D =
X \ E. E ∃-defends X iﬀ:
1. for any attacker y of D, y ̸∈∪{Z ∈adw(F) | E ⊆Z}, and
2. X ∈adw(F).

New Weak Admissibility Semantics for Abstract Argumentation
125
5
Related and Future Work
In general, one of the main purposes of axiomatisation in formal logic is to
understand the logic with an intuitively understandable small set of principles.
In proposing axioms, care should be taken to ensure that each axiom is suﬃ-
ciently reasonable and suﬃciently independent of others. Ideally, there should be
some degree of philosophical motivation behind them. However, in the principle-
based analysis of abstract argumentation [1,8], thus far the focus has been on the
use of principles to diﬀerentiate between various semantics, and to assist with
computational techniques using decomposability. Concerning the ﬁrst issue, Bau-
mann, Brewka and Ulbricht [4] show that the weakly grounded extensions are
not necessarily unique, and the principle-based analysis by Dauphin, Rienstra
and van der Torre [5] shows that weakly complete semantics does not satisfy the
principles of directionality or SCC decomposability.
The weakly complete semantics of Dondio and Longo [6] (which, despite the
name, is diﬀerent from the weakly complete semantics of BBU) provides yet
another way to deal with defence from arguments that are never accepted. Their
labelling-based semantics is based on an “undecidedness blocking” mechanism
where the undecided label is not always propagated to the arguments that are
attacked. In future work, we plan to include their approach in our analysis.
6
Conclusion
The semantics of abstract argumentation frameworks has been an active area of
research ever since Dung published his seminal’95 paper [7]. The topic deals with
the question of how to determine the acceptable arguments of an argumentation
framework, and forms the foundation of any form of reasoning using Dung’s
model of argumentation. The recent BBU proposal [3,4] to deﬁne semantics in
terms of their new notions of weak admissibility and weak defence is interesting
because it leads to a third category of semantics besides the classically admissible
and na¨ıve categories. While these semantics overcome issues concerning self-
attacking arguments and odd-length cycles, we have shown in earlier work that
there are several principles, often considered desirable, that are violated by their
semantics [5]. In this paper, we deﬁned six new variants of weak admissible
semantics, and provided an initial principle-based analysis to distinguish them
from BBU semantics. While some questions remain (such as whether our new
semantics satisfy the directionality principle, and whether ∀-grounded extensions
are unique), our work shows that the intuitions behind weak defence and weak
admissibility can be applied in diﬀerent ways, leading to a wide range of new
variants of weakly admissible semantics.
Acknowledgements. Leon van der Torre acknowledges ﬁnancial support from
the Fonds National de la Recherche Luxembourg (INTER/Mobility/19/13995684/
DLAl/van der Torre).

126
J. Dauphin et al.
References
1. Baroni, P., Giacomin, M.: On principle-based evaluation of extension-based argu-
mentation semantics. Artif. Intell. 171(10–15), 675–700 (2007)
2. Baroni, P., Giacomin, M., Guida, G.: SCC-recursiveness: a general schema for argu-
mentation semantics. Artif. Intell. 168(1–2), 162–210 (2005)
3. Baumann, R., Brewka, G., Ulbricht, M.: Comparing weak admissibility semantics
to their dung-style counterparts - reduct, modularization, and strong equivalence in
abstract argumentation. In: Proceedings of the the 17th International Conference
on Principles of Knowledge Representation and Reasoning (KR2020) (2020)
4. Baumann, R., Brewka, G., Ulbricht, M.: Revisiting the foundations of abstract argu-
mentation - semantics based on weak admissibility and weak defense. In: The Thirty-
Fourth AAAI Conference on Artiﬁcial Intelligence, AAAI 2020, New York, USA,
7–12 February 2020. AAAI Press (2020). https://www.aaai.org/Library/AAAI/
aaai20contents.php
5. Dauphin, J., Rienstra, T., van der Torre, L.: A principle-based analysis of weakly
admissible semantics. In: Prakken, H., Bistarelli, S., Santini, F., Taticchi, C. (eds.)
Computational Models of Argument - Proceedings of COMMA 2020, Perugia, Italy,
September 4–11, 2020. Frontiers in Artiﬁcial Intelligence and Applications, vol. 326,
pp. 167–178. IOS Press (2020). https://doi.org/10.3233/FAIA200502
6. Dondio, P., Longo, L.: Weakly complete semantics based on undecidedness blocking.
arXiv preprint arXiv:2103.10701 (2021)
7. Dung, P.M.: On the acceptability of arguments and its fundamental role in non-
monotonic reasoning, logic programming and n-person games. Artif. Intell. 77(2),
321–357 (1995)
8. van der Torre, L., Vesic, S.: The principle-based approach to abstract argumenta-
tion semantics. In: Baroni, P., Gabbay, D., Giacomin, M., van der Torre, L. (eds.)
Handbook of Formal Argumentation, chap. 12, pp. 2735–2778. College Publications,
London (2018)

On Restricting the Impact of
Self-attacking Arguments in Gradual
Semantics
Vivien Beuselinck1
, J´erˆome Delobelle2(B)
, and Srdjan Vesic3
1 Aniti, Universit´e F´ed´erale, Toulouse, France
vivien@beuselinck.fr
2 LIPADE, Universit´e de Paris, Paris, France
jerome.delobelle@u-paris.fr
3 CNRS, Univ. Artois, CRIL, Lens, France
vesic@cril.fr
Abstract. The issue of how a semantics should deal with self-attacking
arguments was always a subject of debate amongst argumentation schol-
ars. A consensus exists for extension-based semantics because those argu-
ments are always rejected (as soon as the semantics in question respect
conﬂict-freeness). In case of gradual semantics, the question is more com-
plex, since other criteria are taken into account. A way to check the
impact of these arguments is to use the principles (i.e. desirable prop-
erties to be satisﬁed by a semantics) from the literature. Principles like
Self-Contradiction and Strong Self-Contradiction prescribe how to deal
with self-attacking arguments. We show that they are incompatible with
the well-known Equivalence principle (which is satisﬁed by almost all
the existing gradual semantics), as well as with some other principles
(e.g. Counting). This incompatibility was not studied until now and
the class of semantics satisfying Self-Contradiction is under-explored.
In the present paper, we explore that class of semantics. We show links
and incompatibilities between several principles. We deﬁne a semantics
that satisﬁes (Strong) Self-Contradiction and a maximal number of com-
patible principles. We introduce an iterative algorithm to calculate our
semantics and prove that it always converges. We also provide a char-
acterisation of our semantics. Finally, we experimentally show that our
semantics is computationally eﬃcient.
Keywords: Abstract argumentation · Gradual semantics · Self-attack
1
Introduction
Theory of computational argumentation allows to model exchange of arguments
and conﬂicts between them. Although in most cases a conﬂict occurs between two
arguments, sometimes an argument may conﬂict with itself. Such an argument
is called a self-attacking argument. Discussion on how to deal with self-attacking
c
⃝Springer Nature Switzerland AG 2021
P. Baroni et al. (Eds.): CLAR 2021, LNAI 13040, pp. 127–146, 2021.
https://doi.org/10.1007/978-3-030-89391-0_8

128
V. Beuselinck et al.
arguments is often indirectly included in the problems of dealing with odd-length
cycles, because a self-attack is the smallest odd-length cycle. However, in contrast
to greater odd-length cycles, the presence of a self-attack is due to inconsistency
in an argument itself.
In order to reason in presence of these arguments, several methods have
been deﬁned in abstract argumentation by proposing to deal with them directly
[8,9,11,16] or indirectly [7]. These methods essentially concern extension-based
semantics. In the context of ranking-based and gradual argumentation semantics
[2,5], little research was conducted to ﬁnd out how self-attacking arguments
should be dealt with and what is the impact they have on the acceptability
of other arguments. Existing studies are essentially done through the principle-
based study of these semantics. Indeed, deﬁning and studying principles drew
attention of many scholars in this area.
Consider Equivalence, which is one of the well-known principles, stating that
the acceptability degree of an argument should only depend on acceptability
degrees of its direct attackers and consider the argumentation graph Fex contain-
ing two arguments a and b, and where b is attacked by a self-attacking argument
a (i.e., Fex = ({a, b}, {(a, a), (a, b)})). Equivalence implies that a and b should
be equally acceptable because a and b are both attacked by a self-attacking
argument. However, this is debatable, since the intuition behind a self-attacking
argument is that it is inconsistent in one way or another so we would tend to
accept b being attacked by a (which is self-attacking) rather than accepting a.
Note that, under all semantics returning conﬂict-free extensions, a self-attacking
argument is always rejected, i.e. it does not belong to any extension. Also, regard-
ing the ranking-based and gradual semantics, it was pointed out that it would
be natural to attach the worst possible rank to self-attacking arguments [19].
Furthermore, two principles were deﬁned to formalise this intuition.
The ﬁrst one is called Strong Self-Contradiction, and introduced by Matt
and Toni [19]. It says that the acceptability degree of an argument must be
0 if and only if that argument is self-attacking. The second principle, called
Self-Contradiction, was introduced by Bonzon et al. [12] and states that every
self-attacking argument is strictly less acceptable than every non self-attacking
argument. Consider the argumentation graph Fex again and note that, under
every semantics that satisﬁes Self-Contradiction, b is strictly more acceptable
than a. This example shows that Equivalence and Self-Contradiction are not
compatible, i.e. there exists no semantics that satisﬁes both of them.
To the best of our knowledge, there exists only one semantics (known as
M&T) that satisﬁes Self-Contradiction and Strong Self-Contradiction. That
semantics was introduced by Matt and Toni [19]. However, this semantics has a
limitation that makes it inapplicable in practice. Namely, as noted by Matt and
Toni themselves, as the space used to calculate the scores grows exponentially
with the number of arguments, even with the optimisation techniques they used
it did not scale to more than a dozen of arguments.
The research objective of the present paper is to study the under-explored
family of semantics that satisfy Strong Self-Contradiction. Our goals are thus
to identify which principles are (in)compatible with Strong Self-Contradiction

On Restricting the Impact of Self-attacking Arguments
129
and to deﬁne a semantics, which we call nsa (no self-attacks), that satisﬁes
Strong Self-Contradiction as well as a maximal number of compatible principles.
After introducing the formal setting and recalling the existing principles from
the literature, we prove the incompatibilities between some of the principles, and
identify a maximal set of principles that contains (Strong) Self-Contradiction.
We introduce an iterative algorithm in order to deﬁne a new semantics and
prove that it always converges. The acceptability of degree of each argument
with respect to nsa is then deﬁned as the limit of the corresponding sequence.
We provide a characterisation of nsa, i.e. a declarative (non-iterative) deﬁnition
and show that the two are equivalent: each semantics satisfying the declarative
deﬁnition coincides with nsa. We check which principles are satisﬁed by nsa
and compare it with the h-categorizer semantics [10] and the M&T semantics in
terms of principle satisfaction. We formally prove that no semantics can satisfy a
strict super-set of the set of principles satisﬁed by nsa. We experimentally show
that nsa is computationally eﬃcient and compare it with the M&T semantics
and the h-categorizer semantics. The results conﬁrm the hypothesis that the
M&T semantics does not scale.
2
Formal Setting and Existing Semantics
An argumentation graph (AG) [17] is a directed graph F = (A, R) where A
is a ﬁnite set of arguments and R a binary relation over A, i.e. R ⊆A × A.
For a, b ∈A, (a, b) ∈R means that a attacks b. The notation AttF(a) =
{b | (b, a) ∈R} represents the set of direct attackers of argument a. For two
graphs F = (A, R) and F′ = (A′, R′), we denote by F ⊗F′ the argumentation
graph F′′ = (A ∪A′, R ∪R′).
Dung’s framework comes equipped with various types of semantics used to
evaluate the arguments. These include the extension-based semantics (see [6] for
an overview), the labelling-based semantics [14], the ranking-based semantics
(see [12] for an overview) and the gradual semantics. We refer the reader to
[1,13] for a complete overview of the existing families of semantics in abstract
argumentation and the diﬀerences between these approaches (e.g., deﬁnition,
outcome, application). In this article, we focus on gradual semantics which assign
to each argument in an argumentation graph a score, called acceptability degree.
This degree belongs to the interval [0, 1]. Higher degrees correspond to stronger
arguments.
Deﬁnition 1 (Gradual semantics).
A gradual semantics is a function S
which associates to any argumentation graph F = (A, R) a function DegS
F :
A →[0, 1]. Thus, DegS
F(x) represents the acceptability degree of x ∈A.
In the rest of the section we recall two gradual semantics. We ﬁrst introduce h-
categorizer, which is one of the most studied gradual semantics and also satisﬁes
a maximal compatible set of principles from the literature.1 Then we introduce
1 Formally: out of the principles from Sect. 3, no semantics satisﬁes a strict superset
of the principles satisﬁed by h-categorizer.

130
V. Beuselinck et al.
M&T semantics which is, to the best of our knowledge, the only semantics known
in the literature to satisfy Self-Contradiction.
2.1
h-categorizer Semantics
The h-categorizer semantics [10,20] uses a categorizer function to assign a value
to each argument by taking into account the strength of its attackers, which
itself takes into account the strength of its attackers, and so on.
Deﬁnition 2 (h-categorizer semantics). Let F = (A, R) be an argumenta-
tion graph. The h-categorizer semantics is a gradual semantics such that ∀x ∈A:
Degh
F(x) =
1
1 + 
y∈AttF(x) Degh
F(y)
2.2
M&T Semantics
The gradual semantics introduced by Matt and Toni [19] computes the accept-
ability degree of an argument using a two-person zero-sum strategic game. For an
AG F = (A, R) and an argument x ∈A, the set of strategies for the proponent
is the set of all subsets of arguments that contain x: SP (x) = {P | P ⊆A, x ∈P}
and for the opponent it is the set of all subsets of arguments: SO = {O | O ⊆A}.
Given two strategies X, Y ⊆A, the set of attacks from X to Y is deﬁned by
Y ←X
F
= {(x, y) ∈X × Y | (x, y) ∈R}. From this measurement, Matt and Toni
deﬁne the notion of degree of acceptability of a set of arguments w.r.t. another
one used to compute the reward of a proponent’s strategy.
Deﬁnition 3 (Reward). Let F = (A, R) be an argumentation graph, x ∈A
be an argument, P ∈SP (x) be a strategy chosen by the proponent and O ∈SO
be a strategy chosen by the opponent. The degree of acceptability of P w.r.t. O
is φ(P, O) = 1
2

1 + f(|O←P
F
|) −f(|P ←O
F
|)

with f(n) =
n
n+1. The reward of P
over O, denoted by rF(P, O), is deﬁned by:
rF(P, O) =
⎧
⎨
⎩
0
iﬀP
is not conﬂict-free
1
iﬀP
is conﬂict- free and |P ←O
F
| = 0
φ(P, O) otherwise
Proponent and opponent have the possibility of using a strategy accord-
ing to some probability distributions, respectively p = (p1, p2, . . . , pm) and
q = (q1, q2, . . . , qn), with m = |SP | and n = |SO|. For each argument x ∈A, the
proponent’s expected payoﬀE(x, p, q) is E(x, p, q) = n
j=1
m
i=1 piqjri,j with
ri,j = rF(Pi, Oj) where Pi (respectively Oj) represents the ith (respectively jth)
strategy of SP (x) (respectively SO). The proponent can expect to get at least
minq E(x, p, q), where the minimum is taken over all the probability distribu-
tions q available to the opponent. Hence the proponent can choose a strategy
which will guarantee her a reward of maxp minq E(x, p, q). The opposite is also
true with minq maxp E(x, p, q).

On Restricting the Impact of Self-attacking Arguments
131
Deﬁnition 4 (M&T semantics). The semantics M&T is a gradual semantics
that assigns a score to each argument x ∈A in F as follows:
DegMT
F (x) = max
p
min
q
E(x, p, q) = min
q
max
p
E(x, p, q)
3
Principles for Gradual Semantics
Principles have been introduced by [4] in order to better understand the behavior
of the gradual semantics, choose a semantics for a particular application, guide
the search for new semantics, compare semantics with each other, etc. We do not
claim that all of these principles are mandatory (we will see later that some of
them are incompatible). In the rest of this section, we introduce the principles.2
The ﬁrst one, called Anonymity, states that the name of an argument should
not impact its acceptability degree.
Principle 1 (Anonymity).
A semantics S satisﬁes Anonymity iﬀfor any
two AGs F = (A, R) and F′ = (A′, R′) for any isomorphism f from F to F′,
∀a ∈A, DegS
F(a) = DegS
F′(f(a)).
Independence says that the acceptability degree of an argument should be
independent of unconnected arguments.
Principle 2 (Independence). A semantics S satisﬁes Independence iﬀ, for
any two AGs F = (A, R) and F′ = (A′, R′) such that A ∩A′ = ∅, ∀a ∈A,
DegS
F(a) = DegS
F⊗F′(a).
Directionality states that the acceptability of argument x can depend on y
only if there is a path from y to x.
Principle 3 (Directionality). A semantics S satisﬁes Directionality iﬀ, for
any AG F = (A, R) and F′ = (A, R′) such that a, b ∈A, R′ = R ∪{(a, b)} it
holds that : ∀x ∈A, if there is no path from b to x, then DegS
F(x) = DegS
F′(x).
Neutrality states that an argument with an acceptability degree of 0 should
have no impact on the arguments it attacks.
Principle 4 (Neutrality). A semantics S satisﬁes Neutrality iﬀ, for any AG
F = (A, R) if ∀a, b ∈A, AttF(b) = AttF(a) ∪{x} with x ∈A\AttF(a) and
DegS
F(x) = 0 then DegS
F(a) = DegS
F(b).
Equivalence says that if two arguments have the same attackers, or more
generally attackers of the same strength, they should have the same acceptability
degree.
Principle 5 (Equivalence). A semantics S satisﬁes Equivalence iﬀ, for any
AG F = (A, R), ∀a, b ∈A, if there exists a bijective function f from AttF(a) to
AttF(b) s.t. ∀x ∈AttF(a), DegS
F(x) = DegS
F(f(x)) then DegS
F(a) = DegS
F(b).
2 We do not include the Proportionality principle since it is only applicable when
arguments are attached intrinsic weights.

132
V. Beuselinck et al.
Maximality states that a non-attacked argument should have the highest
acceptability degree.
Principle 6 (Maximality). A semantics S satisﬁes Maximality iﬀ, for any
AG F = (A, R), ∀a ∈A, if AttF(a) = ∅then DegS
F(a) = 1.
Counting states that a non-zero degree attacker should impact the accept-
ability of the attacked argument.
Principle 7 (Counting). A semantics S satisﬁes Counting iﬀfor any AG F =
(A, R), ∀a, b ∈A, if i) DegS
F(a) > 0 and ii) AttF(b) = AttF(a) ∪{y} with
y ∈A\AttF(a) and DegS
F(y) > 0 then DegS
F(a) > DegS
F(b).
Weakening says that the acceptability of an argument should be strictly lower
than 1 if it has at least one attacker with a non-zero acceptability degree.
Principle 8 (Weakening). A semantics S satisﬁes Weakening iﬀfor any AG
F = (A, R), ∀a ∈A, if ∃b ∈AttF(a) s.t. DegS
F(b) > 0, then DegS
F(a) < 1.
Weakening Soundness states that if the acceptability degree of an argument
is not maximal, it must be that it is attacked by at least one non-zero degree
attacker.
Principle 9 (Weakening Soundness). A semantics S satisﬁes Weakening
Soundness iﬀ, for any AG F = (A, R), ∀a ∈A, if DegS
F(a) < 1 then ∃b ∈
AttF(a) such that DegS
F(b) > 0.
Reinforcement states that the acceptability degree increases if the accept-
ability degrees of attackers decrease.
Principle 10 (Reinforcement). A semantics S satisﬁes Reinforcement iﬀfor
any AG F = (A, R), ∀a, b ∈A, if i) DegS
F(a) > 0 or DegS
F(b) > 0, ii)
AttF(a)\AttF(b) = {x}, iii) AttF(b)\AttF(a) = {y}, iv) DegS
F(y) > DegS
F(x),
then DegS
F(a) > DegS
F(b).
Resilience states that no argument in an argumentation graph can have a
acceptability degree of 0. It is certainly not a mandatory principle.
Principle 11 (Resilience). A semantics S satisﬁes Resilience if for any AG
F = (A, R), ∀a ∈A, DegS
F(a) > 0.
The last three principles are incompatible with each other. The ﬁrst princi-
ple, called Cardinality Precedence states, roughly speaking, that the greater the
number of direct attackers of an argument, the lower its acceptability degree.
Principle 12 (Cardinality Precedence). A semantics S satisﬁes Cardinality
Precedence iﬀfor any AG F = (A, R), ∀a, b ∈A, if i) DegS
F(b) > 0, and ii)
|{x ∈AttF(a) s.t. DegS
F(x) > 0}| > |{y ∈AttF(b) s.t. DegS
F(y) > 0}| then
DegS
F(a) < DegS
F(b).
Quality Precedence states, roughly speaking, that the greater the acceptabil-
ity degree of the strongest attacker of an argument, the lower its acceptability
degree.

On Restricting the Impact of Self-attacking Arguments
133
Principle 13 (Quality Precedence). A semantics S satisﬁes Quality Prece-
dence if for any AG F = (A, R), ∀a, b ∈A, if i) DegS
F(a) > 0 and ii)
∃y ∈AttF(b) s.t. ∀x ∈AttF(a), DegS
F(y) > DegS
F(x) then DegS
F(a) > DegS
F(b).
Compensation states that several attacks from arguments with a low accept-
ability degree may compensate one attack from an argument with high accept-
ability degree. 3
Principle 14 (Compensation). A semantics S satisﬁes Compensation iﬀboth
Cardinality Precedence and Quality Precedence are not satisﬁed.
In the literature, two principles directly refer to the self-attacking arguments.
The ﬁrst one, called Self-Contradiction, was introduced by [12] and states that
the degree of a self-attacking argument should be strictly lower than the degree
of an argument that does not attack itself.
Principle 15 (Self-Contradiction). A semantics S satisﬁes Self-Contradict-
ion iﬀ, for any AG F = (A, R) with two arguments a, b ∈A, if (a, a) ∈R and
(b, b) /∈R then DegS
F(b) > DegS
F(a).
The second principle was introduced by Matt and Toni [19]. Its original
name was “Self-contradiction must be avoided”. We rename it for clarity rea-
sons, namely in order to avoid the confusion with the name of Principle 15. This
principle states that an argument that attacks itself should have the smallest
acceptability degree (i.e. 0).
Principle 16 (Strong Self-Contradiction). A semantics S satisﬁes Strong
Self- Contradiction iﬀ, for any AG F = (A, R) with a ∈A, DegS
F(a) = 0 iﬀ
(a, a) ∈R.
4
Analysis of Principles and Links Between Them
In this section we analyse the links between principles and identify two maximal
mutually compatible sets of principles. Let us ﬁrst observe that Strong Self-
Contradiction implies Self-Contradiction. The next proposition follows directly
from the deﬁnitions of the respective principles.
Proposition 1. If a gradual semantics S satisﬁes Strong Self-Contradiction, it
satisﬁes Self-Contradiction.
Proof. Let us suppose that Strong Self-Contradiction is satisﬁed by S. This
means that those and only those arguments that have the minimum score are the
self-attacking arguments (∀a ∈A, DegS
F(a) = 0 iﬀ(a, a) ∈R). This implies that
all arguments that do not attack themselves have an acceptability degree greater
than 0. Formally, ∀b ∈A, DegS
F(b) > 0 iﬀ(b, b) /∈R. Consequently, for two
arguments a, b ∈A, if (a, a) ∈R and (b, b) /∈R then DegS
F(b) > DegS
F(a) = 0. □
3 There are several version of this principle. We use the version that allows to clearly
distinguish between the three cases (CP, QP, Compensation). Namely, each seman-
tics satisﬁes exactly one of the three principles.

134
V. Beuselinck et al.
As discussed in the introduction, the next result shows that Equivalence and
Self-Contradiction are incompatible.
Proposition 2. There exists no gradual semantics S that satisﬁes both Equiv-
alence and Self-Contradiction.
Proof. We provide a proof by contradiction. Let us suppose that a gradual
semantics S satisﬁes both Equivalence and Self-Contradiction and consider the
argumentation graph F = (A, R) with A = {a, b} and R = {(a, a), (a, b)}.
From Self-Contradiction, we have DegS
F(a) < DegS
F(b), while from Equivalence,
we have DegS
F(a) = DegS
F(b).
Contradiction.
Hence,
S
does
not
satisfy
both
Equivalence
and
Self-
Contradiction. Since S was arbitrary, we conclude that there exists no semantics
that satisﬁes both Equivalence and Self-Contradiction.
□
However, the Equivalence principle is not the only one incompatible with
Strong Self-Contradiction. Some other incompatibilities exist mainly because
self-attacking arguments are treated diﬀerently from other arguments. Indeed,
according to Strong Self-Contradiction, self-attacking arguments are directly
classiﬁed as the worst arguments, whereas the other principles just consider
a self-attack as an attack like any other (i.e. an attack between two distinct
arguments).
Proposition 3. There exists no gradual semantics S that satisﬁes both Strong
Self-Contradiction and Resilience.
Proof. We provide a proof by contradiction. Let us suppose that a gradual
semantics S satisﬁes both Strong Self-Contradiction and Resilience, and con-
sider the argumentation graph F = (A, R) where A = {a} and R = {(a, a)}.
From Strong Self-Contradiction, we have DegS
F(a) = 0, while from Resilience,
we have DegS
F(a) > 0.
Contradiction. Hence, S does not satisfy both Strong Self-Contradiction and
Resilience. Since S was arbitrary, there exists no semantics that satisﬁes both
Resilience and Strong Self-Contradiction.
□
Proposition 4. There exists no gradual semantics S that satisﬁes both Strong
Self-Contradiction and Weakening Soundness.
Proof. We provide a proof by contradiction. Let us suppose that a gradual
semantics S satisﬁes both Strong Self-Contradiction and Weakening Sound-
ness, and consider the argumentation graph F = (A, R) where A = {a} and
R = {(a, a)}.
From Strong Self-Contradiction, we have DegS
F(a) = 0, while from Weaken-
ing Soundness, we have DegS
F(a) > 0 because a is the only attacker of a and
DegS
F(a) = 0.
Contradiction. Hence, S does not satisfy both Strong Self-Contradiction and
Weakening Soundness. Since S was arbitrary, there exists no semantics that
satisﬁes both Strong Self-Contradiction and Weakening Soundness.
□

On Restricting the Impact of Self-attacking Arguments
135
Proposition 5. There exists no gradual semantics S that satisﬁes both Strong
Self-Contradiction and Reinforcement.
Proof. We provide a proof by contradiction. Let us suppose that a grad-
ual semantics S
satisﬁes both Strong Self-Contradiction and Reinforce-
ment, and consider the argumentation graph F = ({a, b, c, d}, {(a, a), (c, c),
(c, a), (a, b), (d, b)}). From Strong Self-Contradiction, we have 0 = DegS
F(a) <
DegS
F(b).
From Reinforcement, we have DegS
F(a) > DegS
F(b) because i) DegS
F(b) > 0,
ii) AttF(a)\AttF(b) = {c}, iii) AttF(b)\AttF(a) = {d}, and iv) DegS
F(d) >
DegS
F(c).
Contradiction. Hence, S does not satisfy both Strong Self-Contradiction and
Reinforcement. Since S was arbitrary, there exists no semantics that satisﬁes
both Strong Self-Contradiction and Reinforcement.
□
Proposition 6. There exists no gradual semantics S that satisﬁes both Strong
Self-Contradiction and Neutrality.
Proof. We provide a proof by contradiction. Let us suppose that a gradual
semantics S satisﬁes both Strong Self-Contradiction and Neutrality, and con-
sider the argumentation graph F = ({a, b, x}, {(x, x), (b, b), (x, b), (b, a)}).
From Strong Self-Contradiction, we have 0 = DegS
F(b) < DegS
F(a).
From Neutrality, we have DegS
F(a) = DegS
F(b) because AttF(b) = AttF(a)∪{x}
with DegS
F(x) = 0.
Contradiction. Hence, S does not satisfy both Strong Self-Contradiction and
Neutrality. Since S was arbitrary, there exists no semantics that satisﬁes both
Strong Self-Contradiction and Neutrality.
□
Taking these incompatibilities into account, our goal is now to study two
maximal mutually compatible sets of principles we are interested in. For this,
we need the notion of dominance. A semantics S dominates a semantics S′ on
the set of principles P if the subset of principles from P satisﬁed by S is a strict
superset of the subset of principles from P satisﬁed by S′. In the rest of the
discussion, we suppose that P is the set of all principles studied in Sect. 3. Note
that if a semantics S satisﬁes a maximal for set inclusion set of principles, it is
not dominated by any semantics.
A ﬁrst maximal (for set inclusion) set of principles has been identiﬁed by [4]
and is a direct consequence of their Proposition 1. We deﬁne this set of princi-
ples as PCREW = {Anonymity, Independence, Directionality, Neutrality, Equiva-
lence, Maximality, Weakening, Counting, Weakening Soundness, Reinforcement,
Resilience and Compensation}.
Theorem 1 ([4]). PCREW is a maximal for set inclusion set of principles.
We can formally show that there is a unique maximal set of principles com-
patible with Compensation, Resilience, Equivalence and Weakening Soundness.

136
V. Beuselinck et al.
Theorem 2. Let P be the set of all principles deﬁned in Sect. 3 (Principles 1–
16). Let S be a gradual semantics that satisﬁes Compensation, Resilience, Equiv-
alence and Weakening Soundness. If S is not dominated w.r.t. P, then S satisﬁes
exactly the principles from PCREW .
Proof. On one hand, we know from the work by [4] that h-categorizer satis-
ﬁes all the principles from PCREW . On the other hand, it is clear from the
incompatibility results between the principles that S cannot satisfy Strong Self-
Contradiction which is incompatible with Resilience (see Proposition 3), Self-
Contradiction which is incompatible with Equivalence (see Proposition 2), Car-
dinality/Quality Precedence which are both incompatible with Compensation
(see [4]). Thus, in order not to be dominated by h-categorizer, S must satisfy all
the principles from PCREW ; due to the incompatibilities, S cannot satisfy any
more principles.
□
In this paper we choose to explore the space of principles compatible with
Strong Self-Contradiction (which is not in PCREW ). One naturally wants to max-
imise the set of satisﬁed principles. Can we satisfy Strong Self-Contradiction and
all the other principles? The answer is negative (see Propositions 2–6). First, one
has to choose between Cardinality Precedence, Quality Precedence and Compen-
sation. In this paper, we explore the possibility of satisfying Compensation. This
choice is based on the fact that this principle is satisﬁed by virtually all seman-
tics, as showed by Amgoud et al. [4]. Indeed, Cardinality Precedence and Quality
Precedence represent, roughly speaking, drastic or extreme cases and are satis-
ﬁed only by the semantics speciﬁcally designed to satisfy them, like max-based
semantics and card-based semantics [4] or by semantics having other speciﬁci-
ties. For instance, iterative schema [18], which satisﬁes Quality Precedence, is
a discrete semantics (it takes only three possible values). This yields another
maximal set of principles which includes those two principles. We deﬁne this
set of principles as P2S2C = {Anonymity, Independence, Directionality, Max-
imality, Weakening, Counting, Compensation, Self-Contradiction, Strong Self-
Contradiction}.
Theorem 3. P2S2C is a maximal for set inclusion set of principles.
Proof. Firstly, all the principles in P2S2C are compatible because nsa satisﬁes
all of them (see Proposition 7). Secondly, P2S2C is maximal because for each
remaining principle p ∈{Equivalence, Weakening Soundness, Neutrality, Rein-
forcement, Cardinality Precedence, Quality Precedence and Resilience}, there
exists (at least) one principle in P2S2C which is incompatible with p, i.e. Equiva-
lence and Self-Contradiction are incompatible (see Proposition 2); Neutrality and
Strong Self-Contradiction are incompatible (see Proposition 6); Reinforcement
and Strong Self-Contradiction are incompatible (see Proposition 5); Weakening
Soundness and Strong Self-Contradiction are incompatible (see Proposition 4);
Cardinality Precedence and Compensation are incompatible (see [4]); Quality
Precedence and Compensation are incompatible (see [4]); and Resilience and
Strong Self-Contradiction are incompatible (see Proposition 3).
□

On Restricting the Impact of Self-attacking Arguments
137
We now show that there is a unique maximal set of principles compatible
with Strong Self-Contradiction and Compensation. This follows from the fact
that if a semantics satisﬁes Strong Self-Contradiction, it cannot satisfy several
principles (see Propositions 2–6) but can satisﬁed all the others (as witnessed by
the semantics we introduce in this paper).
Theorem 4. Let P be the set of all principles deﬁned in Sect. 3 (Principles 1–
16). Let S be a gradual semantics that satisﬁes Strong Self-Contradiction and
Compensation. If S is not dominated w.r.t. P, then S satisﬁes exactly the prin-
ciples from P2S2C.
Proof. It is clear that from the incompatibility results between diﬀerent prin-
ciples, S cannot satisfy (i) Resilience, Equivalence and Weakening Soundness
which are incompatible with Strong Self-Contradiction (or Self-Contradiction),
and (ii) Cardinality Precedence and Quality Precedence which are both incom-
patible with Compensation. The set of remaining principles corresponds exactly
to P2S2C which is a maximal for set inclusion set of principles. However, S cannot
satisfy exactly a subset of P2S2C because, in this case, S will be dominated by a
semantics that satisﬁes the principles of P2S2C. Consequently, when S satisﬁes
Strong Self-Contradiction and Compensation, the only way to ensure that S is
not dominated is when S satisﬁes exactly the principles from P2S2C.
□
To the best of our knowledge, no semantics that satisfy all the principles
from P2S2C has been presented in the literature. In the next section, we deﬁne
a semantics that satisﬁes this set of principles.
Before doing that, let us comment on the non satisfaction of some princi-
ples. It is tempting to change the principles in order to treat the self-attacks in
another way, and consequently make the principles ﬁt some deﬁnitions or theo-
rems. We argue that it is better to start by having a full picture of what happens
with existing principles. Indeed, the principles should be the most stable part
of a theory. We are not against introduction of new principles (or changing the
existing ones). This might be part of future work.
5
No Self-Attack h-categorizer Semantics
In this section, we deﬁne a new gradual semantics, called no self-attack h-
categorizer (nsa) semantics, inspired by the h-categorizer semantics. The main
diﬀerence is that we assign 0 degree to the self-attacking arguments.
Deﬁnition 5 (nsa). Let F = (A, R) be an AG. We deﬁne f F,i
nsa : A →[0, +∞]
as follows : for every argument a ∈A for i ∈{0, 1, 2, ..},
f F,i
nsa (a) =
⎧
⎪
⎪
⎨
⎪
⎪
⎩
0
if (a, a) ∈R
1
if (a, a) /∈R and i = 0
1
1 + 
b∈AttF(a) f F,i−1
nsa
(b)
if (a, a) /∈R and i > 0
(1)
By convention, if AttF(a) = ∅, 
b∈AttF(a) f F,i−1
nsa
(b) = 0.

138
V. Beuselinck et al.
Although nsa is inspired by the h-categorizer semantics, the modiﬁcations
made change the result obtained requiring the veriﬁcation that nsa also con-
verges to a unique result. Thus, in the next result, we show that for every argu-
mentation graph F = (A, R), for every argument a ∈A, f F,i
nsa (a) converges as i
approaches inﬁnity. Roughly speaking, the next theorem aims to formally check
that assigning zero values to self-attacking arguments does not impact the con-
vergence of the scores. Thus, applying nsa to the original argumentation graph
F provides the same result as when the h-categorizer semantics is applied on a
restricted version of F where the self-attacking arguments are deleted.
Theorem 5. For every argumentation graph F = (A, R), for every a ∈A, if
(a, a) /∈R, we have lim
i→∞f F,i
nsa (a) = Degh
F′(a) where F′ = (A′, R′) with A′ =
{x ∈A| (x, x) /∈R} and R′ = {(x, y) ∈R | x ∈A′ and y ∈A′}.
Proof. Let F = (A, R) be an AG and F′ = (A′, R′) be an AG such that A′ =
{x ∈A|(x, x) /∈R} and R′ = {(x, y) ∈R | x ∈A′ and y ∈A′}. Without loss of
generality, let us denote A = {a0, a1, . . . , an}.
Let us recall the iterative version of h-categorizer, that can be used to calcu-
late the scores of arguments [20]: for every a, for i ∈N
f F,i
h
(a) =
⎧
⎨
⎩
1
if i = 0
1
1 + 
b∈AttF(a) f F,i−1
h
(b)
if i > 0
(2)
We prove by induction on i that for each a ∈A′:
f F,i
nsa (a) = f F′,i
h
(a)
Base: Let i = 0. From the formal deﬁnition of nsa (Deﬁnition 5) and Eq. (2),
we have f F,0
nsa (a) = f F′,0
h
(a) = 1. Thus, the inductive base holds.
Step: Let us suppose that the inductive hypothesis is true for every k ∈
{0, 1, . . . i} and let us show that it is true for i + 1. We need to prove :
f F,i+1
nsa
(a) = f F′,i+1
h
(a)
From the inductive hypothesis, we know that for each argument a ∈A′,
f F,i
nsa (a) = f F′,i
h
(a). Thus, from Eq. (1), we have:
f F,i+1
nsa
(a) =
1
1 + 
b∈AttF(a) f F,i
nsa (b)
From Eq. (2), we have
f F′,i+1
h
(a) =
1
1 + 
b∈AttF′(a) f F′,i
h
(b)

On Restricting the Impact of Self-attacking Arguments
139
Let us note AttF(a) = AttF′(a) ∪{b0, . . . , bm} with m ≥0 and remark that
∀b ∈{b0, . . . , bm}, we have (b, b) ∈R. According to Eq. (1), ∀b ∈{b0, . . . , bm},
f F,i
nsa (b) = 0. Consequently, as 0 is the neutral element of the addition, we have
∀a ∈A′, f F,i+1
nsa
(a) = f F′,i+1
h
(a).
By induction, we conclude that for every i ∈N and for every a ∈A′
f F,i
nsa (a) = f F′,i
h
(a)
Since fh converges when i →∞and fnsa coincides with fh for every argument
of A′, we conclude that fnsa converges too. Formally, ∀a ∈A′, lim
i→∞f F,i
nsa (a) =
lim
i→∞f F,i
h
(a) = Degh
F′(a).
□
We can now introduce the formal deﬁnition of nsa.
Deﬁnition 6 (nsa). The no self-attack h-categorizer semantics is a function
nsa which associates to any argumentation framework F = (A, R) a function
Degnsa
F (a) : A →[0, 1] as follows: Degnsa
F (a) = lim
i→∞f F,i
nsa(a).
We can now show that the acceptability degrees attributed to arguments by nsa
satisfy the equation from Deﬁnition 5 (naturally, not taking into account the
second line of the equation, since it considers the case i = 0).
Theorem 6. For any F = (A, R), for any a ∈A,
Degnsa
F (a) =
⎧
⎨
⎩
0
if (a, a) ∈R
1
1 + 
b∈AttF(a) Degnsa
F (b) otherwise
Proof. Let F = (A, R) be an argumentation graph and a ∈A.
The case where a is a self-attacking argument is trivial.
In the rest of the proof we consider the case where a is not a self-attacking
argument. Letting lim
i→∞in the following equality
f i+1
nsa (a) =
1
1 + 
b∈AttF(a) f insa(b)
and using the fact that arithmetical operations and sum are continuous functions,
we obtain :
lim
i→∞f i+1
nsa (a) =
1
1 + 
b∈AttF(a) lim
i→∞f insa(b)
then
Degnsa
F (a) =
1
1 + 
b∈AttF(a) Degnsa
F (a)
□

140
V. Beuselinck et al.
We now show that the equation from Theorem 6 is not only satisﬁed by nsa,
but is also its characterization. More precisely, the next result proves that if an
arbitrary semantics D satisﬁes that equation, it must be that D coincides with
nsa.
Theorem 7. Let F = (A, R) be an AG with a ∈A and D : A →[0, 1] be a
function with the following formula:
D(a) =
⎧
⎨
⎩
0
if(a, a) ∈R
1
1 + 
b∈AttF(a) D(b) otherwise
(3)
then D ≡Degnsa
F .
Proof. Let F = (A, R) be an AG and suppose that D : A →[0, 1] is the function
from Eq. (3).
Let A = {a1, .., an} and let F : [0, 1]n →[0, 1]n be the function such
that F(x1, .., xn) = (F1(x1, .., xn), ..., Fn(x1, ..., xn)) where the functions Fi are
deﬁned by the following equality:
Fi(x1, . . . , xn) =
⎧
⎪
⎨
⎪
⎩
0
if (ai, ai) ∈R
1
1 +

j:aj∈AttF(ai)
xj
otherwise
(4)
We also deﬁne the partial order ≤on Rn in the following way: if x =
(x1, . . . , xn) and y = (y1, . . . , yn) then x ≤y iﬀfor every i it holds that xi ≤yi.
Thus, from Eq. (3), it follows that F(D(a1), ..., D(an)) = (D(a1), ..., D(an)).
Observe that F is a non-increasing function and that G = F ◦F is a non-
decreasing function, and that :
(f i+1
nsa (a1), ..., f i+1
nsa (an)) = F((f i
nsa(a1), ..., f i
nsa(an)))
for every i ∈N. Since (f 0
nsa(a1), ..., f 0
nsa(an)) ∈[0, 1]n with f 0
nsa(ai) = 0 iﬀ
(ai, ai) ∈R and f 0
nsa(ai) = 1 otherwise, by the inequalities, we obtain
(f 0
nsa(a1), ..., f 0
nsa(an)) ≥(D(a1), ..., D(an))
(5)
From (5), and since F is non-increasing, we have:
(f 1
nsa(a1), ..., f 1
nsa(an)) ≤(D(a1), ..., D(an))
(6)
From (6), and since G = F ◦F is non-decreasing, we have:
(f 2i
nsa(a1), ..., f 2i
nsa(an)) ≥(D(a1), ..., D(an))
(7)
and
(f 2i+1
nsa (a1), ..., f 2i+1
nsa (an)) ≤(D(a1), ..., D(an))
(8)

On Restricting the Impact of Self-attacking Arguments
141
for every i ∈N.
Since all f i converge, from (7) and (8) we obtain
(Degnsa
F (a1), . . . , Degnsa
F (an)) ≥(D(a1), ..., D(an))
and
(Degnsa
F (a1), . . . , Degnsa
F (an)) ≤(D(a1), ..., D(an))
and thus ∀a ∈A, Degnsa
F (a) = D(a).
□
Below is an example of the nsa semantics applied on an argumentation graph.
Example 1. Let us apply the no self-attack h-categorizer semantics (nsa) on
the argumentation graph illustrated in Fig. 1. By deﬁnition, the self-attacking
arguments have an acceptability degree of 0: Degnsa
F (a0) = Degnsa
F (a2) = 0. The
non-attacked arguments or the arguments only attacked by self-attacking argu-
ments have, by deﬁnition, the maximum score: Degnsa
F (a5) = 1. Applying the
formula from Theorem 6, we obtain the following acceptability degrees for a1 and
a4: Degnsa
F (a1) = 0.732 and Degnsa
F (a4) = 0.399. Finally, following the same
method, here are the details concerning a3 :
Degnsa
F (a3) =
1
1 + Degnsa
F (a1) + Degnsa
F (a2) + Degnsa
F (a4) = 0.477
In order to have an overview of the diﬀerence between nsa and the gradual
semantics introduced in Sect. 2, the degrees of acceptability of arguments w.r.t.
the h-categorizer semantics and the M&T semantics have also been added in the
table of Fig. 1. This comparison clearly shows that nullifying the impact of self-
attacking arguments more or less signiﬁcantly changes the degree of acceptability
of other arguments (e.g. a1 and a3).
a0
a1
a2
a3
a4
a5
DegS
F
nsa
h
MT
a0
0
0.618
0
a1
0.732
0.495
0.25
a2
0
0.618
0
a3
0.477
0.398
0.167
a4
0.399
0.401
0.25
a5
1
1
1
Fig. 1. On the left, an argumentation graph F and, on the right, the table containing
the degrees of acceptability of each argument of F w.r.t. the no self-attack h-categorizer
semantics (nsa), the h-categorizer semantics (h) and the semantics M&T (MT).

142
V. Beuselinck et al.
6
Principle-Based Evaluation of Semantics
In this section we evaluate the nsa semantics with respect to principle compli-
ance, and compare the results with two existing semantics, namely M&T and
h-categorizer (Table 1). We ﬁrst show that nsa satisﬁes all the principles from
P2S2C, and thus cannot be dominated by any semantics.
Proposition 7. The gradual semantics nsa satisﬁes all principles from P2S2C.
The other principles are not satisﬁed.
In order to axiomatically compare nsa with the two other gradual semantics, let
us check for the principles studied in this paper those that are satisﬁed by M&T
and recall those satisﬁed by the h-categorizer semantics.
Proposition 8. The gradual semantics M&T satisﬁes Anonymity, Maximality,
Independence, Directionality, Weakening, Compensation, Self-Contradiction and
Strong Self-Contradiction. The other principles are not satisﬁed.
Proposition 9 ([3]). The gradual semantics h-categorizer satisﬁes all the prin-
ciples from PCREW . The other principles are not satisﬁed.
Note that nsa dominates M&T, i.e. it satisﬁes strictly more principles.
Observe that nsa and h-categorizer are incomparable in terms of principles sat-
isfaction. Indeed, nsa represents one choice, i.e. the position to satisfy Strong
Self-Contradiction and Compensation. It also satisﬁes all the compatible princi-
ples. h-categorizer represents another choice, namely that to satisfy Compensa-
tion, Resilience, Equivalence and Weakening Soundness. Concretely, a semantics
satisfying PCREW considers that a self-attacking argument is a path like the
other ones. So an argument which attacks itself (and is not attacked by any
other argument) can be stronger than an argument which is attacked by several
arguments. On the contrary, a semantics which satisﬁes P2S2C considers that
a self-attacking argument is intrinsically ﬂawed, without even requiring other
arguments to defeat it. Note that there exist other maximal sets of compatible
principles, for example the one containing Resilience and Self-Contradiction. We
leave a detailed study of these maximal sets of compatible principles for future
work.
7
Experimental Results
We now empirically compare nsa with M&T and h-categoriser semantics. We
consider a large experimental setting representing three diﬀerent models used
during the ICCMA competition (http://argumentationcompetition.org/) as a
way to generate random argumentation graphs: i) the Erd¨os-R´enyi model (ER)
which generates graphs by randomly selecting attacks between arguments, ii)
the Barabasi-Albert model (BA) which provides networks, called scale-free net-
works, with a structure in which some nodes have a huge number of links, but
in which nearly all nodes are connected to only a few other nodes, and iii)

On Restricting the Impact of Self-attacking Arguments
143
Table 1. Principles satisﬁed by the M&T, h-categorizer and nsa semantics. The shaded
cells contain the results already proved in the literature.
Principles
M&T h-cat nsa
Anonymity
✓
✓
✓
Independence
✓
✓
✓
Directionality
✓
✓
✓
Neutrality
×
✓
×
Equivalence
×
✓
×
Maximality
✓
✓
✓
Weakening
✓
✓
✓
Counting
×
✓
✓
Weakening Soundness
×
✓
×
Reinforcement
×
✓
×
Resilience
×
✓
×
Cardinality Precedence
×
×
×
Quality Precedence
×
×
×
Compensation
✓
✓
✓
Self-Contradiction
✓
×
✓
Strong Self-Contradiction ✓
×
✓
the Watts-Strogatz model (WS) which produces graphs which have small-world
network properties, such as high clustering and short average path lengths.
The generation of these three types of AGs was done by the AFBenchGen2
generator [15]. We generated a total of 2160 AGs evenly distributed between
the three models. For each model, the number of arguments varies among
Arg = {5, 10, 15, 25, 50, 100, 250, 500} with 90 AGs for each of these values.
The parameters used to generate graphs are as follows: for ER, 10 random
instances for each (numArg, probAttacks) in Arg × {0.2, 0.3, . . . , 1}; for BA, 9
random instances for each (numArg, probCycles) in Arg × {0, 0.1, . . . , 0.9}; for
WS, (numArg, probCycles, β, K) in Arg × {0.25, 0.5, 0.75} × {0, 0.25, 0.5, 0.75, 1}
× {k ∈2N s.t. 2 ≤k ≤|Arg| −1}. We refer the reader to [15] for the meaning
of the parameters.
In order to compare the execution times of the three semantics studied in
this paper, we have implemented them in C and ran the program on a cluster
of identical computers with dual quad-core processors with 128 GB RAM.4
4 The code and benchmarks are available online at https://github.com/jeris90/
nsa code.git.

144
V. Beuselinck et al.
Fig. 2. Execution speed for the nsa (in green), the M&T (in blue) and the h-categorizer
(in red) semantics. x-axis shows the number of arguments of the instances (Arg =
{5, 10, 15, 25, 50, 100, 250, 500}). y-axis shows the execution time in seconds (with a
timeout of 900 s). (Color ﬁgure online)
Fig. 3. A zoomed-in version of the graph from Fig. 2 to better see the diﬀerence between
the execution speed for the nsa and the h-categorizer semantics.
Figure 2 shows the average execution time obtained by each semantics for
the instances classiﬁed according to the number of arguments. A ﬁrst remark
is that, unlike the other two semantics, the M&T semantics quickly explodes
in time since it systematically reaches the timeout (900 s) when the number of
arguments is greater than 15. A second remark is that, unsurprisingly, the nsa
and h-categorizer semantics have very similar execution times for each of the
instances. Figure 3 shows the diﬀerence between nsa and h-categorizer semantics
more precisely. Moreover, they allow us to quickly compute (with an average

On Restricting the Impact of Self-attacking Arguments
145
smaller than one second) the degree of acceptability of each argument even for
large AGs. Only a few very dense instances (i.e. those with a high probability of
cycles) require between 1 and 2 s when numArg = 500.
8
Summary
We studied the question of the treatment of self-attacks by gradual seman-
tics following a principle-based approach. We showed links and incompatibilities
between principles, deﬁned a new semantics called no self-attack h-categorizer
semantics and proved that it dominates the only existing semantics satisfy-
ing Self-Contradiction principle. Moreover, we showed that our semantics satis-
ﬁes a maximal possible amount of principles (i.e. no semantics satisfying Self-
Contradiction can satisfy more principles) and is usable in practice as it returns
results very quickly (on average less than 1 s) even on large and dense AGs.
In addition to the future work already discussed in the paper, we think it
would be interesting to extend the approach we used for the h-categorizer seman-
tics to other gradual semantics (if possible). Finally, the work presented in this
paper concerns “classic” argumentation graphs but one could naturally ask the
same question about AGs containing more information (support relation, weight
on arguments and/or attacks, etc.).
Acknowledgements. Vivien Beuselinck was supported by the ANR-3IA Artiﬁcial
and Natural Intelligence Toulouse Institute. Srdjan Vesic was supported by Responsible
AI Chair a chair in Artiﬁcial Intelligence (https://ia-responsable.eu/).
References
1. Amgoud, L.: A replication study of semantics in argumentation. In: Proceedings of
the 28th International Joint Conference on Artiﬁcial Intelligence (IJCAI’19) (2019)
2. Amgoud, L., Ben-Naim, J.: Ranking-based semantics for argumentation frame-
works. In: Liu, W., Subrahmanian, V.S., Wijsen, J. (eds.) SUM 2013. LNCS
(LNAI), vol. 8078, pp. 134–147. Springer, Heidelberg (2013). https://doi.org/10.
1007/978-3-642-40381-1 11
3. Amgoud, L., Ben-Naim, J.: Axiomatic foundations of acceptability semantics. In:
Principles of Knowledge Representation and Reasoning: Proceedings of the Fif-
teenth International Conference, KR 2016, pp. 2–11. AAAI Press (2016)
4. Amgoud, L., Ben-Naim, J., Doder, D., Vesic, S.: Acceptability semantics for
weighted argumentation frameworks. In: Sierra, C. (ed.) Proceedings of the 26th
International Joint Conference on Artiﬁcial Intelligence, (IJCAI’17), pp. 56–62
(2017)
5. Amgoud, L., Doder, D.: Gradual semantics accounting for varied-strength attacks.
In: Proceedings of the 18th International Conference on Autonomous Agents and
MultiAgent Systems, (AAMAS’19). pp. 1270–1278 (2019)
6. Baroni, P., Caminada, M., Giacomin, M.: An introduction to argumentation
semantics. Knowl. Eng. Rev. 26(4), 365–410 (2011)

146
V. Beuselinck et al.
7. Baroni, P., Giacomin, M.: Solving semantic problems with odd-length cycles in
argumentation. In: Nielsen, T.D., Zhang, N.L. (eds.) ECSQARU 2003. LNCS
(LNAI), vol. 2711, pp. 440–451. Springer, Heidelberg (2003). https://doi.org/10.
1007/978-3-540-45062-7 36
8. Baumann, R., Brewka, G., Ulbricht, M.: Comparing weak admissibility semantics
to their dung-style counterparts - reduct, modularization, and strong equivalence in
abstract argumentation. In: Calvanese, D., Erdem, E., Thielscher, M. (eds.) Proc.
of the 17th International Conference on Principles of Knowledge Representation
and Reasoning, (KR’20), pp. 79–88 (2020)
9. Baumann, R., Brewka, G., Ulbricht, M.: Revisiting the foundations of abstract
argumentation - semantics based on weak admissibility and weak defense. In: Pro-
ceedings of the 34th AAAI Conference on Artiﬁcial Intelligence, (AAAI’20), pp.
2742–2749 (2020)
10. Besnard, P., Hunter, A.: A logic-based theory of deductive arguments. Artif. Intell.
128(1–2), 203–235 (2001)
11. Bodanza, G.A., Tohm´e, F.A.: Two approaches to the problems of self-attacking
arguments and general odd-length cycles of attack. J. Appl. Log. 7(4), 403–420
(2009)
12. Bonzon, E., Delobelle, J., Konieczny, S., Maudet, N.: A comparative study of
ranking-based semantics for abstract argumentation. In: Proceedings of the 30th
AAAI Conference on Artiﬁcial Intelligence (AAAI’16), pp. 914–920 (2016)
13. Bonzon, E., Delobelle, J., Konieczny, S., Maudet, N.: Combining extension-based
semantics and ranking-based semantics for abstract argumentation. In: Proceedings
of the 16th International Conference on Principles of Knowledge Representation
and Reasoning (KR’18), pp. 118–127 (2018)
14. Caminada, M.: On the issue of reinstatement in argumentation. In: Fisher, M., van
der Hoek, W., Konev, B., Lisitsa, A. (eds.) JELIA 2006. LNCS (LNAI), vol. 4160,
pp. 111–123. Springer, Heidelberg (2006). https://doi.org/10.1007/11853886 11
15. Cerutti, F., Vallati, M., Giacomin, M.: Afbenchgen2: a generator for random
argumentation frameworks (2017). http://argumentationcompetition.org/2017/
AFBenchGen2.pdf
16. Dauphin, J., Rienstra, T., van der Torre, L.: A principle-based analysis of weakly
admissible semantics. In: Proceedings of the 8th International Conference on Com-
putational Models of Argument, (COMMA’20), Frontiers in Artiﬁcial Intelligence
and Applications, vol. 326, pp. 167–178 (2020)
17. Dung, P.M.: On the acceptability of arguments and its fundamental role in non-
monotonic reasoning, logic programming and n-person games. Artif. Intell. 77(2),
321–358 (1995)
18. Gabbay, D.M., Rodrigues, O.: Equilibrium states in numerical argumentation net-
works. Log. Univers. 9(4), 411–473 (2015). https://doi.org/10.1007/s11787-015-
0119-7
19. Matt, P.-A., Toni, F.: A game-theoretic measure of argument strength for abstract
argumentation. In: H¨olldobler, S., Lutz, C., Wansing, H. (eds.) JELIA 2008. LNCS
(LNAI), vol. 5293, pp. 285–297. Springer, Heidelberg (2008). https://doi.org/10.
1007/978-3-540-87803-2 24
20. Pu, F., Luo, J., Zhang, Y., Luo, G.: Argument ranking with categoriser function. In:
Buchmann, R., Kifor, C.V., Yu, J. (eds.) KSEM 2014. LNCS (LNAI), vol. 8793, pp.
290–301. Springer, Cham (2014). https://doi.org/10.1007/978-3-319-12096-6 26

Flexible Dispute Derivations with Forward and
Backward Arguments for Assumption-Based
Argumentation
Martin Diller(B)
, Sarah Alice Gaggl
, and Piotr Gorczyca
Logic Programming and Argumentation Group, Faculty of Computer Science,
Technische Universit¨at Dresden, Dresden, Germany
martin.diller@tu-dresden.de
Abstract. Assumption-based argumentation (ABA) is one of the main general
frameworks for structured argumentation. Dispute derivations for ABA allow for
evaluating claims in a dialectical manner: i.e. on the basis of an exchange of argu-
ments and counter-arguments for a claim between a proponent and an opponent
of the claim. Current versions of dispute derivations are geared towards deter-
mining (credulous) acceptance of claims w.r.t. the admissibility-based seman-
tics that ABA inherits from abstract argumentation. Relatedly, they make use of
backwards or top down reasoning for constructing arguments. In this work we
deﬁne ﬂexible dispute derivations with forward as well as backward reasoning
allowing us, in particular, to also have dispute derivations for ﬁnding admissible,
complete, and stable assumption sets rather than only determine acceptability of
claims. We give an argumentation-based deﬁnition of such dispute derivations
and a more implementation friendly alternative representation in which disputes
involve exchange of claims and rules rather than arguments. These can be seen
as elaborations on, in particular, existing graph-based dispute derivations on two
fronts: ﬁrst, in also allowing for forward reasoning; second, in that all arguments
put forward in the dispute are represented by a graph and not only the proponents.
Keywords: Argumentation · Assumption-based argumentation · Dispute
derivations
1
Introduction
Assumption-based argumentation [3,4,12,16,34] (ABA) is one of the main formalisms
for structured argumentation [2], also very much related to ASPIC+ [18,27,28]. ABA
frameworks are built from a deductive system consisting of a language and set of rules.
ABA arguments are then proofs in such a deductive system. Certain elements of the
language are singled out as assumptions and a total mapping is provided associating
each assumption to its so called contrary. Assumptions, and thus arguments using such
This research was partially funded by the Deutsche Forschungsgemeinschaft (DFG, German
Research Foundation) – project number 389792660 – TRR 248, and by the Bundesministerium
f¨ur Bildung und Forschung (BMBF) F¨orderkennzeichen 01IS20056 NAVAS.
c⃝Springer Nature Switzerland AG 2021
P. Baroni et al. (Eds.): CLAR 2021, LNAI 13040, pp. 147–168, 2021.
https://doi.org/10.1007/978-3-030-89391-0_9

148
M. Diller et al.
assumptions, can be attacked by arguments for their contraries. For ﬂat ABA, which
we will be focusing on this work (and has, as far as we are aware, also been the
focus of all other work on reasoning methods for ABA), semantics can be equivalently
deﬁned at the level of assumption sets as well as arguments. In either case one ulti-
mately obtains sets of assumptions which can be deemed reasonable to the same degree
that the arguments that can be built from them are reasonable according to the classical
admissibility-based semantics of abstract argumentation [14].
One of the main reasoning methods which has been devised for (ﬂat) ABA is that of
dispute derivations [10,11,15,17,20,33]. These build on one of if not the main native
(vs reduction-based [9]) method for reasoning in abstract argumentation; namely, argu-
mentation games (see e.g. [5,7,8,13,21–23,26,29,31,35]). Dispute derivations are con-
ceived of as a game between a proponent and opponent, where starting from some goal
claim the proponent searches for an argument proving the goal. This search reveals
assumptions on which the proof depends, which can be attacked by the opponent
by arguments for their contraries. Such arguments from the opponent can in turn be
attacked by the proponent by searching for further arguments and so on. Dispute deriva-
tions can be seen as hybrid syntactic-semantic methods for searching for only those
arguments needed to answer a query and are thus related to the issue of selecting such
relevant arguments in structured argumentation more general [1,6,19,30,32,36].
Although reduction-based methods also for reasoning in ABA (as for abstract
argumentation) have to date proved to be much more efﬁcient than dispute deriva-
tions [24,25], dispute derivations remain interesting for a number of reasons. The main
of these is that reducing argumentation to other formalisms often undermines the pur-
pose of using argumentation in the ﬁrst place; which is presumably to allow for a dialec-
tic evaluation of claims in terms of arguments and counter-arguments. Dispute deriva-
tions deliver such “dialectic explications”. This makes them especially suitable when
information is limited and unreliable; also, for approximate, dynamic, and interactive
reasoning.
As detailed, there have been several versions of dispute derivations to date. But all
have in common that they are conceived primarily as decision procedures for determin-
ing credulous acceptance of a claim w.r.t. the admissible-based semantics (in the ﬁrst
versions of dispute derivations focus was on grounded, admissible, and ideal semantics;
in later [10,11] versions the ideal semantics is dropped); i.e. whether there is an admis-
sible (and hence complete and preferred) assumption set from which the claim can be
proven. Related to this, they make use of backwards reasoning: both the proponent and
opponent make use of top down or backwards reasoning to search for their arguments.
Top down reasoning is often enough. In particular, for the focused task of determin-
ing credulous acceptance of claims; yet, another fundamental paradigm in reasoning is
forward or bottom up from established claims to further claims. In the context of dispute
derivations such reasoning becomes relevant for more global tasks as e.g. determining
acceptance of several claims or, relatedly, determining complete assumption sets rather
than only credulous acceptance. Moreover, while for determining credulous acceptance
computing e.g. complete assumption sets is not necessary, more revealing explications
can often be obtained. In particular, computing complete assumption sets allows, as
the name of the semantics suggests, a more “complete” picture of sets of assumptions

Flexible Dispute Derivations for ABA
149
which are congruous with a claim of interest. Furthermore, forward reasoning allows a
straightforward generalisation of dispute derivations also for the stable semantics, this
semantics not having been considered in previous work on disputes for ABA.
So in this work we add forward reasoning to dispute derivations. This allows us,
in particular, to deﬁne dispute derivations for ﬁnding admissible, complete, and stable
assumption sets as well as for determining acceptance of claims w.r.t. these semantics.
We do so in several steps. We start in Sect. 3 by considering dispute derivations from an
implementation independent and purely argumentation-based perspective: i.e. in terms
of the arguments that are exchanged by the proponent and opponent. In particular, espe-
cially for forward reasoning how much of a dispute is “remembered” and made use of
in further dispute steps is crucial. We provide a deﬁnition of ﬂexible dispute deriva-
tions (with forward and backward arguments) based on structured dispute derivations
from [33] and then graph-based dispute derivations from [10] in Sect. 3.2. The only
thing that distinguishes these variants of dispute derivations is precisely how much of
previous dispute steps is made use of in further steps. We note that there is room for
improvement in this regard, particularly for the purpose of forward reasoning, and thus
propose a novel variant of ﬂexible dispute derivations in Sect. 3.3.
We then in Sect. 4 change gear to a more implementation focused perspective more
in line with existing work on ABA disputes and give an alternative representation of
our novel variant of dispute derivations from Sect. 3.3. In this version disputes involve
the exchange of claims and rules rather than arguments; in particular, the opponents and
proponents arguments are represented in a shared graph consisting in the dependency
relations between rules and statements put forward during the dispute. Thus we further
generalise [10] in which only the proponents arguments are represented as a graph,
while the opponents are not. In Sect. 5 we then provide details on an interactive interface
we implemented for our dispute derivations that is freely available. Section 2 contains
the background needed for our work and Sect. 6 the conclusions.
2
Formal Background
Deﬁnition 1. An ABA framework is a tuple F = (L ,R,A , ) where
– (L ,R) is a deductive system, with a language L and a set of inference rules R,
– A ⊆L is a (non-empty) set, whose elements are referred to as assumptions,
–
is a total mapping from A into L , where a is the contrary of a.
We also deﬁne for a set of statements S ⊆L , S = {u ∈L | u ∈(S ∩A )}. As in pre-
vious work on dispute derivations, here we also restrict our attention to ﬂat ABA: i.e.
frameworks where there is no rule h ←B ∈R s.t. h ∈A . In all of this work we will
consider the ABA framework to be ﬁxed and thus not deﬁne notions relative to an ABA
framework. Elements of L we will refer to as statements, sometimes as claims.
Arguments have been deﬁned in several different ways for ABA. For a comprehen-
sive deﬁnition we deﬁne arguments in ASPIC+ [27] style:
Deﬁnition 2. For an ABA F = (L ,R,A , ), an argument is deﬁned as follows.

150
M. Diller et al.
(i) a = s is an argument if s ∈L . Then Prem(a) = {s}, Asm(a) = {s}∩A , Conc(a) = s,
TopSub(a) = {s}, Sub(a) = {s}.
(ii) a = s ←a1,...,an is an argument if a1,...,an are arguments such that there
exists s ←Conc(a1),...,Conc(an) ∈R. Then Prem(a) = Prem(a1)∪...∪Prem(an),
Asm(a) = Asm(a1) ∪... ∪Asm(an) ∪({s} ∩A ), Conc(a) = s, TopSub(a) = {s} ∪
{s ←a′
1,...,a′
n | a′
1 ∈TopSub(a1),...,a′
n ∈TopSub(an)}, Sub(a) = Sub(a1) ∪...∪
Sub(an)∪TopSub(a).
For instance let a = p ←b,[q ←r,s] be an argument built from rules p ←b,q
and q ←r,s with only b ∈A . Then we have that the premisses of the argument are
Prem(a) = {b,r,s}, the assumptions Asm(a) = {b}, the conclusion Conc(a) = p, the
top-sub-arguments TopSub(a) = {p; p ←b,q; p ←b,[q ←r,s]}, and the sub-arguments
Sub(a) = {b; r; s; q ←r,s}∪TopSub(a). We extend the above notions to sets of argu-
ments in the obvious manner; e.g. for a set of arguments A, Prem(A) = 
a∈A Prem(a).
We denote all arguments in F as Args. An argument a is complete if Prem(a) ⊆A .
This is what is usually called an argument for ABA; what we have deﬁned are “potential
arguments”. The reason for the latter being that these are what dispute derivations work
on. Related to this, note that our notion of sub-arguments, differently to what is the
case in ASPIC+, includes all sub-arguments; not only those with the same premisses
as the main argument. Given that statements and rules can be thought of as (potential)
simple arguments we notationally and otherwise will usually not distinguish between
such simple arguments and the statements and rules underlying them.
Attacks in (ﬂat) ABA can be deﬁned between assumption sets, between arguments,
as well as in the form of hybrid attacks between assumptions and arguments. This leads
to equivalent assumption, argument, and hybrid views respectively of the semantics.
Dispute derivations are based on a hybrid view and so we here review this perspective.
Deﬁnition 3. The notions of attack we need are:
– An argument a attacks a set of assumptions U′ if Conc(a) = u′ for a u′ ∈U′.
– A set of assumptions U attacks a set of assumptions U′ if there is a (complete) argu-
ment a with Prem(a) ⊆U that attacks U′. In particular, if U′ = {u′} (i.e. U′ is a
singleton set with only the assumption u′) we say simply that U attacks u′.
– A set of assumptions U attacks an argument a′ if there is a (complete) argument a
with Prem(a) ⊆U that attacks Asm(a′).
Deﬁnition 4. The deﬁnitions of the semantics we mainly consider in this work are:
– A set of assumptions is admissible if it does not attack itself and it attacks all com-
plete arguments that attack it.
– A set of assumptions is complete if it is admissible and contains all assumptions
it defends, where U ⊆A defends u ∈A if U attacks all complete arguments that
attack u.
– A set of assumptions is stable if it does not attack itself and attacks all assumptions
it does not contain.
A set of statements S is (credulously) acceptable w.r.t. a semantics σ if there is a σ
assumption set U w.r.t. which S ⊆Conc(A) for A ⊆Args with Asm(A) ⊆U.

Flexible Dispute Derivations for ABA
151
3
Argument-Based Flexible Dispute Derivations
In this section we develop rather abstract (not implementation focused) deﬁnitions of
ﬂexible dispute derivations, ﬁrst of all, following structured dispute derivations [33]
and then graph-based dispute derivations [10] (Sect. 3.2). We call these StFlexDDs and
GrFlexDDs for short. We focus on the common aspects of these, at ﬁrst sight, rather
different looking versions of dispute derivations by considering how the disputes evolve
in terms of the arguments put forward by the proponent and opponent.
We identify certain shortcomings (inherited from their non-ﬂexible counterparts)
in the manner in which StFlexDDs and GrFlexDDs make use of the arguments con-
structed in previous steps in the disputes. These shortcomings are particularly relevant
for incorporating forward reasoning into dispute derivations, since forward reasoning
builds on established claims. We thus then propose a different form of dispute deriva-
tions which we call simply ﬂexible dispute derivations or FlexDDs for short (Sect. 3.3).
Although from an argument-based perspective FlexDDs seem quite complex, we will
see in Sect. 4 that in fact they lead to an equally natural yet implementation friendly
alternative representation where claims and rules are put forward rather than arguments.
3.1
Argument and Dispute State Expansions
Basic moves both from the proponent and opponent in ﬂexible dispute derivations
involve expansions of arguments which we deﬁne as follows:
Deﬁnition 5. An expansion of A = {a1,...,an} ⊆Args w.r.t. an argument a′ ∈Args
with Conc(a1) ∪... ∪Conc(an) ⊆Prem(a′) is obtained from a′ by replacing at least
one si ∈Prem(a′) for which si = Conc(ai) with ai for each 1 ≤i ≤n. We denote it
a′ ⋖A. When n = 1, we will often denote the expansion as a′ ⋖a1.
Thus a forward expansion of a set of arguments A w.r.t. R (now taken as a set of 1-step
arguments) is of the form r ⋖A with r ∈R. A backward expansion of an argument a
w.r.t. R amounts to an expansion of the form a⋖r with r ∈R.
Disputes consist of sequences of dispute states which we deﬁne simply as tuples
(B,P) where B ⊆Args are the arguments considered by the opponent and P ⊆Args
those considered by the proponent. The different types of moves which the proponent
and opponent can make in a dispute amount to “expanding” either B or P. The expan-
sion is by an argument a with i) a = u ∈A , ii) a = h ←B, iii) a = h ←B ⋖A′ or iv)
a = a′ ⋖h ←B for A′ ⊆B and a′ ∈B, or A′ ⊆P, a′ ∈P respectively, h ←B ∈R.
There are several viable options for deﬁning such expansions. These correspond to
differences in how much of the arguments put forward during a dispute is “remem-
bered” and considered in future expansions by the proponent and opponent. The dif-
ferent variants of ﬂexible dispute derivations we consider in this work, i.e. StFlexDDs,
GrFlexDDs, and FlexDDs will differ precisely on the underlying notion of expansion.

152
M. Diller et al.
Table 1. Auxiliary notation for argument-based ﬂexible dispute derivations. All deﬁned w.r.t. a
dispute state (B,P).
Notation
Description
D = Asm(P)
Defenses
C = {u ∈A | u ∈Conc(P)}
Culprits
R−= {h ←B ∈R | B∩C ̸= /0}
Blocked rules (culprits in bodies)
R∼= {h ←B ∈R | ({h}∪B)∩(B∪C ∪D) ̸= /0} Rules blocked for the proponent (either
inconsistent; otherwise culprits or contraries
of defenses in head or body)
P∗= {a ∈P | Prem(a) ⊆A }
Proponents complete arguments
B∗/−= {a ∈B | Prem(a) ⊆(A \C )}
Opponents complete unblocked arguments
P+ = {a ∈P \P∗| ¬∃a′ ̸= a ∈
P s.t. Conc(a′) = Conc(a) and a′ ∈P∗or a ∈
Sub(a′)}
Maximal incomplete proponent arguments
P#
γ∪C = {a ∈P+ | Conc(a) ∈γ ∪C }
Maximal incomplete proponent arguments
for goals and contraries of culprits
B!/−
S
= {a ∈B | Asm(a)∩C = /0,Conc(a) ∈S} Unblocked arguments with conclusions in
S ⊆L
A ! = {u ∈A | u ∈Asm(B!/−
D )}
Candidates for culprits
I = {u ∈A \C | u ̸∈Conc(B∗/−)}
Assumptions defended at the dispute state
3.2
Argument-Based Flexible Dispute Derivations Following Structured and
Graph-Based Dispute Derivations
Flexible Structured Dispute Derivations. Dispute derivations consist of a sequence of
dispute states which are tuples of the form (B,P) where B ⊆Args are the opponents
and P ⊆Args the proponents arguments. Dispute derivations are also deﬁned for a set
of goals γ ⊆L which we assume to be consistent; i.e. γ ∩γ = /0. Note that we consider a
set of goals here rather than a single goal as in previous versions of dispute derivations.
In Table 1 we give deﬁnitions of several auxiliary notions needed to deﬁne the pos-
sible moves in dispute derivations. These are all deﬁned w.r.t. a dispute state (B,P).
Dispute derivations consist of a sequence of dispute advancements either by the
proponent or the opponent and a termination condition indicating when the dispute has
concluded. Each of the advancements consist of a move by the proponent or opponent,
there being several conceivable “backward” and “forward” moves that accord with ABA
semantics. We give thus a very general deﬁnition of dispute advancements including all
such conceivable moves in what follows. The moves can be restricted in several ways to
obtain, together with tailored termination conditions, restricted dispute variants which,
for instance, are sound w.r.t. the admissible, complete, or stable semantics.
For StFlexDDs1 a proponent dispute state advancement from a dispute state (B,P)
is a dispute state (B,P′) with P′ = P ∪{a} ̸= P, X1 ⊆A , X2 ⊆A where either
1 Note that in [10,33] the rules blocked for the proponent and opponent are identical (i.e. R−),
while we use the stronger notion of blocked rules for the proponent R∼.

Flexible Dispute Derivations for ABA
153
P-B-⟨A ! ∪X1⟩:
i) a = a′ ⋖h ←B for h ←B ∈R \R∼, a′ ∈P#
γ∪C ; or
ii) a = h ←B for h ←B ∈R \R∼with h ∈(A ! ∪X1)\D;
P-F–⟨(A ! ∩A )∪X2⟩: i) a = h ←B⋖A for A ⊆P∗, h ←B ∈R \R∼; or
ii) a = u for u ∈((A ! ∩A )∪X2)\({u}∪C ∪D).
An opponent dispute state advancement from a dispute state (B,P) is a dispute
state (B′,P) with B′ = B ∪{a} ̸= B, Y1 ⊆A , and Y2 ⊆A where either
O-B-⟨D ∪Y1⟩:
i) a = a′ ⋖h ←B for a′ ∈B!/−
D ∪Y1, h ←B ∈R \R−; or
ii) a = h ←B for a h ←B ∈R \R−with h ∈D ∪Y1;
O-F-⟨(D ∩A )∪Y2⟩: i) a = h ←B⋖A for A ⊆B∗/−, h ←B ∈R \R−; or
ii) a = u for u ∈(D ∩A )∪Y2 \C .
Each of the types of moves in disputes, e.g. P-B-⟨A ! ∪X1⟩which represents a back-
ward move from the proponent, depend on a parameter, here X1 ⊆A . When X1 = A ,
the move P-B is “least constrained”. P-B is “most constrained” when X1 = {}. The latter
we denote as P-B-⟨A !⟩. The least constrained moves give us the most general possi-
ble dispute advancements, which we denote “free style” (DF) dispute advancements.
The most constrained moves gives us dispute advancements which are sound and com-
plete (when L is ﬁnite and R is acyclic) for credulous acceptance w.r.t. the admissible
semantics. These, which we denote DAB, follow previous versions of dispute deriva-
tions as in [33] and [10]. The dispute advancements we consider in this work, including
also for complete and stable semantics, are summarised in Table 2. Here e.g. for dispute
advancements of type DAB, the proponent can move in P-B-⟨A !⟩manner: both making
P-B-⟨A !⟩-i or P-B-⟨A !⟩-ii moves. On the other hand, the proponent can move in P-F-
⟨A ! ∩A ⟩-ii but not in P-F-⟨A ! ∩A ⟩-i manner. The dispute advancement types listed
in Table 2 are just a few of the most obvious of several possible combinations. Note
that DAB ⊆DABF (i.e. DAB moves are DABF moves), DABF ⊆DC, DABF ⊆DS,
DC ⊆DF, and DS ⊆DF (also, usually ⊊).
Table 2. Dispute advancements with DAB for credulous acceptance w.r.t. the admissible seman-
tics, DABF for credulous acceptance w.r.t. the admissible semantics but including “conservative”
forward moves of the proponent, DC for the complete semantics, DS for the stable semantics,
and DF for “free style”. Columns “Proponent” and “Opponent” represent allowed moves by the
proponent and opponent respectively.
Advancement Proponent
Opponent
DAB
P-B-⟨A !⟩, P-F-⟨A ! ∩A ⟩-ii
O-B-⟨D⟩, O-F-⟨D ∩A ⟩-ii
DABF
P-B-⟨A !⟩, P-F-⟨A ! ∩A ⟩
O-B-⟨D⟩, O-F-⟨D ∩A ⟩-ii
DC
P-B-⟨A !⟩, P-F-⟨(A ! ∩A )∪I ⟩O-B-⟨D ∪I ⟩, O-F-⟨(D ∪I )∩A ⟩-ii
DS
P-B-⟨A !⟩, P-F-⟨A ⟩
O-B-⟨D⟩, O-F-⟨D ∩A ⟩-ii
DF
P-B-⟨A ⟩, P-F-⟨A ⟩
O-B-⟨A ⟩, O-F-⟨A ⟩

154
M. Diller et al.
Table 3. Termination conditions. TA for admissible, TC for complete, and TS for stable.
Cond. Proponent winning
Opponent cannot move
Proponent cannot move
TA
γ ∪C ⊆Conc(P∗),
B!/−
D
∩B∗/−= /0
O-B-⟨D⟩+
O-F-⟨D ∩A ⟩-ii or
O-F-⟨A ⟩
P-B-⟨A !⟩+
P-F-⟨A ! ∩A ⟩-ii or
P-F-⟨A ⟩
TC
γ ∪C ⊆Conc(P∗),
B!/−
D
∩B∗/−= /0,
I \D = /0
O-B-⟨D⟩+
O-F-⟨D ∩A ⟩-ii or
O-F-⟨A ⟩
P-B-⟨A !⟩+
P-F-⟨(A ! ∩A )∪I ⟩or
P-F-⟨A ⟩
TS
γ ∪C ⊆Conc(P∗),
B!/−
D
∩B∗/−= /0,
D ∪C = A
O-B-⟨D⟩+
O-F-⟨D ∩A ⟩-ii or
O-F-⟨A ⟩
P-B-⟨A !⟩+ P-F-⟨A ⟩
The termination conditions we consider in this work are summarised in Table 3.
There is, ﬁrst of all, a condition that has to be satisﬁed at a dispute state (B,P) for
the proponent to be winning. This is in the column “Proponent winning”. Then the
proponent wins if this condition is satisﬁed and the opponent cannot move in either
of the two possible combinations of moves in the column “Opponent cannot move”.
The opponent wins if the “Proponent winning” condition is not satisﬁed and the pro-
ponent cannot move in either of the two possible combinations of moves in the column
“Proponent moves”. So, for the termination condition for the admissible semantics TA,
we have that the proponent wins if γ ∪C ⊆Conc(P∗), B!/−
D
∩B∗/−= /0 and the
opponent cannot advance further either in DAB manner: O-B-⟨D⟩+O-F-⟨D ∩A ⟩-ii;
or in forwards DF manner: O-F-⟨A ⟩. The opponent wins if γ ∪C \ Conc(P∗) ̸= /0 or
B!/−
D
∩B∗/−̸= /0 and the proponent cannot advance further either in DAB manner:
P-B-⟨A !⟩+P-F-⟨A ! ∩A ⟩-ii or in forwards DF manner: P-F-⟨A ⟩.
A dispute derivation variant then depends on allowed moves M and termination cri-
teria C. For simplicity we allow that termination criteria make reference to moves which
may not be allowed at a speciﬁc dispute variant; i.e. although moves are restricted these
are all conceived as subsets of dispute variants where advancements are as in DF and
hence checking for DF moves (and any other subset) is possible. As already indicated,
dispute variants are deﬁned for a set of goals γ ⊆L (s.t. γ ∩γ = /0). They consist of
a sequence of dispute states starting at ({},γ). At each step the last dispute state is
selected and advanced either according to the proponent or opponent and the allowed
moves M. The dispute derivation ends at a dispute state satisfying the termination cri-
teria C.
Example 1. Consider the ABA framework from Example 6.2 in [33] with A = {a,b,c,
d, e, f}, where a = q, b = f, c = u, d = v, e = v, f = v. Also:
R = {p ←a,u; q ←b,r; q ←c,s; q ←c,t; u ←a; s ←; t ←d; t ←e}.
A DAB + TA StFlexDD following the structured dispute derivation of Fig. 7 in [33]
is shown in Table 4. Note ﬁrst of all, that in order to follow structured dispute deriva-
tions as in [33] the opponent must, for every statement that it (backward-) expands

Flexible Dispute Derivations for ABA
155
Table 4. A DAB+TA StFlexDD for Example 1. Labels −, ∗, #, ! are used to distinguish blocked,
complete, maximal incomplete, and opposing arguments respectively. Only complete and maxi-
mal incomplete arguments for goals and contraries of culprits of the proponent are shown. The
dispute derivation ends with the opponent not being able to advance further in O-B-⟨D⟩+O-F-
⟨D ∩A ⟩-ii manner.
Step and move type
P
B
(γ ∪C )\Conc(P ∗)
D
C
0
{# p}
{}
{p}
{}
{}
1 (P-B-i, p ←a,u)
{# p ←a,u}
{}
{p}
{a}
{}
2 (O-B-ii, q ←b,r)
{# p ←a,u}
{!q ←b,r}
{p}
{a}
{}
3 (O-B-ii, q ←c,s)
{# p ←a,u}
{!q ←b,r; !q ←c,s}
{p}
{a}
{}
4 (O-B-ii, q ←c,t)
{# p ←a,u}
{!q ←b,r; !q ←c,s; !q ←c,t}
{p}
{a}
{}
5 (P-B-ii, u ←a)
{# p ←a,u; ∗u ←a}
{!q ←b,r; −!q ←c,s;
−!q ←c,t}
{p}
{a}
{c}
6 (P-B-i, u ←a)
{∗u ←a; ∗p ←a,[u ←a]}
{!q ←b,r; −!q ←c,s;
−!q ←c,t}
{}
{a}
{c}
7 (P-F-ii, f)
{∗u ←a; ∗p ←a,[u ←a]; ∗f}
{−!q ←b,r; −!q ←c,s;
−!q ←c,t}
{}
{a, f}
{b,c}
Table 5. A DF+TA StFlexDD for Example 2. Only complete and maximal incomplete arguments
of the proponent are shown. The dispute derivation ends with the opponent not being able to
advance further in O-F-⟨A ⟩manner.
Step and move type P
B
(γ ∪C )\Conc(P∗) D
C
0
{ #p }
{}
{p}
{}
{b,c}
1 (P-B-i, p ←a)
{ ∗p ←a } {}
{}
{a} {b,c}
2 (O-F-ii, a)
{ ∗p ←a } {∗a}
{}
{a} {b,c}
3 (O-F-i, p ←a)
{ ∗p ←a } { ∗a;
∗p ←a } {}
{a} {b,c}
on (e.g. q in the example in steps 2–4), expand the statement with every non-blocked
rule. This is not necessary in StFlexDDs. Secondly, note that structured dispute deriva-
tions from [33] include a tracking mechanism whereby arguments that are not neces-
sary for further evolution of the dispute derivation are discarded. As we strive for a
general deﬁnition which allows us to consider several manners of expanding the oppo-
nents and proponents argument we do not do this here. For a direct implementation
of StFlexDDs one could e.g. only store complete and maximal incomplete arguments
of the proponent; also, one could remove arguments from the opponent which have
been fully backward expanded. In fact, to simplify the example, we do not show all the
proponents arguments in Table 4.
Nevertheless, we note in the dispute derivation from Table 4 redundancy in the
moves. In particular, u ←a is used twice by the proponent and it is only the second use
that makes c a culprit. The reason is that following [33] the proponent is only “aware”
of its arguments, but not of their internal structure.
Example 2. Consider the ABA framework with A = {a,b,c}, where a =t, b = p,c = p;
and
R = {p ←a; t ←b; t ←c; t ←u; u ←v; v ←u}.

156
M. Diller et al.
A DF + TA StFlexDD (which also satisﬁes TC and TS) is shown in Table 5. Note that
any DAB + TA dispute derivation for the same example will not terminate because of
the circularity in the rules u ←v and v ←u. Even when replacing these circular rules
with a very long chain of rules starting at t ←u and ending e.g. with a rule with one
of b or c in the body, one gets a much shorter dispute derivation using forward moves.
Note nevertheless again here the redundancy in particular in the need for the opponent
to essentially repeat the moves by the proponent.
For ﬂexible dispute derivations following structured dispute derivations and the
variants we consider in this section we have the following results generalising the results
for structured dispute derivations (for credulous reasoning w.r.t. the admissible seman-
tics; i.e. DAB+TA in our context) from [33] in our more ﬂexible setting:
Theorem 1. DF+{TA,TC,TS} StFlexDDs are sound for the admissible, complete, and
stable semantics respectively. This means e.g. for DF + TA that if there is a DF + TA
StFlexDD ending with a dispute state (B,P) and the proponent as winner, then D is
an admissible assumption set w.r.t. which γ is acceptable.
Corollary 1. {DAB,DABF,DC,DS}+{TA,TC,TS} StFlexDDs are sound for the
admissible, complete, and stable semantics respectively.
Theorem 2. If L is ﬁnite and R is acyclic, DAB + TA StFlexDDs are complete for
credulous acceptance w.r.t. the admissible semantics. I.e. if γ is acceptable for some
admissible assumption set, then there is a DAB + TA StFlexDD ending with a dispute
state (B,P) and the proponent as winner, s.t. D is an admissible assumption set w.r.t.
which γ is acceptable. Moreover, DC + TC StFlexDDs are complete for the complete
semantics and DS + TS StFlexDDs are complete for the stable semantics. E.g. for the
complete semantics: if γ is acceptable for some complete assumption set U, then there is
a DC+TC StFlexDD ending with a dispute state (B,P) and the proponent as winner,
s.t. D = U. Finally, {DC,DS,DF} + TA StFlexDDs are complete for the admissible
semantics.
Corollary 2. If L is ﬁnite and R is acyclic, {DABF,DC,DS,DF}+TA StFlexDDs are
complete for credulous acceptance w.r.t. the admissible semantics. Also, DF + TC
StFlexDDs are complete for the complete semantics and DF+TS StFlexDDs are com-
plete for the stable semantics.
Flexible Graph-Based Dispute Derivations. We only need to change the notion of
expansion of the opponents, respectively proponents arguments in the deﬁnition of dis-
pute advancements to get GrFlexDDs. Speciﬁcally, we need the following notions:
Deﬁnition 6. Let A ⊆Args and a ∈Args. Then A⋊{a} is the rule minimal (also called
non bloated in [10]) closure of A∪{a} under sub-arguments and argument expansions.
Here, ﬁrst of all, A′ ⊆Args is closed under sub-arguments if A′ = Sub(A′). Moreover, A′
is closed under expansions if a′ = a′′ ⋖A′′ for some a′′ ∈A′, A′′ ⊆A′, then also a′ ∈A′.
Also, A′ is rule minimal if there are no h ←B,h′ ←B′ ∈Sub(A′) s.t. h = h′ but B ̸= B′.
Then, assuming A is closed under sub-arguments, closed under argument expansions,

Flexible Dispute Derivations for ABA
157
Table 6. A DAB+TA GrFlexDD for Example 3 (ABA framework from Example 1). Only max-
imal arguments of the proponent (for goals and contraries of culprits) and the opponent (for
contraries of defenses) are shown. The dispute derivation ends with the opponent not being able
to advance further in O-B-⟨D⟩+O-F-⟨D ∩A ⟩-ii manner.
Step and move type
P
B
γ ∪C \Conc(P ∗)
D
C
0
{ #p }
{}
{p}
{}
{}
1 (P-B-i, p ←a,u)
{#p ←a,u }
{}
{p,u}
{a}
{c}
2 (O-B-ii, q ←b,r)
{ #p ←a,u }
{ !q ←b,r }
{p,u}
{a}
{c}
3 (P-B-i, u ←a)
{∗u ←a;
∗p ←a,[u ←a]
}
{ !q ←b,r }
{}
{a}
{c}
4 (P-F-ii, f)
{∗u ←a;
∗p ←a,[u ←a];
∗f }
{−!q ←b,r }
{}
{a, f}
{b,c}
and rule minimal, A ⋊{a} is the closure under sub-arguments and argument expan-
sions of A ∪{a} if this closure is also rule minimal, while otherwise A ⋊{a} = A (i.e.
expansions which bloat the argument set are disallowed).
On the other hand, A : {a} is the argument rule minimal union of A and a. Here
A′ ⊆Args is argument rule minimal if for each a′ ∈A′, {a′} is rule minimal (such
an a′ is also called non-ﬂabby in [10]). Then, assuming A is argument rule minimal,
A : {a} = A ∪{a} if A ∪{a} is argument rule minimal, while otherwise A : {a} = A
(i.e. a must be rule minimal, aka non-ﬂabby).
In GrFlexDDs a proponent dispute state advancement from a dispute state (B,P)
is a dispute state (B,P′) with P′ = P ⋊{a} ̸= P, X1 ⊆A , X2 ⊆A with P-B-
⟨A ! ∪X1⟩and P-F–⟨(A ! ∩A ) ∪X2⟩moves deﬁned as before. An opponent dispute
state advancement from a dispute state (B,P) is a dispute state (B′,P) with B′ =
B : {a} ̸= B, Y1 ⊆A , and Y2 ⊆A with O-B-⟨D ∪Y1⟩and O-F-⟨(D ∩A )∪Y2⟩moves
deﬁned as previously.
Example 3. Consider again the ABA framework from Example 1. To compare, a
DAB+TA GrFlexDD following more or less that in Table 4 is shown in Table 6. Note
that here c becomes a culprit already at step 1, while in the DAB + TA StFlexDD of
Table 4 this happens at step 5 (since only then is there an argument in P with conclu-
sion c = u). Also, u ←a only needs to be used once by the proponent, while in the
dispute derivation of Table 4 this occurs twice. In the end the dispute becomes shorter
by 3 steps.
Example 4. Consider a slightly more complex version of the ABA framework from
Example 16 in [10] with A = {a,b,c,d}, where a = t, b = r, c = t, d = c. Also:
R = {p ←q; q ←a; r ←p; t ←b; t ←p,s; t ←q,u,d}.
A DAB+TA GrFlexDD based on the graph-based dispute derivation of Table 8 in [10]
(the ﬁrst 4 steps correspond to the whole dispute derivation in [10], except that here
t ←b is invoked by the opponent rather than simply b) is shown in Table 7. Note
the redundancy in steps 6–7 of the opponent where the argument p ←[q ←a] is con-
structed again. Also q ←a is used in step 7 and then again in step 9.

158
M. Diller et al.
Table 7. A DAB+TA GrFlexDD for Example 4. Only maximal arguments of the proponent (for
goals and contraries of culprits) and the opponent (for contraries of defenses) are shown. The
dispute derivation ends with the opponent not being able to advance further in O-B-⟨D⟩+O-F-
⟨D ∩A ⟩-ii manner.
Step and move type
P
B
γ ∪C \Conc(P ∗)
D
C
0
{ #p }
{}
{p}
{}
{}
1 (P-B-i, p ←q)
{ #p ←q }
{}
{p}
{}
{}
2 (P-B-i, q ←a)
{ ∗p ←[q ←a] }
{}
{}
{a}
{}
3 (O-B-ii, t ←b)
{ ∗p ←[q ←a] }
{ ∗!t ←b }
{}
{a}
{}
4 (P-B-ii, r ←p )
{∗p ←[q ←a];
∗r ←[p ←[q ←a]] }
{ −∗!t ←b }
{}
{a}
{b}
5 (O-B-ii, t ←p,s )
{∗p ←[q ←a];
∗r ←[p ←[q ←a]] }
{−∗!t ←b; !t ←p,s }
{}
{a}
{b}
6 (O-B-i, p ←q )
{∗p ←[q ←a];
∗r ←[p ←[q ←a]] }
{−∗!t ←b;
!t ←[p ←q],s
}
{}
{a}
{b}
7 (O-B-i, q ←a )
{∗p ←[q ←a];
∗r ←[p ←[q ←a]] }
{−∗!t ←b;
!t ←[p ←[q ←a]],s}
{}
{a}
{b}
8 (O-B-ii, t ←q,u,d )
{∗p ←[q ←a];
∗r ←[p ←[q ←a]] }
{−∗!t ←b;
!t ←[p ←[q ←a]],s;
!t ←q,u,d }
{}
{a}
{b}
9 (O-B-ii, q ←a )
{∗p ←[q ←a];
∗r ←[p ←[q ←a]] }
{−∗!t ←b;
!t ←[p ←[q ←a]],s;
!t ←[q ←a],u,d }
{}
{a}
{b}
We again obtain soundness and completeness results generalising the results for
graph-based dispute derivations (for credulous reasoning) from [10]:
Theorem 3. DF + {TA,TC,TS} GrFlexDDs are sound for the admissible, complete,
and stable semantics respectively.
Corollary 3. {DAB,DABF,DC,DS}+{TA,TC,TS} GrFlexDDs are sound for the
admissible, complete, and stable semantics respectively.
Theorem 4. If L is ﬁnite DAB + TA GrFlexDDs are complete for credulous accep-
tance w.r.t. the admissible semantics. Moreover, DC+TC GrFlexDDs are complete for
the complete semantics and DS+TS GrFlexDDs are complete for the stable semantics.
Finally, {DC,DS,DF}+TA GrFlexDDs are complete for the admissible semantics.
Corollary 4. If L is ﬁnite, {DABF,DC,DS,DF} + TA GrFlexDDs are complete for
credulous acceptance w.r.t. the admissible semantics. Also, DF + TC GrFlexDDs are
complete for the complete semantics and DF + TS GrFlexDDs are complete for the
stable semantics.
3.3
Flexible Dispute Derivations
In the previous section we presented deﬁnitions of argument-based ﬂexible variants
of structured and graph-based dispute derivations. The objective was, ﬁrst of all, to
give a general deﬁnition showing the common aspects between the, at the ﬁrst sight,

Flexible Dispute Derivations for ABA
159
different looking forms of dispute derivations while also incorporating ﬂexibility in the
order and types of moves allowed. At the same time, our deﬁnition allows to make
clear the differences between structured and graph-based dispute derivations (and their
ﬂexible variants) in terms of how much of the arguments put forward during a dispute
is stored and made use of in later steps of the dispute. We have seen that in this regard
GrFlexDDs, while improving on StFlexDDs, still have some redundancy in that, ﬁrstly,
the opponent does not make use of the proponents arguments when putting forward its
own arguments. Also, there is redundancy in the moves of the opponent w.r.t. previous
moves of itself (see in particular Example 4). These issues become especially pressing
in the context of dispute derivations with forward moves as forward reasoning, more
than backward reasoning, relies on previous moves.
We now propose FlexDDs to remedy the above mentioned issues. Again, we only
need to change the deﬁnition of expansions of the opponents and proponents arguments
in dispute advancements. Once more, we ﬁrst need a deﬁnition:
Deﬁnition 7. Let A ⊆Args, a ∈Args. Then A ▷◁{a} is the closure of A ∪{a} under
sub-arguments and argument expansions.
Thus A ▷◁{a} is a more relaxed version of A⋊{a} used in the deﬁnition of GrFlexDDs
for the proponents dispute advancements.
In FlexDDs a proponent dispute state advancement from a dispute state (B,P) is
a dispute state (B′,P′) with P′ = P ⋊{a} ̸= P, B′ = B ▷◁{a}, X1 ⊆A , X2 ⊆A
with P-B-⟨A ! ∪X1⟩and P-F–⟨(A ! ∩A ) ∪X2⟩moves deﬁned as before. An opponent
dispute state advancement from a dispute state (B,P) is a dispute state (B′,P) with
B′ = B ▷◁{a} ̸= B, Y1 ⊆A , Y2 ⊆A with O-B-⟨D ∪Y1⟩and O-F-⟨(D ∩A ) ∪Y2⟩
moves deﬁned as previously. So, main changes w.r.t. GrFlexDDs are that the proponents
moves also have an effect on the opponents arguments. Also, B′ = B ▷◁{a} rather
than B′ = B : {a} is used for updating the opponents arguments. We thus, ﬁrst of all,
follow [10] in restricting the set of arguments of the proponent to be rule minimal. This
has been argued for convincingly in [10] for both conceptual reasons (why have more
than one justiﬁcation line for a claim?) as well as computational reasons (guarantees
completeness of disputes when L is ﬁnite even if R contains cycles).
In [10] then the authors have also argued for the opponents arguments to be rule
minimal partly again for conceptual reasons but even more so for computational rea-
sons. Regarding the conceptual arguments of the authors, we note that, in any case, all
possible rule minimal arguments attacking the defenses of the proponent need to be
considered in dispute derivations. Thus the opponents arguments are not globally rule
minimal (as the proponents are). Regarding the computational reasons, while it is true
that restricting attention to the arguments of the opponent that are rule minimal guar-
antees completeness also if R contains cycles (assuming L is ﬁnite), we will show
that this is not necessary. In fact, treatment of the proponents and opponents expan-
sions in an (almost) symmetric way leads to a deﬁnition of dispute derivations which
avoids some of the remaining redundancy in moves of GrFlexDDs while staying com-
plete when L is ﬁnite and R contains cycles. Moreover, as we will show in Sect. 4,
our deﬁnition of FlexDDs leads naturally to an implementation where all arguments in
dispute derivations are represented as a graph rather than only the proponents as in the
implementation of [10].

160
M. Diller et al.
Table 8. A DAB+TA FlexDD for Example 5 (ABA framework from Example 4). Here $ labels
arguments which are held by the proponent as well as the opponent. Only complete and maximal
arguments for goals and contraries of culprits as well as maximal arguments for contraries of
defenses are shown. The dispute derivation ends with the opponent not being able to advance
further in O-B-⟨D⟩+O-F-⟨D ∩A ⟩-ii manner.
Step and move type
B
γ ∪C \Conc(P∗)
D
C
0
{ #$p }
{p}
{}
{}
1 (P-B-i, p ←q)
{ #$p ←q }
{p}
{}
{}
2 (P-B-i, q ←a)
{ ∗$p ←[q ←a] }
{}
{a} {}
3 (O-B-ii, t ←b)
{ ∗$p ←[q ←a];
∗!t ←b }
{}
{a} {}
4 (P-B-ii, r ←p )
{ ∗$p ←[q ←a];
∗$r ←[p ←[q ←a]];
−∗!t ←b }
{}
{a} {b}
5 (O-B-ii, t ←p,s )
{ ∗$p ←[q ←a];
∗$r ←[p ←[q ←a]];
−∗!t ←b; !t ←[p ←[q ←a]],s }
{}
{a} {b}
6 (O-B-ii, t ←q,u,d ) { ∗$p ←[q ←a];
∗$r ←[p ←[q ←a]];
−∗!t ←b;
!t ←[p ←[q ←a]],s;
!t ←[q ←a],u,d }
{}
{a} {b}
Example 5. Consider again the ABA framework from Example 4. A DAB + TA
FlexDD following more or less the DAB + TA GrFlexDD from Table 7 is shown in
Table 8. Note that here the steps 5–7 from Table 7 are performed in one step: step 5.
Also, steps 8–9 from Table 7 are completed in step 6. A DC+TC (and DS+TS) FlexDD
for the same example is shown in Table 9.
For FlexDDs we have the following results:
Theorem 5. DF+{TA,TC,TS} FlexDDs are sound for the admissible, complete, and
stable semantics respectively.
Corollary 5. {DAB,DABF,DC,DS}+{TA,TC,TS} FlexDDs are sound for the admis-
sible, complete, and stable semantics respectively.
Lemma 1. If
L
is
ﬁnite,
the
number
of
possible
DF
and
hence also {DAB,DABF,DC,DS} moves of the proponent and opponent in FlexDDs
is also ﬁnite.
Proof. We give the proof for the opponent. For the proponent it is analogous. Note ﬁrst
that the opponents moves involve adding an assumption (O-F-⟨A ⟩-ii) or a rule to B (O-
B-⟨A ⟩-ii), or expanding arguments backwards or forwards (O-B-⟨A ⟩-i or O-F-⟨A ⟩-i)
w.r.t. some rule. Now, once an assumption is put in B it cannot be added again by the
requirement B′ = B ▷◁{a} ̸= B. Also, if some rule r is used in one step (either by
adding it to B or expanding some argument w.r.t. it, which means by closure under
sub-arguments that then also r is in B′), then r cannot be used in any other step. For O-
B-⟨A ⟩-ii this is clear by the requirement B′ = B ▷◁{a} ̸= B. For O-B-⟨A ⟩-i note that
if a′ ∈B and h ←B ∈B then a′ ⋖h ←B is also already in B because B is required
to be closed by argument expansions. Analogously for O-F-⟨A ⟩-i moves.

Flexible Dispute Derivations for ABA
161
Table 9. A DC+TC (and DS+TS) FlexDD for Example 5 (ABA framework from Example 4).
Only complete and maximal arguments for goals and contraries of culprits as well as maximal
arguments for contraries of defenses are shown. The dispute derivation ends with the opponent
not being able to advance further in O-F-⟨A ⟩manner.
Step and move type
B
γ ∪C \Conc(P∗) D
C
I \D
0
{ #$p }
{p}
{}
{}
{a,b,c,d}
1 (P-B-i, p ←q)
{ #$p ←q }
{p}
{}
{}
{a,b,c,d}
2 (P-B-i, q ←a)
{ ∗$p ←[q ←a] }
{}
{a}
{}
{b,c,d}
3 (O-B-ii, t ←b)
{ ∗$p ←[q ←a];
∗!t ←b }
{}
{a}
{}
{b,d}
4 (P-B-ii \ P-F-i, r ←p ) {∗$p ←[q ←a];
∗$r ←[p ←[q ←a]];
−∗!t ←b}
{}
{a}
{b}
{c,d}
5 (P-F-ii, c )
{∗$p ←[q ←a];
∗$r ←[p ←[q ←a]];
−∗!t ←b;
∗$c}
{}
{a,c} {b,d} {}
Theorem 6. If L is ﬁnite DAB + TA FlexDDs are complete for credulous acceptance
w.r.t. the admissible semantics. Moreover, DC+TC FlexDDs are complete for the com-
plete semantics and DS + TS FlexDDs are complete for the stable semantics. Finally,
{DC,DS,DF}+TA FlexDDs are complete for the admissible semantics.
Corollary 6. If L is ﬁnite, {DABF,DC,DS,DF}+TA FlexDDs are complete for cred-
ulous acceptance w.r.t. the admissible semantics. Also, DF+TC FlexDDs are complete
for the complete semantics and DF+TS FlexDDs are complete for the stable semantics.
4
Rule-Based Flexible Dispute Derivations
Rule-based ﬂexible dispute derivations, or RlFlexDDs for short, provide an alternative
representation and implementation of FlexDDs. Relying on the observation contained
in the proof of Lemma 1 (on which Theorem 6 depends), in RlFlexDDs the proponent
and opponent put forward claims and rules rather than arguments. Moreover, they make
use of the underlying (labelled) graph of the dependencies between statements and rules
put forward by the proponent and opponent during a dispute. RlFlexDDs thus generalise
the work of [10] which implements DAB+TA GrFlexDD disputes. As we have already
indicated, in the dispute derivations of [10] the proponents arguments are represented
as graph, while the opponents are not. Also, the opponent does not make use of the
proponents arguments.
So, in RlFlexDDs a dispute state for a set of goals γ ⊆L (s.t. γ ∩γ = /0) is a tuple
(B,P) where B ⊆(L ∪R), and P ⊆B. To deﬁne rule-based dispute advancements we
deﬁne the auxiliary notation in Table 10; in large part encoding the analogous notions
from Sect. 3.3 in the rule setting. Concretely, we have that e.g. s ∈P∗∩L iff there is
a complete argument for s using rules in P. Also, s ∈B∗/−∩L iff there is a complete
argument for s using rules in B that does not use any culprit. On the other hand, s ∈B−∩
L implies ﬁrst of all that all arguments for s using non-blocked (i.e. without culprits in

162
M. Diller et al.
bodies) rules use rules only in B. Also, that all such arguments (using rules only in B)
which are complete are blocked (i.e. make use of some culprit). As a consequence then,
s ∈B!/−
S
∩L if s is used in an argument for some s′ ∈S (with S ⊆L ) and the latter
two conditions (for s ∈B−) do not hold.
Table 10. Auxiliary notation for rule-based ﬂexible dispute derivations. All notions w.r.t. a dispute
state (B,P).
Notation
Description
D = P∩A
Defenses
C = {u ∈A | u ∈P}
Culprits
JB = R \B
Remaining rules for the opponent
JP = R \P
Remaining rules for the proponent
J −
B = {h ←B ∈JB | B∩C ̸= /0}
Blocked remaining rules
J ∼
P = {h ←B ∈JP |
({h}∪B)∩(B∪C ∪D) ̸= /0}
Remaining rules blocked for the
proponent
(P∩L )↓= {s ∈P∩L | ¬∃h ←B ∈P with h = s} Played unexpanded statements of the
proponent
(B∩L )↑↑= {s ∈(B∩L ) | ¬∃h ←B ∈
(JB \J −
B ) with h = s}
Played fully expanded statements
B−= (B∩C )∪{s ∈(B∩L )↑↑\A | ¬∃h ←
B ∈(B∩R)\B−with h = s}∪{h ←B ∈B∩R |
B∩B−̸= /0}
Played blocked pieces
P∗= (P∩A )∪{h ←B ∈(P∩R) | B ⊆P∗}∪{s ∈
(P∩(L \A )) | ∃h ←B ∈P∗with h = s}
Complete played pieces of the
proponent
B∗/−= (B∩(A \C ))∪{h ←B ∈(B\B−)∩R |
B ⊆B∗/−}∪{s ∈(B\B−)∩(L \A ) | ∃h ←
B ∈B∗/−with h = s}
Unblocked complete played pieces of
the opponent
B!/−
S
= ((B\B−)∩S)∪{s ∈(B\B−)∩L |
∃h ←B ∈B!/−
S
∩R with s ∈B}∪{h ←B ∈
(B\B−)∩R | h ∈B!/−
S
}
Unblocked pieces supporting
statements in S ⊆L
A ! = A ∩B!/−
D
Candidates for culprits
I = {u ∈A \C | u ̸∈B∗/−}
Currently defended assumptions
Note that B−and P∗are monotonic; i.e. once some element is in the set they remain
in the set. This means these sets can be computed incrementally as the dispute evolves.
On the other hand, B∗/−, and B!/−
S
are not monotonic; but once some element becomes
blocked (is in B−) it cannot be in either B∗/−or B!/−
S
anymore. This means as elements
become blocked, they do not need to be considered for computation of B∗/−and B!/−
S
.

Flexible Dispute Derivations for ABA
163
Now to the deﬁnition of dispute advancements for RlFlexDDs. First of all, a pro-
ponent dispute state advancement from a dispute state (B,P) is a dispute state (B′,P′)
with P′ = P∪T, B′ = B∪T, X1 ⊆A , and X2 ⊆A where either
P-B-⟨A ! ∪X1⟩:
i) T = {h ←B}∪B for h ←B ∈JP \J ∼
P with h ∈(P∩L )↓;
or
ii) T = {h}∪{h ←B}∪B for h ←B ∈JP \J ∼
P with h ∈
(A ! ∪X1)\(P∪D);
P-F–⟨(A ! ∩A )∪X2⟩: i) T = {h}∪{h ←B} with h ←B ∈JP \J ∼
P with h ̸∈P or
h ∈(P∩L )↓, b ∈P∗for each b ∈B; or
ii) T = {u} for u ∈((A ! ∩A )∪X2)\(P∪{u}∪C ∪D}).
An opponent dispute state advancement from a dispute state (B,P) is a dispute state
(B′,P) with B′ = B∪T, Y1 ⊆A , and Y2 ⊆A where either
O-B-⟨D ∪Y1⟩:
i) T = {h ←B}∪B for h ←B ∈JB \J −
B with h ∈B!/−
D ∪Y1 ∩L ;
or
ii) T = ({h}∪{h ←B}∪B) for a h ←B ∈JB \J −
B with h ∈
D ∪Y1;
O-F-⟨(D ∩A )∪Y2⟩: i) T = {h}∪{h ←B} for h ←B ∈JB \J −
B with b ∈B∗/−for
each b ∈B; or
ii) T = {u} for u ∈((D ∩A )∪Y2)\(A ∩B).
Different types of dispute advancements for RlFlexDDs are deﬁned as for
StFlexDDs, GrFlexDDs, and FlexDDs (i.e., with some abuse of notation, as in Table 2).
Only for the termination conditions the deﬁnition needs to change slightly (concretely,
the notion of “proponent winning”) to reﬂect the change in notation. See Table 11.
Table 11. Termination conditions for RlFlexDDs. TA for admissible, TC for complete, and TS
for stable.
Cond. Proponent winning
Opponent cannot move
Proponent cannot move
TA
γ ∪C ⊆P∗,
(D ∩B∗/−) = /0
O-B-⟨D⟩+
O-F-⟨D ∩A ⟩-ii or
O-F-⟨A ⟩
P-B-⟨A !⟩+
P-F-⟨A ! ∩A ⟩-ii or
P-F-⟨A ⟩
TC
γ ∪C ⊆P∗,
(D ∩B∗/−) = /0, I \D = /0
O-B-⟨D⟩+
O-F-⟨D ∩A ⟩-ii or
O-F-⟨A ⟩
P-B-⟨A !⟩+
P-F-⟨(A ! ∩A )∪I ⟩or
P-F-⟨A ⟩
TS
γ ∪C ⊆P∗,
(D ∩B∗/−) = /0,
D ∪C = A
O-B-⟨D⟩+
O-F-⟨D ∩A ⟩-ii or
O-F-⟨A ⟩
P-B-⟨A !⟩+ P-F-⟨A ⟩

164
M. Diller et al.
Table 12. A DC + TC (and DS + TS) RlFlexDD for Example 6 (ABA framework from Exam-
ple 4). Label −represents played blocked pieces, label ∗complete played pieces, label “ unex-
panded statements of the proponent, label ∧fully expanded statements (non assumptions), and
label ! represents opposing pieces. The dispute derivation ends with the opponent not being able
to advance further in O-F-⟨A ⟩manner.
Step and move type
B
γ ∪C \P∗
D
C
I \D
0
{ “$p }
{p}
{}
{}
{a,b,c,d}
1 (P-B-i, p ←q)
{ ∧$p;
“$q;
$p ←q }
{p}
{}
{}
{a,b,c,d}
2 (P-B-i, q ←a)
{ ∗∗$a; ∗∗∧$p;
∗∗∧$q;
∗∗$p ←q;
∗∗$q ←a }
{}
{a}
{}
{b,c,d}
3 (O-B-ii, t ←b)
{ ∗∗$a; ∗!b;
∗∗∧$p;
∗∗∧$q;
∗!t;
∗∗$p ←q;
∗∗$q ←a;
∗t ←b }
{}
{a}
{}
{b,d}
4 (P-B-ii \ P-F-i, r ←p )
{ ∗∗$a; −∗!b; ∗∗∧$p;
∗∗∧$q;
∗∗∧$r;
∗!t;
∗∗$p ←q;
∗∗$q ←a;
−∗t ←b;
∗∗$r ←p }
{}
{a}
{b}
{c,d}
5 (P-F-ii, c )
{ ∗∗$a; −∗!b;
∗∗$c;
∗∗∧$p;
∗∗∧$q;
∗∗∧$r;
∗!t;
∗∗$p ←q;
∗∗$q ←a;
−∗t ←b;
∗∗$r ←p }
{}
{a,c}
{b,d}
{}
Example 6. Consider again the ABA framework from Examples 4 and 5. A DC + TC
(and DS+TS) RlFlexDD following the DC+TC FlexDD from Table 9 is in Table 12.
Based on the results for FlexDDs from Sect. 3.3 and the fact that RlFlexDDs essen-
tially implement FlexDDs we obtain the following results for RlFlexDDs:
Corollary 7. {DAB,DABF,DC,DS,DF}+{TA,TC,TS} RlFlexDDs are sound for the
admissible, complete, and stable semantics respectively.
Corollary 8. If L is ﬁnite {DAB,DABF,DC,DS,DF} + TA RlFlexDDs are complete
for credulous acceptance w.r.t. the admissible semantics. Moreover, {DC,DF} + TC
RlFlexDDs are complete for the complete semantics and {DS,DF}+TS RlFlexDDs are
complete for the stable semantics. Finally, {DC,DS,DF}+TA RlFlexDDs are complete
for the admissible semantics.
5
Implementation
We have implemented an interactive reasoner, aba-dd-rule-based, for all variants
of RlFlexDDs considered in this work. At the moment the system is conceived mainly
for didactic and research purposes. The code is freely available2. The system allows for
choosing a combination of dispute advancement type and termination criteria and then
guiding the user through an RlFlexDD of that nature (advancement types and termina-
tion criteria can also be changed on the ﬂy). At each step the user can choose which
move to make from the list of allowed moves provided by the system. See Fig. 1 for a
screenshot of the interface for step 4 of the RlFlexDD from Table 12. Limited automa-
tisation is also possible in that the user can choose that the system move forward a
2 https://github.com/gorczyca/aba-dd-rule-based.

Flexible Dispute Derivations for ABA
165
Fig. 1. Interface of aba-dd-rule-based at step 4 of the RlFlexDD from Table 12
Fig. 2. Graphical output of aba-dd-rule-based at step 5 (end state) of the RlFlexDD from
Table 12. Here green nodes represents the proponents pieces. The goal is in blue. Yellow is for
the opponents pieces, while those in orange are blocked. Red is for culprits. Grey nodes represent
remaining rules which are blocked but whose heads have been made use of in the dispute. Black
arrows represent support, while red ones denote attacks. (Color ﬁgure online)
random number of steps (of some type) and the system can also backtrack a number
of steps. The system can also produce a graphical representation of the statements and
rules put forward during the dispute until that point. See Fig. 2 for the graphical output
of aba-dd-rule-based at step 5 (end state) of the RlFlexDD from Table 12. We refer
to the webpage for many other features of aba-dd-rule-based as well as larger and
more realistic examples on which to experiment with RlFlexDDs.
6
Conclusions and Future Work
We have deﬁned a variant of dispute derivations which allows for forward in addition to
backward reasoning and thus for computing admissible, complete, and stable assump-
tion sets in addition to reasoning about credulous acceptance of statements. We have
given an abstract argument-based deﬁnition of such dispute derivations which we have
derived from similarly abstract representations of ﬂexible variants of dispute deriva-
tions from [10,33]. We have then provided a more implementation focused rule-based
deﬁnition. For this version we also implemented an interactive system. Ultimately, we
have generalised graph-based dispute derivations from [10] on two fronts: incorporat-
ing forward reasoning, as well as in that both the proponents and opponents arguments

166
M. Diller et al.
are represented in a shared graph rather than only the proponents arguments being rep-
resented in a graph.
While the most immediate beneﬁts of dispute derivations lie in the domain of inter-
active reasoning, investigating to what extent some of the variants of dispute derivations
we have deﬁned in this work can be turned into fully automated reasoning procedures
(even if only to support interactive reasoning) is of interest. In particular, DABF+TA is
an obvious candidate for obtaining more efﬁcient procedures for credulous reasoning.
Also, with forward reasoning giving at least argument-based ﬂexible dispute deriva-
tions for non-ﬂat ABA as well as for sceptical acceptance of statements should be in
reach. We also would like to improve our interactive system, in particular for making
the whole interface graphical and also for allowing switching between argument-based
and rule-based views.
References
1. Amgoud, L., Besnard, P., Vesic, S.: Equivalence in logic-based argumentation. J. Appl. Non
Class. Logics 24(3), 181–208 (2014)
2. Besnard, P., et al.: Introduction to structured argumentation. Argum. Comput. 5(1), 1–4
(2014)
3. Bondarenko, A., Dung, P.M., Kowalski, R.A., Toni, F.: An abstract, argumentation-theoretic
approach to default reasoning. Artif. Intell. 93, 63–101 (1997)
4. Bondarenko, A., Toni, F., Kowalski, R.A.: An assumption-based framework for non-
monotonic reasoning. In: LPNMR, pp. 171–189. MIT Press (1993)
5. Booth, R., Caminada, M., Marshall, B.: DISCO: a web-based implementation of discussion
games for grounded and preferred semantics. In: COMMA. Frontiers in Artiﬁcial Intelli-
gence and Applications, vol. 305, pp. 453–454. IOS Press (2018)
6. Borg, A., Straßer, C.: Relevance in structured argumentation. In: IJCAI, pp. 1753–1759.
ijcai.org (2018)
7. Caminada, M.: A discussion game for grounded semantics. In: Black, E., Modgil, S., Oren,
N. (eds.) TAFA 2015. LNCS (LNAI), vol. 9524, pp. 59–73. Springer, Cham (2015). https://
doi.org/10.1007/978-3-319-28460-6 4
8. Caminada, M.: Argumentation semantics as formal discussion. In: Baroni, P., Gabbay, D.,
Giacomin, M. (eds.) Handbook of Formal Argumentation, pp. 487–518. College Publications
(2018)
9. Cerutti, F., Gaggl, S.A., Thimm, M., Wallner, J.P.: Foundations of implementations for for-
mal argumentation. In: Baroni, P., Gabbay, D., Giacomin, M. (eds.) Handbook of Formal
Argumentation, pp. 689–768. College Publications (2018)
10. Craven, R., Toni, F.: Argument graphs and assumption-based argumentation. Artif. Intell.
233, 1–59 (2016)
11. Craven, R., Toni, F., Williams, M.: Graph-based dispute derivations in assumption-based
argumentation. In: Black, E., Modgil, S., Oren, N. (eds.) TAFA 2013. LNCS (LNAI), vol.
8306, pp. 46–62. Springer, Heidelberg (2014). https://doi.org/10.1007/978-3-642-54373-9 4
12. Cyras, K., Fan, X., Schulz, C., Toni, F.: Assumption-based argumentation: disputes, expla-
nations, preferences. In: Baroni, P., Gabbay, D., Giacomin, M. (eds.) Handbook of Formal
Argumentation, pp. 365–408. College Publications (2018)
13. Doutre, S., Mengin, J.: On sceptical versus credulous acceptance for abstract argument sys-
tems. In: Alferes, J.J., Leite, J. (eds.) JELIA 2004. LNCS (LNAI), vol. 3229, pp. 462–473.
Springer, Heidelberg (2004). https://doi.org/10.1007/978-3-540-30227-8 39

Flexible Dispute Derivations for ABA
167
14. Dung, P.M.: On the acceptability of arguments and its fundamental role in nonmonotonic
reasoning, logic programming and n-person games. Artif. Intell. 77(2), 321–358 (1995)
15. Dung, P.M., Kowalski, R.A., Toni, F.: Dialectic proof procedures for assumption-based,
admissible argumentation. Artif. Intell. 170(2), 114–159 (2006)
16. Dung, P.M., Kowalski, R.A., Toni, F.: Assumption-based argumentation. In: Simari, G.R.,
Rahwan, I. (eds.) Argumentation in Artiﬁcial Intelligence, pp. 199–218. Springer, Heidelberg
(2009). https://doi.org/10.1007/978-0-387-98197-0 10
17. Dung, P.M., Mancarella, P., Toni, F.: Computing ideal sceptical argumentation. Artif. Intell.
171(10–15), 642–674 (2007)
18. Dung, P.M., Thang, P.M.: Closure and consistency in logic-associated argumentation. J.
Artif. Intell. Res. 49, 79–109 (2014)
19. Efstathiou, V., Hunter, A.: Algorithms for generating arguments and counterarguments in
propositional logic. Int. J. Approx. Reason. 52(6), 672–704 (2011)
20. Gaertner, D., Toni, F.: Hybrid argumentation and its properties. In: COMMA. Frontiers in
Artiﬁcial Intelligence and Applications, vol. 172, pp. 183–195. IOS Press (2008)
21. Jakobovits, H., Vermeir, D.: Dialectic semantics for argumentation frameworks. In: ICAIL,
pp. 53–62. ACM (1999)
22. Keshavarzi Zafarghandi, A., Verbrugge, R., Verheij, B.: Discussion games for preferred
semantics of abstract dialectical frameworks. In: Kern-Isberner, G., Ognjanovi´c, Z. (eds.)
ECSQARU 2019. LNCS (LNAI), vol. 11726, pp. 62–73. Springer, Cham (2019). https://doi.
org/10.1007/978-3-030-29765-7 6
23. Keshavarzi Zafarghandi, A., Verbrugge, R., Verheij, B.: A discussion game for the grounded
semantics of abstract dialectical frameworks. In: COMMA. Frontiers in Artiﬁcial Intelli-
gence and Applications, vol. 326, pp. 431–442. IOS Press (2020)
24. Lehtonen, T., Wallner, J.P., J¨arvisalo, M.: From structured to abstract argumentation:
assumption-based acceptance via AF reasoning. In: Antonucci, A., Cholvy, L., Papini, O.
(eds.) ECSQARU 2017. LNCS (LNAI), vol. 10369, pp. 57–68. Springer, Cham (2017).
https://doi.org/10.1007/978-3-319-61581-3 6
25. Lehtonen, T., Wallner, J.P., J¨arvisalo, M.: Reasoning over assumption-based argumentation
frameworks via direct answer set programming encodings. In: AAAI, pp. 2938–2945. AAAI
Press (2019)
26. Modgil, S., Caminada, M.: Proof theories and algorithms for abstract argumentation frame-
works. In: Simari, G.R., Rahwan, I. (eds.) Argumentation in Artiﬁcial Intelligence, pp. 105–
129. Springer, Boston (2009). https://doi.org/10.1007/978-0-387-98197-0 6
27. Modgil, S., Prakken, H.: Abstract rule-based argumentation. In: Baroni, P., Gabbay, D., Gia-
comin, M. (eds.) Handbook of Formal Argumentation, pp. 287–364. College Publications
(2018)
28. Prakken, H.: An abstract framework for argumentation with structured arguments. Argum.
Comput. 1(2), 93–124 (2010)
29. Prakken, H., Sartor, G.: Argument-based extended logic programming with defeasible prior-
ities. J. Appl. Non Class. Logics 7(1), 25–75 (1997)
30. Strass, H., Wyner, A., Diller, M.: EMIL: extracting meaning from inconsistent language:
towards argumentation using a controlled natural language interface. Int. J. Approx. Reason.
112, 55–84 (2019)
31. Thang, P.M., Dung, P.M., Hung, N.D.: Towards a common framework for dialectical proof
procedures in abstract argumentation. J. Log. Comput. 19(6), 1071–1109 (2009)
32. Thimm, M., Rienstra, T.: Approximate reasoning with ASPIC+ by argument sampling. In:
SAFA@COMMA. CEUR Workshop Proceedings, vol. 2672, pp. 22–33. CEUR-WS.org
(2020)
33. Toni, F.: A generalised framework for dispute derivations in assumption-based argumenta-
tion. Artif. Intell. 195, 1–43 (2013)

168
M. Diller et al.
34. Toni, F.: A tutorial on assumption-based argumentation. Argum. Comput. 5(1), 89–117
(2014)
35. Vreeswik, G.A.W., Prakken, H.: Credulous and sceptical argument games for preferred
semantics. In: Ojeda-Aciego, M., de Guzm´an, I.P., Brewka, G., Moniz Pereira, L. (eds.)
JELIA 2000. LNCS (LNAI), vol. 1919, pp. 239–253. Springer, Heidelberg (2000). https://
doi.org/10.1007/3-540-40006-0 17
36. Yun, B., Oren, N., Croitoru, M.: Efﬁcient construction of structured argumentation systems.
In: COMMA. Frontiers in Artiﬁcial Intelligence and Applications, vol. 326, pp. 411–418.
IOS Press (2020)

Towards a General Theory
of Decomposability in Abstract
Argumentation
Massimiliano Giacomin1(B)
, Pietro Baroni1(B)
, and Federico Cerutti1,2
1 University of Brescia, Brescia, Italy
{massimiliano.giacomin,pietro.baroni,federico.cerutti}@unibs.it
2 CardiﬀUniversity, Cardiﬀ, UK
Abstract. The paper introduces a general model for the study of decom-
posability in abstract argumentation, i.e. the possibility of determining
the semantics outcome based on local evaluations in subframeworks. As
such, the paper extends a previous work by generalizing over the kind of
information locally exploited. While not concerned with speciﬁc seman-
tics, the paper shows the range of decomposable semantics with varying
degrees of local information. It also introduces the notion of a canoni-
cal local function, which can enforce decomposability whenever this is
possible.
Keywords: Abstract argumentation · Argumentation semantics ·
Decomposability.
1
Introduction
Dung’s model provides an abstract account of argumentation where arguments
are simply represented as nodes of a directed graph, called argumentation frame-
work, and binary attacks between them correspond to the graph’s edges [13]. This
formalism turns out to capture several approaches in nonmonotonic reasoning
and structured argumentation. Its importance lies in the formal methods, called
argumentation semantics, to assess a set of arguments in order to determine their
justiﬁcation status, and thus the status of the relevant conclusions in structured
instances of the abstract model. This is necessary since conﬂicts between argu-
ments prevent them from being accepted altogether, and a formal method is
needed to solve the conﬂict [1].
While in the original deﬁnitions of argumentation semantics an argumenta-
tion framework is considered as a monolithic structure and arguments are eval-
uated at a global level, in recent years attention has been devoted to deﬁning
semantics in a modular fashion, i.e. determining the semantics outcome based
on local evaluations in subframeworks [3,8,16]. Several motivations underlie this
research interest. First, a local approach can save computation time [7,11] pos-
sibly applying parallel computation techniques [12] or exploiting incremental
c
⃝Springer Nature Switzerland AG 2021
P. Baroni et al. (Eds.): CLAR 2021, LNAI 13040, pp. 169–189, 2021.
https://doi.org/10.1007/978-3-030-89391-0_10

170
M. Giacomin et al.
computation in a dynamic context [17]. Second,various equivalence relations
[6,14,19] heavily rely on modules and can also help summarizing (possibly com-
plex) argumentation frameworks [4]. Furthermore, this research issue is a starting
point to tackle the problem of combining diﬀerent argumentation semantics, i.e.
regarding a global argumentation framework as composed of a set of interacting
parts each associated with a (possibly) diﬀerent semantics [15,18], e.g. to model
a multi-agent context or to integrate diﬀerent kinds of reasoning [5].
In a previous paper [4], the modular deﬁnition of argumentation semantics
has been investigated without any restriction on how an argumentation frame-
work is partitioned into subframeworks. In particular, the property of decom-
posability of argumentation semantics has been introduced concerning the corre-
spondences between semantics outcome at global and local level. A semantics S
is decomposable if, given a partition of an argumentation framework into a set of
sub-frameworks, the outcomes produced by S can be obtained as a combination
of the outcomes produced by a local counterpart of S applied separately on each
sub-framework, and vice versa.
While we are not aware of other investigations at this level of generality, the
framework proposed in [4] assumes that the local computation in each subframe-
work can have access only to a speciﬁc kind of information about the outcome of
the computations in the outside components. In particular, the available infor-
mation is relatively limited, including the set of outside attackers, the labels
assigned to them by the computations in other subframeworks and the attacks
directed from such arguments to inner arguments. It turns out that, among the
most common semantics proposed in the literature, full decomposability with
respect to every arbitrary partition is satisﬁed by some semantics. In contrast,
others require the partition to be based on the strongly connected components
of the argumentation framework. A few semantics then lack the decomposability
property.
An interesting issue is whether exploiting further information would be useful
and lead more semantics to be decomposable. For instance, we may consider
attacks from inner arguments to outside arguments, or we may consider a larger
set of outside arguments, such as the attackers of attackers, and so on.
This paper aims at providing a model for the investigation of the above
issue at a general level, without relying on the speciﬁc argumentation semantics
deﬁnitions (which is left for future work). More speciﬁcally, this paper aims at
providing some answers to the following research issues:
1. How to model in general the diverse kinds of information that can be exploited
in local computations, and the relevant functions representing the local coun-
terparts of argumentation semantics;
2. Determining the range of semantics that are decomposable under diﬀerent
degrees of local information exploited, investigating in particular the extreme
cases of null and complete information, respectively;
3. How to determine, in general, the local counterpart of an argumentation
semantics to guarantee decomposability.

Towards a General Theory of Decomposability in Abstract Argumentation
171
After some background provided in Sect. 2, the ﬁrst question is dealt with in
Sect. 3, by introducing the notions of local information function and local func-
tion. On this basis, a generalized notion of decomposability w.r.t. [4] is provided.
Sections 4 and 5 are devoted to the second and third questions, respectively, while
Sect. 6 discusses and concludes the paper.
2
Background
We follow the traditional deﬁnition of argumentation framework introduced by
Dung [13] and deﬁne its restriction to a subset of arguments.
Deﬁnition 1. An argumentation framework is a pair AF = (A, att) in which A
is a ﬁnite1 set of arguments and att ⊆A×A. An argument α such that (α, α) ∈
att is called self-attacking. Given a set Args ⊆A, the restriction of AF to Args,
denoted as AF↓Args, is the argumentation framework (Args, att ∩(Args ×Args)).
The (inﬁnite) set of all possible argumentation frameworks is denoted as SAF.
We will also need two relations and two operators between argumentation
frameworks.
Deﬁnition 2. Given two argumentation frameworks AF 1 = (A1, att1) and
AF 2 = (A2, att2):
– AF 1 ⊆AF 2 iﬀA1 ⊆A2 and att1 ⊆att2
– AF 1 ⊑AF 2 iﬀA1 ⊆A2 and AF 2↓A1 = AF 1
– AF 1 ⊖AF 2 ≜A1\A2
– AF 1\AF 2 ≜AF 1↓AF 1⊖AF 2
The relation ⊆extends set inclusion to argumentation frameworks, while
AF 1 ⊑AF 2 holds if AF 1 is a subframework2 of AF 2. In this case, AF 2 ⊖AF 1
returns the set of arguments of AF 2 outside AF 1, while AF 2\AF 1 returns the
corresponding argumentation framework.
Proposition 1 shows that ⊆and ⊑are partial orders.
Proposition 1. The relations ⊆and ⊑between argumentation frameworks are
reﬂexive, antisymmetric and transitive.
Proof. The proof that ⊆and ⊑are reﬂexive is immediate from the relevant
deﬁnitions. The fact that ⊆is antisymmetric directly follows from the fact that
the set-inclusion relation ⊆is antisymmetric, and since ⊑is stricter than ⊆it is
antisymmetric in turn. As to transitivity, the proof for ⊆is immediate taking into
account that the set-inclusion relation ⊆is transitive. As to ⊑, if AF 1 ⊑AF 2
and AF 2 ⊑AF 3 then by transitivity of ⊆and the fact that ⊑is stricter than
⊆it holds that AF 1 ⊆AF 3, and in particular A1 ⊆A3. Since AF 3↓A2 = AF 2
and AF 2↓A1 = AF 1, we have that AF 3↓A1 = AF 1, thus AF 1 ⊑AF 3.
⊓⊔
1 In the general deﬁnition, the set of arguments may be inﬁnite.
2 It is immediate to see that ⊑is stricter than ⊆, i.e. AF 1 ⊑AF 2 entails AF 1 ⊆AF 2.

172
M. Giacomin et al.
In this paper we adopt the labelling-based approach to the deﬁnition of argu-
mentation semantics. As shown in [2,9], for the semantics considered in this
paper there is a direct correspondence with the “traditional” extension-based
approach.
A labelling assigns to each argument of an argumentation framework a label
taken from a predeﬁned set Λ. We adopt the most common choice for Λ, i.e.
{in, out, undec}, where the label in means that the argument is accepted, the
label out means that the argument is rejected, and the label undec means
that the status of the argument is undecided. For technical reasons, we deﬁne
labellings both for argumentation frameworks and for arbitrary sets of argu-
ments.
Deﬁnition 3. Given a set of arguments Args, a labelling of Args is a total
function Lab : Args →{in, out, undec}. The set of all labellings of Args is
denoted as LArgs. Given an argumentation framework AF = (A, att), a labelling
of AF is a labelling of A. The set of all labellings of AF is denoted as L(AF). For
a labelling Lab of Args, the restriction of Lab to a set of arguments Args′ ⊆Args,
denoted as Lab↓Args′, is deﬁned as Lab ∩(Args′ × {in, out, undec}). We extend
this notation to sets of labellings, i.e. given a set of a labellings L ⊆LArgs,
L↓Args′ ≜{Lab↓Args′ | Lab ∈L}. Moreover, if Lab ∈L(AF) and AF ′ ⊆AF,
where AF ′ = (A′, att′), Lab↓AF ′ will denote Lab↓A′.
A labelling-based semantics prescribes a set of labellings for each argumen-
tation framework.
Deﬁnition 4. Given an argumentation framework AF = (A, att), a labelling-
based semantics S associates with AF a subset of L(AF), denoted as LS(AF).
Various notions of justiﬁcation can be considered for arguments. The most
common one considers an argument skeptically justiﬁed in an argumentation
framework AF according to a semantics S if it is assigned the label in by all
labellings of LS(AF).
In general, a semantics encompasses a set of alternative labellings for a single
argumentation framework. If a semantics S is deﬁned in such a way that the set
of labellings is always non empty, i.e. ∀AF, LS(AF) ̸= ∅, then S is said to be uni-
versally deﬁned. Moreover, a semantics may be deﬁned so that a unique labelling
is always prescribed, i.e. for every argumentation framework AF, |LS(AF)| = 1.
In this case the semantics is said to be single-status, while in the general case it
is said to be multiple-status.
As an extreme case of semantics corresponding to the most skeptical one,
which has a theoretical, rather than practical, interest, we consider the semantics
UND, a single-status semantics which assigns to all arguments the label undec.
Deﬁnition 5. The semantics UND is such that ∀AF = (A, att) ∈SAF,
LUND(AF) = {Lab}, where ∀α ∈A, Lab(α) = undec.

Towards a General Theory of Decomposability in Abstract Argumentation
173
Many other semantics exist, corresponding to diﬀerent criteria to select
labellings. While in this paper we are not concerned with the relevant deﬁni-
tions, we consider as a basic requirement for a semantics S to satisfy conﬂict-
freeness, i.e. ∀AF ∈SAF and ∀Lab ∈LS(AF), Lab is conﬂict-free according to
the following deﬁnition, taken from [10].
Deﬁnition 6. Let Lab be a labelling of an argumentation framework AF =
(A, att). Lab is conﬂict-free if for each α ∈A it holds that
– if α is labelled in then it does not have an attacker that is labelled in
– if α is labelled out then it has at least an attacker that is labelled in.
3
A General Model for Decomposability
The proposed model for the analysis of decomposability of argumentation seman-
tics is articulated in two layers. The ﬁrst layer deals with the representation, in a
general way, of the information locally used for the computation of labellings in
subframeworks. The second layer focuses on the modelling of this computation
through the notion of the local function.
3.1
Modelling Local Information
Given a subframework of the global argumentation framework, the information
needed for the local computation of the labellings in this subframework should
include the topology of the subframework itself. Still, in general, it has also some
information from the outside. On the one hand, some knowledge of the topology
of the neighboring part of the graph is needed. On the other hand, the labelling
assigned to this part by the local computations on external subframeworks is
required in order to extend it with a local labelling of the subgraph.
The topological information speciﬁcally available depends on the kind of
information exploited for the local computation. For instance, one might decide
to consider external attackers with the unidirectional attacks from them, or one
might also take into account the external nodes attacked by the subframework,
or the attackers of the attackers might also be considered, and so on. To model all
these possibilities we introduce the notion of local information function, which
takes in input a “global” argumentation framework AF ∗and one of its sub-
frameworks AF, and returns as output the portion of AF ∗which can be taken
into account to compute the labellings of AF (note that this portion of course
must extend AF). Some constraints are also introduced concerning the role of
AF ∗(see the relevant explanation later).
Deﬁnition 7. A local information function is a function LI : {(AF ∗, AF) |
AF ∗, AF ∈SAF ∧AF ⊑AF ∗} →SAF such that ∀AF ∗, AF ∈SAF : AF ⊑
AF ∗
– AF ⊑LI(AF ∗, AF) and LI(AF ∗, AF) ⊆AF ∗

174
M. Giacomin et al.
– if AF ∗⊆AF ∗∗then either LI(AF ∗∗, AF) = LI(AF ∗, AF) or it is not the
case that LI(AF ∗∗, AF) ⊆AF ∗
For ease of notation, in the following LI(AF ∗, AF) will be denoted as
LIAF ∗(AF).
Some explanation on the constraints introduced in the above deﬁnition is in
order.
As to the ﬁrst item, AF ⊑LI(AF ∗, AF) means that the local subframework
must be known, and thus is part of the available information, to compute the
appropriate labellings. The other condition LI(AF ∗, AF) ⊆AF ∗expresses that
the neighboring part of AF returned by the function is taken from AF ∗. Here the
use of ⊆rather than ⊑gives more freedom in the choice of the local information,
since it makes it possible to neglect some attacks that otherwise should be taken
into account (e.g. one might consider external attackers with the relevant attacks
directed towards AF but neglect the attacks directed from AF to such attackers).
The second item concerns the role of AF ∗, which must be used only to identify
the neighboring part of the subframework available locally. However, in principle
there might be some further information hidden in the way the output of the
function, say AF ′, is selected depending on AF ∗, e.g. subtle dependencies could
be introduced where part of the external topology might be artiﬁcially excluded
to take into account the topology of AF ∗\AF ′. To avoid this possibility, the
constraint requires that if AF ∗is enlarged, then either AF ′ does not change, or
the additional elements of the enlarged global framework play an explicit role,
i.e. some appear in the novel output of the local information function.
Deﬁnition 7 encompasses various local information functions corresponding
to diﬀerent criteria to select the local information taken into account.
As two extreme cases, we introduce the local information functions mLI and
MLI. The ﬁrst function models the case where no external information is avail-
able, i.e. mLI returns as output just the subframework where local labellings
are computed. The second function models the case where all external topo-
logical information is available, i.e. MLI returns as output the whole global
argumentation framework.
Deﬁnition 8. mLI is the local information function such that ∀AF ∗, AF ∈
SAF : AF ⊑AF ∗, mLIAF ∗(AF) = AF. MLI is the local information function
such that ∀AF ∗, AF ∈SAF : AF ⊑AF ∗, MLIAF ∗(AF) = AF ∗.
There are plenty of other local information functions between the two extreme
cases described above, and in the following we introduce some of them just for the
sake of the example. In order to make their deﬁnitions easier, we ﬁrst introduce
some notations.
Deﬁnition 9. Given an argumentation framework AF = (A, att) and a set of
arguments Args ⊆A:
– Argsinp
AF = {α ∈A\Args | ∃β ∈Args, (α, β) ∈att}
– Argsatt−inp
AF
= att ∩(Argsinp
AF × Args)

Towards a General Theory of Decomposability in Abstract Argumentation
175
– ArgsBatt−inp
AF
= Argsatt−inp
AF
∪(att ∩(Args × Argsinp
AF ))
– Argsout
AF = {α ∈A\Args | ∃β ∈Args, (β, α) ∈att}
– Argsatt−out
AF
= att ∩(Args × Argsout
AF )
– ArgsBatt−out
AF
= Argsatt−out
AF
∪(att ∩(Argsout
AF × Args))
In words, Argsinp
AF includes the arguments attacking Args from the outside,
Argsatt−inp
AF
includes the attacks from Argsinp
AF to Args (but not vice versa),
ArgsBatt−inp
AF
includes the attacks from Argsinp
AF to Args and vice versa. Argsout
AF
includes the outside arguments attacked by Args, Argsatt−out
AF
includes the
attacks from Args to Argsout
AF , while ArgsBatt−out
AF
also includes the existing
reverse attacks.
Deﬁnition 10. The following functions from {(AF ∗, AF) | AF ∗, AF ∈SAF ∧
AF ⊑AF ∗} to SAF are deﬁned:
– inpLIAF ∗(AF) = (A ∪Ainp
AF ∗, att ∪Aatt−inp
AF ∗
)
– BinpLIAF ∗(AF) = (A ∪Ainp
AF ∗, att ∪ABatt−inp
AF ∗
)
– inpoutLIAF ∗(AF) = (A ∪Ainp
AF ∗∪Aout
AF ∗, att ∪Aatt−inp
AF ∗
∪Aatt−out
AF ∗
)
– BinpoutLIAF ∗(AF) = (A ∪Ainp
AF ∗∪Aout
AF ∗, att ∪ABatt−inp
AF ∗
∪ABatt−out
AF ∗
)
where AF = (A, att).
In words, inpLI selects as external information3 the set of outside attackers
and the unidirectional attacks from them to AF, BinpLI is similar but considers
both possible directions for the attacks, inpoutLI extends inpLI with the set of
outside arguments that are attacked by AF as well as the relevant attacks from
AF, while BinpoutLI is similar but considers both directions for the attack
relations.
One may also consider a larger neighboring part w.r.t. direct attackers and
attacked arguments. For instance, besides the direct attackers the local informa-
tion may involve also their attackers, the attackers of their attackers, and so on
until a level k.
Deﬁnition 11. Given an argumentation framework AF = (A, att), a path in
AF of length n from α0 to αn is a sequence of arguments α0, . . . , αn such that
(αi, αi+1) ∈att for each i ∈{0, . . . , n −1}. We indicate that a path of length n
exists from α0 to αn as pn
AF (α0, αn). Given a set of arguments Args ⊆AF and
an integer k > 0, Argsinp−k
AF
≡{α ∈A\Args | ∃β ∈A, pn
AF (α, β), n ≤k}.
The following function considers all the ancestors of the arguments in AF
(w.r.t. the attack relation) of distance less that or equal to a constant k as well
as all involved attacks.
Deﬁnition 12. inp −k −LI is the function from {(AF ∗, AF) | AF ∗, AF ∈
SAF ∧AF ⊑AF ∗} to SAF such that inp−k −LIAF ∗(AF) ≡AF ∗↓(A∪Ainp−k
AF ∗
).
3 This local information function is the one implicitly adopted in [4].

176
M. Giacomin et al.
Fig. 1. Argumentation frameworks AF ∗and AF, with AF ⊑AF ∗.
Example 1. Consider the argumentation frameworks AF ∗= ({α, β, γ1, γ2, γ3,
δ1, δ2, η},
{(δ1, γ1), (δ1, γ2), (γ1, α), (γ2, α), (α, γ2), (α, β), (β, α), (β, γ3), (γ3, δ2),
(δ2, η)}) and AF = AF ∗↓{α,β}, depicted in Fig. 1. It turns out that:
– inpLIAF ∗(AF) = ({α, β, γ1, γ2}, {(α, β), (β, α), (γ1, α), (γ2, α)})
– BinpLIAF ∗(AF) = ({α, β, γ1, γ2}, {(α, β), (β, α), (γ1, α), (γ2, α), (α, γ2)})
– inpoutLIAF ∗(AF)
=
({α, β, γ1, γ2, γ3}, {(α, β), (β, α), (γ1, α), (γ2, α),
(β, γ3)})
– BinpoutLIAF ∗(AF) = ({α, β, γ1, γ2, γ3}, {(α, β), (β, α), (γ1, α), (γ2, α), (α,
γ2), (β, γ3)})
– inp −2 −LIAF ∗(AF) = AF ∗↓{δ1,γ1,γ2,α,β}
To show that the above functions are actually local information functions,
we have to prove that they satisfy the constraints of Deﬁnition 7. The follow-
ing proposition introduces suﬃcient conditions that might be easier to verify
w.r.t. those of Deﬁnition 7. In particular, the constraint concerning the role of
the global framework AF ∗(second item in Deﬁnition 7) holds if a function is
monotone w.r.t. AF ∗and its output does not change if AF ∗is replaced with the
same argumentation framework returned as output.
Proposition 2. Let LI be a function from {(AF ∗, AF) | AF ∗, AF ∈SAF ∧
AF ⊑AF ∗} to SAF. If ∀AF ∗, AF ∈SAF : AF ⊑AF ∗the following conditions
are satisﬁed
– AF ⊑LIAF ∗(AF) and LIAF ∗(AF) ⊆AF ∗
– for every AF ∗∗∈SAF such that AF ∗⊆AF ∗∗, it holds that LIAF ∗(AF) ⊆
LIAF ∗∗(AF)
– LILIAF ∗(AF )(AF) = LIAF ∗(AF)
then LI is a local information function.
Proof. Referring to Deﬁnition 7, only the second item has to be proved since the
ﬁrst one holds by the ﬁrst hypothesis. For this purpose, we show that for every

Towards a General Theory of Decomposability in Abstract Argumentation
177
AF, AF ∗, AF ∗∗∈SAF such that AF ∗⊆AF ∗∗, if LIAF ∗∗(AF) ⊆AF ∗then
LIAF ∗∗(AF) = LIAF ∗(AF).
If LIAF ∗∗(AF) ⊆AF ∗, by the second hypothesis (monotony w.r.t. the global
framework) LILIAF ∗∗(AF )(AF) ⊆LIAF ∗(AF). According to the third hypothe-
sis LILIAF ∗∗(AF )(AF) = LIAF ∗∗(AF), thus LIAF ∗∗(AF) ⊆LIAF ∗(AF). Since
AF ∗⊆AF ∗∗, the second hypothesis yields LIAF ∗(AF) ⊆LIAF ∗∗(AF). Thus
by antisymmetry of ⊆we get LIAF ∗∗(AF) = LIAF ∗(AF).
⊓⊔
We can then show that the functions introduced above are local information
functions.
Proposition 3. The functions mLI, MLI, inpLI, BinpLI, inpoutLI,
BinpoutLI, inp −k −LI are local information functions.
Proof. For all of the functions the proof is based on Proposition 2.
As to mLI, if AF
⊑AF ∗then it is immediate to see that AF
⊑
mLIAF ∗(AF) and mLIAF ∗(AF) ⊆AF ∗, since mLIAF ∗(AF) = AF. Also the
second required constraint that mLIAF ∗(AF) ⊆mLIAF ∗∗(AF) trivially holds,
since mLIAF ∗(AF) = mLIAF ∗∗(AF) = AF. Finally, as to the third constraint
mLImLIAF ∗(AF )(AF) = mLIAF (AF) = AF = mLIAF ∗(AF).
As to MLI, if AF ⊑AF ∗then AF ⊑MLIAF ∗(AF) and MLIAF ∗(AF) ⊆
AF ∗trivially hold, since MLIAF ∗(AF) = AF ∗. The second constraint holds
since MLIAF ∗(AF) ⊆MLIAF ∗∗(AF) equates to AF ∗⊆AF ∗∗. As to the third
constraint, by the deﬁnition of MLI we directly get MLIMLIAF ∗(AF )(AF) =
MLIAF ∗(AF).
As to the other functions, by inspection of their deﬁnitions it is easy to
see that for each LI ∈{inpLI, BinpLI, inpoutLI, BinpoutLI, inp −k −LI}
LIAF ∗(AF) is obtained by adding to AF elements (arguments and attacks)
from AF ∗⊖AF. Thus the ﬁrst item of Proposition 2 is veriﬁed. It is also easy
to see that all elements of LIAF ∗(AF) are still present in the output obtained
with AF ∗enlarged, thus also the second item holds. As to the third item, let
LIAF ∗(AF) = AF ′. According to the deﬁnitions of the functions, each element
included in LIAF ∗(AF) is still an element of LIAF ′(AF), thus also the last item
of Proposition 2 is veriﬁed.
⊓⊔
Local information functions can be partially ordered based on the amount of
information returned as output.
Deﬁnition 13. Given two local information functions LI1 and LI2, LI1 ⪯
LI2 iﬀ∀AF ∗, AF
∈SAF
: AF
⊑AF ∗it holds that LI1AF ∗(AF) ⊆
LI2AF ∗(AF).
In words, if LI1 ⪯LI2 then LI1 always returns an argumentation framework
which is contained in that returned by LI2. For instance, the local information
function inpLI, that returns as output the outside attackers of AF and the
relevant (unidirectional) attacks, is less informative than inpoutLI that also
includes outside attacked nodes and the relevant unidirectional attacks, and
inpoutLI is in turn less informative than BinpoutLI.

178
M. Giacomin et al.
It is easy to see that ⪯is a partial order with the least and the greatest
elements.
Proposition 4. ⪯is reﬂexive, transitive and antisymmetric. mLI and MLI
are the least and greatest element, respectively, w.r.t. ⪯of the set of local infor-
mation functions.
Proof. The proof that ⪯is a partial order is immediate taking into account that
by Proposition 1 the relation ⊆between argumentation frameworks is a partial
order.
By
deﬁnition
of
local
information
function
(see
Deﬁnition
7)
∀LI,
∀AF ∗, AF
∈SAF
: AF
⊑AF ∗, it holds that AF
⊑LIAF ∗(AF) and
LIAF ∗(AF) ⊆AF ∗. Since AF ⊑LIAF ∗(AF) entails AF ⊆LIAF ∗(AF), it
holds that ∀LI, mLI ⪯LI and LI ⪯MLI.
⊓⊔
While local information functions model the identiﬁcation criterion of avail-
able topological information for all possible subframeworks of all global argu-
mentation frameworks, the information available for a speciﬁc subframework of
a given framework is represented by an argumentation framework with input,
which besides topological information includes the labelling externally assigned
to the neighboring part of the subframework. The next deﬁnition introduces this
notion in a generalized form w.r.t. [4].
Deﬁnition 14. Given AF, AF ′ ∈SAF such that AF ⊑AF ′, an argumentation
framework with input is a tuple (AF, AF ′, Lab) where Lab ∈LAF ′⊖AF .
Intuitively, AF plays the role of a subframework, while AF ′ and Lab are the
elements aﬀecting the computation of the labellings of AF. In particular, AF ′
represents the portion of the global argumentation framework which is taken into
account, including AF itself, while Lab is the labelling assigned to the relevant
arguments outside AF, i.e. those belonging to AF ′ ⊖AF.
The relationships between the notions of local information function and argu-
mentation framework with input are described in the following deﬁnitions.
Deﬁnition 15. An argumentation framework with input (AF, AF ′, Lab) is
derived from a local information function LI in AF ∗, written (AF, AF ′, Lab) ∈
AF inp
LI,AF ∗, if AF ′ = LIAF ∗(AF).
(AF, AF ′, Lab) is derived from LI, written (AF, AF ′, Lab) ∈AF inp
LI , if ∃AF ∗
such that (AF, AF ′, Lab) ∈AF inp
LI,AF ∗.
Intuitively, given a subframework AF of AF ∗, one can derive in AF ∗an
argumentation framework with input by applying a local information function
to AF and AF ∗, obtaining (AF, LIAF ∗(AF), Lab). The second part of the deﬁ-
nition removes the reference to a speciﬁc global argumentation framework AF ∗,
by deﬁning an argumentation framework with input as derived from LI if there
is AF ∗where it can be derived from LI.

Towards a General Theory of Decomposability in Abstract Argumentation
179
While in the notions introduced above the labelling component of argumen-
tation frameworks with input is not constrained, the notion of realizability intro-
duced in the following deﬁnition requires the labelling component to be enforced
by a labelling prescribed by the semantics.
Deﬁnition 16. An argumentation framework with input (AF, AF ′, Lab) is
realized from a local information function LI in an argumentation frame-
work AF ∗under a semantics S, written (AF, AF ′, Lab) ∈RAF inp
LI,AF ∗,S, if
(AF, AF ′, Lab) ∈AF inp
LI,AF ∗and ∃Lab∗∈LS(AF ∗) such that Lab∗↓AF ′⊖AF =
Lab.
(AF, AF ′, Lab) is realized from a local information function LI under a
semantics S, written (AF, AF ′, Lab) ∈RAF inp
LI,S, if ∃AF ∗∈SAF such that
(AF, AF ′, Lab) ∈RAF inp
LI,AF ∗,S.
3.2
The Notions of Local Function and Decomposability
We are now able to deﬁne the notion of decomposability of an argumentation
semantics, which corresponds to a generalization to the setting devised above of
the notion introduced in [4] with the same name.
The ﬁrst step is deﬁning a local function, representing a local counterpart
of the notion of semantics, since it takes as input an argumentation framework
with input (rather than a standard argumentation framework) and produces as
output a set of labellings for the inner local argumentation framework. It makes
sense to deﬁne a local function with reference to a local information function,
since only the argumentation frameworks with input derived from the adopted
local information function can play a role (see Deﬁnition 15).
Deﬁnition 17. A local function F for a local information function LI assigns
to any (AF, AF ′, Lab) ∈AF inp
LI a (possibly empty) set of labellings of AF, i.e.
F(AF, AF ′, Lab) ∈2L(AF ).
As in [4], decomposability may hold for a speciﬁc family of partitions of the
argumentation frameworks. A family of partitions is captured by the following
notion from [4].
Deﬁnition 18. A partition selector F is a function receiving as input an argu-
mentation framework AF = (A, att) and returning a set of partitions of A.
A semantics S is decomposable (also called fully decomposable) if the
labellings prescribed on an argumentation framework AF correspond to the pos-
sible combinations of compatible labellings obtained by applying a local function
F in the subframeworks that partition the global framework.
Deﬁnition 19. A local function F for a local information function LI enforces
decomposability of a semantics S under LI w.r.t. a partition selector F iﬀfor
every argumentation framework AF = (A, att) and for every partition P =
{P1, . . . , Pn} ∈F(AF), the following condition holds: LS(AF) = {LP 1 ∪. . . ∪

180
M. Giacomin et al.
LP n | LP i ∈F(AF↓Pi, LIAF (AF↓Pi), (
j=1...n,j̸=i LP j)↓LIAF (AF ↓Pi)⊖AF ↓Pi )}.
A semantics S is decomposable (or equivalently fully decomposable) under LI
w.r.t. F iﬀthere is a local function F which enforces decomposability of S under
LI w.r.t. F. In case the reference to F is omitted, the property holds for every
partition, i.e. w.r.t. the partition selector which returns the set of all possible
partitions of an argumentation framework.
In the above deﬁnition, each subframework enriched with the locally avail-
able external information is modelled by the argumentation framework with
input (AF↓Pi, LIAF (AF↓Pi), (
j=1...n,j̸=i LP j)↓LIAF (AF ↓Pi)⊖AF ↓Pi). The ﬁrst
component is the subframework of AF on the partition element Pi. The second
component is the available topological information on the neighboring part. The
third component is the labelling assigned to the available arguments outside
the subframework AF↓Pi, i.e. those included in the set LIAF (AF↓Pi) ⊖AF↓Pi.
Compatibility refers to the fact that any labelling of a subframework is used by
F to compute other labellings in other subframeworks. More speciﬁcally, each
local labelling LP i depends on the other ones since the labelling component
taken as input by F is obtained from the labellings LP j (with j ̸= i) computed
in external subframeworks.
4
On the Power of Local Information Functions
Intuitively, the more local information is available, the easier it is to determine
the global labellings from local computation. Therefore, we expect a more expres-
sive local information function to foster the correct identiﬁcation of the global
labellings, yielding a larger set of decomposable semantics.
Proposition 5. If a semantics S is decomposable under LI w.r.t. F then for
any LI′ such that LI ⪯LI′, S is decomposable under LI′ w.r.t. F.
Proof. By the hypothesis, there is a local function F for LI such that for
every argumentation framework AF = (A, att) and for every partition P =
{P1, . . . , Pn} ∈F(AF)
LS(AF) = {LP 1 ∪. . . ∪LP n |
LP i ∈F(AF↓Pi, LIAF (AF↓Pi), (

j=1...n,j̸=i
LP j)↓LIAF (AF ↓Pi)⊖AF ↓Pi)} (1)
Let us deﬁne the local function F ′ for LI′ such that for (AF, AF ′, Lab) ∈AF inp
LI′,
F ′(AF, AF ′, Lab) ≡F(AF, LIAF ′(AF), Lab↓LIAF ′(AF )⊖AF ).
We prove that F ′ enforces decomposability of S under LI′ w.r.t. F, i.e. for
every argumentation framework AF = (A, att) and for every partition P =
{P1, . . . , Pn} ∈F(AF)
LS(AF) = {LP 1 ∪. . . ∪LP n |
LP i ∈F ′(AF↓Pi, LI′
AF (AF↓Pi), (

j=1...n,j̸=i
LP j)↓LI′AF (AF ↓Pi)⊖AF ↓Pi )}

Towards a General Theory of Decomposability in Abstract Argumentation
181
This directly derives from (1) if
F ′(AF↓Pi, LI′
AF (AF↓Pi), (

j=1...n,j̸=i
LP j)↓LI′AF (AF ↓Pi)⊖AF ↓Pi)
= F(AF↓Pi, LIAF (AF↓Pi), (

j=1...n,j̸=i
LP j)↓LIAF (AF ↓Pi)⊖AF ↓Pi)
In order to prove this condition, for the sake of clarity we introduce the following
substitutions:
AF →AF ∗
AF↓Pi →AF
LIAF (AF↓Pi) →AF ′
LI′
AF (AF↓Pi) →AF ′′
(

j=1...n,j̸=i
LP j) →Lab
Under these substitutions, it is easy to see that the following conditions hold:
AF ′ = LIAF ∗(AF)
(2)
AF ′′ = LI′
AF ∗(AF)
(3)
AF ′′ ⊆AF ∗
(4)
where the last condition is due to the deﬁnition of local information function
referring to LI′.
Taking into account the substitutions above, the thesis becomes
F ′(AF, AF ′′, Lab↓AF ′′⊖AF ) = F(AF, AF ′, Lab↓AF ′⊖AF )
According to the deﬁnition of F ′, the ﬁrst term can be expressed as
F(AF, LIAF ′′(AF), (Lab↓AF ′′⊖AF )↓LIAF ′′(AF )⊖AF )
Since by deﬁnition of local information function LIAF ′′(AF) ⊆AF ′′, it holds
that (Lab↓AF ′′⊖AF )↓LIAF ′′(AF )⊖AF = Lab↓LIAF ′′(AF )⊖AF and thus the same
term can be expressed as
F(AF, LIAF ′′(AF), Lab↓LIAF ′′(AF )⊖AF )
Now, since by (4) AF ′′ ⊆AF ∗, by deﬁnition of local information function either
LIAF ′′(AF) = LIAF ∗(AF) or it is not the case that LIAF ∗(AF) ⊆AF ′′. On
the other hand, by the hypothesis that LI ⪯LI′, LIAF ∗(AF) ⊆LI′
AF ∗(AF)
which by (3) yields LIAF ∗(AF) ⊆AF ′′. Thus the ﬁrst option holds, yielding
the following expression for the term:
F(AF, LIAF ∗(AF), Lab↓LIAF ∗(AF )⊖AF )
which by (2) is equivalent to F(AF, AF ′, Lab↓AF ′⊖AF ), and we are done.
⊓⊔

182
M. Giacomin et al.
Note that the constraints introduced in Deﬁnition 7 are crucial in the above
proof.
Summing up, the partial order ⪯between local information functions has a
direct impact on the capability of capturing the global labellings through local
computations. It is then interesting to determine the sets of semantics that are
decomposable under the minimum and maximum (w.r.t. ⪯) local information
functions, i.e. mLI and MLI, respectively.
Proposition 6. There are only four semantics satisfying conﬂict-freeness that
are decomposable under mLI:
– The semantics UND
– The semantics S such that ∀AF ∈SAF, LS(AF) = ∅
– The semantics S such that LS(AF) = ∅if there is a self-attacking argument
in AF, LS(AF) = LUND(AF) otherwise
– The semantics S such that LS(AF) = ∅if there is an argument which is not
self-attacking in AF, LS(AF) = LUND(AF) otherwise.
Among these semantics, only UND is universally deﬁned.
Proof. First, to show that the four semantics are fully decomposable, we select
for each semantics S the local function F such that F(AF, AF, ∅) = LS(AF) as
deﬁned above (note in particular that all argumentation frameworks with input
in AF inp
mLI have the form (AF, AF, ∅)). It is then easy to see that F enforces
decomposability of S under mLI.
It is also immediate to verify that all of the four semantics satisfy conﬂict-
freeness, and among them only UND is universally deﬁned.
To show that there are no other semantics satisfying conﬂict-freeness that
are decomposable under mLI, for any AF = (A, att) ∈SAF, consider the
partition P = {{α} | α ∈A}, i.e. consisting of all sets including exactly a single
argument. If S is decomposable under mLI, according to Deﬁnition 19 we must
have, letting A = {α1, . . . , αn},
LS(AF) = {LP 1 ∪. . . ∪LP n | LP i ∈F(AF↓{αi}, AF↓{αi}, ∅)}
(5)
Note that given an argument α there are only two possibilities for AF↓{α}, i.e.
AF1 = ({α}, ∅) if α is not self-attacking and AF2 = ({α}, {(α, α}) otherwise. Let
us then evaluate the possible outcomes for F(AF1, AF1, ∅) and F(AF2, AF2, ∅).
First, the labelling {(α, out)} can be ruled out for both F(AF1, AF1, ∅) and
F(AF2, AF2, ∅) by considering the condition (5) applied to AF1 and AF2,
since the resulting labelling {(α, out)} would violate the second condition of
Deﬁnition 6. Also the labelling {(α, in)} can be ruled out. In particular, as
to F(AF2, AF2, ∅) it is again suﬃcient to consider the condition (5) applied
to AF2, since the resulting labelling {(α, in)} would violate the ﬁrst condi-
tion of Deﬁnition 6. As to F(AF1, AF1, ∅), in the argumentation framework
AF = ({α1, α2}, {(α1, α2)}) the condition (5) would prescribe (possibly among
others) the labelling {(α1, in), (α2, in)}, violating the ﬁrst condition of Deﬁni-
tion 6. As a consequence, only four cases are possible, and according to (5) they
correspond to the four semantics above in the relevant order, i.e.

Towards a General Theory of Decomposability in Abstract Argumentation
183
– F(AF1, AF1, ∅) = {{(α, undec)}} and F(AF2, AF2, ∅) = {{(α, undec)}}
– F(AF1, AF1, ∅) = ∅and F(AF2, AF2, ∅) = ∅
– F(AF1, AF1, ∅) = {{(α, undec)}} and F(AF2, AF2, ∅) = ∅
– F(AF1, AF1, ∅) = ∅and F(AF2, AF2, ∅) = {{(α, undec)}}
⊓⊔
Proposition 7. Every semantics S is decomposable under MLI.
Proof. For a semantics S, we consider the local function F for MLI deﬁned as
F(AF, AF ′, Lab) ≡{Lab′↓A | Lab′ ∈LS(AF ′) ∧Lab′↓AF ′⊖AF = Lab}, where A
denotes the set of arguments of AF.
We have to prove that for every argumentation framework AF = (A, att) and
for every partition P = {P1, . . . , Pn}, it holds that LS(AF) = {LP 1 ∪. . .∪LP n |
LP i ∈F(AF↓Pi, MLIAF (AF↓Pi), (
j=1...n,j̸=i LP j)↓MLIAF (AF ↓Pi)⊖AF ↓Pi)} =
{LP 1 ∪. . . ∪LP n | LP i ∈F(AF↓Pi, AF, (
j=1...n,j̸=i LP j)↓AF ⊖AF ↓Pi )}, where
by the deﬁnition of F and taking into account that AF = (A, att) we have
that F(AF↓Pi, AF, (
j=1...n,j̸=i LP j)↓AF ⊖AF ↓Pi ) = {Lab↓Pi | Lab ∈LS(AF) ∧
Lab↓A\Pi = (
j=1...n,j̸=i LP j)↓A\Pi}.
Let
us
ﬁrst
consider
a
labelling
Lab
∈
LS(AF).
Since
P
is
a
partition,
it
obviously
holds
that
Lab
=
LP 1 ∪. . . ∪LP n
with
LP i
=
Lab↓Pi, and Lab↓A\Pi
=
(
j=1...n,j̸=i LP j)↓A\Pi, thus LP i
∈
F(AF↓Pi, AF, (
j=1...n,j̸=i LP j)↓AF ⊖AF ↓Pi).
Let us then consider a collection of labellings LP i for i = 1 . . . n such that
LP i ∈F(AF↓Pi, AF, (
j=1...n,j̸=i LP j)↓AF ⊖AF ↓Pi ). By the expression above,
LP i = Labi↓Pi with Labi ∈LS(AF) and Labi↓A\Pi = (
j=1...n,j̸=i LP j)↓A\Pi.
The last condition entails that, for any i, j = 1 . . . n, Labi↓Pj = LP j, thus in
particular Lab1 = . . . = Labn. As a consequence, LP 1 ∪. . . ∪LP n ∈LS(AF). ⊓⊔
Summing up, if complete information on the global argumentation framework
is available to the local computations, then all semantics become decomposable.
If no external information is available, decomposable semantics are only those
that are maximally undecided (i.e. those leaving all arguments undecided). This
seems to be perfectly reasonable behavior, conﬁrming the suitability of our model
and the adopted deﬁnition of decomposability.
5
The Canonical Local Function
Once the general model has been designed, the next step is to identify a way
to determine a suitable local function for an argumentation semantics S. By
‘suitable’ we mean being able to enforce decomposability of S if this is possi-
ble, i.e. if S is decomposable. Inspired by the notion of standard argumentation
framework of [4], the idea is to consider, for any argumentation framework with
input (AF, AF ′, Lab) derived from LI, the labellings prescribed by S in an argu-
mentation framework AF ∗in which the argumentation framework with input
is realized from LI. Consequently, any local function enforcing decomposability

184
M. Giacomin et al.
must include as output the restriction of the labellings of AF ∗to the subframe-
work AF. This is shown in the following proposition, whose proof is omitted due
to space limitations.
Proposition 8. Let S be a fully decomposable semantics under LI, and let
(AF, AF ′, Lab) ∈AF inp
LI be an argumentation framework with input derived from
LI. Let AF ∗be an argumentation framework such that AF ′ = LIAF ∗(AF),
and Lab∗∈LS(AF ∗) be a labelling of AF ∗such that Lab∗↓AF ′⊖AF = Lab.
Then, for any local function F which enforces decomposability of S under LI,
Lab∗↓AF ∈F(AF, AF ′, Lab).
We should note that the reverse of the above proposition does not hold, i.e.
F may require additional labellings w.r.t. those mentioned in the proposition.
A labelling included in F(AF, AF ′, Lab) may not play a role in forming the
labellings of AF ∗due to the compatibility conditions, but it may be required
in a diﬀerent argumentation framework. This suggests adopting the following
deﬁnition of the canonical local function, which includes all possible labellings
that play a role in some argumentation framework.
Deﬁnition 20. Given a semantics S and a local information function LI,
the canonical local function F LI
S
of S associated to LI is deﬁned as follows.
For any (AF, AF ′, Lab) ∈AF inp
LI , F LI
S (AF, AF ′, Lab) = {Lab∗↓AF | ∃AF ∗∈
SAF, AF ′ = LIAF ∗(AF), Lab∗∈LS(AF ∗) ∧Lab∗↓AF ′⊖AF = Lab}.
Example 2. Consider (AF, AF ′, Lab) with AF = ({α, β}, {(α, β), (β, α)}), AF ′ =
({α, β, γ1, γ2}, {(α, β), (β, α), (γ1, α), (γ2, α)}) and Lab = {(γ1, out), (γ2, out)}.
Since in Example 1 AF ′ = inpLIAF ∗(AF), it holds that (AF, AF ′, Lab) ∈
AF inp
inpLI. We determine F LI
S (AF, AF ′, Lab) where S is the preferred seman-
tics, a well-known multiple-status semantics [13]. To this purpose, we consider
all AF ∗∈SAF such that AF ′ = inpLIAF ∗(AF) and ∃Lab∗∈LS(AF ∗) with
Lab∗↓{γ1,γ2} = {(γ1, out), (γ2, out)}. Referring again to Example 1, there are two
preferred labellings in AF ∗, both assigning the label in to δ1 and the label out to
γ1 and γ2. One of this labellings assigns in to α and out to β, the other assigns
out to α and in to β, thus {(α, in), (β, out)} and {(α, out), (β, in)} belong to
F LI
S (AF, AF ′, Lab). Finally, it can be proved that for any AF ∗satisfying the
conditions above there are no preferred labellings assigning diﬀerent labellings
to {α, β}, thus F LI
S (AF, AF ′, Lab) = {{(α, in), (β, out)}, {(α, out), (β, in)}}.
The following proposition shows that the output of the canonical local func-
tion is necessary to enforce decomposability (if possible).
Proposition 9. Let S be a decomposable semantics under LI and let F be a
local function which enforces decomposability of S under LI.
Then, ∀(AF, AF ′, Lab) ∈AF inp
LI , F LI
S (AF, AF ′, Lab) ⊆F(AF, AF ′, Lab).
Proof. The proof is an immediate consequence of Proposition 8.

Towards a General Theory of Decomposability in Abstract Argumentation
185
The reverse of this proposition does not hold since a local function F enforcing
decomposability can prescribe for a subframework spurious labellings that are
not compatible with those of the other subframeworks and thus do not alter the
set of labellings obtained by joining the results of local computations.
On the other hand, the output of F LI
S
includes all labellings suﬃcient to
enforce decomposability, if this is possible.
Proposition 10. If a semantics S is fully decomposable under a local informa-
tion function LI, then F LI
S
enforces decomposability of S under LI.
Proof. By the hypothesis there is a local function F for LI such that for
every argumentation framework AF = (A, att) and for every partition P =
{P1, . . . , Pn}
LS(AF) = {LP 1 ∪. . . ∪LP n |
LP i ∈F(AF↓Pi, LIAF (AF↓Pi), (
j=1...n,j̸=i LP j)↓LIAF (AF ↓Pi)⊖AF ↓Pi)}(6)
and we have to prove that for every AF = (A, att) and for every partition
P = {P1, . . . , Pn}
LS(AF) = {LP 1 ∪. . . ∪LP n |
LP i ∈F LI
S (AF↓Pi, LIAF (AF↓Pi), (
j=1...n,j̸=i LP j)↓LIAF (AF ↓Pi)⊖AF ↓Pi)}(7)
First, consider Lab ≡LP 1 ∪. . . ∪LP n such that for every i ∈{1, . . . , n} LP i ∈
F LI
S (AF↓Pi, LIAF (AF↓Pi), (
j=1...n,j̸=i LP j)↓LIAF (AF ↓Pi)⊖AF ↓Pi ). By Propo-
sition 9, F LI
S (AF↓Pi, LIAF (AF↓Pi), (
j=1...n,j̸=i LP j)↓LIAF (AF ↓Pi)⊖AF ↓Pi ) ⊆
F(AF↓Pi, LIAF (AF↓Pi), (
j=1...n,j̸=i LP j)↓LIAF (AF ↓Pi)⊖AF ↓Pi ). Thus by (6) it
holds that Lab ∈LS(AF).
As to the other direction of the proof, take a labelling Lab ∈LS(AF).
According to (6) LS(AF) = LP 1 ∪. . . ∪LP n, where for each i ∈{1, . . . , n}
LP i ∈F(AF↓Pi, LIAF (AF↓Pi), (
j=1...n,j̸=i LP j)↓LIAF (AF ↓Pi)⊖AF ↓Pi ). Note in
particular that LP i = Lab↓Pi. In order to prove condition (7) we show that
LP i ∈F LI
S (AF↓Pi, LIAF (AF↓Pi), (
j=1...n,j̸=i LP j)↓LIAF (AF ↓Pi)⊖AF ↓Pi ).
According
to
the
deﬁnition
of
canonical
local
function
(see
Deﬁni-
tion 20) F LI
S (AF↓Pi, LIAF (AF↓Pi), (
j=1...n,j̸=i LP j)↓LIAF (AF ↓Pi)⊖AF ↓Pi ) =
{Lab∗↓AF ↓Pi
| ∃AF ∗, LIAF (AF↓Pi) = LIAF ∗(AF↓Pi), Lab∗∈LS(AF ∗) ∧
Lab∗↓LIAF (AF ↓Pi)⊖AF ↓Pi = (
j=1...n,j̸=i LP j)↓LIAF (AF ↓Pi)⊖AF ↓Pi}. Choosing
in the last expression AF ∗= AF, we note that letting Lab∗= Lab yields
all the relevant conditions to be satisﬁed. In particular, LIAF (AF↓Pi) =
LIAF ∗(AF↓Pi) trivially holds, Lab ∈LS(AF) holds by assumption, and ﬁnally
the condition Lab↓LIAF (AF ↓Pi)⊖AF ↓Pi = (
j=1...n,j̸=i LP j)↓LIAF (AF ↓Pi)⊖AF ↓Pi
holds because for any i LP i
=
Lab↓Pi. Thus we get Lab↓AF ↓Pi
∈
F LI
S (AF↓Pi, LIAF (AF↓Pi), (
j=1...n,j̸=i LP j)↓LIAF (AF ↓Pi)⊖AF ↓Pi ).
The conclusion follows noting that Lab↓AF ↓Pi = Lab↓Pi = LP i.
⊓⊔
The canonical local function is pivotal for investigating the decomposability
property of a semantics, since it allows one to ﬁx without loss of generality

186
M. Giacomin et al.
the local function in the condition of Deﬁnition 19. In particular, according to
Proposition 10 the proof that a semantics S is fully decomposable under LI can
focus on this condition with F = F LI
S , and conversely to show that a semantics
is not decomposable it is suﬃcient to identify an argumentation framework and
a partition where the same condition is not satisﬁed by F LI
S .
An important question is then how to identify the deﬁnition of the canonical
local function. To answer this question, one needs to consider the speciﬁc seman-
tics deﬁnition, which is outside the scope of the present paper. Here we prove
that such a function can be generated by a standard argumentation framework
function, which associates to any realized argumentation framework with input
a ﬁnite set of argumentation frameworks in which this argumentation framework
with input is realized.
Deﬁnition 21. Given a local information function LI and a semantics S, a
standard argumentation framework function fST from LI under S is a (possibly
partial) function which associates to any argumentation framework with input
(AF, AF ′, Lab) ∈AF inp
LI a ﬁnite set of argumentation frameworks such that
fST (AF, AF ′, Lab) ⊆{AF ∗| (AF, AF ′, Lab) ∈RAF inp
LI,AF ∗,S}.
Note that fST (AF, AF ′, Lab) is not deﬁned, i.e. returns the empty set, if
(AF, AF ′, Lab) ̸∈RAF inp
LI,S.
The following deﬁnition clariﬁes the relationship between standard argumen-
tation framework functions and local functions. Intuitively, a local function F is
generated by a standard argumentation framework function fST if the argumen-
tation frameworks returned by fST for any argumentation framework with input
allows one to construct the output of F, thus providing in a sense a complete
characterization of the argumentation framework with input.
Deﬁnition 22. A local function F for a local information function LI is gen-
erated by a standard argumentation framework function fST from LI under S
if for any (AF, AF ′, Lab) ∈AF inp
LI it holds that
F(AF, AF ′, Lab) = {Lab∗↓AF | ∃AF ∗∈fST (AF, AF ′, Lab), Lab∗∈LS(AF ∗),
Lab∗↓AF ′⊖AF = Lab}
There is always a standard argumentation framework function that generates
the canonical local function.
Proposition 11. Given a semantics S and a local information function LI,
there exists a standard argumentation framework function fST from LI under
S which generates the canonical local function F LI
S .
Proof. We construct fST as follows. Taking into account Deﬁnition 20, for any
(AF, AF ′, Lab) ∈AF inp
LI the output of F LI
S (AF, AF ′, Lab) can be expressed as

AF ∗:AF ′=LIAF ∗(AF )
{Lab∗↓AF | Lab∗∈LS(AF ∗) ∧Lab∗↓AF ′⊖AF = Lab}

Towards a General Theory of Decomposability in Abstract Argumentation
187
Since the number of labellings of AF, i.e. the cardinality of L(AF), is 3n where
n is the number of arguments in AF, obviously the number of distinct labellings
Lab∗↓AF in the set above is ﬁnite as well. Thus there is a ﬁnite set of argumen-
tation frameworks, that we let as fST (AF, AF ′, Lab), such that
F LI
S (AF, AF ′, Lab) =

AF ∗∈fST (AF,AF ′,Lab)
{Lab∗↓AF | Lab∗∈LS(AF ∗) ∧Lab∗↓AF ′⊖AF = Lab}
This corresponds to our desired fST (see Deﬁnition 22).
⊓⊔
6
Discussion and Conclusion
In this paper, we have devised a model for studying the decomposability of
argumentation semantics in Dung’s abstract argumentation setting. The model
corresponds to a generalization of the deﬁnitions introduced in a previous paper:
it encompasses all possible kinds of local information available for the local com-
putations, under some mild constraints. In this general model, we have proved
a monotone relationship between the degree of information available locally and
the set of decomposable semantics, and we have investigated the range of capabil-
ities of local information in allowing decomposability of semantics, by determin-
ing the sets of decomposable semantics in the two extreme situations concerning
the availability of local information. Furthermore, we have identiﬁed in general
terms a local function for any semantics that enforces decomposability whenever
possible, i.e. when the semantics is decomposable. This represents a reference
point to prove or disprove the decomposability of a speciﬁc semantics.
Many future directions of this work can be envisaged, both at the level of
the general model and its instantiation with speciﬁc semantics.
At the abstract level, an interesting issue concerns the possible relationship
between decomposability w.r.t. a partition selector and decomposability under
a local information function. For instance, the fact that a semantics is decom-
posable when the partition elements coincide with the strongly connected com-
ponents of the argumentation framework may imply that, if the available local
information includes such components (and possibly some neighboring part), the
semantics is decomposable. This relation could be investigated in general terms.
Moreover, further investigation may be devoted to the notion of the canonical
local function. For a semantics, there might be various standard argumentation
framework functions that generate the canonical local function. An interesting
issue is to identify a minimal one, i.e. minimizing the number of argumentation
frameworks associated with each argumentation framework with input. A related
issue concerns the identiﬁcation of particular conditions on the local information
function that allows one to identify a local function able to enforce decompos-
ability (if this is possible) and that can be generated by a standard argumenta-
tion framework function which associates to any argumentation framework with
input a singleton, i.e. an argumentation framework only. This happens for some
semantics in [4], where the local information involves direct attackers only.

188
M. Giacomin et al.
Turning to the level of speciﬁc semantics, a ﬁrst issue is to identify for the
semantics available in the literature the canonical local function (or one of its
variations as described above) in an explicit form. This will be useful for studying
decomposability under diﬀerent local information functions and, possibly, deter-
mining the minimal local information suﬃcient to guarantee decomposability.
References
1. Atkinson, K., et al.: Towards artiﬁcial argumentation. AI Mag. 38(3), 25–36 (2017)
2. Baroni, P., Caminada, M., Giacomin, M.: An introduction to argumentation
semantics. Knowl. Eng. Rev. 26(4), 365–410 (2011)
3. Baroni, P., Giacomin, M.: On principle-based evaluation of extension-based argu-
mentation semantics. Artif. Intell. (Spec. Issue Argument. A.I.) 171(10/15), 675–
700 (2007)
4. Baroni, P., Boella, G., Cerutti, F., Giacomin, M., van der Torre, L.W.N., Villata,
S.: On the input/output behavior of argumentation frameworks. Artif. Intell. 217,
144–197 (2014)
5. Baroni, P., Giacomin, M.: Some considerations on epistemic and practical reasoning
in abstract argumentation. In: Proceedings of the 2nd Workshop on Advances in
Argumentation In Artiﬁcial Intelligence, pp. 1–5 (2018)
6. Baumann, R., Brewka, G.: Analyzing the equivalence zoo in abstract argumen-
tation. In: Leite, J., Son, T.C., Torroni, P., van der Torre, L., Woltran, S. (eds.)
CLIMA 2013. LNCS (LNAI), vol. 8143, pp. 18–33. Springer, Heidelberg (2013).
https://doi.org/10.1007/978-3-642-40624-9 2
7. Baumann, R., Brewka, G., Wong, R.: Splitting argumentation frameworks: an
empirical evaluation. In: Modgil, S., Oren, N., Toni, F. (eds.) TAFA 2011. LNCS
(LNAI), vol. 7132, pp. 17–31. Springer, Heidelberg (2012). https://doi.org/10.
1007/978-3-642-29184-5 2
8. Baumann, R.: Splitting an argumentation framework. In: Delgrande, J.P., Faber,
W. (eds.) LPNMR 2011. LNCS (LNAI), vol. 6645, pp. 40–53. Springer, Heidelberg
(2011). https://doi.org/10.1007/978-3-642-20895-9 6
9. Caminada, M.: On the issue of reinstatement in argumentation. In: Fisher, M., van
der Hoek, W., Konev, B., Lisitsa, A. (eds.) JELIA 2006. LNCS (LNAI), vol. 4160,
pp. 111–123. Springer, Heidelberg (2006). https://doi.org/10.1007/11853886 11
10. Caminada, M.W.A.: A labelling approach for ideal and stage semantics. Argument
Comput. 2(1), 1–21 (2011)
11. Cerutti, F., Giacomin, M., Vallati, M., Zanella, M.: A SCC recursive meta-
algorithm for computing preferred labellings in abstract argumentation. In: Pro-
ceedings of the 14th International Conference on Principles of Knowledge Repre-
sentation and Reasoning (KR 2014) (2014, to appear)
12. Cerutti, F., Tachmazidis, I., Vallati, M., Batsakis, S., Giacomin, M., Antoniou, G.:
Exploiting parallelism for hard problems in abstract argumentation. In: Proceed-
ings of the 29th AAAI Conference on Artiﬁcial Intelligence, vol. 29 (2015)
13. Dung, P.M.: On the acceptability of arguments and its fundamental role in non-
monotonic reasoning, logic programming and n-person games. Artif. Intell. 77,
321–357 (1995)
14. Gabbay, D.M.: Fibring argumentation frames. Stud. Log. 93(2–3), 231–295 (2009)

Towards a General Theory of Decomposability in Abstract Argumentation
189
15. Giacomin, M.: Handling heterogeneous disagreements through abstract argumen-
tation (extended abstract). In: An, B., Bazzan, A., Leite, J., Villata, S., van der
Torre, L. (eds.) PRIMA 2017. LNCS (LNAI), vol. 10621, pp. 3–11. Springer, Cham
(2017). https://doi.org/10.1007/978-3-319-69131-2 1
16. Liao, B., Huang, H.: Partial semantics of argumentation: basic properties and
empirical results. J. Log. Comput. 23(3), 541–562 (2013)
17. Liao, B., Jin, L., Koons, R.C.: Dynamics of argumentation systems: a division-
based method. Artif. Intell. 175, 1790–1814 (2011)
18. Rienstra, T., Perotti, A., Villata, S., Gabbay, D.M., van der Torre, L.: Multi-sorted
argumentation. In: Modgil, S., Oren, N., Toni, F. (eds.) TAFA 2011. LNCS (LNAI),
vol. 7132, pp. 215–231. Springer, Heidelberg (2012). https://doi.org/10.1007/978-
3-642-29184-5 14
19. Villata, S., Boella, G., van Der Torre, L.: Argumentation patterns. In: Proceedings
of ARGMAS 2011 8th International Workshop on Argumentation in Multi-Agent
Systems, pp. 133–150 (2011)

Abstract Argumentation with Qualitative
Uncertainty: An Analysis in Dynamic
Logic
Andreas Herzig1
and Antonio Yuste-Ginel2(B)
1 IRIT, Toulouse, France
herzig@irit.fr
2 Departamento de Filosof´ıa, Universidad de M´alaga, M´alaga, Spain
Abstract. We extend the existing encoding of abstract argumentation
frameworks in DL-PA (Dynamic Logic of Propositional Assignments) in
order to capture diﬀerent formalisms for arguing with qualitative forms
of uncertainty. More in particular, we encode the main reasoning tasks
of (rich) incomplete argumentation frameworks and control argumenta-
tion frameworks. After that, and inspired by our encoding, we deﬁne
and study a new class of structures that are shown to be maximally
expressive: constrained incomplete argumentation frameworks.
Keywords: Incomplete argumentation frameworks · Dynamic logic of
propositional assignments · Control argumentation frameworks
1
Introduction
Formal argumentation has been proved to be a successful approach to non-
monotonic reasoning (see e.g. [15]), among many other applications [2,12].
Within the studies directed to provide a formal model for argument-based infer-
ence, abstract models of argumentation play a crucial role, as they answer a
rather fundamental question: how should a rational agent choose among a con-
ﬂicting set of arguments those that are better justiﬁed? The adjective abstract
stresses that these models disregard the nature and structure of arguments, in
order to focus on the diﬀerent semantics through which one could give a precise
answer to the question above. The foremost abstract model of argumentation
is the use of directed graphs, ﬁrst proposed by Dung in [23] under the name of
argumentation frameworks (AFs), where nodes stand for arguments and arrows
stand for attacks among arguments.
Andreas Herzig is partially supported by the EU ICT-48 2020 project TAILOR (No.
952215). Antonio Yuste-Ginel gratefully acknowledges funding received from the PhD
grant No. MECDFPU 2016/04113. We thank Sylvie Doutre and Jean-Guy Mailly for
previous discussions on the topic of this paper, specially for triggering the idea of
constrained incomplete argumentation frameworks.
c
⃝Springer Nature Switzerland AG 2021
P. Baroni et al. (Eds.): CLAR 2021, LNAI 13040, pp. 190–208, 2021.
https://doi.org/10.1007/978-3-030-89391-0_11

Arguing with Qualitative Uncertainty in DL-PA
191
Despite being an elegant and powerful tool, AFs have limited modelling capa-
bilities for many purposes. Consequently, many extensions of Dung’s model have
been proposed in the literature since its publication. Examples of such exten-
sions are the addition of a support relation [16], of recursive forms of attacks [6]
and of preferences among arguments [1]. An essential limitation that AFs come
equipped with is the assumption that the formalized agent has perfect knowledge
about the relevant arguments and attacks of the debate (that is, about the struc-
ture of the AF). This turns out to be an important shortcoming in adversarial
contexts, where usually one wants to model the information (i.e., the part of an
AF) that an agent thinks that her opponent entertains, and thus uncertainty nat-
urally pops up into the picture. However, the assumption of perfect knowledge
has been relaxed through the study of extensions of AFs that include diﬀer-
ent forms of uncertainty, either through the use of probability [28] or through
qualitative methods. Among the second group of approaches, incomplete argu-
mentation frameworks (IAFs) [8–11,24] and control argumentation frameworks
(CAFs) [18,31] have recently received a lot of attention, resulting in a precise
complexity map of the diﬀerent associated reasoning tasks as well as some appli-
cations [19].
Concurrently, a large number of works within formal argumentation have
focused on building a suitable logical theory for reasoning about argumentation
formalisms, with a special focus on AFs and their dynamics (see [13] for a recent
survey on the topic). The dynamic logic of propositional assignments (DL-PA)
[4] has been shown to be a useful tool for this enterprise [20–22]. DL-PA is a
well-behaved variant of propositional dynamic logic (PDL) [26], where atomic
programs are restricted to assignments of propositional variables to either Truth
or Falsity. It is expressive enough to capture all standard argumentation seman-
tics. When compared to encodings in propositional logic, DL-PA can capture
semantics that incorporate minimality or maximality criteria more succinctly.
Moreover, its advantages over other encodings of AFs in equally succinct lan-
guages (e.g. quantiﬁed Boolean formulas) have also been highlighted [21].
Contribution and Structure. In this paper, we explain how to extend the machin-
ery of [20–22] so as to use DL-PA for reasoning about diﬀerent formalisms for
arguing with qualitative uncertainty. In particular, and after introducing the
basic tools (Sects. 2 and 3) we encode in DL-PA programs the main reasoning
tasks concerning incomplete argumentation frameworks (Sect. 4), their enriched
version (called rich incomplete argumentation frameworks [29]) (Sect. 5), and
control argumentation frameworks (Sect. 6). After that, and inspired by our
encoding, we deﬁne and study the expressive power of a new class of structures
for arguing with qualitative uncertainty: constrained incomplete argumentation
frameworks, whose naturally associated reasoning tasks are also encodable in
DL-PA (Sect. 7). We close the paper by discussing related work and pointing
out paths for future research in Sect. 8. Most of the proofs are merely sketched
for space reasons, details are left to the reader.

192
A. Herzig and A. Yuste-Ginel
2
Background
General Notation for Sets of Arguments and Attack Relations. We assume a
ﬁnite, non-empty set of arguments U (the universe) as ﬁxed from now on. We
moreover assume that U is big enough to accommodate our examples. Sets of
arguments (denoted A, sometimes with a superscript) are supposed to be subsets
of U; and all conﬂict relations (denoted R, sometimes with a superscript) are
supposed to be deﬁned over U (i.e., R ⊆U × U). Given A ⊆U and R ⊆U × U,
we use R|A to abbreviate R ∩(A × A) (the restriction of R to A).
2.1
Abstract Argumentation Frameworks and Their Stable
Semantics
An argumentation framework (AF) is a directed graph (A, R) [23], where A
stands for a set of arguments and R stands for a conﬂict-based relation among
them (typically, an attack relation).1 Argumentation semantics are meant to
capture the informal notion of a reasonable position in a debate (i.e. in an AF).
There is a large number of available semantics studied in the literature (see [5]).
For the sake of presentation we stick to stable semantics, but our approach can
be straightforwardly extended to the rest of standard semantics deﬁned by Dung
[23], namely admissible, complete, grounded and preferred: it suﬃces to combine
our results with those of [20]. A set of arguments E ⊆A is a stable extension
if (i) (E × E) ∩R = ∅(‘E is conﬂict-free’) and (ii) x ∈A \ E implies that there
is a y ∈E such that (y, x) ∈R (‘E attacks every argument outside itself’). We
note st(A, R) the set of all stable extensions of (A, R). An argument x ∈E is
said to be credulously (resp. sceptically) accepted if it belongs to at least one
(resp. every) extension.
As an example, for the AF (A0, R0) represented in the picture below we have
st(A0, R0) = {{b, e}, {c, d}}.
a
b
c
d
e
2.2
Dynamic Logic of Propositional Assignments (DL-PA)
We shall use DL-PA as a the general logical framework of this paper. We start
by associating several kinds of propositional variables to arguments. To every
1 As A ⊆U, we actually focus on ﬁnite AFs, as most of the literature does. This is an
essential limitation of our approach, as our encodings use formulas parametrised by
U, which makes ﬁniteness of U necessary. Capturing some argumentation semantics
for the general case has been shown to require powerful logical languages, such as
modal µ-calculus for the grounded semantics [25].

Arguing with Qualitative Uncertainty in DL-PA
193
set of arguments A ⊆U we associate the set of awareness variables AWA =
{awx | x ∈A}, and the set of acceptance variables INA = {inx | x ∈A}.
Furthermore, to every relation R ⊆U ×U we associate the set of attack variables
ATTR = {rx,y | (x, y) ∈R}. The set of propositional variables of our logic is then
PrpU = AWU ∪INU ∪ATTU×U
= {awx | x ∈U} ∪{inx | x ∈U} ∪{rx,y | (x, y) ∈U2}.
Then formulas and programs of DL-PA are deﬁned by mutual recursion:
ϕ ::= p | ¬ϕ | (ϕ ∧ϕ) | [π]ϕ
π ::= +p | −p | ϕ? | (π; π) | (π ∪π) | π⌣
where p ranges over PrpU. The formula [π]ϕ reads “ϕ is true after every possible
execution of π”. The program +p makes p true and −p makes p false. The
program ϕ? tests that ϕ is true (and fails when it is false). The program π1; π2
is the sequential composition of π1 and π2, and π1 ∪π2 is their nondeterministic
composition. Finally, π⌣is the execution of π ‘the other way round’. As usual,
skip abbreviates the program ⊤?.
Formulas of DL-PA are interpreted over classical propositional valuations,
i.e., subsets of PrpU. Programs are interpreted as binary relations on the set of
all valuations. We use v, v ′, v ′′ to denote valuations. Again by mutual recursion,
the interpretation of modal formulas is:
v |= [π]ϕ if (v, v ′) ∈||π|| implies v ′ |= ϕ,
and the interpretation of programs ||π|| ⊆2PrpU × 2PrpU is:
||+p|| = {(v, v ′) | v ′ = v ∪{p}}
||−p|| = {(v, v ′) | v ′ = v \ {p}}
||ϕ?|| = {(v, v) | v |= ϕ}
||π; π′|| = ||π|| ◦||π′||
||π ∪π′|| = ||π|| ∪||π′||
||π⌣|| = ||π||−1
A formula ϕ is DL-PA satisﬁable if v |= ϕ for some v, and it is valid if v |= ϕ
for every v. It is known that satisﬁability, validity, and model-checking are all
PSPACE complete decision problems [3].
From Valuations to AFs and Backward. Each propositional valuation v ⊆PrpU
represents an AF (Av, Rv), where Av = {x ∈U | awx ∈v} and Rv = {(x, y) ∈
U2 | rx,y ∈v}|Av . The other way round, each AF (A, R) can be represented as a
propositional valuation v(A,R) = {awx | x ∈A} ∪{rx,y | (x, y) ∈R}. Note that
if we start with a valuation v ′ we have that v(Av′,Rv′) = v ′ does not generally
hold (because a valuation can contain an attack variable ra,b with neither awa
nor awb being members of it). If we, however, start with an AF (A′, R′) we have
that (Av(A′,R′), Rv(A′,R′)) = (A′, R′) is always the case.

194
A. Herzig and A. Yuste-Ginel
3
Formalisms for Arguing with Qualitative Uncertainty
We now review three formalisms for representing qualitative uncertainty about
abstract argumentation frameworks. We start by presenting control argumenta-
tion frameworks (CAFs) [18], which besides uncertainty, also include a dynamic
component. After that, we introduce rich incomplete argumentation frameworks
(rIAFs) [29] and incomplete argumentation frameworks (IAFs) [8] as special cases
of CAFs.
A control argumentation framework is a triple CAF = (F, C, U) where:
– F = (AF , RF ) is the ﬁxed part, with RF ⊆(AF ∪A?) × (AF ∪A?), and both
AF and A? being two ﬁnite sets of arguments;
– U = (A?, (R? ∪R↔)) is the uncertain part, where
R?, R↔⊆(AF ∪A?) × (AF ∪A?)
and R↔is symmetric and irreﬂexive;2
– C = (AC, RC) is the control part where AC is yet another ﬁnite set of argu-
ments and
RC ⊆(AC × (AF ∪A? ∪AC)) ∪((AF ∪A? ∪AC) × AC);
– AF , A?, and AC are pairwise disjoint; and
– RF , R?, R↔, and RC are pairwise disjoint.
Standard AFs can be viewed as CAFs with empty uncertain and control
parts: CAFs where A?, R?, R↔, and AC are empty (and therefore RC is empty
by deﬁnition too).
Given a CAF = (F, C, U), a control conﬁguration is a subset of control
arguments CFG ⊆AC. The CAF associated to CFG is CAFCFG = (F, CCFG, U)
where CCFG = (CFG, RC |AF ∪A?∪ACFG).
Epistemic Interpretation of CAFs. In order to throw some intuition, let us brieﬂy
recall the epistemic interpretation of CAFs provided in [32]. A CAF can be
thought as modelling an agent (the proponent) who is trying to convince another
agent (the opponent) to accept certain argument(s). Under this interpretation,
F represents the arguments and attacks that the proponent knows the opponent
knows. U represents the argument and attacks such that the proponent is not
sure about how the opponent perceives them. In particular, R↔is an conﬂict
relation such that the proponent knows that the opponent knows that these
attacks hold, but the direction of the attack according to the opponent’s per-
ception is unknown to the proponent. This makes perfect sense if we understand
conﬂict relations as defeat relations (as done in the ﬁeld of structured argumen-
tation [14]). In this picture, the proponent can be sure about the opponent’s
perception of at least one of the attacks between a and b (for instance, because
2 Symmetry and irreﬂexivity of R↔are not assumed in the original paper [18], but as
pointed out by [30,31], both assumptions can be made without loss of generality.

Arguing with Qualitative Uncertainty in DL-PA
195
they have contradictory conclusions), but the proponent still lacks information
about the opponent’s knowledge so as to know how he (the opponent) perceives
the relative strength of a and b, and hence the direction of the defeat. As for
C = (AC, RC), it is supposed to be the part of the framework that depends on
the actions of the proponent. More precisely, it can be interpreted as private,
communicable knowledge of the proponent, i.e., the arguments and attacks such
that (i) they are known to the proponent, (ii) they are unknown to the oppo-
nent (and the proponent knows this). Moreover, CAFs make a strong assumption
about control arguments: (iii) the proponent is completely sure about the eﬀects
of communicating each of them.
Example 1. With the above interpretation in mind, consider the CAF CAF0 =
(F0, C0, U0) where AF
0 = {a}, RF
0 = {(f, e)}, AU
0 = {c, e, f}, RU = {(f, c)},
R↔= {(c, e), (e, c)}, AC
0 = {b, d} and RC
0 = {(b, a), (d, a), (c, b), (e, d)}.
We represent CAF0 graphically as follows:
a
b
c
d
e
f
where solid circles stand for ﬁxed arguments, normal arrows stand for ﬁxed
attacks, dashed circles stand for uncertain arguments, dashed arrows stand for
uncertain attacks, dashed double arrows stand for symmetric attacks, squares
stand for control arguments, and double arrows for control attacks.
A fundamental notion for reasoning about CAFs (and the rest of formalisms
for qualitative uncertainty that will be studied here) is that of completion.
A completion of CAF = (F, C, U) is any AF (A∗, R∗) such that:
– (AF ∪AC) ⊆A∗⊆(AF ∪AC ∪A?);
– (RF ∪RC)|A∗⊆R∗⊆(RF ∪RC ∪R? ∪R↔)|A∗; and
– for every x, y: (x, y) ∈R↔and x, y ∈A∗implies (x, y) ∈R∗or (y, x) ∈R∗.
A completion can be seen as a provisional removal of uncertainty or, in epis-
temic terms, as a possible world (cf. [27,32]). This removal lets the proponent
reason under the assumption that the opponent’s AF is such-and-such. If we
identify standard AFs (A, R) with CAFs with empty uncertain and control parts
then (A, R) is the unique completion of itself.
The completions of CAF0 are depicted in Table 1.
A rich incomplete AF [29] is a pair rIAF = (F, U) where F and U are
exactly as in a CAF. A rich incomplete AF can be informally understood as a
CAF with empty AC and RC, i.e., where we abstract away from the dynamics.
We sometimes unravel F and U and represent rich incomplete AFs as tuples of
the form (AF , A?, RF , R?, R↔). The notion of completion is easily adapted to
rIAFs.

196
A. Herzig and A. Yuste-Ginel
Table 1. Completions of CAF0. The column [1, 2,..., 6] and the row [A, B, C] are just
included for numbering purposes. Empty cells do not represent the empty completion
(∅, ∅).
A
B
C
1
a
b
d
a
b
c
d
a
b
d
e
2
a
b
c
d
e
a
b
c
d
e
a
b
c
d
e
3
a
b
d
f
a
b
c
d
f
a
b
c
d
f
4
a
b
c
d
e
f
a
b
c
d
e
f
a
b
c
d
e
f
5
a
b
c
d
e
f
a
b
c
d
e
f
a
b
c
d
e
f
6
a
b
d
e
f

Arguing with Qualitative Uncertainty in DL-PA
197
Example 2. Let rIAF0 = (AF
0 , AU
0 , RF
0 , RU
0 , R↔
0 ) where AF
0 = {a, b, d}, AU
0 =
{c, e, f}, RF
0
= {(b, a), (d, a), (c, b), (e, d), (f, e)}, RU
0
= {(f, c)}, and R↔
0
=
{(c, e), (e, c)}. Note that rIAF0 has exactly the same set of completions as CAF0
(from Example 1), that is, all those depicted in Table 1. Actually rIAF0 can be
seen as the full development of CAF0, i.e., CAF0 where all the control arguments
have been used by the proponent.
We represent rIAF0 graphically as follows:
a
b
c
d
e
f
An incomplete AF [8] (IAF), is a rich IAF with empty R↔. We represent
IAFs as tuples of the form (A, A?, R, R?). There are some notable subclasses of
IAFs, well-studied in the literature, namely attack-incomplete AFs (att-IAFs,
for short), which are IAFs with empty A?; and argument-incomplete AFs
(arg-IAFs, for short), which are IAFs with empty R?. The notion of completion
is again straightforwardly relativised to IAFs.
Example 3. Let us consider IAF0 = (AF
0 , AU
0 , RF
0 , RU
0 ), where AF
0 = {a, b, d},
AU
0 = {c, e, f}, RF
0 = {(b, a), (d, a), (c, b), (e, d), (c, e), (e, c), (f, e)} and RU
0 =
{(f, c)}, graphically represented below. The set of completions of IAF0 is the one
depicted in Table 1 except for the cells B2, C2, B4, C4, B5 and C5 (as the
symmetric attack c ↔e is now ﬁxed).
a
b
c
d
e
f
Given a control AF, CAF, we note completions(CAF) its set of completions
(and we do the same for IAFs and rIAFs).
Classic reasoning tasks such as extension enumeration or argument accep-
tance have been generalized from AFs to both IAFs and rIAFs. As an example,
let us consider the following one:
stable-Necessary-Credulous-Acceptance (st-NCA)
Given: A rich IAF rIAF = (AF , A?, RF , R?, R↔) and an argument a ∈AF .
Question: Is it true that for every (A∗, R∗) ∈completions(rIAF)
there is an E ∈st(A∗, R∗) such that a ∈E?
We can replace st by any other semantics as well as switch quantiﬁers in the
deﬁnition above in order to obtain diﬀerent variants of the problem.

198
A. Herzig and A. Yuste-Ginel
Regarding CAFs, deﬁning relevant reasoning tasks gets slightly more com-
plicated, since we have to take into account their dynamic aspect (the control
part). In this context, a natural reasoning task is ﬁnding a control conﬁguration
(that is, a set of control arguments) such that a certain argument gets accepted
by the opponent after the latter learns about them. Just as before, acceptabil-
ity is then relativised to quantiﬁcation over completions and extensions. As an
example, let us consider:
stable-Necessary-Sceptical-Controllability (st-NSCon)
Given: A control argumentation framework
CAF = (F, C, U) and an argument a ∈AF .
Question: Is it true that there is a conﬁguration
CFG ⊆AC such that for every completion (A∗, R∗)
of CAFCFG and for every E ∈st(A∗, R∗), a ∈E?
Expressivity via Sets of Completions. Following [29], we can compare the mod-
elling power of each of the previous formalisms for arguing with uncertainty
(IAFs, rIAFs and possibly others) using the sets of completions that they can
represent. Let (att-, arg-)IAF (resp. RIAF, CAF) denote the class of all (att-
,arg-)IAFs (resp. rIAFs, CAFs), and let X and Y be metavariables denoting
arbitrary classes of the previous list. We say that X is at least as expressive
as Y (in symbols, X ⪰Y) if, for every Y ∈Y there is a X ∈X such that
completions(X) = completions(Y ). We use ≻to denote the strict counterpart of
⪰, we use ⪯to denote the inverse of ⪰, and we use ≡to abbreviate ⪰∩⪯. For
instance, in [29], it was proved that RIAF ≻IAF.
4
Incomplete AFs in DL-PA
Our ﬁrst aim is to capture incomplete AFs using DL-PA. More precisely, given an
incomplete argumentation framework IAF = (A, A?, R, R?), we want to design a
program makeCompIAF such that every valuation that is makeCompIAF-accessible
from the valuation vIAF associated to IAF represents a completion of IAF and,
vice versa, every completion of IAF is represented by at least one makeCompIAF-
successor of vIAF.
First of all, we associate to IAF its valuation
vIAF = v(AF ,RF )
= AWAF ∪ATTRF
= {awx | x ∈AF } ∪{rx,y | (x, y) ∈RF }.
Note that (AvIAF, RvIAF) is already a completion of IAF: it is the smallest one,
where only ﬁxed arguments and ﬁxed attacks between them are considered. What
we need to do in order to compute all the completions of IAF is varying the value
of propositional variables representing arguments in A? and attacks in R?. Let

Arguing with Qualitative Uncertainty in DL-PA
199
us ﬁrst deﬁne the DL-PA program that computes all possible combinations of
variables in a given set. Let P = {p1, ..., pn} be a subset of PrpU and deﬁne
vary(P) =

+p1 ∪−p1

; ...;

+pn ∪−pn

.
(Note that the order of the propositional variables does not matter.) With this
abbreviation at hand we are able to deﬁne the program to compute the comple-
tions we are after:
makeCompIAF = vary(AWA?); vary(ATTR?).
The next proposition shows that our original target is reached.
Proposition 1. Let IAF = (A, A?, R, R?), then
– If (vIAF, v) ∈||makeCompIAF||, then (Av, Rv) ∈completions(IAF).
– If (A∗, R∗) ∈completions(IAF), then (vIAF, v(A∗,R∗)) ∈||makeCompIAF||.
Proof. For the ﬁrst item, suppose (vIAF, v) ∈||makeCompIAF||. We recall that
||vary(P)|| = {(v ′, v ′′) | (v ′ \ v ′′) ∪(v ′′ \ v ′) ⊆P} for any set of atoms P [21].3
Hence, by the semantics of the sequential composition operator ;, we have that
(vIAF, v) ∈||makeCompIAF|| amounts to saying that the set of variables whose
truth values diﬀers from vIAF to v, formally the set (v \vIAF)∪(vIAF \v), must be
a subset of AWA? ∪ATTR?. But, since all variables from AWA? ∪ATTR? are false
in vIAF by deﬁnition, we have that v = vIAF ∪P for some P ⊆AWA? ∪ATTR?.
From this statement, and applying the deﬁnition of (Av, Rv) and the one of
completion, we obtain that (Av, Rv) ∈completions(IAF).
For the second item, suppose that (A∗, R∗) ∈completions(IAF), which
amounts to AF ⊆A∗⊆AF ∪A? and RF
|A∗⊆R∗⊆(RF ∪R?)|A∗. Now, remem-
ber that v(A∗,R∗) = AWA∗∪ATTR∗. From the two previous statements and the
deﬁnition of vIAF, we can deduce that the set of variables whose truth values
diﬀer from v to v(A∗,R∗) must be a subset of AWA? ∪ATTR?, which, as argued
before, amounts to saying that (vIAF, v(A∗,R∗)) ∈||makeCompIAF||.
Using this result together with the general technique to compute extensions
provided in [20,22], we can reduce reasoning problems in IAFs to model-checking
problems in DL-PA. Note that we need an encoding of argumentation semantics
that takes into account our “awareness” variables. As shown in [22], the following
propositional schema characterizes the stable semantics in awareness-relativised
AFs:
Stable =

x∈U

(inx →awx) ∧

awx →(inx ↔¬

y∈U
(iny ∧ry,x ∧awx ∧awy)

.
3 Note that vary is noted ﬂipSome in [21].

200
A. Herzig and A. Yuste-Ginel
The authors show that v is a model of Stable if and only if {x ∈U | inx ∈v} is
a stable extension of (Av, Rv). Note that Stable is actually parametrised by U,
but we drop it to simplify notation.
The program makeExtst = vary(INU); Stable? nondeterministically builds all
possible stable extensions by ﬁrst varying the values of the ‘in’ variables and
then checking that a stable valuation has been obtained [20,22]. Our general
technique is then illustrated by the following result.
Proposition 2. Let IAF = (A, A?, R, R?), and a ∈AF , then the answer to st-
NCA with input IAF and a is yes iﬀvIAF |= [makeCompIAF]⟨makeExtst⟩ina.
Proof (Sketched). The result follows from the deﬁnition of the reasoning task, the
correctness of makeExtst ([20,21]), Proposition 1, and the semantics of DL-PA.
5
Rich Incomplete AFs in DL-PA
Things get slightly more complicated when computing the completions of a rich
IAF in DL-PA, since the program vary does not suﬃce to compute the symmetric
attacks of R↔. We can, however, ﬁnd a speciﬁc program for this purpose.
First of all, given rIAF = (AF , A?, RF , R?, R↔), we associate to rIAF its
valuation
vrIAF = v(AF ,RF )
= AWAF ∪ATTRF
= {awx | x ∈AF } ∪{rx,y | (x, y) ∈RF }.
Note that, contrarily to what happened with IAFs, (AvrIAF, RvrIAF) is not always
a completion of rIAF (this is false as soon as R↔∩(AF × AF ) is not empty).
Let us now deﬁne the program that will be used to compute the presence of
elements of R↔in each completion. Let ATTR = {rx1,y1, ..., rxn,yn} be a set of
attack variables, and deﬁne
dis(ATTR) = (+rx1,y1 ∪+ry1,x1) ; . . . ; (+rxn,yn ∪+ryn,xn) .
Intuitively, dis makes true at least one of the pairs from the set {(xi, yi), (yi, xi)},
for each 1 ≤i ≤n. Moreover, when applied to symmetric relations, dis makes
true either (xi, yi), or (yi, xi), or both. We have now the tools to deﬁne the
program makeComp in its version for rIAFs. Let rIAF = (AF , A?, RF , R?, R↔),
and deﬁne
makeComprIAF = vary(AWA?); vary(ATTR?); dis(ATTR↔).
The following proposition shows that the above program is correct.
Proposition 3. Let rIAF = (AF , A?, RF , R?, R↔), then:
– If (vrIAF, v) ∈||makeComprIAF||, then (Av, Rv) ∈completions(rIAF).

Arguing with Qualitative Uncertainty in DL-PA
201
– If (A∗, R∗) ∈completions(rIAF), then (vrIAF, v(A∗,R∗)) ∈||makeComprIAF||.
Proof (Sketched). The proof is analogous to the one of Proposition 1, but tak-
ing into account the observation that, when applied to the symmetric relation
R↔= {(x1, y1), (y1, x1), ..., (xn, yn), (yn, xn)}, every execution of dis(ATTR↔)
makes true either rxi,yi, or ryi,xi or both, for every 1 ≤i ≤n.
Again, acceptance problems can be reduced to model-checking problems. As
an example, consider the following reduction, where st-PSA stands for stable-
Possible-Sceptical Acceptance.
Proposition 4. Let rIAF = (AF , A?, RF , R?, R↔), and let a ∈AF , then the
answer to st-PSA with input rIAF and a is yes iﬀ
vrIAF |= ⟨makeComprIAF⟩[makeExtst]ina.
Proof (Sketched). The result follows from the deﬁnition of the reasoning prob-
lem, the correctness of makeExtst [20,21], Proposition 3, and the semantics of
DL-PA.
6
Control AFs in DL-PA
We now move to control argumentation frameworks. Regarding uncertainty, con-
trol argumentation frameworks are essentially rich incomplete argumentation
frameworks; however, the delicate part is their dynamic component, i.e., the
control part.
First, given a CAF CAF = (F, C, U), we deﬁne its associated valuation as
vCAF = v(AF ,RF ∪RC)
= AWAF ∪ATTRF ∪ATTRC
= {awx | x ∈AF } ∪{rx,y | (x, y) ∈RF } ∪{rx,y | (x, y) ∈RC}.
Note that vCAF contains all attack variables corresponding to control attacks,
but none of them appear in (AvCAF, RvCAF), since none of the control arguments
has been communicated yet. This highlights the fact that in the epistemic inter-
pretation of CAFs, the proponent knows how the opponent will perceive the
attack relations regarding all communicable arguments (a point that might be
subject to criticism).
To capture the dynamic component of CAF we deﬁne the following program:
controlCAF = vary(AWAC).
Intuitively, controlCAF nondeterministically chooses some of the possible control
conﬁgurations of CAF (i.e., some subset of control arguments).
What about completions? As mentioned, if we restrict to uncertainty, CAFs
are essentially rIAFs [29]. Hence, once we have computed some control conﬁgu-
ration, it suﬃces to use the same program as for rIAFs:
makeCompCAF = vary(AWA?); vary(ATTR?); dis(ATTR↔).
We again state a correctness result:

202
A. Herzig and A. Yuste-Ginel
Proposition 5. Let CAF = (F, C, U).
– If (vCAF, v) ∈||controlCAF; makeCompCAF||, then there is a control conﬁgura-
tion CFG ⊆AC and a completion (A∗, R∗) of CAFCFG such that (Av, Rv) =
(A∗, R∗).
– For every control conﬁguration CFG
⊆
AC
and every (A∗, R∗)
∈
completions(CAFCFG) there is a valuation v ∈2PrpU such that (vCAF, v) ∈
||controlCAF; makeCompCAF|| and (Av, Rv) = (A∗, R∗).
Proof (Sketched). The proof is analogous to those of Propositions 1 and 3. The
essential diﬀerence lies in the fact that the previous execution of controlCAF is
needed to nondeterministically choose a control conﬁguration of CAF. Also, note
that ATTRC ⊆vCAF is essential for obtaining the needed control attacks in the
corresponding completion.
We can then combine the previous programs with makeExt in order to reduce
controllability problems to model-checking problems in DL-PA. As an example,
consider the following.
Proposition 6. Let CAF = (F, C, U) and a ∈AF . The answer to st-NSCon
with input CAF and a is yes if and only if
vCAF |= ⟨controlCAF⟩[makeCompCAF; makeExtst]ina.
Proof (Sketched). The result follows from the deﬁnition of the reasoning task,
the correctness of makeExtst [20,21], Proposition 5, and the semantics of DL-PA.
7
Constrained Incomplete AFs and Their Encoding
in DL-PA
We now move to study a very general class of structures for modelling quali-
tative uncertainty about AFs: constrained incomplete AFs. To the best of our
knowledge, these structures have not been studied before in the literature. They
are however inspired by the notion of constrained AF [17], and by the encoding
of other structures in DL-PA as undertaken in this paper.
Let U be given, a constrained incomplete AF (cIAF) is a pair cIAF =
(U, ϕ) where ϕ is a Boolean formula built over the set of propositional variables
AWU ∪ATTU×U. The set of completions of a given cIAF is deﬁned as
completions(U, ϕ) = {(Av, Rv) | v ⊆PrpU and v |= ϕ}.
We note c-IAF the class of all constrained incomplete argumentations frame-
works.
Example 4. Let us consider cIAF1 = (U, ϕ) with U = {a, b} and ϕ = (awa ∧
awb) ∧(ra,b ∨rb,a) ∧¬(ra,b ∧rb,a) ∧¬ra,a ∧¬rb,b. The completions of cIAF1 are:
a •
•b
a •
•b

Arguing with Qualitative Uncertainty in DL-PA
203
Proposition 7. cIAFs are strictly more expressive than IAFs and rIAFs. In
other words, for every (r)IAF, there is a cIAF with the same set of completions;
but there is a cIAF such that no (r)IAF has the same set of completions.
Proof. We only have to prove c-IAF ≻RIAF (as c-IAF ≻IAF follows from
RIAF ≻IAF [29] and the transitivity of ≻).
For the ﬁrst part of the statement (for every rIAF there is a cIAF with
the same set of completions), let rIAF be a rIAF with completions(rIAF) =
{(A∗
1, R∗
1), ..., (A∗
n, R∗
n)}. Note that, for any AF (A, R) deﬁned over U, we can
write its theory (see e.g. [22]), that is, the formula
Th(A, R) =

x∈A
awx ∧

x∈U\A
¬awx ∧

(x,y)∈R
rx,y ∧

(x,y)∈U2\R
¬rx,y.
It is then easy to show that for any valuation v ⊆PrpU, we have that v |=
Th(A, R) iﬀ(Av, Rv) = (A, R). Now, letting ρ = 
1≤i≤n Th(A∗
i , R∗
i ), we have
that
completions(U, ρ) = completions(rIAF).
In order to prove the second half of the proposition, it suﬃces to use the cIAF of
Example 4 (called cIAF0). Reasoning towards contradiction, suppose that there
is a rIAF rIAF = (AF , A?, RF , R?, R↔) with the same set of completions as
cIAF0. Then (a, b) ∈RF ∪R? ∪R↔(since (a, b) appears in a completion of rIAF).
We show that the last statement is absurd. If (a, b) ∈RF , then (a, b) should
appear in all completions of rIAF where a and b are present, but this is not true.
If (a, b) ∈R?, we reason by cases on (b, a) ∈RF ∪R? ∪R↔: the ﬁrst one is
impossible, since (b, a) would be in every completion where a and b appear, and
that is not the case; the second one is absurd because we would have an extension
with neither (a, b) nor (b, a), and this is not the case; the third one is impossible
because it would imply (a, b) ∈R↔, but we have assumed that (a, b) ∈R?, and
we know that R? ∩R↔= ∅by deﬁnition. Finally, suppose that (a, b) ∈R↔,
which implies (b, a) ∈R↔(by symmetry of R↔), which is impossible because
we would have a completion with both (a, b) and (b, a), but this is not the case.
Note that in the ﬁrst part of the proof we have used an argument that works
for any set of directed graphs with domain U (and not only for the completions
of a given rIAF), hence we can state that:
Corollary 1. For any set S of directed graphs with domain U, there is a cIAF
cIAF such that S = completions(cIAF).
In words, cIAFs are a maximally expressive formalism for representing qual-
itative uncertainty about AFs. Figure 1 depicts the relative expressivity of the
diﬀerent formalisms adding qualitative uncertainty to abstract argumentation
that we have discussed in this paper.

204
A. Herzig and A. Yuste-Ginel
AF
att-IAF
arg-IAF
IAF
RIAF
CAF
c-IAF
Fig. 1. Relative expressivity of formalisms for qualitative uncertainty in formal argu-
mentation. An arrow from X to Y means that X ⪯Y. Transitive and reﬂexive arrows
are omitted.
The Need of cIAFs. Besides being mathematically interesting, one may wonder
why one should use cIAFs. Our main motivation is that, while the computational
complexity of reasoning tasks associated to the previously introduced formalisms
((r)IAFs and subclasses) is well-known and relatively low, their modelling power
is rather limited. Consider, for instance, a proponent reasoning about the view of
her opponent on a very simple debate, containing only two arguments {a, b}. Sup-
pose that a is an argument about public health policies stated by the right-wing
presidential candidate. Similarly, b is an argument stated by the left-wing candi-
date. Imagine that a and b have contradictory conclusions, so they are mutually
incompatible. Let us informally understand R as a defeat relation here, that is,
a relation based on logical incompatibility plus some kind of epistemic-based
assessment of the involved arguments (for instance, regarding the reliability of
their premisses), as it is usually done in structured argumentation. Now, suppose
our proponent knows that her opponent is polarized, in the sense that he (the
opponent) is already inclined towards one side of the political spectrum, but she
does not know which one; then the possible AFs that the agent attributes to
her opponent are exactly the completions of cIAF1 (see Example 4). As we have
shown in the proof of Proposition 7, there is no rIAF (and therefore no IAF)
with that exact set of completions as cIAF1.
Let us now show how cIAFs can be captured using DL-PA. Let cIAF = (U, ϕ),
and deﬁne its associated valuation simply as the empty set, that is, vcIAF = ∅.
(Actually any valuation over PrpU will do the job.) The program that generates
all completions of cIAF is deﬁned as
makeCompcIAF = vary(AWU); vary(ATTU×U); ϕ?.
Proposition 8. Let cIAF = (U, ϕ), then:
– If (vcIAF, v) ∈||makeCompcIAF||, then (Av, Rv) ∈completions(cIAF).
– If (A∗, R∗) ∈completions(cIAF), then (vcIAF, v(A∗,R∗)) ∈||makeCompcIAF||.
Proof (Sketched). Note that the interpretation of vary(AWU); vary(ATTU×U),
when restricted to 2PrpU\INU , is actually the total relation 2PrpU\INU × 2PrpU\INU .
Hence from vcIAF = ∅we have an execution of vary(AWU); vary(ATTU×U) that
goes to any valuation in 2PrpU\INU . Then, the execution of ϕ? ﬁlters those valu-
ations of 2PrpU\INU that satisfy the constraint of cIAF, i.e. the set of valuations

Arguing with Qualitative Uncertainty in DL-PA
205
of 2PrpU\INU representing the set of completions of cIAF. As an illustration of the
proof, consider Fig. 2.
a •
•b
v1
a •
•b
v2
∅
Fig. 2. Completions of cIAF1 seen as valuations over Prp{a,b}. Dashed double arrows
represent the interpretation of makeCompcIAF (the other valuations over Prp{a,b} are
omitted).
Reasoning problems for IAFs can be easily adapted to cIAFs: we just have
to ensure that the argument about which we formulate the query belongs to all
completions. As an example, consider:
stable-Necessary-Credulous-Acceptance (st-NCA)
Given: A constrained IAF cIAF = (U, ϕ)
and an argument a ∈U such that |= ϕ →awa.
Question: Is it true that for every
(A∗, R∗) ∈completions(cIAF)
there is an E ∈st(A∗, R∗) such that a ∈E?
Note that requiring |= ϕ →awa amounts to requiring a ∈A for all (A, R) ∈
completions(U, ϕ). Once again, we can reduce acceptability problems in cIAFs
to DL-PA model-checking problems. As an example, we have the following:
Proposition 9. Let cIAF = (U, ϕ) and let a ∈U such that |= ϕ →awa, then
the answer to st-PSA with input cIAF and a is yes if and only if
vcIAF |= ⟨makeCompcIAF⟩[makeExtst]ina.
Proof (Sketched). The result follows from from the deﬁnition of the reasoning
task, the correctness of makeExtst ([20,21]), Proposition 8, and the semantics of
DL-PA.
8
Discussion and Future Work
Getting Closer to the Model-Checking Approach. Our encoding of formalisms for
arguing with qualitative uncertainty can be qualiﬁed as hybrid, since it combines

206
A. Herzig and A. Yuste-Ginel
some previous semantic reasoning with reasoning inside DL-PA. For instance,
in order to compute the completions of an IAF, one ﬁrst needs to ﬁnd its asso-
ciated valuation (reasoning outside the logic, using semantic objects), then has
to write down the makeComp program, and ﬁnally reasoning in DL-PA to ﬁnd
the makeComp-successors of the associated valuation. We followed this hybrid
method because we found intuitive the identiﬁcation of directed graphs with
propositional valuations over PrpU. However, we can adopt results from [20–22]
to get a more homogeneous method here. For instance, let IAF = (A, A?, R, R?)
be an IAF, instead of computing its associated valuation, we can write down a
propositional formula that characterizes its ﬁxed elements (similarly to what is
done in [20] for standard AFs):
Th(IAF) =

x∈AF
awx ∧

x∈U\AF
¬awx ∧

(x,y)∈RF
rx,y

(x,y)∈U2\RF
¬rx,y.
If we combine this formula with the makeComp program and the inverse operator
we obtain a formula whose models completely characterize the set of completions
of IAF:
completions(IAF) = {(Av, Rv) | v ∈||⟨

Th(IAF)?; makeCompIAF⌣⟩⊤||}.
Comparison to QBF Encodings. As mentioned before, all we have done in DL-PA
can as well be done in equally expressive logical frameworks like propositional
logic or quantiﬁed Boolean formulas (QBF). The advantage over the former is
that (1) some semantics can be expressed more compactly in DL-PA, and (2) the
reasoning problems can be expressed directly as DL-PA programs. The advan-
tage over QBFs is that the DL-PA encoding of reasoning problems by means of
programs is more natural than the rather complex QBF encodings that one can
ﬁnd in the literature. Actually, most of the works on arguing with qualitative
uncertainty use QBF encodings and algorithms for determining the complexity
of associated reasoning tasks (see e.g. [8] or [31]). All advantages already pointed
out by [21] of using DL-PA instead of QBF for encoding argumentative semantics
are preserved by our encodings. In particular, “extension construction programs
such as makeExtσ capture things in a more general, ﬂexible and natural way than
a QBF encoding”. This enables a straightforward extension of our results to all
semantics that have been encoded in DL-PA (admissible, complete, grounded,
preferred) and potentially others.
Dynamics and Uncertainty. The dynamic nature of our approach also paves the
way for a systematic study of the diﬀerent dynamic extensions of IAFs (e.g. in
order to enforce arguments, as done in [7]) and the rest of formalisms studied
here, which we leave for future work.
References
1. Amgoud, L., Vesic, S.: A new approach for preference-based argumentation frame-
works. Ann. Math. Artif. Intell. 63(2), 149–183 (2011). https://doi.org/10.1007/
s10472-011-9271-9

Arguing with Qualitative Uncertainty in DL-PA
207
2. Atkinson, K., et al.: Towards artiﬁcial argumentation. AI Mag. 38(3), 25–36 (2017).
https://doi.org/10.1609/aimag.v38i3.2704
3. Balbiani, P., Herzig, A., Schwarzentruber, F., Troquard, N.: DL-PA and DCL-
PC: model checking and satisﬁability problem are indeed in PSPACE. CoRR
abs/1411.7825 (2014). http://arxiv.org/abs/1411.7825
4. Balbiani, P., Herzig, A., Troquard, N.: Dynamic logic of propositional assignments:
a well-behaved variant of PDL. In: 2013 28th Annual ACM/IEEE Symposium on
Logic in Computer Science, pp. 143–152. IEEE (2013). https://doi.org/10.1109/
LICS.2013.20
5. Baroni, P., Caminada, M., Giacomin, M.: Abstract argumentation frameworks and
their semantics. In: Handbook of Formal Argumentation, pp. 159–236. College
Publications (2018)
6. Baroni, P., Cerutti, F., Giacomin, M., Guida, G.: Encompassing attacks to
attacks in abstract argumentation frameworks. In: Sossai, C., Chemello, G. (eds.)
ECSQARU 2009. LNCS (LNAI), vol. 5590, pp. 83–94. Springer, Heidelberg (2009).
https://doi.org/10.1007/978-3-642-02906-6 9
7. Baumann, R., Brewka, G.: Expanding argumentation frameworks: enforcing and
monotonicity results. In: Baroni, P., Cerutti, F., Giacomin, M., Simari, G.R. (eds.)
Proceedings of the COMMA 2010, vol. 216, pp. 75–86. IOS Press (2010). https://
doi.org/10.3233/978-1-60750-619-5-75
8. Baumeister, D., J¨arvisalo, M., Neugebauer, D., Niskanen, A., Rothe, J.: Accep-
tance in incomplete argumentation frameworks. Artif. Intell. 295, 103470 (2021).
https://doi.org/10.1016/j.artint.2021.103470
9. Baumeister, D., Neugebauer, D., Rothe, J.: Credulous and skeptical acceptance
in incomplete argumentation frameworks. In: Proceedings of the COMMA 2018.
Frontiers in AI and Applications, vol. 305, pp. 181–192. IOS Press (2018). https://
doi.org/10.3233/978-1-61499-906-5-181
10. Baumeister, D., Neugebauer, D., Rothe, J., Schadrack, H.: Complexity of veriﬁ-
cation in incomplete argumentation frameworks. In: McIlraith, S.A., Weinberger,
K.Q. (eds.) Proceedings of the Thirty-Second AAAI Conference on Artiﬁcial Intel-
ligence, (AAAI 2018), pp. 1753–1760. AAAI Press (2018)
11. Baumeister, D., Neugebauer, D., Rothe, J., Schadrack, H.: Veriﬁcation in incom-
plete argumentation frameworks. Artif. Intell. 264, 1–26 (2018). https://doi.org/
10.1016/j.artint.2018.08.001
12. Bench-Capon, T.J., Dunne, P.E.: Argumentation in artiﬁcial intelligence. Artif.
Intell. 171(10–15), 619–641 (2007). https://doi.org/10.1016/j.artint.2007.05.001
13. Besnard, P., Cayrol, C., Lagasquie-Schiex, M.C.: Logical theories and abstract
argumentation: a survey of existing works. Argument Comput. 11(1–2), 41–102
(2020). https://doi.org/10.3233/AAC-190476
14. Besnard, P., et al.: Introduction to structured argumentation. Argument Comput.
5(1), 1–4 (2014). https://doi.org/10.1080/19462166.2013.869764
15. Caminada, M.: Rationality postulates: applying argumentation theory for non-
monotonic reasoning. J. Appl. Log. 4(8), 2707–2734 (2017)
16. Cayrol, C., Lagasquie-Schiex, M.C.: On the acceptability of arguments in bipolar
argumentation frameworks. In: Godo, L. (ed.) ECSQARU 2005. LNCS (LNAI),
vol. 3571, pp. 378–389. Springer, Heidelberg (2005). https://doi.org/10.1007/
11518655 33
17. Coste-Marquis, S., Devred, C., Marquis, P.: Constrained argumentation frame-
works. In: Proceedings of the Tenth International Conference on Principles of
Knowledge Representation and Reasoning, pp. 112–122. AAAI Press (2006)

208
A. Herzig and A. Yuste-Ginel
18. Dimopoulos, Y., Mailly, J., Moraitis, P.: Control argumentation frameworks. In:
McIlraith, S.A., Weinberger, K.Q. (eds.) Proceedings of the Thirty-Second AAAI
Conference on Artiﬁcial Intelligence, (AAAI 2018), The 30th innovative Applica-
tions of Artiﬁcial Intelligence (IAAI 2018), and the 8th AAAI Symposium on Edu-
cational Advances in Artiﬁcial Intelligence (EAAI 2018), New Orleans, Louisiana,
USA, 2–7 February 2018, pp. 4678–4685. AAAI Press (2018). https://www.aaai.
org/ocs/index.php/AAAI/AAAI18/paper/view/16639
19. Dimopoulos, Y., Mailly, J.G., Moraitis, P.: Argumentation-based negotiation with
incomplete opponent proﬁles. In: 13`emes Journ´ees d’Intelligence Artiﬁcielle Fon-
damentale (JIAF 2019), pp. 91–100 (2019)
20. Doutre, S., Herzig, A., Perrussel, L.: A dynamic logic framework for abstract argu-
mentation. In: Baral, C., De Giacomo, G., Eiter, T. (eds.) Fourteenth International
Conference on the Principles of Knowledge Representation and Reasoning. AAAI
Press (2014)
21. Doutre, S., Herzig, A., Perrussel, L.: Abstract argumentation in dynamic logic:
representation, reasoning and change. In: Liao, B., ˚Agotnes, T., Wang, Y.N. (eds.)
CLAR 2018. LASLL, pp. 153–185. Springer, Singapore (2019). https://doi.org/10.
1007/978-981-13-7791-4 8
22. Doutre, S., Maﬀre, F., McBurney, P.: A dynamic logic framework for abstract
argumentation: adding and removing arguments. In: Benferhat, S., Tabia, K., Ali,
M. (eds.) IEA/AIE 2017. LNCS (LNAI), vol. 10351, pp. 295–305. Springer, Cham
(2017). https://doi.org/10.1007/978-3-319-60045-1 32
23. Dung, P.M.: On the acceptability of arguments and its fundamental role in non-
monotonic reasoning, logic programming and n-person games. Artif. Intell. 77(2),
321–357 (1995). https://doi.org/10.1016/0004-3702(94)00041-X
24. Fazzinga, B., Flesca, S., Furfaro, F.: Revisiting the notion of extension over incom-
plete abstract argumentation frameworks. In: Proceedings of IJCAI 2020, pp. 1712–
1718. IJCAI Organization, July 2020. https://doi.org/10.24963/ijcai.2020/237
25. Grossi, D.: On the logic of argumentation theory. In: Proceedings of the 9th Inter-
national Conference on Autonomous Agents and Multiagent Systems, pp. 409–416.
IFAMA (2010)
26. Harel, D., Kozen, D., Tiuryn, J.: Dynamic Logic. MIT Press, Cambridge (2000)
27. Herzig, A., Yuste-Ginel, A.: On the epistemic logic of incomplete argumentation
frameworks. In: Proceedings of International Conference on Principles of Knowl-
edge Representation and Reasoning. AAAI Press (2021)
28. Li, H., Oren, N., Norman, T.J.: Probabilistic argumentation frameworks. In: Mod-
gil, S., Oren, N., Toni, F. (eds.) TAFA 2011. LNCS (LNAI), vol. 7132, pp. 1–16.
Springer, Heidelberg (2012). https://doi.org/10.1007/978-3-642-29184-5 1
29. Mailly, J.G.: A note on rich incomplete argumentation frameworks. arXiv preprint
arXiv:2009.04869 (2020)
30. Niskanen, A.: Computational approaches to dynamics and uncertainty in abstract
argumentation. Ph.D. thesis, Helsingin yliopisto (2020)
31. Niskanen, A., Neugebauer, D., J¨arvisalo, M., et al.: Controllability of control argu-
mentation frameworks. In: Proceedings of the Twenty-Ninth International Joint
Conference on Artiﬁcial Intelligence (IJCAI 2020). IJCAI Organization (2021).
https://doi.org/10.24963/ijcai.2020/257
32. Proietti, C., Yuste-Ginel, A.: Dynamic epistemic logics for abstract argumentation.
Synthese 1–60 (2021). https://doi.org/10.1007/s11229-021-03178-5

Explanations of Non-monotonic Inference
in Admissibility-Based Abstract
Argumentation
Timotheus Kampik1(B) and Kristijonas ˇCyras2
1 Ume˚a University, Ume˚a, Sweden
tkampik@cs.umu.se
2 Ericsson Research, Stockholm, Sweden
kristijonas.cyras@ericsson.com
Abstract. In this paper, we introduce a formal framework for explaining
change of inference in abstract argumentation, in particular in the con-
text of iteratively drawing inferences from a sequence of normal expan-
sions, with a focus on admissible set-based semantics. We then conduct a
formal analysis, showing that given an initial argumentation framework
and an extension that has been inferred from it, we can guarantee the
existence of explanation arguments for the violation of monotony when
inferring an extension from a normal expansion of the initial argumen-
tation framework.
Keywords: Formal argumentation · Explainable artiﬁcial
intelligence · Non-monotonic reasoning
1
Introduction
Recently, formal argumentation approaches have received increasing attention
in the Artiﬁcial Intelligence (AI) community, partly because argumentation is
considered an enabler of explainable AI. However, claiming that argumentation-
based inference is in itself always explainable is naive; indeed, a range of
approaches that facilitate explainability in argumentation have been introduced
in recent years [11,26]. In this paper, we advance the research direction of
explainable argumentation by introducing a formal approach that explains the
violation of monotony in sequential argumentation, where we draw inferences
from an argumentation framework, then update it with new arguments and
attacks, draw new inferences and so on. In particular, we introduce the notion
of monotony violation explanations, i.e. sets of arguments that can explain the
violation of monotony, given an argumentation semantics that satisﬁes a newly
introduced relaxed monotony principle; we prove that three of Dung’s initial
admissible set-based semantics1 satisfy this principle. With this approach, our
1 The exception among the four semantics that Dung introduces in his seminal paper
is stable semantics, which is not universally deﬁned.
c
⃝Springer Nature Switzerland AG 2021
P. Baroni et al. (Eds.): CLAR 2021, LNAI 13040, pp. 209–223, 2021.
https://doi.org/10.1007/978-3-030-89391-0_12

210
T. Kampik and K. ˇCyras
work extends the body of research on explainable formal argumentation by
enabling the explanation of dynamic inference.
Let us provide an example that gives an intuition of the approach this paper
introduces.
Example 1. Assume we have a machine reasoner R that draws inferences from
a belief base (that may contain conﬂicting beliefs). The belief base expands with
time, and R draws new inferences after every expansion. Several IT systems sub-
scribe to R’s inferences and update their conﬁgurations based on the conclusions
that R serves. Updating a conﬁguration may be costly (imply down-time, man-
ual eﬀort, and the re-routing of workﬂow instances); hence, R needs to provide
an explanation every time monotony is violated, i.e. when a previous recommen-
dation about a system conﬁguration is withdrawn.
For instance, let us assume an abstract argumentation-based model, in which
R starts with the initial argumentation framework AF = (AR, AT) – where AR
is a set of statements (“arguments”) and AT ⊆AR × AR (“attacks”) – such
that AF = ({a}, {}); i.e., we have only one statement and no attacks. From this
framework, R infers2 {a}. Then, AF normally expands to AF ′ = (AR′, AT ′) =
({a, b, c, d}, {(a, b), (b, a)}): new arguments and attacks are added to AF, but the
attacks between arguments in AR remain unaﬀected3. From AF ′, R’s inference
function allows to infer either {a, c, d} or {b, c, d}. R opts to infer {a, c, d} because
it is monotonic w.r.t. the previous inference {a} and no explanations need to be
provided.
However, things get more tricky when AF ′ is normally expanded to AF ′′ =
(AR′′, AT ′′) = ({a, b, c, d, e, f, g}, {(a, b), (b, a), (e, c), (e, d), (e, f), (f, a), (f, e),
(f, g), (g, f)}). R’s inference function allows to infer either {a, e, g}, or {b, e, g},
or {b, c, d, f}. Now, R is forced to violate monotony in order to comply with
the constraints the inference function imposes. Intuitively, a reasonable decision
is to infer {b, c, d, f} because it minimizes the number of arguments (w.r.t car-
dinality) that are part of the previous conclusion but not part of the current
conclusion, i.e. |{a, c, d}\{b, c, d, f}| < |{a, c, d}\{a, e, g}| < |{a, c, d}\{b, e, g}|.
(While more nuanced variants of monotony-maximizing extension-selection are
introduced in [19], in this paper, we focus on cardinality-based monotony maxi-
mization with respect to a particular previous inference, which – self-evidently –
may but does not necessarily have to be the most recently drawn inference from
a temporal perspective.) To explain the violation of monotony, R may proceed
by highlighting monotony violation explanations, i.e. arguments that satisfy the
following constraints:
– The argument has been newly added.
– The argument attacks an argument that was in the previous conclusion.
2 In this example, the behavior of R’s inference function coincides with preferred
semantics [13], to be deﬁned later.
3 We focus on normal expansions because we consider it a reasonable assumption that
in an argumentation context, dynamic scenarios are modeled by adding arguments
to an argumentation framework without deleting arguments (instead, arguments can
be defeated) and without changing the attack relations between existing arguments.

Explanations of Non-monotonic Inference in Abstract Argumentation
211
– The argument is not attacked by any subset of arguments in the new con-
clusion that defends itself against all attackers and is not in conﬂict with the
previous conclusion.
Figure 1 depicts the example’s argumentation frameworks. The monotony vio-
lation explanations of the conclusion {b, c, d, f} as inferred from AF ′′ w.r.t. the
previous conclusion {a, c, d} that has been inferred from AF ′ are the arguments
comprising the set {e, f}. Intuitively, the fact that we infer f explains that we
can no longer infer a; in turn, e explains why we have to infer f, i.e. to still be
able to infer c and d.
a
(a) AF.
a
b
c
d
(b) AF .
a
b
c
d
e
f
g
(c) AF .
Fig. 1. Explaining the violation of monotony. Here and henceforth, the gray arguments
in each argumentation framework comprise the inferred extension; arguments with a
dashed border are rejected and arguments with a bold border are monotony violation
explanations.
The rest of this paper is organized as follows. Section 2 provides the necessary
theoretical preliminaries. Then, Sect. 3 introduces and analyzes the monotony
violation explainability framework. An implementation of the framework is
described in Sect. 4. Section 5 discusses the framework in the context of related
work, before Sect. 6 concludes the paper.
2
Preliminaries
The central model that this paper makes use of is the notion of an abstract
argumentation framework.
Deﬁnition 1 (Argumentation Framework [13]). An argumentation frame-
work AF is a tuple (AR, AT), such that AR is a set of elements (called argu-
ments) and AT ⊆AR × AR (called attacks).
We assume that the arguments in an argumentation framework are ﬁnite.
Given an argumentation framework AF = (AR, AT), we say for two arguments

212
T. Kampik and K. ˇCyras
a, b ∈AR that a attacks b if and only if (a, b) ∈AT. Given S ⊆AR, we say that
S attacks a if and only if there exists an argument c ∈S, such that c attacks a
and we say that a attacks S if and only if there exists an argument d ∈S, such
that a attacks d; we say that S attacks P ⊆AR if and only if there exists an
argument e ∈S, such that e attacks P. We say that S defends a if and only if
for every argument g ∈AR, such that g attacks a it holds true that S attacks g.
In abstract argumentation, admissible and conﬂict-free sets are important
notions.
Deﬁnition 2 Conﬂict-free and Admissible Sets [13]). Let AF = (AR, AT)
be an argumentation framework. A set S ⊆AR:
– is conﬂict-free (in AF) iﬀ∄a, b ∈S such that a attacks b;
– is admissible (in AF) iﬀS is conﬂict-free and ∀a ∈S, it holds true that S
defends a.
Let us now introduce some argumentation semantics, i.e. functions that infer
sets of extensions from an argumentation framework, where each extension is a
subset of the argumentation framework’s arguments.
Deﬁnition 3 (Dung’s Admissibility-based Semantics [13]). Let AF =
(AR, AT) be an argumentation framework. An admissible set S ⊆AR is a:
– stable extension of AF iﬀS attacks each argument that does not belong to S.
Stable semantics σst(AF) denotes all stable extensions of AF;
– complete extension of AF iﬀeach argument that is defended by S belongs to
S. Complete semantics σco(AF) denotes all complete extensions of AF;
– preferred extension of AF iﬀS is a maximal (w.r.t. set inclusion) admissible
subset of AR. Preferred semantics σpr(AF) denotes all preferred extensions
of AF;
– grounded extension of AF iﬀS is the minimal (w.r.t. set inclusion) com-
plete extension of AF. Grounded semantics σgr(AF) denotes all grounded
extensions of AF.
Given an argumentation semantics σ and an argumentation framework AF,
we call every E ∈σ(AF) a σ-extension of AF. Colloquially speaking, argu-
mentation framework expansions constrain how an argumentation framework is
manipulated: (simple) expansions specify that no arguments or attacks can be
removed, whereas normal expansions demand that in addition, no new attacks
can be added between existing arguments.
Deﬁnition 4 (Argumentation Framework Expansions [4]). Let AF =
(AR, AT) and AF ′ = (AR′, AT ′) be argumentation frameworks.
– AF ′ is an expansion of AF (denoted by AF ⪯AF ′) iﬀAR ⊆AR′ and
AT ⊆AT ′.
– AF ′ is a normal expansion of AF (denoted by AF ⪯N AF ′) iﬀAF ⪯AF ′
and (AR × AR) ∩(AT ′ \ AT) = ∅.

Explanations of Non-monotonic Inference in Abstract Argumentation
213
To facilitate the design and analysis of argumentation semantics, formal argu-
mentation principles have been introduced in the literature [25]. The universality
principle describes whether an argumentation semantics always returns at least
one extension [3].
Deﬁnition 5 (Universality). Let σ be an argumentation semantics. σ is uni-
versally deﬁned (σ satisﬁes universality) iﬀfor every argumentation framework
AF it holds true that |σ(AF)| ≥1.
A particularly relevant principle in the context of this work is weak cautious
monotony, which stipulates that normally expanding an argumentation frame-
work must allow us to infer any set of arguments contained in any of the original
argumentation framework’s extensions, given this extension is not attacked by
any of the newly added arguments.
Deﬁnition 6 (Weak Cautious Monotony [20]). Let σ be an argumentation
semantics. σ satisﬁes weak cautious monotony iﬀfor every two argumentation
frameworks AF = (AR, AT) and AF ′ = (AR′, AT ′), such that AF ⪯N AF ′, and
∀E ∈σ(AF), it holds true that if {(a, b) | (a, b) ∈AT ′, a ∈AR′ \AR, b ∈E} = ∅
then ∃E′ ∈σ(AF ′) such that E ⊆E′.
As a measure of how much an inference result violates monotony w.r.t. a previous
inference, we have deﬁned the notion of a degree of monotony in a recent work.
Deﬁnition 7 (Degree of Monotony [19]). Let E and E′ be two ﬁnite sets
of arguments. We deﬁne the degree of monotony of E′ w.r.t. E, denoted by
degmon(E′, E), as follows:
degmon(E′, E) =

1
if |E| = 0;
|E′∩E|
|E|
otherwise.
The degree of monotony allows us to guide extension selection when ﬁrst picking
an extension that a semantics infers from an argumentation framework and then
determining the extensions a semantics returns from an update of this argumen-
tation framework, such that these extensions maximize the degree of monotony
w.r.t. the previously inferred extension.
Deﬁnition 8 (Degree of Monotony-Maximizing Extensions [19]). Let
AF ′
=
(AR′, AT ′) be an argumentation framework. Let σ be a univer-
sally deﬁned argumentation semantics, and let E be a ﬁnite set of argu-
ments. We deﬁne the monotony-maximizing σ-extensions of AF ′ w.r.t. E,
denoted by Extsmon(E, AF ′, σ), as {E′|E′ ∈σ(AF ′), ∄E′′ ∈σ(AF ′), such that
degmon(E′, E) < degmon(E′′, E)}.
Let us illustrate the notion of degree of monotony-maximizing extensions by
introducing an example.

214
T. Kampik and K. ˇCyras
Example 2. Consider the argumentation frameworks AF = (AR, AT) = ({a, b,
c}, {(a, b), (b, a)}) and AF ′ = (AR′, AT ′) = ({a, b, c, d}, {(a, b), (b, a), (d, c)}), as
well as preferred semantics. Note that AF ⪯N AF ′. σpr(AF) = {{a, c}, {b, c}}
and σpr(AF ′) = {{a, d}, {b, d}}. Let us assume we ﬁrst select E = {a, c} from
σpr(AF) and then normally expand AF to AF ′. No matter which extension
we select from σpr(AF ′), we will violate monotony. However, intuitively, it does
not make sense to “switch” from an inference that entails a to an inference
that entails b. The degree of monotony-maximizing extensions support this intu-
ition: degmon({a, d}, E) = 1
2 and degmon({b, d}, E) = 0; Extsmon(E, AF ′, σpr) =
{{a, d}}.
3
Explainability Framework
Let us now provide a formal explainability framework for the intuition we have
outlined in the introduction. We call the central principle of our framework the
Relaxed Monotony Explainability (RME) principle, as it helps us explain the
relaxation (or: the constrained violation) of monotony.
Deﬁnition 9 (Relaxed Monotony Explainability (RME) Principle). Let
σ be an argumentation semantics. σ satisﬁes the Relaxed Monotony Explainabil-
ity (RME) principle iﬀfor every two argumentation frameworks AF = (AR, AT)
and AF ′ = (AR′, AT ′), such that AF ⪯N AF ′, the following statement holds
true:
∀E ∈σ(AF), ∃E′ ∈σ(AF ′), such that if E ̸⊆E′
Then ∃a ∈AR′ \ AR, such that
a attacks E and ∄S ⊆E′, such that
S is admissible in AF ′, S ∪E is conﬂict-free and S attacks a
Intuitively, the principle says that after a normal expansion, an originally inferred
extension must be entailed by some extension of the normal expansion unless
the original extension is attacked by some new arguments that in turn are not
attacked by a set of arguments in the new extension that defends itself and
is not in conﬂict with arguments in the original extension. We can show that
the satisfaction of the RME principle implies the satisfaction of weak cautious
monotony.
Proposition 1. Let σ be an argumentation semantics. If σ satisﬁes the RME
principle then σ satisﬁes weak cautious monotony.
Proof. 1. By deﬁnition of weak cautious monotony (Deﬁnition 6), σ satisﬁes
weak cautious monotony iﬀthe following statement holds true for every two
argumentation frameworks AF = (AR, AT) and AF ′ = (AR′, AT ′), such
that AF ⪯N AF ′:
∀E ∈σ(AF), if ∄E′ ∈σ(AF ′), such that E ⊆E′
Then ∃a ∈AR′ \ AR, such that
a attacks E

Explanations of Non-monotonic Inference in Abstract Argumentation
215
2. By deﬁnition of the RME principle (Deﬁnition 9) it follows that σ satisﬁes
the RME principle iﬀthe following statement holds true for every two argu-
mentation frameworks AF = (AR, AT) and AF ′ = (AR′, AT ′), such that
AF ⪯N AF ′:
∀E ∈σ(AF), if ∄E′ ∈σ(AF ′), such that E ⊆E′
Then ∃E′′ ∈σ(AF ′), ∃a ∈AR′ \ AR, such that
a attacks E and ∄S ⊆E′′, such that
S is admissible in AF ′, S ∪E is conﬂict-free and S attacks a
3. From 2. and 3. it follows that if σ satisﬁes the RME principle then σ satisﬁes
weak cautious monotony.
⊓⊔
Also, let us show that complete, preferred, and grounded semantics satisfy the
RME principle.
Proposition 2. Let σx be an argumentation semantics such that x ∈{co, pr,
gr}. σx satisﬁes the RME principle.
Proof. For every two argumentation frameworks AF = (AR, AT) and AF ′ =
(AR′, AT ′), such that AF ⪯N AF ′, for every E ∈σx(AF), we have two cases.
Case 1: If ∃E′ ∈σx(AF ′), such that E ⊆E′, it follows from the deﬁnition of
the RME principle (Deﬁnition 9) that the proposition holds true.
Case 2: If ∄E′ ∈σx(AF ′), such that E ⊆E′, we have two sub-cases.
Sub-case 2.1: x ∈{co, pr}. Because E ∈σx(AF) and ∄E′ ∈σx(AF ′),
such that E ⊆E′, by deﬁnition of σx (Deﬁnition 3), it holds true that E
attacks all arguments that attack E in AF and ∄S′ ⊆AR′, such that S′ is
conﬂict-free, E ⊆S′ and S′ attacks all arguments that attack S′ in AF ′.
It follows that ∃a ∈AR′\AR, such that a attacks E and a is not attacked
by any set S ⊆AR, such that E ⊆S and S is admissible in AF ′. Hence,
from the deﬁnition of an admissible set (Deﬁnition 2) and the deﬁnition
of σx (Deﬁnition 3), it follows that ∃a ∈AR′ \ AR, ∃E′′ ∈σx(AF ′), such
that a attacks E and a is not attacked by any set S ⊆E′′, such that S
is admissible in AF ′, and S ∪E is conﬂict-free; consequently, σx satisﬁes
the RME principle as stipulated in Deﬁnition 9 and the proposition holds
true for this sub-case.
Sub-case 2.2: x = gr. Note that σgr is universally uniquely deﬁned, i.e.
|σgr(AF ′)| = 1. Let E′ be the grounded extension of AF ′. Suppose for a
contradiction that E ̸⊆E′ and ∀a ∈AR′ \ AR, such that a attacks E it
holds true that a is attacked by some set S ⊆E′, such that S is admissible
in AF ′ and S∪E is conﬂict-free. It follows that because E is the grounded
extension of AF (and hence by deﬁnition the ⊆-minimal complete exten-
sion of AF), E is defended by the ⊆-minimal complete extension (and
hence the grounded extension) of AF ′, from which it follows that E ⊆E′.
This is a contradiction, which means that if E ̸⊆E′, then there must be

216
T. Kampik and K. ˇCyras
a ∈AR′\AR, such that a attacks E and a is not attacked by S ⊆E′, such
that S is admissible in AF ′ and S∪E is conﬂict-free. Hence, from the def-
inition of the RME principle (Deﬁnition 9), it follows that the proposition
holds true for x = gr.
⊓⊔
In contrast, we can show that stable semantics violates the RME principle.
Proposition 3. Stable semantics σst violates the RME principle.
Proof. We provide a proof by counter-example. Let us consider the argumenta-
tion frameworks AF = ({b}, {}) and AF ′ = ({a, b}, {(a, a)}). Let us observe that
AF ⪯N AF ′, σst(AF) = {{b}}, and σst(AF ′) = ∅. It follows that the following
statement does not hold true:
∀E ∈σ(AF), ∃E′ ∈σ(AF ′), such that if E ̸⊆E′
Then ∃a ∈AR′ \ AR, such that
a attacks E and and ∄S ⊆E′, such that
S is admissible in AF ′, S ∪E is conﬂict-free and S attacks a
By deﬁnition (Deﬁnition 9), this violates the RME principle, which proves the
proposition.
⊓⊔
It makes sense to combine the RME principle with the degree of monotony-
maximizing extension selection approach. Let us motivate this using an example.
Example 3. We go back to AF and AF ′ as introduced in Example 2 (also, see
Fig. 2) and consider preferred semantics. Again, we select {a, c} as our pre-
ferred extension of AF. No matter which extension we select from σpr(AF ′) =
{{a, d}, {b, d}}, we will violate monotony and {d} will be our explanation.
However, {d} can hardly explain why we no longer infer a; this change in
inference is certainly counter-intuitive, and can be prevented by determining
Extsmon(E, AF ′, σ) = {{a, d}} as a ﬁlter when selecting the extension we want
to infer from AF ′.
Let us introduce the RMEmax principle, a stricter variant of the RME principle
that ensures we can apply the approach outlined by Example 3.
Deﬁnition 10 (RME max Principle). Let σ be an argumentation semantics.
σ satisﬁes the RMEmax principle iﬀσ is universally deﬁned and for every two
argumentation frameworks AF = (AR, AT) and AF ′ = (AR′, AT ′), such that
AF ⪯N AF ′, the following statement holds true:
∀E ∈σ(AF), ∀E′ ∈Extsmon(E, AF ′, σ), if E ̸⊆E′
Then ∃a ∈AR′ \ AR, such that
a attacks E and ∄S ⊆E′, such that
S is admissible in AF ′, S ∪E is conﬂict-free and S attacks a

Explanations of Non-monotonic Inference in Abstract Argumentation
217
a
b
c
(a) AF.
a
b
c
d
(b) AF .
Fig. 2. {d} explains the violation of monotony when ﬁrst inferring {a, c} from AF and
then inferring {d, c} from AF ′. Intuitively, d better explains losing only c when the
selected extension is monotony maximizing (i.e. {a, d}) as opposed to losing a and c
when the selected extension is not monotony maximizing (i.e. {b, d}).
Let us highlight that the diﬀerence to the RME principle (Deﬁnition 9) is
that if monotony is violated, the then condition must hold true not merely for at
least one extension of the expanded argumentation framework, but for all maxi-
mally monotonic extensions. Note that by deﬁnition, if one maximally monotonic
extension violates monotony, then all maximally monotonic extensions violate
monotony.
Also note that – as a potential alternative to the RMEmax principle – it is
not possible to require an attack from a “new” argument to at least one (or
every) previously inferred argument that is no longer inferred after the update
as a necessary condition for the violation of monotony (at least not if we want to
select a newly inferred extension that is maximally monotonic w.r.t. the previous
inference result). We can illustrate this using another example.
Example 4. Consider AF
= (AR, AT) = ({a, b, c, d}, {(a, b), (b, a)}), AF ′ =
({a, b, c, d, e}, {(a, b), (b, a), (b, e), (e, c), (e, d)}) – see Fig. 3 – and preferred
semantics σpr. Note that AF ⪯N AF ′ and σpr(AF) = {{a, c, d}, {b, c, d}}.
Assume that before expanding AF to AF ′, we have selected {a, c, d} from
σpr(AF). Given σpr(AF ′) = {{a, e}, {b, c, d}}, let us select {b, c, d} as our con-
clusion, assuming that we want to maximize monotony, i.e. to reject as few of
the previously inferred arguments as possible. However, AR′\AR = {e} does not
attack {a, c, d} \ {b, c, d} = {a}; it merely dictates that to maintain a maximal
degree of monotony, our conclusion needs to entail b, which in turn attacks a; i.e.,
it is not necessary to require the “new” argument e to attack some previously,
but no longer inferred argument, namely a, to violate monotony.
Now, let us prove that the RME principle can indeed be combined with the
degree of monotony-maximizing extension selection approach, i.e. that complete,
preferred, and grounded semantics satisfy the RMEmax principle.
Proposition 4. Let σx
be an argumentation semantics, such that x
∈
{co, pr, gr}. σx satisﬁes the RMEmax principle.

218
T. Kampik and K. ˇCyras
a
b
c
d
(a) AF.
a
b
c
d
e
(b) AF .
Fig. 3. e, which is the only argument in AR′ \ AR, does not attack any argument
accepted in AF but rejected in AF ′ after selecting maximally monotonic extensions.
Proof. Let us note that σx is universally deﬁned [3]. Because for every argu-
mentation framework, there exists exactly one grounded extension, for x = gr
we conclude that |Extsmon(E, AF ′, σx)| = |σx(AF ′)| = 1 and the proof follows
from Proposition 2. For x ∈{co, pr}, we have two cases ∀E ∈σx(AF), ∀E′ ∈
Extsmon(E, AF ′, σx):
Case 1: E ⊆E′. By deﬁnition of RMEmax, the proposition holds true for this
case.
Case 2: E ̸⊆E′. By deﬁnition of Extsmon (Deﬁnition 8), ∀E′′ ∈σx(AF ′) it
holds that E ̸⊆E′′ (because otherwise, if E ⊆E′′, then degmon(E′′, E) = 1,
i.e. degmon(E′′, E) is maximal, and hence degmon(E′′, E) > degmon(E′, E)
(since E ̸⊆E′), which contradicts E′ ∈Extsmon(E, AF ′, σx)). Hence, from
Proposition 2 it follows that ∃E∗∈σx(AF ′) such that ∃a ∈AR′ \ AR, such
that a is not attacked by any set S ⊆E∗, such that S is admissible in AF ′
and S ∪E is conﬂict-free. Suppose for a contradiction that ∀a′ ∈AR′ \ AR,
such that a′ attacks E it holds true that a′ is attacked by some set S′ ⊆E∗,
such that S′ is admissible in AF ′ and S′ ∪E is conﬂict-free. It follows that
by deﬁnition of σx (Deﬁnition 3), S′ ∪E is an admissible set in AF ′ and
hence, (again by deﬁnition of σx), ∃E′′ ∈σx(AF ′), such that E ⊆E′′. This
contradicts that E ̸⊆E′′ as noted above, after the premise of the case (Case
2), and proves the proposition.
⊓⊔
Finally, let us deﬁne the notion of monotony violation explanations, i.e. argu-
ments whose attacks on arguments in a previously inferred extension explain –
in a normal expansion scenario – the violation of monotony, given a semantics
that satisﬁes the RMEmax principle.
Deﬁnition 11 (Monotony Violation Explanations). Let AF = (AR, AT)
and AF ′ = (AR′, AT ′) be argumentation frameworks, such that AF ⪯N AF ′
and let σ be an argumentation semantics that satisﬁes the RMEmax principle.
Let E ∈σ(AF) and E′ ∈σ(AF ′), such that E′ ∈Extsmon(E, AF ′, σ). The
monotony violation explanations of E′ w.r.t. E, σ, AF and AF ′ (denoted by
EXPSE,E′(AF, AF, σ) are {a|a ∈AR′ \ AR, a attacks E, a is not attacked by
any set S ⊆E′, such that S is admissible in AF ′, S ∪E is conﬂict-free}.
Let us go back to the examples and identify the monotony violation explanations.

Explanations of Non-monotonic Inference in Abstract Argumentation
219
Example 5. Consider the following examples:
– Consider the argumentation frameworks AF ′ and AF ′′ as depicted by Fig. 1,
preferred semantics and E = {a, c, d}, E ∈σpr(AF ′), E′ = {b, c, d, f}, E′ ∈
Extsmon(E, AF ′′, σpr). EXPSE,E′(AF ′, AF ′′, σpr) = {e, f}.
– Consider the argumentation frameworks AF and AF ′ as depicted by Fig. 2,
preferred semantics and E = {b, c}, E ∈σpr(AF), E′ = {b, d}, E′ ∈
Extsmon(E, AF ′, σpr). EXPSE,E′(AF, AF ′, σpr) = {d}.
– Consider the argumentation frameworks AF and AF ′ as depicted by Fig. 3,
preferred semantics and E = {a, c, d}, E ∈σpr(AF), E′ = {b, c, d}, E′ ∈
Extsmon(E, AF ′, σpr). EXPSE,E′(AF, AF ′, σpr) = {e}.
Finally, let us show that given complete, preferred or grounded semantics, for
every argumentation frameworks, one of its extensions, and any of its normal
expansions, for all extensions of the normal expansion that entail the originally
inferred extension (if there are any), the set of monotony violation explanations
of any of these new extensions w.r.t. the originally inferred extension is empty.
Proposition 5. Let σx
be an argumentation semantics such that x
∈
{co, pr, gr}. For every two argumentation frameworks AF = (AR, AT), AF ′ =
(AR′, AT ′) such that AF ⪯N AF ′, ∀E ∈σx(AF), E′ ∈σx(AF ′), such that
E ⊆E′, it holds true that EXPSE,E′(AF, AF ′, σx) = ∅.
Proof. Suppose for a contradiction that there exist two argumentation frame-
works AF = (AR, AT), AF ′ = (AR′, AT ′), such that AF ⪯N AF ′ and ∃E ∈
σx(AF), E′ ∈σx(AF ′), such that E ⊆E′ and EXPSE,E′(AF, AF ′, σx) ̸= ∅. By
deﬁnition of σx (Deﬁnition 3), it holds true that E′ is conﬂict-free and ∀b ∈E′,
E′ defends b (in AF ′). Because E ⊆E′, it follows that E′ is admissible in AF ′,
E′ ∪E is conﬂict-free and E′ attacks all arguments that attack E. Consequently,
it holds true that ∄a ∈AR′ \AR, such that a attacks E and a is not attacked by
any set S ⊆E′, such that S is admissible in AF ′ and S ∪E is conﬂict-free. From
the deﬁnition of monotony violation explanations (Deﬁnition 11), it follows that
EXPSE,E′(AF, AF ′, σx) = ∅, which contradicts EXPSE,E′(AF, AF ′, σx) ̸= ∅
as noted above and proves the proposition.
⊓⊔
4
Implementation
A Java implementation, including documentation (tutorial and application pro-
gramming interface documentation) of the explainability framework is available
at https://git.io/JOizF. The source code is openly available and the software
can be installed using Java dependency management and build tools such as
Maven4 and Gradle5. The implementation is part of the DiArg argumentation-
based dialog reasoner, which in turn is based on the abstract argumentation
libraries that are provided by the Tweety project [24]. As the implementation
4 https://maven.apache.org/.
5 https://gradle.org/.

220
T. Kampik and K. ˇCyras
can – to a large extent – rely on existing argumentation reasoners, we consider
an analysis of algorithmic implementation details (which depend on the imple-
mentation of these dependencies) out of the scope of this paper, yet potentially
relevant future work.
5
Discussion
Our explainability framework makes use of research results on argumentation
dynamics (see [12] for a survey), and in particular relies on notions that have
been introduced in the context of monotony analysis, i.e. on Baumann’s and
Brewka’s normal expansions [4]6 and our recently introduced weak cautious
monotony abstract argumentation principle [20]. By extending the weak cau-
tious monotony principle, we make the aforementioned results applicable to the
domain for explainable argumentation. From the perspective of explainable auto-
mated reasoning (see [10] for a survey), our research can be considered a novel
contribution at the intersection of principle-based [25] and explainable [26] argu-
mentation.
Argumentation-based explanations take many forms (see e.g. [11] for a recent
survey). A common approach to explaining argument acceptability – i.e. mem-
bership in extensions, or inference – in argumentation frameworks essentially
amounts to traversing the argument graph and can be formalized by extracting
graphs that satisfy some formal properties [8]. A popular example of explanations
as sub-graphs with desirable properties uses the concept of a dispute tree [14,15],
which commonly, but not exclusively, gives rise to conversational explanations,
often by means of a dialogue (game). Explanations in argumentation frameworks
can also come in the form of extensions themselves, e.g. [18,21], as well as by
means of the structure of the extensions’ arguments and relationships, where
applicable in structured argumentation frameworks.
Notions of argumentation-based explanations that are most related to our
work are approaches that modify the argument graph to make an argument
(non-)acceptable. Commonly, addition or removal of arguments and/or relations
that change the acceptability status of some pre-speciﬁed argument is a form of
explanation, e.g. [17,22,23]. Such changes typically presuppose some “universal”
space of argument graph modiﬁcation [6,22,28]. Instead, our Monotony Viola-
tion Explanations amount to sets of arguments that best explain the diﬀerences
between inferences in an abstract argumentation framework before and after a
change – a (normal) expansion – of the argument graph. Importantly, our expla-
nations consider the aspect of monotony maximization when selecting extensions
for inference after the change. This roughly pertains to indicating changes that
6 Let us highlight that we make use of normal expansions and not of the change
operations for abstract argumentation frameworks that were introduced by Cayrol et
al. [7] because the latter do not support the addition of arbitrarily many arguments as
part of a single operation, which makes Baumann’s and Brewka’s normal expansions
slightly more convenient in our case.

Explanations of Non-monotonic Inference in Abstract Argumentation
221
led to altered inferences and indirectly explain why some new inferences are pre-
ferred over others. Consequently, our approach can be seen as the reverse of the
kind of explanations that indicate what changes could be applied to an argu-
mentation framework to achieve desirable inferences, as in the works discussed
above.
Future work can extend the formal framework we provide in this paper, for
example as follows.
– Analyses of RME and RMEmax principle satisfaction for naive set-based [1]
and weak admissible set-based [5] argumentation semantics can be conducted.
Let us claim that some naive set-based semantics like stage [27], CF2 [1],
and stage2 [16] semantics do not satisfy the RME and RMEmax principles:
consider the argumentation frameworks AF = ({a, b, c}, {(a, b), (b, c), (c, a)}),
AF ′ = ({a, b, c, d}, {(a, b), (b, c), (c, a), (d, c)}) for a counter-example. Conse-
quently, new principles are required to explain the violation of monotony
for these semantics, and potentially, the identiﬁcation of additional relaxed
monotony explainability principles can apply a principle-based analysis
instead of proving the satisfaction with/violation of a principle semantics-
by-semantics.
– Analogous principles can potentially be introduced to other formal argumen-
tation approaches, such as gradual (bipolar) argumentation (see e.g. [2]). For
instance, one could deﬁne monotony with respect to the relative order of
argument ﬁnal strengths after either some expansion of the argument graph
or a change in the initial strengths of arguments. The degree of monotony
could then be based on some of the many similarity measures over ordered
sequences. Instead of looking at monotony-maximizing extensions then, one
could look at arguments that changed their relative ordering, and deﬁne and
extract explanatory arguments (or changes in their initial strengths) that
best explain those changes, potentially by also referring to other properties
studied in [2].
– Human-Computer Interaction (HCI) studies that assess the eﬀectiveness
of the explanations can be conducted. Let us highlight that at the cur-
rent stage, we consider an HCI evaluation premature. The behavior of
Dung-style admissible set-based semantics is in many cases counter-intuitive
(see [9], and consider, for instance, the argumentation framework AF =
({a, b}, {(a, a), (a, b)}) and preferred semantics); hence, an HCI study is likely
to yield rather “noisy” results, considering that technically correct explana-
tion of counter-intuitive semantics behavior may confuse study participants.
6
Conclusion
In this paper, we have introduced explanations for the acceptability dynamics in
dynamic systems, where explanations attribute changes to argumentation frame-
works with reference to a desirable relaxed monotony property. Based on this
property, we have constructed a theoretical framework for explaining the viola-
tion of monotony in the context of Dung-style admissible set-based semantics.

222
T. Kampik and K. ˇCyras
While a software implementation of this theoretical framework is provided, we
consider this work primarily an initial stepping stone towards real-world applica-
ble explainability of monotony violations of non-monotonic machine reasoners.
Acknowledgments. We thank the anonymous reviewers for their thoughtful and
useful feedback. This work was partially supported by the Wallenberg AI, Autonomous
Systems and Software Program (WASP) funded by the Knut and Alice Wallenberg
Foundation.
References
1. Baroni, P., Caminada, M., Giacomin, M.: Abstract argumentation frameworks and
their semantics (chap. 4). In: Baroni, P., Gabbay, D., Massimiliano, G., van der
Torre, L. (eds.) Handbook of Formal Argumentation, pp. 159–236. College Publi-
cations (2018)
2. Baroni, P., Rago, A., Toni, F.: From ﬁne-grained properties to broad principles
for gradual argumentation: a principled spectrum. Int. J. Approximate Reasoning
105, 252–286 (2019). https://doi.org/10.1016/j.ijar.2018.11.019
3. Baumann, R.: On the nature of argumentation semantics: existence and unique-
ness, expressibility, and replaceability. J. Appl. Log. 4(8), 2779–2886 (2017)
4. Baumann, R., Brewka, G.: Expanding argumentation frameworks: enforcing and
monotonicity results. COMMA 10, 75–86 (2010)
5. Baumann, R., Brewka, G., Ulbricht, M.: Revisiting the foundations of abstract
argumentation-semantics based on weak admissibility and weak defense. In: AAAI,
pp. 2742–2749 (2020)
6. Booth, R., Gabbay, D.M., Kaci, S., Rienstra, T., van der Torre, L.: Abduction and
dialogical proof in argumentation and logic programming. In: Schaub, T., Friedrich,
G., O’Sullivan, B. (eds.) 21st European Conference on Artiﬁcial Intelligence. Fron-
tiers in Artiﬁcial Intelligence and Applications, vol. 263, pp. 117–122. IOS Press,
Prague (2014). https://doi.org/10.3233/978-1-61499-419-0-117
7. Cayrol, C., de Saint-Cyr, F.D., Lagasquie-Schiex, M.C.: Change in abstract argu-
mentation frameworks: adding an argument. J. Arti. Intell. Res. 38, 49–84 (2010)
8. Cocarascu, O., ˇCyras, K., Rago, A., Toni, F.: Explaining with argumentation
frameworks mined from data. In: 1st International Workshop on Dialogue, Expla-
nation and Argumentation in Human-Agent Interaction (DEXAHAI), Southamp-
ton (2018)
9. Cramer, M., Guillaume, M.: Empirical study on human evaluation of complex
argumentation frameworks. In: Calimeri, F., Leone, N., Manna, M. (eds.) JELIA
2019. LNCS (LNAI), vol. 11468, pp. 102–115. Springer, Cham (2019). https://doi.
org/10.1007/978-3-030-19570-0 7
10. ˇCyras, K., et al.: Machine reasoning explainability. arXiv preprint arXiv:2009.00418
(2020)
11. ˇCyras, K., Rago, A., Albini, E., Baroni, P., Toni, F.: Argumentative XAI: a survey.
In: Zhou, Z.H. (ed.) 30th International Joint Conference on Artiﬁcial Intelligence,
pp. 4392–4399. IJCAI, Montreal (2021). https://doi.org/10.24963/ijcai.2021/600
12. Doutre, S., Mailly, J.G.: Constraints and changes: a survey of abstract argumenta-
tion dynamics. Argum. Comput. 9, 223–248 (2018). https://doi.org/10.3233/AAC-
180425

Explanations of Non-monotonic Inference in Abstract Argumentation
223
13. Dung, P.M.: On the acceptability of arguments and its fundamental role in non-
monotonic reasoning, logic programming and n-person games. Artif. Intell. 77(2),
321–357 (1995)
14. Dung, P.M., Kowalski, R., Toni, F.: Dialectic proof procedures for assumption-
based, admissible argumentation. Artif. Intell. 170(2), 114–159 (2006). https://
doi.org/10.1016/j.artint.2005.07.002
15. Dung, P.M., Mancarella, P., Toni, F.: Computing ideal sceptical argumentation.
Artif. Intell. 171(10–15), 642–674 (2007). https://doi.org/10.1016/j.artint.2007.05.
003
16. Dvoˇr´ak, W., Gaggl, S.A.: Stage semantics and the SCC-recursive schema for argu-
mentation semantics. J. Log. Comput. 26(4), 1149–1202 (2014). https://doi.org/
10.1093/logcom/exu006
17. Fan, X., Toni, F.: On explanations for non-acceptable arguments. In: Black, E.,
Modgil, S., Oren, N. (eds.) TAFA 2015. LNCS (LNAI), vol. 9524, pp. 112–127.
Springer, Cham (2015). https://doi.org/10.1007/978-3-319-28460-6 7
18. Fan, X., Toni, F.: On computing explanations in argumentation. In: Bonet, B.,
Koenig, S. (eds.) 29th AAAI Conference on Artiﬁcial Intelligence, pp. 1496–1502.
AAAI Press, Austin (2015)
19. Kampik, T., Gabbay, D.: The “degrees of monotony” - dilemma in abstract argu-
mentation. In: Symbolic and Quantitative Approaches to Reasoning with Uncer-
tainty 2021 (2021, to appear)
20. Kampik, T., Nieves, J.C.: Abstract argumentation and the rational man. J. Log.
Comput. 31(2), 654–699 (2021). https://doi.org/10.1093/logcom/exab003
21. Liao, B., van der Torre, L.: Explanation semantics for abstract argumentation. In:
Prakken, H. (ed.) Computational Models of Argument, vol. 326, pp. 271–282. IOS
Press (2020). https://doi.org/10.3233/FAIA200511
22. Sakama, C.: Abduction in argumentation frameworks. J. Appl. Non-Class. Log.
28(2–3), 218–239 (2018). https://doi.org/10.1080/11663081.2018.1487241
23. Saribatur, Z.G., Wallner, J.P., Woltran, S.: Explaining non-acceptability in
abstract argumentation. In: Giacomo, G.D., et al. (eds.) 24th European Conference
on Artiﬁcial Intelligence, pp. 881–888. IOS Press, Santiago de Compostela (2020).
https://doi.org/10.3233/FAIA200179
24. Thimm, M.: Tweety: a comprehensive collection of Java libraries for logical aspects
of artiﬁcial intelligence and knowledge representation. In: Proceedings of the Four-
teenth International Conference on Principles of Knowledge Representation and
Reasoning. KR 2014, pp. 528–537. AAAI Press (2014)
25. van der Torre, L., Vesic, S.: The principle-based approach to abstract argumenta-
tion semantics. IfCoLog J. Log. Appl. 4(8), 2735–2778 (2017)
26. Vassiliades, A., Bassiliades, N., Patkos, T.: Argumentation and explainable arti-
ﬁcial intelligence: a survey. Knowl. Eng. Rev. 36, e5 (2021). https://doi.org/10.
1017/S0269888921000011
27. Verheij, B.: Two approaches to dialectical argumentation: admissible sets and argu-
mentation stages. In: Proceedings of the NAIC 1996, pp. 357–368 (1996)
28. Wakaki, T., Nitta, K., Sawamura, H.: Computing abductive argumentation in
answer set programming. In: McBurney, P., Rahwan, I., Parsons, S., Maudet, N.
(eds.) ArgMAS 2009. LNCS (LNAI), vol. 6057, pp. 195–215. Springer, Heidelberg
(2010). https://doi.org/10.1007/978-3-642-12805-9 12

The Burden of Persuasion in Abstract
Argumentation
Timotheus Kampik1(B), Dov Gabbay2,3,4, and Giovanni Sartor5,6
1 Ume˚a University, Ume˚a, Sweden
tkampik@cs.umu.se
2 King’s College London, London, UK
dov.gabbay@kcl.ac.uk
3 University of Luxembourg, Esch-sur-Alzette, Luxembourg
4 Bar Ilan University, Ramat Gan, Israel
5 European University Institute, Florence, Italy
giovanni.sartor@eui.eu
6 Universit`a di Bologna, Bologna, Italy
Abstract. In this paper, we provide a formal framework for modeling
the burden of persuasion in legal reasoning. The framework is based on
abstract argumentation, a frequently studied method of non-monotonic
reasoning, and can be applied to diﬀerent argumentation semantics; it
supports burdens of persuasion with arbitrary many levels, and allows
for the placement of a burden of persuasion on any subset of an argu-
mentation framework’s arguments. Our framework can be considered an
extension of related works that raise questions on how burdens of persua-
sion should be handled in some conﬂict scenarios that can be modeled
with abstract argumentation. An open source software implementation
of the introduced formal notions is available as an extension of an argu-
mentation reasoning library.
Keywords: Formal argumentation · Non-monotonic reasoning · Legal
reasoning
1
Introduction
Over the past decades, formal argumentation has emerged as a promising col-
lection of methods for reasoning under uncertainty [4]. A particularly relevant
application domain that can beneﬁt from argumentation-based models of con-
ﬂicts and contradictions is legal reasoning [9]. An important notion in legal argu-
mentation – but also in other domains in which an outcome has to be reached
under time and resource constraints, such as political debates – is the burden
of persuasion [20]. By saying that an argument is burdened with persuasion we
mean that the argument only is relevant when it is convincing, i.e. when it over-
comes all relevant objections against it. If this is not the case, the argument has
to be rejected for failing to meet its burden of persuasion. In an argumentation-
based theory, the burden of persuasion may be placed on some of the arguments
c
⃝Springer Nature Switzerland AG 2021
P. Baroni et al. (Eds.): CLAR 2021, LNAI 13040, pp. 224–243, 2021.
https://doi.org/10.1007/978-3-030-89391-0_13

The Burden of Persuasion in Abstract Argumentation
225
in the theory. Roughly speaking, if there are several conﬂicting conclusions (here
and henceforth referred to as extensions to align with formal argumentation ter-
minology), we can infer from the theory (considering constraints imposed by
a basic inference function), the burden of persuasion dictates that we must be
less skeptical towards unburdened arguments than towards burdened ones. If
we are faced with conﬂicting extensions, one being only supported by burdened
arguments and one being only supported by unburdened arguments, we select
the latter. Moreover, any successful attacks against a burdened argument entail
that the burdened argument is to be rejected1. In a recent paper, Calegari et
al. present a model of the burden of persuasion that is based on a structured
argumentation approach [11]; in their paper, the authors also highlight some
limitations of their model, such as the inability to meaningfully model burdened
arguments that are part of cyclic structures. This paper aims to address these
limitations by introducing a model of the burden of persuasion that only relies
on abstract argumentation and supports any abstract argumentation framework
(where the burden of persuasion may be placed on any subset of the argumen-
tation framework’s arguments), as well as arbitrary many levels of burdens.
Let us introduce an example that gives an intuition of our approach.
Example 1. Usually patients have the burden of persuasion on the liability of
medical doctors in order to be compensated for the harm they suﬀered as a
consequence of an unsuccessful treatment. This follows from the general principle
that the plaintiﬀs in a legal case should persuade the judge in order to get
a favorable decision. Should the outcome remain uncertain, their claim has to
be rejected. However, doctors do not have to pay compensation in case they
were diligent in treating the patient and the failure of the treatment was not
due to incompetence or carelessness. The possibility of doctors to avoid liability
is limited by the fact that – at least in some legal systems – they have the
burden of persuasion with regard to their diligence. Their arguments to this
eﬀect must be convincing. Otherwise they will be rejected: in case uncertainty
remains on whether they were diligent or not, their liability will consequently be
established. Note that this is a simpliﬁed representation of the matter at stake,
since other aspects of the case may have to be considered, such as the diﬃculty
or extraordinary nature of the case of the patient.
Let us assume however, that under the given normative framework a patient
asks for compensation. The patient’s argument l for the doctors’ liability is
based on the fact that the doctor subjected him to an unsuccessful and harmful
therapy. Argument l is attacked by an expert witness in favor of the doctor, whose
argument a claims that the doctor was diligent, since the adopted therapy is
successful in the vast majority of cases; this was argued in a leading top scientiﬁc
journal, the evidence of this journal being suﬃcient to guarantee the truth of
the claim. The patient’s expert witness attacks argument a through argument
b, according to which a therapy with a higher success rate is available. The high
success rate of the adopted treatment is insuﬃcient to establish diligence, if an
even more eﬀective treatment is state-of-the art. The Court’s expert witness
1 Here, we assume a model where an argument is either burdened or unburdened.

226
T. Kampik et al.
attacks argument b through one further argument c, according to which the
scientiﬁc evidence in favor of b is insuﬃcient, being based on a restricted set of
the scientiﬁc literature. Finally, argument c is attacked by argument a, which
includes the claim that one single journal was suﬃcient to establish a scientiﬁc
claim.
We end up with the following argumentation framework – a tuple consisting
of a set of arguments AR and a set of attacks AT ⊆AR × AR (Fig. 1):
AF ′ = (AR′, AT ′) = ({l, a, b, c}, {(a, c), (a, l), (b, a), (c, b)})
l
(a) AF.
l
a
b
c
(b) AF .
Fig. 1. We restrict AF ′ to {l}, generating AF, to reﬂect that the burden of persuasion
rests on the rejection of l. Then, we infer {l} from AF and check if we can infer an
extension that entails {l} from AF ′. Since this is the case, we have to consider {l} as
valid. In the example, arguments with a gray background are unambiguously inferred;
arguments with a white background and a solid border may be inferred (are part of at
least one extension, considering the burden of persuasion approach); arguments with
a dashed border are unambiguously rejected.
Intuitively, it is not clear which of the arguments are valid in this frame-
work, so that their conclusion (extension) has to be endorsed, and in particular
whether l is valid or not. As noted above, the patient should have the burden
of persuasion on liability, but the doctor has the burden of persuasion on her
diligence. We assume that it is uncontroversial that the patient has been harmed
by the wrong therapy: there is no doubt that the patient has satisﬁed his bur-
den of persuasion on this point. The issue is whether the doctor has satisﬁed
her burden of persuasion relative to her diligence. She has no beneﬁt of doubt
in this regard: in case doubts remain on her diligence, her argument has to be
rejected, and so her liability toward the patient will have to be established. The
crucial point is then to establish whether there is doubt on her diligence based
on the circle of arguments {a, b, c}.
Hence, we generate the following argumentation framework sequence from
AF ′: AFS = ⟨AF, AF ′⟩, where AF = ({l}, {}); we call AF the restriction of
AF ′ to {l}. We ﬁrst determine all possible extensions of AF, and trivially, there
is only one, which is {l}. Then, we determine all extensions of AF ′. Here, we
have diﬀerent options.
1. Assuming that the cycle of arguments “a attacks c attacks b attacks a” is a
self-contradiction, we can say that the only extension is the empty set; the

The Burden of Persuasion in Abstract Argumentation
227
traditional abstract argumentation semantics as introduced in Dung’s seminal
paper [14] behave accordingly. However, from a legal reasoning perspective,
we need to employ a more credulous approach.
2. Again considering the cycle of arguments “a attacks c attacks b attacks c”
as a self-contradiction, we can discard the arguments in this cycle, but then
conclude that surely, l cannot be rejected; the recently introduced weak admis-
sible set-based argumentation semantics family [8] formalizes this intuition,
and allows us to again infer {l} as the only extension. This result is aligned
with common legal notions of the burden of persuasion in our case, because
the practitioner’s diligence is not beyond doubt2.
3. We can assume that any of the arguments a, b, or c could be part of an
extension, but that these three arguments are mutually exclusive, and hence
infer that {a}, {b, l} and {c, l} are extensions. This intuition is formalized
(for example) by CF2 [6] and SCF2 [12] semantics; not all extensions reject
l; hence, the notion of the burden of persuasion constrains us to select one of
the extensions that entail l, i.e. either {b, l} or {c, l}. This means we have to
accept l and we conclude that the doctor has not successfully persuaded the
court that she has acted without negligence.
Let us highlight that our framework for modeling the burden of persuasion
is not merely determining whether a set of arguments is credulously accepted
– whether it is entailed by at least one extension – or skeptically accepted, i.e.
whether it is entailed by all extensions. For this, we introduce an additional
(abstract) example, which also illustrates how we can manage multiple levels of
the burden of persuasion.
Example 2. Consider the following argumentation framework:
AF ′′ = ({a, b, c, d, e}, {(a, b), (a, e), (b, a), (b, e), (c, d), (d, c), (e, a), (e, b)})
and the following burdens of persuasion: i) a and b are unburdened; ii) c is
burdened with a “light-weight” level 1 burden; iii) d and e are burdened with a
“heavier” level 2 burden. Let us assume a credulous inference function allows for
the following extensions3 (given only AF ′′ and no burden of persuasion model):
{a, c}, {a, d}, {b, c}, {b, d}, {e, c}, {e, d}
We take a look at the unburdened arguments and their attacks among each other,
which gives us the argumentation framework AF = ({a, b}, {(a, b), (b, a)}). We
2 For
the
sake
of
conciseness,
we
do
not
consider
weak
admissibility-based
semantics in detail. However, let us claim that the simple example AF
=
({a, b, c}, {(a, b), (b, c), (c, a)}) illustrates that all weak admissible set-based seman-
tics Baumann et al. may not be suﬃciently credulous for many applications that
require a model of the burden of persuasion.
3 In this example, the inferences we draw from the abstract argumentation frameworks
coincide, for example, with the extensions (sets of arguments) returned by CF2 [6]
and SCF2 [12] semantics.

228
T. Kampik et al.
assume that from AF, we can infer either {a} or {b}. This means that we need
to consider all extensions that can be inferred from AF ′′, given they entail either
{a} or {b}. We “ﬁlter” the extensions accordingly and remain with the following
sets4:
{a, c}, {a, d}, {b, c}, {b, d}
Now, we consider the arguments that carry the ﬁrst-level burden of persuasion,
i.e. {c} and AF ′ = ({a, b, c}, {(a, b), (b, a)}). Because of the unburdened argu-
ments, we have to be able to infer either {a} or {b}. But surely, we can allow
for this inference and still guarantee that we can infer {c}: we merely need to
remove the extensions {a, d} and {b, d}:
{a, c}, {b, c}
It follows that {a, c} and {b, c} are our ﬁnal extensions; the arguments that carry
the second-level burden of persuasion – d and e – are rejected. No unambiguous
conclusion can be reached, as our ﬁnal inference result is “either {a, c} or {b, c}”
(Fig. 2).
a
b
(a) AF.
a
b
c
(b) AF .
a
b
c
d
e
(c) AF .
Fig. 2. Multiple levels of burdens of persuasion.
A software implementation of the formal concepts we introduce in this paper
is available at https://git.io/JGueN. The implementation relies on the abstract
argumentation reasoner provided by the Tweety project [21].
The rest of this paper is organized as follows. Section 2 provides relevant theo-
retical preliminaries. Then, Sect. 3 introduces our formal framework for modeling
the burden of persuasion in abstract argumentation. The suitability of applying
diﬀerent argumentation semantics, as well as the relevance of skeptical accep-
tance are discussed in Sect. 4. Finally, Sect. 5 discusses the framework in the
context of related research, before Sect. 6 concludes the paper.
2
Preliminaries
This section introduces the preliminaries that our work is based upon. The cen-
tral notion this paper uses is Dung’s (abstract) argumentation framework [14].
4 Let us note that there are some intricate details in the ﬁltering approach that this
example does not cover.

The Burden of Persuasion in Abstract Argumentation
229
An argumentation framework AF is a tuple (AR, AT), such that AR is a set of
arguments and AT is a set of attacks, AT ⊆AR × AR. We assume that the set
of arguments in an argumentation framework is ﬁnite. For (a, b) ∈AT, we say
that “a attacks b”. For S ⊆AR, b ∈S, and a ∈AR, iﬀ(b, a) ∈AT, we say
that “S attacks a” and iﬀ(a, b) ∈AT, we say that “a attacks S”; we denote
{a|a ∈AR, a attacks S} by S−and {b|b ∈AR, S attacks b} by S+. For S ⊆AR,
P ⊆AR such that ∃(a, b) ∈AT, a ∈S, b ∈P, we say that “S attacks P”. For
S ⊆AR, a ∈AR, we say that “S defends a” iﬀ∀b ∈AR, such that b attacks a it
holds true that S attacks b. Given S ⊆AR, we deﬁne AF ↓S= (S, AT ∩S × S).
We call AF ↓S the restriction of AF to S. Let us introduce some properties of
sets of arguments in an argumentation framework.
Deﬁnition 1 (Conﬂict-free, Unattacked, and Admissible Sets [3]). Let
AF = (AR, AT) be an argumentation framework. A set S ⊆AR: i) is conﬂict-
free iﬀ∄a, b ∈S such that a attacks b; ii) is unattacked iﬀ∄a ∈AR \ S such
that a attacks S; iii) is admissible iﬀS is conﬂict-free and ∀a ∈S, it holds true
that S defends a.
Argumentation framework expansions model the addition of new arguments
and attacks to an argumentation framework.
Deﬁnition 2 (Argumentation Framework Expansions [7]). Let AF =
(AR, AT) and AF ′ = (AR′, AT ′) be argumentation frameworks. AF ′ is an
expansion of AF (denoted by AF ⪯E AF ′) iﬀAR ⊆AR′ and AT ⊆AT ′.
AF ′ is a normal expansion of AF (denoted by AF ⪯N AF ′) iﬀAF ⪯E AF ′
and (AR × AR) ∩(AT ′ \ AT) = {}.
While our formal framework does not rely on expansions or normal expan-
sions, these notions can be used to establish the connection between our work
and the research direction of dynamics in formal argumentation (see Sect. 5).
An argumentation semantics σ takes an argumentation framework as its
input and determines sets of arguments (extensions) that can be considered
valid conclusions. Dung’s seminal paper introduces stable, preferred, complete,
and grounded argumentation semantics.
Deﬁnition 3 (Dung’s
Argumentation
Semantics
[14]).
Let
AF
=
(AR, AT) be an argumentation framework. An admissible set S ⊆AR is a:
– stable extension of AF iﬀS attacks each argument that does not belong to S.
σst(AF) denotes all stable extensions of AF.
– preferred extension of AF iﬀS is a maximal (w.r.t. set inclusion) admissible
subset of AR. σpr(AF) denotes all preferred extensions of AF.
– complete extension of AF iﬀeach argument that is defended by S belongs to
S. σco(AF) denotes all complete extensions of AF.
– grounded extension of AF iﬀS is the minimal (w.r.t. set inclusion) complete
extension of AF. σgr(AF) denotes all grounded extensions of AF.

230
T. Kampik et al.
Given any argumentation semantics σ and any argumentation framework
AF, we call a set S ∈σ(AF) a σ-extension of AF. If and only if for every
argumentation framework AF it holds true that |σ(AF)| ≥1 we say that σ
is universally deﬁned; if and only if for every argumentation framework AF it
holds true that |σ(AF)| = 1 we say that σ is universally uniquely deﬁned. Dung’s
semantics are all based on the notion of an admissible set. Later works introduce
semantics based on naive (⊆-maximal conﬂict-free) sets.
Deﬁnition 4 (Naive and Stage Semantics [23]). Let AF = (AR, AT) be an
argumentation framework and let S ⊆AR.
– S is a naive extension of AF iﬀS is a maximal conﬂict-free subset of AR
w.r.t. set inclusion. σnaive(AF) denotes all naive extensions of AF.
– S is a stage extension of AF iﬀS is conﬂict-free and S ∪S+ is maximal
w.r.t. set inclusion, i.e. ∄S′ ⊆AR, such that S′ is a conﬂict-free set and
S ∪S+ ⊂S′ ∪S′+. σstage(AF) denotes the stage extensions of AF.
Given an argumentation framework AF and an argumentation semantics σ,
the skeptically accepted set of arguments is the intersection of the σ-extensions
of AF.
Deﬁnition 5 (Skeptical Acceptance). Let AF = (AR, AT) be an argumen-
tation framework and let σ be an argumentation semantics. We call 
E∈σ(AF ) E
the skeptically accepted set of arguments of
AF
given
σ and denote it by
σ∩(AF).
Let us introduce some preliminaries for so-called SCC-recursive semantics,
starting with the notion of a path between arguments.
Deﬁnition 6 (Path between Arguments). Let AF = (AR, AT) be an argu-
mentation framework. A path from an argument a0 ∈AR to another argument
an ∈AR is a sequence of arguments Pa0,an = ⟨a0, ..., an⟩, such that for 0 ≤i < n,
ai attacks ai+1.
Based on this deﬁnition, we can deﬁne the notion of reachability.
Deﬁnition 7 (Reachability). Let AF = (AR, AT) be an argumentation
framework. We say that given two arguments a, b ∈AR, “b is reachable from a”
iﬀthere exists a path Pa,b or a = b.
Based on the notion of reachability, we can deﬁne strongly connected compo-
nents.
Deﬁnition 8 (Strongly Connected Components (SCC)). Let AF
=
(AR, AT) be an argumentation framework. S ⊆AR is a strongly connected
component of AF iﬀ∀a, b ∈S, a is reachable from b and b is reachable from a
and ∄c ∈AR \ S, such that a is reachable from c and c is reachable from a. Let
us denote the strongly connected components of AF by SCCS(AF).
Another preliminary for SCC-recursive semantics is the UP function.

The Burden of Persuasion in Abstract Argumentation
231
Deﬁnition 9 (UP [6]). Let AF = (AR, AT) be an argumentation framework
and let E ⊆AR, S ⊆AR. We deﬁne UPAF (S, E) = {a|a ∈S, ∄b ∈E \
S such that (b, a) ∈AT}.
Now, we can introduce the SCC-recursive and naive set-based CF2 semantics.
Deﬁnition 10 (CF2 Semantics [6]). Let AF = (AR, AT) be an argumenta-
tion framework and let E ⊆AR. E is a CF2 extension iﬀ:
– E is a naive extension of AF if |SCCS(AF)| = 1;
– ∀S ∈SCCS(AF), (E ∩S) is a CF2 extension of AF ↓UPAF (S,E), otherwise.
σCF 2(AF) denotes all CF2 extensions of AF.
To give a rough intuition of how SCC-recursive semantics (and in particular:
CF2 semantics) work, let us introduce an example.
Example 3. Consider AF = ({a, b, c}, {(a, b), (b, a), (a, c), (b, c)}). We have two
SCCs: {a, b} and {c}. Colloquially speaking, we traverse the SCC graph, starting
with unattacked (“top-level”) SCCs: ﬁrst, we take the top-level SCC {a, b} and
determine σnaive(AF ↓{a,b}) = {{a}, {b}}. Then, ∀E ∈{{a}, {b}}, we determine
UPAF (S, E), where S = {c}, because {c} is the “next” and only remaining SCC.
Because UPAF ({c}, {a}) = UPAF ({c}, {b}) = {} and σnaive(({}, {})) = {{}},
we remain with {a} and {b} as our CF2 extensions.
Stage2 is an SCC-recursive semantics that has been introduced to address
some shortcomings of CF2 semantics, notably unintuitive behavior when resolv-
ing even-length cycles of length ≥6, roughly speaking (see Example 4, argumen-
tation framework AF ∗∗).
Deﬁnition 11 (Stage2 Semantics [15]). Let AF = (AR, AT) be an argumen-
tation framework and let E ⊆AR. E is a stage2 extension iﬀ:
– E is a stage extension of AF if |SCCS(AF)| = 1;
– ∀S ∈SCCS(AF), (E∩S) is a stage2 extension of AF ↓UPAF (S,E), otherwise.
σstage2(AF) denotes all stage2 extensions of AF.
Another “CF2 improvement attempt” is made by Cramer’s and Van der
Torre’s SCF2 semantics [12]. The authors start by deﬁning a notion that ignores
self-attacking arguments.
Deﬁnition 12 (nsa(AF) [12]). Let AF = (AR, AT) be an argumentation
framework. We deﬁne nsa(AF) = AF ↓{a|a∈AR and (a,a)̸∈AT }.
Based on this notion, Cramer and Van der Torre introduce nsa(CF2) seman-
tics as an intermediate step on the way to SCF2 semantics.
Deﬁnition 13 (nsa(CF2) Semantics [12]). Let AF = (AR, AT) be an argu-
mentation framework. A set E ⊆AR is an nsa(CF2)-extension of AF iﬀ
E ∈σCF 2(nsa(AF)). σnsa(CF 2)(AF) denotes all nsa(CF2) extensions of AF.

232
T. Kampik et al.
This approach ﬁxes some issues with CF2 semantics and self-attacking argu-
ments. To tackle the problem with even-length cycles, we need to deﬁne some
preliminaries.
Deﬁnition 14 (Attack Cycles). Let AF = (AR, AT) be an argumentation
framework. An attack cycle C is a sequence of arguments ⟨a0, ..., an⟩where
(ai, ai+1) ∈AT for 0 ≤i < n and aj ̸= ak for 0 ≤j < k ≤n if not j = 0 and
k = n, and where a0 = an. An attack cycle is odd iﬀn is odd and even iﬀn is
even.
Cramer and Van der Torre introduce a speciﬁc property to describe how a
CF2-like semantics should ideally behave in the case of even cycles that are not
“aﬀected” by odd cycles, roughly speaking.
Deﬁnition 15 (Strong Completeness Outside Odd Cycles (Set) [12]).
Let AF = (AR, AT) be an argumentation framework. A set S ⊆AR is strongly
complete outside odd cycles iﬀ∀a ∈AR, if no argument in {a} ∪{a}−is in an
odd attack cycle and S ∩{a}−= {} then a ∈S.
To systematically analyze argumentation semantics, a range of formal argu-
mentation principles have been deﬁned [5,22]. Cramer and Van der Torre turn
the strong completeness outside odd cycles property into a principle to “catch”
unintuitive CF2 behavior.
Deﬁnition 16 (SCOOC Principle [12]). An argumentation semantics σ is
Strongly Complete Outside Odd Cycles (SCOOC) iﬀfor every argumentation
framework AF, ∀E ∈σ(AF), E is strongly complete outside odd cycles.
Based on this principle and the notion of nsa(CF2) semantics, SCF2 seman-
tics is deﬁned.
Deﬁnition 17 (SCF2 Semantics [12]). Let AF = (AR, AT) be an argumen-
tation framework and let E be a set such that E ⊆AR. E is an SCF2 extension
iﬀ:
– E is a naive extension of nsa(AF) and E is strongly complete outside odd
cycles if |SCCS(nsa(AF))| = 1;
– ∀S ∈SCCS(nsa(AF)), (E ∩S) is an SCF2 extension of AF ↓UPnsa(AF )(S,E),
otherwise.
σSCF 2(AF) denotes all SCF2 extensions of AF.
Let us introduce some examples that illustrate the behaviors of – and high-
lights the diﬀerence between – stage, CF2, stage2, and SCF2 semantics. However,
let us note that a detailed explanation of the semantics is beyond the scope of
this paper and the reader may consult the original works instead.
Example 4. Let us consider the following argumentation frameworks: i) AF ′ =
({a, b, c}, {(a, b), (b, c), (c, c)}); ii) AF ′′ = ({a, b, c}, {(a, b), (a, c), (b, c), (c, a)});
iii) AF ∗= ({a, b, c}, {(a, b), (b, c), (c, a), (c, c)}); iv) AF ∗∗= ({a, b, c, d, e, f},
{(a, b), (b, c), (c, d), (d, e), (e, f), (f, a)}). Table 1 displays the extensions stage,
CF2, stage2, and SCF2 semantics yield for these argumentation frameworks.

The Burden of Persuasion in Abstract Argumentation
233
Table 1. Diﬀerences between stage, CF2, stage2, and SCF2 semantics (examples).
Stage
CF2
Stage2
SCF2
AF ′
{a}, {b}
{a}
{a}
{a}
AF ′′
{a}
{a}, {b}, {c}
{a}
{a}, {b}, {c}
AF ∗
{a}, {b}
{a}, {b}
{a}, {b}
{a}
AF ∗∗{a, c, e}, {b, d, f} {a, c, e},
{b, d, f}
{a, d}, {b, e},
{c, f}
{a, c, e}, {b, d, f} {a, c, e}, {b, d, f}
Argumentation principles that are relevant in the context of this paper are
the admissibility and naivety principles.
Deﬁnition 18 (Admissibility and Naivety Principles [5]). Let σ be an
argumentation semantics. σ satisﬁes the admissibility principle iﬀfor every
argumentation framework AF = (AR, AT), ∀E ∈σ(AF), E is an admissi-
ble set. σ satisﬁes the naivety principle iﬀfor every argumentation framework
AF = (AR, AT), ∀E ∈σ(AF), E is a maximal conﬂict-free subset (w.r.t. set
inclusion) of AR.
3
An Abstract Argumentation-Based Burden of
Persuasion
In this section, we introduce our formal framework for modeling burdens of
persuasion in abstract argumentation.
Deﬁnition 19 (Burden of Persuasion-Framework (BPF)). A Burden of
Persuasion Framework (BPF) is a tuple AFBP = (ARS, AT), where:
– ARS = ⟨S0, ..., Sn⟩and each Si, 0 ≤i ≤n is a non-empty set of arguments,
such that for each Sj, 0 ≤j ≤n, i ̸= j, it holds true that Si ∩Sj = {};
– We denote 
0≤k≤n Sk by ARGS(ARS);
– AT ⊆ARGS(ARS) × ARGS(ARS).
We assume that given a BPF AFBP F (ARS, AT), ARGS(ARS) is ﬁnite. Let
us introduce some short-hand notation that makes it easier to work with BPFs.
Deﬁnition 20 (BPF Short-hand Notation). Let AFBP = (ARS, AT) be a
BPF, such that ARS = ⟨S0, ..., Sn⟩. Given 0 ≤i ≤n, we denote 
0≤j≤i Sj by
ARi and (ARi, AT ∩(ARi × ARi)) by AFi. Also, for any AFBP = (ARS, AT),
such that ARS = ⟨S0, ..., Sn⟩, we denote:
AFBP −1 =
⎧
⎪
⎨
⎪
⎩
AFBP
if n = 0;
(⟨S0 ∪Sn⟩, AT)
if n = 1;
(⟨S0, ..., Sn−2, Sn−1 ∪Sn⟩, AT)
otherwise.

234
T. Kampik et al.
For a set of arguments S ⊆S0 we say that S is unburdened and for any argument
a ∈S0 we say that a is unburdened. For a set of arguments S′ ⊆Sk, 0 < k ≤n,
we say that S′ is burdened or that S′ is level k-burdened, and for an argument
a′ ∈Sk we say that a′ is burdened or that a′ is level k-burdened.
Let us introduce an example of a BPF.
Example 5. Consider Example 2. When modeling the argumentation frameworks
that we have in the example as a BPF, we get:
– AFBP
=
(⟨{a, b}, {c}, {d, e}⟩, {(a, b), (a, e), (b, a), (b, e), (c, d), (d, c), (e, a),
(e, b)});
– AF2 = ({a, b, c, d, e}, {(a, b), (a, e), (b, a), (b, e), (c, d), (d, c), (e, a), (e, b)});
– AF1 = ({a, b, c}, {a, b), (b, a)});
– AF0 = ({a, b}, {(a, b), (b, a)});
– AFBP −1
=
(⟨{a, b}, {c, d, e}⟩, {(a, b), (a, e), (b, a), (b, e), (c, d), (d, c), (e, a),
(e, b)}).
The set of arguments {a, b} is unburdened, {c} is level 1-burdened and {d, e} is
level 2-burdened.
Before we can deﬁne a way to determine the extensions of BPFs, let us
introduce the notion of ⊆-maximal monotonic extensions.
Deﬁnition 21 (⊆-Maximal Monotonic Extensions). Let AR and A be
ﬁnite sets of arguments (extensions) and let EXTS ⊆2AR and ES ⊆2A. We
deﬁne the ⊆-maximal monotonic extensions of EXTS w.r.t. ES, denoted by
EXTS⊆−max
mon
(EXTS, ES), as follows:
EXTS⊆−max
mon
(EXTS, ES) =
{E|E ∈EXTS, ∃S ∈ES such that ∀E′ ∈EXTS, E′ ∩S ⊆E ∩S}
Let us highlight that the notion of ⊆-maximal monotonic extensions is
purposefully diﬀerent from the cardinality-based monotony measure and opti-
mization approach [19] that we have recently introduced. Colloquially speak-
ing, we can say that the ⊆-maximal approach is more credulous. As an
example, consider the argumentation frameworks AF
= ({a, b, c}, {}) and
AF ′ = ({a, b, c, d, e}, {(d, a), (d, e), (e, b), (e, c), (e, d)}) and preferred semantics.
σpr(AF) = {{a, b, c}}; the only cardinality-maximal monotonic extension of
σpr(AF ′) w.r.t. to {{a, b, c}} is {b, d, c}, whereas we have two ⊆-maximal mono-
tonic extensions of σpr(AF ′) w.r.t. to {{a, b, c}}, i.e. {b, d, c} and {a, e}. Hence,
⊆-maximal monotonic extensions are better aligned with the notion of the bur-
den of persuasion in legal reasoning: intuitively, we cannot eliminate doubt in
this scenario. However, we want to avoid the inclusion of extensions that are not
Pareto optimal. Let us provide an example to illustrate this problem.
Example 6. Consider
EXTS
=
{{a, b}, {}}
and
ES
=
{{a}, {c}}.
EXTS⊆−max
mon
(EXTS, ES) = {{a, b}, {}}. However, intuitively, it makes sense
to “drop” {}, because its absence does not aﬀect the fact that c is not entailed
by any set of arguments in EXTS, but its presence implies that we may select
a set of arguments from EXTS that does not entail a.

The Burden of Persuasion in Abstract Argumentation
235
To address this issue, we deﬁne Pareto optimal ⊆-maximal monotonic exten-
sions.
Deﬁnition 22 (Pareto Optimal ⊆-Maximal Monotonic Extensions).
Let AR and A be ﬁnite sets of arguments (extensions), let EXTS ⊆2AR and
ES ⊆2A. We deﬁne the Pareto optimal ⊆-maximal monotonic extensions of
EXTS w.r.t. ES, denoted by EXTS⊆−max
po−mon(EXTS, ES), as follows:
EXTS⊆−max
po−mon(EXTS, ES) = {E|E ∈EXTS and
∄E′ ∈EXTS, such that
∀S ∈ES, S ∩E ⊆S ∩E′ and
∃S′ ∈ES, such that S′ ∩E ⊂S′ ∩E′}
Let us continue the previous example to illustrate the diﬀerence between the
previous two deﬁnitions.
Example 7. Consider again EXTS = {{a, b}, {}} and ES = {{a}, {c}}.
EXTS⊆−max
po−mon(EXTS, ES) = {{a, b}}.
Now, let us deﬁne a way to determine the extension of a BPF, given any
universally deﬁned argumentation semantics.
Deﬁnition 23 (BP Semantics and Extensions). Let AFBP = (ARS, AT)
be a BPF, such that ARS = ⟨S0, ..., Sn⟩, and let σ be an argumentation seman-
tics. We deﬁne the σ-extensions of AFBP as returned by the BP semantics σBP ,
denoted by σBP (AFBP ), as follows:
σBP (AFBP ) =

σ(AF0)
if n = 0;
EXTS⊆−max
po−mon(σBP (AFBP −1), σ(AF0) ∪... ∪σ(AFn−1))
otherwise.
Let us provide an example of how BPF extensions are determined.
Example 8. Consider the BPF AFBP = (ARS, AT) = (⟨{a, b}, {c, d, e}, {f}⟩,
{(a, c), (a, e), (c, d), (d, b), (d, f), (e, a), (e, c), (f, b), (f, d)}). Let us assume we
apply SCF2 semantics5 and ﬁrst provide an intuition that strays from the
recursive deﬁnition (Deﬁnition 23). Based on AFBP , we generate the follow-
ing argumentation frameworks: AF0 = ({a, b}, {}); AF1 = ({a, b, c, d, e}, {(a, c),
(a, e), (c, d), (d, b), (e, a), (e, c)});
AF2
=
({a, b, c, d, e, f}, {(a, c), (a, e), (c, d),
(d, b), (d, f), (e, a), (e, c), (f, b), (f, d)}). Figure 3 depicts AF0, AF1, and AF2.
Then, we determine the CF2 extensions of AF2 and AF0: σSCF 2(AF2) =
{{a, d}, {a, f}, {e, d}, {e, f}}
and
σSCF 2(AF0)
=
{{a, b}}.
EXTS⊆−max
po−mon
(σSCF 2(AF2), σSCF 2(AF0))
=
{{a, d}, {a, f}}.
Next,
we
determine
the
SCF2 extensions of AF1: σSCF 2(AF1)
=
{{a, d}, {e, d}}. EXTS⊆−max
po−mon
5 Let us note that for this BPF, applying preferred semantics would not make a
diﬀerence at any of the steps that follow. This may help the reader follow along.

236
T. Kampik et al.
(σSCF 2(AF2), σSCF 2(AF0) ∪σSCF 2(AF1)) = {{a, d}}; hence our ﬁnal result is
σBP
SCF 2(AFBP ) = {{a, d}}.
Following the recursive deﬁnition (Deﬁnition 23), we proceed as follows.
1. σBP
SCF 2(AFBP ) =
EXTS⊆−max
po−mon(σBP
SCF 2(AFBP −1), σSCF 2(AF0) ∪σSCF 2(AF1));
2. AFBP −1 = (⟨{a, b}, {c, d, e, f}⟩, AT);
3. σBP
SCF 2(AFBP −1) = EXTS⊆−max
po−mon(σBP
SCF 2(AF(BP −1)−1), σSCF 2(AF0));
4. AF(BP −1)−1 = (⟨{a, b, c, d, e, f}⟩, AT);
5. σBP
SCF 2(AF(BP −1)−1) = σSCF 2(AF2) = {{a, d}, {a, f}, {e, d}, {e, f}};
6. σSCF 2(AF0) = {{a, b}};
7. σBP
SCF 2(AFBP −1) = EXTS⊆−max
po−mon(σBP
SCF 2(AF(BP −1)−1), σSCF 2(AF0)) =
{{a, d}, {a, f}};
8. σBP
SCF 2(AFBP ) =
EXTS⊆−max
po−mon(σBP
SCF 2(AFBP −1), σSCF 2(AF0) ∪σSCF 2(AF1)) =
EXTS⊆−max
po−mon({{a, d}, {a, f}}, {{a, b}} ∪{{a, d}, {e, d}}) = {{a, d}}.
a
b
(a) AF0.
a
b
c
d
e
(b) AF1.
a
b
c
d
e
f
(c) AF2.
Fig. 3. Example: given the AFBP = (⟨{a, b}, {c, d, e}, {f}⟩, {(a, c), (a, e), (c, d), (d, b),
(d, f), (e, a), (e, c), (f, b), (f, d)}), the ﬁgure depicts AF0, AF1, and AF2.
We can show that given an argumentation semantics σ that is universally
deﬁned, the corresponding BPF semantics σBP is universally deﬁned as well.
Proposition 1. Let σ be an argumentation semantics. If σ is universally deﬁned
then σBP is universally deﬁned.
Similarly, given an argumentation semantics σ that is universally uniquely
deﬁned, the corresponding BP semantics σBP is universally uniquely deﬁned.
Proposition 2. Let σ be an argumentation semantics. If σ is universally
uniquely deﬁned then σBP is universally uniquely deﬁned.
We provide the proofs in the Appendix. Let us claim that for every universally
uniquely deﬁned argumentation semantics σ, for every burden of persuasion-
framework AFBP = (⟨S0, ..., Sn⟩, AT) it holds true that σBP (AFBP ) = σ(AFn).
We call any argumentation semantics for which this condition holds true burden
agnostic – every universally uniquely deﬁned argumentation semantics is burden
agnostic and for burden agnostic semantics, it does not make sense to construct
burden of persuasion-frameworks.

The Burden of Persuasion in Abstract Argumentation
237
4
Semantics Selection and Skeptical Acceptance
The formal framework we have introduced in the previous section can be applied
together with any universally deﬁned argumentation semantics (see Propo-
sition 1)6. To analyze the feasibility of diﬀerent argumentation semantics in
the context of our framework, let us ﬁrst give an overview of the three main
abstract argumentation semantics families, using the argumentation framework
AF = ({a, b, c, d}, {(a, b), (b, c), (c, a), (a, d)}) as an example that highlights key
diﬀerences7.
Admissible Set-Based Semantics. The four argumentation semantics (sta-
ble, complete, preferred and grounded, see Deﬁnition 3) that Dung introduces
in his seminal paper all satisfy the principle of admissibility (see Deﬁnition 18):
any extension such a semantics yields must be an admissible set. Considering the
example argumentation framework AF, the only set in 2AR that is admissible
is {}. Hence, we suggest that typically, admissible set-based semantics are too
skeptical to be useful when applied to burden of persuasion frameworks. In the
example, no matter where we place burdens of persuasion, we always have to
infer the empty set. In case this skepticism is considered adequate in face of odd
cycles, users may consider applying a universally deﬁned admissible set-based
semantics that is relatively credulous, such as preferred or complete semantics
and should then consider ignoring self-attacking arguments (or abstaining from
constructing argumentation frameworks that contain self-attacking arguments).
However, let us note that even then, applying weak admissible set based seman-
tics (see below) may be more suitable.
Weak Admissible Set-Based Semantics. Baumann et al. introduce the weak
admissible set-based semantics family [8] to address a long-standing problem
with admissible set-based semantics that Dung observes in his seminal paper.
Consider the example argumentation framework AF, or the even simpler frame-
work AF ′ = ({a, d}, {(a, a), (a, d)}) and assume that an argument that – roughly
speaking – defeats itself should be rejected (which is, arguably, an intuition that
motivates admissibility). According to this assumption, we want to reject a when
considering AF ′, and a, b and c, when considering AF. Consequently, we should,
for sure, be able to infer d from AF (and AF ′). Weak admissible set-based seman-
tics achieve this behavior by systematically relaxing admissibility. For the sake
of conciseness, we do not introduce a formal perspective on weak admissible
set-based semantics. Still, let us speculate that the application of weak admis-
sible set-based semantics may be useful in the context of burden of persuasion
frameworks, given we want to ensure skepticism in face of odd cycles.
6 However, it does not make sense to apply the approach using universally uniquely
deﬁned semantics, see the previous section.
7 Note that in this section, we merely provide intuitions that can guide a practical
selection of argumentation semantics. These intuitions are informed by more thor-
ough, overviews and principle-based analyses of abstract argumentation semantics,
as for example surveyed by Baroni et al. [3] (argumentation semantics overview) and
Van der Torre and Vesic [22] (overview of argumentation principles).

238
T. Kampik et al.
Naive Set-Based Semantics. Naive set-based semantics, as initially intro-
duced by Verheij [23] form the most credulous of the three semantics families;
the naivety principle (see Deﬁnition 18) merely requires that every extension a
semantics infers is a ⊆-maximal conﬂict-free (naive) set. By deﬁnition, every
extension that an admissible set-based or weak admissible set-based semantics
yields is conﬂict-free and hence entailed by a naive set. Any of the naive set-
based semantics whose deﬁnitions we provide in Sect. 2 infers the following three
extensions from the example framework AF: {a}, {b, d}, and {c, d}. Naive set-
based semantics start oﬀwith the naivety principle, and then typically formalize
further constraints that are related to the notions of SCC-recursiveness (see
Sect. 2) or range, i.e. ⊆-maximality of an extension in union with the arguments
the extension attacks. Among the four “reasonable” naive set-based semantics
(not considering naive semantics, which does not impose any further constraint
besides naivety), the two semantics that employ the notion of range, i.e. stage
and stage2 semantics, can be considered more skeptical than the two semantics
that are SCC-recursively deﬁned, but do not use range (CF2 and SCF2 seman-
tics). Consider AF ′′ as introduced by Example 4. Also, Example 4 highlights
that stage, stage2, and CF2 semantics may behave counter-intuitively when
self-attacking arguments are present; hence, self-attacking arguments should be
avoided or ignored. Because of the well-known limitations (see Example 4 and
also Dvorak and Gaggl [15], as well as Cramer and Van der Torre [12]), there is
most likely no use-case that justiﬁes the application of CF2 semantics; instead
SCF2 semantics should be applied, or – if SCF2 semantics is deemed too com-
plex – a stage semantics variant that ignores self-attacking arguments may be a
reasonable and slightly more skeptical approximation.
In the context of our burden of persuasion framework, naive set-based seman-
tics are arguably the most interesting abstract argumentation family, due to their
relatively credulous behavior. This behavior can then be further constrained by
the burden of persuasion model in a BPF. Still, in many scenarios, a naive set-
based semantics yields several extensions for a given BPF, and hence is incon-
clusive. Then, we can use the notion of credulous and skeptical acceptance as
an additional assessment layer; in particular, we may ask the following ques-
tions. i) Given a set of arguments that includes burdened arguments (or, in the
case of multiple levels of burdens: arguments with a high level of burden), are
these arguments entailed by the skeptical extension we can infer? ii) Given a
set of arguments that are unburdened (or, in the case of multiple levels of bur-
dens: unburdened arguments or arguments with a low level of burden), are these
arguments entailed by at least one extension we can infer? Let us claim that
in the case of naive set-based semantics, the notions of credulous and skeptical
acceptance are more useful than the notion of undecided arguments in traditional
labeling-based approaches (see, e.g., Wu and Caminada [24]); all arguments that
are not entailed by a naive-based extension are in conﬂict with this extension
and hence, it is counter-intuitive to consider arguments that are not attacked by
the extension – and consequently, are attackers of the extension – as undecided.

The Burden of Persuasion in Abstract Argumentation
239
5
Discussion
From a formal theory perspective, our framework for modeling burdens of per-
suasion can be considered a contribution to the research area of argumentation
dynamics (see Doutre and Mailly [13] for a survey). At ﬁrst glance, this con-
nection may not be obvious. However, let us observe that we can model a BPF
AFBP = (⟨S0, ..., S1⟩, AT) as a sequence of normal expansions (see Deﬁnition 2)
⟨AF0, ..., AFn⟩, such that for AFi, 0 < i ≤n, AFi−1 ⪯N AFi. For example,
given the BPF AFBP = (⟨{a}, {b}, {c}⟩, {(a, b), (b, a), (b, c), (c, b)}), we have the
sequence of normally expanding argumentation frameworks ⟨AF0, AF1, AF2⟩=
⟨({a}, {}), ({a, b}, {(a, b), (b, a)}), ({a, b, c}, {(a, b), (b, a), (b, c), (c, b)})⟩.
Given this sequence (and an argumentation semantics σ), BP semantics applies
an abstract argumentation semantics and returns EXTS⊆−max
po−mon(EXTS⊆−max
po−mon
(σ(AF2), σ(AF0)), σ(AF0) ∪σ(AF1)).
Let us note that the formal framework we provide is fundamentally diﬀerent
from traditional approaches to model preferences in formal argumentation, such
as preference-based [1] and value-based [10] argumentation (where value-based
argumentation is a generalization of preference-based argumentation). While the
sequence of sets of arguments in a BPF can be considered as a total preference
order on non-intersecting sets of arguments, the way this order is interpreted by
BP semantics does not allow for the inference of sets of arguments that entail
conﬂicts; the order merely gives us a way to treat uncertainty (“doubt”) that is
inherent in the corresponding abstract argumentation framework. In contrast,
in preference-based argumentation, preferences may lead to a disregard of con-
ﬂicts. Colloquially speaking, we can summarize that value-based and preference-
based argumentation favor preferred arguments no matter what when drawing
inferences in face of contradictions, whereas our burden of persuasion approach
merely favors preferred sets of arguments if in doubt.
Still, let us note that our burden of persuasion frameworks and semantics
reﬂect the idea of using preferences on the set of arguments in an argumentation
framework to “narrow down” the extensions that an abstract argumentation
semantics returns. Work in this direction has been conducted by Kaci et al. [18],
as well as by Amgoud and Vesic [2]. For the sake of conciseness, let us informally
claim here that each BPF can be mapped to a preference-based argumentation
framework, but that the aforementioned approaches are fundamentally diﬀerent
to ours. For instance, let us claim that when considering the BPF AFBP =
⟨{a, c}, {b, d}⟩, {(a, b), (a, c), (b, a), (b, d)}) and preferred semantics, neither Kaci
et al.’s approach, nor the two approaches (democratic and elitist) introduced by
Amgoud and Vesic allow for inferring only the extension {a, d} but also infer the
extension {b, c}. However, as b carries the burden of persuasion, it should not be
able to defeat a, which then in turn can defeat the unburdened argument c. A
formal, detailed comparison can be considered promising future work.
Similarly, our approach is diﬀerent from argumentation with many lives in
which arguments and attacks have numeric weights and an argument is defeated
iﬀthe sum of the weights of successful attacks on the argument exceeds the
number of lives of the argument (roughly speaking) [17]. Similarly to value-

240
T. Kampik et al.
based argumentation, argumentation with many lives allows for the inference of
sets of arguments that are not conﬂict-free; also, it requires the assignment of
weights (quantiﬁcation) of arguments and attacks, which is not feasible in many
legal use cases.
From a legal perspective, let us note that the burden of persuasion is related
to, but diﬀerent from, the standard of persuasion [16] which, from a formal
argumentation perspective, relates more directly to the required strength of one
or several attackers to defeat an argument. Modeling standards of persuasion
in formal argumentation is certainly interesting future work, but not within the
scope of this paper.
Considering previous research on formal models of burdens of persuasion,
our work can be considered a continuation of recent research that introduces
the burden of persuasion to structured argumentation [11]. This model of the
burden of persuasion is based on grounded semantics and can be described –
from an abstract argumentation perspective – as follows.
1. Given an abstract argumentation framework AF = (AR, AT), we place the
burden of persuasion on the arguments in a set S ⊆AR.
2. We determine the grounded extension Egr of AF and say that an argument
a ∈AR is labeled as follows. IN if a ∈Egr; OUT if a ∈E+
gr; UND, otherwise.
We denote all arguments labeled IN by INgr(AF); all arguments labeled
OUT by OUTgr(AF); all arguments labeled UND by UNDgr(AF).
3. Based
on
the
grounded
labeling,
we
create
the
grounded
burden
of
persuasion
labeling
(BP
labeling).
A
BP-labeling
is
a
3-tuple
(IN BP (AF), OUT BP (AF), UNDBP ), such that ∀a ∈AR, the following
holds:
If a ∈S. a ∈IN BP (AF) if a ∈Egr; a ∈OUT BP (AF) if a ∈E+
gr or
a ∈(UNDgr(AF) \ S)+; a ∈UNDBP (AF), otherwise.
If a ̸∈S.) a ∈IN BP (AF) if a ̸∈E+
gr and ∀b ∈IN BP (AF), b does not attack
a; a ∈OUT BP (AF), otherwise.
This approach has shortcomings (even when only considering one burden of
persuasion level as above). Below we give two examples that also illustrate how
our framework addresses the issues.
Self-attacking Arguments. Consider the argumentation framework AF =
(AR, AT) = ({a, b, c, }, {(a, a), (a, b), (b, c)}) with the burden of persuasion
placed on {b}. Considering the approach by Calegari et al., we have: i) a is
UND; ii) b is initially undecided, and because it carries the burden of per-
suasion, it is ﬁnally out; iii) hence, c is in. This is problematic, because a as
a self-defeating argument should arguably not defeat b, even if the burden of
persuasion lies on b. In contrast, when using our approach we have the follow-
ing BPF: AFBP = (⟨{a, c}, {b}⟩, AT). σBP
SCF 2(AFBP ) = {{b}}; i.e., we infer {b}
because the burden of persuasion is not strong enough to allow for the defeat of
b by a self-attacking argument.
Consistent Defeat from Inconsistent Arguments. Consider the abstract
argumentation framework AF ′ = (AR′, AT ′) = ({a, b, c, d, e}, {(a, b), (b, a),

The Burden of Persuasion in Abstract Argumentation
241
(a, c), (b, c), (c, d), (d, e)}). What we have in this framework is a phenomenon
that we can colloquially describe as consistent defeat from inconsistent argu-
ments. We place the burden of persuasion on argument {d}. Let us apply the
approach by Calegari et al. a and b attack each other and are hence undecided,
but both arguments consistently attack c. Again considering three-valued label-
ing and grounded semantics, we have d is out and e is in. However, we claim that
we should conclude that c is out, because it is attacked by both a and b, and
that consequently, d is in and e is out. Let us highlight the diﬀerence to the pre-
vious example. In the previous example, we maintain it should be impossible to
infer a because a is inconsistent with itself. However, in this example, we main-
tain it should be impossible to infer “not d”, because we have to infer “either
a or b”, which implies the defeat of c. Our approach supports this intuition:
AF ′
BP = (⟨{a, b, c, d}, {e}⟩, AT ′) and σBP
SCF 2(AF ′
BP ) = {{a, d}, {b, d}}.
6
Conclusion
In this paper, we have introduced a formal framework for modeling the burden of
persuasion in abstract argumentation, which is accompanied by an open source
software implementation. The framework supports arbitrary many levels of bur-
dens, can be combined with any universally deﬁned argumentation semantics,
and addresses some open issues that previous works have identiﬁed in models of
burdens of persuasion for structured argumentation. By abstracting from struc-
tured argumentation speciﬁcs, the framework can be applied to a range of formal
argumentation variants.
Acknowledgments. We thank the anonymous reviewers for their thoughtful and
useful feedback. This work was partially supported by the Wallenberg AI, Autonomous
Systems and Software Program (WASP) funded by the Knut and Alice Wallenberg
Foundation.
Appendix - Proofs
Proposition 1. Let σ be an argumentation semantics. If σ is universally deﬁned
then σBP is universally deﬁned.
Proof. Let AFBP = (ARS, AT) be a BPF and ARS = ⟨S0, ..., Sn⟩. If n = 0,
by deﬁnition of σBP (Deﬁnition 23) it holds true that σBP (AFBP ) = σ(AF0).
Hence, the proposition holds true for n = 0. For n > 0, we provide a proof by
induction on n.
Base Case: n = 1. By deﬁnition of σBP , it holds true that σBP (AFBP ) =
EXTS⊆−max
po−mon(σ(AF1), σ(AF0)). Because σ is universally deﬁned, by deﬁ-
nition of EXTS⊆−max
po−mon (Deﬁnition 22), it holds true that |EXTS⊆−max
po−mon
(σ(AF1), σ(AF0))| ≥1. Hence, the proposition holds true for the base case.

242
T. Kampik et al.
Inductive Case: n = k + 1. By deﬁnition of σBP , it holds true that
σBP (AFBP ) = EXTS⊆−max
po−mon(σ(AFBP −1), σ(AF0) ∪... ∪σ(AFk+1)). Because
σ is universally deﬁned it holds true that |σ(AF0) ∪... ∪σ(AFk+1)| ≥1 and
from the base case and from the deﬁnition of EXTS⊆−max
po−mon it follows that
|σ(AFBP −1)| ≥1. Hence, σBP (AFBP ) is universally deﬁned for n = k + 1
and the proof follows from the inductive case.
⊓⊔
Proposition 2. Let σ be an argumentation semantics. If σ is universally
uniquely deﬁned then σBP is universally uniquely deﬁned.
Proof. Let AFBP = (ARS, AT) be a BPF and ARS = ⟨S0, ..., Sn⟩. If n = 0,
by deﬁnition of σBP (Deﬁnition 23) it holds true that σBP (AFBP ) = σ(AF0).
Hence, the proposition holds true for n = 0. For n > 0, we provide a proof by
induction on n.
Base
case:
n
=
1.
By
deﬁnition
of
σBP ,
it
holds
true
that
σBP (AFBP )
=
EXTS⊆−max
po−mon(σ(AF1), σ(AF0)). Because σ is universally
uniquely deﬁned, by deﬁnition of EXTS⊆−max
po−mon (Deﬁnition 22), it holds true
that |EXTS⊆−max
po−mon(σ(AF1), σ(AF0))| = 1. Hence, the proposition holds true
for the base case.
Inductive Case: n = k + 1. By deﬁnition of σBP , it holds true that
σBP (AFBP ) = EXTS⊆−max
po−mon(σ(AFBP −1), σ(AF0) ∪... ∪σ(AFk+1)). Because
σ is universally uniquely deﬁned it holds true that |σ(AF0)∪...∪σ(AFk+1)| ≥1
and from the base case and from the deﬁnition of EXTS⊆−max
po−mon it follows
that |σ(AFBP −1)| = 1. Hence, σBP (AFBP ) is universally uniquely deﬁned for
n = k + 1 and the proof follows from the inductive case.
⊓⊔
References
1. Amgoud, L., Cayrol, C.: Inferring from inconsistency in preference-based argumen-
tation frameworks. J. Autom. Reason. 29(2), 125–169 (2002). https://doi.org/10.
1023/A:1021603608656
2. Amgoud, L., Vesic, S.: Rich preference-based argumentation frameworks. Int. J.
Approx. Reason. 55(2), 585–606 (2014)
3. Baroni, P., Caminada, M., Giacomin, M.: Abstract argumentation frameworks and
their semantics. In: Baroni, P., Gabbay, D., Massimiliano, G., van der Torre, L.
(eds.) Handbook of Formal Argumentation. College Publications, chap. 4, pp. 159–
236. College Publications (2018)
4. Baroni, P., Gabbay, D.M., Giacomin, M., van der Torre, L.: Handbook of Formal
Argumentation. College Publications (2018)
5. Baroni, P., Giacomin, M.: On principle-based evaluation of extension-based argu-
mentation semantics. Artif. Intell. 171(10), 675–700 (2007)
6. Baroni, P., Giacomin, M., Guida, G.: SCC-recursiveness: a general schema for
argumentation semantics. Artif. Intell. 168(1), 162–210 (2005). https://doi.org/
10.1016/j.artint.2005.05.006

The Burden of Persuasion in Abstract Argumentation
243
7. Baumann, R., Brewka, G.: Expanding argumentation frameworks: enforcing and
monotonicity results. COMMA 10, 75–86 (2010)
8. Baumann, R., Brewka, G., Ulbricht, M.: Revisiting the foundations of abstract
argumentation-semantics based on weak admissibility and weak defense. In: AAAI,
pp. 2742–2749 (2020)
9. Bench-Capon, T., Prakken, H., Sartor, G.: Argumentation in legal reasoning. In:
Simari, G., Rahwan, I. (eds.) Argumentation in Artiﬁcial Intelligence, pp. 363–382.
Springer, Heidelberg (2009). https://doi.org/10.1007/978-0-387-98197-0 18
10. Bench-Capon, T.J.: Persuasion in practical argument using value-based argumen-
tation frameworks. J. Log. Comput. 13(3), 429–448 (2003)
11. Calegari, R., Riveret, R., Sartor, G.: The burden of persuasion in structured argu-
mentation. In: Proceedings of the Nineteenth International Conference on Artiﬁcial
Intelligence and Law, ICAIL ’21. Association for Computing Machinery, New York
(2021)
12. Cramer, M., van der Torre, L.: SCF2-an argumentation semantics for rational
human judgments on argument acceptability. In: Proceedings of the 8th Workshop
on Dynamics of Knowledge and Belief (DKB-2019) and the 7th Workshop KI\
& Kognition (KIK-2019) co-located with 44nd German Conference on Artiﬁcial
Intelligence (KI 2019), Kassel, Germany, 23 September 2019, pp. 24–35 (2019)
13. Doutre, S., Mailly, J.G.: Constraints and changes: a survey of abstract argumenta-
tion dynamics. Argum. Comput. 9, 223–248 (2018). https://doi.org/10.3233/AAC-
180425
14. Dung, P.M.: On the acceptability of arguments and its fundamental role in non-
monotonic reasoning, logic programming and n-person games. Artif. Intell. 77(2),
321–357 (1995)
15. Dvoˇr´ak, W., Gaggl, S.A.: Stage semantics and the SCC-recursive schema for argu-
mentation semantics. J. Logic Comput. 26(4), 1149–1202 (2014). https://doi.org/
10.1093/logcom/exu006
16. Friedman, R.D.: Standards of persuasion and the distinction between fact and law.
Northwest. Univ. Law Rev. 86, 916 (1991)
17. Gabbay, D.M., Rozenberg, G.: Introducing abstract argumentation with many
lives. FLAP 7(3), 295–336 (2020)
18. Kaci, S., van der Torre, L., Villata, S.: Preference in abstract argumentation. In:
Computational Models of Argument, pp. 405–412. IOS Press (2018)
19. Kampik, T., Gabbay, D.: The “Degrees of Monotony”-dilemma in abstract
argumentation. In: Vejnarov´a, J., Wilson, N. (eds.) Symbolic and Quantitative
Approaches to Reasoning with Uncertainty 2021. Springer, Cham (2021, to appear)
20. Prakken, H., Sartor, G.: A logical analysis of burdens of proof. In: Legal Evidence
and Proof: Statistics, Stories, Logic, pp. 223–253 (2009)
21. Thimm, M.: Tweety: a comprehensive collection of java libraries for logical aspects
of artiﬁcial intelligence and knowledge representation. In: Proceedings of the Four-
teenth International Conference on Principles of Knowledge Representation and
Reasoning, KR 2014, pp. 528–537. AAAI Press (2014)
22. van der Torre, L., Vesic, S.: The principle-based approach to abstract argumenta-
tion semantics. IfCoLog J. Log. Appl. 4(8), 2735–2778 (2017)
23. Verheij, B.: Two approaches to dialectical argumentation: admissible sets and argu-
mentation stages. Proc. NAIC 96, 357–368 (1996)
24. Wu, Y., Caminada, M.: A labelling-based justiﬁcation status of arguments. Stud.
Logic 3(4), 12–29 (2010)

Handling Support Cycles and Collective
Interactions in the Logical Encoding of
Higher-Order Bipolar Argumentation
Frameworks
Marie-Christine Lagasquie-Schiex(B)
Universit´e de Toulouse, IRIT, 118 route de Narbonne, 31062 Toulouse, France
lagasq@irit.fr
Abstract. In our paper [13], we have proposed a logical encoding of
argumentation frameworks with higher-order interactions (i.e. attacks or
supports whose targets are arguments or other attacks or supports) with
an evidential meaning for supports, such frameworks are called REBAF.
With this encoding, we are able to characterize the semantics of REBAF
under the form of speciﬁc logical models. Nevertheless this encoding
has two important drawbacks: ﬁrst the handling of support cycles has
some weaknesses and secondly the collective interactions (i.e. attacks or
supports whose source is a set of arguments and not only one argument)
are not taken into account. The current paper proposes an improvement
of this encoding for solving these drawbacks.
Keywords: Abstract argumentation · Logical translation ·
Higher-order interactions · Bipolar interactions
1
Introduction
Formal argumentation has become an essential paradigm in Artiﬁcial Intelli-
gence (see for instance [24]) and the original Dung’s argumentation framework
(AF) [15] is the cornerstone of this domain. An AF is a collection of arguments
interacting with each other through a relation reﬂecting conﬂicts between them,
called attack, and enables to determine acceptable sets of arguments called exten-
sions. Then AF have been extended along diﬀerent lines, e.g. by enriching them
with positive interactions between arguments (usually expressed by a support
relation, see for instance [9,17,25]), or higher-order interactions (i.e. interac-
tions whose targets are other interactions, see for instance [3,4,14,16,20,26]).
Note that there exist several interpretations of the support (deductive sup-
port [5], necessary support [22], evidential support [23]). Here is an example
of such frameworks in the legal ﬁeld (this example is an extension of an example
presented in [2]).
Example 1. The prosecutor says that the defendant had intention to kill the
victim (argument b). A witness says that she saw the defendant throwing a sharp
c
⃝Springer Nature Switzerland AG 2021
P. Baroni et al. (Eds.): CLAR 2021, LNAI 13040, pp. 244–265, 2021.
https://doi.org/10.1007/978-3-030-89391-0_14

Logical Encoding of REBAF
245
knife towards the victim (argument a). Argument a can be considered as a sup-
port for argument b. The lawyer argues back that the defendant was in a habit
of throwing the knife at his wife’s foot once drunk (argument c). This latter
argument is better considered attacking the support from a to b, than attacking
or supporting arguments a or b themselves. So, the prosecutor’s argumentation
seems no longer suﬃcient for proving the intention to kill.
□
Such frameworks are of interest when one wants to keep an abstract point of
view but with an enriched context. In [13], a logical encoding of argumentation
frameworks with higher-order attacks and supports has been proposed consid-
ering that the support meaning is the evidential one [23]1 (so we talk about
REBAF) and the acceptability semantics are deﬁned as in [7]. This encoding is
able to take into account REBAF but with two important drawbacks; ﬁrst we
will show that the handing of support cycles is unsuﬃcient, and secondly the
collective interactions (those whose source is not a single argument but a set
of arguments) are not taken into account. So our aim is to propose a solution
to these two drawbacks. The paper is organized as follows: the necessary back-
ground about argumentation frameworks is given in Sect. 2; the logical encoding
for frameworks with higher-order attacks and evidential supports (REBAF) is
recalled in Sect. 3; an analysis of the case of REBAF with support cycles is pre-
sented and a new proposition that can properly handle supports cycles is given
in Sect. 4; Sect. 5 is dedicated to the treatment of the collective interactions; and
Sect. 6 concludes the paper. Sketch of proof are given in Appendix A (complete
proofs and many examples can be found in [18,19]).
2
Background on REBAF Given in [7]
We recalled here the main deﬁnitions and properties concerning REBAF.
Deﬁnition 1 [7].
An
evidence-based
recursive
argumentation
framework
(REBAF) is a sextuple ⟨A, Ra, Re, s, t, P⟩where A, Ra and Re are three (pos-
sible inﬁnite) pairwise disjunct sets respectively representing arguments, attacks
and supports names, and where P ⊆A∪Ra∪Re is a set representing the prima-
facie elements that do not need to be supported. Functions s : (Ra∪Re) −→2A\∅
and t : (Ra ∪Re) −→(A ∪Ra ∪Re) respectively map each attack and support
to its source and its target.
Note that the source of attacks and supports is a set of arguments (so any
interaction is a collective one),2 the set P may contain arguments, attacks or
supports and no constraint on the prima-facie elements is assumed (they can be
1 This meaning allows to distinguish between two diﬀerent kinds of arguments: prima-
facie (those that are justiﬁed whenever they are not defeated) and standard argu-
ments (those that are not directly assumed to be justiﬁed and must inherit support
from prima-facie arguments through a chain of supports).
2 This kind of interactions has been introduced by [21] in the context of SETAF:
argumentation frameworks with attacks whose source is a set of arguments.

246
M.-C. Lagasquie-Schiex
attacked or supported). Note also that no constraint is given about the existence
or not of cycles; so support cycles, attack cycles or mixed cycles (with attacks
and supports) can appear in a REBAF.
Semantics of REBAF are deﬁned in [7] using the notion of structure: a struc-
ture plays the same role as an extension in the Dung framework, i.e. gives a set
of elements (arguments and interactions) that are “acceptable together”.
Deﬁnition 2 [7]. Let REBAF = ⟨A,Ra,Re,s,t,P⟩. A triple U = (S, Γ, Δ) is a
structure of REBAF iﬀS ⊆A, Γ ⊆Ra and Δ ⊆Re. Moreover, for any pair
of structures U = (S, Γ, Δ) and U ′ = (S′, Γ ′, Δ′), U ⊆U ′ iﬀ(S ∪Γ ∪Δ) ⊆
(S′ ∪Γ ′ ∪Δ′). A structure U is ⊆-maximal (resp. ⊆-minimal) iﬀevery U ′ that
satisﬁes U ⊆U ′ (resp. U ′ ⊆U) also satisﬁes U ′ ⊆U (resp. U ⊆U ′).
Some speciﬁc sets of elements w.r.t. a structure can be deﬁned:
Deﬁnition 3 [7]. Let REBAF = ⟨A,Ra,Re,s,t,P⟩and given a structure U =
(S, Γ, Δ),
• The sets of defeated elements w.r.t. U:
Def X(U)
def
= {x ∈X|∃α ∈Γ, s(α) ⊆S and t(α) = x} with X ∈{A, Ra, Re}
Def (U)
def
= Def A(U) ∪Def Ra(U) ∪Def Re(U)
• The set of supported elements Sup(U) is recursively deﬁned as follows:3
Sup(U)
def
= P ∪{t(α)|∃α ∈Δ ∩Sup(U\{t(α)}), s(α) ⊆(S ∩Sup(U\{t(α)}))}
• The set of unsupportable elements w.r.t. U:4
UnSupp(U)
def
= Sup(U ′) with U ′ = (Def A(U), Ra, Def Re(U))
• The set of unacceptable elements w.r.t. U: UnAcc(U)
def
= Def (U) ∪UnSupp(U)
• The set of unactivable attacks w.r.t. U:
UnAct(U)
def
= {α ∈Ra|α ∈UnAcc(U) or s(α) ∩UnAcc(U) ̸= ∅}
• The set of acceptable elements w.r.t. U: Acc(U)
def
= {x ∈A ∪Ra ∪Re | x ∈
Sup(U) and ∀α ∈Ra st t(α) = x, α ∈UnAct(U)}
Then using these sets, REBAF semantics can be deﬁned:
Deﬁnition 4 [7]. Let REBAF = ⟨A,Ra,Re,s,t,P⟩. Let U = (S, Γ, Δ), U is
• self-supporting iﬀ(S ∪Γ ∪Δ) ⊆Sup(U)
• conﬂict-free iﬀX∩Def Y (U)=∅for any (X, Y ) ∈{(S, A), (Γ, Ra), (Δ, Re)}
• U is admissible iﬀit is conﬂict-free and S ∪Γ ∪Δ ⊆Acc(U)
• complete iﬀit is conﬂict-free and Acc(U) = S ∪Γ ∪Δ
• grounded iﬀit is a ⊆-minimal complete structure
• preferred iﬀit is a ⊆-maximal admissible structure
• stable iﬀ(S ∪Γ ∪Δ) = UnAcc(U)
3 By abuse of notation, we write U\T instead of (S\T, Γ\T, Δ\T) with T ⊆(A∪Ra ∪
Re).
4 Let X be a subset of a set Y , X denotes the set complement of X w.r.t. Y . Here Y
will be A, Ra, Re or their union, depending of the context.

Logical Encoding of REBAF
247
Example 1 (cont’d): The argumentation framework corresponding to the
example given in the introduction can be represented as follows (argument names
are given in circular nodes, interaction names in square nodes, prima-facie ele-
ments are in grey nodes and non prima-facie element in white nodes; attacks are
represented by simple edges and supports by double edges):
a
α
b
β
c
In this framework, neither β nor its source is attacked and β and its source
are prima-facie. So, for any structure U, it holds that neither β nor its source c is
unacceptable w.r.t. U. As a consequence, for any structure U, α is not acceptable
w.r.t. U as α is attacked by β and β is not unactivable w.r.t. U.
As b is not prima-facie, and α is the only support to b, no admissible structure
contains b. As a consequence, there is a unique complete, grounded, preferred
and stable structure U = ({a, c}, {β}, ∅).
□
3
Background on the Logical Description of a REBAF
Given in [13]
The logical description of a REBAF proposed in [13] allows an explicit repre-
sentation of arguments, attacks, evidential supports and their properties using
ﬁrst-order logics with the binary equality predicate.
Note that, in [13], only a variant of REBAF has been considered in which
interactions are restricted to binary interactions (that is for any interaction α,
s(α) is a singleton). This restriction is one of the drawbacks we are interested in
and will be removed in Sect. 5.
Note also that the quantiﬁers ∃and ∀range over some domain D. To restrict
them to subsets of D, bounded quantiﬁers are used: ∀x ∈E (P(x)) means
∀x(E(x) →P(x)).
The following tables give respectively the used vocabulary, the formulae
describing a given REBAF and those describing the four diﬀerent principles used
in REBAF semantics5 and the logical bases built using the previous formulae.
5 Note that the conﬂict-freeness principle is expressed by the formulae (1), (2), (3),
(2bis), (3bis).

248
M.-C. Lagasquie-Schiex
Vocabulary for the logical description of a REBAF
Predicate symbol
Meaning
Arg(x)
x is an argument
Attack(x) (resp. ESupport(x))
x is an attack (resp. evidential support)
P rimaF acie(x)
x is a prima-facie element
Acc(x)
x is accepted, with x ∈A
NAcc(x)
x cannot be accepted, with x ∈A
V al(α)
α is valid, with α ∈(Ra ∩Re)
Supp(x)
x is supported, with x ∈(A ∪Ra ∩Re)
UnSupp(x)
x is unsupportable, with x ∈(A ∪Ra ∩Re)
eAcc(x)
x is accepted and supported, with x ∈A
eV al(α)
α is valid and supported, with α ∈(Ra ∩Re)
Function symbol
Meaning
T (α) (resp. S(α))
denotes the target (resp. source) of α, with α ∈(Ra ∩Re)
Note that the word “accepted” used for giving the meaning of the predicat
Acc is a relic of a previous work in which only attacks have been taken into
account (see [12]). Here, considering that an argument must also be supported
(see Deﬁnition 3), the meaning of Acc is so closer to the notion of defence,
whereas the predicate eAcc corresponds to the acceptability in the sense of Def-
inition 3 (defence and support).
Logical Theory for Describing any REBAF: Description of the impact of
an attack or a support to its target; and constraint on the variables: any variable
must correspond either to an argument, or an attack, or a support (exclusive or)
(1)
∀x ∈(Attack ∪ESupport) ∀y ∈Attack
((eV al(y) ∧(T (y) = x) ∧eAcc(S(y))) →¬V al(x))
(2)
∀x ∈Arg ∀y ∈Attack ((eV al(y) ∧(T (y) = x) ∧eAcc(S(y))) →NAcc(x))
(3)
∀x ∈Arg (NAcc(x) →¬Acc(x))
(1bis) ∀x ∈(Attack ∪ESupport ∪Arg) ((P rimaF acie(x) ∨
∃y ∈ESupport (eV al(y) ∧(T (y) = x) ∧eAcc(S(y)))) →Supp(x))
(2bis) ∀x ∈Arg ((Acc(x) ∧Supp(x)) ↔eAcc(x))
(3bis) ∀x ∈(Attack ∪ESupport)
((V al(x) ∧Supp(x)) ↔eV al(x))
(4)
∀x (Attack(x) →¬Arg(x))
(4bis) ∀x (Attack(x) →¬ESupport(x))
(4ter) ∀x (ESupport(x) →¬Arg(x))
(5)
∀x (Arg(x) ∨Attack(x) ∨ESupport(x))
Logical Encoding of Speciﬁcities of a Given REBAF = ⟨A,Ra,Re,s,t,P⟩,
A = {a1, . . . an}, Ra = {α1, . . . , αk}, Re = {αk+1, . . . , αm}, P = {x1, . . . xl}
(6)
(S(α) = a) ∧(T (α) = b) for all α ∈Ra ∪Re with s(α) = a and t(α) = b
(7)
∀x (Arg(x) ↔(x = a1) ∨. . . ∨(x = an))
(8)
∀x (Attack(x) ↔(x = α1) ∨. . . ∨(x = αk))
(8bis) ∀x (ESupport(x) ↔(x = αk+1) ∨. . . ∨(x = αm))
(8ter) ∀x (P rimaF acie(x) ↔(x = x1) ∨. . . ∨(x = xl))
(9)
ai ̸= aj for all ai, aj ∈A with i ̸= j
(10)
αi ̸= αj for all αi, αj ∈Ra ∪Re with i ̸= j
Logical formalisation of REBAF semantics (4 principles)
Self-supporting principle: Each supported element must receive evidential
support (so either it is prima-facie, or it is the target of an e-valid support

Logical Encoding of REBAF
249
from an e-accepted source). And elements that are unsupportable cannot be
supported.
(17)
∀x ∈(Attack ∪ESupport ∪Arg)
⎛
⎜
⎜
⎝
Supp(x) →
⎛
⎝
P rimaF acie(x)∨
∃y ∈ESupport
(eV al(y) ∧(T (y) = x) ∧eAcc(S(y)))
⎞
⎠
⎞
⎟
⎟
⎠
(18)
∀x ∈(Attack ∪ESupport ∪Arg)
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎝
UnSupp(x) ↔
⎛
⎜
⎜
⎜
⎜
⎜
⎝
¬P rimaF acie(x) ∧
∀y ∈ESupport(T (y) = x →
⎛
⎜
⎝
∃β ∈Attack(T (β) ∈{S(y), y}∧
eV al(β) ∧eAcc(S(β))))
∨UnSupp(S(y))
∨UnSupp(y))
⎞
⎟
⎠
⎞
⎟
⎟
⎟
⎟
⎟
⎠
⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎠
Defence Principle: An attacked element is “accepted” only if for each attack
against it, either the source or the attack itself is defeated (by an e-valid attack
from an e-accepted argument), or the source or the attack itself is unsupportable
(w.r.t. e-valid elements and e-accepted arguments).
(11)
∀α ∈Attack
⎛
⎜
⎜
⎜
⎝
Acc(T (α)) →
⎛
⎜
⎝
∃β ∈Attack(T (β) ∈{S(α), α}
∧eV al(β) ∧eAcc(S(β)))
∨UnSupp(S(α))
∨UnSupp(α)
⎞
⎟
⎠
⎞
⎟
⎟
⎟
⎠
(12)
∀α
∈
Attack
∀δ
∈
(Attack ∪
ESupport)
⎛
⎜
⎜
⎜
⎝
((δ = T (α)) ∧V al(δ)) →
⎛
⎜
⎝
∃β ∈Attack(T (β) ∈{S(α), α}
∧eV al(β) ∧eAcc(S(β)))
∨UnSupp(S(α))
∨UnSupp(α)
⎞
⎟
⎠
⎞
⎟
⎟
⎟
⎠
Reinstatement Principle: This is a dual principle of that of defence. So an
attacked element is “accepted” if for each attack against it, either the source or
the attack itself is defeated (by an e-valid attack from an e-accepted argument),
or the source or the attack itself is unsupportable
(13)
∀c ∈Arg (
⎛
⎜
⎜
⎜
⎜
⎜
⎝
∀α ∈Attack
⎛
⎜
⎜
⎜
⎝
T (α) = c →
⎛
⎜
⎝
∃β ∈Attack(T (β) ∈{S(α), α} ∧
eV al(β) ∧eAcc(S(β)))
∨UnSupp(S(α))
∨UnSupp(α)
⎞
⎟
⎠
⎞
⎟
⎟
⎟
⎠
⎞
⎟
⎟
⎟
⎟
⎟
⎠
→Acc(c))
(14)
∀δ ∈(Attack ∪ESupport) (
⎛
⎜
⎜
⎜
⎜
⎜
⎝
(∀α ∈Attack
⎛
⎜
⎜
⎜
⎝
T (α) = δ →
⎛
⎜
⎝
∃β ∈Attack(T (β) ∈{S(α), α} ∧
eV al(β) ∧eAcc(S(β)))
∨UnSupp(S(α))
∨UnSupp(α)
⎞
⎟
⎠
⎞
⎟
⎟
⎟
⎠
⎞
⎟
⎟
⎟
⎟
⎟
⎠
→V al(δ))
Stability Principle: If an element is not “accepted” (resp. supported) then
it must be attacked by the structure (resp. unsupportable w.r.t. the structure)
(15)
∀c ∈Arg (¬Acc(c)
→

∃β ∈Attack(T (β) = c ∧
eV al(β) ∧eAcc(S(β)))
	
)
(16)
∀α ∈(Attack ∪ESupport) (¬V al(α)
→

∃β ∈Attack(T (β) = α ∧
eV al(β) ∧eAcc(S(β)))
	
)
(19)
∀x ∈(Arg ∪Attack ∪ESupport) (¬Supp(x) →UnSupp(x))
Five
Logical
Bases
for
Encoding
a
REBAF
and
Its
Semantics
Σ(REBAF) = {(1), . . . , (10)}
Σss(REBAF) = Σ(REBAF) ∪{(17), (18)}
Σd(REBAF) = Σss(REBAF) ∪{(11), (12)}
Σr(REBAF) = Σss(REBAF) ∪{(13), (14)}
Σs(REBAF) = Σss(REBAF) ∪{(15), (16), (19)}
[13] proposed characterizations of the REBAF structures under diﬀer-
ent semantics in terms of models of the previous bases. Let REBAF =
⟨A,Ra,Re,s,t,P⟩. Let Σx be one of these bases. Given I an interpretation of
Σx, we deﬁne UI = (SI, ΓI, ΔI) with: SI = {x ∈A|I(eAcc(x)) = true},

250
M.-C. Lagasquie-Schiex
ΓI = {x ∈Ra|I(eV al(x)) = true} and ΔI = {x ∈Re|I(eV al(x)) = true}.
Moreover, let I be a model of Σx, I is a ⊆-maximal (resp. minimal) model of
Σx iﬀthere is no model I′ of Σx with (SI∪ΓI∪ΔI) ⊂(resp. ⊃) (SI′ ∪ΓI′ ∪ΔI′).
Two diﬀerent characterizations are given in [13], one for REBAF without
support cycles and another for REBAF with support cycles. In both cases, the
idea is that a structure gathers the acceptable elements w.r.t. it. In this paper, we
are interested in the second one in which only some models must be considered.
Deﬁnition 5 (Def. 6.1 in [13]). I is a support-founded interpretation iﬀfor
each argument (resp. support) x s.t. Σss(REBAF) |= Supp(x) →eAcc(x) (resp.
eV al(x)), it holds that I(eAcc(x)) (resp. I(eV al(x))) = false, I(UnSupp(x)) =
true. Then a support-founded model of Σd(REBAF) is a support-founded inter-
pretation which is a model of Σd(REBAF).
In [13], this deﬁnition has been used for characterizing admissible structures
(and some other kinds of structures) of a given REBAF with support cycles by
a subclass of models of Σd(REBAF):
Proposition 1 (Prop. 6.2 in [13]). Let REBAF = ⟨A,Ra,Re,s,t,P⟩with only
binary interactions. Let U = (S, Γ, Δ) be a structure on REBAF.
• U is admissible iﬀthere exists a support-founded model I of Σd(REBAF) with
U = UI.
• U is complete iﬀthere exists a support-founded model I of (Σd(REBAF) ∪
Σr(REBAF)) with U = UI.
• U is a preferred structure iﬀthere exists a ⊆-maximal support-founded model
I of Σd(REBAF) with U = UI.
• U is the grounded structure iﬀU = UI where I is a ⊆-minimal support-
founded model of (Σd(REBAF) ∪Σr(REBAF)).
4
REBAF with Support Cycles: Analysis and New
Proposition
In this section, the deﬁnition of support-founded models is discussed using exam-
ples and we show that it leads to a characterisation of REBAF semantics that
only holds when considering REBAF with speciﬁc cycles. First of all, some deﬁ-
nitions about supports cycles must be given before analysing the impact of such
support cycles in the logical computation of structures for the REBAF.
Deﬁnition 6. Let REBAF = ⟨A,Ra,Re,s,t,P⟩. A directed cycle of supports
(DCS) in this REBAF is a sequence C = (x0, . . . , xn−1, xn), n > 0, such that:6
6 By abuse of language, the set of the elements composing C will be also denoted by
C. So C will be used with set operators as ∩ou ∪and will be comparable with other
sets.

Logical Encoding of REBAF
251
• ∀i = 0 . . . n, xi ∈A ∪Re and xn = x0 (n is the size of the DCS),
• ∀i = 0 . . . n −1, if xi ∈A then xi+1 ∈Re and s(xi+1) = xi,
• ∀i = 0 . . . n −1, if xi ∈Re then xi+1 = t(xi).
A simple DCS C = (x0, . . . , xn−1, xn) is a DCS in which ∀i, j = 0 . . . n −1, if
i ̸= j then xi ̸= xj.
Let C = (x0, . . . , xn−1, xn) and C′ = (x′
0, . . . , x′
m−1, x′
m) be two DCS of this
REBAF s.t. there exist xi ∈C and x′
j ∈C′ and xi = x′
j. The aggregation of C
and C′, denoted by C ∪C′, is the directed cycle corresponding to the union of
the sets {x0, . . . , xn−1} and {x′
0, . . . , x′
m−1}.
Let C = (x0, . . . , xn−1, xn) be a DCS. C is a maximal DCS iﬀthere does not
exist another DCS that could be aggregated with C.
Two counterexamples of Prop. 6.2 in [13] (numbered 1 here) can be exhibited
showing that the deﬁnition given for support founded models (Deﬁnition 5) is
not suﬃcient to avoid some problematic models.
Example 2. Consider 3 simple DCS that can be agglomerated into a non-simple
DCS with P = {α1, α2, α3, β1, β2, β3}.
α1
α2
α3
a
b
c
d
β1
β2
β3
Here Σss does not entail Supp(x) →eAcc(x) for x ∈{a, b, c, d}. So Deﬁnition 5
cannot be used in order to remove models in which a (resp. b, c, d) is supported
by itself. The origin of this problem is the fact that, following Formula (17), the
existence of several supporters for b and c prevents the entailment described in
Deﬁnition 5: Σss |= Supp(c) →(eAcc(c) ∨eAcc(b)) and not Σss |= Supp(c) →
eAcc(c).
□
Example 3. Consider an attacked argument that supports an even-length sup-
port cycle C = (a, α, b, β, a) with P = {c, d, π, μ, α, β}.
α
c
π
d
μ
a
b
β
Once again Deﬁnition 5 is not enough for removing the model I of Σd with
SI = {a, b, c}, ΓI = {π} and ΔI = {α, β, μ}. And the structure (SI, ΓI, ΔI) is
not admissible since it is not self-supporting in the sense of Deﬁnition 3: there is
no chain of supported supports leading to a (resp. to b) rooted in a prima-facie
argument that belongs to the structure (since d is attacked and not defended). □

252
M.-C. Lagasquie-Schiex
Thus, Deﬁnition 5 is not suﬃcient in the general case. In order to identify
the elements that cannot be supported without themselves, the main point must
be to ﬁnd the elements of the REBAF that would be able to play a role for
supporting the elements of a cycle. That leads us to deﬁne the impacting support
chains for an element of a REBAF. Informally an impacting support chain for an
element x is a sequence targeting x, originated in a prima-facie argument and
composed alternatively by “an argument, a support, an argument, a support,
. . . ”. Moreover no repetition is authorized (so any element appears only one
time in the sequence); and x cannot belong to the sequence. Note that the
existence of such a chain for an element x does not imply that x is supported
(it is just a necessary condition for this supportability).
Deﬁnition 7. Let REBAF = ⟨A,Ra,Re,s,t,P⟩. Let x be an element of this
REBAF. An impacting support chain for x is a sequence ISC = (x0, . . . , xn)
with n > 0 and:
• ∀i ∈[0 . . . n], xi ∈(A ∪Re) \ {x}, x0 ∈A ∩P, xn ∈Re s.t. t(xn) = x,
• ∀i, j ∈[0 . . . n], if i ̸= j, then xi ̸= xj,
• ∀i ∈[1 . . . n], if xi ∈Re then xi−1 = s(xi) and if xi ∈A then xi = t(xi−1).
Example 2 (cont’d): Here, for any element, there is no impacting support
chain.
□
Example 3 (cont’d): Considering the arguments in the cycle, argument a has
one ISC, (d, μ), and argument b has also one ISC, (d, μ, a, α).
□
Example 4. Here 2 simple DCS are interconnected and can be aggregated: C =
(a, α, β, c, γ, d, δ, a) and C′ = (b, β, c, γ, d, μ, b) with P = {e, π, μ, α, δ, γ}.
b
e
a
α
β
μ
π
c
γ
d
δ
Considering
the
impacting
support
chains of some elements of the DCS,
we have for instance:
• The ISC for d: (e, π).
• The ISC for c: (e, π, d, μ, b, β).
• The ISC for a: (e, π, d, δ).
• The ISC for β: (e, π, d, δ, a, α).
□
Moreover we must also take into account the fact that the existence of sup-
port cycles has an impact on the UnSupp predicate. Considering for instance
a REBAF reduced to a simple DCS (a, α, b, β, a) with P = {α, β}, for any
structure U, UnSupp(U) = {a, b}, whereas a model I of Σss exists in which
I(UnSupp(a)) = I(UnSupp(b)) = false that does not reﬂect the reality con-
cerning the “unsupportable” status of a and b.
All the previous remarks lead to the following improvement of the notion of
support-founded interpretation given in [13]:
Deﬁnition 8. Let REBAF = ⟨A,Ra,Re,s,t,P⟩. I is a support-founded interpre-
tation iﬀthe two following conditions hold:

Logical Encoding of REBAF
253
1. for each argument (resp. support) x non prima-facie, belonging to a maxi-
mal DCS and s.t. I(eAcc(x)) = true (resp. I(eV al(x)) = true), there exists
at least one impacting support chain ISC = (x0, . . . , xn) for x that is sat-
isﬁed by I, i.e. ∀xi ∈ISC, if xi ∈A then I(eAcc(xi)) = true, otherwise
I(eV al(xi)) = true;
2. for each element x of REBAF, I(UnSupp(x)) = true iﬀx ∈UnSupp(UI).
Let Σx be a base of formulae built over REBAF. A support-founded model
of Σx is a support-founded interpretation which is a model of Σx.
Using Deﬁnition 8, the characterization of REBAF semantics becomes:7
Proposition 2. Let REBAF = ⟨A,Ra,Re,s,t,P⟩with only binary interactions.
Let U = (S, Γ, Δ) be a structure on REBAF.
1. U is admissible iﬀthere exists a support-founded model I of Σd(REBAF) (in
the sense of Deﬁnition 8) with U = UI.
2. U is complete iﬀthere exists a support-founded model I of (Σd(REBAF) ∪
Σr(REBAF)) (in the sense of Deﬁnition 8) with U = UI.
3. U is a preferred structure iﬀthere exists a ⊆-maximal support-founded model
I of Σd(REBAF) (in the sense of Deﬁnition 8) with U = UI.
4. U is the grounded structure iﬀU = UI where I is a ⊆-minimal support-
founded model of (Σd(REBAF) ∪Σr(REBAF)) (in the sense of Deﬁnition 8).
5. U is stable iﬀthere exists I support-founded model of Σs(REBAF) (in the
sense of Deﬁnition 8) with U = UI.
Let us illustrate the above results on the previous examples:
Example 2 (cont’d): Apply Proposition 2 leads to the unique complete, pre-
ferred, stable and grounded structure (∅, ∅, {α1, α2, α3, β1, β2, β3}).
□
Example 3 (cont’d): Apply Proposition 2 leads to the unique complete, pre-
ferred, stable and grounded structure ({c}, {π}, {α, β, μ}).
□
Example 4 (cont’d): Apply Proposition 2 leads to the unique complete, pre-
ferred, stable and grounded structure ({a, b, c, d, e}, ∅, {α, β, γ, δ, π, μ}).
□
5
Collective Interactions in REBAF: Impact on the
Logical Encoding
Considering the logical translation of a REBAF, it remains a constraint given
in [13] that must be relaxed since, here, we want to handle collective interactions.
First consider an example that shows how the source of a collective interaction
that is not reduced to a singleton can impact the computation of structures.
7 Note that this proposition is more complete that Prop. 6.2 in [13] (numbered Propo-
sition 1 here) since stable semantics is also taken into account.

254
M.-C. Lagasquie-Schiex
Example 5. In this example, there are a collective attack and a collective sup-
port using the same source (this source is graphically represented by a “dotted
diamond” containing the elements composing the source). Arguments c and e are
the only elements that are not prima-facie.
b
c
β
d
π
f
ϵ
e
Since c is unsupportable, then neither β nor ϵ can be activable and there is
one preferred structure that is: ({b, d}, {β, π}, {ϵ}). Trivially, an interaction can
be activable w.r.t. a structure only if all the arguments in its source are in this
structure.
Consider now the 3 types of changes that must be done in the encoding in
order to handle collective interactions: a change in the vocabulary, a change in
the formulae, and a change related to the impact of support cycles.
Vocabulary. We must now express the fact that the source of an interaction can
be a set of arguments and so that a given argument belongs to the source of a
given interaction. So the old unary function S becomes now a binary predicate:
S(a, α) means that “the argument a belongs to the source of α”
Formulae. What happens to the formulae in which sources appear? Three cases
occur and each case corresponds to a particular behaviour:8
• The source is used as a parameter in the predicate eAcc; in this case, the idea
is that the source of an interaction is e-accepted iﬀall the arguments belonging
to this source are also e-accepted; so the old formula eAcc(sα) corresponds
to: ∀a ∈Arg(S(a, α) →eAcc(a))
• The source is used as a parameter in the predicate UnSupp; in this case,
the idea is that the source of an interaction is unsupportable iﬀat least one
argument belonging to this source is also unsupportable; so the old formula
UnSupp(sα) corresponds to: ∃a ∈Arg(S(a, α) ∧UnSupp(a))
• The source is used as a parameter in the equality predicate; here two subcases
are possible depending of the aim of this equality in the formulae:
• either this equality is used for testing if a given argument a belongs to
the source of an interaction α and so the old equality sα = a becomes a
logical or between all the elements of the source:
(a1 = a) ∨(a2 = a), ∨. . . ∨(an = a), for s(α) = {a1, a2, . . . , an}
that is equivalent to: ∃x ∈Arg(S(x, α) ∧x = a)
8 Note that a formula as x ∈{sy, y} is just a shortcut for (x = sy) ∨(x = y) (see for
instance formulae (18) and (11) to (14)).

Logical Encoding of REBAF
255
• or this equality is used for deﬁning the source of an interaction α with a
given argument a and so the old equality sα = a becomes a logical and
between all the elements of the source:
S(a1, α) ∧S(a2, α), ∧. . . ∧S(an, α), for s(α) = {a1, a2, . . . , an}
This last case appears only in formula (6). In the other formulae, the ﬁrst
case applies when an equality appears.
Of course formulae (1) to (19) could be rewritten using the new formalism
but the result becomes hard to read. So, our choice is to keep the old formulae in
which the predicates applied to a source are considered as the shortcut deﬁned
as previously. For instance, formula (2) can be kept (shortcuts shown in a box):
∀x ∈Arg ∀y ∈Attack

eV al(y) ∧(ty = x) ∧eAcc(sy)

→NAcc(x)

but that means (formulae corresponding to the shortcuts shown in a box):
∀x ∈Arg ∀y ∈Attack
 
eV al(y) ∧(ty = x) ∧∀xi ∈Arg(S(xi, y) →eAcc(xi))

→NAcc(x)

Another example is formula (11), we keep:
∀α ∈Attack
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎝
Acc(tα)
→
⎛
⎜
⎜
⎜
⎝
∃β ∈Attack
((tβ = α ∨tβ = sα ) ∧eV al(β) ∧eAcc(sβ) )
∨UnSupp(sα)
∨UnSupp(α)
⎞
⎟
⎟
⎟
⎠
⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎠
but that means:
∀α ∈Attack
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎝
Acc(tα)
→
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎝
∃β ∈Attack
((tβ = α ∨∃x ∈Arg(S(x, α) ∧tβ = x) )
∧eV al(β) ∧∀x ∈Arg(S(x, β) →eAcc(x) )
∨∃x ∈Arg(S(x, α) ∧UnSupp(x))
∨UnSupp(α)
⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎠
⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎠
As it has already been said, the only exception of this use of shortcut is
formula (6) that is very speciﬁc and must be rewritten; the old formula
(sα = a) ∧(tα = b) for all α ∈Ra ∪Re with s(α) = a and t(α) = b
becomes:
S(a1, α) ∧. . . ∧S(an, α) ∧(tα = b) for all α ∈Ra ∪Re
with s(α) = {a1, . . . , an} and t(α) = b
Note that the deﬁnition of the bases of formulae remains unchanged.
At this point, it is worth to note that if there is no support cycles in the
REBAF then the use of the formulae bases is enough for characterizing the
REBAF semantics without the removal of some models. So the diﬃculty comes
with the existence of these cycles and implies that we are able to remove the
models in which an element is supported only because it is satisﬁed by these

256
M.-C. Lagasquie-Schiex
models (so with no supported supports without itself contrary to what is required
in Deﬁnition 3). The detection of such models was exactly the aim of Deﬁnition 8.
Nevertheless, since we now want to take into account collective supports,
some questions appear:
• “Is Deﬁnition 8 enough for characterizing support-founded models when col-
lective supports exist in the REBAF?”
• and more generally “How to take into account support cycles when we have
collective supports?”.
The answer to these questions implies new deﬁnitions for DCS and support-
founded interpretations.
Support Cycles and Collective Interactions. First we must adapt the pre-
vious deﬁnitions about support cycles in order to take into account collective
interactions. Concerning the deﬁnition of DCS, the important point is the fact
that, in a cycle, the targets and the sources must be clearly identiﬁed since they
could be diﬀerent (an interaction can only target one element of the source of
another interaction):
Deﬁnition 9. Let REBAF = ⟨A,Ra,Re,s,t,P⟩. A directed cycle of supports
(DCS) in this REBAF is a sequence C = (x0, . . . , xn−1, xn) such that:9
• n > 0 and n is the size of the DCS
• ∀i = 0 . . . n, either xi ∈Re, or xi = (a, S) with S ∈2A \ ∅and a ∈A ∩S (a
is called the “target ﬁeld” of xi and S is called the “source ﬁeld” of xi),
• xn = x0
• ∀i = 0 . . . n −1, if xi = (a, S) ∈(A, 2A \ ∅) then xi+1 ∈Re and s(xi+1) = S,
• ∀i = 0 . . . n −1, if xi ∈Re then
• if xi+1 ∈Re then t(xi) = xi+1
• if xi+1 = (a, S) ∈(A, 2A \ ∅) then t(xi) = a.
A simple DCS C = (x0, . . . , xn−1, xn) is a DCS in which ∀i, j = 0 . . . n −1,
if i ̸= j then xi ̸= xj.
Note that a DCS is now an “hybrid” sequence composed either with inter-
actions, or with pairs (an argument, a non-empty set of arguments). The other
deﬁnitions (for aggregation and maximal DSC) remain unchanged.
Example 6. This example gives an example of support cycles with an higher-
order support. Here β, d and e are not prima-facie.
9 We use the same notation as the one given in Deﬁnition 6. So here too, by abuse of
language, the set of the elements composing C will be also denoted by C and C will
be used with set operators as ∩ou ∪and will be comparable with other sets.

Logical Encoding of REBAF
257
b
c
a
d
α
β
γ
e
Here there is one DCS: ((d, {a, d}), α, β, (e, {e}), γ, (d, {a, d})).
Note that the only preferred structure is ({a, b, c}, ∅, {α, γ}).
It is also interesting to notice that a DCS can be represented by several
sequences (n sequences if n is the size of the DCS, each sequence being obtained
by shifting to the right – or to the left). For instance, the DCS of this REBAF
can also be expressed with: (β, (e, {e}), γ, (d, {a, d}), α, β).
Example 7. This example gives an example of several support cycles that can
be aggregated
β1
α2
e
γ
d
a
b
c
α1
β2
Here there are three DCS (only the last one is a maximal DCS):
• ((d, {d}), β1, (a, {a, b}), α1, (d, {d}))
• ((c, {c}), β2, (b, {a, b}), α2, (c, {c}))
• ((d, {d}), β1, (a, {a, b}), α2, (c, {c}), β2, (b, {a, b}), α1, (d, {d}))
The interesting point is the fact that the set {a, b} that is the source of α1 and
α2 corresponds to two distinct elements in a DCS: (a, {a, b}) and (b, {a, b}); and
each of them can be used as the preceding element of the supports α1 or α2 in
the DCS.
Note that the only preferred structure is ({e, d, a}, ∅, {α1, α2, β1, β2, γ}).
Consider now the notion of impacting support chain. The following example
shows that this notion must also be improved:
Example 8. Consider the following REBAF with only arguments and supports;
among these, there exist 2 collective supports (one from {a, b} to x and the
another one from {c, d, e} to y).

258
M.-C. Lagasquie-Schiex
a0
d0
e0
e′
0
α1
α2
α3
α4
a
b
c
d
e
β1
β2
x
y
γ1
γ2
z
Let consider the elements that impact the supported status of argument z.
Clearly simple chains are not enough and we must use the notion of “trees”;
indeed, any element of the source of a collective support must be supported if we
want the target of this support to be also supported. Here, three “trees” must be
taken into account for computing the supported status of z:
a0
α1
a
b
β1
x
γ1
d0
e0
α2
α3
c
d
e
β2
y
γ2
d0
e′
0
α2
α4
c
d
e
β2
y
γ2
The previous example gives the main ideas for deﬁning the notion of impact-
ing support tree for an element of the REBAF:

Logical Encoding of REBAF
259
Deﬁnition 10. Let REBAF = ⟨A,Ra,Re,s,t,P⟩. Let x be an element of this
REBAF. An impacting support tree for x is a set IST = {x0, . . . , xn} with
n > 0 s.t.:
• ∀xi, i ∈[0 . . . n], xi ∈(A ∪Re) \ {x} and is called a node of the tree;
• Let ISTP = (IST ∩P ∩A). ISTP ̸= ∅;
• !∃xi ∈IST s.t. xi ∈Re and t(xi) = x; xi is called the root of the tree;10
• ∀i, j ∈[0 . . . n], if i ̸= j, then xi ̸= xj;
• ∀xi ∈IST ∩A, either ∃xj ∈IST ∩Re s.t. xi = t(xj), or xi ∈ISTP (in this
case xi is called a leaf of the tree);
• ∀xi ∈IST ∩Re, ∀xj ∈s(xi), xj ∈IST.
Note that, as in Deﬁnition 7, an element x cannot belong to its impacting
support tree, and by deﬁnition non repetition is authorized.
Example 5 (cont’d): There is no IST for any interaction or argument. Indeed
the only element that is the target of a support is e and e has no IST, because the
support ϵ cannot belong to an IST for e (one argument of its source, c, cannot
belong to an IST; it is neither prima-facie, nor targeted by a support).
□
Example 6 (cont’d): Considering the existence of the DCS and the fact that
d in this DCS needs to be supported without itself, there is no IST for d (idem
for β and e).
□
Example 7 (cont’d): In this example, considering the non prima-facie elements,
there are an IST for d ({γ, e}) and another for a ({β1, d, γ, e}), but nothing for
c, nor b. Indeed, c needs the support of b and b needs the support of c, so its
own support that is forbidden by Deﬁnition 3.
□
Example 8 (cont’d): Considering a, there is one IST = {α1, a0}. Considering
d, there is one IST = {α2, d0}. Considering e, there are two IST, {α3, e0} and
{α4, e′
0}. Considering z, there are three IST:
• {γ1, x, β1, a, b, α1, a0} (root: γ1, leaves: a0 and b),
• {γ2, y, β2, c, d, e, α2, d0, α3, e0} (root: γ2, leaves: c, d0 and e0),
• {γ2, y, β2, c, d, e, α2, d0, α4, e′
0} (root: γ2, leaves: c, d0 and e′
0).
The other elements of the REBAF have no IST.
□
Characterization: A New Proposition. The previous deﬁnition completed
by the constraint concerning the unsupportable status of the element11 leads to
the following new deﬁnition for support-founded interpretations and models:
Deﬁnition 11. Let REBAF = ⟨A,Ra,Re,s,t,P⟩. I is a support-founded inter-
pretation iﬀthe two following conditions hold:
10 !∃xi ∈IST means “there exists only one xi ∈IST.
11 See Deﬁnition 7.

260
M.-C. Lagasquie-Schiex
1. for each argument (resp. support) x non prima-facie, belonging to a maximal
DCS and s.t. I(eAcc(x)) = true (resp. I(eV al(x)) = true), there exists at
least one impacting support tree IST = (x0, . . . , xn) for x that is satisﬁed by I,
i.e. ∀xi ∈IST, if xi ∈A then I(eAcc(xi)) = true, otherwise I(eV al(xi)) =
true;
2. for each element x of REBAF, I(UnSupp(x)) = true iﬀx ∈UnSupp(UI)
with UI = (SI, ΓI, ΔI).
Let Σx be a base of formulae built over REBAF. A support-founded model
of Σx is a support-founded interpretation which is a model of Σx.
Then using these support-founded models, the following characterization of
REBAF semantics can be given for any kind of REBAF:
Proposition 3. Let REBAF = ⟨A,Ra,Re,s,t,P⟩. Let U = (S, Γ, Δ) be a struc-
ture on REBAF.
1. U is admissible iﬀthere exists I support-founded model of Σd(REBAF) (in
the sense of Deﬁnition 11) with SI = S, ΓI = Γ and ΔI = Δ.
2. U is complete iﬀthere exists I support-founded model of (Σd(REBAF) ∪
Σr(REBAF)) (in the sense of Deﬁnition 11) with SI = S, ΓI = Γ and
ΔI = Δ.
3. U is a preferred structure iﬀthere exists I ⊆-maximal support-founded model
of Σd(REBAF) (in the sense of Deﬁnition 11) with SI = S, ΓI = Γ and
ΔI = Δ.
4. U is the grounded structure iﬀS = SI, ΓI = Γ and ΔI = Δ where I is
a ⊆-minimal support-founded model of (Σd(REBAF) ∪Σr(REBAF)) (in the
sense of Deﬁnition 11).
5. U is stable iﬀthere exists I support-founded model of Σs(REBAF) (in the
sense of Deﬁnition 11) with SI = S, ΓI = Γ and ΔI = Δ.
Using Proposition 3, consider the previous examples and the preferred seman-
tics:
Example
5
(cont’d):
The
⊆-maximal
support-founded
models
I
of
Σd(REBAF) (in the sense of Deﬁnition 11) correspond to the preferred structure
({b, d}, {β, π}, {ϵ}).
□
Example
6
(cont’d):
The
⊆-maximal
support-founded
models
I
of
Σd(REBAF) (in the sense of Deﬁnition 11) correspond to the preferred structure
({a, b, c}, ∅, {α, γ}). The models that satisfy eAcc(d) (resp. eAcc(e), eV al(β))
are not kept since they are not support-founded (no IST for these arguments or
this interaction that could be satisﬁed).
□
Example
7
(cont’d):
The
⊆-maximal
support-founded
models
I
of
Σd(REBAF) (in the sense of Deﬁnition 11) correspond to the preferred structure
({e, d, a}, ∅, {α1, α2, β1, β2, γ}).
□
Example
8
(cont’d):
The
⊆-maximal
support-founded
models
I
of
Σd(REBAF) (in the sense of Deﬁnition 11) correspond to the preferred structure
(A, Ra, Re).
□

Logical Encoding of REBAF
261
6
Conclusion and Future Works
This paper presents two improvements of the logical translation of argumen-
tation frameworks with higher-order attacks and evidential supports (REBAF)
described initially in [13]. First, we have proven that the attempt done for han-
dling the support cycles in REBAF in [13] does not hold in the general case. So
a new deﬁnition for the notion of support-founded models is proposed in this
paper. Note that, as a side-eﬀect, we have also deﬁned an additional notion: the
Directed Cycles of Supports (DCS) (and their possible aggregation); this notion
is not simple in the case of higher-order argumentation frameworks, since the
graphical representation of such frameworks is not a “directed graph” as deﬁned
in Graph Theory (unlike what happens for Dung argumentation frameworks).
Secondly, in order to respect the general deﬁnition of REBAF, we have pro-
posed an extension of the original encoding given in [13] that deals with collec-
tive interactions (attacks or supports whose source is a set of arguments). These
improvements provide characterizations of admissible (resp. complete, preferred,
grounded but also stable) structures in the presence of all kinds of support cycles
and of collective interactions, so for all types of REBAF.
Considering future works, several possibilities appear. The ﬁrst one is the
implementation of this work for obtaining an eﬃcient solver for the computation
of REBAF semantics.12 This point is related with the existence of the Inter-
national Competition on Computational Models of Argumentation (ICCMA,
see [1]), currently only centered around Dung framework, and so this could
be the opportunity for this competition to open up to enriched frameworks as
RAF and REBAF, for instance. A second future work could be an extension
of this work to other argumentation frameworks also using bipolar and higher-
order interactions. Indeed, there exist at least two other meanings of the support
relation (the deductive and the necessary supports) and it could be interesting
to study the impact of these other meanings on our modelization, particularly
knowing that some links exist between the evidential support and the necessary
support, and that deductive and necessary supports are dual notions (see [8,10]).
And a third future work could be a comparative study with some other existing
works also using logics for argumentation encoding and computation (see for
instance ADS - Abstract Dialectical Frameworks - in [6]).
A
Sketchs of Proof
The proofs of Proposition 3 (or 2) are done using the following lemmas.
Lemma 1 (Lemma Appendix A.1 in [13]). Any conﬂict-free self-supporting
structure U satisﬁes: Acc(U) ⊆UnAcc(U) ⊆Def(U).
Lemma 2 (Lemma Appendix A.2 in [13]). Any stable structure U satisﬁes:
Sup(U) = UnSupp(U).
12 A basic implementation has already been done but without any code optimization,
see [11].

262
M.-C. Lagasquie-Schiex
Lemma 3 (Lemma Appendix A.3, in [13]). Let U = (S, Γ, Δ) be a structure
and x /∈P be the target of a support y s.t. y ∈Δ∩Sup(U) and sy ∈S ∩Sup(U).
Then, there exists a support z s.t. tz = x, z ∈Δ ∩Sup(U \ {x}) and sz ∈
S ∩Sup(U \ {x}) and so x ∈Sup(U).
The preceding lemma can be adapted for collective interactions with a similar
proof (the ∈of the source being replaced by a ⊆).
Lemma 4. Let U = (S, Γ, Δ) be a structure and x /∈P be the target of a support
y s.t. y ∈Δ ∩Sup(U) and sy ⊆S ∩Sup(U). Then, there exists a support z s.t.
tz = x, z ∈Δ ∩Sup(U \ {x}) and sz ⊆S ∩Sup(U \ {x}) and so x ∈Sup(U).
Sketchs of Proof of Proposition 3 (or 2). These proofs are strongly inspired
by the proofs of props 6.1 and 6.2 in [13]. The only diﬀerences concern the nature
of the source (now a set, so the ∈of the source will be replaced by a ⊆for proving
Proposition 3) and the use of speciﬁc support-founded models.
For the ⇒direction and for each semantics, given a structure U = (S, Γ, Δ)
that is an extension of this semantics, an interpretation I is built s.t. UI = U
(as in the proofs of propositions 6.1 and 6.2 in [13]); then we prove that I is
a model of the corresponding logical bases, so a model of any formula in these
bases (for instance when the semantics is the admissibility, I must be a model
of Σd so a model of formulae (1) to (12), plus formulae (17) and (18)); and
ﬁnally we prove that I is a support-founded model. We give here only proofs
for formulae (17), (18) and (19), and for the fact that I is a support-founded
model since they are the most impacted by our changes.
• Let us ﬁrst consider formula (17) (for all semantics). Let x s.t. I(Supp(x)) =
true. By deﬁnition of I(Supp), x ∈Sup(U). By deﬁnition of Sup(U), either
x ∈P or x is the target of a support α s.t. α ∈Δ, α ∈Sup(U \ {x}), sα ⊆S
(or sα ∈S) and sα ⊆Sup(U \ {x}) (or sα ∈Sup(U \ {x})). In the ﬁrst case,
formula (17) is trivially satisﬁed by I (following the building of I). In the
second case, as S = SI and Δ = ΔI it holds that I(eAcc(sα)) = true and
I(eV al(α)) = true. Hence formula (17) is satisﬁed by I.
• Let us now consider formula (18) (for all semantics). Let x s.t. I(UnSupp(x))
= true. By deﬁnition of I(UnSupp), x ∈UnSupp(U). And, since UnSupp(U)
= Sup(U ′) (where U ′ = (Def A(U), Ra, Def Re(U))), x ∈Sup(U ′). So x /∈P
and using the contrapositive of Lemma 4 (or Lemma 3 for Proposition 2),
applied to the structure U ′, it follows that for each support leading to x,
either the support or its source13 is defeated by U, or the support or its
source is itself not supported by U ′, hence belongs to UnSupp(U). So I
satisﬁes the “only if” part of formula (18). For the “if” part, let us consider
x s.t. x /∈P and for each support leading to x, either the support or its
source is defeated by U, or the support or at least one component of its source
belongs to UnSupp(U) = Sup(U ′). As U ′ \ {x} ⊆U ′, it holds that Sup(U ′)
13 If the source is defeated by U, that means that at least one of its components is
defeated by U (idem for the unsupportability of the source).

Logical Encoding of REBAF
263
⊆Sup(U ′ \ {x}). Hence, from Deﬁnition 3, it holds that x /∈Sup(U ′), that
is x ∈UnSupp(U) and so I(UnSupp(x)) = true. So I satisﬁes formula (18).
• Consider now formula (19) (for stable semantics). Let x ∈A ∪Ra ∪Re s.t.
I(Supp(x)) = false. By deﬁnition of I(Supp), x /∈Sup(u). Due to Lemma 2,
it follows that x ∈UnSupp(U), hence I(UnSupp(x)) = true, by deﬁnition of
I(UnSupp). We have proved that I satisﬁes formula (19). So I is a model
of Σs(REBAF).
• And ﬁnally, we have to prove that I is support-founded (for all semantics).
Condition 2 of Deﬁnition 11 (or Deﬁnition 8) is trivially satisﬁed (following
the building of I). Consider now Condition 1. Let x ∈A s.t. x is non prima-
facie and there exists a DCS C containing x. Assume that I(eAcc(x)) =
true. So x ∈U and, since U is admissible (so self-supporting) and x non
prima-facie, then there exists at least one tree (or chain for Proposition 2)
of supported supports (x0, . . . , xn) leading to x with any xi belonging to U.
Moreover, for all xi, we have xi ∈Sup(U). So following the deﬁnition of I
we have either I(eAcc(xi)) = true or I(eV al(xi)) = true depending of the
nature of xi (argument or support). Thus there exists an impacting support
tree (or chain for Proposition 2) (x0, . . . , xn) for x that is satisﬁed by I. So
I is a support-founded model. The proof for x ∈Re is similar.
For the ⇐direction and for each semantics, given a support-founded inter-
pretation I that is a model of the corresponding logical bases, we show that UI
is a structure of the semantics (for instance, for the admissible semantics, UI
must be conﬂict-free, self-supporting and any element of the structure must be
acceptable wrt UI). Of course the proofs for the preferred (or grounded) seman-
tics are simpler since we only use the maximality (or minimality) property (as
in the proofs of props 6.1 and 6.2 in [13]).
References
1. International Competition on Computational Models of Argumentation (ICCMA).
http://argumentationcompetition.org/
2. Arisaka, R., Satoh, K.: Voluntary manslaughter? A case study with meta-
argumentation with supports. In: Kurahashi, S., Ohta, Y., Arai, S., Satoh, K.,
Bekki, D. (eds.) JSAI-isAI 2016. LNCS (LNAI), vol. 10247, pp. 241–252. Springer,
Cham (2017). https://doi.org/10.1007/978-3-319-61572-1 16
3. Baroni, P., Cerutti, F., Giacomin, M., Guida, G.: AFRA: argumentation framework
with recursive attacks. Int. J. Approx. Reason. 52, 19–37 (2011)
4. Barringer, H., Gabbay, D., Woods, J.: Temporal dynamics of support and attack
networks: from argumentation to zoology. In: Hutter, D., Stephan, W. (eds.) Mech-
anizing Mathematical Reasoning. LNCS (LNAI), vol. 2605, pp. 59–98. Springer,
Heidelberg (2005). https://doi.org/10.1007/978-3-540-32254-2 5
5. Boella, G., Gabbay, D.M., van der Torre, L., Villata, S.: Support in abstract argu-
mentation. In: Proceedings of COMMA, pp. 111–122. IOS Press (2010)
6. Brewka, G., Ellmauthaler, S., Strass, H., Wallner, J.P., Woltran, S.: Abstract
dialectical frameworks. In: Baroni, P., Gabbay, D., Giacomin, M., van der Torre,
L. (eds.) Handbook of Formal Argumentation, chap. 5, pp. 237–286. College Pub-
lications (2018)

264
M.-C. Lagasquie-Schiex
7. Cayrol, C., Fandinno, J., Fari˜nas del Cerro, L., Lagasquie-Schiex, M.-C.: Argu-
mentation frameworks with recursive attacks and evidence-based supports. In:
Ferrarotti, F., Woltran, S. (eds.) FoIKS 2018. LNCS, vol. 10833, pp. 150–169.
Springer, Cham (2018). https://doi.org/10.1007/978-3-319-90050-6 9
8. Cayrol, C., Fandinno, J., Fari˜nas del Cerro, L., Lagasquie-Schiex, M.C.: Structure-
based semantics of argumentation frameworks with higher-order attacks and sup-
ports (short paper). In: Modgil, S., Budzynska, K., Lawrence, J. (eds.) Proceedings
of COMMA, pp. 29–36. IOS Press (2018)
9. Cayrol, C., Lagasquie-Schiex, M.C.: Gradual valuation for bipolar argumentation
frameworks. In: Godo, L. (ed.) ECSQARU 2005. LNCS (LNAI), vol. 3571, pp.
366–377. Springer, Heidelberg (2005). https://doi.org/10.1007/11518655 32
10. Cayrol, C., Lagasquie-Schiex, M.C.: Bipolarity in argumentation graphs: towards
a better understanding. Intl. J. Approx. Reason. 54(7), 876–899 (2013)
11. Cayrol, C., Lagasquie-Schiex, M.C.: The Graﬁx website. http://www.irit.fr/graﬁx
12. Cayrol, C., Lagasquie-Schiex, M.C.: Logical encoding of argumentation frameworks
with higher-order attacks. In: Proceedings of the 30th International Conference on
Tools with Artiﬁcial Intelligence (ICTAI). IEEE (2018)
13. Cayrol, C., Lagasquie-Schiex, M.C.: Logical encoding of argumentation frameworks
with higher-order attacks and evidential supports. Int. J. Artif. Intell. Tools 29(3–
4), 2060003:1–2060003:50 (2020). https://doi.org/10.1142/s0218213020600039
14. Cohen, A., Gottifredi, S., Garc´ıa, A.J., Simari, G.R.: An approach to abstract
argumentation with recursive attack and support. J. Appl. Logic 13(4), 509–533
(2015)
15. Dung, P.M.: On the acceptability of arguments and its fundamental role in non-
monotonic reasoning, logic programming and n-person games. Artif. Intell. 77,
321–357 (1995)
16. Gabbay, D.M.: Fibring argumentation frames. Stud. Logica. 93, 231–295 (2009)
17. Karacapilidis, N., Papadias, D.: Computer supported argumentation and collabo-
rative decision making: the Hermes system. Inf. Syst. 26(4), 259–277 (2001)
18. Lagasquie-Schiex, M.C.: Handling support cycles in the logical encoding of argu-
mentation frameworks with higher-order attacks and evidential supports. Rap-
port de recherche IRIT/RR-2021-04-FR, IRIT, France (2021). http://www.irit.fr/
publis/ADRIA/PapersMCL/Rapport-IRIT-2021-04.pdf
19. Lagasquie-Schiex, M.C.: Logical encoding of argumentation frameworks with
higher-order attacks and evidential supports: taking into account the collective
interactions. Rapport de recherche IRIT/RR-2021-05-FR, IRIT, France (2021).
http://www.irit.fr/publis/ADRIA/PapersMCL/Rapport-IRIT-2021-05.pdf
20. Modgil, S.: Reasoning about preferences in argumentation frameworks. Artif. Intell.
173, 901–934 (2009)
21. Nielsen, S.H., Parsons, S.: A generalization of Dung’s abstract framework for argu-
mentation: arguing with sets of attacking arguments. In: Maudet, N., Parsons, S.,
Rahwan, I. (eds.) ArgMAS 2006. LNCS (LNAI), vol. 4766, pp. 54–73. Springer,
Heidelberg (2007). https://doi.org/10.1007/978-3-540-75526-5 4
22. Nouioua, F., Risch, V.: Argumentation frameworks with necessities. In: Benferhat,
S., Grant, J. (eds.) SUM 2011. LNCS (LNAI), vol. 6929, pp. 163–176. Springer,
Heidelberg (2011). https://doi.org/10.1007/978-3-642-23963-2 14
23. Oren, N., Reed, C., Luck, M.: Moving between argumentation frameworks. In:
Proceedings of COMMA, pp. 379–390. IOS Press (2010)
24. Rahwan, I., Simari, G.: Argumentation in Artiﬁcial Intelligence. Springer, Boston
(2009). https://doi.org/10.1007/978-0-387-98197-0

Logical Encoding of REBAF
265
25. Verheij, B.: DefLog: on the logical interpretation of prima facie justiﬁed assump-
tions. J. Logic Comput. 13, 319–346 (2003)
26. Villata, S., Boella, G., Gabbay, D.M., van der Torre, L.: Modelling defeasible and
prioritized support in bipolar argumentation. AMAI 66(1–4), 163–197 (2012)

Tableau-Based Decision Procedure for
Logic of Knowing-How via Simple Plans
Yanjun Li(B)
College of Philosophy, Nankai University, Tianjin, China
Abstract. Recently, there has been an increasing interest in studying
logic of knowing-how based on the idea of planning. In literature, it
is shown that knowing-how logics based on 10 diﬀerent types of plans,
including simple plans, share the same proof system. In this paper, we
present a tableau system for the knowing-how logic via simple plans,
and we show that there is an algorithm that runs in polynomial space
for deciding whether a formula of the knowing-how logic is satisﬁable.
Since the knowing-how logic is an extension of epistemic logic which is
PSPACE-hard for multi-agent version, it follows that the multi-agent
knowing-how logic via simple plans is PSPACE-complete.
Keywords: Epistemic logic · Knowing-how logic · Tableau
1
Introduction
Standard epistemic logic proposed by von Wright and Hintikka concerns with
reasoning about propositional knowledge which is expressed by knowing that ϕ
[7,14]. However, beyond knowing that, there are other expressions of knowledge in
natural language, such as knowing whether, knowing what, knowing how, knowing
why, and so on. All of them are usually called knowledge of knowing-wh. Recently,
there has been an increasing interest on the logics of these knowing-wh (cf. e.g.,
[3–5,8,9,15,17]). Among the logics of knowing-wh, the logics of knowing-how
received the most attention (cf. [4,10,13,16]).
The discussion about formalizing knowing-how can date back to [11,12]. In
[15,16], Wang proposed a new way of formalizing knowing-how motivated by the
idea of planning under uncertainty in artiﬁcial intelligence (AI). Planning under
uncertainty is to ﬁnd a plan that is always executable to the end to guarantee
achieving the goal, given that the agent is uncertain about the exact state where
he is. Take the following example presented in [10]. The map of a hotel’s ﬂoor
is illustrated below, where rooms (denoted by si) are connected by (one-way)
corridors (r arrows) or stairs (u arrows). The proposition p is true at rooms only
s2 and s3, and q is true at only s4, s7, and s8.
s6
s7 : q
s8 : q
s1
r  s2 : p
r

u

s3 : p
r

u

s4 : q
r

u

s5
c
⃝Springer Nature Switzerland AG 2021
P. Baroni et al. (Eds.): CLAR 2021, LNAI 13040, pp. 266–283, 2021.
https://doi.org/10.1007/978-3-030-89391-0_15

Tableau-Based Decision Procedure for ELKh
267
An agent now is lost in the ﬂoor. He only knows that he is in a p-room, but he
is not sure whether he is in s2 or s3. However, with the map in hand, he does
have a plan to guarantee achieving a q-room by ﬁrst moving right (r) and then
moving up (u). Inspired by this idea, Wang interpreted the notion of knowing
how to achieve ϕ as there exists a linear plan (i.e. a sequence of actions) such
that the agent knows that performing the plan can guarantee achieving ϕ.
Along with this approach of formalizing knowing-how based on planning, [4]
proposed a knowing-how logic based on a diﬀerent notion of plan, a uniform
strategy, which is a partial function from belief states to actions. Besides linear
plan and uniform strategy, there are other intuitive notions of plan. For example,
in the example above, the action sequence rrr is a weaker linear plan for achiev-
ing a ¬q-state since the agent will always terminate on s5 even though it cannot
alway fully executable to the end. In [10], they use a programming language to
specify 10 types of plans, such as simple plans, linear plans, unbounded linear
plans, conditional plans, knowledge-based plans, and so on. They show that all
these 10 types of plans lead to the same knowing-how logic in the sense that
they share the same proof system.
In this paper, we present a tableau-based decision procedure for the knowing-
how logic via simple plans, and so a decision procedure for the proof system
presented in [10]. A simple plan is an at most one step plan, that is, a single action
a or the empty sequence ϵ. Based on the semantic tableau method for epistemic
logic which is proposed in [6] and developed in [2], we present a tableau calculus
for the knowing-how logic via simple plans. Moreover, we show that there is an
algorithm that runs in polynomial space for deciding whether there is a closed
tableau. With other known results, this leads to the result that multi-agent
knowing-how logic via simple plans is PSPACE-complete.
The structure of this paper are as follows: Sect. 2 introduces the knowing-how
logic based on simple plans; Sect. 3 presents the tableau system; Sect. 4 shows
the completeness of the tableau system. Section 5 presents a decision procedure
based on the tableau system. Finally, we conclude with some remarks in Sect. 6.
2
Preliminaries
In this section, we introduce the knowing-how logic via simple plans. Let P be
a countable set of propositional symbols, and let I be a set of agents.
Deﬁnition 1 (ELKh Language). The Epistemic Language L of Knowing How
is deﬁned by the following BNF where p ∈P and i ∈I:
ϕ :: = ⊥| p | ¬ϕ | (ϕ ∧ϕ) | Kiϕ | Khiϕ.
We use ⊤, ∨, →as usual abbreviations and write Kiϕ for ¬Ki¬ϕ. The formula
Kiϕ means that the agent i knows that ϕ, and the formula Khiϕ means that
the agent knows how to achieve ϕ.
Formulas are interpreted on models deﬁned as follows.

268
Y. Li
Deﬁnition 2 (Model). An Epistemic Transition System (or, a model) M is a
quintuple ⟨W, {∼i| i ∈I}, {Ai | i ∈I}, {R(a) | a ∈Ai, i ∈I}, V ⟩where:
– W is a non-empty set of states,
– ∼i ⊆W × W is an equivalence relation for each i ∈I,
– Ai is a set of actions for each i ∈I,
– R(a) ⊆W × W is a binary relation for each i ∈I and each a ∈Ai,
– V : W →2P is a valuation function.
Notations. For each s ∈W, [s]i ⊆W denotes the equivalence class {t ∈W | s ∼i
t}, and [W]i denotes the collection of all the equivalence classes on W for ∼i. The
binary relation R(a) on W also can be seen as a function from W to the power
set of W, such that for each s ∈W, R(a)(s) = {t ∈W | (s, t) ∈R(a)}. Thus, by
abusing the notation, we sometimes also write (s, t) ∈R(a) as t ∈R(a)(s). We
use Aϵ
i to denote the set Ai ∪{ϵ}. If σ = ϵ, let R(σ)(s) = {s}. Given a set of
states X and σ ∈Aϵ
i, we use R(σ)(X) to denote the set 
s∈X R(σ)(s).
Before we introduce the semantics, we ﬁrstly introduce the following auxiliary
notion of strong executability.
Deﬁnition 3 (Strong executability). Let A be a set of actions. Let X be a
set of states. We say that an action a ∈A is strongly executable on X if for
each s ∈X, there exists t such that (s, t) ∈R(a). In particular, the empty ϵ is
strongly executable on all sets of states.
Now we are ready to introduce the semantics.
Deﬁnition 4 (Semantics ⊨). The satisfaction relation ⊨is deﬁned as follows
between formulas and pointed models:
M, s ⊭⊥
always
M, s ⊨p
⇐⇒p ∈V (s)
M, s ⊨¬ϕ
⇐⇒M, s ⊭ϕ
M, s ⊨ϕ ∧ψ ⇐⇒M, s ⊨ϕ and M, s ⊨ψ
M, s ⊨Kiϕ
⇐⇒for all s′ : s∼is′ implies M, s′ ⊨ϕ
M, s ⊨Khiϕ ⇐⇒there exists σ ∈Aϵ
i such that
1. σ is strongly executable on [s]i, and
2. M, t ⊨ϕ for all t∈R(σ)([s]i).
In [10], an atom action or the empty sequence ϵ is called a simple plan.
Besides simple plans, there also discusses knowing-how based on other types of
plans, such as linear plans, conditional plans, knowledge-based plans, and so on.
Example 1. Let the model M be depicted as below, where there are two agents i
and j, and Ai = Aj = {a}. Dash dot lines below represent equivalence relations,
and reﬂexive dash dot lines are omitted.

Tableau-Based Decision Procedure for ELKh
269
s4
s5 : q
s1 : p
a

i
s2 : p
a

j
s3
aFFFF
FFF
We then have the followings:
– M, s2 ⊨Khip. At the state s2, the agent i knows how to achieve p-states,
since he can achieve that goal by doing ϵ, namely staying where he is.
– M, s2 ⊨Khjq. At the state s2, the agent j knows how to achieve the q-state,
since he can achieve that goal by doing the action a.
Proposition 1. The following formulas are valid:
1. ¬Khi⊥
2. Kiϕ →Khiϕ
3. Khiϕ →KiKhiϕ
4. ¬Khiϕ →K¬Khiϕ
Proof. 1. Assume that there is a pointed model (M, s) such that M, s ⊨Khi⊥.
This follows that there is σ ∈Aϵ
i such that σ is strongly executable on [s]i
and M, t ⊨⊥for all t ∈R(σ)([s]i). Since s ∈[s]i, this follows that σ is
strongly executable on s. We then have that R(σ)(s) ̸= ∅. Since we have
shown that M, t ⊨⊥for all t ∈R(σ)([s]i), this follows that there is M, t ⊨⊥
for some t. Contradiction! Therefore, there is no pointed model (M, s) such
that M, s ⊨Khi⊥, namely, ⊨¬Khi⊥.
2. Let (M, s) be a pointed model such that M, s ⊨Kiϕ. Next we will show that
M, s ⊨Khiϕ. Since M, s ⊨Kiϕ, this follows that M, t ⊨ϕ for all t ∈[s]i.
Please note that R(ϵ)([s]i) = [s]i and that ϵ is strongly executable on [s]i.
Thus, we know that ϵ is a good plan for M, s ⊨Khiϕ.
3. Let (M, s) be a pointed model such that M, s ⊨Khiϕ. Next we will show
that M, s ⊨KiKhiϕ. Since M, s ⊨Khiϕ, this follows that there is σ ∈Aϵ
i
such that σ is strongly executable on [s]i and M, t ⊨ϕ for all t ∈R(σ)([s]i).
For each s′ ∈[s]i, since ∼i is an equivalence relation, we have that [s]i =
[s′]i and then that R(σ)([s]i) = R(σ)([s′]i). Thus, σ also is a good plan for
M, s′ ⊨Khiϕ. Therefore, we have shown that M, s′ ⊨Khiϕ for each s′ ∈[s]i.
Thus, we have that M, s ⊨KiKhiϕ.
4. Let (M, s) be a pointed model such that M, s ⊨¬Khiϕ. Next we will show
that M, s ⊨Ki¬Khiϕ. Assume that M, s ⊭Ki¬Khiϕ. This follows that
M, s′ ⊨Khiϕ for some s′ ∈[s]i. Since we have shown above that ⊨Khiϕ →
KiKhiϕ, this follows that M, s′ ⊨KiKhiϕ. Since s′ ∈[s]i, this follows that
s ∈[s′]i due to the fact that ∼i is an equivalence relation. We then have that
M, s ⊨Khiϕ. This is contradictory with the fact that M, s ⊨¬Khiϕ. Thus,
M, s ⊨Ki¬Khiϕ.
The proof system SLKH is presented in Table 1. It is shown in [10] that
SLKH is sound and complete with respect to knowing-how via simple plans.

270
Y. Li
Table 1. Proof System SLKH
Axioms
TAUT
all axioms of propositional logic
DISTK
Kip ∧Ki(p →q) →Kiq
T
Kip →p
4
Kip →KiKip
5
¬Kip →Ki¬Kip
AxKtoKh
Kip →Khip
AxKhtoKhK
Khip →KhiKip
AxKhtoKKh
Khip →KiKhip
AxKhKh
KhiKhip →Khip
AxKhbot
Khi⊥→⊥
Rules
MP
ϕ, ϕ →ψ
ψ
NECK
ϕ
Kiϕ
MONOKh
ϕ →ψ
Khiϕ →Khiψ
SUB
ϕ(p)
ϕ[ψ/p]
3
Tableau System for ELKh
In this section, we present the tableau system. Intuitively, a tableau is a tree with
additional information about models. Nodes of tableau tree represent states of
models.
Before we formally deﬁne tableaux, we ﬁrstly introduce two auxiliary notions
below.
Deﬁnition 5 (Labelled formula). A labelled formula is a pair of the form
⟨n, ϕ⟩where n ∈N and ϕ ∈L.
The label n in a labelled formula ⟨n, ϕ⟩is a node of tableau trees. The labelled
formula ⟨n, ϕ⟩represents that the state that the node n represents satisﬁes the
formula ϕ.
Moreover, there are two kinds of relations in models: epistemic relations ∼i
and action relation R(a). These information about ∼i and R(a) will also be
attached on tableau trees.
Deﬁnition 6 (Branch). A branch is a pair of the form ⟨L, S⟩where L is a set
of labelled formulas and S ⊆((I ∪L|Kh) × N × N) where L|Kh = {Khiϕ ∈L |
i ∈I, ϕ ∈L}.
The set S carries information about relations ∼i and R(a). If ⟨i, n, m⟩∈S,
it represents that the pair of the states n and m are in the relation ∼i, namely,
n ∼i m. If ⟨Khiϕ, n, m⟩∈S, it represents that there is an action a such that
R(a) connects n and m (namely (n, m) ∈R(a)) and that a is a good plan for

Tableau-Based Decision Procedure for ELKh
271
the state n satisﬁes Khiϕ. The relation S in the branch represents a part of
the relations ∼i and R(a) in models. This will be more clear when we construct
models from tableau branches in the proof of Proposition 7.
Now we are ready to deﬁne tableaux.
Deﬁnition 7 (Tableau).
A tableau for ϕ is a set of branches T inductively
deﬁned as follows:
– T = {⟨{⟨0, ϕ⟩}, ∅⟩}. This is called the initial tableau for ϕ.
– T = (T ′\{b}) ∪B, where T ′ is a tableau for ϕ that contains the branch
b = ⟨L, S⟩, and B is a ﬁnite set of branches generated by one of the tableau
rules deﬁned below:
• R¬:
if ⟨n, ¬¬ϕ⟩∈L then B = {⟨L ∪{⟨n, ϕ⟩}, S⟩}.
• R∧:
if ⟨n, ϕ1 ∧ϕ2⟩∈L then B = {⟨L ∪{⟨n, ϕ1⟩, ⟨n, ϕ2⟩}, S⟩}.
• R∨:
if ⟨n, ¬(ϕ1 ∧ϕ2)⟩∈L then B = {⟨L ∪{⟨n, ¬ϕ1⟩, ⟨n, ¬ϕ2⟩}, S⟩, ⟨L ∪
{⟨n, ¬ϕ1⟩, ⟨n, ϕ2⟩}, S⟩, ⟨L ∪{⟨n, ϕ1⟩, ⟨n, ¬ϕ2⟩}, S⟩}.
• Cut-¬K:
if ⟨n, ¬Kiϕ⟩∈L then B
= {⟨L ∪{⟨n, ¬ϕ⟩}, S⟩, ⟨L ∪
{⟨n, ϕ⟩}, S⟩}.
• KT:
if ⟨n, Kiϕ⟩∈L then B = {⟨L ∪{⟨n, ϕ⟩}, S⟩}.
• Cut-Kh:
if ⟨n, Khiϕ⟩∈L, we have that B = {b1, b2} where b1 = ⟨L ∪
{⟨n, ¬Kiϕ⟩, ⟨n, ¬Khi⊥⟩}, S⟩and b2 = ⟨L ∪{⟨n, Kiϕ⟩, ⟨n, ¬Khi⊥⟩}, S⟩.
• Cut-¬Kh:
if ⟨n, ¬Khiϕ⟩∈L then B = {⟨L ∪{⟨n, ¬Kiϕ⟩}, S⟩}.
• RK:
if ⟨n, Kiϕ⟩∈L and (i, n, n′) ∈S then B = {⟨L ∪{⟨n′, ϕ⟩}, S⟩}.
• K4:
if ⟨n, Kiϕ⟩∈L and (i, n, n′) ∈S then B = {⟨L ∪{⟨n′, Kiϕ⟩}, S⟩}.
• K5:
if ⟨n, ¬Kiϕ⟩∈L and (i, n, n′) ∈S then B = {⟨L∪{⟨n′, ¬Kiϕ⟩}, S⟩}.
• R¬K:
if ⟨n, ¬Kiϕ⟩∈L then B = {⟨L ∪{⟨n′, ¬ϕ⟩}, S ∪{(i, n, n′)}⟩} for
some n′ ∈N not occurring in b.
• Kh4:
if ⟨n, Khiϕ⟩
∈
L and (i, n, n′)
∈
S then B
=
{⟨L ∪
{⟨n′, Khiϕ⟩}, S⟩}.
• Kh5:
if ⟨n, ¬Khiϕ⟩∈L and (i, n, n′) ∈S then we have that B =
{⟨L ∪{⟨n′, ¬Khiϕ⟩}, S⟩}.
• R±Kh:
if {⟨n, ¬Khiϕ⟩, ⟨n, Khiψ⟩, ⟨n, ¬Kiψ⟩} ⊆L then B = {⟨L ∪
{⟨n′, ¬ϕ⟩, ⟨n′, ψ⟩}, S ∪{(Khiψ, n, n′)}⟩} for some n′ ∈N not occurring in
b.
Tableau rules in ‘nominator/denominator’ form are presented in Table 2.
Please note that we use the colon ‘:’ to distinguish elements of L and elements
of S. For example, in the rule K4, the notation ⟨n, Khiϕ⟩: ⟨i, n, n′⟩means that
⟨n, Khiϕ⟩is an element in L and that ⟨i, n, n′⟩is an element in S. When there
is no need to mention elements of S, we will omit the colon.
There is no cut rule for K, since the rule KT plays the same role. The cut rules
and the rules R¬, R∨and R∧together will make sure that in fully expanded
tableaux, it is closed over subformulas (see Proposition 3). This is also the reason
why our rule R∨is diﬀerent from standard one, which is normally as follows:
¬(ϕ1 ∧ϕ2)
¬ϕ1 | ¬ϕ2

272
Y. Li
Table 2. Tableau rules
⟨n, ¬¬ϕ⟩
(R¬)
⟨n, ϕ⟩
⟨n, ¬(ϕ1 ∧ϕ2)⟩
(R∨)
⟨n, ¬ϕ1⟩⟨n, ¬ϕ1⟩⟨n, ϕ1⟩
⟨n, ¬ϕ2⟩⟨n, ϕ2⟩
⟨n, ¬ϕ2⟩
⟨n, ϕ1 ∧ϕ2⟩
(R∧)
⟨n, ϕ1⟩
⟨n, ϕ2⟩
⟨n, ¬Kiϕ⟩
(Cut-¬K)
⟨n, ¬ϕ⟩| ⟨n, ϕ⟩
⟨n, Kiϕ⟩
(KT)
⟨n, ϕ⟩
⟨n, Khiϕ⟩
(Cut-Kh)
⟨n, ¬Kiϕ⟩
⟨n, Kiϕ⟩
⟨n, ¬Khi⊥⟩⟨n, ¬Khi⊥⟩
⟨n, ¬Khiϕ⟩
(Cut-¬Kh)
⟨n, ¬Kiϕ⟩
⟨n, ¬Kiϕ⟩
(R¬K)
n′ is new
⟨n′, ¬ϕ⟩: ⟨i, n, n′⟩
⟨n, Kiϕ⟩: ⟨i, n, n′⟩
(RK)
⟨n′, ϕ⟩
⟨n, Kiϕ⟩: ⟨i, n, n′⟩
(K4)
⟨n′, Kiϕ⟩
⟨n, ¬Kiϕ⟩: ⟨i, n, n′⟩
(K5)
⟨n′, ¬Kiϕ⟩
⟨n, Khiϕ⟩: ⟨i, n, n′⟩
(Kh4)
⟨n′, Khiϕ⟩
⟨n, ¬Khiϕ⟩: ⟨i, n, n′⟩
(Kh5)
⟨n′, ¬Khiϕ⟩
⟨n, ¬Khiϕ⟩
⟨n, Khiψ⟩
⟨n, ¬Kiψ⟩
(R±Kh)
n′ is new
⟨n′, ¬ϕ⟩
⟨n′, ψ⟩: ⟨Khiψ, n, n′⟩
The property of closing over subformulas together with rules K4, K5, Kh4 and
Kh5 plays an important role in showing that all epistemic accessible nodes share
the same epistemic formulas (see Proposition 6). All these are standard for epis-
temic logic.
The real characteristic rule of our tableau system for knowing-how logic is
the rule R±Kh. (Of cours, the rules Kh4 and Kh5 are important for all epistemic
accessible states having the same Kh- and ¬Kh-formulas, but these can be done
by imitating rules for K.) Firstly, if among formulas attached on n, there are
only formulas of the form ¬Khiϕ but without any formula of the form Khiψ,
then we only need to ensure that n satisﬁes ¬Kiϕ but need not to add any
action-successor n′ of n. This is why both Kh- and ¬Kh-formulas are involved

Tableau-Based Decision Procedure for ELKh
273
in the rule R±Kh. Secondly, if there is indeed a formula Khiψ attached on n,
by the rule Cut-Kh, we have either ⟨n, Kiψ⟩or ⟨n, ¬Kiψ⟩and ⟨n, ¬Khi⊥⟩. If n
satisﬁes Kiψ, it follows that n satisﬁed Khiψ. Otherwise, the rule R±Kh will be
triggered.
Deﬁnition 8 (Closed tableau). Let b = ⟨L, S⟩be a branch. The set L is closed
if and only if for some n and ϕ, either {⟨n, ϕ⟩, ⟨n, ¬ϕ⟩} ⊆L or ⟨n, ⊥⟩∈L. The
branch b is closed if and only if L is closed. The branch b is open if and only if
it is not closed. A tableau is closed if and only if all its branches are closed. A
tableau is open if and only if it is not closed.
In the remaining section, we will show the soundness of the tableau system.
Deﬁnition 9 (Interpretation of branch). Given a model M and a branch
b = ⟨L, S⟩, let f be a function which assigns a state in M to each n occurring
in b and assigns an action in Ai to each (Khiϕ, n, n′) in S. We say that f is an
interpretation of b in M if and only if the following conditions hold:
– M, f(n) ⊨ϕ for all ⟨n, ϕ⟩∈L;
– f(n) ∼i f(n′) for all (i, n, n′) ∈S;
– f(n′) ∈R(f(Khiϕ, n, n′))([f(n)]i) for all (Khiϕ, n, n′) ∈S.
Proposition 2. Let f be an interpretation of a branch b = ⟨L, S⟩in a model
M. If B is a set of branches generated by applying one of the tableau rules to b,
then there exists a branch b′ ∈B that has an interpretation in M.
Proof. If the rule applied is R¬, R∨, R∧, or Cut-¬K, it is straightforward. We
restrict our attention to the other rules.
– Cut-Kh: We then have that ⟨n, Khiϕ⟩∈L and B = {b1, b2} where b1 =
⟨L ∪{⟨n, ¬Kiϕ⟩, ⟨n, ¬Khi⊥⟩}, S⟩and b2 = ⟨L ∪{⟨n, Kiϕ⟩, ⟨n, ¬Khi⊥⟩}, S⟩.
Since f is an interpretation of b in M, this implies that M, f(n) ⊨Khiϕ.
By Proposition 1, we know that M, f(n) ⊨¬Khi⊥. Please note that either
M, f(n) ⊨Kiϕ or M, f(n) ⊨¬Kiϕ. Therefore, if M, f(n) ⊨Kiϕ, this follows
that f is an interpretation of b2. If M, f(n) ⊨¬Kiϕ, this follows that f is an
interpretation of b1.
– KT: We then have that ⟨n, Kiϕ⟩∈L and B = {⟨L ∪{⟨n, ϕ⟩}, S⟩}. Since f is
an interpretation of b in M, this implies that M, f(n) ⊨Kiϕ. Moreover, since
the relation ∼i in M is reﬂexive, this implies that M, f(n) ⊨ϕ. Therefore, f
is also an interpretation of the branch in B.
– Cut-¬Kh: We then have that ⟨n, ¬Khiϕ⟩∈L and B = {⟨L∪{⟨n, ¬Kiϕ⟩}, S⟩}.
Since f is an interpretation of b in M, this implies that M, f(n) ⊨¬Khiϕ.
Suppose that M, f(n) ⊨Kiϕ. This implies that ϵ ∈Aϵ
i would be a witness
plan for M, f(n) ⊨Khiϕ. Contradiction! Thus, we have that M, f(n) ⊨
¬Kiϕ. Therefore, f is also an interpretation of the branch in B.
– R¬K: We then have that ⟨n, ¬Kiϕ⟩∈L and B = {⟨L ∪{⟨n′, ¬ϕ⟩}, S ∪
{(i, n, n′)}⟩} where n′ ∈N does not occur in b. Since f is an interpretation of
b, this implies that M, f(n) ⊨¬Kiϕ. Thus, there is a state s in M such that

274
Y. Li
f(n) ∼i s and M, s ⊨¬ϕ. We deﬁne f ′ as f ′ = f ∪{n′ →s}. Since n′ does
not occur in b, f ′ is a well-deﬁned function. Therefore, f ′ is an interpretation
of the branch in B.
– RK: We then have ⟨n, Kiϕ⟩∈L, (i, n, n′) ∈S and B = {⟨L ∪{⟨n′, ϕ⟩}, S⟩}.
Since f is an interpretation of b in M, this implies that M, f(n) ⊨Kiϕ and
f(n) ∼i f(n′). Thus, we have have that M, f(n′) ⊨ϕ. Therefore, f is also an
interpretation of the branch in B.
– K4: We then have ⟨n, Kiϕ⟩∈L, (i, n, n′) ∈S and B = {⟨L∪{⟨n′, Kiϕ⟩}, S⟩}.
Since f is an interpretation of b, this implies that M, f(n) ⊨Kiϕ and f(n) ∼i
f(n′). Since ∼i is transitive, we then have that f(n) ∼i s for all s with
f(n′) ∼i s. This implies that M, s ⊨ϕ for all s with f(n′) ∼i s. Thus, we
have that M, f(n′) ⊨Kiϕ. Therefore, f is also an interpretation of the branch
in B.
– K5: We have ⟨n, ¬Kiϕ⟩∈L, (i, n, n′) ∈S and B = {⟨L ∪{⟨n′, ¬Kiϕ⟩}, S⟩}.
Since f is an interpretation of b, this implies that M, f(n) ⊨¬Kiϕ and
f(n) ∼i f(n′). Due to M, f(n) ⊨¬Kiϕ, we then have that M, s ⊨¬ϕ for
some s with f(n) ∼i s. Since ∼i is an equivalence relation and f(n) ∼i f(n′),
this implies that f(n′) ∼i s. Thus, we have that M, f(n′) ⊨¬Kiϕ. Therefore,
f is also an interpretation of the branch in B.
– Kh4: We then have that ⟨n, Khiϕ⟩∈L, (i, n, n′) ∈S and B = {⟨L ∪
{⟨n′, Khiϕ⟩}, S⟩}. Since f is an interpretation of b, this implies M, f(n) ⊨
Khiϕ and f(n) ∼i f(n′). By the semantics ⊨, this implies M, f(n′) ⊨Khiϕ.
Therefore, f is also an interpretation of the branch in B.
– Kh5: We then have that ⟨n, ¬Khiϕ⟩∈L, (i, n, n′) ∈S and B = {⟨L ∪
{⟨n′, ¬Khiϕ⟩}, S⟩}. Since f is an interpretation of b, it follows that M, f(n) ⊨
¬Khiϕ and f(n) ∼i f(n′). Suppose that M, f(n′) ⊨Khiϕ. This implies that
there exists a witness plan σ ∈Aϵ
i for M, f(n′) ⊨Khiϕ. Since f(n) ∼i f(n′),
this implies that [f(n)]i = [f(n′)]i. By the semantics ⊨, we then have that
σ is also a witness plan for M, f(n) ⊨Khiϕ. This is contradictory with
that M, f(n) ⊨¬Khiϕ. Thus, we have that M, f(n′) ⊮Khiϕ and then
M, f(n′) ⊨¬Khiϕ. Therefore, f is also an interpretation of the branch in B.
– R±Kh: We then have that {⟨n, ¬Khiϕ⟩, ⟨n, Khiψ⟩, ⟨n, ¬Kiψ⟩} ⊆L and B =
{⟨L ∪{⟨n′, ¬ϕ⟩, ⟨n′, ψ⟩}, S ∪{Khiψ, n, n′}⟩}. Since f is an interpretation of
b, this implies that M, f(n) ⊨¬Khiϕ, M, f(n) ⊨Khiψ, and M, f(n) ⊨
¬Kiψ. Due to M, f(n) ⊨Khiψ, there exists σ ∈Aϵ
i such that σ is strongly
executable on [f(n)]i and that M, t ⊨ψ for all t ∈R(σ)([f(n)]i). Since
M, f(n) ⊨¬Kiψ, this implies that σ ̸= ϵ, i.e., σ ∈Ai. Moreover, since
M, f(n) ⊨¬Khiϕ and σ is strongly executable on [f(n)]i, this implies that
M, v ⊮ϕ for some v ∈R(σ)([f(n)]i). Thus, we have that there exists v ∈
R(σ)([f(n)]i) such that M, v ⊨ψ and M, v ⊨¬ϕ. We then deﬁne f ′ as
f ′ = f ∪{n′ →v, (Khiϕ, n, n′) →σ}. Since n′ does not occur in b, this
implies that f ′ is well-deﬁned. Thus, f ′ is an interpretation of the branch b2.
Theorem 1 (Soundness). If ϕ0 is satisﬁable, then there are no closed tableaux
for ϕ0.

Tableau-Based Decision Procedure for ELKh
275
Proof. Since ϕ0 is satisﬁable, this implies that there exists a pointed model
(M, s) such that M, s ⊨ϕ0. Suppose that T is a closed tableau for ϕ0. By
Deﬁnition 7, we know that T is an extension of the initial tableau {⟨{⟨0, ϕ0⟩}, ∅⟩}.
We deﬁne a function f as f = {0 →s}. Then f is an interpretation of the
initial tableau. By Proposition 2, there exists a branch b ∈T which has an
interpretation in M. Since T is closed, this implies that b is closed. Contradiction!
Therefore, we have that there are no closed tableaux for ϕ0.
4
Completeness
In this section, we show the completeness of the tableau system. The key is to
show that there is a model satisfying ϕ if there is an open saturated tableau for
ϕ.
Deﬁnition 10 (Saturated tableau). Let T be a tableau for ϕ. T is saturated
if and only if T is saturated under all tableau rules, as deﬁned below:
1. T is saturated under rule R¬ if and only if for all b = ⟨L, S⟩∈T, if
⟨n, ¬¬ϕ⟩∈L, then ⟨n, ϕ⟩∈L.
2. T is saturated under rule R∧if and only if for all b = ⟨L, S⟩∈T, if ⟨n, ϕ1 ∧
ϕ2⟩∈L, then {⟨n, ϕ1⟩, ⟨n, ϕ2⟩} ⊆L.
3. T is saturated under rule R∨if and only if for all b = ⟨L, S⟩∈T, if
⟨n, ¬(ϕ1 ∧ϕ2)⟩∈L, then {⟨n, ¬ϕ1⟩, ⟨n, ¬ϕ2⟩} ⊆L, or {⟨n, ¬ϕ1⟩, ⟨n, ϕ2⟩} ⊆
L, or {⟨n, ϕ1⟩, ⟨n, ¬ϕ2⟩} ⊆L.
4. T is saturated under rule KT if and only if for all b = ⟨L, S⟩∈T, if
⟨n, Kiϕ⟩∈L, then ⟨n, ϕ⟩∈L.
5. T is saturated under rule Cut-¬K if and only if for all b = ⟨L, S⟩∈T, if
⟨n, ¬Kiϕ⟩∈L, then either ⟨n, ¬ϕ⟩∈L or ⟨n, ϕ⟩∈L.
6. T is saturated under rule Cut-Kh if and only if for all b = ⟨L, S⟩∈T, if
⟨n, Khiϕ⟩∈L, then either we have that {⟨n, ¬Kiϕ⟩, ⟨n, ¬Khi⊥⟩} ⊆L, or
we have that {⟨n, Kiϕ⟩, ⟨n, ¬Khi⊥⟩} ⊆L.
7. T is saturated under rule Cut-¬Kh if and only if for all b = ⟨L, S⟩∈T, if
⟨n, ¬Khiϕ⟩∈L, then ⟨n, ¬Kiϕ⟩∈L.
8. T is saturated under rule R¬K if and only if for all b = ⟨L, S⟩∈T, if
⟨n, ¬Kiϕ⟩∈L, then (i, n, n′) ∈S and ⟨n′, ¬ϕ⟩∈L for some n′ ∈N.
9. T is saturated under rule RK if and only if for all b = ⟨L, S⟩∈T, if
⟨n, Kiϕ⟩∈L and (i, n, n′) ∈S, then ⟨n′, ϕ⟩∈L.
10. T is saturated under rule K4 if and only if for all b = ⟨L, S⟩∈T, if
⟨n, Kiϕ⟩∈L and (i, n, n′) ∈S, then ⟨n′, Kiϕ⟩∈L.
11. T is saturated under rule K5 if and only if for all b = ⟨L, S⟩∈T, if
⟨n, ¬Kiϕ⟩∈L and (i, n, n′) ∈S, then ⟨n′, ¬Kiϕ⟩∈L.
12. T is saturated under rule Kh4 if and only if for all b = ⟨L, S⟩∈T, if
⟨n, Khiϕ⟩∈L and (i, n, n′) ∈S, then ⟨n′, Khiϕ⟩∈L.
13. T is saturated under rule Kh5 if and only if for all b = ⟨L, S⟩∈T, if
⟨n, ¬Khiϕ⟩∈L and (i, n, n′) ∈S, then ⟨n′, ¬Khiϕ⟩∈L.

276
Y. Li
14. T is saturated under rule R±Kh if and only if for all b = ⟨L, S⟩∈T, if
{⟨n, ¬Khiϕ⟩, ⟨n, Khiψ⟩, ⟨n, ¬Kiψ⟩} ⊆L, then {⟨n′, ¬ϕ⟩, ⟨n′, ψ⟩} ⊆L and
(Khiψ, n, n′) ∈S for some n′ ∈N.
Before we construct a model for ϕ from an open saturated tableau, we ﬁrst
introduce some auxiliary notions.
Deﬁnition 11 (Subformulas). The function sub : L →P(L) is deﬁned as
follows:
sub(⊥) = {⊥}
sub(p) = {p}
sub(¬ϕ) = sub(ϕ) ∪{¬ϕ}
sub(ϕ ∧ψ) = sub(ϕ) ∪sub(ψ) ∪{ϕ ∧ψ}
sub(Kiϕ) = sub(ϕ) ∪{Kiϕ}
sub(Khiϕ) = sub(ϕ) ∪{Khiϕ, Kiϕ, Khi⊥}
Each ψ ∈sub(ϕ) is called a subformula of ϕ. Particularly, ψ is called a proper
subformula if ψ ̸= ϕ. Let sub+(ϕ) = sub(ϕ) ∪{¬ψ | ψ ∈sub(ϕ)}.
The deﬁnition of subformulas here is a little diﬀerent from the common def-
inition of subformulas, since here we call Kiϕ and Khi⊥subformulas of Khiϕ.
The reason is the following: in constructing the tableau, we need to apply the
rule R±Kh if we must build a witness plan for Khiψ. To trigger the rule R±Kh,
besides the formula Khiψ, we still need the formula ¬Kiψ and a negation of
Khi-formula. Moreover, to keep the size of tableau for ϕ as small as possible, we
normally use only subformulas of ϕ. Therefore, in this paper, we call Kiϕ and
Khi⊥subformulas of Khiϕ.
Deﬁnition 12 (Length of formulas). The length of formulas len(ϕ) is deﬁned
as follows:
len(⊥) = 1
len(p) = 1
len(¬ϕ) = len(ϕ) + 1
len(ϕ ∧ψ) = len(ϕ) + len(ψ) + 1
len(Kiϕ) = len(ϕ) + 1
len(Khiϕ) = len(ϕ) + 3
Please note that applying the rule Cut-Kh will generates ¬Kiϕ for Khiϕ. To
ensure that the length of formulas will be shrunk during application of rules, we
need the length of ¬Kiϕ to be less than that of Khiϕ. This is the reason that
len(Khiϕ) = len(ϕ) + 3.
It can be shown that |sub(ϕ)| ≤len(ϕ) and |sub+(ϕ)| ≤2 · len(ϕ).
The following proposition says that formulas labelled on a node n are closed
under subformulas.
Proposition 3. Let b = ⟨L, S⟩be a branch of a saturated tableau for ϕ0. If
⟨n, ϕ⟩∈L, then for each subformula ψ of ϕ, either ⟨n, ψ⟩∈L or ⟨n, ¬ψ⟩∈L.

Tableau-Based Decision Procedure for ELKh
277
Proof. We prove it by induction on the length of ϕ. If len(ϕ) = 1, it implies that
ϕ is a proposition letter p or ⊥, then the claim holds trivially. Before moving on,
we would like to make it clear that the claim holds trivially if the subformula
ψ is ϕ, i.e., ψ := ϕ. If len(ϕ) = k + 1 where k ≥1, we then have the following
cases:
– ϕ := ¬p for some p, or ϕ := ¬⊥. It is obvious.
– ϕ := ¬¬χ. Except for ψ := ¬χ, each proper subformula ψ of ϕ is a subformula
of χ. Since the tableau is saturated, by the rule ⟨n, χ⟩∈L. By induction on
the length, we then have that either ⟨n, ψ⟩∈L or ⟨n, ¬ψ⟩∈L.
– ϕ := ¬(ϕ1 ∧ϕ2). Let ψ be a proper subformula of ϕ. We then have that
ψ := (ϕ1 ∧ϕ2), or ψ is a subformula of either ϕ1 or ϕ2. If ψ := (ϕ1 ∧ϕ2), we
then have that ⟨n, ¬ψ⟩∈L. Let ψ be a subformula of ϕ1. Since the tableau is
saturated, by the rule R∨, it implies that either ⟨n, ¬ϕ1⟩∈L or ⟨n, ϕ1⟩∈L.
By induction on the length, we have that either ⟨n, ψ⟩∈L or ⟨n, ¬ψ⟩∈L.
The proof is similar if ψ is a subformula of ϕ2.
– ϕ := ¬Kiχ. Except for ψ := Kiχ, each proper subformula ψ of ϕ is a subfor-
mula of χ. Since the tableau is saturated, by the rule Cut-¬K, it implies that
either ⟨n, ¬χ⟩∈L or ⟨n, χ⟩∈L. By induction on the length, we then have
that either ⟨n, ψ⟩∈L or ⟨n, ¬ψ⟩∈L.
– ϕ := ¬Khiχ. Except for ψ := Khiχ, each proper subformula ψ of ϕ is a
subformula of Kiχ. Since the tableau is saturated, by the rules Cut-¬Kh, it
implies that ⟨n, ¬Kiχ⟩∈L. By induction on the length, we then have that
either ⟨n, ψ⟩∈L or ⟨n, ¬ψ⟩∈L.
– ϕ := (ϕ1 ∧ϕ2). Each proper subformula ψ of ϕ is a subformula of either ϕ1
or ϕ2. By the rule R∧, we then have that both ⟨n, ϕ1⟩∈L and ⟨n, ϕ2⟩∈L.
By induction, we then have that either ⟨n, ψ⟩∈L or ⟨n, ¬ψ⟩∈L.
– ϕ := Kiχ. Each proper subformula ψ of ϕ is a subformula of χ. By the rule
KT, we then have that ⟨n, χ⟩∈L. By induction, we then have that either
⟨n, ψ⟩∈L or ⟨n, ¬ψ⟩∈L.
– ϕ := Khiχ. If the subformula of Khiχ is either Kiχ or Khi⊥, by the rule Cut-
Kh, we have that ¬Khi⊥∈L and either Khiχ ∈L or ¬Kiiχ ∈L. Except
Kiχ and Khi⊥, each proper subformula ψ of ϕ is a subformula of χ. By the
rules Cut-Kh, Cut-¬K, and KT, we then have that either ⟨n, ¬χ⟩∈L or
⟨n, χ⟩∈L. By induction, we then have that either ⟨n, ψ⟩∈L or ⟨n, ¬ψ⟩∈L.
Next, we will show that if n and n′ are linked by the epistemic relation ∼i,
then they share the same epistemic formulas and knowing-how formulas. Before
that, we ﬁrst show two auxiliary propositions.
Proposition 4. Let b = ⟨L, S⟩be a branch of a tableau T. If ⟨i, n, n′⟩∈S and
⟨n′, ψ⟩∈L, then there exists ⟨n, ϕ⟩∈L such that ψ is either a subformula of ϕ
or a negation of some subformula of ϕ.
Proof. For the branch in the initial tableau, the claim holds trivially, since the
set S in the branch of the initial tableau is ∅. We can observe that all the tableau
rules preserve the claim. Thus, the claim holds for all branches.

278
Y. Li
Proposition 5. Let b = ⟨L, S⟩be a branch of a saturated tableau T. If we have
that {⟨i, n0, n1⟩, · · · , ⟨i, nk, nk+1⟩} ⊆S and ⟨nk+1, ψ⟩∈L, we then have that
either ⟨n0, ψ⟩∈L or ⟨n0, ¬ψ⟩∈L.
Proof. It follows from Propositions 3 and 4.
Proposition 6. Let b = ⟨L, S⟩be an open branch of a saturated tableau T, and
let {⟨i, n0, n1⟩, · · · , ⟨i, nk, nk+1⟩} ⊆S. We have that ⟨n0, ψ⟩∈L iﬀ⟨nk+1, ψ⟩∈L
if ψ is either an epistemic formula Kiχ or a knowing-how formula Khiχ.
Proof. If ⟨n0, ψ⟩∈L, by the rule K4 or Kh4, we then have that ⟨nk+1, ψ⟩∈L.
If ⟨nk+1, ψ⟩∈L, by Proposition 5, we have that either ⟨n0, ψ⟩∈L or
⟨n0, ¬ψ⟩∈L. Suppose that ⟨n0, ¬ψ⟩∈L, by the rule K5 or Kh5, we then
have that ⟨nk+1, ¬ψ⟩∈L. This is contradictory with the fact that b is open.
Thus, we have that ⟨n0, ψ⟩∈L.
Now we are ready to show the key proposition of this section.
Proposition 7. Let T be a saturated tableau for ϕ0. If T is open, then ϕ0 is
satisﬁable.
Proof. Since T is open, there exists a branch b = ⟨L, S⟩∈T that is open. Next,
we will build a model for ϕ from the branch b. The model M = ⟨W, {∼i| i ∈
I}, {Ai | i ∈I}, {R(a) | a ∈Ai, i ∈I}, V ⟩is deﬁned as follows:
– W is the set of n occurring in b,
– for each i ∈I, ∼i is the reﬂexive, transitive and symmetric closure of the
binary relation {⟨n, n′⟩| ⟨i, n, n′⟩∈S} on W,
– for each i ∈I, Ai = {aKhiϕ | ⟨n, Khiϕ⟩∈L for some n},
– for each i ∈I and each aKhiϕ ∈Ai, R(aKhiϕ) = {⟨n, n′⟩| (Khiϕ, n, n′) ∈S},
– for each n ∈W, V (n) = {p | ⟨n, p⟩∈L}.
Since T is a saturated tableau for ϕ0, this implies that ⟨0, ϕ0⟩∈L. To show that
ϕ0 is satisﬁable, we will show the following more general claim:
M, n ⊨ϕ for all ⟨n, ϕ⟩∈L.
We prove the claim by induction on len(ϕ). If len(ϕ) = 1, since b is open,
this implies that ϕ := p. By the deﬁnition of M, we then have that M, n ⊨p. If
len(ϕ) = k + 1 where k ≥1, we then have the following cases:
– ϕ := ¬⊥. It is obvious.
– ϕ := ¬p. Since b is open and ⟨n, ¬p⟩∈L, this implies that ⟨n, p⟩̸∈L. By the
deﬁnition of M, we then have that M, n ⊨¬p.
– ϕ := ¬¬χ. Since T is saturated, by the rule R¬, we have that ⟨n, χ⟩∈L. By
induction, we have that M, n ⊨χ, and then M, n ⊨¬¬χ.
– ϕ := ¬(ϕ1 ∧ϕ2). By the rule R∨, we have that ⟨n, ¬ϕ1⟩∈L or ⟨n, ¬ϕ2⟩∈L.
By induction, we have that M, n ⊨¬ϕ1 or M, n ⊨¬ϕ2. Thus, we have
M, n ⊨¬(ϕ1 ∧ϕ2).

Tableau-Based Decision Procedure for ELKh
279
– ϕ := ¬Kiχ. By the rule R¬K, there is n′ such that (i, n, n′) ∈S and ⟨n′, ¬χ⟩∈
L. By induction, we have M, n′ ⊨¬χ. By the deﬁnition of M, we have that
n ∼i n′. Thus, we have that M, n ⊨¬Kiχ.
– ϕ := ¬Khiχ. Firstly, by the rule Cut-¬Kh, we have that ⟨n, ¬Kiχ⟩∈L. By
induction, we have that M, n ⊨¬Kiχ. This implies that ϵ cannot be a witness
plan for M, n ⊨Khiχ.
We continue to show that every action in Ai cannot not be a witness plan. If
there is some aKhiψ ∈Ai such that it is strongly executable on [n]i. It implies
that there is some n′ such that (n, n′) ∈R(aKhiψ) in M. By the deﬁnition
of M, we have that (Khiψ, n, n′) ∈S. Such triples can only be generated by
the rule R±Kh. Thus, we have that ⟨n′, ¬χ⟩∈L. By induction, we have that
M, n′ ⊨¬χ. Thus, aKhiψ is not a witness plan for M, n ⊨Khiχ.
Therefore, we have shown that for each σ ∈Aϵ
i, if it is strongly executable
on [n]i then there is some n′ ∈R(σ)([n]i) such that M, n′ ⊨¬χ. Thus, we
have M, n ⊨¬Khiχ.
– ϕ := (ϕ1∧ϕ2). By the rule R∧, we have that both ⟨n, ϕ1⟩∈L and ⟨n, ϕ2⟩∈L.
By induction, we have that both M, n ⊨ϕ1 and M, n ⊨ϕ2. Thus, we have
that M, n ⊨ϕ1 ∧ϕ2.
– ϕ := Kiχ. By the deﬁnition of ∼i, for each n′ ∈[n]i, there are three cases: (1)
n = n′; (2) there are (i, n0, n1), · · · , (i, nk, nk+1) in S such that n0 = n and
nk+1 = n′; (3) there are (i, n0, n1), · · · , (i, nk, nk+1) in S such that n0 = n′
and nk+1 = n.
For (1), by the rule KT, we have ⟨n′, χ⟩∈L. For (2) and (3), by Proposition
6, we have that ⟨n′, Kiχ⟩∈L. By the rule KT again, we have ⟨n′, χ⟩∈L.
Thus, we have shown that ⟨n′, χ⟩is in L in all cases. By induction, we have
M, n′ ⊨χ. Thus, we have M, n ⊨Kiχ.
– ϕ := Khiχ. By the rule Cut-Kh, we have that either ⟨n, Kiχ⟩∈L or
⟨n, ¬Kiχ⟩∈L. If ⟨n, Kiχ⟩∈L, by induction, we have that M, n ⊨Kiχ.
This means that ϵ can be a witness plan for M, n ⊨Khiχ. Therefore, we have
M, n ⊨Khiχ.
Next we focus on the case of ⟨n, ¬Kiχ⟩∈L. Since ⟨n, Khiχ⟩∈L, by
the rule Cut-Kh, we have that ⟨n, ¬Khi⊥⟩∈L. Thus, we now have that
{⟨n, Khiχ⟩, ⟨n, ¬Kiχ⟩, ⟨n, ¬Khi⊥⟩} ⊆L. Furthermore, by Proposition 6, we
have that for each m ∈[n]i, there is {⟨m, Khiχ⟩, ⟨m, ¬Kiχ⟩, ⟨m, ¬Khi⊥⟩} ⊆
L. By the rule R±Kh, we know that for each m ∈[n]i, there is nm such that
(Khiχ, n, nm) ∈S. By the deﬁnition of M, we know that aKhiχ is strongly
executable on [n]i. Moreover, for each n′ ∈R(aKhiχ)([n]i), we have by the
deﬁnition of M that (Khiχ, m, n′) ∈S where m ∈[n]i. By the tableau rules,
we know that there is ⟨n′, χ⟩∈L whenever a triple like (Khiχ, m, n′) is gen-
erated. Thus, by induction, we have that M, n′ ⊨χ. Therefore, we have that
M, n ⊨Khiχ.
Now we are ready to show the completeness of the tableau system.
Theorem 2 (Completeness). If there are no closed tableaux for ϕ0, then ϕ0
is Satisﬁable.

280
Y. Li
Proof. If there are no closed tableaux for ϕ0, it means that all tableaux for ϕ0
are open. We then can extend the initial tableau for ϕ0 to be an open saturated
tableau for ϕ0. By Proposition 7, ϕ0 is satisﬁable.
5
Decision Procedure
In this section we present a procedure of the tableau calculus deﬁned in Sect. 3.
The procedure below will construct a tree and deﬁne a function L that labels
each node of the tree with a set of formulas. There are three types of successors:
normal tree successors, i-successors, and Khiψ-successors. Moreover, for each
inner node s of the tree, either it has only normal tree successors, or it has i-
successors for each ¬Kiϕ ∈L(s) and Khiψ-successors for each Khiψ ∈L(s) but
Kiψ ̸∈L(s).
The procedure for constructing a tableau tree for ϕ:
1. Construct a tree consisting of a single node s0 (the “root”), with L(s0) =
{ϕ0}.
2. Repeat until none of below applies:
(a) Forming a subformula-closed tableau: if s is a leaf of the tree, L(s) is
not closed, and ψ is a witness to one of the following rules (we call them
‘static rules’): R¬, R∧, KT, Cut-Kh, Cut-¬K, Cut-¬Kh, and R∨, then:
* if ψ is the witness of R¬, R∧, KT, Cut-¬Kh, then create a successor
node s′ of s and set L(s′) = L(s) ∪Ψ where Ψ is the set of formulas
generated by applying the corresponding rule;
* if ψ is the witness of Cut-¬K or Cut-Kh, then create two successors
s1 and s2 of s and set L(s1) = L(s) ∪Ψ1 and L(s2) = L(s) ∪Ψ2
where Ψ1 and Ψ2 are the set of generated formulas by applying the
corresponding rule;
* if ψ is the witness of R∨, such as ¬(ψ1 ∧ψ2) ∈L(s), then create
three successors s1, s2, s3 of s and set L(s1) = L(s) ∪{¬ψ1, ¬ψ2},
L(s2) = L(s) ∪{¬ψ1, ψ2}, and L(s3) = L(s) ∪{ψ1, ¬ψ2}.
(b) Creating K and Kh successor nodes: if s is a leaf of the tree, L(s) is not
closed, and no static rules are applicable, then:
i. for each witness of the rule R¬K, such as ¬Kiχ ∈L(s), if there is no
ancestor s′′ of s in the tree such that
L(s′′) = {¬χ} ∪L(s)|Ki ∪L(s)|¬Ki ∪L(s)|Khi ∪L(s)|¬Khi
(where L(s)|Ki is the set of formulas Kiψ′ such that Kiψ′ ∈L(s) and
the sets L(s)|¬Ki, L(s)|Khi, L(s)|¬Khi are similarly deﬁned), then
create an i-successor node s′ (i.e., add node s′ th the tree and an edge
from s to s′ labelled i) and set L(s′) = {¬χ} ∪L(s)|Ki ∪L(s)|¬Ki ∪
L(s)|Khi ∪L(s)|¬Khi.
ii. for each witness of the rule R±Kh, such as {¬Khiχ, Khiψ, ¬Kiψ} ⊆
L(s), create a Khiψ-successor s′ and set L(s′) = {¬χ, ψ}.

Tableau-Based Decision Procedure for ELKh
281
In the remaining section, we will show that the procedure can be done in
polynomial spaces. Firstly, we show that the size of the tree constructed by the
procedure is of polynomial.
Proposition 8. The ﬁnal tree for ϕ constructed by the procedure above is an
O(m3)-ary tree whose height is at most m3, where m = |sub+(ϕ)|.
Proof. First, let us make an observation that for each node s of the tree, the set
L(s) is a subset of the set sub+(ϕ). This implies |L(s)| ≤m for each node s.
In step 2(a), we at most create three successors for a leaf. In step 2(b), there
are at most m witnesses for the rule R¬K because of |L(s)| ≤m. Since each
witness for the rule R±Kh is a set of three formulas, there are at most
m
3

witnesses for this rule. Thus, in step 2(b), we at most create
m
3

+ m successors
for a leaf. Therefore, the ﬁnal tree is an O(m3)-ary tree.
Next we show that the height of the ﬁnal tree is at most m3. Before that,
we introduce some notations. We use len(L(s)) to denote the biggest length of
formulas in L(s). Because of |L(s)| ≤m for each node s, this implies that we
can apply step 2(a) at most m times before we reach a node s′ such that either
L(s′) is closed or there are no static rules applicable to L(s′). In step 2(b), for
each successor node s′ created in 2(b)ii, we have that len(L(s′)) < len(L(s)).
However, this is not the case if the successor s′ is created in 2(b)i. For successor
node s′ created in 2(b)i, we have that len(L(s′)) ≤len(L(s)). As it is shown in
[6], there are at most m2 consecutive successors of s before the length of formulas
becomes strictly less. Thus, the height of the ﬁnal tree at most m3.
Please note that the ﬁnal tree for ϕ is an and-or tree, and each node is
attached a subset of sub+(ϕ). With a depth-ﬁrst exploration of an and-or tree,
we have the following:
Theorem 3. There is an algorithm that runs in polynomial space for deciding
whether there is a closed tableau for a formula.
Theorem 4. The satisﬁability of multi-agent knowing-how logic is PSPACE-
complete.
Proof. Multi-agent epistemic logic is a fragment of multi-agent knowing-how
logic. Since the multi-agent epistemic logic is PSPACE-hard (cf. [6]), this implies
that multi-agent knowing how logic is also PSPACE-hard. Moreover, to check
whether a formula ϕ is satisﬁable, by Theorems 1 and 2, we only need to check
whether there is a closed tableau for ϕ. By Theorem 3, we know that checking
the satisﬁability of a formula ϕ ∈L is in PSPACE. Thus, it is PSPACE-complete.
6
Conclusion
In this paper, we presented a tableau system for the knowing-how logic via simple
plans which is an extension of the standard epistemic logic. The tableau system
is an adaption of that proposed in [2]. We also presented a tableau-based decision

282
Y. Li
procedure that runs in polynomial space, which is an extension of the decision
procedure proposed in [6] for the standard epistemic logic. Since the multi-agent
epistemic logic is PSPACE-hard, it follows that the multi-agent knowing-how
logic via simple plans is PSPACE-complete.
A direct future work is to show the complexity of single-agent knowing-
how logic via simple plans. We know that the complexity of single-agent epis-
temic logic is NP-complete while the complexity of multi-agent epistemic logic
is PSPACE-complete. We guess that this is not the case for knowing-how logic
via simple plans. We conjecture the complexity of single-agent and multi-agent
knowing how logic via simple plans is the same. It is also interesting to discuss the
complexity for other knowing-how logics. In [1], they show that a knowing-how
logic with binary Khi-modalities is NP-complete.
Acknowledgment. This work is supported by the National Social Science Founda-
tion for Young Scholars of China (Grant No. 18CZX062). The author thanks three
anonymous reviewers for their useful comments, which helped the author to improve
the presentation of the paper.
References
1. Areces, C., Fervari, R., Saravia, A.R., Vel´azquez-Quesada, F.R.: Uncertainty-based
semantics for multi-agent knowing how logics. In: Halpern, J., Perea, A. (eds.) Pro-
ceedings Eighteenth Conference on Theoretical Aspects of Rationality and Knowl-
edge, Beijing, China, 25–27 June 2021. Electronic Proceedings in Theoretical Com-
puter Science, vol. 335, pp. 23–37. Open Publishing Association (2021). https://
doi.org/10.4204/EPTCS.335.3
2. Balbiani, P., van Ditmarsch, H., Herzig, A., De Lima, T.: Tableaux for public
announcement logic. J. Log. Comput. 20(1), 55–76 (2010). https://doi.org/10.
1093/logcom/exn060
3. Fan, J., Wang, Y., van Ditmarsch, H.: Contingency and knowing whether. Rev.
Symb. Log. 8(01), 75–107 (2015)
4. Fervari, R., Herzig, A., Li, Y., Wang, Y.: Strategically knowing how. In: IJCAI
International Joint Conference on Artiﬁcial Intelligence, pp. 1031–1038 (2017).
https://doi.org/10.24963/ijcai.2017/143
5. Gu, T., Wang, Y.: “Knowing value” logic as a normal modal logic. In: Proceedings
of AiML, vol. 11 (2016)
6. Halpern, J.Y., Moses, Y.: A guide to completeness and complexity for modal logics
of knowledge and belief. Artif. Intell. 54(2), 319–379 (1992)
7. Hintikka, J.: Knowledge and Belief: An Introduction to the Logic of the Two
Notions. Cornell University Press, Ithaca (1962)
8. Li, Y., Wang, Y.: Achieving while maintaining: a logic of knowing how with inter-
mediate constraints. In: Proceedings of ICLA 2017, pp. 154–167 (2017)
9. Li, Y., Wang, Y.: Multi-agent knowing how via multi-step plans: a dynamic epis-
temic planning based approach. In: Blackburn, P., Lorini, E., Guo, M. (eds.) LORI
2019. LNCS, vol. 11813, pp. 126–139. Springer, Heidelberg (2019). https://doi.org/
10.1007/978-3-662-60292-8 10
10. Li, Y., Wang, Y.: Planning-based knowing how: a uniﬁed approach. Artif. Intell.
296, 103487 (2021)

Tableau-Based Decision Procedure for ELKh
283
11. McCarthy, J.: First order theories of individual concepts and propositions. Mach.
Intell. 9, 129–147 (1979)
12. Moore, R.C.: A formal theory of knowledge and action. Technical report, DTIC
Document (1984)
13. Naumov, P., Tao, J.: Together we know how to achieve: an epistemic logic of know-
how. Artif. Intell. 262, 279–300 (2018)
14. Von Wright, G.H.: An Essay in Modal Logic. North Holland, Amsterdam (1951)
15. Wang, Y.: A logic of knowing how. In: van der Hoek, W., Holliday, W.H., Wang,
W. (eds.) LORI 2015. LNCS, vol. 9394, pp. 392–405. Springer, Heidelberg (2015).
https://doi.org/10.1007/978-3-662-48561-3 32
16. Wang, Y.: A logic of goal-directed knowing how. Synthese 195(10), 4419–4439
(2016). https://doi.org/10.1007/s11229-016-1272-0
17. Wang, Y., Fan, J.: Knowing that, knowing what, and public communication: public
announcement logic with Kv operators. In: Proceedings of IJCAI 2013, pp. 1147–
1154 (2013)

Integrating Individual Preferences
into Collective Argumentation
Chonghui Li(B)
and Beishui Liao
Institute of Logic and Cognition, Zhejiang University, Hangzhou, China
{lisabell,baiseliao}@zju.edu.cn
Abstract. In the ﬁeld of collective argumentation, multiple agents may
have distinct knowledge representations and individual preferences. In
order to obtain reasonable collective outcome for the group, either indi-
vidual frameworks should be merged or individual preference should be
aggregated. However, framework merging and preference aggregation are
diﬀerent procedures, leading to disagreements on collective outcome. In
this paper, we ﬁgure out a solution to combine framework merging, argu-
mentative reasoning and incomplete preference aggregation together.
Furthermore, a couple of rational postulates are proposed to be the cri-
teria for the reasonability of collective outcome obtained based on our
approach.
Keywords: Collective argumentation · Framework merging ·
Incomplete preference aggregation · Concordance
1
Introduction
Based on abstract argumentation, collective argumentation deals with the sce-
narios in which multiple agents have distinct individual frameworks representing
their observed information and reasoning knowledge, aiming to obtain a reason-
able reasoning outcome for the group [1]. For this purpose, an operation called
framework merging is adopted to form representative collective frameworks ﬁrst
and then jointly accepted arguments can be obtained by argumentative reason-
ing with the collective frameworks. The criteria for the reasonability lie in the
representativeness of collective frameworks and the acceptability of arguments
at the group level. Existing literatures [2–6] are along with this line. However, if
we extend individual frameworks to include individual preferences, what inﬂu-
ences do they have on collective outcome? And what are the renewed criteria
for the reasonability of collective outcome? Let us illustrate the questions with
an example: Three Detectives.
Example 1. There are four suspects A, B, C and D in a stolen jewellery case.
Each of them has an argument as follows.
– A: B is the criminal, because I saw B sold the jewellery to D two days ago.
(argument a)
c
⃝Springer Nature Switzerland AG 2021
P. Baroni et al. (Eds.): CLAR 2021, LNAI 13040, pp. 284–301, 2021.
https://doi.org/10.1007/978-3-030-89391-0_16

Integrating Individual Preferences into Collective Argumentation
285
– B: It’s none of my business. The truth is A, C and D conspired the stealing.
(argument b)
– C: I saw B wore a jewellery very similar to the stolen one yesterday. (argument
c)
– D: I know nothing about this incident. (argument d)
Assume there is a committee of three detectives (subscript indexed as 1, 2,
3) in charge of the case. They need to identify the conﬂicting arguments with
their own knowledge and reason with the case independently. Three individual
frameworks representing detectives’ distinct observed information are shown in
Fig. 1. Here each detective represents the arguments (the dots) which have attack
relation (the directed edges) in a di-graph, excluding the arguments which he/she
personally supposes to be irrelevant. Apart from this, three detectives have their
own preferences over the conﬂicting arguments, based on their personal credences
on the suspects’ arguments. Assume that each detective is a rational agent, whose
preference is always coherent with his/her cognition. That is to say, if a detective
supposes that argument a attacks argument b, then it is impossible for him/her
to suppose b is more credible than a.
Fig. 1. The proﬁle for three detectives
Note that the modelling of knowledge representations for three detectives
may not be unique. Due to the vagueness of natural language and the subjec-
tivity of personal cognition, multiple agents may have a variety of options for
their knowledge representations. Now based on the example, our research ques-
tion becomes more explicit: among four arguments, what are those arguments
accepted by the committee as a reasonable collective choice? And what are the
reasons for the choice?
Before the response, we need to make a further analysis on the nature of these
questions. On one hand, if individual preferences were not considered, through
the operations of framework merging and argumentative reasoning, three detec-
tives may reach a reasonable collective outcome. On the other hand, if we were
only informed with individual preferences over arguments, then through a pro-
cedure of preference aggregation, three detectives would agree on a social prefer-

286
C. Li and B. Liao
ence which leads to a reasonable collective choice too. It is obvious that frame-
work merging and preference aggregation are diﬀerent operations, they deviate
from each other in at least three points: diﬀerent inputs, diﬀerent measurements
on social agreement, and as a result, diﬀerent outputs. However, in the sce-
nario of Three Detectives, both individual frameworks and individual preferences
are provided as given information, we need to ﬁgure out an approach to com-
bine framework merging, argumentative reasoning and preference aggregation
together and ﬁnd an updated reasonable choice for the committee. Since indi-
vidual preferences indicate the credence on arguments and are always coherent
with the structure of individual frameworks, if they are aggregated to a reason-
able social preference, it is supposed to have dominant inﬂuences on collective
reasoning outcome. That is to say, an argument with greater credence according
to social preference should be more acceptable than the ones with less credences
for the group. Therefore, a solution for the combination could be: the collective
outcome obtained from framework merging and argumentative reasoning is in
concordance with social preference.
In this paper, we propose a novel method for framework merging which can
form representative collective frameworks and has less complexity in compu-
tation and better explainability, compared to Coste-Marquis’ method [2]. As
individual preferences might be incomplete with respect to the proﬁle, we adopt
a pairwise majority based procedure for incomplete preference aggregation, pro-
posed by Koncazk in [7]. Considering that the winner(s) of social preference is
possibly discarded in the stage of argumentative reasoning, we apply social pref-
erence as modiﬁcation of collective frameworks before argumentative reasoning.
Then the criteria for the reasonability of collective outcome are renewed: it is the
result obtained from reasoning with representative collective frameworks and in
concordance with majority-based social preference.
The layout of the paper is as follows. Section 2 recalls some preliminaries
of abstract argumentation, preference-based abstract argumentation, framework
merging, preference aggregation. In Sect. 3, we propose a novel method for frame-
work merging and evaluate the advantages of our method. In Sect. 4, we intro-
duce a procedure of incomplete preference aggregation, deﬁne a method to obtain
social preference over arguments and verify the reasonability of it. We establish
the concordance between collective framework and social preference and have it
evaluated in Sect. 5. Finally we conclude the paper in Sect. 6.
2
Preliminaries
First, let’s recall some key elements of abstract argumentation frameworks as
proposed by Dung in [8].
Deﬁnition 1. An abstract argumentation framework (AF) is a pair F = (A, D)
where A is a set of arguments and D ⊆A × A is a defeat relation.
The key problem is to determine the sets of arguments that can be accepted
together. According to some criteria, a set of accepted arguments is called an

Integrating Individual Preferences into Collective Argumentation
287
extension. Let us ﬁrst introduce two basic criteria: conﬂict-freeness and accept-
ability.
Deﬁnition 2. Given an AF F = (A, D) and a set of arguments S ⊆A, we
say that S is conﬂict-free iﬀ∄A, B ∈S such that (A, B) ∈D. We say that an
argument A ∈A is acceptable w.r.t. S iﬀ∀B ∈A, if (B, A) ∈D then ∃C ∈S
such that (C, B) ∈D.
A set of arguments S is admissible when it is conﬂict-free and each argument
in the set is acceptable w.r.t. S. Several semantics have been proposed based on
admissible sets. In this paper, we only focus on the standard semantics deﬁned in
[8]. We say S is a complete extension of F iﬀit is admissible and each argument
acceptable w.r.t. S belongs to S. S is a preferred extension of F iﬀit is a
maximal(w.r.t. set inclusion) complete extension of F. S is a grounded extension
of F iﬀit is the minimal (w.r.t. set inclusion) complete extension of F. S is a
stable extension of F iﬀit is conﬂict-free and it attacks all the arguments that
do not belong to S. We denote Eσ(F) the set of extensions of F for the semantics
σ ∈{co(mplete), pr(eferred), gr(ounded), st(able)}.
Preference-based argumentation framework is ﬁrst proposed by [9] as a
extended framework of abstract argumentation framework.
Deﬁnition 3. A preference-based argumentation framework (PAF) is a triple
Fp = (A, R, ≻), where A is a set of arguments, R ⊆A × A is a binary attack
relation and ≻is a strict partial order(irreﬂexive and transitive) over A, called
preference relation.
Deﬁnition 4. Let (A, R, ≻) be a PAF and the reduction of PAF is an AF F =
(A, D) s.t. ∀a, b ∈A:
– Reduction 1 [9]: (a, b) ∈D iﬀ(a, b) ∈R and b ⊁a;
– Reduction 2 [10]: (a, b) ∈D iﬀ((a, b) ∈R, b ⊁a) or ((b, a) ∈R, (a, b) /∈
R, a ≻b).
– Reduction 3 [11]: (a, b) ∈D iﬀ((a, b) ∈R, b ⊁a) or ((a, b) ∈R, (b, a) /∈R))
– Reduction 4 [11]: (a, b) ∈D iﬀ((a, b) ∈R, b ⊁a) or ((a, b) ∈R, (b, a) /∈R))
or ((b, a) ∈R, (a, b) /∈R, a ≻b).
Note that if preference is not included, a PAF is exactly an AF since each
attack in PAF is successfully converted to a defeat in AF. When preference is
given, there exists a relationship between PAF and AF, called reduction. Deﬁ-
nition 4 introduces four kinds of reduction in the existing literature. It is intu-
itive that an attack is successful (i.e. converted to a defeat) if and only if the
attacked argument is not stronger than the attacker. It is exactly what Reduc-
tion 1 states. However, if a class of attacks which is called critical attack exists,
namely (a, b) ∈R and b ≻a, they won’t be kept as defeats in AF. As a result,
conﬂicting arguments may be all accepted which violates conﬂict-freeness of
extensions. Critical attack is reversed in Reduction 2, deleted by Reduction 3
only if the opposite attack (b, a) ∈R exists and made to be a symmetric attack
by Reduction 4.
Next, we introduce basic deﬁnitions of framework merging and preference
aggregation within the scope of collective argumentation.

288
C. Li and B. Liao
Deﬁnition 5. Given {1, . . . , n} a set of agents and a proﬁle of AFs
ˆF =
(F1, . . . , Fn), where Fi = (Ai, Ri). Framework merging is an operation Mer :
ˆF →Fcoll, where Fcoll = (Acoll, Rcoll).
Note that diﬀerent operations may give rise to diﬀerent outputs and as a
result, collective framework may not be unique.
Deﬁnition 6. Given {1, . . . , n} is a set of agents, A1, . . . , An are sets of argu-
ments which belong correspondingly to agents {1, . . . , n} and a proﬁle of individ-
ual preferences is ˆP = (≻1, . . . , ≻n), where ≻i is agent i’s preference over Ai.
Then preference aggregation is a procedure Agg : ˆP →≿s. When A1 = · · · = An,
it is called complete preference aggregation, otherwise we say it is incomplete
preference aggregation.
Previous work [12–14] focuses on complete preference aggregation in the area
of collective argumentation. However, based on the settings of this paper, we con-
sider the more complicated situation, namely incomplete preference aggregation.
3
A Novel Method for Framework Merging
Given distinct individual frameworks and individual preferences, in this section
we temporarily put individual preferences aside and focus on obtaining collec-
tive frameworks from individual frameworks through the operation of framework
merging. In the vein of framework merging, quantitative approach and qualita-
tive approach tackle the problem diﬀerently. While the former treats the appear-
ances of an attack in individual frameworks as weight [4–6], the latter treats it
in a qualitative way. In extant literatures, Coste-Marquis proposes a qualitative
approach [2]. There are three steps: consensual expansion, distance-based frame-
work merging and argumentative reasoning. The main idea is to form represen-
tative collective frameworks ﬁrst and then obtain collective reasoning outcome.
However, it has high complexity in computation, limited capacity in explanation
and diﬃculty in including individual preference.
As preference is regarded as a qualitative force inﬂuencing argument strength,
we adopt qualitative approach to merging individual frameworks. We propose a
novel method for framework merging. First of all, we deﬁne a class of relation in
collective framework.
Deﬁnition 7. Given a proﬁle of AFs ˆF = (F1, . . . , Fn), where Fi = (Ai, Ri).
We say a relation (a, b) is exclusive w.r.t. ˆF iﬀa, b ∈Ai and ∄Fk = (Ak, Rk)
where i ̸= k s.t. a ∈Ak and b ∈Ak.
Deﬁnition 7 identiﬁes a special class of binary relation, which appears only
once in the proﬁle of individual frameworks. Note that exclusive relations
includes either attack or non-attack. Based on it, we deﬁne our method of frame-
work merging.
Deﬁnition 8. Given a proﬁle of AFs ˆF = (F1, . . . , Fn), where Fi = (Ai, Ri).
Our method of framework merging is the operation giving rise to a set of collective
framework, denoted as Γ = {Fcoll1, . . . , Fcollk}, where Fcollj = (Acollj, Rcollj).
Γ is deﬁned as:

Integrating Individual Preferences into Collective Argumentation
289
– Acoll1 = · · · = Acollk = 
i Ai;
– Rcoll1, . . . , Rcollk are exactly the members in R1
 R2
 R∗
3, where1:
• R1 = {(a, b)|(a, b) is an exclusive attack w.r.t. ˆF};
• R2 = {(a, b)|#({i|(a, b) ∈Ri}) > #({j|(a, b) /∈Rj}), where Fi =
(Ai, Ri), Fj = (Aj, Rj) and a, b ∈Ai ∩Aj};
• R∗
3 ∈2R3, where R3 = {(a, b)|#({i|(a, b) ∈Ri}) = #({j|(a, b) /∈Rj}),
where Fi = (Ai, Ri), Fj = (Aj, Rj) and a, b ∈Ai ∩Aj}.
Let’s proceed with some elaborations on Deﬁnition 8. In each collective frame-
work, the set of attacks is corresponding to each member in the union of: R1, R2
and R∗
3. R1 is the set of attacks which are exclusive w.r.t the proﬁle of individual
frameworks. R2 and R3 are sets of attacks involving pairs of arguments which
are in common in the proﬁle of individual frameworks. For any attack, only if
the votes of its appearance in the proﬁle of individual frameworks are strictly
greater than the ones of its absence can it be preserved in R2. Therefore, R2
is based on strict majority. R3 deals with the attacks which have equal votes
for their appearances and absences in the proﬁle of individual frameworks. Each
member of 2R3 has equal possibility to appear in the set of attack in collective
frameworks. For instance, if R3 = {(a, b)}, then we have two collective frame-
works: one includes the pair in its set of attack and the other denies the pair as
its attack.
In the following, we illustrate two basic properties of our approach of frame-
work merging.
Proposition 1. #(Γ) = 2#(R3).
Proof. The cardinality of set Γ is the number of collective frameworks we
obtained from framework merging operation Mer. According to Deﬁnition 8, the
number of collective frameworks is determined by #({Acoll}) and #({Rcoll}).
Due to #({Acoll}) = 1, the number of collective frameworks is determined by
#({Rcoll}), i.e. #({R1
 R2
 R∗
3}). As R∗
3 ∈2R3, #(Γ) = #(2R3), i.e. equals
to 2#(R3).
Corollary 1. If R3 = ∅, then the collective framework is unique.
Let us illustrate the method with the running example.
Example 2. Given the proﬁle of three detectives’ individual frameworks as Fig. 1
shows, if we exclude individual preferences in this stage, we obtain four collective
frameworks Fcoll1, Fcoll2, Fcoll3, Fcoll4 according to Deﬁnition 8, shown in Fig. 2.
Here, R1 = {(a, c)}, R2 = {(c, b), (b, d), (d, b)(a, d)}, R3 = {(a, b), (b, a)}. Hence
according to Proposition 1, #(Γ) = 22 = 4.
Our approach forms collective frameworks on the basis of classifying the
attacks in the proﬁle of individual frameworks into three categories. It is one-step
operation and has better explainability on how we merge individual frameworks.
Another beneﬁt is that we are informed the number of collective frameworks as
soon as R3 is calculated. For the evaluation, we deﬁne ﬁve rational postulates,
referring some of them to [15] and [16].
1 For any set S, #(S) denotes the cardinality of S.

290
C. Li and B. Liao
Fig. 2. Four collective frameworks for Three Detectives example
Deﬁnition 9. Given a proﬁle of AFs ˆF = (F1, . . . , Fn), where Fi = (Ai, Ri).
Through a framework merging operation Mer, we obtain the set of collective
frameworks Γ = {Fcoll1, . . . , Fcollk}, where Fcollj = (Acollj, Rcollj). Five rational
postulates on attack are deﬁned as:
– Nomination [15] (P1). If #({i ∈n|(a, b) ∈Ri}) = 1, then (a, b) ∈
j Rcollj.
– Unanimity [16] (P2). If #({i ∈n|(a, b) ∈Ri}) = n, then (a, b) ∈
j Rcollj.
– Strict majority (P3). Let #({i ∈n|a ∈Ai, b ∈Ai}) = m. If #({i ∈
m|(a, b) ∈Ri}) > m
2 , then (a, b) ∈
j Rcollj.
– Weak majority (P4). Let #({i ∈n|a ∈Ai, b ∈Ai}) = m. If #({i ∈
m|(a, b) ∈Ri}) = m
2 , then ∃Fcollj ∈Γ s.t. (a, b) ∈Rcollj.
– Closure [16] (P5). 
j Rcollj ⊆
i Ri.
Nomination (P1) means once the attack appears in individual frameworks
it will appear in collective frameworks. According to Deﬁnition 8, it is obvious
that: P1 is satisﬁed by R1; unanimity (P2) and strict majority (P3) are satisﬁed
by R2; weak majority (P4) is satisﬁed by R3. Note that strict minority of attacks
in the proﬁle of individual frameworks will not preserved in the set of attack of
collective frameworks but closure (P5) on attack is held. In short, our method
satisﬁes above ﬁve rational postulates and the collective frameworks obtained
from the method is representative for the proﬁle of individual frameworks.
Proposition 2. The collective frameworks obtained according to Deﬁnition 3
satisﬁes P1, P2, P3, P4 and P5.
Now we introduce argumentative reasoning. To obtain a collective outcome
for the group, we need to ﬁnd the acceptability for arguments in collective frame-
works. As we introduced in Sect. 2, acceptability of arguments is determined by
abstract argumentation semantics (refer as Deﬁnition 2). If collective framework
is unique, we can ﬁgure out the extensions instantly. If there are multiple collec-
tive frameworks, how to ﬁnd out the joint acceptability of arguments? Here, we
adopt Coste-Marquis’ proposal in [2].
Deﬁnition 10. Given a set of collective frameworks Γ = {Fcoll1, ..., Fcollk},
obtained from ˆF according to Deﬁnitions 8, where Fcollj = (Acollj, Rcollj). For
any subset S ⊆Acollj:
S is sceptically jointly accepted for Γ iﬀ∀Fcolli ∈Γ, ∃E ∈Eσ(Fcolli) and S ⊆E.
S is credulously jointly accepted for Γ iﬀ∃Fcolli ∈Γ, ∃E ∈Eσ(Fcolli) and S ⊆E.
The sets of arguments which are sceptically and credulously jointly accepted under
a certain semantics σ are denoted respectively as Saσ(Γ), Caσ(Γ).

Integrating Individual Preferences into Collective Argumentation
291
4
Incomplete Preference Aggregation
In this section, we deal with individual preferences. In order to ﬁnd a reasonable
social preference for the group, a procedure for preference aggregation is needed.
Since each individual framework is distinct, individual preferences are incomplete
with respect to the proﬁle. Thus a procedure of incomplete preference aggrega-
tion should be considered. In this section, we adopt pairwise majority based
procedure to obtain Condorcet winners for the proﬁle of incomplete individual
preferences, proposed by Konczak in [7] and deﬁne a social preference over argu-
ments of collective frameworks based on Condorcet winners. We evaluate the
social preference obtained based on our method with three rational postulates.
In the following, we provide the basic notion of Condorcet winner in tradi-
tional preference aggregation, introduce the extended notions of necessary Con-
dorcet winner and possible Condorcet winner, and the algorithms to compute
two kinds of Condorcet winner. These are already introduced in [7]. We adapt
the deﬁnitions in the context of collective argumentation.
Deﬁnition 11. Given ˆP = (≻1, . . . , ≻n) is a proﬁle of complete individual pref-
erences, where ≻i is a strict total order over a set of alternatives: {a, b, . . . }. An
alternative x is deﬁned as a Condorcet winner iﬀ∀y ̸= x, #({i|x ≻i y}) > n
2 .
Deﬁnition 12. Given a proﬁle of AFs ˆF = (F1, . . . , Fn), where Fi = (Ai, Ri)
and ˆP = (≻1, . . . , ≻n) is a proﬁle of incomplete individual preferences w.r.t.

i Ai, where ≻i is a strict total order over Ai, we say ≻′
i is a completion of ≻i
w.r.t. ˆP iﬀ≻′
i is a strict total order over 
i Ai and ≻′
i extends ≻i. The set of
all completions of ≻i is denoted as Com(≻i).
Deﬁnition 13. Given a proﬁle of AFs ˆF = (F1, . . . , Fn), where Fi = (Ai, Ri)
and ˆP = (≻1, . . . , ≻n) is a proﬁle of incomplete individual preferences w.r.t.

i Ai, let Com( ˆP) = Com(≻1) × ... × Com(≻n), for any a ∈
i Ai we deﬁne:
– a is a necessary Condorcet winner iﬀ∀ˆP′ ∈Com( ˆP), a is a Condorcet winner
for ˆP′;
– a is a possible Condorcet winner iﬀ∃ˆP′ ∈Com( ˆP), a is a Condorcet winner
for ˆP′.
Deﬁnition 14. Given a proﬁle of AFs ˆF = (F1, . . . , Fn), where Fi = (Ai, Ri)
and ˆP = (≻1, . . . , ≻n) is a proﬁle of incomplete individual preferences w.r.t.

i Ai, for x, y ∈
i Ai, we denote N ˆ
P(x, y) = #({i|x ≻i y}) −#({i|y ≻i x}),
then we deﬁne:
N max
≻i
(x, y) =

+1
if not (y ≻i x)
−1
if y ≻i x
and N min
≻i (x, y) =

+1
if x ≻i y
−1
if not (x ≻i y)
N max
ˆ
P
(x, y) =
n

i=1
N max
≻i
(x, y) and N min
ˆ
P
(x, y) =
n

i=1
N min
≻i (x, y)

292
C. Li and B. Liao
Argument a is a necessary Condorcet winner iﬀ∀y ̸= a, N min
ˆ
P
(a, y) > 0. The
set of necessary winners for ˆP is denoted as NW( ˆP).
Argument a is a possible Condorcet winner iﬀ∀y ̸= a, N max
ˆ
P
(a, y) > 0. The
set of possible winners for ˆP is denoted as PW( ˆP).
Note that due to x, y ∈
i Ai, y ≻i x implies that x, y ∈Ai and hence “not
y ≻i x” indicates the situations as follows: (1)x, y ∈Ai but x ≻i y; (2)either x
or y is not in Ai; (3)neither x nor y is in Ai. The intuition of the algorithms
is that for any pair of arguments (x, y), N max
ˆ
P
(x, y) covers the “best” case and
N min
ˆ
P
(x, y) covers the “worst” case among all completions of individual prefer-
ences. If an argument is superior to any other arguments in the “worst” case, it
is a necessary Condorcet winner for ˆP.
In [7], Konczak states that possible Condorcet winners surely exist while nec-
essary Condorcet winners do not. However, our question is: based on necessary
and possible Condorcet winners, how to form a social preference over arguments
of collective frameworks? Next, we propose a method.
Deﬁnition 15. Given a proﬁle of AFs ˆF = (F1, . . . , Fn), where Fi = (Ai, Ri)
and ˆP = (≻1, . . . , ≻n) is a proﬁle of incomplete individual preferences over

i Ai. Let NW( ˆP) and PW( ˆP) be the set of necessary and possible winners
for ˆP, then an aggregated social preference over 
i Ai (i.e. the set of arguments
of collective frameworks), denoted as ≿s, is deﬁned based on a strict partition
≫on the sets of arguments:
– If NW( ˆP) ̸= ∅, then NW( ˆP) ≫PW( ˆP) \ NW( ˆP) ≫
i Ai \ (NW( ˆP) ∪
PW( ˆP));
– If NW( ˆP) = ∅, then PW( ˆP) ≫
i Ai \ PW( ˆP).
Then for any two arguments a, b ∈
i Ai:
– If a, b belong to the same partition, then: a ∼s b;
– If a, b belong to diﬀerent partitions, then a ≻s b iﬀa is in the former partition
and b is in the latter.
We illustrate the operation for incomplete preference aggregation deﬁned
above with Three Detectives example.
Example 3. Proceed with Example 1. The AFs proﬁle is ˆ
F3 = (F′
1, F′
2, F′
3) as
shown in Fig. 1. The proﬁle of incomplete individual preferences w.r.t {a, b, c, d}
is ˆP3 = (≻1, ≻2, ≻3), where:
• ≻1: a ≻1 d and b ≻1 d,
• ≻2: c ≻2 b ≻2 d,
• ≻3: a ≻3 c ≻3 b and a ≻3 d.
According to Deﬁnition 14, N min
ˆ
P
(x, y) and N max
ˆ
P
(x, y) are shown in Table 1,
where x, y ∈{a, b, c, d}. As ∄y ̸= x, N min
ˆ
P
(x, y) > 0, NW( ˆP3) = ∅; As ∀y ̸= x,
when x = a and c, N max
ˆ
P
(x, y) > 0, PW( ˆP3) = {a, c}. Thus there is no necessary
Condorcet winner and the possible Condorcet winners for ˆP3 are arguments a, c.
According to Deﬁnition 15, we obtain a social preference: a ∼s c ≻s b ∼s d.

Integrating Individual Preferences into Collective Argumentation
293
Table 1. N min
ˆ
P
(x, y) and N max
ˆ
P
(x, y) for ˆP3
N min
ˆ
P
(x, y)
a
b
c
d
a
–
−1 −1
1
b
−3
–
−3 −1
c
−3
1
–
−1
d
−3 −1 −3
–
N max
ˆ
P
(x, y)
a
b
c
d
a
–
3
3
3
b
1
– −1 1
c
1
3
–
3
d
−1 1
1
–
To evaluate social preference obtained according to Deﬁnition 14 and 15, we
propose three postulates as follows.
Deﬁnition 16. Given a proﬁle of AFs ˆF = (F1, . . . , Fn), where Fi = (Ai, Ri)
and ˆP = (≻1, . . . , ≻n) is a proﬁle of incomplete individual preferences over

i Ai. Let Γ be the set of collective frameworks, the social preference for ˆP be
≿s and σ be a certain semantics. Three rational postulates on social preference
are deﬁned as:
– Completeness (P6). ≿s is complete and transitive.
– Pairwise strict majority (P7). If a ≻s b, then: #({i ∈n|a ≻i b}) >
#({i ∈n|b ≻i a}) or #({i ∈n| not (b ≻i a)}) > #({i ∈n| not (a ≻i b)}).
– Decisiveness in joint acceptance (P8). If NW( ˆP) = {a}, then a ∈
Saσ(Γ).
First of all, let us explain the implications of these rational postulates. Com-
pleteness means each argument in collective framework can be compared w.r.t.
social preference. As individual preferences are partial orders which means some
of arguments are incomparable w.r.t. individual preferences. Our method con-
tributes the total comparability of arguments at the collective level. Pairwise
strict majority indicates social preference has two characteristics of pairwise-
majority-based consensus among agents, which actually maximises the agree-
ment for the group. Decisiveness in joint acceptance states the necessary Con-
dorcet winner always sceptically jointly accepted under a certain semantics as a
collective outcome.
The satisfaction of P6 can be obtained instantly according to Deﬁnition 15
and the satisfaction of P7 are given in the following proposition.
Proposition 3. Given a proﬁle of AFs ˆF = (F1, . . . , Fn), where Fi = (Ai, Ri)
and ˆP = (≻1, . . . , ≻n) is a proﬁle of incomplete individual preferences over

i Ai. Let the social preference for ˆP be ≿s, if a ≻s b, then: #({i ∈n|a ≻i
b}) > #({i ∈n|b ≻i a}) or #({i ∈n| not (b ≻i a)}) > #({i ∈n| not (a ≻i b)}).
Proof. According to [7], if necessary Condorcet winner exists, it is also a possible
Condorcet winner and PW( ˆP)\NW( ˆP) = ∅. Then according to Deﬁnition 15, if
a ≻s b, we have two possible situations:(1) a is a necessary Condorcet winner and
b is neither a necessary Condorcet winner nor a possible Condorcet winner. If we
want to prove #({i ∈n|a ≻i b}) > #({i ∈n|b ≻i a}) holds for this situation, we

294
C. Li and B. Liao
need to prove N min
ˆ
P
(a, b) > 0. It is always held, since a is a necessary Condorcet
winner and ∀x ̸= a, N min
ˆ
P
(a, x) > 0. (2) a is a possible Condorcet winner and b
is neither a necessary Condorcet winner nor a possible Condorcet winner. If we
want to prove #({i ∈n| not (b ≻i a)}) > #({i ∈n| not (a ≻i b)}), we need to
prove N max
ˆ
P
(a, b) > 0. It is always held, since a is a possible Condorcet winner
and ∀x ̸= a, N max
ˆ
P
(a, x) > 0.
The veriﬁcation for our method on P8 is based on the deﬁnition preference-
coherent, which is a reasonable assumption to require agents to be rational. That
is to say, an argument with less credence should not attack the argument more
credible than it. Note that symmetric attack possibly exists when two arguments
are incomparable w.r.t a partial order.
Deﬁnition 17. Given a PAF FP = (A, R, ≻), where ≻is a strict partial order
over A. We say Fp is preference-coherent iﬀfor any a, b ∈A : (a, b) ∈R, (b, a) /∈
R iﬀa ≻b; (a, b) ∈R, (b, a) ∈R only if a, b is incomparable w.r.t ≻.
Theorem 1. Given a proﬁle of AFs ˆF = (F1, . . . , Fn) and ˆP = (≻1, . . . , ≻n) is
a proﬁle of individual preferences, where Fi = (Ai, Ri) and ≻i is an individual
preference over Ai. Let each AF in ˆF be preference-coherent w.r.t. its individual
preference, Γ be the set of collective frameworks, ≿s be social preference for ˆP
and σ = gr. If NW( ˆP) = {b}, then b ∈Saσ(Γ).
Proof. Given NW( ˆP) = {b}, we know that b is on the top rank of ≿s and it is the
unique winner. b ∈Sagr(Γ) means b is not attacked in all collective frameworks.
Assume the contrary, that is to say b is attacked in some of collective frameworks
and we need to prove a contradiction with NW( ˆP) = {b}. Let the attacker of b
in some of collective frameworks be argument c, we have b ≻s c. According to P7,
the characteristic of pairwise majority for necessary winner b is held as: #({i ∈
n|b ≻i c}) > #({i ∈n|c ≻i b}) (equation (i)). As each AF in ˆF is preference-
coherent w.r.t. its individual preference, the set of individual frameworks which
has individual preference b ≻i c has two situations: let the cardinalities of two
situations be k1 = #({i|(b, c) ∈Ri and (c, b) /∈Ri}), k2 = #({i|(b, c), (c, b) /∈
Ri}); the set of individual frameworks which has individual preference c ≻i b also
has two situations: let the cardinalities of two situations be k3 = #({i|(c, b) ∈Ri
and (b, c) /∈Ri, k4 = #({i|(b, c), (c, b) /∈Ri}); There are two situations left for
individual preference in which b and c are incomparable, let the cardinalities of
two situations be k5 = #({i|(b, c), (c, b) ∈Ri}), k6 = #({i|(b, c), (c, b) /∈Ri}).
Then according to equation (i), we have: k1 + k2 > k3 + k4 + k5 + k6 (equation
(ii)). Since c is the attacker of b in some of collective frameworks and (c, b)
can’t be an exclusive attack in R1 since b is a necessary Condorcet winner,
according to Deﬁnition 8, we have (c, b) ∈R3 or (c, b) ∈R2, which means
k3 + k5 ≥k1 + k2 + k4 + k6 (equation (iii)), contradicting to equation (ii),
which means b is not a necessary Condorcet winner. Contradiction. Hence the
conclusion is held.
Three postulates consist of criteria for the reasonability of social preference.
As discussed above, we reach the conclusion that our method satisﬁes all of them
and the social preference is reasonable.

Integrating Individual Preferences into Collective Argumentation
295
Proposition 4. The Social preference obtained from the method according to
Deﬁnition 14 and Deﬁnition 15 satisﬁes P6, P7 and P8.
5
The Concordance Between Collective Framework and
Social Preference
In Sect. 3 we deﬁne a method for framework merging and in Sect. 4 we pro-
vide a method for obtaining social preference based on Konczak’s deﬁnitions of
necessary and possible Condorcet winners. Furthermore, we evaluate the rea-
sonabilities of two methods respectively with a couple of postulates. The results
are positive, showing that they are both reasonable according to the criteria.
However, in our scenario, individual preferences are provided as given informa-
tion as well as individual frameworks. A uniﬁed reasonable collective outcome is
expected for the group of agents. Since framework merging and preference aggre-
gation are diﬀerent operations with diﬀerent inputs, it is supposed that collective
outcomes obtained respectively may not agree with each other. Although in The-
orem 1, we have already proved that the necessary Condorcet winner is always
sceptically jointly accepted under grounded semantics as a collective outcome,
the disagreement on the joint acceptability of other arguments could still exist.
Let us check it with the running example Three Detectives.
Example 4. First we perform argumentative reasoning according to Deﬁnition
10 with four collective frameworks obtained in Example 2. Let σ = pr, we
have: Epr(Fcoll1) = {{a, b}}, Epr(Fcoll2) = {{a}}, Epr(Fcoll3) = {∅}, Epr(Fcoll4) =
{{a}, ∅}. Therefore, we don’t have sceptically jointly accepted arguments under
preferred semantics and credulously jointly accepted arguments under preferred
semantics are a, b. While the result of social preference obtained in Example 3
shows that a, c should be mostly acceptable. The results of two operations agree
on one argument but disagree with each other on two arguments!
Now the question comes: how to obtain a renewed reasonable collective out-
come with more agreements? Since social preference stands for majority based
consensus on the credence over arguments in collective frameworks, it should
have dominance on the acceptability of arguments. For this reason, shall we
only take the result of social preference into account and disregard the reasoning
result from collective frameworks? It is unreasonable. Take the running example
for illustration, there is an attack between the winners of social preference accord-
ing to each collective framework, which means argument a and c can not be both
accepted. Therefore, we need to ﬁnd a solution which integrates social preference
into collective frameworks or collective extensions. As proposed in [10,11,17],
preference may have two roles in single-framework argumentation: one role as
modiﬁcation of framework and the other role as reﬁnement of extensions. In our
scenario, after framework merging, we obtain a set of representative collective
frameworks. To some extent, each of them can be seen as a single framework rep-
resenting for the group as a whole. Thus we may consider the application of two
roles for social preference. If we apply it as reﬁnement on collective extensions,

296
C. Li and B. Liao
a possible situation could be that the winners of social preference are discarded
in the stage of argumentative reasoning. Hence the option left for us is to apply
social preference as modiﬁcation of collective frameworks, which is also called
reduction in [9–11]. In the background of collective argumentation, we call it the
concordance between collective framework and social preference. We distinguish
two forms of concordance, namely strong concordance and weak concordance.
Their deﬁnitions are based on Reduction 2 and Reduction 4 in Deﬁnition 4.
Formally, we deﬁne them as follows.
Deﬁnition 18. Given a proﬁle of AFs ˆF = (F1, . . . , Fn), where Fi = (Ai, Ri)
and ˆP = (≻1, . . . , ≻n) is a proﬁle of incomplete individual preferences over

i Ai. Let Γ = {Fcoll1 . . . Fcollk} be the set of collective frameworks, where
Fcollj = (Acollj, Rcollj) and the social preference for ˆP be ≿s.
– Strong concordance is a mapping Const
:
Γ
→
Γ ′
st, where Γ ′
st
=
{F′
coll1 . . . F′
collk} and F′
collj = (Acollj, Dcollj), deﬁned as: ∀Fcollj ∈Γ s.t.
(b, a) ∈Rcollj, (a, b) /∈Rcollj, if a ≻s b, then: (a, b) ∈Dcollj.
– Weak concordance is a mapping Conwe
:
Γ
→
Γ ′
we, where Γ ′
we
=
{F′
coll1 . . . F′
collk} and F′
collj = (Acollj, Dcollj), deﬁned as: ∀Fcollj ∈Γ s.t.
(b, a) ∈Rcollj, (a, b) /∈Rcollj, if a ≻s b, then: (b, a) ∈Dcollj, (a, b) ∈Dcollj.
We apply two concordances with Three Detectives example and check
whether the disagreement is diminished.
Example 5. Proceed with Example 4. Let σ = gr, according to Deﬁnition 18:
– If we require a strong concordance between collective framework and social
preference, Γ ′
st = {F′
coll1, F′
coll2}, where F′
coll1 and F′
coll2 are shown in Fig. 3.
Egr(F′
coll1) = {{a, b}} and Egr(F′
coll2) = {{a}}. Therefore, argument a is
sceptically jointly accepted under grounded semantics as collective outcome.
– If we require a weak concordance between collective framework and social
preference, Γ ′
we = {F′
coll1, F′
coll2, F′
coll3}, where F′
coll1, F′
coll2 and F′
coll3 are
shown in Fig. 3. Egr(F′
coll1) = {{a, b}}, Egr(F′
coll2) = {{a}} and Egr(F′
coll3) =
{∅}. Therefore, argument a is credulously jointly accepted under grounded
semantics as collective outcome.
Fig. 3. Collective frameworks after concordance in Three Detectives
From Example 5 we can see that after the operation of concordance, under
grounded semantics (which is the most sceptical of all), argument a can be

Integrating Individual Preferences into Collective Argumentation
297
sceptically (with strong concordance) or credulously (with weak concordance)
jointly accepted as a collective outcome. Actually, if we choose preferred seman-
tics (which is the most credulous of all), argument a will be sceptically jointly
accepted with both strong and weak concordance. After the operation of con-
cordance, an agreement (i.e. the sceptical joint acceptability of arguments under
a certain semantics) has been reached between the reasoning result from frame-
work merging and one of social winners!
To evaluate the operation of concordance and provide new criteria for the
reasonability of collective outcome, we propose three postulates as follows.
Deﬁnition 19. Let Γ = {Fcoll1 . . . Fcollk} be the set of collective frameworks,
where Fcollj = (Acollj, Rcollj) and the social preference for ˆP be ≿s. Let the
operation of concordance be Conx where x ∈{st, we}. Let the sets of collective
frameworks obtained after concordance be Γ ′
x. Let σ ∈{co, pr, gr, st} and the
sets of sceptically and credulously jointly accepted arguments after concordance
be Saσ(Γ ′
x) and Caσ(Γ ′
x). Let win(≿s) = {a|∀b ∈Acollj s.t. a ≻s b or a ∼s b
but not the case b ≻s a} denote the set of social winners.
– Collective cardinality decline (P9). #(Γ ′
x) ⊆#(Γ).
– Joint acceptance growth (P10). Saσ(Γ) ⊆Saσ(Γ ′
x) and Caσ(Γ) ⊆
Caσ(Γ ′
x).
– Social winner(s) dominance (P11). ∃a ∈win(≿s) s.t. a ∈Saσ(Γ ′
x).
Let us elaborate the implications of these postulates. P9 states that after
concordance, the cardinality of collective frameworks declines which means rep-
resentative frameworks for the group become more concentrated and complexity
of computation is reduced. P10 indicates that another beneﬁt of concordance
is more arguments are possible to be jointly accepted. P11 says although it
seems that the group are less prudent on the acceptance of arguments than
before according P10, we make sure that at least one of social winners is scep-
tically accepted under a certain semantics as collective outcome, which implies
non-emptiness of collective outcome. Next, we verify our methods with three
postulates.
Proposition 5. The operations of strong concordance and weak concordance
satisfy collective cardinality decline (P9).
Proof. Only if ∃a, b ∈Acoll s.t. (a, b), (b, a) ∈R3 and a, b is not indiﬀerent
according to ≿s, we have #(Γ ′
x) ⊂#(Γ) and in other situations we have #(Γ ′
x) =
#(Γ). Thus the conclusion is held.
Corollary 2. #(Γ ′
st) ⊆#(Γ ′
we).
Proof. When ∃a, b ∈Acoll s.t. (a, b), (b, a) ∈R3 and a, b is not indiﬀerent accord-
ing to ≿s, we have at least four collective frameworks. According to strict con-
cordance, ∅, (a, b) or ∅, (b, a) will preserved as a result while symmetric attack
(a, b)(b, a) will be excluded. According to weak concordance, (a, b)(b, a) will
also preserved, which means #(Γ ′
st) ⊂#(Γ ′
we). In other situations we have
#(Γ ′
x) = #(Γ). Thus the conclusion is held.

298
C. Li and B. Liao
Proposition 6. The operation of strong concordance doesn’t satisfy joint accep-
tance growth (P10) while the operation of weak concordance satisﬁes it only if
under complete, preferred and stable semantics.
Proof. First we prove the violation of strong concordance. According to the
deﬁnition, ∀Fcollj ∈Γ, if a ≻s b, (b, a) ∈Rcollj, (a, b) /∈Rcollj, then (a, b) ∈
Dcollj. It means argument a will take the place of argument b appearing in the set
of sceptically jointly accepted arguments if a is not defeated by other arguments.
∃b ∈Saσ(Γ) and b /∈Saσ(Γ ′
st), thus Saσ(Γ) ⊈Saσ(Γ ′
st). The proof of Caσ(Γ) ⊈
Caσ(Γ ′
st) is the same. Next we prove the operation of weak concordance satisﬁes
P10 only if under complete, preferred and stable semantics. According to the
deﬁnition, ∀Fcollj ∈Γ, if a ≻s b, (b, a) ∈Rcollj, (a, b) /∈Rcollj, weak concordance
make the attack (b, a) to be symmetric. It means if argument a and b are not
defeated by other arguments, under grounded semantics neither of them can be
sceptically jointly accepted. ∃b ∈Sagr(Γ) and b /∈Sagr(Γ ′
we). Thus Sagr(Γ) ⊈
Sagr(Γ ′
we). The proof of Cagr(Γ) ⊈Cagr(Γ ′
x) is the same. Let σ ∈{co, pr, st},
∀Fcollj ∈Γ, if argument a and b are not defeated by other arguments and after
weak concordance, (a, b)(b, a) ∈Dcollj, we have b ∈Saσ(Γ) and a, b ∈Saσ(Γ ′
we).
Thus Saσ(Γ) ⊆Saσ(Γ ′
we). The proof of Caσ(Γ) ⊆Caσ(Γ ′
we) is the same.
Proposition 7. The operation of strong concordance satisﬁes social winner(s)
dominance (P11) and the operation of weak concordance satisﬁes it only if under
complete, preferred and stable semantics.
Proof. As proved in Theorem 1, if social winner is the necessary Condorcet win-
ner, without the operation of concordance, it will be sceptically jointly accepted.
Here we only need to prove that if NW( ˆP) = ∅and ∃a ∈PW( ˆP) then
a ∈Saσ(Γ ′
x). (1) If a is attacked by a possible Condorcet winner b, since a ∼s b
there is no concordance, i.e. Γ = Γ ′
x. b will be sceptically jointly accepted. Thus
b ∈win(≿s) s.t. b ∈Saσ(Γ). (2)∀Fcollj ∈Γ, if a is attacked by an argument
b ∈
i Ai \PW( ˆP), since a ≻s b concordance is needed. The operation of strong
concordance will reverse the attack and then ∀F′
collj ∈Γ ′
st, a ∈Eσ(F′
collj), i.e.
a ∈Saσ(Γ ′
st). Let σ ∈{co, pr, st}, the operation of weak concordance will make
the attack be symmetric so that ∀F′
collj ∈Γ ′
we, a ∈Eσ(F′
collj), i.e. a ∈Saσ(Γ ′
we).
Since when σ = gr, ∀F′
collj ∈Γ ′
we, a /∈Egr(Fcollj), i.e. a /∈Sagr(Γ ′
we). Therefore
under grounded semantics, the conclusion is not held.
Table 2. The evaluation on two concordances
Concordance P1-P5 P9 P10
P11
Const
✓
✓
×
✓
Conwe
✓
✓
✓σ∈{pr,st,co} ✓σ∈{pr,st,co}
For clariﬁcation, we list all above results in Table 2. From the table, we can
see that both strong and weak concordances satisfy P1-P5 since the operation
of framework merging is same for them and it satisﬁes all of ﬁve postulates.

Integrating Individual Preferences into Collective Argumentation
299
Further, weak concordance satisﬁes all of three postulates under complete, pre-
ferred and stable semantics, including grounded semantics in P9. Although
strong concordance doesn’t satisfy P10, it satisﬁes both P9 and P11 under all
standard semantics. Note that the collective outcome obtained after the oper-
ation of concordance, not only preserves majority based consensus among indi-
vidual frameworks, but also modiﬁes collective frameworks to ensure at least
one of social winners will be accepted by the group. Therefore, it is more reason-
able than the results obtained from framework merging or incomplete preference
aggregation, since it reﬂects the interplayed consensus on reasoning result and
social credence.
6
Conclusion
Individual preferences give rise to argument strength in collective argumentation
and may have inﬂuences on collective outcome correspondingly. In order to tackle
individual preferences as well as distinct individual frameworks in a multi-agent
scenario, in this paper we ﬁrst propose a method for the operation of framework
merging and then deﬁne a method to obtain social preference through the oper-
ation of incomplete preference aggregation. However, two diﬀerent operations
may not agree with each other on the joint acceptability of arguments. Aiming
to ﬁnd a solution to reach more agreements between the results from framework
merging and incomplete preference aggregation, we deﬁne an operation called
concordance, which is actually the modiﬁcation of collective frameworks accord-
ing to social preference. As a result, the collective outcome obtained from argu-
mentative reasoning with modiﬁed collective frameworks is renewed to reﬂect
the dominance of social preference. We propose a couple of rational postulates
and verify that the methods we propose are equipped with reasonability.
6.1
Related Work
Preference has been studied in single-framework argumentation [9–11,17]. [10,17]
proposes two roles for preference and the following paper [11] agrees with them but
proposes four methods for reduction. We adopt two reductions proposed in [10]
and [11] for the reason that they can preserve conﬂicting relation between pairs
of arguments and strengthen the argument strength of social winners. Although
these previous work hasn’t studied preference in the background of collective argu-
mentation, they genuinely construct basis for the research in this paper.
In the perspective of framework merging, Coste-Marquis’ approach [2] is close
to us. Since distance-based framework merging always gives rise to majority-based
results, we deﬁne two subsets of attack for collective framework based on the
majority and adopt Coste-Marquis’ proposal in argumentative reasoning. How-
ever, our approach is more concise on the deﬁnition and more explainable on
the results. Another qualitative approach for framework merging is Delobelle’s
work [3]. He propose an approach for framework merging based on belief revision
[18] and represent the expected extensions as formula consisting of arguments.
His approach is deviated from ours and each individual framework in his settings

300
C. Li and B. Liao
shares the same set of arguments. Apart from these, Delobelle [6], Gabbay [5] and
Cayrol [4] adopt a quantitative way for framework merging, treating the appear-
ances of an argument or an attack in individual frameworks as weights. Delobelle
selects collective extensions based on weights. In Gabbay’s approach, weights can
be propogated in the collective framework and the acceptability of arguments
is determined by a threshold. Cayrol’s approach only deﬁnes a quasi-semantics
named vs-defend to justify a successful defense between pairs of arguments.
Based on Bench-Capon’s innovative VAF [12–14,19] study value preference
in the ﬁeld of multi-agent systems. Airiau [12] discusses the criteria for ratio-
nalisation of the proﬁle of individual frameworks. The rationalisation actually
comes from transitivity and acyclicity of strict total ordering. Lisowski [13] con-
cerns about the correspondence between the reasoning results obtained from
value preference aggregation and framework merging. They ﬁgure out a method
to construct the correspondence. Liao [14] studies value preference’s inﬂuences
on the reasoning results based on diﬀerent aggregation rules and ordering-lifting
principles. However, preference aggregation in both [13] and [14] is dealing with
complete preference according to their settings and the approach for framework
merging adopted in [13] is a quota rule which is unable to tackle framework
merging of distinct individual frameworks.
6.2
Future Work
First, as studied in [14], diﬀerent aggregation rules may give rise to diﬀerent
results with certain properties. We’d like to adopt other incomplete preference
aggregation procedures, such as Borda procedure proposed in [7] and minmax
regret approximation [20], and evaluate the reasonability of them respectively.
Second, as proposed by Baumeister in [21], there is a class of argumentation
framework with uncertainty called incomplete argumentation framework. In
future, we can extend our research to integrate incomplete individual prefer-
ences into the proﬁle of incomplete individual frameworks. Third, since individ-
ual preference can be quantitatively represented as personal degree of belief, in
other words, we can treat it as a probability. Then we can connect this area with
probabilistic argumentation framework.
Acknowledgments. The research reported in this paper was supported in part by
the “2030 Megaproject”—New Generation Artiﬁcial Intelligence of China under Grant
2018AAA0100904, the Natural Science Foundation of Zhejiang Province under Grant
No. LY20F030014, and the National Social Science Foundation Major Project of China
under grant No. 20 & ZD047.
References
1. Bodanza, G., Tohm´e, F., Auday, M.: Collective argumentation: a survey of aggrega-
tion issues around argumentation frameworks. Argument Comput. 8, 1–34 (2017)
2. Coste-Marquis, S., Devred, C., Konieczny, S., Lagasquie-Schiex, M.-C., Marquis,
P.: On the merging of Dung’s argumentation systems. Artif. Intell. 171, 730–753
(2007)

Integrating Individual Preferences into Collective Argumentation
301
3. Delobelle, J., Haret, A., Konieczny, S., Mailly, J.G., Rossit, J., Woltran, S.: Merging
of abstract argumentation frameworks. In: KR, pp. 33–42 (2016)
4. Cayrol, C., Lagasquie-Schiex, M.-C.: Weighted argumentation systems: a tool for
merging argumentation systems. In: 2011 IEEE 23rd International Conference on
Tools with Artiﬁcial Intelligence, pp. 629–632 (2011)
5. Gabbay, D., Rodrigues, O.: A numerical approach to the merging of argumentation
networks. In: Fisher, M., van der Torre, L., Dastani, M., Governatori, G. (eds.)
CLIMA 2012. LNCS (LNAI), vol. 7486, pp. 195–212. Springer, Heidelberg (2012).
https://doi.org/10.1007/978-3-642-32897-8 14
6. Delobelle, J., Konieczny, S., Vesic, S.: On the aggregation of argumentation frame-
works: operators and postulates. J. Log. Comput. 28, 1671–1699 (2018)
7. Konczak, K., Lang, J.: Voting procedures with incomplete preferences. In: Pro-
ceedings of the IJCAI 2005 Multidisciplinary Workshop on Advances in Preference
Handling, vol. 20 (2005)
8. Dung, P.M.: On the acceptability of arguments and its fundamental role in non-
monotonic reasoning, logic programming and n-person games. Artif. Intell. 77,
321–357 (1995)
9. Amgoud, L., Cayrol, C.: Inferring from inconsistency in preference-based argumen-
tation frameworks. J. Autom. Reason. 29, 125–169 (2002)
10. Amgoud, L., Vesic, S.: Rich preference-based argumentation frameworks. Int. J.
Approximate Reasoning 55, 585–606 (2014)
11. Kaci, S., van der Torre, L., Villata, S.: Preference in abstract argumentation. In:
7th International Conference on Computational Models of Argument (COMMA),
vol. 305, pp. 405–412 (2018)
12. Airiau, S., Bonzon, E., Endriss, U., Maudet, N., Rossit, J.: Rationalisation of pro-
ﬁles of abstract argumentation frameworks: characterisation and complexity. J.
Artif. Intell. Res. 60, 149–177 (2017)
13. Lisowski, G., Doutre, S., Grandi, U.: Aggregation in value-based argumentation
frameworks. arXiv preprint arXiv:1907.09113 (2019)
14. Liao, B., Li, C.: A solution to ethical dilemmas based on preference aggregation
and formal argumentation. J. Hunan Univ. Sci. Technol. (Soc. Sci. Ed.) 23(3),
33–49 (2020)
15. Chen, W., Endriss, U.: Preservation of semantic properties in collective argumen-
tation: the case of aggregating abstract argumentation frameworks. Artif. Intell.
269, 27–48 (2019)
16. Dunne, P.E., Marquis, P., Wooldridge, M.: Argument aggregation: basic axioms
and complexity results. In: Computational Models of Argument, vol. 129–140. IOS
Press (2012)
17. Amgoud, L., Vesic, S.: Two roles of preferences in argumentation frameworks. In:
Liu, W. (ed.) ECSQARU 2011. LNCS (LNAI), vol. 6717, pp. 86–97. Springer,
Heidelberg (2011). https://doi.org/10.1007/978-3-642-22152-1 8
18. Coste-Marquis, S., Konieczny, S., Mailly, J.G., Marquis P.: On the revision of
argumentation systems: minimal change of arguments statuses. In: KR, pp. 52–61
(2014)
19. Bench-Capon, T.J.: Persuasion in practical argument using value-based argumen-
tation frameworks. J. Log. Comput. 13, 429–448 (2003)
20. Lu, T., Boutilier, C.: Robust approximation and incremental elicitation in voting
protocols. In: IJCAI, pp. 287–293 (2011)
21. Baumeister, D., Neugebauer, D., Rothe, J., Schadrack, H.: Veriﬁcation in incom-
plete argumentation frameworks. Artif. Intell. 264, 1–26 (2018)

A Logic for Binary Classiﬁers and Their
Explanation
Xinghan Liu1(B) and Emiliano Lorini2
1 ANITI, Toulouse University, Toulouse, France
xinghan.liu@univ-toulouse.fr
2 IRIT-CNRS, Toulouse University, Toulouse, France
Emiliano.Lorini@irit.fr
Abstract. Recent years have witnessed a renewed interest in Boolean
functions in explaining binary classiﬁers in the ﬁeld of explainable AI
(XAI). The standard approach to Boolean functions is based on propo-
sitional logic. We present a modal language of a ceteris paribus nature
which supports reasoning about binary classiﬁers and their properties.
We study a family of classiﬁer models, axiomatize it and show complete-
ness of our axiomatics. Moreover, we prove that satisﬁability checking for
our modal language relative to such a class of models is NP-complete. We
leverage the language to formalize counterfactual conditional as well as
a variety of notions of explanation including abductive, contrastive and
counterfactual explanations, and biases. Finally, we present two exten-
sions of our language: a dynamic extension by the notion of assignment
enabling classiﬁer change and an epistemic extension in which the clas-
siﬁer’s uncertainty about the actual input can be represented.
Keywords: Boolean classiﬁer · Explainable AI · Modal logic · Ceteris
paribus logic · Epistemic logic
1
Introduction
The notions of explanation and explainability have been extensively investigated
by philosophers [13,19] and are key aspects of AI-based systems given the impor-
tance of explaining the behavior and prediction of an artiﬁcial intelligent system.
A variety of notions of explanations have been discussed in the area of explain-
able AI (XAI) including abductive, contrastive and counterfactual explanation
[1,8,18,21–23]. Recently, there has been a renewed interest for the notion of
explanation in the context of classiﬁer systems, i.e., explaining why a classi-
ﬁer has classiﬁed a given input instance in a certain way [7,17,18,25]. Classiﬁer
systems can be seen as “black boxes” computing a given (Boolean) function in
the context of a classiﬁcation or prediction task. Artiﬁcial feedforward neural
networks are special kinds of classiﬁer systems aimed at learning or, at least
approximating, the function mapping instances of the input data to their corre-
sponding outputs. Explaining why the system has classiﬁed a given instance in
c
⃝Springer Nature Switzerland AG 2021
P. Baroni et al. (Eds.): CLAR 2021, LNAI 13040, pp. 302–321, 2021.
https://doi.org/10.1007/978-3-030-89391-0_17

A Logic for Binary Classiﬁers and Their Explanation
303
a certain way and identifying the set of features that is necessary (minimally)
suﬃcient for the classiﬁcation is crucial for making the system intelligible and
for ﬁnding biases in the classiﬁcation process.
In this paper we introduce a modal language for representing classiﬁers with
binary input data.1 It extends propositional logic by a ﬁnite set of atomic for-
mulas of type t(x), t(y), . . . , which we call decision atoms. Moreover, it includes
ceteris paribus (CP) modal operators of the form [X] to represent that a formula
is necessarily true regardless of the truth or the falsity of the atomic propositions
outside the set of atomic propositions X.
A question may come immediately: why bother us by a modal language? A
classiﬁer is nothing but a function. A Boolean classiﬁer is thus a function whose
inputs are valuations of atomic propositions and outputs are True or False,
which can in turn be expressed as some propositional formula, particularly in
disjunctive normal form (DNF). This is already known since the seminal work
of Boole on propositional logic. Our answer is that extending to modal logic is
both a natural and a fruitful move.
To see why a modal logic viewpoint is natural, ﬁrst notice that a clas-
siﬁer can be viewed as a partition of all possible inputs. Figure 1 illustrates
a classiﬁer, which can be expressed as {({p, q}, yellow)} ∪{({¬p, q}, red)} ∪
{({p, ¬q}, blue)}∪{({¬p, ¬q}, blue)}, or equivalently (p∧q ∧t(yellow))∨(¬p∧
q ∧t(red)) ∨(p ∧¬q ∧t(blue)) ∨(¬p ∧¬q ∧t(blue)) in propositional logic. But
clearly, it can also be seen as an S5 Kripke model, where each world represents
a possible valuation of atoms.
Moreover, as Quine [24] found, a Boolean classiﬁer can be uniquely character-
ized by a DNF consisting of its prime implicants which will be introduced later.
Intuitively, it means that if a data point is classiﬁed as True by a classiﬁer f, then
we can perturb it by changing values of some of its variables, and it keeps being
True, as long as some of its prime implicants stays invariant. Obviously, this
understanding contains a ceteris paribus reading of modality. For example, in
our language we will be allowed to write the formula (¬p ∧¬q) →[{q}]t(blue).
It says that any input which evaluates atom q in the same way as the input
{¬p, ¬q} is necessarily classiﬁed as blue. In other words, when atom q is false
the input is classiﬁed as blue regardless of the other atoms’ truth values, which
indicates that ¬q is an implicant of t(blue).2
As for fruitfulness, extending the logical framework to modal logic and more
generally to non-classical logics, opens up new vistas including (i) deﬁning coun-
terfactual conditional and studying its relationship with the notions of abductive
and contrastive explanation, (ii) modeling classiﬁer dynamics through the use of
formal semantics for logics of communication and change [27,30], and (iii) rep-
1 So the classiﬁer we model here is slightly more expressive than Boolean classiﬁer.
Introducing decision atoms t(x), t(y), . . . below allows us to encode more than two
decision values (classiﬁcations). Sometime we also use binary/Boolean classiﬁer in
this more general sense. Notice that we cannot use the term psuedo-Boolean, since
in Boolean function it means Val = R [5], but we need our Val staying ﬁnite.
2 In fact it appears to be a prime implicant, when we formally introduce this notion.

304
X. Liu and E. Lorini
p q
p ¬q
¬p ¬q
¬p q
Fig. 1. A classiﬁer as a function is a partition on an S5 model
resenting the classiﬁer’s uncertainty about the actual instance to be classiﬁed
through the use of epistemic logic [10].
To sum up, the paper oﬀers a uniﬁed logical framework for modeling and
comparing diﬀerent notions of explanation and bias in classiﬁer systems. It is
structured as follows. In Sect. 2 we introduce the ceteris paribus language and
the notion of classiﬁer model which is used to interpret it. Moreover, we investi-
gate some extra properties of classiﬁer models to capture interesting subclasses
of classiﬁer models for the sake of classiﬁer explanation. In Sect. 3 a counter-
factual conditional operator will be deﬁned and its relevance for understanding
the behavior of a classiﬁer will be highlighted. Section 4 is devoted to classiﬁer
explanation, where notions of abductive explanation (AXp), contrastive expla-
nation (CXp) and bias in terms of classiﬁer will be represented in the classiﬁer
model.3 Besides, the connection between CXp and counterfactual are elucidated.
Finally, in Sect. 5 we present two extensions of our language: (i) a dynamic exten-
sion by the notion of assignment enabling classiﬁer change and (ii) an epistemic
extension in which the classiﬁer’s uncertainty about the actual input can be
represented.
2
A Language for Binary Classiﬁers
In this section we introduce a language for modeling binary classiﬁers and present
its semantics. The language has a ceteris paribus nature. It contains ceteris
paribus operators of the form [X] that allow us to express the fact that the
classiﬁer’s actual decision (or classiﬁcation) does not depend on the features
of the input in the complementary set Atm \ X, with Atm the set of atomic
propositions and X a subset of it. Such operators were introduced for the ﬁrst
time in [12].
2.1
Basic Language and Classiﬁer Model
Let Atm be a ﬁnite set of atomic propositions with elements noted p, q, . . . We
deﬁne AtmSet = 2Atm.
3 The notations AXp and CXp are credited to [17,18].

A Logic for Binary Classiﬁers and Their Explanation
305
Let us assume the set Atm includes special atomic formulas of type t(x),
where x ∈Val and Val is a ﬁnite set of decision values with elements noted
x, y, . . . We call them decision atoms and note Dec = {t(x) : x ∈Val} the
corresponding set. The decision atom t(x) has to be read “the actual decision
takes value x”.
The modal language L(Atm) is deﬁned by the following grammar:
ϕ ::= p | ¬ϕ | ϕ1 ∧ϕ2 | [X]ϕ,
where p ranges over Atm and X ranges over AtmSet. The set of atomic propo-
sitions occurring in a formula ϕ is noted Atm(ϕ). It should be clear that x and
X refer to diﬀerent things in our setting.
The formula [X]ϕ has a ceteris paribus (CP) reading: “ϕ is necessary all
features in X being equal” or “ϕ is necessary regardless of the truth or falsity of
the atoms in Atm \ X”. Operator ⟨X⟩is the dual of [X] and is deﬁned as usual:
⟨X⟩ϕ =def ¬[X]¬ϕ.
The language L(Atm) is interpreted relative to classiﬁer models whose class
is deﬁned as follows.
Deﬁnition 1 (Classiﬁer model).
A classiﬁer model (CM) is a tuple C =
(S, f) where:
– S = 2Atm\Dec is the set of states, and
– f : S −→Val is a decision (or classiﬁcation) function.
The class of classiﬁer models is noted CM.
A pointed classiﬁer model is a pair (C, s) with C = (S, f) a classiﬁer model and
s ∈S.
Formulas in L(Atm) are interpreted relative to a pointed classiﬁer model, as
follows.
Deﬁnition 2 (Satisfaction relation). Let (C, s) be a pointed classiﬁer model
with C = (S, f) and s ∈S. Then:
(C, s) |= p ⇐⇒p ∈s for p ∈(Atm \ Dec),
(C, s) |= t(x) ⇐⇒f(s) = x for t(x) ∈Dec,
(C, s) |= ¬ϕ ⇐⇒(C, s) ̸|= ϕ,
(C, s) |= ϕ ∧ψ ⇐⇒(C, s) |= ϕ and (C, s) |= ψ,
(C, s) |= [X]ϕ ⇐⇒∀s′ ∈S : if (s ∩X) = (s′ ∩X)
then (C, s′) |= ϕ.
Note in particular the ceteris paribus interpretation of the modal operator
[X]. The formula [X]ϕ is true at a state s if ϕ is true at all states that are modulo-
X equivalent to state s. The condition (s ∩X) = (s′ ∩X) indeed stipulates that
s and s′ are indistinguishable with regard to the atoms (the features) in X.
We abbreviate (C, s) |= ϕ as s |= ϕ when the context is clear.

306
X. Liu and E. Lorini
Notions of satisﬁability and validity for formulas in L(Atm) relative to the
class CM as well as classiﬁer model validity are deﬁned in the usual way. Specif-
ically, a formula ϕ of L(Atm) is said to be satisﬁable relative to the class CM if
there exists a pointed classiﬁer model (C, s) with C ∈CM such that (C, s) |= ϕ.
It is said to be valid relative to CM, noted |=CM ϕ, if ¬ϕ is not satisﬁable
relative to CM. Moreover, we say that that ϕ is valid in the classiﬁer model
C = (S, f), noted C |= ϕ, if (C, s) |= ϕ for every s ∈S.
Let us close this part by forecasting how we will use classiﬁer models to
represent explanations and bias in Sect. 4 with the following example.
Example 1 (Applicant Alice).
Given the language L(Atm) with Atm
=
{p1, p2, q1, q2, t(x), t(y)}. Let us have a CM C = (S, f) s.t. C |= t(x) ↔
((q1 ∧q2)∨(p1 ∧q1)). Consider a pointed CM (C, s) where s = {p2, q1}, f(s) = y.
We interpret p1, p2, q1, q2 in the example above as gender (male p1 or female ¬p1),
postcode (inner city p2 or suburb ¬p2), employment situation (employed q1 or
unemployed ¬q1) and property ownership (possess q2 or rent ¬q2), respectively;
f as a classiﬁer of loan; x, y as acceptance and rejection by the bank, respectively;
s as the state of an applicant, say, Alice. So this models a scenario that Alice is
applying for a loan from her bank. She is female, employed, rents an apartment
in the inner city. The bank decides to reject Alice’s application.
Now Alice is asking for explanations of the decision/classiﬁcation, e.g., 1)
which of her features (necessarily) lead to the current decision, 2) changing
which features would make a diﬀerence, 3) perhaps most importantly, whether
the decision for her is biased. In Sect. 4 we will show how to use the language
L(Atm) and its semantics to answer these questions.
2.2
Properties of Classiﬁer Models
Though the correspondence between classiﬁer models and classiﬁers is salient,
things are subtler than they seem. In this section, we are going to study interest-
ing subclasses of classiﬁer models satisfying extra properties which are relevant
in some domains of application.
Deﬁnition 3 (Properties). Let X ⊆

Atm \Dec

be ﬁnite and let C = (S, f)
be a classiﬁer model. Then, C is said to be
– X-deﬁnite (i.e., def (X)) if, ∀s, s′ ∈S, if (s∩X) = (s′∩X) then f(s) = f(s′),
– X-essential (i.e. ess(X)), if ∀p ∈X, C is not Atm \(Dec ∪{p})-deﬁnite, and
∀p /∈X, C is Atm \ (Dec ∪{p})-deﬁnite;
– X-non trivial (i.e., ntr(X)) if ∃s, s′ ∈S such that (s ∩X) ̸= (s′ ∩X) and
f(s) ̸= f(s′).
Let P ⊆Prop with
Prop ={def (X), ess(X), ntr(X) : X ⊆

Atm \ Dec

}.
We denote by CMP the class of classiﬁer models satisfying each property in P.
The following proposition captures the interesting aspects of certain X-
property and connections between diﬀerent properties.

A Logic for Binary Classiﬁers and Their Explanation
307
Proposition 1. Let X, X′ ⊆

Atm \ Dec

and let C = (S, f) be any classiﬁer
model. Then,
1. C ∈CM{def (Atm\Dec)},
2. if C ∈CM{def (X)} and X ⊆X′ then C ∈CM{def (X′)},
3. ∃!Y ⊆(Atm \ Dec) such that C ∈CM{ess(Y )},
4. if C ∈CM{ess(Y ),def (X)} for some Y ⊆(Atm \ Dec), then Y ⊆X,
5. if C ∈CM{ntr(X)}, then C ∈CM{ntr(Y )} for all Y ⊆(Atm \ Dec),
6. if C ∈CM{ntr(Y ),def (X)} for some Y ⊆(Atm \ Dec), and X ∩X′ = ∅, then
C /∈CM{def (X′)}
The proposition states that a classiﬁer model always has deﬁnite set(s) and
a unique essential set, which is also the minimal deﬁnite set. Non-triviality is
an “all or all not” property, i.e., knowing whether C is X-non trivial or not
for some X is enough to know whether C is Y -non trivial or Y -trivial for any
Y ⊆(Atm \ Dec). The last item highlights that there are cases in which the
class of classiﬁer models crushes, i.e., for some set of semantic properties P, the
model class CMP is empty.
The fact that not all variables in a function are essential plays an impor-
tant role in explaining classiﬁers. Actually, when an intelligent agent, human or
artiﬁcial, makes a classiﬁcation, she only takes a (ﬁnite) subset of all possible
features into account. Take human eyes for instance. It is quite common that
we perceive a lot, but not all of them are recognized with awareness. Dretske
hence distinguished between sensual perception, and meaningful perception or
perceptual recognition (for more discussion see [9,14]). Figure 2 illustrates this
idea.
p2
p4
p5
p1
p0
p3
p0
p1
p2
p3
p4
p5
Fig. 2. Two pointed models of the Eye Model
Example 2 (Eye Model). Figure 2 gives two pointed classiﬁer models, call them
(C⋖, sl) and (C⋖, sr), where C⋖= (S, f). We have sl = {p1, p2, p3, p4, p5},
f(sl) = {triangle}, and sr = {p0, p1, p2, p3, p4, p5}, f(sr) = {quadrilateral}.
Moreover, we have:

308
X. Liu and E. Lorini
C⋖|= t(triangle) ↔

X⊆Atm\(Dec∪{p1,p2}):|X|=3
 
p∈X
p ∧

p∈Atm\(Dec∪{p1,p2}∪X)
¬p

,
C⋖|= t(quadrilateral) ↔(p0 ∧p3 ∧p4 ∧p5), and C⋖∈CM{ess({p0,p3,p4,p5})}.
Thus, the eye classiﬁes an input as “triangle” if exactly three of {p0.p3, p4, p5}
are true in the input, and as “quadrilateral” when all four of them are true in
the input. The inessential variables p1 and p2 are put in the grey zone, which
indicates that they are out of the perceptual recognition/awareness.
One last thing to introduce, before eventually representing classiﬁer expla-
nation in our model, is a conditional operator.
3
Counterfactual Conditional
In this section we investigate a simple notion of counterfactual conditional for
binary classiﬁers, inspired from Lewis’ notion [20]. In Sect. 4, we will elucidate
its connection with the notion of explanation.
We start our analysis by deﬁning the following notion of similarity between
worlds in a model relative to a ﬁnite set of features X.
Deﬁnition 4. Let C = (S, f) be a classiﬁer model, s, s′ ∈S and X ⊆

Atm \
Dec

. The similarity between s and s′ in S relative to the set of features X,
noted simC(s,s′,X), is deﬁned as follows:
simC(s,s′,X) = |{p ∈X : (C, s) |= p iﬀ(C, s′) |= p}|.
A dual notion of distance between worlds can deﬁned from the previous
notion of similarity:
distC(s,s′,X) = |X| −simC(s,s′,X).
This notion of distance is in accordance of [6] in knowledge revision.4 The fol-
lowing deﬁnition introduces the concept of conditional. Following Lewis’ view,
we evaluate a conditional at a state of a classiﬁer model and stipulate that the
conditional holds if all closest worlds to the actual world in which the antecedent
is true satisfy the consequent of the conditional.
Deﬁnition 5. Let C = (S, f) be a classiﬁer model, s ∈S and X ⊆

Atm \Dec

.
We say that “if ϕ was true then ψ would be true, relative to the set of features
X” at s, noted (C, s) |= ϕ ⇒X ψ, if and only closestC(s,ϕ,X) ⊆||ψ||C where
closestC(s,ϕ,X) = arg max
s′∈||ϕ||C
simC(s,s′,X),
and for every ϕ ∈L(Atm):
||ϕ||C = {s ∈S : (C, s) |= ϕ}.
4 There are other options besides measuring distance by cardinality, e.g., distance in
sense of subset relation as [2]. We will consider them in further research.

A Logic for Binary Classiﬁers and Their Explanation
309
As the following proposition highlights the previous notion of counterfactual
conditional is expressible in the language L(Atm).
Proposition 2. Let C = (S, f) be a classiﬁer model, s ∈S and X ⊆

Atm \
Dec

. Then,
(C, s) |=ϕ ⇒X ψ if and only if
(C, s) |=

0≤k≤|X|

maxSim(ϕ,X,k) →

Y ⊆X:|Y |=k
[Y ](ϕ →ψ)

,
with
maxSim(ϕ,X,k) =def

Y ⊆X:|Y |=k
⟨Y ⟩ϕ ∧

Y ⊆X:k<|Y |
[Y ]¬ϕ.
In light of the previous proposition, we can see ϕ ⇒X ψ as an abbreviation of
its corresponding L(Atm)-formula.5 For notational convenience, we simply write
ϕ ⇒ψ instead of ϕ ⇒(Atm\Dec) ψ. Formula ϕ ⇒ψ captures the standard notion
of conditional of conditional logic. One can show that ⇒satisﬁes all semantic
conditions of Lewis’ logic VC.6
The interesting aspect of the previous notion of counterfactual conditional is
that it can be used to represent a binary classiﬁer’s approximate decision for a
given instance. Let us suppose the set of decision values Val includes a special
symbol ? meaning that the classiﬁer has no suﬃcient information enabling it to
classify an instance in a precise way. More compactly, ? means that the classiﬁer
abstains from making a precise decision. In this situation, the classiﬁer can try
to make an approximate decision: it considers the closest instances to the actual
instance for which it has suﬃcient information to make a decision and checks
whether the decision is uniform among all such instances. In other words, x is
the classiﬁer’s approximate classiﬁcation of (or decision for) the actual instance,
noted apprDec(x) if and only if “if a precise decision was made for the input then
this decision would be x”. Formally:
apprDec(x) =def


y∈Val:y̸=?
t(y)

⇒t(x).
The following proposition provides two interesting validities.
5 A similar approach of ceteris paribus is [11]. They also reﬁne Lewis’ semantics for
counterfactual by selecting the closest worlds according to not only the actual world
and antecedent, but also a set of formulas where they note as Γ. The main technical
diﬀerence is that they allow any counterfactual-free formula as a member of Γ, while
in our setting X only contains atomic formulas.
6 A remarkable fact is that not all ⇒X satisfy the strong centering condition, which
says that the actual world is the only closest world when the antecedent is already
true here. To see it, consider a toy classiﬁer model (C, s) such that S = {s, s′, s′′, s′′′}
with s = {p, q}, s′ = {p}, s′′ = {q}, s′′′ = ∅. We have closestC(s,p,∅) = {s, s′}, rather
than closestC(s,p,∅) = {s}. All the rest of conditions in VC are satisﬁed regardless
of what X is.

310
X. Liu and E. Lorini
Proposition 3. Let x, y ∈Val \ {?}. Then,
|=CM apprDec(x) →¬apprDec(y) if x ̸= y,
|=CM t(x) →apprDec(x).
According to the ﬁrst validity, a classiﬁer cannot make two diﬀerent approximate
decisions. According to the second validity, if the classiﬁer is able to make a
precise decision for a given instance, then its approximate decision coincides
with it.
It is worth noting that the following formula is not valid relative to the class
CM

x∈Val\{?}
apprDec(x).
This means that a classiﬁer may be unable to approximately classify the actual
instance.
4
Explanations and Biases
We will formalize some existing notions of explanation of classiﬁer in our model,
and deepen the current study. For this purpose it is necessary to introduce
the following notations. Given a classiﬁer model C = (S, f), for any s ∈S,
call s =def

p∈s p ∧
p/∈s ¬p an instance. Instances are special terms, a.k.a.
properties, where a term λ =def

p∈X p∧
p∈Y ¬p for some X, Y ⊆(Atm \Dec)
such that X ∩Y = ∅; and by λ we mean 
p∈X ¬p ∧
p∈Y p. By convention ⊤is
a term of zero conjuncts. We say λ ⊆λ′ when the set of literals included in λ is
a subset of the set of literals included in λ′, and λ ⊂λ′ when λ ⊆λ′ but λ′ ̸⊆λ.
In this case we may say λ′ is a part of λ. Additionally, to deﬁne bias we may
distinguish the set of protected features PF, like gender and race, and the set of
non-protected features NF, such that PF ∪NF = (Atm \ Dec) and PF ∩NF = ∅.
4.1
Prime Implicant Expressed in CM
Now we are in position to formalize prime implicant, which plays a fundamental
role in Boolean functions and in classiﬁer explanations.
Deﬁnition 6 (Prime Implicant (PImp)). Let C = (S, f) ∈CM. We call
property λ an implicant of x w.r.t. f at s, if ∀s′ ∈S, if (C, s′) |= λ then
f(s′) = x.
Moreover, we call property λ a prime implicant of x w.r.t. f at s, noted
(C, s) |= PImp(λ, x), if λ is an implicant of x w.r.t. f at s, and there is no λ′,
s.t. λ′ ⊆λ, and λ′ is an implicant of x w.r.t. f at s.

A Logic for Binary Classiﬁers and Their Explanation
311
Notice that being a prime implicant is a global property of the classiﬁer,
though we formalize it by means of a pointed model. Obviously Deﬁnition 6
generalizes the deﬁnition of prime implicant of the pure Boolean function. If we
take Val = {True, False} and interpret x as True, we will recover the deﬁnition
in e.g., [5].
As the following proposition highlights, the notion of prime implicant is
expressible in the language L(Atm). Thus, like counterfactual conditional, we will
conceive PImp(λ, x) as an abbreviation of its corresponding L(Atm)-formula. We
will do the same for the notions of abductive explanation, contrastive explana-
tion and bias which will also be seen as abbreviations of corresponding L(Atm)-
formulas.
Proposition 4. Let C = (S, f) ∈CM and s ∈S. We have (C, s) |= PImp(λ, x)
iﬀ
(C, s) |= [∅]

λ →(t(x) ∧

p∈Atm(λ)
⟨Atm(λ) \ {p}⟩¬t(x))

The following proposition shows the relation between prime implicants of a
classiﬁer and the essential set of its model.
Proposition 5. Let C = (S, f) ∈CM. C is X-essential, if ∀p ∈(Atm \ Dec),
p ∈X iﬀfor some x ∈Val there is a prime implicant λ of x w.r.t. f and
p ∈Atm(λ).
4.2
Abductive Explanation (AXp)
Theoretically, knowing all prime implicants helps make the classiﬁer transpar-
ent and understandable to humans. However, prime implicants are hard to list.
Therefore, many researchers focus on prime implicants of a given input [7,17].
In such a way the explanation stays “local”.
Deﬁnition 7 (Abductive Explanation (AXp)). Let C = (S, f) ∈CM and
s ∈S. We say property λ abductively explains the decision x of f at s, noted
(C, s) |= AXp(λ, x), if (C, s) |= λ ∧PImp(λ, x).
The two conjuncts indicate respectively that 1) λ is a part of instance s, i.e.
λ ⊆s, since λ is true at s; 2) λ is a prime implicant of x. Notice that 1) uses the
fact that (C, s) |= λ iﬀs →λ is a propositional logical tautology.
Many names besides AXp are found in literature, e.g. PI-explanation and
suﬃcient reason [7]. We prefer the name AXp used by Ignatiev et al. [17,18]
because of its connection with CXp in the next subsection. Darwiche and Hirth
in [7] proved that any decision has a suﬃcient reason, in our setting:
Proposition 6. Let C = (S, f) ∈CM, s ∈S and f(s) = x. We have (C, s) |=
AXp(λ, x) for some property λ ⊆s.

312
X. Liu and E. Lorini
We can show it by Proposition 1.3 that C is always X-essential for some X,
which means 
p∈s∩X p∧
p/∈s&p∈X ¬p contain all AXps that we look for. Notice
that when C is trivial, X = ∅and λ is ⊤, which by convention is the conjunction
of zero literal.
Last, let us continue with the Alice example.
Example 3. In Alice’s case, since s is the instance ¬p1 ∧p2 ∧q1 ∧¬q2, (recall
s = {p2, q1} ), we have (C, s) |= AXp(¬p1 ∧¬q2, y), namely that Alice’s being
female and not owning a property abductively explains the rejection.
4.3
Contrastive Explanation (CXp)
AXp is a minimal part of a given instance s verifying the current decision. A
natural counterpart of AXp, contrastive explanation (CXp, named in [17]), is a
minimal part of s which falsiﬁes the current decision.
Deﬁnition 8 (Contrastive Explanation (CXp)). Let C = (S, f) ∈CM,
s ∈S, and f(s) = x. We say that λ contrastively explains the decision x of
f at s, noted (C, s) |= CXp(λ, x), if λ ⊆s; ∃s′ ∈S, s.t. s△s′ = Atm(λ), and
f(s′) ̸= x; and ∀s′′ ∈S, s△s′′ ⊂Atm(λ) implies f(s′′) = x.7
In plain words, λ is a CXp of x at s, if λ is a part of s; changing the valuation
of every atom in λ falsiﬁes the current decision; and no falsiﬁcation happens
when we only consider changing the valuation of a proper part of λ. Like prime
implicant and abductive explanation, the language L(Atm) is expressive enough
to capture contrastive explanation.
Proposition 7. Let C = (S, f) ∈CM and s ∈S. (C, s) |= CXp(λ, x) iﬀ
(C, s) |=λ ∧t(x) ∧⟨Atm \ Atm(λ)⟩¬t(x) ∧

p∈Atm(λ)
[(Atm \ Atm(λ)) ∪{p}]t(x).
We deﬁne CXp by minimizing the change from the current input, while in
deﬁning counterfactual conditional we maximize the similarity. It makes one
question whether these are two paths towards the same end. Actually in XAI,
many researchers consider contrastive explanations and counterfactual explana-
tions either closely related [32], or even interchangeable [26]. Our framework
agrees that CXp has a counterfactual nature in light of the next proposition.
Proposition 8. We have the following validity:
|=CM CXp(λ, x) →(λ ⇒¬t(x)).
Proof. For any C = (S, f) ∈CM and s ∈S, suppose (C, s) |= CXp(λ, x), we
need to show (C, s) |= λ ⇒¬t(x). By the antecedent, ∃s′ ∈S, s.t. s△s′ =
Atm(λ) and f(s′) ̸= x. It is not hard to show that closestC(s,λ,Atm) = {s′}.
Therefore (C, s) |= λ ⇒¬t(x), since closestC(s,λ,Atm) ⊆||¬t(x)||C.
■
7 The symbol △denotes symmetric diﬀerence.

A Logic for Binary Classiﬁers and Their Explanation
313
Notice that |=CM (λ ⇒¬t(x)) →CXp(λ, x) does not hold. Consider the
pointed model in the proof above: for any property λ′ s.t. λ ⊂λ′ ⊆s, we have
(C, s) |= λ
′ ⇒¬t(x), but (C, s) |= ¬CXp(λ′, x). Hence, we view CXp as a special
kind of counterfactual, whose antecedent needs to be minimal.
Example 4. In Alice’s case, (C, s) |= CXp(¬p1, y) ∧CXp(¬q2, y), namely both
Alice’s being female and not owning property contrastively explain the rejection.
Moreover, since gender is hard to change, owing a property is the (relatively)
actionable explanation for Alice8, if she wants to follow the rule of f. But surely
Alice has another option, i.e. alleging the classiﬁer as biased. As we will see in
the next subsection, an application of CXp is to detect decision bias.
4.4
Decision Bias
A primary goal of XAI is to detect and avoid biases. Bias is understood as
making decision w.r.t. some protected features, e.g. race, gender and age.
A widely accepted notion of decision bias, see e.g. [7,16], can be expressed in
our setting as follows. Intuitively, the rejection for Alice is biased, if there is a
Bob, who only diﬀers from Alice on some protected feature, but gets accepted.
Deﬁnition 9 (Decision Bias). Let C = (S, f) ∈CM, s ∈S, and f(s) = x.
We say that the decision x of f at s is biased, noted (C, s) |= Bias(x), if ∃s′ ∈S,
s.t. s△s′ ⊆PF and f(s′) ̸= x.
The notion of bias is also expressible in our language.
Proposition 9. Let C = (S, f) ∈CM and s ∈S. Then, (C, s) |= Bias(x) iﬀ
(C, s) |= t(x) ∧

X⊆PF
⟨Atm \ X⟩¬t(x).
Let us answer the last question regarding Alice raised at the end of Sect. 2.1.
Example 5. Split (Atm\Dec) in Example 1 into PF = {p1, p2} and NF = {q1, q2}.
We then have (C, s) |= Bias(y). The decision for Alice is biased, since gender is
the protected feature responsible for the rejection, a bias as we want to model.
As we stated, CXp can be used to detect decision bias. Actually, we have
(C, s) |= CXp(¬p1, y), i.e. being female contrastively explains Alice’s rejection;
and (C, s) |= p1 ⇒t(x), namely if Alice were male, she would get accepted. The
following result makes the statement precise.
Proposition 10. We have the following validity:
|=CMBias(x) ↔

Atm(λ)⊆PF
CXp(λ, x).
8 For the signiﬁcance of actionablility in XAI, see e.g. [26].

314
X. Liu and E. Lorini
Proof. We show that for any C = (S, f) ∈CM and s ∈S, both directions
are satisﬁed in (C, s). The right to left direction is obvious, since from the
antecedent we know there is a property λ′ s.t. ∃s′ ∈S, s△s′ = Atm(λ′) ⊆PF
and (C, s′) |= ¬t(x), which means (C, s) |= Bias(x). The other direction is proven
by contraposition. Suppose for any λ s.t. Atm(λ) ⊆PF, (C, s) |= ¬CXp(λ, x),
then it means ∀s′ ∈S, if s△s′ = Atm(λ), then f(s′) = x, which means
(C, s) |= ¬Bias(x).
■
5
Axiomatization and Complexity
In this section we provide a sound and complete axiomatics for the language
L(Atm) relative to the formal semantics deﬁned above. The following abbrevia-
tion is given for the sake of compactness, for every ﬁnite X, Y ⊆Atm:
cnY ,X =def

p∈Y
p ∧

p∈X\Y
¬p.
Deﬁnition 10 (Logic BCL). We deﬁne BCL (Binary Classiﬁer Logic) to be the
extension of classical propositional logic given by the following axioms and rules
of inference:

[∅]ϕ ∧[∅](ϕ →ψ)

→[∅]ψ
(K[∅])
[∅]ϕ →ϕ
(T[∅])
[∅]ϕ →[∅][∅]ϕ
(4[∅])
ϕ →[∅]⟨∅⟩ϕ
(B[∅])
[X]ϕ ↔

Y ⊆X

cnY ,X →[∅](cnY ,X →ϕ)

(Red[∅])

x∈Val
t(x)
(AtLeastt(x))
t(x) →¬t(y) if x ̸= y
(AtMostt(x))

Y ⊆

Atm\Dec


cnY ,

Atm\Dec
 ∧t(x)

→[∅]

cnY ,

Atm\Dec
 →t(x)
	
(Def)

X⊆

Atm\Dec
⟨∅⟩cnX,

Atm\Dec

(Comp)
ϕ →ψ ϕ
ψ
(MP)
ϕ
[∅]ϕ
(Nec[∅])
It can be seen that [∅] is an S5 style modal operator, Red[∅] reduces any [X] to
[∅]. AtLeastt(x), AtMostt(x), Def represent the decision function syntactically,

A Logic for Binary Classiﬁers and Their Explanation
315
that every cnY ,Atm\Dec maps to some unique t(x).9 Comp ensures the function
is total.
The following theorem highlights that the logic BCL is sound and complete
relative to its corresponding semantics. The proof is entirely standard and based
on a canonical model argument.
Theorem 1. The logic BCL is sound and complete relative to the class CM.
The following theorem provides a complexity result for checking satisﬁability
of formulas in L(Atm) relative to the class CM. The proof of the complexity
result is based on three steps. First, we have that validity relative to the class
CM is equivalent to validity relative to the class of ceteris paribus models pre-
sented in [12] that “globally” satisfy a ﬁnite set of formulas corresponding to
the axioms in {AtLeastt(x), AtMostt(x), Def, Comp}. The size of such a set
of formulas is constant and does not depend on the size of the formula to be
checked. Therefore, we can polynomially reduce satisﬁability checking relative
to class CM to satisﬁability checking relative to such a model class. In [12] it
is shown that, if the set of atomic propositions is ﬁnite, then the latter problem
is in NP. This gives NP-membership for our logic. NP-hardness follows from
NP-hardness of propositional logic.
Theorem 2. Checking satisﬁability of formulas in L(Atm) relative to CM is
NP-complete.
6
Extensions
In this section, we brieﬂy discuss two interesting extensions of our logical frame-
work and analysis of binary classiﬁers. Their full development is left for future
work.
6.1
Dynamic Extension
The ﬁrst extension we want to discuss consists in adding to the language L(Atm)
dynamic operators of the form [x := ϕ] with x ∈Dec, where x := ϕ is a kind
of assignment in the sense of [27,31] and the formula [x := ϕ]ψ has to be read
“ψ holds after every decision is set to x in context ϕ”. The resulting language,
noted Ldyn(Atm), is deﬁned by the following grammar:
ϕ ::= p | ¬ϕ | ϕ1 ∧ϕ2 | [X]ϕ | [x:=ϕ]ψ
where p ranges over Atm, X ranges over AtmSet and x ranges over Dec. The
interpretation of formula [x := ϕ]ψ relative to a pointed classiﬁer model (C, s)
with C = (S, f) goes as follows:
(C, s) |= [x:=ϕ]ψ ⇐⇒(Cx:=ϕ, s) |= ψ,
9 Notice that cnY ,Atm\Dec is just another expression of s where s = Y .

316
X. Liu and E. Lorini
where Cx:=ϕ = (S, f x:=ϕ) is the updated classiﬁer model where, for every s′ ∈S:
f x:=ϕ(s′) =

x if (C, s′) |= ϕ,
f(s′) otherwise.
Intuitively, the operation x := ϕ consists in globally classifying all instances
satisfying ϕ with value x.
Dynamic operators [x := ϕ] are useful for modeling a classiﬁer’s revision.
Speciﬁcally, new knowledge can be injected into the classiﬁer thereby leading to
a change in its classiﬁcation. For example, the classiﬁer could learn that if an
object is a furniture, has one or more legs and has a ﬂat top, then it is a table.
This is captured by the following assignment:
table:=objIsFurniture ∧objHasLegs ∧objHasFlatTop.
An application of dynamic change is to model the training process of a
classiﬁer, together with counterfactual conditionals with ? in Sect. 3. Suppose
at the beginning we have a CM C = (S, f) which is totally ignorant, i.e.
∀s ∈S, f(s) =?. We then prepare to train the classiﬁer. The training set consists
of pairs (s1, x1), (s2, x2) . . . (sn, xn) where ∀i ∈{1, . . . , n}, si ∈S, xi ∈(Val \{?})
and ∀j ∈{1, . . . , n}, i ̸= j implies si ̸= sj. We train the classiﬁer by revising
it with [x1 = s1] . . . [xn = sn] one by one. Obviously the order does not matter
here. In other words, we re-classify some states. With a bit abuse of notation,
let Ctrain = (S, f train) denote the model resulting from the series of revisions.
We ﬁnish training by inducing the ﬁnal model C† = (S, f †) from Ctrain, where
∀s ∈S, f †(s) = x, if (Ctrain, s) |= apprDec(x), otherwise f †(s) = f train(s).
The logic BCL−DC (BCL with Decision Change) extends the logic BCL by
the dynamic operators [x:=ϕ]. It is deﬁned as follows.
Deﬁnition 11 (Logic BCL−DC). We deﬁne BCL−DC (BCL with Decision
Change) to be the extension of BCL of Deﬁnition 10 generated by the follow-
ing reduction axioms for the dynamic operators [x:=ϕ]:
[x:=ϕ]t(x) ↔

ϕ ∨t(x)

[x:=ϕ]t(y) ↔

¬ϕ ∧t(y)

if x ̸= y
[x:=ϕ]p ↔p if p ̸∈Dec
[x:=ϕ]¬ψ ↔¬[x:=ϕ]ψ
[x:=ϕ](ψ1 ∧ψ2) ↔

[x:=ϕ]ψ1 ∧[x:=ϕ]ψ2

[x:=ϕ][X]ψ ↔[X][x:=ϕ]ψ
and the following rule of inference:
ϕ1 ↔ϕ2
ψ ↔ψ[ϕ1/ϕ2]
(RE)

A Logic for Binary Classiﬁers and Their Explanation
317
It is routine exercise to verify that the equivalences in Deﬁnition 11 are
valid for the class CM and that the rule of replacement of equivalents (RE)
preserves validity. The completeness of BCL−DC for this class of models follows
from Theorem 1, in view of the fact that the reduction axioms and the rule of
replacement of proved equivalents can be used to ﬁnd, for any Ldyn-formula, a
provably equivalent L-formula.
Theorem 3. The logic BCL−DC is sound and complete relative to the class
CM.
The following complexity result is a consequence of Theorem 2 and the fact
that via the reduction axioms in Deﬁnition 11 we can ﬁnd a polynomial reduc-
tion of satisﬁability checking for formulas in Ldyn to satisﬁability checking for
formulas in L.
Theorem 4. Checking satisﬁability of formulas in Ldyn(Atm) relative to CM
is NP-complete.
6.2
Epistemic Extension
In the second extension we consider that, a classiﬁer is conceived as an agent
which has to classify what it perceives. The agent could have uncertainty about
the actual instance to be classiﬁed since it cannot see all its features.
In order to represent the agent’s epistemic state and uncertainty, we slightly
redeﬁne the set of atomic formulas Atm. We note Atm0 the set of basic atoms
and assume that Dec ∩Atm0 = ∅, where Dec is the set of decision atoms deﬁned
in Sect. 2.1. Then, we deﬁne:
Atm = Atm0 ∪Dec ∪{o(p) : p ∈Atm0},
where o(p) is a ‘observability’ (or ‘visibility’) atom in the sense of [4,15,28,29]
which has to be read “the agent can see the truth value of p”. For notational
convenience, we note ObsAtm = {o(p) : p ∈Atm0}.
The language for our epistemic extension is noted Lepi(Atm) and deﬁned by
the following grammar:
ϕ ::= p | ¬ϕ | ϕ1 ∧ϕ2 | [X]ϕ | Kϕ,
where p ranges over Atm and X ranges over AtmSet.
The epistemic operator K is used to represent what agent i knows in the
light of what it sees. In order to interpret this new modality, we have to enrich
classiﬁer models with an epistemic component.
Deﬁnition 12 (Epistemic classiﬁer model). An epistemic classiﬁer model
(ECM) is a tuple C = (S, f, ∼) where C = (S, f) is a classiﬁer model such that,
for all s, s′ ∈S:
if (s ∩Atm0) = (s′ ∩Atm0) then f(s) = f(s′),

318
X. Liu and E. Lorini
and ∼is a binary relation on S such that, for all s, s′ ∈S:
s ∼s′ if and only if (i) Obs(s) = Obs(s′) and
(ii) (s ∩ObsAtm) = (s′ ∩ObsAtm),
where, for every s ∈S, Obs(s) = {p ∈Atm0 : o(p) ∈s} is the set of atomic
propositions that are visible to the agent at s.
The class of ECMs is noted ECM.
According to Deﬁnition 12, the classiﬁcation of a given input instance should
only depend on its features captured by basic atoms. In other words, observ-
ability atoms are irrelevant for classiﬁcation. Furthermore, the agent cannot
distinguish between two states s and s′ if and only if (i) the truth values of the
visible variables are the same at s and s′, and (ii) what the agent can see is
the same at s and s′. The way the epistemic accessibility relation ∼is deﬁned
guarantees that it is an equivalence relation.
Proposition 11. Let C = (S, f, ∼) be a ECM. Then, the relation ∼is reﬂexive,
transitive and symmetric.
The interpretation for formulas in Lepi(Atm) extends the interpretation for
formulas in L(Atm) given in Deﬁnition 2 by the following condition for the
epistemic operator:
(C, s) |= Kϕ ⇐⇒∀s′ ∈S : if s ∼s′ then (C, s′) |= ϕ.
The following are three interesting validities of our epistemic extension:
|=ECM o(p) →

(p →Kp) ∧(¬p →K¬p)

,
(1)
|=ECM o(p) ↔K o(p),
(2)
|=ECM


p∈Atm0
o(p) ∧t(x)

→K t(x).
(3)
According to the ﬁrst validity, the agent knows the truth value of each variable
it can see. According to the second validity, the agent knows what it can see.
Finally, according to the third validity, if the agent can see all features of the
input, then it has no uncertainty about the classiﬁcation of the actual instance.
Indeed, the agent’s uncertainty about the classiﬁcation is only determined by
the imperfect visibility of the input features (if all features are visible, then the
agent has no uncertainty about how the input should be classiﬁed).
As the following theorem indicates, the complexity result of Sect. 5 general-
izes to the epistemic extension. It is based on (i) the fact that for every formula in
Lepi(Atm) we can ﬁnd an equivalent formula in L(Atm) with no epistemic oper-
ators, (ii) the adaptation of the polynomial satisﬁability preserving translation
from L(Atm) to the modal logic S5 given in [12].
Theorem 5. Checking satisﬁability of formulas in Lepi(Atm) relative to ECM
is NP-complete.

A Logic for Binary Classiﬁers and Their Explanation
319
7
Conclusion
We have introduced a modal language and a formal semantics that allow us to
capture the ceteris paribus nature of binary classiﬁers. We have formalized in the
language a variety of notions which are relevant for understanding a classiﬁer’s
behavior including counterfactual conditional, abductive and contrastive expla-
nation, bias. We have provided two extensions that support reasoning about
classiﬁer change and a classiﬁer’s uncertainty about the actual instance to be
classiﬁed. We have also oﬀered axiomatics and complexity results for our logical
setting.
We believe that the complexity results presented in the paper are exploitable
in practice. We have shown that satisﬁability checking in the basic ceteris paribus
setting and in its epistemic extension are NP-complete. Indeed, both problems
are polynomially reducible to satisﬁability checking in the modal logic S5 for
which a polynomial satisﬁability preserving translation into propositional logic
exists [3]. This opens up the possibility of using SAT solvers for automated
veriﬁcation and generation of explanation and bias in binary classiﬁers. We plan
to focus on this topic in future research.
Another direction of future research is the generalization of the epistemic
extension given in Sect. 6.2 to the multi-agent case. The idea is to conceive classi-
ﬁers as agents and to be able to represent both the agents’ uncertainty about the
instance to be classiﬁed and their knowledge and uncertainty about other agents’
knowledge and uncertainty (i.e., higher-order knowledge and uncertainty).
Finally, we plan to investigate more in depth classiﬁer dynamics we brieﬂy
discussed in Sect. 6.1. The idea is to see them as learning dynamics. Based on this
idea, we plan to study the problem of ﬁnding a sequence of update operations
guaranteeing that the classiﬁer will be able to make approximate decisions for a
given set of instances.
Acknowledgements. Support from the ANR-3IA Artiﬁcial and Natural Intelligence
Toulouse Institute is gratefully acknowledged.
References
1. Biran, O., Cotton, C.: Explanation and justiﬁcation in machine learning: a survey.
In: IJCAI 2017 Workshop on Explainable AI (XAI), vol. 8, no. 1, pp. 8–13 (2017)
2. Borgida, A.: Language features for ﬂexible handling of exceptions in information
systems. ACM Trans. Database Syst. (TODS) 10(4), 565–603 (1985)
3. Caridroit, T., Lagniez, J.-M., Le Berre, D., de Lima, T., Montmirail, V.: A SAT-
based approach for solving the modal logic S5-satisﬁability problem. In: Proceed-
ings of the Thirty-First AAAI Conference on Artiﬁcial Intelligence (AAAI 2017),
pp. 3864–3870. AAAI Press (2017)
4. Charrier, T., Herzig, A., Lorini, E., Maﬀre, F., Schwarzentruber, F.: Building epis-
temic logic from observations and public announcements. In: Proceedings of the
Fifteenth International Conference on Principles of Knowledge Representation and
Reasoning (KR 2016), pp. 268–277. AAAI Press (2016)

320
X. Liu and E. Lorini
5. Crama, Y., Hammer, P.L.: Boolean Functions: Theory, Algorithms, and Applica-
tions. Cambridge University Press, Cambridge (2011)
6. Dalal, M.: Investigations into a theory of knowledge base revision: preliminary
report. In: Proceedings of the Seventh National Conference on Artiﬁcial Intelli-
gence, vol. 2, pp. 475–479. Citeseer (1988)
7. Darwiche, A., Hirth, A.: On the reasons behind decisions. In: 24th European Con-
ference on Artiﬁcial Intelligence, ECAI 2020. Frontiers in Artiﬁcial Intelligence and
Applications, vol. 325, pp. 712–720. IOS Press (2020)
8. Dhurandhar, A., et al.: Explanations based on the missing: towards contrastive
explanations with pertinent negatives. In: Advances in Neural Information Pro-
cessing Systems, pp. 592–603 (2018)
9. Dretske, F: Meaningful perception. An Invitation to Cognitive Science: Visual Cog-
nition, pp. 331–352 (1995)
10. Fagin, R., Moses, Y., Halpern, J.Y., Vardi, M.Y.: Reasoning about Knowledge.
MIT Press, Cambridge (1995)
11. Girard, P., Triplett, M.A.: Ceteris paribus logic in counterfactual reasoning. In:
TARK 2015, pp. 176–193 (2016)
12. Grossi, D., Lorini, E., Schwarzentruber, F.: The ceteris paribus structure of logics
of game forms. J. Artif. Intell. Res. 53, 91–126 (2015)
13. Hempel, C.G., Oppenheim, P.: Studies in the logic of explanation. Philos. Sci.
15(2), 135–175 (1948)
14. Herzig, A., Lorini, E.: A modal logic of perceptual belief. In: Lihoreau, F., Rebuschi,
M. (eds.) Epistemology, Context, and Formalism. SL, vol. 369, pp. 197–211.
Springer, Cham (2014). https://doi.org/10.1007/978-3-319-02943-6 12
15. Herzig, A., Lorini, E., Maﬀre, F.: A poor man’s epistemic logic based on propo-
sitional assignment and higher-order observation. In: van der Hoek, W., Holliday,
W.H., Wang, W. (eds.) LORI 2015. LNCS, vol. 9394, pp. 156–168. Springer, Hei-
delberg (2015). https://doi.org/10.1007/978-3-662-48561-3 13
16. Ignatiev, A., Cooper, M.C., Siala, M., Hebrard, E., Marques-Silva, J.: Towards
formal fairness in machine learning. In: Simonis, H. (ed.) CP 2020. LNCS, vol.
12333, pp. 846–867. Springer, Cham (2020). https://doi.org/10.1007/978-3-030-
58475-7 49
17. Ignatiev, A., Narodytska, N., Asher, N., Marques-Silva, J.: From contrastive to
abductive explanations and back again. In: Baldoni, M., Bandini, S. (eds.) AIxIA
2020. LNCS (LNAI), vol. 12414, pp. 335–355. Springer, Cham (2021). https://doi.
org/10.1007/978-3-030-77091-4 21
18. Ignatiev, A., Narodytska, N., Marques-Silva, J.: Abduction-based explanations for
machine learning models. In: Proceedings of the AAAI Conference on Artiﬁcial
Intelligence, vol. 33, pp. 1511–1519 (2019)
19. Kment, B.: Counterfactuals and explanation. Mind 115(458), 261–310 (2006)
20. Lewis, D.: Counterfactuals. Harvard University Press, Cambridge (1973)
21. Martens, D., Provost, F.: Explaining data-driven document classiﬁcations. MIS Q.
38(1), 73–100 (2014)
22. Mittelstadt, B., Russell, C., Wachter, S.: Explaining explanations in AI. In: Pro-
ceedings of the Conference on Fairness, Accountability, and Transparency, pp. 279–
288 (2019)
23. Mothilal, R.K., Sharma, A., Tan, C.: Explaining machine learning classiﬁers
through diverse counterfactual explanations. In: Proceedings of the 2020 Confer-
ence on Fairness, Accountability, and Transparency, pp. 607–617 (2020)
24. Quine, W.V.: A way to simplify truth functions. Am. Math. Mon. 62(9), 627–631
(1955)

A Logic for Binary Classiﬁers and Their Explanation
321
25. Shi, W., Shih, A., Darwiche, A., Choi, A.: On tractable representations of binary
neural networks. arXiv preprint arXiv:2004.02082 (2020)
26. Sokol, K., Flach, P.A.: Counterfactual explanations of machine learning predic-
tions: opportunities and challenges for AI safety. In: SafeAI@ AAAI (2019)
27. Van Benthem, J., Van Eijck, J., Kooi, B.: Logics of communication and change.
Inf. Comput. 204(11), 1620–1662 (2006)
28. van der Hoek, W., Iliev, P., Wooldridge, M.J.: A logic of revelation and conceal-
ment. In: Proceedings of the International Conference on Autonomous Agents and
Multiagent Systems, (AAMAS 2012), pp. 1115–1122. IFAAMAS (2012)
29. Van Der Hoek, W., Troquard, N., Wooldridge, M.J.: Knowledge and control. In:
Proceedings of the 10th International Conference on Autonomous Agents and Mul-
tiagent Systems (AAMAS 2021), pp. 719–726. IFAAMAS (2011)
30. van Ditmarsch, H., van Der Hoek, W., Kooi, B.: Dynamic Epistemic Logic. Syn-
these Library, vol. 337. Springer, Heidelberg (2007)
31. van Ditmarsch, H.P., van der Hoek, W., Kooi, B.P.: Dynamic epistemic logic
with assignment. In: Proceedings of the 4th International Joint Conference on
Autonomous Agents and Multiagent Systems (AAMAS 2005), pp. 141–148. ACM
(2005)
32. Verma, S., Dickerson, J., Hines, K.: Counterfactual explanations for machine learn-
ing: a review. arXiv preprint arXiv:2010.10596 (2020)

Extension-Based Semantics
for Incomplete Argumentation
Frameworks
Jean-Guy Mailly(B)
LIPADE, University of Paris, Paris, France
jean-guy.mailly@u-paris.fr
Abstract. Incomplete Argumentation Frameworks (IAFs) have been
deﬁned to incorporate some qualitative uncertainty in abstract argu-
mentation: information such as “I am not sure whether this argument
exists” or “I am not sure whether this argument attacks that one” can
be expressed. Reasoning with IAFs is classically based on a set of com-
pletions, i.e. standard argumentation frameworks that represent the pos-
sible worlds encoded in the IAF. The number of these completions may
be exponential with respect to the number of arguments in the IAF.
This leads, in some cases, to an increase of the complexity of reasoning,
compared to the complexity of standard AFs. In this paper, we follow an
approach that was initiated for Partial AFs (a subclass of IAFs), which
consists in deﬁning new forms of conﬂict-freeness and defense, the prop-
erties that underly the deﬁnition of Dung’s semantics for AFs. We gen-
eralize these semantics from PAFs to IAFs. We show that, among three
possible types of admissibility, only two of them satisfy some desirable
properties. We use them to deﬁne two new families of extension-based
semantics. We study the properties of these semantics, and in particular
we show that their complexity remains the same as in the case of Dung’s
AFs. Finally, we propose a logical encoding of these semantics, that paves
the way to the development of SAT-based solvers for reasoning with our
new semantics for IAFs.
Keywords: Abstract argumentation · Uncertainty
1
Introduction
Abstract argumentation has been a major subﬁeld of Knowledge Representation
and Reasoning since the seminal paper by Dung [14]. However, although it is
very appealing, Dung’s framework is limited in the kind of information that
can be modeled: only (abstract) arguments and attacks between them. For this
reason, many generalization of this framework have been proposed, introducing
the notion of support between arguments [2], weighted attacks [15] or arguments
[26], preferences between arguments [1], and so on.
Among these generalizations of Dung’s framework, a very natural research
direction is the introduction of uncertainty in the model. Indeed, uncertainty
c
⃝Springer Nature Switzerland AG 2021
P. Baroni et al. (Eds.): CLAR 2021, LNAI 13040, pp. 322–341, 2021.
https://doi.org/10.1007/978-3-030-89391-0_18

Extension-Based Semantics for Incomplete Argumentation Frameworks
323
is omnipresent in real world, and must be taken into account in the modeling
of agents that reason about their environment or about other agents. More-
over, when arguments are generated from natural language processing [21], the
nuances that exist in natural language are likely to be sources of uncertainty [5]
that should appear in the formal model. Two directions have been followed for
integrating uncertainty in abstract argumentation: quantitative representation
of uncertainties (e.g. probabilities [19,22]) and qualitative ones [6,11,12]. While
quantitative representation of uncertainty is valuable when it is available, allow-
ing ﬁne grained reasoning about uncertainty, it may not be available in many
realistic cases. The study of qualitative models of uncertainty is thus of utter
importance for the design of AI systems.
In this paper, we follow this direction. Qualitative uncertainty in abstract
argumentation was originally studied in a context of Argumentation Framework
(AF) merging [12]: Partial Argumentation Frameworks (PAFs) are AFs with
possible ignorance about the existence of some attacks. Semantics dedicated
to these PAFs were then deﬁned in [11]. However, most of the work in this
ﬁeld focuses on a generalization of PAFs, namely Incomplete AFs (IAFs), and
reasoning is based on completions. A completion is an argumentation framework
that represents one of the (uncertain) options encoded in the IAF. Classical
reasoning tasks are then adapted in two versions: the possible view (is some
property true for some completion?) and the necessary view (is some property
true for each completion?). However, the number of completions is (in the worst
case) exponential in the number of arguments. This means that various reasoning
problems are harder for IAFs than their counterpart for standard AFs [6,8,18].
In this paper, we follow the approach initiated by [11]: we deﬁne new forms
of conﬂict-freeness and defense based on the diﬀerent types of information in an
IAF. The combination of a notion of conﬂict-freeness and a notion of defense
yields a notion of admissibility; we show that among the three possible variants
of admissibility, only two of them satisfy some desirable property, namely Dung’s
Fundamental Lemma. This lemma states, in classical AFs, that an admissible
set remains admissible if an argument defended by it is added to the set. From
the two “fundamental” notions of admissibility for IAFs, we deﬁne variants of
the classical complete, preferred and stable semantics. We study some properties
of these semantics, and we show that their complexity remains the same as in
the standard AF case. Finally, we propose logical encodings, in the same vein
as [9], that pave the way to SAT-based implementations for reasoning with our
new semantics.
The rest of the paper is organized as follows. Section 2 describes the back-
ground notions on abstract argumentation. In Sect. 3, we deﬁne our new seman-
tics and study some of their properties, in particular the satisfaction of the
Fundamental Lemma, and some inclusion relations between them. In Sect. 4, we
show that the complexity remains the same as in the standard AF case,1 and
we provide a logical encoding for our semantics. Finally, Sect. 5 describes some
related work, and Sect. 6 concludes the paper.
1 At the exception of skeptical acceptability under the complete semantics, for which
we do not have a tight complexity result yet.

324
J.-G. Mailly
2
Background
2.1
Abstract Argumentation Frameworks
Abstract argumentation is the study of relations between abstract pieces of infor-
mation called arguments; the internal nature of arguments, as well as their ori-
gin, is considered as irrelevant. Only the interactions between arguments are
considered in order to determine which arguments are acceptable or not. The
most classical type of relationship is the so-called attack relation, that expresses
a contradiction between arguments. An attack is generally directed from one
argument to another one, meaning that the ﬁrst one somehow defeats the sec-
ond one. The seminal paper [14] has launched the strong interest for abstract
argumentation in the last 25 years. In this section, we formally introduce this
abstract framework and how it is used for reasoning.
We suppose the existence of a ﬁnite set of arguments A.
Deﬁnition 1 (Argumentation Framework). An argumentation framework
(AF) is a pair F = ⟨A, R⟩with A ⊆A the set of arguments and R ⊆A × A
the set of attacks.
For a, b ∈A, we say that a attacks b if (a, b) ∈R. If b attacks some c ∈A,
then a defends c against b. Similarly, a set S ⊆A attacks (resp. defends) an
argument b if there is some a ∈S that attacks (resp. defends) b.
Example 1. Figure 1 depicts an AF F = ⟨A, R⟩, with A = {a, b, c} (i.e. the
nodes of the graph) and R = {(b, a), (b, c), (c, b)} (i.e. the edges of the graph).
a
b
c
Fig. 1. An example of AF F
The acceptability of arguments is classically evaluated through the concept
of extensions, i.e. sets of arguments that are jointly acceptable. This form of
joint acceptance can be interpreted as deﬁning a coherent point of view about
the argumentative scenario that is represented by the AF. Diﬀerent semantics
have been deﬁned, that yield diﬀerent sets of extensions. The usual semantics
are based on two main principles: conﬂict-freeness and admissibility.
Deﬁnition 2 (Conﬂict-freeness and Admissibility). Given F = ⟨A, R⟩an
AF, the set S ⊆A is
– conﬂict-free iﬀ∀a, b ∈S, (a, b) ̸∈R;
– admissible iﬀit is conﬂict-free and ∀a ∈S, ∀b ∈A s.t. (b, a) ∈R, ∃c ∈S
s.t. (c, b) ∈R.

Extension-Based Semantics for Incomplete Argumentation Frameworks
325
The meaning of conﬂict-freeness is quite easy to understand: we do not want
to accept together arguments that are conﬂicting. Admissibility corresponds to a
notion of “self-defense”: a (conﬂict-free) set of arguments must be able to defend
itself against external attacks in order to be considered as a valid point of view.
We use cf(F) (resp. ad(F)) to denote the set of conﬂict-free (resp. admissible)
sets of an AF F.
These principles are usually considered to be too weak to deﬁne semantics,
but the classical semantics are based on them.2 We recall now the deﬁnition of
these semantics:
Deﬁnition 3 (Admissibility-based Semantics). Given F = ⟨A, R⟩an AF,
the admissible set S ⊆A is
– a complete extension iﬀS contains all the arguments that it defends;
– a preferred extension iﬀS is a ⊆-maximal admissible set;
– a grounded extension iﬀS is a ⊆-minimal complete extension.
A fourth semantics is deﬁned by Dung, that does not directly rely on the
notion of admissibility:
Deﬁnition 4 (Stable Semantics). Given F = ⟨A, R⟩an AF, the conﬂict-free
set S ⊆A is a stable extension iﬀ∀a ∈A\S, S attacks a.
We use co(F), pr(F), gr(F) and st(F) for the sets of (respectively) complete,
preferred, grounded and stable extensions. Among their basic properties:
– ∀F, |σ(F)| ≥1 for σ ∈{co, pr, gr};
– ∀F, |gr(F)| = 1;
– ∀F, st(F) ⊆pr(F) ⊆co(F).
The last point implies that stable extensions are admissible sets as well, even if
they are not explicitly deﬁned through admissibility.
Example 2. Considering again F from Example 1; its extensions for the four
semantics deﬁned previously are given in Table 1 (second column).
For further details about these semantics, as well as other semantics that
have been deﬁned subsequently, we refer the reader to [4,14].
Given an argumentation framework and a semantics, classical reasoning tasks
include the veriﬁcation that a given set of arguments is an extension, and that
a given argument is credulously or skeptically acceptable, i.e. belongs to some
or each extension. Formally:
σ-Ver Given an AF F = ⟨A, R⟩and S ⊆A, is S a σ-extension of F?
σ-Cred Given an AF F = ⟨A, R⟩and a ∈A, does a belong to some σ-extension
of F?
2 However, let us notice that we will sometimes include them in the family of studied
semantics, for homogeneity of the presentation, e.g. in the complexity results (see
Sect. 4.1).

326
J.-G. Mailly
σ-Skep Given an AF F = ⟨A, R⟩and a ∈A, does a belong to each σ-extension
of F?
We use Credσ(F) (resp. Skepσ(F)) to denote the set of credulously (resp. skepti-
cally) accepted arguments of F, i.e. those for which the answer to σ-Cred (resp.
σ-Skep) is “YES”.
Example 3. The credulously and skeptically accepted arguments in F from
Example 1 are given in Table 1 (third and fourth columns).
Table 1. Extensions and acceptable arguments of F, for σ ∈{gr, st, co, pr}.
Semantics σ σ(F)
Credσ(F) Skepσ(F)
gr
{∅}
∅
∅
st
{{b}, {a, c}}
{a, b, c}
∅
co
{∅, {b}, {a, c}} {a, b, c}
∅
pr
{{b}, {a, c}}
{a, b, c}
∅
The complexity of these problems for various semantics has been established,
see e.g. [16] for an overview. The relevant results for this paper are summarized
in Table 2. We assume that the reader is familiar with basic notions of complexity
theory, otherwise see e.g. [3].
Table 2. Complexity of σ-Ver, σ-Cred and σ-Skep, for σ ∈{cf, ad, gr, st, co, pr}. C-c
means C-complete.
Semantics σ σ-Ver
σ-Cred σ-Skep
cf
in L
in L
Trivial
ad
in L
NP-c
Trivial
gr
P-c
P-c
P-c
st
in L
NP-c
coNP-c
co
in L
NP-c
P-c
pr
coNP-c NP-c
ΠP
2 -c
2.2
Qualitative Uncertainty in AFs
Now we present the existing models that incorporate qualitative uncertainty in
abstract argumentation.
Incomplete Argumentation Frameworks
Deﬁnition 5 (Incomplete Argumentation Framework). An incomplete
argumentation framework (IAF) is a tuple I = ⟨A, A?, R, R?⟩where

Extension-Based Semantics for Incomplete Argumentation Frameworks
327
– A ⊆A is the set of certain arguments;
– A? ⊆A is the set of uncertain arguments;
– R ⊆(A ∪A?) × (A ∪A?) the set of certain attacks;
– R? ⊆(A ∪A?) × (A ∪A?) the set of uncertain attacks.
A and A? are disjoint sets of arguments, and R, R? are disjoint sets of attacks.
Intuitively, A and R correspond, respectively, to arguments and attacks that
certainly exist, while A? and R? are those that may (or may not) actually exist.
Example 4. Figure 2 depicts an IAF I = ⟨A, A?, R, R?⟩with A = {a, b} (plain
nodes), A? = {c} (square dashed node), R = {(c, b)} (plain edge) and R? =
{(b, a)} (dotted edge). It means that the arguments a and b certainly exist, and
there is an uncertainty regarding the existence of the attack (b, a). Then, the
argument c is uncertain, but if it exists then the attack (c, d) certainly exists as
well.
a
b
c
Fig. 2. An example of IAF I
Reasoning with such IAFs is generally made through the notion of comple-
tion:
Deﬁnition 6 (Completion). Let I = ⟨A, A?, R, R?⟩be an IAF. A completion
of I is a pair ⟨Ac, Rc⟩such that
– A ⊆Ac ⊆A ∪A?;
– R ∩(Ac × Ac) ⊆Rc ⊆(R ∪R?) ∩(Ac × Ac).
Example 5. Figure 3 depicts the completions of I from Example 4. F1 shows the
situation where none of the uncertain elements actually exists, while F4 shows
the opposite situation (all the uncertain elements appear). F2 and F3 shows the
intermediate situations, where only one uncertain element (either the argument
c, or the attack (b, a)) exists.
a
b
(a) F1
a
b
c
(b) F2
a
b
(c) F3
a
b
c
(d) F4
Fig. 3. The completions of I
As seen with the previous example, the number of completions is generally
exponential in the size of the IAF. More precisely, it is bounded by 2|A?|+|R?|.

328
J.-G. Mailly
Finally, reasoning tasks like credulous acceptance, skeptical acceptance or
veriﬁcation are deﬁned with respect to some or each completion [6,8]: each clas-
sical reasoning task has two variants, following the possible view (the property
holds in some completion) and the necessary view (the property holds in each
completion). These reasoning tasks are, in most cases, computationally harder
than their counterpart for standard AFs (under the usual assumption that the
polynomial hierarchy does not collapse) [6,8]. This can be explained by the
exponential number of completions.
Partial Argumentation Frameworks. Partial Argumentation Frameworks were
initially deﬁned as tool in a merging process [12]. They are tuples ⟨A, R, I, N⟩
with three binary relations over the set of arguments A: R is the (certain) attack
relation, I the ignorance relation, and N the (certain) non-attack relation. Since
N = (A × A)\(R ∪I), a PAF can be identiﬁed with only ⟨A, R, I⟩. Since the
meaning of I is exactly the same as the meaning of R?, PAFs actually form
a subclass of IAFs:3 any PAF ⟨A, R, I⟩is an IAF ⟨A, ∅, R, R?⟩with A = A,
R = R, R? = I.
Extension-based semantics for PAFs have been deﬁned in [11]. Intuitively, the
idea consists in deﬁning diﬀerent forms of conﬂict-freeness and defense, and then
combine them for deﬁning three types of admissibility. From these new notions
of admissibility, the authors deﬁne three variants of the preferred semantics,
and study their properties. An interesting point is the fact that the complexity
remains the same as in Dung’s setting, contrary to the other reasoning methods
for IAFs. These are the notions that are generalized from PAFs to IAFs in the
next section.
3
Generalizing Extension-Based Semantics from PAFs
to IAFs
In this section, we follow the same approach as [11] for deﬁning semantics for
IAFs. Instead of deﬁning the extensions with respect to the set of completions of
the IAF, we will generalize the basic concepts of conﬂict-freeness and defense to
take into account the uncertainty in the IAF. Then, the usual admissibility-based
semantics can be deﬁned.
3.1
Conﬂict-Free and Admissible Sets of IAFs
We follow two approaches for deﬁning conﬂict-freeness and defense for IAFs:
– Optimistic view: we consider that only certain arguments and attacks are
harmful, so keep the deﬁnition of conﬂict-freeness and defense as in Dung’s
frameworks;
– Pessimistic view: we consider that all attacks are harmful, and must be
defended by certain arguments and attacks only.
3 This subclass was studied under the name Attack-Incomplete AFs [7].

Extension-Based Semantics for Incomplete Argumentation Frameworks
329
By optimistic, we mean that the agent considers (e.g.) that (a, b) ∈R? does not
make a a real “threat” against the acceptance of b. Roughly speaking, it means
that the agent is tolerant to conﬂicts if they are uncertain. On the opposite,
the pessimistic view means that the agent considers that all uncertain attacks
against an argument are real threats against the acceptance of b, and that b must
be defended by certain elements only in order to be accepted. Let us formally
deﬁne the corresponding versions of conﬂict-freeness and defense.
Deﬁnition 7 (Weak and Strong Conﬂict-freeness). Let I = ⟨A, A?, R, R?⟩
be an IAF. The set S ⊆A ∪A? is
– weakly conﬂict-free iﬀ∀a, b ∈S ∩A, (a, b) ̸∈R;
– strongly conﬂict-free iﬀ∀a, b ∈S, (a, b) ̸∈R ∪R?.
We use cfw(I) and cfs(I) to denote, respectively, the weakly and strongly
conﬂict-free sets of an IAF I.
Example 6. Figure 4 depicts an IAF I2 = ⟨A, A?, R, R?⟩, with A = {a, b, d, e},
A? = {c, f}, R = {(c, b), (e, b), (e, f)} and R? = {(b, a), (b, e), (d, e)}. The set
{a, b, c} is weakly conﬂict-free: the attack from b to a does not violate the weak
conﬂict-freeness since it is uncertain, and the attack from c to b does not violate
it either because the attacker (c) is uncertain. It is not strongly conﬂict-free
because of the same two attacks.
a
b
c
d
e
f
Fig. 4. An example of IAF I2
Strong conﬂict-freeness can be regarded as conﬂict-freeness applied on the
“full” graph Ffull = ⟨A ∪A?, R ∪R?⟩, i.e. an AF made from the same argu-
ments and attacks than the IAF, but without any uncertainty. However, weakly
conﬂict-free sets do not correspond to the conﬂict-free sets of the “minimal”
graph Fmin = ⟨A, R ∩(A × A)⟩(i.e. the AF obtained by simply ignoring the
uncertain elements): see e.g. {a, b, c} exhibited in Example 6, which is not a set
of arguments in Fmin (since c ̸∈A).
Deﬁnition 8 (Weak and Strong Defense).
Let I = ⟨A, A?, R, R?⟩be an
IAF. Given a set of arguments S ⊆A ∪A? and an argument a ∈A ∪A?,
– S weakly defends a iﬀ∀b ∈A such that (b, a) ∈R, ∃c ∈S ∩A s.t. (c, b) ∈R;
– S strongly defends a iﬀ∀b ∈A ∪A? such that (b, a) ∈R ∪R?, ∃c ∈S ∩A
s.t. (c, b) ∈R.

330
J.-G. Mailly
Example 7. Considering again I2 from Example 6, we observe that S = {a}
weakly defends a, since there is no x ∈A s.t. (x, a) ∈R. On the contrary, a is
not strongly defended by S, because there is no argument in S ∩A that attacks
b. But S′ = {a, e} strongly defends a: e ∈S′ ∩A (certainly) attacks b.
We observe that in the case where A? = ∅, then weak conﬂict-freeness and
defense correspond to the notions of R-conﬂict-freeness and R-acceptability
deﬁned in [11], while the strong versions correspond to RI-conﬂict-freeness and
RI-acceptability. Then, if R? = ∅also holds, then both weak conﬂict-freeness
and strong conﬂict-freeness coincide with the classical conﬂict-freeness [14], while
both forms of defense deﬁned here correspond with the classical defense.
For deﬁning a notion of admissibility, we must combine conﬂict-freeness and
defense. In theory, Deﬁnitions 7 and 8 induce four notions of admissibility. How-
ever, the following result shows that weak conﬂict-freeness and strong conﬂict-
freeness induce the same notion of admissibility when combined with strong
defense.
Proposition 1. Let I = ⟨A, A?, R, R?⟩be an IAF. Let S ⊆A ∪A? be a set of
arguments such that S is weakly conﬂict-free and ∀a ∈S, S strongly defends a.
Then S is strongly conﬂict-free.
The proof is similar to the proof of [11, Property 1].
Proof. Reasoning towards a contradiction, let us suppose that S is not strongly
conﬂict-free, i.e. ∃a, b ∈S such that (a, b) ∈R? (we can exclude the option
(a, b) ∈R because S is assumed to be weakly conﬂict-free). Then, since S
strongly defends all its elements, in particular it strongly defends b, so ∃c ∈S
such that (c, a) ∈R. This is a contradiction with the weak conﬂict-freeness of
S. So we can conclude that S is strongly conﬂict-free.
Now we deﬁne the three variants of admissibility.4
Deﬁnition 9 (Weak, Mixed and Strong Admissibility).
Given I =
⟨A, A?, R, R?⟩an IAF, a set of arguments S ⊆A ∪A? is
– weakly admissible iﬀS is weakly conﬂict-free and weakly defends all its ele-
ments;
– mixedly admissible iﬀS is strongly conﬂict-free and weakly defends all its
elements;
– strongly admissible iﬀS is strongly conﬂict-free and strongly defends all its
elements.
The weakly (resp. mixedly, strongly) admissible sets of an IAF I are denoted
by adw(I) (resp. adm(I), ads(I)).
The deﬁnitions imply that ads(I) ⊆adm(I) ⊆adw(I), for any IAF I. Also,
as in the standard Dung’s framework, every IAF has at least one admissible set,
4 The terminology “strong defense” and “strong admissibility” has been used with
another meaning in [10], where it applies to classical AFs, not IAFs.

Extension-Based Semantics for Incomplete Argumentation Frameworks
331
for all the variations of admissibility. Indeed, for any IAF I, ∅∈ads(I). This
fact will be useful later to guarantee the existence of extensions for the semantics
based on admissibility.
Before going further with the deﬁnition of semantics based on these new
notions of admissibility, we brieﬂy discuss a property of classical semantics that
we believe is important. It is called the Fundamental Lemma by Dung [14,
Lemma 10]. This lemma states that if a set of arguments S is admissible, and
defends an argument a, then S ∪{a} is admissible. Besides its technical interest
for proving some further results, this lemma describes an intuitive property of
argumentation in general: if a point of view (i.e. a set of arguments) is seen as
valid, then it should be jointly acceptable with any argument that it success-
fully defends. We thus consider this property as necessary for deﬁning reason-
able semantics. With the following lemma, we determine which of the notions of
admissibility given in Deﬁnition 9 satisfy a notion of “fundamentality” similar to
Dung’s lemma. More precisely, we show that only weak and strong admissibility
are suitable for deﬁning semantics.
Lemma 1 (Fundamental Lemma). Given I = ⟨A, A?, R, R?⟩an IAF, and
S ⊆A ∪A? a weakly (resp. strongly) admissible set, if S weakly (resp. strongly)
defends some a ∈A ∪A?, then S ∪{a} is weakly (resp. strongly) admissible.
Proof. We ﬁrst consider weak admissibility. Let us prove that S ∪{a} is weakly
conﬂict-free. First of all, notice that if a ∈A? then the set S ∪{a} is weakly
conﬂict-free iﬀS is weakly conﬂict-free, since only certain attacks between cer-
tain arguments violate weak conﬂict-freeness. So in the rest of the reasoning
we suppose that a ∈A. Towards a contradiction, suppose that S ∪{a} is not
weakly conﬂict-free. Then, ∃b ∈S ∩A such that, either (b, a) ∈R or (a, b) ∈R.
In the former case, since S weakly defends a, then there must be a c ∈S ∩A
with (c, b) ∈R, which is impossible since S is weakly conﬂict-free. Hence the
contradiction. In the latter case ((a, b) ∈R), since S is weakly admissible, it
must defend b against a, and the same reasoning applies for concluding the
impossibility. Thus S ∪{a} is weakly conﬂict-free.
The fact that S ∪{a} weakly defends all its elements comes from the fact
that S weakly defends all its elements, as well as a. So we conclude that S ∪{a}
is weakly admissible.
Now, consider S a strongly admissible set that strongly defends some a ∈
A ∪A?. Suppose that S ∪{a} is not strongly conﬂict-free. It means that some
b ∈S is such that (b, a) ∈R ∪R? or (a, b) ∈R ∪R?. In the ﬁrst case, the fact
that S strongly defends a (against b) means that some c ∈S ∩A attacks b, which
violates strong conﬂict-freeness of S. In the second case, since S strongly defends
all its elements, there is a c ∈S ∩A such that (c, a) ∈R, which is impossible for
similar reasons to the ﬁrst case. Hence S ∪{a} is strongly conﬂict-free. Finally,
the fact that S ∪{a} strongly defends all its elements follows the fact that S
strongly defends all its elements and a. So we conclude that S ∪{a} is strongly
admissible.

332
J.-G. Mailly
On the contrary, mixed admissibility does not satisfy a property of funda-
mentality.
Proposition 2. There is an IAF I = ⟨A, A?, R, R?⟩, S ⊆A ∪A? and an
argument a ∈A∪A? such that S is mixedly admissible, S weakly defends a, and
S ∪{a} is not mixedly admissible.
Proof. The IAF given at Fig. 5 provides an example. The set S = {b} is mixedly
admissible (it is strongly conﬂict-free, and it has no attacker). S weakly defends
a (since there is no x ∈A such that (x, a) ∈R, there is actually no need to
weakly defend a). But S ∪{a} is not strongly conﬂict-free, hence not mixedly
admissible.
a
b
Fig. 5. A counter-example about fundamentality of mixed admissibility
Because of this reason, we do not consider mixed admissibility as suitable for
deﬁning semantics (e.g. mixed preferred or mixed complete semantics).
Example 8. Based on Example 6 and 7, we observe that, in I2 from Fig. 4, {a} is
weakly admissible but not strongly admissible. {a, e} is not strongly admissible
either, because it does not strongly defend e (against the uncertain attack (d, e)).
The full sets of weakly and strongly admissible sets of I2 are given in Table 3.
Table 3. Weakly and Strongly Admissible Sets of I2.
adw(I2) ∅, {a}, {c} , {d}, {e}, {a, c}, {a, d},
{a, e}, {c, d}, {c, e}, {d, e}, {a, c, d},
{a, c, e}, {a, d, e}, {c, d, e}, {a, c, d, e}
ads(I2)
∅, {c}, {d}, {c, d}
3.2
Admissibility-Based Semantics for IAFs
The classical deﬁnitions of Dung’s semantics can be adapted to IAFs, based on
the two diﬀerent notions of admissibility identiﬁed as suitable in Lemma 1.
Deﬁnition 10 (Admissibility-based Semantics). Given I = ⟨A, A?, R, R?⟩
an IAF, a weakly (resp. strongly) admissible set of arguments S ⊆A ∪A? is

Extension-Based Semantics for Incomplete Argumentation Frameworks
333
– a weakly (resp. strongly) complete extension iﬀS contains all the arguments
that it weakly (resp. strongly) defends;
– a weakly (resp. strongly) preferred extension iﬀit is a ⊆-maximal weakly
(resp. strongly) admissible set.
For x ∈{w, s} and σ ∈{co, pr}, the set of x-σ extensions of an IAF I
is denoted σx(I). In the deﬁnition of the versions of complete semantics, the
notion of defense used is the same as in the underlying notion of admissibility.
Example 9. We continue Example 8. From the weakly and strongly admissible
sets described in Table 3, we deduce cow(I2) = prw(I2) = {{a, c, d, e}}, and
cos(I2) = prs(I2) = {{c, d}}.
We observe some usual properties regarding these semantics.
Proposition 3. Given I = ⟨A, A?, R, R?⟩an IAF, and x ∈{w, s},
– prx(I) ̸= ∅;
– prx(I) ⊆cox(I).
Proof. The ﬁrst item is a direct consequence of the fact that adx(I) ̸= ∅, as seen
previously. The existence of (ﬁnitely many) admissible sets implies the existence
of ⊆-maximal admissible sets.
Now, let S be a x-preferred extension of I. Reasoning towards a contradiction,
let us suppose that S ̸∈cox(I). Since S is x-admissible, it means that S x-defends
some argument a that it does not contain. According to Lemma 1, S ∪{a} is
x-admissible. This means that we have identiﬁed a proper superset of S which is
x-admissible, thus S is not a ⊆-maximal x-admissible set. This contradicts the
fact that S is x-preferred. So we can conclude S ∈cox(I).
3.3
Stable Semantics for IAFs
Now we focus on a counterpart of stable semantics for IAFs.
Deﬁnition 11 (Stable Semantics). Given I = ⟨A, A?, R, R?⟩an IAF,
– a weakly conﬂict-free set of arguments S ⊆A∪A? is a weakly stable extension
iﬀ∀a ∈A\S, there is some b ∈S ∩A such that (b, a) ∈R;
– a strongly conﬂict-free set of arguments S ⊆A ∪A? is a strongly stable
extension iﬀ∀a ∈(A ∪A?)\S, there is some b ∈S ∩A such that (b, a) ∈R.
Weakly and strongly stable extensions of an IAF I are denoted by stx(I),
where x ∈{w, s}.
Example 10. Continuing Example 9, we observe that the weakly preferred exten-
sion S = {a, c, d, e} is weakly stable as well: the argument e ∈S ∩A (certainly)
attacks all the arguments in A\S. It is not strongly stable, since it is not strongly
conﬂict-free.
On the contrary, the strongly preferred extension S′ = {c, d} is not strongly
stable, since it does not attack all the arguments in (A ∪A?)\S (e.g. a is not
attacked by S′).

334
J.-G. Mailly
In Dung’s framework, although admissibility is not directly involved in the
deﬁnition of the stable semantics, any stable extension is actually an admissible
set. We show here that it is also the case for strong and weak stable semantics
of IAFs.
Proposition 4 (Admissibility of Stable Extensions).
For any IAF I =
⟨A, A?, R, R?⟩, stx ⊆adx(I), with x ∈{w, s}.
Proof. Consider S a weakly stable extension of I. By deﬁnition of weakly stable
semantics, S is weakly conﬂict-free. Let us prove that it weakly defends all its
elements. Consider any a ∈A\S such that (a, b) ∈R for some b ∈S. By
deﬁnition of the weakly stable semantics, there is a c ∈S ∩A such that (c, a)
∈R, so S weakly defends b. Thus, S weakly defends all its elements, hence it is
weakly admissible.
Now we consider S a strongly stable extension of I. Again, strong conﬂict-
freeness is implied by the deﬁnition, so we just need to prove that S strongly
defends all its elements. Consider any a ∈A ∪A? such that (a, b) ∈R ∪R?, for
some b ∈S. By deﬁnition of strongly stable extensions, there is some c ∈S ∩A
such that (c, a) ∈R. Thus S strongly defends a, and then all its elements. We
can conclude that it is strongly admissible.
Another classical results that still holds for our new semantics is the rela-
tionship between (weakly or strongly) stable and (weakly or strongly) preferred
extensions.
Proposition 5 (Preferredness of Stable Extensions).
For any IAF I =
⟨A, A?, R, R?⟩, stx ⊆prx(I), with x ∈{w, s}.
Proof. Consider S ∈stw(I). From Proposition 4, we know that S is weakly
admissible. Towards a contradiction, suppose that S is not weakly preferred,
i.e. ∃S′ ∈adw(I) such that S ⊂S′. This implies the existence of an argument
a ∈S′\S. The weak stability of S implies the existence of some b ∈S ∩A
such that (b, a) ∈R, which violates the weak admissibility of S′. We reach a
contradiction, and thus we conclude that S ∈prw(af).
Now consider S ∈sts(I). Again, Proposition 4 implies the strong admissibil-
ity of S. Suppose the existence of S′ ∈ads(I) with S ⊂S′. Take a ∈S′\S; the
strong stability of S implies the existence of b ∈S ∩A such that (b, a) ∈R, thus
violating the strong admissibility of S′. We reach a contradiction, and conclude
that S′ does not exist, hence S ∈prs(I).
Example 10 and Proposition 5 imply that sts(I2) = ∅. The non-existence
of stable extensions in Dung’s framework is one of the main diﬀerences between
this semantics and the ones based on admissibility. We can simply show a similar
example for the weakly stable semantics as well: add a certain argument g to A
and (g, g) ∈R. The set {a, c, d, e} remains the single weakly preferred extension,
but it does not attack g, so it is not weakly stable in the new IAF.

Extension-Based Semantics for Incomplete Argumentation Frameworks
335
4
Computational Issues
4.1
Computational Complexity
In this section, we study the complexity of the variants of veriﬁcation, cred-
ulous acceptability and skeptical acceptability for IAFs. Formally, for σ ∈
{cf, ad, co, pr, st} and x ∈{w, s}:
σx-Ver Given an IAF I = ⟨A, A?, R, R?⟩and S ⊆A, is S a x-σ-extension of F?
σx-Cred Given an IAF I = ⟨A, A?, R, R?⟩and a ∈A ∪A?, does a belong to
some x-σ-extension of F?
σx-Skep Given an IAF I = ⟨A, A?, R, R?⟩and a ∈A ∪A?, does a belong to
each x-σ-extension of F?
Lower Bounds. We can prove that reasoning with our semantics for IAFs is
(at least) as hard as reasoning with the corresponding semantics for AFs. This
can be done by showing that any AF F = ⟨A, R⟩can be transformed into an
IAF IF that has the same extensions.
Deﬁnition 12 (IAF Associated with an AF). Given F = ⟨A, R⟩an AF,
the IAF associated with F is IF = ⟨A, ∅, R, ∅⟩.
Now we prove the correspondance of extensions, i.e. σ(F) = σw(IF) =
σs(IF), for any σ ∈{cf, ad, pr, co, st}.
Proposition 6 (Dung Compatibility).
Given F = ⟨A, R⟩an AF, σ ∈
{cf, ad, pr, co, st} and x ∈{w, s}, σ(F) = σx(IF), where IF follows Deﬁni-
tion 12.
Proof. Observe that a set S ⊆A is conﬂict-free (in F) iﬀit is weakly and
strongly conﬂict-free (in IF). Then, a set S ⊆A defends an argument a ∈A
against all it attackers (in F) iﬀit weakly and strongly defends a against all
its attackers (in IF). These facts imply ad(F) = adw(IF) = ads(IF), which
in turn imply the equivalence of complete and preferred extensions of F with
the (weak and strong) complete and preferred extensions of IF. Given S ⊆A,
the equivalence between the conditions for S being stable in F and (weakly or
strongly) stable in IF is straightforward.
This allows to prove that the complexity of reasoning with AFs provides a
lower bound of the complexity of reasoning with IAFs.
Proposition 7. Given
σ
∈
{cf, ad, pr, co, st},
x
∈
{w, s},
and
P
∈
{Ver, Cred, Skep}, if σ-P is C-hard, then σx-P is C-hard.
Proof. Proposition 6 provides a polynomial-time reduction from σ-P to σx-P.

336
J.-G. Mailly
Upper Bounds for Extension Veriﬁcation. Similarly to Dung’s classical
setting, most of the properties of extensions can be veriﬁed in polynomial time
for our IAF semantics.
Lemma 2. Given an IAF I = ⟨A, A?, R, R?⟩and a set of arguments S ⊆
A ∪A?, the following tasks are doable in polynomial time:
1. check whether S is weakly (resp. strongly) conﬂict-free,
2. check whether S weakly (resp. strongly) defends some argument a ∈A (resp.
a ∈A ∪A?),
3. check whether each argument in A\S (resp. (A ∪A?)\S) is attacked by an
argument in S ∩A.
Proof. For item 1., weak (resp. strong) conﬂict-freeness is checked by enumerat-
ing every (a, b) ∈S ×S, and verifying whether (a, b) ∈R (resp. (a, b) ∈R∪R?).
There are |S|2 such pairs (a, b), and verifying the membership to R (resp.
R ∪R?) is bounded by |A ∪A?|2 (i.e. the maximal number of possible attacks
in an IAF).
For item 2., identifying the arguments b ∈A (resp. b ∈A ∪A?) such that
(b, a) ∈R (resp. (b, a) ∈R∪R?) only requires to enumerate all the arguments in
A (resp. A ∪A?), and then polynomially check the membership to R (resp. R ∪
R?). Then, for each of these attackers b, enumerate all the arguments c ∈S ∩A
and check the membership of (c, b) to R (resp. R ∪R?). All the enumerations
are polynomially bounded.
Finally, for item 3., enumerate all the pairs (a, b) such that a ∈S ∩A and
b ∈A\S (resp. b ∈(A ∪A?)\S), and then check whether (a, b) ∈R.
Combining these polynomial operations allows to check whether a set of
arguments is an extension, for most of the semantics studied in this paper.
Proposition 8. For σ ∈{cf, ad, co, st} and x ∈{w, s}, σx-Ver is polynomial.
Proof. The result straightforwardly follows Lemma 2.
Following Proposition 7, the veriﬁcation of (weakly or strongly) preferred
extensions is intractable (under the usual assumptions of complexity theory).
The following results proves that it remains at the ﬁrst level of the polynomial
hierarchy, similarly to Dung’s preferred semantics.
Proposition 9. For x ∈{w, s}, prx-Ver is in coNP.
Proof. Given S ⊆A ∪A?, proving that S is not a weakly (resp. strongly) pre-
ferred extension is doable with the following non-deterministic polynomial algo-
rithm:
1. Check whether S is weakly (resp. strongly) admissible. If not, then S is not
weakly (resp. strongly) preferred.
2. Otherwise, guess a proper superset of S, i.e. S ⊂S′ ⊆A ∪A?. Verifying
whether S′ is a weakly (resp. strongly) admissible set is doable in polynomial
time with a deterministic algorithm. If S′ is weakly (resp. strongly) admissi-
ble, then S is not a weakly (resp. strong) preferred extension.
This algorithm proves that the complementary problem is in NP, thus we con-
clude that prx-Ver ∈coNP for x ∈{w, s}.

Extension-Based Semantics for Incomplete Argumentation Frameworks
337
Upper Bounds for Acceptability. First, consider the case of cfx, for x ∈
{w, s}. An argument a is credulously accepted w.r.t. cfx iﬀ{a} ∈cfx(I). This
can be easily checked, by verifying that (a, a) ̸∈R and (a, a) ̸∈R?. This is doable
in polynomial time and logarithmic space. Thus cfx-Cred ∈L, for x ∈{w, s}.
Skeptical acceptability is even easier: since ∅is weakly (resp. strongly) conﬂict-
free, there is no skeptically acceptable argument w.r.t. cfx for any IAF. The
reasoning is the same for adx-Skep.
Proposition 10. For σ ∈{ad, co, st, pr} and x ∈{w, s}, σx-Cred is in NP.
Proof. For σ ∈{ad, co, st}, guess a set of arguments that contains the queried
argument a, and check (in polynomial time, see Proposition 8) whether it is a
x-σ-extension. This is a NP algorithm for deciding σx-Cred.
For σ = pr, notice that an argument belongs to some weakly (resp. strongly)
preferred extension iﬀit belongs to some weakly (resp. strongly) admissible set,
hence the result.
Proposition 11. For σ ∈{co, st} and x ∈{w, s}, σx-Skep is in coNP.
Proof. Guess a set of arguments that does not contain the queried argument
a and check (in polynomial time) whether it is a x-σ-extension, i.e. a is not
skeptically accepted w.r.t. σx. This is a NP algorithm, thus σx-Skep is in coNP.
Proposition 12. For x ∈{w, s}, prx-Skep is in ΠP
2 .
Proof. Analogous to Proposition 11, except that the higher complexity of veri-
ﬁcation under the (weakly or strongly) preferred semantics yields a higher com-
plexity upper bound for skeptical acceptability as well.
Discussion. We have proved that, in spite of the higher expressivity of IAFs
compared to standard AFs, the complexity of most classical reasoning tasks
remains the same. The only exception is skeptical acceptability under (weakly
or strongly) complete semantics, for which we only have a coNP upper bound,
while it is polynomial in standard Dung’s AFs. We plan to study a counterpart
of the grounded semantics for IAFs, which could bring new insights for the
complete semantics. Finally, notice that using the weak or strong counterpart of
our semantics does not have an impact on the complexity of reasoning.
4.2
SAT-Based Computational Approach
We follow the classical approach, initiated by [9], which consists in associating
an AF with a propositional formula such that there is a bijection between the
extensions of the AF and the models of the formula. Its has been applied with
success for developing argumentation solvers [20,24].
In the following, we consider an IAF I = ⟨A, A?, R, R?⟩, and we deﬁne a
set of propositional variables XA ∪A? = {xa | a ∈A ∪A?}. Intuitively, an
interpretation ω corresponds to the set of arguments S = {a ∈A ∪A? | ω(xa) =
⊤}. We will provide in the rest of this section propositional formulas such that
their models correspond to desirable sets of arguments (e.g. weakly or strongly
conﬂict-free sets or extensions).

338
J.-G. Mailly
Conﬂict-Freeness. Recall that a set of arguments is weakly conﬂict-free if there
is no certain attack between two certain arguments in it, while it is strongly
conﬂict-free if there is no attack at all (neither certain nor uncertain) between
any element of the set. This is encoded, respectively, by the following formulas
φw
cf and φs
cf:
φw
cf =

a,b∈A,(a,b)∈R
(¬xa ∨¬xb)
φs
cf =

a,b∈A∪A?,(a,b)∈R∪R?
(¬xa ∨¬xb)
Admissibility. Weak (resp. strong) admissibility is based on weak (resp. strong)
conﬂict-freeness, and weak (resp. strong) defense. We introduce a formula δw
(resp. δs) which characterizes sets of arguments that weakly (resp. strongly)
defend all their elements.
δw =

a∈A∪A?
xa →

b∈A,(b,a)∈R

c∈A,(c,b)∈R
xc
δs =

a∈A∪A?
xa →

b∈A∪A?,(b,a)∈R∪R?

c∈A,(c,b)∈R
xc
Then, weak and strong admissibility are encoded in
φx
ad = φx
cf ∧δx
where x ∈{w, s}.
Complete Extensions. The formulas δw and δs characterize sets of arguments
that (weakly or strongly) defend all their elements. To characterize complete
extensions, we just need to replace the implication by an equivalence, which
yields sets of arguments that defend all their elements and contain everything
they defend. Formally,
φx
co = φx
cf ∧δ′
x
where x ∈{w, s}, and
δ′
w =

a∈A∪A?
xa ↔

b∈A,(b,a)∈R

c∈A,(c,b)∈R
xc
δ′
s =

a∈A∪A?
xa ↔

b∈A∪A?,(b,a)∈R∪R?

c∈A,(c,b)∈R
xc

Extension-Based Semantics for Incomplete Argumentation Frameworks
339
Stable Extensions. Weakly (resp. strongly) stable extensions are weakly (resp.
strongly) conﬂict-free sets that attack all the certain arguments (resp. all the
arguments) that they do not contain. Said otherwise, it means that an argument
which is not attacked by (a certain argument in) the extension belongs to the
extension. It can be characterized as follows:
φw
st = φw
cf ∧

a∈A
((

b∈A,(b,a)∈R
¬xb) →xa)
φs
st = φs
cf ∧

a∈A∪A?
((

b∈A,(b,a)∈R
¬xb) →xa)
Preferred Extensions. Finally, weakly and strongly preferred semantics can-
not (under the usual assumptions of complexity theory) be directly encoded as
propositional formulas, since the complexity of reasoning with weak and strong
preferred semantics is higher than the complexity of Boolean satisﬁability (espe-
cially, skeptical acceptability is ΠP
2 -complete). However, other techniques related
to propositional logic have been used in the past for computing preferred exten-
sions, e.g. quantiﬁed Boolean formulas [17], maximal satisﬁable subsets [20] or
CEGAR (CounterExample Guided Abstraction Reﬁnement) [24]. These tech-
niques could be adapted for computing weakly or strongly preferred extensions.
5
Related Work
Control Argumentation Frameworks (CAFs) [13,23,25] are highly related to
IAFs. They add another kind of uncertainty (about the direction of an attack),
and a “control part”, which is a set of arguments and attacks that must be
selected by the agent, the goal being to enforce the acceptability of a set of argu-
ments in each (or some) completion, by means of the selected control arguments.
Reasoning with CAFs is only based on completions, and generally the compu-
tational complexity is high (at least the same as reasoning with completions of
IAFs, and sometimes higher).
Reasoning with weighted AFs (i.e. AFs with weights on the attacks) [15] con-
sists, somehow, in relaxing conﬂict-freeness in order to jointly accept conﬂicting
arguments, as soon as the total amount of conﬂict (i.e. the sum of the weights
of the attacks) is lower than a given inconsistency budget. We could adapt this
principle for IAFs, by accepting only a given amount of uncertain attacks in
extensions.
6
Conclusion
In this paper, we have continued an eﬀort started by [11], and deﬁned extension-
based semantics for Incomplete Argumentation Frameworks that do not rely on
the completions of the IAF. We have studied the properties of our new semantics,

340
J.-G. Mailly
and provided complexity results and logical encoding that pave the way to SAT-
based computation.
Future work include, naturally, missing complexity results (i.e. tight results
for the skeptical acceptability under weakly and strongly complete semantics)
and implementation of our encodings. In particular, the comparison of the var-
ious methods that reach the second level of the polynomial hierarchy for com-
puting the preferred extensions is an enthralling question. The study of the
grounded semantics will fulﬁll our study of Dung-style semantics for IAFs. We
also plan to apply this kind of semantics to Control Argumentation Frameworks,
which would decrease the complexity of controllability. This requires to take into
account the additional type of information, namely the uncertainty about the
direction of attacks. The link with weighted AFs, i.e. integrating an inconsis-
tency budget in the weak variants of our semantics, is also a promising line for
future research.
References
1. Amgoud, L., Cayrol, C.: A reasoning model based on the production of acceptable
arguments. Ann. Math. Artif. Intell. 34(1–3), 197–215 (2002)
2. Amgoud, L., Cayrol, C., Lagasquie-Schiex, M., Livet, P.: On bipolarity in argu-
mentation frameworks. Int. J. Intell. Syst. 23(10), 1062–1093 (2008)
3. Arora, S., Barak, B.: Computational Complexity - A Modern Approach. Cambridge
University Press, Cambridge (2009)
4. Baroni, P., Caminada, M., Giacomin, M.: Abstract argumentation frameworks and
their semantics. In: Baroni, P., Gabbay, D., Giacomin, M., van der Torre, L. (eds.)
Handbook of Formal Argumentation, pp. 159–236. College Publications (2018)
5. Baroni, P., Giacomin, M., Liao, B., van der Torre, L.: Encompassing uncertainty
in argumentation schemes. In: Proceedings of the Workshop on Frontiers and Con-
nections between Argumentation Theory and Natural Language Processing, Forl`ı-
Cesena, Italy, 21–25 July 2014 (2014)
6. Baumeister, D., J¨arvisalo, M., Neugebauer, D., Niskanen, A., Rothe, J.: Acceptance
in incomplete argumentation frameworks. Artif. Intell. 295, 103470 (2021)
7. Baumeister, D., Neugebauer, D., Rothe, J.: Veriﬁcation in attack-incomplete argu-
mentation frameworks. In: Walsh, T. (ed.) ADT 2015. LNCS (LNAI), vol. 9346, pp.
341–358. Springer, Cham (2015). https://doi.org/10.1007/978-3-319-23114-3 21
8. Baumeister, D., Neugebauer, D., Rothe, J., Schadrack, H.: Veriﬁcation in incom-
plete argumentation frameworks. Artif. Intell. 264, 1–26 (2018)
9. Besnard, P., Doutre, S.: Checking the acceptability of a set of arguments. In:
10th International Workshop on Non-Monotonic Reasoning (NMR 2004), pp. 59–64
(2004)
10. Caminada, M., Dunne, P.E.: Strong admissibility revisited: theory and applica-
tions. Argument Comput. 10(3), 277–300 (2019)
11. Cayrol, C., Devred, C., Lagasquie-Schiex, M.C.: Handling ignorance in argumen-
tation: semantics of partial argumentation frameworks. In: Mellouli, K. (ed.)
ECSQARU 2007. LNCS (LNAI), vol. 4724, pp. 259–270. Springer, Heidelberg
(2007). https://doi.org/10.1007/978-3-540-75256-1 25
12. Coste-Marquis, S., Devred, C., Konieczny, S., Lagasquie-Schiex, M., Marquis, P.:
On the merging of Dung’s argumentation systems. Artif. Intell. 171(10–15), 730–
753 (2007)

Extension-Based Semantics for Incomplete Argumentation Frameworks
341
13. Dimopoulos, Y., Mailly, J.G., Moraitis, P.: Control argumentation frameworks.
In: 32nd AAAI Conference on Artiﬁcial Intelligence (AAAI 2018), pp. 4678–4685
(2018)
14. Dung, P.M.: On the acceptability of arguments and its fundamental role in non-
monotonic reasoning, logic programming and n-person games. Artif. Intell. 77(2),
321–358 (1995)
15. Dunne, P.E., Hunter, A., McBurney, P., Parsons, S., Wooldridge, M.J.: Weighted
argument systems: basic deﬁnitions, algorithms, and complexity results. Artif.
Intell. 175(2), 457–486 (2011)
16. Dvor´ak, W., Dunne, P.E.: Computational problems in formal argumentation and
their complexity. In: Baroni, P., Gabbay, D., Giacomin, M., van der Torre, L. (eds.)
Handbook of Formal Argumentation, pp. 631–688. College Publications (2018)
17. Egly, U., Woltran, S.: Reasoning in argumentation frameworks using quanti-
ﬁed boolean formulas. In: Computational Models of Argument: Proceedings of
COMMA 2006, 11–12 September 2006, Liverpool, UK, vol. 144, pp. 133–144 (2006)
18. Fazzinga, B., Flesca, S., Furfaro, F.: Revisiting the notion of extension over incom-
plete abstract argumentation frameworks. In: 29th International Joint Conference
on Artiﬁcial Intelligence (IJCAI 2020), pp. 1712–1718 (2020)
19. Hunter, A.: Some foundations for probabilistic abstract argumentation. In: Ver-
heij, B., Szeider, S., Woltran, S. (eds.) Computational Models of Argument - Pro-
ceedings of COMMA 2012, Vienna, Austria, 10–12 September 2012. Frontiers in
Artiﬁcial Intelligence and Applications, vol. 245, pp. 117–128. IOS Press (2012)
20. Lagniez, J.M., Lonca, E., Mailly, J.G.: CoQuiAAS: a constraint-based quick
abstract argumentation solver. In: 27th IEEE International Conference on Tools
with Artiﬁcial Intelligence, ICTAI 2015, Vietri sul Mare, Italy, 9–11 November
2015, pp. 928–935. IEEE Computer Society (2015)
21. Lawrence, J., Reed, C.: Argument mining: a survey. Comput. Linguist. 45(4), 765–
818 (2019)
22. Li, H., Oren, N., Norman, T.J.: Probabilistic argumentation frameworks. In: Pro-
ceedings of the First International Workshop on Theory and Applications of Formal
Argumentation (TAFA 2011), pp. 1–16 (2011)
23. Mailly, J.G.: Possible controllability of control argumentation frameworks. In: 8th
International Conference on Computational Models of Argument (COMMA 2020),
pp. 283–294 (2020)
24. Niskanen, A., J¨arvisalo, M.: μ-toksia: an eﬃcient abstract argumentation reasoner.
In: Calvanese, D., Erdem, E., Thielscher, M. (eds.) Proceedings of the 17th Inter-
national Conference on Principles of Knowledge Representation and Reasoning,
KR 2020, Rhodes, Greece, 12–18 September 2020, pp. 800–804 (2020)
25. Niskanen, A., Neugebauer, D., J¨arvisalo, M.: Controllability of control argumen-
tation frameworks. In: Proceedings of the Twenty-Ninth International Joint Con-
ference on Artiﬁcial Intelligence, IJCAI 2020, pp. 1855–1861 (2020)
26. Rossit, J., Mailly, J.G., Dimopoulos, Y., Moraitis, P.: United we stand: accruals in
strength-based argumentation. Argument Comput. 12(1), 87–113 (2021)

Relevant Epistemic Logic with Public
Announcements and Common Knowledge
V´ıt Punˇcoch´aˇr and Igor Sedl´ar(B)
Institute of Computer Science, Czech Academy of Sciences,
Prague, Czech Republic
vit.puncochar@centrum.cz, sedlar@cs.cas.cz
Abstract. Building on our previous work in non-classical dynamic epis-
temic logic, we add common knowledge operators to a version of public
announcement logic based on the relevant logic R. We prove a complete-
ness result with respect to a relational semantics, and we show that an
alternative semantics based on information states is dual to the rela-
tional one. We add a question-forming inquisitive disjunction operator
to the language and prove a completeness result with respect to the infor-
mation semantics. It is argued that relevant public announcements are
particularly suitable for modelling public argumentation.
1
Introduction
Various problematic closure properties of epistemic operators in classical epis-
temic logic led to the exploration of a number of alternatives to the classical
framework; see [9]. One approach to avoiding closure under classical consequence
is to represent epistemic states of agents as sets of abstract situations, roughly
in the sense of Barwise and Perry [2], instead of representing them as sets of
possible worlds. This approach leads naturally to epistemic logics based on para-
consistent and substructural propositional logics; see [3,10,19,21,22] for exam-
ple. Combining these logics with an account of information dynamics is a topic
of recent interest: [1,11] explore versions of intuitionistic public announcement
logic, [18,20] study paraconsistent bilattice public announcement logic, and [4]
outlines a fuzzy version of public announcement logic. Authors of the present
paper explored versions of public announcement logic based on relevant and
substructural logics in [14] and [25]. The latter paper focuses on modelling epis-
temic updates in the standard relational semantics for relevant modal logic and
the former paper used a more general information-state semantics. All papers
mentioned so far use languages without common knowledge, a concept linked to
information dynamics in a number of important ways.
The aim of this paper is to (i) extend the frameworks presented in [14] and
[25] with common knowledge and provide a complete axiomatization, and (ii)
explore the relationship between these frameworks. In Sect. 2 we add common
knowledge to the relational semantics introduced in [25]. We argue that the
notion of update embodied in the semantics has a natural link to the notion of
c
⃝Springer Nature Switzerland AG 2021
P. Baroni et al. (Eds.): CLAR 2021, LNAI 13040, pp. 342–361, 2021.
https://doi.org/10.1007/978-3-030-89391-0_19

Relevant Epistemic Logic with Public Announcements
343
public argumentation. In Sect. 3 we prove a completeness result for the relational
semantics. Then, in Sect. 4, we introduce an informational semantics following
the approach of [14]. The main result here is that informational and relational
models are dual, implying that the sound and complete axiomatization of Sect. 3
is sound and complete with respect to information models as well. In Sect. 5 we
add questions to our object language in the style of inquisitive semantics [7] and
show that the completeness proof of Sect. 3 can be extended to completeness of
this enriched language with respect to informational semantics.
2
Relational Semantics
Deﬁnition 1. Fix a countable set of propositional variables Pr and a ﬁnite set
of agent indices G. The language L contains operators t (zero-ary), ∧, →, ⊗, [ ]
(binary), ¬ and Ba, CA for all a ∈G and non-empty A ⊆G (unary). The set of
formulas of L, denoted as FmL, is generated by Pr using the operators of L in
the usual way.
We deﬁne ϕ ↔ψ := (ϕ →ψ) ∧(ψ →ϕ), ϕ ∨ψ := ¬(¬ϕ ∧¬ψ), BAϕ :=

a∈A Baϕ, B+
Aϕ := BACAϕ, and Kaϕ := C{a}ϕ. Operators t, ¬, ∧, ⊗, →are
propositional, all Ba and CA are epistemic operators and [ ] is the dynamic
operator. We use r to range over propositional operators, ri over i-ary proposi-
tional operators and r>0 over propositional operators of non-zero arity.
We read “Baϕ” as “Agent a believes that ϕ”, although what we mean is,
more generally, that a has information that supports (or allows a to conclude
that) ϕ. BAϕ means that all agents in the group A ⊆G believe that ϕ. We
read “CAϕ” as “ϕ is common knowledge in the group of agents A”. Kaϕ is read
“Agent a knows that ϕ” and B+
Aϕ as “it is common belief in group A that ϕ”.
Our choice of primitive epistemic operators may seem a bit odd, but it can be
shown that belief, knowledge, common belief and common knowledge interact in
expected ways. In particular, B+
Aϕ holds in s iﬀBAϕ holds in s, BABAϕ holds
in s, and so on, which corresponds to the usual semantics of common belief. Ka
is an “S4-type” knowledge operator, that is, Kaϕ →ϕ and Kaϕ →KaKaϕ are
valid, as we will see below.
The dynamic operator [ ] expresses eﬀects of public announcement of a piece
of information: we read [ϕ]ψ as “ψ is the case after ϕ is publicly announced to all
agents”. Our notion of public announcement diﬀers somewhat from the notion
embodied in Public Announcement Logic [12,26]: we do not assume that the
announced piece of information is truthful, nor is it implied that the information
is accepted by the agents upon the announcement; we also allow the possibility
that the announcement may cause some agents to drop some of the previously
accepted information.1
1 We note that while “announcement” seem to us to best express the notion we have
in mind, we have hesitated because of its technical connotations. Another term
that may be used is “reception” – upon an announcement agents receive a piece of
information, but nothing is implied about the nature of the information nor about
what the agents make of it.

344
V. Punˇcoch´aˇr and I. Sedl´ar
A natural informal interpretation of such a general notion of public announce-
ment is in terms of public argumentation. Imagine a group of agents, engaged in
a public discussion. Public announcements can be seen as acts of putting forward
arguments for or against claims in the discussion. These arguments do not have
to be truthful and they do not have to be persuasive, meaning that the agents
do not always accept the arguments. Moreover, arguments can cause agents to
reject some of the information they accepted before. All of these features are
characteristic aspects of our general rendering of public announcement. We will
return to these aspects after introducing the semantics.
We note that our semantics extends the semantic framework of relevant logic
introduced by Routley and Meyer in the 1970s. Our axiomatization extends the
axiomatization of the relevant logic R, introduced by Anderson and Belnap in
the 1960s. We do not have the space to review relevant logic in detail. The reader
is referred to [8] or [17], for example.
Deﬁnition 2. A relevant epistemic model for G is M = (S, ⊑, L, R, C, E, V )
where (S, ⊑, L, R, C, V ) is a Routley–Meyer model for the relevant logic R, i.e.
– (S, ⊑) is a partially ordered set;
– L is an up-set in (S, ⊑);
– R is a ternary relation on (S, ⊑) that is anti-monotonic in the ﬁrst two coordi-
nates and monotonic in the third coordinate, and satisﬁes the following frame
conditions (we use the standard notation Rstuw := ∃x(Rstx & Rxuw) and
Rs(tu)w := ∃x(Rtux & Rsxw))
Rstuw =⇒Rs(tu)w
(1)
Rstuw =⇒Rt(su)w
(2)
Rstu =⇒Rsttu
(3)
Rstu =⇒Rtsu
(4)
– s ⊑t iﬀthere is x ∈L such that Rsxt;
– C is a symmetric binary relation on (S, ⊑) that is anti-monotonic in both
coordinates such that for all s there is a unique maximal element ¯s of the set
C(s) = {t | Cst} and
¯¯s = s
(5)
Rstu =⇒Rs¯u¯t
(6)
– V is a function from Pr to up-sets in (S, ⊑);
and E is a function from G to binary relations on (S, ⊑) that are anti-monotonic
in the ﬁrst coordinate and monotonic in the second coordinate.
Informally, E(a) represents the information about the epistemic state of a
provided by situations in the model as follows. For each s ∈S there is a body
of information, denote it as s(a), such that s provides information that s(a) is
the epistemic state of a (s(a) may be empty). E(a)st represents the assumption
that s(a) is contained in t. Hence, E(a)(s) = {t | E(a)st} can be seen as the
representation of s(a).

Relevant Epistemic Logic with Public Announcements
345
We deﬁne E(A) := 
a∈A E(a) and E∗(A) as the reﬂexive transitive closure
of (⊑∪E(A)).2 E+(A) is the transitive closure of E(A). We will usually write
the agent (group) indices in a subscript.
Remark 1. We note that each relevant epistemic model is fully associative:
Rstuw ⇐⇒Rs(tu)w
(7)
The full associativity condition will be required in our completeness proof, in par-
ticular in the steps for [ϕ][ψ]χ. Without common knowledge in the language,
these cases are dealt with implicitly using the monotonicity rule R5; however, in
the present context they have to be dealt with explicitly. This means that our
present approach is limited to logics based on fully associative frames, for exam-
ple the R-based logics we focus on here. An extension of our results to weaker
logics is an open problem.
Deﬁnition 3. The satisfaction relation between pointed models (that is, pairs
of the form (M, s) where s is in M) and L-formulas is induced by V of M as
follows:
– (M, s) |= p iﬀs ∈V (p);
– (M, s) |= t iﬀs ∈L;
– (M, s) |= ¬ϕ iﬀ∀t, Cst implies (M, t) ̸|= ϕ;
– (M, s) |= ϕ ∧ψ iﬀ(M, s) |= ϕ and (M, s) |= ψ;
– (M, s) |= ϕ →ψ iﬀ, ∀tu, if Rstu and (M, t) |= ϕ, then (M, u) |= ψ;
– (M, s) |= ϕ ⊗ψ iﬀ∃tu such that Rtus and (M, t) |= ϕ and (M, u) |= ψ;
– (M, s) |= Baϕ iﬀ∀t, East only if (M, t) |= ϕ;
– (M, s) |= CAϕ iﬀ∀t, E∗
Ast only if (M, t) |= ψ;
– (M, s) |= [ϕ]ψ iﬀ(M[ϕ], s) |= ψ, where M[ϕ] diﬀers from M only in that
E[ϕ]
a
st iﬀthere are u, v such that Easu, Ruvt and (M, v) |= ϕ.
A formula ϕ is valid in M iﬀ(M, s) |= ϕ for all s ∈L. We deﬁne M(ϕ) := {s |
(M, s) |= ϕ}.
M [ϕ] is the model that results from M after the public announcement of ϕ.
Intuitively, M[ϕ] results from M by extending all situations in M with the infor-
mation that ϕ has been publicly announced. This transformation of the model
M does not aﬀect the “non-epistemic” structure consisting of the underlying
Routley–Meyer model, but it does aﬀect the epistemic accessibility relations
since, intuitively, s(a) for each s and a is modiﬁed by the announcement. Our
semantics reﬂects the idea that this modiﬁcation can be represented using the
ternary relation R. We take R to represent the eﬀects of “merging” situations:
Rstu iﬀthe result of “merging” the information in s with the information in t
2 Note that this notation is somewhat misleading as E∗(A) does not denote the reﬂex-
ive transitive closure of E(A).

346
V. Punˇcoch´aˇr and I. Sedl´ar
is contained in u. Crucially, “merging” is not necessarily monotonic.3 Merging
is lifted to sets of situations X, Y (representing arbitrary pieces of information)
using the standard construction
X ⊗Y = {u | ∃st(s ∈X & t ∈Y & Rstu} .
(8)
After the information that ϕ has been announced to a is added to s, the epis-
temic state s(a) is transformed into a new epistemic state s(a)[ϕ]. Intuitively,
announcing ϕ triggers a “merge” of the epistemic state of the given agent with
the information expressed by ϕ. Using (8), we obtain
E [ϕ]
a
(s) = Ea(s) ⊗M(ϕ) = {u | ∃tv(East & (M, v) |= ϕ & Rtvu} .
(9)
Hence, s(a)[ϕ] is contained in u iﬀu contains the result of merging s(a) with
the information that ϕ. This is exactly how M[ϕ] is deﬁned.
Proposition 1. Formulas of the following forms are not valid: 1. ¬ϕ →[ϕ]ψ;
2. [ϕ]Baϕ; 3. Baϕ →[ψ]Baϕ.
We leave the construction of counterexamples to the reader. The fact that
¬ϕ →[ϕ]ψ is not valid means that announcements are not necessarily truthful:
announcing a false formula does not lead to “explosion”. The failure of [ϕ]Baϕ
means that announced information is not necessarily accepted by agents. This
feature is related in spirit to well-known unsuccessful updates of classical public
announcement logic, but the mechanism underlying the feature is more general
than the so-called Moorean phenomena at work in the classical case. The failure
of Baϕ →[ψ]Baϕ shows that announcements in our setting are non-monotonic:
after an announcement of ψ, agents may abandon previously held beliefs. As
mentioned above, all three aspects are typical features of public argumentation.
Deﬁnition 4. For any M, ϕ and non-empty A ⊆G:
– an A-path in M is a ﬁnite sequence ⟨si | i < n⟩of situations in M, for some
n ≥0, such that for all j < n −1, either sj ⊑sj+1 or EAsjsj+1;
– an A[ϕ]-path in M is a ﬁnite sequence ⟨si | i < n⟩of situations in M, for
some n ≥0, such that for all j < n −1, either sj ⊑sj+1 or E[ϕ]
A sjsj+1.
A path (A-path or an A[ϕ]-path) is a path from s iﬀit is non empty and its ﬁrst
element is s; it is a path ending in t iﬀit is non-empty and its last element is t.
Note that (M, s) |= CAϕ iﬀ(M, t) |= ϕ for all t such that there is an A-path in
M starting with s and ending in t; similarly (M, s) |= [ψ]CAϕ iﬀ(M, t) |= [ψ]ϕ
for all t such that there is an A[ψ]-path in M starting with s and ending in t.
3 This reading is related to a number of interpretations of R popular in the relevant
logic literature. For instance, Dunn and Restall point out that “perhaps the best
reading [of Rstu] is to say that the combination of the pieces of information s and
t (not necessarily the union) is a piece of information in u” [8, p. 67]. Restall adds
that “a body of information warrants ϕ →ψ if and only if whenever you update
that information with new information which warrants ϕ, the resulting (perhaps
new) body of information warrants ψ” [17, p. 362] (notation adjusted).

Relevant Epistemic Logic with Public Announcements
347
3
A Relational Completeness Result
In this section we provide a complete axiomatization of the set of formulas valid
in all relevant epistemic models. The axiom system RPAC, shown in Fig. 1, is
a combination of the proof system for the relevant logic R, axioms and rules
specifying that Ba are regular and monotonic modalities, the usual axioms and
rules for the common knowledge operator, and the so-called reduction axioms
for the update operator.
The completeness proof will combine the method of “partial ﬁltration”, used
to prove completeness for versions of Propositional Dynamic Logic based on rel-
evant logics [23,24], the standard canonical model argument for R, and the com-
pleteness argument for Public Announcement Logic using reduction axioms. Our
proof follows the usual strategy of proving completeness for Public Announce-
ment Logic with common knowledge, but we use a diﬀerent notion of ﬁltration
(the “ﬁltrated model” is inﬁnite, only epistemic accessibility relations are deﬁned
in terms of a ﬁnite set of formulas) and our models are more general. We note
that, unlike in [23,24], our proof does not require the presence of “extensional
truth constants” ⊤, ⊥. (We will specify the reason for this in Remark 2 below).
(A1) An axiomatization of R
(A2) Baϕ ∧Baψ →Ba(ϕ ∧ψ)
(A3) CAϕ ↔(ϕ ∧BaCAϕ)
(A4) [ϕ]p ↔p
(A5) [ϕ]t ↔t
(A6) [ϕ]r>0(ψ1, . . . , ψn)
↔r>0 ([ϕ]ψ1, . . . ,[ϕ]ψn)
(A7) [ϕ]Baψ ↔Ba(ϕ →[ϕ]ψ)
(A8) [ϕ][ψ]χ ↔[ϕ ⊗[ϕ]ψ]χ
(R1) ϕ
ϕ →ψ
ψ
(R2) ϕ
ψ
ϕ ∧ψ
(R3)
ϕ →ψ
Baϕ →Baψ
(R4)
ϕ →ψ
CAϕ →CAψ
(R5)
ϕ →ψ
[χ]ϕ →[χ]ψ
(R6) ϕ →(ψ ∧BAϕ)
ϕ →CAψ
(R7) χ →BA(ϕ →χ)
χ →[ϕ]ψ
χ →[ϕ]CAψ
Fig. 1. The axiom system RPAC.
Lemma 1. All theorems of RPAC are valid in all relevant epistemic models.
Proof. We prove only the cases for A7 and R7 explicitly. First, (M, s) ̸|= [ϕ]Baψ
iﬀthere is t such that E[ϕ]
a
st and (M[ϕ], t) ̸|= ψ iﬀthere are t, u, v such that
Easu and Ruvt and (M, v) |= ϕ and (M, t) ̸|= [ϕ]ψ iﬀ(M, s) ̸|= Ba(ϕ →[ϕ]ψ).
Second, to show that R7 preserves validity, assume that M(χ) ⊆M(Ba(ϕ →
χ)) and M(χ) ⊆M([ϕ]ψ). Let (M, s) |= χ. To prove that (M, s) |= [ϕ]CAψ, we

348
V. Punˇcoch´aˇr and I. Sedl´ar
prove that for all A[ϕ]-paths from s ending in t, (M, t) |= [ϕ]ψ; using the second
assumption of the rule, this can be established by showing that (M, t) |= χ for
each such t. We show this by induction on the length of A[ϕ]-paths from s ending
in t. The base case s = t follows directly from our assumptions. Now assume
that we have a path (t1, . . . , tm, t) such that t1 = s and that (M, tm) |= χ. If
tm ⊑t, then we are done. If E[ϕ]
A tmt, then we reason as follows. (M, tm) |= χ
entails that (M, tm) |= BA(ϕ →χ) and E[ϕ]
A tmt entails that there are u, v such
that EAtmu, Ruvt and (M, v) |= ϕ. Hence, (M, t) |= χ.
⊓⊔
Deﬁnition 5. A set of formulas Γ is closed iﬀϕ ∈Γ implies ψ ∈Γ for all
subformulas ψ of ϕ, and
– CAϕ ∈Γ only if {BACAϕ, BAϕ} ⊆Γ;
– [ϕ]r>0(ψ1, . . . , ψn) ∈Γ only if {[ϕ]ψi | i ≤n} ⊆Γ;
– [ϕ]BAψ ∈Γ only if BA(ϕ →[ϕ]ψ) ∈Γ;
– [ϕ]CAψ ∈Γ only if [ϕ]BACAψ ∈Γ and [ϕ]ψ ∈Γ;
– [ϕ][ψ]χ ∈Γ only if [ϕ ⊗[ϕ]ψ]χ ∈Γ.
A set of formulas is a prime RPAC-theory iﬀit is closed under forming con-
junctions, closed under RPAC-provable implications, and satisﬁes the property
that if ϕ ∨ψ is in the set, then ϕ or ψ is in the set.
Deﬁnition 6. Let Φ be a ﬁnite closed set. The canonical model for Φ is a struc-
ture MΦ = (S, ⊑, L, R, C, E, V ) where
– S is the set of all prime RPAC-theories;
– ⊑is set inclusion;
– Γ ∈L iﬀΓ contains all theorems of L;
– RΓΔΣ iﬀ, for all ϕ →ψ ∈Γ, if ϕ ∈Δ, then ψ ∈Σ;
– CΓΔ iﬀ, for all ¬ϕ ∈Γ, ϕ ̸∈Δ;
– E(a)ΓΔ iﬀ, for all Baϕ ∈Φ ∩Γ, ϕ ∈Δ;
– V (p) = {Γ | p ∈Γ}.
We deﬁne F(a)ΓΔ iﬀ, ϕ ∈Δ for all Baϕ ∈Γ. The satisfaction relation is
deﬁned just as for epistemic models.
Note that the canonical epistemic accessibility relations E(a) are deﬁned
using Baϕ ∈Φ, not arbitrary Baϕ; the latter deﬁnes the auxiliary relations F(a).
As in epistemic models, EA denotes the union of E(a) for a ∈A. E∗(A) is the
reﬂexive transitive closure of the union of ⊆with E(A). Note that F(a) ⊆E(a)
for all a, but the converse inclusion does not hold.
The notation ⊢RPAC ϕ means that ϕ is a theorem of RPAC; we will use only
⊢ϕ in this paper. We call a pair of sets of formulas (Γ, Δ) independent iﬀthere
are no ﬁnite non-empty Γ ′ ⊆Γ and Δ′ ⊆Δ such that ⊢ Γ ′ → Δ′.
Lemma 2 (Pair Extension). If (Γ, Δ) is independent, then there is a prime
theory Σ ⊇Γ disjoint from Δ.

Relevant Epistemic Logic with Public Announcements
349
Proof. This is a corollary of the well-known fact that each non-overlapping ﬁlter-
ideal pair in a distributive lattice is extended by a non-overlapping prime ﬁlter-
ideal pair. This result is usually stated for non-empty ﬁlters and ideals. However,
if Γ is empty, then we can set Σ := ∅and if Γ is non-empty but Δ is empty,
then we set Σ := Fm. It is clear that both Fm and ∅are prime theories.
⊓⊔
Lemma 3. For all Φ, MΦ is a relevant epistemic model.
Deﬁnition 7. For all ﬁnite Φ, we deﬁne the following:
– If Γ is a prime theory not disjoint from Φ, then ΓΦ :=  (Γ ∩Φ);
– if X is a non-empty set of prime theories, then XΦ := 
Γ ∈X ΓΦ.
If Φ is clear from the context, then we write just Γ and X.
Note that X is well-deﬁned even for inﬁnite X since Φ is ﬁnite. Note also
that Γ ∈X implies X ∈Γ (since if the assumption holds then Γ →X is a
theorem and obviously Γ ∈Γ).
Remark 2. Formulas of the form ΓΦ and XΦ will be used in the proof of the
Truth Lemma, in the cases for CAϕ and [ϕ]CAψ. In that particular context,
each Γ we will need to “characterize” by ΓΦ will have a non-empty intersection
with Φ and each X considered will be non-empty. For this reason, we do not need
to account for empty conjunctions and disjunctions and so, unlike in [23,24], we
do not need the presence of the “extensional” truth constants ⊤and ⊥in the
language.
Deﬁnition 8 (Complexity). We deﬁne the following complexity function c :
Fm →N:
1. c(p) = 1 for all p ∈Pr;
2. c(t) = 1;
3. c(f(ϕ1, . . . , ϕn)) = (n
i=1 c(ϕi)) + 1 for all f ∈{¬, ∧, →, ⊗, Ba, CA};
4. c([ϕ]ψ) = (4 + c(ϕ)) · c(ψ).
The closure of Γ is the smallest closed superset of Γ.
It can be shown that the closure of any ﬁnite set is ﬁnite. Our deﬁnition of
the complexity function is virtually the same as the deﬁnition used in [26], for
example.
Lemma 4. For all ϕ, ψ and χ:
1. c(ϕ) > c(ψ) if ψ is a proper subformula of ϕ;
2. c([ϕ]r>0(ψ1, . . . , ψnψn)) > r>0([ϕ]ψ1, . . . , [ϕ]ψn);
3. c([ϕ]Baψ) > c(ϕ →[ϕ]ψ) + 1;
4. c([ϕ]CAψ) > c([ϕ]ψ);
5. c([ϕ][ψ]χ) > c([ϕ ⊗[ϕ]ψ]χ).

350
V. Punˇcoch´aˇr and I. Sedl´ar
Lemma 5 (Truth Lemma). For all M, all ﬁnite closed Φ, all formulas ϕ ∈Φ
and all prime theories Γ:
ϕ ∈Γ ⇐⇒(MΦ, Γ) |= ϕ .
(10)
Proof. Induction on c(ϕ). The base case is trivial. The rest of the cases are
established as follows. Our induction hypothesis is that (10) holds for all ϕ such
that c(ϕ) < c(θ) for some ﬁxed θ. We prove that (10) holds for θ. We reason by
cases.
The cases where the main connective of θ is r>0 are established as usual in
completeness proofs for R (these cases use the assumption that Φ is closed under
subformulas), and the case for θ = Baϕ is established as usual in modal logic.
If θ = CAϕ, then we reason as follows. To prove the left-to-right implication,
we will use the following facts:
(i) if CAϕ ∈Γ ∩Φ and EAΓΔ, then CAϕ ∈Δ; and
(ii) if CAϕ ∈Γ ∩Φ, then each A-path from Γ ends with Δ such that CAϕ ∈Δ.
Fact (i) is established as follows: If CAϕ ∈Φ, then BACAϕ ∈Φ and so BaCAϕ ∈
Φ for all a ∈A. If EAΓΔ, then EaΓΔ for some a ∈A. Hence, if CAϕ ∈Γ, then
BaCAϕ ∈Γ using A3 and R3. Hence, CAϕ ∈Δ by the deﬁnition of Ea and
properties of prime theories.
Fact (ii) is established by induction on the length of A-paths from Γ. The
base case of the one-element path is trivial: CAϕ ∈Γ by assumption and ϕ ∈Γ
by A3. Now assume that we have a path (Δ1, . . . , Δm, Δ) such that Δ1 = Γ
and that the claim holds for (Δ1, . . . , Δm). Then CAϕ ∈Δm. If Δm ⊆Δ, then
clearly CAϕ ∈Δ and so ϕ ∈Δ by A3. If EAΔmΔ, then CAϕ ∧ϕ ∈Δ by (i).
Now assume that CAϕ ∈Γ ∩Φ and E+
AΓΔ. The latter means that there is
an A-path from Γ ending with Δ. Hence, ϕ ∈Δ by (ii). Since Δ was arbitrary,
we obtain (M, Γ) |= CAϕ.
Conversely, let X be the set of Δ such that there is an A-path (Γ, . . . , Δ).
Assume that (M, Δ) |= ϕ for all Δ ∈X. By the induction hypothesis, ϕ ∈Δ for
all Δ ∈X. Since ϕ ∈Φ, Γ and indeed Δ for all Δ ∈X and X are deﬁned. (We
know that at least Γ ∈X.) We prove that
(iii) ⊢Γ →X;
(iv) ⊢X →ϕ;
(v) ⊢X →BAX.
Using R6, (iv) and (v) entail ⊢X →CAϕ, which together with (iii) gives
⊢Γ →CAϕ. Hence, CAϕ ∈Γ.
Claims (iii) and (iv) are obvious. Claim (v) is established as follows. If ̸⊢
X →BAX, then there are Δ ∈X and Θ such that Δ ∈Θ and BAX ̸∈Θ. Using
the Pair Extension Lemma, there is Σ such that FAΘΣ and X ̸∈Σ. But since
Δ ∈Θ, FAΘΣ implies that EAΔΣ. (FAΘΣ entails that EaΘΣ for some a ∈A.
Assume that Baχ ∈Δ ∩Φ. Then ⊢Δ →Baχ and so Baχ ∈Θ. This means that
χ ∈Σ.) Hence, Δ ∈X implies Σ ∈X, contradicting X ̸∈Σ.

Relevant Epistemic Logic with Public Announcements
351
Now we consider the case θ = [ϕ]ψ. We reason by cases, depending on the
form of ψ:
Case 1. θ = [ϕ]p. Then θ ∈Γ iﬀp ∈Γ (using A4) iﬀ(M, Γ) |= p (using
the induction hypothesis) iﬀ(M[ϕ], Γ) |= p (using the deﬁnition of M[ϕ]) iﬀ
(M, Γ) |= [ϕ]p (using the deﬁnition of |=).
Case 2. θ = [ϕ]r(ψ1, . . . , ψn). All sub-cases of this form are established using
the deﬁnition of a closed set (closure under subformulas), Lemma 4, and the
fact that update with ϕ does not modify the underlying Routley–Meyer model
(S, ⊑, L, R, C, V ), just the epistemic accessibility relations Ea.
Case 3. θ = [ϕ]Baψ. Then θ ∈Γ iﬀBa(ϕ →[ϕ]ψ) ∈Γ (using A7) iﬀ
(M, Γ) |= Ba(ϕ →[ϕ]ψ) (using the induction hypothesis, relying on the
deﬁnition of a closed set and item 3 of Lemma 4) iﬀfor all Σ, Σ′ and Δ,
EAΓΣ
&
RΣΣ′Δ and (M, Σ′) |= ϕ only if (M[ϕ], Δ) |= ψ (deﬁnition
of |=) iﬀ, for all Δ, E[ϕ]
A ΓΔ only if (M[ϕ], Δ) |= ψ (deﬁnition of E[ϕ]
A ) iﬀ
(M[ϕ], Γ) |= Baψ (deﬁnition of |=) iﬀ(M, Γ) |= [ϕ]Baψ (deﬁnition of |=).
Case 4. θ = [ϕ]CAψ. We will use the following two facts:
(vi) If [ϕ]CAψ ∈Φ ∩Γ and E[ϕ]
A ΓΔ, then [ϕ]CAψ ∈Δ and [ϕ]ψ ∈Δ; and
(vii) if [ϕ]CAψ ∈Φ ∩Γ, then each A[ϕ]-path from Γ ends with Δ such that
[ϕ]CAψ ∈Δ and [ϕ]ψ ∈Δ.
Fact (vi) is established as follows. If E[ϕ]
A ΓΔ, then there is a ∈A such that
E[ϕ]
a
ΓΔ, which means that there are Σ1, Σ2 such that EaΓΣ1, RΣ1Σ2Δ and
(M, Σ2) |= ϕ (note that E[ϕ]
a
is deﬁned using |=). Using the induction hypothesis
(ϕ is a subformula of θ), we get ϕ ∈Σ2. Now [ϕ]CAψ ∈Γ entails [ϕ]BaCAψ ∈
Γ and [ϕ]Baψ ∈Γ (using A3 and R5) and this entails Ba(ϕ →[ϕ]CAψ) ∈Γ
and Ba(ϕ →[ϕ]ψ) ∈Γ (using A7). It follows from the deﬁnition of a closed
set that {Ba(ϕ →[ϕ]CAψ), Ba(ϕ →[ϕ]ψ)} ⊆Φ, and so we can infer that
ϕ →[ϕ]CAψ ∈Σ1 and ϕ →[ϕ]ψ ∈Σ1, which also means that [ϕ]CAψ ∈Δ
and [ϕ]ψ ∈Δ.
Fact (vii) is established by induction on the length of A[ϕ]-paths from Γ.
The base case of a one-element path is trivial: [ϕ]CAψ is assumed to be in
Γ and [ϕ]ψ ∈Γ by A3. Now assume that (vii) holds for all A[ϕ]-paths of
length m, where 2 ≤m < n and take (Δ1, . . . , Δn), where Δ1 = Γ. We know
that CAϕ ∈Δn−1. If Δn ⊆Δn−1, then we are done. If E[ϕ]
A Δn−1Δn, then
[ϕ]CAϕ ∈Δn thanks to (vi).
Now assume that [ϕ]CAψ ∈Γ and that E[ϕ]
A ΓΔ. The latter means that
there is a A[ϕ]-path (Γ1, . . . , Γn) such that Γ1 = Γ and Γn = Δ. By (vii),
[ϕ]ψ ∈Δ. By the induction hypothesis, (M, Δ) |= [ϕ]ψ (see item 5 of Lemma
4) and so (M[ϕ], Δ) |= ψ. Since Δ was arbitrary, we obtain (M[ϕ], Γ) |= CAϕ.
This means that (M, Γ) |= [ϕ]CAψ.
Conversely, let X be the set of Δ such that there is an A[ϕ]-path (Γ, . . . , Δ).
Assume that (M, Γ) |= [ϕ]CAψ, which means that (M[ϕ], Δ) |= ψ for all
Δ ∈X. By the induction hypothesis, [ϕ]ψ ∈Δ for all Δ ∈X. Since [ϕ]ψ ∈Φ,

352
V. Punˇcoch´aˇr and I. Sedl´ar
Γ and indeed Δ for all Δ ∈X and X are deﬁned. (We know that at least
Γ ∈X.) We prove that
(viii) ⊢Γ →X;
(ix) ⊢X →[ϕ]ψ;
(x) ⊢X →BA(ϕ →X).
Using R7, (ix) and (x) entail that ⊢X →[ϕ]CAψ, which together with (viii)
entails ⊢Γ →[ϕ]CAψ. This means that [ϕ]CAψ ∈Γ.
Claim (viii) follows from Γ ∈X. Claim (ix) follows from the assumption that
[ϕ]ψ ∈ X. Claim (x) is established as follows. If ̸⊢X →BA(ϕ →X), then
there is Δ ∈X such that ̸⊢Δ →BA(ϕ →X). Hence, by the Pair Extension
Lemma, there is Θ such that Δ ∈Θ and BA(ϕ →X) ̸∈Θ. The latter means
that there is a ∈A and Σ such that FaΘΣ and ϕ →X ̸∈Σ. The latter here
means that there are Π, Ω such that RΣΠΩ, ϕ ∈Π and X ̸∈Ω. Using the
induction hypothesis, we obtain (M, Π) |= ϕ, and so E[ϕ]
A ΔΩ (since FAΘΣ and
Δ ∈Θ imply that EAΔΣ). Since Δ ∈X, it follows that Ω ∈X, contradicting
X ̸∈Ω.
Case 5. θ = [ϕ][ψ]χ. We will use the following fact:
(xi) For a ∈G and all formulas α, β: E [α][β]
a
= E [α⊗[α]β]
a
.
(xi) needs the assumption of full associativity (7):
E[α][β]
a
ΔΣ ⇐⇒∃Σ1Σ2(E[α]
a
ΔΣ1 & RΣ1Σ2Σ & (M[α], Σ2) |= β)
⇐⇒∃Θ1Θ2Σ2(EaΔΘ1 & RΘ1Θ2Σ2Σ &
(M, Θ2) |= α & (M, Σ2) |= [α]β)
⇐⇒∃Θ1Θ2Σ2(EaΔΘ1 & RΘ1(Θ2Σ2)Σ &
(M, Θ2) |= α & (M, Σ2) |= [α]β)
⇐⇒∃Θ1Θ3(EaΔΘ1 & RΘ1Θ3Σ & (M, Θ3) |= α ⊗[α]β)
⇐⇒E[α⊗[α]β]
a
ΔΣ
Now we reason as follows: θ ∈Γ iﬀ[ϕ⊗[ϕ]ψ]χ ∈Γ (using A8) iﬀ(M, Γ) |=
[ϕ ⊗[ϕ]ψ]χ (induction hypothesis, relying on item 6 of Lemma 4 and the
deﬁnition of a closed set) iﬀ(M[ϕ⊗[ϕ]ψ], Γ) |= χ iﬀ(M[ϕ][ψ], Γ) |= χ (since
M[ϕ⊗[ϕ]ψ] = M[ϕ][ψ] by (xi)) iﬀ(M, Γ) |= [ϕ][ψ]χ.
⊓⊔
Theorem 1. ϕ is a theorem of RPAC iﬀϕ is valid in all relevant epistemic
models.
Proof. Soundness follows from Lemma 1. Completeness is established using the
Pair Extension Lemma, the Truth Lemma and Lemma 3: If ϕ is not a theorem,
then neither is t →ϕ. Take Φ the closure of {t →ϕ} and consider MΦ, which is
a relevant epistemic model by Lemma 3. By the Pair Extension Lemma, there
is a Γ ∈L such that ϕ ̸∈Γ. By the Truth Lemma, ϕ is not valid in MΦ.
⊓⊔

Relevant Epistemic Logic with Public Announcements
353
4
Information Models
The semantics used in the previous sections builds on the framework introduced
in [25], which has been in this paper adjusted to the background logic R and
extended with common knowledge. Another approach to a public announcement
logic with a substructural basis was developed in [14]. It turns out that these two
approaches are closely related, which will be discussed in detail in this section.
The merit of the alternative perspective that we will now describe is that it will
allow us in the next section to enrich our logic with a further dimension that
forms a crucial ingredient of informational dynamics. In particular, this perspec-
tive will allow us to express in the object language not only statements but also
questions. For deﬁnition of the semantic models of this alternative framework
we will need the following notion of a situation.
Deﬁnition 9. Let (P, ≤) be a complete lattice, where for any X ⊆P,  X
denotes the join of X. An element s ∈P is called a situation in (P, ≤) iﬀit is
completely join-irreducible, i.e. iﬀfor every X ⊆P, s =  X only if s = x, for
some x ∈X. The set of situations in (P, ≤) will be denoted as Sit(P). For any
x ∈P, the set of situations below x, i.e. the set {s ∈Sit(P) | s ≤x}, will be
denoted as Sit(x).
Note that if meet distributes over arbitrary joins in a complete lattice (P, ≤)
then for every situation s ∈Sit(P) and every X ⊆P, if s ≤ X then s ≤x for
some x ∈X.
Deﬁnition 10. An information model for G is N = (P, ≤, 1, ·, C, σ, V ) such
that (a) ⟨P, ≤⟩is a complete lattice; (b) every state from P is identical to the
join of a set of situations, that is, for any x ∈P, x =  Sit(x); (c) 1 is an
identity with respect to the binary operation · on P, i.e. 1 · x = x; (d) ⊓(i.e. the
ﬁnite meet) and · distribute over arbitrary joins from both directions; (e) C is
symmetric binary relation on P, and Cx  Y iﬀthere is y ∈Y such that Cxy;
(f) σ is a map that assigns to each agent a ∈G a function σ(a) (we will often
write σa) from situations to states; (g) if s, t are situations such that s ≤t then
σa(s) ≤σa(t); (h) V (p) ∈S, for every atomic formula p.
P represents a set of information states, x ≤y expresses that the state x is an
informational reﬁnement of the state y (i.e. x is informationally stronger than
y), 1 is called a logical state, x · y is called fusion of the states x and y, Cxy says
that x is compatible with y, σ is called an information state map, V is a valuation
that assigns to every atomic formula an informational content, represented as a
state in P.
Note that distributivity of fusion over joins implies its monotonicity, i.e.
x1 ≤x2 and y1 ≤y2 only if x1 · y1 ≤x2 · y2. Moreover, there is the least element
0 in N that can be deﬁned as  ∅.
Deﬁnition 11. A relevant information model for G is an information model
N = (P, ≤, 1, ·, C, σ, V ) for G where (i) fusion is associative, commutative, and
x ≤x·x, (ii) for every situation s ∈Sit(P) there is a state x ∈P such that Cxy
if and only if s ≤y, (iii) for all states x, y, z ∈S, if Cx(y · z) then C(x · y)z.

354
V. Punˇcoch´aˇr and I. Sedl´ar
Let σ be an inquisitive state map, A ⊆G a set of agents, and s a situation.
We deﬁne σA(s) = 
a∈A σa(s). Moreover, we deﬁne:
σ∗
A(s) = {t ∈S | ∃t1, . . . , tn ∈Sit(S): t1 = s, ti+1 ≤σA(ti), tn = t }.
The support relation between pointed relevant information models and for-
mulas from L is deﬁned as follows:
– (N, x) ⊩p iﬀx ≤V (p);
– (N, x) ⊩t iﬀx ≤1;
– (N, x) ⊩¬ϕ iﬀ, ∀y, if Cxy, then (N, y) ⊮ϕ;
– (N, x) ⊩ϕ ∧ψ iﬀ(N, x) ⊩ϕ and (N, x) ⊩ψ;
– (N, x) ⊩ϕ →ψ iﬀ, ∀y, if (N, y) ⊩ϕ, then (N, x · y) ⊩ψ;
– (N, x) ⊩ϕ ⊗ψ iﬀ, ∃yz, (N, y) ⊩ϕ, (N, z) ⊩ψ, and x ≤y · z;
– (N, x) ⊩Baϕ iﬀ, for all s ∈Sit(x), (N, σa(s)) ⊩ϕ;
– (N, x) ⊩CAϕ iﬀ, for all s ∈Sit(x), (N, σ∗
A(s)) ⊩ϕ;
– (N, x) ⊩[ϕ]ψ iﬀ(N[ϕ], x) ⊩ψ, where N[ϕ] diﬀers from N only in that
σ[ϕ]
a
(s) = {σa(s) · y | (N, y) ⊩ϕ}.
A formula ϕ is valid in a relevant information model N if (N, 1) ⊩ϕ. Note that
since 1 is an identity for fusion an implication ϕ →ψ is valid in N iﬀψ is
supported by all states of N that support ϕ.
Lemma 6. For any relevant information model N and any formula ϕ from L,
there is a state infoN(ϕ) in N such that N, x ⊩ϕ iﬀx ≤infoN(ϕ).
Proof. The claim follows from the fact that for any ϕ from L the set of states
supporting ϕ contains 0, is downward closed and closed under . This can be
shown by induction on ϕ. We will consider only the inductive steps for modal
operators. The inductive steps for ¬, ∧, →are discussed in [15]. Support by
0 and downward persistence for the operators Ba, CA, [ϕ] is straightforward.
Let us prove that the set of states supporting Baϕ is closed under . Assume
(N, xi) ⊩Baϕ, for each i ∈I. Take any s ∈Sit(
i∈I xi). Since s is a situation,
we obtain s ∈Sit(xi), for some i ∈I. It follows that (N, σa(s)) ⊩ϕ. Hence
(N, 
i∈I xi) ⊩Baϕ. The inductive step for CA is analogous and the step for
[ϕ] is straightforward.
⊓⊔
The state infoN(ϕ), the existence of which is guaranteed by the previous lemma,
represents the informational content of the formula ϕ in N. (If no confusion arises
the superscript will be omitted.) Its existence allows us to characterize update
of states in the following simpliﬁed way.
Lemma 7. σ[ϕ]
a
(s) = σa(s) · info(ϕ).
The semantics based on relevant information models is closely related to the
semantics based on relevant epistemic models. In order to spell out the exact
connection we will use the notion of duality of two semantic frameworks intro-
duced in [15]. Let S1 and S2 be two semantic frameworks based respectively on

Relevant Epistemic Logic with Public Announcements
355
some classes of models C1 and C2 and equipped with semantic clauses deter-
mining which formulas are valid in which models. We say that models M ∈C1
and N ∈C2 are L-equivalent if they validate exactly the same formulas from
L. We say that the semantic system S2 is a dual counterpart of S1 w.r.t. the
language L if there are two maps f : C1 →C2 and g : C2 →C1 such that (a)
every M ∈C1 is L-equivalent to f(M), and (b) for every M ∈C1 and N ∈C2
it holds that g(f(M)) is isomorphic to M and f(g(N)) is isomorphic to N.
The main goal of this section is to show that the semantics based on rele-
vant information models is a dual counterpart of the semantics based on rele-
vant epistemic models. (As already pointed out, the added value of this dual
counterpart is that it will allow us to capture not only statements but also ques-
tions.) This result extends the results from [15] that established similar duality
between information models and Routley–Meyer models for a basic propositional
language involving only the operators {∧, →, ¬}.
We will now describe an operation that transforms relevant epistemic models
into relevant information models. We will use the following notation: Let (S, ⊑)
be a partial order and s ∈S. Then UpS denotes the set of all up-sets of S, and
s↑denotes the set {t ∈S | s ⊑t}. Note that the sets of the form s↑are exactly
the situations in the complete lattice (UpS, ⊆).
Deﬁnition 12. Let M = (S, ⊑, L, R, C, E, V ) be a relevant epistemic model.
We deﬁne a corresponding structure Mi = (P i, ≤i, 1i, ·i, Ci, σi, V i), where P i =
UpS; ≤i=⊆; 1i = L; x ·i y = {s ∈S | ∃t ∈x, u ∈y such that Rtus}; Cixy iﬀ
there are s ∈x and t ∈y such that Cst; σi
a(s↑) = Ea(s); V i = V .
Lemma 8. If M is a relevant epistemic model then Mi is a relevant information
model.
Theorem 2. Mi is L-equivalent to M, for every relevant epistemic model M.
Proof. Let M = (S, ⊑, L, R, C, E, V ) be a relevant epistemic model, and Mi =
(P i, ≤i, 1i, ·i, Ci, σi, V i) the corresponding relevant information model. We have
to show that for any θ from L, (Mi, L) ⊩θ iﬀfor all s ∈L, (M, s) |= θ. We
prove something more general:
(*) For any X ∈UpS, (Mi, X) ⊩θ iﬀ, for all s ∈X, (M, s) |= θ.
This can be proved by induction on θ. We will go only through the inductive
steps for the operators Ba, CA, and [ϕ]. Take any X ∈UpS. As the induction
hypothesis, assume that the claim (*) holds for some given formulas ϕ, ψ.
Assume that θ = Baϕ. Then it holds: (Mi, X) ⊩Baϕ iﬀ, for all s ∈X,
(Mi, σi
a(s↑)) ⊩ϕ iﬀ, for all s ∈X, (Mi, Ea(s)) ⊩ϕ iﬀ(by induction hypothesis),
for all s ∈X and for all t ∈Ea(s), (M, t) |= ϕ iﬀ, for all s ∈X, (M, s) |= Baϕ.
Assume that θ = CAϕ. It holds that (σi
A)∗(s↑) = E∗
A(s) so we can proceed
in the same way as in the case of Baϕ.
Finally assume that θ = [ϕ]ψ. It can be shown that (Mi)[ϕ] = (M[ϕ])i.
So, we can proceed as follows: (Mi, X) ⊩[ϕ]ψ iﬀ((Mi)[ϕ], X) ⊩ψ iﬀ
((M[ϕ])i, X) ⊩ψ iﬀ, for all s ∈X, (M[ϕ], s) |= ψ iﬀ, for all s ∈X,
(M, s) |= [ϕ]ψ.

356
V. Punˇcoch´aˇr and I. Sedl´ar
Now we will deﬁne an inverse operation that transforms relevant information
models into relevant epistemic models.
Deﬁnition 13. Let N = (P, ≤, 1, ·, C, σ, V ) be a relevant information model.
We deﬁne a corresponding structure Ne = (Se, ⊑e, Le, Re, Ce, Ee, V e), where
Se = Sit(P); s ⊑e t iﬀt ≤s; Le = Sit(1); Restu iﬀu ≤s · t; Cest iﬀCst;
Ee
a(s) = Sit(σa(s)); V e(p) = Sit(V (p)).
Lemma 9. If N is a relevant information model then Ne is a relevant epistemic
model.
Lemma 10. Let M = (S, ⊑, L, R, C, E, V ) be a relevant epistemic model and let
Mie = (Sie, ⊑ie, Lie, Rie, Cie, Eie, V ie). Then the map assigning to any s ∈S the
set s↑is a bijection between S and Sie. Moreover, the following holds: (a) s ⊑t
iﬀs↑⊑ie t↑, (b) s ∈L iﬀs↑∈Lie, (c) Rstu iﬀRies↑t↑u↑, (d) Cst iﬀCies↑t↑,
(e) East iﬀEie
a s↑t↑, (f) s ∈V (p) iﬀs↑∈V ie(p).
Proof. For an illustration, we will just show how to prove (c) and (e). The proof
of (c) goes as follows: Ries↑t↑u↑iﬀu↑≤i s↑·i t↑iﬀu↑⊆s↑·i t↑iﬀu ∈s↑·i t↑iﬀ
∃v ∈s↑∃w ∈t↑: Rvwu iﬀRstu. (e) can be proved in the following way: East iﬀ
t ∈σi
a(s↑) iﬀt↑≤i σi
a(s↑) iﬀEie
a s↑t↑.
Lemma 11. Let N = (P, ≤, 1, ·, C, σ, V ) be a relevant information model and let
Nei = (P ei, ≤ei, 1ei, ·ei, Cei, σei, V ei). The map assigning to any x ∈P the set
Sit(x) is a bijection between P and P ei. Moreover, the following holds: (a) x ≤y
iﬀSit(x) ≤ei Sit(y), (b) Sit(1) = 1ei, (c) Sit(x · y) = Sit(x) ·ei Sit(y), (d) Cxy
iﬀCeiSit(x)Sit(y), (e) Sit(σa(s)) = σei
a (Sit(s)), (f) Sit(V (p)) = V ei(p).
Lemmas 10 and 11 lead directly to the following theorem.
Theorem 3. M is isomorphic to Mie, for every relevant epistemic model M,
and N is isomorphic to Nei, for every relevant information model N.
Theorems 3 and 2 together show that the the semantics based on relevant
information models is indeed a dual counterpart of the semantics based on rel-
evant epistemic models. As a consequence, RPAC is also complete with respect
to relevant information models.
5
Questions
In this section we will extend the language L so that it will be possible to express
not only statements but also questions. To this end, we will borrow some tech-
niques from inquisitive semantics (see, e.g., [5,7]). Let Linq denote the language
L enriched with a binary connective
⩾
called inquisitive disjunction. The oper-
ator
⩾
can be embedded arbitrarily under any operator with the exception of
the public announcement modality. We will assume that [ϕ]ν is in the language
Linq only if ϕ is a formula of the language L (but ν may contain inquisitive
disjunction).

Relevant Epistemic Logic with Public Announcements
357
The formulas of the language L will be called declarative. The connective
⩾
produces questions from declarative formulas. Given declarative formulas ϕ, ψ,
the formula ϕ
⩾
ψ expresses the question whether ϕ or ψ. This can be contrasted
with ϕ ∨ψ which expresses the statement that ϕ or ψ. (Recall that ϕ ∨ψ is
deﬁned as ¬(¬ϕ ∧¬ψ)). The support condition for this additional connective is
deﬁned as follows:
(N, x) ⊩ν
⩾
μ iﬀ(N, x) ⊩ν or (N, x) ⊩μ.
This captures the idea that an information state resolves a question if it provides
some answer to the question. Compare the clause to the support condition for
the declarative disjunction ∨spelled out in the following lemma.
Lemma 12. (N, x) ⊩ν ∨μ iﬀfor all s ∈Sit(x), (N, s) ⊩ν or (N, s) ⊩μ.
In the language Linq we can express directly, for example, that the agent’s infor-
mation state resolves the question ν (Baν), that the question is resolved by the
common knowledge in a group (CAν), or that ν would be resolved after the
public announcement of ϕ ([ϕ]ν).
It is obvious from the semantic clause for inquisitive disjunction that the set
of states supporting ν
⩾
μ is the union of the set of states supporting ν and
the set of states supporting μ. As a consequence, Lemma 6 cannot be formu-
lated for the whole language Linq. Sets of states supporting formulas of Linq are
not in general closed under join, though they are always downward closed and
nonempty (contain always the least element).
Let InqRPAC be the logic consisting of all formulas from the language Linq
that are valid in all relevant information models. In formulation of an axiomatic
system for InqRPAC we have to be careful to specify which schemata of RPAC
are semantically valid for the whole language Linq and which must be restricted
to the declarative language L. In particular, we can take the axiomatization of
RPAC as speciﬁed in Fig. 1 and assume that we can substitute any formulas of
Linq for the variables in the axiom and rule schemata, with the exception of the
variables occurring in the scope of the public announcement modality and in the
double negation axiom (which is among the axioms of R), the reduction axiom
for the belief modality (A7), and the rules (R6) and (R7). That is, the exception
concerns the public announcement modality and the following axioms and rules:
(DN) ¬¬ϕ →ϕ
(A7) [ϕ]Baψ ↔Ba(ϕ →[ϕ]ψ)
(R6) ν →(ϕ ∧BAν)
ν →CAϕ
(R7) ν →BA(ϕ →ν)
ν →[ϕ]ψ
ν →[ϕ]CAψ
To secure soundness we must assume that only declarative formulas can be
substituted for ϕ and ψ in these four schemata (but any formula of Linq can be
substituted for ν). Let us illustrate the reason behind this restriction on the rule
R6. Assume that ν →(ϕ ∧BAν) is valid in a relevant information model N and
assume that N, x ⊩ν. Then N, x ⊩ϕ∧BAν. Let s ∈Sit(x). Then ϕ is supported
by every state in {t ∈P | ∃t1, . . . , tn ∈Sit(P): t1 = s, ti+1 ≤σA(ti), tn = t }.

358
V. Punˇcoch´aˇr and I. Sedl´ar
Since we assume that ϕ is in L, it is supported also by the join of this set, i.e. by
σ∗
A(s). Since this holds for every s ∈Sit(x), we obtain N, x ⊩CAϕ as desired.
Hence, ν →CAϕ is valid in N.
The system for InqRPAC consists of the system for RPAC, adjusted to the
language Linq in the just described way, and extended with the axioms in Fig. 2
that characterize inquisitive disjunction. Note that while ν, μ, θ range over arbi-
trary formulas of Linq, ϕ (in the axioms Inq7 and Inq10) is again restricted to
formulas of L. The axioms Inq1-Inq3 are the standard (introduction and elim-
ination) axioms for disjunction. The axioms Inq4-Inq10 specify how the other
operators of the language distribute over inquisitive disjunction. Note that the
inverse implications of Inq4-Inq10 are provable from the other axioms.
(Inq1) ν →ν
μ
(Inq2) μ →ν
μ
(Inq3) ((ν →θ) ∧(μ →θ)) →((ν
μ) →θ)
(Inq4) ¬(ν
μ) →(¬ν ∧¬μ)
(Inq5) (θ ∧(ν
μ)) →((θ ∧ν)
(θ ∧μ))
(Inq6) (θ ⊗(ν
μ)) →((θ ⊗ν)
(θ ⊗μ))
(Inq7) (ϕ →(ν
μ)) →((ϕ →ν)
(ϕ →μ)) (for declarative ϕ)
(Inq8) Ba(ν
μ) →(Baν ∨Baμ)
(Inq9) CA(ν
μ) →(CAν ∨CAμ)
(Inq10) [ϕ](ν
μ) →([ϕ]ν
[ϕ]μ) (for declarative ϕ)
Fig. 2. The axioms for inquisitive disjunction in the system for InqRPAC.
Lemma 13. The system for InqRPAC is sound with respect to all relevant infor-
mation models.
We can prove completeness of the system InqRPAC using a strategy that is
common in inquisitive logic (see, e.g., [15]). In our speciﬁc setting this strategy
amounts to the reduction of completeness for InqRPAC to completeness for RPAC
(which was proved in Sect. 3). Such a reduction is possible due to two character-
istic properties of the logic that need to be proved: (1) disjunctive normal form,
and (2) disjunction property.
Lemma 14. For any formula ν of Linq there are formulas ϕ1, . . . , ϕn of L such
that ν ↔(ϕ1
⩾
. . .
⩾
ϕn) is a theorem of InqRPAC.
Proof. This is a straightforward extension of a standard theorem in inquisitive
logic. (For more details, see, e.g., [13].) One can proceed by induction on the
complexity of ν using the distributive axioms Inq4-Inq10 and their converses.
Lemma 15. Let ν, μ be formulas of Linq. Then ν
⩾
μ is valid in every relevant
information model only if ν is valid in every relevant information model or μ is
valid in every relevant information model.

Relevant Epistemic Logic with Public Announcements
359
Proof. To prove this claim, we will adapt to our current setting a technique devel-
oped in [13]. For any relevant information models N1 = (P1, ≤1, 11, ·1, C1, σ1, V1)
and N2 = (P2, ≤2, 12, ·2, C2, σ2, V2) we can deﬁne their product N1 × N2 =
(P, ≤, 1, ·, C, σ, V ) where P
= P1 × P2 (the Cartesian product of P1 and
P2); (x, y) ≤(v, w) iﬀx ≤1 v and y ≤2 w; 1 = (11, 12); (x, y) · (v, w) =
(x ·1 v, y ·2 w); C(x, y)(v, w) iﬀC1xv or C2yw; σa((s, t)) = (σ1(a)(s), σ2(a)(t));
V (p) = (V1(p), V2(p)). It can be shown that N1 ×N2 is again a relevant informa-
tion model. Assume that 01 is the least element of N1 and 02 is the least element
of N2. The following holds for any formula ν of Linq:
(a) (N1 × N2, (x, 02)) ⊩ν iﬀ(N1, x) ⊩ν,
(b) (N1 × N2, (01, y)) ⊩ν iﬀ(N2, y) ⊩ν.
These claims can be proved by induction on the complexity of ν. For an illustra-
tion, let us consider the inductive step for [ϕ]. Assume that (a) and (b) hold for
some ϕ from L and μ from Linq. Using the induction hypothesis it can be shown
that (N1 × N2)[ϕ] = N[ϕ]
1
× N[ϕ]
2
. Using this fact we can prove the inductive
step for [ϕ] as follows: (N1 × N2, (x, 02)) ⊩[ϕ]μ iﬀ((N1 × N2)[ϕ], (x, 02)) ⊩μ
iﬀ(N[ϕ]
1
× N[ϕ]
2
, (x, 02)) ⊩μ iﬀ(N[ϕ]
1
, x) ⊩μ iﬀ(N1, x) ⊩[ϕ]μ. The step for
(b) is analogous.
Assuming that we have proved (a) and (b) we can prove disjunction prop-
erty as follows. Assume that there is a relevant information model N1 in
which ν is not valid, and a relevant information model N2 in which μ is
not valid. Then (N1, 11) ⊮ν and (N2, 12) ⊮μ. If follows from (a) and (b)
that (N1 × N2, (11, 02)) ⊮ν and (N1 × N2, (01, 12)) ⊮μ. By persistence,
(N1 × N2, (11, 12)) ⊮ν
⩾
μ and thus ν
⩾
μ is not valid in N1 × N2.
Theorem 4. ν is a theorem of InqRPAC iﬀν is valid in all relevant information
models.
Proof. The left-to-right direction amounts to Lemma 13. For the right-to-left
direction assume that ν is valid in all relevant information models. Then, by
disjunctive normal form (Lemma 14), there are ϕ1, . . . , ϕn in L such that ν ↔
(ϕ1
⩾
. . .
⩾
ϕn) is a theorem of InqRPAC. By soundness (Lemma 13), ϕ1
⩾
. . .
⩾
ϕn is
valid in all relevant information models. By disjunction property (Lemma 15), for
some i, ϕi is valid in all relevant information models. By duality between relevant
information models and relevant epistemic models for L (Theorems 3 and 2) we
obtain that ϕi is valid in every relevant epistemic model. By completeness of
RPAC w.r.t. relevant epistemic models (Theorem 1), ϕi is a theorem of RPAC.
Since InqRPAC is an extension of RPAC, ϕi is also a theorem of InqRPAC. It
follows that ϕ1
⩾
. . .
⩾
ϕn is a theorem of InqRPAC. Hence, ν is a theorem of
InqRPAC.
The semantics based on information models allows us to equip agents not
only with information states but also with issues.4 Then one can deﬁne also
4 In [6] issues were introduced in the context of standard inquisitive epistemic logic
based on classical logic. In [16] issues were introduced in the semantics of substruc-
tural inquisitive epistemic logic.

360
V. Punˇcoch´aˇr and I. Sedl´ar
a public utterance of questions and the inquisitive analogues of the modalities
Ba and CA.5 This would be an interesting further extension of the language
Linq. However, the methods employed in this paper cannot be directly applied
to this extension. The reason is that completeness for such a language cannot
be straightforwardly reduced to completeness of its non-inquisitive fragment,
which was possible in the case of the language Linq. The inquisitive analogue
of Ba was studied in the context of substructural inquisitive logics in [16]. The
investigation of the inquisitive analogue of CA is left for future research.
6
Conclusion
This paper can be seen as a further expansion of our previous work on modal and
inquisitive substructural logics [13–16,24,25]. In particular, we have extended
the relevant logic R with various epistemic operators and studied their interac-
tions. The main novelty of the paper is the incorporation of common knowledge
into this rich context. The main result of the paper is a completeness of R,
extended with a belief modality, public announcement and common knowledge,
with respect to a suitable relational semantics (Theorem 1). We also considered
an alternative semantics that allowed us to express also questions in the object
language and we presented a completeness proof also for this enriched language
(Theorem 4).
Acknowledgement. This work is supported by the Czech Science Foundation grant
number GJ18-19162Y. We thank three anonymous reviewers for their valuable com-
ments.
References
1. Balbiani, P., Galmiche, D.: About intuitionistic public announcement logic. In:
Beklemishev, L., Demri, S., M´at´e, A. (eds.) Proceedings of 11th International Con-
ference on Advances in Modal Logic (AiML 2016), pp. 97–116. College Publications
(2016)
2. Barwise, J., Perry, J.: Situations and Attitudes. MIT Press, Cambridge (1983)
3. B´ılkov´a, M., Majer, O., Peliˇs, M.: Epistemic logics for sceptical agents. J. Log.
Comput. 26(6), 1815–1841 (2016)
4. Cabrer, L., Rivieccio, U., Rodriguez, R.O.: Lukasiewicz public announcement logic.
In: Carvalho, J.P., Lesot, M.-J., Kaymak, U., Vieira, S., Bouchon-Meunier, B.,
Yager, R.R. (eds.) IPMU 2016. CCIS, vol. 611, pp. 108–122. Springer, Cham (2016).
https://doi.org/10.1007/978-3-319-40581-0 10
5. Ciardelli, I.: Questions in logic. Ph.D. thesis, University of Amsterdam (2016)
6. Ciardelli, I., Roelofsen, F.: Inquisitive dynamic epistemic logic. Synthese 192(6),
1643–1687 (2015)
5 The inquisitive analogue of Ba is a standard modality in inquisitive epistemic logic
usually denoted as Ea (see [6]). The inquisitive analogue of CA was introduced
semantically in [5] in the context of standard inquisitive epistemic logic without an
axiomatic characterization.

Relevant Epistemic Logic with Public Announcements
361
7. Ciardelli, I., Groenendijk, J., Roelofsen, F.: Inquisitive Semantics. Oxford Univer-
sity Press, Oxford (2019)
8. Dunn, J.M., Restall, G.: Relevance logic. In: Gabbay, D.M., Guenthner, F. (eds.)
Handbook of Philosophical Logic, 2nd edn., vol. 6, pp. 1–128. Kluwer (2002)
9. Fagin, R., Halpern, J.Y., Moses, Y., Vardi, M.Y.: Reasoning About Knowledge.
MIT Press, Cambridge (1995)
10. Levesque, H.: A logic of implicit and explicit belief. In: Proceedings of AAAI 1984,
pp. 198–202 (1984)
11. Ma, M., Palmigiano, A., Sadrzadeh, M.: Algebraic semantics and model complete-
ness for intuitionistic public announcement logic. Ann. Pure Appl. Log. 165(4),
963–995 (2014)
12. Plaza, J.: Logics of public communications. In: Emrich, M.L., Pfeifer, M.S.,
Hadzikadic, M., Ras, W.Z. (eds.) Proceedings of 4th International Symposium
on Methodologies for Intelligent Systems: Poster Session Program, pp. 201–216.
Oak Ridge National Laboratory (1989)
13. Punˇcoch´aˇr, V.: Substructural inquisitive logics. Rev. Symb. Log. 12, 296–330
(2019)
14. Punˇcoch´aˇr, V.: Inquisitive dynamic epistemic logic in a non-classical setting.
In: Martins, M.A., Sedl´ar, I. (eds.) DaLi 2020. LNCS, vol. 12569, pp. 205–221.
Springer, Cham (2020). https://doi.org/10.1007/978-3-030-65840-3 13
15. Punˇcoch´aˇr, V.: A relevant logic of questions. J. Philos. Log. 49(5), 905–939 (2020)
16. Punˇcoch´aˇr, V., Sedl´ar, I.: Epistemic extensions of substructural inquisitive logics.
J. Log. Comput. (2020). First Online
17. Restall, G.: Relevant and substructural logics. In: Hanbook of the History of Logic,
vol. 7, pp. 289–398. Elsevier (2006)
18. Rivieccio, U.: Bilattice public announcement logic. In: Gor´e, R., Kooi, B., Kurucz,
A. (eds.) Advances in Modal Logic 2014, pp. 459–477. College Publications (2014)
19. Routley, R., Routley, V.: The role of inconsistent and incomplete theories in the
logic of belief. Comm. Cogn. 8(2/4), 185–235 (1975)
20. Santos, Y.D.: A four-valued dynamic epistemic logic. J. Log. Lang. Inf. 29(4),
451–489 (2020)
21. Sedl´ar, I.: Substructural epistemic logics. J. Appl. Non-Classical Log. 25(3), 256–
285 (2015)
22. Sedl´ar, I.: Epistemic extensions of modal distributive substructural logics. J. Log.
Comput. 26(6), 1787–1813 (2016)
23. Sedl´ar, I.: A general completeness argument for propositional dynamic logic. In:
Advances in Modal Logic 2020, Short Papers, pp. 102–106 (2020)
24. Sedl´ar, I.: Relational semantics for propositional dynamic logics. Submitted
manuscript, June 2021
25. Sedl´ar, I., Tedder, A.: Situated epistemic updates. In: Proceedings of LORI-VIII
(2021, to appear)
26. van Ditmarsch, H., van der Hoek, W., Kooi, B.: Dynamic Epistemic Logic.
Springer, Heidelberg (2008). https://doi.org/10.1007/978-1-4020-5839-4

A Variant with the Variable-Sharing
Property of Brady’s 4-Valued Implicative
Expansion BN4 of Anderson and Belnap’s
Logic FDE
Gemma Robles(B)
Dpto. de Psicolog´ıa, Sociolog´ıa y Filosof´ıa, Universidad de Le´on,
Campus de Vegazana, s/n, 24071 Le´on, Spain
gemma.robles@unileon.es
http://grobv.unileon.es
Abstract. A logic L has the “variable-sharing property” (VSP) if in
all L-theorems of conditional form antecedent and consequent share at
least a propositional variable. Anderson and Belnap consider the VSP
as a necessary property any relevance logic has to fulﬁl. Now, among
relevance logicians, Brady’s logic BN4 is widely viewed as the adequate
implicative 4-valued logic. But BN4 does not have the VSP. The aim of
this paper is to deﬁne a variant of BN4 having, in addition to the VSP,
some properties that do not support its consideration as a mere artiﬁcial
construct.
Keywords: Relevant logics · 4-valued relevant logics · Two-valued
Belnap-Dunn semantics · Variable-sharing property · Brady’s 4-valued
logic BN4
1
Introduction
A logic L has the “variable-sharing property” (VSP) if in all L-theorems of the
form A →B, A and B share at least a propositional variable. Anderson and
Belnap consider the VSP as a necessary condition any relevance logic worthy of
the name has to fulﬁl (cf. [1]). On the other hand, Anderson and Belnap’s First
degree entailment logic, FDE, is the minimal logic in their De Morgan family of
relevant logics (cf. [1], §15.2). FDE is also known as Belnap and Dunn’s 4-valued
logic BD4 (our label). BD4 can be viewed as a 4-valued logic in which formulas
can be both true and false or neither true nor false, in addition to being true
and false (cf. [1,5,6,9,10]).
The question of expanding FDE with a full implicative connective poses
itself, since as the name of the logic suggests, formulas of the form A →B are
This work is supported by the Spanish Ministry of Science and Innovation under Grant
[PID2020-116502GB-I00]. We thank three referees of CLAR 2021 for their comments
and suggestions on a previous draft of this paper.
c
⃝Springer Nature Switzerland AG 2021
P. Baroni et al. (Eds.): CLAR 2021, LNAI 13040, pp. 362–376, 2021.
https://doi.org/10.1007/978-3-030-89391-0_20

A Variant with the VSP of Brady’s 4-Valued Implicative Expansion BN4
363
not considered in FDE if either A or B contains →(cf. [1], p. 158 where the
postulates of the system are given together with the note “the variables range
over truth-functions of variables”). Some full implicative expansions of FDE have
been given in the literature (cf. [7,13–15,17,18,21] and references in the last two
items), but there is still a lot of investigation to be done in the topic (cf. [17]).
Among the implicative expansions of FDE, Brady’s 4-valued logic BN4 (cf.
[7]) seems to be regarded as the adequate implicative 4-valued logic. In this
sense, Meyer et al. note: “BN4 is the correct logic for the 4-valued situation
where extra values are to be interpreted in the both and neither senses” (cf. [16],
p. 25). On his part, Slaney thinks that BN4 has the truth-functional implication
most naturally associated with FDE (cf. [24], p. 289). And, nevertheless, BN4
lacks the VSP (cf. [21]1), as it is the case with all the implicative expansions of
FDE proposed so far, to the best of our knowledge.
The aim of this paper is then to deﬁne a variant of BN4, the logic BN4VSP,
enjoying the variable-sharing property. It will be proved that, in addition to
the VSP, BN4VSP has other interesting properties such as paraconsistency and
paracompleteness. Moreover, BN4VSP has a natural conditional in a sense akin to
that deﬁned in [25] (cf. Deﬁnition 5 and Remark 4 below), and last but not least,
it fulﬁls all conditions required of implicative logics in the classical Polish logical
tradition except, of course, that of complying with the rule VEQ, A⇒B →A (cf.
Deﬁnition 9 below)2.
Before explaining the structure of the paper, let us note a last remark. It is
known that there are inﬁnitely many logics with the VSP (cf. [11]). Furthermore,
some many-valued logics with the VSP have been studied in the literature. For
example, the logic characterized by Belnap’s eigth-element matrix M0 (cf. [4]),
axiomatized in [8]; or the logic determined by Meyer’s six-element crystal lattice
CL, also axiomatized in [8]. But it does not seem possible to interpret in a
intuitive clear way the meaning of the logical values in these matrices. However,
the meaning of the four values in FDE (or BD4) and its expansions is crystalline.
The paper is organized as follows.
In Sect. 2, the matrix MBN4VSP, a variant of Brady’s matrix MBN4 is
deﬁned. Let L be the logic deﬁned by using the consequence relation associ-
ated with MBN4VSP: for any set of wﬀs Γ and wﬀA, Γ ⊨MBN4VSP A iﬀA is
assigned a designated value whenever Γ is assigned a designated value for any
MBN4VSP-interpretation (cf. Deﬁnition 1). It is proved that L has a natural
conditional and also that L (and so any logic included in it) has the variable-
sharing property. In Sect. 3, a Hilbert-type system equivalent to L is given. Let
us call this system BN4VSP. Of course, we could have used the methods in [2,3]
1 Actually, in [21] it is stated that BN4 has the “quasi relevance property” (QRP) The
QRP reads: if A →B is a theorem, then either A and B share at least a propositional
variable or both ¬A and B are theorems. But BN4 lacks the VSP: ¬(A →A) →
(B →B) is MBN4-valid.
2 Notice that the rule VEQ encloses an inﬁnity of paradoxes of relevance, the simplest
of which may be q →(p →p). Consequently, it cannot be a rule of a logic with the
VSP.

364
G. Robles
(resp., those in [18]), in order to deﬁne a Gentzen-type system (resp., a natural
deduction system) equivalent to L. Instead, we shall use two-valued Belnap-Dunn
semantics to formulate BN4VSP. But let us stress that the aim of this paper is
not to axiomatize MBN4VSP, but to highlight this matrix and the properties
the logic it determines enjoys when deﬁned from a Hilbert-style point of view.
No doubt, other properties of this logic can be emphasized when deﬁned as a
Gentzen-type system or a natural deduction one. Concerning the relative merits
of these three methods just mentioned, cf. [20], §6 and [18], §8. Anyway, the one
used here has been employed in other works by us (cf. [14,15,21]). As pointed
out in the referred papers, this method is based upon [7] as applied in said
papers. Thus, it will not be necessary to go to each detail in the soundness and
completeness proofs, and some of the general ideas or strategies in these proofs
will be referred to the items mentioned above. In Sect. 3, we prove some of the
proof-theoretical properties of BN4VSP, that is, some of the properties of the
logic determined by MBN4VSP when formulated as a Hilbert-type system. In
Sect. 4, we prove the (strong) soundness and completeness of BN4VSP w.r.t. the
two-valued Belnap-Dunn semantics deﬁned in Sect. 3. Finally, the paper is ended
in Sect. 5 with some concluding remarks on the results obtained and a couple of
suggestions on future work on the topic.
2
The Matrix MBN4VSP
In this section the matrix MBN4VSP is deﬁned.
MBN4VSP is an implicative expansion of Belnap and Dunn’s matrix FOUR
characterizing Anderson and Belnap’s First degree entailment logic, FDE (cf.
[1], §15.2, [5,6,9,10]). But MBN4VSP actually originates as a modiﬁcation of
Brady’s matrix MBN4, also an implicative expansion of FOUR (cf. [7]). It will
be proved that the implicative expansion of FDE, BN4VSP, enjoying the VSP is
determined by the matrix MBN4VSP.
Deﬁnition 1 (Preliminary notions). The propositional language consists of
a denumerable set of propositional variables p0, p1, ..., pn, ..., and the following
connectives: →(conditional), ∧(conjunction), ∨(disjunction) and ¬ (negation).
The biconditional and the set of wﬀs is deﬁned in the customary way. A, B, C,
etc. are metalinguistic variables. Then logics are formulated as Hilbert-type
axiomatic systems, the notions of ‘theorem’ and ‘proof from a set of premises’
being the usual ones, while the following notions are understood in a fairly stan-
dard sense (cf., e.g., [14,15,21]): extension and expansion of a given logic, logi-
cal matrix M and M-interpretation, M-consequence, M-validity and, ﬁnally, M-
determined logic.
Deﬁnition 2 (Belnap and Dunn’s matrix FOUR). The propositional lan-
guage consists of the connectives ∧, ∨and ¬. Belnap and Dunn’s matrix FOUR
is the structure (V, D, F) where (1) V is {0, 1, 2, 3} and is partially ordered as
shown in the following lattice:

A Variant with the VSP of Brady’s 4-Valued Implicative Expansion BN4
365
(2) D = {2, 3}; F = {f∧, f∨, f¬} where f∧and f∨are deﬁned as the glb
(or lattice meet) and the lub (or lattice joint), respectively. Finally, f¬ is an
involution with f¬(0) = 3, f¬(3) = 0, f¬(1) = 1, f¬(2) = 2 (cf. [5,6,9,10]). We
display the tables for ∧, ∨and ¬:
∧0 1 2 3
0 0 0 0 0
1 0 1 0 1
2 0 0 2 2
3 0 1 2 3
∨0 1 2 3
0 0 1 2 3
1 1 1 3 3
2 2 3 2 3
3 3 3 3 3
¬
0 3
1 1
2 2
3 0
Remark 1 (On the symbols for referring to the four truth-values). It is customary
to use f, n, b and t instead of 0, 1, 2 and 3, respectively (cf., e.g., [17]). The former
stand for false only, neither true or false, both true and false and true only,
respectively. The latter have been chosen in order to use the tester in [12], in
case one is needed. Also, to put in connection the results in the present paper
with previous work by us.
Deﬁnition 3 (Brady’s matrix MBN4). The propositional language consists
of the connectives →, ∧, ∨and ¬. The matrix MBN4 is the structure (V, D, F)
where (1) V and D are deﬁned as in FOUR and F = {f→, f∧, f∨, f¬} where
f∧and f∨and f¬ are deﬁned as in FOUR, and f→is deﬁned according to the
following truth-table (cf. [7]):
→0 1 2 3
0
3 3 3 3
1
1 3 1 3
2
0 1 2 3
3
0 1 0 3
Deﬁnition 4 (The matrix MBN4VSP). The matrix MBN4VSP is deﬁned
similarly as MBN4, except that the truth-table according to which →is inter-
preted in MBN4 is replaced by the following one:
→0 1 2 3
0
3 3 1 3
1
1 3 1 3
2
0 1 2 1
3
0 1 0 3

366
G. Robles
Remark 2 (The table for ↔). Below, the truth-table of the biconditional (↔) is
displayed since this connective plays a role more signiﬁcant in BN4VSP than in
most propositional logics (cf. Propositions 5 and 6 below).
↔0 1 2 3
0
3 1 0 0
1
1 3 1 1
2
0 1 2 0
3
0 1 0 3
Remark 3 (On the conditional table in MBN4V SP ). We note that the condition
0 →2 = 1 is not strictly necessary in order to prove the VSP. Nevertheless, if 0 →
2 = 3 is maintained, then the rule Contraposition (i.e., A →B ⇒¬B →¬A)
would not preserve MBN4VSP-validity (consider any MBN4VSP-interpretation I
such that for diﬀerent propositional variables p, q, we have I(p) = 0 and I(q) = 2.
Then, I(p →q) = 3, but I(¬q →¬p) = 1).
We remark that the conditional deﬁned by MBN4VSP is a natural conditional
in accordance with the following deﬁnition (cf. Deﬁnition 2.5 in [22]).
Deﬁnition 5 (Natural conditionals). Let V and D be deﬁned as in Deﬁnition
2. Then an f→-function on V
deﬁnes a natural conditional if the following
conditions are satisﬁed:
1. f→coincides with (the f→-function for) the classical conditional when
restricted to the subset {0, 3} of V.
2. f→satisﬁes Modus Ponens, that is, for any a, b ∈V, if a →b ∈D and a ∈D,
then b ∈D.
3. For any a, b ∈V, a →b ∈D if a = b.
Remark 4 (Natural conditionals in Tomova’s original paper). We note that nat-
ural conditionals are deﬁned in [25] exactly as in Deﬁnition 5 except for condi-
tion (3), which reads there as follows: For any a, b ∈V, a →b ∈D if a ≤b.
(Notice that the conditional deﬁned by Brady’s MBN4 is a natural conditional
in Tomova’s sense.)
In the following section, it is proved that the logic BN4VSP, shown MBN4VSP-
determined in Sect. 4, fulﬁls all conditions required of an implicative logic in the
classical Polish logical tradition (cf., e.g., [19] or [26]), except, of course, that
of complying with VEQ (cf. Sect. 1 above). For now, it is proved that BN4VSP
enjoys (an adapted to the matrix-determined logics version of) the variable-
sharing property (VSP).
Deﬁnition 6 (VSP for matrix-determined logics). Let L be a logic deter-
mined by the matrix M. L has the variable-sharing property (VSP) if A and B
share at least a propositional variable in all M-valid wﬀs of the form A →B.
Deﬁnition 7 (VSP standard deﬁnition). A logic L has the VSP if A and
B share at least a propositional variable in all L-theorems of the form A →B.

A Variant with the VSP of Brady’s 4-Valued Implicative Expansion BN4
367
Of course, once L has been shown M-determined via a soundness and com-
pleteness theorem, L has the VSP in the sense of Deﬁnition 6 iﬀL has the
VSP in the sense of Deﬁnition 7. Next, it is proved that the logic determined
by MBN4VSP we have referred to by BN4VSP has the VSP as this property is
rendered in Deﬁnition 6.
Proposition 1 (BN4VSP has the VSP). Let A →B be an MBN4VSP-valid
wﬀ. Then A and B share at least a propositional variable.
Proof. Suppose that A and B do not share propositional variables. It is proved
that A →B is not MBN4VSP-valid. Let I be an MBN4VSP-interpretation assign-
ing 2 (resp., 0) to each propositional variable in A (resp., B). Then, I(A) = 2 and
I(B) ∈{0, 3} since {2} and {0, 3} are closed under →, ∧, ∨and ¬. Consequently,
I(A →B) ∈{0, 1}.
3
The Logic BN4VSP
The logic BN4VSP, that is, the logic determined by the matrix MBN4VSP, can
be formulated in a Hilbert-style way as follows.
Deﬁnition 8 (The logic BN4VSP). The logic BN4VSP can be formulated with
the following axioms, rules of inference and metarule (A1,..., An ⇒B means ‘if
A1, ..., An, then B’)3:
Axioms:
A1. A →A
A2. (A ∧B) →(B ∧A)
A3. [A ∧(B ∧C)] →[(A ∧B) ∧C]
A4. [A ∧(B ∨C)] ↔[(A ∧B) ∨(A ∧C)]
A5. ¬(A ∨B) ↔(¬A ∧¬B)
A6. (A →¬B) →(B →¬A)
A7. ¬¬A →A
A8. (A ∨¬B) ∨(A →B)
A9. [(A ∧B) ∧(¬A ∧¬B)] →(A →B)
3 A referee of CLAR 2021 worries about many-valued extensions because of the pres-
ence of such formulas as A8. This is an interesting question we cannot discuss in
detail here. Let us only remark that the type of formulas the referee is concerned
about is not the only fault of many-valued extensions; actually, they do not seem
to collide with the VSP. For example, it is shown in “A general characterization of
the variable-sharing property by means of logical matrices” (G. Robles and J. M.
M´endez, Notre Dame Journal of Formal Logic, 53(2), 223–244, 2012) that relatively
strong logics with the VSP have Dummett’s axiom for the intermediate logic LC (i.e.,
(A →B) ∨(B →A)) as one of their theorems. The conclusion seems inescapable:
the VSP and the disjunction property are independent of each other.

368
G. Robles
Rules of inference:
R1 (Adj). A, B ⇒A ∧B
R2 (MP). A →B, A ⇒B
R3 (E ∧). A ∧B ⇒A, B
R4 (I ∨). A ⇒A ∨B, B ∨A
R5 (CI ∧). A →B, A →C ⇒A →(B ∧C)
R6 (Fac ↔). A ↔B ⇒(A ∧C) ↔(B ∧C)
R7 (Pref). B →C ⇒(A →B) →(A →C)
R8. ¬A ∧¬B ⇒(A ∨B) ∨(A →B)
R9. A ∧B ⇒(¬A ∨¬B) ∨(A →B)
R10. A →B, A ∧¬A ⇒¬B
R11. A →B, B ∧¬B ⇒¬A
R12. ¬(A →B) ⇒A ∧¬B
R13. A ∧¬B ⇒¬(A →B)
Metarule:
(MR). If A, B ⇒C, then D ∨A, D ∨B ⇒D ∨C
Remark 5 (On the axiomatization of BN4V SP ). CI∧, Fac↔and Pref abbreviate
“conditioned introduction of conjunction”, “factor w.r.t. ↔” and “Preﬁxing”,
respectively. The metarule MR can be dropped if a “disjunctive version” of
each rule is added. (The disjunctive version of, e.g., MP is the following rule:
C ∨(A →B), C ∨A ⇒C ∨B. On the role of disjunctive rules in certain logics,
cf. [8,23] and references therein.)
Remark 6 (On BN4V SP and the logic DW). Routley and Meyer’s basic logic
B is axiomatized as follows (cf. [23], Chapter 4). Axioms: (a1) A →A; (a2)
(A ∧B) →A, (A ∧B) →B; (a3) A →(A ∨B), B →(A ∨B); (a4) [(A →
B) ∧(A →C)] →[A →(B ∧C)]; (a5) [(A →C) ∧(B →C)] →[(A ∨B) →C];
(a6) [A ∧(B ∨C)] →[(A ∧B) ∨(A ∧C)]; (a7) A →¬¬A; (a8) ¬¬A →A. Rules
of inference: Adj; MP; Pref; Suﬃxing (Suf) A →B ⇒(B →C) →(A →C) and
contraposition (Con) A →B ⇒¬B →¬A. Then the logic DW is an important
weak relevant logic extending B, which is axiomatized when deleting A7 and
Con, while adding the axiom (a7′) (A →¬B) →(B →¬A) (cf. [23], Chapter 4).
Well then, consider now the logic DW′ axiomatized with A1-A7 and R1-R5,
Evee (T16), Pref and Suf. This is a sublogic of DW obtained by restricting a2,
a3, a4 and a5 to their respective rule form. Thus, BN4VSP can intuitively be
considered as a 4-valued extension of DW′ enjoying the “relevance principle”,
i.e., the VSP. Axioms A8 and A9 and R8-R13 are characteristic features of this
4-valued extension.
Remark 7 (The axiomatization of BN4). Brady’s BN4 can be axiomatized as a
4-valued extension of contractionless relevant logic RW. Given DW (cf. Remark

A Variant with the VSP of Brady’s 4-Valued Implicative Expansion BN4
369
6), RW can be axiomatized by deleting the rules Pref and Suf, while adding the
axioms (a8) (A →B) →[(B →C) →(A →B)], (a9) A →[(A →B) →B]
and the rule Disjunctive Modus Ponens (dMP), C ∨(A →B), C ∨A ⇒C ∨B.
Then, BN4 can be axiomatized by adding the following axioms to RW. (a10)
(¬A ∧B) →(A →B); (a11) ¬A →[A ∨(A →B)], (a12) (A ∨¬B) ∨(A →B)
and (a13) A ∨[¬(A →B) →A] (cf. [15,21]). So a10-a13 are the characteristic
axioms of BN4, a 4-valued extension of relevant logic RW, while BN4VSP is a
4-valued extension of the (weaker) relevant logic DW.
On the other hand, all axioms and rules of BN4VSP, except R10, are provable
in BN4, while a10, a11 and a13 of BN4 fail in BN4VSP, and a9 holds only as a
rule of inference.
In what follows, we prove some proof-theoretical properties of BN4VSP.
Proposition 2 (Some theorems and rules of BN4VSP). The following are
provable in BN4VSP:
T1. A ↔A
T2. (A ↔B) →(B ↔A)
T3 (Trans). A →B, B →C ⇒A →C
T4 (Trans ↔). A ↔B, B ↔C ⇒A ↔C
T5. A →¬¬A
T6. A ↔¬¬A
T7. (A →B) →(¬B →¬A)
T8. (¬A →¬B) →(B →A)
T9. (A →B) ↔(¬B →¬A)
T10. (¬A →B) →(¬B →¬A)
T11 (Con ↔). A ↔B ⇒¬B ↔¬A
T12 (Suf). A →B ⇒(B →C) →(A →C)
T13 (Pref ↔). A ↔B ⇒(C →A) ↔(C →B)
T14 (Suf ↔). A →B ⇒(B →C) ↔(A →C)
T15. (A ∨B) ↔¬(¬A ∧¬B)
T16 (E ∨). A →C, B →C ⇒(A ∨B) →C
T17 (Sum ↔). A ↔B ⇒(A ∨C) ↔(B ∨C)
T18. (A ∧B) ↔(B ∧A)
T19. [(A ∧B) ∧C] →[A ∧(B ∧C)]
T20. [(A ∧B) ∧C] ↔[A ∧(B ∧C)]
T21. (A ∨B) ↔(B ∨A)
T22. (A ∨A) →A
T23. A →(A ∧A)

370
G. Robles
T24 (Fac′ ↔). A ↔B ⇒(C ∧A) ↔(C ∧B)
T25 (Sum′ ↔). A ↔B ⇒(C ∨A) ↔(C ∨B)
Trans, Trans↔, Con↔, Suf, Pref↔, Suf↔and Sum↔abbreviate Transitiv-
ity, Transitivity w.r.t. ↔, Contraposition w.r.t. ↔, Suﬃxing, Preﬁxing w.r.t. ↔,
Suﬃxing w.r.t. ↔and Summation w.r.t. ↔, respectively. Fac′ ↔and Sum′ ↔
are alternative versions of Fac↔and Sum↔.
Proof. It is easy and it is left to the reader.
Proposition 3 (Replacement). For any wﬀs A, B, A ↔B ⇒C[A] ↔
C[A/B] where C[A] is a wﬀin which A appears and C[A/B] is the result of
substituting A by B in C[A] in one or more places where A occurs.
Proof. By induction on the structure of C[A] using Fac↔(R6), Trans↔(T4),
Con↔(T11), Pref↔(T13), Suf↔(T14), Sum↔(T17), Fac′ ↔(T24) and
Sum′ ↔(T25).
Proposition 4 (Additional theorems and rules of BN4VSP). The follow-
ing are provable in BN4VSP:
T26. (A ∧B) ↔¬(¬A ∨¬B)
T27. ¬(A ∧B) ↔(¬A ∨¬B)
T28. [A ∨(B ∨C)] ↔[(A ∨B) ∨C]
T29. [A ∨(B ∧C)] ↔[(A ∨B) ∧(A ∨C)]
T30 (Modus Tollens —MT). A →B, ¬B ⇒¬A
T31. A →B, B ∧¬B ⇒A
Proof. Easy by using Replacement (Proposition 3).
Proposition 5 (Arrangement in conjunctive and disjunctive wﬀs). Let
A be a wﬀof the form B1 ∧... ∧Bn (resp., B1 ∨... ∨Bn) where the n wﬀs are
arranged in a given way. And let A′ be the result of associating B1, ..., Bn in any
way whichever. Then, ⊢BN4VSP A ↔A′.
Proof. By Replacement and the commutative and associative properties of ∧
and ∨(T18, T20, T21 and T28).
Proposition 6 (Summation w.r.t. ⇒—Sum⇒). For any wﬀs A, B1, ..., Bn,
if B1, ..., Bn ⇒A, then C ∨B1, ..., C ∨Bn ⇒C ∨A.
Proof. By induction on the length of the proof B1, ..., Bn ⇒A. We remark that
in [15], §3, it is noted that the modest strength of FDE suﬃces to carry out
the proof of the Extension Lemma provided Proposition 6 is at our disposal.
Now, Proposition 6 does not follow if the facts in Proposition 5 have not been
proved previously. But said facts can be elusive in certain weak logics, hence our
interest in proving Replacement and the commutative and associative properties
of ∧(those of ∨are not necessary, although T22 certainly is (cf. [14,15,21]).

A Variant with the VSP of Brady’s 4-Valued Implicative Expansion BN4
371
The section is ended noting that BN4VSP complies with the requirements
imposed to “implicative logics” in the classical Polish logical tradition, except,
of course, VEQ (cf. [19], pp. 179–180 or [26], p. 228). Consider the following
deﬁnition:
Deﬁnition 9 (Implicative logics). A logic L is implicative if the following
properties (C1)-(C5) are predicable of L:
C1. A →A
Reﬂexivity
C2. A →B, A ⇒B
Modus Ponens
C3. A ⇒B →A
VEQ
C4. A →B, B →C ⇒A →C
Transitivity
C5. A ↔B →C[A] ↔C[A/B]
Replacement
Now, BN4VSP has properties C1, C2, C4 and C5 (cf. Deﬁnition 8 and Propo-
sitions 2 and 3).
4
Belnap-Dunn Semantics for BN4VSP
As it is well-known, Belnap-Dunn two-valued semantics (BD-semantics) is char-
acterized by the possibility of assigning T, F, both T and F or neither T nor
F to the formulas of a given logical language (cf. [5,6,9,10]; T represents truth
and F represents falsity).
Given an implicative expansion of FOUR (Deﬁnition 2), M, the idea for
deﬁning a BD-semantics, M′, equivalent to the matrix semantics based upon M
is simple: a wﬀA is assigned both T and F in M′ iﬀit is assigned 2 in M; A is
assigned neither T nor F in M′ iﬀit is assigned 1 in M; ﬁnally, A is assigned T
but not F (resp., F but not T) in M′ iﬀit is assigned 3 (resp., 0) in M.
The BD-semantics for BN4VSP, equivalent to the matrix semantics based
upon MBN4VSP (Deﬁnition 4), to be deﬁned below has been built by following
the simple intuitive ideas just exposed.
In the sequel, the notion of a BN4VSP-model and the accompanying notions of
BN4VSP-consequence and BN4VSP-validity are deﬁned. BN4VSP-models and said
annexed notions constitute a BD-semantics for BN4VSP (a BN4VSP-semantics)
equivalent to the one based upon the matrix MBN4VSP, in the sense explained
above. It will be proved that the logic BN4VSP is sound and complete w.r.t.
BN4VSP-semantics.
Deﬁnition 10 (BN4VSP-models). A BN4VSP-model is a structure (K, I),
where (i) K = {{T}, {F}, {T, F}, ∅}, and (ii) I is a BN4VSP-interpretation
from the set of all wﬀs to K, this notion being deﬁned according to the following
conditions for each propositional variable p and wﬀs A, B:

372
G. Robles
1. I(p) ∈K
2a. T ∈I(¬A) iﬀF ∈I(A)
2b. F ∈I(¬A) iﬀT ∈I(A)
3a. T ∈I(A ∧B) iﬀT ∈I(A) & T ∈I(B)
3b. F ∈I(A ∧B) iﬀF ∈I(A) or F ∈I(B)
4a. T ∈I(A ∨B) iﬀT ∈I(A) or T ∈I(B)
4b. F ∈I(A ∨B) iﬀF ∈I(A) & F ∈I(B)
5a. T ∈I(A →B) iﬀ[T /∈I(A) & F /∈I(B)] or
[T /∈I(A) & F ∈I(A) & T /∈I(B) & F ∈I(B)] or
[T ∈I(A) & F ∈I(A) & T ∈I(B) & F ∈I(B)] or
[T ∈I(A) & F /∈I(A) & T ∈I(B) & F /∈I(B)]
5b. F ∈I(A →B) iﬀT ∈I(A) & F ∈I(B)
Deﬁnition 11 (BN4VSP-consequence,
BN4VSP-validity). Let M be a
BN4VSP-model. For any set of wﬀs Γ and wﬀA:
1. Γ ⊨M A (A is a consequence of Γ in M) iﬀT ∈I(A) whenever T ∈I(Γ).
2. Γ ⊨BN4VSP A (A is a consequence of Γ in BN4VSP-semantics) iﬀΓ ⊨M A
for each BN4VSP-model M (T ∈I(Γ) iﬀ∀A ∈Γ(T ∈I(A)); F ∈I(Γ) iﬀ
∃A ∈Γ(F ∈I(A))).
3. In particular, ⊨BN4VSP A (A is valid in BN4VSP-semantics) iﬀ⊨M A for each
BN4VSP-model M (i.e., iﬀT ∈I(A) for each BN4VSP-model M).
(By ⊨BN4VSP we shall refer to the relation just deﬁned.)
Now, given Deﬁnition 4 together with the adjoined notions of MBN4VSP-
interpretation and MBN4VSP-validity (cf. Deﬁnition 1), and Deﬁnitions 10 and
11, we easily prove:
Proposition 7 (Coextensiveness of ⊨MBN4VSP and ⊨BN4VSP). For any set
of wﬀs Γ and wﬀA, Γ ⊨MBN4VSP A iﬀΓ ⊨BN4VSP A. In particular, ⊨MBN4VSP A
iﬀ⊨BN4VSP A. (By ⊨MBN4VSP, we refer to the consequence relation deﬁnable in
MBN4VSP —cf. Deﬁnitions 1 and 4)4
Proof. Cf., e.g., the proof of Theorem 8 in [7] or Proposition 4.4 in [14], where
the simple proof procedure is exempliﬁed in the cases of the logics BN4 and Sm4,
respectively.
Proposition 7 simply formalizes the intuitive translation (explained above) of
the matrix semantics based upon MBN4VSP into Belnap and Dunn’s two-valued
type BN4VSP-semantics. Nevertheless, Proposition 7 is a most useful proposition:
4 A referee of CLAR 2021 remarks that this result can be obtained as a special case
of the general procedure described in §2 of “Generalizing functional completeness in
Belnap-Dunn logic” (H. Omori and K. Sano, Studia Logica, 103(5), 883–917, 2015).

A Variant with the VSP of Brady’s 4-Valued Implicative Expansion BN4
373
it gives us the possibility of easily proving soundness of BN4VSP w.r.t. ⊨MBN4VSP,
while proving completeness w.r.t. ⊨BN4VSP by using a canonical model construc-
tion.
Theorem 1 (Soundness of BN4VSP). For any set of wﬀs Γ and wﬀA, if
Γ ⊢BN4VSP A, then (1) Γ ⊨MBN4VSP A and (2) Γ ⊨BN4VSP A.
Proof. Let I be an MBN4VSP-interpretation (deﬁned in the MBN4VSP-model
M). (1) It is easy to check the following facts: (i) I assigns a designated value to
the conclusion of rules R1-R13 if it assigns a designated value to the premise(s)
of said rules; (ii) A1-A9 are assigned 2 or 3 by I; (iii) concerning the metarule
MR, let I(D ∨A) = I(D ∨B) = 2 or 3 but I(D ∨C) = 0 or 1 for some wﬀs A, B
and C. Then, it is clear that C is not a M-consequence of A, B (i.e., A, B ⇒C
is falsiﬁed). (2) It is immediate from (1) and Proposition 7 (in case a tester is
needed, the one in [12] can be used).
As has just been pointed out, completeness is proved by a canonical model
construction, similarly as in, e.g., [14,15] or [21]. Let us see how this proof
proceeds. Firstly, the notion of a BN4VSP-theory and the classes of BN4VSP-
theories of interest in the present paper are introduced. Then, the concept of a
canonical model is deﬁned.
Deﬁnition 12 (BN4VSP-theories.
Classes
of
BN4VSP-theories).
A
BN4VSP-theory (theory, for short) is a set of formulas closed under BN4VSP-
entailment (BN4VSP-ent), all the rules of BN4VSP and the metarule MR (a
theory t is closed under BN4VSP-ent iﬀwhenever A →B is a BN4VSP-theorem
and A ∈t, then B ∈t). Then, a theory t is regular iﬀit contains all BN4VSP-
theorems, and it is prime iﬀit has the disjunction property (i.e., if A ∨B ∈t,
then A ∈t or B ∈t).
The following lemma is instrumental in the completeness proof.
Lemma 1 (The conditional in prime, regular theories). Let t be a regular
and prime theory. For any wﬀs A, B, we have:
(a) A →B ∈t iﬀ[A /∈t & ¬B /∈t] or [A /∈t & ¬A ∈t & B /∈t & ¬B ∈t]
or [A ∈t & ¬A ∈t & B ∈t & ¬B ∈t] or [A ∈t & ¬A /∈t & B ∈t &
¬B /∈t]
(b) ¬(A →B) ∈t iﬀA ∈t & ¬B ∈t
Proof. Similar to those of Theorem 10 in [7], Lemma 2.3 in [14], Lemma 3.6 in
[15] or Lemma 5.7 in [21]. In order to prove (a), we can use A8, A9, MP, R8,
R9, R10, R11, T30 and T31 (cf. Proposition 4). The proof of (b) is obtained by
using R12 and R13.
(a) (⇒) Suppose (1) A →B ∈t and, for reductio, (2) [A ∈t or ¬B ∈t] &
[A ∈t or ¬A /∈t or B ∈t or ¬B /∈t]
&
[A /∈t or ¬A /∈t or B /∈t or
¬B /∈t] & [A /∈t or ¬A ∈t or B /∈t or ¬B ∈t]. Suppose (3) A ∈t. Then,
we have 64 possibilities to consider. But each one of them belongs to one of the

374
G. Robles
following categories. (i) It contains a contradiction (e.g., A ∈t & A /∈t); (ii) it
contains A ∈t and B ∈t; (iii) it contains ¬A /∈t and ¬B ∈t; (iv) it contains
A ∈t, ¬A ∈t and ¬B /∈t; (v) it contains B ∈t, ¬B ∈t and ¬A /∈t. Now, the
situations in (ii)-(v) also lead to contradiction by using (1) and the rules MP,
MT, T30, R10 and R11, respectively. (4) ¬B ∈t. We have also 64 possibilities
to consider, which are proved similarly as case (3) was solved. (We use MP, MT,
T30 and T31.)
(a) (⇐) A →B follows by A8, R8, A9 and R9, respectively. Let us prove, for
example, the ﬁrst of the cases. Suppose A /∈t and ¬B /∈t. By A8, (A∨¬B)∨(A →
B), and primeness of t, A ∈t or ¬B ∈t or A →B ∈t. Consequently, A →B ∈t,
as it was to be proved.
Next, (b) is immediate by R10 and R11.
Next, we sketch the framework of the completeness proof. A canonical model
is a structure (K, It) where K is deﬁned as in Deﬁnition 10 and It is a t-
interpretation built upon a regular and prime theory t. A t-interpretation is a
function from the set of all wﬀs to K deﬁned as follows: for each wﬀA, T ∈It(A)
iﬀA ∈t and F ∈It(A) iﬀ¬A ∈t. Canonical models are shown BN4VSP-models
by proving that It fulﬁls the conditions listed in Deﬁnition 10. But it is obvious
that A5, A7, T5 and T27 guarantee that clauses (1a) to (4b) hold canonically (cf.
Propositions 3 and 4) while Lemma 1 takes care of clauses (5a) and (5b). Once
canonical models are shown BN4VSP-models, completeness is proved as follows.
Suppose that Γ is a set oﬀwﬀs and A a wﬀsuch that Γ ⊬BN4VSP A. Then A
does not belong to the set of consequences derivable in BN4VSP from Γ (in sym-
bols, A /∈CnΓ[BN4VSP]). Next, the regular theory CnΓ[BN4VSP] is extended
to a prime theory t such that A /∈t. Then t generates a t-interpretation It such
that T ∈It(Γ) (since T ∈It(CnΓ[BN4VSP]) : Cn[BN4VSP] ⊆t) but T /∈It(A),
whence A does not follow from Γ in the canonical BN4VSP-model built upon t.
So, Γ ⊭BN4VSP A. (Notice that we have not needed consistent theories in any
sense of the term “consistent”.)
Remark 8 (On the Extension Lemma). Once the instrumental Propositions 5
and 6 have been shown to hold for BN4VSP, the Extension Lemma can be proved
similarly as, e.g., in [7], Lemma 9; [14], Lemma 24; [15], Lemma 3.11.
Leaning upon the argumentation just developed, I think that I am entitled
to state the following completeness theorem w.r.t. both ⊨MBN4VSP and ⊨BN4VSP.
Theorem 2 (Completeness of BN4VSP). For any set of wﬀs Γ and wﬀA,
Γ ⊢BN4VSP A if (1) Γ ⊨MBN4VSP A or (2) Γ ⊨BN4VSP A.
The paper is ended with some suggestions for future work on the topic.
5
Concluding Remarks
According to Anderson and Belnap, the variable-sharing property (VSP) is a
property a logic has to enjoy in order to deserve being named a relevance logic. As

A Variant with the VSP of Brady’s 4-Valued Implicative Expansion BN4
375
pointed out in the introduction to the paper, Brady’s BN4 is widely considered
the correct 4-valued logic among relevant logicians. But BN4 lacks the VSP.
The initial impetus of the investigation reported in the present paper was to
ﬁnd a signiﬁcant 4-valued implicative expansion of FDE with the VSP worthy
of consideration. The logic BN4VSP, a variant of BN4, does have the VSP, in
addition to sporting some properties that do not support its consideration as a
mere artiﬁcial construct.
There is a number of ways in which the investigation carried out in this paper
can be pursued. We limit ourselves to remark two of them.
1. Is BN4VSP just one of a class of signiﬁcant 4-valued implicative expansions
of FDE having the VSP?5
2. According to Anderson and Belnap, two properties need to be predicable of a
logic of entailment: one of them is the VSP, the other one is the Ackermann
Property (AP). The AP reads as follows: a logic L has the AP if in all L-
theorems of the form A →(B →C), →appears in A (cf. [1]). Well then,
is there a signiﬁcant 4-valued expansion of FDE with both the VSP and the
AP?
References
1. Anderson, A.R., Belnap, N.D., Jr., Dunn, J.M.: Entailment, the Logic of Relevance
and Necessity, vol. II. Princeton University Press, Princeton (1992)
2. Avron, A., Ben-Naim, J., Konikowska, B.: Cut-free ordinary sequent calculi for
logics having generalized ﬁnite-valued semantics. Logica Universalis 1(1), 41–70
(2007). https://doi.org/10.1007/s11787-006-0003-6
3. Avron, A., Konikowska, B., Zamansky, A.: Cut-free sequent calculi for C-systems
with generalized ﬁnite-valued semantics. J. Log. Comput. 23(3), 517–540 (2013).
https://doi.org/10.1093/logcom/exs039
4. Belnap, N.D., Jr.: Entailment and relevance. J. Symb. Log. 25(2), 144–146 (1960)
5. Belnap, N.D., Jr.: A useful four-valued logic. In: Epstein, G., Dunn, J.M. (eds.)
Modern Uses of Multiple-Valued Logic, pp. 8–37. D. Reidel Publishing Co., Dor-
drecht (1977)
6. Belnap, N.D., Jr.: How a computer should think. In: Ryle, G. (ed.) Contemporary
Aspects of Philosophy, pp. 30–55. Oriel Press Ltd., Stocksﬁeld (1977)
7. Brady, R.T.: Completeness proofs for the systems RM3 and BN4. Logique et Anal.
(N.S.) 25, 9–32 (1982)
8. Brady, R.T. (ed.): Relevant Logics and Their Rivals, vol. II. Ashgate, Aldershot
(2003)
9. Dunn, J.M.: Intuitive semantics for ﬁrst-degree entailments and “coupled trees”.
Philos. Stud. 29, 149–168 (1976)
5 A referee of CLAR 2021 remarks that there are 217 diﬀerent matrices with natural
conditionals (in the sense of Deﬁnition 5) complying with the VSP. Well then, since
this paper was written, we have pursued the topic it introduces and almost all the 217
variants are non-signiﬁcant in the sense that they lack one or more of the properties
MBN4VSP exhibits (actually, only 24 of said matrices share the properties MBN4VSP
has).

376
G. Robles
10. Dunn, J.M.: Partiality and its dual. Studia Logica 66, 5–40 (2000)
11. Dziobiak, W.: There are 2ℵ0 logics with the relevance principle between R and
RM. Studia Logica 42(1), 49–61 (1983). https://doi.org/10.1007/BF01418759
12. Gonz´alez, C.: MaTest (2011). https://sites.google.com/site/sefusmendez/matest.
Accessed 27 June 2021
13. L´opez, S.M.: Belnap-Dunn semantics for the variants of BN4 and E4 which contain
Routley and Meyer’s logic B. Logic Logical Philos. 1–28 (2021). https://doi.org/
10.12775/LLP.2021.004
14. M´endez, J.M., Robles, G.: The logic determined by Smiley’s matrix for Anderson
and Belnap’s First Degree Entailment Logic. J. Appl. Non-Classical Log. 26(1),
47–68 (2016). https://doi.org/10.1080/11663081.2016.1153930
15. M´endez, J.M., Robles, G.: Strengthening Brady’s paraconsistent 4-valued logic
BN4 with truth-functional modal operators. J. Log. Lang. Inf. 25(2), 163–189
(2016). https://doi.org/10.1007/s10849-016-9237-8
16. Meyer, R.K., Giambrone, S., Brady, R.T.: Where gamma fails. Studia Logica 43,
247–256 (1984). https://doi.org/10.1007/BF02429841
17. Omori, H., Wansing, H.: 40 years of FDE: an introductory overview. Studia Logica
105(6), 1021–1049 (2017). https://doi.org/10.1007/s11225-017-9748-6
18. Petrukhin, Y., Shangin, V.: Correspondence analysis and automated proof-
searching for ﬁrst degree entailment. Eur. J. Math. 6, 1452–1495 (2020). https://
doi.org/10.1007/s40879-019-00344-5
19. Rasiowa, H.: An Algebraic Approach to Non-classical Logics, vol. 78. North-
Holland Publishing Company, Amsterdam (1974)
20. Robles, G.: The class of all 3-valued implicative expansions of Kleene’s strong logic
containing Anderson and Belnap’s First degree entailment logic. J. Appl. Log. 8(7),
2035–2071 (2021)
21. Robles, G., M´endez, J.M.: A companion to Brady’s 4-valued relevant logic BN4:
the 4-valued logic of entailment E4. Log. J. IGPL 24(5), 838–858 (2016). https://
doi.org/10.1093/jigpal/jzw011
22. Robles, G., M´endez, J.M.: The class of all natural implicative expansions of
Kleene’s strong logic functionally equivalent to Lukasiewicz’s 3-valued logic L3. J.
Log. Lang. Inf. 29(3), 349–374 (2020). https://doi.org/10.1007/s10849-019-09306-
2
23. Routley, R., Meyer, R.K., Plumwood, V., Brady, R.T.: Relevant Logics and Their
Rivals, vol. 1. Ridgeview Publishing Co., Atascadero (1982)
24. Slaney, J.: Relevant logic and paraconsistency. In: Bertossi, L., Hunter, A., Schaub,
T. (eds.) Inconsistency Tolerance. LNCS, vol. 3300, pp. 270–293. Springer, Heidel-
berg (2005). https://doi.org/10.1007/978-3-540-30597-2 9
25. Tomova, N.: A Lattice of implicative extensions of regular Kleene’s logics. Rep.
Math. Log. 47, 173–182 (2012). https://doi.org/10.4467/20842589RM.12.008.0689
26. W´ojcicki, R.: Theory of Logical Calculi: Basic Theory of Consequence Operations.
Springer, Dordrecht (1988). https://doi.org/10.1007/978-94-015-6942-2

Intrinsic Argument Strength
in Structured Argumentation:
A Principled Approach
Jeroen Paul Spaans(B)
Utrecht University, Utrecht, The Netherlands
Abstract. Abstract argumentation provides us with methods such as
gradual and Dung semantics with which to evaluate arguments after
potential attacks by other arguments. Some of these methods can take
intrinsic strengths of arguments as input, with which to modulate the
eﬀects of attacks between arguments. Coming from abstract argumenta-
tion, these methods look only at the relations between arguments and
not at the structure of the arguments themselves. In structured argu-
mentation the way an argument is constructed, by chaining inference
rules starting from premises, is taken into consideration. In this paper
we study methods for assigning an argument its intrinsic strength, based
on the strengths of the premises and inference rules used to form said
argument. We ﬁrst deﬁne a set of principles, which are properties that
strength assigning methods might satisfy. We then propose two such
methods and analyse which principles they satisfy. Finally, we present
a generalised system for creating novel strength assigning methods and
speak to the properties of this system regarding the proposed principles.
Keywords: Intrinsic argument strength · Structured argumentation ·
Principles · Weight aggregation · Aggregation method
1
Introduction
Argumentation is used in Artiﬁcial Intelligence to aid in solving many varied
problems; for example, it is used to help with nonmonotonic reasoning [6], to
help in making and explaining decisions [13] and to develop architectures for
agents in a multi-agent setting [8]. Argumentation’s core concept is justifying
claims by use of arguments. These arguments are reasons to believe or accept a
claim.
Arguments might not agree with one another, such as when two arguments
support contradicting claims or when one argument contradicts a premise of
another. In these cases we speak of one argument standing in an attack relation
to another. To help draw conclusions about which arguments to accept Dung
introduced abstract argumentation frameworks [6] in which arguments and the
binary attack relations between them are modelled in a directed graph. Diﬀerent
semantics may then be used to determine the status of each argument.
c
⃝Springer Nature Switzerland AG 2021
P. Baroni et al. (Eds.): CLAR 2021, LNAI 13040, pp. 377–396, 2021.
https://doi.org/10.1007/978-3-030-89391-0_21

378
J. P. Spaans
Dung’s semantics [6] and those in the same family, such as those researched
in [2], deﬁne extensions of arguments such that every argument is in (accepted),
out (rejected) or, in some cases, undecided.
Gradual semantics, introduced by Cayrol and Lagasquie-Schiex [5] and fur-
ther researched in [1], do not seek to accept or reject arguments like the afore-
mentioned Dung- or extension semantics but rather to compute their overall
strength.
Arguments will often have a base weight, or intrinsic strength, representing,
for example, the certainty of the argument’s premises [4]. To determine the
overall strength of an argument, the attacks against it are taken into account.
These attacks may also be weighted, for example to represent their degree of
relevance [7].
Gradual semantics have been proposed both for semi-weighted abstract argu-
mentation frameworks (i.e. those frameworks where only the arguments have a
base weight) [1] and for weighted abstract argumentation frameworks (i.e. those
frameworks where arguments and attacks are weighted) [3], each based on dif-
ferent ways of aggregating attacks, considering the strength of each attacker and
(where applicable) the strength of each attack, to lower the weight or strength
of the argument under attack.
The aforementioned falls under what is known as abstract argumentation.
Here the internal structure of an argument and the nature of attacks is not
considered. When we do take these factors into consideration, such as in [11,12]
and this paper, we speak of structured argumentation.
An argument, in structured argumentation, can intuitively be seen as the
application of one or more strict or defeasible inference rules, starting from a set
of premises. We might apply the strict inference rule if X is a bird, then X is
an animal (strict, because this inference is based on a deﬁnition and is therefore
not open to attack) to the premise Tweety is a bird to form an argument for
the claim Tweety is an animal. Similarly we might apply the defeasible inference
rule if X is a bird, then X can most likely ﬂy (defeasible because X might be
a penguin or a baby bird, in which case they cannot ﬂy, leaving the inference
open to attack) to the same premise to form an argument for the claim Tweety
can ﬂy. It is plain to see how inference rules can be combined to form more
complex arguments in the shape of an inference tree. If conﬂict arises between
the conclusion of an argument A and some part of an argument B we speak of
an attack from A to B. we may specify such an attack to, for example, be a
rebuttal when A attacks B on its conclusion or an undermining when it attacks
B on a premise.
While gradual semantics allow us to determine the overall strength of argu-
ments after attacks when we have been given the intrinsic strength of each
argument, no standard has arisen in the literature for deriving these intrinsic
strengths from the structure of the arguments. Such a standard is what we hope
to work toward with this paper. The aim is to investigate diﬀerent methods for
aggregating given weights of the premises and inference rules used to form the
argument to derive the intrinsic strength of the argument as a whole.

Intrinsic Argument Strength in Structured Argumentation
379
The paper is structured as follows. We ﬁrst introduce the basic concepts used
in structured argumentation. Then we will deﬁne a series of principles, each
of which will be a property a method for assigning an argument its intrinsic
strength can satisfy. We then propose two intrinsic strength assigning methods
and evaluate which principles they satisfy. Next we introduce the aggregation
method, a framework for creating new strength assigning methods. Lastly, we
speak to the properties of an aggregation method, especially in regard to the
earlier-proposed principles.
2
Basic Concepts
In argumentation `a la Dung, we look at arguments in an argumentation graph,
which consists of a set of arguments and a binary attack relation on this set. In
gradual argumentation, as in [3] which is where we take the following deﬁnition
from, we often assign weights in the interval [0, 1] (lower is weaker) to both
the arguments and attacks in our argumentation graph, resulting in a weighted
argumentation graphs.
Deﬁnition 1 (Weighted Argumentation Graph). A weighted argumenta-
tion graph (WAG) is an ordered tuple G = ⟨A, σ, R, π⟩, where A is a non-empty
ﬁnite set of arguments, R ⊆A × A, σ : A →[0, 1] and π : R →[0, 1].
Here σ(a) is the base weight of argument a, (a, b) ∈R means a attacks b and
π((a, b)) is the weight of the attack from a to b. In this paper we are looking to
formulate σ such that it represents an argument’s intrinsic strength, where σ(a)
is an aggregation of the strengths of the premises and inference rules used in a
over the structure of a.
Example 1. Take the argumentation graph in Fig. 1. Here A = {a, b, c, d, e} and
R = {(a, b), (b, c), (b, e), (d, c)}. Assume the weight of all arguments and attacks
in the graph is 1.
a
b
c
d
e
Fig. 1. An argumentation graph
Grounded Dung semantics [6] would give us the set of arguments, called an
extension, to accept. Grounded semantics, speciﬁcally, would give the smallest
complete extension. To ﬁnd this extension we need a few concepts:

380
J. P. Spaans
– an argument a ∈A is acceptable with respect to E ⊆A iﬀE defends a. That
is, ∀b ∈A s.t. (b, a) ∈R, ∃c ∈E s.t. (c, b) ∈R.
– A set of arguments E is conﬂict free iﬀ∀a, b ∈E, (a, b) /∈R.
– A set of arguments E is admissible iﬀit is conﬂict-free and all arguments in
E are acceptable with respect to E.
– A set of arguments E is a complete extension iﬀit is an admissible set and
every acceptable argument with respect to E belongs to E.
Following these concepts we see that b and c cannot be included in a complete
extension, since a and d have no attackers and as such a set containing b and
c could never defend them from the attacks of a and d. From here we get the
unique grounded extension Eg = {a, d, e}.
The gradual Weighted h-Categorizer Semantics [1] (which we can use because
all attack weights are 1) would assign each argument x an acceptability degree
Deg(x) = limi→∞f i(x) where
f i(x) =

σ(x)
if i = 0
σ(x)
1+
bi∈Att(x) f i−1(bi)
otherwise
and Att(x) denotes the attackers of x. This would result in Deg(a) = 1, Deg(b) =
1
2, Deg(c) = 2
5, Deg(d) = 1 and Deg(e) = 2
3.
Having seen how arguments can relate to one another, we now look to how
arguments are formed. In doing so, we introduce a modiﬁed variant of the
ASPIC+ framework [11].
To construct an argument, we must ﬁrst know the building blocks that are at
our disposal. In an argument we make inferences based on inference rules with
antecedents and consequents that are all well-formed formulae in some logical
language.
Deﬁnition 2 (Argumentation System). An argumentation system is a pair
AS = (L, R) where:
– L is a logical language consisting of propositional or ground predicate-logic
literals that is closed under negation.
– R = Rd ∪Rs with Rd ∩Rs = ∅, where Rd is a ﬁnite set of defeasible
inference rules of the form {ϕ1, . . . , ϕn} ⇒ϕ, Rs is a ﬁnite set of strict
inference rules of the form {ϕ1, . . . , ϕn} →ϕ and ϕ, ϕi are meta-variables
ranging over well-formed formulae in L. We call ϕ1, . . . , ϕn the antecedents
of the rule and ϕ its consequent.
Just in case ψ = ¬ϕ or ϕ = ¬ψ, we write ψ = −ϕ. Here −is not a member
of L but rather a metalinguistic symbol used to simplify notation.
In any argument we start our reasoning from one or more premises. These are
the pieces of knowledge from which we infer other information. What is impor-
tant to notice, is that a premise may be fallible or infallible. Fallible premises are
open to attack. Suppose we combine our belief that we saw Robin in Rotterdam

Intrinsic Argument Strength in Structured Argumentation
381
this morning with the knowledge that Rotterdam is in the Netherlands to argue
Robin was in the Netherlands this morning. This argument is deductively valid
but still open to attack. Suppose our friend Alex informs us they saw Robin in
Berlin at the same time we believe to have seen them in Rotterdam. Since our
friends usually tell us the truth, this allows us to form an argument that attacks
the original premise that we saw Robin in Rotterdam. Infallible premises, such
as 1 is a natural number, are not open to attack. In accordance with [11] we will
call these infallible premises axiom premises and we will refer to premises that
are open to attack as ordinary premises. We call the body of information from
which premises may be taken a knowledge base.
Deﬁnition 3 (Consistency). For any S ⊆L, let the closure of S under strict
rules, denoted ClRS(S), be the smallest set containing S and the consequent of
any strict rule in Rs whose antecedents are in ClRS(S). Then a set S ⊆L is
directly consistent iﬀthere are no ψ, ϕ ∈S such that ψ = −ϕ and indirectly
consistent iﬀClRS(S) is directly consistent. [12]
Deﬁnition 4 (Knowledge Base). A knowledge base in an AS = (L, R) is a
set K ⊆L, where K = Kn ∪Kp, Kn is a set of axioms, Kp is a set of ordinary
premises, Kn is indirectly consistent and Kn ∩Kp = ∅.
With an argumentation system and a knowledge base we could create an
argument, but we would still be missing the rule and premise weights. To codify
these we introduce the weighted argumentation theory.
Deﬁnition 5 (Weighted Argumentation Theory). A weighted argumenta-
tion theory is a tuple WAT = (AS, K, s) where:
– AS = (L, R) is an argumentation system.
– K is a knowledge base.
– s is a function assigning weights to rules and premises, such that ∀r ∈
Rs, s(r) = 1; ∀p ∈Kn, s(p) = 1; ∀r′ ∈Rd, s(r′) ∈[0, 1); ∀p′ ∈Kp, s(p′) ∈
[0, 1) and a higher weight is assigned to stronger premises and inference rules.
Example 2. Continuing with the Tweety is a bird example from the introduction
to this paper, we might have:
– s(Tweety is a bird →Tweety is an animal) = 1; because all birds are, by
deﬁnition, animals and as such this is a strict inference rule.
– s(Tweety is a bird ⇒Tweety can ﬂy) = 0.95; because most birds can ﬂy, so
this is a strong defeasible inference rule.
– s(Tweety is a bird ⇒Tweety is yellow) = 0.05; because, while existent, yel-
low birds are quite rare, so this is a weak defeasible inference rule.
We can now deﬁne an argument over a WAT = (AS, K, s). As in ASPIC+ [11]
we chain together applications of inference rules from AS into inference trees,
starting from premises in K.

382
J. P. Spaans
For a given argument A, Conc(A) returns the conclusion of A, TopRule(A)
returns the last inference rule used in the argument, Ant(A) returns the argu-
ment’s set of antecedent arguments, Sub(A) returns the subarguments of A,
DefRules(A) returns all the defeasible rules used in A, StrRules(A) returns all
the used strict rules and OrdPrem(A) and Axioms(A) return the ordinary and
axiomatic premises used to construct the argument respectively.
The structure of an argument deﬁned like this is the same as in ASPIC+, but
there are two diﬀerences between the functions we deﬁne over an argument and
those commonly used in ASPIC+. Firstly, we split up the function Prem, which
returns all of the premises used in an argument, into Axioms and OrdPrem to
more easily distinguish between the strict and defeasible parts of an argument.
Secondly and more notably, while ASPIC+ uses ordinary sets for the values of
Prem, StrRules and DefRules, we use multisets for the values of the four premise
and rule functions. A multiset, also called a bag, is much like an ordinary set
but, contrary to a normal set, is able to contain an element more than once
[10]. The use of multisets allows us to more easily determine the strength of
an argument in later sections of this paper because, intuitively, each use of a
defeasible premise or inference rule should aﬀect the strength of an argument
and these multisets allow us to easily iterate over each occurence.
Deﬁnition 6 (Multiset). A multiset is a modiﬁcation of a set that allows mul-
tiple instances of its elements. Like an ordinary set, a multiset is unordered. e.g.
[a, a, a, b, b] is a multiset containing a and b where a has multiplicity m(a) = 3
and b has multiplicity m(b) = 2. This multiset may also be denoted [a3, b2] or
{(a, 3), (b, 2)}.
We often say the elements of a multiset come from a ﬁxed set U called the
universe, such that the support of a multiset A is the multiset’s underlying set
Supp(A) = {x ∈U|mA(x) > 0}. For readability, we say A = ∅when Supp(A) =
∅.
We use the following functions on multisets:
– Union: the union of multisets A and B, A ∪B is the multiset C with multi-
plicity function mC(x) = max(mA(x), mB(x)), ∀x ∈U.
– Sum: the sum of of multisets A and B, A⊎B is the multiset C with multiplicity
function mC(x) = mA(x) + mB(x), ∀x ∈U.
When using multisets in product or sum notation we assume to iterate over each
occurrence of an element; for instance 
a∈[b,b,c] a = b·b·c. The same assumption
is made for set builder notation, such that {f(x)|x ∈[a, a, b]} = [f(a), f(a), f(b)].
Deﬁnition 7 ((General) Argument). A general argument A over a WAT =
(AS, K, s) is deﬁned recursively. It can be obtained by applying one or more of
the following steps a ﬁnite amount of times;
1. premise ϕ, if ϕ ∈Kn, where:
Conc(A) = ϕ;
TopRule(A) = undefined;

Intrinsic Argument Strength in Structured Argumentation
383
Ant(A) = ∅;
Sub(A) = {ϕ};
DefRules(A) = ∅;
StrRules(A) = ∅;
OrdPrem(A) = ∅;
Axioms(A) = [ϕ].
2. premise ϕ, if ϕ ∈Kp, where:
Conc(A) = ϕ;
TopRule(A) = undefined;
Ant(A) = ∅;
Sub(A) = {ϕ};
DefRules(A) = ∅;
StrRules(A) = ∅;
OrdPrem(A) = [ϕ];
Axioms(A) = ∅.
3. {A1, . . . , An} →ϕ, if A1, . . . , An are arguments and
{Conc(A1), . . . , Conc(An)} →ϕ ∈Rs, where:
Conc(A) = ϕ;
TopRule(A) = {Conc(A1), . . . , Conc(An)} →ϕ;
Ant(A) = {A1, . . . , An};
Sub(A) = Sub(A1) ∪· · · ∪Sub(An) ∪{A};
DefRules(A) = DefRules(A1) ⊎· · · ⊎DefRules(An);
StrRules(A) = StrRules(A1) ⊎· · · ⊎StrRules(An) ⊎[{Conc(A1), . . . , Conc
(An)} →ϕ];
OrdPrem(A) = OrdPrem(A1) ⊎· · · ⊎OrdPrem(An);
Axioms(A) = Axioms(A1) ⊎· · · ⊎Axioms(An)
4. {A1, . . . , An} ⇒ϕ, if A1, . . . , An are arguments and
{Conc(A1), . . . , Conc(An)} ⇒ϕ ∈Rd, where:
Conc(A) = ϕ;
TopRule(A) = {Conc(A1), . . . , Conc(An)} ⇒ϕ;
Ant(A) = {A1, . . . , An};
Sub(A) = Sub(A1) ∪· · · ∪Sub(An) ∪{A};
DefRules(A) = DefRules(A1) ⊎· · · ⊎DefRules(An) ⊎[{Conc(A1), . . . , Conc
(An)} ⇒ϕ];
StrRules(A) = StrRules(A1) ⊎· · · ⊎StrRules(An);
OrdPrem(A) = OrdPrem(A1) ⊎· · · ⊎OrdPrem(An);
Axioms(A) = Axioms(A1) ⊎· · · ⊎Axioms(An).
A general argument A is an argument iﬀ:
1. Sub(A) is indirectly consistent; and
2. If A contains non-strict subarguments A′ and A′′ such that Conc(A′) =
Conc(A′′), then A′ = A′′.
An argument A is called strict when DefRules(A) = OrdPrem(A) = ∅. Else it is
called defeasible.

384
J. P. Spaans
Later in this paper, we will use the premises and inference rules used in an
argument as the input of functions to determine the argument’s strength. To
simplify notation we introduce the basis of an argument.
Deﬁnition 8 ((Defeasible/Strict) Basis). For an argument A the defeasi-
ble basis of A, written DefBasis(A) is the multiset of all ordinary premises
and defeasible inference rules used in A. i.e. DefBasis(A) = OrdPrem(A) ⊎
DefRules(A).
The strict basis of A, StrBasis(A) = Axioms(A) ⊎StrRules(A), is the mul-
tiset of all axiomatic premises and strict inference rules used in A.
The basis of A is the sum of its strict and defeasible bases, s.t. Basis(A) =
DefBasis ⊎StrBasis.
For ease of notation we also introduce the Rules and Prem functions which
return the multisets of all inference rules and premises used in an argument
respectively.
Deﬁnition 9 (Rules). For an argument A,
Rules(A) = StrRules(A) ⊎DefRules(A).
Deﬁnition 10 (Prem). For an argument A,
Prem(A) = Axioms(A) ⊎OrdPrem(A).
We say two arguments are isomorphic if they have the same structure (or
shape) and have the same weights for the equivalently positioned premises and
inference rules.
Deﬁnition 11 (Isomorphism).
Take arguments A over WAT = (AS, K, s)
and A′ over a WAT′ = (AS′, K′, s′). There exists an isomorphism between A
and A′ when:
– If the arguments state a premise (Items 1, 2; Deﬁnition 7),
s(Conc(A)) = s′(Conc(A′)).
– If the arguments make an inference (Items 3, 4; Deﬁnition 7),
s(TopRule(A)) = s′(TopRule(A′)) and
there exists a bijective function f : Ant(A) →Ant(A′) such that
∀A′′ ∈Ant(A), f(A′′) ∈Ant(A′) is an isomorphic image of A′′.
With our arguments deﬁned, we are looking to assign each argument an
intrinsic strength, based on its structure.
Deﬁnition 12 (Intrinsic Strength). Str is a function that assigns numbers
in [0, 1] to arguments, such that for an argument A over a WAT = (AS, K, s),
Str(A) is the intrinsic strength of A where stronger arguments are assigned
higher values.

Intrinsic Argument Strength in Structured Argumentation
385
3
Principles
When assigning intrinsic strength to arguments, we may wish to look to certain
principles our method of assigning these strengths might adhere to. This aids
us in understanding the method we use to assign strengths, in comparing dif-
ferent strength-assigning methods, in proposing sensible methods for assigning
strengths, and in selecting a suitable method for assigning strength for a certain
application.
In this section we propose 13 such principles, which describe the way the
weights of premises and inference rules and the intrinsic strengths of antecedent
arguments aﬀect the intrinsic strength of an argument. Most of these principles
are intended to be intuitively desirable traits for the assigning of a strength value
to an argument.
A similar approach is taken in [1] and later in [3] in the exploration of seman-
tics that assign acceptability degrees to arguments after attacks by other argu-
ments in (semi-)weighted argumentation graphs by aggregating attacks, (their
weights,) and the base argument weights. Many of the principles proposed in
this section resemble those used in the aforementioned papers.
Our ﬁrst principle states that the identity, that is the name and meaning, of
an argument A should not aﬀect the strength assigned to it. Only its structure
should.
Principle 1 (Anonymity)
∀WAT = (AS, K, s), ∀A A′ over WAT,
if an isomorphism exists between A and A′, Str(A) = Str(A′)
The second principle says that when an argument A only states a premise,
the argument should have a strength equal to the weight of its premise.
Principle 2 (Premising)
∀WAT = (AS, K, s), ∀A over WAT,
TopRule(A) = undeﬁned →Str(A) = s(Conc(A))
Our next principle prescribes that when all of an argument A’s premises are
certain and its inferences are strict, the argument’s strength should be 1.
Principle 3 (Strict Argument)
∀WAT = (AS, K, s), ∀A over WAT, DefBasis(A) = ∅→Str(A) = 1
The Resilience principle states that when all premises and inference rules used
in an argument have a weight higher than 0, the argument’s strength should also
be higher than 0.
Principle 4 (Resilience)
∀WAT = (AS, K, s), ∀A over WAT, (∀b ∈Basis(A), s(b) > 0) →Str(A) > 0

386
J. P. Spaans
According to the next principle, if any of the premises or inference rules used
in argument A has weight 0, the intrinsic strength of A should also be 0.
Principle 5 (Argument Death)
∀WAT = (AS, K, s), ∀A over WAT, (∃b ∈Basis(A), s(b) = 0) →Str(A) = 0
The next principle says that when all antecedents of an argument A have
intrinsic strength 1, the intrinsic strength of A should equal the weight of its top
rule.
Principle 6 (Antecedent Maximality)
∀WAT = (AS, K, s), ∀A over WAT, ∀A′ ∈Ant(A),
Str(A′) = 1 ∧TopRule(A) ̸= undeﬁned →Str(A) = s(TopRule(A))
Next, Antecedent Neutrality says that any antecedents of an argument A
with intrinsic strength 1 should not aﬀect the intrinsic strength of A.
Principle 7 (Antecedent Neutrality)
∀WAT = (AS, K, s), ∀A A′ A′′ over WAT,
s(TopRule(A)) = s(TopRule(A′)) ∧Ant(A′) = Ant(A) ∪{A′′} ∧Str(A′′) = 1
→Str(A) = Str(A′)
Dual to Antecedent Neutrality, Antecedent Weakening says that any
antecedents of an argument A with intrinsic strength lower than 1 should lower
the intrinsic strength of A if it is not already 0.
Principle 8 (Antecedent Weakening)
∀WAT = (AS, K, s), ∀A A′ A′′ over WAT,
s(TopRule(A)) = s(TopRule(A′)) ∧Ant(A′) = Ant(A) ∪{A′′}
∧Str(A′′) < 1 ∧Str(A) > 0
→Str(A) > Str(A′)
To satisfy Inferential Weakening, applying a defeasible inference rule should
result in an argument with an intrinsic strength lower than that of any of its
antecedent arguments, so long as none of the antecedent arguments have strength
0.
Principle 9 (Inferential Weakening)
∀WAT = (AS, K, s), ∀A over WAT,
TopRule(A) ∈Rd ∧(∀A′ ∈Ant(A), Str(A′) > 0)
→Str(A) < min{Str(A′)|A′ ∈Ant(A)}

Intrinsic Argument Strength in Structured Argumentation
387
For Inference Weight Sensitivity to apply, applying a weaker defeasible infer-
ence rule to a set of antecedent arguments should result in a weaker argument
than applying a stronger rule to the same antecedents would, so long as none of
the antecedent arguments have strength 0.
Principle 10 (Inference Weight Sensitivity)
∀WAT = (AS, K, s), ∀A A′ over WAT,
Ant(A) = Ant(A′) ∧s(TopRule(A)) < s(TopRule(A′))
∧(∀A′′ ∈Ant(A), Str(A′′) > 0)
→Str(A) < Str(A′)
The Proportionality principle says that when two arguments have equally
strong top rules and for each of the ﬁrst argument’s antecedents the second
argument has a distinct antecedent with a lower strength, the ﬁrst argument’s
overall strength should be higher.
Principle 11 (Proportionality)
∀WAT = (AS, K, s), ∀A A′ over WAT,
s(TopRule(A)) = s(TopRule(A′))
∧there exists an injective function f : Ant(A) →Ant(A′)
such that ∀A′′ ∈Ant(A), Str(A′′) > Str(f(A′′))
→Str(A) > Str(A′)
Prescribing a single correct valuation, Weakest Link says an argument A’s
strength should be equal to the weight of its weakest premise or inference rule.
Principle 12 (Weakest Link)
∀WAT = (AS, K, s), ∀A over WAT, Str(A) = min({s(b)|b ∈Basis(A)})
The Weakest Link principle is so restrictive in what strengths it allows that
most methods of assigning strength will not satisfy it. Still, limiting the strength
of an argument to the weight of its weakest link seems to be a desirable property.
To accommodate this we introduce the Weakest-Link Limiting principle, which
states the intrinsic strength should be no higher than the weight of its weakest
premise or inference rule.
Principle 13 (Weakest-Link Limiting)
∀WAT = (AS, K, s), ∀A over WAT, Str(A) ≤min({s(b)|b ∈Basis(A)})
4
Assigning Intrinsic Strength
Having deﬁned a series of principles by which to evaluate methods for assigning
intrinsic strength to arguments, we now look to what said methods might be. Two

388
J. P. Spaans
methods that come to mind are the simple product method, where we multiply
the weights of all the premises and inference rules used in an argument (adding
a factor for each time a premise or rule is used) to determine this arguments
strength, and the weakest link method, where we equate the intrinsic strength
of an argument to the lowest weight of any premise or inference rule used in it.
Deﬁnition 13 (Simple Product Method). The simple product method (SP)
assigns any argument A over any WAT = (AS, K, s) an intrinsic strength equal
to the product of the weights of all members of Basis(A), such that:
Strsp(A) =

b∈Basis(A)
s(b)
Because Basis(A) = DefBasis(A) ⊎StrBasis(A), ∀b ∈StrBasis(A), s(b) = 1
(Deﬁnitions 5, 7 and 8) and 1 is the identity element for multiplication, this is
equivalent to:
Strsp(A) =

b∈DefBasis(A)
s(b)
Deﬁnition 14 (Weakest Link Method). The weakest link method (WL)
assigns any argument A over any WAT = (AS, K, s) an intrinsic strength equal
to the minimum of the weights of all members of Basis(A), such that:
Strwl(A) = min{s(b)|b ∈Basis(A)}
Example 3. We look at an example argument A4 with subarguments A1, A2 and
A3, shown in Fig. 2. Argument A1 states an axiomatic premise with weight 1.
a1
p1 ∼1
2
d1 ∼1
4
s1
C
c1
A1
A3
A4
A2
Fig. 2. An argument

Intrinsic Argument Strength in Structured Argumentation
389
A2 makes an inference from the premise stated in A1 using defeasible inference
rule d1 with strength 1
4. Argument A3 states an ordinary premise with weight
1
2. Finally, argument A4 uses strict inference rule s1 to infer its conclusion from
the conclusion of A2 and the premise stated in A3.
If we were to use the simple product method to assign strengths to A4 and
its subarguments, we would have:
– Strsp(A1) = 1 as it uses no rules and states an axiomatic premise.
– Strsp(A2) = 1 · 1
4 = 1
4; multiplying the weight of its one premise and its one
defeasible inference rule.
– Strsp(A3) = 1
2; the weight of the ordinary premise it states.
– Strsp(A4) = 1 · 1 · 1
4 · 1
2 = 1
8; the product of the weights of all the inference
rules and premises used in the argument.
If we were to use the weakest link method instead, we would have:
– Strwl(A1) = 1 as it uses no rules and states an axiomatic premise.
– Strwl(A2) = min(1, 1
4) = 1
4; the smallest weight of its one premise and its
one defeasible inference rule.
– Strwl(A3) = 1
2; the weight of the ordinary premise it states.
– Strwl(A4) = min(1, 1
4, 1
2) = 1
4; the smallest of the weights of all the inference
rules and premises used in the argument.
Note that for SP, because of the commutative and associative properties of
multiplication, instead of assigning strength equal to the product of the weights
of all the premises and inference rules used in an argument, we can equivalently
assign the weight of the premise for arguments just stating a premise and mul-
tiply the weight of the inference rule used with the strengths of the antecedent
arguments for an argument making an inference. This method better matches
the recursive nature of an argument. Similarly, we can keep the weight of the
premise for arguments just stating a premise and take the minimum of the weight
of the inference rule used and the strengths of the antecedent arguments for an
argument making an inference when using WL.
Theorem 1 (SP Works Recursively). For an argument A over a WAT =
(AS, K, s):
– if TopRule(A) = undeﬁned, Strsp(A) = s(Conc(A))
– else, Strsp(A) = s(TopRule(A)) · 
a∈Ant(A) Strsp(a)
Theorem 2 (WL Works Recursively). For an argument A over a WAT =
(AS, K, s):
– if TopRule(A) = undeﬁned, Strwl(A) = s(Conc(A))
– else, Strwl(A) = min(s(TopRule(A)), m)
where m = min({Strwl(a)|a ∈Ant(A)})
Note 1. A proof for Theorem 1 is provided in the appendix. A proof for Theorem
2 can be constructed in the same fashion.

390
J. P. Spaans
We now look to each of the principles deﬁned in the previous section and
determine which are satisﬁed by the simple product method and the weakest
link method respectively:
Theorem 3. SP satisﬁes Anonymity, Premising, Strict Argument, Resilience,
Argument Death, Antecedent Maximality, Antecedent Neutrality, Antecedent
Weakening, Inferential Weakening, Inference Weight Sensitivity, Proportionality
and Weakest-Link Limiting. SP does not satisfy Weakest Link.
Theorem 4. WL satisﬁes Anonymity, Premising, Strict Argument, Resilience,
Argument Death, Antecedent Maximality, Antecedent Neutrality, Weakest Link
and Weakest-Link Limiting.
WL does not satisfy Antecedent Weakening, Inferential Weakening, Inference
Weight Sensitivity or Proportionality.
A full formal proof for every element of Theorem 3 can be found in the
appendix. Many of the proofs to support Theorem 4 are very similar to those
used for Theorem 3. Because of this, combined with the fact that in Sect. 6 we
take a closer look at the class WL belongs to and how this class relates to our
principles, we take a more informal approach with Theorem 4 and oﬀer a proof
sketch in the appendix instead.
5
Aggregation Methods
In the previous section we proposed two methods for assigning intrinsic strength
to arguments. We saw that the simple product method satisﬁes most of the
principles proposed in Sect. 3. The weakest link method satisﬁes signiﬁcantly
fewer of the principles, but nevertheless represents an intuitive concept. We
also saw that both methods can be rewritten to not derive the assigned strength
directly from the basis of an argument as a whole, but rather to assign arguments
that state a premise a strength based on the weight of that premise and to
assign arguments that make an inference a strength based on an aggregation of
the strengths of the argument’s antecedents combined with the weight of the
applied inference rule.
In this section we introduce a technique that we may use to come up with new
methods for assigning strength, based on the rewriting of our previous methods.
We combine two functions, one to aggregate the strengths of the antecedents
of the argument we are assessing and the other to combine this aggregate with
the weight of the top rule used or inference made by the argument. This struc-
ture allows us to easily mix and match these two components to ﬁne-tune the
behaviour of our strength assigning method.
Deﬁnition 15 (Aggregation Method). An aggregation method M = (f, g) is
a pair of functions g : ∞
n=0[0, 1]n →[0, 1] and f : [0, 1] × [0, 1] →[0, 1] such that
g is symmetric, used to evaluate the intrinsic strength of an argument A over a
WAT = (AS, K, s) such that, when {A1, . . . , An} = Ant(A):

Intrinsic Argument Strength in Structured Argumentation
391
– If TopRule(A) is deﬁned, Str(A) = f(s(TopRule(A)), g(Str(A1), . . . , Str
(An))).
– Else, Str(A) = f(s(Conc(A)), g(Str(A1), . . . , Str(An))).
Here g aggregates the strengths of the antecedents of A and f combines the weight
of the inference or premise with the aggregated antecedent strengths.
This deﬁnition of an aggregation method is inspired by [3], where a similar
method is used to assign arguments an acceptability degree after attacks by
other arguments in a fully weighted argumentation graph.1
Using our new deﬁnition of an aggregation method, we can construct a
method that replicates the behaviour of our simple product method; take
Msp = (fprod, gprod) where:
fprod(x, y) = x · y
gprod(x1, . . . , xn) =
n

i=1
xi
Similarly we can replicate the weakest link method with Mwl = (fmin, gmin),
where:
fmin(x, y) = min{x, y}
gmin(x1, . . . , xn) =

1
if n = 0
min{x1, . . . , xn}
otherwise
We may now also recombine the functions we used to construct Msp and
Mwl to create other aggregation methods. For instance we might make a method
Mwm = (fprod, gmin) that looks at the weakest antecedent of an argument and
returns the product of said antecedent’s strength and the argument’s top rule
or premise, which we might call the weakening minimum method.
We want the user of the aggregation methods to be free to choose aggregation
functions that suit their use case. Therefore we deliberately left the choice of
aggregation functions in the deﬁnition of an aggregation method unconstrained
beyond the required symmetry of g. There are, however, some intuitive properties
we want our aggregation methods to satisfy. To ensure they do we introduce the
notion of a well-behaved aggregation method:
Deﬁnition 16 (Well-Behaved
Aggregation
Method). An aggregation
method M = (f, g) is considered well-behaved iﬀ:
1. f is non-decreasing in both variables whenever neither variable is 0.
2. f(0, x) = f(x, 0) = 0
1 In [3], a function is used to aggregate the weight of an attack with the weight of the
attacker, a second function is used to aggregate the results of the ﬁrst function for
all attacks and a third function is used to combine this second aggregate with the
initial weight of the argument under attack.

392
J. P. Spaans
3. f(x, 1) = f(1, x) = x
4. g() = 1
5. g(x) = x
6. g(x1, . . . , xn, 0) = 0
7. g(x1, . . . , xn) = g(x1, . . . , xn, 1)
8. g(x1, . . . , xn, y) ≤g(x1, . . . , xn, z) if y ≤z
We considered adding two requirements, being f(x, y) > 0 whenever x, y >
0 and g(x1, . . . , xn) > 0 whenever x1, . . . , xn > 0, that correspond to the
Resilience principle to the deﬁnition of a well-behaved aggregation method. We
ﬁnally decided against this, because we feel it should be permissible for an aggre-
gation method to ’kill’ an argument if its components are too weak. It should
be noted, however, that an aggregation method that kills oﬀarguments in this
way is precluded from satisfying Resilience.
It is plain to see how both Msp and Mwl satisfy all the requirements presented
in Deﬁnition 16 and, as such, are considered well-behaved aggregation methods.
Note how both f-functions we proposed are t-norms and both g-functions
make use of t-norms [9]. It would seem that when one is looking to create a novel
aggregation method, t-norms are a good place to look, at least for functions f.
For functions g one might be tempted to also look to common aggregate functions
such as the mean or median, but using these often results in a non-well-behaved
aggregation method (speciﬁcally violating Deﬁnition 16 Point 7).
What follow are a few more examples of functions we could use to construct
an aggregation method. For function f we might also use the Hamacher product
fHam or the Lukasiewicz t-norm fLuk, both being t-norms:
fHam(x, y) =

0
if x = y = 0
xy
x+y−xy
otherwise
fLuk(x, y) = max(0, x + y −1)
We might base our function g on the same two t-norms, adding special cases for
when an argument has no or just one antecedent, giving us gHam and gLuk:
gHam(x1, . . . , xn) =
⎧
⎪
⎨
⎪
⎩
1
if n = 0
x1
if n = 1
x1 ⊕· · · ⊕xn
otherwise
where x1 ⊕x2 =

0
if x = y = 0
xy
x+y−xy
otherwise
gLuk(x1, . . . , xn) =
⎧
⎪
⎨
⎪
⎩
1
if n = 0
x1
if n = 1
x1 ⊕· · · ⊕xn
otherwise
where x1 ⊕x2 = max(0, x + y −1)

Intrinsic Argument Strength in Structured Argumentation
393
Like the functions making up Msp and Mwl, the functions f and g proposed here
satisfy their respective requirements for an aggregation method based on them
to be well-behaved.
6
Properties of Aggregation Methods
When choosing functions to construct an aggregation method, t-norms have the
clear beneﬁts of being commutative, monotonic and associative, as well as having
1 as their identity element and 0 as a null-element. These properties make it so
that when we pick a t-norm for f and we base our g on a t-norm as we did for
gHam, making sure an empty input results in value 1 and a single input value x
results in output value x, we are guaranteed to have a well-behaved aggregation
method.
We now look at the principles proposed in Sect. 3 to see how they relate to
(well-behaved) aggregation methods.
Our ﬁrst observation is that all aggregation methods satisfy Anonymity. This
is because two isomorphic arguments have the same shape and the same weights
for the premises and inference rules in the same places and an aggregation
method only considers these two factors. A formal proof for this can be found
in the appendix.
Theorem 5. Any aggregation method satisﬁes Anonymity.
The other principles are not necessarily satisﬁed by any aggregation method.
We see that a well-behaved aggregation method is guaranteed to satisfy seven
out of our thirteen principles, including Anonymity. This, however, does not
mean the other principles cannot be satisﬁed by an aggregation method. Take,
for instance, the well-behaved aggregation method Msp which, as demonstrated
in Sect. 4, satisﬁes ﬁve of the non-guaranteed principles.
Theorem 6. Beyond Anonymity, any well-behaved aggregation method is guar-
anteed to satisfy Premising, Strict Argument, Argument Death, Antecedent Max-
imality, Antecedent Neutrality and Weakest-Link Limiting.
The satisfaction of Resilience, Antecedent Weakening, Inferential Weakening,
Inference Weight Sensitivity, Proportionality, or Weakest Link is not guaranteed.
Once again, many of the proofs for Theorem 6 closely resemble those pre-
sented in Sect. 4. Some others are simple counterexamples. Because of this we
present only a proof sketch, which can be found in the Appendix.
7
Conclusion
In the ﬁeld of argumentation, the focus of much of the research done has been
on ﬁnding sensible ways of interpreting conﬂicts between arguments. The fruits
of this labour can be found in Dung semantics that accept or reject arguments

394
J. P. Spaans
based on the attack relations between them [6] and in the many gradual seman-
tics that assign these arguments acceptability degrees [3]. Both of these types
of semantics belong to what we call abstract argumentation. That is, they do
away with the internal structure of the arguments under consideration and look
only at the relations between arguments. While gradual semantics have emerged
that can take into consideration the weights of attacks and base weights of argu-
ments when determining arguments’ ﬁnal acceptability degree, no standard had
emerged for relating these weights to the structure of an argument.
What we set out to do in writing this paper is to investigate how to create
suitable methods for taking the structure of an argument and using it, com-
bined with weights for the premises and inference rules used in the argument, to
determine the intrinsic strength of an argument. Throughout this investigation
we related the method for assigning strength under inspection to a set of prin-
ciples corresponding to traits we deemed desirable, or at the least intuitive, in a
strength-assigning method.
The fact that we take the weights of premises and inference weights to cor-
respond to a degree of defeasibility, with strict rules and premises having weight
1 and defeasible rules and premises having weight <1, gives rise to a possible
criticism to our approach. Some might object to the idea of an argument being
‘punished’ twice for being defeasible: once by having a lowered intrinsic strength
and a second time by being opened up to attacks from other arguments.
The ﬁrst strength-assigning methods we looked at, the simple product
method (SP) and the weakest link method (WL), both take the weights of every
occurrence of a premise or inference rule in an argument as input when deter-
mining said argument’s intrinsic strength. We found SP to satisfy many of our
principles. WL satisﬁed fewer of our principles but nevertheless represents an
important concept, in that any argument can only be so strong as its weakest
link.
Our deﬁnition of an argument closely resembles that used in ASPIC+, the
system for structured argumentation introduced by Modgil and Prakken [11].
This deﬁnition allows for an argument to state a premise or to apply an inference
rule to the conclusions of a set of antecedent arguments. We saw how both SP
and WL can be equivalently redeﬁned to not take the strengths of the members
of the basis of an argument as input, but rather to assign an argument stating
a premise an intrinsic strength equal to the weight of said premise and for an
argument making an inference to combine the weight of the applied inference
rule with an aggregation of the strengths of its antecedent arguments. This
observation led to the introduction of aggregation methods.
An aggregation method is a combination of two functions that are used to
assign an argument an intrinsic strength; one function g to aggregate antecedent
argument strengths and another function f to combine the resulting aggregate
with the weight of the last applied inference rule or the stated premise. Aggre-
gation methods allow us to mix and match these two functions to easily create
new methods of assigning intrinsic strength to an argument.

Intrinsic Argument Strength in Structured Argumentation
395
To capture what behaviours we wanted aggregation methods to express, we
introduced the notion of a well-behaved aggregation method. One compelling
result here is that we found that whenever one picks a t-norm for f and bases
their g on a t-norm, the resulting aggregation method is guaranteed to be well-
behaved. A possible criticism to our deﬁnition of an aggregation method is that
the way it is used to assign an intrinsic strength to an argument is perhaps need-
lessly complicated. We deﬁne special cases for arguments making an inference
and those stating a premise, both using functions f and g, but what follows from
our notion of a well-behaved aggregation method is that we always want premis-
ing arguments to get assigned a strength equal to the weight of the premise they
state. It might have been more clear to change the case for premising arguments
to reﬂect this directly.
When relating well-behaved aggregation methods to the principles we deﬁned
earlier in the paper, we found that a well-behaved aggregation method is only
guaranteed to satisfy half of our principles. This ﬁnding might give rise to the
criticism that when the methods we ourselves deem well-behaved do not neces-
sarily satisfy our own principles, the principles may be too strict. We, however,
believe that this result is acceptable as our principles are intended not as require-
ments, but rather as formalisations of options.
We see a bright future for aggregation methods in structured argumentation.
Future work we would speciﬁcally like to see done is an exploration of the weak-
ening of the proposed principles that are not guaranteed to be satisﬁed by a
well-behaved aggregation method, such that they still express the same ideas,
but might be satisﬁed by all well-behaved aggregation methods. Another avenue
for future work we believe to be promising is an exploration of the relation-
ships between the proposed principles; we would, for instance, be interested to
see whether certain principles follow from (a combination of) other principles
or whether there are other properties, such as the guarantee that any subargu-
ment of an argument A is at least as strong as A, that hold as a consequence
of satisfying certain principles. Finally, we feel interesting prospects lie in the
development of aggregation methods tailored to speciﬁc use cases, making use
of the aggregation method’s easily adaptable nature.
Acknowledgements. Special thanks go out to Dragan Doder, for his expert guidance
in writing this paper, for introducing us to many of the topics we discuss and for always
being there to discuss new ideas. This paper would not have existed without his help.
Appendix
For a full version of this paper, including proofs and proof sketches, please refer
to https://arxiv.org/abs/2109.00318.
References
1. Amgoud, L., Ben-Naim, J., Doder, D., Vesic, S.: Acceptability semantics for
weighted argumentation frameworks. In: Sierra, C. (ed.) Proceedings of the

396
J. P. Spaans
Twenty-Sixth International Joint Conference on Artiﬁcial Intelligence, IJCAI 2017,
Melbourne, Australia, 19–25 August 2017, pp. 56–62. ijcai.org (2017). https://doi.
org/10.24963/ijcai.2017/9
2. Amgoud, L., Cayrol, C.: A reasoning model based on the production of acceptable
arguments. Ann. Math. Artif. Intell. 34(1–3), 197–215 (2002). https://doi.org/10.
1023/A:1014490210693
3. Amgoud, L., Doder, D.: Gradual semantics accounting for varied-strength attacks.
In: Elkind, E., Veloso, M., Agmon, N., Taylor, M.E. (eds.) Proceedings of the
18th International Conference on Autonomous Agents and MultiAgent Systems,
AAMAS 2019, Montreal, QC, Canada, 13–17 May 2019, pp. 1270–1278. Interna-
tional Foundation for Autonomous Agents and Multiagent Systems (2019). http://
dl.acm.org/citation.cfm?id=3331831
4. Benferhat, S., Dubois, D., Prade, H.: Argumentative inference in uncertain and
inconsistent knowledge bases. In: Heckerman, D., Mamdani, E.H. (eds.) UAI 1993:
Proceedings of the Ninth Annual Conference on Uncertainty in Artiﬁcial Intelli-
gence, The Catholic University of America, Providence, Washington, DC, USA,
9–11 July 1993, pp. 411–419. Morgan Kaufmann (1993). https://dslpitt.org/uai/
displayArticleDetails.jsp?mmnu=1&smnu=2&article id=606&proceeding id=9
5. Cayrol, C., Lagasquie-Schiex, M.: Graduality in argumentation. J. Artif. Intell.
Res. 23, 245–297 (2005). https://doi.org/10.1613/jair.1411
6. Dung, P.M.: On the acceptability of arguments and its fundamental role in non-
monotonic reasoning, logic programming and n-person games. Artif. Intell. 77(2),
321–358 (1995). https://doi.org/10.1016/0004-3702(94)00041-X
7. Dunne, P.E., Hunter, A., McBurney, P., Parsons, S., Wooldridge, M.J.: Weighted
argument systems: basic deﬁnitions, algorithms, and complexity results. Artif.
Intell. 175(2), 457–486 (2011). https://doi.org/10.1016/j.artint.2010.09.005
8. Kakas, A., Amgoud, L., Kern-Isberner, G., Maudet, N., Moraitis, P.: ABA: argu-
mentation based agents. In: McBurney, P., Parsons, S., Rahwan, I. (eds.) ArgMAS
2011. LNCS (LNAI), vol. 7543, pp. 9–27. Springer, Heidelberg (2012). https://doi.
org/10.1007/978-3-642-33152-7 2
9. Klement, E., Mesiar, R., Pap, E.: Triangular Norms, Trends in Logic, vol. 8.
Springer, Heidelberg (2000). https://doi.org/10.1007/978-94-015-9540-7
10. Knuth, D.E.: The Art of Computer Programming, Volume II: Seminumerical
Algorithms, 3rd edn. Addison-Wesley (1998). https://www.worldcat.org/oclc/
312898417
11. Modgil, S., Prakken, H.: The ASPIC+ framework for structured argumenta-
tion: a tutorial. Argument Comput. 5(1), 31–62 (2014). https://doi.org/10.1080/
19462166.2013.869766
12. Prakken, H.: Probabilistic strength of arguments with structure. In: Thielscher, M.,
Toni, F., Wolter, F. (eds.) Principles of Knowledge Representation and Reasoning:
Proceedings of the Sixteenth International Conference, KR 2018, Tempe, Arizona,
30 October–2 November 2018, pp. 158–167. AAAI Press (2018). https://aaai.org/
ocs/index.php/KR/KR18/paper/view/17978
13. Zhong, Q., Fan, X., Luo, X., Toni, F.: An explainable multi-attribute decision
model based on argumentation. Expert Syst. Appl. 117, 42–61 (2019). https://
doi.org/10.1016/j.eswa.2018.09.038

How Can You Resolve a Trilemma?
- A Topological Approach -
Kazuko Takahashi(B) and Tamon Okubo
Kwansei Gakuin University, 2-1, Gakuen, Sanda 669-1338, Japan
ktaka@kwansei.ac.jp
Abstract. This paper discusses how to escape a state in which argu-
mentation can reach no conclusion, by oﬀering a new argument. We
formalize our approach based on Dung’s abstract argumentation frame-
work (AF). When an AF has no stable extension, we have no mean-
ingful conclusion. We address the problem of whether it is possible to
revise this situation by adding an argument that attacks an existing one.
If possible, how many solutions can we generate and at what position
should it be added? We discuss this problem using an AF consisting of a
trilemma and show conditions depending on the topology of the AF. We
also address the point that a speciﬁc argument can be accepted or not
by this action. We extend the discussion into two possible directions: a
general N-lemma case and a set of AFs, each of which consists of several
trilemmas. It follows that when a large argumentation becomes stuck in
a practical situation, the position to which a counter-argument should
be added can be detected by a check of the topology of the AF.
Keywords: Abstract argumentation · Computational argumentation ·
Revision of argumentation · Graph topology
1
Introduction
Argumentation appears in many scenes in our daily life and has been studied
from various perspectives. In the ﬁeld of artiﬁcial intelligence and logic program-
ming, the Abstract Argumentation Framework (AF) introduced by Dung [15] has
been regarded as a strong framework to handle inconsistency and has generated
considerable work on computational argumentation [17].
An AF can be represented as a directed graph in which a node corresponds
to an argument, and an edge to an attack relation. When we consider an argu-
mentation as a graph, we ﬁnd several topological types. One type that attracts
our interest is that including a cycle, which means that arguments are attacked
by each other.
When two arguments A and B are attacked by each other, we cannot arrive
at a unique outcome that each agent can accept. In this case, either A or B is
This work was supported by JSPS KAKENHI Grant Number JP17H06103.
T. Okubo—Currently, Fuji Soft Incorporated.
c
⃝Springer Nature Switzerland AG 2021
P. Baroni et al. (Eds.): CLAR 2021, LNAI 13040, pp. 397–416, 2021.
https://doi.org/10.1007/978-3-030-89391-0_22

398
K. Takahashi and T. Okubo
Fig. 1. A trilemma in argumentation.
acceptable. Furthermore, consider what happens when three arguments, A, B,
and C, attack in such an order that A attacks B, B attacks C, and C attacks
A. We call this a trilemma. In this case, either one of A, B or C is acceptable.
However, this result is weak in the sense that each single argument does not
attack all of the other arguments. According to Dung’s semantics, such an AF
does not have a stable extension, and no argument is skeptically or credulously
accepted. In practical argumentation, the argumentation becomes stuck, and no
meaningful result is possible. We can escape from this sticky state by providing a
new counter-argument. Moreover, if we want a speciﬁc argument to be accepted,
we have to choose an appropriate position.
For example, consider the situation in which three agents give their argu-
ments:
a: We should go to Okinawa; it is cold in Hokkaido.
b: We should go to Tokyo because it costs a lot to go to Okinawa.
c: We should go to Hokkaido because we cannot ﬁnd beautiful scenery in
Tokyo.
In this case, these arguments constitute a trilemma (Fig. 1). If an agent adds
a new argument d, “It is risky to go to Tokyo now because of COVID-19,” then
the argument b is defeated, and as a result, a and d are accepted. Therefore, if
an agent wants her claim a to be accepted, she needs to oﬀer such an argument.
If the entire argumentation is larger, trilemmas may appear in many loca-
tions, and they may interact in complicated ways. In such a case, how can one
agent ﬁnd a way to persuade the others?
Changes in argumentation systems have been discussed in several works [14].
In these works, the authors consider the properties depending on the patterns
of change in extensions and do not discuss the position to which a new attack is
added. Here, we do not address the problem based on a principle of change in
extension types but in terms of positions where an argument will be added.
In this paper, we consider AFs consisting of trilemmas that share one or two
nodes. We investigate the properties of such an argument graph according to
each topology and formalize them. We focus on stable semantics, since this is
considered most suitable in a practical situation for drawing a plausible conclu-
sion that is admitted by all agents and that attacks every argument against the
conclusion.
More speciﬁcally, we discuss the problem of whether we can get an AF with
a stable extension by adding one argument and an attack to the AF without it.
If it is possible, we show the position to be added. We consider such a change

How Can You Resolve a Trilemma?
399
based on the topology. Starting from a simple trilemma, we discuss extensions
of the result in two directions: the N-lemma case and the meta-AF case.
Our aim is to resolve a stuck argumentation by oﬀering a counter-argument
for a practical situation, rather than to ﬁnd a general method that can be applied
to any argument graph including the ones that seldom appear in practical situ-
ations.
This paper is organized as follows. In Sect. 2, we describe basic concepts.
In Sect. 3 and in Sect. 4, we consider the stable extension in the case of an AF
including a single trilemma and an AF constructed by more than one trilemma,
respectively, as well as one including the N-lemma. In Sect. 5, we consider a case
of a meta-AF. In Sect. 6, we compare our approach with related works. Finally,
in Sect. 7, we present conclusions and directions for future research.
2
Basic Concepts
The abstract argumentation framework (AF), proposed by Dung [15], is a rep-
resentation of an argumentation structure, ignoring its content.
Deﬁnition 1 (argumentation framework (AF)). Argumentation Frame-
work (AF) is deﬁned as a pair ⟨A, R⟩where A is a set of arguments and
R ⊆A × A.
A pair (A, B) ∈R is called an attack, and it is said that A attacks B.
AF can be represented as a graph in which each node corresponds to an
argument, and each edge corresponds to an attack. In this paper, we consider a
ﬁnite AF.
Deﬁnition 2 (sub-AF). Let AF1 = ⟨A1, R1⟩and AF2 = ⟨A2, R2⟩be AFs. An
AF1 is said to be a sub-AF of AF2 if A1 ⊆A2 and R1 ⊆R2, and is denoted by
AF1 ⊆AF2.
Semantics is deﬁned either by an extension or labeling, which has a one-to-
one relation [2]. In this paper, we consider stable semantics.
Deﬁnition 3 (stable extension). Let ⟨A, R⟩be an AF. S ⊆A is said to be a
stable extension if the following two conditions hold.
– ¬∃A, B ∈S; (A, B) ∈R (There is no pair of arguments that attacks each
other (conﬂict-freeness).)
– ∀B ∈A \ S, ∃A ∈S; (A, B) ∈R (Each argument outside the set is attacked
by some argument in the set (stability).)
Deﬁnition 4 (labeling, complete labeling). Let ⟨A, R⟩be an AF. Labeling
is a total function from a set of arguments to a set {in, out, undec}. Labeling L
is said to be complete if the following conditions are satisﬁed for any argument
A ∈A.
– L(A) = in iﬀ∀B ∈A; (B, A) ∈R ⇒L(B) = out.
– L(A) = out iﬀ∃B ∈A; L(B) = in ∧(B, A) ∈R.

400
K. Takahashi and T. Okubo
Deﬁnition 5 (stable labeling). Let ⟨A, R⟩be an AF. For a complete labeling
L, if {A|A ∈A, L(A) = undec} = ∅, then it is called stable labeling.
It has been proven that stable extension and stable labeling coincide, that is,
a stable extension corresponds to exactly one stable labeling and vice versa [2].
In addition to these concepts, we introduce several new concepts and termi-
nology.
An AF with three arguments that constitutes a cycle is called a triangular
unit.
Deﬁnition 6 (triangular unit(TU)). An AF of the form ⟨{A, B, C}, {(A, B),
(B, C), (C, A)}⟩is called a triangular unit (TU), and is denoted by t(A, B, C).
When a TU is a sub-AF of an AF, then it is said that the AF includes a trian-
gular unit.
Deﬁnition 7 (connector, faucet). Let ⟨A, R⟩be an AF that includes a trian-
gular unit T = ⟨AT , RT ⟩. If (A, B) ∈R, A ∈A \ AT , B ∈AT , then B is said
to be a connector of T ; if (A, B) ∈R, A ∈AT , B ∈A \ AT , then A is said to be
a faucet of T .
Example 1. In Fig. 2, a is the connector, and b and c are faucets of t(a, b, c),
respectively.
Fig. 2. Example of a triangular unit (TU).
For a TU, a sub-AF connected to C, which includes C itself, from the outside
of the TU is called an input part to C and that connected from F, which includes
F itself, to the outside of the TU is called an output part from F (Fig. 2).
Deﬁnition 8 (input part, output part). (1) For an AF ⟨A, R⟩including
TU ⟨AT , RT ⟩, its sub-AF ⟨A1, R1⟩such that A1 = {A | ∃σ = (A1, . . . , An−1);
∀i(1 ≤i ≤n −1)(Ai, Ai+1) ∈R \ RT , where A1 = A, An = C ∈AT } ∪{C},
and R1 = {(A, B)|A, B ∈A1}, is called an input part to C.
(2) For an AF ⟨A, R⟩including TU ⟨AT , RT ⟩, its sub-AF ⟨A2, R2⟩such that
A2 = {B | ∃σ = (A1, . . . , An−1); ∀i(1 ≤i ≤n −1)(Ai, Ai+1) ∈R \ RT , where
A1 = F ∈AT , An = B} ∪{F}, and R2 = {(A, B)|A, B ∈A2}, is called an
output part from F.

How Can You Resolve a Trilemma?
401
Note that if a node C is not a connector, then input part to C consists of
only C. An AF may have several input parts or output parts.
Deﬁnition 9 (start-TU). A triangular unit included by an AF without a con-
nector is said to be a start-TU.
Deﬁnition 10 (whisker). For a new argument P and an attack I from P, a
pair ⟨P, I⟩is said to be a whisker, and P is said to be a whisker node.
Deﬁnition 11 (stable AF, repair.1) An AF with a stable extension is called
a stable AF, and one without a stable extension is called an unstable AF. For
an unstable AF, the act of revising it by adding a single whisker to get a stable
AF is called a repair.
The node to which a whisker is added is always labeled out when repaired,
from the deﬁnition of stable labeling.
Deﬁnition 12 (entrance, acceptance set). If we repair an unstable AF by
adding a whisker to a node E, then the node is called an entrance of AF and
their set is denoted by ent(AF), and the obtained stable extension is called an
acceptance set.
3
AF Including One Triangular Unit
We pick up a triangular unit as the simplest odd-length cycle, and consider a
ﬁnite AF that includes at most three TUs sharing their nodes. We assume that
the entire AF has no cycle other than TUs and that it is uncontroversial, that
is, there exists no arguments A and B connected by two diﬀerent paths of even-
length and odd-length. From this assumption, we have only one stable extension
as a result of repair, and we denote the acceptance set on the entrance E for AF
by acc(AF, E).
We address the following problems:
1. When an AF is unstable, is it possible to repair it?
2. If so, how many solutions are possible, and where are the entrances?
In this section, we discuss the case in which an AF includes TUs sharing
their nodes.
First, we discuss the case in which an AF includes only one TU.
When the TU has a faucet, the output part can be labeled without using
undec if TU can be labeled without using undec. Therefore, we investigate only
the case without a faucet.
1 The meaning of “repair” is not exactly the same as that used in [4].

402
K. Takahashi and T. Okubo
Fig. 3. An AF with one TU.
3.1
No Connector
If a TU has no connector, it is a start-TU, and it is trivial that a start-TU is
unstable.
Proposition 1. If AF includes only one start-TU, then it is unstable.
In this case, we can repair it.
Proposition 2. If an AF has only one start-TU, then we can repair it by taking
any node as an entrance, yielding three solutions.
Proof. Let AF be a triangular unit t(a, b, c). Assume that we add a whisker node
P to a without losing generality. Then, a becomes a connector of this TU. We
get a labeling L such that L(P) = in, L(a) = out, L(b) = in, L(c) = out, and
acc(AF, a) = {P, b}.
⊓⊔
We show three solutions in Fig. 3. Hereafter, in the ﬁgures, the pink nodes
and blue nodes show the arguments labeled in and out, respectively.
3.2
One Connector
When a TU has one connector, the AF has a stable extension depending on the
topology. We divide the AF into the TU and the input part to the connector
(both of which share the connector), and we consider labeling in each sub-AF.
If two labelings can give the same value to the connector, then the AF is stable.
Proposition 3. Let AF be an AF that includes a TU t(a, b, c) with the unique
connector a. Let L and LC be labelings of the AF and the input part to a,
respectively. Then, LC(a) = in iﬀAF has no stable extension.
Proof. (⇒) Assume that LC(a) = in. Then, L(a) should be in, and L(b) = out,
L(c) = in, which means that (c, a) is an attack from the node labeled in to the
node labeled in. This is a contradiction.
(⇐) Assume that LC(a) = out. Then, L(a) should be out. L(a) is out,
regardless of the value of L(c), from the deﬁnition of stable labeling. Therefore,
there exists a labeling L(a) = out, L(b) = in, L(c) = out, which means that
there exists a stable extension.
⊓⊔

How Can You Resolve a Trilemma?
403
If we add a whisker to an arbitrary node a in the TU, then that node becomes
a connector. Therefore, if the AF has no stable extension, then we add a whisker
to any node in the TU or any node in the input part so that LC(a) = out holds.
Proposition 4. Let AF be an unstable AF that includes a TU t(a, b, c) with
the unique connector a. Let LC be labelings of the input part to a. If there is no
branch in the input part to a, that is, no node in the input part is attacked by
more than one node, then we can repair it if we take a node in T or any node
x in the input part such that LC(x) = in holds as an entrance, and there are at
least three solutions.
Proof. Let L′ be a labeling of the AF obtained by adding a whisker.
Assume that we add a whisker to a. Then, L′(a) = out, and then, L′(b) = in,
L′(c) = out, which is stable.
Assume that we add a whisker to an arbitrary node x in the input part
such that LC(x) = in holds. Let L′
C be a label of the input part to a after the
whisker is added. Then we get L′
C(x) = out and L′
C(a) = out. Therefore, we
have L′(a) = out, L′(b) = in, L′(c) = out, which is stable. Note that if there is a
branch, then we need more than one whisker to make LC(a) = out, depending on
the number of edges from the connector to the branching point, and there is no
solution by adding only one whisker to the input part other than the connector.
Assume that we add a whisker to b. Then, L′(b) = out, and then, L′(c) = in,
L′(a) = out, which is stable.
Assume that we add a whisker to c. Then, L′(c) = out, and L′(a) = in,
L′(b) = out, which is stable.
Conversely, if we add a whisker to the other nodes, then we cannot repair
the AF.
Therefore, there are at least three solutions.
⊓⊔
3.3
k Connectors
We generalize the case in which the number of connectors is k (k = 0, 1, 2, 3).
Theorem 1. Let AF be an AF that includes a TU t(a, b, c). Let LA, LB and LC
be labelings to input part to a, input part to b, and input part to c, respectively.
Then, LA(a) = LB(b) = LC(c) = in iﬀAF has no stable extension.
Proof. (⇒) We show that we cannot deﬁne a stable labeling L to the AF. Assume
that L(a) = in. As such, L(b) = out, and then, L(c) = in. This indicates an
attack from the node labeled in to the one labeled in, which is a contradiction.
Assume that L(a) = out. Then, L(b) = LB(b) = in, L(c) = out, and L(a) =
LA(a) = in, which is a contradiction. Hence, AF has no stable extension.
(⇐) We prove the contraposition by assuming that LA(a) = out, without
losing generality. Assume that L(a) = out. Then, L(b) = in, and then, L(c) =
out and L(a) = LA(a) = out, which is consistent. Therefore, AF has a stable
extension.
⊓⊔

404
K. Takahashi and T. Okubo
(a) butterﬂy type
(b) diamond type
Fig. 4. AF with two TUs.
If AF has no stable extension, we can repair it.
Theorem 2. Let AF be an AF that includes a TU t(a, b, c). Let LA, LB, and
LC be labelings to input part to a, input part to b, and input part to c, respectively.
If the AF is unstable and each input part has no branch, then we can repair it
iﬀwe take any of the following nodes as an entrance:
1. any node x of input part to a such that LA(x) = in.
2. any node y of input part to b such that LB(y) = in.
3. any node z of input part to c such that LC(z) = in.
There are at least three solutions.
Proof. This can be proven, similarly to Proposition 4.
⊓⊔
4
Triangular Units Sharing Nodes
4.1
AF Including Two triangular units
Assume that AF includes two TUs that share their nodes. For simplicity, we
assume that each node in AF is included in at least one TU.
There are two topologies, depending on the number of nodes shared with
the two TUs. If only one node is shared, we call it the Butterﬂy type (B-type),
and if two nodes are shared, the Diamond type (D-type) (Fig. 4). In both types,
TUs have only one common connector. In B-type (Fig. 4(a)), both TUs have
the common connector c, and in D-type (Fig. 4(b)), both TUs have the common
connector b. The connectors are shown as red nodes in the ﬁgures. A node that
is not a connector is attacked by exactly one node. Neither of these AFs has a
stable extension, and we can repair them. We have three solutions in the case of
B-type (Fig. 5) and two solutions in the case of D-type (Fig. 6).
4.2
AF Including Three triangular units
Assume that AF includes three TUs that share their nodes. For simplicity, we
assume that each node in the AF is included in at least one TU. There are three
types of topology: BB-type (Fig. 7), BD-type (Fig. 10), and DD-type (Fig. 14),
depending on the types sharing nodes. None of these AFs have a stable extension,
and we can repair them.

How Can You Resolve a Trilemma?
405
Fig. 5. Solutions of B-type: ent(AF) = {a, c, e}.
Fig. 6. Solutions of D-type: ent(AF) = {b, c}.
In this case, there exist one or two connectors. If two connectors exist, the
position of the entrance is determined depending on the direction of an attack
between the connectors. For each topology, we show that we can repair it by
adding a whisker so that all the connectors are labeled out.
In the BB-type, each pair of TUs shares a single node. There are two topolo-
gies of the BB-type (Fig. 7).
(a) BB1
(b) BB2
Fig. 7. BB-type.
For the BB1-type, there are four solutions: ent(AF) = {c, d, a, g} (Fig. 8),
and for BB2-type, there are two solutions: ent(AF) = {d, f} (Fig. 9).
In the BD-type, a pair of TUs share a single node, and another pair of TUs
share an edge. There are three BD-type topologies (Fig. 10).
For the BD1-type, there are three solutions: ent(AF) = {b, c, e} (Fig. 11), for
the BD2-type, there are two solutions: ent(AF) = {c, e} (Fig. 12), and for the
BD3-type, there is one solution: ent(AF) = {b} (Fig. 13).
In the DD-type, two pairs of TUs share an edge. There are three DD-type
topologies (Fig. 14).

406
K. Takahashi and T. Okubo
Fig. 8. Solutions of BB1: ent(AF) = {c, d, a, g}.
Fig. 9. Solutions of BB2: ent(AF) = {d, f}.
For DD1-type, there are two solutions: ent(AF) = {b, c} (Fig. 15), for DD2-
type, there is one solution: ent(AF) = {b} (Fig. 16), and for DD3-type, there is
one solution: ent(AF) = {c} (Fig. 17).
4.3
AF Including k triangular units
From the investigation in Subsect. 4.1 and Subsect. 4.2, we show that the posi-
tions of the entrances can be determined generally for any topology presented
in these previous sections.
We restrict the target AF to the one that satisﬁes the following conditions,
since we want to clarify the properties of a trilemma itself, avoiding the AF that
does not frequently appear in a practical argumentation from our target.
Deﬁnition 13 (module). We call the AF that satisﬁes the following conditions
Cond a module.
[Cond]
1. The AF consists of at most three TUs sharing their nodes.
2. Each node in the AF is included in at least one TU.
3. It has no cycle other than TUs.
4. It is uncontroversial.

How Can You Resolve a Trilemma?
407
(a) BD1
(b) BD2
(c) BD3
Fig. 10. BD-type.
Fig. 11. Solutions of BD1: ent(AF) = {b, c, e}.
Theorem 3. 1. A module AF has no stable extension.
2. When AF = ⟨A, R⟩has one connector C, it can be repaired iﬀthe common
connector C or any node A that satisﬁes (C, A) ∈R is taken as an entrance.
3. When AF = ⟨A, R⟩has two connectors CA and CB such that (CA, CB) ∈
R, it can be repaired iﬀCB or any node B that satisﬁes (CB, B) ∈R and
(B, CA) ̸∈R is taken as an entrance.
Proof. 1. Since any TU included in AF is unstable, AF is unstable.
2. Assume that AF has one connector C. Let an arbitrary TU in AF be
t(A, B, C).
(a) If we add a whisker to the node C, then C is labeled out. Node A is
attacked only by C in AF. Therefore, if C is labeled out, then A is
labeled in. Then, B, which is attacked by A, should be labeled out. All
TUs can be labeled similarly, since the connector is common. Therefore,
AF can be repaired.
(b) If we add a whisker to the node A such that (C, A) ∈R, then A is labeled
out, B attacked only by A is labeled in and as a result, C is labeled out.
Therefore, AF can be repaired.
(c) In contrast, assume that we add a whisker to B. Then B is labeled out.
Let t′(C, A′, B′) be another TU that shares the connector C. If C is
labeled out, then A′ is labeled in, since A′ is attacked only by C; B′ is
labeled out, since B′ is attacked only by A′; and C is labeled in, since
both its attackers B and B′ are labeled out, which is a contradiction. If
C is labeled in, then A′ is labeled out and B′ is labeled in, and then C
should be out, which is a contradiction.

408
K. Takahashi and T. Okubo
Fig. 12. Solutions of BD2: ent(AF)
= {c, e}.
Fig. 13. Solution of BD3: ent(AF)
= {b}.
(a) DD1
(b) DD2
(c) DD3
Fig. 14. DD-type.
3. Assume that AF has two connectors CA and CB such that (CA, CB) ∈R.
Let t(A, CA, CB) be an arbitrary TU in AF that has two connectors, and
t(CA, D, E) be an arbitrary TU in AF that has one connector CA.
(a) If we add a whisker to CB, then CB is labeled out. Node A is attacked
only by CB. Therefore, if CB is labeled out, then A is labeled in. Then, CA
which is attacked by A, should be labeled out. As for t(CA, D, E), node
D is labeled in since it is attacked only by CA, and node E is labeled out
since it is attacked only by D. A TU that shares only CB can be labeled
without a contradiction for the same reason as that in the case of one
connector. Therefore, AF can be repaired.
(b) If we add a whisker to the node B that satisﬁes (CB, B) ∈R and
(B, CA) ̸∈R, then B is labeled out. Let t(CB, B, F) be a TU that has
only one connector CB. Then B is labeled out, regardless of the label of
its other attacker. And F, attacked only by B, is labeled in, and CB is
labeled out. Therefore, AF can be repaired.
(c) In contrast, assume that we add a whisker to CA. Then, CA is labeled out.
Let t(CB, B, F) be another TU that has only one connector CB. If CB is
labeled in, then B is labeled out, and then F is labeled in. Therefore, CB
is labeled out, since CB is attacked by F, which is a contradiction. If CB
is labeled out, then B is labeled in, and then F is labeled out. Therefore,
CB should be in, since CB is attacked by F and CA, both of which are
labeled out, which is a contradiction. When we add a whisker to the other
node, a similar discussion follows.
⊓⊔
This theorem shows that we can ﬁnd an entrance by simply checking the
topology of an AF.

How Can You Resolve a Trilemma?
409
Fig. 15. Solutions of DD1: ent(AF) = {b, c}.
Fig. 16. Solution of DD2: ent(AF)
= {b}.
Fig. 17. Solution of DD3: ent(AF) = {c}.
Example 2. The BB2-type AF ⟨A, R⟩, shown in Fig. 7(b), has connectors c and
d such that (c, d) ∈R, (d, f) ∈R, and (f, c) ̸∈R hold. Therefore, d and f are
entrances (Fig. 9).
In contrast, the BD3-type AF ⟨A, R⟩, shown in Fig. 10(c), has connectors b
and d such that (d, b) ∈R, (b, c) ∈R, and (c, d) ∈R hold. Therefore, b is an
entrance, but c is not (Fig. 13).
Theorem 3 does not always hold if the AF consists of more than three TUs.
For example, the AF shown in Fig. 18, which has three connectors, c, e and f,
cannot be repaired.
Fig. 18. AF that cannot be repaired.
4.4
Acceptance of a Speciﬁc Argument
We have discussed the entrances to obtain a stable AF. The next question is
whether we can ﬁnd a solution in which a speciﬁc argument can be accepted,
that is, ﬁnd an entrance on which an acceptance set includes the argument. The
above investigation shows that it is impossible to make the connector be an

410
K. Takahashi and T. Okubo
accepted argument in the case of a trilemma. How about the arguments other
than the connector? Unfortunately, it is impossible to ensure that some speciﬁc
arguments will be accepted, even if any position is selected as an entrance in
some topology. For example, see the solutions for BB2-type shown in Fig. 9. In
this case, ¬∃E; b ∈acc(AF, E), and we have to add more than one whisker to
the graph to make b accepted.
4.5
N-Lemma
Theorem 3 holds not only for a trilemma but also N-lemma for any ﬁnite N =
2m + 1.
Deﬁnition 14 (odd-unit). An AF of the form ⟨{A1, . . . , A2m+1}, {(A1, A2),
(A2, A3), . . . , (A2m, A2m+1), (A2m+1, A1)}⟩is called an odd-unit and is denoted
by t(A1, . . . , A2m+1).
We set the Cond N by replacing the term ‘TU’ in Cond by ‘odd-unit’, and
obtain the following theorem.
Theorem 4. 1. The AF that satisﬁes Cond N has no stable extension.
2. When AF = ⟨A, R⟩has one connector C, it can be repaired iﬀthe com-
mon connector C or any node B such that there exists a sequence of attacks
(Bi, Bi+1) ∈R (1 ≤i ≤2s −1) where B1 = C and B2s = B is taken as an
entrance.
3. When AF has two connectors CA and CB such that there exists a sequence of
attacks (Ai, Ai+1) ∈R (1 ≤i ≤2h−1) where A1 = CA and A2h = CB. Then,
it can be repaired iﬀa node B that satisﬁes one of the following conditions is
taken as an entrance:
(i) B = CB
(ii) B is a node of an odd-unit including both CA and CB and there exists a
sequence of attacks (Bi, Bi+1) ∈R (1 ≤i ≤2s −1) where B1 = CA and
B2s = B.
(iii) B is a node of an odd-unit including CB but not CA, and there exists a
sequence of attacks (Bi, Bi+1) ∈R (1 ≤i ≤2s −1) where B1 = B and
B2s = CB and each Bi (1 ≤i ≤2s −1) is not shared with the other
odd-units.
The theorem can be proved using the properties that all the nodes but for
the connectors are attacked only by one node, respectively, and that the label of
the entrance is always out.
Sketch of Proof. Due to space constraints, here we discuss the case in which AF
has one connector. Let t(A1, . . . , A2m+1) be an arbitrary odd-unit.
Assume that it shares an odd number of nodes A1, A2, . . . , A2t−1 where
(Ai, Ai+1) ∈R (∀i; 1 ≤i ≤2t, t ≤m). Then, A1, A3, . . . , A2t−1 have the
same label, since each of them is attacked only by one node. Thus, we can
consider labeling by reducing A1, A2, . . . , A2t−1 to one node. Then, the num-
ber of shared nodes can be considered as one. Similarly, since non-shared nodes

How Can You Resolve a Trilemma?
411
A2t, A2t+2, . . . , A2m have the same label, we can consider labeling by reducing
A2t, A2t+1, . . . , A2m to one node. Then, the number of the non-shared nodes can
be considered as two. As a result, the problem is reduced to the one in the case
of a trilemma.
If
an
odd-unit
t(A1, . . . , A2m+1)
shares
an
even
number
of
nodes
A1, A2, . . . , A2t, the problem is reduced to the one of a trilemma consisting of
two shared nodes and one non-shared node.
⊓⊔
Note that diﬀerent from the case of a trilemma, the connector is not neces-
sarily labeled out when repaired (Fig. 19).
(a) unstable AF including 5-lemmas (b) labeling when a whisker is added
Fig. 19. Repaired AF in which the connector is not labeled in.
5
Connected Modules
In this section, we consider an AF consisting of modules connected by edges that
are not included in any TU.
Deﬁnition 15 (meta-AF). Let M be a set of modules {M1, . . . , Mk}, where
Mi = ⟨Ai, Ri⟩. Let AF(M) be an AF ⟨A, R⟩where A = k
i=1 Ai, R = k
i=1 Ri ∪
{(Ai, Bj)|Ai ∈Ai, Bj ∈Aj(1 ≤i ̸= j ≤k)}. Then, AF(M) is said to be a meta-
AF of M.
We deﬁne the terms connector, faucet, and start-module for meta-AF, simi-
larly with the case of a single triangular unit.
Deﬁnition 16 (connector, faucet, start-module). Let M be a set of mod-
ules {M1, . . . , Mk}, where Mi = ⟨Ai, Ri⟩. Let AF(M) be a meta-AF of M.
If (A, B) ∈R, A ∈A \ Ai, B ∈Ai, then B is said to be a connector of
Mi; if (A, B) ∈R, A ∈Ai, B ∈A \ Ai, then A is said to be a faucet of Mi.
conn(Mi) and faucet(Mi) denote the set of connectors and that of faucets of
Mi, respectively. A module without a connector is said to be a start-module.
For simplicity, we assume that no module is isolated and that each pair of
modules is connected by at most one edge. Note that {M1, . . . , Mk} is not nec-
essarily connected linearly. Each Mi may have more than one connector and/or
faucet.

412
K. Takahashi and T. Okubo
Example 3. Figure 20 shows an AF that consists of four modules. M1 is a start-
module. The connector and faucets of these modules are: conn(M1) = {},
faucet(M1) = {d, f}, conn(M2) = {h}, faucet(M2) = {j}, conn(M3) = {p},
faucet(M3) = {q}, and conn(M4) = {k, m}, faucet(M4) = {}.
Fig. 20. Connected modules without a meta-cycle.
AF(M) is unstable since each module is unstable.
Proposition 5. AF(M) is unstable.
Let M be a set of modules {M1, . . . , Mk}, where Mi = ⟨Ai, Ri⟩. Let AF(M)
be a meta-AF of M. In the following, we discuss its repair.
If there exists more than one start-module, then we have no solution since we
have to add a whisker to each start-module so that each of them is stable. If there
is one start-module, a conﬁguration of modules should satisfy some condition so
that it is possible to be repaired.
Proposition 6. Let M = {M1, . . . , Mk} and AF(M) = ⟨A, R⟩. Assume that
AF(M) has exactly one start-module.
We can repair AF(M) by setting the connector E of the start-module as an
entrance iﬀthe following three conditions hold for each Mi ∈M:
1. If Mi is a start-module, then ∃E, F; (E ∈ent(M) ∧F ∈acc(Mi, E)).
2. If Mi is not a start-module, let (Fl, Ci) ∈R (1 ≤l ̸= i ≤k) where Fl ∈
faucet(Ml),
then ∃Ci; (Ci ∈conn(Mi) ⇒Ci ∈ent(Mi) ∧Fl ∈acc(Ml, Cl)).
3. If Mi is not a start-module and if ∃Di; Di ̸= Ci, Di ∈conn(Mi), let (Fj, Ci) ∈
R (1 ≤j ̸= i, l ≤k) where Fj ∈faucet(Mj), then Di ∈acc(Mi, Ci) ⇔Fj ̸∈
acc(Mj, Cj).
Sketch of Proof. First, let M be a start-module. If we add a whisker to an
entrance E of M, then we can repair M.
Next, let M not be a start-module. Then, it has a connector.

How Can You Resolve a Trilemma?
413
Assume that Mi (1 ≤i ≤k) has only one connector Ci. From the second
condition, Ci is labeled out since the faucet Fl is labeled in, and it is an entrance
of Mi. Therefore, Mi has a stable labeling. Let L be this labeling.
Assume that Mi (1 ≤i ≤k) has a connector Di diﬀerent from Ci. From the
third condition, L(Di) = in iﬀL(Fj) = out, and L is a consistent labeling to
Mi.
Therefore, AF(M) can be repaired.
⊓⊔
Example 4. Consider the AF shown in Fig. 20.
For a start-module M1, it is a BB2-type module where ent(M1) = {a, c} and
acc(M1, c) = {a, d, f}. Since c ∈ent(M1) and d ∈acc(M1, c), the ﬁrst condition
is satisﬁed.
For M2, ent(M2) = {h, i, j} and acc(M2, h) = {i}. For the connector h of
M2 where (d, h) ∈R, h ∈ent(M2) ∧d ∈acc(M1, c) holds. For M3, ent(M3) =
{p, q, r} and acc(M3, p) = {q}. For the connector p of M3 where (f, p) ∈R, p ∈
ent(M3)∧f ∈acc(M1, c) holds. For M4, ent(M4) = {k, m, n} and acc(M4, m) =
{k, o}. For the connector m of M4 where (q, m) ∈R, m ∈ent(M4) ∧q ∈
acc(M3, p) holds. Therefore, the second condition is satisﬁed.
M4 has one more connector k where (j, k) ∈R, j ∈faucet(M2). j ̸∈
acc(M2, h) ∧k ∈acc(M4, m) holds. Therefore, the third condition is satisﬁed.
Hence, we can repair it by adding a whisker node P to c, and the obtained
stable extension is {P, a, d, f, i, k, o, q}.
Example 5. For the AF in Fig. 20, assume that an attack (f, p) is replaced by
(f, r).
For M3, conn(M3) is changed to {r}, and acc(M3, r) = {p}. As a result, in
M4, q ̸∈acc(M3, r), which breaks the second condition.
Therefore, we cannot repair it.
Proposition 6 can be extended for an AF(M) that has a meta-cycle. In this
case, we must consider the connections between modules.
Example 6. Figure 21 presents an AF consisting of four modules that constitute
a meta-cycle. In this case, we regard an arbitrary module as a start-module.
We take M1 as a start-module where ent(M1) = {a, c} and acc(M1, a) =
{b, d, f}. Since a ∈ent(M1) ∧d ∈acc(M1, a), the ﬁrst condition is satisﬁed.
It can be checked that the second condition is satisﬁed for each module.
In this case, it can be considered that M1 has a connector f in addition to a,
where (p, f) ∈R, p ∈faucet(M4). And p ̸∈acc(M4, q) ∧f ∈acc(M1, a) holds.
Therefore, the third condition is satisﬁed.
Therefore, we can repair it by adding a whisker node P to a, and the obtained
stable extension is {P, b, d, f, i, l, m, r}.

414
K. Takahashi and T. Okubo
Fig. 21. Connected modules with a meta-cycle.
6
Related Works
In general, the main issue in changing an argumentation framework is the possi-
bility of modiﬁcation so that a set of arguments becomes a subset of an extension.
This issue was introduced as an enforcing problem and was ﬁrst discussed in [4].
Subsequently, considerable work has been done on this problem [14].
Boella et al. discussed the change in grounded semantics if we add or remove
an attack relation [8,9]. They investigated the properties of the grounded exten-
sions, such as expansive change or narrowing change.
Cayrol et al. expanded this discussion to several kinds of semantics including
stable semantics. They investigated the properties of the change in extensions
with regard to the addition and removal of an argument with an attack. They
ﬁrst investigated a single attack and then extended the procedure to addition and
removal of multiple attacks [10–12]. They showed that some propositions depend
on the changing type of extensions, but they did not address the classiﬁcation
of topological features, and not all topological patterns were covered.
Coste-Marquis et al. addressed the revision of extension on changing an
attack relation between existing arguments as well as adding an argument with
an attack [13].
Alfono et al. developed an eﬃcient algorithm to compute the extension of
the revised AF by adding an attack between existing arguments [1].
Baumann et al. showed the minimal change required in an extension to accept
a given set of arguments [4], speciﬁcally, the change in extensions under several
semantics for addition and removal of arguments and attacks [6,7]. They investi-
gated the change in extensions in various cases. The complexity for the revision
was also discussed [5,19].
These works focused mainly on how to ﬁnd a solution to realize a minimal
change in an extension and the type of properties involved in changes in exten-
sions. In contrast, we did not focus on the properties of changes in extensions.
Instead, we investigated the position to which an attack from a new argument
is added. Speciﬁcally, we considered the AF consisting of TUs that has no sta-

How Can You Resolve a Trilemma?
415
ble extension and discussed the problem of how to modify it, depending on the
topology. We also attempted to resolve the case of general odd-length cycles.
Some works have utilized the topological features of an argument graph for
the treatment of dynamic argumentation frameworks [3,16]. They used simple
topological features such as symmetry and similarity to reduce the complexity
of computing changes in extensions, whereas we investigated the relationship of
the topological feature and the possibility of repair.
A repair shown in our work can be regarded as an abduction in logic pro-
gramming, in the sense of ﬁnding a minimal change in the knowledge base by
adding a fact and a rule. ˇSefr´anek described the relationship between a dynamic
argumentation framework and revision of logic programming [18]. It would be
interesting to relate our approach to an abduction of logic programming.
7
Conclusion
We investigated the conditions under which an unstable AF consisting of a tri-
angular unit can be revised to be stable by adding a new attack from a new
argument. We have shown the positions to be added and the number of solu-
tions.
The main contribution of our work is showing a uniform treatment of a
trilemma in AFs using its topological features. We also discussed how the result
can be extended in two possible directions. One is an extension from the trilemma
to N-lemma for any odd-number N ≥3, and the other is the case in which
multiple triangular units are connected by edges that are not included in any
triangular unit.
The results suggest that we can use topological features, such as connection
patterns and the direction of edges, to obtain a stable AF. It follows that when
a large argumentation falls into a sticky state, the position to which a counter-
argument should be added can be detected by checking the topology of the AF.
Three main problems remain for future research. First, we should investigate
the case in which a module includes more than three trilemmas (or N-lemmas).
Second, we would like to explore other types of topology, such as those including
even-length cycles and other semantics. Third, we plan to discuss the complex-
ity of ﬁnding a position. It is not expensive to detect the connectors and the
entrances for each topology, but a high computational cost may be incurred to
identify its topology.
References
1. Alfaso, G., Greco, S., Parisi, F.: Incremental computation in dynamic argumenta-
tion frameworks. IEEE Intell. Syst. 36(2), 6–12 (2021)
2. Baroni, P., Caminada, M., Giacomin, M.: An introduction to argumentation
semantics. Knowl. Eng. Rev. 26(4), 365–410 (2011)
3. Baroni, P., Giacomin, M., Liao, B.: On topology-related properties of abstract
argumentation semantics. A correction and extension to dynamics of argumenta-
tion systems: a division-based method. Artif. Intell. 212, 104–115 (2014)

416
K. Takahashi and T. Okubo
4. Baumann, R., Brewka, G.: Expanding argumentation frameworks: enforcing and
monotonicity results. In: COMMA 2010, pp. 75–86 (2010)
5. Baumann, R., Ulbricht, M.: If nothing is accepted - repairing argumentation frame-
works. In: KR 2018, pp. 108–117 (2018)
6. Baumann, R., Brewka, G.: Extension removal in abstract argumentation - an
axiomatic approach. In: AAAI 2019, pp. 2670–2677 (2019)
7. Baumann, R., Gabbay, D.M., Rodrigues, O.: Forgetting an argument. In: AAAI
2020, pp. 2750–2757 (2020)
8. Boella, G., Kaci, S., van der Torre, L.: Dynamics in argumentation with sin-
gle extensions: abstraction principles and the grounded extension. In: Sossai, C.,
Chemello, G. (eds.) ECSQARU 2009. LNCS (LNAI), vol. 5590, pp. 107–118.
Springer, Heidelberg (2009). https://doi.org/10.1007/978-3-642-02906-6 11
9. Boella, G., Kaci, S., van der Torre, L.W.N.: Dynamics in argumentation with single
extensions: attack reﬁnement and the grounded extension. In: AAMAS 2009, pp.
1213–1214 (2009)
10. Cayrol, C., de Saint-Cyr, F.D., Lagasquie-Schiex, M.-C.: Change in abstract argu-
mentation frameworks: adding an argument. J. Artif. Intell. Res. 38, 49–84 (2010)
11. Cayrol, C., de Saint-Cyr, F.D., Lagasquie-Schiex, M.-C.: Revision of an argumen-
tation system. In: KR 2008, pp. 124–134 (2011)
12. Cayrol, C., Lagasquie-Schiex, M.-C.: Weighted argumentation systems: a tool for
merging argumentation systems. In: ICAI 2011, pp. 629–632 (2011)
13. Coste-Marquis, S., Konieczny, S., Mailly, J.-G., Marquis, P.: Extension enforcement
in abstract argumentation as an optimization problem. In: IJCAI 2015, pp. 2876–
2882 (2015)
14. Doutre, S., Mailly, J.-G.: Constraints and changes: a survey of abstract argumen-
tation dynamics. Argum. Comput. 9(3), 223–248 (2018)
15. Dung, P.M.: On the acceptability of arguments and its fundamental role in non-
monotonic reasoning, logic programming and n-person games. Artif. Intell. 77,
321–357 (1995)
16. Liao, B., Jin, L., Koons, R.C.: Dynamics of argumentation systems: a division-
based method. Artif. Intell. 175(11), 1790–1814 (2011)
17. Rahwan, I., Simari, G.R. (eds.): Argumentation in Artiﬁcial Intelligence. Springer,
Heidelberg (2009)
18. ˇSefr´anek, J.: Updates of argumentation frameworks. In: NMR 2012 (2012)
19. Wallner, J.P., Niskanen, A., J¨arvisalo, M.: Complexity results and algorithms for
extension enforcement in abstract argumentation. J. Artif. Intell. Res. 60, 1–40
(2017)

A Multi Attack Argumentation
Framework
Alexandros Vassiliades1,2(B), Giorgos Flouris2, Theodore Patkos2,
Antonis Bikakis3, Nick Bassiliades1, and Dimitris Plexousakis2
1 School of Informatics, Aristotle University of Thessaloniki, Thessaloniki, Greece
{valexande,nbassili}@csd.auth.gr
2 Institute of Computer Science, Foundation for Research and Technology, Hellas,
Heraklion, Greece
{fgeo,patkos,dp}@ics.forth.gr
3 Department of Information Studies, University College London, London, UK
a.bikakis@ucl.ac.uk
Abstract. This paper presents a novel abstract argumentation frame-
work, called Multi-Attack Argumentation Framework (MAAF), which
supports diﬀerent types of attacks. The introduction of types gives rise to
a new family of non-standard semantics which can support applications
that classical approaches cannot, while also allowing classical semantics
as a special case. The main novelty of the proposed semantics is the
discrimination among two diﬀerent roles that attacks play, namely an
attack as a generator of conﬂicts, and an attack as a means to defend an
argument. These two roles have traditionally been considered together
in the argumentation literature. Allowing some attack types to serve one
of those roles only, gives rise to the diﬀerent semantics presented here.
1
Introduction
Many models for reasoning with arguments are grounded on Dung’s abstract
argumentation framework (AAF) [8], where the only ingredients are a set of
arguments and a binary attack relation on that set. The simplicity and intu-
itiveness of this model led to its wide acceptance, and, at the same time, helped
reveal additional features that needed to be devised, in order to accommodate
the requirements of diverse domains. For instance, AAFs are based on the strong
assumption that all arguments and all attacks have the same strength; many vari-
ations have been proposed in order to overcome this limitation, which consider
preferences on arguments [2] or attacks [11], add weights to arguments [1] or
attacks [9], associate arguments with values [5], or impose hierarchies on argu-
ments [12].
In this paper, we focus on accommodating a diﬀerent need, namely to support
a reasoning argumentation model where the attack relation among arguments
can be of diﬀerent types. This gives rise to a new class of semantics, which is
based on a treatment of diﬀerent attack types. Note that an attack, in the stan-
dard argumentation literature, is used both as a conﬂict-generator (i.e., creating
c
⃝Springer Nature Switzerland AG 2021
P. Baroni et al. (Eds.): CLAR 2021, LNAI 13040, pp. 417–436, 2021.
https://doi.org/10.1007/978-3-030-89391-0_23

418
A. Vassiliades et al.
conﬂicts which disallow conﬂicting arguments to be put in the same extension
and which create the need for defense) and as a defender (i.e., defending other
arguments against attacks). Separating these two roles, and allowing certain
attacks to be treated in the non-classical way (e.g., allowing them to play only
one of these two roles), gives rise to various non-classical semantics which may
ﬁnd applications in diﬀerent settings.
Consider, for example, the process of a trial. The presumption of innocence is
so important that only speciﬁc types of attacks on the defendant’s claims should
be taken into consideration by the jury, e.g., claims by eye witnesses, experts
etc. Other attacks, e.g., on the defendant’s credibility, prior life choices etc., that
generate doubts, should not be accounted for as evidence for conviction and need
to be ignored. Interestingly, these latter types of attacks should still be considered
relevant when placed against the claims of eye witnesses, experts etc., in order to
ensure that the beneﬁt of the doubt is given to the claimant. Figure 1 provides
such an example. Intuitively, A1, A3 and A4 should all be acceptable; the latter
two, because they do not receive any attacks so there is no reason not to accept
them, and A1 because questioning the credibility of the defendant (attack from
A3) should not be enough to lead to conviction. The same type of attack (i.e.,
credibility), however, should still be suﬃcient to defend the defendant’s claims
from other attacks; in this case, for example, questioning the credibility of the
witness (attack from A4 to A2) should be enough to defend the defendant from
the witness’ testimony (attack from A2 to A1).
Fig. 1. Credibility attacks should be treated diﬀerently when they may lead to convic-
tion than when they protect from it.
Notice that modeling diﬀerent attack types is not always the same as model-
ing diﬀerent argument types; while many of the existing AFs that characterize
arguments and certain argument relations can indeed transfer this information
to the attack relation, in the form of a strength value or a preference relation
(see for example [7]), the inverse is not always possible. Attack types, such as
rebuttals, undermines or undercuts, do not characterize the argument per se, but
rather the relation between two arguments. Similarly, characterizing an attack
as being of type irrelevant, i.e., arguing that a given argument is irrelevant in a
given context, is not information inherent in the formulation of the argument,

An MAAF
419
but, in a sense, on the placement of the argument in the argumentation tree.
Eliminating (ﬁltering) attacks made by irrelevant arguments, before generating
the sets of acceptable extensions of a dialogue, can therefore be considered a
beneﬁcial pre-processing step.
The objective of this paper is to provide a framework that supports the
above scenarios, by introducing two important novelties. The ﬁrst is the intro-
duction of attack types, that allows treating diﬀerent attacks in a diﬀerent man-
ner. The second is the separation among the two roles of attacks, namely as
conﬂict-generators and as defenders. In particular, by seeing these two functions
of attacks as separate, and allowing some of the attacks to be used for only one,
or both, of these roles, we get three diﬀerent semantics:
– Loose semantics, where certain attack types are used only as defenders, as
e.g., in the case of credibility attacks in Fig. 1.
– Restricted semantics, where certain attack types are ignored altogether (i.e.,
they have none of the two roles).
– Firm semantics, where certain attack types are used only as conﬂict-
generators.
Following a related work analysis (Sect. 2), we formalise (Sect. 3) the three
semantics explained above; the formalisation results to various types of exten-
sions, in a manner similar to standard frameworks [8]. Then, we explore the
properties of such semantics (Sect. 4), such as the existence of the diﬀerent exten-
sions, relationships among themselves and with the Dung semantics and others,
and conclude in Sect. 5.
2
Related Work
The need to further reﬁne the notion of attack in argumentation frameworks
has led to several diﬀerent extensions of Abstract Argumentation Frameworks.
For example, Abstract Argumentation Frameworks with Recursive Attacks
(AFRA) [3] and Extended Argumentation Frameworks (EAF) [12] extend the
deﬁnition of attack, allowing attacks to be directed not only to arguments but
also to other attacks. The diﬀerence between the two is that, while in EAFs
only attacks whose target is an argument can be attacked, in AFRA any attack
can be attacked. This idea is orthogonal to our approach that considers diﬀerent
types of attack, which are, however, all directed to arguments, and studying the
combination of these two approaches, e.g. by allowing diﬀerent types of attack
that can be directed to arguments or attacks is an interesting research direction.
Commonsense Argumentation Frameworks [16], on the other hand, include
two types of attacks, which diﬀer in the type of arguments they are directed
to, i.e. deductive arguments and commonsense arguments. They can therefore
be considered as specializations of Multi-Attack Argumentation Frameworks,
which we propose in this paper.
Some other studies have introduced weights or preferences on attacks follow-
ing quantitative or qualitative approaches. For example, Weighted Argumenta-
tion Systems [9] assign weights to attacks as a way to describe their strength

420
A. Vassiliades et al.
and use the idea of an inconsistency budget as a way to disregard attacks up to
a certain weight. The idea of weighted attacks is also used in [10], where the
acceptability of arguments is not deﬁned in terms of the standard Dung-style
extensions, but in terms of numerical values derived from a set of equations
describing the arguments and their attack relations. While social networks is
indeed a domain where numerical weights can be derived from the reactions of
the users, in many other domains (for example, the legal domain) such types of
data may not be available.
A qualitative approach to represent preferences among attacks was proposed
in [11]. Similarly to our approach, they deﬁne a framework with (an arbitrary
number of) types of attack. These are partially ordered, and each attack is
assigned one of these types. This allows for a ﬁner grained deﬁnition of defence
(compared to AAFs), which can roughly be described as follows: an argument
is defended against an attack from a counter-argument, if the latter receives
a stronger attack from another argument. It also allows for a ﬁner deﬁnition
of acceptability semantics, which take into account the relative diﬀerence of
strength between defensive and oﬀensive attacks.
All such preference-based approaches, which use either numerical values or
priorities to represent the (relative) strength of attacks, have a common charac-
teristic: any non-preferred attack is either ignored or invalidated. Our approach
oﬀers alternative ways to treat attacks, which take into account their roles in
an argumentation system, i.e. whether they are used as oﬀensive or defensive
attacks. For example, according to the ﬁrm semantics, a defense is eﬀective only
if it is from an argument of a speciﬁc type, while according to the loose seman-
tics, an oﬀensive attack is eﬀective if the attacker is of a speciﬁc type. Choosing
the right semantics depends on the speciﬁc requirements and characteristics of
the application domain.
Another approach that also considers diﬀerent types of attack in abstract
argumentation was proposed in [15]. The motivation is similar to ours, namely
that each attack relation can represent a diﬀerent criterion according to which
the arguments can be evaluated one against another. The evaluation of argu-
ments, however, is based on the aggregation of the diﬀerent relations using meth-
ods from social choice theory, such as majority voting, and the use of the standard
acceptability semantics in the aggregate argumentation framework. They do not,
therefore, provide ways to treat certain criteria diﬀerently than others, which is
one of the main characteristics of Multi-Attack Argumentation Frameworks.
Diﬀerent types of attack are common in structured argumentation frame-
works. For example, in ASPIC+ [13] arguments can be attacked in three diﬀer-
ent ways: on their uncertain premises (undermining), on their defeasible infer-
ences (undercutting), or on the conclusions of their defeasible inferences (rebut-
ting). Deductive argumentation [6] also supports diﬀerent types of attack, which
depend on the underlying logic. For example, choosing classical logic as the base
logic provides seven diﬀerent types of attack. The diﬀerent types of attack in such
frameworks are associated with the internal structure of arguments and cannot
therefore be directly compared with Multi-Attack Argumentation Frameworks
in which arguments are abstract. They can, however, easily be mapped to the

An MAAF
421
representation model of Multi-Attack Argumentation Frameworks, i.e. by map-
ping each of the diﬀerent types of attack they support to a diﬀerent attack type
of MAAF. This mapping enables alternative ways to reason with structured
arguments by treating diﬀerently the diﬀerent types of attack, which may be
meaningful in some domains.
3
Multi Attack Argumentation Frameworks (MAAFs)
We deﬁne a multi-attack argumentation framework as an argumentation frame-
work where attacks are of multiple types. Formally:
Deﬁnition 1. A multi-attack argumentation framework (MAAF for short) is
a tuple ⟨A, T , R⟩, such that:
– A is a set of arguments
– T is a set of attack types
– R ⊆A × A × T is a set of type-annotated attacks among arguments
Note that A and/or T can be inﬁnite, so R can be inﬁnite too. Intuitively
an attack (a, b, τ) ∈R represents that a attacks b, and that the attack is of type
τ. Note that the same two arguments may be related with attacks of diﬀerent
types, in which case each attack type is represented as a diﬀerent triple in R.
For any given set of types T0 ⊆T , we say that a attacks b w.r.t. T0 (denoted
by a →T0 b) if there exists τ ∈T0, such that (a, b, τ) ∈R. For simplicity, we
often write →τ to denote →{τ}, and →to denote →T . We extend notation to
sets of arguments, and, for B, C ⊆A, we write B →T0 C if and only if ∃b ∈B,
c ∈C such that b →T0 c. For singleton sets, we often write b →T0 C and B →T0 c
instead of {b} →T0 C and B →T0 {c}, respectively.
The restriction of an MAAF to a speciﬁc set of types T0 is the AAF that
is generated from the MAAF by considering only the attacks in T0. Formally,
given an MAAF ⟨A, T , R⟩, the restriction of ⟨A, T , R⟩to T0 is an AAF ⟨A′, R′⟩,
where A′ = A and R′ = {(a, b) | (a, b, τ) ∈R for some τ ∈T0}.
The ﬂattening of an MAAF is the AAF that is generated from the MAAF by
ignoring types. Formally, for an MAAF F = ⟨A, T , R⟩, the ﬂattening of F is an
AAF ⟨A′, R′⟩, where A′ = A and R′ = {(a, b) | (a, b, τ) ∈R for some τ ∈T }.
Note that the ﬂattening of F is the same as the restriction of F to T .
3.1
Classes of Extensions for MAAFs
To deﬁne MAAF extensions, we introduce three new classes of semantics: ﬁrm,
restricted and loose. For each type of semantics deﬁned in [8] (e.g., admissible,
complete, etc.), we deﬁne its counterpart for each class (e.g., ﬁrmly admissible,
restrictedly stable, loosely complete, etc.). The three classes diﬀer in how certain
types of attack are considered. As already mentioned, the idea behind our seman-
tics is the treatment of certain types of attacks as being conﬂict-generators only
or attackers only. To do this, we consider a certain set of types, say T0, which
are treated in the “normal” manner. Diﬀerent types of semantics can now result
depending on the exact behaviour of the attacks in T \ T0. In particular:

422
A. Vassiliades et al.
1. Firm semantics (e.g., admissible, complete etc.) w.r.t. a certain set of attack
types (say T0) requires a candidate extension to be defended against all types
of attacks, and an attack can be defended only by attacks from T0. In other
words, attacks in T0 have the standard behaviour, but attacks in T \T0 act as
conﬂict-generators only, not as defenders. We call them ﬁrm because, while
they allow any type of argument to unleash oﬀensive attacks, they only allow
certain types of attack (those in T0) to defend an argument, making its defense
more diﬃcult.
2. Restricted semantics (e.g., admissible, complete etc.) w.r.t. a certain set of
attack types (say T0) require a candidate extension to be defended against
attacks from T0 only, and an attack can be defended only by attacks from T0.
Thus, restricted semantics essentially consider only the attacks in T0, both for
the attacks and for defending against them, i.e., attacks in T \ T0 are totally
ignored. This brings them quite close to the notion of the restriction of an
MAAF, a statement that will be made precise in Proposition 4.
3. Loose semantics (e.g., admissible, complete etc.) w.r.t. a certain set of attack
types (say T0) are the most “relaxed” ones, as they require a candidate exten-
sion to be defended only against attacks from T0, while defense can happen
by any type of attack. In other words, in loose semantics, attacks in T \ T0
are treated as defenders only, and cannot generate attacks. Loose semantics
allows attacks to be ignored, so they may result to extensions that are not
defended against all attacks, speciﬁcally against attacks that are of types not
in T0.
In the following, we use shorthands to refer to the various types and classes
of semantics. In particular, for the three classes of semantics, we use fr for ﬁrm,
re for restricted, and lo for loose semantics. We also use θ as a catch-all variable
that refers to any of these classes. Similarly, for types of extensions, we use
cf for conﬂict-free, ad for admissible, co for complete, pr for preferred, gr for
grounded, and st for stable. We also use σ as a catch-all variable to indicate
any of these extension types. For example, we write fr-co-extension to refer to
a ﬁrmly complete extension, and θ-σ-extension to refer to an extension of class
θ and the type denoted by σ.
To formalise the above ideas, we ﬁrst reﬁne the notion of defense:
Deﬁnition 2. Consider an MAAF ⟨A, T , R⟩, some T0 ⊆T , some a ∈A and
some set E ⊆A. We deﬁne the notion of defense for the diﬀerent classes of
semantics as follows:
– E ﬁrmly defends a (or fr-defends a) w.r.t. T0 if and only if E →T0 b whenever
b →a
– E restrictedly defends a (or re-defends a) w.r.t. T0 if and only if E →T0 b
whenever b →T0 a
– E loosely defends a (or lo-defends a) w.r.t. T0 if and only if E →b whenever
b →T0 a
Figure 2 visualises the notion of defense for various cases.

An MAAF
423
a1
a2
a3
a4
a5
a6
τ
τ ′
τ
τ ′
τ
For T0 = {τ}, it holds that:
{a1} fr-defends a3 w.r.t. T0
{a1} re-defends a4 w.r.t. T0
{a2} lo-defends a6 w.r.t. T0
For any E, E fr-defends a1 w.r.t. T0
For any E, E re-defends a3 w.r.t. T0
For any E, E lo-defends a3 w.r.t. T0
{a2} does not fr-defend a5 w.r.t. T0
{a2} does not re-defend a6 w.r.t. T0
Fig. 2. The concept of fr/re/lo-defense visualised
3.2
Firm, Restricted and Loose Extensions
Now we can recast the standard deﬁnitions for the diﬀerent types of semantics
given in [8], using the above ideas:
Deﬁnition 3. Consider an MAAF ⟨A, T , R⟩and some T0 ⊆T . A set E ⊆A
is:
– Firmly conﬂict-free (fr-cf) w.r.t. T0 if and only if it is not the case that E →E
– Restrictedly conﬂict-free (re-cf) w.r.t. T0 if and only if it is not the case that
E →T0 E
– Loose conﬂict-free (lo-cf) w.r.t. T0 if and only if it is not the case that E →T0
E
Note how the intuition behind the diﬀerent classes of semantics are applied
in Deﬁnition 3: lo-cf and re-cf sets may include self-attacks, as long as they
are not of types in T0 (because attacks in T \ T0 are not conﬂict-generators in
these semantics), whereas fr-cf sets cannot include any self-attack. As a result,
the deﬁnition of re-cf and lo-cf coincides, since the notion of defense (where
the two classes of semantics diﬀer) is not relevant to that of conﬂict-freeness.
Nevertheless, for purposes of uniformity and symmetry, we decided to include
both deﬁnitions.
The same ideas are applied to admissible extensions, whose deﬁnition essen-
tially mimics the ones typically used in AAFs, but considers the alternative
notions of defense (Deﬁnition 2) for each case:
Deﬁnition 4. Consider an MAAF ⟨A, T , R⟩and some T0
⊆
T . For
θ ∈{fr, re, lo}, a set E
⊆A is a θ-ad extension w.r.t. T0 (in words:
ﬁrmly/restrictedly/loosely admissible) if and only if:
– E is θ-cf
– If a ∈E, then E θ-defends a w.r.t. T0

424
A. Vassiliades et al.
Complete semantics’ deﬁnition slightly deviates from the respective one in
AAFs to accommodate the diﬀerences in the deﬁnition of conﬂict-freeness.
Deﬁnition 5. Consider an MAAF ⟨A, T , R⟩and some T0
⊆
T . For
θ
∈{fr, re, lo}, a set E
⊆A is a θ-co extension w.r.t. T0 (in words:
ﬁrmly/restrictedly/loosely complete) if and only if:
– E is θ-ad
– If E θ-defends a w.r.t. T0, and E ∪{a} is θ-cf w.r.t. T0, then a ∈E
Note that, in the above deﬁnition, instead of only requiring that a ∈E
whenever E θ-defends a, we have included the additional requirement that E∪{a}
is θ-cf, thereby deviating somewhat from the deﬁnition pattern used in AAFs for
co-semantics [8]. This additional requirement is redundant in the AAF setting,
because it results as a corollary of the weaker deﬁnition. The same is true in
the MAAF setting, but only for the fr and re semantics (see Proposition 2 and
the analysis that follows it). For this reason, and for purposes of uniformity and
symmetry, we decided to include this extra requirement in Deﬁnition 5.
Grounded and preferred semantics are deﬁned analogously:
Deﬁnition 6. Consider an MAAF ⟨A, T , R⟩and some T0 ⊆T . A set E ⊆A
is a θ-gr extension w.r.t. T0 (in words: ﬁrmly/restrictedly/loosely grounded) if
and only if E is a minimal with respect to set inclusion θ-co extension w.r.t. T0.
Deﬁnition 7. Consider an MAAF ⟨A, T , R⟩and some T0 ⊆T . A set E ⊆A
is a θ-pr extension w.r.t. T0 (in words: ﬁrmly/restrictedly/loosely preferred) if
and only if E is a maximal with respect to set inclusion θ-ad extension w.r.t. T0.
Stable semantics also follow a similar pattern:
Deﬁnition 8. Consider an MAAF ⟨A, T , R⟩and some T0 ⊆T . A set E ⊆A
is:
– A ﬁrmly stable extension (fr-st) w.r.t. T0 if and only if:
• E is maximally fr-cf w.r.t. T0
• E →T0 a whenever a /∈E
– A restrictedly stable extension (re-st) w.r.t. T0 if and only if:
• E is maximally re-cf w.r.t. T0
• E →T0 a whenever a /∈E
– A loosely stable extension (lo-st) w.r.t. T0 if and only if:
• E is maximally lo-cf w.r.t. T0
• E →a whenever a /∈E
Note that Deﬁnition 8 also deviates somewhat from the deﬁnition pattern
of st semantics in standard AAFs. In particular, instead of requiring that E is
θ-cf (for the various θ), we have required that it is maximally θ-cf, i.e., a θ-cf
set that is maximal among all other θ-cf sets. As with the co semantics, this
stronger requirement is redundant in the AAF setting, and also in the MAAF
setting for fr and re semantics (we have, however, included it in their deﬁnitions
for uniformity), but is necessary for lo semantics (see Proposition 3 and the
analysis that follows it).

An MAAF
425
4
Properties of MAAFs
We can show several properties with regards to the interplay among various types
of θ-σ-extensions. To simplify presentation, all the following results assume an
arbitrary MAAF F = ⟨A, T , R⟩and some T0 ⊆T . Also, the reference to T0 is
often omitted when obvious; e.g., we write that E is a lo-co extension, to signify
that E is a lo-co extension w.r.t. T0.
4.1
Initial Results and Special Cases
We ﬁrst show the analogous of Dung’s fundamental lemma (Lemma 10 in [8]).
Note the diﬀerent formulation of this result for lo semantics1:
Proposition 1. For any given E ⊆A, a ∈A, it holds that:
1. If E is θ-ad, and E θ-defends a, then E ∪{a} is θ-ad, for θ ∈{fr, re}
2. If E is lo-ad, E lo-defends a, and E ∪{a} is lo-cf, then E ∪{a} is lo-ad
Proposition 2 shows that the extra requirement of Deﬁnition 5 (compared to
its counterpart in AAFs) is redundant for fr and re semantics:
Proposition 2. For θ ∈{fr, re}, E ⊆A, the following are equivalent:
– E is a θ-co-extension w.r.t. T0
– The following hold for E:
• E is θ-ad w.r.t. T0
• If E θ-defends a w.r.t. T0, then a ∈E
Note that the above equivalence does not hold for loose semantics. Indeed,
the diﬀerent formulation of Proposition 1 does not allow its use in the proof
of Proposition 2. The MAAF visualised in Fig. 3 provides a counter-example:
{a, b} is lo-co, despite the fact that {a, b} lo-defends c and c /∈{a, b}. This is
due to the extra requirement that we added in Deﬁnition 5; without it, neither
{a, b}, nor {a, b, c} would be lo-co, i.e., we would end up having a maximal lo-
ad extension ({a, b}), that is not lo-co, which is against the intuition behind
complete extensions.
Similarly, Proposition 3 shows that the extra requirement of Deﬁnition 8
(compared to its AAF counterpart) is redundant for fr-st and re-st semantics:
Proposition 3. For θ ∈{fr, re}, E ⊆A, the following are equivalent:
– E is a θ-st-extension
– The following hold for E:
• E is θ-cf
• E →T0 a whenever a /∈E

426
A. Vassiliades et al.
a
b
c
τ ′
τ
For T0 = {τ}, we have that:
{a, b} is lo-ad w.r.t. T0
{a, b} lo-defends c w.r.t. T0
{a, b, c} is not lo-co w.r.t. T0
Fig. 3. Counter-example for the counterpart of Proposition 2 for lo semantics
a
b
c
τ ′
τ
For T0 = {τ}, we have that:
{b} is lo-cf w.r.t. T0
{b} →a, {b} →c,
{a, b} is lo-cf w.r.t. T0
Fig. 4. Counter-example for the counterpart of Proposition 3 for lo semantics
The example of Fig. 4 shows a case where the counterpart of Proposition 3
would fail for lo semantics. The set {b} attacks all other arguments, and is lo-
cf, but not maximally so. Thus, it is not lo-st. On the contrary, {a, b} is lo-st.
This shows why the extra maximality condition that was added to Deﬁnition 8
(compared to its counterpart in AAFs) is necessary: without it, both {a, b} and
{b} would be lo-st.
The next result shows that restricted semantics can be computed using the
restriction of an MAAF:
Proposition 4. Consider an MAAF F = ⟨A, T , R⟩and some T0 ⊆T . Set
F′ = ⟨A′, R′⟩the restriction of F to T0. For any given σ ∈{cf, ad, co, gr, pr, st}
and E ⊆A, E is a re-σ-extension w.r.t. T0 if and only if E is a σ-extension of
F.
The following result describes a special case, showing essentially that our
semantics is a generalisation of Dung’s (i.e., that AAF semantics emerge as a
special case of MAAFs):
Proposition 5. Consider an MAAF F = ⟨A, T , R⟩and set T0 = T . Con-
sider also the MAAF’s ﬂattening F′ = ⟨A′, R′⟩, and its restriction to T0,
F′′ = ⟨A′′, R′′⟩. Then, for any σ ∈{cf, ad, co, gr, pr, st}, E ⊆A the following
are equivalent:
1. E is a lo-σ-extension w.r.t. T0
2. E is a re-σ-extension w.r.t. T0
1 The proofs of all results appear in the Appendix.

An MAAF
427
3. E is a fr-σ-extension w.r.t. T0
4. E is a σ-extension of F′
5. E is a σ-extension of F′′
4.2
Relations Among Extension Types, and Existence Results
The next proposition shows that the hierarchy of extensions that holds in the
Dung setting, also holds for each class of extensions:
Proposition 6. For any E ⊆A:
1. If E is a θ-ad-extension w.r.t. T0, then E is a θ-cf-extension w.r.t. T0
2. If E is a θ-co-extension w.r.t. T0, then E is a θ-ad-extension w.r.t. T0
3. If E is a θ-gr-extension w.r.t. T0, then E is a θ-co-extension w.r.t. T0
4. If E is a θ-pr-extension w.r.t. T0, then E is a θ-co-extension w.r.t. T0
5. If E is a θ-st-extension w.r.t. T0, then E is a θ-pr-extension w.r.t. T0
Our next result shows that we can “incrementally” construct minimally-
complete extensions starting from an ad one. The proof follows an iterative
function, similar to the function FAF used by Dung in [8]. However, for MAAFs,
there are two subtleties.
First, FAF (as deﬁned in [8]) adds all acceptable arguments in each iteration;
for the lo case, this could lead to a set that is not lo-cf (see, e.g., Fig. 5: both
b and c are acceptable by {a}, but {a, b, c} is not lo-cf); thus, a more elaborate
construction is needed.
Second, for inﬁnite frameworks, the existence of a minimal ﬁxpoint for FAF
(in [8]) is guaranteed by the implicit use of the Knaster-Tarski theorem ([14]),
which requires an order preserving function. Although FAF is order-preserving,
our alternative is not.
To overcome these problems, the proof of Proposition 7 uses a more complex
iterative function, employing ordinals. Importantly, this construction applies to
all our semantics, as well as to standard AAFs, so it can be viewed also as an
alternative proof for a well-known property of AAFs. Note also that the proof
employs the Axiom of Choice.
Proposition 7. Take any MAAF F = ⟨A, T , R⟩, some T0 ⊆T , and some
E∗⊆A such that E∗is θ-ad (for θ ∈{fr, re, lo}). Then, there exists some E
such that E ⊇E∗, and the following hold:
1. E is θ-co.
2. For any E′ such that E∗⊆E′ ⊂E, there exists a ∈E \ E′ which is θ-defended
by E′ and E′ ∪{a} is θ-cf.
3. For any E′ such that E∗⊆E′ ⊂E, E′ is not θ-co.
We next show that the existence of θ-σ extensions is guaranteed (except from
θ-st), for all θ, analogously to the AAF case (see [8], [4]). Note that the proof
for the inﬁnite case in some of the semantics requires the Axiom of Choice:

428
A. Vassiliades et al.
a
b
c
τ ′
τ ′
τ
τ
For T0 = {τ}, we have that both
{a, b} and {a, c} are lo-gr extensions.
Fig. 5. An MAAF with two lo-gr extensions
Proposition 8. For any MAAF F
=
⟨A, T , R⟩, θ
∈
{fr, re, lo}, σ
∈
{cf, ad, co, gr, pr} and T0 ⊆T , there exists a θ-σ extension w.r.t. T0 in F.
In AAFs, a gr extension is unique. The counter-example of Fig. 5 shows that
this is not the case for lo-gr extensions. However, for the other semantics (fr,
re), the uniqueness of gr extensions is guaranteed:
Proposition 9. For any MAAF F = ⟨A, T , R⟩, θ ∈{fr, re} and T0 ⊆T , there
exists a unique θ-gr extension w.r.t. T0 in F.
Conﬂict-free (1+)
Admissible (1+)
Complete (1+)
Preferred (1+)
Grounded
(1 for fr, re; 1+ for lo)
Stable (0+)
Fig. 6. Properties of MAAF extensions (apply to fr, re, lo, unless mentioned other-
wise)
Propositions 6, 8 and 9 are summarised in Fig. 6.

An MAAF
429
4.3
Relations Among Extension Classes
The following propositions show the relation among fr, re and lo extensions, as
well as the relation between these extensions and the extensions of the ﬂattened
AAF. This, along with Proposition 4, completes the picture with regards to the
relationship among the diﬀerent extension classes. We provide one proposition
for each extension type (cf, ad, etc.), starting with the simple case of cf:
Proposition 10. Take an MAAF F = ⟨A, T , R⟩, its ﬂattened AAF FF =
⟨A, R′⟩and some E ⊆A. Then:
1. E is fr-cf if and only if E is cf in FF .
2. If E is fr-cf then E is re-cf.
3. E is re-cf if and only if E is lo-cf.
Interestingly, the direction of inference for the case of defense reverses (com-
pared to the cf case) for the ﬂattened AAF and the re class:
Proposition 11. Take an MAAF F = ⟨A, T , R⟩, its ﬂattened AAF FF =
⟨A, RF ⟩, some E ⊆A and some a ∈A. Then:
1. If E fr-defends a, then E re-defends a.
2. If E re-defends a, then E defends a in FF .
3. If E defends a in FF , then E lo-defends a.
This reversal of the direction of inference (in Propositions 10, 11) leads to
the following proposition:
Proposition 12. Take an MAAF F = ⟨A, T , R⟩, its ﬂattened AAF FF =
⟨A, RF ⟩and some E ⊆A. Then:
1. If E is fr-ad, then E is re-ad.
2. If E is fr-ad, then E is ad in FF .
3. If E is re-ad, then E is lo-ad.
4. If E is ad in FF , then E is lo-ad.
5. If E is re-ad and cf in FF , then E is ad in FF .
For complete, grounded and preferred semantics, the situation is more com-
plex:
Proposition 13. Take an MAAF F = ⟨A, T , R⟩, its ﬂattened AAF FF =
⟨A, RF ⟩and some E ⊆A. Then:
1. If E is re-co and fr-ad, then E is fr-co.
2. If E is co in FF and re-ad, then E is re-co.
3. If E is lo-co and ad in FF , then E is co in FF .
Proposition 14. Take an MAAF F = ⟨A, T , R⟩, its ﬂattened AAF FF =
⟨A, RF ⟩and some E ⊆A. Then:

430
A. Vassiliades et al.
1. If E is fr-gr and re-co, then E is re-gr.
2. If E is re-gr and co in FF , then E is gr in FF .
3. If E is gr in FF and lo-co, then E is lo-gr.
Proposition 15. Take an MAAF F = ⟨A, T , R⟩, its ﬂattened AAF FF =
⟨A, RF ⟩and some E ⊆A. Then:
1. If E is re-pr and fr-ad, then E is fr-pr.
2. If E is pr in FF and re-ad, then E is re-pr.
3. If E is lo-pr and ad in FF , then E is pr in FF .
Finally, for stable semantics, the situation is similar to the case of admissible
semantics:
Proposition 16. Take an MAAF F = ⟨A, T , R⟩, its ﬂattened AAF FF =
⟨A, RF ⟩and some E ⊆A. Then:
1. If E is fr-st, then E is re-st.
2. If E is fr-st, then E is st in FF .
3. E is re-st, if and only if E is lo-st.
4. If E is re-st and cf in FF , then E is st in FF .
Further corollaries can be derived by combining the above results (Proposi-
tions 10, 11, 12, 13, 14, 15, 16) with Propositions 4 and 6, to connect the various
types and classes of semantics among themselves, and with the semantics of
restricted/ﬂattened AAF. These are direct and omitted.
5
Discussion and Conclusion
In this paper we presented the semantics of multi-attack argumentation frame-
works, i.e., frameworks which support multiple attack types among arguments.
The important novelty of our semantics is the discrimination between two roles of
attacks that have traditionally been considered inseparably: the role of conﬂict-
generator, and the role of defender. The combination of these two aspects allowed
us to deﬁne new classes of semantics, which model interesting real-life situations,
have nice formal properties, and engulf standard models as a special case. An
AAF cannot capture the aforementioned aspects to the extent that an MAAF
does.
Note that, although MAAFs admit several types of attacks, during the com-
putation of semantics, all attack types are split into two classes: those that are
in T0, and those that are not. Thus, we could deﬁne the same semantics by
just allowing two diﬀerent types. However, such a solution, albeit simpler, would
have two disadvantages. The ﬁrst is that it is intuitively better for the mod-
eller to have several attack types, and then decide which ones are “normal” (to
be placed in T0), and which ones are “special” (to be placed in T \ T0). This
approach has the additional advantage that the modeller can choose a diﬀerent
T0 depending on the application at hand. Second, our modelling allows more
sophisticated semantics to be developed, e.g., by deﬁning sets T1, T2 and treat-
ing the attacks in T1 as defenders only, and attacks in T2 as conﬂict-generators
only. This extension is part of our future work.

An MAAF
431
Acknowledgments. This project has received funding from the Hellenic Foundation
for Research and Innovation (HFRI) and the General Secretariat for Research and
Technology (GSRT), under grant agreement No 188.
A
Appendix
Proof of Proposition 1
For the ﬁrst result, E ∪{a} θ-defends E ∪{a}, since, by our assumptions, E
θ-defends E, and E θ-defends a. So it suﬃces to show that, E ∪{a} is θ-cf.
Let us consider the case of ﬁrm semantics ﬁrst. Suppose that E ∪{a} is not fr-cf.
Then, there exist a1, a2 ∈E ∪{a} such that a1 →a2. We consider four cases, all
of which lead to a contradiction, thus proving the point:
1. If a1, a2 ∈E, then E is not fr-cf, a contradiction.
2. If a1 ∈E, a2 = a, then, since E fr-defends a, it follows that there exists some
a3 ∈E such that a3 →T0 a1, a contradiction by case #1.
3. If a1 = a, a2 ∈E, then, since E is an fr-ad-extension, it follows that there
exists a3 ∈E, such that a3 →T0 a, i.e., a3 →a, a contradiction by case #2.
4. If a1 = a2 = a, then, since E fr-defends a, it follows that there exists some
a3 ∈E such that a3 →T0 a, i.e., a3 →a, a contradiction by case #2.
The case of restricted semantics is completely analogous and omitted.
For the second result, using the same reasoning we note that E ∪{a} lo-defends
E ∪{a}. Given that E ∪{a} is lo-cf by our assumptions, the result follows.
⊓⊔
Proof of Proposition 2
By Proposition 1 when E is θ-ad, and E θ-defends a, then E ∪{a} is θ-cf, for
θ ∈{fr, re}. The result then follows trivially.
⊓⊔
Proof of Proposition 3
It suﬃces to show that when E is θ-cf, and E →T0 a whenever a /∈E, then E is
maximally θ-cf. Indeed, suppose that E′ is θ-cf and E′ ⊃E. Then, take some
a ∈E′ \ E. By our hypothesis, E →T0 a, i.e., E′ →T0 E′, a contradiction by our
hypothesis that E′ is θ-cf.
⊓⊔
Proof of Proposition 4
Since A = A′, take any a, b ∈A, E ⊆A. Then, apparently:
– a attacks b in F′ if and only if a →T0 b in F
– E defends a in F′ if and only if E re-defends a in F
Using the above two statements and Propositions 2, 3 (necessary for the case of
co- and st-extensions respectively), it is easy to show the result.
⊓⊔
Proof of Proposition 5
Since T0 = T , we note that a →T0 b if and only if a →b. The equivalence
among #1, #2, #3 is then obvious by the respective deﬁnitions on θ-extensions.
Moreover, the equivalence among #2 and #4 is obvious from Proposition 4,
whereas the equivalence among #4 and #5 follows from the fact that F′ = F′′.
⊓⊔

432
A. Vassiliades et al.
Proof of Proposition 6
For re semantics, all results follow from Proposition 4 and the corresponding
results on the AAF (e.g., [8]), so let us consider the case of fr and lo semantics.
#1, #2 and #3 are obvious by the respective deﬁnitions.
For #4, let θ ∈{fr, lo}, and take E to be a θ-pr-extension. Then it is θ-ad.
Suppose that it is not θ-co. Then, there is some a /∈E, such that E θ-defends a
and E ∪{a} is θ-cf. But then, it is easy to see that E ∪{a} is θ-ad, which is a
contradiction by the deﬁnition of θ-pr-extensions and the fact that E ∪{a} ⊃E.
For #5, let us consider the case of ﬁrm semantics ﬁrst, and take E to be an fr-
st-extension. Then, it is fr-cf (and maximally so). We will show that it is also
fr-ad. Indeed, take some a, b ∈A, such that a ∈E and b →a. Then b /∈E (since
E is fr-cf), thus E →T0 b (since E is fr-st), which implies that E fr-defends a.
Thus, E is also fr-ad. It is also maximal, because E is maximally fr-cf. Therefore,
E is an fr-pr-extension.
For the lo case, take E to be a lo-st-extension. Then, it is lo-cf (and maximally
so). We will show that it is also lo-ad. Indeed, take some a, b ∈A, such that
a ∈E and b →T0 a. Then b /∈E (since E is lo-cf), thus E →b (since E is lo-st),
which implies that E lo-defends a. Thus, E is also lo-ad. It is also maximal,
because E is maximally lo-cf. Therefore, E is a lo-pr-extension.
⊓⊔
Proof of Proposition 7
We will prove the claim constructively. First, we will describe a construction
over F, and then we will show that this construction generates some E with
the above properties. The proof is broken down in steps, represented as claims
proved individually below. The last claim (Claim 5) shows the result.
Construction. We assume a well-order < over A (its existence is guaranteed by
the Axiom of Choice). For a given set E ⊆A, we denote by min< E the minimal
element of E according to <.
Moreover, for E ⊆A, set E  = {a ∈A \ E | E: θ-defends a, E ∪{a}: θ-cf},
i.e., the arguments that are defended by E, and do not conﬂict with E.
We deﬁne the function: φ : 2A →2A as follows:
φ(E) =
E
, when E  = ∅
E ∪{min<(E )} , when E  ̸= ∅
Finally, we deﬁne a function G recursively on the ordinals as follows:
G(β) = E[∗]
, when β = 0
G(β + 1) = φ(G(β))
, when β is a successor ordinal
G(β) = {G(γ) | γ < β} , when β is a limit ordinal
Claim 1. For two ordinals β, γ, if β < γ, then G(β) ⊆G(γ).
Proof of Claim 1. We will use transﬁnite induction on γ.
If γ = 0, then the result holds trivially as there is no β for which β < γ. Suppose
that the result holds for all γ < δ; we will show that it holds for γ = δ.

An MAAF
433
If δ is a successor ordinal, then there exists some δ−such that δ = δ−+1. Clearly,
by the deﬁnition of G and φ, G(δ) ⊇G(δ−). Furthermore, by the inductive
hypothesis, G(δ−) ⊇G(β), which shows the result.
If δ is a limit ordinal, then the result follows directly by the deﬁnition of G.
◦
Claim 2. For any ordinals β, G(β) ⊇E∗.
Proof of Claim 2. If β = 0 the result follows by the deﬁnition of G. If β > 0, the
result follows by Claim 1.
◦
Claim 3. For any ordinal β, G(β) is θ-ad.
Proof of Claim 3. We will use transﬁnite induction over β. For β = 0, the result
follows by our assumption on E∗. Now suppose that it holds for all β < γ. We
will show that it holds for β = γ.
If γ is a successor ordinal, then take γ−such that γ = γ−+1. Then, by deﬁnition,
G(γ) = φ(G(γ−)). By the inductive hypothesis G(γ−) is θ-ad. Moreover, by the
deﬁnition of φ, φ(E) is θ-ad whenever E is θ-ad, so G(γ) is θ-ad.
If γ is a limit ordinal, then suppose that G(γ) is not θ-cf. Then, there exist
a1, a2 ∈G(γ) such that {a1, a2} is not θ-cf, and, thus, there exist ordinals δ1, δ2
such that δ1 < γ, δ2 < γ, a1 ∈G(δ1), a2 ∈G(δ2). If δ1 = δ2 then G(δ1) is not
θ-cf, a contradiction by the inductive hypothesis. If δ1 < δ2 then G(δ2) ⊇G(δ1)
(by Claim 1), so a1, a2 ∈G(δ2), a contradiction by the inductive hypothesis. The
case of δ2 < δ1 is analogous. Thus, G(γ) is θ-cf.
Now consider some a ∈G(γ). Then, by the deﬁnition of G, there exists some
δ < γ such that a ∈G(δ). Since G(δ) is θ-ad by the inductive hypothesis, it
follows that G(δ) θ-defends a, so, given that G(γ) ⊇G(δ) (Claim 1), we conclude
that G(γ) θ-defends a. Thus, G(γ) is θ-ad.
◦
Claim 4. There exists ordinal β such that G(β) = G(β + 1).
Proof of Claim 4. By Claim 1, we conclude that G is an increasing function from
the ordinals into 2A. It cannot be strictly increasing, as if it were we would have
an injective function from the ordinals into a set, violating Hartogs’ lemma.
Therefore the function must be eventually constant, so for some β, G(β) =
G(β + 1).
◦
Claim 5. There exists some E such that E ⊇E∗, and the following hold:
1. E is θ-co.
2. For any E′ such that E∗⊆E′ ⊂E, there exists a ∈E \ E′ which is θ-defended
by E′ and E′ ∪{a} is θ-cf.
3. For any E′ such that E∗⊆E′ ⊂E, E′ is not θ-co.
Proof of Claim 5. By Claim 4, there exists ordinal β such that G(β) = G(β +1).
Set E = G(β). By Claim 2, E ⊇E∗, so it is an adequate choice. We will show
that E satisﬁes the required properties.

434
A. Vassiliades et al.
For the ﬁrst result, note that by Claim 3, E is θ-ad. Moreover, E = G(β) =
G(β + 1) = φ(G(β)) = φ(E), which implies that E  = ∅, which, in tandem with
the fact that E is θ-ad leads to the conclusion that E is θ-co.
For the second result, take some E′ such that E∗⊆E′ ⊂E.
Set S = {γ | G(γ) ̸⊆E′}. We observe that β ∈S, so S ̸= ∅. Set δ = min< S.
Obviously, δ = β or δ < β.
If δ = 0, then G(δ) = E∗⊆E′, a contradiction.
If δ is a successor ordinal, then take δ−such that δ = δ−+ 1. Thus, G(δ) =
φ(G(δ−)). By construction, G(δ−) ⊆E′ and G(δ) ̸⊆E′, therefore G(δ) = G(δ−) ∪
{a}, for some a for which G(δ−) θ-defends a and G(δ−) ∪{a} is θ-cf. If a ∈E′,
then G(δ) ⊆E′, a contradiction by the choice of δ, so a /∈E′. Moreover, a ∈G(δ).
If δ = β then G(δ) = E, so a ∈E. If δ < β then a ∈G(δ) ⊆G(β) (by Claim 1),
so a ∈E. We conclude that a ∈E \ E′. Thus, we have found some a with the
required properties.
If δ is a limit ordinal, then, by the deﬁnition of δ, G(δ′) ⊆E′ for all δ′ < δ.
Therefore, G(δ) = 
δ′<δ G(δ′) ⊆E′, a contradiction by the choice of δ.
The third result follows from the second: indeed, as there exists a ∈E \ E′ which
is θ-defended by E′ and E′ ∪{a} is θ-cf, it cannot be the case that E′ is θ-co. ◦
⊓⊔
Proof of Proposition 8
For the case where θ = re, the proof follows directly by Proposition 4 and the
related results from the AAF literature. So suppose that θ ∈{fr, lo}.
We ﬁrst note that ∅is θ-cf and θ-ad w.r.t. T0, so the claim is true for σ ∈
{cf, ad}.
Let us now turn our attention to the case where σ = pr. Our proof follows the
lines of the respective proof in [4]. Set AD = {E | E is θ-ad} (AD ̸= ∅, as shown
above). We will show that, any ⊆-chain (Ei)i∈I in AD possesses an upper bound.
Indeed, set E =  Ei. Obviously E ⊇Ei, so it is an upper bound; it remains to
show that E ∈AD, i.e., that E is θ-ad.
Now suppose that E is not θ-cf. Then there exist a1, a2 ∈E that attack each
other (a →b for θ = fr, a →T0 b for θ = lo). By the deﬁnition of E, there exist
Ei, Ej such that a1 ∈Ei, a2 ∈Ej for some i, j ∈I. It is the case that Ei ⊆Ej or
Ei ⊆Ej, so suppose, without loss of generality, that Ei ⊆Ej. Then a1, a2 ∈Ej,
a contradiction, since Ej is θ-ad (thus θ-cf). Thus, E is θ-cf. It remains to show
that E defends all a ∈E. Indeed, take some a ∈E. Then, a ∈Ei for some i ∈I,
and, thus Ei θ-defends a, which implies that E θ-defends a, since E ⊇Ei. Thus,
any ⊆-chain (Ei)i∈I in AD possesses an upper bound, which, by Zorn’s Lemma,
implies that AD has a maximal element, i.e., that there exists a θ-pr extension.
By proposition 6, this implies that there exists a θ-co extension as well.
For θ-gr extensions, note that ∅is θ-ad, so applying Proposition 7 for E∗= ∅
we ensure the existence of some E which is minimally θ-co, i.e., E is θ-gr.
⊓⊔
Proof of Proposition 9
Given that ∅is θ-ad, we can apply Proposition 7 for E∗= ∅to get some E
which is minimally θ-co, i.e., E is θ-gr. Now suppose that there is a second θ-gr
extension, say E′ (E′ ̸= E). Obviously, E ̸⊆E′ and E′ ̸⊆E. Set E0 = E ∩E′. It

An MAAF
435
follows that ∅⊆E0 ⊂E, so by Proposition 7 again there exists some a ∈E \ E0
which is θ-defended by E0 and E0∪{a} θ-cf. Moreover, E0 ⊂E′, so a is θ-defended
by E′. Thus, E′ is θ-gr, thus θ-co, and also E′ θ-defends a, so by Proposition 2,
a ∈E′, a contradiction by the choice of a.
⊓⊔
Proof of Proposition 10
The ﬁrst case is direct from Deﬁnition 3 and the deﬁnition of FF . The second
case is direct using proof by contradiction and the fact that E →T0 E implies
E →E. The third is direct from Deﬁnition 3.
⊓⊔
Proof of Proposition 11
The ﬁrst case follows from the fact that b →T0 c implies that b →c for any b, c ∈
A. For the second and third cases, note that a →b if and only if (a, b) ∈RF ,
and that a →T0 b implies that a →b. From these, and the deﬁnition of defense
in AAFs and MAAFs, the results follow easily.
⊓⊔
Proof of Proposition 12
The ﬁrst four cases are direct from Propositions 10, 11. For the ﬁfth case, note
that, since E is re-ad, it follows that for all a ∈E, E re-defends a for τ0, and,
thus, by Proposition 11, E defends a in FF . Combining this with the fact that
E is cf in FF , we get the result.
⊓⊔
Proof of Proposition 13
For the ﬁrst case, it suﬃces to show that, if E fr-defends a w.r.t. T0, then a ∈E.
Indeed, if E fr-defends a, then, by Proposition 11, E re-defends a, so, given that
E is re-co, it follows that a ∈E. The proofs for the other cases are analogous. ⊓⊔
Proof of Proposition 14
For the ﬁrst case, we note that ∅is fr-ad, so applying Proposition 7 for E∗= ∅,
we will get a fr-co extension (say E) that is minimal among fr-co extensions,
thus it is the (only) fr-gr extension of F. By Proposition 7 again, we observe
that, for any E′ ⊂E, there exists some a ∈E \ E′ such that E′ fr-defends a, i.e.,
E′ re-defends a, i.e., E′ is not re-co. Thus, E is re-gr.
The second case is totally analogous.
The third case uses a similar proof (and the same reasoning, except that the
existence of a is guaranteed by the results in [8] (instead of Proposition 7).
⊓⊔
Proof of Proposition 15
For the ﬁrst case, suppose that E is not fr-pr. Then, there exists some E′ ⊃E
such that E′ is fr-pr. But then, E′ is fr-ad so (by Proposition 12) E′ is re-ad, a
contradiction by the fact that E is re-pr. The other cases are analogous.
⊓⊔
Proof of Proposition 16
For the ﬁrst: observe that, by Proposition 10, E is maximally fr-cf if and only
if E is maximally re-cf. Then, the result is obvious by Deﬁnition 8.
For the second: we obtain by Proposition 10 that E is cf in FF . Also, since E is
fr-st, E →T0 a for all a /∈E, thus E →a in FF . We conclude that E is st in FF .
For the third: we observe that, by Proposition 10, E is maximally re-cf if and
only if it is maximally lo-cf. Now take some a /∈E. If E is re-st, then ext →T0 a,

436
A. Vassiliades et al.
so E →a, so E is lo-st. If E is lo-st, then E →a, and suppose that it is not the
case that E →T0 a. Then, E ∪{a} ⊃E and lo-cf, a contradiction.
For the fourth: since E is re-st, we get that E →T0 a whenever a /∈E, thus E →a
in FF for all a /∈E, and E is cf in FF by the hypothesis, so E is st in FF .
⊓⊔
References
1. Amgoud, L., Ben-Naim, J., Doder, D., Vesic, S.: Acceptability semantics for
weighted argumentation frameworks. In: IJCAI 2017, pp. 56–62 (2017)
2. Amgoud, L., Vesic, S.: Rich preference-based argumentation frameworks. Int. J.
Approximate Reasoning 55(2), 585–606 (2014)
3. Baroni, P., Cerutti, F., Giacomin, M., Guida, G.: AFRA: argumentation framework
with recursive attacks. IJAR 52(1), 19–37 (2011)
4. Baumann, R., Spanring, C.: Inﬁnite argumentation frameworks. In: Eiter, T.,
Strass, H., Truszczy´nski, M., Woltran, S. (eds.) Advances in Knowledge Repre-
sentation, Logic Programming, and Abstract Argumentation. LNCS (LNAI), vol.
9060, pp. 281–295. Springer, Cham (2015). https://doi.org/10.1007/978-3-319-
14726-0 19
5. Bench-Capon, T.J.M.: Persuasion in practical argument using value-based argu-
mentation frameworks. J. Log. Comput. 13(3), 429–448 (2003)
6. Besnard, P., Hunter, A.: A logic-based theory of deductive arguments. Artif. Intell.
128(1–2), 203–235 (2001)
7. Cayrol, C., Lagasquie-Schiex, M.: From preferences over arguments to preferences
over attacks in abstract argumentation: a comparative study. In: 25th IEEE Inter-
national Conference on Tools with Artiﬁcial Intelligence, pp. 588–595 (2013)
8. Dung, P.M.: On the acceptability of arguments and its fundamental role in non-
monotonic reasoning, logic programming and n-person games. Artif. Intell. 77(2),
321–357 (1995)
9. Dunne, P.E., Hunter, A., McBurney, P., Parsons, S., Wooldridge, M.: Weighted
argument systems: basic deﬁnitions, algorithms, and complexity results. Artif.
Intell. 175(2), 457–486 (2011)
10. E˘gilmez, S., Martins, J., Leite, J.: Extending social abstract argumentation with
votes on attacks. In: Black, E., Modgil, S., Oren, N. (eds.) TAFA 2013. LNCS
(LNAI), vol. 8306, pp. 16–31. Springer, Heidelberg (2014). https://doi.org/10.
1007/978-3-642-54373-9 2
11. Martınez, D.C., Garcıa, A.J., Simari, G.R.: An abstract argumentation framework
with varied-strength attacks. In: KR 2008, pp. 135–144 (2008)
12. Modgil, S.: Reasoning about preferences in argumentation frameworks. Artif. Intell.
173(9–10), 901–934 (2009)
13. Modgil, S., Prakken, H.: A general account of argumentation with preferences.
Artif. Intell. 195, 361–397 (2013)
14. Tarski, A.: A lattice-theoretical ﬁxpoint theorem and its applications. Pac. J. Math.
5(2), 285–309 (1955)
15. Tohm´e, F.A., Bodanza, G.A., Simari, G.R.: Aggregation of attack relations: a
social-choice theoretical analysis of defeasibility criteria. In: Hartmann, S., Kern-
Isberner, G. (eds.) FoIKS 2008. LNCS, vol. 4932, pp. 8–23. Springer, Heidelberg
(2008). https://doi.org/10.1007/978-3-540-77684-0 4
16. Vassiliades, A., Patkos, T., Bikakis, A., Flouris, G., Bassiliades, N., Plexousakis, D.:
Preliminary notions of arguments from commonsense knowledge. In: 11th Hellenic
Conference on Artiﬁcial Intelligence, pp. 211–214 (2020)

Towards a Sound and Complete Dialogue
System for Handling Enthymemes
Andreas Xydis(B), Christopher Hampson, Sanjay Modgil, and Elizabeth Black
Department of Informatics, King’s College London, London, UK
{andreas.xydis,christopher.hampson,sanjay.modgil,
elizabeth.black}@kcl.ac.uk
Abstract. A common assumption for argumentation-based dialogues
is that any argument exchanged is complete, in the sense that its
premises entail its claim. However, in real world dialogues, agents com-
monly exchange enthymemes—arguments with incomplete logical struc-
ture. This paper formalises the dialogical exchange of enthymemes that
are missing some constituent elements, such that it is not possible to
directly entail the claim of the intended argument from the premises of
the enthymeme exchanged. This can lead to misunderstandings between
agents; we provide a rich set of locutions for identifying and resolving
such misunderstandings, and a protocol that governs the use of these. We
show that, under certain conditions, the status of moves made during a
dialogue conforming to our system corresponds with the status of argu-
ments in the Dung argument framework instantiated by the contents of
the moves made at that stage in the dialogue. This is signiﬁcant since it
ensures that the use of enthyememes does not prevent the agents from
reaching the appropriate decision according to the information they have
shared.
Keywords: Argumentation · Enthymemes · Dialogue · Framework
1
Introduction
Context. Structured approaches to argumentation [1] deﬁne binary attack (or
defeat) relations amongst arguments constructed from a belief base of logical
formulae B. The claims of the winning (acceptable) arguments in the deﬁned
graph or ‘argument framework’ (AF) identify the non-monotonic inferences from
B. These approaches, initially deﬁned for single agent (monological) reasoning,
can be generalised to dialogical models of distributed reasoning in which agents
exchange arguments and other locutions (e.g., [4,7,13]). One then aims at show-
ing that the dialogue establishes a topic α as acceptable iﬀα is the claim of a jus-
tiﬁed argument in the AF deﬁned by the contents B of the locutions exchanged
(i.e., α is non-monotonically inferred from B). These models are motivated by
requirements for normatively scaﬀolding integration of human-AI and human-
human reasoning via dialogue [6], and thus need to account for features of real-
world dialogue.
c
⃝Springer Nature Switzerland AG 2021
P. Baroni et al. (Eds.): CLAR 2021, LNAI 13040, pp. 437–456, 2021.
https://doi.org/10.1007/978-3-030-89391-0_24

438
A. Xydis et al.
In structured argumentation, arguments typically consist of a conclusion
(claim) deductively and/or defeasibly inferred from some premises. However, the
aforementioned scaﬀolding requires that dialogues accommodate human agents’
ubiquitous use of ‘incomplete’ arguments known as enthymemes [18]. Most works
dealing with enthymemes focus on how an enthymeme can be constructed from
the intended argument and how the intended argument can be reconstructed
from a received enthymeme, based on assumptions that the sender and the
receiver make about their shared knowledge and context, e.g. [2,3,7–9]. Few
works that consider enthymemes additionally examine how enthymemes can be
handled during dialogues between human and/or computational agents.
Suppose that two agents Ag1 and Ag2 have a dialogue to decide whether
information about Blojo’s aﬀair should be published, where the intended argu-
ment of Ag1 is A = “If Blojo is no longer a public ﬁgure (¬pf ), information
about his aﬀair is not in the public interest (¬pi), and the information is private
(pr), then the information should not be published (¬pub). Blojo is no longer a
public ﬁgure. Aﬀairs do not concern the public (¬ap), hence information about
Blojo’s aﬀair is not in the public interest. Romantic preferences are private (rp),
hence the information about Blojo’s aﬀair is private. Therefore the information
about Blojo’s aﬀair should not be published.” (see Fig. 1(i)). Ag1 may move the
enthymeme E1 = “¬pf , ¬pi, and pr, hence ¬pub”, holding back from communi-
cating the supports for the intermediate conclusions ¬pi and pr. Ag2 might then
query ¬pi and pr (separately), eliciting Ag1’s arguments “¬ap hence ¬pi” and
“rp hence pr” (A′ and A′′ respectively; see Fig. 1(i)) which together ‘backward
extend’ E1 to yield the complete argument A.
In [10,11] and [13], the locutions formalised allow for the backward extension
of enthymemes where agents can ask for further information to justify what
appears as a premise in the enthymeme (as described in the above example).
However, these works do not support the use of enthymemes that require forward
extending in order to arrive at the claim, and which are commonly seen in real
world dialogues. Consider that argument B = “Blojo is UN envoy for the Middle
East (en), hence Blojo is a public ﬁgure (pf ).” is the intended argument of Ag2,
but Ag2 attacks E1 with the enthymeme E2 = en. It is not immediately clear
why E2 attacks E1 (since en does not directly challenge any element of E1).
As discussed in [5], to avoid misunderstanding and so ensure a fully rational
exchange, normative scaﬀolding would prompt Ag1 to seek clariﬁcation—“what
is implied by en such that your intended argument attacks E1?”—to which Ag2
might reply that en implies pf , thus forward extending E2 to yield B which
negates a premise in E1.1
1 Notice that before Ag1 seeks clariﬁcation, although it appears that Ag2 wins the
dialogue (since she moves E2 against A), E2 does not formally attack A (since E2
does not negate any element of A) and so Ag1’s argument A is determined acceptable
according to the AF constructed by the contents of the enthymemes revealed by the
agents. In other words, a mismatch can exist between the pragmatic and the logical
conclusions implied by a dialogue in which enthymemes are used.

Towards a Sound and Complete Dialogue System for Handling Enthymemes
439
A
E1
¬pub
¬pf
¬pi
pr
A′
A′′
¬ap
rp
B
E2
pf
en
(i)
A
¬pub
¬pf, ¬pi, pr ⇒¬pub
¬pf
¬pi
pr
¬ap ⇒¬pi
¬ap
rp →pr
rp
B
pf
en ⇒pf
en
(ii)
Fig. 1.
(i) shows a formal representation of the arguments and enthymemes in the
Blojo example from Sect. 1: arguments A and B (enclosed by a dashed line) as typically
represented in the ASPIC+ framework where a node is a claim (or intermediate claim)
and the node’s children are the premises that either strictly (if they are connected with
a solid line) or defeasibly (if they are connected with a dotted line) infer this claim
(or intermediate claim); the sub-arguments A′ and A′′ of A, which backward extend
A on ¬pi and pr, respectively, are enclosed by a dashed line; the enthymemes E1 of A
and E2 of B are enclosed by a dotted line; B forward extends E2. (ii) shows A and B
as we represent arguments in this paper, where the inference rules applied (⇒and →
denoting the defeasible and strict inference, respectively) are explicitly provided and a
claim (or intermediate claim) is connected to its premises via the inference rule applied.
Observe that [12] allows for both backward and forward extending of
enthymemes, as does the dialogue system in [14], which additionally enables
resolution of misunderstandings that arise due to use of enthymemes. However,
these and the above mentioned works do not consider how the outcome of the dia-
logue relates to the AF that is instantiated based on contents of the enthymemes
moved during a dialogue, meaning that there is no guarantee that the dialogue
outcome respects the underlying argumentation theory. A notable exception is
[13], but this work only addresses backward extension of enthymemes.
Contributions. Our primary contribution is the development of a dialogue sys-
tem in which agents can move enthymemes and seek clariﬁcation to elicit forward
extension of enthymemes, such that under certain conditions, the dialogical sta-
tus of the moves made during the dialogue—determined by what we call the
dialogue framework—corresponds to the acceptability of the arguments in the
Dung AF instantiated from the contents of the moves made at that stage in
the dialogue. This correspondence—not shown previously for dialogue systems
that support forward extension of enthymemes—is signiﬁcant since it demon-
strates that the dialogue system we propose respects the logic and semantics
of the underlying argumentation theory. Additionally, our results verify that
when enthymemes are implemented in a dialogue, participants can still reach
the same outcome as they would have done if they used their complete intended
arguments (as shown in the Blojo example described above). This is important

440
A. Xydis et al.
as we therefore show that there is no disadvantage to the use of enthymemes
in dialogues, a common real-world feature of dialogues that supports eﬃcient
inter-agent communication. If we are to enable eﬀective human-computer inter-
action and provide normative support for human-human dialogue, we need to
account for the ubiquitous use of enthymemes in real-world dialogues and make
sure that agents can still reach the “correct” conclusions based on the knowledge
they have shared.
Moreover, we formalise enthymemes in the ASPIC+ framework [16]—a gen-
eral framework that subsumes other argumentation formalisms, and that has
been shown to provide argumentative formalisations of a wide range of non-
monotonic logics. To the best of our knowledge, this paper is the ﬁrst to show
soundness and completeness results for dialogical generalisations of ASPIC+
(since complete arguments are a special case of enthymemes)2. Due to lack of
space, we do not here account for the backward extension of enthymemes nor for
the full range of misunderstandings that may occur due to use of enthymemes
(as done in [14]). However, our work paves the way for a sound and complete
dialogue system that accommodates use of any kind of enthymeme, and where
any kind of uncertainty that arises from their use can be resolved.
Paper Outline.
In Sect. 2 we review relevant background and formalise
enthymemes within ASPIC+. In Sect. 3 we deﬁne our dialogue system, instan-
tiation of a dialogue framework from the moves made during a dialogue, and
the evaluation of these moves. In Sect. 4 we prove soundness and completeness.
Finally, we conclude and review directions for future work in Sect. 5.
2
Preliminaries
The ASPIC+ framework [16] abstracts from the particularities of the underlying
language, the nature of conﬂict, the defeasible inference rules, and strict inference
rules (which can encode a deductive logic of one’s choosing) that are used to chain
inferences from premises to an argument’s conclusion. ASPIC+ arguments are
evaluated in a Dung AF [15], and ASPIC+ provides guidelines for ensuring that
the outcome of evaluation yields rational outcomes.
An ASPIC+ argumentation theory AT is a tuple ⟨AS, K⟩consisting of an
argumentation system AS and a knowledge base K. AS is a tuple ⟨L, ( · ), R, nom⟩
where L is a logical language and ( · ) : L →(2L −{∅}) is a function that
generalises the notion of negation, so as to declare that two formulae are in
conﬂict (e.g., married = {single, unmarried}). Additionally, R = Rs ∪Rdef is
a set of strict (Rs) and defeasible (Rdef ) inference rules and nom : R∗
def →L
(where R∗
def is the class of all defeasible rules) is a naming function which assigns
a name (or nominal) to each defeasible rule (so that rules can be referenced in the
object language). Lastly, R = Rs ∪Rdef is the (disjoint) union of a set of strict
2 [4] formalises a dialogical generalisation of ASPIC+ extended to accommodate rea-
soning about preferences; however soundness and completeness results are not shown.

Towards a Sound and Complete Dialogue System for Handling Enthymemes
441
rules Rs of the form p1, . . . , pn →p, and a set of defeasible rules Rdef of the form
p1, . . . , pn ⇒p, for p, p1, . . . , pn ∈L. For each rule r ∈R let antecedents(r) =
{p1, . . . , pn} denote the set of antecedents of r and consequent(r) = p denote the
consequent of r. Finally, a knowledge base K ⊆L is a set of premises.3
Deﬁnition 1. Given an argumentation system AS = ⟨L, ( · ), R, nom⟩and an
argumentation theory AT = ⟨AS, K⟩, an argument is a labelled (downward
directed) tree A = ⟨Nodes(A), Edges(A), labA⟩such that:
1. labA : Nodes(A) →L ∪R is a node labelling;
2. Edges(A) ⊆Nodes(A)×Nodes(A) such that if (ni, nj) ∈Edges(A), then either:
(a) labA(ni) ∈L, labA(nj) ∈R and consequent(labA(nj)) = labA(ni), or
(b) labA(ni) ∈R and antecedents(labA(ni)) = {labA(nj) | (ni, nj) ∈
Edges(A)} ⊆L,
and if (ni, nj), (ni, nk) ∈Edges(A) and nj ̸= nk then labA(nj) ̸= labA(nk);
3. for every node n ∈Leaves(A), we have labA(n) ∈K;
4. |Roots(A)| = 1;
5. labA(Conc(A)) ∈L, where Conc(A) is the unique element in Roots(A);
where Leaves(A) = {ni ∈Nodes(A) | ∄(ni, nj) ∈Edges(A)}, and Roots(A) =
{ni ∈Nodes(A) | ∄(nj, ni) ∈Edges(A)}. Let AAT denote the set of arguments
instantiated using the elements in AT. Let A∗denote the class of all arguments,
and deﬁne Rules(A) = {n ∈Nodes(A) | labA(n) ∈R}, for all A ∈A∗.
In the above deﬁnition of an argument, a strict/defeasible inference rule is
incorporated as a node, intermediating between the parent node (the rule’s con-
clusion) and the child node(s) (the rule’s antecedent(s)). This contrasts with
the standard ASPIC+ notion of an argument in which the rules are represented
by undirected edges (where solid lines represent strict rules and dotted lines
represent defeasible rules) linking the conclusion to the rule’s antecedents (see
Fig. 1(i) and 1(ii)).
The binary attack and defeat relations over arguments are deﬁned as for
ASPIC+ arguments. An attack from argument X to argument Y may succeed
as a defeat, contingent on preferences deﬁned over the argument X and the
targeted sub-argument of Y , if X’s claim conﬂicts with an ordinary premise or
the consequent or name of a defeasible rule in Y (see [16] for more details).
Deﬁnition 2. The argument framework AF instantiated by an argu-
mentation theory AT is a tuple ⟨AAT , Dfs⟩where Dfs ⊆AAT × AAT is the
ASPIC+ defeat relation.
In the deﬁnition below, we deﬁne a complete labelling on the argument frame-
work instantiated by an argumentation theory [17].
3 Note that in this paper we do not utilise the ASPIC+ distinction between the disjoint
sets of axiom (Kn) and ordinary (Kp) premises (K = Kn ∪Kp), whereby only
ordinary premises are fallible and so can be challenged/attacked.

442
A. Xydis et al.
A′
¬pub
¬pi
¬ap ⇒¬pi
rp →pr
rp
(i)
E′
E
¬pub
¬pf, ¬pi, pr ⇒¬pub
¬pf
¬pi
pr
¬ap ⇒¬pi
¬ap
rp →pr
rp
(ii)
Fig. 2.
(i) shows a valid enthymeme in this paper, which is generated by removing
multiple elements of A in Fig. 1(ii) such as inference rules, premises, and intermediate
conclusions of A. (ii) Shows an upwards extendable enthymeme E of A and the upwards
extension E′ of E that yields A.
Deﬁnition 3. Let AF = ⟨AAT , Dfs⟩be instantiated by AT. We deﬁne a com-
plete labelling on AF to be a (total) function L : AAT →{in, out, undec}
such that for every X ∈AAT :
1. L(X) = in iﬀfor all Y ∈AAT , if (Y, X) ∈Dfs then L(Y ) = out;
2. L(X) = out iﬀthere exists Y ∈AAT such that (Y, X) ∈Dfs and L(Y ) = in;
3. L(X) = undec iﬀL(X) ̸= in and L(X) ̸= out.
This paper does not adopt the standard ﬁgurative representations of ASPIC+
arguments (e.g., Fig. 1(i)) because when an enthymeme E is constructed from an
intended argument A, one may choose to remove the conclusion of an inference
rule while retaining the inference rule, or remove a sub-argument whose conclu-
sion is the antecedent of a strict/defeasible rule (see Fig. 2(i)). So an enthymeme
E of an argument A is a forest of trees (i.e. a disjoint union of trees), whose
nodes and edges are a subset of the nodes and edges of A, and the label of each
node in E is the same label of the corresponding node in A.
Deﬁnition 4. Let AT = ⟨AS, K⟩and A ∈AAT . An enthymeme E of
an argument A (written E ≤A) is a labelled (downward directed) tree
E = ⟨Nodes(E), Edges(E), labE⟩such that ∅̸= Nodes(E) ⊆Nodes(A) and
Edges(E) ⊆Edges(A)∩(Nodes(E)×Nodes(E)) and for every node n ∈Nodes(E),
labE(n) = labA(n).
As for arguments, we deﬁne Roots(E) = {ni ∈Nodes(E) | ∄(nj, ni) ∈
Edges(E)} and Leaves(E) = {ni ∈Nodes(E) | ∄(ni, nj) ∈Edges(E)}.
Note that the union of two enthymemes E1 and E2, deﬁned in the obvi-
ous way, is itself an enthymeme (denoted E1 ∪E2) and that an argument A
is an enthymeme of itself, where Roots(A) = {Conc(A)} and {lab(n) : n ∈
Leaves(A)} ⊆K. The class of all enthymemes is denoted E∗and so includes the
class of all arguments (A∗⊆E∗).

Towards a Sound and Complete Dialogue System for Handling Enthymemes
443
As mentioned earlier, this paper only focuses on the forward extension of
enthymemes. In other words, we are interested in enthymemes for which the only
missing information needed to reconstruct the complete argument (from which
an enthymeme was generated) is the information between the roots of the trees
of the enthymeme and the root (claim) of the intended argument. Therefore, we
deﬁne an upwards extendable enthymeme E of an argument A as an enthymeme
which includes the premises (leaves) of A, and for each root rt of a tree in E,
the label of rt is an element of L, i.e. that either it is a premise, in the case that
rt is also a leaf, or it is the consequent of a rule used in E (e.g., see Fig. 2(ii)).
Deﬁnition 5. We say that E = ⟨Nodes(E), Edges(E), labE⟩is an upwards
extendable enthymeme of A = ⟨Nodes(A), Edges(A), labA⟩iﬀ(i) Leaves(E) =
Leaves(A), and (ii) labE(n) ∈L, for every n ∈Roots(E).
If E is an upwards extendable enthymeme of A, then we deﬁne the upwards
extension of E that yields A to be the enthymeme E′ (unique up to isomor-
phism) of A such that A = E ∪E′ and Roots(E) = Leaves(E′) (e.g., see
Fig. 2(ii)).
Notice that if Conc(A) ∈Roots(E), then Roots(E) = {Conc(A)} and E = A.
3
Dialogue System
In this section we present a dialogue system that handles enthymemes, and
deﬁne how its dialogues can be represented by a dialogue framework (i.e., a graph
whose nodes correspond to the moves made during the dialogue and whose edges
represent the relationships between those moves). A complete labelling function
on the dialogue framework evaluates the dialogical status of a move; in Sect. 4 we
show that this evaluation is sound and complete with reference to the argument
framework AF instantiated from the contents of all the moves made during the
dialogue. That is to say, an argument moved in the dialogue is judged to be
winning in the dialogue under Dung’s complete semantics iﬀthe claim of the
corresponding argument is justiﬁed (under Dung’s complete semantics) in the
AF instantiated from the contents of the moves of the dialogue.
An enthymeme dialogue d between Prop and Op is a sequence of moves,
where each move is a 5-tuple that comprises the move’s sender, locution, content,
target and reply. The sender of each move is either Prop or Op (the participants
of the dialogue). The locution of a move can be assert (used to posit upwards
extendable enthymemes), and-so (used to request an upwards extension to an
enthymeme) or hence (used to provide an upwards extension to an enthymeme).
The content of a move depends on its locution: if a move’s locution is assert
or hence, its content is an enthymeme; if a move’s locution is and-so, its content
is ∅. The and-so and hence moves are made in explicit response to a previous
move made: if a move’s locution is and-so or hence, its reply is a natural number
that is the index of the move to which it replies, otherwise its reply is ∅. When
assertions are made, the enthymeme being asserted is being moved as a defeat
against an enthymeme previously moved—the target of the assertion. If a move’s

444
A. Xydis et al.
locution is assert, its target is the natural number that indexes the move whose
content is the asserted enthymeme that is being moved against otherwise its
target is ∅.
When an agent asserts an enthymeme, or moves an upwards extension to
an enthymeme with a hence move, it has in mind a complete argument and
this is the intended argument of the move. Note, since we may be dealing with
nefarious agents, we do not insist here that the intended argument of a move
must indeed extend the enthymeme moved; in Sect. 4 we consider honest agents,
whose intended arguments do indeed extend the enthymemes moved and can be
constructed from the sender’s belief base. Similarly, when an agent asserts an
enthymeme as a defeat against some target enthymeme, the agent has in mind a
particular argument that it believes was intended as the complete argument of
the target enthymeme: this is the intended target argument of the assert move.
Section 4 considers understanding agents, whose intended targeted arguments
match the intended argument of the target.
Deﬁnition 6. An enthymeme dialogue between two participants Prop and
Op
is a sequence of moves d
=
[m0, m1, . . . , mℓ], where each move
mi = ⟨s(mi), l(mi), c(mi), re(mi), t(mi)⟩is a 5-tuple comprising the following:
– Sender: s(mi) ∈{Prop, Op};
– Locution: l(mi) ∈{assert, and-so, hence};
– Content: if l(mi) ∈{assert, hence} then c(mi) ∈E∗, otherwise c(mi) = ∅;
– Reply: if l(mi) ∈{and-so, hence} then re(mi) ∈{0, . . . , (i −1)}, otherwise
re(mi) = ∅;
– Target: if l(mi) ∈{assert} then t(mi) ∈{0, . . . , (i −1)} ∪{∅}, otherwise
t(mi) = ∅.
If l(m) ∈{assert, hence}, IntArg(m) ∈A∗is the intended argument of m and
if l(m) = assert, IntTarArg(m) ∈(A∗∪{∅}) is the intended target argument.
We now deﬁne a well-formed enthymeme dialogue d with two participants,
Prop and Op. We assume that the agents share the same underlying argumenta-
tion system, ensuring they can understand each other, except that the defeasible
rules they are each aware of may diﬀer (and of course they may each have diﬀer-
ent belief bases, which are not deﬁned by the argumentation system). The par-
ticipants alternate turns and cannot repeat moves. Prop must start by asserting
an argument (the conclusion of which we call the topic of the dialogue) and so
we disallow a participant to ask for a forward extension of this argument with
an and-so move.
An assert move puts forward an upwards extendable enthymeme4 that targets
(i.e., is moved as a defeat against) an enthymeme that has been moved previously
(except for the ﬁrst assert move, which has no target). Note that, while the
target m′ of a move m consists of the enthymeme E′ (E′ = content of m′)
this does not necessarily imply a valid defeat relation from the content E of m
4 Recall, here we deal only with forward extension of enthymemes, so that an ‘upwards
extendable enthymeme’ is an enthymeme that can potentially be forward extended.

Towards a Sound and Complete Dialogue System for Handling Enthymemes
445
Table 1. A well-formed enthymeme dialogue d = [m0, . . . , m6]. The internal structure
of enthymemes and intended arguments of moves are shown in Fig. 3.
Step Dialogue d
IntArg(mi) IntTarArg(mi)
1
m0 = (Prop, assert, E, ∅, ∅)
E
∅
2
m1 = (Op, assert, A′, ∅, 0)
A
E
3
m2 = (Prop, and-so, ∅, 1, ∅)
–
–
4
m3 = (Op, hence, A′′, 2, ∅)
A
–
5
m4 = (Prop, assert, B′, ∅, 1) B
A
6
m5 = (Op, assert, C, ∅, 4)
C
B
7
m6 = (Prop, assert, D, ∅, 3)
D
A
(i.e. while m’s enthymeme E purportedly defeats E′ in m′, E may not validly
defeat E′ according to the ASPIC+ deﬁnition of defeat). Since we are dealing
with enthymemes, the existence of valid defeat relations cannot necessarily be
determined and our deﬁnition of well-formed enthymeme dialogues does not
enforce them—the participants may be mistaken in the assumptions they have
made regarding the other’s intended arguments (i.e. E may not legitimately
defeat the intended argument of m′), or may dishonestly target a move, even
knowing that their enthymeme does not defeat it, for strategic purposes.
An and-so move is used to request an upwards extension of a previously
asserted upwards extendable enthymeme, while a hence move replies to a previ-
ous and-so move and provides an upwards extension of the questioned upwards
extendable enthymeme. Table 1 shows a well-formed enthymeme dialogue d and
Fig. 3 shows the internal structure of enthymemes and intended arguments of
moves made in d together with a natural language translation.
Deﬁnition 7. Let AS Ag = ⟨L, ( · ), RAg, nom⟩be an argumentation system for
Ag ∈{Prop, Op} such that RAg = Rs ∪RAg
def , where RAg
def is Ag’s defeasible rules.
An enthymeme dialogue d = [m0, . . . , mℓ] between Prop and Op is said to be
well-formed if mi ̸= mj for all i ̸= j, and for all i ≤ℓ:
1. s(mi) = Prop if i is even, otherwise s(mi) = Op;
2. If i = 0, then l(mi) = assert, c(mi) ∈A∗, and t(mi) = ∅;
3. If i > 0 and l(mi) = assert, then c(mi) is an upwards extendable enthymeme
of an argument A ∈A∗and t(mi) = j such that l(mj) ∈{assert, hence};
4. If l(mi) = and-so, then re(mi) = j > 0 and l(mj) = assert;
5. If l(mi) = hence, then there exists A ∈A∗such that A = c(mi) ∪c(mk) and
re(mi) = j such that l(mj) = and-so and re(mj) = k.
The topic of d (denoted Topic(d)) is the label of the conclusion of the argu-
ment moved in m0.
Henceforth, we use ‘dialogue’ as a shorthand for a well-formed enthymeme
dialogue, and write di to refer to a dialogue whose last move is mi (i.e.

446
A. Xydis et al.
E
Information about Blojo’s aﬀair should be
published.
(pub)
B
B′
Therefore, Blair is a public ﬁgure.
(pf)
If Blair is UN envoy for the Middle East
then apparently Blair is a public ﬁgure.
(en ⇒pf)
Blair is UN envoy for the Middle East.
(en)
A
A′′
A′
Information about Blojo’s aﬀair should not be
published.
(¬pub)
If Blojo is no longer a public ﬁgure, information about his aﬀair is
not in the public interest, and information is private then
apparently information about Blojo’s aﬀair should not be published.
(¬pf, ¬pi, pr ⇒¬pub)
Blojo is no longer a
public ﬁgure.
(¬pf)
Hence, Blojo’s aﬀair is
not in the public interest.
(¬pi)
Hence, information about
Blojo’s aﬀair is private.
(pr)
If aﬀairs do not concern
the public, then
apparently Blair’s aﬀair is
not in the public interest.
(¬ap ⇒¬pi)
Aﬀairs do not
concern the public
(¬ap)
If romantic preferences
are private then
information about
Blojob’s aﬀair is private.
(rp →pr)
Romantic
preferences are
private.
(rp)
C
Therefore, Blair is not UN envoy for the
Middle East.
(¬en)
If Blair was ﬁred then Blair is not UN
envoy for the Middle East.
(f →¬en)
Blair was ﬁred.
(f)
D
Therefore, information about Blojo’s
aﬀair should be published.
(pub)
If publishing a scandal regarding Blair would return
huge earnings then apparently information about
Blojo’s aﬀair should be published.
(se ⇒pub)
Publishing a scandal regarding Blair
would return huge earnings.
(se)
Fig. 3. The internal structure of enthymemes (enclosed by a dotted line) and intended
arguments of moves in d (enclosed by a dashed line) described in Table 1, with pub
being the topic of the dialogue. We, also, show the natural language translation of each
premise (green), inference rule (purple), intermediate conclusion (orange) and claim of
intended argument (red). (Color ﬁgure online)
di = [m0, . . . , mi]). We deﬁne a dialogue framework of a dialogue d as a 4-
tuple DF = ⟨M, T , R, S⟩where M is the set of moves made in d, T is a binary
defeat relationship between moves that is determined by the target relationship
between moves, R is a binary reply relationship that is determined by the reply
relationship between moves, and S is a binary support relationship that is deter-
mined by the reply relationship (mi supports mj iﬀthere is some m such that
mi replies to m and m replies to mj). Intuitively, the content E′ of mi is used
as a response to m, where m questions the sender of mj to provide an upwards
extension of the enthymeme E in mj. Hence E′ upward extends E and so mi
supports mj. Finally, we let mi ∼S mj denote that either mi = mj, or that mi
supports mj, or that mj supports mi. For example, Fig. 4 depicts the dialogue
framework of the dialogue presented in Table 1.
Deﬁnition 8. The dialogue framework of a dialogue d = [m0, . . . , mℓ] is a
tuple DF = ⟨M, T , R, S⟩where:
– M = {m0, . . . , mℓ} is the set of moves of d,
– T ⊆M × M is a binary defeat relation such that miT mj ⇐⇒t(mi) = j,

Towards a Sound and Complete Dialogue System for Handling Enthymemes
447
m0
m1
m2
m3
m4
m5
m6
T
T
T
T
S
R
R
in
in
in
in
out
out
out
Fig. 4. The dialogue framework DF instantiated by d presented in Table 1. According
to the complete labelling L on DF, L(m0) = L(m2) = L(m5) = L(m6) = in and
L(m1) = L(m3) = L(m4) = out.
– R ⊆M × M is a binary reply relation such that miRmj ⇐⇒re(mi) = j,
– S ⊆M × M is a binary support relation such that miSmj ⇐⇒∃m ∈M :
miRm and mRmj.
Take ∼S ⊆M × M to be the smallest equivalence relation containing S.
We deﬁne a complete labelling on a dialogue framework DF = ⟨M, T , R, S⟩
such that the label of a move m ∈M is in iﬀa) for every move m′ that targets
or replies to m, m′ is labelled out; and b) if m supports a move m′′ and there
is a move m′′′ targeting m′′, then for every such move m′′′, m′′′ is labelled out
(intuitively, since m’s enthymeme forward extends m′′’s enthymeme, then any
challenge on m′′ is a challenge on m, and so must be out in order that m
be in). Additionally, m ∈M is labelled out iﬀa) there is a move m′ that
targets or replies to m such that m′ is labelled in; or b) there is a move m′′
that m supports (i.e., m’s enthymeme forward extends m′′’s enthymeme) such
that there is a move m′′′ that targets m′′ and m′′′ is labelled in. Figure 4 shows
a complete labelling on a DF. A move m ∈M is labelled undec iﬀit is not
labelled in or out.
Deﬁnition 9. Let DF = ⟨M, T , R, S⟩be the dialogue framework of a dialogue
d. We deﬁne a complete labelling on DF to be a (total) function L : M →
{in, out, undec} such that, for every mi ∈M:
1. L(mi) = in iﬀfor all mj, mk ∈M:
(a) if (mj, mi) ∈T ∪R then L(mj) = out, and
(b) if (mi, mj) ∈S and (mk, mj) ∈T then L(mk) = out;
2. L(mi) = out iﬀthere is some mj, mk ∈M such that:
(a) (mj, mi) ∈T ∪R and L(mj) = in, or
(b) (mi, mj) ∈S, (mk, mj) ∈T and L(mk) = in.
We deﬁne an argumentation theory instantiated by a dialogue d as a tuple
ATd = ⟨ASd, Kd⟩, where the logical language L, the contrariness function ( · ),
the naming function nom, and the strict rules Rs of ASd are those shared by the
participants of d (as assumed in Deﬁnition 7). The defeasible rules of ASd is the
set of all the defeasible rules revealed during d. The premises in ATd (i.e., Kd)
is the set of the labels of the leaves of the enthymemes that have been moved

448
A. Xydis et al.
during d with an assert move; this is because, as described earlier, the content
E of an assert move is an upwards extendable enthymeme and so its leaves
are the premises of the argument A from which E was constructed (according
to Deﬁnition 5), whereas all the other elements of L in E and in the content
E′ of every hence move in d are the conclusions of inference rules. Lastly, we
deﬁne an argumentation theory of an agent Ag instantiated by a dialogue d as
a tuple AT Ag
d
= ⟨ASAg
d , KAg
d ⟩where L, ( · ), nom and Rs are the same elements
as explained earlier, the defeasible rules of ASAg
d
is the set of defeasible rules
revealed during d together with the defeasible rules that Ag knows, and KAg
d
is
the set of premises revealed during d together with the premises that Ag knows.
Deﬁnition 10. Let d = [m0, . . . , mℓ] be a dialogue between Prop and Op, where
AS Ag = ⟨L, ( · ), RAg, nom⟩is the argumentation system for Ag ∈{Prop, Op}
and RAg = Rs ∪RAg
def . The set of defeasible rules in d is given by:
DefDRules(d) =
ℓ
i=0

labc(mi)(n) ∈R∗
def | c(mi) ∈E∗and n ∈Nodes(c(mi))

.
The set of premises in d is:
DPrem(d) =
ℓ
i=0

labc(mi)(n) ∈L | l(mi) = assert and n ∈Leaves(c(mi))

.
The argumentation theory instantiated by dialogue d is ATd = ⟨ASd, Kd⟩,
where ASd = ⟨L, ( · ), Rs ∪DefDRules(d), nom⟩and Kd = DPrem(d).
The argumentation theory of Ag instantiated by dialogue d is AT Ag
d
=
⟨ASAg
d , KAg
d ⟩, where ASd = ⟨L, ( · ), Rs ∪DefDRules(d) ∪RAg
def , nom⟩and Kd =
DPrem(d) ∪KAg.
Example 1. From Table 1 and Fig. 3, Kd = {pub; ¬pf ; ¬ap; rp; en; f ; se} and
DefDRules(d) = {¬ap ⇒¬pi; ¬pf , ¬pi, pr ⇒¬pub; en ⇒pf ; se ⇒pub}.
4
Soundness and Completeness
In this section we show a soundness and completeness correspondence between
the status of moves made in a dialogue (as determined by a complete labelling
on the dialogue framework) and the status of the intended arguments of those
moves in the argument framework instantiated by the dialogue (as determined by
a complete labelling on the argument framework). This correspondence depends
on agents being honest and understanding, and on the dialogue being exhaustive.
If the participants of a dialogue are honest then the content of the ﬁrst
move is the same as its intended argument and there is no intended targeted
argument (since the ﬁrst move does not have a target). It also means that the
intended argument of a move, whose content is an enthymeme, is an argument
that the sender can construct based on their own private knowledge and the

Towards a Sound and Complete Dialogue System for Handling Enthymemes
449
knowledge shared so far during the dialogue. If the participants of a dialogue are
honest, this ensures that whenever they assert an enthymeme, this can indeed
be upwards extended to provide the intended argument of the move, and the
intended argument does defeat the intended targeted argument of the move (i.e.,
what the sender assumes to be the target move’s intended argument) according
to the ASPIC+ deﬁnition of defeat.5 An honest agent will only make an and-so
move requesting an upwards extension to a previously asserted enthymeme, if
that enthymeme does not defeat the content of its target (the intuition here is
that an honest agent will not make spurious and-so moves when it is clear from
the publicly moved information why an enthymeme has been moved). Finally,
if an honest agent makes a hence move to supply an upwards extension to a
previously asserted (and subsequently questioned with an and-so) enthymeme,
then the intended argument of the hence move is the same as the intended
argument of the questioned enthymeme, and the content of the hence move is
the upwards extension to the enthymeme that yields this intended argument.
Deﬁnition 11. Let d = [m0, . . . , mℓ] be a dialogue between Prop and Op, and
DF = ⟨M, T , R, S⟩the dialogue framework of d. Then Ag ∈{Prop, Op} is
honest with respect to d iﬀfor every i ≤ℓsuch that s(mi) = Ag:
1. If i = 0, then c(mi) = IntArg(mi) and IntTarArg(mi) = ∅;
2. If c(mi) ∈E∗, then IntArg(mi) ∈AAT Ag
di ;
3. If l(mi)
=
assert and miT mj, then c(mi)
≤
IntArg(mi), c(mj)
≤
IntTarArg(mi), and IntArg(mi) defeats IntTarArg(mi);
4. If l(mi) = and-so, miRmj and mjT mk, then c(mj) does not defeat
IntArg(mk);
5. If l(mi) = hence, miRmj and mjRmk, then IntArg(mi) = IntArg(mk), and
IntArg(mi) = c(mi) ∪c(mk).
Example 2. Based on Table 1 and Fig. 3, we assume A is preferred to E since
E is just a statement, whereas A is an argument whose claim is supported
by some rationale. We also assume D is preferred to A since in the example’s
assumed context (the editorial board of a newspaper) ﬁnancial considerations
take precedence. Therefore, Prop and Op are honest.
Suppose an honest agent asserts an enthymeme E, their counterpart replies to
E with an and-so move and the agent replies with a hence move whose content is
an enthymeme E′. We know that E and E′ are enthymemes of the same intended
argument A (essentially, if there are two moves m and m′ in d such that their
contents are enthymemes and either m = m′ or there is a support relationship
between m and m′ then their intended arguments are the same).
Lemma 1. Let d = [m0, . . . , mℓ] be a dialogue between Prop and Op who are
honest with respect to d. If mi ∼S mj (j, i ≤ℓ) then IntArg(mi) = IntArg(mj).
5 We assume that the participants of a dialogue have the same preferences and so they
agree to whether an argument A defeats an argument B or not.

450
A. Xydis et al.
Proof. The proof is straightforward and follows from Deﬁnitions 7, 8 and 11.5.
⊓⊔
When an honest participant moves an enthymeme E against an enthymeme
E′, their belief is that their intended argument of E defeats the intended argu-
ment of E′. However, they may be mistaken about the intended argument of E′.
To deal with the full range of misunderstandings that can ensure thorough use
of enthymemes, a large number of locutions is needed (as shown in [14]). For
reasons of space, in this paper we assume that these misunderstandings do not
arise so that we can restrict the locutions we require to a small set. We thus
assume understanding participants; i.e., the intended targeted arguments of the
moves they make correctly match each other. For example, Prop and Op from
Table 1 are understanding.
Deﬁnition 12. Let d = [m0, . . . , mℓ] be a dialogue between Prop and Op. Prop
and Op are understanding agents (with respect to d) iﬀfor every i = 0, . . . , ℓ,
if l(mi) = assert, then IntTarArg(mi) = IntArg(mj) where t(mi) = j.
A dialogue d with honest and understanding participants is exhaustive iﬀ:
if there is an argument that can be constructed from the argument framework
instantiated by d and that argument defeats the intended argument of some move
m, then that argument has been asserted to target m′, where either m′ = m, or
there is a support relation between m and m′ (since the participants are honest,
by Lemma 1, m and m′ have the same intended argument and so an agent can
target either one of the two moves); if an enthymeme has been asserted and does
not defeat its target, then an and-so has been moved as a reply to the assertion
(requesting that the enthymeme be extended to make the defeat explicit); and
if an and-so is moved, then it is responded to. This is similar to Prakken’s [13]
notion of logical completeness.
Deﬁnition 13. Let d = [m0, . . . , mℓ] be a dialogue with participants who are
both honest and understanding with respect to d. Let DF = ⟨M, T , R, S⟩be
the dialogue framework of d and AF = ⟨AAT d, Dfs⟩be the argument framework
instantiated by the argumentation theory AT d. We say that d is exhaustive iﬀ
for every i ≤ℓ:
1. if there are A, B ∈AAT d such that IntArg(mi) = A and B defeats A, then
there are moves mj, mk ∈M such that IntArg(mj) = B, mi ∼S mk and
t(mj) = k;
2. if l(mi) = assert and c(mi) does not defeat IntTarArg(mi), then there is a
move mj where j > i such that l(mj) = and-so and re(mj) = i;
3. if l(mi) = and-so, then there is a move mj where j > i, such that l(mj) =
hence and re(mj) = i;
Example 3. The dialogue given in Table 1 is not exhaustive since there is no
and-so move that replies to m4.

Towards a Sound and Complete Dialogue System for Handling Enthymemes
451
If a dialogue d is exhaustive with honest and understanding participants, then
for every move made whose content is an enthymeme, its intended argument can
be instantiated by the argumentation theory instantiated by d. In what follows,
let d = [m0, . . . , ml] be an exhaustive dialogue between agents Prop and Op who
are both honest and understanding with respect to d, and let DF = ⟨M, T , R, S⟩
and AF = ⟨AAT d, Dfs⟩be, respectively, the dialogue framework of d and the
argument framework instantiated by AT d.
Lemma 2. For every mi ∈M, if c(mi) ∈E∗then IntArg(mi) ∈AAT d.
Proof. Let mi ∈M be such that c(mi) ∈E∗, and let Ei = c(mi). If Ei =
IntArg(mi) then, by Deﬁnition 10, the premises of Ei belong to Kd and the
defeasible rules of Ei belong to DefDRules(d) so IntArg(mi) ∈AAT d. Otherwise
Ei ̸= IntArg(mi) and, by Deﬁnitions 11.3 and 11.5, we must have that Ei ≤
IntArg(mi). We have two cases:
Case 1) Suppose that l(mi) = assert. So by Deﬁnition 11.3, Ei ≤IntArg(mi)
and IntArg(mi) defeats IntTarArg(mi). By Deﬁnition 7.3, and since
Ei ̸= IntArg(mi) and Ei ≤IntArg(mi), Ei is an upwards extend-
able enthymeme of IntArg(mi) and Conc(Ei) ̸= Conc(IntArg(mi)), so
Ei does not defeat IntTarArg(mi). Thus, by Deﬁnitions 13.2 and 13.3,
there are moves m, mj ∈M such that mjRmRmi. By Deﬁnition 11.5,
IntArg(mi) = c(mi) ∪c(mj). Therefore, IntArg(mi) ∈AAT d.
Case 2) Suppose that l(mi) = hence. So by Deﬁnition 7.5, there are moves
m, mj ∈M such that miRmRmj and, by Deﬁnition 11.5, IntArg(mi) =
c(mi) ∪c(mj). Therefore, IntArg(mi) ∈AAT d.
⊓⊔
If a dialogue d is exhaustive, with honest and understanding participants,
and includes a move mi that targets mj, then the intended argument of mi
defeats the intended argument of mj in the AF instantiated by d (i.e., if there is
a targeting relationship between two moves in the DF then there is also a defeat
relationship between their intended arguments in the AF instantiated by d).
Lemma 3. If there are moves mi, mj ∈M such that (mi, mj) ∈T then it holds
that (IntArg(mi), IntArg(mj)) ∈Dfs.
Proof. By Lemma 2, for every mi ∈M such that c(mi) ∈E∗, IntArg(mi) ∈
AAT d. By Deﬁnitions 11.3 and 12, IntArg(mi) defeats IntArg(mj).
⊓⊔
We now show our main result. If a dialogue is exhaustive, with participants
who are honest and understanding, then the dialectical status of the moves in
the DF (determined by a complete labelling) is sound and complete in relation
to the dialectical status of the arguments in the AF instantiated by the contents
of the moves made in the dialogue (determined by a complete labelling).
Theorem 1. Let d = [m0, . . . , mℓ] be an exhaustive dialogue between Prop and
Op, who are honest and understanding with respect to d. Let DF = ⟨M, T , R, S⟩
be the dialogue framework of d, and AF = ⟨AAT d, Dfs⟩the argument framework
instantiated by the argumentation theory AT d. It follows that:

452
A. Xydis et al.
(i) For every complete labelling function LAF on AF, there exists a complete
labelling function LDF on DF such that for every mi ∈M, if c(mi) ∈
E∗then:
LDF(mi) = LAF(IntArg(mi)).
(ii) For every complete labelling function LDF on DF, there exists a complete
labelling function LAF on AF such that for every A ∈AAT d, if there is some
mi ∈M such that A = IntArg(mi) then:
LAF(A) = LDF(mi).
Proof. (i) Let LAF be a complete labelling on AF and deﬁne a new function LDF
on DF such that for all mi ∈M,
LDF(mi) = LAF(IntArg(mi))
(1)
if c(mi) ∈E∗and the usual
LDF(mi) =
⎧
⎪
⎨
⎪
⎩
in
if ∀mj ∈M; mjRmi implies LDF(mj) = out,
out
if ∃mj ∈M; mjRmi and LDF(mj) = in,
undec
otherwise
(2)
if c(mi) ̸∈E∗, which is to say, when l(mi) = and-so.
We claim that LDF is a complete labelling on DF, so suppose mi ∈M:
Case 1) Suppose that LDF(mi) = in.
– Suppose to the contrary that there is some mj ∈M such that
(mj, mi) ∈T and LDF(mj) ̸= out. It follows that c(mi), c(mj) ∈E∗
and LAF(IntArg(mj)) ̸= out. Based on Lemma 3, we have that
(IntArg(mj), IntArg(mi)) ∈Dfs in AF and since LAF(IntArg(mj)) ̸=
out, we have that LAF(IntArg(mi)) ̸= in, contrary to (1).
– Suppose to the contrary that there is some mj ∈M such that
(mj, mi) ∈R and LDF(mj) ̸= out. From (2) we must have that
c(mi) ∈E∗and hence l(mj) = and-so. By Deﬁnition 13.3, there is
some mk ∈M such that c(mk) ∈E∗and (mk, mj) ∈R. By (2) we
must have that LDF(mk) ̸= in and so by (1), LAF(IntArg(mk)) ̸= in.
By Lemma 1, we then have that IntArg(mi) = IntArg(mk) and so
LAF(IntArg(mi)) ̸= in, contrary to (1).
– Suppose to the contrary that there is some mj, mk ∈M such that
(mi, mj) ∈S, (mk, mj) ∈T and LDF(mk) ̸= out, and so we have
that LDF(mj) ̸= in. Then c(mi), c(mk) ∈E∗and by (1), we have that
LAF(IntArg(mk)) ̸= in. Then by Lemma 1, we have that IntArg(mi) =
IntArg(mk) and so LAF(IntArg(mi)) ̸= in, contrary to (1).
Conversely, suppose that LDF(mi) ̸= in. If c(mi) ̸∈E∗then by (2),
there is some mj ∈M such that (mj, mi) ∈R and LDF(mj) ̸= out,
as required. Otherwise, by (1), LAF(IntArg(mi)) ̸= in. Hence, according
to Deﬁnition 3 there is some A ∈AAT d such that (A, IntArg(mi)) ∈Dfs
and LAF(A) ̸= out. By Deﬁnition 13.1, there are moves m′
i, mj ∈M

Towards a Sound and Complete Dialogue System for Handling Enthymemes
453
such that mi ∼S m′
i, (mj, m′
i) ∈T and IntArg(mj) = A. It follows
from (1) that LDF(mj) = LAF(IntArg(mj)) ̸= out. While by Lemma 1
we have that IntArg(m′
i) = IntArg(mi), and so again from (1), LDF(m′
i) =
LAF(IntArg(m′
i)) ̸= in. Then, by Deﬁnition 8, we have three cases:
– If mi = m′
i then we are done since (mj, m′
i) ∈T and LDF(mj) ̸= out.
– If (m′
i, mi) ∈S then, by Deﬁnition 8, there is some m ∈M such that
(m′
i, m), (m, mi) ∈R. Since LDF(m′
i) ̸= in, by (1), we then have that
LDF(m) ̸= out, so we are done.
– If (mi, m′
i) ∈S then we are done, since LDF(mj) ̸= out and also
(mj, m′
i) ∈T .
Case 2) This case is analogous to Case 1 and is proved similarly.
(ii) Let LDF be a complete labelling on DF. According to Lemma 2, we have
that IntArg(mi) ∈AAT d for every mi ∈M with c(mi) ∈E∗, and so for each
mi ∈M let IntArgs = {IntArg(mi) | mi ∈M}, and deﬁne a function LAF
on AF by taking
LAF(Ai) = LDF(mi)
(3)
for all Ai = IntArg(mi) ∈IntArgs—since the dialogue is exhaustive we have
that for every move mi, mj of the dialogue if IntArg(mi) = IntArg(mj) then
LDF(mi) = LDF(mj) and so this function is well-deﬁned. For A ̸∈IntArgs
we have the usual
LAF(A) =
⎧
⎪
⎨
⎪
⎩
in
if ∀B ∈AAT d; (B, A) ∈Dfs implies LAF(B) = out,
out
if ∃B ∈AAT d; (B, A) ∈Dfs and LAF(B) = in,
undec
otherwise.
(4)
We claim that LAF is a complete labelling on AF, so suppose A ∈AAT d:
Case 1) Suppose that LAF(A) = in and suppose to the contrary that
there is some B ∈AAT d such that (B, A) ∈Dfs and LAF(B) ̸= out.
It follows from (4) that A ∈IntArgs so let mi ∈M be a move such
that A = IntArg(mi). By Deﬁnition 13.1, there are some mj, mk ∈M
such that B = IntArg(mj), mi ∼S mk and (mj, mk) ∈T . By Lemma 1,
IntArg(mi) = IntArg(mk) = A. It then follows from (3) that LDF(mk) =
LAF(A) = in and LDF(mj) = LAF(B) ̸= out, contrary to Deﬁnition 9.
Conversely, suppose that LAF(A) ̸= in. If A ̸∈IntArgs then there is some
B ∈AAT d such that (B, A) ∈Dfs and LAF(B) ̸= out, as required. So
suppose that A = IntArg(mi) for some mi ∈M. By (3) we have that
LDF(mi) = LAF(IntArg(mi)) ̸= in. So there are three cases:
– Suppose there is an mj ∈M such that (mj, mi) ∈T and LDF(mj) ̸=
out. Hence, by Lemma 3, there is some B = IntArg(mj) ∈AAT d
such that (B, A) ∈Dfs and LAF(B) = LDF(mj) ̸= out.
– Suppose there is an mj ∈M such that (mj, mi) ∈R and that
LDF(mj) ̸= out. It follows from Deﬁnitions 9 and 13.3 that there
is some mk ∈M such that (mk, mj) ∈R and LDF(mk) ̸= in. It
then follows that there is some m′
j ∈M such that (m′
j, mk) ∈T
and LDF(m′
j) ̸= out. Hence, by Lemma 3, there is some B =

454
A. Xydis et al.
pub
E
¬pub
pf, ¬pi, pr ⇒¬pub
¬pf
¬pi
pr
¬ap
rp →pr
rp
¬ap ⇒¬pi
A
A1
A2
A3
A4
A5
pf
en ⇒pf
en
B
B1
¬en
f →¬en
f
C
C1
pub
se →pub
se
D
D1
(i)
m0
m1
m2
m3
m4
m5
m6
m7
m8
T
T
T
T
S
S
R
R
R
R
IN
IN
IN
IN
IN
OUT
OUT
OUT
OUT
(ii)
E
A1
A2
A
A3
A4
A5
B1
B
C1
C
D1
D
IN
IN
IN
IN
IN
IN
IN
IN
IN
IN
OUT
OUT
OUT
(iii)
Fig. 5. (i). The arguments instantiated by ATd′ enclosed by a dashed line. (ii) The dia-
logue framework DF d′ of d′. (iii) The argument framework AF d′ instantiated by ATd′.
IntArg(m′
j) ∈AAT d such that (B, IntArg(mk)) ∈Dfs and LAF(B) =
LDF(m′
j) ̸= out. However, we have that (mk, mi) ∈S and so it fol-
lows from Lemma 1 that IntArg(mk) = IntArg(mi) = A, as required.
– Suppose there is some mj, mk ∈M such that (mi, mk) ∈S and
(mj, mk) ∈T and LDF(mj) ̸= out. Hence, by Lemma 3, there is
some B = IntArg(mj) ∈AAT d such that (B, IntArg(mk)) ∈Dfs and
LAF(B) = LDF(mj) ̸= out. However, we have that (mi, mk) ∈
S
and so it follows from Lemma 1 that IntArg(mk) = IntArg(mi) = A,
as required.
Case 2) This case is analogous to Case 1 and is proved similarly.
It is easy to understand that for any dialogue d, the label of the ﬁrst move
on DF shows the dialogical status of the topic t of d, since t is the conclusion of
the argument moved by m0. So, if d is exhaustive and its participants are honest
and understanding (by Theorem 1) the acceptability of t in DF corresponds to
the acceptability of t in the AF instantiated by d.
Example 4. Suppose d in Table 1 continues such that d′ = [m0, . . . , m7, m8]
where m7 = ⟨Op, and-so, ∅, 4, ∅⟩and m8 = ⟨Prop, hence, B, 7, ∅⟩(see Fig. 5(i) for
the internal structure of B). Suppose also that there are no other intended argu-
ments that the participants can move in d′ and that defeats have been calculated

Towards a Sound and Complete Dialogue System for Handling Enthymemes
455
according to preferences. In other words, d′ is exhaustive and its participants are
honest and understanding. Figure 5(i) shows the arguments instantiated by ATd′,
whereas Fig. 5(ii) and 5(iii) show the DF d′ and the AF d′, respectively. In both
frameworks the topic pub of d′ is labelled in, since m0 is labelled in in DF d′ and
IntArg(m0) is labelled in in AF d′.
5
Conclusion
This paper introduces a novel dialogue system that handles upwards extendable
enthymemes and instantiates a dialogue framework that is used to determine the
dialogical status of the dialogue moves. As far as we are aware, there are no other
works that handle upwards extendable enthymemes and also propose a mech-
anism for determining the status of the dialogue moves. Most importantly, we
have shown that, for exhaustive dialogues with honest and understanding par-
ticipants, there is a correspondence (under the complete semantics [15]) between
the acceptability of the moves made during a dialogue and the acceptability of
the intended arguments of those moves in the argument framework instantiated
by the contents moved in the dialogue; similar to Prakken’s [13] soundness and
fairness results (which apply to a system that supports backwards extension
of arguments, through a why move, but does not support upwards extendable
enthymemes). This is important since it ensures the dialogue can be played out
such that an enthymeme moved in the dialogue is only justiﬁed in the case that
its intended argument is justiﬁed by the contents of the moves made in the dia-
logue. It is also worth highlighting that our paper is the ﬁrst to formalise a sound
and complete dialogical generalisation of the ASPIC+ framework (soundness and
completeness has not been shown for [4]).
This work is an important step towards deﬁning how a dialogue framework
is constructed for a more general dialogue system for handling enthymemes [14]
that deals with both backward and forward extension of enthymemes—as well
as the full range of misunderstandings that can occur as a result—such that
there is a similar equivalence with the argument framework instantiated from
the contents of the dialogue moves.
Note, the grounded and preferred labellings of an argument framework are the
minimal and maximal complete labellings, respectively, whereas stable labellings
are complete labellings with no arguments labelled as undecided [17]. Therefore,
correspondence between complete labellings on the AF and DF as shown here
can be extended to the grounded, preferred and stable labellings on the AF and
DF, although we lack the space here to do so.
Our protocol allows participants to attack and reply to their own moves,
request a forward extension for their own enthymemes and forward extend their
interlocutor’s enthymemes. This allows for cooperative, inquiry-style, dialogues
where the participants jointly reason to determine the dialogical status of the
topic, where it is natural to assume that the participants are honest. Our system
also allows for more adversarial interactions, where the participants may act
strategically to try to persuade one another; we will explore in future work how

456
A. Xydis et al.
enthymemes might be used to give a strategic advantage to a participant (for
example, an agent may omit some elements of its intended argument to make it
harder for the receiver to identify counter arguments, or to make it harder for
the receiver to identify whether the enthymeme does indeed defeat the argument
it has been moved against).
References
1. Besnard, P., et al.: Introduction to structured argumentation. Argum. Comput. 5,
1–4 (2014)
2. Black, E., Hunter, A.: A relevance-theoretic framework for constructing and decon-
structing enthymemes. J. Log. Comput. 22, 55–78 (2012)
3. Hosseini, S.-A., Modgil, S., Rodrigues, O.: Enthymeme construction in dialogues
using shared knowledge. In: Proceedings of Computational Models of Argument,
pp. 325–332 (2014)
4. Modgil, S.: Towards a general framework for dialogues that accommodate reasoning
about preferences. In: Black, E., Modgil, S., Oren, N. (eds.) TAFA 2017. LNCS
(LNAI), vol. 10757, pp. 175–191. Springer, Cham (2018). https://doi.org/10.1007/
978-3-319-75553-3 13
5. Modgil, S.: Revisiting abstract argumentation. In: Proceedings of Theory and
Applications of Formal Argumentation, pp. 1–15 (2013)
6. Modgil, S.: Dialogical scaﬀolding for human and artiﬁcial agent reasoning. In: Pro-
ceedings of Workshop on AI and Cognition, pp. 58–71 (2017)
7. Fan, X., Toni, F.: A general framework for sound assumption-based argumentation
dialogues. Artif. Intell. 216, 20–54 (2014)
8. Hunter, A.: Real arguments are approximate arguments. In: Proceedings of AAAI
Conference on Artiﬁcial Intelligence, pp. 66–71 (2007)
9. Walton, D., Reed, C.: Argumentation schemes and enthymemes. Synthese 145(3),
339–370 (2005)
10. Black, E., Hunter, A.: A generative inquiry dialogue system. In: Proceedings of
Autonomous Agents and Multiagent Systems, pp. 1–8 (2007)
11. Hosseini, S-A.: Dialogues Incorporating Enthymemes and Modelling of Other
Agents’ Beliefs. PhD Thesis, King’s College London (2017)
12. Dupin de Saint-Cyr, F.: Handling enthymemes in time-limited persuasion dialogs.
In: Proceedings of International Conference on Scalable Uncertainty Management,
pp. 149–162 (2011)
13. Prakken, H.: Coherence and ﬂexibility in dialogue games for argumentation. J.
Log. Comput. 15, 1009–1040 (2005)
14. Xydis, A., Hampson, C., Modgil, S., Black, E.: Enthymemes in dialogues. In: Pro-
ceedings of Computational Models of Argument, pp. 395–402 (2020)
15. Dung, P.-M.: On the acceptability of arguments and its fundamental role in non-
monotonic reasoning, logic programming and n-person games. Artif. Intell. 77(2),
321–357 (1995)
16. Modgil, S., Prakken, H.: Abstract rule-based argumentation. Handbook of Formal
Argumentation, pp. 286–361 (2018)
17. Caminada, M.: On the issue of reinstatement in argumentation. In: Fisher, M., van
der Hoek, W., Konev, B., Lisitsa, A. (eds.) JELIA 2006. LNCS (LNAI), vol. 4160,
pp. 111–123. Springer, Heidelberg (2006). https://doi.org/10.1007/11853886 11
18. Walton, D.: Informal Logic: A Handbook for Critical Argumentation. Cambridge
University Press, Cambridge (1989)

Short Papers and Extended Abstracts

A Henkin-Style Completeness Proof
for the Modal Logic S5
Bruno Bentzen(B)
Carnegie Mellon University, Pittsburgh, PA, USA
Abstract. This paper presents a recent formalization of a Henkin-style
completeness proof for the propositional modal logic S5 using the Lean
theorem prover. The proof formalized is close to that of Hughes and
Cresswell [8], but the system, based on a diﬀerent choice of axioms, is
better described as a Mendelson system augmented with axiom schemes
for K, T, S4, and B, and the necessitation rule as a rule of inference.
The language has the false and implication as the only primitive logical
connectives and necessity as the only primitive modal operator. The full
source code is available online and has been typechecked with Lean 3.4.2.
Keywords: Modal logic · Completeness · Formal methods · Lean
1
Introduction
A proof of the completeness theorem for a given logic conforms to the Henkin
style when it applies nonconstructive methods to build models out of maximal
consistent sets of formulas (possibly after a Henkin language extension) using the
deductive system itself. Henkin-style completeness proofs for modal logics have
been around for over ﬁve decades [9] but the formal veriﬁcation of completeness
with respect to Kripke semantics is comparatively recent.
We present a formalization of a Henkin-style completeness proof for the
propositional modal logic S5 using the Lean theorem prover. Although the proof
is speciﬁc to S5, the same techniques can be applied to weaker normal modal
systems such as K, T, S4, and B, by forgetting the appropriate extra accessi-
bility conditions (as described in [8]). The formalization covers the syntax and
semantics of S5, the deduction theorem, structural rules (weakening, contrac-
tion, exchange), the recursive enumerability of the language, and the soundness
and completeness theorems. It has approximately 1,500 lines of code (but only
two thirds of the development is required for the completeness proof). The full
source code is available online. It has been typechecked with Lean 3.4.2.
The author thanks Jeremy Avigad, Mario Carneiro, Rajeev Gor´e, and Minchao Wu for
helpful suggestions. An early version of this work was presented at the Lean Together
2019, Amsterdam, January 7–11, 2019. The source code described in this paper is
publicly available online at: https://github.com/bbentzen/mpl/. An extended version
is available at https://arxiv.org/abs/1910.01697.
c
⃝Springer Nature Switzerland AG 2021
P. Baroni et al. (Eds.): CLAR 2021, LNAI 13040, pp. 459–467, 2021.
https://doi.org/10.1007/978-3-030-89391-0_25

460
B. Bentzen
1.1
Related Work
The use of proof assistants in the mechanization of completeness proofs in the
context of Kripke semantics has been recently studied in the literature for a vari-
ety of formal systems. Coquand [2] uses ALF to give a constructive formal proof
of soundness and completeness w.r.t. Kripke models for intuitionistic proposi-
tional logic with implication as the sole logical constant. Building on Coquand’s
work, a constructive completeness proof w.r.t Kripke semantics for intuitionistic
logic with implication and universal quantiﬁcation has been veriﬁed with Coq
by Heberlin and Lee [7]. Also using Coq, Doczal and Smolka present a con-
structive formal proof of completeness w.r.t. Kripke semantics and decidability
of the forcing relation for an extension of modal logic K [4] and a variety of
temporal logic [5]. In his formal veriﬁcation of cut elimination for coalgebraic
logics, Tews [13] provides a formalization of soundness and completeness proofs
covering many diﬀerent logics, including modal logic K.
To the best of our knowledge, our formalization of a Henkin-style complete-
ness proof for propositional modal logic S5 is the ﬁrst of its kind.1 Our proof
is close to that of Hughes and Cresswell [8], but given for a system based on a
diﬀerent choice of axioms. In Hughes and Cresswell’s book, the basis of S5 is
that of T plus an additional axiom. Here S5 is built on axiom schemes for K,
T, S4 and B. This has the advantage that we can easily adapt the proof for dif-
ferent weaker systems. Another choice had to be made between using a deep or
a shallow embedding for the formalization. Because our aim is metatheoretical,
we use a deep embedding for the encoding of the syntax, as it allows us to prove
metatheorems by structural induction on formulas or derivations.
1.2
Lean
Lean is an interactive theorem prover developed principally by Leonardo de
Moura based on a version of dependent type theory known as the Calculus of
Inductive Constructions [3,11]. Theorem proving in Lean can be done by con-
structing proof terms directly, as in Agda [10], by using tactics, imperative com-
mands that describe how to construct a proof term, as in Coq [12], or by mixing
them together in the same environment. Lean also supports classical reasoning,
which is employed in the formalization along with the declaration of noncom-
putable constructions. The formalization also presupposes a few basic results on
data structures which are not in the standard library, so, our development makes
use of mathlib, the library of formalized mathematics for Lean [1].
In the remainder of this paper, Lean code will be used to illustrate design
choices and give an overview of the proof method, not to discuss the proof itself.
Interested readers are encouraged to consult completeness.lean, the main ﬁle
1 In independent work done roughly at the same time the author ﬁrst completed this
formalization in 2018, Wu and Gor´e [14] have described a formalization in Lean of
modal tableaux for modal logics K, KT, and S4 with decision procedures with proofs
of soundness and completeness. Also in 2018, but unknown to the author, From [6]
formalized a Henkin-style completeness proof for system K in Isabelle.

A Henkin-Style Completeness Proof for the Modal Logic S5
461
of the formalization where the crucial proof steps are given in detail. We shall also
give an informal proof sketch of the completeness theorem using mathematical
notation to convey the key ideas of the proof.
2
Modal Logic
2.1
The Language
For simplicity, we shall work with a language which has implication (⊃) and
the false (⊥) as the only primitive logical connectives, and necessity (□) as the
only primitive modal operator. This language can be conveniently deﬁned using
inductive types in Lean:
inductive
form {σ :nat} : Type
|
atom : fin σ →form
|
bot
: form
|
impl : form →form →form
|
box
: form →form
Using one of the four constructors displayed above (atom, bot, impl, box) is the
only way to construct a term of type form. The elimination rule of this type is
precisely the principle of induction on the structure of a formula.
While newly-deﬁned terms are always exhibited in Polish notation by default,
Lean supports unicode characters and has an extensible parser which allows the
declaration of customized preﬁx or inﬁx notations for terms and types.
prefix
‘#’
:=
form.atom
notation ‘⊥’
:=
form.bot _
infix
‘⊃’
:=
form.impl
notation ‘∼’:40 p := form.impl p (form.bot _)
prefix
‘□’:80
:=
form.box
prefix
‘♦’:80
:=
λ p, ∼(□(∼p))
Contexts are just sets of formulas. In Lean, sets are functions of type A →Prop:
def ctx : Type :=
set (form σ)
notation ‘·’ := {}
notation Γ ‘`’ p := set.insert p Γ
2.2
The Proof System
We deﬁne a Mendelson system augmented with axiom schemes for K, T, S4,
and B, and the necessitation rule as a rule of inference. The proof system is
implemented with a type of proofs, which is inductively deﬁned as follows:
inductive
prf : ctx σ →form σ →Prop
|
ax {Γ} {p} (h :p∈Γ): prf Γ p
|
pl1 {Γ} {p q}
: prf Γ (p ⊃(q ⊃p))
|
pl2 {Γ} {p q r}
: prf Γ ((p ⊃(q ⊃r)) ⊃((p ⊃q) ⊃(
p ⊃r)))

462
B. Bentzen
|
pl3 {Γ} {p q}
: prf Γ (((∼p) ⊃∼q) ⊃(((∼p) ⊃q) ⊃
p)
|
k {Γ} {p q}
: prf Γ (□(p ⊃q) ⊃(□p ⊃□q))
|
t
{Γ} {p}
: prf Γ (□p ⊃p)
|
s4 {Γ} {p}
: prf Γ (□p ⊃□□p)
|
b {Γ} {p}
: prf Γ (p ⊃□♦p)
|
mp {Γ} {p q} (hpq: prf Γ (p ⊃q)) (hp :prf Γ p) :prf Γ q
|
nec {Γ} {p} (h :prf · p) : prf Γ (□p)
notation Γ ‘ ⊢s5 ’ p := prf Γ p
notation Γ ‘ ⊬s5 ’ p := prf Γ p →false
2.3
Semantics
Kripke Models. The semantics for S5 are given by Kripke semantics. A model
M is a triple ⟨W, R, v⟩where
– W is a non-empty set of objects called possible worlds;
– R is a binary, equivalence relation on possible worlds;
– v speciﬁes the truth value of a formula at a world.
It is useful to let the members of W (possible worlds) be sets of formulas:
def wrld (σ :nat) :=
set (form σ)
Kripke models can be implemented as structures (inductive types with only one
constructor). This can be done using the structure command in Lean. We deﬁne
a 6-tuple composed of a domain, an accessibility relation, a valuation function,
and reﬂexivity, symmetry and transitivity proofs for the given relation:
structure
model :=
(wrlds : set (wrld σ))
(access : wrld σ →wrld σ →bool)
(val : fin σ →wrld σ →bool)
(refl : ∀w ∈wrlds , access w w = tt)
(symm : ∀w ∈wrlds , ∀v ∈wrlds , access w v = tt →access v
w = tt)
(trans : ∀w ∈wrlds , ∀v ∈wrlds , ∀u ∈wrlds ,
access w v
=
tt →access v u = tt →access w u = tt)
The Boolean type bool is used for truth values (i.e. either tt or ff).
Semantic Consequence. We have a forcing function which takes a model, a
formula, and a world as inputs and returns a boolean value. Non-modal connec-
tives are given truth-functionally and a formula □p is true at a world w iﬀif
R(w, v) then p is true at v, for all v ∈W:
def
forces_form (M : model) : form σ →wrld σ →bool
|
(#p)
:=
λ w, M.val p w
|
(bot σ) :=
λ w, ff

A Henkin-Style Completeness Proof for the Modal Logic S5
463
|
(p ⊃q) := λ w, (bnot ( forces_form p w))
| | ( forces_form q w)
|
(□p)
:=
λ w, if (∀v ∈M.wrlds , w ∈M.wrlds →
M.access w v =
tt →forces_form p v = tt) then tt else ff
This function can be extended to contexts in the obvious way:
def
forces_ctx (M : model) (Γ :ctx σ) :wrld σ →bool :=
λ w, if (∀p, p ∈Γ →forces_form M p w = tt) then tt else ff
A formula p is a semantic consequence of a context Γ iﬀ, for all M and
w ∈W, Γ being true at w in M implies p being true at w in M.
inductive
sem_csq (Γ :ctx σ) (p :form σ) :Prop
|
is_true (m : ∀(M : model) (w : wrld σ),
forces_ctx M Γ w = tt →forces_form M p w = tt) : sem_csq
notation Γ ‘⊨s5’ p := sem_csq Γ p
3
The Completeness Theorem
In this section we formalize a proof of completeness with respect to the proof
system and semantics developed in the previous sections.
Theorem 1 (Completeness). For every context Γ, any formula p that follows
semantically from Γ is also derivable from Γ in the modal logic S5. In symbols:
Γ ⊨S5 p =⇒Γ ⊢S5 p
That is, every semantic consequence is also a syntactic consequence in S5.
The proof requires a non-constructive use of contraposition. We assume that
both Γ ⊨S5 p and Γ ⊬S5 p hold, and then derive a contradiction using the syntax
to build a model M = ⟨W, R, v⟩(the canonical model) where Γ is true but p is
false at a speciﬁc world in the domain.
We shall focus on sketching the formal argument for the following facts:
1. Γ ∪{∼p} has a maximal consistent extension Δ = 
n∈N Δn, for
Δ0 :=Γ ∪{∼p}
Δn+1 :=

Δn ∪{ϕn+1}
if Δn ∪{ϕn+1} is consistent
Δn ∪{∼ϕn+1}
otherwise
2. There exists a canonical model where p is true at w iﬀp ∈w;

464
B. Bentzen
Maximal Consistent Sets. We say that a context is maximal consistent if it
is consistent and, moreover, for every formula expressible in the language, either
it or its negation is contained in that context.
def
is_max (Γ :ctx σ) := is_consist Γ ∧(∀p, p ∈Γ ∨(∼p) ∈Γ)
Our language is countable, so we can construct each Δn+1 using natural num-
bers to run through the set of all formulas, deciding whether or not a number’s
corresponding formula (when it exists) is consistent with Δn or not. The enumer-
ability of the language is expressed using encodable types, which are construc-
tively countable types in Lean. Essentially, a type α is encodable when it has an
injection encode :α →nat and a (partial) inverse decode :nat →option α .
def
insert_form (Γ :ctx σ) (p :form σ) :ctx σ :=
if is_consist (Γ ` p) then
` p else
` ∼p
def
insert_code (Γ :ctx σ) (n :nat) : ctx σ :=
match
encodable.decode (form σ) n with
|
none
:=
Γ
|
some p :=
insert_form p
end
def maxn (Γ :ctx σ) :nat →ctx σ
|
0
:=
Γ
|
(n+1) :=
insert_code (maxn n) n
def max (Γ :ctx σ) :ctx σ :=  n, maxn Γ n
Before proceeding any further, we must show that Γ in contained in max Γ and
that max Γ is maximal and consistent. For each maxn Γ n of the family of sets,
we have Γ ⊆maxn Γ n. So Γ must also be contained in their union, max Γ. This
proof argument produces a term of type:
lemma
subset_max_self {Γ :ctx σ} :Γ ⊆max Γ
Now, every formula must be in the enumeration somewhere, so suppose that the
formula p has index i. By the deﬁnition of maxn Γ i, either p or ∼p is a member
of maxn Γ i, so one of them is a member of max Γ. Thus, we have a term
theorem
mem_or_mem_max {Γ :ctx σ} (p :form σ) :p ∈max Γ ∨(∼p)
∈max Γ
Assume for the sake of contradiction that Γ is consistent but max Γ is not. By
structural induction on the proof tree, we prove that there exists an i such that
maxn Γ i is inconsistent. However, each maxn Γ i preserves consistency. This
gives a function
lemma
is_consist_max {Γ :ctx σ} :is_consist Γ →is_consist (
max Γ)
The above proof sketches are implemented purely by unfolding deﬁnitions
and inductive reasoning. They consist of approximately 150 lines of code in
completeness.lean. There is even a one-line short case-reasoning proof that
maximal consistent sets are closed under derivability:

A Henkin-Style Completeness Proof for the Modal Logic S5
465
lemma
mem_max_of_prf {Γ :ctx σ} {p :form σ} (h1 :is_max Γ)
(h2 : Γ ⊢S5 p) :p ∈Γ :=
(h1.2 p).resolve_right (λ hn , h1.1 (prf.mp (prf.ax hn) h2))
The Canonical Model Construction. We build the model as follows:
– W is the set of all maximal consistent sets of formulas;
– R(w, v) iﬀ□p ∈w implies p ∈v;
– v(w, p) = 1 if w ∈W and p ∈w, for a propositional letter p.
We have to show that R is an equivalence relation. Reﬂexivity translates as
follows: □p ∈w implies p ∈w for a given world w ∈W. But this is easy because
w is closed under derivability (it is a maximal consistent set of formulas) and
our proof system has modus ponens and axiom schema (t).
Proving symmetry requires more work. Given any worlds w, v ∈W, sup-
pose ﬁrst that □ϕ ∈w implies ϕ ∈v for all formulas ϕ, and suppose that
□p ∈v. We want to show that p ∈w. Since ♦□p ⊃p is a theorem of S5 (see
syntax/lemmas.lean) we just have to prove that ♦□p ∈w, or, equivalently,
that □∼□p /∈w. By contraposition on our initial hypothesis, it suﬃces to show
that ∼□p /∈v. But □p ∈v and v is consistent.
For transitivity, we must show that p ∈u, on the assumptions that □p ∈w,
that □ϕ ∈w implies ϕ ∈v, and that □ϕ ∈v implies ϕ ∈u, for any formula ϕ.
In other words, we want to show that □□p ∈w. But this follows from modus
ponens and axiom scheme (s4).
This model construction is represented by the Lean code
def
domain (σ :nat) : set (wrld σ) := {w
|
ctx.is_max w}
def unbox (w : wrld σ) :wrld σ := {p
|
(□p) ∈w}
def access : wrld σ →wrld σ →bool :=
λ w v, if (unbox w ⊆v) then tt else ff
def val : fin σ →wrld σ →bool :=
λ p w, if w ∈domain σ ∧(#p) ∈w then tt else ff
lemma
mem_unbox_iff_mem_box {p : form σ} {w :wrld σ} :
p ∈unbox w ↔(□p) ∈w := ⟨id , id ⟩
What is here called unbox is a set operation which takes a set of formulas w as
an input and returns the set of formulas p such that □p is a member of w.
A useful lemma about this operation is that if p is deducible from unbox w
then actually □p ∈w. It can be proved by structural induction on the derivation
using the necessitation rule, giving us a term:
lemma
mem_box_of_unbox_prf {p : form σ} {w :wrld σ}
(H : w ∈domain σ) :(unbox w ⊢s5 p) →(□p) ∈w

466
B. Bentzen
Truth and Membership. To prove completeness, we ﬁrst show that a formula
is true at a world in the canonical model iﬀit is a member of that world:
lemma
form_tt_iff_mem_wrld {p : form σ} :
∀(w ∈domain σ), (forces_form
model w p) = tt ↔p ∈w
Here model is the canonical model deﬁned in the previous section. To prove this,
we use induction on the structure of the formula p.
In the proof mechanization, we use the induction tactic in the tactic mode.
This tactic produces four goals, of which the fourth is the most relevant one. To
prove it, we begin by assuming the inductive hypothesis for p. If w is a world,
and, if it is a maximal consistent set of formulas, then, by unfolding the deﬁnition
of truth of a formula at a world in a model, the biconditional statement becomes
⊢(∀(v :wrld σ),
v ∈model.wrlds →w ∈model.wrlds →model.access w v = tt →
forces_form
model w p = tt) ↔(□p) ∈w)
In the forwards direction, we assume that □p is true at w in the canonical
model and that ∼□p ∈w. But then, by lemma mem box of unbox prf, the
context unbox w∪{∼p} is consistent and can be extended to a maximal consistent
set (i.e. a world in the domain). It is accessible to w because unbox w ⊆max
(unbox w ∪{∼p}), so p should be true at w. But p /∈max (unbox w ∪{∼p})
because it is consistent.
For the backwards direction, assume that □p ∈w. Given a maximal consis-
tent set of formulas v and assuming that □ϕ ∈w then ϕ ∈v for all ϕ, we have
to show that p is true at v in the model. By the inductive hypothesis, however,
it suﬃces to show that p ∈v, but this follows from □p ∈w.
The Completeness Proof. We now complete our proof by putting together all
the above pieces into 24 lines of code. Since we know by hypothesis that Γ ⊬S5 p,
it follows that Γ ∪{∼p} is consistent–otherwise, if the false were deducible from
it, we would have a contradiction by double negation elimination.
lemma
consist_not_of_not_prf {Γ :form σ} {p :form σ} :
(Γ ⊬s5 p) →is_consist (Γ ` ∼p) := λ hnp hc , hnp (mp dne (
deduction hc))
Now assuming that Γ ⊨S5 p, the basic idea for deriving the contradiction is that,
as max Γ ∪{∼p} is a world in the canonical model, and each formula ϕ ∈Γ is
true at that world, Γ is true as well. Clearly, p is not consistent with Γ ∪{∼p},
so p /∈max Γ ∪{∼p}, meaning that p must be false at that world.
This allows us to prove the desired theorem
theorem
completenss {Γ :form σ} {p :form σ} :(Γ ⊨s5 p) →Γ ⊢s5
Acknowledgments. Work supported in part by the AFOSR grant FA9550-18-1-0120.
Any opinions, ﬁndings and conclusions or recommendations expressed in this material
are those of the author(s) and do not necessarily reﬂect the views of the AFOSR.

A Henkin-Style Completeness Proof for the Modal Logic S5
467
References
1. Carneiro, M.: The lean 3 mathematical library (mathlib) (2018). https://
robertylewis.com/ﬁles/icms/Carneiro mathlib.pdf.
International
Congress
on
Mathematical Software
2. Coquand, C.: A formalised proof of the soundness and completeness of a simply
typed lambda-calculus with explicit substitutions. Higher-Order Symb. Comput.
15(1), 57–90 (2002)
3. Coquand, T., Huet, G.: The calculus of constructions. Inf. Comput. 76(2–3), 95–
120 (1988)
4. Doczkal, C., Smolka, G.: Constructive completeness for modal logic with transitive
closure. In: Hawblitzel, C., Miller, D. (eds.) CPP 2012. LNCS, vol. 7679, pp. 224–
239. Springer, Heidelberg (2012). https://doi.org/10.1007/978-3-642-35308-6 18
5. Doczkal, C., Smolka, G.: Completeness and decidability results for CTL in coq. In:
Klein, G., Gamboa, R. (eds.) ITP 2014. LNCS, vol. 8558, pp. 226–241. Springer,
Cham (2014). https://doi.org/10.1007/978-3-319-08970-6 15
6. From, A.H.: Epistemic logic. Archive of Formal Proofs, October 2018. https://
devel.isa-afp.org/entries/Epistemic Logic.html. Formal proof development
7. Herbelin, H., Lee, G.: Forcing-based cut-elimination for Gentzen-style intuitionistic
sequent calculus. In: Ono, H., Kanazawa, M., de Queiroz, R. (eds.) WoLLIC 2009.
LNCS (LNAI), vol. 5514, pp. 209–217. Springer, Heidelberg (2009). https://doi.
org/10.1007/978-3-642-02261-6 17
8. Hughes, G.E., Cresswell, M.J.: A New Introduction to Modal Logic. Psychology
Press (1996)
9. Negri, S.: Kripke completeness revisited. In: Acts of Knowledge: History, Philoso-
phy and Logic: Essays Dedicated to G¨oran Sundholm, pp. 247–282 (2009)
10. Norell, U.: Dependently typed programming in Agda. In: Koopman, P., Plasmei-
jer, R., Swierstra, D. (eds.) AFP 2008. LNCS, vol. 5832, pp. 230–266. Springer,
Heidelberg (2009). https://doi.org/10.1007/978-3-642-04652-0 5
11. Pfenning, F., Paulin-Mohring, C.: Inductively deﬁned types in the calculus of con-
structions. In: Main, M., Melton, A., Mislove, M., Schmidt, D. (eds.) MFPS 1989.
LNCS, vol. 442, pp. 209–228. Springer, New York (1990). https://doi.org/10.1007/
BFb0040259
12. The Coq project: The coq proof assistant. http://www.coq.inria.fr (2017)
13. Tews, H.: Formalizing cut elimination of coalgebraic logics in Coq. In: Galmiche,
D., Larchey-Wendling, D. (eds.) TABLEAUX 2013. LNCS (LNAI), vol. 8123, pp.
257–272. Springer, Heidelberg (2013). https://doi.org/10.1007/978-3-642-40537-
2 22
14. Wu, M., Gor´e, R.: Veriﬁed decision procedures for modal logics. In: Harrison,
J., O’Leary, J., Tolmach, A. (eds.) 10th International Conference on Interac-
tive Theorem Proving (ITP 2019). Leibniz International Proceedings in Infor-
matics (LIPIcs), vol. 141, pp. 31:1–31:19. Schloss Dagstuhl-Leibniz-Zentrum fuer
Informatik, Dagstuhl (2019). https://doi.org/10.4230/LIPIcs.ITP.2019.31. http://
drops.dagstuhl.de/opus/volltexte/2019/11086

Base Argumentation as an Abstraction
of Deductive Argumentation
Jinsheng Chen1(B), Beishui Liao1, and Leendert van der Torre2
1 Department of Philosophy, Zhejiang University, Hangzhou, China
2 Department of Computer Science, University of Luxembourg,
Esch-sur-Alzette, Luxembourg
Abstract. Base argumentation is a logic-based instantiation of abstract
argumentation. Each base argument is a subset of the given knowledge
base. In this paper, we show that base argumentation satisﬁes some ratio-
nality postulates, and that base argumentation is equivalent to deduc-
tive argumentation under complete semantics. Due to its simplicity, base
argumentation can be seen as an abstraction of deductive argumentation.
Keywords: Abstract argumentation · Deductive argumentation ·
Assumption-based argumentation
1
Introduction
Dung’s abstract argumentation (AA) [9] is a formalism that provides many
important insights into the nature of argumentation. A situation involving argu-
mentation is represented by a directed graph, with each node representing an
argument and each arc denoting an attack by one argument on another. Some
general criteria are given to determining which arguments are acceptable. Even
though the unspeciﬁed notions of argument and attack can be seen as a great
advantage of the framework, they do not capture every interesting aspect of
argumentation.
Structured argumentation provides more detailed formalisations of arguments
than is available with abstract argumentation. These formalisations include
assumption-based argumentation (ABA), a surplus-production model incorpo-
rating covariates (ASPIC+), Defeasible Logic Programming (DeLP), deduc-
tive argumentation and so on. The relationship between these formalisms has
attracted the attention of researchers.
A formalism F1 is claimed to be an instance of formalism F2 if there exists a
correspondence between F1-frameworks and F2-frameworks and correspondence
between their extensions. Formally, let F1, F2 be argumentation formalisms, σ1
a semantics in F1, and σ2 a semantics in F2. We say that F1 is an instance
of F2 under (σ1, σ2)-semantics if for each F1-framework F1, we can form a F2-
framework (F1)• and for each σ1-extension of F1, we can form a σ2-extension of
c
⃝Springer Nature Switzerland AG 2021
P. Baroni et al. (Eds.): CLAR 2021, LNAI 13040, pp. 468–476, 2021.
https://doi.org/10.1007/978-3-030-89391-0_26

Base Argumentation as an Abstraction of Deductive Argumentation
469
(F1)•. When σ1 and σ2 are the same, we simply say that F1 is an instance of F2
under σ1-semantics. If F1 and F2 are instances of each other under σ-semantics,
we say that F1 and F2 are equivalent under σ-semantics.
For ABA and AA, Dung, Mancarella and Toni [8] show that ﬂat ABA is
an instance of AA under admissible, grounded and ideal extensions. Toni [14]
proves this result for stable semantics, and Caminada et al. [6] for complete
and preferred extensions. A negative result is shown in [6] that ﬂat ABA is not
an instance of AA under semi-stable and eager semantics. Conversely, Toni [14]
shows that AA is an instance of ﬂat ABA under admissible extensions, and
claims that the proof for other semantics is similar. Therefore, ﬂat ABA and AA
are equivalent under admissible, grounded, ideal, stable, complete and preferred
semantics, but are not equivalent under semi-stable and eager semantics. For
a general overview of the correspondence between AA and ABA, we refer the
reader to [7].
For ABA and ASPIC+, Modgil and Prakken [12] claim that ABA is a special
case of ASPIC+. However, Caminada et al. [6] provide counter-examples to this
claim in the context of semi-stable and eager semantics.
In this paper, we investigate the relationship between deductive argumen-
tation and a new formalism called base argumentation. We show that base
argumentation is equivalent to deductive argumentation under complete seman-
tics. As will be illustrated below, base argumentation is simpler than deductive
argumentation. Therefore, base argumentation can be seen as an abstraction of
deductive argumentation.
Deductive argumentation [2,4] is an instantiation of abstract argumentation,
and provides a more detailed formalisation of arguments and attacks. In deduc-
tive argumentation, a formal language and a base logic for representing knowl-
edge and constructing arguments and counter-arguments is assumed. Formally,
deductive arguments are premises-conclusion pairs such that the premises are,
according to the base logic, consistent and subset-minimal sets logically imply-
ing their conclusions. Various options for specifying when one argument attacks
another are deﬁned based on the base logic and the notion of inconsistency.
In base argumentation, arguments are deﬁned to be consistent subsets of
the knowledge base. We call such arguments base arguments. The base logic is
Tarski’s abstract logic [13]. Argument Γ attacks argument Δ if Γ can logically
deduce the negation of a formula in Δ.
In this paper, we: (1) show that base argumentation satisﬁes two rationality
postulates adapted from [5] (Proposition 15); and (2) prove a correspondence
between the attack relation of base argumentation frameworks and the attack
relation of deductive argumentation frameworks (Proposition 16) with a bijective
map between the sets of complete extensions of these frameworks (Proposition
18). With these results, base argumentation is equivalent to deductive argumen-
tation under complete semantics.
Base argumentation is valued for its simplicity compared to deductive argu-
mentation. Amgoud et al. [3] show that for a deductive argumentation system
with a propositional logic base and a ﬁnite knowledge base, an inﬁnite set of

470
J. Chen et al.
arguments and an inﬁnite set of attacks among them can be generated. By con-
trast, since a ﬁnite knowledge base has a ﬁnite number of consistent subsets,
the number of arguments in base argumentation is ﬁnite. Since base argumen-
tation is equivalent to deductive argumentation under complete semantics, base
argumentation can be seen as an abstraction of deductive argumentation.
The remainder of this paper is structured as follows. Section 2 presents some
basic notions and concepts. Section 3 provides the formal deﬁnition of base argu-
mentation frameworks and shows that they satisfy two rationality postulates.
Section 4 shows a correspondence between the attack relation of base argumenta-
tion frameworks and the attack relation of deductive argumentation frameworks
with a bijective map between the set of complete extensions of these frameworks.
Section 5 concludes the paper and discusses some future work.
2
Preliminaries
2.1
Abstract Argumentation Framework
Central to the theory of abstract argumentation is the notion of an abstract
argumentation framework, which is essentially a directed graph in which the
arguments are represented by nodes and the attack relation is represented by
arrows.
Deﬁnition 1. An abstract argumentation framework T is a pair (A, R) where
A is a set and R ⊆A × A. Each element A ∈A is called an argument and
(A, B) ∈R means that A attacks B.
Let T = (A, R) be an argumentation framework. A set of arguments S ⊆A
attacks argument A ∈A if there is an argument A′ ∈S such that A′ attacks A.
S defends A if for each argument B ∈A, if B attacks A, then S attacks B.
Various proposals have been proposed in the literature for argumentation
semantics to decide which arguments in an abstract argumentation framework
are acceptable. In this paper, we consider the following semantics:
Deﬁnition 2. Let T = (A, R) be an argumentation framework and S ⊆A.
1. S is a conﬂict-free extension iﬀthere is no argument A ∈S such that S
attacks A.
2. S is an admissible extension iﬀS is conﬂict-free and S defends each of its
elements.
3. S is a complete extension iﬀS is admissible and contains each argument it
defends.
Argument ϕ is sceptically or credulously justiﬁed under complete semantics
in T if ϕ belongs to all or at least one complete extension.

Base Argumentation as an Abstraction of Deductive Argumentation
471
2.2
Tarski’s Abstract Logic
Logic-based instantiations of abstract argumentation frameworks rely on an
underlying logic for generating logical arguments and for deﬁning the attack
relation, using inference of conﬂict or existence of inconsistency. In this paper,
the base logic under consideration is Tarski’s abstract logic, which is deﬁned with
the notion of an abstract consequence relation.
Deﬁnition 3. Let L be a denumerable logical language containing a unary con-
nective ¬ for negation. A relation ⊢⊆P(L) × L is an abstract consequence
relation if it satisﬁes the following conditions: for any Γ, Δ ⊆L and ϕ, ψ ∈L:
1. if ϕ ∈Γ, then Γ ⊢ϕ.
2. if Γ ⊢ϕ and Γ ⊆Δ, then Δ ⊢ϕ.
3. if Γ ⊢ϕ and for every ψ ∈Γ, Δ ⊢ψ, then Δ ⊢ϕ.
An abstract logic is a pair (L, ⊢) where ⊢is an abstract consequence relation.
Note that almost all well-known monotonic logics (classical logics, intuition-
istic logics, modal logics, etc.) are special cases of Tarski’s abstract logic.
The notion of inconsistency is important for deﬁning the attack relation.
Deﬁnition 4. Let (L, ⊢) be an abstract logic. A set of formulas Γ is inconsis-
tent if there exists a formula ϕ such that Γ ⊢ϕ and Γ ⊢¬ϕ. It is consistent
otherwise.
We make the following assumption on negation in this paper1, which holds
in most logics with negation2:
– If Γ ∪{ϕ} is inconsistent, then Γ ⊢¬ϕ.
Note that the above assumption is implied by the contraposition of the under-
lying logic.
2.3
Deductive Argumentation Framework
Having deﬁned the base logic and the notion of inconsistency, we are ready to
present the notion of deductive argumentation frameworks. The presentation is
adapted from [2]. We start with the notion of a knowledge base.
1 In the literature, the following condition of contraposition is considered:
If Γ ∪{ϕ} ⊢ψ, then Γ ∪{¬ψ} ⊢¬ϕ.
If an abstract logic contains falsehood ⊥, contrapostion implies the above assump-
tion: Since Γ ∪{ϕ} is inconsistent, Γ ∪{ϕ} ⊢⊥. By contraposition, Γ ∪{¬⊥} ⊢¬ϕ.
Since ¬⊥is equivalent to a tautology, Γ ⊢¬ϕ.
2 For propositional logic, the proof is as follows: Since Γ ∪{ϕ} is inconsistent, Γ ∪{ϕ} ⊢
⊥. By Deduction Theorem, Γ ⊢ϕ →⊥. Since (ϕ →⊥) ↔¬ϕ is a tautology, Γ ⊢¬ϕ.

472
J. Chen et al.
Deﬁnition 5. Let (L, ⊢) be an abstract logic. A knowledge base Σ is a subset of
L such that Σ is free of tautologies: for all ϕ ∈Σ, it is not the case that ∅⊢ϕ.
Deductive arguments are premises-conclusion pairs such that the premises
are, according to the base logic, consistent and subset-minimal sets logically
implying their conclusion.
Deﬁnition 6. Let (L, ⊢) be an abstract logic and Σ a knowledge base. A deduc-
tive argument is a pair (Γ, ϕ) such that (1) Γ ⊆Σ and Γ is consistent, (2)
Γ ⊢ϕ and (3) there is no Γ ′ ⊂Γ such that Γ ′ ⊢ϕ. We use α, β etc. to denote
deductive arguments. (Γ, ϕ) is a sub-argument of (Δ, ψ) if Γ ⊆Δ.
Assumption 7. This paper makes the following assumption about the exis-
tence of deductive arguments:
– For any consistent set Γ ⊆Σ, there exists ϕ such that (Γ, ϕ) is a deductive
argument.
This assumption is natural since if we have the conjunction ∧in our language
and Γ is ﬁnite, the desired ϕ is {ψ | ψ ∈Γ}. Note that we assume Σ to be
free of tautologies. Therefore, it is not the case that ⊢{ψ | ψ ∈Γ}.
Now we deﬁne the attack relation on deductive arguments.
Deﬁnition 8. Let (L, ⊢) be an abstract logic and Σ a knowledge base. Let (Γ, ϕ)
and (Δ, ψ) be deductive arguments. Then (Γ, ϕ) attacks (Δ, ψ) iﬀthere exists a
formula φ ∈Δ such that {ϕ, φ} is inconsistent.
The attack relation deﬁned above is called an assumption attack in [10]. It
follows directly that (Γ, ϕ) attacks (Δ, ψ) iﬀΓ ⊢¬φ for some φ ∈Δ.
Deﬁnition 9. Let (L, ⊢) be an abstract logic and Σ a knowledge base. A deduc-
tive argumentation framework Td is a pair (Ard(Σ), Rd) where Ard(Σ) is the
set of deductive arguments based on Σ, and Rd is the attack relation deﬁned in
Deﬁnition 8.
Rationality postulates require that extensions of argumentation frameworks
satisfy certain conditions. Amgoud [1] shows that any deductive argumentation
framework satisﬁes the following proposition:
Proposition 10. Let Td = (Ard(Σ), Rd) be a deductive argumentation frame-
work. Then for any complete extension E of Td,
1. E is closed under sub-arguments, that is, for any deductive arguments (Γ, ϕ)
and (Δ, ψ), if (Γ, ϕ) ∈E and Δ ⊆Γ, then (Δ, ψ) ∈E.
2. E satisﬁes the consistency postulate, that is, {Γ | (Γ, ϕ) ∈E} is consistent.
Deductive argumentation frameworks also satisfy other rationality postu-
lates, but that is outside the scope of this paper.

Base Argumentation as an Abstraction of Deductive Argumentation
473
3
Base Argumentation Frameworks
In this section, we introduce the formalism of base argumentation. Each base
argument is a consistent subset of the knowledge base. The attack relation on
base arguments is similar to the assumption attack in Deﬁnition 8. The satisfac-
tion of two rationality postulates adapted from [5] and [2] is proven.
Deﬁnition 11. Let (L, ⊢) be an abstract logic and Σ a knowledge base. A base
argument is a consistent subset of Σ. We use Γ, Δ etc. to denote base arguments.
Base argument Γ is a sub-argument of Δ if Γ ⊆Δ.
Deﬁnition 12. Let (L, ⊢) be an abstract logic and Σ a knowledge base. Let Γ
and Δ be deductive arguments. Γ attacks Δ iﬀthere exists a formula φ ∈Δ
such that Γ ⊢¬φ.
Deﬁnition 13. Let (L, ⊢) be an abstract logic and Σ a knowledge base. A base
argumentation framework Tb is a pair (Arb(Σ), Rb) where Arb(Σ) is the set of
base arguments based on Σ, and Rb is the attack relation deﬁned in Deﬁnition
12.
Now we show that base argumentation satisﬁes two rationality postulates.
Deﬁnition 14. Let (L, ⊢) be an abstract logic, Σ a knowledge base and Tb =
(Arb(Σ), Rb) a base argumentation framework.
– Tb is closed under sub-arguments iﬀfor each complete extension E of Tb, if
Γ ∈E and Δ ⊆Γ, then Δ ∈E.
– Tb satisﬁes the consistency postulate iﬀfor each complete extension E of Tb,

Γ ∈E Γ is consistent.
Proposition 15. Let (L, ⊢) be an abstract logic, Σ a knowledge base and Tb =
(Arb(Σ), Rb) a base argumentation framework. Then Tb is closed under sub-
arguments and satisﬁes the consistency postulate.
4
Correspondence Between Base and Deductive
Argumentation Frameworks
In this section, we prove some correspondence results between a base argumen-
tation framework Tb = (Arb(Σ), Rb) and a deductive argumentation framework
Td = (Ard(Σ), Rd) obtained from the same abstract logic and knowledge base
Σ. The correspondence results include a correspondence between Rb and Rd
with a bijective map between the set of complete extensions of Tb and that of
Td.
For simplicity, we say that Γ attacks Δ instead of (Γ, Δ) ∈Rb for base
arguments Γ, Δ, and that (Γ, ϕ) attacks (Δ, ψ) instead of ((Γ, ϕ), (Δ, ψ)) ∈Rd
for deductive arguments (Γ, ϕ), (Δ, ψ).
The following proposition is about the correspondence between Rb and Rd:

474
J. Chen et al.
Proposition 16. Let (L, ⊢) be an abstract logic, Σ a knowledge base, Tb =
(Arb(Σ), Rb) a base argumentation framework and Td = (Ard(Σ), Rd) a deduc-
tive argumentation framework. Then,
1. For Γ, Δ ∈Arb(Σ), if Γ attacks Δ, then there exist deductive arguments
(Γ ′, ϕ) and (Δ′, ψ) such that (a) (Γ ′, ϕ) attacks (Δ′, ψ) and (b) Γ ′ ⊆Γ and
Δ′ ⊆Δ.
2. For (Γ, ϕ), (Δ, ψ) ∈Ard(Σ), if (Γ, ϕ) attacks (Δ, ψ), then Γ attacks Δ.
Denote by COM(Tb) the set of complete extensions of Tb and by COM(Td) the
set of complete extensions of Td. The following proposition deﬁnes and justiﬁes
functions (.)• : COM(Tb) →COM(Td) and (.)• : COM(Td) →COM(Tb).
Proposition 17. Let (L, ⊢) be an abstract logic and Σ a knowledge base. Let
Tb = (Arb(Σ), Rb) be a base argumentation framework and Td = (Ard(Σ), Rd)
a deductive argumentation framework.
1. If E is a complete extension of Tb, then E•, deﬁned as follows, is a complete
extension of Td.
E• := {(Γ, ϕ) | (Γ, ϕ) is a deductive argument and Γ ⊆Γ ′ for some Γ ∈E}
2. If Ed is a complete extension of Td and (Γ, ϕ) ∈E, then E•
d, deﬁned as follows,
is a complete extension of Tb.
E•
d := {Γ | (Γ, ϕ) ∈Ed}
Next, we show that functions (.)• and (.)• are bijective.
Proposition 18. Let (L, ⊢) be an abstract logic and Σ a knowledge base. Let
Tb = (Arb(Σ), Rb) be a base argumentation framework and Td = (Ard(Σ), Rd)
a deductive argumentation framework.
1. (.)• : COM(Tb) →COM(Td) is bijective.
2. (.)• : COM(Td) →COM(Tb) is bijective.
5
Conclusion and Future Work
This paper presented a preliminary formalism of base argumentation. It can be
seen as an abstraction of deductive argumentation.
There are some possibilities for further research:
1. This paper only considers assumption attacks in deductive argumentation and
then only for complete semantics. There are other settings in the literature.
2. We might investigate the relationship between extensions of base argumenta-
tion frameworks under diﬀerent semantics and maximal consistent sets.

Base Argumentation as an Abstraction of Deductive Argumentation
475
3. Base argumentation is similar to ABA. Both base argumentation and ABA
treat the subsets of the knowledge base as the basic entities, which are called
base arguments in base argumentation and sets of assumptions in ABA. The
deductive mechanism in base argumentation is Tarski’s logic, and ABA uses a
deductive system. Extensions in base argumentation are sets of subsets of the
knowledge base, while extensions in ABA are subsets of the knowledge base.
Because of these similarities, we expect to ﬁnd some connections between
base argumentation and ABA.
4. Logic-based instantiations of ABA is studied by Heyninck and Arieli [11]. We
will compare base argumentation with their work in the extended version of
this paper.
Acknowledgements. The research reported in this paper was supported by the
National Social Science Foundation Major Project of China under grants No. 20&
ZD047 and No.18ZDA290. Leon van der Torre acknowledges ﬁnancial support
from the Fonds National de la Recherche Luxembourg (INTER/Mobility/19/1399
5684/DLAl/van der Torre).
References
1. Amgoud, L.: Postulates for logic-based argumentation systems. Int. J. Approx.
Reason. 55(9), 2028–2048 (2014)
2. Amgoud, L., Besnard, P.: Logical limits of abstract argumentation frameworks. J.
Appl. Non-Classical Log. 23(3), 229–267 (2013)
3. Amgoud, L., Besnard, P., Vesic, S.: Identifying the core of logic-based argumenta-
tion systems. In: 2011 IEEE 23rd International Conference on Tools with Artiﬁcial
Intelligence, pp. 633–636. IEEE (2011)
4. Besnard, P., Hunter, A.: A review of argumentation based on deductive arguments.
Handbook of Formal Argumentation, pp. 437–484 (2018)
5. Caminada, M., Amgoud, L.: On the evaluation of argumentation formalisms. Artif.
Intell. 171(5–6), 286–310 (2007)
6. Caminada, M., S´a, S., Alcˆantara, J., Dvoˇr´ak, W.: On the diﬀerence between
assumption-based argumentation and abstract argumentation. IfCoLog J. Log.
Appl. 2(1), 15–34 (2015)
7. ˇCyras, K., Schulz, C., Toni, F., Fan, X.: Assumption-based argumentation: dis-
putes, explanations, preferences. IFCoLog J. Log. Appl. 4(8), 2407–2456 (2017)
8. Dung, P.M., Mancarella, P., Toni, F.: Computing ideal sceptical argumentation.
Artif. Intell. 171(10–15), 642–674 (2007)
9. Dung, P.M.: On the acceptability of arguments and its fundamental role in non-
monotonic reasoning, logic programming and n-person games. Artif. Intell. 77(2),
321–357 (1995)
10. Elvang-Gøransson, M., Krause, P.J., Fox, J.: Acceptability of arguments as ‘log-
ical uncertainty’. In: Clarke, M., Kruse, R., Moral, S. (eds.) ECSQARU 1993.
LNCS, vol. 747, pp. 85–90. Springer, Heidelberg (1993). https://doi.org/10.1007/
BFb0028186
11. Heyninck, J., Arieli, O.: Simple contrapositive assumption-based argumentation
frameworks. Int. J. Approx. Reason. 121, 103–124 (2020)

476
J. Chen et al.
12. Modgil, S., Prakken, H.: A general account of argumentation with preferences.
Artif. Intell. 195, 361–397 (2013)
13. Tarski, A.: On some fundamental concepts of metamathematics. Oxford (1956)
14. Toni, F.: Reasoning on the web with assumption-based argumentation. In: Eiter,
T., Krennwallner, T. (eds.) Reasoning Web 2012. LNCS, vol. 7487, pp. 370–386.
Springer, Heidelberg (2012). https://doi.org/10.1007/978-3-642-33158-9 10

An Argumentative Dialogue System
for COVID-19 Vaccine Information
Bettina Fazzinga1,2
, Andrea Galassi3(B)
, and Paolo Torroni3
1 ICAR-CNR, Rende, Italy
bettina.fazzinga@icar.cnr.it
2 DICES, University of Calabria, Rende, Italy
3 DISI, University of Bologna, Bologna, Italy
{a.galassi,paolo.torroni}@unibo.it
Abstract. Dialogue systems are widely used in AI to support timely and
interactive communication with users. We propose a general-purpose dia-
logue system architecture that leverages computational argumentation to
perform reasoning and provide consistent and explainable answers. We
illustrate the system using a COVID-19 vaccine information case study.
Keywords: Computational argumentation · Dialogue systems ·
Explainability · Expert systems · Chatbots
1
Introduction
Since the early days of AI, research has been inspired by the idea of develop-
ing programs that can communicate with users in natural language. With the
advent of language technologies able to reach human performance in various
tasks, AI chatbots and dialogue systems are starting to mature and this vision
seems nearer than ever. As a result, more organizations are investing in chatbot
development and deployment. In the 2019 Gartner CIO Survey, CIOs identiﬁed
chatbots as the main AI-based application used in their enterprises,1 with a
global market valued in the billions of USD.2
In fact, chatbots are one example of the extent AI technologies are becoming
ever more pervasive, both in addressing global challenges, and in the day-to-day
routine. Public administrations too are adopting chatbots for key actions such as
helping citizens in requesting services3 and providing updates and information,
for example, in relation with COVID-19 [13].4
1 https://www.gartner.com/smarterwithgartner/chatbots-will-appeal-to-modern-wor
kers/.
2 https://www.mordorintelligence.com/industry-reports/chatbot-market.
3 https://www.canada.ca/en/employment-social-development/services/my-account/te
rms-use-chatbot.html.
4 https://government.economictimes.indiatimes.com/news/digital-india/covid-19-gov
t-launches-facebook-and-messenger-chatbot/74843125.
B. Fazzinga, A. Galassi, and P. Torroni—Equal contribution.
c
⃝Springer Nature Switzerland AG 2021
P. Baroni et al. (Eds.): CLAR 2021, LNAI 13040, pp. 477–485, 2021.
https://doi.org/10.1007/978-3-030-89391-0_27

478
B. Fazzinga et al.
However, the expansion of intelligent technologies has been met by growing
concerns about possible misuses, motivating a need to develop AI systems that
are trustworthy. On the one hand, governments are pressured for gaining or
preserving an edge in intelligent technologies, which make intensive use of large
amounts of data. On the other hand, there is an increasing awareness of the need
for trustworthy AI systems.5
In the context of information-providing chatbots and assistive dialogue sys-
tems, especially in the public sector, we believe that trustworthiness demands
transparency, explainability, correctness, and it requires architectural choices
that take data access into account from the very beginning. Arguably, this kind
of chatbot should not only use transparent and veriﬁable methods and be so
conceived as to respect relevant data protection regulations, but it should also
be able to explain its outputs or recommendations in a manner adapted to the
intended (human) user.
We thus propose an architecture for AI dialogue systems where user inter-
action is carried out in natural language, not only for providing information to
the user, but also to answer user queries about the reasons leading to the sys-
tem output (explainability). The system selects answers based on a transparent
reasoning module, built on top of a computational argumentation framework
with a rigorous, veriﬁable semantics (transparency, auditability). Additionally,
the system has a modular architecture, so as to decouple the natural language
interface, where user data is processed, from the reasoning module, where expert
knowledge is used to generate outputs (privacy and data governance).
Our work is positioned at the intersection of two areas: computational argu-
mentation and natural language understanding. While computational argumen-
tation has had signiﬁcant applications in the context of automated dialogues
among software agents, its combination with systems able to interact in natu-
ral language in socio-technical systems has been more recent. The most related
proposal in this domain is a recent one by Chalaguine and Hunter [4]. With
respect to such work, our focus is not on persuading the user but on oﬀering
correct information. Accordingly, we put greater emphasis on the correctness
and justiﬁcation of system outputs, and on the system’s ability to reason with
every relevant user input, as opposed to reacting to the last input. Our modular
architecture enables a separation between language understanding and argumen-
tative reasoning, which enables signiﬁcant generality. In particular, our dialogue
system architecture can be applied to multiple domains, without requiring any
expensive retraining.
In this article we focus on the system’s architecture and on the knowledge
representation and reasoning module. We start with a brief overview of related
approaches (Sect. 2). Next, we give a high-level description of the system archi-
tecture (Sect. 3) and then zoom in on the argumentation module supporting
knowledge representation and reasoning and dialogue strategies (Sect. 4). To
illustrate, we sketch a dialogue between chatbot and human in the context of
5 https://ec.europa.eu/digital-single-market/en/news/ethics-guidelines-trustworthy-
ai.

An Argumentative Dialogue System for COVID-19 Vaccine Information
479
COVID-19 vaccines (Sect. 5), showing how background knowledge and user data
can be formalized and jointly used to provide correct answers, and how the
system output can be challenged by the user. Section 6 concludes.
2
Related Work
In the ﬁeld of computational argumentation, signiﬁcant work has been devoted
to deﬁning and reasoning over the argumentation graphs [1,5,10], leading to sev-
eral ways of identifying “robust” arguments or sets of arguments [7,8]. However,
the practical combination of computational argumentation and dialogue systems
based on natural language has not been much explored. Among the few exist-
ing approaches, Rosenfeld and Kraus [16] combine theoretical argumentation
with reinforcement learning to develop persuasive agents, while Rach et al. [14]
extract a debate’s argument structure and envision the dialogue as a game, struc-
turing the answers as moves along a previously deﬁned scheme. In both cases
the agents are limited in their inputs and outputs to sentences “hard-coded” in
the knowledge base.
An interesting approach in this direction is by Chalaguine and Hunter [4],
who exploit sentence similarity to retrieve an answer from a knowledge base
expressed in the form of a graph. No conversation history is kept, therefore the
answers produced by the system do not take into account previous user inputs.
We believe that this approach is inappropriate for complex scenarios where mul-
tiple pieces of information must be considered at the same time, since the user
would have to include all of them in the same sentence. Moreover, this approach
does not involve reasoning, but relevance-based answer retrieval. Our approach,
instead, aims to output replies ‘consistent’ with all the information provided
thus far by the user, and that will not be proven wrong later on. In particular,
what we do is we enforce the condition of acceptance of some arguments, by
eliciting speciﬁc user input. This can be seen as a practical application of the
concepts deﬁned by Baumann and Brewka [2]. In particular, our system relies
on an argumentation module that maintains a history of the concepts expressed
by the user and performs reasoning over an argumentation graph to compute
the answer. It is therefore possible for the user to consider multiple information
at the same time, to ask for more information if they are needed, and also to
provide an explanation for the previous answers.
3
System Architecture
Our chatbot architecture consists of two core modules: the language module and
the argumentation module. The former provides a natural language interface to
the user input, while the latter deals with the problem of computing correct
replies to be provided to the user, and it relies on computational argumentation.
In this work, we will focus on the argumentation module, leaving the speciﬁc
implementation of the language module for future developments.

480
B. Fazzinga et al.
Fig. 1. System architecture.
We assume the presence of a scenario-speciﬁc knowledge base (KB) created
by experts, in the form of an argumentation graph (see Sect. 3) with two kinds of
nodes. Nodes are either status arguments or reply arguments. The former encode
facts that correspond to the possible user sentences. Each status node is linked to
one or more reply arguments it supports6, and that represent replies to the facts
stated by the user. Status nodes may also attack other status or reply nodes,
typically because the facts they represent are incompatible with one another.
Additionally, a set of natural language sentences is associated with each status
node and represents some possible ways a user would express the facts the node
encodes. These diﬀerent representations of facts could be produced by domain
experts or crowd-sourced.
The behaviour of the system and the interaction between the modules is illus-
trated in Fig. 1. The language module compares each user sentence against the
sentences embedded in the KB. In particular, like Chalaguine and Hunter [4], we
propose to use a sentence similarity measure to identify KB sentences matching
the user input. Since each KB sentence is associated with a status node, a list
of related status nodes can be computed from the list of sentences in the KB
identiﬁed by the language module as a match. Accordingly, when a user writes a
sentence, a set of status nodes N is ‘activated’, in the sense that they are recog-
nized as matching with the user’s input. However, diﬀerently from Chalaguine
and Hunter [4], all the status arguments activated during the chat with the user
are stored in a set S.
The fundamental principle that characterizes our approach is that a reply
R among those supported by N is given to the user only if it is acceptable
w.r.t. S. This means that the information given by the user needs to support
and defend R from its attacks. If there is no acceptable reply with respect to
S, the chatbot selects anyway a candidate reply R, but instead of oﬀering R
immediately, it prompts the user in order to acquire new information that could
activate new status arguments which, added to S, could make R acceptable w.r.t.
S. This elicitation process aims to guarantee that R is not proven wrong in the
continuation of the chat. In fact, all the information that can be in contrast with
R (i.e., that attack R) are asked to the user, in order to be sure to defeat any
potential attackers.
6 We point out that our concept of support is a new notion linking status nodes to
reply nodes, and its semantics is diﬀerent from the standard one [3,9].

An Argumentative Dialogue System for COVID-19 Vaccine Information
481
This underlying strategic reasoning marks a signiﬁcant diﬀerence from previ-
ous approaches. Another distinguishing feature is our system’s ability to provide
users with online, on-demand explanations. In particular, besides providing infor-
mation and getting replies, users can also require an explanation for a given reply
r. An explanation for r consists of a sequence of natural language sentences built
from (i) descriptions of the status nodes of S supporting r and ii) motivations
against other possible conﬂicting replies that the system discarded.
4
Argumentation Module
The argumentation module is based on a knowledge base expressed as an argu-
ment graph.
Deﬁnition 1 (Argumentation graph). An argumentation graph is a tuple
⟨A, R, D, T⟩, where A and R are the arguments of the graph and are called status
arguments and reply arguments, respectively, D ⊆A × (A ∪R) encodes the
attack/defeat relation, and T ⊆A × R encodes the support relation.
Each argument a in A is annotated with a set of natural language sentences,
as described in the previous section. We say that a attacks (resp., supports) a
reply node r iﬀ(a, r) ∈D (resp., (a, r) ∈T). By extension, we say that a set S
attacks (resp., supports) r, or equivalently that r is attacked by (resp., supported
by) S, iﬀthere exists an argument a ∈S s.t. a attacks (resp., supports) r.
The aim of the argumentation module is to identify the reply nodes in
response to the user sentences. To this end, in addition to the KB, each dia-
logue session relies on dynamically acquired knowledge, expressed as a set of
facts or status arguments S. The dialogue strategy is to provide the user with
a reply that is supported and defended by S. However, diﬀerently from other
proposals, our system does not simply select a consistent reply at each turn.
On the contrary, it strategizes in order to provide only robust replies, possibly
delaying replies that need further fact-checking. To that end, the two following
deﬁnitions distinguish between consistent and potentially consistent reply. The
former can be given to the user right away, as it can not possibly be proven
wrong in the future.7 The latter, albeit consistent with the current known facts,
may still be defeated by future user input, and therefore it should be delayed
until a successful elicitation process is completed.
The formal deﬁnitions are based on the KB and on a representation of the
state of the dialogue consisting of two sets: S and N. In particular, S ⊆A
contains the arguments activated during the conversation so far, whereas N ⊆S
contains arguments in support of the system’s possible replies to the user. We
recall that an argument a is acceptable w.r.t. a set S iﬀS defends a from every
attack towards a.
7 The implicit assumption here is that the user does not enter conﬂicting information,
and that the language model correctly interprets the user input. Clearly, if this is
not the case, the system’s output becomes unreliable. But that wouldn’t depend on
the underlying reasoning framework. The deﬁnition of fall-back strategies able to
handle such exceptions would be an important extension to the system.

482
B. Fazzinga et al.
Deﬁnition 2 (Consistent
reply).
Given
an
argumentation
graph
⟨A, R, D, T⟩and two sets S ⊆A and N ⊆S, a reply r ∈R is consistent iﬀ
N supports r and r is acceptable w.r.t. S.
Deﬁnition 3 (Potentially consistent reply).
Given an argumentation
graph ⟨A, R, D, T⟩and two sets S ⊆A and N ⊆S, a reply r ∈R is poten-
tially consistent iﬀN supports r, S does not attack r and r is not acceptable
w.r.t. S.
Finally, users can challenge the system output. An explanation of a reply
r consists of two parts. The ﬁrst one contains the arguments leading to r, i.e.,
those belonging to a set S that supports r. The second one encodes the why
nots, to explain why the chatbot did not give other replies.
Deﬁnition 4 (Explanation). Given an argumentation graph ⟨A, R, D, T⟩, a
set S ⊆A and a reply r ∈R, an explanation for r is a pair ⟨Supp, NotGiven⟩,
where Supp contains the arguments a ∈S s.t. (a, r) ∈T and NotGiven is a set
of pairs ⟨r′, N ′⟩, where r′ ̸= r, r′ is supported by S and N ′ ⊆S contains the
arguments b attacking r′.
In the next section we brieﬂy explain how our strategy works to provide
the user with consistent replies, by means of an example in the context of the
COVID-19 vaccines.
5
Case Study
Disclaimer. The illustration that follows is based on a (simplistic) representa-
tion of the domain knowledge. Its purpose is to show a proof of concept of our
approach–not to oﬀer sound advice about vaccines. We base our example on the
content of the AIFA website.8
We consider the context of the vaccines for COVID-19, where we aim to create
a dialogue system able to answer user inquiries about vaccination procedures,
vaccine safety, and so on. Figure 2 shows an excerpt of the argumentation graph
encoding the KB, in particular the part related to options for getting vaccinated.
Yellow rectangles represent status arguments, blue ovals reply arguments,
green solid arrows support relations, pointing to the possible replies to user sen-
tences, and red dotted arrows denote attack relations. It is worthwhile noticing
that the graph contains both the positive and negative version of each status
argument. This is a key modeling feature in the context at hand, as it enables
the chatbot to properly capture and encode all the information provided by the
user about their health conditions.
Let us consider this example: the user writes “Hi, I am Morgan and I suﬀer
from latex allergy, can I get vaccinated?” The language module processes the user
sentence and compares it against all the sentences provided by the knowledge
base, resulting in a single positive match with the sentence “I have latex allergy”
8 Italian medicines agency, https://www.aifa.gov.it/en/vaccini-covid-19.

An Argumentative Dialogue System for COVID-19 Vaccine Information
483
Bronchial
asthma
Get
vaccinated at
the hospital
Drug
Allergy
Get vaccinated at any
vaccine site. Monitoring 
for 60 minutes
Celiac
Get vaccinated at any
vaccine site. No 
special monitoring
Immunosuppr
ession
No celiac
No drug
allergy
No bronchial
asthma
No 
immunosuppres
sion
N1
R2
N2
N3
N4
N5
N6
N16
N8
R1
R3
No 
diabetes
Diabetes
N9
N10
Latex 
allergy
N11
N12
No latex 
allergy
Mastocy
tosis
No 
mastocytosis
N13
N14
Previous
serious
anaphylaxis
N15
No previous
anaphylaxis
N7
Fig. 2. An excerpt of an argumentation graph encoding knowledge about COVID-19
vaccines.
associated with node N11. At this point, the argumentation module deals with
the computation of the replies, ﬁnding that the only reply supported by S =
{N11} is R2 and that it is not a consistent reply, because it is attacked by both
N8 and N15. It is, however, a potentially consistent reply: thus, although we
cannot give it yet to the user, what we can do is acquire new information that
would make it consistent. To make R2 consistent, S must be augmented with
both N7 and N16. This means that the user must tell that they do not suﬀer
from bronchial asthma and that they had no previous anaphylaxis. Then, our
strategy is to query the user whether they suﬀer from bronchial asthma and/or
whether they had any previous anaphylaxis. Assume at this point that the user
replies are U1 =I do not suﬀer from bronchial asthma and U2 =I have never
had any anaphylaxis. Then, we can extend S with the new corroborating bits
of information, obtaining S = {N11, N7, N16}. Because R2 is now a consistent
reply, we can return R2 to the user.
Alternatively, suppose that the user writes that they do suﬀer from bronchial
asthma. In that case, we would have S = {N11, N8, N16}, hence R2 would not
be a consistent reply. Accordingly, the only consistent reply that can be given
to the user would be R3.
Finally, suppose that, upon getting R3 as a reply, the user asks for an explana-
tion. In that case, ⟨Supp, NotGiven⟩is such that Supp = {N8}, and NotGiven
consists of the unique pair ⟨R2, {N8}⟩, meaning that R2 was not given due to
N8, that is, due to the fact that the user suﬀers from bronchial asthma.

484
B. Fazzinga et al.
6
Conclusion
We presented a new modular dialogue system architecture based on compu-
tational argumentation and language technologies. In particular, our system
exploits both user input and a knowledge base built by domain experts to per-
form reasoning in order to compute answers and identify missing bits of infor-
mation. We illustrated our proposal with an information-seeking scenario, where
a user requires information about COVID-19 vaccines.
Our proposal has multiple advantages over previous approaches. With respect
to corpus-based dialogue systems, it can use expert knowledge. This is espe-
cially important in domains that require trustworthy, correct and explainable
solutions. Indeed, a remarkable feature of argumentation graphs is their ability
to support reasoning over the conﬂicts between arguments, leading to approv-
ing or discarding some responses. We believe that highlighting the reasons why
a response can not be given, along with the facts that rule out other possible
responses, is a good way to make the user understand the response and trust the
system. Importantly, the architecture is general-purpose and does not require
domain-speciﬁc training or reference corpora. With respect to prior work on
argumentation-based dialogue systems, its major advantage is its ability to rea-
son with multiple elements of user information, in order to provide focused and
sound answers, by eventually performing the elicitation of missing data.
In this paper we focused on the argumentation module, leaving the imple-
mentation of the language module for future works. In this regard, we plan to
explore the use of recent attention-based neural architectures [11] by representing
the user input using BERT-based [6] sentence embeddings [15] and by comparing
them using advanced similarity measures [12].
Since our proposal is general and not limited to a speciﬁc domain, it will be
interesting to test our approach on new scenarios and also to consider languages
other than English. Another important aspect we plan to address in the future
is the management of conﬂicting information provided by the user, and the
possibility to revise previously submitted information.
Acknowledgments. The research reported in this work was partially supported by
the EU H2020 ICT48 project “Humane AI Net” under contract #952026.
References
1. Baroni, P., Giacomin, M.: Semantics of abstract argument systems. In: Simari,
G., Rahwan, I. (eds.) Argumentation in Artiﬁcial Intelligence, pp. 25–44. Springer,
Boston, MA (2009). https://doi.org/10.1007/978-0-387-98197-0 2
2. Baumann, R., Brewka, G.: Expanding argumentation frameworks: enforcing and
monotonicity results. In: COMMA, vol. 216, pp. 75–86. IOS Press (2010). https://
doi.org/10.3233/978-1-60750-619-5-75
3. Cayrol, C., Lagasquie-Schiex, M.C.: On the acceptability of arguments in bipolar
argumentation frameworks. In: Godo, L. (ed.) ECSQARU 2005. LNCS (LNAI),
vol. 3571, pp. 378–389. Springer, Heidelberg (2005). https://doi.org/10.1007/
11518655 33

An Argumentative Dialogue System for COVID-19 Vaccine Information
485
4. Chalaguine, L.A., Hunter, A.: A persuasive chatbot using a crowd-sourced argu-
ment graph and concerns. In: COMMA, vol. 326, pp. 9–20. IOS Press (2020).
https://doi.org/10.3233/FAIA200487
5. Charwat, G., Dvor´ak, W., Gaggl, S.A., Wallner, J.P., Woltran, S.: Methods for
solving reasoning problems in abstract argumentation - a survey. Artif. Intell. 220,
28–63 (2015). https://doi.org/10.1016/j.artint.2014.11.008
6. Devlin, J., Chang, M., Lee, K., Toutanova, K.: BERT: pre-training of deep bidi-
rectional transformers for language understanding. In: NAACL-HLT, no. 1, pp.
4171–4186. Association for Computational Linguistics (2019). https://doi.org/10.
18653/v1/n19-1423
7. Dung, P.M.: On the acceptability of arguments and its fundamental role in non-
monotonic reasoning, logic programming and n-person games. Artif. Intell. 77(2),
321–358 (1995). https://doi.org/10.1016/0004-3702(94)00041-X
8. Dung, P.M., Mancarella, P., Toni, F.: Computing ideal sceptical argumentation.
Artif. Intell. 171(10–15), 642–674 (2007). https://doi.org/10.1016/j.artint.2007.05.
003
9. Fazzinga, B., Flesca, S., Furfaro, F.: Probabilistic bipolar abstract argumentation
frameworks: complexity results. In: IJCAI, pp. 1803–1809. ijcai.org (2018). https://
doi.org/10.24963/ijcai.2018/249
10. Fazzinga, B., Flesca, S., Furfaro, F.: Complexity of fundamental problems in prob-
abilistic abstract argumentation: beyond independence. Artif. Intell. 268, 1–29
(2019). https://doi.org/10.1016/j.artint.2018.11.003
11. Galassi, A., Lippi, M., Torroni, P.: Attention in natural language processing. IEEE
Trans. Neural Netw. Learn. Syst. 1–18 (2020). https://doi.org/10.1109/TNNLS.
2020.3019893
12. Galassi, A., Drazewski, K., Lippi, M., Torroni, P.: Cross-lingual annotation projec-
tion in legal texts. In: COLING, pp. 915–926. International Committee on Compu-
tational Linguistics, Barcelona, Spain (Online) (December 2020). https://doi.org/
10.18653/v1/2020.coling-main.79
13. Miner, A.S., Laranjo, L., Kocaballi, A.B.: Chatbots in the ﬁght against the COVID-
19 pandemic. NPJ Digit. Med. 3(1), 1–4 (2020). https://doi.org/10.1038/s41746-
020-0280-0
14. Rach, N., Langhammer, S., Minker, W., Ultes, S.: Utilizing argument mining tech-
niques for argumentative dialogue systems. In: D’Haro, L.F., Banchs, R.E., Li, H.
(eds.) 9th International Workshop on Spoken Dialogue System Technology. LNEE,
vol. 579, pp. 131–142. Springer, Singapore (2019). https://doi.org/10.1007/978-
981-13-9443-0 12
15. Reimers, N., Gurevych, I.: Sentence-BERT: sentence embeddings using Siamese
BERT-networks. In: EMNLP/IJCNLP, no. 1, pp. 3982–3992. Association for Com-
putational Linguistics, Hong Kong, China (November 2019). https://doi.org/10.
18653/v1/D19-1410
16. Rosenfeld, A., Kraus, S.: Strategical argumentative agent for human persuasion.
In: ECAI, pp. 320–328. IOS Press, NLD (2016). https://doi.org/10.3233/978-1-
61499-672-9-320

Extractive-Abstractive Summarization
of Judgment Documents Using Multiple
Attention Networks
Yan Gao1
, Zhengtao Liu1
, Juan Li2(B)
, Fan Guo1,2, and Fei Xiao1,2
1 School of Automation, Central South University, Changsha 410083, China
2 School of Law, Central South University, Changsha, China
Abstract. Judgment documents contain rich legal information, they are
simultaneously lengthy with complex structure. This requires summariz-
ing judgment documents in an eﬀective way. By analyzing the struc-
tural features of Chinese judgment documents, we propose an automatic
summarization method, which consists of an extraction model and an
abstraction model. In the extraction model, all the sentences are encoded
by a Self-Attention network and are classiﬁed into key sentences and
non-key sentences. In the abstraction model, the initial summarization
is reﬁned into a ﬁnal summarization by a unidirectional-bidirectional
attention network. Such a summarization could help improve the eﬃ-
ciency in case handling and make judgment documents more accessible
to the general readers. The experimental results on CAIL2020 dataset
are satisfactory.
Keywords: Judgment documents · Automatic summarization ·
Attention network · Encoder-decoder
1
Introduction
Judgment documents contain a wealth of information. They record the processes
and results of legal cases, which is an important means for the courts to opening
the trial activities and publishing the reasons and results of their decisions. The
judgment document is the only evidence for the courts to determine and allo-
cate the substantive rights and obligations of the parties. However, the judgment
documents use domain knowledge in a lengthy way and their structure tend to
be complex, which set reading obstacles to the general readers. The summa-
rization of judgment documents is compression of court decisions, reﬂecting the
adjudication process, facts, reasons and judgment basis in the process of trial. A
summarization of judgment documents with a short, simple sentence structure
can help legal practitioners improve the eﬃciency of handling cases and enhance
the public acceptance of the law.
A novel Extractive-Abstractive summarization method for Chinese judgment
documents is proposed in this paper. The method includes an extraction model
and an abstraction model. For a complete judgment document, key sentences are
c
⃝Springer Nature Switzerland AG 2021
P. Baroni et al. (Eds.): CLAR 2021, LNAI 13040, pp. 486–494, 2021.
https://doi.org/10.1007/978-3-030-89391-0_28

Summarization of Judgment Documents
487
extracted by the extraction model and combined into an initial summarization.
Then, the initial summarization is reﬁned into a ﬁnal summarization through
the abstraction model. Summarization generated in this way contains almost
all relevant information in a legal case in a brief way. Such a model could help
to improve the eﬃciency of judicial professionals in handling cases and make
judgment documents more accessible to the general readers.
2
Related Work
How to employ computers to process legal texts is a core problem in the AI&Law
domain [1–3]. Automatic summarization of legal texts is to apply technology in
natural language processing (NLP) to compress the legal texts automatically.
At present, automatic text summarization (ATS) broadly employs two
approaches: extractive and abstractive. Extractive summarization refers to select
key sentences from the original text as summarization, which is usually regarded
as a sequence labeling task. For example, Kageback et al. [4] deﬁned an objective
function on the text to be compressed. They regarded extractive summarization
as a problem of optimal selection of sentence sequences. Cao et al. [5] sought to
make the selection more accurate. They predicted the score of each sentence and
sorted them, then judged whether to add sentences to the summary according
to the principle of redundancy. Cheng et al. [6] used LSTM (Long Short-Term
Memory) [7] as a decoder for each sentence, whose input was the embedding
of the previous sentence and its output was classiﬁed to determine whether the
sentence should be included in the summary.
Abstractive summarization is to generate new sentences through the fusion
of the original information, with stronger coherence and readability. Rush et
al. [8] and Chopra et al. [9] combined the attention mechanism [10] with neural
network, and constructed an automatic text summarization model based on
Seq2Seq (sequence-to-sequence) [11] framework. They achieved good results on
general text data sets. With the introduction of the pre-trained language model
BERT [12], subsequent works [13,14] tried to combine Bert with Seq2Seq, which
provided a new method for our task of summarizing judgment documents.
3
Proposed Model
In this section, we will describe our Extractive-Abstractive summarization model
for judgment documents in detail. A summary of the judgment document should
be logical, readable and consistent. This requires to extract the key sentences
accurately, then reﬁne and rewrite them. The whole model consists of two
parts: key sentences extraction based on Self-Attention mechanism and sum-
mary abstraction based on attention mask mechanism.

488
Y. Gao et al.
Fig. 1. Overall framework of our model.
3.1
Overview
Figure 1 shows the framework of our model. Extraction model: a com-
plete judgment document is preprocessed and divided into a sentence set
{ST1, ST2, ST3...STn}. Then a pre-trained language model with Self-Attention
mechanism is used as an encoder to obtain the feature embedding of the whole
sentence. A trained classiﬁer is combined to get the label of each sentence (“1”
represents key sentence, “0” represents non-key sentence). Abstraction model:
all the sentences labeled “1” are merged into an initial summarization, which is
segmented into a sub-paragraph set {P1, P2, P3...Pn}. Sub-paragraphs are sent
into a generation model model based on RoBERTa-wwm1 and uniﬁed language
model (UniLM) [14] training method to generate corresponding summary set
{S1, S2, S3...Sn}. Finally, summary set is merged into a ﬁnal summary of the
whole judgment document.
3.2
Key Sentences Extraction Model
According to People’s Court Civil Judgment Document Production Standards2,
cause of action, facts, issue, ratio of the decision, ruling basis and ﬁnal judgment
are important components in a judgment document. They are described in detail
as follows:
1 https://github.com/ymcui/Chinese-BERT-wwm.
2 https://m.lawtime.cn/info/wenshu/pjmscpwsyishen/201607073334851.html.

Summarization of Judgment Documents
489
– Cause of action: the source of the case and the category of legal disputes
– Facts: the chronological events that led to the lawsuit, including the legal
claims and defenses of contending parties and the facts repeated in the court’s
opinion.
– Issue: legal issues being discussed
– Ratio of the decision: rationale of the Court for the ﬁnal ruling
– Ruling basis: citations to established laws by the current case
– Final judgment: conclusion of the court
Fig. 2. Sentences in a Chinese judgment document and corresponding label.
As the Chinese judgment document shown in Fig. 2, there are many formal
structural sentences labeled “0” that have no important information of the case.
The sentences labeled “1”, by comparison, contain signiﬁcant information, which
belong to the important components above.
On analyzing sentences labeled “1”, we ﬁnd that they usually contain some
special key words or phrases, such as plaintiﬀ’s claimant, court’s opinion and
court’s decision. Sentences containing similar keywords or synonyms are more
likely to be identiﬁed as key sentences. Self-Attention [12] is a special form of
Attention to search the connection of words within a sentence. In this paper,
Self-Attention mechanism is used to make the model distinguish the categories
of sentences by local word information.

490
Y. Gao et al.
3.3
Summary Abstraction Model
The key sentences extraction model extracts most important information from
judgment documents and keeps the overall logical consistency. However, the
initial summarization are inconsistent and diﬃcult to understand since these
sentences are selected directly from the original text. The summary abstraction
model is aimed to rewrite and reﬁne the initial summarization.
In this paper, the generation of the ﬁnal summary is transformed into a
Seq2Seq problem. The input sequence is the initial summarization, and the tar-
get sequence is the ﬁnal summary. Seq2Seq is an encoder-decoder framework,
in which the encoder compresses input sequence into embeddings with speciﬁed
length, and the decoder generates speciﬁed sequences through these embeddings.
According to [14], we adopt RoBERTa-wwm as the framework, and summariza-
tion can be regarded as sentence completion [15].
Initial summarization is represented as a sequence{A, B, C, D, E}, and the
ﬁnal summarization is represented as a sequence{F, G, H}. Sequence generation
based on unidirectional language model can be represented by Eq. (1). Atten-
tion map of unidirectional language model is shown in the left of Fig. 3. The
shaded part represents the MASK ﬂag, which indicates that these information is
invisible. When MASKs of the input sequence are removed, Attention of input
sequence becomes bidirectional and Attention of target sequence becomes uni-
directional, Attention map of this uniﬁed language model is shown in the right
of Fig. 3.
P(A, B, C, D, E, F, G, H) = P(A)P(B|A)P(C|A, B) . . .
P(H|A, B, C, D, E, F, G)
(1)
Fig. 3. Attention matrix of unidirectional language model (left) and uniﬁed language
model (right)

Summarization of Judgment Documents
491
Due to the length limit of RoBERTa-wwm, the sum length of input sequence
and target sequence can not exceed 512 words. We segment the initial sum-
marization into sub-paragraphs to retain complete legal information. Each sub-
paragraph is sent into the abstraction model to obtain a corresponding summary.
All the summaries of sub-paragraphs are merged into a ﬁnal summary of the
whole judgment document.
4
Data and Experiment
4.1
Dataset and Evaluation Metric
The experimental data in this paper is available from CAIL20203. It contains
13.5K Chinese judgment documents, labels of sentences and manual summaries.
ROUGE (Recall-Oriented Understudy for Gisting Evaluation) [16] is a com-
monly used evaluation index of automatic abstracting, which calculates the over-
lap rate of the reference summary and the model-generated summary. In this
paper, the ﬁnal summary is evaluated by ROUGE-1, ROUGE-2, ROUGE-L.
ROUGE-N measures the N-gram overlap rate between reference summary
and generated summary. ROUGE-1 measures the matching of unigram. ROUGE-
2 measures the matching of bigram. ROUGE-L measures the proportion of
longest common subsequence between the reference summary and generated
summary.
We take the F1 value of ROUGE to balance precision and recall. The calcu-
lation of F1 is computed as Eq. (2), where P denotes precision, R denotes recall.
Weights [0.2, 0.4, 0.4] are set for the three indicators to get an overall ROUGE
score, as shown in (3), to evaluate in a more objective way.
F1 = 2 ∗P(ROUGE) ∗R(ROUGE)
P(ROUGE) + R(ROUGE)
(2)
ROUGE = 0.2 ∗F1(ROUGE −1) + 0.4 ∗
F1(ROUGE −2) + 0.4 ∗F1(ROUGE −L)
(3)
4.2
Result
In this section, the proposed model is compared internally to reﬂect the eﬀect
of each part. We compare the results of the extraction model, the abstraction
model, extraction + abstraction without segmentation (E+A) and the complete
model, as shown in Table 1. We can see that the extraction model achieves the
highest recall but a poor precision, which leads to a low F1. The abstraction
model and Extraction & abstraction (without segmentation) get better preci-
sions but much lower recalls than the extraction model. This is because of the
length limit of the abstraction model, summaries of judgment documents suﬀer
3 http://cail.cipsc.org.cn/.

492
Y. Gao et al.
from a serious legal information loss, such as the fact and reasons, judgment basis
and judgment result. The complete model reaches the highest F1. It retains most
of the important legal information, segments and sends them into the abstrac-
tion model, so it gets an high F1 and is closer to a manual summary of judgment
document.
Table 1. The ROUGE scores of each part in our model in test set
Part
ROUGE-1(%)
ROUGE-2(%)
ROUGE-L(%)
ROUGE(%)
P
R
F1
P
R
F1
P
R
F1
P
R
F1
Extract
33.65
83.14 46.56
24.70
60.47 34.08
30.49
75.13 42.16
28.80
70.87 39.81
Abstract
47.01
30.79
36.95
19.30
12.89
15.34
36.23
23.84
28.54
31.61
20.85
24.94
E+A
60.01 43.23
49.86
37.92
27.66
31.70
50.08 36.36
41.78
47.20
34.25
39.36
Our Model 57.95
65.84
60.09 41.29 46.59
42.61 49.55
56.05
51.20 47.93 54.22
49.54
The proposed model is also compared to other summary models as shown
in Table 2, our Extractive-Abstractive summary model reaches the highest pre-
cision and F1, keeping the recall staying a good level. LEAD4, the baseline of
CAIL2020, reﬂects the level in which the most basic summary method—snippet
selection can achieve for judgment documents. TextCNN has the best recall of
ROUGE, which indicates that it extracts more complete legal information. How-
ever, TextCNN and other summary models have a common problem that the
precision of ROUGE is unsatisfactory. This indicates that the generated sum-
maries contain a lot of useless information, and are not satisfactorily reﬁning.
TextRank, as a sorting model, is comparable to other neural network models,
because we give higher scores to the legal information in this model to make it
more suitable for judgment documents.
Table 2. The ROUGE scores of summary models in test set
Model
ROUGE-1(%)
ROUGE-2(%)
ROUGE-L(%)
ROUGE(%)
P
R
F1
P
R
F1
P
R
F1
P
R
F1
LEAD
40.02
20.62
26.01
20.69
10.15
13.02
31.54
15.83
20.16
28.90
14.51
18.47
TextRank [17] 38.93
63.34
47.28
25.56
41.62
31.05
33.17
53.94
40.28
31.28
50.89
37.99
FastText [18]
36.32
74.16
47.16
25.07
50.92
32.49
31.49
64.29
40.90
29.89
60.92
38.79
TextCNN [19] 35.47
79.33 47.55
25.39
56.32 33.96
31.49
70.41 42.23
29.84
66.56 39.99
TextRNN [20] 35.79
71.72
45.90
24.23
48.37
31.03
30.44
61.07
39.06
29.02
58.12
37.22
Our Model
57.95 65.84
60.09 41.29 46.59
42.61 49.55 56.05
51.20 47.93 54.22
49.54
The statistical results of the model are shown in Fig. 4. It can be seen that
the summarization of judgment documents has a high compression ratio.
4 https://github.com/china-ai-law-challenge/CAIL2020/tree/master/sfzy/baseline.

Summarization of Judgment Documents
493
Fig. 4. The length distribution histogram of judgment documents (left), initial sum-
maries (middle) and ﬁnal summaries (right).
5
Conclusion and Future Work
In this paper, an Extractive-Abstractive summary model for the Chinese judg-
ment documents is proposed. Compared with the existing summary algorithm,
the proposed model contains a key sentence extraction model based on the Self-
Attention mechanism and a summary abstraction model based on the attention
mask mechanism. Such a model could improve the eﬃciency in case handling and
make judgment documents more accessible to the general readers. The experi-
mental results show that the summary generated by our model is more similar
to manual summary than other models.
In the future research, we plan to build a knowledge graph based on pub-
lic judgment documents and integrate more external legal knowledge into our
model. To utilize more advanced models, we intend to pre-train a judicial lan-
guage model with publicly available data and apply it to more legal language
processing tasks.
Acknowledgements. This work is supported by The National Social Science Foun-
dation Project of China (No.20BFX077) and National Natural Science Foundation of
China (No.61502537).
References
1. Rissland, E.L., Ashley, K.D., Loui, R.P.: Ai and law: a fruitful synergy. Artif. Intell.
150(1–2), 1–15 (2003)
2. Bench-Capon, T., et al.: A history of AI and law in 50 papers: 25 years of the
international conference on AI and law. Artif. Intell. Law 20(3), 215–319 (2012)
3. Surden, H.: Artiﬁcial intelligence and law: an overview. Ga. St. UL Rev. 35, 1305
(2018)
4. K˚ageb¨ack, M., Mogren, O., Tahmasebi, N., Dubhashi, D.: Extractive summariza-
tion using continuous vector space models. In: Proceedings of the 2nd Workshop on
Continuous Vector Space Models and their Compositionality (CVSC), pp. 31–39
(2014)
5. Cao, Z., Wei, F., Li, S., Li, W., Zhou, M., Wang, H.: Learning summary prior
representation for extractive summarization. In: Proceedings of the 53rd Annual
Meeting of the Association for Computational Linguistics and the 7th International
Joint Conference on Natural Language Processing (Volume 2: Short Papers), pp.
829–833 (2015)

494
Y. Gao et al.
6. Cheng, J., Lapata, M.: Neural summarization by extracting sentences and words.
In: Proceedings of the 54th Annual Meeting of the Association for Computational
Linguistics (Volume 1: Long Papers), pp. 484–494 (2016)
7. Hochreiter, S., Schmidhuber, J.: Long short-term memory. Neural Comput. 9(8),
1735–1780 (1997)
8. Rush, A.M., Chopra, S., Weston, J.: A neural attention model for abstractive
sentence summarization. In: EMNLP (2015)
9. Chopra, S., Auli, M., Rush, A.M.: Abstractive sentence summarization with atten-
tive recurrent neural networks. In: Proceedings of the 2016 Conference of the North
American Chapter of the Association for Computational Linguistics: Human Lan-
guage Technologies, pp. 93–98 (2016)
10. Vaswani, A., et al.: Attention is all you need. In: NIPS (2017)
11. Sutskever, I., Vinyals, O., Le, Q.V.: Sequence to sequence learning with neural
networks. In: Advances in Neural Information Processing Systems (2014)
12. Devlin, J., Chang, M.W., Lee, K., Toutanova, K.: BERT: pre-training of deep
bidirectional transformers for language understanding. In: Proceedings of the 2019
Conference of the North American Chapter of the Association for Computational
Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers),
pp. 4171–4186 (2019)
13. Song, K., Tan, X., Qin, T., Lu, J., Liu, T.Y.: Mass: masked sequence to sequence
pre-training for language generation. In: International Conference on Machine
Learning, pp. 5926–5936. PMLR (2019)
14. Dong, L., et al.: Uniﬁed language model pre-training for natural language under-
standing and generation. In: Proceedings of the 33rd International Conference on
Neural Information Processing Systems, pp. 13063–13075 (2019)
15. Su, J.: From language models to seq2seq: Transformer and mask (2019). https://
kexue.fm/archives/6933
16. Lin, C.Y.: Rouge: a package for automatic evaluation of summaries. In: Text sum-
marization branches out, pp. 74–81 (2004)
17. Mihalcea, R., Tarau, P.: Textrank: bringing order into text. In: Proceedings of
the 2004 Conference on Empirical Methods in Natural Language Processing, pp.
404–411 (2004)
18. Joulin, A., Grave, ´E., Bojanowski, P., Mikolov, T.: Bag of tricks for eﬃcient text
classiﬁcation. In: Proceedings of the 15th Conference of the European Chapter
of the Association for Computational Linguistics: Volume 2, Short Papers, pp.
427–431 (2017)
19. Kim, Y.: Convolutional neural networks for sentence classiﬁcation. arXiv preprint
arXiv:1408.5882 (2014)
20. Liu, P., Qiu, X., Huang, X.: Recurrent neural network for text classiﬁcation with
multi-task learning. In: Proceedings of the Twenty-Fifth International Joint Con-
ference on Artiﬁcial Intelligence, pp. 2873–2879 (2016)

A Framework for Intuitionistic Grammar
Logics
Tim S. Lyon(B)
Computational Logic Group, Institute of Artiﬁcial Intelligence,
Technische Universit¨at Dresden, Dresden, Germany
timothy stephen.lyon@tu-dresden.de
Abstract. We generalize intuitionistic tense logics to the multi-modal
case by placing grammar logics on an intuitionistic footing. We provide
axiomatizations for a class of base intuitionistic grammar logics as well
as provide axiomatizations for extensions with combinations of seriality
axioms and what we call intuitionistic path axioms. We show that each
axiomatization is sound and complete with completeness being shown
via a typical canonical model construction.
Keywords: Bi-relational model · Completeness · Context-free ·
Converse · Grammar logic · Intuitionistic logic · Modal logic · Path
axiom
1
Introduction
Having been introduced in 1988 by Fari˜nas del Cerro and Penttonen [5], grammar
logics form a prominent class of normal, multi-modal logics that extend classical
propositional logic with a set of modalities indexed by characters from an alpha-
bet. Such logics obtain their name due to the incorporation of axioms which can
be viewed as production rules in a context-free grammar, and which generate
sequences of edges (which can be viewed as words) in a relational model. More
signiﬁcantly however, the class of grammar logics includes many well-known log-
ics that have practical value in computer science; e.g. description logics [17],
epistemic logics [11], information logics [27], temporal logics [4], and standard
modal logics (e.g. K, S4, and S5) [8].
Another logical paradigm that is useful within computer science is that of
constructive reasoning (e.g. [18,22]), that is, reasoning where the claimed exis-
tence of an object implies its constructibility [3]. One of the most renowned logics
for formalizing constructive reasoning is intuitionistic logic, which employs a ver-
sion of implication that is stronger than its classical counterpart. Resting on the
philosophical work of L.E.J. Brouwer, propositional intuitionistic logic was pro-
vided axiomatizations in the early 20th century by Kolmogorov [19], Orlov [21],
and Glivenko [15], with a ﬁrst-order axiomatization given by Heyting [16].
Work supported by the European Research Council (ERC) Consolidator Grant 771779
(DeciGUT).
c
⃝Springer Nature Switzerland AG 2021
P. Baroni et al. (Eds.): CLAR 2021, LNAI 13040, pp. 495–503, 2021.
https://doi.org/10.1007/978-3-030-89391-0_29

496
T. S. Lyon
The interest in modal and intuitionistic logics naturally gave rise to com-
binations of the two, thus giving birth to the paradigm of intuitionistic modal
logics. A diverse set of intuitionistic modal logics have been proposed in the lit-
erature [1,2,9,13,14,24,25], though the class of logics introduced by Plotkin and
Stirling [24] has become (most notably through the work of Simpson [25]) one of
the most popular formulations. In the same year that Plotkin and Stirling [24]
introduced their intuitionistic modal logics, Ewald introduced intuitionistic tense
logic [10], which not only includes modalities that make reference to the future
in a relational model (♦and □), but also includes modalities that make reference
to the past (♦and ■). As with (multi-)modal and intuitionistic logics, intuition-
istic modal logics have proven useful in computer science; e.g. such logics have
been used to design veriﬁcation techniques [12], in reasoning about functional
programs [23], and in the deﬁnition of programming languages [7].
Due to the practical import of the aforementioned logics, it seems both natu-
ral and worthwhile to formulate intuitionistic versions of grammar logics. Hence,
the main goal of this paper will be to axiomatize intuitionistic context-free gram-
mar logics with converses, thus generalizing the work of [5,10,24]. In the following
section (Sect. 2), we axiomatize and provide a semantics for intuitionistic gram-
mar logics. Afterward (in Sect. 3), we prove the soundness and completeness of
our logics, with completeness being shown on the basis of a standard canonical
model construction (adapting techniques provided in [10]). In the ﬁnal section
(Sect. 4), we brieﬂy conclude and discuss future work.
2
Intuitionistic Grammar Logics
We deﬁne our languages for intuitionistic grammar logics relative to an alpha-
bet Σ consisting of a non-empty countable set of characters, which will be
used to index modalities. Following [8], we stipulate that each alphabet Σ
can be partitioned into a forward part Σ+ := {a, b, c, . . .} and a backward part
Σ−:= {a, b, c, . . .} such that each part has the same cardinality and the follow-
ing is satisﬁed:
Σ := Σ+ ∪Σ−where Σ+ ∩Σ−= ∅and a ∈Σ+iﬀa ∈Σ−
We use a, b, c, . . . . (possibly annotated) to denote the forward characters con-
tained in the forward part Σ+, and a, b, c, . . . . (possibly annotated) to denote
the backward characters contained in the backward part Σ−. Both forward and
backward characters are referred to as characters more generally, and we use x, y,
z, . . . . (possibly annotated) to denote them. Intuitively, modalities indexed with
forward characters make reference to future states within a relational model, and
modalities indexed with backward characters make reference to past states. The
converse operation · is deﬁned to be a function mapping each forward character
a ∈Σ+ to its converse a ∈Σ−and vice versa; hence, the converse operation is
its own inverse, i.e. for any x ∈Σ, x = x.
Each of our languages includes propositional atoms from the denumerable
set Φ := {p, q, r, . . .}. Each language L(Σ) is deﬁned via the following grammar
in BNF:

A Framework for Intuitionistic Grammar Logics
497
A ::= p | ⊥| A ∨A | A ∧A | A ⊃A | ⟨x⟩A | [x]A
where p ranges over the set of propositional atoms Φ and x ranges over the alpha-
bet Σ. We use A, B, C, . . . . to range over formulae in L(Σ), deﬁne ∼A:=A ⊃⊥,
and deﬁne A ⊃⊂B := (A ⊃B)∧(B ⊃A). We interpret formulae on bi-relational
Σ-models, which are inspired by the models for intuitionistic modal and tense
logics presented in [2,9,10,24]:
Deﬁnition 1 (Bi-relational Σ-Model). We deﬁne a bi-relational Σ-model to
be a tuple M = (W, ≤, {Rx | x ∈Σ}, V ) such that:
– W is a non-empty set of worlds {w, u, v, . . .};
– The intuitionistic relation ≤⊆W × W is a preorder, i.e. it is reﬂexive and
transitive;
– The accessibility relation Rx ⊆W × W satisﬁes:
(F1) For all w, v, v′ ∈W, if wRxv and v ≤v′, then there exists a w′ ∈W
such that w ≤w′ and w′Rxv′;
(F2) For all w, w′, v ∈W, if w ≤w′ and wRxv, then there exists a v′ ∈W
such that w′Rxv′ and v ≤v′;
(F3) wRxu iﬀuRxw;
– V : W →2Φ is a valuation function satisfying the monotonicity condition:
for each w, u ∈W, if w ≤u, then V (w) ⊆V (u).
The (F1) and (F2) conditions ensure the monotonicity of complex formulae
(see Lemma 1) in our models, which is a property characteristic of intuitionistic
logics.1 We note that we interpret accessibility relations indexed with forward
characters as relating worlds to future worlds, and accessibility relations indexed
with backward characters as relating worlds to past worlds. Such an interpreta-
tion shows that our models have a tense character, and additionally, shows that
our logics generalize the intuitionistic tense logics of [10].
We interpret formulae from L(Σ) over bi-relational models via the following
clauses.
Deﬁnition 2 (Semantic Clauses).
Let M be a bi-relational Σ-model with
w ∈W. The satisfaction relation M, w ⊩Σ A between w ∈W of M and a
formula A ∈L(Σ) is inductively deﬁned as follows:
– M, w ⊩Σ p iﬀp ∈V (w), for p ∈Φ;
– M, w ̸⊩Σ ⊥;
– M, w ⊩Σ A ∨B iﬀM, w ⊩Σ A or M, w ⊩Σ B;
– M, w ⊩Σ A ∧B iﬀM, w ⊩Σ A and M, w ⊩Σ B;
– M, w ⊩Σ A ⊃B iﬀfor all w′ ∈W, if w ≤w′ and M, w′ ⊩Σ A, then
M, w′ ⊩Σ B;
– M, w ⊩Σ ⟨x⟩A iﬀthere exists a v ∈W such that wRxv and M, v ⊩Σ A;
– M, w ⊩Σ [x]A iﬀfor all w′, v′ ∈W, if w ≤w′ and w′Rxv′, then M, v′ ⊩Σ A.
1 For a discussion of these conditions and their encompassing literature, see [25, Ch. 3].

498
T. S. Lyon
Lemma 1. Let M be a bi-relational Σ-model with w, u ∈W of M. If w ≤u
and M, w ⊩Σ A, then M, u ⊩Σ A.
Proof. By induction on the complexity of A.
⊓⊔
As will be shown in the subsequent section, given an alphabet Σ, the set of
formulae valid with respect to the class of bi-relational Σ-models is axiomatiz-
able. We refer to the axiomatization as HIKm(Σ) (with H denoting the fact that
the axiomatization is a Hilbert calculus), and call the corresponding logic that
it generates IKm(Σ). We note that IKm(Σ) is taken to be the base intuitionistic
grammar logic relative to Σ; below, we will also consider extensions of IKm(Σ)
by extending its axiomatization with common modal axioms.
Deﬁnition 3 (Axiomatization). We deﬁne our axiomatization HIKm(Σ)
below, where we have an axiom and inference rule for each x ∈Σ.
A0 Any axiomatization for intuitionis-
tic propositional logic
A1 [x](A ⊃B) ⊃([x]A ⊃[x]B)
A2 [x](A ∧B) ⊃⊂([x]A ∧[x]B)
A3 ⟨x⟩(A ∨B) ⊃⊂(⟨x⟩A ∨⟨x⟩B)
A4 [x](A ⊃B) ⊃(⟨x⟩A ⊃⟨x⟩B)
A5 [x]A ∧⟨x⟩B ⊃⟨x⟩(A ∧B)
A6 ∼⟨x⟩⊥
A7 (A ⊃[x]⟨x⟩A) ∧(⟨x⟩[x]A ⊃A)
A8 (⟨x⟩A ⊃[x]B) ⊃[x](A ⊃B)
A9 ⟨x⟩(A ⊃B) ⊃([x]A ⊃⟨x⟩B)
R1
A
[x]A(nec)
We deﬁne the logic IKm(Σ) to be the smallest set of formulae from L(Σ)
closed under substitutions of the axioms and applications of the inference rules.
A formula A is deﬁned to be a theorem of IKm(Σ) iﬀA ∈IKm(Σ).
We also consider logics that are extensions of IKm(Σ) with sets A of the
following axioms.
Dx : [x]A ⊃⟨x⟩A
IPA : (⟨x1⟩· · · ⟨xn⟩A ⊃⟨x⟩A) ∧([x]A ⊃[x1] · · · [xn]A)
We refer to axioms of the form shown above left as seriality axioms, and axioms
of the form shown above right as intuitionistic path axioms (IPAs). We use A to
denote any arbitrary collection of axioms of the above forms. Moreover, we note
that the collection of IPAs includes multi-modal variants of standard axioms
such as Tx, Bx, 4x, and 5x, which are shown below.
Tx : (A ⊃⟨x⟩A) ∧([x]A ⊃A)
4x : (⟨x⟩⟨x⟩A ⊃⟨x⟩A) ∧([x]A ⊃[x][x]A)
Bx : (⟨x⟩A ⊃⟨x⟩A) ∧([x]A ⊃[x]A)
5x : (⟨x⟩⟨x⟩A ⊃⟨x⟩A) ∧([x]A ⊃[x][x]A)
In the next section, we show that any extension of HIKm(Σ) with a set A of
axioms is sound and complete relative to a speciﬁed sub-class of the bi-relational
Σ-models. For each axiom we extend HIKm(Σ) with, we impose a frame condition
on our class of bi-relational Σ-models. Axioms and related frame conditions are
displayed in Fig. 1, and extensions of HIKm(Σ) with seriality and IPA axioms,
along with their corresponding models, are deﬁned below.

A Framework for Intuitionistic Grammar Logics
499
Axiom
[x]A ⊃x A
( x1
xn A
x A) ∧([x]A ⊃[x1] · · · [xn]A)
Condition ∀w∃u(wRxu) ∀w0, . . . , wn(w0Rx1w1 ∧· · · ∧wn−1Rxnwn ⊃w0Rxwn)
Fig. 1. Axioms and their related frame conditions. We note that when n = 0, the
related frame condition is taken to be wRxw.
Deﬁnition 4 (Terminology for Extensions). We deﬁne the axiomatization
HIKm(Σ, A) to be HIKm(Σ)∪A, and deﬁne the logic IKm(Σ, A) to be the smallest
set of formulae from L(Σ) closed under substitutions of the axioms and applica-
tions of the inference rules. A formula A is deﬁned to be an IKm(Σ, A)-theorem,
written ⊢Σ
A A, iﬀA ∈IKm(Σ, A), and a formula A is said to be derivable from
a set of formulae A ⊆L(Σ), written A ⊢Σ
A A, iﬀfor some B1, . . . , Bn ∈A ,
⊢Σ
A B1 ∧· · · ∧Bn ⊃A.
Moreover, we deﬁne a bi-relational (Σ, A)-model to be a bi-relational Σ-
model satisfying each frame condition related to an axiom A ∈A. A formula A is
deﬁned to be globally true on a bi-relational (Σ, A)-model M, written M ⊩Σ
A A,
iﬀM, u ⊩Σ A for all worlds u ∈W of M. A formula A is deﬁned to be (Σ, A)-
valid, written ⊩Σ
A A, iﬀA is globally true on every bi-relational (Σ, A)-model.
Last, we say that a set A of formulae semantically implies a formula A, written
A ⊩Σ
A A, iﬀfor all bi-relational (Σ, A)-models M and each w ∈W of M, if
M, w ⊩Σ B for each B ∈A , then M, w ⊩Σ A.
Remark 1. Note that the axiomatization HIKm(Σ) = HIKm(Σ, ∅) and that a bi-
relational (Σ, ∅)-model is a bi-relational Σ-model.
Let us now move on to the next section and prove the soundness and com-
pleteness results for our logics.
3
Soundness and Completeness
In this section, we show that the ⊢Σ
A and ⊩Σ
A relations coincide, that is to say, we
show that each intuitionistic grammar logic IKm(Σ, A) is sound and complete.
As usual, soundness is straightforward to prove:
Theorem 1 (Soundness). If A ⊢Σ
A A, then A ⊩Σ
A A.
Proof. One can prove that if ⊢Σ
A A, then ⊩Σ
A A by showing that each axiom is
valid and each inference rule preserves validity. Then, if we assume that A ⊢Σ
A A,
it follows that for some B1, . . . , Bn ∈A , ⊢Σ
A B1 ∧· · · ∧Bn ⊃A, which further
implies that ⊩Σ
A B1 ∧· · · ∧Bn ⊃A. The last fact permits us to conclude that
A ⊩Σ
A A.
⊓⊔
To establish completeness we combine techniques used for establishing the
completeness of intuitionistic logic [6] and intuitionisitc tense logic [10]. Our
strategy is rather standard and consists of constructing a canonical model where

500
T. S. Lyon
worlds are pairs of the form (A ω, Bω) with A ω and Bω sets of formulae. If one
assumes that A ̸⊢Σ
A A, then one can show that a pair exists in the canonical
model satisfying A , but not A, thus establishing completeness (see Theorem 2
below). We begin by deﬁning two useful notions, viz. the notion of an IKm(Σ, A)-
consistent set and the notion of an IKm(Σ, A)-saturated pair.
Deﬁnition 5 (IKm(Σ, A)-Consistent). We deﬁne a pair of sets of formulae
(A , B) to be IKm(Σ, A)-consistent iﬀfor no ﬁnite subsets A0 ⊆A and B0 ⊆B
we have ⊢Σ
A
 A0 ⊃ B0.
Deﬁnition 6 (IKm(Σ, A)-Saturated).
We
deﬁne
a
pair
(A , B)
to
be
IKm(Σ, A)-saturated iﬀ
1. (A , B) is IKm(Σ, A)-consistent;
2. if A ⊢Σ
A A, then A ∈A ;
3. if A ⊢Σ
A A ∨B, then A ∈A or B ∈A ;
4. A ∩B = ∅;
5. A ∪B = L(Σ).
Lemma 2. Suppose that (A , B) is IKm(Σ, A)-consistent. Then, there exists a
saturated pair (A ω, Bω) such that A ⊆A ω and B ⊆Bω.
Proof. Let us enumerate all disjunctions from L(Σ) where each disjunction
occurs inﬁnitely often: ⟨B0,i ∨B1,i⟩i∈N. We set (A0, B0):=(A , B) and deﬁne
an inﬁnite sequence of pairs as follows: An+1:=An ∪{Bj,n} and Bn+1:=Bn, if
(An∪{Bj,n}, Bn) is IKm(Σ, A)-consistent (and if (An∪{Bj,n}, Bn) is IKm(Σ, A)-
consistent for both j = 0 and j = 1, then we set An+1:=An ∪{B0,n}), and
An+1:=An and Bn+1:=Bn ∪{B0,i, B1,i} otherwise.
Let A ω:= 
i∈N Ai and Bω:= 
i∈N Bi. We now argue that (A ω, Bω) is sat-
urated. It is straightforward to show that for each n, (An, Bn) is IKm(Σ, A)-
consistent and that An ∩Bn = ∅from which the saturation properties 1 and 4
can be deduced (see Deﬁnition 6 above). We note that saturation properties 3
and 5 follow from the above construction procedure, and 2 follows from 3 since
if A ⊢Σ
A A, then A ⊢Σ
A A ∨A (cf. [6, Lemma 5.3.8]).
⊓⊔
Deﬁnition 7. (Canonical Model). We deﬁne the canonical model M C(Σ, A)
:= (W C, ≤C, {RC
x | x ∈Σ}, V C) as shown below, and let w, u ∈W C with
w := (A , B) and u := (A ′, B′).
– W C:={(C , D) | (C , D) is saturated.};
– w ≤C u iﬀA ⊆A ′;
– wRC
x u iﬀ(i) for all A ∈L(Σ), if [x]A ∈A , then A ∈A ′, and (ii) for all
A ∈L(Σ), if A ∈A ′, then ⟨x⟩A ∈A ;
– w ∈V C(p) iﬀp ∈A .
The following two lemmas are proven in an almost identical fashion to
Lemma 3 and 5 of [10].

A Framework for Intuitionistic Grammar Logics
501
Lemma 3. Let w:=(A0, B0) ∈W C. Then, ⟨x⟩A ∈A0 iﬀthere exists a
u:=(A1, B1) ∈W C such that wRC
x u and A ∈A1.
Lemma 4. Let w:=(A0, B0) ∈W C. Then, [x]A ∈A0 iﬀfor each u:=(A1, B1)
and v:=(A2, B2) in W C, if w ≤C u and uRC
x v, then A ∈A2.
Lemma 5. The canonical model M C(Σ, A) is a bi-relational (Σ, A)-model.
Proof. It is straightforward to show that M C is a bi-relational (Σ, A)-model.
The proof that M C satisﬁes properties (F1)–(F3) uses axioms A8, A9, and A7,
respectively (cf. [10]), and the fact that the valuation function V C is monotonic
follows from its deﬁnition and the deﬁnition of ≤C. Below, we show that M C
satisﬁes each frame property associated with an axiom from A.
Dx We show that if the seriality axiom [x]A ⊃⟨x⟩A is included in our axiom-
atization, then Rx is serial. Let w:=(A , B) ∈W C and observe that the
formula [x](p ⊃p) ∈A since if it were in B, w would not be IKm(Σ, A)-
consistent (and hence, not saturated). Therefore, by applying the seriality
axiom Dx, we may conclude that ⟨x⟩(p ⊃p) ∈A , from which it follows
that there exists a u:=(C , D) ∈W C such that wRC
x u by Lemma 3.
IPA We show that if (⟨x1⟩· · · ⟨xn⟩A ⊃⟨x⟩A)∧([x]A ⊃[x1] · · · [xn]A) is included
in our axiomatization, then for any w0, . . . , wn ∈W C, if wiRC
xi+1wi+1 for
each i ∈{0, . . . , n −1}, then w0RC
x wn. Let w0, . . . , wn be arbitrary worlds
in W C and suppose that wiRC
xi+1wi+1 for each i ∈{0, . . . , n −1}. We
aim to show that w0RC
x wn, where w0:=(A0, B0) and wn:=(An, Bn). First,
assume that [x]A ∈A0. Then, by the above axiom, [x1] · · · [xn]A ∈A0, and
by our assumption and the deﬁnition of the RC
x relation, A ∈An. Second,
assume that A ∈An. Then, by our assumption and the deﬁnition of the RC
x
relation, ⟨x1⟩· · · ⟨xn⟩A ∈A0, so by the above axiom, ⟨x⟩A ∈A0. Therefore,
w0RC
x wn.
⊓⊔
Lemma 6 (Truth Lemma). Let w:=(A , B) be saturated. Then, we have
M C(Σ, A), w ⊩Σ A iﬀA ∈A .
Proof. We prove the result by induction on the complexity of A and argue the
∨, ⊃, ⟨x⟩, and [x] cases since the other cases are simple.
B ∨C. M C(Σ, A), w ⊩Σ B ∨C iﬀM C(Σ, A), w ⊩Σ B or M C(Σ, A), w ⊩Σ C
iﬀB ∈A or C ∈A iﬀB ∨C ∈A . We note that the second ‘iﬀ’ follows from
IH an the third follows from the fact that w is saturated (see Deﬁnition 6).
B ⊃C. The right-to-left direction is straightforward, so we show the left-
to-right direction by contraposition. Suppose that B ⊃C ̸∈A . It follows that
A ∪{B} ̸⊢Σ
A C, implying that the pair (A ∪{B}; {C}) is IKm(Σ, A)-consistent,
and so, we may extend it to a saturated pair u:=(C , D). Observe that A ⊆C ,
B ∈C , and C ̸∈C . By the deﬁnition of ≤C and IH, it follows that u ∈
W C with w ≤C u, M C(Σ, A), u ⊩Σ B, and M C(Σ, A), u ̸⊩Σ C, entailing that
M C(Σ, A), w ̸⊩Σ B ⊃C.
⟨x⟩B. The left-to-right direction is straightforward, so we show the right-
to-left direction. Suppose that ⟨x⟩B ∈A . Then, by Lemma 3 we know that

502
T. S. Lyon
there exists a u := (C , D) ∈W C such that wRC
x u and B ∈C . Therefore,
M C(Σ, A), u ⊩Σ B by IH, implying that M C(Σ, A), w ⊩Σ ⟨x⟩B.
[x]B. Follows from Lemma 4 and IH.
⊓⊔
Theorem 2 (Completeness). If A ⊩Σ
A A, then A ⊢Σ
A A.
Proof. Suppose A ̸⊢Σ
A A. Then, (A , {A}) is IKm(Σ, A)-consistent and can be
extended to a saturated pair w:=(A ω, Bω). By Lemma 6, M C, w ⊩Σ B for each
B ∈A ω, but M C, w ̸⊩Σ C for each C ∈Bω. Hence, A ̸⊩Σ
A A.
⊓⊔
4
Conclusion
This paper provided sound and complete axiomatizations for intuitionistic gram-
mar logics. We deﬁned a base intuitionistic grammar logic IKm(Σ), for each
alphabet Σ, and provided axiomatizations for extensions of IKm(Σ) with combi-
nations of seriality axioms and intuitionistic path axioms. In future work, we aim
to provide nested sequent systems in the style of [26] for the logics discussed here
by making use of the structural reﬁnement methodology of [20]. The goal will be
to identify decidable fragments of intuitionistic grammar logics via proof-search.
Moreover, due to the connection between modal logics and description logics, it
could be worthwhile to investigate the use of intuitionistic grammar logics (or
close variants thereof) in knowledge representation.
References
1. Bierman, G.M., de Paiva, V.C.V.: On an intuitionistic modal logic. Stud. Log.: Int.
J. Symb. Log. 65(3), 383–416 (2000). http://www.jstor.org/stable/20016199
2. Boˇzi´c, M., Doˇsen, K.: Models for normal intuitionistic modal logics. Stud. Log.
43(3), 217–245 (1984)
3. Brouwer, L.E.J., Heyting, A.: L.E.J. Brouwer: Collected Works, Volume 1: Phi-
losophy and Foundations of Mathematics. North-Holland Publishing Company,
American Elsevier Publishing Company, New York (1975)
4. del Cerro, L.F.n., Herzig, A.: Modal deduction with applications in epistemic and
temporal logics. In: Gabbay, D.M., Hogger, C.J., Robinson, J.A. (eds.) Handbook
of Logic in Artiﬁcial Intelligence and Logic Programming (Vol. 4): Epistemic and
Temporal Reasoning, pp. 499–594. Oxford University Press Inc., USA (1995)
5. del Cerro, L.F., Penttonen, M.: Grammar logics. Log. Anal. 31(121/122), 123–134
(1988)
6. van Dalen, D.: Logic and Structure. Springer, Heidelberg (2004). https://doi.org/
10.1007/978-3-540-85108-0
7. Davies, R., Pfenning, F.: A modal analysis of staged computation. J. ACM 48(3),
555–604 (2001). https://doi.org/10.1145/382780.382785
8. Demri, S., de Nivelle, H.: Deciding regular grammar logics with converse through
ﬁrst-order logic. J. Log. Lang. Inf. 14(3), 289–329 (2005). https://doi.org/10.1007/
s10849-005-5788-9
9. Doˇsen, K.: Models for stronger normal intuitionistic modal logics. Stud. Log. 44(1),
39–70 (1985)

A Framework for Intuitionistic Grammar Logics
503
10. Ewald, W.B.: Intuitionistic tense and modal logic. J. Symb. Log. 51(1), 166–179
(1986). http://www.jstor.org/stable/2273953
11. Fagin, R., Moses, Y., Halpern, J.Y., Vardi, M.Y.: Reasoning About Knowledge.
MIT Press, Cambridge (1995)
12. Fairtlough, M., Mendler, M.: An intuitionistic modal logic with applications to
the formal veriﬁcation of hardware. In: Pacholski, L., Tiuryn, J. (eds.) CSL 1994.
LNCS, vol. 933, pp. 354–368. Springer, Heidelberg (1995). https://doi.org/10.1007/
BFb0022268
13. Fischer Servi, G.: Axiomatizations for some intuitionistic modal logics. Rend. Sem.
Mat. Univers. Politecn. Torino 42(3), 179–194 (1984)
14. Fitch, F.B.: Intuitionistic modal logic with quantiﬁers. Portugaliae Math. 7(2),
113–118 (1948). http://eudml.org/doc/114664
15. Glivenko, V.: Sur quelques points de la logique de m. brouwer. Bull. Classe Sci.
15(5), 183–188 (1929)
16. Heyting, A.: Die formalen regeln der intuitionistischen logik. Sitzungsbericht
PreuBische Akad. Wissenschaften Berlin Phys.-Math. Klasse II, 42–56 (1930)
17. Horrocks, I., Sattler, U.: Decidability of SHIQ with complex role inclusion axioms.
Artif. Intell. 160(1–2), 79–104 (2004)
18. Howard, W.A.: The formulae-as-types notion of construction. To HB Curry: Essays
Combin. Log. Lambda Calculus Formalism 44, 479–490 (1980)
19. Kolmogorov, A.: On the principle of tertium non datur. Math. ussr sbornik 32,
646–667 (1925). In: Van Heijenoort, J. (ed.) From Frege to G¨odel: a source book
in mathematical logic, 1879–1931, vol. 9. Harvard University Press (1967)
20. Lyon, T.: Reﬁning labelled systems for modal and constructive logics with appli-
cations. Ph.D. thesis, Technische Universit¨at Wien (2021)
21. Orlov, I.E.: The calculus of compatibility of propositions. Mathe. USSR Sbornik
35, 263–286 (1928)
22. Osorio, M., Navarro, J.A., Arrazola, J.: Applications of intuitionistic logic in answer
set programming. Theory Pract. Log. Program. 4(3), 325–354 (2004). https://doi.
org/10.1017/S1471068403001881
23. Pitts, A.M.: Evaluation logic. In: Birtwistle, G. (ed.) IV Higher Order Workshop,
Banﬀ1990, pp. 162–189. Springer, London (1991). https://doi.org/10.1007/978-1-
4471-3182-3 11
24. Plotkin, G., Stirling, C.: A framework for intuitionistic modal logics: extended
abstract. In: Proceedings of the 1986 Conference on Theoretical Aspects of Rea-
soning about Knowledge, TARK 1986, pp. 399–406. Morgan Kaufmann Publishers
Inc., San Francisco (1986)
25. Simpson, A.K.: The proof theory and semantics of intuitionistic modal logic. Ph.D.
thesis, University of Edinburgh. College of Science and Engineering. School of
Informatics (1994)
26. Straßburger, L.: Cut elimination in nested sequents for intuitionistic modal logics.
In: Pfenning, F. (ed.) FoSSaCS 2013. LNCS, vol. 7794, pp. 209–224. Springer,
Heidelberg (2013). https://doi.org/10.1007/978-3-642-37075-5 14
27. Vakarelov, D.: Abstract characterization of some knowledge representation systems
and the logic nil of nondeterministic information. In: Jorrand, P., Sgurev, V. (eds.)
Artiﬁcial Intelligence II, pp. 255–260. North-Holland, Amsterdam (1987)

Choosing a Logic to Represent
the Semantics of Natural Language
Adam Pease(B)
Articulate Software, San Jose, CA, USA
apease@articulatesoftware.com
Abstract. We attempt to answer the question of which kind of logical
language should be chosen to represent the semantics of a broad selec-
tion of natural language sentences, and how prevalent diﬀerent kinds
of sentences are that require diﬀerent levels of logical expressiveness.
We examine these requirements for representing the semantics of text
in logic by studying a sample of several balanced corpora. Our method
is to create lists of words and sentential constructs that can easily be
assessed in text, which are then mapped to requirements for logics of
diﬀerent expressiveness. We then run an automated analysis on thou-
sands of sentences from two English corpora and manually validate a
sample.
1
Introduction
Work in linguistic semantics has often employed logics that are quite expressive,
exceeding that of ﬁrst order logic, typically employing various modal operators
[4,8,10]. Work in computer science, particularly in industrial applications, often
employs languages of lesser expressiveness, informal approaches such as knowl-
edge graphs [15], or the description logic [1] used in semantic web languages
and tools. Implicit in these uses is that the logic employed is suﬃcient for the
task at hand. Tools are often chosen based on some combination of an assess-
ment of prevalence and ease of use. When logics are used to represent a wide
domain of knowledge, or used to capture knowledge from a variety of textual
sources, it would be beneﬁcial to have quantitative metrics that would indicate
the proportion of statements that are expressible in a variety of logics.
There is no system that can automatically convert arbitrary text into an
expressive logic, and even human coders will have diﬀerent interpretations of
text, which may, at times, result in statements that require a diﬀerent logic.
However, we can attempt a ﬁrst exploration in this area, with the hope that this
will lead to further studies.
Our approach is to start with looking at particular words that typically
require particular logics to capture the semantics of sentences in which they
appear. We then collect statistics on those words in diﬀerent corpora. Lastly,
we take a small sample of expressive sentences from a corpus and encode them
manually, in order to validate whether the word lists are in fact indicative of the
logical constructs we believe are required.
c
⃝Springer Nature Switzerland AG 2021
P. Baroni et al. (Eds.): CLAR 2021, LNAI 13040, pp. 504–512, 2021.
https://doi.org/10.1007/978-3-030-89391-0_30

Choosing a Logic to Represent the Semantics of Natural Language
505
While many researchers such as [9] have shown examples where linguistic
semantics requires expressive logics, to date there has not been an automated
quantitative experiment to determine how prevalent such sentences are in large
and balanced linguistic corpora. That is what that paper attempts to address.
2
Diﬀerent Logics
We will only consider a few broad categories or kinds of logics rather than exhaus-
tively considering many specialized logics or variants within these categories. We
attempt to show that those categories can be determined from particular words
and simple syntactic constructs. We will also assume that we must go beyond a
propositional representation. Propositional logic does not allow for use of vari-
ables. While it is often possible to create an abstraction of a single sentence that
is propositional, once we have a text with multiple sentences, we assume that it
will rarely be possible to avoid some need for variables. This will hopefully be
clear once we provide example formalizations of some sample sentences.
Logics less expressive than ﬁrst order logic have only restricted forms of nega-
tion and quantiﬁcation, such as the atomic negation in standard (AL) descrip-
tion logic, so words that lead to these logical features will be the ﬁrst test for
expressiveness.
Beyond standard ﬁrst-order (barring a special purpose encoding of a ﬁrst-
order modal logic, which we will consider equivalent) are constructs that require
a notion of necessity or possibility, as in the S1-S5 families of modal logics [6]. We
will attempt to verify this assertion by showing that in our sample, few examples
avoid quantiﬁcation over formulas.
A next level of expressiveness is that of epistemics and authorship expres-
sions, which attribute a text to a particular person.
Note that for each of these logical features, we need not have 100% accuracy
in our analysis. It is acceptable to have words missing for each feature, as we
aim simply to have a conservative estimate of expressiveness required. If we
fail to identify logically expressive sentences that will simply lead to a more
conservative assessment. We do however need to be careful about false positives
and a manual coding of the identiﬁed expressive sentences should help to provide
conﬁdence in that regard.
3
Computation and Lexical Semantics
We employ the Suggested Upper Merged Ontology (SUMO) [11]1 and its asso-
ciated SUO-KIF [12] language due to its large size (roughly 20,000 terms and
80,000 human-authored logical axioms) and expressive representation in a higher
order logic. Its use in modern theorem provers allows the theory and extensions
to be tested and employed in practical reasoning [2,13,14]. By choosing a more
expressive logic we can use a single language and less expressive formulas will
1 http://www.ontologyportal.org.

506
A. Pease
simply not take advantage of the full expressiveness of the language. We can also
anchor our terms to an existing deﬁned set of terms in the ontology, and not
have to use symbols that have an imagined or intended meaning as opposed to a
formal and logically speciﬁed one. We can also avoid the impractical alternative
of having to deﬁne all the symbols used from scratch.
Brieﬂy, in order to interpret the formulas below, SUO-KIF is a preﬁx notation
in a standard Lisp S-expression syntax, where only the seven logical operators
(“forall”, “exists”, “=>”, “and”, “or”, “not”, “<=>”) plus equality (“=”) are
reseved words in the language, and all other symbols must be deﬁned in SUMO
in terms of those operators. Universal quantiﬁcation is implicit for unquantiﬁed
variables. Variables are denoted by a leading ‘?’ sign. In this paper we will
highlight terms from SUMO given in the text in typewriter font.
4
Word Lists
We rely on the Stanford CoreNLP system [7] to identify negation. It is a machine
learning based system that was trained on a large set of manually-labeled sen-
tences. To indicate quantiﬁers we select the words “some”, “many”, “few”, “all”.
We will assess sentences with negation or quantiﬁers as requiring ﬁrst order logic.
For modal expressions we chose a list of “can”, “could”, “may”, “might”,
“must”, “shall”, “should” and “would”. Some other modals, which appear to be
less reliable indicators are “ought”, “dare”, and “need”.
Finally, we have words that indicate statements of knowledge or belief, which
we can broadly call epistemic operators. These include “know”, “think”, “learn”,
“understand”, “perceive”, “feel”, “guess”, “recognize”, “notice”, “want”, “wish”,
“hope”, “decide”, “expect”, “prefer”, “remember”, “forget”, “imagine”, and
“believe”. Statements of authorship would require a diﬀerent operator that takes
a formula as an argument, but have the same requirement for logical expressive-
ness as epistemics. They are “say”, and “write”.
5
Experiment
We wrote a simple open source program in Java2 that calls the Stanford
CoreNLP system to do sentence segmentation, tokenization, lemmatization and
dependency parsing as steps to enable this analysis. Those functions enable Stan-
ford’s negation detection component as well as checking for the presence of words
in our various word lists. We only count a sentence as being in one particular
category even if it has multiple kinds of operators. Execution time is dominated
by negation detection because of its upstream reliance on dependency parsing,
but is still relatively fast, completing analysis of the Brown corpus [5] in just a
few minutes on a modern laptop computer. Our results for the Brown Corpus
are shown in Table 1.
2 https://github.com/ontologyportal/sigmanlp/blob/master/src/main/java/com/arti
culate/nlp/corpora/LogicLevel.java.

Choosing a Logic to Represent the Semantics of Natural Language
507
In addition, since we are not primarily concerned with works of ﬁction in
commercial applications, we chose a comparably sized portion of the newspaper
collection from the Corpus of Contemporary American English [3]. Running on
just the year 2012 we get comparable results to the Brown corpus tests, which
seem to indicate that these logical features are broadly no more or less prevalent
in news than in a balanced corpus that includes works of ﬁction, poetry and spo-
ken text transcripts. These results are shown in Table 2. Note that percentages
are rounded and so do not add up to 100%. Note also that the spacing in the
examples reﬂects tokenizing, where tokens such as in “ca n’t” are separated by
a space.
Table 1. Brown Corpus statistics
Type of operator Count %
Negation
419
10.00%
Epistemic
243
6.00%
Modal
666
16.00%
Other modal
27
0.66%
Quantiﬁer
177
4.30%
Authorship
196
4.80%
Simple
2304
57.00%
Total
4032
Table 2. COCA 2012 News statistics
Type of operator Count %
Negation
513
13.00%
Epistemic
328
8.60%
Modal
369
9.70%
Other modal
27
0.71%
Quantiﬁer
223
5.90%
Authorship
416
11.00%
Simple
1897
50.00%
Total
3773
6
Experiment Validation
We next selected a random sample of 100 sentences, using Java’s Random class,
that were marked by our automated analysis as not “simple” and attempted to
formalize them manually in an expressive logic. Note that we are simply inter-
ested in a “upper bound” of how many sentences do not require expressive logics,

508
A. Pease
so we do not need to perform a manual formalization of any of the sentences
in the category of “simple”, since if a simple sentence required an expressive
formalization that would only decrease the upper bound.
Even in the case of a balanced corpus like the Brown Corpus that includes
ﬁction and poetry, only 57% of sentences are “simple” and without negation,
modals, authorship or epistemics. This is also likely to be conservative since we
do not consider constructs such as metaphors, some of which can require complex
logical representations without the explicit keywords that we have measured.
The ﬁrst randomly selected sentence (from corpus line 45437) marked as
being a statement of “authorship” was
“It’s just a waste of resources, if you ask me,” she said.
We coded the statement in the SUO-KIF logical language, using terms from
SUMO. No new terms were needed for this encoding. The interested reader can
look at the deﬁnitions of these terms by entering them in the online browser3.
The formalization can be paraphrased as “There is a speaking event, where the
agent of the event says that there’s an diﬀerent event that uses a resource, which
does not beneﬁt anyone.”
There are many possible encodings of this statement, and no doubt many that
could be considered “deeper” by explicitly modeling a notion of waste rather than
just an absence of beneﬁt, or the implications of politeness or modesty of the
phrase “...if you ask me...” But the essential feature relevant to this experiment,
which would still be present in other options for formalization, is that the speech
has some logical content and stating that content as an explicit logical formula, as
opposed to a logically opaque term or proposition, requires logical expressiveness
beyond ﬁrst order logic. The relation in this case is containsFormula, which
relates a Physical thing (which is a class that includes any thing positioned in
space and time, and therefore includes Processes) and a Formula.
(exists (?S ?SAY)
(and
(instance ?SAY Speaking)
(agent ?SAY ?SHE)
(containsFormula ?SAY
(exists (?IT ?R)
(and
(resource ?IT ?R)
(not
(exists (?P)
(benefits ?IT ?P))))))))
3 https://sigma.ontologyportal.org:8443/sigma/Browse.jsp?kb=SUMO&lang=Englis
hLanguage&ﬂang=SUO-KIF&term=Speaking.

Choosing a Logic to Represent the Semantics of Natural Language
509
Statements about propositions are so common that even when one is found
there are usually more in the same sentence that aren’t signalled by simple
keywords, as in
Ministers were exploring several options to close that gap, but as talks
dragged on Monday, no ﬁnal solution appeared imminent .
which was marked as a negation (“...no ﬁnal solution...”) but where appeared
and imminent also state relationships (epistemic and temporal, respectively) to
a proposition (that a ﬁnal agreement will be achieved in the negotiation) that
require a higher-order logic.
We now present some of a set of randomly chosen sentences from the COCA
2012 news corpus (ﬁle wlp news 2012.txt) the ﬁrst few along with their formal-
ization in SUO-KIF/SUMO. The line number of the corpus is given and then a
keyword for how it was classiﬁed on the basis of the diﬀerent word lists given
in the body of the paper. There were two sentences out of our random sample
of 100 with critical elisions and two that do not require an expressive logic. The
two sentences in our sample of 100 that one could argue have been misclassiﬁed
are
(corpus line 6504) epistemic: The testing, to be carried out over the next
several weeks, marks a signiﬁcant expansion of the agency ’s probe in
Dimock, a tiny crossroads at the center of a national debate over gas
drilling and the extraction technique known as hydraulic fracturing, or
fracking.
“...known...” in this case is not an epistemic but just an expression of syn-
onymy. If we create a class of Fracking one could have a simple relation of
“communicationAbout” that would relate a communication event “...debate...”
and a class representing a topic, so it’s possible this could be done in a description
logic.
(corpus line 6431) neg: I ca n’t even tell you, again, what a relief this is.
Read literally, “...can’t tell...” is a negation but it isn’t since later in the
sentence the speaker does tell the listener what he or she wants to say, that [it]
is a “relief”. It’s just a politeness construct. If the referent of “it” is a complex
statement that would have to be modeled as a formula, then this is HOL. But
if it’s just an event, then it could be represented in FOL or even DL
Five sentences of the 100 were fully formalized in SUO-KIF/SUMO - corpus
line numbers 65640, 9632, 77220, 70553 and 53967.
Note that one additional sentence (corpus line 45437) is formalized in the
text above.

510
A. Pease
(corpus line 65640) neg: Ministers were exploring several options to close
that gap, but as talks dragged on Monday, no ﬁnal solution appeared
imminent.
(exists (?M1 ?M2 ?N ?M)
(and
(attribute ?M1 GovernmentPerson)
(attribute ?M2 GovernmentPerson)
(not
(equal ?M1 ?M2))
(instance ?M Monday)
(instance ?N Negotiating)
(during ?N ?M)
(agent ?N ?M1)
(agent ?N ?M2)
(not
(expects ?M1
(holdsDuring
(ImmediateFutureFn
(WhenFn ?N)
(exists (?A)
(and
(instance ?A Agreement)
(result ?N ?A)))))))
(not
(expects ?M2
(holdsDuring
(ImmediateFutureFn
(WhenFn ?N)
(exists (?A)
(and
(instance ?A Agreement)
(result ?N ?A)))))))))
Note this sentence is already given in the text above but the formalization
is given here. Also to note is that we know from the plural ‘Ministers’ that
there is more than one minister involved in the event. But we do not know that
there are more than two involved. The logical form created with two diﬀerent
GovernmentPersons in an agent relation requires two ministers, but does not
entail that there are only two.
7
Conclusion
We reviewed all 98 of the randomly chosen sentences. Two sentences were
rejected because the news corpus has some elided phrases, replaced with “@
@ @...” that makes it impossible to provide a complete formalization. For two

Choosing a Logic to Represent the Semantics of Natural Language
511
sentences of the 98, it should be possible for formalize them using only a descrip-
tion logic. We did a “complete” formalization of the ﬁrst 6 sentences. Of the 90
remaining sentences we reviewed that have required the logic determined by the
keyword lists, they usually also require several more advanced logical operators.
We have posted these validations on line as an appendix to this paper4. We
believe that we can reasonably conclude that the statistics given in Sect. 5 are
conservative. The results show that roughly half of a the sentences in the test
corpus require a logical expressiveness of full ﬁrst order logic or greater. We hope
that this may lead researchers and practitioners to reconsider the choice of less-
expressive logics for knowledge representation, or at least be more aware about
the limitations they impose on the percentage of human communication that
requires greater expressiveness.
References
1. Baader, F., Horrocks, I., Sattler, U.: Description logics (chap. 3). In: van Harmelen,
F., Lifschitz, V., Porter, B. (eds.) Handbook of Knowledge Representation, pp.
135–180. Elsevier (2008). download/2007/BaHS07a.pdf
2. Benzm¨uller, C., Pease, A.: Progress in automating higher-order ontology reasoning.
In: Konev, B., Schmidt, R., Schulz, S. (eds.) Workshop on Practical Aspects of
Automated Reasoning (PAAR-2010). CEUR Workshop Proceedings, Edinburgh
(2010)
3. Davies, M.: The corpus of contemporary American English as the ﬁrst reliable
monitor corpus of English. Lit. Linguistic Comput. 25(4), 447–464 (2010)
4. Gochet, P., Gribomont, E.P.: Epistemic logic. In: Gabbay, D.M., Woods, J. (eds.)
Logic and the Modalities in the Twentieth Century, Handbook of the History of
Logic, vol. 7, pp. 99–195. Elsevier (2006)
5. Kucera, H., Francis, W.N.: Computational Analysis of Present-Day American
English. Brown University Press, Providence (1967)
6. Lewis, C.I., Langford, C.H.: Symbolic logic. The Century Co. (1932)
7. Manning, C.D., Surdeanu, M., Bauer, J., Finkel, J., Bethard, S.J., McClosky,
D.: The Stanford CoreNLP natural language processing toolkit. In: Association
for Computational Linguistics (ACL) System Demonstrations, pp. 55–60 (2014).
http://www.aclweb.org/anthology/P/P14/P14-5010
8. Mineshima, K., Mart´ınez-G´omez, P., Miyao, Y., Bekki, D.: Higher-order logical
inference with compositional semantics. In: Proceedings of the 2015 Conference on
Empirical Methods in Natural Language Processing, pp. 2055–2061. Association
for Computational Linguistics, Lisbon, September 2015. https://doi.org/10.18653/
v1/D15-1244, https://www.aclweb.org/anthology/D15-1244
9. Montague, R.: The proper treatment of quantiﬁcation in ordinary English. In:
Hintikka, K.J.J., Moravcsic, J., Suppes, P. (eds.) Approaches to Natural Language,
pp. 221–242. Reidel, Dordrecht (1973)
10. Moss, L.S., Tiede, H.J.: Applications of modal logic in linguistics. In: Handbook
of Modal Logic (2007)
11. Niles, I., Pease, A.: Toward a standard upper ontology. In: Welty, C., Smith, B.
(eds.) Proceedings of the 2nd International Conference on Formal Ontology in
Information Systems (FOIS-2001), pp. 2–9 (2001)
4 https://adampease.org/CLAR20201-appendix.pdf.

512
A. Pease
12. Pease, A.: SUO-KIF Reference Manual. web document (2009). https://github.com/
ontologyportal/sigmakee/blob/master/suo-kif.pdf. Accessed 20 June 2020
13. Pease, A.: Arithmetic and inference in a large theory. In: AI in Theorem Proving
(2019)
14. Pease, A., Sutcliﬀe, G., Siegel, N., Trac, S.: Large theory reasoning with SUMO at
CASC. AI Commun. 23(2–3), 137–144 (2010). Special issue on Practical Aspects
of Automated Reasoning
15. Singhal, A.: Introducing the knowledge graph: things, not strings (2012). https://
blog.google/products/search/introducing-knowledge-graph-things-not/

The Placeholder View of Assumptions
and the Curry–Howard Correspondence
(Extended Abstract)
Ivo Pezlar(B)
Institute of Philosophy, Czech Academy of Sciences, Jilska 1, 110 00 Praha, Czechia
pezlar@flu.cas.cz
Abstract. Proofs from assumptions are amongst the most fundamen-
tal reasoning techniques. Yet the precise nature of assumptions is still
an open topic. One of the most prominent conceptions is the placeholder
view of assumptions generally associated with natural deduction for intu-
itionistic propositional logic. It views assumptions essentially as holes in
proofs (either to be ﬁlled with closed proofs of the corresponding propo-
sitions via substitution or withdrawn as a side eﬀect of some rule), thus
in eﬀect making them an auxiliary notion subservient to proper proposi-
tions. The Curry-Howard correspondence is typically viewed as a formal
counterpart of this conception. In this talk, based on my paper of the
same name (Synthese, 198(11), 10109–10125, 2021), I will argue against
this position and show that even though the Curry-Howard correspon-
dence typically accommodates the placeholder view of assumptions, it
is rather a matter of choice, not a necessity, and that another more
assumption-friendly view can be adopted.
Keywords: Placeholder view of assumptions · Assumption
withdrawing · Curry–Howard correspondence · Natural deduction ·
Intuitionistic propositional logic
1
Introduction
Proofs from assumptions are amongst the most fundamental reasoning tech-
niques. Yet the precise nature of assumptions is still an open topic. One of the
most prominent conceptions is the placeholder view of assumptions generally
associated with natural deduction for intuitionistic propositional logic. It views
assumptions essentially as holes in proofs (either to be ﬁlled with closed proofs
of the corresponding propositions via substitution or withdrawn as a side eﬀect
This is an extended abstract of a paper [8] with the same title published at Syn-
these 2021. Adapted by permission from Springer Nature Customer Service Centre
GmbH: Springer Nature, Synthese 198(11), 10109–10125, 2021, The placeholder view
of assumptions and the Curry–Howard correspondence. Pezlar, Ivo, c⃝2020. Work on
this paper was supported by Grant Nr. 19-12420S from the Czech Science Foundation,
GA ˇCR.
c
⃝Springer Nature Switzerland AG 2021
P. Baroni et al. (Eds.): CLAR 2021, LNAI 13040, pp. 513–520, 2021.
https://doi.org/10.1007/978-3-030-89391-0_31

514
I. Pezlar
of some rule), thus in eﬀect making them an auxiliary notion subservient to
proper propositions (see, e.g., [15], p. 5). The Curry-Howard correspondence is
typically viewed as a formal counterpart of this conception (recently, see, e.g.,
[13]). I this talk, based on my paper [8], I will argue against this position and
show that even though the Curry-Howard correspondence typically accommo-
dates the placeholder view of assumptions, it is rather a matter of choice, not a
necessity, and that another more assumption-friendly view can be adopted.
Assumption Withdrawing. The rule for implication introduction from natural
deduction for intuitionistic propositional logic is arguably the best-known exam-
ple of the assumption withdrawing rule:
[A]...
B
A ⊃B
It prescribes the following inference step: if we can derive B from assumption
A, then we can derive A ⊃B and withdraw the initial assumption A (it is
worth noting that other assumptions than A may be used in deriving B and
those remain open after discharging A). Note that this rule eﬀectively embodies
the deduction theorem from standard axiomatic systems. In other words, the
implication introduction rule is internalizing structural information from the
proof level (“B is derivable from A”) to the propositional level (“A implies
B”).1
The problematic aspect of this and other assumption withdrawing rules stems
from the fact that it behaves diﬀerently from the non-assumption withdrawing
rules. More speciﬁcally, with the implication introduction rule we are deriving
the proposition A ⊃B not from other propositions as with other standard
rules (e.g., conjunction introduction), but from a hypothetical proof. To put it
diﬀerently, the inference step validated by the implication introduction takes
us from a derivation starting with a hypothesis to a proposition, not just from
propositions to another proposition as do rules without assumptions.2
For example, consider the following simple proof of the theorem A ⊃((A ⊃
B) ⊃B) of propositional logic:
[A ⊃B]1
[A]2
⊃E
B
⊃I1
(A ⊃B) ⊃B
⊃I2
A ⊃((A ⊃B) ⊃B)
1 [13] describes this as a two-layer system. Note that, strictly speaking, the assump-
tions are not really withdrawn, they are rather incorporated into the propositional
level in the form of an antecedent.
2 This non-standard behaviour is also the reason why [10] describes assumption with-
drawing rules as improper rules and introduces the distinction between inference
rules and deductions rules. For more, see [7,10].

The Placeholder View of Assumptions
515
We start by making two assumptions A ⊃B and A. Applying the implication
elimination rule (modus ponens) we derive B. What follows are two consecutive
applications of implication introduction rule, ﬁrst withdrawing the assumption
A ⊃B, the second withdrawing the assumption A. Note that it is the fact that
B is derivable from A ⊃B together with A that warrants the application of the
implication introduction rule and the derivation of the corresponding proposition
(A ⊃B) ⊃B, at that moment still depending on the assumption A. Analogously
with the second application of the implication introduction rule that withdraws
this remaining assumption.
A proof that relies on no assumptions is called a closed proof. If a proof
depends on some assumptions that are yet to be withdrawn (i.e., open/active
assumptions) it is called an open proof. For example, our derivation of A ⊃((A ⊃
B) ⊃B) constitutes a closed proof, since both assumption were withdrawn in
the course of the derivation. Assuming we would not have carried out the last
inference step, we would get an open proof:
[A ⊃B]1
A
⊃E
B
⊃I1
(A ⊃B) ⊃B
since the assumption A, upon which the derivation of ((A ⊃B) ⊃B) depends,
is still active.
Closed proofs are usually preferred to open ones for the simple reason that
closed proofs are generally viewed as the fundamental notion in standard proof-
theoretic systems. From this perspective, assumptions are just temporary holes
in the proof that are preventing us from reaching a closed proof. These open holes
can be are either completely discarded via assumption withdrawing rules or ﬁlled
in with other already closed proofs via substitution. This is the reason why [13]
and others3 call this the placeholder view of assumptions: active assumptions
are just auxiliary artefacts of the employed proof system that behave diﬀerently
than proper propositions, i.e., propositions that do not appear as assumptions.
The Curry-Howard Correspondence. The placeholder view of assumptions is also
supported to a large extent by the Curry-Howard correspondence in its basic
form which links typed lambda calculus and implicational fragment of intuition-
istic propositional logic.4 Under this correspondence, natural deduction assump-
tions correspond to free variables of lambda calculus, which ﬁts well with the
interpretation of assumptions as open holes in the proof.
For example, assuming only the implicational fragment of intuitionistic
propositional natural deduction, we get the following correspondences between
the propositional and functional dimensions of the Curry-Howard correspon-
dence:
3 See, e.g., [1].
4 See, e.g., [14].

516
I. Pezlar
Natural Deduction
Lambda Calculus
Assumption
Free variable
Implication introduction Function abstraction
Implication elimination
Function application
Under this correspondence, the implication introduction rule will then look
as follows:
[x : A]
...
b(x) : B
λx.b(x) : A ⊃B
Note that the act of withdrawing the assumption A corresponds to λ-binding of
the free variable x. The whole proof of the theorem A ⊃((A ⊃B) ⊃B) would
then proceed in the following way:
[x : A ⊃B]1
[y : A]2
⊃E
xy : B
⊃I1
λx.xy : (A ⊃B) ⊃B
⊃I2
λy.λx.xy : A ⊃((A ⊃B) ⊃B)
with the concluding proof object (closed term) λy.λx.xy with no free variables
representing the ﬁnal closed proof with no active assumptions. In contrast, the
open proof discussed earlier:
[x : A ⊃B]1
y : A
⊃E
xy : B
⊃I1
λx.xy : (A ⊃B) ⊃B
concludes with the proof object λx.xy that still contains the free variable y
corresponding to the yet to be withdrawn assumption A.
The Placeholder View of Assumptions and Consequence Statements. The Curry-
Howard correspondence is generally viewed as incorporating the placeholder view
of assumptions. Probably most recently, this point was explicitly made in [13].
Furthermore, in the same paper Schroeder-Heister advocates for a more general
concept of inference that takes us not from propositions to other propositions,
but from (inferential) consequence statements A |= B to other consequence
statements in order to, amongst other things, equalize the status of assumptions
and assertions.5 The general form of inference rules he discusses is the following:
5 Strictly speaking, we should be writing A |=D B, i.e., that A |= B can be derived
with respect to a set of deﬁnitional clauses D (see [12]), but for simplicity we omit
these considerations.

The Placeholder View of Assumptions
517
A1 |= B1
. . .
An |= Bn
C |= D
where the antecedents can be empty and its correctness means that whenever
A1 |= B1, . . . , An |= Bn, then C |= D. As Schroeder-Heister explains:
This corresponds to the idea that in natural deduction, derivations can
depend on assumptions. Here this dependency is expressed by non-empty
antecedents, as is the procedure of the sequent calculus. Our model of
inference is the sequent-calculus model. . . ([12], p. 938)
To show that this rule is correct, we have demonstrated that given the grounds
for the premises (denoted as g : A |= B) we can construct grounds for the
conclusion. In other words, the grounds of the conclusion have to contain some
operation f transforming the grounds for the premises to the grounds for the
conclusion. Schematically:
g1 : A1 |= B1
. . .
gn : An |= Bn
f(g1, . . . gn) : C |= D
Schroeder-Heister comments on this rule as follows:
. . . [H]andling of grounds in the sense described is diﬀerent from that
of terms in the typed lambda calculus. When generating grounds from
grounds according to [the rule immediately above], we consider grounds
for whole sequents, whereas in the typed lambda calculus terms represent-
ing such grounds are handled within sequents. So the notation g : A |= B
we used above, which is understood as g : (A |= B), diﬀers from the
lambda calculus notation x : A ⊢t : B, where t represents a proof of B
from A and the declaration x : A on the left side represents the assumption
A. ([12], p. 939)
However, it should be mentioned that he left it “open how to formalize grounds
and their handling.” (ibid., p. 938) I will argue that even though lambda calcu-
lus with the Curry-Howard interpretation can be seen as embodying the place-
holder view of assumptions in the intuitionistic propositional logic, within the
family of Curry-Howard correspondence based systems we can consider a gen-
eralized approach that is free of this view. This generalized approach will treat
consequence statements A |= B as higher-order functions A ⇒B that can be
naturally captured in Martin-L¨of’s constructive type theory ([4]), speciﬁcally in
its higher-order presentation (see [5,6]).
Function-Based Approach to Assumptions. Let us return to the implication intro-
duction rule. Adopting the sequent-style notation for natural deduction,6 we can
rewrite this rule as follows:
x : A ⊢b(x) : B
⊢λx.b(x) : A ⊃B
6 See, e.g., Gentzen’s system NLK, discussed in [9].

518
I. Pezlar
where the symbol ⊢is used to separate assumptions from (derived) propositions.
Notice that the derivation of B from A is coded with an abstraction term from
lambda calculus, which means it captures some sort of a function. Reasoning
backwards, this should mean that between the assumption (context) and the
conclusion (asserted proposition) has to be a relationship that can be understood
functionally, otherwise, we would have nothing to code via lambda terms. To put
it diﬀerently, there has to be some more fundamental notion of a function at play
that we are coding through the concrete abstraction term.
We can try to capture this observation via the following rule:
x : A ⊢b(x) : B
f : A ⇒B
where f is to be understood as exemplifying the more fundamental notion of a
function that takes us from A to B.
Note that this rule can be roughly understood as the opposite of the impli-
cation introduction rule that goes in the other direction: while the implication
introduction rule makes the hypothetical derivation “from A is derivable B” in
its premise more concrete in the form of implication proposition A ⊃B and the
corresponding lambda term λx.b(x), this rule makes the derivation more general
in the sense that it is now considered as a function f (not speciﬁcally a lambda
term) from A to B. Also notice that assumptions are no longer placeholders or
contexts, but types of arguments for the function f capturing the corresponding
derivation. In other words, assumptions now stand equal to proper propositions,
they are not just an auxiliary notion captured via free variables.
Furthermore, capturing derivations in this way allows us to consider grounds
for the whole consequence statements as Schroeder-Heister required, not just
grounds for the conclusions under some assumptions. More speciﬁcally, treating
consequence statement A |= B as a function type A ⇒B (in accord with the
Curry-Howard correspondence) and a ground g as an object f of this type, we
can reformulate the general rule as follows (see [12], p. 938):
g1 : A1 ⇒B1
. . .
gn : An ⇒Bn
f(g1, . . . gn) : C ⇒D
Formalization. So far, I have treated f : A ⇒B informally to mean “f is a
function from A to B”. Utilizing Martin-L¨of’s constructive type theory ([4]),
speciﬁcally its higher-order presentation ([5,6]), we can capture it more rigor-
ously as a higher-order judgment of the form (x)b : (A)B. To explain why, let
us return to the hypothetical judgment x : A ⊢b(x) : B that appears as the sole
premise of the implication introduction rule. It tells us that we know b(a) to be a
proof of the proposition B assuming we know a to be a proof of the proposition
A. In other words, the hypothetical judgment x : A ⊢b(x) : B can be seen as
stating that b(x) is a function with domain A and range B.7 This fact, how-
ever, cannot be stated directly in the lower-order presentation of constructive
7 See [4].

The Placeholder View of Assumptions
519
type theory. Thus we move towards the higher-order presentation, which is as a
generalization of the lower-order presentation using a more primitive notion of
a type. The higher-order variant of constructive type theory allows us to form a
higher-order notion of a function which can be used to capture the function hid-
den behind the hypothetical judgment x : A ⊢b(x) : B as an object (x)b of type
(A)B. Consequently, (x)b : (A)B can then be used to interpret our statement
f : A ⇒B, as was required. In other words, (x)b : (A)B can be understood as
a higher-order judgment declaring that we have (potentially open) derivation of
B from A captured by the function (x)b.
It is important to emphasize that the higher-order function type (A)B cannot
be conﬂated with the lower-order function type A ⊃B. The most basic reason
is that they are inhabited by diﬀerent objects: the former by functions, the
latter by elements speciﬁed by ⊃-introduction rule, i.e., objects of the form
λx.b(x) that are used to code functions. More generally, the notion of a function
behind the type A ⊃B is parasitic on a more fundamental notion of a function
behind the type (A)B.8 From the logical point of view, the main reason we
should avoid merging (A)B and A ⊃B is that A in (A)B is an assumption of
derivation, while A in A ⊃B is an antecedent of implication, hence they are
objects of diﬀerent inferential roles. This is perhaps best illustrated by the fact
that assuming some function f of type (A)B essentially corresponds to assuming
a rule A
B in Schroeder-Heister’s natural deduction with higher-level rules ([11]).
Conclusion. In this talk, I have argued that the Curry-Howard correspondence
is not necessarily connected with the placeholder view of assumptions generally
associated with natural deduction systems for intuitionistic propositional logic.
Although in the basic form of this correspondence, assumptions, which corre-
spond to free variables, can indeed be thought of as just holes to be ﬁlled, we
can consider also a functional approach where derivations from assumptions are
regarded as functions (see [8]). On this account, assumptions are no longer just
placeholders but domains of the corresponding functions. From the logical point
of view, this move corresponds to the shift from reasoning with propositions to
reasoning with consequence statements.
References
1. Francez, N.: Proof-theoretic Semantics. College Publications (2015)
2. Klev, A.: A comparison of type theory with set theory. In: Centrone, S., Kant, D.,
Sarikaya, D. (eds.) Reﬂections on the Foundations of Mathematics. SL, vol. 407, pp.
271–292. Springer, Cham (2019). https://doi.org/10.1007/978-3-030-15655-8 12
3. Klev, A.: Name of the Sinus Function. In: Sedl´ar, I., Blicha, M. (eds.) The Logica
Yearbook 2018. College Publications, London (2019)
4. Martin-L¨of, P.: Intuitionistic type theory: Notes by Giovanni Sambin of a series of
lectures given in Padua, June 1980. Bibliopolis, Napoli (1984)
8 See [2,3].

520
I. Pezlar
5. Nordstr¨om, B., Petersson, K., Smith, J.M.: Programming in Martin-L¨of’s Type
Theory: An Introduction. International Series of Monographs on Computer Sci-
ence, Clarendon Press, Oxford (1990)
6. Nordstr¨om, B., Petersson, K., Smith, J.M.: Martin-L¨of’s type theory. In: Handbook
of Logic in Computer Science: Volume 5: Logic and Algebraic Methods. Oxford
University Press, Oxford (2001)
7. Pezlar, I.: Towards a more general concept of inference. Log. Univers. 8(1), 61–81
(2014). https://doi.org/10.1007/s11787-014-0095-3
8. Pezlar, I.: The placeholder view of assumptions and the Curry–Howard correspon-
dence. Synthese 198(11), 10109–10125 (2021). https://doi.org/10.1007/s11229-
020-02706-z
9. von Plato, J.: Gentzen’s proof systems: byproducts in a work of genius. Bull. Symb.
Log. 18(3), 313–367 (2012). https://doi.org/10.2178/bsl/1344861886
10. Prawitz, D.: Natural Deduction: A Proof-Theoretical Study. Almqvist & Wiksell,
Stockholm (1965)
11. Schroeder-Heister, P.: A natural extension of natural deduction. J. Symb. Log.
49(4), 1284–1300 (1984). https://doi.org/10.2307/2274279
12. Schroeder-Heister, P.: The categorical and the hypothetical: a critique of some
fundamental assumptions of standard semantics. Synthese 187(3), 925–942 (2012).
https://doi.org/10.1007/s11229-011-9910-z
13. Schroeder-Heister, P.: Open problems in proof-theoretic semantics. In: Piecha, T.,
Schroeder-Heister, P. (eds.) Advances in Proof-Theoretic Semantics. TL, vol. 43,
pp. 253–283. Springer, Cham (2016). https://doi.org/10.1007/978-3-319-22686-
6 16
14. Sørensen, M.H., Urzyczyn, P.: Lectures on the Curry-Howard Isomorphism, Volume
149 (Studies in Logic and the Foundations of Mathematics). Elsevier Science Inc.,
New York (2006)
15. Troelstra, A.S., Schwichtenberg, H.: Basic Proof Theory. Cambridge University
Press, Cambridge (2000). https://doi.org/10.1017/cbo9781139168717

Paranegations and the Square
of Oppositions
Mariusz Urba´nski(B)
and Zoﬁa ˙Zm´ojdzin
Faculty of Psychology and Cognitive Science, Adam Mickiewicz University,
Pozna´n, Poland
murbansk@amu.edu.pl
Abstract. In this paper, a description of semantics for non-classical
negations of paralogics CLuN and CLaN is presented in terms of the
theory of oppositions. An outline of a synthetic tableaux method for
these and some other paralogics is given as well.
Keywords: Paralogics · Theory of oppositions · Synthetic tableau
method
1
Introduction
In this paper we describe semantics for non-classical negations of paralogics
CLuN and CLaN ([2,4]; see also [7,12]), in terms of relations represented in
the square of oppositions, the relations of contrariness and subcontrariness in
particular (in Sect. 2). Although semantic conditions imposed on these so-called
paranegations are not complicated by themselves, their diagrammatic represen-
tations are more vivid and allow for a clear and transparent account of their
interconnections (which we will present in the form of an octahedron of opposi-
tions at the end of Sect. 2). We shall also give a brief description of a certain direct
proof method for these logics, that is, the synthetic tableaux method (STM, in
Sect. 3). In the case of STM semantic justiﬁcation for the rules for the introduc-
tion of paranegated formulas stems directly from the relations represented in the
square of oppositions.
2
The Basic Paralogics and the Square of Oppositions
The basic paralogics are obtained by dropping some requirements imposed on
negation in classical logic. The paraconsistent logic CLuN, which allows for gluts
with respect to negation, is obtained by dropping the consistency requirement (if
v(A) = 1, then v(¬A) = 0). The paracomplete logic CLaN, which allows for gaps
Research reported in this paper were supported by the National Science Centre, Poland
(DEC-2013/10/E/HS1/00172). We would like to thank the anonymous reviewers for
their suggestions and comments.
c
⃝Springer Nature Switzerland AG 2021
P. Baroni et al. (Eds.): CLAR 2021, LNAI 13040, pp. 521–532, 2021.
https://doi.org/10.1007/978-3-030-89391-0_32

522
M. Urba´nski and Z. ˙Zm´ojdzin
with respect to negation, is obtained by dropping the completeness requirement
(if v(A) = 0, then v(¬A) = 1). The logic CLoN, which allows for both gluts and
gaps concerning negation, is obtained by dropping both requirements. Batens et
al. [4, p. 30] indicate two reasons why these weak logics are important. The ﬁrst
is, that many paralogics are extensions of them (see [10]). The second is, that
these three logics themselves have some interesting applications in research on
adaptive logics (see [3]). We focus our attention on CLuN and CLaN, because
semantics for negations in these paralogics may be adequately described within
the framework of the square of oppositions, with its four relations of contrariness,
subcontrariness, contradictoriness and subalternation (see [5,8]). The case of the
third paralogic is more complicated, as the truth values of a formula and its
CLoN-negation are unrelated to each other. We shall comment on this issue at
the end of Sect. 3.3.
We shall start with semantic characteristics of propositional parts of the basic
paralogics (see [4]). Their languages are extensions of the language of Classical
Propositional Calculus (CPC); we shall consider the version with ¬ (classical
negation), ∧(classical conjunction), ∨(classical disjunction) and →(classical
implication) as the primitive connectives. We shall use the symbols +, ∼and
⊸for CLoN-, CLuN- and CLaN-negation, respectively. The notion of well-
formed formula (wﬀfor short) is deﬁned as usual. Let V ar stands for the set of all
the propositional variables of a considered language and Formo, Formu, Forma
for the sets of all the wﬀs of the logic CLoN, CLuN, CLaN, respectively.
Finally, let Form+
o , Form∼
o , Form⊸
o
stand for the sets of all the wﬀs of the
form +A,∼A, ⊸A, respectively. We assume also that the notions of truth under
a valuation, semantic consequence and validity are deﬁned as usual, relatively
to a logic considered.
We shall start with the logic CLoN. Its language extends CPC language
with a unary connective + (CLoN-negation). The semantics is deﬁned in terms
of two separate functions, which assign truth values, Truth (1) or Falsehood (0),
to wﬀs. The assignment functions fulﬁl the following conditions:
S.1 vM : V ar →{1, 0}
S.2 vN : Form+
o →{1, 0}
A function v: Formo →{1, 0} is a CLoN-valuation iﬀ:1
V.1 v(A) = vM(A) iﬀA ∈V ar
V.2 v(¬A) = 1 iﬀv(A) = 0
V.3 v(+A) = vN(A)
V.4 v(A ∧B) = 1 iﬀv(A) = 1 and v(B) = 1
V.5 v(A ∨B) = 1 iﬀv(A) = 1 or v(B) = 1
V.6 v(A →B) = 1 iﬀv(A) = 0 or v(B) = 1
1 The conditions V.1, V.2 and V.4 – V.6 deﬁne CPC-valuations. Classical negation, ¬,
may be introduced in CLoN (and in other basic paralogics as well) by means of the
constant ⊥, deﬁned as usual: v(⊥) = 0. However, we shall consider ¬ as a primitive
connective.

Paranegations and the Square of Oppositions
523
The idea underlying CLoN-negation is this: the truth value of a formula +A
is unrelated to the truth value of A, and thus the assignment of truth value to
+A is independent of the truth value of A.2
The language of CLuN extends the CPC language with a unary connective ∼
(CLuN-negation). A CLuN-valuation is a function Formu →{1, 0} obtained
by replacing the conditions S.2 and V.3 with the following:
S.2∼vN : Form∼
u →{1, 0}
V.3∼v(∼A) = 1 iﬀv(A) = 0 or vN(∼A) = 1
Thus a formula ∼A is true under a valuation v iﬀeither A is false under v or
∼A is assigned the value 1 by the assignment function vN, independently of the
valuation v. As a result, both A and ∼A may be true under v, but they cannot
both be false: they are subcontrariae formulas.
As we claimed above, semantic relations between the formulas A and ∼A
may be adequately described within the framework of the theory of oppositions
and depicted in the CLuN-version of the square of oppositions (see Fig. 1). The
relations that hold between pairs of connected formulas are the same as in the
classical square of oppositions:
contrariae: F∼A and FA;
subcontrariae: TA and T ∼A;
contradictoriae: FA and TA, F∼A and T∼A;
subalternae: TA to F∼A, T∼A to FA.3
In Fig. 1 the relation of contrariness is indicated by a dotted line, the relation
of subcontrariness – by a dashed line, the relation of contradictoriness – by
loosely dotted lines. Arrows indicate the direction of subalternation.
From the CLuN-version of the square of oppositions, we may read oﬀin
particular, that TA is semantic consequence of F ∼A, as well as T ∼A is a
semantic consequence of FA. Also, F ∼A and FA are contrariae formulas, and
2 In what follows we will be using the concept of signed formulas: if A is a formula
of a given language, then TA and FA are signed formulas (T and F will be referred
to as truth-signs). We will refer to them as ‘formulas’ in cases where no ambiguity
can arise. We will use #, & as variables for truth-signs if needed. Truth-signs do not
belong to the vocabularies of languages we will be considering, so the truth values of
signed formulas are not determined by valuations. Nevertheless, the truth value of
a signed formula #A (where # is any of T, F) is dependent upon the truth value of
formula A under a certain valuation, so we will speak of the truth value of formula
#A with respect to that valuation. Thus a signed formula TA takes the value 1 with
respect to a valuation v iﬀv(A) = 1 whereas a signed formula FA takes the value 1
with respect to a valuation v iﬀv(A) = 0.
3 The relation of subalternation of A to B amounts to A being a semantic consequence
of B.

524
M. Urba´nski and Z. ˙Zm´ojdzin
Fig. 1. CLuN-version of the square of oppositions
thus they may both be false but cannot both be true (under a certain valuation
v). The relation of contradictoriness is self-explanatory.
Finally, consider the case of CLaN. The language of CLaN extends the CPC
language with a unary connective ⊸(CLaN-negation). A CLaN-valuation is
a function Forma →{1, 0} obtained by replacing in the deﬁnition of CLoN-
valuation the conditions S.2 and V.3 with the following:
S.2⊸vN : Form⊸
a →{1, 0}
V.3⊸v(⊸A) = 1 iﬀv(A) = 0 and vN(⊸A) = 1
Thus a formula ⊸A is true under a valuation v iﬀtwo conditions are met:
A is false under v and ⊸A is assigned the value 1 by the assignment function
vN. As a result, both A and ⊸A may be false under v, but they cannot both
be true: they are contrariae formulas.
Semantic relations between the formulas A and ⊸A may be depicted in the
CLaN-version of the square of oppositions (see Fig. 2). Again, the relations that
hold between pairs of connected formulas are exactly the same as in the classical
square of oppositions (and are indicated by diﬀerent lines as in Fig. 1):
contrariae: TA and T⊸A
subcontrariae: F⊸A and FA
contradictoriae: TA and FA, T⊸A and F⊸A
subalternae: F⊸A to TA, FA to T⊸A
Fig. 2. CLaN-version of the square of oppositions
This means, in particular, that F⊸A is semantic consequence of TA and FA is
semantic consequence of T⊸A. The formulas F⊸A and FA, as subcontrariae,
may both be true but cannot both be false (again, under a certain valuation v).

Paranegations and the Square of Oppositions
525
Although CLuN-valuations and CLaN-valuations are distinct functions,
nevertheless the truth values of the formulas ∼A and ⊸A are related to the
truth value of A and, as a result, are related to each other as well. These rela-
tions may be represented in an octahedron of oppositions (see Fig. 3; the relations
are indicated by diﬀerent lines as in Fig. 1). To ﬁnd out what are the relations
between CLuN-negation, CLaN-negation and classical negation just remove all
the T’s and replace all the F’s with ¬.
Fig. 3. An octahedron of oppositions for CLuN- and CLaN-negation
Let us note two further points.4 First, this octahedron, as it should be
expected, is just a fragment of a much more complex structure of oppositional
geometry: the “oppositional tetrahexahedron” [9,11,13]. Second, there is another
square of oppositions identiﬁable within the octahedron, with the vertices T⊸A,
F∼A, F⊸A and T∼A. Thus our analysis of the paralogical oppositional space
by no means is exhaustive. However, these issues go beyond the scope of the
present paper.
3
Synthetic Tableaux Method
Now we shall use our geometric consideration in order to introduce and justify
the rules for CLuN and CLaN negations within the framework of synthetic
tableaux method (STM) – a model-seeking and proof method [14–17]. It was
developed as a decision procedure for Classical Propositional Calculus (CPC)
4 We owe these remarks to Alessio Moretti.

526
M. Urba´nski and Z. ˙Zm´ojdzin
and some non-classical logics. Roughly speaking, a synthetic tableau for a for-
mula A is deﬁned as a family of interconnected derivations (so-called synthetic
inferences) of either A or non-A, based on all the relevant suitably deﬁned sets
of basic constituents of A (in the case of propositional logics these basic con-
stituents are signed propositional variables of A). The formulas occurring in a
synthetic inference of A can only be (signed) subformulas of A.5 Recently, STM
has been developed also for ﬁrst-order logic and propositional intuitionistic logic
[6]. There, the authors deﬁned a synthetic tableau as a ﬁnite labelled tree with
an empty root.
The fundamental ideas underlying STM can be traced back to L. Kalm´ar’s
proof of the completeness of CPC [15, p. 69]. As the reader will recall, in this
proof one makes use of the fact that every valid formula is entailed by every con-
sistent set made up of all of its propositional variables or their negations. How-
ever, Kalm´ar’s original proof is system-dependent: it can be applied to every
logic which validates certain theorems. STM generalizes its idea. The result
is a tableau-style decision procedure which, in contradistinction to Beth-like
tableaux, is based on direct reasoning. An STM-proof of a formula A is a syn-
thetic tableau Ω for A such that every element of Ω is a synthetic inference of A.
Intuitively it can be said that a formula A is proved if and only if all the possible
attempts at ‘synthesize’ A or non-A lead to A. Thus, “one way or another” is
the shortest description of the ideas underlying STM as a proof method.
The set R of inference rules for CPC consists of the following rules:
rn1
TA\\F¬A
rn2
FA\\T¬A
rd1
TA\\TA ∨B
rd2
TB\\TA ∨B
rd3
FA, FB\\FA ∨B
rc3
FA\\FA ∧B
rc2
FB\\FA ∧B
rc3
TA, TB\\TA ∧B
ri1
FA\\TA →B
ri2
TB\\TA →B
ri3
TA, FB\\FA →B
3.1
The Case of CLaN
In the case of CLaN the notion of synthetic inference is deﬁned as follows:
Deﬁnition 31. A ﬁnite sequence s = s1, . . . , sn of signed formulas is a synthetic
inference of #A iﬀ:
1. every term of s is a signed subformula of A;
5 We will make use of the following notion of an immediate subformula and of a
subformula of a given wﬀ[17, p. 322]. If A is a propositional variable, then it has
no proper subformulas at all. If A is a formula of the form ‘$B’ (where ‘$’ stands
for a negation sign), then B is a proper subformula of A and the only immediate
subformula of A as well. If A is of the form ‘B ∗C’ (where ‘∗’ stands for any of
the binary connectives), then both B, C are proper subformulas of A and the only
immediate subformulas of A. If C is a proper subformula of B and B is a proper
subformula of A, then C is a proper subformula of A. A formula B is a subformula
of a formula A iﬀB is a proper subformula of A or A = B.

Paranegations and the Square of Oppositions
527
2. s1 is a signed propositional variable;
3. sn is #A;
4. for every sg (g = 1, . . . , n) either sg is a signed propositional variable, or sg
is derivable on the basis of a certain set of formulas such that each element
of this set precedes sg in s;
5. for every sg (g = 1, . . . , n) the following hold:
(a) if sg is a signed propositional variable #ϕ, then none of Tϕ, Fϕ occurs
at any other place in s;
(b) if sg is of the form #⊸B, then none of T⊸B, F⊸B occurs at any other
place in s.
Thus a synthetic inference of a signed formula #A is a ﬁnite sequence of its
signed subformulas, which begins with some signed propositional variable and
ends with #A itself. Moreover, every (signed) propositional variable occurs as a
term in s only once, no matter of truth-signs (the same pertains to the (signed)
paranegated wﬀs in s), and every formula which is not a (signed) propositional
variable is derivable from some earlier formula(s) of s. Derivability relation is
deﬁned based on the set R of classical inference rules extended with the following
speciﬁc CLaN rules:
ra1
FA\\T ⊸A
ra2
FA\\F ⊸A
ra3
TA\\F ⊸A
The rules ra1 and ra2 are based on subcontrariness relation and are obviously
unsound. The rule ra3 is based on subalternation and it is sound.
The notion of synthetic tableau in CLaN is given by the following deﬁnition:
Deﬁnition 32. Let A be an unsigned formula and let #, & be distinct truth-
signs. A family Ω of ﬁnite sequences of signed formulas is a synthetic tableau
for A iﬀevery element of Ω is a synthetic inference of TA or FA, there exists
a propositional variable ϕ such that the ﬁrst element of every sequence in Ω is
Tϕ or Fϕ and for every sequence s = s1, . . . , sn in Ω the following hold:
1. if si (i = 1, . . . , n) is a signed propositional variable #ψ, then:
(a) there exists in Ω a sequence s∗such that s∗
i is & ψ and, if i > 1, then s
and s∗do not diﬀer up to the level of their i −1th terms;
(b) if i > 1, then for every sequence s∗such that s and s∗do not diﬀer up to
the level of their i −1th terms, s∗
i is Tψ or Fψ;
2. if si (i = 2, . . . , n) is of the form # ⊸B and there exists sh (h < i) such that
sh is of the form FB, then:
(a) Ω contains a sequence s∗such that s and s∗do not diﬀer up to the level
of their i −1th terms and s∗
i is & ⊸B;
(b) for every sequence s∗such that s and s∗do not diﬀer up to the level of
their i −1th terms, s∗
i is # ⊸B or & ⊸B.
A synthetic tableau Ω for a formula A is a family of interconnected synthetic
inferences of FA or TA. The clause 1a of Deﬁnition 32 warrants that introduction
of a (signed) propositional variable into a tableau forces branching, which is
semantically ‘fair’: if #ψ is to be introduced as an ith term of a path s of a

528
M. Urba´nski and Z. ˙Zm´ojdzin
tableau, then another branch s∗should be created, which is exactly as s up to
the level of their i −1th terms and such that its ith term is &ψ (where #, &
stand for distinct truth-signs). On the other hand, clause 1b warrants, that this
branching is always binary.
Clause 2, in turn, warrants fair branching and binary branching with respect
to (signed) CLaN-negated formulas (that is, formulas of the form F ⊸B, T ⊸
B), provided that they are introduced into a tableau as a result of the application
of one of the rules ra1 or ra2.
These two clauses form a kind of cut rule. However, it is a tree-construction
rule rather than an inferential rule. Moreover, this cut is very restricted: it can be
applied only to propositional variables or to the paranegated formulas (provided
that they are subformulas of the initial formula). Therefore, the restrictions here
are even stronger than in the case of Smullyan’s analytic cut.
Another point is, that if a formula A is of a ‘branching-forcing’ type (that is,
it is a propositional variable or a formula & ⊸B resulting from the application
of one of the unsound rules), then branching a tableau on FA and TA can be
done only once (because of the clause 5 of Deﬁnition 31). Thus, no branch of a
tableau can contain the very same wﬀpreceded with T at one place and with F
at another (see [17, p. 325–326]).
In order to prove soundness and completeness of the method with respect to
the semantics of CLaN, we need the following lemmas and a theorem (we shall
only outline their proofs; the details can be found in [18] and are analogous to
the ones for CPC and CLuN, which are given in [14] and [17]).
Lemma 33. Let s be a synthetic inference of a formula #A. Let X be the set
made up of all the terms of s. Let Θ be a subset of X made up of all the signed
propositional variables in X. Then every formula in X is derivable via CLaN-
rules based on the set Θ.
The proof of Lemma 33 is based on induction on the degree of complexity of the
elements of X (degree of complexity of a formula B is deﬁned as the number of
arguments of connectives in B). The synthesizing character of rules of inference
guarantees that a formula introduced into a synthetic inference as a result of an
application of a rule is of a greater degree of complexity than the premise (or
premises) of the rule.
Theorem 34. Let s be a synthetic inference of a (signed) formula A. Let X be
the set made up of all the terms of s. Then there exists a valuation v such that
all the elements of X are true with respect to v.
Notice that due to the deﬁnition of a synthetic inference the following hold
(pi ∈V ar):
1. Tpi ∈X iﬀFpi /∈X
2. if T ⊸A ∈X, then FA ∈X and TA /∈X
The proof starts with deﬁning the appropriate valuation. Let v be a CLaN-
valuation determined by assignment functions vM and vN such that:

Paranegations and the Square of Oppositions
529
1. for every pi:
(a) if Tpi ∈X, then vM(pi) = 1;
(b) if Fpi ∈X, then vM(pi) = 0;
(c) if neither Tpi nor Fpi are in X, then vM(pi) = 0;
2. for every formula of the form ⊸A:
(a) if T ⊸A ∈X, then vN(⊸A) = 1;
(b) if F ⊸A ∈X, then vN(⊸A) = 0;
(c) if neither T ⊸A nor F ⊸A are in X, then vN(⊸A) = 0.
Then we prove that v has the desired property, by induction on the degree of
complexity of the formulas in X and by Lemma 33.
Lemma 35. For every formula A of the considered language, there exists a
synthetic tableau for A.
The proof of Lemma 35 consists in deﬁning a method of construction of a syn-
thetic tableau for any given formula of the considered language. We start with
characterizing a family of all the possible classes of CLaN-valuations, deter-
mined by truth values assigned to all the propositional variables and paranegated
formulas occurring in the elements of X. Then we show that each such class
determines a unique synthetic inference of #A and that all these inferences form
a tableau for A, which is in a sense maximal – that is, which contains all the
possible branchings (these are so-called canonical synthetic tableaux, see [14]).
All this warrants soundness and completeness of the method:
Theorem 36. A formula A is CLaN-valid iﬀthere exists a synthetic tableau
for A such that every path of it leads to TA.
The detailed proof of this theorem, based on the notion of a minimal error
point of a synthetic inference, is given in [18, p. 24–25].
Let us now consider some examples.
Example 1. The formulas p and ⊸p are contrariae, thus ¬(p∧⊸p) is CLaN-
valid:
Tp
F ⊸p
F(p∧⊸p)
T¬(p∧⊸p)
Fp
F(p∧⊸p)
T¬(p∧⊸p)
Example 2. The formulas ¬ ⊸p and ¬p are subcontrariae and cannot both be
false; thus ¬(¬ ⊸p ∧¬p) is not CLaN-valid:
Tp
F¬p
F(¬ ⊸p ∧¬p)
T¬(¬ ⊸p ∧¬p)
Fp
T¬p

H
H
H
H
T ⊸p
F¬ ⊸p
F(¬ ⊸p ∧¬p)
T¬(¬ ⊸p ∧¬p)
F ⊸p
T¬ ⊸p
T(¬ ⊸p ∧¬p)
F¬(¬ ⊸p ∧¬p)

530
M. Urba´nski and Z. ˙Zm´ojdzin
3.2
The Case of CLuN
In the case of the logic CLuN the deﬁnition of synthetic inference of a formula
#A is the same as in the case of CLaN (with one obvious diﬀerence that the
CLaN negation ⊸should be changed to CLuN negation ∼). Derivability rela-
tion is deﬁned based on the set R of classical inference rules and the following
speciﬁc CLuN rules:
ru1
TA\\T∼A
ru2
TA\\F∼A
ru3
FA\\T∼A
Again, the rules ru1 and ru2 are based on subcontrariness and are unsound.
The rule ru3 is based on subalternation and it is sound.
The deﬁnition of a synthetic tableau for a given formula in the case of CLuN
diﬀers from the CLaN version with respect to clause 2, which this time should
look like this:
2. if si (i = 2, . . . , n) is of the form #∼B and there exists sh (h < i) such that
sh is of the form TB, then:
(a) Ω contains a sequence s∗such that s and s∗do not diﬀer up to the level
of their i −1th terms and s∗
i is &∼B;
(b) for every sequence s∗such that s and s∗do not diﬀer up to the level of
their i −1th terms, s∗
i is #∼B or &∼B.
This is because in the case of CLuN the formulas TB and T∼B are subcon-
trariae. As a result, an attempt to synthesize a CLuN-negated formula on the
basis of TB may lead to T ∼B as well as to F ∼B. Thus, every application of
the rule ru1 (resp. ru2) should be accompanied by an application of the rule ru2
(resp. ru1), resulting in splitting current branch of a tableau. Again, soundness
and completeness of the method with respect to the semantics of CLuN can be
proved (see [17, p. 325–329]).
Let us consider some examples (taken from [17]).
Example 3. The formulas p and ∼p are subcontrariae, thus ¬(p∧∼p) is not
CLuN-valid:
Tp

H
H
H
T∼p
Tp∧∼p
F¬(p∧∼p)
F∼p
Fp∧∼p
T¬(p∧∼p)
Fp
Fp∧∼p
T¬(p∧∼p)
Example 4. The formulas ¬ ∼p and ¬p are contrariae, thus ¬(¬ ∼p ∧¬p) is
CLuN-valid:
Tp
F¬p
F¬∼p ∧¬p
T¬(¬∼p ∧¬p)
Fp
T∼p
F¬∼p
F¬∼p ∧¬p
T¬(¬∼p ∧¬p)

Paranegations and the Square of Oppositions
531
3.3
The Case of CLoN
On the one hand, the case of CLoN is somewhat more complicated than the
cases of CLaN and CLuN. This is because the truth values of a CLoN-negated
formula, +A, and of an argument of the negation, A, are unrelated to each other:
they are assigned to these formulas independently of each other. Thus the square
of oppositions in its usual form is not helpful here. All we can say is that none of
the classical relations holds neither between +A and A nor their signed versions.
On the other hand, this simpliﬁes the matter of deﬁning appropriate synthetic
rules for +-introduction. The only prerequisite for introducing a formula # + A
into a tableau is the presence of &A on a given branch (and in the case of CLoN
# and & need not be distinct!). However, to warrant soundness of the method
we still need to take care of the fair-branching condition.
The deﬁnition of synthetic inference of formula #A is the same as in the
case of CLaN and CLuN (only the paranegation should be changed to CLoN
negation +). Derivability relation is deﬁned based on the set R of classical
inference rules and the following speciﬁc CLoN rules:
ro1
FA\\T +A
ro2
FA\\F +A
ro3
TA\\T +A
ro4
TA\\F +A
None of the rules ro1 – ro4 is sound. Clause 2 of the deﬁnition of a synthetic
tableau for a given formula in the case of CLoN (which is the only diﬀerence
between this version and CLaN and CLuN versions) should look like this:
2. if si (i = 2, . . . , n) is of the form #+B, then:
(a) Ω contains a sequence s∗such that s and s∗do not diﬀer up to the level
of their i −1th terms and s∗
i is &+B;
(b) for every sequence s∗such that s and s∗do not diﬀer up to the level of
their i −1th terms, s∗
i is #+B or &+B.
Thus, in the case of CLoN, (signed) paranegated formulas are introduced
into a tableau in the same way as (signed) propositional variables. We may
even get rid of the inference rules ro1 – ro4 and put the clauses for introducing
formulas of the form &+B into tree-construction rules only. In order to do this
we would have to change clause 4 of the deﬁnition of a synthetic inference (see
deﬁnition 31) to the following:
4. for every sg (g = 1, . . . , n) either sg is a signed propositional variable, or sg
is of the form &+A, or sg is derivable on the basis of a certain set of fomulas
such that each element of this set precedes sg in s;
This makes it even more clear that in the case of CLoN both (signed) proposi-
tional variables and (signed) paranegated formulas are introduced into a tableau
as a kind of assumptions and not as derived formulas. Thus a problem arises:
does the ‘+’ operator represent a negation at all? No information is reversed,
no information is cancelled, no failure is present. This is an interesting issue;
however, it goes well beyond the scope of the paper.

532
M. Urba´nski and Z. ˙Zm´ojdzin
4
Conclusion
The square of oppositions (or, more generally: oppositional geometry) allows
for a clear and transparent representation of the semantics of paranegations in
logics CLaN and CLuN. In the STM setting, the properties of subcontrariness
relation oﬀer an intuitive justiﬁcation for both unsound inference rules and tree-
construction rules, which force branching of a tableau if one of the unsound rules
is applied. It may be worth investigating if such a diagrammatic representation
of semantic interconnections of formulas could also be successfully applied to
other logics, and not only with respect to negation. Another possible direction
of research are possible connections to non-deterministic semantics [1].
References
1. Avron, A., Konikowska, B.: Multi-valued calculi for logics based on non-
determinism. Log. J. IGPL 13(4), 365–387 (2005)
2. Batens, D.: Paraconsistent extensional propositional logics. Logique et Analyse
90–91, 195–234 (1980)
3. Batens, D.: A survey of inconsistency-adaptive logics. In: Batens, D., Mortenson,
C., Priest, G., Van Bendegem, J.P. (eds.) Frontiers of Paraconsistent Logic, pp.
49–73. Research Studies Press, King’s College Publications, Baldock (2000)
4. Batens, D., De Clercq, K., Kurtonina, N.: Embedding and interpolation for some
paralogics. The propositional case. Rep. Math. Log. 33, 29–44 (1999)
5. Boche´nski, I.M.: Ancient Formal Logic. North-Holland Publication, Amsterdam
(1951)
6. Leszczynska-Jasion, D., Chlebowski, S.: Synthetic tableaux with unrestricted cut
for ﬁrst-order theories. Axioms 8(4), 133 (2019)
7. Lopari´c, A., da Costa, C.A.: Paraconsistency, paracompleteness and induction.
Logique et Analyse 113, 73–80 (1986)
8. Lukasiewicz, J.: Aristotle’s Syllogistic from the Standpoint of Modern Formal
Logic. Oxford UP (1951)
9. Pellissier, R.: “Setting” n-opposition. Logica Universalis 2, 235–263 (2008).
https://doi.org/10.1007/s11787-008-0038-y
10. Popov, V.M.: Sequential axiomatizations for simple paralogics. Log. Investig. 16,
205–221 (2010)
11. Sauriol, P.: Remarques sur la Th´eorie de l’hexagone logique de Blanch´e. Dialogue
7(3), 374–390 (1968)
12. Sette, A.M., Alves, E.H.: On the equivalence between some systems of nonclassical
logic. Bull. Sect. Log. 25, 68–72 (1996)
13. Smessaert, H.: On the 3D visualisation of logical relations. Log. Univers. 3(2),
303–332 (2009). https://doi.org/10.1007/s11787-009-0010-5
14. Urba´nski, M.: Remarks on synthetic tableaux for classical propositional calculus.
Bull. Sect. Log. 30, 194–204 (2001)
15. Urba´nski, M.: Synthetic tableaux and erotetic search scenarios: extension and
extraction. Logique et Analyse 173–174–175, 69–91 (2001)
16. Urba´nski, M.: Synthetic Tableaux for Lukasiewicz’s Calculus L3. Logique et Anal-
yse 177–178, 155–173 (2002)
17. Urba´nski, M.: How to synthesize a paraconsistent negation. The case of CLuN.
Logique et Analyse 185–188, 319–333 (2004)
18. ˙Zm´ojdzin, Z.: Synthetic tableaux for paralogic CLaN. M.A. thesis (unpublished),
Institute of Psychology, Adam Mickiewicz University, Pozna´n (2011)

Validity Under Assumptions and Modus
Ponens
Xuefeng Wen(B)
Institute of Logic and Cognition, Department of Philosophy, Sun Yat-sen University,
Guangzhou 510275, China
Abstract. Slightly altering and extending McGee’s semantics for con-
ditionals, we deﬁne a ternary notion of validity for natural language
arguments, which can be regarded as a uniﬁcation of two kinds of valid-
ity in the literature. By the new notion of validity, an inference is not just
valid or invalid, but valid or invalid under a set of assumptions. Based
on this notion, we formulate the validity and invalidity of modus ponens.
Keywords: Validity · Modus ponens · Epistemic modality · Ternary
notion of truth
1
Introduction
This paper aims to unify two notions of validity in the literature, and apply it
to formulating the validity and invalidity of modus ponens for natural language
arguments.
The basic idea is to take McGee’s ternary notion of truth given in [10] more
formally and deﬁne a ternary notion of validity. By the ternary validity, an
inference is not just valid or invalid, but valid or invalid under a set of assump-
tions. So a complete inference is tripart: a set of premises, a conclusion, and a
set of assumptions. Assumptions provide contexts for evaluating formulas. Like
McGee’s semantics, conditional antecedents are treated as making assumptions.
To formalize both indicatives and counterfactuals, we build the semantics in the
framework of possible worlds semantics, using selection functions initiated by
Stalnaker [14] in his conditional logic. To avoid some undesirable consequences
of McGee’s semantics, we tweak it and allow formulas with undetermined truth
values. The new semantics with the new notion of validity shed light on diﬀerent
senses of validity concerning modus ponens.
The rest of the paper is organized as follows. Section 2 provides a new seman-
tics for a formal language containing both conditionals and epistemic modals,
together with the new notion of validity based on the semantics. Some seman-
tic propertied are prepared. Section 3 applies the semantically deﬁned logic to
analyzing modus ponens, showing how empirical data from natural language
arguments are predicted by the logic. Section 4 concludes the paper and sug-
gests some future work.
c
⃝Springer Nature Switzerland AG 2021
P. Baroni et al. (Eds.): CLAR 2021, LNAI 13040, pp. 533–542, 2021.
https://doi.org/10.1007/978-3-030-89391-0_33

534
X. Wen
2
Semantics and Validity
2.1
Semantics
Deﬁnition 1 (Formal language). Given a set At of atoms, the formal lan-
guage LCM for the logic of conditionals and epistemic modals is inductively
deﬁned by the following BNF:
LCM ∋ϕ, ψ:: = p | ¬ϕ | (ϕ ∧ψ) | (ϕ ∨ψ) | (ϕ > ψ) | □ϕ | ♦ϕ,
where p ∈At.
We omit the outermost parentheses of formulas and stipulate that ∧and
∨have priority to >. For instance, (((p ∧q) ∨r) > s) can be shortened as
(p ∧q) ∨r > s. As usual, we often abbreviate Δ ∪{ϕ, . . . , ϕn} as Δ, ϕ, . . . , ϕn,
and {ϕ, . . . , ϕn} as ϕ, . . . , ϕn.
Among the compound formulas, ¬ϕ, ϕ ∧ψ, ϕ ∨ψ, and ϕ > ψ are standard
Boolean formulas, ϕ > ψ represents conditionals in natural language, and □ϕ
and ♦ϕ are epistemic modal formulas, which read ‘it must be the case that ϕ’
and ‘it might be the case that ϕ’, respectively. Formulas without >, □, and ♦
are called Boolean. Formulas without □and ♦are called modal free. Atoms and
negated atoms are called literals. Conditionals whose consequents are literals are
called conditional literals.
The following deﬁnition follows Chellas’ selection models [3], which were
inspired by Stalnaker’s selection models [14].
Deﬁnition 2 (Models). A selection model is a triple M = (W, f, V ), where
W ̸= ∅consists of worlds, V : At →℘(W) is the valuation function, and
f : W ×℘(W) →℘(W) the selection function satisfying the following conditions.
For all w ∈W and X, Y ⊆W,
(id) f(w, X) ⊆X
(cent) w ∈X implies f(w, X) = {w}
(lim) f(w, X) = ∅implies X = ∅
(arr) X ⊆Y and f(w, Y ) ∩X ̸= ∅imply f(w, X) = f(w, Y ) ∩X
A pair (M, w) with w in M is called a pointed model.
A selection function f chooses for each world w and each proposition X (set
of worlds) the closest (or most similar) worlds to w in X. It is not diﬃcult to
verify that the conditions above entail the following two conditions, which are
less intuitive but more familiar in conditional logics. Together with (id) and
(cent), they give rise to Lewis’ conditional logic VC (a.k.a. C1, cf. [7,8]).
(cso) f(w, X) ⊆Y and f(w, Y ) ⊆X imply f(w, X) = f(w, Y )
(pie) f(w, X ∪Y ) ⊆X or f(w, X ∪Y ) ⊆Y or f(w, X ∪Y ) = f(w, X) ∪f(w, Y )

Validity Under Assumptions and Modus Ponens
535
It follows from (cso) and (pie) that f(w, X ∪Y ) = f(w, X) or f(w, X ∪Y ) =
f(w, Y ) or f(w, X ∪Y ) = f(w, X) ∪f(w, Y ), which will be used in the proofs.
To invalidate modus ponens and validate Import-Export, McGee [10] pro-
posed a semantics based on selection models such that a new parameter other
than the pointed model is supplemented to evaluate the truth value of formulas.
The new parameter is a set of hypotheses (we call assumptions), used to keep
track of the antecedents of conditionals. A conditional is true at a pointed model
under a set of assumptions, iﬀthe consequent of the conditional is true at the
pointed model under the set of hypotheses supplemented by the antecedent of
the conditional. This idea is also adopted in our semantics given below.
Deﬁnition 3 (Truth conditions). Given a model M = (W, f, V ), the ternary
satisfaction relation ⊩is deﬁned as follows, in which ϕM,Δ = {w ∈W |
M, w ⊩Δ ϕ}, ΔM,∅= 
δ∈ΔδM,∅, and M, w ⊩ϕ means M, w ⊩∅ϕ.
– M, w ⊩p iﬀw ∈V (p);
– M, w ⊩¬p iﬀw /∈V (p);
– M, w ⊩Δ p iﬀf(w, ΔM,∅) ⊆V (p), where Δ ̸= ∅;
– M, w ⊩Δ ¬p iﬀf(w, ΔM,∅) ⊆W −V (p), where Δ ̸= ∅;
– M, w ⊩Δ ϕ ∧ψ iﬀM, w ⊩Δ ϕ and M, w ⊩Δ ψ;
– M, w ⊩Δ ϕ ∨ψ iﬀM, w ⊩Δ ϕ or M, w ⊩Δ ψ;
– M, w ⊩Δ ϕ > ψ iﬀM, w ⊩Δ,ϕ ψ;
– M, w ⊩Δ □ϕ iﬀfor all u ∈W, M, u ⊩Δϕ;
– M, w ⊩Δ ♦ϕ iﬀfor some u ∈W, M, u ⊩Δ ϕ.
If M is clear from the context, we will simply write ϕΔ for ϕM,Δ, ϕ
for ϕM,∅, and Δ for ΔM,∅respectively. We write M, w ⊩Δ Γ if for all
ϕ ∈Γ, M, w ⊩Δ Γ. Note that the above deﬁnition does not give truth conditions
for all formulas. Speciﬁcally, negation is not deﬁned yet, though negated atoms
are deﬁned. We postpone the truth condition for general negated formulas to
Deﬁnition 4.
The following lemma is just a reformulation of the truth conditions for ∧, ∨, >
, □, and ♦.
Lemma 1. For all models M and Δ ∪{ϕ, ψ, χ} ⊆LCM,
1. ϕ ∧ψΔ = ϕΔ ∩ψΔ
2. ϕ ∨ψΔ = ϕΔ ∪ψΔ
3. ϕ > ψΔ = ψΔ,ϕ
4. □ϕΔ =

W
if ϕΔ = W
∅
otherwise
5. ♦ϕΔ =

W
if ϕΔ ̸= ∅
∅
otherwise
Though the basic idea of the semantics is the same as McGee’s, we highlight
three diﬀerences between McGee’s semantics and ours.
First, following Lewis and pace Stalnaker, we do not assume that the closest
ϕ-worlds to w are unique. Consider a world w in which a circuit has two closed

536
X. Wen
switches A and B in series. Then there are at least two closest worlds to w such
that A or B is open: one is with A open and B closed, the other B open and A
closed. There is no reason to decide that one is closer than the other.
Second, because of the non-uniqueness assumption, we treat negation dif-
ferently. We cannot just deﬁne M, w ⊩Δ ¬ϕ by M, w ⊮Δ ϕ, as in McGee’s
semantics. For if negation is deﬁned like this, then p and ¬p will have asym-
metric truth conditions at w under Δ: one with f(w, Δ) ⊆p and the other
f(w, Δ) ̸⊆p, which is equivalent to f(w, Δ) ∩¬p ̸= ∅. Now the truth
condition for p has a universal structure (all closest Δ-worlds are p-worlds),
whereas for ¬p it has an existential structure (some closest Δ-worlds are ¬p-
worlds), which is unjustiﬁed. To treat negation properly, we deﬁne the truth
conditions of p and ¬p both by the universal structure, and deﬁne compound
negated formulas by reduction as follows.
Deﬁnition 4 (Negation). The truth set of compound negated formulas are
deﬁned inductively as follows. For all models M and Δ ∪{ϕ, ψ} ⊆LCM,
1. ¬¬ϕΔ = ϕΔ
2. ¬(ϕ ∧ψ)Δ = ¬ϕ ∨¬ψΔ
3. ¬(ϕ ∨ψ)Δ = ¬ϕ ∧¬ψΔ 4. ¬(ϕ > ψ)Δ = ϕ > ¬ψΔ
5. ¬□ϕΔ = ♦¬ϕΔ
6. ¬♦ϕΔ = □¬ϕΔ
Remark 1. The above deﬁnition implies that all formulas can be equivalently
transformed into negation normal forms, in which negations are only applied to
atoms. Hence, in the proofs by induction on formulas, we need only consider
negated atoms, without considering arbitrary negated formulas.
The third diﬀerence is that, we allow f(w, X) to be empty, without assuming
some absurd world, and since the empty set is a subset of any set, we do not
need an additional clause to stipulate that ϕ > ψ is true for any ψ if ϕ is
impossible. Its truth is derivable from other clauses in our semantics, as shown
by the following lemma.
Lemma 2. For all model M = (W, f, V ) and Δ ⊆LCM, if Δ = ∅then for all
ϕ ∈LCM, ϕΔ = W.
Proof. By induction on ϕ. It is straightforward when ϕ is Boolean. When ϕ =
α > β, suppose Δ = ∅. Then Δ, α ⊆Δ = ∅, by the inductive hypothesis,
we have α > βΔ = βΔ,α = W. When ϕ = □ψ, by the inductive hypothesis,
ψΔ = W and hence □ψΔ = W by Lemma 1. When ϕ = ♦ψ, by the inductive
hypothesis ψΔ = W ̸= ∅and hence ♦ψΔ = W by Lemma 1.
⊓⊔
Moreover, we extend McGee’s formal language and incorporate modal oper-
ators, whose semantics is deﬁned independently, rather than deﬁned by condi-
tionals as in Stalnaker-Lewisian conditional logics (cf. [14] and [8, p. 22]).
The following lemmas about the semantic properties will be used in the
sequel. The proofs of Lemmas 3–5 are easy and left to the reader.

Validity Under Assumptions and Modus Ponens
537
Lemma 3. For all models M and Δ ∪{ϕ, ψ, χ} ⊆LCM,
1. ϕ > ψ ∧χΔ = ϕ > ψΔ ∩ϕ > χΔ
2. ϕ > ψ ∨χΔ = ϕ > ψΔ ∪ϕ > χΔ
3. ϕ > (ψ > χ)Δ = ϕ ∧ψ > χΔ
Remark 2. Together with Remark 1, Lemma 3 implies that all modal free condi-
tionals can be equivalently transformed into formulas building from conditional
literals, using the operators of conjunction and disjunction.
Lemma 4. For all models M = (W, f, V ) and Δ ∪{ϕ, ψ} ⊆LCM, if ψ is
Boolean then for all w ∈W, M, w ⊩Δ ψ implies f(w, Δ) ⊆ψ.
Lemma 5. For all models M and Δ ∪Δ′ ∪{ϕ} ⊆LCM, if Δ = Δ′, then
ϕΔ = ϕΔ′.
Lemma 6. For all models M and all Δ ∪{ϕ, ψ, χ} ⊆LCM, if χ is modal free,
then χΔ,ϕ ∩χΔ,ψ ⊆χΔ,ϕ∨ψ.
Proof. By induction on χ, noting that we have either f(w, α ∨β) = f(w, α)
or f(w, α ∨β) = f(w, β) or f(w, α ∨β) = f(w, α) ∪f(w, β).
⊓⊔
2.2
Validity
Deﬁnition 5 (Validity). Let Γ ∪Δ ∪{ϕ} ⊆LCM.
1. The inference from Γ to ϕ is valid under Δ (denote Γ ⊨Δ ϕ), if for all pointed
models (M, w), M, w ⊩Δ Γ implies M, w ⊩Δ ϕ, i.e., ΓM,Δ ⊆ϕM,Δ, where
ΓM,Δ = 
γ∈ΓγM,Δ.
2. The inference from Γ to ϕ is valid (denoted Γ ⊨ϕ), if it is valid under ∅; it
is fully valid, if it is valid under any Δ.
3. ϕ is valid under Δ (denoted ⊨Δ ϕ), valid (denoted ⊨ϕ), or fully valid, if the
inference from ∅to ϕ is valid under Δ, valid, or fully valid, respectively.
With the ternary notion of validity, we can distinguish four forms of the
inference from {ϕ, ψ} to χ.
Standard Form ϕ, ψ ⊨χ, which reads: ϕ and ψ imply χ.
Assumptive Form ⊨ϕ,ψ χ, which reads: χ is valid, assuming ϕ and ψ.
Hybrid Form 1 ϕ ⊨ψ χ, which reads: ϕ implies χ, assuming ψ.
Hybrid Form 2 ψ ⊨ϕ χ, which reads: ψ implies χ, assuming ϕ.
The four forms are not always equivalent to each other. An inference can be valid
in one form but not in another. We will see in Sect. 3 that the puzzle concerning
modus ponens can be resolved by distinguishing the four forms of inferences.

538
X. Wen
3
Modus Ponens
Modus ponens for material implication is a fundamental rule in classical logic.
Presumably, it should also be valid for conditionals. Indeed, in conditional logics
proposed by Stalnaker [14] and Lewis [8], the rule ϕ, ϕ > ψ / ψ is always valid.
But McGee [10] gave a famous counterexample to modus ponens for indicative
conditionals, which was about the 1980 US presidential election. Opinion polls
showed that the republican Ronald Reagan was decisively ahead of the demo-
crat Jimmy Carter, who was in turn decisively ahead of the other republican
John Anderson. Then the premises (1a) and (1b) below sound true, while the
conclusion (1c) does not, for if Reagan does not win, Carter will.
(1) (a) If a republican wins the election, then if it’s not Reagan who wins it will
be Anderson.
(b) A republican will win the election.
(c) Therefore, if it’s not Reagan who wins, it will be Anderson.
Based on such examples, McGee argued that when ψ contains embedded con-
ditionals as above, ϕ, ϕ > ψ/ψ is not valid. Another motivation for McGee to
invalidate modus ponens is that, together with some innocuous assumptions, val-
idating both modus ponens and Import-Export leads to collapse of conditionals,
i.e. conditionals are logically indistinguishable from material implication (see [4]
for a proof). Since Import-Export has not been found any convincing counterex-
ample (cf. [6]) and collapse is generally unacceptable, invalidating modus ponens
seems the unique solution to the problem.
Despite the diﬀerences given in Sect. 2.1, our semantics inherits most features
of McGee’s. Modus ponens is still invalid in our semantics, except that with epis-
temic modals augmented, we can formulate more counterexamples. The following
is one based on the same scenario.
(2) (a) If a republican wins the election, then the winner must be Reagan.
(b) A republican will win the election.
(c) Therefore, the winner must be Reagan.
We have good reason to believe that (2a) and (2b) are true. But since we cannot
completely rule out the possibility of Reagan’s lose, (2c) is not true. Thus we
obtain another counterexample to modus ponens. Both counterexamples are
predicted by our semantics, as the following proposition demonstrates.
Proposition 1. Modus ponens is invalid in the following forms, where p, q, r ∈
At,
1. p, p > (q > r) ⊭q > r
2. p, p > □q ⊭□q
Proof. For 1, consider M = (W, f, V ), where W = {w, u, v}, V (p) = {w, u},
V (q) = {u, v}, V (r) = {u}, f(w, {u}) = {u}, f(w, {u, v}) = {v}. Then M, w ⊩p
and M, w ⊩p > (q > r), but M, w ⊮q > r.

Validity Under Assumptions and Modus Ponens
539
For 2, consider M = (W, f, V ), where W = {w, u}, V (p) = V (q) = {w},
f(w, {w}) = f(u, {w}) = {w}. Then M, w ⊩p and M, w ⊩p > □q, but
M, w ⊮□q.
⊓⊔
Nonetheless, giving up modus ponens completely is too hasty. Indeed, we can
keep some forms of modus ponens, as formulated below.
Proposition 2. Modus ponens is valid in the following forms.
1. Standard Form ϕ, ϕ > ψ ⊨ψ, where ψ is Boolean
2. Assumptive Form ⊨ϕ,ϕ>ψ ψ, where ψ is modal free
3. Hybrid Form ϕ > ψ ⊨ϕ ψ
Proof. For 1, given any model M = (W, f, V ) and w ∈W, suppose M, w ⊩ϕ
and M, w ⊩ϕ > ψ. By Lemma 4, we have f(w, ϕ) ⊆ψ. By (cent), we have
f(w, ϕ) = {w}. Then M, w ⊩ψ.
For 2, we prove by induction on ψ. We will prove a stronger claim: if ψ is
modal free, then for any Δ ⊆LCM, ⊨Δ,ϕ,ϕ>ψ ψ. First, it can be veriﬁed that for
any model M, ϕ∩ϕ > p ⊆p and ϕ∩ϕ > ¬p ⊆¬p. When ψ = p ∈At,
for any model M = (W, f, V ) and w ∈W, f(w, Δ, ϕ, ϕ > p) ⊆ϕ∩ϕ > p ⊆
p = V (p). Hence, pΔ,ϕ,ϕ>p = W. It follows that ⊨Δ,ϕ,ϕ>p p. Analogously, we
have ⊨Δ,ϕ,ϕ>¬p ¬p.
When ψ = α ∧β, for any model M = (W, f, V ), α ∧βΔ,ϕ,ϕ>α∧β =
αΔ,ϕ>β,ϕ,ϕ>α, ∩βΔ,ϕ>α,ϕ,ϕ>β = W ∩W = W, where the ﬁrst = is by
Lemma 3 and Lemma 5, and the second = is by the inductive hypothesis.
When ψ = α ∨β, for any model M = (W, f, V ), α ∨βΔ,ϕ,ϕ>α∨β = α ∨
βΔ,ϕ,(ϕ>α)∨(ϕ>β) ⊇α∨βΔ,ϕ,ϕ>α∩α∨βΔ,ϕ,ϕ>β ⊇αΔ,ϕ,ϕ>α∩βΔ,ϕ,ϕ>β =
W ∩W = W, where the ﬁrst = is by Lemma 3 and Lemma 5, the ﬁrst ⊇is by
Lemma 6, and the penultimate = is by the inductive hypothesis.
When ψ = α > β, for any model M = (W, f, V ), α > βϕ,ϕ>(α>β) =
βϕ,ϕ>(α>β),α = βϕ∧α,ϕ∧α>β = W, where the second = is by Lemma 3 and
Lemma 5, and the last = is by the inductive hypothesis.
For 3, given any model M = (W, f, V ) and w ∈W, suppose M, w ⊩ϕ ϕ > ψ.
Then M, w ⊩ϕ,ϕ ψ, i.e. M, w ⊩ϕ ψ. Hence, ϕ > ψ ⊩ϕ ψ.
⊓⊔
The standard form restricted to Boolean formulas is inherited from McGee’s
semantics, while the other two forms can only be formulated in our framework.
Before moving on, let us give two remarks.
Remark 3. The assumptive form does not hold if ψ contains modal operators.
This is because modal formulas may be self-refuting. One can easily verify that
⊭♦p,♦p>p∧♦¬p p ∧♦¬p, since the assumption ♦p > p ∧♦¬p can only be true at
p-worlds. So under this assumption, ♦¬p cannot be true.
Remark 4. The other hybrid form of modus ponens is not valid. More precisely,
ϕ ⊭ϕ>ψ ψ, even if ψ is modal free. One can verify p ⊭p>(q>r) q > r using the
same counter-model for the proof of Clause 1 of Proposition 1.

540
X. Wen
Both counterexamples like (1) and (2) had been objected by Over [11], among
others. Over argued that if the premises of modus ponens have been certainly
assumed, the conclusion cannot be false. This intuition is formulated by the
assumptive form of modus ponens in our semantics. Though it is not generally
valid, its restricted form for the two examples above are valid, as shown by the
following proposition.
Proposition 3. For any p, q, r ∈At,
1. ⊨p,p>(q>r) q > r
2. ⊨p,p>□q □q
Proof. Clause 1 is already contained in Clause 3 of Proposition 2.
For 2, note that p > □q ⊆p > q. Thus, for any model M = (W, V, f) and
w ∈W, f(w, p, p > □q) ⊆p ∩p > □q ⊆p ∩p > q ⊆q, where the last
⊆is by Clause 1 of Proposition 2. Hence, M, w ⊩p,p>□q q for all w ∈W, which
means M, w ⊩p,p>□q □q.
⊓⊔
Now in the literature concerning the validity of modus ponens, often two
notions of validity are distinguished. Mandelkern [9] categorized them as truth-
preserving validity, which is the standard one, and informational validity, which
was defended in [1], based on the semantics initiated by Veltman [15] and devel-
oped by Gillies [5] and Yalcin [16], among others. The two notions of validity yield
two forms of modus ponens. The truth-preserving form reads: if ϕ and ϕ > ψ
are true, then ψ is true. The informational form reads: if ϕ and ϕ > ψ are fully
accepted, then rationality requires ψ to be fully accepted. To better understand
the three forms of modus ponens formulated in our framework, we can roughly
equate the standard form with the truth-preserving form, the assumptive form
with the informational form, and the hybrid form with the combination of the
truth-preserving form and the informational one.
Bledin [2] argues that, though truth-preserving modus ponens may not be
valid, informational modus ponens is still valid. Consider McGee’s example
again. If we fully accept that a republican will win, and that if a republican
wins then if it is not Reagan who wins it will be Anderson, then we must accept
that if Reagan does not win, then Anderson will win. The intuition is similar to
Over’s, which could also be formulated by assumptive modus ponens.
But to dispel the counterexample does not require us to fully accept both
premises. Fully accepting that a republican will win is enough for us to infer
from ‘if a republican wins then if it is not Reagan who wins it will be Anderson’
to its consequent, which is predicted by the validity of the hybrid form of modus
ponens. Note that fully accepting (1a) only does not make the conclusion true
from the other premise, which has been predicted in Remark 4.
We leave the full comparison for future research, but just point out one merit
of our framework. Note that the truth-preserving form and the informational
form of modus ponens in the literature cannot actually be combined directly,
since they rely on diﬀerent notions of validity. One appeals to truth and the
other to acceptance. In our framework, however, we have a ternary notion of

Validity Under Assumptions and Modus Ponens
541
validity, which relies on a ternary notion of truth, so that the two notions of
validity and the two forms of modus ponens can be uniﬁed. Since both truth-
preserving validity and informational validity are inadequate for natural lan-
guage arguments (see e.g. [13] and [12] for criticism of informational validity), a
combination or uniﬁcation of them is desirable.
4
Conclusion and Future Work
We deﬁne a logic for conditionals and epistemic modals, based on McGee’s
ternary notion of truth. The crucial contribution is a ternary notion of valid-
ity, by which an inference is not (in)valid per se, but (in)valid under a set of
assumptions. Thus, an inference has three diﬀerent forms: standard form (no
premises are assumed), assumptive form (all premises are assumed), and hybrid
form (some premises are assumed), which are not equivalent to each other.
Armed with this diﬀerentiation, we give an analysis of the puzzle concerning
the (in)validity of modus ponens. This is a preliminary attempt to unify two
kinds of validity proposed in the literature. Future work includes a full compar-
ison to existing works, and applications of the new notion of validity to other
puzzles.
Acknowledgements. I thank two referees for their helpful comments. The work
was supported by National Social Science Foundation of China for key projects (No.
18ZDA033).
References
1. Bledin, J.: Logic informed. Mind 123(490), 277–316 (2014)
2. Bledin, J.: Modus ponens defended. J. Philos. 112(2), 57–83 (2015)
3. Chellas, B.F.: Basic conditional logic. J. Philos. Log. 4(2), 133–153 (1975)
4. Gibbard, A.: Two recent theories of conditionals. In: Harper, W.L., Stalnaker, R.,
Pearce, G. (eds.) Ifs: Conditionals, Belief, Decision, Chance, and Time, pp. 211–
248. Reidel, Dordrecht (1981)
5. Gillies, A.: Epistemic conditionals and conditional epistemics. Noˆus 4, 585–616
(2004)
6. Khoo, J., Mandelkern, M.: Triviality results and the relationship between logical
and natural languages. Mind 128(510), 485–526 (2019)
7. Lewis, D.: Completeness and decidability of three logics of counterfactual condi-
tionals. Theoria 37(1), 74–85 (1971)
8. Lewis, D.: Counterfactuals. Harvard University Press (1973)
9. Mandelkern, M.: A counterexample to modus ponenses. J. Philos. 117(6), 315–331
(2020)
10. McGee, V.: A counterexample to modus ponens. J. Philos. 82(9), 462–471 (1985)
11. Over, D.: Assumptions and the supposed counterexamples to modus ponens. Anal-
ysis 47(3), 142–146 (1987)
12. Santorio, P.: Trivializing informational consequence. Philos. Phenomenol. Res.
(forthcoming)

542
X. Wen
13. Schulz, M.: Epistemic modals and informational consequence. Synthese 174(3),
385–395 (2010)
14. Stalnaker, R.: A Theory of conditionals. In: Rescher, N. (ed.) Studies in Logical
Theory, pp. 98–112. Basil Blackwell Publishers (1968)
15. Veltman, F.: Defaults in update semantics. J. Philos. Log. 25(3), 221–261 (1996)
16. Yalcin, S.: Epistemic modals. Mind 116(464), 983–1026 (2007)

Entailments with Sentential Predicates
Richard Zuber(B)
Ray´e des cadres du CNRS, Paris, France
Richard.Zuber@linguist.univ-paris-diderot.fr
Abstract. A simple model accounting for entailments between senten-
tial predicates with propositional attitude verbs is proposed. In this
model no reference to propositions is made. Sentential predicates denote
speciﬁc sets of sentences (of a given natural language). This approach
avoids the problem of intensionality of propositional attitude operators
and permits to use many tools from the generalised quantiﬁer theory.
1
Introduction
In this paper I discuss, in a preliminary way, properties which give rise to spe-
ciﬁc entailment relations holding between sentences formed from propositional
attitude verbs and operators. I discuss in particular the relation of presupposi-
tion of factive verbs and the entailment associated with the so-called neg-raising
verbs. The propositional operators are of the form A V that/whether where A is
a proper name and V a verb of propositional attitudes. I will also ignore the fact
that such verbs can take quantiﬁcational noun phrases as grammatical subjects.
They are denoted by O, with additional information concerning the comple-
mentizer they take. The class of all propositional operators, which are of category
S/S is denoted by PO. The set PA (propositional attitude operator). is a sub-
set of PO. A linguistic object expressing a PO in a given language and taken
without the complementizer is called a sentential predicate (SP)
Factive predicates, when completed by the grammatical subject referring to a
human, form sentential operators which presuppose the truth of their sentential
argument: positive forms of sentences formed from factive predicates and their
(natural) negations both entail the complement sentence: (1a) and (1b) both
entail that sentence P is true:
(1) a. Leo knows/remembers that P.
b. Leo does not know/remember that P.
Consequently we will consider that Leo knows that and Leo remembers that are
factive PA operators, that is operators presupposing their sentential argument.
The verbs remember and forget are considered as factives.
Another case of intensional sentence-embedding predicates with speciﬁc
entailments concerns neg-raising predicates: when negated sentences with such
predicates imply a corresponding sentence in which the negation takes scope in
the embedded clause: (2a) entails (2b):
Thanks to at least one referee for useful comments.
c
⃝Springer Nature Switzerland AG 2021
P. Baroni et al. (Eds.): CLAR 2021, LNAI 13040, pp. 543–550, 2021.
https://doi.org/10.1007/978-3-030-89391-0_34

544
R. Zuber
(2) a. Leo does not think that life is sad.
b. Leo thinks that life is not sad.
In the above example we have an intensional operator, formed from the verb
of propositional attitude to think. This is not the case in general: some neg-
transportable operators are not formed from verbs of propositional attitude: the
operator It is true (false) that is neg-transportable but is not a propositional
attitude operator. Observe that (3) entails neither (2a) nor (2b):
(3) It is not true that Leo thinks that life is sad
Given the role of the negation we have to take into account precisely the fact
that it has to apply to intensional sentential operators and to make clear what
the notion of intensionality of such sentential operators is.
Semantic relations between PA operators are related to principles expressing
knowledge of the attitude by agents. They echo various “iteration principles”
used in epistemic logics. For instance the so-called KK principle says that for
any proposition P if one knows that P then one knows that one knows that P.
Thus I will assume the following attitudinal self-awareness principle (ASAP):
ASAP: If any agent has a speciﬁc propositional attitude then he/she knows that
he/she has this attitude.
The following examples illustrate what I mean by the ASAP: we suppose
that (4) entails (5), when taken in de dicto readings:
(4) Bo believes/knows/regrets/understands that life is sad.
(5) Bo knows that she believes/knows/regrets/understands that life is sad.
Propositional operators are noted O, O1, O2, Q. Propositional operators
formed from verbs whose subject NP denotes a are noted Oa. The set of true
sentences is noted T and any subset of T is called a veridical operator and the
set of such operators is noted V ER. The set of sentences that the agent a knows
to be true is noted Ka and the set of sentences of which a knows whether they
are true or not is noted KWa. If O is a propositional operator then S ∈O means
that sentence formed from O and having S as propositional argument is true.
Thus S ∈T means It is true that S and S ∈Ka means that a knows that S is
true. Moreover S ∈O and S /∈O will be considered as sentences. The distinction
between variables in the object language and metalanguage will be ignored.
In D1 we have a semantic deﬁnition of propositional attitude operators:
Deﬁnition 1. A propositional operator Oa is a propositional attitude operator,
Oa ∈PA, iﬀS ∈Oa entails a knows whether S ∈Oa, for any sentence S
Thus the agent has to be aware that he has the attitude expressed by the
main verb of the operator. Since the operators such as a wrote that and a proved
that do not have this property they are not PA operators.
In what follows we will consider the entailment between PO and not the
entailment between sentences.

Entailments with Sentential Predicates
545
2
Propositional Attitude Operators
The universe from which we construct the denotational algebra of PA operators
consists of the set of (declarative) sentences of a given, ﬁxed, natural language.
To be more precise we exclude from the universe sentences whose interpretation
is context dependent. In particular we exclude sentences with free variables,
indexicals and pronouns externally bound. Thus denotations of propositional
operators will be constructed from elements of the power set algebra of the set of
sentences whose interpretation does not depend on the context. If Σ is the set of
sentences of, say, English, the ℘(Σ) can be considered as a Boolean algebra whose
elements are sets of sentences and Boolean operations correspond to operations
on sets of sentences. The unit of this algebra is the set Σ itself and the zero
element is the empty set. The entailment corresponds to the (generalised) cross-
categorial entailment (Keenan and Faltz 1985) which is just the partial order of
the corresponding Boolean algebra, the denotational algebra of PO.
The POs are interpreted as sets of sentences. Informally, one can consider
that PO It is true that denotes the set T and PO It is false that denotes the
set of false sentences. The reason is that linguistic objects of category S/S can
be lifted and become of category S/(S/S). Consequently this interpretation is
not context dependent and POs denote a set of sentences, taken independently
of their truth value.
Thus to construct sets of sentences constituting denotations propositional
operators we use the set of (declarative) sentences of a given natural language.
We distinguish negated and non-negated sentences. Negated sentences are sen-
tences of the form It is not true that S, where S is a sentence. They are noted
nS and the set of negated sentences is noted NS. There is obvious semantic
dependence between S and nS: S is true iﬀnS is false. We also need a function
corresponding to the deletion of the negation of a negated sentence. Thus:
Deﬁnition 2. Let S ∈NS. Then (n)S = S0 if S = nS0 and nS otherwise.
Thus (n)S is the sentence obtained from a negated sentence by deleting its
negation: (n)(nS) = S. We will also use other Booleanly complex sentences.
Thus if S1 and S2 are sentences then S1 or S2 is a sentence. The semantics of
such complex sentences is induced by the semantics of the corresponding Boolean
connector.
The negation nS of S in D2 corresponds to a syntactic negation. We need also
to deﬁne semantic negations. Since propositional operators are sets of Boolean
objects they have two negations, the Boolean complement and the set of their
negated elements:
Deﬁnition 3. Let O be a propositional operator. Then ¬O, the Boolean com-
plement of O is deﬁned as ¬O = {S : S /∈O}. The post-negation of O, noted
O¬, is deﬁned as O¬ = {nS : S ∈O ∧S /∈NS} ∪{(n)S : nS ∈O}.
Informally, we get the post-negation of an element by replacing all sentence
which belong to it by their negations. For instance the relationship between the
operators Ka and KWa can be expressed as KWa = Ka ∪Ka¬.

546
R. Zuber
For Booleanly complex propositional operators the following holds:
Fact 1. Let O1 and O2 be propositional operators. Then: (i) (O1 ∩O2)¬ =
O1¬ ∩O2¬, (ii) (O1 ∪O2)¬ = O1¬ ∪O2¬, (iii) (O¬)¬ = O.
The ASAP concerns the positive, non-negated form PA operators. I will
consider, in addition that there is a negation of PA operators which preserves
the attitudinal property of PA operators: PA operators negated by this negation
are also PA operators. Syntactically such attitude preserving negation is not a
propositional negation but a negation of the category (S/S)/(S/S) and negated
PA operators also satisfy ASAP. It follows from this that ∼O, the attitude
preserving negation of O, satisﬁes the following necessary condition:
NASAP: For any sentence S and any propositional operator Oa, if S ∈∼Oa
then S ∈¬Oa and a knows that S /∈Oa.
The positive and the negative versions of the ASAP taken jointly allow us
to specify what PA operators presuppose. The conditions expressed by ASAP
and NASAP belong to logical, and more generally linguistic, competence of the
agent having a speciﬁc propositional attitude. For us they are characteristic
properties of (positive and negative) PA operators. They can be considered as
generalisations of the KK principle.
Recall that propositional operators (PO) denote sets of sentences and thus
the set of PA operators is a sub-set of PO. Given ASAP and NASAP principles
a PA operator is deﬁned as follows:
Deﬁnition 4. A propositional operator Oa is a propositional attitude operator,
or Oa ∈PA, iﬀ∀S((S ∈Oa) →KWa(S ∈Oa) ∧(S /∈Oa) →(KWa(S /∈Oa))
The attitudinal character of PA operators is preserved by the post-negation:
Fact 2. If Oa ∈PA iﬀOa¬ ∈PA.
The reason is that a knows whether S iﬀa knows whether nS. The Boolean
complement does not need to preserve the attitudinal character of PA operators.
Thus a propositional operator based on the agent a is a set of sentences such
that a knows which sentences belong to it. A non-trivial propositional operator
is a set of sentences which is neither empty nor equal to the set of all sentences.
Negative PA operators are obtained from the positive ones by applying to
them a speciﬁc “attitude inverting” negation. Syntactically this negation takes a
propositional operator as argument and gives a propositional operator as result;
it is of category (S/S)/S/S). Semantically, such a negation preserves the atti-
tudinal force of the operator to which it applies. For this purpose we can use
the ASAP principle and deﬁnition D4. We have the following deﬁnition of the
negation ∼of a PA operator Oa:
Deﬁnition 5. Let Oa ∈PA. Then ∼Oa = {S : S /∈Oa ∧(S /∈Oa) ∈KWa}.
The negation deﬁned in D5 will be called PA preserving negation. It is
stronger than “ordinary” negation corresponding to the Boolean complement.
We can now make precise the sense in which PA operators are intensional:

Entailments with Sentential Predicates
547
Deﬁnition 6. Oa is normally intensional, Oa ∈NI, iﬀ∀S(S ∈Oa →∃S0(S ≡
S0) ∧S0 /∈Oa)
A typical (and basic) NI operator is the operator Ka. The reason is that
a human agent is “strongly non-omniscient”: if an agent knows the truth of a
given sentence then there is always another sentence with the same logical value
as a given sentence and such that the agent is not aware of its truth value.
Given that PA operators are deﬁned with the help of K, we have:
Proposition 1. Any PA operator is normally intensional.
Proof. : Suppose, a contrario that Oa /∈NI. Then, by deﬁnition D6, there exists
a sentence S such that S ∈Oa and for all sentences S0 with the same truth value
as S we would have S0 ∈Oa. But this is impossible because Oa ∈PA.
⊓⊔
Thus PA negation preserves normal intensionality.
We deﬁne now various semantic relations discussed above. For simplicity all
PA operators are based an a ﬁxed agent a and thus Oa, Qa, O1, O2, etc. denote
PA operators all based on the agent a. First we deﬁne a presupposition:
Deﬁnition 7. Let O1 be a PA operator and O2 be a propositional operator. Then
O1 presupposes O2 iﬀO1 ⊆O2 and ∼O1 ⊆O2
The following facts are obvious:
Fact 3. (i) Any PA operator Oa presupposes Oa∪∼Oa, (ii) Any PA operator
Oa presupposes {S : (S ∈Oa) ∈KWa}, (iii) If O1 presupposes O2 and O2 ⊆O3
then O1 presupposes O3.
It follows from fact 3 that any PA operator Oa has a presupposed part, the
subset {S : (S ∈Oa) ∈KWa}. This set will be called PP(Oa) - presupposed part
of Oa. The important point is that Oa∪∼Oa ̸= T and thus the presupposition
indicated in Fact 3 (i) is not trivial.
Factives are speciﬁc presupposing PA operators:
Deﬁnition 8. PA operator Oa is factive, Oa ∈FACT, iﬀOa presupposes T.
The attitude preserving negation also preserves factivity:
Fact 4. Oa is factive iﬀ∼Oa is factive.
A more interesting property of presupposing operators is indicated in
Proposition 2. Any veridical PA operator is factive.
Proof. : (after Zuber (2011). We have to show that ∼Oa ⊆T. Suppose a
contrario that this is not the case. Then there exist S such that S ∈∼Oa and
S /∈T. Since ∼Oa is a PA operator, given Proposition 1, it is also normally
intensional. This means that there exist a sentence S0 which is false (because S
is false) and such that S0 /∈∼Oa. But then, given the deﬁnition of attitudinal
negation and the fact that Oa ∈NI, we have S0 ∈Oa. Contradiction, since Oa
is veridical.
⊓⊔

548
R. Zuber
The relation between knowledge and factivity is indicated in:
Proposition 3. If Oa ∈PA and Oa ⊆Ka or Oa ⊆∼Ka then Oa is factive.
Proof. : Observe that if Oa ⊆Ka then Oa is veridical and thus, given Proposition
2, Oa is factive. Similarly, if Oa ⊆∼Ka then Oa is veridical and thus factive. ⊓⊔
To illustrate Proposition 3 observe that: know that, realise that, reveal that
and remember that entail know that. Similarly forget, not remember and not
know entail not know.
Factivity relates propositional operators to the truth of their arguments since
factive operators are veridical ones. Another class of propositional operators
related to the truth of their arguments is the class of operators that I will call,
following Westerst˚ahl (2012), midpoint operators (MP operators):
Deﬁnition 9. O is a midpoint operator, O ∈MP, iﬀO = O¬.
MP operators can be deﬁned as in Fact 5:
Fact 5. O ∈MP iﬀ∀S(S ∈O) ≡(nS ∈O).
Given the properties of post-negation and deﬁnition D9, the set of MP oper-
ators is closed with respect to Boolean operations and the post-negation:
Fact 6. If O1, O2 ∈MP then ¬O1 ∈MP, O1¬ ∈MP, (O1 ∪O2) ∈MP and
(O1 ∩O2) ∈MP.
Facts 5 and 6 allow us to show that MP operators are speciﬁc unions and
intersections of sets of sentences as indicated in:
Proposition 4. A propositional operator O is a MP operator iﬀthere exists a
propositional operator Q such that O = Q ∪Q¬ (or O = Q ∩Q¬).
Proof. The implication from right to left is obvious since it follows from the
deﬁnition of MP that Q ∪Q¬ and Q ∩Q¬ are MP operators.
To prove the implication from left to right we use Fact 5. We decompose
the set O into two sets, the set of non-negated sentences which are its elements
and the set of the corresponding negated sentences. The ﬁrst set of sentences
constitutes a propositional operator, say Q and the second set constitutes the
operator Q¬. The second disjunct of the necessary condition of the proposition
is a consequence of Fact 6.
⊓⊔
Thus a MP operator O is decomposable into Q ∪Q¬ or into Q ∩Q¬ or that
it is decomposable into a disjunctive or into a conjunctive form.
The set MP has an empirically important subset of propositional operators
that I will call indirectly truth telling operators:
Deﬁnition 10. O is indirectly truth telling operator, O ∈ITT for short, iﬀ
O ∈MP and O is decomposable into Q ∪Q¬ and Q ∈V ER.

Entailments with Sentential Predicates
549
Thus ITT operators are MP operators that are composed of two parts one
containing only true sentences and one containing only false ones.
Deﬁnition of MP operators suggests that there may be some propositional
operators in NLs which can be decomposed into their disjunctive form. This is
indeed the case and it is related, in English, to the distinction between whether-
clauses and that-clauses. One observes that many operators taking whether com-
plementizer can be decomposed into disjunctive form:
(6) a. Bo told/informed Dan whether Lea left (or not).
b. Bo informed Dan that Lea left or Bo told Dan that Lea did not leave.
(7) a. Bo remembers whether Lea left (or not).
b. Bo remembers that Lea left or Bo remembers that Lea did not leave.
In the above examples the disjunction indicated in parenthesis is not a dis-
junction between sentences but an exclusive disjunction between propositional
operators, The above examples show that operators based on tell whether, inform
whether and remember whether are all MP operators. However, there is a diﬀer-
ence between tell and inform whether on the one hand, and know and remember
whether on the other: only the second group belongs to the ITT class.
We have now enough tools to study the class of neg-transportable operators:
Deﬁnition 11. Let Oa be a PA operator. Then Oa is neg-transportable, Oa ∈
NTR for short, iﬀ∼Oa ⊆Oa¬.
For neg-transportable operators we have the following propositions:
Proposition 5. No factive operator is neg-transportable.
Proof. : Suppose Oa ∈FACT ∩NTR. Then ∼Oa ⊆T since Oa ∈FACT and
∼Oa ⊆Oa¬, since Oa ∈NTR. Contradiction, because Oa¬ ∩T = ∅.
⊓⊔
Proposition 6. No neg-transportable operator is a midpoint operator.
Proof. Suppose a contrario that some Oa ∈NTR ∩MP. Then ∼Oa ⊆Oa¬.
Since Oa ∈MP we have Oa¬ = Oa. Hence ∼Oa ⊆Oa. Contradiction.
⊓⊔
The class of NTR operators can be equivalently deﬁned as in:
Proposition 7. Oa is neg-transportable iﬀOa presupposes Oa ∪Oa¬.
Proof. (a) Suppose Oa ∈NTR. Since Oa ∈PA given fact 3, Oa presupposes
Oa∪∼Oa. But then, since Oa ∈NTR, Oa presupposes Oa ∪Oa¬.
(b) Suppose now that Oa presupposes Oa ∪Oa¬. We have to show that
Oa ∈NTR. Given the supposition we have ∼Oa ⊆Oa ∪Oa¬. Given that
Oa∩∼Oa = ∅, we have ∼Oa ⊆Oa¬ and thus Oa ∈NTR.
⊓⊔
The following fact is an obvious consequence of Proposition 7:
Fact 7. Oa ∈NTR iﬀOa¬ ∈NTR.

550
R. Zuber
The presupposition indicated in P 8 corresponds to the excluded middle pre-
supposition (EMP). Thus EMP is equivalent to neg-transportability, and, given
Fact 3, is a particular case of the presupposition proper to PA operators in
general.
The EMP corresponds to the truth expressed by the completeness:
Deﬁnition 12. The propositional operator O is complete, O ∈CMPL, iﬀfor
any sentence S, either S ∈O or nS ∈O.
A relation between completeness and neg-transportability is indicated in:
Proposition 8. Any complete PA operator is neg-transportable.
Proof. Let Oa ∈CMPL and, a contrario Oa /∈NTR. Then for some S we have
S ∈∼Oa and S /∈Oa¬. Hence nS /∈Oa. But then, since Oa is complete, S ∈Oa.
Contradiction.
⊓⊔
Thus no (non trivial) factive operator is complete.
3
Conclusion
Constructions with verbs expressing propositional attitude play an important
role in reasoning. The leading approach in the semantics of such constructions is
propositionalism: denotations of clausal complements in such constructions are
deﬁned with the help of propositions or sets of propositions. This means that
propositional operators based on proper nouns denote relations between individ-
uals and sets of propositions. In this note I propose a sententialist approach to
the semantics of propositional attitude operators. In this approach the universe
of the model for propositional attitude operators and predicates they form is
constructed from the set of sentences of a given natural language. This approach
avoids the basic diﬃculty meet by of the propositionalists approach, which is the
intensionality of PA operators (cf. Partee 1982) and, at the same time allows us
to use various formal tools from the generalised quantiﬁer theory. It has also an
additional explanatory power since it leads to a simple explanation of various
constraints on the semantic relations between PA operators.
References
Keenan, E.L., Faltz, L.M.: Boolean Semantics for Natural Language. D. Reidel Pub-
lishing Company, Dordrecht (1985)
Partee, B.H.: Belief-sentences and the limits of semantics. In: Peters, S., Saarinen, E.
(eds.) Processes, Beliefs, and Questions, pp. 87–106. D. Reidel Publishing Company
(1982)
Westerst˚ahl, D.: Midpoints. In: Graf, T., et al. (eds.) Theories of Everything, pp. 427–
439. UCLA (2012)
Zuber, R.: Factives and intensionality. In: Onada, T., Bekki, D., McCready, E. (eds.)
JSAI-isAI 2010. LNCS (LNAI), vol. 6797, pp. 104–114. Springer, Heidelberg (2011).
https://doi.org/10.1007/978-3-642-25655-4 9

Author Index
Baldoni, Matteo
60
Baroni, Pietro
169
Bassiliades, Nick
417
Bentzen, Bruno
459
Beuselinck, Vivien
127
Bikakis, Antonis
417
Black, Elizabeth
437
Budán, Maximiliano C. D.
20
Calegari, Roberta
40
Cerutti, Federico
169
Chen, Jinsheng
468
Chen, Weiwei
79
Cobo, Maria Laura
20
Cramer, Marcos
94
Čyras, Kristijonas
209
Dauphin, Jérémie
112
Delobelle, Jérôme
127
Diller, Martin
147
Du, Wenjing
3
Escañuela Gonzalez, Melisa G.
20
Fazzinga, Bettina
477
Flouris, Giorgos
417
Gabbay, Dov
224
Gaggl, Sarah Alice
147
Galassi, Andrea
477
Gao, Yan
486
Giacomin, Massimiliano
169
Giordano, Laura
60
Gorczyca, Piotr
147
Guo, Fan
486
Hampson, Christopher
437
Herzig, Andreas
190
Kampik, Timotheus
209, 224
Lagasquie-Schiex, Marie-Christine
244
Li, Chonghui
284
Li, Juan
486
Li, Yanjun
266
Liao, Beishui
284, 468
Liu, Xinghan
302
Liu, Zhengtao
486
Lorini, Emiliano
302
Lyon, Tim S.
495
Mailly, Jean-Guy
322
Martínez, Diego I.
20
Modgil, Sanjay
437
Niu, Zihan
3
Okubo, Tamon
397
Patkos, Theodore
417
Pease, Adam
504
Pezlar, Ivo
513
Plexousakis, Dimitris
417
Punčochář, Vít
342
Rienstra, Tjitze
112
Robles, Gemma
362
Sartor, Giovanni
40, 224
Satoh, Ken
60
Sedlár, Igor
342
Simari, Guillermo R.
20
Spaans, Jeroen Paul
377
Spörl, Yannick
94
Takahashi, Kazuko
397
Torroni, Paolo
477

Urbański, Mariusz
521
van der Torre, Leendert
112, 468
Vassiliades, Alexandros
417
Vesic, Srdjan
127
Wen, Xuefeng
533
Xiao, Fei
486
Xiong, Minghui
3
Xydis, Andreas
437
Yuste-Ginel, Antonio
190
Żmójdzin, Zoﬁa
521
Zuber, Richard
543
552
Author Index

