Bayesian Emulation for Sequential Modeling,
Inference and Decision Analysis
by
Kaoru Irie
Department of Statistical Science
Duke University
Date:
Approved:
Mike West, Supervisor
David L. Banks
Surya T. Tokdar
Andrew Cron
Dissertation submitted in partial fulﬁllment of the requirements for the degree of
Doctor of Philosophy in the Department of Statistical Science
in the Graduate School of Duke University
2016

Abstract
Bayesian Emulation for Sequential Modeling, Inference and
Decision Analysis
by
Kaoru Irie
Department of Statistical Science
Duke University
Date:
Approved:
Mike West, Supervisor
David L. Banks
Surya T. Tokdar
Andrew Cron
An abstract of a dissertation submitted in partial fulﬁllment of the requirements for
the degree of Doctor of Philosophy in the Department of Statistical Science
in the Graduate School of Duke University
2016

Copyright c⃝2016 by Kaoru Irie
All rights reserved

Abstract
Advances in three related areas of state-space modeling, sequential Bayesian learn-
ing, and decision analysis are addressed, with core statistical challenges of scalability
and associated dynamic sparsity. Research presented in these three areas empha-
sizes the common theme of Bayesian model emulation: solving challenging analy-
sis/computational problems using creative model emulators. This idea deﬁnes theo-
retical and applied advances in non-linear, non-Gaussian state-space modeling, dy-
namic sparsity, decision analysis and statistical computation, across linked contexts
of multivariate time series and dynamic networks studies. Examples and applications
in ﬁnancial time series and portfolio analysis, macroeconomics and internet studies
from computational advertising demonstrate the utility of the core methodological
innovations.
Chapter 1 summarizes the three areas/problems and the key idea of Bayesian em-
ulation in those areas. Chapter 2 discusses the sequential analysis of latent threshold
models with use of emulating models that allow for analytical ﬁltering to enhance
the eﬃciency of posterior sampling. Chapter 3 examines a novel emulation approach
in decision analysis, using synthetic statistical models to deﬁne computational ap-
proaches to solving optimization problems, and evaluating its performance in the
context of sequential portfolio optimization.
Chapter 4 develops sets of eﬃcient
sub-models for counts/ﬂows of streaming data on networks, and exploits them in
emulation of more structured inter-dependent network ﬂow models, with studies of
iv

internet data in e-commerce. Chapter 5 reviews and summarizes these research ad-
vances, and adds pointers to potential future directions.
v

To my family
vi

Contents
Abstract
iv
List of Tables
xi
List of Figures
xii
List of Abbreviations and Symbols
xvii
Acknowledgements
xix
1
Introduction
1
2
Sequential Analysis and Bayesian Model Emulation for Dynamic
Latent Threshold Models
4
2.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4
2.2
Model
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5
2.2.1
Latent Threshold Models . . . . . . . . . . . . . . . . . . . . .
5
2.2.2
Challenges to Sequential Analysis . . . . . . . . . . . . . . . .
6
2.3
Sequential Importance Sampling and Model Emulation . . . . . . . .
7
2.3.1
SIS and Emulating Models
. . . . . . . . . . . . . . . . . . .
7
2.3.2
Choices of LTM Emulators . . . . . . . . . . . . . . . . . . . .
8
2.3.3
Comparison of Emulators
. . . . . . . . . . . . . . . . . . . .
11
2.4
Sequential Learning with Fixed Parameters and Volatilities
. . . . .
13
2.4.1
Particle Learning for AR(1) Parameters
. . . . . . . . . . . .
13
2.4.2
Auxiliary Particle Filter for Latent Threshold
. . . . . . . . .
14
vii

2.4.3
Volatility Models . . . . . . . . . . . . . . . . . . . . . . . . .
14
2.4.4
Sequential Posterior Update . . . . . . . . . . . . . . . . . . .
15
2.5
Application: US Macroeconomic Study . . . . . . . . . . . . . . . . .
18
2.5.1
Latent Thresholded TV-VAR Models . . . . . . . . . . . . . .
19
2.5.2
Posterior Analysis
. . . . . . . . . . . . . . . . . . . . . . . .
22
2.5.3
Comparison . . . . . . . . . . . . . . . . . . . . . . . . . . . .
28
2.6
Summary Comments . . . . . . . . . . . . . . . . . . . . . . . . . . .
31
2.7
Appendix: Technical Details of SMC for LTMs
. . . . . . . . . . . .
34
2.7.1
Forward Filtering with Emulators
. . . . . . . . . . . . . . .
34
2.7.2
Particle Learning . . . . . . . . . . . . . . . . . . . . . . . . .
35
2.7.3
Auxiliary Particle Filter
. . . . . . . . . . . . . . . . . . . . .
36
2.7.4
Extension to Stochastic Volatility . . . . . . . . . . . . . . . .
37
2.8
Appendix: Supplemental Figures on Parameter Learning . . . . . . .
38
3
Bayesian Emulation in Decision Analysis: Sequential, Multi-Step
Portfolio Optimization
42
3.1
Emulation by Synthetic Models in General Decision Analysis
. . . .
42
3.2
Introduction: Sequential Portfolio Optimization . . . . . . . . . . . .
44
3.3
Statistical Model Emulation of Expected Loss Functions
. . . . . . .
48
3.3.1
Settings and Notation
. . . . . . . . . . . . . . . . . . . . . .
48
3.3.2
Dynamic Linear Models for Quadratic Loss . . . . . . . . . . .
49
3.3.3
FFBS for Posterior Modes . . . . . . . . . . . . . . . . . . . .
51
3.4
Laplace State Space Models and Implied Loss Function . . . . . . . .
52
3.4.1
Synthetic Models and EM Algorithm . . . . . . . . . . . . . .
53
3.4.2
Another Laplace Factor for Non-Negativity Constraint
. . . .
56
3.5
Marginalization of Loss Functions . . . . . . . . . . . . . . . . . . . .
58
3.5.1
Joint and Marginal Loss Functions
. . . . . . . . . . . . . . .
58
viii

3.5.2
Marginal Laplace Loss Function and Mode Searching . . . . .
60
3.6
Application: FX Commodity Dataset . . . . . . . . . . . . . . . . . .
62
3.6.1
Dataset
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
62
3.6.2
Models for Prediction . . . . . . . . . . . . . . . . . . . . . . .
62
3.6.3
Evaluation by Cumulative Returns
. . . . . . . . . . . . . . .
63
3.6.4
Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
64
3.7
Summary Comments . . . . . . . . . . . . . . . . . . . . . . . . . . .
72
3.8
Appendix: Forward Filtering with Multiple Observations . . . . . . .
74
3.8.1
Forward Filtering
. . . . . . . . . . . . . . . . . . . . . . . .
74
3.8.2
Two Observational Equations with the Common State
. . . .
74
3.8.3
Computational Eﬃciency
. . . . . . . . . . . . . . . . . . . .
77
3.9
Appendix: Exact Shrinkage in EM Algorithm
. . . . . . . . . . . . .
78
3.10 Appendix: Posterior Marginal Mode of Laplace Models . . . . . . . .
79
3.10.1 Gibbs Sampler and Maximization for Marginal Models
. . . .
79
3.10.2 Sum-to-One Constraint . . . . . . . . . . . . . . . . . . . . . .
80
3.10.3 Realization of Exact Zero Weights and Transitions
. . . . . .
82
3.11 Appendix: Dynamic Dependence Network Models . . . . . . . . . . .
83
3.12 Appendix: Supplemental Analysis . . . . . . . . . . . . . . . . . . . .
86
3.12.1 Choice of Tuning Parameters
. . . . . . . . . . . . . . . . . .
86
3.12.2 Additional Figures for Proﬁled and Marginal Portfolios . . . .
89
4
Emulation of Dynamic Gravity Model by Bayesian Dynamic Flow
Models
91
4.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
91
4.2
Bayesian Dynamic Flow Models . . . . . . . . . . . . . . . . . . . . .
93
4.2.1
Forward Filtering and Backward Sampling . . . . . . . . . . .
94
4.2.2
Marginal Likelihoods and Optimal Discount Factor . . . . . .
97
ix

4.2.3
Generalized Gamma Random Walk and Power Discount
. . .
99
4.2.4
Extension to Multinomial-Dirichlet State-Space Models
. . .
99
4.3
Dynamic Gravity Models
. . . . . . . . . . . . . . . . . . . . . . . . 102
4.3.1
Identiﬁcation
. . . . . . . . . . . . . . . . . . . . . . . . . . . 104
4.3.2
Identiﬁcation by a Reference Flow . . . . . . . . . . . . . . . . 105
4.3.3
Identiﬁcation by Geometric Means
. . . . . . . . . . . . . . . 106
4.3.4
Computational Problems in Practice
. . . . . . . . . . . . . . 107
4.3.5
Alternative Identiﬁcation Strategy under Sparsity . . . . . . . 109
4.4
Dependent Gravity Model and MCMC . . . . . . . . . . . . . . . . . 110
4.5
Application: Analysis of FoxNews Website Access Records . . . . . . 112
4.5.1
Study of Internet Traﬃc Flow . . . . . . . . . . . . . . . . . . 112
4.5.2
Context and Data
. . . . . . . . . . . . . . . . . . . . . . . . 113
4.5.3
BDFM Analysis of FoxNews Data
. . . . . . . . . . . . . . . 116
4.5.4
DGM Analysis of FoxNews Data
. . . . . . . . . . . . . . . . 121
4.5.5
Comparison Across Days . . . . . . . . . . . . . . . . . . . . . 126
4.6
Summary Comments . . . . . . . . . . . . . . . . . . . . . . . . . . . 128
4.7
Appendix: FFBS for Poisson-Gamma Models
. . . . . . . . . . . . . 132
4.7.1
Forward Filtering
. . . . . . . . . . . . . . . . . . . . . . . . 132
4.7.2
Backward Sampling
. . . . . . . . . . . . . . . . . . . . . . . 134
5
Concluding Remarks
135
Bibliography
142
Biography
148
x

List of Tables
2.1
Log-Marginal Likelihoods of emulators.
. . . . . . . . . . . . . . . . . .
28
2.2
Multistep RMSFEs for 3 variables with MC errors.
. . . . . . . . . . . .
32
3.1
List of currencies, commodities and indeces. . . . . . . . . . . . . . . . .
62
3.2
Parental sets used in prediction. . . . . . . . . . . . . . . . . . . . . . .
85
xi

List of Figures
2.1
US macroeconomic indices. From top to bottom, the inﬂation, unemploy-
ment rate and hort-term nominal interest rate in US from 1963 to 2011.
This is the same dataset as used in Nakajima and West (2013a).
. . . . .
18
2.2
Posterior estimate of B1t and the inclusion probability. Each element of the
9 plots corresponds with the result of (i, j)-element of B1t. In the upper
3×3 frames, the solid line and dotted lines represent on-line updates of the
posterior median and 90% intervals of (i, j)-element of B1t for t = 1:196,
respectively. The lower 3×3 frames show the corresponding values of each
the inclusion probability deﬁned by Pr[|βjt| > dj] for each of B1t.
. . . .
24
2.3
Posterior estimate of thresholds d for B1t. Shown are the posterior medians
and 90% intervals of thresholds d for each (i, j)-element of B1t.
. . . . .
25
2.4
Posterior trajectories for (a21t, a31t, a32t) and the corresponding inclusion
probabilities. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
26
2.5
Stochastic volatilities (h1t, h2t, h3t). The left column shows the results on
the log-scale, and the right column shows them on the original scale (sta-
nard deviation).
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
27
2.6
Posterior trajectories for intercepts (c1t, c2t, c3t) and the corresponding in-
clusion probabilities. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
27
2.7
1-step/4-step ahead predictive distributions with observation. The sum-
maries of time trajectories of sequentially updated predictive distributions
for the three series are shown for 1-step (top) and 4-step (bottom) ahead
forecasting.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
29
2.8
Comparison of log marginal likelihoods and posterior model probabilities.
Log marginal likelihoods (Top) and posterior model probabilities (Bottom)
for the three emulators and vanilla SMC. Red: DLM, Blue: Shrinkage,
Green: LLTM, Pink: Vanilla SMC.
. . . . . . . . . . . . . . . . . . . .
30
xii

2.9
ESS results in analyses of DLM, Shrinkage, LLTM and vanilla SMC emu-
lation methods. The ESS is scaled percentage, i.e., 100 × ESS/N, where
N is the number of particles. The 3 columns represent results on each of
the 3 univariate time series LTMs. For each, the upper 4 rows show time
trajectories of the ESS measures, while the lower 4 rows show the resulting
histograms of ESS measures aggregated over the time period.
. . . . . .
33
2.10 Time trajectories of posteriors for elements of B2t and the corresponding
inclusion probabilities. . . . . . . . . . . . . . . . . . . . . . . . . . . .
38
2.11 Time trajectories of posteriors for elements of B3t and the corresponding
inclusion probabilities. . . . . . . . . . . . . . . . . . . . . . . . . . . .
39
2.12 On-line posteriors of Φ for B1t. . . . . . . . . . . . . . . . . . . . . . . .
40
2.13 On-line posteriors of Σ for B1t. . . . . . . . . . . . . . . . . . . . . . . .
40
2.14 On-line posteriors of α for B1t. . . . . . . . . . . . . . . . . . . . . . . .
41
3.1
The statistical approach to loss minimization. There are two interpretations
for this diagram. If the problem of interest has the speciﬁc loss function to
be minimized, it can be transformed into the synthetic model, shown by the
arrow from top to bottom, so that the computational method of statistical
inference can solve the original problem. The other interpretation is that,
for statisticians, the problem itself is deﬁned as the statistical models, then
transformed back into the form of optimization of an expected loss function,
indicated by the arrow from bottom to top, in order to make use of the
knowledge and techniques of statistical modeling. . . . . . . . . . . . . .
44
3.2
Sequence of porfolio optimization problems. At each time t, the posterior
and forecast distribution is updated with additional information xt. Based
on the prediction of rt+1 (and rt+i for i ≥1), the loss function of wt+1
is deﬁned. The output at time t is thus the portfolio for the next time,
wt+1. This process is repeated at every time point, yielding the sequence
of portfolio vectors, {wt}t=1:T .
. . . . . . . . . . . . . . . . . . . . . .
45
3.3
Optimal portfolios of DLM loss function and Markowitz method. From left
to right, top to bottom: portfolio weights of a quadratic loss function with
λt = 1, 100 and 10000 with (αt, βt) = (100, 1) and Markowitz-type portfolio.
65
3.4
Cumulative returns of DLM and Markowitz portfolios. Top: cumulative
returns with no transaction cost.
Bottom: with 0.1% transaction cost.
Four cumulative returns of DLM portfolios with λt = 1 (red), 100 (blue),
10000 (green) and Markowitz portfolio (grey) are shown in both pictures.
66
xiii

3.5
Standard deviations of DLM and Markowitz portfolios.
Four standard
deviations of DLM portfolios of λt = 1 (red), 100 (blue), 10000 (green)
and Markowitz portfolio (grey) are shown in both pictures with that of
minimum risk portfolio (black).
. . . . . . . . . . . . . . . . . . . . . .
66
3.6
Optimal portfolio of the Laplace model.
From top to bottom, left to
right: portfolio of Laplace loss function with (λt, γt) = (100, 100), (100, 1),
(1000, 100), (1000, 1) with (αt, βt) = (100, 1).
. . . . . . . . . . . . . . .
68
3.7
A Laplace portfolio with the number of active weights.
Top: portfolio
of Laplace loss function with (αt, βt, λt, γt) = (1, 100, 100, 100). Bottom:
number of non-zero weights in the portfolio.
. . . . . . . . . . . . . . .
68
3.8
Cumulative returns of Laplace portfolios for λt = 100. While the weights
for transaction costs (|wt −wt−1|) are ﬁxed as λt = 100 in addition to
(αt, βt) = (100, 1), those for sparsity in portfolio (|wt|) are γt = 10, 100 or
1000 (red, blue and green, respectively). For comparison, the cumulative
returns of Gaussian portfolio with γt = 100 (dotted black) and Markowitz
(grey) are shown.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
69
3.9
Cumulative returns of Laplace portfolios for γt = 100. Conversely to Fig-
ure 3.8, we ﬁx γt = 100 and change the value of λt to 10, 100 and 1000.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
70
3.10 Portfolios of proﬁled and marginal Laplace models. Top: portfolio of pro-
ﬁled Laplace loss function with λt = 100. Bottom: portfolio of marginal
Laplace loss function with λt = 100.
. . . . . . . . . . . . . . . . . . .
71
3.11 Cumulative returns of proﬁled and marginal Laplace portfolios. No trans-
action cost is used (δ = 0). Four portfolios are distinguished by red lines
for proﬁled (joint) loss functions, blue lines for marginal ones, solid lines
for λt = 100 and dotted lines for λt = 10.
. . . . . . . . . . . . . . . . .
72
3.12 Convergence diagnoses for w1:3,t+1 at t = 1. From the top row to the bottom
one, the correlograms, sample paths and estimated marginal densities are
shown. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
81
3.13 Convergence diagnoses for τ1:3,t+1 at t = 1. The sample paths shown in the
second row are re-scaled to be 10−4τit.
. . . . . . . . . . . . . . . . . .
81
3.14 Cumulative returns for λt = 10000.
Top: cumulative returns with no
transaction cost. Bottom: with 0.1% transaction cost. Four cumulative
returns of DLM portfolios of λt = 1 (red), 100 (blue), 10000 (green) and
Markowitz portfolio (grey) are shown in both pictures.
. . . . . . . . . .
87
xiv

3.15 Standard deviation for λt = 10000.
The black line shows the standard
deviation of the minimum risk portfolio.
. . . . . . . . . . . . . . . . .
87
3.16 Cumulative returns for (αt, βt) = (0.01, 1). Top: cumulative returns with
no transaction cost. Bottom: with 0.1% transaction cost. Four cumulative
returns of DLM portfolios of αt = 0.0001 (red), 0.01 (blue), 0.1 (green), 1
(pink) and Markowitz portfolio (grey) are shown in both pictures.
. . . .
88
3.17 Standard deviation for (αt, βt) = (0.01, 1). . . . . . . . . . . . . . . . . .
88
3.18 Proﬁled and marginal Portfolios for λt = 10.
Top:
proﬁled, Bottom:
marginal.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
89
3.19 Proﬁled and marginal portfolios for λt = 1000.
Top: proﬁled, Bottom:
marginal.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
90
4.1
Network schematic and notation for ﬂows at time t.
The circular
numbered nodes represent the domains at the current time point t.
Each arrow i →j shows the ﬂow of yijt visitors. . . . . . . . . . . . . 115
4.2
The standardized values of the marginal log-posteriors of discount factors
δi for the in-ﬂows to FoxNews nodes i = 1:22 (top right, reading across
rows), for the period 09:05am-09:55am on February 23, 2015.
. . . . . . 117
4.3
BDFM-based inference over time t on in-ﬂows to domain i = 10 (Leisure).
Upper: data y0Xt (circles) with one-step ahead forecast means and 95%
intervals. Center. trajectory of mean and 95% intervals from on-line pos-
teriors p(φ0Xt|y0X,1:t) plotted against t. Lower: revised trajectory under
full retrospective posterior p(φ0Xt|y0X,1:T ).
. . . . . . . . . . . . . . . . 119
4.4
BDFM-based inference over time t on transitions from domain i = 1 (Home-
page) to j = 2 (Politics). Upper: data y12t (plus signs) with one-step ahead
forecast means and 95% intervals. Center. trajectory of mean and 95%
intervals from on-line posteriors of φ12t. Lower: revised trajectory under
full retrospective posterior.
. . . . . . . . . . . . . . . . . . . . . . . . 119
4.5
Retrospective mean and 95% CI of trajectories of transition probability θ11t
(staying at Homepage) from analysis on data collected from each of the six
mornings.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120
4.6
Retrospective mean and 95% CI of trajectories of transition probability θ10t
(Homepage →External) from analysis on each of the six mornings.
. . . 120
4.7
Retrospective mean and 95% CI of trajectories of transition probabilities
θ15t (Homepage →Entertainment) for each of the six mornings.
. . . . . 121
xv

4.8
DGM-based smoothed trajectory of baseline level process µ1:T . In this and
following ﬁgures, the dashed lines indicate 95% intervals about the dis-
played posterior mean trajectory.
. . . . . . . . . . . . . . . . . . . . . 122
4.9
DGM-based smoothed trajectories of node-speciﬁc outﬂows αi,1:T .
. . . . 123
4.10 DGM-based smoothed trajectories of node-speciﬁc inﬂows βj,1:T .
. . . . . 123
4.11 Upper: DGM-based smoothed trajectories of transition aﬃnities, Home-
page →Opinion. Lower: Bayesian credible values corresponding to the
aﬃnity trajectories.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . 125
4.12 Upper: DGM-based smoothed trajectories of transition aﬃnities, Home-
page →Science. Lower: Corresponding Bayesian credible values.
. . . . 125
4.13 DGM-based inference on baseline ﬂow level trajectories for all six days,
with 95% credible intervals. The red trajectories correspond to the 09:05-
09:55am time window, and the blue trajectories correspond to the 01:05-
01:55 p.m. time window.
. . . . . . . . . . . . . . . . . . . . . . . . . 127
4.14 Posterior trajectories of µ1:T with the common restriction.
. . . . . . . . 128
4.15 DGM-based inference on γ0,5,1:T for all six days.
The 12 retrospective
posterior trajectories of the aﬃnity eﬀect, γ0,5,t, which corresponds to the
ﬂow from External to Entertainment.
. . . . . . . . . . . . . . . . . . . 129
xvi

List of Abbreviations and Symbols
Symbols
N(x|µ, Σ)
Normal distirbution with mean µ and variance matrix Σ, or its
density evaluated at x.
Ga(x|r, c)
Gamma distirbution with shape r and rate c (mean r/c) with
normalizing constant Γ(r) if c = 1.
Be(x|a, b)
Beta distribution with mean a/(a+b) with norm. const. B(a, b).
Po(x|µ)
Poisson distribution with mean (rate) µ.
Multi(x|n, θ)
Multinomial distribution with probability vector θ and popula-
tion n.
Dir(x|q)
Dirichlet distribution with concentration parameters q.
Dt
Information available at time t.
s : t
Indices s, s + 1, · · · , t −1, t.
Abbreviations
APF
Auxiliary Particle Filter.
AR(p)
Autoregressive process with order p.
BDFM
Bayesian Dynamic Flow Model.
DDN
Dynamic Dependent Network (models).
DGM
Dynamic Gravity Model.
DLM
Dynamic Linear Model.
GIG
Generalized Inverse Gaussian (distribution).
LTM
Latent Threshold Model.
xvii

MCMC
Markov Chain Monte Carlo.
PL
Particle Learning.
SMC
Sequential Monte Carlo.
SVD
Singular Value Decomposition (of a matrix).
TV-VAR(p)
Time-Varying Vector Autoregressive Model with order p.
xviii

Acknowledgements
First, I would like to sincerely thank my advisor Mike West. His guidance, help and
encouragement have been, and will be, undoubtedly essential to my study and career
development. The discussion with him about research, that was always full of novel
ideas and insights, was deﬁnitely the integral part of my academic life at Duke, which
led to the realization of this thesis.
I thank the faculty and staﬀat Department of Statistical Science and appreciate
their work and eﬀort that create this great research environment. I thank my Ph.D.
and Preliminary Exam Committee Members, David Banks, Surya Tokdar, Andrew
Cron, Li Ma, Sayan Mukherjee and Galen Reeves for their time and support. My
further thanks go to David and Li for their personal advice and help for my re-
search and academic career. I also thank my fellow graduate students for their daily
discussion about Bayesian statistics in Old Chem 017 that kept me motivated.
I am deeply grateful to many people and institutes oﬀcampus who supported
my research. Yasuhiro Omori brought me to Bayesian research and strongly rec-
ommended that I study at Duke.
The Nakajima Foundation and their generous
scholarship ﬁnancially supported my four years. The BEST Award, funded by the
BEST Foundation, provided ﬁnancial support of my research in summer 2015. Max-
Point kindly oﬀered me many research opportunities on applied data analysis.
Finally, I thank my family members, Minoru, Masae and Atsushi, for their love
and respect.
xix

1
Introduction
This thesis concerns advances in three related areas of state-space modeling, sequen-
tial Bayesian analysis, and decisions. Innovations in these areas are linked in several
ways, including a key theme of Bayesian model emulation: solving challenging anal-
ysis/computational problems using creative model emulators.
• Chapter 2, Inference: “Sequential Analysis and Bayesian Model Emulation for
Dynamic Latent Threshold Models”
This research focuses on ﬁltering and forecasting of time series using latent
threshold models—an approach to dynamic sparsity via state-dependent dy-
namic variable selection. On-line ﬁltering of time-evolving posterior and pre-
dictive distributions in these models is computationally challenging. My new
idea is to build analysis “emulators”—synthetic models that are more compu-
tationally tractable—using ideas from auxiliary particle ﬁltering. Sequential
importance sampling is used to adapt analyses of emulators to the original
latent threshold model. Several choices of emulating models are examined in
studies of synthetic data and a serious applied problem of macroeconomic time
1

series forecasting, evaluating accuracy of prediction and eﬃciency in posterior
approximation. An interesting ﬁnding is that one of the best emulators is, in
fact, that based on direct, adaptive “soft shrinkage” of state variables, while
the target models are based on underlying “hard shrinkage” of latent states.
This chapter is based on Irie and West (2016b).
• Chapter 3, Decision: “Bayesian Emulation in Decision Analysis: Sequential,
Multi-Step Portfolio Optimization”
In the context of sequential forecasting and portfolio optimization, I intro-
duce a novel approach to Bayesian analysis based on mapping a speciﬁed loss
function minimization problem to that of ﬁnding the mode of a posterior dis-
tribution in a “synthetic” statistical model. Computational methods for ex-
ploring distributions can then be applied to solve the original optimization
problem. I do this in the context of novel portfolio utility functions that ex-
tend traditional Markowitz-type methods to multiple-step ahead investments
with explicit penalties for transaction costs.
Various forms introduced and
explored include sparsity-inducing penalties on portfolio turnover, which yield
interesting classes of synthetic statistical models of state-space forms with non-
Gaussian structure. The resulting computational problems are addressed using
combinations of EM, MCMC and analytic ﬁltering and smoothing. Signiﬁcant
practical beneﬁts in application to ﬁnancial portfolios are realized in applied
studies of FX, commodity and stock index time series, based on sequential
forecasting using customized dynamic dependency network models.
This chapter is based on Irie and West (2016a).
• Chapter 4, Modeling: “Emulation of Dynamic Gravity Model by Bayesian Dy-
namic Flow Models”
2

This research concerns models and analyses of counts/ﬂows of traﬃc into, out of
and between nodes in a time-evolving network. The applied/motivating context
and case study involves time series of ﬂows between domains within a web
site. New approaches based on dynamic Poisson-Gamma (and Multinomial-
Dirichlet) models are invented, using ideas from stochastic volatility modeling.
Sequential analysis is analytically tractable in forward ﬁltering and eﬃcient
backward sampling, and scalable due to conditional decoupling across nodes
that yet maintains the full complexity of dynamic network ﬂows. Again using
the idea of emulation, this ﬂexible framework maps to a parallel model of
greater complexity– a so-called gravity model of ﬂow dynamics that aims to
more incisively infer node-speciﬁc and node-pair patterns and their changes.
The overall analysis can inherently exploit parallel computation, so is scalable
to large networks.
This chapter is based on “Bayesian Dynamic Modeling and Analysis of Stream-
ing Network Data” (Chen et al., 2015).
Final discussion in Chapter 5 provides summary review of the thesis and com-
ments on open research areas. At a high-level, this thesis deﬁnes theoretical and ap-
plied advances in non-linear, non-Gaussian state-space modeling, dynamic sparsity,
decision analysis and statistical computation, across linked contexts of multivariate
time series and dynamic networks studies. Examples and applications in ﬁnancial
time series and portfolio analysis, macroeconomics and internet studies from compu-
tational advertising demonstrate the utility of the core methodological innovations.
All computations are implemented in Ox (Doornik, 2007).
3

2
Sequential Analysis and Bayesian Model Emulation
for Dynamic Latent Threshold Models
2.1
Introduction
As time series analysis faces challenges of increasing dimensions of time series record-
ings, the need to induce dynamic sparsity into model structures– in the sense of both
global and local shrinkage of parameters– is increasingly important. To meet this
need, dynamic latent thresholding (Nakajima and West, 2013a) deﬁnes a general ap-
proach to adaptive, dynamic sparsity modeling. Recent applications of LTMs (e.g.
Nakajima and West, 2013b, 2015; Zhou et al., 2014) demonstrate insightful inter-
pretations and increased predictive accuracy relative to standard models. To date,
however, analysis and model ﬁtting have involved intensive MCMC methods that
are restricted to batch processing of historical data. On-line analysis for sequentially
observed/streaming data is increasing in importance, in areas such as economics (e.g.
Carvalho and Lopes, 2007; Lopes and Tsay, 2011) and ﬁnance, but also now moving
into business/IT areas that are generating time series challenges with increasingly
high-dimensional dynamic data streams. In response, our work here concerns se-
4

quential Bayesian learning and forecasting in LTMs.
The inherent nonlinearities of LTMs obviate the use of particle learning (Carvalho
et al., 2010) though allow for variants of auxiliary particle ﬁltering (Liu and West,
2001) to address ﬁxed parameter learning in state space models. To address particle
degeneracy, we exploit the theoretical model structure by introducing model emu-
lators to enhance existing sequential Monte Carlo (SMC) methods using adaptive
sequential importance sampling (SIS, e.g., Liu and Chen, 1998).
We review the speciﬁcation of LTMs in Section 2.2, and then discuss sequential
analysis and the approach of model emulation in Section 2.3. Here we discuss several
candidate LTM emulators and measures for comparative evaluation of emulation
approaches. The full procedure of sequential analysis is outlined Section 2.4, covering
emulation-based SMC methods for dynamic states combined with the crucial issue
of ﬁxed parameter learning. Technical support material appears in the appendix.
Section 2.5 considers a topical macroeconomic application based on LTM extensions
of time-varying vector autoregressive (TV-VAR) models. The applied analyses bear
out the utility of the Bayesian model emulation/SMC approach. Some summary
comments are given in Section 2.6.
2.2
Model
2.2.1
Latent Threshold Models
In a univariate latent threshold model (LTM, Nakajima and West, 2013a), scalar
observations yt (t = 1:T) are represented as
yt = (xt ◦st)′βt + ϵt,
ϵt ∼N(0, vt),
βt = (β1t, . . . , βkt)′,
(2.1)
sjt = I[ |βjt| > dj ],
st = (s1t, . . . , skt)′,
(2.2)
βt = µ + Φ(βt−1 −µ) + ωt,
ωt ∼N(0, Σ),
(2.3)
5

where xt is a k×1-vector of predictors known at time t, vt is the observational
variance, d = (d1, . . . , dk)′ are threshold parameters, and the error and innovation
sequences, ϵt and ωs, are independent over time and mutually independent. The
◦symbol represents the element-wise product, and I(·) is the indicator function.
This is a non-linear (in state βt) Gaussian state space model. The latent state fol-
lows the stationary vector autoregressive model of order 1 with µ = (µ1, . . . , µk)′,
Φ = diag(φ1, . . . , φk) and Σ = diag(σ2
1, . . . , σ2
k); this VAR(1) is thus a set of indepen-
dent univariate AR(1) processes
βjt = µj + φi(βj(t−1) −µj) + wjt,
wjt ∼N(0, σ2
j),
(2.4)
independently over j = 1:k and where 0 < φj < 1 for each j. LTMs represent dynam-
ically adaptive variable selection models in which the eﬀects of individual predictors
may be apparent for some periods of time but practically irrelevant at other periods,
based on the trajectory of the latent states and whether they lie outside/inside the
threshold regions. Multiple applications show that this can substantially improve
predictive modelling (e.g. Nakajima and West, 2013a,b, 2015; Zhou et al., 2014)
2.2.2
Challenges to Sequential Analysis
The challenges of on-line analysis can be seen immediately. Suppose we are standing
at time t with a prior for the latent state βt together with the ﬁxed parameters
(µ, Φ, Σ, d) and error variance vt, all conditional on current information Dt−1. The
ﬁltering step updates this prior to the posterior given, in addition, yt. Whatever
the form of the prior, the resulting posterior p(·|Dt) is very complicated due to the
signiﬁcant non-linearities in the conditional likelihood function p(yt|βt, vt, d) from
eqn. (2.1). This involves truncations in each βjt dimension based on the threshold
indicators sjt, and a complicated form in the threshold parameters as well, so that the
implied posterior is not at all manageable analytically. These issues are exacerbated
6

for models with higher-dimensional state vectors.
However, the fact that the likelihood function can be trivially evaluated at any
set of values of (βt, d, vt) indicates the potential for particular methods, i.e. some
form of SMC approach. It is also clear, however, that the dependence of the model
on a set of ﬁxed parameters (µ, Φ, Σ, d) in addition to the time-evolving states will
present challenges; we do not, for example, have access to existing eﬃcient SMC
methods such as particle learning (Carvalho et al., 2010) that rely on “nice” analytic
structure. Hence a more holistic approach to customizing SMC methods to the LTM
context is mandated.
2.3
Sequential Importance Sampling and Model Emulation
This section assumes that constant model parameters and error variances are known,
so focusing on SMC for ﬁltering only on the time-evolving states βt. Extension to
include parameter learning then follows in Section 2.4.
2.3.1
SIS and Emulating Models
Particle-based methods of sequential important sampling (SIS, e.g., Liu and Chen,
1998; West, 1993b) represent the time t−1 posterior in terms of a discrete distribution
on N particles βi
t with weights wi
t−1, i.e.,
p(βt−1|Dt−1) =
X
i=1:N
wi
t−1δβi
t−1(βt−1),
wi
t−1 > 0,
X
i=1:N
wi
t−1 = 1,
where δb(β) is the k−dimensional Dirac delta function of βt at point b. Under the
VAR(1) evolution of eqn. (2.3), the conditional prior for βt and the “auxiliary” index
i is p(βt, i|Dt−1) ∝p(βt|βi
t−1)wi
t−1 where the ﬁrst term is the conditional normal p.d.f.
of the state evolution. The resulting posterior is then
p(βt, i|Dt) ∝p(yt|βt)p(βt|βi
t−1)wi
t−1,
(2.5)
7

with likelihood function p(yt|βt) from eqn. (2.1).
We consider SIS methods that maximally exploit the analytic form of the prior
here, each having proposal distributions of the form
˜p(βt, i|Dt) ∝˜p(yt|βt, βi
t−1)p(βt|βi
t−1)wi
t−1,
(2.6)
where ˜p(yt|βt, βi
t−1) represents an approximation to the exact likelihood function
based on the local region of the state space for βt consistent with the value of prior
particle βi
t−1. So ˜p(·|·) may depend on βi
t−1 and model parameters as well as βt;
diﬀerent choices of ˜p(·|·) deﬁne diﬀerent emulators of the LTM updates. If we now
sample a pair (βi
t, i) from the emulating density eqn. (2.6), importance reweighting
is based on the updated/posterior weights give by the ratio of eqn. (2.5) to (2.6), i.e.,
wi
t ∝p(βi
t, i|Dt)
˜p(βi
t, i|Dt) ∝
p(yt|βi
t)
˜p(yt|βi
t, βi
t−1).
A core example is traditional auxiliary particle ﬁltering (APF, e.g., Pitt and Shep-
hard, 1999; Liu and West, 2001; Lopes et al., 2010) in which ˜p(yt|βt, βi
t−1) = p(yt|ˆβi
t)
for some choice of a point-estimate ˆβi
t, such as the conditional prior mean ˆβi
t = Φβi
t−1.
In this case, it is easy to directly sample (βi
t, i) from eqn. (2.6) by composition: sam-
ple the auxiliary index i from the the set of N with weights wi
t−1|t ∝p(yt|ˆβi
t)wi
t−1,
then draw the state from the evolution model/prior p(βt|βi
t−1). We will refer to this
as vanilla SMC, or simply SMC.
2.3.2
Choices of LTM Emulators
The ﬁrst point is to simply note that any emulating model that replaces the sjt in
eqn. (2.1) with estimates or approximating values known at time t creates a model
that is conditionally linear and Gaussian for the one-step ﬁltering update, and thus
moves us into a dynamic linear model with analytically trivial (Kalman ﬁlter-style)
analysis. We consider several such emulators to be used in parallel. That is, at time
8

t −1 use a conditionally Gaussian dynamic linear model (DLM) where ˜p(·|·) comes
from
yt = (xt ◦qt)′βt + ϵt,
ϵt ∼N(0, vt),
where qt does not involve βt but may be dependent on the past states βt−1 as well
as other model parameters including thresholds d. Then sampled particles will be
reweighted using the resulting approximation with indicators qi
t based on the sampled
auxiliary indicators. Eﬃciency of sampling, in terms of variability of resulting weights
and the need to avoid degeneracy, depends on the choice of the forms of qt.
Emulator 1: Dynamic Linear Model (DLM)
An easy ﬁrst choice is to set qt = (1, . . . , 1)′ for all t, resulting in the unthresholded
DLM. This is equivalent to setting each di = 0 in the LTM, and follows the use of
this as a global approximating model to deﬁne MCMC methods in non-sequential
batch analysis of LTMs (Nakajima and West, 2013a). Computation and generation
of proposal values is trivial, and this choice of emulator will be increasingly eﬀective
in cases when the data suggests generally low probabilities of thresholding for all pre-
dictors. In practical cases requiring substantial levels of dynamic sparsity, there will
tend to be over-dispersion in posteriors for states and greater potential for particle
weight degeneracy in the resulting SIS.
Emulator 2: Linearized LTM
A standard “extended Kalman ﬁltering” approach uses a linear (in βt) approximation
to the mean term of yt to deﬁne an approximating, analytically tractable DLM (e.g.,
West and Harrison, 1997, sect 13.2). That is, at any chosen value βt = ct for some
c = (c1t, . . . , ckt)′, take qjt = I[ |cjt| > dj ] to deﬁne a linearized latent threshold model
(LLTM). Here ct can depend on anything but βt, its value being known at time t −1
based on existing state particles and parameter values. Particle-speciﬁc vectors ci
t
9

customize a local approximation to each current particle, such as ci
t = α+Φβi
t−1 with
the intercept in AR(1) process α = (I −Φ)µ as used in the vanilla SMC using the
auxiliary particle strategy. This strategy can be expected to improve on vanilla SMC
since, in contrast to that standard approach, the LLTM strategy more thoroughly
exploits the analytic form of the model, drawing particles βi
t from the analytically
available conditional (normal) posterior deﬁned in the linearized model.
A potential drawback of this emulator is persistence in thresholding; use of (I −
Φ)µ + Φβt−1 at time t tends to imply the same thresholding pattern as that at time
t −1, being potentially under-adaptive in cases of more sudden change in elements
of the state.
Emulator 3: Shrinkage
It is natural to consider alternative emulators that modify the “hard-thresholded”
LLTM emulator above with a “soft-thresholding” extension where qt contains dynam-
ically updated thresholding probabilities. A natural choice is to take the expected
value of the original indicator function sit in the current on-line posterior of βit. This
results in
qjt = Pr[ sjt = 1 | βj(t−1) ]
= 1 −Φ

(dj −αj −φjβj(t−1))/σj

+ Φ

−(dj + αj + φjβj(t−1))/σj

,
where Φ[·] is the standard normal c.d.f. and αj = (1 −φj)µj. Refer to this as the
shrinkage emulator since 0 < qjt < 1. That is, at each time we simply plug-in the
one-step ahead predictive probability sjt = 1 for each state element j, so acting to
more aggressively push towards zero those elements for which the conditional state
distribution p(βt|βt−1) suggests a high probability of thresholding. Again as with all
emulators, this will be applied at each particle βi
t−1 in the SMC analysis outlined in
Section 2.3.1.
10

2.3.3
Comparison of Emulators
We are interested in exploring the comparative performance of emulators across
situations. An holistic comparison from a Bayesian decision theoretic viewpoint is
generated by taking a broader view of the deﬁnition of “model”, one that includes
the speciﬁcation of the emulator. Deﬁne the extended model M = {M0, E, N} as
the triplet of elements: M0, the exact, or “target” model, here a speciﬁc LTM;
the emulator E; and a speciﬁc number of particles N for the SMC. We have four
emulating methods E: vanilla SMC, DLM, LLTM and the shrinkage emulator; we
explicitly include the standard SMC as a benchmark. The number of particles, N
must be taken into account to evaluate its eﬀect on the comparisons, and to explore
potential insights relevant to its choice in practice.
Denoting the set of models
compared by M = {M1, . . . , Mm}, we make comparisons of all M ∈M using the
following metrics.
Marginal Likelihood.
On sequential analysis of any t = 1:T observations, the time T
marginal likelihood values
p(y1:T|M) =
TY
t=1
p(yt|Dt−1, M),
where
M ∈M,
(2.7)
score cumulative one-step forecasting performance (and, of course, are used to deﬁne
conditional– time T– posterior model probabilities p(M|DT), if desired.)
In our
SMC-based analyses of the LTM, the compositional one-step components of marginal
likelihood are directly approximated sequentially over t = 1:T via
p(yt|Dt−1, M) =
N
X
i=1
wi
t−1N(yt|(xt ◦si
t)′βi
t, vt),
where (si
t, βi
t) is the particle which evolves from the current posterior particle
(si
t−1, βi
t−1) following the state equations. If the particles were resampled at t −1,
11

then, of course, wi
t−1 = 1/N.
Since it directly underlies posterior model probabilities, higher marginal likeli-
hood should be preferred. However, as noted above and as is explicit in eqn. (2.7),
this essentially scores models based only on one-step ahead forecasting accuracy;
other metrics should also be considered.
Empirical Forecast Errors.
In our macroeconomic example– as in other applications
of LTMs– key interest lies in forecasting multiple steps ahead. Hence, following Naka-
jima and West (2013a), we include evaluations of h-step ahead empirical forecasting
accuracy, in terms of root mean squared forecast errors (RMSFE), for h ≥1 up to
some horizon. For any h ≥1, the RMSFE of h-step ahead predictions across period
t = t0:t1 is denoted by Rh,t0:t1 and deﬁned as
R2
h,t0:t1 =
X
t=t0:t1
(yt+h −ˆyt+h)2 / (t1 −t0 + 1)
where ˆyt+h is the forecast mean. SMC methods trivially yield forecasts in terms of
Monte Carlo samples: at any time t, sampling current state and parameter particles
underlies projection of those samples through the evolution equations over R =
1:h steps ahead, and then Monte Carlo approximation of the predictive means. In
models with lagged values of yt as predictors– as in latent thresholded time-varying
autoregressive models such as in Section 2.5– this is extended to generate samples of
each yt+r at each r = 1:h to be saved and used as predictors for the next step r + 1.
Then, p(yt+h|Dt, M) can be simulated with the posterior particles at time t.
Eﬀective Sample Size.
Eﬀective Sample Size (ESS, Liu, 1996) is an often consid-
ered a measure of eﬃciency in SIS, and importance sampling more generally. At
each time t, the current ESS measure Mt,ESS = 1/ P
i=1:N(wi
t)2 relates to variation
in the resampling weights wi
t, so deﬁnes a metric relevant to the current accuracy
12

of approximation of the posterior for state and parameters. Larger values on the
range Mt,ESS ∈[1, N] indicate more uniform weights, whereas smaller values indi-
cate substantial variation and particle “degeneration”. As discussed in Gruber and
West (2016), there is also direct relationship between ESS and the Kullback-Leibler
divergence of the Monte Carlo approximating posterior from the exact/target poste-
rior, derived from the Monte Carlo/discrete version of Kullback-Leibler based on the
entropy of the weights relative to uniformity, P
i=1:N wi
t log(Nwi
t) (e.g. West, 1993a).
2.4
Sequential Learning with Fixed Parameters and Volatilities
We now discuss completion of the overall sequential analysis that includes learning on
the ﬁxed model parameters (α, Φ, Σ, d), after re-parameterizing µ into α = (I −Φ)µ,
as well as conditional error variances vt under speciﬁc volatility models. For these we
utilize best-practices based on particle learning (PL) and auxiliary particle ﬁltering
(APF) overlaid on the SIS emulation approach for states.
2.4.1
Particle Learning for AR(1) Parameters
The parameters (α, Φ, Σ) = {αj, φj, σ2
j; j = 1:k}, appear only in the state evolu-
tion model of eqns. (2.3,2.4) that deﬁne a set of conditionally independent AR(1)
models. We adopt the traditionally used priors for these AR(1) parameters: inde-
pendently over j = 1:k. These are either normal/gamma priors for the (αj, φj, 1/σ2
j),
or modiﬁed forms in which the conditional normal prior for any one or more of the
φj are truncated to (0, 1) or (−1, 1) to enforce stationarity. In these cases, particle
learning (Carvalho et al., 2010; Lopes et al., 2010) applies to these parameters since,
conditional on values of the latent state process β∗over times 0:t, there exist condi-
tional suﬃcient statistics St for (α, Φ, Σ) that are trivially updated from time t −1
to t based on values of βt, βt−1 and yt. That is, their time t full conditional posterior
reduces to p(α, Φ, Σ|β0:t, d, Dt) = p(α, Φ, Σ|St) where St is a trivially updated sum-
13

mary deﬁning a set of k conditional normal/gamma, or truncated normal/gamma
posteriors across the j = 1:k latent state processes. These conditional posteriors
above are easy to sample, and the PL approach is enabled. See Section 2.7.2 for full
technical details.
2.4.2
Auxiliary Particle Filter for Latent Threshold
The mathematical form of the conditional likelihood function in thresholds d obvi-
ates the possibility of PL for these parameters. We therefore adopt the standard
APF method for ﬁxed parameters, using kernel approximations to each of the k
marginal posterior densities for each dj at each time (Liu and West, 2001) to re-
generate particles for weighting in the SIS analysis. The speciﬁc form of the kernel
APF uses non-Gaussian kernels customized to the threshold context, as detailed in
Section 2.7.3.
2.4.3
Volatility Models
In most applications of LTMs. we will utilize some form of stochastic volatility model
for the error variances vt, the popular choices being the simple gamma/beta random
walk model (West and Harrison, 1997) and the widely-used stationary log-AR(1)
model; several examples of each appear in prior MCMC-based analyses of LTM
(Nakajima and West, 2013a,b, 2015; Zhou et al., 2014). The simple gamma/beta
random walk model has the advantage that the emulator-based SIS method for la-
tent states βt is directly extended to include particles for the vt with little change.
Use of the log-AR(1) volatility model, which is often desirable in view of the ability
to constrain to stationarity, introduces vt as a new latent state along with the addi-
tional ﬁxed parameters of the AR(1) model for log(vt). However, the SIS approach
is trivially extended to include eﬃcient resampling of vt particles, and this can be
directly coupled with an extension of the PL method to now include this additional
14

ﬁxed parameters. Full technical details appear in Section 2.7.4.
2.4.4
Sequential Posterior Update
In the following, we use the log-AR(1) model to model the latent observational
variance vt sequence;
vt = eht,
ht = (1 −φh)µh + φhht−1 + ηt,
ηt ∼N(0, σ2
h),
(2.8)
where 0 < φh < 1. Denote the intercept by αh = (1 −φh)µh. The three additional
parameters, αh, φh and σ2
h, have suﬃcient statistics conditional on values of the
variance series, this enables the use of particle learning.
In total, the variables to be sampled at time t are {βt, ht, d}∪{αj, φj, σ2
j}j∈{1:k,h}.
We group them into three categories; state variables θt = {βt, ht}, parameters with
suﬃcient statistics ϑ = {αj, φj, σ2
j}j∈{1:k,h}, and latent thresholds d. For the latent
thresholds, there are no suﬃcient statistics and hence there is a need for density
estimation. Denote the set of suﬃcient statistics of ϑ by St; this is a function of
{θt, θt−1, St−1}. Finally, summarize these parameters at time t by Θt = {θt, St, ϑ, d}.
and the sequential analysis in the following is still valid for them.
The sequential update at time t starts with the on-line posterior at time t −1 as
the prior, approximated by particles as
p(Θt−1|Dt−1) =
N
X
i=1
wi
t−1 pi
t−1(d) δ(θi
t−1,Si
t−1,ϑi)(θt−1, St−1, ϑ),
(2.9)
where wi
t−1 = 1/N for all i. The deﬁnition of kernel function, pi
t−1(d), is given in 2.7.3.
With a little modiﬁcation to the calculation in Section 2.3, the joint distribution of
the implied time t posterior can be decomposed as
p(Θt, i|Dt) ∝p(ϑ|St)p(St|θt, θi
t−1, Si
t−1)p(yt|θt, ϑi, d)p(θt|θi
t−1, ϑi)pi
t−1(d)wi
t−1, (2.10)
15

where p(yt|θ, ϑi, d) is the likelihood in the observational equation and p(βt|βi
t−1, ϑi)
is the prior in the state transition speciﬁed in eqns. (2.1,2.3). p(ϑ|St) is the posterior
of ﬁxed parameters and p(St|θt, d, θi
t−1, Si
t−1) deﬁnes the deterministic update of suf-
ﬁcient statistics; the details of these terms are discussed in 2.7.2. The distribution of
{Θt, i} in eqn. (2.10) is the target distribution to sample. Next, consider the proposal
density used in SIS,
˜p(Θt, i|Dt) ∝p(ϑ|St)p(St|θt, θi
t−1, Si
t−1)˜pi(yt|βt)p(θt|θi
t−1, ϑi)pi
t−1(d)wi
t−1,
(2.11)
where ˜pi means the likelihood, posterior and forecast densities of the emulator model,
each of which may depend on i-th particle and (ˆhi
t, θi
t−1, ϑi, ˆdi). Note that the product
of the likelihood and prior is re-written as the product of the posterior and marginal
likelihood,
˜pi(yt|βt)p(θt|θi
t−1, ϑi) = ˜pi(βt|Dt)˜pi(yt|Dt−1)p(ht|hi
t−1, ϑi).
To be precise, the likelihood of emulator, ˜pi(yt|βt), means ˜p(yt|βt, ˆhi
t, ϑi, ˆdi) and is
deﬁned by
yt = (xt ◦qi
t)′βt + N(0, vi
t),
qi
t = qt(βi
t−1, ˆdi, ϑi),
vi
t = e
ˆht.
(2.12)
Note that this emulator model, to be used to sample the candidate particles, does
not include ht and d, but ˆhi
t and ˆdi that are available prior to sampling θt. Note
also that, as mentioned in Section 2.3, posterior and forecast densities, ˜pi(βt|Dt) and
˜pi(yt|Dt−1), are Gaussian and derived analytically by forward ﬁltering. Therefore,
the former density is used to sample state variables and the latter is absorbed in
the weights of particles that deﬁnes the new weights for propagation as wi
(t−1)|t ∝
˜pi(yt|Dt−1)wi
t−1. For notational clarity, rename the auxiliary particle index i as i0
(this is the particle at time t −1 used in sampling the current particle at t) and
introduce i1 for the index of a current particle to be sampled. Then, new particles
16

{Θi1
t }i1=1:N from the posterior of emulator ˜p need to be resampled with weights
proportional to the ratio of the target and proposal densities
wi1
t ∝p(Θi1
t |Dt)
˜p(Θi1
t |Dt) ∝
p(yt|θi1
t , ϑi0, di1)
˜p(yt|βi1
t , ˆhi0
t , ϑi0, ˆdi0)
.
(2.13)
This procedure corrects the bias caused by the use of the emulator. The sampling
procedure is modiﬁed as follows:
1. (Propagate) For i1 = 1:N, repeat the following.
(i) Sample an auxiliary index i0 from {1, . . . , N} with probability wi0
t−1|t ∝
˜pi0(yt|Dt−1)wi0
t−1. Call this index i0 = i0(i1).
The observational variance in the emulator is replaced by ˆvt = exp{ˆhi0
t },
and ˆhi0
t = αi0
h +φi0
h hi0
t−1. Similarly, the latent threshold parameter involved
in the computation has the particle-dependent value, ˆdi0, that is deﬁned
based on the theory of APF in (2.7.3). Conditional on those variables, the
forecast density in the weight is computed by forward ﬁltering in (2.7.1).
(ii) Sample di1 from pi0(d|Dt−1).
The elements of this vector are sampled independently from gamma dis-
tributions given in (2.7.3).
(iii) Sample βi1
t from ˜pi0(βt|Dt) and hi1
t from N(ht|αi0
h + φi0
h hi0
t−1, (σi0
h )2). The
former distribution is Gaussian and computed by forward ﬁltering as dis-
cussed in (2.7.1).
(iv) Construct Si1
t from Si0
t−1, θi1
t , and θi0
t−1. See (2.7.2).
(v) Sample ϑi1 from p(ϑ|Si1
t ).
Each element of ϑ, i.e. {αj, φj, σ2
j} for j = {1:k, h}, is sampled indepen-
dently from the normal-inverse gamma distribution given in (2.7.2).
17

2. (Resampling) Resample {Θi1
t , Θi0(i1)
t−1 }i1=1:N with weights wi1
t .
This weight is proportional to the ratio of two likelihoods: LTM N(yt|(xt ◦
si1
t )′βi1
t , vi1
t ) and Emulator N(yt|(xt ◦qi0(i1)
t
)′βi1
t , ˆvi0(i1)
t
), where vi1
t = exp{hi1
t }
and ˆvi0(i1)
t
= exp{ˆhi0(i1)
t
}.
2.5
Application: US Macroeconomic Study
1965
1970
1975
1980
1985
1990
1995
2000
2005
2010
5
10
Inflation pt
1965
1970
1975
1980
1985
1990
1995
2000
2005
2010
5.0
7.5
10.0
Unemployment ut
1965
1970
1975
1980
1985
1990
1995
2000
2005
2010
5
10
15
Interest rt
Figure 2.1: US macroeconomic indices. From top to bottom, the inﬂation, unemploy-
ment rate and hort-term nominal interest rate in US from 1963 to 2011. This is the same
dataset as used in Nakajima and West (2013a).
The US macroeconomic time series of Nakajima and West (2013a) has m = 3
series of quarterly inﬂation, unemployment and nominal short-term interest rates
from 1963/Q1 to 2011/Q4 (T = 196); see Figure 2.1. The inﬂation rate is the an-
nual percentage change in a chain-weighted GDP price index, the unemployment
rate is seasonally adjusted (all workers over 16), and the interest rate is the yield on
three-month Treasury bills. These and related macroeconomic series are of central in-
terest in economic policy studies; similar series are widely studied in national/central
18

banking analyses in multiple countries, where models to forecast several steps ahead
underlie impulse response analyses that feed into policy discussions. Improved se-
quential analysis for forecasting is a key interest; we study this here using LTM
extensions of the class of time-varying vector autoregressive models that have be-
come increasingly adopted for such macroeconomic studies (e.g. Cogley and Sargent,
2005; Primiceri, 2005; Koop et al., 2009; Koop and Korobilis, 2010; Korobilis, 2011;
Koop and Korobilis, 2013; Nakajima and West, 2013a). Modeling assumptions and
details follow the latter reference, and sequential analysis results are compared with
the MCMC results of that paper.
2.5.1
Latent Thresholded TV-VAR Models
Model Structure
The m−dimensional column vector time series Yt = (y1t, . . . , ymt)′ follows the TV-
VAR model of order p given by
(I −At)Yt = ct + B1tYt−1 + · · · + BptYt−p + N(0, Λ−1
t ),
Λt = diag(e−h1t, . . . , e−hmt),
(2.14)
where ct = (c1t, . . . , cmt)′, the Blt are m×m-matrices of time-varying coeﬃcients at
lags l = 1:p, and At is a strict lower triangular matrix whose non-zero entries rep-
resent contemporaneous and time-varying dependencies among the univariate series
yjt. In this study, m = 3 with y1t = inﬂation rate, y2t =unemployment rate, and
y3t =interest rate in quarter t.
The general development in Sections 2.2–2.4 applied to a univariate time series yt.
Our development here uses that directly for each of these three univariate series yt =
yjt, for each j = 1, 2, 3 in turn and in parallel. This arises as the multivariate model
decouples the three for model ﬁtting and sequential learning, while recoupling them
to properly infer cross-series relationships for forecasting. This yields eﬃciencies in
19

sequential computation as it does in the original MCMC analysis, and is enabled by
the triangular form of At, i.e.,
At =


0
0
0
a21t
0
0
a31t
a32t
0

.
The implied reduced model form is
Yt = c∗
t + B∗
1tYt−1 + · · · + B∗
ptYt−p + N(0, Ω−1
t ),
Ωt = (I −A′
t)Λt(I −At),
(2.15)
where c∗
t = (I−At)−1ct and B∗
jt = (I−At)−1Bjt for j = 1:p. The precision matrix Ωt is
a “Cholesky-syle” time-varying volatility matrix with the ﬂexibility to model diﬀerent
patterns of change over time in contemporaneous relationships. The univariate series
follow conditionally independent dynamic regression models in the compositional
form (Zhou et al., 2014)
y1t = c1t + b′
11tYt−1 + · · · + b′
1ptYt−p
+ N(0, e−h1t),
yjt = cjt + b′
j1tYt−1 + · · · + b′
jptYt−p +
j−1
X
r=1
ajrtyrt + N(0, e−hjt),
for j ≥2,
(2.16)
where b′
jlt is the j-th row of matrix Blt. The univariate LT-AR(1) model of Sec-
tion 2.2 is applied independently to each of the scalar elements of ct and each
Blt. For each series j, map to the notation of Section 2.2 with: (i) yt is substi-
tuted by yjt; (ii) β′
t is given by (cjt, b′
j1t, · · · , b′
jpt, aj1t, . . . , aj(j−1)t) where the last
terms a∗appear only for j > 1; (iii) x′
t is given by the (known at time t) vector
(1, Y ′
t−1, · · · , Y ′
t−p, y1t, . . . , y(j−1)t)′ where the last terms y∗appear only for j > 1; and
(iv) vt is the volatility e−hit.
Decoupled SIS and Recoupled Forecasting Analyses
With the full multivariate model decomposed into these m univariate, independent
LTMs, analysis runs on each in parallel, applying the SIS approach with the same
20

Monte Carlo sample size N across series. At each time t, with Θjt representing the
set of current states, volatilities and ﬁxed model parameters in analysis of series
j, these parallel SIS analyses will generate posterior samples {Θi
jt; i = 1:N)} that
can be directly combined to recouple across series j = 1:m for inference on Ωt, if
desired. Forecasting is via simulation and most eﬃciently recouples by exploiting the
compositional representation of the full joint distribution given in eqn. (2.16). This
is basically as used in MCMC analysis when forecasting ahead (Nakajima and West,
2013a).
At time t, forecast ahead to time t+T, (T > 0), by repeating the following proce-
dure independently (and in parallel) over Monte Carlo particles i = 1:N. Beginning
at s = 1, proceed sequentially to each step-ahead s = 1:T by recursively simulating
the model equations as follows.
• First, at s = 1 simulating values of Yt+1 is based wholly on the model and
posterior conditional on the observed data Dt. However, for s > 1 we will
have available forecast samples Y i
t+1:t+s−1 = {Y i
t+1, . . . , Y i
t+s−1}, (i = 1:N), to
augment the observed data Dt.
• To generate samples for Yt+s:
1. First, evolve all N particles in the states and volatilities to “move” through
the one-step AR(1) evolutions of each, in each of the j = 1:m models.
2. Set j = 1 and draw a sample yi
1,t+s from the ﬁrst model in eqn. (2.16)
with all required states and parameters set at value i from the current
particles, and conditioning on already sampled values Y i
t+1:t+s−1.
3. For j > 1, draw a sample yi
j,t+s from the j−th model in eqn. (2.16) with
all required states and parameters set at i from the current particles,
and conditioning on the current values of all yi
r,t+s just simulated for r =
21

1:(j −1) as well as the already sampled Y i
t+1:t+s−1.
This results in a full posterior predictive sample of the entire trajectory of the
m−dimensional series over steps ahead s = 1:T, i.e., the full predictive sample
{Y i
t+1, . . . , Y i
t+T; i = 1:N}.
Priors
Priors are modiﬁed versions of those in Nakajima and West (2013a). Some diﬀerences
arise due to the interest in maintaining conditional conjugacy as required in the
PL component of the SIS; this, for example, the φi are assigned normal priors.
Otherwise, the priors and hyperparamters are set to be as consistent with Nakajima
and West (2013a) as possible: βi0 ∼N(0, 2) (initial distribution of state variables);
(αi, φi, σ−2
i ) ∼N(αi|0, 27.938σ2
i ) N(φi|0.95, 22.8σ2
i ) G(σ−2
i |20, 0.01) for i ≤mp +
1 (AR(1) parameters for c and B); (αi, φi, σ−2
i ) ∼N(αi|0, 1.47σ2
i ) N(φi|0, 1.2σ2
i )
G(σ−2
i |2, 0.01) for i > mp + 1 (AR(1) parameters for A); and (αh,i, φh,i, σ−2
h,i) ∼
N(αh,i, φh,i|mh,i, σ2
h,iCh,i) G(σ−2
h,i|2, 0.01) for i = 1:m (AR(1) parameters for h) where
mh,i =
−0.23
0.95

,
Ch,i =
24.95
5.4
5.4
1.2

.
These priors have the same means (or mode for φi) and variances as those in Nakajima
and West (2013a). Note that the priors of di and (βi0, γi, di) are used only in sampling
the initial particles. This samples the former from di ∼[0, µi + 3σi] and the latter
from its stationary distribution. The discount factors in the kernel density of (d, γ)
are set 0.97.
2.5.2
Posterior Analysis
This subsection presents some results on parameter learning using the Shrinkage
emulator, with N = 50, 000 particles for each regression, at each time (150,000
22

particles in total). The results here naturally show diﬀerences to those based on
MCMC in Nakajima and West (2013a), due inherently to the sequential analysis here
in which posteriors are based only on historical data. That said, there is a good degree
of concordance and they show the similar patterns in posterior distributions and
thresholding that are meaningful and interpretable in the context of macroeconomic
study.
Figure 2.2 shows the posterior median and 90% intervals of B1t for t = 1:T and
its inclusion probability (i.e., probability that the variable is not thresholded). From
this ﬁgure, the analysis conﬁrms the basic characteristics that are known by the
existing analyses by TV-VAR in macroeconomic applications: some of the diago-
nal, self-autoregressive elements are positively active, while the oﬀ-diagonal, cross-
autoregressive terms have their posterior mass around zero, meaning they contribute
little to the model. This is more apparent in the plots of inclusion probabilities which
show the model thresholded all the entries of the matrix except for (1, 1)-element,
b11,1t, which is signiﬁcantly positive. The corresponding threshold parameters esti-
mated by APF are plotted in Figure 2.3. In this ﬁgure, it is seen that the posterior
of thresholds become small to include the state variable more for (1, 1)-entry, but un-
changed for the others. From these results, it seems that the ﬁrst variable, inﬂation,
has strong and signiﬁcant autocorrelation of order 1. The other terms, on the other
hand, are completely thresholded and ignored in the model. In contrast, (1, 2)-entry
is included in the model with more than 80% posterior probability until 1980, but
later excluded from the model, losing all the inclusion probability. This is the typical,
local sparsity in time series, in addition to “signiﬁcance” and “insigniﬁcance” in the
usual variable selection problem; the model allows cases where the state variables
are “sometime signiﬁcant, sometime not.”
The other state variables in B2t and B3t are shown in the appendix: Figures 2.10
and 2.11 in Section 2.8. In contrast to the ﬁrst-lag matrix, these evidence higher
23

1980
2000
0
2
β 1 
1980
2000
-1
0
1
β 2 
1980
2000
0
2
β 3 
1980
2000
-4
-2
0
β 4 
1980
2000
-0.5
0.0
0.5
β 5 
1980
2000
-2
-1
0
β 6 
1980
2000
-2
0
2
β 7 
1980
2000
-1
0
1
2
β 8 
1980
2000
-2
0
2
β 9 
0
100
200
0.5
1.0
Prob[st=1] (β 1 )
0
100
200
0.5
1.0
Prob[st=1] (β 2 )
0
100
200
0.5
1.0
Prob[st=1] (β 3 )
0
100
200
0.5
1.0
Prob[st=1] (β 4 )
0
100
200
0.5
1.0
Prob[st=1] (β 5 )
0
100
200
0.5
1.0
Prob[st=1] (β 6 )
0
100
200
0.5
1.0
Prob[st=1] (β 7 )
0
100
200
0.5
1.0
Prob[st=1] (β 8 )
0
100
200
0.5
1.0
Prob[st=1] (β 9 )
Figure 2.2: Posterior estimate of B1t and the inclusion probability. Each element of
the 9 plots corresponds with the result of (i, j)-element of B1t. In the upper 3×3 frames,
the solid line and dotted lines represent on-line updates of the posterior median and 90%
intervals of (i, j)-element of B1t for t = 1:196, respectively. The lower 3×3 frames show the
corresponding values of each the inclusion probability deﬁned by Pr[|βjt| > dj] for each of
B1t.
24

1980
2000
2
4
d, lag=1, i=1
1980
2000
1
2
3
d, lag=1, i=2
1980
2000
1
2
3
d, lag=1, i=3
1980
2000
0.25
0.50
0.75
d, lag=1, i=4
1980
2000
0.25
0.50
0.75
1.00
d, lag=1, i=5
1980
2000
0.25
0.50
0.75
d, lag=1, i=6
1980
2000
2
4
d, lag=1, i=7
1980
2000
1
2
3
4
d, lag=1, i=8
1980
2000
2
4
d, lag=1, i=9
Figure 2.3: Posterior estimate of thresholds d for B1t. Shown are the posterior medians
and 90% intervals of thresholds d for each (i, j)-element of B1t.
levels of sparsity, having fewer entries with inclusion probability higher than 50%.
This analysis also highlights the advantage of particle learning in the on-line pos-
teriors of AR(1) parameters. Section 2.8 collects some of those results; for parameters
(α, Φ, Σ) underlying B1t, see Figures 2.12, 2.13 and 2.14. Note that the diﬀuse priors
are gradually shaped into the concentrated posteriors as they adapt to the incoming
steam of data.
In addition to the TV-VAR coeﬃcients, the simultaneous regressive coeﬃcient, or
simultaneous correlations, denoted by At, are expected to be signiﬁcant. Figure 2.4
shows the result of posterior analysis of At, the simultaneous eﬀect among the three
variables. All the three variables are always signiﬁcant in the sense of the posterior
inclusion probabilities. Here, the eﬀect from inﬂation to interest rate, a21t in the ﬁrst
row in Figure 2.4, is clear in the location of the posterior density. The spike in 2010
is obvious and has potential interpretation of increased dependence between inﬂation
and unemployment after the ﬁnancial crisis. Also, the posterior on the link between
25

inﬂation and interest rate, a31 in the third row in Figure 2.4, almost always favors
positive values, except for the last few years. This sudden decline of the posterior
median in the last few years is meaningful, reﬂecting the impact of the ﬁnancial crisis
that yields interest rates that are stable at low values as they were more and more
controlled by central bank policies.
1970
1980
1990
2000
2010
5
10
15
a 1
0
50
100
150
200
0.5
1.0
Prob[st=1] (a1t)
1970
1980
1990
2000
2010
-2.5
0.0
2.5
a 2
0
50
100
150
200
0.5
1.0
Prob[st=1] (a2t)
1970
1980
1990
2000
2010
0.0
0.5
1.0
1.5
a 3
0
50
100
150
200
0.5
1.0
Prob[st=1] (a3t)
Figure 2.4: Posterior trajectories for (a21t, a31t, a32t) and the corre-
sponding inclusion probabilities.
Figure 2.5 plots the posteriors of the stochastic volatilities. Their dynamics are
apparently signiﬁcant, which shows the appropriateness of modeling time-varying
volatilities in this context. Some diﬀerences relative to a global MCMC analysis are
partly explained by the diﬀerent results on the intercepts shown in Figure 2.6; the
diﬀerent values and thresholding of ct will naturally impact to reduce/inﬂate of the
variance of the error terms.
The predictive accuracy of the estimated model can be seen in the 1-step and 4-
step ahead predictive distributions shown in Figure 2.7. The posterior medians track
the actual observations and the credible interval correctly quantify the uncertainty.
26

1970
1980
1990
2000
2010
-5.0
-2.5
0.0
h1t
1970
1980
1990
2000
2010
0.25
0.50
0.75
1.00
σ1= exp(h1t/2)
1970
1980
1990
2000
2010
-5.0
-2.5
h2t
1970
1980
1990
2000
2010
0.25
0.50
0.75
σ2= exp(h2t/2)
1970
1980
1990
2000
2010
-5.0
-2.5
0.0
h3t
1970
1980
1990
2000
2010
0.5
1.0
σ3= exp(h3t/2)
Figure 2.5: Stochastic volatilities (h1t, h2t, h3t). The left column shows the results on
the log-scale, and the right column shows them on the original scale (stanard deviation).
1970
1980
1990
2000
2010
-2
0
2
c 1
0
50
100
150
200
0.5
1.0
Prob[st=1] (c1t)
1970
1980
1990
2000
2010
0.5
1.0
1.5
2.0
c 2
0
50
100
150
200
0.5
1.0
Prob[st=1] (c2t)
1970
1980
1990
2000
2010
0
2
c 3
0
50
100
150
200
0.5
1.0
Prob[st=1] (c3t)
Figure 2.6: Posterior trajectories for intercepts (c1t, c2t, c3t) and the corresponding in-
clusion probabilities.
27

In the ﬁrst half of the time series, 4-step ahead predictions become challenged because
of the lack of data and diﬀuse posteriors, and succeed in stabilizing in the last half.
This result is summarized and compared with those of the other emulators in the
next subsection.
Overall, our sequential method is able to represent both global and local sparsity
and, to some extent, successfully recover the well-known ﬁnding in LTMs from the
dataset, under almost the same conditions as MCMC in terms of, for example, prior
settings.
2.5.3
Comparison
In this section, the three emulators and vanilla SMC are compared using the metrics
introduced in Section 2.3.3. The number of particles is still N = 50, 000 for each
variable and emulator for fair comparison.
First, the marginal likelihoods and model probabilities are calculated after ob-
taining the particles from the sequentially updated posteriors using each method.
As seen in Table 2.1 and Figure 2.8, the LLTM emulator has the largest marginal
likelihood, followed by the shrinkage emulator. In particular, both emulators are
still successful in the sense of marginal likelihood between 1991 and 2011, the pe-
riod which includes the time of ﬁnancial crisis and in which any model or emulator
is challenged by the series of unusual events and corresponding observations. This
result shows that LLTM and Shrinkage emulators totally outperform SMC, while a
bad choice of emulator, such as the DLM emulator in the presence of sparsity, leads
Table 2.1: Log-Marginal Likelihoods of emulators.
log ML
DLM
Shrinkage
LLTM
SMC
Full Sample
-1222.4
-727.88
-566.97
-1080.0
1996-2011
-377.78
-146.97
-102.57
-290.16
28

1965
1970
1975
1980
1985
1990
1995
2000
2005
2010
0
10
20
^y1t+1
1965
1970
1975
1980
1985
1990
1995
2000
2005
2010
0
10
20
^y2t+1
1965
1970
1975
1980
1985
1990
1995
2000
2005
2010
0
10
20
^y3t+1
1965
1970
1975
1980
1985
1990
1995
2000
2005
2010
0
10
20
^y1t+4
1965
1970
1975
1980
1985
1990
1995
2000
2005
2010
0
10
20
^y2t+4
1965
1970
1975
1980
1985
1990
1995
2000
2005
2010
0
10
20
^y3t+4
Figure 2.7: 1-step/4-step ahead predictive distributions with observation. The sum-
maries of time trajectories of sequentially updated predictive distributions for the three
series are shown for 1-step (top) and 4-step (bottom) ahead forecasting.
29

DLM 
LLTM 
Shrinkage 
SMC 
1965
1970
1975
1980
1985
1990
1995
2000
2005
2010
-1000
-750
-500
-250
0
cumulative log ML: log p(yt+1|Dt)
DLM 
LLTM 
Shrinkage 
SMC 
1965
1970
1975
1980
1985
1990
1995
2000
2005
2010
0.2
0.4
0.6
Posterior Model Probabilities
Figure 2.8:
Comparison of log marginal likelihoods and posterior
model probabilities. Log marginal likelihoods (Top) and posterior model
probabilities (Bottom) for the three emulators and vanilla SMC. Red:
DLM, Blue: Shrinkage, Green: LLTM, Pink: Vanilla SMC.
to less reliable analysis.
Since the marginal likelihood considers one-step ahead prediction only, the multi-
step forecast errors are considered by RMSFE. Following Nakajima and West (2013a),
the period for forecasting starts from 1996 Q4 and ends at 2011 Q4. At each time
point of the period t based on current data Dt, predictive analysis then simulates
the 1:4-step ahead forecasts (Yt+1, . . . , Yt+4). Estimated forecast distributions and
RMSFE measures are calculated based on these predictive particles, the results of
which are summarized in Table 2.2. As expected, MCMC shows better prediction
than all the sequential analyses, while both Shrinkage and LLTM achieve similar
accuracy of prediction to MCMC in the sense of RMSFE. These results conform the
validity and utility of the proposed sequential method in prediction.
In addition to predictive performance, for the three univariate submodels, it is
of interest to consider ESS as a measure of particle degeneracy and the eﬃcacy of
30

sampling. The time series and histograms of ESS in Figure 2.9 show that shrink-
age/LLTM outperform vanilla SMC quite substantially. In fact, this is the main
advantage of using emulators; the high ESS shows its eﬃciency in sampling and
reduced particle degeneracy. Also, note that the particles of the DLM emulator se-
riously degenerate, indicated by very low ESS. This is because DLM includes all the
parameters in the model, while as observed in Section 2.5.2, there is a high-degree of
sparsity in LTM with our dataset, which leads to the discrepancy between the simple
DLM emulator and the original LTM.
Though some emulators show higher ESS than vanilla SMC, the degeneracy is
still seen in the period when ESS becomes below, for example, 50%. In practice,
one can avoid this potential degeneracy by running oﬀ-line MCMC to reﬂesh the
particles and then come back to the on-line sequential analysis. ESS is again useful
in detecting the timing of need for such intervention and refresh.
2.6
Summary Comments
In this chapter, to realize sequential analysis in LTMs, we introduce the emulat-
ing approach and proposed Shrinkage emulator as a good approximation of LTMs.
By combining this idea with PL and APF, practically useful sequential analysis of
posteriors in LTMs, including those of the ﬁxed parameters, is fully possible. In
the macroeconomic application, this method gives interpretable posterior summaries
that have all the characteristics expected and are comparable in many respects to the
“gold standard” results based on repeated (moving window) analysis using MCMC,
an approach that is infeasible in problems of higher dimensions and high incoming
data rates. The results of diﬀerent emulators and vanilla SMC are compared by
marginal likelihood, ESS and RMSFE, concluding that the usage of Shrinkage and
LLTM emulators should be recommended in terms of model ﬁtting, eﬃcient sampling
and accurate prediction.
31

Table 2.2: Multistep RMSFEs for 3 variables with MC errors.
1-step ahead forecast
DLM
Shrinkage
LLTM
SMC
MCMC
pt+1
1.242
0.298
0.278
0.294
0.264
(1.017)
(0.298)
(0.261)
(0.742)
ut+1
2.677
0.558
0.342
2.550
0.308
(3.883)
(1.042)
(0.555)
(8.426)
rt+1
3.253
0.721
0.602
1.986
0.477
(3.839)
(0.831)
(0.555)
(5.694)
2-step
DLM
Shrinkage
LLTM
SMC
MCMC
pt+2
2.164
0.518
0.439
0.475
0.393
(2.101)
(0.564)
(0.417)
(1.421)
ut+2
4.990
0.885
0.624
1.193
0.539
(7.754)
(1.436)
(0.800)
(10.184)
rt+2
2.833
1.214
1.067
1.650
0.839
(5.344)
(1.143)
(0.838)
(7.404)
3-step
DLM
Shrinkage
LLTM
SMC
MCMC
pt+3
2.071
0.711
0.574
0.820
0.552
(3.790)
(0.835)
(0.565)
(14.993)
ut+3
5.221
1.249
0.918
6.391
0.840
(10.388)
(1.832)
(1.004)
(183.005)
rt+3
4.779
1.668
1.521
4.926
1.147
(9.648)
(1.434)
(1.064)
(124.833)
4-step
DLM
Shrinkage
LLTM
SMC
MCMC
pt+4
2.555
0.881
0.717
1.831
0.726
(5.550)
(1.078)
(0.710)
(32.385)
ut+4
8.278
1.427
1.182
12.872
1.121
(23.277)
(2.143)
(1.192)
(268.381)
rt+4
5.665
2.137
1.881
9.949
1.431
(18.606)
(1.744)
(1.282)
(196.232)
32

1980
2000
50
100
%
var=1
DLM
1980
2000
50
100
%
var=2
1980
2000
50
100
%
var=3
1980
2000
50
100
%
Shrinkage
1980
2000
50
100
%
1980
2000
50
100
%
1980
2000
50
100
%
LLTM
1980
2000
50
100
%
1980
2000
50
100
%
1980
2000
50
100
%
SMC
1980
2000
50
100
%
1980
2000
50
100
%
0
50
100
0.01
0.02
0.03
DLM         var=1
%
0
50
100
0.01
0.02
0.03
                   var=2
%
0
50
100
0.01
0.02
0.03
                   var=3
%
0
50
100
0.01
0.02
0.03
Shrinkage
%
0
50
100
0.01
0.02
0.03
 
%
0
50
100
0.01
0.02
0.03
 
%
0
50
100
0.01
0.02
0.03
LLTM
%
0
50
100
0.01
0.02
0.03
 
%
0
50
100
0.01
0.02
0.03
 
%
0
50
100
0.01
0.02
0.03
SMC
%
0
50
100
0.01
0.02
0.03
 
%
0
50
100
0.01
0.02
0.03
 
%
Figure 2.9: ESS results in analyses of DLM, Shrinkage, LLTM and vanilla SMC emu-
lation methods. The ESS is scaled percentage, i.e., 100 × ESS/N, where N is the number
of particles. The 3 columns represent results on each of the 3 univariate time series LTMs.
For each, the upper 4 rows show time trajectories of the ESS measures, while the lower 4
rows show the resulting histograms of ESS measures aggregated over the time period.
33

2.7
Appendix: Technical Details of SMC for LTMs
2.7.1
Forward Filtering with Emulators
Throughout Section 4, it has been emphasized that forward ﬁltering is available with
emulators. In this section, the statement above is reviewed with the basics of forward
ﬁltering in DLMs (West and Harrison, 1997; Prado and West, 2010).
As speciﬁed in Section 4.1, any emulator of LTMs has the following form,
yt = F ′
tβt + N(0, vt),
Ft = xt ◦qt
(2.17)
βt = α + Φβt−1 + N(0, Σ),
(2.18)
where qt is free from βt but may be dependent on (βt−1, α, Φ, Σ, d). This lack of
dependence of qt on βt makes the observational equation linear in βt, so the em-
ulator becomes a DLM. Then, the forward ﬁltering for this model, conditional on
{Ft, vt, α, Φ, Σ}, is conducted as follows:
• Posterior at t −1: p(βt−1|Dt−1) = N(mt−1, Ct−1).
• Prior: p(βt|Dt−1) = N(at, Rt),
where at = α + Φmt−1 and Ri
t = ΦCt−1Φ′ + Σ.
• Forecast: p(yt|Dt−1) = N(ft, qt),
where ft = F ′
tat and qt = F ′
tRtFt + vt.
• Posterior: p(βt|Dt) = N(mt, Ct),
where mt = at + Atet, Ct = Rt −AtA′
t/qt, et = yt −ft and At = RtFt/qt.
In the sequential analysis of Section 2.4.4, the forecast and posterior distributions
above become necessary; the former is used in evaluating the forecast density as the
part of mixture weights and tha latter is the distribution from which we sample the
candidates of state variables βt.
34

The computations above rely on two assumptions: the initial posterior is normally
distributed and all the other parameters are given. Fortunately, when sampling βt
during the sequential learning from t −1 to t, both assumptions are satisﬁed. To
see this, remember that we start the sequential update by sampling auxiliary index i
and the associated partcile at t−1. This ﬁxes βt−1 to be βi
t−1 in the subsequent steps
of sequential learning, meaning that βt−1 follows the degenerate normal distribution
with mt−1 = βi
t−1 and Ct−1 = 0. Also, this auxiliary index i allows us to condition the
distributions of interest on hi
t−1, {αi
j, φi
j, (σi
j)2}j=1:k,h and di; these variables deﬁne
{Ft, vt, α, Φ, Σ} and enable us to focus on sampling of βt and to apply the theory of
ﬁltering.
2.7.2
Particle Learning
The evolution model of eqns. (2.3,2.4) is a set of k conditionally independent AR(1)
processes with transition p.d.f.s N(βjt|αj + φjβj,t−1, 1/wj) for j = 1:k, where αj =
(1 −φj)µj and wj = 1/σ2
j. Consider ﬁrst the traditional normal/gamma priors for
(αj, φj, wj) assumed independent over j. Take these priors as
p(αj, φj, wj|D0) = N(αj, φj|mj0, Cj0/wj) Ga(wj|aj0/2, bj0/2)
for speciﬁed prior parameters S0 = {mj0, Cj0, aj0, bj0; j = 1:k}. Standard theory
shows that, for all t > 0 and maintaining independence across j,
p(αj, φj, wj|Dt) = p(αj, φj, wj|St) = N(αj, φj|mjt, Cjt/wj) Ga(wj|ajt/2, bjt/2)
where the set St = {mjt, Cjt, ajt, bjt; j = 1:k} is updated from St−1 via
mjt = mj,t−1 + Ajtejt
Cjt = Cj,t−1 −qjtAjtA′
jt
ajt = aj,t−1 + 1
bjt = bj,t−1 + e2
jt/qjt,
and
Gjt =

1, βj,t−1

ejt = βjt −G′
jtmj,t−1
qjt = 1 + G′
jtCj,t−1Gjt
Ajt = Cj,t−1Ft/qjt.
35

The above analysis holds with a minor modiﬁcation in cases when one or more of
the priors adds a stationarity constraint (e.g. Prado and Lopes, 2013). That is, if
the prior for any one φj is normal truncated to (0, 1), then the posterior at any time
t maintains the above form– based on the suﬃcient summaries in St– but subject to
the truncation. The conditional posteriors can still be easily sampled in this case.
2.7.3
Auxiliary Particle Filter
Unlike AR(1) parameters in the previous section, latent thresholds d = (d1, . . . , dk)′
have no suﬃcient statistics because of the complexity of the mean term in eqns. (2.1)
and (2.2).
Instead of sampling from its full conditional based on particle learing, we estimate
the marginal posterior density of d at time t −1 by the particles, and generate the
next particle from the estimated distribution. With the assumption of independence,
the estimated density of d is written as
p(d|Dt−1) =
X
i=1:N
wi
t−1
k
Y
j=1
G(dj|ai
jt, bi
jt).
(2.19)
To construct this density, we need to estimate the univariate density of each threshold
dj with gamma kernels. The two parameters in the kernels, (ai
jt, bi
jt), are chosen in
the same way as in Liu and West (2001), in order for the mean and variance of the
kernel to match those of those of sample analogue, mj and Vj, computed by particles
{di
j}i=1:N with the technique of shrinkage. Therefore, the kernel parameters are then
determined by
ai
jt = (αdi
j + (1 −α)mj)2
(1 −α2)Vj
,
bi
jt = (αdi
j + (1 −α)mj)
(1 −α2)Vj
,
(2.20)
where α is the tuning parameter for shrinkage and set to be 0.985.
36

The independence and distributional assumptions might be viewed as too restric-
tive, but the successful results of the empirical analysis in Section 2.5 suggest that
these assumptions do not aﬀect the estimation signiﬁcantly. From the theoretical
point of view, it can be seen that the dependencies among elements of d, which
are ignored in the prior of d under the independence assumption, is also captured
in mixture weights wi
t−1|t. Also, the exponential decay in the tail of gamma den-
sity has already observed in empirical studies in (Nakajima and West, 2013a) and is
appropriate especially for modeling the distribution of latent thresholds.
2.7.4
Extension to Stochastic Volatility
The log-AR(1) stochastic volatility model in eqn. (2.8) introduces additional state
variable {ht}t=1:T and three paramters {αh, φh, σ2
h} where αh = (1 −φh)µh. These
parameters can be sampled by the methods discussed already in the previous sections.
First, the sequential update of ht is explained in Section 2.4.4; the new state variable
is sampled from its prior N(αh + φhht−1, σ2
h) conditional on (ht−1, αh, φh, σ2
h). Next,
the AR(1) coeﬃcient and variance, (αh, φh, σ2
h), have the suﬃcient statistics and
posterior conjugacy with normal-inverse gamma prior, similar to that for (α, Φ, Σ) in
(2.7.2). Thus, the sampling procedure in (2.7.2) is valid for (αh, φh, σ2
h) by replacing
subscript j by h, and βjt by ht.
37

2.8
Appendix: Supplemental Figures on Parameter Learning
1980
2000
0
2
β 1 
1980
2000
-1
0
1
β 2 
1980
2000
-2
0
2
β 3 
1980
2000
-2
-1
0
β 4 
1980
2000
-2
-1
0
β 5 
1980
2000
-1.5
-1.0
-0.5
0.0
β 6 
1980
2000
-1
0
1
2
β 7 
1980
2000
-1
0
1
β 8 
1980
2000
-1
0
1
β 9 
0
100
200
0.5
1.0
Prob[st=1] (β 1 )
0
100
200
0.5
1.0
Prob[st=1] (β 2 )
0
100
200
0.5
1.0
Prob[st=1] (β 3 )
0
100
200
0.5
1.0
Prob[st=1] (β 4 )
0
100
200
0.5
1.0
Prob[st=1] (β 5 )
0
100
200
0.5
1.0
Prob[st=1] (β 6 )
0
100
200
0.5
1.0
Prob[st=1] (β 7 )
0
100
200
0.5
1.0
Prob[st=1] (β 8 )
0
100
200
0.5
1.0
Prob[st=1] (β 9 )
Figure 2.10: Time trajectories of posteriors for elements of B2t and the corresponding
inclusion probabilities.
38

1980
2000
0
2
β 1 
1980
2000
-2
0
2
β 2 
1980
2000
-1
0
1
β 3 
1980
2000
0
2
4
β 4 
1980
2000
0.0
0.5
β 5 
1980
2000
-1
0
1
β 6 
1980
2000
-1
0
1
2
β 7 
1980
2000
-1
1
β 8 
1980
2000
0
2
β 9 
0
100
200
0.5
1.0
Prob[st=1] (β 1 )
0
100
200
0.5
1.0
Prob[st=1] (β 2 )
0
100
200
0.5
1.0
Prob[st=1] (β 3 )
0
100
200
0.5
1.0
Prob[st=1] (β 4 )
0
100
200
0.5
1.0
Prob[st=1] (β 5 )
0
100
200
0.5
1.0
Prob[st=1] (β 6 )
0
100
200
0.5
1.0
Prob[st=1] (β 7 )
0
100
200
0.5
1.0
Prob[st=1] (β 8 )
0
100
200
0.5
1.0
Prob[st=1] (β 9 )
Figure 2.11: Time trajectories of posteriors for elements of B3t and the corresponding
inclusion probabilities.
39

1980
2000
0.8
0.9
1.0
phi, lag=1, i=1
1980
2000
0.50
0.75
1.00
phi, lag=1, i=2
1980
2000
0.7
0.8
0.9
1.0
phi, lag=1, i=3
1980
2000
0.8
0.9
1.0
phi, lag=1, i=4
1980
2000
0.8
0.9
1.0
phi, lag=1, i=5
1980
2000
0.8
0.9
1.0
phi, lag=1, i=6
1980
2000
0.7
0.8
0.9
1.0
phi, lag=1, i=7
1980
2000
0.7
0.8
0.9
1.0
phi, lag=1, i=8
1980
2000
0.7
0.8
0.9
1.0
phi, lag=1, i=9
Figure 2.12: On-line posteriors of Φ for B1t.
1980
2000
0.020
0.025
sigma, lag=1, i=1
1980
2000
0.020
0.025
0.030
sigma, lag=1, i=2
1980
2000
0.020
0.025
sigma, lag=1, i=3
1980
2000
0.020
0.025
sigma, lag=1, i=4
1980
2000
0.0200
0.0225
0.0250
0.0275
sigma, lag=1, i=5
1980
2000
0.020
0.025
sigma, lag=1, i=6
1980
2000
0.020
0.025
0.030
sigma, lag=1, i=7
1980
2000
0.020
0.025
sigma, lag=1, i=8
1980
2000
0.020
0.025
0.030
sigma, lag=1, i=9
Figure 2.13: On-line posteriors of Σ for B1t.
40

1980
2000
-0.25
0.00
0.25
alpha, lag=1, i=1
1980
2000
-0.2
0.0
0.2
alpha, lag=1, i=2
1980
2000
0.0
0.2
alpha, lag=1, i=3
1980
2000
-0.1
0.0
0.1
alpha, lag=1, i=4
1980
2000
0.0
0.1
alpha, lag=1, i=5
1980
2000
-0.10
-0.05
0.00
alpha, lag=1, i=6
1980
2000
0.0
0.2
alpha, lag=1, i=7
1980
2000
-0.2
0.0
0.2
alpha, lag=1, i=8
1980
2000
-0.2
0.0
0.2
alpha, lag=1, i=9
Figure 2.14: On-line posteriors of α for B1t.
41

3
Bayesian Emulation in Decision Analysis:
Sequential, Multi-Step Portfolio Optimization
3.1
Emulation by Synthetic Models in General Decision Analysis
The topic of this chapter is decision analysis after conducting posterior and predic-
tive analysis. Given predictive information, we discuss loss (or utility) functions and
methodology to compute the resulting optimal Bayesian decisions. The role of em-
ulation arises here, in quite novel ways, as the resulting optimization problems can
be cast as problems of searching for modes in posterior distributions in completely
synthetic statistical/probabilistic models. That is, we propose Bayesian statistical
model emulators for solving decision problems. For a certain class of loss functions
L(w) of decision w, there exists a corresponding probability density deﬁned by
p(w) ∝exp

−1
2L(w)

,
if
Z
p(w)dw < ∞.
Therefore, the loss minimization problem is now equivalent to the computation of the
mode of density p(w). This simple idea is seen and well-known in, for example, ordi-
nary least squares and maximum likelihood in the Gaussian linear model; minimizing
42

L(β) = (y −Xβ)′(y −Xβ) in β is equivalent to computing the mode of a posterior
distribution (with non-informative prior) deﬁned by likelihood y = Xβ + N(0, σ2I).
This classical idea has also been examined in detail in Bayesian decision theory
and its application to complex decision making problems, as surveyed by M¨uller
(1999). The following methodological development and application include M¨uller
et al. (2004) and Amzal et al. (2006), in which the loss function, as the synthetic
model, is integrated with statistical models for inference, hence the optimal decision
can be simulated from a “synthetic” posterior using methods such as MCMC and
simulated annealing.
This research takes the same approach and advantage in portfolio optimization
problems. It can be regarded as a special case of the existing research cited above in
the sense that the decision making process is independent of inference, so that the
optimization can be conducted separately after the computation needed for posterior
and predictive analysis of the model, as illustrated in Figure 3.2 in the next section.
On the other hand, this simpliﬁcation allows for a variety of choices in computa-
tional methodology for optimization such as analytical FFBS and EM methods, in
addition to MCMC, exploiting the statistical features of the synthetic models. In
addition to its computational advantages, this approach can also help decision mak-
ers to deﬁne the appropriate loss functions that match their personal or corporate
preferences. In any speciﬁc decision problem, where one has to consider multiple
aspects of preferences to be expressed in mathematical form, it is easier, at least for
the applied statisticians, to propose statistical models that have the required math-
ematical properties. Figure 3.1 depicts these two advantages in using a synthetic
model. The transformation of the original loss minimization problem to the anal-
ysis of synthetic models enables not only the computational methods for Bayesian
time-series analysis but also the translation of well-known properties of the parallel,
emulating statistical model into the decision analysis problem.
43

L(w)
Synthetic Models
p(w) ∝exp(−L(w)/2)

Minimization
/_
_
_
_
_
_
_
_
_
_
_
_
ˆw
p(w)
Deﬁne Losses
L(w) = −2 log p(w)
W
Posterior Mode
I
Figure 3.1: The statistical approach to loss minimization. There are two interpretations
for this diagram. If the problem of interest has the speciﬁc loss function to be minimized,
it can be transformed into the synthetic model, shown by the arrow from top to bottom, so
that the computational method of statistical inference can solve the original problem. The
other interpretation is that, for statisticians, the problem itself is deﬁned as the statistical
models, then transformed back into the form of optimization of an expected loss function,
indicated by the arrow from bottom to top, in order to make use of the knowledge and
techniques of statistical modeling.
3.2
Introduction: Sequential Portfolio Optimization
Portfolio optimization, where the investors update their portfolio based on their pre-
diction of ﬁnancial asset returns, has been an important problem in statistics and
ﬁnancial econometrics. This problem concerns both predictions by Bayesian statis-
tical model(s) and decision making based on those predictions. On modeling and
predictive analysis, recent advances in portfolio study emphasize the aspect of se-
quential analysis that discusses the computational feasibility in updating the current
predictions by incorporating daily or more frequently observed stream of data into
the models. Figure 3.2 shows the procedure of sequential portfolio optimization, con-
ducted simultaneously with posterior analysis and prediction. To make a decision
on portfolio choice in a timely manner, the preceding research of sequential analysis
avoids the use of MCMC methods to save the computational time. The examples of
MCMC-free modeling and computation include the use of massive numbers of ana-
lytically tracktable DLMs to make predictions by model averaging technique (Zhou
et al., 2014), advanced computational methodologies such as parallel computing by
44

GPUs (Gruber and West, 2016), and non-linear stochastic volatility model with SMC
methods (Johannes et al., 2014).
t
t + 1
t + 2
· · ·
xt
/ p(rt+1|Dt)
xt+1 /

p(rt+2|Dt+1)
/
xt+2 /

p(rt+3|Dt+2)
xt+3 /

· · ·
L(wt+1)

L(wt+2)

L(wt+3)

wt+1
wt+2
wt+3
Figure 3.2: Sequence of porfolio optimization problems. At each time t, the posterior
and forecast distribution is updated with additional information xt. Based on the prediction
of rt+1 (and rt+i for i ≥1), the loss function of wt+1 is deﬁned. The output at time t is
thus the portfolio for the next time, wt+1. This process is repeated at every time point,
yielding the sequence of portfolio vectors, {wt}t=1:T .
However, in comparison to modeling and forecasting, less attention has been paid
in the statistical research literatures to the aspect of decision problem: the appropri-
ate functional form of the loss function and the methodology for optimization. To
this problem, the mean-variance optimization (Markowitz, 1952, 1968) is known as
a simple but feasible and practical approach and has been applied very broadly for
decades; in the Bayesian forecasting literature, most recent works include copious
historical references (e.g.
Zhou et al., 2014; Gruber and West, 2016). Denote the
optimal portfolio at time t = 1, that is computed at t = 0, by the k-dimensional
vector w1. This is deﬁned as the minimizer of the following expected loss function
of w1:
L(w1) = w′
1K−1
1 w1
subject to
1′
kw1 = 1
and
E[r′
1w1] = m1,
(3.1)
where K1 is the predictive precision matrix (k × k-matrix), mt is the target total
return (scaler) and r1 is the observed return (k-dimensional vector). Solving this
45

problem is not costly in most cases; the analytical form of the optimal portfolio is
available and its numerical computation involves one inversion of k × k-matrix only.
In practice, however, the simple functional form in eqn. (3.1) might not describe
precisely the personal preference on more proﬁtable and stable portfolios. The more
carefully the loss function is speciﬁed, the more proﬁt and stability can be expected
from the optimal portfolio as desired, which motivates further extension of this loss
function. One crucial improvement of this loss function is to consider the multiple-
step ahead predictions, rather than the one-step ahead prediction only. From this
perspective, the loss function in eqn. (3.1) should include not only w′
1K−1
1 w1 but
also w′
tK−1
t wt for t = 2, . . . , h for some horizon h, which allows investers to weight
their uncertainties and utilities about outcomes and risk over several, forthcoming
time periods. Another improvement is motivated by the switching cost of portfolios,
which we call transaction costs in this research, to smooth the dynamics of portfolios.
Though there is theoretical and practical evidence that explicitly incorporating trans-
action costs in the loss function contributes to more proﬁtable portfolios we rather
consider this factor important as the realization of the psychological cost of individ-
uals for the volatile portfolios. In the loss function, transaction costs are measured
by distances between consecutive portfolios and can have a signiﬁcant impact on the
realized portfolios. While these two aspects of investment—multiple-step ahead pre-
dictions and transaction costs—can improve the quality of loss functions suﬃciently
for the practical application, in return for this improvement, the methodology to
solve the resulting optimization problems are relatively under-developed.
In this research, we propose novel loss functions for the portfolio optimization
problem based on multiple-steps ahead forecasting and transaction cost and, to solve
it, oﬀer a feasible and computationally eﬃcient method. As stated in Section 3.1, we
address the latter using novel Bayesian ideas to “translate” the optimization problem
into an estimation problem in statistics. The resulting expected loss functions are,
46

in fact, the state space models in Bayesian time series analysis that are DLMs in the
simplest case. This transformation also enables “modeling” the loss function with de-
sirable characteristics exploiting insights generated from the statistical models. For
these models, we can make use of the existing methods of computation, including an-
alytical forward ﬁltering and backward smoothing (FFBS), EM algorithm, MCMC,
and their combination, to ﬁnd the optimal portfolio weights as the posterior mode.
These advances in modeling and computation are applied in Section 3.3 to portfo-
lios that can be solved using computation by FFBS. Its extension to modiﬁed loss
functions that include absolute distance metrics for transaction costs is discussed in
Section 3.4, with the development of the tailored EM algorithm.
In addition to the above-mentioned modeling and computational advantages in
practice, the statistical approach to the portfolio problem highlights classical but
fundamental questions about deﬁnitions of loss functions in this context. Since we
only need w1 at time t = 0, the loss function should be dependent solely on w1, and
it is obtained by minimizing the “joint” loss function of (w1, w2, . . . , wh), or “proﬁl-
ing out” redundant variables (w2, . . . , wh). On the other hand, once the statistical
approach is taken, it makes more sense for Bayesians to marginalize the redundant
variables out in the synthetic model and transform the marginal model back to the
form of loss function again. This “marginalization” and its connection to “proﬁling”
is an important topic in statistical research today; Polson and Scott (2015) shows
theoretical connection between the two approaches in shrinkage models, which is,
unfortunately, not directly applicable to our portfolio problem. We, instead, pro-
pose methodology for computing the marginal model in Section 3.5, then discuss its
diﬀerence from the joint model through the extensive application to real datasets in
Section 3.6.
The performance of new loss functions introduced in this research, based on imple-
mentation using the Bayesian emulation concept and resulting synthetic statistical
47

models, is examined through application to foreign exchange rate forecasting and
portfolio construction in Section 3.6. Cumulative returns of portfolios are monitored
with and without discounts by transaction cost in order to evaluate the performance
and sensitivity of diﬀerent portfolio strategies. In the presence of transaction costs,
the optimal portfolio strategy based on our loss functions consistently outperforms
the mean-variance loss function with one-step forecasting. The marginalization ap-
proach is also applied and we discuss and compare the results with those achieved
under the joint proﬁling method.
3.3
Statistical Model Emulation of Expected Loss Functions
3.3.1
Settings and Notation
The general sequential analysis consists of estimation, prediction and optimization;
one receives a new observation at time t, processes this datum and updates his or
her model (estimation), forecasts the future observations by using the updated model
(prediction), optimizes his or her action at time t + 1 (optimization), and moves on
to the next observation at time t + 1 (see Figure 3.2). In the context of portfolio
analysis, the observation is the asset prices or returns and the decision made by
investors is to change the portfolio allocation based on the prediction of returns at
the next set of time points of interest. Suppose we have the model for the time series
of asset prices pt (k × 1 vector, k is the number of assets of consideration), or return
rates rt deﬁned by rit = pit/pi(t−1)−1. At time t, with the set of information updated
as Dt = {rt} ∪Dt−1, Bayesian analysis of this model provides the predictive means
and variances: fh = E[rt+h|Dt] and K−1
h
= V [rt+h|Dt]. Note that both fh and K−1
h
depend on t, but this subscript is abbreviated in the following. For simplicity, and
without loss of generality, set the current time point to be t = 0 and abbreviate D0
in the conditional expectation; this means the same argument can be made at any
t-th repetition of the sequential analysis by replacing subscript 0 by t, 1 by t + 1,
48

and so on. Also, note that the model for rt and (fh, K−1
h ) are assumed to be given
for necessary t and h.
Denote the portfolio weights at time t by wt. Now, the portfolio optimization
problem is speciﬁed as the minimization of the expected loss function, L(w1). To
incorporate the uncertainty about the future into the loss function appropriately, we
deﬁne the joint loss function, L(w1, . . . , wh), for some horizon h, which implicitly
deﬁnes the target loss function L(w1) after minimization in (w2, . . . , wh).
3.3.2
Dynamic Linear Models for Quadratic Loss
Next, we need to specify the functional form of the joint loss function.
In this
research, there are three (or four in Section 3.5) components which the loss function
comprises; mean squared error (MSE), risk and transaction cost.
• MSE: (mt −f ′
twt)2.
This is the mean squared error of predictive return f ′
twt against target return
mt. The target return, mt, has to be provided by investors prior to the analysis
to reﬂect their preference on the loss function. Ralative to the other compo-
nents in the loss function, the contribution of this MSE to the entire loss is
determined by weight parameter αt in eqn. (3.2). When αt = 0, it realizes the
hard constraint on the target return, f ′
twt = mt, as in the traditional Markowitz
approach. For this reason, we call this term a “soft constraint” on the target
return, and control the strength of this constraint by weight αt. An obvious
drawback in using this soft constraint is the penalty on the excess return; the
portfolio is penalized even if it achieves the target return, i.e. f ′
twt ≥mt.
49

• Risk: w′
tK−1
t wt.
Risk is the term used here for– explicitly– the variance of predictive return,
i.e., V [w′
trt]. The correponding weight is denoted by βt.
• Transaction cost: (wt −wt−1)′(wt −wt−1).
This represents the loss caused by the distance between wt and wt−1. It is
weighted by λt.
The loss function we consider is the weighted sum of the three factors above, i.e.
L(w1:h) =
h
X
t=1
n
α−1
t (mt −f ′
twt)2 + β−1
t w′
tK−1
t wt
+ λ−1
t (wt −wt−1)′W −1
t
(wt −wt−1)
o
,
(3.2)
where αt, βt and λt are also given prior to decision making in order to balance their
impacts on the loss function. This quadratic functional form is motivated as the
“expected loss function” of Bayesian decision theory (e.g. Berger, 1985, Section 1.3);
the squared error of target/realized return, (r′
twt −mt)2, gives our loss function in
eqn. (3.2) with αt = βt as the expectation in p(r1:h|D0).
Now, we claim that this has the corresponding “synthetic” model,
mt = f ′
twt + N(0, αt),
zt = wt + N(0, βtKt),
wt = wt−1 + N(0, λtWt),
(3.3)
which is a DLM with state variance Wt = Ik and initial portfolio w0 when observing
zt = 0k. The synthetic DLM must have the initial prior, w0 ∼N(µ0, C0), and this is
automatically set as C0 = 0 and µ0 = w0 since w0 is given in the process of sequential
decision making. Denote the two densities of the time t likelihood and prior in this
50

model by p(mt, zt|wt) and p(wt|wt−1). The correspondence between the loss function
in eqn. (3.2) and the model in eqn. (3.3) is now clear by observing that
e−1
2 L(w1:h) ∝
k
Y
t=1
p(mt, zt|wt)p(wt|wt−1)
∝p(w1:h|m1:h, z1:h).
(3.4)
Therefore, ﬁnding the minimizer of L(w1:h) is equivalent to calculating the posterior
mode in the synthetic DLM. After computing the posterior mode as w1:h, take w1,
the ﬁrst sub-vector only, and simply ignore the rest. That is the solution of the
original optimization problem.
Sum-to-One Constraint
In the synthetic model, the sum-to-one constraint is realized by the degenerate co-
variance matrix, Wt = Ik −1k1′
k/k. This covariance matrix implies, almost surely,
that 1′
kwt = 1′
kw0 for all t. Consequently, as long as the initial portfolio satisﬁes the
sum-to-one constraint, all the subsequent porfolios satisfy this constraint as well. In
fact, conversely, conditioning the original synthetic model by 1′
kwt = 1′
kwt−1 implies
the degenerate covariance, so this approach is justiﬁed in the probabilistic sense.
Thus, the optimal portfolio under this constraint is the posterior mode of the model
deﬁned by this covariance matrix.
3.3.3
FFBS for Posterior Modes
To compute the posterior mode of DLMs eﬃciently, the theory of FFBS (e.g. West
and Harrison, 1997; Prado and West, 2010), plays a crucial role. With given hyper-
parameters, FFBS becomes analytic, with the backward smoothing step (rather than
backward sampling or simulation) being analytic– as well as the forward ﬁltering
step. This leads to eﬀectively trivial computation of the full, smoothed posterior
distributions for the w1:h based on any synthetic data over times 1 : h.. Thus, we can
51

compute the joint posterior mean w1:h and simply note that, due to the joint normal
structure, this implies the value of the posterior mode of p(w1|m1:h, z1:h). The details
of computation by FFBS and its eﬃcacy are discussed in the appendix: Section 3.8.1.
The use of FFBS in computation is more eﬃcient than working directly on the
quadratic loss function in eqn. (3.2) without any advanced theory of optimization.
The closed form of the optimizer involves the inverse of kh × kh matrix that is
the function of (Kt, ft, mt), the direct computation of which becomes intense, for
example, in the analysis of stock prices where k is large. We touch the details of
computational eﬃciency in Section 3.8.3.
In application, the sum-to-one constraint causes the degeneracy of the variance
matrix. This degeneracy can be inherited to other related matrices that have to be
inverted in FFBS. To avoid this problem, we use the generalized inverse based on
the singular value decomposition to compute the necessary inverse matrices. The
resulted posterior mode is still valid in the synthetic model as the posterior mode
conditional on the sum-to-one constraint.
3.4
Laplace State Space Models and Implied Loss Function
The quadratic loss function in Section 3.3 can smooth the dynamics of portfolios
over time as desired, but it is still impossible for that loss function to have portfolios
remain unchanged in some period of time either partially or wholly. In times of stable
economy and asset prices, it is rather desirable that the optimal portfolio keeps its
weights for some assets to be the same as those at the previous time, i.e. wit = wi,t−1
for some i. This property can be realized by adding penalty terms in the loss function
or, in the Bayesian synthetic models, by using shrinkage priors on state variables.
52

Motivated by the ideas above, we modify the loss function as
L(w1:h) =
h
X
t=1

α−1
t (mt −f ′
twt)2 + β−1
t w′
tK−1
t wt + 2λ−1
t 1′
k|wt −wt−1|
	
.
(3.5)
The third term for transaction costs is now the sum of absolute changes of asset
weights.
3.4.1
Synthetic Models and EM Algorithm
The synthetic state-space model is
mt
∼
N(f ′
twt, αt),
(3.6)
zt
∼
N(wt, βtKt),
(3.7)
wit −wi(t−1) : iid ∼
L(λ−1
t ),
(3.8)
where L(λ−1
t ) means the Laplace distribution with parameter λ−1
t , the density of
which is given by
p(wit|wi(t−1)) = λ−1
t
2 e−λ−1
t
|wit−wi(t−1)|.
In fact, this is the state-space version of a Bayesian lasso model (Park and Casella,
2008; Figueiredo, 2003), or might be interpreted as use of a fused lasso priors (Liu
et al., 2014), in which the posterior modes of parameters (in our case, wit −wi,t−1)
can exactly be zeros. This property of the model clearly addresses our preference on
sparsity in portfolio switching.
In computation, note that the density of the state evolution has the form of a
scale mixture of normals (Andrews and Mallows, 1974 and West, 1987) with mixing
parameter τt as
p(wt|wt−1) =
Z
N(wt|wt−1, diag(τt))
k
Y
i=1
G(τit|1, λ−2
t /2)dτt,
53

so the augmented model is
mt = f ′
twt + N(0, αt),
zt = wt + N(0, βtKt),
wt = wt−1 + N(0, Wt),
Wt = diag(τt),
τit : iid ∼G(1, λ−2
t /2).
(3.9)
Conditional on τ1:h, the model becomes a DLM, and FFBS for this conditional model
gives the posterior mode of p(w1:h|τ1:h, m1:h, z1:h). This is not the posterior mode of
interest that should maximize p(w1:h|m1:h, z1:h). To marginalize τ1:h out, we can use
the EM algorithm (Dempster et al., 1977) combined with FFBS at the maximization
step. In this algorithm, instead of working on the original loss function in eqn. (3.5)
and the non-Gaussian synthetic model in eqn. (3.6), we can use the augmented model
in eqn. (3.9) that is analytically tractable in posterior analysis, and iteratively maxi-
mize the posterior of this model and update the latent variables. In other words, we
ﬁrst deﬁne the objective function in eqn. (3.2) with parametrization of Wt = diag(τt).
w1:h is the control variables and τ1:h is considered to be the latent parameters. Note
that this is the exponential part of the augmented model in eqn. (3.9). EM methods
claims that the iterative minimization of the expectation of this objective function
ensure the convergence of the sequence of solutions to the minimizer of the original
loss function. The computation by this algorithm proceeds as follows:
EM Algorithm for Laplace Loss/Model
1. (Initialization): Set w(0)
t
arbitrarily.
We recommend to use the solution of
the quadratic loss function optimization in Section 3.3, as it is reliable as the
approximation of the target solution while being easy to compute.
2. For s = 1:S, repeat the following two steps. At s-th iteration,
(a) (Expectation): Replace τt in Wt = diag(τt) of the objective function in
54

eqn. (3.2) by
τ (s)
it
= λ2
t
w(s−1)
it
−w(s−1)
i(t−1)
 ,
and deﬁne W (s)
t
= diag

τ (s)
t

.
This computation comes from the conditional expectation of the objective
function or, essentially, E
h
W −1
t
y1:h, w(s−1)
1:h
i
.
(b) (Optimization): Implement FFBS for Model in eqn. (3.9) to ﬁnd the
optimizer w(s)
t
with replacing covariance matrix by W (s)
t
.
This is equivalent to solving the objective function in eqn. (3.2) with
Wt = W (s)
t
.
3. For a suﬃciently large S, we can use w(S)
1:h as the approximate posterior mode
of p(w1:h|y1:h).
Note that the algorithm above does not give exact zeros, i.e. wit = wi,t−1, though
the value of wit can be very similar to that of wi,t−1 numerically. One can have an
additional step at each iteration to set wit = wi,t−1 for some i if they are suﬃciently
close to one another. See Section 3.9 for details.
Sum-to-One Constraint in Laplace Models
It is worth exploring the degenerate multivariate lasso model to have the built-in
sum-to-one constraint in the synthetic model. However, to the extent we know, there
has been no research on such models. For example, Eltoft et al. (2006) develops the
multivariate Laplace distribution with one mixing random variable, but limited to
the non-degenerate case.
To impose the sum-to-one constraint on the optimizer, we take the same approach
in Section 3.3.2 for the augmented model by replacing the covariance matrix in the
55

synthetic model by Wt = diag(τt)−τtτ ′
t/1′
kτt. As in the Gaussian case, this degenerate
covariance matrix implies 1′
kwt = 1′
kw0 for all t almost surely.
3.4.2
Another Laplace Factor for Non-Negativity Constraint
In the practice of personal investments, it is sometimes of interest to take long po-
sitions only, i.e. to have portfolio weights always non-negative. The hard constraint
on this non-negativity condition is directly addressed by adding kh inequalities, i.e.
wjt ≥0 for j = 1:k and t = 1:h, which complicates the computation if k is large. To
promote computational simplicity, a partial, soft constraint is considered here with
the introduction of an additional absolute term, the sum of |wjt|, which is originally
intended for another shrinkage of weights toward zeros. This additional shrinkage
penalizes portfolios with negative weights only under the sum-to-one constraint. To
see this, note that 1′
k|wt| > 1 if the portfolio has negative weights, while 1′
k|wt| = 1
if all the weights are non-negative. Again, this does not always guarantee the non-
negativity condition theoretically, but, in practice, it is rare that the non-negativity
constraint is violated under this speciﬁcation. We see this in Section 3.6 with appli-
cation.
The new loss function based on this idea is
L(w1:h) =
h
X
t=1
n
α−1
t (mt −f ′
twt)2 + β−1
t w′
tK−1
t wt
+ 2γ−1
t 1′
k|wt| + 2λ−1
t 1′
k|wt −wt−1|
o
,
with additional tuning parameter γt. The synthetic model with augmention is
mt = f ′
twt + N(0, αt),
zt = wt + N(0, βtKt),
ut = wt + N(0, Φt),
Φt = diag(φt),
φit : iid ∼G(1, γ−2
t /2),
wt = wt−1 + N(0, Wt),
Wt = diag(τt),
τit : iid ∼G(1, λ−2
t /2),
(3.10)
56

with phantom observations, zt = ut = 0, and another mixing parameter φt for |wt|,
where τ1:h and φ1:h are mutually independent. For this model, the EM algorithm
introduced in Section 3.4.1 is still applicable with additional expectation step on φt.
The algorithm is modiﬁed as follows:
EM Algorithm for Full Laplace Loss/Model
1. (Initialization): Set w(0)
t
arbitrarily.
2. For s = 1:S, repeat the following three steps.
(a) (Expectation 1): Update τt in the objective function by
τ (s+1)
it
= λ2
t
w(s)
it −w(s)
i(t−1)
 ,
and replace Wt in the synthetic model by W (s+1)
t
= diag

τ (s+1)
t

.
(b) (Expectation 2): Update φt in the objective function by
φ(s+1)
it
= γ2
t
w(s)
it
 ,
and replace Φt in the synthetic model Φ(s+1)
t
= diag

φ(s+1)
t

.
(c) (Optimization): Implement FFBS for the model in eqn. (3.10) to ﬁnd the
optimizer w(s+1)
t
.
3. w(S)
1:h are the estimate of posterior mode of p(w1:h|m1:h, z1:h, u1:h).
Similarly to the EM method for the former Laplace model, the original algorithm
yields neither wit = 0 nor wit = wi,t−1. To realize this exact sparsity in portfolio
switching, we can take the additional step at the end of each iteration, as discussed
in details in Section 3.9.
57

3.5
Marginalization of Loss Functions
3.5.1
Joint and Marginal Loss Functions
Under the setting of sequential portfolio optimization, the decision problem at time
t = 0 concerns only the portfolio weights at the next time point, i.e. w1. The other
weights observed in the further future, w2:h, do not have to be derived at t = 0 but
later. For example, we can obtain desirable w2 with more information at time t = 1
when observing new prices r1 and updating our predictive distribution. Likewise, we
should decide w3, knowing r2 at t = 2, and continue this process sequentially. Put
diﬀerently from the viewpoint of decision theory, it is proper to set up and work on
the loss function of w1 that is independent of w2:h. In contrast, the joint loss function,
L(w1:h), is useful and easy to be speciﬁed in application to incorporate the multiple-
step ahead predictions into the decision making process. In Section 3.3 and 3.4, the
joint loss function is directly minimized in w1:h, then w1 is taken out from the entire
vector w1:h, ignoring the rest w2:h. This is justiﬁed as the minimizer of the following
proper loss function,
L(w1) = min
w2:h L(w1:h).
(3.11)
Once the loss function is converted to the synthetic model, the deﬁnition of the
loss function above is equivalent to proﬁling the joint model p(w1:h) to obtain the
optimal w1. However, this is not the only way to obtain the optimizing w1 from the
joint loss function. From this viewpoint of synthetic models, it makes more sense for
Bayesians (e.g. Polson and Scott, 2015) to marginalize out the nuisance variables to
deﬁne the marginal synthetic model, p(w1), then induce the loss function from this
model. Given the joint loss function L(w1:h), the following steps deﬁne the resulting
marginal loss function L∗(w1):
1. Find the corresponding statistical model, i.e.
likelihood p(yt|wt) and prior
58

p(wt|wt−1), from the relation
p(w1:h|y1:h) ∝
h
Y
t=1
p(yt|wt)p(wt|wt−1) ∝exp

−1
2L(w1:h)

,
with the appropriate deﬁnition of yt (e.g., in Section 3.4, the Laplace models
set yt = {mt, zt} with zt = 0) and other necessary variables.
2. Take the marginal posterior as
p(w1|y1:h) =
Z
p(w1:h|y1:h)dw2:h.
3. Deﬁne the loss function by
L∗(w1) = −2 log {p(w1|y1:h)} .
We denote the marginal loss function by L∗(·) to distinguish it from L(·) in eqn. (3.11)
that is based on proﬁling of the joint loss function.
The objective of this section is to provide the methodologies for minimization
of marginal loss functions, in order to address the diﬀerence between the two ap-
proaches: the proﬁled loss function L(w1) and marginal loss function L∗(w1).
Even if the proﬁled and marginal loss functions share the common joint loss
function in their deﬁnitions, their solutions, ˆw1 and w∗
1, could be diﬀerent in general.
One signiﬁcant exception is the case of the quadratic loss functions and synthetic
DLMs in Section 3.3.
If the synthetic model deﬁned in step 2 is a DLM as in
eqn. (3.9) (or, if the joint loss function is quadratic as in eqn. (3.2)), the optimal
portfolio obtained from the marginal loss function is, in fact, exactly the same as
that of the proﬁled one, since the joint posterior of state variables in the emulating
synthetic DLM is known to be the normal distribution and the marginal mean/mode
of a normal distribution equals the corresponding element of the joint mean/mode.
59

Thus, to see the diﬀerence between the marginal and proﬁled loss functions, we
need to examine non-Gaussian emulating synthetic models, and the Laplace-type
loss function discussed in Section 3.4 is suitable for this consideration.
3.5.2
Marginal Laplace Loss Function and Mode Searching
Consider the Laplace joint loss function in eqn. (3.5) or the statistical model in
eqn. (3.9) with the sum-to-one constraint. The density function to be maximized
is not the joint posterior, p(w1:h|Dh), but the marginal one, p(w1|Dh), where Dh =
{m1:h, z1:h}. The parameters in the augmented synthetic model before marginaliza-
tion are grouped naturally into two groups: control variables w1 and nuisance pa-
rameters (w2:h, τ1:h). We discuss the computational procedure to integrate out the
latter and maximize the marginal loss function of the former.
Unfortunately, unlike the minimization of the joint loss function in Section 3.4.1,
the direct application of EM methods for the current problem is not straightforward.
To see this diﬃculty, note that the original EM idea consists of the E-step and the
M-step. The M-step is easy to be implemented even in the marginal case, since
the expected objective function is quadratic in w1. However, in the E-step we are
required to, but unable to, derive the analytical expression of the expected logarithm
of the loss function in terms of p(w2:h, τ1:h|w1, Dh), where w1 is the tentative solution
at an iteration of the algorithm. This conditional distribution is not well known,
while we need the moments of this distribution, such as E[W −1
2 ] and E[W −1
2 w2].
To solve or avoid this problem, there are several approaches based on the exist-
ing literature, including the extension of EM methods and the direct approximation
of the target density. For example, the complex expectations in the E-step can be
replaced by simulation-based approximation so that we are still able to use the EM
method. We have explored and evaluated a range of methods, including rejection
sampling, MCMC and mean-ﬁeld approximation (Ghahramani, 1995), but they all
60

suﬀer from numerical bias and computational ineﬃciency. Other than EM methods,
as the approximating technique for the posterior density, integrated nested Laplace
approximation (INLA,
Rue et al., 2009) is widely known for its accuracy of ap-
proximation in contexts that provide some analytic structure in terms of conditional
Gaussianity. This method is, unfortunately, computationally infeasible in our case
because of the curse of dimensionality. Yet, the analytical form of the model allows
for the easy implementation of MCMC, and we utilize it to deﬁne direct numeri-
cal/analytic approximation of the marginal posterior.
The target, marginal density is approximated by its sample analogue
ˆp(w1|Dh) = 1
S
S
X
i=1
p

w1
τ (i)
1:h, Dh

,
(3.12)
with S particles, where {τ (i)
1:h}i=1:S are sampled by MCMC with {w(i)
1:h}i=1:S. The
details of this MCMC and the diagnosis of its convergence in the real-data application
in Section 3.6 are discussed in Section 3.10. Most importantly, the density in the
right-hand-side is the mixture of normals; the conditional density p

w1
τ (i)
1:h, Dh

is the retrospective marginal posterior distribution of the corresponding emulating
DLM, i.e., the normal distribution with known mean and variance computed by
FFBS. Thus, the problem reduces to the optimization of the mixture of normal
densities. We propose to use a simple updating rule based on the ﬁrst order derivative
of the target density. With a reliable initial value, the solution is iteratively updated
by the ﬁrst order condition to converge to the optimal point. The drawback of this
method is the speed of convergence, so one has to choose an initial value which is
suﬃciently close to the actual solution. The candidates for such an appropriate initial
value include sampled w1t, the means of the mixture components and the previous
optimal portfolio. For the details of the mixture representation, its optimization and
MCMC, see Section 3.10.
61

3.6
Application: FX Commodity Dataset
3.6.1
Dataset
The proposed loss functions, portfolio strategies and computational methodologies
are applied to dynamic portfolio choice in analysis and sequential forecasting of daily
ﬁnancial returns time series focused on a series of 10 FX series, 2 US stock market
index series, and 2 commodity series, over a long recent period of years. Table 3.1
shows the list of the thirteen variables (k = 13) used in this analysis. The series
of prices is recorded daily from August 8, 2000, to December 30, 2011. The whole
time series is used for the sequential learning of the model, while the prediction and
portfolio optimization starts from January 1, 2009 (T = 761).
Table 3.1: List of currencies, commodities and indeces.
Names
Acronyms
Names
Acronyms
Australian Dollar
AUD
Swiss Franc
CHF
Euro
EUR
British Pound
GBP
Japanese Yen
JPY
New Zealand Dollar
NZD
Canadian Dollar
CAD
Norwegian Kroner
NOK
South African Rand
ZAR
Oil price
OIL
Gold
GLD
Nasdaq index
NSD
S&P index
S&P
3.6.2
Models for Prediction
The model used for this analysis is a TV-VAR(2) (e.g. Primiceri, 2005; Nakajima,
2011) with the covariance modeled by a dynamic dependence network structure
(DDN, Zhao et al., 2016) to integrate the conditional independence relationships
of assets– and their dynamics over time– into the model. Prior to the main posterior
and predictive analyses, we take the ﬁrst 500 observations as the training dataset
to estimate the simultaneous correlations of returns with the TV-VAR model with
the full covariance matrix.
This preliminary analysis determines the conditional
62

independence structure assumed in the main analysis by ignoring the insigniﬁcant
correlations.
In computation, the multivariate TV-VAR model is decomposed into univariate
sub-DLMs that are processed independently and in parallel. The DDN framework
couples these parallel univariate models to deﬁne a ﬂexible global but dynamic model
representing time-varying multivariate volatility pattern across the series. Analytical
forward ﬁltering can be applied to each submodel to obtain its on-line posterior and
predictive distribution. Then, the multiple-step ahead forecast means and variances,
{ft+i, K−1
t+i}i=1:h, are computed by Monte Carlo, simulating many particles from these
predictive distributions and coupling these samples across series to deﬁne coherent
multivariate forecast. The number of particles used in this simulation-based method
is 50000 at each t. The more detailed description of the model, settings and methods
of forecasting is given in Section 3.11.
Based on the predictive information, the loss function is set up and the opti-
mization problems are solved in the ways introduced in Section 3.3, 3.4 and 3.5, in
addition to the mean-variance optimization in eqn. (3.1). We evaluate progressively
revised cumulative returns for the comparison of diﬀerent portfolios/loss functions.
3.6.3
Evaluation by Cumulative Returns
For weights w1:s, realized returns r1:s and transaction cost δ, we deﬁne cumulative
return Rs at time s by
Rs =
s
Y
t=1
h
(rt + 1k)′wt −δ1′
k|wt −wt−1|
i
−1.
(3.13)
In the following examples, we compute the resulting series of cumulative returns
with and without transaction costs; δ = 0 and 0.001, respectively. It is expected
by deﬁnition that the Markowitz approach yields more cumulative return with no
transaction cost, while the portfolios with λt works better with nonzero δ.
63

3.6.4
Results
In the following, h = 5; up to 5-day-ahead predictions are considered. The values
of the tuning parameters are changed to see their eﬀect on portfolios. We ﬁrst ﬁx
αt = 100, βt = 1, λt = 100 and γt = 100 for all t, and then change one of them. The
target returns are always set at mt = 0.0005 for all t. Approximately, daily 0.05%
returns for a year (261 days) lead to 13.9% expected annual return.
Note that, the larger λt is, the less weight we put on the transaction term. As λt
becomes larger, we expect more volatile portfolios with less penalty from transaction
costs, and vice versa.
Gaussian Models
Figure 3.3 compares the portfolio weight vectors of the quadratic loss functions in
eqn. (3.3) with diﬀerent tuning parameters, computed by FFBS as discussed in Sec-
tion 3.3, and the Markowitz-type portfolio obtained by the mean-variance optimiza-
tion deﬁned in eqn. (3.1). From the comparison with the Markowitz portfolio, it is
clear that the transaction cost in our loss function signiﬁcantly aﬀects the smooth-
ness of portfolio dynamics. We also conﬁrm that large λt makes the portfolio be
more volatile and imitate the Markowitz portfolio.
In Figure 3.4, the cumulative returns from the portfolios in Figure 3.3 are shown
for diﬀerent transaction costs. Again, as expected in Section 3.6.3, the Markowitz-
type method is totally outperformed by our portfolios in the presence of transaction
costs. Obviously, the smaller λt is, the more robust to transaction costs the cumu-
lative return becomes, as seen in the downward shift of the cumulative return curve
in the result of λt = 10000. One interesting ﬁnding here is that, during 2009, or
right after the initial phase of the economic crisis, the Markowitz rule performs as
well as our portfolios do. However, after that period, especially during late 2010 and
early 2011, the loss functions with moderate λt yield more proﬁt by tracking the
64

OIL 
EUR 
ZAR 
AUD 
JPY 
GLD 
NSD 
GBP 
NOK 
CAD 
NZD 
CHF 
S&P 
 
2009
2010
2011
2012
0.00
0.25
0.50
λ= 1
OIL 
EUR 
ZAR 
AUD 
JPY 
GLD 
NSD 
GBP 
NOK 
CAD 
NZD 
CHF 
S&P 
 
2009
2010
2011
2012
0.00
0.25
0.50
λ= 100
2009
2010
2011
2012
0.00
0.25
0.50
λ= 10000
2009
2010
2011
2012
0.00
0.25
0.50
Markowitz
Figure 3.3: Optimal portfolios of DLM loss function and Markowitz method. From left
to right, top to bottom: portfolio weights of a quadratic loss function with λt = 1, 100 and
10000 with (αt, βt) = (100, 1) and Markowitz-type portfolio.
ideal allocation with less switching, saving not only the transaction costs but also
the variance of portfolios.
Figure 3.5 shows the realized standard deviation of portfolios, i.e.
p
w′
tK−1
t wt.
The standard deviation of the minimum risk portfolio is deﬁned by
 1′
kK−1
t 1k
−1/2
and this is, in fact, the lower bound of standard deviations of the other portfolios. The
portfolios with less penalty on switching (λt = 10000) have almost as small standard
deviations as the minimum risk portfolio. The other portfolios, such as λt = 100,
have smaller standard deviation in most period than that of the Markowitz method.
This means that we do not have to inﬂate the risk of our portfolios in return to
the smoothness in their dynamics and robustness to transaction costs. While large
λt leads to small portfolio risk in general, interestingly, the relation between the
parameter λt and the risk is not linear; we see a period in the middle of 2009 in
which the standard deviation of λt = 100 is larger than that of λt = 1. It is worth
65

λ= 1 
λ= 10000 
λ= 100 
Markowitz 
2009
2010
2011
2012
0.0
0.2
0.4
λ= 1 
λ= 10000 
λ= 100 
Markowitz 
2009
2010
2011
2012
0.0
0.2
0.4
Discount = 0.001
Figure 3.4: Cumulative returns of DLM and Markowitz portfolios. Top: cumulative
returns with no transaction cost. Bottom: with 0.1% transaction cost. Four cumulative
returns of DLM portfolios with λt = 1 (red), 100 (blue), 10000 (green) and Markowitz
portfolio (grey) are shown in both pictures.
λ= 1 
λ= 10000 
Min Risk 
λ= 100 
Markowitz 
 
2009
2010
2011
2012
0.003
0.004
0.005
0.006
0.007
0.008
λ= 1 
λ= 10000 
Min Risk 
λ= 100 
Markowitz 
 
Figure 3.5: Standard deviations of DLM and Markowitz portfolios.
Four standard
deviations of DLM portfolios of λt = 1 (red), 100 (blue), 10000 (green) and Markowitz
portfolio (grey) are shown in both pictures with that of minimum risk portfolio (black).
66

mentioning that a portfolio becomes almost constant over time if transaction cost is
heavily imposed as in λt = 1, which might explain why its standard deviance can be
temporally small.
Laplace Models
In this section, we see the performance of the full Laplace loss function in Sec-
tion 3.4.2, which involves shrinkage of weights represented by 1′
k|wt|. The Laplace
loss function in Section 3.4.1 is presented in the next subsection with its marginal
equivalent discussed in Section 3.5.
Figure 3.6 shows the optimal weights obtained from Laplace loss functions with
diﬀerent tuning parameters. As expected, we see from this ﬁgure the two shrinkage
eﬀects on the diﬀerence of consecutive weights and weights themselves. First, the
hard shrinkage of weights diﬀerence leads to less switching in portfolio allocation over
time, seen in the ﬁgure as the stepwise increase and decrease of portfolio weights.
These zero changes are also observed even in the case of larger λt, where the portfolio
becomes volatile and similar to that of Markowitz.
Next, the hard shrinkage of
weights themselves, related to the penalty on short positions, makes the weights in
Figure 3.6 almost always non-negative as expected in Section 3.4.2. In addition,
it works to enforce shrinkage and some weights become zeros exactly. Figure 3.7
shows another result with (αt, βt, λt, γt) = (1, 100, 100, 100) in which we are more
ambitious to achieve the target return. Ultimately, such a portfolio is known to be
“degenerate,” having all the weights on a single asset. Reﬂecting this aspect, the
shrinkage from |wt| pushes the weights of irrelevant assets to zeros. The ﬁgure also
shows the number of nonzero weights over time out of thirteen assets, where we see
the portfolio does not always use all the thirteen assets, but some of them. This
exact shrinkage and its meaning are crucial in practice, especially when the number
of assests in consideration is large and our portfolio should consist of not all but
67

OIL 
EUR 
ZAR 
AUD 
JPY 
GLD 
NSD 
GBP 
NOK 
CAD 
NZD 
CHF 
S&P 
 
2009
2010
2011
2012
0.1
0.2
0.3
0.4
(γ, λ) = (100,100)
OIL 
EUR 
ZAR 
AUD 
JPY 
GLD 
NSD 
GBP 
NOK 
CAD 
NZD 
CHF 
S&P 
 
2009
2010
2011
2012
0.1
0.2
0.3
0.4
(γ, λ) = (1,100)
2009
2010
2011
2012
0.1
0.2
0.3
0.4
(γ, λ) = (100,1000)
2009
2010
2011
2012
0.1
0.2
0.3
0.4
(γ, λ) = (1,1000)
Figure 3.6: Optimal portfolio of the Laplace model. From top to bottom, left to right:
portfolio of Laplace loss function with (λt, γt) = (100, 100), (100, 1), (1000, 100), (1000, 1)
with (αt, βt) = (100, 1).
OIL 
EUR 
ZAR 
AUD 
JPY 
GLD 
NSD 
GBP 
NOK 
CAD 
NZD 
CHF 
S&P 
 
2009
2010
2011
2012
0.25
0.50
0.75
(α, β,γ, λ) = (1,100,100,1)
OIL 
EUR 
ZAR 
AUD 
JPY 
GLD 
NSD 
GBP 
NOK 
CAD 
NZD 
CHF 
S&P 
 
2009
2010
2011
2012
5
10
Figure 3.7: A Laplace portfolio with the number of active weights. Top: portfolio of
Laplace loss function with (αt, βt, λt, γt) = (1, 100, 100, 100). Bottom: number of non-zero
weights in the portfolio.
68

several assets that are really necessary.
These two types of shrinkage are balanced by two tuning parameters: λt and γt.
Large λt makes the eﬀect of |wt| relatively ignorable, meaning that we prefer the
persistency of portfolios and expect to see more stepwise allocation switch in our
portfolio. Conversely, if γt is suﬃciently large, then we appreciate the non-negativity
and sparsity of portfolio more, resulting in dynamically switching portfolio weights
with fewer assets, since we allow for more switching by discounting the sparsity eﬀect
from |wt −wt−1| by relatively small λt.
γ= 10 
γ= 1000 
Markowitz 
γ= 100 
Gaussian: λ= 100 
 
2009
2010
2011
2012
0.0
0.2
0.4
0.6
γ= 10 
γ= 1000 
Markowitz 
γ= 100 
Gaussian: λ= 100 
 
2009
2010
2011
2012
0.0
0.2
0.4
Discount = 0.001
Figure 3.8: Cumulative returns of Laplace portfolios for λt = 100. While the weights for
transaction costs (|wt −wt−1|) are ﬁxed as λt = 100 in addition to (αt, βt) = (100, 1), those
for sparsity in portfolio (|wt|) are γt = 10, 100 or 1000 (red, blue and green, respectively).
For comparison, the cumulative returns of Gaussian portfolio with γt = 100 (dotted black)
and Markowitz (grey) are shown.
The cumulative returns are shown in Figure 3.8 and 3.9. All the results show the
strong robustness to the transaction costs, thanks to the hard shrinkage on portfolio
switching. With λt and γt being chosen appropriately, the portfolio of the Laplace
loss function can outperform both those of DLM loss functions and Markowitz-type
69

λ= 10 
λ= 1000 
Markowitz 
λ= 100 
Gaussian: λ= 100 
 
2009
2010
2011
2012
0.0
0.2
0.4
λ= 10 
λ= 1000 
Markowitz 
λ= 100 
Gaussian: λ= 100 
 
2009
2010
2011
2012
0.0
0.2
0.4
Discount = 0.001
Figure 3.9: Cumulative returns of Laplace portfolios for γt = 100. Conversely to Fig-
ure 3.8, we ﬁx γt = 100 and change the value of λt to 10, 100 and 1000.
method with and without transaction costs. In Figure 3.8, we see the robustness of
cumulative returns to the value of γt, while in Figure 3.9 the choice of λt aﬀects the
performance of portfolios signiﬁcantly.
Marginal Loss Approach
Figure 3.10 shows the optimal weights of the proﬁled Laplace loss function in Sec-
tion 3.4.1 and the marginal Laplace loss function in Section 3.5 where γt = ∞and
|wt| terms are ignored. The patterns of portfolio switching in both models are almost
the same. For example, both portfolios consist mainly of JPY in 2009, but later fa-
vor GBP and CAD. Yet, the diﬀerence between these two portfolios are clear in the
shrinkage on weights diﬀerence; the proﬁled loss function leads to a longer period in
which some of the weights are totally unchanged, while the marginal loss function
allows for ﬂexibility in portfolio dynamics as the quadratic loss function does. It is
not that the marginal portfolio has no shrinkage at all; the stepwise weights shift
70

exists in the marginal portfolios, though they last for a short period of time and this
is not clearly seen in the ﬁgure.
OIL 
EUR 
ZAR 
AUD 
JPY 
GLD 
NSD 
GBP 
NOK 
CAD 
NZD 
CHF 
S&P 
 
2009
2010
2011
2012
0.0
0.2
0.4
λ= 100 (Profiled)
OIL 
EUR 
ZAR 
AUD 
JPY 
GLD 
NSD 
GBP 
NOK 
CAD 
NZD 
CHF 
S&P 
 
2009
2010
2011
2012
0.0
0.2
0.4
λ= 100 (Marginal)
Figure 3.10: Portfolios of proﬁled and marginal Laplace models.
Top: portfolio of
proﬁled Laplace loss function with λt = 100. Bottom: portfolio of marginal Laplace loss
function with λt = 100.
The cumulative returns without transaction costs are presented in Figure 3.11.
While the proﬁled portfolio with λt = 100 has the highest cumulative return in this
group, the marginal portfolio is relatively “robust” to the value of λt. The reason that
the marginal portfolio outperforms the proﬁled one when λt = 10 is that the proﬁled
portfolio becomes completely constant because of the strong eﬀect of transaction
costs, while the marginal portfolio remain persistent but dynamic.
This marginal strategy, which is insensitive to the tuning parameter λt, could be
a conservative approach to the optimization problem when an investor is afraid of
the misspeciﬁcation of his or her loss function. Even if one uses too large or too small
λt, the optimal portfolios of marginal models do not suﬀer from a serious failure as
those of the joint models do.
71

Profiled: λ= 100 
Marginal: λ= 100 
Profiled: λ= 10 
Marginal: λ= 10 
2009
2010
2011
2012
0.0
0.1
0.2
0.3
0.4
0.5
0.6
Profiled: λ= 100 
Marginal: λ= 100 
Profiled: λ= 10 
Marginal: λ= 10 
Figure 3.11: Cumulative returns of proﬁled and marginal Laplace portfolios. No trans-
action cost is used (δ = 0). Four portfolios are distinguished by red lines for proﬁled (joint)
loss functions, blue lines for marginal ones, solid lines for λt = 100 and dotted lines for
λt = 10.
3.7
Summary Comments
In this chapter, the new loss functions formed by the multi-step ahead predictions
and transaction costs are proposed and the computational methods tailored to those
loss functions are developed in detail. The application shows empirical evidence that
the portfolio strategy based on the proposed loss functions consistently outperforms
the mean-variance optimization with and without transaction costs. By choosing
appropriate loss functions and tuning parameters, it is possible to customize the
portfolio to avoid suﬀering from a large loss of returns in the economically challeng-
ing period during/after the recession and to achieve reasonable proﬁt in the stable
economy after 2011.
The key theme of this chapter, or the “translation” of loss functions to synthetic
models, can lead to the further development and extension of this type of research
72

in the future. The idea of synthetic models allow us to start from the statistical
models to construct the loss function, as we make good use of the sparseness in the
Laplace models in Section 3.4.1 and deﬁne the marginal loss function in Section 3.5.
By this approach, many promising loss functions, which have not been tested in the
ﬁeld of ﬁnance, might be proposed for evaluation in the future. For example, the
asymmetric penalty for the target return, in which we penalize the excess return less
(or, ideally, not at all), can be formed through the skewed distributions. Also, as the
loss functions are sophisticated in this way, more technical methods of estimation
in statistics, such as simulation based approach, are expected to be useful in this
optimization problem.
73

3.8
Appendix: Forward Filtering with Multiple Observations
3.8.1
Forward Filtering
The DLM with random walk state evolution is written as
yt = F ′
tθt + vt,
vt ∼N(0, Vt),
θt = θt−1 + wt,
wt ∼N(0, Wt),
where yt is k × 1 observational vector and θt is p × 1 state vector. All the necessary
matrices, including Ft, Vt and Wt, are assumed to be known; this assumption is
satisﬁed in the synthetic models of interest. Deﬁne the update of information at
time t by Dt = {yt} ∪Dt−1.
Forward Filtering:
• Posterior at t −1: p(θt−1|Dt−1) = N(mt−1, Ct−1).
• Prior at t: p(θt|Dt−1) = N(at, Rt),
where at = mt−1 and Rt = Ct−1 + Wt.
• Forecast at t: p(yt|Dt−1) = N(ft, Qt),
where ft = F ′
tmt−1 and Qt = F ′
tRtFt + Vt.
• Posterior at t: p(θt|Dt) = N(mt, Ct),
where mt = at + At(yt −ft), Ct = Rt −AtQtA′
t and At = RtFtQ−1
t .
See West and Harrison (1997) for the proof and more details.
3.8.2
Two Observational Equations with the Common State
Consider the DLM with two observational equations with the common state vector,
y1t = F ′
1tθt + v1t,
v1t ∼N(0, V1t),
y2t = F ′
2tθt + v2t,
v2t ∼N(0, V2t),
θt = θt−1 + wt,
wt ∼N(0, Wt),
74

where y1t and y2t are the k1- and k2-dimensional vectors, respectively, and mutually
independent. The set of information is, in this context, Dt = {y1t, y2t} ∪Dt−1, and
the on-line posterior of θt is deﬁned accordingly. To compute the posterior, we can
still use the forward ﬁltering by stacking the vectors and matrices as
yt =
y1t
y2t

(k × 1),
Ft =

F1t
F2t

(p × k),
Vt =
V1t
0
0
V2t

(k × k),
where k = k1 + k2. Despite its theoretical simplicity, this approach could be compu-
tationally burdensome with large k, especially in inverting k × k-matrix Qt.
To soften this problem, the method of ﬁltering is decomposed into two steps by
processing y1t and y2t to make the size of inverse matrices to be k1 and k2. This
method ﬁrst ignores the second observation and work on the following submodel
y1t = F ′
1tθt + v1t,
v1t ∼N(0, V1t),
θt = θt−1 + wt,
wt ∼N(0, Wt),
to obtain the half-updated temporal posterior
p(θt|y1t, Dt−1) = N(m1t, C1t).
This is, in fact, considered the prior distribution when integrating the second obser-
vation into the current posterior, since the full on-line posterior has the form
p(θt|Dt) ∝p(y2t|θt, y1t, Dt−1)p(θt|y1t, Dt−1)
= p(y2t|θt)p(θt|y1t, Dt−1),
where the second equation is justiﬁed by the the conditional independence of obser-
vations. This implies that the forward ﬁltering for DLM with a single observation
can be used for computing the above distribution by using N(m1t, C1t) as “prior at
t” for the second observation. Call this repeated use of forward ﬁltering “sequential
forward ﬁltering.” The algorithm is summarized as follows:
75

Sequential Forward Filtering:
• Posterior at t −1: p(θt−1|Dt−1) = N(mt−1, Ct−1).
• Stage 1: Process y1t and implement forward ﬁltering.
– Prior at t: p(θt|Dt−1) = N(a1t, R1t).
– Forecast at t: p(y1t|Dt−1) = N(f1t, Q1t).
– Posterior at t: p(θt|y1t, Dt−1) = N(m1t, C1t).
• Stage 2: Use the posterior to be the prior to process y2t.
– Prior at t: Deﬁne the prior by N(m1t, C2t) as
p(θt|y1t, Dt−1) = N(a2t, R2t) = N(m1t, C2t).
Implement forward ﬁltering:
– Forecast at t: p(y2t|y1t, Dt−1) = N(f2t, Q2t).
– Posterior at t: p(θt|y2t, y1t, Dt−1) = N(m2t, C2t).
• On-line posterior: p(θt|Dt) = N(mt, Ct) = N(m2t, C2t).
Again, the matrix inversion needed in this procedure is for k1 × k1- and k2 × k2-
matrices. Considering the cost of the direct inversion of k × k-matrix that is roughly
O(k3), this sequential approach has the great advantage in computation.
Note that this is easily extended to the case of N observations with the single com-
mon state vector. In our portfolio research, y1t = mt, y2t = zt = 0 in eqns. (3.3,3.9)
and y3t = ut = 0 in eqn. (3.10). Another advantage of this approach can be seen in
this application as the easiness to add and drop the new component of the model. It
is also useful when we have some missing observation in some period. This ﬂexibility
is helpful in simplifying the code for computations.
76

It is also worth mentioning that the multiple obvervations in DLMs do not aﬀect
the retrospective analysis; we compute p(θ1:T|DT) and its marginal distributions
completely in the same way as we do in the single observation case. Denote the
on-line prior and posterior by N(at, Rt) and N(mt, Ct). With the single observation,
the marginal and conditional recursive posteriors are as follows:
Backward Smoothing/Sampling:
• p(θt−1|DT) = N(at(−1), Rt(−1)),
where at(−1) = mt−1 + Bt−1(mt −at), Rt(−1) = Ct−1 −Bt−1[Ct −Rt]B′
t−l and
Bt−1 = Ct−1R−1
t .
• p(θt−1|θt, DT) = N(ht−1, Ht−1),
where ht−1 = mt−1 + Bt−1(θt −at) and Ht−1 = Ct−1 −Bt−1RtB′
t−1.
As seen in the list of distributions above, the vectors and matrices needed in this
analysis are all about the state variables, not observations. Therefore, even in the
case of multiple observations, one can still use the same backward smoothing or
sampling after he or she has ﬁnished the sequential forward ﬁltering by keeping the
on-line posterior mean and variance (mt, Ct). In the sequential forward ﬁltering, the
on-line prior mean and variance (at, Rt) are obtained as (a1t, R1t).
3.8.3
Computational Eﬃciency
We emphasized the computational eﬃciency of FFBS in Section 3.3.3, but, of course,
there are many methodological advances in the area of optimization and matrix
manipulation that are potentially applicable for our study. For example, we pointed
out the diﬃculty in inverting kh×kh-matrix in the optimal portfolio, but the sparsity
of this matrix can be exploited to contribute to more eﬃcient computation. The
general computational algorithm for this type of matrix, called block-banded matrices
77

(in our case, with lag 1), is developed by Asif and Moura (2005), in which the
inversion of the kh × kh matrix is reduced to those of k × k submatrices. Similarly,
FFBS used in our method only needs the inverses of submatrices, from which we can
conﬁrm the computational eﬃciency of our method and conclude that the sequential
FFBS is at least as eﬃcient as the optimization method with the advanced matrix
calculation technique.
3.9
Appendix: Exact Shrinkage in EM Algorithm
Section 3.4.1 shows the rough sketch of the EM methods used for the Laplace models,
but its Expectation step needs more detailed explanation for implementation.
Suppose we have τ (s)
it
= λ2
t|w(s)
it −w(s)
i(t−1)| = 0 at s-th iteration. Then, the ex-
pectation of the objective function diverges unless wit −wi(t−1) = 0 in which the
corresponding term that involves τit is erased before expectation. This means that
any decision that does not satisfy wit −wi(t−1) = 0 cannot be the optimal point of
the objective function. Hence, the diﬀerence at the next iteration must be zero, i.e.
w(s+1)
it
−w(s+1)
i(t−1) = 0. In computation, if we encounter this situation, we use τit = 0
and the SVD-based generalized inverse matrix of degenerated Wt. By this trick, we
can numerically ensure that w(s+1)
it
−w(s+1)
i(t−1) = 0 in the algorithm.
Note that the algorithm itself does not yield wit−wi(t−1) = 0 which we appreciate
as the sparsity in portfolio switching. In the actual computation in Section 3.6, we
insert (as noted in the section) an additional step where we set w(s+1)
it
−w(s+1)
i(t−1) = 0
if |w(s+1)
it
−w(s+1)
i(t−1)| < ϵ for some pre-speciﬁed threshold ϵ (we used ϵ = 0.0001). We
may implement this additional step only if the monotonicity of the objective function
is guaranteed so that the convergence of series is still assured. Similarly, for the full
Laplace model in eqn. (3.10), we use two thresholds for both wt −wt−1 and wt.
Because of this thresholding, the portfolio weights are classiﬁed into three groups:
78

changed, unchanged and thresholded to zero. The application of this thresholding
might violate the sum-to-one constraint, so the thresholded weights must be added
to the other active weights (see Section 3.10.3).
We have to be careful to avoid
breaking the monotonicity of the objective function by this additional step.
3.10
Appendix: Posterior Marginal Mode of Laplace Models
3.10.1
Gibbs Sampler and Maximization for Marginal Models
To construct the approximate density in eqn. (3.12), we need to sample from the
(joint) posterior of the model in eqn. (3.9). The Gibbs sampler for our model is the
same as that of lasso regression in Park and Casella (2008) with re-parametrization
and the slight modiﬁcation by FFBS.
Gibbs Sampler for Laplace State-Space Models:
Suppose t = 0. At each iteration i ∈1:S,
1. Sample j-th element of vector τt from
τ (i)
jt |w(i−1)
1:h
∼GIG(p = 1/2, a = λ−2
t , b = (wjt −wj(t−1))2),
independently across j and t. This is the Generalized Inverse Gaussian distri-
bution with density deﬁned by
p(x|p, a, b) ∝xp−1 exp{(ax + b/x)/2}.
2. Sample w(i)
1:h|τ (i)
1:h by Backward Sampling.
3. For the later use, record the marginal mean and variances, (m(i)
1 , C(i)
1 ), in
p(w1|τ (i)
1:h, Dh) = N(w1|m(i)
1 , C(i)
1 ).
In application of Section 3.6, we sampled 2000 particles after 1000 burn-in. Fig-
ures 3.12 and 3.13 show some convergence diagnoses for w1:3,t+1 and τ1:3,t+1 at t = 1
79

(this means we are at t = 1 and the loss functions has w(t+1):(t+h).). The chain is
mixing well, and this is true for the other variables and time points.
With the samples {w(i)
1:h, τ (i)
1:h} and the by-product {m(i)
1 , C(i)
1 }, the estimate be-
comes
ˆp(w1|Dh) = 1
S
S
X
i=1
N(w1|m(i)
1 , C(i)
1 ).
Here, note that we know the normality of p(w1|τ (i)
1:h, Dh) = N(w1|m(i)
1 , C(i)
1 ) by the
theory of FFBS.
The next step is the maximization of this mixture of normals. The maximizer of
the mixture density must satisfy the ﬁrst order condition,
w1 =
(
1
S
S
X
i=1
N(w1|mi, Ci)C−1
i
)−1 (
1
S
S
X
i=1
N(w1|mi, Ci)C−1
i mi
)
(3.14)
with mi = m(i)
1
and Ci = C(i)
1 . We use this equation for the iterative optimization,
so that the solution in the s-th step w(s)
1
is obtained from the equation above with
w1 = w(s)
1
in the left-hand-side and w1 = w(s−1)
1
in the right. In application, we have
100 iterations of this update.
3.10.2
Sum-to-One Constraint
Note that, if the sum-to-one constraint is imposed on the original model by setting
Wt = diag(τt) −τtτ ′
t/1′
kτt, then the full conditional of τt is not necessarily a GIG
distribution as in the previous section.
To sample τt in such a case, we use an
independent Metropolis-Hastings algorithm with this GIG distribution as a proposal
distribution that is based on the model with Wt = diag(τt). Though the degenerate
normal distribution has no proper density, we deﬁne its approximation based on the
idea of SVD-based generalized inverse, by using Wt = diag(τt) −τtτ ′
t/(1′
kτt + c) when
evaluating the proposal density. The constant c should be very small and we use
80

0
300
600
900
0
1
Correlogram
0
300
600
900
0
1
Correlogram
0
300
600
900
0
1
Correlogram
0
1000
2000
0
200 w1,t+1
0
1000
2000
0
200 w2,t+1
0
1000
2000
0
200 w3,t+1
-100
0
100
0.005
0.010
0.015
Density
-250
0
250
0.0025
0.0050
0.0075
Density
-250
0
250
0.0025
0.0050
Density
Figure 3.12: Convergence diagnoses for w1:3,t+1 at t = 1. From the top row to the
bottom one, the correlograms, sample paths and estimated marginal densities are shown.
0
300
600
900
0
1
Correlogram
0
300
600
900
0
1
Correlogram
0
300
600
900
0
1
Correlogram
0
1000
2000
5
10
15 τ1,t+1
0
1000
2000
5
10
15 τ2,t+1
0
1000
2000
5
10
15 τ3,t+1
0
5
10
0.2
0.4
0.6
Density
0
10
20
0.2
0.4
Density
5
15
0.2
0.4
Density
Figure 3.13: Convergence diagnoses for τ1:3,t+1 at t = 1. The sample paths shown in
the second row are re-scaled to be 10−4τit.
81

c = 10−9 in our study in Section 3.6. The acceptance probability of proposed sample
τ new
it
conditional on previous sample τ old
it
and the other parameters is
s
c + 1′
kτ new
t
c + 1′
kτ old
t
,
where τ new
t
= (τ1t, · · · , τ new
it
, · · · , τkt)′ and τ old
t
= (τ1t, · · · , τ old
it , · · · , τkt)′.
We ob-
served that this acceptance probability is almost always high enough, about 98%.
Also, because of the sum-to-one constraint, the sampled Ci, hence the matrix
that is inverted in eqn. (3.14), are rank-deﬁcient. We use the generalized inverse
based on singular value decomposition in FFBS of Gibbs Sampler and optimization.
This usage of generalized inverse ensures the sum-to-one condition at every iteration
of optimization.
3.10.3
Realization of Exact Zero Weights and Transitions
In the iterations of the Gibbs sampler and optimization in Section 3.10.1, there
is no step where w1 can shrink to the old portfolio w0. One can make the add-
hoc “correction” to this output of the optimization as follows. Denote the original
maximizer obtained from the optimization by w1. We want the additional constraint
that requires wi1 = wi0 if |wi1 −wi0| < ϵ. This destroys the sum-to-one constraint,
so we need another correction after implementing this constraint. Suppose there
are k1 ≤k elements in w1 that satisﬁes |wi1 −wi0| ≥ϵ, denote the set of those
elements by S and set k0 = k −k1. Deﬁne the diﬀerence between the two portfolios
by ∆= P
i̸∈S(wi1 −wi0). Then, we “correct” w1 to w∗
1 so that it satisﬁes both the
sum-to-one constraint and exact shrinkage. We do this by setting w∗
i1 = wi0 if i ̸∈S
and w∗
i1 = wi1 −∆/k1 otherwise. The threshold used in Section 3.6 is ϵ = 0.0001.
82

3.11
Appendix: Dynamic Dependence Network Models
In this appendix, the model used in analyzing and predicting the log prices is ex-
plained. It is largely based on the work by Zhao et al. (2016) and called Dynamic
Dependence Network Models (DDNMs). Denote the k × 1 vector of asset prices by
yt. This follows the TV-VAR(2) as
yt ∼N(Φtxt, Σt),
where Φt is the matrix of dynamic regression coeﬃcients and xt = (1, y′
t−1, y′
t−2)′.
The stochastic volatility matrix, Σt, is supposed to have the following Cholesky
decomposition (or, if necessary, the singular value decomposition),
Σt = AtDtA′
t,
(3.15)
where Dt = diag(v1t, . . . , vkt) and At is the lower triangular matrix with diagonal
ones. Note that the inverse of At is also lower triangular, so write A−1
t
= I −Γt
where Γt is the lower triangular matrix with diagonal zeros. Then, the model is
rewritten as
yt = Φtxt + Γtyt + N(0, Dt).
Each j-th element of the vector follows
yjt = x′
tφjt + y′
pa(j),tγjt + N(0, vjt),
(3.16)
where φ′
jt is the j-th row of matrix Φt, pa(j) is the parental set deﬁned as the indices
of j-th row of Γt with non-zero elements, and ypa(j),t and γjt are the corresponding
sub-vectors with |pa(j)| elements of yt and j-th row of Γt. The rest of the model
has the same structure as that of DLMs. The state parameters are (φjt, γjt) and
these are assumed to follow Gaussian random walks with the discount factor for the
state innovations. The observational variance vjt is modeled by stochastic volatility,
83

i.e., the traditional gamma-beta random walk based on another speciﬁed (volatility)
discount factor.
See Zhao et al. (2016) and West and Harrison (1997) for more
details.
Given the parental sets pa(j), the model is estimated eﬃciently through indepen-
dent analyses of the univariate submodels in Equation (3.16). This strategy allows
us to implement forward ﬁltering in each submodels to construct analytically the
online posterior of state parameters and one-step forward predictive distribution of
obervations. In the computation of h-step ahead forecasts, however, the analytical ex-
pression is no longer obvious because of the future observation yt+i (1 ≤i ≤h) in the
predictor xt+h that is unknown at time t. For this reason, we use the simulation-based
method to generate simulated predictions. In other words, we generate suﬃciently
many random variables from
p(y(t+1):(t+h)|Dt) =
h
Y
i=1
p(yt+i|Dt+i−1),
sequentially from yt+1 to yt+h.
The observational variable yt in the model above is usually the log prices, yt =
log pt. In contrast, the forecast we need in portfolio choice is on the return scale.
The return from i-th asset is deﬁned by rit = (pit −pi(t−1))/pi(t−1). Similarly, the
return of the h-step ahead forecast at time t is ri(t+h)|t = (pi(t+h) −pit)/pit. To obtain
the moments of these h−step ahead returns, we can simply transform the sampled
prices into returns ri(t+h)|t and then calculate the sample analogues of the moments
of returns.
Before starting the posterior analysis and prediction, we have to ﬁx the parental
sets. To do this, we take the naive thresholding approach with the estimate of Γt in
a speciﬁed training period. First, we use the ﬁrst 500 observation of the time series
as a training set and estimate the model with full Γt matrix with pa(j) = 1:(j −1).
84

Table 3.2: Parental sets used in prediction.
Parent j
pa(j)
OIL
∅
GBP
∅
EUR
∅
NOK
EUR
ZAR
GBP NOK
CAD
∅
AUD
NOK CAD
NZD
AUD
JPY
GBP EUR CAD AUD
CHF
∅
GLD
GBP ZAR CAD CHF
S&P
GBP EUR NOK CAD AUD NZD
NSD
AUD JPY CHF S&P
Then, the Cholesky decomposition of the posterior mean of ΓT is computed, where
T here is the end point of the training dataset. Finally, we set the threshold d, and
deﬁne the parental set pa(j) by setting i ∈pa(j) for each j ≥2 and i ≤j −1 if the
(i, j)-element of the estimated Γt is above the threshold. Note that pa(1) = ∅.
The choice of the threshold is crucial. The larger the threshold is, the closer to
the full covariance our model becomes. The threshold controls the number of condi-
tional independence assumptions, aﬀecting the uncertainty in the resulting predictive
information. After trying several values of the threshold, we decided to use d = 0.2
to choose the parental sets. The resulting parental sets are displayed in Table 3.2.
All the results presented in Section 3.6 are based on the predictions obtained
with 500 training time series, 0.97 for discount factors of stochastic volatilities, 0.98
for those of state evolutions, 50000 simulation to obtain the predictive means and
variances.
85

3.12
Appendix: Supplemental Analysis
3.12.1
Choice of Tuning Parameters
In the main analysis of the quadratic loss functions, we used (αt, βt) = (0.01, 1) for
all t and the three values of λt. Now we change these tuning parameters to see their
eﬀects on the resulting portfolios.
Similarity to Markowitz Rule
Fixing λt = 10000 and βt = 1, we try αt = 0.0001, 0.001, 0.01, 0.1, and 1. With
the strong discount of the transaction cost, the portfolio is expected to be similar
to Markowitz portfolio. The choice of small αt relative to (βt, λt) means the loss
from MSE has more impact on the decision. Remember that this includes the hard
constraint on the achievement of the target return as the limiting case where αt →0.
Figures 3.14 and 3.15 show the cumulative return and standard deviation of
those portfolios. With no transaction cost, the cumulative returns are almost the
same, while our portfolios still possess their robustness to the transaction costs. The
standard deviation with values of αt is larger than the lower bound but less than that
of Markowitz rule. This indicates that having the soft shrinkage on MSE with the
moderate value of αt can achieve the intermediate state between the minimum-risk
portfolio and the proﬁtable one by the hard constraint on the target return.
Balance between MSE and Variance
In contrast to the main analysis, consider a large discount on the variance term and
more weight on the MSE term by αt = 0.01 and βt = 1. In other words, we now
persue more proﬁt by achieving the target return with more risk. The results are
shown in Figures 3.16 and 3.17. Unfortunately, these over-ambitious strategies were
not successful in this example, as seen in less return and the inﬂated risk.
86

α= 0.0001 
α= 0.1 
Markowitz 
α= 0.01 
α= 1 
 
2009
2010
2011
2012
0.0
0.2
0.4
α= 0.0001 
α= 0.1 
Markowitz 
α= 0.01 
α= 1 
 
2009
2010
2011
2012
-0.1
0.0
0.1
0.2
0.3
0.4
Discount = 0.001
Figure 3.14: Cumulative returns for λt = 10000. Top: cumulative returns with no
transaction cost. Bottom: with 0.1% transaction cost. Four cumulative returns of DLM
portfolios of λt = 1 (red), 100 (blue), 10000 (green) and Markowitz portfolio (grey) are
shown in both pictures.
α= 0.0001 
α= 0.1 
Markowitz 
α= 0.01 
α= 1 
Min Risk 
2009
2010
2011
2012
0.003
0.004
0.005
0.006
0.007
0.008
α= 0.0001 
α= 0.1 
Markowitz 
α= 0.01 
α= 1 
Min Risk 
Figure 3.15: Standard deviation for λt = 10000. The black line shows the standard
deviation of the minimum risk portfolio.
87

λ= 1 
λ= 10000 
λ= 100 
Markowitz 
2009
2010
2011
2012
0.0
0.2
0.4
λ= 1 
λ= 10000 
λ= 100 
Markowitz 
2009
2010
2011
2012
0.0
0.2
0.4
Discount = 0.001
Figure 3.16: Cumulative returns for (αt, βt) = (0.01, 1). Top: cumulative returns with
no transaction cost. Bottom: with 0.1% transaction cost. Four cumulative returns of DLM
portfolios of αt = 0.0001 (red), 0.01 (blue), 0.1 (green), 1 (pink) and Markowitz portfolio
(grey) are shown in both pictures.
λ= 1 
λ= 10000 
Min Risk 
λ= 100 
Markowitz 
 
2009
2010
2011
2012
0.004
0.006
0.008
0.010
0.012
λ= 1 
λ= 10000 
Min Risk 
λ= 100 
Markowitz 
 
Figure 3.17: Standard deviation for (αt, βt) = (0.01, 1).
88

Use of Prior on Tuning Parameters
The diﬃculty of tuning the ﬁxed parameters motivates us to put a prior on (αt, βt, λt).
Though the functional form of the loss function becomes unclear, the use of priors
in the synthetic model is useful especially in the case where one cannot write down
his or her preference in the form of the tuning parameters. The computation of the
posterior mode is feasible by, for example, the EM methods with the gamma priors.
Yet, one has to make the “initial guess” on the values of his or her tuning parameters
to set the hyperparameters of those priors.
3.12.2
Additional Figures for Proﬁled and Marginal Portfolios
Figures 3.18 and 3.19 show the proﬁled and marginal portfolios with the smaller and
lager values of λt than in the main analysis.
OIL 
EUR 
ZAR 
AUD 
JPY 
GLD 
NSD 
GBP 
NOK 
CAD 
NZD 
CHF 
S&P 
 
2009
2010
2011
2012
0.0
0.2
0.4
λ= 10 (Profiled)
OIL 
EUR 
ZAR 
AUD 
JPY 
GLD 
NSD 
GBP 
NOK 
CAD 
NZD 
CHF 
S&P 
 
2009
2010
2011
2012
0.0
0.2
0.4
λ= 10 (Marginal)
Figure 3.18: Proﬁled and marginal Portfolios for λt = 10.
Top: proﬁled, Bottom:
marginal.
89

OIL 
EUR 
ZAR 
AUD 
JPY 
GLD 
NSD 
GBP 
NOK 
CAD 
NZD 
CHF 
S&P 
 
2009
2010
2011
2012
0.0
0.2
0.4
λ= 1000 (Profiled)
OIL 
EUR 
ZAR 
AUD 
JPY 
GLD 
NSD 
GBP 
NOK 
CAD 
NZD 
CHF 
S&P 
 
2009
2010
2011
2012
0.0
0.2
0.4
λ= 1000 (Marginal)
Figure 3.19: Proﬁled and marginal portfolios for λt = 1000. Top: proﬁled, Bottom:
marginal.
90

4
Emulation of Dynamic Gravity Model
by Bayesian Dynamic Flow Models
4.1
Introduction
Traﬃc ﬂow count data in networks arise in many applications, such as automobile or
aviation transportation, certain directed social network contexts, and internet stud-
ies. This increasing access to streaming data on large and evolving networks drives
interest in formal models to quantify stochasticity and structure of latent processes
underlying observable data streams. A key challenge is to deﬁne relevant statistical
models that yield computationally eﬃcient and scalable methods for streaming data,
and that lead to sound statistical methods for monitoring, short-term prediction,
single sample inference, and multi-sample comparisons across contexts.
We contribute to this area with an applied study that builds on two method-
ological advances. First, we develop a ﬂexible, adaptive (non-stationary and non-
Gaussian) state-space model for streaming count data. The analysis is explicitly
designed to be computationally eﬃcient for on-line data analysis; it scales quadrat-
ically in the number of network nodes, and is inherently parallelizable so enables
91

distributed implementation for streaming data on increasingly large networks. We
achieve this by (a) theory-based decoupling of models for individual network node-
pair ﬂows, and (b) adapting a computationally trivial univariate stochastic volatility
model (e.g. West and Harrison, 1997, Section 10.8) to apply to latent rates of under-
lying ﬂows. This Bayesian dynamic ﬂow model (BDFM) is developed in Section 4.2
with its underlying model theory and Bayesian analysis.
Second, we use the BDFM as an emulator of a dynamic gravity model (DGM). The
DGM represents ﬂows between network nodes with time-varying random processes
for node-speciﬁc main eﬀects and node-pair interaction eﬀects. This is fundamentally
interesting for understanding dynamics in network ﬂows and node-node interactions.
However, the fully Bayesian analyses of speciﬁc classes of gravity models involve
signiﬁcant computational demands inherent in the use of MCMC and related meth-
ods. In any realistic dynamic extension appropriate for scalable, on-line analysis of
streaming network ﬂow data, such methods must be avoided. Emulation analysis
uses the unconstrained BDFM as a surrogate model, mapping posterior distribu-
tions to those of a coupled DGM. This exploits the statistical ﬂexibility/adaptability
and computational eﬃciency/scalability of the BDFM to create posterior inferences
on the more highly structured and substantively focused DGM whose analysis is
otherwise far more challenging. This is developed in Section 4.3.
Section 4.5.4 concerns application of this emulation analysis in a study of past
browser traﬃc on FoxNews websites. We focus on ﬂows of visitors to a set of domains
of webpages in a structurally well-deﬁned but dynamic/evolving network. The anal-
ysis by BDFM and DGM reveals the dynamic aspects of network structure, including
overall traﬃc population, popular/unpopular domains and outstanding ﬂows in the
network. Summary comments conclude this chapter in Section 4.6.
92

4.2
Bayesian Dynamic Flow Models
We deﬁne a state-space model for the univariate series of counts, {yt}t=1:T, where
yt ∈Z+. We assume conditional Poisson sampling models for observations at each
time point; yt|φt ∼Po(φt). The question is how the state evolution of φt, or the prior
of φt, should be modeled in order to appropriately allow for temporal changes while
also providing analytic tractability. One approach to this goal is to have a model that
yields marginal prior gamma distributions for φt at each time, so deﬁning conjugate
prior-posterior updates. In other words, we require the prior, or p(φt|Dt−1), to be
gamma distributed, and deﬁne the state evolution, or the conditional distribution
p(φt|φt−1, Dt−1), so that it matches this property.
The eﬀort to ﬁnd such an ideal state-space model dates back to Smith (1979),
where he proposes “power discounting” to ensure that the current marginal posterior
distribution becomes the conjugate prior for the likelihood of the next observation.
Though this idea is general and applicable to other types of state-space models, it
lacks a probability model justiﬁcation; the state evolution is not deﬁned explicitly.
This research is reviewed in Section 4.2.3 as a special case of our state-space mod-
els. However, the standard gamma-beta discount volatility model as used in earlier
chapters is such a formal model, and is adopted here.
Denote by Dt the set of information available at time t that includes y1:t. Suppose
the posterior distribution at time t −1 is p(φt−1|Dt−1) = Ga(φt−1|rt−1, ct−1). Then,
conditional on Dt−1 and φt−1, the state evolution at time t is deﬁned by
φt = φt−1ηt/δ,
(4.1)
where ηt ∈(0, 1) is the stochastic, multiplicative contamination term that is condi-
tionally independent of φt−1 and distributed as
ηt|Dt−1 ∼Be(δrt−1, (1 −δ)rt−1),
93

and δ ∈(0, 1). This constant value, δ, is called the discount factor and interpreted as
an “information decay rate” controlling parameter, deﬁning the level of variation in
the random “shock” ηt to the latest state φt−1. For now, assume this value is ﬁxed
prior to the analysis. Note that the contamination term is deﬁned conditional on
Dt−1 and the result of the posterior analysis at the previous time point. By deﬁnition,
E[φt|φt−1, Dt−1] = φt−1,
so that the model has the form of a multiplicative random walk. A lower value of δ
leads to a more diﬀuse beta innovation distribution for ηt and more ﬂexibility for on-
line posteriors to adapt to volatile observations, while a value closer to one indicates
a steady, stable evolution. This random walk nature of the model allows for changes,
but does not anticipate speciﬁc directional changes.
The gamma random walk model for positive state variables was ﬁrst introduced
in modeling the dynamic variance parameter (or stochastic volatility) in DLMs (as
a special case of matrix-beta discount formulation proposed by Uhlig (1994, 1997)),
and is discussed in detail by West and Harrison (1997) and Prado and West (2010).
Some contents covered in this section are also discussed in Section 10.4.8 of West
and Harrison and Section 4.3.7 of Prado and West.
4.2.1
Forward Filtering and Backward Sampling
The goal of the posterior analysis is to sequentially revise the following probability
distributions:
• Forecast distribution: p(yt|Dt−1).
• On-line posterior: p(φt|Dt).
• Retrospective posterior: p(φ1:T|DT).
94

Key interest lies in the retrospective posterior as it represents our best understanding
on the parameters of interest, utilizing all the information available for use. Yet,
the other two distributions are necessary and need to be computed prior to the
retrospective analysis. Moreover, the forecast distribution is closely related to the
marginal likelihood, naturally central to model comparison and choice of discount
factor, as seen in Section 4.2.2. Though our main interest is in the retrospective
analysis in this research, we do note and stress that the on-line ﬁltering and forecast
distributions are critical for monitoring data as it is processed, as well as for predictive
purposes.
Forward Filtering
Assume the prior is set as φ0 ∼Ga(r0, c0). The forecast distribution and on-line
posterior are obtained recursively as follows.
1. Posterior at t −1:
φt−1|Dt−1 ∼Ga(rt−1, ct−1).
2. Prior at t:
φt|Dt−1 ∼Ga(δrt−1, δct−1).
3. Forecasting for t:
yt|Dt−1 ∼NB(kt, pt),
Pr[yt = y] =
y + kt −1
y

pkt
t qy
t ,
(4.2)
where
kt = δrt−1,
pt =
δct−1
1 + δct−1
.
4. Posterior at t:
φt|Dt ∼Ga(rt, ct)
95

where
rt = δrt−1 + yt,
ct = δct−1 + 1.
The proof is given in Section 4.7.1. The updating rule for the gamma parameters
of the on-line posterior is similar to that of the Poisson-gamma model with no time-
dependence; if φt = φ for all t and φ ∼Ga(r0, c0), then p(φ|Dt) = Ga(rt, ct) where
rt = rt−1 + yt and ct = ct−1 + 1. This static model is a special case of our dynamic
model with δ →1. It also clariﬁes the eﬀect of the discount factor; it literally dis-
counts the past information, rt−1 and ct−1, against the new observation. In addition,
regarding sensitivity to prior speciﬁcation, this updating rule shows that the prior
choice has little impact. Suppose we have a non-informative prior in the sense that
c0 is extremely small to realize the large variance in prior of φ0. Once we observe
counts at time t = 1, however, this uncertainty is “washed away” immediately as
c1 = δc0 + 1. With the adjustment of the location by r1 = δr0 + y1, the variance of
on-line posterior has to be moderate, no matter how diﬀuse the rate parameter is in
the initial distribution.
This adaptation of the existing gamma-beta volatility model for Poisson rates
was ﬁrst examined by Harvey and Fernandes (1989a,b) and Shephard (1994) and
applied it to the study of polical science by Brandt et al. (2000) and Brandt and
Williams (2001). Their non-Bayesian analysis emphasizes some part of the results of
ﬁltering above, especially the forecast distribution, and they use it as the likelihood to
derive point estimates of the hyperparameters. We, from the Bayesian point of view,
understand the results above as posterior distributions; we can explicitly evaluate
distributions of state variables which are integrated out in non-Bayesian analysis as
nuisance parameters.
96

The next step is to derive the retrospective posterior, p(φ1:T|DT). However, unlike
the three distributions we obtained in ﬁltering, the retrospective posterior is not a
well-known distribution by itself.
For this reason, we take the simulation-based
approach, in that we sample many particles from the target, retrospective posterior
distribution to represent its density and moments by the histogram and sample
analog. To sample from p(φ1:T|DT), we take the compositional form of this joint
distribution, based on the decomposition
p(φ1, · · · , φT|DT) = p(φT|DT)
T−1
Y
t=1
p(φt|φt+1, DT),
by which the problem reduces to sampling from p(φt|φt+1, DT). Given φt+1, we sample
φt from p(φt|φt+1, DT) and repeat this procedure inductively by starting from φT so
that the sampled {φ1, . . . , φT} follows p(φ1:T|DT). Note that the initial marginal
distribution we ﬁrst sample from, p(φT|DT), is actually the on-line posterior at time
t = T, that is the gamma distribution with known parameters.
Backward Sampling
For p(φt|φt+1, DT), the following distributional equation holds:
φt = δφt+1 + ϵt,
ϵt ∼G((1 −δ)rt, ct).
The detailed derivation is given in Section 4.7.2. The equation above tells us that
we may sample ϵt from G((1 −δ)rt, ct) and set φt = δφt+1 + ϵt. Here, the discount
factor serves as a smoothness parameter; the larger δ is, the smoother the latent
process becomes; precisely, φt →φt+1 and ϵt →0 almost surely as δ →1.
4.2.2
Marginal Likelihoods and Optimal Discount Factor
The choice of discount factor impacts the posterior analysis greatly. The formal rule
derived from the theory of Bayesian model selection in choosing the best discount
97

factor is based on the posterior of δ, i.e. p(δ|DT). That is, the discount factor which
maximizes this posterior is regarded as the optimal discount factor. The posterior
is decomposed as p(δ|DT) ∝p(y1:T|δ)p(δ) and, if we use the non-informative prior,
or the constant prior deﬁned as p(δ) ∝1, the target posterior is proportional to the
marginal likelihood, p(y1:T|δ). For ﬁxed δ, the form of this density is analytically
known as
p(y1:T|δ) =
TY
t=1
p(yt|Dt−1, δ) =
TY
t=1
NB(yt|kt, pt),
where (kt, pt) are the parameters of one-step forecast distributions in eqn. (4.2). It
is not easy to maximize this function in δ directly since the second derivative of the
log density shows this function is not concave. Still, we can compute the value of
this density across a discrete grid of values of δ to choose the best discount factor
among the pre-speciﬁed ﬁnite set.
The process of choosing the discount factor is summarized as follows:
1. Deﬁne the ﬁnite set of discount factors ∆⊂(0, 1].
E.g., ∆= {0.900, 0.901, . . . , 0.998, 0.999}.
2. For each δ ∈∆, compute p(y1:T|δ) (or log p(y1:T|δ)).
3. Add the prior information p(δ) to compute p(δ|DT) in case a non-constant prior
is used.
4. Identify the posterior mode for δ.
The logarithm form is useful in computation. This is simpliﬁed as
log p(yt+1|Dt, δ) = const. + 1[ yt+1 ̸= 0 ]
yt+1
X
n=1
log(yt+1 + δct −n)
+ δrt log(δct) −(δrt + yt+1) log(1 + δct).
(4.3)
98

4.2.3
Generalized Gamma Random Walk and Power Discount
We can extend the proposed gamma random walk as
ηt|Dt−1 ∼Be(αt, βt),
αt + βt = rt−1.
Our model sets αt = δrt−1 and βt = (1 −δ)rt−1. For this extended model, the same
ﬁltering and smoothing is valid. The key feature is the constraint on the sum of
two parameters, αt + βt = rt−1, which erases the term φrt−1−(αt+βt)
t−1
in computing
p(φt, φt−1|Dt−1) and realizes the conjugacy.
This model includes power discounting for generalized state-space models pro-
posed by Smith (1979). It deﬁnes the prior at t through the posterior at t −1 as
p(φt|Dt−1) ∝

pφt−1|Dt−1(φt)
	δ ,
where pφt−1|Dt−1(φt) in the right-hand-side means the density of p(φt−1|Dt−1) evalu-
ated at φt. This is generally applicable to a wide class of state-space models, but, in
the context of Poisson-gamma models, it means
p(φt|Dt−1) = Ga(δ(rt −1) + 1, δct−1),
where the shape parameter is slightly diﬀerent from ours. This indirect deﬁnition of
the state evolution is interpreted as a special case of the extended gamma random
walk with αt = δ(rt−1 −1) + 1 and βt = (1 −δ)(rt−1 −1). The problem with this
approach is that the model is not well-deﬁned in the sense of probability theory if
rt−1 ≤1 and βt ≤0. This problem might arise when the process of counts is sparse,
yielding yt = 0 at many time points. It is also required to have r0 > 1 in the initial
prior. In such a case, the use of power discounting is limited.
4.2.4
Extension to Multinomial-Dirichlet State-Space Models
Now we consider the multivariate observation of counts, deﬁned by yt = {yjt}j=1:J.
While the individual count series can be usefully modeled by Poisson-Gamma mod-
99

els independently, the data might have additional information about the sum of
outcomes as PJ
j=1 yjt = nt. In such a case, the basic underlying sampling models is
a multinomial distribution, Multi(yt|nt, θt) with θt on (J −1)-dimensional simplex,
p(yt|θt) =

nt
y1t, · · · , yJt

J
Y
j=1
θ
yjt
jt .
The conjugate prior for this likelihood is the Dirichlet distribution, Dir(θt|qt), the
density of which is
p(θt|qt) =
Γ(q·t)
QJ
j=1 Γ(qjt)
J
Y
j=1
θ
qjt−1
jt
,
where q·t =
J
X
j=1
qjt.
Our interest is again in the state evolution of θt that preserves Dirichlet distribution
as its marginal. For this purpose, we re-parametrize the model by the well-known de-
composition of Dirichlet random quantities into gamma variables; if φjt ∼Ga(rjt, ct)
independently across j, and if θt is deﬁned as the ratio
θjt =
φjt
PJ
j=1 φjt
,
then θt ∼Dir(qt) where qjt = rjt/ PJ
j=1 rjt. With this characteristic, we propose to
deﬁne a multinomial-Dirichlet state-space model implicitly through multiple, inde-
pendent Poisson-gamma models as constructed in the previous section. Denote the
on-line posterior of each Poisson-gamma model by φjt|Dt ∼Ga(rjt, cjt) with discount
factor δj. In order to recover the Dirichlet distribution, we need to set cj0 = c0 and
δj = δ for all j, so that we have all the subsequent rate parameters to be common
across j; cjt = ct for all j at any t. This common rate parameter/discount factor
among observations implies our informational gain from known nit against the use
of completely independent Poisson-gamma models.
100

The resulting on-line posterior and forecast distribution are summarized below.
Forward Filtering of Multinomial-Dirichlet State-Space Models
With the prior θ0 ∼Dir(q0), the ﬁltering proceeds as follows:
1. Posterior at t −1:
θt−1|Dt−1 ∼Dir(qt−1).
2. Prior at t:
θt|Dt−1 ∼Dir(δqt−1).
3. Forecasting for t:
yt|Dt−1 ∼MP(qt−1),
known as multivariate Polya distribution, whose density is
p(yt|Dt−1, δ) =
nt!
QJ
j=1 yjt!
Γ(δq·t)
QJ
j=1 Γ(δqjt)
QJ
j=1 Γ(yjt + δqjt)
Γ(nt + δq·t)
,
where q·t = PJ
j=1 qjt.
4. Posterior at t:
qt|Dt ∼Dir(qt),
where qt = δqt−1 + yt.
For the evaluation of marginal likelihoods and posterior model probabilities, the
forecast density is simpliﬁed as
p(yt|Dt−1, δ) =
nt!
QJ
j=1 yjt!
Q
j∈J+
Qyjt
m=1(yjt + δqjt −m)
Qnt
m=1(nt + δq·t −m)
,
101

where J+ = { j ∈1:J | yjt > 0 }, the set of elements that has non-zero counts. The
log-density is
log p(yt|Dt−1, δ) = const.+
X
j∈J+
yjt
X
m=1
log (yjt+δqjt−m)−
nt
X
m=1
log (nt+δq·t−m). (4.4)
In ﬁltering, it is hard to derive p(θt|θt−1, Dt−1) explicitly since the state evolution
of θt is implicitly deﬁned through independent gamma random walks. Unfortunately,
this aspect becomes problematic in the retrospective analysis. Alternatively, we can
simply keep the latent gamma parameters (rjt, ct), sample φjt from its retrospective
posterior, and re-construct Dirichlet parameters θt. The problem of this approach is
the dependece on the choice of c0, which originally does not exist in multinomial-
Dirichlet models.
However, as discussed in Section 4.2.1, the eﬀect of c0 on the
posteriors is limited. The resulting retrospective posterior of θt is expected to be ro-
bust to the choice of c0 as it should be in the original multinomial-Dirichlet structure
that does not have that rate parameter.
4.3
Dynamic Gravity Models
Consider the time series of a square matrix of counts: Yt = {yijt}i,j=1:I where
yijt ∈Z+. In application, yijt represents the ﬂow from node i to j at time t on
the network. In modeling this type of observation, it is natural to consider the de-
pendence between two ﬂows, or observations on two diﬀerent edges in the network,
that share the common origin i or the destination j. One framework that has been
developed for static networks is that of gravity models, in which the likelihoods are
independent Poisson distributions conditional on rate parameters that capture the
network dependence in the form of Analysis of Variance (ANOVA). To be precise,
and making the novel extension of traditional, static gravity models to a dynamic
context with potentially time-varying parameters, the dynamic gravity model (DGM)
102

is written as
yijt|φijt ∼Po(φijt),
(4.5)
independently across i, j and t, and
φijt = µt αit βjt γijt,
(4.6)
where {µt, αit, βjt, γijt} are called overall eﬀect, origin eﬀect of i, destination eﬀect of
j and individual eﬀect, or aﬃnity, of ﬂow from i to j, respectively. Models of this and
more elaborate forms have been popular in transportation studies (e.g. West, 1994;
Sen and Smith, 1995) where the interaction term is typically structured as a function
of physical distance between nodes; there the “gravity model” terminology relates
to the role of small distances in deﬁning large interactions and hence “attraction”
of traﬃc from node i to node j. We refer to the γijt interactions as “aﬃnities.” In
dissecting the network ﬂow activity, we are most interested in questions about which
aﬃnities are greater than one (j attracts ﬂow from i over and above the main eﬀects),
or less than one (j is relatively unattractive to i), or not signiﬁcantly diﬀerent to
one (neutral). Critically, aﬃnities are time-varying, and any identiﬁed patterns of
variation over time may be related to interpretable events or network changes.
In the ﬁrst fully Bayesian approach to gravity models using MCMC methods,
West (1994) developed such models in the static case; i.e., with no dynamics in the
model parameters, and applied the model to a large transportation ﬂow network.
Congdon (2000) explored a similar approach in studies of patient ﬂows to hospitals.
Analysis via MCMC is computationally very demanding, and the burden increases
quadratically in I, and inherently non-sequentially. More recently, Jandarov et al.
(2014) studied such models for spread of infectious diseases, and used Gaussian
process approximations for approximate inference rather than full MCMC or other
computational methods.
103

We share the spirit of this latter work, in using the simply and eﬃciently imple-
mented BDFM as a path to ﬁtting the gravity model—now extended to time-varying
eﬀect parameter processes. However, we do not constrain the aﬃnity parameters γijt
as a function of covariates of any kind, simply treating the DGM as a dynamic, ran-
dom eﬀects model. This leads to a direct parameter mapping between the BDFM to
the DGM; as a result, the trivially generated simulations from the full posterior of
the BDFM are mapped directly to full posterior samples from the DGM, providing
immediate access to inference on main eﬀect and aﬃnity processes over time.
While the models and analyses developed here represent new applications of
Bayesian dynamic modeling ideas, there are at least conceptual intersections with
studies of monitoring, inference, and forecasting traﬃc ﬂows in areas. Some of the
developments here may well extend to apply to such areas, including, for example,
inference in origin-destination analysis (e.g. Tebaldi and West, 1998) and physical
traﬃc studies (e.g. Tebaldi et al., 2002; Queen and Albers, 2009; Anacleto et al.,
2013a,b).
4.3.1
Identiﬁcation
In emulating DGM by BDFMs, speciﬁcally, we independently apply the Poisson-
gamma model for each ﬂow yijt, or the multinomial-Dirichlet model for the set of
ﬂows, say (yi1t, . . . , yiIt) if conditioned by nit = P
j=1:I yijt, in order to obtain particles
{φijt} from the retrospective posterior and map them to those of DGM. Note that we
can sample these particles in parallel and the computational complexity is at most
order O(T), while we completely ignore the dependency of ﬂows on the network
in applying independent BDFMs. The mapping of those particles to the gravity
model components, {µt, αit, βjt, γijt}, can be done in a deterministic way, without
adding any signiﬁcant computations, as shown in this and subsequent subsections.
This enables the construction of posterior distributions of gravity model components
104

based on simulation in a feasible way under the scalable network. We expect that,
though we ignore the dependence of nodes in BDFM emulators, we are able to see
dependencies in the implied DGM posteriors in terms of the “signiﬁcant” values of µt,
αit and βjt, recovering the degree of dependency through their posterior distributions.
In this subsection, the theory to convert the Poisson mean parameters to the
components of gravity models, or mapping BDFMs to DGM, is explained. As we
saw, these two representations of parameters are tied in eqn. (4.6) and on the log-
scale,
fijt = mt + ait + bjt + gijt,
(4.7)
where fijt = log φijt, mt = log µt, ait = log αit, bjt = log βjt and gijt = log γijt. At
each time t, the number of parameters, {φijt}i,j=1:I, in the emulator is I2, while the
DGM representation has {µt, {αit}i=1:I, {βjt}j=1:I, {γijt}i,j=1:I}, where the number of
elements is (I+1)2. Thus, the DGM is over-parameterized against the emulators from
which we sample particles. To map the parameters of emulators to those of DGM
uniquely, we need additional constraints on parameters and decrease the number of
free parameters, or degrees of freedom.
4.3.2
Identiﬁcation by a Reference Flow
In the additive representation in eqn. (4.7), the similarity to a traditional linear
ANOVA model is evident; this suggests the use of the traditional methods for iden-
tiﬁcation. One straightforward set of constraints for identiﬁcation, used frequently
in ANOVA models, is to set some parameters to be constant as the reference level.
For example,
α1t = 1,
β1t = 1,
γ1jt = 1,
γi1t = 1
for i, j = 1:I. By these constraints, 1 + 1 + (2I −1) = 2I + 1 parameters become
constrained, and the total number of free parameters in the model is now I2. The
105

one-to-one mapping is obtained by the following equations,
φ11t = µt,
φi1t = µtαit,
i = 2 : I
φ1jt = µtβjt,
j = 2 : I
φijt = µtαitβjtγijt,
i, j = 2 : I,
or, equivalently,
µt = φ11t,
αit = φi1t/µt,
i = 2 : I
βjt = φ1jt/µt,
j = 2 : I
γijt = φijt/µtαitβjt,
i, j = 2 : I,
in addition to α1t = β1t = γi1t = γ1jt = 1. This transformation is easy to implement,
but it makes the interpretation of each parameter more complicated. For instance,
the overall level, µt, is deﬁned only by φ11t. This means the ﬂow from domain 1 to 1
is now considered the reference level for the other ﬂows, i.e., all the other parameters,
αit, βjt and γijt, are understood as the deviation from this reference. Therefore, the
order of domains, or the choice of the reference ﬂow, is crucial in interpretation.
Plus, of course, once the order of domains is changed, the posteriors of the DGM
parameters become diﬀerent.
4.3.3
Identiﬁcation by Geometric Means
Another set of constraints consists of the geometric means of DGM parameters as
I
X
i=1
ait = 0,
i = 1:I;
I
X
j=1
bjt = 0,
j = 1:I;
I
X
j=1
gijt = 0,
i = 1:I;
I
X
i=1
gijt = 0,
j = 1:(I −1).
106

In total, we have 1 + 1 + I + (I −1) = 2I + 1 equations, and the degrees of freedom
decreases by 2I +1 and becomes I2. Note that, even for j = I, these equations imply
the same sum-to-zero constraint as
I
X
i=1
giIt =
I
X
i=1
I−1
X
j=1
n
−gijt
o
=
I−1
X
j=1
n
−
I
X
i=1
gijt
o
=
I−1
X
j=1
n
−0
o
= 0.
Next, use those constraints in the deﬁnition of DGM parameters in eqn. (4.7), taking
the sum in i, j and both to obtain the equations relating φijt to DGM parameters
as follows:
I
X
i=1
I
X
j=1
fijt = I2mt,
I
X
j=1
fijt = Imt + Iait,
I
X
i=1
fijt = Imt + Ibjt.
Thus, DGM parameters are obtained recursively by
mt = 1
I2
I
X
i=1
I
X
j=1
fijt,
ait = 1
I
I
X
j=1
fijt −mt,
bjt = 1
I
I
X
i=1
fijt −mt,
gijt = fijt −mt −ait −bjt.
This transformation has several advantages in interpretation. First, thanks to the
sum-to-zero constraints, the signs and magnitudes of domain-speciﬁc eﬀects, ait and
bjt, mean how they deviate from the average of all the domains. Second, unlike the
previous transformation, this is invariant to the order of domains. For these reasons,
this transformation is preferred.
4.3.4
Computational Problems in Practice
To implement the transformation above, we need to take the logarithm of the Poisson
rate parameters as in eqn. (4.7), and this might be problematic in an applied study.
The problem arises in the case where some of the ﬂows are “sparse”, i.e. yijt = 0 for
107

many t in the ﬂow from i to j. In the extreme case where yijt = 0 for all t, the posterior
of the Poisson-gamma model at t = T is Ga(δTr0, δTc0+(1−δT−1)/(1−δ)). For large
T, this distribution is nearly degenerate at zero, having almost all probability mass
in the neighborhood of the origin. In computation, generating random variables from
the gamma distribution with small shape parameter is not straightforward. While
we can generate the log scale particles by using the importance sampling method of
Liu et al. (2013), once it is converted to the exponential scale it become numerically
zero.
This is not desirable if the ﬂow might become active again after a long period of
sparsity. In such a case, we implicitly assume that the model should preserve the
uncertainty in its posterior and avoid being overly conﬁdent. This aspect of our belief
is realized in the Poisson-gamma model by the additional constraint on ﬁltering as
rijt = r
if
δrij,t−1 + yijt < r,
(4.8)
for some r. In other words, when the scale parameter of the on-line posterior be-
comes below the threshold r, we abandon the original updating rule but keep the
shape parameter on the threshold. This exceptional treatment is understood as an
intervention on the process deﬁned by the model, and included in the set of infor-
mation Dt. In Section 4.5, we use r = 0.1.
More importantly, another technical problem with this mapping arises in cases
of sparse ﬂows, in which the very small values of concentration of the posterior for
φijt unduly impacts the resulting overall mean and/or origin or destination means.
To see this, suppose yijt = 0 for many pairs of (i, j) and we sampled very small φijt
for those (i, j). On taking logarithms, fijt = log φijt tends to be negative and large.
Since the deﬁnion of mt is the average of all the fijt, those large and negative values
of fijt make the overall level µt = emt extremely small. With this small µt, the other
parameters give little insight. For example, the aﬃnity of sparse ﬂow γijt has to be
108

extremely large to counter the smallness of {µt, αit, βjt} to balance them to the value
of φijt.
While one can imagine model extensions to address this, at a practical level it
suﬃces to adjust the mapping as is typically done in related problems of log-linear
models of contingency tables with structural zeros. This is implemented by simply
restricting the summations in the identiﬁability constraints to those node pairs for
which yijt > d, for some small d, and adjusting the divisors to count the numbers of
terms in each summation. With this adjustment, very small φijt appropriately lead
to very small aﬃnities γijt, so the latter then represent very sparse ﬂows. We will
see this part in detail in the next subsection.
4.3.5
Alternative Identiﬁcation Strategy under Sparsity
The DGM can account for zero counts on a certain edge in diﬀerent ways, but,
for our purpose of analysis, it is meaningful to let γijt be very small, so that the
other parameters can be interpreted as the levels of “active” ﬂow. To allow for this
interpretation, we restrict the decomposition of Poisson rate parameters into DGM
components by adding several constraints (Bishop et al., 1975, chap. 5). First, we
assume that a ﬂow {yijt}t=1:T is sparse if P
t=1:T yijt < d where d is the pre-speciﬁed
threshold that should be a small value. In Section 4.5, this threshold is set to be
d = 10. Deﬁne sij = 0 if the ﬂow from i to j is sparse, and sijt = 1 otherwise. Next,
we modify the indentiﬁcation constraints as
I
X
i=1
si·ait = 0,
i = 1:I;
I
X
j=1
s·jbjt = 0,
j = 1:I;
I
X
j=1
sijgijt = 0,
i = 1:I;
I
X
i=1
sijgijt = 0,
j = 1:(I −1),
where si· = PI
j=1 sij and s·j = PI
i=1 sij. The indicator variables introduced above
allow us to exclude Poisson rate parameters of sparse ﬂows from the deﬁnition of the
109

overall mean and the average of origin/desination eﬀects. The set of parameters, µt,
αit and βjt, can then be computed by solving the linear equations
X
i,j=1:I
sijfijt = s··mt +
I
X
i=1
s·jait +
I
X
j=1
si·bjt,
X
j=1:I
sijfijt = si·mt + si·ait +
I
X
j=1
sijbjt,
i = 1:I,
X
i=1:I
sijfijt = s·jmt +
I
X
j=1
sijait + s·jbjt,
j = 1:I,
where s·· = P
i,j=1:I sij. This linear system is solvable in DGM components if si· > 0
and s·j > 0, and we assume this is true in most cases. Once these three types of
parameters are obtained, the interaction eﬀects are deﬁned as gijt = fijt−mt−ait−bjt.
If a ﬂow is sparse, its log-rate fijt is negatively large, making its log-aﬃnity gijt to
be negative and large as well, and γijt to become dominant in φijt.
4.4
Dependent Gravity Model and MCMC
In Section 4.3, the direct analysis of the DGM is mentioned with its diﬃculty in
computation under scalable datasets. Here, one of those approaches is examined in
detail to see its speciﬁcation, diﬃculty, and problem.
We now put priors on the four types of state variables in eqn. (4.6) that comprise
the state-space model. Let ϕt ∈{µt, αit, βit, γijt}. A natural choice for this latent
process is the log-normal AR(1) process,
log ϕt = µϕ + φϕ(log ϕt−1 −µϕ) + N(0, σ2
ϕ),
as in the static generalized linear model. Alternatively, the same gamma random
walk can be used for each component as
ϕt = ϕt−1ηϕ
t /δϕ,
(4.9)
110

with the appropriate distribution for ηϕ
t . The advantage of this model is the avail-
ability of forward ﬁltering in Gibbs sampling, i.e., conditional on the other DGM
components, all the state variables of interest, ϕ1:T, can be sampled simultaneously.
To take an example, the full conditional posterior of αi,1:T for some i depends on the
likelihoods of yijt for j = 1:I, so its kernel is
Y
j=1:I
Po(yijt|φijt) ∝α
P
j=1:I yijt
it
exp
(
−αit
X
j=1:I
µtβjtγijt
)
,
and this likelihood contributes to the shape and rate parameters of the on-line poste-
rior by P
j=1:I yijt and P
j=1:I µtβjtγijt, respectively. Note also that the retrospective
analysis is exactly the same as Poisson-gamma BDFMs. The full analysis by MCMC
proceeds as follows.
MCMC for Dependent DGM:
The parameters of interest are the state variables ϕt ∈{µt, α1:I,t, β1:I,t, γ1:I,1:I,t}.
1. Set priors, ϕ0 ∼G(rϕ
0 , cϕ
0), and discount factors δϕ.
2. At each iteration of MCMC, for each DGM component ϕt conditional on the
others, implement FFBS. In ﬁltering, ϕt ∼G(rϕ
t , cϕ
t ), where
• ϕt = µt:
rµ
t = δµrµ
t−1 +
I
X
i=1
I
X
j=1
yijt,
cµ
t = δµcµ
t−1 +
I
X
i=1
I
X
j=1
αitβjtγijt.
• ϕt = αit:
rαi
t
= δαirαi
t−1 +
I
X
j=1
yijt,
cαi
t = δαicαi
t−1 +
I
X
j=1
µtβjtγijt.
111

• ϕt = βjt:
r
βj
t
= δβjr
βj
t−1 +
I
X
i=1
yijt,
c
βj
t = δβjc
βj
t−1 +
I
X
i=1
µtαitγijt.
• ϕt = γijt:
r
γij
t
= δγijr
γij
t−1 + yijt,
c
γij
t
= δγijc
γij
t−1 + µtαitβjt.
Sampling of αit, βjt and γijt can be done in parallel across i, j and (i, j),
respectively.
3. The sampled parameters are not constrained. That is, the model is augmented
with an excess number of parameters. For identiﬁcation, modify the original
particles as
• g∗
ijt = gijt −gi·t −g·jt + g··t,
• a∗
it = [ait + gi·t] −1
I
PI
i′=1[ai′t + gi′·t],
• b∗
jt = [bjt + g·jt] −1
I
PI
j′=1[bj′t + g·j′t],
• m∗
t = mt −g··t + 1
I
PI
i=1[ait −gi·t] + 1
I
PI
j=1[bjt −g·jt],
where a·t, b·t, g·jt, gi·t and g··t are the means in i and/or j. The new particles
above satisfy the constraints for identiﬁcation. This transformation is easily
adjusted to the case of identiﬁcation under the constraints by sparse ﬂow dis-
cussed in Section 4.3.4.
4.5
Application: Analysis of FoxNews Website Access Records
4.5.1
Study of Internet Traﬃc Flow
We focus on ﬂows of visitors to a set of domains of webpages in a structurally well-
deﬁned but dynamic/evolving network. The network is a subset of domains in the
112

FoxNews website, monitored to generate streaming data on visitors to each domain
over time. We use the term “domain” loosely, to refer to collections of webpages that
correspond to categories of interest, as deﬁned by Fox News.
On-line advertisers are interested in a host of statistical issues related to traﬃc
ﬂow and domain content. The ﬁeld has become quite sophisticated, employing com-
plex recommender systems (Koren et al., 2009), sentiment analysis (Pang and Lee,
2008), text mining (Soriano et al., 2013), and other methods (Agarwal et al., 2010;
Taddy, 2013). However, basic questions of understanding and characterizing traﬃc
across domains have not received the attention they require.
Trajectories of users, and groups of users, can give important information about
browsing intent and the evolution of purchase interest, and thus ultimately aﬀect
ad placement decisions. As pages within a website are updated, questions arise as
to whether browsing traﬃc patterns change as a result. To begin to address this
statistically, we need to understand stochastic variation in past browser traﬃc so
that comparisons can be made of incoming traﬃc streams against recent statistical
“norms,” and signiﬁcant deviations from short-term predictions based on current
dynamic patterns can be identiﬁed.
4.5.2
Context and Data
Modeling internet traﬃc ﬂow is a Big Data problem. We necessarily focus on smaller
deﬁned networks for which there is contextual knowledge to guide interpretation.
Our context is traﬃc ﬂow among “domains” of the FoxNews website. Besides the
home/landing page, other domains include Politics, Entertainment, Travel, Science,
and similar broad categories of news content. The contents of the domains change,
usually on a daily basis at midnight, but more rapidly when some noteworthy event
occurs. MaxPoint places ads on pages in these FoxNews domains, and thus can track
ﬂows of anonymized users as they move through its pages.
113

Data
The dataset contains FoxNews website visit data during 09:00-10:00am and 01:00-
02:00pm EST on each of six days, February 23-24, March 2-3 and 9-10, 2015. These
days are Mondays or Tuesdays. Since the FoxNews website structure changes of-
ten, with new pages being added and old pages being archived, the analysis ag-
gregates webpages into groups speciﬁed by the host domain www.foxnews.com, and
the set of ﬁrst url paths after the host domain, including examples such as e.g.
www.foxnews.com/politics/* and www.foxnews.com/US/*. These classify all the
pages into 22 domains: Homepage, Politics, US, Opinion, Entertainment, Technol-
ogy, Science, Health, Travel, Leisure, World News, Sports, Shows, Weather, Cate-
gory, Latino, Story, On-Air, Video, National News, Magazine, and Other.
The dataset includes anonymized users (browsers) from nearly every time zone on
the planet. In order to study time-of-day eﬀects, such as, say, a tendency to browse
news in the morning and entertainment in the afternoon, it is necessary to stratify
by time zone. Here we focus on users in the Eastern North America time zone; those
are the most numerous, and the two time windows used in this study were chosen
with the expectation that diﬀerent browsing patterns might occur at those times.
We aggregate data to counts in half-minute intervals to form a time series with
120 time points showing domain occupancy, ﬂows from each domain, and ﬂows into
each domain for each period. Several details are relevant. First, in each half minute
interval, if the record shows the same user in two or more domains, then each of
her/his moves is counted in the ﬂow data into each of these domains. Second, if the
user refreshes the same page multiple times spanning more than one time interval,
then s/he is counted as simply staying in that domain; this can be done as the
web browsing tool performs automatic refresh. Importantly, if a user stays in the
same domain for more than ﬁve minutes, we assume s/he is no longer active, and
114

is counted as leaving the FoxNews site. If such a user later appears in one domain,
s/he counts as in-ﬂow from outside the FoxNews site. Finally, we cannot track user
information either before or after the one-hour observation window, so there is a
form of censoring; we thus restrict attention to the period 09:05 −09:55am and
01:05 −01:55pm, consisting of uncensored ﬂows, using the ﬁrst 5 minutes of data
informally to deﬁne priors. Thus the series runs from t = 1:T with T = 110 in each
time period.
Network Structure and Notation
Referring to sites external to the FoxNews website as node 0, we have 23 network
nodes; the I = 22 actual domains and “External”, indexed as i = 0:I. At each time
t = 1:T, deﬁne nit as the number of occupants of node i, and deﬁne yijt as the ﬂow
count from node i to j, including the in-ﬂows y0it and out-ﬂows yi0t relative to the
External domain. The ﬂows outside Foxnews, y00t, are unobservable and missing.
The schematic chart in Figure 4.1 reﬂects our notation.
In-ﬂow
y0it
(
ONML
HIJK
1
GFED
@ABC
i
yi1t
4
u
r p
n
l
j
i
yijt
/_
_
_
_
_
_
_
_
_
yiIt
*
I
L N
P
R
T
U
yi0t
v
m
m
m
m
m
m
ONML
HIJK
j
Out-ﬂow
ONML
HIJK
I
Figure 4.1: Network schematic and notation for ﬂows at time t.
The circular
numbered nodes represent the domains at the current time point t. Each arrow
i →j shows the ﬂow of yijt visitors.
115

4.5.3
BDFM Analysis of FoxNews Data
Consider now the set of ﬂows departing from node i. Before observing the ﬂow at
time t, the population on this domain is known as the sum of ﬂows incoming into i
at the previous time point t −1, denoted by nit = PI
j=0 yij,t−1. Thus, the subsequent
move of visitors at t must be constrained by this known number of population, which
justiﬁes the multinomial likelihood
yi,0:I,t ind :∼Multi(nit, θit)
i = 1:I.
We can model the evolution of θit by introducing the latent rate parameters φi,0:I,t
that recovers θit as their ratios as discussed in Section 4.2.4. In contrast, there is no
available information on the population in the external websites that is considered
in modeling the in-ﬂow y0jt for j = 1:I. Naturally, the Poisson-gamma models in
Section 4.2 are used for the in-ﬂows as
y0jt ind :∼Poi(φ0jt)
j = 1:I.
The state variables are the rate parameters and follow gamma random walk model
in eqn. (4.1), associated with discount factors δi for θit (or φi,0:I,t) and δ0jt for φ0jt.
The posterior analysis is conducted separately for each of the 12 datasets of the six
days. We analyze the morning of the ﬁrst day (February 23 2015) for illustration of
parameter learning before the comparison across days. In each dataset and analysis,
the gamma priors for the in-ﬂow rates are φi0|y0i0 ∼Ga(ri0, ci0) with ci0 = 1 and
ri0 = ci0zi where zi is the point estimate based on the in-ﬂows of the ﬁrst 5 minutes
(prior to t = 1). The Dirichlet prior for the transition probabilities is θi,0:I,0|yi,0:I,0 ∼
Dir(qi,0:I,0) where each qij0 is a simple point estimate based on the ﬁrst 5 minutes
in-ﬂows but rescaled so that qi0:I0 becomes a probability vector. The priors for the
underlying, unconstrained node-node ﬂow rates are then φij0|y0ij0 ∼Ga(rij0, ci0)
116

with ci0 = 1 and rij0 = qij0. The threshold for the shape parameters is set to be
r = 0.1.
Priors for each discount factor are Be(19, 1) distributions truncated to (0.9, 1)
with grid 0.001; reanalysis using uniform priors on this range led to little in the
way of noticeable diﬀerences, as the marginal likelihoods at t = T dominate. The
prior truncation ensures some degree of smoothness. Running the models in parallel
across discrete grids of discount factors and evaluating the marginal likelihoods in
eqns. (4.3,4.4) at each time point t gives the marginal posteriors of discount factors.
Across all in-ﬂows, this suggested δi ≈0.9 as a posterior mode. Figure 4.2 plots
posteriors truncated at 0.9 for the discounts δi in the transition ﬂow models. Some
nodes exhibit higher volatility in ﬂows to other nodes over time than others, requiring
and hence favoring smaller discount factors; these are particularly associated with
0.90
0.95
1.00
-3
-1
homepage
0.90
0.95
1.00
-3
-1
politics
0.90
0.95
1.00
-3
-1
us
0.90
0.95
1.00
-3
-1
opinion
0.90
0.95
1.00
-3
-1
entertainment
0.90
0.95
1.00
-3
-1
tech
0.90
0.95
1.00
-3
-1
science
0.90
0.95
1.00
-3
-1
health
0.90
0.95
1.00
-3
-1
travel
0.90
0.95
1.00
-3
-1
leisure
0.90
0.95
1.00
-3
-1
world
0.90
0.95
1.00
-3
-1
sports
0.90
0.95
1.00
-3
-1
shows
0.90
0.95
1.00
-3
-1
weather
0.90
0.95
1.00
-3
-1
category
0.90
0.95
1.00
-3
-1
latino
0.90
0.95
1.00
-3
-1
story
0.90
0.95
1.00
-3
-1
on-air
0.90
0.95
1.00
-3
-1
video
0.90
0.95
1.00
-3
-1
nation
0.90
0.95
1.00
-3
-1
magazine
0.90
0.95
1.00
-3
-1
others
Figure 4.2: The standardized values of the marginal log-posteriors of discount factors δi
for the in-ﬂows to FoxNews nodes i = 1:22 (top right, reading across rows), for the period
09:05am-09:55am on February 23, 2015.
117

nodes representing domains with high ﬂow counts (e.g., in-ﬂows from External to
Homepage).
Some summary inferences on selected model components are reported, based on
models with discount factors ﬁxed at their posterior modes. Figure 4.3 gives one
example of learning about in-ﬂow rates, in this case the ﬂow from all nodes to node
10 (the Leisure domain). The ﬁgure exempliﬁes sequential learning about the ﬂow
rate together with its retrospectively updated trajectory and a visual assessment of
one-step ahead forecasting aligned with the data.
A similar display in Figure 4.4 highlights the same aspects of the analysis, now
with an example of ﬂow between two network nodes (from Homepage to the Poli-
tics domain). It shows the rate between two nodes together with the retrospective
smoothing for full inference on the trajectory and one-step ahead forecast summaries.
Homepage is the most popular single domain on FoxNews, so the transition proba-
bilities from Homepage to other domains are of particular interest. Figure 4.5 shows
that most Homepage visitors stay on Homepage for a while. Of those that leave,
many exit the FoxNews site entirely. Across all six days, the probability of staying
on the Homepage decreases over the course of the 50 minute morning period.
On examples of transition probabilities, Figure 4.6 shows that the probability
of people leaving the FoxNews website from Homepage increases in this 50 minute
window for each of the six mornings. Note that there are signiﬁcant day eﬀects; e.g.,
visitors are more likely to leave FoxNews on the morning of March 9th compared to
the other mornings. More detailed insights, based on the gravity model, are noted
in the next section.
As an illustration of a more detailed analysis of a very speciﬁc ﬂow, consider
Figure 4.7.
Among the visitors who leave the Homepage for other FoxNews do-
mains, Entertainment is generally the most popular destination. For the six datasets
collected during the morning, we see large diﬀerences in transition probabilities; in
118

5
10
15
20
25
30
35
40
45
50
55
10
20
30
y
5
10
15
20
25
30
35
40
45
50
55
10
20
30
φ
5
10
15
20
25
30
35
40
45
50
55
10
20
30
Time
φ
Figure 4.3: BDFM-based inference over time t on in-ﬂows to domain i = 10 (Leisure).
Upper: data y0Xt (circles) with one-step ahead forecast means and 95% intervals. Center.
trajectory of mean and 95% intervals from on-line posteriors p(φ0Xt|y0X,1:t) plotted against
t. Lower: revised trajectory under full retrospective posterior p(φ0Xt|y0X,1:T ).
5
10
15
20
25
30
35
40
45
50
55
40
60
y
5
10
15
20
25
30
35
40
45
50
55
40
60
φ
5
10
15
20
25
30
35
40
45
50
55
40
60
Time
φ
Figure 4.4: BDFM-based inference over time t on transitions from domain i = 1 (Home-
page) to j = 2 (Politics). Upper: data y12t (plus signs) with one-step ahead forecast means
and 95% intervals. Center. trajectory of mean and 95% intervals from on-line posteriors
of φ12t. Lower: revised trajectory under full retrospective posterior.
119

10
20
30
40
50
0.6
0.7
0.8
23 Feb (M)
10
20
30
40
50
0.6
0.7
0.8
24 Feb (Tu)
10
20
30
40
50
0.6
0.7
0.8
 3 Mar (M)
10
20
30
40
50
0.6
0.7
0.8
 4 Mar (Tu)
10
20
30
40
50
0.6
0.7
0.8
 9 Mar (M)
10
20
30
40
50
0.6
0.7
0.8
10 Mar (Tu)
Figure 4.5: Retrospective mean and 95% CI of trajectories of transition probability θ11t
(staying at Homepage) from analysis on data collected from each of the six mornings.
10
20
30
40
50
0.2
0.3
23 Feb (M)
10
20
30
40
50
0.2
0.3
24 Feb (Tu)
10
20
30
40
50
0.2
0.3
 3 Mar (M)
10
20
30
40
50
0.2
0.3
 4 Mar (Tu)
10
20
30
40
50
0.2
0.3
 9 Mar (M)
10
20
30
40
50
0.2
0.3
10 Mar (Tu)
Figure 4.6: Retrospective mean and 95% CI of trajectories of transition probability θ10t
(Homepage →External) from analysis on each of the six mornings.
120

10
20
30
40
50
0.02
0.03
23 Feb (M)
10
20
30
40
50
0.02
0.03
24 Feb (Tu)
10
20
30
40
50
0.02
0.03
 3 Mar (M)
10
20
30
40
50
0.02
0.03
 4 Mar (Tu)
10
20
30
40
50
0.02
0.03
 9 Mar (M)
10
20
30
40
50
0.02
0.03
10 Mar (Tu)
Figure 4.7: Retrospective mean and 95% CI of trajectories of transition probabilities
θ15t (Homepage →Entertainment) for each of the six mornings.
particular February 23 and 24 have larger rates than the other days. It is noteworthy
that the Academy Awards ceremony was held on the night of February 22, which
may have driven this uptick.
4.5.4
DGM Analysis of FoxNews Data
We now consider DGM as the more nuanced model that structures ﬂow rates in
terms node-speciﬁc main eﬀects and node-node interaction terms. With the sampled
rate parameters {φijt}i,j=1:I, it is straightforward to apply the mapping from BDFMs
to DGM in Section 4.3. The rate parameter of the missing ﬂow, φ00t, is naturally
excluded from the mapping procedure by setting s00 = 0.
February 23 2015, 09:00-10:00am
We ﬁrst apply the gravity model decomposition to the morning data on Febru-
ary 23rd. Each ﬂow is analyzed by the dynamic Poisson-Gamma and multinomial-
Dirichlet models independently, under the same settings used in Section 4.5.3. The
121

5
10
15
20
25
30
35
40
45
50
55
0.50
0.55
0.60
0.65
0.70
µ
Time
Figure 4.8: DGM-based smoothed trajectory of baseline level process µ1:T . In this and
following ﬁgures, the dashed lines indicate 95% intervals about the displayed posterior
mean trajectory.
particles of Poisson rate parameters sampled from their posteriors are decomposed
into the gravity model components, which allows us to construct the posteriors for
the gravity model parameters.
Figure 4.8 shows the retrospective posterior of the baseline level µt. Its poste-
rior mean is almost stable around 0.60 throughout the ﬁfty minute period and its
ﬂuctuation is at most 0.10, or a 10% increase of its eﬀect to the total access counts.
The origin and destination eﬀects are shown in Figures 4.9 and 4.10. The posteri-
ors for origin eﬀects show that large-scale domains, such Homepage (domain 1), have
higher values of αit, while domains with low or zero ﬂows, such as Shows (domain 13),
naturally have lower values. The two graphs show similar patterns in many domains,
but diﬀerences are also apparent. In particular, the posterior analysis for several do-
mains, such as Health (domain 8) and Video (domain 19), shows “signiﬁcance” in
their origin eﬀects but “insigniﬁcance” in their destination eﬀects (i.e., their 95%
Bayesian credible intervals of the destination eﬀects contain one, but this is not case
for the origin eﬀects). These distinctions between the two eﬀects show the roles of
122

20
40
20
60
α1t homepage
20
40
1.0
1.4
α2t politics
20
40
2
6
α3t us
20
40
1.0
1.2
α4t opinion
20
40
2
4
α5t entertainment
20
40
0.5
1.0
α6t tech
20
40
0.5
1.0
α7t science
20
40
0.8
1.2
α8t health
20
40
0.5
1.0
α9t travel
20
40
0.75
1.25
α10t leisure
20
40
2
4
α11t world
20
40
0.5
1.0
α12t sports
20
40
0.5
1.0
α13t shows
20
40
0.5
1.0
α14t weather
20
40
0.5
1.0
α15t category
20
40
0.5
1.0
α16t latino
20
40
0.5
1.0
α17t story
20
40
0.5
1.0
α18t on-air
20
40
0.75
1.00
α19t video
20
40
0.8
1.2
α20t nation
20
40
0.5
1.0
α21t magazine
20
40
2
6
α22t others
20
40
10
30
α0t external
Figure 4.9: DGM-based smoothed trajectories of node-speciﬁc outﬂows αi,1:T .
20
40
20
40
β1t homepage
20
40
1.0
1.4
β2t politics
20
40
2
4
β3t us
20
40
1.0
1.5
β4t opinion
20
40
2
4
β5t entertainment
20
40
0.5
1.0
β6t tech
20
40
0.8
1.2
β7t science
20
40
0.8
1.2
β8t health
20
40
0.5
1.0
β9t travel
20
40
1.25
1.75
β10t leisure
20
40
2
3
β11t world
20
40
0.5
1.0
β12t sports
20
40
0.5
1.0
β13t shows
20
40
0.5
1.0
β14t weather
20
40
0.5
1.0
β15t category
20
40
0.5
1.0
β16t latino
20
40
0.5
1.0
β17t story
20
40
0.5
1.0
β18t on-air
20
40
0.8
1.2
β19t video
20
40
1.0
1.5
β20t nation
20
40
0.5
1.0
β21t magazine
20
40
2
4
β22t others
20
40
10
30
β0t external
Figure 4.10: DGM-based smoothed trajectories of node-speciﬁc inﬂows βj,1:T .
123

αit and βjt; they represent the common factors across the origin and destination of
the ﬂows, which is conﬁrmed by the diﬀerences of the two results. These eﬀects are
also essential in order to capture the scale of the domains, by having similar patterns
for αit and βjt when i = j.
For the aﬃnity eﬀects γijt, we have (I + 1)2 −1 parameters (one for each pair of
nodes except the unobserved External →External ﬂow) at each time t. The number
of eﬀects becomes massive for large I. Even in this example for illustration, I = 22,
the number of γijt for ﬁxed t is 528, so it is impossible to examine all the results
here. For this reason, we pick up a few aﬃnity eﬀects that may interest readers in
terms of interpretation. For aﬃnity γijt with retrospective posterior c.d.f Φijt(γ), we
use the Bayesian credible value pijt = min{Φijt(1), 1−Φijt(1)} as a simple numerical
measure of deviation from the “neutral” value of 1. This highlights the practical
relevance of the aﬃnity eﬀect and its changes over time.
First, we focus on the ﬂows from Homepage (domain 1). Those ﬂows are crucial
in understanding the user’s preference from the aggregated data since Homepage
is usually the landing page for visitors. Flows from it must have information on
which domain the user wants to access ﬁrst, which would be an important ﬁnding
in advertisement and marketing. Figure 4.11 shows that the aﬃnity trajectory and
credible values for ﬂows from Homepage (domain 1) to Opinion (domain 4) are
entirely greater than 1. This implies that visitors to the FoxNews landing page tend
to access articles in the Opinion domain (during this time period).
In contrast,
Figure 4.12 displays the aﬃnity trajectory and credible values for the ﬂow from
Homepage to Science (domain 7).
The aﬃnity eﬀect is signiﬁcantly negative for
much of the time interval, implying that at the beginning of the hour, people on
the FoxNews landing page tend not to check the websites within the Science domain.
But, as time passes, the trajectory gradually increases to 1 and becomes insigniﬁcant.
This change of signiﬁcance is clear in the Bayesian credible values, which are almost
124

5
10
15
20
25
30
35
40
45
50
55
1.00
1.25
1.50
1.75
γ
5
10
15
20
25
30
35
40
45
50
55
0.05
0.10
0.15
0.20
p
Time
Figure 4.11: Upper: DGM-based smoothed trajectories of transition aﬃnities, Home-
page →Opinion. Lower: Bayesian credible values corresponding to the aﬃnity trajectories.
5
10
15
20
25
30
35
40
45
50
55
0.6
0.8
1.0
γ
5
10
15
20
25
30
35
40
45
50
55
0.05
0.10
0.15
0.20
p
Time
Figure 4.12: Upper: DGM-based smoothed trajectories of transition aﬃnities, Home-
page →Science. Lower: Corresponding Bayesian credible values.
125

zero at ﬁrst but suddenly begin to increase at around 9:40-9:45am and quickly exceed
the reference line 0.05.
The change in signiﬁcance of the Homepage →Opinion aﬃnities shows that the
DGM has the ﬂexibility to detect time-varying sparsity in parameters. This phe-
nomenon is peculiar to time series analysis and modeling, and the example demon-
strates that such sparsity actually exists in the dataset. It also has important im-
plications for on-line advertising, as it shows that users have diﬀerent interests at
diﬀerent times of the day.
4.5.5
Comparison Across Days
The FoxNews dataset covers both the morning (09:00-10:00am) and the afternoon
(01:00-02:00pm) period on each of the 6 days. We have already discussed a range of
comparisons, and diﬀerences, across days for the morning periods in Section 4.5.3.
Moving to the DGM, we now explore additional features concerning time-of-day
eﬀects as well as day-to-day variation. This is based on running the coupled BDFM-
DGM analysis separately on each time period/day.
Figure 4.13 shows the DGM trajectories for the retrospective baseline parameter
process µ1:T for each of the 12 ﬁfty-minute intervals. Trajectories are similar across
days but for notable diﬀerences between February 24 and March 9. On February 24,
the afternoon ﬂow is signiﬁcantly lower than the morning ﬂow, while the morning
ﬂow that day is much larger than across other days. One plausible reason is increased
morning traﬃc in response to discussions following the Academy Awards ceremony,
with a resulting lull in the afternoon traﬃc. The reverse happens on March 3, 4 and
9 where, although the morning traﬃc seems typical, the afternoon traﬃc is unusually
high. March 3 was the day on which FoxNews posted an article concerning Hillary
Clinton’s use of her personal email account for all correspondence during her tenure
as Secretary of State. It is plausible that this led to larger than usual afternoon
126

10
20
30
40
50
0.4
0.6
0.8
23 Feb (M)
10
20
30
40
50
0.4
0.6
0.8
24 Feb (Tu)
10
20
30
40
50
0.4
0.6
0.8
 3 Mar (M)
10
20
30
40
50
0.4
0.6
0.8
 4 Mar (Tu)
10
20
30
40
50
0.4
0.6
0.8
 9 Mar (M)
10
20
30
40
50
0.4
0.6
0.8
10 Mar (Tu)
Figure 4.13: DGM-based inference on baseline ﬂow level trajectories for all six days,
with 95% credible intervals. The red trajectories correspond to the 09:05-09:55am time
window, and the blue trajectories correspond to the 01:05-01:55 p.m. time window.
traﬃc ﬂows as the controversy unfolded.
A “fair” comparison of the diﬀerent datasets is diﬃcult since the DGM can pro-
vide diﬀerent results for the same dataset if the identiﬁcation strategy is changed.
The comparison above is based on the identiﬁcation with constraints from Sec-
tion 4.3.5 that are applied to each dataset independenly. Since restriction indicators
sij are deﬁned by observations yij,1:T, the diﬀerent datasets may lead to diﬀerent
restrictions even under the same identiﬁcation rule. This problem motivates another
possible approach to comparison that uses a common restriction: deﬁning sij based
on the ﬁrst dataset and using the same indicators for the others. Figure 4.14 shows
the posteriors of µ1:T obtained with the common restriction (deﬁned by the morn-
ing data on 23rd February, so the result of this time/date is the reference line for
the other datasets). Though they are diﬀerent from the posteriors in Figure 4.13
in terms of their scales, the basic relation between morning and afternoon within a
127

10
20
30
40
50
0.25
0.50
0.75
23 Feb (M)
10
20
30
40
50
0.25
0.50
0.75
24 Feb (Tu)
10
20
30
40
50
0.25
0.50
0.75
 3 Mar (M)
10
20
30
40
50
0.25
0.50
0.75
 4 Mar (Tu)
10
20
30
40
50
0.25
0.50
0.75
 9 Mar (M)
10
20
30
40
50
0.25
0.50
0.75
10 Mar (Tu)
Figure 4.14: Posterior trajectories of µ1:T with the common restriction.
day is preserved. This representation emphasizes the increase of the population of
visitors in the afternoon of 3rd March, that matches the eﬀect of the political article
posted on that date.
One of the advantages of the DGM representation is that it allows an easy path
to check these speculative explanations. For example, as seen in Figure 4.15, the ex-
amination of the aﬃnity eﬀect on the incoming ﬂow into the Entertainment domain,
γ0,5,t, shows the unusual popularity of this domain that continues until the morning
of February 24. The observed aﬃnity eﬀects in the end of February that are much
larger than those in early March supports our reasoning that ties the increase of
traﬃc to the Academy Awards ceremony.
4.6
Summary Comments
The BDFM framework is adaptive to time-varying rates of ﬂows within dynamic
networks and able to coherently quantify non-stationary changes in within- and
into-/out of- network ﬂow rate processes. The sequential analysis of this Bayesian
128

10
20
30
40
50
2
4
23 Feb (M)
10
20
30
40
50
2
4
24 Feb (Tu)
10
20
30
40
50
2
4
 3 Mar (M)
10
20
30
40
50
2
4
 4 Mar (Tu)
10
20
30
40
50
2
4
 9 Mar (M)
10
20
30
40
50
2
4
10 Mar (Tu)
Figure 4.15: DGM-based inference on γ0,5,1:T for all six days. The 12 retrospective pos-
terior trajectories of the aﬃnity eﬀect, γ0,5,t, which corresponds to the ﬂow from External
to Entertainment.
dynamic ﬂow model is fast and eﬃcient; computational demands scale linearly in
time and quadratically in node number. Importantly, this almost semi-parametric
approach generates a parallelizable analysis yielding full posterior distributions for
underlying rate parameter process parameters across nodes and pairs of nodes in a
scalable manner. While the model inherently reﬂects the complexity of interactions
among the full set of nodes, and their changes over time, the BDFM approach “de-
couples” analysis to individual nodes and pairs of nodes, and “recouples” them (via
the map from decoupled gamma to recoupled Dirichlet posteriors over time) for for-
mal inferences. Our analysis of the FoxNews network time series datasets shows the
utility of the BDFM in generating initial inferences on ﬂow rate processes, in high-
lighting diﬀerences across days and in generating potential practical “leads”. On the
latter, for example, it is immediately clear from the BDFM results that most visitors
go to just one domain, rather than traversing to multiple domains. This has poten-
129

tial decision implications for computational advertising, and also likely highlights a
diﬀerence between on-line news consumers and traditional newspaper readers.
The Bayesian emulation “map” from the BDFM to the dynamic gravity model
represents a modelling/computational strategy of increasing interest in many areas,
and especially in emerging Big Data applications. That is, we ﬁt a ﬂexible, adaptive
model in a set of (conditionally) decoupled analyses, and then directly map posterior
samples to the more substantively interesting and interpretable parameter processes
in a model, the DGM, that is otherwise challenging to ﬁt. Applied to the FoxNews
ﬂow data, we see that this indicates “time-varying sparsity” in node-node interaction
eﬀects over time, nicely captured by the DGM. Our use of Bayesian credible values
over time is one nice way of focusing attention on this, allowing us to highlight the
“signiﬁcance” of inferred DGM interactions across time. Interestingly, many of the
interaction eﬀects (aﬃnities) appear signiﬁcant at some points in time but not in
others. A number of the speciﬁc node-node inferences mentioned in the application
section highlight additional results of substantive interest, some of which are initially
unexpected. These include, for example, the sustained positive aﬃnity of Opinion for
Homepage, but a similarly sustained but negative aﬃnity of Science for Homepage.
Additionally, comparisons across diﬀerent times of the day identiﬁed and quantiﬁed
patterns related to anomalous ﬂows corresponding to identiﬁable news events that
appear to have driven traﬃc to speciﬁc nodes on the FoxNews site.
From this point, we see opportunities to now develop these models as a basis to
characterize the stochastic dynamics of website ﬂows, and hence feed into modeling
and decision analysis that addresses the needs to respond to changing patterns in
computational advertising.
An ability to rapidly signal potential anomalies in a
small subset of domains in real-time will be of huge interest in this ﬁeld. We also
note, as remarked in the introduction to the chapter, the potential connections with
problems of physical traﬃc ﬂows, origin-destination problems, and other kinds of
130

dynamic network studies including social networks, capital ﬂows between ﬁnancial
institutions, electrical power grids, and others.
More immediately, some of the evident questions arising from the current study
concern the overlay of the “unbiased” inferences about changes and structure in net-
work ﬂows with substantive covariate information. In many applications, including
computational advertising but also capital and transportation ﬂows, there are useful
covariates that could inform the analysis. Our perspective here has been more ex-
ploratory, aiming to deﬁne a formal basis for eﬀectively characterizing non-stationary
stochastic dynamics in ﬂow data. A next step is to overlay any particular application
with covariate information as descriptive/explanatory as we exempliﬁed with some
vignettes from the FoxNews study. At a more predictive level, the DGM is naturally
extensible to incorporate covariates– in main eﬀects and/or interaction terms– so
that some consideration of how to extend the ﬂexible, computational eﬃcient and
scalable BDFM-DGM in that direction is warranted.
131

4.7
Appendix: FFBS for Poisson-Gamma Models
4.7.1
Forward Filtering
The derivation of the prior, forecast and on-line posterior distributions are explained.
To compute the prior p(φt|Dt−1), use the method of change of variables for φt.
First, note that ηt = δφt/φt−1, so the Jacobian is dηt/dφt = δ/φt−1. Also, since
0 < ηt < 1, the support of the distribution of φt is φt−1 > δφt. Thus, the conditional
distribution of φt is
p(φt|φt−1, Dt−1) = p(ηt|Dt−1)

dηt
dφt

=
1
B(δrt−1, (1 −δ)rt−1)
 δφt
φt−1
δrt−1−1 
1 −δφt
φt−1
(1−δ)rt−1−1
δ
φt−1
∝φ−rt−1+1
t−1
φδrt−1−1
t
(φt−1 −δφt)(1−δ)rt−1−1 ,
where the last expression above is obtained by ignoring the constant terms which
contain neither φt nor φt−1. With the prior at t −1, the prior at t is calculated by
p(φt|Dt−1) =
Z
{0<φt<δφt−1}
p(φt|φt−1, Dt−1)p(φt−1|Dt−1)dφt−1
∝
Z
{0<φt<δφt−1}

φ−rt−1+1
t−1
φδrt−1−1
t
(φt−1 −δφt)(1−δ)rt−1−1
×

φrt−1−1
t−1
e−ct−1φt−1
dφt−1
∝φδrt−1−1
t
Z
{0<φt<δφt−1}
(φt−1 −δφt)(1−δ)rt−1−1 e−ct−1φt−1dφt−1,
and, with another change of variable in that θ = φt−1 −δφt, dθ/dφt−1 = 1 and
132

θ ∈(0, ∞) (since, as mentioned above, ηt < 1 implies φt−1 > δφt), we continue as
p(φt|Dt−1) ∝φδrt−1−1
t
Z ∞
0
θ(1−δ)rt−1−1e−ct−1θe−δct−1φtdθ
= φδrt−1−1
t
e−δct−1φt Γ((1 −δ)rt−1)
(δc1−δrt−1
t−1
)
∝φδrt−1−1
t
e−δct−1φt,
which is exactly the kernel of gamma density with shape δrt−1 and rate δct−1.
The forecast distribution is obtained in a similar way by integrating the joint
distribution of (yt, φt) as
p(yt|Dt−1) =
Z
p(yt|φt)p(φt|Dt−1)dφt
=
Z φyt
t
yt! e−φt
 (δct−1)δrt−1
Γ(δrt−1) φδrt−1−1
t
e−δct−1φt

dφt
∝1
yt!
Z
φyt+δrt−1−1
t
e−(δct−1+1)φtdφt
∝1
yt!
Γ(yt + δrt−1)
(δct−1 + 1)yt+δrt−1
∝Γ(yt + δrt−1)
Γ(yt + 1)

1
δct−1 + 1
yt
,
which is the negative binomial distribution as desired.
The on-line posterior can be obtained from the joint distribution as
p(φt|Dt) ∝p(yt, φt|Dt−1)
= p(yt|φt)p(φt|Dt−1)
=
φyt
t
yt! e−φt
 (δct−1)δrt−1
Γ(δrt−1) φδrt−1−1
t
e−δct−1φt

∝φδrt−1+yt−1e−(δct−1+1)φt,
which is the kernel of gamma distribution with shape rt = δrt−1 + yt and rate
ct = δct−1 + 1.
133

4.7.2
Backward Sampling
Based on the result of ﬁltering, the details of backward sampling are explained.
First, note that the conditional independence structure in this state-space model
simpliﬁes the target distribution as p(φt|φt+1, DT) = p(φt|φt+1, Dt), i.e., the observa-
tions after t are independent of φt conditional on φt+1. Then,
p(φt|φt+1, DT) ∝p(φt+1|φt, Dt)p(φt|Dt)
=
1
B(δrt, (1 −δ)rt)
δφt+1
φt
δrt−1 
1 −δφt+1
φt
(1−δ)rt−1 δ
φt
×
crt
t
Γ(rt)φrt−1
t
e−ctφt
∝(φt −δφt+1)(1−δ)rt−1 e−ctφt
∝(φt −δφt+1)(1−δ)rt−1 e−ct(φt−δφt+1),
and, by the change of variables with ϵt = φt −δφt+1, it follows that
ϵt ∼G((1 −δ)rt, ct),
which proves the statement in Section 4.2.1.
134

5
Concluding Remarks
This dissertation has discussed research advances in three areas of Bayesian time
series analysis: sequential modeling, inference and decision making. In each area, we
have considered modern and challenging statistical problems of modeling/analyzing
multivariate time series in the presence of high-dimensionality and sparsity. Building
on the cross-cutting concept of Bayesian model emulation, the thesis demonstrates
substantial advances in Bayesian methodology to overcome challenging problems
raised in addressing practical use in both academic and industrial applications.
Each research area has multiple themes and directions that are open to future
research.
Chapter 2: Inference
• Though the two recommended LTM emulators perform well in predictive ac-
curacy, the central problem of particle degeneracy– the main issue facing all
SMC approaches– leaves room for improvements. The combination of SMC
with MCMC, mentioned in Chapter 2, can help to resolve this, by allowing for
periodic “refreshing” of particle samples using oﬀ-line MCMC methods, that
135

then seed a new period of SMC analysis.
• There is no unique deﬁnition of the LTM emulator. This research developed and
explored several, and left open questions of “optimal” emulators. For example,
one idea would be to develop some kind of model discrepancy measure, such as
based on Kullback-Leibler divergences between target and emulating posteriors
(at some time point or points), aiming to deﬁne “optimal” choices. This idea
could be applied, instead, to emulation of sampling distributions at some time
points, and/or one-step ahead predictive distributions. How to begin to develop
this concept is an open question, but the ideas seem natural.
• The idea and methodology of Bayesian model emulation in time series is not
restricted to LTMs, and could be explored and developed in other contexts of
non-linear state-space models, such as Markov switching models (increasingly
popular in macroeconomics), or others.
Chapter 3: Decisions
• The idea of emulation will yield many synthetic models in various kinds of deci-
sion problems. In our example, the asymmetric version of MSE that penalizes
excess returns less (if at all!) than losses can be derived from the generalized
hyperbolic skewed-t distribution in the synthetic model. This distribution, as
well as the Laplace distribution, has the mixture form (e.g. Hu and Kercheval,
2008) that enables modeling of the target return as
mt = f ′
twt + N(ξtρt, ξt),
ξ−1
t
∼Ga(νt/2, νt/2),
where (νt, ρt) are the pre-speciﬁed degree of freedom and skewness parameters.
Related EM methods allow for numerical search for posterior modes in the
synthetic/emulating model.
136

Another example is to group similar assets and consider common shrinkage to-
ward that group. Such a grouping/classiﬁcation might be done in the inference
step based on the emulating statistical model. For the s-th group of assets,
deﬁned by an index subset Ss ⊂1:k, we could then make use of a common
mixing parameter for the Laplace distribution, i.e.,
ws,t = ws,t−1 + N(0, τs,tWs,t),
τs,t ∼Ga(1, λ−2
s,t /2),
where ws,t = {wit}i∈S, the sub-vector of wt, and with Ws,t as the pre-speciﬁed
covariance matrix (typically Ws,t = I.) This distribution is known as the mul-
tivariate version of Laplace distribution (Eltoft et al., 2006). The EM method
is available and open for development for solution in this grouped context, and
compatible with the other mixing parameters.
Again, it should be emphasized that the core idea of mapping a hard, computa-
tional optimization problem to an emulating, purely synthetic statistical model
exploration program, is very general strategy and likely of interest to explore
in many future areas. Some opportunities may exist in exploring discussions of
currently topical optimization problems in applied mathematics and engineer-
ing ﬁelds, for example, that may be open (technically) to approaches based on
new Bayesian emulation ideas.
• It is of interest in both theory and practice to explore what classes of loss
functions might in fact yield parallel synthetic models. Presumably, not all
expected loss functions can be converted to probabilistic models. To see this,
consider the new MSE loss function in a portfolio example that does not penal-
ize excess returns at all. One example is the truncated quadratic loss function
deﬁned as
(mt −f ′
twt)2 1[ f ′
twt ≤mt ].
137

Any monotonic transformation of the loss function above results in the function
of wt that is constant on { wt | f ′
twt > mt }. This cannot yield a parallel, syn-
thetic probability density because its integral is not ﬁnite. Instead, it might be
viewed as an “improper likelihood,” that could yield a proper posterior distri-
bution, assuming a proper (synthetic) prior. Though the philosophical question
on the appropriateness of this type of analysis remains, it may be practically
useful unless it loses the well-deﬁned posterior and the unique posterior mode.
• The diﬀerence between the proﬁled and marginal approaches was examined
empirically but not fully theoretically. In multi-step optimization– in portfolio
analysis and other areas, such as dynamic control in engineering, or in policy
decision making in macroeconomics– this issue is central and critical. The two
approaches simply lead to diﬀerent loss functions; they just represent diﬀerent
preferences. Yet, it is worth understanding that diﬀerence theoretically, since
the theory on the diﬀerence between those loss functions can help the decision
maker to choose one of them that really matches his or her personal preference.
Theoretical studies of relationships between joint and marginal modes are of
interest here. In simple lasso regression,
y = Xβ + ϵ,
ϵ ∼N(0, σ2In)
with known σ2, we can ﬁnd the marginal density, p(β1|y), analytically with
β partitioned as β1 and β2. The extension of this type of analysis to more
elaborate problems may reveal insights based on diﬀerences in results, including
the relevance to resulting diﬀerences in portfolios based on joint versus marginal
optimization, as in Section 3.5 and 3.6.
In more general contexts, theoretical considerations of the marginal loss func-
tion might be addressed in terms of nuisance parameters for inference, e.g.
138

using ideas from semi-parametric estimation.
• More extensive application to higher-dimensional portfolio investment prob-
lems is a key interest– from applied perspectives in ﬁnancial analysis, and also
from research perspectives in terms of computational feasibility. With advances
in research in dynamic models and forecasting geared at scaling forecasting
models to many more series– such as in Gruber and West (2016) and our work
with LTMs– the ability to generate sensitive short-term predictive models is
advancing, so promoting a need for more active research in scaling the decision
analysis to enable banks of portfolios to be run in real-time against multiple
utility functions. Signiﬁcant advances in the abilities to (i) customize multi-
step utility functions to context and increasing numbers of assets, potentially
with structure to group assets within classes, and (ii) implement fast and re-
liable portfolio optimization to help advise allocation decisions, promotes and
highlights the core ideas underlying our Bayesian emulation research presented
here, and the need for active development to scale and implement the idea
more broadly.
Chapter 4: Modeling
• The beautiful mathematical property of the mapping from BDFMs to DGM is
largely dependent on the relatively simple parametrization of DGM. This is no
longer available if one introduces covariates and regression forms in one of the
DGM components, e.g., log γijt = x′
ijtλijt. It is of great practical interest to
have covariates associated with each node or edge/ﬂow in the model in many
areas.
Naturally, the parallelizable simulation-based methods are needed in sampling
from the retrospective posteriors of this type of model. There exists some re-
139

search on sequential analysis of the Poisson state-space models (Aktekin et al.,
2016), but the use of covariates in such models is very limited– at least in terms
of easily accessible, published research. The idea of Bayesian model emulation
might help the development of new sequential analysis methods for extended
DGM and broader classes of models, including speciﬁcally classes of dynamic
generalized linear models.
• In practice, covariates are often categorical or can be reasonably discretized.
The proposed emulation by BDFMs is valid for this case by dividing the nodes
into several sub-groups based on the covariates. For example, the FoxNews
dataset has information on the time zone associated with each visit. For time
zone s, we might deﬁne a new node (i, s) and ﬂow yijst to reﬂect this. For the
Poisson rate φijst, the DGM would then correspond to a 3-way ANOVA, adding
the time-zone speciﬁc eﬀect and the interaction to the origin/destination.
Each of the three main areas of research represented in this thesis has its own
origin, structure and problems, but they are tied together through the core idea
of deﬁning analysis solutions via emulation: emulating a target model, or a target
decision function, depending on context.
While it is easier to deﬁne the model
that directly addresses the problem/data/preference of interest, such an approach
is highly likely to result in a non-linear, non-Gaussian state-space model that is
mathematically complex and overly parametrized, e.g. LTMs in Chapter 2, Laplace
models in Chapter 3, and DGMs in Chapter 4. The emulator(s) should be “simple”
statistical models associated with the well-known computational methodologies, that
are thoughtfully developed so as to address the core goals of the target context
remaining amenable to eﬃcient solution.
The emulators used in this dissertation are all DLMs—Gaussian linear state-space
140

models—and their variants, which are theoretically complete and well-understood
(e.g. West and Harrison, 1997). It is worth reiterating that posterior analysis using
simulation via FFBS is central to computation in many situations, even though the
models are no longer Gaussian and linear. Despite computation advances that en-
able use of increasingly large-scale and complex MCMC methods, the fact that many
statistical challenges are still emerging and unsolved implies the importance of revis-
iting simpler but analytically tractable models and potential tools, as exempliﬁed by
this core role of DLM/FFBS analysis in all three areas of this thesis. As a result of
this experience, and deﬁning a position for future research and application, I believe
that the spirit of Bayesian emulation will be seen in the future in various areas of
statistical research and application.
141

Bibliography
Agarwal, D., Agrawal, R., Khanna, R., and Kota, N. (2010), “Estimating rates of
rare events with multiple hierarchies through scalable long-linear models,” KDD’10
Proceedings of the 16th ACM SIGKDD, pp. 213–222.
Aktekin, T., Polson, N. G., and Soyer, R. (2016), “Sequential Bayesian analysis of
multivariate Poisson count data,” arXiv preprint arXiv:1602.01445.
Amzal, B., Bois, F. Y., Parent, E., and Robert, C. P. (2006), “Bayesian-optimal
design via interacting particle systems,” Journal of the American Statistical Asso-
ciation, 101, 773–785.
Anacleto, O., Queen, C., and Albers, C. J. (2013a), “Forecasting multivariate road
traﬃc ﬂows using Bayesian dynamic graphical models, splines and other traﬃc
variables,” Australian & New Zealand Journal of Statistics, 55, 69–86.
Anacleto, O., Queen, C., and Albers, C. J. (2013b), “Multivariate forecasting of
road traﬃc ﬂows in the presence of heteroscedasticity and measurement errors,”
Journal of the Royal Statistical Society (Series C, Applied Statistics), 62, 251–270.
Andrews, D. F. and Mallows, C. L. (1974), “Scale mixtures of normal distributions,”
Journal of the Royal Statistical Society (Series B: Methodological), 36, 99–102.
Asif, A. and Moura, J. M. (2005), “Block matrices with L-block-banded inverse:
Inversion algorithms,” IEEE Transactions on Signal Processing, 53, 630–642.
Berger, J. O. (1985), Statistical Decision Theory and Bayesian Analysis, Springer.
Bishop, Y., Fienberg, S. E., and Holland, P. (1975), Discrete Multivariate Analysis:
Theory and Practice, The MIT Press.
Brandt, P. T. and Williams, J. T. (2001), “A linear Poisson autoregressive model:
The Poisson AR (p) model,” Political Analysis, 9, 164–184.
Brandt, P. T., Williams, J. T., Fordham, B. O., and Pollins, B. (2000), “Dynamic
modeling for persistent event-count time series,” American Journal of Political
Science, pp. 823–843.
142

Carvalho, C. M. and Lopes, H. F. (2007), “Simulation-based sequential analysis of
Markov switching stochastic volatility models,” Computational Statistics & Data
Analysis, 51, 4526–4542.
Carvalho, C. M., Johannes, M. S., Lopes, H. F., and Polson, N. G. (2010), “Particle
learning and smoothing,” Statistical Science, 25, 88–106.
Chen, X., Irie, K., Banks, D., Haslinger, R., Thomas, J., and West, M. (2015),
“Bayesian dynamic modeling and analysis of streaming network data,” Technical
Report, Duke University.
Cogley, T. and Sargent, T. J. (2005), “Drifts and volatilities: Monetary policies and
outcomes in the post WWII U.S.” Review of Economic Dynamics, 8, 262–302.
Congdon, P. (2000), “A Bayesian approach to prediction using the gravity model,
with an application to patient ﬂow modeling,” Geographical Analysis, 32, 205–224.
Dempster, A. P., Laird, N. M., and Rubin, D. B. (1977), “Maximum likelihood from
incomplete data via the EM algorithm,” Journal of the Royal Statistical Society.
Series B (Methodological), pp. 1–38.
Doornik, J. A. (2007), Object-Oriented Matrix Programming Using Ox, 3rd ed., Lon-
don: Timberlake Consultants Press and Oxford, 3rd edn.
Eltoft, T., Kim, T., and Lee, T.-W. (2006), “On the multivariate Laplace distribu-
tion,” IEEE Signal Processing Letters, 13, 300–303.
Figueiredo, M. A. T. (2003), “Adaptive sparseness for supervised learning,” IEEE
Transactions on Pattern Analysis and Machine Intelligence, 25, 1150–1159.
Ghahramani, Z. (1995), “Factorial learning and the EM algorithm,” in Advances in
neural information processing systems, pp. 617–624, Morgan Kaufman.
Gruber, L. F. and West, M. (2016), “GPU-accelerated Bayesian learning in simulta-
neous graphical dynamic linear models,” Bayesian Analysis, 11, 125–149, Advance
Publication, 2 March 2015.
Harvey, A. and Fernandes, C. (1989a), “Time series models for insurance claims,”
Journal of the Institute of Actuaries, 116, 513–528.
Harvey, A. C. and Fernandes, C. (1989b), “Time series models for count or qualitative
observations,” Journal of Business & Economic Statistics, 7, 407–417.
Hu, W. and Kercheval, A. (2008), “The skewed t distribution for portfolio credit
risk,” Advances in econometrics, 22, 55–83.
Irie, K. and West, M. (2016a), “Bayesian emulation for multi-step portfolio deci-
sions,” Technical Report, Duke University.
143

Irie, K. and West, M. (2016b), “Bayesian emulation for sequential analysis of dynamic
latent threshold models,” Technical Report, Duke University.
Jandarov, R., Haran, M., Bjornstad, O. N., and Grenfell, B. T. (2014), “Emulating
a gravity model to infer the spatiotemporal dynamics of an infectious disease,”
Journal of the Royal Statistical Society (Series C, Applied Statistics), 63, 423–444.
Johannes, M., Korteweg, A., and Polson, N. (2014), “Sequential learning, predictabil-
ity, and optimal portfolio returns,” Journal of Finance, 69, 611–644.
Koop, G. and Korobilis, D. (2010), “Bayesian multivariate time series methods for
empirical macroeconomics,” Foundations and Trends in Econometrics, 3, 267–358.
Koop, G. and Korobilis, D. (2013), “Large time-varying parameter VARs,” Journal
of Econometrics, 177, 185–198.
Koop, G., Leon-Gonzalez, R., and Strachan, R. W. (2009), “On the evolution of the
monetary policy transmission mechanism,” Journal of Economic Dynamics and
Control, 33, 997–1017.
Koren, R., Bell, R., and Volinsky, C. (2009), “Matrix factorization techniques for
recommender systesms,” Computer, 8, 30–37.
Korobilis, D. (2011), “VAR forecasting using Bayesian variable selection,” Journal
of Applied Econometrics.
Liu, C., Martin, R., and Syring, N. (2013), “Simulating from a gamma distribution
with small shape parameter,” arXiv preprint arXiv:1302.1884.
Liu, F., Chakraborty, S., Li, F., Liu, Y., Lozano, A. C., et al. (2014), “Bayesian
regularization via graph Laplacian,” Bayesian Analysis, 9, 449–474.
Liu, J. and West, M. (2001), “Combined parameter and state estimation in
simulation-based ﬁltering,” in Sequential Monte Carlo Methods in Practice, eds.
A. Doucet, J. F. G. D. Freitas, and N. J. Gordon, pp. 197–217, Springer.
Liu, J. S. (1996), “Metropolized independent sampling with comparisons to rejection
sampling and importance sampling,” Statistics and Computing, 6, 113–119.
Liu, J. S. and Chen, R. (1998), “Sequential Monte Carlo methods for dynamic sys-
tems,” Journal of the American Statistical Association, 93, 1032–1044.
Lopes, H. F. and Tsay, R. S. (2011), “Particle ﬁlters and Bayesian inference in
ﬁnancial econometrics,” Journal of Forecasting, 30, 168–209.
144

Lopes, H. F., Carvalho, C. M., Johannes, M., and Polson, N. G. (2010), “Particle
learning for sequential Bayesian computation,” in Bayesian Statistics 9, eds. J. M.
Bernardo, M. J. Bayarri, J. O. Berger, A. P. Dawid, D. Heckerman, A. F. M.
Smith, and M. West, pp. 175–96, Oxford University Press.
Markowitz, H. (1952), “Portfolio Selection,” The Journal of Finance, 7, 77–91.
Markowitz, H. M. (1968), Portfolio Selection: Eﬃcient Diversiﬁcation of Invest-
ments, Yale University Press.
M¨uller, P. (1999), “Simulation based optimal design,” in Bayesian Statistics 6, eds.
J. M. Bernardo, J. O. Berger, A. P. Dawid, and A. F. M. Smith, pp. 459–474,
Oxford University Press.
M¨uller, P., Sans´o, B., and De Iorio, M. (2004), “Optimal Bayesian design by inho-
mogeneous Markov chain simulation,” Journal of the American Statistical Associ-
ation, 99, 788–798.
Nakajima, J. (2011), “Time-varying parameter VAR model with stochastic volatility:
An overview of methodology and empirical applications,” Tech. rep., Institute for
Monetary and Economic Studies, Bank of Japan.
Nakajima, J. and West, M. (2013a), “Bayesian analysis of latent threshold dynamic
models,” Journal of Business and Economic Statistics, 31, 151–164.
Nakajima, J. and West, M. (2013b), “Bayesian dynamic factor models:
Latent
threshold approach,” Journal of Financial Econometrics, 11, 116–153.
Nakajima, J. and West, M. (2015), “Dynamic network signal processing using latent
threshold models,” Digital Signal Processing, 47, 5–16.
Pang, B. and Lee, L. (2008), “Opinion mining and sentiment analysis,” Foundations
and Trends in Information Retrieval, 2, 1–135.
Park, T. and Casella, G. (2008), “The Bayesian lasso,” Journal of the American
Statistical Association, 103, 681–686.
Pitt, M. K. and Shephard, N. (1999), “Filtering via simulation: Auxiliary variable
particle ﬁlter,” Journal of the American Statistical Association, 94, 590–599.
Polson, N. G. and Scott, J. G. (2015), “Mixtures, envelopes and hierarchical duality,”
Journal of the Royal Statistical Society: Series B (Statistical Methodology).
Prado, R. and Lopes, H. F. (2013), “Sequential parameter learning and ﬁltering
in structured autoregressive state-space models,” Statistics and Computing, 23,
43–57.
145

Prado, R. and West, M. (2010), Time Series: Modeling, Computation and Inference,
Chapman and Hall/CRC Press.
Primiceri, G. E. (2005), “Time varying structural vector autoregressions and mone-
tary policy,” The Review of Economic Studies, 72, 821–852.
Queen, C. M. and Albers, C. J. (2009), “Intervention and causality: Forecasting traf-
ﬁc ﬂows using a dynamic Bayesian network,” Journal of the American Statistical
Association, 104, 669–681.
Rue, H., Martino, S., and Chopin, N. (2009), “Approximate Bayesian inference for
latent Gaussian models by using integrated nested Laplace approximations,” Jour-
nal of the Royal Statistical Society (Series B: Methodological), 71, 319–392.
Sen, A. and Smith, T. (1995), Gravity Models of Spatial Interaction Behavior,
Springer.
Shephard, N. (1994), “Local scale models: State space alternative to integrated
GARCH processes,” Journal of Econometrics, 60, 181–202.
Smith, J. Q. (1979), “A generalization of the Bayesian steady forecasting model,”
Journal of the Royal Statistical Society, Series B (Methodological), 375–387.
Soriano, J., Au, T., and Banks, D. (2013), “Text mining in computational advertis-
ing,” Statistical Analysis and Data Mining, 6, 273–285.
Taddy, M. (2013), “Multinomial inverse regression for text analysis,” Journal of the
American Statistical Association, 108, 755–770.
Tebaldi, C. and West, M. (1998), “Bayesian inference on network traﬃc using link
count data (with discussion),” Journal of the American Statistical Association, 93,
557–576.
Tebaldi, C., West, M., and Karr, A. F. (2002), “Statistical analyses of freeway traﬃc
ﬂows,” Journal of Forecasting, 21, 39–68.
Uhlig, H. (1994), “On singular Wishart and singular multivariate beta distributions,”
The Annals of Statistics, pp. 395–405.
Uhlig, H. (1997), “Bayesian vector autoregressions with stochastic volatility,” Econo-
metrica: Journal of the Econometric Society, pp. 59–73.
West, M. (1987), “On scale mixtures of normal distributions,” Biometrika, 74, 646–
648.
West, M. (1993a), “Approximating posterior distributions by mixtures,” Journal of
the Royal Statistical Society (Ser. B), 54, 553–568.
146

West, M. (1993b), “Mixture models, Monte Carlo, Bayesian updating and dynamic
models,” Computing Science and Statistics, 24, 325–333.
West, M. (1994), “Statistical inference for gravity models in transportation ﬂow
forecasting,” Discussion Paper 94-20, Institute of Statistics & Decision Sciences,
Duke University (June 1994). Also available as NISS Technical Report #60, US
National Institute of Statistical Sciences.
West, M. and Harrison, P. J. (1997), Bayesian Forecasting and Dynamic Models,
Springer Verlag, 2nd edn.
Zhao, Z. Y., Xie, M., and West, M. (2016), “Dynamic dependence networks: Fi-
nancial time series forecasting and portfolio decisions (with discussion),” Applied
Stochastic Models in Business and Industry, To appear.
Zhou, X., Nakajima, J., and West, M. (2014), “Bayesian forecasting and portfolio
decisions using dynamic dependent sparse factor sparse,” International Journal of
Forecasting, 30, 963–980.
147

Biography
Kaoru Irie was born in Tochigi, Japan. He earned his B.A. and M.A. in Economics
from University of Tokyo in 2010 and 2012, and his M.S. in Statistical Science from
Duke University in 2014. He will earn his Ph.D. in Statistical Science from Duke
University in 2016. In June of 2016, he will be joining Graduate School of Economics
at University of Tokyo as an Assistant Professor.
148

