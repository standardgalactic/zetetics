zkSaaS: Zero-Knowledge SNARKs as a Service
Sanjam Garg1, Aarushi Goel2, Abhishek Jain3, Guru-Vamsi Policharla4, and Sruthi Sekar4
1UC Berkeley and NTT Research, sanjamg@berkeley.edu
2NTT Research, aarushi.goel@ntt-research.com
3Johns Hopkins University, abhishek@cs.jhu.edu
4UC Berkeley, {guruvamsip,sruthi}@berkeley.edu
Abstract
A decade of active research has led to practical constructions of zero-knowledge succinct non-
interactive arguments of knowledge (zk-SNARKs) that are now being used in a wide variety of appli-
cations. Despite this astonishing progress, overheads in proof generation time remain significant.
In this work, we envision a world where consumers with low computational resources can out-
source the task of proof generation to a group of untrusted servers in a privacy-preserving manner.
The main requirement is that these servers should be able to collectively generate proofs at a faster
speed (than the consumer). Towards this goal, we introduce a framework called zk-SNARKs-as-a-
service (zkSaaS) for faster computation of zk-SNARKs. Our framework allows for distributing proof
computation across multiple servers such that each server is expected to run for a shorter duration
than a single prover. Moreover, the privacy of the prover’s witness is ensured against any minority of
colluding servers.
We design custom protocols in this framework that can be used to obtain faster runtimes for
widely used zk-SNARKs, such as Groth16 [EUROCRYPT 2016], Marlin [EUROCRYPT 2020] and Plonk
[EPRINT 2019]. We implement proof of concept zkSaaS for the Groth16 and Plonk provers. In compari-
son to generating these proofs on commodity hardware, we show that not only can we generate proofs
for a larger number of constraints (without memory exhaustion), but can also get ≈22× speed-up when
run with 128 parties for 225 constraints with Groth16 and 221 gates with Plonk.
1

Contents
1
Introduction
3
1.1
Overview of Our Approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4
1.2
Example Applications of zkSaaS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
6
1.3
Related Work
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
6
1.4
Future Directions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
7
2
Preliminaries
7
2.1
Bilinear Groups . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
8
2.2
Succinct Non-Interactive Arguments of Knowledge . . . . . . . . . . . . . . . . . . . . . . . .
8
3
zkSaaS Framework
9
4
Overview of Groth, Marlin and Plonk
11
4.1
Groth16, Marlin, and Plonk Provers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
14
5
Distributed Sub-Protocols for the zkSaaS Framework
14
5.1
Distributed Protocol for Fast Fourier Transform . . . . . . . . . . . . . . . . . . . . . . . . . . .
15
5.1.1
Overview of our Protocol . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
15
5.1.2
Our Protocol . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
17
5.2
Distributed Protocol for Partial Products . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
19
5.2.1
Overview of our Protocol . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
19
5.2.2
Our Protocol . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
20
5.3
Distributed Protocol for Multi-Scalar Multiplications . . . . . . . . . . . . . . . . . . . . . . . .
23
5.3.1
Overview of our Protocol . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
23
5.3.2
Our Protocol . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
24
6
zkSaaS for Admissible zk-SNARKs
26
7
Implementation and Evaluation
27
A Groth16 zkSaaS
36
B
Plonk zkSaaS
38
C Sub-Protocols for Standard Functionalities
39
C.1
Secret Sharing Random Values . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
40
C.2
Double Sharing of Random Values . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
40
C.3
Packed Secret Sharing of Random Vectors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
40
C.4
Double Packed Secret Sharing of Random Vectors . . . . . . . . . . . . . . . . . . . . . . . . .
41
C.5
Multiplying Packed Secret Shared Vectors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
42
C.6
Multiplying Secret Shared Values . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
43
C.7
A Protocol for Converting Regular Shares to Packed Shares
. . . . . . . . . . . . . . . . . . .
44
C.8
Converting Packed Shares to Regular Shares . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
46
C.9
Permutation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
46
D Alternate Protocol for Partial Products with Equal Division of Work
49
2

1
Introduction
zk-SNARKs are zero-knowledge succinct non-interactive arguments of knowledge [11], that allow a prover
to non-interactively convince a verifier of the knowledge of a witness attesting to the validity of an NP
relation, without revealing any information about the witness. zk-SNARKs have been a topic of extensive
research in recent years [19, 20, 81, 71, 21, 59, 58, 84, 22, 50, 28, 39]. Their flexibility and expressiveness
make them applicable to a wide variety of scenarios such as private transactions [7, 66], roll-ups [87],
private smart contracts [54, 23], access control in compliance with KYC regulations [68, 69], social net-
works with private reputation monitoring [26], proving existence of bugs in zero-knowledge [49], static
program analysis [37], zero-knowledge middleboxes for enforcing network policies on encrypted traffic
[52], verifiable inference of machine learning [83, 62, 60, 79] and verifiable database queries [85].
Despite recent advances [12, 53, 15, 14, 50, 28, 39, 30], generation of zk-SNARKs remains thousands of
times [78, 64] slower than checking the relation directly for typical applications, with large memory usage
— effectively gate keeping users without access to large machines. A natural way out for such users is to
outsource proof generation to more powerful servers. While one could use a cloud server such as AWS,
GCP or Azure to generate proofs, this approach requires sharing the witness in the clear with the cloud
server. As such, this solution offers no privacy against insider threats such as rogue administrators [32]
who may compromise data privacy for financial gains. Even if the cloud service provider were trusted,
the witness might consist of sensitive data such as patient medical records that legally cannot be placed
off-premises due to data protection laws.
To address the privacy problem, recently, Ozdemir et al. [64] introduced the idea of collaborative zk-
SNARKs for distributed generation of zk-SNARKs. Collaborative zk-SNARKs are essentially secure mul-
tiparty computation (MPC) protocols that allow a group of parties holding shares of the witness to col-
lectively generate a single succinct proof. The key security guarantee is that the witness remains hidden
as long as only a subset of the parties collude. Ozdemir et al. design collaborative zk-SNARK analogs of
Groth16 [50], Marlin [28] and Plonk [39]. In their protocols, all parties run in parallel and each of them
performs as much work as the (single) prover of the underlying zk-SNARK. This results in approximately
the same runtime as that in the single prover model.1
We posit that requiring each of the parties running in parallel to do as much work as the zk-SNARK
prover is an overkill. Indeed, a previous work of Wu et al. [80] leveraged parallelism to distribute proof
computation across different machines in a compute cluster to achieve faster proof generation times. Their
approach, however, requires leaking the witness to the cluster, resulting in a loss of privacy.
In this work, we explore the possibility of combining the best features of collaborative zk-SNARKs [64]
and the work of Wu et al. [80]. We ask:
Is it possible to outsource zk-SNARK proof generation to a group of parties in a privacy-preserving manner
for faster proof generation?
Our Contributions. Our contributions are as follows:
1. We present a general framework for zk-SNARKs-as-a-service (zkSaaS), where a client delegates proof
computation to a group of untrusted servers in a privacy preserving manner. Each of these servers is
expected to run for a shorter duration than a single local prover.
2. We instantiate this framework with custom protocols to obtain faster runtimes than local provers for
widely used zk-SNARKs, such as Groth16 [50], Marlin [28] and Plonk [39].
1This is interesting since they manage to avoid additional security parameter overhead that is usually incurred when securely
computing a function.
3

3. Finally, we implement prototypes of zkSaaS for the Groth16 [50] and Plonk [39] proof systems. Con-
cretely, we show that when creating a proof for 225 constraints in the case of Groth16 (and 221 con-
straints with Plonk), the zkSaaS protocol with 128 servers is ≈22× faster than a local prover. We
also show that deploying more servers helps us get a further speed-up. For instance, when creating
a Groth16 proof for 219 constraints, we see an improvement from ≈1.9× to ≈22× when the number
of servers is increased from 8 to 128. This is in contrast to collabortive zk-SNARKs [64] which do not
obtain any speedup.
4. We also estimate the financial cost of using zkSaaS to compute a Groth16 proof for an instance of size
219 to be under $0.23 with 128 parties using a 64 Mbps link between servers.
1.1
Overview of Our Approach
Similar to [64], our initial idea is to identify common building blocks within widely used zk-SNARKs and
design custom secure multiparty computation (MPC) protocols to compute them efficiently. We then stitch
them together to obtain zkSaaS, an efficient MPC protocol for the corresponding zkSNARK prover.
An Important Observation. One of the key observations made in [64] is that it is possible to directly
secret share points on the elliptic curve and fields and apply MPC techniques on these shares, which avoids
the large overheads incurred when using generic MPC techniques with very few rounds of communica-
tion.2 We go one step ahead and observe that these building blocks can actually be rewritten in a manner
that allows us to leverage significant SIMD structure that appears within their computation.
To leverage this SIMD structure, we make use of a tool called packed secret sharing (PSS) [38].3 This
is a more efficient sibling of Shamir’s polynomial-based secret sharing scheme [72], that allows secret-
sharing a vector of values amongst a set of parties. In particular, at the cost of a slight reduction in the
corruption threshold, using PSS we can “hide” ℓ= O(n)4 secrets (where n is the total number of servers)
in a polynomial and each of the n servers receives an evaluation at a single point in this polynomial. Such
sharings allow parties to efficiently perform SIMD computations on secret shared data, while reducing the
workload on each of them. We use this in the design of each of our sub-protocols.
Multi-Scalar Multiplications (MSM). One of the main building blocks in the zkSNARKs we consider is
MSM, which are operations of the form Πi∈[m]gαt
i , where gi’s are points on an elliptic curve. This is by far
the most expensive component.5 We design a bespoke MPC protocol where the total work (as well as the
asymptotic space requirement) of each server is a factor of ℓless than that of a single prover.
Next we discuss the remaining components i.e., Product Check, Fast Fourier Transform (FFT) and
polynomial computations, which exclusively involve field operations that are much cheaper than elliptic
curve operations.
Product-Check.
Product-Check requiring computations of the form ∏j∈[i] xj, for all i ∈[m], which
are referred to as partial products. Similar to MSM, we design a special-purpose MPC protocol for partial
products, that allows us to divide the work of each server by a factor of ℓless than that of a single prover.
Fast Fourier Transform. The standard description of the FFT algorithm on a polynomial with m coeffi-
cients can be divided into log m steps, with O(m) field multiplications at each step. For the first log m/ℓ
steps, we are able to divide the work of each server by a factor of ℓ. For the remaining log ℓsteps, however,
2This is mainly due to generic MPC techniques making non-blackbox use of the elliptic curve.
3This is also the main building block used in the design of all of general-purpose MPC protocols that support some division
of work (See Section 1.3 for more details.)
4In the implementation we set this to be n/4.
5In Figure 7 we show the fraction of time spent computing MSMs for Groth16.
4

we require one of the parties to do O(m) field operations and have O(m) memory, while the work and
memory requirement of the remaining parties gets divided by ℓ.
Polynomial Multiplication and Division. Finally, we show how to combine standard packed secret
sharing based subprotocols for addition and multiplication along with our custom MPC for FFT to enable
secure distributed polynomial computations.
Composing different subprotocols based on packed secret sharing is not straightforward, and requires
care. We show how to combine the above subprotocols to obtain zkSaaS for faster generation of zk-
SNARKs such as Groth16, Marlin and Plonk.
Communication over a Star Topology Network. Our distributed sub-protocols for all of the functions
described above, do not require servers to communicate with all other servers. Aside from receiving shares
of the extended witness from the client, we require the servers to only communicate with the one large
server, throughout the rest of the computation. As a result, we only need communication channels between
the client and each server and between the large server and every other server.
Instantiating zkSaaS.
As discussed above, the distributed FFT protocol requires one party which has
memory proportional to the size of the relation but the computational resources demanded from all other
parties is reduced by a factor of ℓ. Therefore, a zkSaaS deployment requires one large server. While not
ideal, we argue that this is still reasonable for two reasons — (1) even if the private view of this large server
is leaked, it does not compromise a client’s secrets unlike when a client simply rents a large server to
generate the proof. (2) it is very easy and quite cheap to rent a large server from a cloud service provider.
Finally, we remark that proof generation in the zk-SNARKs that we consider proceeds in two steps:
first, the prover uses its (short) witness to evaluate the relation circuit and obtain a corresponding extended
witness, which is then used to generate the proof (See Section 3 for a detailed discussion). Similar to
collaborative zk-SNARKs [64], in this work, we focus on designing secure distributed protocols for proof
generation and assume that the client computes and shares the extended witness with the servers. We
view faster generation of the extended witness as an important orthogonal question but such protocols
would need to essentially be redesigned for every application.
Security. We now discuss the key aspects of our security model and the guarantees provided by zkSaaS.
We assume that a majority of the servers are honest. Specifically, let n be the total number of servers
and ℓbe the total number of secrets that we can pack in a single packed secret sharing. We require that at
most t < n
2 −ℓof the servers can be corrupted. Further, we assume that the corruptions are semi-honest.
Our zkSaaS framework retains the soundness property of the underlying zk-SNARK and provides the
following completeness and zero-knowledge guarantees:
— Completeness: For any true statement, an execution of zkSaaS involving an honest client and honest
servers outputs an accepting proof.6
— t-Zero Knowledge: In any execution of zkSaaS, the view of the t corrupt servers can be efficiently
simulated without the client’s witness. This, in particular, implies that the corrupt servers learn
nothing about the client’s witness.
We conclude with a few remarks on security against malicious servers. We first note that proofs output
by zkSaaS remain sound even when all servers are malicious. Next, we conjecture that our protocols can
be augmented to achieve t-zero knowledge against malicious servers by using highly efficient compilers
from the recent MPC literature [41, 40, 6, 46, 47]. In essence, these compilers show that semi-honest
MPC protocols that are “secure against malicious corruptions up to linear attacks” can be compiled into
6The completeness property, in fact, holds even if the servers are semi-honest (since such servers follow protocol instructions.)
5

maliciously secure protocols with a small constant (typically, at most two) overhead. We conjecture that
our semi-honest zkSaaS protocols already satisfy the properties required for these efficient compilers; a
formal treatment of the same, however, is outside the scope of this work.
1.2
Example Applications of zkSaaS
We now discuss some real-world applications where we envision our zkSaas-framework to be useful.
Private Transactions and Smart Contracts.
A simple spend transaction on a private chain such as
ZCash[7] already involves ≈130,000 R1CS constraints7 which takes roughly 10 seconds on a high-end
laptop in single threaded mode. This would take even longer on weaker devices such as smart phones
making the process quite tedious for users.
Private smart contracts are immutable programs running on blockchains, which provide confidentiality
of the computation carried out on blockchains [54, 23]. Although these chains can be designed more
carefully to reduce the overhead for simple transactions, they aim to support general computation on the
smart contracts which can blow up to a very large number of constraints as there may be very complicated
logic that gets executed involving cryptographic functions such as signature verification. With zkSaaS,
users can potentially pay a tiny transaction fee in exchange for a seamless experience akin to current
centralized payment methods.
Statements involving Ethereum Wallets. Ethereum uses EdDSA signatures for authentication of trans-
actions over the ed25519 elliptic curve which is not proof friendly. As a result, one needs to emulate non-
native 256-bit field arithmetic which is quite expensive. The verification circuit of an EdDSA signature
costs over 2.5 million R1CS constraints8 and the proving key itself is 1.6 GB in size. Common tasks such as
proof of membership viz. ”I own an Ethereum wallet out of these set of 1024 wallets” become impractical
on mobile devices as the statements are simply too large and lead to memory exhaustion.
Combating Disinformation. It was shown that zero-knowledge proofs can be used to prove that images
appearing in news articles underwent an approved set of transformations from the time of creation [63].
This is particularly helpful in allowing reporters to hide sensitive content while at the same time proving
authenticity of the image. While fast generation of zk-SNARKs is possible for images, doing the same for
compute-heavy video files is currently far from practical and our zkSaaS-framework could aid in carrying
out such a computation.
Verifiable Private ML Inference. A user can commit to a machine learning model and provide a proof
of inference on this machine learning model, which can be used to verify accuracy of a machine learning
model or to ensure that a certain entity who claims to use AI for a task is actually producing predictions
using a machine learning model. Since circuits for inference can be quite large as the models grow in size,
they quickly become impractical to prove even on consumer grade laptops. Again, the data used to train
this model could be patient health records for example which cannot be placed on servers that do not
comply with HIPAA9. Hence, a solution is to use zkSaaS to compute proofs of inferences where no server
sees sensitive information.
1.3
Related Work
Some prior works [55, 31] have considered building MPC-as-a-service, which involves deploying MPC in
a volunteer-operated network (like blockchains). However, such protocols are built for generic function-
7https://github.com/zcash/librustzcash
8https://github.com/Electron-Labs/ed25519-circom
9https://www.hipaajournal.com/
6

alities and do not offer efficient solutions for our specific goal. In a different line of work (unrelated to our
goal), MPC has been used to securely sample the common parameters used in zk-SNARKs [8, 24, 57].
A different line of work has considered the problem of speeding-up the zk-SNARK prover time, but they
either do not hide the witness [80, 70], or lead to [25] linear verification time with a security guarantee that
is weaker than both our framework and the collaborative zk-SNARK framework [64]. Some prior works
have also studied other distributed models of proof systems, including ones where the statement is shared
amongst multiple verifiers [1, 17, 18], or where there are two (or more) non-colluding provers [4, 13].
Our goal in some sense is very similar to the design of MPC protocols, where the total computation and
communication is independent of the number of parties, which has been the focus of a significant line of
research [35, 34, 40, 45, 6, 46, 48]. However for arithmetic circuits, most of these require round complexity
linear in the multiplicative depth of the circuit, which is not ideal in our setting since the prover algorithms
in zk-SNARKs typically don’t have a constant multiplicative depth. Moreover, representing cryptographic
operations such as group exponentiations as an arithmetic circuit and computing them inside an MPC is
extremely inefficient. Therefore, na¨ıvely using these protocols in computing a zk-SNARK will result in
inefficient solutions.
More recently, in a concurrent and independent work, Chiesa et al. [29] also considered the problem of
private delegation of zk-SNARKs for faster proof generation. However, their model is quite different from
ours. In particular, they assume that the client remains online throughout the computation and actively
participates in the zk-SNARK computation along with the servers. For this, they design an MPC protocol
(that is run between the servers and the clients) for zk-SNARK computation leveraging the fact that one
of the parties (i.e., the client) is always honest and the witness need not be hidden from them. Their goal is
to essentially “reduce” the work done by the client. In contrast, in our setting, after sharing the extended
witness, the client does not need to do any work and can delegate the entire zk-SNARK computation to
the servers.
1.4
Future Directions
A promising direction for future work would be to eliminate the need of a single large server in zkSaaS.
In our current solution, this large server is only needed for our distributed protocol for FTT. Potential
approaches for avoiding this could be – (1) Designing a more efficient subprotocol for for distributed
computation of FFT or (2) designing zkSaaS for zk-SNARKs that do not use FFT operations e.g. Orion
[82], Brakedown [44], Hyperplonk [27]. Another interesting problem would be to enable faster generation
of the extended witness in a similar framework. Finally, as discussed in Section 1.1, it would be interesting
to formally demonstrate how the protocols developed in this work can be augmented to achieve security
against malicious servers.
Paper Organization.
We start by establishing some notations in Section 2. We then formally define
zkSaaS- in Section 3, and give an overview of the popular zk-SNARKs of interest (Groth, Marlin and
Plonk) in Section 4. A detailed technical exposition of each of our distributed sub-protocols (FFT, MSM
and sum of partial products) appears in Section 5, and we show how to build a zkSaaS for a specific class
of zk-SNARKs in Section 6. Finally, we discuss the concrete efficiency of our scheme in Section 7.
2
Preliminaries
For any n ∈N, we use [n] to denote the set {1,⋯,n} and for i,j ∈N with i < j, we use [i,j] to denote
the set {i,i + 1,...,j}. We denote a vector of ℓelements from a field F, (x1,⋯,xℓ), by x. For any two
vectors x and y, the component-wise multiplication is denoted by x ⊙y ∶= (x1 ⋅y1,⋯,xℓ⋅yℓ). We always
use capital letters (e.g. X) to denote elements from a group G, and correspondingly X denotes a vector of
7

ℓgroup elements (X1,⋯,Xℓ). We use a multiplicative notation for our group operations throughout the
paper. We begin by describing the notations specific to linear secret sharing schemes used by us.
Linear Secret Sharing Schemes. In this work we make use of polynomial based, regular threshold secret
sharing scheme as well as a packed secret sharing scheme. For regular threshold secret sharing, we use
[x], ⟨x⟩to denote shares of a value x, w.r.t. to a degree t and n −1 polynomial respectively. For packed
secret sharing, we use JxK, ⟪x⟫to denote shares of a vector x w.r.t. to a degree D and n −1 polynomial
respectively, where we assume that the length of x is ℓ∈O(n) and D = t +ℓ. We use [x]i,⟨x⟩i,JxKi,⟪x⟫i
to denotes shares held by a party Pi and [x]S,⟨x⟩S,JxKS,⟪x⟫S to denote the shares held by a subset S of
the parties. Finally, we use functions [x] ←share(F,x,t) and JxK ←pshare(F,x,D) to compute shares
and open(F,JxK,D) and open(F,[x],t) to reconstruct shares.
In the subsequent sections below, we formally define bilinear groups, zk-SNARKs and secure multi-
party computation.
2.1
Bilinear Groups
Let (G1,G2,GT ) be cyclic groups of prime order q with generators g1 ∈G1, g2 ∈G2. e ∶G1 ×G2 →GT be
an efficiently computable and non-degenerate pairing, such that e(hα
1 ,hβ
2) = e(h1,h2)αβ, for all α,β ∈Fq,
and all h1 ∈G1 and h2 ∈G2.
2.2
Succinct Non-Interactive Arguments of Knowledge
In this section, we provide a formal definition for the notion of zero-knowledge succinct non-interactive
arguments of knowledge (zk-SNARKs).
Definition 1 (zk-SNARKs [50]). Let R be a relation generator that given a security parameter λ in unary
returns a polynomial time decidable binary relation R. For pairs (ϕ,w) ∈R we call ϕ the statement and w
the witness. We define Rλ to be the set of possible relations R that the relation generator may output given
1λ. We will in the following for notational simplicity assume λ can be deduced from the description of R. The
relation generator may also output some side information, an auxiliary input z, which will be given to the
adversary. An efficient prover publicly verifiable non-interactive argument for R is a quadruple of probabilistic
polynomial algorithms (Setup,Prove,Ver,Sim) defined as:
— (crs,τ) ←Setup(1λ,R): The setup takes the security parameter λ and the relation R as input and produces
a common reference string crs and a simulation trapdoor τ.
— π ←Prove(crs,R,ϕ,w): The prover algorithm takes as input a common reference string crs and (ϕ,w) ∈
R and returns an argument π.
— 0/1 ←Ver(crs,R,ϕ,π): The verification algorithm takes as input a common reference string crs, a state-
ment ϕ and an argument π and returns 0 (reject) or 1 (accept).
— π ←Sim(R,τ,ϕ): The simulator takes as input a simulation trapdoor τ and statement ϕ and returns an
argument ϕ.
We say that Σ = (Setup,Prove,Ver,Sim) is a zk-SNARK if it satisfies completeness, , succinctness, computa-
tional knowledge soundness and zero-knowledge as described below:
— Completeness. Completeness says that, given any true statement, an honest prover should be able to
convince an honest verifier. For all λ ∈N, R ∈Rλ, (ϕ,w) ∈R
Pr[(crs,τ) ←Setup(1λ,R);π ←Prove(crs,R,ϕ,w) ∶Ver(crs,R,ϕ,w) = 1] ≥1 −negl(λ).
8

— Zero-Knowledge. An argument is zero-knowledge if it does not leak any information besides the truth
of the statement. We say that Σ = (Setup,Prove,Ver,Sim) is zero-knowledge if for all λ ∈N, (R,z) ←
R(1λ), (ϕ,w) ∈R and all adversaries A
Pr[(crs,τ) ←Setup(1λ,R);π ←Prove(crs,R,ϕ,w) ∶A(crs,R,ϕ,τ,π) = 1]
≈c Pr[(crs,τ) ←Setup(1λ,R); π ←Sim(R,τ,ϕ) ∶A(crs,R,ϕ,τ,π) = 1]
— Computational Knowledge Soundness. We say that Σ = (Setup,Prove,Ver,Sim) is an argument of
knowledge if there is an extractor that can compute a witness whenever the adversary produces a valid
argument. The extractor gets full access to the adversary’s state, including any random coins. Formally,
we require that for all non-uniform polynomial time adversaries A there exists a non-uniform polynomial
time extractor XA such that
Pr
⎡⎢⎢⎢⎢⎢⎣
(R,z) ←R(1λ);(crs,τ) ←Setup(1λ,R);
((ϕ,π);w) ←(A∥XA)(crs,R,z) ∶
(ϕ,w) ∉R and Ver(crs,R,ϕ,π) = 1
⎤⎥⎥⎥⎥⎥⎦
≤negl(λ).
— Succinctness. A non-interactive argument of knowledge where the verifier runs in polynomial time in
λ + ∣ϕ∣+ log(∣R∣) and the proof size is polynomial in λ + log(∣R∣) is called a pre-processing SNARK. If we
also restrict the common reference string to be polynomial in λ + log(∣R∣) we say that the non-interactive
argument is a fully succinct SNARK.
In recent years, several SNARK constructions have been proposed both in the random oracle model
and the standard model based on a variety of assumptions. The above definition is in the crs-model, but
can be easily adapted to the random oracle model [30].
3
zkSaaS Framework
As discussed earlier, zkSaaS is a collaborative zk-SNARK [64] framework, where a client delegates the task
of computing a zk-SNARK to n-servers. To realize our goal of enabling fast computation of zk-SNARKs,
the resultant zkSaaS protocol must ensure that – (1) the work done by the clients is minimized and (2) the
work required to compute the zk-SNARK gets divided across all servers.
RICS Format. Let us briefly recall the structure of existing zk-SNARKs. Different zk-SNARKs work with
different representations of the relation R - e.g., quadratic arithmetic programs [65, 70], low-depth cir-
cuits [16, 33, 43, 74, 75, 76, 77, 81, 86], binary arithmetic circuits [39], etc. The most popular representation
amongst state-of-the-art proof systems [9, 28, 50, 51] is known as the rank-1 constraint systems (R1CS)
that generalizes arithmetic circuits.
Proof systems working with this representation proceed in two steps: (1) First, extend the given (short)
statement-witness pair (ϕ,w) into a satisfying assignment z for the RICS relation. The length of this satis-
fying assignment is proportional to the size of the relation. (2) second, give an argument of knowledge for
this satisfying assignment for the RICS relation. Step 1 is inexpensive and only requires non-cryptographic
field operations, while Step 2 requires more expensive cryptographic operations and is typically the bot-
tleneck.
Our Framework. zkSaaS is essentially a secure multiparty computation (MPC) protocol for computing
zk-SNARKs, between a client and n-servers.
Client.
Since Step 1 of the proof generation is inexpensive, we assume that client performs this
9

Definition 2 (zkSaaS). Let λ be the security parameter, n be the number of parties, R ∈Rλ be an
NP-relation and ΣR = (Setup,Prove,Ver,Sim) be a zk-SNARK for R such that: the prover computa-
tion time is Tprover = Tfield + Tcrypto, where Tfield and Tcrypto are the times taken by the prover for the
field operations and cryptographic operations, respectively; the prover space complexity is Sprover. Let
(Preprocessing,Πonline) be a tuple defined as follows:
— Preprocessing(crs,1n) →pre1,...,pren ∶This is a PPT algorithm that takes the crs output by Setup
and the number of servers n as input and outputs correlated randomness prei for each server Pi (for
i ∈[n]).
— Πonline(crs,ϕ,w,pre1,...,pren) →π ∶This is an MPC protocol between a client C and n servers
P1,...,Pn. The client has the statement ϕ and private input w. It sends messages to each of the
n servers in a single round. Given these messages, ϕ and their respective correlated randomness
pre1,...,pren, the servers then engage in an interactive protocol amongst each other to compute a
proof π.
We say that Π = (Preprocessing,Πonline) is a zkSaaS for ΣR, if the following properties are satisfied.
1. Completeness: For all (ϕ,w) ∈R, the following holds:
Pr
⎡⎢⎢⎢⎢⎢⎣
crs ←Setup(1λ)
pre1,...,pren ←Preprocessing(crs,1n)
π ←Πonline(crs,ϕ,w,pre1,...,pren)
RRRRRRRRRRR
Ver(crs,ϕ,π) = 0
⎤⎥⎥⎥⎥⎥⎦
≤negl(λ)
2. t-zero-knowledge: Let crs ←Setup(1λ), pre1,...,pren ←Preprocessing(crs,1n). For all semi-
honest PPT adversaries A controlling at most a t-sized subset Corr ⊂[n] of the servers, there exists an
efficient Simulator SimzkSaaS, such that the following holds for all ϕ,w (where b ←R(ϕ,w) ∈{0,1}):
{viewA
Πonline[ϕ,w]} ≈c {SimzkSaaS(crs,ϕ,b,{prei}i∈Corr)}
here viewA
Πonline[ϕ,w] denotes the view of A in an execution of Πonline(crs,ϕ,w,pre1,...,pren), and
we use ≈c to denote computational indistinguishability between the two distributions.
3. Efficiency: Π = (Preprocessing,Πonline) satisfy the following efficiency requirements:
Preprocessing: The computation complexity of the Preprocessing algorithm is o(Tfield). For each i ∈
[n], size of the correlated randomness ∣prei∣∈O(Sprover/n).
Client: Computation complexity of the client o(Tfield) field operations.
Special Server P1: The first server has a computation complexity of o(Tfield) field operations and
O(Tcrypto/n) cryptographic operations. It’s space and communication complexities are O(Sprover)
and o(Tfield), resp.
Other Servers P2,...,Pn: All other servers have computation complexity of o(Tfield/n) field and
O(Tcrypto/n) cryptgraphic operations. Their space and communication complexities are O(Sprover/n)
and o(Tfield/n), resp.
step and “securely” shares the resulting satisfying assignment z with the servers at the start of the
protocol. To compute this satisfying assignment, the client essentially needs to represent the original
10

relation R as an arithmetic circuit CR and compute all the values induced on the intermediate wires in
circuit CR when evaluated on inputs (ϕ,w). These intermediate values form the satisfying assignment z
for the corresponding RICS relation. Looking ahead, in our construction, the client (pack) secret shares
[38] the vector z with the servers.
Computing and sharing this satisfying assignment requires O(∣R∣log N) ≈O(∣R∣) field operations
and very little space. Indeed, observe that the client can do this computation in a streaming fashion, where
it computes a fraction of the circuit at a time and secret shares the resulting wire values before proceeding
with evaluating the next part of the circuit, thereby minimizing the required space. However, if the client
is unwilling, this computation can also be done via an MPC protocol, where the client only needs to share
the original statement-witness pair (ϕ,w) with the servers, who then run a generic MPC to compute CR
and obtain shares of z.
In this work, we focus on designing an efficient protocol for Step 2, which is the main bottleneck in
the computation of existing zk-SNARKs.
Servers. Given shares of the extended witness, Step 2 is executed via an MPC protocol between the
servers.
We want the total computation and space complexity of this protocol to be asymptotically
identical to that of computing the zk-SNARK by a monolithic entity.
Let the space complexity of the underlying zk-SNARK be Sprover and the computation complexity
be Tfield field operations and Tcrypto cryptographic operations. Then, our zkSaaS-framework guarantees
the following efficiencies: first, in terms of space complexity, one of the servers requires a O(Sprover)
space, while all others require a O(Sprover/n) space; second, in terms of computation, the cryptographic
operations are almost equally divided amongst all the n servers, i.e., all the servers perform O(Tcrypto/n)
cryptographic operations, and the remaining field operations are divided amongst the servers such
that the server with more memory performs o(Tfield)10 field operations, while the remaining (n −1)
low-memory servers each perform O(Tfield/n) field operations.
Pre-Processing. Finally, we assume that the servers get access to some correlated-randomness at the
start of this MPC protocol. This relation-independent correlated-randomness can be generated as part of a
pre-processing step with o(Tfield) computation complexity (requiring only non-cryptographic operations).
This can be either be generated by the client or by the servers themselves using a generic MPC protocol.
Since the computation in this pre-processing phase is independent of the relation, it can be pre-computed
by the servers during downtime.
Communication and Round Complexity.
Finally, we remark that in order to minimize the overhead
from communication, we want to limit the total communication to O(Tfield) and restrict the number
of rounds of interaction between the servers to a constant value. zkSaaS-framework is formalized in
Definition 2.
4
Overview of Groth, Marlin and Plonk
In this section, we review the design of the prover algorithms in three widely used zk-SNARK construction:
Groth16 [50], Marlin [28] and Plonk [39]. We start by discussing the key components (that are often the
main bottleneck) used in the generation of Groth16-, Marlin- and Plonk-proofs.
Fast Fourier Transform, Polynomial Multiplication and Division.
One of the key components
used to optimize prover computation is the Fast Fourier Transform (FFT), which helps evaluate a given
10We note that here we are hiding a logarithmic factor in the n
11

polynomial at m points in O(mlog m) time. The prover computations also typically require additional
FFT-based computations:
1. Inverse FFT (iFFT) is used to convert m evaluations of a polynomial to the coefficient representation
of the polynomial in time O(mlog m).
2. Polynomial Multiplication, which given the coefficient representation, can just be computed using
one call each to FFT and iFFT along with m field multiplications and takes O(mlog m) time.
3. Polynomial Division, which can actually be run by making two calls to polynomial multiplication–
takes O(mlog m) time, where m is degree of the dividend polynomial. For completion, we describe
the polynomial division protocol below. We want to efficiently divide a polynomial p1(X) ∈F[X]
of degree m1 by a polynomial p2(X) ∈F[X] of degree m2 and generate the quotient and remainder
polynomials. In [10], it was shown that this can be done efficiently using two sequential calls of the
polynomial multiplication algorithm as described below:
— Let p1(x) = ∑m1
i=0 aixi and p2(x) = ∑m2
i=0 bixi. The goal is to find q(x) = ∑m1−m2
i=0
qixi and r(x) =
∑m2−1
i=0
rixi such that p1(x) = q(x)p2(x) + r(x). This is equivalent to computing q0,⋯,qm1−m2
and r0,⋯,rm2−1 such that:
⎡⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
am1
am1−1
⋮
⋮
⋮
⋮
a1
a0
⎤⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
=
⎡⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
bm2
0
...
bm2−1
⋱
⋮
⋱
bm2
b0
0
bm2−1
⋮
⋱
⋮
b0
⎤⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
⎡⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
qm1−m2
qm1−m2+1
⋮
q1
q0
⎤⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
+
⎡⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
0
⋮
⋮
⋮
0
rm2−1
⋮
r0
⎤⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
— Here, we consider the first m1 −m2 + 1 equations only, in which case there are no ri’s to solve
for. Let B be the (m1 −m2 + 1) × (m1 −m2 + 1) sub-matrix (with first m1 −m2 + 1 rows) of the
matrix (called a toeplitz matrix) with bi’s above. Then, by computing the inverse matrix11 B−1
and multiplying with the sub-matrix of ai’s with first m1−m2+1 entries12, we get q0,⋯,qm1−m2.
— Now, we can find r(x) directly by computing p1(x) −q(x)p2(x).
Thus, the total time taken to compute the inverse of B and the two polynomial multiplications (one
for computing q(x) and the other for r(x)) is O(m1 log m1).
Multi-scalar Multiplications (MSMs).
Multi-scalar multiplications are of the form ∏j∈[m](Xj)yj,
where y1,...,ym ∈F, and X1,...,Xm ∈G.
Polynomial Commitments. In interactive oracle proofs (IOP)-based zkSNARKs, like Marlin and Plonk,
in each round, the prover sends polynomial oracles to the verifier, which are essentially encodings of the
witness, that the verifier can query. To convert these polynomial-IOPs to SNARKs, the prover commits
to these polynomial oracles using a polynomial commitment scheme [56]. These commitments allow a
11In [61], it is shown how to compute inverse of a triangular k × k toeplitz matrix in time O(k log k). Morever, the inverse
matrix is also a triangular toeplitz matrix.
12Here we use a standard property of the triangular toeplitz matrix, B, described by the vector (bk, ⋯, b0): The matrix product
B(a0, ⋯, ak)⊺represents convolution of (bk, ⋯, b0) and (a0, ⋯, ak), which is just the polynomial multiplcation of the corre-
sponding polynomials with these coefficients.
12

prover to commit to a univariate polynomial p(X) ∈F[X] and get a com, such that the prover can later
open to an evaluation of p(X) at any point z, while giving a proof π of correct evaluation. Formally, a
polynomial commitment scheme consists of a tuple (PC.Setup,PC.Commit,PC.Eval) such that:
— PC.Setup(d) →pp: for polynomials up to degree d, the setup generates the public parameter.
— PC.Commit(pp,p,r) →com: generates the commitment of a polynomial p, using randomness r.
— PC.Eval(pp,x,y,com;p,r) →0/1: this is a protocol between the prover and verifier, where verifier
accepts and outputs 1 if and only if com commits to a p such that p(x) = y. Only the prover knows
p & r.
The security requirement from such commitment schemes is that the encoded polynomial, p, correspond-
ing to the witness remains hidden from the verifier, and on the other hand, a cheating prover should not
be able to convince the verifier of a wrong evaluation (in fact a stronger extraction property is needed).
The formal definitions of the security guarantees needed for the SNARKs can be found in [28, 39]. Keeping
in mind our goal of designing a custom-made protocol for our zkSaaS-framework, we look at the spe-
cific polynomial commitment scheme used in these SNARKs. The most popular polynomial commitment
scheme is the KZG commitment [56] scheme. To compute these commitments, the prover needs to perform
the following functions: (1) to generate the commitment, the prover needs to run the MSM function on d
field and group elements and (2) to generate the proof, the prover needs to perform polynomial division
and then invoke the MSM function on d field and group elements. We now give a detailed description of
KZG commitments explaining the above observations.
KZG Commitments. [56] This polynomial commitment scheme is used both in Marlin and Plonk13.
Consider the bilinear groups from Section 2.1 with generators g1 ∈G1, and g2 ∈G2. To commit to a
polynomial p(X) ∈F[X] of degree d, do the following:
— PC.Setup(d) ∶Sample α ←$F and output pp ∶= (gα
1 ,...,gαd
1 , gα
2 ). The α is a trapdoor, which must
be discarded for security.
— PC.Commit(pp,p) ∶output com = gp(α)
1
, which can be computed as ∏d
i=0(gαi
1 )pi, where pi’s are the
coefficients of the polynomial p.
— PC.Prove(pp,p,x) ∶compute the quotient and remainder polynomials q(X) and r(X) correspond-
ing to the division (p(X) −p(x))/(X −x), and output π = gq(α)
1
, computed as ∏d
i=0(gαi
1 )qi where
qi’s are the coefficients of q(X). Note here, the remainder r(X) must be zero.
— PC.Check(pp,com,x,y,π) ∶outputs 1 if and only if e(π,gα
2 ⋅g−x
2 ) = e(com ⋅g−y
1 ,g2).
the PC.Eval protocol involves the prover running the PC.Prove procedure and the verifier accepting if and
only if PC.Check outputs 1. The security of the scheme holds from the fact that (p(X)−p(x)) is divisible
by X −x, thus making the remainder r(X) a zero polynomial, if and only if p(x) = y. The detailed security
analysis can be found in [56].
Note that, in the above KZG commitments, the underlying operations that the prover performs are:
— To generate the commitment, the prover needs to run the multi-scalar multiplication on inputs
p0,...,pd ∈F and g1,gα
1 ,...,gαd
1
∈G1 to get com.
13Extensions of this protocol are used in [28, 39] and our framework can be setup for these extensions as well, but for ease of
exposition, we explain the KZG scheme without these optimizations.
13

— To generate the proof, the prover needs to run the polynomial division to get quotient q(X) and
remainder r(X) on dividing p(X)−x by (X −x). Finally the proof π is generated by again invoking
the MSM function on q0,...,qd ∈F and g1,gα
1 ,...,gαd
1
∈G1.
Sumcheck Protocol.
Marlin relies heavily on what is known as a sumcheck protocol for univariate
polynomials. For a polynomial oracle p(X) ∈F[X] sent by the prover, this involves giving a proof of
the fact that evaluations of p(X) on the set S ∶= {1,ω,...,ωm−1}, sums to some value σ ∈F, where ω
is the m-th primitive root of unity in the field F. It was shown in [9] that ∑x∈S p(x) = σ, if and only if
p(X) can be written as q(X) ⋅X + σ/∣S∣, for some q(X) ∈F[X]. Thus, the prover in the polynomial-IOP
first evaluates the polynomial q(X) by dividing the polynomial p(X) −σ/∣S∣by X and sends q(X) as
an oracle. Hence, for running each sumcheck, the prover in Marlin invokes polynomial division before
committing to this polynomial using the polynomial commitment.
Partial Products.
In Plonk, the prover needs to compute (for reference, see round 2 of [39, Section
8.3]) partial products of the form ∏i∈[j] p(ωi−1) for all j ∈∣S∣, where p(X) ∈F[X] is some polynomial
(which in turn is some encoding of the witness), and S ∶= {1,ω,...,ωm−1}, where ω is the m-th primitive
root of unity in the field F. The prover uses this in computing the polynomial z(X) obtained by additional
polynomial multiplication and addition operations and sends it as an oracle in the polynomial-IOP protocol.
In the final Plonk protocol z is committed using the polynomial commitment.
4.1
Groth16, Marlin, and Plonk Provers
We now briefly describe how each of the three zk-SNARKs that we consider can be computed via some
combination of the above functions.
Groth [50].
Groth16 is the smallest, non-interactive zk-SNARK, where the prover only sends 3 group
elements to the verifier. This construction makes use of a structured CRS consisting of group elements
proportional to the number of constraints. To generate the proof, the prover needs to compute a polyomial
multiplication, polynomial division and a constant number of multi-scalar multiplications with the group
elements in the CRS. As a concrete example, we give a detailed description of this proof system in Section
A and explain in detail how one would compute this using our zkSaaS framework.
Marlin [28].
Marlin is a six round protocol, where overall, the prover generates the KZG polynomial
commitments of 21 polynomials, and requires the following operations, each called for a small constant
number of times: three sequential calls to the sumcheck protocol with each call additionally needing a
call to polynomial division, all involving polynomials with a degree bound of the size of the relation, and
polynomial additions. As a final step, this interactive protocol is converted to a SNARK using the Fiat-
Shamir transformation.
Plonk [39].
Plonk on the other hand is a five round protocol, where overall the prover generates the
KZG polynomial commitments of 9 polynomials, and requires the following operations, each called a small
constant number of times, to generate these polynomials: polynomial multiplication and division involving
polynomials with a degree bound of the size of the relation, partial products, and polynomial additions.
This interactive protocol is also converted to a SNARK in the RO model. As a concrete example, we give
a detailed description of this proof system in Section B and explain in detail how one would compute this
using our zkSaaS framework.
5
Distributed Sub-Protocols for the zkSaaS Framework
For each of the sub-functions (FFT, MSM, Sum of Partial Products) discussed in section 4, we build custom
MPC protocols. Looking ahead, we show how to compose these protocols, to design a zkSaaS for a specific
14

subclass of zk-SNARKs.
For our protocols in this section, we rely heavily on some standard sub-protocols, from the secret shar-
ing based-MPC literature. A description of these sub-protocols can be found in Section C. For readability,
we include here, a list of the ideal functionalities that these sub-protocols realize and that our custom pro-
tocols in this section invoke. frand (and fprand resp.) are used for generating secret shares (and packed
shares resp.) of random values (and vectors resp.). fdouble−prand is used for generating two packed sharings
of a random vector w.r.t., degrees D and n −1. fmult (and fpack−mult resp.) are used for multiplying secret
shares (and packed shares resp.) of random values (and vectors resp.). fpsstoss is used for transforming
packed shares to regular threshold shares. fsstopss can be used for transforming regular shares to packed
shares. Finally, fpermute is for permuting a set of pack secret shared vectors.
5.1
Distributed Protocol for Fast Fourier Transform
Before formally defining our distributed FFT protocol, we give an overview of our key technical ideas.
5.1.1
Overview of our Protocol
The fast Fourier transform (FFT) algorithm is a recursive divide-and-conquer algorithm that helps evaluate
a polynomial at multiple points efficiently. In particular, to evaluate a polynomial p(x) ∈F[X] of degree
m −1 at the points S = {ωi ∶i ∈[m]}, where ω is the m-th primitive root of unity in the field F, FFT does
the following: At level i = log m, each of the m polynomials will be evaluated at a single point, which is
the identity element in 1 ∈F. Subsequently, given the evaluations at level i (for any i ∈[log(m),1]), the
FFT algorithm gives us evaluations at the level i −1 in the following way: For each j ∈[2i−1], and each
k ∈[m/2i],
xi−1,k
j
∶= xi,k
2j−1 + ωk2i−1 ⋅xi,k
2j
&
xi−1,(m/2i)+k
j
∶= xi,k
2j−1 + ω((m/2i)+k)2i−1 ⋅xi,k
2j
At the end (i = 0), the algorithm outputs all the m evaluations of p at S. We represent the recursion by the
following function defined for each i = log m,...,1:
F i
FFT({xi,k
j }j∈[2i],k∈[m/2i]) ∶= {xi−1,k
j
}j∈[2i−1],k∈[m/2i−1],
(1)
Here, the input to F log m
FFT
are the values xj = xlog m,1
j
for each j ∈[m], representing the evaluations14
of each of the m polynomials of level i = log m at the single point 1. Note that F 1
FFT outputs the re-
quired evaluations {p(1),p(ω),...,p(ωm−1)}. Using this notation, the FFT algorithm can be written as
FFFT(x1,...,xm) = F 1
FFT(F 2
FFT(...F log m
FFT (x1,...,xm))).
An Alternate View of the FFT algorithm. Our goal is to compute FFFT via a secure MPC protocol.
Notice that FFT is a logarithmic step algorithm, while we want a constant round MPC protocol for com-
puting it. Towards designing such a protocol, we begin by making some key observations about FFT, and
abstracting the main idea behind our final MPC protocol. For ease of exposition, consider an example
where the input size is m = 32. We want to convert the linear function evaluation on each pair of values
(at each recursive level i), into a linear function evaluation on a pair of vectors (of say ℓ= 4 values) and be
able to recurse on these vectors. Looking ahead, this will help us to pack share these vectors together and
locally compute on them.
14 For p(X) = ∑i∈[m] ci−1xi−1, the xi’s are just a rearrangement of the ci’s, obtained by recursively reordering the ci’s as: put
the even indexed terms at each level on the left and the odd indexed terms on the right. Continue the recursion for log m steps.
15

1. FFT Step I: Since log m = log 32 = 5, the inputs to the FFT algorithm will be x5,1
1 ,...,x5,1
32 . The next level
i = 4 of the recursion is computed as: x4,1
j
= x5,1
2j−1+ω16⋅x5,1
2j and x4,2
j
= x5,1
2j−1+ω32⋅x5,1
2j , for each j ∈[16].
We now look at the same step as being computed on a vector instead of individual values. Suppose
we group ℓ= 4 elements to get the following 8 vectors at level i = 5: x5,1
1
= (x5,1
1 ,x5,1
3 ,x5,1
5 ,x5,1
7 ),
x5,1
2
= (x5,1
2 ,x5,1
4 ,x5,1
6 ,x5,1
8 ), ...,x5,1
8
= (x5,2
26 ,x5,2
28 ,x5,2
30 ,x5,2
32 ).
Observation I. The key observation here is that, each pair of vectors x5,1
2j and x5,1
2j−1 are used to compute
two vector evaluations x4,1
j
(which uses ω16) and x4,2
j
at the level i = 4 (which uses ω32), for each j ∈[4].
In other words:
∀j ∈[4], x4,1
j
= x5,1
2j + ω16 ⋅x5,1
2j−1 & x4,2
j
= x5,1
2j + ω32 ⋅x5,1
2j−1.
2. FFT Step II: We want to continue to compute on pairs of vectors linearly to obtain the next recursive
step i = 3. However, note that now x4,1
2j−1 and x4,1
2j do not contain the values that are linearly combined
in the next recursive step of FFT. For instance we have vectors x4,1
1
= (x4,1
1 ,x4,1
2 ,x4,1
3 ,x4,1
4 ) and x4,1
2
=
(x4,1
5 ,x4,1
6 ,x4,1
7 ,x4,1
8 ), while the values that we want to combine are x4,1
1
with x4,1
2 , and x4,1
3
with x4,1
4 .
Observation II. The key observation that we make to resolve this issue is that, if at level i = 5, we had
started with vectors: x5,1
1
= (x5,1
1 ,x5,1
5 ,x5,1
9 ,x5,1
13 ), x5,1
2
= (x5,1
2 ,x5,1
6 ,x5,1
10 ,x5,1
14 ), etc., then Step 1 would
have led to the vectors (at i = 4): x4,1
1
= (x4,1
1 ,x4,1
3 ,x4,1
5 ,x4,1
7 ), x4,1
2
= (x4,1
2 ,x4,1
4 ,x4,1
6 ,x4,1
8 ), etc. These
vectors x4,1
1
and x4,1
2
can now be combined using a linear combination, the same way as we did in step
1, to get x3,1
1
and x3,2
1
(and similarly others) of level i = 3. But, this reordering will only help us for this
level and we run into the same issue when computing the next level i = 2.
MPC for FFT. The key point from observations I and II above is that in order to continue doing the FFT
computations for each recursive level as a linear combination of vectors, instead of individual values, we
must take the initial vectors at level i = 5 to be such that the values x5,k
j ’s in the same vector have the j’s
as far away as possible– this ensures that we push our problem down to as far a recursive layer as possible.
However, even with the best ordering that we start with, we would reach a recursive level beyond which
we cannot hope to compute on the vectors through a linear combination. Our MPC protocol combines
the above key idea of packing the inputs into vectors such that local computations can be performed on
them for as long as possible, along with additional techniques to overcome the challenge in computing the
remaining recursive layers.
For m inputs, we start with a packed sharing of ℓ-sized vectors at level i = log m: xlog m,1
j
= (xlog m,1
j
,
xlog m,1
m
ℓ+j
,...,xlog m,1
m(ℓ−1)
ℓ
+j), for each j ∈[m/ℓ]. As discussed above, this allows us to locally compute on the
shares at each recursive layer (as in Steps 1 and 2) until level i = log ℓ+ 1, beyond which we cannot do a
local computation.
Beyond i = log ℓ: One approach that comes to mind is to rearrange the elements packed together (using
some interaction) in such a way that a similar local computation can be done. However, one can observe
that doing such a rearrangement actually leads to another problem– each pair of vectors are combined now
using a vector of the ωi’s (instead of a single one), which leads to an “interactive” multiplication protocol
at each level. This approach does give a feasible solution, but requires the parties to communicate at each
of the remaining log ℓlevels. Furthermore, the total communication in each round is O(m) which will
become a bottleneck when dealing with a large constraint size.
We minimize the number of communication rounds and give a more efficient solution than the above
by making use of our all powerful server and just two rounds of communication. On a high level, this
uses the fact that FFT (and each of its recursive layer) is a linear function, i.e.: F i
FFT((x1 + r1),...,(xm +
rm)) = F i
FFT(x1,...,xm)+F i
FFT(r1,...,rm). Suppose that the parties get packed shares of random values
16

(r1,...,rm) and packed shares of (s1,...,sm) generated as:
(s1,...,sm) = F 1
FFT(F 2
FFT(...F log ℓ
FFT (r1,...,rm)))
Then, the packed shares of the level i = log ℓare masked using the packed shares of (r1,...,rm) locally,
and sent to the powerful party P1. Now, P1 reconstructs, computes the remaining recursive levels of FFT
until i = 1, and sends the packed shares of the output to all parties. By virtue of linearity, the parties
can obtain packed shares of the FFT output by locally subtracting the packed shares of (s1,...,sm). This
securely reduces the communication rounds to two15.
We now present a detailed description of this protocol and show how to use the above protocol to
devise distributed protocols for inverse FFT, polynomial multiplication and polynomial division.
5.1.2
Our Protocol
Our goal is to compute FFFT in a distributed and secure way. Let ℓbe the packing constant. For each i ∈
[m/ℓ], let xi = (xi,x m
ℓ+i,...,x m(ℓ−1)
ℓ
+i). The ideal functionality fFFT from Figure 1 takes Jx1K,...,Jxm/ℓK
as input and computes the packed shares of the output of the FFT algorithm described above, i.e., the
evaluations of p on S. We now describe our complete protocol in Figure 2, and the ideal functionality that
this protocol realizes is described in Figure 1. This protocol requires parties to start with some correlated
randomness.
The functionality fFFT(FFFT)
The functionality fFFT, running with a set of parties {P1,...,Pn} and the ideal adversary Sim pro-
ceeds as follows:
— fFFT receives the set of corrupted parties, denoted Corr ⊂[n].
— fFFT receives shares Jx1K,...,Jxm/ℓK from all parties.
— For each j ∈[m/ℓ], fFFT receives from the adversary a set of shares {ui,j}i∈Corr.
— For each i ∈[m/ℓ], fFFT runs open(F,JxiK,t) to obtain (xi,x m
ℓ+i,...,x m(ℓ−1)
ℓ
+i).
— fFFT computes z1,...,zm = FFFT(x1,...,xm). For each j ∈[m/ℓ], let zj = (zi)i∈[(j−1)ℓ+1,jℓ].
— For each j ∈[m/ℓ], fFFT samples a random sharing of zj, such that the shares of the corrupted
parties are identical to those received from the adversary, i.e., {ui,j}i∈Corr.
— fFFT distributes the shares of z1,...,zm/ℓto the honest parties.
Figure 1: Ideal Functionality for Fast Fourier Transform
The protocol πFFT
Inputs: Every party Pi holds packed shares (Jx1K,...,Jxm/ℓK).
Pre-Processing: For each k ∈[m/ℓ], every party Pi holds packed shares ⟪maskk⟫and JunmaskkK.
Here maskk = {rk
1,...,rk
ℓ} are random vectors unknown to any party and unmaskk = {sk
1,...,sk
ℓ}
is computed as: {sk
1,...,sk
ℓ}k∈[m/ℓ] ∶= F 1
FFT(F 2
FFT(...F log ℓ
FFT ({rlog ℓ,k
j
}j∈[ℓ],k∈[m/ℓ]))), where rlog ℓ,k
j
∶=
15A curious reader might wonder why the linearity doesn’t help us use the powerful server to compute all the recursive levels.
For input size m (which is as large as the constraint size), this solution leads to a O(m log m) compute time for both the pre-
processing step and the server time, as opposed to our demand of O(m) compute time for both.
17

rk
j for each k ∈[m/ℓ], j ∈[ℓ] and the F i
FFT’s are as defined in equation 1.
Protocol: The parties (P1,...,Pn) proceed as follows:
1. Set Jxlog m,1
j
K ∶= JxjK for each j ∈[m/ℓ]. For each i ∈[log(m),log(ℓ)+1], j ∈[2i−1/ℓ], k ∈[m/2i],
all parties compute
Jxi−1,k
j
K = Jxi,k
2j−1K + ωk2i−1Jxi,k
2j K
Jxi−1,(m/2i)+k
j
K = Jxi,k
2j−1K + ω((m/2i)+k)2i−1Jxi,k
2j K
2. For each k ∈[m/ℓ], all parties compute ⟪ylog ℓ,k
1
⟫= Jxlog ℓ,k
1
K + ⟪maskk⟫and send them to P1.
3. For each k ∈[m/ℓ], P1 runs open(F,⟪ylog ℓ,k
1
⟫) to get (ylog ℓ,k
1
,...,ylog ℓ,k
ℓ
).
4. P1 computes {y0,k
1 }k∈[m] ∶= F 1
FFT(F 2
FFT(...F log ℓ
FFT ({ylog ℓ,k
j
}j∈[ℓ],k∈[m/ℓ]))).
5. For each j ∈[m/ℓ], let zj = (y0,k
1 )k∈[(j−1)ℓ+1,jℓ]. P1 computes JzjK ←pshare(F,zj,t) and sends
JzjKi to party Pi (for each i ∈[2,n]).
6. For each j ∈[m/ℓ], parties compute JoutjK = JzjK −JunmaskjK.
Output: Each party Pi outputs {JoutjKi}j∈[m/ℓ].
Figure 2: Distributed Protocol for Fast Fourier Transform
Lemma 1. Protocol πFFT securely computes functionality fFFT (c.f. figure 1) against a semi-honest adversary
who corrupts at most t parties.
Proof. Correctness. The correctness of the protocol follows directly from the discussion in the protocol
overview and the fact that every recursive step, F i
FFT, of the FFT protocol is a linear function.
Security Proof. Let Corr ⊂[n], with ∣Corr∣= t, be the set of corrupted parties. We show how to simulate the
view of Corr in the ideal world, given the input shares (Jx1KCorr,...,Jxm/ℓKCorr) of the corrupted parties.
The simulator S does the following:
— For
the
pre-processing,
S
samples
the
random
vectors
{maskk}k∈[m/ℓ],
and
computes
{unmaskk}k∈[m/ℓ] ∶= F 1
FFT(F 2
FFT(...F log ℓ
FFT ({maskk}k∈[m/ℓ]))), as in the main protocol.
Then, S
generates the shares ⟪mask1⟫Corr, ..., ⟪maskk⟫Corr,Junmask1KCorr,...,JunmaskkKCorr, corresponding
to the corrupted parties.
— For Steps 1 and 2, S sets Jxlog m,1
j
KCorr ∶= JxjKCorr for each j ∈[m/ℓ] and locally computes: first, the
recursive steps to get Jxlog ℓ,k
1
KCorr, for each k ∈[m/ℓ]; second, adds ⟪maskk⟫Corr to get ⟪ylog ℓ,k
1
⟫Corr
for each k ∈[m/ℓ].
— For Steps 3,4 and 5, S first generates (ylog ℓ,k
1
,...,ylog ℓ,k
ℓ
) for each k ∈[m/ℓ] at random, then computes
{y0,k
1 }k∈[m] ∶= F 1
FFT(F 2
FFT(...F log ℓ
FFT ({ylog ℓ,k
j
}j∈[ℓ],k∈[m/ℓ]))), as in the actual protocol and sets zj ∶=
(y0,k
1 )k∈[(j−1)ℓ+1,jℓ] for each j ∈[m/ℓ]. Note that these intermediate values can be used when P1 ∈Corr.
Then, S generates Jz1KCorr,...,Jzm/ℓKCorr. This can be done as the ylog ℓ,k
j
’s look random to Corr, by
the security of packed secret sharing.
— Finally, S computes the output shares of Corr as JoutjKCorr ∶= JzjKCorr −JunmaskjKCorr for each j ∈
[m/ℓ].
18

Note here that for each step, by security of the corresponding packed secret sharing scheme (wher-
ever mentioned) and as the random maskj’s are hidden from all parties, S generates a distribu-
tion that is identical to the views of Corr in the real world.
Hence, the ideal world distribution
IDEALfFFT,Corr,S(1λ,(Jx1K,... , Jxm/ℓK)), corresponding the functionality fFFT is identical to the real
world distribution REALπFFT,Corr,A(1λ, (Jx1K,...,Jxm/ℓK)).
Sub-protocols relying on FFT. We require three distributed sub-protocols: for iFFT, polynomial multi-
plication and polynomial division as described below.
— Inverse FFT (iFFT): The protocol πIFFT is required to convert the packed shares of the evaluation repre-
sentation of a polynomial back to its coefficient representation. πIFFT on input Jx1K,...,Jxm/ℓK, runs
fFFT(FIFFT) on these inputs (i.e. replaces the use of FFFT with FIFFT), where FIFFT(x1,...,xm)
does the following: first, runs FFFT on (x1,...,xm) using ω−1 (inverse in F) in place of ω, to get
(z1,...,zm); second, outputs −m′ ⋅(z1,...,zm), where m′ is such that m ⋅m′ = ∣F∣−1.
— Polynomial Multiplication: The protocol πpolymult is used to multiply p1(X),p2(X) ∈F[X], of de-
grees m1 and m2 respectively (such that m1 + m2 < ∣F∣−1), given the packed shares of their coef-
ficients as input. It does the following: first, use fFFT(FFFT) to convert and obtain packed shares
(Jx1K,...,JxmK) and (Jy1K,...,JymK) of evaluations of p1(x) and p2(x), respectively, at m-points,
where m is a divisor of ∣F∣−1, such that m > m1 +m2; second, run fpack−mult, m times to get packed
shares of (Jx1 ⊙y1K,...,Jxm ⊙ymK); finally run fFFT(FIFFT) on these packed shares to get the
packed shares of coefficients of p1(X)⋅p2(X). Let the ideal functionality corresponding to polyno-
mial multiplication be denoted by fpoly−mult.
— Polynomial Division: This protocol πpolydivide takes as input the packed shares of coefficients of
p1(X) ∈F[X] (of degree m1), a public polynomial (known to all parties) p2(X) ∈F[X] (of de-
gree m2 < m1), and outputs the packed shares of q(X) (with m1 −m2 coefficients) and r(X) (with
m2 −1 coefficients), such that p1(X) = p2(X)q(X) + r(X). The computation of the packed shares
q(X) and r(X) can essentially be done by two sequential invocations of the polynomial multipli-
cation functionality fpoly−mult. Let the ideal functionality corresponding to a polynomial division be
denoted by fpoly−divide.
Complexity of our distributed FFT. Our protocol runs in two rounds, where in the first round each
party communicates O(m/ℓ) field elements and in the second round, party P1 communicates O(m/ℓ)
field elements to each of the remaining parties. P1 does O((log ℓ+ log n)m + m(log m −log ℓ)/ℓ) field
operations and has a space complexity of O(m). The remaining parties perform O(m(log m −log ℓ)/ℓ)
field operations and require O(m/ℓ) space.
5.2
Distributed Protocol for Partial Products
Before we formally define our distributed protocol for partial products, we give an on overview of our key
ideas.
5.2.1
Overview of our Protocol
We want to securely compute functions of the form Fpart(x1,...,xm) = (∏j∈[i] xj)i∈[m], in a distributed
way. When computing on a single machine, this function requires computing the x[1,i] ∶= x1⋯xi values for
each i ∈[m] in a sequential order. Simply implementing this approach inside an MPC protocol will require
O(m) rounds. Moreover, since each step only requires multiplying two values at a time (i.e., x[1,i−1] and
xi), it is unclear how to leverage packed sharing to get a division of work amongst the parties.
19

Our goal is to design a computation mechanism that is more amenable to parallelism and where we
can meaningfully use an approach based on packed secret sharing.
The key idea to achieve this comes from rewriting Fpart in the following way: Fpart(xi,...,xj) =
(xi,x[i,i+1],...,x[i,j]) = (Fpart(x (i−1)m
ℓ
+1, ...,x im
ℓ)⋅x[1, (i−1)m
ℓ
])i∈[ℓ]. Observe that the Fpart(x (i−1)m
ℓ
+1,...,
x im
ℓ)’s depend on disjoint subsets of the input xi’s. Thus, they can all be computed in parallel. In fact,
since each of these Fpart(x (i−1)m
ℓ
+1,...,x im
ℓ) are computed identically, albeit on a different set of inputs,
this is exactly the kind of SIMD computation for which packed secret sharing is most helpful.
MPC for Fpart. We start with a packed secret sharing of vectors x1,...,xm/ℓ, where xj is an ℓ-sized vector
consisting of the jth inputs i.e., xj = (xj,x m
ℓ+j,...,x m(ℓ−1)
ℓ
+j), for each j ∈[m/ℓ]. We now compute
Fpart(Jx1K,...,Jxm/ℓK) to obtain packed shares of (yj = (x[ (i−1)m
ℓ
+1, (i−1)m
ℓ
+j])i∈[ℓ])j∈[m/ℓ] using known
techniques with O(m) total computation and communication.
A careful reader might have observed that while the above idea allows us to compute {yj}j∈[m/ℓ]
simultaneously, doing this na¨ıvely will still require O(m/ℓ) rounds. To avoid this, we observe that a
slightly modified version of Bar-Ilan and Beaver’s [5] constant-round MPC for unbounded multiplication
can be used to compute this in a constant number of rounds.16 We defer more details about this protocol
and the modification to the technical sections.
Finally, to compute Fpart(x1,...,xm), given the packed secret sharings of {yj}j∈[m/ℓ] from the previ-
ous step, we note that while computing these packed shares of {yj}j∈[m/ℓ], the parties also inevitably end
up computing a packed secret sharing of the vector z = (x[1,m/ℓ],x[ m
ℓ+1, 2m
ℓ],...,x[ m(ℓ−1)
ℓ
,m]).
Given {JyjK}j∈[m/ℓ] and JzK, our final step computes the shares of desired output:
1. Convert a packed sharing of z into regular threshold shares of the individual elements in z, i.e.,
[x[1,m/ℓ]], ...,[x[ m(ℓ−1)
ℓ
,m]].
2. Use the above modified version of Bar-Ilan and Beaver’s protocol on these shares to compute shares
[x[1,m/ℓ]],[x[1,2m/ℓ]]...,[x[1,m]].
3. Finally, for each j ∈[m/ℓ], compute an inner product between JyjK and packed shares of vector
(1,x[1,m/ℓ],x[1,2m/ℓ], ...,x[1, m(ℓ−1)
ℓ
]).
5.2.2
Our Protocol
In this section, we formally describe our MPC protocol to compute Fpart. Let ℓbe the packed secret shar-
ing constant. We assume the parties have packed secret sharings of the following vectors: Let k = m/ℓ.
For each i ∈[k], xi = (xi,x m
ℓ+i,...,x m(ℓ−1)
ℓ
+i). We describe the ideal functionality fpart−product in fig-
ure 3 which computes the shares of the required partial product of (x1,⋯,xm), when the packed shares
Jx1K,...,JxkK are given as input. Our complete protocol is described in figure 4.
The functionality fpart−product
The functionality fpart−product, running with a set of parties {P1,...,Pn} and the ideal adversary Sim
proceeds as follows:
16We note that this protocol crucially relies on the fact that none of the values being multiplied are zero. Which is indeed the
case (w.h.p.) for our use-case in Plonk.
20

— fpart−product receives the set of corrupted parties, denoted Corr ⊂[n].
— fpart−product receives shares Jx1K,...,JxkK from all parties.
— fpart−product receives from the adversary a set of shares {ui}i∈Corr.
— For each j ∈[k], fpart−product runs open(F,JxjK,D) to obtain (xj,x m
ℓ+j,...,x m(ℓ−1)
ℓ
+j).
— fpart−product computes (z1,...,zm) ∶= (∏i∈[j] xi)j∈[m].
For each j
∈[m/ℓ], let zj
=
(zj,z m
ℓ+j,..., z m(ℓ−1)
ℓ
+j).
— fpart−product samples a random sharing of zj, such that the shares of the corrupted parties are
identical to those received from the adversary, i.e., {ui,j}i∈Corr.
— fpart−product distributes the shares of z1,...,zm/ℓto the honest parties.
Figure 3: Ideal Functionality for Partial Products
The protocol πpart−prod
Inputs: Every party Pi holds packed shares of the values to be multiplied (Jx1K,...,JxkK).
Protocol: The parties (P1,...,Pn) proceed as follows:
1. Invoke fprand 2k times to receive (Js1K,...,JskK,Jw1K,...,JwkK).
2. Computing Inverse: For each j ∈[k]
— Run fpack−mult(F,JsjK,JwjK) to receive JvjK, where vj = sj ⊙wj and send JvjK to P1.
— P1 runs open(F,JvjK,D) to obtain vj and sends vj to all other parties.
— Compute Js−1
j K = v−1
j ⊙JwjK.
3. Compute JyjK where yj = xj ⊙maskj by computing the following for all j ∈[k]
— Run fpack−mult(F,JsjK,JxjK), to receive Jxj ⊙sjK.
— Run fpack−mult(F,Jxj ⊙sjK,Js−1
j K) to receive JyjK and send JyjK to P1.
— P1 runs open(F,JyjK,D) to obtain yj.
4. For each j ∈[k], P1 computes y[1,j] = y1 ⊙... ⊙yj. Then run fpack−mult(F,Js−1
1 K,y[1,j]) to
receive Js−1
1 ⊙y[1,j]K and finally run fpack−mult(F,Js−1
1 ⊙y[1,j]K,Jsj+1K) to receive Jz[1,j]K.
5. Run fpsstoss(F,Jz1,kK) to get [h1],...,[hℓ].
6. Invoke frand 2ℓ+ 2 times to receive ([s1],...,[sℓ+1],[w1],...,[wℓ+1]).
7. Computing Inverse: For each j ∈[ℓ+ 1]
— Run fmult(F,[sj],[wj]) to receive [vj], where vj = sj ⋅wj and send [vj] to P1.
— P1 runs open(F,[vj],t) to receive vj and sends vj to all other parties.
— Compute [s−1
j ] = v−1
j [wj].
21

8. Compute [yj] where yj = sj ⋅hj ⋅s−1
j+1 by computing the following for all j ∈[ℓ]
— Run fmult(F,[sj],[hj]), to receive [hj ⋅sj].
— Run fmult(F,[hj ⋅sj],[s−1
j+1]) to receive [yj] and send [yj] to P1.
— P1 runs open(F,[yj],t) to receive yj and sends yj to all other parties.
9. For each j ∈[ℓ] compute y[1,j] = y1 ⋅... ⋅yj. Then run fmult(F,[s−1
1 ⋅y1,...,j],[sj+1]) to receive
[q[1,j]].
10. Run fsstopss(F,[1],[q[1,1]],...,[q[1,ℓ−1]]) to get JQK.
11. For each j ∈[k], run fpack−mult(F,Jz[1,j]K,JQK) to obtain JoutjK.
Output: Each party Pi outputs {JoutjKi}j∈[k].
Figure 4: Distributed Protocol for Computing Partial Products
Lemma 2. Protocol πpart−prod securely computes functionality fpart−product (c.f.
figure 3) in the
fprand,fpack−mult, frand,fmult,fpsstoss,fsstopss-hybrid model against a semi-honest adversary who corrupts
at most t parties.
Proof. Correctness. The correctness of the protocol follows directly from the correctness of the underlying
functionalities, fprand,fpack−mult,frand,fmult,fpsstoss,fsstopss and the discussion in the protocol overview.
Security Proof. The security of this protocol only holds when xj ≠0, for all j ∈[m], except with a negligible
probability.17 Let Corr ⊂[n], with ∣Corr∣= t, be the set of corrupted parties. We show how to simulate the
view of Corr in the ideal world, given the input shares (Jx1KCorr,...,JxkKCorr) of the corrupted parties.
The simulator S does the following:
— For Step 1, the parties run 2k + 2 invocations of the ideal functionality fprand, while S sam-
ples vectors of random values s1,...,sk+1,w1,...,wk+1 to generate the packed shares and get
Js1KCorr,...,Jsk+1KCorr, Jw1KCorr,...,Jwk+1KCorr, corresponding to the corrupted parties.
— For Step 2, the parties run the ideal functionality fpack−mult. S can generate vj = sj ⊙wj, for each
j ∈[k + 1], generate the s−1
j ’s, and get Js−1
1 KCorr,...,Js−1
k+1KCorr.
— For Step 3, the parties call the fpack−mult-functionality twice. S can just set the shares of outputs for
each of these calls as shares of some random vectors (by security of the packed secret sharing) and
picks yj at random for each j ∈[k] (since the sj’s look random to Corr, the yj’s also look random to
Corr. This is true only because the xj’s are all non-zero!).
— For Step 4, for each j ∈[k], S can generate y[1,j] = y1 ⊙... ⊙yj, compute s−1
1 ⊙y[1,j] and z[1,j] =
s−1
1 ⊙y[1,j] ⊙sj+1, and get Js−1
1 ⊙y[1,j]KCorr and Jz[1,j]KCorr.
— For Step 5, S can output [h1]Corr,[hℓ]Corr, as shares of random values (by security of secret sharing).
— For Steps 6-9, S does exactly the same thing as it did for Steps 1-4, except for replacing the role of
packed shares with regular shares, and the parties invoke the corresponding functionalities on regular
shares.
17Looking ahead at our application of this protocol, we use this sub-protocol only for inputs that are all non-zero w.h.p.
22

— Finally, for Steps 10 and 11, S sets JQKCorr and the final output shares of Corr, JoutjKCorr for each j ∈[k],
to be shares of random values (by security of packed secret sharing).
Note here that for each step, by the security of the secret sharing and packed secret sharing schemes (wher-
ever mentioned) and since the yj’s look random to Corr (under our assumption that the xj’s are all non-zero
w.h.p.), S generates a distribution that is identical to the views of Corr in the real world, assuming that the
xj’s are all non-zero. Hence, the ideal world distribution IDEALfpart−product,Corr,S(1λ,(Jx1K,...,JxkK)), cor-
responding the functionality fpart−product is statistically close to REALπpart−prod,Corr,A(1λ,(Jx1K,...,JxkK)),
where the parties are all given access to the ideal functionality fpack−mult.
Complexity of our distributed Partial Products Protocol.
Our protocol runs in constant rounds,
where each of the small servers communicates O(m/ℓ) field elements. They perform O(m/ℓ) field op-
erations and require a space complexity of O(m/ℓ). While the big server, P1 has a space complexity of
O(m) and performs O(m) field operations and communicates O(m) field elements. This is because of the
sub-protocol that we adapt from Bar-Ilan and Beaver’s [5] constant-round MPC for unbounded multipli-
cation. Since our distributed FFT protocol already assumes that one of the servers has more memory and
computational resources, this is the version we use in our implementation of Plonk. However, in Section
D we present an alternate protocol for distributed computation of partial products, where the total work
gets equally divided amongst all parties. In particular, each server in that protocol requires O(m/ℓ) field
operations, a space complexity of O(m/ℓ), and each server communicates O(m/ℓ+ n) field elements. We
note however, that unlike all of our other protocols (where the weak servers only need to communicate
with the client and the large server), that protocol requires point-to-point communication between every
pair of servers.
5.3
Distributed Protocol for Multi-Scalar Multiplications
Before we formally describe our distributed protocol for multi-scalar multiplication protocol, we give an
overview of our key ideas.
5.3.1
Overview of our Protocol
Polynomial-based secret sharing schemes typically only support arithmetic operations over a finite field.
Several zk-SNARKs perform many elliptic curve group operations, such as multiplying group elements or
group exponentiations. Representing these group operations as an arithmetic circuit over a finite field and
computing it inside an MPC protocol is not feasible.
Prior works [73, 64] have explored generalizations of polynomial-based secret sharing schemes for
group operations. Let G be a group of order p, with generator g, such that each element A ∈G can be
represented as ga, where a ∈Zp. The main idea in these works is to first compute secret shares (say
s1,...,sn) of the field element a, and then compute the shares of A as gs1,...,gsn. This allows us to
perform arithmetic field operations in the exponent which can be used for group exponentiation and for
multiplying group elements.
— Addition in the exponent. Given packed secret shares of another vector B = (B1,...,Bℓ) ∈Gℓ, each
party Pi can locally multiply their shares JAKi ⋅JBKi, to get a valid packed secret sharing of C =
(A1 ⋅B1,...,Aℓ⋅Bℓ).
— Multiplication in the exponent. Given packed secret shares of another vector of field elements b =
(b1,...,bℓ) ∈Zℓ
p, each party Pi can locally compute JAKJbKi
i
to get a packed secret sharing of C =
(Ab1
1 ,...,Abℓ
ℓ). However, in this case, since the shares of a and b get multiplied in the exponent, the
23

degree of the resulting sharing will be twice that of the original sharings. To reduce the degree, we can
use the standard ideas for degree reduction, albeit in the exponent.
MPC for MSM.
Given the above observations,
our idea for computing multi-scalar mul-
tiplications
of
the
form
FMSM(A1,b1 ...,Am,bm)
=
∏i∈[m] Abi
i
is
to
first
observe
that
this decomposes as is quite intuitive.
Observe,
this computation can be decomposed as:
∏i∈[ℓ] (FMSM(Ai,bi,Aℓ+i,bℓ+i,...,A( m
ℓ−1)ℓ+i,b( m
ℓ−1)ℓ+i)).
This is essentially equivalent to com-
puting ℓinstances of FMSM in parallel and then multiplying the ℓoutputs. We compute this using PSS as
follows:
1. Assuming that the parties have packed secret shares of vectors Aj = (A(j−1)ℓ+i)i∈[ℓ] and bj =
(b(j−1)ℓ+i)i∈[ℓ] for each j ∈[m/ℓ], the parties compute FMSM function on these packed shares to get
packed shares of a vector C.
2. Convert JCK to regular threshold shares [C1],...,[Cℓ] of the individual elements in C.
3. Finally, the parties locally multiply these shares to get a sharing of the desired output.
5.3.2
Our Protocol
In this section, we formally describe our MPC protocol to compute the multi-scalar multiplication, FMSM.
Let ℓbe the packed secret sharing constant. We assume that the parties have packed secret shares of the fol-
lowing vectors: Let k = m/ℓ. For each i ∈[k] yi = (y(i−1)ℓ+1,...,yiℓ) and Xi = (X(i−1)ℓ+1,...,Xiℓ). We
describe the ideal functionality fMSM in Figure 5, which computes the shares of the required multi-scalar
multiplication of (y1,...,ym) and (X1,...,Xm), given the input (Jy1K,...,JykK),(JX1K,...,JXkK).
Our complete protocol is described in Figure 6.
The functionality fMSM
The functionality fMSM, running with a set of parties {P1,...,Pn} and the ideal adversary Sim pro-
ceeds as follows:
— fMSM receives the set of corrupted parties, denoted Corr ⊂[n].
— fMSM receives shares (Jy1K,...,JykK),(JX1K,...,JXkK) from all parties.
— fMSM receives from the adversary a set of shares {ui}i∈Corr.
— For each j
∈
[k],
fMSM runs open(F,JXjK,t) to obtain (X(i−1)ℓ+1,...,Xiℓ) and
open(F,JyjK,t) to obtain (y(i−1)ℓ+1,...,yiℓ).
— fMSM computes out = ∏j∈[m](Xj)yj.
— fMSM samples a random sharing of out, such that the shares of the corrupted parties are identical
to those received from the adversary, i.e., {ui}i∈Corr.
— fMSM distributes the shares of out to the honest parties.
Figure 5: Ideal Functionality for Multi-Scalar Multiplications
24

The protocol πMSM
Inputs: Every party Pi holds shares of the values Jy1K,...,JykK),JX1K,...,JXkK).
Protocol: The parties (P1,...,Pn) proceed as follows:
1. Parties run fdouble−prand to receive (JrK,⟪r⟫).
2. Parties run fpsstoss(F,JrK) to receive [r1],...,[rℓ].
3. Each party Pi computes ⟪C⟫i = ∏j∈[k] JXjK
JyjKi
i
.
4. Each party Pi computes ⟪D⟫i = ⟪C⟫i ⋅g⟪r⟫i.
5. Each party Pi sends ⟪D⟫i to P1.
6. P1 runs open(F,⟪D⟫,n −1) to receive D = (D1,...,Dℓ).
7. P1 computes E = ∏j∈[ℓ] Dj and sends E to all other parties.
8. Parties compute [out] =
E
∏j∈[ℓ] g[rj]
Output: Each party Pi outputs [out]i.
Figure 6: Multi-Scalar Multiplications
Lemma 3. Protocol πMSM securely computes functionality fMSM (c.f. figure 5) in the fdouble−prand,fpsstoss-
hybrid model against a semi-honest adversary who corrupts at most t parties.
Proof. Correctness. The correctness of the protocol follows directly from the correctness of the underlying
functionalities fdouble−prand,fpsstoss and from the discussion in the protocol overview.
Security Proof. Let Corr ⊂[n], with ∣Corr∣= t, be the set of corrupted parties. We show how to simulate the
view of Corr in the ideal world, given the input shares (Jy1KCorr,...,JykKCorr),(JX1KCorr,...,JXkKCorr)
of the corrupted parties. The simulator S does the following:
— For Steps 1 and 2, S picks a random vector r = (r1,...,rℓ) and generates the shares to get
JrKCorr,⟪r⟫Corr and [r1]Corr,...,[rℓ]Corr.
— For Steps 3 and 4, S does local computations on (Jy1KCorr,...,JykKCorr), (JX1KCorr,...,JXkKCorr) and
⟪r⟫Corr, to generate ⟪D⟫Corr.
— For Steps 6 and 7, S can pick D at random (each component picked as a random group element), which
is directly needed if P1 ∈Corr, and evaluate E = ∏j∈[ℓ] Dj. This can be done as the vector D looks
random to Corr by the security of packed secret sharing.
— Finally, the output shares of Corr are evaluated as [out]Corr ∶= E/g∑j∈[ℓ][rj]Corr.
Note here that for each step, by security of the corresponding packed secret sharing scheme (wherever
mentioned) and as the random r is hidden from all parties, S generates a distribution that is identical to the
views of Corr in the real world. Hence, the ideal world distribution IDEALfMSM,Corr,S(1λ,((Jy1K,...,JykK),
(JX1K,...,JXkK)), corresponding the functionality fMSM is identical to the real world distribution
REALπMSM,Corr,A(1λ,((Jy1K,...,JykK),(JX1K,...,JXkK)).
25

Complexity of distributed MSM. Our protocol runs in constant rounds, where each party communicates
O(1) group elements. All parties perform O(m/ℓ) group exponentiations and have a space complexity of
O(m/ℓ).
6
zkSaaS for Admissible zk-SNARKs
In this section, we formally define a notion of admissible zk-SNARKs and show that our techniques from
Section 5 can be used to obtain a zkSaaS for them.
Admissible zk-SNARKs. We start by formalizing a class of zk-SNARKs that are amenable to our zkSaaS
framework and refer to them as admissible zk-SNARKs. Informally speaking, we say that a zk-SNARK
with computation complexity Tfield + Tcrypto is admissible if the prover algorithm is composed of some
combination of a subset or all of the following six types of operations on the satisfying assingment z for
the RICS relation R — (1) multi-scalar multiplications (MSMs), (2) Fast Fourier Transforms (FFT), (3) sum
of partial-products, (4) multiplication/Hadamard product, (5) additions and (6) permutations.
To formally capture this, our initial idea is to say that the prover algorithm in admissible zk-SNARKs
can be represented as a polynomial-sized circuit consisting of special gates with “multi-ary” inputs and
outputs, where each of these special gates correspond to one of the above six operations. However, this
is alone is not sufficient. To capture the efficiency requirements of a zkSaaS (as discussed in Section 3),
we need to further restrict the number of times a particular gate with a certain ari-ty can appear in this
circuit.
Indeed, consider for instance a circuit, where two-input multiplication gates appear O(Tfield) times
in the circuit. Since the only distributed protocol that we can use for evaluating such gates is πmult (c.f.
Figure 20), which requires a total communication and computation of O(n), the total communication and
computation incurred in evaluating O(Tfield) such gates would be O(n.Tfield). This clearly violates the
efficiency requirement of zkSaaS. Therefore, we must limit the number of such gates with low-ary inputs
that appear in this circuit to ensure that the cost of computing them does not surpass the asymptotic bound
that we have on the total computation complexity of zkSaaS. More concretely, in order to use our packed
secret sharing based sub-protocols, we must limit the number of gates with o(n) inputs. Hence, we define
the notion of admissibility w.r.t. the number of parties n. This is formalized in Definition 3.
Definition 3 (n-Admissible zk-SNARKs). Let λ be the security parameter, R ∈Rλ be an NP-relation
and Σ = (Setup,Prove,Ver,Sim) be a zk-SNARK for R. We say that Σ is n admissible if n < Tfield,
n < Tcrypto and the Prove algorithm can be represented as a circuit C comprising of gates implementing
the following functionalities:
Multi-Scalar Multiplication: FMSM(y1,...,ym,X1,...,Xm) = ∏j∈[m](Xj)yj.
Fast Fourier Transform: FFFT(x1,...,xm) = F 1
FFT(F 2
FFT(...F log m
FFT (x1,...,xm))), where each F i
FFT
is the recursive function described in equation 1.
Sum of Partial Products: Fpart−prod(x1,...,xm) = ∑j∈[m] ∏i∈[j] xi.
Multiplication/Hadamard Product: Fprod(x1,...,xm,y1,...,ym) = (x1 ⋅y1),...,(xm ⋅ym).
Addition: Fsum(x1,...,xm,y1,...,ym) = (x1 + y1),...,(xm + ym).
Permutation: Fperm(x1,...,xm) ∶= (xperm(1),...,xperm(m)), where perm is a permutation function on
[m].
Furthermore, the total number of MSM gates with m ∈o(n) inputs is limited to O(Tcrypto/n)
26

and all other types of gates m ∈o(n) inputs are limited to O(Tcrypto/n).
We now present our main composition theorem and show that the three zk-SNARKs that we discussed
in Section 4.1 are admissible.
Theorem 1. Let λ be the security parameter, R ∈Rλ be an NP-relation and Σ = (Setup,Prove,Ver,Sim)
be an n-admissible zk-SNARK for relation R. Then, there exists a secure n-server zkSaaS Π for Σ, which
securely computes Prove in the fdouble−prand,fprand,fpack−mult,frand,fpsstoss,fmult,fsstopss, fpart−product,
fpoly−mult,fpoly−divide, fFFT,fMSM,fpermute-hybrid model18.
Proof of Theorem 1. As defined in Defintion 3, the Prove function/algorithm in Σ only comprises of the fol-
lowing functionalities: FFT, MSM, sum of partial products, multiplication/hadamard product, addition and
permutation. It is easy to see that for computing such a function, we can design a non-interactive MPC pro-
tocol Π where the parties only make oracle access to the ideal functionalities fdouble−prand,fprand,fpack−mult,
frand,fmult,fpsstoss,fsstopss,fFFT,fMSM,fpermute,fpart−product,fpoly−mult,fpoly−divide, besides performing
local operations on the shares of the input (which in this case is a sharing of the satisfying assignment
z for the RICS representation of the relation). The security of this protocol follows trivially.
Efficiency: Each of these ideal functionalities can be realized using the sub-protocols described in Sec-
tions 5 and C. Recall that for computing field operation based functions where the number of inputs are
limited to m ∈o(n), we cannot leverage packed secret sharing to get computational savings and based on
current techniques, such functions must inevitably be computed with a total computation of O(n). Since
the number of gates with m ∈o(n)-inputs is limited to ˜O(Tfield/n), the total computation required for
computing these gates is at most ˜O(Tfield). The same argument extends to MSM gates with fewer inputs.
For all the remaining gates, we can use our packed secret sharing based subprotocols that allow division
of work amongst the servers and comply with the efficiency requirements of our zkSaaS framework.
Instantiation.
We note that, as discussed in Section 4.1, the provers of Groth16 [50], Marlin [28] and
Plonk [39] only call the functionalities listed in defintion 3. Furthermore, the number of gates with o(n)-
inputs in each of these is at most a constant number. Hence, using Theorem 1 we can directly get a
zkSaaS for Groth16, Marlin and Plonk. Note here that Marlin and Plonk are described as interactive
protocols, but as mentioned in Section 4.1 they can be converted to non-interactive protocols in the random
oracle model, by using the Fiat-Shamir transformation. Specifically, this would require the prover to make
random oracle queries on parts of the transcript– in our zkSaaS this translates to each party reconstructing
shares of the transcript, to make these random oracle queries locally. The protocol clearly remains zero-
knowledge.
7
Implementation and Evaluation
To evaluate the concrete performance of our techniques, we implemented a proof-of-concept zkSaaS
framework supporting Groth16 [50] and Plonk [39] (the protocol described in Section A and B) in Rust. We
use the arkworks [3] library for finite field, pairing-friendly curves and, FFT implementations and the
mpc-net crate from the collaborative-snarks implementation [2] to facilitate communication between
parties. Our code is available on Github.19 All of our experiments are run on the Google Cloud Platform
(GCP) using two types of machines – all servers with low memory requirements are custom N1 instances
with 1 vCPU and 2GB of memory, while the powerful server is a custom N1 instance with 96 vCPUs and
128 GB of RAM.
18A formal description of these ideal functionalities can be found in Sections 5 and C.
19https://github.com/guruvamsi-policharla/zksaas
27

We compare the performance of our zkSaaS protocol against a prover running locally on an N1 instance
with 1 vCPUs and 4 GB of RAM, emulating a mid tier consumer laptop and hence refer to this as the
consumer machine. Our VM configuration choices aim to reflect realistic deployment scenarios for zkSaaS,
where one powerful instance is hired to aid many weak — volunteer-run nodes, often on outdated and
older hardware. Throughout the analysis when the zkSaaS protocol is run with n parties, the corruption
threshold is set to be t = n/4 −1 and the number of secrets packed together to be ℓ= n/4. All numbers
reported are the average of five trials.
We view our implementation as a proof-of-concept to estimate running times and network delays and
do not implement multi-threading on the powerful server. In a production-level implementation, we expect
the powerful server to use multi-threading in the FFT protocol which includes packing/opening shares
and communicating with parties. The data we present takes this into account by dividing the time taken
during computation by the number of threads on the server and the time spent during communication by
min(n,# of threads). Finally, we implement a variant of our distributed partial products protocol which
avoids all-to-all communication but the king party does linear work. This does not affect our speedup as
we assume the king is multi-threaded and simplifies the communication to a star like structure.
Pre-processing.
Our goal is to analyze the online work carried out by the servers. In both the single
prover baseline and the zkSaaS protocol, we do not benchmark the time taken to prepare the witness,
since we assume this is given to the zkSaaS servers by the clients. We do not evaluate pre-processing as it
can be carried out during periods of low demand when spare compute and bandwidth are available. Prior
work [64] also omits this analysis.
Evaluation. We now evaluate the performance of our zkSaaS framework against a prover running locally
on a consumer machine for Groth16 and Plonk. In particular, we aim to answer three main questions: (1)
How does the performance of zkSaaS compare to a Groth16/Plonk prover running on a single consumer
machine? We are interested in two main metrics — (a) the largest number of constraints that can be
supported without memory exhaustion and (b) the time required to generate the proof. (2) Does the per-
formance of zkSaaS improve as we increase the number of servers? (3) How does the performance of
zkSaaS vary with network bandwidth?
Varying Constraints. For our first experiment, we run benchmarks on a high speed network (4Gbps).
We compare the running time of zkSaaS with 128 parties against a local execution of Groth16/Plonk prover
on a single consumer machine, by varying the number of constraints. We summarize our results in Figure
7.
The performance of our zkSaaS for larger constraints is approximately 22× better better than the
consumer machine. Here, we incur a loss from the theoretically expected savings of 32× due to a few
factors:
— Pippenger’s algorithm [67] provides a way to compute a multi-scalar multiplication ΠN
i=1gαi
i
using
O(N/log N) group operations as opposed to O(N) in the naive strategy. However, Pippenger’s al-
gorithm is not conducive to our packed secret sharing MPC techniques as it lacks sufficient SIMD
structure. With an optimal division of work, each weak server would carry out O(N/(ℓ⋅log N)) group
operations. While we do not attain an optimal division of work, we come very close with a per server
complexity of O(N/ℓ⋅log N/ℓ). In fact, since the constants inside the big O notation are the same,
we can theoretically predict the percentage loss in performance under infinite bandwidth conditions by
simply dividing the two asymptotics. As can be seen in Figure 8, a 4Gbps connection closely emulates
infinite bandwidth and our implementation indeed comes very close to the theoretical prediction.
— In our distributed FFT/partial product protocol, during degree reduction, the King unpacks and repacks
shares adding additional overhead. Our FFT implementation is also not as carefully optimized as the
arkworks implementation which is used by the consumer machine.
28

28 29 210211212213214215216217218219220221222223224225
Constraints
20
22
24
26
28
210
212
214
216
218
220
Time (ms)
Groth16(128)
Local
MSM
R1CS to QAP
29
210 211 212 213 214 215 216 217 218 219 220 221
Gates
20
22
24
26
28
210
212
214
216
218
220
Time (ms)
Plonk(128)
Local
Group Operations
Field Operations
Figure 7: Comparison between proof generation time for a local prover (Groth16 and Plonk resp.) run on the
consumer machine against that of the zkSaaS protocol with 128 servers on a 4 Gigabit link. The bar graph
indicates the fraction of time spent computing Field Operations (Tfield) vs Group Operations (Tcrypto). Missing
data points on the local curve indicates memory exhaustion.
Also, observe in Figure 7, that the fraction of time spent computing the field operations (refered to as
R1CS to QAP mapping in the case of Groth16) increases with the number of constraints. This is because
the FFT operation is asymptotically more expensive (O(mlog m)) than the MSM (O(m/log m)).
Varying Parties and Network Speeds. For our next experiment, we show how zkSaaS scales as the
number of parties increase, at varying network speeds. The dotted black line denotes the time taken by
a local prover. We simulate slower connections by scaling up the time spent on communication by the
network slowdown factor, comparing this to an implementation of Groth16/Plonk on a single consumer
machine and present our findings in Figure 8. Even at lower network speeds (64 Mbps), we observe that
the performance degradation is ≈2×.
Discussion on Financial Costs. We now estimate the costs of providing zk-SNARKs as a service. The
powerful VM costs has a spot pricing of $0.79/hr20 and cross continent egress traffic pricing is $0.08/GB21.
Being very conservative, our estimates show that with 128 parties, generating a Groth16 proof for an R1CS
instance of size 219 takes under 1 minute on a 4-Gbps link and under 5 minutes on a 64 Mbps link, with
the total outgoing communication from the server < 1.85GB. Hence, creating this proof would cost < 18
cents with a 4 Gbps link and < 23 cents on a 64 Mbps link.
Acknowledgements
Sanjam Garg, Guru-Vamsi Policharla and Sruthi Sekar are supported in part by DARPA under Agreement
No. HR00112020026, AFOSR Award FA9550-19-1-0200, NSF CNS Award 1936826, and research grants by
the Sloan Foundation, and Visa Inc. Guru-Vamsi Policharla is also supported by the UC Berkeley Center
for Long-Term Cybersecurity. Abhishek Jain is supported in part by NSF CNS-1814919, NSF CAREER
1942789, Johns Hopkins University Catalyst award, AFOSR Award FA9550-19-1-0200, and research gifts
from Ethereum, Stellar and Cisco.
20https://cloud.google.com/compute/vm-instance-pricing
21https://cloud.google.com/compute/network-pricing
29

23
24
25
26
27
Parties (n)
2
0
2
1
2
2
2
3
2
4
2
5
Speedup
Groth16-64.0Mbps
Groth16-256.0Mbps
Groth16-4Gbps
Single Prover Baseline
Perfect Division
23
24
25
26
27
Parties (n)
2
0
2
1
2
2
2
3
2
4
2
5
Speedup
Plonk-64.0Mbps
Plonk-256.0Mbps
Plonk-4Gbps
Single Prover Baseline
Perfect Division
Figure 8: Proving time versus number of parties, normalized by a single-prover time for 219 constraints (gates)
denoted by the dotted black line.
References
[1] Surya Addanki, Kevin Garbe, Eli Jaffe, Rafail Ostrovsky, and Antigoni Polychroniadou. Prio+: Privacy
preserving aggregate statistics via boolean shares. Cryptology ePrint Archive, Report 2021/576, 2021.
https://eprint.iacr.org/2021/576.
[2] alex ozdemir. collaborative-zksnark. https://github.com/alex-ozdemir/collaborative-zksnark, 2022.
[3] arkworks contributors. arkworks zksnark ecosystem. https://arkworks.rs, 2022.
[4] L´aszl´o Babai, Lance Fortnow, and Carsten Lund. Non-deterministic exponential time has two-prover
interactive protocols. In 31st FOCS, pages 16–25. IEEE Computer Society Press, October 1990.
[5] Judit Bar-Ilan and Donald Beaver. Non-cryptographic fault-tolerant computing in constant number
of rounds of interaction. In Piotr Rudnicki, editor, Proceedings of the Eighth Annual ACM Symposium
on Principles of Distributed Computing, Edmonton, Alberta, Canada, August 14-16, 1989, pages 201–209.
ACM, 1989.
[6] Gabrielle Beck, Aarushi Goel, Abhishek Jain, and Gabriel Kaptchuk. Order-C secure multiparty com-
putation for highly repetitive circuits. In Anne Canteaut and Franc¸ois-Xavier Standaert, editors,
EUROCRYPT 2021, Part II, volume 12697 of LNCS, pages 663–693. Springer, Heidelberg, October 2021.
[7] Eli Ben-Sasson, Alessandro Chiesa, Christina Garman, Matthew Green, Ian Miers, Eran Tromer, and
Madars Virza. Zerocash: Decentralized anonymous payments from bitcoin. In 2014 IEEE Symposium
on Security and Privacy, pages 459–474. IEEE Computer Society Press, May 2014.
[8] Eli Ben-Sasson, Alessandro Chiesa, Matthew Green, Eran Tromer, and Madars Virza. Secure sampling
of public parameters for succinct zero knowledge proofs. In 2015 IEEE Symposium on Security and
Privacy, pages 287–304, 2015.
[9] Eli Ben-Sasson, Alessandro Chiesa, Michael Riabzev, Nicholas Spooner, Madars Virza, and Nicholas P.
Ward. Aurora: Transparent succinct arguments for R1CS. In Yuval Ishai and Vincent Rijmen, editors,
EUROCRYPT 2019, Part I, volume 11476 of LNCS, pages 103–128. Springer, Heidelberg, May 2019.
[10] Dario Bini and Victor Y. Pan. Polynomial division and its computational complexity. J. Complex.,
2(3):179–203, 1986.
30

[11] Nir Bitansky, Ran Canetti, Alessandro Chiesa, Shafi Goldwasser, Huijia Lin, Aviad Rubinstein, and
Eran Tromer. The hunting of the SNARK. J. Cryptol., 30(4):989–1066, 2017.
[12] Nir Bitansky, Ran Canetti, Alessandro Chiesa, and Eran Tromer. Recursive composition and boot-
strapping for SNARKS and proof-carrying data. In Dan Boneh, Tim Roughgarden, and Joan Feigen-
baum, editors, 45th ACM STOC, pages 111–120. ACM Press, June 2013.
[13] Nir Bitansky and Alessandro Chiesa. Succinct arguments from multi-prover interactive proofs and
their efficiency benefits. In Reihaneh Safavi-Naini and Ran Canetti, editors, CRYPTO 2012, volume
7417 of LNCS, pages 255–272. Springer, Heidelberg, August 2012.
[14] Alexander R. Block, Justin Holmgren, Alon Rosen, Ron D. Rothblum, and Pratik Soni. Public-coin
zero-knowledge arguments with (almost) minimal time and space overheads. In Rafael Pass and
Krzysztof Pietrzak, editors, TCC 2020, Part II, volume 12551 of LNCS, pages 168–197. Springer, Hei-
delberg, November 2020.
[15] Alexander R. Block, Justin Holmgren, Alon Rosen, Ron D. Rothblum, and Pratik Soni. Time- and
space-efficient arguments from groups of unknown order. In Tal Malkin and Chris Peikert, editors,
CRYPTO 2021, Part IV, volume 12828 of LNCS, pages 123–152, Virtual Event, August 2021. Springer,
Heidelberg.
[16] Andrew J. Blumberg, Justin Thaler, Victor Vu, and Michael Walfish. Verifiable computation using
multiple provers. Cryptology ePrint Archive, Report 2014/846, 2014. https://eprint.iacr.org/2014/846.
[17] Dan Boneh, Elette Boyle, Henry Corrigan-Gibbs, Niv Gilboa, and Yuval Ishai. Zero-knowledge proofs
on secret-shared data via fully linear PCPs. In Alexandra Boldyreva and Daniele Micciancio, editors,
CRYPTO 2019, Part III, volume 11694 of LNCS, pages 67–97. Springer, Heidelberg, August 2019.
[18] Dan Boneh, Elette Boyle, Henry Corrigan-Gibbs, Niv Gilboa, and Yuval Ishai. Lightweight techniques
for private heavy hitters. In 2021 IEEE Symposium on Security and Privacy, pages 762–776. IEEE
Computer Society Press, May 2021.
[19] Jonathan Bootle, Andrea Cerulli, Essam Ghadafi, Jens Groth, Mohammad Hajiabadi, and Sune K.
Jakobsen. Linear-time zero-knowledge proofs for arithmetic circuit satisfiability. In Tsuyoshi Takagi
and Thomas Peyrin, editors, ASIACRYPT 2017, Part III, volume 10626 of LNCS, pages 336–365. Springer,
Heidelberg, December 2017.
[20] Jonathan Bootle, Andrea Cerulli, Jens Groth, Sune K. Jakobsen, and Mary Maller. Arya: Nearly linear-
time zero-knowledge proofs for correct program execution. In Thomas Peyrin and Steven Galbraith,
editors, ASIACRYPT 2018, Part I, volume 11272 of LNCS, pages 595–626. Springer, Heidelberg, Decem-
ber 2018.
[21] Jonathan Bootle, Alessandro Chiesa, and Jens Groth. Linear-time arguments with sublinear verifi-
cation from tensor codes. In Rafael Pass and Krzysztof Pietrzak, editors, TCC 2020, Part II, volume
12551 of LNCS, pages 19–46. Springer, Heidelberg, November 2020.
[22] Jonathan Bootle, Alessandro Chiesa, and Siqi Liu. Zero-knowledge IOPs with linear-time prover and
polylogarithmic-time verifier. In Orr Dunkelman and Stefan Dziembowski, editors, EUROCRYPT 2022,
Part II, volume 13276 of LNCS, pages 275–304. Springer, Heidelberg, May / June 2022.
[23] Sean Bowe, Alessandro Chiesa, Matthew Green, Ian Miers, Pratyush Mishra, and Howard Wu. ZEXE:
Enabling decentralized private computation. In 2020 IEEE Symposium on Security and Privacy, pages
947–964. IEEE Computer Society Press, May 2020.
31

[24] Sean Bowe, Ariel Gabizon, and Matthew D. Green. A multi-party protocol for constructing the public
parameters of the pinocchio zk-snark. In Aviv Zohar, Ittay Eyal, Vanessa Teague, Jeremy Clark,
Andrea Bracciali, Federico Pintore, and Massimiliano Sala, editors, Financial Cryptography and Data
Security - FC 2018 International Workshops, BITCOIN, VOTING, and WTSC, Nieuwpoort, Curac¸ao, March
2, 2018, Revised Selected Papers, volume 10958 of Lecture Notes in Computer Science, pages 64–77.
Springer, 2018.
[25] Benedikt B¨unz, Jonathan Bootle, Dan Boneh, Andrew Poelstra, Pieter Wuille, and Greg Maxwell.
Bulletproofs: Short proofs for confidential transactions and more. In 2018 IEEE Symposium on Security
and Privacy, pages 315–334. IEEE Computer Society Press, May 2018.
[26] Vitalik Buterin. Some ways to use zk-snarks for privacy.
[27] Binyi Chen, Benedikt B¨unz, Dan Boneh, and Zhenfei Zhang. HyperPlonk: Plonk with linear-time
prover and high-degree custom gates. Cryptology ePrint Archive, Report 2022/1355, 2022. https:
//eprint.iacr.org/2022/1355.
[28] Alessandro Chiesa, Yuncong Hu, Mary Maller, Pratyush Mishra, Noah Vesely, and Nicholas P. Ward.
Marlin: Preprocessing zkSNARKs with universal and updatable SRS. In Anne Canteaut and Yuval
Ishai, editors, EUROCRYPT 2020, Part I, volume 12105 of LNCS, pages 738–768. Springer, Heidelberg,
May 2020.
[29] Alessandro Chiesa, Ryan Lehmkuhl, Pratyush Mishra, and Yinuo Zhang. Eos: Efficient private dele-
gation of zksnark provers. In USENIX Security Symposium. USENIX Association, 2023.
[30] Alessandro Chiesa, Dev Ojha, and Nicholas Spooner. Fractal: Post-quantum and transparent recursive
proofs from holography. In Anne Canteaut and Yuval Ishai, editors, EUROCRYPT 2020, Part I, volume
12105 of LNCS, pages 769–793. Springer, Heidelberg, May 2020.
[31] Arka Rai Choudhuri, Aarushi Goel, Matthew Green, Abhishek Jain, and Gabriel Kaptchuk. Fluid MPC:
Secure multiparty computation with dynamic participants. In Tal Malkin and Chris Peikert, editors,
CRYPTO 2021, Part II, volume 12826 of LNCS, pages 94–123, Virtual Event, August 2021. Springer,
Heidelberg.
[32] William R Claycomb and Alex Nicoll. Insider threats to cloud computing: Directions for new research
challenges. In 2012 IEEE 36th annual computer software and applications conference, pages 387–394.
IEEE, 2012.
[33] Graham Cormode, Michael Mitzenmacher, and Justin Thaler. Practical verified computation with
streaming interactive proofs. In Shafi Goldwasser, editor, ITCS 2012, pages 90–112. ACM, January
2012.
[34] Ivan Damg˚ard, Yuval Ishai, and Mikkel Krøigaard. Perfectly secure multiparty computation and the
computational overhead of cryptography. In Henri Gilbert, editor, EUROCRYPT 2010, volume 6110 of
LNCS, pages 445–465. Springer, Heidelberg, May / June 2010.
[35] Ivan Damg˚ard, Yuval Ishai, Mikkel Krøigaard, Jesper Buus Nielsen, and Adam Smith. Scalable multi-
party computation with nearly optimal work and resilience. In David Wagner, editor, CRYPTO 2008,
volume 5157 of LNCS, pages 241–261. Springer, Heidelberg, August 2008.
[36] Ivan Damg˚ard and Jesper Buus Nielsen. Scalable and unconditionally secure multiparty computation.
In Alfred Menezes, editor, CRYPTO 2007, volume 4622 of LNCS, pages 572–590. Springer, Heidelberg,
August 2007.
32

[37] Zhiyong Fang, David Darais, Joseph P. Near, and Yupeng Zhang. Zero knowledge static program
analysis. In Giovanni Vigna and Elaine Shi, editors, ACM CCS 2021, pages 2951–2967. ACM Press,
November 2021.
[38] Matthew K. Franklin and Moti Yung. Communication complexity of secure computation (extended
abstract). In 24th ACM STOC, pages 699–710. ACM Press, May 1992.
[39] Ariel Gabizon, Zachary J. Williamson, and Oana Ciobotaru. PLONK: Permutations over lagrange-
bases for oecumenical noninteractive arguments of knowledge. Cryptology ePrint Archive, Report
2019/953, 2019. https://eprint.iacr.org/2019/953.
[40] Daniel Genkin, Yuval Ishai, and Antigoni Polychroniadou. Efficient multi-party computation: From
passive to active security via secure SIMD circuits. In Rosario Gennaro and Matthew J. B. Robshaw,
editors, CRYPTO 2015, Part II, volume 9216 of LNCS, pages 721–741. Springer, Heidelberg, August
2015.
[41] Daniel Genkin, Yuval Ishai, Manoj Prabhakaran, Amit Sahai, and Eran Tromer. Circuits resilient to
additive attacks with applications to secure computation. In David B. Shmoys, editor, 46th ACM STOC,
pages 495–504. ACM Press, May / June 2014.
[42] Rosario Gennaro, Craig Gentry, Bryan Parno, and Mariana Raykova. Quadratic span programs and
succinct NIZKs without PCPs. In Thomas Johansson and Phong Q. Nguyen, editors, EUROCRYPT 2013,
volume 7881 of LNCS, pages 626–645. Springer, Heidelberg, May 2013.
[43] Shafi Goldwasser, Yael Tauman Kalai, and Guy N. Rothblum. Delegating computation: interactive
proofs for muggles. In Richard E. Ladner and Cynthia Dwork, editors, 40th ACM STOC, pages 113–
122. ACM Press, May 2008.
[44] Alexander Golovnev, Jonathan Lee, Srinath Setty, Justin Thaler, and Riad S. Wahby. Brakedown:
Linear-time and post-quantum SNARKs for R1CS. Cryptology ePrint Archive, Report 2021/1043,
2021. https://eprint.iacr.org/2021/1043.
[45] S. Dov Gordon, Daniel Starin, and Arkady Yerukhimovich. The more the merrier: Reducing the cost of
large scale MPC. In Anne Canteaut and Franc¸ois-Xavier Standaert, editors, EUROCRYPT 2021, Part II,
volume 12697 of LNCS, pages 694–723. Springer, Heidelberg, October 2021.
[46] Vipul Goyal, Antigoni Polychroniadou, and Yifan Song. Unconditional communication-efficient MPC
via hall’s marriage theorem. In Tal Malkin and Chris Peikert, editors, CRYPTO 2021, Part II, volume
12826 of LNCS, pages 275–304, Virtual Event, August 2021. Springer, Heidelberg.
[47] Vipul Goyal, Antigoni Polychroniadou, and Yifan Song. Sharing transformation and dishonest major-
ity MPC with packed secret sharing. In Yevgeniy Dodis and Thomas Shrimpton, editors, CRYPTO 2022,
Part IV, volume 13510 of LNCS, pages 3–32. Springer, Heidelberg, August 2022.
[48] Vipul Goyal, Antigoni Polychroniadou, and Yifan Song.
Sharing transformation and dishonest
majority MPC with packed secret sharing.
Cryptology ePrint Archive, Report 2022/831, 2022.
https://eprint.iacr.org/2022/831.
[49] Matthew Green, Mathias Hall-Andersen, Eric Hennenfent, Gabriel Kaptchuk, Benjamin Perez, and
Gijs Van Laer. Efficient proofs of software exploitability for real-world processors. Proc. Priv. Enhanc-
ing Technol., 2023(1):627–640, 2023.
33

[50] Jens Groth. On the size of pairing-based non-interactive arguments. In Marc Fischlin and Jean-
S´ebastien Coron, editors, EUROCRYPT 2016, Part II, volume 9666 of LNCS, pages 305–326. Springer,
Heidelberg, May 2016.
[51] Jens Groth and Mary Maller. Snarky signatures: Minimal signatures of knowledge from simulation-
extractable SNARKs. In Jonathan Katz and Hovav Shacham, editors, CRYPTO 2017, Part II, volume
10402 of LNCS, pages 581–612. Springer, Heidelberg, August 2017.
[52] Paul Grubbs, Arasu Arun, Ye Zhang, Joseph Bonneau, and Michael Walfish. Zero-knowledge middle-
boxes. In USENIX Security Symposium, pages 4255–4272. USENIX Association, 2022.
[53] Justin Holmgren and Ron Rothblum. Delegating computations with (almost) minimal time and space
overhead. In Mikkel Thorup, editor, 59th FOCS, pages 124–135. IEEE Computer Society Press, October
2018.
[54] Harry A. Kalodner, Steven Goldfeder, Xiaoqi Chen, S. Matthew Weinberg, and Edward W. Felten. Ar-
bitrum: Scalable, private smart contracts. In William Enck and Adrienne Porter Felt, editors, USENIX
Security 2018, pages 1353–1370. USENIX Association, August 2018.
[55] Sanket Kanjalkar, Ye Zhang, Shreyas Gandlur, and Andrew Miller. Publicly auditable mpc-as-a-service
with succinct verification and universal setup. In IEEE European Symposium on Security and Privacy
Workshops, EuroS&P 2021, Vienna, Austria, September 6-10, 2021, pages 386–411. IEEE, 2021.
[56] Aniket Kate, Gregory M. Zaverucha, and Ian Goldberg. Constant-size commitments to polynomials
and their applications. In Masayuki Abe, editor, ASIACRYPT 2010, volume 6477 of LNCS, pages 177–
194. Springer, Heidelberg, December 2010.
[57] Markulf Kohlweiss, Mary Maller, Janno Siim, and Mikhail Volkhov. Snarky ceremonies. Cryptology
ePrint Archive, Report 2021/219, 2021. https://eprint.iacr.org/2021/219.
[58] Abhiram Kothapalli, Elisaweta Masserova, and Bryan Parno. A direct construction for asymptotically
optimal zksnarks. IACR Cryptol. ePrint Arch., page 1318, 2020.
[59] Jonathan Lee. Dory: Efficient, transparent arguments for generalised inner products and polynomial
commitments. In Kobbi Nissim and Brent Waters, editors, TCC 2021, Part II, volume 13043 of LNCS,
pages 1–34. Springer, Heidelberg, November 2021.
[60] Seunghwa Lee, Hankyung Ko, Jihye Kim, and Hyunok Oh. vCNN: Verifiable convolutional neural
network. Cryptology ePrint Archive, Report 2020/584, 2020. https://eprint.iacr.org/2020/584.
[61] Fu-Rong Lin, Wai-Ki Ching, and Michael K. Ng. Fast inversion of triangular toeplitz matrices. Theor.
Comput. Sci., 315(2-3):511–523, 2004.
[62] Tianyi Liu, Xiang Xie, and Yupeng Zhang. zkCNN: Zero knowledge proofs for convolutional neural
network predictions and accuracy. In Giovanni Vigna and Elaine Shi, editors, ACM CCS 2021, pages
2968–2985. ACM Press, November 2021.
[63] Assa Naveh and Eran Tromer. Photoproof: Cryptographic image authentication for any set of per-
missible transformations. In IEEE Symposium on Security and Privacy, SP 2016, San Jose, CA, USA,
May 22-26, 2016, pages 255–271. IEEE Computer Society, 2016.
[64] Alex Ozdemir and Dan Boneh.
Experimenting with collaborative zk-SNARKs: Zero-Knowledge
proofs for distributed secrets. In 31st USENIX Security Symposium (USENIX Security 22), pages 4291–
4308, Boston, MA, August 2022. USENIX Association.
34

[65] Bryan Parno, Jon Howell, Craig Gentry, and Mariana Raykova. Pinocchio: Nearly practical verifiable
computation. In 2013 IEEE Symposium on Security and Privacy, SP 2013, Berkeley, CA, USA, May 19-22,
2013, pages 238–252. IEEE Computer Society, 2013.
[66] Alexey Pertsev, Roman Semenov, and Roman Storm. Tornado cash privacy solution version 1.4. 2019.
[67] Nicholas Pippenger. On the evaluation of powers and monomials. SIAM J. Comput., 9(2):230–250,
1980.
[68] Deevashwer Rathee, Guru Vamsi Policharla, Tiancheng Xie, Ryan Cottone, and Dawn Song. Zebra:
Anonymous credentials with practical on-chain verification and applications to kyc in defi. Cryptol-
ogy ePrint Archive, Paper 2022/1286, 2022. https://eprint.iacr.org/2022/1286.
[69] Michael Rosenberg, Jacob White, Christina Garman, and Ian Miers. zk-creds: Flexible anonymous
credentials from zkSNARKs and existing identity infrastructure. Cryptology ePrint Archive, Report
2022/878, 2022. https://eprint.iacr.org/2022/878.
[70] Berry Schoenmakers, Meilof Veeningen, and Niels de Vreede. Trinocchio: Privacy-preserving out-
sourcing by distributed verifiable computation. In Mark Manulis, Ahmad-Reza Sadeghi, and Steve
Schneider, editors, ACNS 16, volume 9696 of LNCS, pages 346–366. Springer, Heidelberg, June 2016.
[71] Srinath Setty. Spartan: Efficient and general-purpose zkSNARKs without trusted setup. In Daniele
Micciancio and Thomas Ristenpart, editors, CRYPTO 2020, Part III, volume 12172 of LNCS, pages 704–
737. Springer, Heidelberg, August 2020.
[72] Adi Shamir. How to share a secret. Communications of the Association for Computing Machinery,
22(11):612–613, November 1979.
[73] Nigel P. Smart and Younes Talibi Alaoui. Distributing any elliptic curve based protocol. In Martin
Albrecht, editor, Cryptography and Coding - 17th IMA International Conference, IMACC 2019, Oxford,
UK, December 16-18, 2019, Proceedings, volume 11929 of Lecture Notes in Computer Science, pages 342–
366. Springer, 2019.
[74] Justin Thaler. Time-optimal interactive proofs for circuit evaluation. In Ran Canetti and Juan A. Garay,
editors, CRYPTO 2013, Part II, volume 8043 of LNCS, pages 71–89. Springer, Heidelberg, August 2013.
[75] Victor Vu, Srinath T. V. Setty, Andrew J. Blumberg, and Michael Walfish. A hybrid architecture for
interactive verifiable computation. In 2013 IEEE Symposium on Security and Privacy, SP 2013, Berkeley,
CA, USA, May 19-22, 2013, pages 223–237. IEEE Computer Society, 2013.
[76] Riad S. Wahby, Max Howald, Siddharth Garg, Abhi Shelat, and Michael Walfish. Verifiable asics. In
IEEE Symposium on Security and Privacy, SP 2016, San Jose, CA, USA, May 22-26, 2016, pages 759–778.
IEEE Computer Society, 2016.
[77] Riad S. Wahby, Ioanna Tzialla, Abhi Shelat, Justin Thaler, and Michael Walfish. Doubly-efficient
zksnarks without trusted setup. In 2018 IEEE Symposium on Security and Privacy, SP 2018, Proceedings,
21-23 May 2018, San Francisco, California, USA, pages 926–943. IEEE Computer Society, 2018.
[78] Michael Walfish and Andrew J Blumberg. Verifying computations without reexecuting them. Com-
munications of the ACM, 58(2):74–84, 2015.
[79] Chenkai Weng, Kang Yang, Xiang Xie, Jonathan Katz, and Xiao Wang. Mystique: Efficient conver-
sions for zero-knowledge proofs with applications to machine learning. In Michael Bailey and Rachel
Greenstadt, editors, USENIX Security 2021, pages 501–518. USENIX Association, August 2021.
35

[80] Howard Wu, Wenting Zheng, Alessandro Chiesa, Raluca Ada Popa, and Ion Stoica. DIZK: A dis-
tributed zero knowledge proof system. In William Enck and Adrienne Porter Felt, editors, USENIX
Security 2018, pages 675–692. USENIX Association, August 2018.
[81] Tiancheng Xie, Jiaheng Zhang, Yupeng Zhang, Charalampos Papamanthou, and Dawn Song. Li-
bra: Succinct zero-knowledge proofs with optimal prover computation. In Alexandra Boldyreva and
Daniele Micciancio, editors, CRYPTO 2019, Part III, volume 11694 of LNCS, pages 733–764. Springer,
Heidelberg, August 2019.
[82] Tiancheng Xie, Yupeng Zhang, and Dawn Song. Orion: Zero knowledge proof with linear prover
time. In Yevgeniy Dodis and Thomas Shrimpton, editors, CRYPTO 2022, Part IV, volume 13510 of
LNCS, pages 299–328. Springer, Heidelberg, August 2022.
[83] Jiaheng Zhang, Zhiyong Fang, Yupeng Zhang, and Dawn Song. Zero knowledge proofs for decision
tree predictions and accuracy. In Jay Ligatti, Xinming Ou, Jonathan Katz, and Giovanni Vigna, editors,
ACM CCS 2020, pages 2039–2053. ACM Press, November 2020.
[84] Jiaheng Zhang, Tianyi Liu, Weijie Wang, Yinuo Zhang, Dawn Song, Xiang Xie, and Yupeng Zhang.
Doubly efficient interactive proofs for general arithmetic circuits with linear prover time. In Giovanni
Vigna and Elaine Shi, editors, ACM CCS 2021, pages 159–177. ACM Press, November 2021.
[85] Yupeng Zhang, Daniel Genkin, Jonathan Katz, Dimitrios Papadopoulos, and Charalampos Papaman-
thou. vSQL: Verifying arbitrary SQL queries over dynamic outsourced databases. In 2017 IEEE Sym-
posium on Security and Privacy, pages 863–880. IEEE Computer Society Press, May 2017.
[86] Yupeng Zhang, Daniel Genkin, Jonathan Katz, Dimitrios Papadopoulos, and Charalampos Papaman-
thou. vram: Faster verifiable RAM with program-independent preprocessing. In 2018 IEEE Symposium
on Security and Privacy, SP 2018, Proceedings, 21-23 May 2018, San Francisco, California, USA, pages
908–925. IEEE Computer Society, 2018.
[87] ZkRollups. An incomplete guide to rollups. https://vitalik.ca/general/2021/01/ 05/rollup.html, 2021.
A
Groth16 zkSaaS
In [50], Groth introduced the smallest SNARKs based on pairing assumptions, where the proof size only
consists of 3 group elements. These SNARKs rely on an honestly generated structured common reference
string (CRS). In this section, we recall the construction of these SNARKs and then demonstrate how our
techniques can be used to efficiently compute them in our zkSaaS framework.
Quadratic Arithmetic Programs (QAP). Groth16 SNARKs use a QAP representation of the relation. We
start by recalling this representation and then proceed to give an overview of how the proof is computed.
Let CR be an arithmetic circuit representation (over field F) of the relation function that takes the
statement and witness as input and outputs either 1 or 0 depending on whether or not the relation is
satisfied. Such a relation can also be described by a set of equations over the statement (a1,...,aℓ) and
witness (aℓ+1,...,am). In particular, let a1,...,am ∈F be variables used to denote the statement and
witness and let a0 = 1 be an extra variable. Then there exist variables {ui,q,vi,q,wi,q}i∈[0,m],q∈[Q] ∈F such
that each of the following equations are satisfied if and only if the output of CR on input a1,...,am is 1:
∑
i∈[0,m]
ai ⋅ui,q ⋅
∑
i∈[0,m]
ai ⋅vi,q =
∑
i∈[0,m]
ai ⋅wi,q
36

Here m is the size of CR and Q are the number of multipication gates in the circuit. Gennaro, Gen-
try, Parno and Raykova [42] showed that for a large enough F, this set of arithmetic constraints can be
reformulated as a quadratic arithmetic program. Let r1,...,rQ ∈F be arbitrary distinct field elements. Let
t(x) = ∏q∈[Q](x −rq) and for each i ∈[0,m], let ui(x),vi(x),wi(x) be degree Q −1 polynomials such
that
∀q ∈[Q],
ui(rq) = ui,q
vi(rq) = vi,q
wi(rq) = wi,q
The relation is satisfied if the following condition is satisfied for some degree n−2 quotient polynomial
h(X):
∑
i∈[0,m]
ai ⋅ui(X) ⋅
∑
i∈[0,m]
ai ⋅vi(X) =
∑
i∈[0,m]
ai ⋅wi(X) + h(X)t(X)
In order to compute the proof, the prover must first compute the polynomial h(X). We assume that the
client packed secret shares a1,...,am with the servers. The client also packed secret shares Q “evaluations”
of the polynomials ∑i∈[0,m] aiui(X), ∑i∈[0,m] aivi(X) and ∑i∈[0,m] aiwi(X). We also assume that the
servers have a packed secret sharing of the evaluation representation of polynomial t(X). Given this, the
servers compute the following:
— Using our distributed protocols for polynomial multiplication and division they compute packed
shares of the evaluation representation of h(X). Finally they use the distributed protocol for inverse
FFT to compute packed shares of the coefficients of h(X). Let h0,...,hQ−2 denote the coefficients
of polynomial h(X).
Structured Random String. As discussed earlier, Groth SNARKs are based on pairing assumption. Let
the map be e ∶G1 × G2 →GT . Let g1 be the generator for G1 and g2 be the generator for G2. The CRS
consists of 3+m+2Q elements in G1 and 3+Q elements in G2. The actual values contained in this CRS are
immaterial for the purpose of this example. Hence, we use random variables to denote the group elements
in the CRS.
— G1 Elements:
We use variables (L,M,N,{Si}i∈[0,m], {Hi}i∈[0,m], {Ti}i∈[0,ℓ], {Wi}i∈[ℓ+1,m],
{Ui}i∈[0,Q−2]) to denote elements in G1.
We assume that all the servers computing the
proof get L,M,N in the clear and only receive packed shares of the remaining elements
{Si}i∈[0,Q−1],{Hi}i∈[0,Q−1],{Ti}i∈[0,ℓ], {Wi}i∈[ℓ+1,m], {Ui}i∈[0,Q−2].
— G2 Elements: Similarly, we use variables (Z,O,K,{Vi}i∈[0,m]) to denote the elements in G2. As
before, we assume that all the servers computing the proof get Z,O,K in the clear and only receive
packed shares of the remaining elements {Vi}i∈[0,Q−1].
Proof. The proof consists of three group elements A,C ∈G1 and B ∈G2. The prover samples random
field elements r,s ∈F. The parties can run frand to collectively sample and compute (regular) secret shares
of r and s.
1. The prover computes the following:
A = L ⋅(N)r ⋅
∏
i∈[0,m]
(Si)ai
Given packed shares of Si and aui terms, the servers can use πMSM to compute ∏i∈[0,Q−1](Si)ai.
Since the output of MSM are regular shares, they can then be combined with L,N and regular shares
of r to get regular shares of A.
37

2. Next, the prover computes:
B = Z ⋅(K)s ⋅
∏
i∈[0,m]
(Vi)ai
In our setting, this can be computed exactly as before. Given packed shares of Vi and avi terms, the
servers can use πMSM to compute ∏i∈[0,Q−1](Vi)ai. The output of MSM can then be combined with
Z,K and regular shares of s to get regular shares of B.
3. Finally, the prover computes:
C=(∏i∈[ℓ+1,m](Wi)ai)(∏i∈[0,Q−2](Ui)hi)⋅As⋅(M)r⋅(∏i∈[0,m](Hi)ai)r
In our setting, the servers invoke 3 instances of πMSM to compute regular shares of ∏i∈[ℓ+1,m](Wi)ai,
∏i∈[0,Q−2](Ui)hi and ∏i∈[0,Q−1](Hi)ai. The outputs of these are then combined with A,N,M and
shares of r and s to obtain shares of C.
B
Plonk zkSaaS
In Plonk [39], the authors build SNARKs based on pairing assumptions, using a universal setup, which as
opposed to the CRS-model of Groth16 (which is circuit-specific), uses the same structured random string
for statements about all circuits of a certain bounded size, and can be updated. The proof size of Plonk
consists of 9-group elements and 6 field elements. In this section, we only give an overview of the key
steps of the Plonk construction and describe how our techniques can be used to efficiently compute them
in our zkSaaS framework. For the detailed description of Plonk, we refer the reader to [39, Section 8.3]. We
only discuss the version of Plonk without zero-knowledge, for ease of exposition, however we can easily
extend our technique to the zero-knowledge version.
Plonk Arithmetization.
This differs from the QAP model used by Groth16. We begin by describing
the constraint system used in Plonk [39] before proceeding to give an overview of how the proof is com-
puted. For fixed integers m,Q, the Plonk constraint system C = (V,Q) defined below captures fan-in two
arithmetic circuits of unlimited fan-out with Q gates and m wires.
— V is of the form V = (a,b,c) ∈[m]3Q, where a,b, and c are the left, right and output sequence of
C.
— Q = (qL,qR,qO,qM,qC) ∈(FQ)5, where qL,qR, qO,qM,qC are “selector vectors”.
x ∈Fm satisfies C if for each i ∈[Q],
(qL)i ⋅xai + (qR)i ⋅xbi + (qO)i ⋅xci + (qM)i ⋅xaixbi + (qC)i = 0
A relation RC is defined as the set of pairs (x,w) ∈Fm, such that (x,w) satisfies C. In the pre-processing
step, the polynomials that defined the circuit are computed: qM(X),qL(X),qR(X),qO(X),qC(X) are
the selector polynomials, SID1,SID2 and SID3 are the polynomials that help in performing the permutation
checks (to ensure the correct ordering of the 3Q wires across the gates) that are defined by a permutation
map σ∗on 3Q. Given these, to prove that (x,w) ∈F3Q satisfies the constraint C, in addition to the
constraint check defined above, the prover also proves that wi = wσ∗(i) and xi = xσ∗(i), ∀i.
We assume that the client packed secret shares the values qMi, qLi, qRi, qOi, qCi corresponding to
all Q gates, and the σ∗(i) corresponding to all 3Q wires. This corresponds to the packed shares of the
evaluation representation of the respective polynomials.
38

Structured Random String.
The Plonk pre-processing outputs an SRS consisting of 3Q +
3(#(addition gates))-G1 and 1-G2 elements along with all the polynomials mentioned above. This con-
sists of powers of a random value τ, that will be used to get polynomial evaluations in the main protocol
at τ. We assume that all these group elements are given as packed shares to the servers. In addition, as
we mentioned above, the packed shares corresponding to the evaluations of all the polynomials are given
to the server. Since, the Plonk-protocol uses evaluation representations of all polynomials throughout the
protocol, we also assume that the Lagrange polynomial values at τ are packed secret shared and given to
the servers. Looking ahead, this would be used in our MSM computations.
Proof. On input (x,w) ∈F3Q, the Plonk prover algorithm interacts with the verifier in 5 rounds and sends
9-G1 elemets and 6-F elements. We mention the exact calls made to the sub-protocols (KZG commitment
and proof generation, MSMs, partial products and FFTs) that are done in each of these five rounds. These
can then be adapted to our techniques as well. For a detailed description of each round, refer to [39, Section
8.3].
1. In Round 1, the Plonk prover computes three polynomials a(X),b(X) and c(X), each of degree Q −1
that correspond to each of the Q left, right and output wire values given in the input and sends their
KZG commitments to the verifier. We assume that the client packed secret shares the evaluations of a,
b and c and sends to the server. Given these packed secret shares, computing each KZG commitment
involves one call to the MSM functionality of size Q. Thus, use three invocations of our distributed
MSM to compute the commitments in this round.
2. In Round 2, the prover sends the commitment of a single polynomial z correponding to the wire permu-
tation check. The evaluations of z correspond to partial products on input of size Q. In our setting, the
servers can invoke the distributed partial products to compute the packed shares of z and then invoke
the distributed MSM to compute its commitment.
3. In Round 3, the prover computes a quotient polynomial t(X) obtained by diving by a public polynomial
ZH(X) = XQ −1, and then computes 3 polynomial commitments on three parts of t(X), each of de-
gree < Q. Evaluating the polynomial t(X), given the evaluations of all the polynomials from previous
rounds, requires a constant number of field multiplications and additions followed by a single call to
polynomial division. Splitting of this larger degree polynomial into the three degree < Q polynomi-
als helps in reducing the group elements in the SRS. In our setting, post the field multiplications and
divisions on the corresponding packed shares, the servers invoke our distributed polynomial division
which outputs the packed shares of t(X) in the evaluation representation, and thus requires 2 calls to
the distributed FFT.
4. In Rounds 4 and 5, the Plonk prover computes 6 polynomial openings on random values along with
a KZG proof of these openings. Computing each opening involves a call to FFT, while computing the
combined KZG proof involves doing one polynomial division followed by an 2 MSMs. In our setting,
the servers can invoke the distributed FFT for each opening. For the opening proof, the servers can
invoke distributed polynomial division once, followed by two calls to the distributed MSM.
C
Sub-Protocols for Standard Functionalities
We now give a description of some standard MPC sub-protocols that are used in the design of our protocols
in Section 5.
39

C.1
Secret Sharing Random Values
In this section, we describe a protocol πrand (Figure 10) for computing shares of a batch of random and
independently chosen values in F. It makes use of the regular Shamir secret sharing scheme along with an
n × (n −t) Vandermonde matrix Vn,(n−t). First, each party samples a random value and (regular) secret
shares it amongst the other parties. The parties then compute n −t linear combinations of these shares
using the Vandermonde matrix to obtain shares of n −t uniformly random values in F.
This protocol realizes n −t instantiations of the functionality frand (Figure 9) with abort. The total
communication and computation complexity of this protocol is O(n2). However, since each protocol yields
shares of n −t random values, the amortized cost of sharing a single random value using this protocol is
O(n).
The functionality frand
The n-party functionality frand, running with parties {P1,...,Pn} and the ideal adversary Sim pro-
ceeds as follows:
— frand receives the set of corrupted parties, denoted Corr ⊂[n].
— frand receives shares {ui}i∈Corr from Sim.
— frand chooses a random value r ∈F, and samples a random (degree t) sharing of r, such that the
shares of the corrupted parties are identical to those received from the Sim, i.e., {ui}i∈Corr.
— frand distributed the shares of r to the honest parties.
Figure 9: Functionality for Generating Shares of a Random Value in F
Lemma 4. The protocol πrand described in Figure 10 securely computes n −t instantiations of frand against a
semi-honest adversary who controls upto t parties.
The proof of this lemma follows from [36].
C.2
Double Sharing of Random Values
In this section, we describe a protocol πdouble−rand (Figure 12) for computing doubles shares for a batch of
random and independently chosen values in F. This protocol is very similar to πrand, except that here we
generate two sharings of the same random value – one w.r.t. to a degree t sharing and another w.r.t. a
degree n −1 sharing. The complexity of this protocol is same as that of πrand.
Lemma 5. The protocol πdouble−rand described in Figure 12 securely computes n−t instantiations of fdouble−rand
against a semi-honest adversary who controls upto t parties.
The proof of this lemma follows from [36].
C.3
Packed Secret Sharing of Random Vectors
We now describe a protocol πprand (in Figure 14) for computing a batch of packed secret shares of ran-
dom vectors and do not reconstruct the vectors. This protocol is similar also to frand, except that now
we compute packed shares of random vectors. The functionality fprand realized by this protocol is pre-
sented in Figure 13. As before, the total communication and computation complexity of this protocol is
40

The protocol πrand
Auxiliary Input: Vandermonde matrix Vn,n−t over F.
Inputs: The parties do not have any inputs.
Protocol: The parties P1,...,Pn proceed as follows:
— Each party Pi for i ∈[n] samples ui ←$F uniformly at random and evaluates share(F,ui,t) to
receive [ui].
— For each i,j ∈[n], party Pi sends [ui]j to Pj.
— The parties compute
([r1],...,[rn−t]) = VT
n,n−t ⋅([u1],...,[un]).
Output: Each party Pi outputs shares [r1]i,...,[rn−t]i.
Figure 10: Protocol for Generating Shares of a Random Value in F
The functionality fdouble−rand
The n-party functionality fdouble−rand, running with parties {P1,...,Pn} and the ideal adversary Sim
proceeds as follows:
— fdouble−rand receives the set of corrupted parties, denoted Corr ⊂[n].
— fdouble−rand receives shares {ui,vi}i∈Corr from Sim.
— fdouble−rand chooses a random value r ∈F, and samples random degree t and n −1 sharing of r,
such that the shares of the corrupted parties are identical to those received from the Sim, i.e.,
{ui,vi}i∈Corr.
— fdouble−rand distributed the two sharings of r to the honest parties.
Figure 11: Functionality for Generating Double Sharings of a Random Value in F
O(n2). However, since each protocol yields packed sharings of O(n−t) vectors, each of length O(n), the
amortized cost of sharing a random value using this protocol is O(1).
Lemma 6. The protocol πprand described in Figure 14 securely computes n −t instantiations of fprand against
a semi-honest adversary who controls upto t parties.
The proof of this Lemma follows from [34].
C.4
Double Packed Secret Sharing of Random Vectors
We now describe a protocol πdouble−prand (in Figure 16) for generating double packed sharings of a batch
of random vectors. This is essentially a packed sharing based counterpart of πdouble−prand. The complexity
of this protocol is similar to πprand.
Lemma 7. The protocol πdouble−prand described in Figure 16 securely computes n −t instantiations of
fdouble−prand against a semi-honest adversary who controls upto t parties.
41

The protocol πrand
Auxiliary Input: Vandermonde matrix Vn,n−t over F.
Inputs: The parties do not have any inputs.
Protocol: The parties P1,...,Pn proceed as follows:
— Each party Pi for i ∈[n] samples ui ←$F uniformly at random and evaluates share(F,ui,t) and
share(F,ui,n −1) to receive [ui] and ⟨ui⟩.
— For each i,j ∈[n], party Pi sends [ui]j and ⟨ui⟩j to Pj.
— The parties compute
([r1],...,[rn−t]) = VT
n,n−t ⋅([u1],...,[un])
(⟨r1⟩,...,⟨rn−t⟩) = VT
n,n−t ⋅(⟨u1⟩,...,⟨un⟩).
Output: Each party Pi outputs shares [r1]i,...,[rn−t]i and ⟨r1⟩i,...,⟨rn−t⟩i.
Figure 12: Protocol for Generating Double Sharings of a Random Value in F
The functionality fprand
The n-party functionality fprand, running with parties {P1,...,Pn} and the ideal adversary Sim pro-
ceeds as follows:
— fprand receives the set of corrupted parties, denoted Corr ⊂[n].
— fprand receives shares {ui}i∈Corr from Sim.
— fprand chooses a random vector r ∈Fℓ, and samples a random (degree D) sharing of r, such that
the shares of the corrupted parties are identical to those received from the Sim, i.e., {ui}i∈Corr.
— fprand distributed the shares of r to the honest parties.
Figure 13: Functionality for Generating Packed Sharing of a Random Vector over F
The proof of this Lemma follows from [34].
C.5
Multiplying Packed Secret Shared Vectors
In this section, we describe a sub-protocol for multiplication. This subprotocol is identical to the one used
in [34]. As proved in [34], this protocol is secure against a semi-honest adversary. This protocol πpack−mult
is described in Figure 20. We note that we describe this protocol assuming that it takes as input two pack
secret shared inputs, where both are secret shared w.r.t. a degree D polynomial. However, it is easy to
see that it still works as is, if any of those values are secret shared using a smaller degree polynomial. The
protocol in Figure 20 incurs a total communication cost of O(n) in order to multiply packed secret shares,
containing O(n) elements. As such, the amortized cost of multiplication is O(1).
Lemma 8. The protocol πpack−mult described in Figure 18 securely computes fpack−mult against a semi-honest
adversary who controls upto t parties.
42

The protocol πprand
Auxiliary Input: Vandermonde matrix Vn,n−t over F.
Inputs: The parties do not have any inputs.
Protocol: The parties P1,...,Pn proceed as follows:
— Each party Pi for i ∈[n] samples ui ←$Fℓuniformly at random and evaluates pshare(F,ui,D)
to receive JuiK.
— For each i,j ∈[n], party Pi sends JuiKj to Pj.
— The parties compute
(Jr1Ki,...,Jrn−tKi) = VT
n,n−t ⋅(Ju1Ki,...,JunKi).
Output: Each party Pi outputs Jr1Ki,...,Jrn−tKi.
Figure 14: Protocol for Generating Packed Sharing of Random Vectors over F
The functionality fdouble−prand
The n-party functionality fdouble−prand, running with parties {P1,...,Pn} and the ideal adversary Sim
proceeds as follows:
— fdouble−prand receives the set of corrupted parties, denoted Corr ⊂[n].
— fdouble−prand receives shares {ui,vi}i∈Corr from Sim.
— fdouble−prand chooses a random vector r ∈Fℓ, and samples random degree D and n −1 sharing
of r, such that the shares of the corrupted parties are identical to those received from the Sim,
i.e., {ui,vi}i∈Corr.
— fdouble−prand distributed the two sharings of r to the honest parties.
Figure 15: Functionality for Generating Double Packed Sharings of a Random Vector in F
The proof of this Lemma follows from [34].
C.6
Multiplying Secret Shared Values
We now describe protocol πmult for securely multiplying two secret shared values. This is a regular secret
sharing variant of πpack−mult and works exactly like that protocol, albeit on regular shares. This protocol
incurs a total communication cost of O(n) for multiplying 2 secret shared values.
Lemma 9. The protocol πmult described in Figure 20 securely computes fmult against a semi-honest adversary
who controls upto t parties.
The proof of this lemma follows from [36].
43

The protocol πdouble−prand
Auxiliary Input: Vandermonde matrix Vn,n−t over F.
Inputs: The parties do not have any inputs.
Protocol: The parties P1,...,Pn proceed as follows:
— Each party Pi for i ∈[n] samples ui ←$Fℓuniformly at random and evaluates pshare(F,ui,D)
and pshare(F,ui,n −1) to receive JuiK and ⟪ui⟫.
— For each i,j ∈[n], party Pi sends JuiKj and ⟪ui⟫j to Pj.
— The parties compute
(Jr1Ki,...,Jrn−tKi) = VT
n,n−t ⋅(Ju1Ki,...,JunKi).
(⟪r1⟫i,...,⟪rn−t⟫i) = VT
n,n−t ⋅(⟪u1⟫i,...,⟪un⟫i).
Output: Each party Pi outputs Jr1Ki,...,Jrn−tKi and ⟪r1⟫i,...,⟪rn−t⟫i.
Figure 16: Protocol for Generating Double Packed Sharings of a Random Vector in F
The Functionality fpack−mult
The functionality fpack−mult running with a set of parties {P1,...,Pn} and the ideal adversary Sim
proceeds as follows:
— fpack−mult receives the set of corrupted parties, denoted Corr ⊂[n].
— fpack−mult receives shares JaK and JbK from all parties.
— fpack−mult receives from the adversary a set of shares {ui}i∈Corr from Sim.
— fpack−mult runs open(F,JaK,D) and open(F,JbK,D) to obtain (a1,...,aℓ) and (b1,...,bℓ).
— For each j ∈[ℓ], fpack−mult computes cj = aj ⋅bj. Set c = (c1,...,cℓ).
— fpack−mult samples a random sharing of c, such that the shares of the corrupted parties are
identical to those received from Sim, i.e., {ui}i∈Corr.
— fpack−mult distributes the shares of c to the honest parties.
Figure 17: Functionality for Multiplying Two Packed Shared Vectors in F
C.7
A Protocol for Converting Regular Shares to Packed Shares
In this section, we describe the non-interactive share conversion protocol presented in [6]. We slightly
change notation to integrate it into the rest of our presentation. Additionally, because we work in Zp, all
described operations are in Zp.
Let f1,...,fℓbe the degree t + ℓpolynomials that were used for secret sharing secrets s1 ...,sℓre-
spectively such that each fi(z) (for i ∈[ℓ]) is of the form si + qi(z)∏ℓ
j=1(z −ej), where qi is a degree t
polynomial. Then each party Pj (for j ∈[n]) holds shares [s1]Pj,...,[s1]Pj = f1(αj),...,fℓ(αj).
44

The protocol πpack−mult
Inputs: The parties hold shares JaK and JbK.
Protocol: The parties P1,...,Pn proceed as follows:
— Parties invoke fdouble−prand to receive (JrK,⟪r⟫).
— Parties compute ⟪c⟫= JaK ⋅JbK.
— Parties compute ⟪d⟫= ⟪c⟫+ ⟪r⟫and send ⟪d⟫to P1.
— P1 runs open(F,⟪d⟫,n −1) to receive d.
— P1 computes JdK ←pshare(F,d,D) and sends JdKi to party Pi (for each i ∈[n]).
— Parties computes JcK = JdK −JrK
Output: Each party Pi outputs JcKi.
Figure 18: Protocol for Multiplying Two Packed Shared Vectors in F
The Functionality fmult
The functionality fmult running with a set of parties {P1,...,Pn} and the ideal adversary Sim proceeds
as follows:
— fmult receives the set of corrupted parties, denoted Corr ⊂[n].
— fmult receives shares [a] and [b] from all parties.
— fmult receives from the adversary a set of shares {ui}i∈Corr from Sim.
— fmult runs open(F,[a],t) and open(F,[b],t) to obtain a and b.
— fmult computes c = a ⋅b.
— fmult samples a random sharing of c, such that the shares of the corrupted parties are identical
to those received from Sim, i.e., {ui}i∈Corr.
— fmult distributes the shares of c to the honest parties.
Figure 19: Functionality for Multiplying Two Secret Shared Values in F
Given these shares, each party Pj (locally) computes a packed secret share Js1,...,sℓK as follows:
ssToPss(Zp,{fi(αj)}i∈[ℓ]) =
ℓ
∑
i=1
fi(αj)Li(αj) = f(αj)
where Li(αj) = ∏ℓ
j=1,j≠i
(αi−ej)
(ei−ej) is the Lagrange interpolation constant and f corresponds to a new degree
D = t + 2ℓ−1 polynomial for the packed secret sharing Js1,...,sℓK.
Lemma 10. For each i ∈[ℓ], let sa ∈Zp be secret shared using a degree t + ℓpolynomial fi of the form
si +qi(z)∏ℓ
j=1(z −ej), where qi is a degree t polynomial and e1,...,eℓare some pre-determined elements in
45

The protocol πmult
Inputs: The parties hold shares [a] and [b].
Protocol: The parties P1,...,Pn proceed as follows:
— Parties invoke fdouble−rand to receive ([r],⟨r⟩).
— Parties compute ⟨c⟩= [a] ⋅[b].
— Parties compute ⟨d⟩= ⟨c⟩+ ⟨r⟩and send ⟨d⟩to P1.
— P1 runs open(F,⟨d⟩,n −1) to receive d.
— P1 computes [d] ←share(F,d,t) and sends [d]i to party Pi (for each i ∈[n]).
— Parties computes [c] = [d] −[r]
Output: Each party Pi outputs [c]i.
Figure 20: Protocol for Multiplying Two Secret Shared Values in F
Zp. Then for each j ∈[n], ssToPss(Zp,{fi(αj)}i∈[ℓ]) outputs the jth share corresponding to a valid packed
secret sharing of the vector v = (s1,...,sℓ), w.r.t. a degree-D = t + 2ℓ−1 polynomial.
The proof of Lemma 10 can be found in [6].
C.8
Converting Packed Shares to Regular Shares
In this section we describe a sub-protocol for converting packed shares to regular shares. The protocol
begins with the parties generating masks in regular and packed secret shared form. This can be done by
slightly modifying the randomness generation protocols, where each party sends a packed sharing and
regular shares of a vector of random values. The shares received from all parties are then multiplied with
the Vandermonde matrix to obtain the required shares of a batch of n −t sharings. Next, the parties
apply these pack secret shared masks to the pack secret sharing that we want to convert and publicly
reconstruct the values. Finally, the parties can locally remove the masks using the regular shares of the
masks. The total computation complexity for generating the batch of random sharings here is O(n3). But
this randomness generation allows us to generate O(n) sets of randomness that can be used to convert
O(n) packed sharings to regular sharings. Therefore the amortized cost of this step is O(n2). The total
computational complexity of the remaining protocol is O(n2), to convert a vector of O(n) shares. Thus,
the amortized cost of converting packed shares to regular shares is O(n).
Lemma 11. The protocol πpsstoss described in Figure 22 securely computes fpsstoss against a semi-honest
adversary who controls upto t parties.
Proof of this lemma following similarly to that of Lemma 5.
C.9
Permutation
In this section, we present a protocol for permuting a block of pack secret shared vectors. This protocol
is similar to the one presented in [34]. For x1,...,xm ∈F and for each i ∈[k] (where k = m/ℓ), let xi =
(x(i−1)ℓ+1,...,xiℓ). Let pperm be a permutation function that permutes x1,...,xkℓto give z1,...,zkℓ. Set
46

The Functionality fpsstoss
The n-party functionality fpsstoss, running with parties {P1,...,Pn} and the ideal adversary Sim
proceeds as follows:
— fpsstoss receives the set of corrupted parties, denoted Corr ⊂[n].
— fpsstoss receives shares JxK from all parties.
— For each j ∈[ℓ], fpsstoss receives from the adversary a set of shares {uj,i}i∈Corr from Sim.
— fpsstoss runs open(F,[x],D) to obtain x = (x1,...,xℓ)
— For each j ∈[ℓ], fpsstoss computes a random sharing of xj such that the shares of the corrupted
parties are identical to those received from Sim, i.e., {uj,i}i∈Corr.
— For each j ∈[ℓ], fpsstoss distributes the shares of xj to the honest parties.
Figure 21: Functionality for Transforming Packed Secret Sharing to Regular Secret Sharing
The protocol πpsstoss
Inputs: The parties hold the packed sharing JxK to be converted.
Protocol: The parties P1,...,Pn proceed as follows:
— Each party Pi for i ∈[n] samples ui = (ui[1],...,ui[ℓ]) ←$Fℓuniformly at random
and evaluates pshare(F,ui,D) and share(F,ui[j],t) for every j ∈[ℓ] to receive JuiK and
[ui[1]],...,[ui[ℓ]].
— For each i,j ∈[n], party Pi sends JuiKj and [ui[1]]j,...,[ui[ℓ]]j to Pj.
— The parties compute
(Jr1Ki,...,Jrn−tKi) = VT
n,n−t ⋅(Ju1Ki,...,JunKi).
∀j ∈[ℓ],([r1[j]]i,...,[rn−t[j]]i) = VT
n,n−t ⋅([u1[j]]i,...,[un−t[j]]i).
— Parties compute JyK = JxK −Jr1K and send JyK to P1.
— P1 runs open(F,JyK,D) to obtain y = (y1,...,yℓ). It sends y to all other parties.
— For each j ∈[ℓ], parties compute [xj] = yj + [r1[j]].
Output: Each party Pi outputs ([x1]i,...,[xℓ]i).
Figure 22: Protocol for Transforming Packed Secret Sharing to Regular Secret Sharing
zi = (z(i−1)ℓ+1,...,ziℓ), for each i ∈[k]. We want the following permutation functionality fpermute(pperm),
that takes the packed shares Jx1K,...,JxkK as input and outputs the packed shares of the permuted values,
Jz1K,...,JzkK.
Protocol Overview: From the pre-processing step, for each j ∈[k] the parties get packed shares ⟪maskj⟫,
JunmaskjK, where maskj = {rj,1,...,rj,ℓ} (hidden from all parties) are picked at random and unmaskj =
47

The functionality fpermute(pperm)
The functionality fpermute, running with a set of parties {P1,...,Pn} and the ideal adversary Sim
proceeds as follows:
— fpermute receives the set of corrupted parties, denoted Corr ⊂[n].
— fpermute receives shares Jx1K,...,JxkK from all parties.
— For each j ∈[k], fpermute receives from the adversary a set of shares {uj,i}i∈Corr.
— For each j ∈[k], fpermute runs open(F,JxjK,t) to obtain (x(j−1)ℓ+1,...,xjℓ).
— fpermute computes z1,...,zkℓ= pperm(x1,...,xkℓ). For each j ∈[k], set zj = (z(j−1)ℓ+1,...,zjℓ).
— For each j ∈[k], fpermute samples a random sharing of zj, such that the shares of the corrupted
parties are identical to those received from the adversary, i.e., {uj,i}i∈Corr.
— fpermute distributes the shares of z1,...,zk to the honest parties.
Figure 23: Ideal Functionality for Permuting a List of Pack Shared Field Elements
{sj,1,...,sj,ℓ} is computed as: {sj,1,...,sj,ℓ}j∈[k] = pperm({rj,1,...,rj,ℓ}j∈[k]). In Step 1 of the protocol,
the parties locally mask their shares using the ⟪maskj⟫’s, and get the (n −1)-sharings of yj = xj + maskj
for each j ∈[k]. In Steps 2 and 3, P1 opens all the packed shares to get (y1,...,ykℓ) and generates the
permutation z1,...,zkℓ= pperm(y1,...,ykℓ). P1 then sets zj = (z(j−1)ℓ+1,...,zjℓ) for each j ∈[k] and
generates the packed shares Jz1K,...,JzkK. Once all parties receive this, in the final Step 5, the parties
unmask these packed shares using the JunmaskjK’s to get the packed shares Jout1K,...,JoutkK, which
are the desired packed shares of pperm(x1,...,xkℓ). The detailed protocol is as given in Figure 24.
The Protocol πpermute(pperm)
Inputs: Every party Pi holds packed shares of the values to be multiplied (Jx1K,...,JxkK).
Pre-Processing: For each j ∈[k], every party Pi holds packed shares ⟪maskj⟫,JunmaskjK. Here
maskj = {rj,1,...,rj,ℓ} are random vectors unknown to any party and unmaskj = {sj,1,...,sj,ℓ},
such that {sj,1,...,sj,ℓ}j∈[k] = pperm({rj,1,...,rj,ℓ}j∈[k]).
Protocol: The parties (P1,...,Pn) proceed as follows:
1. For each j ∈[k], compute JyjK = JxjK + ⟪maskj⟫and send JyjK to P1.
2. For each j ∈[k], P1 runs open(F,JyjK,n −1) to obtain (y(j−1)ℓ+1,...,yjℓ).
3. P1 computes z1,...,zkℓ= pperm(y1,...,ykℓ) and for each j ∈[k], set zj = (z(j−1)ℓ+1,...,zjℓ).
4. For each j ∈[k], P1 runs JzjK ←pshare(F,zj,D) and sends JzjKi to party Pi (for each i ∈[1,n]).
5. For each j ∈[k], parties compute JoutjK = JzjK + JunmaskjK.
Output: Each party Pi outputs Jout1Ki,...,JoutkKi.
Figure 24: Permuting a List of Pack Shared Field Elements
48

Lemma 12. Protocol πpermute securely computes functionality fpermute against a semi-honest adversary who
corrupts at most t parties.
Proof. The correctness of the protocol follows directly from the discussion in the protocol overview and
the fact that pperm is a linear function.
Security Proof. Let Corr ⊂[n], with ∣Corr∣= t, be the set of corrupted parties. We show how to simulate the
view of Corr in the ideal world, given the input shares (Jx1KCorr,...,JxkKCorr) of the corrupted parties.
The simulator S does the following:
— For the pre-processing step, the simulator samples the sets of random values mask1,⋯,maskk, and
computes unmaskj = {sj,1,...,sj,ℓ} for each j ∈[k], where {sj,1,...,sj,ℓ}j∈[k] = pperm(⋃j∈[k] maskj).
Then, S generates the shares ⟪mask1⟫Corr,...,⟪maskk⟫Corr,Junmask1KCorr,..., JunmaskkKCorr, corre-
sponding to the corrupted parties.
— For Step 1, S can locally compute JyjKCorr = JxjKCorr + ⟪maskj⟫Corr.
— For Steps 2, 3 and 4, S first generates (y1,...,ykℓ) at random, computes z1,...,zkℓ= pperm(y1,...,ykℓ)
and for each j ∈[k], sets zj = (z(j−1)ℓ+1,...,zjℓ). Note that, these intermediate values can be used when
P1 ∈Corr. Finally S generates Jz1KCorr,...,JzkKCorr. This can be done as the yj’s look random to Corr,
by the security of packed secret sharing.
— Finally, S computes and sets the output shares of Corr as JoutjKCorr ∶= JzjKCorr + JunmaskjKCorr for
each j ∈[k].
Note here that for each step, by security of the corresponding packed secret sharing scheme (wherever
mentioned) and as the random maskj’s are hidden from all parties, S generates a distribution that is identi-
cal to the views of Corr in the real world. Hence, the ideal world distribution IDEALfpermute(pperm),Corr,S(1λ,
Jx1K , ...,JxkK), corresponding the functionality fpermute is identical to the real world distribution
REALπpermute,Corr,A(1λ, Jx1K,...,JxkK).
D
Alternate Protocol for Partial Products with Equal Division of Work
In this section, we present an alternative protocol for distributed computation of partial products, where
the work gets equally divided amongst all parties.
For this alternate protocol, the parties are assumed to have packed secret sharing of the following
vectors: Let k = m/ℓ. For each i ∈[k], xi = (x(i−1)ℓ+1,...,xiℓ). Since the order in which the vectors
are packed is different here, correspondingly, we describe the alternate ideal functionality for this order in
Figure 25.
Protocol Overview. In the pre-processing step, for each j ∈[m/ℓ], the parties get packed shares JmaskjK
and JunmaskjK, where maskj ∶= sj ⊙sinv
j , for a random vector sj = ((sj)1,...,(sj)ℓ), unknown to any
party and sinv
j
= ((s−1
j )2,...,(s−1
j )ℓ,(s−1
j+1)1), and unmaskj = ((s−1
1 )1,...,(s−1
1 )1) ⊙sj.
In the main protocol, the first step involves masking the input to compute the packed shares of the
vectors yj = xj ⊙maskj, following which party P1 opens and sends k/n vectors (yj)j=(i−1)k/n+1,...,ik/n
to party Pi, for each i = 2,...,n. In the second step, each party Pi computes the partial product function
Fpart on input of size k/n ⋅ℓ= m/n, to get ((z(i−1)k/n+1)1,...,(z(i−1)k/n+1)ℓ,...,(zik/n)1,...,(zik/n)ℓ).
Here, (zi)j represents the j-th value in vector zi. Then, for each i ∈[n], party Pi sends the last value,
(zik/n)ℓ= (s(i−1)k/n+1)1 ⋅(∏
ik/n
j=(i−1)k/n+1 ∏ℓ
i=1(xj)i) ⋅(sinv
ik/n)ℓto all the parties.
In Step 3, for each i = 2,...,n, Pi computes ∏i−1
j=1(zjk/n)ℓand multiplies it with the vector
that it computed, i.e., ((z(i−1)k/n+1)1,...,(z(i−1)k/n+1)ℓ,...,(zik/n)1,...,(zik/n)ℓ) to get the vectors
49

The functionality fpart−product−2.0
The functionality fpart−product−2.0, running with a set of parties {P1,...,Pn} and the ideal adversary
Sim proceeds as follows:
— fpart−product−2.0 receives the set of corrupted parties, denoted Corr ⊂[n].
— fpart−product−2.0 receives shares Jx1K,...,JxkK from all parties.
— fpart−product−2.0 receives from the adversary a set of shares {ui}i∈Corr.
— For each j ∈[k], fpart−product−2.0 runs open(F,JxjK,D) to obtain (x(j−1)ℓ+1,...,xjℓ).
— fpart−product−2.0 computes (z1,...,zm) ∶= (∏i∈[j] xi)j∈[m].
For each j ∈[m/ℓ], let zj =
(zi)i∈[(j−1)ℓ+1,jℓ].
— fpart−product−2.0 samples a random sharing of zj, such that the shares of the corrupted parties
are identical to those received from the adversary, i.e., {ui,j}i∈Corr.
— fpart−product−2.0 distributes the shares of z1,...,zm/ℓto the honest parties.
Figure 25: Ideal Functionality for Partial Products 2.0
(h(i−1)k/n+1,...,hik/n). Finally, for each j ∈[k], the parties compute the packed shares of unmaskj ⊙hj,
where hj = zj for each j ∈[1,k/n]. Note that from the way that the maskj’s and unmaskj’s are setup, this
final output exactly contains the partial products desired. The detailed protocol is given in Figure 26.
Complexity. It is easy to see that this protocol runs in constant rounds. Moreover, each party is required
to communicate O(m/ℓ+ n) field elements. Each server performs O(m/ℓ) field operations and requires
O(m/ℓ) space complexity. We note that unlike all our other sub-protocols, where the weak servers only
communicate with the large server, this protocol requires every server to talk to every other server.
Lemma 13. Protocol πpart−prod−2.0 securely computes functionality fpart−product−2.0 (c.f. figure 25) in the
fpack−mult-hybrid model against a semi-honest adversary who corrupts at most t parties.
Proof. Correctness. The correctness of the protocol follows directly from the correctness of the underlying
functionality, fpack−mult and the discussion in the protocol overview.
Security Proof. The security of this protocol only holds when xj ≠0, for all j ∈[m], except with a negligible
probability. Let Corr ⊂[n], with ∣Corr∣= t, be the set of corrupted parties. We show how to simulate the
view of Corr in the ideal world, given the input shares (Jx1KCorr,...,JxkKCorr) of the corrupted parties.
The simulator S does the following:
— For the pre-processing,S samples the random vectors maskj and unmaskj as described in the
main protocol.
Then, S generates the shares (Jmask1KCorr,...,JmaskkKCorr),(Junmask1KCorr,...,
JunmaskkKCorr), corresponding to the corrupted parties.
— For Step 1, the parties run the ideal functionality fpack−mult. S can set the shares of the output of this as
shares of some random vectors (by the security of the packed secret sharing), and picks yj at random
for each j ∈[k] (since the maskj’s look random to Corr, the yj’s also look random to Corr. This is true
only because xj’s are all non-zero!).
— For Step 2, S can generate Fpart((y(i−1)k/n+1)1,...,(y(i−1)k/n+1)ℓ,...,(yik/n)1, ...,(yik/n)ℓ) to get
((z(i−1)k/n+1)1,...,(z(i−1)k/n+1)ℓ, ...,(zik/n)1,...,(zik/n)ℓ), for each i ∈Corr.
50

The protocol πpart−prod−2.0
Inputs: Every party Pi holds packed shares of the values to be multiplied (Jx1K,...,JxkK).
Pre-processing: For each j ∈[m/ℓ], every party Pi holds packed shares JmaskjK, and JunmaskjK.
Here, for each j ∈[m/ℓ], maskj ∶= sj⊙sinv
j , where sj = ((sj)1,...,(sj)ℓ) is a random vector, unknown
to any party and sinv
j
= ((s−1
j )2,...,(s−1
j )ℓ,(s−1
j+1)1), and unmaskj = ((s−1
1 )1,...,(s−1
1 )1) ⊙sj.
Protocol: The parties (P1,...,Pn) proceed as follows:
1. Compute JyjK where yj = xj ⊙maskj by computing the following for all j ∈[k]
— Run fpack−mult(F,JxjK,JmaskjK) to receive JyjK and send JyjK to P1.
— P1 runs open(F,JyjK,D) and sends (yj)j=(i−1)k/n+1,...,ik/n to party Pi, for each i =
2,...,n.
2. For each i ∈[n], party Pi computes Fpart((y(i−1)k/n+1)1,...,(y(i−1)k/n+1)ℓ,...,(yik/n)1,...,
(yik/n)ℓ) to get ((z(i−1)k/n+1)1,...,(z(i−1)k/n+1)ℓ,...,(zik/n)1,...,(zik/n)ℓ).
Here, (zi)j
represents the j-th value in vector zi. Then, for each i ∈[n], party Pi sends the last value,
(zik/n)ℓto all the parties.
Note here that each party is computing the partial product of k/n⋅ℓ= m/n inputs, and sending
one field element to every other party.
3. For each i = 2,...,n, party Pi first computes ∏i−1
j=1(zjk/n)ℓand then multiplies it with the
vector that it computed, i.e., ((z(i−1)k/n+1)1,...,(z(i−1)k/n+1)ℓ,...,(zik/n)1,...,(zik/n)ℓ) to
get (h(i−1)k/n+1,...,hik/n). For j ∈[1,k/n], set hj = zj.
4. Finally, for each j ∈[k], run fpack−mult(F,JunmaskjK,hj) to get JoutjK.
Output: Each party Pi outputs {JoutjKi}j∈[k].
Figure 26: Distributed Protocol for Computing Partial Products 2.0 with Equal Division of Work
— For Step 3, since for each i ∈Corr, (z(i−1)k/n)ℓreceived from the party Pi−1 looks random to Pi, S can
pick it at random and multiply it with ((z(i−1)k/n+1)1,...,(z(i−1)k/n+1)ℓ,..., (zik/n)1,...,(zik/n)ℓ) to
get (h(i−1)k/n+1,...,hik/n). If i = 1, S just sets hj = zj for each j ∈[1,k/n].
— Finally, in Step 4 the parties run fpack−mult. S sets the output shares outj’s corresponding to Corr as
shares of random values (by the security of packed secret sharing).
Note here that for each step, by security of the packed secret sharing scheme (wherever mentioned) and
since the yj’s look random to Corr (under our assumption that the xj’s are all non-zero w.h.p.), S gener-
ates a distribution that is identical to the views of Corr in the real world, assuming that the xj’s are all
non-zero. Hence, the ideal world distribution IDEALfpart−product−2.0,Corr,S(1λ,(Jx1K,...,JxkK)), correspond-
ing the functionality fpart−product−2.0 is statistically close to REALπpart−prod−2.0,Corr,A(1λ,(Jx1K,...,JxkK)),
where the parties are all given access to the ideal functionality fpack−mult.
51

