METATOOL BENCHMARK FOR LARGE LANGUAGE
MODELS: DECIDING WHETHER TO USE TOOLS AND
WHICH TO USE
Yue Huang1† ∗, Jiawen Shi2, Yuan Li3, Chenrui Fan2, Siyuan Wu2, Qihui Zhang1†
Yixin Liu1, Pan Zhou2, Yao Wan2, Neil Zhenqiang Gong4, Lichao Sun1∗
Lehigh University1
Huazhong University of Science and Technology2
University of Cambridge3
Duke University4
ABSTRACT
Large language models (LLMs) have garnered significant attention due to their
impressive natural language processing (NLP) capabilities. Recently, many studies
have focused on the tool utilization ability of LLMs. They primarily investigated
how LLMs effectively collaborate with given specific tools. However, in scenarios
where LLMs serve as intelligent agents, as seen in applications like AutoGPT and
MetaGPT, LLMs are expected to engage in intricate decision-making processes
that involve deciding whether to employ a tool and selecting the most suitable
tool(s) from a collection of available tools to fulfill user requests. Therefore, in this
paper, we introduce METATOOL, a benchmark designed to evaluate whether LLMs
have tool usage awareness and can correctly choose tools. Specifically, we create a
dataset called TOOLE within the benchmark. This dataset contains various types
of user queries in the form of prompts that trigger LLMs to use tools, including
both single-tool and multi-tool scenarios. Subsequently, we set the tasks for both
tool usage awareness and tool selection. We define four subtasks from different
perspectives in tool selection, including tool selection with similar choices, tool
selection in specific scenarios , tool selection with possible reliability issues, and
multi-tool selection. We conduct experiments involving nine popular LLMs and
find that the majority of them still struggle to effectively select tools, highlighting
the existing gaps between LLMs and genuine intelligent agents. However, through
the error analysis, we found there is still significant room for improvement. Finally,
we conclude with insights for tool developers that follow ChatGPT to provide
detailed descriptions that can enhance the tool selection performance of LLMs.
Our TOOLE dataset is available at the URL 1 and the code is available in Github 2.
1
INTRODUCTION
Tool-empowered large language models (LLMs) (Qin et al., 2023a;b; Patil et al., 2023; Ruan et al.,
2023; Liang et al., 2023) have recently attracted widespread attention. An important milestone for
LLMs marching toward intelligent agents (Park et al., 2023; Liu et al., 2023b; Zhu et al., 2023) is the
flexible use of tools (e.g., APIs (Qin et al., 2023b; Rapid, 2023) and plugins (OpenAI, 2023d)) to
fulfill users’ requirements. By utilizing tools, LLMs can obtain real-time data, such as getting the
latest weather forecast (GPTStore, 2023); enhance interactions with users, like helping users book
flight tickets (Deng et al., 2023); and better deal with uncertain questions by querying knowledge
∗Correspondence to howiehwong@gmail.com, lis221@lehigh.edu
†Visiting students in
Lehigh University.
1https://atlas.nomic.ai/map/a43a6a84-4453-428a-8738-2534d7bf0b89/
b2b8134b-a37e-45d2-a0d9-765911f27df6
2https://github.com/HowieHwong/MetaTool
1
arXiv:2310.03128v3  [cs.SE]  23 Oct 2023

Table 1: Comparison of previous work and METATOOL.
Dimension
APIBank
GPT4Tool
APIBench
ToolLLM
ToolBench
MetaTool
(Li et al., 2023d)
(Yang et al., 2023c)
(Patil et al., 2023)
(Qin et al., 2023b)
(Xu et al., 2023)
(Ours)
Evaluation Range
③④
③④
③④
③④
③④
①②
Number of Tasks
1
1
1
1
1
4
Reliability Test
✘
✘
✔
✘
✘
✔
Multi-Tool Test
✘
✘
✘
✔
✘
✔
Different Scenarios
✘
✘
✘
✔
✘
✔
Diverse Queries
✘
✘
✘
✘
✘
✔
bases (Li et al., 2023c; Hu et al., 2023) or Internet (Lazaridou et al., 2022). The capacity to use tools
enables LLMs to break through their own limitations, acquire external information, and thereby make
more accurate and effective responses, providing users with better service.
Previous research has focused on how to enhance the ability of LLMs to use tools, including training
models with instruction related to tool usage (Qin et al., 2023b; Tang et al., 2023; Patil et al., 2023;
Schick et al., 2023), or augmenting the model’s problem-solving capabilities for domain-specific
tasks through external APIs (Yang et al., 2023c). A typical process of employing LLMs to use tools
is illustrated in Figure 1. Initially, users input a question (i.e., query) that triggers the tool usage.
Based on prior research (Yang et al., 2023c; Qin et al., 2023b), under the ReAct (Yao et al., 2022)
prompt approach, the process of using tools can be divided into four stages: Firstly, LLMs consider
whether to employ a tool (①) and if so, which tools to select (②). The tool selection process involves
directly having LLMs choose from a provided tool list (Yang et al., 2023c; Ruan et al., 2023) or
selecting via a retriever (Qin et al., 2023b). Next, LLMs configure the users’ input as tool parameters
(③), then handle the results from the tool (④), and finally return the outcomes to the user.
Tool database
①
Thought: Do I need to use a tool?
②
Action: Tool name I want to use.
③
Action Input: The input of the tool.
④
Observation: The results from the tool.
Use tools
Return results
Query
Return results
Can you recommend 
some popular attractions 
in New York City?
Users
LLMs
Figure 1: Tool usage pipeline of LLMs. METATOOL includ-
ing awareness of tool usage (①) and tool selection (②).
With the emergence of more and more
LLMs like open-source Llama2 (Tou-
vron et al., 2023), Vicuna (Chiang
et al., 2023), and closed-source ones
like ChatGPT (OpenAI, 2023a) and
GPT-4 (OpenAI, 2023b), designing a
comprehensive benchmark to measure
the tool-related capability of these
models has become crucial. Current
studies have proposed several bench-
marks (Xu et al., 2023; Qin et al.,
2023b; Li et al., 2023d) about tool us-
age for LLMs, with the main contributions being limited to the stages ③and ④. However, the
awareness of tool usage (①) and tool selection (②) ability are also important for LLMs when they’re
acting as intelligent agents including AutoGPT (Significant-Gravitas, 2023), MetaGPT (geekan,
2023) and BabyAGI (babyagi, 2023), or in the multi-agent environment where LLMs need to
use tools to solve collaborative tasks (Shen et al., 2023; Qian et al., 2023; Park et al., 2023; Cai
et al., 2023). As a result, it is necessary to establish a benchmark to evaluate LLMs’ tool usage
consciousness and tool selection ability.
The difficulty in establishing such a benchmark is reflected in two aspects. The first one is the dataset:
previous research proposed datasets (Qin et al., 2023b; Xu et al., 2023) lacked diverse user inputs,
making it hard to cover various real-world scenarios. Additionally, there is an issue of overlapping
in the dataset, meaning that a user’s needs can be addressed by more than one tool, which makes it
challenging to conduct evaluations since user inputs can correspond to multiple tools. The second
aspect is the task setting: the benchmark should include different tasks to evaluate LLMs from
different perspectives, such as reliability, the performance under different scenarios in daily life. To
address these issues, we propose METATOOL, a benchmark designed to evaluate the awareness of tool
usage and tool selection capability of LLMs. As demonstrated in Table 1, METATOOL distinguishes
itself from previous research efforts and is structured into three primary components:
• TOOLE dataset. We introduce TOOLE, a comprehensive dataset that encompasses a wide range
of 21,127 user queries, with both single-tool and multi-tool queries. Different from the previous
2

What are the trending topics on 
Twitter in U.S.A?
Good day! I’m hoping to find some 
amazing bargains and discounts today. 
Can you guide me in the right direction?
I’m feeling really down today, can 
you summarize this YouTube video 
for me? [Link to YouTube video]
Could you recommend some popular 
shopping malls or markets in New York 
City that offer a wide range of products, 
including local and international brands,
diverse food options, and unique 
shopping experiences?
I can’t tell the 
difference of 
these tools.
Tool selection with similar choices
software engineer
students
Tool selection in specific scenarios
Need: 
Answer 1: 
Answer 2:           
Answer 3: None
(b) Tool Usage Motivation and Tool Selection
(c) Evalation Results
Should I use 
tools to solve 
this query?
(a) Diverse Queries
Need:       
Answer 1: 
Answer 2: 
Answer 3: 
Tool selection with possible 
reliability issues
Multi-tool selection
Figure 2: METATOOL benchmark architecture. It contains the dataset TOOOLE with diverse queries
related to different tools (a), and based on it, we conduct the evaluation of the awareness of tool usage
and tool selection (b) and finally obtain the results of nine prominent LLMs (c). We show the detailed
evaluation result in the radar figure in Appendix F.
single-method generation (Yang et al., 2023c; Qin et al., 2023b), these queries are generated
using various prompting methods, including emotional generation, keyword generation, direct
diverse generation, and detailed generation. Moreover, to address the challenge of overlapping tool
functionality, we undertake tool merging and decomposition.
• Evaluation on awareness of tool usage and tool selection. We construct a test set to evaluate the
awareness of tool usage based on TOOLE and existing instruction datasets. Moreover, we formulate
four distinct tasks to evaluate the tool selection ability of LLMs. These tasks are thoughtfully
designed to assess semantic comprehension, adaptability, reliability, and inferential capability,
namely tool selection with similar choices, tool selection in specific scenarios, tool selection with
possible reliability issues, and multi-tool selection.
• Empirical analysis on results. We rigorously evaluate the performance of nine well-known LLMs.
We have observed that most LLMs struggle to recognize their capability boundaries and lack a
good awareness of tool usage. We study the cases of overconfidence and lack of confidence among
LLMs and also find conflicting perceptions of their abilities. Regarding tool selection, we find that
while LLMs possess basic tool selection capabilities, the tool selection of most LLMs remains
unreliable, with noticeable variations in performance across different daily scenarios. Moreover, the
error analysis indicates there is still room for improvement in tool selection. Finally, by exploring
the relationship between tool descriptions and tool selection effectiveness, we recommend that tool
developers follow ChatGPT’s examples and provide as detailed tool descriptions as possible for
better understanding by LLMs.
2
METATOOL DESIGN
2.1
REQUIRED PROPERTIES AND ABILITIES
The evaluation mainly requires LLMs with the following properties and abilities: (1) Less hallu-
cination and sycophancy. The awareness of tool usage can reflect the truthfulness about whether
an LLM has a clear understanding of its own capabilities (e.g., realizing its capability limitation
about what problems it cannot solve well and using tools for assistance), thereby helping to mitigate
issues of hallucination (Ji et al., 2023) and sycophancy (Wei et al., 2023). (2) Recommendation and
retrieval. Moreover, existing research has tentatively explored the potential of LLMs in applications
like LLM-based recommendation systems (e.g., tool recommendation for users) (Gao et al., 2023;
Wang et al., 2023e; Dai et al., 2023). In LLM-as-agent scenarios, LLMs usually need to select the
specific tool according to the text description (Park et al., 2023; Shen et al., 2023; Ruan et al., 2023),
actually is a kind of information retrieval (Sun et al., 2023), making the ability of tool selection
crucial. (3) Task-level abilities. In METATOOL, we set four tasks as shown in Table 2. Incorporating
similar tools for selection (i.e., Task 1) requires a high-level semantic comprehension for LLMs, and
tool selection in specific scenarios tests the flexibility of LLMs when using tools in different scenarios
3

Human Checking
Multi-Tool Query Generation
(     ,     )
(     ,     )
...
Tool-Description
Emotional Generation
Direct Diverse Generation
Keyword Generation
Details Generation
Single-Tool Query Generation
 Mergence
Decomposition
Overlapped Issue Solving
Figure 3: The process of dataset generation.
(e.g., finance (Wu et al., 2023a) and biomedical domain (Zhang et al., 2023; Wang et al., 2023c)).
Task 3 aims to explore the internal hallucination and reliability extent of LLMs when using tools and
Task 4 is designed to evaluate the inference ability (e.g., order of using multiple tools) (Creswell
et al., 2022) of LLMs.
2.2
TOOLE DATASET
In this section, we introduce the TOOLE dataset with 21.1k diverse user queries related to tool usage.
Each entry within the dataset comprises a user request (i.e., query) along with its corresponding tool
name and tool description. These queries serve as triggers that prompt LLMs to utilize specific tools.
The step-by-step process employed for generating the dataset is shown in Figure 3.
2.2.1
DATASET GENERATION
Tool description. Tool description is important for LLMs to use them (Hsieh et al., 2023). We
retrieve tool names and descriptions from OpenAI’s plugin list (OpenAI, 2023d). The reason for
selecting Open AI plugins as the data source for our tools is that these tools have been installed in
ChatGPT (OpenAI, 2023a) and GPT-4 (OpenAI, 2023b), and they have been widely used, making
them more practical. We obtained names and descriptions for a total of 390 tools across different
domains. We show more details about tool descriptions in Appendix A.5.
Single-tool queries generation. Next, we describe how we generated queries. Inspired by prior
studies (Qin et al., 2023b; Yang et al., 2023c), our approach revolves around incorporating a tool’s
description into a prompt while implementing specific constraints to guide the generation of user
queries by ChatGPT/GPT-4. We adopt four distinct techniques for query creation: direct diverse
generation, emotional generation, keyword generation, and details generation. We show the data
examples generated by different prompt ways in Table 8 of the Appendix A.5. (1) Direct diverse
generation. We introduced conditional criteria within the prompt to encourage ChatGPT/GPT-4 to
produce a variety of query types, encompassing distinct tones (such as requests or orders) and levels
of detail. (2) Emotional generation. Building on prior research (Li et al., 2023a; Goodside, 2023),
which highlights the influence of emotion within prompts on model performance, we augmented the
prompt with constraints to guide ChatGPT in generating content in different emotions. Here we used
four distinct emotions - happiness, excitement, anger, and depression. (3) Keyword generation. Direct
generation occasionally fell short in capturing specific description details, such as tools limited to
particular regions, so we devised the generation way through keywords. This way involved ChatGPT
extracting keywords from the tool’s description and then we incorporated both the extracted keyword
and the tool’s description within the prompt, tasking ChatGPT with generating queries focused on the
given keyword. (4) Details generation. To add more details to the queries, we instructed ChatGPT to
add details to augment the original queries generated by direct diverse generation methods.
Overlapped issue. Overlapped issue refers to a query that can be solved by multiple tools. If left
unaddressed, this overlap could potentially influence the computation of final metrics. For instance,
given a query q, the corresponding tool in our dataset is ta, yet an alternate tool tb could also
feasibly address the same query q. In a single-label scenario, the accuracy of tool selection becomes
compromised. To address this, we merge the group of tools with similar functions as a single tool.
Meanwhile, if a tool can function for multiple purposes across the groups of tools, the corresponding
generated queries cannot be simply merged into any one of them. So decompositions are needed for
the queries of these tools before merging. After decomposition and merging, each query in our dataset
has only one ground truth label. The decomposition and merging operation follows three steps, and
more details about this can be found in Appendix A.1: (1) Embeddings and hierarchical clustering:
4

Table 2: Comparison of four tasks in tool selection.
Task
Tool list
Ideal output
Tool selection with similar choices
Tool t and its most similar (n −1) tools.
t
Tool selection in specific scenarios
Specified tools in a certain scenario.
t
Tool selection with possible reliability issues
The tools randomly chosen are from the remaining set of
tools, which excludes tool t and its k most similar tools.
∅
Multi-tool Selection
The tools randomly chosen are from the remaining set of
tools, which excludes the union set of k most similar tools
of t ∈St, where St is the ground-truth tool set.
St
We created embeddings for tool descriptions and used hierarchical clustering to find patterns. (2)
Tool merging and decomposition: We manually merged or split tools based on functionality, guided
by human expertise and practical considerations. (3) Similarity verification and human validation:
We ensured the quality of merged and decomposed tools through similarity analysis and human
validation. This process yielded a refined set of 198 tools in TOOLE, and we also show the efficiency
of our operation in Appendix A.2 through the silhouette coefficient.
Multi-tool queries generation. Unlike single-tool queries, we generate multi-tool queries only after
addressing the overlapped issue because it is challenging to map the original labels to new labels
in the case of multi-label (i.e., multi-tool) situations. Here, we only consider queries related to two
tools. We observe that if we obtain combinations of two tools by iterating through all the tools (i.e.,
C2
n iterations, where n is the size of the toolset), there would be many tool combinations that are
not practical (i.e., rarely encountered in daily life, such as the combination of fortune-telling tools
and currency exchange tools). Therefore, we select the top 15 most popular tools from the toolset,
and for each pair of tools, we generate 5 queries. We determine the popularity of a tool based on the
number of tools it is merged with, as shown in Appendix A.5. The multi-tool queries we generate
can be divided into two types: The first category pertains to situations where tools are employed in
parallel, indicating that the utilization of each tool operates independently of the others. The second
category deals with cases where tools are used causally, signifying that the deployment of one tool
may be contingent upon the outcomes of a preceding tool. Detailed prompt templates can be found in
Appendix D.2.
Human checking. We conducted manual verification of all queries in TOOLE, including the removal
of non-compliant queries and tools, as well as the handling of queries corresponding to special
categories of tools. Detailed guidelines for human validation are provided in Appendix A.3.
2.3
TASK FORMULATION
We seek to address two research questions in this paper: (1) To what extent can LLMs be conscious
of their limitations and ask for assistance from external tools? (2) How effectively can LLMs select
the tools when they ask for assistance? To answer these questions, we design two tasks based on the
TOOLE dataset to evaluate the capacity of LLMs regarding tool usage.
2.3.1
AWARENESS OF TOOL USAGE
In this part (i.e., Thought (①)), we aim to investigate the awareness of tool usage of LLMs; that
is, whether LLMs can resort to external tools when they encounter problems they cannot solve. To
this end, we need to construct the test set with both positive and negative samples. Positive samples
are the queries that can not be solved by LLMs themselves, and need tool usage, whereas negative
samples are queries that can be directly solved by LLMs and therefore do not necessitate tool usage.
For positive samples, we selected a subset of samples from TOOLE and conducted manual validation
to confirm whether they would trigger LLMs to use the tool (the process of which is detailed in
the Appendix B). As for negative samples, we select three recent instruction datasets, including
instructions about downstream tasks (Wang et al., 2022), common-sense questions (Talmor et al.,
2019), and high-quality instructions used in LIMA (Zhou et al., 2023). Similarly, we conducted
manual verification to ensure that these requests can be resolved by LLMs’ intrinsic capabilities.
Specifically, we use the prompt with a query to inquire the LLMs whether need to employ a tool or
not, and the output of LLMs should be either "yes" or "no".
5

2.3.2
TOOL SELECTION
Preliminary. We propose four subtasks to evaluate LLMs in tool selection 3(i.e., Action phase
(②)). Generally, the prompt comprises a query q ∈Q (i.e., the user’s input) and a tool list Lt
(Lt ⊆T) containing n potential tool candidates. In the single-tool tasks (Task 1∼3), we designate the
corresponding tool for query q as t ∈T. In the multi-tool task (Task 4), this corresponds to St ⊂T
(|St| > 1). Consequently, we obtain yAction ⊆(Lt ∪∅) as the outcome of the tool selection process,
where yAction represents the selected tool(s).
Task 1: tool selection with similar choices. The task is designed to challenge LLMs to select the
correct tool from a tool list containing similar tools, thereby testing their thorough understanding
of tool functionality. Given a query q with its label t, we task LLMs with selecting a tool from the
specified tool list Lt containing n candidates. To construct Lt, we first obtain the embedding of t’s
description, denoted as E(t), where E(·) represents the embedding function (here, we utilize the
text-embedding-ada-002 model (OpenAI, 2023c) to generate embeddings). Denote the most similar
tools of t as top-(n −1)t, which are selected based on the cosine similarity of their embeddings:
top-(n −1)t = arg top-kt′∈T \{t}sim(E(t), E(t′)). Consequently, Lt = {t} ∪top-(n −1)t.
Task 2: tool selection in specific scenarios. The objective of this task is to simulate how LLMs
perform using tools when they act as controllers of a system (Shen et al., 2023) faced with different
scenarios. As LLMs are widely applied across various domains like biomedical domain (Zhang et al.,
2023) and educational domain (Kasneci et al., 2023), in scenarios where the system caters to diverse
demographics or professions (e.g., software engineer (Qian et al., 2023)), its set of tools also varies.
This task allows us to explore the performance disparities of LLMs in selecting different kinds of
tools, essentially highlighting a form of bias inherent to LLMs (Ferrara, 2023). In such cases, this
task examines how effectively LLMs utilize the tools. Given a query q with its label t, we specify
the tool list Lt containing n candidates according to its corresponding scenarios. This task consists
of two types of scenarios: the first one is the popularity-related scenario, and the second one is the
group-related scenario. For the popularity-related scenario, we have selected the 5, 10, and 15 most
popular tools based on the number of tools it’s merged with (refer to Table 9 in the Appendix A.5 for
details.) to construct the tool list. As for the group-related scenario, we chose six usual occupations
or identities and manually curated a tool list consisting of the 10 most relevant tools for each of them
(see Table 10 in the Appendix A.5 for details).
Task 3: tool selection with possible reliability issues. The reliability of LLMs’ tool selection is of
utmost importance. However, issues like hallucination (Ji et al., 2023) and sycophancy (Wei et al.,
2023) within LLMs’ responses will negatively impact their selection of tools. Therefore, we introduce
Task 3. In this task, given a query q and its corresponding tool t, we need to construct the tool list
Lt and ensure t /∈Lt. This aims to assess whether LLMs can answer questions honestly and avoid
issues like choosing non-existent tools or selecting unrelated tools. It should be noted that this task
closely resembles real-world scenarios, as not all existing tools capable of addressing user queries are
present in the tool list controlled by LLMs. To be specific, we obtain the embedding of t’s description
E(t) and get the top-kt similar tools about t as the way in Task 1. Then we randomly sample n tools
from the rest tool set T ′ to construct Lt, denoted as Lt = {t1, t2, ..., tn} where ti ∈T ′(1 ≤i ≤n)
and T ′ = T\({t} ∪top-kt). Overall, we remove the ground-truth tool t of query q and the similar
tools of t to keep the tools in Lt not related to t as much as possible.
Task4: multi-tool selection. In addition to testing the selection of single tools, like previous research
(Qin et al., 2023b), we set up a task for multi-tool selection which may evaluate the inference ability
and more complex semantic comprehension in the tool selection. We tested whether LLMs would
correctly choose the specified tools by inputting multi-tool queries. Specifically, given a query q with
its related tool set St (|St| > 1), we construct the tool list Lt containing n tool candidates (n > |St|).
Like the candidate selection way in task 3, we obtain each tool t’s embedding E(t) where t ∈St, and
get the most k similar tools of t1, t2, ..., t|St|, denoted as top-kt1, top-kt2, ... top-kt|St|. We randomly
select (n−|St|) tools from T ′ = T\(St ∪top-kt1 ∪top-kt2 ∪...∪top-kt|St|). Finally, these (n−|St|)
tools and the tools ∈St consist of the tool list Lt. The reason we do not include the most similar tool
in Lt like task 3 rather than task 1 is that the multi-tool selection task itself is inherently challenging,
and we do not want to further increase the difficulty.
3We separate the prompt of Thought (①) and Action (②) to avoid the influence taken from different tool lists.
6

Table 3: The results for the awareness of tool usage test.
Metric
ChatGPT ChatGLM2 Llama2-7b Llama2-13b Vicuna-7b Vicuna-13b Vicuna-33b Koala-13b Baichuan2
Accuracy
74.85
54.56
53.88
51.94
52.43
61.17
65.05
54.95
51.36
Precision
69.63
61.90
52.71
80.00
74.51
82.49
79.92
55.53
50.84
Recall
88.16
40.39
84.85
6.21
7.38
28.35
40.19
52.62
99.42
F1 Score
77.81
48.88
65.03
11.53
13.43
42.20
53.49
54.04
67.28
Table 4: The CSR (%) for tool selection with similar choices and with possible reliability issues.
Task
ChatGPT ChatGLM2 Llama2-7b Llama2-13b Vicuna-7b Vicuna-13b Vicuna-33b Koala-13b Baichuan2
Similar
69.05
54.17
45.95
44.06
73.46
58.23
53.96
56.34
59.12
Reliable
50.35
6.63
0.90
2.31
1.50
2.51
2.81
1.70
32.26
3
EXPERIMENTS
3.1
EXPERIMENTAL SETUP
Model selection. We have chosen nine models that are currently excelling and popular in this field.
These models include ChatGPT (OpenAI, 2023a), ChatGLM2 (6B) (THUDM, 2023), Llama2 (7b,
13b) (Touvron et al., 2023), Vicuna (7b, 13b, 33b) (Chiang et al., 2023), Baichuan2 (13b) (Baichuan,
2023) and Koala (13b) (Geng et al., 2023).
Prompt template and test samples. Due to the large scale of TOOLE, we sample from it as our
test set (more details are shown in Appendix C). For a better understanding of the importance of
tool usage and to tell LLMs when need to use tools, we add the reasons for tool usage in the prompt
template of Thought (①) part. We show the detailed prompt template in Appendix D.2.
Metrics. For the awareness of tool usage evaluation, we use accuracy, recall, precision, and F1 score
as the metrics. For tool selection, we propose the Correct Selection Rate (CSR) to calculate the
percentage of correct selection action. Denote the output results for all queries as Y = {y1, y2, . . .},
for a specific output y, we use A(y) to denote the tool(s) that the model chooses from the tool list.
The CSR is computed as follows:
CSR =
1
|Y |
X
y∈Y
I
 
A(y) =
( t
for Task 1,2
∅
for Task 3
St
for Task 4
!
(1)
3.2
RESULTS ANALYSIS
Tool usage awareness. We found that most models’ awareness of tool usage is not ideal, as shown
in Table 3. ChatGPT has the best performance in this regard, but only has an accuracy of less than
75%, and the worst-performing model, Llama2-13b, has an F1 Score of only 11.53%. Additionally,
the accuracy of many LLMs is close to the level of random guessing (50%). The awareness of some
LLMs appears polarized, with Baichuan2 essentially considering the use of tools for all queries,
while LLama2-13b and Vicuna-7b are overly confident and rarely choose to use tools in most cases.
We study the failure cases when LLMs are overconfident and lack confidence, and find LLMs have
conflicting perceptions of their own capabilities, as shown in Appendix E.
Tool selection with similar choices. In Table 4, we provide the CSR results for subtask 1 in tool
selection. These results demonstrate that LLMs are generally capable of selecting the appropriate
tools from a list of similar tools. Particularly, Vicuna-7b and ChatGPT exhibit decent performances
with around 70% CSR, whereas other LLMs achieve CSR values fluctuating between 45% and 60%.
Tool selection with possible reliability issues. We show the result of subtask 3 in tool selection in
Table 4. In contrast, most of the LLMs struggle to accomplish it. They fail to realize the absence
of necessary tools within the provided list to address the queries and seven of them get the CSR of
even less than 10%. Nevertheless, ChatGPT maintains a relatively robust performance with a CSR of
7

chatglm2
chatgpt
llama2-7b
llama2-13b
vicuna-7b
vicuna-13b vicuna-33b
koala-13b
baichuan2
Model
0.0
0.2
0.4
0.6
0.8
CSR
Top 5
Top 10
Top 15
Figure 4: The CSR results (%) of top n (n=5,10,15) tool in different scenarios.
0.0
0.2
0.4
0.6
0.8
1.0
Software engineer
0.0
0.2
0.4
0.6
0.8
1.0
Elders
0.0
0.2
0.4
0.6
0.8
1.0
Finance staff
0.0
0.2
0.4
0.6
0.8
1.0
Housewife
0.0
0.2
0.4
0.6
0.8
1.0
Artists&designers
0.0
0.2
0.4
0.6
0.8
1.0
Students
chatglm2
chatgpt
llama2-7b
llama2-13b
vicuna-7b
vicuna-13b
vicuna-33b
koala-13b
baichuan2
Figure 5: The CSR result (%) of tool selection in specific scenarios.
50.35%, and Baichuan2 attains a 32.26% CSR. This indicates that the tool selection for most LLMs
is still unreliable and prone to generating hallucination issues.
Tool selection in specific scenarios. In Figure 4, we present the results of tool selection based on
popularity, revealing that as the size of tool lists increases, the performance of most LLMs declines.
Notably, among open-source models, Vicuna-33b stands out, even surpassing ChatGPT in the top
5 selection settings. All LLMs have a more significant performance decline when the size of the
tool list changes from five to ten. Additionally, ChatGPT exhibits remarkable stability, with only a
minor decline in CSR as the size of tool lists grows, indicating consistent performance. Furthermore,
ChatGLM2, with a relatively modest 6 billion parameters, emerges as the only model among those
with smaller parameter sizes in the top 5 to achieve a CSR value exceeding 80%.
We show the group-related scenario results in Figure 5. It can be observed that LLMs perform the
worst when dealing with tools related to students, while the performance is relatively better with
tools related to elders. This observation encourages tool developers to write more understandable
tool descriptions to help LLMs better grasp the functionalities of the tools. Additionally, we found
that ChatGPT and Vicuna-13b generally outperformed in six different scenarios, whereas Llama2-
13b exhibited the worst performance. This observation highlights the substantial differences in
performance among LLMs when tasked with selecting tools in varying scenarios. As a result,
choosing the appropriate LLM is crucial in specific domains such as medicine and education, which
cater to a diverse array of demographics and professions.
Multi-tool selection. The results of multi-tool selection are shown in Table 5. Surprisingly, in the
multi-tool selection, LLMs’ performance variance is greater compared to single-tool tasks. ChatGPT
excels with a performance of 2/2 CSR exceeding 80%. In contrast, Baichuan2 performs the worst,
with a 2/2 CSR of less than 20%. Furthermore, when compared to the single-tool selection, ChatGPT,
Llama2-13b, and Vicuna-13b exhibit significant improvements, while the performance of other
LLMs has declined. It’s also worth noting that the 2/2 CSR result for Vicuna-33b is inferior to
8

Table 5: Multi-tool selection results. We consider the different kinds of CSR (%): the LLM selects
two correct tools (2/2 CSR), selects only one tool and it’s correct (1/1 CSR), and selects two but only
one is correct (1/2 CSR).
Metric
ChatGPT ChatGLM2 Llama2-7b Llama2-13b Vicuna-7b Vicuna-13b Vicuna-33b Koala-13b Baichuan2
2/2 (CSR)
88.28
20.20
35.69
81.49
44.06
83.70
48.69
39.03
18.26
1/1 (CSR)
3.03
36.57
21.98
0.00
25.55
1.01
48.49
1.61
1.52
1/2 (CSR)
1.01
13.94
8.87
11.07
7.04
8.05
0.20
20.32
13.48
Table 6: Error analysis results.
Top@k ChatGPT ChatGLM2 Llama2-7b Llama2-13b Vicuna-7b Vicuna-13b Vicuna-33b Koala-13b Baichuan2
Top@1
18.44
19.89
14.37
15.12
15.03
15.91
16.62
15.04
23.68
Top@3
34.29
36.48
34.08
34.94
34.43
35.94
35.09
35.34
34.25
Top@5
47.26
43.63
51.41
49.81
50.55
48.15
48.28
49.62
41.88
that of Vicuna-13b, which is because Vicuna-33b tends to favor selecting a single tool and lacks a
comprehensive understanding of user queries.
Error analysis. We further investigate the reasons for errors in LLM’s tool selection. Initially, we
employ the Top@k metric to analyze failure cases in tool selection with similar choices, as shown
in Table 6. The Top@k metric quantifies the proportion of incorrect choices by the model that are
ranked within the Top@k positions of the similarity-ranked list which suggests that, despite being
incorrect, the choices made by the model often retain a degree of similarity to the correct tool. For
instance, Baichuan2 demonstrates the best performance of the Top@1, while Llama2-7b exhibited
the worst performance. In general, all LLMs have a nearly 50% chance of choosing a tool from the
Top@5 most similar to the correct tool, and more than a 15% chance of choosing the most similar
one (i.e., Top@1). This suggests that there is still significant room for improvement in tool selection
with LLMs.
3.3
INSIGHTS FOR TOOL DEVELOPER
0
10
20
30
40
50
Description Length
0.2
0.4
0.6
0.8
1.0
CSR
New tool
Original tool
Fit Line
Avg CSR (New)
Avg CSR (Original)
Figure 6: The error rate of tool selection
and description length.
The description of tools is crucial for the accurate selection
of tools by the model. Therefore, we also investigated the
relationship between tool descriptions and CSR. Specif-
ically, we obtained each tool t ∈T. We calculated CSR
for the queries corresponding to t and visualized them in
Figure 6. There are two categories of tools: those that
have been decomposed and merged (i.e., new tools) which
the description is generated by ChatGPT, and those that
have not been merged or decomposed (i.e., original tools),
which the description is written by tool developers. From
the figure, we can draw the following conclusions: (1)
The more detailed the description, the more efficient
tool selection. As shown by the fitted line, as the length of
the description increases, the CSR continuously increases,
indicating that detailed descriptions can help LLMs better
understand the functionality of tools, thus improving the
accuracy of tool selection. (2) Tool descriptions gener-
ated by ChatGPT are better than those provided by
tool developers. It can be observed that the average CSR
for new tools is significantly higher than that of the origi-
nal tools, indicating that descriptions written by ChatGPT have higher quality and are more easily
understood by LLMs.
9

4
CONCLUSION
In this paper, we introduce METATOOL, a benchmark for evaluating LLMs based on their tool usage
awareness and tool selection capabilities. We propose TOOLE within the benchmark, which contains
diverse queries to trigger LLMs to use tools. In our evaluation of nine prominent LLMs, we found that
most LLMs lack good tool usage awareness and exhibit a significant gap from real intelligent agents
in tool selection. Through error analysis, we identify substantial room for improvement in LLMs.
Additionally, we recommend that developers of relevant tools provide more detailed descriptions to
encourage better understanding by LLMs.
10

REFERENCES
Nomic AI. Nomic ai, 2023. https://atlas.nomic.ai/.
Abid Ali Awan. The 10 best chatgpt plugins for data science, 2023. https://www.datacamp.
com/blog/the-10-best-chat-gpt-plugins-for-data-science.
babyagi. Babyagi, 2023. https://github.com/yoheinakajima/babyagi.
Baichuan. Baichuan 2: Open large-scale language models. arXiv preprint arXiv:2309.10305, 2023.
URL https://arxiv.org/abs/2309.10305.
NATALY BIRCH and ANDRIAN VALEANU. 16 best ai tools for web designers, 2023. https:
//designmodo.com/ai-tools-designers/.
Adrian Bridgwater. Auto-tech series - octoml: Large language model (llm) automation for develop-
ers, 2023. https://www.computerweekly.com/blog/CW-Developer-Network/
Auto-tech-series-OctoML-Large-Language-Model-LLM-automation-for-developers.
Tianle Cai, Xuezhi Wang, Tengyu Ma, Xinyun Chen, and Denny Zhou. Large language models as
tool makers. arXiv preprint arXiv:2305.17126, 2023.
Feilong Chen, Minglun Han, Haozhi Zhao, Qingyang Zhang, Jing Shi, Shuang Xu, and Bo Xu. X-llm:
Bootstrapping advanced large language models by treating multi-modalities as foreign languages.
ArXiv, abs/2305.04160, 2023. URL https://api.semanticscholar.org/CorpusID:
258558106.
Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng,
Siyuan Zhuang, Yonghao Zhuang, Joseph E. Gonzalez, Ion Stoica, and Eric P. Xing. Vicuna: An
open-source chatbot impressing gpt-4 with 90%* chatgpt quality, March 2023. URL https:
//lmsys.org/blog/2023-03-30-vicuna/.
Antonia Creswell, Murray Shanahan, and Irina Higgins. Selection-inference: Exploiting large
language models for interpretable logical reasoning. arXiv preprint arXiv:2205.09712, 2022.
Sunhao Dai, Ninglu Shao, Haiyuan Zhao, Weijie Yu, Zihua Si, Chen Xu, Zhongxiang Sun, Xiao
Zhang, and Jun Xu. Uncovering chatgpt’s capabilities in recommender systems. arXiv preprint
arXiv:2305.02182, 2023.
debbie.
25 best online housewife jobs you can apply to right now, 2020.
https://www.
theoffbeatlife.com/online-housewife-jobs/.
Xiang Deng, Yu Gu, Boyuan Zheng, Shijie Chen, Samuel Stevens, Boshi Wang, Huan Sun, and
Yu Su. Mind2web: Towards a generalist agent for the web. arXiv preprint arXiv:2306.06070,
2023.
Emilio Ferrara. Should chatgpt be biased? challenges and risks of bias in large language models.
arXiv preprint arXiv:2304.03738, 2023.
Yunfan Gao, Tao Sheng, Youlin Xiang, Yun Xiong, Haofen Wang, and Jiawei Zhang.
Chat-
rec: Towards interactive and explainable llms-augmented recommender system. arXiv preprint
arXiv:2303.14524, 2023.
geekan. Metagpt, 2023. https://github.com/geekan/MetaGPT.
Xinyang Geng, Arnav Gudibande, Hao Liu, Eric Wallace, Pieter Abbeel, Sergey Levine, and
Dawn Song. Koala: A dialogue model for academic research. Blog post, April 2023. URL
https://bair.berkeley.edu/blog/2023/04/03/koala/.
Riley
Goodside.
The
past
and
future
of
prompt
engineer-
ing,
2023.
https://exchange.scale.com/public/videos/
the-past-and-future-of-prompt-engineering-2023-08-23.
GPTStore. Overview of ai/chatgpt plugin weather, 2023. https://gptstore.ai/plugins/
weather--vicentescode-repl-co.
11

Level
Up
Coding
Youssef
Hosni.
9
helpful
chatgpt
plugins
for
data
scientists,
2023.
https://levelup.gitconnected.com/
9-helpful-chatgpt-plugins-for-data-scientists-32eceb8d07a8.
Cheng-Yu Hsieh, Si-An Chen, Chun-Liang Li, Yasuhisa Fujii, Alexander Ratner, Chen-Yu Lee,
Ranjay Krishna, and Tomas Pfister. Tool documentation enables zero-shot tool-usage with large
language models. arXiv preprint arXiv:2308.00675, 2023.
Chenxu Hu, Jie Fu, Chenzhuang Du, Simian Luo, Junbo Zhao, and Hang Zhao. Chatdb: Augmenting
llms with databases as their symbolic memory. arXiv preprint arXiv:2306.03901, 2023.
Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Ye Jin Bang,
Andrea Madotto, and Pascale Fung. Survey of hallucination in natural language generation. ACM
Computing Surveys, 55(12):1–38, 2023.
Vartika Kashyap. 26 best designer tools for web and graphic design professionals, 2023. https:
//www.proofhub.com/articles/designer-tools.
Enkelejda Kasneci, Kathrin Seßler, Stefan Küchemann, Maria Bannert, Daryna Dementieva, Frank
Fischer, Urs Gasser, Georg Groh, Stephan Günnemann, Eyke Hüllermeier, et al. Chatgpt for good?
on opportunities and challenges of large language models for education. Learning and individual
differences, 103:102274, 2023.
Lace. 5 must-have android apps for housewives to simplify life, 2022. https://joyofandroid.
com/must-have-android-apps-for-housewives/.
Angeliki Lazaridou, Elena Gribovskaya, Wojciech Stokowiec, and Nikolai Grigorev. Internet-
augmented language models through few-shot prompting for open-domain question answering.
arXiv preprint arXiv:2203.05115, 2022.
Cheng Li, Jindong Wang, Kaijie Zhu, Yixuan Zhang, Wenxin Hou, Jianxun Lian, and Xing Xie.
Emotionprompt: Leveraging psychology for large language models enhancement via emotional
stimulus. arXiv preprint arXiv:2307.11760, 2023a.
Chunyuan Li, Cliff Wong, Sheng Zhang, Naoto Usuyama, Haotian Liu, Jianwei Yang, Tristan
Naumann, Hoifung Poon, and Jianfeng Gao. Llava-med: Training a large language-and-vision
assistant for biomedicine in one day. ArXiv, abs/2306.00890, 2023b. URL https://api.
semanticscholar.org/CorpusID:258999820.
Jinyang Li, Binyuan Hui, Ge Qu, Binhua Li, Jiaxi Yang, Bowen Li, Bailin Wang, Bowen Qin, Rongyu
Cao, Ruiying Geng, et al. Can llm already serve as a database interface? a big bench for large-scale
database grounded text-to-sqls. arXiv preprint arXiv:2305.03111, 2023c.
Minghao Li, Feifan Song, Bowen Yu, Haiyang Yu, Zhoujun Li, Fei Huang, and Yongbin Li. Api-bank:
A benchmark for tool-augmented llms. arXiv preprint arXiv:2304.08244, 2023d.
Yaobo Liang, Chenfei Wu, Ting Song, Wenshan Wu, Yan Xia, Yu Liu, Yang Ou, Shuai Lu, Lei Ji,
Shaoguang Mao, et al. Taskmatrix. ai: Completing tasks by connecting foundation models with
millions of apis. arXiv preprint arXiv:2303.16434, 2023.
Gemingtian Liu, Xinyu Ma, Yu Zhang, Boyan Su, and Pinan Liu. Gpt4: The indispensable helper for
neurosurgeons in the new era. Annals of Biomedical Engineering, 51:2113 – 2115, 2023a. URL
https://api.semanticscholar.org/CorpusID:258787338.
Xiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu Lai, Yu Gu, Hangliang Ding,
Kaiwen Men, Kejuan Yang, et al.
Agentbench: Evaluating llms as agents.
arXiv preprint
arXiv:2308.03688, 2023b.
Chenyang Lyu, Minghao Wu, Longyue Wang, Xinting Huang, Bingshuai Liu, Zefeng Du, Shuming
Shi, and Zhaopeng Tu. Macaw-llm: Multi-modal language modeling with image, audio, video,
and text integration. ArXiv, abs/2306.09093, 2023. URL https://api.semanticscholar.
org/CorpusID:259165461.
12

Teresa
Mears.
10
essential
tech
tools
for
older
adults,
2015.
https:
//money.usnews.com/money/retirement/articles/2015/11/16/
10-essential-tech-tools-for-older-adults.
Ofer Mendelevitch. Large language models for code generation – part 2, 2023. https://vectara.
com/large-language-models-llms-for-code-generation-part-2/.
Manuel
Odendahl.
Llms
will
fundamentally
change
soft-
ware
engineering,
2023.
https://dev.to/wesen/
llms-will-fundamentally-change-software-engineering-3oj8.
OpenAI. Introducing chatgpt, 2023a. URL https://openai.com/blog/chatgpt.
OpenAI. Gpt-4 technical report. 2023b. URL https://arxiv.org/pdf/2303.08774.pdf.
OpenAI.
new-and-improved-embedding-model, 2023c.
https://openai.com/blog/
new-and-improved-embedding-model.
OpenAI. Openai plugin, 2023d. https://openai.com/blog/chatgpt-plugins.
Joon Sung Park, Joseph C O’Brien, Carrie J Cai, Meredith Ringel Morris, Percy Liang, and
Michael S Bernstein. Generative agents: Interactive simulacra of human behavior. arXiv preprint
arXiv:2304.03442, 2023.
Shishir G Patil, Tianjun Zhang, Xin Wang, and Joseph E Gonzalez. Gorilla: Large language model
connected with massive apis. arXiv preprint arXiv:2305.15334, 2023.
Zhi Qi, Yi Yu, Meiqi Tu, Junyi Tan, and Yongfeng Huang. Foodgpt: A large language model in food
testing domain with incremental pre-training and knowledge graph prompt. ArXiv, abs/2308.10173,
2023. URL https://api.semanticscholar.org/CorpusID:261048937.
Chen Qian, Xin Cong, Cheng Yang, Weize Chen, Yusheng Su, Juyuan Xu, Zhiyuan Liu, and Maosong
Sun. Communicative agents for software development. arXiv preprint arXiv:2307.07924, 2023.
Yujia Qin, Shengding Hu, Yankai Lin, Weize Chen, Ning Ding, Ganqu Cui, Zheni Zeng, Yufei
Huang, Chaojun Xiao, Chi Han, et al. Tool learning with foundation models. arXiv preprint
arXiv:2304.08354, 2023a.
Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan Yan, Yaxi Lu, Yankai Lin, Xin Cong, Xiangru
Tang, Bill Qian, et al. Toolllm: Facilitating large language models to master 16000+ real-world
apis. arXiv preprint arXiv:2307.16789, 2023b.
Salvatore Raieli.
Fingpt:
open-source llm for finance, 2023.
https://levelup.
gitconnected.com/fingpt-open-source-llm-for-finance-e8ec10d0bf40.
Rapid. Rapid api, 2023. https://rapidapi.com/.
Peter J Rousseeuw. Silhouettes: a graphical aid to the interpretation and validation of cluster analysis.
Journal of computational and applied mathematics, 20:53–65, 1987.
Jingqing Ruan, Yihong Chen, Bin Zhang, Zhiwei Xu, Tianpeng Bao, Guoqing Du, Shiwei Shi,
Hangyu Mao, Xingyu Zeng, and Rui Zhao. Tptu: Task planning and tool usage of large language
model-based ai agents. arXiv preprint arXiv:2308.03427, 2023.
Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer,
Nicola Cancedda, and Thomas Scialom. Toolformer: Language models can teach themselves to
use tools. arXiv preprint arXiv:2302.04761, 2023.
National Science and Technology Council. Emerging technologies to support an aging popula-
tion, 2019. https://trumpwhitehouse.archives.gov/wp-content/uploads/
2019/03/Emerging-Tech-to-Support-Aging-2019.pdf.
Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming Lu, and Yueting Zhuang. Hugginggpt:
Solving ai tasks with chatgpt and its friends in huggingface. arXiv preprint arXiv:2303.17580,
2023.
13

Significant-Gravitas. Autogpt, 2023. https://github.com/Significant-Gravitas/
Auto-GPT.
Peter HA Sneath, Robert R Sokal, et al. Numerical taxonomy. The principles and practice of
numerical classification. 1973.
Weiwei Sun, Lingyong Yan, Xinyu Ma, Pengjie Ren, Dawei Yin, and Zhaochun Ren. Is chat-
gpt good at search? investigating large language models as re-ranking agent. arXiv preprint
arXiv:2304.09542, 2023.
Alon Talmor, Jonathan Herzig, Nicholas Lourie, and Jonathan Berant. CommonsenseQA: A question
answering challenge targeting commonsense knowledge. In Proceedings of the 2019 Conference of
the North American Chapter of the Association for Computational Linguistics: Human Language
Technologies, Volume 1 (Long and Short Papers), pp. 4149–4158, Minneapolis, Minnesota, June
2019. Association for Computational Linguistics. doi: 10.18653/v1/N19-1421. URL https:
//aclanthology.org/N19-1421.
Qiaoyu Tang, Ziliang Deng, Hongyu Lin, Xianpei Han, Qiao Liang, and Le Sun. Toolalpaca: General-
ized tool learning for language models with 3000 simulated cases. arXiv preprint arXiv:2306.05301,
2023.
ODSC
Team.
Have
you
met
fingpt?
a
new
open-source
financial
large
language
model,
2023.
https://opendatascience.com/
have-you-met-fingpt-a-new-open-source-financial-large-language-model/.
THUDM. Chatglm2, 2023. https://github.com/THUDM/ChatGLM2-6B.
A.I For Women Today. 10 genius ways housewives can use chatgpt to save money, 2023. https:
//www.youtube.com/watch?v=OZB45aP8rZ4.
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay
Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. Llama 2: Open foundation
and fine-tuned chat models. arXiv preprint arXiv:2307.09288, 2023.
Laurens Van der Maaten and Geoffrey Hinton. Visualizing data using t-sne. Journal of machine
learning research, 9(11), 2008.
Nicolas
Vidal.
How
ai
and
llms
are
streamlining
financial
services,
2023.
https://www.forbes.com/sites/forbestechcouncil/2023/05/05/
how-ai-and-llms-are-streamlining-financial-services/?sh=
2ea8b923017a.
Leandro von Werra and Loubna Ben Allal. Starcoder: A state-of-the-art llm for code, 2023. https:
//huggingface.co/blog/starcoder.
Guangyu Wang, Guoxing Yang, Zongxin Du, Longjun Fan, and Xiaohu Li.
Clinicalgpt:
Large language models finetuned with diverse medical data and comprehensive evaluation.
ArXiv, abs/2306.09968, 2023a. URL https://api.semanticscholar.org/CorpusID:
259187929.
Hao Wang, Chi-Liang Liu, Nuwa Xi, Zewen Qiang, Sendong Zhao, Bing Qin, and Ting Liu. Huatuo:
Tuning llama model with chinese medical knowledge. ArXiv, abs/2304.06975, 2023b. URL
https://api.semanticscholar.org/CorpusID:258170497.
Haochun Wang, Chi Liu, Nuwa Xi, Zewen Qiang, Sendong Zhao, Bing Qin, and Ting Liu. Huatuo:
Tuning llama model with chinese medical knowledge. arXiv preprint arXiv:2304.06975, 2023c.
Wen Wang, Zhe Chen, Xiaokang Chen, Jiannan Wu, Xizhou Zhu, Gang Zeng, Ping Luo, Tong
Lu, Jie Zhou, Y. Qiao, and Jifeng Dai.
Visionllm: Large language model is also an open-
ended decoder for vision-centric tasks. ArXiv, abs/2305.11175, 2023d. URL https://api.
semanticscholar.org/CorpusID:258762579.
14

Xiaolei Wang, Xinyu Tang, Wayne Xin Zhao, Jingyuan Wang, and Ji-Rong Wen. Rethinking the
evaluation for conversational recommendation in the era of large language models. arXiv preprint
arXiv:2305.13112, 2023e.
Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A. Smith, Daniel Khashabi, and
Hannaneh Hajishirzi. Self-instruct: Aligning language model with self generated instructions,
2022.
Jerry Wei, Da Huang, Yifeng Lu, Denny Zhou, and Quoc V Le. Simple synthetic data reduces
sycophancy in large language models. arXiv preprint arXiv:2308.03958, 2023.
Matt Welsh.
The future of software development with llms is here:
Announcing fixie’s
developer preview and 17m in seed funding,
2023.
https://blog.fixie.ai/
the-future-of-software-development-with-llms-is-here-announcing-fixies-developer-p
Stephen
Wolfram
Writings.
Chatgpt
gets
its
“wolfram
superpowers”!,
2023.
https://writings.stephenwolfram.com/2023/03/
chatgpt-gets-its-wolfram-superpowers/.
Shijie Wu, Ozan Irsoy, Steven Lu, Vadim Dabravolski, Mark Dredze, Sebastian Gehrmann, Prabhan-
jan Kambadur, David Rosenberg, and Gideon Mann. Bloomberggpt: A large language model for
finance. arXiv preprint arXiv:2303.17564, 2023a.
Shijie Wu, Ozan Irsoy, Steven Lu, Vadim Dabravolski, Mark Dredze, Sebastian Gehrmann, Prabhan-
jan Kambadur, David Rosenberg, and Gideon Mann. Bloomberggpt: A large language model for
finance. arXiv preprint arXiv:2303.17564, 2023b.
Daniel Xiao. Ai-based literature review tools, 2023. https://tamu.libguides.com/c.
php?g=1289555.
Qiantong Xu, Fenglu Hong, Bo Li, Changran Hu, Zhengyu Chen, and Jian Zhang. On the tool
manipulation capability of open-source large language models. arXiv preprint arXiv:2305.16504,
2023.
Hongyang Yang, Xiao-Yang Liu, and Chris Wang. Fingpt: Open-source financial large language
models. ArXiv, abs/2306.06031, 2023a. URL https://api.semanticscholar.org/
CorpusID:259129734.
Hongyang Yang, Xiao-Yang Liu, and Christina Dan Wang. Fingpt: Open-source financial large
language models. arXiv preprint arXiv:2306.06031, 2023b.
Rui Yang, Lin Song, Yanwei Li, Sijie Zhao, Yixiao Ge, Xiu Li, and Ying Shan. Gpt4tools: Teaching
large language model to use tools via self-instruction. arXiv preprint arXiv:2305.18752, 2023c.
Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao.
React: Synergizing reasoning and acting in language models. arXiv preprint arXiv:2210.03629,
2022.
Zheng Yuan, Hongyi Yuan, Chuanqi Tan, Wei Wang, and Songfang Huang. How well do large
language models perform in arithmetic tasks? arXiv preprint arXiv:2304.02015, 2023. URL
https://arxiv.org/abs/2304.02015.
Jennifer
Zhang.
Unleashing
the
potential
of
llms:
a
new
era
for
financial
services,
2023.
https://www.wiz.ai/
unleashing-the-potential-of-llms-a-new-era-for-financial-services/.
Kai Zhang, Jun Yu, Zhiling Yan, Yixin Liu, Eashan Adhikarla, Sunyang Fu, Xun Chen, Chen Chen,
Yuyin Zhou, Xiang Li, et al. Biomedgpt: A unified and generalist biomedical generative pre-trained
transformer for vision, language, and multimodal tasks. arXiv preprint arXiv:2305.17100, 2023.
Chunting Zhou, Pengfei Liu, Puxin Xu, Srini Iyer, Jiao Sun, Yuning Mao, Xuezhe Ma, Avia Efrat,
Ping Yu, Lili Yu, et al. Lima: Less is more for alignment. arXiv preprint arXiv:2305.11206, 2023.
15

Xizhou Zhu, Yuntao Chen, Hao Tian, Chenxin Tao, Weijie Su, Chenyu Yang, Gao Huang, Bin Li,
Lewei Lu, Xiaogang Wang, et al. Ghost in the minecraft: Generally capable agents for open-world
enviroments via large language models with text-based knowledge and memory. arXiv preprint
arXiv:2305.17144, 2023.
16

Appendix
Table of Contents
A
TOOLE Dataset Details
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
17
A.1
Details of Overlapped Issue
. . . . . . . . . . . . . . . . . . . . . . . . . . .
17
A.2
Efficiency of the Operation . . . . . . . . . . . . . . . . . . . . . . . . . . . .
18
A.3
Guidelines for human validation . . . . . . . . . . . . . . . . . . . . . . . . .
19
A.4
Flexibility of TOOLE
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
19
A.5
Others Statistics of TOOLE . . . . . . . . . . . . . . . . . . . . . . . . . . . .
20
B
Test Set for Evaluation on the Awareness of Tool Usage . . . . . . . . . . . . . . .
22
C
Experimental Settings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
23
C.1
Models and Test Samples . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
23
C.2
Answer Matching . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
23
D
Prompt Template . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
23
D.1
TOOLE Dataset Generation . . . . . . . . . . . . . . . . . . . . . . . . . . . .
23
D.2
Prompt Template of Experiments . . . . . . . . . . . . . . . . . . . . . . . . .
26
E
Failure Case Study . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
27
F
Radar Figures
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
29
A
TOOLE DATASET DETAILS
In this section, we show the details of TOOLE, including how we solve the overlapped issue (Section
A.1), guidelines for human validation (Section A.3), and the statistics of TOOLE (Section A.5).
A.1
DETAILS OF OVERLAPPED ISSUE
WeatherTool: Provide you with 
the latest weather information. 
MixerBox_Weather: Get real-
time worldwide weather 
updates & forecasts, instantly! 
Weather_Forecast: WeatherWhiz: 
Accurate current weather and 
forecasts for any location.
...
SummarizeAnything_pr: 
Summarize YouTube videos, web 
pages, and PDF documents ...
PDF&URLTool: Interact with 
any PDF files, provide page 
references for fact-checking, ...
VideoSummarizeTool: 
Eneble summaries from 
YouTube video links, ...
...
Tool decomposition
Tool mergence
Figure 7: Two examples of tool mergence and
decomposition.
Operation pipeline. (1) Embeddings and Hi-
erarchical Clustering. We initiated by gener-
ating embeddings for tool descriptions using
the text-embedding-ada-002 model (OpenAI,
2023c), an API provided by OpenAI, aiming to
perform hierarchical clustering (Sneath et al.,
1973) on different tools, based on the similar-
ity of their embeddings, to reveal underlying
patterns among them. (2) Tool Merging and De-
composition. Based on the results of clustering,
we manually merged and decomposed the data.
Specifically, several popular topics (e.g., news,
weather) were identified based on their functions
if they overlapped functionality with other tools
(an example is shown in Figure 7). The criteria
for merging and decomposition revolved around whether such tools are commonly encountered and
make practical sense in daily life. For instance, it is logical to merge a tool that offers both flight and
train ticket bookings with another tool that solely focuses on hotel reservations. For merged tools,
we only needed to modify the original labels; for decomposed tools, we manually assigned original
queries to the appropriate decomposed tools and changed their labels accordingly. We manually
17

20
10
0
10
20
Dimension 1
20
10
0
10
20
Dimension 2
0
5
10
15
20
25
Cluster Label
(a)
15
10
5
0
5
10
15
Dimension 1
10
5
0
5
10
15
Dimension 2
0
5
10
15
20
25
Cluster Label
(b)
Figure 8: t-SNE (Van der Maaten & Hinton, 2008) visualization of original tool description embed-
ding (a) and new tool description embedding (b).
10
20
30
40
50
Cluster Number
0.015
0.020
0.025
0.030
0.035
0.040
0.045
Score
New
Original
Figure 9: Silhouette score (Rousseeuw, 1987) of new tool description embedding and original tool
description embedding in different cluster numbers.
created the names of new tools and employed ChatGPT to generate descriptions for both merged
and decomposed tools, based on the initial descriptions of these tools. (3) Similarity Verification and
Human Validation. We iterated each tool and searched for the ten most similar tools by its description
embedding, then we checked whether the tool could be further merged or decomposed with the tools
in Lsim.
A.2
EFFICIENCY OF THE OPERATION
To evaluate the effectiveness of our operations in solving overlapped issues, we use the silhouette
coefficient (Rousseeuw, 1987) to measure the degree of functional overlap between tools. Based on
it, we compare the changes in the silhouette coefficients before and after the operations. Specifically,
we aim to significantly reduce the functional overlap between tools after merging and decomposition
to achieve a more uniform distribution of tool functionalities in the embedding space. We embed the
tool description before (390 tools) and after the operations (195 tools) and compared the changes
in the silhouette coefficients under the same number of clusters. A greater silhouette coefficient
indicates better clustering performance and higher functional overlap between tools, while a smaller
coefficient suggests lower overlap, reflecting the effectiveness of the operations.
In Figure 9, we present the variation of silhouette coefficients with changes in the number of clusters.
It can be observed that the silhouette coefficients of tools after the operations are significantly smaller
18

than before, indicating that the operations have made the distribution of tools more uniform and
effectively reduced tool functionality overlap. Additionally, in Figure 8, we visualize the results using
t-SNE (Van der Maaten & Hinton, 2008) when the number of clusters is 30. It is evident that the
distribution on the left side is more uniform compared to the right side.
A.3
GUIDELINES FOR HUMAN VALIDATION
We conducted rigorous manual evaluations to ensure the integrity and quality of TOOLE. We estab-
lished the following rules to guide the manual evaluation:
• Low-quality tool descriptions. In some cases, ChatGPT was unable to understand the purpose of a
tool due to low-quality or overly brief tool descriptions. We conducted a manual review of these
descriptions and eliminated tools with unclear or low-quality explanations.
• High repetition queries. Since we generated multiple queries for a single tool in one batch, some
batches had issues with high query repetition. To address this problem, we selected one query and
removed the others.
• Queries contain tool name. The inclusion of a tool’s name in a query can significantly bias our
evaluation as an obvious hint for all tasks in METATOOL. Therefore, we removed queries containing
the tool’s name. For example, ’How can I calculate my MBTI type through [tool name]?’
• Calculation-related tools. TOOLE contained numerous tools related to calculations. For simple
calculations (e.g., ‘What is the value of sin 30 degrees?’ or ‘7 * 9 = ?’), LLMs can perform them
without the need for a tool. However, for complex calculations, recent research (Yuan et al., 2023)
suggests that LLMs still perform poorly. For queries corresponding to calculation-related tools, we
removed queries involving simple calculations and retained those involving complex calculations.
• Tool retrieval-related tools. We found that some tools were designed for users to retrieve other
tools. This kind of tool conflicted with our task, so we removed these tools.
• AI comprehensive tools. We identified some AI comprehensive tools that encompassed a wide
range of AI-related tools, making them impractical for our evaluation. Therefore, we removed
these tools.
• Mentions of ’ChatGPT’ in queries. Some queries included the term ’ChatGPT,’ for example, ’Hi,
ChatGPT! ...’ We uniformly replaced ’ChatGPT’ with ’Chatbot’."
A.4
FLEXIBILITY OF TOOLE
Figure 10: The motivation labeling interface.
Sometimes, when an LLM undergoes special-
ized training in a particular domain (Wu et al.,
2023b; Wang et al., 2023a; Qi et al., 2023; Wang
et al., 2023b; Yang et al., 2023a), its capabili-
ties improve significantly, and in some cases,
some LLMs are also capable of handling vari-
ous types of information (e.g., images or audio)
(Liu et al., 2023a; Chen et al., 2023; Wang et al.,
2023d; Lyu et al., 2023; Li et al., 2023b). These
improvements render some external tools that
may not be necessary for some LLMs in the fu-
ture. Therefore, we have annotated the reasons
why LLMs need to use these tools to solve user
problems.
Specifically, we use four kinds of motivation
for tool usage (some examples are shown in
Table 7): A. Solving issues with real-time or
external data, databases, or APIs. B. Handling
specialized inputs/outputs. C. Enhancing do-
main tasks beyond LLM’s capabilities. D. User
customization, personalization, and interaction.
We have enlisted the expertise of two experts to annotate the usage motivations of tools in TOOLE
(the annotation interface is shown in Figure 10).
19

Table 7: Possible reasons for the motivation of tool usage.
Tool
Description
Reason
airqualityforeast
Planning something outdoors? Get the 2-day air quality forecast
for your city.
A
Now
Get Google Trends. In Japan, you can also get Twitter trends and
search Twitter keywords.
A
abc_to_audio
Converts ABC music notation to WAV, MIDI, and PostScript files.
B
ChatOCR
The best way to read text from from any document. ChatOCR
will scan and read aloud any text document you provide.
B
FinanceTool
Begin an exciting journey through time, interact with historical
events, and learn about the past in a fun and engaging way.
C
LawTool
Enables quick search functionality for relevant laws.
C
TicTacToe
Playing a game of Tic Tac Toe with varying board sizes. You can
submit your move and get the AI’s response move.
D
Planfit
Get your tailored workout plan and instructions with videos - AI-
powered Workout Coach, Planfit.
D
A.5
OTHERS STATISTICS OF TOOLE
0
20
40
60
80
100
Length
0.00
0.01
0.02
0.03
0.04
0.05
Density
Figure 11: Density distribution of all queries’
length.
Data quantity. Due to the constraints of API us-
age costs, we exclusively employ GPT-4 for direct
diverse generation, utilizing ChatGPT for all other
forms of generation techniques. This strategy yielded
a total of 29,000 dataset entries. Following a metic-
ulous human review process, we ultimately curated
the TOOLE dataset, culminating in a collection com-
prising 20,881 entries. A comprehensive overview of
dataset statistics can be found in Table 11.
Length distribution. Figure 11 displays the distri-
bution of dataset lengths. It can be observed that the
majority of the data falls within 40 words or less,
aligning with the typical question lengths in people’s
daily lives.
Visualization and release.
We used Nomic AI
(AI, 2023) to embed user queries in the
TOOLE dataset, then clustered the embeddings, and finally visualized the results.
The
visualization is shown in Figure 12, and you can view it through the following link:
https://atlas.nomic.ai/map/a43a6a84-4453-428a-8738-2534d7bf0b89/
b2b8134b-a37e-45d2-a0d9-765911f27df6.
Tool description. These original tool descriptions encompass two distinct categories: machine-
readable descriptions and user-facing descriptions. The machine-readable descriptions prioritize
considerations such as token context length or keyword incorporation, aiming to enhance tool
prompting within an 8,000-character limit. Conversely, the user-facing descriptions offer succinct
and simplified explanations of each tool’s functionality. While the majority of tools share identical
descriptions across both categories, we opt to adopt the user-facing descriptions as the definitive tool
descriptions. This choice is informed by the tendency of machine-readable descriptions to be overly
verbose, often delving into instructing the language models on how to handle tool input and output –
aspects that are not pertinent to our benchmark.
Generation times. For each type of original tool, we perform two rounds of direct diverse generation,
producing ten queries each time. In the case of emotional generation, we generate five samples for
each of the four distinct emotions. For keyword generation, we extract five keywords from the tool’s
description and subsequently formulate a query for each identified keyword. Concerning details
generation, the number of samples generated aligns with that of the direct diverse generation.
20

Table 8: Data examples in TOOLE.
Example
Type
I can’t seem to remember anything I study. I need help with learning and
retaining information effectively.
Emotion-angry
I’m feeling really down today, can you summarize this YouTube video for me?
[Link to YouTube video]
Emotion-depressed
Good day! I’m hoping to find some amazing bargains and discounts today. Can
you guide me in the right direction?
Emotion-happy
Hey Chatbot, I’m looking for a new pair of sneakers on GoFynd. Can you help
me find the latest designs and recommend some popular brands?
Emotion-excited
I’m interested in Japanese cosmetics. Can you recommend some good brands?
Direct-request
Draw a state diagram for a vending machine.
Direct-order
Twitter Trends: What are the trending topics on Twitter in Japan?
Keyword
Could you recommend some popular shopping malls or markets in Singapore
that offer a wide range of products, including local and international brands,
diverse food options, and unique shopping experiences?
Details
Table 9: Top 15 tools ranked by the number of merged tools.
Tool Name
Merged Tools Tool Name
Merged Tools Tool Name
Merged Tools
FinanceTool
22
ResearchFinder
7
TripAdviceTool
6
ProductSearch
19
NewsTool
7
WeatherTool
6
JobTool
12
RepoTool
6
HousePurchasingTool
5
TripTool
10
ResearchHelper
6
Discount
5
PDF&URLTool
8
CourseTool
6
MusicTool
5
Table 10: The tool lists of different scenarios.
Scenario
Tools
Ref.
Software
Engi-
neer
RepoTool, AI2sql, SSH, AutoInfra1, noteable, dart,
hackit_web_scanner, LarkBaseImporter, webhooks, uni-
versal
(von Werra & Allal, 2023;
Odendahl,
2023;
Welsh,
2023;
Bridgwater,
2023;
Mendelevitch, 2023)
Elders
NewsTool, PolishTool, CharityTool, MapTool, Memo-
ryTool, WeatherTool, RestaurantBookingTool, DietTool,
NotesTool, TripAdviceTool
(Science & Council, 2019;
Mears, 2015)
Finance Staff
FinanceTool, ChartTool, PDF&URLTool, NotesTool, Ex-
changeTool, CreditYelp, LawTool, DataRetrievalTool,
fundsdbsearch, CompanyInfoTool
(Raieli, 2023; Zhang, 2023;
Vidal, 2023; Yang et al.,
2023b; Team, 2023)
Housewife
tira, Discount, ProductSearch, ABCmouse, Restaurant-
BookingTool, IndoorPlants, recipe_retrieval, HouseR-
entingTool, TripTool, CreditYelp
(debbie, 2020; Today, 2023;
Lace, 2022)
Students
CourseTool, ResearchFinder, ResearchHelper, speak,
noteable, search, MemoryTool, NotesTool, Mixer-
Box_Translate_AI_language_tutor, ABCmouse
(Xiao, 2023; Awan, 2023;
Hosni,
2023;
Writings,
2023)
Artists&designers placid, find_agency, ArtCollection, ChartTool, story-
bird_stories, MediaModifyTool, PolishTool, MusicTool,
ImageSearch, BookTool
(Kashyap, 2023; BIRCH &
VALEANU, 2023)
21

Figure 12: TOOLE embedding visualization.
Table 11: Dataset Statistics of TOOLE.
Generation method
Model
Sample number
Direct generation
ChatGPT, GPT-4
11,700
Emotional generation
ChatGPT
7,800
Keyword generation
ChatGPT
1,950
Details generation
ChatGPT
7,800
Multi-tool generation
ChatGPT, GPT-4
1624
After checking →21,127 (20630 single-tool + 497 multi-tool)
B
TEST SET FOR EVALUATION ON THE AWARENESS OF TOOL USAGE
To assess to what extent are LLMs aware of their limitations, we construct the dataset for the
awareness of tool usage by merging the positive samples from a subset of TOOLE dataset and the
negative samples from some subsets of public datasets. To exclude the ambiguous situation where the
queries in TOOLE can be solved either with or without the assistance of external tools, we manually
check the output of the queries by feeding them directly into the LLMs and retain those whose
responses are unsatisfactory(i.e. the model apologizes, the response contains errors, and etc). In this
way, we verify that solving the queries in our selected subset(containing 515 samples) is beyond
22

the capacity of the existing LLMs and the queries can therefore be treated as positive samples when
evaluating the awareness of tool usage. Meanwhile, we collect negative samples of equal size from
the public datasets of daily conversations (Wang et al., 2022; Zhou et al., 2023) and common sense
(Talmor et al., 2019), the queries of which are expected to be answered by LLMs without the help of
external tools.
C
EXPERIMENTAL SETTINGS
C.1
MODELS AND TEST SAMPLES
We conducted extensive experiments on nine commonly used LLMs including ChatGPT (OpenAI,
2023a), ChatGLM2 (6B) (THUDM, 2023), Llama2 (7b, 13b) (Touvron et al., 2023), Vicuna (7b,
13b, 33b) (Chiang et al., 2023), Baichuan2 (13b) (Baichuan, 2023) and Koala (13b) (Geng et al.,
2023). The temperature parameter for these models was uniformly set to 0.0 in our experiments. For
tool selection with similar choices and with possible reliability issues, we sampled five samples for
each tool, resulting in a total of 975 samples. For tool selection in specific scenarios, we sampled
20 samples for each tool within each scenario. This means that for popularity-related scenarios,
namely the top 5, 10, and 15 scenarios, we obtained 100, 200, and 300 samples, respectively. As for
group-related scenarios, each scenario yielded 200 samples. In the case of"multi-tool selection, given
the relatively small dataset size, we utilized the entire set of samples for testing.
C.2
ANSWER MATCHING
Due to the model’s practice of providing an explanatory context for its responses rather than directly
outputting answers, it is necessary to perform answer matching (obtaining "yes," "no," or the name of
a tool) for a more accurate evaluation.
Tool usage awareness. We use the following rules to match the results:
• If "yes" is present in the sentence and "no," "not," or "don’t" is absent from the sentence: The
answer is "yes."
• If "no" is present in the sentence and "yes" is absent from the sentence: The answer is "yes." If
phrases like "not seem necessary," "not think it is necessary," "not need to use," "not necessary to
use," and "do not think I need to use" are present in the sentence: The answer is "no."
• If phrases like "I need to use," "I think it is necessary," "I may need to use," "I would need to use,"
"I believe it is necessary to use," "would need access," "might be necessary to use," "I might need
to use," "tools would be necessary," "may be necessary to use," "be beneficial to use," "I will need
to use," "might need to use," "would need to rely," and "may need to access" are present in the
sentence: The answer is "yes."
For cases not covered by the above rules, the answers are analyzed manually.
Tool selection. We match the names of tools from the results that contain a tool list. For single-tool
tasks, if no matches are found, it is recorded as "None." If one match is found, and "None" is not
present in the results, it is compared with the ground-truth label. If more than two matches are found,
manual analysis is performed. For multi-tool tasks, if the number of matches is less than two, it is
considered an incorrect answer. If the number of matches is equal to two, it is compared with the
ground-truth label. If more than two matches are found, the answers are manually evaluated.
D
PROMPT TEMPLATE
D.1
TOOLE DATASET GENERATION
We show the prompt templates of TOOLE dataset generation as follows:
23

Direct diverse generation
Here is a tool for ChatGPT, which can help it solve users’
requests better.
The description of this tool includes a
description of users and a description of ChatGPT.
The description of users:
{human description}
The description of ChatGPT: {model description}
Please give 10 examples where you would use this plugin to
answer a user’s question and you should only tell me what
users will say.
Please ensure that the provided examples are distinct from
one another.
Feel free to employ various sentence styles,
such as instructions or requests, and vary the level of
detail as needed.
The format of your answer should be like:
1.
User:
[Your
Answer].
2.
User:
[Your Answer] ...
Details diverse generation
Here is a plugin designed to enhance ChatGPT’s responsiveness
to users’ needs.
ChatGPT only uses the plugin when it thinks
the tools will enhance its response.
Now, I would like you
to complete the following tasks:
I will provide you with a description of the plugin, and
based on that description, you need to provide five examples
of user inputs that would prompt ChatGPT to utilize the
plugin in order to enhance its responses for users.
Please ensure that your answers satisfy the following
conditions:
1.
Each example should be the first input in a new
conversation, without any prior context.
2.
The sentence should contain description information.
3.
Your answers should be as detailed as possible.
4.
Format your answers as follows:
1.
User:
[Answer], 2.
User:
[Answer], ...
5.
Utilizing this plugin has the potential to significantly
improve ChatGPT’s ability to address users’ requests.
The plugin includes descriptions for both users and ChatGPT.
The description for users is as follows:
{human
description}, and the description for ChatGPT is:
{model
description}.
Keywords extraction for keywords generation
Here is a tool for ChatGPT, which can help it solve users’
requests better.
The description of this tool includes a description of users
and a description of ChatGPT.
The description of users:
{human description}
The description of ChatGPT: {model description}.
Now your task is to give me five words or phrases to label
this tool.
These labels can be not mentioned in the description and
labels should be as short as possible.
The format of your answer should be:
1.
[label 1], 2.
[label 2], ..., 5.
[label 5].
24

Keywords generation
Here is a tool for ChatGPT, which can help it solve users’
requests better.
The description of this tool includes a description of users
and a description of ChatGPT.
The description of users:
{human description}
The description of ChatGPT: {model description}
Now I will give you five labels of this tool and what you
need to do is give me five sentences the user will input to
ChatGPT when they may need the help of this tool.
Here are the labels:
{labels}
The format of your answer should be:
1.
[label 1]:
[sentence 1], 2.
[label 2]:
[sentence 2], ..., 5.
[label
5]:
[sentence 5].
Emotional generation
Here is a plugin designed to enhance ChatGPT’s responsiveness
to users’ needs.
ChatGPT only uses the plugin when it thinks
the tools will enhance its response.
Now, I would like you
to complete the following tasks:
I will provide you with a description of the plugin, and
based on that description, you need to provide five examples
of user inputs that would prompt ChatGPT to utilize the
plugin in order to enhance its responses for users.
Please ensure that your answers satisfy the following
conditions:
1.
Each example should be the first input in a new
conversation, without any prior context.
2.
The sentence should contain description information.
3.
The example should be in a {Emotion type} mood.
4.
Format your answers as follows:
1.
User:
[Answer], 2.
User:
[Answer], ...
5.
Utilizing this plugin has the potential to significantly
improve ChatGPT’s ability to address users’ requests.
The plugin includes descriptions for both users and ChatGPT.
The description for users is as follows:
{human
description}, and the description for ChatGPT is:
{model
description}.
25

Multi-tool queries generation
Now you are a query generation assistant.
Here are two tools for ChatGPT, which can help it solve
users’ requests better.
The first tool is {first tool name}, its description is
"{first tool description}".
The second tool is {second tool name}, its description is
"{second tool description}".
Please give five examples where you would use these two tools
AT THE SAME TIME to answer a user’s query and you should only
tell me what users will say.
Remember that the queries you give must be related to both
two tools!
Please ensure that the provided examples are distinct from
one another.
Feel free to employ various sentence styles,
such as instructions or requests, and vary the level of
detail as needed.
Remember that the 5 queries you generate should include both
parallel tool usage (two tools without any relationship)
and causal tool usage (one tool dependent on the result of
the other tool).
Also, the user’s query cannot include the
specific name of the tool.
The format of your answer should be like:
1.
User:
[Your
Answer].
2.
User:
[Your Answer] ...
D.2
PROMPT TEMPLATE OF EXPERIMENTS
We show the experimental prompt in this section including the Thought part (①) and the Action part
(②).
Thought (①) prompt
You are an intelligent agent, and you need to constantly
be aware of your own limitations.
I will provide you with
a user’s query, and you should assess, based on your own
capabilities, whether you need to use external tools to
better address the user’s query.
Typically, there are four
reasons why you might need to use external tools:
[Reasons Begin]
{tool_reason}
[Reasons End]
Here is the user’s query:
[User Query Begins]
{user_query}
[User Query Ends]
Based on the above query, if you think it’s necessary to
use external tools, please respond with "yes"; otherwise,
respond with "no." Additionally, you should provide a brief
explanation for your answer.
26

Action (②) prompt in the single-tool tasks
You are a helpful AI assistant.
Your current task is to
choose the appropriate tool to solve the user’s query based
on their question.
I will provide you with the user’s
question and information about the tools.
If there is a tool in the list that is applicable to this
query, please return the name of the tool (you can only
choose one tool).
If there isn’t, please return ’None.’
Additionally, you will need to support your answer with a
brief explanation.
User’s Query:
[User’s Query Start]
{user_query}
[User’s Query End].
List of Tools with Names and Descriptions:
[List of Tools with Names and Descriptions Start]
{tool_list}
[List of Tools with Names and Descriptions End]
Action (②) prompt in the multi-tool task
You are a helpful AI assistant.
Your current task is to
choose the appropriate tool to solve the user’s query based
on their question.
I will provide you with the user’s
question and information about the tools.
If there is a tool in the list that is applicable to this
query, please return the name of the tool (you can choose
two tools at most).
If there isn’t, please return ’None.’
Additionally, you will need to support your answer with a
brief explanation.
User’s Query:
[User’s Query Start]
{user_query}
[User’s Query End].
List of Tools with Names and Descriptions:
[List of Tools with Names and Descriptions Start]
{tool_list}
[List of Tools with Names and Descriptions End]
E
FAILURE CASE STUDY
We show some failure cases of tool selection motivation in LLMs, as shown in Table 12 and Table 13.
The following conclusions can be drawn from these cases: (1) LLMs can be overconfident or lack
confidence. On one hand, LLMs demonstrate overconfidence in their capabilities, as exemplified
by the first three instances in Table 12, where LLMs erroneously perceive themselves as having
the capacity to offer reminders and conduct internet searches. On the other hand, LLMs display
an unquestioning reliance on external tools, as evidenced by three instances in Table 13. Even for
conventional language model tasks like sentiment classification and text generation, they prefer tool-
based solutions. (2) LLMs have conflicting perceptions of their own capabilities. As demonstrated
by the 4th, 5th, and 6th examples in Table 12, ChatGPT provides contradictory responses regarding
the utilization of external tools when handling mathematical and logical queries. Based on the
aforementioned findings, it is imperative to conduct additional research and training to enhance
LLMs’ proficiency in correctly utilizing tools.
27

Table 12: Examples of tool usage awareness on ChatGPT.
ID
Query
Answer
1
I need to remember to attend a meeting
at 10 a.m. Can you set a reminder for
me?
No, it is not necessary to use external tools for this query.
As an intelligent agent, I have the capability to set reminders
for users and can do so without the need for external tools.
2
Can you tell me more about the services
offered by Magnetis?
No. As an AI language model, I have access to a vast amount
of information on the internet and can gather information
about services offered by Magnetis by searching relevant
web pages and extracting information. Therefore, I do not
need to use external tools to address this query.
3
My brother is a music lover. Can you
find a gift related to music for him?
No. The query is straightforward and does not require exter-
nal tools. The agent can search for music-related gift ideas
using its own search capabilities.
4
What is the result of 3.01173.82488?
No. As an AI language model, I can perform basic mathe-
matical calculations, including exponentiation. I can directly
calculate the result of 3.0117 raised to the power of 3.82488
without the need for external tools.
5
Find the four smallest perfect numbers. Yes, it is necessary to use external tools to find the four
smallest perfect numbers.
6
Converting 85 F to Celsius.
Yes. Converting Fahrenheit to Celsius requires a conversion
formula. Although I possess the knowledge for this calcula-
tion, I do not have the capability to perform mathematical
operations. I would need to use an external tool, such as a
calculator or programming language, to accurately convert
the temperature.
Table 13: Examples of tool usage awareness on vicuna.
ID
Query
Answer
1
Detect if the Reddit thread contains hate
speech. r/worldnews
• Posted by u/madneon_ 3 hours ago
Russia ‘borrows $13.6bn in largest ever
debt issuance in a single day’ to continue
faltering war
• macross1984 · 3 hr. ago
Russia will become deadbeat.
Yes. To detect if the Reddit thread contains hate speech,
external tools such as natural language processing (NLP)
models or sentiment analysis algorithms may be required.
These tools can analyze the text and identify any offensive
or hateful language used in the comments.
2
Prove that every set is countable.
Yes. The query involves proving a mathematical statement,
specifically about the countability of sets. As a language
model, I can provide a general explanation or approach to
solving this problem, but I cannot perform real-time calcula-
tions or generate formal proofs. To fully address the user’s
query, it would be beneficial to use external tools such as
mathematical software (e.g., Mathematica, MATLAB) or
consult with a human expert in the field of mathematics..
3
Create a fun math question for children.
Yes, it is necessary to use external tools. The query requires
the creation of a fun math question for children, which in-
volves generating a specific type of content that may not
fall within the capabilities of the language model. External
tools or resources may be needed to generate appropriate
and engaging math questions that are suitable for children.
28

F
RADAR FIGURES
We show the visualization results of tool usage awareness and tool selection in Figure 13 and Figure
14.
Figure 13: The evaluation results (%) of tool usage awareness
29

Figure 14: The CSR result (%) of tool selection.
30

