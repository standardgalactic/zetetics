3 First-order logic
Mathematical logic is a branch of mathematics that investigates the foundations of math-
ematics. In this chapter, we shall do the same. Specifically, in Section 3.1, we discuss first-
order languages, together with some examples of first-order languages. First-order logic
is rich enough to formalize virtually all of mathematics. In Section 3.2, we will investi-
gate mathematical structures (models) and Tarski’s definition of truth (satisfaction) in a
structure. In Section 3.3, we shall examine the definition of proof (deduction) in a first-
order language.
3.1 First-order languages
In this section, we will formally define the syntax of the language of first-order logic.
First-order logic deals with formal statements that are expressed in terms of predicates,
logical connectives, variables, and quantifiers. A preview of such a logic is given in Sec-
tion 1.2.3. We will first identify the symbols of the language. An expression will then be
any finite string of these symbols. Some expressions will be nonsensical, while others
will be meaningful. Some of the meaningful expressions will denote terms which act as
the nouns and pronouns of the language; the terms can be interpreted as naming an
individual object. Once we have the terms of the language, we can define the atomic
formulas of the language. Atomic formulas are analogous to the sentence symbols of
propositional logic. We can then identify the correct rules of grammar and define the
well-formed formulas (wffs) of the language. To specify the terms and wffs requires def-
inition by recursion (see Section 1.1.5).
Definition 3.1.1. The alphabet of a first-order language ℒconsists of the following dis-
tinct symbols:
A.
Required symbols
1.
Parentheses: (, ).
2.
Logical connectives: →, ¬.
3.
Variables: v1, v2, v3, v4, . . . , vn, . . . .
4.
Predicate symbols: For each natural number n > 0, a (possibly empty) set of
n-place predicate symbols.
5.
Quantifier symbol: ∀.
B.
Optional symbols
1.
Equality symbol: ̇=, a 2-place relation.
2.
Constant symbols: A set of symbols, for example, {c1, c2, . . . }.
3.
Function symbols: For each natural number n > 0, a (possibly empty) set of
n-place function symbols.
https://doi.org/10.1515/9783110782073-003

3.1 First-order languages
౪
53
A dot over a familiar symbol is used to emphasize that the symbol has to be inter-
preted. This is also done to make a distinction between the symbol itself and the object
that it commonly represents.
A finite string of symbols from the language ℒwill be called an ℒ-expression. For
example, v3c4c1)v3 is an ℒ-expression that starts with the symbol v3. Moreover, v3c4 is
a proper initial segment of v3c4c1)v3. The ℒ-expression v3c4c1)v3 does not appear to be
expressive. We will soon isolate the meaningful ℒ-expressions from those that are mean-
ingless.
There exists a one-to-one correspondence between each ℒ-expression α and a finite
sequence of symbols in ℒdenoted by ⟨α∗⟩, where α∗is the result of putting commas
between all of the symbols in α. So an ℒ-expression α is a proper initial segment of the
ℒ-expression β when ⟨α∗⟩is a proper initial segment of ⟨β∗⟩(see Definition 1.1.6).
In the formal language ℒ, we have listed only the logical connectives →and ¬. Since
these two connectives are tautologically complete (see Exercise 5 on page 43), there is
no need to add more.
We also only identified the universal quantifier ∀. Since ¬∀x¬Px is equivalent to
∃xPx (see Quantifier Negation Laws 1.2.4(3)), the existential quantifier ∃x can be viewed
as an abbreviation for ¬∀x¬.
In the language ℒ, an n-place function symbol is intended to represent a function of
n relevant ℒ-expressions ε1, ε2, . . . , εn. Let f be a 3-place function with input ε1, ε2, ε3. In
mathematics f (ε1, ε2, ε3) would be the standard notation for the output value; however,
if f is a function symbol in the language ℒ, we shall represent this output value by using
the Polish notation fε1ε2ε3, where there are no parentheses or commas.
An n-place predicate symbol is intended to represent a property or relationship
of n relevant ℒ-expressions; for example, if P is a 4-place predicate symbol in the lan-
guage ℒ, then Pε1ε2ε3ε4 can be viewed as an assertion about ε1, ε2, ε3, ε4. Predicate sym-
bols are sometimes also called relation symbols.
The predicate, constant, and function symbols can be viewed as the parameters of
the language. To specify a language we must identify the particular predicate, constant,
and function symbols that we wish to use. Suppose our language ℒcontains the equality
symbol, the predicate symbols P1, P2, . . . , constant symbols c1, c2, . . . , and function sym-
bols f1, f2, . . . . In the future we shall describe a language ℒby expressing it as a set of
these selected parameters, that is, we shall say that ℒis the set
ℒ= {P1, P2, . . . , c1, c2, . . . , f1, f2, . . . , ̇=}.
Example 3.1.2 (Language of groups). When working with groups, one employs the lan-
guage ℒ= {e, ∗, ̇=}, which has a 2-place function symbol ∗for the group operation and a
constant symbol e for the identity element. We can write v1 ∗v2 and v1 ̇= v2 to represent
the Polish notation ̇=v1v2 and ∗v1v2, respectively.

54
౪
3 First-order logic
Example 3.1.3 (Language of set theory). Set theory uses the language ℒ= { ̇∈, ̇=}, where
̇∈is a 2-place predicate symbol. We shall write v1 ̇∈v2 to denote ̇∈v1v2.
Example 3.1.4 (Language of elementary number theory). In number theory one can use
the language ℒ= { ̇<, ̇0, ̇S, ̇+, ̇×, ̇E, ̇=}, which has a 2-place relation symbol ̇<, a constant
symbol ̇0, a 1-place function symbol ̇S (successor), and 2-place function symbols ̇+ (addi-
tion), ̇× (multiplication), and ̇E (exponentiation). Using Polish notation with these func-
tion symbols,
̇Sx denotes “x ̇+ 1,”
̇+xy denotes “x ̇+ y,”
̇×xy denotes “x ̇× y,”
̇Exy denotes “xy.”
We will write x
̇< y to represent
̇<xy. The Polish notation
̇S ̇S ̇0 can be translated to
̇S( ̇S( ̇0)). Continuing in this vein, how does one translate
̇+ ̇S ̇S ̇0 ̇S ̇S ̇S ̇0? Since ̇S ̇S ̇S ̇0 trans-
lates to
̇S( ̇S( ̇S( ̇0))) and
̇S ̇S ̇0 translates to
̇S( ̇S( ̇0)), we see that
̇+SS ̇0 ̇S ̇S ̇0 translates to
̇S( ̇S( ̇0)) ̇+ ̇S( ̇S( ̇S( ̇0))). For any natural number n, we will write
̇Sn ̇0 =
n times
⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞⏞
̇S ̇S ⋅⋅⋅̇S ̇0.
Example 3.1.5 (A language for real analysis). In real analysis, one could use the language
ℒ= { ̇<, ̇−, ̇0, c, | |, f , ̇=} which has a 2-place relation symbol ̇< (less than), constant symbols
̇0 (zero) and c, a 2-place function symbol ̇−(subtraction), and 1-place function symbols
| | (absolute value) and f .
3.1.1 Terms and atomic formulas
We will now describe how to generate the terms of a language ℒ. The method we shall
use to construct the terms is not new; it is just an application of Theorem 1.1.24. Let U be
the set of all ℒ-expressions. For each n-place function symbol f in the language ℒ, define
the (mathematical) function ℰf : Un →U by
ℰf (ε1, ε2, . . . , εn) = fε1ε2 ⋅⋅⋅εn.
(3.1)
Definition 3.1.6. Let ℱ= {ℰf : f is a function symbol in ℒ} and let 𝒯be the set of all
the variables and constants in the language ℒ. Let 𝒯be the set generated from 𝒯by the
functions in ℱ. An ℒ-expression τ is an ℒ-term if and only if τ ∈𝒯.

3.1 First-order languages
౪
55
So the set of ℒ-terms 𝒯is the set of ℒ-expressions that can be constructed by starting
with the variables and constants and by repeatedly applying the functions in ℱ. This
may all seem a bit abstract. Let us try to make Definition 3.1.6 a little more concrete by
revisiting Theorem 1.1.24 in the current context.
Let C0 = 𝒯be the set of all the variables and constants in the language ℒ. Constants
and variables are ℒ-terms, and we can use these to build more ℒ-terms. Let h be a 3-place
function symbol in ℒ. Thus,
ℰh(ε1, ε2, ε3) = hε1ε2ε3,
by (3.1). Now, using ℰh, the following set produces more ℒ-terms:
ℰh[C0] = {hε1ε2ε3 : ε1, ε2, ε3 ∈C0}.
Thus, t ∈ℰh[C0] if and only if t = hε1ε2ε3, where ε1, ε2, ε3 are constants or variables.
For example, t1 = hv7c5v3 and t2 = hc4c1v2 are ℒ-terms in ℰh[C0]. This is only a small
sample of all the ℒ-terms that can be constructed. For any other function symbol g in ℒ,
there are new ℒ-terms in ℰg[C0] as well. To put all of these ℒ-terms together in one set,
we define C1 = C0 ∪⋃{ℰf [C0] : ℰf ∈ℱ}, where ℱis as in Definition 3.1.6. So t1, t2 ∈C1.
Using all of the ℒ-terms in C1, we can build more ℒ-terms by letting C2 = C1 ∪⋃{ℰf [C1] :
ℰf ∈ℱ}. So, for example, if g is a 4-place function symbol in ℒ, then gv4t1c1t2 ∈C2. Note
that
gv4t1c1t2 = gv4hv7c5v3c1hc4c1v2.
By repeating this process, we get the set of ℒ-terms
Cn+1 = Cn ∪⋃{ℰf [Cn] : ℰf ∈ℱ}
for each n. Then the set of all the ℒ-terms is 𝒯= ⋃n∈ℕCn, that is, the set 𝒯is generated
from 𝒯by the functions in ℱ. Definition 3.1.6 and the previous discussion justify the
following useful remark.
Remark 3.1.7. An ℒ-expression t is an ℒ-term of a language ℒif and only if either
1.
t is a variable, or
2.
t is a constant symbol, or
3.
t is ft1t2 ⋅⋅⋅tn, where f is an n-place function symbol of ℒand each ti is an ℒ-term.
If the language ℒhas no function symbols, then the terms are just the constants and
the variables.

56
౪
3 First-order logic
3.1.2 Induction on terms principle
Since there is a procedure for building all of the ℒ-terms by starting with the variables
and constants and then repeatedly applying the function symbols of ℒ, Theorem 1.1.25
yields the following term induction principle and associated proof strategy.
Term Induction Principle. Let 𝕊(t) be a statement about ℒ-terms t. If
1.
𝕊(v) and 𝕊(c) hold for all the variables v and constants c and
2.
for all n-place function symbols f in ℒand all ℒ-terms t1, t2, . . . , tn, if S(ti) holds for
each 1 ≤i ≤n, then 𝕊(ft1t2 ⋅⋅⋅tn),
then 𝕊(t) is true for all ℒ-terms t.
Proof Strategy. In order to prove an assertion “for all ℒ-terms t, 𝕊(t)” by induction on
ℒ-terms, use the following proof diagram:
Base step:
Prove 𝕊(v) and 𝕊(c) for all the variables v and constants c.
Inductive step:
Let f be an n-place function symbol and let t1, t2, . . . , tn be ℒ-terms.
Assume 𝕊(ti) for each 1 ≤i ≤n.
Prove 𝕊(ft1t2 ⋅⋅⋅tn).
Applications of the term induction principle
Theorem 3.1.8. Let ℒbe a language. For all ℒ-terms t and τ, neither t nor τ is a proper
initial segment of the other.
Proof. For all ℒ-expressions τ and t, we shall write τ ≺t to mean that τ is a proper initial
segment of t and write τ ⊀t to mean that τ is not a proper initial segment of t. Consider
the following statement about ℒ-terms t:
For all ℒ-terms τ, τ ⊀t and t ⊀τ.
We prove that the above statement holds for all ℒ-terms t by induction.
Base step: Let t be a variable or a constant symbol and let τ be any ℒ-term. As t has
no proper initial segments, we see that τ ⊀t. Since t is either a variable or a constant
symbol, Exercise 1 below implies that t ⊀τ.
Inductive step: Let f be an n-place function symbol in ℒand also let t1, t2, . . . , tn be
ℒ-terms. Assume the induction hypothesis:
For all ℒ-terms τ, τ ⊀ti and ti ⊀τ, whenever 1 ≤i ≤n.
(IH)
Let τ be any ℒ-term. We must prove that
τ ⊀ft1t2 ⋅⋅⋅tn
and
ft1t2 ⋅⋅⋅tn ⊀τ.

3.1 First-order languages
౪
57
First we show that τ ⊀ft1t2 ⋅⋅⋅tn. Assume, to the contrary, that (󳵳) τ ≺ft1t2 ⋅⋅⋅tn. Hence,
τ must start with the symbol f . Since f is an n-place function symbol and τ is a term,
τ must have the form τ = fτ1τ2 ⋅⋅⋅τn, where τ1, τ2, . . . , τn are ℒ-terms. From (󳵳), we obtain
fτ1τ2 ⋅⋅⋅τn ≺ft1t2 ⋅⋅⋅tn. By dropping the common starting symbol f , we conclude that
τ1τ2 ⋅⋅⋅τn ≺t1t2 ⋅⋅⋅tn.
(3.2)
As τ1 and t1 are ℒ-terms, the induction hypothesis (IH) implies that τ1 and t1 cannot be
proper initial segments of one another. Thus, (3.2) implies that τ1 = t1. Hence,
τ2 ⋅⋅⋅τn ≺t2 ⋅⋅⋅tn.
(3.3)
By similar reasoning, (3.3) implies that τ2 = t2. Continuing in this manner, we infer that
τ1 = t1, τ2 = t2, . . . , τn−1 = tn−1. From (3.2), we now conclude that tn ≺τn, which contra-
dicts (IH). Hence, τ ⊀ft1t2 ⋅⋅⋅tn. A very similar argument shows that ft1t2 ⋅⋅⋅tn ⊀τ.
Theorem 3.1.9 (Unique readability of terms). Let ℒbe a language and let 𝒯be the set of
all the variables and constant symbols. Moreover, let 𝒯be the set of terms generated from
𝒯by the functions in ℱ= {ℰf : f is a function symbol in ℒ}. When the functions in ℱare
restricted to the set of ℒ-terms 𝒯, we have the following:
(a) The range of each function in ℱis disjoint from 𝒯.
(b) Any two distinct functions in ℱhave disjoint ranges.
(c) Every function in ℱis one-to-one.
That is, the set of all terms is freely generated from the set 𝒯by the functions in ℱ.
Proof. Let ℒ, 𝒯, ℱ, and 𝒯be as stated in the theorem and let all the functions in ℱbe
restricted to 𝒯.
(a) Let ℰf ∈ℱ. Since every term in the range of ℰf starts with the function symbol f , we
see that the range of ℰf is disjoint from 𝒯.
(b) Let f and g be two distinct function symbols in ℒ. Since f
̸= g, we see that the ranges
of ℰf and ℰf are disjoint.
(c) Let f be an n-place function symbol in ℒ. We must show that ℰf is one-to-one. Let
τ1, τ2, . . . , τn and t1, t2, . . . , tn be ℒ-terms. Assume that
ℰf (τ1, τ2, . . . , τn) = ℰf (t1, t2, . . . , tn).
Thus, fτ1τ2 ⋅⋅⋅τn = ft1t2 ⋅⋅⋅tn. Theorem 3.1.8, together with its proof, allows us to
conclude that τ1 = t1, τ2 = t2, . . . , τn = tn.
The above unique readability theorem (Theorem 3.1.9) will now allow us, via Theo-
rem 1.1.27, to recursively define a function on the ℒ-terms using a function that is only
defined on the variables and constants of a language ℒ.
We are now able to define the atomic formulas.

58
౪
3 First-order logic
Definition 3.1.10. An atomic formula of a language ℒis an expression of the form
Pt1t2 ⋅⋅⋅tn, where P is an n-place predicate symbol of ℒand each ti is an ℒ-term.
For example, if the language ℒhas the 2-place equality symbol, then the expression
̇=vivj is an atomic formula as the variables are ℒ-terms. In the future, we shall let ̇=vivj
be denoted by vi ̇= vj. In the language of set theory, ̇∈vivj is an atomic formula, which we
will denote by vi ̇∈vj. As we will see, the atomic formulas will play a role similar to that
of the sentence symbols of propositional logic.
Theorem 3.1.8 directly implies an analogous result for atomic formulas.
Theorem 3.1.11. Let ℒbe a language. No proper initial segment of an atomic formula is
itself an atomic formula.
3.1.3 Well-formed formulas
We will now formally define the concept of a well-formed formula (wff or formula) in
first-order logic. Informally speaking, wffs are the atomic formulas and those expres-
sions that can be built up from the atomic formulas using the logical connectives and
the quantifier symbol.
Before defining wffs, we need the following formula building functions. Let α and β
be expressions. Then
ℰ¬(α) = (¬α),
ℰ→(α, β) = (α →β),
(3.4)
ℰQi(α) = ∀viα,
where i = 1, 2, 3, . . . . The following definition is a special case of Theorem 1.1.24.
Definition 3.1.12. Let ℒbe a language, let ℱ= {ℰ¬, ℰ→, ℰQ1, ℰQ2, . . . }, and let 𝒮be a set of
all of the atomic formulas in the language ℒ. Let 𝒮be the set generated from 𝒮by the
functions in ℱ. An ℒ-expression α is a wff if and only if α ∈𝒮.
We will also say that α is an ℒ-formula, or an ℒ-wff , to mean that α is a wff in the
language ℒ. The following remark is justified by Definition 3.1.12.
Remark 3.1.13. An ℒ-expression ψ is a wff if and only if either
1.
ψ is an atomic formula, or
2.
ψ has the form (¬α), where α is a wff, or
3.
ψ has the form (α →β), where α and β are wffs, or
4.
ψ has the form ∀viα, where α is a wff and i ≥1.
Example 3.1.14. Let ℒ= {P, f , c, ̇=}, where P is a 2-place predicate symbol, f is a 1-place
function symbol, and c is a constant symbol. The following are ℒ-formulas:

3.1 First-order languages
౪
59
1.
∀v1(Pv1c →v1 ̇= fc), where Pv1c and v1 ̇= fc are atomic formulas,
2.
∀v1(fv2 ̇= fc →(¬Pfv1c)), where fv2 ̇= fc and Pfv1c are atomic formulas,
3.
∀v1∀v2(fv1 ̇= fv2 →v1 ̇= v2), where fv1 ̇= fv2 and v1 ̇= v2 are atomic formulas.
3.1.4 Induction on wffs principle
Since Definition 3.1.12 ensures that there is a procedure for building each wff by first
starting with atomic formulas and then applying the connective symbols ¬, →and the
quantifier symbol ∀, Theorem 1.1.25 validates the following induction on wffs princi-
ple.
Wff Induction Principle. Let 𝕊(α) be a statement about an arbitrary wff α. If
1.
𝕊(ϕ) is true for all atomic formulas ϕ and
2.
for all wffs α and β, 𝕊(α) and 𝕊(β) imply that 𝕊((¬α)), 𝕊((α →β)), and 𝕊(∀viα),
then 𝕊(α) is true for all wffs α.
Proof Strategy. In order to prove an assertion “for all wffs α, 𝕊(α)” by induction, use
the following diagram:
Base step:
Prove 𝕊(ϕ) for all atomic formulas ϕ.
Inductive step:
Let α and β be arbitrary wffs.
Assume 𝕊(α) and 𝕊(β).
Prove 𝕊((¬α)), 𝕊((α →β)), and 𝕊(∀viα).
Applications of wff induction principle
Theorem 3.1.15. Let ℒbe a language. For all wffs α and β, neither α nor β is a proper
initial segment of the other.
Proof. For all ℒ-expressions ψ and φ, we shall write ψ ≺φ to mean that ψ is a proper
initial segment of φ and write ψ ⊀φ to mean that ψ is not a proper initial segment of φ.
Consider the following statement about wffs α:
For all wffs γ, γ ⊀α and α ⊀γ.
We prove that the above statement holds for all wffs α by induction.
Base step: Let α be an atomic formula and let γ be an arbitrary wff. To show that
γ ⊀α, assume, to the contrary, that γ ≺α. Since α is an atomic formula, there exist
an n-place predicate symbol P and terms t1, t2, . . . , tn such that α = Pt1t2 ⋅⋅⋅tn. Hence,
(󳵳) γ ≺Pt1t2 ⋅⋅⋅tn. So γ starts with the predicate symbol P. As γ is a wff, it follows
that γ must also be an atomic formula. Thus, (󳵳) contradicts Theorem 3.1.11. A similar
argument shows that α ⊀γ.

60
౪
3 First-order logic
Inductive step: Let α and β be wffs. Assume the induction hypothesis:
For all wffs γ, we have γ ⊀α, α ⊀γ and γ ⊀β, β ⊀γ.
(IH)
Let γ be any wff. We must prove that γ ⊀ψ and ψ ⊀γ whenever ψ has the form
(1) (¬α),
(2) (α →β), or
(3) ∀viα.
Let us first consider case (2). To show that γ ⊀(α →β), assume (for a contradiction) that
(󳶃) γ ≺(α →β). So γ starts with the symbol (. Thus, as γ is a wff, γ must have the form
(¬ϑ) or (ζ →φ), where ϑ, ζ, and φ are wffs (see Remark 3.1.13). If γ had the form (¬ϑ),
then (󳶃) would imply that the wff α starts with the symbol ¬, which is impossible. Hence,
γ = (ζ →φ), and thus (ζ →φ) ≺(α →β). Therefore, by dropping the left parenthesis,
the induction hypothesis (IH) implies that ζ = α. It now follows that φ ≺β (why?), which
contradicts (IH). An analogous argument shows that (α →β) ⊀γ. The proofs of cases (1)
and (3) also follow by a similar argument.
It is now straightforward to establish the following important theorem (see the
proof of Theorem 2.2.1).
Theorem 3.1.16 (Unique readability of wffs). Let ℒbe a language and let 𝒮be the set of all
the atomic formulas. Moreover, let ℱ= {ℰ¬, ℰ→, ℰQ1, ℰQ2, . . . }. Let 𝒮be the set generated
from 𝒮by the functions in ℱ. When the functions in ℱare restricted to the set of wffs 𝒮,
we have the following:
(a) The range of each function in ℱis disjoint from 𝒮.
(b) Any two distinct functions in ℱhave disjoint ranges.
(c) Every function in ℱis one-to-one.
That is, the set of all wffs is freely generated from the set 𝒮by the functions in ℱ.
Theorem 3.1.16 will now allow us, via Theorem 1.1.27, to recursively define a function
on the wffs of a language ℒusing a function that is only defined on the atomic formulas
of the language.
3.1.5 Free variables
A variable v is free in a wff if it occurs at least once in the formula without being intro-
duced by the quantified expression ∀v. In set theory one uses the language ℒ= { ̇∈, ̇=},
which has the 2-place predicate symbol ̇∈. Here are two wffs from the language of set
theory and their translations into English.

3.1 First-order languages
౪
61
1. ∀v1(v1 ̇∈v1)
English: “Every set is an element of itself.”
2. ∀v3(v3 ̇∈v1 →v3 ̇∈v2)
English: “Every element in v1 is also in v2.”
There is a critical difference between these two formulas. The first formula translates
to a complete English sentence, whereas the second formula translates to an English
expression containing the two variables v1 and v2. In the second formula, we shall say
that v1 and v2 are “free variables.” Note the variable in the first formula is attached to a
quantifier. In this case we say that the variable is bound by a quantifier. For another ex-
ample, let ℒ= {P, c, ̇=}, where P is a 2-place predicate symbol and c is a constant symbol.
Then the variable v1 is free in the wff (∀v1Pv1v1 →(¬Pv1c)) because the appearance of
v1 after →is not attached to the quantifier.
The above descriptions of “free” and “not free” variables may seem a bit vague. We
shall now give a precise mathematical definition for the concept of a variable occurring
free in a wff. The following definition by recursion is an application of Theorems 1.1.27
and 3.1.16, as will be demonstrated. It is this definition that one should use to determine
whether or not a variable appears free in a wff.
Definition 3.1.17. Let ℒbe a language with variable v. The concept that v occurs free in
a wff of ℒis defined recursively as follows:
1.
v occurs free in ϕ if ϕ is an atomic formula and v appears as a symbol in ϕ;
2.
v occurs free in (¬α) if and only if v occurs free in α;
3.
v occurs free in (α →β) if and only if v occurs free in α or v occurs free in β;
4.
v occurs free in ∀viα if and only if v occurs free in α and v
̸= vi.
We will now formally justify the validity of Definition 3.1.17. Before continuing, it is
recommended that one revisit Theorem 1.1.27. Let ℒbe a language and let V be the set of
all finite sets of the variables of ℒ. Let ℱ= {ℰ¬, ℰ→, ℰQ1, ℰQ2, . . . }, let S be the set of atomic
formulas, and let 𝒮be the set generated from 𝒮by the functions in ℱ. Of course, 𝒮is the
set of all the wffs. For each function in ℱwe define the associated functions F¬: V →V,
F→: V 2 →V, FQi: V →V (for each i ≥1) as follows:
F¬(a) = a,
F→(a, b) = a ∪b,
FQi(a) = a \ {vi}.
Now let h: S →V be defined by
h(ϕ) = set of variables, if any, that occur in the atomic formula ϕ.
Theorems 1.1.27 and 3.1.16 imply that there is a unique h: 𝒮→V such that:
(1) h(α) = h(α) if α is an atomic formula,
(2) h((¬α)) = h(α),

62
౪
3 First-order logic
(3) h((α →β)) = h(α) ∪h(β),
(4) h(∀viα) = h(α) \ {vi}.
For every wff α, it follows that h(α) is the set of all the free variables in α. Thus, if h(α) = ⌀,
then α has no free variables.
Definition 3.1.18. Let α be a wff in a language ℒ. If no variable occurs free in α, then α
is called a sentence, or an ℒ-sentence.
Let α be a sentence. When one translates α into English, one will obtain a complete
English sentence. On the other hand, if β is a wff in which variables occur free, then an
English translation of β will lead to an English expression containing variables.
3.1.6 Notational abbreviations
The limitations that our first-order languages have imposed upon us should be clear.
For example, we cannot use the logical connectives ∧and ∨, and we cannot use the
existential quantifier ∃v. These restrictions will now be removed by using the method
of “abbreviations,” which will translate our wffs into a more readable form. This method
does not change our formal definition of a wff; it will only enhance the readability of our
wffs. However, whenever we define or prove new results about a first-order language,
we will use Definition 3.1.12 as our definition of a wff.
Since the set of logical connectives {¬, →} is tautologically complete, the usage of
the logical connectives ∧and ∨can be expressed in terms of the connectives ¬ and →.
Moreover, the existential quantifier ∃can be expressed in terms of ¬ and ∀(recall the
Quantifier Negation Law 1.2.4(3)). Hence, we will be using the following abbreviations
and conventions. The word “abbreviated” is intended to mean “easier to read.”
1.
The expression (α ∧β) is the abbreviated form of (¬(α →(¬β))).
2.
The expression (α ∨β) is the abbreviated form of ((¬α) →β).
3.
The expression (α ↔β) is equivalent to ((α →β) ∧(β →α)) and thus the abbrevi-
ated form of
(¬((α →β) →(¬(β →α)))).
4.
The expression ∃vα is the abbreviated form of (¬∀v(¬α)).
5.
x ̇=y is the abbreviated form of ̇=xy. Similar abbreviations will apply to several other
2-place predicate and function symbols; namely, x ̇<y is the abbreviated form of ̇<xy
and x ̇+ y is the abbreviated form of ̇+xy.
6.
x
̸̇= y is the abbreviated form of ¬ ̇=xy. Similar abbreviations apply to the negation
of a few other 2-place predicate symbols. For example, x ̸̇<y is the abbreviated form
of ¬ ̇<xy.

3.1 First-order languages
౪
63
7.
The outermost parentheses need not be explicitly written. So we can write ∀xα →β
rather than (∀xα →β) and ¬α rather than (¬α).
8.
¬, ∀, and ∃apply to as little as possible. For example,
(a) ¬α ∧β denotes (¬α) ∧β, and not ¬(α ∧β);
(b) ∀xα →β denotes (∀xα →β), and not ∀x(α →β);
(c) ∃xα ∧β denotes (∃xα ∧β), and not ∃x(α ∧β).
9.
∧and ∨will apply to as little as possible, given that convention 8 is observed. For
example, α ∧β →¬γ ∨δ denotes ((α ∧β) →((¬γ) ∨δ)).
10. When one connective is used repeatedly, grouping is to the right. For example, we
will write α ∧β ∧γ to denote α ∧(β ∧γ) and α →β →γ to denote α →(β →γ).
11. We will add parentheses when necessary to ensure readability.
Given an abbreviated wff, one can eliminate all of the abbreviations and obtain the un-
abbreviated version. For example, consider the abbreviated wff ∃x(α∧β). We can begin
to “expand” it to the original wff as follows:
∃x(α ∧β) ⇔(¬∀x(¬(α ∧β)))
by item 4 above,
⇔(¬∀x(¬(¬(α →(¬β)))))
by item 1 above.
Thus, ∃x(α ∧β) expands to (¬∀x(¬(¬(α →(¬β))))). Now, if required, expand α and β,
and do a substitution. For another example, let us rewrite ∃xα →β. We obtain
∃xα →β ⇔(∃xα →β)
adding parentheses,
⇔((¬∀x(¬α)) →β)
by item 4 above.
Throughout the text, we will attempt to use the following conventions:
–
Predicate symbols: Upper-case symbols. Also, ̇∈, ̇<, and ̇=.
–
Variables: vi, u, v, x, y, z.
–
Function symbols: f , g, h. Also, S, ̇+, ̇−, ̇×, etc.
–
Constant symbols: c1, c2, . . . , a, b, c, . . . . Also, ̇0.
–
Terms: t, τ.
–
Wffs: Lower-case Greek letters.
–
Sets of wffs: Upper-case Greek letters.
3.1.7 Examples of languages
Example 3.1.19 (Language of groups). The language ℒ= {e, ∗, ̇=} is used in group theory.
The language ℒhas a 2-place function symbol ∗for the group operation and a constant
symbol e for the identity element. The quantifier ∀is intended to mean “for all elements
in the group.” Using ℒand writing ∗xy as x ∗y, we can express the following group ax-
ioms:

64
౪
3 First-order logic
1.
∀v1∀v2∀v3(v1 ∗(v2 ∗v3) ̇= (v1 ∗v2) ∗v3),
(associativity)
2.
∀v1(v1 ∗e ̇= v1),
(identity element)
3.
∀v1∃v2(v1 ∗v2 ̇= e).
(inverses exists)
Example 3.1.20 (Language of set theory). In set theory one employs the language ℒ=
{ ̇∈, ̇=}, which has a 2-place predicate symbol ̇∈. It is intended that ∀should mean “for all
sets.” Using ℒand writing ̇∈xy as x ̇∈y, one can express the following:
1.
∀v1∃v2(v1 ̇∈v2):
“every set is an element of some set,”
2.
∀v3(v3 ̇∈v1 →v3 ̇∈v2):
“every element in v1 is also in v2,”
3.
∀v2∀v3((v3 ̇∈v1 ∧v2 ̇∈v1) →v2 ̇= v3):
“v1 has at most one element.”
Example 3.1.21 (A language for real analysis). If we are working in real analysis, then we
could use a language like ℒ= { ̇<, ̇−, ̇0, c, ℓ, | |, f }, which has a 2-place relation symbol ̇<
(less than); constant symbols ̇0 (zero), c, and ℓ; a 2-place function symbol ̇−(subtraction);
the 1-place function symbol | | (absolute value); and the 1-place function symbol f . It is
intended that ∀should mean “for all real numbers.” The following wff in the language
ℒasserts that limx→c f (x) = ℓ:
∀v1∃v2( ̇0 ̇< v1 →∀v3(( ̇0 ̇< |v3 −c| ∧|v3 −c| ̇< v2) →|fv3 −ℓ| ̇< v1)).
Example 3.1.22 (Language of elementary number theory). In elementary number theory
one can use the language ℒ= { ̇<, ̇0, ̇S, ̇+, ̇×, ̇E, ̇=}, which has a 2-place relation symbol ̇<
(less than), a constant symbol ̇0, a 1-place function symbol ̇S (successor; ̇S ̇0 denotes 1,
̇S ̇S ̇0 denotes 2, etc.), and three 2-place function symbols ̇+ (addition), ̇× (multiplication),
and ̇E (exponentiation; ̇Exy usually denotes xy). The universal quantifier ∀is intended
to mean “for all natural numbers.” The wff
∀v1(( ̇S ̇S ̇S ̇0 ̇< v1 ∨v1 ̇= ̇S ̇S ̇S ̇0) →∀v2∀v3∀v4( ̇Ev2v1 ̇+ ̇Ev3v1
̸̇=
̇Ev4v1))
in the language ℒasserts Fermat’s last theorem: “For all v1 ≥3, the equation vv1
2 +vv1
3 = vv1
4
has no solutions.”
Exercises 3.1.
1. Prove that every ℒ-term cannot have a variable or constant symbol as a proper
initial segment.
2. Prove Theorem 3.1.11.
3. Let ℒbe a language. Prove that every wff has an even number of parentheses.
4. Let t1, t2, . . . , tn be ℒ-terms, where n > 1. Show that t1t2 ⋅⋅⋅tn is not an ℒ-term.
5. Let ℒbe a language and let α1, α2, . . . , αn be wffs, where n > 1. Show that α1α2 ⋅⋅⋅αn
is not a wff.
6. Let ℒbe a language and let α1, α2, . . . , αn, β1, β2, . . . , βn be wffs, where n ≥1. Show
that if α1α2 ⋅⋅⋅αn = β1β2 ⋅⋅⋅βn, then αi = βi for all i ≤n.

3.1 First-order languages
౪
65
7. Let ℒbe a language and let α1, α2, . . . , αk, β1, β2, . . . , βn be wffs, where 1 ≤k < n.
Show that α1α2 ⋅⋅⋅αk
̸= β1β2 ⋅⋅⋅βn.
8. Let ℒbe a language and let α1, α2, . . . , αn, β1, β2, . . . , βm be wffs, where n, m ≥1. Show
that if α1α2 ⋅⋅⋅αn = β1β2 ⋅⋅⋅βm, then m = n and αi = βi for all i ≤n.
9. In the proof of Theorem 3.1.15, complete the proof of the inductive step by estab-
lishing cases (1) and (3).
10. Let ℒ= { ̇<, ̇0, ̇S, ̇+, ̇×, ̇E, ̇=} be as in Example 3.1.22.
(a) Construct one term using all of the function symbols ̇S, ̇×, and ̇+.
(b) Construct one term using all of the function symbols ̇S, ̇+, ̇×, and ̇E.
(c) Using only your terms in (a) and (b), give an example of an atomic formula.
*11. Let ℒbe a language and let 𝒯be the set of all the variables and constant symbols.
Let 𝒯be the set of the terms of ℒ. Let x ∈𝒯be a variable and let t ∈𝒯. Define
h: 𝒯→𝒯by
h(v) = {t,
if v = x,
v,
if v
̸= x.
(3.5)
By Theorems 3.1.9 and 1.1.27, there is a unique function h: 𝒯→𝒯such that:
(1) h(v) = h(v) for each v ∈𝒯;
(2) h(ft1t2 ⋅⋅⋅tn) = f h(t1)h(t2) ⋅⋅⋅h(tn) for each n-place function symbol f and terms
t1, t2, . . . , tn.
For all τ ∈𝒯, let τx
t = h(τ). Prove by induction on terms that for all terms τ, τx
t is
the term obtained by replacing all occurrences of x in τ with t.
12. Let ℒ= { ̇<, ̇0, ̇S, ̇+, ̇×, ̇E, ̇=} be as in Example 3.1.22. For each of the following wffs,
find the free variables, if any:
(a) x ̇< ̇S ̇S ̇0,
(b)
̇0 ̇< ̇S ̇S ̇0,
(c) x ̇< ̇S ̇Sy,
(d) x ̇= ̇S ̇0 ∨y ̇= ̇0,
(e) ∀x(x ̇< ̇S ̇S ̇0) →(x ̇= ̇S ̇0 ∨x ̇= ̇0),
(f) ∀x(x ̇< ̇S ̇S ̇0 →(x ̇= ̇S ̇0 ∨x ̇= ̇0)).
Which of these wffs are sentences?
13. Eliminate all of the abbreviations and obtain the unabbreviated version of the fol-
lowing wffs, where P, H, C, D are 1-place predicate symbols:
(a) ∃v1Pv1 ∨Pv1,
(b) ∀v1Pv1 ∧Hv1 →∃v2¬Cv2 ∨Dv2.
14. Prove Theorem 3.1.16.
15. Let ℒ= { ̇<, ̇0, ̇S, ̇+, ̇×, ̇E, ̇=} be as in Example 3.1.22. Write wffs that express each of
the following:
(a) “v5 is even,”
(b) “v5 is odd,”

66
౪
3 First-order logic
(c) “v5 is a prime number,”
(d) “there is no largest even number,”
(e) “v1 is a perfect square,”
(f) “every natural number is the sum of four perfect squares.”
16. Let ℒ= {P, c}, where P is a 3-place predicate symbol and c is a constant symbol.
Using the induction on wffs principle, prove that for every wff α, the number of
symbols n (counting repetitions and parentheses) in α can be written as a linear
combination of 2 and 3, that is, n = 2a + 3b, where a and b are integers. (Note:
abbreviations are not allowed and a variable vi is counted as one symbol.)
Exercise Notes: For Exercise 1, use induction on terms. For Exercise 2, no induction is
required. Read the inductive step of the proof of Theorem 3.1.15. For Exercise 7, use proof
by contradiction and then conclude that αk = βkβk+1 ⋅⋅⋅βn.
3.2 Truth and structures
In Section 3.1, we investigated the syntax of first-order languages. This syntax involves
certain rules of grammar that dictate the correct formation of a wff. Semantics, on the
other hand, involves giving meaning to these logical formulas. In this section, we will
pursue the semantics of these languages and attach meaning to their wffs. This involves
the definition of a structure which interprets the parameters of the language. To define
the concept of a wff being “true” in such a structure requires a precise mathematical
definition. This formidable definition is due to Alfred Tarski and formalizes the intuitive
meanings of the logical connectives and the quantifiers. Because of its mathematical
precision, Tarski’s semantic conception of truth is often said to be the best formulation
of truth in a structure.
3.2.1 Structures for first-order languages
In order to determine the truth value of a wff that contains quantified variables, we must
investigate structures in which one can deal with the possible values that the variables
may possess. Structures will also address the following questions:
–
What are the objects that the universal quantifier ∀refers to?
–
What objects do the constant, function, and predicate symbols represent?
Given a language of the form
ℒ= {P1, P2, . . . , c1, c2, . . . , f1, f2, . . . , ̇=},
a structure A for the language ℒ, or an ℒ-structure, is a sequence of the form

3.2 Truth and structures
౪
67
A = ⟨A; PA
1 , PA
2 , . . . , cA
1 , cA
2 , . . . , f A
1 , f A
2 , . . . ⟩
such that:
1.
The set A is nonempty and is called the domain of A. The set A is sometimes denoted
by |A|.
2.
A assigns to each n-place predicate symbol P an n-place relation PA ⊆An.
3.
A assigns to each constant symbol c a member cA of the universe A.
4.
A assigns to each n-place function symbol f an n-place function f A: An →A.
5.
The equality symbol ̇= will always be interpreted as “equality.”
The idea is that A assigns meaning to each of the parameters of the language ℒ. The
quantifier ∀is to mean “for every element in A.” The symbol c is the name of an element
cA in A. Each atomic formula Pt1t2 ⋅⋅⋅tn is to be interpreted as asserting that the n-tuple
of elements in A, named by t1, . . . , tn, is in the relation PA. Each term of the form ft1t2 ⋅⋅⋅tn
can be interpreted as being the value of the function f A: An →A when applied to the
elements in A which are named by t1, . . . , tn.
Example 3.2.1 (Groups). Consider the language ℒ= {e, ∗, ̇=} of groups discussed in Ex-
ample 3.1.19. A structure for this language is A = ⟨ℚ+; eA, ∗A⟩, where ℚ+ is the set
of all positive rational numbers, eA = 1, and ∗A is the usual multiplication of rational
numbers. This structure is a group as it satisfies the following group axioms:
1.
∀v1∀v2∀v3(v1 ∗(v2 ∗v3) ̇= (v1 ∗v2) ∗v3),
(associativity)
2.
∀v1(v1 ∗e ̇= v1),
(identity element)
3.
∀v1∃v2(v1 ∗v2 ̇= e).
(inverses exists)
Example 3.2.2 (Set theory). Let ℒ= { ̇∈, ̇=} be the language of set theory presented in
Example 3.1.20. A structure for this language is A = ⟨ℕ; ∈A⟩, where
̇∈A = {⟨m, n⟩: m < n and m, n ∈ℕ}.
The structure A satisfies the sentence ∀v1∃v2(v1 ̇∈v2), as for every v1 ∈ℕthere is a v2 ∈ℕ
such that v1 < v2.
Example 3.2.3. Consider the language ℒ= {L, f , c}, where L is a 2-place predicate sym-
bol, f is a 1-place function symbol, and c is a constant symbol. Now let A be the structure
A = ⟨ℕ; LA, f A, cA⟩, where:
(a) A = ℕ,
(b) LA is the set of pairs ⟨m, n⟩such that m < n,
(c) f A = S is the successor function S(n) = n + 1,
(d) cA = 0 is the natural number zero.
The sentence ∀xLxfx is true in the structure A, because n < n + 1 for all n ∈ℕ.

68
౪
3 First-order logic
In the above examples, we have used the ambiguous notions that “A satisfies φ”
or that “φ is true in A,” where φ is a sentence of the language. Is the concept of being
true in a structure so vague that one cannot hope to give an accurate formalization of
this concept? That is, can one give a precise mathematical definition for the concept of
a formula being “true in a structure”?
In 1933, the mathematician Alfred Tarski published a paper in which he discussed
the conditions that a definition for a “true sentence” should satisfy. In 1956, he and his
colleague Robert Vaught at UC Berkeley published a revised version of this paper to serve
as a definition of truth in a structure for first-order languages. In the next section, we
shall present Tarski’s definition of truth.
3.2.2 Satisfaction (Tarski’s definition)
We will define a satisfaction relation between a structure and wffs. Let A be a structure
for a language ℒwith domain A. The satisfaction relation between A and a wff will be
defined by means of the following ordered steps:
(a) We first assign each variable in ℒto an element in A.
(b) Using the assignment in (a), we assign each term in ℒto an element in A.
(c) Using the assignment in (b), we define the satisfaction relation on the wffs.
Definition 3.2.4. Let A be an ℒ-structure with domain A. Let V be the set of all the vari-
ables of ℒ. A function ν: V →A is called a variable assignment. Now let 𝒯be the set of
all the variables and constant symbols in ℒ. Given a variable assignment ν, we shall call
the function s: 𝒯→A defined by
s(v) = {ν(vi),
if v = vi, a variable,
cA,
if v = c, a constant symbol,
(3.6)
an assignment.
Let A be a structure for a language ℒ, with domain A. Let s: 𝒯→A be an assignment
as defined in (3.6). Let ℱ= {ℰf : is a function symbol in ℒ} (see (3.1)). Theorem 3.1.9
implies that 𝒯is the set of all the terms and is freely generated from 𝒯by the functions
in ℱ. For each function ℰf in ℱ, we also have the corresponding function f A assigned
by the structure A. Theorem 1.1.27 now implies the following result.
Theorem 3.2.5. Let A be an ℒ-structure with domain A and let s: 𝒯→A be an assign-
ment. Then there is a unique function s: 𝒯→A satisfying the following:
(1) s(v) = s(v) for each variable v;
(2) s(c) = cA for each constant symbol c;
(3) s(ft1t2 ⋅⋅⋅tn) = f A(s(t1), s(t2), . . . , s(tn)) for each n-place function symbol f and terms
t1, t2, . . . , tn.

3.2 Truth and structures
౪
69
Theorem 3.2.5 shows that for any given assignment s, the extension s assigns all of
the terms in ℒto elements in A. So each term t in ℒcan be viewed as a name for the
element s(t) in A.
As we will see, a wff is satisfiable in a structure if it holds under some assignment
of its variables. In the definition below, the satisfaction relation is first defined on the
atomic formulas. The atomic formulas are the building blocks for constructing all of
the wffs. Then we define the satisfaction relation by recursion on the more complicated
formulas which are built from the building blocks using ¬, →, and ∀. The validity of this
recursive definition follows from Theorems 1.1.27 and 3.1.16, as will be shown.
Definition 3.2.6 (Tarski’s definition). Let ℒbe a language and let A be an ℒ-structure. We
define the relation A 󳀀󳨐φ[s], for all assignments s and all formulas φ, by recursion as
follows:
(1) A 󳀀󳨐̇=t1t2[s] iff s(t1) = s(t2), for terms t1 and t2;
(2) A 󳀀󳨐Pt1 ⋅⋅⋅tn[s] iff ⟨s(t1), . . . , s(tn)⟩∈PA, for atomic formulas Pt1 ⋅⋅⋅tn;
(3) A 󳀀󳨐(¬φ)[s] iff A
̸󳀀󳨐φ[s];
(4) A 󳀀󳨐(φ →ψ)[s] iff (if A 󳀀󳨐φ[s], then A 󳀀󳨐ψ[s]);
(5) A 󳀀󳨐∀vφ[s] iff for all d ∈A, A 󳀀󳨐φ[sv|d].
In (5), the assignment sv|d is exactly like s except at the variable v, where sv|d(v) = d, that
is,
sv|d(v′) = {s(v′),
if v′
̸= v,
d,
if v′ = v.
(3.7)
Example 3.2.7. Let ℒ= {L, f , c} and let A = ⟨ℕ; LA, f A, cA⟩be the structure for this
language as defined in Example 3.2.3, that is,
(a) A = ℕ,
(b) LA is the set of pairs ⟨m, n⟩such that m < n,
(c) f A = S is the successor function S(n) = n + 1,
(d) cA = 0 is the natural number zero.
Let 𝒯be the set of all the variables and constant symbols and let s: 𝒯→ℕbe the
assignment satisfying (󳵳) s(vi) = i −1 for i = 1, 2, . . . . So s(v1) = 0, s(v2) = 1. Thus,
(1) s(c) = 0, by Theorem 3.2.5(2);
(1) s(ffc) = f A(s(fc)) = f A(f A(s(c))) = S(S(0)) = 2, by Theorem 3.2.5(3) and (c);
(2) s(ffv3) = S(S(2)) = 4 and s(fv6) = S(5) = 6, by Theorem 3.2.5(3) and (c);
(3) A 󳀀󳨐Lcfv6[s], because ⟨s(c), s(fv6)⟩= ⟨0, 6⟩∈LA, by Definition 3.2.6(2);
(4) A 󳀀󳨐∀v2Lcfv2[s], because

70
౪
3 First-order logic
A 󳀀󳨐∀v2Lcfv2[s]
iff
for all n ∈ℕ, A 󳀀󳨐Lcfv2[sv2|n],
Definition 3.2.6(5)
iff
for all n ∈ℕ, ⟨sv2|n(c), sv2|n(fv2)⟩∈LA,
Definition 3.2.6(2)
iff
for all n ∈ℕ, ⟨0, f A(sv2|n(v2))⟩∈LA,
Theorem 3.2.5(2)(3)
iff
for all n ∈ℕ, ⟨0, f A(n)⟩∈LA,
by (3.7)
iff
for all n ∈ℕ, ⟨0, S(n)⟩∈LA,
since f A = S
iff
for all n ∈ℕ, ⟨0, n + 1⟩∈LA,
S(n) = n + 1
iff
for all n ∈ℕ, 0 < n + 1;
by (b)
thus, A 󳀀󳨐∀v2Lcfv2[s] because it is true that for all n ∈ℕ, 0 < n + 1;
(5) A
̸󳀀󳨐∀v2Lv3fv2[s]; otherwise,
A 󳀀󳨐∀v2Lv3fv2[s]
iff
for all n ∈ℕ, A 󳀀󳨐Lv3fv2[sv2|n],
Definition 3.2.6(5)
iff
for all n ∈ℕ, ⟨sv2|n(v3), sv2|n(fv2)⟩∈LA,
Definition 3.2.6(2)
iff
for all n ∈ℕ, ⟨2, sv2|n(fv2)⟩∈LA,
by (3.7) and (󳵳)
iff
for all n ∈ℕ, ⟨2, f A(sv2|n(v2))⟩∈LA,
Theorem 3.2.5(3)
iff
for all n ∈ℕ, ⟨2, f A(n)⟩∈LA,
by (3.7)
iff
for all n ∈ℕ, ⟨2, S(n)⟩∈LA,
as f A = S
iff
for all n ∈ℕ, ⟨2, n + 1⟩∈LA,
S(n) = n + 1
iff
for all n ∈ℕ, 2 < n + 1;
a falsehood
thus, A
̸󳀀󳨐∀v2Lv3fv2[s], as 2
̸< 0 + 1 and 0 ∈ℕ.
Remark 3.2.8 (Extended definition of satisfaction). The abbreviations presented in Sec-
tion 3.1.6 allow us to extend Definition 3.2.6. Let A be an ℒ-structure. Then for all as-
signments s and all formulas α and β, one can establish the following extension of Defi-
nition 3.2.6:
(1) A 󳀀󳨐̇=t1t2[s] iff s(t1) = s(t2), for terms t1 and t2;
(2) A 󳀀󳨐Pt1 ⋅⋅⋅tn[s] iff ⟨s(t1), . . . , s(tn)⟩∈PA, for atomic formulas Pt1 ⋅⋅⋅tn;
(3) A 󳀀󳨐(¬α)[s] iff A
̸󳀀󳨐α[s];
(4) A 󳀀󳨐(α ∧β)[s] iff (A 󳀀󳨐α[s] and A 󳀀󳨐β[s]);
(5) A 󳀀󳨐(α ∨β)[s] iff (A 󳀀󳨐α[s] or A 󳀀󳨐β[s]);
(6) A 󳀀󳨐(α →β)[s] iff (if A 󳀀󳨐α[s], then A 󳀀󳨐β[s]);
(7) A 󳀀󳨐(α ↔β)[s] iff (A 󳀀󳨐α[s] iff A 󳀀󳨐β[s]);
(8) A 󳀀󳨐∀vα[s] iff for all d ∈A, A 󳀀󳨐α[sv|d];
(9) A 󳀀󳨐∃vα[s] iff for some d ∈A, A 󳀀󳨐α[sv|d].
When applying Remark 3.2.8 on a wff with multiple quantifiers, note the next re-
mark.

3.2 Truth and structures
౪
71
Remark 3.2.9. Let A be an ℒ-structure and let s: 𝒯→A be an assignment, where 𝒯is
the set of the variables and constant symbols in ℒ. For a variable v and d ∈A, recall that
the function sv|d is exactly like s, except at v, where sv|d(v) = d, that is,
sv|d(v′) = {s(v′),
if v′
̸= v,
d,
if v′ = v.
Let x be a variable where x
̸= v and let e ∈A. Then, the function (sv|d)x|e is exactly like s,
except at the variables v and x, where
(sv|d)x|e(v) = d
and
(sv|d)x|e(x) = e.
Observe that
(sv|d)x|e = (sx|e)v|d.
(3.8)
On the other hand, one can show that (sv|d)v|e = sv|e and (sx|e)x|d = sx|d.
We end this section by showing, as promised, that Definition 3.2.6 is an application
of Theorems 1.1.27 and 3.1.16. Let A be an ℒ-structure with domain A. Let 𝒮be the set of
all the atomic formulas of ℒ, let ℱ= {ℰ¬, ℰ→, ℰQ1, ℰQ2, . . . } (see (3.4)), and let 𝒮be the set
generated from 𝒮by the functions in ℱ. By Theorem 3.1.16, we know that 𝒮is the set of
all the wffs and that 𝒮is freely generated from the set 𝒮by the functions in ℱ. Let U be
the set of all assignments and let 𝒰be the set of all subsets of U. For each function in ℱ
we define the associated functions F¬: 𝒰→𝒰, F→: 𝒰2 →𝒰, FQi: 𝒰→𝒰(for each i ≥1)
as follows:
F¬(a) = U \ a,
F→(a, b) = (U \ a) ∪b,
FQi(a) = {s ∈U : for all d ∈A, svi|d ∈a}.
Now define h: 𝒮→𝒰by
h( ̇=t1t2) = {s ∈U : s(t1) = s(t2)},
h(Pt1t2 ⋅⋅⋅tn) = {s ∈U : ⟨s(t1), . . . , s(tn)⟩∈PA},
for each atomic formula ̇=t1t2 and Pt1t2 ⋅⋅⋅tn. Theorems 1.1.27 and 3.1.16 now imply that
there is a unique function h: 𝒮→𝒰such that:
(1) h(α) = h(α) if α is an atomic formula,
(2) h((¬α)) = U \ h(α),
(3) h((α →β)) = (U \ h(α)) ∪h(β),
(4) h(∀viα) = {s ∈U : for all d ∈A, svi|d ∈h(α)}.

72
౪
3 First-order logic
Define the relation A 󳀀󳨐φ[s] between φ and s by
A 󳀀󳨐φ[s]
if and only if
s ∈h(φ)
(3.9)
for all wffs φ and all assignments s. Using (3.9) and conditions (1)–(4), one can show that
the relation A 󳀀󳨐φ[s] satisfies Definition 3.2.6.
Satisfaction relation for sentences
A sentence in a first-order language has no free variables. So given a structure for this
language, one may suspect that if a sentence is true in the structure, then its truth should
be independent of any assignment to the variables in the language. Our focus in this
section is on addressing this suspicion. First we must show that if two assignments agree
on all of the variables in a term, then the two assignments will assign the term to the
same element in the domain of the structure.
Lemma 3.2.10. Let A be a structure for a language ℒ. Suppose that s and s′ are assign-
ments that agree on all of the variables in a term t. Then s(t) = s′(t), where s′ = s′.
Proof. We prove the following statement by induction on terms: Whenever assign-
ments s and s′ agree on all of the variables in a term t, then s(t) = s′(t).
Base step: Let c and v be a constant and a variable, respectively, of the language ℒ.
Clearly, s(c) = s′(c) by the definition of s and s′, for any two assignments s and s′. If
s and s′ agree on the variables in v, then s(v) = s′(v), and thus s(v) = s′(v).
Inductive step: Let f be an arbitrary n-place function symbol in ℒand let t1, t2, . . . , tn be
arbitrary terms. Assume the induction hypothesis
For each i ≤n, if s and s′ agree on the variables in ti, then s(ti) = s′(ti).
(IH)
We must prove that the same holds for the term ft1t2 ⋅⋅⋅tn. Let s and s′ be assignments
that agree on the variables in ft1t2 ⋅⋅⋅tn. Then for each i ≤n s and s′ agree on the vari-
ables in ti. Hence
s(ft1t2 ⋅⋅⋅tn) = f A(s(t1), s(t2), . . . , s(tn))
by Theorem 3.2.5(3),
= f A(s′(t1), s′(t2), . . . , s′(tn))
by (IH),
= s′(ft1t2 ⋅⋅⋅tn)
by Theorem 3.2.5(3).
We can now extend Lemma 3.2.10 to formulas as well.
Theorem 3.2.11. Let A be an ℒ-structure. For all assignments s and s′ that agree on all
of the free variables in the wff φ, we have
A 󳀀󳨐φ[s]
if and only if
A 󳀀󳨐φ[s′].

3.2 Truth and structures
౪
73
Proof. We prove the following statement by induction on wffs: If assignments s and s′
agree on all of the free variables in φ, then A 󳀀󳨐φ[s] if and only if A 󳀀󳨐φ[s′].
Base step: Let ϕ = Pt1t2 ⋅⋅⋅tn be an atomic formula and let s and s′ be assignments that
agree on all of the free variables in Pt1 ⋅⋅⋅tn. Hence, s and s′ agree on all of the free
variables in t1, . . . , tn. Thus,
A 󳀀󳨐Pt1t2 ⋅⋅⋅tn[s]
iff
⟨s(t1), . . . , s(tn)⟩∈PA
by Definition 3.2.6(2),
iff
⟨s′(t1), . . . , s′(tn)⟩∈PA
by Lemma 3.2.10,
iff
A 󳀀󳨐Pt1t2 ⋅⋅⋅tn[s′]
by Definition 3.2.6(2).
Therefore, the proof of the base step is complete.
Inductive step: Let α and β be arbitrary wffs. Assume the induction hypothesis
A 󳀀󳨐α[s]
iff
A 󳀀󳨐α[s′],
A 󳀀󳨐β[s]
iff
A 󳀀󳨐β[s′],
(IH)
for all assignments s and s′ that agree on the free variables in the formulas α and β,
respectively. We must prove that the same holds for each of the following:
(¬α), (α →β), ∀vα.
Case (¬α): Let s and s′ be assignments that agree on all of the free variables in (¬α). It
follows that s and s′ agree on all of the free variables in α. Therefore, the first part of the
induction hypothesis (IH) holds. Hence
A 󳀀󳨐(¬α)[s]
iff
A
̸󳀀󳨐α[s]
by Definition 3.2.6(3),
iff
A
̸󳀀󳨐α[s′]
by (IH),
iff
A 󳀀󳨐(¬α)[s′]
by Definition 3.2.6(3).
Case (α →β): Let s and s′ be assignments that agree on all of the free variables in the
wff (α →β). It follows that s and s′ agree on all of the free variables in both α and β.
Therefore, the induction hypothesis (IH) holds. Hence
A 󳀀󳨐(α →β)[s]
iff
A 󳀀󳨐α[s] implies A 󳀀󳨐β[s]
by Definition 3.2.6(4),
iff
A 󳀀󳨐α[s′] implies A 󳀀󳨐β[s′]
by (IH),
iff
A 󳀀󳨐(α →β)[s′]
by Definition 3.2.6(4).
Case ∀vα: Let s and s′ be assignments that agree on all of the free variables in ∀vα. Since
v is not free in ∀vα, it does not follow that s and s′ agree on the variable v. However, for
any d ∈A, it does follow that sv|d and s′
v|d agree on v and hence on all the variables in

74
౪
3 First-order logic
α. Thus, the induction hypothesis (IH) implies that A 󳀀󳨐α[sv|d] if and only if A 󳀀󳨐α[s′
v|d],
for any d ∈A. Therefore,
A 󳀀󳨐∀vα[s]
iff
for every d ∈A, A 󳀀󳨐φ[sv|d]
by Definition 3.2.6(5),
iff
for every d ∈A, A 󳀀󳨐φ[s′
v|d]
by (IH),
iff
A 󳀀󳨐∀vα[s′]
by Definition 3.2.6(5).
The following corollary shows that for a sentence φ, the truth or falsity of A 󳀀󳨐φ[s]
is independent of the assignment s. Thus, we can write A 󳀀󳨐φ if for some (hence every)
assignment s, we have A 󳀀󳨐φ[s].
Corollary 3.2.12. Let A be a structure for a language ℒ. Let φ be a sentence. Then
A 󳀀󳨐φ[s] for every assignment s if and only if A 󳀀󳨐φ[s′] for some assignment s′.
Proof. Let A be a structure for a language ℒwith domain A. Let φ be any sentence.
(⇒). Assume that A 󳀀󳨐φ[s] for every assignment s. Then (since A is nonempty) it
follows that A 󳀀󳨐φ[s′] for some assignment s′.
(⇐). Assume that A 󳀀󳨐φ[s′] for some assignment s′. We shall show that A 󳀀󳨐φ[s] for
every assignment s. Let s be an arbitrary assignment. Since φ is a sentence, it has no free
variables. Thus, s and s′ agree on all the free variables in φ. Theorem 3.2.11 now implies
that A 󳀀󳨐φ[s].
Corollary 3.2.12 supports our next definition.
Definition 3.2.13. Let A be an ℒ-structure. Let φ be any sentence. We shall say that φ is
true in A or that A is a model of φ, denoted by A 󳀀󳨐φ, if for some (or every) assignment s,
we have A 󳀀󳨐φ[s]. In addition, let Σ be a set of sentences. We shall say that A is a model
of Σ if A 󳀀󳨐φ for all φ in Σ.
Example 3.2.14. Let ℒ= { ̇0, ̇1, ̇+, ̇×, ̇=} be the language having equality, two 2-place func-
tion symbols ̇+ and ̇×, and two constant symbols ̇0, ̇1. Now consider the two structures
R = ⟨ℝ; 0, 1, +, ×⟩and Q = ⟨ℚ; 0, 1, +, ×⟩, where + and × are the standard addition and
multiplication operations. Find a sentence φ in the language ℒthat is true in one of these
structures but false in the other.
Solution. Let φ be the sentence ∃v(v ̇× v = ̇1 ̇+ ̇1). Then R 󳀀󳨐φ since √2 ∈ℝ. However,
Q
̸󳀀󳨐φ because √2 ∉ℚ.
3.2.3 Logical implication
Logical implication is a truth preserving relation between a given set of premises and
a conclusion; namely, whenever the premises are all true, the conclusion is true. The
definition of logical implication in first-order logic is very similar to the definition of

3.2 Truth and structures
౪
75
tautological implication in propositional logic (see Definition 2.2.10). However, the fol-
lowing definition of logical implication is more complicated than that of tautological
implication, in part because Tarski’s definition of satisfaction is complex.
For the duration of this section, let ℒbe a given language and let 𝒯be the set of all
the variables and constant symbols in ℒ.
Definition 3.2.15. Let Γ be a set of wffs and let φ be a wff. Then Γ logically implies φ,
denoted by Γ 󳀀󳨐φ, if and only if for every structure A and every assignment s: 𝒯→A, if
A 󳀀󳨐α[s] for every α in Γ, then A 󳀀󳨐φ[s].
Remark 3.2.16. Some special cases concerning Definition 3.2.15 deserve mention.
(a) If Γ is the empty set ⌀, then every structure models Γ.
(b) It follows from (a) that ⌀󳀀󳨐φ if and only if A 󳀀󳨐φ[s] for every structure A and every
assignment s.
(c) If there is no structure and assignment that will satisfy all of the wffs in Γ, then it is
vacuously true that Γ 󳀀󳨐φ, for any φ.
(d) If Γ is a singleton {γ}, then we write γ 󳀀󳨐φ in place of {γ} 󳀀󳨐φ.
Definition 3.2.17. Let φ be a wff. Then φ is logically valid (written as 󳀀󳨐φ) if and only if
for every structure A and every assignment s: 𝒯→A, we have A 󳀀󳨐φ[s].
Definition 3.2.18. Two wffs φ and ψ are logically equivalent (denoted by φ 󳀀󳨐
󳀀󳨐
ψ) if φ 󳀀󳨐ψ
and ψ 󳀀󳨐φ.
Corollary 3.2.12 implies that for sentences, Definition 3.2.15 does not depend on the
assignments. So logical implication can be stated more concisely for sentences.
Corollary 3.2.19. Let Σ be a set of sentences and let ψ be a sentence. Then:
1.
Σ 󳀀󳨐ψ if and only if every model of Σ is also a model of ψ;
2.
ψ is logically valid if and only if ψ is true in every structure.
Example 3.2.20. Let ℒ= {Q, P}, where Q is a 1-place predicate symbol and P is a 2-place
predicate symbol. Show that the following hold:
1.
∀v1Qv1 󳀀󳨐Qv2,
2.
Qv1
̸󳀀󳨐∀v1Qv1,
3.
󳀀󳨐¬¬α →α,
4.
∀v1Qv1 󳀀󳨐∃v2Qv2,
5.
∃x∀yPxy 󳀀󳨐∀y∃xPxy,
6.
∀y∃xPxy
̸󳀀󳨐∃x∀yPxy,
7.
󳀀󳨐∃x(Qx →∀yQy).
Solution. We will show why items 1–7 hold.
1.
To show ∀v1Qv1 󳀀󳨐Qv2, let A be an ℒ-structure with assignment s: 𝒯→A such that
A 󳀀󳨐∀v1Qv1[s]. We must show that A 󳀀󳨐Qv2[s], that is, we must show that s(v2) ∈QA.

76
౪
3 First-order logic
Let d = s(v2). Since A 󳀀󳨐∀v1Qv1[s], it follows that A 󳀀󳨐Qv1[sv1|d]. Thus, sv1|d(v1) ∈QA,
so d ∈QA. Therefore, s(v2) ∈QA.
2.
To show Qv1
̸󳀀󳨐∀v1Qv1, we must find a structure A and an assignment s: 𝒯→A
such that A 󳀀󳨐Qv1[s] and A
̸󳀀󳨐∀v1Qv1[s]. Let A = {1, 2}, QA = {2}, PA = ⌀and let
A = ⟨A; QA, PA⟩. For an assignment s such that s(v1) = 2, one can now show that
A 󳀀󳨐Qv1[s] and A
̸󳀀󳨐∀v1Qv1[s].
3.
To show 󳀀󳨐¬¬α →α, let A be an ℒ-structure with assignment s: 𝒯→A. Assume
that A 󳀀󳨐¬¬α[s]. We must show that A 󳀀󳨐α[s]. Since A 󳀀󳨐¬¬α[s], it follows that
A
̸󳀀󳨐¬α[s] by Remark 3.2.8(3). Since A
̸󳀀󳨐¬α[s], it follows that A 󳀀󳨐α[s], again by
Remark 3.2.8(3).
4.
To show ∀v1Qv1 󳀀󳨐∃v2Qv2, let A be an ℒ-structure with assignment s: 𝒯→A. As-
sume that A 󳀀󳨐∀v1Qv1[s]. We must show that A 󳀀󳨐∃v2Qv2[s], that is, we must show
that for some d ∈A we have A 󳀀󳨐Qv2[sv2|d]. Since A 󳀀󳨐∀v1Qv1[s], it follows that for
all d ∈A, A 󳀀󳨐Qv1[sv1|d]. Thus, because the universe of A is nonempty, there is a
d ∈A such that A 󳀀󳨐Qv1[sv1|d]. Hence, sv1|d(v1) = d ∈QA, so sv2|d(v2) = d ∈QA. We
conclude that A 󳀀󳨐∃v2Qv2[s].
5.
To show ∃x∀yPxy 󳀀󳨐∀y∃xPxy, let A be an ℒ-structure and let s: 𝒯→A be such that
A 󳀀󳨐∃x∀yPxy[s]. By Remark 3.2.8(8)(9), there exists a d ∈A such that for all e ∈A,
we have A 󳀀󳨐Pxy[(sx|d)y|e] (see Remark 3.2.9). So, for all e ∈A, there is a d ∈A
such that A 󳀀󳨐Pxy[(sy|e)x|d] (see equation (3.8)). Therefore, by Remark 3.2.8(8)(9),
A 󳀀󳨐∀y∃xPxy[s].
6.
To show ∀y∃xPxy
̸󳀀󳨐∃x∀yPxy, we must find a structure A and s: 𝒯→A such that
A 󳀀󳨐∀y∃xPxy[s] and A
̸󳀀󳨐∃x∀yPxy[s]. Let A = ℤ, PA = < (the standard less than
relation), QA = ⌀and let A = ⟨A; QA, PA⟩. For any assignment s, one can now
show that A 󳀀󳨐∀y∃xPxy[s] (because there is no largest integer) and A
̸󳀀󳨐∃x∀yPxy[s]
(because there is no smallest integer).
7.
To show that 󳀀󳨐∃x(Qx →∀yQy), let A be an ℒ-structure and let s: 𝒯→A. We must
show that A 󳀀󳨐∃x(Qx →∀yQy)[s]. There are two cases to consider.
Case (i): QA = A. Let d ∈A. As QA = A, we see that d ∈QA. So A 󳀀󳨐Qx[sx|d] and
A 󳀀󳨐∀yQy[sx|d]. It thus follows that A 󳀀󳨐(Qx →∀yQy)[sx|d], by Remark 3.2.8(6).
Therefore, A 󳀀󳨐∃x(Qx →∀yQy)[s], by Remark 3.2.8(9).
Case (ii): QA
̸= A. Let d ∈A be such that d ∉QA. We see that A
̸󳀀󳨐Qx[sx|d]. It thus fol-
lows (vacuously) that if A 󳀀󳨐Qx[sx|d], then A 󳀀󳨐∀yQy[s]. Hence, by Remark 3.2.8(6),
A 󳀀󳨐(Qx →∀yQy)[sx|d]. Therefore, A 󳀀󳨐∃x(Qx →∀yQy)[s], by Remark 3.2.8(9).
3.2.4 Definability over a structure
Let A be an ℒ-structure with universe A. Some subsets of A and relations on A can be
singled out by using a wff and the satisfaction relation. In this case, we can say that the
subset or relation is definable over A. This is an important concept that we will pursue
in this section. Theorem 3.2.11 justifies the following definition.

3.2 Truth and structures
౪
77
Definition 3.2.21. Let A be an ℒ-structure and let φ be a wff having all of its free vari-
ables in the list v1, v2, . . . , vk. For all a1, a2, . . . , ak in A, the notation
A 󳀀󳨐φ⟦a1, a2, . . . , ak⟧
means that for some (hence for any) assignment s: 𝒯→A such that s(vi) = ai for each
i = 1, 2, . . . , k, we have A 󳀀󳨐φ[s].
Example 3.2.22. Let ℒ= {L, f , c} and let A be as in Example 3.2.7. Let φ be the wff
∃v2Lfv2v1. Then A 󳀀󳨐φ⟦2⟧and A
̸󳀀󳨐φ⟦1⟧.
Let ℒ= { ̇0, ̇1, ̇+, ̇×, ̇=} be the language having equality, two 2-place function symbols
̇+ and ̇×, and two constant symbols ̇0, ̇1. Let R = ⟨ℝ; 0, 1, +, ×⟩be the structure, where
+ and × are the standard operations of addition and multiplication. The structure R is
called the real field. Note that for any a ∈ℝ, it follows that a ≥0 if and only if a = x2 for
some x ∈ℝ. This fact implies that there is a wff φ with a free variable such that
R 󳀀󳨐φ⟦a⟧
iff
a ≥0.
Let φ be the wff ∃x(v1 ̇= x ̇× x). Then
R 󳀀󳨐∃x(v1 ̇= x ̇× x)⟦a⟧
iff
a ≥0.
For this reason, we shall say that the interval [0, ∞) is definable over R and that the
formula ∃x(v1 ̇= x ̇× x) defines [0, ∞) in R.
Moreover, for any a, b ∈ℝ, a ≤b if and only if b = a + x2 for some x ∈ℝ. Thus, the
ordering relation “less than or equal to” is also definable over the structure R, that is,
there is a wff ψ with two free variables such that
R 󳀀󳨐ψ⟦a, b⟧
iff
a ≤b.
Let ψ be the wff ∃x(v2 ̇= v1 ̇+ x ̇× x). Then
R 󳀀󳨐∃x(v2 ̇= v1 ̇+ x ̇× x)⟦a, b⟧
iff
a ≤b.
Thus, we can say that the relation {⟨a, b⟩∈ℝ× ℝ| a ≤b} is definable over R and that
the formula ∃x(v2 ̇= v1 ̇+ x ̇× x) defines this relation in R.
We now give a precise description of the concept of definability over a structure.
Definition 3.2.23. Let A be an ℒ-structure with domain A. Let φ be a wff having all of
its free variables in the list v1, v2, . . . , vk. Then the k-ary relation on A
{⟨a1, a2, . . . , ak⟩| A 󳀀󳨐φ⟦a1, a2, . . . , ak⟧}
is definable over A and the formula φ defines this k-ary relation in A.

78
౪
3 First-order logic
Example 3.2.24 (Sublanguage of elementary number theory). Recall
the
language
of
number theory ℒ= { ̇<, ̇0, ̇S, ̇+, ̇×, ̇E, ̇=} in Example 3.1.4. Consider the sublanguage
ℒ′ = { ̇0, ̇S, ̇+, ̇×, ̇=} of ℒand also the ℒ′-structure 𝒩= ⟨ℕ; 0, S, +, ×⟩, where ̇0𝒩= 0,
̇S𝒩= S (successor function), and
̇+𝒩= +,
̇×𝒩= × are the standard operations of
addition and multiplication, respectively. We identify some subsets of ℕand relations
on ℕthat are definable over 𝒩:
1.
Let m, n ∈ℕ. Clearly, m < n if and only if n = m + k for some k ∈ℕ, where k ≥1.
Moreover, k ≥1 when k = i + 1 for an i ∈ℕ. This allows us to now show that the
relation {⟨m, n⟩: m < n} is definable over 𝒩. The formula
∃v3(v2 ̇= v1 ̇+ ̇Sv3)
is such that
m < n
iff
𝒩󳀀󳨐∃v3(v2 ̇= v1 ̇+ ̇Sv3)⟦m, n⟧.
2.
For each n ∈ℕ, it follows that {n} is definable. For example, for the wff v1
̇= ̇S ̇S ̇S ̇0,
we see that {3} = {n : 𝒩󳀀󳨐v1 ̇= ̇S ̇S ̇S ̇0⟦n⟧}.
3.
The set of prime numbers is also definable over 𝒩. Observe that p ∈ℕis a prime
if and only if 1 < p and for all m, n ∈ℕ, if m ⋅n = p, then m = 1 or n = 1. Let us
first try the following formula, where 1 is represented by ̇S ̇0, p is represented by the
variable v1, and v2 and v3 represent m and n, respectively. Thus, we obtain
̇S ̇0 < v1 ∧∀v2∀v3(v2 ̇× v3 ̇= v1 →(v2 ̇= ̇S ̇0 ∨v3 ̇= ̇S ̇0)).
As < is not part of the language ℒ′, we must replace ̇S ̇0 < v1 with an appropriate
ℒ′-wff. By item 1, we have 1 < p if and only if 𝒩󳀀󳨐∃v3(v1 ̇= ̇S ̇0 ̇+ ̇Sv3)⟦p⟧. Thus, the
set of primes is definable over 𝒩by the ℒ′-wff
∃v3(v1 ̇= ̇S ̇0 ̇+ ̇Sv3) ∧∀v2∀v3(v2 ̇× v3 ̇= v1 →(v2 ̇= ̇S ̇0 ∨v3 ̇= ̇S ̇0)).
Some relations on a structure are definable over the structure and some are not.
The concept of a homomorphism (see Section 3.2.6) can sometimes be used to show that
a relation is not definable over a given structure.
3.2.5 Classes of structures
A structure consists of a set along with functions and relations that are defined on the
set. In mathematics, one often studies a particular collection of structures because they
each satisfy a specific set of axioms. For example, groups, rings, fields, and vector spaces
are four types of structures that each satisfy four different sets of axioms. In this section,

3.2 Truth and structures
౪
79
we want to pursue this theme in terms of structures of a particular language that satisfy
all of the sentences in a specific set.
Definition 3.2.25. Let Σ be a set of sentences in a given language ℒ. Then Mod(Σ) de-
notes the class (collection) of all ℒ-structures in which every sentence in Σ is true, that
is, Mod(Σ) is the collection of all ℒ-structures A such that A 󳀀󳨐φ for all φ ∈Σ.
For a single sentence ψ we shall write Mod(ψ) rather than Mod({ψ}).
Example 3.2.26. Consider the language ℒ= {e, ∗, ̇=} of groups as discussed in Exam-
ple 3.2.1. Let Σ be the set consisting of the following three group axioms:
1.
∀v1∀v2∀v3(v1 ∗(v2 ∗v3) ̇= (v1 ∗v2) ∗v3),
2.
∀v1(v1 ∗e ̇= v1),
3.
∀v1∃v2(v1 ∗v2 ̇= e).
Then Mod(Σ) is the collection of all groups.
Let 𝒦be a collection of structures for a language. Suppose that every structure in
𝒦satisfies one particular sentence and any structure that satisfies this sentence is also
in 𝒦. When this is the case, 𝒦is called an elementary class (EC).
Definition 3.2.27. Let 𝒦be a class of structures for a given language ℒ. Then 𝒦is said
to be an EC if 𝒦= Mod(ψ) for some ℒ-sentence ψ.
The term “elementary” is a synonym for “first-order” and the term “class” is a
synonym for the word “collection.” Our next definition is just an extension of Defini-
tion 3.2.27.
Definition 3.2.28. A class 𝒦of ℒ-structures is said to be an EC in the wider sense (ECΔ)
if 𝒦= Mod(Σ) for some set of ℒ-sentences Σ.
Two structures for a language may be different, but they may be alike with respect
to satisfying the exact same sentences in the language.
Definition 3.2.29. Let A and B be ℒ-structures. Then A and B are elementarily equiva-
lent, denoted by A ≡B, if and only if for every sentence φ
A 󳀀󳨐φ
iff
B 󳀀󳨐φ.
That is, two structures are elementarily equivalent if they satisfy the same sen-
tences. Different worlds can sometimes share the same truths.
Definition 3.2.30. Let 𝒦be a class of ℒ-structures. Then 𝒦is elementarily closed if for
all ℒ-structures A and B, if A ∈𝒦and A ≡B, then B ∈𝒦.
Let Σ be a set of sentences in a language ℒ. Then 𝒦= Mod(Σ) is elementarily closed,
because if A ∈𝒦and A ≡B, then B 󳀀󳨐φ for all φ ∈Σ, so B ∈𝒦.

80
౪
3 First-order logic
Definition 3.2.31. Let A be an ℒ-structure. The theory of A, denoted by Th(A), is the set
of all ℒ-sentences true in A, that is,
Th(A) = {φ : φ is a sentence and A 󳀀󳨐φ}.
Let A be an ℒ-structure. Then A ∈Mod(Th(A)) and, as noted above, Mod(Th(A))
is elementarily closed. So, in particular, given any ℒ-structure A there is always a set of
sentences Σ such that A ∈Mod(Σ).
3.2.6 Homomorphisms
In linear algebra there is an interest in functions from one vector space V into another
vector space W that preserve vector addition and scalar multiplication.
Definition. If T: V →W is a function from a vector space (V, +, ⋅) to the vector space
(W, ⊕, ∗), then T is called a linear transformation if for all vectors x and y in V and for
all scalars c, the following hold:
(1) T(x + y) = T(x) ⊕T(y),
(2) T(c ⋅x) = c ∗T(x).
In group theory one defines what it means for a function from one group G to an-
other group G′ to preserve the algebraic structure of the group G.
Definition. Let (G, ∗) and (G′, ⊛) be two groups. A function φ : G →G′ is called a homo-
morphism if for all a, b ∈G, φ(a ∗b) = φ(a) ⊛φ(b).
In this section, we will generalize these fundamental concepts to structures.
Functions that preserve operations and relations of structures
In mathematics, one uses a function to relate one set to another set. In mathematical
logic, a homomorphism relates one structure with another structure. More specifically,
a homomorphism is a structure preserving function between two structures of the same
language. The word homomorphism is derived from ancient Greek, where “homos”
means “same” and “morphe” means “form.”
Definition 3.2.32. Let A = ⟨A; . . . ⟩and B = ⟨B; . . . ⟩be ℒ-structures. A function h: A →B
is called a homomorphism if h has the following properties:
(1) For each n-place predicate symbol P and for all a1, a2, . . . , an ∈A, we have
⟨a1, a2, . . . , an⟩∈PA
iff
⟨h(a1), h(a2), . . . , h(an)⟩∈PB.
(2) For each n-place function symbol f and for all a1, a2, . . . , an ∈A, we have

3.2 Truth and structures
౪
81
h(f A(a1, a2, . . . , an)) = f B(h(a1), h(a2), . . . , h(an)).
(3) For each constant symbol c, we have h(cA) = cB.
Conditions (1)–(3) are often expressed, respectively, as: “h preserves the relations,
the functions, and the constants.”
Example 3.2.33. Consider the language ℒ= { ̇+, ̇×} and let A = ⟨ℕ; ̇+A, ̇×A⟩, where
̇+A and
̇×A are the standard addition and multiplication operations, respectively, on
the natural numbers. Define a new structure, whose domain has just two elements, by
B = ⟨{o, e}; ̇+B, ̇×B⟩, where ̇+B and ̇×B are given by the following addition and multi-
plication tables:
̇+B
e
o
e
e
o
o
o
e
̇×B
e
o
e
e
e
o
e
o
The addition table can be viewed as saying that “even plus even is even,” “even plus odd
is odd,” and “odd plus odd is even,” and similarly for the multiplication table.
Now define h: ℕ→{o, e} by
h(n) = {e,
if n is even,
o,
if n is odd.
Then h is a homomorphism, as clause (2) of Definition 3.2.32 is satisfied as follows:
h(n ̇+A m) = h(n) ̇+B h(m),
h(n ̇×A m) = h(n) ̇×B h(m).
For example, if m and n are both odd, then n
̇×A m is odd. Thus, h(n
̇×A m) = o and
h(n) ̇×B h(m) = o ̇×B o = o. Hence, h(n ̇×A m) = h(n) ̇×B h(m).
Definition 3.2.34. Let A = ⟨A; . . . ⟩and B = ⟨B; . . . ⟩be structures for the language ℒ.
Let h: A →B be a homomorphism.
–
We shall say h is a homomorphism of A into B.
–
We shall say that h: A →B is an isomorphism or an isomorphic embedding if h is
one-to-one. In this case, we shall say that h is an isomorphism of A into B.
–
When h: A →B is onto B, we shall say that h is a homomorphism of A onto B.
–
If h is both one-to-one and onto B, then A and B are isomorphic, denoted by A ≅B.
In this case, we shall say that h is an isomorphism of A onto B.
Example 3.2.35. Let ℒ= { ̇<} and let 𝒫= ⟨ℙ; ̇<𝒫⟩, where ℙ= {1, 2, 3, . . . } and ̇<𝒫is the
standard “less than” relation on ℙ. Let 𝒩= ⟨ℕ; ̇<𝒩⟩, where ℕ= {0, 1, 2, 3, . . . } and ̇<𝒩

82
౪
3 First-order logic
is the standard “less than” relation on ℕ. Define h: ℙ→ℕby h(n) = n −1. Then h is a
homomorphism, as clause (1) of Definition 3.2.32 is satisfied as follows:
n ̇<𝒫m
iff
h(n) ̇<𝒩h(m).
Since h is one-to-one, we conclude that h is an isomorphic embedding. In addition, be-
cause h is onto ℕ, we see that the structures 𝒫and 𝒩are isomorphic.
Definition 3.2.36. Let A = ⟨A; . . . ⟩and B = ⟨B; . . . ⟩be ℒ-structures. We shall say that A
is a substructure of B if A ⊆B and the following conditions hold:
(a) For each n-place predicate symbol P and for all a1, a2, . . . , an ∈A, we have
⟨a1, a2, . . . , an⟩∈PA
iff
⟨a1, a2, . . . , an⟩∈PB.
(b) For each n-place function symbol f and for all a1, a2, . . . , an ∈A, we have
f A(a1, a2, . . . , an) = f B(a1, a2, . . . , an).
(c) For each constant symbol c, we have cA = cB.
Example 3.2.37. Consider the language ℒ= { ̇+} and let 𝒬= ⟨ℚ; ̇+𝒬⟩, where ℚis the set
of rational numbers and ̇+𝒬is the standard addition operation on ℚ. Let ℛ= ⟨ℝ; ̇+ℛ⟩,
where ℝis the set of real numbers and
̇+ℛis the standard addition operation on ℝ.
Then 𝒬is a substructure of ℛbecause clause (b) of Definition 3.2.36 is satisfied, that is,
the operations ̇+𝒬and ̇+ℛagree on the rational numbers.
Let A and B be structures for the language ℒ. Then A is a substructure of B if and
only if A ⊆B and the identity function i: A →B is a homomorphism.
The homomorphism theorem
We will soon state and prove our primary theorem about homomorphisms. The last part
of this theorem will provide us with a technique for showing that some relations are not
definable over a structure (see Theorem 3.2.41).
We begin by making some relevant remarks. Let A = (A; . . . ) and B = (B; . . . ) be
ℒ-structures and let 𝒯be the set of all the variables and constants of ℒ. Let s: 𝒯→A
be an assignment. Thus, by Theorem 3.2.5, there is a unique extension s: 𝒯→A, where
𝒯is the set of all the terms of ℒ. Suppose that h is a homomorphism of A into B. Then
h ∘s: 𝒯→B is also an assignment, where (h ∘s)(v) = h(s(v)) for all v ∈𝒯. Thus, by
Theorem 3.2.5, there is a unique extension h ∘s: 𝒯→B. We also note that a quantifier-
free wff is one in which no quantifier appears in the formula.
Theorem 3.2.38 (Homomorphism theorem). Let A and B be ℒ-structures, let h be a ho-
momorphism of A into B, and let s: 𝒯→A be an assignment, where 𝒯is the set of all the
variables and constant symbols of ℒand A is the domain of A.

3.2 Truth and structures
౪
83
(a) For every term t of the language, h(s(t)) = h ∘s(t).
(b) For every quantifier-free wff φ that does not contain the equality symbol,
A 󳀀󳨐φ[s]
iff
B 󳀀󳨐φ[h ∘s].
(c) If h is one-to-one, then for every quantifier-free wff φ that can contain the equality
symbol,
A 󳀀󳨐φ[s]
iff
B 󳀀󳨐φ[h ∘s].
(d) If h is onto B, then for every wff φ that does not contain the equality symbol,
A 󳀀󳨐φ[s]
iff
B 󳀀󳨐φ[h ∘s].
(e) If h is one-to-one and onto B, then for every wff φ,
A 󳀀󳨐φ[s]
iff
B 󳀀󳨐φ[h ∘s].
Proof. We shall prove (a)–(e) below. Let h be a homomorphism of A into B. In the proofs
of (a)–(c), let s: 𝒯→A be an arbitrary assignment.
(a) We must first prove that for every term t of the language, h(s(t)) = h ∘s(t). This will
be accomplished by induction on terms (see Section 3.1.2 on page 56).
Base step: For a constant symbol c, we have h(s(c)) = h(cA) = cB by Theorem 3.2.5(2)
and Definition 3.2.32(3). Also, h ∘s(c) = cB by Theorem 3.2.5(2) applied to h ∘s.
Therefore, h(s(c)) = h ∘s(c). In the case where v is a variable,
h(s(v)) = h(s(v)) = (h ∘s)(v) = h ∘s(v),
by Theorem 3.2.5(1) applied to s and h ∘s.
Inductive step: Let f be an n-place function symbol in ℒand let t1, t2, . . . , tn be terms.
Assume the induction hypothesis
For each i ≤n, we have h(s(ti)) = h ∘s(ti).
(IH)
We prove that the same holds for the term ft1t2 ⋅⋅⋅tn, that is, we prove that
h(s(ft1t2 ⋅⋅⋅tn)) = h ∘s(ft1t2 ⋅⋅⋅tn).
We do this as follows:
h(s(ft1t2 ⋅⋅⋅tn)) = h(f A(s(t1), s(t2), . . . , s(tn)))
by Theorem 3.2.5(3),
= f B(h(s(t1)), h(s(t2)), . . . , h(s(tn)))
by Definition 3.2.32(2),

84
౪
3 First-order logic
= f B(h ∘s(t1), h ∘s(t2), . . . , h ∘s(tn))
by (IH),
= h ∘s(ft1t2 ⋅⋅⋅tn)
by Theorem 3.2.5(3).
(b) For every φ that is a quantifier-free wff not containing the symbol ̇=, we prove that
A 󳀀󳨐φ[s]
iff
B 󳀀󳨐φ[h ∘s].
(󳵳)
We use induction on wffs.
Base step: We show that (󳵳) holds for all atomic formulas. So, let P be an n-place
predicate symbol and let t1, . . . , tn be terms. We show that
A 󳀀󳨐Pt1t2 ⋅⋅⋅tn[s]
iff
B 󳀀󳨐Pt1t2 ⋅⋅⋅tn[h ∘s]
as follows:
A 󳀀󳨐Pt1t2 ⋅⋅⋅tn[s]
iff
⟨s(t1), . . . , s(tn)⟩∈PA
by Definition 3.2.6(2),
iff
⟨h(s(t1)), . . . , h(s(tn))⟩∈PB
by Definition 3.2.32(1),
iff
⟨h ∘s(t1), . . . , h ∘s(tn)⟩∈PB
by part (a) above,
iff
B 󳀀󳨐Pt1t2 ⋅⋅⋅tn[h ∘s]
by Definition 3.2.6(2).
Inductive step: Let α and β be quantifier-free formulas that do not contain the equal-
ity symbol. Assume the induction hypothesis
A 󳀀󳨐α[s]
iff
B 󳀀󳨐α[h ∘s],
A 󳀀󳨐β[s]
iff
B 󳀀󳨐β[h ∘s].
(IH)
One must now prove that (¬α) and (α →β) both satisfy condition (󳵳). We first prove
that (¬α) satisfies condition (󳵳) with the following argument:
A 󳀀󳨐¬α[s]
iff
A
̸󳀀󳨐α[s]
by Definition 3.2.6(3),
iff
B
̸󳀀󳨐α[h ∘s]
as α satisfies (IH),
iff
B 󳀀󳨐¬α[h ∘s]
by Definition 3.2.6(3).
We now prove that (α →β) satisfies condition (󳵳) as follows:
A 󳀀󳨐(α →β)[s]
iff
A 󳀀󳨐α[s] implies A 󳀀󳨐β[s]
by Definition 3.2.6(4),
iff
B 󳀀󳨐α[h ∘s] implies B 󳀀󳨐β[h ∘s]
as α, β satisfy (IH),
iff
B 󳀀󳨐(α →β)[h ∘s]
by Definition 3.2.6(4).
(c) We must show that if h is one-to-one, then for every quantifier-free formula φ,
A 󳀀󳨐φ[s]
iff
B 󳀀󳨐φ[h ∘s].

3.2 Truth and structures
౪
85
The argument is by induction, just as in the above proof of part (b). However, in the
base step of (b), we need to add the following proof showing that the atomic formula
̇=t1t2 satisfies (󳵳). Let t1 and t2 be terms. We then have the following:
A 󳀀󳨐̇=t1t2[s]
iff
s(t1) = s(t2)
by Definition 3.2.6(1),
iff
h(s(t1)) = h(s(t2))
because h is one-to-one,
iff
h ∘s(t1) = h ∘s(t2)
by part (a) above,
iff
B 󳀀󳨐̇=t1t2[h ∘s]
by Definition 3.2.6(1).
The rest of the argument is exactly like the one given for (b).
(d) Let h be onto B. For every formula φ not containing the symbol ̇=, we prove that
A 󳀀󳨐φ[s]
iff
B 󳀀󳨐φ[h ∘s],
for all assignments s.
(3.10)
The argument is by induction. For atomic formulas φ, the proof of (3.10) is as in
the above proof of part (b). However, in the inductive step, we need to include the
quantifier symbol ∀. The proof of this case follows. Let α be a formula that does not
contain the equality symbol. Assume the induction hypothesis
A 󳀀󳨐α[s]
iff
B 󳀀󳨐α[h ∘s],
for all assignments s.
(IH)
We must show that
A 󳀀󳨐∀vα[s]
iff
B 󳀀󳨐∀vα[h ∘s],
for all assignments s.
Let s: 𝒯→A be an arbitrary assignment and let B be the domain of B. Thus,
A 󳀀󳨐∀vα[s]
iff
for all a ∈A, A 󳀀󳨐α[sv|a]
by Definition 3.2.6(5),
iff
for all a ∈A, B 󳀀󳨐α[h ∘sv|a]
by (IH); sv|a is an assignment,
iff
for all a ∈A, B 󳀀󳨐α[(h ∘s)v|h(a)]
as h ∘sv|a = (h ∘s)v|h(a),
iff
for all b ∈B, B 󳀀󳨐α[(h ∘s)v|b]
as h: A →B is onto B,
iff
B 󳀀󳨐∀vα[(h ∘s)]
by Definition 3.2.6(5).
(e) Suppose that h is one-to-one and onto B. We must show that for every formula φ,
A 󳀀󳨐φ[s]
iff
B 󳀀󳨐φ[h ∘s],
for all assignments s.
The argument is by induction on wffs. For the base step one uses the arguments
given for the base steps in the above proofs of (b) and (c). For the inductive step one
uses the arguments given for the inductive steps in the above proofs of (b) and (d).
This completes the proof of the homomorphism theorem.

86
౪
3 First-order logic
Applications of the homomorphism theorem
Before we state and prove the next theorem, recall that h is said to be an isomorphism
of A onto B when h: A →B is both a one-to-one and onto homomorphism. In this case,
A and B are said to be isomorphic, denoted by A ≅B. Also, recall Definition 3.2.29.
Theorem 3.2.39. Let A and B be structures for a language ℒ. Suppose that A and B are
isomorphic. Then A ≡B.
Proof. Assume that A ≅B. Let φ be a sentence. We will show that A 󳀀󳨐φ iff B 󳀀󳨐φ. Let
h be an isomorphism of A onto B and let s: 𝒯→A be an assignment, where 𝒯is the set
of all the variables and constant symbols of ℒ. Then
A 󳀀󳨐φ
iff
A 󳀀󳨐φ[s]
by Definition 3.2.13,
iff
B 󳀀󳨐φ[h ∘s]
by Theorem 3.2.38(e),
iff
B 󳀀󳨐φ
by Definition 3.2.13.
Application 1. Let ℒ= { ̇<, ̇=} and let 𝒫= ⟨ℙ; ̇<𝒫⟩, where ℙ= {1, 2, 3, . . . } and ̇<𝒫is the
standard “less than” relation on ℙ. Let 𝒩= ⟨ℕ; ̇<𝒩⟩, where ℕ= {0, 1, 2, 3, . . . } and ̇<𝒩
is the standard “less than” relation on ℕ. Now define h: ℙ→ℕby
h(n) = n −1.
As discussed in Example 3.2.35, h is a one-to-one and onto homomorphism, and thus
𝒫and 𝒩are isomorphic. So by Theorem 3.2.39, for any ℒ-sentence φ, we have 𝒫󳀀󳨐
φ iff 𝒩󳀀󳨐φ, that is, 𝒫and 𝒩are elementarily equivalent.
On the other hand, let us define h′: ℙ→ℕto be
h′(n) = n.
Then h′ is also a homomorphism and is one-to-one, but it is not onto ℕ. Let s: T →ℙbe
an assignment. Hence, by Theorem 3.2.38(c), if φ is quantifier-free, then
𝒫󳀀󳨐φ[s]
iff
𝒩󳀀󳨐φ[h′ ∘s].
(3.11)
The equivalence (3.11) may fail for a formula φ that contains quantifiers. To illustrate
this, let s be an assignment such that s(v1) = 1. Since h′ is the identity function, it follows
that h′ ∘s = s. Let φ be the quantified statement
∀v2(v1
̸̇= v2 →v1 ̇< v2).
Since s(v1) = 1 and (h′ ∘s)(v1) = 1, it follows that 𝒫󳀀󳨐φ[s] and 𝒩
̸󳀀󳨐φ[h′ ∘s]. So, because
h′ is one-to-one and not onto ℕ, (3.11) can fail when φ contains quantifiers.
Definition 3.2.40. Let A = ⟨A; . . . ⟩be an ℒ-structure. A function h: A →A is called an
automorphism of the structure A if h is an isomorphism of A onto A.

3.2 Truth and structures
౪
87
Let A = ⟨A; . . . ⟩be a structure for a language ℒ. Recall that a k-ary relation R on A
is definable over A if there is a wff φ with free variables v1, . . . , vk such that
⟨a1, a2, . . . , ak⟩∈R
iff
A 󳀀󳨐φ⟦a1, a2, . . . , ak⟧
for all a1, a2, . . . , ak ∈A.
Theorem 3.2.41. Let A be a structure for a language ℒand let h be an automorphism of
the structure A. Let R be a k-ary relation that is definable over A. Then
⟨a1, a2, . . . , ak⟩∈R
iff
⟨h(a1), h(a2), . . . , h(ak)⟩∈R
for all a1, a2, . . . , ak ∈A.
Proof. Let φ be a wff that defines R. For all a1, a2, . . . , ak ∈A, we have
⟨a1, a2, . . . , ak⟩∈R
iff
A 󳀀󳨐φ⟦a1, a2, . . . , ak⟧
because φ defines R,
iff
A 󳀀󳨐φ
?h(a1), h(a2), . . . , h(ak)
?
by Theorem 3.2.38(e),
iff
⟨h(a1), h(a2), . . . , h(ak)⟩∈R
because φ defines R.
Application 2. Let ℒ= { ̇<, ̇=} and let R = ⟨ℝ; <⟩, where ℝis the set of real numbers and
< is the usual “less than” relation on ℝ. Define h: ℝ→ℝby
h(x) = x3.
Then h is a homomorphism, because clause (1) of Definition 3.2.32 holds as follows:
x < y
iff
h(x) < h(y).
Since h is one-to-one and onto ℝ, we conclude that h is an automorphism of the struc-
ture R. Note that ℕ⊆ℝ. We can now show that ℕis not definable over R. Suppose, for
a contradiction, that there is a wff φ such that
a ∈ℕ
iff
R 󳀀󳨐φ⟦a⟧
for all a ∈ℝ. Theorem 3.2.41 then implies that for all a ∈ℝ,
a ∈ℕ
iff
h(a) ∈ℕ.
Let a =
3√2. Since h(a) = 2 ∈ℕ, the above equivalence implies that
3√2 ∈ℕ. This
contradiction shows that ℕis not definable over R.
Exercises 3.2.
1. Verify item (9) of Remark 3.2.8.
2. Let A be an ℒ-structure and let s be an assignment, as in Definition 3.2.4. Let ψ be
a wff. Show that either A 󳀀󳨐ψ[s] or A 󳀀󳨐(¬ψ)[s], but not both.

88
౪
3 First-order logic
3. Let ℒ= {L, f , c} and let A be as in Example 3.2.7. Let s: 𝒯→ℕbe an assignment
satisfying s(vi) = i + 1. So, s(v1) = 2 and s(v2) = 3. Show that:
(a) A 󳀀󳨐∃v2Lv2fc[s],
(b) A 󳀀󳨐∃v2Lv2v1[s],
(c) A
̸󳀀󳨐∃v2Lv2c[s].
4. Let ℒ= {L, f , c} and let A be as in Example 3.2.7. Show that:
(a) A 󳀀󳨐∀v1∃v2Lfv1v2,
(b) A
̸󳀀󳨐∃v2∀v1Lfv1v2.
5. Let ℒ= { ̇+, ̇0, ̇1, ̇2, ̇=}, where ̇+ is a 2-place function symbol and ̇0, ̇1, ̇2 are constant
symbols.
(a) Find a structure for the language ℒin which the two sentences ̇1 ̇+ ̇1 = ̇2 and
∀v(v ̇+ ̇0 ̇= v) are true.
(b) Find a structure for the language ℒin which the two sentences ̇1 ̇+ ̇1 = ̇2 and
∀v(v ̇+ ̇0 ̇= v) are false.
6. Let ℒ= {f , ̇=} be a language where f is a 1-place function symbol.
(a) Find a sentence φ so that A 󳀀󳨐φ if and only if f A: A →A is one-to-one, for any
structure A = ⟨A; f A⟩.
(b) Find a sentence φ so that A 󳀀󳨐φ if and only if f A: A →A is onto A, for any
structure A = ⟨A; f A⟩.
7. Let ℒ= { ̇<} be the language having just the 2-place relation symbol ̇<. Consider the
structures A = ⟨ℕ; ̇<A⟩and B = ⟨ℝ; ̇<B⟩, where ̇<A and ̇<B are to be interpreted
as the standard “less than” relation. Find a sentence φ in the language ℒthat is true
in one of the structures but false in the other.
8. Let ℒ= { ̇×, ̇=} be the language having equality and ̇×, a 2-place function symbol.
Let A = ⟨ℝ; ̇×A⟩and B = ⟨ℝ∗; ̇×B⟩be structures where ℝ∗is the set of nonzero
real numbers and ̇×A and ̇×B are both the usual multiplication operation. Find a
sentence φ in the language ℒthat is true in one of the structures but false in the
other.
*9. Let α, ψ, φ be wffs and let Γ be a set of wffs in a language ℒ. Show that
(a) Γ ∪{α} 󳀀󳨐φ if and only if Γ 󳀀󳨐(α →φ),
(b) φ 󳀀󳨐
󳀀󳨐
ψ if and only if 󳀀󳨐(φ ↔ψ).
10. Show that the set of any two of the following sentences does not logically imply the
third sentence:
(a) ∀x∀y∀z(Pxy →Pyz →Pxz),
(b) ∀x∀y(Pxy →Pyx →x ̇= y),
(c) ∀x∃yPxy →∃y∀xPxy.
*11. Let A be a structure and let s be an assignment such that s(x) = s(y), where x and
y are variables.
(a) Prove that for all terms t, if t′ is obtained from t by replacing some, none, or
all of the occurrences of x in t with y, then s(t) = s(t′).

3.2 Truth and structures
౪
89
(b) Let Pt1t2 ⋅⋅⋅tn be an atomic formula and let Pt′
1t′
2 ⋅⋅⋅t′
n be the result of replacing
some, none, or all of the occurrences of x in Pt1t2 ⋅⋅⋅tn with y. Show that A 󳀀󳨐
Pt1t2 ⋅⋅⋅tn[s] if and only if A 󳀀󳨐Pt′
1t′
2 ⋅⋅⋅t′
n[s].
*12. Show that {∀x(α →β), ∀xα} 󳀀󳨐∀xβ.
*13. Show that if x does not occur free in α, then α 󳀀󳨐∀xα.
*14. Show that a wff θ is logically valid if and only if ∀xθ is logically valid.
15. Let ℒ= { ̇+, ̇×, ̇=} and let 𝒩= ⟨ℕ; +, ×⟩be an ℒ-structure, where
̇+𝒩= + and
̇×𝒩= × are the usual operations of addition and multiplication, respectively. Show
that each of the following sets are definable over 𝒩:
(a) {0},
(b) {1},
(c) {⟨m, n⟩: n is the successor of m},
(d) {⟨m, n⟩: m < n}.
16. Let ℒ= { ̇+, ̇×, ̇=} be the language having equality and 2-place function symbols ̇+
and ̇×. Consider the ℒ-structure R = ⟨ℝ; +, ×⟩, where + and × are the usual addition
and multiplication operations.
(a) Show that [0, ∞) is definable over R.
(b) Show that {1} is definable over R.
(c) Show that {2} is definable over R.
17. Let Σ and Γ be sets of sentences in a language ℒ. Show that:
(a) if Γ ⊆Σ, then Mod(Σ) ⊆Mod(Γ),
(b) Mod(Γ) ∩Mod(Σ) = Mod(Γ ∪Σ),
(c) Mod(Γ) ∪Mod(Σ) ⊆Mod(Γ ∩Σ).
18. Let Σ = {φ1, φ2, . . . , φn} be a finite set of ℒ-sentences and let ψ = φ1 ∧⋅⋅⋅∧φn. Show
that Mod(Σ) = Mod(ψ).
*19. Let A and B be ℒ-structures.
(a) Show that for every ℒ-sentence ψ, either ψ ∈Th(B) or ¬ψ ∈Th(B).
(b) Show that if A 󳀀󳨐Th(B), then A and B are elementarily equivalent.
20. Let ℒ= { ̇<, ̇=} and let R = ⟨ℝ; <⟩, where ℝis the set of real numbers and < is the
standard “less than” relation on ℝ.
(a) What subsets of ℝare definable over R?
(b) Let R ⊆ℝ2 be such that ⟨a, a⟩∈R and ⟨b, b⟩∉R. Is R definable over R?
(c) Let R ⊆ℝ2 be such that ⟨a, b⟩∈R and ⟨c, d⟩∉R. Show that if a < b and c < d,
then R is not definable over R.
21. Let ℒ= { ̇<, ̇=}, where ̇< is a 2-place predicate symbol. Let 𝒵= ⟨ℤ; <⟩be the struc-
ture, where ℤis the set of integers and < is the standard less than relation.
(a) Prove that for all n ∈ℤ, the set {n} is not definable over 𝒵.
(b) Let θ be a wff with one free variable v1. Suppose that 𝒵󳀀󳨐θ⟦2⟧. Using Theo-
rem 3.2.38, prove that 𝒵󳀀󳨐∀v1θ.
22. Let ℒ= { ̇<, ̇×, ̇=} be a language with a 2-place predicate symbol ̇< and 2-place func-
tion symbol ̇×. Let ℛ= ⟨ℙ; <, ×⟩be the structure, where ℙis the set of positive real

90
౪
3 First-order logic
numbers, < is the standard less than relation, and × is the standard multiplication
function on the positive real numbers.
(a) Define the function h: ℙ→ℙby h(x) = x2. Prove that h is an automorphism of
the structure ℛ.
(b) Let A = {⟨x, y, z⟩∈ℙ3 : x + y = z}. Prove that A is not definable over ℛ.
Exercise Notes: For Exercise 1, use Definition 3.2.6 and abbreviation 4 on page 62. For
Exercise 3 and Exercise 4, use Remark 3.2.8. For Exercise 11, use induction on terms. For
Exercise 21(b), show that 𝒵󳀀󳨐θ⟦n⟧for all n ∈ℤ.
3.3 Deductions
What is proof?
In Section 3.1 we described a formal language ℒand also defined what it means for
a formula of the language to be grammatically correct. In addition, in Section 3.2 we
defined the notion of “truth” in a structure, that is, A 󳀀󳨐φ, where φ is a sentence. Recall
that a sentence φ is logically implied by a set of sentences Γ, denoted by Γ 󳀀󳨐φ, if every
model of Γ is a model of φ. In this section we shall define the notion of “proof” from a
set of axioms (or formulas), that is, we shall define when φ is deducible from the axioms
in Γ, denoted by Γ ⊢φ.
Surely the most important discovery for mathematics by the ancient Greeks was
the notion of proof, turning mathematics into a deductive science. Each theorem φ must
have a proof from a set Γ of more or less explicitly stated assumptions, or axioms. The
proof must demonstrate that the conclusion φ follows from the axioms in Γ by the laws
of logic alone. The natural question is:
Can the notions of “laws of logic” and “proof” be made mathematically precise?
A proof is an argument that you give to someone else which completely convinces him
or her of the correctness of your assertion. Thus, a proof should be finitely long, as you
cannot give an infinite argument to another person. If the set of axioms Γ is infinite, that
is fine, but they cannot all be used in one proof (otherwise, we would have an infinitely
long proof). Another essential feature of a proof is that it must be possible for another
person to check the proof to ascertain that it contains no fallacies.
In Section 2.5, we presented a system of deduction for propositional logic, where
our axioms were the tautologies of propositional logic and our one rule of inference
was modus ponens. Our system of deduction for first-order logic will be similar. We will
select a set Λ of wffs to be called logical axioms and we will use modus ponens as our
one rule of inference. This will enable us to deduce a new wff from other wffs. Then
for a set Γ of wffs, the theorems of Γ will be the wffs which can be deduced from Γ ∪Λ.
A wff φ will be a theorem of Γ (written Γ ⊢φ) if and only if there a finite sequence of

3.3 Deductions
౪
91
wffs which identifies how φ was derived from Γ ∪Λ. Such a derivation, which uses the
logical axioms and the rule of inference, will be called a deduction of φ from Γ. The term
deduction will be used to avoid confusion with our own mathematical proofs.
There are other deduction systems for first-order logic that are equivalent to the
one we shall present. Each such system of deduction may have a different version of Λ
and different rules of inference, but each system will produce the same theorems.
Before we identify the set of logical axioms Λ, we must first discuss tautologies, gen-
eralizations, and substitutions in first-order logic.
3.3.1 Tautologies in first-order logic
In Remark 2.2.13, we defined the concept of a tautology in propositional logic. The def-
inition of a tautology can be extended to wffs in first-order logic, where the wff may
contain quantifiers—an attribute absent from wffs in propositional logic.
Definition 3.3.1 (First-order tautologies). Let ℒbe a first-order language and let A1, A2,
A3, . . . be the sentence symbols of propositional logic. Let φ be a tautology in proposi-
tional logic containing only the connectives ¬ and →. Suppose that the sentence sym-
bols in φ are in the list A1, A2, . . . , An. Let φ∗be the result of replacing A1, A2, . . . , An with
α1, α2, . . . , αn, where each αi is a first-order wff in ℒ. We shall then say that φ∗is a first-
order tautology.
First-order tautologies are simple generalizations of the tautologies of propositional
logic. For example, the propositional wff
(A →B) →(¬B →¬A)
(3.12)
is a tautology where A and B are two sentence symbols. We can use this tautology to
create first-order tautologies. Let φ and ψ be wffs of first-order logic. Then
(φ →ψ) →(¬ψ →¬φ)
is a first-order tautology. All the first-order tautologies are obtained in this manner, that
is, from the tautologies of propositional logic.
For another example, consider the propositional tautology (3.12). Let α and Pt be any
two formulas of first-order logic, where Pt is an atomic formula. Then
(∀vα →Pt) →((¬Pt) →(¬∀vα))
is a first-order tautology. We now present four more examples of first-order tautologies.
In these examples, we reverse the replacement procedure and then determine if we get
a propositional tautology. If so, we have a first-order tautology.

92
౪
3 First-order logic
1.
(∀zPz ∨¬∀zPz)
Replace the wff ∀zPz with the sentence symbol A. Thus, item 1 is a first-order tau-
tology, because (A ∨¬A) is a tautology.
2.
(∃zPz →∀xQx) →(¬∀xQx →¬∃zPz)
Replace ∃zPz with the sentence symbol A and replace ∀xQx with B. Item 2 is a first-
order tautology, because (A →B) →(¬B →¬A) is a tautology.
3.
¬(∀zPz →Qx) →∀zPz
Replace ∀zPz with A and replace Qx with B. Item 3 is a first-order tautology because
¬(A →B) →A is a tautology.
4.
¬(∀zPz →Qx) →¬Qx
Replace ∀zPz with A and replace Qx with B. Item 4 is a first-order tautology because
¬(A →B) →¬B is a tautology,
Propositional logic revisited
We will now apply certain concepts from propositional logic, covered in Chapter 2, to
first-order logic. We will also refer to a first-order wff as being an ℒ-formula. In proposi-
tional logic, the concept of a truth assignment is based on having sentence symbols. Can
the concept of a sentence symbol be extended to first-order logic?
Definition 3.3.2 (Prime formulas). We divide the ℒ-formulas into two groups:
1.
A wff is called prime if it is an atomic formula or has the form ∀vα for a wff α.
2.
A wff is called nonprime if it has the form (¬α) or (α →β) for wffs α and β.
Thus, ¬∀z¬Pz is a nonprime formula, whereas ∀z¬Pz is a prime formula. The prime
formulas of first-order logic can be viewed as analogues of the sentence symbols in
propositional logic.
Definition 3.3.3. Let 𝒮be a set of prime formulas. Then we shall let 𝒮be the set of wffs
that can be built from the prime formulas in 𝒮by using the two formula building func-
tions ℰ¬ and ℰ→.
Every wff of first-order logic can be built up from the prime formulas by the opera-
tions ℰ¬ and ℰ→. Thus, if one considers the prime formulas as “sentence symbols,” then
the wffs of first-order logic can also be seen, from a global point of view, as “formulas of
propositional logic.”
Definition 3.3.4. Let 𝒮be a set of prime formulas in a first-order language ℒ. A function
u: 𝒮→{F, T} is called an ℒ-truth assignment for 𝒮.
Let 𝒮be a set of prime formulas and let u: 𝒮→{F, T} be an ℒ-truth assignment for 𝒮.
Let ℱ= {ℰ¬, ℰ→}. Theorem 2.2.1 implies that the set 𝒮of all wffs generated by 𝒮from
the functions in ℱis freely generated. Thus, there is a unique function u: 𝒮→{F, T}
satisfying the analogous conclusions of Theorem 2.2.4(1)(4).

3.3 Deductions
౪
93
Let ψ be a wff of first-order logic. Recall Definition 3.3.1. One can now show that ψ
is a first-order tautology if and only if for every ℒ-truth assignment u, defined on the
prime formulas in ψ, we have u(ψ) = T.
Remark 3.3.5. Let A be an ℒ-structure with domain A and also let s: 𝒯→A be an as-
signment, where 𝒯is the set of all the variables and constant symbols of ℒ. Now let u be
an ℒ-truth assignment. It is possible that u(∀vα) = F, while A 󳀀󳨐∀vα[s]. Thus, an ℒ-truth
assignment may disagree with the satisfaction relation of Definition 3.2.6.
Definition 3.3.6. Let φ be an ℒ-formula and let u be an ℒ-truth assignment that is de-
fined on the prime formulas in φ. Then u satisfies φ if and only if u(φ) = T.
Let φ and ψ be two ℒ-wffs. Then φ tautologically implies ψ if and only if for every
ℒ-truth assignment u defined on all of the prime formulas that appear in φ and ψ, if u
satisfies φ, then u satisfies ψ. Moreover, φ and ψ are tautologically equivalent if φ tauto-
logically implies ψ and the converse holds as well.
Definition 3.3.7. Let Σ be a set of ℒ-wffs. Then Σ is ℒ-satisfiable if there is an ℒ-truth
assignment u that is defined on the prime formulas in every φ ∈Σ such that u(φ) = T
for every φ ∈Σ.
Definition 3.3.8. A set of ℒ-formulas Σ is finitely ℒ-satisfiable if and only if every finite
subset of Σ is ℒ-satisfiable.
The notion of tautological implication can now be applied to first-order logic.
Definition 3.3.9. Let Σ be a set of ℒ-formulas and let φ be an ℒ-formula. Then Σ tauto-
logically implies φ if and only if for every ℒ-truth assignment u, defined on the prime
formulas occurring in formulas in Σ and in φ, if u satisfies Σ, then u(φ) = T.
Theorem 2.4.2, the compactness theorem of propositional logic, and its corollaries
now extend to first-order logic.
Theorem 3.3.10. Let Σ be a set of ℒ-formulas. If Σ is finitely ℒ-satisfiable, then Σ is
ℒ-satisfiable.
The above extension of the propositional compactness theorem holds even when
the set of prime formulas is uncountable (see Remark 2.4.3). The proof of Corollary 2.4.5
establishes the following result.
Corollary 3.3.11. If a set of ℒ-formulas Σ tautologically implies an ℒ-formula φ, then Σ0
tautologically implies φ for some finite Σ0 ⊆Σ.
3.3.2 Generalization and substitution
Given an ℒ-formula ψ, a generalization of ψ is the result of putting universal quantifiers
prior to ψ.

94
౪
3 First-order logic
Definition 3.3.12 (Generalization). Let ℒbe a first-order language. Let ψ be a wff. A wff
φ is a generalization of ψ if and only if for some n ≥0 and some variables x1, x2, . . . , xn,
φ = ∀x1∀x2 ⋅⋅⋅∀xnψ.
In particular, when n = 0, any wff is a generalization of itself.
Substitution
In mathematics, one often replaces a variable with some expression that represents a
possible value of the variable. We will also need to do this in first-order logic. In particu-
lar, we will need to substitute a free variable appearing in a wff α with a term. We shall
write αx
t to denote the wff obtained by replacing the free occurrences of the variable x
in the wff α with the term t.
Before we give a mathematical definition of the operation αx
t , we give an example of
what the operation αx
t should not do. Let ℒ= { ̇+, ̇0}, where ̇+ is a 2-place function symbol
and ̇0 is a constant symbol. Consider the wff ∀x(x ̇+ ̇0 ̇=x). If we replace the variable x with
the term ̇0, then we obtain the expression ∀̇0( ̇0 ̇+ ̇0 ̇= ̇0), which is not a wff. One cannot
“quantify over a constant.” So, the definition of the operation αx
t must avoid replacing a
quantified variable with the term t (see item 4 of the following definition).
Definition 3.3.13 (The operation αx
t ). Let ℒbe a language where x is a variable and t is a
term. Let α be a wff. The wff αx
t is defined recursively as follows:
1.
αx
t is the result of replacing all occurrences of x in α with t, when α is atomic;
2.
(¬α)x
t = ¬αx
t ;
3.
(α →β)x
t = αx
t →βx
t ;
4.
(∀vα)x
t = {∀vα,
if x = v,
∀vαx
t ,
if x
̸= v.
In the right hand side of the equalities in items 2 and 3 of Definition 3.3.13, we have
dropped the outermost parentheses (see 7 on page 63). Exercise 5 shows that Defini-
tion 3.3.13 is an application of Theorems 1.1.27 and 3.1.16.
We offer some observations and examples that illustrate Definition 3.3.13:
(a) φx
x = φ for all wffs φ;
(b) φx
t = φ when x is not a free variable in φ;
(c) observe that
(Qx →∀yPy)x
y = Qxx
y →(∀yPy)x
y = Qy →∀yPy
by items 3, 1, and 4 of Definition 3.3.13;
(d) note that
(¬∀yLxy)x
z = ¬(∀yLxy)x
z = ¬∀yLxyx
z = ¬∀yLzy

3.3 Deductions
౪
95
by items 2, 4, and 1 of Definition 3.3.13;
(e) observe that
∀x¬∀yLxy →(¬∀yLxy)x
z = ∀x¬∀yLxy →¬∀yLzy
by item (c). This example has the form ∀xα →αx
t , where t is a term.
One might wonder why we have the two-case distinction in item 4 of Definition 3.3.13.
Suppose that instead, item 4 was defined to be (∀vα)x
t = ∀vαx
t even if v = x. Then this
version of Definition 3.3.13 would allow us to conclude that
(∃x(x
̸̇= y))
x
y = ∃x(y
̸̇= y),
which is false in all structures and all assignments. This illustrates why item 4 is defined
as it is in Definition 3.3.13.
The next two examples (i) and (ii) illustrate the concept of being and not being “sub-
stitutable,” respectively. Let ℒ= {L, f , c}, where L is a 2-place predicate symbol, f is a
1-place function symbol, and c is a constant symbol. Consider the wff α = ∀vLvx. Note
that α contains the two distinct variables v and x. Using the terms fy and fv, let us eval-
uate the new formulas αx
fy and αx
fv:
(i)
αx
fy = (∀vLvx)x
fy = ∀vLvfy
So, when the term fy is substituted for the variable x, the quantifier “∀v” does not
“capture” the variable y in fy.
(ii) αx
fv = (∀vLvx)x
fv = ∀vLvfv
Thus, when the term fv is substituted for the variable x, the quantifier “∀v” does
“capture” the variable v in fv.
In (i) we shall say that fy is “substitutable” for x, whereas in (ii) we shall say that fv is not
“substitutable” for x. We want to avoid substitutions, as in (ii), that result in a variable
in a term being “captured” by a quantifier. Why? See Example 3.3.14, below.
Example 3.3.14. The wff ∀xα →αx
t asserts that “if α is true of everything, then α is true
of t.” This appears to be obviously true. Let ℒ= { ̇=} and let A be an ℒ-structure whose
domain contains at least two elements. Now let α be the formula (¬∀y(x ̇= y)). Observe
that αx
y = (¬∀y(x ̇= y))x
y = ¬∀y(y ̇= y). Thus, the conditional ∀xα →αx
y is
∀x¬∀y(x ̇= y) →¬∀y(y ̇= y).
(3.13)
The hypothesis ∀x¬∀y(x ̇=y) in (3.13) is equivalent to ∀x∃y(x
̸̇= y), which is true in A. On
the other hand, the conclusion ¬∀y(y ̇= y) in (3.13) is equivalent to ∃y(y
̸̇= y), so it is false
in A. Thus, sentence (3.13) is also false in A. The problem here is that the substitution
(¬∀y(x ̇= y))x
y resulted in a variable being “captured” by a quantifier.

96
౪
3 First-order logic
We conclude from Example 3.3.14 that when performing a substitution, we must
avoid capturing a variable by a quantifier. Thus, we must identify a specific restriction
that will prevent a variable from being so captured. A term will be said to be substi-
tutable for a variable in a formula if its substitution does not produce a captured vari-
able. The formal definition follows.
Definition 3.3.15 (Substitutable). Let ℒbe a language with variable x and term t. Then
“t is substitutable for x in α” is defined recursively as follows:
1.
t is always substitutable for x in α when α is an atomic formula;1
2.
t is substitutable for x in (¬α) iff t is substitutable for x in α;
3.
t is substitutable for x in (α →β) iff t is substitutable for x in both α and β;
4.
t is substitutable for x in (∀vα) iff either
(a) x does not occur free in (∀vα)2 or
(b) v does not occur in t and t is substitutable for x in α.3
It follows from Definition 3.3.15 that a variable x is substitutable for x in every wff.
Remark. Given a wff α and a term t, the operation αx
t is always defined, but it may be
the case that t is not substitutable for x in α. However, if a term t is a constant symbol or
contains no variables, then t will always be substitutable for x in α.
Problem 3.3.16. Let ℒ= {P, Q, f , g, c}, where P, Q are 2-place predicate symbols, f , g are
1-place function symbols, and c is a constant symbol. Let φ be the wff (Pxy →∀xQgxz)
and consider the term fx. Evaluate the wff φz
fx and decide if fx is substitutable for z in φ.
Solution. We evaluate φz
fx as follows:
φz
fx = (Pxy →∀xQgxz)z
fx
by definition of φ,
= Pxyz
fx →(∀xQgxz)z
fx
by Definition 3.3.13(3),
= Pxy →(∀xQgxz)z
fx
by Definition 3.3.13(1),
= Pxy →∀xQgxfx
by Definition 3.3.13(4).
Thus, φz
fx is the wff Pxy →∀xQgxfx. However, the term fx is not substitutable for z in φ
because fx is not substitutable for z in ∀xQgxz by condition 4(b) of Definition 3.3.15 (x in
the term fx is captured by ∀x).
1 There are no quantifiers in an atomic formula, so no variable in t can be captured.
2 In this case, (∀vα)x
t = ∀vα.
3 This ensures that the quantifier “∀v” does not capture any variable in t and that no variable in t will
get captured in αx
t .

3.3 Deductions
౪
97
3.3.3 The logical axioms
There are some formulas in a first-order language that are logically valid, that is, these
formulas are satisfied by every structure and every assignment. Usually one selects a
minimal set of such formulas to be identified as the logical axioms. From a selected set
of logical axioms, one must be able to deduce all the other logically valid formulas. Our
discussions on first-order tautologies, generalizations, and substitutions will now allow
us to present a set Λ of the logical axioms, which are arranged in six groups.
Logical Axioms 3.3.17. Let ℒbe a language of first-order logic. Let Λ be the set of all
generalizations of wffs having the following forms, where x, y are any variables, α, β are
any wffs, and t is any term:
1.
first-order tautologies;
2.
∀xα →αx
t , where t is substitutable for x in α;
3.
∀x(α →β) →(∀xα →∀xβ);
4.
α →∀xα, where x does not occur free in α.
If the language ℒincludes the equality symbol ̇=, then we add the following forms:
5.
x ̇= x;
6.
x ̇= y →(α →αx
y), where α is an atomic formula.
We shall call the resulting set Λ the set of logical axioms.
We prove in Section 4.1 that every logical axiom in Λ is logically valid (see Defini-
tion 3.2.17), that is, each logical axiom holds in all structures and for all assignments.
Remark (On the logical axioms). In Logical Axiom 1, the first-order tautologies will also
be called tautologies. They are included to handle the propositional connective sym-
bols. Logical Axiom 2 reflects the intended meaning of the quantifier symbol, that is, if
a statement is true of all objects in the domain, then the statement is true of an individ-
ual denoted by t. Logical Axioms 3 and 4 are used to prove the generalization theorem
(Theorem 3.3.29) later in this section. Logical Axioms 1 and 2 are used to deduce the im-
portant properties of equality (see Theorem 3.3.54). Logical Axiom 6 is an application of
Leibniz’s law: If two things are equal, then whatever is true of one is true of the other.
Generalizations of logical axioms are also logical axioms.
In the following problem, one is asked to identify whether or not a given wff is a
logical axiom.
Problem 3.3.18. Let ℒ= {P, Q, R, c}, where P, Q are 1-place predicate symbols, R is a
2-place predicate symbol, and c is a constant symbol. To which logical axiom groups, if
any, do each of the following wffs belong?
1.
(∃zPz →∀xQx) →(¬∀xQx →¬∃zPz).
2.
∀x(∀zPz ∨¬∀zPz).

98
౪
3 First-order logic
3.
∀zQz →Qc.
4.
∀x∀zQz →Qc.
5.
∀x∀yRxy →∀yRcy.
6.
∀x∀yRxy →∀yRyy.
7.
∀x(∃zPz →∀zPz) →(∀x∃zPz →∀x∀zPz).
8.
∃zPz →∀x∃zPz.
Solution.
1.
(∃zPz →∀xQx) →(¬∀xQx →¬∃zPz)
The above wff belongs to axiom group 1. To verify this, let α be the wff ∃zPz and let
β be the wff ∀xQx. The above can then be written as
(α →β) →(¬β →¬α),
which is a tautology.
2.
∀x(∀zPz ∨¬∀zPz)
The above wff belongs to axiom group 1, since it is a generalization of a tautology.
To see this, let α be the wff ∀zPz. The above can then be written as a generalization
of (α ∨¬α), which is a tautology.
3.
∀zQz →Qc
This wff belongs to axiom group 2. To affirm this, let α be the wff Qz. The above can
then be written as ∀zα →αz
c and c is substitutable for z in α.
4.
∀x∀zQz →Qc
The above wff is not a logical axiom. Note that the above wff is not a generalization
of an axiom in group 2.
5.
∀x∀yRxy →∀yRcy
The given wff belongs to axiom group 2. To see this, let α be the wff ∀yRxy. The above
can then be written as ∀xα →αx
c and c is substitutable for x in α.
6.
∀x∀yRxy →∀yRyy
The above wff is not a logical axiom, for the following reason. Let α be the wff ∀yRxy.
Then the above wff has the form ∀xα →αx
y. However, y is not substitutable for x in
α. So, the above wff is not a logical axiom.
7.
∀x(∃zPz →∀zPz) →(∀x∃zPz →∀x∀zPz)
The above wff belongs to axiom group 3. To confirm this, let α be the wff ∃zPz and
let β be the wff ∀zPz. The above wff can then be written as
∀x(α →β) →(∀xα →∀xβ).
8.
∃zPz →∀x∃zPz
This wff belongs to axiom group 4. To see this, let α be the wff ∃zPz. The above can
then be written as α →∀xα and x is not free in α.

3.3 Deductions
౪
99
3.3.4 Formal deductions
A deduction in first-order logic, as in propositional logic, is going to be a finite list of
formulas that satisfies certain conditions.
Definition 3.3.19 (An inference rule). Let ℒbe a language of first-order logic. Let α and
β be wffs in the language ℒ. Modus ponens is the rule of inference: From the formulas α
and α →β we can infer β, that is,
α →β
α
∴β
.
(modus ponens)
Definition 3.3.20. Let Γ be a set of formulas. A deduction of φ from Γ is a sequence
⟨α1, . . . , αn⟩of formulas such that αn = φ and for all 1 ≤k ≤n, either
(a) αk is in Γ ∪Λ, or
(b) αk is obtained by modus ponens from two earlier wffs in the sequence, that is, for
some i and j less than k, the wffs αi and αj = (αi →αk) are in the sequence.
Definition 3.3.21. Let Γ be a set of formulas. A formula φ is a theorem of Γ, denoted by
Γ ⊢φ, if there is a deduction of φ from Γ. When Γ = {ψ} we shall write ψ ⊢φ to denote
that there is a deduction of φ from the wff ψ. When Γ = ⌀we shall write ⊢φ to denote
that there is a deduction of φ from the logical axioms alone.
In Definition 3.3.21, Γ can be viewed as a set of assumptions. The notation Γ ⊢φ
means that one can deduce φ from the assumptions and the logical axioms.
Example 3.3.22. Let ℒcontain two 1-place predicate symbols P, Q and a constant sym-
bol c. Let Γ = {∀x(Px →Qx), ∀zPz}. Show that Γ ⊢Qc.
Solution. A deduction of Qc from Γ (with explanation) is given below:
1.
∀x(Px →Qx)
in Γ,
2.
∀zPz
in Γ,
3.
∀x(Px →Qx) →(Pc →Qc)
by Logical Axiom 2,
4.
∀zPz →Pc
by Logical Axiom 2,
5.
Pc →Qc
from 1 and 3, by modus ponens,
6.
Pc
from 2 and 4, by modus ponens,
7.
Qc
from 5 and 6, by modus ponens.
Therefore, Γ ⊢Qc.
Example 3.3.23. Let P be a 1-place predicate symbol. Show that ⊢Px →∃xPx.

100
౪
3 First-order logic
Solution. A deduction of Px →¬∀x¬xPx (with explanation) is given below:
1.
∀x¬Px →¬Px
by Logical Axiom 2,
2.
(∀x¬Px →¬Px) →(Px →¬∀x¬Px)
by Logical Axiom 1,
3.
Px →¬∀x¬Px
from 1 and 2, by modus ponens.
Since ¬∀x¬Px is abbreviated by ∃xPx, we conclude that ⊢Px →∃xPx.
In the above step 1 we used ¬Px as α and t = x in Logical Axiom 2, that is, ∀xα →αx
x
is the instance of Logical Axiom 2 that we used. Moreover, in step 2 we used the tautology
(A →¬B) →(B →¬A).
Example 3.3.24. Let P be a 1-place predicate symbol. Show that ⊢∀x(Px →∃yPy).
Solution. A deduction of ∀x(Px →¬∀y¬Py) (with explanation) is given below:
1.
∀x(∀y¬Py →¬Px)
Logical Axiom 2 (gen),
2.
∀x( (∀y¬Py →¬Px) →(Px →¬∀y¬Py) )
Logical Axiom 1 (gen),
3.
∀x( (∀y¬Py →¬Px) →(Px →¬∀y¬Py) )
→( ∀x(∀y¬Py →¬Px) →∀x(Px →¬∀y¬Py) )
Logical Axiom 3,
4.
∀x(∀y¬Py →¬Px) →∀x(Px →¬∀y¬Py)
modus ponens: 2 and 3,
5.
∀x(Px →¬∀y¬Py)
modus ponens: 1 and 4.
Thus, ⊢∀x(Px →∃yPy).
In the above solution, “gen” means “generalization.” In step 1 we used ¬Py as α and
t = x in Logical Axiom 2, that is, ∀yα →αy
x is the instance of Logical Axiom 2 we applied.
In step 2 we used the tautology (A →¬B) →(B →¬A). In step 3 we used (∀y¬Py →¬Px)
as α and (Px →¬∀y¬Py) as β in Logical Axiom 3.
Example 3.3.25. Let ℒhave a 1-place predicate symbol Q. Show that ∀yQy ⊢∀xQx.
Solution. A deduction of ∀xQx from ∀yQy (with explanation) is given below:
1.
∀yQy
given,
2.
∀x(∀yQy →Qx)
Logical Axiom 2 (gen),
3.
∀yQy →∀x∀yQy
Logical Axiom 4,
4.
∀x(∀yQy →Qx) →(∀x∀yQy →∀xQx)
Logical Axiom 3,
5.
∀x∀yQy →∀xQx
modus ponens: 2 and 4,
6.
∀x∀yQy
modus ponens: 1 and 3,
7.
∀xQx
modus ponens: 5 and 6.
So ∀yQy ⊢∀xQx.
All of the standard proof techniques that are used in mathematics hold for deduc-
tions as well; for example, “proof by contradiction” can be used to show that a deduction
exists in first-order logic (see Corollary 3.3.37 below).

3.3 Deductions
౪
101
We will now present and prove lemmas and theorems about deductions. In our first
such result we identify some useful observations about deductions. Each item in the
following lemma follows directly from Definition 3.3.20.
Lemma 3.3.26. Let Γ be a set of formulas and let α, β, δ, and γ be formulas.
1.
If α ∈Γ or α ∈Λ, then Γ ⊢α.
2.
If ⊢α, then Γ ⊢α.
3.
If α ⊢β and β ⊢γ, then α ⊢γ.
4.
If Γ ⊢α and α ⊢β, then Γ ⊢β.
5.
If Γ ⊢δ and Γ ⊢(δ →β), then Γ ⊢β.
The proof of our next result can be seen as an application of the compactness theo-
rem of propositional logic.
Theorem 3.3.27. Let Γ be a set of wffs of first-order logic and let φ be a wff of first-order
logic. Then Γ ⊢φ if and only if Γ ∪Λ tautologically implies φ.
Proof. (⇒): Assume that Γ ⊢φ. We shall show that Γ ∪Λ tautologically implies φ. Let
⟨α1, α2, . . . , αn⟩be a deduction of φ from the set Γ of wffs. We shall prove the following
statement: For all k ≤n, Γ∪Λ tautologically implies αk. We shall use strong induction on
the natural number variable k.
Base step: Let k = 1. Since α1 is the first step in the deduction, we must have α1 ∈Γ ∪Λ.
Thus, Γ ∪Λ tautologically implies α1.
Inductive step: Assume the strong induction hypothesis
Γ ∪Λ tautologically implies αi for all i < k.
(SIH)
We show that Γ∪Λ tautologically implies αk. As αk is in the deduction, either (a) αk ∈Γ∪Λ
or (b) αk is obtained by modus ponens from some αi and αj = (αi →αk), where i, j < k.
If (a) holds, then Γ ∪Λ tautologically implies αk just as in the above base step. If (b)
holds, then by the strong induction hypothesis (SIH), we conclude that Γ∪Λ tautologically
implies αi and Γ ∪Λ tautologically implies (αi →αk). Hence, Γ ∪Λ tautologically implies
αk (see page 35).
(⇐): Assume that Γ ∪Λ tautologically implies φ. As Γ ∪Λ tautologically implies φ,
Corollary 3.3.11 implies that there exists a finite subset Γ0 of Γ ∪Λ such that Γ0 tautolog-
ically implies φ. Since Γ0 is finite, let Γ0 = {γ1, γ2, . . . , γn}. It follows (see Exercise 6 on
page 51) that
γ1 →γ2 →⋅⋅⋅→γn →φ
is a tautology. By repeated use of modus ponens, it easily follows that Γ0 ⊢ψ. As Γ0 ⊆Γ,
we conclude that Γ ⊢φ.

102
౪
3 First-order logic
Note that the above Theorem 3.3.27 was established by giving a mathematical proof
in English. That is, we proved a theorem about deductions. Hence, one is now in a po-
sition to prove theorems about “mathematical proof.” It is generally accepted that all
proofs in classical mathematics can be expressed as a deduction in first-order logic.
Thus, one can now ask and answer questions about the limits of mathematical proof.
3.3.5 Metatheorems about deductions
If Γ ⊢α, then we say that α is a theorem of Γ. However, we have also been using the word
“theorem” in a different way when proving theorems in English about deductions. These
English theorems are sometimes referred to as being metatheorems to emphasize that
they are statements in English about deductions and first-order logic.
We now pose a question about deductions.
How can we show that a deduction exists without actually giving one?
Answer: One must first prove metatheorems about deductions.
Induction on deductions
Let S be a set of wffs. Then S is said to be closed under modus ponens if whenever α ∈S
and (α →β) ∈S, we have β ∈S. Since there is a procedure for building all the theorems
of Γ using the formulas in Γ ∪Λ and applying modus ponens, we have the following
induction principle.
Theorem 3.3.28 (Induction principle). Let S be a set of wffs such that:
(1) Γ ∪Λ ⊆S,
(2) S is closed under modus ponens.
Then {φ : Γ ⊢φ} ⊆S, that is, S contains all the theorems of Γ.
Proof. Let S and Γ be as stated. Assume that Γ ⊢φ. Now let ⟨α1, α2, . . . , αn⟩be a deduction
of φ from the set Γ of wffs. Thus, αn = φ. We shall prove that for all k ≤n, αk ∈S. We
shall use strong induction on the natural number variable k.
Base step: Let k = 1. Since α1 is the first step in the deduction, we must have α1 ∈Γ ∪Λ.
Thus, α1 ∈S by (1).
Inductive step: Assume the strong induction hypothesis
αi ∈S for all i < k.
(SIH)
We show that αk ∈S. As αk is in the deduction, either (a) αk ∈Γ∪Λ or (b) αk is obtained by
modus ponens from some αi and αj = (αi →αk), where i, j < k. If (a) holds, then αk ∈S.

3.3 Deductions
౪
103
If (b) holds, then by the induction hypothesis we see that αi ∈S and (αi →αk) ∈S. By
(2), S is closed under modus ponens. Hence, αk ∈S. Therefore, for all k ≤n, αk ∈S. In
particular, φ ∈S.
Theorem 3.3.28 validates the following strategy, which will allow us to prove results
about formulas φ that are deducible from a set of wffs Γ.
Proof Strategy. Let 𝕊(φ) be a statement about a wff φ. In order to prove an assertion
“for all wffs φ, if Γ ⊢φ, then 𝕊(φ)” by induction, use the following diagram:
Base step:
Prove 𝕊(ϕ) for all formulas ϕ ∈Γ ∪Λ.
Inductive step:
Let α and β be wffs.
Assume 𝕊(α) and 𝕊(α →β).
Prove 𝕊(β).
The above proof strategy is Theorem 3.3.28 applied to the set S = {φ is a wff : 𝕊(φ)}.
We will apply this strategy in the proof of our next theorem, where 𝕊(φ) is “Γ ⊢∀xφ.” In
this proof we will tacitly be using Lemma 3.3.26.
Theorem 3.3.29 (Generalization theorem). Suppose that x does not occur free in any for-
mula in Γ. For all wffs φ, if Γ ⊢φ, then Γ ⊢∀xφ.
Proof. Assume that the variable x does not occur free in any formula in Γ. Using the
induction principle, we shall prove the following: For all wffs φ, if Γ ⊢φ, then Γ ⊢∀xφ.
Base step: Let ϕ be in Γ ∪Λ. If ϕ ∈Γ, then x does not occur free in ϕ. Thus, (ϕ →∀xϕ)
is in axiom group 4 of the logical axioms (page 97). Since Γ ⊢ϕ and Γ ⊢(ϕ →∀xϕ), we
conclude (by modus ponens) that Γ ⊢∀xϕ. If ϕ ∈Λ, then ϕ is a logical axiom. Thus, the
generalization ∀xϕ is also a logical axiom. Therefore, Γ ⊢∀xϕ.
Inductive step: Let α and β be wffs. Assume the induction hypothesis
Γ ⊢∀xα
and
Γ ⊢∀x(α →β).
(IH)
We need to prove that Γ ⊢∀xβ. Note that (󳵳) ∀x(α →β) →(∀xα →∀xβ) is in axiom
group 3 of the logical axioms. By (IH) we have Γ ⊢∀x(α →β) and Γ ⊢∀xα. Thus, by
applying modus ponens twice to (󳵳), we have Γ ⊢∀xβ.
A converse of the generalization theorem (Theorem 3.3.29) holds, whether or not x
occurs free in a formula in Γ.
Theorem 3.3.30. For all wffs φ, if Γ ⊢∀xφ, then Γ ⊢φ.
Proof. Assume that Γ ⊢∀xφ. By Logical Axiom 2, we have Γ ⊢(∀xφ →φ). Thus, by
modus ponens, we conclude that Γ ⊢φ.
Given that certain deductions exist, the following “tautology rule” allows one to
show that another deduction exists.

104
౪
3 First-order logic
Theorem 3.3.31 (Rule T). If Γ ⊢α1, . . . , Γ ⊢αn and {α1, . . . , αn} tautologically implies β,
then Γ ⊢β.
Proof. Assume that Γ ⊢α1, . . . , Γ ⊢αn and that {α1, . . . , αn} tautologically implies β. Thus,
α1 →α2 →⋅⋅⋅→αn →β is a tautology (see Exercise 6 on page 51), so it is in axiom
group 1 of the logical axioms. Since Γ ⊢α1, . . . , Γ ⊢αn, we conclude that Γ ⊢β by applying
modus ponens n times.
Note that ¬(ψ →θ) tautologically implies ψ and ¬θ and that {ψ, ¬θ} tautologically
implies ¬(ψ →θ). We therefore have the following corollary.
Corollary 3.3.32. We have Γ ⊢¬(ψ →θ) if and only if Γ ⊢ψ and Γ ⊢¬θ.
In order to simplify our notation, we shall write Γ; ψ as an abbreviation for Γ ∪{ψ}.
Theorem 3.3.33 (Deduction theorem). Let Γ be a set of wffs and γ, φ be wffs. Then Γ; γ ⊢φ
if and only if Γ ⊢(γ →φ).
Proof. Let Γ be a set of wffs and let γ, φ be wffs. Then
Γ; γ ⊢φ
iff
Γ; γ ∪Λ tautologically implies φ
by Theorem 3.3.27,
iff
Γ ∪Λ tautologically implies (γ →φ)
by Exercise 9 on page 38,
iff
Γ ⊢(γ →φ)
by Theorem 3.3.27.
Thus, to deduce a conditional, one can assume the hypothesis and then deduce the
conclusion, just like in mathematics.
Corollary 3.3.34. Let Γ be a set of wffs. If α and β are tautologically equivalent, then:
(1) Γ ⊢α iff Γ ⊢β,
(2) Γ; α ⊢φ iff Γ; β ⊢φ, for any wff φ.
Proof. Let Γ be a set of wffs and let α and β be wffs that are tautologically equivalent.
Thus, α →β and β →α are tautologies. To prove (1), assume that Γ ⊢α. Since α →β is
a tautology, we see that Γ ⊢β. The converse holds in a similar fashion.
To prove (2), let φ be a wff. Since α and β are tautologically equivalent, it follows
that (󳵳) α →φ and β →φ are tautologically equivalent. Thus,
Γ; α ⊢φ
iff
Γ ⊢(α →φ)
by Theorem 3.3.33,
iff
Γ ⊢(β →φ)
by (1) and (󳵳),
iff
Γ; β ⊢φ
by Theorem 3.3.33.
Corollary 3.3.35 (Contraposition). We have Γ; φ ⊢¬ψ iff Γ; ψ ⊢¬φ.
Proof. Let Γ be a set of wffs and let φ, ψ be wffs. Since
(φ →¬ψ) and (ψ →¬φ) are tautologically equivalent,
(󳵳)

3.3 Deductions
౪
105
we have
Γ; φ ⊢¬ψ
iff
Γ ⊢(φ →¬ψ)
by Theorem 3.3.33,
iff
Γ ⊢(ψ →¬φ)
by Corollary 3.3.34(1) and (󳵳),
iff
Γ; ψ ⊢¬φ
by Theorem 3.3.33.
Definition 3.3.36. A set Γ of wffs is consistent if there is no formula β such that Γ ⊢β
and Γ ⊢¬β; Γ is inconsistent if Γ ⊢β and Γ ⊢¬β for some formula β.
If a set of wffs Γ is inconsistent, then for any wff α, we have Γ ⊢α. The reason for
this follows. Let β such that Γ ⊢β and Γ ⊢¬β. Since β →(¬β →α) is a tautology, it
follows that Γ ⊢α via modus ponens.
Proof by contradiction is often used in mathematical proofs. It can also be used in
first-order logic to show that a deduction exists.
Corollary 3.3.37 (Reductio ad absurdum). If Γ; φ is inconsistent, then Γ ⊢¬φ.
Proof. Assume that Γ; φ is inconsistent. So, there is a formula β such that Γ; φ ⊢β and
Γ; φ ⊢¬β. Thus, Γ ⊢(φ →β) and Γ ⊢(φ →¬β) by the deduction theorem. Since
{φ →β, φ →¬β} tautologically implies ¬φ, we conclude that Γ ⊢¬φ by Rule T.
Theorem 3.3.38. If a set of formulas Γ is inconsistent, then a finite subset of Γ is inconsis-
tent.
Proof. See Exercise 12.
Strategies to show that deductions exist
To show that a deduction exists without having to explicitly present a deduction, one
may be able to use the following eight deduction strategies:
(S1) To show that Γ ⊢(ψ →θ), it is sufficient to show that Γ; ψ ⊢θ, by the deduction
theorem.
(S2) To show that Γ; ¬ψ ⊢¬θ, it is sufficient to show that Γ; θ ⊢ψ, by contraposition.
Also, Γ; α ⊢¬∀xψ iff Γ; ∀xψ ⊢¬α.
(S3) To show that Γ ⊢∀xψ, it is sufficient to show that Γ ⊢ψ when x does not occur free
in Γ, by the generalization theorem (Theorem 3.3.29).
(S4) To show that Γ ⊢¬(ψ →θ), it is sufficient to show that Γ ⊢ψ and Γ ⊢¬θ, by Rule T
and the fact that {ψ, ¬θ} tautologically implies ¬(ψ →θ).
(S5) To show that Γ ⊢¬¬ψ, it is sufficient to show that Γ ⊢ψ, by Rule T and the fact that
{ψ} tautologically implies ¬¬ψ.
(S6) To show that Γ ⊢¬ψ, it is sufficient to show that Γ; ψ is inconsistent, by reductio ad
absurdum.
(S7) To show that Γ ⊢¬∀xψ, it is sufficient to show that Γ ⊢¬ψx
t for some term t. Note
that Γ ⊢(¬ψx
t →¬∀xψ) by Logical Axiom 2 and Corollary 3.3.34(1). Thus, Γ ⊢¬∀xψ
would follow by modus ponens. (If this is not useful, try (S6).)

106
౪
3 First-order logic
(S8) To show that Γ; ∀yα ⊢¬∀xψ, try to show that Γ; ∀xψ ⊢¬α. Thus, Γ; α ⊢¬∀xψ, and
since ∀yα →α is a logical axiom, we have Γ; ∀yα ⊢¬∀xψ. Now apply contraposition,
Corollary 3.3.35, to conclude that Γ; ∀yα ⊢¬∀xψ.
Problem 3.3.39. Using the above strategies, show that:
(1) ⊢∀xPx →∃xPx,
(2) ∀x∀yPxy ⊢∀y∀zPzy,
(3) ∀xPx ⊢∀xQx →∀x¬(Px →¬Qx).
Solution. For each of the above items, we will show that such a deduction exists.
(1) To show that ⊢∀xPx →∃xPx, we will apply (S1). By the deduction theorem, we
just need to show that ∀xPx ⊢∃xPx. Theorem 3.3.30 implies that ∀xPx ⊢Px. By
Example 3.3.23 on page 99 and the deduction theorem, we have Px ⊢∃xPx. Since
∀xPx ⊢Px and Px ⊢∃xPx, Lemma 3.3.26(4) implies that ∀xPx ⊢∃xPx. Therefore,
⊢∀xPx →∃xPx.
(2) We shall show that ∀x∀yPxy ⊢∀y∀zPzy. Two applications of Logical Axiom 2 and
modus ponens shows that ∀x∀yPxy ⊢Pzy. Since z is not free in ∀x∀yPxy, we see
that ∀x∀yPxy ⊢∀zPzy, by applying (S3). Similarly, as y is not free in ∀x∀yPxy, we
conclude that ∀x∀yPxy ⊢∀y∀zPzy.
(3) We will show that ∀xPx ⊢∀xQx →∀x¬(Px →¬Qx). By the deduction theorem, it
is sufficient to show that {∀xPx, ∀xQx} ⊢∀x¬(Px →¬Qx). So by strategy (S3), we
just need to show that {∀xPx, ∀xQx} ⊢¬(Px →¬Qx). By Logical Axiom 2 and modus
ponens, we see that
{∀xPx, ∀xQx} ⊢Px and {∀xPx, ∀xQx} ⊢Qx.
Thus, {∀xPx, ∀xQx} ⊢Px, and {∀xPx, ∀xQx} ⊢¬¬Qx by Corollary 3.3.34(1). Applying
strategy (S4), we conclude that {∀xPx, ∀xQx} ⊢¬(Px →¬Qx). Therefore, ∀xPx ⊢
∀xQx →∀x¬(Px →¬Qx).
Problem 3.3.40. Show that ⊢∃x∀yφ →∀y∃xφ.
Solution. We will show that a deduction of ∃x∀yφ →∀y∃xφ exists. By the deduction the-
orem it is sufficient to show that ∃x∀yφ ⊢∀y∃xφ. Hence, by the generalization theorem
(Theorem 3.3.29), it is sufficient to show that ∃x∀yφ ⊢∃xφ. Removing the abbreviations,
we need to show that ¬∀x¬∀yφ ⊢¬∀x¬φ. By contraposition, this reduces to showing
that ∀x¬φ ⊢∀x¬∀yφ (see Corollary 3.3.35). So, by the generalization theorem (Theo-
rem 3.3.29), we must show that ∀x¬φ ⊢¬∀yφ and thus, by reductio ad absurdum, it is
now sufficient to show that Σ = {∀x¬φ, ∀yφ} is inconsistent. Note that Σ ⊢¬φ and Σ ⊢φ
by Logical Axiom 2 and modus ponens. Hence, Σ is inconsistent. Therefore, it follows
that there is a deduction of ∃x∀yφ →∀y∃xφ.
Proposition 3.3.41. Let α be a wff. Then ⊢¬∀xα ↔∃x¬α and ⊢¬∃xα ↔∀x¬α.

3.3 Deductions
౪
107
Proposition 3.3.42. If x does not occur free in α, then
⊢(α →∀xβ) ↔∀x(α →β).
Proof. By Rule T, it is sufficient to show that
⊢(α →∀xβ) →∀x(α →β),
(⋆)
⊢∀x(α →β) →(α →∀xβ).
(⋆⋆)
To prove (⋆), by the deduction theorem, we must show that
(α →∀xβ) ⊢∀x(α →β).
By assumption, x does not occur free in α. Hence, x does not occur free in (α →∀xβ).
Therefore, by Theorem 3.3.29, it is now enough to show that (α →∀xβ) ⊢(α →β).
Again, by the deduction theorem, it is enough to show that {(α →∀xβ), α} ⊢β. Let
Γ = {(α →∀xβ), α}. We argue that Γ ⊢β as follows:
(1)
Γ ⊢α →∀xβ
in Γ,
(2)
Γ ⊢α
in Γ,
(3)
Γ ⊢∀xβ
by (1), (2), and modus ponens,
(4)
Γ ⊢∀xβ →β
by Logical Axiom 2,
(5)
Γ ⊢β
by (3), (4), and modus ponens.
This completes the proof of (⋆). Note that the above list (1)–(5) is not a deduction. It is
just part of a proof showing that a deduction of (⋆) exists.
To establish (⋆⋆), we need to show, by the deduction theorem, that
∀x(α →β) ⊢(α →∀xβ).
So, again by the deduction theorem, we must show that {∀x(α →β), α} ⊢∀xβ. Since x
does not occur free in ∀x(α →β) or in α, the generalization theorem (Theorem 3.3.29)
implies that we just need to show {∀x(α →β), α} ⊢β. Let Γ = {∀x(α →β), α}. We show
that Γ ⊢β as follows:
(1)
Γ ⊢∀x(α →β)
in Γ,
(2)
Γ ⊢α
in Γ,
(3)
Γ ⊢∀x(α →β) →(α →β)
by Logical Axiom 2,
(4)
Γ ⊢α →β
by (1), (3), and modus ponens,
(5)
Γ ⊢β
by (2), (4), and modus ponens.
Proposition 3.3.43. If x is not free in α, then ⊢(α →∃xβ) ↔∃x(α →β).

108
౪
3 First-order logic
Proposition 3.3.44. If x is not free in β, then ⊢(∀xα →β) ↔∃x(α →β).
Proposition 3.3.45. If x is not free in β, then ⊢(∃xα →β) ↔∀x(α →β).
Proof. By Rule T, it is sufficient to show that
⊢(∃xα →β) →∀x(α →β),
(⋆)
⊢∀x(α →β) →(∃xα →β).
(⋆⋆)
We shall first prove (⋆). It is sufficient to show that
(∃xα →β) ⊢∀x(α →β),
(3.14)
by the deduction theorem. By assumption, x does not occur free in β. Thus, x does not
occur free in (∃xα →β). To establish (3.14), the generalization theorem (Theorem 3.3.29)
implies that it is enough to verify that (∃xα →β) ⊢(α →β). Again, by the deduction
theorem, we now just need to show that {(∃xα →β), α} ⊢β. Let Γ = {(∃xα →β), α}.
Thus, as ∃xα is an abbreviation for ¬∀x¬α, we have
(1)
Γ ⊢¬∀x¬α →β
in Γ,
(2)
Γ ⊢α
in Γ,
(3)
Γ ⊢∀x¬α →¬α
by Logical Axiom 2,
(4)
Γ ⊢α →¬∀x¬α
by (3) and Corollary 3.3.34(1),
(5)
Γ ⊢¬∀x¬α
by (2), (4), and modus ponens,
(6)
Γ ⊢β
by (1), (5), and modus ponens.
In (4) we used the fact that (∀x¬α →¬α) and (α →¬∀x¬α) are tautologically equivalent.
We shall now prove (⋆⋆). By the deduction theorem we need to show that
∀x(α →β) ⊢(∃xα →β).
So, by the deduction theorem and contraposition, it is sufficient to show that
{∀x(α →β), ¬β} ⊢¬∃xα.
By Corollary 3.3.34(1), we only need to show that
{∀x(α →β), ¬β} ⊢∀x¬α.
Since x does not occur free in β, we see that x does not occur free in any formula in the
set {∀x(α →β), ¬β}. So, by the generalization theorem (Theorem 3.3.29), it is enough to
show that
{∀x(α →β), ¬β} ⊢¬α.

3.3 Deductions
౪
109
Furthermore, by contraposition, we just need to show that
{∀x(α →β), α} ⊢β.
Let Γ = {∀x(α →β), α}. We show that Γ ⊢β as follows:
(1)
Γ ⊢∀x(α →β)
in Γ,
(2)
Γ ⊢α
in Γ,
(3)
Γ ⊢∀x(α →β) →(α →β)
by Logical Axiom 2,
(4)
Γ ⊢α →β
by (1), (3), and modus ponens,
(5)
Γ ⊢β
by (2), (4), and modus ponens.
The following theorem can be useful to show that certain deductions exist.
Theorem 3.3.46. Let α and β be wffs. If ⊢α →β, then ⊢∀xα →∀xβ.
3.3.6 Equality
As you may recall, the logical axioms have two groups of axioms that concern equality.
However, as yet, we have not discussed deductions that involve the equality symbol ̇=.
In this section, we will examine deductions in languages ℒthat contain the equality
symbol. Using the logical axioms, we will show that all of the common properties of
equality can be deduced from the axioms. One should go to page 97 and review the
logical axioms and the equality axioms before continuing.
Proposition 3.3.47. We have ⊢∀x(x ̇= x).
Proof. Since x ̇= x is a logical axiom, ∀x(x ̇= x) is also a logical axiom by generalization
(a generalization of a logical axiom is a logical axiom).
Proposition 3.3.48. Let Γ be any set of wffs and let t be a term. Then Γ ⊢t ̇= t.
Proof. The following holds for any set Γ, even the empty set:
(1)
Γ ⊢∀x(x ̇= x)
by Proposition 3.3.47,
(2)
Γ ⊢∀x(x ̇= x) →t ̇= t
by Logical Axiom 2,
(3)
Γ ⊢t ̇= t
by (1), (2), and modus ponens.
In (2) we are using x ̇= x as α in Logical Axiom 2 and (x ̇= x)x
t is t ̇= t.
Before we prove our next result, we introduce some temporary notation. Let α be an
atomic formula. The formula α may have multiple occurrences of a particular variable,
say x. To identify all of the occurrences of x that appear in α, we shall use the nota-
tion α(x, . . . , x). In our next proposition, we will discuss the result of replacing some of

110
౪
3 First-order logic
these occurrences of x with another variable. To distinguish the occurrences of the vari-
able x that are to be kept from those that are to be replaced, we shall use the notation
α(x, . . . , x|x, . . . , x), where the occurrences of x on the left of | are to be kept and the oc-
currences on the right are to be replaced. Again, this somewhat ambiguous notation is
only temporary. Recall that Γ; (x ̇= y) is the set Γ ∪{x ̇= y}.
Proposition 3.3.49. Suppose that Γ; (x ̇=y) ⊢α, where α is an atomic formula and x, y are
variables. Let α′ be the result of replacing some or all of the occurrences of x in α with y.
Then Γ; (x ̇= y) ⊢α′.
Proof. We are given that Γ; (x
̇= y) ⊢α. As discussed above, we shall use the notation
α(x, . . . , x|x, . . . , x) to indicate that the occurrences of x on the right of | are to be replaced
by y. Thus, α′ = α(x, . . . , x|y, . . . , y). Now let z be a variable that is distinct from x, y, and
all of the variables that appear in α. Consider the new atomic formula α(z, . . . , z|x, . . . , x).
We observe that the formula
x ̇= y →α(z, . . . , z|x, . . . , x) →α(z, . . . , z|x, . . . , x)x
y
(3.15)
is in logical axiom group 6. Since α(z, . . . , z|x, . . . , x)x
y
= α(z, . . . , z|y, . . . , y), we see
that (3.15) is the same as
x ̇= y →α(z, . . . , z|x, . . . , x) →α(z, . . . , z|y, . . . , y).
(3.16)
Let β denote the formula in (3.16). Therefore, by generalization, ∀zβ is in logical axiom
group 6 and ∀zβ →βz
x is in logical axiom group 2. By modus ponens, we infer that
Γ; (x ̇= y) ⊢βz
x.
Since α(z, . . . , z|x, . . . , x)z
x = α and α(z, . . . , z|y, . . . , y)z
x = α′, we see that βz
x is the formula
x ̇= y →α →α′. Hence,
Γ; (x ̇= y) ⊢x ̇= y →α →α′.
As Γ; (x ̇= y) ⊢α, by applying modus ponens twice, we see that Γ; (x ̇= y) ⊢α′.
Proposition 3.3.50. We have ⊢∀x∀y(x ̇= y →y ̇= x).
Proof. By Theorem 3.3.29, it is sufficient to show that ⊢(x
̇= y →y
̇= x), and by the
deduction theorem, we just need to show that {x ̇= y} ⊢y ̇= x. We do this as follows:
(1)
{x ̇= y} ⊢x ̇= x
as x ̇= x is a logical axiom,
(2)
{x ̇= y} ⊢y ̇= x
by Proposition 3.3.49.
In (2) we are using x ̇= x as α in Proposition 3.3.49.
The proof of the following result is requested in Exercise 19.

3.3 Deductions
౪
111
Proposition 3.3.51. We have ⊢∀x∀y∀z(x ̇= y →y ̇= z →x ̇= z).
Proposition 3.3.52. We have ⊢∀x1∀x2∀y1∀y2(x1 ̇= y1 →x2 ̇= y2 →Px1x2 →Py1y2).
Proof. By the generalization theorem (Theorem 3.3.29), it is sufficient to show that
⊢x1 ̇= y1 →x2 ̇= y2 →Px1x2 →Py1y2.
By the deduction theorem we need to prove that
{x1 ̇= y1, x2 ̇= y2, Px1x2} ⊢Py1y2.
Let Γ = {x1 ̇= y1, x2 ̇= y2, Px1x2}. We now show that Γ ⊢Py1y2 as follows:
(1)
Γ ⊢Px1x2
in Γ,
(2)
Γ ⊢Py1x2
by Proposition 3.3.49,
(3)
Γ ⊢Py1y2
by Proposition 3.3.49.
Proposition 3.3.53. We have ⊢∀x1∀x2∀y1∀y2(x1 ̇= y1 →x2 ̇= y2 →fx1x2 ̇= fy1y2).
Proof. By the generalization theorem (Theorem 3.3.29), it is sufficient to show that
⊢x1 ̇= y1 →x2 ̇= y2 →fx1x2 ̇= fy1y2.
By the deduction theorem we need to prove that
{x1 ̇= y1, x2 ̇= y2} ⊢fx1x2 ̇= fy1y2.
Let Γ = {x1 ̇= y1, x2 ̇= y2}. We now prove that Γ ⊢fx1x2 ̇= fy1y2 as follows:
(1)
Γ ⊢fx1x2 ̇= fx1x2
by Proposition 3.3.48,
(2)
Γ ⊢fx1x2 ̇= fy1x2
by Proposition 3.3.49,
(3)
Γ ⊢fx1x2 ̇= fy1y2
by Proposition 3.3.49.
The following theorem follows directly from Propositions 3.3.47–3.3.53.
Theorem 3.3.54. We have:
1.
⊢∀x(x ̇= x),
2.
⊢∀x∀y(x ̇= y →y ̇= x),
3.
⊢∀x∀y∀z(x ̇= y →y ̇= z →x ̇= z),
4.
⊢∀x1∀x2∀y1∀y2(x1 ̇= y1 →x2 ̇= y2 →Px1x2 →Py1y2), where P is a 2-place predicate
symbol, and similarly for n-place predicate symbols,
5.
⊢∀x1∀x2∀y1∀y2(x1
̇= y1 →x2
̇= y2 →fx1x2
̇= fy1y2), where f is a 2-place function
symbol, and similarly for n-place function symbols.

112
౪
3 First-order logic
Items 1–3 of Theorem 3.3.54 show that equality is reflexive, symmetric, and transi-
tive, respectively. Items 4 and 5 show that the substitution property of equality holds,
that is, if two quantities are equal, then one can replace one with the other. Thus, the
important properties of equality can be deduced from the logical axioms alone.
3.3.7 More metatheorems about deductions
The next problem illustrates an ability to “generalize on a constant.”
Problem 3.3.55. Let ℒcontain a constant symbol c and 1-place predicate symbols P
and Q. Let Γ = {∀x(Px →Qx), ∀zPz}. One can show that Γ ⊢Qc. Since c does not ap-
pear in any formula in Γ, can one then show that Γ ⊢∀xQx?
Solution. We show, in steps, that such a deduction exists.
(a) Γ ⊢Qc
A deduction confirming (a) is given in Example 3.3.22 on page 99.
(b) Γ ⊢Qy
To confirm (b), in the deduction given in Example 3.3.22, replace c with y.
(c) Γ ⊢∀yQy
This follows from (b) by Theorem 3.3.29, as y does not occur in Γ.
(d) ∀yQy ⊢∀xQx
This is proven in Example 3.3.25 on page 100.
(e) Γ ⊢∀xQx
This follows from (c) and (d).
Our next theorem shows that the steps in the solution of the above problem can
be generalized. Let α be a wff and let y be a variable that does not occur in α. Define
αc
y to be the wff obtained by replacing all occurrences of the constant symbol c in α
with y.
Theorem 3.3.56 (Generalization on constants). Suppose that Γ ⊢φ and let c be a constant
symbol that occurs in no formula in Γ. Then there is a variable y which does not appear in
φ such that Γ ⊢∀yφc
y. Moreover, there is a deduction of ∀yφc
y from Γ in which c does not
occur.
Proof. Assume Γ ⊢φ and assume that c is a constant symbol that occurs in no formula
in Γ. Let ⟨α1, . . . , αn⟩be a deduction of φ from Γ, where αn = φ. So for all k ≤n, either
(a) αk is in Γ ∪Λ, or
(b) αk is obtained by modus ponens from two earlier wffs in the sequence ⟨α1, . . . , αk⟩.
Now, let y be a variable that does not occur in αk for all 1 ≤k ≤n. We will show that
⟨α1
c
y, . . . , αn
c
y⟩is a deduction of φc
y from Γ. Let k be so that 1 ≤k ≤n.

3.3 Deductions
౪
113
Case (a): Suppose that αk is in Γ ∪Λ. If αk ∈Γ, then c does not occur in αk. Thus,
αk
c
y = αk, and therefore αk
c
y ∈Γ. If αk ∈Λ, then αk
c
y is also a logical axiom (for each α
that appears in a logical axiom, by replacing α with αc
y we get another logical axiom).
Therefore, αk
c
y ∈Λ.
Case (b): If αk is obtained by modus ponens from two earlier wffs in the sequence
⟨α1, . . . , αk⟩, then for some i and j less than k, the wffs αi and αj = (αi →αk) are in the
sequence ⟨α1, . . . , αk⟩. Since
αj
c
y = (αi →αk)c
y = (αi
c
y →αk
c
y),
we see that αk
c
y is obtained by modus ponens from two earlier wffs in the sequence
⟨α1
c
y, . . . , αk
c
y⟩.
So ⟨α1
c
y, . . . , αn
c
y⟩is a deduction of φc
y from Γ. Let
Φ = {αi : αi ∈Γ and 0 ≤i ≤n}.
Since αi
c
y = αi for all αi ∈Φ, we see that Φ ⊢φc
y. As y does not occur in any formula
in Φ, the generalization theorem (Theorem 3.3.29) implies that Φ ⊢∀yφc
y. Since Φ ⊆Γ,
we conclude that Γ ⊢∀yφc
y.
Therefore, ⟨α1
c
y, . . . , αn
c
y⟩is a deduction of φc
y from Γ that does not involve the con-
stant c. As the proof of Theorem 3.3.29 adds no new symbols to a deduction, we conclude
there is a deduction of ∀yφc
y from Γ in which c does not occur.
Lemma 3.3.57 (Re-replacement). Let x be a variable and let φ be a wff in which the vari-
able y does not appear. Then x is substitutable for y in the wff φx
y and φxy
yx = φ.
Proof. See Exercise 21.
Corollary 3.3.58. Assume Γ ⊢φx
c, where c is a constant symbol that does not occur in φ
and c does not occur in any formula in Γ. Then Γ ⊢∀xφ. In addition, there is a deduction
of ∀xφ from Γ in which c does not occur.
Proof. Assume Γ ⊢φx
c, where c is a constant symbol that occurs neither in φ nor in any
formula in Γ. Theorem 3.3.56 implies that there is a variable y which does not occur in
φx
c such that Γ ⊢∀yφxc
cy. In addition, there is a deduction of ∀yφxc
cy from Γ in which c
does not occur. Since c does not occur in φ, we see that φxc
cy = φx
y. Hence, (󳵳) Γ ⊢∀yφx
y.
Lemma 3.3.57 asserts that x is substitutable for y in φx
y. Thus,
∀yφx
y →φxy
yx
is in axiom group 2. Since Lemma 3.3.57 also asserts that φxy
yx = φ, we conclude that
∀yφx
y →φ

114
౪
3 First-order logic
is a logical axiom. Thus, ⊢∀yφx
y →φ. So, by the deduction theorem, we have ∀yφx
y ⊢φ.
Since x does not occur free in ∀yφx
y, the generalization theorem (Theorem 3.3.29) implies
that ∀yφx
y ⊢∀xφ. Because Γ ⊢∀yφx
y by (󳵳), we conclude that Γ ⊢∀xφ.
In mathematics, suppose that one can prove a result by using an arbitrary constant.
Afterwards, one can then ask: Is there a proof that does not use the constant? The next
corollary positively addresses this question.
Corollary 3.3.59. Let c be a constant symbol that does not occur in φ, in ψ, or in any
formula in Γ. If Γ; φx
c ⊢ψ, then Γ; ∃xφ ⊢ψ. Moreover, there is a deduction of ψ from Γ; ∃xφ
in which c does not occur.
Proof. Let c be a constant symbol that does not occur in φ, in ψ, or in any formula in Γ.
Suppose that Γ; φx
c ⊢ψ. By contraposition (Corollary 3.3.35), we see that Γ; ¬ψ ⊢¬φx
c.
Corollary 3.3.58 implies that Γ; ¬ψ ⊢∀x¬φ and this can be confirmed by a deduction in
which c does not appear. Thus, by contraposition, Γ; ¬∀x¬φ ⊢ψ. Hence, Γ; ∃xφ ⊢ψ and
this can be verified by a deduction in which c does not occur.
Alphabetic variants
We begin with some terminology. Let v be a variable and consider a wff of the form ∀xφ.
If v occurs in φ, then v is said to be within the scope of the quantifier ∀. An alphabetic
variant of wff α is a wff α that is the result of a one-to-one replacement of some, none, or
all of the quantified variables of α with variables that are not in the scope of a quantifier
in α. A precise definition of an alphabetic variant can be given by recursion (see the proof
of Theorem 3.3.61 below). Here are some examples:
1.
The wff ∀w∀xPwx is an alphabetic variant of ∀y∀zPyz, because the change of quan-
tified variables y 󳨃→w, z 󳨃→x is one-to-one and w, x do not occur in ∀y∀zPyz.
2.
The wff ∀z∀zPzz is not an alphabetic variant of ∀y∀zPyz, because the change of the
quantified variable y 󳨃→z is such that z is in the scope of ∀in ∀y∀zPyz.
Here are two examples which indicate that one can deduce alphabetic variants:
1.
∀yQy ⊢∀xQx (see Example 3.3.25),
2.
∀y∀zPyz ⊢∀x∀wPxw.
The above examples illustrate that one can deduce a “change of quantified variables.”
In Theorem 3.3.61 below, such a “change of variables” result is established in general.
Consequently, when a term is not substitutable for a variable in a given wff, one can
change the quantified variables so that the term will become substitutable.
The following is essentially a restatement of Theorem 3.3.46.
Lemma 3.3.60. Let α and β be wffs and let x be any variable. If α ⊢β, then ∀xα ⊢∀xβ.

3.3 Deductions
౪
115
Given a term t and a wff φ, the term t may not be substitutable for a specific variable
in φ. The following theorem shows that one can change the quantified variables in φ to
get an equivalent formula φ in which t is substitutable.
Theorem 3.3.61 (Alphabetic variants). Let φ be a wff, t a term, and x a variable. There
exists an alphabetic variant φ of φ such that:
(a) φ ⊢φ and φ ⊢φ;
(b) t is substitutable for x in φ.
Proof. Let the variable x and let term t be fixed. If t is substitutable for x in φ, then let
φ = φ. Otherwise, we will define φ and prove the following statement by induction on
φ: φ ⊢φ, φ ⊢φ, and t is substitutable for x in ϕ.
Base step: Let ϕ = Pt1t2 ⋅⋅⋅tn be an atomic sentence. Let ϕ = ϕ. Clearly, ϕ ⊢ϕ, ϕ ⊢ϕ, and
t is substitutable for x in ϕ.
Inductive step: Let α and β be arbitrary wffs. Assume the induction hypothesis that there
are wffs α and β such that
α ⊢α, α ⊢α, and t is substitutable for x in α,
β ⊢β, β ⊢β, and t is substitutable for x in β.
(IH)
We must prove that the same holds for each of the following: ¬α, α →β, ∀yα.
Case ¬α: Let ¬α = ¬α. By (IH), contraposition, and Definition 3.3.15, we see that ¬α ⊢¬α,
¬α ⊢¬α, and t is substitutable for x in ¬α.
Case α →β: Let α →β = α →β. By (IH), Exercise 22, and Definition 3.3.15, we see that
(α →β) ⊢(α →β), (α →β) ⊢(α →β), and t is substitutable for x in α →β.
Case ∀yα : Choose a variable z
̸= x that occurs neither in α nor in t. Let ∀yα = ∀zαy
z. We
must prove that
∀yα ⊢∀zαy
z, ∀zαy
z ⊢∀yα, and t is substitutable for x in ∀zαy
z.
We first show that t is substitutable for x in ∀zαy
z. By the induction hypothesis (IH),
the term t is substitutable for x in α. Since x
̸= z and z does not occur in t, it follows
that t is substitutable for x in αy
z. Thus, by Definition 3.3.15(4)(b), we conclude that t is
substitutable for x in ∀zαy
z.
By the induction hypothesis we have α ⊢α. Since z does not occur in α, we see that
(⋆) z is substitutable for y in α. Also, as z does not occur in α, it follows that z does not
occur free in α (if it occurred free in α, it would occur in α). Therefore, (⋆⋆) z does not
occur free in ∀yα. We now prove that ∀yα ⊢∀z(α)y
z as follows:
α ⊢α
by (IH),
∀yα ⊢∀yα
by Lemma 3.3.60,

116
౪
3 First-order logic
∀yα ⊢αy
z
by modus ponens as ∀yα →αy
z is a logical axiom (group 2) via (⋆),
∀yα ⊢∀zαy
z
by (⋆⋆) and the generalization theorem (Theorem 3.3.29).
We now prove that ∀zαy
z ⊢∀yα. Recall that z does not appear in α. Lemma 3.3.57 thus
implies that y is substitutable for z in αy
z and that αyz
zy = α. Also, we note that (󳵳) y does
not occur free in ∀zαy
z. Since ∀zαy
z →αyz
zy is a logical axiom, we see that (󳶃) ∀zαy
z ⊢αyz
zy.
Finally, we prove that ∀zαy
z ⊢∀yα as follows:
∀zαy
z ⊢αyz
zy
by (󳶃,)
∀zαy
z ⊢α
because αyz
zy = α,
∀zαy
z ⊢α
by (IH) α ⊢α, and so Lemma 3.3.26(4) applies,
∀zαy
z ⊢∀yα
by (󳵳) and the generalization theorem (Theorem 3.3.29).
Exercises 3.3.
*1. Let 𝒮be the set of all prime formulas in a language ℒ. Let ℱ= {ℰ¬, ℰ→} and let 𝒮
be the set of all wffs generated by 𝒮from the functions in ℱ. Prove by induction on
wffs that every wff is in 𝒮.
*2. Let A be an ℒ-structure with domain A. Let V be the set of all the variables of ℒ. Let
s: V →A be a variable assignment. Define a truth assignment on the set of prime
wffs α by
u(α) = {T,
if A 󳀀󳨐α[s],
F,
if A
̸󳀀󳨐α[s].
(a) Show that for all wffs θ,
u(θ) = T
iff
A 󳀀󳨐θ[s].
(b) Let Γ be a set of wffs and let φ be a wff. Show that if Γ tautologically implies φ,
then Γ logically implies φ.
3. Show that the wff ∀v1(v1 ̇=v1) →v1 ̇=v1 is logically valid and that it is not a first-order
tautology.
4. Let ℒ= {c, f , ̇=}, where c is a constant symbol and f is a 1-place function symbol. For
each of the following wffs φ and terms t, evaluate φx
t and decide if t is substitutable
for x in φ:
(a) ∀x(x ̇= y →fx ̇= fy) and t is fc,
(b) ∀y(x ̇= y →fx ̇= fy) and t is fy,
(c) (x ̇= y →∀x(fx ̇= fy)) and t is fy.
*5. Let ℒbe a language, let x be a variable in ℒ, and, in particular, let x = vi0. Now let
t be a term. Let A be the set of all the atomic formulas and let X be the set of wffs
defined by

3.3 Deductions
౪
117
X = {∀vi0α : α is a wff}.
Thus, X is the set of wffs of the form ∀xα, where α is some wff. Let 𝒮= A ∪X, a
disjoint union. Let Q = {ℰQi : i
̸= i0}. Let ℱ= {ℰ¬, ℰ→} ∪Q (see (3.4)) and let 𝒮be
the set generated from 𝒮by the functions in ℱ. Theorem 3.1.16 implies that 𝒮is
the set of all the wffs and is freely generated from the set 𝒮by the functions in ℱ.
By Exercise 11 on page 65, for each term τ, τx
t is the term obtained by replacing all
occurrences of x in τ with t. Define h: 𝒮→𝒮by
h(v) = {Pτ1
x
t τ2
x
t ⋅⋅⋅τn
x
t ,
if v = Pτ1τ2 ⋅⋅⋅τn is in A,
∀xα,
if v = ∀xα is in X.
(3.17)
Theorem 1.1.27 implies there is a unique function h: 𝒮→𝒮such that
(1) h(α) = h(α) if α ∈S,
(2) h((¬α)) = ¬h(α),
(3) h((α →β)) = h(α) →h(β),
(4) h(∀vα) = ∀vh(α) whenever v
̸= x.
Prove, by induction on wffs, that for all wffs α, h(α) = αx
t .
6. Let ℒ= {P, Q, c}, where P is a 1-place predicate symbol, Q is a 2-place predicate
symbol, and c is a constant symbol. To which logical axiom groups, if any, do each
of the following wffs belong?
(a) ((∀xPx →∀yPy) →Pz) →(∀xPx →(∀yPy →Pz)).
(b) ∀y(∀x(Px →Px) →(Pc →Px)).
(c) ∀x∃yQxy →∃yQyy.
7. Using Definition 3.3.20, prove Lemma 3.3.26.
8. Suppose that Γ is consistent and Γ ⊢φ. Show that Γ ∪{φ} is consistent.
9. Let Γ = {∀xα, ∀x¬α}, where α is a wff. Show that Γ is inconsistent.
*10. Suppose that the term t is substitutable for x in wff α. Show that ⊢αx
t →∃xα.
11. Show that ⊢∀xφ →∃xφ by presenting an explicit deduction.
*12. Prove Theorem 3.3.38.
13. Prove Proposition 3.3.41.
14. Prove Proposition 3.3.43.
15. Prove Proposition 3.3.44.
16. Prove Theorem 3.3.46.
17. Show the following:
(a) ⊢∃x(Px →∀xPx),
(b) {Qx, ∀y(Qy →∀zPz)} ⊢∀xPx.
18. Show that ∀x∀yPxy →∀y∀xPyx.
*19. Prove Proposition 3.3.51.
*20. Let f be a 1-place function symbol and let t and τ be terms. Show that:
(a) ⊢∀x∀y(x ̇= y →fx ̇= fy),
(b) ⊢(t ̇= τ →ft ̇= fτ).

118
౪
3 First-order logic
*21. Prove Lemma 3.3.57 by induction on φ.
*22. Suppose that:
1.
α ⊢α and α ⊢α,
2.
β ⊢β and β ⊢β.
Prove that (α →β) ⊢(α →β) and (α →β) ⊢(α →β).
23. Let Γ and Δ be sets of wffs. Suppose that Γ ⊢φ for all φ ∈Δ and that Δ ⊢σ. Prove
that Γ ⊢σ.
*24. Prove that a set of wffs Γ is consistent if and only if every finite subset of Γ is con-
sistent.
*25. Suppose that Γ is a consistent set of wffs and let φ be a wff. Show that if Γ ⊬φ, then
Γ ∪{¬φ} is consistent.
26. Suppose Σ is a set of sentences, φ is any wff, and x is any variable. Prove that Σ ⊢φ
if and only if Σ ⊢∀xφ.
*27. Show that ⊢¬∀vα →¬∀v¬¬α.
28. Show that ⊢∃xβ →∀xβ if x does not occur free in β.
29. Show that ⊢∃x(∃xPx →Px).
30. Let Σ0 ⊆Σ1 ⊆Σ2 ⊆Σ3 ⊆⋅⋅⋅be sets of wffs. Suppose that each Σi is consistent. Show
that ⋃i∈ℕΣi is consistent.
Exercise Notes: For Exercise 11, ∀xφ →φ and ∀x¬φ →¬φ are logical axioms. In addi-
tion,
(∀x¬φ →¬φ) →(φ →¬∀x¬φ) and
(∀xφ →φ) →(φ →¬∀x¬φ) →(∀xφ →¬∀x¬φ)
are tautologies. For Exercise 17, use reductio ad absurdum by showing that
∀x¬(Px →∀xPx) ⊢∀xPx
(via Logical Axiom 2, a tautology, and generalization) and showing, via Logical Axiom 2
and a tautology, that ∀x¬(Px →∀xPx) ⊢¬∀xPx. For Exercise 18, use Problem 3.3.39(2) on
page 106. For Exercise 20, by Theorem 3.3.61 one can assume that x and y do not appear
in t or τ.

