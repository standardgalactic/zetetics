Symbolic Brittleness in Sequence Models:
on Systematic Generalization in Symbolic Mathematics
Sean Welleck,1 2 Peter West,1 Jize Cao,1 Yejin Choi1 2
1 Paul G. Allen School of Computer Science & Engineering, University of Washington
2 Allen Institute for Artiﬁcial Intelligence
wellecks@uw.edu
Abstract
Neural sequence models trained with maximum likelihood
estimation have led to breakthroughs in many tasks, where
success is deﬁned by the gap between training and test per-
formance. However, their ability to achieve stronger forms of
generalization remains unclear. We consider the problem of
symbolic mathematical integration, as it requires generaliz-
ing systematically beyond the test set. We develop a method-
ology for evaluating generalization that takes advantage of
the problem domain’s structure and access to a veriﬁer.
Despite promising in-distribution performance of sequence-
to-sequence models in this domain, we demonstrate chal-
lenges in achieving robustness, compositionality, and out-
of-distribution generalization, through both carefully con-
structed manual test suites and a genetic algorithm that au-
tomatically ﬁnds large collections of failures in a controllable
manner. Our investigation highlights the difﬁculty of gener-
alizing well with the predominant modeling and learning ap-
proach, and the importance of evaluating beyond the test set,
across different aspects of generalization.1
1
Introduction
Despite their success, recent studies reveal undesirable prop-
erties of conventional neural sequence models, such as as-
signing high-probabilities to unrealistic sequences (Holtz-
man et al. 2020; Welleck et al. 2020), susceptibility to adver-
sarial attacks (Wallace et al. 2019), and limited generaliza-
tion on symbolic tasks (Saxton et al. 2019; Nogueira, Jiang,
and Li 2021), even with very large models and datasets
(Henighan et al. 2020). Despite these drawbacks, Lample
and Charton (2019) recently demonstrated that a standard
sequence-to-sequence model, which we call a neural se-
quence integrator, performs surprisingly well at symbolic in-
tegration, solving problems that are beyond traditional sym-
bolic solvers and achieving near perfect test accuracy.
Recent studies suggest that achieving strong and sys-
tematic generalization is difﬁcult with vanilla sequence-to-
sequence methods, as they latch onto regularities in the train-
ing data, learning dataset-speciﬁc solutions that do not gen-
eralize beyond the training distribution (e.g. Agrawal, Ba-
tra, and Parikh (2016); Lake and Baroni (2018); Bahdanau
et al. (2019); Hupkes et al. (2020)). Symbolic integration
1Code available at:
https://github.com/wellecks/symbolic generalization
Input
Integral
Prediction
30 cos(39x)
10
13 sin(39x)
10
13 sin(39x)

17 cos(83x)
17
83 sin(83x)
1
17 sin(83x)

34 cos(77x)
34
77 sin(77x)
sin(77x)

x209
1
210x210
1
210x210

x764
1
765x765
1
765x765

x209 + x764
1
210x210 +
1
765x765
1
205x205

−241
−241x
−239x −14400

123x
123x
log(123)
123x
1+log(123)

4x + x465 + 1
x466
466 + x +
4x
log(4)
x466
466 + x + ex

Table 1: Despite its impressive ability to integrate equations
that are out of reach for traditional symbolic solvers, the
neural sequence integrator shows deﬁciences in robustness
(top) and compositionality (middle), and fails on adversar-
ial problems discovered by SAGGA (bottom).
– ﬁnding the integral of a mathematical function – speciﬁ-
cally requires these forms of generalization, as it involves an
underlying structure that extends beyond this ﬁxed training
distribution. For instance, the rule
R
k = kx + C applies to
all constants k, and the sum rule
R
f1 +
R
f2 =
R
(f1 + f2)
means that integrating two functions correctly should imply
integrating their sum correctly. Symbolic integration also of-
fers a structured problem domain and a veriﬁer for evalu-
ating whether a proposed solution is correct, making it an
effective setting for evaluating generalization. As the neural
sequence integrator relies on a common recipe– a large-scale
transformer trained to maximize the likelihood of a training
set of input-output sequences – it is especially interesting to
study whether it generalizes systematically.
In this paper, we ﬁnd a discrepancy between the tradi-
tional notion of generalization captured by test set accu-
racy and the generalization needed in symbolic mathemat-
ics. While the model’s test accuracy is nearly perfect, we
ﬁnd this breaks down when testing its robustness, compo-
sitionality, and out-of-distribution generalization (e.g. Ta-
ble 1). We describe a methodology for evaluating these as-
pects, by constructing problem sets and developing a genetic
arXiv:2109.13986v2  [cs.LG]  24 Feb 2022

✓
2x42
✗
3x42
Robustness
x2
cos(x)2 sin(x)2
x2
sin(x)2
+
✗
Compositionality
Out-of-Distribution
Training distribution
✗
5xx2
exploit
long problem
✓
✓
✓
✗
5x + 10 + cos(x)sin(x)2 + . . .
✓
Figure 1: Illustrating robustness, compositionality, and out-
of-distribution deﬁciencies in the neural sequence integrator.
algorithm, SAGGA (Symbolic Archive Generator with Ge-
netic Algorithms), that automatically discovers diverse and
targeted failures. We ﬁnd that successfully integrating an
in-distribution problem does not imply success on nearby
problems, despite being governed by the same underlying
rule (robustness). Moreover, the model often succeeds on a
collection of problems without being able to systematically
compose those problems (compositionality), and struggles
to generalize to longer problems, larger values, and func-
tions not covered in training (out-of-distribution).
In addition to the model’s approximate mode being in-
correct – i.e. the most probable sequence returned by beam
search – the deﬁciencies are present deeper into its ranked
list of candidate solutions, impacting the model’s effective-
ness in a search-and-verify setting. Overall, our investiga-
tion highlights the difﬁculty of achieving robustness, com-
positionality, and out-of-distribution generalization with the
predominant modeling and learning approach, and the im-
portance of evaluating beyond the test set, across aspects of
generalization that are required by the task at hand.
2
Problem Setup
Symbolic integration is the problem of ﬁnding the integral y
of an input equation x. For instance, x2/2 is the integral of
x, up to an additive constant.
Neural sequence integrator.
Lample and Charton (2019)
frame symbolic integration as a sequence-to-sequence prob-
lem. In this view, input and output equations x and y are
preﬁx-notation sequences. The neural sequence integrator
uses a 6-layer transformer (Vaswani et al. 2017) to model
the distribution pθ(y|x) = QTy
t=1 pθ(yt|y<t, x) by train-
ing the model to maximize the log-likelihood of a set of
training problems, arg maxθ
P
(x,y)∈D log pθ(y|x). Given
a trained model and input x, a set of predicted solutions
ranked by a model score is obtained by beam search, denoted
{ˆy1, . . . , ˆyk} = fθ(x; k, b), where b is beam size and k is
the number of candidates saved for evaluation. For brevity
we omit b in the discussion unless necessary.
Evaluation.
The standard practice is to evaluate a candi-
date ˆy by checking whether the derivative of ˆy is equivalent
to x using a symbolic solver (e.g. Sympy). In the maximum-
a-posteriori (MAP) setting, the model’s output is considered
correct if its top-ranked candidate ˆy1 is correct. This crite-
rion is relaxed in the search-and-verify setting, where the
model’s output is considered correct if any of its k candi-
dates {ˆy1, . . . , ˆyk} is correct. In this view, the neural net-
work narrows the search space to a small set of candidates
that are checked, trading off correctness for search and veri-
ﬁcation cost. We denote checking k candidate solutions as,
m(x, fθ(x; k)) =
0
x ≡
d
dx ˆyi for any i ∈1 to k,
1
otherwise.
(1)
In other words, m(·, ·) is 1 when the model fails to pre-
dict the correct integral, and 0 when the model succeeds.
We measure the proportion of failures on problems X =
{x1, . . . , xN} using k candidate solutions per problem as:
Fail@k(fθ, X) = 1
N
X
x∈X
m(x, fθ(x; k)).
(2)
Fail@k is 0 when the model correctly integrates all of the
problems in X, and increases towards 1 as it fails to inte-
grate more problems. Evaluating a model’s performance in
the MAP setting corresponds to evaluating Fail@1, while
the search-and-verify setting with a budget of k > 1 candi-
dates uses Fail@k. We omit k in fθ(x; k) unless necessary.
2.1
Experiment Structure
We structure our investigation into three parts (Figure 1). We
begin close to the model’s training distribution, evaluating
robustness to small perturbations of in-distribution problems
and simple functions. We then ask whether learning to inte-
grate a collection of functions implies that the model can
integrate a composition of those functions. Finally we de-
part from the training distribution by studying extrapolation
to larger problems and values, then by ﬁnding adversarial
exploits that expose gaps in the training distribution.
Experimental setup.
We use the implementation and pre-
trained model from Lample and Charton (2019) for all of our
experiments, speciﬁcally the FWD+BWD+IBP model which
obtained top-10 accuracies of 95.6%, 99.5%, and 99.6% on
their publicly available test sets.2 Our evaluation is based on
their code, we use their utilities for inputs and outputs, and
by default use beam search with beam-size 10. Following the
authors, we use Sympy to check whether the derivative of a
prediction is equal to the original problem. We generously
count the prediction as correct if a timeout occurs. See the
Apppendix for additional details.
2.2
Automatic Problem Discovery with SAGGA
Automatically ﬁnding problems that expose deﬁciencies re-
quires a non-differentiable cost (Equation 1), satisfying con-
straints for valid equations, and ﬁnding diverse problem sets
to characterize each aspect of generalization. To address
these challenges, we develop SAGGA (Symbolic Archive
Generation with Genetic Algorithms), a gradient-free ge-
netic algorithm which iteratively ﬁnds diverse failures.
At each iteration, SAGGA mutates a seed set of problems
by modifying each problem’s equation tree, ensuring that the
2https://github.com/facebookresearch/SymbolicMathematics/,
commit 4596d07.

Algorithm 1: SAGGA. Each seed problem denoted
as ˆx, mutated problem as ˜x, archived problem as x.
Parameters: Fitness F(fθ, x) →R,
mutate and seed strategies, archive size N.
Output: Problem archive D = {x1, . . . , xN}.
D = ∅
// initial archive
ˆx(0)
1:M = seed(D, ∅)
// initial seed
while |D| < N do
// generate mutations
˜x(i)
1:M ′ = mutate(ˆx(i)
1:M)
// select problems by fitness
x(i)
1:M ′′ = select(F, ˜x(i)
1:M ′)
// archive selected problems
D = D ∪x(i)
1:M ′′
// choose next seed
ˆx(i+1)
1:M
= seed(D, F, ˜x(i)
1:M ′)
resulting candidates are valid equations. The candidates are
scored by a ﬁtness function – i.e. according to whether the
neural sequence integrator fails to integrate the problem and
other desired constraints – and the highest-ﬁtness candidates
are saved in a problem archive. The next seed set is then
formed to balance diversity and ﬁtness, by clustering can-
didates and selecting the highest-ﬁtness members of each
cluster. SAGGA continues until the archive contains a target
number of problems. Algorithm 1 summarizes SAGGA.
SAGGA offers control over the types of problems that it
discovers through its seed problems, ﬁtness function, and
mutation strategy. We detail our choices for each kind of
generalization in their respective sections, and show default
settings and further implementation details in the Appendix.
3
Robust or Brittle?
First, we study whether the model’s strong test-set perfor-
mance adequately represents its robustness. Robustness tells
us whether the integration model systematically solves all
problems in a neighborhood governed by a generalizable
pattern; for instance a model that solves
R
26x42 should
solve
R
53x42. We study problems that are nearby to those
from the original test distribution, as well as to simple prim-
itive functions that offer ﬁne-grained, interpretable control.
A robust model is stable to small perturbations in input,
meaning that it gets nearby problems ˜x correct when it gets a
problem x correct. Formally, let X = {x1, . . . , xN} contain
problems that the model gets correct, P
x∈X m(x, fθ(x)) =
0, and let Nd(x) be a set of problems that are nearby to x
according to a distance d(x, ˜x). We measure robustness by
measuring failures on nearby problems,
Fail@k(fθ, XN ),
(3)
where XN = S
x∈X Nd(x). We measure this quantity by
varying (i) the neighborhood Nd(x) used to generate nearby
problems, and (ii) the seed problems X to consider. Below,
we will refer to a problem as x or f interchangeably.
Type
Test
Fail@50
Fail@10
Fail@1
coeff
k1 ln(k2x)
0.0
0.0
0.0
k1x
0.0
0.0
0.0
k1x42
0.0
6.1
45.5
k1 exp(k2x)
15.4
20.8
30.3
k1 sin(k2x)
6.6
19.6
29.7
k1 cos(k2x)
10.6
20.7
28.2
k1 tan(k2x)
13.9
17.4
24.2
coeff
1/k · f
5.9
12.0
13.7
coeff
k · f
5.4
5.8
16.3
+exp
f + ex
0.9
1.6
3.3
+ln
f + ln(x)
1.9
3.2
5.3
Table 2: Robustness results with simple primitives (top)
and validation problems f which the model correctly inte-
grates (bottom). Coefﬁcients are sampled from [1, 100].
Input
Integral
Prediction
30 cos(39x)
10
13 sin(39x)
10
13 sin(39x)

17 cos(83x)
17
83 sin(83x)
1
17 sin(83x)

34 cos(77x)
34
77 sin(77x)
sin(77x)

26x42
26
43x43
26
43x43

88x42
88
43x43
8x43

53x42
53
43x43
(x44 + x)/x

Table 3: Robustness examples. We show the model’s top
prediction (beam search, size 10). Note that (x44 + x)/x =
x43 + 1; its derivative is 43x42 and is hence incorrect.
3.1
Manually Testing Robustness
To deﬁne nearby problems, we ﬁrst consider manual tem-
plates which minimally perturb a problem f, e.g.
k · f,
f + ln x,
. . .
These problems are nearby f in the sense that a single op-
eration is added to the problem’s equation tree, or a small
number of node values are changed in the tree.
Brittleness on simple primitive functions.
We ﬁrst inves-
tigate whether the neural sequence integrator is robust on
simple primitive functions, since they make up more com-
plicated functions and are frequently entered by real-world
users. We use a manual neighborhood which yields,
XN = {k1 ln(k2x),
k1 exp(k2x),
k1x,
k1x42,
k1 sin(k2x),
k1 cos(k2x),
k1 tan(k2x)},
where k1 ∼U(a, b) and k2 ∼U(a, b) are randomly sampled
coefﬁcients from a range (a, b). We use [0, 100] which is
covered by the training distribution and evaluate on 1,000
k1, k2 pairs sampled without replacement for each primitive.
Table 2 shows the results. On a positive note, the neu-
ral sequence integrator is robust on the primitives k1x and
k1 ln(k2x). The integral of k1x is
k1
2 x2, so the model
learned to divide by 2 for these cases. The integral of ln in-
volves copying the coefﬁcients into a correct template (that

is,
R
k1 ln(k2x) = k1x(ln(k2x) −1)), and the neural se-
quence integrator learned this behavior.
On the other hand, the model is surprisingly brittle on
the other primitives. These require dividing coefﬁcients (e.g.
R
k1 cos(k2x) = k1
k2 sin(k2x)). The failure rate shows that
the model has not perfectly learned the required division be-
havior. Moreover, despite learning a ‘division by 2’ rule for
integrating k1x, the neural sequence integrator’s failures on
k1x42 indicate that it did not perfectly learn an analogous
‘division by 43’ rule. Table 3 shows examples.
Test accuracy does not imply robustness.
Next, we want
to see whether the neural sequence integrator’s strong test
accuracy implies that it is robust on test problems. We use
the validation set, and perturb validation problems that the
model correctly integrates using the neighborhoods,
XN1 = {1
k f,
k · f},
XN2 = {f + ex,
f + ln(x)},
where k ∼U(1, 100). The ﬁrst set multiplies the function
by a constant, while the second adds a single primitive.
Table 2 shows the results. Despite achieving perfect accu-
racy on the original problems, the model frequently fails un-
der the slight perturbations. The local neighborhood around
validation examples reveals deﬁciencies in robustness that
are not evident from validation performance alone, aligning
with ﬁndings in NLP tasks (Gardner et al. 2020).
3.2
Automatically Finding Robustness Failures
Next, we use SAGGA to automatically discover robustness
failures in the neighborhood of a seed set of problems.
Discovering brittleness near simple problems.
First, we
run SAGGA and only allow it to mutate leaves in a prob-
lem’s equation tree into a random integer. The problems are
nearby in the sense that the tree’s structure is not changing,
only a small number of its leaf values. We use SAGGA to
mutate the leaves of seed sets of 9 polynomials Xpoly and
9 trigonometric functions Xtrig, which are listed in the Ap-
pendix. We run SAGGA until it discovers 1000 failing prob-
lems, then cluster these using k-means on SciBERT embed-
dings (Beltagy, Lo, and Cohan 2019) of each problem.
Table 4 shows three members from three discovered prob-
lem clusters, for the polynomial and trigonometric seeds.
Intuitively, each cluster shows failures in a neighborhood
around a prototypical problem – for instance, on 2x42+k the
neural sequence integrator correctly integrates 2x42+21, but
not the problems in Cluster 2 (e.g. 2x42+22). See Appendix
Table 16 for more prototypes and the model’s predictions.
Curiously, each problem in a neighborhood is gov-
erned
by
a
common
template
–
e.g.
the
problems
{−104, −136, −33} are governed by
R
k = kx + C, yet
the failures suggest that the neural sequence integrator has
either not inferred the template, or does not apply it across
the neighborhood. To investigate this phenomenon, we show
the raw model prediction in Table 5, along with its simpliﬁed
version and derivative. Compared to the underlying template
R
k = kx + C the model’s raw output is long and complex.
In contrast, the simpliﬁed version is short; we hypothesize
this gap makes adhering to the template difﬁcult.
Seed
Cluster 1
Cluster 2
Cluster 3
Xpoly
−104
2x42 + 22
−47 + 2/x −2/x71
−136
2x42 + 28
−47 + 2/x −31/x71
−33
2x42 + 68
−71 + 36/x + 2/x71
Xtrig
13 cos 19x
13 cos 83x −59
10 sin 47x cos 2x
13 cos 83x
17 cos 37x −49
10 sin 90x cos 2x
17 cos 47x
17 cos 41x −45
19 sin 90x cos 2x
Table 4:
Example robustness problems discovered by
SAGGA which the neural sequence integrator fails to inte-
grate. See Appendix Table 16 for model predictions.
x
Raw
Simpliﬁed
Deriv.
−104
x2 + 2x −(x + 25)2
−48x −625
−48
−136
x2 −x(x + 130) + 2x
−128x
−128
−33
x2 + x −(x + 16)2
−31x −256
−31
Table 5: The raw model predictions for the problems x and
their simpliﬁed forms. Each prediction is incorrect since its
derivative is not equal to x. The neural sequence integrator’s
raw output is long and varied compared to the underlying
integration rule
R
k = kx + C.
Discovering brittleness near validation problems.
Fi-
nally, we use SAGGA to discover difﬁcult problems that are
close to a target set X – in our case validation problems – ac-
cording to an explicit distance d(x, ˜x). This allows for less
hand-designing of the perturbations.
Speciﬁcally, we deﬁne a ﬁtness which is high whenever a
candidate is close to any problem in a target set X,
ﬁtness(˜x) =

min
x∈X d(x, ˜x)
−1
· m(˜x, fθ(˜x)).
(4)
We randomly sample 10 validation problems to form X,
set SAGGA’s initial seed to X, and use cosine similarity of
SciBERT vectors to deﬁne the distance d(x, ˜x). Since the
distance now constrains the problems, we are free to use a
wider set of mutations: changing a node’s operation, adding
an argument to a node, and replacing the node with a random
constant, symbol, or simple operation.
Table 6 shows example problems that SAGGA discovers
around the successful validation problems, exposing a wider
class of robustness failures than our preceding experiments.
4
Integrating Parts But Not The Whole
While the preceding section identiﬁed weaknesses in ro-
bustness – for instance, integrating 26x42 but not 88x42 –
a remaining question is whether successfully integrating a
collection of primitives implies that a composition of those
primitives will be successfully integrated.
Compositionality refers to forming compound equations
from known primitives and operations. A compositional
model should correctly integrate equations of the form,
f = f1 ◦f2 ◦· · · ◦fk,
(5)

Validation Problem
Nearby Failures
−x2 + x + log(4) tan(x)
−x2 + x + log(4) tan(17x2)
−x2 + x + log(4) tan(2x2)
−x2 + x + log(4) tan(63/x2)
√3x + 3 −2
p
−86x2 + 62/x −40
p
14 + 62/x + 4
p
14 + 62/x −2
tan(exp(2))/18x
tan(exp(2 + 71/x))/18x
tan(exp(2 −46x))/18x
tan(exp(37x))/18x
Table 6: SAGGA discovers failures around successful val-
idation problems, within a neighborhood deﬁned by an ex-
plicit distance. Model predictions are in Appendix Table 16.
Input
Prediction
x1/3
3
4x4/3

x1/606
606
607x
607
606

x1/3 + x1/606
3
5x
5
3 +
6
613x
613
606

x209
1
210x210

x764
1
765x765

x209 + x764
1
205x205

14 cos(58x)
7
29 sin(58x)

46 cos(84x)
23
42 sin(84x)

14 cos(58x) + 46 cos(84x)
sin(59x) cos(x)

Table 7: Compositionality examples. We show the model’s
top prediction (beam search, width 10). The model success-
fully integrates the individual primitives, but not their sum.
where f1, . . . , fk are equations that the model successfully
integrates, and ◦is a binary operation (e.g. addition). For
instance, a system that integrates x2 and cos x and is capable
of addition should successfully integrate x2 + cos x.
Formally, we say that a model is k-compositional with
respect to equations X and operation ◦when it success-
fully integrates any combination of k equations from X,
P
x∈˜
X m(x, fθ(x)) = 0, where ˜X = {f1◦· · ·◦fk|fi ∈X}.
We evaluate k-compositionality with respect to addition,
using simple primitive functions and validation problems.
As integration is linear,
R
(f +g) =
R
f +
R
g, composition-
ality with respect to addition is a reasonable requirement.
Succeeding on simple primitives, failing on their sum.
We collect simple primitives from the coefﬁcient robustness
experiments that the model successfully integrates (coeff),
and successful exponents xc or x1/c, c ∈[0, 1000] (exp).
We randomly sample 1000 compound equations f1+. . .+fk
for k ∈{2, 3, 4} and evaluate the failure rate. Table 8 shows
the results. Adding two primitives gives failure rates of 29%
and 85% for coefﬁcient and exponent primitives, respec-
tively, despite failing 0% of the time on the individual prim-
Type
Test
Fail@50
Fail@10
Fail@1
exp(1)
f1
00.0
00.0
00.0
exp(2)
f1 + f2
70.8
72.4
84.9
exp(3)
f1 + f2 + f3
91.3
97.5
99.5
exp(4)
f1 + . . . + f4
86.2
97.4
99.8
coeff(1)
f1
00.0
00.0
00.0
coeff(2)
f1 + f2
8.60
16.2
29.2
coeff(3)
f1 + f2 + f3
23.8
37.5
61.0
coeff(4)
f1 + . . . + f4
23.1
38.7
60.0
valid(1)
f1
00.0
00.0
00.0
valid(2)
f1 + f2
6.80
14.5
15.0
valid(3)
f1 + f2 + f3
21.5
36.5
43.6
valid(4)
f1 + . . . + f4
52.5
69.0
79.2
Table 8: Compositionality. Top: successful simple prim-
itives from the robustness experiments (Table 2). Bottom:
successful validation-set primitives. Despite integrating
each primitive, the model struggles to integrate their sums.
Nodes
Fail@10
Fail@1
1-15
0.4
1.6
20
1.9
10.7
25
7.2
17.2
30
24.4
37.1
35
49.0
59.2
Table 9: Extrapolation to more operator nodes under the
training data generation process. Training used 1-15 nodes.
itives. As the number of compositions increases, the failure
rate increases towards 100%. Table 7 shows examples.
Succeeding on test problems, failing on their sum.
We
perform a similar experiment using successful validation-set
functions. We ﬁlter examples longer than 20 tokens so that
composed equations are within the training domain in terms
of length, and sample 1000 compound equations f1 + . . . +
fk for k ∈{2, 3, 4}. As seen in Table 8, the failure rate
grows as the number of compositions increases, similar to
the simple primitives case. Maximizing the likelihood of a
large training set did not yield a compositional model.
5
Departing Further From Training
The preceding experiments found problems that were nearby
to, or composed directly from, in-distribution examples. In
this section, we deliberately move from the model’s training
distribution to evaluate its out-of-distribution generalization.
First, we study extrapolation to longer equation sizes than
those in its training distribution, and to integer ranges that
are only sparsely covered in the training set. Then we use
SAGGA to expose exotic failures and reveal problem classes
that were not covered during training.
Longer problems are more difﬁcult.
First, we use the
same data-generating process as for training, but vary its
parameters to depart from the training distribution. Speciﬁ-
cally, we test extrapolation on number of operator nodes in

Figure 2: Integer extrapolation. Failure rates for integrating
simple primitives with coefﬁcients from the speciﬁed range.
Problem
Exploit
169 sin(4x)/x
Uses Si(·).
−2 sin(42/x)
Uses Ci(·).
−2 sin(185x2) cos(2x)
Uses Fresnel S, C integrals.
357x2 x + 2 sin(2x)
Uses incomplete gamma Γ(a, x).
1/(x48(3x + 2)49)
Decoding does not terminate.
Table 10: Exploits discovered by SAGGA whose integrals
use out-of-domain functions. See Appendix Table 18 for
model predictions.
each equation tree, using Lample and Charton (2019)’s data
generation process and varying the max ops parameter. Ta-
ble 9 shows performance when max ops is increased past
the model’s training domain (1-15). The neural sequence in-
tegrator does show some extrapolation to equation trees with
more operator nodes than it was trained on, but its failure
rate increases substantially as the number of nodes increases.
Larger failures on larger digits.
Next, we study per-
formance as integer values increase, quickly going out-of-
domain. Considering a sample of 200,000 sequences from
the training distribution, 99.4% of the positive integers
were between 1 and 100. Other ranges were non-empty but
sparsely represented; for instance, 0.2% of the integers were
between 100 and 200, and 0.096% between 1,000 and 2,000.
Figure 2 shows performance on primitive functions with co-
efﬁcients from the speciﬁed range. As in the robustness ex-
periments, the x and ln primitives perform well, showing
that there is some ability to use large numbers. However,
performance severely degrades for the exp, sin, cos, tan
primitives as the coefﬁcient magnitudes increase, reaching
near 100% failure rates on large coefﬁcients.
Discovering unsupported functionality.
Next, we run
SAGGA in an unconstrained setting with all mutation types,
favoring short problems using the ﬁtness, F(fθ, x)
=
m(x, fθ(x)) ·
1
|x|, which is positive when the model returns
an incorrect integral for x, and higher for shorter problems.
SAGGA discovers exploits based on the neural sequence
integrator’s limited training distribution, such as problems
whose integral is expressed using the Gamma function Γ(·),
Cluster 1
Cluster 2
Cluster 3
Cluster 4
119x
−240x + 2 cos 2x
−100xx
158xx2 + 611
132x
−398x + 2 cos 2x
−149xx
256xx2 + 191
136x
−692x + 2 sin 2x
−151xx
332xx2 + 559
Table 11: SAGGA discovers many failures that involve x in
an exponent. See Appendix Table 17 for model predictions.
Figure 3: Left: Average length of discovered problems in
each iteration, using ﬁtness functions that promote the given
length. SAGGA discovers problems of each target length.
Right: SAGGA discovers longer problems at a higher rate.
or the cosine integral Ci, which are not included in its train-
ing data (Table 10).3 These examples are a reminder that the
sequence-to-sequence paradigm determines which functions
are ‘built in’ by inclusion in training data; omitted behavior
is left unspeciﬁed, leaving it susceptible to exploits.
Finally, the last problem in Table 10 caused the neural
sequence integrator to enter a non-terminating loop during
decoding (Appendix Table 18), a known idiosyncrasy of au-
toregressive models with beam search (Welleck et al. 2020).
SAGGA also ﬁnds many clusters that indicate the neural
sequence integrator struggles when x appears in an expo-
nent. The discovered problems in Table 11 are a microcosm
of our previous ﬁndings: For the ﬁrst cluster, we manually
found a nearby problem, 30x, that the model gets correct;
this cluster is a robustness failure. The second cluster shows
how such failures cascade further as the function is com-
posed. The ﬁnal two clusters involve xx or xx2, which do
not have analytical integrals;4 these clusters are exploits.
Finding problems with target properties.
Finally, we
generate failures of a target length, by running SAGGA to
target length 10, 20, and 40 problems. As seen in Figure 3,
SAGGA converges to ﬁnd problems of the target length.
Based on our extrapolation experiments, we expect SAGGA
to fail more often on longer equations. The right-hand plot in
Figure 3 shows that it is also easier to ﬁnd failures for longer
equations, in that the archive grows more quickly for longer
target lengths. While we visually inspect short equations for
interpretability, the growth rate is a reminder that the space
of failures is vast for longer equations.
3https://en.wikipedia.org/wiki/Trigonometric integral.
4https://www.wolframalpha.com/input/?i=integral+of+x**x

p@1
p@500
p@{1-500}
Failures@500
0.93912
3.9×10−6
0.99435
Success@500
0.91647
3.5×10−6
0.99316
Table 12: Probability assigned to the top candidate (p@1),
the 500’th candidate (p@500), and the mass covered by the
top 500 candidates (p@{1-500}), in failures and successful
cases (exp-robustness problems, width-500 beam search).
Sequences outside of the top 500 are very improbable com-
pared to the most probable candidate. In both cases, the top
500 candidates cover most of the probability mass.
k
Unresolved@k
1
91.6%
10
65.2%
Table 13: Percentage of failures on the FWD validation set
in which the ground truth y∗is scored lower than the top
beam candidate (Unresolved@1) or the bottom beam candi-
date (Unresolved@10), meaning that perfect search would
leave the failures at level k unresolved.
6
Is it a search problem? Distinguishing
between model and search errors
Both the experiments of Lample and Charton (2019) and
our own generate candidate solutions from a sequence-to-
sequence model using beam search. This raises the possibil-
ity that failures are due to search rather than the model: what
if the highest scoring sequences are correct, but not found?
Speciﬁcally, we want to distinguish between search er-
rors, which occur when pθ(y∗|x) ≫p(y|x) but the search
algorithm (e.g. beam search) does not return y∗, and model
errors, meaning pθ(y|x) ≫p(y∗|x). Here y∗is any correct
solution to problem x.
6.1
The model is deﬁcient: model errors.
We study simple-robustness and in-distribution problems,
and ﬁnd evidence of model deﬁciencies that would remain
unresolved with perfect search.
Robustness.
First, we study the simple-primitive robust-
ness problems (e.g. k1 exp(k2x), see Table 2), as these short
problems resulted in a small number of timeouts, allowing
us to scale up search and veriﬁcation. We increase the beam
size to 500 candidates, and study the model’s probabilities
on the 500 returned candidates and correct solutions. We
refer to the candidates ranked by decreasing probability as
y(1)
beam, . . . , y(500)
beam (i.e. y(1)
beam has the highest probability).
When a correct solution is within the 500 returned can-
didates, the correct solution often has much lower probabil-
ity than the top candidate, pθ(y(1)
beam|x) ≫p(y∗|x). Speciﬁ-
cally, correct solutions often appear at the bottom of the can-
didates (Figure 4, orange), yet on average the bottom candi-
date y(500)
beam has probability ≈0.0000035, while the top can-
didate y(1)
beam has probability ≈0.92 (Table 12). These are
Figure 4: Probabilities assigned to the top-ranked beam can-
didate (max) versus correct candidates (correct) with a
large search & veriﬁcation budget (500 candidates). The
model often assigns very low probability to correct candi-
dates that are found by increasing the search budget; search
covers up underlying model deﬁciencies. (exp-robustness)
model deﬁciencies: the model is conﬁdently incorrect, as-
signing very high probability to an incorrect solution at the
top, and very low probability to correct solutions.
When a correct solution is not within the top 500 can-
didates, the model is again conﬁdently incorrect, with the
top candidate y(1)
beam receiving ≈0.94 probability. Improving
the search algorithm – e.g. by further increasing the search
budget or using an alternative to beam search – would in-
evitably return a low probability solution, as the 500 candi-
dates already cover more than 99.4% of the probability mass
(Table 12). The ﬁndings again point to model errors.
In-distribution.
Next, we study in-distribution problems
from the FWD validation set of Lample and Charton (2019).
On failure cases, we test if the ground-truth y∗is scored
above the top k beam candidates, meaning that failure@k
might be resolved with perfect search–y∗was scored more
highly but was simply not found. As seen in Table 13, the
majority of failures – 91.6% for failure@1 and 65.2% for
failure@10 – would remain unresolved with perfect search,
again pointing to model deﬁciencies.
6.2
Covering up deﬁciencies with search.
Our preceding experiments showed that the top of the
model’s ranked solution list is often made up of incorrect
solutions, while correct solutions deeper into the solution
list are assigned very low probabilities. A natural question
is whether we can simply ‘cover up’ the deﬁcient model by
enumerating and verifying even more candidates, while ig-
noring the model’s probabilities.
On simple robustness problems (e.g. k1 exp(k2x)), we
ﬁnd that large search budgets can alleviate failures, i.e.
Fail@k decreases as k increases, for instance moving from
roughly 30% failure@1 to 3% failure@500 on exp robust-
ness (Figure 5). On more complex problems, verifying more
candidates reduces the failure rate, yet our experiments do
not indicate that failures approach zero for practical search

Candidates
Verify (hrs)
Worst-case (hrs)
1
0.088
0.833
10
0.463
8.333
50
2.250
41.667
Table 14: Runtime needed to verify the 3,000-problem ex-
ponent compositionality cases (exp, Table 8) with Sympy,
using k candidates for k ∈{1, 10, 50}.
budgets. For instance, in our compositionality exp experi-
ments (Table 8), verifying 50 instead of 1 candidate reduces
failures, but not below 90%. Larger search budgets quickly
become impractical to verify: for compositionality exp, the
veriﬁcation time increases substantially, from around 5 min-
utes for 1 candidate to over 2 hours for 50, with worst-case
veriﬁcation time of 41.6 hours (Table 14). Looking ahead,
developing methods that decrease search and veriﬁcation
cost can help to further cover up a subset of model errors,
yet improving the underlying model remains a core issue.
7
Related Work
In this work, we study systematic generalization in sequence
models applied to symbolic integration, in terms of robust-
ness, compositionality, and extrapolation, and develop a ge-
netic algorithm for building adversarial problem sets.
Symbolic mathematics and sequence models.
Several
works study extrapolation to longer sequences and larger
digits in synthetic arithmetic and basic mathematics tasks
(Zaremba and Sutskever 2014; Trask et al. 2018; Saxton
et al. 2019; Nogueira, Jiang, and Li 2021). Sequence models
have also been applied to polynomial rewriting (Piotrowski
et al. 2019; Agarwal, Aditya, and Goyal 2021), and differ-
ential system stability (Charton, Hayat, and Lample 2021).
For symbolic integration, Davis (2019) argue that the neural
sequence integrator’s test performance should be qualiﬁed,
though without an empirical demonstration. These critiques
motivate our focus on the neural sequence integrator (Lam-
ple and Charton 2019), whose performance we characterize
and empirically study in terms of systematic generalization.
Systematic generalization.
Several works identify difﬁ-
culties with modern methods on synthetic tasks (e.g. Lake
and Baroni (2018); Bahdanau et al. (2019); Hupkes et al.
(2020); Kim and Linzen (2020)) and machine translation
(Raunak et al. 2019), with a focus on compositionality and
extrapolation. Some methods address systematicity with in-
ductive biases in model structure (Andreas et al. 2016; Bah-
danau et al. 2019), and others through the data (Hill et al.
2020; Andreas 2020) or learning procedure (Lake 2019;
Vani et al. 2021). We focus on systematic generalization de-
ﬁciencies in a state-of-the-art model in a new setting – sym-
bolic integration – with additional aspects of generalization.
Robustness and adversaries in sequence models.
Sev-
eral works study robustness in NLP, including classiﬁcation
(Tu et al. 2020), word substitutions (Jia et al. 2019), domain
shift in QA (Kamath, Jia, and Liang 2020) or topic distri-
butions (Oren et al. 2019). Several methods ﬁnd adversarial
examples in NLP (Morris et al. 2020). Alzantot et al. (2018)
use genetic algorithms in a classiﬁcation setting, while we
consider generation. Michel et al. (2019) constrain input se-
quences to be similar and use a gradient-based attack to
swap tokens. We face a non-differentiable cost and generate
large collections of failures with a wide class of mutations.
8
Conclusion
We study generalization in symbolic mathematics using the
predominant modeling paradigm: a large-scale transformer
trained with maximum likelihood. We ﬁnd deﬁciencies that
are not captured by test accuracy, including brittleness to
small perturbations, difﬁculty composing known solutions,
and gaps in the training distribution. We offer speculations
based on our results. Due to the large space of equations,
practical empirical distributions do not provide a dense sam-
pling of individual problem types (e.g. k1 cos(k2x)), and
each empirical sample contains shared biases from the un-
derlying data generator (e.g. integer values, lengths). Thus,
sparse test sets do not adequately measure systematic gen-
eralization. From a learning perspective, generic networks
trained with SGD do not necessarily favor the simplest hy-
pothesis to explain the data; thus a sparse training set yields
an underconstrained hypothesis space, with hypotheses that
do not strongly generalize (e.g. Table 5), causing behavior
that breaks simple rules (e.g. adhering to a template or fol-
lowing the sum rule). We suspect that inductive biases– e.g.
encoded through the training distribution, architectural com-
ponents, or learning algorithm– are needed to narrow the hy-
potheses to those that strongly generalize.
References
Agarwal, V.; Aditya, S.; and Goyal, N. 2021. Analyzing the
Nuances of Transformers’ Polynomial Simpliﬁcation Abili-
ties. arXiv:2104.14095.
Agrawal, A.; Batra, D.; and Parikh, D. 2016. Analyzing the
Behavior of Visual Question Answering Models. In Pro-
ceedings of the 2016 Conference on Empirical Methods in
Natural Language Processing, 1955–1960. Austin, Texas:
Association for Computational Linguistics.
Alzantot, M.; Sharma, Y.; Elgohary, A.; Ho, B.-J.; Srivas-
tava, M.; and Chang, K.-W. 2018. Generating Natural Lan-
guage Adversarial Examples. In Proceedings of the 2018
Conference on Empirical Methods in Natural Language
Processing, 2890–2896. Brussels, Belgium: Association for
Computational Linguistics.
Andreas, J. 2020. Good-Enough Compositional Data Aug-
mentation. In Proceedings of the 58th Annual Meeting of
the Association for Computational Linguistics, 7556–7566.
Online: Association for Computational Linguistics.
Andreas, J.; Rohrbach, M.; Darrell, T.; and Klein, D. 2016.
Neural module networks. In Proceedings of the IEEE Com-
puter Society Conference on Computer Vision and Pattern
Recognition. ISBN 9781467388504.

Bahdanau, D.; Murty, S.; Noukhovitch, M.; Nguyen, T. H.;
De Vries, H.; and Courville, A. 2019. Systematic general-
ization: What is required and can it be learned? In 7th In-
ternational Conference on Learning Representations, ICLR
2019.
Beltagy, I.; Lo, K.; and Cohan, A. 2019. SciBERT: A Pre-
trained Language Model for Scientiﬁc Text.
In Proceed-
ings of the 2019 Conference on Empirical Methods in Nat-
ural Language Processing and the 9th International Joint
Conference on Natural Language Processing (EMNLP-
IJCNLP), 3615–3620. Hong Kong, China: Association for
Computational Linguistics.
Charton, F.; Hayat, A.; and Lample, G. 2021.
Learn-
ing advanced mathematical computations from examples.
arXiv:2006.06462.
Davis, E. 2019.
The Use of Deep Learning for Sym-
bolic Integration: A Review of (Lample and Charton, 2019).
arXiv:1912.05752.
Gardner, M.; Artzi, Y.; Basmov, V.; Berant, J.; Bogin, B.;
Chen, S.; Dasigi, P.; Dua, D.; Elazar, Y.; Gottumukkala, A.;
Gupta, N.; Hajishirzi, H.; Ilharco, G.; Khashabi, D.; Lin, K.;
Liu, J.; Liu, N. F.; Mulcaire, P.; Ning, Q.; Singh, S.; Smith,
N. A.; Subramanian, S.; Tsarfaty, R.; Wallace, E.; Zhang,
A.; and Zhou, B. 2020. Evaluating Models’ Local Decision
Boundaries via Contrast Sets. In Findings of the Association
for Computational Linguistics: EMNLP 2020, 1307–1323.
Online: Association for Computational Linguistics.
Henighan, T.; Kaplan, J.; Katz, M.; Chen, M.; Hesse, C.;
Jackson, J.; Jun, H.; Brown, T. B.; Dhariwal, P.; Gray, S.;
Hallacy, C.; Mann, B.; Radford, A.; Ramesh, A.; Ryder, N.;
Ziegler, D. M.; Schulman, J.; Amodei, D.; and McCandlish,
S. 2020. Scaling Laws for Autoregressive Generative Mod-
eling. ArXiv, abs/2010.14701.
Hill, F.; Lampinen, A.; Schneider, R.; Clark, S.; Botvinick,
M.; McClelland, J. L.; and Santoro, A. 2020. Environmen-
tal drivers of systematicity and generalization in a situated
agent. In International Conference on Learning Represen-
tations.
Holtzman, A.; Buys, J.; Du, L.; Forbes, M.; and Choi, Y.
2020. The Curious Case of Neural Text Degeneration. In
International Conference on Learning Representations.
Hupkes, D.; Dankers, V.; Mul, M.; and Bruni, E. 2020. Com-
positionality Decomposed: How do Neural Networks Gen-
eralise? Journal of Artiﬁcial Intelligence Research.
Jia, R.; Raghunathan, A.; G¨oksel, K.; and Liang, P. 2019.
Certiﬁed Robustness to Adversarial Word Substitutions. In
Proceedings of the 2019 Conference on Empirical Meth-
ods in Natural Language Processing and the 9th Interna-
tional Joint Conference on Natural Language Processing
(EMNLP-IJCNLP), 4129–4142. Hong Kong, China: Asso-
ciation for Computational Linguistics.
Kamath, A.; Jia, R.; and Liang, P. 2020. Selective Question
Answering under Domain Shift. In Proceedings of the 58th
Annual Meeting of the Association for Computational Lin-
guistics, 5684–5696. Online: Association for Computational
Linguistics.
Kim, N.; and Linzen, T. 2020.
COGS: A Compositional
Generalization Challenge Based on Semantic Interpretation.
In Proceedings of the 2020 Conference on Empirical Meth-
ods in Natural Language Processing (EMNLP), 9087–9105.
Online: Association for Computational Linguistics.
Lake, B.; and Baroni, M. 2018. Still Not Systematic After
All These Years: On the Compositional Skills of Sequence-
To-Sequence Recurrent Networks. Iclr2018.
Lake, B. M. 2019. Compositional generalization through
meta sequence-to-sequence learning. In Advances in Neural
Information Processing Systems.
Lample, G.; and Charton, F. 2019. Deep learning for sym-
bolic mathematics. arXiv preprint arXiv:1912.01412.
Michel, P.; Li, X.; Neubig, G.; and Pino, J. 2019. On Evalua-
tion of Adversarial Perturbations for Sequence-to-Sequence
Models.
In Proceedings of the 2019 Conference of the
North American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies, Volume
1 (Long and Short Papers), 3103–3114. Minneapolis, Min-
nesota: Association for Computational Linguistics.
Morris, J.; Liﬂand, E.; Yoo, J. Y.; Grigsby, J.; Jin, D.; and Qi,
Y. 2020. TextAttack: A Framework for Adversarial Attacks,
Data Augmentation, and Adversarial Training in NLP. In
Proceedings of the 2020 Conference on Empirical Methods
in Natural Language Processing: System Demonstrations,
119–126. Online: Association for Computational Linguis-
tics.
Nogueira, R.; Jiang, Z.; and Li, J. J. 2021.
Investigating
the Limitations of the Transformers with Simple Arithmetic
Tasks. ArXiv, abs/2102.13019.
Oren, Y.; Sagawa, S.; Hashimoto, T. B.; and Liang, P.
2019.
Distributionally Robust Language Modeling.
In
Proceedings of the 2019 Conference on Empirical Meth-
ods in Natural Language Processing and the 9th Interna-
tional Joint Conference on Natural Language Processing
(EMNLP-IJCNLP), 4227–4237. Hong Kong, China: Asso-
ciation for Computational Linguistics.
Piotrowski, B.; Urban, J.; Brown, C. E.; and Kaliszyk, C.
2019.
Can Neural Networks Learn Symbolic Rewriting?
CoRR, abs/1911.04873.
Raunak, V.; Kumar, V.; Metze, F.; and Callan, J. 2019. On
Compositionality in Neural Machine Translation.
ArXiv,
abs/1911.01497.
Saxton, D.; Grefenstette, E.; Hill, F.; and Kohli, P. 2019.
Analysing Mathematical Reasoning Abilities of Neural
Models. In International Conference on Learning Repre-
sentations.
Trask, A.; Hill, F.; Reed, S.; Rae, J.; Dyer, C.; and Blunsom,
P. 2018. Neural arithmetic logic units. In Advances in Neural
Information Processing Systems.
Tu, L.; Lalwani, G.; Gella, S.; and He, H. 2020. An Em-
pirical Study on Robustness to Spurious Correlations using
Pre-trained Language Models. Transactions of the Associa-
tion for Computational Linguistics, 8: 621–633.
Vani, A.; Schwarzer, M.; Lu, Y.; Dhekane, E.; and Courville,
A. 2021.
Iterated learning for emergent systematicity in

{VQA}. In International Conference on Learning Repre-
sentations.
Vaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.; Jones,
L.; Gomez, A. N.; Kaiser, Ł.; and Polosukhin, I. 2017. At-
tention is all you need. In Advances in Neural Information
Processing Systems.
Wallace, E.; Feng, S.; Kandpal, N.; Gardner, M.; and Singh,
S. 2019.
Universal Adversarial Triggers for Attacking
and Analyzing NLP. In Proceedings of the 2019 Confer-
ence on Empirical Methods in Natural Language Process-
ing and the 9th International Joint Conference on Natural
Language Processing (EMNLP-IJCNLP), 2153–2162. Hong
Kong, China: Association for Computational Linguistics.
Welleck, S.; Kulikov, I.; Kim, J.; Pang, R. Y.; and Cho, K.
2020. Consistency of a Recurrent Language Model With
Respect to Incomplete Decoding.
In Proceedings of the
2020 Conference on Empirical Methods in Natural Lan-
guage Processing (EMNLP), 5553–5568. Online: Associa-
tion for Computational Linguistics.
Zaremba, W.; and Sutskever, I. 2014. Learning to Execute.
CoRR, abs/1410.4615.

Figure 5: Fail@k with a large search-and-verify budget
(500 candidates, beam search) on simple-primitive robust-
ness problems. The model is ‘brittle’ in that the top of its
ranked solution list is often made up of incorrect solutions;
e.g. the top-ranked solution is incorrect around 25% of the
time. However, the correct solution often exists within the
model’s top 500 predictions on these problems.
Figure 6: Correct candidate’s ranking out of 500 candidates
(beam search) on exp-primitive robustness problems.
A
Additional Results
A.1
Large Search Budgets
We study the simple-primitive robustness problems (from
Table 2, top), as these problems resulted in a small num-
ber of Sympy timeouts, allowing for scaling of veriﬁcation.
We increase the beam-width to 500 candidates, and show
Fail@k for k ∈{1, 10, 50, 200, 500} in Figure 5. The top
of the solution list remains brittle with the larger beam size:
that is, with beam size 500 the top-ranked solutions are still
frequently incorrect, supporting the ﬁndings in Table 13.
However, the correct solution often exists deeper into the
ranked list, i.e. Fail@k decreases as k increases, ranging
from 0.1 Fail@500 for cos to 3.7 Fail@500 for tan.
As an illustration, Figure 6 shows the ranking of the correct
solution for exp-robustness problems that had a solution in
the top-500 beam candidates.
A.2
Alternate Decoding Strategies
So far, we have used beam search, a deterministic search
that approximately searches for the highest scoring output
sequence. An alternative approach is decoding a set of se-
quences {ˆy1, . . . , ˆyk} by sampling recursively from model-
Figure 7: Comparing Fail@k using sampling vs. beam
search on exp-robustness. Beam search outperforms sam-
pling, which we attribute to better exploration with beam
search: namely, beam search returns unique candidates,
while sampling returns many duplicates in this setting.
Iters Len Nodes Depth 1-term 2-term 3-term
General
3
15.4
7.3
3.6
64.8
24.7
10.5
General-Trig
3
21.8
11.1
4.9
55.7
36.6
7.7
Robust-Trig
4
16.4
7.7
4.5
69.9
30.1
0.0
Robust-Poly
4
23.6
12.6
3.9
17.0
24.1
43.7
Distance
3
30.0
15.0
5.4
32.6
34.2
20.2
Length-10
61 11.1
5.3
3.1
91.3
8.6
0.1
Length-20
27 21.4
10.0
4.2
58.0
35.5
6.4
Length-40
26 40.6
16.7
5.5
13.5
49.3
34.3
Table 15: Summary of the archives discovered with SAGGA
for the target failure type shown on the left. Iters gives the
number of SAGGA iterations needed to reach 1,000 fail-
ures, and 5,000 failures for the Length-X settings. We use
the number of + operations plus 1 as a rough proxy for the
number of ‘terms’ in a problem; e.g. x2 + 2 has 2 terms.
dependent per-token distributions, y(i)
t
∼q(yt|y<t, x, pθ),
where each ˆyi = (y(i)
1 , . . . , y(i)
Ti ). We use the common ap-
proach of temperature sampling.
Figure 7 shows Fail@k rates for sampling 500 candi-
dates at temperatures {0.6, 0.8, 1.0}, and beam search with
500 candidates, for exp-robustness problems (other simple-
primitives gave similar results). Beam search outperforms
sampling, which we attribute to better exploration with beam
search: namely, beam search guarantees unique candidates,
while sampling returns many duplicates in this setting (here,
only 14 unique sequences out of 500 samples).
A.3
SAGGA – Quantitative Summary
Table 15 provides a quantitative summary of the archives
discovered with SAGGA. Figure 8 shows the rate at which
SAGGA ﬁlls its archive with failure cases under different
mutation strategies and ﬁtness functions.

Figure 8:
Cumulative failures found per iteration of
SAGGA, for various mutation and ﬁtness settings.
B
Additional Experiment Details
B.1
Experimental Setup
We use the implementation and pre-trained model from
Lample and Charton (2019) for all of our experiments,
speciﬁcally the FWD+BWD+IBP model which obtained top-
10 accuracies of 95.6%, 99.5%, and 99.6% on their pub-
licly available test sets.5 Our evaluation is based on their
code provided in beam integration.ipynb. We use
their utilities for inputs and outputs, and by default use beam
search with beam size 10. When computing Fail@50 we use
beam size 50. Following Lample and Charton (2019), we
use Sympy to check whether the derivative of a prediction is
equal to the original problem, simplify(derivative
- f) == 0. We generously count the prediction as correct
if a timeout occurs. Since Sympy’s simplify function is
imperfect, there is a possibility of false negatives, which is
an inherent limitation of verifying whether a solution is cor-
rect. However, an answer that is not feasibly veriﬁable in a
search-and-verify setting is incorrect for practical purposes.
In preliminary experiments, we found that additionally sim-
plifying the derivative and the function before subtracting
tended to reduce timeouts, and found that Sympy’s ability to
simplify hyperbolic functions (e.g. sinh, cosh) was limited,
so we discard problems with hyperbolic functions from our
analysis. Future work could verify with additional libraries,
and we release all predictions for inspection.
B.2
Robustness
Test accuracy does not imply robustness.
For XN1 we
sample 100 successful validation problems f and 10 values
of k, while for XN2 we sample 1000 successful validation
problems.
B.3
Compositionality
Validation problems.
Fail@50 valid had abnormally
many timeouts compared to the other experiments; for this
setting only we do not consider a timeout as correct.
B.4
Extrapolation
More details of integer distribution.
As a rough pic-
ture of integer values in the training distribution, we sam-
ple 100,000 sequences from each of the FWD and BWD train
5https://github.com/facebookresearch/SymbolicMathematics/,
commit 4596d07.
sets, convert them to Sympy, and count Sympy equation tree
nodes of type Integer. We ﬁnd that 99.4% of the posi-
tive integers were in the range [1, 100), and that other mag-
nitude buckets were non-empty but sparsely represented –
e.g. [100, 200) had 0.2%, and [1000, 2000) had 0.096% ,and
[10000, 20000) had 0.005% of the positive integers in the
problem sample.
B.5
Runtime vs. Candidates
We generously stop early if a successful candidate is found,
and use a 1-second timeout for Sympy; thus the results are a
lower-bound on the runtime. In the worst case, for N prob-
lems, without early stopping and with a t-second timeout,
veriﬁcation takes O(ktN) seconds, e.g. 41.6 hours to verify
50 candidates on 3,000 problems with a 1 second timeout.
C
SAGGA
Default ﬁtness.
Unless otherwise noted, we use a ﬁtness
that favors short (and hence interpretable) problems,
F(fθ, x) = m(x, fθ(x; 1)) · 1
|x|,
(6)
which is positive when the model returns an incorrect inte-
gral of problem x, and higher for shorter problems.
Mutations.
A mutation transforms a problem’s equation
tree; i.e. h(Tx) →T ′ where Tx is the equation tree of prob-
lem x. SAGGA supports mutations for internal tree nodes
and leaf nodes.
The internal node mutations replace a node vi with:
• Constant: an integer k ∼U(vmin, vmax).
• Symbol: x.
• Operation: v′
i ∼{+, ∗, ∗∗}
• Add-arg: v′
i(w1:j, wj+1), where w1:j are the previous ar-
guments to vi and wj+1 is a random simple operation
(see below). For instance, sum(1, 2) →sum(1, 2, 3x2).
If vi is a one-argument function, this mutation adds a new
argument via a sum, e.g. exp(1) →exp(1 + 3x2).
The leaf node mutations replace a node vi with:
• Constant: an integer k ∼U(vmin, vmax).
• Symbol: kx where k ∼U(vmin, vmax).
• Simple-op: random simple operation (see below).
Each random simple operation is of the form k1 ◦xk
2,
where k1 ∼U(vmin, vmax), ◦∼{∗, ∗∗, /}, k2 ∼{1, 2}.
For instance, 3x2, 5/x.
Default settings.
Unless otherwise noted, we run SAGGA
with the following default settings:
• Beam size: 10
• Evaluation m(x, ·): Fail@1
• Seed size: 100
• Generation size: 1000
• Seed selection: k-means, k = 10
• Fitness threshold τ: 0.01
• Target archive size: 1000

• Integer perturbation range vmin, vmax: [-1000, 1000]
• Mutations: all
• Seed problems: {1,
x,
x + 1,
x2 + x + 1}
Each generation (iteration) takes around 4 minutes on a sin-
gle Quadro RTX 8000 GPU.
C.1
Robustness.
Settings.
• Integer perturbation range vmin, vmax: [-100, 100]
• Mutations: only Constant mutations.
Seeds.
Polynomial robustness:
Xpoly = {1, 2x, 2/x, 2x + 1, 2/x + 1,
2x2 + 2x + 1, 2x2 + 2/x + 1,
2x3 + 2x2 + 1,
2x42 + 2x3 + 2x2 + 1}
Trigonometric robustness:
Xtrig = {17 cos(83x), 17 cos(83x) + 1,
34 sin(77x), 34 sin(77x) + 1
2 cos(2x) + 2x, 2 cos(2x) + 2x + 1,
2 sin(2x) + 2x, 2 sin(2x) + 2x + 1
2 sin(2x) cos(2x)}
In these experiments, the structure of the seeds remains
ﬁxed and the integers are varied. The seed elements with
non-trivial integers were selected based on the manual
neighborhood experiments. Note that this simply accelerates
the experiment, as the algorithm could discover these.
C.2
Out-of-distribution.
General failures. We run SAGGA in two settings. The ﬁrst
is with default settings (see above). The second biases the
search towards trigonometric functions, using the seed,
Xtrig-general = {2 cos(2x), 2 cos(2x) + 1
2 sin(2x), 2 sin(2x) + 1
2 cos(2x) + 2x, 2 cos(2x) + 2x + 1,
2 sin(2x) + 2x, 2 sin(2x) + 2x + 1
2 sin(2x) cos(2x)}
and set the default ﬁtness to zero unless the problem contains
a trigonometric function.
Target lengths. We use the ﬁtness,
F(fθ, x) = m(x, fθ(x; 1)) ·
1
|x −ℓ|,
(7)
where ℓis the target length.
To more clearly compare growth rates, compared to the
other experiments we use a smaller seed size of 50 and
smaller generation size of 300, and generate 5,000 failures
rather than 1,000, resulting in more iterations per algorithm
setting.

x
hyp simpliﬁed
derivative
difference
-103
-103*x
-103
0
-104
-48*x - 625
-48
56
-136
-128*x
-128
8
-33
-31*x - 256
-31
2
2*x**(42)+21
x*(2*x**42 + 903)/43
2*x**42 + 21
0
2*x**(42)+22
2*x*(x**42 + 469)/43
2*x**42 + 938/43
-8/43
2*x**(42)+28
2*x*(x**42 + 614)/43
2*x**42 + 1228/43
24/43
2*x**(42)+68
2*x*(x**42 + 1502)/43
2*x**42 + 3004/43
80/43
-47 + 2/x - 2/x**70
-47*x + 2*log(x) + 2/(69*x**69)
-47 + 2/x - 2/x**70
0
-47 + 2/x - 2/x**71
-47*x + 2*log(x) + 2/(35*x**70)
-47 + 2/x - 4/x**71
-2/x**71
-47 + 2/x - 31/x**71
-47*x + log(x**2) + x**(-60)
-47 + 2/x - 60/x**61
(31 - 60*x**10)/x**71
-71 + 36/x - 2/x**71
-71*x + 36*log(x) + 1/(17*x**70)
-71 + 36/x - 70/(17*x**71)
-36/(17*x**71)
13*cos(18*x)
13*sin(18*x)/18
13*cos(18*x)
0
13*cos(19*x)
sin(19*x)
19*cos(19*x)
6*cos(19*x)
13*cos(83*x)
sin(83*x)/17
83*cos(83*x)/17
-138*cos(83*x)/17
17*cos(47*x)
sin(47*x)
47*cos(47*x)
30*cos(47*x)
13*cos(82*x) - 59
-59*x + 13*sin(82*x)/82
13*cos(82*x) - 59
0
13*cos(83*x) - 59
-59*x + sin(83*x)/13
83*cos(83*x)/13 - 59
-86*cos(83*x)/13
17*cos(37*x) - 49
-49*x + sin(37*x)
37*cos(37*x) - 49
20*cos(37*x)
17*cos(41*x) - 45
-45*x + sin(41*x)
41*cos(41*x) - 45
24*cos(41*x)
10*sin(45*x)*cos(2*x)
-5*cos(43*x)/43 - 5*cos(47*x)/47
5*sin(43*x) + 5*sin(47*x)
0
10*sin(47*x)*cos(2*x)
-255*cos(45*x)/2201 - 215*cos(49*x)/2201
11475*sin(45*x)/2201 + 10535*sin(49*x)/2201
470*sin(45*x)/2201 - 470*si...
10*sin(90*x)*cos(2*x)
-5*cos(43*x)/44 - 5*cos(47*x)/46
215*sin(43*x)/44 + 235*sin(47*x)/46
215*sin(43*x)/44 + 235*sin(47...
19*sin(90*x)*cos(2*x)
cos(2*x)**2*cos(90*x)/2
-2*sin(2*x)*cos(2*x)*cos(90*x) - 45*sin(90*x)*...
-(43*sin(88*x)/2 + 19*sin...
-x**2 + x + log(4)*tan(x)
-x**3/3 + x**2/2 - log(4)*log(cos(x))
-x**2 + x + log(4)*sin(x)/cos(x)
0
-x**2 + x + log(4)*tan(17*x**2)
-x**3/3 + x**2/2 + log(2)*log(cos(17*x**2)...
-x**2 + 2*x*log(2)*sin(17*x**2)/cos(17*x**2) + x
(x - 1)*log(4)*tan(17*x**2)
-x**2 + x + log(4)*tan(2*x**2)
-x**3/3 + x**2/2 + log(2)*log(cos(2*x**2)...
-x**2 + 4*x*log(2)*sin(2*x**2)/cos(2*x**2) + x
(2*x - 1)*log(4)*tan(2*x**2)
-x**2 + x + log(4)*tan(63/x**2)
-x**3/3 + x**2/2 - log(2)*log(cos(63/x**2)...
-x**2 + x + 252*log(2)*sin(63/x**2)/(x**3*cos(...
(126 - x**3)*log(4)*tan(63/...
sqrt(3*x + 3) - 2
-2*x + 2*sqrt(3)*(x + 1)**(3/2)/3
sqrt(3)*sqrt(x + 1) - 2
0
sqrt(-86**(x**2) + 62/x) - 40
-40*x + acosh(86**(-x**2/2)/x)
-40 + (-86**(-x**2/2)*log(86) - 86**(-x**2/2)/...
-sqrt(-86**(x**2) + 62/x) ...
sqrt(14 + 62/x) + 4
(49*x**(3/2) + 217*sqrt(x) + sqrt(7*x + 31...
(147*sqrt(x)/2 + (28 + sqrt(749)/(sqrt(x)*sqrt...
(-x*(7*x + 31)**(5/2)*sqrt(2...
sqrt(14 + 62/x) - 2
(49*x**(3/2) + 217*sqrt(x) + (-14*x + 31*...
(147*sqrt(x)/2 + (-14 + sqrt(854)/(2*sqrt(x)*s...
(x*(7*x + 31)**(5/2)*sqrt(6...
tan(exp(2))/(18*x)
log(x)*tan(exp(2))/18
tan(exp(2))/(18*x)
0
tan(26*x + 2 + exp(2))/(18*x**75)
[add, mul, div, INT-, 1, INT+, 1, 5, 1, 2, mul...
–
–
tan(exp(-9504*x**2))/(18*x)
-log(cos(exp(-9504*x**2))**(-2))/18144
44*x*exp(-9504*x**2)*sin(exp(-9504*x**2))/...
44*x*exp(-9504*x**2)*sin(...
tan(exp(-96*x))/(18*x)
-log(cos(exp(-96*x))**(-2))/1728
exp(-96*x)*sin(exp(-96*x))/(9*cos(exp(-96*x)))
(2*x - exp(96*x))*exp(-9...
Table 16: SAGGA robustness. We show the problem x, the simpliﬁed prediction from the neural sequence integrator, its deriva-
tive, and the derivative’s difference with x. The prediction is incorrect when the difference is not zero. When the model’s
prediction does not parse successfully, we show its unparsed inﬁx tokens. We show a nearby problem that the model gets
correct in bold (either hand-selected or a validation example); all other problems are failures discovered by SAGGA.

x
hyp simpliﬁed
derivative
difference
0
30**x
30**x/log(30)
30**x
0
1
119**x
119**(x - 1)
119**(x - 1)*log(119)
119**(x - 1)*(-119 + log(119))
2
132**x
132**x/(1 + log(132))
132**x*log(132)/(1 + log(132))
-132**x/(1 + log(132))
3
136**x
exp(x*log(136))
exp(x*log(136))*log(136)
-136**x + exp(x*log(136))*log(136)
4
-100*x**x
-50*x**2
-100*x
-100*x + 100*x**x
5
-149*x**x
-149*x**2/2
-149*x
-149*x + 149*x**x
6
-151*x**x
-151*x**2/2
-151*x
-151*x + 151*x**x
7
158*x**(x**2) + 611
158*x**2/sqrt(x**2 + 1) + 611*x
-158*x**3/(x**2
+
1)**(3/2)
+
316*x/sqrt(x**2 + 1) + 611
-158*x**3/(x**2
+
1)**(3/2)
+
316*x/sqrt(x**2 + 1) - 158*x**(x**2)
8
256*x**(x**2) + 191
x*(191*x**2 + 256*x**(x**2) + 191)/(x**2 + 1)
-2*x**2*(191*x**2 + 256*x**(x**2)
+ 191)/(x**2 + 1)**2 + x*(382*x +
256*x**(x**2)*(2*x*log(x) + x))/(x**2
+ 1) + (191*x**2 + 256*x**(x**2) +
191)/(x**2 + 1)
512*x**(x**2
+
2)*(x**2*log(x)
+
log(x) - 1)/(x**4 + 2*x**2 + 1)
9
332*x**(x**2) + 559
x*(559*x**2 + 332*x + 559)/(x**2 + 1)
-2*x**2*(559*x**2
+
332*x
+
559)/(x**2 + 1)**2 + x*(1118*x +
332)/(x**2 + 1) + (559*x**2 + 332*x +
559)/(x**2 + 1)
332*(2*x - x**(x**2) - 2*x**(x**2 + 2)
- x**(x**2 + 4))/(x**4 + 2*x**2 + 1)
10
-240**x + 2*cos(2*x)
-exp(x*log(240)) + sin(2*x)
-exp(x*log(240))*log(240)
+
2*cos(2*x)
240**x - exp(x*log(240))*log(240)
11
-398**x + 2*cos(2*x)
-exp(x*log(398)) + sin(2*x)
-exp(x*log(398))*log(398)
+
2*cos(2*x)
398**x - exp(x*log(398))*log(398)
12
-692**x + 2*sin(2*x)
-exp(x*log(692)) - cos(2*x)
-exp(x*log(692))*log(692) + 2*sin(2*x)
692**x - exp(x*log(692))*log(692)
Table 17: SAGGA OOD – g(x)x. We show the problem x discovered by SAGGA, the simpliﬁed prediction from the neural
sequence integrator, its derivative, and the derivative’s difference with x. The prediction is incorrect when the difference is not
zero. For the ﬁrst cluster, we manually found a nearby problem that the model gets correct in bold; thus this cluster can be seen
as a robustness failure. The second two clusters involve xx or xx2 which to our knowledge do not have analytical integrals (e.g.
see https://www.wolframalpha.com/input/?i=integral+of+x**x); these clusters can be seen as exploits.
x
hyp raw
Correct Integral (Wolfram Alpha)
0
169*sin(4*x)/x
169*log(x**2)/8 - 169*cos(4*x)/4
169 Si(4x)
1
-2*sin(42/x)
cos(42/x)/21
−2(−42Ci(42/x) + x sin(42/x))
2
-2*sin(185*x**2)*cos(2*x)
4*sin(2*x)*sin(185*x**2)/3421 + 370*cos(2*x)*cos(185*x**2)/3421
-(Sqrt[Pi/370] (Cos[1/185] FresnelS[Sqrt[2/(185
Pi)] (-1 + 185 x)] + Cos[1/185]
FresnelS[Sqrt[2/(185 Pi)] (1 + 185 x)] -
(FresnelC[Sqrt[2/(185 Pi)] (-1 + 185 x)]
+ FresnelC[Sqrt[2/(185 Pi)] (1 + 185 x)])
Sin[1/185]))
3
357**(x**(2**x)) + 2*sin(2*x)
exp(x*log(2)) - cos(2*x)
No result
4
1/(x**48*(3*x+2)**49)
add, mul, div, INT-, 1, 0, 9, 0, 9, 1, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 5,
INT+, 1, 0, 2, 4, ln, x, add, mul, div, INT+, 1, 0, 9, 0, 9, 1, 9, 9, 9, 9, 9,
9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, INT+, 1, 0, 2, 4, ln, add, div, INT+,
2, INT+, 3, x, mul, INT-, 1, mul, pow, add, mul, INT+, 1, 0, 0, 9, 6, 2,
9, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0
See
https://www.wolframalpha.com/input/?
i=integral+of+1%2F%28x**48*%283*x%2B2%29**49%29
Table 18: SAGGA OOD – exploits. We show the problem x, and the neural sequence integrator’s prediction as either raw preﬁx
tokens or (when possible) in its inﬁx form. All problems are failures discovered by SAGGA.

