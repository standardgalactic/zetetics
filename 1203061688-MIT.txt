Minimal I-MAP MCMC for Scalable Structure
Discovery in Causal DAG Models
by
Raj Agrawal
Submitted to the Department of Electrical Engineering and Computer
Science
in partial fulfillment of the requirements for the degree of
Masters of 
in Electrical Engineering and Computer Science
at the
MASSACHUSETTS INSTITUTE OF TECHNOLOGY
February 2020
@ 2019 Raj Agrawal. All Rights Reserved.
The author here by grants to MIT the permission to reproduce and to
distribute publicly paper and electronic copies of the thesis document in
whole or in part in any medium now known or hereafter created.
Signature redacted
A u th o r ................................................................
Department of Electrical Engineering and Computer Science
Signature redacted 
September 12, 2019
C ertified by .. 
...........................
Tamara Broderick
Associate Professor of Electrical Engineering and Computer Science
Signature redacted 
Thesis Supervisor
C ertified by .... 
.........................
Caroline Uhler
Associate Professor of Electrical Engineering and Computer Science
Signature redacted 
Thesis Supervisor
A ccepted by ... 
........................
MASSACHUSTSL NSTITUTE 
' 
vLeslie A. Kolodziejski
OFTECHNOLOGY
I 
-rofessor of Electrical Engineering and Computer Science
MAR 13 2020 
Chair, Department Committee on Graduate Students
LIBRARIES

MITLibraries
77 Massachusetts Avenue
Cambridge, MA 02139
http://Iibraries.mit edu/ask
DISCLAIMER NOTICE
Due to the condition of the original material, there are unavoidable
flaws in this reproduction. We have made every effort possible to
provide you with the best copy available.
Thank you.
The images contained in this document are of the
best quality available.

2

Minimal I-MAP MCMC for Scalable Structure Discovery in
Causal DAG Models
by
Raj Agrawal
Submitted to the Department of Electrical Engineering and Computer Science
on September 12, 2019, in partial fulfillment of the
requirements for the degree of
Masters of Engineering in Electrical Engineering and Computer Science
Abstract
Learning a Bayesian network (BN) from data can be useful for decision-making or
discovering causal relationships. However, traditional methods often fail in modern
applications, which exhibit a larger number of observed variables than data points. The
resulting uncertainty about the underlying network as well as the desire to incorporate
prior information recommend a Bayesian approach to learning the BN, but the highly
combinatorial structure of BNs poses a striking challenge for inference. The current
state-of-the-art methods such as order MCMC are faster than previous methods
but prevent the use of many natural structural priors and still have running time
exponential in the maximum indegree of the true directed acyclic graph (DAG) of the
BN. We here propose an alternative posterior approximation based on the observation
that, if we incorporate empirical conditional independence tests, we can focus on a
high-probability DAG associated with each order of the vertices. We show that our
method allows the desired flexibility in prior specification, removes timing dependence
on the maximum indegree, and yields provably good posterior approximations; in
addition, we show that it achieves superior accuracy, scalability, and sampler mixing
on several datasets.
Thesis Supervisor: Tamara Broderick
Title: Associate Professor of Electrical Engineering and Computer Science
Thesis Supervisor: Caroline Uhler
Title: Associate Professor of Electrical Engineering and Computer Science
3

4

Contents
1 
Introduction 
11
2 Preliminaries and Related Work 
15
2.1 
Bayesian Networks ............................ 
15
2.2 
Bayesian Inference for DAG models . . . . . . . . . . . . . . . . . . .
16
3 Minimal I-MAP MCMC 
19
3.1 
Reduction to the Space of Minimal I-MAPs 
. . . . . . . . . . . . . .
19
3.2 
Bayesian Inference on Minimal I-MAPs . . . . . . . . . . . . . . . . .
22
3.3 
Minimal I-MAP MCMC . . . . . . . . . . . . . . . . . . . . . . . . .
24
4 Experiments 
27
4.1 
Prior and Likelihood . . . . . . . . . . . . . . . . . . . . . . . . . . .
27
4.2 
Mixing and Convergence . . . . . . . . . . . . . . . . . . . . . . . . .
28
4.3 
ROC Performance. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
31
4.4 
Time and Memory Complexity. . . . . . . . . . . . . . . . . . . . . .
32
4.5 
Incorporating Priors . . . . . . . . . . . . . . . . . . . . . . . . . . .
32
5 Concluding Remarks 
35
A Appendix 
37
A.1 CI Testing for Gaussian Data . . . . . . . . . . . . . . . . . . . . . .
37
A.2 Update Algorithm. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
37
A.3 Discussion of the Assumptions . . . . . . . . . . . . . . . . . . . . . .
38
5

A .4 Proofs . . . . . . . . . . . . . . . . . . . .
.
A.4.1 Proof of Lemma 3.1.3 . . . . . . . .
.
A.4.2 Proof of Theorem 3.1.2 . . . . . . .
.
A.4.3 Proof of Proposition 3.3.1 
. . . . .
.
A.4.4 Proof of Proposition A.4.1 . . . . .
.
A.4.5 Proof of Proposition 3.3.2 . . . . .
.
A.5 Justification for restricting the prior space 
.
A.6 Prior Specification on Topological Orderings
A.7 Path and Order Priors . . . . . . . . . . .
.
A.8 Additional Experiments and Plots . . . . .
.
6
. . . . . . . . . .
39
. . . . . . . . . .
39
. . . . . . . . . .
40
. . . . . . . . . .
42
. . . . . . . . . .
42
. . . . . . . . . .
43
. . . . . . . . . .
43
. . . . . . . . . .
44
. . . . . . . . . .
45
. . . . . . . . . .
47

List of Figures
4-1 
From left to right, the columns represent the n = 100, n = 1000, and
Dream4 datasets, respectively. From top to bottom, the rows correspond
to minimal I-MAP (minIMAP), order, and partition MCMC. The black
dotted line corresponds to runs seeded with the true permutation.
The purple and brown lines correspond to runs seeded with a random
permutation and the red and green curves represent runs seeded with
M M H C .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
29
4-2 
The top row and bottom row correspond to the n = 100 and n = 1000
datasets respectively. Each point represents the posterior probability
of a directed feature estimated by different seeded runs of MCMC. We
consider all possible combinations of random and MMHC seeded runs
for completeness. Red (x), blue (o), and brown (+) correspond to
minIMAP, order, and partition MCMC respectively. . . . . . . . . . .
30
4-3 
Average iteration times for different sized networks. The times are
relative to the average iteration time for p = 25 nodes; c denotes the
slope of the dotted lines and estimates the computational complexity
O (pC). 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
33
A-i The top ROC curves represent recovery of undirected features and the
bottom for compelled features. From left to right, the plots correspond
to the Dream4, n=100, and n=1000 datasets. 
. . . . . . . . . . . . .
46
7

A-2 The network on the left is taken from Mukherjee and Speed [2008].
The ROC plot on the right corresponds to the recovery of directed
edges. Path and order refers to a prior that takes both path and order
information into account as specified in Section 4.5. For order and
partition MCMC, only order information can be used in the prior as
discussed in Section 4.5. . . . . . . . . . . . . . . . . . . . . . . . . .
48
8

List of Tables
4.1 
AUROC results by dataset and method. NBC, PBC, and FBC stand
for no, partial, and full bias correction. The columns represent AUROC
values for undirected and compelled features respectively. . . . . . . .
32
4.2 
AUROC results for directed edge recovery in the protein network in
Figure A -2. 
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
34
A.1 
Average correlation of directed features between runs seeded with the
true network and runs seeded with MMHC from two hundred randomly
generated DAGs with p = 30 nodes. Higher is better. . . . . . . . . .
47
9

10

Chapter 1
Introduction
Bayesian networks (BNs)-or probabilistic graphical models based on directed acyclic
graphs (DAGs)-form a powerful framework for representing complex dependencies
among random variables. Learning BNs among observed variables from data has proven
useful in decision tasks-such as credit assessment or automated medical diagnosis-as
well as discovery tasks-such as learning gene regulatory networks [Spirtes et al., 2000,
Friedman et al., 2000, Pearl, 2009, Robins et al., 2000, Khashei and Mirahmadi, 2015].
When the number of data points is much larger than the number of observed variables,
a point estimate of the BN can be found using constraint-based or greedy search
methods [Spirtes et al., 2000, Chickering, 2002, Tsamardinos et al., 2006]. However,
in many applications, the number of observed variables is larger than the number of
data points. In this case, many BNs may agree with the observed data. A Bayesian
approach offers a natural weighting scheme across BNs via the Bayesian posterior
distribution. This weighting propagates coherently to point estimates and uncertainty
quantification for structural features of the BN (such as the presence of certain directed
edges). Moreover, a Bayesian approach allows the incorporation of prior information,
which is common in applications of interest Mukherjee and Speed [2008].
Unfortunately, due to the combinatorial explosion of the number of DAGs, exact
posterior computation is intractable for graphs with more than thirty nodes [Koivisto
and Sood, 2004, Tian and He, 2009]. This motivated Madigan and York [1995]
to propose structure MCMC, an approximate method using Markov chain Monte
11

Carlo (MCMC). To overcome the slow mixing of structure MCMC and its variants
[Grzegorczyk and Husmeier, 2008], Friedman and Koller [2003] introduced order
MCMC. This algorithm achieves significantly faster mixing by running a Markov chain
not over DAGs, but in the reduced space of permutations (i.e., orders) of the vertices
of the DAG. However, order MCMC requires a particular (often undesirable) form
for the prior on DAGs, and its iterations suffer from exponential time and memory
complexity in the maximum indegree of the true DAG. Heuristic fixes for scalability
exist [Friedman and Koller, 2003], but their statistical costs are unclear.
In this paper, we propose a new method to leverage the improved mixing of MCMC
moves in the permutation space; in addition, our approach comes with theoretical
guarantees on approximation quality and allows more realistic DAG priors. The key
new ingredient is an observation by Verma and Pearl [1992] that has been used for
causal inference in the frequentist setting [Mohammadi et al., 2018, Raskutti and Uhler,
2013]; namely, if we have access to conditional independence (CI) tests, we can associate
each permutation with a unique DAG known as the minimal I-MAP (independence
map). This is the sparsest DAG that is consistent with a given permutation and
Markov to a given set of CI relations. We prove that the vast majority of posterior
mass is concentrated on the corresponding reduced space of DAGs, and we call our
method minimal I-MAP MCMC.
We start in Section 2 by reviewing BNs and Bayesian learning of BNs. We show
how to reduce to the space of minimal I-MAPS in Section 3.1 and theoretically bound
the posterior approximation error induced by this reduction. In Section 3.2, we show
by an empirical Bayes argument that sufficiently accurate CI tests allow using what
amounts to our original prior and likelihood on DAGs but, crucially, restricted to the
space of minimal I-MAPs. Thus, we demonstrate that our method allows arbitrary
prior structural information. In Section 3.3, we present an MCMC approach for
sampling according to this minimal I-MAP model and provide intuition for why it
exhibits good mixing properties. Moreover, we prove that, for p the number of observed
variables and k the maximum indegree of the true DAG, our method takes O(p 2
)
memory and O(p4 ) time per MCMC iteration (vs. O(pk+1) time and memory for order
12

MCMC). In Section 4 we empirically compare our model to order MCMC and partition
MCMC [Kuipers and Moffa, 2017], the state-of-the-art version of structure MCMC.
In experiments we observe O(p) time scaling for our method, and we demonstrate
better mixing and ROC performance for our method on several datasets.
13

14

Chapter 2
Preliminaries and Related Work
2.1 
Bayesian Networks
Let G = ([p, A) be a directed acyclic graph (DAG) consisting of a collection of vertices
[p] 
{1, ... 
, p} and a collection of arrows (i.e., directed edges) A, where (i, j) E A
represents the arrow i -+ j. A DAG induces a partial order 2 on the vertices [p]
through (i, j) E A if and only if i 2 j. Let Sp be the symmetric group of order p. A
topological order of a DAG is a permutation 7r E S, such that for every edge (i, j) c A,
i j in 7r; thus it is a total order that extends (i.e., is consistent with) the partial
order of the DAG, also known as a linear extension of the partial order.
A Bayesian network is specified by a DAG G and a corresponding set of edge
weights 0 c RJAI. Each node in G is associated with a random variable Xi. Under the
Markov Assumption, which we assume throughout, each variable Xi is conditionally
independent of its nondescendants given its parents, i.e., the joint distribution factors
as ]1pt P(Xi | PaG(Xi)), where PaG(Xi) denotes the parents of node Xi [Spirtes et al.,
2000, Chapter 4]. This factorization implies a set of conditional independence (CI)
relations that can be read off from the DAG G by d-separation. The faithfulness
assumption states that the only CI relations realized by P are those implied by
d-separation in G [Spirtes et al., 2000, Chapter 4]. DAGs that share the same d-
separation statements make up the Markov equivalence class of a DAG [Lauritzen,
1996, Chapter 3]. The Markov equivalence class of a DAG can be uniquely represented
15

by its CP-DA G, which places arrows on those edges consistent across the equivalence
class Andersson et al. [1997]. The arrows of the CP-DAG are called compelled edges
and represent direct causal effects Andersson et al. [1997].
2.2 
Bayesian Inference for DAG models
In many applications, the goal is to recover a function f(G) of the underlying causal
DAG G given n i.i.d. samples on the nodes, which we denote by D = {Xi 
: m E
[n], i c [p]}. For example, we might ask whether a directed edge (i, j) is in A, or
we might wish to discover which nodes are in the Markov blanket of a node i. In
applications where n is large relative to p, a point estimate of G-and thereby of
f(G)-suffices from both a practical and theoretical perspective Chickering [2002].
However, in many applications of modern interest, n is small relative to p. In this case
there may be many DAGs that agree with the observed data and it is then desirable
to infer a distribution across DAGs instead of outputting just one DAG. Taking a
Bayesian approach we can define a prior P(G) on the space of DAGs, which can
encode prior structural knowledge about the underlying DAG-as well as desirable
properties such as sparsity. The likelihood P(D | G) is obtained by marginalizing out
0:
P(D I G) = jIP(D, 0 1 G) dO
= jIP(D |0, G)P(O | G) dO
and can be tractably computed for certain classes of distributions Geiger and Heck-
erman [1999], Kuipers et al. [2014]. Applying Bayes theorem yields the posterior
distribution P(G | D) cx P(D | G)P(G), which describes the state of knowledge about
G after observing the data D. From the posterior one can then compute EP(GID)f (G),
the posterior mean of the function of interest. Note that in the common setting
where f takes the form of an indicator function, this quantity is simply a posterior
probability.
16

Unfortunately, computing the normalizing constant of the posterior distribution
is intractable already for moderately sized graphs, since it requires evaluating a sum
over the space of all DAGs on p vertices Koivisto and Sood [2004]. To sample from
the posterior without computing the normalizing constant, Madigan and York [1995]
proposed structure MCMC, which constructs a Markov chain on the space of DAGs
with stationary distribution equal to the exact posterior. T samples {Gt} from such a
Markov chain can then be used to approximate the posterior mean of the function of
interest, namely ElP(GD)f(G) ~T-' t=1 f(Gt).
Problematically, the posterior over DAGs is known to exhibit many local maxima,
so structure MCMC exhibits poor mixing even on moderately sized problems Friedman
and Koller [2003], Ellis and Wong [2008]. To overcome this limitation, Friedman and
Koller [2003] proposed order MCMC, which constructs a Markov chain on the space
of permutations, where the moves are transpositions. The posterior over orders
is smoother than the posterior over DAGs, since the likelihood corresponding to
each order is a sum over many DAGs, and increased smoothness usually leads to
better mixing behavior. However, strong modularity assumptions are needed to make
computing the likelihood tractable. Even under these assumptions, there remains
a considerable computational cost: namely, let k be the maximum indegree of the
underlying DAG, then the likelihood can be computed in O(pk+1) time and memory
Friedman and Koller [2003]. Hence, in practice k can be at most 3 or 4 for this method
1 -T
to scale to large networks. The Monte Carlo estimate -j 
j f(G,,), where G, is
drawn from P(G 
I 7t, D) and rt is sampled from the posterior over permutations
P(7r I D), is then used to approximate the posterior mean of the function of interest.
Friedman and Koller [2003] obtain a practical MCMC sampler when the prior over
permutations is uniform, but such a model introduces significant bias toward DAGs
that are consistent with more permutations [Ellis and Wong, 2008]. Correcting for this
bias by re-weighting each sampled DAG by the inverse number of its linear extensions
can be done, but it is #P in general Ellis and Wong [2008].
A recent extension of order MCMC is partial order MCMC Niinimaki et al. [2016].
This method works on the reduced space of partial orders, thereby leading to improved
17

mixing as compared to order MCMC, but with a' similar runtime. Kuipers and Moffa
[2017] further introduced a related method known as partition MCMC, which avoids
the bias of order MCMC by working on the larger space of node partitions consisting
of permutations and corresponding partition elements. Although partition MCMC
generally mixes more slowly than order MCMC, it was empirically found to mix more
quickly than structure MCMC Kuipers and Moffa [2017].
18

Chapter 3
Minimal I-MAP MCMC
3.1 
Reduction to the Space of Minimal I-MAPs
To overcome the computational bottleneck of order MCMC and at the same time avoid
the slow mixing of structure MCMC, we propose to restrict our focus to a carefully
chosen, reduced space of DAGs that is in near one-to-one correspondence with the
space of permutations. We construct this subspace of DAGs from the CI relations
that hold in the data D. In Appendix A.1 we review a CI testing framework based on
partial correlations for the Gaussian setting.
Given a CI test, let Oijs(D, a) be 1 if the corresponding CI test at level a based
on the n data points in D was rejected-i.e., X4Xi 
| Xs-and 0 otherwise. Let
On(D, a) denote the collection of CI test outcomes across all triples (i, j, S). Given
On(D, a) we associate to each permutation 7r E Sp its minimal I-MAP O,: a DAG
with vertices [p] and arrows 7r(i) -+ ir(j) if and only if O(n (D, a) = 1 with i < j and
S 
{r(1) - -(j 
-
1)} \ {7r(i)}. In light of Occam's razor it is natural to consider
this mapping, since removing any edge in 0, induces a CI relation that is not in
On(D, a) Spirtes et al. [2000], Raskutti and Uhler [2013].
Let g := {0, I -r E Sp}. Then any posterior IP(7 
D) defined by a likelihood and
19

prior on S, induces a distribution on the space of all DAGs, denoted by g, namely
N(G | D) := 
1G = 0,}P(7r | D). 
(3.1)
This distribution places mass only on # and weights each minimal I-MAP according
to the posterior probability of sampling a permutation that is consistent with it.
In the remainder of this section we introduce our main result showing that the
posterior mean of a function based on the posterior P(G | D) defined by a likelihood
and prior on g is well approximated by the posterior mean of the function based on
the distribution $P(G | D) that has support only on O. Before stating our main result,
we introduce the assumptions required for this result.
Assumptions 3.1.1. Let (G*, 0*) define the true but unknown Bayesian network. Let
0* be the equivalent of On(D, a) based on the true but unknown joint distribution on
G*. For each 
EC Sp let G* denote the minimal I-MAP with respect to 0*. We make
the following assumptions:
(a) X, | (G*, 0*) is multivariate Gaussian.
(b) Let p*,jis be the partial correlation derived from the Bayesian network (G*, 0*)
for the triple (i, j, S) and let Q* 
sup(ijjs){IpI,si}. Then there exists q* < 1
such that P(Q* < q*) = 1.
(c) Let R* := inf(,s){|P*jSI 
: P*,jis -# 0}. 
Then there exists r* > 0 such that
P(R* > r*) = 1.
(d) G7 is a sufficient statistic for P(G I r, D), i.e., P(G I r, D) = P (G \0,).
(e) Let A , denote the event that {0 = G*}. ThenIP( A,| 
, ) =P( A , ).
(f) There exists some M < oo such that maxG |f(G)| < M.
An in-depth discussion of these assumptions is provided in Appendix A.3. As-
sumption 3.1.1(c) can be regarded as the Bayesian analogue of the strong-faithfulness
assumption, which is known to be restrictive Uhler et al. [2013] but is a standard as-
sumption in causal inference for obtaining theoretical guarantees Kalisch and Buhlmann
20

[2007], Zhang and Spirtes [2012]. Practitioners often choose f to be an indicator
function (e.g. the presence of a directed edge), so Assumption 3.1.1(f) is typically
satisfied in practice.
We now state our main result that motivates constructing a Markov chain on the
reduced DAG space O instead of g.
Theorem 3.1.2. Under Assumptions 3.1.1(a)-(f) it holds that
EIP(GID)f(G) - EI(GID)f(G) 
< 2f(n, p),
where f(n, p) = C1Mp 2(n - p) exp{-C2 (r*) 2 (n -
p)}.
Theorem 3.1.2 is proven in Appendix A.4.2. The main ingredient of the proof is
the following lemma that bounds the probability of the events AC for all 7r.
Lemma 3.1.3. Under Assumptions 3.1.1 (a)-(c) there exist constants C1, C2 that
depend only on q* such that
P(G* # O7r) < f (n, p),
for all ,F C Sp, where f(n, p) is as in Theorem 3.1.2 and 0, is constructed using
Fisher's z-transform to do CI testing at level a = 2(1 - <b(__) 
.
From Theorem 3.1.2 and Equation (3.1), it follows that
EP(G|D) [f (G)] 
~ 
EN(GID) [f (G)]
= 
f(,)P(ir I D). 
(3.2)
7rESp
Hence, using the near one-to-one mapping between S, and O to associate to each
permutation a particular DAG, we can show that the posterior mean EP(GID)f(G)
can be well approximated by sampling from a posterior over permutations. This is
of particular interest given the observation by Friedman and Koller [2003] that a
posterior over permutations is generally smoother than a posterior over DAGs and
hence more conducive to fast mixing in MCMC methods.
21

3.2 
Bayesian Inference on Minimal I-MAPs
Our original Bayesian generative model consisted of a prior P(G) and a likelihood
P(DIG). In some sense, -r may be thought of an auxiliary random variable that aids
our reduction to the minimal I-MAP space. But inventing a prior and likelihood for
7r in order to arrive at the posterior P((r | D) in Equation (3.2) may be conceptually
difficult. In particular, it is natural to imagine we might have prior and modeling
information for G rather than 7r in applications. And Sp does not induce a partition
in 9 Ellis and Wong [2008]; see also Appendix A.6. In this section, we demonstrate
that, when the available CI information is sufficiently reliable, a good approximation
to EP(GID) [f(G)] can be obtained as follows.
EP(GID)[f (G)] 
~ Zf(0)P(OID), 
where 
(3.3)
P(GD) oc P(DIG = G)P(G =G)
and the final two terms are the original likelihood P(D G) and prior P(G) restricted
to the minimal I-MAP space. This formula is intuitively appealing; it effectively says
that we can obtain a good approximation of the desired posterior expectation by
simply restricting our original model to the minimal I-MAP space.
To show this, we start from Equation (3.2) and let O := O(D, a) for brevity.
Note that P(7r|D) = P(7r|D, O) since O is a function of D. Then, by Bayes theorem,
P(7r I D) oc IP(D | -r, O)P(7r On). 
(3.4)
Conditioning on a statistic of the data, namely On here, before applying Bayes theorem
may be thought of as an empirical Bayes procedure Darnieder [2011].
We examine each of the two factors on the righthand side of Equation (3.4) in turn.
22

Recall that A,: 
{O 
= G*} is the event that we make no CI errors. First, note that
P(D |17, O,) = 
P(D |6r,O, G)P(G |0g,O)
GEg
S 
P(D G)P(G 
). 
(3.5)
GEg
Moreover, note that
P(G I G)
= P(G 60, A,)IP(Ar,|O) + P(G 1 06, A )P(A 
Od,)
= P(G | 0j, A,)P(A,) + P(G 
GiO, AC)IP(AC)
By Assumption 3.1.1(e), P(A,,Id) = P(A,). By Lemma 3.1.3, P(A,) approaches
1 exponentially fast in n, and so P(AC) approaches zero exponentially fast in n.
Observing that P(GIOI,, A,.) ={G = 0,} and that P(GIG,., A) is bounded by
one, we find P(Gj,) 
~ 11{G =,} for a sufficiently accurate CI test. Therefore,
substituting back into Equation (3.5), we find that
P(D I 7r, O6,) ~P(D | G = ,)
the likelihood restricted to the space of minimal I-MAPs.
A similar argument, detailed in Appendix A.5, yields that the second term in
Equation (3.4) is approximately equal to the prior restricted to the space of minimal
I-MAPs:
P(7 6,O) 
~-1- P(G = 0,).
Finally, if we let P(O, D) represent the distribution over G, proportional to the
likelihood P(DIG = 0,) times the prior P(G = 0,), we can replace Equation (3.2)
with Equation (3.3) at the beginning of this section, as was our goal. In the next
section we develop a Markov Chain Monte Carlo sampler with the desired stationary
distribution, P(0j, D).
23

3.3 
Minimal I-MAP MCMC
In this section we develop a Markov Chain Monte Carlo sampler, which we call minimal
I-MAP MCMC, to generate approximate samples from the target distribution, P(G, D).
We show that unlike structure MCMC our approach is amenable to fast mixing.
Furthermore, we show that minimal I-MAP MCMC overcomes the computational
limitations of order MCMC, since its complexity does not depend on the maximum
indegree of the underlying DAG G*.
Our minimal I-MAP MCMC algorithm is detailed in Algorithm 1 for the Gaussian
setting. Algorithm 2, denoted as update minimal I-MAP (UMI), is used as a step
in Algorithm 1 and describes how to compute a minimal I-MAP O, from a minimal
I-MAP O, when 7r and T differ by an adjacent transposition without recomputing
all edges; see also Solus et al. [2017]. We prove the following proposition about the
correctness of our sampler in Appendix A.4.3.
Proposition 3.3.1. In the Gaussian setting, the transitions in Algorithm 1 define an
ergodic, aperiodic Markov chain on g with stationary distribution P(G,|ID).
Note that minimal I-MAP MCMC can easily be extended to the non-Gaussian
setting by replacing the CI tests based on partial correlations by CI tests based on
mutual information. However, for non-Gaussian data our theoretical guarantees do
not necessarily hold.
In Section 4 we show empirically that minimal I-MAP MCMC mixes faster than
other MCMC samplers. The following example provides intuition for this behavior.
Example 3.3.1. Suppose the true DAG G* is the star graph with arrows 2 -* 1, 3 -+
1,...p -± 1. For the sake of simplicity, suppose O(D, a) = 0*. Then for the
permutation T = (13 --. 
p2) the corresponding minimal I-MAP G equals the fully
connected graph. However, a single transposition from T yields the permutation
7r = (23 ... pl), which is consistent with the DAG G*. Hence minimal I-MAP MCMC
can move in a single step from the fully connected graph to the correct DAG, while
structure MCMC, which updates one edge at a time, would require many steps and
could get stuck along the way.
24

While this example is clearly idealized, it captures the intuition that traversing
the space of minimal I-MAPs via transpositions allows the sampler to make large
jumps in DAG space, which allows it to escape local maxima faster and hence mix
faster than structure MCMC. In the following result we characterize the memory and
time complexity of minimal I-MAP MCMC, showing that unlike order MCMC it does
not depend on the maximum indegree of the true DAG G*. The proof is given in
Appendix A.4.5.
Proposition 3.3.2. Let K be the thinning rate of the Markov chain and T the num-
ber of iterations. Consider minimal I-MAP MCMC (Algorithm 1) with a proposal
distribution that puts mass only on adjacent transpositions, i.e.
s 
if 7 
-
7t+1
q(Et -+ 7t+1) = 
1 
if I((t, t1) = 1
0 
otherwise,
where 0 < s < 1 and I(.,-) 
1 if the permutations differ by a single adjacent
transposition. This algorithm takes 0(KTp2) memory and has average time complexity
of O(Tp4 + p5 ). 
Note that a transposition between the first and last element of a
permutation is still considered an adjacent transposition in our definition.
Using a proposal that considers only adjacent transpositions leads to a considerable
speed up. In particular, if we consider any possible transition, updating O, to OC
requires O(p 2) CI tests in general. But the cost is reduced to 8(p) CI tests for adjacent
transpositions that do not swap the first and last elements. Since performing a CI
test based on partial correlations takes O(p 3) time Viertl [2011], this yields a total
speed up of a factor of p at each step. We should note that Algorithm 1 can be sped
up by considering only adjacent transpositions that are connected by an edge; i.e., in
minimal I-MAP space 9 these adjacent transpositions would correspond to considering
only covered edge flips Spirtes et al. [2000], Solus et al. [2017].
We now comment on why our method does not face the computational intractability
of order MCMC. Working in the space of minimal I-MAPS parametrized by permuta-
25

Algorithm 1 Minimal I-MAP MCMC
Input: Data D, number of iterations T, significance level a, initial permutation
7ro, sparsity strength -y, thinning rate rK
Output: G, -.. ,GKT
Construct 0, from O,(D, a) via Fisher's z-transform
for i = 1 to T do
Sample 7ri ~ q(7i_ 1 -
7i)
G, 
= UMI(7ri7, ri_, Gj_,, a, D) (Algorithm 2, Appendix A.2)
pi-1 
logJP(D | O,_1)P(O,m)
pi = logIP(D | Or)P(Os,)
si = min {1, exp(p - pi-1)}
z 
~. Bernoulli(si)
if zi = 0 then
7ri =ri_-1 and Os =GOr_- 
(chain does not move)
end if
if T is divisible by 
then
Store G
end if
end for
tions is similar in spirit to order MCMC, but our approximation of the posterior (that
is, the approximation we make even before applying MCMC) allows us to avoid the
poor scaling of order MCMC. In particular, the intractability of order MCMC arises
due to the focus on an exact likelihood; acquiring this likelihood requires summing
over O(pk+1) parent sets in order to sum over the full space of DAGs. In our case, we
instead exploit the fact that the likelihood concentrates around a single DAG O, once
we condition on O(D, a).
26

Chapter 4
Experiments
In this section we empirically compare minimal I-MAP MCMC to order and partition
MCMC. We chose partition MCMC since it does not have the bias of order MCMC
and empirically has faster mixing than structure MCMC Kuipers and Moffa [2017].
We use the max-min-hill-climbing (MMHC) algorithm Tsamardinos et al. [2006] in
conjunction with the nonparametric DAG bootstrap approach Friedman et al. [1999]
as an additional baseline for comparison. For each dataset, we ran the Markov chains
for 105 iterations, including a burn-in of 2 x 104 iterations, and thinned the remaining
iterations by a factor of 100. Seeded runs correspond to starting the Markov chain
at the permutation/DAG obtained using MMHC. We also considered "cheat" runs
that start at the true permutation with the intuition that we expect high scores
on the true generating model. In terms of software, we used the code provided by
Kuipers and Moffa [2017] to run partition and order MCMC. We used the method
and software of Kangas et al. [2016] for counting linear extensions for bias correction,
and we implemented minimal I-MAP MCMC using the R-package bnlearn.
4.1 
Prior and Likelihood
As in many applications, a prior that induces sparsity in the underlying structure
is desirable for interpretability and computation. Further, note that the true DAG
G* is equal to the sparsest minimal I-MAP G* over all permutations S, based on CI
27

relations 0* Verma and Pearl [1992], Solus et al. [2017], Raskutti and Uhler [2013];
thus, on minimal I-MAP space, a sparsity prior is natural. To achieve this end, we
choose a prior of the form
P(G) = P*(G) exp (- yllG||),
where P*(G) can include any structural information known about the DAG. Except
where explicitly mentioned in what follows, we use this prior with P*(G) uniform
over DAGs. We note that, unlike our method or partition MCMC, order MCMC
uses a uniform prior over permutations; the induced prior over DAGs as a result of
such a prior is Porder(G) = |#inext(G)IP(G), where |#Iinext(G)| denotes the number
of linear extensions of G Ellis and Wong [2008]. Finally, each method assumes the
data follow a multivariate Gaussian distribution with a Wishart prior on the network
parameters. This assumption allows computation of P(D|G) via the BGe score Geiger
and Heckerman [1999], Kuipers et al. [2014].
4.2 
Mixing and Convergence
We consider three different datasets. The first two were obtained by simulating data
from a network consisting of p = 30 nodes with n = 100 and n = 1000 observations
respectively. The data were generated according to a linear structural equation model
with additive Gaussian noise, where the edge weights on the underlying DAG G*
were sampled uniformly from [-1, -. 25] U [.25, 1] as in Solus et al. [20171. The third
dataset is from the Dream4 in-silico network challenge Schaffter et al. [2011] on gene
regulation. In particular, we examine the multifactorial dataset consisting of ten nodes
and ten observations.
In Figure 4-1 we analyze the mixing performance of the different methods. The
convergence of different runs to the same score neighborhood can be taken as an
indication of adequate mixing. Figure 4-1 suggests that for the n = 100 and the
Dream4 dataset all three methods have mixed well while for the dataset with n = 1000
28

(0
CO
C>
C14
00
0
I
0 
200 400 
600 
800 1000
Every 100th Iteration
C14
9? 
-
CO
CO
0
C>
C>
CO)
0
CD
C-)I
8
C.-
C.,I
0
CD
1~=
C-)
1'
0 
200 400 
600 800 1000
Every 100th Iteration
0)
M
C-)
0
0 
200 
400 600 
800 1000
Every 100th Iteration
Figure 4-1: From left to right, the columns represent the n = 100, n = 1000, and
Dream4 datasets, respectively. From top to bottom, the rows correspond to minimal
I-MAP (minIMAP), order, and partition MCMC. The black dotted line corresponds
to runs seeded with the true permutation. The purple and brown lines correspond to
runs seeded with a random permutation and the red and green curves represent runs
seeded with MMHC.
29
0
Cl)
ax)
L_.0
CO,
a)
0
0
C.)
.1I~~
...~-.................~
il
a? I 
I I- i

V
Cu
V
0)
Cu
C,)
E0VC
Cu
V
0)V
Cu
0)
Co
E0
VC
Cu
++ 
+
0
+ 
+
0+
0.0 
0.2 
04 
0.6 
0.8 
1.0
0++
..
00
0.0 
0.2 
0.4 
0.6 
0.8 
1.0
Random Seeded
V
Cu
~0
Cu
Cu
Co
C)
I
V
Cu
~0
Cu
Cu
Co
C)I
++ 
+
+ 
+
+ 
+
0+
00 0 
04 
0.+ 
.8 10
0.0 
0,2 
0.4 
0.6 
0.8 
1.0
0
00
0.0 
0.2 
0.4 
0.6 
0.8 
1.0
MMHC Seeded
Figure 4-2: The top row and bottom row correspond to
(D
CU
E
E0"a
C
CO
0V
1000 datasets respectively. 
Each point represents the posterior probability of a
directed feature estimated by different seeded runs of MCMC. We consider all possible
combinations of random and MMHC seeded runs for completeness. Red (x), blue (o),
and brown (+) correspond to minIMAP, order, and partition MCMC respectively.
samples there is evidence of poor mixing in all methods since the posterior landscape
is more peaky due to increased sample size. However, the score plots are markedly
worse for order and partition MCMC.
Since the end goal is often to obtain robust estimates of particular feature proba-
bilities, in Figure 4-2 we analyze the correlation between the approximated posterior
probabilities of directed features with respect to different seeded runs. Figure 4-2 shows
that the correlation is higher across all models for the dataset with n = 100 samples,
which is to be expected, since the chains seem to have mixed given the analysis in the
score plots in Figure 4-1. Conversely, for the n = 1000 dataset, Figure 4-2 shows that
order and partition MCMC yield vastly different posterior probabilities across different
runs, while minimal I-MAP MCMC maintains high correlation, thus suggesting again
superior mixing.
30
9X
0x
O ++ 
x 
x
0.0 
0.2 
0,4 
0.6 
0.8 
1.0
0.0 
0.2 
0.4 
0.6 
0.8 
1.0
MMHC Seeded
the n = 100 and n=

4.3 
ROC Performance
As described in Section 2, the bias of order MCMC can be removed by dividing the
functional of interest f(Gt) by the number of linear extensions of Gt, where Gt is a
DAG sampled during the Monte-Carlo Step. We denote this by full bias correction
(FBC). Although this leads to an unbiased estimator for order MCMC, there is a
bias-variance trade-off. If a sampled DAG has few linear extensions, this DAG will be
given more weight in the Monte Carlo step, thereby increasing the variance. Therefore,
we also consider a partial bias correction (PBC), where the weights are truncated and
re-normalized to belong to the 25th and 75th quartile of the inverse linear extension
counts of the sampled DAGs. Finally, we denote no bias correction by NBC.
In Table 4.1 we report the area under the ROC curves (AUROC) for detecting
directed and undirected features for the different methods. For order MCMC, we see a
marginal performance boost after bias correction on the simulated datasets, but worse
performance on Dream4. For the n = 100 and n = 1000 datasets, the Bayesian models
perform better than the MMHC bootstrap. While Table 4.1 shows that MMHC
achieves the highest AUROC performance on the Dream4 dataset, the corresponding
ROC plot provided in Figure A-1 in Appendix A.8 shows that minimal I-MAP MCMC
and order MCMC compare favorably to MMHC when the true negative rate (TNR),
which equals one minus the false positive rate (FPR), is greater than 0.4. This range
for the TNR is the relevant regime for biological applications, where it is often more
important to control for Type I errors (i.e. incorrectly specifying causal relationships
between nodes).
The second column of Table 4.1 for each dataset shows AUROC performance on
the compelled edges and Figure A-1 in Appendix A.8 contains the corresponding ROC
plots. Recovering compelled edges is important because these are the only causal
effects that are identifiable from observational data alone Pearl [2009]. Table 4.1 shows
that minimal I-MAP MCMC achieves the best performance in terms of recovering
compelled edges on the n = 1000 dataset and is marginally better than the other
methods on the n = 100 dataset.
31

Table 4.1: AUROC results by dataset and method. NBC, PBC, and FBC stand for no,
partial, and full bias correction. The columns represent AUROC values for undirected
and compelled features respectively.
METHOD 
N=100 
N=1000 
DREAM4
MINIMAP 
.946 .695 
1.00 .958 
.574 .556
ORDER-NBC 
.957 .675 
.949 .395 
.599 .600
ORDER-PBC 
.956 .677 
.949 .393 
.579 .444
ORDER-FBC 
.952 .695 
.950 .395 
.563 .489
PARTITION 
.857 .660 
.890 .674 
.497 .733
MMHC-BooT 
.842 .693 
.892 .668 
.552 .533
4.4 
Time and Memory Complexity
Since partition MCMC has a similar time and memory complexity as order MCMC,
we focus on comparing minimal I-MAP MCMC to order MCMC in these regards.
Recall that p denotes the number of nodes and k denotes the maximum indegree
of the underlying DAG G*. To control for different implementations, we computed
the average iteration times relative to the average iteration time for p = 25 nodes.
The average iteration times do not include the time it takes to cache all the scores
in order MCMC and the time it takes to construct 0r for initiating the Markov
chain. Figure 4-3 shows that order MCMC scales similarly to its predicted theoretical
complexity of O(pk+l). For minimal I-MAP MCMC, we provided a bound of 0(p4
)
in Proposition 3.3.2. Figure 4-3 suggests that the complexity scales by a factor of p
better than the bound we obtained, namely 0(p3 ). Finally, we note that order MCMC
runs out of memory quickly when either k or p grows. As a specific example, for only
p = 80 nodes and k = 5, order MCMC takes over 40 GB of space while minimal
I-MAP MCMC takes around 1 MB.
4.5 
Incorporating Priors
Unlike minimal I-MAP MCMC, both partition and order MCMC require that the prior
over DAGs factorizes as P(G) = Hlp_1 p(Xi, PaG(Xi)) which is defined as structure
modularity by Friedman and Koller [2003]. P(G) is used in order MCMC to specify
32

; 
I 
a
35 4 
45
4
-40
a 'a 
Order,k=5
............ ....... 
O rder, k= 4
o r 
a 
-
Order, k=3
-minIMAP
3.5 
4.0 
4.5 
5.0 
5.5
Log # of Nodes
Figure 4-3: Average iteration times for different sized networks. The times are relative
to the average iteration time for p = 25 nodes; c denotes the slope of the dotted lines
and estimates the computational complexity 0(p').
33

Table 4.2: AUROC results for directed edge recovery in the protein network in Figure
A-2.
METHOD 
AUROC
MINIMAP w/ PATH AND ORDER PRIOR 
.929
MINIMAP w/ ORDER PRIOR 
.917
ORDER W/ ORDER PRIOR 
.874
PARTITION W/ ORDER PRIOR 
.912
MMHC-BOOT 
.909
the conditional distribution P(G | 7r) = I(G 7 ir)P(G), which is needed to calculate
the likelihood P(D 17r) in order MCMC; see also Appendix A.6. The assumption of
structure modularity is a practical limitation. In biological applications, for example,
prior information often comes in the form of path information between classes of
vertices, which is not structure modular in general. In the following, we illustrate this
point using the biological network studied by Mukherjee and Speed [2008] (reproduced
in Figure A-2 in Appendix A.8). In this application, we have prior knowledge on
both orders and paths. In particular, we expect ligands to come before receptors, and
receptors before cytosolic proteins. In addition, we expect to see paths from ligands
to receptors and paths from receptors to cytosolic proteins Mukherjee and Speed
[2008]. Such path information cannot be used by order and partition MCMC since
this information is not structure modular. To test if path knowledge leads to better
inference, we compared the ROC plots (Figure A-2, Appendix A.8) and AUROC
(Table 4.2) for directed edge recovery for the different methods. Table 4.2 shows that
the path prior leads to a boost in AUROC performance of minimal I-MAP MCMC
by 1 - 2% percent, thereby suggesting that structure modularity can be limiting for
certain applications. The specific form of the path and order prior are provided in
Appendix A.7.
34

Chapter 5
Concluding Remarks
In this paper, we introduced minimal I-MAP MCMC, a new Bayesian approach to
structure recovery in causal DAG models. Our algorithm works on the data-driven
space of minimal I-MAPs with theoretical guarantees on posterior approximation
quality. We showed that unlike order or partition MCMC the complexity of an
iteration in minimal I-MAP MCMC does not depend on the maximum indegree of the
true underlying DAG. This theoretical result was confirmed in our empirical study. In
addition, our empirical study showed that minimal I-MAP MCMC achieves similar or
faster mixing than other state-of-the-art methods for Bayesian structure recovery.
While we have focused on the Gaussian setting, it would be interesting in future
work to extend the theoretical analysis to other distributions, in particular the discrete
setting. Finally, it would be interesting to explore the performance of minimal I-MAP
MCMC for obtaining MAP estimates or as a new DAG scoring criterion. In particular,
the scoring criterion of the greedy SP (GSP) algorithm Solus et al. [2017] is equivalent
to our DAG score (i.e., unnormalized posterior probability) when -y -+ oc in the prior
in Section 4.1 and the search space is restricted to 0. In this case, the likelihood
term has no influence in picking the minimal I-MAP from 9. We might therefore
find improved performance in terms of structure recovery over the GSP algorithm by
incorporating the likelihood term by setting 7 < oc.
35

36

Appendix A
Appendix
A.1 
CI Testing for Gaussian Data
In the case of multivariate Gaussian data, one may use the Fisher z-transform [Fisher,
1915] to perform CI testing. The Fisher z-transform is given by
Z(.ij 
S) 
1 log(1 + i,jls)
2 log(1 - Ajis)
where i,jis is the empirical partial correlation between Xi and Xj given Xs. To
conduct a two-sided hypothesis test at significance level a, one may test if
n -|S1 - 3|Z(i,j | S)| < <-1(1 - a/2),
where <»-' is the inverse CDF of N(O, 1).
A.2 
Update Algorithm
Algorithm 2 specifies the update procedure used in Algorithm 1 to reduce the number
of CI tests needed.
37

Algorithm 2 Update Minimal I-MAP (UMI)
Input: Current permutation 7ri, previous permutation ri_1, previous minimal
I-MAP Gs, significance level a, data D
Output: G,
k = min index of adjacent transposition
if k = 1 (first and last element swapped) then
Compute G, from 09(D, a)
else
G7r = G7ri1
Reverse edge from X~i(k+l) to X,i(k) in G, if such an edge exists
for s = 1 to k - 1 do
for j 
k to k + 1 do
S = {7r(1), -- - ,r(j - 1)} \ {r(s)}
Let z= Os(D,a)
Update edge from X,(,) to X,(j) to z in G,
end for
end for
end if
A.3 
Discussion of the Assumptions
Based on the discussion of Kalisch and Buhlmann [2007], Assumption 3.1.1(b) is not
such a strong assumption and seems more of a regularity condition needed to prove
the bounds. Assumption 3.1.1(d) has an intuitive interpretation; it says that the best
prediction of G based on the data and order is captured by the constructed network.
Conditioned on the order, the inference problem is not hard; i.e., we just need to
recover the skeleton. Since we can recover the skeleton via the empirical CI relations,
O, is indeed the best prediction of the network given the data and order in many cases,
which would imply that 0, can reasonably be assumed to be a sufficient statistic.
Assumption 3.1.1(e) is a quite weak assumption; it says that the information of O,
does not help in predicting the probability of a CI error. This makes sense because we
want to know if O, does not equal G*. But, without observing G*, or conditioning
on some property of G* in addition to 
7,, it seems reasonable to assume that our
prediction is left unchanged when knowing 0,.
38

A.4 
Proofs
A.4.1 
Proof of Lemma 3.1.3
The proof relies heavily on the concentration bounds used to prove the high-dimensional
consistency of the PC algorithm Kalisch and Buhlmann [2007]. To start, notice that
P(G, / O, G, 0) = P(CI error(s) constructing O^,)
p-1 
p
E E P (Eijy (G*,) 0*)), 
(A. 1)
i=1 j=i+1
where Ej,j(G*, 0*) is the event that a CI error is made when testing X, (j) L X,(j) 
| Xs,
for S = {7(1), -.- 
, 7r(j - 1)} \ {7r(i)}, conditioned on the Bayesian network (G*, 0*)
generating the observed data. Note that these tests are performed at the significance
level provided in the statement of the lemma.
By assumption, Q*,* 
< q* < 1 and 0 < r* 
R*,G* (without loss of generality,
ignore measure zero sets). Picking such q* and r* then satisfy the assumptions required
in Lemma 4 of Kalisch and Buhlmann [2007]. Equations (16) and (17) from Kalisch
and Buhlmann [2007] imply that there exist constants C1 , C2 that depend only on q*
such that
P(E, (G*, 0*)) < C1(n - p) exp{-C2(r*) 2(n -p)}
for any i, j. Hence,
P(G, # O, I G, 0) < f(n, p), 
(A.2)
where f (n, p) = p 2 C1(n - p) exp{-C2(r*) 2(n -p)}.
39

Now,
P(G* 7/ O,)
= SjIP(G* 
,r 
G, O)P(O | G)P(G)dO
GEg
< E 
jf(n, )P(O | G)P(G)dO
G=n
as desired.
A.4.2 
Proof of Theorem 3.1.2
By the tower property,
EP(GID)f(G) = EP(7r|D)Ep(GID,7r)f(G).
40

As before, define A, as the event that G,= G*. We may expand EP(GID, 7)f(G) as
EP(GID,r)f(G)
=Zf(G)P(G 
| D,I r)
GEg
= 
f(G)P(G, A7, 
07,) + 
f(G)P(G, AC 0)
GEQj 
GEg
by Assumption 3.1.1(d) and the law of total probability
= f (0,) + P(Ar 
I O,r)
- [Zf(G)P(G |O ,
IAS) - f(a7r)]
by the fact that P(G |GO, A ,) = I(G =0,,)
according to the exact reasoning used in Section 3.2
= f(G7, ) + P(A7)
-
f(G)P(G |0, 
A6 
) - f(07,
)
where the final equality uses Assumption 3.1.1(e).
We claim that
EP(7r|D)f (Gr) 
E(G|D)f (G). 
(A.3)
To prove Equation (A.3), notice that
EP(7rID) f(G7r)
= 
f(O 7
, )P(wT 
D)
7rESp
-
f(G) 5i1{G C $}1{G 
0 ,}IP(7r D)
GEg 
7ESp
= 
f(G)P(G | D)
GEg
- Ef(GID)[f(G)].
41

Finally,
f(G)P(G I ,,, AC) - f(O,) < 2M
GEg
and
P(A') < C1(n - p)exp{-C2(r*)2(n -)
by Lemma 3.1.3. The result now follows by taking expectations and using the above
bounds.
A.4.3 
Proof of Proposition 3.3.1
Ergodicity follows from the fact that any permutation can be reached from adjacent
transpositions, and aperiodicity follows from our constraint that s E (0, 1). Since
adjacent transpositions trivially satisfy the detailed balance equations, the Markov
chain has stationary distribution P(G, I D).
A.4.4 
Proof of Proposition A.4.1
Proposition A.4.1. If rt and 7t+1 differ by an adjacent transposition, Algorithm 2
correctly calculates 0,, from G,.
This update rule was also used by Solus et al. [2017]. We here provide the proof
for completeness. The result trivially follows if rt+1 is obtained by swapping the first
and last element of rt since all CI tests are recomputed in this case. Hence, we may
assume 7rt and 7rt+1 differ by an adjacent transposition not at the border. Suppose
7rt = (n1 ... nini+1 ... np) and 7rt+1 = (ni 
... n+ini -... np), where the permutations
differ at an adjacent permutation at position i. Then, the only edges that can be
different in O, and O,C 
are those edges connected nodes ni / ni+1 with nodes
nk, 1 < k < i. Correcting the edges (ni, nk) and (ni+1, nk) corresponds to recomputing
the conditional independence statements Xi - 4Xn I Xs, and Xn, 4 Xnk XSi+,
for Xs, = {ni,... , ni+ 1} \ {nk} and Xs 1 = {ni, --- , ni- 1} \ {nk} and updating the
corresponding edges. The for loop in Algorithm 2 carries out the CI tests specified
42

in the previous sentence. Finally, we need to reverse the edge between nodes X,
and Xs,   
if there was an edge between them in the old DAG G,; this reversal is
accomplished at the very start of Algorithm 2.
A.4.5 
Proof of Proposition 3.3.2
The memory complexity follows trivially from the fact that it takes O(p2) memory
to store 0, in an adjacency matrix. Computing partial correlations takes at most
O(p3) time using the well-known partial correlation recursive formula Viertl [2011].
Instantiating G,0 requires 0(p 2) CI tests and hence takes at most O(p5 ) time to
compute. The subsequent Os are computed using Algorithm 2. The correctness of
Algorithm 2 was shown in Appendix A.4.4. We claim Algorithm 2 takes average case
O(p4 ) time.
First, we show that the first and last elements of Tri are swapped with probability
less than 1 when moving from ri to rji. Notice from our definition of the adjacent
p
transposition distribution q that the probability of either the first or last element
undergoing an adjacent transposition is 2(1-). Conditioned on either the first or last
p
element being chosen to be swapped, there is probability 1 that the first (last) element
will be swapped with the last (first) element. Hence, the probability of the first and
last element being swapped equals (1") which is less than 1. When the first and
p 
p
last element are swapped, all p2 CI tests need to be recomputed. All the remaining
adjacent transpositions require at most 2p additional CI tests to be performed in the
for loop of Algorithm 2. Hence, on average, the number of additional CI tests is O(p)
which implies the average running time of Algorithm 2 is O(p).
A.5 
Justification for restricting the prior space
Following nearly the same reasoning used to motivate our likelihood approximation in
Section 3.2, here we justify
P(7 16O,) ~P(G = O,).
43

Notice that
P(wr 16O)
= P(7r | On, A,)P(A,jOn) + P(7r| On, A )P(A|O)
- P(7r On, A,)P(A,) + P(7r 16O, A )P(A 
)
where the final equality follows from Assumption 3.1.1(e). We claim that
P(7r 16O,1 A,) = P(G = O,). 
(A.4)
Given On, we can construct G,, and conditioned on A., G, = G*. Each permutation
7r may therefore be associated with its true corresponding DAG G* which equals O,.
Hence, the conditional probability P(7r|On, A,) equals the prior probability of O,
namely P(G = 0,).
Finally, since P(A,) goes to zero exponentially fast by Lemma 3.1.3, P(7r|O) is
well approximated by P(G = 0,).
A.6 
Prior Specification on Topological Orderings
Here we illustrate the computational difficulty of specifying a posterior P(r|D) that
agrees with our original prior P*(G) and likelihood P(G|D) on the space of DAGs.
Notice that
P(D 17r) = ZP(D I G)P(G |7r). 
(A.5)
G
Equation (A.5) implies that we must specify a conditional distribution P(Gl7r) to calcu-
late the likelihood term for P(wrD). To understand what this conditional distribution
should be, notice that the induced prior over DAGs equals
P(G) = 1 P(G I 7r)P(7r). 
(A.6)
44

In order MCMC, the assumed prior P(7r) is equal to I Friedman and Koller [2003]. A
natural distribution one may specify for P(G|7), and the one assumed in Friedman
and Koller [2003], is
P(G 1 r) = I(G 
-r)P*(G). 
(A.7)
However, it is trivial to check that Equation (A.7) implies Equation (A.6) equals
#inext(G)|P*(G), where |#inext(G)| denotes the number of linear extensions of G
Ellis and Wong [2008]. Therefore, we instead need
1
P(G 1 7r) 
=- 
I 
(G 
7 r)P*(G)
) #Iinext(G)|
to construct a model that agrees with our desired prior P* (G) on DAGs. The difficulty
of defining a prior on P(7r|OQ) is calculating |#inext(G)|, which is #P in general. We
should note that we avoid these issues by instead defining a prior on P(irIOn). P(7r|O,)
allows us to define a distribution that approximately induces the correct DAG prior;
see the discussion in Section 3.2.
A.7 
Path and Order Priors
Here we provide the specific form of the order and path priors used in the experiment
in Section 4.5. Let L, R, and C denote the set of ligands, receptors, and cytosolic
proteins, respectively, in the network in Figure A-2. For the order prior, IP(7r), we set
P(-r) := exp (E 
fL(l) + 
fR(T 
,
L 
R
where fL(l) indicates if ligand node I came before all nodes in RUC and fR(r) indicates
if receptor r came before all nodes in C and after L in r. For our method, the order
prior is incorporated into our prior on DAGs. Specifically, we replace the DAG prior
of P(G) = exp ( -
^yllG|) used in our other experiments with,
P(G) := exp (--ylG) exp( 
fL(l) +Zf 
(r))-
45

minIMAP
order-nbc
order-pbc
-order-fbc
parfition
-
MMHC-boot
1.0 
0.8 
06 
0.4 
0.2 
0.0
1.0 
0.8 
0.6 
0.4 
0.2
True Negative Rate
C9-
WO
a.
20
N-
6~
0.0
q
0~~
0~
1.0 
0.8 
0.6 
04 
0.2 
0,0
1.0 
0.8 
0.6 
0.4 
0.2 
0.0
True Negative Rate
1.0 
0.8 
06 
0.4 
0.2 
0.0
1.0 
0.8 
0.6 
0.4 
0.2 
0.0
True Negative Rate
Figure A-1: The top ROC curves represent recovery of undirected features and the
bottom for compelled features. From left to right, the plots correspond to the Dream4,
n=100. and n=1000 datasets.
We refer to the prior above as minIMAP w path prior in Table A.8. To incorporate
path information, we take a prior of the form,
exp ( 
h (l) + 
hR(r),
L 
R
where hL(1) indicates if ligand node I had a path to at least one node in R and hR(r)
indicates if receptor r had a path to at least one node in C. Combined with the order
prior, the prior minIMAP w/ path and order in Table A.8 is given by,
P(G) := exp ( - 7||GII) exp
EfL
L
exp ( 
hL(l)
+ZfRA(r))
R 
r'
+ 1 hR~r)•
R
L
46
6
2
-
-
-
-
-
-
-
-
-
-
-
-

Table A.1: Average correlation of directed features between runs seeded with the true
network and runs seeded with MMHC from two hundred randomly generated DAGs
with p = 30 nodes. Higher is better.
METHOD 
AVG. CORRELATION 
STD. ERROR
MINIMAP 
.977 
.004
ORDER 
.928 
.007
PARTITION 
.784 
.006
A.8 
Additional Experiments and Plots
To further analyze the mixing behavior of the different methods, we compute the
correlation between different seeded runs for estimating marginal directed edge proba-
bilities. Table A.1 shows the average correlations and standard errors based on two
hundred synthetic datasets with n = 1000 observations and p = 30 nodes. Note: Each
method was run with 1 x 10' iterations and a burn-in of 2 x 104 iterations.
The ROC plots for the n = 100, n = 1000, and Dream4 datasets are shown in
Figure A-1; see Section 4.3 for a discussion of these plots. The network in Mukherjee
and Speed [2008] used for the experiments in Section 4.5 is given in Figure A-2.
47

0-6
Ligand
0
Receptor
Cytosolic
Protein0
-2
0
0
to
(;
CM
0;
0D
minIMAP w/ path & order
minIMAP w/ order
mOrder w/ order
Partition w/ order
MMHC bootstrap
1.0 
0.8 
0.6 
0.4 
0.2 
0.0
True Negative Rate
Figure A-2: The network on the left is taken from Mukherjee and Speed [2008]. The
ROC plot on the right corresponds to the recovery of directed edges. Path and order
refers to a prior that takes both path and order information into account as specified
in Section 4.5. For order and partition MCMC, only order information can be used in
the prior as discussed in Section 4.5.
48

Bibliography
S. A. Andersson, D. Madigan, and M. D. Perlman. A characterization of Markov
equivalence classes for acyclic digraphs. The Annals of Statistics, 25:505-541, 1997.
D. M. Chickering. Optimal structure identification with greedy search. Journal of
Machine Learning Research, 3:507-554, 2002.
W. Darnieder. Bayesian Methods for Data-Dependent Priors. PhD thesis, Ohio State
University, 2011.
B. Ellis and W. H. Wong. Learning causal Bayesian network structures from ex-
perimental data. Journal of the American Statistical Association, 103:778-789,
2008.
R. A. Fisher. Frequency distribution of the values of the correlation coefficient in
samples from an indefinitely large population. Biometrika, 10:507-521, 1915.
N. Friedman and D. Koller. Being Bayesian about network structure. A Bayesian
approach to structure discovery in Bayesian networks. Machine Learning, 50:95-125,
2003.
N. Friedman, M. Goldszmidt, and A. J. Wyner. Data analysis with Bayesian networks:
A bootstrap approach. In Proceedings of the Fifteenth Conference on Uncertainty
in Artificial Intelligence, 1999.
N. Friedman, M. Linial, I. Nachman, and D. Pe'er. Using Bayesian networks to analyze
expression data. In Proceedings of the Fourth Annual International Conference on
Computational Molecular Biology, 2000.
D. Geiger and D. Heckerman. Parameter priors for directed acyclic graphical models
and the characterization of several probability distributions. In Proceedings of the
Fifteenth Conference on Uncertainty in Artificial Intelligence, 1999.
M. Grzegorczyk and D. Husmeier. Improving the structure MCMC sampler for
Bayesian networks by introducing a new edge reversal move. Machine Learning, 71:
265-305, 2008.
M. Kalisch and P. Buhlmann. Estimating high-dimensional directed acyclic graphs
with the PC-algorithm. Journal of Machine Learning Research, 8:613-636, 2007.
49

K. Kangas, T. Hankala, T. Niinimaki, and M. Koivisto. Counting linear extensions of
sparse posets. In Proceedings of the Twenty-Fifth International Joint Conference
on Artificial Intelligence, 2016.
M. Khashei and A. Mirahmadi. A soft intelligent risk evaluation model for credit
scoring classification. International Journal of Financial Studies, 3:411-422, 2015.
M. Koivisto and K. Sood. Exact Bayesian structure discovery in Bayesian networks.
Journal of Machine Learning Research, 5:549-573, 2004.
J. Kuipers and G. Moffa. Partition MCMC for inference on acyclic digraphs. Journal
of the American Statistical Association, 112:282-299, 2017.
J. Kuipers, G. Moffa, and D. Heckerman. Addendum on the scoring of Gaussian
directed acyclic graphical models. The Annals of Statistics, 42:1689-1691, 2014.
S. Lauritzen. Graphical Models. Oxford University Press, 1996.
D. Madigan and J. York. Bayesian graphical models for discrete data. International
Statistical Review, 63:215-232, 1995.
F. Mohammadi, C. Uhler, C. Wang, and J. Yu. Generalized permutohedra from
probabilistic graphical models. SIAM Journal on Discrete Mathematics, 32:64-93,
2018.
S. Mukherjee and T. P. Speed. Network inference using informative priors. Proceedings
of the National Academy of Sciences, 105:14313-14318, 2008.
T. Niinimaki, P. Parviainen, and M. Koivisto. Structure discovery in Bayesian networks
by sampling partial orders. Journal of Machine Learning Research, 17:2002-2048,
2016.
J. Pearl. Causality: Models, Reasoning and Inference. Cambridge University Press,
2nd edition, 2009.
G. Raskutti and C. Uhler. Learning directed acyclic graphs based on sparsest permu-
tations. 2013.
J. Robins, M. A. Hernan, and B. Brumback. Marginal structural models and causal
inference in epidemiology. Epidemiology, 11:550-60, 2000.
T. Schaffter, D. Marbach, and D. Floreano. Bioinformatics, 27:2263-2270, 2011.
L. Solus, Y. Wang, L. Matejovicova, and C. Uhler. Consistency guarantees for
permutation-based causal inference algorithms. arXiv:1702.03530, 2017.
P. Spirtes, C. Glymour, and R. Scheines. Causation, Prediction, and Search. MIT
press, 2nd edition, 2000.
50

J. Tian and R. He. Computing posterior probabilities of structural features in Bayesian
networks. In Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial
Intelligence, 2009.
I. Tsamardinos, L. E. Brown, and C. F. Aliferis. The max-min hill-climbing Bayesian
network structure learning algorithm. Machine Learning, 65:31-78, 2006.
C. Uhler, G. Raskutti, P. Biihlmann, and B. Yu. Geometry of the faithfulness
assumption in causal inference. The Annals of Statistics, 41:436-463, 2013.
T. Verma and J. Pearl. An algorithm for deciding if a set of observed independencies
has a causal explanation. In Proceedings of the Eighth Conference on Uncertainty
in Artificial Intelligence, 1992.
R. Viertl. Probability and Bayesian Statistics. Springer US, 2011.
J. Zhang and P. Spirtes. Strong faithfulness and uniform consistency in causal inference.
In Proceedings of the Nineteenth Conference on Uncertainty in Artificial Intelligence,
2012.
51

