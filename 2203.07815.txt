Adversarial Counterfactual Augmentation:
Application in Alzheimer’s Disease
Classiﬁcation
Tian Xia 1,∗, Pedro Sanchez 1, Chen Qin 1 and Sotirios A. Tsaftaris 1,2
1School of Engineering, University of Edinburgh, UK
2The Alan Turing Institute, London, UK
Correspondence*:
Corresponding Author
tian.xia@ed.ac.uk
ABSTRACT
Due to the limited availability of medical data, deep learning approaches for medical image
analysis tend to generalise poorly to unseen data. Augmenting data during training with random
transformations has been shown to help and became a ubiquitous technique for training neural
networks. Here, we propose a novel adversarial counterfactual augmentation scheme that aims at
ﬁnding the most effective synthesised images to improve downstream tasks, given a pre-trained
generative model. Speciﬁcally, we construct an adversarial game where we update the input
conditional factor of the generator and the downstream classiﬁer with gradient backpropagation
alternatively and iteratively. This can be viewed as ﬁnding the ‘weakness’ of the classiﬁer
and purposely forcing it to overcome its weakness via the generative model. To demonstrate
the effectiveness of the proposed approach, we validate the method with the classiﬁcation of
Alzheimer’s Disease (AD) as a downstream task. The pre-trained generative model synthesises
brain images using age as conditional factor. Extensive experiments and ablation studies have
been performed to show that the proposed approach improves classiﬁcation performance and
has potential to alleviate spurious correlations and catastrophic forgetting.
Code will be released upon acceptance.
Keywords: Alzheimer’s Disease, Generative model, Classiﬁcation, Counterfactuals, Data efﬁciency
1
INTRODUCTION
Deep learning has been playing an increasingly important role in medical image analysis in the past decade,
with great success in segmentation, diagnosis, detection, etc (Shen et al., 2017). Although deep-learning
based models can signiﬁcantly outperform traditional machine learning methods, they heavily rely on the
large size and quality of training data (Chlap et al., 2021). In medical image analysis, the availability of large
dataset is always an issue, due to high expense of acquiring and labelling medical imaging data (Shorten
and Khoshgoftaar, 2019). When only limited training data are available, deep neural networks tend to
memorise the data and cannot generalise well to unseen data (Dietterich, 1995; Srivastava et al., 2014).
This is known as over-ﬁtting (Dietterich, 1995). To mitigate this issue, data augmentation has become a
popular approach. The aim of data augmentation is to generate additional data that can help increase the
variation of the training data.
1
arXiv:2203.07815v2  [eess.IV]  1 Oct 2022

Xia et al.
Adversarial Counterfactual Augmentation: Application in AD Classiﬁcation
*
Brain image ”
Target age f
«
Generator
f
Synthetic images ”)
Classifier
ó)
Predicted AD labels
ó
Groundtruth AD labels
89
update f to maximise 89: +‘O89(ó, ó))
update « to minimise 89:  - ‘?89(ó, ó))
Supervised loss
Figure 1. A schematic of the adversarial classiﬁcation training. The pre-trained generator G takes a brain
image x and a target age a as input and outputs a synthetically aged image ˆx that corresponds to the target
age a. The classiﬁer C aims to predict AD label for a given brain image. To utilise G to improve C, we
formulate an adversarial game between a (in red box) and C (in cyan box), where a and C are updated
alternatively and iteratively using L1 and L2, respectively (see Sec. 2.3). Note G is frozen.
Conventional data augmentation approaches mainly apply random image transformations, such as
cropping, ﬂipping, and rotation etc. to the data. Even though such conventional data augmentation
techniques are general, they may not transfer well from one task to another (Cubuk et al., 2019). For
instance, color augmentation could prove useful for natural images but may not be suitable for MRI images
which are presented in greyscale images (Shorten and Khoshgoftaar, 2019). Furthermore, traditional data
augmentation methods may introduce distribution shift, i.e., the change of the joint distribution of inputs
and outputs, and consequently adversely impact the performance on non-augmented data during inference1
(i.e., during the application phase of the learned model) (Gong et al., 2021b).
Some recently developed approaches learn parameters for data augmentation that can better improve
downstream task, e.g. segmentation, detection, diagnosis, etc., performance (Chen et al., 2021; Cubuk
et al., 2019; Gao et al., 2021) or select the hardest augmentation for the target model from a small batch of
random augmentations for each traning sample, (Gong et al., 2021a). However, these approaches still use
conventional image transformations and do not consider semantic augmentation (Wang et al., 2021), i.e.,
creating unseen samples by changing semantic information of images such as changing the background
of an object or changing the age of a brain image. Semantic augmentation can complement traditional
techniques and improve the diversity of augmented samples (Wang et al., 2021).
One way to achieve semantic augmentation is to train a deep generative model to create counterfactuals,
i.e., synthetic modiﬁcations of a sample such that some aspects of the original data remain
unchanged (Zhang et al., 2020; Shamsolmoali et al., 2021; Bowles et al., 2018; Oh et al., 2021; Dash et al.,
2022). However, these approaches mostly focus on the training stage of generative models and randomly
generate samples for data augmentation, without considering which counterfactuals are more effective
for downstream tasks, i.e. data-efﬁciency of the generated samples . Wang et al. (2021); Li et al. (2021);
Chen and Su (2021) proposed to augment the data in the latent space of the target deep neural network, by
estimating the covariance matrix of latent features obtained from latent layers of the target deep neural
network for each class (e.g., car, horse, tree, etc.) and sampling directions from the feature distributions.
These directions should be semantic meaningful such that changing along one direction can manipulate one
property of the image, e.g. color of a car. However, there is no guarantee that the found directions will be
semantically meaningful, and it is hard to know which direction controls a particular property of interest.
1 An example could be when training and testing brain MRI data are already well-registered, traditional augmentations, e.g. rotation, shift, etc., on the training
data will hurt the performance of the trained model on testing data. See Section 4.1.3 for more details.
Frontiers
2

Xia et al.
Adversarial Counterfactual Augmentation: Application in AD Classiﬁcation
In this work, we consider the scenario that we have a classiﬁer which we want to improve (e.g. an
image-based classiﬁer of Alzheimer’s Disease (AD) given brain images). We are also given some data and
a pre-trained generative model that is able to create new data given an image as input and conditioning
factors that can alter corresponding attributes in the input. For example, the generative model can alter the
brain age of the input. We propose an approach to guide a pre-trained generative model to generate the most
effective counterfactuals via an adversarial game between the input conditioning factor of the generator
and the downstream classiﬁer, where we use gradient backpropagation to update the conditioning factor
and the classiﬁer alternatively and iteratively. A schematic of the proposed approach is shown in Fig. 1.
Speciﬁcally, we choose the classiﬁcation of AD as the downstream task and utilise a pre-trained brain
ageing synthesis model to improve the AD classiﬁer. The brain ageing generative model used in this paper
is adopted from a recent work (Xia et al., 2021), which takes a brain image and a target age as inputs
and outputs an aged brain image2. We show that the proposed approach can improve the test accuracy of
the AD classiﬁer. We also demonstrate that it can be used in a continual learning3 context to alleviate
catastrophic forgetting, i.e. deep models forget what they have learnt from previous data when training on
new given data, and can be used to alleviate spurious correlations, i.e. two variables appear to be causally
related to one another but in fact they are not. Our contributions can be summarised as follows:
1. We propose an approach to utilise a pre-trained generative model for a classiﬁer via an adversarial game
between conditional input and the classiﬁer. To the best of our knowledge, this is the ﬁrst approach that
formulates such an adversarial scheme to utilise pre-trained generators in medical imaging.
2. We improve a recent brain ageing synthesis model by involving Fourier encoding to enable gradient
backpropagation to update conditional factor and demonstrate the effectiveness of our approach on the task
of AD classiﬁcation.
3. We consider the scenario of using generative models in a continual learning context and show that our
approach can help alleviate catastrophic forgetting.
4. We apply the brain ageing synthesis model for brain rejuvenation synthesis and demonstrate that the
proposed approach has the potential to alleviate spurious correlations.
2
METHODOLOGY
2.1
Notations and problem overview
We denote an image as x ∼X, and a conditional generative model G that takes an image x and a
conditional vector v as input and generates a counterfactual ˆx that corresponds to v: ˆx = G(x, v). For
each x, there is a label y ∼Y. We deﬁne a classiﬁer C that predicts the label ˆy for given x: ˆy = C(x).
In this paper, x is a brain image, y is the AD diagnosis of x, and v represents the target age a and AD
diagnosis on which the generator G is conditioned. We select age and AD status to be conditioning factors
as they are major contributors to brain ageing. We use a brain ageing generative model as G, and a
VGG4-based (Simonyan and Zisserman, 2015) AD classiﬁcation model as C. Note that we only change
the target age a in this paper, thus we write the generative process as ˆx = G(x, a) for simplicity.
2 Code is available at https://github.com/xiat0616/BrainAgeing
3 Deep models continuously learn based on input of new data while preserving previously learnt knowledge.
4 A popular deep learning neural network that has widely been used for classiﬁcation.
Frontiers
3

Xia et al.
Adversarial Counterfactual Augmentation: Application in AD Classiﬁcation
Suppose a pre-trained G and a C are given, the question we want to answer is: “How can we use G to
improve C in a (data) efﬁcient manner”? To this end, we propose an approach to utilise G to improve C
via an adversarial game with gradient backpropagation to update a and C alternatively and iteratively.
2.2
Fourier encoding for conditional factors
The proposed approach requires backpropagation of gradient to the conditional factor to ﬁnd the hard
counterfactuals. However, the original brain ageing synthesis model (Xia et al., 2021) used ordinal encoding
to encode the conditional age and AD diagnosis, where the encoded vectors are discrete in nature and need
to maintain a certain shape, which hinders gradient backpropagation to update these vectors.
To enable gradient backpropagation to update the conditional vectors, we propose to use Fourier encoding
(Tancik et al., 2020; Mildenhall et al., 2020) to encode the conditional attributes, i.e., age and heath state
(diagnosis of AD). The effectiveness of Fourier encoding has been experimentally shown in Tancik et al.
(2020); Mildenhall et al. (2020), and we also achieved similar synthetic results with Fourier encoding
as the original model. The key idea of Fourier encoding is to map low-dimensional vectors to a higher
dimensional domain using a set of sinusoids. For instance, if we have a d-dimensional vector which is
normalised into [0, 1), v ∈[0, 1)d, then the encoded vector can be represented as Tancik et al. (2020):
γ(v) = [p1 cos(2πbT
1 v), p1 sin(2πbT
1 v), ..., pm cos(2πbT
mv), pm sin(2πbT
mv)],
(1)
where bj can be viewed as the Fourier basis frequencies, and p2
j the Fourier series coefﬁcients.
In this work, the vector v represents the target age a and the health status (AD diagnosis), and d = 2. In
our experiments, we set p2
j = 1 for j = 1, ..., m, and bj are independently and randomly sampled from a
Gaussian distribution, bj ∼N(µscale ∗I, 0), where µscale is set to 10. We set m = 100 and the resulting
γ(v) is 200-dimensional. After encoding, the generator G takes the encoded vector γ(v) as input.
The use of Fourier encoding offers two advantages. First, Xia et al. (2021) encoded age and health state
into two vectors and had to use two MLPs to embed the encoded vectors into the model. This may not be a
big issue when the number of factors is small. However, extending the generative model to be conditioned
on tens or hundreds of factors will increase the memory and computation costs signiﬁcantly. With Fourier
encoding, we can encode all possible factors into a single vector, which offers more ﬂexibility to scale the
model to multiple conditional factors. Second, Fourier encoding allows us to compute the gradients with
respect to the input vector v or certain elements of v, since the encoding process is differentiable. As such,
we replace the ordinal encoding with Fourier encoding for all experiments. The generative model G takes
v as input: ˆx = G(x, v), where v represents target age and health state. Since we only change the target
age a in this paper, we write the generative process as ˆx = G(x, a) for simplicity.
2.3
Adversarial counterfactual augmentation
Suppose we have a conditional generative model G and a classiﬁcation model C. The goal is to utilise
G to improve the performance of C. To this end, we propose an approach consisting of three steps:
pre-training, hard sample selection and adversarial classiﬁcation training. A schematic of the adversarial
classiﬁcation training is presented in Fig. 1. Algorithm 1 summarises the steps of the method. Below we
describe each step in detail.
Frontiers
4

Xia et al.
Adversarial Counterfactual Augmentation: Application in AD Classiﬁcation
Algorithm 1 Adversarial counterfactual augmentation with a pre-trained G.
Input: Training set Dtrain; hyperparameter k, N; a pre-trained G; C.
Pre-training:
1. Train the classiﬁer C on Dtrain (Eq. 2).
Hard sample selection:
2. Select N samples from Dtrain that result in highest classiﬁcation errors
for C, denoted as Dhard.
Adversarial classiﬁcation training:
3. Randomly initialize target ages a, and obtain initial synthetic data.
For k do
4. Update a in the direction to maximise classiﬁcation error (Eq. 4).
5. Obtain synthetic images with Dhard and the updated a, denoted as Dsyn.
6. Update C to optimise Eq. 5 on Dtrain ∪Dsyn for one epoch.
Pre-training. The generative model is pre-trained using the same losses as in Xia et al. (2021) except that
we use Fourier encoding to encode age and AD diagnosis. Consequently, we obtain a pre-trained G that
can generate counterfactuals conditioned on given target ages a: ˆx = G(x, a).
The classiﬁcation model C is a VGG-based network (Simonyan and Zisserman, 2015) trained to predict
the AD diagnosis from brain images, optimised by minimising:
Lpre−train = Ex∼Xtrain,y∼YtrainLs(C(x), y),
(2)
where Ls(.) is a supervised loss (binary cross-entropy loss in this paper), x is a brain image, and y is its
ground-truth AD label. To note that if the pre-trained G and C are available in practice, we could avoid the
pre-training step.
Hard sample selection. Liu et al. (2021); Feldman and Zhang (2020) suggested that training data samples
have different inﬂuence on the training of a supervised model, i.e., some training data are harder for the
task and are more effective to train the model than others. Liu et al. (2021) propose to up-sample, i.e.
duplicate, the hard samples as a way to improve the model performance. Based on these observations, we
propose a similar strategy to Liu et al. (2021) to select these hard samples: we record the classiﬁcation
errors of all training samples for the pre-trained C and then select N = 100 samples with the highest errors.
The selected hard samples are denoted as Dhard: {Xhard, Yhard}.
Adversarial classiﬁcation training. (Bowles et al., 2018; Frid-Adar et al., 2018a; Dar et al., 2019)
augmented datasets by randomly generating a number of synthetic data with pre-trained generators. Similar
to training samples, some synthetic data could be more effective for downstream tasks than others. Here
we assume that if a synthetic data sample is hard, then it is more effective for training. We propose an
adversarial game to ﬁnd the hard synthetic data to boost C.
Speciﬁcally, let us ﬁrst deﬁne the classiﬁcation loss for synthetic data as:
LC = Ex∼Xhard,y∼YhardLs(C(ˆx), y),
(3)
where ˆx is a generated sample conditioned on the target age a: ˆx = G(x, a), and y is the ground-truth AD
label for x. Here we assume that changing target age does not change the AD status, thus x and ˆx have the
same AD label.
Frontiers
5

Xia et al.
Adversarial Counterfactual Augmentation: Application in AD Classiﬁcation
Since the encoding of age a is differentiable (see Section 2.2), we can obtain the gradients of LC with
respect to a as: ∇aLC = ∇a[Ls(C(G(x, a)), y)], and update a in the direction of maximising LC by:
˜a = a + γa∇aLC, where γa is the step size (learning rate) for updating a. Formally, the optimization
function of a can be written as:
L1 = max
a
Ex∼Xhard,y∼Yhard Ls(C(ˆx), y).
(4)
Then we could obtain a set of synthetic data using the updated ˜a: ˆxsyn = G(x, ˜a) where x ∼Xhard,
denoted as Dsyn : {Xsyn, Ysyn}.
The classiﬁer C is updated by optimising:
L2 = min
C Ex∼Xcombined,y∼Ycombined Ls(C(x), y),
(5)
where Dcombined: {Xcombined, Ycombined} is a combined dataset consisting of the training dataset and
synthetic dataset: {Xcombined, Ycombined} = {Xtrain ∪Xsyn, Ytrain ∪Ysyn}. Similar to Liu et al. (2021),
we update C on Dcombined instead of Dsyn as we found updating C only on Dsyn can cause catastrophic
forgetting (Kirkpatrick et al., 2017).
The adversarial game is formulated by alternatively and iteratively updating a and classiﬁer C via Eqs. 4
and 5, respectively. In practice, to prevent a from going to unsuitable ages, we clip it to be in [60, 90] after
every update.
Updating a vs. updating G. Note here the adversarial game is formulated between a and C, instead of G
and C. This is because training G against C allows G to change its latent space without considering image
quality, and the output of G could be unrealistic. Please refer to Section 4.1.2 for more details and results.
Counterfactual augmentation vs. conventional augmentation. Here we choose to augment data
counterfactually instead of applying conventional augmentation techniques. This is because that the
training and testing data are already pre-processed and registered to MNI 152, and in this case conventional
augmentations do not introduce helpful variations. Please refer to Section 4.1.3 for more details and results.
2.4
Adversarial classiﬁcation training in a continual learning context
Most previous works (Bowles et al., 2018; Antoniou et al., 2018; Frid-Adar et al., 2018a,b; Shin et al.,
2018; Dar et al., 2019) that used pre-trained deep generative models for augmentation focused on generating
a large number of synthetic samples, and then merged the synthetic data with the original dataset and
trained the downstream task model (e.g. a classiﬁer) on this augmented dataset. However, this requires
training the task model from scratch, which could be inconvenient. For instance, if we suddenly decided to
generate some new synthetic data for augmentation, we would have to retrain the task model from scratch.
Furthermore, if the size of the original dataset is large, then the number of synthetic samples can be huge,
which would make the training process extremely expensive and time-consuming. Thus, in practice, we
need to consider cases where we aim to improve a pre-trained classiﬁer with synthetic data but without
retraining the whole model from scratch. We design the proposed procedure in such a way that allows us to
use the pre-trained G to improve C ﬂexibly.
In Section 2.3, after we obtain the synthetic set Dsyn, we choose to update the classiﬁer C on the
augmented dataset Dsyn ∪Dtrain, instead of Dsyn (stage 6 in Algorithm 1). This is because re-training
the classiﬁer only on the Dsyn would result in catastrophic forgetting (Kirkpatrick et al., 2017), i.e. a
Frontiers
6

Xia et al.
Adversarial Counterfactual Augmentation: Application in AD Classiﬁcation
Algorithm 2 Adversarial classiﬁcation learning with Dstore.
Input: Training dataset Dtrain; hyperparameter M, N, k; a pre-trained generator G; a pre-trained
classiﬁer model C.
Construct Dstore:
1. Randomly select M% data from Dtrain, denoted as Dstore.
Hard sample selection
2. Select N samples from Dstore that result in highest classiﬁcation errors for C, denoted as Dhard.
Adversarial training:
3. Randomly initialise target ages a, and obtain initial synthetic data.
For k do
4. Update a in the direction to maximise classiﬁcation error (Equation 4).
5. Obtain synthetic images with Dhard and the updated a, denoted as Dsyn.
6. Update C to minimise the classiﬁcation error on Dstore ∪Dsyn (Equation 5).
phenomenon where deep neural networks tends to forget what it has learnt from previous data when being
trained on new data samples. To alleviate catastrophic forgetting, efforts have been devoted to developing
approaches to allow artiﬁcial neural networks to learn in a sequential manner (Delange et al., 2021; Parisi
et al., 2019). These approaches are known as continual learning (Delange et al., 2021; Chaudhry et al., 2019;
Lopez-Paz and Ranzato, 2017), lifelong learning (Chen and Liu, 2018; Aljundi et al., 2017), sequential
learning (McCloskey and Cohen, 1989; Aljundi et al., 2018), or incremental learning (Chaudhry et al.,
2018; Gepperth and Karaoguz, 2016). Despite different names and focuses, the main purpose of these
approaches is to overcome catastrophic forgetting and to learn in a sequential manner.
If we consider the generated data as new samples, then the update of the pre-trained classiﬁer C can
be viewed as a continual learning problem, i.e. how to learn new knowledge from the synthetic set
Dsyn without forgetting old knowledge that is learnt from the original training data Dtrain. To alleviate
catastrophic forgetting, we re-train the classiﬁer on both the synthetic dataset Dsyn and the original training
dataset Dtrain. This strategy is known as memory replay in continual learning (Robins, 1995; van de
Ven et al., 2020) and was also used in other augmentation works (Liu et al., 2021). The key idea is to
store previous data in a memory buffer and replay the saved data to the model when training on new data.
However, it could be expensive to store and revisit all the training data, especially when the data size is
large (van de Ven et al., 2020). In Section 4.2, we perform experiments where we only provide a portion
(M%) of training data to the classiﬁer when re-training with synthetic data (to simulate the memory buffer).
We want to see whether catastrophic forgetting would happen or not when only a portion (M%) of training
data is provided, and if so, how much it affects the test accuracies. Algorithm 2 summarises the steps of the
method in the continual learning context.
3
EXPERIMENTAL SETUP
Data. We use the ADNI dataset (Petersen et al., 2010) for experiments. We select 380 AD and 380
CN (control normal) T1 volumes between 60 and 90 years old. We split the AD and CN data into
training/validation/testing sets with 260/40/260 volumes, respectively. All volumetric data are skull-
stripped using DeepBrain5, and linearly registered to MNI 152 space using FSL-FLIRT (Woolrich et al.,
2009). We normalise brain volumes by clipping the intensities to [0, V99.5], where V99.5 is the 99.5% largest
intensity value within each volume, and then rescale the resulting intensities to the range [−1, +1]. We
5 https://github.com/iitzco/deepbrain
Frontiers
7

Xia et al.
Adversarial Counterfactual Augmentation: Application in AD Classiﬁcation
select the middle 60 axial slices from each volume and crop each slice to the size of [208, 160], resulting in
31200 training, 4800 validation and 9600 testing slices.
Implementation. The generator is trained the same way as in Xia et al. (2021), except we replace ordinal
encoding with Fourier encoding. We pre-train the classiﬁer for 100 epochs. The experiments are performed
using Keras and Tensorﬂow. We train pre-trained classiﬁers C with Adam with a learning rate of 0.00001
and decay of 0.0001. During adversarial learning, the step size of a is tuned to be 0.01, and the learning
rate for C is 0.00001. The experiments are performed using a NVIDIA Titan X GPU.
Comparison methods. We compare with the following baselines:
1. Na¨ıve: We directly use the pre-trained C for comparison as the lower bound.
2. RSRS: Random Selection + Random Synthesis. We randomly select N = 100 samples from the training
set Dtrain, denoted as Drand, and then use the generator G to randomly generate Nsynthesis = 5 synthetic
samples for each sample in Drand, denoted as Dsyn. Then we train the classiﬁer on the combined dataset
Dtrain ∪Dsyn for k = 5 steps. This is the typical strategy used by most previous works (Bowles et al.,
2018; Frid-Adar et al., 2018a; Dar et al., 2019).
3. HSRS: Hard Selection + Random Synthesis. We select N = 100 hard samples from Dtrain based on
their classiﬁcation errors of C, denoted as Dhard, and then use the generator G to randomly generate
Nsynthesis = 5 synthetic samples for each sample in Dhard, denoted as Dsyn. Then we train the classiﬁer
on the combined dataset Dtrain ∪Dsyn for k = 5 steps.
4. RSAT: Random Selection + Adversarial Training. We randomly select N = 100 samples from the
training set Dtrain, denoted as Drand, and then use the adversarial training strategy to update the classiﬁer
C, as described in Sec. 2.3.. The difference between RSAT and our approach is that we select hard samples
for generating counterfactuals, while RSAT uses random samples.
5. JTT: Just Train Twice (Liu et al., 2021) record samples that are misclassiﬁed by the pre-trained classiﬁer,
obtaining an error set. Then they construct an oversampled dataset Dup that contain examples in the error
set λup times and all other examples once. Finally, they train the classiﬁer on the oversampled dataset
Dup. In this paper, we set λup = 2 as we found large λup results in bad performance. We also found the
original learning rate (0.01) used for the second training stage results in very bad performance and set it to
be 0.00001.
4
RESULTS AND DISCUSSION
4.1
Improving the performance of classiﬁers.
4.1.1
Comparison with baselines.
We ﬁrst compare our method with baseline approaches by evaluating the test accuracy of the classiﬁers.
We set N = 100 and k = 5 in experiments. We pre-train C for 100 epochs and G as described in Section 3.
The weights of the pre-trained C and the pre-trained G are the same for all methods. For a fair comparison,
the total number of synthetically generated samples is ﬁxed to 500 for RSRS, HSRS, RSAT and our approach.
For JTT, there are 2184 samples mis-classiﬁed by C and oversampled. We initialize a randomly between
real ages of original brain images x and maximal age (90 yrs old).
From Table 1 we can observe that our proposed procedure achieves the best overall test accuracy, followed
by baseline RSAT. This demonstrates the advantage of adversarial training between the conditional factor
Frontiers
8

Xia et al.
Adversarial Counterfactual Augmentation: Application in AD Classiﬁcation
Table 1. Average test accuracies of models trained via our procedure and baselines. We ﬁrst present the
average test accuracies for different age groups with AD (column 2-4) or CN (column 5-7) and then
present the average test accuracies for the whole testing set (column 8). For each method, the worst-group
performance is shown in italic. For each age group, i.e. each column, the best performance is shown in
bold. We also report the number of testing images for each age group.
Acc %
CN
AD
All
Age group
60-70yrs
70-80yrs
80-90yrs
60-70yrs
70-80yrs
80-90yrs
overall
Test group size
1540
1600
1660
1720
1540
1540
9600
Na¨ıve
85.2
91.5
70.7
92.5
94.2
97.1
88.4
RSRS
86.0
90.4
73.8
87.3
95.1
90.0
87.0
HSRS
85.6
91.1
80.4
89.8
93.8
96.9
89.5
RSAT
86.1
93.1
81.5
91.8
96.0
95.7
90.6
JTT
83.9
94.2
80.1
92.8
90.8
93.7
89.2
Proposed
86.4
93.7
83.4
91.5
96.5
95.7
91.1
Table 2. The test precision and recall values for all methods. We ﬁrst present the precision for different
age groups (column 2-4) and all testing data (column 5), and then present the recall for different age groups
(column 6-8) and all testing data (column 9). For each group, the best results are shown in bold.
Age Range
60-70
70-80
80-90
Overall
60-70
70-80
80-90
Overall
Metrics
Precision
Recall
Naive
0.875
0.914
0.761
0.842
0.925
0.942
0.971
0.945
RSRS
0.874
0.905
0.768
0.844
0.873
0.951
0.900
0.906
HSRS
0.874
0.910
0.826
0.866
0.898
0.938
0.969
0.933
RSAT
0.881
0.930
0.832
0.877
0.918
0.960
0.957
0.943
JTT
0.865
0.938
0.822
0.868
0.928
0.908
0.960
0.924
Proposed
0.883
0.936
0.848
0.885
0.915
0.965
0.965
0.945
(target age) a and the classiﬁer. On top of that, it shows that selecting hard examples for creating augmented
synthetic results helps, which is also demonstrated by the improvement of performance of HSRS over Na¨ıve.
We also observe that JTT (Liu et al., 2021) improves the classiﬁer performance over Na¨ıve, showing the
beneﬁt of up-sampling hard samples. In contrast, baseline RSRS achieves the lowest overall test accuracy,
even lower than that of Na¨ıve. This shows that randomly synthesising counterfactuals from randomly
selected samples could result in synthetic images that are harmful to the classiﬁer.
Furthermore, we observe that for all methods, the worst-group performances are achieved on the 80-
90 CN group. A potential reason could be: as age increases, the brains shrink, and it is harder to tell
if the ageing pattern is due to AD or caused by normal ageing. Nevertheless, we observe that for this
worst group, our proposed method still achieves the best performance, followed by RSAT. This shows
that adversarial training can be helpful to improve the performance of the classiﬁer, especially for hard
groups. The next best results are achieved by HSRS and JTT, which shows that ﬁnding hard samples and
up-sampling or augmenting them was helpful to improve the worst-group performance. We also observe
the improvement of worst-group performance for RSRS over Na¨ıve, but the improvement is small compared
to other baselines.
We also report the precision and recall for all methods, as presented in Table 2. We can observe that our
approach achieves the highest overall precision and recall rersults.
In summary, the quantitative results show that it is helpful to ﬁnd and utilise hard counterfactuals for
improving the classiﬁer.
Frontiers
9

Xia et al.
Adversarial Counterfactual Augmentation: Application in AD Classiﬁcation
!: 70
f:
71
72                   73                  74               75                 76                 77                   78                 79                   80
(a) Synthetic results of pre-trained G.
71
72                   73                  74               75                 76                 77                   78                 79                   80
f:
(b) Synthetic results of G after training G v.s. C.
|!) −!|
|!) −!|
!)
!)
Figure 2. The synthetic results for a healthy (CN) subject x at age 70: (a) the results of the pre-trained G,
i.e. before we train G against C; (b) the results of G after we train G against C. We synthesise aged images
ˆx at different target ages a. We also visualise the difference between x and ˆx, |ˆx −x|. For more details see
text.
4.1.2
Train G against C
We choose to formulate an adversarial game between the conditional generative factor a (the target
age) and the classiﬁer C, instead of between the generator G and the classiﬁer C. This is because we
are concerned that an adversarial game between G and C could result in unrealistic outputs of G. In this
section, we perform an experiment to investigate this.
Speciﬁcally, we deﬁne an optimization function:
LG = max
G Ex∼Xtrain,y∼Ytrain Ls(C(G(x, a)), y),
(6)
where we aim to train G in the direction of maximising the loss of the classiﬁer C on the synthetic data
G(x, a).
After every update of G, we construct a synthetic set Dsyn by generating 100 synthetic images from
Dtrain, and update C on Dtrain ∪Dsyn via Equation 5. The adversarial game G vs. C is formulated by
alternatively optimising Equation 6 and 5 for 10 epochs.
In Figure 2, we present the synthetic brain ageing progression of a CN subject before and after the
adversarial training of G vs. C. We can observe that after the adversarial training, the generator G produces
unrealistic results. This could be because there is no loss or constraint to prevent the generator G from
producing low-quality results. The adversarial game only requires the generator G to produce images that
are hard for the classiﬁer C, and naturally, images of low quality would be hard for C. A potential solution
could be to involve a GAN loss with a discriminator to improve the output quality, but this would make
the training much more complex and require more memory and computations. We also measure the test
accuracy of the classiﬁer C after training G against C to be 81.6%, which is much lower than the Na¨ıve
method (88.4%) and our approach (91.1%) in Table 1. The potential reason is that C is misled by the
unrealistic samples generated by G.
Frontiers
10

Xia et al.
Adversarial Counterfactual Augmentation: Application in AD Classiﬁcation
4.1.3
Effect of conventional augmentations for registered brain MRI data.
In this section, we test the effect of applying conventional augmentations, e.g. rotation, shift, scale and
ﬂip, to the training of the AD classiﬁer. These are typical conventional augmentation techniques applied to
computer vision classiﬁcation task. Speciﬁcally, we train the classiﬁer the same way as Na¨ıve, except we
augment training data with conventional augmentations.
Interestingly, we ﬁnd that after applying rotation (range 10 degrees), shift (range 0.2), scale (range 0.2),
and ﬂip to augment the training data, the accuracy of the trained classiﬁer drops from 88.4% to 71.6%. We
then measure accuracies when trained with each augmentation to be 74.1% (rotation), 87.1% (shift), 82.9%
(scale), and 87.8% (ﬂip). This could be because both training and testing data are already pre-processed,
including registered to MNI 152, and these conventional augmentations do not introduce helpful variations
to the training data but distract the classiﬁer from focusing on subtle differences between AD and CN
brains.
We also tried to train the classiﬁer with MaxUp (Gong et al., 2021a) with conventional augmentations.
The idea of MaxUp is to generate a small batch of augmented samples for each training sample and train
the classiﬁer on the worst-performance augmented sample. The overall test accuracy is 57.7%. This could
be because that MaxUp tends to select the augmentations that distract the classiﬁer from focusing on subtle
AD features the most.
The results with conventional aumentations (+MaxUp) suggest that for the task of AD classiﬁcation,
when training and testing data are pre-processed well, conventional data augmentation techniques seem
to not help improve the classiﬁcation performance. Instead, these augmentations distract the classiﬁer
from identifying subtle changes between CN and AD brains. By contrast, the proposed procedure augment
data in terms of semantic information, which could alleviate data imbalance and improve classiﬁcation
performance.
4.2
Adversarial counterfactual augmentation in a continual learning context
4.2.1
Results when re-training with a portion (M%) of training data
Suppose we have a pre-trained classiﬁer C and a pre-trained generator G, and we want to improve C
by using G for data augmentation. However, after pre-training, we only store M% (M ∈(0, 100]) of the
training dataset, denoted as Dstore. During the adversarial training, we synthesise N samples using the
generator G, denoted as Dsyn. Then we update the classiﬁer C on Dstore ∪Dsyn, using Equation 5 where
Dcombined = Dstore ∪Dsyn. The target ages are initialised and updated the same way as in Section 4.1.
Algorithm 2 illustrates the procedure in this section.
Table 3 presents the test accuracies of our approach and baselines when M changes. For Na¨ıve-100, the
results are then same as in Table 1. For JTT, the original paper Liu et al. (2021) retrained the classiﬁer using
the whole training set. Here we ﬁrst randomly select M% training samples as Dstore and ﬁnd misclassiﬁed
data Dmis within Dstore to up-sample, then we retrain the classiﬁer on the augmented set. We can observe
that when M decreases, catastrophic forgetting happens for all approaches. However, our method suffers
the least from catastrophic forgetting, especially when M is small. With M = 20% of training data for
retraining, our approach achieves better results than Na¨ıve. This might be because the adversarial training
between a and C tries to detect what is missing in Dstore and tries to recover the missing data by updating
a towards those directions. We observe that RSAT achieves the second best results, only slightly worse than
the proposed approach. Moreover, HSRS and JTT are more affected by catastrophic forgetting and achieve
Frontiers
11

Xia et al.
Adversarial Counterfactual Augmentation: Application in AD Classiﬁcation
Table 3. Test accuracies of our approach and baselines when the ratio of the size Dstore vs. the size of
Dtrain changes. We can observe the decreases of test accuracies when M decreases, which was due to the
effect of catastrophic forgetting.
Acc %
M%
Methods
1
10
20
50
100
Na¨ıve
N/A
N/A
N/A
N/A
88.4
HSRS
75.6
81.4
84.5
87.4
89.5
RSAT
84.2
85.8
87.2
88.6
90.6
JTT
77.3
82.3
85.1
88.1
89.2
Proposed
84.8
86.8
88.5
89.4
91.1
Table 4. Test accuracies when N changes (M = 1) of our approach and baselines.
acc %
N
Methods
1
10
50
100
HSRS
65.4
71.0
73.4
75.6
RSAT
81.3
82.1
83.2
84.2
Proposed
82.1
82.9
84.1
84.6
worse results. This might be because the importance of selecting hard samples declines as M decreases,
since the Dstore becomes smaller.
These results demonstrate that our approach could alleviate catastrophic forgetting. This could be helpful
in cases where we want to utilise generative models to improve pre-trained classiﬁers (or other task models)
without revisiting all the training data (a continual learning context).
4.2.2
Results when number of samples used for synthesis (N) changes
We also performed experiments where we changed N, i.e. the number of samples used for generating
counterfactuals. Speciﬁcally, we set M = 1, i.e. only 1% of original training data are used for re-training
C, to see how many synthetic samples are needed to maintain good accuracy, especially when there are
only a few training data stored in Dstore. This is to see how efﬁcient the synthetic samples are in terms of
training C and alleviating catastrophic forgetting. The results are presented in Table 4.
From Table 4, we can observe that the best results are achieved by our method, followed by RSAT. Even
with only one sample for synthesis, our method could still achieve a test accuracy of 80%. This is probably
because the adversarial training of a vs. C guides G to generate hard counterfactuals, which are efﬁcient to
train the classiﬁer. The results demonstrate that our approach could help alleviate catastrophic forgetting
even with a small number of synthetic samples used for augmentation. This experiment could also be
viewed as a measurement of the sample efﬁciency, i.e. how efﬁcient a synthetic sample is in terms of
re-training a classiﬁer.
4.3
Can the proposed procedure alleviate spurious correlations?
Spurious correlation occurs when two factors appear to be correlated to each other but in fact they are
not (Simon, 1954). Spurious correlation could affect the performance of deep neural networks and has been
actively studied in computer vision ﬁeld (Sagawa et al., 2020; Liu et al., 2021; Sagawa et al., 2020, 2019;
Youbi Idrissi et al., 2021; Goel et al., 2021) and in medical imaging analysis ﬁeld (Mahmood et al., 2021;
DeGrave et al., 2021). For instance, suppose we have an dataset of bird and bat photos. For bird photos,
most backgrounds are sky. For bat photos, most backgrounds are cave. If a classiﬁer learns this spurious
correlation, e.g. it classiﬁes a photo as bird as long as the background is sky, then it will perform poorly on
Frontiers
12

Xia et al.
Adversarial Counterfactual Augmentation: Application in AD Classiﬁcation
!: 85
f:
83
81                   79                    77                   75                   73
!)
!) −!
Figure 3. Example results of brain rejuvenation for an image (x) of a 85 year old CN subject. We
synthesise rejuvenated images ˆx at different target ages a. We also show the differences between ˆx and x,
ˆx −x. For more details see text.
images where bats are ﬂying in the sky. In this section, we investigate if our approach could correct such
spurious correlations by changing a to generate hard counterfactuals.
Here we create a dataset where 7860 images between 60 and 75 yrs old are AD, and 7680 images
between 75 and 90 yrs old are healthy, denoted as Dspurious. This is to construct a spurious correlation:
young →AD and old →CN (in reality older people have higher chances of getting AD (Goedert and
Spillantini, 2006)). Then we pre-train C on Dspurious. The brain ageing model proposed in Xia et al. (2021)
only considered simulating ageing process, but did not consider brain rejuvenation, i.e., the reverse of
ageing. To utilise old CN data, we pre-train another generator in the rejuvenation direction, i.e.,generating
younger brain images from old ones. As a result, we obtain two generators that are pre-trained on Dtrain,
denoted as Gageing and Grejuve, where Grejuve is trained to simulate the rejuvenation process. Fig. S2
in Supplementary material shows visual results of Grejuve. After that, we select 50 CN and 50 AD hard
images from Dspurious, denoted as Dhard and perform the adversarial classiﬁcation training using Grejuve
for old CN samples and Gageing for young AD samples. The target ages a are initialized as real ages of x.
After we obtain Gageing and Grejuvenation, we select 50 CN and 50 AD images from Dspurious that
result in highest training errors, denoted as Dhard. Note that the selected CN images are between 75 and
90 yrs old, and the AD images are between 60 and 75 yrs old. Then we generate synthetic images from
Dhard using Grejuvenation for old CN samples and Gageing for young AD samples. The target ages a
are initialized as their ground-truth ages. Finally, we perform the adversarial training between a and the
classiﬁer C. Here we want to see if the adversarial training can detect the spurious correlations purposely
created by us, and more importantly, we want to see if the adversarial training between a and C can break
the spurious correlations.
Table 5 presents the test accuracies of our approach and baselines. For Na¨ıve, we directly use the
classiﬁer C pre-trained on Dspurious. For HSRS, we randomly generate synthetic samples from Dhard
for augmentation. For JTT, we simply select mis-classiﬁed samples from Dspurious and up-sample these
samples.
We can observe from Table 5 that the pre-trained C on Dspurious (Na¨ıve) achieves much worse
performance (67.0% accuracy) compared to that of Table 1 (88.4% accuracy). Speciﬁcally, it tends
to misclassify young CN images as AD and misclassify old AD images as CN. This is likely due to the
spurious correlations that we purposely create in Dspurious: young →AD and old →CN. We notice that
Frontiers
13

Xia et al.
Adversarial Counterfactual Augmentation: Application in AD Classiﬁcation
f after adversarial training
f before adversarial training
(a) Target ages f for AD subjects in /%OL(.
(b) Target ages f for CN subjects in /%OL(.
Target age f
Target age f
Number of samples
Number of samples
Figure 4. Histograms of target ages a before and after adversarial training: (a) the histogram of a for the
50 AD subjects in Dhard; (b) the histogram of a for the 50 CN subjects in Dhard. Here we show histograms
of a before (in orange) and after (in blue) the adversarial training.
for Na¨ıve, the test accuracies of AD groups are higher than that of CN groups. This is likely due to the fact
we have more AD training data, and the classiﬁer is biased to classify a subject to AD. This can be viewed
as another spurious correlation. Overall, we observe that our method achieves the best results, followed by
HSRS. This shows that the synthetic results generated by the generators are helpful to alleviate the effect of
spurious correlations and improve downstream tasks. The improvement of our approach over HSRS is due
to the adversarial training between a and C, which guides the generator to produce hard counterfactuals.
We observe JTT does not improve the test accuracies signiﬁcantly. A potential reason is that JTT tries to
ﬁnd ‘hard’ samples in the training dataset. However, in this experiment, the ‘hard’ samples should be young
CN and old AD samples which do not exist in the training dataset Dspurious. By contrast, our procedure
could guide G to generate these samples, and HSRS could create these samples by random chance.
Figure 4 plots the histograms of the target ages a before and after the adversarial training. From Figure 4
we can observe that the adversarial training pushes a towards the hard direction, which could alleviate
the spurious correlations. For instance, in Dspurious and Dhard the AD subjects are all in the young group,
i.e. 60-75 yrs old, and the classiﬁer learns the spurious correlation: young →AD, but in Figure 4 (a) we
can observe that the adversarial training learns to generate AD synthetic images in the range of 75-90 yrs
old. These old AD synthetic images can help alleviate the spurious correlation and improve the performance
of C. Similarly, we can observe a are pushed towards young for CN subjects in Figure 4 (b).
Table 5. Test accuracies for our procedure and baselines when C pre-trained on Dspurious. We ﬁrst present
the average test accuracies for different age groups with CN diagnosis (column 2-3) or AD (column 4-5),
and then present the average test accuracies for the whole testing set (column 6). For each method, the
worst-group performance is shown in italic. For each age group, i.e. each column, the best performance
was shown in bold. For more details see text.
Acc %
CN
AD
Methods
60-75yrs
75-90yrs
60-75yrs
75-90yrs
Overall
Na¨ıve
40.9
81.6
95.1
45.7
67.0
HSRS
60.7
85.3
81.1
67.2
75.0
JTT
50.5
88.4
85.5
40.7
67.9
proposed
73.1
83.4
81.5
75.8
79.0
Frontiers
14

Xia et al.
Adversarial Counterfactual Augmentation: Application in AD Classiﬁcation
5
CONCLUSION
We presented a novel adversarial counterfactual scheme to utilise conditional generative models for
downstream tasks, e.g. classiﬁcation. The proposed procedure formulates an adversarial game between
the conditional factor of a pre-trained generative model and the downstream classiﬁer. We improved
a recent brain ageing synthesis model as the generative model and focused on AD classiﬁcation. We
presented quantitative results showing that our approach can improve the performance of the AD classiﬁer.
Furthermore, we showed that our method could alleviate the effect of catastrophic forgetting and spurious
correlations. There are several future directions. The proposed approach can be potentially applied to
other generators on other datasets. The way we updated the conditional factor (target age) could be
improved. Instead of a continuous scalar (target age), we can consider extending the proposed adversarial
counterfactual augmentation to update other types of conditional factors, e.g., discrete factor or image. The
strategy that we used to select hard samples may not be the most effective and could be improved.
CONFLICT OF INTEREST STATEMENT
The authors declare that the research was conducted in the absence of any commercial or ﬁnancial
relationships that could be construed as a potential conﬂict of interest.
AUTHOR CONTRIBUTIONS
TX, PS, CQ and SAT contributed to the conceptualization of this work. TX, PS, CQ and SAT designed the
methodology. TX developed the software tools necessary for preprocessing and analysing images ﬁles and
for training the model. TX drafted this manuscript. All authors reviewed the manuscript.
ACKNOWLEDGMENTS
This work was supported by the University of Edinburgh, the Royal Academy of Engineering and Canon
Medical Research Europe via PhD studentships of Pedro Sanchez (grant RCSRF1819/825). This work was
partially supported by the Alan Turing Institute under the EPSRC grant EP//N510129//1. S.A. Tsaftaris
acknowledges the support of Canon Medical and the Royal Academy of Engineering and the Research
Chairs and Senior Research Fellowships scheme (grant RCSRF1819/8/25).
REFERENCES
Aljundi, R., Chakravarty, P., and Tuytelaars, T. (2017). Expert gate: Lifelong learning with a network
of experts. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.
3366–3375
Aljundi, R., Rohrbach, M., and Tuytelaars, T. (2018). Selﬂess sequential learning. In International
Conference on Learning Representations
Antoniou, A., Storkey, A., and Edwards, H. (2018). Data augmentation generative adversarial networks.
arXiv preprint arXiv:1711.04340
Bowles, C., Chen, L., Guerrero, R., Bentley, P., Gunn, R., Hammers, A., et al. (2018). Gan augmentation:
Augmenting training data using generative adversarial networks. arXiv preprint arXiv:1810.10863
Chaudhry, A., Dokania, P. K., Ajanthan, T., and Torr, P. H. (2018). Riemannian walk for incremental
learning: Understanding forgetting and intransigence. In Proceedings of the European Conference on
Computer Vision (ECCV). 532–547
Frontiers
15

Xia et al.
Adversarial Counterfactual Augmentation: Application in AD Classiﬁcation
Chaudhry, A., Rohrbach, M., Elhoseiny, M., Ajanthan, T., Dokania, P. K., Torr, P. H. S., et al. (2019).
Continual learning with tiny episodic memories. CoRR abs/1902.10486
Chen, C., Qin, C., Ouyang, C., Wang, S., Qiu, H., Chen, L., et al. (2021). Enhancing mr image segmentation
with realistic adversarial data augmentation. arXiv preprint arXiv:2108.03429
Chen, J. and Su, B. (2021).
Sample-speciﬁc and context-aware augmentation for long tail image
classiﬁcation
Chen, Z. and Liu, B. (2018). Lifelong machine learning. Synthesis Lectures on Artiﬁcial Intelligence and
Machine Learning 12, 1–207
Chlap, P., Min, H., Vandenberg, N., Dowling, J., Holloway, L., and Haworth, A. (2021). A review of
medical image data augmentation techniques for deep learning applications. Journal of Medical Imaging
and Radiation Oncology 65, 545–563
Cubuk, E. D., Zoph, B., Mane, D., Vasudevan, V., and Le, Q. V. (2019). Autoaugment: Learning
augmentation strategies from data. In Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition. 113–123
Dar, S. U., Yurt, M., Karacan, L., Erdem, A., Erdem, E., and C¸ ukur, T. (2019). Image synthesis in
multi-contrast mri with conditional generative adversarial networks. IEEE transactions on medical
imaging
Dash, S., Balasubramanian, V. N., and Sharma, A. (2022). Evaluating and mitigating bias in image
classiﬁers: A causal perspective using counterfactuals.
In Proceedings of the IEEE/CVF Winter
Conference on Applications of Computer Vision. 915–924
DeGrave, A. J., Janizek, J. D., and Lee, S.-I. (2021). Ai for radiographic covid-19 detection selects
shortcuts over signal. Nature Machine Intelligence , 1–10
Delange, M., Aljundi, R., Masana, M., Parisot, S., Jia, X., Leonardis, A., et al. (2021). A continual learning
survey: Defying forgetting in classiﬁcation tasks. IEEE Transactions on Pattern Analysis and Machine
Intelligence
Dietterich, T. (1995). Overﬁtting and undercomputing in machine learning. ACM computing surveys
(CSUR) 27, 326–327
Feldman, V. and Zhang, C. (2020). What neural networks memorize and why: Discovering the long tail via
inﬂuence estimation. arXiv preprint arXiv:2008.03703
Frid-Adar, M., Diamant, I., Klang, E., Amitai, M., Goldberger, J., and Greenspan, H. (2018a). Gan-based
synthetic medical image augmentation for increased cnn performance in liver lesion classiﬁcation.
Neurocomputing 321, 321–331
Frid-Adar, M., Klang, E., Amitai, M., Goldberger, J., and Greenspan, H. (2018b).
Synthetic data
augmentation using gan for improved liver lesion classiﬁcation. In 2018 IEEE 15th international
symposium on biomedical imaging (ISBI 2018) (IEEE), 289–293
Gao, Y., Tang, Z., Zhou, M., and Metaxas, D. (2021). Enabling data diversity: Efﬁcient automatic
augmentation via regularized adversarial training. In International Conference on Information Processing
in Medical Imaging (Springer), 85–97
Gepperth, A. and Karaoguz, C. (2016). A bio-inspired incremental learning architecture for applied
perceptual problems. Cognitive Computation 8, 924–934
Goedert, M. and Spillantini, M. G. (2006). A century of alzheimer’s disease. Science 314, 777–781
Goel, K., Gu, A., Li, Y., and R´e, C. (2021). Model patching: Closing the subgroup performance gap with
data augmentation. ICLR
Frontiers
16

Xia et al.
Adversarial Counterfactual Augmentation: Application in AD Classiﬁcation
Gong, C., Ren, T., Ye, M., and Liu, Q. (2021a). Maxup: Lightweight adversarial training with data
augmentation improves neural network training. In Proceedings of the IEEE/CVF Conference on
Computer Vision and Pattern Recognition. 2474–2483
Gong, C., Wang, D., Li, M., Chandra, V., and Liu, Q. (2021b). Keepaugment: A simple information-
preserving data augmentation approach. In Proceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition. 1055–1064
Kirkpatrick, J., Pascanu, R., Rabinowitz, N., Veness, J., Desjardins, G., Rusu, A. A., et al. (2017).
Overcoming catastrophic forgetting in neural networks. Proceedings of the national academy of sciences
114, 3521–3526
Li, S., Gong, K., Liu, C. H., Wang, Y., Qiao, F., and Cheng, X. (2021). Metasaug: Meta semantic
augmentation for long-tailed visual recognition. In Proceedings of the IEEE/CVF Conference on
Computer Vision and Pattern Recognition. 5212–5221
Liu, E. Z., Haghgoo, B., Chen, A. S., Raghunathan, A., Koh, P. W., Sagawa, S., et al. (2021). Just train
twice: Improving group robustness without training group information. In International Conference on
Machine Learning (PMLR), 6781–6792
Lopez-Paz, D. and Ranzato, M. (2017). Gradient episodic memory for continual learning. Advances in
neural information processing systems 30, 6467–6476
Mahmood, U., Shrestha, R., Bates, D. D. B., Mannelli, L., Corrias, G., Erdi, Y. E., et al. (2021). Detecting
spurious correlations with sanity tests for artiﬁcial intelligence guided radiology systems. Frontiers in
Digital Health 3
McCloskey, M. and Cohen, N. J. (1989).
Catastrophic interference in connectionist networks: The
sequential learning problem. In Psychology of learning and motivation (Elsevier), vol. 24. 109–165
Mildenhall, B., Srinivasan, P. P., Tancik, M., Barron, J. T., Ramamoorthi, R., and Ng, R. (2020). Nerf:
Representing scenes as neural radiance ﬁelds for view synthesis. In European conference on computer
vision (Springer), 405–421
Oh, K., Yoon, J. S., and Suk, H.-I. (2021). Learn-explain-reinforce: Counterfactual reasoning and its
guidance to reinforce an alzheimer’s disease diagnosis model. arXiv preprint arXiv:2108.09451
Parisi, G. I., Kemker, R., Part, J. L., Kanan, C., and Wermter, S. (2019). Continual lifelong learning with
neural networks: A review. Neural Networks 113, 54–71
Petersen, R. C., Aisen, P., Beckett, L. A., Donohue, M., Gamst, A., Harvey, D. J., et al. (2010). Alzheimer’s
disease neuroimaging initiative (ADNI): clinical characterization. Neurology 74, 201–209
Robins, A. (1995). Catastrophic forgetting, rehearsal and pseudorehearsal. Connection Science 7, 123–146
Sagawa, S., Koh, P. W., Hashimoto, T. B., and Liang, P. (2019). Distributionally robust neural networks
for group shifts: On the importance of regularization for worst-case generalization. arXiv preprint
arXiv:1911.08731
Sagawa, S., Raghunathan, A., Koh, P. W., and Liang, P. (2020).
An investigation of why
overparameterization exacerbates spurious correlations.
In International Conference on Machine
Learning (PMLR), 8346–8356
Shamsolmoali, P., Zareapoor, M., Shen, L., Sadka, A. H., and Yang, J. (2021). Imbalanced data learning by
minority class augmentation using capsule adversarial networks. Neurocomputing 459, 481–493
Shen, D., Wu, G., and Suk, H.-I. (2017). Deep learning in medical image analysis. Annual review of
biomedical engineering 19, 221–248
Shin, H.-C., Tenenholtz, N. A., Rogers, J. K., Schwarz, C. G., Senjem, M. L., Gunter, J. L., et al. (2018).
Medical Image Synthesis for Data Augmentation and Anonymization Using Generative Adversarial
Networks. In International Workshop on Simulation and Synthesis in Medical Imaging (Springer), 1–11
Frontiers
17

Xia et al.
Adversarial Counterfactual Augmentation: Application in AD Classiﬁcation
Shorten, C. and Khoshgoftaar, T. M. (2019). A survey on image data augmentation for deep learning.
Journal of Big Data 6, 1–48
Simon, H. A. (1954). Spurious correlation: A causal interpretation. Journal of the American statistical
Association 49, 467–479
Simonyan, K. and Zisserman, A. (2015).
Very deep convolutional networks for large-scale image
recognition. ICLR
Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., and Salakhutdinov, R. (2014). Dropout: a
simple way to prevent neural networks from overﬁtting. The journal of machine learning research 15,
1929–1958
Tancik, M., Srinivasan, P. P., Mildenhall, B., Fridovich-Keil, S., Raghavan, N., Singhal, U., et al. (2020).
Fourier features let networks learn high frequency functions in low dimensional domains. NeurIPS
van de Ven, G. M., Siegelmann, H. T., and Tolias, A. S. (2020). Brain-inspired replay for continual learning
with artiﬁcial neural networks. Nature communications 11, 1–14
Wang, Y., Huang, G., Song, S., Pan, X., Xia, Y., and Wu, C. (2021). Regularizing deep networks with
semantic data augmentation. IEEE Transactions on Pattern Analysis and Machine Intelligence
Woolrich, M. W., Jbabdi, S., Patenaude, B., Chappell, M., Makni, S., Behrens, T., et al. (2009). Bayesian
analysis of neuroimaging data in FSL. Neuroimage 45, S173–S186
Xia, T., Chartsias, A., Wang, C., Tsaftaris, S. A., Initiative, A. D. N., et al. (2021). Learning to synthesise
the ageing brain without longitudinal data. Medical Image Analysis 73, 102169
Youbi Idrissi, B., Arjovsky, M., Pezeshki, M., and Lopez-Paz, D. (2021). Simple data balancing achieves
competitive worst-group-accuracy. arXiv e-prints , arXiv–2110
Zhang, X., Wang, Z., Liu, D., Lin, Q., and Ling, Q. (2020). Deep adversarial data augmentation for
extremely low data regimes. IEEE Transactions on Circuits and Systems for Video Technology 31,
15–28
Frontiers
18

