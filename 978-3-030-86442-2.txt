Philosophical Studies Series
Wolfgang Pietsch
On 
the Epistemology 
of Data Science
Conceptual Tools for a New Inductivism

Philosophical Studies Series
Volume 148
Editor-in-Chief
Mariarosaria Taddeo, Oxford Internet Institute, University of Oxford, Oxford, UK
Editorial Board Member
Patrick Allo, Vrije Universiteit Brussel, Brussel, Belgium
Advisory Editors
Lynne Baker, Department of Philosophy, University of Massachusetts, Amherst,
USA
Stewart Cohen, Arizona State University, Tempe, AZ, USA
Radu Bogdan, Dept. Philosophy, Tulane University, New Orleans, LA, USA
Marian David, Karl-Franzens-Universität, Graz, Austria
John Fischer, University of California, Riverside, Riverside, CA, USA
Keith Lehrer, University Of Arizona, Tucson, AZ, USA
Denise Meyerson, Macquarie University, Sydney, Australia
Francois Recanati, Ecole Normale Supérieure, Institut Jean Nicod, Paris, France
Mark Sainsbury, University of Texas at Austin, Austin, TX, USA
Barry Smith, State University of New York at Buffalo, Buffalo, NY, USA
Nicholas Smith, Department of Philosophy, Lewis and Clark College, Portland, OR,
USA
Linda Zagzebski, Department of Philosophy, University of Oklahoma, Norman, OK,
USA

Philosophical Studies Series aims to provide a forum for the best current research in
contemporary philosophy broadly conceived, its methodologies, and applications.
Since Wilfrid Sellars and Keith Lehrer founded the series in 1974, the book series
has welcomed a wide variety of different approaches, and every effort is made to
maintain this pluralism, not for its own sake, but in order to represent the many
fruitful and illuminating ways of addressing philosophical questions and investigat-
ing related applications and disciplines.
The book series is interested in classical topics of all branches of philosophy
including, but not limited to:
•
Ethics
•
Epistemology
•
Logic
•
Philosophy of language
•
Philosophy of logic
•
Philosophy of mind
•
Philosophy of religion
•
Philosophy of science
Special attention is paid to studies that focus on:
•
the interplay of empirical and philosophical viewpoints
•
the implications and consequences of conceptual phenomena for research as well
as for society
•
philosophies of speciﬁc sciences, such as philosophy of biology, philosophy of
chemistry, philosophy of computer science, philosophy of information, philoso-
phy of neuroscience, philosophy of physics, or philosophy of technology; and
•
contributions to the formal (logical, set-theoretical, mathematical, information-
theoretical, decision-theoretical, etc.) methodology of sciences.
Likewise, the applications of conceptual and methodological investigations to
applied sciences as well as social and technological phenomena are strongly encouraged.
Philosophical Studies Series welcomes historically informed research, but priv-
ileges philosophical theories and the discussion of contemporary issues rather than
purely scholarly investigations into the history of ideas or authors. Besides mono-
graphs, Philosophical Studies Series publishes thematically uniﬁed anthologies,
selected papers from relevant conferences, and edited volumes with a well-deﬁned
topical focus inside the aim and scope of the book series. The contributions in the
volumes are expected to be focused and structurally organized in accordance with
the central theme(s), and are tied together by an editorial introduction. Volumes are
completed by extensive bibliographies.
The series discourages the submission of manuscripts that contain reprints of
previous publishedmaterial and/or manuscripts that are below 160 pages/88,000 words.
For inquiries and submission of proposals authors can contact the editor-in-chief
Mariarosaria Taddeo via: mariarosaria.taddeo@oii.ox.ac.uk
More information about this series at https://link.springer.com/bookseries/6459

Wolfgang Pietsch
On the Epistemology of Data
Science
Conceptual Tools for a New Inductivism

Wolfgang Pietsch
Munich Center for Technology in Society
Technical University of Munich
Munich, Germany
ISSN 0921-8599
ISSN 2542-8349
(electronic)
Philosophical Studies Series
ISBN 978-3-030-86441-5
ISBN 978-3-030-86442-2
(eBook)
https://doi.org/10.1007/978-3-030-86442-2
© Springer Nature Switzerland AG 2022
This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part of the
material is concerned, speciﬁcally the rights of translation, reprinting, reuse of illustrations, recitation,
broadcasting, reproduction on microﬁlms or in any other physical way, and transmission or information
storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar methodology
now known or hereafter developed.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this publication
does not imply, even in the absence of a speciﬁc statement, that such names are exempt from the relevant
protective laws and regulations and therefore free for general use.
The publisher, the authors, and the editors are safe to assume that the advice and information in this
book are believed to be true and accurate at the date of publication. Neither the publisher nor the authors or
the editors give a warranty, expressed or implied, with respect to the material contained herein or for any
errors or omissions that may have been made. The publisher remains neutral with regard to jurisdictional
claims in published maps and institutional afﬁliations.
This Springer imprint is published by the registered company Springer Nature Switzerland AG
The registered company address is: Gewerbestrasse 11, 6330 Cham, Switzerland

To my wife Katja and my parents Ilse and
Bernhard for being the crucial difference
makers.

Preface
While the thoughts of mankind have on many subjects worked
themselves practically right, the thinking power remains as
weak as ever; and on all subjects on which the facts which
would check the result are not accessible, as in what relates to
the invisible world, and even, as has been seen lately, to the
visible world of the planetary regions, men of the greatest
scientiﬁc acquirements argue as pitiably as the merest
ignoramus. For though they have made many sound
inductions, they have not learnt from them (and Dr. Whewell
thinks there is no necessity that they should learn) the
principles of inductive evidence.
(Mill 1886, 284)
After more than two thousand years of Western science, which more than any other
human enterprise has enabled modern civilization with its profound knowledge of
nature and impressive technological achievements, one might think that the meth-
odological basis which ultimately is responsible for these successes should be fairly
well established and understood. Surprisingly, this is not the case. Few areas in
science are more controversial than the foundations of scientiﬁc methodology.
Worse still, where consensus emerges, it often seems to result from shared opinions
and superﬁcial beliefs rather than from sound arguments and precise conceptual
analysis. While humans are quite successful at solving practical problems, the
human mind does not appear to be particularly suited for reﬂecting on the principles
of its own working.
Epistemology and scientiﬁc method once formed part of most science curricula.
In the nineteenth century, methodological treatises such as John Stuart Mill’s A
System of Logic, William Whewell’s The Philosophy of the Inductive Sciences, or
John Herschel’s Preliminary Discourse on the Study of Natural Philosophy were
bestsellers that were discussed widely by the educated public as well as by the
foremost scientists of the time such as Charles Darwin, Michael Faraday, or Charles
Babbage, who is considered one of the fathers of the modern computer. To
vii

considerable extent, this tradition of methodological reﬂection has been abandoned.
For example, some fairly basic issues regarding induction that had been well
understood by scholars such as Herschel or Mill have since been obscured and
neglected, as will be explained in detail later in this volume.
In view of this decline of methodological reﬂection in the sciences, it is not
surprising that there is plenty of confusion regarding the real impact that novel
information technologies such as machine learning and big data are having on
scientiﬁc methodology. Some claim that the scientiﬁc method itself is at stake or
on the verge of being replaced. Others hold that, far from being revolutionary, the
novel developments will eventually ﬁnd their place within traditional scientiﬁc
methodology. Many of the arguments that are brought up in this debate have been
around for decades or even centuries. But these arguments are often used in a
rhetorical manner that lacks careful argumentation and sound conceptual analysis.
A further reason why the impact of these modern developments is so controver-
sial stems from their effect on our self-image. The use of science and technology is
commonly considered one of the distinguishing features of humans in comparison to
other living creatures. Homo sapiens is homo faber, a creative tool-using being that
is able to purposefully change the world. To even consider the possibility that mere
things and machines could be capable of predicting or even understanding the world
to the same extent that humans can is in the eyes of many a sacrilege. Thus, these
novel technologies threaten a profound humiliation to mankind on a scale that is
comparable only to the great intellectual revolutions in history such as the Coperni-
can Revolution, which by removing mankind from the center of the physical cosmos
led to the demise of the ancient Aristotelian worldview in areas as diverse as
astrology or chemistry.
Could there be an artiﬁcial intelligence able to explain, to predict, and to intervene
in ways comparable to human scientists and engineers? Brieﬂy summarized, a
common argument against the possibility of such an intelligence proceeds along
the following lines. First, science allegedly requires intuition and creativity, in
particular when it comes to formulating interesting and meaningful hypotheses.
After all, hypotheses are commonly considered to be at the core of the scientiﬁc
process, and many believe that the true genius of a scientist lies in the formulation of
hypotheses. Second, such intuition and creativity, more or less by deﬁnition, do not
follow general rules and thus are beyond the capabilities of an ultimately rule-based,
algorithm-driven machine. Therefore, artiﬁcial intelligence can never match up to a
human scientist but can at best furnish material that supports human ingenuity.
This argument is mistaken. One crucial reason for taking data science seriously
draws on its various undeniable success stories. As of today, machines not only play
chess better than any human being, but they have recently excelled in areas that
unlike chess cannot be reduced to a relatively small number of abstract rules. Until a
few years ago, such applications were widely believed to be the exclusive domain of
human expertise, except by a small community of AI enthusiasts. In retrospect, these
enthusiasts were right to considerable extent. By now, machine intelligence has
shown capabilities that are at least comparable with human accomplishments in
viii
Preface

areas as diverse as quiz shows, the diagnosis of diseases, image recognition, or
machine translation.
While a number of methods and algorithms in machine learning and data science
have proven astonishingly successful, this success has been mostly heuristic. It is not
supported by a deeper epistemological analysis that could reveal the methodological
underpinnings. To the contrary, as will be shown in the course of this book, some
widespread ideas concerning data science—for example, that correlation is replacing
causation or that theoretical modeling is allegedly coming to an end—are misguided.
Apparently, as Mill stressed in the quote above, scientists can get quite far without a
profound understanding of the actual epistemological foundations, just by trying out
what works well and what not, at times following basic intuitions and analogies with
the human brain. But eventually, one should not expect further advances resulting
from mere trial and error. Rather, a deeper understanding of the epistemological
foundations of data science will be required as guidance.
Because it tries to mimic the epistemological process by which knowledge of the
world is acquired, machine learning essentially is applied epistemology. Thus,
research in both ﬁelds can inform each other. What role should hypotheses play in
artiﬁcial intelligence? Can creativity and intuition be implemented in artiﬁcial
intelligence and is that even necessary? Will machine learning be able to come up
with fundamental theories like quantum mechanics or the theory of evolution? The
complexity and challenges inherent in these problems are often underestimated and
philosophy will certainly play a central role in tackling these questions.
Munich, Germany
Wolfgang Pietsch
Preface
ix

Synopsis
Preface: In which it is observed that human achievements in science and technology
have rarely been matched by an equally profound understanding of scientiﬁc meth-
odology. This familiar pattern from the history of science is repeated in modern
debates on the foundations of data science and machine learning. The many and
impressive successes of these ﬁelds have not been accompanied by a comparable
understanding of their epistemological foundations.
Chapter 1: In which I ﬁrst introduce some basic terminology and then proceed to
formulate ten theses about data science. First, data science, narrowly understood as
the application of machine learning methods to large data sets, leads to the increasing
predictability of complex phenomena, especially to more reliable short-term pre-
dictions. Second, the nature of modeling changes from heavily theory-laden
approaches with little data to simple models using a lot of data. Third, conventional
statistics is insufﬁcient to deal with the data deluge, and novel inductive methodol-
ogy is necessary in order to account for data scientiﬁc practice. Fourth, new types of
formal representation are required for modeling irreducibly complex phenomena.
Fifth, there are strong analogies between exploratory experimentation and data
science. Sixth, causality is the central concept for understanding why data-intensive
approaches can be scientiﬁcally relevant, in particular why they can establish reliable
predictions or allow for effective interventions. Seventh, the conceptual core of
causality in data science consists in difference-making, that is, that a change in
circumstances produces a change in the examined phenomena. Eighth, data science
provides explanations by specifying causes or at least proxies of causes, but not by
referring to unifying principles. Ninth, the increasing automation of science funda-
mentally changes the role of scientiﬁc experts. Tenth, the ethics and epistemology of
data science cannot be separated.
Chapter 2: In which data science is characterized as an inductivist approach, that is,
an approach which aims to start from the facts to infer increasingly general laws and
xi

theories. This perspective is corroborated ﬁrst by a case study of successful scientiﬁc
practice from the ﬁeld of machine translation and second by an analysis of recent
developments in statistics, in particular the shift from so-called data modeling to
algorithmic modeling. Over the past century, inductivism has not been well regarded
by many scientists and philosophers of science. Given that inductivism is generally
considered to be a failed methodology, the fundamental epistemological problem of
data science turns out to be the justiﬁcation of inductivism. Some classic objections
against inductivism are revisited, the most pertinent of which is the so-called
problem of induction. Without a satisfying solution to the problem of induction,
data science seems doomed to failure.
Chapter 3: In which a distinction between phenomenological and theoretical science
is introduced. The former establishes causal knowledge, which can be used for
prediction and possibly manipulation. The latter aims at theoretical and abstract
frameworks, which are non-causal and provide explanations by unifying seemingly
disparate phenomena. Data science belongs to phenomenological science. Some of
the classic arguments against inductivism, in particular underdetermination, theory-
ladenness of observation, and conﬁrmational holism, turn out to be relevant mainly
for theoretical science rather than for phenomenological science. Given that data
science is a phenomenological approach, these arguments cannot undermine the
project of an inductivist data science.
Chapter 4: In which a distinction between enumerative, eliminative, and variational
induction is elaborated. Enumerative induction infers causal relationships from
observed regularities, that is, from the repetition of instances. Eliminative induction
proceeds by eliminating hypotheses from a given exhaustive and mutually exclusive
set. Variational induction infers causal relationships from systematically varying the
circumstances of the examined phenomenon and examining the corresponding
impact on the phenomenon. The quintessential method of the latter is the method
of difference. In part due to the general skepticism concerning inductivist
approaches, variational induction has largely been neglected in twentieth-century
philosophy of science. However, variational induction constitutes the central meth-
odology of phenomenological science. Also, most, if not all, data science and
machine learning algorithms rely on variational induction.
Chapter 5: In which a notion of causation is developed that ﬁts well with scientiﬁc
practice in data science. It is shown that many traditional accounts of causation do
not imply the variational evidence that is typically used in data science. The
approach, which turns out to be most suitable for analyzing data-scientiﬁc practice,
is the counterfactual account. The remainder of the chapter therefore is devoted to
developing a reﬁned version of the counterfactual account of causation which
addresses some of the familiar objections against it. Because the method of differ-
ence plays an essential role, the proposed counterfactual account is referred to as
difference making account. In particular, a somewhat novel approach for evaluating
counterfactual propositions is introduced, which draws heavily on the method of
xii
Synopsis

difference. Causal relevance and causal irrelevance are introduced as the two
fundamental notions, while many traditional analyses of causal dependency have
been based on the necessity and sufﬁciency of circumstances or conditions. Further
concepts are derived from the two fundamental notions, in particular causal factors,
alternative causes and inus complexes. Finally, some classical themes from the
literature on causation are discussed under the perspective of the difference making
account, for example, the time asymmetry of causation, transitivity of causation, or
the role of mechanisms and interventions. The formal framework is summarized in
an appendix.
Chapter 6: In which a reﬁned version of Mill’s inductive methods is proposed that is
based on two fundamental methods, the method of difference to determine causal
relevance and the strict method of agreement to determine causal irrelevance. This
framework for variational induction is supposed to underlie all inductive inferences
in machine learning, data science, and beyond. It is both simpler and more rigorous
than comparable accounts of variational induction. It is argued that the problem of
variational induction is distinct from David Hume’s problem of enumerative induc-
tion. Speciﬁcally, variational induction does not presuppose an indefensible unifor-
mity of nature, but instead the following premises which are more plausible: (i) the
principle of causality that every phenomenon is fully determined by its circum-
stances; (ii) an adequate causal language; (iii) constancy of background;
(iv) repeatability of background and causal conditions. This analysis mitigates the
problem of induction insofar as it is relevant for the project of an inductivist data
science. Since many data science algorithms implement variational induction, the
above analysis can be used to determine the necessary premises in order for these
algorithms to yield reliable results and thus to address the controversial issue of
theory-ladenness in data science.
Chapter 7: In which it is shown that variational induction can also be employed for
concept development. To this purpose, concept formation in phenomenological and
theoretical science is distinguished. The differences between phenomenological and
theoretical concepts largely parallel those between phenomenological and theoreti-
cal laws as discussed in previous chapters. In particular, phenomenological concepts
are local and are mostly used for prediction and manipulation. By contrast, theoret-
ical concepts are universal and mostly ﬁgure in grand explanatory schemes. In
phenomenological science, both deﬁnitions and empirical laws can be formulated
in terms of inus complexes of circumstances relative to a constant background. In the
case of deﬁnitions, necessity and sufﬁciency have a normative character, and in the
case of phenomenological laws, they have an empirical character. Since variational
induction does not depend in essential ways on this character of necessity and
sufﬁciency, it can be employed both for the inference of empirical laws and for
concept formation in phenomenological science. In data science, many machine
learning algorithms relying on variational induction are indeed used for concept
development.
Synopsis
xiii

Chapter 8: In which a causal approach to analogical reasoning is presented. Such
reasoning, which is ubiquitous in data science, addresses the question how evidence
from various phenomena can be combined and made relevant for theory develop-
ment and prediction. First, some inﬂuential accounts of analogical reasoning, both
historical and contemporary, are reviewed focusing in particular on Keynes, Carnap,
Hesse, and more recently Bartha. I argue that enumerative approaches to analogical
reasoning especially in the Carnapian tradition have largely failed, while the episte-
mological assumptions of variational approaches, for example by Keynes, seem
much more plausible. Then, a general framework is sketched. To this purpose, a
distinction between a predictive and a conceptual type of analogical reasoning is
introduced. According to a common intuition, predictive analogical inferences hold
if the differences between source and target concern only irrelevant circumstances. I
attempt to make this idea more precise by addressing possible objections and in
particular by specifying that irrelevance is adequately interpreted in terms of causal
irrelevance based on difference making in homogeneous contexts.
Chapter 9: In which a notion of causal probability is developed that ﬁts with
phenomenological
science
as
well
as
with
variational
induction
and
the
corresponding difference making account of causation. Consequently, the notion is
also adequate for data science. In the proposed account, causation is used to
distinguish between meaningful and accidental relationships, where meaningful
probabilities are those that can be reliably used for prediction and possibly manip-
ulation. In the spirit of variational induction, different types of circumstances or
conditions are distinguished, in particular collective conditions, which remain con-
stant in different trials of a given probabilistic phenomenon, and range conditions,
which can vary and which determine the outcome in a speciﬁc trial of the probabi-
listic phenomenon. Causal probability is then based on the fundamental notion of
causal symmetries. Essentially, a causal symmetry requires that the causal structure
responsible for the probability distribution of outcome events is invariant under a
relabeling of the outcome events. Causal symmetries determine the relative proba-
bilities of the relabeled outcome events according to a rule that is termed the
principle of causal symmetry, which is an objective counterpart to the principle of
insufﬁcient reason. Furthermore, the random nature of subsequent outcomes is
guaranteed by the independence of trials. Such probabilistic independence is also
analyzed in causal terms, essentially in terms of causal irrelevance of the outcome of
a previous trial for the collective conditions of the subsequent trial. A probability
interpretation relying on causal symmetries can be seen as a generalization of
objective interpretations in the tradition of the method of arbitrary functions and
resolves some of their problems. With respect to the distinction between frequencies
and symmetries as the two fundamental types of evidence for probabilistic relation-
ships, frequency interpretations of objective probability are well known. By contrast,
the proposed account attempts to base objective probability solely on symmetries.
xiv
Synopsis

Contents
1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
1.1
Big Data, Machine Learning, and Data Science . . . . . . . . . . . . . .
1
1.2
Ten Theses on Data Science . . . . . . . . . . . . . . . . . . . . . . . . . . .
5
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
10
2
Inductivism . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
11
2.1
Characteristics of Inductivism . . . . . . . . . . . . . . . . . . . . . . . . . .
12
2.2
Data Science as an Inductivist Framework . . . . . . . . . . . . . . . . .
16
2.3
An Example from Data Science . . . . . . . . . . . . . . . . . . . . . . . . .
19
2.4
The Recent Emergence of Inductivist Paradigms in Statistics . . . .
22
2.5
Arguments Against Inductivism . . . . . . . . . . . . . . . . . . . . . . . . .
29
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
35
3
Phenomenological Science . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
37
3.1
Theoretical Versus Phenomenological Science . . . . . . . . . . . . . .
37
3.2
Exploratory Experimentation . . . . . . . . . . . . . . . . . . . . . . . . . . .
47
3.3
Data Science as Phenomenological Science . . . . . . . . . . . . . . . .
50
3.4
Truth in Phenomenological Science—Resolving Duhem’s
Challenge to Inductivism . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
56
3.5
Case Study: Hierarchies in Deep Neural Networks . . . . . . . . . . .
61
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
70
4
Variational Induction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
73
4.1
Enumerative, Eliminative, and Variational Induction . . . . . . . . . .
73
4.2
A Brief History of Variational Induction . . . . . . . . . . . . . . . . . . .
79
4.2.1
Bacon and His Predecessors . . . . . . . . . . . . . . . . . . . . . .
79
4.2.2
Herschel and Mill . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
81
4.2.3
Problems of Mill’s Account of Variational Induction . . . .
85
4.2.4
Twentieth Century Attempts to Solve These Problems . . .
90
4.3
Variational Induction in Machine Learning Algorithms . . . . . . . .
95
4.3.1
Decision Trees . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
96
4.3.2
Naïve Bayes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
98
xv

4.4
Solomonoff Induction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
100
4.5
Computational Learning Theory . . . . . . . . . . . . . . . . . . . . . . . .
102
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
106
5
Causation as Difference Making . . . . . . . . . . . . . . . . . . . . . . . . . . .
109
5.1
Causation in Data Science . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
109
5.1.1
The Argument for Causation . . . . . . . . . . . . . . . . . . . . . .
109
5.1.2
Causation in Data Science . . . . . . . . . . . . . . . . . . . . . . .
112
5.1.3
A Brief Overview of What Is to Come . . . . . . . . . . . . . .
118
5.2
Deﬁning Causation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
119
5.2.1
Causal Relevance and Causal Irrelevance . . . . . . . . . . . .
120
5.2.2
A Difference-Making Account of Causal
Counterfactuals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
125
5.2.3
Remarks on the Asymmetry of Causation . . . . . . . . . . . .
131
5.3
A Causal Calculus . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
133
5.3.1
Causal Factors and Alternative Causes . . . . . . . . . . . . . .
133
5.3.2
Effect Factors and Alternative Effects . . . . . . . . . . . . . . .
138
5.3.3
Causal Hierarchies and Transitivity . . . . . . . . . . . . . . . . .
139
5.3.4
Functional Dependencies . . . . . . . . . . . . . . . . . . . . . . . .
145
5.4
Objections and Criticism . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
147
5.4.1
Objections to Mill’s Method of Difference . . . . . . . . . . . .
147
5.4.2
Objections Against Counterfactual Accounts . . . . . . . . . .
149
5.4.3
Mechanisms and Interventions . . . . . . . . . . . . . . . . . . . .
151
5.4.4
Objections Speciﬁc to the Difference-Making
Account . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
154
5.4.5
Further Scenarios . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
157
Appendix: The Formal Framework . . . . . . . . . . . . . . . . . . . . . . . . . . .
162
A.1 Notation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
162
A.2 Basic Deﬁnitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
163
A.3 Simple Theorems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
167
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
172
6
Evidence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
175
6.1
Mill’s Methods Revisited . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
175
6.2
Hume’s Problem of Induction Revisited . . . . . . . . . . . . . . . . . . .
179
6.3
Data Curation and Theory-Ladenness . . . . . . . . . . . . . . . . . . . . .
184
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
187
7
Concept Formation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
189
7.1
Phenomenological and Theoretical Concepts . . . . . . . . . . . . . . .
189
7.2
Concept Formation in Phenomenological Science . . . . . . . . . . . .
191
7.3
The Problem of Grue . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
195
7.4
Discussion: Supervised and Unsupervised Machine
Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
198
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
200
xvi
Contents

8
Analogy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
201
8.1
Analogy and Data Science . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
201
8.1.1
Analogical Inferences in Data Science and Beyond . . . . .
201
8.1.2
A Brief Overview of What is to Come . . . . . . . . . . . . . . .
204
8.2
Three Historical Perspectives . . . . . . . . . . . . . . . . . . . . . . . . . . .
205
8.2.1
Carnap and the Inadequacy of Enumerative
Approaches . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
205
8.2.2
Keynes and the Ubiquity of Analogical Reasoning . . . . . .
207
8.2.3
Hesse, Bartha and the Two-Dimensional Approach . . . . .
210
8.3
Predictive and Conceptual Analogies . . . . . . . . . . . . . . . . . . . . .
211
8.4
A Deterministic Framework for Predictive Analogies . . . . . . . . .
215
8.4.1
A First Suggestion . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
215
8.4.2
The Notion of Causal Irrelevance . . . . . . . . . . . . . . . . . .
218
8.4.3
A Necessary and Sufﬁcient Criterion . . . . . . . . . . . . . . . .
222
8.4.4
Conceptual Derivation . . . . . . . . . . . . . . . . . . . . . . . . . .
226
8.4.5
Further Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
227
8.5
Analogy and Probability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
231
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
233
9
Causal Probability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
235
9.1
Probability in Data Science . . . . . . . . . . . . . . . . . . . . . . . . . . . .
236
9.1.1
The Debate on Probability in Light of Data Science . . . . .
236
9.1.2
A Brief Overview of What Is to Come . . . . . . . . . . . . . .
239
9.2
Predecessors and Contemporary Debate . . . . . . . . . . . . . . . . . . .
242
9.2.1
Historical Proponents: Cournot, Mill, von Kries . . . . . . . .
242
9.2.2
Contemporary Debate: Abrams, Rosenthal, Strevens . . . .
246
9.2.3
Some Praise . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
249
9.2.4
Critical Reﬂections . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
250
9.3
Induction, Causation, and Probability . . . . . . . . . . . . . . . . . . . . .
251
9.3.1
Enumerative Induction and the Frequency Theory . . . . . .
252
9.3.2
Variational Induction and the Causal Conception of
Probability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
253
9.3.3
A Brief Comparison with Other Accounts . . . . . . . . . . . .
260
9.4
Causal Symmetries and the Principle of Causal Symmetry . . . . . .
264
9.4.1
Causal Symmetries . . . . . . . . . . . . . . . . . . . . . . . . . . . .
264
9.4.2
Further Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
267
9.4.3
The Principle of Causal Symmetry . . . . . . . . . . . . . . . . .
269
9.5
Causal Irrelevance and Probabilistic Independence . . . . . . . . . . .
272
9.5.1
Independence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
272
9.5.2
Interpreting the Measure . . . . . . . . . . . . . . . . . . . . . . . . .
277
9.6
Ontic and Epistemic Probabilities . . . . . . . . . . . . . . . . . . . . . . . .
279
9.6.1
Single-Case Probabilities and Indeterminism . . . . . . . . . .
279
9.6.2
Epistemic and Ontic Probabilities . . . . . . . . . . . . . . . . . .
280
9.6.3
Probabilities from Causal Symptoms . . . . . . . . . . . . . . . .
281
9.6.4
Probabilities of Causal Hypotheses . . . . . . . . . . . . . . . . .
282
Contents
xvii

9.7
Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
285
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
286
10
Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
289
Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
291
xviii
Contents

Chapter 1
Introduction
Abstract In this Chapter, I ﬁrst introduce some basic terminology and then proceed to
formulate ten theses about data science. First, data science, narrowly understood as the
application of machine learning methods to large data sets, leads to the increasing
predictability of complex phenomena, especially to more reliable short-term predic-
tions. Second, the nature of modeling changes from heavily theory-laden approaches
with little data to simple models using a lot of data. Third, conventional statistics is
insufﬁcient to deal with the data deluge, novel inductive methodology is necessary in
order to account for data scientiﬁc practice. Fourth, new types of formal representation
are required for modeling irreducibly complex phenomena. Fifth, there are strong
analogies between exploratory experimentation and data science. Sixth, causality is
the central concept for understanding why data-intensive approaches can be scientiﬁ-
cally relevant, in particular why they can establish reliable predictions or allow for
effective interventions. Seventh, the conceptual core of causality in data science
consists in difference-making, i.e. that a change in circumstances produces a change
in the examined phenomena. Eighth, data science provides explanations by specifying
causes or at least proxies of causes, but not by referring to unifying principles. Ninth,
the increasing automation of science fundamentally changes the role of scientiﬁc
experts. Tenth, the ethics and epistemology of data science cannot be separated.
Keywords Data science · Big data · Machine learning · Inductivism · Causality ·
Difference making · Exploratory experimentation
1.1
Big Data, Machine Learning, and Data Science
When assessing the signiﬁcance of modern information technology for scientiﬁc
methodology, one is confronted with a confusing number of buzzwords: big data,
machine learning, artiﬁcial intelligence, data science, predictive analytics, among
© Springer Nature Switzerland AG 2022
W. Pietsch, On the Epistemology of Data Science, Philosophical Studies Series 148,
https://doi.org/10.1007/978-3-030-86442-2_1
1

others. In this chapter, I brieﬂy address how these notions relate to each other and the
epistemological analysis which is the topic of this book.
Data science is the scientiﬁc practice of extracting knowledge from data, usually
referring to large and complex bodies of data. The term, as it is used in contemporary
debates, often seems to imply a novel kind of science that differs from more
conventional approaches in that it puts data at the center of the scientiﬁc analysis.
Of course, all science relies on data to some extent, in particular the so-called
empirical sciences, ranging from physics to sociology, from biology to economics.
After all, empirical science, by its very deﬁnition, starts from experience (Greek:
empeiría), i.e. from data extracted from observation and experiment. Do all these
disciplines then form part of data science? Is data science just empirical science?
Maybe data science differs from conventional empirical science, because a
speciﬁc understanding of ‘data’ is involved? Data, of course, derives from the
Latin word ‘datum’ (pl. data), relating to something which is ‘given’. A number of
epistemological analyses have addressed how the notion could be interpreted (see
e.g. Floridi 2008 for an overview; Leonelli 2016).1 Fortunately, we do not have to
delve into terminological details here, since the present context of scientiﬁc meth-
odology clearly indicates that data is best understood as something ‘given’ in terms
of evidence, i.e. as ‘given’ by more or less direct observation or measurement. For
our purposes, a datum thus is a record of empirical evidence for a phenomenon,
which ﬁts well with an inﬂuential analysis of James Bogen and James Woodward
(1988; cp. also Woodward 2011, 166).2 Thus, a fairly conventional understanding of
data can be employed for the epistemological analysis of data science, which is the
subject of the present book.
Perhaps it comes down to a matter of quantity in that data science relies more
extensively on data compared with traditional empirical science and largely dis-
penses with theory and theoretical assumptions. At the very least, such a perspective
captures important aspects of data-scientiﬁc practice, in particular that data science
puts the focus on data and highlights various steps in the scientiﬁc analysis of data,
1Luciano Floridi, the leading contemporary philosopher of information, presents an interesting
overview distinguishing four analyses (2008; see also Lyon 2016, Sec. 2). (1) According to the
epistemic interpretation, data are just collections of facts. But clearly, this analysis does not ﬁt well
with the common usage of the term ‘data’, since data can be stored and processed—can be
encrypted, compressed, or deleted—while facts cannot. (2) The informational interpretation iden-
tiﬁes data with information, but nothing much is gained without a thorough understanding of what
information is. Also, information is generally considered to be derived from data, but not identical
with the data. (3) The computational interpretation is closest to the technological perspective of
computer scientists. It understands data in terms of a collection of binary elements that are processed
and transmitted electronically. But this approach is too narrow for our purposes, since it conﬁnes the
notion of data to the context of modern computational science. (4) Finally, Floridi develops and
defends what he calls the diaphoric interpretation, according to which a datum is a lack of
uniformity.
2Bogen and Woodward’s distinction between data, phenomena, and theories ﬁts quite well the
framework that will be proposed in Chap. 3.
2
1
Introduction

from data gathering to data curation to basic data analysis, while being largely silent
on more abstract theoretical modeling.
Some distinguish between data-driven and data-intensive science, wherein the
latter is just conventional theory-dependent science, but with a lot of data. Thus, a
particularly important task in data-intensive science is the development of complex
models and theories.3 By contrast, data-driven science focuses on data and its
analysis rather than on the elaboration of complex theoretical constructs as in
more traditional scientiﬁc approaches. More speciﬁcally, data-driven science
works on the assumption that at least some scientiﬁc analyses do not require
substantial background theory. From the perspective of this book, a crucial question
is to what extent such a ‘theory-free’ approach is possible at all, given that science as
we know it is mostly theory-dominated.
In some of the pertinent literature, the term ‘data-intensive science’ is used
differently, namely synonymously with data-driven science. Jim Gray, a Turing
Award winner, introduced the inﬂuential idea that data-intensive science should be
seen as a ‘fourth paradigm’ in scientiﬁc research, in addition to theory, experiment,
and simulation: “The world of science has changed, and there is no question about
this. The new model is for the data to be captured by instruments or generated by
simulations before being processed by software and for the resulting information or
knowledge to be stored in computers. Scientists only get to look at their data fairly
late in this pipeline. The techniques and technologies for such data-intensive science
are so different that it is worth distinguishing data-intensive science from computa-
tional science as a new, fourth paradigm for scientiﬁc exploration.” (Gray 2007, xix).
Gray highlights an important aspect: in data science much of the scientiﬁc process
is automated. Consequently, the epistemic circumstances under which science takes
place are not determined anymore by the human cognitive apparatus, but rather by
the computer. In particular, storage capacity and processing speed of the data vastly
differ between computer and human. Thus, ‘machine science’ can examine phe-
nomena, which from the perspective of a ‘human science’ are too complex to
reliably predict or to effectively manipulate, because these phenomena involve too
many variables or because the dependencies between the variables cannot be
represented by sufﬁciently simple functions. In this way, scientiﬁc knowledge can
be generated by data science which is no longer accessible to the human mind.
This leads to the notion of big data. Like all the other concepts addressed above,
big data is an ambiguous and malleable term and can mean quite different things in
different contexts from computer science to economics. Essentially, the notion of big
data just highlights that in science but also in many practical applications one is
increasingly dealing with data sets that are much larger than ever before. Of course,
this so-called data deluge results primarily from advances in modern information
technology, in particular the development of the internet and its ongoing extension
into an internet of things. The internet has made formerly unthinkable modes of data
3I have used the term data-intensive science differently in earlier papers, but now think that this
explication is more suitable.
1.1
Big Data, Machine Learning, and Data Science
3

collection possible that are largely unrestricted by spatial distances. With the internet
of things and the increasing availability of cheap sensors for almost everything from
humidity to blood pressure, the amount of data will only continue to grow. And all of
this data naturally is connected and connectable with other data, given that we are
essentially dealing with one giant network.
In the literature, big data is often further speciﬁed with reference to the so-called
3 V’s, i.e. the amount of data (Volume), the data rate (Velocity) and, ﬁnally, the
heterogeneous structure of the data (Variety) (see Laney 2001). This approach has
sometimes been extended to include 4, 5 or even 7 V’s. While such a deﬁnition
seems adequate when focusing on the technical challenges of dealing with large
datasets, it proves largely unsuitable for addressing the epistemological and meth-
odological issues that are of interest in this book. The main problem lies in the
exclusive focus on the data and its structure while neglecting the algorithms and
methods of data processing, in other words the scientiﬁc methodology with which
data is evaluated. Furthermore, volume, velocity, and variety are all relational
concepts, as Luciano Floridi has pointed out (2012, 435). For example, whether
data is big depends on the size of data sets that scientists are used to handle at a
certain moment in history. Consequently, the big data of today could easily be the
small data of tomorrow, depending for example on the progress of technological
hardware. Just emphasizing the sheer amount of data thus fails to establish any
interesting developments with respect to scientiﬁc methodology.
Apparently, conventional ‘human’ science, essentially due to human cognitive
restrictions, is not anymore able to deal with the deluge of data with which many
areas of science are currently confronted. By contrast, artiﬁcial intelligence or
machine learning may be in a more promising position, since these possess the
data storage capability and processing power to analyze such enormous data sets.
Here, artiﬁcial intelligence is the wider term that includes the full range of intellec-
tual activities such as theorizing, formation of analogies, problem solving, creativity,
planning, etc. By contrast, machine learning refers more narrowly to learning from
experience. In other words, machine learning is the part of artiﬁcial intelligence that
attempts to infer knowledge from (big) data sets, where the respective knowledge is
not explicitly programmed but is acquired by the program itself.4 Consequently,
most machine learning algorithms reason chieﬂy inductively, while artiﬁcial
4Cp. Bernard Marr’s analysis in Forbes: “Artiﬁcial Intelligence is the broader concept of machines
being able to carry out tasks in a way that we would consider ‘smart’. And, Machine Learning is a
current application of AI based around the idea that we should really just be able to give machines
access to data and let them learn for themselves.” (https://www.forbes.com/sites/bernardmarr/2016/
12/06/what-is-the-difference-between-artiﬁcial-intelligence-and-machine-learning/
#79566b142742) Gregory Wheeler writes: “Machine learning, like statistics, is interested in the
question of what can be inferred from data. But unlike statistics, machine learning aims to
circumvent the requirement to explicitly set modeling assumptions prior to drawing meaningful
inferences or, when unavoidable, seeks to design algorithms that learn on their own what modeling
assumptions are best to select.” (2016) The relation between machine learning and epistemology is
discussed for example by Kevin Korb (2004) and Jon Williamson (2004).
4
1
Introduction

intelligence includes the whole range of possible inferences, including deduction and
abduction.
To conclude this brief and somewhat superﬁcial overview of relevant terminol-
ogy, let me explain how I will use the term ‘data science’ in the remainder of
this book: as the application of machine learning approaches relying on big data
with the aim of predicting complex phenomena rather than explaining them. Some,
mostly outside academia and in particular in business, speak of predictive analytics
(Siegel 2013).
More speciﬁcally, a proposal for a deﬁnition of data science tailored to the context
of scientiﬁc methodology is:
Data science refers to the systematic collection and analysis of data sets that represent a large
part of all possible variations of a complex phenomenon,5 such that the relevant causal
structure of the phenomenon can be inferred algorithmically without further theoretical
background assumptions.
I will later return to the details of this deﬁnition, in particular the importance of
variational evidence, the relative theory-independence and the focus on causality.
One might further specify that the phenomena studied in data science typically are so
complex that automated methods yield more accurate predictions compared with
traditional approaches of a ‘human science’. Due to the automation of data collection
and analysis, many more predictor variables can be taken into account—as well as
data points that link certain values for the predictor variables with corresponding
values of the response variables. In this twofold sense, data science deals with big
data.
1.2
Ten Theses on Data Science
In the following, some key characteristics of data science will be laid out in a number
of theses, all of which will be elaborated in further detail later in the book. Let us start
with the great promise of data science:
First thesis: Data science, understood as the application of machine learning methods to large
data sets, leads to the increasing predictability of complex phenomena, especially to more
reliable short-term predictions.
This essentially follows from the described change in epistemic circumstances,
particularly the improved ways of storing and processing data, in combination with
an inductive methodology. The central role of inductivism for the methodological
underpinning of data science will be discussed in Chap. 2.
5i.e. variational evidence.
1.2
Ten Theses on Data Science
5

A crucial distinction is between emergent and irreducible complexity.6 Emergent
complexity can arise for phenomena that are describable with a relatively simple
system of laws or instructions, i.e. a model with few variables and well-deﬁned
dependencies between the variables. The complex dynamics usually originates in
nonlinearities of the underlying laws, which imply that the system behavior is
strongly sensitive to small variations in the initial conditions. Typical systems with
emergent complexity are treated in the physics of non-equilibrium or in chaos
theory, for example, the double pendulum, simple predator-prey systems, or Ray-
leigh-Bénard convection.
By contrast, phenomena that are irreducibly complex cannot be accounted for in
terms of a few equations with a small number of variables and clearly deﬁned
dependencies. Instead, a large number of diverse elements interact according to
complicated dependencies. Dynamic complexity is not emergent, since the complex
dynamics cannot be derived from a simple underlying model. Rather, the phenom-
enon itself is irreducibly complex. Of course, all the characteristics of emergent
complexity may still be present such as nonlinearities, feedback loops, or the lack of
additivity.
Data science is particularly advantageous for dealing with this latter form of
complexity. After all, in order to properly model irreducibly complex phenomena, a
large amount of evidence is required. From what we know today, such irreducibly
complex phenomena exist in almost all applied sciences, especially the social
sciences, medicine, and biology. By contrast, phenomena in the theoretical sciences,
especially in physics, are usually only complex in the emergent sense. To some
extent, this is due to the deliberate focus in many theoretical sciences on a small
number of supposedly paradigmatic phenomena.
The fact that data science analyzes irreducibly complex phenomena leads to a
speciﬁc type of modeling:
Second thesis: With data science, the nature of modeling changes from heavily theory-laden
approaches with little data to simple models using a lot of data.
When dealing with emergent complexity, theoretical background knowledge can
ﬁx the basic structure of the dependencies between variables. For instance, the
relevant equations of the double pendulum can be derived from the fundamental
laws of mechanics. A few sufﬁciently accurate and well-chosen data points sufﬁce to
determine the additional parameters of the model. For example, an ordinary double
pendulum has four parameters, the two masses and the lengths of the two arms.
By contrast, in the case of irreducible complexity, an adequate model cannot be
determined from a small number of simple theoretical background assumptions but
must instead be inferred from the data. This leads to the inductivist and largely
theory-free approach of data science as mentioned above. The classic example for
the change in modeling that is described in the second thesis stems from machine
6A closely related distinction between compositional and dynamic complexity is developed by
Meinard Kuhlmann (2011; see also Mitchell 2008).
6
1
Introduction

translation, where a data-driven approach has turned out to be much more successful
than a rule-based approach. This example will be presented in Sect. 2.3.
In other words, inductive methodology has proven much more adequate for data
science compared with a hypothetico-deductive approach based on theoretical
background knowledge and complex modeling assumptions. This is remarkable
insofar as inductivism was mostly frowned upon in the twentieth century—not
least in statistics. To this day, many statisticians maintain that any sound statistical
approach must necessarily involve substantial modeling, which leads us to the third
thesis:
Third thesis: Conventional statistics is insufﬁcient to deal with the data deluge; novel
inductive methodology is necessary in order to account for data science.
The thesis can be illustrated by recent developments in statistics, which will be
examined in Sect. 2.4. In a well-known essay on this topic that will also be discussed,
the statistician Leo Breiman introduces a distinction between data modeling, which
basically is conventional model-driven statistics, and algorithmic modeling, which
can be exempliﬁed by machine learning.
It turns out that such algorithmic models no longer can be represented in terms of
coupled systems of equations, the mathematical paradigm that has dominated sci-
ence for centuries. Traditionally, for example in physics, partial differential equa-
tions reﬂected the dynamics of the system variables, for instance Hamilton’s
equations in classical mechanics or the Schrödinger equation in quantum mechanics.
It follows:
Fourth thesis: New types of formal representation are required for modeling irreducibly
complex phenomena.
To model complex phenomena, discrete, scalable structures are often employed,
especially networks (e.g. decision trees, neural networks, or Bayesian networks).
The medium for representation changes as well. The sheet of paper, the book, or the
human brain is increasingly replaced by the computer, which alone seems capable to
develop models on the required scale of many irreducibly complex phenomena.
The distinction between model-driven and data-driven approaches in statistics ﬁts
well with a broader distinction between theoretical and phenomenological science,
which will be elaborated in Chap. 3. Broadly speaking, phenomenological science
relies on an inductive approach aiming at causal knowledge, which mainly serves for
prediction and manipulation of phenomena. By contrast, theoretical science employs
a hypothetico-deductive methodology developing non-causal theoretical frame-
works mainly for explanatory purposes. In phenomenological science, experimen-
tation has a largely exploratory role, while in theoretical science, experimentation is
mainly theory-driven, as will be argued in Sect. 3.2:
Fifth thesis: There are strong analogies between exploratory experimentation and data
science.
Exploratory experimentation and data science are remarkably similar. Most
importantly, a substantial theory-independence characterizes both scientiﬁc prac-
tices. Moreover, both share a logic of variable variation, by which the impact of
1.2
Ten Theses on Data Science
7

changing conditions or circumstances on the phenomenon is examined and thereby
the causal structure of the examined phenomena is determined.
While it is generally accepted that exploratory experimentation aims at causal
knowledge, for data science many deny a central role for causation. For example, in a
widely quoted article in the technology magazine WIRED, Chris Anderson writes
that in the wake of big data, causality is being replaced by correlation (2008).
Similarly, Viktor Mayer-Schönberger and Kenneth Cukier claim that big data
implies “a move away from the age-old search for causality” (2013, p. 14). As I
will argue in Chaps. 4 and 5, the opposite is the case:
Sixth thesis: Causality is the central concept for understanding why data-intensive
approaches can be scientiﬁcally relevant, in particular why they can establish reliable pre-
dictions or allow for effective interventions.
In a nutshell, the argument for this thesis can be illustrated with the following
quotation by Nancy Cartwright: “causal laws cannot be done away with, for they are
needed to ground the distinction between effective strategies and ineffective ones”
(1979, p. 420). Because data science aims at effectively manipulating phenomena,
correlations are not sufﬁcient but rather causal connections must be established—for
example, if Facebook wants to nudge its members to spend as much time as possible
on the social network or if Google wants its users to click on certain advertising
links.
Causation, of course, is one of the most controversial concepts in scientiﬁc
methodology. One ﬁnds in the history of science and still in contemporary science
both extremes: prominent voices that completely reject causation as an incoherent
concept, but also the opposite view that scientiﬁc knowledge must always be of
causal nature. This conﬂict can only be resolved by further specifying what exactly
one means by causality:
Seventh thesis: The conceptual core of causality in data science consists in difference-
making, i.e. that a change in circumstances produces a change in the examined phenomena.
In Chap. 4, I will argue that a variational approach to causal inference is crucial
for understanding the role of causality in data science. More exactly, many algo-
rithms in data science will be shown to rely on John Stuart Mill’s method of
difference (Sects. 3.5 and 4.3).
In the relevant literature, the idea that correlation replaces causation is often
connected with the lack of explanation in data science. “Without causation no
explanation,” runs a widespread argument. While it is true that data science does
not yield profound explanations, this has little to do with the role of causation.
Rather, it results from the nature of data science as a phenomenological science. If
causality is understood in terms of difference-making, as suggested above, then
causal relationships are not explanatory in a strong sense. This leads to the eighth
thesis:
Eighth thesis: Data science provides explanations by specifying causes or at least proxies of
causes, but not by referring to unifying principles.
8
1
Introduction

As already stated, this thesis is closely related with the aforementioned distinction
between phenomenological and theoretical science. Nancy Cartwright has intro-
duced two different types of explanation that one might call ‘causal explanation’
on the one hand and ‘unifying explanation’ on the other: “there are two quite
different kinds of things we do when we explain a phenomenon [. . .] First, we
describe its causes. Second, we ﬁt the phenomenon into a theoretical frame.”
(Cartwright 1983, p. 16) The second type of explanation is reserved largely for
theoretical sciences, while the ﬁrst type is more prevalent in phenomenological
sciences. Since data science is conﬁned primarily to the phenomenological level,
only the much weaker form of explanation referring to causes in terms of difference-
makers can be realized (Sect. 3.3).
In the wake of data science, various disciplines such as medicine or the social
sciences are increasingly perceived as phenomenological rather than theoretical
sciences. In other words, scientists focus on the collection of data rather than on
the development of theoretical schemes. Also, it is increasingly acknowledged that
for irreducibly complex phenomena in these ﬁelds, scientiﬁc explanations in the
conventional sense are not feasible, while manipulation and prediction remain
possible. Since only the computer, rather than the human scientist, can analyze
many of these complex phenomena, one ﬁnds:
Ninth thesis: The increasing automation of science fundamentally changes the role of
scientiﬁc experts.
Due to the limitations of the human cognitive apparatus, the computer will
eventually outpace the human scientist in certain tasks in science. In some areas,
the role of human experts is already changing accordingly. An example which we
have already referred to is that grammatical knowledge of human experts seems no
longer required for developing machine translation programs. As another example,
recommendations of online bookshops are no longer written by cultural journalists,
but are algorithmically generated, which at least from a ﬁnancial perspective turns
out to be extremely successful.
These transformations and their consequences for the labor market illustrate the
enormous impact of data science on society at large. In fact, the ethical relevance of
the current developments reaches far beyond the ubiquitous debate on privacy. The
latter is indisputably important, but the improved capabilities for predicting and
manipulating complex phenomena by means of data science, for example in the
social sciences or in medicine, as well as the use of data-driven predictions for
developing new products such as automated driving lead to a much larger variety of
mostly unanswered ethical questions. It should however be noted:
Tenth thesis: The ethics and epistemology of data science cannot be separated.
Most ethical problems related to data science can only be addressed if the
epistemological foundations are broadly understood. Therefore, in the present
book I will focus on an epistemological analysis and will leave the discussion of
ethical questions for another occasion.
1.2
Ten Theses on Data Science
9

Acknowledgements This chapter is a revised version of Chapter 2 in Wolfgang Pietsch, Jörg
Wernecke, Maximilian Ott (eds.), Berechenbarkeit der Welt, Wiesbaden: Springer VS (2017).
Permission by co-author Jörg Wernecke has been kindly granted.
References
Anderson, Chris. 2008. The End of Theory: The Data Deluge Makes the Scientiﬁc Method
Obsolete. WIRED Magazine 16/07. http://www.wired.com/science/discoveries/magazine/16-
07/pb_theory
Bogen, James, and James Woodward. 1988. Saving the Phenomena. The Philosophical Review
97 (3): 303.
Cartwright, Nancy. 1979. Causal Laws and Effective Strategies. Noûs 13 (4): 419–437.
———. 1983. How the Laws of Physics Lie. Oxford: Oxford University Press.
Floridi, Luciano. 2008. Data. In International Encyclopedia of the Social Sciences, ed. W.A. Darity.
———. 2012. Big Data and Their Epistemological Challenge. Philosophy & Technology 25 (4):
435–437.
Gray, Jim. 2007. Jim Gray on eScience: A Transformed Scientiﬁc Method. In The Fourth Para-
digm. Data-Intensive Scientiﬁc Discovery, ed. Tony Hey, Stewart Tansley, and Kristin Tolle.
Redmond: Microsoft Research.
Korb, Kevin B. 2004. Introduction: Machine Learning as Philosophy of Science. Minds and
Machines 14: 433–440.
Kuhlmann, Meinard. 2011. Mechanisms in Dynamically Complex Systems. In Causality in the
Sciences, ed. P. McKay Illari, F. Russo, and J. Williamson, 880–906. Oxford: Oxford University
Press.
Laney, Doug. 2001. 3D Data Management: Controlling Data Volume, Velocity, and Variety.
Research Report. http://blogs.gartner.com/doug-laney/ﬁles/2012/01/ad949-3D-Data-Manage
ment-Controlling-Data-Volume-Velocity-and-Variety.pdf
Leonelli, Sabina. 2016. Data-Centric Biology: A Philosophical Study. Chicago: University of
Chicago Press.
Lyon, Aidan. 2016. Data. In The Oxford Handbook of Philosophy of Science, ed. Paul Humphreys.
Oxford: Oxford University Press.
Mayer-Schönberger, Viktor, and Kenneth Cukier. 2013. Big Data. London: John Murray.
Mitchell, Sandra. 2008. Komplexitäten. Warum wir erst anfangen, die Welt zu verstehen. Frankfurt
a.M.: Suhrkamp.
Siegel, Eric. 2013. Predictive Analytics. Hoboken: John Wiley & Sons.
Wheeler, Gregory. 2016. Machine Epistemology and Big Data. In The Routledge Companion to
Philosophy of Social Science, ed. L. McIntyre and A. Rosenberg. Routledge.
Williamson, Jon. 2004. A Dynamic Interaction Between Machine Learning and the Philosophy of
Science. Minds and Machines 14: 539–549.
Woodward, James F. 2011. Data and Phenomena: a Restatement and Defense. Synthese 182 (1):
165–179.
10
1
Introduction

Chapter 2
Inductivism
Abstract In this Chapter, data science is characterized as an inductivist approach,
i.e. an approach which aims to start from the facts to infer increasingly general laws
and theories. This perspective is corroborated ﬁrst by a case study of successful
scientiﬁc practice from the ﬁeld of machine translation and second by an analysis of
recent developments in statistics, in particular the shift from so-called data modeling
to algorithmic modeling. Over the past century, inductivism has not been well
regarded by many scientists and philosophers of science. Given that inductivism is
generally considered to be a failed methodology, the fundamental epistemological
problem of data science turns out to be the justiﬁcation of inductivism. Some classic
objections against inductivism are revisited, the most pertinent of which is the
so-called problem of induction. Without a satisfying solution to the problem of
induction, data science seems doomed to failure.
Keywords Data science · Inductivism · Hypothetico-deductivism · Problem of
induction · Algorithmic modeling · Non-parametric · Machine translation
As we have seen in the previous chapter, data science is a strongly inductivist
approach and the main epistemological problem of data science is the justiﬁcation
of inductivism.
Unfortunately, this seems like a hopeless endeavor, since for much of the
twentieth century inductivism has been almost universally rejected by both episte-
mologists and scientists. Consensus has emerged that a reliable inductive method
does not exist. In the words of Karl Popper, one of the strongest and most inﬂuential
critics of inductivism: “Induction, i.e. inference based on many observations, is a
myth. It is neither a psychological fact, nor a fact of ordinary life, nor one of
scientiﬁc procedure.” (Popper 1963, 53) Today, hypothetico-deductivism in the
tradition of Popper and others is generally considered to reﬂect sound scientiﬁc
practice.
And indeed, most criticism that has been brought forward against data science is
directed against its inductivist nature. For example, the information scientist Martin
Frické writes in his epistemological assessment of data science: “An immediate
© Springer Nature Switzerland AG 2022
W. Pietsch, On the Epistemology of Data Science, Philosophical Studies Series 148,
https://doi.org/10.1007/978-3-030-86442-2_2
11

concern about the present enchantment with data-driven Big Data is just that it might
be inductivism, the hoary punching bag from the philosophy of science. [. . .] That
inductivism is a mistaken philosophy of science is not controversial—it is received
wisdom.” (2014) Thus, any epistemological defense of data science must start with a
thorough analysis of inductivism, in particular revisit those arguments due to which
inductivism has been rejected. To this, I will turn in the following.
2.1
Characteristics of Inductivism1
Throughout the history of science, two major methodological paradigms have
dominated controversies about what constitutes correct scientiﬁc epistemology.
Inductivism, on the one hand, claims that science starts with the facts and then relies
on inductive inferences to formulate general laws. Hypothetico-deductivism, or in
short deductivism, on the other hand, maintains that science begins with hypotheses
about general laws and then uses deductive inferences to derive singular statements
of fact, which are subsequently compared with experiment and observation. Cer-
tainly a considerable number of variants have been proposed for each paradigm, but
the fundamental distinction nevertheless remains useful for thinking about scientiﬁc
methodology.
A somewhat older distinction between empiricism and rationalism parallels that
between inductivism and hypothetico-deductivism. While the latter emphasizes the
type of inferences that are used in scientiﬁc study, i.e. inductive versus deductive, the
former focuses on the primary source of knowledge. According to empiricism, all of
our knowledge originates in sense experience, which rationalists deny by suggesting
that the mind plays an indispensable role in forming our beliefs about the world.
The connection between both distinctions is as follows. According to empiricism,
experience in terms of concrete statements of fact constitutes the fundamental source
of human knowledge. Thus, concepts, laws and theories must be derived inductively
from these statements of fact. Hypothetico-deductivism by contrast begins with
general hypotheses about the world, which cannot be gained directly from experi-
ence. Indeed, the very notion of something being hypothetical presupposes that it
cannot fully be justiﬁed by statements of fact. Hypotheses are to a considerable
extent constructs of the mind.
A classic statement of an inductivist approach can be found in Jean-Marie
Ampère’s masterpiece, his “mathematical theory of electro-dynamic phenomena
uniquely derived from experiments” (Ampère 1826/2012). Ampère, of course, was
one of the most important contributors to the classical theory of electromagnetism. In
fact, he has often been referred to as the “Newton of electromagnetism”. In the
introduction to his treatise, Ampère summarizes his method as follows:
1The exposition in this section is based on Chap. 3 of Pietsch (2021).
12
2
Inductivism

First observe the facts, while varying the conditions to the extent possible, accompany this
ﬁrst effort with precise measurement in order to deduce general laws based solely on
experiments, and deduce therefrom, independently of all hypotheses regarding the nature
of the forces which produce the phenomena, the mathematical value of these forces, that is to
say, the formula which represents them, this was the path followed by Newton. This was the
approach generally adopted by the scholars of France to whom physics owes the immense
progress which has been made in recent times, and similarly it has guided me in all my
research into electrodynamic phenomena. I have relied solely on experimentation to estab-
lish the laws of the phenomena and from them I have derived the formula which alone can
represent the forces which are produced; I have not investigated the possible cause of these
forces, convinced that all research of this nature must proceed from pure experimental
knowledge of the laws [. . .] (Ampère 1826/2012, p. 2)
This brief statement includes all core tenets of an inductivist approach2: (i) Scientiﬁc
laws can and should be proven by induction from the phenomena, i.e. from exper-
iment and observation (“I have solely relied on experimentation”). (ii) These laws
can be considered true or at least highly probable in the sense that only one correct
set of laws adequately describes a certain range of phenomena (“the formula which
alone can represent the forces”). (iii) This implies an aversion against hypotheses,
which by deﬁnition are always preliminary and never proven beyond doubt (“inde-
pendently of all hypotheses”). As many authors in the inductivist tradition stress,
hypotheses may be and are formulated in a premature state of a scientiﬁc ﬁeld, but
eventually scientiﬁc knowledge should move beyond the merely hypothetical.
(iv) Relatedly, background knowledge or modeling assumptions play only a minor
role, but are often justiﬁed by or derived from the empirical data. (v) It is often
assumed that scientiﬁc laws are derived by a methodology of varying the circum-
stances (“varying the conditions to the extent possible”). (vi) This process continu-
ously improves the knowledge about the phenomena, at least in the long run. (vii)
Finally, inductivism establishes a hierarchy of laws of increasing universality,
starting with simple observation statements which are combined into low-level
phenomenological laws, and then into laws of increasing generality and abstractness
slowly rising until the highest level of generality.
The dominance of inductivism during long periods of the development of modern
science can be traced back to Francis Bacon, who by many is considered among the
founders of modern empirical science. His Novum Organum was conceived to
replace Aristotle’s Organon, the most inﬂuential methodological treatise of ancient
and medieval science. Bacon contrasted his inductivist method of discovering truth
to the approach that he considered prevalent in his days in the following manner:
There are and can be only two ways of searching into and discovering truth. The one ﬂies
from the senses and particulars to the most general axioms, and from these principles, the
truth of which it takes for settled and immoveable, proceeds to judgment and to the discovery
of middle axioms. And this way is now in fashion. The other derives axioms from the senses
and particulars, rising by gradual and unbroken ascent, so that it arrives at the most general
axioms last of all. This is the true way, but as yet untried. (1620, I.XIX)
2Compare Pietsch (2017).
2.1
Characteristics of Inductivism
13

The ﬁrst approach, described in this quote, bears some resemblance to hypothetico-
deductivism, while Bacon’s methodology, i.e. the second approach, exhibits many
of the characteristics of inductivism as listed above. Most importantly, Bacon
insisted that science should start with the facts, with careful observation and exper-
iment, and then slowly ascend to increasingly general laws until ﬁnally arriving at
what he called the forms of the phenomena, i.e. their real nature or true causes.
Furthermore, Bacon’s methodology based on his tables of discovery clearly exhibits
a variational element. Indeed, Bacon considered it to be one of the major improve-
ments of his method that he replaced naïve conceptions of induction by enumeration
with more sophisticated inductive approaches. All these issues will be addressed in
detail in Chap. 4.
For a long time, methodologists and scientists alike referred primarily to Bacon
when expounding their methodological views. Some of the most inﬂuential scien-
tists between the seventeenth and the nineteenth century considered themselves to be
direct heirs of Bacon’s scientiﬁc methodology. Major ﬁgures situating themselves in
the empiricist and inductivist Baconian tradition were William Herschel and John
Stuart Mill, to whose methodological views I will also return in Chap. 4.
The long list of Baconian scientists notably includes Isaac Newton, whose
methodological writings are brief and scattered across his work.3 In his celebrated
“four rules of reasoning in philosophy” from the Principia Mathematica
Philosophiae Naturalis, in which Newton lays the foundations of modern physics,
he summarizes his epistemological stance (1726/1999, pp. 794–796)—clearly
endorsing many of the central tenets of inductivism as listed above. For example,
Newton makes clear that truth is the ultimate aim of science. Rule one states his
doctrine of verae causae, which requires that science should look for those causes
which are “both true and sufﬁcient to explain [the] appearances” (1726/1999,
p. 794). In rule four, Newton stresses the crucial role of induction for his method-
ology: “In experimental philosophy we are to look upon propositions inferred by
general induction from phenomena as accurately or very nearly true, notwithstand-
ing any contrary hypotheses that may be imagined, till such time as other phenomena
occur by which they may either be made more accurate or liable to exceptions.”
(1726/1999, p. 796) Again, scientiﬁc knowledge that is inductively gained can
approximate truth according to Newton. Contrary instances do not refute scientiﬁc
laws but help to delineate the range of applicability of these laws. As will be seen in
Chap. 4, this role for contrary instances constitutes a crucial feature of Baconian
variational induction as opposed to naïve enumerative induction. Finally, Newton
voices his well-known distaste for hypotheses—as also famously expressed in his
dictum “hypotheses non ﬁngo” (“I do not feign hypotheses”) from the General
Scholium of the third book of the Principia.
3That Newton stands in a Baconian tradition is widely recognized in the literature (e.g. Ducheyne
2005). Newton’s posthumous editors Collin MacLaurin, Roger Cotes, and Henry Pemberton have
played a crucial role in establishing the connection (Pérez-Ramos 1996, 319).
14
2
Inductivism

Let me brieﬂy mention one further scientist who, judging from his methodolog-
ical commitments, forms part of the inductivist and empiricist tradition: Antoine
Lavoisier, whose standing as a central ﬁgure in the chemical revolution can be
compared to Newton’s role in laying the foundations for modern physics. In the
preface to his Elements of Chemistry, Lavoisier formulates his inductivist credo:
I have imposed upon myself, as a law, never to advance from what is known to what is
unknown; never to form any conclusion which is not an immediate consequence necessarily
ﬂowing from observation and experiment; and always to arrange the fact, and the conclu-
sions which are drawn from them, in such an order as shall render it most easy for beginners
in the study of chemistry thoroughly to understand them. [. . .] All these chemists [devising
various tables of elements] were carried along by the inﬂuence of the genius of the age in
which they lived, which contended itself with assertions without proofs; or, at least, often
admitted as proofs the slightest degrees of probability, unsupported by that strictly rigorous
analysis required by modern philosophy. (1789/1890, p. xviii-xxiii)
Of course, when Lavoisier rejects “assertions without proofs” this amounts to an
inductivist repudiation of hypotheses. Like Ampère or Newton, Lavoisier seems to
believe that scientiﬁc truth can be empirically established.
The dismissal of such inductivist commitments as naïve and irreconcilable with
scientiﬁc practice as well as a signiﬁcant depreciation of Francis Bacon by many
modern methodologists and scientists indicate that inductivism is in general not
well-regarded today. Instead, hypothetico-deductivism reigns in epistemology, but
especially in the sciences themselves. In fact, inductivism has been under attack at
least since the second half of the nineteenth century, leading to several prominent
debates between inductivists and deductivists. There was a famous exchange
between John Stuart Mill and William Whewell, the former siding with inductivism,
the latter arguing for a deductivist approach, stressing the indispensable role of
hypotheses in science. Several decades later, the controversy was continued between
the empiricists of the Vienna Circle and Karl Popper taking the opposing view of
deductivism.
The major arguments in these debates will be considered in Section 2.5. Let me
now brieﬂy sketch the main tenets of hypothetico-deductivism using the following
quote by Albert Einstein:4
We have now assigned to reason and experience their place within the system of theoretical
physics. Reason gives the structure to the system; the data of experience and their mutual
relations are to correspond exactly to consequences in the theory. On the possibility alone of
such a correspondence rests the value and the justiﬁcation of the whole system, and
4Another version of the hypothetico-deductive doctrine is given by Richard Feynman, arguably the
most inﬂuential physicist in the second half of the 20th century, in his Character of Physical Law:
“In general we look for a new law by the following process. First we guess it. Then we compute the
consequences of the guess to see what would be implied if this law that we guessed is right. Then we
compare the result of the computation to nature, with experiment or experience, compare it directly
with observation, to see if it works. If it disagrees with experiment it is wrong. In that simple
statement is the key to science. It does not make any difference how beautiful your guess is. It does
not make any difference how smart you are, who made the guess, or what his name is – if it
disagrees with experiment it is wrong. That is all there is to it.” (Feynman 1967, 156)
2.1
Characteristics of Inductivism
15

especially of its fundamental concepts and basic laws. But for this, these latter would simply
be free inventions of the human mind which admit of no a priori justiﬁcation either through
the nature of the human mind or in any other way at all. [. . .] the ﬁctitious character of the
principles [of mechanics] is made quite obvious by the fact that it is possible to exhibit two
essentially different bases, each of which in its consequences leads to a large measure of
agreement with experience. This indicates that any attempt logically to derive the basic
concepts and laws of mechanics from the ultimate data of experience is doomed to failure.
(Einstein 1934, 165)
Hypothetico-deductivism thus is the claim that science starts with a hypothesis,
deductively derives empirical consequences from the hypothesis and tests these
consequences using experiments and observations. Obviously, hypothetico-
deductivism is in many ways opposed to inductivism: (i) While inductivists are
generally wary of hypotheses, for deductivists hypotheses are the very starting point
of the scientiﬁc enterprise. Any general law or theory will always remain hypothet-
ical to a certain extent (“free inventions of the mind”; “ﬁcticious character of the
principles”). (ii) Consequently, deductivists are reluctant to ascribe truth or proba-
bility to any general law or theory—as Einstein hints when he argues that the same
empirical facts can often be described by “different bases”, i.e. by different theoret-
ical frameworks. (iii) Deductivists deny that there is a universal inductive method
with which laws and theories can be uniquely derived from experience (“any attempt
logically to derive [. . .] is doomed to failure”). (iv) Instead, they emphasize the
crucial importance of deductive inferences (“the data of experience and their mutual
relations are to correspond exactly to [deductive] consequences in the theory. On the
possibility alone [. . .] rests the value and justiﬁcation of the whole system”). (v) In a
rationalist vein, hypothetico-deductivism emphasizes the contributions of the mind,
of intuition and creativity, for the formulation of hypotheses, e.g. when Einstein
speaks of the ﬁctitious character of the principles of mechanics. They will point to
the indispensable role of background knowledge and modeling assumptions in
science. Obviously, inductivism and hypothetico-deductivism are in many aspects
irreconcilable. Thus, scientists have to make a choice.
As the most inﬂuential scientist of his age, Newton paved the way for
inductivism. Similarly, Einstein’s views helped establish hypothetico-deductivism
as the dominant methodological framework of his time and subsequent decades.
Apparently, the strong reaction and widespread rejection of data science results from
the implicit assumption that hypothetico-deductivism is the correct scientiﬁc meth-
odology. After all, data science clearly exhibits inductivist features, as will be shown
in the following section.
2.2
Data Science as an Inductivist Framework
Data science exhibits many features of an inductivist framework as characterized in
the previous section. Most importantly—and somewhat trivially—, it starts with
often enormous amounts of data. Here, data are best understood as records of
16
2
Inductivism

empirical evidence for a given phenomenon, i.e. recorded observations or experi-
mental results (cp. Section 1.1). For example, the data used by a search engine may
include previous search queries or various characteristics of a user like age, gender,
nationality, etc. All these data are particular facts rather than general laws or
hypotheses. This, of course, ﬁts well with the ﬁnding from the previous section
that inductivism starts with statements of fact derived from observations and exper-
iments, while hypothetico-deductivism starts with postulated, i.e. hypothetical, uni-
versal relationships.
Besides the data, the second crucial ingredient of data science is various machine
learning algorithms that are able to derive predictions from the data, i.e. that infer
inductively to as yet unknown events or individuals (cp. Section 1.2). For example, a
search engine typically makes an inductive inference based on all relevant data,
which answer best suits a particular query by a given user. The predominant role of
inductive, as opposed to deductive, inferences was identiﬁed as one of the key
features of inductivism in the previous section. In the course of this book, some of
the machine learning algorithms carrying out inductive inferences will be discussed
in much detail, such as decision trees, neural nets or k-nearest neighbor
classiﬁcation.
While the workings of these algorithms may sometimes be opaque due to the
sheer number of steps that are executed, there is no mystical element in how they
achieve their results. In particular, there is little room for intuition or creativity—at
least once the data are given and the algorithms are chosen. The working principles
of most machine learning algorithms are well understood and, once set up, these
algorithms are rarely in need of further human interference. Search engines illustrate
this automation well, as answers to search queries are usually generated without any
human contribution. Thus, at least for some applications of data science, it seems to
be the case that inductive inferences can be automatized to a considerable extent.
There is no need for human intuition and creativity, as it is generally required for the
formulation of meaningful hypotheses according to the hypothetico-deductive
approach.
Furthermore, it will be shown in Chap. 4 that many machine learning algorithms
follow a variational rationale as identiﬁed as a crucial characteristic of sophisticated
inductivist approaches in the previous section. The decisive evidence for most
algorithms comes not in terms of regularities or constant conjunction but rather in
terms of a variation of circumstances while continuously tracking the impact that
these variations have on the examined phenomenon. For example, a search engine
may quickly identify that the variable ‘location’ of the user is highly relevant when
she/he searches for restaurants.
It is usually the case that the results of data science can be improved by adding
more data, in line with the inductivist notion that additional experiments and
observations lead to the continuous reﬁnement of causal knowledge, often by
determining exceptions and clarifying the range of applicability. This basic insight
is behind the success of those companies that have amassed the largest data sets of
our times, such as Google, Facebook, or Amazon. Being the most successful
companies in their ﬁelds just means further opportunities to collect relevant data,
2.2
Data Science as an Inductivist Framework
17

which will only strengthen their respective monopolies. Of course, the data needs to
be of the right kind to constitute adequate evidence for the examined phenomenon,
as further discussed in Chap. 6.
While
inductivism
captures
such
incremental
increase
of
knowledge,
hypothetico-deductive approaches consider the falsiﬁcation of hypotheses as the
crucial element in the scientiﬁc process (in particular Popper 1935/2002). In typical
machine learning algorithms, falsiﬁcation of hypotheses does not occur. For exam-
ple, additional data in general will not falsify a decision tree, but only render the tree
more exact.
Besides the characteristics of inductivism that were outlined in the previous
section, there are further indicators that data science constitutes an inductivist
approach. For example, the knowledge generated in inductivist approaches is often
local, i.e. it is obtained for very speciﬁc contexts and is not easily generalizable
beyond those contexts. This strong context-dependency of course constitutes the
reason why data science in most cases needs Big Data, i.e. very large data sets that
cover all kinds of possibilities and contexts. Relatedly, inductivist frameworks often
aim at prediction of the phenomena rather than fundamental understanding. Cer-
tainly, understanding usually requires knowledge of sufﬁcient universality that
draws connections between a wide variety of phenomena. Such non-local knowl-
edge is usually unavailable in data science and therefore a deeper understanding of
the phenomena seems unfeasible through data science.
Many of the objections against data science echo typical objections that have
been evoked against inductivism. Some scholars are very explicit about this. For
instance, the information scientist Martin Frické writes: “An immediate concern
about the present enchantment with data-driven Big Data is just that it might be
inductivism, the hoary punching bag from the philosophy of science. [. . .] That
inductivism is a mistaken philosophy of science is not controversial—it is received
wisdom.” (2014)
In the pertinent literature, which is critical of data science, the scientiﬁc method is
often directly identiﬁed with a hypothetico-deductive approach, i.e. essentially with
empirical tests of hypotheses, whereas inductivist methodologies are rejected as
being unscientiﬁc. Scholars emphasize the allegedly indispensable role of universal
theories for science in contrast to the inductivist focus on local, fairly theory-
independent knowledge. Relatedly, critics of data science denounce the idea that
the scientiﬁc process can be largely automatized, which of course is only possible if
an inductive method exists which can be made explicit and be programmed in a
machine-learning algorithm. By contrast, one of the central tenets of hypothetico-
deductivism, as we had seen, is that such an inductive method does not exist.
In summary, data science, understood as the application of machine learning
algorithms to large data sets, is an inductivist framework. Consequently, the main
task for an epistemology of data science is a rehabilitation of inductivism, which has
been so universally rejected in recent science and philosophy of science.
18
2
Inductivism

2.3
An Example from Data Science5
In this section and the next, I provide two arguments for rehabilitating inductivism in
the wake of data science. The ﬁrst argument, discussed in this section, is a case study
of successful scientiﬁc practice, where an inductivist, data-driven approach turns out
superior to a model-driven approach. The second argument, which is taken up in the
next section, depicts a development in statistics, which has experienced in recent
decades the emergence of inductivist methodology in contrast to the model-driven
paradigm that dominated much of the twentieth century.
The development of machine translation is one of the standard success stories in
data science. It illustrates particularly well the shift from a model-driven to a data-
driven approach, i.e. from complex modeling with relatively scarce data to simple
modeling with a lot of data (cp. the second thesis in Section 1.2). Although it is
somewhat of an oversimpliﬁcation, two different approaches can be distinguished:
one rule-based, the other data-driven (Halevy et al. 2009). Historically prior was the
rule-based approach, which relies on complex computational models of the gram-
matical structure of languages that have to be explicitly programmed. Thus, when
translating a sentence, the translation software detects the grammatical structure of
the sentence in the source language, translates the various words in the sentence into
the target language by using a conventional dictionary, and then transforms the
sentence according to the grammatical rules of the target language.
This rule-based approach was largely a failure. Presumably, the reason lies in the
complexity of language. Making explicit all grammatical rules with all their excep-
tions turned out to be impossible. In the end, language is very contextual. What a
word or even a sentence really means depends very much on the speciﬁc situation in
which it is spoken or written. Of course, this should not come as a surprise to anyone
who has ever learned a foreign language. The basic structure of a language can be
learned from a grammar book, but in order to speak ﬂuently, one has to immerse
oneself in a foreign culture for a longer time, and hear and speak the language day in
and day out.
Remarkably, what turned out much more successful than the rule-based approach
was a data-driven or statistical approach that largely neglects the grammatical
structure and works instead with huge corpora of texts in combination with Bayesian
inferential statistics. It relies both on monolingual corpora, e.g. in English and a
foreign language, and on bilingual corpora containing sample translations. All of
these are representative of current speech practice. The frequencies of words in the
corpora and of sequences of words, so-called n-grams, can for example be used to
calculate the most probable translation of a foreign word sequence f into English e
using Bayes’ rule6: best translation ¼ argmaxe P(e|f) ¼ argmaxe P(f|e) P(e). Here P
(e) denotes the probability of a word sequence e in English and P(f|e) denotes the
probability of the word sequence f in the foreign language given the word sequence e
5The exposition in this section is based on Pietsch (2016).
6Norvig 2009, 240; cp. also Jelinek 2009, 492.
2.3
An Example from Data Science
19

at the corresponding location in an English text. The probabilities are evaluated in
terms of relative frequencies in the corpora.
The data-driven approach has been strikingly successful. Apparently, probability
distributions of words and word sequences yield reasonable results for many tasks
such as spellchecking, speech recognition or translation, while explicit grammatical
knowledge is largely dispensable. Two quotes from practitioners well illustrate this
remarkable situation. Peter Norvig, who for a long time headed Google’s machine
translation group, once stated that they were able ‘to build models for languages that
nobody on the team speaks.’7 Frederick Jelinek, a pioneering and by now legendary
ﬁgure in the ﬁeld, is often quoted as saying that ‘every time I ﬁre a linguist, the
performance of the speech recognizer goes up.’8 These quotes indicate that for
certain tasks in linguistics, speciﬁc kinds of theory and modeling assumptions can
be dispensed with.
Data-driven machine translation ﬁts well with the notion of data science devel-
oped in Section 1.1, i.e. as machine learning algorithms applied to large data sets. In
particular, practitioners have often emphasized that the data-driven approach to
machine translation requires enormous corpora (e.g. Halevy et al. 2009, 9). As
early as 2006, Google Translate relied on a trillion-word corpus assembled from
the Internet with frequency counts of all sequences up to ﬁve words (ibd.). Plausibly,
such a corpus represents a considerable fraction of all possible phrases, i.e. of all
possible variations of speech for some contexts. Data-driven machine translation is
also a good example for the automation of the research process. After all, the corpora
are collected online, stored in data bases and algorithmically analyzed without much
human intervention and in particular without notable input in terms of theoretical
knowledge from linguistics.
The development of machine translation as outlined above can be broadly
understood in terms of a shift from a hypothetico-deductive to an inductivist
approach. According to the historically prior rule-based approach, explicit knowl-
edge of the grammar is required beforehand, so that the various grammatical rules
can be implemented in the translation software. These rules constitute a rather
complex model of the respective language, from which the correct translation can
be deductively inferred. Thus, the rule-based paradigm relies on a (hypothetical)
model as well as on deductive inferences, just as required by the hypothetico-
deductive approach. The rule-based approach also provides some understanding
for why a translation is correct. For example, the grammatical rules make it possible
to determine the subject and object, the tense of the verb, adjectives and adverbs,
whether a sentence is negated, etc. All this can give insight into the meaning of a
sentence and thus establish why a particular translation was chosen. To a certain
7‘The Unreasonable Effectiveness of Data’, talk given by Peter Norvig at UBC, 23.9.2010 http://
www.youtube.com/watch?v¼yvDCzhbjYWs at 43:45.
8http://www-03.ibm.com/ibm/history/ibm100/us/en/icons/speechreco/team/, accessed 1.8.2013.
20
2
Inductivism

extent translations can be explained in terms of the underlying grammatical models.
Such deeper understanding, of course, is typical for hypothetico-deductive
approaches. Finally, proponents of a rule-based approach occasionally claim that
the rules cannot be entirely derived from scientiﬁc practice, but are to a certain extent
innate and thus part of the human mind—as in Noam Chomsky’s concept of a
‘universal grammar’ (1965).9
By contrast, the data-driven approach starts with the data—more precisely, with
huge amounts of data. While for the rule-based approach a simple dictionary
supposedly sufﬁces, the data-driven approach requires enormous monolingual and
bilingual corpora that must be representative of speech practice. It is characteristic of
inductivism that the rules and laws are not given beforehand, but are derived from
the data—as is obviously the case for grammatical rules in the data-driven approach
to machine translation. Furthermore, the data-driven approach relies on very few and
very general modeling assumptions. Consequently, it can react much more ﬂexibly
to changes in linguistic practice if represented in the respective text corpora—while
there is no obvious mechanism in the rule-based approach how rules are adjusted
when language changes.
The variational aspect, which was identiﬁed as a key feature of sophisticated
inductive methodology, is also present in the case study. For adequate results in data-
driven machine translation, sufﬁcient evidence is required, which closely maps what
impact the variation of words and word sequences has on a translation. Large text
corpora capture as much variation in linguistic practice as possible. Quite recently,
researchers in machine translation have switched from using Bayesian modeling to
deep neural networks, which apparently yield better and more natural results.10 As
will be discussed in Section 3.5, neural networks essentially rely on a logic of
difference making, which explicitly requires variational evidence. Thus, the varia-
tional rationale of inductive methodology is even more pronounced in recent
approaches to machine translation compared with the earlier Bayesian modeling.
In summary, the case study suggests a shift from strongly model-based
approaches with scarce data to data-intensive approaches with very simple models,
i.e. from an essentially hypothetico-deductive to an inductivist methodology. When
dealing with complex phenomena such as human language, it thus seems advisable
to dispense with strong modeling assumptions, which are necessarily oversimpliﬁed,
and replace them by very large data sets representing all possible variation of a
phenomenon.
9For an interesting exchange between Noam Chomsky and Peter Norvig, representing a model-
driven approach and a statistical approach to linguistics, respectively, compare Norvig (2017).
10For example, Google Translate switched in November 2016.
2.3
An Example from Data Science
21

2.4
The Recent Emergence of Inductivist Paradigms
in Statistics11
Nate Silver, famous for his aggregate predictions of American presidential elections
as well as his blog ﬁvethirtyeight.com, once said that “data scientist is a sexed-up
term for a statistician”.12 Indeed, it has often been claimed that data science is just
statistics with some additional computational elements. But while it is true that there
is a close resemblance between data science and statistics, especially concerning the
overall goal of extracting knowledge from data, the differences in fact run deeper.
Broadly speaking, conventional statistics is a model- or hypothesis-driven approach,
very much in the tradition of hypothetico-deductivism, whereas data science is
strongly inductivist and often relies on only few and very general modeling assump-
tions. In a way, data science is statistics from a strongly inductivist perspective.
This relationship between data science and statistics is obscured by a somewhat
different usage of terminology in conventional statistics. Statisticians usually distin-
guish between descriptive statistics on the one hand and inductive or inferential
statistics on the other hand. The former aims to account for the characteristics of the
data pertaining to a given population, for example by determining averages or
variety. By contrast, inductive statistics infers from such data to a much larger
population. Usually, for these inferences considerable model assumptions must be
presupposed regarding the larger population, e.g. that a certain feature follows a
Gaussian distribution or that a dependency is linear. Inductive statistics thus is often
concerned with determining the parameters of the distribution function or of the
functional dependency. Since inductive or inferential statistics relies on considerable
model assumptions, the approach ﬁts better with hypothetico-deductivism than with
inductivism.
Thus, when we argue for the emergence of novel inductivist paradigms in
statistics, this does not conﬂict with the fact that statisticians have long spoken of
inductive statistics. ‘Inductive statistics’ is not ‘inductivist statistics’—and in my
view is a misnomer. Instead, one may want to introduce a distinction within
inferential statistics between hypothesis- and model-driven approaches on the one
hand and strongly inductivist approaches on the other hand. Remarkably, the
development of inductivist statistics has met considerable opposition. Over the
past years, I have repeatedly spoken with statisticians that more or less by deﬁnition
identiﬁed statistics with a model-driven approach. These statisticians have internal-
ized the Popperian idea that inductivism does not work and that the only sensible
scientiﬁc approach is hypothetico-deductive.
The locus classicus, in which the mentioned distinction between hypothetico-
deductive and inductivist statistics is introduced, is Leo Breiman’s highly inﬂuential
essay ‘Statistical Modeling: The Two Cultures’ from 2001. Breiman—a statistician
11The exposition in this section is based on Pietsch (2015).
12http://www.statisticsviews.com/details/feature/5133141/Nate-Silver-What-I-need-from-statisti
cians.html
22
2
Inductivism

who for a long time of his career worked outside academia—distinguishes data
modeling, which corresponds to conventional model-driven statistics, and algorith-
mic modeling, which is more strongly inductivist. Machine learning is a typical
example of the latter. Breiman summarizes the distinction as follows:
There are two cultures in the use of statistical modeling to reach conclusions from data. One
assumes that the data are generated by a given stochastic data model. The other uses
algorithmic models and treats the data mechanism as unknown. The statistical community
has been committed to the almost exclusive use of data models. This commitment has led to
irrelevant theory, questionable conclusions, and has kept statisticians from working on a
large range of interesting current problems. Algorithmic modeling, both in theory and
practice, has developed rapidly in ﬁelds outside statistics. It can be used both on large
complex data sets and as a more accurate and informative alternative to data modeling on
smaller data sets. If our goal as a ﬁeld is to use data to solve problems, then we need to move
away from exclusive dependence on data models and adopt a more diverse set of tools.
(Breiman 2001, 199)
Of course, “treating the data mechanism as unknown” implies that only few and very
general model assumptions are presupposed and that predictions are generated
algorithmically more or less directly from the data. In short, algorithmic modeling
is an inductivist approach, in contrast to data modeling, which relies on much more
elaborate modeling assumptions that are not derived from the data but have to be
presupposed. Thus, data modeling strongly resembles a hypothetico-deductive
approach.
According to Breiman, both approaches differ in most aspects of statistical
analysis. The models in data modeling generally consist in a set of stochastic
equations taking the form: response variables ¼ f (predictor variables, random
noise, parameters). The given data are assumed to be independent draws, generated
by such data models. Finally, the models are evaluated in terms of how well the
empirical data ﬁt the modeling assumptions that are implicit in the stochastic
equations, e.g. by means of goodness-of-ﬁt tests and residual examination. For
example, the model may postulate a linear dependency between two variables. By
employing linear regression, estimates for the relevant parameters can be deter-
mined, in this case offset, i.e. y-intercept, and slope. The goodness of ﬁt can be
judged by calculating the residual sums of squares, i.e. by examining the differences
between the data points and the regression line
Xn
i¼1bEi
2 ¼
Xn
i¼1 yi 
bβ0 þ bβ1xi



2
,
where (xi, yi) are the given data points and bβ0 and bβ1 denote the estimates for offset
and slope. Often a better measure of ﬁt is the so-called ‘coefﬁcient of determination’:
R2 ¼ 1 
Pn
i¼1bEi
2
Pn
i¼1 yi  y
ð
Þ2
2.4
The Recent Emergence of Inductivist Paradigms in Statistics
23

where y is the mean of the y-coordinate, calculated from the observed data points. In
general, the closer this coefﬁcient is to 1, the better the model explains or at least
predicts the variance in the data. In the given example, if the coefﬁcient of determi-
nation is 1, then the data perfectly ﬁts a linear model. Further criteria for model
validation are for example whether the mean of the deviations is 0, whether the
probability distribution of the errors is normal etc. Based on a measure of ﬁt like the
coefﬁcient of determination, a threshold may be introduced indicating whether
certain models are good enough for an intended purpose. As Breiman also empha-
sizes, in conventional statistics it is often a yes-no decision whether or not to accept a
given model, rather than a gradual measure for the adequacy of a model.
By contrast, in algorithmic modeling, an explicit data model in terms of a set of
stochastic equations is not assumed. Rather, the mechanism generating output from
input data is considered to be “complex and unknown” (ibid, 199). Thus, data
modeling relies on much stronger and far more restrictive modeling assumptions
compared with algorithmic modeling. For example, an a priori assumption of linear
or other functional dependency is characteristic for data modeling, whereas algo-
rithmic modeling is much more ﬂexible. Indeed, typical algorithms such as decision
trees or neural nets are able to deal with a wide variety of underlying functional
relationships. Furthermore, algorithmic models are evaluated in terms of predictive
accuracy rather than goodness of ﬁt. Since the model assumptions are far less
restrictive compared with data modeling, the question whether the model corre-
sponds to the actual mechanism, which generates the data, becomes largely mean-
ingless. In algorithmic modeling, there is no need to justify speciﬁc model
assumptions like linear dependency and evaluate whether these are true.
Breiman adds a sociological ﬂavor to his distinction between two cultures of
statistical modeling by claiming that in 2001, when he was writing the article, 98%
of all statisticians were working within the data modeling paradigm, while algorith-
mic modeling was developed chieﬂy outside academic statistics departments, by
computer scientists, physicists, and others. By now, the need for a novel methodol-
ogy is increasingly recognized within the statistics community as well. For example,
in a 2010-piece in Amstat News, the magazine of the American Statistical Associ-
ation, Mark van der Laan and Sherri Rose argue under the heading “Statistics ready
for a revolution” that the “next generation of statisticians must build tools for
massive data sets”.13 By now, major research initiatives on the topic have formed
in various countries.
As already stated, data modeling largely follows a hypothetico-deductive ratio-
nale. Notably, most of the modeling assumptions are intuited, which describe the
mechanism determining the values of the response variables. Certainly, such model-
ing assumptions are not derived directly from the data. Rather, data modelers often
emphasize the ingenuity and creativity required for coming up with an adequate
model. In other words, these data models are largely hypothetical. In the spirit of a
hypothetico-deductive approach, models are evaluated in terms of their empirical
13http://magazine.amstat.org/blog/2010/09/01/statrevolution/ (accessed 31.1.2015).
24
2
Inductivism

consequences, i.e. by comparing how well the deductive consequences of the models
correspond to the facts. If the correspondence is weak, the model is abandoned and
another model may be tried, e.g. by assuming a different functional relationship. Of
course, sometimes the larger theoretical context also plays a role for evaluating
models.
By contrast, algorithmic modeling exhibits many features of inductivist method-
ology. Most importantly, due to the absence of detailed and restrictive modeling
assumptions, the data largely speaks for itself. Algorithmic modelers rarely aim at
explanation and understanding in terms of making explicit an underlying mechanism
or of embedding a model into a general theoretical context. Rather, they are mostly
satisﬁed with local knowledge that allows for fairly reliable predictions. While some
pragmatic decisions have to be made, e.g. which algorithms to employ and how to
tweak certain parameters of these algorithms, these are determined by the given data
set rather than by any assumptions about an underlying mechanism. As I will argue
later in the book, many approaches in algorithmic modeling follow a variational
rationale,
as
is
characteristic
of
sophisticated
inductivist
approaches
(cp. Section 2.1).
It would be wrong to think of the emergence of an inductivist, data-driven
paradigm in statistics as a sudden phenomenon. Breiman describes how he devel-
oped his view on algorithmic modeling during his time working as a consultant
outside of academia in the 1960’s and 70’s. A period of major progress in algorith-
mic modeling begins around the mid-1980’s. One need not be a historian to observe
that these theoretical developments parallel enormous advances in information
technology around the same time period.14 Moreover, many core ideas in algorith-
mic modeling have been known for many centuries, e.g. the concept of decision trees
or simple non-parametric regression methods such as ‘connecting the dots.’ How-
ever, these methods have gained scientiﬁc importance chieﬂy due to recent advances
of information and communication technology in the acquisition, storage, and
processing of large data sets. This in turn has led to further theoretical analysis
regarding the reliability and limits of the various algorithmic approaches and statis-
tical tools. From the mid-90’s onwards, the increasing interconnectedness of infor-
mation technology, in particular the Internet, has led to very large high-dimensional
data sets for example in the social domain. In a way, the recent hype concerning Big
Data is the culmination of a development that has started much earlier.
As of today, several well-established approaches of algorithmic modeling exist.
In the following, I focus on a speciﬁc development that well illustrates the distinction
between data and algorithmic modeling, namely the shift from parametric to non-
parametric modeling.15 The latter is by now an established approach in statistics, but
14For a graphic illustration of this claim compare the terms ‘computer’ and ‘non-parametric’ on
Google’s Ngram Viewer https://books.google.com/ngrams.
15Hastie & Tibshirani (1990) is a milestone; a useful overview can be found in Kauermann
(2006); from a philosophical perspective, Sprenger (2011) discusses an interesting example of
non-parametric modeling, bootstrap resampling, and argues for its epistemic signiﬁcance.
2.4
The Recent Emergence of Inductivist Paradigms in Statistics
25

its signiﬁcance in terms of applications is still increasing mostly due to further
advances in information technologies. Goeran Kauermann explicitly makes
the link: “Statistics and econometrics have been dominated by linear and parametric
models over decades. A major reason for this were the numerical possibilities which
simply forbid to ﬁt highly structured models with functional and dynamic compo-
nents.” (2006, 137)
The distinction between non-parametric and parametric modeling relates to the
number and nature of assumptions in the respective models. In particular,
non-parametric models cannot be characterized by a bounded set of model param-
eters, in contrast to parametric models.16 Therefore, non-parametric models allow for
a wide range of dependencies between input and output variables, while in paramet-
ric modeling the functional dependency is usually predetermined by a ﬁnite set of
parameters, e.g. the mean μ and the standard deviation σ in the case of a Gaussian
distribution.
In the following I will discuss two examples, ﬁrst the comparison between
parametric and non-parametric regression and second between parametric and
non-parametric density estimation. With respect to the former, a typical method
for parametric regression is univariate linear regression, in which a number of given
data points (xi;yi) are summarized in terms of a linear dependency: y ¼ ax + b. Thus,
two parameters need to be determined, offset b and slope a, which are usually chosen
such that the sum of the squared deviations P
n
i¼1
yi  axi þ b
ð
Þ
ð
Þ2 is minimized.
By contrast, in non-parametric regression, the data is not summarized in terms of
a small number of parameters a and b, but rather all data is kept and used for
predictions (Russell & Norvig 2009, Ch. 18.8.4). A simple non-parametric proce-
dure is connect-the-dots. Somewhat more sophisticated is locally weighted regres-
sion, in which a regression problem has to be solved for every query point xq. The yq-
value is determined as yq ¼ aqxq + bq with the two parameters ﬁxed by minimizing
P
n
i¼1
K d xq, xi




yi  aqxi þ bq



2. Here, K denotes a so-called kernel function that
speciﬁes the weight of the different xi depending on the distance to the query point xq
in terms of a distance function d(). Of course, an xi should be given more weight the
closer it is to the query point.
Both connect-the-dots and locally weighted regression are examples of next-
neighbor methods, for which the value of the response variable at a query point is
determined primarily by the values of the response variable at those data points
which are closest to the query point. The generalization to higher dimensions is
straight-forward, though for next-neighbor methods a problem arises that has been
termed the ‘curse of dimensionality’ (Bellman 1961). With an increasing number of
dimensions, i.e. of predictor variables, the average distance between neighboring
points rapidly becomes very large of order (1/N)1/n, where N is the total number of
16Here, parameters are not to be understood in terms of variables but of constants that determine the
properties of a speciﬁc model: e.g. in the linear model y ¼ ax + b, a and b are the model parameters.
26
2
Inductivism

points and n the number of dimensions. Consequently, the data points will almost
always be sparsely distributed in many dimensions.17
Let me brieﬂy reﬂect on how these regression methods illustrate differences
between parametric and non-parametric modeling. While in the example of para-
metric regression linear dependency is presupposed as a modeling assumption, the
non-parametric method can adapt to arbitrary dependencies. In parametric regres-
sion, the type of functional relationship has to be independently justiﬁed for example
by reference to a theoretical context, which prevents an automation of the modeling
process. Certainly non-parametric regression also makes modeling assumptions,
e.g. a suitable kernel function must be chosen that avoids both over- and underﬁtting.
But these modeling assumptions are often very general and they can usually be
automatically evaluated. Fortunately, predictions mostly turn out relatively stable
with respect to different choices of kernel functions.
While non-parametric regression is more ﬂexible than parametric regression, it is
also much more data-intensive and requires more calculation power. Notably, in the
parametric case, a regression problem must be solved only once. All predictions can
be calculated from the resulting parametric model. In the non-parametric case, a
regression problem must be solved for every query point. In principle, each predic-
tion makes use of all the data. While the parametric model consists in a relatively
simple mathematical equation, the non-parametric model consists in all the data and
an algorithmic procedure for making predictions. Note that non-parametric regres-
sion essentially implements Mill’s method of concomitant variation as discussed in
Chap. 4.
Consider density estimation as a second example (Russell & Norvig 2009,
Ch. 20.2.6). Here, the parametric approach makes an explicit modeling assumption
about the nature of the distribution function, for example by postulating a Gaussian
distribution f x
ð Þ ¼
1
σ ﬃﬃﬃﬃ
2π
p
e xμ
ð
Þ2
2σ2 . This distribution is determined by two parameters,
the mean μ and the standard deviation σ, which are chosen to achieve the best ﬁt with
the data.
A simple non-parametric approach for density estimation is the histogram
method, in which the parameter space is partitioned into cells of equal volume ΔV
and the number ki of all N data points is counted for each cell i. The density is given
by f(x) ¼ ki / N ΔV, where ki is the number of data points in the same cell as the query
point x. A closely related and often more effective non-parametric method is k-
nearest-neighbors, in which the same formula is used but k is now ﬁxed and one
determines the minimal volume ΔV surrounding the query point x such that k points
are included. The parameter k should be chosen in a way to avoid overﬁtting, but still
be sufﬁciently sensitive. A suitable k can be ﬁxed by comparing the values in a test
17This curse of dimensionality does not automatically apply to all algorithms in data science and
machine learning. To the contrary, it occasionally turns out helpful to artiﬁcially increase the
dimensionality of the variable space in methods like decision trees or support vector machines
(Breiman 2001, 208-209).
2.4
The Recent Emergence of Inductivist Paradigms in Statistics
27

set with the predictions by the trained model, allowing for an automation of the
non-parametric approach.
Again, in the parametric case the data is summarized in terms of a model
characterized by a few parameters μ and σ resulting in a simple formula, while the
non-parametric method makes no assumptions about the nature of the distribution
function and is thus much more ﬂexible. On the other hand, the non-parametric
method is very data-intensive since it uses the original data points to make pre-
dictions rather than relying on a parametric model. The difference between the two
types of modeling is striking: While parametric models usually are more or less
simple equations, the non-parametric models consist in the original data plus an
algorithm to infer predictions from the data. Since a bounded set of parameters does
not exist, non-parametric models cannot be framed in terms of general equations
at all.
From these examples, we can extract a list of features that distinguish parametric
from non-parametric modeling:
i) Parametric methods usually presuppose considerable modeling assumptions that
must be based on background theory as well as on intuition and ingenuity. In
particular, they summarize the data in terms of a ‘small’ number of model
parameters specifying for example a Gaussian distribution or linear dependence.
By contrast, non-parametric modeling presupposes few and weaker modeling
assumptions, e.g. allows for a wide range of functional dependencies or of
distribution functions.
ii) In non-parametric modeling, predictions are calculated directly from the data.
There is no detour over a hypothesized parametric model that attempts to
summarize the data in terms of a few parameters.
iii) While this renders non-parametric modeling quite ﬂexible with the ability to
quickly react to unexpected data, it also becomes extremely data- and calcula-
tion-intensive. This aspect helps explain why non-parametric modeling is a
relatively recent phenomenon in scientiﬁc method.
iv) Non-parametric models can better handle complexity in the phenomena than
parametric modeling. Notably, a crucial shift occurs from equation modeling to
algorithmic modeling. Conventional parametric modeling in terms of equations,
describing for example functional dependencies or distribution functions,
already presupposes that the picture has been reduced to a (usually small)
number of parameters as well as to (often relatively simple) functional relation-
ships. By contrast, non-parametric modeling does not have such restrictions. It
relies less on sophisticated mathematics and more on a brute-force execution of a
large number of steps. Since the set of parameters is by deﬁnition unbounded,
non-parametric models cannot be expressed in terms of general equations.
Rather, non-parametric models consist of the original data and an algorithmic
procedure to derive predictions from the data. Of course, if the mechanism
underlying a phenomenon is extremely complex, a hypothetico-deductive
approach seems excluded from the outset, since no human being will ever be
28
2
Inductivism

capable of grasping this complexity. Inductivist algorithmic modeling in the
computer remains the only option under such circumstances.
v) The complexity of non-parametric models prevents a deeper understanding of
the phenomena. Thus, there is a shift in epistemic values regarding the aims of
modeling. Non-parametric modeling, like most inductivist approaches, is geared
almost exclusively at prediction and rarely at understanding in terms of general
laws or rules. By contrast, parametric modeling usually emphasizes understand-
ing and explanation, which as we had seen is typical for hypothetico-deductive
approaches. Presumably, this shift in epistemic values is at the root of the
mentioned divide between Breiman’s different ‘cultures’ of statistical modeling.
The above differences clearly identify parametric modeling as a broadly
hypothetico-deductive framework and non-parametric
modeling as strongly
inductivist. In summary, the increasing availability of data leads to the emergence
of novel paradigms in statistics that ﬁt well with the data-driven, strongly inductive
approach of data science with the goal of analyzing complex phenomena.
2.5
Arguments Against Inductivism
If data science is an inductivist approach and if inductivism is by many considered a
ﬂawed methodology in science, then the justiﬁcation of inductivism is the funda-
mental epistemological problem of data science. In a way, the remainder of the
present book can be considered a long argument in favor of inductivism, introducing
various distinctions concerning scientiﬁc practice, presenting conceptual analyses of
crucial terms, and addressing the main arguments from the literature.
In Section 2.1, a somewhat superﬁcial historical picture was sketched according
to which under the inﬂuence of Francis Bacon and Isaac Newton, among others, an
inductivist approach to scientiﬁc methodology dominated much of the time since
Bacon until the middle of the nineteenth century. A period followed during which
there was intense debate on the foundations of scientiﬁc methodology and several
highly inﬂuential scholars dedicated voluminous books as well as considerable parts
of their academic lives to the topic. The most notable among these debates is perhaps
that between William Whewell, who broadly argued for hypothetico-deductivism,18
18Some authors deny that Whewell should be considered a deductivist (e.g. Snyder 2017, Sec. 2).
But while his epistemological stance does not fulﬁll all the criteria laid out in Section 2.1, he can
certainly be seen as a precursor to hypothetico-deductivism. In particular, his methodological
approach has considerable rationalistic elements, stressing the importance of ideas, which are
“not a consequence of experience, but a result of the particular constitution and activity of the
mind, which is independent of all experience in its origin, though constantly combined with
experience in its exercise” (Whewell 1858b, 91; cited in Snyder 2017, Sec. 2). This was a major
point of contention in the debate with Mill. In a somewhat Kantian perspective, Whewell introduced
the notion of ‘colligation of facts’ referring to a process which subsumes certain phenomena under a
general idea, for example geometric phenomena under the concept of space (Whewell 1858a, Ch. II.
IV).
2.5
Arguments Against Inductivism
29

and John Stuart Mill, who represented a more strongly inductivist view. Then, at the
beginning of the twentieth century, the logical positivists, who endorsed
inductivism, clashed with Karl Popper, who took the opposite stance of
hypothetico-deductivism. Another important ﬁgure is the physicist, historian, and
philosopher of science Pierre Duhem, who was himself a hypothetico-deductivist,
and who in his main epistemological work Aim and Structure of Physical Theory
(1906/1962) formulated many of the main arguments against inductivism. In the
following, I outline several standard arguments against inductivism, each addressing
different tenets or assumptions of inductivism. I will discuss the role of hypotheses,
the problem of induction in its various disguises, theory-ladenness of observation,
conﬁrmational holism, and ﬁnally the underdetermination thesis.
A ﬁrst argument concerns the allegedly indispensable role of hypotheses for
scientiﬁc practice. According to this objection, inductivists generally overlook the
hypothetical and preliminary status of all scientiﬁc laws and theories. To this,
inductivists will reply that while hypotheses play a role in preliminary research
stages, eventually science moves beyond mere hypotheses and aims to establish truth
or at least probability. Of course, hypothetico-deductivists maintain that the latter is
impossible, which leads directly to the problem of induction.
The old and venerable problem of induction is generally considered to be one of
the main problems in philosophy of science and epistemology. Presumably, it
constitutes the main argument against the feasibility of inductivist data science. In
its classical formulation, which is due to the empiricist philosopher David Hume, the
problem of induction asks whether inductive inferences can be justiﬁed. Hume
notoriously claimed that justiﬁcation is impossible (1748, Section VII).
In very broad terms, Hume’s argument was the following: He saw two ways in
which inductive inferences might be justiﬁed, either in terms of relations of ideas or
by referring to matters of fact, i.e. either rationally or empirically. With respect to the
former, Hume pointed out that truths in the realm of ideas are established by the
principle of contradiction, which states that the same thing cannot at the same time
both belong and not belong to the same object. But there is nothing contradictory in
the assumption that nature may change its course. It may well happen that future
experiences contradict laws that are inductively well established. Even after a large
number of observations conﬁrming that snow is cold, it remains possible that one
day burning hot ﬂakes will fall from the sky.
A justiﬁcation in terms of matters of facts amounts to a causal justiﬁcation, since
for Hume causation constitutes the way of reasoning concerning matters of fact. But
causal relationships, of course, are established by inductive inferences. Thus, to
justify inductive inferences in terms of matters of facts amounts to an inductive
justiﬁcation of induction. Obviously, such reasoning is circular, the fallacy of a
petitio principii, in which what eventually shall be proven is already presupposed.
More speciﬁcally, an inductive metaprinciple has to be assumed: that the future will
always be similar to the past. However, this metaprinciple, which is often called the
30
2
Inductivism

principle of the uniformity of nature, is plagued by countless counterexamples, in
which nature does rather unexpectedly change its course. Think for example of
Bertrand Russell’s infamous turkey: after being fed every morning for many years,
the turkey ends up being killed on the day before Thanksgiving. According to
Hume’s classical framing, the problem of induction amounts to justifying the
principle of uniformity of nature, which seems utterly hopeless.
The problem of induction is occasionally raised in epistemological debates about
machine learning by those who recognize the inductivist nature of the latter
(e.g. Gillies 1996, Harman and Kulkarni 2007). Besides Hume’s classical version,
there are a number of variants. One inﬂuential version is the new riddle of induction
or the so-called ‘problem of grue’ by Nelson Goodman, which has had a huge impact
on debates about induction in the twentieth century (Goodman 1954). Goodman’s
new riddle is largely equivalent to Hume’s problem, but assumes a different per-
spective by focusing on linguistic aspects of inductive inferences, in particular on the
extension of terms or concepts to yet unknown events or objects.
If one ﬁnds emeralds always to be green in a sequence of observations before a
certain moment t, why, Goodman asks, do we infer from these observations that the
next emerald after t will also be green? Why do we inductively infer that all emeralds
are green, rather than that all emeralds are grue, where grue is deﬁned as ‘green until
time t and blue afterwards’? As a ﬁrst reaction, one might point out that the term
‘grue’ has in its deﬁnition an explicit reference to a point in time and that inductive
inferences should generally rely on attributes without such time-dependence. How-
ever, if a further term ‘bleen’ is introduced, denoting blue until t and green after-
wards, the situation becomes completely symmetric. If one deﬁnes grue and bleen in
terms of green and blue, there is time-dependence in the deﬁnitions. But if one
deﬁnes green and blue in terms of grue and bleen, the same happens. For example,
green is grue until time t and bleen afterwards.
Goodman’s riddle asks the same question as Hume’s problem of induction,
namely why we can expect that a sequence of constant conjunction will be continued
in the future. But it poses this question in terms of the extensibility of predicates.
Why are inferences relying on established categories such as green or blue usually
more successful than those relying on odd categories such as grue or bleen? As we
have seen, the time-dependence in the respective deﬁnitions cannot solve this
question.
Furthermore, Goodman’s new riddle shows a problem with a typical response to
the problem of induction, namely that induction establishes only probability, never
truth. After all, the probability of an inductive inference will broadly relate to the
number of observed instances that are taken into account. But this number is the
same for both a prediction in terms of green and one in terms of grue. Thus, the
probabilities of both predictions should be similar, immediately leading to contra-
dictions with the axioms of probability.
Remarkably, both Hume’s and Goodman’s skeptical arguments rely on enumer-
ative induction. Therefore, one approach to solving the problem of induction calls
into question whether such enumerative induction constitutes the appropriate induc-
tive methodology. This issue will be taken up again in Chap. 4. For now, let me point
2.5
Arguments Against Inductivism
31

out that there is considerable controversy about what the correct type of induction is
and whether enumerative induction constitutes an important part of inductive meth-
odology. To this day it remains unclear what a valid canon of inductive methodology
is and whether such a canon exists at all, which only underscores the uncertainty of
empirical predictions as implied by the problem of induction. Analyzing the logic of
predictively successful algorithms from data science may contribute to a solution of
this issue.
Another important argument against inductivism, which also ﬁgures prominently
in debates on data science, is based on the so-called theory-ladenness of observation,
according to which any observation statement necessarily presupposes background
theory. Obviously, such theory-ladenness of observation undermines the distinction
between theory and data which is indispensable for any inductivist approach. After
all, inductivism starts with a collection of facts, more exactly with data representing
these facts, and infers theoretical statements from the data. For the same reasons, the
argument from theory-ladenness also undermines the notion of data science, which
supposedly starts with pure uninterpreted data in order to derive predictions and
general laws. This is possible only if a sharp data–theory distinction exists. Further-
more, data science is habitually portrayed as being largely theory-independent,
which is impossible if the data themselves are heavily theory-laden.
A version of theory-ladenness can already be found in Whewell’s writings.
Theory-ladenness follows from his construal of induction as colligation of facts,
i.e. as subsumption of facts under certain abstract ideas (Whewell 1858a, Ch. II.IV).
However, the classical argument for theory-ladenness stems from Duhem’s Aim and
Structure of Physical Theory. Duhem writes: “We have seen that in the mind of the
physicist there are constantly present two sorts of apparatus: one is the concrete
apparatus in glass and metal, manipulated by him, the other is the schematic and
abstract apparatus which theory substitutes for the concrete apparatus and on which
the physicist does his reasoning. For these two ideas are indissolubly connected in
his intelligence, and each necessarily call on the other.” (1962, 182–3) For Duhem,
theory and facts are intimately linked. His main argument for theory-ladenness is
that, at least in advanced sciences such as physics, experiment and observation
presuppose sophisticated instruments such as manometers, calorimeters, or galva-
nometers, which require all kinds of theoretical knowledge for their successful
employment and interpretation.
Duhem was chieﬂy interested in the logic of experiments in physics. However, he
did note an interesting distinction with respect to experiments in more phenomeno-
logical sciences like chemistry or physiology. These do not usually presuppose the
theory itself that is being tested, but rather theories from another domain, often from
physics. Duhem considered the distinction “of little importance” (1962, 183)—an
assessment, with which I will eventually come to disagree (cp. Chap. 3). Norwood
Russell Hanson, in his Patterns of Discovery, extended the notion of theory-
ladenness from the domain of physics to any kind of observation or sensual
impression. Hanson illustrated his claims using optical riddles such as the rabbit-
duck illusion, which seem to support the notion that perception and interpretation are
32
2
Inductivism

not clearly separable. With respect to the visual sense, Hanson famously claimed that
“there is more to seeing than meets the eyeball” (1958, 294)
Many modern-day critics of an inductivist data science refer to theory-ladenness.
For instance, Sabina Leonelli writes that: “Inferential reasoning from data is tightly
interrelated with speciﬁc theoretical commitments about the nature of the [. . .]
phenomena under investigation, as well as with experimental practices through
which data are produced, tested and modelled.” (Leonelli 2012, 2) Similarly, Werner
Callebaut evokes a “search-light theory” for scientiﬁc enquiry in data science,
according to which background knowledge and prior modeling assumptions are an
indispensable guideline for scientists (2012, 74). Finally, Rob Kitchin points out that
theoretical knowledge seems necessary for many of the modern companies trading in
big data: “Google undertakes extensive research and development, it works in
partnership with scientists and it buys scientiﬁc knowledge, either funding research
within universities or by buying the IP of other companies, to reﬁne and extend the
utility of how it organizes, presents and extracts value from data. Thus, if statistical
algorithms ﬁnd patterns in data it is because pattern recognition science, along with
domain-speciﬁc knowledge, has been employed.” (Kitchin 2014, 134; my italics) An
attentive reader will notice the tension between such viewpoints and the case study
of section 2.2.
Duhem is widely considered to be the originator of another argument
undermining naïve versions of both inductivism and hypothetico-deductivism.
This argument is based on the thesis of conﬁrmational holism, according to which
isolated hypotheses can neither be conﬁrmed nor falsiﬁed, but only larger groups of
hypotheses. Thus, induction can never prove isolated general laws to be true, but
such judgments always depend on the theoretical context. Also, conﬁrmational
holism undermines the Baconian notion that induction should proceed slowly from
the data to laws of increasing generalization until the most abstract level is reached.
According to Duhem, the main argument for conﬁrmational holism is based on
the theory-ladenness of observation. After all, if every observation requires a
considerable theoretical framework for its interpretation, whatever is derived from
observation only holds under the assumption that the framework itself is correct.
While Duhem again restricted his claim to physics (“An experiment in physics can
never condemn an isolated hypothesis but only a whole theoretical group”; 1962, II.
VI.2, my italics), the thesis of conﬁrmational holism was generalized later by Willard
Van Orman Quine to all observations, both in the sciences and in everyday life
(Quine 1951).
Two further theses that can at least in part be traced back to Duhem and that are
somewhat related to theory-ladenness and conﬁrmational holism are the impossibil-
ity of an experimentum crucis and the underdetermination of theories. The former
refers to experiments that decide between two or more competing hypotheses,
e.g. between the wave or particle nature of light. Duhem notoriously claimed that
such experiments are “impossible in physics” (1962, II.VI.3). Broadly, the impos-
sibility of an experimentum crucis can be argued on the basis of conﬁrmational
holism, according to which hypotheses can never be conﬁrmed and falsiﬁed in
isolation. Thus, both the claim that light behaves like a wave and the claim that it
2.5
Arguments Against Inductivism
33

behaves like a particle, each taken in isolation without a much broader context of
additional theoretical assumptions, lack empirical meaning. Therefore, an experi-
ment cannot decide between them. Duhem also points out that in the empirical
sciences—in contrast to mathematics—one can never be certain whether the con-
sidered alternatives exhaust all possibilities. After all, one can easily imagine that
light is neither particle nor wave but something entirely different.
If there is no way to empirically decide between opposing ontological views,
e.g. concerning the true nature of light, then it is plausible to assume that physical
theories are not fully determined by experience—which corresponds to the
underdetermination thesis that has been much discussed in modern philosophy of
science. Duhem writes: “If we conﬁne ourselves strictly to considerations of pure
logic, we cannot prevent a physicist from representing by several incompatible
theories diverse groups of laws, or even a single group of laws; [...] Logic evidently
imposes on the physicist only one obligation: not to confuse or mix up the various
methods of classiﬁcation he employs. [...] Logic does not, therefore, furnish any
unanswerable argument to anyone who claims we must impose on physical theory
an order free from all contradiction. Are there sufﬁcient grounds for imposing such
an order if we take as a principle the tendency of science toward the greatest
intellectual economy? We do not think so.” (Duhem 1962, 101–102; my italics)
Duhem’s various epistemological claims, in particular conﬁrmational holism and
the underdetermination thesis, undermine the notion of scientiﬁc truth, which is
crucial for inductivist approaches, as we have seen. If different theoretical frame-
works are capable of accounting for a range of phenomena comparably well, one
cannot expect to eventually ﬁnd the one true framework reﬂecting the real ontology.
Instead, Duhem’s epistemological claims seem to highlight that there are signiﬁcant
ingredients in any scientiﬁc theory that cannot be deduced from experience, but
originate in human reason and intuition. This is problematic for a data science which
aims to automatize the scientiﬁc process while obviously lacking both human reason
and intuition.
Furthermore, Duhem directly criticizes the inductivist approaches of Newton and
Ampère (1962, II.VI.4-5). To this end, he points out that it is generally not possible
to derive the most abstract level of physical theories from phenomenological laws.
According to Duhem, Newton’s axioms are symbolic and approximate:
two inevitable rocky reefs make the purely inductive course impracticable for the physicist.
In the ﬁrst place, no experimental law can serve the theorist before it has undergone an
interpretation transforming it into a symbolic law, and this interpretation implies adherence
to a whole set of theories [conﬁrmational holism]. In the second place, no experimental law
is exact but only approximate, and is therefore susceptible to an inﬁnity of distinct symbolic
translations; and among all these translations the physicist has to choose one which will
provide him with a fruitful hypothesis without his choice being guided by experiment at all
[underdetermination]. (1962, 199)
According to Duhem, Newton’s axioms are approximate in that they differ slightly
in their empirical claims from Kepler’s laws for planetary orbits. Here, the latter are
experimental laws or at least closer to the experimental laws. And Newton’s axioms
are symbolic because they introduce abstract terms such as force and mass that do
34
2
Inductivism

not have immediate empirical meaning—in contrast to Kepler’s laws, which refer
only to the more directly observable geometry of space and time. Note again that in
the quote above, Duhem cites conﬁrmational holism and underdetermination as
undermining the inductivism of Newton and others.
In response to these sophisticated attacks, many have rejected inductivism. Thus,
the challenge of the next chapters will consist in rehabilitating inductivism to an
extent that these arguments do not undermine the inductivist methodology of data
science. To this purpose, two distinctions are introduced in the next two chapters: a
distinction between phenomenological and theoretical science and a distinction
between enumerative and variational induction. I eventually conclude that while
Duhem’s arguments do not undermine an inductivist data science, they show that
data science as we know it today is not capable of deriving fundamental theories of
the natural sciences such as Newtonian physics or Ampère’s electromagnetic theory.
References
Ampère, Jean-Marie. 1826/2012. Mathematical theory of electro-dynamic phenomena uniquely
derived from experiments. Transl. Michael D. Godfrey. Paris: A. Hermann. https://archive.org/
details/AmpereTheorieEn
Bacon, Francis. 1620/1994. Novum Organum. Chicago, Il: Open Court.
Bellman, Richard E. 1961. Adaptive Control Processes: A Guided Tour. Princeton: Princeton
University Press.
Breiman, Leo. 2001. Statistical Modeling: The Two Cultures. Statistical Science 16 (3): 199–231.
Callebaut, Werner. 2012. Scientiﬁc perspectivism: A philosopher of science’s response to the
challenge of big data biology. Studies in History and Philosophy of Biological and Biomedical
Science 43 (1): 69–80.
Chomsky, Noam. 1965. Aspects of the Theory of Syntax. MIT Press.
Ducheyne, Steffen. 2005. Bacon’s Idea and Newton’s Practice of Induction. Philosophica 76:
115–128.
Duhem, Pierre. 1906/1962. The Aim and Structure of Physical Theory. New York: Atheneum.
Einstein. 1934. On the Method of Theoretical Physics. Philosophy of Science 1 (2): 163–169.
Feynman, Richard. 1967. The Character of Physical Law
Frické, Martin. 2014. Big Data and Its Epistemology. Journal of the Association for Information
Science and Technology 66 (4): 651–661.
Gillies, Donald. 1996. Artiﬁcial Intelligence and Scientiﬁc Method. Oxford: Oxford University
Press.
Goodman, Nelson. 1954. Fact, Fiction, and Forecast. London: Athlone Press.
Halevy, Alon, Peter Norvig, and Fernando Pereira. 2009. The Unreasonable Effectiveness of Data.
IEEE Intelligent Systems 24 (2): 8–12.
Hanson, Norwood Russell. 1958. Patterns of Discovery: An Inquiry into the Conceptual Founda-
tions of Science. Cambridge: Cambridge University Press.
Harman, Gilbert, and Sanjeev Kulkarni. 2007. Reliable Reasoning. Induction and Statistical
Learning Theory. Boston: MIT Press.
Hastie, T., and R. Tibshirani. 1990. Generalized Additive Models. London: Chapman and Hall.
Hume, David. 1748. An Enquiry concerning Human Understanding. London: A. Millar.
Jelinek, Frederick. 2009. The Dawn of Statistical ASR and MT. Computational Linguistics 35 (4):
483–494.
References
35

Kauermann, Goeran. 2006. Nonparametric Models and their Estimation. In Modern Econometric
Analysis, ed. Olaf Hübler and Joachim Frohn, 137–152. Springer: Berlin.
Kitchin, Rob. 2014. The Data Revolution. Los Angeles: Sage.
Lavoisier, Antoine. 1789/1890. Elements of Chemistry. Edinburgh: William Creech. http://www.
gutenberg.org/ﬁles/30775/30775-h/30775-h.htm
Leonelli, Sabina. 2012. Introduction: Making sense of data-driven research in the biological and
biomedical sciences. Studies in History and Philosophy of Biological and Biomedical Sciences
43 (1): 1–3.
Newton, Isaac. 1726/1999. Mathematical Principles of Natural Philosophy. Berkeley: University
of California Press.
Norvig, Peter. 2009. Natural Language Corpus Data. In Beautiful Data, ed. T. Segaran and
J. Hammerbacher, 219–242. Sebastopol: O’Reilly.
———. 2017. On Chomsky and the Two Cultures of Statistical Learning. In Berechenbarkeit
der Welt? Philosophie und Wissenschaft im Zeitalter von Big Data, ed. W. Pietsch, J. Wernecke,
and M. Ott, 61–83. Wiesbaden: Springer.
Pérez-Ramos, Antonio. 1996. Bacon’s Forms and the Maker’s Knowledge. In The Cambridge
Companion to Bacon, ed. Markuu Peltonen, 99–120. Cambridge: Cambridge University Press.
Pietsch, Wolfgang. 2015. Aspects of Theory-Ladenness in Data-Intensive Science. Philosophy of
Science 82 (5): 905–916.
———. 2016. The Causal Nature of Modeling with Big Data. Philosophy & Technology 29 (2):
137–171.
———. 2017. Causation, Probability, and all that: Data Science as a Novel Inductive Paradigm. In
Frontiers in Data Science, ed. Matthias Dehmer and Frank Emmert-Streib, 329–353. Boca
Raton: CRC Press.
———. 2021. Big Data. Cambridge: Cambridge University Press.
Popper, Karl. 1935/2002. The Logic of Scientiﬁc Discovery. London: Routledge Classics.
———. 1963. Conjectures and Refutations. Abingdon: Routledge.
Quine, Willard Van Orman. 1951. Two Dogmas of Empiricism. The Philosophical Review 60 (1):
20–43.
Russell, Stuart, and Peter Norvig. 2009. Artiﬁcial Intelligence. Upper Saddle River, NJ: Pearson.
Snyder, Laura J. 2017. William Whewell. Stanford Encyclopedia of Philosophy (Winter 2017
Edition). https://plato.stanford.edu/archives/win2017/entries/whewell/
Sprenger. 2011. Science without (parametric) models: the case of bootstrap resampling. Synthese
180 (1): 65–76.
Whewell, William. 1858a. Novum Organon Renovatum. 3rd ed. London: John W. Parker.
———. 1858b. History of Scientiﬁc Ideas. Vol. I. London: John W. Parker.
36
2
Inductivism

Chapter 3
Phenomenological Science
Abstract In this Chapter, a distinction between phenomenological and theoretical
science is introduced. The former establishes causal knowledge, which can be used
for prediction and possibly manipulation. The latter aims at theoretical and abstract
frameworks, which are non-causal and provide explanations by unifying seemingly
disparate phenomena. Data science belongs to phenomenological science. Some of
the classic arguments against inductivism, in particular underdetermination, theory-
ladenness of observation and conﬁrmational holism, turn out to be relevant mainly
for theoretical science rather than for phenomenological science. Given that data
science is a phenomenological approach, these arguments cannot undermine the
project of an inductivist data science.
Keywords Data science · Phenomenological science · Exploratory
experimentation · Underdetermination · Holism · Theory-ladenness · Neural network
In this chapter, I elaborate a distinction between theoretical and phenomenological
science that originates in the epistemological views of, among others, Ernst Mach,
Henri Poincaré, Pierre Duhem, Thomas Kuhn, and more recently the so-called
Stanford School in philosophy of science, in particular Nancy Cartwight and Ian
Hacking. I argue that data science belongs to phenomenological science, which
allows sidestepping some of the epistemological arguments against inductivism
from the previous chapter, since these arguments mainly concern theoretical science.
3.1
Theoretical Versus Phenomenological Science
Methodologists have for a long time distinguished between two kinds of scientiﬁc
activities: one that stays close to the facts and another that is interested primarily in
abstract and universal relationships. Often, this distinction is thought to be between
the observable and the unobservable, i.e. between entities and phenomena that can
be directly experienced, such as chairs or tables, and entities and phenomena that can
© Springer Nature Switzerland AG 2022
W. Pietsch, On the Epistemology of Data Science, Philosophical Studies Series 148,
https://doi.org/10.1007/978-3-030-86442-2_3
37

at best be indirectly perceived given some theoretical background assumptions, such
as atoms or quarks. However, as for example Nancy Cartwright has pointed out, the
distinction between observable and unobservable phenomena is a shaky one (1983,
1–3). After all, every sense experience involves both the signals detected by the
respective sense organ and certain structures in the brain which are responsible for
interpreting the detected signals. Thus, it is questionable whether direct,
uninterpreted observation is possible at all. And even if one concedes that some
phenomena are directly perceivable while others are not, the distinction seems to
vary over time. For example, one could argue that atoms were once unobservable but
have become observable in the twentieth century through technological advances
such as the electron microscope. Thus, when Ernst Mach and others denied the
existence of atoms in the nineteenth century, this was a somewhat viable standpoint,
since there was only indirect evidence for these entities.
I agree with Nancy Cartwright that the distinction between observable and
unobservable phenomena is too blurry to ascribe deeper epistemological signiﬁcance
to it. Instead, the distinction I want to argue for is between phenomenological science
on the one hand and abstract or theoretical science on the other hand. I have begun
to recognize the importance of this distinction as a philosopher of science with a
background in physics working at a technical university with strong engineering
departments. When I held my ﬁrst introductory philosophy of science classes to
engineering students, I had a naïve conception of engineering being more or less
applied natural science, mostly just applied physics. Slowly, not least thanks to the
feedback I got from students, I started to realize that the engineering sciences do not
ﬁt into this picture at all. Instead, as I argue in the following, the relationship between
engineering and physics can best be understood if one recognizes that the former is a
phenomenological science and the latter is a theoretical science. So let me elaborate
the distinction using these disciplines as examples. In the next Sect. 3.2, I will then
proceed to argue that data science is a phenomenological science, which will help to
explain many features of data science.
Theoretical science has dominated the work and views of philosophers of science
for much of the last century, mostly because its explanatory frameworks, such as
quantum mechanics, the theory of relativity, or the theory of evolution, are much
more spectacular than the piecemeal work of phenomenological science. For exam-
ple, a detailed epistemology of engineering science, which is a paradigmatic phe-
nomenological science, is still largely missing. Moreover, even the great
technological achievements of humankind, such as airplanes, computers, or nuclear
power plants, are typically ascribed to theoretical science, while the much more
important contributions of phenomenological science to these achievements are
largely ignored. The distinction between theoretical and phenomenological science
has been defended most notably by Pierre Duhem and more recently by Nancy
Cartwright. Note that their accounts differ signiﬁcantly, as they also differ from my
viewpoint which is developed in the following.
Maybe the most fundamental difference between theoretical and phenomenolog-
ical science concerns the overall aim: while the former wants to explain phenomena
and understand the world, the latter focuses on predicting and changing the world.
38
3
Phenomenological Science

For example, physics provides grand theories that show the hidden unity in a wide
range of phenomena, while engineering mostly focuses on how to realize certain
goals by designing and constructing suitable artifacts.
A related difference concerns the nature of the laws that are prevalent in these
scientiﬁc practices. While the laws of phenomenological science are mostly causal,
the laws of theoretical science are not. This difference will become clearer, when a
suitable account of causation is developed in Chap. 5. Here, it sufﬁces to say that the
crucial feature of causal laws according to the proposed account is that causal laws
allow for effective manipulation of the phenomena. Changing the causes alters the
respective effects. This feature of causation was also stressed by Nancy Cartwright:
“causal laws cannot be done away with, for they are needed to ground the distinction
between effective strategies and ineffective ones” (Cartwright 1979, 420). Referring
to the difference in aim, engineers can manipulate the phenomena in systematic ways
exactly because they possess causal knowledge about them. Building bridges,
improving computers, or producing energy—all these activities require causal
knowledge about the respective domains. By contrast, physicists, who are mainly
interested in understanding and explanation, do not necessarily have to rely on
causal laws, as we will see in a moment.
Given that phenomenological science mainly deals with causal knowledge,
important characteristics of phenomenological science can be derived from a con-
ceptual analysis of causation. One important characteristic of the account of causa-
tion elaborated in Chap. 5 is that causal laws are always local and contextual. This
follows because causal laws are derived inductively and there are always conditions
or circumstances whose potential relevance for the phenomenon has not yet been
tested. Thus, the complete set of circumstances under which a certain causal
relationship holds can never be made fully explicit. In other words, causal laws
always require a ceteris paribus clause, i.e. the respective relationships only hold
under the assumption that no further relevant circumstances change. And indeed, the
functioning of technical artifacts in the engineering sciences can only be guaranteed
in contexts for which these artifacts have been tested. Under unforeseen circum-
stances, they might easily cease to function as expected.
In summary, because knowledge in the phenomenological sciences aims at
prediction and manipulation, it is causal, and because it is causal, this knowledge
is local and contextual. The respective causal relationships hold only under the
circumstances which have so far been tested. And for much the same reason these
relationships hold only approximately, because there will always be some known or
unknown circumstances which have a minor inﬂuence on the examined phenome-
non. But often this effect is negligible with respect to a given aim or it may not even
be perceivable with the current measurement accuracy.
Since phenomenological science generates local causal knowledge, it does not
allow for theoretical explanation that, by tracing the similarities in a wide range of
seemingly disparate phenomena, relies on the uniﬁcation of those phenomena under
a common theoretical framework. Phenomenological science does however allow
for causal explanation, which basically refers to relevant causal factors that made a
difference to the examined phenomenon in a given context. But such causal
3.1
Theoretical Versus Phenomenological Science
39

explanations are generally rather shallow and superﬁcial, because they hold only
locally and do not expose deeper connections between the phenomena (cp. the eighth
thesis in the introduction 1.2).
A further important feature of phenomenological science is that it aims to gather
causal knowledge for as wide a range of phenomena in a given domain as possible.
For example, aeronautical engineers want to build airplanes that ﬂy even under the
most adverse circumstances, as can be seen in the enormous decrease of fatal
accidents in aeronautics over the past century. Computer engineers design computers
that function not only if operated by specialists but also by rather naïve laypeople.
The development of many technologies can be understood in terms of an extension
of the range of their applicability, while effectiveness and efﬁciency are also
optimized. Engineers, as phenomenological scientists, are interested in the full
range of phenomena operating out there ‘in the wild’.
Theoretical science is quite different. It is chieﬂy interested in what Thomas Kuhn
in his inﬂuential Structure of Scientiﬁc Revolutions has called paradigmatic phe-
nomena or ‘exemplars’. The latter term is introduced in the postscript to the book
referring to speciﬁc problems and their solutions which are typical for a ﬁeld (Kuhn
1996, 174–210). Exemplars are studied by new students that want to learn a
discipline. Typical exemplars in physics are the pendulum, the inclined plane, the
movement of the planets, or modern particle accelerators.
Physicists generally are not interested in the full breadth of phenomena, but rather
study such exemplars under extremely well-controlled circumstances (i.e. in labo-
ratory environments). These exemplars are studied to the utmost accuracy in order to
ﬁnd yet unexplained small errors and aberrations. For example, the perihelion
precession of Mercury, a small deviation of Mercury from its predicted path,
contributed to the demise of Newtonian mechanics and played an important role
for the eventual acceptance of the general theory of relativity. For most practical
purposes, for sending satellites into orbit and ﬂying to the moon, this small deviation
is irrelevant. For these tasks the Newtonian framework is sufﬁcient.
The task of the physicist is to develop a hierarchical framework of laws that can
fully account for such exemplars. If possible, every effect should be explained up to
its current measurement accuracy. And physicists go a long way to ﬁnd minuscule
discrepancies between theory and phenomena that are often practically irrelevant.
Up to this point, these laws can still be understood as causal laws about a given
exemplar, accounting for what is happening on the phenomenological level. But
theoretical science has much more wide-reaching ambitions. The laws of physics are
not intended to be local and contextual, but rather they aim to be universal and exact.
When it became clear that the laws of Newtonian mechanics could not account for
certain phenomena like blackbody radiation or the perihelion precession of Mercury,
these laws were abandoned and replaced by different conceptual frameworks that
aspired to be fully universal and exact, namely quantum mechanics and the theory of
relativity.
However, universality and exactness cannot be reached for causal laws. Again,
this will become clear in Chap. 5, when a suitable account of causation is elaborated.
As mentioned, the very process by which causal laws are inductively derived from
40
3
Phenomenological Science

observation and experiment implies that these laws are always ceteris paribus. In
other words, causal laws can never be fully universal and fully exact as com-
monly required for the fundamental laws of physics. Thus, there is a decisive step
from considering the laws of physics as phenomenological laws, which govern
exemplary phenomena and which are causal and therefore local and approximate,
to considering the laws of physics as abstract theoretical laws, which are strictly
universal and strictly exact, but not causal anymore.
The step from causal phenomenological laws to non-causal theoretical laws is
only possible by compromising the empirical nature of the respective laws. Theo-
retical laws exhibit considerable normative aspects that scientists have to commit
to. In the face of recalcitrant experiences, it is usually not an option to abandon the
theoretical laws: other strategies should be employed ﬁrst, e.g. assuming auxiliary
hypotheses or changing deﬁnitions. Of course, such strategies are only feasible if the
theoretical laws are sufﬁciently remote from direct experience. In a similar vein,
some have argued that theoretical laws are conventions or implicit deﬁnitions. For
example, Newton’s axioms are often taken to deﬁne the notion of force. As the
French mathematician and physicist Henri Poincaré put it, who ﬁrst proposed such
conventionalism regarding the fundamental laws of physics: “Thus is explained how
experiment may serve as a basis for the principles of mechanics, and yet will never
invalidate them.” (1905, 105; his italics).
The step from phenomenological to theoretical science is far from trivial, mainly
because it presupposes a choice which phenomena are taken to be exemplars.
Obviously, the natural world does not come with clear designations as to which
phenomena are paradigmatic and which are not. For example, other phenomena
were paradigmatic for Aristotelian science than for Galilean-Newtonian science.
There is an unavoidable circularity: which phenomena are paradigmatic depends on
the assumed theory and vice versa. The notion of an exemplar ﬁts well with Bacon’s
classiﬁcation of 27 prerogative instances, which are especially useful for inductive
enquiry (1620/1994, II.XXII-II.LII). For instance, exemplars bear some similarity to
Bacon’s concept of solitary instances, which “exhibit the required nature in subjects
that have nothing in common with any other subject than the nature in question”, for
example color in prisms or crystalline gems (1620/1994, II.XXII).
Since a unique, objective choice of exemplars does not exist, abstracting from
phenomenological laws to theoretical laws will largely depend on pragmatic con-
siderations concerning simplicity, fruitfulness, or consistency of description with
respect to a given range of phenomena. There are no true exemplars, just as there is
not one true theoretical framework accounting for a given range of phenomena
(cp. the discussion on underdetermination in Sect. 2.5). Generalizing from phenom-
enological laws to a universal theoretical framework thus requires a considerable
amount of intuition and conceptual creativity. A substantial amount of rhetoric is
necessary to eventually convince the respective community to accept a theoretical
framework.
This leads to a further crucial difference between theoretical and phenomenolog-
ical science, which links to the topic of the previous chapter. Phenomenological
science
aiming
at
causal
knowledge
primarily
proceeds
inductively,
by
3.1
Theoretical Versus Phenomenological Science
41

experimentally determining phenomenological laws for a wide range of empirical
phenomena. Those who have held in their hands one of the massive compendia of
phenomenological relationships that are collected and used in the engineering
sciences will realize that causal knowledge in engineering science is not fully
derivable from the fundamental equations of a theoretical framework. For example,
the 1600-page VDI Heat Atlas gathers thousands of phenomenological constants,
equations, and graphs that have been established empirically and cannot be derived
from the fundamental laws of thermodynamics (VDI 2010).
All these phenomenological laws are determined inductively by careful experi-
mentation and observation. As will be further elaborated in Sect. 3.2, such inductive
analysis always relies on a process of variable variation. By systematically changing
those variables which are deemed potentially relevant, the impact on a given
phenomenon is examined. This procedure is well suited for determining causal
dependencies according to the difference making account of causation elaborated
in Chap. 5. In summary, phenomenological science proceeds inductively, because it
aims at causal knowledge.
By contrast, theoretical science is dominated by a hypothetico-deductive meth-
odology. Remember in this respect that physicists such as Einstein or Feynman
endorsed hypothetico-deductivism and that physics—in particular twentieth century
physics—can be seen as a paradigmatic theoretical science (cp. Sect. 2.1). Of course,
the causal laws governing certain exemplars are still determined by induction, but
the step to a universal theoretical framework cannot be carried out inductively.1 As
already stated, this step involves intuition and creativity, and it is governed by
pragmatic criteria—just as hypothetico-deductivism requires for the formulation of
hypotheses. Besides the development of a conceptual framework, an essential task
for the theoretical scientist is to verify whether certain predictions that are deduc-
tively derived from a hypothesized theoretical framework correspond to the facts.
Note that such derivations are never straightforward, but often involve further
assumptions, reﬁnement of deﬁnitions, etc. The theoretical framework is certainly
never veriﬁed in this process. Ascribing truth or probability to a theoretical frame-
work amounts to a category mistake (Pietsch 2013; see also Sect. 3.4 below). Thus,
there are obvious parallels between theoretical science and a hypothetico-deductive
methodology, which essentially result from the fact that theoretical laws, in contrast
to phenomenological laws, cannot be inductively derived from experiment and
observation, but largely have to be hypothesized.
There are further differences between theoretical and phenomenological science
related to those mentioned above. An interesting one concerns the extent to which
both practices are affected by scientiﬁc revolutions.2 With respect to theoretical
science, scientiﬁc revolutions crucially involve a change of the respective theoretical
1In some of the literature, the inference to an explanatory framework is called abduction. Since this
terminology somewhat obscures that theoretical science mostly follows a hypothetico-deductive
rationale, I have chosen not to use it.
2For a discussion of the nature of scientiﬁc revolutions, see of course Kuhn (1996).
42
3
Phenomenological Science

framework. In a way, scientiﬁc revolutions are deﬁned by such a change. Thus, most
aspects of theoretical science are revised: the exemplars, the theoretical laws, the
concepts employed in these laws as well as the fundamental explanations of the
relevant phenomena.
By contrast, phenomenological science changes to a much lesser extent in
the course of scientiﬁc revolutions. Certainly, novel phenomena might be added to
the causal knowledge in the respective ﬁeld—in particular those which led to the
abandonment of the earlier theoretical framework. But these are rather minor
additions, while the bulk of phenomenological science remains intact. Of course,
the new theoretical framework introduces novel terminology, which can be used to
describe the phenomena. But many phenomenological laws continue to be formu-
lated in the language of the previous theoretical framework. Often, the new frame-
work just adds one further possibility how to account for the phenomena, an issue
that I will return to in Sect. 3.3. Indeed, engineers readily rely on all kinds of
theoretical frameworks that have long been abandoned by physicists, such as
Newtonian mechanics or classical thermodynamics, as long as these yield adequate
approximations for the practical problems at hand.
The distinction between theoretical and phenomenological science as it was
presented above owes much to Nancy Cartwright’s philosophy of science. Most
importantly, we both take serious the distinction between fundamental and phenom-
enological laws (1983, Essay 6):
“A long tradition distinguishes fundamental from phenomenological laws, and favours the
fundamental. Fundamental laws are true in themselves; phenomenological laws hold only on
account of more fundamental ones. This view embodies an extreme realism about the
fundamental laws of basic explanatory theories. Not only are they true (or would be if we
had the right ones), but they are, in a sense, more true than the phenomenological laws that
they explain. I urge just the reverse. I do so not because the fundamental laws are about
unobservable entities and processes, but rather because of the nature of theoretical explana-
tion itself. As I have often urged in earlier essays, like Pierre Duhem, I think that the basic
laws and equations of our fundamental theories organize and classify our knowledge in an
elegant and efﬁcient manner, a manner that allows us to make very precise calculations and
predictions. The great explanatory and predictive powers of our theories lie in their funda-
mental laws. Nevertheless the content of our scientiﬁc knowledge is expressed in the
phenomenological laws.” (Cartwright 1983, 100, her italics).
As will be further elaborated in Sect. 3.4, I agree with Cartwright that contrary to
received wisdom the phenomenological laws are better candidates for truth than the
fundamental laws (i.e. the theoretical laws, as I have called them). While fundamen-
tal laws are highly explanatory by providing a framework for the uniﬁcation of
various phenomena, they do not summarize the empirical content of a respective
ﬁeld, which remains in the phenomenological laws. The primary reason for this lies
in the complexity of most phenomena. Thus, Cartwright emphasizes, as I have, that
theoretical science mainly aims at explanation and phenomenological science at
empirical adequacy, e.g. in terms of correct predictions.
Drawing on many case studies from the sciences, in particular physics and
economics, Cartwright emphasizes that the world is much more complex than the
neat and tidy account of fundamental laws in the theoretical sciences would have us
3.1
Theoretical Versus Phenomenological Science
43

expect. The empirical content of human experience cannot be summarized in terms
of true laws which are “‘few in number’, ‘simple’ and ‘all-embracing’” (1999, 10).
Rather, an “immense number of very highly conﬁrmed phenomenological laws”
exist, which are in general not derived from fundamental laws (Cartwright 1983, 3).
This leads to Cartwright’s notion of a Dappled World, as is the title of her third book:
“The laws that describe this world are a patchwork, not a pyramid. They do not take after the
simple, elegant and abstract structure of a system of axioms and theorems. Rather they look
like – and steadfastly stick to looking like – science as we know it: apportioned into
disciplines, apparently arbitrarily grown up; governing different sets of properties at differ-
ent levels of abstraction; pockets of great precision; large parcels of qualitative maxims
resisting precise formulation; erratic overlaps; here and there, once in a while, corners that
line up, but mostly ragged edges; and always the cover of law just loosely attached to the
jumbled world of material things. For all we know, most of what occurs in nature occurs by
hap, subject to no law at all.” (1999, 1)
For Cartwright, reliable regularities can only be experienced in speciﬁc, well-
controlled situations that she terms ‘nomological machines’, which are “ﬁxed
(enough) arrangement[s] of components, or factors, with stable (enough) capacities
that in the right sort of stable (enough) environment will, with repeated operation,
give rise to the kind of regular behavior that we represent in our scientiﬁc laws”
(1999, 50). Thus, phenomenological laws governing such nomological machines
hold only in the speciﬁc context for which they have been devised. In other words,
they exhibit a pronounced ceteris paribus character. To some extent, exemplars are
nomological machines, although the latter notion is apparently intended to be much
broader including all situations where phenomenological laws hold and lead to
regularities.
While our viewpoints are in many ways similar and my own position owes much
to Cartwright’s approach, some differences exist. For example, Cartwright does not
endorse the conventionalism regarding fundamental laws that I have advocated,
which allowed me to establish universality and exactness for the fundamental laws
as usually claimed in theoretical science. Cartwright does state that fundamental
laws are more detached from actual experience and only apply to the world via a
model: “The abstract theoretical concepts of high physics describe the world only via
the models that interpret these concepts more concretely. So the laws of physics
apply only where its models ﬁt, and that, apparently, includes only a very limited
range of circumstances.” (1999, 4) I would argue that the theoretical framework
directly describes the world in the case of exemplars and otherwise only serves as a
guideline for the description of the phenomena—while agreeing with the basic point
that models are intermediaries between theory and experience.3
3With respect to the theory-model distinction, an important type of scientiﬁc model consists in a
systematic framework of phenomenological laws and concepts. In contrast to theories, such models
thus belong to phenomenological science, which accounts for many characteristics that are com-
monly ascribed to scientiﬁc models, e.g. by Daniela Bailer-Jones: „In my use, theories are not about
the empirical world in the same concrete sense as models. Models, by their very constitution, are
applied to concrete empirical phenomena, wheras theories are not. Theories, in turn, have the
44
3
Phenomenological Science

We both share the basic intuition that causation is essential for identifying those
relationships in the world that allow for intervention and manipulation (Sect. 5.1),
but the details of our accounts of causation differ considerably. Maybe most
importantly, Cartwright is a pluralist about causation (2004), while I argue that
difference making captures the essence of causation and that all other aspects can be
ﬁt into that general picture (Chap. 5). Relatedly, Cartwright believes that some
phenomena are not governed by laws (as stated in the above quote), whereas
according to my approach even highly irregular phenomena can be accounted for
in terms of causal laws, which admittedly are often forbiddingly complex. As
another example, I disagree with Cartwright’s claim “no causes in, no causes out”,
i.e. that “old causal knowledge must be supplied for new causal knowledge to be
had” (1999, Ch. 2). While, as Cartwright argues, a reduction of causality to
non-causal probabilities seems indeed not feasible, difference making can establish
causation without itself being a causally tainted notion. Since causal laws are central
to phenomenological science, these and other conceptual differences concerning
causation have repercussions for our respective views on phenomenological science.
The outlined antirealist stance regarding fundamental science owes considerably
to Pierre Duhem, whose philosophy of science was already discussed in Sect. 2.5.
Most importantly, Duhem introduces a distinction between experimental laws and
theoretical principles, where the latter are symbolic and approximate. It resembles in
many ways the distinction between phenomenological and theoretical laws that was
proposed in the present section:
“A physical theory [. . .] is a system of mathematical propositions, deduced from a small
number of principles, which aim to represent as simply, as completely, and as exactly as
possible a set of experimental laws. [. . .] These principles may be called ‘hypotheses’ in the
etymological sense of the word for they are truly the grounds on which the theory will be
built; but they do not claim in any manner to state real relations among the real properties of
bodies. These hypotheses may then be formulated in an arbitrary way. [. . .] The various
consequences [. . .] drawn from the hypotheses may be translated into as many judgments
bearing on the physical properties of the bodies. [. . .] These judgments are compared with
the experimental laws which the theory is intended to represent.” (Duhem 1962, 19-20)
In this quote, Duhem emphasizes the hypothetico-deductive character of theoret-
ical science. Duhem also casts doubt on whether theoretical laws can be considered
true or false in contrast to phenomenological laws:
“Would it not be contradictory to say that a law is provisional, that it may be accepted by one
person and rejected by another? Yes and no. Yes, certainly, if we mean by ‘laws’ those that
capacity of being applied to empirical phenomena. This means that speciﬁc constraints belonging to
a concrete case are inserted into the (intrinsically more abstract) theory [. . .]. A theory needs to be
customized for its use in modeling a speciﬁc empirical phenomenon.“(Bailer-Jones 2009, 3) Due to
their phenomenological nature, such models inherit many of the characteristics of phenomenolog-
ical science as described in this section. For example, they refer to concrete objects or phenomena.
Also, they are formulated with a speciﬁc epistemic aim in mind, often in terms of prediction and
manipulation. They employ approximations and simpliﬁcations as long as these do not undermine
the mentioned epistemic aim. Finally, there may be different and even contradictory models of the
same phenomenon (see Chap. 7).
3.1
Theoretical Versus Phenomenological Science
45

common sense reveals [which are according to Duhem merely generalizations], those we can
call true in the proper sense of the word; such laws cannot be true today and false tomorrow,
and cannot be true for you and false for me. No, if we mean by ‘laws’ the laws that physics
states in mathematical form. Such laws are always provisional; not that we must understand
this to mean that a physical law is true for a certain time and then false, but at no time is it
either true or false. It is provisional because it represents the facts to which it applies with an
approximation that physicists today judge to be sufﬁcient but will some day cease to judge
satisfactory.” (1962, 172)
Presumably, the experimental laws from Duhem’s ﬁrst quote would also be such
common sense laws.
In summary, phenomenological science is distinguished from theoretical science
by the following characteristics. First of all, the aim is different. While phenomeno-
logical science focuses on prediction and manipulation of the phenomena, theoret-
ical science aims at explanation and understanding by developing a conceptual
framework that uniﬁes a large range of phenomena. From a methodological per-
spective, an important difference concerns the nature of the laws that dominate each
practice. While phenomenological science relies on causal laws that are inferred
inductively from observation and experiment, the laws of theoretical science are
abstract and, crucially, not causal. Due to their causal nature, the laws of phenom-
enological science hold only ceteris paribus, implying that they are context-
dependent and only approximate. By contrast, the non-causal laws of theoretical
science exhibit considerable normative aspects due to their conventional and deﬁ-
nitional nature. These theoretical laws can be assumed to be universal and exact only
because they are non-causal and abstract. Phenomenological science usually aims to
account for a wide range of related phenomena, while theoretical science is devel-
oped in view of certain paradigmatic phenomena or exemplars, e.g. the inclined
plane, particle accelerators, or Galapagos ﬁnches.
In terms of overall methodology, phenomenological science largely follows an
inductivist approach. After all, causal laws are generally inferred inductively. By
contrast, the methodology of theoretical science bears a strong resemblance to
hypothetico-deductivism, not least because theoretical laws, due to their abstract
nature, cannot be inductively inferred from experience. This difference in basic
methodology implies that scientiﬁc revolutions affect theoretical science much
more profoundly than phenomenological science. Phenomenological laws, once
they are reliably established by induction, remain valid even after scientiﬁc revolu-
tions, while the corresponding theoretical framework may be completely overthrown
in the course of a revolution. Predictions that rely on well-established phenomeno-
logical laws will remain intact, while theoretical explanations may differ substan-
tially before and after the revolution. The distinction between theoretical and
phenomenological science can be illustrated well by comparing physics as a para-
digmatic theoretical science with engineering as a typical phenomenological
approach. In later sections of this chapter, it will be shown that data science
constitutes a scientiﬁc practice that largely remains on the phenomenological level.
46
3
Phenomenological Science

3.2
Exploratory Experimentation
In this section, an experimental approach called exploratory experimentation is
introduced as a typical practice within phenomenological science. Given that data
science also belongs to phenomenological science, data science and exploratory
experimentation turn out to exhibit crucial similarities, which will be outlined in
Sect. 3.3.
In the introduction to his inﬂuential book Representing and Intervening, Ian
Hacking writes that experiments “have been neglected for too long by philosophers
of science, so writing about them has to be novel. Philosophers usually think about
theories.” (1983, xiv) Hacking’s book consists of two parts: the ﬁrst part on
‘representing’ focuses on theory, the second part on ‘intervening’ focuses on exper-
iment. Hacking is generally credited with founding a novel movement in philosophy
of science which is referred to as ‘New Experimentalism.’4 Many of the philoso-
phers of the Stanford School played a signiﬁcant role in this development, including
Nancy Cartwright and John Dupré, whose work I will brieﬂy discuss in Sect. 3.4.
Two of Hacking’s slogans have become characteristic of this New Experimen-
talism. First, Hacking proclaimed that “experimentation has a life of its own” (1983,
150). According to this thesis, experimental enquiry is often largely independent of
high-level theory and in particular is not always geared at testing theories. This claim
stands in contrast to the thesis of theory-ladenness of observation as introduced in
Sect. 2.5. However, Hacking’s thesis ﬁts well with the distinction between phenom-
enological and theoretical science as introduced in the previous section, because the
former, as a strongly inductive practice, does not presuppose an elaborate theoretical
framework. Thus, the distinction between theoretical and phenomenological science
substantiates Hacking’s thesis, if it can be shown that certain experimental practices
belong to phenomenological science. Later in this section, it will be argued that
so-called exploratory experimentation is a phenomenological approach, which
should be distinguished from theory-driven experimentation.
Second, Hacking argued for a speciﬁc type of realism that is based on the nature
of experimental enquiry. Referring to experiments with microscopic particles like
electrons, he claimed: “If you can spray them, then they are real.” (1983, 23) In other
words, if one can manipulate an entity in systematic ways, then this entity must in
some way really exist. Apparently, the ability to causally interact with an entity is
taken to be a strong argument for the existence of this entity. In the literature, this
4Other important works of this New Experimentalism are Peter Galison’s How Experiments End
(1987) or Steven Shapin’s and Simon Schaffer’s Leviathan and the Air Pump (1989). Earlier
milestones in the philosophy of experiment are, among others, Francis Bacon’s Novum Organon
(1620/1994) with its detailed exposition of prerogative instances, Claude Bernard’s Introduction to
the Study of Experimental Medicine (1865/1957), or Ronald Fisher’s Design of Experiments (1935/
1951).
3.2
Exploratory Experimentation
47

position is called ‘entity realism’.5 Hacking’s second thesis also ﬁts well with the
distinction between phenomenological and theoretical science. After all, it was
argued in the previous section that causal relationships belong to the phenomeno-
logical level and that causal laws are much better candidates for truth than the
abstract laws of the theoretical level. Thus, there is good reason to endorse some
kind of realism with respect to the causal relationships of the phenomenological level
in line with the position of entity realism proposed by Hacking.6 The problem of
truth in phenomenological and theoretical science will be tackled in more detail in
Sect. 3.4.
Apparently, the distinction between phenomenological and theoretical science
constitutes a crucial premise for the central theses of Hacking’s New Experimental-
ism. What is still lacking in Hacking’s account is some general guideline which
experimental practices belong to phenomenological and which to theoretical science.
This question leads to the important distinction between exploratory experimenta-
tion, which forms part of phenomenological science, and theory-driven experimen-
tation, which belongs to theoretical science. As will be seen, exploratory
experimentation relies on an inductivist methodology, while theory-driven experi-
mentation relies on a hypothetico-deductive methodology.
It is intriguing that for much of the twentieth century philosophers of science have
missed this distinction which is arguably the most fundamental distinction with
respect to experimental practice in the sciences. It was only introduced in 1997,
independently by Friedrich Steinle and Richard Burian. The neglect of this important
distinction may well result from the general rejection of inductivism. Indeed, many
methodologists of the twentieth century such as Popper conﬁned the role of exper-
iments in scientiﬁc research to theory-testing within a hypothetico-deductive
approach. The almost exclusive focus of many philosophers of science on funda-
mental theorizing in physics, while neglecting the wide variety of other scientiﬁc
practices, e.g. in the engineering sciences, may also have played a role for these
misconceptions about experimentation.
Before the reign of modern hypothetico-deductivism, methodologists working
from an inductivist perspective were clearly aware of exploratory functions of
experiments.7 Ernst Mach, for example, dedicates a long chapter of his book
Knowledge and Error to the analysis of experimental research, and concludes that:
“What we can learn from an experiment resides wholly and solely in the dependence
or independence of the elements or conditions of a phenomenon. By arbitrarily
5The position has been defended by Nancy Cartwright as well: “an explanation of an effect by a
cause has an existential component” (1983, 91). More recently, causal realism has been developed
by, among others, Matthias Egg (2016).
6I would, however, disagree with his conclusion that electrons or atoms are real, since these are
general, abstract concepts, which plausibly belong to theoretical science.
7Even in the twentieth century, scientists who were willing to reﬂect on their own scientiﬁc practice
emphasized the exploratory nature of many experiments. A concise account of exploratory exper-
imentation can for example be found in Richard Feynman’s Caltech Commencement Address
(1974)
48
3
Phenomenological Science

varying a certain group of elements or a single one, other elements will vary too or
perhaps remain unchanged. The basic method of experiment is the method of
variation.“(1905/1976, 149) Mach goes on to discuss whether such variation is
feasible given that the number of combinations becomes forbiddingly large already
with a few independent variables.
Compare Mach’s depiction with a recent account of exploratory experimentation
by Friedrich Steinle and Uljana Feest, according to whom exploratory experimen-
tation is “a type of experiment that consists in systematic variation of experimental
variables with the aim of phenomenologically describing and connecting phenom-
ena in a way that allows a ﬁrst conceptual structure of a previously poorly structured
research ﬁeld. [. . .] exploratory experiments typically take place during historical
episodes in which no theories or appropriate conceptual frameworks are available
and can result in the formation of such frameworks.” (Steinle and Feest 2016, 282)
Both Mach as well as Feest and Steinle emphasize a methodology of variable
variation as the core feature of exploratory experimentation. As will be elaborated
in the next chapters, such an approach allows to inductively infer causal relationships
governing the examined phenomenon. Variational induction employed with the aim
of identifying causal structure thus is the main characteristic feature of exploratory
experimentation.
Laboratory experiments are typical examples for exploratory experimentation—
at least when the causal laws and causal concepts governing the examined phenom-
ena are still largely unknown, i.e. when there is no theory guiding the experimental
enquiry. Usually, experimenters ﬁrst try to determine those variables which may
have an impact on the phenomenon based on background knowledge and intuitions.
Then, they systematically vary those variables—if possible only one at a time—in
order to determine whether they actually have an impact on the phenomenon. There
are plenty of examples for exploratory experimentation in present and past scientiﬁc
practice. Think of Röntgen when he tried to experimentally understand the new kind
of radiation that he had accidentally discovered. Or think of the day-to-day work of
engineers, when they try to determine those innumerable, highly contextual, causal
relationships that for example ﬁll the VDI Heat Atlas mentioned in the previous
section. Many of these relationships are inferred by exploratory experimentation,
while sometimes theoretical assumptions also play a role.
A typical statement of theory-driven experimentation can be found in Karl
Popper’s work: “The theoretician puts certain questions to the experimenter and
the latter by his experiments tries to elicit a decisive answer to these questions, and to
no others. [. . .] Theory dominates the experimental work from its initial planning to
the ﬁnishing touches in the laboratory.” (1935/2002, 89–90) Obviously, this role of
experiments ﬁts well with hypothetico-deductivism, of which Popper was a main
proponent. A typical example of a theory-driven experiment is Sir Arthur
Eddington’s 1919 expedition to observe a solar eclipse in order to verify some
empirical consequences of Einstein’s theory of relativity.8 In a theory-driven
8Cf. Collins and Pinch (1998, Ch. 2) for an argument that the actual story is much more complex.
3.2
Exploratory Experimentation
49

experiment, the respective theory is already well established. The experimental setup
is not exploratory, there is little variation of potentially relevant variables. Rather, a
theory-driven experiment is generally expected to yield a yes-or-no answer: does
reality correspond to the prediction of the theory or not?
Clearly, exploratory experimentation ﬁts well with phenomenological science.
Most importantly, it relies on the variation of circumstances in order to inductively
infer causal relationships. In the previous section, such an approach was identiﬁed
as the basic methodology of phenomenological science. By exploratory experimen-
tation, the causal relationships are established only locally for the speciﬁc (labora-
tory) context in which the experimentation takes place. Therefore, these
relationships have little explanatory value. Deeper explanations result only when
the discovered causal relationships are embedded into a larger theoretical frame-
work, i.e. when one moves beyond phenomenological to theoretical science. Given
that exploratory experimentation is an inductive practice, it is largely theory-inde-
pendent. Not much has to be known beforehand about the causal structure of the
examined phenomenon. Certainly, exploratory experimentation is not only used to
determine the causal structure of paradigmatic phenomena such as exemplars, but to
infer phenomenological causal laws regarding a wide range of phenomena including
all those which are not expected to reveal any deeper understanding of the world.
By contrast, theory-driven experimentation presupposes a well worked-out the-
oretical framework and relies on a hypothetico-deductive approach. Thus, it should
generally be classiﬁed as a practice within theoretical science. Of course, interme-
diary cases also exist, e.g. when an experimenter uses a causal model in the absence
of an abstract theoretical framework justifying this model. As follows from the
discussion of the model-theory distinction in footnote 3 of Sect. 3.1, the develop-
ment of causal models mostly falls under phenomenological science.
3.3
Data Science as Phenomenological Science
Data science, here broadly understood as machine learning methods applied to large
data sets, exhibits all the characteristics of phenomenological science introduced in
Sect. 3.1. Since exploratory experimentation and data science both belong to phe-
nomenological science, it is not surprising that methodologically they are closely
related. Before addressing these similarities, let me turn to the ﬁrst issue and argue
why data science should be considered a phenomenological science.
An interesting debate that is ongoing both in data science and in statistics
concerns the fundamental goals of scientiﬁc enquiry. The crucial observation by
many scholars is that data science is geared mainly at the prediction of phenomena.
Indeed, it is sometimes referred to as ‘predictive analytics.’ Traditionally, of course,
many considered a deeper understanding of the world to be the principal goal of
science. This discrepancy is addressed already in Leo Breiman’s classic paper on the
two cultures in statistical modeling (2001; cp. Section 2.4). While Breiman’s data
modeling chieﬂy aims at a deeper understanding of the phenomena in terms of an
50
3
Phenomenological Science

underlying model, the focus of algorithmic modeling, which includes machine
learning, lies very much on prediction.
This perspective has since been criticized, e.g. by the statistician Emanuel Parzen:
“The two goals in analyzing data which Leo [Breiman] calls prediction and infor-
mation I prefer to describe as ‘management’ and ‘science.’ Management seeks proﬁt,
practical answers (predictions) useful for decision making in the short run. Science
seeks truth, fundamental knowledge about nature which provides understanding and
control in the long run.” (2001, 224; his italics) I have encountered this line of
reasoning again and again in many discussions with scientists and statisticians from
various ﬁelds, who identify a scientiﬁc approach with model building that leads to
explanation and deeper understanding. However, it does not seem sensible to
exclude large parts of scientiﬁc practice from the deﬁnition of science, notably
exploratory experimentation and data science, just because these focus on prediction
rather than understanding. Breiman is right to speak of different cultures, since the
differing values underlying the respective viewpoints have led to bitter and unre-
lenting debate.
More recently, the data scientist and statistician Galit Shmueli addressed the issue
of prediction versus explanation in a highly cited paper “To explain or to predict?” in
the journal Statistical Science, in which Breiman’s article was also originally
published. Shmueli recounts the underlying change in scientiﬁc practice which led
to the novel focus on prediction: “In many scientiﬁc ﬁelds such as economics,
psychology, education, and environmental science, statistical models are used
almost exclusively for causal explanation, and models that possess high explanatory
power are often assumed to inherently possess predictive power. In ﬁelds such as
natural language processing and bioinformatics, the focus is on empirical prediction
with only a slight and indirect relation to causal explanation.” (2010, 289) Shmueli
introduces a distinction between explanatory and predictive modeling which is
related to Breiman’s distinction between data and algorithmic modeling:
“explanatory modeling refers here to the application of statistical models to data for testing
causal hypotheses about theoretical constructs. [. . .] I deﬁne predictive modeling as the
process of applying a statistical model or data mining algorithm to data for the purpose of
predicting new or future observations.” (Shmueli 2010, 291)
Two essential differences between theoretical and phenomenological science are
present in Shmueli’s distinction between explanatory modeling, i.e. more traditional
statistical approaches, and predictive modeling, as in data science. First, there is a
difference in goal, i.e. explanation versus prediction. Second, explanatory modeling,
just like theoretical science, broadly follows a hypothetico-deductive approach in
terms of hypothesis testing. By contrast, predictive modeling inductively infers
predictions from the data, which ﬁts well with phenomenological science.9
9Shmueli identiﬁes a third type of modeling, descriptive modeling, which aims at “summarizing or
representing the data structure in a compact manner” (2010, 291), essentially corresponding to
descriptive statistics as brieﬂy introduced in Sect. 2.4. Because the focus of my book is on
inferences from data, either in terms of predictions or in terms of a model or theory, rather than
on mere description, I will not discuss this third type of modeling in further detail.
3.3
Data Science as Phenomenological Science
51

The lack of explanatory power in data science largely results from the epistemic
opacity of many machine learning algorithms. In general, it is impossible for a
human to understand what is going on when these algorithms generate predictions
from large data sets. This is the case with most algorithms, although there admittedly
are gradual differences. For example, a decision tree can output a list of variables that
were decisive for the classiﬁcation of a given instance. Such a list may hint at some
underlying explanation of the result produced by an algorithm. By contrast, for
neural networks, even such basic understanding in terms of the decisive variables is
mostly impossible. Remarkably, a movement in data science exists to render
machine learning more explanatory, to achieve Explainable Artiﬁcial Intelligence.10
This goal will be difﬁcult to realize, not least because some of the phenomena
analyzed by machine learning might be too complex for human understanding
anyways.
Attentive readers will have noted a difference concerning the role of causation
ascribed by Shmueli in comparison with the discussion of phenomenological science
in Sect. 3.1. While I consider causation to be crucial for phenomenological science,
Shmueli sees the primary role for causation in explanatory modeling, decidedly not
in predictive modeling. For example, she writes: “I focus on the use of statistical
modeling for causal explanation and for prediction. My main premise is that the two
are often conﬂated, yet the causal versus predictive distinction has a large impact on
each step of the statistical modeling process and on its consequences.” (2010, 289;
my italics).
The underlying argument, which is widespread though rarely made explicit,
apparently proceeds along the following lines: When models are explanatory, it is
assumed that the explanation is furnished by the underlying causal structure. There-
fore, explanatory modeling must be based on causal knowledge, whereas there is no
need for causal models, when the focus is only on prediction. This line of reasoning
can be found again and again in the relevant literature. For example, Viktor Mayer-
Schoenberger and Kenneth Cukier, authors of a best-selling book on Big Data make
it their own. They proclaim a shift in the wake of big data “from causation to
correlation [representing] a move away from always trying to understand the deeper
reasons behind how the world works to simply learning about an association among
phenomena and using that to get things done.” (2013, 32).
As ubiquitous as this argument is, it nevertheless relies on a misconception
regarding the notion of causation. As will be argued in much more detail in
Chap. 5, explanation does not constitute a primary function of causation—contrary
to what the above authors assume. Rather, the core feature of causation is difference
making. Broadly speaking, a causal relationship exists if the cause can be used to
make a difference to the effect. Consequently, causal knowledge primarily serves for
prediction and/or manipulation—the latter, if there is a direct causal relationship
between two variables, while an indirect link in terms of a common cause
10For example, the US Defense Advanced Research Projects Agency (DARPA) ﬁnances a project
with that title: https://www.darpa.mil/program/explainable-artiﬁcial-intelligence
52
3
Phenomenological Science

structure sufﬁces for reliable predictions. This connection between difference mak-
ing and causation constitutes the reason why causal knowledge is essential for
predictive modeling in phenomenological science, rather than for explanatory
modeling. Since data science aims at prediction and manipulation, e.g. when trying
to cure a disease or making a user buy a certain product, causation is a central
concept for data science.
Many authors have stressed a dual nature of causation as exempliﬁed in the
so-called Russo-Williamson thesis, according to which twofold evidence has to be
taken into account in order to establish causal relationships: statistical evidence as
well as evidence in terms of mechanisms (Russo and Williamson 2007). As an
example, if one wants to know whether a medication cures a certain disease, it is on
the one hand helpful to conduct randomized controlled trials. But one should also
consult the bio-medical literature whether it is possible to understand the mecha-
nism, how the medication cures the disease. So there is an undeniable link here
between causation and explanation. After all, the mechanism explains why the
medication cures the disease, while the evidence from the randomized control trial
does not.
In Sect. 5.4, I will argue that such mechanisms should also be understood in terms
of difference making—which renders difference making the more fundamental
concept in comparison with mechanisms. Indeed, causal mechanisms generally
provide intermediary steps linking the overall cause and effect of the considered
relationships. In the example above, these steps might include laws that account for
how the medication spreads in the body of the patient, how different chemical
substances attack the causes of the disease, etc. It is straight-forward to show on
the basis of a difference making account of causation why evidence for the interme-
diary causal laws will generally increase the conﬁdence in the overall causal law
(cp. Sect. 5.4.3).
Three types of explanation should be distinguished in this context. The failure to
introduce such a distinction is a further shortcoming of Shmueli’s account. The ﬁrst
type is explanation in terms of the causal factors determining an effect, when for
example the recovery of a patient is explained by the medication that she took. As
was already emphasized, this type has little explanatory value. While knowing the
determining factors may be helpful to reproduce a phenomenon, it does not allow for
a deeper understanding. Note that this type of explanation is often available in
phenomenological science and in particular in data science, e.g. when looking at
the decisive variables in a decision tree. But for some machine learning algorithms,
e.g. neural networks, even this rudimentary type of explanation is mostly
unavailable.
The second type of explanation is explanation in terms of a theoretical framework
and thus belongs to theoretical science. This type is generally considered the most
explanatory—mainly because it achieves the greatest uniﬁcation of the phenomena.
For example, Newton’s theory of gravitation allows to link phenomena as diverse as
the tides, the motion of a pendulum or the trajectories of the planets in the sky. As is
characteristic for theoretical science, such explanation proceeds in terms of a
3.3
Data Science as Phenomenological Science
53

hypothetico-deductive argument that shows how certain phenomena can be derived
from the fundamental equations in a ﬁeld under further assumptions. Clearly, in a
phenomenological approach like data science, one should not expect such wide-
ranging explanations.
Note that the distinction between phenomenological and theoretical explanation
as introduced above relies on a substantial separation between predictive and
explanatory modeling, in contrast to what is commonly believed11 and what is
often argued in philosophy. For example, Carl Gustav Hempel proposed a thesis
of the structural identity of explanation and prediction, which more or less follows
from the mistaken assumption that both prediction and explanation follow a
hypothetico-deductive rationale (1965, 366–76). By contrast, according to the pro-
posed framework, those abstract scientiﬁc theories possess the highest explanatory
value which usually cannot be used for prediction.
Let me mention a third type of explanation that is intermediary between the
previous two. Here, the explanation relies on a causal model, i.e. not on an abstract
theory as in theoretical explanation.12 Such causal-model explanations take into
account not only the relevant causal factors, but also mechanistic evidence further
detailing how the causes lead to the effects.13 This third type has considerable
explanatory strength, since it subsumes the considered causal relationship under a
causal model and thus refers to a substantial number of causal laws and the evidence
supporting those laws. However, it does not achieve the wide-ranging uniﬁcation
that is characteristic of theoretical science. Explanation in terms of a causal model in
principle belongs to phenomenological science, since the laws that constitute the
causal model are causal rather than theoretical laws. It may well happen that as data
science advances, more powerful algorithms will be able to establish complex causal
models. Causal-model explanation thus is feasible in data science, although it may
still be the case that humans will not be able to understand such explanations,
because the models are too complex to be grasped by the human cognitive apparatus.
Thus, causation is crucial for predictive and much less for explanatory modeling.
That this is not widely recognized stems from the deep confusion that has plagued
debates on causation ever since the introduction of the term. In the wake of
hypothetico-deductivism, the very idea of causal analysis has often been rejected
in the sciences and especially in statistics. I will return to this topic in Chap. 5, where
I propose a notion of causation that well traces the distinction between theoretical
and phenomenological science and in particular is adequate for a methodological
analysis of data science.
A detailed analysis of various machine learning algorithms will further substan-
tiate the link between data science and causation. In particular, I show in the next
chapter that many of these algorithms rely on variational induction in order to
11As also pointed out by Shmueli in the above quote: “models that possess high explanatory power
are often assumed to inherently possess predictive power” (2010, 289).
12This is the type of explanation prevalent in Shmueli’s explanatory modeling.
13Regarding the model-theory distinction, compare footnote 3 in Sect. 3.1.
54
3
Phenomenological Science

establish causal dependency (cp. especially Sect. 4.3). Such a variational approach,
examining how changing circumstances impact a phenomenon, was also identiﬁed
as typical for phenomenological science in Sect. 3.1. Importantly, variational induc-
tion provides the link to other crucial features of phenomenological science. For
example, it can only establish ceteris paribus laws, i.e. local and contextual causal
knowledge. Also, since the methodology is inductive, it is largely independent of
substantial modeling assumptions or an underlying theoretical framework.14
In summary, data science exhibits all essential features of phenomenological
science and thus should be classiﬁed as such. It aims at prediction rather than
explanation. It relies on an inductive methodology with the goal of establishing
causal relationships. Given its inductive nature, data science presupposes little
theory or modeling assumptions. Finally, most machine learning algorithms follow
a variational rationale, which implies that the resulting causal knowledge depends on
context and holds only locally.
Given that exploratory experimentation and data science both belong to phenom-
enological science, it is not surprising that they share essential features. Most
importantly, they aim at the causal analysis of phenomena by following a logic of
variable variation. To this purpose, they rely on evidence in terms of the impact that
changing circumstances have on a phenomenon. Given the shared inductive
approach, both exploratory experimentation and data science are largely theory-
independent, presupposing few modeling assumptions and little theoretical back-
ground knowledge.
A number of differences exist as well. In particular, exploratory experimentation
generally relies on experimental evidence while data science often works with
observational data. Also, exploratory experimentation usually takes place under
laboratory conditions, i.e. in an environment where all relevant circumstances are
extremely well controlled. By contrast, data science gathers evidence out there ‘in
the wild’ from a huge variety of contexts and sources. This in turn has implications
for the complexity of the phenomena that can be treated with either practice. Highly
complex social phenomena, for example, cannot be explored in a laboratory, which
has been a source of constant frustration for social scientists, while data science
holds the greatest promises exactly for those phenomena.
That these differences are rather minor can be shown on the basis of the difference
making account of causation of Chap. 5. Most importantly, difference making does
not require experimental evidence in order to establish causal relationships
(in contrast to other approaches to causation). Evidence in terms of interventions
and manipulations provides only a pragmatic advantage in comparison with purely
observational data. Also, it will be shown that causal analysis in terms of difference
making presupposes a homogeneity condition that relevant background conditions
remain constant. While homogeneity is much easier to establish for a laboratory
context in exploratory experimentation, there are no in principle reasons why the
condition should not hold for observations gathered outside the laboratory. Finally,
14The issue of theory-ladenness in data science will be addressed in depth in Sect. 6.3.
3.3
Data Science as Phenomenological Science
55

complexity obviously renders causal analysis more difﬁcult, but certainly not
impossible, especially if a lot of relevant data are available.
The close analogy between exploratory experimentation and data science sug-
gests that the general perspective suggested by the New Experimentalists is useful
for data science as well. For example, one could easily argue that “data science has a
life of its own” independently of theory, adapting Hacking’s analogous slogan. With
respect to his second slogan, realism concerning the causal knowledge that is
generated in data science has some plausibility. In the next section, therefore, I
will look more closely at the question to what extent phenomenological science and
thus data science allow to establish scientiﬁc truth.
3.4
Truth in Phenomenological Science—Resolving
Duhem’s Challenge to Inductivism
Given that this book aims to defend inductivism, let me return to the arguments
against inductivism that were delineated in Sect. 2.5. In the following, I argue that
these objections can be defused or mitigated when taking into account the distinction
between phenomenological and theoretical science. This holds in particular for the
challenges raised against inductivism by Pierre Duhem, notably the arguments based
on theory-ladenness of observation, conﬁrmational holism and underdetermination.
Essentially, I argue that these concern chieﬂy theoretical science and therefore do not
undermine an inductivist data science, which is a phenomenological approach. Note
that this line of argument owes considerably to Duhem, who—as we had seen—was
always careful to restrict his various theses to physical theories.
In a way, Duhem’s arguments all undermine the notion of scientiﬁc truth,
understood as correspondence with reality, which as we have seen in Sect. 2.1 is a
central goal of inductivist methodology. For example, theory-ladenness of observa-
tion implies that the truth or falsity of observation statements cannot be decided
without assuming a theoretical context. Similarly, conﬁrmational holism means that
observation statements cannot conﬁrm or falsify the truth of general laws without
presupposing a larger theoretical context. Finally, the underdetermination thesis
maintains that there is never just one true description of the phenomena, but usually
a plurality of incompatible descriptions exists.
As indicated, the issue of scientiﬁc truth depends on whether it is posed in
phenomenological science or in theoretical science. In particular, the causal laws
of the former can be true in a much more straight-forward sense compared with the
abstract laws of the latter. Notably, causal laws can be employed to correctly predict
facts about the world in a given context up to a certain accuracy. By contrast,
theoretical laws, due to their abstract nature, demand a substantial amount of
interpretation and additional assumptions in order to be applicable to concrete
phenomena. A framework of theoretical laws does not by itself yield concrete
predictions about the world. Thus, in phenomenological science, a notion of truth
56
3
Phenomenological Science

is available in terms of a correspondence of the causal laws with the world, which is
absent on the theoretical level. Of course, the price to be paid for this access to truth
consists in the contextual and approximate nature of phenomenological laws com-
pared with the ambitions of universality and exactness in theoretical science.
That different notions of truth are at stake in phenomenological and theoretical
science has been observed before, notably by Pierre Duhem and by Nancy Cart-
wright. Duhem writes in his Aim and Structure of Physical Theory:
“A law of physics is, properly speaking, neither True nor False but Approximate. A common
sense law is merely a general judgement – this judgement is either true or false. This is not
the case with the laws of physical science at maturity, which are stated in the form of
mathematical propositions – such laws are symbolic. But a symbol is neither true nor false, it
is selected to stand for the reality it represents, and pictures that reality in a more or less
precise or detailed manner. To apply to a symbol the words ‘truth’ or ‘error’ no longer has
any meaning, so the logician concerned with the strict meaning of words will have to answer
anyone who asks whether physics is true or false, as ‘I do not understand the question’.”
(1906/1962, 168)
Duhem distinguishes between the theoretical laws of physics, which cannot be
true or false in a strict sense because they are symbolic and approximate, and
phenomenological or common sense laws stating a “relation between diverse con-
crete facts”, which can be true or false (1906/1962, 147). Note that Duhem attributes
the fact that truth is not an adequate category for judging theoretical laws to their
being symbolic, whereas I had stressed that the conventional nature of these laws as
well as the claim that theoretical laws hold universally and exactly are incompatible
with the notion of truth. In this respect, my perspective is more closely aligned with
the conventionalism of Henri Poincaré than with Duhem’s philosophy of science.
More recently, Nancy Cartwright has also emphasized that phenomenological
laws rather than theoretical ones are better candidates for truth, broadly understood
in terms of descriptive accuracy:
“In modern physics, and I think in other exact sciences as well, phenomenological laws are
meant to describe, and they often succeed reasonably well. But fundamental equations are
meant to explain, and paradoxically enough the cost of explanatory power is descriptive
adequacy. Really powerful explanatory laws of the sort found in theoretical physics do not
state the truth.” (1983, 3)
Note that Cartwright claims here that explanatory power comes at the cost of
descriptive accuracy, a trade-off that we have already discussed in Sect. 3.3.
Cartwright also points out the link between the issue of truth with the causal and
contextual nature of phenomenological laws and the abstract, non-causal nature of
theoretical laws, respectively:
“The causal story uses highly speciﬁc phenomenological laws which tell what happens in
concrete situations. But the theoretical laws, like the equation of continuity and Boltzmann’s
equation, are thoroughly abstract formulae which describe no particular circumstances. [. . .]
the function of the laws is different in the two cases, and so too, I have argued, are their
claims to truth.” (1983, p. 11)
3.4
Truth in Phenomenological Science—Resolving Duhem’s Challenge to. . .
57

Let me now address to what extent the different notions of truth in theoretical and
phenomenological science shed new light on the various theses by Pierre Duhem as
well as the arguments against inductivism that build on these theses.
Underdetermination of theory by observation, for example, occurs both in phe-
nomenological and in theoretical science. However, it is much more benign in the
former. Underdetermination in phenomenological science results when the relevant
concepts in a ﬁeld are redeﬁned, while changing the formulation of the laws in
complementary ways. For example, instead of stating that “all non-Australian swans
are white” and “all Australian swans are black” one could maintain that “all swans
are white” and refer to the Australian birds by a different name, e.g. “all austraswans
are black.” Prima facie, the two descriptions are incompatible, since according to the
ﬁrst it is false that “all swans are white” as the second claims. But crucially, both
frameworks attribute the same truth values to the same instances. Their empirical
content therefore is the same.
Under certain additional assumptions, the attribution of truth in phenomenolog-
ical science is invariant under changes of description. These assumptions, which are
stated in Sect. 6.2, include: determinism (although this requirement can be somewhat
weakened), a stable context and sufﬁcient variational evidence. If evidence satisfy-
ing these assumptions is available in a speciﬁc situation, then variational induction
uniquely determines the true causal laws in that situation (cp. Sect. 6.1). While
different formulations are possible, such reformulations preserve the truth value of
the derived causal laws and of corresponding predictions, as in the example of the
preceding paragraph. Thus, the argument from underdetermination does not under-
mine the notion of scientiﬁc truth in phenomenological science, since the empirical
content even of prima facie incompatible descriptions remains the same under
reformulation. Of course, simpler formulations still hold an advantage from a
pragmatic point of view. But in phenomenological science, the argument from
underdetermination does not undermine the inductivist aim of establishing true
causal laws.
By contrast, underdetermination in theoretical science comes with a substantially
different ﬂavor. Various theoretical frameworks that are empirically equivalent with
respect to a range of phenomena will often provide widely distinct perspectives on as
yet
unfamiliar
phenomena.
Full
underdetermination
in
theoretical
science,
i.e. identical empirical content for different theoretical frameworks, depends very
much on the commitment of scientists to keep developing these frameworks in
analogous ways in as yet unknown terrain. Thus, there is a considerable normative
element in judgments of underdetermination in theoretical science in contrast with
underdetermination in phenomenological science. Since theoretical laws, due to
their universality and exactness, cannot be established by variational induction,
they cannot be true in the same sense as causal phenomenological laws. In particular,
they
do
not
have
a
clearly
delineated
empirical
content.
Consequently,
underdetermination in theoretical science cannot be construed in terms of a transla-
tion between frameworks preserving empirical content and thus truth. To the very
contrary, I have argued elsewhere that the crucial virtue of underdetermination in
theoretical science is that different frameworks provide different intuitions and
58
3
Phenomenological Science

perspectives how to analyze yet unfamiliar phenomena (Pietsch 2011). In summary,
an argument against scientiﬁc truth based on Duhem’s underdetermination thesis can
be made in theoretical science, but not in phenomenological science.
At this point, a brief digression on the topic of incommensurability can be
illuminating. Authors like Thomas Kuhn or Paul Feyerabend have argued that
competing scientiﬁc frameworks often are not only incompatible, i.e. they contradict
each other, but they are incommensurable,15 i.e. they are to some extent incompa-
rable. A central argument for incommensurability is that framework-independent
criteria for fully assessing a comparison between competing frameworks do not
exist. Another argument is that the meaning of fundamental concepts changes in a
way that cannot be fully made explicit, e.g. when comparing Newtonian mass with
Einsteinian mass. A reason for this incomparability of fundamental concepts in
theoretical science lies in the fact that they aim to be just as universal as the
corresponding theoretical laws, whereas the conceptual framework in phenomeno-
logical science again is local and contextual (cp. Chap. 7). In summary, while
incommensurability can be found in theoretical science, it is implausible for phe-
nomenological science, where translation rules between causal laws and the respec-
tive
concepts
exist
and
where
identical
empirical
content
of
different
phenomenological frameworks can be established. Thus, incommensurability turns
out to be a powerful tool for arguing against realism with respect to theoretical
science, but is a blunt weapon in phenomenological science.
Let me next turn to theory-ladenness of observation. As we had seen in Sect. 2.5,
theory-ladenness undermines the inductivist idea that one can ascend step by step
from concrete statements of particular fact to increasingly general laws. According to
the doctrine of theory-ladenness, such a clean hierarchical ordering is impossible,
since every experiment and observation already presupposes considerable theoreti-
cal background knowledge. In particular, there are no basic, theory-independent
statements of fact.
However, just pointing to theory-ladenness is not sufﬁcient to tip the balance
against inductivism. Instead, one has to examine carefully how much and what kind
of theory must be presupposed. For example, some observations, e.g. regarding the
color of a tree or the smell of food, can be stated by merely relying on primary
sensory categories, while others presuppose the latest most abstract physical theo-
ries, e.g. when a physicist reports on recent experiments at CERN. Some sophisti-
cated experiments may even presuppose the very theory that is being tested.
As will be shown later in the book, it is possible to derive local causal knowledge
from the comparison of basic observation statements relying on primary sensory
qualities. Such local laws can serve as the lowermost level of phenomenological
laws in the inductive hierarchy and thus can provide a relatively stable basis for
induction. When taking into account further evidence, this local causal knowledge
can be extended and generalized. Furthermore, higher-level concepts and laws can
be deﬁned based on the concepts and laws of the levels below. Obviously, there is
15literally: ‘have no common measure’
3.4
Truth in Phenomenological Science—Resolving Duhem’s Challenge to. . .
59

theory-ladenness, but it is rather benign and unproblematic, since the truth of the
causal laws on every level of the hierarchy can be established by means of varia-
tional induction. The thesis of theory-ladenness does not undermine the notion of an
inductivist phenomenological science.
By
contrast,
in
theoretical
science,
theory-ladenness
appears
within
a
hypothetico-deductive methodology. There exists no stepwise procedure to induc-
tively derive the abstract theoretical framework, which instead is merely hypothe-
sized. The whole outlook on the phenomena is shaped by the presupposed
theoretical framework and different frameworks will generally provide incompatible
pictures of the examined phenomena. Due to incommensurability, there is no
straight-forward correspondence between these different pictures. Theory-ladenness
affects theoretical science much more strongly than phenomenological science.
Notably, Duhem as well distinguishes theory-ladenness of experimental enquiries
in the abstract sciences from the role of theory in common experience:
“The result of an experiment in physics is an abstract and symbolic judgement. The
characteristics, which so clearly distinguish the experiment in physics from common
experience, by introducing into the former, as an essential element, a theoretical inter-
pretation, excluded from the latter, also mark the results arrived at by these two sorts of
experiences.
The result of common experience is the perception of a relation between diverse concrete
facts. Such a fact having been artiﬁcially produced, some other fact has resulted from
it. For instance, a frog has been decapitated, and the leg has been pricked with a needle;
the right leg has been set into motion and has tried to move away from the needle: there
you have the result of an experiment in physiology. It is a recital of concrete and obvious
facts, and in order to understand it, not a word of physiology need be known.
The result of the operations, in which an experimental physicist is engaged, is by no means
the perception of a group of concrete facts – it is the formulation of a judgement
interrelating certain abstract and symbolic ideas, which theories alone correlate with
the facts already observed. Open any report of an experiment in physics and read its
conclusions – in no way are they simply an exposition of certain phenomena. They are
abstract propositions to which no meaning can be attached if the physical theories
admitted by the author are not known. When you read, for example, that the
electromotive force of a certain gas battery increases by so many volts when the pressure
is increased by so many atmosphere, what does this proposition mean? We cannot
attribute any meaning to it without recourse to the most varied and advanced theories
of physics.” (1906/1962, 147–148)
Clearly, Duhem distinguishes theory-ladenness with respect to common experi-
ence from theory-ladenness in theoretical sciences like physics. Apparently, he
considers only the latter as problematic.16
Finally, conﬁrmational holism supposedly undermines the inductivist idea that
observations and experiments can directly conﬁrm general laws. But remember that
Duhem’s central argument for this thesis relied on theory-ladenness of observation.
It is thus plausible that conﬁrmational holism as well mainly affects theoretical
science and does not undermine inductivism in phenomenological science. Indeed,
the stepwise procedure outlined above how increasingly general knowledge can be
16I will return to the issue of theory-ladenness in Sect. 6.3.
60
3
Phenomenological Science

derived from sensory impressions seems incompatible with a strong reading of
conﬁrmational holism.17 By contrast, the thesis seems problematic for theoretical
science—since a hypothetico-deductive approach more or less by deﬁnition pre-
supposes a sophisticated theoretical framework the truth of which has not been
established. Thus, if experiments in theoretical science presuppose considerable
theoretical assumptions, both conﬁrmation and falsiﬁcation of isolated hypotheses
are only as good as the conﬁdence in the assumed theoretical background
knowledge.
In summary, Duhem’s anti-inductivist arguments based on underdetermination,
theory-ladenness, and conﬁrmational holism do not undermine the notion of an
inductivist phenomenological science and thus of an inductivist data science. They
are relevant mainly for theoretical sciences like physics. Judging from his writings,
this view is compatible with Duhem’s outlook.
3.5
Case Study: Hierarchies in Deep Neural Networks18
Currently, one of the most successful classes of algorithms in machine learning and
artiﬁcial intelligence are so-called deep neural networks or deep learning algo-
rithms.19 As Yann LeCun, Yoshua Bengio, and Geoffrey Hinton write in a recent
review article in Nature: “Deep learning [. . .] methods have dramatically improved
the state-of-the-art in speech recognition, visual object recognition, object detection
and many other domains such as drug discovery and genomics. [. . .] Deep
convolutional nets have brought about breakthroughs in processing images, video,
speech and audio, whereas recurrent nets have shone light on sequential data such as
text and speech.” (LeCun et al. 2015, 436).
The architecture of artiﬁcial neural networks is vaguely inspired by the human
brain. Partly because our understanding of the latter is still premature, many details
of these networks lack a direct correspondence with biological systems. Artiﬁcial
neural networks should not be considered as models of how the human brain actually
works, though a deeper understanding of the latter can certainly contribute to the
development of the former and vice versa.
In analogy to the human brain, the fundamental building blocks of neural
networks are artiﬁcial neurons, which are connected with each other. As is well
studied, biological neurons communicate electrochemically. They process an input
from other neurons to generate an electric output signal, which they then feed to still
17Unequal conﬁrmation of different theoretical assumptions through certain bits of evidence is a
concern that is also addressed by Clark Glymour’s bootstrap account of conﬁrmation (1983).
18The exposition in this section is based on Sect. 4.2.3 of Pietsch (2021).
19Much of the following is taken from the ﬁrst textbook on Deep Learning, written by some of the
major ﬁgures in the ﬁeld: Ian Goodfellow, Yoshua Bengio, and Aaron Courville. Wikipedia was
also a helpful source.
3.5
Case Study: Hierarchies in Deep Neural Networks
61

further neurons via so-called axons. In the human brain, neurons generally become
activated when the input signal surpasses a certain threshold, and after activation,
they send a spike to other neurons, i.e. ﬁre an action potential. In the brain, the
neurons are often organized in several subsequent layers, e.g. in the visual cortex,
which is one of the best understood parts of the brain.
Efforts to computationally model the processes in the brain have developed in
parallel with an increased understanding of the brain. The ﬁrst substantial attempt
was the so-called ‘perceptron’, which was invented by the American psychologist
Frank Rosenblatt at Cornell Aeronautical Laboratory in the late 1950s.20 Rosenblatt
developed a number of algorithms for neural networks which were eventually
implemented on some of the ﬁrst computers. Also, an image recognition machine,
the ‘Mark I Perceptron’, was built consisting of an array of 20  20 photocells that
were connected with a number of response cells. The adaptive weights of the
connections between photocells and response cells were realized by potentiometers
that could be controlled using electric motors.
Mathematically, the perceptron can be modeled in terms of a function that maps
an input vector x to an output value f(x). In the simplest case the output is a binary
classiﬁer:
f x
ð Þ ¼
1 if wx þ b > 0
0 otherwise

Here, the vector w denotes the respective weights, with which the various input
values are taken into account for the output, as realized by the potentiometers in the
Mark I perceptron, and b is the bias shifting the threshold, above which the classiﬁer
yields a positive result.
Crucial restrictions of simple perceptron models turned out to be the linear nature
of the connections between input and output as well as the lack of depth of the
network consisting of only an input and an output level. Indeed, a perceptron of the
above design is not able to learn important types of functions, e.g. XOR,21 as pointed
out in the notorious book Perceptrons by two further AI pioneers, Marvin Minsky
and Seymour Papert (1969). This book, with its rather pessimistic outlook, arguably
played a crucial role in the subsequent decline in interest in neural networks over a
period of approximately a decade. Remarkably, periods of renewed and declining
interest occurred several times in the history of AI, computer scientists speak rather
poetically of winters of AI. Goodfellow et al. make out three different periods of
development of neural networks, the ﬁrst in the 1940s-1960s in the ﬁeld of
20Rosenblatt writes in the preface to his Principles of Neurodynamics: „For this writer, the
perceptron program is not primarily concerned with the invention of devices for ‘artiﬁcial intelli-
gence’, but rather with investigating the physical structures and neurodynamic principles which
underlie ‘natural intelligence’. A perceptron is ﬁrst and foremost a brain model, not an invention for
pattern recognition. As a brain model, its utility is in enabling us to determine the physical
conditions for the emergence of various psychological properties.” (1962, vi)
21The XOR-function is deﬁned as follows: f 1, 1
ð
Þ ¼ f 0, 0
ð
Þ ¼ 0; f 1, 0
ð
Þ ¼ f 0, 1
ð
Þ ¼ 1.
62
3
Phenomenological Science

cybernetics, then in the 1980s and 1990s under the term ‘connectionsm’, and in the
last decade or so, the term ‘deep learning’ has been used (2016, 12).
In recent times, so-called deep neural networks have proven to be very effective
for a large range of applications. In contrast to the simple perceptron model as
employed in the Mark I, such networks are arranged in a number of layers, which
subsequently process and transform the input data. Because the variables in the
intermediary layers cannot be directly observed, these layers are also referred to as
hidden layers. But hidden layers alone do not solve the XOR problem. Thus, a
non-linear mapping between subsequent layers was a further crucial element in
dealing with the shortcomings of some early realizations of the perceptron. Essen-
tially, these deep neural networks are just computational representations of mathe-
matical functions: “A multilayer perceptron is just a mathematical function mapping
some set of input values to output values. The function is formed by composing
many simpler functions. We can think of each application of a different mathemat-
ical function as providing a new representation of the input.” (Goodfellow et al.
2016, 5) A crucial advantage of deep learning algorithms is that they can represent
almost any functional relationship with sufﬁcient accuracy in contrast to traditional
statistical modeling tools such as linear regression, which are limited to speciﬁc
families of functions.
In current research, a considerable number of algorithms for artiﬁcial neural
networks is developed, many of them specialized for certain types of input data.
For example, the currently very popular convolutional neural networks are particu-
larly suitable for tasks processing a grid of values such as in image recognition. One
useful feature is their scalability, e.g. from smaller to larger images. As another
example, recurrent neural nets are especially good at dealing with sequential data,
e.g. temporal sequences in language processing (ibid., 363). In the following, I will
concentrate on so-called feedforward deep neural networks, which are generally
considered “the quintessential example of a deep learning model” (ibid., 5).
Almost any machine learning algorithm relies on a data set that is represented by
a computational model. A cost function measures the discrepancy between the actual
data and the corresponding results of the model. Finally, an optimization procedure
improves the model, such that the cost function is minimized up to an acceptable
extent (ibid., 149–150). Deep feedforward networks are multilayer artiﬁcial neural
networks with the input layer representing those variables that correspond to the
input data of the data set. An arbitrary number of hidden layers follow, where direct
links only exist between variables in subsequent layers. Thus, from a graph-
theoretical perspective such models are directed acyclic graphs, lacking feedback
connections between the various levels. Finally, the variables of the last layer, which
is usually termed the output layer, correspond to the output data of the data set (ibid.,
163–166; see also LeCun et al. 2015).
Mathematically speaking, the structure of these networks consists in a chain of
nested mathematical functions:
f n
ð Þ . . . f 3
ð Þ
f 2
ð Þ
f 1
ð Þ x
ð Þ




. . .


3.5
Case Study: Hierarchies in Deep Neural Networks
63

Here, the upper index denotes the respective layer. For example, f (1) determines
the values on the ﬁrst hidden layer, f (2) on the second etc. with n being the overall
depth of the network. The chain of functions has the Markov property, i.e. the values
in every layer depend only on the values in the subsequent lower level. Note again
that at least some of the functions f must be non-linear so that the network is able to
represent non-linear functions such as XOR.
A typical choice for a function f connecting subsequent layers consists in a linear
transformation and a subsequent application of a non-linear activation function
which is usually applied element-wise. Various non-linear activation functions
have been tried in the past. Currently, the default recommendation is to use the
so-called rectiﬁed linear unit, often abbreviated as ReLU, which yields the maximum
of either the input value or zero: g(z) ¼ max{0,z} (Goodfellow et al. 2016, 168).22
Because ReLU and similar functions are not differentiable at all points, they were
originally rejected out of what in hindsight seems to be mostly superstition. But they
turned out to yield good results in many practical applications. Thus, we have as a
typical mapping from one layer to the next:
f x
ð Þ ¼ max 0, Wx þ b
ð
Þ
The maximum is taken elementwise, i.e. the result is again a vector, denoting the
values of the variables on the subsequent level. W is a matrix linearly transforming
the vector x and b is the bias adjusting the offset of the function. The values of the
matrix W denote the strength of the connections between the different nodes or
variables in subsequent layers. For example, the value at position (1,1) in the matrix
determines the strength of the connection between the ﬁrst nodes in subsequent
layers. Obviously, the number of rows and lines of the matrix determine the number
of nodes in subsequent levels.23
The weights W determining the strength of the connection between nodes in
subsequent layers as well as the bias b of the various layers are the model parameters
that are optimized in the machine learning process. In typical neural networks, the
number of parameters is usually quite large, not least because the number of input
variables is often already substantial. For example, in image processing, the color
values of every pixel can be taken as input variables. In the beginning, the param-
eters are initialized, often to some small random values (ibid., 172). Then, an
optimization procedure is applied, trying to change the parameters in a way such
that the output values of the model are as close as possible to the corresponding
values in the data set.24
22Often, the choice of activation function is largely irrelevant: “New hidden unit types that perform
roughly comparably to known types are so common as to be uninteresting.” (ibid.,190)
23The exact network architecture is mostly determined by trial and error: „The ideal network
architecture for a task must be found via experimentation guided by monitoring the validation set
error.“(ibid., 192)
24At least in supervised learning. In unsupervised learning, one would expect that the output
captures relevant aspects of the examined phenomenon.
64
3
Phenomenological Science

The standard optimization procedure in machine learning is gradient descent. For
this procedure, a suitable cost, loss, or error function is chosen measuring the
difference between the model output and the corresponding ‘desired’ values from
the data set. Then, the gradient of this cost function is determined with respect to the
parameters of the model. The gradient essentially determines how the parameters of
the model must be changed in order to minimize the cost function, i.e. in order for the
model to achieve better results. From a computational perspective, this optimization
procedure is implemented in small steps. The gradient is calculated locally at the
current values of the parameters and then the values of the parameters are adjusted to
a small extent, expressed in terms of a learning rate α, such that the impact on the
cost function is optimized. The procedure is repeated for the adjusted values of the
parameters again and again until the cost function reaches a (local) minimum, where
the gradient is zero and further changes in the parameters do not lead to any
improvement in the cost function.
Gradient descent can be visualized as a walk in a multidimensional landscape.
Imagine a hiker on a mountain who wants to get down as fast as possible. For every
step of ﬁxed length α, she tries to descend as much as possible. She will continue this
procedure until she reaches a local minimum, which might be the bottom of a valley,
but which could also be a global minimum like the shore of the ocean. For gradient
descent, the algorithm moves along a multi-dimensional hyper-surface determined
by the parameters of the model instead of moving on the two-dimensional surface of
the earth. Also, while the hiker tries to minimize altitude, gradient descent aims to
minimize the cost function. An obvious problem of the procedure is that one might
get stuck in local minima, which are at a far higher altitude than the global minimum
one is actually seeking. Think of a plane high up in the mountains that is covered
with little craters. Following gradient descent, the hiker could easily get stuck in one
of these craters. This problem cannot be entirely avoided in gradient descent, in
particular because the nonlinearity of neural networks causes most interesting cost
functions to become non-convex, where convex functions have the useful property
that there is at most one minimum (ibid., 171). A related problem is that the eventual
result of gradient descent is sensitive to the initial choice of parameter values, i.e. to
the speciﬁc site where the hiker starts her descent. In machine learning, these
problems are approached in a pragmatic way, where those cost and activation
functions are chosen, which yield good overall results.
As an example, let me brieﬂy outline the gradient descent procedure for a single-
layer neural network with a non-linear activation function g25:
by ¼ g h
ð Þ ¼ g
X
jIj
i¼1
xiwi þ b
 
!
25I broadly follow Bruce Rosen’s account from web.cs.ucla.edu/~rosen/161/NeuralNotes/deriving_
delta_rule.ps
3.5
Case Study: Hierarchies in Deep Neural Networks
65

Here, the input variable x is a vector of dimension |I|, while the output variable is a
scalar. The given data set consists of |P| pairs of input and output variables (x( p),
y( p)), where the index ( p) ranges from 1 to |P|. Finally, by p
ð Þ are the calculated output
values of the model using x( p) as values for the input variable.
Let us employ the following cost function, which basically is the mean squared
error with an additional factor 1/2 that is added for convenience26:
E X, θ
ð
Þ ¼ 1
2
X
jPj
p¼1
by p
ð Þ  y p
ð Þ

2
θ denotes the parameters wi and b of the model, and X denotes all input vectors
x( p) used to calculate by p
ð Þ.
Now, one can determine the partial derivative of the cost function with respect to
each weight wi, where the latter denote the strength of the connection between input
node i and the output node27:
∂E
∂wi
¼
X
jPj
p¼1
∂E
∂by p
ð Þ
∂by p
ð Þ
∂wi
¼
X
jPj
p¼1
by p
ð Þ  y p
ð Þ

 ∂by p
ð Þ
∂wi
¼
X
jPj
p¼1
by p
ð Þ  y p
ð Þ

 ∂g p
ð Þ
∂h p
ð Þ x p
ð Þ
i
According to gradient descent and using a positive constant α as learning rate, the
update rule for the weights is:
Δwi ¼ α ∂E
∂wi
¼ α
X
jPj
p¼1
y p
ð Þ  by p
ð Þ


g0 h p
ð Þ


x p
ð Þ
i
The negative sign in the ﬁrst equality results in order to move in the negative
direction of the gradient so that the loss function is minimized. The update rule for
single-layer neural networks is often called delta rule. For linear networks such as the
Mark 1, the derivative g0(h( p)) ¼ 1.
For multi-layer neural networks, the approach is in principle the same. However,
the number of parameters increases considerably in that there are now weights and
biases for every level k: w k
ð Þ
ij
and b k
ð Þ
i . Running gradient descent in such networks
quickly becomes computationally expensive. This problem has been tackled by an
algorithmic procedure called backpropagation, which allows calculating the error
rates
∂E
∂w k
ð Þ
ij starting from the uppermost level and moving downwards level by level.
Obviously, the procedure moves in the opposite direction compared with the calcu-
lation of the output values byi—hence the name. Essentially, backpropagation to carry
26Other cost functions are used more often in deep learning applications, e.g. calculating the cross-
entropy between training data and model distribution (ibid., 173).
27Updating b works in an analogous way and carries no speciﬁc difﬁculties.
66
3
Phenomenological Science

out gradient descent in multi-layer networks relies on the chain rule for the differ-
entiation of nested functions, while employing “a speciﬁc order of operations that is
highly efﬁcient” (ibid., 199).
Having introduced some basics of deep learning, let me now turn to an episte-
mological analysis. I focus on two interrelated issues. The ﬁrst is the role of
difference making in deep learning algorithms. The second is the meaning of the
hierarchy of levels, in particular whether this hierarchy is somehow connected with
the distinction between phenomenological and theoretical science.
Essentially, deep learning algorithms aim to determine those input variables that
are the difference makers for the outcome variables. This basically follows from
gradient descent. As an example, assume that a single difference maker xd exists
among a huge number of input variables and, for the sake of simplicity, that there is a
linear relationship between the difference making variable and the outcome variable
y ¼ a xd. If there is sufﬁcient data, in a neural network without hidden layers,
gradient descent will gradually adjust the weights wi and bias b such that wd ¼ a and
all other wi ¼ 0. In other words, the algorithm learns that the only relevant variable
for the outcome is the input variable xd, with all other variables being irrelevant.
Depending on the learning rate and the criteria of model acceptance, these ideal
values will only be reached up to a certain level of accuracy. Note further that if
ReLU is used as activation function, the algorithm will only pick up the correct
dependency for xd > 0.
As a second example, non-linear multilayer neural networks are capable of
reproducing Boolean expressions of the following type: E is true if and only if
C1C2 ˅ ØC1C3 is true. As will be seen, such expressions, combining binary input
variables with the operators ˅ (‘or’), ˄ (‘and’), and Ø (‘not’), constitute the funda-
mental type of difference-maker according to the approach to causation presented in
Chap. 5.
Consider a neural network with one hidden layer. There are at least three binary
input variables c1, c2, and c3 with values ci ¼ 1 if Ci is present and ci ¼ 1 if Ci is
absent, i.e. if ØCi is present. For the example, only two variables are necessary in the
hidden layer and only one variable in the outcome layer. The latter corresponds to E
with possible values 1 if E is true and 0 if E is false. Let the neural network be fully
connected at the outset. Thus, we have weights w1i;1 and bias b1;1 connecting
variable ci in the input layer with the ﬁrst variable in the hidden layer, as well as
weights w2i;1 and bias b2;1 connecting the variable ci with the second variable in the
hidden layer. Furthermore, from the two variables in the hidden layer to the single
variable in the output layer, we have weights w1;2 and w2;2, respectively, as well as
bias b1;2.
As is easy to prove, the relationship ‘E is true if and only if C1C2 ˅ ØC1C3 is true’
can be represented in terms of the following parameter values:
w11;1 ¼ w12;1 ¼  w21;1 ¼ w23;1 ¼ 2
b1;1 ¼ b2;1 ¼  3
w1;2 ¼ w2;2 ¼ 1
and all other parameters ¼ 0
3.5
Case Study: Hierarchies in Deep Neural Networks
67

With respect to a data set that fulﬁlls the mentioned relationship, the cost function
will be at a global minimum, if these parameters are used. In fact, the overall squared
mean error is zero. If a sufﬁcient number of data points exist, it will even be the only
global minimum. In reality, of course, data is noisy. Also, there is no guarantee that
imperfect optimization procedures like gradient descent ﬁnd the global minimum
rather than getting stuck in local minima. But for many practical applications,
gradient descent seems to work just ﬁne.
In summary, gradient descent determines which input variables are difference
makers and which are irrelevant. For the latter, the connection to subsequent layers is
erased by setting the corresponding weights to zero. Deep neural networks, like
many other machine learning algorithms, rely on difference making to determine the
dependencies between input and outcome variables. Thus, they ﬁt well with varia-
tional induction as presented in the next chapter.
Let me proceed with the second epistemological question concerning the inter-
pretation of the hierarchy of layers in deep neural networks. Indeed, the hierarchical
structure is very pronounced in multilayer neural networks compared with other
machine learning algorithms. These layers may recall the distinction between theo-
retical and phenomenological science, which is the reason why we have discussed
deep learning algorithms at the end of this chapter. Prima facie, it seems plausible to
assume a relation to the hierarchical ordering that is familiar from the sciences,
e.g. that living beings are determined by their genes, which are built from molecules,
which in turn are built from atoms, etc.
Thus, should some of the lower layers of deep neural networks be considered to
model theoretical science? To understand the role of the various layers, some authors
have tried to visualize what is happening in deep convolutional networks, which as
already stated are especially suited for image recognition tasks (Lee et al. 2009;
Zeiler and Fergus 2014). Not surprisingly, it has turned out that, broadly speaking,
higher layers combine variables of the underlying layers. As an example, the lowest
hidden layer of a convolutional network for image recognition may only recognize
etches of different length, width, and orientation, while the subsequent hidden layer
analyzes corners and contours, i.e. simple forms that are to some extent combined
from the earlier layer. The third hidden layer may then identify basic object parts,
such as the wheels of a car or the nose of a human being, which in turn can be
understood as combinations of the contours in the second layer, etc.
Obviously, there are many differences between the lower layers of neural net-
works and the explanatory frameworks of theoretical science. For example, while the
latter strive for simplicity, this is generally not the case for the lower layers of neural
networks, which usually exhibit a large number of nodes. It remains completely
unclear how the variables in neural networks could relate to the fundamental
concepts and laws governing theoretical science.
In Sect. 3.1, we identiﬁed explanation and understanding of natural phenomena as
the fundamental task for theoretical science. For example, an underlying structure of
atoms and molecules can explain macroscopic physical phenomena such as the ideal
gas law, and genes can explain some of the macroscopic features of living beings. In
comparison, the lower layers of neural nets do not seem particularly explanatory.
68
3
Phenomenological Science

Can simple edges and corners in images contribute to an understanding of more
complex objects? While this sounds strange to our modern ears, it is not entirely
far-fetched with respect to the geometric worldview of the ancients. Plato, in his
Timaeus, associated the ﬁve so-called Platonic solids, i.e. extremely regular geo-
metrical shapes, with the fundamental elements as ultimate constituents of the world:
e.g. the tetrahedron was identiﬁed with ﬁre or the cube with earth. As another
example, Aristotle’s hylemorphism considered all matter to be determined by sub-
stance and form, again referring to geometrical notions. According to the ancient
worldview, geometrical forms could thus indeed have an explanatory value, but not
in the sense that the geometrical features of a concrete object can be used to explain
that object.
Most importantly, deep neural networks aim at causal analysis in terms of
variational induction (cp. Chap. 4). As we have seen, neural networks search for
difference makers among the input variables with respect to the outcome variables.
Introducing lower layers of a network and thus a hierarchy of more and more abstract
features just renders the search for difference makers more efﬁcient. Also, we will
ﬁnd in Sect. 5.3.3 that variational induction allows for the same hierarchical struc-
turing, representing concepts and laws on different levels of resolution. It is primar-
ily this analogy that allows understanding the different layers in deep neural
networks fully in terms of phenomenological science.
The analysis is further corroborated by the kind of phenomena that are studied
using deep learning. Notably, these are not paradigmatic phenomena as in theoretical
science. Rather, in accordance with the difference making approach to causation, the
results of deep learning algorithms are context-dependent and hold only locally.
Deep learning is employed to study the world in its full complexity, e.g. aims to
analyze images from an extremely wide range of contexts. As a successful scientiﬁc
practice aiming at many real-world applications, deep learning research certainly
seems much more closely related to the engineering sciences than to fundamental
natural sciences like physics. All these aspects, of course, were identiﬁed as typical
of phenomenological science in Sect. 3.1.
In summary, the hierarchy of layers in deep neural networks serves for complex-
ity reduction and efﬁcient concept formation, but these layers should not be under-
stood in terms of theoretical science. Rather, deep neural networks represent
complex causal models. Those computer scientists that expect machine learning to
be able to derive theoretical frameworks any time soon, generally fail to acknowl-
edge that machine learning thus far has thrived only in phenomenological science
and also underestimate the gap between phenomenological and theoretical science.
The idea that a computer may rival the work of a Newton or Einstein sounds
spectacular and it is widespread. An interesting example is the paper ‘Distilling Free-
Form Natural Laws from Experimental Data’ by Michael Schmidt and Hod Lipson
in the journal Science. The two Cornell computer scientists algorithmically analyze
video recordings of typical physical systems, like a double pendulum or arrange-
ments with several springs. They claim:
3.5
Case Study: Hierarchies in Deep Neural Networks
69

“For centuries, scientists have attempted to identify and document analytical laws that
underlie physical phenomena in nature. Despite the prevalence of computing power, the
process of ﬁnding natural laws and their corresponding equations has resisted automation. A
key challenge to ﬁnding analytic relations automatically is deﬁning algorithmically what
makes a correlation in observed data important and insightful. We propose a principle for the
identiﬁcation of nontriviality. We demonstrated this approach by automatically searching
motion-tracking data captured from various physical systems, ranging from simple harmonic
oscillators to chaotic double-pendula. Without any prior knowledge about physics, kine-
matics, or geometry, the algorithm discovered Hamiltonians, Lagrangians, and other laws of
geometric and momentum conservation. The discovery rate accelerated as laws found for
simpler systems were used to bootstrap explanations for more complex systems, gradually
uncovering the ‘alphabet’ used to describe those systems.” (Schmidt and Lipson 2009, 81)
The paper has met considerable criticism, though most of it misses what I believe
to be the crucial point. An essential step to ﬁnding the fundamental theoretical laws
of physics consists in identifying some phenomena as paradigmatic. And that, of
course, is not achieved by the algorithm, but rather is implicit in the choice of
physical systems by the authors. As should be clear to anyone who is at least
superﬁcially familiar with the history of Western science, the identiﬁcation of
paradigmatic phenomena is a highly complex and difﬁcult task. For example, one
could easily argue that it was one of Galileo’s major accomplishments to realize the
importance of systems like the inclined plane. Without the assumption that the
considered phenomena are paradigmatic, all the algorithm detects are local phenom-
enological laws, which are formulated in terms of differential equations. That this is
possible is not surprising given the recent successes in machine learning. But the
algorithm has not detected any fundamental law of physics, because it cannot
overcome the divide between phenomenological and theoretical science.
References
Bacon, Francis. 1620/1994. Novum Organum. Chicago: Open Court.
Bailer-Jones, Daniela. 2009. Scientiﬁc Models in Philosophy of Science. Pittsburgh: University of
Pittsburgh Press.
Bernard, Claude. 1865/1957. An Introduction to the Study of Experimental Medicine. New York:
Dover.
Breiman, Leo. 2001. Statistical Modeling: The Two Cultures. Statistical Science 16 (3): 199–231.
Burian, Richard. 1997. Exploratory Experimentation and the Role of Histochemical Techniques in
the Work of Jean Brachet, 1938-1952. History and Philosophy of the Life Sciences 19: 27–45.
Cartwright, Nancy. 1979. Causal Laws and Effective Strategies. Noûs 13 (4): 419–437.
———. 1983. How the Laws of Physics Lie. Oxford: Oxford University Press.
———. 1999. The Dappled World. In A Study of the Boundaries of Science. Cambridge: Cam-
bridge University Press.
———. 2004. Causation: One Word Many Things. Philosophy of Science 71: 805–819.
Collins, Harry, and Trevor Pinch. 1998. The Golem: What Everyone Should Know About Science.
Cambridge: Cambridge University Press.
Duhem, Pierre. 1906/1962. The Aim and Structure of Physical Theory. New York: Atheneum.
Egg, Matthias. 2016. Expanding Our Grasp: Causal Knowledge and the Problem of Unconceived
Alternatives. British Journal for the Philosophy of Science 67 (1): 115–141.
70
3
Phenomenological Science

Feynman, Richard. 1974. Cargo Cult Science. Engineering and Science 37 (7): 10–13.
Fisher, Ronald A. 1935/1951. The Design of Experiments. Edinburgh: Oliver and Boyd.
Galison, Peter. 1987. How Experiments End. Chicago: University of Chicago Press.
Glymour, Clark. 1983. On Testing and Evidence. In Minnesota Studies in Philosophy of Science,
ed. John Earman, vol. X. University of Minnesota Press.
Goodfellow, Ian, Yoshua Bengio, and Aaron Courville. 2016. Deep Learning. Cambridge, MA:
MIT Press.
Hacking, Ian. 1983. Representing and Intervening. Cambridge: Cambridge University Press.
Hempel, Carl G. 1965. Aspects of Scientiﬁc Explanation. New York: Free Press.
Kuhn, Thomas. 1996. The Structure of Scientiﬁc Revolutions. 3rd ed. Chicago: University of
Chicago Press.
LeCun, Yann, Yoshua Bengio, and Geoffrey Hinton. 2015. Deep Learning. Nature 521: 436–444.
Lee, Honglak, Roger Grosse, Rajesh Ranganath, and Andrew Y. Ng. 2009. Convolutional Deep
Belief Networks for Scalable Unsupervised Learning of Hierarchical Representations. In Pro-
ceedings of the 26th International Conference on Machine Learning, Montreal, Canada.
Mach, Ernst. 1905/1976. Knowledge and Error. Dordrecht: D. Reidel.
Mayer-Schönberger, Viktor, and Kenneth Cukier. 2013. Big Data. London: John Murray.
Minsky, Marvin L., and Seymour A. Papert. 1969. Perceptrons. An Introduction to Computational
Geometry. Cambridge, MA: MIT Press.
Parzen, Emanuel. 2001. Comment on statistical modeling: The two cultures. Statistical Science 16:
224–226.
Pietsch, Wolfgang. 2011. The Underdetermination Debate: How Lack of History Leads to Bad
Philosophy. In Integrating History and Philosophy of Science. Boston Studies in the Philosophy
of Science, ed. T. Schmaltz and S. Mauskopf, vol. 263. Dordrecht: Springer.
———. 2013. The limits of probabilism. In EPSA11 Perspectives and Foundational Problems in
Philosophy of Science, ed. V. Karakostas and D. Dieks. Dordrecht: Springer.
———. 2021. Big Data. Cambridge: Cambridge University Press.
Poincaré, Henri. 1905. Science and Hypothesis. London: Walter Scott.
Popper, Karl. 1935/2002. The Logic of Scientiﬁc Discovery. London: Routledge Classics.
Rosenblatt, Frank. 1962. Principles of Neurodynamics: Perceptrons and the Theory of Brain
Mechanisms. Washington: Spartan Books.
Russo, Federica, and Jon Williamson. 2007. Interpreting Causality in the Health Sciences. Inter-
national Studies in the Philosophy of Science 21 (2): 157–170.
Schmidt, Michael, and Hod Lipson. 2009. Distilling Free-Form Natural Laws from Experimental
Data. Science 324 (5923): 81–85.
Shapin, Steven, and Simon Schaffer. 1989. Leviathan and the Air-Pump: Hobbes, Boyle, and the
Experimental Life. Princeton: Princeton University Press.
Shmueli, Galit. 2010. To Explain or to Predict? Statistical Science 25 (3): 289–310.
Steinle, Friedrich. 1997. Entering New Fields: Exploratory Uses of Experimentation. Philosophy of
Science 64: S65–S74.
Steinle, Friedrich, and Uljana Feest. 2016. Experiment. In The Oxford Handbook of Philosophy of
Science, ed. P. Humphreys. Oxford: Oxford University Press.
VDI Gesellschaft Verfahrenstechnik und Chemieingenieurwesen, ed. 2010. VDI Heat Atlas. Hei-
delberg: Springer.
Zeiler, Matthew D., and Rob Fergus. 2014. Visualizing and Understanding Convolutional Net-
works. In ECCV 2014, Part I, LNCS 8689, ed. D. Fleet et al., 818.
References
71

Chapter 4
Variational Induction
Abstract In this Chapter, a distinction between enumerative, eliminative and var-
iational induction is elaborated. Enumerative induction infers causal relationships
from observed regularities, i.e. from the repetition of instances. Eliminative induc-
tion proceeds by eliminating hypotheses from a given exhaustive and mutually
exclusive set. Variational induction infers causal relationships from systematically
varying the circumstances of the examined phenomenon and examining the
corresponding impact on the phenomenon. The quintessential method of the latter
is the method of difference. In part due to the general skepticism concerning
inductivist approaches, variational induction has largely been neglected in twentieth
century philosophy of science. However, variational induction constitutes the central
methodology of phenomenological science. Also, most, if not all, data science and
machine learning algorithms rely on variational induction.
Keywords Data science · Induction · Computational learning theory · Decision
tree · Naïve Bayes · Mill’s methods · Solomonoff
4.1
Enumerative, Eliminative, and Variational Induction1
Following the decline of inductivism, there has been little interest in topics related to
induction in the twentieth century. Inductive methodology was thought to be so
troubled by David Hume’s notorious problem of induction that there seemed little
merit in engaging with the details. Why bother with a logical analysis if inductive
inferences could at best provide heuristic and fallible tools for hypothesis genera-
tion? As a result, a lot of conceptual details and reﬁnements concerning induction
have been neglected, e.g. the distinction between enumerative and variational
induction that will be the main topic of this chapter. Furthermore, inductive methods
that had long before been discredited provided easy straw men for opponents of
inductivism, while some of the more sophisticated inductive methodology was
1The exposition of this section is based on Sect. 4.1 of Pietsch (2021).
© Springer Nature Switzerland AG 2022
W. Pietsch, On the Epistemology of Data Science, Philosophical Studies Series 148,
https://doi.org/10.1007/978-3-030-86442-2_4
73

largely ignored. There has been little innovative literature for almost a century with a
few notable exceptions, e.g. in the writings of von Wright or Mackie.
The philosopher of science Hans Reichenbach introduced a distinction between
the context of discovery and the context of justiﬁcation. The former concerns the
question how scientiﬁc laws and theories are found, the latter how they are eventu-
ally justiﬁed. Many methodologists in the twentieth century were skeptical that
anything systematic could be said about the context of discovery, which allegedly
belongs to the realm of intuition and creative thought. As Popper said, the issue may
be “of great interest to empirical psychology; but it is irrelevant to the logical
analysis of scientiﬁc knowledge” (1935/2002, 7). Some modern authors, in partic-
ular John Norton with his material theory of induction (2003), have even attempted
to turn the alleged lack of general rules for induction into a virtue. As Thomas Kelly
explains: “if it turns out that inductive reasoning is not a matter of following general
rules or principles, then there is no corresponding optimistic assumption about the
world that stands in need of justiﬁcation—and thus, nothing to serve as grist for
Hume’s mill [. . .]. In this way, Hume’s skeptical challenge is defused, having been
revealed to rest on a mistaken presupposition about how inductive reasoning actually
works.” (2010, 755).
Given the confused state of the debate concerning induction and inductivism, we
have to start from the basics. The most fundamental distinction with respect to
inductive methodology is that between enumerative, eliminative, and variational
induction. In the literature, the latter two types are often conﬂated, but as will be
elaborated, important reasons exist to keep them apart.
Enumerative induction is arguably the oldest and most familiar type of induction.
As the term indicates, such inferences are established by an enumeration of instances
that link similar events of a type A with similar events of another type C. Given a
sufﬁcient number of observations where A and C co-occur, and lacking instances in
which C is absent in the presence of A, it is justiﬁed to conclude that there is a
general dependency between A and C. For example, observing that a certain type of
skin cancer is lethal in a number of patients leads to the conclusion that this skin
cancer kills in general.
It is unclear how many instances are necessary to justify the inference to a general
law—which constitutes one of the major objections against enumerative induction.
Indeed, this puzzle was already raised by Hume and subsequently reiterated by many
others. Sometimes, successful enumerative inferences are based on just a few
instances, while often even a large number of instances still lead to erroneous
conclusions. One could call this the problem of the measure of conﬁrmation for
enumerative induction. Another crucial and related objection is that no criterion
exists to distinguish between meaningful versus merely accidental conjunctions of
events, i.e. between evidence that warrants reliable predictions and evidence that
does not.
Nevertheless, in epistemology and also in the sciences, enumerative induction is
held by many and distinguished scholars to be an important, if not the crucial, type of
induction: “The most ancient form of induction, the archetype of this family, is
enumerative induction, or induction by simple enumeration. [. . .] Examples are
74
4
Variational Induction

readily found in Aristotle. Traditionally, enumerative induction has been synony-
mous with induction, and it was a staple of older logic texts to proceed from
deductive syllogistic logic to inductive logic based on the notion of enumerative
induction.” (Norton 2005, 10) Norton continues: “The actual inductive practice of
science has always used enumerative induction, and this is not likely to change. For
example, we believe all electrons have a charge of 1.6  1019 Coulombs, simply
because all electrons measured so far carry this charge.” (ibid., 12) Certainly,
enumerative induction seems to play a role in everyday reasoning. One usually
expects that a relationship which has been observed many times will continue to hold
in the future. Enumerative thinking also lies at the heart of many conceptual analyses
in epistemology, e.g. regularity conceptions of scientiﬁc laws, of causation or the
frequency interpretation of probability.
We will later see that instead of being the core of inductive methodology,
enumerative induction does not even constitute an important type of inductive
inferences. In fact, what prima facie appears to be enumerative induction should
actually be understood in terms of variational induction serving two main functions:
(1) ﬁrst, to control for possibly relevant circumstances; (2) second, to establish
relative frequencies for probabilistic analyses.2 In the ﬁrst case, alleged enumerative
induction actually constitutes an application of the method of agreement. This
perspective, which will be further elaborated in Sect. 8.2.2, both explains the general
unreliability of enumerative induction and solves the problem of the measure of
conﬁrmation for enumerative induction.
The second type of induction that I want to discuss is eliminative induction. This
type relies on the assumption that an exhaustive set of hypotheses or theories about a
phenomenon is available. One after another, all false hypotheses or theories can be
eliminated, until only the true one remains. This elimination in general proceeds
deductively via modus tollens by showing that certain deductive consequences of a
hypothesis are in contradiction with actual experience.
A classic example for eliminative induction is the discovery of the causes of
childbed or puerperal fever by Ignaz Semmelweis in the nineteenth century (Bird
2010; see also Lipton 2004, Ch. 5), though this example has also been used to
illustrate rivaling accounts of scientiﬁc inference (e.g. Hempel 1966, Ch. 2; Scholl
2013). In two maternity wards of the General Hospital in Vienna in the 1840’s,
mortality rates widely differed. Whereas in one ward only about 2–3% of the women
died when giving birth, in the other, mortality rates were much higher, in some years
even above 10%. Ignaz Semmelweis was a young doctor determined to solve the
puzzle concerning the origin of this remarkable situation. According to the standard
lore, based in part on his own detailed documentation, Semmelweis formulated a
number of possible hypotheses regarding the cause of the high mortality rates. For
example, he observed that women in ward I delivered on their backs, while those in
ward II delivered on their sides. Thus, he arranged for the women in ward I to also
deliver on their sides, but with no effect on mortality—thus eliminating the
2On the second issue, cf. Chap. 9.
4.1
Enumerative, Eliminative, and Variational Induction
75

corresponding hypothesis. Another hypothesis concerned psychological effects of
priests passing through one of the wards on their way to extremely ill patients.
Semmelweis had the priests take a different route, but again, there was no effect on
mortality rates. After many such unsuccessful attempts, Semmelweis hypothesized
that the women in ward I attracted an infection by medical students, who were
trained in that ward and who as part of their education also assisted in autopsies. By
comparison, in ward II, midwives were trained who did not take part in autopsies.
Semmelweis could show that consequences of this last hypothesis largely turned out
to be true. In particular, having the medical students wash their hands after autopsies
with chlorinated water, a disinfectant, signiﬁcantly lowered the mortality rate in
ward I.
Eliminative induction has been criticized for various reasons. Perhaps the most
important objection is that it may not constitute an inductive method at all. Indeed, it
resembles much more closely a hypothetico-deductive approach, where hypotheses
are postulated and their deductive consequences are examined. Apparently, the
additional premise in comparison with conventional hypothetico-deductivism is
that an exhaustive set of hypotheses is available, among which the true hypothesis
can be found. In general, this premise seems impossible to establish and it is already
wildly implausible in the case study of childbed fever. In fact, the eventual ‘true’
hypothesis was not even among the original set that Semmelweis considered, but
was suggested to him by the death of a close colleague who succumbed to a disease
with very similar symptoms as childbed fever after an infection attracted during a
post-mortem examination (Bird 2010, p. 6). The additional premise of an exhaustive
set of hypotheses does little work in eliminative induction and thus its classiﬁcation
as a hypothetico-deductive approach is plausible.
Let us ﬁnally turn to variational induction.3 Representative of this type are John
Stuart Mill’s ﬁve canons of induction. Arguably, the two most important methods
are the method of difference and the method of agreement. In Mill’s formulation, the
latter states:
If two or more instances of the phenomenon under investigation have only one circumstance
in common, the circumstance in which alone all the instances agree, is the cause (or effect) of
the given phenomenon. (1886, 255)
The method of difference reads:
If an instance in which the phenomenon under investigation occurs, and an instance in which
it does not occur, have every circumstance save one in common, that one occurring only in
the former; the circumstance in which alone the two instances differ, is the effect, or cause, or
a necessary part of the cause, of the phenomenon. (ibid., 256)
Both methods infer a causal relationship between a phenomenon and its circum-
stances by relying on variational evidence, i.e. on evidence, which tracks changes in
a phenomenon resulting from systematic variations of circumstances.
3This terminology, which is not standard, is borrowed from Russo (2007, 2009), who has empha-
sized a ‘rationale of variation’ underlying much of our inductive reasoning.
76
4
Variational Induction

There are fundamental differences in comparison with enumerative induction.
While in enumerative induction the focus lies on regularities of events, in variational
induction it is on changes in circumstances. Consequently, the decisive type of
evidence and the measure of conﬁrmation differ for both inductive methods. In
enumerative induction, conﬁrmation is mostly thought to increase4 with the number
of observed co-occurrences of two phenomena A and C. By contrast, conﬁrmation in
variational induction increases with the variety of evidence, i.e. with observing as
many different situations in terms of changing circumstances as possible. Relatedly,
fully identical instances, i.e. those with exactly the same circumstances, increase the
conﬁdence in a generalization according to enumerative induction but not according
to variational induction. While negative instances ØB play only a destructive role in
enumerative induction resulting in the abandonment of generalizations, they are
constructively taken into account in variational induction leading to the reﬁnement
of causal knowledge. All these differences imply, not surprisingly, that whether and
how inductive inferences can be justiﬁed is substantially different between enumer-
ative and variational induction. I will return to this question in Sect. 6.2.
Many proponents of variational induction have been quite vocal about their
rejection of enumerative induction, including inﬂuential ﬁgures like Francis
Bacon, John Stuart Mill, or John Maynard Keynes. The ﬁrst writes that “the
induction [. . .] which proceeds by simple enumeration is a childish affair, unsafe
in its conclusions, in danger from a contradictory instance, taking account only of
what is familiar, and leading to no result.” (Bacon 1620/1994, 21) Mill agrees:
“[Enumerative induction] is the kind of induction which is natural to the mind when
unaccustomed to scientiﬁc methods. [. . .] It was, above all, by pointing out the
insufﬁciency of this rude and loose conception of Induction that Bacon merited the
title so generally awarded to him of Founder of the Inductive Philosophy.” (Mill
1886, 204) The economist John Maynard Keynes in his Treatise on Probability
emphasizes the importance of variation as opposed to regularity: “by emphasizing
the number of instances Hume obscured the real object of the method. [. . .] The
variety of the circumstances [. . .] rather than the number of them, is what seems to
impress our reasonable faculties.” (1921, 233–234)
Let me also brieﬂy address how variational induction differs from eliminative
induction. This is particularly important because many consider Mill’s canons to be a
main example of eliminative induction. For example, John Norton writes: “Mill’s
canons provide some of the best known examples of eliminative induction. He
labelled them ‘methods of elimination’ since they are intended to enable one to
eliminate all but the true causes out of the range of possible causes for a given
phenomenon.” (1995, 30) And indeed, Mill himself claims that his methods of
agreement and of difference constitute an eliminative approach: “[The term ‘elim-
ination’] is well suited to express the operation [. . .] which has been understood
since the time of Bacon to be the foundation of experimental inquiry: namely, the
4But remember the above discussion concerning the problem of the measure of conﬁrmation for
enumerative induction.
4.1
Enumerative, Eliminative, and Variational Induction
77

successive exclusion of the various circumstances which are found to accompany a
phenomenon in a given instance, in order to ascertain what are those among them
which can be absent consistently with the existence of the phenomenon. The Method
of Agreement stands on the ground that whatever can be eliminated, is not connected
with the phenomenon by any law. The Method of Difference has for its foundation,
that whatever cannot be eliminated, is connected with the phenomenon by a law.”
(1886, 256)
But, as I want to argue, the parallels are rather superﬁcial. Importantly, in
variational induction, circumstances are eliminated from the list of potential causes
of a phenomenon, while in eliminative induction competing hypotheses are elimi-
nated. In variational induction, circumstances are examined, whether they are
necessary or sufﬁcient conditions for a phenomenon. Certainly, they do not reﬂect
competing causal hypotheses, but all kinds of interdependencies between individual
circumstances are possible.
Moreover, circumstances can take on a much wider variety of roles in contrast to
competing hypotheses. For example, circumstances can be relevant or irrelevant for
a considered phenomenon, while eliminative induction is interested in truth or
falsehood rather than relevance. Also, the negation of a circumstance can turn out
to be causally relevant in variational induction, whereas false hypotheses do not play
a constructive role in eliminative induction. Circumstances can undergo gradual
changes, rather than being only absent or present, while nothing analogous can be
said about competing hypotheses.
With respect to the distinction between theoretical and phenomenological sci-
ence, variational induction clearly constitutes a phenomenological approach since
the principal aim of methods like the method of difference is causal analysis. By
contrast, eliminative induction may feature both in theoretical and in phenomeno-
logical science, depending largely on the nature of the competing hypotheses that are
examined. If these hypotheses describe possible causes of a phenomenon, then
eliminative induction is clearly a part of phenomenological science. But in many
case studies of eliminative induction, the competing hypotheses actually concern
different theoretical explanations of a phenomenon. A good example is John
Norton’s analysis of Einstein’s discovery of general relativity in terms of eliminative
induction (1995).
Relatedly, it is much more obvious that variational induction constitutes an
inductive approach than is the case with eliminative induction. Indeed, variational
methods like the method of difference infer from observation statements to general
causal relationships, while little background theory is required. By contrast, elimi-
native induction, as already pointed out, has a decisive hypothetico-deductive
character.
Finally, the spectrum of different methods in variational induction has no ana-
logue in eliminative induction. For example, the method of difference does not aim
at elimination or falsiﬁcation, but directly establishes a causal relationship between
two variables. Something similar could be said about the method of concomitant
variation to be discussed in the next section. By contrast, eliminative induction can
establish the truth of a hypothesis only by elimination of all potential rivals.
78
4
Variational Induction

Thus, there are many reasons to hold eliminative and variational induction apart,
even though the two have generally been conﬂated in the past.
4.2
A Brief History of Variational Induction
4.2.1
Bacon and His Predecessors
As one should expect for any elementary scientiﬁc method, variational induction has
been around for a long time. The method of difference is ubiquitous both in everyday
and in scientiﬁc reasoning. An interesting question with respect to the history of
variational induction is at what point scholars started to explicitly reﬂect on the logic
behind such inferences. As far as I am aware, not much on this topic can be found in
the Greek or Roman classics. For example, Aristotle’s treatment of scientiﬁc
method, which is among the deepest and most extensive analyses in ancient philos-
ophy, does not discuss variational methods like the method of difference. He
distinguishes two types of induction, enumerative induction on the one hand and
induction by intuition on the other hand. According to this second type, the general
law subsuming a range of observations is intuited—bearing some similarity to what
contemporary methodologists call abductive reasoning (Losee 2001, Ch. 1).
Apparently, the ﬁrst major explicit analyses of variational induction we owe to
scholars of the supposedly dark and intellectually unfertile Middle Ages, in partic-
ular Roger Bacon, Duns Scotus, and William of Ockham.5 Duns Scotus is often
credited as being among the ﬁrst to have stated the method of agreement, according
to which one has to look for a circumstance that is always present among a number of
varying circumstances in order to discover the cause of a phenomenon. William of
Ockham, who is known in modern times primarily for his requirement of ontological
sparsity commonly referred to as Ockham’s razor, explicitly formulated the method
of difference.
Today, Francis Bacon is usually credited with overcoming the naïve conception
of induction by enumeration—while the substantial prehistory during the Middle
Ages is usually ignored.6 Bacon construes his version of variational induction,
which is often referred to as the method of exclusion, as a gradual generalization
from the particular to the most general. The empirical basis of his method consists in
collecting as wide a variety of relevant instances as possible. These instances are
then arranged in three different tables.
The ﬁrst so-called table of essence or presence lists instances in which the
examined phenomenon occurs. Bacon’s primary example with which he illustrates
the method of exclusion concerns the nature of heat. In the table of presence, he lists
among many other instances: “the rays of the sun, especially in summer and at
5Cp. Losee (2001, Ch. 5)
6Cp. the quotes in the previous Sect. 4.1.
4.2
A Brief History of Variational Induction
79

noon”; “the rays of the sun reﬂected and condensed, as between mountains, or on
walls, and most of all in burning glasses and mirrors“; “eruptions of ﬂame from the
cavities of mountains”; “all ﬂame”; “natural warm baths”; “air conﬁned and under-
ground in some caverns, especially in winter”; “all villous substances, as wool, skins
of animals, and down of birds”; “green and moist vegetables conﬁned and bruised
together”; “oil of marjoram and similar oils [. . .] in burning the bones of the teeth”;
etc. (Bacon 1620/1994, II.11) Clearly, the evidence that Bacon draws upon in his
table of presence concerns variation in the circumstances under which heat can be
found, rather than mere regularity.
The second table is the table of deviation or of absence in proximity which
collects instances that are similar to those in the ﬁrst table, but where the examined
phenomenon does not occur. In his example concerning the nature of heat, Bacon
observes with respect to the ﬁrst afﬁrmative instance, i.e. rays of the sun, that rays are
not always hot: “The rays of the moon and of stars and comets are not found to be hot
to the touch; indeed the severest colds are observed to be at the full moons.” As a
second example, Bacon refers to his previous observation that rays of the sun
condensed in burning glasses convey heat and compares this case with “a glass
fashioned in a contrary manner to a common burning glass and, placing it between
your hand and the rays of the sun”. Apparently, this arrangement “diminishes the
heat of the sun, as a burning glass increases and strengthens it.” (ibid., II.12)
Finally, the third table, the table of degrees or of comparison, lists instances in
which the phenomenon occurs in different degrees. For example, Bacon observes
that there are a number of inanimate substances that are strongly disposed to heat or
ﬂame such as “sulphur, naphtha, rock ail”. Or, Bacon ﬁnds that plants usually do not
exhibit warmth when touched. However, when being shut up, “green herbs gain
warmth”. Also, in “plasters and ointments”, some vegetables are perceptibly warm.
(ibid., II.13)
Given these lists of instances, Bacon then puts the method of exclusion at work:
“Which presentation [of the three tables] having been made, induction itself must be
set at work; for the problem is, upon a review of the instances, all and each, to ﬁnd
such a nature as is always present or absent with the given nature, and always
increases and decreases with it; and which is, as I have said, a particular case of a
more general nature.” (ibid., II.15) Bacon refers to this step as ‘the ﬁrst vintage’.
With respect to his example, he proposes various hypotheses of what the nature of
heat might be and subsequently invalidates these hypotheses on the basis of coun-
terinstances. For example, Bacon excludes light and brightness because of the rays
of the moon, which are bright but cold. Or he excludes a heavenly origin of heat,
since there are subterraneous ﬁres like volcanoes.
Bacon’s conclusion concerning the nature of heat is as follows:
From a survey of the instances, all and each, the nature of which heat is a particular case
appears to be motion. This is displayed most conspicuously in ﬂame, which is always in
motion, and in boiling or simmering liquids, which also are in perpetual motion. It is also
shown in the excitement or increase of heat caused by motion, as in bellows and blasts [. . .].
Again it is shown in the extinction of ﬁre and heat by any strong compression, which checks
and stops the motion [. . .]. It is shown also by this, that all bodies are destroyed, or at any rate
80
4
Variational Induction

notably altered, by all strong and vehement ﬁre and heat; whence it is quite clear that heat
causes a tumult and confusion and violent motion in the internal parts of a body, which
perceptibly tend to its dissolution. (ibid., II.20)
Bacon’s answer comes quite close to our modern conception of heat in terms of
microscopic motion. This is all the more remarkable considering that for many
centuries after Bacon the predominant view considered heat to be a substance, the
so-called caloric, rather than motion.
While Bacon’s approach has unique features, it is an inﬂuential forerunner of the
most important methods of variational induction. The table of presence together with
the instruction “to ﬁnd such a nature as is always present [. . .] with the given nature”
broadly corresponds to the method of agreement. Taking into account the table of
absence in proximity and requiring that the sought-after nature must be absent if the
examined phenomenon is absent, amounts to what Mill later called the combined
method of difference and agreement. In ideal cases where the instance in the table of
presence and the corresponding instance in the table of absence are exactly alike
except for one circumstance, Bacon’s method of exclusion more or less corresponds
to the method of difference. Finally, the table of degrees together with the require-
ment to “ﬁnd such a nature as [. . .] always increases and decreases with [a given
nature]” closely resembles Mill’s method of concomitant variation, which is
discussed below.
A peculiarity of Bacon’s methodology is that he is not looking for causal
relationships on which predictions and interventions can be based, but rather he
examines the nature or essence of speciﬁc phenomena as the heat example well
illustrates. Thus, Bacon’s analysis seems to concern theoretical science aiming at
understanding and explanation. In this respect, Bacon’s depiction of variational
induction deviates from later accounts such as Herschel’s or Mill’s. Bacon’s
approach is in many ways a hybrid combining hypothesis testing with variational
procedures. However, the logic underlying his so-called ﬁrst vintage clearly corre-
sponds to the methods of difference, agreement, and concomitant variations.
For a long time, Bacon was considered by many to be the founder of modern
scientiﬁc method overcoming naïve conceptions of induction in ancient philosophy
as well as the deductivism of medieval scholastics. Mill called Bacon the “Founder
of the Inductive Philosophy” (Mill 1886, 204). Remarkably, Bacon’s contribution to
scientiﬁc methodology—pinpointing the weak spots of enumerative induction and
replacing it by an entirely different perspective on inductive inference—is lost in
many modern assessments regarding the signiﬁcance of Bacon.
4.2.2
Herschel and Mill
Bacon’s signiﬁcance for modern science was enormous and it is easy to discern his
ideas in methodological remarks by both scientists and methodologists in the
following centuries. Today, however, Bacon’s role is rarely recognized. The origin
4.2
A Brief History of Variational Induction
81

of his waning inﬂuence lies partly in intense methodological debates during the
nineteenth century. In that time, scholars like John Herschel, William Whewell, or
John Stuart Mill devoted large parts of their academic efforts to thick methodological
treatises on scientiﬁc method.
John Herschel is a central ﬁgure for the history of variational induction. Notably,
he explicitly stated and to a certain extent systematized many of the methods that
later became widely known as Mill’s canons. Herschel’s account of variational
induction forms a crucial part of his main book on philosophy of science, The
Preliminary Discourse on the Study of Natural Philosophy (1851). John Herschel
may not be well known today, but he was very inﬂuential in his days as a method-
ologist. An example is Charles Darwin’s recollection in his autobiography: “During
my last year at Cambridge I read with care and profound interest Humboldt’s
Personal Narrative. This work and Sir J. Herschel’s Introduction to the Study of
Natural Philosophy [i.e. the Preliminary Discourse] stirred up in me a burning zeal to
add even the most humble contribution to the noble structure of Natural Science. No
one or a dozen other books inﬂuenced me nearly so much as these two.” (cited in
Ruse 1975, 164) Also, Darwin refers to Herschel in the opening paragraph of the
Origin of Species, where he says: “When on board H. M. S. ‘Beagle’ as naturalist, I
was much struck with certain facts in the distribution of the inhabitants of South
America, and in the geological relations of the present to the past inhabitants of that
continent. These facts seemed to me to throw some light on the origin of species—
that mystery of mysteries, as it has been called by one of our greatest philosophers.”
(Darwin 1861, 9) The phrase “mystery of mysteries” is Herschel’s from a letter to
geologist Charles Lyell (cf. Warner 2009, 436).
Herschel lists the following characteristics for causal relationships:
1st, invariable connection, and in particular, invariable antecedence of the cause and
consequence of the effect, unless prevented by some counteracting cause. [. . .] 2nd, invari-
able negation of the effect with absence of the cause, unless some other cause be capable of
producing the same effect. 3rd, increase or diminution of the effect, with the increased or
diminished intensity of the cause, in cases which admit of increase and diminution. 4th,
proportionality of the effect to its cause in all cases of direct unimpeded action. 5th, reversal
of the effect with that of the cause. (1851, 151–152)
Starting from these characteristics, Herschel renders plausible a number of
inductive rules for causal inferences from observations. Thus, one remarkable
feature of Herschel’s approach is that he hints at a connection between the concep-
tual analysis of the cause-effect relation and the methodology how to infer causal
relationships. In the following, I will brieﬂy present only those rules that are the most
relevant for my discussion. For example, Herschel’s second rule reads:
That any circumstance in which all the facts without exception agree, may be the cause in
question, or, if not, at least a collateral effect of the same cause: if there be but one such point
of agreement, this possibility becomes a certainty; and, on the other hand, if there be more
than one, they may be concurrent causes. (ibid., 152)
Obviously, this rule corresponds to Mill’s method of agreement. It even is in
certain ways more reﬁned than Mill’s formulation. In particular, Herschel carefully
82
4
Variational Induction

distinguishes in his nine rules different types of causal concepts, e.g. concurrent
causes, counteracting causes, or collateral effects. While Mill is clearly aware of
such complications, he does not explicitly address them in his canons.
In his fourth rule, Herschel stresses the crucial importance of negative instances,
which I already highlighted as a distinguishing characteristic of variational induction
in comparison to enumerative induction:
That contrary or opposing facts are equally instructive for the discovery of causes with
favourable ones. (ibid., 153)
Mill’s method of difference can be found in Herschel’s seventh rule:
If we can either ﬁnd produced by nature, or produce designedly for ourselves, two instances
which agree exactly in all but one particular, and differ in that one, its inﬂuence in producing
the phenomenon, if it have any, must thereby be rendered sensible. If that particular be
present in one instance and wanting altogether in the other, the production or non-production
of the phenomenon will decide whether it be or be not the only cause: still more evidently, if
it be present contrariwise in the two cases, and the effect be thereby reversed. [. . .] (ibid.,
154–155)7
Again, there are a number of differences in comparison with Mill’s formulation as
presented in Sect. 4.1. For example, Herschel proposes an interesting distinction
between the absence and the reversal of a particular or circumstance. One might
think of the absence of heat versus the presence of cold. Also, he explicitly addresses
which conclusion can be drawn if a change in circumstance does not produce a
phenomenon, namely that the circumstance cannot be the only cause. In other words,
the circumstance is either irrelevant or requires other circumstances to be present in
order to produce the phenomenon.
Finally, Herschel also formulated a version of the method of residues that we will
soon see to be part of Mill’s account of variational induction:
Complicated phenomena, in which several causes concurring, opposing, or quite indepen-
dent of each other, operate at once, so as to produce a compound effect, may be simpliﬁed by
subducting the effect of all the known causes, as well as the nature of the case permits, either
by deductive reasoning or by appeal to experience, and thus leaving, as it were, a residual
phenomenon to be explained. It is by this process, in fact, that science, in its present
advanced state, is chieﬂy promoted. Most of the phenomena which nature presents are
very complicated; and when the effects of all known causes are estimated with exactness,
and subducted, the residual facts are constantly appearing in the form of phenomena
altogether new, and leading to the most important conclusions. (ibid., 156)
Thus, Herschel stresses that the method of residues is helpful for the analysis of
complex phenomena which are determined by various causal factors. It allows to
gradually discover more and more esoteric and detailed phenomena in the advanced
sciences.
7Herschel clearly sees a link to exploratory experimentation as discussed in Sect. 3.2: “In nature, it
is comparatively rare to ﬁnd instances pointedly differing in one circumstance and agreeing in every
other; but when we call experiment to our aid, it is easy to produce them; and this is, in fact, the
grand application of experiments of enquiry in physical researches.” (ibid., 155)
4.2
A Brief History of Variational Induction
83

As mentioned, Herschel’s account is in some ways more sophisticated and
detailed than Mill’s discussion. However, the compactness of Mill’s account may
be the reason why his version of variational induction has become by far the best-
known approach, while Herschel’s admirable work on variational induction is all but
forgotten. Mill, of course, is no less important for Western history of thought than
Herschel. He is by some considered the most inﬂuential English-speaking philoso-
pher of the nineteenth century. Also, Mill is a father ﬁgure of modern economics and
one of the most outspoken proponents of a liberal conception of society. In moral
philosophy, Mill was a staunch defender of utilitarianism.
Mill’s formulations of the methods of agreement and difference were given in
Sect. 4.1. He considered the method of difference as the most effective
variational rule: “It thus appears to be by the Method of Difference alone that we
can ever, in the way of direct experience, arrive with certainty at causes.” (1886, 258)
Some have argued that Mill later distanced himself from this view, but these claims
nevertheless remain in further editions of his System of Logic. The method of
difference is crucial for the logic of exploratory experimentation, ensuring that a
cause can actually produce a phenomenon. Production and in particular reproduction
are of course generally considered proof of experimental knowledge of a phenom-
enon (ibid., 257). The method of agreement for Mill is the method of elimination.
Under the assumption that the true and only cause is among the considered circum-
stances, sufﬁcient evidence can eliminate all other circumstances from the list of
potential causes. This assumption, of course, is quite strong, as will be discussed in
the following section when we look at typical objections against Mill’s methods.
Mill’s framework furthermore includes the method of concomitant variation,
which also ﬁgures in Herschel’s account, e.g. in the fourth aspect of his deﬁnition
of cause (cf. the quote above). Mill states the method in the following manner:
Whatever phenomenon varies in any manner whenever another phenomenon varies in some
particular manner, is either a cause of an effect of the phenomenon, or is connected with it
through some fact of causation. (ibid., 263)
Like Herschel, Mill sees the primary function of this method in the discovery and
proof of laws with permanent causes, i.e. such circumstances which cannot fully be
eliminated (ibid., 260). Mill points to a connection with the method of difference,
saying that true causes which allow for the production of phenomena can only be
proven, if the concomitance itself is established by the method of difference, i.e. if all
other antecedents are left unchanged and only the examined circumstance is sys-
tematically varied (ibid., 263).
The method of residues also forms part of Mill’s canons, but it has a somewhat
different function compared with Herschel’s account. While the latter saw the
primary function of this method in dealing with complex phenomena, Mill consid-
ered it one of the most important tools for discovery (ibid., 260). After all, the
method allows one to identify yet unexplained phenomena as well as circumstances
of which the signiﬁcance is not yet sufﬁciently understood:
84
4
Variational Induction

Subduct from any phenomenon such part as is known by previous inductions to be the effect
of certain antecedents, and the residue of the phenomenon is the effect of the remaining
antecedents. (ibid.)
Obviously, the method of residues relies on the principle of the composition of
causes that “the same law which expresses the effect of each cause acting by itself
shall also correctly express the part due to that cause of the effect which follows from
the two together” (ibid., 242). Mill certainly acknowledges that this principle is not
always satisﬁed, which in fact constitutes one of the main objections against Mill’s
canons, as we will see below. He draws an interesting link that the method of
residues essentially relies on the method of difference, where the negative instance
is not gathered from experience but is deductively derived from causal relationships
that are already known (ibid., 260).
Mill considered these four methods—the method of agreement, the method of
difference, the method of residues, and the method of concomitant variations—as
“the only possible methods of experimental inquiry—of direct induction a
posteriori” (ibid., 266). For practical purposes, however, he adds a ﬁfth method,
which is the combined or joint method of agreement and difference:
If two or more instances in which the phenomenon occurs have only one circumstance in
common, while two or more instances in which it does not occur have nothing in common
save the absence of that circumstance, the circumstance in which alone the two sets of
instances differ is the effect, or the cause, or an indispensable part of the cause, of the
phenomenon. (ibid., 259)
Mill sees the joint method as an improvement on the method of agreement but as
less rigorous than the method of difference (ibid.). The joint method also has the
advantage that it is not affected by the plurality of causes, in contrast to the method of
agreement.
4.2.3
Problems of Mill’s Account of Variational Induction
Mill was well aware of a number of problems for his methods. Some of these
surfaced in exchanges and discussions with other methodologists of his time, most
notably perhaps William Whewell, his eternal counterpart and opponent. Among
other criticism, the latter doubted that Mill’s four methods play a substantial role in
scientiﬁc practice:
Upon these methods the obvious thing to remark is, that they take for granted the very thing
which is most difﬁcult to discover, the reduction of the phenomena to formulae such as are
here presented to us. When we have any set of complex facts offered to us,—for instance,
those which were offered in the cases of discovery which I have mentioned,—the facts of the
planetary paths, of falling bodies, of refracted rays, of cosmical motions, of chemical
analysis; and when, in any of these cases, we would discover the law of nature which
governs them, or, if any one chooses so to term it, the feature in which all the cases agree,
where are we to look for our A, B, C [i.e. the circumstances] and a, b, c [i.e. the
corresponding phenomena]? Nature does not present to us the cases in this form; and how
4.2
A Brief History of Variational Induction
85

are we to reduce them to this form? You say, when we ﬁnd the combination of A B C with a
b c and A B D with a b d, then we may draw our inference. Granted; but when and where are
we to ﬁnd such combinations? Even now that the discoveries are made, who will point out to
us what are the A, B, C and a, b, c elements of the cases which have just been enumerated?
Who will tell us which of the methods of inquiry those historically real and successful
inquiries exemplify? Who will carry these formulae through the history of the sciences as
they have really grown up; and show us that these four methods have been operative in their
formation; or that any light is thrown upon the steps of their progress by reference to these
formulae? (Whewell 1860, 263–4; cited in Mill 1886, 282)
Whewell also criticizes the examples that Mill uses to illustrate his methods
saying: “If Mr. Mill’s four methods had been applied by him in his book to a large
body of conspicuous and undoubted examples of discovery, well selected and well
analysed, extending along the whole history of sciences, we should have been able to
estimate the values of these methods.” (ibid., 264–265)
Mill concedes to Whewell that “the greatest difﬁculty” of his inductive approach
is “ﬁrst that of obtaining the evidence, and next, reducing it to the form which tests
its conclusiveness” (1886, 283). But Mill insists that his methods play a crucial role
in all experimental philosophy and that they are the centerpiece of inductive logic,
providing rules and models “to which, if inductive arguments conform, those
arguments are conclusive, and not otherwise” (ibid.). Whether experimenters are
aware of it or not, they have used Mill’s canons “long before any one sought to
reduce the practice to theory” (ibid.). Indeed, we found in the previous chapter that
variational induction and in particular the method of difference constitute the basic
logic of exploratory experimentation. Mill draws a comparison with deductive logic,
which at ﬁrst sight also appears quite detached from actual reasoning, while in fact it
underlies many everyday and scientiﬁc inferences.
To those methodologists like Whewell who emphasize the role of hypotheses in
experimental enquiry, Mill replies in typical inductivist manner that hypotheses are
useless if they are not based on ﬁrst generalizations which have been established
inductively. While Mill does not deny the fruitful role of hypotheses in scientiﬁc
enquiry, they “must end by being proved, and are in reality [. . .] proved, by the Four
Methods” (ibid., 284). Such a temporary role for hypotheses was identiﬁed as an
important characteristic of an inductivist perspective according to Sect. 2.1.
Furthermore, Whewell rightly raises the question where the concepts and cate-
gories come from in which the circumstances and the phenomena are formulated and
which thus form the basis of the fundamental type of evidence for variational
induction. We will return to this issue in Chap. 7, where it will be shown that
variational induction can also be employed for concept formation. Thus it turns out
that Whewell was wrong to assume that a fully developed conceptual framework
already has to exist in order to apply Mill’s methods.
The method of difference is the only one according to Mill that can provide actual
proof for causal dependence. Thus, from a logical perspective, it is quite important to
examine its premises. According to Mill’s own account this method requires that two
instances exist which “have every circumstance in common save one”. As Mill
86
4
Variational Induction

himself is certainly aware this is practically and maybe even in principle impossible.8
But he readily points out that the similarity between instances need not extend to
those circumstances that “are already known to be immaterial to the result” (ibid.,
256). Note that much the same holds for the other methods of Mill’s framework. In
order for these methods to work in scientiﬁc practice, one has to presuppose that a
large number of circumstances are irrelevant for the examined phenomenon and thus
that the possibly inﬁnite number of potentially relevant circumstances can somehow
be reduced to a small number that a scientist can handle. According to Mill,
experiments constitute pretty much the only situations in which one can expect
evidence so that the method of difference can be reasonably applied (ibid.).
Apparently, a problem remains in that none of Mill’s rules is tailored to
establishing the irrelevance of circumstances to a phenomenon. Rather, he infor-
mally suggests that “in the case of most phenomena we learn at once, from the
commonest of experience, that most of the co-existent phenomena of the universe
may be either present or absent without affecting the given phenomenon; or, if
present, are present indifferently when the phenomenon does not happen and when it
does.” (ibid.) In the next two chapters, this problem will be tackled by introducing an
inductive rule for establishing causal irrelevance.
Further substantial assumptions are required for Mill’s methods to yield correct
results. Maybe the most important but also most controversial premise is causal
determinism. All methods of variational induction require that the examined phe-
nomenon is fully determined by its circumstances. Otherwise, they could easily lead
to erroneous results. For example, irrelevant changes in the circumstances might be
identiﬁed as causally relevant by the method of difference, even though the changes
of an indeterministic phenomenon were merely due to chance. Relatedly, variational
induction presupposes as a practical requirement that the actual cause of the phe-
nomenon is among those circumstances that are considered. We will return to the
issue of determinism in Chap. 9.
Another serious objection against Mill’s framework of variational induction is
that his methods are not capable of dealing with certain widespread causal structures,
in particular the plurality of causes and the intermixture of effects. Causes rarely are
single circumstances, but rather they can in general be expressed in terms of INUS-
conditions, i.e. a causally relevant circumstance usually ﬁgures as an Insufﬁcient, but
Non-redundant part of an Unnecessary but Sufﬁcient condition. In other words,
causally relevant circumstances A generally form part of Boolean expressions of
the form (A ˄ B) ˅ C, which constitute the full cause. Note that B and C can
themselves be placeholders for more complicated expressions.9
The plurality of causes turns out to be problematic especially for the method of
agreement. Notably, if a phenomenon can be caused by different circumstances C1 ˅
8Peter Lipton calls this the “problem of multiple differences” (2004, 128; cf. also Scholl 2015,
Sec. 3).
9The notion of an INUS-condition was introduced by John Mackie in his Cement of the Universe
(1980) and will be discussed in more depth in Sect. 5.2.
4.2
A Brief History of Variational Induction
87

C2, there will be no single circumstance in which all phenomena agree, even though
the actual causes are among the considered circumstances. As Mill emphasizes, this
problem is ubiquitous, there are for example many causes for mechanical motion or
many causes for death (ibid., 286). He notes that by contrast, the method of
difference is free of this difﬁculty (ibid.). This is indeed mostly the case, since the
method of difference just identiﬁes the actual cause of a phenomenon in a given
situation, rather than other potential causes, which were not active. However, the
method of difference occasionally runs into problems when faced with plurality of
causes in situations of overdetermination or of preemption, i.e. situations in which
two potential causes of a phenomenon are present. This topic will be taken up again
in Sect. 5.4.2.10
The second class of causal structure that Mill addresses in much detail regards the
intermixture of effects: “[a] concurrence of two or more causes, not separately
producing each its own effect, but interfering with or modifying the effects of one
another” (ibid., 289). Thus, the problem concerns situations in which several causes
interact to produce a phenomenon. Mill also speaks of the composition or interfer-
ence of causes in this context. He distinguishes two cases. In the ﬁrst, the individual
effects of the different circumstances can still be traced in the resulting phenomena,
but they do not appear separately. An example is the vector addition of forces in
classical mechanics. In the second case, the separate effects disappear entirely giving
way to a completely novel phenomenon. Examples here are certain chemical reac-
tions, for example when hydrogen and oxygen combine to form water. (ibid.)
Mill believes that the intermixture of effects is particularly problematic for
situations of the ﬁrst kind, where “each cause continues to produce its own proper
10Remarkably, Mill sees in the mere repetition of instances an important tool to deal with the
plurality of causes: “The Plurality of Causes is the only reason why mere number is of any
importance. The tendency of unscientiﬁc inquirers is to rely too much on number, without analyzing
the instances; without looking closely enough into their nature, to ascertain what circumstances are
or are not eliminated by means of them. Most people hold their conclusions with a degree of
assurance proportioned to the mere mass of the experience on which they appear to rest; not
considering that by the addition of instances to instances, all of the same kind, that is, differing from
one another only in points already recognized as immaterial, nothing whatever is added to the
evidence of the conclusion. A single instance eliminating some antecedent which existed in all the
other cases is of more value than the greatest multitude of instances which are reckoned by their
number alone. It is necessary, no doubt, to assure ourselves, by repetition of the observation or
experiment, that no error has been committed concerning the individual facts observed; and until we
have assured ourselves of this, instead of varying the circumstances, we cannot too scrupulously
repeat the same experiment or observation without any change. But when once this assurance has
been obtained, the multiplication of instances which do not exclude any more circumstances is
entirely useless, provided there have been already enough to exclude the supposition of Plurality of
Causes.” (ibid., 287–8) Thus, Mill sees the primary role for the repetition of instances in checking
whether other combinations of circumstances are also able to produce a phenomenon. The rejection
of naïve enumerative induction is of course an important feature of variational induction as will be
further discussed in Chap. 6. In the above quote, Mill hints at another role for the repetition of
instances, namely to check whether a causal analysis is indeed correct, e.g. whether there are further
relevant circumstances that were so far ignored.
88
4
Variational Induction

effect according to the same laws to which it conforms in its separate state” (ibid.,
291). In such situations the intermixture is often so complicated that it becomes
impossible to inductively identify the inﬂuence of each individual circumstance.
Mill illustrates his discussion with an example from the medical sciences of his days
regarding whether mercury is able to cure certain diseases: “The mercury of our
experiment being tried with an unknown multitude (or even let it be a known
multitude) of other inﬂuencing circumstances, the mere fact of their being inﬂuenc-
ing circumstances implies that they disguise the effect of the mercury, and preclude
us from knowing whether it has any effect or not. [. . .] The Method of Difference, in
the ordinary mode of its use, namely, by comparing the state of things following the
experiment with the state which preceded it, is thus, in the case of intermixture of
effects, entirely unavailing; because other causes than that whose effect we are
seeking to determine have been operating during the transition.” (ibid., 297) Mill’s
exact line of argumentation on this issue remains somewhat unclear. At times, he
seems to imply that the inapplicability of his inductive framework is due to practical
limitations in the face of the complexity of many real world phenomena. But on
other occasions, Mill seems to suggest that it is a matter of principle.
With respect to the role that individual circumstances A play in full causes of the
form (A ˄ B) ˅ C, the ‘˅ C’-part addresses the plurality of causes, while the ‘˄
B’-part addresses the interference of causes. Mill believes that his framework is
mostly unable to deal with these issues which constitute “the principal part of the
complication and difﬁculty of the study of nature; and with which the four only
possible methods of directly inductive investigation by observation and experiment
are for the most part, as will appear presently, quite unequal to cope” (ibid.).
Remarkably, Mill adds that “[d]eduction alone is adequate to unravel the com-
plexities proceeding from this source; and the four methods have little more in their
power than to supply premises for, and a veriﬁcation of, our deductions” (ibid.).
Besides medicine, Mill names two other disciplines, politics and history, for which
he believes that his framework will generally fail and only the deductive method can
be applied—that method “which considers the causes separately, and infers the
effect from the balance of the different tendencies which produce it” (ibid., 299).
By contrast, I argue in this book that many successful data science algorithms rely on
variational induction and that data science holds promises in exactly those ﬁelds that
Mill wants to exclude from an inductive approach, in particular medicine and the
social sciences. Of course, Mill understandably could not foresee the enormous
calculating powers of modern computers and the interconnectedness of the internet.
Thus, in the historical context, his viewpoint is entirely reasonable.
In summary, Mill’s methods are plagued by substantial problems. They presup-
pose determinism, while modern scientists and epistemologists generally believe
that many phenomena are indeterministic. They seem to require extensive back-
ground knowledge in order for the methods to be at all applicable. In particular, a
conceptual framework has to be presupposed to adequately formulate the examined
circumstances and phenomena. Also, some of the possibly inﬁnite number of
potentially relevant circumstances must be known to be irrelevant. Finally, Mill’s
methods seem unable to deal with certain widespread causal structures, in particular
4.2
A Brief History of Variational Induction
89

the plurality and the composition of causes. Apparently, they are able to analyze only
situations where single circumstances are causes, which is in general an unrealistic
assumption. In view of these problems, it is not surprising that many consider Mill’s
methods to be merely heuristic tools rather than universal rules for induction. In the
remaining chapters of this book, an improved version of Mill’s inductive framework
will be developed that proposes solutions to all the above issues.
4.2.4
Twentieth Century Attempts to Solve These Problems
Strangely, in the course of the twentieth century many of the intellectual achieve-
ments of Bacon, Herschel, Mill, and others were mostly forgotten, and in both the
sciences and in epistemology, the inductive method was often identiﬁed with plain
enumerative induction leading to faulty regularity views concerning causation or
scientiﬁc laws and equally faulty frequentist approaches to probability.11 These
topics will be further addressed in the next chapters; here I brieﬂy discuss one and
pretty much the only effort in the twentieth century to improve on Mill’s version of
variational induction, which is in large parts due to Georg Henrik von Wright (1951)
and John Mackie (1980, appendix), but is later modiﬁed also by Brian Skyrms
(2000, Ch. 5).12
Von Wright must be credited with having introduced a number of fundamental
ideas. But Mackie’s account, drawing heavily on von Wright but also his own work
on causation, is in several ways more mature and conceptually clearer. Therefore, the
following discussion will focus on Mackie’s version, which appears as an appendix
to The Cement of the Universe, his seminal book on causation.13
Von Wright and Mackie suggest a novel systematization of variational induction,
which is substantially different from Mill’s four (or ﬁve) methods. In particular, they
11An example of the distorted view with which the achievements of these methodologists are
considered today, comes from the article on ‘Mill’ in the venerable Stanford Encyclopedia of
Philosophy: “All genuine inferential knowledge we have of the world, then, is justiﬁed by the use of
simple enumerative induction—this is ‘free-standing and the sole load-bearing structure in Mill’s
logic’ (Godden 2017: 175). The reasoning that takes place in our scientiﬁc engagement with the
world, Mill holds, is simply the application of a particularly reﬁned version of such enumerative
induction.” (Macleod 2017, Sec. 3.3) That is patently wrong given Mill’s outright criticism of
enumerative induction as discussed in Sect. 4.1. The importance of Mill’s methods for scientiﬁc
practice is generally underestimated, e.g. in the article on ‘scientiﬁc method’ of the Stanford
Encyclopedia: “Mill put forward speciﬁc methods for identifying causes—now commonly known
as Mill’s methods. These ﬁve methods look for circumstances which are common among the
phenomena of interest, those which are absent when the phenomena are, or those for which both
vary together. Mill’s methods are still seen as capturing basic intuitions about experimental methods
for ﬁnding the relevant explanatory factors.” (Andersen and Hepburn 2016, Ch. 2)
12Predecessors are Johnson and Broad.
13Mackie’s account also appeared as an entry on ‘Mill’s Methods of Induction’ in Paul Edward’s
Encyclopedia of Philosophy (1967).
90
4
Variational Induction

attempt to solve the problems of plurality of causes and of composition of causes by
delineating a range of methods tailored for speciﬁc types of causes. Unfortunately,
the resulting systematization turns out to be rather complex.
These accounts essentially interpret the cause of a phenomenon in terms of
conditions that are both necessary and sufﬁcient for that phenomenon. In everyday
parlance, conditions that are only necessary or conditions that are only sufﬁcient are
also sometimes referred to as causes. Usually, these notions are deﬁned on the basis
of the following equivalences: ‘A is a necessary condition of C’ is equivalent to
‘whenever C is present, A is present as well’; ‘A is a sufﬁcient condition of C’ is
equivalent to ‘whenever A is present, C is present as well’. Here, the letters ‘A’ and
‘C’ denote circumstances and phenomena, i.e. certain features or characteristics that
are present in speciﬁc instances. Note that if A is a necessary condition of C, then A
˅ B is also a necessary condition with a more or less arbitrary B. And if A is a
sufﬁcient condition of C, then A ˄ B is a sufﬁcient condition of C with a more or less
arbitrary B. Of course, in neither case B should be in any way causally relevant for
C. This problem is usually countered by requiring that causal factors are expressed in
terms of smallest sufﬁcient and smallest necessary conditions.
One of the advantages of Mackie’s account, in comparison with Mill’s and also
von Wright’s, is that he relativizes causal statements to a ﬁeld, i.e. a set of back-
ground conditions: “our question is, say, ‘What causes this disease in human beings
living in ordinary conditions, breathing air, and so on?’ or, ‘What causes the greater-
than ordinary hardness in iron in ordinary circumstances and at ordinary tempera-
tures?” (1980, 300). This move mitigates one of the objections discussed above that
it is widely implausible to list a full cause in terms of necessary and sufﬁcient
conditions for any real-world phenomenon.
As a next step in Mackie’s approach, prior assumptions about the causal structure
of the examined phenomenon have to be made.14 In particular, it has to be assumed
that some combination of the considered circumstances constitutes a necessary and
sufﬁcient condition for the phenomenon with respect to a ﬁeld. Furthermore, the
considered circumstances as well as the examined phenomenon must be sometimes
absent and sometimes present in the ﬁeld in order for the variational approach to
succeed. Finally, an assumption has to be made how complex the causal structure of
the examined phenomenon is. In particular, are only single circumstances candidates
for necessary and sufﬁcient conditions or are complex causes feasible, i.e. is plurality
and/or composition of causes possible? Mackie lists the following options which
each require slightly different methods of variational induction (ibid., 301–2):
1. the actual cause is one of the considered circumstances (this is the simplest case)
2. it is one of the circumstances or a negation of one
3. either a circumstance or a conjunction of circumstances
4. either a circumstance or a disjunction of circumstances
14The same assumptions have to be presupposed in von Wright’s and Skyrms’s accounts.
4.2
A Brief History of Variational Induction
91

5. a circumstance, or the negation of a circumstance, or a conjunction each of whose
members is a circumstance or the negation of a circumstance
6. a circumstance, or the negation of a circumstance, or a disjunction each of whose
members is a circumstance or the negation of a circumstance
7. a circumstance, or a conjunction of circumstances, or a disjunction each of whose
members is a circumstance or a conjunction of circumstances
8. a circumstance; or the negation of a circumstance; or a conjunction each of whose
members is a circumstance or the negation of one; or a disjunction each of whose
members is a circumstance, or the negation of one, or a conjunction each of
whose members is a circumstance or the negation of one (the most complex and
general case)
Mackie further distinguishes several methods of variational induction (ibid.):
1. A variant of the method of agreement
2. A variant of the method of difference
3. A variant of the joint method (interpreted as an ‘indirect method of difference’)
4. A new but related method
These two lists yield a two-dimensional system of different methods of varia-
tional induction, where the ﬁrst number designates the allowed complexity of
potential causes and the second number the type of method that is employed,
e.g. method of difference or agreement.
For example, the simplest variant of the method of difference (1.2) presupposes
that one of the considered circumstances is the actual cause, i.e. a necessary and
sufﬁcient condition, for the phenomenon with respect to a particular ﬁeld. For this
method, every circumstance can be eliminated as a potential cause that is (a) absent
when the phenomenon is present and/or (b) present when the phenomenon is absent.
These two criteria can be justiﬁed in terms of the above deﬁnitions of necessary and
sufﬁcient conditions. With respect to (a), a circumstance that is absent when the
phenomenon is present cannot be a necessary condition. And with respect to (b), a
circumstance that is present when the phenomenon is absent cannot be a sufﬁcient
condition. Thus, the actual cause must be present when the phenomenon is present,
and absent when the phenomenon is absent.
In the case (2.2), i.e. a more complex variant of the method of difference where
also negations of circumstances are considered as potential causes, the elimination
becomes more difﬁcult. To eliminate a circumstance from the list of potential causes,
there must be different instances for which (a) the circumstance is present both while
the phenomenon is present and while it is absent, and/or (b) the circumstance is
absent both while the phenomenon is present and while it is absent. Again, these two
rules for elimination can be justiﬁed from the assumption that a circumstance or its
negation only is a cause if that circumstance or its negation is a sufﬁcient and
necessary condition. The actual cause, therefore, must either (i) be present while
the phenomenon is present and absent while the phenomenon is absent or (ii) be
absent while the phenomenon is present and present while the phenomenon is
92
4
Variational Induction

absent. Obviously, these requirements (i) or (ii) for the actual cause are incompatible
with situations (a) and (b).
In the case (3.2), i.e. the method of difference where conjunctions of positive
circumstances are allowed (i.e. Mill’s intermixture of effects), one has to ﬁnd
circumstances which are necessary, but which may not be sufﬁcient by themselves
but only in conjunction. Consequently, the elimination becomes more difﬁcult. In
particular, a circumstance may be both present and absent while the phenomenon is
absent, but may nevertheless be part of the cause of the phenomenon. Of course, a
circumstance that is absent when the phenomenon is present cannot be a necessary
condition and thus can be ruled out as forming part of the cause. If conjunctions are
allowed, a successful realization of the method of difference, in general identiﬁes
only one causal factor. For this reason, Mill added the clause to his version of the
method of difference that a circumstance singled out by this method may not be the
full cause, but only “an indispensable part of the cause”.
For the most complex case, in which the most general type of causal conditions is
allowed (item 8 in the list above), Mackie states a new rule 8.4. This rule essentially
consists in observing all possible combinations of circumstances while keeping track
whether the phenomenon is present or not. The complete cause in terms of a
necessary and sufﬁcient condition then consists in the disjunction of those conjunc-
tions of circumstances or their negations under which the phenomenon is present.
Thus, if n circumstances are considered, 2n observations are required in order to
reliably determine the actual cause of the phenomenon. For example, if there are
only two circumstances and it is observed that the phenomenon is present in the
cases AØB as well as ØAB, but absent in the cases AB and ØAØB, then a necessary
and sufﬁcient condition for the phenomenon is AØB ˅ ØAB. Mackie stresses that
the ordinary method of difference allows to identify INUS-conditions even in the
most complex case, somewhat corroborating Mill’s claim that this method is the
most powerful in variational induction.
Apparently, the identiﬁcation of causes becomes increasingly difﬁcult when the
assumptions about which causal structures to expect among the circumstances
become less and less rigorous. Mackie concludes:
while we must recognize very different variants of these methods according to the different
kinds of assumptions used, and while the reasoning which validates the simplest variants
fails when it is allowed that the actual cause may be constituted by negations, conjunctions
and disjunctions of [circumstances] combined in various ways, nevertheless there are valid
demonstrative methods which use even the least rigorous kind of assumption, that is, which
assume only that there is some necessary and sufﬁcient condition for [the phenomenon] P in
[background] F, made up in some way from a certain restricted set of [circumstances]. But
with an assumption of this kind we must be content either to extract [. . .] a very incomplete
conclusion from the classic difference observation or to get more complete conclusions [. . .]
only from a large number of diverse instances in which the [circumstances] are present or
absent in systematically varied ways. (309–310)
In principle, Mackie’s account solves the problems of plurality and composition
of causes by stating explicit rules regarding the kind of evidence that is required to
4.2
A Brief History of Variational Induction
93

draw causal inferences in such situations. Thus, his account (or similarly that of von
Wright) certainly constitutes an improvement in comparison with Mill’s framework.
A drawback is that Mackie offers a confusing variety of different methods in
order to tackle these problems. All in all, there are several dozens of distinct
methods, the exact relation between which remains somewhat unclear. For example,
Mackie explicitly categorizes the most powerful method (8.4), which we just
discussed, as a method that is substantially different from the methods of difference
and of agreement, which in particular undermines the central role for the method of
difference in variational induction as ascribed to it by many authors. Furthermore,
scientists do not seem to choose between the various methods as prescribed by
Mackie’s approach when carrying out variational induction. They generally make no
assumptions about the logical structure of the underlying phenomena, e.g. whether
they allow for conjunctions of circumstances or not.
Furthermore, the methods still require substantial background knowledge. As
Brian Skyrms remarks in a related context: “The conclusions we drew [. . .] always
began with phrases such as ‘If one of the possible conditioning properties is a
necessary condition for E . . .,’ or ‘If one of the possible conditioning properties
which is present in [a speciﬁc] occurrence is a sufﬁcient condition for E . . .,’ and so
on. It would seem that our conﬁdence that Mill’s methods have found a necessary
condition, or a sufﬁcient condition, or a necessary and sufﬁcient condition depends
on our conﬁdence that the list of possible conditioning properties contains the
requisite kind of condition. But how can we be sure that this list does contain the
type of condition being sought?” (2000, 94) Relatedly, Whewell’s question remains
how to formulate the correct categories in which to express circumstances and
phenomena. Certainly, many artiﬁcial categories like Goodman’s ‘grue’ would
lead to wrong conclusions (cp. Chap. 7). Skyrms also emphasizes this problem:
“In the search for necessary and sufﬁcient conditions, Mill’s methods are part of the
picture, but they are not the whole picture. The most basic, and least understood, part
of the process is the setting up of lists of possible conditioning properties.” (Skyrms
2000, 95)
It is in general implausible to assume that among the considered circumstances a
necessary and sufﬁcient condition exists in terms of the disjunction of conjunctions
of circumstances. For example, sufﬁciency will require the absence of an inﬁnite
number of possibly interfering circumstances. No meteors, no aliens, no magic, etc.
A possible solution lies in relativizing causal relationships to a ﬁeld which summa-
rizes such background-conditions. But the ﬁeld must be chosen in a way such that
changes in background conditions have no inﬂuence on the phenomenon. Mackie
fails to provide a criterion, which ﬁelds are adequate for variational induction and
which are not. Natural choices will not do, e.g. the requirement that INUS-conditions
in the ﬁeld may not change would be much too strong. Thus, Mackie fails to
integrate the ﬁeld-concept convincingly into his account of variational induction.
One could call this the problem of the ﬁeld.
Relatedly, the ﬁeld concept in Mackie’s account of variational induction is much
too static, it lacks the dynamic nature that background conditions exhibit in many
empirical investigations. For instance, Mackie mentions as examples of a ﬁeld
94
4
Variational Induction

(as quoted above): “human beings living in ordinary conditions, breathing air, and so
on” or “iron in ordinary circumstances and at ordinary temperatures” (1980, 300).
Once ﬁxed, the researcher seems stuck with her choice. But in scientiﬁc practice, it
often happens that background conditions which were long neglected suddenly
move into the focus as important causal factors. Also, a typical question is whether
a causal relationship that was established for a certain ﬁeld is also valid beyond that
context. Mackie’s account of variational induction lacks a mechanism how the ﬁeld
can be extended or narrowed down.
All those challenges will be addressed in the following chapters. One important
key to tackling these problems will be a change in perspective from seeing sufﬁcient
and necessary conditions as fundamental to formulating variational induction on the
basis of relevant and irrelevant conditions.
4.3
Variational Induction in Machine Learning Algorithms
While elements of both enumerative and eliminative induction may occasionally
play a role, machine learning algorithms generally rely on a logic of variational
induction and in particular of difference making. Indeed, many machine learning
algorithms try to determine in one way or other which variables make the largest
difference to achieving a correct classiﬁcation of the data. In so-called supervised
machine learning, a training data set is employed to develop an inferential model.
Such a training set usually captures the impact that different variations of circum-
stances have on the response variable, which is to be predicted. A test data set is then
used to evaluate the accuracy of the inferential model.
In Sect. 3.5, we argued that difference making is crucial in neural networks. In the
following, the same will be shown for further types of algorithms in machine
learning, namely decision trees and naïve Bayes. Let me add that the overall number
of fundamental algorithm types in machine learning is surprisingly small. In a way,
the argument of this book further uniﬁes these different algorithms by claiming that
variational induction forms the logical core of all these machine learning algorithms.
That variational induction is crucial for machine learning is also corroborated by
the type of evidence that is commonly employed, which tracks the impact of
variations in predictor variables on a response variable. For example, an algorithm
for spam detection is usually trained by a set of emails classiﬁed as either spam or not
(the binary response variable) on the basis of whether certain words appear in the
subject and body of the email (the predictor variables). When a user keeps moving
emails to and from the spam folder the algorithm will learn further examples with
which the classiﬁcation can be improved. A large variety of examples is crucial as it
will allow to identify relevant predictor variables on the basis of difference making,
i.e. variational induction. By contrast, evidence in terms of mere regularities as
required for enumerative induction plays only a marginal role. For example, if the
user keeps receiving the same spam email again and again, mostly this will not
further contribute to an effective training of the algorithm.
4.3
Variational Induction in Machine Learning Algorithms
95

4.3.1
Decision Trees15
Decision trees are among the “simplest and yet most successful forms of machine
learning” (2009, 697), as Stuart Russell and Peter Norvig write in the leading
modern textbook on artiﬁcial intelligence: “In many areas of industry and commerce,
decision trees are usually the ﬁrst method tried when a classiﬁcation method is to be
extracted from a data set. One important property of decision trees is that it is
possible for a human to understand the reason for the output of the learning
algorithm. (Indeed, this is a legal requirement for ﬁnancial decisions that are subject
to anti-discrimination laws.) This is a property not shared by some other represen-
tations, such as neural networks.” (ibid., 707) Decision trees were developed and
made popular among others by the very Leo Breiman, who introduced the distinction
between data and algorithmic modeling as discussed in Sect. 2.4 (Breiman 2001).
Like most machine learning algorithms, decision trees can be considered as
complex functions mapping several input variables on an outcome variable (which
constitutes the ‘decision’). Decision trees employ what is in the machine learning
literature called a “greedy divide-and-conquer” strategy. According to this strategy,
it is ﬁrst determined which variable “makes the most difference to the classiﬁcation
of the example” (Russell and Norvig 2009, 700; my emphasis). Depending on the
value of that variable, several subproblems result, for which again the variable
among the remaining ones is sought which makes the most difference, etc. (ibid.,
700). Thus, the decision process proceeds on a tree-like graph, where different
branches are selected depending on the values of the variables, which constitute
the nodes of the graph. Each of these branches terminates with a leaf, which
ultimately ﬁxes the value of the outcome variable. As an example of a decision
tree, Norvig and Russell discuss the deliberation process whether one should wait at
a restaurant or not depending on variables such as the number of patrons currently in
the restaurant, whether one is hungry, or whether it is weekend (ibid., 702).
The variable that makes the most difference is the variable which conveys the
most information that is relevant for the classiﬁcation. Information can be measured
in terms of the Shannon entropy, which according to information theory describes
the uncertainty of a random variable. More exactly, the algorithm proceeds as
follows for a classiﬁcation problem with respect to an outcome variable A which
can take on the values a1, . . ., an. Given that these values appear with relative
frequencies p(a1), . . ., p(an) in the training set, the Shannon entropy is then calculated
as H A
ð Þ ¼ P
i
p ai
ð Þ log 2p ai
ð Þ. The Shannon entropy is maximal, when all out-
comes are equally likely, and minimal in the case of perfect classiﬁcation, i.e. if the
probability of a single ax equals one, and the probabilities for all other a’s are zero. In
the example, the outcome variable A is binary regarding whether one decides to wait
at the restaurant or not.
15The exposition in this section is based on sect. 4.2.2 of Pietsch (2021).
96
4
Variational Induction

One can then introduce a classiﬁcation taking into account a variable CX with
possible values x1, . . ., xk. In the example, CX could be the number of patrons at the
restaurant or whether it is weekend. Again, the p(xj) and p(ai | xj) can be determined
on the basis of relative frequencies in the training set. Accordingly, a conditional
Shannon
entropy
can
be
calculated:
H AjCX
ð
Þ ¼ P
j
p x j


H AjCX ¼ x j


¼
P
j
p x j

P
i
p aijx j


log 2p aijx j


. The so-called information gain is deﬁned as H
(A) – H(A|CX). It is always positive or zero and quantiﬁes the improvement of the
classiﬁcation A|CX with respect to just A. The information gain is maximal, namely
H(A), for a perfect classiﬁcation, i.e. a classiﬁcation where all p(ai | xj) are either 1 or
0. In this way, the CX can be determined that exhibits the largest information gain of
all C, resulting in a number of subtrees corresponding to the different values of the
parameter CX. The whole procedure is then repeated for every subtree.
In the case of a perfect classiﬁcation, the algorithm yields an expression of
necessary and sufﬁcient conditions for each value of A: e.g. iff (C1 ¼ y1 ˄
C2 ¼ y2) ˅ (C1 ¼ y3 ˄ C3 ¼ y4), then A ¼ a1. Thus, if a full set of relevant
conditions is among the parameters C and if there is enough data in terms of variation
of parameters to exclude accidental correlations, then the algorithm will identify the
actual INUS conditions—possibly with some redundancies, but redundant variables
can usually be identiﬁed and eliminated. In the expression above, C1 ¼ y1, C2 ¼ y2,
C1 ¼ y3, and C3 ¼ y4 are all INUS-conditions for A ¼ a1. An algorithm yields fairly
reliable predictions, whenever it manages to at least approximate some necessary
and sufﬁcient conditions for the phenomenon.
There are various ways in which the evidence may not be ideal. For example, we
may lack information in terms of speciﬁc conﬁgurations or a causally relevant
variable may be absent from the examined variables C. Furthermore, it may be the
case that some variables are only proxies of the actual causally relevant variables,
which may be unknown. A proxy here is understood as a condition that is causally
related to the actual cause, but need not always co-occur with it. If the probability of
co-occurrence is large then the classiﬁcation tree will yield decent results on the basis
of proxies. Broadly speaking, decision trees can be understood as a heuristic
implementation of variational induction, in particular the method of difference, for
situations of incomplete evidence.
Finally, let me emphasize that decision trees as well as so-called random forests
combining several decision trees in a single model require evidence in terms of
variable variation rather than regularities. For example, if there are three parameters
C1, C2, and C3 with C2 being the actual cause of A, it sufﬁces to know one instance
for all possible combinations of C1, C2, C3 in order to identify C2 as the cause both
according to variational induction and also according to the decision tree algorithm
as presented above. Further knowledge of identical instances, i.e. evidence in terms
of regularities, is completely redundant.
4.3
Variational Induction in Machine Learning Algorithms
97

4.3.2
Naïve Bayes
In a similar manner, naïve-Bayes classiﬁcation can be interpreted in terms of
difference making and variational induction, although the connection is a little less
obvious. This very simple algorithm is also widely used, for example in the
identiﬁcation of spam emails as discussed at the beginning of the section. The
problem structure is the same as in the case of decision trees. A number of variables
C1, . . ., CN, representing for example certain words or sequences of words appearing
in emails, is used to determine the probability that a speciﬁc instance has a certain
property A or not, e.g. that an email is spam or not. The algorithm uses a modiﬁca-
tion of Bayes’ Theorem:
P AjC1, . . . , CN
ð
Þ ¼ P A
ð ÞP C1, . . . , CNjA
ð
Þ
P C1, . . . , CN
ð
Þ
The ‘naïve’ part of the algorithm is that the variables Ci are assumed to be
independent given A, i.e. P(C1, . . ., CN|A) ¼ Πi ¼ 1,. . .,N P(Ci|A), which of course
may not be the case. Thus, the naïve Bayes formula reads:
P AjC1, . . . , CN
ð
Þ ¼
P A
ð Þ
Q
i¼1, ..., N
P CijA
ð
Þ
P C1, . . . , CN
ð
Þ
As with decision trees, a training data set is employed to develop the model. It
provides representative frequencies for joint occurrences of A and the different Ci
and thereby the probabilities P(Ci|A), P(A), and P(C1, . . ., CN). The model allows
classifying new instances given certain values Ci. It can be validated using a set of
test instances.
For a Bayesian approach without the naïve independence assumption, it can be
proven that a correct classiﬁcation results both when a sufﬁcient condition is present
as well as when a necessary condition is absent. In contrast to decision trees, the
Bayesian approach does not explicitly identify causal factors, but if they are present
in terms of INUS-conditions, novel instances will be correctly classiﬁed.
Complications arise if not all causally relevant factors are known or if only
proxies of the actual factors are available. Furthermore, the independence assump-
tion of the naïve-Bayes approach strongly simpliﬁes calculations but is not always
compatible with an INUS perspective. For example, if (C1˄C2)˅C3 is the complete
cause for A, the independence assumption will in general not hold, since e.g. there is
no reason to assume P(C1˄C2˄ØC3|A) ¼ P(C1|A) P(C2|A) P(ØC3|A).
Nevertheless, difference-makers C among the predictor variables will decisively
inﬂuence the classiﬁcation as they correlate substantially with the phenomenon A,
i.e. mostly P(C|A)>>P(C|ØA)—even if C is not sufﬁcient, but only a necessary
condition for A. By contrast, if C is causally unrelated to A, then we can plausibly
assume that A and C are independent P(C|A)P(C|ØA)P(C). Thus, there is a good
98
4
Variational Induction

chance that the outcome of the naïve-Bayes algorithm is determined by the most
important difference-makers or appropriate proxies and thus for many instances a
correct classiﬁcation will result.
Since the naïve-Bayes approach does not explicitly identify relevant variables, it
is often combined with a separate procedure of feature selection. For this purpose, a
considerable number of different approaches exist and many of them at least
implicitly rely on difference-making (e.g. Guyon and Elisseeff 2003). One important
example is variable ranking, in which potential predictor variables are ranked
according to a speciﬁc measure and then a threshold is introduced up to which
value of the measure the variables are taken into account. A typical measure is
‘mutual information’ which corresponds to the information gain discussed before,
i.e. at least in this case the ranking again relies on the amount of difference-making
by the various variables.
Variational induction thus provides a fruitful perspective on the methodological
analysis of the naïve-Bayes algorithm that can lead to a better understanding under
which circumstances the algorithm will actually be successful.
As a further example, non-parametric regression, as introduced in Sect. 2.4, relies
on variational induction. The causal nature of the resulting curve can be justiﬁed in
terms of the method of concomitant variations which in turn derives its inferential
power from the method of difference (cf. Sect. 5.3.4). Finally, in the previous chapter
we had seen that neural networks rely on difference making in order to determine the
model parameters.
Due to the imperfections of the various machine learning algorithms in compar-
ison with strict variational induction as presented in the following chapters, ensem-
ble methods combining several contradictory models have proven quite successful
as they often seem to level out mistakes or problems of the individual models. A
classic ensemble approach is using so-called random forests which combine a
usually large number of decision trees.
In summary, while machine learning algorithms are less rigorous than pure
variational induction, many of them can be considered as heuristic implementations
for situations with less-than-ideal evidence. They are optimized for computational
feasibility and stand a good chance to yield useful approximations of some causal
story behind a phenomenon. To some extent, it remains a challenge for contempo-
rary statistics to work out the mathematical details, under which premises these
methods are successful. In general, including more variables C will increase the
probability that the actual cause of A might be among them, while admittedly also
increasing the probability for accidental correlations, i.e. that conditions produce the
correct classiﬁcation merely by chance. However, more data in terms of variations of
instances can reduce the probability for such accidental correlations. Thus, more data
in terms of variables and instances will generally increase the probability that correct
causal relations are identiﬁed by machine learning algorithms.
4.3
Variational Induction in Machine Learning Algorithms
99

4.4
Solomonoff Induction
For those computer scientists interested in the foundations of artiﬁcial intelligence,
rather than merely focusing on applications, i.e. those who are interested in the
epistemological questions that are raised in this book, Ray Solomonoff is a central
ﬁgure. Solomonoff studied in Chicago and attended lectures by philosopher Rudolf
Carnap, whose lifelong project was a theory of inductive logic. Solomonoff himself
developed a ‘General Theory of Inductive Inference’ (1964a, b), which takes cues
from Carnap’s work and in the opinion of some scholars provides the epistemolog-
ical framework behind modern machine learning. Solomonoff is also known as (one
of) the inventors of algorithmic complexity, anticipating many of Kolmogorov’s
central ideas. He was one of about 20 attendees of the legendary Dartmouth Summer
Research Project on Artiﬁcial Intelligence at Dartmouth College in Hanover, New
Hampshire, in 1956, which included some of the deﬁning ﬁgures in the ﬁeld,
e.g. Marvin Minsky, who wrote the book Perceptron which we brieﬂy discussed
in Sect. 3.5, Herbert Simon, the later economics Nobel Prize laureate, Claude
Shannon, the founder of modern information theory, and Warren McCulloch, who
together with Walter Pitts created one of the ﬁrst computational models of the
neuron. Already the fact that Solomonoff witnessed this birth moment of modern
artiﬁcial intelligence renders him a highly inﬂuential ﬁgure in the ﬁeld of computer
science, even though not everyone shares his interest in foundations.
Excellent discussions of Solomonoff’s approach can be found elsewhere
(e.g. Rathmanner and Hutter 2011). Very recently, his theory has also caught the
attention of philosophers of science (Sterkenburg 2016, forthcoming). Tom
Sterkenburg summarizes the relevance of Solomonoff’s theory from a philosophical
viewpoint:
Not only can the theory be seen as the progenitor to multiple successful modern approaches
in statistics and machine learning, including universal prediction or prediction with expert
advice [. . .] and the principle of minimum description length [. . .]; the theory itself origi-
nated as a branch of a major philosophical project—namely, Carnap’s early programme of
inductive logic, pursued with tools from information theory and computability theory. In this
capacity the theory brings together a diverse range of motifs from the philosophy of
induction, that in turn connect the theory to several other approaches: among those we
ﬁnd formal learning theory [. . .], that likewise puts effectiveness centre stage, and the project
of meta-induction [. . .], the philosophical counterpart to prediction with expert advice.
(2016, 459)
I refrain from a detailed analysis of Solomonoff’s General Theory and instead
want to raise a fundamental criticism that concerns the framing of his approach.
Solomonoff’s perspective very much stems from enumerative induction rather than
the variational induction that we identiﬁed in this chapter as basis of successful AI
algorithms. This renders Solomonoff induction a poor candidate for providing an
epistemological footing of modern machine learning.
Solomonoff sets up the nature of the problem as follows:
The problem dealt with will be the extrapolation of a long sequence of symbols—these
symbols being drawn from some ﬁnite alphabet. More speciﬁcally, given a long sequence,
100
4
Variational Induction

represented by T, what is the probability that it will be followed by the sequence represented
by a? In the language of Carnap [. . .], we want c(a, T), the degree of conﬁrmation of the
hypothesis that a will follow, given the evidence that T has just occurred. [. . .] In all cases
being considered, the known sequence of symbols is very long, and contains all of the
information that is to be used in the extrapolation. (1964a, 2)
Exclusively looking at long sequences of events and analyzing how often certain
types of events reoccur, of course, is the starting point of enumerative induction.
Variational induction, by contrast, is characterized by examining in much detail the
circumstances under which certain types of events occur. In variational induction, a
sequence of symbols representing the considered events decidedly does not contain
all of the information that should be used for extrapolation—in contrast to
Solomonoff’s claims above. Furthermore, the sequence of symbols does not even
have to be particularly long. As we have seen, in ideal situations two instances can be
sufﬁcient to establish a causal relationship according to variational induction, i.e. by
the method of difference.
The applications that Solomonoff discusses in the second part of his paper
(1964b) only underline this analysis. For example, he examines how to extrapolate
Bernoulli sequences, i.e. sequences of binary random variables. Solomonoff ﬁnds
that the predictions according to his framework are “identical to those given by
‘Laplace’s Rule of Succession’” (224). This rule states that if a certain event has been
observed n times in (n + m) instances then the probability that the event will occur in
the next instance is (n + 1)/(n + m + 2). Clearly, Laplace’s rule of succession also
stands in the tradition of enumerative induction and does not ﬁt easily with varia-
tional induction since it focuses on the number of events rather than the variation of
circumstances.
Solomonoff hypothesizes that the extrapolation of sequences underlies any
inductive inference: “The author [i.e. Solomonoff] feels that all problems in induc-
tive inference, whether they involve continuous or discrete data, or both, can be
expressed in the form of the extrapolation of a long sequence of symbols.” (1964a, 2)
In a much latter paper, he introduces a distinction between two types of problems in
probabilistic induction: (i) the ﬁrst deals with the kind of linearly ordered sequences
of symbols that we just discussed; (ii) the second wants to extrapolate unordered sets
of ﬁnite strings (1999).
Solomonoff frames the second type in the following terms: “we have as data, a set
of pairs of numbers [xi; yi]. Given a new xj, what is the probability distribution over
all possible values of yj?” (1999, 257) As an example, he mentions the question
whether a mushroom is poisonous or not “given a vector of properties associated
with each of a set of mushrooms” (ibid.). As we have seen, this second type is
characteristic of many problems in machine learning. It is also the typical framing of
an inductive problem according to variational induction. However, Solomonoff
essentially attempts to treat this second class of inductive problems by generalizing
his earlier framework of sequential extrapolation, i.e. enumerative induction. Thus,
he does not recognize the fundamental divide between both approaches to induction.
4.4
Solomonoff Induction
101

In particular, Solomonoff’s framework does not convincingly integrate the basic
methods of variational induction such as the method of difference.16
Given that Solomonoff was much inﬂuenced by Carnap’s inductive logic, it
should not come as a surprise that Carnap’s approach suffers from the same problem,
as will be discussed extensively in Sect. 8.2.1. Thus, Carnap’s approach to induction,
just like Solomonoff’s, is doomed from the very beginning because it is framed in
terms of enumerative induction rather than variational induction. As we will see,
Carnap relies on a generalization of the straight rule of induction as the fundamental
building block of his theory, where the straight rule basically corresponds to
Laplace’s rule of succession. The straight rule deals with sequences of events
focusing on the number of events just as in enumerative induction rather than on
systematic changes in circumstances as in variational induction.
4.5
Computational Learning Theory
Computational Learning Theory is based in statistics and computer science and aims
to provide a general theoretical framework for learning patterns or rules from data.
The approach does not primarily analyze speciﬁc algorithms in machine learning or
statistics, but attempts to formulate general criteria and principles regarding under
which circumstances algorithms are successful or fail. Computational Learning
Theory addresses fundamental questions such as: How can one learn concepts
from samples? Can a concept be learned in polynomial time? How many examples
are needed to reliably learn a concept? How can we be sure that an adopted
hypothesis will yield correct predictions for unknown instances? Which hypothesis
space should be used? Should a simple hypothesis be preferred over more
complex ones?
The standard model of learning in Computational Learning Theory is Probably
Approximately Correct Learning (PAC Learning), the origin of which is usually
traced back to a 1984 paper entitled “A theory of the learnable” by Turing Award
Winner Leslie Valiant.17 The fundamental idea of PAC Learning is already
contained in its name. The framework attempts to provide criteria, when it is possible
to learn from data a model or hypothesis that has a high probability of being
approximately correct, i.e. with high probability deviates from the real relationship
in only a small fraction of instances. According to Valiant, requiring high probability
takes into account so-called “misfortune errors”, while approximate correctness
allows for “rarity errors” (2013, 71).
16Solomonoff (2008) still further generalizes his approach of sequential extrapolation, introducing
three kinds of probabilistic induction. However, the basic assessment given above remains the same
also with respect to this additional distinction.
17Valiant gives a popular science introduction to his approach in his 2013 book Probably Approx-
imately Correct.
102
4
Variational Induction

The basic approach of PAC learning usually includes a set of all possible
examples or instances corresponding to an input space and further a set of all
possible labels corresponding to different target values. Concepts are mappings
from input space to target values. If the target variable is binary, i.e. allows only
for values 0 or 1, a concept could be deﬁned by a subset of the input space, which
implies value 1 for the target variable. For example, the concept may be determined
by all points inside a speciﬁc triangle. A concept class C then is a set of concepts,
e.g. the set of all triangles in a plane. Concept learning presupposes that examples are
drawn, which are assumed to be independently and identically distributed according
to an unknown probability distribution D. A learner, which may be a person or an
algorithm, starts from a certain hypothesis set H, which may but need not correspond
to the concept class. The task of the learner is to select, based on the drawn examples,
a speciﬁc hypothesis h from H, which has a small generalization error with respect to
the actual concept underlying the examined phenomenon. The error is deﬁned as the
probability that the selected hypothesis and the actual concept disagree on an
instance drawn randomly according to the probability distribution D (the above
exposition largely follows Mohri et al. 2018, Sec. 2.1; Haussler 1996, Sec. 1.2).
Based on this conceptual framing, learnability can be deﬁned as follows: A
concept class C is PAC-learnable by a hypothesis space H if there exists a polyno-
mial time learning algorithm A and a polynomial function p(,,,) such that for all
target concepts c in the concept class, for all probability distributions D, and for any
error threshold ε and any probability threshold δ, if the algorithm A is given at least p
(n, size(c), 1/ε, 1/δ) independent random examples of the target concept drawn
according to D, then with probability at least 1- δ, algorithm A returns a hypothesis
h of the hypothesis space, which has an error smaller or equal ε. Polynomial time
here is supposed to guarantee the computational efﬁciency of such an algorithm. If
an algorithm runs in polynomial time p(n, size(c), 1/ε, 1/δ), the concept class is
sometimes called efﬁciently PAC-learnable (e.g. Haussler 1996, Sec. 1.2; Mohri
et al. 2018, Ch. 2).
According to a typical estimation, the required number of examples m or
so-called sample complexity is bound by the following limit: m  (ln |H| – ln δ) /
ε. In other words, if a learning algorithm based on m examples returns a hypothesis
of a hypothesis space of ﬁnite cardinality or size |H|, then the hypothesis with at least
probability 1-δ has an error equal or smaller than ε, i.e. is approximately correct. This
result follows from basic statistical considerations, with which probability a seri-
ously wrong hypothesis may still yield consistent results for m examples. Essen-
tially, if a hypothesis yields correct predictions over a sufﬁcient number of instances,
such a hypothesis is unlikely to be seriously wrong. Obviously, some kind of
stationarity has to be presupposed that future examples are drawn from the same
distribution as past examples (Russell and Norvig 2009, 714–715; Haussler 1996,
Sec. 1.4; Valiant 2013, Sec. 5.2).
The above estimation can be used to illustrate a venerable principle of scientiﬁc
methodology, so-called Occam’s razor dating back to the medieval philosopher
William of Ockham. According to Ockham, entities should not be multiplied
without necessity or as it is often understood today, simple hypotheses should be
4.5
Computational Learning Theory
103

preferred over complex ones, when they are equally consistent with the data. The
above-described bound for sample complexity illustrates this principle quite ade-
quately. After all, it follows from the above estimation that for smaller sizes |H| of the
hypothesis space, i.e. a hypothesis space consisting of a smaller number of simpler
hypotheses, the number m of required examples will also be smaller. Of course, this
presupposes that a consistent or at least sufﬁciently correct hypothesis h is included
in the hypothesis space in the ﬁrst place. Note that this application of Ockham’s razor
bears considerable similarity to Karl Popper’s observation that in a hypothetico-
deductive approach simpler hypotheses are more easily falsiﬁed (cp. Valiant 2013,
Sec. 5.7; Russell and Norvig 2009, 696; see also Sect. 2.1).
One shortcoming of the standard PAC learning approach is that it does not apply
to continuous function classes, where |H| is inﬁnite. This problem has been over-
come by introducing the so-called VC-dimension, termed after its inventors Vladi-
mir Vapnik and Alexey Chervonenki, who are both among the most important
contributors to computational learning theory. Essentially, ﬁniteness of the
VC-dimension determines the learnability of concepts in this extension of Valiant’s
learnability model (Blumer et al. 1989; Russell and Norvig 2009, 759).
Some of the most important results in PAC learning theory spell out which
speciﬁc classes of functions are PAC-learnable or are not PAC-learnable. For
example, it has been proven that the classes of k-disjunctive normal forms are
PAC-learnable for each ﬁxed k (Valiant 1985; Haussler 1996, Sec. 1.3). Here,
k-disjunctive normal forms are essentially disjunctions of conjunctions, where
each conjunction comprises at most k literals. For example, (A1 ˅ ØA2) ˄ (A1 ˅
ØA3) ˄ A4 is a 2-disjunctive normal form. Note that these forms are quite similar to
the inus-complexes discussed as general expressions for causes in Chap. 5 in the
context of the difference making account of causation.
Thus, PAC learning bears some similarity with the epistemological framework
developed in this book. Certainly, a more detailed analysis of PAC learning could be
fruitful. However, there are two reasons, which in my view justify why at this point
we do not have to delve deeper into the PAC approach.
First, PAC learning attempts to provide a mathematical model for the inductive
process, i.e. a formal framework, which is suitable to derive rigorous mathematical
results. By contrast, the present book attempts to motivate, based on epistemological
arguments, a conceptual framework that is useful for framing induction. Whereas
computational learning theory approaches the problem of inductively learning about
the world from the perspective of statistics and computational science, the present
book approaches inductive inference from an epistemological perspective based on
debates and results from epistemology and philosophy of science. In this book, we
are less concerned with mathematical results and formalizations and more with
concept development of central notions like causation or induction itself. Such
concept development is based on informal arguments often rooted in common
experience and everyday language. It cannot as such be formalized, but naturally
has to precede any rigorous formalization. Only once a coherent conceptual frame-
work is in place can a formal mathematized approach be developed based on the
conceptual framework. Thus, the investigation in this book in a way precedes an
104
4
Variational Induction

approach like PAC learning which in general does not problematize its explicit or
implicit inherent epistemological assumptions, e.g. regarding the role of hypotheses,
the notion of simplicity etc.
Second, PAC learning differs substantially in its fundamental epistemological
assumptions from the approach of the present book. In particular, PAC learning
implements several elements of hypothesis-driven approaches, while the framework
developed here attempts as purely an inductivist approach as possible. For example,
PAC Learning presupposes a hypothesis space, a notion that sits awkwardly with
inductivism, which aims to eliminate hypotheses from the scientiﬁc process as much
as possible. Similarly, Occam’s razor prescribing to prefer the simplest hypothesis is
clearly an element of hypothesis-driven, but not of inductivist approaches. In a
purely inductivist framework, one should not have to choose between alternative
hypotheses of different complexity, since phenomenological laws are quasi-
mechanically derived from the data. As a result, at least parts of the PAC learning
framework ﬁt better with eliminative induction than with variational induction, since
eliminative induction also works from the notion of a hypothesis space and the
fundamental assumption that a correct hypothesis is included in the hypothesis
space.
Furthermore, while the epistemological framework of the present book based on
variational induction and the difference making account of causation can be gener-
alized to probabilistic settings, it is at heart a deterministic approach. By contrast,
PAC learning theory is fundamentally probabilistic. Being deterministic, the
approach of this book does not necessarily require a probability distribution D
over the sample space. But without such a probability distribution, the probability
of a generalization error cannot be derived, which as we have seen presupposes a
probability distribution over the sample space. Therefore, for some applications of
the framework of this book, the notion of ‘probably approximately correct’ cannot
even be deﬁned.
Computational Learning Theory and in particular PAC Learning provide a rich
framework for analyzing machine learning and we cannot do full justice to the
framework here. To avoid any misunderstandings, PAC Learning is not in any way
wrong or misguided, but the approach of this book chooses to start from different
epistemological assumptions, namely those of variational induction, to understand
the inner workings of machine learning. Because the fundamental epistemological
assumptions differ, the results of PAC Learning will not be transferrable to the
approach of this book, at least not in a straight-forward manner. In the end, these
views could be complementary providing different perspectives with which to view
the world of machine learning and statistics, one implementing at least to some
extent a hypothesis-driven approach, the other, as developed in this book, attempting
a purely inductivist approach.
4.5
Computational Learning Theory
105

References
Andersen, Hanne and Brian Hepburn. 2016. Scientiﬁc Method. In The Stanford Encyclopedia of
Philosophy (Summer 2016 Edition). http://plato.stanford.edu/archives/sum2016/entries/scien
tiﬁc-method/
Bacon, Francis. 1620/1994. Novum Organum. Chicago: Open Court.
Bird, Alexander. 2010. Eliminative Abduction: Examples from Medicine. Studies in History and
Philosophy of Science Part A 41 (4): 345–352.
Blumer, A., A. Ehrenfeucht, D. Haussler, and M.K. Warmuth. 1989. Learnability and the Vapnik–
Chervonenkis Dimension. Journal of the ACM 36 (4): 929–865.
Breiman, Leo. 2001. Statistical Modeling: The Two Cultures. Statistical Science 16 (3): 199–231.
Darwin, Charles. 1861. On the Origin of Species. New York: D. Appleton and Company.
Godden, D. 2017. Mill on Logic. In A Companion to John Stuart Mill, ed. C. Macleod and
D. Miller, 175–191. Oxford: Wiley-Blackwell.
Guyon, Isabelle, and André Elisseeff. 2003. An Introduction to Variable and Feature Selection.
Journal of Machine Learning Research 3 (2003): 1157–1182.
Haussler, David. 1996. Chapter 18: Probably Approximately Correct Learning and Decision-
Theoretic Generalizations. In Mathematical Perspectives on Neural Networks, ed. Paul
Smolensky, Michael C. Mozer, and David E. Rumelhart. Mahwah: Lawrence Erlbaum
Associates.
Hempel, Carl G. 1966. Philosophy of Natural Science. Upper Saddly River: Prentice Hall.
Herschel, John F.W. 1851. Preliminary Discourse on the Study of Natural Philosophy. London:
Longman, Brown, Green & Longmans.
Kelly, Thomas. 2010. Hume, Norton, and Induction Without Rules. Philosophy of Science 77:
754–764.
Keynes, John M. 1921. A Treatise on Probability. London: Macmillan.
Lipton, Peter. 2004. Inference to the Best Explanation. London: Routledge.
Losee, John. 2001. A Historical Introduction to the Philosophy of Science. Oxford: Oxford
University Press.
Mackie, John L. 1967. Mill’s Methods of Induction. In The Encyclopedia of Philosophy, ed. Paul
Edward, vol. 5, 324–332. New York: Macmillan.
———. 1980. The Cement of the Universe. Oxford: Clarendon Press.
Macleod, Christopher. 2017. John Stuart Mill. In The Stanford Encyclopedia of Philosophy (Spring
2017 Edition). https://plato.stanford.edu/archives/spr2017/entries/mill/
Mill, John S. 1886. System of Logic. London: Longmans, Green & Co.
Mohri, Mehryar, Afshin Rostamizadeh, and Ameet Talwalkar. 2018. Foundations of Machine
Learning. Boston: MIT Press.
Norton, John D. 1995. Eliminative Induction as a Method of Discovery: Einstein’s Discovery of
General Relativity. In The Creation of Ideas in Physics: Studies for a Methodology of Theory
Construction, ed. J. Leplin, 29–69. Dordrecht: Kluwer Academic Publishers.
———. 2003. A Material Theory of Induction. Philosophy of Science 70: 647–670.
———. 2005. A Little Survey of Induction. In Scientiﬁc Evidence, ed. Peter Achinstein, 9–34.
Baltimore: John Hopkins University Press.
Pietsch, Wolfgang. 2021. Big Data. Cambridge: Cambridge University Press.
Popper, Karl. 1935/2002. The Logic of Scientiﬁc Discovery. London: Routledge Classics.
Rathmanner, Samuel, and Marcus Hutter. 2011. A Philosophical Treatise of Universal Induction.
Entropy 13 (6): 1076–1136.
Ruse, Michael. 1975. Darwin’s Debt to Philosophy: An Examination of the Inﬂuence of the
Philosophical Ideas of John F.W. Herschel and William Whewell on the Development of
Charles Darwin’s Theory of Evolution. Studies in History and Philosophy of Science 6 (2):
159–181.
Russell, Stuart, and Peter Norvig. 2009. Artiﬁcial Intelligence. Upper Saddle River: Pearson.
106
4
Variational Induction

Russo, Federica. 2007. The Rationale of Variation in Methodological and Evidential Pluralism.
Philosophica 77: 97–124.
———. 2009. Causality and Causal Modelling in the Social Sciences. Measuring Variation.
New York: Springer.
Scholl, Raphael. 2013. Causal Inference, Mechanisms, and the Semmelweis Case. Studies in
History and Philosophy of Science Part A 44 (1): 66–76.
———. 2015. Inference to the Best Explanation in the Catch-22: How Much Autonomy for Mill’s
Method of Difference? European Journal for Philosophy of Science 5 (1): 89–110.
Skyrms, Brian. 2000. Choice and Chance: An Introduction to Inductive Logic. Belmont:
Wadsworth/Thomson Learning.
Solomonoff, Ray. 1964a. A Formal Theory of Inductive Inference, Part I. Information and Control
7 (1): 1–22.
———. 1964b. A Formal Theory of Inductive Inference, Part II. Information and Control 7 (2):
224–254.
———. 1999. Two Kinds of Probabilistic Induction. The Computer Journal 42 (4): 256–259.
———. 2008. Three Kinds of Probabilistic Induction: Universal Distributions and Convergence
Theorems. The Computer Journal 51 (5): 566–570.
Sterkenburg, Tom F. 2016. Solomonoff Prediction and Occam’s Razor. Philosophy of Science
83 (4): 459–479.
———. forthcoming. Putnam’s Diagonal Argument and the Impossibility of a Universal Learning
Machine. Erkenntnis. https://doi.org/10.1007/s10670-018-9975-x.
Valiant, Leslie G. 1984. A Theory of the Learnable. Communications of the ACM 27 (11):
1134–1142.
———. 1985. Learning Disjunctions of Conjunctions. Proceedings of the 9th IJCAI 1: 560–566.
———. 2013. Probably Approximately Correct. New York: Basic Books.
von Wright, Georg H. 1951. A Treatise on Induction and Probability. New York: Routledge.
Warner, Brian. 2009. Charles Darwin and John Herschel. South African Journal of Science 105:
432–439.
Whewell, William. 1860. Philosophy of Discovery. London: John W. Parker and Son.
References
107

Chapter 5
Causation as Difference Making
Abstract In this Chapter, a notion of causation is developed that ﬁts well with
scientiﬁc practice in data science. It is shown that many traditional accounts of
causation do not imply the variational evidence that is typically used in data science.
The approach, which turns out to be most suitable for analyzing data-scientiﬁc
practice, is the counterfactual account. The remainder of the chapter therefore is
devoted to developing a reﬁned version of the counterfactual account of causation
which addresses some of the familiar objections against it. Because the method of
difference plays an essential role, the proposed counterfactual account is referred to
as difference making account. In particular, a somewhat novel approach for evalu-
ating counterfactual propositions is introduced, which draws heavily on the method
of difference. Causal relevance and causal irrelevance are introduced as the two
fundamental notions, while many traditional analyses of causal dependency have
been based on the necessity and sufﬁciency of circumstances or conditions. Further
concepts are derived from the two fundamental notions, in particular causal factors,
alternative causes and inus complexes. Finally, some classical themes from the
literature on causation are discussed under the perspective of the difference making
account, for example the time asymmetry of causation, transitivity of causation, or
the role of mechanisms and interventions. The formal framework is summarized in
an appendix.
Keywords Data science · Causation · Difference making · Counterfactual · Inus ·
Transitivity · Time asymmetry
5.1
Causation in Data Science
5.1.1
The Argument for Causation
One epistemological mantra of big data and data science as has already been pointed
out several times is that correlation replaces causation. In the years that I have been
working on the epistemology of data science, I have heard and read this claim over
and over again—from journalists, policy advisers, but also from scientists working
© Springer Nature Switzerland AG 2022
W. Pietsch, On the Epistemology of Data Science, Philosophical Studies Series 148,
https://doi.org/10.1007/978-3-030-86442-2_5
109

in diverse disciplines. Let me give two examples from the literature, the ﬁrst from the
infamous but hugely inﬂuential article by WIRED editor-in-chief Chris Anderson
who claims: “Correlation supersedes causation, and science can advance even
without coherent models, uniﬁed theories, or really any mechanistic explanation at
all.” (2008) The other is from Victor Mayer-Schönberger and Kenneth Cukier’s
widely read account Big Data: A revolution that will transform how we live, work,
and think. According to one of their central theses big data implies
a move away from the age-old search for causality. As humans we have been conditioned to
look for causes, even though searching for causality is often difﬁcult and may lead us down
the wrong paths. In a big-data world, by contrast, we won’t have to be ﬁxated on causality;
instead we can discover patterns and correlations in the data that offer us novel and
invaluable insights. The correlations may not tell us precisely why something is happening,
but they alert us that it is happening. (Mayer-Schönberger and Cukier 2013, 14)
In spite of all these assertions, the argument for a crucial role of causation in data
science is quite simple to make (cp. Sect. 1.2). It comes down to the question what
the overall function of causal knowledge is. Why is it important to identify a
relationship as causal rather than as a mere correlation? Many, also in the current
debate on the epistemology of data science, believe that knowing the causal story is
largely equivalent with being able to explain a phenomenon. Allegedly, without
causal knowledge, one can merely describe how things are, but one cannot explain
why they are as they are. Mayer-Schönberger and Cukier clearly rely on such a link
between causation and explanation in the above quote.
However, such unfortunately widespread thinking is fundamentally mistaken
about the actual function of causal knowledge. While causal knowledge sometimes
contributes to theoretical explanations, causal explanations often constitute very
poor and superﬁcial explanations (cp. Sect. 3.3). Furthermore, many explanations
do not refer to causal knowledge at all. Thus, the distinction, which is most notably
established by causation, is that between empirical relationships which allow chang-
ing the phenomena in desired ways and those relationships that do not. In an article
by Nancy Cartwright, the grande dame of modern philosophy of science, she stated
this important insight in the following manner: “I claim causal laws cannot be done
away with, for they are needed to ground the distinction between effective strategies
and ineffective ones.” (1979, 420) Her example is a letter she got from an insurance
company making the argument that its clients have a longer life expectancy com-
pared with the average population—insinuating that one’s own life expectancy can
be extended just by buying their insurance. Of course, such an inference is mistaken
exactly because no direct1 causal link exists between being insured by this company
and life expectancy. Instead, the certainly real statistical correlation between these
variables is due to a common cause, i.e. an indirect causal link, that the company
1As I use the terminology, a direct causal link between variables A and B is one, where the causal
arrows between all variables linking A with B point in the direction from A to B. By contrast, for an
indirect causal link, at least one of those arrows points in the opposite direction. If all arrows point
from B to A, one could deﬁne that there exists a direct causal link between B and A, but only an
indirect causal link between A and B.
110
5
Causation as Difference Making

predominantly insures teachers and that teachers generally have a longer life expec-
tancy than the average population. However, nobody becomes a teacher just from
buying an insurance policy.
In other words, causal relationships identify difference-makers in the sense that if
a certain variable is changed this will have an impact on another variable. Pushing
the light switch turns on the light, because a causal relationship exists between those
variables. By contrast, increasing the stork population does not change human birth
rate, because there is no causal relationship, but only a correlation between the
respective variables. Scholars like Mayer-Schönberger miss this primary function of
causal knowledge to establish difference making and instead mistakenly see the
fundamental role of causal knowledge in providing theoretical explanations. Above
all, causation is a guide how to effectively intervene in the world.
Data science of course is mainly interested in difference making, i.e. in how to
effectively intervene in phenomena. For example, algorithms are designed to deter-
mine the best medicine to cure a certain cancer, to make someone click on a link, buy
a certain product or vote for a certain person. For such applications, correlations are
never enough. Rather, these algorithms must at least implicitly establish causal
relationships. This follows more or less by deﬁnition. Note that such causal knowl-
edge mostly will not be explanatory, but yield at best poor answers to why ques-
tion—mirroring the asymmetry between predictive power on the one hand and lack
of explanations on the other hand that is characteristic for data science.
Causal knowledge turns out indispensable not only for effective intervention but
also for reliable prediction. In the absence of a causal connection between different
variables, including especially the absence of an indirect connection via common
causes, any existing correlation between those variables, no matter how strong,
cannot establish reliable prediction. After all, any such correlation must be purely
accidental and there is no reason to believe that it will continue to hold in the future.
Of course, this argument presupposes that there is also no normative, e.g. a deﬁni-
tional, connection between the respective variables. Thus, even data science appli-
cations that do not aim at effective intervention but only at reliable prediction need to
establish causal knowledge in terms of at least an indirect connection by means of
common causes. If an algorithm wants to predict whether someone will commit a
crime, pay back a credit, or is authorized based on her/his face or ﬁngerprint,
causation is indispensable as well. In summary, both central functions of data
science, prediction and intervention, require access to causal knowledge.
A connection between causation and explanation undeniably exists. Causes can
serve as answers to why-questions even though such answers often do not yield
deeper explanations. After all, a complex expression of necessary and sufﬁcient
conditions for a phenomenon may be the actual cause of that phenomenon but will
still leave the scientist puzzled as to why there is a connection between the circum-
stances and the phenomenon in the ﬁrst place. Knowing that aspirin cures headaches
can explain, why in in some situations, in which a sick person took aspirin, she or he
was cured, but it yields at best a superﬁcial explanation for why this was the case.
Deeper explanations generally refer either to unifying theoretical laws or to causal
mechanisms linking the circumstances with the phenomenon. Note that in the latter
5.1
Causation in Data Science
111

case, the required causal knowledge does not only cover the overall relationship
between circumstances and phenomenon but extends to many further causal con-
nections in between. Certainly, knowing the exact chemical processes how aspirin
acts in the human body and eventually extinguishes the feeling of headache is highly
explanatory.
In summary, causal knowledge sometimes but not always yields adequate expla-
nations of the phenomena. Conversely, some deeper explanations of the phenomena,
in particular those referring to theoretical laws, are not fundamentally causal at all.
The fundamental mistake of those scholars claiming a shift from causation to
correlation in the wake of data science is that they more or less equate causation
with theoretical explanation and overlook the much more important function of
causation to establish reliable prediction and effective intervention.
Some scholars have claimed that current methods in machine learning at some
point need to be supplemented with causal reasoning in order to overcome the
limitations of merely associational knowledge (e.g. Pearl 2018, Introduction,
Ch. 10). According to this viewpoint, causal reasoning must be implemented in
machine learning using a proper calculus of causation including a symbolic language
that answers, how variables respond to interventions: P(L|do(D)) describing the
probability distribution of variable L in response to an intervention on variable
D. Such a calculus implies a sharp distinction between a realm of passive observa-
tions, which cannot lead to causal knowledge, and a realm of interventions, which
hold the key to causality (ibd., Ch. 1).
As will become clear in the following, the approach to causation defended in this
book reaches very different conclusions. In particular, the results of machine learn-
ing algorithms like decision trees or neural networks do not yield mere correlations,
but should be interpreted in causal terms. In fact, the strength of these algorithms
results mainly from their ability to grasp an underlying causal structure of the
phenomena. Also, the notion of causation defended in the following disagrees
with respect to several fundamental features. For instance, an interventionist notion
of causation as defended by Pearl and reﬂected in the do-calculus is a fundamentally
asymmetric notion, distinguishing the variable upon which one intervenes from the
variable showing the effect of the intervention. By contrast, the difference-making
notion defended in the following is in its conceptual core symmetric. Such examples
justify once again the need for thorough conceptual analysis, as they clearly show
that the whole outlook on a ﬁeld is framed by the basic concepts that are used—a
point which is emphatically stressed by Pearl as well (ibd., 10).
5.1.2
Causation in Data Science
Having established the crucial role of causation in data science in order to distinguish
between relationships that allow for effective intervention and/or reliable prediction
and those that do not, we next have to ask, which deﬁnition or concept of causation is
adequate for data science. Of course, causation is among the most controversial and
112
5
Causation as Difference Making

most ﬁercely debated notions in philosophy of science and epistemology. One can
still meet people both from the sciences and from statistics who hold causation to be
a prescientiﬁc notion that should not play a substantial role in sound scientiﬁc
methodology. For twentieth century statistics, Ronald Fisher has set the tone. The
originator of many essential modern statistical tools was highly critical of the notion
of causation and suggested to entirely replace it by the notion of correlation.
Various explications of causation exist, in terms of regularities, of interventions,
of underlying mechanisms, and of counterfactuals—to name just the most important
ones (cp. e.g. Hüttemann 2013). I do not want to engage here in a metaphysical
debate about what really constitutes causation—as important as it may be, but rather
ask the more modest question, which concept of causation ﬁts best with the practice
of data science.
The classical interpretation analyzes causation in terms of regularities. This
approach can be traced back at least to the writings of the Scottish philosopher
David Hume, who deﬁned the regularity approach to causation in the following
manner: “We may deﬁne a cause to be an object followed by another, and where all
the objects, similar to the ﬁrst, are followed by objects similar to the second.” (1748,
Section VII) Thus, causal relationships consist in regularities in which an event or
property of a certain type A is always followed by an event or property of another
type C. Apparently, there is a close connection between this deﬁnition or explication
of causation and the methodology of enumerative induction as discussed in the
previous chapter. After all, if causal relationships consist in regularities, it is plau-
sible to infer causal relationships from observed regularities, i.e. by collecting
instances in which events always occur subsequently—while at the same time no
falsifying or negative instances occur, i.e. instances in which A is not followed by C.
As we have seen, there is a close relationship between the conceptual analysis of
causation, the inductive methodology as well as the relevant evidence. With respect
to a regularity account, the conceptual analysis of causation is in terms of regular-
ities, the methodology is enumerative induction and regularities are the most impor-
tant type of evidence in order to discover causal relationships in the world. However,
when looking at scientiﬁc practice in data science, clearly the evidence that is
commonly used has a decidedly variational character, and correspondingly the
methodology underlying most algorithms is variational induction rather than enu-
merative induction (as argued in Chap. 4). Thus, a conceptual analysis in terms of
regularities neither reﬂects the type of evidence nor the methodology that is preva-
lent in data science. Therefore, regularity approaches to causation do not seem to
constitute an adequate choice for data science.
In the previous chapter, a rationale of regularity with respect to inductive infer-
ences was contrasted with a rationale of variation (Russo 2009). The conceptual
analysis of causation that most closely mirrors a methodology of variational induc-
tion and in particular of difference making is the counterfactual approach, which is
also brieﬂy mentioned by Hume, although he otherwise focuses almost exclusively
5.1
Causation in Data Science
113

on the regularity analysis. Hume summarizes the counterfactual approach2 as fol-
lows: “We may deﬁne a cause to be an object followed by another, [. . .] where, if the
ﬁrst object had not been, the second never had existed.” (1748, Section VII) The
approach is called counterfactual, because for a causal relationship to exist or to be
derived statements of facts about what is the case in the world do not sufﬁce. Rather,
one also needs to know whether certain statements are true, which are against the
facts, i.e. so-called counterfactual statements as in: if the ﬁrst object had not been, the
second never had existed. Apparently, the counterfactual deﬁnition of causation
reﬂects very well the idea of difference making as it appears in variational induction.
In particular, if the counterfactual conditional is true, then the ‘ﬁrst object’ in Hume’s
deﬁnition is a difference making circumstance for the ‘second object’.
Furthermore, the counterfactual deﬁnition implies the central type of evidence
used in variational induction, i.e. observing phenomena under systematic variation
of circumstances. After all, one is not only looking for positive instances as in naïve
regularity or enumerative approaches, but negative instances where the examined
phenomenon is absent must also be taken into account. Of course, both positive and
negative instances must be considered in order to identify the difference makers of a
phenomenon in various contexts. Thus, judging from the prevalent methodology and
the main type of evidence used in data science, a counterfactual analysis seems much
more adequate for data science than regularity approaches.
The crucial epistemological problem of the counterfactual approach concerns the
counterfactual conditional itself: “if the ﬁrst object had not been, the second never
had existed”. If the explication of causation shall indeed mirror scientiﬁc practice,
immediately the problem arises, how such counterfactual conditionals can be eval-
uated in scientiﬁc practice, i.e. how their truth values can be determined. Since these
statements are counterfactual, it is by deﬁnition not possible to ﬁnd out these truth
values merely by direct observation or immediate experience. As will be elaborated
in the Sect. 5.2.2, the traditional approaches to tackle this problem, by David Lewis
and others, are highly problematic in that they lead to considerable subjectivity in
judging counterfactuals and consequently also in the analysis of causal relationship.
As a remedy, I will argue that variational induction can provide a plausible solution
to this problem.
The interventionist analysis of causation is in many ways similar to the counter-
factual approach. The basic idea of this approach is the following: A causal rela-
tionship between an event or property A and an event or property C exists, if and
only if under an intervention that changes the value of A (with no other intervention
occurring) there is an associated change in the value of C (cp. in particular Wood-
ward 2003; see also Pearl 2000). Interventions to a certain degree seem to provide a
plausible answer how to determine the truth value of counterfactual conditionals:
Perform an intervention on the circumstance A in question, and if the intervention
succeeds in making the phenomenon C disappear (or appear), then the counterfactual
conditional is true. Interventions in many ways seem to be the closest we can get to
2Of course, the approach did not have a name yet in Hume’s days.
114
5
Causation as Difference Making

observing and verifying counterfactual propositions in the actual world. Apparently,
the interventionist approach shares with the counterfactual approach that it well
reﬂects the methodology of difference making as well as the variational evidence
that are both central to data science.
However, interventions carry some problematic connotations, which are at odds
with scientiﬁc practice in data science. For example, the notion of an intervention
seems to be itself causally charged. Therefore, if causation is deﬁned in terms of
interventions, this necessarily implies a circularity in the deﬁnition. For some writers
this appears to be just right, when for example Nancy Cartwright famously claimed
that causal knowledge always has to rely on causal knowledge: “no causes in, no
causes out” (1994, Ch. 2). I disagree and believe that one can do better. After all, in
statistics and computational science causal relationships are often successfully
inferred from purely observational data, i.e. from mere statements of fact, which at
ﬁrst do not involve causal knowledge.
Maybe the most important objection against the interventionist approach is that
interventions seem to require an agent actively intervening in the phenomena, mostly
a human being, possibly also an animal or a machine. Unfortunately, this does not ﬁt
well with scientiﬁc practice in data science, in particular with respect to the type of
evidence. Many applications in data science rely on evidence that does not in any
obvious way result from interventions. For example, when an algorithm wants to
determine, whether a certain skin cancer is lethal, the underlying evidence is just
labeled images of skin anomalies. There is no obvious candidate for an intervening
agent in this case. Other examples concern causal relationships from domains in
which our knowledge is also mainly observational, such as meteorology, astronomy,
or even some phenomena in the social sciences.
There exist a number of ways how to react to this problem from an interventionist
perspective. The ﬁrst is to conceptually widen the notion of an intervening agent to
include cancers, planets or weather phenomena, in short to include anything that may
itself be a cause in some situation. But this leads nowhere, since the notion of
‘intervention’ more or less becomes identical with the notion of a cause of the
antecedent variable, and consequently it would be rendered redundant, not serving
any additional conceptual function.
A second possibility is to resort to hypothetical interventions and this is the route
usually taken in contemporary interventionist accounts. While acknowledging that
the antecedent variables are in reality not always causally determined by interven-
tions, the claim is that a causal relationship exists if and only if a possibly hypothet-
ical intervention by an agent on a certain variable would lead to a change in a
phenomenon. But such a move seems completely ad hoc and unilluminating, as it
more or less identiﬁes hypothetical interventions with causes of the antecedent
variable. Such a move cannot inform methodology and the search for adequate
evidence, e.g. in domains like astronomy, where intervention in the phenomena is
often impossible.
Thirdly, the most promising attempt found in contemporary literature is to require
that in the case of an intervention, the causal history of the antecedent variable fulﬁlls
5.1
Causation in Data Science
115

a number of conditions. Woodward speaks of a ‘surgical’ change to the antecedent
variable:
a ‘surgical’ change in A which is of such a character that if any change occurs in C, it occurs
only as a result of its causal connection, if any, to A and not in any other way. In other words,
the change in C, if any, that is produced by the manipulation of A should be produced only
via a causal route that goes through A. Manipulations or changes in the value of a variable
that have the right sort of surgical features have come to be called interventions in the recent
literature [. . .] and I will now follow this practice. (Woodward 2013, §5; letters A and C were
adapted to render them consistent with the terminology used in the present book)
However, in this approach the problem of deﬁnitional circularity persists and is
maybe even worsened, since the notion of a surgical change again is causally laden
to a considerable extent. One crucial feature of such a surgical change is that it
completely breaks the previously existing relationships between the variable A
which is intervened on and its causes X, with the intervention now being the only
cause of the state of A (Woodward 2013, §6). This feature is present in both
Woodward’s and Pearl’s accounts, which are among the most inﬂuential in contem-
porary literature. In general, such an assumption does not seem very realistic. After
all, variables are very rarely disentangled from the complex causal network of
dependencies that our world constitutes and only determined by a single interven-
tionist variable (cp. Frisch 2014, Ch. 4). For example, how many physical objects
exist that are not subject to a multitude of gravitational and electromagnetic forces
and certainly remain so under possible interventions?
Recognizing this default, Eberhardt and Scheines (2007) have attempted to
weaken
the
mentioned
assumption
and
introduce
what
they
call
soft
(or parametric) interventions, which leave the causal relationships X acting on A
intact and only add a further intervention Y on A that changes its value (p. 5). The
example with gravitational forces seems to ﬁt this approach, if a further gravitational
force, e.g. due to an additional planet, is added to the already existing inﬂuences and
its impact examined. However, the crucial disadvantage of these soft interventions is
that possible common causes of Y and A (so-called confounding variables) are not
excluded and thus, any inference to a causal relationship must remain doubtful. One
could resolve this issue by requiring that the intervention variable Y is itself
uncaused and that it only causes A and no other variables (Eberhardt and Scheines
2007, p. 5), but such a step again introduces implausible assumptions now of the
intervening variable Y. After all, the additional planet in the example above, will
itself be acted on gravitationally by other planets. In total, the very reason for
introducing the disruption of other inﬂuences on A was precisely to make sure that
the relationship is indeed causal and not just due to common causes. Thus, the notion
of (hard) intervention is often inapplicable, while the notion of (soft) intervention
does not reliably single out causal relationships.
In summary, I believe that these sophistications show that the interventionist
approach is mistaken as far as it relies on a substantial notion of intervention. While
interventionist accounts of the type suggested by Woodward or Pearl do not require
any kind of agency, they do have to ontologically distinguish interventions from
non-interventions. Therefore, they postulate a hard characteristic that singles out
116
5
Causation as Difference Making

interventions, in particular that they disrupt causal inﬂuences on the variable that is
intervened on, what was above called the surgical nature of intervention. But this is
unreasonable, since it seems quite plausible that such complete disruptions of causal
inﬂuences do not exist.
Notably, when it comes to data science, the data fed into machine learning
algorithms in general do not stem from situations where such disruptions of causal
inﬂuences occur. Rather, this data is gathered from all kinds of contexts, both
observational and interventionist. While a plausible feature of the interventionist
approach is that it highlights difference making just like the counterfactual account
of causation, the interventionist approach fails to account for those situations in data-
scientiﬁc practice in which the causal structure of a phenomenon is inferred on the
basis of observational rather than interventionist data. Arguably, these problems
arise when the notion of intervention requires additional features beyond simple
difference making.
By contrast, a counterfactual approach relying on simple difference making as
will be delineated in the remainder of this chapter does not require a hard distinction
between intervention and observation when it comes to evidence for causal infer-
ences. This point has also been stressed by Mill: “For the purpose of varying the
circumstances, we may have recourse (according to a distinction commonly made)
either to observation or to experiment [i.e. intervention]; we may either ﬁnd an
instance in nature suited to our purposes or, by an artiﬁcial arrangement of circum-
stances, make one. [...] There is, in short, no difference in kind, no logical distinc-
tion, between the two processes of investigation. There are, however, practical
distinctions to which it is of considerable importance to advert.” (Mill 1843/1950,
211; cited by Eberhardt 2009, 9) That causal inference based merely on observa-
tional, non-interventionist data should be possible, seems a desideratum for any
account of causation suitable for data science.
The fourth and ﬁnal class of accounts of causation that I want to brieﬂy discuss
regards so-called mechanistic accounts or process theories of causation. Here, the
basic idea is that a causal relationship between an antecedent A and a consequent C
exists if and only if there is a causal mechanism or a causal process linking these
variables. The central difﬁculty of these accounts is to give a precise analysis of the
notions of a causal mechanism or a causal process.
With respect to the question whether a mechanistic or process account of causa-
tion ﬁts the practice of data science, we can again point to the evidence that is used
for causal inferences. In many data-scientiﬁc applications, algorithms like decision
trees or neural networks identify causal structure without having access to knowl-
edge about underlying mechanisms or processes. For example, a remedy for a
disease may be identiﬁed without any knowledge about how exactly the medicine
cures biochemically. Therefore, mechanistic and process accounts imply the wrong
kind of evidence, namely knowledge about underlying processes or mechanisms
rather than the variational evidence that is used in data science. Later in the chapter, I
will argue that the obvious advantages of having mechanistic or process knowledge
about certain dependencies can be made plausible in terms of difference making as
well (cp. also Pietsch 2016b). Thus, difference making is fundamental.
5.1
Causation in Data Science
117

Note that in this section mainly epistemological objections have been raised
against some standard accounts of causation. For example, we have shown how
the variational evidence that is typically employed in data science is in conﬂict with
regularity and mechanistic accounts. Note that there may still be a metaphysical level
of causation which is independent of such considerations of evidence and of
methodology. Be that as it may, here we are interested in ﬁnding a conceptual
explication of causation that is both informed by and informs the inductive meth-
odology how to infer causal relationships from empirical evidence as well as the
nature of evidence, on which such causal inferences draw. From this perspective, the
counterfactual approach constitutes the account of causation that ﬁts best with
scientiﬁc practice in data science. The rest of the chapter therefore is devoted to
developing a reﬁned counterfactual account addressing some of the familiar objec-
tions and problems against such an approach.
5.1.3
A Brief Overview of What Is to Come
In Sect. 5.2, causation is deﬁned in terms of difference making. More precisely,
counterfactual deﬁnitions for the fundamental notions of causal relevance and causal
irrelevance are given. Then a difference-making account of counterfactuals is pro-
posed, according to which the truth or falsity of a counterfactual statement can be
determined by showing that it belongs to a class of statements with the same truth-
value, of which at least one is realized in the actual world. The main advantage of
this account with respect to other prominent approaches—in particular the semantic
approach based on possible worlds due to Robert Stalnaker and David Lewis and the
metalinguistic view due chieﬂy to Nelson Goodman—is that the evaluation of
counterfactuals is less vague, thereby rendering causation more objective. In its
deﬂationist spirit, the approach to causation, as outlined in this chapter, is quite
similar to Federica Russo’s ‘invariance across changes’ account (2014), which tries
to extend basic interventionist ideas to situations where manipulations play no
obvious role. The proposed account also bears considerable resemblance to sophis-
ticated regularity theories like those of Mill (1886), Mackie (1980), or Baumgartner
and Graßhoff (2004).3 With all of them, it shares the focus on variational induction
and like Mackie, it emphasizes the importance of background dependence and of
counterfactual reasoning. At the end of the section, causal ordering and the direction
of causation are brieﬂy discussed.
In Sect. 5.3, further causal concepts, in particular causal factors and alternative
causes, are deﬁned on the basis of the two fundamental notions, i.e. causal relevance
3Given the distinction between enumerative and variational induction and the fact that both Mill
and Mackie were staunch defenders of variational induction, the characterization of both as
regularity theorists may well be questioned. After all, variational induction is characterized by
relying on evidence in terms of variations rather than regularities.
118
5
Causation as Difference Making

and causal irrelevance. A link to the inus-logic of causal conditions is established. It
is also shown that the difference-making approach can account for some crucial
features of the pragmatics of causation, most importantly that causal relations can be
formulated at various levels of coarse-graining and that they fulﬁll some basic
intuitions about transitivity. Finally, I discuss how functional relationships can be
grounded in the logic of relevant and irrelevant conditions, mitigating one of the
classic objections against inus-accounts of causation that these can allegedly only
deal with discrete relationships concerning the absence and presence of factors.
In Sect. 5.4, a number of conceivable objections are rehearsed. Also, the role of
mechanisms and interventions for the difference-making account is brieﬂy
addressed. In summary, I argue that the proposed account manages fairly well to
establish an objective approach to causation as appropriate when considering the role
of causal knowledge in the sciences and in particular in data science.
The developed notion of causation will allow us to address in subsequent chapters
some further methodological issues concerning causal inference. A reframing of
Mill’s methods will be suggested in Sect. 6.1, based on two fundamental methods,
which correspond to the concepts of causal relevance and of causal irrelevance in the
difference-making account. We will also take a look at several long-standing
epistemological problems that are connected with causal inference. In particular,
the problem of induction both in its Humean version (Sect. 6.2) and according to
Goodman’s new formulation (Sect. 7.3) will be discussed from the perspective of the
difference-making account and of the corresponding methodology of variational
induction. We will argue that the problem of induction that arises for variational
induction is largely distinct from traditional versions of this issue. As another
epistemological problem, we will look at concept formation in Chap. 7, where it is
argued that variational induction provides a promising framework for formulating
causally adequate categories. In Chap. 8, a formal framework for analogical reason-
ing will be developed. Speciﬁcally, we will argue that analogical inferences can be
naturally integrated into variational inductive approaches in the tradition of Mill’s
methods. Finally, in Chap. 9, we will propose a notion of causal probability, which
ﬁts with variational induction and a difference-making view on causation.
5.2
Deﬁning Causation
In the following, the main elements of the proposed difference making account will
be introduced: First, the notions of causal relevance and causal irrelevance are
deﬁned in counterfactual terms—broadly in line with the original counterfactual
deﬁnition of causation as provided by David Hume. Second, the main conceptual
problem of counterfactual approaches will be addressed, namely how truth-values of
counterfactual statements are evaluated. It seems fair to say that all suggestions made
in the past for this purpose face serious objections. I will therefore introduce a further
5.2
Deﬁning Causation
119

proposal taking Mill’s method of difference4 as a guideline. Third, the concept of a
causal background or context will be introduced in the tradition of John Anderson
and John Mackie. According to the suggested view, all causal statements will be
rendered background- or context-dependent, i.e. without exception they hold only
ceteris paribus.
5.2.1
Causal Relevance and Causal Irrelevance
As is well known, Hume proposed two distinct deﬁnitions of causation, as discussed
in the previous section. He somewhat mysteriously equated these deﬁnitions
although their relation is anything but clear: “We may deﬁne a cause to be an object
followed by another, and where all the objects, similar to the ﬁrst, are followed by
objects similar to the second. Or, in other words, where, if the ﬁrst object had not
been, the second never had existed.” (Hume 1748, Section VII). In fact, Hume
elaborated merely the ﬁrst deﬁnition leading to his regularity account which focuses
on constant conjunction and notoriously results in the subjectivization of causal
relationships. The second deﬁnition, relying on counterfactuals, was developed into
a full account of causation only in the twentieth century by David Lewis. But Hume
still deserves the merit of having formulated the core idea: in order to determine a
causal dependence between two events—or whatever one takes the causal relata to
be—both events must be realized in the actual world in a certain instance and the
truth of the corresponding counterfactual conditional must be somehow established.
To introduce the fundamental concepts of the proposed counterfactual account it
is useful to recall Lewis’s counterfactual approach for comparison. According to
Paul Horwich (1987), the latter combines four basic elements. First, Lewis intro-
duces a counterfactual deﬁnition of ‘causal dependence’ closely following Hume’s
view. According to Lewis, it is problematic that such causal dependence turns out
not to be transitive. Typical counterexamples are cases of preemption,5 where causal
dependence holds for the individual steps in a causal chain, but not for the relation
between end and starting points (cp. Menzies 2014, Sec. 2.3). He therefore deﬁnes
‘causation’ in terms of causal chains as the transitive complement to causal depen-
dence: “C caused E if and only if there was a sequence of events X1, X2, . . ., Xn
such that: if C had not occurred, than X1 would not have occurred; if X1 had not
occurred, then X2 would not have occurred, . . . if Xn had not occurred, then E would
4Which actually is not Mill’s, but was formulated before him by various known and unknown
methodologists, including William Ockham, Francis Bacon, and John Herschel.
5I will come back to this issue in Sect. 5.4.2.
120
5
Causation as Difference Making

not have occurred.” (Lewis 1973, quoted in Horwich 1987, p. 167) Obviously, if
there is causal dependence between two events, there is causation, but not vice versa.
As a second crucial element of his account, Lewis needs to specify how the truth-
values of the counterfactual conditionals are determined, which trivially cannot be
directly observed. To this purpose, he introduces his so-called semantic approach
relying on possible worlds and the notion of similarity between these worlds: “‘If C
were true, then A would also be true’ is true (at a world w), iff either (1) there are no
possible C-worlds, or (2) some C-world where A holds is closer to the actual world
than is any C-world where A does not hold.” (Lewis 1973, 560) This issue will be
discussed in detail in Sect. 5.2.2.
Given that the notion of similarity between possible worlds appears in Lewis’s
account of counterfactuals, the next difﬁculty consists in formulating a suitable
account of similarity. It seems fair to say that Lewis never managed to ﬁnd a
satisfying solution for this task. He determines the main criteria for measuring
similarity, namely resemblance with respect to laws and with respect to matters of
facts (1979). But what is lacking is a detailed account providing a set of rules how to
combine these two fundamental aspects in concrete situations. Rather, he seems to
be constantly adjusting his approach in hindsight in order to accommodate certain
examples for which clear intuitions about causal dependencies exist. Lewis has
repeatedly stressed that this failure correctly reﬂects the in his view essentially
subjective nature of causation, but this is clearly at odds with the fairly objective
nature of causal knowledge in the sciences. Think in particular of the engineering
sciences, where based on causal knowledge, complicated and highly reliable tech-
nical artifacts can be built like bridges, airplanes, or computers.
Finally, the fourth element of Lewis’s account concerns the time asymmetry of
causation. For Lewis, the asymmetry consists mainly in the fact that counterfactuals
do not generally hold in both directions: if the present were different, the future
would change, but the past would generally not have changed. This topic will be
brieﬂy elaborated in Sect. 5.2.3.
Let me now present the basic ingredients of the proposed account, which, just as
Lewis’s approach, relies on a counterfactual deﬁnition of causation. However, it
takes a different route to evaluating the truth-values of counterfactual propositions,
one that gets by without the slippery notion of similarity between possible worlds.
Rather it refers to situations in the actual world that differ only in terms of irrelevant
circumstances. Thus, a notion of causal irrelevance is required as a complement to
the notion of causal relevance.
The difference-making account deﬁnes causal relevance and causal irrelevance in
the following manner:
5.2
Deﬁning Causation
121

In a context B, in which a condition or circumstance A and a phenomenon C occur, A is
‘causally relevant’ to C, in short A R C | B, iff the following counterfactual holds: if A had
not occurred in context B, C would also not have occurred.6,7
In a context B, in which a condition or circumstance A and a phenomenon C occur, A is
‘causally irrelevant’ to C, in short A I C | B, iff the following counterfactual holds: if A had
not occurred, C would still have occurred.
Here and in the following, capital letters denote speciﬁc states, and lowercase
letters denote variables that generally allow for a range of different states. Thus x ¼
X means that variable x is in state X and x ¼ ØX means that it is in state ØX. In
general X denotes the presence of state X, and ØX the absence of X.
From the treatment of counterfactual propositions as elaborated in Sect. 5.2.2, it is
easily seen that the following relations hold:
ARC j B $ ØARØC j B
ð5:1Þ
AI C j B $ ØAI C j B
ð5:2Þ
Here, negation Ø is understood in the sense of classical logic, in particular
Ø(X˄Y) ¼ ØX˅ØY as well as Ø(X˅Y) ¼ ØX˄ØY.
The proposed terminology is supposed to work both for the token and for the type
level. In fact, I believe the distinction not to be particularly relevant in the current
context. To begin with, ‘conditions’ or ‘circumstances’ and ‘phenomena’ in the
above deﬁnitions refer to types, i.e. they can all be instantiated more than once.
Events are speciﬁed by a number of types, i.e. all events are in principle repeatable.
In particular, variables as well as speciﬁc states of variables must be interpreted as
types. Finally, the background is thought to be constituted by a large number of
conditions, therefore it is equally a type-concept. Thus, causal relationships as
identiﬁed by the above deﬁnitions are generally situated on the type level. However,
sometimes the combined conditions determining a speciﬁc event may be so strong
that may turn out in practice not to be repeatable, i.e. a token.
In contrast to Lewis’s counterfactual approach, the proposed account does not
need to distinguish between causal dependence and causation, since it will deal
differently with both transitivity and preemption (see Sects. 5.3.3 and 5.4.2). Note
further that according to conventional terminology (e.g. Baumgartner and Graßhoff
2004, Ch. 3.2), causal relevance requires that a condition makes a difference in at
least one situation, while according to the above framework it must always make a
difference in a speciﬁed context. Correspondingly, causal irrelevance is convention-
ally taken to require that a condition never makes a difference, while in the
framework proposed above it must never make a difference with respect to a
6Note that the meaning of causal relevance as deﬁned here is not identical with that in the context of
probabilistic causation, where causal relevance merely indicates the increase of probability under
conditionalization.
7In a strict sense, a “difference maker” to a phenomenon could be deﬁned as a variable or inus
complex, which is causally relevant to the phenomenon.
122
5
Causation as Difference Making

speciﬁed context. Obviously, according to the conventional perspective, causal
irrelevance is in practice impossible to establish since nobody can ever claim to
have examined all possible contexts, which has led to the general rejection of this
notion in the literature. Conversely, a meaningful notion of causal irrelevance is only
possible when requiring universal background dependence of causal statements.
Thus, one notable feature of the proposed counterfactual account is that it
attributes a central role to the notion of causal irrelevance—which arguably distin-
guishes it from all other contemporary accounts of causation.8 In particular, causal
irrelevance will turn out crucial for the novel manner to evaluate counterfactuals that
will be outlined in Sect. 5.2.2. Roughly, a counterfactual statement is true if an
instance is realized in the actual world that differs from the examined counterfactual
instance only in terms of irrelevant circumstances.
A further important characteristic is that according to the proposed account all
causal relations are rendered context-dependent, i.e. they are always deﬁned with
respect to a background or context of further conditions or circumstances that are
held constant if potentially causally relevant or that are allowed to vary if causally
irrelevant.9 More precisely:
A ‘background’ or ‘context’10 shall consist in (i) certain conditions A1, . . ., An that are
considered potentially causally relevant to a number of phenomena C1, . . ., Cm and whose
impact on these phenomena is explicitly examined; (ii) conditions that co-vary with some of
the As, e.g. because they lie on causal chains leading through at least one of the As to at least
one of the Cs; (iii) further conditions that may vary and that are assumed to be causally
irrelevant to the considered phenomena; (iv) further conditions that remain or are explicitly
held constant, some of which may be causally relevant to the considered phenomena.11
As an example, consider an experiment to examine the causal structure of a
simple pendulum. (i) Typical conditions A that are explicitly varied are the length of
the rod, the mass of the weight, or the initial displacement of the weight. A
phenomenon C in this example could be the period of the pendulum. (ii) A condition
that is not explicitly considered as one of the As but co-varies with them is the
gravitational force on the weight which changes with its mass and thereby leads to a
change in period. In other words, the variable gravitational force lies on a causal
chain between the variables weight and period. (iii) Certainly, there are myriads of
8A notion of causal irrelevance is discussed in Galles and Pearl (1997, Sec. 4). However, these
authors, working within an interventionist rather than a counterfactual approach, do not ascribe a
central role to irrelevance in their conceptual framework. In particular, they do not acknowledge the
fundamental role of causal irrelevance for the evaluation of counterfactual statements, as discussed
in Sect. 5.2.2. Tilman Sauer, in a yet unpublished manuscript, provides an interesting case study
from physics regarding the analysis of the cosmic microwave background, where conclusions to
irrelevance are frequently made and an explicit statistical methodology for detecting causal irrel-
evance is developed.
9Context dependence is of course stressed in Mackie’s account of causation, while the basic idea
dates back at least to his teacher John Anderson.
10These terms are used synonymously throughout the manuscript.
11Note that sometimes in the following context or background only refers to items (iii) and
(iv) above.
5.2
Deﬁning Causation
123

conditions that might change even during a simple pendulum experiment, e.g. the
position of the earth with respect to the sun, the formation of clouds in the sky, the
thoughts of the president of the United States etc. All of these conditions are
generally assumed to be irrelevant for the causal structure of the considered set-up.
But note that it may occasionally happen that this third category comprises condi-
tions that eventually turn out relevant to the examined causal structure, which would
then require a readjustment of the context. (iv) Finally, in the last category are all
those conditions that stay constant in the considered set-up, either because they are
explicitly held ﬁx or because they coincidentally happen to remain constant. This
category usually comprises some conditions that are known to be relevant or
potentially relevant for the set-up, such as in the discussed example the mass of
the earth or the position of other large bodies in the immediate vicinity of the
pendulum.
As a matter of terminology a change in background or context will be noted in the
following manner: B˄X, i.e. x¼X is held constant in addition to the requirements
determined by B; B˄x, i.e. variable x can take on any possible value, e.g. X or ØX.
We speak of a background or context within B if it is at least as restrictive as B, i.e. if
it imposes at least the restrictions of B concerning constancy of conditions. Further-
more, B\X and B\x denote that the variable x or the state X are not anymore
considered as background conditions, but are explicitly considered.
Let me also provide an example to point out some consequences of the deﬁnitions
of causal relevance and irrelevance. In 1871, a terrible ﬁre almost completely
destroyed the city of Chicago. Relatively quickly, the location was found where
the ﬁre had originated, namely in a barn in the southwest of the city. Soon after-
wards, a newspaper published a story, according to which a cow belonging to the
owners of the barn Patrick and Catherine O’Leary had kicked over a lantern and
started the ﬁre. As is well-known, the logic of such causal conditions has been
analyzed by John Mackie, constituting his most important contribution to the
literature of causation. According to Mackie, a cause is an inus-condition, i.e. an
insufﬁcient but non-redundant part of an unnecessary but sufﬁcient condition.
Clearly, the kicked-over lantern is such an inus-condition since the general expres-
sion for the cause of a barn ﬁre may be something like: (kicked-over lantern ˄ hay on
the ﬂoor) ˅ lightning cause a barn ﬁre with respect to a background of other
conditions B*.
Let us brieﬂy examine in the example of the Chicago ﬁre, which events or
conditions are causally relevant or irrelevant. As we will see, some of the conse-
quences are somewhat counter-intuitive. For example, the kicked-over lantern is
only relevant with respect to certain backgrounds, e.g. with respect to background
B* ˄ hay ˄ no lightning. However, it is causally irrelevant with respect to B* ˄ no
hay ˄ no lightning. Moreover, it is causally irrelevant with respect to a background,
in which another factor causes the ﬁre, e.g. with respect to B* ˄ hay ˄ lightning. A
further consequence is that in some contexts the question of relevance or irrelevance
is underdetermined, for example with respect to B* ˄ no lightning. After all, both
may be the case depending on the presence or absence of hay. The concepts of causal
124
5
Causation as Difference Making

factor and alternative cause required for adequately describing such situations will be
introduced in Sect. 5.3.1.
Let me stress again that some of this may sound counter-intuitive at ﬁrst, since
according to conventional terminology a condition is considered causally relevant to
an event just in case that there exists some background under which it makes a
difference to the event. Thus, the kicked-over lantern is always considered causally
relevant to a barn ﬁre, no matter if combustible material is present or not. But again,
it is essentially this conceptual choice, which renders it more or less impossible to
deﬁne a meaningful concept of causal irrelevance. Also, it is exactly this move that is
at the origin of many contradictions and inconsistencies in classical approaches to
causation, e.g. concerning overdetermination and preemption. Arguably, the only
way to avoid these problems is to carefully keep track of the background with respect
to which causal relevance or irrelevance can be stated.
From the perspective of the sketched framework, causal knowledge can be
acquired and improved in a process of variation of conditions or circumstances.12
In particular, causal relevance and irrelevance of conditions must be examined in
different contexts. By increasing the set of known irrelevant conditions for a certain
phenomenon the generalizability of causal relationships can be determined. In other
words, causal knowledge can be established on the basis of what was called in
Chap. 4 variational evidence. But note again that by this procedure, one never arrives
at strictly universal relationships, the ceteris-paribus character implied by the
background-dependence will always remain.13
Note ﬁnally that in distinction to Mackie’s approach the fundamental terminology
of the difference-making account is not in terms of necessary and sufﬁcient condi-
tions, but in terms of causally relevant and irrelevant conditions with respect to a
context. Crucially, the difference-making approach to counterfactuals which will
now be outlined is not accessible to the wide-spread terminology of necessity and
sufﬁciency.
5.2.2
A Difference-Making Account of Causal
Counterfactuals
As mentioned, the main challenge for the counterfactual analysis of causation
concerns the evaluation of the truth-values of the counterfactual conditionals.
Once this problem is solved, many features of causation follow directly, e.g., that
12This variational rationale, which is in spirit opposed to Humean regularity views, can be found
with a variety of authors including Bacon, Mill, and Keynes. In recent literature, it has been most
forcefully defended by Federica Russo (e.g. 2009).
13Thus, strictly universal relationships, as they can for example be found in physics, cannot be fully
causal, but must have a decisive conventional element. This constitutes yet another answer to the
ongoing debate, to what extent causality plays a role for physics.
5.2
Deﬁning Causation
125

causation implies some kind of necessity and therefore can establish claims about
prediction and manipulation. In the literature, one ﬁnds two main accounts of
counterfactuals, an older one often called the metalinguistic framework that was
chieﬂy developed by Nelson Goodman and a newer one mostly referred to as
possible worlds or semantic view due mainly to Robert Stalnaker and David Lewis
(cp. e.g. Psillos 2015; Reutlinger 2012, Sec. 4).
The basic idea of the metalinguistic framework (e.g. Goodman 1983, Ch. I) when
evaluating a counterfactual propositions such as “if A had been true, C would also
have been true” is to examine under which additional premises in terms of laws and
matters of facts, A would actually entail C. Thus, the fundamental problem for the
metalinguistic approach is to determine which premises are ‘cotenable’ with A and
which are not, i.e. what should be admitted in addition to A in order to determine if C
is the case and thereby the truth value of the counterfactual. It turns out that this issue
has never been satisfactorily resolved.
As a consequence, Mackie developed what is sometimes called the supposition
view, which stands broadly in the tradition of the metalinguistic framework but
stresses a strong contextuality of counterfactual statements: to assert a counterfactual
statement like that given above is to claim that C broadly belongs to the implications,
if A is supposed. Thus, the truth value of the counterfactual proposition much
depends on the attitude and context in which it is expressed. Cotenable are those
propositions that are naturally presupposed in a certain context along with A. (Psillos
2015, 88–89)
The other main approach to counterfactuals that has dominated discussions about
causation in the past decades attempts to determine the truth value of counterfactual
statements by referring to possible worlds and the similarity between them. While
fundamental ideas are due to Robert Stalnaker, it was mainly David Lewis who
turned these into a full-blown and sophisticated account (Lewis 2001).
The basic idea in Lewis’s approach is the following: “If A were true, then C
would also be true” is true (at a world w), iff either (1) there are no possible
A-worlds, or (2) some A-world where C holds is closer to the actual world than is
any A-world where C does not hold (Lewis 1973, 560). Here, an A-world just refers
to a possible world in which A is realized. The ﬁrst part (1) amounts to a deﬁnition
for speciﬁc, rather extraordinary situations and thus, the second part (2) is certainly
more interesting. Obviously, the main challenge to this approach is to come up with a
proper account of possible worlds and especially with a plausible notion of
similarity.
Lewis’s remarks concerning similarity are quite vague and general: “Overall
similarity among worlds is some sort of resultant of similarities and differences of
many different kinds, and I have not said what system of weights and priorities
should be used to squeeze these down into a single relation of overall similarity. I
count that a virtue. Counterfactuals are both vague and various. Different resolutions
of the vagueness of overall similarity are appropriate in different contexts.” (Lewis
1979, 465) As also required in the metalinguistic account, Lewis needs to balance
considerations of laws and of matters of facts when judging counterfactual state-
ments. The feeling remains that his account can reconstruct many causal analyses in
126
5
Causation as Difference Making

hindsight, but that it mostly fails to guide intuitions in difﬁcult cases. Notorious and
much-discussed counterexamples to Lewis’s approach concern situations in which a
single antecedent has enormous consequences, for example pressing the infamous
red button to start a nuclear war.
Thus, the two most inﬂuential approaches suffer from considerable vagueness
which admittedly may sometimes be a property of counterfactual statements. How-
ever, judging from common intuitions about causal knowledge, the subjectivity
seems overemphasized at least for those counterfactuals corresponding to causal
dependencies. After all, for a large number of phenomena the causal structure is
fairly well understood and more or less unambiguous. Think for example of all those
achievements that the engineering sciences have contributed to human knowledge.
A further issue is that both traditional approaches refer to the notion of law when
evaluating counterfactual statements—which introduces at least the threat of circu-
larity, since often such laws will themselves be of causal nature.
In view of these problems, let me argue for yet another way to evaluate the truth
of counterfactual statements. On the positive side, it will not be plagued by the
vagueness and subjectivity of the above approaches and it will not refer to laws. On
the negative side, the account is not meant as a full-blown account for all counter-
factual statements. For example, it cannot plausibly answer what the truth-value is of
strongly hypothetical propositions that differ substantially from familiar phenomena,
e.g. describing the consequences had Julius Caesar led the UN-forces in the Korean
War, to cite an oft-used example from the literature. Rather, the account will be
limited to counterfactual statements that occur in causal contexts. It is explicitly
intended as an account of causal counterfactuals.
The starting point of the proposed account is that in order to determine the truth-
value of a counterfactual proposition two things have to be established: (i) it must be
shown that the counterfactual statement belongs to a class of propositions with the
same truth value; (ii) and at least one of the propositions in this class must describe
an instance which is either realized in the actual world implying that the examined
counterfactual proposition is true, or the negation of which is realized implying that
the counterfactual proposition is false. Note once more that the proposed account
does not need to construe possible worlds, but refers only to instances which are
realized in the actual world.
A guiding idea is to use the method of difference as a reference point to ﬁll in the
details. As discussed in detail in Sect. 4.2, the most inﬂuential formulation of this
method is of course due to John Stuart Mill: “If an instance in which the phenom-
enon under investigation occurs, and an instance in which it does not occur, have
every circumstance in common save one, that one occurring only in the former; the
circumstance in which alone the two instances differ, is the effect, or the cause, or an
indispensable part of the cause, of the phenomenon.” (1886, 256)
There are several obvious problems (cp. Sect. 4.2.3). First of all, it seems
impossible to ever change only a single factor. At least, the causes and effects of a
considered factor will always change with it. In addition, there will always be
myriads of presumably unrelated conditions in the universe that will be different.
Furthermore, there are a number of situations in which the method does not yield
5.2
Deﬁning Causation
127

results in accordance with usual intuitions. For example, it fails to identify necessary,
but insufﬁcient factors, when additional necessary conditions are not instantiated,
although we habitually speak of those as causes. Furthermore, the method has
problems with cases of overdetermination and preemption. Many authors have
inferred from this rather devastating survey that the method of difference can only
serve as a heuristic rule to identify candidate causal factors—a conclusion, which
certainly contributed to the wide-spread view of causation as a subjective concept.
Here, I will take a different route arguing that the mentioned problems are
solvable by conceptually reﬁning the method of difference. The main trick will
consist in introducing the notion of causal irrelevance as a complement to causal
relevance and to require that the instances compared in the method of difference
differ only in terms of irrelevant circumstances with some exceptions that will be
speciﬁed further below. This condition will be called homogeneity in the
following. Thus:
‘If A were not the case, C would not be the case’ is true with respect to an instance in which
both A and C occur in a context B, iff (1) at least one instance is realized in the actual world
in which neither A nor C occurs in the same context B and (2) if B guarantees homogeneity.
As a next step, homogeneity needs to be deﬁned:
Context B guarantees homogeneity, iff only conditions that are causally irrelevant to C (and
ØC) can change, (i) except for A and (ii) conditions that are causally relevant to C in virtue
of A being causally relevant to C.
Note that, strictly speaking, irrelevance in this deﬁnition of homogeneity must
again be understood with respect to a speciﬁed background, which turns out, in fact,
to be also B excluding of course the considered irrelevant condition itself as well as
other conditions that vary in virtue of changes of the considered condition. Calling to
mind the deﬁnition of a context as provided in the previous Sect. 5.2.2, homogeneity
requires that all other conditions A1, . . ., An with the exception of the considered
condition A are causally irrelevant to C. Homogeneity conditions have occasionally
been evoked in the literature on causality, for example by Baumgartner and Graßhoff
(2004, Sec. 2.4) who formulate a quite sophisticated version of this requirement in
the context of a regularity approach to causation or by Holland (1986, p. 948) who
employs it in the context of a counterfactual theory.
Holland deﬁnes homogeneity of two instances that they exhibit the same value for
the dependent variable given the same value of the independent variable. By
contrast, Baumgartner and Graßhoff deﬁne homogeneity in terms of causal rele-
vance,14 essentially that all causally relevant conditions must remain constant
between instances. A serious problem for the latter account is that the authors are
working with conventional terminology, according to which, as already stated, a
condition is causally relevant basically if it makes a difference to a phenomenon in
some context. Consequently, many conditions are identiﬁed as causally relevant to a
phenomenon that count as causally irrelevant with respect to speciﬁc contexts
14i.e. not causal irrelevance as in the deﬁnition given in the present article.
128
5
Causation as Difference Making

according to the deﬁnitions in the present essay. Even worse, the danger looms large
that according to conventional terminology almost everything is causally relevant to
everything else since one can always construct complex stories where one thing
leads to another. For example, the current position of Jupiter might be used by a
psychic to scare some poor person to an extent that she commits suicide conﬁrming
the very astrological prediction. It seems to follow that the position of Jupiter has to
be held ﬁx to fulﬁll homogeneity when examining causes of suicides. This renders
Baumgartner and Graßhoff’s version of the homogeneity condition a much stronger
requirement than the context-dependent one proposed in this article. In fact, the
former may even turn out inapplicable.
The deﬁnition of homogeneity suggested here in terms of causal irrelevance is
also superior since it is closer to scientiﬁc practice. Judgments of irrelevance seem to
be ubiquitous, e.g. when the range of validity of a causal relationship is extended to
novel contexts. Indeed, one important manner of improving causal knowledge is by
showing that a causal relation that has originally been established for a very speciﬁc
context continues to be stable under the change of an increasing number of condi-
tions, i.e. that these further conditions are irrelevant to the considered phenomenon.
Thus, a general theory of causation without a notion of irrelevance appears not
viable.
Finally, we need to explicate a further concept that appears in the deﬁnition of
homogeneity:
A condition X is causally relevant to C in virtue of A being causally relevant to C with
respect to a context B, iff in all contexts within B, in which X is causally relevant to C, A is
causally relevant to C as well (but not necessarily vice versa).
Remember that contexts within B are all those contexts that are at least as
restrictive as B, i.e. in which some further conditions might be ﬁxed in comparison
with B. Conditions X include those that lie on a causal chain through A to C (both
prior or posterior to A) or are epiphenomena of such conditions. From the difference-
making account as presented above we can immediately derive relation (5.1). That
causal relevance of A to C in a context B implies causal relevance of ØA to ØC in the
same context B, trivially follows from the truth condition for the counterfactual
which requires two situations to exist in the same context B, one where both A and C
are present and one where both A and C are absent.
Let me give an example for the evaluation of causal counterfactuals using again
the story of the Chicago ﬁre. In order to say that the kicked-over lantern is causally
relevant to the barn ﬁre with respect to a background B* ˄ hay ˄ no lightning, we
ﬁrst have to know that on the evening in question the cow kicked over the lantern and
a ﬁre started. Second we have to evaluate the truth-value of the causal counterfactual
“if the lantern had not been kicked over the ﬁre would not have started”. For this, an
instance must be found with the same background B* ˄ hay ˄ no lightning which
differs only in circumstances that are causally irrelevant to the barn ﬁre, except that
the lantern is not kicked over, and the causal conditions leading to the kicked-over
lantern may be different as well as the conditions leading from the kicked-over
lantern to the barn-ﬁre. And indeed, the night before, everything was at the same
5.2
Deﬁning Causation
129

place in the barn except that the cow did not raise its hoof and no ﬁre happened.
Abundant experience suggests that all other circumstances that differed in the two
nights were irrelevant to the barn ﬁre, e.g. what the neighbors did on those evenings,
the chicken running around in front of the barn etc.
The causal counterfactual that appears in the deﬁnition of causal irrelevance is
evaluated in a fully analogous manner:
‘If A were not the case, C would still be the case’ is true with respect to an instance in which
both A and C occur in a context B, iff (1) there exists at least one instance in which A does
not occur but C still occurs in the same context B and (2) B guarantees homogeneity.
Note that with respect to the deﬁnition of homogeneity, there trivially are no
conditions that are causally relevant to C in virtue of A being causally relevant to
C. Obviously, causal irrelevance of A to C with respect to B immediately implies
causal irrelevance of ØA to C with respect to B (relation (5.2) of the previous
section). One might suspect that one can also infer causal irrelevance of A and ØA
to ØC with respect to B. But this is clearly not the case for the simple reason that by
deﬁnition ØC cannot be realized with respect to B if A is causally irrelevant to C and
B guarantees homogeneity.
Let us brieﬂy point out some of the characteristics of the discussed approach to
counterfactuals. First, the approach can only account for the small class of counter-
factuals which were referred to as causal counterfactuals. In particular, it cannot
determine the truth value of counterfactual statements if no instance exists in which
A is not realized with respect to the same background B. Sometimes, idealizations
and simpliﬁcations may help, for example when determining the causal nature of the
gravitational interaction of the planets in the solar system. But in many situations,
this is impossible. The above account just cannot provide any clue, whether
New York would exist, if the Neandertals had survived, or who would have won
the Korean War, if Caesar had led the UN-forces. In a way, the difference-making
approach to counterfactuals singles out those cases in which an objective evaluation
is possible modulo the speciﬁc problem of induction discussed in Sect. 6.2.
Second, one might be tempted to think that the presented account for evaluating
counterfactuals is just a special case of Lewis’s possible world approach. But this is
clearly not true. For one thing, the given account evaluates counterfactuals based on
actual phenomena occurring in the one and only world accessible to human expe-
rience and not with respect to possible worlds.15 Also, the measure of comparison
between different situations is not at all a similarity measure of the kind as David
Lewis had envisaged it. In the difference-making approach, the ‘measure’ is only a
two-valued function: either homogeneity is fulﬁlled for two situations, i.e. the two
situations differ only in terms of irrelevant circumstances, or not. Moreover, this
measure depends not only on the two situations or states that are compared, but also
on the phenomenon C and the potential cause A as is clear from the deﬁnition of
15Given that the proposed account refers to the actual world, one might think that it really is about
indicative conditionals. But obviously, this is not the case since the target of analysis clearly is a
counterfactual proposition.
130
5
Causation as Difference Making

homogeneity. By contrast, similarity is usually framed as a gradual and universal
measure that only depends on the compared instances, not on the epistemological
aim, i.e. in this case the causal relation which is examined. For example, Lewis’s
similarity measure between possible worlds only depends on these worlds and not on
the events mentioned in the considered counterfactual statement. Finally, let me
emphasize again that the measure of comparison in the difference-making approach
does not exhibit the subjectivity and vagueness that Lewis associated with similarity.
Third, the suggested account of causation prioritizes singular causation, since the
deﬁnition of causal relevance refers to a speciﬁc instance in a certain context with
respect to which counterfactual questions are asked. Clearly, a causal relationship
can be established without any actual or even potential regularity, based only on two
instances as required in the deﬁnition of causal relevance. On the other hand, causal
regularities may follow if the relevant conditions under which the causal relationship
has been established are in combination so weak that the relationship is repeatable.
But note that such causal regularities always remain context-dependent, they pre-
serve a distinct ceteris-paribus character in that all relevant conditions can never be
made explicit in total.16
Finally, a crucial restriction of the account as outlined thus far is that it works only
for deterministic contexts. For example, in a situation of indeterminism, conditions
might be identiﬁed as irrelevant even though they are statistically relevant for a
phenomenon. But an extension of the framework to reasonable cases of indetermin-
ism is quite straightforward as will be outlined in Sect. 6.2 and discussed in much
further detail in Chap. 9.
5.2.3
Remarks on the Asymmetry of Causation
A perennial problem plaguing the debate on causation concerns the nature and origin
of the causal asymmetry in particular in relation to the temporal asymmetry and
various connected asymmetries (Hausman 1998; Price and Weslake 2009; Frisch
2014, Ch. 5). It is clear that the account given so far cannot be sufﬁcient. Most
importantly, the deﬁnition of causal relevance is almost—though not fully—sym-
metric with respect to the role of A and C, while causal relevance certainly is not a
symmetric concept. In most cases, causal relevance of A to C does not imply causal
relevance of C to A.
Let us therefore focus brieﬂy on the asymmetric aspects in the deﬁnition of causal
relevance. There is an asymmetry in terms of the context dependence in that the
conditions that are held constant in the background are usually required not to be
16With respect to universal regularities that are not context-dependent like the axioms of physical
theories, I have argued in Chap. 3 that these do not have an exclusively empirical character but are
rather of conventional or deﬁnitional nature, in line with conventionalist ideas brought forward in
particular in the second half of the 19th century by Poincaré, Duhem, Mach, and others.
5.2
Deﬁning Causation
131

causally and temporally posterior to the examined phenomenon. This holds both for
causal relevance and for causal irrelevance. But note that there is a further asymme-
try for the latter in that even without background dependence the situation is not
symmetric with respect to A and C. After all, causal irrelevance of A to C requires
two situations to be observed, namely A and C co-occurring as well as ØA and C
co-occurring, while by deﬁnition ØC cannot occur with respect to background B.
One crucial question is whether time coordinates must be introduced for all events
in order to account for the asymmetry of causation. While time coordinates may be
pragmatically useful, I believe that sub specie aeterni, they should be dispensable—
if assuming in the tradition of Leibniz and others that time is ultimately a relational
concept that describes how phenomena evolve in relation to other phenomena. Thus,
if all changes in the world were of causal nature, then the asymmetry of time should
be reducible to asymmetries of causation.
I will in the following brieﬂy sketch an argument, according to which both
temporal ordering and the temporal asymmetry can be linked to the notion of causal
chains. It belongs to our basic human experiences that there are processes, which
closely link several events C1, . . ., CN by means of causal relevance with respect to a
relatively broad and stable context B*: any Ci is causally relevant for any Cj with
respect to B* (at least for i < j). It is also the case that we can often interfere with such
systems in a targeted manner. Let us therefore further introduce N interruption events
I1, . . ., IN and as many stimulation events S1, . . ., SN: an interruption event Ii prevents
Ci from occurring, thus basically is an inhibiting cause of Ci in the presence of Ci-1.
A stimulation event Si is an event that starts or upholds a causal process, i.e. an
alternative cause of Ci instead of Ci-1. Both interruption and stimulation events can
be thought of as external interventions in the system comprising C1, . . ., CN.
Obviously, B* as framed before must include the absence of interruption and
stimulation events to ensure causal relevance between the members of the causal
chain.
Let me give two examples: ﬁrst, a chain of toothed wheels, where each toothed
wheel moves a subsequent toothed wheel. Here, event Cx is the rotation of wheel
number x. In the second example, billiard balls collide elastically on a linear track.
Here, event Cx is the setting in motion of ball x by the previous ball x-1. Both
examples concern extremely stable processes, where one event regularly leads to the
next with respect to a wide variety of backgrounds. The crucial difference concerns
the fact that in the ﬁrst example the interaction is instantaneous (at least according to
classical physics), in the second it is not.
It is easy to see that causal chains introduce a deﬁnite causal ordering through the
notion of interruption and external stimulation. Consider the chain of toothed
wheels. In the presence of an interruption, two groups of wheels result, such that
relations of causal relevance remain that link every element with every other within
each group, while all wheels belonging to different groups are causally irrelevant to
each other. In a causal chain linking N events, there are N-1 possibilities to interrupt
leading to N-1 different groupings, which in turn imply a deﬁnite causal ordering of
the Cs. After all, the groupings can be arranged in a way that neighboring groupings
132
5
Causation as Difference Making

differ only in terms of one of the Cs changing sides. In this manner, causal ordering
can be constructed for a large class of phenomena from experience.
As already mentioned, the main difference between the two examples is that the
chain of billiard balls introduces a causal asymmetry, i.e. a speciﬁc direction in the
chain. After all, in the example of the toothed wheels, we have for any stimulation
event S that they are possible alternative causes for all C. The situation is asymmetric
in the example of the billiard balls in that only for one end of the chain all S are
possible alternative causes or more generally, for Ci only all Sj with j  i are possible
alternative causes. This introduces a causal asymmetry in such processes that can be
identiﬁed with the temporal asymmetry. The asymmetry is in accordance, of course,
with the basic experience that while we can inﬂuence the future, we cannot inﬂuence
the past. Thus, the basic suggestion is that the time asymmetry derives (at least
partly) from the experience that there are processes which exhibit the described
causal asymmetry with respect to interventions and stimulations.
Thus, by means of the notion of causal chains, both an ordering and an asymme-
try can be established. Arguably, this causal ordering and asymmetry are at the basis
of our spatial and temporal ordering of the world. Spatial relationships correlate
closely with the question how easily one can causally interact with certain events and
I very tentatively believe that space should eventually be reducible to this feature of
causation. A point that was not addressed thus far is why the ordering relations and
the asymmetry should be universal, i.e. imply a universal spatial and temporal
ordering as well as a universal time direction for all human experience. The brief
answer is that none of the causal chains depicted above exists in isolation. Rather,
every phenomenon is embedded in a large web of causal relations. Through this web,
the ordering can be transferred and compared with other events. Indeed, if the
empirical world fell apart in two or more causally separated regions, the sketched
perspective would imply that there could be no spatial and temporal relations
between these regions.
5.3
A Causal Calculus
5.3.1
Causal Factors and Alternative Causes
Causal relevance and causal irrelevance are the fundamental building blocks of the
proposed counterfactual account of causation. Other causal notions can be deﬁned
on this basis by what one might call a causal signature, which states in which speciﬁc
contexts a factor is causally relevant and in which it is causally irrelevant. Most
importantly, by this approach, we will be able in the following to reproduce the inus-
logic of causal factors that arguably constituted John L. Mackie’s most important
contribution to the debate on causation.
A crucial concept is that of a causal factor A for phenomenon C with respect to a
background B. A causal factor is not itself sufﬁcient in the context B to produce the
5.3
A Causal Calculus
133

phenomenon C, but requires other factors X to be instantiated at the same time. The
deﬁnition of causal factors can be stated as follows:
A is a ‘causal factor’ for phenomenon C with respect to background B, iff there exists an X
such that A is causally relevant to C with respect to B˄X and irrelevant to ØC with respect to
B˄ØX (i.e. C is always absent in B˄ØX).
As is easy to see, it follows: X is relevant to C with respect to B˄A and causally
irrelevant to ØC with respect to B˄ØA, i.e. X is also a causal factor for C with
respect to B. After all, according to the above deﬁnition, the states A˄X˄C˄B,
ØA˄X˄ØC˄B, A˄ØX˄ØC˄B, ØA˄ØX˄ØC˄B must exist. We can combine the
ﬁrst and the third state to show that X is relevant to C with respect to B˄A and the
second and fourth state to show that X is causally irrelevant to ØC with respect to
B˄ØA.
Note further that X cannot be redundant with respect to A, i.e. A cannot itself be
causally relevant to C with respect to B. Equally, A cannot be redundant with respect
to X. In other words, the deﬁnition already implies, what Baumgartner has called the
principle of non-redundancy with respect to causal factors (2013).
From the deﬁnition follows theorem <I>:
If and only if A is a causal factor, then A˄X is causally relevant to C with respect to B. (A˄X
R C | B $ A R C | B˄X and A I ØC | B˄ØX)17
After all, according to the deﬁnition of causal relevance, we need to observe A˄X
as well as Ø(A˄X)¼ ØA˅ØX. If we introduce the additional requirement18 that in
the case of ˅-connections all possible combinations of conditions must be realizable,
we thus need to observe the following four instances A˄X˄C˄B, ØA˄X˄ØC˄B,
A˄ØX˄ØC˄B, ØA˄ØX˄ØC˄B, which are exactly the ones mentioned before when
introducing the notion of a causal factor.19
In the example of the Chicago ﬁre of the previous section, we had identiﬁed
(kicked-over lantern ˄ hay) ˅ lightning as possible causes in some context B*. Thus,
the kicked-over lantern is a causal factor A of the barn ﬁre C with respect to a
background B* ˄ no lightning with presence of hay being the complementary
factor X.
The second concept required for establishing the inus-logic is that of an alterna-
tive cause:
A is an ‘alternative cause’ to C with respect to background B iff there exists an X such that A
is causally relevant to C with respect to a background B˄ØX, but causally irrelevant to C
with respect to a background B˄X (i.e. C is always present in B˄X).
17Here, X refers to the same quantity as in the deﬁnition of causal factor.
18which is implicit in the deﬁnition of alternative causes.
19From the second and third instance taken together nothing follows, the ﬁrst and fourth can be
combined as A◊X R C | B according to terminology introduced in Sect. 5.3.3. According to a
theorem derived there, it follows from the ﬁrst and fourth state that there is an inus-complex drawing
on A and/or X which is causally relevant to C.
134
5
Causation as Difference Making

It immediately follows that X is causally relevant to C with respect to a back-
ground B˄ØA, and causally irrelevant to C with respect to a background B˄A, i.e. X
is also an alternative cause to C with respect to B. After all, the deﬁnition of an
alternative cause requires the following states: A˄ØX˄C˄B, ØA˄ØX˄ØC˄B,
A˄X˄C˄B, ØA˄X˄C˄B. Again, we can recombine these: the second and fourth
to show that X is causally relevant to C with respect to a background B˄ØA, the ﬁrst
and third to show that X is causally irrelevant to C with respect to a background
B˄A. An example in the Chicago ﬁre case is lightning as alternative cause to
(kicked-over lantern ˄ hay).
Again, the deﬁnition implies Baumgartner’s principle of non-redundancy, now
with respect to alternative causes. Essentially, non-redundancy for the difference-
making account amounts to the requirement that all possible combinations deter-
mined by the ˅-connector, if it appears in positive and/or negative instances actually
occur.
It follows theorem <II>:
If and only if A is an alternative cause, then A˅X is causally relevant to C with respect to
B. (A˅X R C | B $ A R C | B˄ØX and A I C | B˄X)20
This is again easy to see. Causal relevance requires that (A˅X)˄C as well as
Ø(A˅X)˄ØC ¼ ØA˄ØX˄ØC are instantiated. Keeping in mind that in case of the
˅-connection all possible combinations must occur, this results in the four combi-
nations listed after the deﬁnition of alternative causes.
Theorems <I> and <II> allow for a pragmatic way to deal with several causal
factors and several alternative causes, since according to them every condition can
itself be considered a more complex operator of several alternative causes and causal
factors.
Finally, let me introduce a related notion of alternative causes relying on an
exclusive (˅) ‘or’ rather than a non-exclusive (˅) ‘or’ and which shall be referred to
as substitute cause in the following. Regarding the state A˄X˄B several options are
possible. For example, such a state may be impossible, if A and X are incompatible,
or two instantiations of C could result, if both A and X produce an instantiation
separately.21 The latter case will be taken up when discussing concomitant variations
in Sect. 5.3.4.
We now have the conceptual resources to deﬁne the crucial notions of an inus-
condition and of an inus-complex based on causal factors and alternative causes:
A factor X is an ‘inus-condition’ for C with respect to a background B, iff X is a causal factor
of a condition A that is causally relevant to C with respect to a background (B plus absence
of all alternative causes for C, of which there is at least one). 22
20Here, X refers to the same quantity as in the deﬁnition of an alternative cause.
21Correspondingly, there could be special types of causal factors, where the absence of both A and
X is not instantiated.
22There is a slight ambiguity, since one might want to distinguish alternative and substitute causes,
here. But nothing much hinges on this choice.
5.3
A Causal Calculus
135

The notion is largely identical with Mackie’s concept of an inus-condition, i.e. it
constitutes a direct translation of what an “insufﬁcient, but non-redundant part of an
unnecessary, but sufﬁcient condition” amounts to in terms of alternative causes and
causal factors. As we had seen, the required non-redundancy23 is implied already by
the deﬁnitions of causal factors and alternative causes, though in Sect. 5.3.3 one
slight deviation from Mackie’s understanding of non-redundancy will be introduced
in order to render the proposed concept of an inus-condition transitive. Furthermore:
A complex of conditions of the form (X˄Y)˅Z shall be called an ‘inus-complex’ for C with
respect to B, iff it is causally relevant to C with respect to B. Note that each condition X, Y, or
Z may itself be an inus-complex. By deﬁnition, it may be the case that Y¼1 and/or Z¼0.
Essentially, an inus-complex is a condition that is itself causally relevant and
consists of an arbitrary number of alternative causes that are each composed of an
arbitrary number of causal factors. In the example, the kicked-over lantern would be
an inus-condition, and (kicker-over lantern ˄ hay) ˅ lightning would be an inus-
complex.
Let me also introduce the notion of an inhibiting factor:
Condition A is an ‘inhibiting factor’ counteracting a causally relevant X for C with respect
to background B iff X is causally relevant to C with respect to B˄ØA; X is causally irrelevant
to ØC with respect to a background B˄A.
According to this deﬁnition, we have the following states ØA˄C˄X˄B,
ØA˄ØC˄ØX˄B, A˄ØC˄X˄B, A˄ØC˄ØX˄B. A recombination of these yields
the following: A is causally relevant to ØC with respect to B˄X; A is causally
irrelevant to ØC with respect to a background B˄ØX. Note that an inhibiting cause A
is not a causal factor for C, but ØA fulﬁlls the deﬁnition. Thus, A is an inhibiting
factor counteracting X for C with respect to background B, if and only if ØA is a
causal factor for C with respect to background B.
Finally, a further notion is that of a common cause:
A is a ‘common cause’ to X and Y with respect to a background B, iff in all backgrounds
within B, in which X R Y and/or Y R X, we also have A R X and A R Y.
There are certain difﬁculties distinguishing various causal structures: common
cause; a causal chain A-X-Y or A-Y-X; a situation, where X and Y are deﬁnitionally
related etc. For lack of space, we cannot go into details, here. Essentially, what is
required for a common cause structure is that there are backgrounds within B, where
X is causally irrelevant to Y and/or vice versa, because X and/or Y are caused by
conditions other than A. In a way, the approach to common causes as outlined above
is a deterministic version of Reichenbach’s screening-off condition, which essen-
tially states that when there is correlation between two effects this can be completely
attributed to the common cause. Here, the analogous statement holds that when there
is causal relevance between effects, it can be completely attributed to the causal
23sometimes also referred to as minimality.
136
5
Causation as Difference Making

relevance of the common cause. The probabilistic version should follow given an
appropriate account of causal probability—a topic to be addressed in Chap. 9.
At the end of this section, let me elaborate in some additional depth on the notion
of causal irrelevance. First, we have theorem <III> regarding the extension or
widening of backgrounds:
A I C | B˄X and A I C | B˄ØX ! A I C | B˄x, if X, ØX are all possible values of x.24
A R C | B˄X and A R C | B˄ØX ! A R C | B˄x, if X, ØX are all possible values of x.
This follows in a straightforward manner from the deﬁnitions of causal relevance
and irrelevance. Since variables with more than two possible values can always be
expressed in terms of binary variables, an extension to discrete variables in general is
straightforward. These relations address the problem of Mackie’s account of varia-
tional induction, how ﬂexible background dependence can be introduced based on
the notion of causal irrelevance.
As a matter of terminology, let me also introduce the notion of irrelevance*,
which applies to contexts in which relevant factors are allowed to change (theorem
<III*>):
A I C | B˄X and A I ØC | B˄ØX ! a I  c | B˄x, if A, ØA are all possible values of a; C,
ØC all possible values of c; and X, ØX all possible values of x.
In other words, a circumstance is irrelevant* to a phenomenon, if it is separately
irrelevant (without *) to the phenomenon with respect to all different backgrounds in
which only irrelevant conditions can change. From A I C | B˄X and A I ØC |
B˄ØX follow four equivalent expressions: A I  C | B˄x; A I  ØC | B˄x; ØA I  C |
B˄x; ØA I  ØC | B˄x. In short, this shall be expressed as a I  c | B˄x. Again, the
notion irrelevance* is required, when irrelevance of conditions is stated in contexts
where relevant conditions may change. In particular, when we required in the
explication of homogeneity that all conditions in the background that can vary are
causally irrelevant, this should actually have been irrelevant*.
We also have theorem <III**>:
A˅D I C | B ! A I C | B˄d and D I C | B˄a, where d can take on the values D or ØD and
a the values A or ØA.
Furthermore, A˅D I C | B $ A˄D I C | B.
The second part follows from the deﬁnition of causal irrelevance plus the
requirement that for ˅-connections, all possible combinations must be realized. It
is then easy to show that for both A˅D and A˄D the following states must be
realized: D˄A˄C˄B, ØD˄A˄C˄B, D˄ØA˄C˄B, ØD˄ØA˄C˄B leading to the
stated equivalence. The ﬁrst part follows from these states using theorem <III>.
Here, the converse arrow does not hold since again it is not required that all possible
combinations in the background are instantiated.
24There is no double arrow, since it is generally not required that all possible combinations in the
background must actually occur.
5.3
A Causal Calculus
137

Conversely, the following theorem <IV> demonstrates how relationships for a
narrower background can be derived from relationships for a wider background:
A ^ X RC j B ! ARC j B ^ X;
A ^ X RC j B ! AIØC j B ^ ØX;
A ^ X RC j B ! AI C j B ^ X;
A ^ X RC j B ! ARC j B ^ ØX:
These relationships follow directly from the deﬁnitions of causal relevance for
circumstances connected by ˅ or ˄ (see appendix).
5.3.2
Effect Factors and Alternative Effects
While the logical structure of the causes in terms of inus-conditions is generally
addressed in various accounts of causation, the logical structure of the effects is
rarely examined. In the following, I propose the analogous notions of alternative
effects and effect factors, which will become important in the next section when
causal hierarchies are considered.
An effect factor can be deﬁned in the following way:
C is an ‘effect factor’ of the cause A with respect to a background B iff there exists an X such
that A is causally relevant to C˄X with respect to background B.
This implies the following situations due to Ø(C˄X) ¼ ØC˅ØX: A˄X˄C˄B,
ØA˄ØX˄C˄B, ØA˄X˄ØC˄B, and ØA˄ØX˄ØC˄B. It follows that A R X | B˄C
and A R C | B˄X. Note that here the additional conditions in the background are
effects and not causal conditions as was always assumed up to now. However, one
could read this notation merely as shorthand for the requirement that the causal
conditions determining these respective effects are held constant. As an example for
the notion of an effect factor, consider how, during that night in Chicago in October
1871, the barn ﬁre ﬁrst spread to two immediately adjacent buildings. It follows that
if the barn ﬁre had been different that night, one or both of the buildings would not
have caught ﬁre or at least would have burnt in a different way.
While this may sound plausible, the notion of an effect factor is fraught with one
additional difﬁculty. The four states listed above suggest a conclusion, which stands
in contradiction with the combined premises of homogeneity and determinism:
namely that a change in the effects may happen without a change in possible causes,
e.g. when comparing ØA˄ØX˄C˄B and ØA˄X˄ØC˄B. The somewhat obvious
solution is to assume an inner causal structure for A according to which the change
from ØX˄C to X˄ØC is determined. Thus, we have to presuppose that given a
Boolean structure of the effect, the cause must have a corresponding structure that is
at least as detailed. Let us call this the causal structure assumption.
138
5
Causation as Difference Making

An alternative effect can be deﬁned in an analogous way:
C is an ‘alternative effect’ of the cause A with respect to a background B iff there exists an X
such that A is causally relevant to C˅X with respect to background B.
Due to Ø(C˅X) ¼ ØC˄ØX, this implies the situations: A˄X˄C˄B, A˄ØX˄C˄B,
A˄X˄ØC˄B, and ØA˄ØX˄ØC˄B. It follows A R X | B˄ØC and A R C | B˄ØX.
As an example consider an arsonist walking around late at night with a single torch
A. He sets either barn C or barn X on ﬁre, but it may well happen that in the end both
barns burn down. Again, the additional difﬁculty of a possible violation of deter-
minism arises and is once more resolved by presupposing the causal structure
assumption.
A further important notion is that of a substitute effect:
C is a ‘substitute effect’ of the cause A with respect to a background B iff there exists an X
such that A is causally relevant to (C˅X) with respect to background B, where X˄C cannot
occur with respect to B under condition of homogeneity.
This concept plays an important role in the analysis of concomitant variations
where a member of a certain class of causes can individually cause any one but only
one member of a certain class of effects. We have: A R X | B˄ØC and A R C |
B˄ØX. And again we have to assume a corresponding Boolean structure for the
cause to avoid contradictions.
For causal irrelevance the following holds regarding effect factors:
AI C ^ X j B $ AI C j B ^ X $ AI X j B ^ C
After all, for all three expressions the following situations are required:
A˄X˄C˄B, ØA˄X˄C˄B. For alternative effects C˅X, possible states are C˄X,
C˄ØX, and ØC˄X, i.e. changes in effects are feasible and one therefore has to
employ the notion of irrelevance*. Generally, if a I  c | B˄x and a I  x | B˄c then
a will be irrelevant* to all possible inus-complexes consisting of C, X, and/or their
negatives.
5.3.3
Causal Hierarchies and Transitivity
A crucial requirement regarding the pragmatics of causation is that one can look at
causal relations at a variety of different resolutions, both horizontally, i.e. when
considering causal chains, and vertically, i.e. when looking at the formulation of
causes and effects at various levels of coarse-graining, e.g. macro- and micro-levels.
Let us discuss the vertical relations ﬁrst. Certainly, causal factors can be formu-
lated in different levels of detail: for example, we might generally claim that the
kicked-over lantern caused the ﬁre while actually referring to a bundle of conditions
that includes the kicked-over lantern itself, the spilled oil, the presence of hay, the
absence of rain etc. Some basic rules for the coarse-graining of causes were already
5.3
A Causal Calculus
139

derived in Sect. 5.3.1 in terms of theorems <I> and <II> demonstrating that an inus-
complex can itself be considered causally relevant. Equally, in Sect. 5.3.2, some
results concerning the coarse-graining of effects were presented.25
However, often the exact inus-conditions are unknown. Rather, one may be
confronted with just a bundle of conditions which apparently have an impact on a
certain phenomenon. The following theorem <V> is supposed to cover those cases:
If one observes under homogeneity the following two states: A1, . . ., An present with C as
well as ØA1, . . ., ØAn present with ØC (notation for this evidence situation: A1◊A2◊. . .◊An
R C | B), then there is an inus-complex among the A that is causally relevant to C with
respect to B.
Obviously, the conclusion follows directly from the assumptions of homogeneity
and determinism. The theorem is important, because the set-up corresponds to a
typical situation that arises in scientiﬁc practice, in which we observe presence and
absence of a larger number of conditions but do not yet have any clue about the exact
causal structure. In particular, it may very well be the case that some of the A are
actually irrelevant to C. However, the experimenter knows in such situations that the
difference-maker is among the differences between the two situations.
To illustrate the theorem, consider the simple situation that we observe A1 and A2
present with C and ØA1 and ØA2 present with ØC, then there are the following
possibilities: (i) A1 R C and a2 I  c; (ii) a1 I  c and A2 R C; (iii) A1˅A2 R C;
(iv) A1˄A2 RC. This is an exhaustive set, since there are exactly four possibilities to
choose C for the remaining situations ØA1˄A2 and A1˄ØA2.26 Generalizations to a
larger number of conditions are straightforward. Note that a statement analogous to
theorem <V> does not hold for causal irrelevance. After all, there may for example
be inhibiting causes among the A.
Of course, it should also be possible that we consider a phenomenon on various
levels of coarse-graining on the side of the effects:
If one observes under homogeneity the following two states: A present with C1, . . ., Cn as
well as ØA present with ØC1, . . ., ØCn (notation: A R C1◊C2◊. . .◊Cn | B), then given
determinism there is an inus-complex that must include all C and to which A is causally
relevant. According to the causal structure assumption there must be a corresponding inus-
structure hidden in A.
If we observe under determinism that A and ØA are both present with C1, . . ., Cn
under condition of homogeneity, we can of course conclude that A is irrelevant to all
individual C with respect to a background that includes the presence of all other C’s,
respectively. While we have thus far examined coarse-graining in the causes and the
effects, separately, a combination of both brings no further difﬁculties.
25Note that statistical methods like randomized control trials or propensity score matching essen-
tially rely on coarse graining as well, more speciﬁcally the construction of higher-level concepts, in
this case populations, for which a causal analysis is feasible.
26It may of course also be the case that some of these situations are not observable or even
impossible, which would leave the causal structure underdetermined.
140
5
Causation as Difference Making

Let us conclude the part about causal hierarchies by commenting on an issue that
is widely discussed in current literature. According to the proposed account causal
relationships may exist between various levels of coarse-graining as long as there is
general consistency. In particular, there can be causation from the micro- to the
macro-level and vice versa.
Let us next examine transitivity, which is closely connected with the feasibility of
different horizontal resolutions. Many authors have considered transitivity a funda-
mental requirement of causal relationships, while others completely deny that it
constitutes a property of causation, mainly in reaction to some pertinent counterex-
amples, which will be discussed below. Essentially, I will broadly follow David
Lewis’s suggestion that some causal notions are transitive while others are not.
Notably, in the difference-making account causal relevance is a transitive concept,
while causal irrelevance is not:
If X is causally relevant to Y with respect to B and Y is causally relevant to Z with respect
to B, then X is causally relevant to Z with respect to B.
This is just a consequence of the deﬁnition of causal relevance. As deﬁned in
Sect. 5.2.1, causal relevance amounts to an “iff . . ., then . . .” relation (plus the causal
asymmetry), which is trivially transitive. It follows:
If X is causally irrelevant to Z wrt B, then there is no Y such that X is causally relevant to Y
wrt B and Y is causally relevant to Z wrt B.
But note that causal irrelevance is not a transitive notion, i.e. it does not hold: If X
is causally irrelevant to Y and Y is causally irrelevant to Z, then X is causally
irrelevant to Z. Certainly, shooting at someone is irrelevant for the sun rising at that
very moment and the sunrise will be irrelevant to the death of the person, but the shot
is still very relevant to the death.
By contrast, the notions of causal factor, alternative cause and inus-condition are
also transitive:27
If X is a causal factor (alternative cause, inus-condition) for Y wrt B and Y is a causal factor
(alternative cause, inus-condition) for Z wrt B, then X is a causal factor (alternative cause,
inus-condition) for Z wrt B.28
This again follows from the respective deﬁnitions of causal factors, alternative
causes, and inus-conditions. Let me provide the sketch of a proof for the transitivity
of inus-conditions. Given that X is inus-condition for Y, i.e. there exist a D and E
such that ‘if and only if (X˄D) ˅ E then Y’ and Y is inus-condition for Z, i.e. there
exist an F and G such that ‘if and only if (Y˄F) ˅ G then Z’. It follows that ‘if and
only if (X˄D˄F) ˅ (E˄F) ˅ G then Z’. While this expression already looks much as if
27I am much indebted to Michael Baumgartner for apt criticism of earlier versions of my claim
concerning the transitivity of inus-conditions. Among other things, I owe him the reference to the
switching examples that are discussed further below.
28One should exclude well-deﬁned cases of the type as the potassium salt-ﬁre-death example
discussed below.
5.3
A Causal Calculus
141

X were an inus-condition for Z, it remains to be shown that X is indeed a
non-redundant part of an alternative cause of Z.
Thus, assume that X is non-redundant for Y with respect to D and that Y is
non-redundant for Z with respect to F. It must be proven that X is non-redundant for
Z with respect to D˄F. Two problematic situations can arise: X can be redundant for
Z with respect to D˄F, if either (i) X is fully contained as a factor in D˄F or if (ii) X
determines only such aspects of Y that are irrelevant for Z or (iii) a mixture of both
cases. Since the third situation adds nothing essentially novel, it sufﬁces to consider
the ﬁrst two.
Ad (i), there must be substantial overlap between the factors Y and F (and
possibly between X and D). In this situation, D˄F contains factors that have the
same effect as X, which could either be X itself or an alternative to X with the same
effect. In both cases X remains an inus-condition of F.
Ad (ii), this corresponds to the example of the potassium salts and the ﬁre, which
is discussed further below. In such cases, it must be ensured that all components of a
sufﬁcient condition have a causal function, in particular those factors that become
explicit only through earlier links in a causal chain. Thus, the more precisely one
knows what exactly is causally relevant for each link in a causal chain, the more
plausible that inus-conditions will turn out transitive.
The transitivity of causal factors and of alternative causes follows in exactly the
same way, if E and G are set to zero or D and F are set to one, respectively. In the
case of causal factors it again has to be ascertained that causal factors earlier in the
chain remain relevant to later links.
At this point, we need to address what some take to be the classic counterexample
against the transitivity of inus-conditions, namely so-called switching structures (see
in particular Baumgartner 2013, Fig. 3). Consider a train that travels from A to B
either passing through C if a switch is in position E or passing through D if the switch
is in position ØE. Now, A˄E is at least inus for C and C is at least inus for B, but E is
not at least inus for B, since (A˄E)˅(A˄ØE)¼A is a sufﬁcient and necessary
condition for B. In other words, E does not seem part of a minimal sufﬁcient
condition for B, which by Mackie is deﬁned as: “none of its conjuncts is redundant,
no part of it [. . .] is itself sufﬁcient” (1980, 62). Rather, E in A˄E seems to be
redundant, since A is already sufﬁcient for B.
In such cases, I would reply that one should qualify the type of redundancy
involved here. After all, it is not the case that A is complemented with an arbitrary ˄
(E˅ØE), which would certainly be absurd. Rather, E and ØE stand for different
causal paths how B can be reached from A. One might want to speak of non-
redundancy post factum since the additional factor designates the exact causal
pathway on which a certain effect is reached. The importance of distinguishing
pathways is further underlined when the causal structure is slightly altered. For
example, one could specify the events B according to their causal history as BC and
BD. Then E and ØE are non-redundant for BC and BD, respectively. Or, when an
interference factor breaks one of the pathways either through C or D, then E or ØE,
respectively, will become non-redundant for B. Thus, when claiming the transitivity
of inus-conditions, the possibility of such non-redundancy post factum must be
142
5
Causation as Difference Making

taken into account as well. From another perspective, one could question, whether
the chosen labeling as E and ØE is misleading, i.e. whether it is indeed appropriate to
label one position of a switch as the negation of the other position. In this respect, the
notion of non-redundancy used in the present article differs from Mackie’s view-
point and that of many contemporary authors, especially those, who have argued for
the intransitivity of inus.
Let us take a look at some further stock examples brought forward against the
transitivity of causation (see e.g. Paul and Hall 2013, Ch. 5). One of them is the
following: A man is hiking in the mountains. Suddenly, a rock is set in motion and
starts rolling towards him. He crouches down and survives. In this speciﬁc situation,
it could seem that the falling rock somehow is causally responsible for the survival of
the hiker, which certainly sounds counterintuitive.
The ﬁrst important remark is that according to the account of causation presented
here, transitivity only holds with respect to a ﬁxed context or background. In many
alleged counterexamples to transitivity, including the one just outlined, background-
dependence is not guaranteed. This neglect is at least partly responsible for some of
the putative paradoxes of transitivity.
Let us depict the formal structure of the mentioned example, which is in fact
analogous to that of many similar counterexamples. The background B* broadly
concerns someone hiking in the mountains on a trail with rocky grounds above him.
The various events are: the falling of a rock R from somewhere above the hiker, the
crouching C of the hiker, some additional conditions X under which the hiker
crouches in case of a falling rock, in particular that he realizes it early enough, and
ﬁnally either death D or survival S ¼ ØD of the hiker. The following relations hold:
R R D j B ^ C
ð5:3Þ
R I S j B ^ C
ð5:4Þ
R ^ X R C j B ! R R C j B ^ X
ð5:5Þ
C R S j B ^ R
ð5:6Þ
C I S j B ^ ØR
ð5:7Þ
We can already deduce from (5.3, 5.5, and 5.6) that there is no transitivity in
terms of causal relevance. However, this is consistent with the general claims above
since the background changes, while transitivity of causal relevance holds only in
the case of constant background. It follows using theorems <I> and <II>:
R ^ ØC R D j B
$ ØR ^ C R S j B
ðfrom 5:3, 5:4, 5:6, 5:7Þ
ð5:8Þ
! ØR ^ ðR ^ XÞ R S j B
ðfrom 5:5Þ
ð5:9Þ
The double arrow in (5.8) also results from negation (5.1). According to (5.9), R
is formally an inus condition of S with respect to background B* corroborating the
transitivity of the (at least) inus-relation with respect to a constant background.
5.3
A Causal Calculus
143

However, it is a strange kind of inus-condition. After all, it follows from (5.9) via the
deﬁnition of alternative causes:
R ^ X R S j B ^ R
ð5:10Þ
Obviously, the ﬁrst R is redundant, since it is already ﬁxed by the background. In
fact, in (5.9) the second R can be dropped without changing the content of the
statement. 29 This redundancy directly correlates with the fact that no background
within B* exists, in which R is causally relevant to S, only backgrounds in which ØR
is causally relevant to S. Certainly, this situation implicitly contributes to the wide-
spread refusal to see R as a cause for the survival. Again, the justiﬁcation for seeing
R as non-redundant is that it designates a speciﬁc causal path, which requires R˄X in
order for the crouching C to happen.
The sketched formal analysis in terms of the difference-making account can
clarify to what extent transitivity holds and why R is such a peculiar inus-condition
in this example. By the way, Lewis presents a closely related analysis of an
analogous case (2000, 194–195) claiming that our reluctance to accept R as a causal
factor stems from several issues: (i) R and ØR both appear as at least inus-conditions
(Lewis is not using the term), which may lead to confusion, but in principle there is
nothing wrong with this double role; (ii) in most cases, the falling of a rock leads to
death and not to survival, i.e. judging by the number of possible realizations, the
presence of R all in all increases the probability of death for the hiker; (iii) falling
rocks do not matter for a careful hiker, who will always survive: if X ¼ 1, then (5.9)
becomes ØR ˅ R ¼ 1 R S | B*, i.e. the hiker always survives.
There are other supposed counter-examples to transitivity. A well-known one is
the following that was already alluded to: suppose that potassium salts P put into the
ﬁre place are a cause of the ﬁre turning purple, and that the ﬁre F is a cause of the
eventual death D of a person. Are the potassium salts then a cause for the death?
Plausibly not. The seeming paradox can be easily dissolved within the framework of
the difference-making account. In the case that we are largely ignorant about the
working of ﬁres, we may ﬁnd that purple ﬁres are indeed causally relevant to the
death of a person, i.e. P◊F R D | B*. However, by taking into account further
instances, it can be established that it was not the color of the ﬁre that killed but other
properties: P I D | B*˄F and P I ØD |B*˄ØF, therefore p I  d | B*˄f by theorem
<III*>. The addition of potassium is not an inus-condition for the ﬁre as a cause of
death, except in the artiﬁcial non-causal sense: (P˄F)˅(ØP˄F) R D | B*. Crucially,
we do not have non-redundancy post factum in this case since P and ØP do not
constitute different pathways leading to D, i.e. pathways that can be independently
interrupted. In summary, there is no transitivity, because the potassium salts are
causally irrelevant to the death.
29Note also that the requirement stated in Section 3a that all feasible combinations must be realized
is clearly not possible for the expression in (5.9), e.g. ØR ˄ (R˄X) is not realizable.
144
5
Causation as Difference Making

A further class of counterexamples concerns long chains of inus-conditions. For
instance, several authors have pointed out that the birth of a person is formally an
inus-condition to his/her death, which seems awkward. Several aspects play a role to
resolve this apparent paradox. First, the relationship between birth and death is to
some extent of deﬁnitional character: one can only die, if one was born, and those
who are born must all eventually die. Second, for long causal chains in terms of inus-
conditions the causal nature eventually wears off. After all, the range of backgrounds
with respect to which the remote condition is causally relevant becomes increasingly
smaller as the following argument shows. Given A˅(C˄D) R E | B and F˅(E˄G) R
X | B, then C R E | B˄ØA˄D and C R X | B˄ØA˄D˄ØF˄G. Clearly, the further
down the causal chain we move, the more restrictive the backgrounds become,
where an inus-condition remains causally relevant. Consequently, speciﬁc circum-
stances at the birth of a person are only in a very restricted way causally relevant to
speciﬁc aspects of the death of a person. Note that such an argument cannot be
construed for chains purely in terms of causal relevance, but those almost never
exist, not least due to possible external interventions.
This discussion is closely related with an important theme, which we can only
brieﬂy touch upon in the current article, namely the pragmatics of causation regard-
ing in particular the question under which circumstances inus-conditions are collo-
quially singled out as “causes”. Certainly, stability with respect to background,
manipulability of the causal conditions and available contrast classes are among
the principal criteria, why sometimes certain events or properties are distinguished as
causes and others that also fulﬁll the formal criteria are not.
5.3.4
Functional Dependencies
When causation came under attack towards the end of the nineteenth century, one of
the main objections concerned what Ernst Mach called the pharmaceutical character
of causation, where a piece of this leads to a piece of that. Historical approaches to
causation did not seem suited to account for the causal character of some of the most
fundamental laws of science, for example the axioms of mechanics, which obviously
are not formulated in terms of the presence or absence of certain factors, but rather as
functional dependencies. Bertrand Russell, in his famous critique of the notion of
cause (1913), concurred that the old concept of causation should be replaced by
functional laws, in particular by differential equations.
Such criticism is not entirely fair, since many approaches to causation in the
nineteenth century and before included methods to account for the causal character
of functional relationships. Maybe, the most important is the method of concomitant
variations in Mill’s approach: “Whatever phenomenon varies in any manner when-
ever another phenomenon varies in some particular manner, is either a cause or an
effect of that phenomenon, or is connected with it through some fact of causation.”
(1886, 263) Bacon’s table of degrees can be seen as a precursor to this method.
5.3
A Causal Calculus
145

Admittedly, the quantitative method of concomitant variations sits somewhat
apart from the other methods in Mill’s inductive framework, which are qualitative
concerning the presence and absence of factors. Several authors have therefore tried
to establish a closer connection between quantitative and qualitative induction
(e.g. von Wright 1951, 154; Skyrms 2000, Sec. V.9). I will broadly follow this
line of approach to show how the method of concomitant variations can be under-
stood as a special case of the method of difference.
Consider two ﬁnite sets of events of the same size n, a set of cause events {A1, . . .,
An} and a set of effect events {C1, . . ., Cn}. These could for example be distance
elements, velocity elements or small amounts of a solid or liquid etc. Let there be a
natural ordering among the C, but not among the A. One can then construct integral
events Cm¼Λi¼1,. . .,m Ci ˄ Λi¼m+1,. . .,n ØCi and Am,{m from n}¼Λi¼{m from n}Ai ˄ Λi¼K
({m from n})ØAi ,where {m from n} denotes a speciﬁc subset of size m and K({m from
n}) denotes the complement of this subset.30 These integral events are aggregated
distances, velocities, amounts of stuff etc. We have some rudimentary version of
concomitant variation if Am,{m from n} R Cm | B, 8 m (i.e. relevance of at least one
subset {m from n} for all m).
Now, let this relation hold for any subset, i.e. the Ai are completely interchange-
able regarding their effect on the phenomenon C. With Am¼Vall possible subsetsAm,{m
from n} we have: Am R Cm | B.31 In reasonable cases, this family of causal relations
can be idealized as a continuous linear function based on the indices m. A simple
example is the supposedly linear relation between the expended amount of fuel and
the distance covered by an (idealized) car. In principle, it does not matter, which part
of the fuel is spent for driving which distance. Note that there may be interchange-
ability on the side of the effects as well, but this brings no additional difﬁculties.
Several complications are conceivable. For example, at ﬁrst glance the account
just presented seems to allow only for linear relationships m(A) ! m(C), where m
denotes a measure ascribed to the phenomena on the basis of the respective indices.
But of course, arbitrary functional relationships are feasible by allowing for trans-
formations of the measures for both the source and the target phenomena essentially
corresponding to a change in indices. For discrete phenomena, there exists a natural
measure by just counting the number of elementary causes and effects. By contrast,
for continuous phenomena, such a natural measure does not normally exist and the
measure is usually ﬁxed by pragmatic considerations aiming at overall simplicity of
various interconnected functional relationships.
Furthermore, the Ai may not be strictly interchangeable, i.e. not every Ai may be
able to cause a speciﬁc Cj. For example, a certain Ai may appear only after other A’s
are already present. But those cases can easily be covered by the given framework.
30Λ, V, and V shall be understood in analogy to the ∑-sign denoting a sum over several elements,
e.g. Λi¼1,2 Ci ¼ C1 ˄ C2. Remember that V denotes an exclusive or, where only one option can be
realized at a time.
31For m¼2, we have: ØA1˄ØA2 R ØC1˄ØC2 | B; (ØA1˄A2) ˅ (A1˄ØA2) R C1˄ØC2 | B; A1˄A2
R C1˄C2 | B
146
5
Causation as Difference Making

The same holds for functions with several variables. Finally, various limiting
processes may occur. First, the number of cause and effect events may be inﬁnite.
Second and more importantly, the cause events and the effect events may become
inﬁnitesimally small. The latter process can be understood on the basis of the
outlined discrete framework if the individual A’s and C’s are themselves considered
as aggregate quantities etc. Since human experience is in general ﬁnite, limits
involving inﬁnity could be interpreted as idealizations.
In summary, the method of concomitant variations is a special case of the method
of difference applied to certain classes of cause and effect events.32 As already von
Wright has stressed, quantitative laws thus turn out a subspecies of qualitative laws
(1951, 83). As a ﬁnal remark, note that the resulting functional relationships convey
more information than the mathematical laws known from the sciences, which
generally lack a causal interpretation, most importantly a distinction between
cause and effect variables.
5.4
Objections and Criticism
I will in the following discuss a number of conceivable objections against the
difference-making account. Given that the proposed approach to causal counterfac-
tuals relies on the method of difference, the usual criticism of Mill’s methods has to
be considered. It is addressed mostly by offering various reﬁnements to these
methods. A second group of objections concerns those traditionally raised against
counterfactual accounts. This includes the plethora of counterexamples that are
discussed in the contemporary literature on causation, e.g. cases of preemption or
overdetermination. Furthermore, since the difference-making account aims to be a
monistic approach to causation, it has to make sense of the core intuitions that are
considered fundamental in other approaches. In particular, it has to take a stance
regarding the role of interventions and of mechanisms in causal reasoning. Finally,
some problems arise due to certain peculiarities of the difference-making account
itself, in particular in connection with the notion of causal irrelevance.
5.4.1
Objections to Mill’s Method of Difference
A general worry that may come to mind with respect to the outlined account is that it
is guilty of mixing up metaphysics and methodology of causation, i.e. the question
what causation is with the question how causal relationships can be discovered in the
world. In contrast, I would argue that these issues should not and cannot be fully
32With respect to data science, this implies that the proposed framework can be used for analyzing
classiﬁcation as well as regression.
5.4
Objections and Criticism
147

separated. The deﬁnition of causation must be informed by methodological consid-
erations and conversely, the deﬁnition should to some extent imply the methodol-
ogy.33 Indeed, the proposed difference-making account of causation constitutes a
direct counterpart to the account of induction broadly outlined in Pietsch (2014) and
in Chap. 6, which stands in the tradition of variational induction and Mill’s methods
type of reasoning. The method of difference and the strict method of agreement as
formulated there respectively determine causal relevance and irrelevance according
to the deﬁnitions given in Sect. 5.2.1.34
Consequently, a ﬁrst important class of objections concerns those traditionally
raised against variational induction and in particular the method of difference, most
of which apply to the strict method of agreement as well. These objections are
usually targeted at Mill’s original formulation of the method of difference, which
continues to be the most inﬂuential: “If an instance in which the phenomenon under
investigation occurs, and an instance in which it does not occur, have every
circumstance save one in common, that one occurring only in the former; the
circumstance in which alone the two instances differ, is the effect, or cause, or a
necessary part of the cause, of the phenomenon.” (1886, 256)
One serious worry concerns the applicability of this method. After all, it seems
generally impossible to vary only a single one of the circumstances. Rather, always a
large, plausibly inﬁnite number of circumstances changes along with the one whose
inﬂuence is explicitly examined. Thus, strictly speaking Mill’s construal of the
method of difference turns out inapplicable. However, the reﬁned account of causal
relevance outlined in the present essay resolves this issue by specifying which
circumstances may change, namely irrelevant circumstances and those that lie on a
causal chain through the purported cause to the phenomenon (cf. the deﬁnition of
homogeneity in Sect. 5.2.2; cp. also Sect. 6.1). These requirements, although they
can never be deﬁnitely established in concrete applications, are nonetheless much
more viable than Mill’s rather crude premise.
Another aspect that is already alluded to in Mill’s own writings is that the method
of difference according to his formulation can only handle situations in which a
single circumstance is causally responsible for a phenomenon. For example, it
cannot identify necessary but insufﬁcient factors, since these generally do not
make a difference, e.g. a short-circuit does not cause a ﬁre in the absence of
inﬂammable material. Relatedly, Mill’s formulation of the method of difference
cannot identify causal factors in the presence of inhibiting causes. For example,
33Compare Nancy Cartwright’s viewpoint: “If causal claims are to play a central role in social
science and in policy – as they should – we need to answer three related questions about them: What
do they mean? How do we conﬁrm them? What use can we make of them? The starting point for the
chapters in this collection is that these three questions must go together. For a long time we have
tended to leave the ﬁrst to the philosopher, the second to the methodologist and the last to the policy
consultant. That, I urge, is a mistake. Metaphysics, methods and use must march hand in hand.”
(2007, 1)
34This topic will be taken up in Sect. 6.1.
148
5
Causation as Difference Making

lightning should plausibly count as a cause for burnt-down houses even though ﬁre-
extinguishers sometimes prevent ﬁres from destroying buildings.
All these difﬁculties are resolved in the difference-making account by introducing
a reﬁned terminology that carefully distinguishes various types of causal notions, in
particular causal relevance, causal irrelevance, causal factors, and alternative causes,
and that is capable of replicating the inus-logic of causal conditions.
5.4.2
Objections Against Counterfactual Accounts
A further class of possible objections concerns those that are traditionally raised
against counterfactual approaches like that of David Lewis. One topic that Lewis
discusses extensively regards those infamous examples of plural causation that had
already turned out problematic for regularity accounts, in particular instances of
overdetermination and of preemption.
In cases of overdetermination, there are (at least) two causes present that are
independently sufﬁcient for a phenomenon. A classic example is the simultaneous
assassination by two marksmen. Why this situation is problematic for counterfactual
accounts can be easily grasped. If one of the marksmen had not pulled the trigger, the
poor fellow would still have died from the shot of the other. Therefore a basic
counterfactual analysis would not identify each of the shots as a cause of death,
which seems counterintuitive.
In cases of preemption, two causes are again independently sufﬁcient for a
phenomenon, only that now one of them prevents the other from becoming causally
relevant. Lewis further distinguishes early from late preemption (1986, Sec. E). In
the former, one of the causes is prevented from being relevant, before the phenom-
enon actually happens. A typical example concerns the desert traveler with two
mortal enemies. One of them poisons the drinking water, the other later pours the
water out. Both of these deeds would kill the traveler, but the pouring out of the
water led to his dying of thirst, while at the same time preventing the traveler from
being poisoned.
In late preemption, one of the causes is hindered from being relevant by the fact
that the considered phenomenon has already been produced by the other cause.
Consider two kids throwing rocks at a bottle. The ﬁrst throw shatters the bottle, while
the second would have shattered it as well, if the ﬁrst had not already done so. Note
that for reasons beyond the scope of the present article, the distinction between early
and late preemption is especially important in Lewis’s account. In fact, while his
solution for early preemption is rather convincing, he always struggled with late
preemption. Recall also that preemption cases constitute one of the reasons—along
with ensuring transitivity—why Lewis’s deﬁnition of causation employs causal
chains.
Within the framework of the difference-making account, all these cases of plural
causation can be easily treated. In a way, the mentioned problems only arise when
not being sufﬁciently precise about the type of causal dependence that is considered.
5.4
Objections and Criticism
149

For instance, preemption can be accounted for on the basis of alternative causes,
where one of the alternative causes (or a causal factor of it) constitutes an inhibiting
factor of the other alternative cause (or a causal factor of it). In the case of the desert
traveler, who either dies D from poisoning P or from pouring out the water W, we
clearly have such an alternative-cause structure according to the deﬁnition of Sect.
5.3.1: P R D | B˄ØW; W R D | B˄ØP; P I D | B˄W; W I D | B˄P. To see the
presence of an inhibiting cause, subscripts need to be introduced distinguishing
different types of death, i.e. by poisoning DP and by thirst DW: P R DP | B˄ØW;
P I
ØDP | B˄W. According to the corresponding deﬁnition in Sect. 5.3.1,
W constitutes an inhibiting factor counteracting P with respect to DP. An analogous
causal structure can be identiﬁed in the example of the two kids throwing rocks at a
bottle. Thus, late and early preemption can be treated in largely the same manner,
essentially because, in contrast to Lewis’s approach, the analysis does not rely on the
notion of causal chains. Finally, in situations of overdetermination we are also
dealing with alternative causes except that none constitutes an inhibiting factor for
the other—which implies that both types of events may co-occur, e.g. being shot to
death by both marksmen at the same time.
While cases of overdetermination and preemption allegedly show that counter-
factual deﬁnitions are not necessary for causality, other authors have claimed that
they are in fact not sufﬁcient either. Notably, Jaegwon Kim has argued that various
kinds of non-causal relations fulﬁll the basic counterfactual deﬁnition as well—in
particular logical or analytical dependence (if George had not been born in 1950, he
would not have reached the age of 21 in 1971), parthood (if I had not written ‘r’
twice in succession, I would not have written ‘Larry’), interdependent actions (if I
had not turned the knob, I would not have opened the door), and non-causal
determination (if my sister had not given birth at t, I would not have become an
uncle at t) (Kim 1973). A typical rejoinder has been to specify the kind of relata
ﬁguring in causal relations. For example, Menzies requires that causally connected
events are distinct, i.e. “not identical, neither is part of the other, and neither implies
the other” (Menzies 2014, § 2.1).
Let me brieﬂy sketch a different solution. The difference-making account can
indeed be applied to various kinds of necessity, in particular to the physical necessity
(but logical contingency) of causal relations and also to the conventional necessity of
deﬁnitional relations. In fact, all the counterexamples mentioned in the previous
paragraph seem to some extent of deﬁnitional nature, although not much hinges on
allowing for further kinds of necessity.35
Now, the fact that the difference-making approach works for both causal and
deﬁnitional necessity should be seen as a virtue rather than a vice. After all, it ﬁts
with well-established skepticism concerning a deﬁnite analytic-synthetic distinction.
Indeed, in many parts of science and everyday knowledge, deﬁnitional and empirical
relations cannot clearly be held apart, which essentially is implied by the Duhem-
35Note that in particular relations of parthood need not be deﬁnitional, but can also be of causal
nature.
150
5
Causation as Difference Making

Quine thesis of conﬁrmational holism. To a certain extent, it is always possible to
shift the empirical content from one part of the relevant regularities to another. For
some ornithologists, it may be part of the deﬁnition that all ravens are black, for
others it may be a matter of empirical fact. Of course, such ﬂexibility in assigning
empirical import would not be possible, if the formal structure of deﬁnitional and of
causal-empirical relations would be radically different.
A further problem for counterfactual approaches consists in the fact that most of
them presuppose determinism, i.e. that all considered phenomena are fully deter-
mined by their circumstances. At least in simple versions, counterfactual approaches
therefore fail to make sense of statistical causal relationships like ‘smoking causes
lung cancer’. After all, it is not universally true that if someone had not smoked,
he/she would not have died of lung cancer. This issue is addressed in Chap. 9, where
I argue that statistical and even indeterministic relationships can be covered by the
difference-making account of causation if it is extended by a causal interpretation of
probability.
5.4.3
Mechanisms and Interventions
The difference-making account aims to be a monistic account of causation. There-
fore, it should be able to make sense of typical intuitions that are the focus of other
approaches, in particular: (a) Causal relationships can be corroborated by evidence
concerning the underlying mechanisms linking causes with effects; (b) causal
knowledge must be acquired experimentally by examining the impact of interven-
tions on a phenomenon. Obviously, these claims correspond to two major classes of
interpretations of causality, namely mechanistic or process accounts, on the one
hand, and the recently very popular interventionist accounts, on the other hand.
The prominent role of interventions for determining causal relationships can
easily be understood from the perspective of the difference-making account. After
all, controlled interventions are ideally suited to yield the type of evidence required
for establishing causal relationships according to the difference-making account.
They generate in close temporal succession two situations which usually differ in a
relatively small number of circumstances and hopefully only in irrelevant circum-
stances except those that were explicitly changed by the intervention.
While accounting for the evidential power of interventions, the difference-
making approach avoids the most troubling objections against interventionist
accounts. Most importantly, it does not require interventions to determine causal
relationships and thus evades the problem that such approaches by deﬁnition fail in
contexts where interventions are impossible, e.g. to establish the supposedly causal
nature of the regularities governing the movement of stars and planets. In compar-
ison, the difference-making account allows for a much broader range of evidence for
5.4
Objections and Criticism
151

causal relationships.36 While the notion of an intervention apparently presupposes
that the two instances which are compared are temporally and spatially close and that
they belong to one and the same system, according to the difference-making account
the compared instances can be arbitrarily far away from each other both in temporal
and in spatial terms and can belong to different systems. For the proposed account it
does not matter whether the required variational evidence results from intervention
or mere observation.
A further problem concerns the question how exactly interventions should be
conceptually framed. Several authors have suggested an anthropomorphic account
resulting in unsurmountable difﬁculties. Are, for example, only humans able to
effectuate interventions or are animals as well, not to speak of technical artifacts or
even natural objects? In the face of such irresolvable challenges, inﬂuential authors
like Woodward (2003) and Pearl (2000) have introduced less demanding deﬁnitions
in terms of “‘surgical’ change”: “the proposals variously speak of an intervention on
X as breaking the causal connection between X and its causes while leaving other
causal mechanisms intact or as not affecting [the target variable] Y via a causal route
that does not go through X.” (Woodward 2013, §§ 5–6) Pearl (2000) develops a
special calculus that models interventions in this sense, deﬁning the “causal effect”
of X on Y in terms of the value of Y given that X is explicitly set to x: P(y|do(X¼x)).
Still, both Woodward and Pearl rely on a special ontological category of an
intervention to establish their notion of causation. As mentioned, one crucial feature
is that an intervention on a variable X cuts off other possible inﬂuences for this
variable as well as causal inﬂuences on the phenomenon Y that are not mediated by
X. But this somewhat peculiar requirement contradicts basic human experiences.
When intervening in the world, it rarely seems the case that all other possible causal
inﬂuences are disrupted. Rather, even in simple situations, e.g. when kicking a ball,
all kinds of causal inﬂuences remain intact, including the pull of gravity, air pressure
etc.37 Thus, in addition to general worries about ontological parsimony, even
Woodward’s and Pearl’s weaker reading of interventions in terms of surgical change
does not seem realistic for many contexts of application.
The difference-making account can make sense of interventions, while not
relying on the controversial idea that causal connections are broken. Indeed, it
does not have to introduce a distinct ontological category at all. The complex
technical features of an intervention, as for example laid out by Woodward (2013,
§6), can nevertheless be reproduced. They essentially follow from the requirement of
homogeneity of context. Conceptually speaking, external interventions in a system
can be modeled within the difference-making account in terms of changes in the
background such that some previous relations of causal relevance or irrelevance
cease to be valid. For instance, the disruption of a causal inﬂuence can be accounted
for if the corresponding variable is held constant in the causal background or if the
36In spirit, this perspective is quite similar to Federica Russo’s ‘invariance under changes’ approach
(2014).
37I owe this point to Mathias Frisch.
152
5
Causation as Difference Making

background is restricted in a way that the variable becomes causally irrelevant. Note
further that the proposed account can address issues of external validity by examin-
ing a phenomenon with respect to various backgrounds, while typical interventionist
approaches that lack the concept of a causal background must generally and wrongly
conclude that a causal relationship once established will continue to hold in all
contexts.
Accounts in the interventionist tradition mostly use two kinds of representations
for causal relationships, structural equations and DAGs, i.e. directed acyclic graphs
(cf. in particular Pearl 2000). While these representations are compatible with the
difference-making account, the Boolean logic of circumstances employed in the
latter is more general. As argued in Pietsch (2016a) as well as Sect. 4.3, this logic
works well in non-parametric contexts in which (exact) structural equations cannot
exist since by deﬁnition the relation between cause and effect cannot be described
with a ﬁnite amount of parameters. As another example, directed acyclic graphs
presuppose a static picture of causal relationships and thus cannot adequately deal
with strong context-dependence in complex phenomena. Also, the graph-theoretic
framework fails to account for the inus-logic of causal conditions. In particular, by
relying solely on directed links between variables, it does not distinguish between
causal factors and alternative causes.38
In summary, interventionist approaches introduce a problematic distinction
between situations, where variables are observed, and others, where they are set
by intervention. By contrast, the difference-making account gets along without a
sharp division, while still acknowledging the extraordinary epistemic power of
interventions for detecting causal relationships.
Mechanisms constitute another central concept for causal reasoning. In fact,
several authors go as far as arguing for a dual nature of causation, part interventionist
and part mechanistic. By contrast, I will now argue that mechanisms can be
integrated into the difference-making account in straightforward manner. Here,
they can broadly be framed along the following lines: “A mechanism for a phenom-
enon consists of entities and activities organized in such a way that they are
responsible for the phenomenon.” (Illari and Williamson 2012, 120) For the present
discussion, I would add that mechanisms should be understood in terms of causal
(maybe also deﬁnitional) relations and introduce context- or background-
dependence. Essentially: “A mechanism for a causal relationship between a set of
circumstances and a phenomenon in a certain context consists in more ﬁne-grained
causal dependencies that together account for this relationship.”
Such causal mechanisms can be interpreted as ﬁlling in the details of a more
coarse-grained causal picture. Consider for example a causal dependence between a
circumstance A and a phenomenon C with respect to a background B. A simple
mechanism would consist in a number of intermediary circumstances A1, . . ., AN,
such that A is causally relevant to A1, A1 to A2, ..., AN to C, all with respect to the
38Baumgartner and Graßhoff (2004) suggest an extension of causal graphs for this purpose.
5.4
Objections and Criticism
153

same background B. Of course, one can easily imagine more complex dependencies
relying on various causal factors and alternative causes.
From the perspective of the difference-making account, the individual dependen-
cies constituting the mechanism would again be ordinary causal relationships that
themselves can be accounted for in terms of difference making. This explains the
most important lesson about mechanisms in the context of causal reasoning, namely
that knowledge of mechanisms can to some extent improve the conﬁdence in coarse-
grained causal relationships, essentially because it allows taking into account further
evidence, namely evidence for the intermediary steps. This is particularly effective in
the case of physical mechanisms since the corresponding mechanical laws are so
well established. Note ﬁnally that sometimes there may be no independent evidence
for the coarse-grained relationship itself. Then, the conﬁdence in the latter derives
fully from the evidence for the intermediary steps.
In contrast to mechanistic approaches, the difference-making account takes the
notion of cause as fundamental and the notion of mechanism as parasitic on
causation instead of the other way around. Therefore, the latter is not susceptible
to the familiar objections against mechanistic approaches. Most importantly, the
usual problems with the concepts of process and mechanism do not arise. A causal
mechanism as outlined above does not have to transmit structure, marks, or signals,
and it does not have to be reducible to the laws of physics. Furthermore, a mecha-
nism in the proposed sense need not be local, while nevertheless the fruitful role of
locality for inductive reasoning can be accounted for (cf. Sect. 6.2). Also, there can
be mechanisms for causation by omission, since the absence of a circumstance may
well be causally relevant to a phenomenon in the sense of difference making and one
can easily imagine a more ﬁne-grained picture corroborating such a causal relation-
ship. Finally, the difference-making account does not face the foundationalist
problem of mechanistic approaches that regularities at the most fundamental onto-
logical level cannot themselves be accounted for in terms of mechanisms and thus
they cannot be causal. After all, it is difference making that is essential for causality,
rather than the existence of mechanisms.
Thus, like in the case of interventions, the approach proposed in this essay can
account for the immensely fruitful evidential role of mechanisms, while not being
affected by the problems that result from putting the notion of mechanism at the core
of an interpretation of causality.
5.4.4
Objections Speciﬁc to the Difference-Making Account
Let us ﬁnally address a number of objections that are more or less speciﬁc to the
difference-making account. Crucially, it exhibits a circularity in the deﬁnitions of
causal relevance and irrelevance, which consists in the fact that these very notions
again ﬁgure in the requirement of homogeneity of background. More exactly, the
two instances that are compared when evaluating causal relevance and irrelevance
should differ only in circumstances that are themselves causally irrelevant except for
154
5
Causation as Difference Making

those that lie on a causal chain through the examined circumstance to the phenom-
enon. However, the latter relevance and irrelevance claims concern causal relation-
ships that are different from the one that is explicitly examined. Therefore, the
supposed circularity just comes down to a consistency requirement. At least in
principle, causal claims can be established merely on the basis of an (often very
large) number of instances with varying circumstances.
Thus, the difference-making account allows reducing causal claims to non-causal
evidence in terms of instances under varying conditions. This constitutes a crucial
difference compared with interventionist approaches, which also exhibit a circularity
in the deﬁnition of causation in that intervention is itself a causally tainted term. For
example, in both Pearl’s and Woodward’s versions of interventionism, the notion of
intervention itself draws upon various causal concepts, e.g. the interruption of causal
inﬂuences on the variable X whose inﬂuence is examined or the causal relation
between the intervening variable I and variable X (cf. Sect. 5.4.3). In contrast to what
I have argued above for the difference-making account, interventionist approaches
are generally non-reductive due to this circularity, i.e. they do not allow “the
possibility of a reduction of causal claims to claims that are non-causal” (Woodward
2013, §1).
A further difﬁculty of the difference-making account regards the fact that in
certain contexts, circumstances will be identiﬁed as causally relevant that one
would not ordinarily consider as such. This typically happens in common cause
structures, which are discussed extensively by Mackie (1980, 83–86). Consider for
example two different effects of a disease, e.g. a fever C and a rash D as symptoms of
roseola A. Now, in speciﬁc contexts B, there may always be covariation of fever and
rash in the presence of the roseola virus with, say, the fever preceding the rash. It
seems that one is forced to accept the counterintuitive conclusion that with respect to
such B’s the fever is causally relevant to the rash.
At this point, it helps to recall the notion of a common cause as explicated in
Sect. 5.3.1. Roughly, A is a common cause of C and D with respect to a
background B, (i) if in all backgrounds within B, in which C R D (assuming that
C is always temporally prior), we have A R C and A R D, and (ii) if in all
backgrounds within B, in which C is caused by conditions other than A, then C I D
and/or C I ØD.39
Consider the following set-up, which fulﬁlls these requirements: let conditions A
and E be the only alternative causes for C, condition A shall be causally relevant to
phenomenon D, and E causally irrelevant to D, all with respect to a background
B. Assume further that C is temporally prior to D. It follows that A is causally
relevant to C and D with respect to B˄ØE, that C is causally relevant to D with
respect to B˄ØE, but that C is irrelevant to ØD with respect to B˄ØA. In the
example, E could be another virus, e.g. the ﬂu, which also leads to fever, but not
to a rash. In the absence of roseola, fever is irrelevant to the rash, while in the
absence of ﬂu, fever is causally relevant to the rash.
39Assuming that there is only one common cause.
5.4
Objections and Criticism
155

Again, the latter is a strange result, since intuitively causal relevance between
different effects should not exist in the case of a common cause structure. In
particular, this consequence seems to contradict the conception that causal relation-
ships can be employed to manipulate phenomena since in general one effect cannot
be used to change another effect. However, strictly speaking with respect to back-
ground B˄ØE, by manipulating C phenomenon D is also changed—essentially
because C can only be manipulated via A. The actual common cause structure is
then established by showing that in various other contexts, when C and D are due to
other conditions than A, they are irrelevant for each other.
In fact, this example illustrates well the development of causal language when
increasing evidence is gathered. There is nothing contradictory in the fact that causal
structure changes when the background is extended (e.g. from the causal relevance
of a condition to being an alternative cause) and that with respect to certain evidence
the causal structure may be underdetermined. In complex situations like Mackie’s
notorious example, in which the sounding of the Manchester hooters could seem a
cause for the Londoners to return from work, the causal structure can only be
resolved by taking into account a sufﬁciently large context of other causal relations.
With very limited evidence, it may seem that there is causal relevance, but when we
learn about the spatial distance separating the two events, the various temporal
relationships, the causal laws regarding sound propagation and so on, a causal
relevance between the Manchester hooters and the London workers can be excluded
with respect to sufﬁciently general backgrounds.
Relatedly, someone might expect some kind of convergence of causal statements,
when the background or context is increasingly extended. By contrast, a fundamen-
tal lesson of the difference making account is that causal statements always have to
be relativized to context. Thus, there is no contradiction in the fact that convergence
might not necessarily happen. In other words, according to the proposed account,
there are no true context-independent causes. But this seeming drawback may
actually be turned into a virtue, if taking into account that it ﬁts quite well with
scientiﬁc practice. Indeed, experimental scientists in general seem to be deeply
aware that experimental results hold only with respect to a context, which is
intuitively assumed. And it seems to distinguish good experimenters that they are
always aware that certain results may fail in different or extended contexts.
The history of science is full of examples in this regard. While it may be difﬁcult
to realize in hindsight, the question of generalizability of basic phenomenological
laws like the law of free fall is mostly an experimental endeavor. Is the law of free
fall the same on a mountain as in a valley? Does it depend on the presence of a
surrounding medium, e.g. air or water? Does it depend on an underlying motion,
e.g. of a boat or a carriage? There is no shortcut to an experimental inquiry for
determining the answers to this question. And indeed, on a considerable number of
occasions, the expectations of the scientists involved were proven wrong.
One might object that at least convergence to fundamental natural laws should be
expected. However, as argued in Chap. 3, fundamental laws are of a completely
different nature compared with causal laws of phenomenological science which are
156
5
Causation as Difference Making

accessible to the difference making approach. In particular, such fundamental laws
are typically non-causal and to a considerable part conventional or deﬁnitional.
Another objection is speciﬁc to the notion of causal irrelevance of the difference-
making account, namely that the latter obviously depends on measurement accuracy.
Indeed, there may be causal relevance that is just not detectable due to the small size
of the inﬂuence. My suggestion is to bite the bullet on this one. Arguably, this feature
constitutes another aspect of the pragmatics of causation. Indeed, causal irrelevance
to some extent depends on the choice of representation, and measurement accuracy
should be considered one aspect of this. Certainly, paradoxical situations can arise:
for example when several undetectable contributions add up to a measureable effect.
In such cases the representation just needs to be adjusted to recover consistency.
Obviously, a certain amount of simpliﬁcation and idealization will always be
required for the causal representation of empirical phenomena, since otherwise it
may well turn out that everything depends on everything else.
A ﬁnal remark concerns the requirement of background dependence in the
difference-making account. Since this implies a ceteris-paribus character for all
causal laws, those scientiﬁc laws that claim to be truly universal cannot have a
distinct causal nature. This holds in particular for the fundamental axioms of
physical theories like Newton’s laws of mechanics. The suggestion is that such
axioms acquire a causal character only when they are restricted and applied in a
speciﬁc context. While this may sound strange to some working scientists, it ﬁts well
with ideas of Mach, Poincaré, Duhem, and others, who have argued that the
fundamental laws of physics are conventions or implicit deﬁnitions rather than
empirical (and thus causal) statements. Recall also that there has been an ongoing
debate in philosophy to what extent causation plays a role in physics at all. Doubts
have been raised from various perspectives. For example, some interventionists have
argued that interventions are impossible when fundamental physical theories apply
to the whole universe (Woodward 2013, §12), presumably because the notion of
interrupting causal inﬂuences does not make sense anymore. Russell and Mach have
argued that the laws of physics cannot be causal since they are functional and this
does not go well with regularity accounts requiring constant conjunction of condi-
tions. The difference-making account gives yet another answer, namely that the laws
of physics cannot be causal since they do not exhibit a ceteris-paribus character and
thus they cannot be derived in a process of variational induction which according to
the proposed account constitutes the only way to generate causal knowledge
(cf. Chaps. 3 and 4).
5.4.5
Further Scenarios
A crucial problem of the difference making account is that in certain contexts or
backgrounds, variables or states are relevant according to the deﬁnitions of Sect. 5.2,
which would not be considered causally relevant according to a common
5.4
Objections and Criticism
157

understanding of the notion of causation. Consider the following example,40 which
illustrates that in some contexts proxy variables, shadowing variables or symptoms
of causes may be causally relevant according to the proposed difference making
account.
In a factory, there are several different machines, which all play a role in the
manufacture of a certain product. Let us assume that, with respect to some
unspeciﬁed context, one of these machines is causally relevant, i.e. is a difference
maker, to a given property of the product, e.g. places a speciﬁc toothed wheel
without which the product would not function. Now, each of the machines is
surveilled by a respective monitor, which has two states: enabled, when the
corresponding machine is working properly, and disabled, when it is not working
properly.
Although some readers may ﬁnd the answer unintuitive, according to the deﬁni-
tions of Sect. 5.2, the monitor is indeed causally relevant to the functioning of the
product with respect to certain contexts, in which the corresponding machine is
causally relevant to the functioning. However, in those contexts there is perfect
correlation, i.e. the monitor is enabled whenever the machine is working properly
and it is disabled whenever the machine is not working properly.
Now, one could object that because of the causal relevance of the monitor, a
mischievous intelligent agent could destroy just the monitor, but not the machine, in
order to render the resulting product defective. This result is obviously non-sensical
as we all know that the monitor is just a proxy or shadowing variable for the machine
and that the intelligent agent needs to destroy the machine in order to achieve the
desired result.
This problem is resolved in the following manner within the difference making
account. By destroying the monitor but not the machine, the intelligent agent leaves
the context, in which the monitor strictly correlates with the respective machine. In
the new context, according to the deﬁnitions of Sect. 5.2, the monitor is not anymore
causally relevant to the functioning of the product, while the machine still
is. Because the monitor is not anymore causally relevant in this new context,
destroying the monitor need not have the desired impact of rendering the product
defective.
By contrast, in the original context, where there is strict correlation between
monitor and machine, changing the state of the monitor will impact the functioning
of the product because the state of the monitor can only be changed by changing the
state of the machine, which then will impact the functioning. From a different
perspective, in the original context with strict correlation, the state of the monitor
and of the machine could be considered as a single phenomenon, which is causally
relevant. Only when learning that the link between machine and monitor can be
broken, e.g. by destroying the monitor and not the machine, do we need to assess,
40I am very grateful to one of the referees for this insightful and illustrative example and for the
further points discussed in the following.
158
5
Causation as Difference Making

whether with respect to this new background the machine is causally relevant or the
monitor.
While some of these assessments of causal relevance may at ﬁrst seem counter-
intuitive, they are consistent within the difference making account. In a way, this is
the price to pay for having a consistent causal language. The counterintuitive nature
of some of these assessments of causal relevance is also a consequence of making
causality strictly dependent on background and context, which is conventionally not
done in everyday and even scientiﬁc causal analysis. But once this step is accepted,
there is no problem in principle with accepting that some events that one would
intuitively consider to be symptoms or proxies can be causally relevant to the
phenomenon in question in certain rather restrictive contexts. As argued above, in
these restrictive contexts, the link between causal relevance and manipulability of a
phenomenon remains intact even with respect to the proxies, essentially because one
can only manipulate the proxies by manipulating common causes of phenomenon
and proxies.
As a second scenario, let us brieﬂy return to the topic of deep neural networks of
Sect. 3.5 and the question, whether the difference making account provides a
suitable framework for understanding the conceptual underpinnings of these algo-
rithms. Most importantly, one can ask, whether deep neural networks can and should
be interpreted in causal terms based on the difference making account.
Consider a neural network with a large number of input variables and with several
hidden layers tasked with learning the XOR-function. As we had seen in Sect. 3.5,
this function can be learned at least approximately in particular if a non-linear
mapping between subsequent layer of the neural network is used. However, it
turns out that the speciﬁc weights given to certain input variables depend decisively
on the model parameters, in particular the values at which these weights are
initialized. Widely different models may result from different initializations. Of
course, this is problematic when the models are interpreted in realistic terms, for
example as reﬂecting the true causes of a phenomenon. And even if there is an input
variable, which approximates the underlying ‘true’ function, it will not necessarily
be given a large weight, but it may play a marginal or even no role at all in the ﬁnal
model. Again, one would think that the mentioned input variable approximating the
underlying function is a plausible candidate for the real cause and that the other
models go wrong by failing to identify this candidate.
As has been stressed in Sect. 3.5, additional difﬁculties arise when trying to
interpret deep neural networks in terms of a difference making account. Crucially,
none of the mentioned variables are causally relevant to any of the states of the
phenomenon, here the XOR-function. After all, causal relevance requires a strict
correlation between causes and phenomena and none of the input variables of the
deep neural net, even when combined with logical operators, yield a strict correla-
tion. Rather, there will always be misclassiﬁcations at least in a small number of
cases.
What one considers colloquially to be difference makers, i.e. all those input
variables, which have some weight in the ﬁnal model, are not causally relevant
difference makers according to the difference making account. Therefore, they are
5.4
Objections and Criticism
159

not causes according to the difference making account. But they can in combination
with all other variables that enter the model at best be thought of as proxies of the real
causes. As discussed above, changing the proxies does not necessarily impact the
phenomena. However, if the variables, which play a role in the neural network
model, are interpreted in terms of proxies, it is not problematic that different models
exist for the same underlying function as it can naturally be accepted that different
combinations of proxies can be used for approximating a function. By contrast, a
plurality of models is to be expected, in particular, when many variables are used.
In summary, except when with respect to a given context there is a strict
correlation between causes and phenomena, which would fulﬁll the deﬁnition of
causal relevance, the correlations detected by deep neural networks are best
interpreted in terms of proxy variables, which are good for prediction but not
necessarily for intervention since the latter requires knowledge of the actual causes.
If, according to a speciﬁc model, a large number of variables has an inﬂuence on the
phenomenon in question, at least some of these variables may pick up a direct causal
relation, while others pick up indirect causal relations via common causes. As
previously explained, the former relations can be used both for manipulation and
prediction, the latter only for prediction. Still other variables may not pick up any
causal relations at all, but only accidental correlations, which in general cannot be
used for manipulation or prediction.
A third scenario illustrates further that in order to shed light on causal relations,
notions like difference making or causal relevance need to be precisely deﬁned.
Consider a voting scenario, e.g. on impeachment of the president of a country, where
a simple majority in the parliament sufﬁces to oust the president, but the president
stays in power if the vote falls short of a majority. In such a scenario, the circum-
stances could be the individual votes of the parliamentarians, which for the sake of
simplicity are either yes or no. The phenomenon determined by the circumstances is,
whether the president is impeached or not.
Especially if there is a large number of parliamentarians, one may easily lose track
of whose votes is relevant to the result or not. It might seem that the votes are
individually irrelevant, but are somehow relevant if the majority vote is considered.
However, such conceptual ambiguity is entirely removed when the notions of
relevance and irrelevance are precisely deﬁned. Indeed, there exists a single Boolean
expression of the individual votes which is causally relevant to impeachment with
respect to a background in which the votes of all parliamentarians are allowed to
change.
For the sake of simplicity, let us assume that the parliament is very small with
only three parliamentarians, whose votes are determined by the variables x1, x2 and
x3. Value 1 for each of these variables means that the respective parliamentarian
voted to impeach while value 0 means that the parliamentarian voted against
impeachment. If a majority voted for impeachment, the impeachment variable c
will have value 1, otherwise 0. The following considerations are easily generalized
to a larger number of parliamentarians.
160
5
Causation as Difference Making

With respect to a background B, in which none of the votes is ﬁxed, there is a
single expression, which is causally relevant to impeachment according to the
deﬁnition of Sect. 5.2, namely:
(X1 ˄ X2 ˄ (X3 ˅ ØX3)) ˅ (X1 ˄ X3 ˄ ØX2) ˅ (X2 ˄ X3 ˄ ØX1)) R C | B
As before, capital letters describe states and small letters describe variables,
e.g. X1 is true iff x1¼1 and ØX1 is true iff x1¼0. It is straight-forward to generalize
the above result to an arbitrary number of parliamentarians. The resulting expression
will become unpleasantly long, but could be simpliﬁed by introducing further
notation e.g. taking into account certain permutations between parliamentarians.
The more general point here, which has become increasingly clear in the wake of
big data science, is that many phenomena do not possess a simple causal structure,
but are often breathtakingly complex. We should not expect that e.g. the phenom-
enology of skin cancer is reducible to a small number of variables.
From the above relation, causal relevance expressions for more restrictive back-
grounds can be derived in a straight-forward manner by canceling those expressions
on the left side, which do not ﬁt with the background, and subsequently eliminating
redundancies. For example, in a context, in which the vote X1 is ﬁxed in addition
to B, i.e. parliamentarian x1 votes in favor of impeachment, we have (X2 ˄ (X3 ˅
ØX3)) ˅ (X3 ˄ ØX2) R C | B ˄ X1. As another example, in a background, in which
the votes X1 and ØX2 are ﬁxed, i.e. parliamentarian x1 votes in favor of and
parliamentarian x2 against impeachment, we have X3 R C | B ˄ X1 ˄ ØX2. In the
latter case, it depends entirely on the vote x3, whether the president is impeached
or not.
In a further complication of the example, one could add a temporal dimension.
For example, parliamentarian x1 might be the boss or ringleader of parliamentarian
x2. Speciﬁcally, if parliamentarian x1 votes ﬁrst, parliamentarian x2 will always vote
in the same way as parliamentarian x1. This temporal dimension could be taken into
account by an additional variable t, where t ¼ T means that x1 votes before x2 and t ¼
ØT means that x1 votes after x2. Thus, we have:
[T ˄ (X1 ˄ X2 ˄ (X3 ˅ ØX3))] ˅ [ØT ˄ [(X1 ˄ X2 ˄ (X3 ˅ ØX3)) ˅ (X1 ˄ X3 ˄ ØX2)
˅ (X2 ˄ X3 ˄ ØX1)]] R C | B
In the ﬁrst part, where T is true, all alternatives in which x1 and x2 differ have
been eliminated, whereas in the second part, where ØT is true, the votes of x1 and x2
remain independent and all alternatives delineated before have to be taken into
account. It is true that, when the number of parliamentarians increases, these
variations soon become forbiddingly complex. But machine learning seems to be
much more suitable to deal with this kind of complexity in comparison to the
human mind.
Thus, there are no conceptual ambiguities as long as one diligently keeps track of
the background or context, in which certain causal statements hold. The perceived
ambiguities of ordinary language with respect to relevance and irrelevance state-
ments at least in part result from a failure to relativize such statements to speciﬁc
contexts. For example, certain variables can be at the same time relevant, irrelevant
5.4
Objections and Criticism
161

or neither of both depending on context. There is no contradiction as long as one
keeps track of the respective context.
In summary, a difference-making account of causation was proposed in this
chapter and its prospects examined. The difference-making account broadly stands
in the counterfactual tradition, but has certain characteristics that help it avoid some
of the most troubling objections with relatively little conceptual and metaphysical
burden. Arguably, the difference-making account fares better than other accounts in
establishing a notion of causation that exhibits little vagueness and subjectivity and
that thus ﬁts well with the role of causation in actual scientiﬁc practice.
Appendix: The Formal Framework
In the following, the formal framework of the present chapter is brieﬂy summarized.
A.1 Notation
small Latin letters a, c, x
variables
capital Latin letters A, C, X (except B)
states
A, C, X
shorthand for a ¼ A, c ¼ C, x ¼ X
ØA, ØC, ØX
shorthand for a ¼ ØA, c ¼ ØC, x ¼ ØX
a, ai, A, Ai
antecedent (circumstance)
c, Ci
consequent (phenomenon)
x, X, y, Y
further variables
˄, e.g. A ˄ X
And, e.g. both states A and X are realized
˅, e.g. A ˅ X
Or, e.g. states A or X are realized (or both)
B
background or context (terms used synonymously)
B ˄ X
background including B and x ¼ X
B ˄ x
background including B and where x can take on any
value, e.g. X or ØX in case of a binary variable
A R C | B
A is causally relevant to C with respect to background B
A Rcf C | B
A is relevant as a causal factor to C with respect to
background B
A Rac C | B
A is relevant as an alternative cause to C with respect to
background B
A I C | B
A is causally irrelevant to C with respect to background
B
∃{A ˄ C ; ØA ˄ ØC | B }
there exists an instance A ˄ C with background B, a
further instance ØA ˄ ØC also with background B and B
guarantees homogeneity
∃X !
there exists an X so that
A ˄ B ! C
if A ˄ B, then C
162
5
Causation as Difference Making

A.2 Basic Deﬁnitions
A.2.1 Causal Relevance
Deﬁnition: In a context B, in which a condition or circumstance A and a phenom-
enon C occur, A is ‘causally relevant’ to C, in short A R C | B, iff the following
counterfactual holds: if A had not occurred in context B, C would also not have
occurred.
Counterfactual: ‘If A were not the case, C would not be the case’ is true with
respect to an instance in which both A and C occur in a context B, iff (1) at least one
instance is realized in the actual world in which neither A nor C occurs in the same
context B and (2) if B guarantees homogeneity.
Formally : ARC j B , ∃A ^ C; ØA ^ ØCjB
f
g
ðD1Þ
Example: Virus Present R Disease Present | B , ∃{(Virus Present) ˄ (Disease
Present); (Virus Absent ˄ Disease Absent) | B }
A.2.1.1 Causal Relevance of A ˄ X
A ^ XRC j B
⟺∃fA ^ X ^ C; ØðA ^ XÞ ^ ØCjBg
, ∃A ^ X ^ C; ØA _ ØX
ð
Þ ^ ØCÞjB
f
g
, ∃A ^ X ^ C; ØA ^ X ^ ØC; A ^ ØX ^ ØC; ØA ^ ØX ^ ØCjB
f
g
ðD1*Þ
The last step is based on the convention that in case of an ˅ - combination all
possible instances are realized.
A.2.1.2 Causal Relevance of A ˅ X
A _ XRC j B
⟺∃fðA _ XÞ ^ C; ØðA _ XÞ ^ ØCjBg
, ∃
A _ X
ð
Þ ^ C; ØA ^ ØX
ð
Þ ^ ØCÞjB
f
g
, ∃A ^ X ^ C; ØA ^ X ^ C; A ^ ØX ^ C; ØA ^ ØX ^ ØCjB
f
g
ðD1**Þ
In the last step the same convention as in the derivation of (D1*) was used.
Appendix: The Formal Framework
163

A.2.2 Causal Irrelevance
Deﬁnition: In a context B, in which a condition or circumstance A and a phenom-
enon C occur, A is ‘causally irrelevant’ to C, in short A I C | B, iff the following
counterfactual holds: if A had not occurred, C would still have occurred.
Counterfactual: ‘If A were not the case, C would still be the case’ is true with
respect to an instance in which both A and C occur in a context B, iff (1) there exists
at least one instance in which A does not occur but C still occurs in the same context
B and (2) B guarantees homogeneity.
Formally : AI C j B , ∃A ^ C; ØA ^ CjB
f
g
ðD2Þ
Example: Full Moon Present I Disease Present | B , ∃{(Full Moon Present) ˄
(Disease Present) ; (Full Moon Absent) ˄ (Disease Present) | B }
A.2.3 Causal Factor
Deﬁnition: A is a ‘causal factor’ for phenomenon C with respect to background B, iff
there exists an X such that A is causally relevant to C with respect to B˄X and
irrelevant to ØC with respect to B˄ØX (i.e. C is always absent in B˄ØX).
Formally : ARcf C j B , ∃X ! ARC j B ^ Xand AIØC j B ^ ØX
ðD3Þ
Note that for A to be a causal factor X cannot be redundant. In other words, if A is
relevant as a causal factor to C with respect to B, it cannot at the same time be
causally relevant to C with respect to B.
Example: Ignited Match Present Rcf Fire Present | B , ∃X (Combustible
Material Present) ! Ignited Match Present R Fire Present | B ˄ Combustible
Material Present AND Ignited Match Present I Fire Absent | B ˄ Combustible
Material Absent
A.2.4 Alternative Cause
Deﬁnition: A is an ‘alternative cause’ to C with respect to background B iff there
exists an X such that A is causally relevant to C with respect to a background B˄ØX,
but causally irrelevant to C with respect to a background B˄X (i.e. C is always
present in B˄X).
164
5
Causation as Difference Making

Formally : ARacC j B , ∃X ! ARC j B ^ ØXand AI C j B ^ X
ðD4Þ
Note that for A to be an alternative cause X cannot be redundant. In other words,
if A is relevant as an alternative cause to C with respect to B, it cannot at the same
time be causally relevant to C with respect to B.
Example: Sprinkler On Rac Lawn Wet | B , ∃X (Rain Present) ! Sprinkler On
R Lawn Wet | B ˄ Rain Absent AND Sprinkler On I Lawn Wet | B ˄ Rain Present
A.2.5 Inus-Complex
Deﬁnition: A complex of conditions of the form (X˄Y)˅Z shall be called an ‘inus-
complex’ for C with respect to B, iff it is causally relevant to C with respect to
B. Note that each condition X, Y, or Z may itself be an inus-complex. By deﬁnition, it
may be the case that Y¼1 and/or Z¼0.
X ^ Y
ð
Þ _ ZRC j B
, ∃
X^Y
ð
Þ^Z^C;Ø X^Y
ð
Þ^Z^C; X^Y
ð
Þ^ØZ^C;Ø X^Y
ð
Þ^ØZ^ØCjB
f
g
(based on D1**)
, ∃X^Y^Z^C; ØX_ØY
ð
Þ^Z^C;X^Y^ØZ^C; ØX_ØY
ð
Þ^ØZ^ØCÞjB
f
g
, ∃
X ^ Y ^ Z ^ C; ØX ^ ØY ^ Z ^ C; ØX ^ Y ^ Z ^ C; X ^ ØY ^ Z ^ C; X ^ Y ^ ØZ ^ C;
ØX ^ ØY ^ ØZ ^ ØC; ØX ^ Y ^ ØZ ^ ØC; X ^ ØY ^ ØZ ^ ØC j B


(based on D1*)
Inus-complexes are the central element of a theory of causality based on the
presence or absence of circumstances as inus-complexes combine the notions of
causal factors and alternative causes. In the above case X and Y are causal factors of
a cause which is alternative to Z (see theorems T1 and T2 below).
A.2.6 Homogeneity
Deﬁnition: Context B guarantees ‘homogeneity’, iff only conditions that are causally
irrelevant to the examined consequent C (and ØC) can change, (i) except for the
examined antecedent A and (ii) conditions X that are causally relevant to C in virtue
of A being causally relevant to C.
Appendix: The Formal Framework
165

A condition X is causally relevant to C ‘in virtue’ of A being causally relevant to
C with respect to a context B, iff in all contexts within B, in which X is causally
relevant to C, A is causally relevant to C as well (but not necessarily vice versa).
Example: X is causally relevant ‘in virtue of A being causally relevant to C’ if it
lies on a causal chain between A and C.
A.2.6.1 Causal Relevance
ARC j B
, ∃A ^ C; ØA ^ ØCjB
f
g
based on < D1 >
ð
Þ
⟺A ^ B ! C and ØA ^ B ! ØC
ðD5Þ
The last equivalence (D5) follows from the deﬁnition of homogeneity.
The importance of equivalence (D5) cannot be understated as it guarantees that
circumstances that are causally relevant can be used to manipulate a phenomenon.
In other words, iff A is causally relevant to C with respect to background B, then
whenever A is present in background B, then C is present and whenever A is absent
in background B, then C is absent as well.
A.2.6.2 Causal Irrelevance
AI C j B
, ∃A ^ C; ØA ^ Cj B
f
g
based on < D2 >
ð
Þ
⟺A ^ B ! C and ØA ^ B ! C
ðD6Þ
The last equality (D6) follows from the deﬁnition of homogeneity.
Thus, changes in causally irrelevant circumstances will never have an impact on
the phenomenon.
In other words, iff A is causally irrelevant to C with respect to background B, then
whenever A is present in background B, then C is present and whenever A is absent
in background B, then C is nevertheless present.
166
5
Causation as Difference Making

A.2.7 Relevance in Conjunction
A1◊A2◊. . . ◊An R C j B ⟺∃fA1 ^ ⋯^ An ^ C; ØA1 ^ ⋯^ ØAn ^ ØCjBg
ðD7Þ
A.3 Simple Theorems
The distinction between lemmata and theorems in the following is somewhat
arbitrary, but shall convey some general sense of importance.
A.3.1 Lemma 1
ARC j B , ØARØC j B
ðL1Þ
Proof : ARC j B , ∃A ^ C; ØA ^ ØCjB
f
g , ∃ØA ^ ØC; A ^ CjB
f
g
, ØARØC j B
The ﬁrst equivalence holds due to (D1), the second equivalence holds because the
ordering of the instances is arbitrary, the third equivalence again holds due to (D1).
A.3.2 Lemma 2
AI C j B , ØAI C j B
ðL2Þ
Proof : A I C j B ⟺∃fA ^ C; ØA ^ CjBg ⟺∃fØA ^ C; A ^ CjBg ⟺ØA I C j B
The ﬁrst equivalence holds due to (D2), the second equivalence holds because the
ordering of the instances is arbitrary, the third equivalence again holds due to (D2).
Appendix: The Formal Framework
167

A.3.3 Lemma 3
∃A ^ C; ØA ^ ØCjB ^ X
f
g , ∃A ^ C ^ X; ØA ^ ØC ^ XjB
f
g
ðL3Þ
This follows from the manner, in which the background is deﬁned.
A.3.4 Lemma 4
ARcf C j B ) ∃X ! X Rcf C j B
ðL4Þ
ARcf C j B
, ∃X ! ARC j B ^ Xand AIØC j B ^ ØX
based on D3
ð
Þ
, ∃X ! ∃A ^ X ^ C; ØA ^ X ^ ØC; A ^ ØX ^ ØC; ØA ^ ØX ^ ØCjB
f
g
D1, D2, L3
ð
Þ
, ∃X ! XRC j B ^ Aand XIØC j B ^ ØA
L3, D1, D2
ð
Þ
) ∃X ! X Rcf C j B
D3
ð
Þ
Thus, as is plausible, if A is relevant as a causal factor to C, then there exists a
complementary causal factor X, wherein A ˄ X R C | B (see theorem T1).
A.3.5 Lemma 5
ARacC j B ) ∃X ! X RacC j B
ðL5Þ
ARacC j B
, ∃X ! ARC j B ^ ØXand AI C j B ^ X
based on D4
ð
Þ
, ∃X ! ∃A ^ ØX ^ C; ØA ^ ØX ^ ØC; A ^ X ^ C; ØA ^ X ^ CjB
f
g
D1, D2, L3
ð
Þ
, ∃X ! XRC j B ^ ØAand XI C j B ^ A
L3, D1, D2
ð
Þ
) ∃X ! X RacC j B
D3
ð
Þ
Thus, as is plausible, if A is relevant as an alternative cause to C, then there exists
a complementary alternative cause X, wherein A ˅ X R C | B (see theorem T2).
168
5
Causation as Difference Making

A.3.6 Theorem 1
ARcf C j B , ∃X ! A ^ X RC j B
ðT1Þ
This theorem together with theorem 2 is important as it shows that the notion of
causal relevance is scalable, i.e. can be employed at different levels of ˄ and ˅
combinations, if the background is adjusted accordingly.
Proof : ARcf C j B
, ∃X ! ARC j B ^ Xand AIØC j B ^ ØX
based on D3
ð
Þ
⟺∃X ! ∃fA ^ C; ØA ^ ØCjB ^ Xg and ∃fA ^ ØC; ØA ^ ØCjB ^ ØXg
ðD1, D2Þ
⟺∃X ! ∃fA ^ C ^ X; ØA ^ ØC ^ XjBg and ∃fA ^ ØC ^ ØX; ØA ^ ØC ^ ØXjBg
ðL3Þ
, ∃X ! ∃A ^ C ^ X; ØA ^ ØC ^ X; A ^ ØC ^ ØX; ØA ^ ØC ^ ØXjB
f
g
, ∃X ! ∃A ^ X ^ C; ØA ^ X ^ ØC; A ^ ØX ^ ØC; ØA ^ ØX ^ ØCjB
f
g
⟺∃X ! A ^ X R C j B
ðD1Þ
q.e.d.
A.3.7 Theorem 2
A RacC j B ) ∃X ! A _ X R C j B
ðT2Þ
This theorem together with theorem 1 is important as it shows that the notion of
causal relevance is scalable, i.e. can be employed at different levels of ˄ and ˅
combinations, if the background is adjusted accordingly.
Proof : ARacC j B
⟺A R C j B ^ ØX and A I C j B ^ X
ðbased on D4Þ
⟺∃X ! ∃fA ^ C; ØA ^ ØCjB ^ ØXg and ∃fA ^ C; ØA ^ CjB ^ Xg
ðD1, D2Þ
⟺∃X ! ∃fA ^ C ^ ØX; ØA ^ ØC ^ ØXjBg and ∃fA ^ C ^ X; ØA ^ C ^ XjBg
ðL3Þ
, ∃X ! ∃A ^ C ^ ØX; ØA ^ ØC ^ ØX; A ^ C ^ X; ØA ^ C ^ XjB
f
g
, ∃X ! ∃A ^ X ^ C; ØA ^ X ^ C; A ^ ØX ^ C; ØA ^ ØX ^ ØCjB
f
g
⟺∃X ! A _ X R C j B
ðD1Þ
q.e.d.
Appendix: The Formal Framework
169

A.3.8 Theorem 3
A I C | B˄X and A I C | B˄ØX ! A I C | B˄x, if X, ØX are all possible values of
x.41
A I C | B˄X and A I ØC | B˄ØX ! a I  c | B˄x, if A, ØA are all possible
values of a; C, ØC all possible values of c; and X, ØX all possible values of x.
A RC | B˄X and A RC | B˄ØX ! A RC | B˄x, if X, ØX are all possible values
of x.
These theorems are important, because they illustrate how relevance and irrele-
vance statements become more general, i.e. how the background can be extended,
when further evidence is collected.
Proof: The ﬁrst part is obvious.
For the second part, note that a speciﬁc notation irrelevance* needed to be
introduced because a circumstance X relevant to C changed in the context.
A I C j B ^ Xand A IØC j B ^ ØX
⟺A I C j B ^ X, ØA I C j B ^ X, A IØC j B ^ ØX and ØA IØC j B ^ ØX
Iff these four irrelevance statements are true, then by deﬁnition a I* c | B˄x is
true, where X R C | B˄a.
Regarding the third part:
A R C j B ^ X and A R C j B ^ ØX
⟺∃fA ^ X ^ C; ØA ^ X ^ ØC; A ^ ØX ^ C; ØA ^ ØX ^ ØCjBg
ðbased on < D1 > and < L3 >Þ
, X I C j B ^ A and X IØC j B ^ ØA
⟺x I c j B ^ aðbased on second part aboveÞ
) ARC j B ^ x
The last step follows, because x is irrelevant* to c with respect to background
B˄a.
A.3.9 Theorem 4
A ^ X R C j B ) A R C j B ^ X; A ^ X R C j B ) AIØC j B ^ ØX;
A _ X R C j B ) A I C j B ^ X; A _ X R C j B ) A R C j B ^ ØX
41There is no double arrow, since it is generally not required that all possible combinations in the
background must actually occur.
170
5
Causation as Difference Making

These relationships all follow directly from the deﬁnitions (D1*) and (D1**).
They illustrate, how relationships for a narrower background can be derived from
relationships for a wider background.
A.3.10 Theorem 5
A1◊A2◊. . .◊An R C | B , ∃{ A1 ˄ . . . ˄ An ˄ C; ØA1 ˄ . . . ˄ ØAn ˄ ØC | B} )
there is an inus-complex among the A, which is causally relevant to C with respect
to B.
The ﬁrst equivalence is deﬁnition (D7). Otherwise, the theorem follows from the
assumptions of homogeneity and determinism.
The theorem illustrates an important intuition that, while at ﬁrst irrelevant cir-
cumstances are co-varied with the actual causes, one can narrow down to the actual
causes by collecting further variational evidence. The theorem ensures that an
expression that is causally relevant exists among the covarying circumstances. For
example, one might ﬁrst observe an instance where a virus and full moon are present,
when a disease is present, and a further instance where the virus and full moon are
absent, when the disease is absent. Further inquiry and collection of instances will
then determine that the virus and not the full moon causes the disease.
A.3.11 Transitivity
XRY j B andYRZ j B ! XRZ j B
Proof : X R Y j B and Y RZ j B
, X ^ B ! Y, Ø X ^ B ! Ø Y, Y ^ B ! Z and Ø Y ^ B ! Ø Z
(based on D5 and D6)
)⁠ X ^ B ! Y ^ B ! Z, Ø X ^ B ! Ø Y ^ B ! Ø Z (B can be added to Y
and ØY, because the background will be present as well)
) X ^ B ! Z, ØX ^ B ! ØZ
, XRZ j B
Under certain conditions, the notions of causal factor, alternative cause and inus-
complex are also transitive (see Sect. 5.3.3). Transitivity, like the possibility to look
at causal relationships at different levels of coarse-graining, is a crucial tool for
keeping track of complex causal relationships.
Appendix: The Formal Framework
171

References
Anderson, Chris. 2008. The End of Theory: The Data Deluge Makes the Scientiﬁc Method Obsolete.
WIRED Magazine: 16/07. http://www.wired.com/science/discoveries/magazine/16-07/pb_
theory.
Baumgartner, Michael. 2013. A Regularity Theoretic Approach to Actual Causation. Erkenntnis 78:
85–109.
Baumgartner, Michael, and Gerd Graßhoff. 2004. Kausalität und kausales Schließen. Norderstedt:
Books on Demand.
Cartwright, Nancy. 1979. Causal Laws and Effective Strategies. Noûs 13 (4): 419–437.
———. 1994. Nature’s Capacities and Their Measurement. Oxford: Oxford University Press.
———. 2007. Hunting Causes and Using Them. Cambridge: Cambridge University Press.
Eberhardt, Frederick. 2009. Causation and Intervention. PhD Thesis. http://www.its.caltech.edu/
~fehardt/papers/PhDthesis.pdf. Accessed 3.9.2017.
Eberhardt, Frederick, and Richard Scheines. 2007. Interventions and Causal Inference. Philosophy
of Science 74 (5): 981–995.
Frisch, Mathias. 2014. Causal Reasoning in Physics. Cambridge: Cambridge University Press.
Galles, David, and Judea Pearl. 1997. Axioms of Causal Relevance. Artiﬁcial Intelligence 97: 9–43.
Goodman, Nelson. 1983. Fact, Fiction, and Forecast. Cambridge, MA: Harvard University Press.
Hausman, Daniel M. 1998. Causal Asymmetries. Cambridge: Cambridge University Press.
Holland, Paul W. 1986. Statistics and Causal Inference. Journal of the American Statistical
Association 81 (396): 945–960.
Horwich, Paul. 1987. Asymmetries in Time. Cambridge, MA: MIT Press.
Hume, David. 1748. An Enquiry Concerning Human Understanding. London: A. Millar.
Hüttemann, Andreas. 2013. Ursachen. Berlin: de Gruyter.
Illari, Phyllis, and Jon Williamson. 2012. What Is a Mechanism? Thinking About Mechanisms
Across the Sciences. European Journal for Philosophy of Science 2 (1): 119–135.
Kim, Jaegwon. 1973. Causes and Counterfactuals. Journal of Philosophy 70: 570–572.
Lewis, David. 1973. Causation. Journal of Philosophy 70: 556–567.
———. 1979. Counterfactual Dependence and Time’s Arrow. Noûs 13: 455–476.
———. 1986. Postscripts to ‘Causation’. In Philosophical Papers, vol. II, 172–213. Oxford:
Oxford University Press.
———. 2000. Causation as Inﬂuence. Journal of Philosophy 97: 182–197.
———. 2001. Counterfactuals. Oxford: Blackwell.
Mackie, John L. 1980. The Cement of the Universe. Oxford: Oxford University Press.
Mayer-Schönberger, Viktor, and Kenneth Cukier. 2013. Big Data. London: John Murray.
Menzies, Peter. 2014. Counterfactual Theories of Causation. Stanford Encyclopedia of Philosophy
(Spring 2014 Edition). Available online: http://plato.stanford.edu/entries/causation-counterfac
tual/.
Mill, John S. 1843/1950. Philosophy of Scientiﬁc Method. New York: Hafner.
———. 1886. System of Logic Ratiocinative and Inductive. London: Longmans, Green, and Co.
Paul, L.A., and Ned Hall. 2013. Causation: A User’s Guide. Oxford: Oxford University Press.
Pearl, Judea. 2000. Causality. New York: Cambridge University Press.
———. 2018. The Book of Why. New York: Basic Books.
Pietsch, Wolfgang. 2014. The Structure of Causal Evidence Based on Eliminative Induction. Topoi
33 (2): 421–435.
———. 2016a. The Causal Nature of Modeling with Big Data. Philosophy & Technology 29 (2):
137–171.
———. 2016b. Two Modes of Reasoning with Case Studies. In Philosophy of Historical Case
Studies. Boston Studies in the Philosophy of Science, ed. T. Sauer and R. Scholl, 49–67.
Springer: Dordrecht.
172
5
Causation as Difference Making

Price, Huw, and Brad Weslake. 2009. The Time-Asymmetry of Causation. In The Oxford Hand-
book of Causation, ed. H. Beebee, C. Hitchcock, and P. Menzies, 414–443. Oxford: Oxford
University Press.
Psillos, Stathis. 2015. Counterfactual Reasoning, Qualitative: Philosophical Aspects. In Interna-
tional Encyclopedia of the Social & Behavioral Sciences, ed. James Wright, 87–94. Amsterdam:
Elsevier.
Reutlinger, Alexander. 2012. Getting Rid of Interventions. Studies in the History and Philosophy of
Science Part C 43 (4): 787–795.
Russell, Bertrand. 1913. On the Notion of Cause. Proceedings of the Aristotelian Society 13: 1–26.
Russo, Federica. 2009. Causality and Causal Modelling in the Social Sciences. Measuring Vari-
ations. New York: Springer.
———. 2014. What Invariance is and How to Test for it. International Studies in the Philosophy of
Science 28 (2): 157–183.
Skyrms, Brian. 2000. Choice and Chance. Belmont: Wadsworth.
von Wright, Georg H. 1951. A Treatise on Induction and Probability. New York: Routledge.
Woodward, James. 2003. Making Things Happen: A Theory of Causal Explanation. Oxford:
Oxford University Press.
———. 2013. Causation and Manipulability. Stanford Encyclopedia of Philosophy (Winter 2013
Edition). http://plato.stanford.edu/archives/win2013/entries/causation-mani/.
References
173

Chapter 6
Evidence
Abstract In this Chapter, a reﬁned version of Mill’s inductive methods is proposed
that is based on two fundamental methods, the method of difference to determine
causal relevance and the strict method of agreement to determine causal irrelevance.
This framework for variational induction is supposed to underly all inductive
inferences in machine learning, data science and beyond. It is both simpler and
more rigorous than comparable accounts of variational induction. It is argued that the
problem of variational induction is distinct from David Hume’s problem of enumer-
ative induction. Speciﬁcally, variational induction does not presuppose an indefen-
sible uniformity of nature, but instead the following premises which are more
plausible: (i) the principle of causality that every phenomenon is fully determined
by its circumstances; (ii) an adequate causal language; (iii) constancy of background;
(iv) repeatability of background and causal conditions. This analysis mitigates the
problem of induction insofar as it is relevant for the project of an inductivist data
science. Since many data science algorithms implement variational induction, the
above analysis can be used to determine the necessary premises in order for these
algorithms to yield reliable results. Furthermore, the analysis of the problem of
variational induction allows evaluating the controversial issue of theory-ladenness
in data science.
Keywords Data science · Causation · Mill’s canons · Mill’s methods ·
Determinism · Problem of induction · Theory-ladenness
6.1
Mill’s Methods Revisited
We now turn from the conceptual question, what causation is to the methodological
question how causal relationships can be determined via inductive methods. In other
words, the perspective is shifted from the abstract realm of deﬁnitions to concrete
situations of evidence that allow for causal inferences. For example, rather than
asking, whether an instance exists in principle as in the deﬁnitions of causal
relevance and irrelevance of the previous chapter, we now focus on whether such
instances are actually observed. Given the characterization of data science in
© Springer Nature Switzerland AG 2022
W. Pietsch, On the Epistemology of Data Science, Philosophical Studies Series 148,
https://doi.org/10.1007/978-3-030-86442-2_6
175

previous chapters, the framework to be presented in the following in our view under-
lies inductive inferences in machine learning and beyond.
In the following, a reﬁned version of Mill’s methods will be delineated, which is
intended to solve some of the major problems not only of Mill’s own approach but
also of later accounts, in particular that of John L. Mackie, which may be the most
sophisticated version of variational induction to date (cp. Sect. 4.2.4). The proposed
framework, which has been broadly outlined in Pietsch (2014), directly derives from
the difference making interpretation of causation in the previous chapter. In partic-
ular, the two basic methods of the proposed framework follow from the two
fundamental deﬁnitions of the difference making account of causation. Speciﬁcally,
the method of difference directly corresponds to the deﬁnition of causal relevance
and the strict method of agreement to the deﬁnition of causal irrelevance as given in
Sect. 5.2.1.
Thus, the proposal is to base variational induction exclusively on two fundamen-
tal methods, the method of difference to determine causal relevance and the strict
method of agreement to determine causal irrelevance:
Method of difference: If two instances with the same background B are observed, which
differ in a potentially relevant circumstance A and in a change of phenomenon C, then A is
causally relevant to C with respect to background B, if B guarantees homogeneity.
Strict method of agreement: If two instances with the same background B are observed,
which differ in a potentially relevant circumstance A, while the phenomenon C remains
unchanged, then A is causally irrelevant to C with respect to background B, if B guarantees
homogeneity.
According to the proposed framework, these two methods exhaust the funda-
mental methodology of causal inference. This is plausible for the case when homo-
geneity is fulﬁlled, since then the method of difference and the strict method of
agreement are exactly complementary. Otherwise, there may be relationships
between A and C with respect to non-homogeneous backgrounds, which constitute
neither causal relevance nor causal irrelevance (cf. Sect. 5.2.2). But such situations
can be covered by introducing further causal terminology that is itself deﬁned
entirely on the basis of causal relevance and irrelevance, including most importantly
causal factors, alternative causes and inus conditions. With these further notions, all
types of causal dependencies can be derived from the two above methods under two
assumptions: that the considered set-up is deterministic and that one is not yet
dealing with functional relationships, but only with the presence or absence of
factors. However, extensions of the framework covering statistical and functional
relationships are straightforward (cp. Sect. 5.3.4 and Chap. 9).
One might object that homogeneity of background, as required for both methods,
cannot be observed. However, as is clear from the deﬁnition of homogeneity in Sect.
5.2.2, homogeneity is itself deﬁned in terms of causal relevance and irrelevance.
Therefore, the question, whether a background is homogeneous can itself be exam-
ined based on the determination of relevance or irrelevance. This circularity is not
vicious, since the background concerns other variables than the variable, for which
causal relevance or irrelevance is explicitly assessed by the method of difference or
the strict method of agreement. As a consequence, the basic type of evidence for
176
6
Evidence

variational induction are pairs of observations that show difference or indifference
making in a given context.
A further objection is that causal dependency usually presupposes an asymmetry
that A needs to be causally prior or at least simultaneous to C, while such an
asymmetry clearly is not present in any of the two proposed methods. This topic
was brieﬂy addressed in Sect. 5.2.3, where it was argued that causal priority can be
derived from evidence on causal chains in combination with interruption and
stimulation variables. Thus, causal priority presumably can itself be determined
with the two methods at least in principle, again based on the mentioned type of
evidence of observation pairs that show difference or indifference making in a given
context.
Let me brieﬂy compare the proposed approach with other prominent expositions
of variational induction as discussed in much detail in Chap. 4. The most popular and
most cited account until today remains Mill’s own formulation, which is usually
referred to as Mill’s methods. Most of these methods had already been known at least
since the middle ages and there were inﬂuential systematizations before Mill, most
notably Bacon’s and Herschel’s. However, it seems fair to say that Mill’s presenta-
tion is in general more systematic and concise than these other accounts, introducing
the following ﬁve methods or canons of induction: the method of agreement, the
method of difference, the joint method of agreement and difference, the method of
residues, and the method of concomitant variations.
Mill’s own method of difference, which was already stated in Sect. 4.2.2, is quite
similar to the formulation above. However, the latter adds some reﬁnements, in
particular introduces background-dependence and the requirement of homogeneity.
Also, the above formulation speciﬁes that causal relevance is derived rather than
causes or parts of causes as in Mill’s formulation.
Mill’s method of agreement is reinterpreted as a method for determining causal
irrelevance. Nevertheless, Mill’s original reading as a method for determining
potential causes can be recovered as well: “If two or more instances of the phenom-
enon under investigation have only one circumstance in common, the circumstance
in which alone all the instances agree, is the cause (or effect) of the given phenom-
enon.” (1886, 255) Indeed, with the proposed framework of variational induction,
the exact premises can be determined, under which Mill’s method of agreement is
valid. For example, there must not be alternative causes among the varying circum-
stances. After all, the phenomenon could be due to different causes in different
instances, while the only common circumstance is in fact irrelevant.
Somewhat more reliable than the method of agreement is Mill’s joint method of
agreement and of difference: “If two or more instances in which the phenomenon
occurs have only one circumstance in common, while two or more instances in
which it does not occur have nothing in common save the absence of that circum-
stance; the circumstance in which alone the two sets of instances differ is the effect,
or cause, or an indispensable part of the cause, of the phenomenon.” (1886, 259) But
again, the presence of alternative causes may undermine such conclusions. However,
based on the proposed framework of variational induction, the irrelevance of
6.1
Mill’s Methods Revisited
177

co-varying circumstances can be established such that inferences based on the joint
method are corroborated.
The method of residues can also be made plausible based on the method of
difference and the strict method of agreement: “Subduct from any phenomenon such
part as is known by previous inductions to be the effect of certain antecedents, and
the residue of the phenomenon is the effect of the remaining antecedents.” (1886,
260) Again, there is no difﬁculty in determining the speciﬁc premises, under which
such inferences are valid. In particular, ensuring homogeneity is crucial. Finally, we
have already discussed in much detail in Sect. 5.3.4, how Mill’s method of concom-
itant variations determining functional relationships can be based on judgments of
causal relevance regarding the presence and absence of factors.
A small number of novel formulations of variational induction have been pro-
posed in the twentieth century, most notably by von Wright (1951, Ch. 4), Skyrms
(2000, Ch. 5), and Mackie (1980, Appendix), but none of these seems to have
eclipsed Mill’s original framework. In a way, these modern approaches are some-
what more systematic, since they start from an explicit logic of necessary and
sufﬁcient conditions and then try to reformulate in particular Mill’s methods of
agreement, of difference, and the joint method. Unfortunately, the resulting meth-
odology is quite complex. Mackie’s framework, for example, which was discussed
in detail in Sect. 4.2.4, introduces a complicated classiﬁcation scheme for the basic
methodology that depends both on the speciﬁc method one uses, e.g. method of
difference or method of agreement, and on the type of causal condition one is after,
i.e. whether the suspected cause is a single factor, a negation of a factor, a conjunc-
tion of factors, a disjunctions of factors, etc. Presumably, the complexity of such
frameworks based on a logic of necessary and sufﬁcient conditions is one of the main
reasons why they have not caught on.
Still, Mackie’s account seems the most sophisticated approach to variational
induction in the tradition of Mill’s methods so far. In particular, it solves some of
the problems of Mill’s original account, as was shown in Sect. 4.2.4. In particular,
Mackie’s approach is able to deal with the plurality and the composition of causes,
just as the framework proposed in this section. However, Mackie’s approach has a
number of drawbacks, which were discussed in Sect. 4.2.4. Let us now brieﬂy
examine, whether the proposed framework can hint at solutions to these problems.
First, Mackie offers a confusing variety of different methods. All in all, there are
several dozens of distinct methods, the exact relation between which remains
somewhat unclear. By contrast, the framework of variational induction as proposed
above is very simple relying on just two fundamental methods, the method of
difference to infer causal relevance and the strict method of agreement to infer
causal irrelevance. All other notions can be derived from these.
Second, scientists usually do not make any a priori assumptions about the logical
structure of the underlying phenomena, e.g. whether conjunctions of circumstances
are allowed as causes or not. Such assumptions are required by Mackie’s approach in
order to choose the right inductive method. By contrast, according to the proposed
framework no additional assumptions about the logical structure of the phenomena
178
6
Evidence

have to be presupposed except for some very general ones such as determinism,
which in any case can be weakened as we will see later.
Third and relatedly, one would expect of an account of variational induction that
the mentioned logical structure can be inferred from empirical evidence rather than
having to be assumed. In particular, variational induction should be able to
destinguish, whether a variable is e.g. an inus condition or a full cause. Indeed,
this is possible according to the proposed account. By applying the method of
difference and the strict method of agreement in different contexts, causal factors,
alternative causes and inus complexes can for example be identiﬁed (see Sect. 5.3.1).
Fourth, Mackie’s account presupposes an adequate conceptual framework for
every examined phenomenon, with which the causal structure can be analyzed. But
the formulation of such a framework is often considered a crucial part of the
inductive process. This topic will be brieﬂy addressed in the next Chap. 7, where I
will argue that the proposed framework of variational induction can also be used for
causal concept formation.
A ﬁfth problem is that Mackie fails to convincingly integrate his concept of a
causal ﬁeld into his formal variational approach. In particular the ﬁeld concept is
much too static compared with actual scientiﬁc practice. It lacks the dynamical
nature that background conditions exhibit in many empirical investigations. For
example, conditions may at one point be considered as part of the background and
later as candidates for causes. Also, the background is extended, when phenomeno-
logical laws are generalized, for which Mackie’s approach does not account. By
contrast, as should be clear from the discussion in Chap. 5, the proposed account
very much sees changes of the background as an integral part of the variational
approach. For example, changes of the background play an important role in the
deﬁnitions of causal factors and alternative causes, as stated in Sect. 5.3.1. Towards
the end of the same section, theorems were given how to formally account for the
widening of the background, when the range of applicability of a causal relationship
is extended.
In summary, I claim that the proposed framework of variational induction, which
relies on causal relevance and irrelevance instead of necessary and sufﬁcient condi-
tions as in Mackie’s approach and which reinterprets the method of agreement as a
method for determining causal irrelevance, has the crucial advantage of simplicity
and rigor in comparison to all other accounts of variational induction that have been
suggested until today.
6.2
Hume’s Problem of Induction Revisited
The feasibility and reliability of inductive inferences has in the past often been
criticized. This criticism culminates in the so-called problem of induction, the
relevance of which for the proposed framework of variational induction we will
examine in the following. The discussion in this and the following section is
supposed to mitigate the problem of induction as far as it is relevant for scientiﬁc
6.2
Hume’s Problem of Induction Revisited
179

practice in data science. This eliminates one of the crucial objections against an
inductivist data science (cp. Chap. 2).
Several epistemologists, including such authorities as Bacon, Mill, or Keynes,
have in the past criticized enumerative induction as a primitive methodology,
i.e. inferences from a number of particular observations of As that are also C to
the general law that all As are C (e.g. Vickers 2014, Sec. 1). And indeed variational
induction draws a much more realistic picture of the inductive process. For example,
it can account for Mill’s observation that sometimes we can reliably infer from only a
few instances—ideally the method of difference needs only two—while in other
situations nothing can be learned even from a large number of instances (Mill 1843,
Ch. III.III). Indeed, variational induction points to the right kind of evidence required
for causal knowledge, namely variational evidence, i.e. instances of a phenomenon
under varying circumstances, instead of a mere repetition of instances (cf. also Russo
2009). This ﬁts well with the observation that reliable causal knowledge is often
generated in experimental contexts, i.e. in laboratory environments, which are
distinguished by an excellent control over potentially relevant circumstances.
Another crucial difference is that in the case of variational induction, one can
show how increasing variational evidence steadily increases the quality of causal
knowledge, while nothing analogous can be claimed for enumerative induction
(cp. Chap. 4).
Every inductive method has its own problem of induction essentially consisting
in the question under which premises reliable inferences result. The traditional
problem of induction, notably in Hume’s inﬂuential formulation, refers mostly to
enumerative induction. Usually, enumerative inferences are taken to presuppose
some principle of the uniformity of nature, which Hume states as follows: “that
instances of which we have had no experience, must resemble those, of which we
have had experience, and that the course of nature continues always uniformly the
same.” (Hume 2009, 62; cited in Vickers 2014, §2) This is indeed impossible to
justify on a general level—essentially due to the vicious circularity that nature is
only uniform in those aspects for which inductive inferences are valid.
The problem of variational induction is completely distinct from Hume’s problem
of enumerative induction. In particular, variational induction does not presuppose an
indefensible uniformity of nature, but rather the following principles that are much
more plausible if however anything but trivial: (i) the principle of causality that every
phenomenon, or at least the examined phenomenon, is fully determined by its con-
ditions or circumstances; (ii) an adequate causal language; (iii) constancy of back-
ground; (iv) repeatability of background and causal conditions (Pietsch 2014,
Sec. 3.6).
Item (ii) will be discussed in the next Chap. 7. It directly relates to Goodman’s
new riddle that explicitly addresses the linguistic dimension of induction (Sect. 7.3).
While the development of causal categories that are adequate for a given phenom-
enon constitutes a considerable challenge, this issue illustrates well some realistic
aspects of variational induction with respect to scientiﬁc practice. Most importantly,
conceptual development always goes hand in hand with the formulation of empirical
laws.
The
framework
of
variational
induction
and
the
corresponding
180
6
Evidence

difference-making account of causation are well-suited to trace how a reﬁnement of
language may take place during the inductive process, when increasing evidence is
gathered.
Regarding item (iii), the requirement of a constant background or context, one
can never be absolutely certain that it is fulﬁlled. But again, the framework outlined
above and in the preceding chapters delineates a procedure how causal knowledge
can be improved in this regard by accumulating the right kind of evidence. In
particular, it can be shown that circumstances, which were originally only postulated
or believed to be irrelevant, really are irrelevant to a phenomenon with respect to a
well-deﬁned background.
Finally, item (iv) is only required if predictions are to be made on the basis of
causal knowledge, not for the analysis of causal relations as such. Therefore, it need
not always be fulﬁlled, rather it should be considered a matter of contingent fact
whether it is the case or not. This ﬁts well with the role of causal analysis for example
in historical or juridical contexts, where repeatability is often not granted. The
historical conditions leading to the Second World War are certainly not repeatable
nor are the political circumstances leading to the creation of the European Union.
Note that of course repeatability depends on the level of coarse-graining of the
description.
Let us now turn to the principle of causality (i) which arguably constitutes the
crucial premise for variational inferences. Why this principle is required is easy to
see by constructing indeterministic situations, where the method of difference and
the strict method of agreement fail, and thus also the deﬁnitions of causal relevance
and irrelevance do not apply. For example, a certain indeterministic phenomenon
may change due to pure chance while at the same time a circumstance varies that is
in fact completely irrelevant to the phenomenon. Obviously, the method of differ-
ence of Sect. 6.1 applying the deﬁnition of causal relevance from Sect. 5.2.1 would
lead to a wrong conclusion in this case.
From a modern perspective, one might be inclined to think that any method that
presupposes the principle of causality cannot be taken seriously given that many
sciences, from quantum mechanics to sociology, nowadays assume the ubiquity of
indeterminism. However, I will argue now that variational induction and thus the
difference-making account also work for weakened versions of the principle of
causality which are compatible with some amount of ‘tame’ indeterminism, while
in the case of ‘wild’ and unrestricted indeterminism science would not be possible
anyways.
A number of authors have pointed out that a trivial sort of determinism is
generally irrefutable and thus cannot be in contradiction to the mentioned develop-
ments in science. For our purposes, the following version of such trivial determinism
is suitable: Any distinct event is individualizable in terms of conditions or circum-
stances. Such determinism is quite plausible and intuitive given that pretty much
every event is individualizable at least in terms of spatial and temporal coordinates,
which according to the argument sketched in Sect. 5.2.3 are just shorthand for
describing complex sets of causal relationships with causally prior or simultaneous
events.
6.2
Hume’s Problem of Induction Revisited
181

Given this trivial determinism, every event is indeed causally ﬁxed, at the very
least by the full list of prior or simultaneous circumstances. Certainly, this is not what
scientists are after. Even if nature were fully determined in this sense, our epistemo-
logical situation would deny us access to the full list of causes. Furthermore, these
causes may not explain much or may not even ground reliable predictions.
Still, the feasibility of trivial determinism implies that variational induction as a
scientiﬁc method cannot be falsiﬁed, as opposed to enumerative induction, which in
fact keeps being refuted time and again. After all, it often occurs that a constant
conjunction is observed for a large number of times only to fail later at a further trial.
By contrast, in the case of variational induction, an analogous situation cannot
happen: if the same phenomenon fails to occur under seemingly the same circum-
stances with respect to the same background, one has to conclude that a causally
relevant circumstance was ignored, or alternatively that the chosen language was
inappropriate. This move is always possible given the mentioned trivial determin-
ism. In fact, variational induction relies on a principle of uniformity of nature that is
true by deﬁnition: “Future events are similar to those of the past with respect to
causal inferences if they differ only in terms of circumstances that are irrelevant for
the inference.” In this sense, variational induction is consistent and irrefutable.
If aiming at predictions and explanations, one has to assume in addition that the
world is to some extent orderly, i.e. that certain individual events can be grouped
together and can be shown to be causally relevant for other groups of events in
certain contexts. John Maynard Keynes has formulated a requirement to that purpose
that he termed principle of limited independent variety: “the objects in the ﬁeld, over
which our generalisations extend, do not have an inﬁnite number of independent
qualities; that, in other words, their characteristics, however numerous, cohere
together in groups of invariable connection, which are ﬁnite in number.” (1921,
Ch. 22) This leads us back to premise (iv). While endorsing the spirit and motivation
of Keynes’ principle, I would suggest a slightly different criterion that might be
called the principle of repeatability of relevant circumstances: at least for some
causal relationships, background and relevant conditions should be so unrestrictive
that they can and will reoccur. As indicated before, for some phenomena, this
principle is not fulﬁlled.
There are a number of old and venerable principles in discussions on scientiﬁc
method that work towards restricting the number of potentially relevant conditions.
The most important is the principle of locality according to which an event can only
be (immediately) causally relevant to other events in its immediate spatial and
temporal vicinity. Apparently, this principle of locality excludes a large number of
circumstances from the list of potential immediate causes. Assuming locality should
not be seen as a strictly binding ontological constraint, but rather it has signiﬁcant
pragmatic connotations enabling variational induction in the ﬁrst place. An argument
for both temporal and spatial locality could start from the assumption that our space-
time geometry may be fully supervenient on causal dependencies (cp. Sect. 5.2.3).
Broadly speaking, it is not only the case that events can interact causally because
they are close, but also that events are considered close because they can causally
interact.
182
6
Evidence

Another old acquaintance from the history of philosophy regards the principle of
(qualitative and quantitative) equality of cause and effect. Without going into details,
one should also consider it a pragmatic constraint, rather than an ontological
necessity. In the case of repeated and ubiquitous violation of this principle to
exorbitant extent, science would just not be possible anymore.
Even if the outlined trivial determinism is irrefutable in principle, it may some-
times be useful to work with various versions of tame indeterminism. The most
innocuous variant of indeterminism is the kind one encounters in quantum mechan-
ics according to the orthodox Copenhagen interpretation, where the circumstances
do not ﬁx the speciﬁc event that is happening, but only a probability distribution over
related events. Such situations are relatively harmless and fully accessible to varia-
tional induction since determinism is restored on a coarse-grained level, apart from
the additional conceptual difﬁculty how to determine relevance or irrelevance with
respect to probability distributions, i.e. essentially with respect to ensembles of
instances. Indeed, orthodox quantum mechanics is deterministic at the level of
wave functions, i.e. probability distributions, whose evolution is fully determined
by the Schrödinger Equation.
One could imagine a somewhat stronger indeterminism, where not even the
probability distribution is ﬁxed by circumstances, but only a range of events. If
both the range of effects and the range of causes are sufﬁciently constrained, one can
still deﬁne summary events. On the coarse-grained level of such summary events a
deterministic description once again becomes feasible. Such indeterminism can
become increasingly wild and complex, i.e. a large variety of events may follow
arbitrarily after a large variety of circumstances. The world would become increas-
ingly chaotic and unpredictable. In the limit of the wildest indeterminism imagin-
able, where anything can happen after anything, science becomes impossible. Note
that variational induction may still formally work, if all events are individualizable in
terms of spatiotemporal coordinates, but predictability is entirely lost.
In summary, indeterminism can only be handled scientiﬁcally, if determinism can
be restored on a coarse-grained level of description involving probability distribu-
tions and/or summary events. This perspective is corroborated in the conceptual
analysis of causal probability of Chap. 9. The restriction to deterministic contexts in
the difference-making account neither narrows down the range of application nor
does it prevent the framework from being applied to the usual cases of indeterminism
familiar from the sciences.
6.2
Hume’s Problem of Induction Revisited
183

6.3
Data Curation and Theory-Ladenness1
The proposed framework of variational induction as well as the analysis of the
problem of variational induction in the two previous sections allow for a fresh look at
the issue of theory-ladenness in phenomenological science and in particular data
science. The question, how much theory has to be presupposed in data science is
important for the transferability of data, i.e. how well and how far data can travel
from one research context to another (cp. Leonelli 2016). If the theoretical context is
indispensable already for the formulation and statement of data, this would cast
doubt whether the same data can at all be used in different theoretical contexts. At a
minimum, in data curation the theoretical context would always need to be added to
the data points and sets such that when the context changes, this could be taken into
account for the formulation of the data. By contrast, if data can be fairly theory-free,
they could much more easily travel from one research context to another.
Proponents of big data and data science claim that important changes are hap-
pening with respect to the role of theory. An extreme, but highly inﬂuential version
of such a statement is by the former editor-in-chief of WIRED Chris Anderson, who
notoriously proclaimed “the end of theory” altogether (2008). More nuanced posi-
tions can be found for example in the writings of Google research director Peter
Norvig (2009): “Having more data, and more ways to process it, means that we can
develop different kinds of theories and models.” Simpler models with a lot of data
supposedly trump more elaborate models with less data (Halevy et al. 2009, 9).
A number of philosophers have objected to claims of a theory-free science—
generally by pointing out various kinds of theory-ladenness. For example, Werner
Callebaut writes: “We know from Kuhn, Feyerabend, and [. . .] Popper that obser-
vations (facts, data) are theory-laden. Popper [. . .] rejected the ‘bucket theory of
knowledge’ in favor of the ‘searchlight theory,’ according to which observation ‘is a
process in which we play an intensely active part.’ Our perceptions are always
preceded by interests, questions, or expectations—in short, by something ‘specula-
tive’.” (Callebaut 2012, 74) Leonelli concurs in her work on big data biology:
“Using data for the purposes of discovery can happen in a variety of ways, and
involves a complex ensemble of skills and methodological components. Inferential
reasoning from data is tightly interrelated with speciﬁc theoretical commitments
about the nature of the biological phenomena under investigation, as well as with
experimental practices through which data are produced, tested and modelled. For
instance, extracting biologically meaningful inferences from high-throughput geno-
mic data may involve reliance on theories about gene expression and regulation,
models of the biological processes being regulated and familiarity with the instru-
ments and organisms from which data were obtained. In this context, ‘inductive’
clearly does not mean ‘hypothesis-free’; nor can automated reasoning be seen as a
substitute to human judgment based on speciﬁc expertise and laboratory experi-
ence.” (2012, 2).
1The exposition in this section is based on Pietsch (2015).
184
6
Evidence

Certainly, the idea of an entirely theory- or model-free science is absurd. So,
Callebaut and Leonelli rightly point out various kinds of theoretical assumptions that
enter scientiﬁc analyses. But this kind of argument turns out too general and in the
end fails to do justice to the remarkable shift towards a strongly inductive approach
in the wake of data science. Instead, the interesting question is in which ways
scientiﬁc approaches based on big data are indeed theory-laden, and, more impor-
tantly, in which sense they can be theory-free. To provide an answer, we now take a
detailed look at two algorithms that are widely employed, namely classiﬁcatory trees
and non-parametric regression. We link these methods to variational induction and
then determine the kind of theoretical knowledge that has to be presupposed.
Let me address as a ﬁrst example the question of theory-ladenness in decision
trees as introduced in Sect. 4.3.1. In that section, I had already pointed out that
decision trees rely on variational induction in order to derive reliable predictions
from the data. Thus, the main premises that have to be fulﬁlled correspond to those
that were identiﬁed in the previous Sect. 6.2 for variational induction. Furthermore,
there are premises that are speciﬁc to the individual algorithms, in particular owing
to deﬁciencies or problems in these algorithms.
Based on the analysis in the previous section, we can now identify the elements of
theory that have to be presupposed. In particular: (a) one has to know all variables A
that are potentially relevant for the phenomenon C in a given context determined by
the background B; (b) one has to assume that for all collected instances and
observations the relevant background conditions remain the same, i.e. a stable
context B; (c) one has to have good reasons to expect that the variables A are
formulated in stable causal categories that are adequate for a speciﬁc research
question; (d) there must be a sufﬁcient number of instances to cover all potentially
relevant conﬁgurations of the phenomenon. If such theoretical knowledge can be
established, then there is enough data to avoid spurious correlations and to map the
causal structure of the phenomenon without further internal theoretical assumptions
about the phenomenon.
This motivates and explains the deﬁnition of data science given in Sect. 1.1. In
particular, the premise that data sets shall represent a large part of all possible
variations of a complex phenomenon turns out to be a fundamental condition for
enabling a strongly inductive approach based on variable variation. This viewpoint is
further corroborated by the fact that in many cases data-driven approaches become
effective rather suddenly—a transition point that could be called a data threshold
(Halevy et al. 2009). Halevy et al. give a plausible explanation for its existence: “For
many tasks, once we have a billion or so examples, we essentially have a closed set
that represents (or at least approximates) what we need, without generative rules.”
(2009, 9) At this threshold, the data represents a large fraction of the relevant
conﬁgurations of the considered phenomenon.
Of course, in scientiﬁc practice full theoretical knowledge (a) to (d) is rarely
available. However, in general, including more potentially relevant variables A will
increase the probability that the actual cause of C might be among them, while
admittedly also increasing the probability for spurious correlations, i.e. that bound-
ary conditions accidentally produce the right classiﬁcation. However, more data in
6.3
Data Curation and Theory-Ladenness
185

terms of instances of different conﬁgurations can reduce the probability for such
spurious correlations. Thus, more data in terms of variables and instances will
generally increase the chance that correct causal relations are identiﬁed by data-
intensive algorithms.
As a second example, let us brieﬂy address non-parametric regression in contrast
with conventional parametric regression (as introduced in Sect. 2.4). The main
difference in terms of theoretical assumptions is that in parametric regression the
type of functional dependency is presupposed in contrast to non-parametric regres-
sion. The latter again relies on variational induction. Essentially, it constitutes a case
of Mill’s method of concomitant variations, which derives its inferential power from
the method of difference as argued in Sect. 5.3.4 (see also Skyrms 2000, Sec. V.9, or
Pietsch 2014, Sec. 3d). Therefore, the conditions for identifying a causal relationship
are largely the same as those discussed in the previous Sect. 6.2—determinism,
constancy of the background, and correct causal language—resulting in the same
premises in terms of theoretical assumptions (a)-(d). In particular, when mapping a
functional dependency, all causally relevant conditions in the background must
remain constant. And there must be sufﬁcient data points such that the functional
dependence can be traced in adequate detail.
We are ﬁnally in a position to evaluate the claims concerning a theory-free
science. In both case studies, certain elements of theory had to be presupposed in
order to yield reliable results in terms of causal structure that in turn can underwrite
successful prediction and manipulation. In particular, among the considered vari-
ables must be those that are causally relevant for a phenomenon in a considered
context and not too many that are causally irrelevant to avoid spurious correlations.
Also, the variables should reﬂect adequate causal categories. Finally, the collected
instances or observations should cover all conﬁgurations that are relevant with
respect to a given research question.
Because these aspects all concern the framing of the problem, one could speak of
external theory-ladenness. By contrast, there is another kind of theory-ladenness that
is largely absent from data-intensive scientiﬁc approaches. For example, in classiﬁ-
catory trees no hypotheses are made about causal connections that link the various
variables. Equally, in non-parametric regression, no assumptions are presupposed
about the functional dependencies between different quantities. Thus, the essential
difference in comparison with a hypothesis-driven approach is that not much is
presupposed about the internal causal structure of the phenomenon. Rather, this
structure is mapped from the data by variable variation, i.e. by variational induction.
How novel is this approach? On closer scrutiny, data science much resembles the
practice of exploratory as distinguished from hypothesis-directed experimentation
(Steinle 1997; Burian 1997; Waters 2007; Vincenti 1993, 291; see also Sect. 3.2).
Exploratory experimentation essentially consists in the same variational induction,
where the experimenter tries to map the system of interest in all those states that she
considers relevant. It is this common methodological core, which links exploratory
experimentation and data science and speaks against the claim, for example by
Krohs (2012), that the latter constitutes a novel experimental approach focusing on
data-gathering.
186
6
Evidence

Not surprisingly, the debate concerning theory-ladenness in exploratory experi-
mentation parallels the discussion concerning theory-ladenness in data science of the
present section. For example, Steinle (2005) suggests a distinction between different
kinds of theory-ladenness. According to his view, exploratory experimentation pre-
supposes theoretical knowledge in terms of classiﬁcation systems or empirical rules,
but not in terms of theories that postulate empirically inaccessible abstract entities
(285). Steinle refers to Duhem, Hacking and Cartwright as having drawn similar
distinctions between an experimental/phenomenological and a theoretical level in
scientiﬁc theories. Indeed, the distinction between exploratory and hypothesis-
driven experimentation ﬁts well with Hacking’s (1983) claim that experiments
have a life of their own and Cartwright’s (1983) position of entity realism, which
postulates a causal level in science that is mostly phenomenological and largely
independent of the theoretical level.
Building on Burian and Steinle’s work, Kenneth Waters emphasizes a subtle
difference between ‘theory-directed’ and ‘theory-informed’. While in exploratory
experimentation, background theories are used “to set up experiments, generate data,
and draw conclusions”, such experiments “are not ‘directed’ by the aim to test,
develop, or otherwise articulate an existing theory or hypothesis.” (2007, 280) Laura
Franklin makes a similar point that exploratory experiments are theory-laden in
terms of background knowledge, but not in terms of local theories (2005, 891).
These remarks closely resemble the previous discussion regarding external and
internal theory-ladenness. As we have seen in Chap. 3, the distinction between a
phenomenological and a theoretical level is also helpful for the methodological
analysis of data science, which concerns the phenomenological level regarding
local, causal structure of phenomena, but does not rise to the theoretical level.
An important difference between exploratory experimentation and data science is
that in the former, data is usually of experimental nature, while the latter often deals
with observational data. But this is largely irrelevant from the perspective of a
difference-making account of causation according to which experimental interven-
tion has only pragmatic advantages over observational data. Another difference
concerns the complexity of the phenomena. While mapping the causal structure by
variable variation is as old as science itself, carrying it out in the computer can
address phenomena that were previously mostly inaccessible to causal analysis in
terms of largely theory-independent variational induction. This new handle, which
data science provides, for mapping the causal structure of highly complex phenom-
ena by variational induction will make all the difference to scientiﬁc practice.
References
Anderson, Chris. 2008. The End of Theory: The Data Deluge Makes the Scientiﬁc Method
Obsolete. WIRED Magazine 16/07. http://www.wired.com/science/discoveries/magazine/16-
07/pb_theory
References
187

Burian, Richard. 1997. Exploratory Experimentation and the Role of Histochemical Techniques in
the Work of Jean Brachet, 1938-1952. History and Philosophy of the Life Sciences 19: 27–45.
Callebaut, Werner. 2012. Scientiﬁc Perspectivism: A Philosopher of Science’s Response to the
Challenge of Big Data Biology. Studies in History and Philosophy of Biological and Biomedical
Sciences 43 (1): 69–80.
Cartwright, Nancy. 1983. How the Laws of Physics Lie. Oxford: Oxford University Press.
Franklin, Laura R. 2005. Exploratory Experiments. Philosophy of Science 72: 888–899.
Hacking, Ian. 1983. Representing and Intervening. Cambridge: Cambridge University Press.
Halevy, Alon, Peter Norvig, and Fernando Pereira. 2009. The Unreasonable Effectiveness of Data.
IEEE Intelligent Systems 24 (2): 8–12.
Hume, David. 2009. A Treatise of Human Nature. Oxford: Oxford University Press.
Keynes, John M. 1921. A Treatise on Probability. London: Macmillan.
Krohs, Ulrich. 2012. Convenience Experimentation. Studies in History and Philosophy of Biolog-
ical and Biomedical Sciences 43 (1): 52–57.
Leonelli, Sabina. 2016. Data-Centric Biology: A Philosophical Study. Chicago: University of
Chicago Press.
Mackie, John L. 1980. The Cement of the Universe. Oxford: Oxford University Press.
Mill, John S. 1886. System of Logic Ratiocinative and Inductive. London: Longmans, Green,
and Co.
Norvig, Peter. 2009. All We Want Are the Facts, Ma’am. http://norvig.com/fact-check.html.
Accessed 20 Oct 2017.
Pietsch, Wolfgang. 2014. The Structure of Causal Evidence Based on Eliminative Induction. Topoi
33 (2): 421–435.
———. 2015. Aspects of Theory-Ladenness in Data-Intensive Science. Philosophy of Science
82 (5): 905–916.
Russo, Federica. 2009. Causality and Causal Modelling in the Social Sciences. Measuring Vari-
ations. New York: Springer.
Skyrms, Brian. 2000. Choice and Chance. Belmont: Wadsworth.
Steinle, Friedrich. 1997. Entering New Fields: Exploratory Uses of Experimentation. Philosophy of
Science 64: S65–S74.
———. 2005. Explorative Experimente. Stuttgart: Franz Steiner Verlag.
Vickers, Peter. 2014. The Problem of Induction. In Stanford Encyclopedia of Philosophy.
Vincenti, Walter. 1993. What Engineers Know and How They Know It. Baltimore: Johns Hopkins
University Press.
von Wright, Georg H. 1951. A Treatise on Induction and Probability. New York: Routledge.
Waters, C. Kenneth. 2007. The Nature and Context of Exploratory Experimentation. History and
Philosophy of the Life Sciences 29 (3): 275–284.
188
6
Evidence

Chapter 7
Concept Formation
Abstract In this Chapter, it is shown that variational induction can also be
employed for concept development. To this purpose, concept formation in phenom-
enological and theoretical science is distinguished. The differences between phe-
nomenological
and
theoretical
concepts
largely
parallel
those
between
phenomenological and theoretical laws as discussed in previous chapters. In partic-
ular, phenomenological concepts are local and are mostly used for prediction and
manipulation. By contrast, theoretical concepts are universal and mostly ﬁgure in
grand explanatory schemes. In phenomenological science, both deﬁnitions and
empirical laws can be formulated in terms of inus complexes of circumstances
relative to a constant background. In the case of deﬁnitions, necessity and sufﬁciency
have a normative character, in the case of phenomenological laws, they have an
empirical character. Since variational induction does not depend in essential ways on
this character of necessity and sufﬁciency, it can be employed both for the inference
of empirical laws and for concept formation in phenomenological science. In data
science, many machine learning algorithms relying on variational induction are
indeed used for concept development.
Keywords Data science · Phenomenological science · Concept formation ·
Induction · Causation · Inus · Grue
7.1
Phenomenological and Theoretical Concepts
With respect to the history of variational induction, it is remarkable in hindsight that
Bacon’s primary example concerning the nature of heat has a different function than
what variational induction in the form of Herschel’s rules or Mill’s methods was later
used for (cp. Sect. 4.2). While Bacon provides a conceptual analysis of a natural-
kind-like notion, Herschel and Mill present their framework as a methodology for
determining causal relationships. Variational induction, thus, seems to have dual
applicability both for concept formation as well as for the discovery of causal laws.
There is a deeper reason for this, namely that both causal analysis and phenomeno-
logical concept formation rely on a logic of necessary and sufﬁcient conditions. In
© Springer Nature Switzerland AG 2022
W. Pietsch, On the Epistemology of Data Science, Philosophical Studies Series 148,
https://doi.org/10.1007/978-3-030-86442-2_7
189

particular, conceptual analyses often provide necessary and sufﬁcient conditions for
the presence of the examined concept. In the following, this analogy between
concept formation and causal inference is used in order to learn about concept
formation from discussions about causal inference in the previous chapters.
With respect to the discussion in Chap. 3, it is helpful to distinguish between two
different practices of concept formation, namely between concept formation in
phenomenological and in theoretical science. Concept formation on the phenome-
nological level exhibits many of the features that were identiﬁed for phenomeno-
logical laws in Sect. 3.1. Such concepts hold only ceteris paribus, i.e. they are local
concepts that are valid only with respect to a certain background or context that can
in general not be fully made explicit. Relatedly, these concepts are often developed
with very speciﬁc phenomena in mind. They are generally tailored for the prediction
and manipulation of those local phenomena rather than for some grand explanatory
scheme, in accordance with prediction and manipulation being the general aim of
phenomenological science. Maybe most importantly, phenomenological concepts
are developed using a variational methodology as presented in the previous Chaps. 5
and 6, which is why we will speak of causal concept formation in the following. To
this issue I will turn in the next section.
By contrast, the concepts on the theoretical level are in general highly abstract and
assumed to hold universally. Often, these theoretical concepts are generalized from a
phenomenological analysis of well-chosen exemplary or paradigmatic phenomena.
The price to pay for universality is that these concepts mostly cannot be used for
prediction and intervention, at least without additional assumptions that reintroduce
a speciﬁc empirical context. Instead, such theoretical concepts are usually employed
in universally applicable explanatory schemes. Consider as an example the concept
of force in physics, which is deﬁned by the fundamental axioms of classical
mechanics. Obviously, the notion taken by itself largely fails to be applicable in
concrete empirical contexts. Rather, a host of further assumptions is needed,
e.g. specifying the entities which exert forces or are acted upon as well as the
exact type of force that is relevant in the context: friction forces, stiction forces,
shearing forces, tension forces, elastic forces, spring forces etc.
In Chap. 3, physics and engineering were used to illustrate theoretical and
phenomenological science, respectively. Differences between both ﬁelds can also
be seen with respect to concept formation in accordance with the discussion above.
Physics as a quintessential theoretical science focuses on deﬁning the notion of
force or interaction in its most general disguise and then on distinguishing a small
number of fundamental and still highly abstract types of forces, in particular
gravitational, electromagnetic, weak and strong forces. By contrast, when opening
an engineering textbook e.g. in mechanics, one is confronted with a breathtaking
variety of forces, each tailored for one or more very speciﬁc contexts of application.
Most physicists have barely heard of many of these forces.
Certainly, there is no direct and unique deductive path from the general notion of
force that is ﬁxed by the axioms of physical theory to the more speciﬁc forces that are
required for various applications. Rather, the general notion provides a conceptual
190
7
Concept Formation

core, which must be supplemented by additional information from the intended
context of application. Much of this additional information is inductively inferred.
7.2
Concept Formation in Phenomenological Science
Let us again look at the structure of causal laws as derived by variational induction.
They generally come in the form of complex Boolean conditions involving the
operators ‘and’ (˄), ‘or’ (˅), and ‘not’ (Ø), more speciﬁcally in the form of inus
complexes A1 A2 ˅ A3 determining a phenomenon, as introduced in Sect. 5.3.1.
Consider the causal law that a light switch is causally relevant for a light. While it
may seem that a light switch is a rather simple condition or circumstance, from the
perspective of human perception it certainly is not. First of all, there exists a wide
variety of technical realizations of light switches, as an image search on google can
prove. Second, and more interestingly, we believe that perceiving a light switch is a
simple cognitive task since we easily recognize switches in our own home but also
when away visiting friends or at work. However, image recognition software has
brought the difﬁculties in such supposedly simple tasks to the fore. Even one and the
same light-switch looks vastly different depending on the angle, from which it is
perceived, or depending on the lighting at different times of day. Thus, the human
brain is fulﬁlling an amazing task, when it recognizes speciﬁc objects from raw
optical data which is fed into the brain through the retina.
Nevertheless, in principle the task of recognizing a light switch can be interpreted
in terms of learning a disjunction of a vast number of complicated conjunctions of
optical stimuli. The analogy to a neural net is somewhat helpful in that neural nets
performing image recognition also take basic stimuli as input, namely the colors of
pixels in a grid. As discussed in Sect. 3.5, neural nets basically constitute complex
non-linear functions of an input to an output. In the example at hand, the output
would be the switch in its two positions ‘on’ or ‘off’. The hidden layers of the neural
net represent different levels of conceptualization, for example edges and corners on
lower levels and more complex geometrical ﬁgures like squares or triangles on
higher levels. These steps from one level to the other can be interpreted as forming
increasingly high-level concepts in terms of necessary and sufﬁcient combinations of
features or concepts on lower levels.
I am not a brain scientist, but it appears reasonable to assume that something
similar is happening in human and animal brains, when objects are consistently
recognized on the basis of the stimuli that are sent from the retina to the brain. The
neurons in the brain will essentially be looking for difference makers in the stimuli
with respect to a light switch and to what a light switch is able to do, namely turn
light on or off. Judging from my own amateurish observation, how my son learns to
perceive the world, the admittedly very simple and superﬁcial analogy to a neural
network does not seem too farfetched. Clearly, he ﬁrst started recognizing very
general and coarse features, the simple shapes with bright colors that one ﬁnds in the
7.2
Concept Formation in Phenomenological Science
191

earliest books for infants. Slowly building on these very simple shapes, his brain was
then eventually able to recognize increasingly complex features.
As we have seen in Sect. 5.3.3, the concept of an inus-complex is able to capture
such conceptual hierarchies, mainly due to the possibility to formulate inus-
complexes on various levels of coarse-graining. For the sake of simplicity, let us
consider just two levels of conceptual complexity. On the most basic level, the inus-
complex for a phenomenon C shall be (A1 A2 ˅ A3) A4 ˅ A5 ¼ A1 A2 A4 ˅ A3 A4 ˅ A5.
Certainly, it makes sense to introduce a higher-level concept D1 ¼ A1 A2 ˅ A3,
which renders the formulation of the original inus-complex simpler: D1 A4 ˅ A5. In
particular if D1 turns out useful also for the formulation of other causal laws, an
economy of description is achieved through its introduction. Such diverse applica-
bility holds for most phenomenological concepts that surround us in everyday life.
Switches are a good example, so are lightbulbs, tables, shoes, doors etc.
The fact that both conceptual explications and relationships of causal relevance
can be analyzed in terms of necessary and sufﬁcient conditions hints at a certain
interpretive ambiguity. Let us distinguish empirical relevance R from deﬁnitional
relevance RD, both with respect to a background. In the ﬁrst case the circumstances
determine necessary and sufﬁcient empirical conditions, in the second case neces-
sary and sufﬁcient deﬁnitional conditions. In the ﬁrst case, necessity and sufﬁciency
are of empirical nature, in the second case of normative nature. The example of the
previous paragraph can be interpreted in the following manner:
A1 A2 ˅ A3 RD D1 and D1 A4 ˅ A5 R C
i.e. the ﬁrst relationship is interpreted as a deﬁnition, while the second is interpreted
as an empirical relationship. But one could just as well interpret both relationships
either as deﬁnitions or as empirical laws. It is this interpretive ambiguity, which was
stressed by Willard Van Orman Quine in his criticism of the analytic-synthetic
distinction, substantially drawing on Pierre Duhem’s thesis of conﬁrmation holism.
This interpretive ambiguity and the fact that both empirical and deﬁnitional causal
relevance follow a logic of necessary and sufﬁcient conditions implies that the same
framework of variational induction can be used both for concept formation and for
the inference of empirical laws. For this variational logic, it is largely irrelevant,
whether the underlying necessity and sufﬁciency is of empirical or of normative
character.
The difference between a normative and an empirical relationship correlates with
the willingness to abandon such relationships. In the case of recalcitrant evidence,
one should generally be prepared to abandon local empirical relationships rather than
widely accepted deﬁnitional relationships. The latter cannot fail in the same way as
the former, when novel evidence is taken into account.
For example, one may ﬁnd that C is present in the absence of D1 A4 ˅ A5. This
falsiﬁes that the inus-complex is a necessary condition of C. A plausible reaction to
the novel evidence is to append the inus-complex with a further disjunction, e.g. it
might turn out that D1 A4 ˅ A5 ˅ A6 A4 is a necessary and sufﬁcient condition for
C. Of course, the same result could have been achieved by changing the deﬁnition of
192
7
Concept Formation

D1 : A1 A2 ˅ A3 ˅ A6. In general, these two reactions are always possible,
i.e. changing the law or changing the deﬁnitions of at least one antecedent. Further-
more, there exists a third option, which consists in changing the deﬁnition of the
consequent, in the considered example by simply denying that in the presence of A6
A4 we are indeed dealing with phenomenon C. Finally, according to the framework
of causation and induction proposed in previous chapters, there remains fourthly
the possibility to put the blame on the background, i.e. when C was observed in the
absence of D1 A4 ˅ A5 this may have been due to a violation of homogeneity of the
background.
As another example, one may ﬁnd in the presence of D1 A4 that C is nevertheless
absent, i.e. the inus-complex and in particular D1 A4 is not a sufﬁcient condition of
C. If the background is homogeneous, there are again three options: ﬁrst, to change
the law; second, to change the deﬁnitions of the antecedents; and third, to change the
deﬁnitions of the consequents. For example, it might turn out that in previous
instances, A6 was always present together with D1 A4 but was missed as a necessary
condition of C. Thus, the law could be amended as: D1 A4 A6˅A5 R C. Or the
original formulation of the law may be kept by redeﬁning D1 as: (A1 A2 ˅ A3) A6.
Finally C could be redeﬁned as requiring the presence of A6 or some equivalent
circumstance in the presence of D1 A4.
Obviously, there is not one correct way, how to react in these situations. Rather,
all three responses are in principle feasible. Indeed, they are identical with respect to
their empirical content. Which of the possibilities one chooses depends mostly on
the pragmatics of the situation, in particular how to achieve the simplest and most
economic formulation of the considered phenomena. One crucial factor in that
respect concerns entrenchment, to employ a term that was used by Nelson Goodman
in a similar context (cp. Sect. 7.3). How well entrenched are the deﬁnitions, here in
particular of D1 and C, i.e. have they proven useful in a large number of other
inductive inferences? If that is the case, it seems apt to change the law rather than the
deﬁnitions. If on the other hand the deﬁnitions are highly context-speciﬁc but the law
in its structure is analogous to a considerable number of other laws, one would
generally keep the law and rather change the deﬁnitions. Apparently, the distinction
between causal deﬁnitions and causal laws, i.e. between normative and empirical
relationships becomes blurry and somewhat arbitrary in these analyses. In a sense,
those relationships are normative to which one holds on in the case of recalcitrant
evidence, while those relationships are empirical, which one is ready to abandon.
Usually, there is considerable ﬂexibility, how to distribute empirical content in
phenomenological science.
The discussion above shows that a multitude of empirically equivalent ways exist
how to account for concepts and laws in phenomenological science, which corre-
spond to the different options in concept formation as sketched above, e.g. whether
to change a law or a deﬁnition in the face of recalcitrant evidence. However, the
above discussion also reveals that in phenomenological science these different
accounts are always related by translation rules, at least for those contexts, for
which the accounts have been fully empirically established. For example, a transla-
tion rule states that if the deﬁnition of an antecedent is changed in a certain manner,
7.2
Concept Formation in Phenomenological Science
193

the corresponding law has to be adapted in a complementary way. By contrast,
theoretical concepts due to their universality are never fully empirically established.
In those areas, where the concepts are not backed by empirical evidence, they
suggest different outlooks on the respective phenomenon. In these areas, no clear
translation rules exist and thus the incommensurability thesis of Sect. 3.4 applies to
theoretical concepts.
Let me very brieﬂy comment on a related issue, namely the question whether
natural kinds exist. Trivially, the answer very much depends on what one under-
stands by natural kinds. Quine, who introduced the term in his essay “Natural Kinds”
deﬁned natural kinds essentially by being those properties or entities that are
projectible, i.e. that are susceptible to induction (1970), which seems a suitable
deﬁnition for the present discussion. Certainly, there are natural kinds in this sense
according to the picture presented above, and there is a huge variety of them.
In philosophy of science and epistemology, the fundamental entities of our most
successful theories are generally considered the best candidates for natural kinds,
e.g. the quarks, the chemical elements, or the genes. According to the view proposed
here, such abstract entities would not constitute projectible kinds, since they belong
to the theoretical level concerned with explanation rather than the phenomenological
causal level concerned with prediction. It is the universal character of these entities
which introduces a substantial normative element undermining their empirical
projectibility. By contrast the myriads of local entities and properties of phenome-
nological science are projectible due to their causal character, even though incom-
patible descriptions exist based on different deﬁnitions of properties and entities and
even though the corresponding concepts cannot fully be integrated into a unique
conceptual hierarchy. John Dupré has introduced the term promiscuous realism for a
related viewpoint, essentially the claim that even though there are numerous ways
for taxonomizing the world, one should nevertheless be realist about them (1995).
Data scientiﬁc practice well illustrates the crucial insight of the above discussion
that the same framework of variational induction can be employed for concept
formation as well as for the formulation of scientiﬁc laws. Indeed, the very same
machine learning algorithms can often be used for developing adequate deﬁnitions
for relevant causal concepts as well as for the formulation of empirical causal laws
that connect those concepts. A good example in this regard is the decision tree
algorithm, which was introduced in Sect. 4.3.1 and which was shown there to
implement a variational approach. This algorithm can both be used both for phe-
nomenological concept development as well as for the inference of phenomenolog-
ical laws. For example, in a medical context, decision trees could be used for
classifying different types of a disease such as skin cancer, e.g. based on images
showing the geometry and color of tumors. On the other hand, decision trees could
also be used to infer, whether a skin cancer is lethal or not—thereby establishing a
phenomenological law. Decision trees clearly work for empirical as well as for
normative relationships.
194
7
Concept Formation

7.3
The Problem of Grue
In the twentieth century, there was a further inﬂuential attempt due to Nelson
Goodman to formulate a problem of induction (1983, Sec. III). While the basic
thrust is similar to Hume’s problem as discussed in Sect. 6.2, Goodman’s new riddle
of induction more clearly sheds doubt on probabilistic inferences and it puts the
focus on linguistic aspects asking which predicates are projectable and which not. It
is for the latter reason that Goodman’s riddle is discussed in the present chapter on
concept formation.
Goodman’s new riddle is often framed in the following manner: suppose a
number of emeralds have been observed in the past which all exhibit the property
green. What is one to infer from these instances? Is one justiﬁed to predict that the
next emerald will be green as well, instead of for example blue? Goodman argues
against this obvious conclusion on the following basis: instead of the usual predicate
pair green/blue, one can construct an alternative pair grue/bleen with grue being
green until some moment t in the near future and blue afterwards, and bleen being
blue until t and green afterwards.
Goodman claims that no fundamental reason exists for preferring the pair green/
blue rather than grue/bleen on empirical grounds. For example, one might argue that
grue and bleen should be rejected because they are deﬁned quantities that further-
more include in their deﬁnition a reference to some moment t. But green and blue can
just as well be taken as being deﬁned quantities with green as grue until time t and
bleen afterwards and blue being bleen until time t and grue afterwards. Also,
attempts at a metaphysical solution of Goodman’s riddle fail that green and blue
constitute natural kinds as opposed to bleen and grue since we lack empirical access
to any natural-kind property for predicates (except as a result of the causal analysis
delineated in the previous section).
As already mentioned, the new riddle of induction is distinct from Hume’s
problem of induction by focusing on the projectability of predicates rather than on
direct predictions. Also, it aggravates Hume’s problem in that probabilistic accounts
of induction are more directly affected. The latter can easily be seen in that the same
evidence affords a possibly inﬁnite number of conclusions: All emeralds are green/
grue/gred/grack etc. According to enumerative induction all these inferences are
based on the same number of observations, i.e. the same evidence, and should thus
be ascribed the same probability, e.g. on the basis of Laplace’s rule of succession.
Even when presupposing only a small range of possible colors, the axioms of
probability imply that the probability for any prediction with a speciﬁc color must
be much smaller than one, e.g. essentially one half, if green and grue are taken into
account, which contradicts scientiﬁc practice.
Let us brieﬂy discuss the new riddle in the framework of the difference-making
account of causation. Suppose there is a lamp and a switch that can make the lamp
change color: if the switch is on (S ¼ 1) then the lamp is green (L ¼ G), if it is off
(S ¼ 0) then the lamp is blue (L ¼ B). Now, someone using the predicates grue and
bleen will discover the following: the lamp changes color from grue to bleen at time t
7.3
The Problem of Grue
195

without a cause in terms of a change in circumstances in sight, while in all other
instances, S covaries with L. Given some conﬁdence in the homogeneity of back-
ground and in determinism, this should prompt a reevaluation of the predicates grue
and bleen resulting in the deﬁnitions green and blue to avoid the causal anomaly at
time t. Of course, there may be other reasons to stick with grue and bleen, in
particular if these predicates have previously shown to be successful in other
contexts.
Goodman’s grue-problem provides a useful illustration, how variational induc-
tion and conceptual development are closely related and generally go hand in hand.
Many more examples could be given. Indeed, in most situations, one has a choice
either to interpret a recalcitrant observation linguistically or empirically, i.e. to either
reevaluate language or to look for wrongly ignored circumstances (or even to bite the
bullet and accept indeterminism). As will be further elaborated below, the more
entrenched certain terms the less viable is the ﬁrst option. By contrast, the better
established homogeneity of background and determinism, the less viable is the
second option. Thus, the process of variational induction not only leads to causal
relationships but also to appropriate causal kinds, which are partly chosen with an
eye on pragmatic criteria, most importantly simplicity.
But the real challenge of Goodman’s argument concerned the projectability of
predicates. Why are we almost always epistemically successful by relying on
inferences containing the predicates green/blue and almost never by using grue/
bleen? From the perspective of variational induction and the difference-making
account an answer can be given that is closely related to Goodman’s own solution
in terms of entrenchment.
A ﬁrst important remark is that variational induction presupposes some primitive
properties on which other properties can be deﬁned. Otherwise, the whole inductive
business would become impossible since everything would resemble everything
else, i.e. every event could be classiﬁed with every other with equal justiﬁcation.
Clearly, science would become futile. But fortunately, human experience of the
world comes in terms of primitive properties that are determined by the sensual
apparatus. Furthermore, it presumably is a result of human evolutionary develop-
ment that these properties can afford at least some causal grip on the world.
A second remark concerns the time-dependence in the deﬁnitions of grue and
bleen. Here, the insight is relevant that, according to the conventionalist perspective
sketched in Sect. 5.2.3, any reference to a point in time is just shorthand for the
conditions that were present at that particular moment or prior to it.
With these insights in mind, consider a situation in which the constant conjunc-
tion of certain properties is observed until some time shortly before t: C with X, and
D with Y. Now, grue-type predicates can be constructed in the familiar manner, in
particular XY, which is X until t and Y thereafter, as well as YX, i.e. Y until t and X
thereafter. Taking into account only the described evidence of constant conjunctions,
Goodman’s problem what to predict for a time after t is indeed not solvable.
However, both the conditions C and D as well as the predicates X and Y generally
appear in other contexts as well. They are all integrated in a huge web of causal
relationships. For example, the colors blue and green are related to physical
196
7
Concept Formation

knowledge about wavelengths, about processes of color generation or of color
change, or to phenomenological knowledge concerning the colors of various objects
in the world etc.
So, it generally does not occur that with the introduction of a grue-type predicate
like XY or YX only one causal relationship is implicated, but rather a large number
of other relationships are affected as well. Thus, from the usage of grue-type
predicates a rupture line in the conceptual web necessarily emerges. In the case of
grue emeralds, for example, we have to ask, whether the wavelengths of green and
blue are exchanged after instant t, whether certain atomic spectra and emission lines
will shift accordingly, or whether trees will turn blue etc. If all this happens, i.e. if
everywhere in the conceptual web the role of green and blue is just exchanged at t,
then grue is just another word for green and there is no riddle at all. Changes in
predicates can of course only be detected against a comparison group, otherwise the
whole notion of a predicate change is meaningless. So, if Goodman’s riddle is to be a
genuine problem for induction then only some of this should happen, e.g. that
emeralds turn blue, while trees remain green.
From the perspective of variational induction, such changes should happen only
in combination with a modiﬁcation of relevant circumstances. Therefore, assuming
determinism and fairly well-established homogeneity of background, it should not
occur that emeralds turn blue without any change in circumstances, while trees
remain green without any change in circumstances or, equivalently, emeralds remain
grue without any change in circumstances, while trees turn from grue to bleen
without any change in circumstances. Thus, there must be a condition that is
responsible for either the change between green and blue or that between grue and
bleen. This decides between the predicate pairs blue/green and grue/bleen. If there is
a relevant change in circumstances for the emeralds, then the pair blue/green
correctly reﬂects this change. If there is a relevant change in circumstances for the
trees, then the pair grue/bleen correctly reﬂects this situation. In other words, the
lesson from variational induction is that a change in predicates should not happen
without a reason in terms of a change in circumstances.1
The better entrenched a predicate, the more tightly knit the causal web, to which it
belongs, i.e. essentially the better a causal relationship involving this predicate is
established by a process of variational induction testing it against a wide variety of
contexts, the less likely that we should experience any conceptual rupture lines,
i.e. any surprises in terms of grue-type predicates in sufﬁciently similar contexts.2
Obviously, this solves the problem of grue only if the issue of determinism as
discussed in the previous section has found a satisfactory answer. Thus, the per-
spective from variational induction defuses Goodman’s riddle in that it yields a clear
criterion, why blue/green should be preferred to grue/bleen when formulating
1Taking into account possible indeterminism does not fundamentally change this assessment as
e.g. the discussions in Sect. 6.2 and Chap. 9 show.
2Note again that grue-typeness can only be identiﬁed for well-entrenched predicates in comparison
with large classes of phenomena that remain green.
7.3
The Problem of Grue
197

predictions, namely in terms of causal entrenchment and of the variational principle
that no change in predicate can occur without a change in relevant circumstances.
Still, it remains to concede as a general moral of Goodman’s riddle that the whole
business of induction depends crucially on language.
7.4
Discussion: Supervised and Unsupervised Machine
Learning
A fundamental distinction with respect to machine learning algorithms is between
supervised and unsupervised learning. Essentially, supervised learning concerns
labeled data and unsupervised learning concerns unlabeled data, i.e. in the latter
meaningful labels have to be inferred from the data. In other words, in supervised
learning the data points are already separated into different categories or groups,
while a primary goal of unsupervised learning is to divide the data points into
meaningful groups in the ﬁrst place. A well-known and inﬂuential example of
successful unsupervised learning is a study mainly by Google researchers, in
which a so-called autoencoder neural network was able to detect high-level features
in unlabeled images consisting in random frames of YouTube videos, for example,
whether the images show a human face, a cat face or a human body (Le et al. 2012).
Cluster analysis is typical for unsupervised learning. In clustering algorithms, one
usually starts with a number of data points in a given parameter space. Each of these
data points is then assigned to a certain cluster, where each cluster stands for a
distinct category. For example, in k-means clustering, the number k of desired
clusters is presupposed. Such an algorithm tries to optimally cluster all data, such
that each data point belongs to the cluster with the nearest mean. In order for such a
categorization to be useful, one would expect that in the chosen parameter space, the
clusters are already clearly distinguished. In other words, cluster analysis presup-
poses that the distances between data points belonging to one group are much
smaller than the distances to data points of another group. By contrast, if the data
points are evenly distributed, cluster analysis is not sensible.
Obviously, if the parameter space is changed, cluster analysis may easily lead to a
completely different result. Prima facie, it is not clear, which of these results should
be preferred. Therefore, cluster analysis leads to similar problems as we had iden-
tiﬁed for enumerative induction and corresponding regularity analyses in previous
chapters. In particular, it is not clear how to distinguish between meaningful and
accidental classiﬁcations, i.e. those classiﬁcations that are useful for prediction and
manipulation and those that are not.
Decision trees as introduced in Sect. 4.3.1 are typical for supervised learning.
These algorithms presuppose labeled data. They aim to construct models for
predicting the labels of unclassiﬁed data points based on training sets of labeled
data points. Decision trees implement a variational approach to concept develop-
ment. Given sufﬁcient training data, they determine, which variables are necessary
198
7
Concept Formation

and sufﬁcient conditions for a certain label or category. In contrast to the
unsupervised cluster analysis, the models derived in this way are meaningful in
that they allow for the prediction and/or manipulation of the given labels. Such
concept formation with a clear purpose in terms of speciﬁc tasks of prediction and
manipulation is likely to be more successful than the mere search for conceptual
regularities as in unsupervised cluster analysis.
Of course, the distinction between unsupervised and supervised learning does not
necessarily determine, whether the results are meaningful or not. For example, the
unsupervised autoencoder neural network mentioned at the beginning of this section
yields meaningful categories that can be useful for prediction and manipulation. The
decisive difference with respect to the unsupervised cluster analysis is that this
neural network learns from a huge amount of high-dimensional data through a
variational analysis. More precisely, there is sufﬁcient data for the neural network
to develop on several layers a wide variety of variables of different levels of
abstraction, implying a conceptual framework of numerous variables that are caus-
ally relevant or irrelevant for each other. In this way, the neural network does not
exhibit the same arbitrariness resulting from different parametrizations as the mere
clustering algorithm.
There are also algorithms of supervised learning that do not fully implement a
variational approach. An example in this regard are so-called support vector
machines, which are widely used algorithms in machine learning (Vapnik 1995;
cp. also Corﬁeld et al. 2009). Support vector machines construct linear separators
between different regions of a given parameter space in order to most effectively
separate data points with different predetermined categories or labels. More exactly,
given a data set with two different labels, a support vector machine would construct a
boundary between both groups that has the largest possible distance to the given data
points (of course only if such a linear separator is feasible at all). Such a boundary is
called the maximum margin separator and the data points that have the smallest
distance to the maximum margin separator are called the support vectors. Because
the separator is essentially determined only by the support vectors, the algorithm can
be seen as combining some of the advantages of both parametric and non-parametric
approaches (Russell and Norvig 2009, 744).
The basic idea just sketched can be generalized in important ways. First of all, in
parameter spaces with dimension higher than two, the separator will not be linear,
but rather a hyperplane deﬁned by all vectors x, which obey the following equation:
x ∙w + b ¼ 0. Furthermore, there are ways to account for outliers or ﬂuctuations,
i.e. for the fact that not all data points necessarily need to lie on the ‘correct’ side of
the separator, by using so-called soft margin classiﬁers. But most importantly, the
feature why support vector machines belong to the most successful machine learning
algorithms is that they can account for non-linear or non-planar separators in the
original parameter space by transforming the parameter space in a way that a linear
or planar separator is feasible in the transformed parameter space. Usually, this is
done by mapping the data points into a space of much higher dimensions compared
with the original parameter space. For instance, if N data points are given, a linear or
planar separation will usually be possible in spaces of N-1 dimensions or more (ibd.,
7.4
Discussion: Supervised and Unsupervised Machine Learning
199

746). Once a separator is found in the higher-dimensional space, it can then be
mapped back into the original feature space. The corresponding calculations can be
immensely simpliﬁed by using so-called kernel functions (ibd. 748).
The separator can be seen as a difference maker for the labels of the data points. In
this way, support vector machines implement to some extent a variational rationale.
However, the choice of an original parameter space limits the possibility for carrying
out variational induction. In general, there is little reason, why the actual difference
makers of the considered phenomenon should be under the variables chosen for that
parameter space. Furthermore, nothing in the set-up ensures homogeneity of back-
ground. Thus, the separator may at least to some extent be spurious, i.e. capture
neither real difference makers nor even proxies of these difference makers. The
transformation of the parameter space of course does not change this assessment,
since it does not add any further variables but only transforms the given variables of
the original parameter space.
In summary, while some preliminary concept formation in machine learning and
artiﬁcial intelligence involves the mere observation of regularities, reﬁned concepts
result from a variational analysis and mostly from supervised learning. In supervised
learning, concepts are usually formulated with a speciﬁc goal in mind in terms of
prediction and/or manipulation (of the label categories). Eventually, those concepts
become central, which allow for prediction and/or manipulation in a wide range of
contexts—leading to increasing simpliﬁcation of the overall conceptual framework.
References
Corﬁeld, David, Bernhard Schölkopf, and Vladimir Vapnik. 2009. Falsiﬁcationism and Statistical
Learning Theory: Comparing the Popper and Vapnik-Chervonenkis dimensions. Journal for
General Philosophy of Science 40: 51–58.
Dupré, John. 1995. The Disorder of Things. Metaphysical Foundations of the Disunity of Science.
Cambridge, MA: Harvard University Press.
Goodman, Nelson. 1983. Fact, Fiction, and Forecast. Cambridge, MA: Harvard University Press.
Le, Quoc, Marc’Aurelio Ranzato, Rajat Monga, Matthieu Devin, Kai Chen, Greg Corrado, Jeff
Dean, and Andrew Ng. 2012. Building High-Level Features Using Large Scale Unsupervised
Learning. In Proceedings of the 29th International Conference on Machine Learning. Madison:
International Machine Learning Society.
Quine, Willard V.O. 1970. Natural Kinds. In Essays in Honor of Carl G. Hempel, ed. N. Rescher,
1–23. Dordrecht: D. Reidel.
Russell, Stuart, and Peter Norvig. 2009. Artiﬁcial Intelligence. Upper Saddle River: Pearson.
Vapnik, Vladimir. 1995. The Nature of Statistical Learning Theory. New York: Springer.
200
7
Concept Formation

Chapter 8
Analogy
Abstract In this Chapter, a causal approach to analogical reasoning is presented.
Such reasoning, which is ubiquitous in data science, addresses the question how
evidence from various phenomena can be combined and made relevant for theory
development and prediction. First, some inﬂuential accounts of analogical reason-
ing, both historical and contemporary, are reviewed focusing in particular on
Keynes, Carnap, Hesse, and more recently Bartha. I argue that enumerative
approaches to analogical reasoning especially in the Carnapian tradition have largely
failed, while the epistemological assumptions of variational approaches, for example
by Keynes, seem much more plausible. Then, a general framework is sketched. To
this purpose, a distinction between a predictive and a conceptual type of analogical
reasoning is introduced. According to a common intuition, predictive analogical
inferences hold if the differences between source and target concern only irrelevant
circumstances. I attempt to make this idea more precise by addressing possible
objections and in particular by specifying that irrelevance is adequately interpreted
in terms of causal irrelevance based on difference making in homogeneous contexts.
Keywords Data science · Analogy · Causation · Difference making · Carnap ·
Keynes · Bartha
8.1
Analogy and Data Science
8.1.1
Analogical Inferences in Data Science and Beyond
When evidence from different phenomena is combined in order to predict, to explain
or to develop a conceptual framework, this can often be understood in terms of
analogical reasoning. After all, analogical inferences, according to a typical expli-
cation, are inferences based on similarity: If two phenomena, source A and target
© Springer Nature Switzerland AG 2022
W. Pietsch, On the Epistemology of Data Science, Philosophical Studies Series 148,
https://doi.org/10.1007/978-3-030-86442-2_8
201

A*, are similar and A has a characteristic C, then under certain circumstances it is
plausible or probable to assume that A* has characteristic C as well.
Analogical inferences are widely used in data science and machine learning, for
example when data scientist attempt to predict, for whom a speciﬁc individual will
vote in an election, based on data about other similar individuals, of whom the voting
preferences are known. Or when a search algorithm tries to predict, which results are
the most useful for a user, based on previous similar searches of the same or of other
users as well as on information, which results users have found useful, i.e. have
clicked on, in the past. Or when a medical algorithm tries to predict, which
medication is most likely to help a patient, given data on past medication adminis-
tered to patients with similar medical conditions as well as information, which of
these patients recovered well and quickly.
Further evidence about the ubiquity of analogical inferences in data science stems
from an analysis of various machine learning algorithms. For example, the decision
trees introduced in Sect. 4.3.1 clearly implement analogical reasoning. After all,
decision trees are constructed by relying on many related but usually not completely
identical instances in order to make predictions about a further instance, which is
similar to all those instances. The same holds for deep learning as introduced in Sect.
3.5, only that the type of model is a neural network rather than a decision tree. Thus,
it is not surprising that inﬂuential researchers in machine learning have worked on
analogical reasoning. For example, Stuart Russell, coauthor together with Peter
Norvig of the most inﬂuential contemporary textbook (2009) on artiﬁcial intelli-
gence wrote his PhD thesis on Analogical and Inductive Reasoning (1986). Among
other things, he proposed a formal framework for analogical inferences based on a
theory of determinations, with which the relevance of similarities can be evaluated
(see also Russell 1988, 1989; Davies and Russell 1990).
Not only in contemporary data science, but at all times in history, scientists have
stressed the epistemological signiﬁcance of analogy, including such luminaries as
William Gilbert, Johannes Kepler, Joseph Priestley, or James Clerk Maxwell.
Johannes Kepler, for example, wrote in his Opticks: “I cherish more than anything
else the Analogies, my most trustworthy masters. They know all the secrets of
nature.” (Kepler 1604; cited in Polya 1954, p. 12) And indeed, analogical reasoning
was a major source of creativity in Kepler’s scientiﬁc method. In his analysis of the
solar system, he crucially relied on the analogy between the emission of light and the
propagation of what he called the anima motrix, i.e. the spirit that moves the planets
around the sun:
Let us suppose, then, as is highly probable, that motion is dispensed by the Sun in the same
proportion as light. Now the ratio in which light spreading out from a center is weakened is
stated by the opticians. For the amount of light in a small circle is the same as the amount of
light or of the solar rays in the great one. Hence, as it is more concentrated in the small circle,
and more thinly spread in the great one, the measure of this thinning out must be sought in
the actual ratio of the circles, both for light and for the moving power [motrice virtute].
(Kepler, 1596/1981, p. 201, cited in Gentner et al. 1997, p. 414-415)
Thus, the analogy suggests that the anima motrix, just as light, constitutes a
conserved quantity acting according to an inverse square law. The example
202
8
Analogy

demonstrates well, how evidence from two different sources, i.e. the theory of
optical phenomena and phenomenological knowledge about the solar system, can
be combined in order to develop a model concerning the interaction of material
bodies in the solar system.
As another example of analogical reasoning in the sciences, consider animal
models such as mouse models that are used in medicine and pharmacology to
determine the efﬁcacy of a treatment in human beings. Again, evidence from
disparate phenomena, here mice and human beings, is amalgamated to further the
knowledge about these phenomena. I will argue later that this case is different from
the previous one in important respects. Most importantly, it aims at prediction, while
Kepler was primarily concerned with theory or model development.
In view of these examples of successful scientiﬁc practice, it is remarkable that
inﬂuential authors have questioned, whether there are any universal rules governing
analogical inferences.1 As an example from the statistics and computer science
literature, Henri Prade and Gilles Richard write in their recent overview of the
ﬁeld: “analogical reasoning is not amenable to a formal framework in a straightfor-
ward manner due to the brittleness of its conclusions.” (2014, 5) Similarly, the
philosopher of science Paul Bartha, who has written the most extensive modern-
day treatise on analogical reasoning from an epistemological perspective (2010),
states: “Despite the conﬁdence with which particular analogical arguments are
advanced, nobody has ever formulated an acceptable rule, or set of rules, for valid
analogical inferences. There is not even a plausible candidate.“ (Bartha 2013, Sec.
2.4) In a similar vein, the philosopher Patrick Maher writes: „Argument by analogy
is a generally accepted form of inductive reasoning and many think that inductive
reasoning can be represented using the probability calculus. From these facts one
might expect that there would be accepted probability models that can represent
inference by analogy, but no such model exists.” (Maher 2001, p. 183)
The most pressing and interesting epistemological problem with respect to
reasoning by analogy therefore is how to bring these two aspects together, on the
one hand, the ubiquitous use of analogy in scientiﬁc practice and, on the other hand,
the widespread belief that a formal framework for analogical inferences does not
exist. Given the ubiquity of analogical inferences in data science and machine
learning, this problem is particularly important for an epistemological foundation
of data science.
1Note that the absence of universal rules for analogical inferences does not necessarily imply that
such inferences cannot be reliable. An interesting proposal in this regard is John Norton’s material
theory of induction (cp. Norton 2011 and references therein). A critique of Norton’s theory of
induction is beyond the scope of this chapter.
8.1
Analogy and Data Science
203

8.1.2
A Brief Overview of What is to Come
In the next Sect. 8.2, relying on short case studies from the history of scientiﬁc
method, I argue for three interrelated points. First, I brieﬂy present Carnap’s
framework of induction, building mainly on enumerative induction. While he tries
to implement analogical reasoning in his approach, he fails to ﬁnd a convincing
manner to do so. This situation leads me to argue for a general failure of enumerative
approaches to implement analogical reasoning. Instead, variational approaches,
focusing on the variation of circumstances rather than the repetition of instances as
in enumerative induction, are much more amenable to analogical reasoning, as the
second case study on Keynes’ approach to induction shows. Third, I introduce two
inﬂuential contemporary frameworks by Mary Hesse and Paul Bartha, which address
one of the major problems of Keynes’ approach, the so-called counting problem. To
this purpose, they develop a two-dimensional framework, which takes into account
the ‘horizontal’ similarities between different phenomena, but also the ‘vertical’
relations between all the properties which are similar or different.
In Sect. 8.3, a distinction between two types of analogical reasoning is intro-
duced, namely conceptual and predictive analogies. These differ in their epistemic
aim, the nature of the vertical relations, the criteria of evaluation, and the method-
ological framework. I argue that the widespread skepticism concerning analogical
inferences partly results from a failure to recognize this distinction. While conceptual
analogies indeed are not amenable to a formal framework to determine the truth or
probability of such inferences, this is not the case for predictive analogies.
In Sect. 8.4, I then sketch a framework for predictive analogies building on the
intuition that ‘a predictive analogical inference holds, if the differences between
source and target are irrelevant to the prediction’. I discuss some preliminary
objections and argue that irrelevance must be understood in causal terms. Examining
different explications of the notion of causal irrelevance from the literature, I ﬁnd
none of them suitable for the context of analogical reasoning. My own proposal
construes causal irrelevance in terms of difference making in a given background
context (see Sect. 5.2.1).
Since the framework that was developed so far is intended for deterministic
situations, I brieﬂy address in Sect. 8.5, how it can be extended to include probabi-
listic analogical inferences. While there are straightforward ways to implement
probability, a crucial problem remains regarding the interpretation of probability in
this context.
204
8
Analogy

8.2
Three Historical Perspectives
The history of methodological thinking about analogy is quite rich. In the following,
I concentrate on three more recent episodes or case studies how methodologists have
approached analogical reasoning. These will provide the groundwork for the
approach to be outlined later in the article.
8.2.1
Carnap and the Inadequacy of Enumerative
Approaches
Rudolf Carnap developed one of the most extensive and detailed inductive frame-
works in the twentieth century, in which he explicitly aimed to include consider-
ations of analogy. Carnap’s approach is based on a conﬁrmation function c(h|e),
which designates the conﬁdence in a hypothesis h based on some evidence e. As is
well-known, Carnap was a dualist about probability, distinguishing an empirical and
a logical role of probability—the former regarding relative frequencies while the
latter is usually identiﬁed with rational degree of belief in a hypothesis based on
some evidence.
Carnap construes analogical inferences as inductive inferences from one individ-
ual to another based on their known similarity, much in line with the general
understanding that was presented in Sect. 8.1.1: “The evidence known to us is the
fact that individuals b and c agree in certain properties and, in addition, that b has a
further property; thereupon we consider the hypothesis that c too has this property.”
(1950, p. 569)
Carnap’s general approach to induction is based on what is often called the
‘straight rule’ of induction: Given a family of predicates P, i.e. a mutually exclusive
but exhaustive group of predicates that applies to a number of individuals, the degree
of conﬁrmation corresponds to the relative frequency sj/s of a property Pj in the ﬁrst s
individuals. In other words, the straight rule of induction is just ordinary enumerative
induction. Carnap recognizes the deﬁciencies of this simple rule and consequently
extends it to ‘a continuum of inductive methods’ which is determined by a number of
additional parameters. There are several versions in his writing over the course of his
life, the best known being the so-called λ-γ system developed in his mature,
posthumously published Basic System of Inductive Logic (1971, 1980) with a
conﬁrmation function
c j s1, . . . , sk
ð
Þ ¼ s j þ λγ j
s þ λ :
Here, s ¼ s1 + . . . + sk can be interpreted as the number of real individuals and λ
the number of virtual individuals. Among the former sj have the property Pj, among
8.2
Three Historical Perspectives
205

the latter λγj. This conﬁrmation function can be rewritten in terms of an empirical
and a logical part:
c j s1, . . . , sk
ð
Þ ¼
s
s þ λ
s j
s þ
λ
s þ λ γ j
For large s, the empirical part dominates, for small s, the logical part. Thus, the
logical part can be interpreted as an a priori contribution to the conﬁrmation
function.
In general, analogical inﬂuence is considered to belong to this logical part.
Carnap speciﬁes several kinds of analogical inﬂuence. First, he draws a distinction
between similarity inﬂuence, which takes into account the distance between prop-
erties, and proximity inﬂuence referring to the distance between individuals—
presupposing in both cases that an adequate metric exists. With respect to the former,
Carnap further distinguishes between analogical inﬂuence within one predicate
family and that between different predicate families. While he acknowledges that
the latter is much more common than the former, he mainly addresses in the Basic
System analogical inﬂuence within one predicate family, presumably because it is the
simpler problem (for a very brief discussion of analogical inﬂuence between differ-
ent predicate families, see Carnap 1950, §110 D). Furthermore, Carnap’s analysis of
analogy is restricted to individuals which have certain properties in common, while
in typical analogical inferences individuals are also known to differ in certain other
properties—a critique spelled out in some detail by Mary Hesse (1964).
Carnap suggests treating analogical inferences in terms of the mentioned γ
corresponding to the width (or weight) of properties and an additional η
corresponding to the distance between properties. If two properties P1 and P2 are
sufﬁciently similar, i.e. are close in terms of the distance measure, then the relative
frequency of P1 will inﬂuence the conﬁrmation function for P2 and vice versa.
Naturally, the width also has to be taken into account: basically, the more weight a
property has, the greater its inﬂuence. According to Carnap, such analogy inﬂuence
“is usually very small”, it “decreases with increasing [evidence in terms of number of
individuals] s”, and therefore can “be practically neglected” if s is large (1980, p. 41).
To repeat, this is because analogy inﬂuence belongs to the logical and a priori part of
the conﬁrmation function, which can be neglected for s >> λ. As an example, Carnap
uses the color space to illustrate the concepts of width, essentially the range or
variation subsumed under a speciﬁc color, and distance, i.e. the perceived similarity
between different colors. Both are determined by the chosen metric of the color
space (1980, Sec. 14.A).
Carnap’s treatment of analogy remains brief and fragmentary—in contrast to his
very detailed treatment of induction in general—and this situation may already cast
doubt over the suitability of enumerative approaches to analogy, i.e. essentially those
approaches that are based on some version of the straight rule. There have since been
a number of attempts to integrate analogical reasoning within an essentially
Carnapian approach to inductive logic (e.g. Hesse 1964; Kuipers 1984, Romeijn
2006, Maher 2001). It seems fair to say that no agreement has been reached (for a
206
8
Analogy

helpful overview, see Huttegger forthcoming). Many decades after Carnap published
his approach to inductive logic, it continues to be doubtful whether his framework is
capable to cover analogical reasoning in a sensible manner.
One strain of criticism attacks the use of additional parameters such as γ or η
which must be derived from a metric over properties, which rarely is explicitly
available. These parameters seem considerably ad hoc as is well illustrated by the
example of the color space for which a wide variety of representations are possible
(Reibe & Steinle 2002). In fact, this situation has led Wolfgang Stegmüller, a close
collaborator of Carnap, to suggest that Carnap is really talking about subjective
rather than logical probability (Stegmüller 1973, 514)—which would further under-
mine any attempt to justify reliable predictions based on analogical reasoning, even
though these are ubiquitous in the sciences, as the examples from Sect. 8.1.1 suggest.
In the end, what seems the most problematic aspect about Carnap’s approach is its
focus on the straight rule and on relative frequencies as the core concepts for
conﬁrmation—automatically conﬁning analogy to prior considerations, which
wash out as increasing evidence in terms of instances is gathered.2 After all,
scientiﬁc practice suggests otherwise: relative frequencies are generally a bad indi-
cator for conﬁrmation, while analogies can often provide highly reliable evidence.
The lesson from the case study on Carnap’s treatment of analogy thus seems to be
that just as enumerative approaches to induction in general, enumerative approaches
to analogy, conﬁning analogy to prior considerations, run into deep and presumably
unsolvable problems.
8.2.2
Keynes and the Ubiquity of Analogical Reasoning
It is often thought that the essence of inductive reasoning lies in the multiplication of
instances and Carnap’s approach with its reliance on the straight rule and on relative
frequencies attempts to formalize this intuition. However, there has been for many
centuries an alternative tradition of inductive reasoning which focuses on the
variation of circumstances rather than on the number of instances (cp. Chap. 4).
Proponents of this later tradition, which is sometimes referred to as variational
induction, are among others Francis Bacon, John Stuart Mill and more recently
John Maynard Keynes. It turns out that its basic inductive framework is much more
amenable to analogical reasoning. After all, an analogical inference concludes from
one instance with certain circumstances to another with different circumstances.
Indeed, proponents of variational induction have often considered analogical
2Note that Bayesian approaches to conﬁrmation often assume a similar role for analogy as being
conﬁned to prior considerations (e.g. Salmon 1990): “I suspect that the use of arguments by analogy
in science is almost always aimed at establishing prior probabilities. [. . .] The moral I would draw
concerning prior probabilities is that they can be understood as our best estimates of the frequencies
with which certain kinds of hypotheses succeed. These estimates are rough and inexact...”
(186-187).
8.2
Three Historical Perspectives
207

inference as the core of inductive reasoning. The best example in this regard is John
Maynard Keynes, who in his Treatise on Probability lays out a general framework
for induction based on analogy:
In an inductive argument, therefore, we start with a number of instances similar in some
respects AB, dissimilar in others C. We pick out one or more respects A in which the
instances are similar, and argue that some of the other respects B in which they are also
similar are likely to be associated with the characteristics A in other unexamined cases. The
more comprehensive the essential characteristics A, the greater the variety amongst the
non-essential characteristics C, and the less comprehensive the characteristics B which we
seek to associate with A, the stronger is the likelihood or probability of the generalisation we
seek to establish. (Keynees 1921, 219-220)
Note again that Keynes’s description closely resembles what we had deﬁned as an
analogical argument in Sect. 8.1.1, while he considers it the fundamental form of an
inductive argument. Keynes introduces some terminology that has since become
standard in the literature on analogical reasoning. The positive analogy concerns
those properties which source and target have in common, the negative analogy
those properties in which source and target differ, and the unknown analogy those
properties of which it is yet unknown whether they belong to the positive or negative
analogy. Finally, the hypothetical analogy concerns those properties which are
known of the source phenomenon and predicted of the target phenomenon (see
also Bartha 2013).
Keynes’ approach to induction turns the Carnapian view upside down.3 While for
Carnap enumerative induction in the form of the straight rule is central and analogy
is conﬁned to prior considerations that wash out with increasing evidence, for
Keynes, analogical inferences are fundamental and enumerative induction only
plays a subordinate role by controlling for circumstances whose inﬂuence thus far
has not been explicitly considered:
The object of increasing the number of instances arises out of the fact that we are nearly
always aware of some difference between the instances, and that even where the known
difference is insigniﬁcant we may suspect, especially when our knowledge of the instances is
very incomplete, that there may be more. Every new instance may diminish the unessential
resemblances between the instances and by introducing a new difference increase the
Negative Analogy. For this reason, and for this reason only, new instances are valuable.
(Keynes 1921, 233)
Relatedly, Keynes denies that relative frequencies can be used to determine proba-
bilities along the lines of the straight rule. The reason is that instances vary in
different ways regarding their circumstances and thus there is usually no reason to
count them with equal weight as the straight rule presupposes:
I do not myself believe that there is any direct and simple method by which we can make the
transition from an observed numerical frequency to a numerical measure of probability.
(Keynes 1921, 367)
3i.e. systematically speaking, historically of course Keynes was prior to Carnap.
208
8
Analogy

In summary, Carnap’s system implements a clear distinction between enumerative
induction and analogy, it conﬁnes analogical inﬂuence to a priori considerations, and
it endorses a principle of instantial relevance (“one of the basic characteristics of
customary inductive reasoning”, Carnap 1971, 161), according to which any positive
instance strictly increases the conﬁrmation function that the next instance is positive
as well.4 All this is incompatible with Keynes’s approach, who argues that all
induction basically relies on analogy, even seeming applications of enumerative
induction actually aim at increasing the negative analogy. He rejects any simple
frequentist approach to conﬁrmation, which quantiﬁes conﬁrmation based on some
variant of the straight rule. Relatedly, he rejects the principle of instantial relevance:
in particular, if two instances are fully identical in all their relevant circumstances,
then the additional instance does not conﬁrm at all (1921, 233).
Unfortunately, the shift away from enumerative induction to an inductive frame-
work based on analogy, while conceptually sensible, eliminates the most obvious
candidates for a measure of conﬁrmation, namely the number of positive instances or
relative frequencies. Instead, a quantitative measure could consist in a weighted
comparison between positive and negative analogy. Bartha suggests the following
characterization of this widespread intuition:
Suppose S and T are the source and target domains. Suppose P1, . . ., Pn (with n  1)
represents the positive analogy, A1, . . ., Ar and ØB1, . . ., ØBs represent the (possibly
vacuous) negative analogy, and Q represents the hypothetical analogy. In the absence of
reasons for thinking otherwise, infer that Q* holds in the target domain with degree of
support p > 0, where p is an increasing function of n and a decreasing function of r and s.
(2013, Sec. 2.4)
But, as many authors including Bartha have stressed, this approach leads to the
notorious counting problem. While counting instances in enumerative induction
seems straight-forward, counting properties in analogical reasoning is not. If two
instances have property ‘color’ in common, but differ in property ‘size’, how
possibly should one compare color and size? It appears impossible to formulate
general rules for this task, which has led many to conclude that analogical reasoning
is necessarily contextual. As a result, Keynes’ approach remains almost entirely
qualitative, which may have contributed to the fact that it is barely used in contem-
porary science.
Still, Keynes does derive some general guidelines for analogical reasoning.
Inductive arguments which conclude from a number of examined instances to a
generalization can be strengthened by the following means:
–
by reducing the resemblances known to be common to all the instances, but ignored as
unessential by the generalization,
–
by increasing the differences known to exist between the instances,
–
by diminishing the sub-analogies or unessential resemblances known to be common to
some of the instances and not known to be false of any. (Keynes 1921, 231–232)
4Carnap speciﬁes that the strict inequality only holds if the original conﬁrmation function is not zero
or one.
8.2
Three Historical Perspectives
209

For this, either new instances have to be examined or the knowledge of familiar
instances has to be extended. Most standard treatments of analogical reasoning
propose similar qualitative guidelines (see Bartha 2013, Sect. 3.1 for a comprehen-
sive list of commonsense guidelines).
In summary, Keynes’ framework bases inductive reasoning on analogical infer-
ences, i.e. every inductive inference is conceived as an inference based on similarity.
While this is conceptually plausible, proponents have largely failed to come up with
a quantitative conﬁrmation measure for such an approach.5
8.2.3
Hesse, Bartha and the Two-Dimensional Approach
No solution to the counting problem seems to be forthcoming. Apparently, how
properties are counted very much depends on the speciﬁc context. There is, however,
one crucial insight that has occasionally been pointed out in discussions of analog-
ical reasoning, but that was most forcefully stressed by Mary Hesse and more
recently by John Norton and Paul Bartha. For analogical reasoning it is important
to not only consider the similarity and differences in properties between source and
target, but also the nature of the relation between these properties:
Under what circumstances can we argue from, for example, the presence of human beings on
the earth to their presence on the moon? The validity of such an argument will depend, ﬁrst,
on the extent of the positive analogy compared with the negative (for example, it is stronger
for Venus than for the moon, since Venus is more similar to the earth) and, second, on the
relation between the new property and the properties already known to be parts of the
positive or negative analogy, respectively. If we have reason to think that the properties in
the positive analogy are causally related, in a favorable sense, to the presence of humans on
the earth, the argument will be strong. If, on the other hand, the properties of the moon which
are parts of the negative analogy tend causally to prevent the presence of humans on the
moon the argument will be weak or invalid.“ (Hesse 1966, 58-59; cited in Norton 2011, 8)
In other words, Hesse proposes a two-dimensional model, where the horizontal
relations concern the similarity between source and target, i.e. the identity or
difference in properties, and the vertical relations concern the relations between
properties, which Hesse believes to be causal in most cases. Simply comparing the
negative and the positive analogy thus will not do, but rather the nature of the
5While the approach proposed in this essay builds on Keynes’s ideas in many ways, one of the
advantages with respect to Keynes is that to some extent it is quantitative. In particular, a sufﬁcient
and necessary criterion is given for analogical inferences in deterministic contexts. Thus, analogical
inferences fulﬁlling this criterion are valid with probability 1. In Section 8.5, an extension of the
proposed framework is brieﬂy sketched, under which circumstances one can meaningfully assign a
probability to a prediction based on an analogical reasoning.
210
8
Analogy

relationship between the properties in the positive and the negative analogy with the
properties in the hypothetical analogy has to be taken into account.
In his recent inﬂuential work on analogical reasoning, Paul Bartha very much
builds on Hesse’s two-dimensional account (Bartha 2010, brieﬂy summarized in
2013, Sect. 3.5.2). He classiﬁes different types of analogical reasoning in terms of
different vertical relations, e.g. logical, causal, or statistical. Bartha’s principle of
prior association then demands that some kind of connection between the positive
analogy and the hypothetical analogy has to be established, taking into account the
negative analogy as well. Bartha’s second principle, the principle of potential for
generalization, requires that there should be reason to expect that the relationship
between positive and hypothetical analogy in the source obtains for the target as
well. In particular, there should be no “critical disanalogy” between source and
target.
Let me emphasize again that these modern authors have established that any
reasonable approach to analogy has to take into account both similarity in properties
between source and target as well as the relations between these properties and the
hypothetical analogy. The proposal in this essay builds on this important idea, a
more detailed critique of both Hesse and Bartha unfortunately is beyond the scope of
this paper.
8.3
Predictive and Conceptual Analogies
In the following, I introduce a distinction between predictive and conceptual anal-
ogies, which differ in various respects: concerning the epistemic aim, the nature of
the vertical relations, the criteria of evaluation, and the methodological framework.6
Arguably, the failure to clearly hold these types of analogical reasoning apart has led
to considerable confusion in the debate on analogical reasoning. Maybe most
importantly, only for conceptual analogies the role of analogical reasoning is
primarily heuristic, while predictive analogies aim at true or at least probable
inferences. As argued in Sect. 8.2.2, when discussing Keynes’ approach, the latter
type of analogies constitutes the core of inductive and causal reasoning.
6The proposal is embedded within a broader distinction between phenomenological science on the
one hand and abstract or theoretical science on the other hand (cp. Chapter 3). Perhaps the most
important difference between phenomenological and theoretical science concerns the aim: the
former is mainly interested in reliable prediction and successful manipulation, the latter in the
development of a conceptual and explanatory framework. Thus, predictive analogies ﬁt well with
phenomenological science, conceptual analogies ﬁt well with theoretical science. There are a
number of further characteristics that both distinctions share, for example whether the laws that
are used are causal or not. Some of the claims in this section can only be understood from the
perspective of this broader distinction between phenomenological and abstract science. Notable
scholars, who have made and argued for the distinction, include Duhem (1954) and
Cartwright (1983).
8.3
Predictive and Conceptual Analogies
211

An example of a predictive analogy is the use of animal models such as the mouse
model in pharmacology to determine the effectiveness of certain medication to cure
diseases in human beings. Predictive analogies aim to establish reliable prediction or
effective intervention. Consequently, the relevant vertical relationships must be of
causal nature. This follows from a view of causation in the sciences as the crucial
concept to distinguish between effective and ineffective strategies—as developed by
Nancy Cartwright and others (especially Cartwright 1979; cp. Sect. 5.1). Only if
there is some causal link between administering the medication and recovery both in
the mouse and in the human being, the analogical inference is reliable.
More exactly, a strategy how to effectively intervene in a phenomenon has to be
based on a direct causal relationship between some circumstances in the positive
analogy and the hypothetical analogy. Similarly, a reliable prediction must be based
on some causal connection, which however need not consist in a direct causal link,
but can also result from a common cause structure. In particular, an analogical
inference aiming at prediction may infer from a correlation between two variables
with a common cause in the source phenomenon to a similar correlation in the target
phenomenon. By contrast, a merely accidental correlation that does not result from
some causal connection cannot be used either for prediction or for intervention.
One might worry that the above argument presupposes Reichenbach’s principle
of common cause (1956, 157–159), which is controversial (e.g. Sober 1988).
Colloquially, this principle can be formulated as follows: ‘If there is a correlation
between two events, then this correlation must be either due to a direct causal
connection between the correlated events or due to a common cause.’7 Clearly, in
the above argument such a principle of common cause is not assumed, since
accidental correlations are possible, which by deﬁnition do not result from a com-
mon cause. Elliott Sober’s well-known example of a correlation between Venetian
sea levels and British bread prices is a plausible candidate for an accidental
correlation.
However, such an accidental correlation is not a reliable correlation and thus
cannot be used for reliable prediction. Therefore, accidental correlations cannot
support sound analogical arguments. A reliable correlation, as I understand it here,
requires that some reason exists, why the correlation holds. Such a reason could be a
direct causal link, a common cause, or a deﬁnitional or normative relationship
between variables.8 For accidental correlations, more or less by deﬁnition, such a
reason does not exist. Therefore these cannot be employed for reliable prediction,
even though a prediction based on an accidental correlation may very well turn out to
7This is a typical formulation (e.g. Sober 2001, 331). Reichenbach was somewhat more cautious:
“the principle of the common cause [. . .] can be stated in the form: If an improbable coincidence has
occurred, there must exist a common cause. [. . .] Chance coincidences, of course, are not impos-
sible [. . .] The existence of a common cause is therefore [. . .] only probable. This probability is
greatly increased if coincidences occur repeatedly.” (1956, 157-158)
8Due to lack of space, we cannot address here certain interesting, but controversial cases, such as
correlations due to indeterministic correlations, which arise for example in connection with the Bell
Inequalities, or correlations due to conservation laws.
212
8
Analogy

be true by chance. Deﬁnitional or normative relationships between variables hold by
stipulation and therefore cannot ground predictive analogical inferences, which
concern empirical relationships.
In summary, no matter if they aim at effective intervention or at reliable predic-
tion, predictive analogies always have to establish a causal relationship in the target
phenomenon based on some knowledge about a corresponding causal relationship in
the source phenomenon.
Predictive analogies are evaluated by verifying whether an intervention works,
which is suggested by the analogy, or whether a prediction turns out to be true. After
all, there is a matter of fact, whether a medication that cures a disease in a mouse will
also lead to recovery in a human being afﬂicted by a similar disease. Of course, as
this example demonstrates, such predictive analogies will in general not be deter-
ministic, but statistical, i.e. they will only hold with a certain probability. Thus,
methodological frameworks for predictive analogies try to determine the truth or at
least probability for analogical inferences. Both Carnap’s and Keynes’ approaches to
analogy, as delineated in the previous sections, are examples of such probabilistic
frameworks for analogical reasoning—covering chieﬂy predictive analogies.
An example for a conceptual analogy is the analogy between the transfer of heat
and interaction in electromagnetic phenomena as it was elaborated in great detail by
William Thomson and James Maxwell towards the end of the nineteenth century—
resulting in the modern particle-ﬁeld theory of classical electrodynamics:
The laws of the conduction of heat in uniform media appear at ﬁrst sight among the most
different in their physical relations from those relating to attractions. The quantities which
enter into them are temperature, ﬂow of heat, conductivity. The word force is foreign to the
subject. Yet we ﬁnd that the mathematical laws of the uniform motion of heat in homoge-
neous media are identical in form with those of attractions varying inversely as the square of
the distances. We have only to substitute source of heat for centre of attraction, ﬂow of heat
for accelerating effect of attraction at any point, and temperature for potential, and the
solution of a problem in attractions is transformed into that of a problem in heat. [. . .]
It is by the use of analogies of this kind that I have attempted to bring before the mind, in a
convenient and manageable form, those mathematical ideas which are necessary to the study
of the phenomena of electricity.” (Maxwell 1855/56, 157)
As is clear from this quote, Maxwell’s aim in developing the analogy between heat
and electricity is not primarily prediction or intervention. Rather, Maxwell wants to
develop a conceptual framework for electromagnetic phenomena based on another
framework that was more familiar and much better developed at the time, namely the
theory of heat. Such reasoning facilitates transferring certain results and solutions
from one ﬁeld to the other.
Since the primary aim is neither prediction nor intervention, the relevant vertical
relationships in such conceptual analogies are in general not causal—arguing again
with a Cartwrightian concept of causation as sketched above. In the example of
classical electrodynamics, there are good reasons to assume that the considered
relationships are to considerable extent deﬁnitional or conventional. In particular,
this perspective is in accordance with a standard view on the nature of axioms and
laws of fundamental scientiﬁc theories—interpreting these as implicit deﬁnitions of
8.3
Predictive and Conceptual Analogies
213

basic theoretical terms (cp. Sect. 3.1). Typical arguments for this view range from
underdetermination of abstract theory to the observation that the laws in fundamental
theories are too abstract to have themselves considerable empirical content. Only
when supplemented by further assumptions, e.g. bridge principles according to the
classic syntactic view of scientiﬁc theories, do these laws acquire empirical meaning.
This observation alone might already sufﬁce to establish the non-causal nature of the
fundamental laws of abstract scientiﬁc theories.
Relatedly, conceptual analogies are evaluated by whether they play a fruitful role
in transferring established solutions and results from one ﬁeld to another rather than
in terms of truth and probability. While in predictive analogies, one can verify
whether an analogical inference corresponds to a matter of fact, e.g. whether a
prediction turns out true or not, this is in general not possible for conceptual
analogies. To verify, whether a Poisson equation for the electric potential holds,
when postulated in analogy to the Poisson equation for temperature in the theory of
heat, is certainly not as simple as verifying predictive analogies. One reason lies in
the considerable underdetermination of abstract conceptual frameworks. Indeed,
Maxwell stressed the underdetermination of classical electrodynamics insisting
that there exists considerable ﬂexibility how to formulate the fundamental laws.
For example, a choice between action at a distance and ﬁeld theory in electrody-
namics remains possible (Pietsch 2012).
Thus, conceptual analogies are a creative endeavor. Whether they hold, is not so
much a matter of truth and probability but to considerable extent depends on the
ingenuity of the scientists—whether they are successful in mapping (part of) the
fundamental structure from one phenomenon to the other. Consequently, such
analogies cannot be treated in terms of probabilistic frameworks like those of Carnap
or Keynes. Approaches to analogical reasoning based on structure mapping, such as
from the work of Dedre Gentner (1983), seem much more adequate. Gentner’s
framework relies on a classiﬁcation of various entities, attributes and relations as
well as a quite sophisticated set of inference rules. Analogies are evaluated according
to a systematicity principle, essentially that those analogies are more plausible that
result from a mapping of mutually connected higher order relations compared with
those mapping only isolated properties. Note that this main criterion of the structure
mapping theory can hardly be translated into probabilities and consequently,
Gentner’s theory, while well suited for conceptual analogies, seems unable to
serve as a framework for predictive analogies.
From yet another perspective, a relatively sharp criterion to distinguish between
predictive and conceptual analogies concerns a difference in epistemic attitude when
formulating analogies. In the case of predictive analogies, one is primarily interested
in whether the respective inferences turn out true or not. By contrast in the case of
conceptual analogies, one is prepared to engage in considerable conceptual
reevaluation trying to reframe and redeﬁne relevant notions in order to make the
analogy work. A conceptual analogy, thus, is never a simple prediction but rather
presupposes a substantial willingness of the scientist to try to make the analogy ﬁt
the facts.
214
8
Analogy

To some extent, conceptual analogies also aim at truth in that the conceptual
framework, which is developed on the basis of such analogies, is at some point used
to make predictions about the phenomena, for which the framework is intended.
However, the primary focus is on developing a simple, but fruitful conceptual basis
with considerable explanatory power, while the truth or probability of any pre-
dictions is only an indirect or secondary aim. In particular, true or probable pre-
dictions based on the conceptual framework become important only at a later stage,
once the framework is sufﬁciently developed.
While this difference in attitude provides a relatively sharp criterion to distinguish
between predictive and conceptual analogies in scientiﬁc practice, one and the same
analogy can still be framed as either predictive or conceptual depending on the
respective attitude of the person formulating the analogy. For example, a scientist
could use a mouse model to predict the efﬁcacy of a medication in humans, but could
also use the same mouse model in order to develop an understanding of how speciﬁc
phenomena in the human body work.
Predictive and conceptual analogies are the main types of analogical reasoning in
the empirical sciences. Whether there are other types, for example in mathematics, is
a difﬁcult question. Given the non-empirical nature of mathematics, predictive
analogical inferences in the above sense will not play a role in this ﬁeld. With
respect to conceptual analogical reasoning, some variant is likely to be used in
mathematics, not least in view of the substantial similarities between mathematics
and theoretical physics. Whether other types of analogical inferences are employed,
ultimately depends on the epistemological status that is attributed to mathematics.
However, that question leads us far away from the actual topic of this chapter (see
e.g. Bartha 2010, Ch. 5).
8.4
A Deterministic Framework for Predictive Analogies
8.4.1
A First Suggestion
There exists a core intuition about valid analogical reasoning that can be found
across the literature and that is in line with the two-dimensional model sketched in
Sect. 8.2.3. This intuition is for example incorporated in Bartha’s second principle
that for valid analogical inferences no essential disanalogy between source and target
should exist. The basic idea is the following (PA):
A (predictive) analogical inference holds, i.e. the hypothetical analogy is true for the target,9
if and only if the negative analogy concerns only causally irrelevant circumstances.
9One might object that the validity of an analogical inference should not be confused with whether a
prediction turns out true or not. Notably, it has been argued that valid inferences are those that
adhere to commonly accepted methodological conventions, largely independently of empirical
success. However, in the case of (predictive) analogical inferences, a necessary and sufﬁcient
8.4
A Deterministic Framework for Predictive Analogies
215

Note that in line with the distinction introduced in Sect. 8.3, the vertical relations of
interest are causal in nature since the focus lies on predictive inferences. To repeat,
this insight stems from a Cartwrightian understanding of causation, the core feature
of which is to draw a distinction between effective and ineffective strategies,
including between reliable and unreliable prediction.
I will in the following suggest a methodology for predictive analogical inferences
that builds on the core intuition (PA). Before discussing the crucial notion of causal
irrelevance, let me brieﬂy point out some possible objections against the proposed
approach which are then mostly addressed later on in order to reﬁne (PA). A ﬁrst
issue concerns situations, where an analogical inference is valid even though some
circumstances in the negative analogy are causally relevant—i.e. (PA) is not a
necessary condition for predictive analogical inferences.10 Notably a factor may be
causally relevant, but may play no role in the considered analogy, because other
contributing factors are not instantiated, e.g. the burning match does not cause a ﬁre
since there is no combustible material present. Also, the inﬂuences of some causally
relevant circumstances could exactly cancel each other. For example, one might
infer from the acceleration that a stone receives on the earth to the acceleration that a
stone of the same mass receives on the moon. The acceleration is indeed the same, if
the difference in gravitational ﬁeld is exactly compensated by an acceleration of the
system of reference on the moon. Similarly, the same effect can be due to alternative
causes, e.g. the acceleration of a body may be caused by gravitational or by
electromagnetic ﬁelds. An analogical inference may still be valid even if in various
instances different alternative causes are active, if the effects of these different causes
add up to the same result.
Secondly, certain cases suggest that (PA) is not a sufﬁcient condition for predic-
tive analogical inferences. In particular, predictive analogical inferences may some-
times be based on relationships other than causal relevance, e.g. on mere
correlations. More exactly, even if the negative analogy is causally irrelevant, the
analogical inference could nevertheless fail to hold due to mere correlations between
some circumstances in the negative analogy and the hypothetical analogy. To use a
well-known example, one might infer that the bread price in London this year will be
the same as the bread price in London last year because the negative analogy is
causally irrelevant. However, upon reading an essay by Elliott Sober (2001), one
discovers that there exists a strong correlation between London bread prices and
Venetian sea levels. In addition, there are clear indications that the sea level in
Venice this year is much higher than last year. This seems to provide substantial
evidence to infer that the analogy fails, i.e. bread prices in London will not remain
the same. Even though Venetian sea levels presumably are causally irrelevant to
criterion for empirical success can be stated. Under these circumstances, it seems adequate to
identify valid (predictive) analogical inferences with those that obey the criterion.
10In this category falls a well-known example concerning the inference that there is life on Mars
based on the existence of life on Earth, even though there apparently are relevant differences
between both planets. How to deal with such examples will be outlined in Section 8.4.3.
216
8
Analogy

London bread prices, a change in the former may suggest a change in the latter due to
the mentioned non-causal correlation—contradicting the claim that only causally
relevant circumstances are important for analogical inferences.
Relatedly, predictions are sometimes based on deﬁnitional relations. This can
again result in situations where analogical inferences fail to hold even though the
causal structure has not changed. For example, an analogical inference from the
gravitational ﬁeld in one location to another at the same distance from the earth could
fail just because the concept of a gravitational ﬁeld is understood differently in both
situations.
A third point concerns the distinction between properties (which are ‘one-place’)
and relations (which are ‘many-place’). While the Keynesian terminology of positive
and negative analogy suggests a focus on properties rather than relations, many
scholars insist that analogy is less about a supposedly superﬁcial similarity in terms
of common properties of source and target, but rather about similarity in terms of
relations. For example, in the analogy between heat and electricity, the essential
similarity is not between corresponding terms such as temperature and electric
potential or source of heat and charge. Rather it concerns relations between these
terms, e.g. that they obey a Poisson equation.
To resolve this issue, note ﬁrst that relations always link properties with each
other. Thus, it would be wrong to think that one could exclusively focus on relations
neglecting properties altogether. The Poisson equation, for instance, relates temper-
ature and sources of heat as well as charges and electric potential. Furthermore, the
proposed approach (PA) obviously takes into account relationships as well, by
examining the causal relevance or irrelevance of certain properties for others.
It might still be questionable, whether complex analogies can be formulated in
terms of positive and negative analogies. After all, it does not appear straightforward
how to compare concepts like temperature and electric potential in terms of differ-
ences and similarities? In response, it should be stressed that if shared relations exist
one can always formulate shared properties corresponding to these relations. For
example, both temperature and electric potential share the abstract property that they
serve as potentials which by means of corresponding forces lead to the distribution of
certain quantities. By contrast, electric potential and temperature differ in terms of
the nature of the potential, in particular regarding the quantity on which it acts,
namely either charged matter or heat. In this manner, positive and negative analogy
can be distinguished. With sufﬁcient ingenuity, this is always possible.
Fourth and last, there are substantial worries concerning the notion of causal
irrelevance. For example, it is far from certain, whether causal irrelevance can ever
be established at all. After all, a circumstance that is normally considered irrelevant
may suddenly become causally relevant in some obscure situation. The constellation
of the stars at birth is usually not considered relevant to the fate of a person, but in
some contrived story it might have an impact. For example, the person may be
superstitious and the astrological prediction of a psychic may be so scaring that it
becomes a self-fulﬁlling prophecy. The ultimate lesson to draw from such counter-
examples is that causal irrelevance is context-dependent and that in an explication of
analogical reasoning this must be taken into account. Such context-dependence is of
8.4
A Deterministic Framework for Predictive Analogies
217

course not surprising to anyone familiar with the philosophical debate on causation.
It was stressed in particular by John Mackie, who in his approach to causation
introduced the crucial notion of a causal ﬁeld, to which all causal statements are
relative (1980).
Whether the basic intuition (PA) has merits or not, crucially depends on the
construal of the notion of causal irrelevance. To this issue we will turn now.
8.4.2
The Notion of Causal Irrelevance
In the following, I discuss several suggestions from the literature how to deﬁne
causal irrelevance and based on these will later lay out my own proposal (as already
presented in Sect. 5.2.1). All in all, it seems fair to say that the notion of causal
irrelevance has not played a central role especially in philosophical accounts of
causation, which are almost exclusively focused on the notion of cause in a positive
sense, i.e. on causal relevance. Therefore, the following overview can be rather brief.
First, one might try to deﬁne causal irrelevance based on statistical indepen-
dence.11 The most straightforward connection between both notions originates
within a probabilistic approach to causation (see e.g. Hitchcock 2016 for a useful
overview). If, broadly speaking, causal relevance of an event C to another event E is
identiﬁed with the increase or decrease of the conditional probability P(E|C) ≶P(E|Ø
C), it seems natural to deﬁne causal irrelevance of C to E in terms of an unchanged
probability P(E|C) ¼ P(E|ØC). As mentioned, most accounts of probabilistic causa-
tion do not explicitly address the notion of causal irrelevance in much detail. A
notable exception in this regard is Ellery Eells who distinguishes positive, negative,
mixed, and neutral causal relevance—the latter corresponding to causal irrelevance
(Eells 1991).
One important problem for a deﬁnition of causal relevance and irrelevance along
these lines are common cause structures, where a correlation between two variables
F and G does not result from a direct causal link between them, but rather from a
common cause H that is causally relevant to both variables. Let us assume in the
following for reasons of simplicity that all variables are binary. Even though no
direct causal relevance between the variables F and G exists, the conditional
probability changes, e.g. P(G|F) 6¼ P(G|ØF). However, it is well known that common
causes shield off such correlations—i.e. while P(G|F) 6¼ P(G|ØF), we have P(G|
F&H) ¼ P(G|ØF&H) when conditionalising on H. Thus, one needs to control for
common causes in order to identify the true relations of causal relevance or
irrelevance.
For his deﬁnition of causal irrelevance, Eells suggests considering the probabi-
listic impact of a potential cause X on a potential effect Y in various causal
11While I will eventually seek a deterministic notion of causal irrelevance, it is nevertheless helpful
to ﬁrst also look at related suggestions, including statistical notions.
218
8
Analogy

background contexts. In each causal background context, all factors F1, . . ., Fn that
are causally relevant to Y, independently of X12, are held ﬁxed. Only if the
probability of Y is not changed by X in all possible contexts, should one speak of
causal irrelevance (Eells 1991, 86). This condition is often called contextual una-
nimity. Note that Eells’ deﬁnition of causal irrelevance is circular to some extent
since the deﬁniens itself employs the notion of causal relevance in that it requires all
causally relevant factors to be held ﬁxed in causal background contexts. However, he
argues that the circularity is not vicious, since the deﬁniens refers to the causal
relevance of factors other than X, of which the irrelevance is examined (87). Eells
further relativizes causal relevance and irrelevance to “a particular population, as
well as to a kind that the token population exempliﬁes” (87). In part, this is required
in order for a probability distribution to exist at all. Certainly, causal and probabi-
listic dependencies will differ between populations and kinds of populations.
The deﬁnition of causal irrelevance (CI) proposed below in Sect. 8.4.3 is in many
ways similar to Eells’s approach, but it is deterministic and introduces context-
dependence in a somewhat different manner. Broadly speaking, context-dependence
becomes simpler, since in a deterministic situation the existence of a probability
distribution does not have to be ensured. As should be obvious, these changes with
respect to Eells’s account are necessary for correctly interpreting the role of causal
irrelevance in (PA).
In recent years, a link between causality and probabilistic independence has been
elaborated in the context of causal modeling on the basis of directed acyclic graphs
satisfying the causal Markov condition—such graphs are often referred to as causal
Bayes nets. The causal Markov condition implies a range of probabilistic indepen-
dency relations. In particular, the probabilities P for all nodes X1, X2, . . ., Xn must be
probabilistically independent when conditionalising on all parents PT of the nodes in
the graph:
PðX1, X2, . . . , XnÞ ¼ ΠiPðXijPTðXiÞÞ
Conditions like faithfulness or minimality further restrict the range of possible causal
models. Faithfulness, for example, states that both conditional and unconditional
probabilistic independencies in a graph must follow from the causal Markov condi-
tion. In particular, if two variables are probabilistically independent there should be
no causal link between them.
The faithfulness condition illustrates well the difﬁculties that arise when building
causal models merely from statistical relationships. On the one hand, premises like
faithfulness are indispensable to reduce the number of possible models to a man-
ageable amount. On the other hand, a range of counterexamples shows that faith-
fulness and related conditions can be little more than pragmatic and fallible tools to
12i.e. factors that are causally relevant to Y but to which X is not causally relevant—excluding in
particular factors that lie on a causal chain from X to Y.
8.4
A Deterministic Framework for Predictive Analogies
219

develop causal models. As an example, the faithfulness condition cannot account for
causal relationships that exactly cancel each other.
Generally speaking, statistical independence is neither a sufﬁcient nor a necessary
criterion for causal irrelevance. As mentioned, when causal inﬂuences between two
variables exactly cancel each other, there is presumably a causal link between these
variables even though they are probabilistically independent. Also, two variables
may be probabilistically independent, but in a number of instances of measure zero,
there may nevertheless be causal relevance. Such cases show that probabilistic
independence is not sufﬁcient for causal irrelevance. But probabilistic independence
is not necessary either. After all, as is elaborated in the following, there are methods
that determine causal irrelevance in deterministic situations, i.e. in situations in
which evidence in terms of probabilistic independence may be entirely absent, for
example because the relevant probability distributions are not even deﬁned. Fur-
thermore, probabilistic independence can never be fully established empirically as
ﬂuctuations will always lead to some small dependence.
As a second approach, let us take a look at deterministic deﬁnitions of causal
relevance, i.e. deﬁnitions that do not refer to probability distributions. A typical
version is given by Christopher Hitchcock:
X is causally relevant to Y, if and only if there is some set of variables, and some set of
values of those variables, such that when we intervene to set all those variables to those
values, at least some interventions on the value of X will lead to different values of Y. (2009,
305)
In a similar vein, Michael Baumgartner and Gerd Grasshoff, who advocate a
sophisticated regularity view of causation, suggest:
Factor A is causally relevant for the occurrence of an effect B, if and only if there exists at
least one causal process, in which an event of type A (partly) causes the occurrence of an
event of type B. (Baumgartner & Grasshoff 2004, 49; my translation)
While most authors discussing causal relevance do not bother to explicitly deﬁne
causal irrelevance, it can be construed as complementary to causal relevance.
Starting from the above deﬁnitions, causal irrelevance would essentially require
that no intervention can lead to a change in values of the effect variable or that no
process exists where an event of type A at least partly causes the occurrence of an
event of type B.
Such an approach to deﬁne causal irrelevance turns out inadequate for an analysis
of analogical inferences based on intuition (PA). After all, it may well happen that a
circumstance is causally relevant in some situation, while for the considered ana-
logical inference it plays no role, for example because other contributing causal
factors are missing or because there is a counteracting cause (cf. the ﬁrst objection in
Sect. 8.4.1). Thus, circumstances that are causally relevant according to the above
deﬁnitions may change from source to target, while the analogical inference may still
be valid—contradicting (PA).
Indeed, very few circumstances will turn out causally irrelevant according to the
above deﬁnitions, because in some obscure situation these might all be causally
relevant (cp. the fourth objection in Sect. 8.4.1). For this very reason, Baumgartner
220
8
Analogy

and Grasshoff largely reject the notion of causal irrelevance (2004, 212). One main
lesson to draw from these attempts to deﬁne causal irrelevance is that context-
dependence is not taken into account in an adequate manner. Exceptions to causal
irrelevance in more or less obscure situations should be discounted on the basis that
they occur within a context that differs from the one that is employed in the
analogical inference.
David Galles and Judea Pearl belong to the small number of authors, who in an
inﬂuential article (1997) explicitly deﬁne deterministic causal irrelevance and care-
fully implement context dependence:
A variable X is causally irrelevant to Y, given Z [. . .] if, for every set W disjoint of X [ Y
[ Z, we have
8 u, z, x, x0, w
ð
Þ,
Yxzw u
ð Þ ¼ Yx0zw u
ð Þ
where x and x’ are two distinct values of X. (reproduced in Pearl 2000, 235-6)
Here, u are the values of the background or exogenous variables of the model.
According to Pearl, this deﬁnition captures the intuition that “if X is causally
irrelevant to Y, then X cannot affect Y under any circumstance u or under any
modiﬁcation of the model that includes do(Z¼z).” (236)
It may be possible to use this deﬁnition for an approach to predictive analogies
based on (PA). However, this would turn out unnecessarily complicated. The ﬁrst
reason concerns model dependence. Galles and Pearl relativize their deﬁnition to a
speciﬁc causal model that is determined by a number of exogenous or background
variables U, a number of endogenous variables, and functions that determine each
endogenous variable based on the other variables. The type of background depen-
dence to be sketched in Sect. 8.4.3 is much simpler than such rather sophisticated
model dependence. Secondly, by relying on an interventionist account of causation,
Galles and Pearl subscribe to a substantial distinction between interventions and
observations, which leads them to introduce the so-called do-calculus for formally
handling interventions. However, the notion of intervention plays no major role in
analogical reasoning, neither in predictive nor in conceptual analogies, which
suggests that an interventionist framework might not be the ﬁrst choice for expli-
cating analogy (cp. also the criticism of interventionist accounts of causation in
Sects. 5.1.2 and 5.4.3).13
Note ﬁnally that while (PA) suggests looking for a deterministic explication of
causal irrelevance, this raises the question how to deal with indeterministic contexts
and with situations, in which the evidence allows to formulate only probabilistic
dependencies—an issue that will be brieﬂy addressed in Sect. 8.5.
13I have emphasized repeatedly Cartwright’s point that causation allows for implementing effective
strategies. Note that this does not necessarily imply an interventionist take on causation. Instead, I
favor an understanding in terms of difference making (cp. Chapter 5). The latter is more general and
implies less ontological commitments compared with the interventionist approach.
8.4
A Deterministic Framework for Predictive Analogies
221

8.4.3
A Necessary and Sufﬁcient Criterion
Let me in the following sketch an account of causal irrelevance based on difference-
making in context. The proposed deﬁnitions were introduced and defended in Sect 5.
2.1 and are brieﬂy summarized in the following for the convenience of the reader.
They get some initial plausibility from their close resemblance to the method of
difference, which is arguably the most successful rule in scientiﬁc method to
determine causal dependence.
Causal relevance shall be deﬁned in the following manner (CR):
A is causally relevant to C in a context B, if and only if (i) an instance exists, where A and C
occur in the context B, (ii) a second instance exists, where neither A nor C occur in the same
context B, and (iii) B guarantees homogeneity.
Note again that this deﬁnition largely corresponds to the method of difference as
given in particular by John Stuart Mill. Note further that causal relevance of A to C
with respect to B implies that a change in A within a context B always leads to a
change of C—in contrast to the deﬁnitions by Hitchcock as well as Baumgartner and
Grasshoff given in the previous section. Causal irrelevance can then be deﬁned as the
complementary14 notion (CI):
A is causally irrelevant to C in a context B, if and only if (i) an instance exists, where A and
C occur in context B, (ii) a second instance exists, where A does not but C still occurs in the
same context B, and (iii) B guarantees homogeneity.
Causal irrelevance of A to C with respect to B implies that a change in A within
context B never leads to a change in C. For example, a switch is causally irrelevant to
a light given two instances, one, in which both switch and light are on, and another,
in which the switch is off but the light still on, while nothing else that could be
relevant to the light has changed—the last premise essentially corresponding to
homogeneity. By contrast, the switch is causally relevant, if in the second instance,
the light is off.15,16
14As in Eells’s approach, there are mixed cases, in which a circumstance is neither relevant nor
irrelevant with respect to a given context.
15Note that the deﬁnition has some seemingly counterintuitive implications. If, for example, a light
is controlled by two switches A and A*, where the light is on if at least one of the switches is on, and
if it is presupposed as part of the background conditions that A* is on, then A will be classiﬁed as
causally irrelevant according to the deﬁnition (CI). While this sounds counterintuitive, the deﬁni-
tions above are intended as reﬁnements or improvements of our everyday notions in order to make
causal language more precise and avoid contradictions. Eventually, these seemingly counterintui-
tive implications will allow to resolve the ﬁrst group of problems for (PA) as discussed in
Section 8.4.1.
16Building on the example of the previous footnote, A is causally relevant to C, if it is part of the
background conditions that A* is always off, while A is causally irrelevant to C, if it is part of the
222
8
Analogy

The context or background B is constituted on the one hand by a set of circum-
stances that are allowed to change and on the other hand by a set of circumstances
that must remain constant. Homogeneity, which was already invoked by Mill in his
formulation of the method of difference, essentially captures the intuition that factors
in the background that are causally relevant to the examined phenomenon may not
change. This concept is used both in counterfactual approaches to causation such as
by Rubin and Holland (e.g. Holland 1986) and also in sophisticated regularity
approaches such as Baumgartner and Grasshoff (2004). The latter provide an
extensive discussion (2004, 208).
While homogeneity17 is usually deﬁned that all causally relevant factors must
remain constant, I prefer the complementary perspective that only causally irrele-
vant circumstances are allowed to change. When also taking into account the
deﬁnitions discussed in the previous Sect. 8.4.2, this has some subtle implications.
Most importantly, the explication of homogeneity given in the following is less
demanding in that more circumstances are allowed to change. Notably, some
circumstances, e.g. causal factors that are only active in certain contexts, may be
identiﬁed as causally irrelevant based on (CI), while they are causally relevant
according to conventional deﬁnitions, such as those of Baumgartner and Grasshoff.
Thus, these circumstances would have to remain constant to ensure homogeneity
according to Baumgartner and Grasshoff, while they are allowed to change
according to the following explication of homogeneity (H):
Context B guarantees homogeneity with respect to the relationship between A and C, if and
only if only circumstances that are causally irrelevant to C can change, (i) except for A and
(ii) except for circumstances that are causally relevant to C in virtue of A being causally
relevant to C.
The second exception allows for circumstances to change that lie on a causal chain
through A to C or that are effects of circumstances that lie on this causal chain.18
Clearly, the above explication also implements the before-mentioned intuition
behind the notion of homogeneity that factors in the background B that are causally
relevant to the examined phenomenon C may not change.
Let me now brieﬂy address how to deal with the problems that were raised in
Sect. 8.4.1. Concerning the ﬁrst objection, consider for example cases where two
inﬂuences A and B exactly cancel each other and therefore the analogical prediction
remains valid even though causally relevant circumstances change. In response, it is
speciﬁed that for valid analogical inferences it is not required that every property in
the negative analogy taken by itself must be causally irrelevant, but strictly speaking
background conditions that A* is always on. Again, this seeming contradiction only underlines the
need to always relativize causal dependencies to a background.
17Homogeneity broadly corresponds to context-unanimity in Eells’ account.
18The notion of ’causal relevance in virtue of‘ was introduced in Section 5.2.2. An exact
explication is: “A condition X is causally relevant to C in virtue of A being causally relevant to
C with respect to a background B, iff in all contexts within B, in which X is causally relevant to C, A
is causally relevant to C as well (but not necessarily vice versa).”
8.4
A Deterministic Framework for Predictive Analogies
223

only all properties in the negative analogy taken in conjunction19. If A and B exactly
compensate each other, then a change from A ˄ B to ØA ˄ ØB is irrelevant.
Similarly, if A and B are alternative causes for a phenomenon C, then a change
from A ˄ ØB to ØA ˄ B is irrelevant for the phenomenon C. In the ﬁrst case, A and B
taken in conjunction are causally irrelevant to C, as are ØA and ØB. In the second
case, A and ØB taken in conjunction are causally irrelevant to C, as are ØA and B.
In general, causal irrelevance of circumstances taken in conjunction can be
deﬁned in the following way (CI’):
A number of factors A1, A2, . . ., AN taken in conjunction is causally irrelevant to a
hypothetical analogy C with respect to a context B, if and only if (i) an instance exists,
where A1, A2, . . ., AN and C occur in context B, (ii) a second instance exists, where ØA1,
ØA2, . . ., ØAN and C occur in the same context B, and (iii) B guarantees homogeneity.
Thus, in order to determine causal irrelevance of a number of factors taken in
conjunction, one does not need to test the causal irrelevance of each factor individ-
ually or the potentially huge number of all possible combinations of those factors.
Instead, it sufﬁces to establish the two situations mentioned above.20
Note further that if a factor A which is commonly considered a cause fails to be
relevant for the considered analogy because other contributing factors are not
instantiated, e.g. the burning match does not cause a ﬁre since there is no combus-
tible material present, such a factor A is identiﬁed as causally irrelevant with respect
to the considered context according to the proposed deﬁnition (CI)—in contrast to all
other deﬁnitions of causal irrelevance discussed in the previous section. Therefore,
only the proposed deﬁnition of causal irrelevance (CI) in combination with the
intuition (PA) correctly classiﬁes such analogical inferences as valid. As an example,
one might conclude from a barn without ﬁre that another barn is not on ﬁre either
notwithstanding the presence of a burning match, just because combustible material
is absent in the second barn.
The second problem raised in Sect. 8.4.1 concerned analogies based on correla-
tions. Consider again the example that a circumstance F changes from source to
target, which is causally irrelevant to the hypothetical analogy G, but which is
correlated with it and therefore leads to the failure of the analogical inference. It
turns out that such situations are precluded in the sketched approach. Indeed,
according to the view of causation introduced in Chap. 5 and summarized in Sect.
8.3, any meaningful correlation between variables must result from a common cause,
i.e. any correlation that leads to a reliable prediction. Therefore, in order for an
analogical inference to fail in the described manner, the corresponding common
19i.e. a conjunction using the ◊-operator introduced in Section 5.3.3.
20Requiring irrelevance for all possible combinations of variables or for each variable individually
would be much too strong such that (PA’) as stated below would not be a necessary criterion. For
example, analogical inferences, in which two causally relevant factors exactly cancel each other,
would be wrongly identiﬁed as invalid.
224
8
Analogy

cause variable must change. However, such a change in common cause variables is
precluded by (PA), since these are not causally irrelevant to the hypothetical
analogy.
In response to the problem that analogies may be based on deﬁnitional, instead of
causal relevance, one might be tempted to restrict predictive analogies to causal
vertical relationships only. However, this runs into problems with familiar episte-
mological issues such as conﬁrmational holism and relatedly the lack of a clear
distinction between empirical and deﬁnitional statements. Instead, I broadly suggest
to integrate deﬁnitional relevance in the framework which should be rather easily
done since deﬁnitional relevance can be deﬁned in much the same manner as causal
relevance—given that the main difference merely lies in the nature of the necessity
between antecedent and consequent.21
With respect to the two other issues that were raised in Sect. 8.4.1, the distinction
between properties and relations was already discussed. Concerning the notion of
irrelevance, (CI) in combination with (H) is supposed to yield an adequate explica-
tion. In particular, by introducing strict context-dependence, (CI) aims to avoid the
problem that was pointed out in Sect. 8.4.1, namely that causal irrelevance is
practically inexistent, since any circumstance can be relevant in some obscure
situation.
But a crucial question remains, namely what exactly should be chosen as an
adequate context for the statement of irrelevance in the basic intuition (PA).
Remember that a context consists of circumstances that are allowed to change and
others that must remain constant. Since all circumstances that change (i.e. the
negative analogy) are explicitly considered as antecedent, these cannot be ascribed
to the context. What is left to account for are thus all circumstances that remain
constant, i.e. the positive analogy. Apparently, these then constitute the context.
In summary, the proposed deterministic approach to predictive analogical infer-
ences is given by the following explication (PA’) in combination with the deﬁnitions
of causal irrelevance (CI) and homogeneity (H):
Predictive analogical inferences from a source instance to a target instance are valid, if and
only if the negative analogy (taken in conjunction) is causally (and deﬁnitionally) irrelevant
to the hypothetical analogy with respect to a context constituted by the constancy of the
positive analogy.
It is important to emphasize that in (PA’) the negative analogy refers to the complete
negative analogy, i.e. comprises all circumstances that differ between the source
instance and the target instance. Similarly, the positive analogy refers to the complete
positive analogy, i.e. all circumstances that are the same for source and target
instance. In both cases, the considered circumstances thus include known as well
21Basically, one needs to replace in (PA), (CI), (CR), and (H) “causally irrelevant” with “causally
and deﬁnitionally irrelevant” as well as “causally relevant” with “causally or deﬁnitionally rele-
vant”. Note that for predictive analogies, all changes in the deﬁnitions of relevant terms must be
known in advance in order to clearly distinguish predictive from conceptual analogies according to
the criterion that one is prepared to engage in conceptual reevaluation only for conceptual analogies.
8.4
A Deterministic Framework for Predictive Analogies
225

as unknown circumstances. Furthermore, it is reasonable to restrict the considered
circumstances to those in the past as well as in the present of the event denoted by the
hypothetical analogy. Sub specie aeternitatis, one may need to also take into account
circumstances in the future, but a discussion of this question is far beyond the scope
of this paper.
Let me give an example to illustrate how (PA’) is applied. Regarding the question,
whether the existence of life on Earth allows inferring the existence of life on Mars,
one would start from two instances or situations, the ﬁrst (1) on Earth and the second
(2) on Mars. Let us assume that it is known: (a) that the hypothetical analogy Q is
true for (1), i.e. that life indeed exists on Earth; (b) what the positive and what the
negative analogy between both situations is; (c) that the negative analogy taken in
conjunction is irrelevant to the hypothetical analogy with respect to a background
constituted by the positive analogy. Then, it can be concluded that the hypothetical
analogy is true for situation (2), i.e. that life exists on Mars.
In a very simple illustration, it may be known that Earth and Mars differ only in
temperature, which thus constitutes the negative analogy. Temperature is also the
negative analogy taken in conjunction, since there is only one variable (cp. the
deﬁnition in Sect. 8.4.2). All other variables constitute the positive analogy, by
assumption these then have the same value for Earth and for Mars. Furthermore, one
knows from some experiment relying on the method of difference that temperature is
irrelevant to the existence of life, with respect to a context constituted by the positive
analogy. For example, an ingenious scientist may succeed in brieﬂy lowering the
temperature on Earth to the temperature that is typically found on Mars, while at
least some kind of life survives the temperature change. Carrying out the experiment
on Earth ensures that the context is the same as in the examined analogical inference.
Under these conditions, one can conclude from the existence of life on Earth to the
existence of life on Mars.
8.4.4
Conceptual Derivation
(PA’) can be reformulated in the following manner (PA”):
Given (i) a source instance P & N1 & . . . & Nk, of which it is known that C is the case, and
(ii) a target instance P & ØN1 & . . . & ØNk, of which it is not known whether C is the
case, where P denotes the positive analogy, N1, . . ., Nk the negative analogy and C the
hypothetical analogy, the following holds:
if and only if (iii) N1 & . . . & Nk taken in conjunction is causally and deﬁnitionally irrelevant
to C with respect to context P,
then the analogical inference that C is the case for the target instance holds.
Note that for the sake of clarity and without loss of generality, all circumstances in
the negative analogy are formulated in a positive way for the source instance and in a
negative way for the target instance.
A proof of (PA”) proceeds as follows:
226
8
Analogy

(I) To show that premise (iii) is a sufﬁcient criterion, assume that (iii) is true.
•
It follows from the deﬁnition (CI’) in combination with premise (i) of (PA’) that
the following instances exist: (1) P & N1 & . . . & Nk & C and (2) P & ØN1 & . . .
& ØNk & C. Note that so far, instance (2) need not coincide with the target
instance.
•
By deﬁnition, P denotes the complete positive analogy and N1 & . . . & Nk denotes
the complete negative analogy with respect to the hypothetical analogy
C. Therefore, in a deterministic setting, for which (PA”) is intended, the circum-
stances P & ØN1 & . . . & ØNk must uniquely determine, whether C is the case
or not.
•
Therefore, since in the target instance the state of the circumstances P & ØN1 &
. . . & ØNk is the same as in instance (2) and it is known that C is the case in
instance (2), it follows that for the target instance the hypothetical analogy C must
also be the case.
•
Thus, the analogical inference is correct.
(II) To show that premise (iii) is a necessary criterion, assume that (iii) is false.
•
It follows that one of the premises in (CI’) must be false, i.e. one of the premises
(a) that an instance P & N1 & . . . & Nk & C exists or (b) that an instance P & ØN1
& . . . & ØNk & C exists or (c) that the context P guarantees homogeneity.
•
By premise (i) of (PA”), an instance P & N1 & . . . & Nk & C exists. Also,
homogeneity is trivially fulﬁlled, because the context consists only of
circumstances P, which by assumption all remain constant. Thus, from premise
(iii) of (PA”) being false follows that the remaining premise (b) of (CI’) must be
false, i.e. there may not be an instance P & ØN1 & . . . & ØNk & C.
•
According to premise (ii) of (PA”), there exists a target instance with the
circumstances P & ØN1 & . . . & ØNk. Furthermore, as explained under
(I) above, the state of the circumstances P & ØN1 & . . . & ØNk must uniquely
determine whether C is the case or not. Since an instance P & ØN1 & . . . & ØNk
& C may not exist, ØC must be the case for the target instance.
•
Thus, the analogical inference is false.
From (I) and (II) follows (PA”) and therefore (PA’).
8.4.5
Further Discussion
In the following, several points of criticisms of the proposal in the previous Sect.
8.4.3 are discussed. As a ﬁrst issue, one might worry about the applicability of (PA’).
For example, one might doubt whether it is always possible to identify the positive
and the negative analogy, even if sufﬁcient evidence is available. In particular, one
could object that analogical inferences are actually based on similarity, while such
8.4
A Deterministic Framework for Predictive Analogies
227

similarity cannot necessarily be spelled out in terms of a constant positive analogy
and changes in a negative analogy.
As an example, consider again the question, whether the existence of life on Mars
can be inferred from the existence of life on Earth. For instance, both Earth and Mars
have an atmosphere, but it is not at all clear, whether having an atmosphere belongs
to the positive or the negative analogy. After all, both planets have an atmosphere,
but it also differs in important respects. Is it only possible to state a similarity
between Earth and Mars with respect to having an atmosphere, while this similarity
cannot be spelled out in terms of differences and conformities? In the end, the
problem is that the chosen description is inadequate for the question at hand, because
the description is too coarse. Using sufﬁciently detailed terminology can resolve the
issue. For example, the positive analogy might be that both planets have an atmo-
sphere containing oxygen and carbon dioxide, while the negative analogy is that the
concentrations of these components differ and that the atmosphere on Mars or Earth
may contain traces of other gases, which are not present in the atmosphere of the
other planet.
While differentiating the negative and the positive analogy will often be chal-
lenging, I do not see any reason, why it should not be possible in principle, if
sufﬁcient evidence is available. The following procedure corroborates this claim.
Start with a sufﬁciently detailed description of the ﬁrst phenomenon. All character-
istics that need to be changed, taken away or added in order to arrive at a sufﬁciently
detailed description of the second phenomenon constitute the negative analogy,
while all properties that remain the same constitute the positive analogy. In sum-
mary, it is an implicit premise of the proposed approach that any statement of
similarity can be broken down into a positive and a negative analogy, but this
premise seems quite plausible.
As a second issue, one might worry about practical applicability. Even if it is
possible to always clearly differentiate the positive and negative analogies in prin-
ciple, it may still be the case that in real-world situations there is rarely sufﬁcient
evidence to apply (PA’). As a ﬁrst remark, let me point out that in practice we often
have quite reliable intuitions that a large range of circumstances are irrelevant and
which circumstances may potentially be relevant. Furthermore, all inductive infer-
ences are based to some extent on analogy, which was the main insight drawn from
the discussion of Keynes’ approach in Sect. 8.2.2.
Consider for example a physicist, who examines two pendulums in order to
determine whether their periods are the same, i.e. the time for a complete cycle.
For this purpose, the physicist consults the relevant formula, which tells her that at
least for small amplitudes, the period depends only on the length of the pendulum
and on the acceleration of gravity at the location of the pendulum. In other words, the
formula tells the physicist which variables are relevant, so that she can examine
whether those relevant variables have the same value for both pendulums
(or whether their deviations mutually compensate each other). If the lengths of the
pendulums are the same and they are located in places with the same acceleration of
gravity, then one can infer by analogy relying on (PA’) from the period of one
pendulum that the period of the other pendulum must be the same.
228
8
Analogy

Whenever an inference is made for a speciﬁc situation based on a phenomeno-
logical scientiﬁc law that is empirically well established, this inference can be
construed according to the above pattern as an analogical inference with respect to
the evidence that was used to establish that law. In particular, the relevant experi-
ments and observations, which were used to establish the law, allow to determine
which variables are causally relevant to the considered phenomenon, usually by
some application of the method of difference or the method of concomitant variation.
Also, the evidence will include instances for which the hypothetical analogy is
identical or at least very similar compared with the speciﬁc instance, which is
predicted. In this way, the application of a phenomenological law can be interpreted
as an implicit analogical inference according to (PA’) with respect to such instances
in the relevant evidence. This view is an inductivist alternative to the conventional
hypothetico-deductive perspective on such applications of phenomenological laws.
Note further that analogical inferences can be considered on different levels of
coarse-graining. In the above-mentioned example, one might infer the explicit
value of the period, merely a value range to which the period belongs or even only
the fact that pendulums have a constant period for subsequent oscillations. This
shows that applications of (PA’) are quite wide-spread.
A further third issue that is also related to questions of applicability arises
regarding the notion of causal irrelevance (CI). It may well be that strictly speaking,
no circumstance fully satisﬁes (CI) and thus that no circumstance is truly irrelevant
to a phenomenon.22 Speciﬁcally, there might always be some however faint causal
inﬂuence, by which the circumstance and the phenomenon are connected. It thus
appears that (PA’) can never be fulﬁlled, because the negative analogy is never
entirely irrelevant to the phenomenon.
The conclusion to draw from this objection is that causal irrelevance is a contex-
tual notion, which depends on the amount of coarse graining that is assumed for the
relevant variables. In the example above, an inference that the periods of two
pendulums are exactly the same is not sensible, since in the empirical sciences,
any value can only be determined up to some degree of accuracy. While the negative
analogy will presumably always be causally relevant to some extent, the crucial
question is, whether the effect of this causal relevance is larger than the amount of
coarse graining that is assumed for the variables in the hypothetical analogy,
i.e. larger than the desired degree of accuracy. If the deviation is small enough for
the purpose at hand, the variables in questions must be considered causally irrele-
vant for that purpose at hand. Consequently, (PA’) can still be used in such
situations.
As a fourth criticism, many analogical inferences do not follow the rationale of
(PA’) by examining the causal irrelevance of the negative analogy, but are based on
other kinds of evidence, for example on correlations, on statistical laws, on retro-
dictions, etc. Such analogical inferences often enough turn out valid and there are in
many cases good reasons to be fairly conﬁdent in them. One may want to call strong
22I am grateful to an anonymous referee for bringing up this issue.
8.4
A Deterministic Framework for Predictive Analogies
229

predictive analogical inferences those that are based on evidence in terms of the
causal irrelevance of the negative analogy, while weak predictive analogical infer-
ences are based on other types of evidence.23 Strong analogical inferences are certain
if sufﬁcient evidence is available, while weak analogical inferences mostly convey
only a degree of probability or even only plausibility. Strong analogical inferences
are based on causal relationships and therefore imply knowledge about interven-
tions, while this is not necessarily the case for weak analogical inferences.
From a fundamental epistemological perspective, any weak analogical inference,
which proves reliable, must be based on a corresponding strong analogy, which
underlies the weak inference but is at least partly unknown to the person drawing the
inference. Thus, all types of evidence mentioned above in connection with weak
analogical inferences are only useful to the extent that they indicate the existence of
an underlying strong analogy. For example, an analogical inference based on
correlations is only reliable, if the correlated variables are adequate proxies for
underlying causal variables, e.g. in terms of common causes. In retrodictions, the
future variables should be suitable proxies for past causal variables, which may for
example be connected to the future variables by means of deterministic laws.
Finally, not all relevant variables may be known such that one has to rely on
statistical causal relationships. The analogical inference will then be valid only with
a certain probability. This case, which has considerable practical signiﬁcance, will be
brieﬂy addressed in the next Sect. 8.5.
According to a ﬁfth point of criticism, (PA’) presupposes determinism with
respect to the variables of the hypothetical analogy, i.e. that those variables are
fully causally determined by their respective circumstances. In the case of indeter-
minism, (PA’) may be fulﬁlled, but the analogical inference may nevertheless fail to
hold because pure chance interferes. One could of course alter (PA’) such that it also
accounts for indeterministic cases. Essentially, in indeterministic situations the
analogical inference holds only with the corresponding objective probability. Fur-
thermore, the status of the indeterministic hypothesis, i.e. the claim that the world is
to some extent indeterministic, remains uncertain even with respect to microphysics,
as supposedly deterministic interpretations of quantum mechanics show, in partic-
ular Bohmian mechanics. And even if the micro-realm is indeterministic, many
macro phenomena are deterministic, e.g. those treated by much of classical physics
and engineering, and thus (PA’) in the deterministic version of the previous section
applies to these phenomena.
A sixth issue concerns the so-called problem of induction. According to a wide-
spread consensus in epistemology and philosophy of science, inductive inferences
are always fallible. We can never know for certain, whether an empirical prediction
based on an inductive inference will turn out true. Some tension seems to exist
between this insight and the claim of the previous section that (PA’) constitutes a
necessary and sufﬁcient criterion for the truth of predictive analogical inferences.
23I am grateful to an anonymous referee for suggesting this helpful distinction.
230
8
Analogy

In this context, two assumptions should be distinguished. The ﬁrst regards
whether a consistent logic of induction exists. The second assumption regards
whether we can ever be completely certain that the premises for a valid inductive
inference are fulﬁlled, even if a consistent inductive logic is available. The general
fallibility of inductive inferences may result from a failure of either the ﬁrst or the
second assumption.
While many scholars doubt the existence of an inductive logic, the ﬁrst assump-
tion is much more controversial than the more general point that inductive inferences
are in principle fallible. Certainly, inﬂuential scholars have in the past attempted to
formulate a consistent inductive logic and seem to have believed that such a program
is feasible at least in principle, e.g. Carnap and Keynes (cp. Sect. 8.2.1 and 8.2.2).
Equally, in this chapter, I start from the assumption that variational induction can
provide a consistent framework of inductive logic, into which (PA’) can be
embedded.
From this view, it is the failure of the second assumption that leads to the general
fallibility of inductive inferences. With respect to predictive analogical inferences, it
turns out impossible to fully verify empirically, whether all premises required for
(PA’) are fulﬁlled. Most importantly, while we often have strong intuitions which
circumstances may be relevant or irrelevant, it is impossible to know with absolute
certainty. After all, among the myriads of circumstances that change between two
instances, there may always be some circumstance, however far-fetched and remote
it may appear, that has not yet been taken into account, but which eventually might
turn out relevant. Thus, judgments of causal irrelevance are always fallible and
consequently inferences based on (PA’).
8.5
Analogy and Probability
Thus far, we have only addressed deterministic analogical inferences that hold with
certainty. Of course, analogical inferences are often only probabilistic: Given a
certain known positive, known negative and unknown analogy, what is the proba-
bility that the hypothetical analogy is the case for the target phenomenon?
An extension of the approach delineated in Sect. 8.4.3 to cover such probabilistic
inferences is straightforward. Let me brieﬂy discuss the most important cases:
(i) ﬁrst, there may be an unknown analogy, which is causally relevant; (ii) second,
there may be a negative analogy, which is causally relevant only with a certain
probability; (iii) there may be situations of indeterminism.
Regarding the ﬁrst case, we have thus far only considered ideal situations, in
which every circumstance is known to belong either to the positive or to the negative
analogy. Now, as Keynes has rightly pointed out, in actual situations it is usually
unknown of a number of circumstances whether they belong to the positive or
negative analogy. Assume for the sake of simplicity that the unknown analogy
consists of only a single circumstance which is causally relevant in the respective
context. Then, the analogical inference is valid with the probability that this
8.5
Analogy and Probability
231

circumstance belongs to the positive rather than the negative analogy, if otherwise
(PA’) holds. Equally, if there is more than one factor in the unknown analogy, one
has to determine the combinations which are causally relevant and then add up the
respective probabilities belonging to those combinations.
In the second case, one may be uncertain whether circumstances that belong to
the negative analogy are causally irrelevant. Thus, the analogical inference is valid
with the probability that these circumstances taken in conjunction are causally (and
deﬁnitionally) irrelevant. Finally, in cases of indeterminism, i.e. in cases where the
circumstances determine the hypothetical analogy only up to a certain probability,
analogical inferences are valid with that probability. Of course, in such situations,
causal relevance has to be interpreted in a probabilistic manner determining a
probability distribution over states and not the state itself.
These are the principal cases, how probabilities may enter the assessment of
analogical inferences. Of course, various combinations are possible, for example
there may be an unknown analogy of which it is unknown whether it is causally
relevant. While one has to carefully keep track of the corresponding probabilities,
these complications do not add any substantial conceptual problems.
At this point, one may again worry about applicability. But in line with the
Keynesian insight that analogical reasoning is essential not only for deterministic,
but in particular also for probabilistic inferences, it turns out that the framework
delineated above underlies many forms of inductive reasoning in statistics and
probability theory. For instance, whenever one infers from a representative sample
to a new individual, the above framework is employed. Let us assume that the
probability to get lung cancer is 30% in a representative sample of a given popula-
tion, e.g. all smokers. From this, one concludes that a certain further individual, who
belongs to the same population of smokers, will get lung cancer with a probability of
30%. Essentially, the population is deﬁned by the extent that certain factors are
allowed to vary while others remain constant, e.g. genetic factors, living conditions,
habits etc. These factors determine the positive and negative analogy between the
various individuals of the population. Of the factors in the negative analogy, it is
often not known, whether they are present or absent in speciﬁc individuals and/or
whether they are causally relevant to smoking. This is the reason why we rely on
representative samples in the ﬁrst place. Now, the 30% probability basically
expresses that
•
in average, combinations of factors which are relevant to smoking are present
with a probability of 30% in each individual of the population or
•
in average, combinations of factors which are present in the population are
relevant to smoking with a probability of 30%.
Basically, these correspond to the cases (i) and (ii) as introduced above. Thus, an
inference to the probability for a new individual relies on the discussed framework, if
we know that the individual belongs to the same population as a representative
sample, for which the respective probability is known, i.e. that the individual has the
same positive analogy. Note ﬁnally that such probabilistic inferences are predictive
232
8
Analogy

analogical inferences as long as the person making them is not prepared to imple-
ment deﬁnitional changes.
One crucial question, however, concerns the interpretation of probability in such
probabilistic analogical inferences. On the one hand, the interpretation presumably
needs to be objective as prediction and intervention concern matters of facts rather
than subjective credence. On the other hand, the most common objective interpre-
tation, the frequentist approach, is not an adequate interpretation since it belongs to
the tradition of what was called above enumerative approaches to induction, which
are generally hostile to analogical reasoning. Let me therefore turn, in the next
chapter, to developing an adequate account of probability that ﬁts with variational
induction, a view on causation as difference making and the above proposed scheme
for analogical reasoning.
Acknowledgements This chapter is a revised version of “A causal approach to analogy”, Journal
for General Philosophy of Science 50(4), pp. 489–520.
References
Bartha, Paul. 2010. By parallel reasoning: The construction and evaluation of analogical argu-
ments. New York: Oxford University Press.
———. 2013. “Analogy and analogical reasoning.” Stanford Encyclopedia of Philosophy (Fall
2013 Edition). http://plato.stanford.edu/archives/fall2013/entries/reasoning-analogy/
Baumgartner, Michael, and Gerd Graßhoff. 2004. Kausalität und kausales Schließen. Norderstedt:
Books on Demand.
Carnap, R. 1950. Logical Foundations of Probability. Chicago: University of Chicago Press.
———. 1971. A Basic System of Inductive Logic Part I. In Studies in Inductive Logic and
Probability, ed. Richard Jeffrey and Rudolf Carnap, 34–165. Berkeley: University of California
Press.
———. 1980. A Basic System of Inductive Logic Part II. In Studies in Inductive Logic and
Probability, Vol. 2, ed. Richard Jeffrey and Rudolf Carnap, 7–155. Berkeley: University of
California Press.
Cartwright, Nancy. 1979. Causal Laws and Effective Strategies. Noûs 13 (4): 419–437.
———. 1983. How the Laws of Physics Lie. Oxford: Oxford University Press.
Davies, Todd R., and Stuart Russell. 1990. A Logical Approach to Reasoning by Analogy. In
Readings in Machine Learning, ed. T. Dietterich. San Mateo: Morgan Kaufmann.
Duhem, Pierre. 1954. The Aim and Structure of Physical Theory. Princeton: Princeton University
Press.
Eells, Ellery. 1991. Probabilistic Causality. Cambridge, UK: Cambridge University Press.
Galles, David, and Judea Pearl. 1997. Axioms of Causal Relevance. Artiﬁcial Intelligence 97: 9–43.
Gentner, Dedre. 1983. Structure-Mapping: A Theoretical Framework for Analogy. Cognitive
Science 7: 155–170.
Gentner, Dedre, Sarah Brem, Ron Ferguson, Phillip Wolff, Arthur B. Markman, and Kenneth
D. Forbus. 1997. Analogy and creativity in the works of Johannes Kepler. In Creative thought:
An investigation of conceptual structures and processes, ed. Thomas B. Ward, Steven M. Smith,
and Jyotsna Vaid. Washington, D.C.: American Psychological Association.
Hesse, Mary B. 1964. Analogy and Conﬁrmation Theory. Philosophy of Science 31: 319–327.
Hesse, Mary. 1966. Models and analogies in science. South Bend: Notre Dame University Press.
References
233

Hitchcock, Christopher. 2009. Causal Modelling. In Helen Beebee, Christopher Hitchcock, and
Peter Menzies (eds.), The Oxford Handbook of Causation, 299–314.
———. 2016. Probabilistic Causation. The Stanford Encyclopedia of Philosophy (Winter 2016
Edition). https://plato.stanford.edu/archives/win2016/entries/causation-probabilistic/
Holland, Paul W. 1986. Statistics and Causal Inference. Journal of the American Statistical
Association 81 (396): 945–960.
Huttegger, Simon. forthcoming. Analogical predictive probabilities. Mind. Preprint: http://faculty.
sites.uci.edu/shuttegg/ﬁles/2011/03/AnalogicalPredictionJuly2016.pdf
Kepler, J. 1596/1981. Mysterium cosmographicum I, II (A. M. Duncan, Transl.). (2nd ed.).
New York: Abaris Books.
Keynes, John M. 1921. A Treatise on Probability. London: Macmillan.
Kuipers, T. 1984. Two types of inductive analogy by similarity. Erkenntnis 21: 63–87.
Mackie, John L. 1980. The Cement of the Universe. Oxford: Oxford University Press.
Maher, P. 2001. Probabilities for multiple properties: The models of Hesse and Carnap and
Kemeny. Erkenntnis 55: 183–216.
Maxwell, James Clerk. 1855/56. On Faraday’s Lines of Force. Transactions of the Cambridge
Philosophical Society X.1: 155-229.
Norton, John. 2011. Analogy. Draft chapter of a book on inductive inference. http://www.pitt.edu/
~jdnorton/papers/material_theory/Analogy.pdf
Pearl, Judea. 2000. Causality. New York: Cambridge University Press.
Pietsch, Wolfgang. 2012. Hidden Underdetermination: A Case Study in Classical Electrodynamics.
International Studies in the Philosophy of Science 26 (2): 125–151.
———. 2016. A Difference-Making Account of Causation. http://philsci-archive.pitt.edu/11913/
Polya, G. 1954. Induction and Analogy in Mathematics. Princeton: Princeton University Press.
Prade, Henri, and Gilles Richard. 2014. Computational Approaches to Analogical Reasoning:
Current Trends. Heidelberg: Springer.
Reibe, Neil, and Friedrich Steinle. 2002. Exploratory Experimentation: Goethe, Land, and Color
Theory. Physics Today 55 (7): 43–49.
Reichenbach, Hans. 1956. The Direction of Time. Berkeley: University of Los Angeles Press.
Romeijn, Jan-Willem. 2006. Analogical Predictions for Explicit Simmilarity. Erkenntnis 64 (2):
253–280.
Russell, Stuart. 1986. Analogical and Inductive Reasoning. Ph. D. Thesis. Stanford University
Computer Science Department Technical Report STAN-CS-87-1150.
———. 1988. Analogy by Similarity. In Analogical Reasoning, ed. D. Helman. Boston: D. Reidel.
———. 1989. The Use of Knowledge in Analogy and Induction. London: Pitman.
Russell, Stuart, and Peter Norvig. 2009. Artiﬁcial Intelligence. Upper Saddle River: Pearson.
Salmon, Wesley. 1990. Rationality and objectivity in science or Tom Kuhn meets Tom Bayes. In
Scientiﬁc Theories, 175, ed. C. Wade Savage. University of Minnesota Press.
Sober, Elliott. 1988. The Principle of the Common Cause. In Probability and Causality, ed. James
Fetzer, 211–229. Dordrecht: Reidel.
———. 2001. Venetian Sea Levels, British Bread Prices, and the Principle of the Common Cause.
British Journal for the Philosophy of Science 52: 331–346.
Stegmüller, Wolfgang. 1973. Carnap II: Normative Theorie des induktiven Räsonierens. Berlin:
Springer.
234
8
Analogy

Chapter 9
Causal Probability
Abstract In this Chapter, a notion of causal probability is developed that ﬁts with
phenomenological science as well as with variational induction. In the proposed
account, causation is used to distinguish between meaningful and accidental rela-
tionships, where meaningful probabilities are those that can be reliably used for
prediction and possibly manipulation. In the spirit of variational induction, different
types of circumstances or conditions are distinguished, in particular collective
conditions, which remain constant in different trials of a given probabilistic phe-
nomenon, and range conditions, which can vary and which determine the outcome in
a speciﬁc trial of the probabilistic phenomenon. Causal probability is then based on
the fundamental notion of causal symmetries. Essentially, a causal symmetry
requires that the causal structure responsible for the probability distribution of
outcome events is invariant under a relabeling of the outcome events. Causal
symmetries determine the relative probabilities of the relabeled outcome events
according to a rule that is termed the principle of causal symmetry, which is an
objective counterpart to the principle of insufﬁcient reason. Furthermore, the random
nature of subsequent outcomes is guaranteed by the independence of trials, which is
explicated in causal terms. A probability interpretation relying on causal symmetries
can be seen as a generalization of objective interpretations in the tradition of the
method of arbitrary functions. Frequencies and symmetries are the two fundamental
types of evidence for probabilistic relationships. While frequency interpretations of
objective probability are well known, the proposed account attempts to base objec-
tive probability solely on symmetries.
Keywords Data science · Probability · Method of arbitrary functions · Symmetry ·
Relative frequency · Principle of indifference · Probabilistic independence
© Springer Nature Switzerland AG 2022
W. Pietsch, On the Epistemology of Data Science, Philosophical Studies Series 148,
https://doi.org/10.1007/978-3-030-86442-2_9
235

9.1
Probability in Data Science
9.1.1
The Debate on Probability in Light of Data Science
In previous chapters, an epistemological framework was developed that aims to be
adequate for an analysis of data science. Regarding the role of probability and
statistics, there are (at least) two serious shortcomings of the proposed framework.
First, it is deterministic as was discussed at length in Chap. 6, in which determinism
was identiﬁed as one crucial premise for the methods of variational induction to yield
reliable results. Moreover, all determining factors should be known in order to suc-
cessfully carry out causal analysis according to variational induction. These premises
are not plausible for many data science applications, because it will almost never be
the case that all causally relevant factors can be taken into account, even if the
phenomenon is fully causally determined in principle. As an example, there may be a
complete list of causal factors for the development of lung cancer in human beings,
but even with the help of big data and machine learning, it is implausible that these
factors will ever be known in totality. Science can certainly ﬁnd out more details
about the various factors, e.g. genetic or environmental, under which someone who
smokes develops lung cancer, but these causal relationships will almost always
remain statistical, i.e. only give probabilities for a phenomenon to happen. Thus,
the epistemological approach of the previous chapters needs to be generalized to
statistical causal relationships, in particular by developing an account of probability
that ﬁts well with variational induction and the corresponding difference making
account of causation.
The second and related shortcoming is that the proposed epistemological frame-
work cannot account for the fact that in many data science applications, predictions
are based on proxy factors that correlate well with the actual causal factors, which are
at least partly unknown. The resulting relationships between proxy variables and the
examined phenomenon will have exceptions and thus will hold only statistically
since the proxy variables will not always adequately reﬂect the state of the actual
cause variables. Also, interventions on proxy variables generally do not lead to
changes in the phenomenon, precisely because the variable is not the actual cause
variable. Thus, proxy variables do not provide a handle for intervention and manip-
ulation of a phenomenon, while they often permit reliable prediction of the phenom-
enon, if a common cause exists of the examined phenomenon and the proxy variable.
For example, Apple users may tend to stay in expensive hotels, since afﬂuence is a
common cause of both. However, since owning an Apple computer is only a proxy
variable, donating an Apple computer to a person will not make her/him stay in more
expensive hotels. Thus, the concept of probability to be developed in the following
will have to take into account the role of proxies for reliable predictions in data-
scientiﬁc practice.
Bearing in mind these two challenges, let us next look at various conceptual
approaches to the notion of probability, trying to determine which of these
approaches is the most adequate for an epistemology of data science. The conceptual
236
9
Causal Probability

debate about probability is as complex as that about causation which was delineated
in Sect. 5.1 and I will proceed here in a similar manner, brieﬂy introducing the core
ideas of the various accounts of probability and then examining to what extent they
ﬁt the practice of data science.
The most fundamental distinction in the debate on probability is that between
epistemic interpretations and ontic or objective interpretations. In line with the
meaning of the Greek term ‘episteme’, the former class of interpretations is
concerned with the role of probability in a theory of knowledge, i.e. in a theory of
how we form our beliefs about the world. Epistemic probabilities thus by their very
nature refer to a subject, who acquires knowledge gradually changing her/his beliefs
in the light of new evidence. In other words, epistemic interpretations understand
probabilities in terms of varying degrees of belief of a subject.
The two principal types of epistemic interpretations can be distinguished in terms
of the characteristics ascribed to the subject. On the one hand, an idealized sub-
ject may be assumed that follows strictly rational or logical rules when she/he
evaluates which degrees of belief one should hold. Such a logical interpretation
identiﬁes probability with rational degrees of belief. On the other hand, probabilities
can be interpreted as the degrees of belief that persons or subjects actually hold,
whether these are truly rational or not. Proponents of such a subjective interpretation
of probability believe that the strict rational rules of the logical interpretation do not
exist. While according to the logical interpretation, in the same knowledge context
the probabilities are uniquely ﬁxed, the subjective interpretation allows for consid-
erable ﬂexibility in assigning probability values as long as the fundamental axioms
of probability theory are observed.
By contrast, ontic or objective interpretations consider probability as an objective
concept that belongs to the ontology of the world rather than being tied to a theory of
knowledge. If all subjects that hold degrees of belief are removed from the world,
ontic probabilities would remain as part of the furniture of the world, while epistemic
probability would not constitute a meaningful concept anymore. Of course, ontic
probabilities should to some extent translate into epistemic probabilities. If an
objective probability relation exists between certain phenomena, one would ideally
expect that the epistemic probabilities correspond to the ontic probabilities if the
latter are known. This rule for assigning epistemic probabilities is commonly
referred to as Principal Principle (e.g. David Lewis 1980). The converse does not
hold, since epistemic probabilities representing degrees of belief need not corre-
spond to any objective relationship in the world. However, if there is not even
approximate correspondence, then such epistemic probabilities are uninteresting for
the questions of scientiﬁc methodology that are at stake in the present book. After all,
in the practice of data science, probabilistic relationships are only important insofar
as they can ground either reliable prediction or effective intervention and to this
purpose probabilistic relationships must somehow refer to what is objectively
the case.
Thus, regarding the epistemology of data science, we are primarily interested in
ontic probabilities and only as a second step in the question, how these ontic
probabilities translate to epistemic probabilities. Traditionally, there are two types
9.1
Probability in Data Science
237

of ontic interpretations. The best known and most widely accepted is the so-called
frequency interpretation according to which the probability of C given A denotes the
(limiting) frequency with which events of type A are also of type C. The frequency
interpretation ﬁts with the rationale of regularity that was discussed in Sect. 4.1 and
is therefore susceptible to the same criticism. Conversely, the frequency interpreta-
tion does not adequately reﬂect the variational rationale underlying the types of
evidence and methods of inductive inference which are usually employed in data
science (cp. Chap. 4). In particular, the frequency interpretation pays too little
attention to the exact circumstances under which events A and C happen.
Such criticism was already raised by Karl Popper among others, which eventually
led him to reject the frequency interpretation. Instead, Popper suggested to interpret
probabilities in terms of tendencies or propensities inherent in the circumstances
which bring about a certain event. By focusing on the speciﬁc circumstances that are
relevant for a phenomenon, this propensity interpretation of probability is consid-
erably closer to the variational rationale that underlies much of data science. Popper
also draws a link to causation, by considering propensity a sort of generalized
causality, where causality establishes deterministic relationships and propensities
only partial determination.
Starting from the argument in Sect. 5.1, the probabilistic relationships of interest
from the perspective of data science should be of causal nature since causality is the
crucial concept to ground effective intervention in the case of a direct causal
relationship as well as reliable prediction either based on a direct causal dependence
or on a common cause relationship. Thus, a notion of causal probabilities will be
developed corresponding to degrees of causal determination of a phenomenon by
certain circumstances. If the partial causal determination is direct, changes in the
relevant circumstances can be used in order to manipulate as well as to predict a
probabilistic phenomenon. If the partial causal determination is indirect, the circum-
stances can only be used for prediction, not for manipulation. As we will see later in
the chapter, this role of causation is different from the role according to the
propensity interpretation.
As is well known, Popper was highly critical of induction, so he did not raise the
question, how propensities can be inductively determined. Relatedly, Popper never
developed an account of induction, how causal relationships can be inferred from
evidence. Thus, the conceptual connection between causation, induction and pro-
pensity is rather weak in Popper’s epistemological framework. By contrast, the
notion of causal probability to be developed in the following will be closely linked
to a corresponding inductive approach and a related concept of causation. In light of
the discussion in Chap. 4, such an inductive methodology should fall into the realm
of variational induction.
Because it ﬁts with a variational rationale, the account of probability developed in
the following can serve as a conceptual foundation to interpret statistical results from
various machine learning algorithms and in particular to identify whether these
results are meaningful, in that they can be reliably used for manipulation and
prediction.
238
9
Causal Probability

9.1.2
A Brief Overview of What Is to Come
Research on probabilistic causality has been a thriving enterprise since about the
1980s addressing the mainly methodological question how causality can be inferred
from statistical data. By contrast, this chapter is about causal probability, i.e. the
conceptual question how probability can be integrated into a general framework of
induction and causation.
In recent discussions on the foundations of probability, a novel class of objective
interpretations has been proposed that is distinct from the more familiar propensity
and frequency accounts (Strevens 2006, 2011; Rosenthal 2010, 2012; Abrams
2012). The interpretations essentially stand in the tradition of an approach by
nineteenth-century methodologist Johannes von Kries and of related work on the
method of arbitrary functions. For reasons that will soon become clear, I subsume
these and similar approaches under the notion of causal probability. Two common
features are particularly important: (i) First, causal interpretations replace or supple-
ment the principle of insufﬁcient reason by an objective version of the principle of
indifference1 that refers to physical or causal symmetries. This distinguishes causal
interpretations both from frequentist approaches, which exclusively refer to relative
frequencies as fundamental evidence for probabilities, and from logical accounts,
which base probabilities on ignorance via the principle of insufﬁcient reason, i.e. a
purely epistemic reading of the principle of indifference. As we will see, the
objective variant of the principle of indifference is not troubled by the central
objections brought forth against the principle of insufﬁcient reason, in particular
the ambiguities in its application called Bertrand’s paradox. (ii) Second, causal
interpretations employ a notion of probability in terms of the ratio between favorable
conditions and all conditions. This is another subtle but crucial difference to fre-
quency interpretations which deﬁne probability in terms of the ratio between the
number of events leading to a certain outcome and the total number of events. As will
be shown in Sect. 9.3, rendering probability relative to the conditions determining an
ensemble or collective provides for a simple solution to a speciﬁc version of the
reference class problem.
Note that propensity interpretations also frame probability in terms of circum-
stances or conditions and they sometimes make the link to causation. In fact, the
proposed account owes in many ways to various versions of the propensity inter-
pretation, but it also differs in important respects. First of all, propensity accounts
rely on a distinct ontological category, namely propensities in the sense of tendencies
or dispositions. The relation with causality is not always clariﬁed, but if it is, as in
Karl Popper’s later work, then propensities are often considered to be more general
than causation. By contrast, the causal interpretation presented in Sects. 9.3, 9.4, 9.5,
and 9.6 tries to situate probability within a framework of causal reasoning. While
1A note on terminology: In the following the term ‘principle of indifference’ will be used to refer to
both an epistemic version, called ‘principle of insufﬁcient reason’, and an objective version, called
‘principle of causal symmetry’.
9.1
Probability in Data Science
239

propensity accounts focus conceptually on dispositions or tendencies and rather
casually remark upon the parallel with causation, the interpretation proposed here
starts with the detailed and speciﬁc account of causation developed in previous
Chapters and then examines how probability ﬁts into the picture. Furthermore, a
number of concepts are central to the causal approach that are not usually evoked in
the exposition of propensity interpretations, in particular the notion of causal sym-
metry leading to an objective version of the principle of indifference (Sect. 9.4) and
the causal construal of probabilistic independence based on judgments of causal
irrelevance (Sect. 9.5).
In Sect. 9.2, I discuss various proponents of a causal2 approach to probability
from the nineteenth century as well as more recent developments in the tradition of
the method of arbitrary functions. The latter are mainly due to Michael Strevens,
Jacob Rosenthal, and Marshall Abrams, and are henceforth abbreviated as
SRA-approach. I brieﬂy indicate how causal probability resolves several objections
against other interpretations of probability, e.g. the problem of distinguishing
between accidental and necessary relations in the frequentist approach, or problems
regarding the principle of indifference in the logical approach. I then point out some
shortcomings of the SRA-approach. Besides some technical difﬁculties, it makes no
connection with a general framework of induction and causation. Also, it cannot
handle indeterminism and epistemic probabilities. Later in the chapter, I suggest how
causal probability can deal with these issues.
Starting from Sect. 9.3, I develop a speciﬁc account of causal probability,
according to which probabilities are understood as degrees or grades of causal
determination of a phenomenon by a given set of circumstances or conditions,
which can be considered both in direction from causes to effects and vice versa to
avoid Humphreys’ paradox. First, two fundamental inductive frameworks are
outlined, enumerative and variational induction. For each, I show how probability
can be integrated. Enumerative induction leads to a naïve frequency view of
probability, which suffers from the familiar problems, in particular that it cannot
distinguish between law-like and accidental frequencies. Variational induction
resolves this issue by carefully keeping track of all conditions under which a
phenomenon happens. The corresponding account of probability, which carefully
distinguishes different types of conditions, is termed causal probability. What I will
call the collective conditions determine the possibility space of a probabilistic
phenomenon, i.e. all possible outcomes. The outcomes are categorized and the
classes are labeled, where the labels are called attributes3. The range conditions
(together with the collective conditions) then determine exactly which of the attri-
butes occurs, at least in deterministic contexts. While the collective conditions
2Some do not explicitly use the term causality, but instead refer to nomic dependencies. Many of the
central ideas and concepts nevertheless remain the same.
3The terms ‘attribute’ (translated from the German ‘Merkmal’) and ‘range’ (German ‘Spielraum’)
are used in reverence to von Mises and von Kries, respectively, on whose ideas the present essay
draws substantially.
240
9
Causal Probability

remain constant for a probabilistic phenomenon, the range conditions will vary. A
measure over the input space, spanned by the range conditions, is also ﬁxed by the
collective conditions, more exactly by symmetries in the causal set-up. One could
say that symmetrism replaces frequentism. Via the mathematical theorem, called the
law of large numbers, the measure denotes the limiting relative frequency with
which the different input states are instantiated. Causal probability then is calculated
as the fraction of outcome states, weighted with the measure, that pertain to a
certain attribute. Rendering probability relative to collective conditions and measure
resolves the mentioned technical problems of the SRA-approach while adding an
irreducible epistemic element.
Section 9.4 introduces the notion of a causal symmetry which allows inferring
probabilities without taking recourse to relative frequencies of input states or of
outcome events. A causal symmetry essentially requires that the causal structure
responsible for a probability distribution of outcome events is invariant under a
relabeling of the outcome events. The concept leads to an objective version of the
principle of indifference, which I term principle of causal symmetry. In the simplest
case, two attributes that exhibit a causal symmetry are assigned equal probability.
Furthermore, I argue that the epistemic principle of insufﬁcient reason yields the
same results as the principle of causal symmetry, whenever the resulting probabil-
ities are predictive, i.e. essentially whenever these probabilities correspond to the
actual limiting frequencies. If the relevant causal symmetries are not epistemically
accessible, as is often the case, relative frequencies can be consulted as a weaker type
of evidence for predictive probabilities.
In Sect. 9.5, the notion of probabilistic independence is explicated at some length
establishing its relationship with causal irrelevance as determined by variational
induction. Independence guarantees randomness in the sequence of input states and
consequently of attributes. Since many theorems in probability theory like the law of
large numbers presuppose independence of trials, a causal construal of independence
is another crucial ingredient of the causal interpretation of probability. It broadly
corresponds to the notion of randomness in frequentism and exchangeability in the
subjectivist approach to probability. Furthermore, I outline how a probability mea-
sure can be established and interpreted based on arguments of symmetry and
irrelevance without having to take recourse to relative frequencies. To sum up, the
deﬁnition of probability in Sect. 9.3.2, the principle of causal symmetry, and the
causal rendering of probabilistic independence should be considered as a coherent
package of the account of causal probability proposed in this essay.
Finally, various ontic and epistemic aspects in probability statements are identi-
ﬁed in Sect. 9.6, and it is shown how the framework of causal probability can cover a
wide range of applications from indeterministic phenomena to probabilities from
causal symptoms or proxy variables to the probabilities of hypotheses.
9.1
Probability in Data Science
241

9.2
Predecessors and Contemporary Debate
9.2.1
Historical Proponents: Cournot, Mill, von Kries
The two main ingredients of a causal interpretation as sketched in the introduction
and elaborated later on in the article can be found with a variety of writers until the
end of the nineteenth century. As already indicated, the viewpoint is rather rare in the
twentieth century presumably due to widespread hostility towards inductive or
causal approaches in science.
The distinction between an epistemic principle of insufﬁcient reason and an
objective principle of causal symmetry may be foreshadowed already in Laplace’s
classic ‘Philosophical Essay on Probabilities’: “The theory of chance consists in
reducing all events of the same kind to a certain number of cases equally possible,
that is to say, to such as we may be equally undecided about in regard to their
existence, and in determining the number of cases favorable to the event whose
probability is sought.” (Laplace 1902, 6–7; see also Strevens, Ch. 3.2) Of course,
Laplace has in mind what was later called the classical deﬁnition of probability,
i.e. the ratio of favorable to all possible cases. But everything hinges on the exact
interpretation of equal possibility and how it is determined. Curiously, Laplace
alludes to both epistemic and objective aspects, though these are not clearly held
apart in his writing. In the quote given above, equal undecidedness implies an
epistemic reading of equal possibility. But a later discussion of a loaded die evokes
objective connotations in that Laplace distinguishes between judgments with respect
to the knowledge of the observer and the presumably objective bias manifest in the
coin. Laplace adds that the determination of respective possibilities is “one of the
most delicate points of the theory of chances” (p. 11).
Other authors have been more explicit in drawing the distinction between episte-
mic and objective versions of the principle of indifference. One of the clearest
expositions is due to Antoine-Augustin Cournot, who in the following quote delin-
eates a principle of insufﬁcient reason, which cannot establish objective probabili-
ties: “If, in an imperfect state of our knowledge, we have no reason to believe that
one combination is realized rather than another, even though in reality these com-
binations are events that may have unequal mathematical [i.e. objective] probabil-
ities or possibilities, and if we understand by the probability of an event the ratio of
the number of combinations that are favorable to the event to the total number of
combinations that we put on the same line, this probability could still serve, in lack
of a better option, to ﬁx the conditions of a bet [. . .]; but this probability would not
anymore express the ratio that really and objectively exists between things; it would
take on a purely subjective character and could vary from one individual to the other
depending on the extent of her knowledge.”4 (1843, 438, my translation)
4“Si, dans l’état d’imperfection de nos connaissances, nous n’avons aucune raison de supposer
qu’une combinaison arrive plutôt qu’une autre, quoiqu’en réalité ces combinaisons soient autant
d’événements qui peuvent avoir des probabilités mathématiques ou des possibilités inégales, et si
242
9
Causal Probability

Cournot also sketches the role of frequencies with respect to objective probabil-
ities leading to the following colloquial statement of the law of large numbers: “If
one considers a large number of trials of the same chance process, the ratio of the
number of trials where the same event happens to the total number, becomes
perceptibly equal to the ratio of the number of chances favorable to the event to
the total number of chances, or what one calls the mathematical probability of an
event.”5 (437, my translation) According to Cournot, the chances are measured in
terms of the possibilities that certain conditions occur together to produce a partic-
ular type of event. Obviously, he employs a notion of probability distinct from
relative frequencies referring to the ratio of favorable to all conditions or
circumstances.
Thus, Cournot’s account hints at both ingredients of causal probability that were
identiﬁed in the introduction: the distinction between an epistemic and an objective
version of the principle of indifference and a deﬁnition of probability that refers to
the number of favorable conditions, not instances.
The basic idea of an objective causal interpretation distinct from a frequentist
approach is present with several other authors in the nineteenth century, for example
in the writings of John Stuart Mill: “The probability of events as calculated from
their mere frequency in past experience affords a less secure basis for practical
guidance than their probability as deduced from an equally accurate knowledge of
the frequency of occurrence of their causes.” (1886, 355) Mill also recognizes the
distinction between an epistemic and an objective reading of the principle of
indifference. For example, he criticizes the alleged purely epistemic reading by
Laplace: “To be able [. . .] to pronounce two events equally probable, it is not
enough that we should know that one or the other must happen, and should have
no grounds for conjecturing which. Experience must have shown that the two are of
equally frequent occurrence.” (351) Mill sketches several options how the latter
could happen, e.g. for the case of a coin toss: “We may know [that two events are of
equal occurrence] if we please by actual experiment; or by the daily experience
which life affords of events of the same general character; or deductively, from the
effect of mechanical laws on a symmetrical body acted upon by forces varying
indeﬁnitely in quantity and direction.” (351) Here, Mill introduces the important
distinction between evidence in terms of frequencies and in terms of mechanical
symmetries to establish objective equipossibility (cf. Sect. 9.4.4). On this basis, he
nous entendons par probabilité d’un événement le rapport entre le nombre des combinaisons qui lui
sont favorables, et le nombre total des combinaisons mises par nous sur la même ligne, cette
probabilité pourra encore servir, faute de mieux, à ﬁxer les conditions d’un pari, d’un marché
aléatoire quelconque; mais elle cessera d’exprimer un rapport subsistant réellement et
objectivement entre les choses; elle prendra un caractère purement subjectif, et sera susceptible
de varier d’un individu à un autre, selon la mesure de ses connaissances.”
5“Lorsque l’on considère un grand nombre d’épreuves du même hasard, le rapport entre le nombre
des cas où le même événement s’est produit, et le nombre total des épreuves, devient sensiblement
égal au rapport entre le nombre des chances favorables à l’événement et le nombre total des chances,
ou à ce qu’on nomme probabilité mathématique de l’événement.” (437)
9.2
Predecessors and Contemporary Debate
243

roughly formulates the notion of causal probability referring not to the frequency of
events, but to causal conditions: “We can make a step beyond [the frequentist
estimation of probabilities] when we can ascend to the causes on which the occur-
rence of [an event] A or its non-occurrence will depend, and form an estimate of the
comparative frequency of the causes favourable and of those unfavourable to the
occurrence.” (355)
Curiously, Mill eventually retreats from this position that he so clearly formulated
in the ﬁrst edition of his ‘Logic’, adding the following comment in later editions: “I
have since become convinced that the theory of chances, as conceived by Laplace
and by mathematicians generally, has not the fundamental fallacy which I had
ascribed to it [essentially referring to the epistemic reading of the principle of
indifference].” (351) Mill claims that probability is fundamentally an epistemic
notion and that probabilistic statements have no objective meaning anyways,
because in a deterministic world any future event is fully determined by preceding
conditions.
It remains somewhat unclear where Mill is heading with these remarks. Does he
just want to rehabilitate the epistemic reading of the principle of indifference or does
he want to deny the distinction between epistemic and objective readings altogether?
From the viewpoint of this essay, Mill is correct that in a deterministic world, there is
an epistemic element to any probabilistic statement, but he apparently fails to
recognize that a fairly6 objective meaning of probability nevertheless remains
feasible: if one always relates probability to a causally determined collective
(as elaborated in Sect. 9.3.2). In any case, it is quite remarkable to observe how
even an ingenious thinker like Mill struggles with the concept of probability.
Finally, the approach of Johannes von Kries should be mentioned (as summarized
in his 1886, vii–viii; cp. also Kamlah 1983).7 His account was highly inﬂuential on
twentieth-century philosophy, both on discussions within the Vienna Circle
(Waismann, Wittgenstein) and on recent proposals regarding a novel class of
objective probabilities (Strevens, Rosenthal, Abrams). Central to von Kries’ notion
of probability is the spielraum8 concept denoting the range of initial conditions that
lead to a certain result. In principle, probability is determined by the ratio of the
measure of the spielraum leading to a speciﬁc outcome to the measure of the entire
spielraum. Based on this idea, von Kries formulates three conditions for numerical
probabilities: (i) the different possibilities must correspond to comparable
(‘vergleichbar’) spielräume9. In particular, it should be feasible to establish the
equality in terms of measure of the various spielräume leading to different outcomes.
6depending on whether the various epistemic elements discussed in Sect. 9.6 are present. Certainly,
causation has to be interpreted objectively as well.
7For a recent discussion consult the edited volume by Rosenthal and Seck (2016). In an interesting
contribution, Helmut Pulte (2016) elaborates von Kries’ conceptions of natural laws and nomolog-
ical knowledge as a conceptual background for his approach to probability and examines to what
extent these are rooted in the historical context of his time.
8Spielraum translates to ‘range of possibilities’.
9I am using the German plural Spielräume.
244
9
Causal Probability

(ii) Furthermore, the spielräume should be original (‘ursprünglich’), i.e. the equality
of the spielräume must not cease to be the decisive criterion for our expectations
when tracing the further history of the conditions making up the spielräume. (iii)
Third, von Kries requires that the spielräume be indifferent (‘indifferent’), i.e. only
the size of the spielräume and no other logical conditions should be relevant for the
probability. According to von Kries, the most important criterion in this respect is
that a small change in conditions may already lead to a different outcome. The
various outcomes are supposed to alternate rapidly when continuously changing the
conditions.
It is mainly this last criterion that establishes the parallel with the method of
arbitrary functions, a term coined by Henri Poincaré (1912, p. 148). The French
mathematician is usually seen as the originator of this tradition, although many ideas
are already present in the mentioned work by von Kries (1886; later proponents are
von Smoluchowski 1918, Hopf 1936; for a philosophical-historical overview, see
von Plato 1983). In general, proponents of the method of arbitrary functions aim to
establish objective probability for deterministic phenomena. Building on physical
instability, they argue that any sufﬁciently regular distribution over the initial
conditions leads to roughly the same ratio of occurrences in macroscopic outcomes.
Primary applications are games of chance like roulette, which already Poincaré
discussed in much detail, or the throwing of dice and coins.
Von Kries’ account can broadly be classiﬁed as causal probability because the
two criteria outlined in the introduction are present in his theory as well. First, his
treatise on probability contains one of the most insightful assessments of the
principle of insufﬁcient reason in the history of probability (1886, Ch. 2). Second,
he deﬁnes probability not in terms of frequencies of events but in terms of the ratio
between different spielräume, i.e. conditions.
The outlined accounts are meant to be exemplary, a deeper look into nineteenth-
century discussions on probability would presumably reveal that similar causal
viewpoints were widespread.10 In the ﬁrst half of the twentieth century, the ideas
of von Kries were picked up and developed into an objective interpretation of
probability by Friedrich Waismann (1930/1931), who claims in turn to have been
inﬂuenced by Wittgenstein.11 These accounts are somewhat similar to independent
suggestions elaborated in recent years by Michael Strevens, Jacob Rosenthal, and
Marshall Abrams, to which we will turn now.
10In fact, already Jacob Bernoulli in his Ars conjectandi interpreted equipossibility in a causal
manner: “All cases are equally possible, that is to say, each can come about as easily as any other”
(1713, 219; cited in Hacking 1971, 344).
11For a historical overview, see Heidelberger (2001).
9.2
Predecessors and Contemporary Debate
245

9.2.2
Contemporary Debate: Abrams, Rosenthal, Strevens
Apparently, the history of causal interpretations of probability before the twentieth
century is quite rich and it seems plausible that the demise of this perspective more or
less parallels the rise of causal skepticism in the beginning of the twentieth century.
At the same time, the distinction between frequentist evidence for objective proba-
bilities and evidence in terms of causal symmetries largely disappears from the
debate leading to a purely frequentist view of objective probabilities. Furthermore,
only the epistemic version of the principle of indifference remains as a centerpiece of
the logical interpretation, while the objective reading is largely abandoned. A
notable exception in the latter respect are the writings of John Maynard Keynes
who clearly recognizes a difference between ascribing equal probabilities on the
basis of no evidence as opposed to evidence in terms of frequencies or relevant
circumstances. He believes that the distinction is gradual and introduces the notion
of weight of argument to account for it (1921, Ch. VI). But the idea has not caught on
in twentieth-century literature on probability.12
In recent years, one can observe a revival of objective interpretations that go
beyond the frequency account by making explicit reference to initial conditions as
well as system dynamics and thus bear resemblance to the historical accounts
depicted in the previous section. This type of objective interpretations, which has
been more or less independently developed by Marshall Abrams, Jacob Rosenthal,
and Michael Strevens, substantially relies on ideas from the method of arbitrary
functions.13
The best-known account in this modern tradition is Michael Strevens’
microconstant probability (2011; see also 1998, 2006, 2013). In part, his approach
is inspired by Maxwell’s derivation of the molecular velocity distribution in an ideal
gas which was carried out without empirical data about those velocities, i.e. without
frequency data. Strevens elaborates in much detail the distinction between an
objective and an epistemic reading of the principle of indifference (2013, Ch. 3).
In his recent book ‘Tychomancy’, he lays out the most important principles for
applying the objective version, which he terms equidynamics, by analyzing exem-
plary processes such as stirring or shaking (Ch. 5–8).
In one recent article, Strevens deﬁnes microconstant probability as an objective
physical probability for deterministic systems along the lines of the method of
arbitrary functions: “The event of a system S’s producing an outcome of type e
has a microconstant probability equal to p if (1.) the dynamics of S is microconstant
with respect to e, and has strike ratio p, (2.) the actual initial conditions of nearly all
12As Keynes himself stated, he was inﬂuenced by von Kries in framing the notion of weight of
argument (cp. Fioretti 1998).
13One should also mention the work of Richard Johns, who proposed a causal account of chance:
“the chance of an event is the degree to which it is determined by its cause” (2002, 4). Moreover,
propensity accounts are related to the causal approach, as already pointed out in the introduction and
discussed further in Sect. 9.3.3.
246
9
Causal Probability

long series of trials on systems of the same type as S make up macroperiodically
distributed sets, and (3.) the macroperiodicity of the initial conditions is robust.”
(2011, 359)
Apparently, the crucial notions are microconstancy and macroperiodicity. The
former refers to the premise that “within any small but not too small neighborhood,
the proportion of initial conditions producing a given outcome is [approximately] the
same” (2013, 11). This proportion is called strike ratio and it essentially determines
the probability modulo substantial problems concerning the limiting process to
inﬁnitesimal neighborhoods and thus to exact probability values. Macroperiodicity
denotes a certain smoothness in the probability distribution over initial conditions,
such that neighboring initial conditions leading to different results should occur with
approximately the same frequency in long series of trials.14 This uniformity together
with microconstancy leads to stable strike ratios and thus probabilities that are
largely independent of the exact probability distribution over initial conditions.
Finally, robustness in Strevens’ third premise refers to counterfactual robustness,
i.e. that counterfactual and predictive statements about frequencies are sufﬁciently
reliable. Typical applications for microconstant probability are games of chance like
roulette or playing dice, but Strevens believes that the notion also covers scientiﬁc
applications from statistical physics15 to the theory of evolution. Obviously,
Strevens’ approach features both characteristics of causal probability mentioned in
the introduction.
A further prominent account in the tradition of the method of arbitrary functions
is Marshall Abrams’ far-ﬂung frequency (FFF) mechanistic probability (2012). His
approach, although independently developed, bears close resemblance to the
accounts of both Strevens and Rosenthal. In particular, he relies on the same
concepts of microconstancy and macroperiodicity as coined by Strevens. Abrams
introduces the idea of a causal map device, which maps the input space to the
outcome space, and partitions the outcome space into basic outcomes. A bubble is
deﬁned as a region in the input space containing points leading to all possible
outcomes. A partition of the entire input space into bubbles he calls a bubble
partition. Probability then is determined in the following manner: “There is a bubble
partition of the [causal map] device’s input space, such that many ‘far ﬂung’ large
natural collections of inputs together determine an input measure which makes most
of the collections macroperiodic (and such that moderately signiﬁcant changes in the
spatiotemporal range across which natural collections are deﬁned don’t signiﬁcantly
affect outcome probabilities).” (Sec. 6) For lack of space, I won’t go into details what
exactly Abrams understands by “‘far ﬂung’ large natural collections of inputs”, but
essentially they fulﬁll two conditions: they are microconstant and they reﬂect actual
input patterns in the world (Sec. 4.2). Abrams emphasizes that he intends an
14In ‘Tychomancy’, Strevens replaces the term by the “in essence identical” (2013, 58) notion of
microequiprobability that the probability density is approximately uniform over any small contig-
uous interval or region in the initial state space (2013, 246).
15For a related discussion, cf. Myrvold 2011; see also Glynn 2010.
9.2
Predecessors and Contemporary Debate
247

objective probability interpretation that can account for a wide range of applications
in games of chance, statistical mechanics and perhaps also the social and biological
sciences (Sec. 6).
Finally, Rosenthal presents a very clear and thoroughly argued account of an
objective probability interpretation largely construed around the notion of arbitrary
functions, which he terms natural range conception in reminiscence of von Kries’
spielraum-concept. He formulates two equivalent versions, one in terms of an
integral over those initial states that lead to a desired outcome and the other referring
to the ratio of ranges in the initial state space. I will focus on the second explication,
which Rosenthal frames as follows: “Let E be a random experiment and A a possible
outcome of it. Let S be the initial-state space attached to E, and SA be the set of those
initial states leading to A. We assume that S and SA are measurable subsets of the n-
dimensional real vector space Rn (for some n). Let μ be the standard (Lebesgue-)
measure. If there is a number p such that for each not-too-small n-dimensional
(equilateral) interval I in S, we have
μ I \ SA
ð
Þ
μ Ið Þ
 p
then there is an objective probability of A upon a trial of E, and its value is p.”
(2012, 224)
Thus, Rosenthal explicitly frames his account as an objective probability inter-
pretation for deterministic systems (2010, Sec. 5.3). In summary, the idea is that the
probability of an outcome is proportional to that fraction of the initial-state space
leading to the outcome, as determined by the Lebesgue measure. Since Rosenthal
aims to develop an account for deterministic chance, i.e. he wants to eliminate
epistemic aspects as far as possible, he has to require that in the initial-state space
the conditions leading to the different outcomes are everywhere equally distributed,
at least when looking with sufﬁcient coarse-graining. This implies that any sufﬁ-
ciently smooth density function over the initial-state space will lead to approxi-
mately the same probability, which establishes the connection to the approach of
arbitrary functions and the close relatedness with Strevens’ microconstant probabil-
ity relying on the notions of microconstancy and macroperiodicity. Of the three
accounts discussed in this section, Rosenthal’s deﬁnition remains closest to the
original ideas of von Kries’ spielraum conception by referring explicitly to a speciﬁc
measure over the initial space. Without this element, the method of arbitrary
functions could also be understood in terms of a frequentist approach with respect
to the occurrence of initial states.
Rosenthal discusses a central objection against his own approach which comes in
two slightly differing versions (2012, Sec. 4; 2010, Sec. 5.5). First, an eccentric
distribution over initial states might be realized in nature leading to observed
frequencies deviating substantially from p. Rosenthal suggests that at least in some
such cases a nomological factor has been overlooked that determines the eccentric
distribution. According to the second variant of the objection, there usually exist
248
9
Causal Probability

various ways in which the initial-state space could be reformulated such that it loses
the characteristics required for Rosenthal’s deﬁnition of probability. In particular, the
Lebesgue measure might cease to be an appropriate choice to account for observed
frequencies. Thus, one has to motivate why a certain formulation of initial conditions
suitable for the natural-range conception is superior to others that are not suitable.
Rosenthal essentially acknowledges that these are open problems for his approach.
Note that they are equally troublesome for Strevens’ and Abrams’ account since
the concepts of microconstancy and macroperiodicity already presuppose a choice of
measure. As a solution, Strevens suggests to always use standard variables, mea-
sured in standard ways. Because these tend to be macroperiodically distributed,
microconstancy with respect to standard variables is meaningful. While Strevens’
account is quite sophisticated in this respect (2006, Sec. 2.5; 2013, Ch. 12), I believe
that the rejoinder eventually fails due to the blurriness and context-dependence of the
notion of standard variable. After all, most phenomena can be accounted for in a
large number of ways and it is just not plausible that all formulations will always
yield microconstancy and macroperiodicity to the same extent.
A related problem concerns the various imprecisions and approximations ﬁguring
in the deﬁnition of probability of all three accounts. For example, Rosenthal’s
deﬁnition refers to “not-too-small” intervals and that the ratio of ranges only
approximately determines the probability “p”. In fact, the strike ratio will in
general slightly ﬂuctuate between different regions of the initial-state space. Thus,
all theorems concerning microconstancy and macroperiodicity also hold only
approximately. Especially, when aiming at a purely objective interpretation, these
features are troublesome.16 In Sect. 9.3.2, I suggest how the outlined technical
problems can be avoided by rendering probability measure-dependent.
Due to the close similarity of the accounts developed by Strevens, Rosenthal, and
Abrams, I will in the following refer to them as the SRA-approach to objective
probability.
9.2.3
Some Praise
The causal approach referring to initial or boundary conditions can resolve a number
of problems for traditional accounts of probability. These issues are discussed
extensively by the authors mentioned in the previous section, so I will not delve
into details. Let me just brieﬂy comment on a few points.
According to Strevens, the “fundamental ﬂaw” of the frequency account is that it
cannot distinguish between meaningful and arbitrary frequencies and thus cannot
reliably ground counterfactual statements and predictions in probabilities (2011,
Sec. 2). The issue largely parallels the standard problem of induction. In reply, the
16In personal communication, Michael Strevens has suggested as a response to consider
microconstant probability as objective, but slightly indeterminate.
9.2
Predecessors and Contemporary Debate
249

causal account offers as a criterion that frequencies are only meaningful, when they
result from a collective determined by causal conditions. Of course, this solution can
only get off the ground given a defensible notion of causation, a topic that has been
extensively discussed in previous chapters and will be brieﬂy summarized in
Sect. 9.3.
A further major advantage in comparison with frequency theories is that causal
interpretations can establish probability independently of observed frequencies, for
example by referring to symmetries or by rendering probabilistic phenomena largely
independent of the probability distribution over initial states. Among other things,
this allows for a non-circular reading of the law of large numbers if probabilities are
not themselves deﬁned in terms of limiting frequencies (e.g. Abrams 2012, Sec. 1.1;
Rosenthal 2010, Sec. 5.2).
By relying on some version of the principle of indifference, causal probabilities
bear resemblance to logical interpretations of probability. However, the principle of
insufﬁcient reason referring to ignorance, as it is used in the logical approach, is
notoriously ﬂawed by challenging objections—in particular Bertrand’s paradox,
which highlights ambiguities in the application of this principle (Bertrand 1889;
van Fraassen 1990, Ch. 12). The causal approach resolves these ambiguities by
introducing an objective variant of the principle of indifference, later referred to as
principle of causal symmetry in the speciﬁc account of causal probability to be
developed in Sects. 9.3, 9.4, 9.5, and 9.6 (cp. esp. Sect. 9.4.3).
9.2.4
Critical Reﬂections
While clearly being a major step in the right direction, the recent attempts to develop
an objective account of probability in the tradition of the method of arbitrary
functions suffer from a number of shortcomings. There are the technical objections
already pointed out towards the end of Sect. 9.2.2. In addition, there are three more
general issues, which I will delineate in the following.
First, the SRA-approach tries to establish that probabilities are largely indepen-
dent of the measure over the input space. But this does not eliminate the need to
interpret the measure in a way that does not refer to relative frequencies which would
lead us back to essentially a frequency interpretation. To solve this problem, I argue
in Sect. 9.5.2 that the measure can be interpreted in terms of symmetries in the
circumstances determining a probabilistic phenomenon.
Second, the objective accounts of the SRA-approach mostly fail to clarify the
relation to epistemic probabilities and therefore implicitly subscribe to an in my view
misguided sharp distinction between ontic and epistemic probabilities. Instead, I will
pin down in Sect. 9.6 several epistemic features that can but need not be present in
the assignment of probabilities. I will sketch how the various shades of epistemic and
ontic probabilities can all be accounted for in terms of a single causal interpretation.
Thus, the range of application is widely extended beyond cases in which the method
of arbitrary functions can be employed.
250
9
Causal Probability

Third, the mentioned accounts all rely on physical or causal laws determining the
dynamics of the considered phenomena largely without explaining the origin of
these laws. In the worst case, they need to be established inductively leading us back
to the problem of distinguishing between meaningful and arbitrary relations, which
the SRA-approach aimed to resolve in the ﬁrst place. Thus, a major task for any
approach to probability is to clarify how it ﬁts into a more general framework of
induction and causation. This will be attempted in the following.
9.3
Induction, Causation, and Probability
In the previous section, a shortcoming of the SRA-approach was identiﬁed that the
probabilities rely on physical knowledge in terms of dynamics and laws of motion
but fail to make a connection with a speciﬁc account of induction and a
corresponding notion of causation. In the following, I try to ameliorate the situation
by comparing two distinct accounts of induction, namely enumerative and varia-
tional, and by examining how in each case a notion of probability could be integrated
(see Chap. 4). Enumerative induction leads to a naïve frequency account of proba-
bility that must be rejected in particular for failing to draw a distinction between
accidental and lawlike regularities. By contrast, variational induction offers a solu-
tion to this problem in terms of a difference making account of causation, while of
course some amount of uncertainty remains for any inductive inference. Trying to
implement probability in variational induction will lead to an account of causal
probability that resembles those presented in Sects. 9.2.1 and 9.2.2. From now on,
the terms ‘causal interpretation of probability’ and ‘causal probability’ more nar-
rowly refer to the speciﬁc account to be developed in the remainder of this chapter.
According to the proposed viewpoint, probabilities are understood as degrees or
grades of causal determination by a given set of circumstances or conditions. It
should be added that such determination may be considered both in the direction
from causes to effects and from effects to causes (for the latter cp. in particular Sect.
9.6.4).17,18
17One referee has suggested that the proposed notion of probability should be interpreted as an
abstract framework into which every causal interpretation of probability has to ﬁt. In principle, I am
happy with such a pluralistic reading in terms of a class of interpretations rather than a single one. In
particular, there certainly is some room for allowing different understandings of causality.
18Marshall Abrams, in an interesting recent paper (2015), formulates a notion of causal probability
that is strictly speaking neither an interpretation nor a class of interpretations. Rather, he considers
the causal nature an additional feature of some interpretations of probability including long run
propensities and his own ‘mechanistic probability’ (2012). Broadly speaking, Abrams terms
probabilities causal when a change in properties of a chance set-up affects the relative frequencies
of outcomes. For a more exact deﬁnition, he employs Woodward’s interventionist framework.
While Abram’s approach is certainly related, the proposal in the present paper ascribes a much more
central role to causality extending to a number of fundamental concepts in probability theory like
probabilistic independence or the principle of indifference. Causal probability therefore should be
9.3
Induction, Causation, and Probability
251

9.3.1
Enumerative Induction and the Frequency Theory
Enumerative induction is the rather naïve view that general laws can be deduced
from the observation of mere regularities: If in all observations, one ﬁnds two events,
objects, properties, etc. A and B always conjoined then there supposedly exists a
causal connection between A and B. This basic idea is shared by all naïve regularity
conceptions of natural laws and causation.
The generalization to statistical laws is straight-forward although some technical
complications arise due to possible ﬂuctuations in the observed frequencies. Basi-
cally, if in a sequence of events of type A one ﬁnds a more or less constant ratio p for
another type of event B, then one can conclude to a statistical law connecting A and
B with probability p. For example, if a coin lands heads in approximately one half of
all trials, then the probability of this event probably is somewhere close to one half.
Serious problems arise because the true value of the probability is usually identiﬁed
with the limiting frequency in an inﬁnite number of trials. The naïve frequency view
thus grants epistemic access only to observed frequencies but not to the underlying
probabilities themselves. Therefore, it exhibits considerable difﬁculties dealing with
cases, where the frequencies by pure coincidence deviate (substantially) from the
actual probabilities.
However, at this point we can neglect the problems arising in this regard since the
naïve frequency view falls prey to a much more fundamental ﬂaw, the same as the
naïve regularity conception of laws and causation: it cannot distinguish between
accidental and lawlike statistical relationships, i.e. between those that can ground
predictions and successful manipulations and those that cannot (cp. Strevens 2011,
Sec. 2; as already discussed in Sect. 9.2.3). For example, the naïve frequency view
cannot handle the following situation of an exchanged coin. Consider a sequence of
throws, during which the coin is exchanged at some point with another one looking
very much alike. Presumably, the naïve frequentist would have to derive predictions
about future events from the whole sequence. He cannot make the crucial distinction
between the case, where both coins are structurally similar, and the case, where the
coins are structurally distinct, e.g. one fair the other loaded. As we will see shortly,
such distinctions can be systematically established only within the context of
variational induction. In other words, the naïve frequency view leads to an essen-
tially unresolvable reference class problem since it lacks clear rules how to determine
structural similarity.
In comparison, the causal interpretation elaborated in this essay accepts that any
single event can be attributed to different collectives, which in general imply
different probabilities for the event. In other words, there is an ambiguity in the
choice of reference class, which however is not fatal to the causal interpretation,
since causal probability is deﬁned with respect to a collective. This dissolves what
understood as a speciﬁc interpretation of probability in its own right (or at least a class of
interpretations determined by different accounts of causation) that is conceptually incompatible
with other interpretations. For a discussion of those differences, see in particular Sect. 9.3.3.
252
9
Causal Probability

Alan Hájek has termed the metaphysical reference class problem (2007). Note that
an epistemic agent acting on the basis of probabilities should use the collective that is
as speciﬁc as possible in terms of causally relevant conditions under the additional
constraint that the agent has epistemic access to some evidence for the corresponding
probabilities in terms of symmetries or relative frequencies. By contrast, the fatal
reference class problem for the naïve frequentist is that he may construct an
ensemble of seemingly similar events, which are however structurally dissimilar,
and therefore the resulting frequencies are not predictive. This problem is avoided in
the causal approach because the collective conditions are by deﬁnition causally
relevant for the considered phenomenon and must remain constant during all trials,
while the range conditions are supposed to vary randomly.
9.3.2
Variational Induction and the Causal Conception
of Probability
Variational induction is distinguished from enumerative induction in that it examines
not the mere repetition of phenomena but rather phenomena under varying circum-
stances or conditions. Variational methods determine the causal relevance or irrel-
evance of conditions for a certain phenomenon. The main methods are the method of
difference and the strict method of agreement (cp. Sect. 6.1). The ﬁrst establishes
causal relevance of a condition C to a phenomenon P from the observation of two
instances which are alike in all conditions that are causally relevant to P except for
C. If in one instance both C and P are present and in the other both C and P are
absent, then C is causally relevant to P. The strict method of agreement establishes
causal irrelevance in much the same manner, except that the change in C has no
inﬂuence on P.19 According to this view of variational induction, causal (ir-)
relevance is a three-place notion: Condition C is causally (ir-)relevant to P with
respect to a background B consisting of further conditions that remain constant if
causally relevant to P or that are allowed to vary if causally irrelevant. For further
details, see Chap. 6 (see also Pietsch 2014).
The outlined approach to induction has a counterpart in an account of causation
that broadly stands in the counterfactual tradition and that was termed difference-
making account in Chap. 5.20 It is distinguished from conventional counterfactual
approaches, in particular that of David Lewis, by the following characteristics: a
notion of causal irrelevance is introduced; all causal relationships are rendered
background-dependent; and counterfactual propositions are not evaluated in terms
of possible worlds but on the basis of reﬁned versions of the method of difference
19Note that as a complication, judgments of causal irrelevance depend on measurement accuracy.
20In the following I can only provide a very brief sketch of the account. A basic outline can be found
in Pietsch (2015, Sec. 4.1), a detailed defense in Chap. 5 and Pietsch (2016).
9.3
Induction, Causation, and Probability
253

and the strict method of agreement and therefore by referring to instances in the
actual world.
The main ingredients of this difference-making account are (i) counterfactual
deﬁnitions of the fundamental notions of causal relevance and causal irrelevance: ‘in
a context B, in which a condition C and a phenomenon P occur, C is causally
relevant (irrelevant) to P, iff the following counterfactual holds: if C had not
occurred, P would also not have occurred (if C had not occurred, P would still
have occurred)’; (ii) obviously, these deﬁnitions implement background- or context-
dependence, an idea roughly taken from John Mackie’s work: in principle, a
background or context is deﬁned by conditions that must remain constant and others
that are allowed to vary; (iii) ﬁnally, an account of counterfactuals is employed that
takes its inspiration directly from the method of difference: ‘“If C were not the case,
P would not be the case” is true with respect to an instance in which both C and P
occur in a context B, if ﬁrst, at least one instance is realized in which neither C nor P
occurs in the same context B and second, if B guarantees homogeneity.’ The latter is
the case, iff only conditions that are causally irrelevant to P can change, except for C
itself and conditions that are causally relevant to P in virtue of C being causally
relevant to P, i.e. in particular conditions that lie on a causal chain through C to P. Let
me emphasize again that the deﬁnitions of causal relevance and irrelevance corre-
spond directly to the method of difference and the strict method of agreement,
respectively.
How does probability ﬁt into this picture of induction and causation? Note ﬁrst
that both principal methods of variational induction and the corresponding deﬁni-
tions of causal relevance and irrelevance presuppose determinism, i.e. that P is fully
determined by causal conditions (cp. Sect. 6.2; see also Pietsch 2014, Sec. 3f).
Consequently, we will in the following delineate an essentially epistemic probability
conception for deterministic phenomena, while indeterministic probabilities can be
integrated later on, as discussed in Sects. 9.6.1 and 9.6.2.
Let me begin with a simple example to outline the basic idea of the proposed
causal interpretation of probability. Consider a wheel of fortune with four different
areas of equal size, which are labeled, say, as green, blue, red, and yellow. Let a
blindfolded person determine the moment, when to stop the wheel. Apparently,
certain conditions remain constant in different instances or trials of this set-up, for
example the mentioned distribution of labels on the wheel, maybe also the velocity
with which the wheel is turning etc. These constant conditions in probabilistic
phenomena shall be called collective conditions. A number of other conditions
may change from trial to trial, in particular the moment and the position at which
the wheel starts turning and the moment when the blindfolded person stops the
wheel. Let these conditions be called range conditions. Obviously, collective and
range conditions taken together causally ﬁx the speciﬁc event that will happen.
254
9
Causal Probability

The range conditions span an outcome space21 and each point in this space is
labeled in terms of the resulting attribute, which in the discussed example is the color
at which the wheel stops. In the next step, one is interested in the distribution of
attributes in the outcome space. According to the proposed interpretation, this issue
is tackled using symmetry arguments, e.g. by examining the dynamics of the
probabilistic phenomenon. And indeed it turns out that the considered causal
structure is invariant under permutation of the different colors, which implies that
all colors appear in the outcome space to the same extent, i.e. they all have equal
measure. Note that at this point the measure does not yet have to be a probability
measure, e.g. it can follow from a regular dynamics, but it has to be characteristic of
the extent in which the various attributes are realized, in order to eventually establish
the connection with frequencies. In the example, we know that the color sequence of
the rotating wheel of fortune follows a perfectly regular pattern with each color
appearing an equal amount of time.
Thus, an additional argument is needed to establish the measure as a probability
measure. In particular, it has to be shown that different trials are independent of each
other. Generally, this can be guaranteed based on causal irrelevance. Roughly, since
the person stopping the wheel is blindfolded and the wheel is turning at considerable
speed, we know on the basis of fairly simple scientiﬁc laws that the rotational state of
the wheel is causally unrelated with the moment when the blindfolded person stops
the wheel. Given that the measure designates how often an attribute is realized and
that in addition independence of trials can be established by means of arguments
from causal irrelevance, the ratios of the various attributes in the outcome space
weighted by the measure can be interpreted as probabilities. Also, since the main
premises for the law of large numbers are fulﬁlled, a link to relative frequencies can
be established.
Let me now introduce the formal framework. In developing a probability concept
for variational induction, the focus must lie on the variation of conditions, which
constitutes the crucial change in perspective compared with enumerative induction
which focuses on the number of instances (cp. Federica Russo’s variational episte-
mology for causation, e.g. Illari and Russo 2014, Ch. 16). In particular, a careful
distinction between various types of circumstances or conditions needs to be
introduced.
We are interested in the impact of a number of potentially relevant conditions C1,
. . ., CM on a statistical22 phenomenon P with respect to a background B. Since P is
statistical, it must be linked to a space O of possible outcome states, which may be
continuous and many-dimensional, but will for the sake of simplicity from now on
be assumed as discrete and one-dimensional. No additional conceptual difﬁculties
21More generally, the range conditions span an input space, which may be identical with the
outcome space, with respect to which the attributes are introduced (see further below).
22‚Statistical phenomenon‘ here is not identical with ‚probabilistic phenomenon‘ as deﬁned below,
but is more broadly understood as a phenomenon that is not fully determined by the considered
circumstances or conditions.
9.3
Induction, Causation, and Probability
255

arise in the former case. The outcome space is divided into mutually exclusive
regions covering the whole space. These regions are labeled and the labels are called
attributes M1, . . ., MN.23 Note that the labels are introduced in addition to the
parameters spanning the outcome space for reasons that will become clear later on
when the notion of causal symmetry is deﬁned.
Let me now introduce various types of conditions, in particular the distinction
between collective24 conditions and range25 conditions. Both types are causally
relevant (in the sense of difference-making) to P. When examining a particular
probabilistic phenomenon, the collective conditions must remain constant, while
the range conditions are allowed to vary. The collective conditions ﬁx the occurrence
of the class P but do not determine which of the attributes M1, . . ., MN will actually
happen, i.e. these conditions determine the probability space regarding the various
manifestations of the phenomenon P. Note that the collective conditions include all
causally relevant conditions in the background or context B. Collective and range
conditions together causally ﬁx the exact outcome state and thereby also which event
MX of the M1, . . ., MN will actually happen in a speciﬁc instance or trial. Further-
more, a measure W needs to be introduced denoting the probability with which
certain combinations of range conditions appear and thus the probability of
the corresponding outcome states. In principle, this measure is determined by the
collective conditions as further discussed in Sect. 9.4. It is normalized over the whole
outcome space and should, via the various laws of large numbers, correspond to the
limiting frequencies with which the outcome states of a speciﬁc probabilistic phe-
nomenon will be instantiated.
The exact interpretation of this measure constitutes a crucial challenge for the
causal account mainly for two reasons: (i) there is an immediate threat of conceptual
circularity if the measure is itself explicated in probabilistic terms; (ii) in particular, if
the measure is interpreted in terms of relative frequencies we are thrown back on a
frequentist interpretation of probability. The suggested solution in the framework of
the causal approach is to establish the measure quantitatively on the basis of causal
symmetries in the collective conditions and to identify it as a probability measure
that corresponds to limiting frequencies by arguments based on causal irrelevance. In
other words, the measure is interpreted in terms of causal symmetries and causal
irrelevance (cf. Sect. 9.5.2).26
Sometimes, when it is possible to clearly specify the process determining the
measure, it may make sense to distinguish between two types of collective condi-
tions: set-up conditions determining the possible combinations of range conditions;
and measure conditions, which ﬁx the measure over the space spanned by the range
23In reverence to von Mises who used the German term ‘merkmal’ that translates to feature,
attribute, characteristic.
24Again, we rely on the terminology of von Mises.
25The terminology here is of course in reverence to von Kries.
26Like the frequentist interpretation this constitutes an operationalist approach, only on the basis of
symmetries rather than relative frequencies.
256
9
Causal Probability

conditions and thus the probabilities of the outcomes.27 Note that in the exceptional
case of indeterministic phenomena, there are no range conditions that vary. The
measure therefore becomes dispensable, and the probabilities directly result from the
system’s indeterministic dynamics.28
This leads to the notions of a probabilistic phenomenon and of causal probability
(deﬁnition 1):
A ‘probabilistic phenomenon P’ is determined by collective conditions C that remain
constant; range conditions R that are allowed to vary and that span an outcome space O;
as well as a probability measure W over the outcome space. The causal probability of a
speciﬁc attribute MX, combining a set of possible outcomes of the phenomenon P, is given by
the fraction of outcome states pertaining to attribute MX, weighted29 with the measure W. 30
As already said, the measure is in principle determined by causal symmetries in
the collective conditions (cf. Sect. 9.4) and the nature as a probability measure (i.e. a
measure that corresponds to the actual limiting frequencies) must be established in
terms of causal irrelevance (Sect. 9.5). In summary, probabilities according to the
proposed view denote degrees of causal determination of the attributes by the
collective conditions.
In some situations, it may be useful to add more structure to the probabilistic
phenomenon by introducing an input space of possible input states S1, . . ., SQ, which
is now spanned by the range conditions, as well as a causal mapping S !
C O. Again,
we assumed a discrete, one-dimensional input space for the sake of simplicity, a
generalization would add no further difﬁculties. Most importantly, this extra struc-
ture of the probabilistic phenomenon allows to better show the connection with the
method of arbitrary functions and the SRA framework (deﬁnition 2):
A ‘probabilistic phenomenon P’ is determined by collective conditions C, range conditions
R spanning the input space S, a probability measure W over the input space and a causal
mapping S !
C O of the input space on the outcome space O. The causal probability of a
speciﬁc attribute MX, combining a set of possible outcomes of the phenomenon P, is given by
the fraction of input states leading to attribute MX, weighted with the measure W.
The ﬁrst deﬁnition can be seen as a special case of the second, if input and
outcome space are identical. From another perspective, the ﬁrst deﬁnition can be
seen as more general, since it makes no additional assumptions about system
dynamics.
According to both deﬁnitions, probability is always relative to collective condi-
tions—which is very much in the spirit of von Mises’ famous statement “ﬁrst the
27There is often a normative component to the measure and thus also to the collective conditions,
since it is partly a matter of choice which events to include in a collective and which not.
28We will return to this topic in Section 6a.
29Henceforth, I will speak of the ‘weighted fraction of outcome states’.
30I claim that this is the notion of probability that many of the classical thinkers mentioned in
Section 2a had in mind. Strevens (2006) makes a similar suggestion, but sees it as a special kind of
probability, namely ‘complex probability’, in contrast with ‘simple probabilities’ that appear in or
depend on fundamental laws of nature.
9.3
Induction, Causation, and Probability
257

collective—then the probability” (1981, 18).31 Sometimes, when the range condi-
tions and the measure over those conditions are not explicitly known, one may
express a probabilistic phenomenon in terms of the attribute space, but a constant
collective is nevertheless always required. Note ﬁnally that the basic axioms of
probability will be satisﬁed since the deﬁnitions are based on fractions referring to a
normalized measure.
Let me brieﬂy elaborate on the issue, why the presented approach merits to be
called ‘causal’. Most importantly, the collective conditions causally determine the
probabilistic phenomenon P, and collective32 and range conditions taken together
causally determine a speciﬁc manifestation of P. While sophisticated frequency
accounts like von Mises’ approach also require a collective, they do not consider it
ﬁxed strictly by causal conditions, but presumably other types of conditions may
also appear, e.g. these accounts lack the important distinction between causal vari-
ables and proxy variables as discussed in Sect. 9.6.3. Note that this constitutes the
decisive step with respect to frequency accounts to solve the problem of properly
distinguishing between arbitrary and meaningful frequencies.
In the following sections, I will introduce several further concepts that are central
to the causal interpretation. The notion of causal symmetry, referring to invariance of
causal structure with respect to attribute permutations, and the related principle of
causal symmetry, as explicated in Sect. 9.4, allow establishing the measure to an
extent that the probability distribution of the attributes can be ﬁxed without relying
on relative frequencies as evidence. In Sect. 9.5, a causal construal of the notion of
independence will be provided ensuring that sequences of outcome states will be
random. Without independence (or related concepts like exchangeability), one could
hardly speak of a probabilistic phenomenon, since many theorems of probability
theory like the various laws of large numbers justifying the convergence of relative
frequencies to the actual probabilities rely on independence of subsequent events.
The notions of causal symmetry and the causal construal of independence further
underline the causal nature of the proposed account of probability. The deﬁnition of
probability given above, the principle of causal symmetry, and a causal construal of
the notion of independence should be seen as one package making up causal
probability. The connection with variational induction can be understood in terms
of a coarse-grained formulation. Instead of examining particular instances, where
speciﬁc R and O are realized, statistical phenomena P as a whole can be consid-
ered—determined by certain collective conditions and an attribute distribution,
e.g. an ideal gas in a box or a long sequence of throws with a die. The causal
relations how changes in collective conditions affect the respective statistical phe-
nomena within this macro-perspective can again be established by the method of
difference and the strict method of agreement. Predictions and counterfactual state-
ments can thus be derived.
31“we shall not speak of probability until a collective has been deﬁned” (ibid.)
32more exactly, the set-up conditions, if these can be distinguished from the measure conditions
258
9
Causal Probability

Let me illustrate the proposed notion of probability with another simple example
regarding the throw of a coin (P). The attributes partitioning the outcome space are
heads-up (M1) or tails-up (M2). The collective conditions are the causal conditions of
the set-up, e.g. concerning the type of coin, the allowed types of throwing, the types
of surface on which the coin lands, etc. These conditions are held ﬁx in all instances
of the phenomenon. The range conditions are also causally relevant to the outcome
but randomly vary from throw to throw: including the exact initial state of the coin
before the throw, the initial speed, direction, and torque of the throw, etc. Assuming
determinism, the attribute is ﬁxed by the range conditions. Finally, the measure W
denotes the probability, with which the various range conditions occur. In principle,
W is ﬁxed by causal symmetries in the collective conditions. In particular, the
dynamics of the throw as well as the process determining the initial state of the
coin might both be invariant with respect to exchanging the labels on the coin. It
should be added that it generally sufﬁces that the instructions how to throw the coin
determine the measure over range conditions to an extent that the attribute distribu-
tion is fairly stable. In other words, the measure is seldom ﬁxed to full extent. This is
the lesson learned from the method of arbitrary functions. Note ﬁnally that the range
conditions can usually be formulated in different ways for a probabilistic phenom-
enon, which requires a complementary adjustment of the measure.
As long as the collective for the throws remains the same, including that the initial
states vary sufﬁciently, long-run frequencies will almost always closely approximate
the actual probabilities according to the mathematical theorem called the law of large
numbers. This solves the problem of the exchanged coin of Sect. 9.3.1. As long as
both coins are structurally similar, e.g. fair, the collective conditions stay the same
when the coin is exchanged, and therefore predictions based on combined frequen-
cies can be expected to hold. If one coin is fair and the other loaded, then the
instances do not form a collective, because a causally relevant condition has changed
and therefore predictions based on relative frequencies will in general fail to hold
(though there may be ways of formulating a combined collective, see Sect. 9.6.2).
Another classic application of probability concerns population statistics, e.g. the
question whether a certain person will die at a given age. Regarding this type of
problem Mill has claimed that probability lacks an objective meaning since for every
individual death is supposedly a matter of deterministic fact (cf. Sect. 9.2.1). With
respect to single-case probabilities in deterministic settings, this assessment is
certainly correct. However, there is a fairly objective meaning to probability if
relating it to a speciﬁc collective as required by the deﬁnition of causal probability
given above (regarding a discussion of various epistemic elements in causal prob-
abilities, cf. Sect. 9.6).
To determine the probability whether someone will die at a speciﬁc age we thus
ﬁrst have to ﬁx a collective specifying causally relevant circumstances, for example
the gender of a person, certain habits, e.g. whether he/she smokes, is active in sports,
or has pre-existing diseases. The collective conditions leave open the two possibil-
ities of interest that the person dies at a given age or not. Probabilities result from the
range conditions and a measure over the space spanned by the range conditions,
although these need not—and often cannot—be made explicit. While admittedly it is
9.3
Induction, Causation, and Probability
259

impossible to list all the relevant causal conditions for phenomena with a complex
causal structure like the death of a person, in principle the construction of a collective
according to the deﬁnition above is possible assuming determinism. And the fact that
insurance companies manage to arrive at fairly stable probability distributions
suggests that they have some epistemic access to appropriate collectives.
In combination, collective and range conditions causally determine whether a
person will die or not. Of course, the exact boundary between collective and range
conditions is usually quite arbitrary. In the case of population statistics, the collective
is mostly determined by choosing a certain group of the total population, for example
white male living in New York State. Since epistemic access to causal symmetries is
implausible for phenomena of such complexity, the required information about
range conditions and measure is derived from past frequency data—under the
assumption that this data is representative of the group and that the collective
conditions will approximately stay the same for the time period that is to be
predicted. Note again that the collective should generally be chosen in such a way
that it includes all conditions that are known to be causally relevant in a considered
instance, if one wants to act on the basis of the resulting probabilities. For example
when someone is known to have prostate cancer, this information should be included
in the collective conditions concerning an imminent death, if, of course, there is also
sufﬁcient frequency data available to determine the corresponding probabilities.
9.3.3
A Brief Comparison with Other Accounts
In the brief overview in Sect. 9.1.2, I had already pointed out the main differences
between the causal approach and the logical as well as the frequentist accounts. With
respect to the former, the causal approach relies on an ontic and not on an epistemic
version of the principle of indifference. With respect to the latter, the causal approach
deﬁnes probability in terms of the ratio of favorable boundary or initial conditions
and not in terms of relative frequencies of events.33
The account proposed in Sect. 9.3.2 is conceptually closest to the SRA-approach
and to the propensity theory. It is therefore worthwhile to brieﬂy address the most
important differences in each case. Without any loss of generality, I will rely on
deﬁnition 2 in the following discussion. With respect to the SRA-approach based on
the method of arbitrary functions, a crucial difference is that causal probability34 is
always relative to the collective conditions and thereby also to the measure over the
33One should also mention best-systems interpretations originating with Lewis (1994); Hoefer
(2007) is a more recent development in this tradition. These interpretations pursue a different aim
compared with causal interpretations by trying to situate probability within a framework of
Lewisian metaphysics. Let me further brieﬂy point to an interesting recent attempt to combine a
spielraum approach with a best-systems interpretation by Claus Beisbart (2016).
34Remember that the terms ‘causal interpretation’ and ‘causal probability’ now refer exclusively to
the account developed in Section 3b.
260
9
Causal Probability

input space while the SRA-approach tries to establish that probabilities are indepen-
dent of the choice of measure. Rendering probability relative to the measure resolves
in a simple manner the central objection against the natural-range conception that
was described towards the end of Sect. 9.2.2. Concerning the ﬁrst situation, i.e. the
problem of eccentric distributions over initial states, the causal perspective is the
following. If the collective conditions determine an eccentric distribution, the mea-
sure must reﬂect this distribution. By contrast, if an eccentric sequence of initial
states occurs by coincidence given a non-eccentric measure, then the eccentric
sequence must be attributed to chance.
The second situation, Rosenthal worries about, is that reformulations of the initial
conditions lead to a change in probabilities. Indeed according to his natural range
conception, which relies on the Lebesgue measure over the initial-state space,
reformulations could easily imply probabilities in contradiction with observed fre-
quencies. Rosenthal suggests excluding such “unphysical” descriptions, but it
remains completely unclear how to construe a suitable notion of unphysicality.
Rather, the various debates on conventionality in physics have shown that suppos-
edly unphysical descriptions are often feasible and empirically adequate. Further-
more, opinions about physicality habitually change over the course of history. This
difﬁculty is also resolved in a simple manner by the account of causal probability.
Essentially, any change in the formulation of the range conditions has to be com-
pensated by a complementary change in measure in order to stay consistent with the
collective conditions and the observed frequencies. Obviously, this option is not
available to Rosenthal since he insists on using the Lebesgue measure as probability
measure. Note again that the same difﬁculties which Rosenthal makes explicit are
hidden in the conditions of microconstancy and macroperiodicity in Strevens’ and
Abrams’ account which presuppose a measure. Strevens’ response in terms of
standard variables was already described in Sect. 9.2.2 and is largely equivalent to
Rosenthal’s proposal.
Furthermore, there is no need for approximations or imprecisions in the causal
account in contrast with Rosenthal’s deﬁnition of probability or the related deﬁni-
tions of microconstancy and macroperiodicity in Strevens’ and Abrams’ accounts
(cf. the end of Sect. 9.2.2). Rather, the probability according to the causal interpre-
tation corresponds exactly to the weighted fraction of outcome states. Again, this
move is possible since the causal account renders probability relative to the measure,
but also because the causal construal of independence ensures randomness in the
sequence of initial conditions and thus convergence of relative frequencies to the
causal probabilities by the law of large numbers.
The price to pay is that probability becomes relative to the essentially epistemic
choice of a collective (cf. Sect. 9.6), which thwarts the project of a purely objective
probability interpretation in deterministic settings. On the other hand, I don’t see
why accepting some epistemic aspects in probability is problematic except if one
adheres to an overly realist view of science. And again, this very step enables the
causal interpretation to cover a wide range of applications from indeterministic
probabilities to probabilities of hypotheses as described in Sect. 9.6—compared
9.3
Induction, Causation, and Probability
261

with the rather narrow range of applications of the SRA-approach requiring
microconstancy and macroperiodicity.
Of course, phenomena accessible to the method of arbitrary functions can be
treated within the causal approach as well. In such cases, the collective conditions35
and the measure need to be ﬁxed only to the extent that the probability distribution is
approximately stable. As an example, consider the throw of a die. The probability
distribution does not depend much on the exact instructions for the collective,
e.g. concerning the original position of the die, the way it is thrown etc. Generally
speaking, the exact choice of collective conditions and measure is largely irrelevant,
if the dynamics of the system is sufﬁciently complex—a topic that is discussed today
mainly in the domain of ergodic theory.
On a deeper level, the introduction of measure-dependence in the causal approach
calls for new concepts that are not central to the SRA-approach. First, the measure
over input states must be determinable independently of relative frequencies in the
causal approach—otherwise we would be thrown back on frequentism. To this
purpose, the principle of causal symmetry is introduced in the next Sect. 9.4. Second,
when the condition of microconstancy is dropped, it cannot be assumed anymore
that the occurrence of attributes will be sufﬁciently random due to slight variations in
initial conditions. Therefore, in the causal interpretation randomness has to be
established by other means leading to the causal construal of independence proposed
in Sect. 9.5. By referring to causal symmetries in the collective conditions and to
causal irrelevance establishing probabilistic independence, the causal interpretation
resolves a fundamental problem of the SRA-approach, namely how to interpret the
measure over input space (cp. Sect. 9.5.2).
The causal approach also owes considerably to various versions of the propensity
interpretation. Most importantly, they share the broad (and important) idea that
probabilities arise from circumstances or conditions. However, a direct comparison
is rendered somewhat difﬁcult by the enormous spectrum of propensity accounts in
the literature (a good recent overview can be found in Berkovitz 2015). In fact, the
various accounts differ so substantially that some scholars subsume under the notion
of propensity any objective approach that is not a frequency interpretation (Gillies
2000a, 114). The most fundamental distinction is between long-run and single-case
propensity theories: “A long-run propensity theory is one in which propensities are
associated with repeatable conditions, and are regarded as propensities to produce, in
a long series of repetitions of these conditions, frequencies which are approximately
equal to the probabilities. A single-case propensity theory is one in which propen-
sities are regarded as propensities to produce a particular result on a speciﬁc
occasion.” (Gillies 2000a, 126) One crucial problem of single-case propensity
interpretations, especially those in which probabilities depend on the whole state
of the universe at a given time (e.g. accounts by the later Popper or David Miller), is
to establish a connection between propensities and relative frequencies. On the other
hand, long-run propensity interpretations run the risk of collapsing into a frequency
35in particular the measure conditions, if these can be separated from the set-up conditions
262
9
Causal Probability

interpretation, since relative frequencies are invoked on a fundamental conceptual
level. By contrast, the proposed account of causal probability does not rely on
relative frequencies but on symmetries to establish probability distributions on a
fundamental level, while at the same time making a connection with relative
frequencies via the law of large numbers, if probabilistic independence can be
shown by arguments of causal irrelevance.
There are a number of crucial differences between propensity theories and the
proposed account. The ﬁrst point concerns ontology. If the proponents of propensi-
ties were thinking of causal determination, why not call it causation? Why use a
rather obscure term like propensity? Popper and other proponents of propensity
accounts seem to have felt the need to introduce a novel ontological category to
account for probabilistic phenomena. In later years, Popper considered causation to
be a special case of propensities, namely when the propensity equals one. As another
example, Donald Gillies claims that non-causal correlations for example between a
low barometer reading and subsequent rainfall also constitute propensities (2000b,
829–830). Other proponents of a propensity interpretation like D.H. Mellor reject the
view that chance is a sort of “weak or intermittently successful causal link”
maintaining that “causal talk is not really illuminating in statistical contexts” (Mellor
cited in Berkovitz 2015, 657). To resolve this confusing disagreement concerning
the relationship between causation and probability, the approach proposed in this
essay tries to situate probability within a speciﬁc framework of causation. While in
general propensity accounts focus conceptually on dispositions or tendencies and
rather casually remark upon the parallel with causation, the interpretation proposed
here starts with a detailed and speciﬁc concept of causation as difference making and
examines how probability ﬁts into the picture.
On a more methodological level, causal probability is relative not only to
collective conditions but—unlike propensities—also to the measure over the space
spanned by the range conditions. From this difference it can be understood why
propensities are intended mainly for indeterministic contexts, while causal probabil-
ity starts from a deterministic viewpoint. Relatedly, propensity approaches are often
silent on the question how exactly the circumstances determine the probabilities.
They typically lack the notion of causal symmetry, the ontic version of the principle
of indifference, and the causal construal of probabilistic independence. With respect
to the last issue, the randomness of subsequent events is often considered as implicit
in the notion of tendency in propensity accounts.
Finally, the fact that propensities are framed in a language of tendencies or
dispositions appears to explicitly exclude the formulation of inverse probabilities,
i.e. evidential probabilities or the probabilities of hypotheses (for an elaboration of
this criticism, cp. Humphreys 1985).36 How causal probabilities as proposed in this
essay can be inversed is brieﬂy indicated in Sect. 9.6.4. Furthermore, while
36Various responses from propensity theorists to this so-called Humphreys’ paradox can be found
in Berkovitz (2015, Sec. 5). Several scholars like Mauricio Suarez conclude that propensities cannot
be probabilities (2011).
9.3
Induction, Causation, and Probability
263

inﬂuential propensity theorists like Popper have argued that inductive concepts like
conﬁrmation are not explicable in terms of probabilities at all, the causal interpreta-
tion explicitly establishes the link with an inductive framework, namely variational
induction. Part of the project of a causal interpretation is to show how the basic idea
that probabilities arise from circumstances can be extended to epistemic probabilities
like the probabilities of hypotheses (cp. Sec. 9.6).
9.4
Causal Symmetries and the Principle of Causal
Symmetry
9.4.1
Causal Symmetries
I will now argue that given full knowledge of the causal setup, the measure over
different combinations of range conditions can always be determined by means of
symmetry considerations without taking recourse to relative frequencies. More
exactly, the symmetries must ﬁx the measure only to the extent that a stable
probability distribution results. Note also, that in this section the measure does not
yet have to be considered a probability measure, e.g. it can result from perfectly
regular dynamics. How the random nature of the attribute sequence can be
established in addition will then be discussed in the next section. That symmetries
and invariances play a crucial role in the determination of probabilities is of course
quite obvious, just think of games of chance or Maxwell’s derivation of the velocity
distribution in an ideal gas. Of course, for many phenomena the underlying sym-
metries may not be fully known, which then requires resorting to relative frequencies
as a weaker kind of evidence. Referring to the examples of the previous section,
population statistics constitutes a typical case of a frequentist approach to the
measure, while the die is a good example for a symmetry approach.
But how exactly the notion of symmetry must be framed in a probabilistic context
is not entirely clear from the relevant literature. Let me therefore deﬁne as the most
basic, if not yet fully general notion of a causal symmetry:
A probabilistic phenomenon exhibits a ‘causal symmetry’ iff the causal structure in terms of
collective conditions, range conditions and measure is invariant, as far as it determines the
probability distribution, under a permutation37 of the attribute space, i.e. invariant under a
mere relabeling of the attribute space.
As discussed in the previous section, the probability distribution is determined by
the weighted fraction of outcome states. The following special case is relevant for
example for games of chance like throwing dice or turning a roulette wheel:
37A generalization to continuous attribute spaces is straightforward.
264
9
Causal Probability

A probabilistic phenomenon exhibits a ‘full causal symmetry’ iff the causal structure in
terms of collective conditions, range conditions and measure is invariant under a permuta-
tion of the attribute space, i.e. invariant under a mere relabeling of the attribute space.
Invariance under transformation of course is commonly held to be the crucial
characteristic of symmetries. For example, an object exhibits a left-right symmetry,
if it is invariant, when the left and right sides are mirrored onto each other. For causal
symmetries, it is the causal structure of a probabilistic phenomenon that is invariant
under certain transformations. In the case of a full causal symmetry, the full causal
structure of the probabilistic phenomenon is invariant under a transformation of the
attribute space. As an example think of a coin, for which the labels on both sides are
exchanged. The coin and also the corresponding probabilistic phenomenon of
throwing a coin are virtually identical before and after the transformation. By
contrast, in the case of a mere causal symmetry, the relevant causal structure before
and after the transformation need not be fully identical. Rather, it must only be
identical to the extent that it determines the probability distribution.
The idea that invariance under reformulations can ﬁx a probability distribution
has long been used with respect to epistemic symmetries in belief states, reaching
back at least to the work of Bolzano (1837/1972, § 161; see also e.g. Jaynes 2003,
Ch. 12; Norton 2008). Above, the same kind of reasoning was employed with
respect to objective causal symmetries.
Only causal symmetries—in contrast to symmetries in belief states—imply the
truth of counterfactual statements, such as: If trials of a probabilistic phenomenon
were carried out with a different labeling, the probability distribution would remain
the same, i.e. any event MX according to the old labeling would have the same
probability as the event MX according to the new labeling. With respect to the
account of variational induction sketched in earlier chapters and summarized in Sect.
9.3.2, counterfactual invariance is established by showing the irrelevance of a
change in circumstances, in this case of the relabeling of the outcome space, for
the causal structure of the probabilistic phenomenon—at least as far as the causal
structure determines the probability distribution.
The deﬁnition of a causal symmetry directly implies a principle of causal
symmetry as an objective variant of the principle of indifference:
In the case of a causal symmetry regarding the exchange of two attributes, these attributes
have equal probability.38
Admittedly, the principle verges on tautology, given the previous deﬁnition of a
causal symmetry. However, the crucial point is that causal symmetries can often be
established non-probabilistically, e.g. on the basis of the laws of classical mechanics
as in the paradigmatic cases of throwing dice and coins or of a roulette wheel.
38Note that any permutation can be reconstructed from a sequence of exchanges of attributes. In the
case of a continuous attribute distribution and invariance under a certain transformation, the
principle of causal symmetry states that an attribute has the same probability as the attribute that
it is mapped on.
9.4
Causal Symmetries and the Principle of Causal Symmetry
265

As a simple example, consider the fair throw of a fair die. The attribute space
consists in the numbers 1 to 6, located on the different sides of the die. Now, a well-
established physical symmetry exists that the numbers on the sides can be permuted
in arbitrary ways without affecting the probability distribution, given typical pro-
cesses of choosing initial conditions and of throwing the die. This symmetry can be
justiﬁed by referring to well-known laws of classical mechanics, e.g. concerning the
mixing of trajectories in certain dynamical systems. Given the principle of causal
symmetry, it follows immediately that all attributes must have the same probability
1/6. It is straightforward to apply this type of reasoning to more complex geometrical
structures, e.g. a triangular prism with three congruent rectangular sides and two
congruent equilateral triangles. Clearly, one can deduce from the corresponding
symmetry transformations of the attribute space—without having to refer to relative
frequencies—that the triangles and the rectangles all have the same probabilities
respectively, while not much can be said about the relative probability between
rectangles and triangles, except of course that they must add up to one.
The notion of causal symmetry can be extended to more complex transformations
of the attribute space including attributes with different probabilities. Such trans-
formations consist in a permutation of the attributes while taking into account the
weighted fractions of outcome states with the respective attributes. Let {M} ¼ {M1,
M2, . . ., Mn} be the attribute space, with P(Mi) denoting the probabilities given by the
weighted fractions of outcome states with attributes Mi. Furthermore, let
{M0} ¼ {M01, M02, . . ., M0n} ¼ T({M}) ¼ {MT(1), MT(2), . . ., MT(n)} be the relabeled
attribute space, where T() denotes a permutation of the original attribute space {M}.
Let P0(M0i) denote the probability of attribute M0i. Under these circumstances, we can
deﬁne:
A probabilistic phenomenon exhibits a ‘generalized causal symmetry’ iff the causal struc-
ture is invariant, as far as it determines the probability distribution when adjusted by
the respective relative weights, under a permutation of the attribute space. More exactly,
the probability distribution of the permuted attribute space {M’} should obey:
P0(M0i) ¼ P0(MT(i)) ¼ P(MT(i))  w(Mi ! MT(i)) ¼ P(Mi), where w(Mi ! Mj) denotes the
ratio of weighted fraction of outcome states with attribute Mi to weighted fraction of
outcome states with attribute Mj.
To avoid circularity, the relative weights w(Mi ! Mj) should again be established
non-probabilistically, e.g. by means of the laws of mechanics or by causal irrele-
vance arguments. A corresponding principle of indifference results:
In case of a generalized causal symmetry, we have: P(MT(i))  w(Mi ! MT(i)) ¼ P(Mi).
Obviously, a simple causal symmetry as formulated at the beginning of this
section results if w ¼ 1. Again a generalization to continuous attribute distributions
and their invariance under certain transformations is straight-forward.
Consider as an example of a generalized symmetry a die that is labelled ‘1’ on one
side and ‘6’ on all other ﬁve sides. The attribute space is {M} ¼ {1, 6} with
P
f g ¼
1
6 , 5
6


. If the attributes are exchanged {M0} ¼ {6, 1} we can calculate as
expected
P0 6
ð Þ ¼ P 6
ð Þ  w 1 ! 6
ð
Þ ¼ 5
6  1
5 ¼ P 1
ð Þ
and
P0 1
ð Þ ¼ P 1
ð Þ 
w 6 ! 1
ð
Þ ¼ 1
6  5 ¼ P 6
ð Þ . Of course, the tricky part is to non-probabilistically
266
9
Causal Probability

establish the causal symmetry and to non-probabilistically determine the relative
weights of the attributes w(). In the described case of a die, this is rather simple, since
the mechanical symmetry with respect to the six sides is fairly obvious, but certainly
most applications will be more complex than that.
Instead of transforming the attribute space one could also introduce a comple-
mentary mapping of the space spanned by the range conditions, which leads to a
further rendering of the notion of causal symmetry, for example:
A probabilistic phenomenon exhibits a ‘causal symmetry in the range conditions’ if there is a
mapping of the space spanned by the range conditions onto a different space, which is also
consistent with the collective conditions, leading to a permutation of the attribute space. The
attributes that are thereby mapped onto each other have the same probability.
Consider for example the throw of a fair coin with a certain set of input states and
a measure. Now, by physical reasoning we know: (i) if for every input state the coin
is rotated by exactly 180, then the attributes after the throw will be exchanged:
heads , tails; (ii) this mapping of the input space is measure-preserving, since for
every throw in the original input space there is a corresponding one with equal
weight in the mapped input space. Of course, the mapped input space is still
consistent with the collective conditions for the fair throw of a fair coin. Finally,
let me stress again that causal symmetries are not epistemic judgments in lack of
knowledge, but statements concerning the irrelevance of attribute transformations—
or, equivalently, transformations of the space spanned by the range conditions—for
the causal structure of a phenomenon and in particular for the probability
distribution.
9.4.2
Further Examples
Let us look at more examples of causal symmetries to show that the notion can be
applied widely. An interesting case in point is Maxwell’s derivation of the equilib-
rium distribution for molecular velocities in an ideal gas from symmetry consider-
ations. Here, the attributes are labels corresponding to different velocities v ¼ (vx, vy,
vz) and positions in space s ¼ (sx, sy, sz). Various symmetry assumptions enter in the
derivation (Maxwell 1860; cp. Strevens 2013, Ch. 1): (i) homogeneity in space,
i.e. there is a causal symmetry with respect to all measure-preserving transformations
(relabeling) of the considered spatial volume. It follows that the probability distri-
bution is independent of the spatial coordinates within the considered container (and
zero outside the container); (ii) isotropy, i.e. there is a causal symmetry with respect
to all rotations (and reﬂections at the origin) of the velocity space. This symmetry
implies that all velocities with the same absolute value
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
v2
x þ v2
y þ v2
z


r
have the
9.4
Causal Symmetries and the Principle of Causal Symmetry
267

same probability;39 (iii) independence of the one-dimensional velocity distributions
along the three Cartesian axes: P(v) ¼ fx(vx)fy(vy)fz(vz) ¼ f(vx)f(vy)f(vz). Strictly
speaking, only the second equality relies on causal symmetry, the ﬁrst on probabi-
listic independence.40 As elaborated in Sect. 9.5.2, probabilistic independence can
be established by showing the irrelevance of one attribute distribution for the other.
For the sake of simplicity, let us assume just two dimensions x and y. A condition for
irrelevance is that the probability fy(vy) for any vy has no inﬂuence on the probability
fx(vx) for any vx. This holds, since in equilibrium the number of collisions with vy for
one of the particles before the collision and vx for one of the particles after the
collision should be equal to the number of collisions with vx for one of the particles
before the collision and vy for one of the particles after the collision. Due to this
relation, which follows from the constancy of the distribution in equilibrium and
from symmetry considerations, changing fx(vx) has no inﬂuence on fy(vy) and vice
versa. That the probability distribution is the same f(.) for all coordinates again
follows from isotropy. Somewhat surprisingly, these relatively weak conditions (i)–
(iii) already hint at the correct probability distribution.
Another causal symmetry is evoked in a later derivation of the equilibrium
velocity distribution by Maxwell (1867, 63). In equilibrium one should have the
following equality for the probability distributions before and after collisions
between two particles: P(v1)P(v2) ¼ P(v1
0)P(v2
0) under the assumption that momen-
tum and kinetic energy is conserved, e.g. v2
1 þ v2
2 ¼ v02
1 þ v02
2 and v1 + v2 ¼ v01 + v02
if all particle masses are the same. Here, primed quantities refer to the velocities after
the collision and unprimed before the collision. Again, the relation is not justiﬁed by
frequency data but by physical reasoning. In fact, it essentially follows from the
deﬁnition of equilibrium, i.e. the requirement that collisions between particles shall
not change the probability distribution: “When the number of pairs of molecules
which change their velocities from [v1,v2] to [v01,v02] is equal to the number which
change from [v01,v02] to [v1,v2], then the ﬁnal distribution of velocity will be
obtained, which will not be altered by subsequent exchanges.” 41 (Maxwell 1867,
63) The equality P(v1)P(v2) ¼ P(v1
0)P(v2
0) can be interpreted as a generalized causal
symmetry with respect to transformations of the attribute space v1 $ v01. It yields
39Maxwell argues: “the directions of the coordinates are perfectly arbitrary, and therefore [the
probability] must depend on the distance from the origin alone” (Maxwell 1860, 153). This
reasoning is criticized by Strevens (2013, 14) on the grounds that Maxwell’s remark supposedly
holds for any probability distribution over velocities, which would be an absurd consequence.
However, if one understands ‘arbitrary’ in the sense that the choice of coordinates is irrelevant for
the probability distribution, then Maxwell’s reasoning is basically correct, evoking a causal
symmetry as we had deﬁned it in the previous section.
40As pointed out by Strevens (2013, 14), Maxwell’s own reasoning in this regard is not entirely
convincing, although Maxwell does appeal to independence: “the existence of velocity x does not in
any way affect the velocities y or z, since these are all at right angles to each other and independent”
(1860, 153).
41The same relation was used above when arguing for mutual independence of the one-dimensional
velocity distributions.
268
9
Causal Probability

direct access to the relative measure w v1 ! v01
ð
Þ ¼ P v20
ð
Þ
P v2
ð
Þ . Since supposedly the
Maxwell distribution is the only plausible function satisfying the equality, the
argument allows establishing this distribution merely by appeal to physical
symmetries.
A further notable example of causal symmetries concerns the ubiquitous binomial
distribution for the calculation of k successes in n trials of an event with
probability p: Pn,p k
ð Þ ¼
n!
k! nk
ð
Þ! pk 1  p
ð
Þnk. For the sake of simplicity let us focus
on the special case p ¼ 1/2. A physical process that generates the corresponding
distribution is the Galton board. The essential mechanical symmetry of the Galton
board is that at each pin there is no difference between a ball going right or left.
Therefore, there is a causal symmetry for each pin i that the probability distribution
will not change if one exchanges the labels left l and right r. It follows from the
principle of causal symmetry for all i: P(l|i) ¼ P(r|i) ¼ 1/2. Based on this insight, the
distribution of balls at each level n of the Galton board can be calculated in a purely
combinatorial manner by tracing the possible trajectories of the balls through the
board. The resulting recursive formula denotes a rather complex causal symmetry
that allows to completely determine the binomial distribution at each level
Pn k
ð Þ ¼ 1
2 Pn1 k  1
ð
Þ þ Pn1 k
ð Þ
½
 with P0(0) ¼ 1, Pn(1) ¼ Pn(n + 1) ¼ 0. Let
me stress again that in deriving the probability distribution for the Galton board we
need not make reference to any frequency data whatsoever.
Note that the mentioned complex symmetry does not immediately ﬁt into the
framework described in the previous Sect. 9.4.1, since the recursive formula relates
distributions for different levels n. But it is straight-forward to reformulate it in a way
that it ﬁts with the form of generalized causal symmetries P(MT(i))  w(Mi ! MT(-
(MT(i))  w(Mi ! MT(i)) ¼ P(Mi). Special cases follow directly from further mechanical symmetries of the
physical set-up, e.g. Pn(k) ¼ Pn(n  k). A generalization to p 6¼ 1
2 is also straight-forward if one can establish
a causal symmetry of the form P(l| i)p ¼ P(r| i)(1  p).
To conclude, let me stress again that the reasoning in these examples does not rely
on an epistemic principle of indifference but rather on an objective principle of
causal symmetry. Causal symmetries do not refer to lack of knowledge, but follow
from the invariance of the causal structure determining the probability distribution
under certain transformations of the attribute space.
9.4.3
The Principle of Causal Symmetry
In Sect. 9.4.1, I deﬁned the notion of causal symmetry and based on it a principle of
causal symmetry as an objective version of the principle of indifference. In its
simplest form the principle of causal symmetry states that given a causal symmetry
one should ascribe equal probabilities to the corresponding attributes.
How does the epistemic version of the principle of indifference ﬁt into the picture,
i.e. the principle of insufﬁcient reason that we should ascribe equal probability when
our knowledge about a process does not favor one or the other outcome? Note that
9.4
Causal Symmetries and the Principle of Causal Symmetry
269

there seem to be clear-cut examples, where this epistemic version is employed, for
example in Laplace’s treatment of the loaded coin: In lack of evidence regarding the
way in which the coin is loaded, so the reasoning goes, we should ascribe equal
probability to both sides (cp. Sect. 9.2.1).
Several authors like Cournot or Strevens suggest grounding the distinction
between epistemic and ontic probabilities on whether they have been established
by an epistemic or an objective version of the principle of indifference, respectively.
By contrast, I will now argue that apparent applications of the principle of insufﬁ-
cient reason yield the same results as the principle of causal symmetry whenever the
resulting probabilities are predictive.42 The key idea lies in constructing an adequate
collective so that the principle of causal symmetry can be applied. Here,
predictiveness requires two things, (i) that the causal structure in terms of collective
conditions is sufﬁciently speciﬁed to warrant an unambiguous ascription of causal
probabilities according to the deﬁnitions given in Sect. 9.3.2 and (ii) that these
collective conditions are compatible with the actual conditions realized in the
considered event(s). By means of the law of large numbers, predictiveness then
implies certain limiting frequencies to be realized in the world for the speciﬁed
collective.
As an example, assume that we know to which extent a coin is loaded, say p ¼ 2/
3, but do not know in which direction. As mentioned, it seems a straight-forward
application of the principle of insufﬁcient reason, when one ascribes probability 1/2
to both heads and tails before the ﬁrst throw. However, we can also construe an
adequate collective to subsume the reasoning under the principle of causal symme-
try. The collective conditions should include the premise that the coin is loaded,
while the measure ascribes equal weight to both possibilities p(heads) ¼ 1/3 and p
(heads) ¼ 2/3. The set-up corresponds to a probabilistic phenomenon, where we are
given two coins that are loaded in opposite ways, randomly pick one of them, and
throw it. With respect to this collective and measure, a probability 1/2 for both heads
and tails results.
When we know what we don’t know in terms of causal inﬂuences on the
probability distribution, i.e. when the lack of knowledge can be expressed in terms
of causal conditions, one can always proceed in this manner, i.e. construct a
collective that accounts for the lack of knowledge and determine the corresponding
probability distribution. Of course, lack of knowledge can come in different degrees.
42One may be tempted to speak of a reduction of the principle of insufﬁcient reason to the principle
of causal symmetry whenever the probabilities are predictive, but such a formulation can be
misleading. The starting point of the present section is the question how the principle of insufﬁcient
reason could be supplemented or changed such that the notorious Bertrand type ambiguities
disappear. A clear criterion how much causal structure is necessary for this task is given in terms
of causal symmetries. Of course, this strategy is somewhat opposed to the original idea and spirit of
the principle of insufﬁcient reason, namely to assign probabilities on the basis of ignorance, no
matter how little we know about a phenomenon. Such a universal principle of insufﬁcient reason is
not sensible according to the proposed approach. By contrast, if one insists on such a universal
principle, which is of course possible (Shackel 2007 is an example, referring himself to van
Fraassen), as a consequence one will always be stuck with Bertrand type ambiguities.
270
9
Causal Probability

For example, it might be the case that we are only given a probability distribution for
the extent to which the coin is loaded. But again, this knowledge already determines
the measure and thus an appropriate collective.
Apparently, there are two types of situations, (i) when the collective refers only to
conditions that are known to be realized in the considered event(s) and (ii) when for
some conditions it is unknown whether they are realized and thus they have to be
postulated (cp. also Sect. 9.6.2). As an example, the two coins that are loaded in
different directions could both really exist, e.g. lie on a table before us. Or, there
could be just a single coin of which we do not know in which direction it is loaded. In
the latter case, the process of randomly choosing between two coins has to be
postulated to avoid contradictions, since otherwise a collective and measure cannot
be assigned. Certainly, the resulting probabilities are only predictive, if the postu-
lated collective conditions are compatible with the partly unknown actual conditions
of the considered event. One might be tempted to ground the distinction between the
epistemic principle of insufﬁcient reason and the ontic principle of causal symmetry
on this difference between an actual and a postulated collective. But note that
conventionally the principle of insufﬁcient reason does not require constructing a
causal collective. Also, the mentioned distinction is certainly not sharp but rather
blurry. In any case, the distinction cannot serve to establish a substantial difference
between epistemic and ontic probabilities.
Are there applications of the principle of insufﬁcient reason that cannot be
accounted for in terms of the principle of causal symmetry? These must be instances
where the collective is not sufﬁciently speciﬁed to warrant the ascription of proba-
bilities. In other words, we do not know what we don’t know in terms of causal
inﬂuences on the probability distribution. But if collective and measure are
underdetermined then we are immediately confronted with Bertrand-type paradoxes.
Consider the notorious example concerning the probabilities of different colors,
e.g. red, blue, and green. Do red and non-red have the same probability according
to the principle of insufﬁcient reason? That cannot be since it would be incompatible
with the analogous case that blue and non-blue have the same probability. According
to the perspective of this essay, such contradictions arise because the causal context
is not speciﬁed in terms of collective conditions, range conditions and measure
insofar as they are relevant to the probability distribution of attributes. Without the
causal context, the principle of insufﬁcient reason leads to contradictions and thus
cannot be meaningfully applied.
Thus, Bertrand-type paradoxes are resolved by rendering probabilities relative to
a collective, i.e. essentially by the requirement that the causal set-up is sufﬁciently
speciﬁed. Consider another classic example dating back to Joseph Bertrand himself
(1889, 4–5): What is the probability that the length of a random chord in a circle is
shorter than the side of an equilateral triangle inscribed in the same circle? Bertrand
points out that there are various incompatible answers depending on which measure
one chooses, e.g. equal measure for the distance of the middle of the chord to the
center of the circle, equal measure for the angle between chord and the
corresponding tangent to the circle, or equal measure for the surface element into
which the middle of the chord falls. Again, the ambiguity is resolved by sufﬁciently
9.4
Causal Symmetries and the Principle of Causal Symmetry
271

specifying the causal process that determines the location of the chord, e.g. the way a
stick is dropped on a circle drawn on the ﬂoor.
When the causal context is sufﬁciently speciﬁed in terms of collective conditions,
then the corresponding probabilities are automatically predictive about the respec-
tive probabilistic phenomenon. Also, under such circumstances, every supposed
application of the epistemic principle of insufﬁcient reason can be reconstructed as
an application of the principle of causal symmetry.43 By contrast, probabilities
resulting from applications of the principle of insufﬁcient reason that cannot be
rendered in terms of the principle of causal symmetry are in general not predictive
because the causal structure is not sufﬁciently speciﬁed to allow an unambiguous
ascription of probabilities.
Note ﬁnally that the principle of causal symmetry is not affected by another
standard objection against the principle of insufﬁcient reason that it supposedly
derives something from nothing, namely probabilities from ignorance. Rather, the
principle of causal symmetry presupposes considerable knowledge in terms of causal
circumstances in order to establish probabilities that are predictive for a speciﬁc
probabilistic phenomenon. Henceforth, we suggest excluding from the theory of
probability all cases where the relevant context in terms of collective conditions is
not speciﬁed and therefore predictiveness cannot be guaranteed.
9.5
Causal Irrelevance and Probabilistic Independence
9.5.1
Independence
As indicated in Sect. 9.4, symmetry arguments primarily establish equal measure for
the realization of different attributes. However, in order to deﬁnitely identify this
measure as a probability measure, the independence of trials has to be shown in
addition. Most importantly, typical derivations of the law of large numbers presup-
pose a sequence of independent and identically distributed44 random variables.
Thus, in order to establish the crucial link via the law of large numbers between
relative frequencies and probabilities based on symmetries, a notion of probabilistic
independence is required. If at least some version of the law of large numbers holds,
then evidence in terms of relative frequencies also constitutes evidence for causal
symmetries.
In the following, I will argue that the causal approach can also throw some light
on the notion of independence—an issue that has been called “one of the most
43In this respect, the viewpoint of this essay resembles the position of North (2010), who also denies
that there exist distinct objective and epistemic versions of the principle of indifference.
44Identical distribution is guaranteed if different trials are of the same probabilistic phenomenon.
272
9
Causal Probability

important problems in the philosophy of the natural sciences”45 by Kolmogorov. In a
recent paper, Strevens essentially concurs and adds that the “matter has, however,
received relatively little attention in the literature” (forthcoming, 3). The notion of
independence is a major issue in the controversy between subjectivist and objectivist
readings of probability. For example, Bruno de Finetti, as a main proponent of
subjectivism, aimed to eliminate the essentially objectivist concept of independence
altogether and to replace it with exchangeability. In the following, a causal construal
of independence will be sketched linking it to causal irrelevance.
For further discussion, it is helpful to distinguish two notions of independence,
(i) the independence of consecutive trials of the same probabilistic phenomenon and
(ii) independence of random variables associated with different probabilistic phe-
nomena. Roughly speaking, independence of two variables A and B means that
(a) one outcome does not affect the other P(A|B)¼P(A) or, equivalently from a
mathematical point of view, that (b) the corresponding probabilities factorize P(A,
B)¼P(A)P(B).46 Independence is often deﬁned in terms of such factorization, for
example by Kolmogorov (1956, §5). But certainly this does not solve the difﬁcult
methodological question how to determine independence in the world. Why, for
example, are two consecutive draws from an urn generally considered independent
in case of replacement and otherwise not?
Let us begin with a widespread intuition and relate independence to irrelevance.
In Sect. 9.3.2, I argued for a link between variational induction and the notion of
causal probability. Such variational induction also provides a framework for
determining a type of irrelevance, namely causal irrelevance in the sense of
difference-making with respect to background conditions. Regarding the ﬁrst notion
of independence (i), consider two trials with the same collective conditions and the
same measure. A sufﬁcient criterion for probabilistic independence is:
Two trials are ‘probabilistically independent’, if the range conditions in one trial are
causally irrelevant47 for the collective conditions in the other trial and thereby for the
probability distribution of range conditions in the other trial.48
In other words, arguments based on causal irrelevance shall establish that what-
ever range conditions are realized in one trial, the probability distribution in the other
trial will be the same—which corresponds to the usual framing of independence.
45“one of the most important problems in the philosophy of the natural sciences is—in addition to
the well-known one regarding the essence of the concept of probability itself—to make precise the
premises which would make it possible to regard any given real events as independent. This
question, however, is beyond the scope of this book.” (Kolmogorov 1956, 9)
46Note that this covers also the ﬁrst notion of independence (i), if one interprets the consecutive
trials as different probabilistic phenomena.
47i.e. irrelevant with respect to a causal background constituted by the collective conditions of the
ﬁrst trial.
48This deﬁnition assumes the absence of a deﬁnitional connection between the range conditions of
the ﬁrst trial and the collective conditions of the second trial.
9.5
Causal Irrelevance and Probabilistic Independence
273

As outlined in the beginning of Sect. 9.3.2, causal irrelevance can be understood
in counterfactual terms: if the range conditions had been different in one trial, the
collective conditions and in particular the process determining the range conditions
in the next trial would not have changed. In many situations, we have fairly reliable
intuitions about such counterfactual statements which are usually evaluated based on
the absence of plausible causal inﬂuences or causal pathways, as e.g. in the case of a
blind-folded person drawing from an urn with replacement or stopping a wheel of
fortune several times in a row.
One might object to the above deﬁnition that causal irrelevance is not sufﬁcient
since there could still be correlations between the range conditions of the ﬁrst trial
and the collective conditions of the second trial that do not result from a direct causal
relationship. In particular, there might be a common cause that inﬂuences the range
conditions in both trials. However, the notion of causal irrelevance from Sect. 9.3.2
excludes such cases (see also Sect. 5.2.1).
To recall, in a context B, in which a condition C and a phenomenon P occur, C
was deﬁned as causally irrelevant to P, iff the following counterfactual holds: if C
had not occurred, P would still have occurred. Now, in cases with a common cause
for C and P, the mentioned counterfactual generally does not have a determined truth
value. After all, there are situations in which P would not have occurred if C had not
occurred, namely exactly those, in which C and P are due to a common cause. In
those situations, the absence of the common cause implies the absence of both C and
P. Thus, whenever a common cause exists, there is no causal irrelevance and
consequently no independence of trials.
Note that this line of reasoning is itself not obvious, but depends intricately on the
speciﬁc understanding of counterfactuals that is employed. David Lewis, for exam-
ple, would disagree with the above assessment on the basis of his possible-worlds
approach to counterfactuals. For reasons that are beyond the scope of this chapter,
Lewis in his analysis excludes so-called backtracking counterfactuals of the type that
if the effect had not happened then the cause would not have happened either. Thus,
in the case of a common cause for C and P but in the absence of a direct causal
connection between C and P, Lewis would generally claim that if C had not
happened, P would still have happened implying causal irrelevance between C
and P.
Therefore, a different analysis of counterfactuals is required that was very brieﬂy
delineated in the beginning of Sect. 9.3.2 (see also Sect. 5.2.2). According to this
approach which takes inspiration from the method of difference, backtracking
counterfactuals are true if the context fulﬁlls the requirement of homogeneity as
also deﬁned in Sect. 9.3.2. Given homogeneity, the absence of an effect must result
from the absence of the considered cause.
Thus, the proposed deﬁnition for probabilistic independence of trials excludes
correlations due to direct causal relevance but also due to common causes. Now what
about other kinds of correlations? A further important type does not result from
causal dependencies, but rather from deﬁnitional relationships. After all, if there is a
deﬁnitional connection between C and P, of course, there could be correlations as
well. But in the case of such relationships, a completely analogous treatment in terms
274
9
Causal Probability

of a counterfactual analysis is possible. After all, the mentioned counterfactual
would not be true either, only that a different kind of necessity is involved compared
with the case of causal irrelevance.49 Furthermore, probabilities are usually consid-
ered to concern empirical relationships and not deﬁnitional relationships.
Last not least, there may be correlations that are neither due to causal nor due to
deﬁnitional connections between C and P. However, in such cases, it is plausible to
assume that the correlations are purely accidental, i.e. that they are merely ﬂuctua-
tions in the observed frequencies that may of course always occur in probabilistic
phenomena, even in the case of probabilistic independence. Thus, the proposed
account of causal probability again manages to draw the correct distinction between
correlations that are meaningful and those that are not.
Now, the independence of random variables (ii) concerns different probabilistic
phenomena that can have different collective conditions. Each random variable is
associated with a speciﬁc probabilistic phenomenon. A sufﬁcient criterion for
independence is:
Two random variables are ‘probabilistically independent’, if the range conditions in one
probabilistic phenomenon are causally irrelevant50 for the collective conditions in the other
probabilistic phenomenon and thereby for the probability distribution of range conditions in
the other probabilistic phenomenon.
This criterion broadly stands in the tradition of deﬁnition (a) for independence,
but it also differs in important respects. Most importantly, it makes reference not to
the attribute distribution but to the usually more ﬁne-grained distribution of range
conditions. Thus, the evaluation of the criterion is more intuitive since it makes
explicit reference to the processes that are causally responsible for the probability
distributions of attributes. As an example the throw of a coin and the probability of
rain tomorrow are independent, because there is no causal connection between the
corresponding processes determining the range conditions in each case. On the other
hand, the probability of smoking and the probability of getting lung cancer are in
general not independent in an individual, because there is a plausible causal inﬂu-
ence from the range conditions of smoking to those of getting lung cancer.
Note again that with respect to the conventional deﬁnition of independence the
criteria given above are only sufﬁcient but not necessary. As an example, consider
two consecutive draws of a ball with replacement. The ﬁrst ball is drawn arbitrarily
from one of two urns B and W both of which have the same ratio of black and white
balls. The second draw depends on the result of the ﬁrst draw. If the ball is black, the
next one is drawn from urn B, otherwise from urn W. Now, even though there is
some causal relevance of the range conditions in the ﬁrst draw for the collective
conditions of the second draw, the draws are still independent in the conventional
sense, i.e. for the attribute distribution black/white in the second draw the attribute of
the ﬁrst draw does not matter. The trick is of course that while there is causal
49This treatment can easily be extended to cover still further types of necessity.
50i.e. irrelevant with respect to a causal background constituted by the collective conditions of the
ﬁrst phenomenon.
9.5
Causal Irrelevance and Probabilistic Independence
275

dependence, this has no inﬂuence on the probability distribution of attributes in the
second draw.
Thus, one could conceptually distinguish probabilistic independence as framed
above in terms of irrelevance of the range conditions from the conventional concept
of probabilistic independence referring to the irrelevance of attributes. Of course, the
former implies the latter—simply because the attributes are deﬁned on the outcome
space spanned by the range conditions. A sufﬁcient and necessary criterion for
independence in the conventional sense is:
Two trials are ‘probabilistically independent’ iff the attributes in one trial are causally
irrelevant51 for the probability distribution of attributes in the other trial.
Thus, there may be causal relevance for the collective conditions in the other trial,
as long as the resulting collective conditions imply the same probability distribution
as in the ﬁrst trial. For example, in cases, where the method of arbitrary functions can
be applied, there may be causal relevance between subsequent initial conditions on a
macroscopic scale, which however will be irrelevant for the probability distribution
due to microconstancy. Equally:
Two random variables are ‘probabilistically independent’ iff the attributes in one probabi-
listic phenomenon are causally irrelevant52 for the probability distribution of attributes in
the other probabilistic phenomenon.
Essentially, this is only the familiar requirement P(A|B) ¼ P(A), while specifying
that the criterion is to be understood in terms of causal irrelevance according to
variational induction. An example was discussed in Sect. 9.4.2 concerning the
mutual independence of velocity distributions along different coordinate axes in an
ideal gas at equilibrium.
Note ﬁnally that the notions of independence and randomness are closely related.
Most importantly: If subsequent trials are independent, then the sequence of out-
comes will be random. Certainly, this perspective on randomness within the causal
approach differs considerably from traditional explications, where randomness has
mostly been deﬁned with respect to certain mathematical or formal properties in the
sequence of attributes. Von Mises’ notion of irregularity, essentially that all sub-
sequences chosen without reference to the attributes must exhibit the same attribute
distribution as the sequence itself, and Kolmogorov’s work on algorithmic com-
plexity are just two examples in this respect.
In summary, we have suggested how probabilistic independence could be derived
from causal irrelevance of probabilistic phenomena as determined by variational
induction. Of course, these few sketchy ideas cannot fully account for the enormous
complexity of the notion.
51i.e. irrelevant with respect to a causal background constituted by the collective conditions of the
ﬁrst trial.
52i.e. irrelevant with respect to a causal background constituted by the collective conditions of the
ﬁrst phenomenon.
276
9
Causal Probability

9.5.2
Interpreting the Measure
In one article, Rosenthal describes as the “main problem of the range approach”
(2010, 81) that it inherits the circularity of the classical approach to probability in
that the measure determining the weights of certain combinations of range condi-
tions itself requires justiﬁcation in terms of probabilities, i.e. probabilities of initial
conditions. For authors like Rosenthal, who argue on the basis of the method of
arbitrary functions, the solution is to establish that for certain phenomena, most
choices of measure lead to roughly the same probabilities. However, as pointed out
towards the end of Sect. 9.2.2, a number of problems result from this approach. Most
importantly, the equivalence of different measures holds only approximately and
there are even some measures for which the probability distribution is far off from
the correct result. These problems were resolved in the causal approach by rendering
probability relative to collective conditions and thereby to the measure over the state
space spanned by the range conditions (cf. Sect. 9.3.2).
For the causal approach the challenge remains to give an interpretation of the
measure without having to refer to other concepts of probability, in particular to
relative frequencies, which essentially would throw us back on a frequentist account
of probability. However, we now have the necessary conceptual tools to tackle this
problem. Essentially, the probability measure over range conditions can be con-
strued in terms of causal symmetries in the collective conditions53 and in terms of
independence of different trials resulting from causal irrelevance. By means of
symmetry arguments, the measure can be quantitatively determined. The measure
often results from the system dynamics, which notably may be deterministic and
even quite regular, e.g. when a wheel of fortune turns with constant velocity.
Arguments from causal irrelevance then allow establishing the independence of
range conditions in different trials and thereby interpreting the measure as a prob-
ability measure. Given the existence of a measure and independence of trials, which
constitute the main premises for the various laws of large numbers, the link to
limiting relative frequencies can be made via those laws. Note that the second-
order probabilities in these laws are not problematic for the causal approach. Rather,
they can be interpreted in a straightforward manner in terms of different copies of the
same causal set-up as determined by the collective conditions.
Independence of subsequent trials is usually guaranteed by allowing two pro-
cesses that are causally irrelevant for each other to interfere within the same
probabilistic phenomenon, where, as argued before, causal irrelevance excludes
direct causal relevance as well as common causes. All probabilistic phenomena
53One could object that it is not always obvious whether the collective conditions really determine
the measure and in particular whether there are the mentioned symmetries in the collective
conditions. However, for any probabilistic phenomenon the collective conditions just amount to
the instructions which events to include as trials of the phenomenon. If these trials have a stable
causal structure then there will automatically be a corresponding probability distribution, which
must necessarily correspond to causal symmetries in the collective conditions as should be obvious
from the deﬁnitions in Sect.9.4.1.
9.5
Causal Irrelevance and Probabilistic Independence
277

(except those with indeterministic dynamics) appear to have such an element that
seems required to ensure the random nature of the attribute sequence. Causal
irrelevance allows establishing counterfactual statements of the following type: if
the range conditions realized in one of the mentioned processes would have been
different, the distribution of range conditions of the other process would still have
been the same.
A good example is the wheel of fortune as already discussed in Sect. 9.3.2. The
dynamics of the wheel, which is perfectly regular, establishes the measure for the
different outcome states of the wheel, in particular equal measure in time for all four
colors. Furthermore, the initial conditions determining the rotation of the wheel are
causally irrelevant for the moment when the wheel is stopped. To ensure this the
person stopping the wheel is blind-folded and all information concerning speed and
state of the wheel is withheld from her. Again, the causal irrelevance can be
informally tested by evaluating the counterfactual, whether the person would have
picked another moment when to stop the wheel had the initial conditions of the
wheel been different.
Applications of the method of arbitrary functions can be explained in the same
manner. Take the roulette wheel as an example. The assumption of microconstancy
requires that slight changes in initial conditions may already lead to a change in
attribute. Again, the process determining the measure over initial conditions has to
be causally irrelevant for the resulting probability distribution of attributes. Obvi-
ously, this is the case when for example we look at what is happening in casinos
around the world. The rotation of the roulette wheel is too fast and the dynamics of
the ball on the roulette wheel too irregular that the croupier could inﬂuence the result
by letting the ball enter in a certain way. The advantage of phenomena falling under
the method of arbitrary functions is that the resulting probability distributions are
robust, i.e. there is a broad range of processes how to choose the initial conditions of
ball and wheel that fulﬁlls the requirement of irrelevance for the probability distri-
bution. Thus, the present analysis does not identify as decisive element in those
examples microconstancy or macroperiodicity, but rather the interference of two
causally unrelated processes, the rotation of the wheel and the entering of the ball.
Again, microconstancy and macroperiodicity just guarantee, that this result is fairly
stable across a wide variety of processes. But they are not decisive for the probabi-
listic nature of the phenomenon.
By contrast, consider the following example originally due to Richard von Mises
which for him explicitly does not constitute a probabilistic phenomenon. Let there be
a sequence of posts along a road, a large always following a small and vice versa.
Certainly, collective conditions can be formulated, e.g. regarding someone driving
along the road and writing down the sequence of posts. Also, a symmetry exists with
respect to large and small posts. However, at this stage one is not dealing with a
probabilistic phenomenon since it lacks the feature of randomness. But again, the
latter could be implemented by adding a further causally unrelated process, e.g. a
process that puts a person on the road at an arbitrary location to then determine the
size of the nearest post.
278
9
Causal Probability

Thus, the short answer to the problem of circularity is that the measure over
different combinations of range conditions designates a probability measure but that
it can be construed conceptually in terms of causal symmetries in the collective
conditions which quantitatively determine the measure and in terms of causal
irrelevance implying the independence of subsequent realizations of range condi-
tions or at least attributes.
9.6
Ontic and Epistemic Probabilities
9.6.1
Single-Case Probabilities and Indeterminism
Indeterministic phenomena can easily be integrated into the suggested framework of
causal probability. For a fully indeterministic phenomenon, there are no hidden
variables, i.e. no range conditions that determine outcome and attribute. More
exactly, with respect to deﬁnition 2 of Sect. 9.3.2, there is only one input state
determined by the collective conditions and the measure over input space thus
becomes trivial. With respect to the terminology introduced in Sect. 9.3.2, there
are no measure conditions and the collective conditions consist only of set-up
conditions, which by means of the indeterministic dynamics S !
C O ﬁx a measure
over the outcome space and thus the probability distribution for the attributes. This
distribution is essentially given by deﬁnition 1 of Sect. 9.3.2 referring to a proba-
bility measure over the outcome space.
The orthodox interpretation of quantum mechanics provides a prime example.
Via the Schrödinger equation, the collective conditions determine the wave function
and thereby the probability distribution upon measurement for certain attributes like
position or momentum of a particle. The orthodox interpretation explicitly excludes
range conditions which would correspond to hidden variables rendering the phe-
nomenon deterministic.
These remarks can also help to clarify the role for single-case probabilities
according to the perspective of this chapter. In principle, there are no probabilities
without collective. However, fully indeterministic events could be viewed as single-
case probabilities, since for these a natural choice of collective conditions exists,
namely those that maximally determine the probability distribution. Thus, the
collective is to some extent already implied by the description of a single event.
Note further that according to the causal approach of this essay one can speak of the
probability of an event, even though the corresponding probabilistic phenomenon
may have occurred only once. As long as one has epistemic access to the measure
over outcome space, the phenomenon need not even be repeatable. This distin-
guishes the causal approach from the naïve frequency view which obviously has to
rely on a sufﬁcient number of instantiations.
9.6
Ontic and Epistemic Probabilities
279

9.6.2
Epistemic and Ontic Probabilities
The discussion of indeterminism in the previous section directly leads to one of the
basic themes in the debate on interpreting probability, namely the distinction
between epistemic and ontic probabilities. As emphasized before, unlike the
SRA-approach, the causal framework delineated in this article is meant to extend
to cases of indeterminism and also to epistemic probabilities such as probabilities of
hypotheses. In fact, causal probability is intended to cover all applications of the
probability axioms in which probability is predictive, i.e. in which the main premises
for the law of large numbers hold, in particular existence of a measure and indepen-
dence of trials.
The deﬁnitions from Sect. 9.3.2 allow identifying different types of probabilities
along the ontic-epistemic spectrum. (i) Purely ontic probabilities are those for which
a speciﬁc collective is singled out by the statistical event. The typical example
concerns indeterminism as discussed in Sect. 9.6.1, e.g. the decay of a radioactive
atom according to the orthodox interpretation of quantum mechanics. In the case of
indeterminism, collective conditions exist that maximally determine an event in
question with a probability unequal to one, in contrast to deterministic settings
where, obviously, the conditions that maximally determine an event yield
probability one.
(ii) When the event does not single out the collective conditions (as in the case of
indeterminism just discussed), there will automatically be an epistemic element in
the choice of these conditions. Most importantly, there remains some leeway, which
causal circumstances to consider as collective conditions and which as range condi-
tions, usually implying a change in probabilities. Notably, different probability
measures may result from different choices of collective conditions. These epistemic
aspects are not problematic for the causal approach since it always relates probability
to a speciﬁc collective. In this sense, we could still speak of objective probabilities.
Note that the mentioned epistemic aspects in principle also exist for the deterministic
probabilities established by the method of arbitrary functions, if somewhat less
pronounced.
(iii) A further epistemic element concerns the distinction between a situation,
where the collective conditions are known to be realized in one or more instances in
the world, and situations, where the known conditions of a speciﬁc event do not
sufﬁce to unambiguously assign a probability and thus additional conditions have to
be imagined or postulated in order to construct an appropriate collective. With
respect to the example of the two coins that was already discussed, it can be asked
whether one actually chooses between two coins that are loaded in different ways—
or whether there is only one coin and the ensemble of two coins is just imagined as a
subjective range of alternatives? These two situations roughly correspond to the
distinction between an objective and an epistemic reading of the principle of
indifference, as introduced in Sect. 9.4.3. In the case that some conditions have to
be imagined or postulated, we must resort to statements like: ‘if such and such
collective conditions are compatible with the considered instance(s), which we do
280
9
Causal Probability

not know for sure, then the resulting probability distribution is predictive with
respect to this collective.’
As noted before, the distinction is not sharp and depends considerably on context.
But of course, the fewer conditions are known about a phenomenon, the more
ﬂexibility exists how to construct the collective—corresponding to a more pro-
nounced subjective element in the assignment of probabilities.
In the following, I will discuss two further variants of epistemic probabilities, ﬁrst
concerning predictions that rely on symptoms instead of the actual causes and
second probabilities of hypotheses.
9.6.3
Probabilities from Causal Symptoms
Sometimes, the space spanned by the range conditions is parametrized not in terms
of causes of the probabilistic phenomenon, but rather in terms of symptoms or proxy
variables that are somehow causally related. Without loss of generality, this problem
is best discussed in terms of deﬁnition 2 of Sect. 9.3.2. A typical example concerns
the correlation between barometer and weather. One can quite reliably predict the
weather by referring to a barometer reading, but of course the barometer reading is
not a cause of the weather. Rather, air pressure is a common cause that inﬂuences
both barometer and weather. Since air pressure is not easily accessible epistemically,
one might be tempted to postulate a probabilistic phenomenon that has as input space
the barometer reading and as outcome space a certain parametrization of the weather.
While in practice such probabilities predicting from symptoms or proxies of com-
mon causes are widespread, let us brieﬂy examine if they are consistent with the
viewpoint of causal probability.
Formally, we have an outcome space O, a space spanned by the parametrization
of the symptoms I, and an unknown input space S that causally determines the
outcome space. In the example above, O would be the weather, I would be the
barometer reading, and S would be spanned by some microparameters determining
the weather, including air pressure. Two situations need to be distinguished: (i) the
symptoms I are fully determined by S; (ii) there are other causes of I that are not in S.
In the ﬁrst case, probabilities from symptoms easily ﬁt into the framework of
causal probability in the following manner. For the sake of simplicity, assume that to
any S can be attributed an I. The symptoms I can then be considered as labels of the
input space and thus as a reparametrization of the input space, which allows to
establish a probability distribution over the attributes based on the symptoms. Note
that the mapping I ! O will in general not be fully deterministic, i.e. the same value
of I can lead to different values of O.
By contrast, such a probability distribution does not exist in the second case,
because there are other unrelated causes for I. For example, someone may mechan-
ically interfere with the barometer reading or the spring in the barometer may break.
If such external causes are possible, then a probability distribution for the attributes
based on symptoms cannot be given. The situation can only be resolved, if one
9.6
Ontic and Epistemic Probabilities
281

includes in the parametrization of the input space S all possible external causes of I
and if one knows the probability measure over those causes. In that case, we can
again interpret the symptoms I as a reparametrization of the extended input space and
a meaningful probability distribution results for the attributes.
In summary, probabilities from symptoms are only meaningful if they can in
principle be reduced to causal probabilities as deﬁned in Sect. 9.3.2.
9.6.4
Probabilities of Causal Hypotheses
Thus far, we have treated probabilities of events or types of events as determined by
their causal circumstances. But the inductive framework of Sect. 9.3.2 can also cover
inverse probabilities, i.e. probabilities of hypotheses regarding possible causes
generating the given evidence. The reason is that the variational logic underlying
causal probability works in both directions—from given causes to possible effects
and from given effects to hypotheses about causes. This resolves Humphreys’
paradox for the proposed account in a way that corresponds quite closely to a
suggestion by Donald Gillies (2000a, 131–133).
Consider again a probabilistic phenomenon determined by certain collective
conditions, an input space, a measure W over the input space and a causal mapping
from input space to outcome space. When determining the probability of hypotheses,
a labelling of the input states must be introduced, which allots these to the different
hypotheses H1, . . ., HN (i.e. each hypothesis is about a certain cause being active in
some of the input states to bring about a certain outcome). This labelling must be
mutually exclusive and must cover the whole input space. If, for the sake of
simplicity, it is assumed that the causal mapping is bijective54, a corresponding
labelling of the outcome space results. The causal mapping also determines a
measure WO over the outcome space from the measure over the input space.
Relevant evidence leading to an adjustment of the probabilities of the various
hypotheses can concern the input space and the outcome space. We can now deﬁne:
The probability of a causal hypothesis HX, combining a set of input states of the probabilistic
phenomenon P, is given by the fraction of input states weighted with measure W carrying the
label HX or, equivalently, by the fraction of outcome states weighted with measure WO
carrying the label HX.55
Let us look at the Monty Hall problem as a simple example for probabilities of
causal hypotheses generating a given evidence. In a quiz show, a candidate is
54Generalizations are straightforward, e.g. to indeterministic mappings or when it is only surjective.
In the latter case, the probabilities have to be calculated in the input space, of course.
55Note that the probabilities of hypotheses can be interpreted in terms of probabilities of events,
when it is possible to look up which of the hypotheses is actually realized in the world. For example,
in the Monty Hall problem discussed below, the corresponding event would consist in opening all
doors to verify where the car is.
282
9
Causal Probability

presented with three doors A, B, C, behind one of which is a car, behind the two
others there are goats. The candidate chooses one of the doors, e.g. A. At the
beginning, the evidence conveyed by the quizmaster does not favor any of the
hypotheses HA, HB, HC that the car is behind the respective door. In other words,
there is a causal symmetry in the set-up of the game with respect to permutations of
the doors A, B, C. Consequently, the labels are equally distributed in both weighted
input and weighted outcome space, resulting in equal probability for all three
hypotheses. Here, the input space is determined by different instances in which the
game is originally set up, while the output space is determined by corresponding
instances how the game is ended by the candidate.
Now, the quizmaster opens a door, e.g. C, of which he knows that there is a goat
behind it and which is not the one chosen by the player. Thereby, new information E
is conveyed—which can be accounted for in terms of an additional collective
condition. In light of this new condition, the input states which are incompatible
with E have to be erased. In particular, all input states associated with hypothesis HC
have to be eliminated, because the truth of HC is incompatible with the evidence.
Furthermore, half of the input states of hypothesis HA have to be eliminated, namely
those, in which the quizmaster would have opened door B. By contrast, none of the
input states of HB are deleted because all of them already imply that the quizmaster
opens door C. This leads to the familiar result that in light of the new evidence we
have P(HA) ¼ 1/3 and P(HB) ¼ 2/3.
Obviously, this result can also be calculated via Bayes’ Theorem: P HXjE
ð
Þ ¼
P EjHX
ð
ÞP HX
ð
Þ
PN
i¼1P EjHi
ð
ÞP Hi
ð
Þ. The quantities on the right side refer to the old collective, P(HX|E) on
the left side is equivalent to the probability P(HX) relative to the new collective
incorporating evidence E. In summary, the change in collective conditions due to
novel evidence corresponds to a process of Bayesian updating.
Another example concerns the loaded coin as already discussed in previous
sections—except that this time we are not interested in the event of throwing the
coin, but in the probability of the two hypotheses H1 and H2 that the coin is loaded P
(heads) ¼ 2/3 or P(heads) ¼ 1/3, respectively. Before the coin is thrown for the ﬁrst
time, the evidence does not favor any of the hypotheses and therefore both hypoth-
eses have equal probability 1/2 with respect to a suitably constructed collective.
After the ﬁrst throw, the situation ceases to be symmetric since there is now evidence
in which way the coin might be loaded. Again, this evidence can be integrated in the
collective conditions leading to a change in measure and thus a new probability
distribution over the causal hypotheses. For example, if the result is ‘head’, then all
those input states have to be eliminated that would have led to ‘tail’ in the ﬁrst throw,
i.e. 1/3 of the input states belonging to H1 and 2/3 of the input states belonging to H2.
The new probabilities are consequently P(H1) ¼ 2/3 and P(H2) ¼ 1/3, which is
exactly the result given by Bayes’ Theorem. From the causal perspective, Bayesian
updating can be interpreted as describing how in light of new evidence, which leads
to additional constraints in the collective conditions, the measure over the hypothesis
space has to be adapted.
9.6
Ontic and Epistemic Probabilities
283

Also in the case of probabilities of hypotheses, the ascription of probabilities is
predictive only if one speciﬁes collective and measure, i.e. in particular if one knows
the complete set of (mutually exclusive) causal hypotheses and if one knows or
assumes a measure over these hypotheses that is determined by the collective
conditions. Of course, one also needs to know with which probabilities the different
hypotheses lead to various pieces of evidence, i.e. essentially the causal mapping of
the input to the outcome space. These requirements delineate a fairly restricted range
of application for probabilities of hypotheses—excluding for example several ‘stan-
dard’ applications of subjective Bayesianism like the probabilities of abstract scien-
tiﬁc theories or hypotheses. Since the range of alternatives is not known in these
cases, it seems implausible to construct a collective and relatedly the measure
remains undetermined. If one requires probabilities to be predictive, the range of
hypotheses to which probabilities should be ascribed is thus rather restricted.56
We are therefore in the position to assess the plausibility of the various Bayesian
programs from the perspective of causal probability. Sometimes, the hypothesis
space and the measure are objectively determined by the causal set-up. Consider
for example the following experiment with three urns, each containing both black
and white balls but in different ratios, e.g. 1:2, 1:1, 2:1, corresponding to three
hypotheses. Now, one of these urns is randomly chosen and then balls are drawn
with replacement. Given a certain sequence of draws as evidence, e.g. w-w-b, a
probability for each of the three hypotheses can be calculated, whether it holds for
the chosen urn. In this speciﬁc situation, an objective Bayesian approach is feasible
because all relevant elements are determined by the physical set-up: the hypothesis
space, the initial probability measure over the hypothesis space, and the probability
of evidence given a certain hypothesis is true.
In other circumstances, we might not be so lucky. We may for example be
confronted with limited information about a single urn, e.g. that the colors of the
balls are only black and white and that there are no more than ﬁve balls in the urn. In
this case, the hypothesis space is determined by the set-up but there is ﬂexibility in
the choice of measure since the actual process with which the urn was prepared is
unknown. In analogy to the discussion in point (iii) of Sect. 9.6.2, the Bayesian can
now construct in her mind a collective to which the urn is attributed, e.g. an ensemble
in which every ratio of balls has equal prior probability. With respect to such a
collective, the posterior probabilities of the various hypotheses can then be calcu-
lated taking into account additional evidence. However, the Bayesian might just as
well have chosen a different measure over the hypothesis space and would have
come up with a different result for the posterior probabilities. There is no contradic-
tion, since strictly speaking the probabilities only hold relative to the respective
collective and if the collective conditions are compatible with the partly unknown
56An argument in this direction was already given by Popper, who claimed in a reductio ad
absurdum that given an inﬁnite number of alternatives, the probabilities of scientiﬁc theories
would always be zero. See also Pietsch (2013) for a different argument against ascribing probabil-
ities to scientiﬁc theories or abstract scientiﬁc hypotheses.
284
9
Causal Probability

conditions
of
the
considered
instances.
In
cases,
where
the
measure
is
underdetermined by given knowledge and somewhat arbitrarily construed with
respect to an imagined collective, we may plausibly speak of subjective
Bayesianism.
Of course, much more should be said how Bayesianism is to be integrated into the
framework of causal probability. But the brief discussion above already suggests
how the notion of causal probability allows determining the limits of a Bayesian
approach.
9.7
Conclusion
We have proposed a speciﬁc account of causal probability that ties in with recent
work on objective probabilities in the tradition of the method of arbitrary functions
and with earlier accounts mainly from the nineteenth century, for example by
Cournot, Mill, or von Kries. The causal probability of the present essay broadly
ﬁts with variational induction and the corresponding difference-making account of
causation. Probability is interpreted as degree of causal determination of a phenom-
enon by a given set of conditions.
As a further constraint, we required that one should speak of probabilities only
when the respective weighted ratios are predictive, i.e. when the causal structure in
terms of collective conditions is sufﬁciently speciﬁed such that probabilities can be
unambiguously determined and if the causal structure corresponds to an actual
structure in the world. This delineates the range of application for probabilities
both of events and of hypotheses. It also allows for a reﬁned version of the principle
of indifference, which was termed principle of causal symmetry. Note again that the
principle of causal symmetry does not fall prey to Bertrand-type ambiguities exactly
because it requires that the causal context is sufﬁciently speciﬁed. Regarding the
difﬁcult notion of probabilistic independence a suggestion was sketched how to
connect it to causal irrelevance. On this basis, randomness in the attribute sequence
generated by a probabilistic phenomenon can be established. The mentioned deﬁni-
tion of probability, the notion of causal symmetry, and the causal construal of
probabilistic independence should be considered as a coherent conceptual package
making up causal probability. In a way, causal probability constitutes an extension of
the
essentially
deterministic
framework
of
variational
induction
and
the
corresponding difference-making account of causation to statistical and indetermin-
istic contexts.
9.7
Conclusion
285

References
Abrams, Marshall. 2012. Mechanistic Probability. Synthese 187 (2): 343–375.
———. 2015. Probability and Manipulation: Evolution and Simulation in Applied Population
Genetics. Erkenntnis 80 (3 Suppl): 519–549.
Beisbart, Claus. 2016. A Humean Guide to Spielraum Probabilities. Journal for General Philoso-
phy of Science 47 (1): 189–216.
Berkovitz, Joseph. 2015. The Propensity Interpretation of Probability: A Re-evaluation. Erkenntnis
80: 629–711.
Bernoulli, Jacob. 1713. Ars conjectandi. Basel: Thurneysen.
Bertrand, Joseph. 1889. Calcul des probabilitiés. Paris: Gauthier-Villars.
Bolzano, Bernard. 1837/1972. Theory of Science. Berkeley: University of California Press.
Cournot, Antoine-Augustin. 1843. Exposition de la théorie des chances et des probabilities. Paris:
Hachette.
Fioretti, Guido. 1998. John Maynard Keynes and Johannes von Kries. History of Economic Ideas
VI/1998/3: 51–80.
Gillies, Donald. 2000a. Philosophical Theories of Probability. London: Routledge.
———. 2000b. Varieties of Propensity. The British Journal for the Philosophy of Science 51:
807–835.
Glynn, Luke. 2010. Deterministic Chance. The British Journal for the Philosophy of Science 61:
51–80.
Hacking, Ian. 1971. Equipossibility Theories of Probability. The British Journal for the Philosophy
of Science 22 (4): 339–355.
Hájek, Alan. 2007. The Reference Class Problem is Your Problem Too. Synthese 156: 563–585.
Heidelberger, Michael. 2001. Origins of the Logical Theory of Probability: von Kries, Wittgenstein,
Waismann. International Studies in the Philosophy of Science 15: 177–188.
Hoefer, Carl. 2007. The Third Way on Objective Probability: A Skeptic’s Guide to Objective
Chance. Mind 116: 549–596.
Hopf,
Eberhard.
1936.
Über
die
Bedeutung
der
willkürlichen
Funktionen
für
die
Wahrscheinlichkeitstheorie.
Jahresbericht
der
Deutschen
Mathematikervereinigung
46:
179–195.
Humphreys, Paul. 1985. Why Propensities Cannot Be Probabilities. The Philosophical Review 94:
557–570.
Illara, Phyllis, and Federica Russo. 2014. Causality. Philosophical Theory Meets Scientiﬁc Prac-
tice. Oxford: Oxford University Press.
Jaynes, Edwin T. 2003. Probability Theory: The Logic of Science. Cambridge: Cambridge Uni-
versity Press.
Johns, Richard. 2002. A Theory of Physical Probability. Toronto: University of Toronto Press.
Kamlah, Andreas. 1983. Probability as a Quasi-theoretical Concept: J. v. Kries’ Sophisticated
Account After a Century. Erkenntnis 17: 135–169.
Keynes, John M. 1921. A Treatise on Probability. London: Macmillan.
Kolmogorov, Andrey N. 1956. Foundations of the Theory of Probability. New York: Chelsea
Publishing Company.
Laplace, Pierre Simon de. 1814. Essai Philosophique sur les Probabilités. Paris. Translated into
English as A Philosophical Essay on Probabilities. New York: Wiley, 1902.
Lewis, David. 1980. A Subjectivist’s Guide to Objective Chance. In Studies in Inductive Logic and
Probability, ed. R.C. Jeffrey, vol. II. Berkeley: Berkeley University Press.
———. 1994. Humean Supervenience Debugged. Mind 103: 473–490.
Maxwell, James C. 1860. Illustrations of the Dynamical Theory of Gases. Reprinted in Steven
G. Brush (ed.) Kinetic Theory. Selected Readings in Physics. Vol. 2, 148–171. Oxford:
Pergamon Press.
———. 1867. On the Dynamical Theory of Gases. Philosophical Transactions of the Royal Society
of London 157: 49–88.
286
9
Causal Probability

Mill, John S. 1886. System of Logic. London: Longmans, Green & Co.
Myrvold, Wayne. 2011. Deterministic Laws and Epistemic Chances. In Probability in Physics,
ed. Yemima Ben-Menahem and Meir Hemmo. New York: Springer.
North, Jill. 2010. An Empirical Approach to Symmetry and Probability. Studies in History and
Philosophy of Modern Physics 41: 27–40.
Norton, John. 2008. Ignorance and Indifference. Philosophy of Science 75: 45–68.
Pietsch, Wolfgang. 2013. The Limits of Probabilism. In EPSA11 Perspectives and Foundational
Problems in Philosophy of Science, ed. Vassilios Karakostas and Dennis Dieks, 55–65. Dor-
drecht: Springer.
———. 2014. The Nature of Causal Evidence Based on Eliminative Induction. In P. Illari and
F. Russo, ed. Topoi. https://doi.org/10.1007/s11245-013-9190-y.
———. 2015. The Causal Nature of Modeling with Big Data. Philosophy & Technology. https://
doi.org/10.1007/s13347-015-0202-2.
———. 2016. A Difference-Making Account of Causation. http://philsci-archive.pitt.edu/11913/.
Poincaré, Henri. 1912. Calcul des probabilités. 2nd ed. Paris: Gauthier-Villars.
Pulte, Helmut. 2016. Johannes von Kries’s Objective Probability as a Semi-classical Concept.
Prehistory, Preconditions and Problems of a Progressive Idea. Journal for General Philosophy
of Science 47 (1): 109–129.
Rosenthal, Jacob. 2010. The Natural-Range Conception of Probability. In Time, Chance and
Reduction. Philosophical Aspects of Statistical Mechanics, ed. Gerhard Ernst and Andreas
Hüttemann, 71–91. Cambridge: Cambridge University Press.
———. 2012. Probabilities as Ratios of Ranges in Initial-State Spaces. Journal of Logic, Lan-
guage, and Information 21: 217–236.
Rosenthal, Jacob, and Carsten Seck, eds. 2016. Kries and Objective Probability. Special Issue of
Journal for General Philosophy of Science. Berlin: Springer.
Shackel, Nicholas. 2007. Bertrand’s Paradox and the Principle of Indifference. Philosophy of
Science 74 (2): 150–175.
Strevens, Michael. 1998. Inferring Probabilities from Symmetries. Noûs 32: 231–246.
———. 2006. Bigger than Chaos. Cambridge, MA: Harvard University Press.
———. 2011. Probability Out of Determinism. In Probabilities in Physics, ed. Claus Beisbart and
Stephan Hartmann. Oxford: Oxford University Press.
———. 2013. Tychomancy. Cambridge, MA: Harvard University Press.
———. forthcoming. Stochastic Independence and Causal Connection. Erkenntnis. Preprint: http://
www.strevens.org/research/prob/Interdependence.pdf
Suárez, Mauricio. 2011. Propensities and Pragmatism. Journal of Philosophy 110 (2): 61–102.
Waismann, Friedrich. 1930/1931. Logische Analyse des Wahrscheinlichkeitsbegriffs. Erkenntnis 1:
228–248.
Van Fraassen, Bas C. 1990. Laws and Symmetry. Oxford: Oxford University Press.
von Kries, Johannes A. 1886. Die Principien der Wahrscheinlichkeitsrechnung. Tübingen: Mohr
Siebeck.
von Mises, Richard. 1981. Probability, Statistics and Truth. New York: Dover.
von Plato. 1983. The Method of Arbitrary Functions. The British Journal for the Philosophy of
Science 34: 37–47.
von Smoluchowski, Marian. 1918. Über den Begriff des Zufalls und den Ursprung der
Wahrscheinlichkeitsgesetze in der Physik. Die Naturwissenschaften 6: 253–263.
References
287

Chapter 10
Conclusion
The present book consists of two parts. The ﬁrst part comprising Chaps. 1, 2, 3, and 4
analyzes what kind of scientiﬁc approach data science constitutes. Essentially, data
science is identiﬁed as a phenomenological approach relying primarily on inductive
inferences. More exactly, the prevalent type of induction is variational induction.
The second part comprising Chaps. 5, 6, 7, 8, and 9 develops a conceptual frame-
work and a corresponding inductive methodology that ﬁts the phenomenological and
variational approach of data science. Referring to the title of the book, this episte-
mological framework provides the “conceptual tools for a new inductivism.”
In the present book, the term ‘data science’ mostly refers to the narrow contem-
porary practice of applying machine learning algorithms to big data. However, the
developed epistemological and conceptual framework is more ambitious as it aims to
provide a foundation for any strongly empiricist and inductivist approach in science.
Indeed, the whole book can be read as one long defense of inductivism, which has
been mostly denigrated in the past century. Accordingly, in some chapters there are
only few references to contemporary data-scientiﬁc practice. In a way, the more
narrowly deﬁned data science as machine learning with big data is one modern
example of the epistemological approach laid out in this book, while it also consti-
tutes unquestionable proof that inductivist approaches are feasible and can yield
reliable scientiﬁc results how to predict and manipulate empirical phenomena.
The underlying methodology is one of conceptual analysis. What is causation?
What is analogy? What is probability? Deﬁnitions and explications of fundamental
terms are never arbitrary. Rather, they fundamentally frame the outlook on the whole
ﬁeld in which those deﬁnitions are used. Throughout the second part of the book,
which lays out the framework of basic epistemological concepts, the respective
deﬁnitions and explications are shaped by the causal and variational perspective
which is delineated in the ﬁrst part. While I generally refer to the philosophical
debates concerning many of the discussed topics, I do not always fully engage with
the relevant literature. Otherwise, many of the individual chapters would have
required book-length treatments themselves undermining one of the primary objects
of the book, namely to exhibit the various links between different conceptual
© Springer Nature Switzerland AG 2022
W. Pietsch, On the Epistemology of Data Science, Philosophical Studies Series 148,
https://doi.org/10.1007/978-3-030-86442-2_10
289

analyses. To repeat, these conceptual links mostly result from the common under-
lying causal and variational outlook.
While not all of the book may be easily accessible, I hope that the chosen
approach renders the basic ideas understandable to both scientiﬁc philosophers and
philosophically minded scientists. In the interest of accessibility, most of the chap-
ters are written in a way that they can be read by themselves, which means that some
redundancies were necessary.
Last not least let me express my deep gratitude to the many colleagues, who have
contributed in one way or another to this book, by discussing relevant issues or by
giving detailed feedback on individual chapters, including: Michael Baumgartner,
Paul Bartha, Claus Beisbart, Mathias Frisch, Rafaela Hillerbrand, Balazs Kegl,
Michael Kuhn, Meinard Kuhlmann, Dennis Lehmkuhl, Sabina Leonelli, Samuel
Pedziwiatr, Jacob Rosenthal, Federica Russo, Michael Strevens, Mauricio Suarez,
Sylvester Tremmel and several anonymous referees. I am also grateful to my former
colleagues at Technische Universität München for providing an intellectual atmo-
sphere, in which many of the ideas in this book could be developed, in particular
Hajo Greif, Tobias Jung, Sabine Maasen, Klaus Mainzer, Fred Slanitz and Jörg
Wernecke. I am grateful for all that I have learned from students in many discussions
in various seminars that I taught on topics related to the book.
290
10
Conclusion

Index
A
Ampère, A.-M., 12, 34, 35
Analogy
conceptual, 213–215, 221, 232
counting problem, 209, 210
hypothetical, 208, 211, 212, 215, 216,
224–227, 229, 231, 232
negative, 208, 210, 211, 215–217, 223,
225–229, 231, 232
positive, 208, 210–212, 217, 225–228, 231,
232
predictive, 212, 214–216, 221, 225
two-dimensional approach, 210–211
unknown, 208, 226, 231, 232
Analytic-synthetic distinction, 150, 192
Anderson, C., 184
Artiﬁcial intelligence (AI), xi, xii, 1, 4, 52, 61,
62, 96, 100, 200, 202
Asymmetry
causal, 111, 131–133
time, xiii, 121, 132, 133
B
Bacon, F., 13–15, 29, 41, 47, 77, 79–81, 90,
120, 125, 177, 189, 207
Bacon’s tables, 79, 145
Bartha, P., xiv, 203, 204, 208–211, 215
Baumgartner, M., 118, 122, 128, 129, 134, 135,
141, 142, 153, 220, 223
Bayesian networks, 7
Bayes’ Theorem, 98, 283
Bertrand’s paradox, 239, 250
Big data, 1–9, 12, 18, 25, 33, 52, 109, 110, 161,
184, 185, 236, 289
Breiman, L., 7, 8, 22, 24, 27, 29, 50, 96
C
Carnap, R., xiv, 100, 204–209, 213, 214, 231
Cartwright, N., 8, 38, 43–45, 47, 48, 57, 110,
115, 148, 187, 211, 212, 221
Causal
background/context, 120, 127, 152, 219,
271, 273, 275, 276, 285
chain, 120, 123, 129, 132, 133, 136, 139,
142, 145, 148–150, 155, 177, 223, 254
determinism, 58, 87, 89, 138–140, 151,
181–183, 186, 196, 197, 236, 254, 259,
260
factor, xiii, 39, 53, 54, 83, 91, 93, 95, 98,
118, 124, 127, 128, 133–139, 141, 142,
144, 145, 148–150, 153, 154, 162, 164,
165, 168, 171, 176, 178, 179, 193, 216,
219, 220, 223, 224, 236
hierarchies, 59, 69, 138–145, 192, 194
irrelevance, xiii, xiv, 87, 118–125, 128–130,
132, 133, 137, 139–141, 147–149, 152,
154, 157, 161, 166, 175–179, 181, 204,
216–222, 224, 225, 229, 231, 240, 241,
253–257, 262, 263, 265–268, 272–279,
285
ordering, 118, 132, 133
probability, 45, 99, 112, 119, 137, 144, 151,
183, 185, 218–220, 230, 232, 235–286,
289
© Springer Nature Switzerland AG 2022
W. Pietsch, On the Epistemology of Data Science, Philosophical Studies Series 148,
https://doi.org/10.1007/978-3-030-86442-2
291

Causal (cont.)
relevance, xiii, xiv, 39, 118–125, 128, 129,
131–138, 141, 143, 145, 148, 149, 152,
154, 156–161, 163, 166, 169, 175–179,
181, 192, 216–220, 222, 225, 229, 232,
253, 254, 274–277
relevance in conjunction, 167
symmetry, 239–243, 246, 250, 253,
255–260, 262–272, 277, 279, 283, 285
symmetry, principle of, 239–241, 250, 256,
258, 262, 265, 269–272, 283, 285
transitivity, xiii, 119, 122, 139–145, 149,
171
Causation
asymmetry of, xiii
counterfactual account, xiv, 118
difference-making account, xiv, 42, 53, 55,
105, 118, 119, 148, 149, 151, 154, 155,
157, 162, 176, 180, 187, 253, 285
interventionist account, 221
invariance across changes account, 118
mechanistic account, 117, 118
probabilistic, 105, 218, 233, 238
process account, 117
regularity account, 113, 120, 149, 157
Cause(s)
alternative, 125, 132, 135, 139, 141, 150,
156, 162, 165, 168, 171, 177
common, 52, 76, 136, 155, 156, 177, 212,
218, 224, 236, 238, 274, 281
composition of, 85
plurality of, 87
substitute, 135, 139
Cluster analysis, 198, 199
Common cause, principle of, 212
Complexity
compositional, 6
dynamic, 6
emergent, 6
irreducible, 6
Computational learning theory, 102–105
Concept
ceteris paribus, 190
phenomenological, 189–194
theoretical, 190
Condition
Boolean, 191
causally irrelevant, 122, 128, 155, 164, 216,
253, 254, 274
causally relevant, 91, 97, 122, 125, 128,
129, 135, 136, 139, 142, 145, 155, 163,
165, 166, 191, 216, 217, 219, 253, 254,
259
collective, 256, 262
inus, 143, 179, 191
necessary, 91, 93, 94, 98, 142, 178, 192,
193, 216
range, 240, 241, 253–261, 263–265, 267,
271, 273–281
sufﬁcient, 91, 93, 94, 98, 142, 178, 192,
193, 216
Conﬁrmation function, 205, 206, 209
Counterfactual conditional
difference-making approach, 125, 130
metalinguistic approach, 126
possible worlds approach, 118, 126, 274
semantic approach, 121
supposition approach, 126
Cournot, A.-A., 242, 243, 270, 285
Cukier, K., 8, 52, 110
D
Darwin, C., ix, 82
Data
computational interpretation, 2
diaphoric interpretation, 2, 237
epistemic interpretation, 2
informational interpretation, 2
threshold, 185
Decision trees, 7, 17, 18, 24, 25, 52, 53, 95–99,
112, 117, 185, 194, 198, 202
Deep learning, 61, 63, 66–69, 202
Directed acyclic graphs, 63, 153, 219
Do-calculus, 112, 221
Duhem, P., 30, 33, 34, 38, 43, 45, 56, 57, 59,
60, 131, 157, 192, 211
E
Effect(s)
alternative, 138–139, 142
intermixture of, 88
substitute, 139
Einstein, A., 15, 16, 42, 69
Engineering sciences, 38, 39, 42, 48, 69, 121,
127
Entrenchment of predicates, 198
Equality of cause and effect, 183
Exclusion, method of, 79–81
Exemplars, 40–44, 46
Experimentation
exploratory, xiii, 7, 8, 47–51, 55, 56, 186,
187
hypothesis-directed, 186
theory-driven, 7, 47–50
292
Index

Experimentum crucis, 33
Explanation
causal, 8, 9, 39, 51–53, 110, 112
theoretical, 9, 25, 53, 54, 68, 110–112
unifying, 9, 111
F
Factor
causal, 76, 78, 133–136, 138, 141, 142, 144,
149, 162, 179
effect, 138, 142
inhibiting, 136, 150
Field, causal, 179
Floridi, L., 2, 4
Fourth paradigm, 3
G
Goodman, N., 31, 94, 118, 119, 126, 180, 195,
196, 198
Graßhoff, G., 118, 122, 128, 129, 153
Gradient descent, 65–68
Gray, J., 3
Grue, problem of, 31, 195, 197
H
Hacking, I., 37, 47, 56
Herschel, J., vii, 14, 81–84, 90, 177, 189
Herschel’s rules, 82, 83, 189
Hesse, M., 204, 206, 210, 211
Holism, conﬁrmation, 33, 60, 192
Homogeneity condition, 55, 128, 129
Hume, D., xiii, 30, 31, 73, 77, 113, 114, 119,
120, 179, 180, 195
Humphrey’s paradox, 240, 263, 282
Hypothetico-deductivism, 11, 12, 14–18, 22,
29, 30, 33, 42, 46, 48, 49, 54, 76
I
Incommensurability, 59, 60, 194
Independence
probabilistic, 240, 241, 262, 263, 268,
272–274, 276, 285
statistical, 220, 258, 285
Indeterminism, 131, 181, 183, 196, 230–232,
240, 279, 280
Indifference, principle of, 239–244, 246, 250,
260, 263, 265, 266, 269, 280, 285
Induction
eliminative, xiv, 74–79, 95, 105
enumerative, xiii, xiv, 14, 31, 73–75, 77,
79, 81, 83, 90, 95, 100–102, 113, 180,
182, 195, 198, 204–209, 240, 251–253,
255
new riddle of, 31, 195
problem of, xii, 75, 94, 104, 114, 180, 184,
197, 240, 251
Solomonoff, 100–102
straight rule of, 102, 205
variational, xii–xiv, 14, 49, 54, 58, 68, 69,
73–75, 77–79, 81–84, 86, 87, 89–92,
94–102, 105, 113, 114, 118, 119, 148,
157, 176–185, 187, 189, 192, 194, 196,
197, 204, 207, 231, 236, 238, 240, 251,
253–260, 265, 273, 285, 289
Inductivism, xiv, 5, 7, 11–35, 37, 48, 56–61, 73,
74, 105, 289
Instantial relevance, 209
Insufﬁcient reason, principle of, xiv, 239, 241,
242, 245, 250, 269–272
Intervention, xiii, 8, 45, 55, 81, 111–117, 119,
132, 133, 145, 147, 151–155, 157, 160,
187, 190, 212, 213, 220, 221, 230, 233,
236–238
Inus
complex, xiii, 135, 136, 140, 165, 179, 191
condition, 97, 124, 135, 138, 140, 142, 143,
176, 179, 191
K
Kepler, J., 34, 202
Keynes, J.M., xiv, 77, 125, 180, 182, 204,
207–211, 213, 228, 231, 246
Kitchin, R., 33
K-means clustering, 198
Kolmogorov, A., 100, 273
Kuhn, T., 37, 40, 42, 59, 60, 184
L
Lavoisier, A., 15
Laws
ceteris paribus, 39, 41, 44, 46, 157, 190
phenomenological, 13, 39–46, 48, 50, 54,
56–59, 69, 70, 190, 194
theoretical, 6, 15, 33, 41, 43–45, 49, 50, 56,
57, 68, 70, 190
Leonelli, S., 2, 33, 184
Index
293

Lewis, D., 114, 118, 121, 126, 131, 141, 144,
149, 150, 237, 253, 274
Limited independent variety, 182
Locality, principle of, 182
M
Mach, E., 37, 48, 131, 145
Machine learning
supervised, 95, 198–200
unsupervised, 198
Machine translation, xii, xiii, 6, 9, 19–21
Mackie, J.L., 74, 87, 90–95, 118, 120, 123, 124,
133, 136, 137, 142, 143, 155, 156, 176,
178, 179, 218
Markov condition, causal, 219
Maxwell, J.C., 213, 246, 264, 267, 268
Mayer-Schönberger, V., 8, 110, 111
Mechanism, causal, 53, 111, 117, 152, 153
Method
of agreement, xiii, 75–77, 79, 81, 82, 84, 85,
87, 92, 94, 148, 176–179, 181, 253, 254,
258
of agreement, strict, xiii, 148, 176, 178, 179,
181, 253, 258
of arbitrary functions, xiv, 239, 240,
245–248, 250, 257, 259, 260, 262,
276–278, 280, 285
of concomitant variations, 27, 78, 81, 84,
85, 99, 145–147, 177, 178, 186, 229
of difference, xiv, 8, 76–79, 81, 83–89,
92–94, 97, 99, 102, 120, 127, 128,
146–149, 176–181, 186, 222, 223, 226,
229, 253, 254, 258, 274
of residues, 83–85, 177, 178
Mill, J.S., 14, 15, 29, 30, 74, 77, 81, 83–86, 88,
90, 93, 117, 118, 125, 177, 180, 189,
207, 223, 243, 244, 259, 285
Mill’s methods, 84, 86, 87, 89, 90, 94, 119, 147,
148, 175–187, 189
Modeling
algorithmic, xiv, 23–25, 28, 51, 96
data, 22–25, 27–29
non-parametric, 25–29
parametric, 25, 27–29
N
Naïve-Bayes, 95, 98–99
Natural kinds, 194, 195
Neural networks, 7, 21, 52, 53, 61–70, 95, 96,
99, 112, 117, 159, 160, 191, 198, 199,
202
New Experimentalism, 47, 48
Newton, I., 13–16, 29, 34, 35, 53, 69, 157
Non-parametric regression, 25–27, 99, 185, 186
Non-redundancy, principle of, 134, 135
Norton, J., 74, 75, 77, 78, 203, 210, 265
Norvig, P., 19–21, 27, 96, 103, 104
O
Observable-unobservable distinction, 37, 38
Ockham, William of, 79, 103
Overdetermination, causal, 88, 125, 128, 147,
149, 150
P
Pearl, J., 112, 114, 116, 123, 152, 153, 155, 221
Poincaré, H., 41, 57, 131, 245
Popper, K., 11, 15, 18, 30, 49, 74, 104, 184,
238, 239, 262, 264, 284
Potential for generalization, principle of, 211
Preemption, causal, 88, 120, 122, 125, 128,
147, 149, 150
Principal Principle, 237
Principle of causality, xiii, 180, 181
Prior association, principle of, 211
Probability
causal interpretation, 239, 241, 243, 246,
250–252, 258, 261
classical interpretation, 113
epistemic, 237, 239–244, 246, 248,
252–254, 259–261, 265, 267, 269, 279,
280
far ﬂung frequency mechanistic, 247
frequency interpretation, xiv, 238, 239, 262
logical interpretation, 237, 246, 250
measure, 241, 244, 247, 248, 255–264, 267,
269–272, 277–280, 282–284
microconstant, 246–248
natural range conception, 248, 261
of hypotheses, 241, 261, 280, 282, 285
ontic, 237, 241, 260, 263, 280
propensity interpretation, 238, 239, 262,
263
single-case, 259, 262, 279
SRA approach, 240, 241, 251, 260, 262,
280
subjective interpretation, 237
Probably Approximately Correct
Learning, 102
Problem of induction, xii, xiii, 30–32, 73, 119,
130, 179–183, 195, 230, 249
Propensity, 238–240, 260, 262–264
294
Index

R
Rosenthal, J., 239, 240, 244–246, 248, 249,
261, 277
Rule of succession, 101, 102, 195
Russell, B., 145, 157
Russo, F., 53, 76, 113, 118, 125, 152, 255
Russo-Williamson thesis, 53
S
Science
data-driven, 3, 7, 9, 12, 18, 20, 29, 185
data-intensive, xiii, 3
Scientiﬁc revolutions, 40, 42, 43, 46
Scotus, D., 79
Skyrms, B., 90, 91, 94, 178, 186, 187
Solomonoff, R., 100–102
Spielraum, 244, 248
Strevens, M., 239, 240, 242, 244, 246, 247,
249, 252, 257, 261, 267, 268,
270, 273
Structural equations, 153
Support vector machines, 199, 200
Symmetry, causal, xiii, 239–241, 250, 258, 263,
264, 267–269, 272, 283, 285
T
Tables of discovery, 14
Theory-free science, 184, 186
Theory-ladenness
external, 186
internal, 186
Theory-model distinction, 44
Transitivity, causal, 139, 142, 143
U
Underdetermination, xiv, 30, 33–35, 41, 56, 58,
59, 61, 214
Uniformity of nature, xiii, 31, 180, 182
V
Valiant, L., 102–104, 110
Variable
interruption, 132
proxy, 97, 158, 236
shadowing, 158
stimulation, 132
variation, 7, 17, 42, 49, 55, 97, 185–187
Vapnik-Chervonenkis dimension, 104
von Kries, J., 239, 240, 242, 244–246, 248, 256,
285
von Wright, G.H., 74, 90, 91, 93, 146, 147, 178
W
Whewell , W., vii, 29, 32, 82, 86
Woodward, J., 2, 114, 116, 152, 155, 251
Index
295

