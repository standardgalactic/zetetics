A Theory of Catadioptric Image Formation * 
Simon Baker and Shree K. Nayar 
Department of Computer Science 
Columbia University 
New York, 
Abstract 
Conventional video cameras have limited fields of 
view which make them restrictive for certain applica- 
tions in computational vision. A catadioptric sensor 
uses a combination of lenses and mirrors placed in 
a carefully arranged configuration to capture a much 
wider field of view. When designing a catadioptric sen- 
sor, the shape of the mirror.(s) should ideally be selected 
to ensure that the complete catadioptric system has a 
single effective viewpoint. In this paper, we derive the 
complete class of single-lens single-mirror catadioptric 
sensors which have a single viewpoint and an expres- 
sion for the spatial resolution of a catadioptric sensor 
in terms of the resolution of the camera used to con- 
struct it. We also include a preliminary analysis of the 
defocus blur caused by the use of a curved mirror. 
1 Introduction 
Many applications in computational vision require 
that a large field of view is imaged. Examples include 
surveillance, teleconferencing, and model acquisition for 
virtual reality. Moreover, a number of other appli- 
cations, such as ego-motion estimation and tracking, 
could benefit from enhanced fields of view. Unfortu- 
nately, conventional imaging systems are severely lim- 
ited in their fields of view and so both researchers and 
practitioners have had to resort to using either multiple 
or rotating cameras in order to image the entire scene. 
One effective way to enhance the field of view is to 
use mirrors in conjunction with lenses (see, for exam- 
ple, [Rees, 19701, [Charles et al., 19871, [Nayar, 19881, 
[Yagi and Kawato, 19901, [Hong, 19911, [Goshtasby and 
Gruver, 19933, [Yamazawa et aZ., 19931, [Bogner, 19951, 
[Nalwa, 19961, and [Nayar, 19971). We refer to the gen- 
eral approach of using mirrors in combination with con- 
ventional imaging systems as catadioptric' image for- 
mation. As noted in [Rees, 19701, [Yamazawa et al., 
19951, [Nalwa, 19961, and [Nayar and Baker, 1997a], it is 
highly desirable that a catadioptric system (or, in fact, 
any imaging system) have a single viewpoint (center of 
projection). The reason a single viewpoint is so desir- 
'This work was supported in parts by the DARPAIONR 
MURI Grant N00014-95-1-0601, an NSF National Young Inves- 
tigator Award, and a David and Lucile Packard Fellowship. 
Dioptrics is the science of refracting elements (lenses) whereas 
cotoptrics is the optics of reflecting aurfaces (mirrors). The com- 
bination of refracting and reflecting elements is therefore referred 
to as catadioptrics [Hecht and Zajac, 19741. 
NY 10027 
able is that it permits the generation of geometrically 
correct perspective images from the image(s) captured 
by the catadioptric cameras. These perspective images 
can subsequently be processed using the vast array of 
techniques developed in the field of computational vi- 
sion which assume perspective projection. Moreover, if 
the image is to be presented to a human, as in [Peri 
and Nayar, 19971, it needs to be a perspective image in 
order to not appear distorted. 
In this paper, we begin in Section 2 by deriving the 
entire class of catadioptric systems with a single effec- 
tive viewpoint and which are constructed just using a 
single conventional lens and a single mirror. As we will 
show, the 2-parameter family of mirrors which can be 
used is exactly the class of rotated (swept) conic sec- 
tions. Within this class of solutions, several swept con- 
ics prove to be degenerate solutions and hence imprac- 
tical, while others lead to practical sensors. During our 
analysis we will stop at many points to evaluate the 
merits of the solutions as well as the merits of closely 
related catadioptric sensors proposed in the literature. 
An important property of a sensor that images a 
large field of view is its resolution. The resolution of 
a catadioptric sensor is not, in general, the same as 
that of the sensors used to construct it. In Section 3 
we study why this is the case, and derive an expression 
for the relationship between the resolution of a con- 
ventional imaging system and the resolution of a de- 
rived catadioptric sensor. This expression should be 
carefully considered when constructing a catadioptric 
imaging system in order to ensure that the final sensor 
has sufficient resolution. 
Another optical property which is modified by the 
use of a catadioptric system is focusing. It is well known 
that a curved mirror increases image blur [Hecht and 
Zajac, 19741, and so in Section 4 we analyze this ef- 
fect for catadioptric sensors. Two factors combine to 
cause blur in catadioptric systems: (1) the finite size 
of the lens aperture, and (2) the curvature of the mir- 
ror. We first analyze how the interaction of these two 
factors causes defocus blur and then present some pre- 
liminary numerical results for one specific mirror shape: 
the hyperboloid. The results show that the focal setting 
of a catadioptric sensor using a curved mirror may be 
substantially different to that needed in il conventional 
sensor. Moreover, our analysis illustrates a numerical 
method of computing the relationship between the two 
35 

settings. 
2 The Fixed Viewpoint Constraint 
The fixed viewpoint constraint is a requirement that 
a catadioptric sensor only measure the intensity of light 
passing through a single point in 3-D space. In other 
words, the catadioptric sensor can only sample the 5-D 
plenoptic function [Adelson and Bergen, 19911 at a sin- 
gle point. The fixed 3-D point at which a catadioptric 
sensor samples the plenoptic function will be referred 
to as the effective viewpoint. 
Suppose we use a single conventional camera as the 
only sensing element and a single mirror as the only 
reflecting surface. If the camera is an ideal perspective 
camera and we ignore defocus blur, it can be modeled 
by the point through which the perspective projection 
is performed; i.e. the effective pinhole. Then, the fixed 
viewpoint constraint requires that each ray of light pass- 
ing through the effective pinhole of the camera (which 
was reflected by the mirror) would have passed through 
the effective viewpoint, if it had not been reflected by 
the mirror. 
2.1 Derivation of the Constraint Equation 
Without loss of generality we can assume that the ef- 
fective viewpoint v of the catadioptric system lies at the 
origin of a Cartesian coordinate system. Suppose that 
the effective pinhole is located at the point p. Then, 
again without loss of generality, we can assume that 
the z-axis D lies in the direction v3. Moreover, since 
perspective projection is rotationally symmetric about 
any line through p, the mirror can be assumed to be 
a surface of revolution about the z-axis 8. Therefore, 
we work in the 2-D Cartesian frame (v, 2,;) where f. is 
a unit vector orthogonal to i, and try to find the 2- 
dimensional profile of the mirror z(r) = z(x,y) where 
r = d m .  
Finally, if the distance from v to p is 
denoted by the parameter c, we have 
= (0,O) and 
p = (0, c). See Figure 1 for an illustration2 of the coor- 
dinate frame. 
We begin the translation of the fixed viewpoint con- 
straint into symbols by denoting the angle between an 
incoming ray from a world point and the r-axis by 8. 
Suppose that this ray intersects the mirror at the point 
( z ,  r). Then, since we assume that it also passes through 
the origin v = (0,O) we have the relationship: 
9 
effective viewpoint, v=(O,O) 
2 
T 
tan8 = -. 
L 
I 
r 
; 
=- 
21n Figure 1 we have drawn the image plane as though it 
were orthogonal to the z-axis !i 
indicating that the optical axis 
of the camera is (anti) parallel to 2. In fact, the effective view- 
point v and the axis of symmetry of the mirror profile .(.) 
need 
not necessarily lie on the optical axis. Since perspective projec- 
tion is rotationally symmetric with respect to any ray that passes 
through the pinhole p, the camera could be rotated about p so 
that the optical axis is not parallel to the z-axis, and moreover 
the image plane can be rotated independently so that it is no 
longer perpendicular to z. 
image of world point 
effective pinhole, p=(O,c) \ 
+ 
I 
I 
I 
, 
I I 
I 
I 
I C  
I 
4 
I + 
z 
image plane 
If we denote by Q the angle between the reflected ray 
and the (negative) r-axis, we also have: 
c - 2  
T 
tan& = - 
since the reflected ray must pass through the pinhole 
p = (0,c). Next, if ,L? is the angle between the z-axis 
and the normal to the mirror at the point ( T , z ) ,  we 
have: 
da - = -tanp. 
dr 
(3) 
Our final geometric relationship is due to the fact that 
we assume the mirror to be specular. This means that 
the angle of incidence must equal the angle of reflection. 
So, if y is the angIe between the reflected ray and the 
z-axis, we have y = 90' - Q and 6 +a + 2p + 27 = 180'. 
36 

(See Figure 1 for an illustration of this constraint.) 
Eliminating y from these two expressions and rearrang- 
ing gives 2p = (Y - 8. Then, taking the tangent of both 
sides yields: 
(4) 
tana - tan6 
1 + tanatarid' 
- - 
2 tanp 
1 - tan2p 
Substituting from Equations (l), (2), and (3) and rear- 
ranging yields the fixed viewpoint constraint equation: 
2.2 General Solution of the Constraint 
The first step in the solution of the fixed viewpoint 
constraint equation is to solve it as a quadratic to yield 
an expression for the surface slope: 
dz 
(zz - r2 - cz) f dr2c2 + (z2 + r2 - C Z ) ~  
* (6) 
_ -  
- 
dr 
r(2z - c) 
The next step is to substitute y = z - f and set b = 4 
which yields: 
(7) 
Then, after substituting 2rx = y2 + r2 - b2 and rear- 
ranging we have: 
Integrating both sides with respect to r results in: 
In x+ 
b +a: 
= f l n r + C  
( 7) 
where C is the constant of integration. Hence, 
(9) 
where IC = 2eC > 0 is a constant. By back substituting, 
rearranging, and simplifying we arrive at the two equa- 
tions which comprise the general solution of the fixed 
viewpoint constraint equation: 
(2 - ;)2 - T 2  (f - 1) = ; 
(Y) 
(IC 2 2) (11) 
( z - $ + r 2 ( 1 + ~ )  
= (T) 
2k + c2 
(k>O). (12) 
In the first of these two equations the constant param- 
eter k is constrained by k 2 2 (rather than IC > 0) since 
0 < k < 2 leads to complex solutions. 
2.3 Specific Solutions of the Constraint 
Together, the two relations in Equations (11) and 
(12) represent the entire class of mirrors that satisfy the 
fixed viewpoint constraint. A quick glance at the form 
of these equations, reveals that the mirror profiles are all 
conic sections. Hence, the 3-D mirrors themselves are 
swept conic sections. However, as we shall see, although 
every3 conic section is theoretically a solution of one 
of these two equations, a number of themi prove to be 
impractical and only some lead to realizable sensors. 
We will now describe each of the solutions in detail. 
2.3.1 Planar Mirrors 
the cross-section of a planar mirror: 
In Solution (ll), if we set IC = 2 and c > 0, we get 
C 
z = -. 
2 
This plane is the one which bisects the line segment v"p 
joining the viewpoint and the pinhole. Moreover, by 
examining the other solutions it follows that the per- 
pendicular bisector of v$ is the only planar solution. 
An immediate corollary of this result is that, for a 
single fixed pinhole, no two different planar mirrors can 
share the same viewpoint. Unfortunately, a single pla- 
nar mirror does not enhance the field of view, since, 
discounting occlusions, the same camera moved from 
p to v and reflected in the mirror would lhave exactly 
the same field of view. It follows that it, is impossi- 
ble to increase the field of view by packing an arbitrary 
nu,mber of planar mirrors (pointing in different direc- 
tions) in front of a single conventional imaging system, 
while still obeying the fixed viewpoint Constraint. On 
the other hand, in applications such as stereo where 
multiple viewpoints are a necessary requirement, the 
multiple views of a scene can be captured by a single 
camera using multiple planar mirrors. See, ffor example, 
[Goshtasby and Gruver, 19931. 
This brin s us to the panoramic camera ,proposed by 
Nalwa [1996f To ensure a single viewpoint while using 
multiple planar mirrors, Nalwa [1996] has arrived at a 
design that uses four separate imaging systems. Four 
planar mirrors are arranged in a square-based pyramid 
and each of the four cameras is placed above one of 
the faces of the pyramid. The effective pinholes of the 
cameras are moved until the four effective viewpoints 
(i.e. the reflections of the pinholes in the mirrors) co- 
incide. The result is a sensor that has a single effec- 
tive viewpoint and a panoramic field of view of approx- 
imately 360" x 50". The panoramic image is of relatively 
high resolution since it is generated from the four im- 
ages captured by the four cameras. Nalwav's sensor is 
3There is one conic section which is an exception: 
the 
parabola. Although the parabola is not a solution off either Equa- 
tion (11) or Equation (12) for finite values of c a.nd IC, it is a 
solution of Equation (11) in the limit that c --t 00, IC --t 00, and 
c/k = h, a constant. As shown in [Nayar and Baker, 1997a], this 
limiting caSe corresponds to orthographic projection. Moreover, 
In that setting the parabola does yield a practical omnidirectional 
sensor with a number of advantageous properties [Nayar, 19971. 
37 

straightforward to implement, but requires four of each 
component: i.e. four cameras and four lenses. 
2.3.2 Conical Mirrors 
conical mirror with circular cross section: 
In Solution (ll), if we set c = 0 and IC 2 2, we get a 
See Figure 2 for an illustration of this solution. The 
angle at the apex of the cone is 27 where t a n r  = 
d
m
.
 
This might seem like a reasonable solu- 
tion, but since c = 0 the pinhole of the camera must 
be at the apex of the cone. This implies that the only 
rays of light entering the pinhole from the mirror are 
the ones which graze the cone and so do not originate 
from (finite extent)' objects in the world (see Figure 2.) 
Hence, the cone (with the pinhole at the vertex) is a 
degenerate solution of no practical value. 
the viewpoint is no longer a single point [Nalwa, 19961. 
If the pinhole lies on the axis of the cone at a distance 
e from the apex of the cone, the locus of the effective 
viewpoint is a circle. The radius of the circle is easily 
seen to be e -cos 2 ~ .  
If T > 60°, the circular locus lies in- 
side (below) the cone, if T < 60" the circular locus lies 
outside (above) the cone, and if T = 60" the circular 
locus lies on the cone. 
2.3.3 Spherical Mirrors 
the spherical mirror: 
In Solution (12), if we set c = 0 and IC > 0, we get 
L- 
image plane 
image of world point 
where: 
Figure 2: The conical mirror is a solution of the fixed view- 
point constraint equation. Since the pinhole is located at 
the apex of the cone, this is a degenerate solution of little 
practical value. If the pinhole is moved away from the apex 
of the cone (along the axis of the cone), the viewpoint is no 
longer a single point but rather lies on a circular locus. If 27. 
is the angle at the apex of the cone, the radius of the circular 
locus of the viewpoint is e .  cos 27, where e is the distance of 
the pinhole from the apex along the axis of the cone. Fur- 
cone, if 7 < 60" the circular locus lies outside (above) the 
cone, and if T = 60" the circular locus lies on the cone. 
ther, if 7 > 60°, the circular locus lies inside (below) the 
The cone has been used for wide-angle imaging a 
number of times [Yagi and Kawato, 19901 [Yagi and 
Yachida, 19911 [Bogner, 19951. In these implementa- 
tions the pinhole is placed quite some distance from the 
apex of the cone. It is easy to show that in such cases 
(15) 
Like the cone, this is a solution with little practical 
value. Since the viewpoint and pinhole coincide at the 
center of, the sphere, the observer only sees itself. 
The sphere has also been used to enhance the field 
of view several times [Hong, 19911 [Bogner, 19951 [Mur- 
phy, 19953. In these implementations, the pinhole is 
placed outside the sphere and so there is no single ef- 
fective viewpoint. The locus of the effective viewpoint 
can be computed in a straightforward manner using a 
symbolic mathematics package, but it is a quite com- 
plex function of the distance between the center of the 
sphere and the pinhole. Spheres have also been used 
in stereo applications [Nayar, 19881, but as described 
before multiple viewpoints are a requirement for stereo. 
2.3.4 Ellipsoidal Mirrors 
In Solution (12), when IC > 0 and c > 0, we get the 
ellipsoidal mirror: 
The ellipsoid is the first solution that can actually be 
used to enhance the field of view. As shown in Fig- 
ure 3, if the viewpoint and pinhole are at the foci of the 
ellipsoid, and the mirror is taken to be the section of 
the ellipsoid that lies below the viewpoint (i.e. z < O), 
the effective field of view is the entire upper hemisphere 
z 2 0. It is also possible to cut the ellipsoid with other 
planes passing through v, but it appears there is little 
to be gained by doing so. 
2.3.5 
Hyperboloidal Mirrors 
hyperboloidal mirror: 
In Solution (ll), when IC > 2 and c > 0, we get the 
where: 
38 

image plane 
image of world point 
1 
Figure 3: The ellipsoidal mirror satisfies the fixed viewpoint 
constraint when the pinhole and viewpoint are located at the 
two foci of the ellipsoid. If the ellipsoid is terminated by the 
horizontal plane passing through the viewpoint z = 0, the 
field of view is the entire upper hemisphere z > 0. 
As seen in Figure 4, the hyperboloid also yields a realiz- 
able solution. The curvature of the mirror and the field 
of view both increase with IC. In the other direction, 
in the limit IC -+ 2, the hyperboloid flattens out to the 
planar mirror of Section 2.3.1. 
Rees [1970] appears to have been first to use a hy- 
perboloidal mirror with a perspective lens to achieve a 
large field of view camera system with a single view- 
point. Later, Yamazawa et al. [1993] [1995] also rec- 
ognized that the hyperboloid is indeed a practical solu- 
tion and implemented a sensor designed for autonomous 
navigation. 
3 Resolution of a Catadioptric Sensor 
In this section, we assume that the conventional cam- 
era used in the catadioptric sensor has a frontal image 
plane located at a distance U from the pinhole, and that 
the optical axis of the camera is aligned with the axis of 
symmetry of the mirror. See Figure 5 for an illustration 
of this scenario. Then, the definition of resolution which 
we will use is the following. Consider an infinitesimal 
area dA on the image plane. If this infinitesimal pixel 
images an infinitesimal solid angle dv of the world, the 
resolution of the sensor (as a function of the point on 
the image plane at the center of the infinitesimal area 
\r- 
image plane 
image of world point 
Figure 4: The hyperboloidal mirror satisfies the fixed view- 
point constraint when the pinhole and the viewpoint are 
located at the two foci of the hyperboloid. This solution 
does produce the desired increase in field of viiew. 
dA) is: 
dA 
dv ' - 
If $ is the angle made between the optical axis and 
the line joining the pinhole to the center of the infinites- 
imal area dA (see Figure 5), the solid angle subtended 
by the infinitesimal area dA at the pinhole is: 
. 
(21) 
dA * COS $ - dA cos3 {) 
dw = 
- 
212 / cos2 $ 
U2 
Therefore, the resolution of the conventional camera is: 
dA 
U 2  
- = -  
dw 
cos3$,' 
Then, the area of the mirror imaged by the infinitesimal 
area dA is: 
(23) 
dw 
(C - z ) ~  - dA * (C - . z ) ~  
* COS$ - 
dS = 
- 
cos q5 cos2 + 
U 2  cos q5 
where q5 is the angle between the normal to the mirror 
at ( T , z )  and the line joining the pinhole to the mirror 
point ( T , z ) .  Since reflection at the mirror is specular, 
39 

pixel area, dA 
image of world point 
-4 
image plane 
4 
,
,
 
I 
I 
optical axis 
I I 
U :  
I 
solid angle, d o  
P
2
 
viewpoint, v=(O,O) 
Figure 5: The geometry used to derive the spatial resolution 
of a catadioptric sensor. We assume that the conventional 
sensor has a frontal image plane which is located at a dis- 
tance U from the pinhole and that the optical axis is aligned 
with the z-axis 8. 
the solid angle of the world imaged by the catadioptric 
camera is: 
d S  * cos4 
dA ( C  - z ) ~  
9 COS$ 
. 
(24) 
- 
dv = 
- 
r2 + z2 
U 2  (r2 + 9) 
Hence, the resolution of the catadioptric camera is: 
- 
- 
- 
dA - u2(r2 + .z2) 
dv 
(C - z ) ~  
. COS@ 
(e - z)2 
dw * 
- 
But, since: 
(e - z)2 
(c - z)2 + T2 
cos2$ = 
Hence, the resolution of the catadioptric camera is the 
resolution of the conventional camera used to construct 
it multiplied by a factor of 
r2 + z2 
(c - z)2 + T2 
where (T, z) is the point on the mirror being imaged. 
The first thing to note from Equation (27) is that for 
the planar mirror z = $, the resolution of the catadiop- 
tric sensor is the same as that of the conventional sensor 
used to construct it. This is as expected by symmetry. 
Secondly, note that the factor in Equation (28) is the 
square of the distance from the point (T, z) to the effec- 
tive viewpoint v divided by the square of the distance 
to the pinhole p. Using simple properties of ellipsoids 
and hyperboloids it follows that for these two mirror 
shapes, the factor in Equation (28) increases with r. 
Hence both hyperboloidal and ellipsoidal catadioptric 
sensors will have highest resolution around the periph- 
ery, a useful property for certain applications such as 
teleconferencing. 
4 Defocus Blur of a Catadioptric Sensor 
Two factors combine to cause defocus blur in cata- 
dioptric imaging systems (that is, in addition to the 
normal causes in conventional dioptric systems, such as 
diffraction and lens aberrations): (1) the finite size of 
the lens aperture, and (2) the curvature of the mirror. 
In this section we investigate this effect for the hyper- 
boloid mirror. (Generalization to the other mirrors is 
straightforward.) We proceed by considering a fixed 
point in the world and a fixed point in the lens. We 
find the point on the curved mirror which reflects a ray 
of light from the world point through the lens point. 
Then, we compute where on the image plane this mir- 
ror point is imaged. By considering the locus of imaged 
mirror points as the lens point varies, we can compute 
the area of the image plane onto which a fixed world 
point is imaged. 
To perform this analysis we need to work in 3-D. We 
use the 3-D Cartesian frame (v, ;G,jr, 2) where v is the 
location of the effective viewpoint, p is the location of 
the effective pinhole, i is a unit vector in the direction 
v$, and the vectors 2 and ;fr are orthogonal unit vectors 
in the plane z = 0. As before, we assume that the effec- 
tive pinhole is located at a distance c from the effective 
viewpoint. Moreover, a3 in Section 3, we assume that 
the conventional camera used in the catadioptric sensor 
has a frontal image plane located at a distance U from 
the pinhole and that the optical axis of the camera is 
aligned with the z-axis. Finally, we assume that the 
effective pinhole of the lens is located at the center of 
the lens and that the lens has a circular aperture. See 
Figure 6 for an illustration of this configuration. 
Consider a point m = (z, y, z) on the mirror and a 
point w = +(x,y,z) 
in the world, where 1 > Ilmll. 
Then, since the hyperboloid mirror satisfies the fixed 
viewpoint constraint, a ray of light from w which is 
reflected by the mirror at m passes directly through the 
center of the lens (i.e. the pinhole.) This ray of light 
is known as the principal ray [Hecht and Zajac, 19741. 
Next, suppose a ray of light from the world point w is 
reflected at the point ml = (zl,yl,zl) 
os the mirror 
and then passes through the lens point 1 = (d cos A, d .  
sin A, e). In general, this ray of light will not be imaged 
mll 
40 

t
o
 
\ 
I
,
 
I 
I mirror 
image plane, z=c+u 
' 
pinhole, p=(O,O,c) 
world point, w=A 
(x,y,z) 
\ 
\ 
principal ray 
viewpoiint, v=(o,o,o) 
Figure 6: The geometry used to analyze the defocus blur. 
We work in the 3-D Cartesian frame (v, 
Et, f, 
2 )  where x and 
f are orthogonal unit vectors in the plane z = 0. In addition 
to the assumptions of Section 3, we also assume that the 
effective pinhole is located at the center of the lens and that 
the lens has a circular aperture. 
at the same point on the image plane as the principal 
ray. When this happens there is defocus blur. The locus 
of the intersection of the incoming rays through 1 and 
the image plane as 1 varies over the lens is known as the 
blur region or region of confusion [Hecht and Zajac, 
19741. For an ideal thin lens, the blur region is circular 
and so is often referred to as the blur circle [Hecht and 
Zajac, 19741. As is shown in [Nayar and Baker, 1997b], 
for a catadioptric sensor the shape of the blur region is 
not, in general, circular. 
If we know the points ml and 1, we can find the 
point on the image plane where the ray of light through 
these points is imaged. First, the line through ml in 
the direction 11& 
is extended to intersect the focused 
plane. 
By the thin lens law [Hecht and Zajac, 19741 
the focused plane is: 
where f is the focal length of the lens and U is the dis- 
tance from the focal plane to the image plane. Since 
all points on the focused plane are perfectly focused, 
the point of intersection on the focused plane can be 
mapped onto the image plane using perspective projec- 
tion. Hence, the x and y coordinates of the intersection 
of the ray through 1 and the image plane are the x and 
y coordinates of: 
1 
--(l+--(mrU 
U 
U 
V 
and the z coordinate is the z coordinate of the image 
plane c + U. 
Given the lens point 1 = (d COSX, d sinX,c) and 
the world point w = &(z, 
y, z), there art? three con- 
straints on the point m1 = (XI, 
y ~ ,  
z1). First, ml must 
lie on the mirror and so we have: 
k .- 2 
(a - ;)'-(xf 
+y:) (: - 1) = 
(-k). (31) 
Secondly, the incident ray (w - ml), the reflected ray 
(ml - l), and the normal to the mirror at ml must lie 
in the same plane. The normal to the mirror at ml lies 
in the direction: 
n = ([k - 21x1, [k - 2]yl,c - 2 ~ 1 ) -  
(32) 
Hence, the second constraint is: 
n.(w-ml)A(l-ml) = 0. 
(33) 
Finally, the angle of incidence must equal the angle of 
reflection and so the third constraint on the point ml 
is: 
n . (w - ml) 
n (1 - ml) 
These three constraints on ml are all multivariate poly- 
nomials in z1, y1, and z1: Equation (31) and Equa- 
tion (33) are both of order 2, and Equation (34) is of6 
order 5. We were unable to find a closed form solution 
to these three equations (Equation (34) has 25 terms in 
general and so it is probable that none exists) but we 
did investigate numerical solutions. Some of the results 
are presented in Figure 7. (The interested reader is re- 
ferred to [Nayar and Baker, 1997133 for a more complete 
presentation of the results, including an explanation of 
the 2 local minima in Figure 7.) 
For the numerical solutions we set c = 1 meter, used 
the hyperboloid mirror with k = 4, and assumed the 
radius of the lens to be 5 centimeters. We considered 
the point m = (0.125,0.0,0.125) on the mirror and set 
the distance from the viewpoint to the world point w 
to be 1 = 5 meters. In Figure 7 we plot the ;%rea of the 
blur region (on the ordinate) against the distance to the 
focused plane U (on the abscissa). The smaller the area 
of the blur region, the better focused the ima.ge will be. 
We see from Figure 7 that the area never reaches exactly 
0, and so an image formed using this catadioptric sensor 
can never be perfectly focused. However, it should be 
emphasized that the minimum area is very small, and 
in practice there is no problem focusing the image for 
a single world point. Moreover, is is possible to use 
additional corrective lenses to compensate for most of 
this effect [Hecht and Zajac, 19741. 
(34) 
- 
- 
Ilw - mill 
111- mill 
* 
41 

4c05 ""I \ 
/ l  
'1 ;
1 os 
1 1  
I IS 
1 2  
I 25 
Distance to the Focused Plane 
v = - 
(in meters) 
U - f  
Figure 7: The area of the blur region plotted against the 
distance to the focused plane 
= 3 
for a point m = 
(0.125,0.0,0.125) on the hyperboloid mirror with k = 4. In 
this example, we have c = 1 meter, the radius of the lens 
5 centimeters, and the distance from the viewpoint to the 
world point I = 5 meters. The area never becomes exactly 0 
and so the image can never be perfectly focused. However, 
the area does become very small and so focusing on a single 
world point is not a problem in practice. 
It is interesting to note that the distance at which 
the image of the world point will be best focused (i.e. 
somewhere in the range 1.05-1.2 meters) is much less 
than the distance from the pinhole to the world point 
(approximately 1 meter from the pinhole to the mirror 
and then 5 meters from the mirror to the world point). 
The reason for this phenomenon is that the mirror is 
convex and so tends to increase the divergence of rays 
emanating from the world point. 
5 
Summary 
In this paper we have studied three design criteria 
of catadioptric sensors: (1) the shape of the mirrors, 
(2) the resolution of the cameras, and (3) the focus 
settings of the cameras. In particular, we have derived 
the complete class of mirrors that can be used with a 
single camera, found an expression for the resolution of 
a catadioptric sensor in terms of the resolution of the 
conventional camera used to construct it, and presented 
a preliminary analysis of defocus blur. 
References 
[Adelson and Bergen, 19911 E.H. Adelson and J.R. 
Bergen. The plenoptic function and elements of early 
vision. In Landy and Movshon, editors, Computa- 
tional Models of Visual Processing, chapter 1. MIT 
Press, 1991. 
[Bogner, 19951 S. Bogner. Introduction to panoramic 
imaging. In Proceedings of the IEEE SMC Confer- 
ence, pages 3100-3106, October 1995. 
[Charles et al., 19871 J.R. Charles, R. Reeves, and 
C. Schur. HowFto build and use an all-sky camera. 
Astronomy Magazine, April 1987. 
[Goshtasby and Gruver, 19931 A. Goshtasby and W.A. 
Gruver. Design of a single-lens stereo camera system. 
Pattern Recognition, 26(6):923-937, 1993. 
[Hecht and Zajac, 19741 E. Hecht and A. Zajac. Optics. 
Addison-Wesley, 1974. 
[Hong, 19911 J. Hong. Image based homing. In Pro- 
ceedings of the IEEE International Conference on 
Robotics and Automation, May 1991. 
[Murphy, 19951 J.R. Murphy. Application of panoramic 
imaging to a teleoperated lunar rover. In Proceedings 
of the IEEE SMC Conference, October 1995. 
[Nalwa, 19961 V.S. Nalwa. 
A true omnidirectional 
viewer. Technical report, Bell Laborat,ories, Holmdel, 
NJ 07733, USA, February 1996. 
[Nayar and Baker, 1997aI S.K. Nayar and S. Baker. 
Catadioptric image formation. In Proceedings of the 
1997 DARPA Image Understanding Workshop, pages 
1431-1437, New Orleans, May 1997. 
[Nayar and Baker, 1997bI S.K. Nayar and S. Baker. A 
theory of catadioptric image formation. Technical 
Report CUCS-015-97, Department of Computer Sci- 
ence, Columbia University, USA, April 1997. 
[Nayar, 19881 S.K. Nayar. Sphereo: Recovering depth 
using a single camera and two specular spheres. In 
Proceedings of SPIE: Optics, Illumination, and Im- 
age Sensing for Machine Vision 11, November 1988. 
Catadioptric omnidirec- 
tional camera. In Proceedings of the 1997 Conference 
on Computer Vision and Pattern Recognition, pages 
482-488, June 1997. 
[Peri and Nayar, 19971 V. Peri and S.K. Nayar. Gener- 
ation of perspective and panoramic video from omni- 
directional video. In Proceedings of the 1997 DARPA 
Image Understanding Workshop, New Orleans, May 
1997. 
[Rees, 19701 D.W. Rees. Panoramic television viewing 
system. United States Patent No. 3,505,465, April 
1970. 
[Yagi and Kawato, 19901 Y. Yagi and S. Kawato. 
Panoramic scene analysis with conic projection. 
In Proceedangs of the International Conference on 
Robots and Systems, 1990. 
[Yagi and Yachida, 19911 Y. Yagi and M. Yachida. 
Real-time generation of environmental map and ob- 
stacle avoidance using omnidirectional image sensor 
with conic mirror. In Proceedings of the 1991 Confer- 
ence on Computer Vision and Pattern Recognition, 
pages 160-165, June 1991. 
[Yamazawa et al., 19931 K. Yamazawa, Y. Yagi, and 
M. Yachida. Omnidirectional imaging with hyper- 
boloidal projection. In Proceedings of the Interna- 
tional Conference on Robots and Systems, 1993. 
[Yamazawa et al., 19951 K. Yamazawa, Y. Yagi, and 
M. Yachida. Obstacle avoidance with omnidirectional 
image sensor HyperOmni Vision. In Proceedings of 
the IEEE International Conference on Robotics and 
Automation, pages 1062-1067, May 1995. 
[Nayar, 19971 S.K. Nayar. 
42 

