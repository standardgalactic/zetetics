“Zero-Shot” Super-Resolution using Deep Internal Learning
Assaf Shocher∗
Nadav Cohen†
Michal Irani∗
∗Dept. of Computer Science and Applied Math, The Weizmann Institute of Science, Israel
†School of Mathematics, Institute for Advanced Study, Princeton, New Jersey
Project Website: http://www.wisdom.weizmann.ac.il/∼vision/zssr/
Abstract
Deep Learning has led to a dramatic leap in Super-
Resolution (SR) performance in the past few years. How-
ever, being supervised, these SR methods are restricted to
speciﬁc training data, where the acquisition of the low-
resolution (LR) images from their high-resolution (HR)
counterparts is predetermined (e.g., bicubic downscaling),
without any distracting artifacts (e.g., sensor noise, image
compression, non-ideal PSF, etc). Real LR images, how-
ever, rarely obey these restrictions, resulting in poor SR re-
sults by SotA (State of the Art) methods. In this paper we in-
troduce “Zero-Shot” SR, which exploits the power of Deep
Learning, but does not rely on prior training. We exploit
the internal recurrence of information inside a single im-
age, and train a small image-speciﬁc CNN at test time, on
examples extracted solely from the input image itself. As
such, it can adapt itself to different settings per image. This
allows to perform SR of real old photos, noisy images, bi-
ological data, and other images where the acquisition pro-
cess is unknown or non-ideal. On such images, our method
outperforms SotA CNN-based SR methods, as well as previ-
ous unsupervised SR methods. To the best of our knowledge,
this is the ﬁrst unsupervised CNN-based SR method.
1. Introduction
Super-Resolution (SR) from a single image has recently
received a huge boost in performance using Deep-Learning
based methods [3, 9, 8, 11, 12]. The recent SotA (State of
the Art) method [12] exceeds previous non-Deep SR meth-
ods (supervised [21] or unsupervised [4, 5, 6]) by a few dBs
– a huge margin! This boost in performance was obtained
with very deep and well engineered CNNs, which were
trained exhaustively on external databases, for lengthy pe-
riods of time (days or weeks). However, while these exter-
nally supervised1 methods perform extremely well on data
satisfying the conditions they were trained on, their perfor-
mance deteriorates signiﬁcantly once these conditions are
not satisﬁed.
For example, SR CNNs are typically trained on high-
quality natural images, from which the low-resolution (LR)
images were generated with a speciﬁc predeﬁned down-
scaling kernel (usually a Bicubic kernel with antialiasing
– MATLAB’s default imresize command), without any dis-
tracting artifacts (sensor noise, non-ideal PSF, image com-
pression, etc.), and for a predeﬁned SR scaling-factor (usu-
ally ×2, ×3 or ×4; assumed equal in both dimensions).
Fig. 2 shows what happens when these conditions are not
satisﬁed, e.g., when the LR image is generated with a non-
ideal (non-bicubic) downscaling kernel, or contains aliasing
effects, or simply contains sensor noise or compression arti-
facts. Fig. 1 further shows that these are not contrived cases,
but rather occur often when dealing with real LR images –
images downloaded from the internet, images taken by an
iPhone, old historic images, etc. In those ‘non-ideal’ cases,
SotA SR methods often produce poor results.
In this paper we introduce “Zero-Shot” SR (ZSSR),
which exploits the power of Deep Learning, without rely-
ing on any prior image examples or prior training. We ex-
ploit the internal recurrence of information within a single
image and train a small image-speciﬁc CNN at test time,
on examples extracted solely from the LR input image itself
(i.e., internal self-supervision). As such, the CNN can be
adapted to different settings per image. This allows to per-
form SR on real images where the acquisition process is un-
known and non-ideal (see example results in Figs. 1 and 2).
On ‘non-ideal’ images, our method outperforms externally-
trained SotA SR methods by a large margin.
The recurrence of small pieces of information (e.g.,
small image patches) across scales of a single image,
1We use the term “supervised” for any method that trains on exter-
nally supplied examples (even if their generation does not require manual
labelling).
1
arXiv:1712.06087v1  [cs.CV]  17 Dec 2017

(a) Historic image: Check-point Charlie (end of World-War II) – SR × 2
ZSSR (ours)
EDSR [12]
(b) iPhone image – SR × 3
(c) Historic image: JFK funeral – SR × 2
EDSR [12]
ZSSR (ours)
(d) Outdoor image downloaded from the Internet – SR × 2
EDSR [12]
ZSSR (ours)
EDSR [12]
ZSSR (ours)
Figure 1: SR of real images (unknown LR acquisition process). Real-world images rarely obey the ‘ideal conditions’
assumed by supervised SR methods. For example, old historic photos (a,c), images taken by smartphones (b), random images
on the Internet (d), etc. Since ZSSR trains at test time on examples extracted from the test image, it is better at performing SR
‘In-the-Wild’ (i.e., in unconstrained and unknown settings). Full sized images can be found on our project website.
2

(a) SR under aliasing:
Ground truth
EDSR+ [12]
ZSSR (ours)
(PSNR /SSIM)
( 21.64 / 0.6641)
(25.02 / 0.7658)
(b) SR under unknown non-ideal downscaling kernel:
Ground truth
EDSR+ [12]
ZSSR (ours)
(PSNR /SSIM)
(24.44 / 0.7006)
(27.62 / 0.8367)
Figure 2: SR of ‘non-ideal’ LR images – a controlled experiment. (a) LR image generated with aliasing (donwscaling
kernel is a delta function). (b) LR image generated with a non-ideal downscaling kernel. The unknown image-speciﬁc kernel
is estimated directly from the LR test image using [14], and fed into our image-speciﬁc CNN as the downscaling kernel (note
that externally-trained networks cannot make use of such image-speciﬁc information at test-time). Full sized images can be
found on our project website. Quantitative evaluation on hundreds of ‘non-ideal’ LR images can be found in Sec. 4.2.
was shown to be a very strong property of natural im-
ages [4, 23].
This formed the basis for many unsu-
pervised image enhancement methods, including unsuper-
vised SR [4, 5, 6], Blind-SR [14] (when the downscal-
ing kernel is unknown), Blind-Deblurring [15, 1], Blind-
Dehazing [2], and more. While such unsupervised methods
can exploit image-speciﬁc information (hence are less sub-
ject to the above-mentioned supervised restrictions), they
typically rely on simple Eucledian similarity of small im-
age patches, of predeﬁned size (typically 5 × 5), using K-
nearest-neighbours search. As such, they do not generalize
well to patches that do not exist in the LR image, nor to new
implicitly learned similarity measures, nor can they adapt to
non-uniform sizes of repeating structures inside the image.
Our image-speciﬁc CNN leverages on the power of the
cross-scale internal recurrence of image-speciﬁc informa-
tion, without being restricted by the above-mentioned lim-
itations of patch-based methods. We train a CNN to infer
complex image-speciﬁc HR-LR relations from the LR im-
age and its downscaled versions (self-supervision). We then
apply those learned relations on the LR input image to pro-
duce the HR output. This outperforms unsupervised patch-
based SR by a large margin.
Since the visual entropy inside a single image is much
smaller than in a general external collection of images [23],
a small and simple CNN sufﬁces for this image-speciﬁc
task. Hence, even though our network is trained at test time,
its train+test runtime is comparable to the test runtime of
SotA supervised CNNs. Interestingly, our image-speciﬁc
CNN produces impressive results (although not SotA) on
the ‘ideal’ benchmark datasets used by the SotA supervised
methods (even though our CNN is small and has not been
pretrained), and surpasses SotA supervised SR by a large
margin on ‘non-ideal’ images. We provide both visual and
empirical evidence of these statements.
The term “Zero-Shot” used here, is borrowed from the
domains of recognition/classiﬁcation. Note however, that
unlike these approaches for Zero-Shot Learning [22] or
One-shot Learning [18], our approach does not require any
side information/attributes or any additional images. We
may only have a single test image at hand, one of a kind,
and nothing else. Nevertheless, when additional informa-
tion is available and provided (e.g., the downscaling kernel
can be estimated directly from the test image using [14]),
our image-speciﬁc CNN can make good use of this at test
time, to further improve the results.
3

Our contributions are therefore several-fold:
(i) To our best knowledge, this is the ﬁrst unsupervised
CNN-based SR method.
(ii) It can handle non-ideal imaging conditions, and a wide
variety of images and data types (even if encountered for
the ﬁrst time).
(iii) It does not require pretraining and can be run with mod-
est amounts of computational resources.
(iv) It can be applied for SR to any size and theoretically
also with any aspect-ratio.
(v) It can be adapted to known as well as unknown imaging
conditions (at test time).
(v) It provides SotA SR results on images taken with ‘non-
ideal’ conditions, and competitive results on ‘ideal’ condi-
tions for which SotA supervised methods were trained on.
2. The Power of Internal Image Statistics
Fundamental to our approach is the fact that natural im-
ages have strong internal data repetition.
For example,
small image patches (e.g., 5×5, 7×7) were shown to re-
peat many times inside a single image, both within the same
scale, as well as across different image scales. This obser-
vation was empirically veriﬁed by [4, 23] using hundreds
of natural images, and was shown to be true for almost any
small patch in almost any natural image.
Fig. 3 shows an example of a simple single-image SR
based on internal patch recurrence (courtesy of [4]). Note
that it is able to recover the tiny handrails in the tiny bal-
conies, since evidence to their existence is found elsewhere
inside this image, in one of the larger balconies. In fact,
the only evidence to the existence of these tiny handrails
exists internally, inside this image, at a different location
and different scale.
It cannot be found in any external
database of examples, no matter how large this dataset is!
As can be seen, SotA SR methods fail to recover this image-
speciﬁc information when relying on externally trained im-
ages. While the strong internal predictive-power is exempli-
ﬁed here using a ‘fractal-like’ image, the internal predictive-
power was analyzed and shown to be strong for almost any
natural image [4].
In fact, it was empirically shown by [23] that the in-
ternal entropy of patches inside a single image is much
smaller than the external entropy of patches in a general
collection of natural images.
This further gave rise to
the observation that internal image statistics often provides
stronger predictive-power than external statistics obtained
from a general image collection. This preference was fur-
ther shown to be particularly strong under growing uncer-
tainty and image degradations (see [23, 16] for details).
Figure 3: Internal predictive power of image-speciﬁc in-
formation. Simple unsupervised internal-SR [4] is able to
reconstruct the tiny handrail in the tiny balconies, whereas
externally-trained SotA SR methods fail to do so. Evidence
to the existence of those tiny handrails exists only internally,
inside this image, at a different location and scale (in one
of the larger balconies). Such evidence is not found in any
external database of images (no matter how large it is).
3. Image-Speciﬁc CNN
Our image-speciﬁc CNN combines the predictive power
and low entropy of internal image-speciﬁc information,
with the generalization capabilities of Deep-Learning.
Given a test image I, with no external examples available
to train on, we construct an Image-Speciﬁc CNN tailored
to solve the SR task for this speciﬁc image. We train our
CNN on examples extracted from the test image itself. Such
examples are obtained by downscaling the LR image I, to
generate a lower-resolution version of itself, I ↓s (where
s is the desired SR scale factor). We use a relatively light
CNN, and train it to reconstruct the test image I from its
lower-resolution version I ↓s (top part of Fig. 4(b)). We
then apply the resulting trained CNN to the test image I,
now using I as the LR input to the network, in order to con-
struct the desired HR output I ↑s (bottom of Fig. 4(b)).
Note that the trained CNN is fully convolutional, hence can
be applied to images of different sizes.
Since our “training set” consists of one instance only (the
test image), we employ data augmentation on I to extract
more LR-HR example-pairs to train on. The augmentation
is done by downscaling the test image I to many smaller
versions of itself (I = I0, I1, I2, ..., In). These play the role
of the HR supervision and are called “HR fathers”. Each
of the HR fathers is then downscaled by the desired SR
scale-factor s to obtain the “LR sons”, which form the in-
put training instances. The resulting training set consists of
many image-speciﬁc LR-HR example pairs. The network
can then stochastically train over these pairs.
We further enrich the training set by transforming each
4

Figure 4: Image-Speciﬁc CNN – “Zero-Shot” SR. (a) Externally-supervised SR CNNs are pre-trained on large external
databases of images. The resulting very deep network is then applied to the test image I. (b) Our proposed method (ZSSR): a
small image-speciﬁc CNN is trained on examples extracted internally, from the test image itself. It learns how to recover the
test image I from its coarser resolutions. The resulting self-supervised network is then applied to the LR image I to produce
its HR output.
LR-HR pair using 4 rotations (0◦, 90◦, 180◦, 270◦) and their
mirror reﬂections in the vertical and horizontal directions.
This adds ×8 more image-speciﬁc training examples.
For the sake of robustness, as well as to allow large SR
scale factors s even from very small LR images, the SR is
performed gradually [4, 20]. Our algorithm is applied for
several intermediate scale-factors (s1, s2, ..., sm = s). At
each intemediate scale si, we add the generated SR image
HRi and its downscaled/rotated versions to our gradually
growing training-set, as new HR fathers. We downscale
those (as well as the previous smaller ‘HR examples’) by
the next gradual scale factor si+1, to generate the new LR-
HR training example pairs. This is repeated until reaching
the full desired resolution increase s.
3.1. Architecture & Optimization
Supervised CNNs, which train on a large and diverse ex-
ternal collection of LR-HR image examples, must capture
in their learned weights the large diversity of all possible
LR-HR relations. As such, these networks tend to be ex-
tremely deep and very complex. In contrast, the diversity of
the LR-HR relations within a single image is signiﬁcantly
smaller, hence can be encoded by a much smaller and sim-
pler image-speciﬁc network.
We use a simple, fully convolutional network, with 8
hidden layers, each has 64 channels. We use ReLU acti-
vations on each layer. The network input is interpolated to
the output size. As done in previous CNN-based SR meth-
ods [9, 8, 3], we only learn the residual between the inter-
polated LR and its HR parent. We use L1 loss with ADAM
optimizer [10]. We start with a learning rate of 0.001. We
periodically take a linear ﬁt of the reconstruction error and
if the standard deviation is greater by a factor than the slope
of the linear ﬁt we divide the learning rate by 10. We stop
when we get to a learning rate of 10−6.
To accelerate the training stage and make the runtime in-
dependent of the size of the test image I, at each iteration we
take a random crop of ﬁxed size from a randomly-selected
father-son example pair. The crop is typically 128×128 (un-
less the sampled image-pair is smaller). The probability of
sampling a LR-HR example pair at each training iteration is
set to be non-uniform and proportional to the size of the HR-
father. The closer the size-ratio (between the HR-father and
the test image I) is to 1, the higher its probability to be sam-
pled. This reﬂects the higher reliability of non-synthesized
HR examples over synthesize ones.
Lastly, we use a method similar to the geometric
self-ensemble proposed in [12] (which generates 8 different
outputs for the 8 rotations+ﬂips of the test image I, and
then combines them).
We take the median of these 8
outputs rather than their mean.
We further combine it
with the back-projection technique of [7, 4], so that each
of the 8 output images undergoes several iterations of
back-projection and ﬁnally the median image is corrected
by back-projection as well.
Runtime: Although training is done at test time, the aver-
age runtime per image is 54 sec for a single increase in SR
5

scale-factor (on a Tesla K-80 GPU). This runtime is inde-
pendent of the image size or the relative SR scale-factor s
(this is a result of the equally sized random crops used in
training; the ﬁnal test runtime is negligible with respect to
training iterations). Nevertheless, better SR results are ob-
tained when using a gradual increase in resolution. For ex-
ample, a gradual increase using 6 intermediate scale-factors
typically improves the PSNR by ∼0.2dB, but increases the
runtime to ∼5min per image. There is therefore a tradeoff
between runtime and the output quality, which is up to the
user to choose. Most of the results reported in this paper
were produced using 6 intermediate scale-factors.
For comparison, the test-time of the leading EDSR+ [12]
(on the same platform) is ∼20 sec for SR×2 on a 200×200
image.
However, EDSR’s run time grows quadratically
with the image size, and reaches 5min for an 800 × 800
image. Beyond that size, our network is faster than EDSR+.
3.2. Adapting to the Test Image
When the acquisition parameters of the LR images from
their HR ones are ﬁxed for all images (e.g., same downscal-
ing kernel, high-quality imaging conditions), current super-
vised SR methods achieve an incredible performance [19].
In practice, however, the acquisition process tends to change
from image to image, since cameras/sensors differ (e.g., dif-
ferent lens types and PSFs), as well as the individual imag-
ing conditions (e.g., subtle involuntary camera shake when
taking the photo, poor visibility conditions, etc). This re-
sults in different downscaling kernels, different noise char-
acteristics, various compression artifacts, etc. One could
not practically train for all possible image acquisition con-
ﬁgurations/settings. Moreover, a single supervised CNN is
unlikely to perform well for all possible types of degrada-
tions/settings. To obtain good performance, one would need
many different specialized SR networks, each trained (for
days or weeks) on different types of degradations/settings.
This is where the advantage of an image-speciﬁc network
comes in. Our network can be adapted to the speciﬁc degra-
dations/settings of the test image at hand, at test time. Our
network can receive from the user, at test time, any of the
following parameters:
(i) The desired downscaling kernel (when no kernel is pro-
vided, the bicubic kernel serves as a default).
(ii) The desired SR scale-factor s.
(iii) The desired number of gradual scale increases (a trade-
off between speed and quality – the default is 6).
(iv) Whether to enforce Backprojection between the LR and
HR image (the default is ‘Yes’).
(v) Whether to add ‘noise’ to the LR sons in each LR-HR
example pair extracted from the LR test image (the default
is ‘No’).
The last 2 parameters (cancelling the Backprojection and
adding noise) allow to handle SR of poor-quality LR images
(whether due to sensor noise in the image, JPEG compres-
sion artifacts, etc.) We found that adding a small amount
of Gaussian noise (with zero mean and a small standard-
deviation of ∼5 grayscales), improves the performance for a
wide variety of degradations (Gaussian noise, speckle noise,
JPEG artifacts, and more). We attribute this phenomenon
to the fact that image-speciﬁc information tends to repeat
across scales, whereas noise artifacts do not [24]. Adding
a bit of synthetic noise to the LR sons (but not to their HR
fathers) teaches the network to ignore uncorrelated cross-
scale information (the noise), while learning to increase the
resolution of correlated information (the signal details).
Indeed, our experiments show that for low-quality LR
images, and for a wide variety of degradation types, the
image-speciﬁc CNN obtains signiﬁcantly better SR results
than SotA EDSR+ [12] (see Sec. 4). Similarly, in the case
of non-ideal downscaling kernels, the image-speciﬁc CNN
obtains a signiﬁcant improvement over SotA (even in the
absence of any noise).
When the downscaling kernel is
known (e.g., a sensor with a known PSF), it can be provided
to our network. When the downscaling kernel is unknown
(which is usually the case), a rough estimate of the kernel
can be computed directly from the test image itself (e.g.,
using the method of [14]). Such rough kernel estimations
sufﬁce to obtain +1dB improvement over EDSR+ on non-
ideal kernels (see examples in Figs. 1 and 2, and empirical
evaluations in Sec. 4).
Note that providing the estimated downscaling kernel to
externally-supervised SotA SR methods at test time, would
be of no use. They would need to exhaustively re-train a
new network on a new collection of LR-HR pairs, generated
with this speciﬁc (non-parametric) downscaling kernel.
4. Experiments & Results
Our method (ZSSR - ‘Zero-Shot SR’) is primarily aimed
at real LR images obtained with realistic (unknown and
varying) acquisition setting.
These usually have no HR
ground truth, hence are evaluated visually (as in Fig. 1).
In order to quantitatively evaluate ZSSR’s performance, we
ran several controlled experiments, on a variety of settings.
Interestingly, ZSSR produces competitive results (although
not SotA) on the ‘ideal’ benchmark datasets for which the
SotA supervised methods train and specialize (even though
our CNN is small, and has not been pretrained). However,
on ‘non-ideal’ datasets, ZSSR surpasses SotA SR by a large
margin. All reported numerical results were produced using
the evaluation script of [8, 9].
4.1. The ‘Ideal’ Case
While this is not the aim of ZSSR, we tested it also
on the standard SR benchmarks of ‘ideal’ LR images. In
these benchmarks, the LR images are ideally downscaled
from their HR versions using MATLAB’s imresize com-
6

Ground Truth
VDSR [8]
EDSR+ [12]
ZSSR (ours)
(PSNR, SSIM)
(20.11, 0.9136)
(25.29 / 0.9627)
(25.68 / 0.9546)
Figure 5: In images with strong internal repetitive structures, ZSSR tends to surpass VDSR, and sometimes also EDSR+,
even though the LR image was generated using the ‘ideal’ supervised setting (i.e., bicubic downscaling).
Supervised
Unsupervised
Dataset
Scale
SRCNN [3]
VDSR [8]
EDSR+ [12]
SelfExSR [6]
ZSSR (ours)
Set5
×2
36.66 / 0.9542
37.53 / 0.9587
38.20 / 0.9606
36.49 / 0.9537
37.37 / 0.9570
×3
32.75 / 0.9090
33.66 / 0.9213
34.76 / 0.9290
32.58 / 0.9093
33.42 / 0.9188
×4
30.48 / 0.8628
31.35 / 0.8838
32.62 / 0.8984
30.31 / 0.8619
31.13 / 0.8796
Set14
×2
32.42 / 0.9063
33.03 / 0.9124
34.02 / 0.9204
32.22 / 0.9034
33.00 / 0.9108
×3
29.28 / 0.8209
29.77 / 0.8314
30.66 / 0.8481
29.16 / 0.8196
29.80 / 0.8304
×4
27.49 / 0.7503
28.01 / 0.7674
28.94 / 0.7901
27.40 / 0.7518
28.01 / 0.7651
BSD100
×2
31.36 / 0.8879
31.90 / 0.8960
32.37 / 0.9018
31.18 / 0.8855
31.65 / 0.8920
×3
28.41 / 0.7863
28.82 / 0.7976
29.32 / 0.8104
28.29 / 0.7840
28.67 / 0.7945
×4
26.90 / 0.7101
27.29 / 0.7251
27.79 / 0.7437
26.84 / 0.7106
27.12 / 0.7211
Table 1: Comparison of SR results for the ’ideal’ case (bicubic downscaling).
mand (a bicubic kernel downsampling with antialiasing).
Table 1 shows that our image-speciﬁc ZSSR achieves com-
petitive results against externally-supervised methods that
were exhaustively trained for these conditions.
In fact,
ZSSR is signiﬁcantly better than the older SRCNN [3], and
in some cases achieves comparable or better results than
VDSR [8] (which was the SotA until a year ago). Within
the unsupervised-SR regime, ZSSR outperforms the lead-
ing method SelfExSR [6] by a large margin.
Moreover, in images with very strong internal repetitive
structures, ZSSR tends to surpass VDSR, and sometimes
also EDSR+, even though these LR images were gener-
ated using the ‘ideal’ supervised setting. One such exam-
ple is shown in Fig. 5. Although this image is not a typ-
ical natural image, further analysis shows that the prefer-
ence for internal learning (via ZSSR) exhibited in Fig. 5
exists not only in ‘fractal-like’ images, but is also found in
general natural images. Several such examples are shown
in Fig. 6. As can be seen, some of the pixels in the image
(those marked in green) beneﬁt more from exploiting inter-
nally learned data recurrence (ZSSR) over deeply learned
external information, whereas other pixels (those marked in
red) beneﬁt more from externally learned data (EDSR+).
As expected, the internal approach (ZSSR) is mostly ad-
vantageous in image area with high recurrence of informa-
tion, especially in areas where these patterns are extremely
small (of extremely low resolution), like the small windows
in the top of the building. Such tiny patters ﬁnd larger (high-
res) examples of themselves elsewhere inside the same im-
age (at a different location/scale). This indicates that there
may be potential for further SR improvement (even in the
‘ideal’ bicubic case), by combining the power of Internal-
Learning with External-Learning in a single computational
framework. This remains part of our future work.
4.2. The ‘Non-ideal’ Case
Real LR images do not tend to be ideally generated. We
have experimented with non-ideal cases that result from
either: (i) non-ideal downscaling kernels (that deviate from
the bicubic kernel), and (ii) low-quality LR images (e.g.,
due to noise, compression artifacts, etc.) In such non-ideal
cases, the image-speciﬁc ZSSR provides signiﬁcantly
better results than SotA SR methods (by 1 −2dB). These
quantities experiments are described next. Fig. 2 shows a
few such visual results. Additional visual results and full
images can be found in our project website.
(A) Non-ideal downscaling kernels:
The purpose of this
experiment is to test more realistic blur kernels with the
ability to numerically evaluate the results. For this purpose
7

VDSR [8]
EDSR+ [12]
Blind-SR [14]
ZSSR [estimated kernel] (ours)
ZSSR [true kernel] (ours)
27.7212 / 0.7635
27.7826 / 0.7660
28.420 / 0.7834
28.8118 / 0.8306
29.6814 / 0.8414
Table 2: SR in the presence of unknown downscaling kernels. LR images were generated from the BSD100 dataset using random
downscaling kernels (of reasonable size). SR×2 was then applied to those images. Please see text for more details.
Bicubic interpolation
EDSR+ [12]
ZSSR (ours)
27.9216 / 0.7504
27.5600 / 0.7135
28.6148 / 0.7809
Table 3:
SR in the presence of unknown image degrada-
tion. Each LR image from the BSD100 dataset was randomly de-
graded using one of 3 types of degradations: (i) Gaussian noise,
(ii) Speckle noise, (iii) JPEG compression. SR×2 was then ap-
plied to those images, without knowing the type of degradation.
ZSSR shows robustness to unknown degradations, whereas SotA
SR methods are not. In fact, under such conditions, bicubic inter-
polation outperforms current SotA SR methods.
we created a new dataset from BSD100 [13] by downscaling
the HR images using random (but reasonably sized) Gaus-
sian kernels. For each image, the covariance matrix Σ of its
downscaling kernel was chosen to have a random angle θ
and random lengths λ1, λ2 in each axis:
λ1, λ2 ∽U[0, s2]
θ ∽U[0, π]
Λ = diag(λ1, λ2)
U =
cos(θ)
−sin(θ)
sin(θ)
cos(θ)

Σ = UΛUt
(1)
where s is the HR-LR downscaling factor.
Thus, each
LR image was subsampled by a different random ker-
nel. Table 2 compares our performance against the lead-
ing externally-supervised SR methods [12, 8].
We also
compared our performance to the unsupervised Blind-SR
method of [14].
We considered two cases for applying
ZSSR: (i) The more realistic scenario of unknown down-
scaling kernel. For this mode we used [14] to evaluate the
kernel directly from the test image and fed it to ZSSR. The
unknown SR kernel is estimated in [14] by seeking a non-
parametric downscaling kernel which maximizes the simi-
larity of patches across scales in the LR test image. (ii) We
applied ZSSR with the true downscaling kernel used to cre-
ate the LR image. Such a scenario is potentially useful for
images obtained by sensors with known specs.
Note that none of the externally-supervised methods are
able to beneﬁt from knowing the blur kernel of the test im-
age (whether estimated or real), since they were trained
and optimized exhaustively for a speciﬁc kernel. Table 2
shows that ZSSR outperforms SotA methods by a very large
margin: +1db for unknown (estimated) kernels, and +2db
when provided the true kernels. Visually, the SR images
Figure 6: Internal vs. External preference. Green: pix-
els that favor Internal-SR (i.e., pixels where ZSSR obtains
lower error with respect to the ground-truth HR image);
Red: pixels that favour External-SR (EDSR+).
Notice
that edges (which are frequent in natural images) prefer
External-SR, whereas unique image structures (e.g., the tiny
windows at the top of the high building) prefer Internal-SR.
Such tiny patters ﬁnd larger (high-res) examples of them-
selves elsewhere inside the same image (at a different loca-
tion/scale).
generated by SotA methods are very blurry (see Fig. 2, and
project website) . Interestingly, the unsupervised Blind-SR
method of [14], which does not use any deep learning, also
outperforms SotA SR methods. This further supports the
analysis and observations of [17], that (i) an accurate don-
wscaling model is more important than sophisticated image
priors, and (ii) using the wrong donwscaling kernel leads to
oversmoothed SR results.
A special case of a non-ideal kernel is the δ kernel,
which results in aliasing. This case too, is not handled well
by SotA methods (see example in Fig. 2).
(B) Poor-quality LR images:
In this experiment, we
tested images with different types of quality degradation.
To test the robustness of ZSSR in coping with unknown
damage, we chose for each image from BSD100 [13] a ran-
dom type of degradation out of 3 degradations: (i) Gaussian
noise [σ = 0.05], (ii) Speckle noise [σ = 0.05], (iii) JPEG
compression [quality = 45 (By MATLAB standard)]. Ta-
ble 3 shows that ZSSR is robust to unknown degradation
types, while these typically damage SR supervised methods
to the point where bicubic interpolation outperforms cur-
rent SotA SR methods!
8

5. Conclusion
We introduce the concept of “Zero-Shot” SR, which ex-
ploits the power of Deep Learning, without relying on any
external examples or prior training. This is obtained via a
small image-speciﬁc CNN, which is trained at test time on
internal examples extracted solely from the LR test image.
This yields SR of real-world images, whose acquisition pro-
cess is non-ideal, unknown, and changes from image to im-
age (i.e., image-speciﬁc settings). In such real-world ‘non-
ideal’ settings, our method substantially outperforms SotA
SR methods, both qualitatively and quantitatively. To our
best knowledge, this is the ﬁrst unsupervised CNN-based
SR method.
References
[1] Y. Bahat, N. Efrat, and M. Irani. Non-uniform blind deblur-
ring by reblurring. In ICCV, 2017. 3
[2] Y. Bahat and M. Irani. Blind dehazing using internal patch
recurrence. In ICCP, 2016. 3
[3] K. H. X. T. Chao Dong, Chen Change Loy. Learning a deep
convolutional network for image super-resolution. In Euro-
pean Conference on Computer Vision (ECCV), 2014. 1, 5,
7
[4] S. B. D. Glasner and M. Irani. Super-resolution from a sin-
gle image. In International Conference on Computer Vision
(ICCV), 2009. 1, 3, 4, 5
[5] G. Freedman and R. Fattal.
Image and video upscaling
from local self-examples. ACM Transactions on Graphics,
30(2):12, 2011. 1, 3
[6] J.-B. Huang, A. Singh, and N. Ahuja. Single image super-
resolution from transformed self-exemplars. In Proceedings
of the IEEE Conference on Computer Vision and Pattern
Recognition, pages 5197–5206, 2015. 1, 3, 7
[7] M. Irani and S. Peleg. Improving resolution by image reg-
istration. CVGIP: Graphical Model and Image Processing,
53(3):231–239, 1991. 5
[8] J. Kim, J. Kwon Lee, and K. Mu Lee. Accurate image super-
resolution using very deep convolutional networks. In The
IEEE Conference on Computer Vision and Pattern Recogni-
tion (CVPR) Workshops, pages 1646–1654, 06 2016. 1, 5, 6,
7, 8
[9] J. Kim, J. K. Lee, and K. M. Lee. Deeply-recursive convolu-
tional network for image super-resolution. In The IEEE Con-
ference on Computer Vision and Pattern Recognition (CVPR
Oral), June 2016. 1, 5, 6
[10] D. P. Kingma and J. Ba. Adam: A method for stochastic
optimization. CoRR, abs/1412.6980, 2014. 5
[11] C. Ledig, L. Theis, F. Huszar, J. Caballero, A. Cunning-
ham, A. Acosta, A. Aitken, A. Tejani, J. Totz, Z. Wang, and
W. Shi. Photo-realistic single image super-resolution using a
generative adversarial network. arXiv:1609.04802, 2016. 1
[12] B. Lim, S. Son, H. Kim, S. Nah, and K. M. Lee. Enhanced
deep residual networks for single image super-resolution.
In The IEEE Conference on Computer Vision and Pattern
Recognition (CVPR) Workshops, July 2017. 1, 2, 3, 5, 6, 7,
8
[13] D. Martin, C. Fowlkes, D. Tal, and J. Malik. A database
of human segmented natural images and its application to
evaluating segmentation algorithms and measuring ecologi-
cal statistics. In Proc. 8th Int’l Conf. Computer Vision, vol-
ume 2, pages 416–423, July 2001. 8
[14] T. Michaeli and M. Irani.
Nonparametric blind super-
resolution. In International Conference on Computer Vision
(ICCV), 2013. 3, 6, 8
[15] T. Michaeli and M. Irani. Blind deblurring using internal
patch recurrence. In European Conference on Computer Vi-
sion (ECCV). 2014. 3
[16] I. Mosseri, M. Zontak, and M. Irani. Combining the power
of internal and external denoising. In ICCP, 2013. 4
[17] A. A. B. N. A. l. Netalee Efrat, Daniel Glasner. Accurate blur
models vs. image priors in single image super-resolution. In
ICCV, 2013. 8
[18] A. Santoro, S. Bartunov, M. Botvinick, D. Wierstra, and T. P.
Lillicrap.
Meta-learning with memory-augmented neural
networks. In International Conference on Machine Learn-
ing (ICML). 3
[19] R. Timofte, E. Agustsson, M.-H. Van Gool, Luc Yang,
L. Zhang, et al. Ntire 2017 challenge on single image super-
resolution: Methods and results. In The IEEE Conference
on Computer Vision and Pattern Recognition (CVPR) Work-
shops, July 2017. 6
[20] R. Timofte, R. Rothe, and L. Van Gool. Seven ways to im-
prove example-based single image super resolution. In The
IEEE Conference on Computer Vision and Pattern Recogni-
tion (CVPR), June 2016. 5
[21] R. Timofte, V. D. Smet, and L. V. Gool. A+: Adjusted an-
chored neighborhood regression for fast super-resolution. In
ACCV, 2014. 1
[22] Y. Xian, B. Schiele, and Z. Akata. Zero-shot learning – the
Good, the Bad and the Ugly. In CVPR, 2017. 3
[23] M. Zontak and M. Irani. Internal statistics of a single natural
image. In IEEE Conference on Computer Vision and Pattern
Recognition (CVPR), June 2011. 3, 4
[24] M. Zontak, I. Mosseri, and M. Irani. Separating signal from
noise using patch recurrence across scales. In CVPR, 2013.
6
9

