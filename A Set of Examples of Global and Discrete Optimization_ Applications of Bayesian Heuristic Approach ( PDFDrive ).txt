
A Set of Examples of Global and Discrete Optimization 

Applied Optimization 
Volume 41 
Series Editors: 
Panos M. Pardalos 
University of Florida, U.S.A. 
Donald Hearn 
University of Florida, U.S.A. 

A Set of Examples of 
Global and Discrete 
Optiinization 
Applications of Bayesian Heuristic Approach 
by 
Jonas Mockus 
Institute of Mathematics and Informatics, 
Kaunas Technological University, 
Lithuania 
llt.,jj '' 
SPRINGER-SCIENCE+BUSINESS MEDIA, B.V. 

A C.I.P. Catalogue record for this book is available from the Library of Congress. 
ISBN 978-1-4613-7114-4 
ISBN 978-1-4615-4671-9 (eBook) 
DOI 10.1007/978-1-4615-4671-9 
Printed on acid-free paper 
All Rights Reserved 
Â© 2000 Springer Science+ Business Media Dordrecht 
Originally published by Kluwer Academic Publishers in 2000 
Softcover reprint of the hardcover 1st edition 2000 
No part of the material protected by this copyright notice may be reproduced or 
utilized in any form or by any means, electronic or mechanical, 
including photocopying, recording or by any information storage and 
retrieval system. without written permission from the copyright owner 

Contents 
Preface 
Part I ABOUT THE BAYESIAN APPROACH 
1. GENERAL IDEAS 
1. 
Outline 
2. 
Direct Bayesian Approach (DBA) 
3. 
Bayesian Heuristic Approach (BHA) 
4. 
Illustrative Examples 
5. 
Heuristics 
2. EXPLAINING BHA BY KNAPSACK EXAMPLE 
1. 
Exact Algorithms 
1.1 
Exhaustive Search 
1.2 
Branch & Bound (B&B) 
2. 
Approximate Algorithms 
2.1 
Monte Carlo 
2.2 
Greedy Heuristics 
2.3 
Randomized Heuristics 
2.4 
Permutation 
3. 
Software Examples of Knapsack Problem 
3.1 
C++ 
3.2 
Java 
Part II SOFTWARE FOR GLOBAL OPTIMIZATION 
3. INTRODUCTION 
1. 
General Description 
1.1 
Background 
1.2 
Description of Methods 
1.3 
Application Areas 
1.4 
Constraints 
v 
XI 
3 
3 
4 
5 
6 
7 
11 
12 
12 
12 
13 
13 
14 
14 
16 
21 
22 
23 
33 
33 
33 
34 
36 
36 

vi 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
1.5 
Computing Environment 
2. 
Early Applications 
3. 
Different Versions 
3.1 
Fortran Library, Portable 
3.2 
Thrbo C, lntreactive 
3.3 
Unix C++, Interactive 
3.4 
Java JDKl.O, Interactive 
3.5 
Java JDK1.1, Interactive 
3.6 
Java JDK1.2, Interactive 
4. 
Web-Sites 
4. FORTRAN 
1. 
Introduction 
2. 
General Discussion 
2.1 
Parameters 
2.2 
List of Methods 
3. 
Program Description 
3.1 
Common Blocks 
3.2 
Objective Functions and Constraints 
3.3 
Main Program 
3.4 
Example of the Main Program 
3.5 
Installation 
5. TURBO C 
1. 
General Discussion 
1.1 
Purpose 
2. 
User's Reference 
6. C++ 
1. 
2. 
2.1 
Requirements 
2.2 
Installation 
2.3 
Initialization 
2.4 
Minimization 
2.5 
Menu System 
2.6 
Navigation 
2.7 
Moving 
2.8 
Sizing 
Purpose of GMC 
User's Reference 
2.1 
Requirements 
2.2 
Installation 
2.3 
Initialization 
2.4 
Menu System 
7. JAVA 1.0 
1. 
Introduction 
2. 
Running GMJO 
2.1 
Defining Objective 
37 
37 
39 
39 
39 
40 
40 
40 
40 
41 
45 
45 
47 
47 
48 
49 
49 
49 
50 
51 
51 
55 
55 
55 
56 
56 
56 
56 
57 
57 
60 
61 
61 
63 
63 
64 
64 
64 
64 
65 
75 
75 
76 
76 

2.2 
Compiling and Running 
2.3 
Graphical Interface 
2.4 
Implementing New Method 
8. JAVA 1.2 
1. 
Introduction 
2. 
Starting GMJ 
2.1 
Configuring Applet 
2.2 
Configuring Stand-Alone Application 
3. 
Running GMJ 
3.1 
Display and Control 
3.2 
Task Selection 
3.3 
Operation Control 
3.4 
Analysis of Results 
3.5 
Method selection 
4. 
Updating G MJ 
4.1 
New Tasks 
4.2 
New Methods 
4.3 
Configuring Property Manager 
4.4 
New Analysis Objects 
4.5 
Programming Tips 
4.6 
Security Restrictions 
5. 
Features of G MJ2 
5.1 
Custom Result Analyzers 
5.2 
Domain Constraint Function 
5.3 
Running GMJ2 
Part III EXAMPLES OF MODELS 
9. NASH EQUILIBRIUM 
1. 
Optimization Problems in Market Models 
2. 
Nash Model 
3. 
Search for Nash Equilibrium 
3.1 
Existence of Nash Equilibrium 
4. 
Stable Coalition, Core of Games 
4.1 
Example of Server Coalition 
10.WALRAS EQUILIBRIUM 
1. 
Walras Model 
2. 
Search for Walras Equilibrium 
3. 
Monte-Carlo Simulation 
3.1 
Search for Equilibrium 
3.2 
Testing Equilibrium Conditions 
3.3 
Wiener Filter 
4. 
Software Example 
1l.INSPECTION MODEL 
Contents 
vii 
76 
77 
80 
85 
85 
86 
86 
88 
88 
88 
90 
92 
92 
92 
93 
95 
97 
98 
100 
103 
104 
105 
105 
106 
107 
115 
115 
116 
118 
119 
119 
120 
123 
123 
126 
128 
128 
131 
131 
136 
143 

Vlll 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
1. 
Bimatrix Game 
143 
2. 
Search for Equilibrium 
144 
2.1 
Direct Search Algorithm (DSA) 
145 
2.2 
Necessary and Sufficient Conditions 
146 
2.3 
Irrelevant Fraud Algorithm (IFA) 
146 
2.4 
Strategy Elimination Algorithm (SEA) 
148 
3. 
Matrix Game 
148 
12.DIFFERENTIAL GAME 
151 
1. 
Introduction 
151 
2. 
Convex Version 
152 
3. 
Mixed Strategies 
153 
4. 
Search for Equilibrium 
155 
4.1 
Bimatrix Game Algorithm 
155 
4.2 
Matrix Game Algorithm 
157 
5. 
One-dimensional Example 
158 
6. 
Economic Duel. Nash Model 
159 
6.1 
Simplified Nash Model. Static Case 
159 
6.2 
Dynamic Nash Model 
161 
7. 
Software Example 
163 
7.1 
Operating Duel 
165 
7.2 
Future Developments 
169 
13.INVESTMENT PROBLEM 
173 
1. 
Introduction 
173 
2. 
Expected Utility 
174 
3. 
Optimal Portfolio, Special Cases 
175 
4. 
Utility Functions 
176 
5. 
Software Example 
178 
5.1 
Running the Program 
178 
5.2 
A Set of Utility Functions 
179 
5.3 
Predicting Investment Results 
180 
5.4 
Data 
182 
5.5 
Results 
183 
5.6 
Future Developments 
184 
14.EXCHANGE RATE PREDICTION 
187 
1. 
Introduction 
187 
2. 
Auto Regressive Moving-Average Models (ARMA) 
189 
2.1 
Definitions 
189 
2.2 
Definition of Residuals 
189 
3. 
Minimization of Residuals of ARMA Models 
189 
3.1 
Optimization of AR Parameters 
190 
3.2 
Optimization of MA Parameters 
191 
3.3 
Predicting "Next-Day" Rate 
191 
3.4 
Evaluation of ARMA Prediction Errors 
192 
4. 
External Factors 
193 

Contents 
ix 
4.1 
Missing Data 
196 
5. 
Applying ARMAto External Factors 
196 
6. 
Artificial Neural Networks Models (ANN) 
197 
6.1 
Involving Auto Regression (AR) into ANN 
197 
7. 
Bilinear Models (BL) 
199 
8. 
Auto Regressive Fractionally Integrated Moving Average 
Models (ARFIMA) 
199 
8.1 
Definitions 
199 
8.2 
Minimization of Residuals 
200 
8.3 
Discussions 
202 
9. 
Multi-Step Predictions 
204 
10. 
Structural Stabilization 
205 
10.1 
Stabilization of Structures of Time Series 
205 
10.2 
Simple Example 
208 
10.3 
Examples of Structural Optimization with External 
Factors 
209 
11. 
Examples of Squared Residuals Minimization 
210 
11.1 
Multi-Modality Examples 
210 
11.2 
Optimization Results 
215 
12. 
Software Examples 
221 
12.1 
C Version of ARMA Software {ARMAC) 
221 
12.2 
Java version of ARMA Software {ARMAJ) 
238 
12.3 
ANN Software 
243 
15.CALL CENTERS 
245 
1. 
Introduction 
245 
1.1 
Outline 
245 
1.2 
Assumptions, Notations, and Objectives 
246 
2. 
Calculation of Stationary Probabilities 
247 
3. 
Asymptotic Expressions 
248 
4. 
"Surrogate" Services 
248 
5. 
Call Rate Estimate 
249 
6. 
Optimization of Number of Servers 
249 
7. 
Monte Carlo Simulation (MCS) 
250 
7.1 
Event Generation 
250 
7.2 
Monte Carlo Errors 
252 
7.3 
Stopping Monte Carlo 
253 
8. 
Common Waiting 
253 
8.1 
Analytical Approximation: Reservation Model 
253 
8.2 
Statistical Approximation: Monte Carlo Model 
254 
8.3 
Call Rate Estimate 
254 
8.4 
Testing Analytical Approximation 
254 
9. 
Time-Dependant Cases 
255 
9.1 
Simple Example 
256 
10. 
Call Rate Predictions 
257 
10.1 
Introduction 
257 

x 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
10.2 
Call Rate Prediction by Scale Models 
10.3 
Expert Model, Event Scale Version 
10.4 
Time Scale Version, Vector Prediction 
10.5 
Time Series Model (ARMA) 
10.6 
Application Examples 
11. 
Call Center Scheduling 
16.0PTIMAL SCHEDULING 
1. 
Introduction 
2. 
Flow-Shop Problem 
2.1 
Permutation Schedule 
2.2 
Heuristics 
2.3 
Results 
2.4 
GMC Software Example 
2.5 
G MJ Software Example 
3. 
School Scheduling 
3.1 
Constraints 
3.2 
Data Structure 
3.3 
Permutation and Evaluation Algorithm 
3.4 
Software Example 
3.5 
Running Software 
17.SEQUENTIAL DECISIONS 
1. 
Introduction 
2. 
Average Utility 
3. 
Single-Marriage Case 
3.1 
Bellman's Equations 
3.2 
Discrete Approximation 
3.3 
Including the Waiting Cost 
3.4 
Non-Linear Case 
4. 
Multi-Marriage Case 
4.1 
" Buy-a-PC" Example 
4.2 
Bellman's Equations 
5. 
Software Examples 
References 
Index 
259 
261 
269 
272 
273 
273 
275 
275 
276 
276 
277 
277 
278 
278 
282 
283 
283 
284 
285 
285 
291 
291 
292 
293 
293 
294 
295 
295 
296 
296 
297 
299 
307 
317 

Preface 
This book shows how the Bayesian Approach (BA) improves well-
known heuristics by randomizing and optimizing their parameters. That 
is the Bayesian Heuristic Approach (BHA). 
The ten in-depth examples are designed to teach Operations Research 
using Internet. Each example is a simple representation of some impor-
tant family of real-life problems. 
The accompanying software can be run by remote Internet users. The 
supporting web-sites include software for Java, C++, and other lan-
guages. 
A theoretical setting is described in which one can discuss a Bayesian 
adaptive choice of heuristics for discrete and global optimization prob-
lems. The techniques are evaluated in the spirit of the average rather 
than the worst case analysis. In this context, "heuristics" are understood 
to be an expert opinion defining how to solve a family of problems of dis-
crete or global optimization. The term "Bayesian Heuristic Approach" 
means that one defines a set of heuristics and fixes some prior distribu-
tion on the results obtained. By applying BHA one is looking for the 
heuristic that reduces the average deviation from the global optimum. 
The theoretical discussions serve as an introduction to examples that 
are the main part of the book. All the examples are interconnected. Dif-
ferent examples illustrate different points of the general subject. How-
ever, one can consider each example separately, too. 
In part I, About the Bayesian Heuristic Approach, some well-known 
results are discussed to help understand what the Bayesian Heuristic Ap-
proach is about. First the general ideas of Bayesian related approaches 
are outlined. This is for readers who want to understand the place of 
BHA in the general optimization theory and applications. Then it is 
shown how BHA works by considering a simple example of the knapsack 
problem. This is for those who are interested in optimization algorithms 
Xl 

x11 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
and would like to skip the underlying theory. In Part II, Software for 
Global Optimization, different versions of software implementing the 
Bayesian and other approaches to global optimization are considered. A 
set of portable Fortran 77 programs, reflecting the early developments 
of global and local optimization software, is discussed. An interactive 
Thrbo C version, designed for DOS environment, and an interactive 
C++ version, designed for Unix environment, are described. Three Java 
versions of global optimization software are presented. The Java soft-
ware is run by standard Internet browsers. 
In part III, Examples of Models, examples of global and discrete op-
timization are described. The choice of examples aims to help teaching. 
The teaching topics include: Operations Research, Theory of Games and 
Markets, Decision Theory, Utility Theory, Queuing Theory, Scheduling 
Theory, Stochastic Optimization, and Discrete Optimization. 
Following mathematical models are considered: 
â¢ competition models with fixed resource prices, the "Nash equilib-
rium," 
â¢ competition models with free resource prices, the "Walras equilib-
rium," 
â¢ models of dynamic competition, 
â¢ bimatrix game models, the "Inspector problem," 
â¢ differential game models, the 'Star Wars' problem, 
â¢ investment models, the "Portfolio problem," 
â¢ auto regressive moving average models (ARMA), the problem of ex-
change rate prediction, 
â¢ queuing models for prediction and optimization, the "Call Center 
problem", 
â¢ discrete optimization models, the 
scheduling problem, 
â¢ sequential statistical decision models, the "Bride problem." 
The first nine models are solved using a set of algorithms of global and 
stochastic optimization. The last model is an example of stochastic 
dynamic programming. All the models are formulated in simple terms 
to serve as "classroom" examples. However, each of these models can 
be considered as simple representations of important families of real-life 

Preface 
xm 
problems. Therefore, the models and the solution algorithms may be of 
interest for application experts, too. 
This book is to describe underlying ideas of algorithms and models 
in mathematical terms supplemented by illustrative examples and ex-
planations. The information is presented in two forms: hard copy and 
web-sites. 
An advantage of the hard copy is that one does not need a computer 
to read it. The disadvantage is the static presentation. A hard copy 
cannot be updated. Therefore, new results must wait until the next 
edition. 
The aim of supporting web-sites is to supplement the algorithms and 
models by software systems for different computing environments, using 
different languages and operating systems. An advantage of web-sites is 
the dynamic presentation. Thus, the results can be easily updated and 
made accessible free of charge for a wide range of readers. An additional 
advantage is the possibility to run the software directly by Internet. 
That is convenient teaching the programming using Internet. 
The author considers the hard copy as a static introduction to the 
dynamic web-sites. There are two of them; they differ by volume and 
scope. 
http: I lmockus.orgloptimum 
http: I loptimum.mii.lt;-jonas 
The software presented on these sites is intended for "active" readers, 
who would like to apply the results to their own proQlems immediately. 
Contact e-mail addresses: 
, 
jonas@optimum.mii.lt 
jonas@mockus.org 
audris@bell - labs.cam 
Finally, I want to express my thanks to colleagues who directly or 
indirectly contributed to this book. I further acknowledge the support 
of the publisher in producing the book. 
J. Mockus 
January 2000 

I 
ABOUT THE BAYESIAN APPROACH 

Chapter 1 
GENERAL IDEAS OF 
BAYESIAN HEURISTIC APPROACH 
1. 
OUTLINE 
The traditional numerical analysis considers optimization algorithms 
that guarantee some accuracy for all functions to be optimized. This 
includes the exact algorithms. That is the worst case analysis. To limit 
maximal errors one needs computational efforts that often increase ex-
ponentially with the size of the problem. This is the main disadvantage 
of the worst case analysis. 
The alternative is the average case analysis. Here an average error 
is not limited but is made as small as possible. The average is taken 
over a set of functions to be optimized. The average case analysis is the 
Bayesian Approach (BA) (Diaconis, 1988; Mockus, 1989a). 
There are several ways to apply BA in optimization. The first one, 
the Direct Bayesian Approach (DBA), is defined by fixing a prior dis-
tribution P on a set of functions f(x) and by minimizing the Bayesian 
risk function (DeGroot, 1970; Mockus, 1989a). The risk function R(x) 
is the expected deviation from the global minimum at a fixed point x. 
The distribution P is considered as a stochastic model of f ( x), x E Rm, 
where f(x) might be a deterministic or a stochastic function. In the 
Gaussian case, assuming (Mockus, 1989a) that the (n+ 1)th observation 
is the last one 
(1.1) 
Here Cn = mi:rJ.iZi- E, Zi = f(xi)Â· mn(x) is a conditional expectation 
with respect to observed values Zi, i = 1, ... ,n. s~(x) is a conditional 
3 

4 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
variance, and t: > 0 is a correction parameter. The minimlllll of the risk 
function R(x) is obtained (Mockus, 1989a) at the point 
Xn+1 = argmax 
( ) 
. 
x 
mn X -
Cn 
(1.2) 
The objective of DBA, used mainly in continuous cases, is to provide as 
small average error as possible while keeping convergence conditions. 
Another way, the Bayesian Heuristic Approach (BHA), means fixing 
a prior distribution P on a set of auxiliary functions fK(x). 
These 
functions define the best values obtained by using K times some heuristic 
h(x). It is assumed that heuristics h(x) depend on some continuous 
parameters x E Rm. The heuristic helps to optimize an original function 
C(y) of variables y ERn, where m < n (Mockus et al., 1997). As usual, 
components of y are discrete variables. Heuristics are based on expert 
opinions about the decision priorities. Now both DBA and BHA will be 
considered in detail. 
2. 
DIRECT BAYESIAN APPROACH (DBA) 
The Wiener process is a common (Kushner, 1964a; Saltenis, 1971; 
Torn and Zilinskas, 1989) stochastic model in the one-dimensional case 
m=l. 
Figure 1.1 shows the conditional expectation, the conditional standard, 
and the risk function with respect to available evaluations. The Wiener 
model implies continuity of almost all sample functions f(x). The model 
assumes that increments j(x4)- j(x3) and j(x2) - f(xt), x1 < x2 < 
x3 < x4, are stochastically independent. Here f(x) is Gaussian (0, ax) 
at any fixed x > 0. Note, that the Wiener process originally provided a 
mathematical model of a particle in the Brownian motion. 
The Wiener model is extended to multidimensional case, too (Mockus, 
1989a). However, simple approximate stochastic models are preferable 
if m > 1. Approximate models are designed by replacing the traditional 
Kolmogorov consistency conditions. These conditions require the inver-
sion of matrices of nth order for computing the conditional expectation 
mn(x) and variance s;(x) 1. 
Replacing the regular consistency conditions by: 
- continuity of the risk function R( x) 
-convergence of Xn to the global minimum 
- simplicity of expressions of mn(x) and sn(x) 
1The favorable exceptions are the Markovian processes including the Wiener one. Extending 
the Wiener process to m > 1 the Markovian property disappears. 

GENERAL IDEAS 
5 
the following simple expression of R(x) is obtained using the results of 
(Mockus, 1989a) 
R(x) = min zÂ·- min llx- xill2 
l:Si:Sn z 
l:Si:Sn 
Zi -
Cn 
The aim of DBA is to reduce the expected deviation. In addition, 
DBA has some good asymptotic properties, too. It is shown {Mockus, 
1989a) that 
Here d* is a density of points Xi around the global optimum. da is an 
average density of Xi in the feasible area. fa is an average value of f ( x) 
in this area. f* is an average value of f(x) around the global minimum. 
t: is the correction parameter in expression (1.1). That means that DBA 
provides convergence to the global minimum for any continuous f ( x) 
and a greater density of observations Xi around the global optimum, if 
n is large. 
Note, that the correction parameter t: has a similar influence as the 
temperature in simulated annealing. However, that is a superficial simi-
larity. The good asymptotic behavior is just some "by-product" of DBA. 
The reason is that Bayesian decisions are applied for small size samples 
where asymptotic properties are not noticeable. To choose the next 
point Xn+l by DBA, one minimizes the expected deviation R(x) from 
the global optimum (see Figure 1). The minimization of R(x) is a com-
plicated auxiliary optimization problem. That means that DBA is useful 
for expensive, in terms of computing times, functions of a few (m < 20) 
continuous variables. This happens in wide variety of problems. 
Some examples are described in {Mockus, 1989a). These include maxi-
mization of the yield of differential amplifiers, optimization of mechanical 
systems of a shock absorber, optimization of composite laminates, eval-
uation of parameters of immunological models and nonlinear time series, 
planning of extremal experiments on thermostable polymeric composi-
tions. A large set of test problems in global optimization is considered 
in (Floudas et al., 1999). 
3. 
BAYESIAN HEURISTIC APPROACH 
(BHA) 
The Bayesian Heuristic Approach (BHA) is for optimization of sim-
ple objective functions with large variable numbers. That is the case 
in many discrete optimization problems. As usual, these problems are 

6 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
solved using heuristics based on an expert opinion. Heuristics often 
involve randomization2 procedures that depend on some empirically de-
fined parameters. 
The examples of such parameters are: 
- an initial temperature of the simulated annealing, 
- probabilities of different randomization algorithms in their "mixture." 
In these problems DBA is a convenient tool for optimization of the con-
tinuous parameters of various heuristic techniques and their mixtures. 
That is the Bayesian Heuristic Approach (BHA) (Mockus et al., 1997). 
Applying DBA, the expert knowledge is involved by defining a prior 
distribution. In BHA one exploits expert knowledge "twice": First time 
one does that by defining the heuristics. Second time the expert knowl-
edge is involved by defining a prior distribution, needed to optimize 
parameters of heuristics using DBA. 
4. 
ILLUSTRATIVE EXAMPLES 
The example of a knapsack problem is convenient to illustrate basic 
principles of BHA in the discrete optimization. Given a set of objects 
j = 1, ... , n with values Cj and weights gj, find the most valuable collec-
tion of a limited weight g 
n 
n 
max C(y), C(y) = 2:= CjYj, 2:= 9jYj S g. 
y 
. 
. 
J=l 
J=l 
Here the objective function C(y) depends on n Boolean variables y = 
(y1 , ... , Yn), where Yj = 1, if an object j is in the collection, and Yj = 0, 
otherwise. The well known greedy heuristic hj = Cj / 9j is the specific 
value of an object j. The greedy heuristic algorithm: "take the greatest 
feasible h/', is very fast but it may get stuck in some non optimal de-
cision. One may force the heuristic algorithm out of there by taking a 
decision j with some probability rj = Px(hj)3 
Here DBA is applied to optimize parameters x of the auxiliary func-
tion fK(x). This function defines the best results obtained applying K 
times a randomized heuristic algorithm Px ( hj). That is the most ex-
pensive operation of BHA. Therefore, the parallel computing of !K(x) 
should be used, if possible4 . Optimization of x adapts the heuristic al-
2 The randomization means that a decision depends on some random variable included into 
an algorithm deliberately. 
31-.{eaning that a randomization is applied. For example: 
- generate an uniformly distributed random number ~ E [0, 1] 
- take a decision j if~ < r j, where Px (h j) is an increasing function of hj and x = ( x 1 , ... , Xm) 
is a parameter vector. 
4 In this case the solution time is inversely proportional to the number of parallel processors. 

GENERAL IDEAS 
7 
gorithm Px(hj) to a given problem. The parameter x may be useful 
to solve related problems (Mockus et al., 1997). That helps using the 
"on-line" optimization. 
We illustrate the parameterization of Px(hj) by using three random-
ization functions r! = hU Lj h;, l = 0, 1, oo. Here the superscript l = 0 
denotes the uniformly distributed component. l = 1 defines the lin-
ear component of randomization. The superscript oo denotes the pure 
heuristics with no randomization. That means r'f = 1, if hi= maxj hj 
and r'f = 0 , otherwise. The parameter x = (xo, x1 , x00 ) defines prob-
abilities of using the randomizations l = 0, 1, oo, correspondingly. That 
can be understand as some "lottery of algorithms" where xz is a proba-
bility to "win" the algorithm l. The detail description of the knapsack 
example is in the next chapter. 
5. 
HEURISTICS 
The main objective of BHA is to improve any given heuristic by defin-
ing the best parameters of some heuristic and/or the best "mixtures" 
of different heuristics. Heuristic decision rules, mixed and adapted by 
BHA, often outperform5 the best individual heuristics, as judged by ex-
amples. In addition, BHA provides almost sure convergence. However, 
the results of BHA depend on the quality of specific heuristics. The 
quality of heuristics reflects the expert knowledge. That means, BHA 
should be considered as a tool for enhancing the heuristics but not for 
replacing them. 
Many well-known optimization algorithms, such as the Genetic Al-
gorithms (GA) (Goldberg, 1989), GRASP (Mavridou et al., 1998), and 
the Tabu Search (TS) (Glover, 1994), may be considered as some general 
heuristics that can be improved using BHA. There are specific heuristics 
tailored to fit particular problems. For example, the Gupta heuristic 
was the best one while applying BHA to the flow-shop problem (Mockus 
et al., 1997). 
The Genetic Algorithms (Goldberg, 1989) is an important "source" 
of interesting and useful stochastic search heuristics. It is well known 
(Androulakis and Venkatasubramanian, 1991) that results of the genetic 
algorithms depend on mutation and crossover parameters. The Bayesian 
Heuristic Approach could be used in optimizing those parameters. 
In the GRASP system (Mavridou et al., 1998), a heuristic is repeated 
many times. During each iteration, a greedy randomized solution is 
constructed and the neighborhood around that solution is searched for 
5In terms of average errors. 

8 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
the local optimrun. The "greedy" component adds one element at a time, 
until a solution is constructed. A possible application of BHA in GRASP 
is in optimizing a random selection of a candidate to be in the solution. 
BHA might be useful as a local component, too, by randomizing the 
local decisions and optimizing the corresponding parameters. 
In the Tabu search, two important parameters may be optimized using 
BHA. Those are: 
â¢ best combinations of short and long term memory, 
â¢ best balances of intensification and diversification strategies. 
The examples show that the Bayesian Heuristics Approach is useful ap-
plying many well-known stochastic and heuristic algorithms of discrete 
optimization. The convergence conditions, if needed, are provided by 
tuning the BHA (Mockus et al., 1997). 

GENERAL IDEAS 
9 
7~---,----------------.-----r---------------,----------, 
6 
5 
4 
3 
2 
, 
---,\ / 
', 
'' 
,, 
,, ,, ,, 
, , 
' ' 
'' 
'. 
m(x)-
s(x) ----Â· 
R(x) -----
' ' 
' 
\ 
\ 
I 
0 ~--~~--------------~----~----------------~----------~ 
x(l) 
x(2) 
x(neld) 
x(3) 
x(4) 
x(5) 
Figure 1.1. 
The Wiener model. 
The conditional expectation m(x), the condi-
tional standard s(x), and the risk function R(x) with respect to observed values 
x(l), y(l), x(2), y(2), .... 

Chapter 2 
EXPLAINING BAYESIAN HEURISTIC 
APPROACH BY EXAMPLE OF 
KNAPSACK PROBLEM 
In the previous chapter we showed how BRA works while searching 
for the solution of the knapsack problem. Now we shall use this problem 
to illustrate similarities and differences of various approaches including 
BRA. 
The reason for such special attention is that the knapsack problem is 
a simple example of important family of NP-complete problems1. Note, 
that this example is good mainly for illustration of BRA and alternative 
approaches. The reason is that the simple greedy heuristic of the knap-
sack problem is very efficient. Therefore, only marginal improvements 
can be made by more sophisticated methods, including BRA. In schedul-
ing problems, such as the flow-shop and batch scheduling (Mockus et al., 
1997), BRA works more efficiently. However, the scheduling problems 
are more difficult for explanations. Thus, we start the explanations by 
the knapsack problem. 
The knapsack problem is to maximize the total value of a collection 
of objects when the total weight g of these objects is limited. Denote 
values of objects i by Ci and their weights by 9iÂ· 
n 
maxLCiYi 
y 
i=l 
n 
L9iYi ~ g 
i=l 
Yi E {0, 1}. 
(2.1) 
(2.2) 
1No polynomial time algorithm has been found for solving the NP-complete problems. No 
proof is known that these problems cannot be solved in polynomial time. 
11 

12 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
Here the objective C(y) = L:f=1 CiYi depends on n Boolean variables 
Yi, i = 1, ... , n. 
1. 
EXACT ALGORITHMS 
1.1 
EXHAUSTIVE SEARCH 
The decision m means that a collection of objects 
I(m) = {i: Yi(m) = 1} is selected. The value of the collection is 
c(m) = C(y(m)). This collection is described by the decision vector 
y = y(m) = (yi(m), i = 1, ... , n). The simplest exact algorithm is to 
compare all the collections: 
1. select a current collection I(mN), N = 1, ... K, 
2. record the best current collection I*(mN), 
3. stop when all the collections are considered N = K = 2n. 
The best current collection I*(mN) denotes the most valuable collection 
satisfying the weight limit that is obtained during N iterations. The 
best current collection is updated during the recording operation in step 
two. It is replaced by better current collection. The exhaustive search 
of all the decisions needs K = 2n of iterations. This means T = C 2n 
of time, where the constant C is the observation time (the CPU time 
needed to evaluate sum (2.1) and to test inequality (2.2)). 
1.2 
BRANCH & BOUND (B&B) 
The efficiency of exact algorithms can be improved by the Branch & 
Bound (B&B) techniques: 
1. define the decision tree, 
2. define the upper limits of the branches, 
3. cut the branch, if the upper limit is less then the best current collec-
tion, 
4. stop, if there are no more branches to consider. 
For example, 
1. branch 0: y1 = 0, branch 1: Yl = 1, 
2. the upper limit of branch 1: 
n 
C 1 = Cl +max LCiYi 
y 
i=2 

EXPLAINING BHA BY KNAPSACK EXAMPLE 
13 
n 
91 + L9iYi ~ g 
i=2 
the upper limit of branch 0: 
n 
C0 = max L CiYi 
y 
i=2 
n 
L9iYi ~ g 
i=2 
3. cut branch 0, if C 0 ~ c1 , 
4. stop, if there are no more branches to consider. 
In this algorithm, the number of iterations to obtain the exact solution is 
K ~ 2n and the time is T ~ C 2n. Usually, the timeT is much less then 
the exact upper limit C 2n. However, this limit may be approached. 
For example, if all the prices Ci and weights 9i are almost equal. In 
such a case no branches will be cut. That is a reason why approximate 
algorithms are preferred, if n is large. 
2. 
APPROXIMATE ALGORITHMS 
2.1 
MONTE CARLO 
The simplest approximate algorithm is Monte-Carlo (MC): 
1. select a collection I(mN), N = 1, ... , K with probability 2 
1 
r(m) = 2n, 
(2.3) 
2. record the best current collection J*(mN), 
3. stop, if the number of iterations N = K. 
Recording just the best current collection, one samples with replace-
ment. Otherwise, one should keep in the memory up to 2n of previous 
samples. In cases with replacement, one does not know when the op-
timum is reached. Therefore, MC stops, if the time allocated for the 
optimization is exhausted. This algorithm converges to an exact solu-
tion with probability one, if the number of iterations K -+ oo. However, 
the convergence is very slow, nearly logarithmic. Note, that the time 
T = Cnm is not a limit for MC with replacement. 
2That can be understood as a lottery with the probability r(m) to win a collection m. This 
lottery can be carried out by generating a random number~ uniformly distributed in [0, 1) 
and by selecting a collection m if~ < r(m). 

14 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
2.2 
GREEDY HEURISTICS 
Define the heuristic hi as the specific value of the object i 
h._ Ci 
z-
. 
9i 
{2.4) 
This "greedy" heuristic is the well known and widely used in the knap-
sack problem. The Greedy Heuristic Algorithms prefer a feasible3 object 
with the highest heuristic hi: 
1. select the object i with the best heuristic hi in the starting list4, 
2. move the object from the starting list into the current one, 
3. test feasibility of the collection which includes this object, 
4. if the collection is infeasible, delete the object from the starting list, 
5. test, whether the starting list is empty, 
6. if the staring list is not empty, go to the step one, 
7. if the starting list is empty, stop and record the current list as the 
best collection J*(mN), where N:::; n is number of the last iteration. 
The greedy heuristic algorithm is fast, T < C n 2 â¢ The inequality is 
there because objects are gradually removed from the starting list. The 
algorithm may stick in some non optimal decision. The greedy heuristic 
hi is obviously useless, if the specific values are equal hi = h, i = 1, ... , n. 
In such cases the outcome depends on the numeration of objects. 
2.3 
RANDOMIZED HEURISTICS 
LINEAR RANDOMIZATION 
Heuristic algorithms are shaked out of non optimal decisions by choos-
ing an object i with some probability ri that is proportional to the spe-
cific value hi, 
Ti = L'l=t hj. 
(2.5) 
This algorithm is similar to that of Greedy Heuristic: 
1. select an object i from the starting list at random with the probability 
3Satisfying inequality (2.2). 
4Initially the starting list includes all the objects 

EXPLAINING BHA BY KNAPSACK EXAMPLE 
15 
2. move the object from the starting list into the current one, 
3. test feasibility of the collection including this object, 
4. if the collection is infeasible, delete the object from the starting list, 
5. test, if the starting list is empty, 
6. if the staring list is not empty, go to step 1, 
7. if the starting list is empty, stop and record the current list as a 
current collection I(mN), N = 1, ... , K, 
8. record the best current collection I*(mN), 
9. start new iteration N + 1 by restoring starting list to the initial state 
(as a set of all the objects) and return to step 1, 
10. stop after K iterations and record the best current collection I*(mK). 
This algorithm is better than the greedy one, in the sense that it con-
verges with probability one when K --+ oo. The algorithm is expected to 
be better than Monte-Carlo, too, since it includes an expert knowledge 
by relating the decision probabilities to heuristics. 
MIXED RANDOMIZATION 
We may choose the preferred heuristic algorithm by considering all of 
them separately. Here the quality estimate of each algorithm is the best 
result obtained after K iterations. That is a traditional way. 
One solves the same problem in a more general setup by considering 
a "mixture" of different heuristic algorithms. For example, 
â¢ denote the Monte Carlo by the index l = 0, 
â¢ denote the Linear Randomization by the index l = 1, 
â¢ denote the Greedy Heuristics by the index l = 2. 
Then the Mixed Randomization uses the algorithm denoted by the index 
l with some probability x(l) that is defined by probability distribution 
x = (x(l), l = 0, 1, 2): 
1. select an algorithm l at random with probability x(l), 
2. record the best current collection I*(mN), N = 1, ... ,K, 
3. start the new iteration N + 1 by returning to step 1, 

16 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
4. stop after K iterations and record the best current collection I* ( mK), 
denote its value by fK(x) = c(mK). 
Here !K(x) is the best result obtained using K times the Mixed Ran-
domization with the probability distribution x5 . 
That is a way to extend a family of possible decisions from the discrete 
set x(l) E {0, 1 }, l = 0, 1, 2 to the continuous one. That is important 
because the best results we often obtain using a mixture of algorithms 
(Mockus et al., 1997). 
Here we mixed three approximate algorithms: the Monte Carlo, the 
Linear Randomization and the Greedy Heuristics. Following expres-
sions define a larger family of different approximate algorithms, includ-
ing these three 
and 
l_ 
hi 
ri -
"'?-
hl., l = 0, 1, 2, ... , L, 
L...J=l 
J 
ri(m) = { 1, 
0, 
if hi= maxi hj, 
otherwise. 
(2.6) 
(2.7) 
Here the superscript l = 0 denotes the Monte-Carlo randomization. The 
superscripts l = 1, l = 2, .... , l = L define a family of "polynomial" ran-
domizations. The superscript oo denotes the greedy heuristics with no 
randomization. The Mixed Randomization means using randomization 
functions rL l = 0, 1, 2, ... , L, oo with probabilities x(l) and recording the 
best result /K(x) obtained during K iterations. 
OPTIMIZATION OF MIXTURE 
The optimization of the mixture x is difficult because !K(x) is a 
stochastic function and the multimodal one, as usual. A natural way 
to consider such problems is by regarding functions !K(x) as samples 
of a stochastic function defined by some prior distribution. The next 
observation is obtained by minimizing the expected deviation from the 
exact solution. This technique is called the Bayesian Heuristic Approach 
(BHA) (Mockus et al., 1997). 
2.4 
PERMUTATION 
If we build a solution from "scratch," then we may apply so-called 
greedy heuristics (Helman et al., 1993). Building from scratch is conve-
nient, if no initial expert decision is known. Otherwise, building from 
5The algorithm is implemented in C++ and Java in the files fi.C and Knapsack.java cor-
respondingly (see section 4. for details). 

EXPLAINING BHA BY KNAPSACK EXAMPLE 
17 
scratch, one ignores the expert information included into that initial de-
cision. As usual, the permutation algorithms are used to improve initial 
decisions. 
In the knapsack problem, the complete collection I is a set of all n 
objects. The initial collection is a set of objects I(m0 ) = {i : Yi(m0 ) = 
1} E I satisfying the inequality 'EiEI(mO) 9iYi(m0) ~g. The value of this 
collection is c(m0). A complement of the initial set I(m0 ) is denoted 
JO(m0 ). We denote permuted collections as I(mi), j = 1, ... , J and 
values of these collections as c(mi). We define the direct permutation 
heuristics as 
(2.8) 
To avoid confusion, the longer symbols h(mi) and hn(mi) are used some-
times instead of the short ones hj and hnj. We define the normalized 
permutation heuristics as 
hnÂ· = hn(mi) = hj -Aj 
3 
Ai -Ai' 
(2.9) 
where Aj = minf=1 hk and Ai = maxf=1 hk. Normalized heuristics (2.9) 
can be easily converted into probabilities by expressions such as (2.6). 
Direct heuristics (2.8) are convenient in some well-known algorithms, 
such as Simulated Annealing. Here is an example of permutation algo-
rithm using linear randomization: 
1. make J feasible changes mJ, j = 1, ... , J of the initial collection 
I(m0), by replacing randomly selected objects using this algorithm 
(a) select at random with equal probabilities an object i1 from initial 
collection I(m0), 
(b) delete this object, 
(c) select at random with equal probabilities an object jo from com-
plement JO(m0) = {i : Yi(m0 ) = 0} of the initial collection, skip 
this step if the complement is empty, 
(d) put the object j 0 into the initial collection, 
(e) test the weight limit, 
return to step one of the replacement algorithm, if the updated 
collection is to heavy, 
2. define normalized permutation heuristics hnj for all the changes j = 
1, ... ,J, 
3. define probabilities ri by expression {2.13), 

18 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
4. select current collection I(mN), N = 1, ... , K at random with prob-
ability rj, 
5. record the best current collection I*(mN), 
6. stop after K iterations and record the best current collection J*(mK). 
SIMULATED ANNEALING 
The Simulated Annealing (SA) is a popular global optimization method. 
Features of SA, considering it as a permutation algorithm, are: 
- only one permutation is made, J = 1, 
- the direct heuristic is used 
(2.10) 
- if hj ~ 0, the new collection J(mi)is selected with probability one, 
- if hj < 0, the new collection is selected with probability rj that declines 
exponentially, 
rj = 
e"'/In(l+N), 
{ 
hj 
1, 
if hj < 0, 
otherwise. 
(2.11) 
Here N is the iteration number and x is the "initial temperature." The 
difference of this formulation from traditional simulating annealing algo-
rithms is that we optimize the parameter x for some fixed number of iter-
ations N = K. We disregard the asymptotic behavior. The asymptotic 
properties are beyond the scope of the Bayesian Heuristics Approach. 
GENETIC ALGORITHMS 
General Idea. Genetic Algorithms ( G A) present a general and vi-
sual way of permutation and randomization. GA is a methodology for 
searching a solution space in the manner similar to the natural selection 
procedure in biological evolution (Roland, 1975). Each candidate solu-
tion is represented by a string of symbols. The set of solutions at some 
state m is called the population of the mth generation. The population 
evolves for a prescribed number M of generations. The basic structure 
processed by GA is the string. Strings are composed of a sequence of 
characters. 
A simple GA consists of 
-one reproductive plan, defined as the fitness proportional reproduction 
- two genetic operators, defined as crossover and mutation. 
The probability of selection is defined in proportion to the fitness of 
individuals 

EXPLAINING BHA BY KNAPSACK EXAMPLE 
19 
During the crossover operation one splits two selected strings at some 
random position s. Then two new strings are created, by exchanging all 
the characters up to the split point s. During the mutation operation 
one alters some string characters at random. A mutation is of l-th 
order, if one changes l elements during one mutation operation. Both 
the crossover and the mutation are feasible, if they satisfy all constraints. 
It follows from this definition that GA may be considered as a special 
case of the Permutation and Randomization. Thus, one may include GA 
into the framework of Bayesian Heuristic Approach. We illustrate that 
by using the Knapsack problem as an example. 
Explaining Genetic Algorithm by Knapsack Example. In the 
Knapsack example the string of the collection J(m) is represented as the 
Boolean vector 
y(m) = (yi(m), i = 1, ... , n). 
(2.12) 
The fitness of feasible6 collection mi is c( mi). The probability to select 
a string mi is 
rÂ· _ 
hnj 
1 -
:Ek=1 hnk ' 
(2.13) 
where hnj is the normalized permutation heuristics 
Â· 
c(mi)- Aj 
hnj = hn(m1) = A. 
A 
. 
(2.14) 
J-
j 
Here Aj = minÂ£=1 c(mk) and Ai = maxÂ£=1 c(mk). 
During the crossover operation one splits two selected strings at some 
random position s, 1 < s < n. Then two new strings are created, by 
exchanging all the characters up to the split point s. 
During the mutation operation one produces J mutants by inverting 
randomly selected components Yi of the Boolean vector y. A mutation 
is of l-th order, if one changes l, 1 ~ l ~ n components during one 
mutation operation. A mutant is fertile, if it satisfies all the constraints. 
Denote by I(mN) a current collection at Nth iteration. Denote by 
I*(mN) the best current collection obtained during N iterations. 
Here is an example of a simple GA algorithm written in BHA terms. 
The algorithm is similar to that of Permutation. 
1. produce a number J of fertile mutants by replacing randomly selected 
objects using feasible changes mJ, j = 1, ... , J of the initial collection 
J(mo), 
6 Assume for simplicity that all the non feasible collections are eliminated automatically. 

20 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
2. define normalized permutation heuristics hnj, j = 1, ... , J for all these 
mutants using expression (2.14), 
3. define probabilities rj by expression (2.13), 
4. select two mutants Ij ( m +) and Ij ( m-) at random with probabilities 
rÂ·7 
J 
l 
5. select a split point s at random with probability 1/n 
6. inverse the components Yi(m+), i :::;: s and Yi(m-), i :::;: s of these 
two mutants, 
7. update normalized permutation heuristics hnj reflecting cross-over 
results 
8. update probabilities Tj using (2.13) 
9. select a current collection at random with the probability rj, 
10. record the best current collection I* ( m 1) 
11. go to step 4 with the probability x(O) 
12. produce J fertile mutants by feasible changes of the current collection, 
13. define normalized permutation heuristics hnj, j = 1, ... , J, 
14. define probabilities rj by expression (2.13), 
15. select a current collection at random with the probability rj, 
16. record the best current collection J*(m2 ) and return to step 11, 
17. stop after K iterations and record the best current collection I*(mK). 
It is tacitly assumed that some segments of strings define specific" traits." 
In such cases, one may" enforce" good traits by uniting" good" segments. 
One may expose bad traits by uniting "bad" segments, too. Then, re-
production plans tend to favor the good traits and to reject the bad 
ones. 
Thus, the crossover operation "improves" the population, if the "traits" 
assumption is true. If not, then the crossover may be considered merely 
as a sort of mutation. That may help to jump the area dividing separate 
7If by chance the same mutant m = m+ = m- will be selected then repeat the selection 
procedure. 

EXPLAINING BHA BY KNAPSACK EXAMPLE 
21 
"local" minima. However, the similar jlllllp may be accomplished by 
high order mutations, too. 
As usual (Androulakis and Venkatasubramanian, 1991), mutations are 
considered as more "radical" operations as compared with crossovers. 
That is correct, if one changes many elements of the "genetic" sequence 
during one mutation. This happens, if the mutation order l is close to 
the string length n. 
The results of some real life examples of network optimization (Mockus, 
1967) and parameter grouping (Dzemyda and Senkiene, 1990) show that 
low order mutations, when merely a few elements of the decision vec-
tor r(k) are changed, work better. In such cases, the mutation may be 
considered as a less radical operation because fewer components of the 
vector y are changed, as compared with the crossover operation. 
We may improve efficiency of the simple GA algorithm by using the 
crossover rate x(O) (see step eleven of the algorithm) as an optimiza-
tion variable in the framework of BHA. This was applied solving the 
Batch Scheduling problems (Mockus et al., 1997). If the crossover rate 
is considered as a time function (Androulakis and Venkatasubramanian, 
1991), the parameters of this function can be optimized using BHA. 
3. 
SOFTWARE EXAMPLES OF KNAPSACK 
PROBLEM 
There are two software versions: one in C++ and one is Java. In 
the C++ version, prices Ci and weights 9i are generated randomly. In 
the Java case, Ci, 9i reflects a real life example (Malisauskas, 1998). 
The optimal probability x( oo) of the greedy heuristic hi = ci/ 9i is near 
to one, but not exactly one. Some degree of randomization helps to 
escape non optimal decisions. The randomized procedures x(l), rY) are 
defined by (2.6) and (2.7). Both the software versions consider just three 
components. 
The G + + version uses the Monte Carlo, the Linear and the Quadratic 
randomizations. Corresponding optimization parameters are 
x = (x(O), x(l), x(2)). The Monte Carlo and Linear randomizations and 
the Pure Greedy heuristic are applied in the Java version. Corresponding 
optimization parameters are 
x = (x(O), x(1), x(oo)). 
We are looking for such probability distribution x that provides the 
maximal fK(x) after K iterations. Bayesian methods (Mockus, 1989a; 
Mockus and Mockus, 1990; Mockus et al., 1997) are used for that. 

22 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
3.1 
C++ 
The aim of the GMC version is to estimate average error of BRA. A set 
of knapsack problems with random prices Ci and weights 9i is considered. 
The results of BRA and the exact deterministic B&B algorithms are in 
Table 2.1. 
Average results were obtained by repeating the optimization proce-
dures K = 100 times at fixed parameters q, 9i and probability distribu-
tion x. In Table 2.1 No is the number of objects. K is the number of rep-
Table 2.1. 
Com pari son of the Bayesian method and the exact one. 
Ks = 100, and K = 1 
No 
KE 
fs 
/E 
t5s% 
xs(O) 
xs(1) 
xs(2) 
50 
313 
9.56057 
9.62347 
0.654 
0.0114 
0.0280 
0.9605 
100 
526 
13.0703 
13.1241 
0.411 
0.0316 
0.0412 
0.9271 
150 
771 
16.6301 
16.6301 
0.000 
0.0150 
0.1945 
0.7904 
200 
875 
37.4665 
37.4859 
0.050 
0.0315 
0.0530 
0.9437 
250 
568 
53.7781 
53.9000 
0.226 
0.0091 
0.0511 
0.9397 
300 
1073 
28.3144 
28.6106 
1.034 
0.0113 
0.0835 
0.9050 
350 
1416 
30.4016 
31.7527 
4.254 
0.0064 
0.0646 
0.9288 
400 
2876 
32.1632 
33.3192 
3.469 
0.0202 
0.0452 
0.9344 
450 
1038 
105.467 
105.578 
0.105 
0.0101 
0.0149 
0.9748 
500 
2132 
39.3583 
42.1047 
6.521 
0.0078 
0.1556 
0.8365 
etitions. KB is the total number of observations by the Bayesian method. 
KE is the number of nodes considered by the exact method. fB is the 
best result of the Bayesian method. f E is the exact optimum. 6 B% is 
the mean percentage error of the Bayesian algorithm. XB(n), n = 0, 1, 2, 
are optimized probabilities of different randomizations obtained using a 
Bayesian method. If the deviation of some solution does not exceed 5%, 
we call this a 5% solution. One can expect that the 5% solution satisfies 
the applications, where the level of data uncertainty is not less than 5%. 
Table 2.1 shows that we need to consider from 313 to 2876 nodes to 
obtain the exact solution. Only 100 observations are needed to obtain 
the 5% solution by the Bayesian method. The deviation exceeds 1% only 
for three cases in ten. The average deviation is 1.67%. 
Assume that roughly the same computing time is necessary for one 
node and for one observation. Then the Bayesian 5% solution is about 
three times "cheaper" as compared to the exact one, if the number of 
objects is fifty. If this number is 400, then the Bayesian 5% solution is 
almost thirty times cheaper. Other examples, in particular ones applying 

EXPLAINING BHA BY KNAPSACK EXAMPLE 
23 
BHA to a family of scheduling problems (Mockus et al., 1997) show 
higher efficiency of BHA. 
3.2 
JAVA 
Here we optimize a "mixture" x of the 11onte Carlo randomization, 
the linear randomization, and the pure greedy heuristic. The aim is to 
show how BHA works while solving a real life knapsack problem. The 
example illustrates how to apply the Java software system for global 
optimization called as GMJl. Therefore, several figures are included. 
They illustrate the input and output of GMJ1 graphical interface. 
DATA FILE 
The data represents the weights, the values, the numbers, and the 
names of inventory items of the "Norveda" shop that sells "Hitachi" 
electrical tools. Table 2.2 shows a fragment of data file 'norveda.txt'. 
Here fields, separated by spaces, denote these parameters of objects: 
Weight 
Value 
Number 
Name 
3.8 
2830 
1 
CNF35U 
10.5 
4170 
2 
CNF65U 
11.5 
3850 
1 
CM12Y 
1.8 
1500 
2 
CE16 
1.7 
1500 
2 
CN16 
17.0 
2100 
4 
CC14 
20.9 
2890 
2 
J9312N 
0.9 
330 
8 
D6SH 
1.7 
1170 
10 
DlOYA 
1.3 
630 
5 
DlOVC 
Table 2.2. 
A fragment of data file 'norveda.txt.' 
â¢ weights 9i (double), 
â¢ prices Ci (double), 
â¢ numbers (integer), 
â¢ names (string). 
IMPLEMENTING TASK 
The algorithm is implemented as a Task of the GMJ1 system. Figure 
2.1 shows a fragment of the file 'Knapsack.java' 

24 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
public class Knapsack implements Task 
{ private double 
norm_point[]; 
private int 
number_of_objects; 
public double total_weight=10; 
private int 
object_taken[]; 
private float object_cost[]; 
private float object_weight[]; 
private double 
object_ratio[]; 
private Random rnd =new Random(); 
public String data_url =new String( 11http://norveda.txt 11 ); 
private String data_url_old =new String(); 
Figure 2.1. 
A fragment of the knapsack program. 
RUNNING GMJl 
Figure 2.2 (top) shows the input page. 
On Property fields, 
TotalW eight is the weight limit, from 10 to 10.000, 
U RL of data file is the URL address. 
This data file is on the same server as the applet. If the data is not 
correct, the corresponding field turns red. In the black-and-white figure 
2.2, red is shown as the dark shadow. Therefore, the incorrect URL 
address is not legible. 
On the Dimension fields, 
Min is the minimal value of x(l), 
Max is the maximal value of x(l), 
Default is the default value of x(l). 
The values x(l) show the proportions of each method. The mixture of 
three methods of picking objects is considered: the Monte Carlo, the 
Linearly Randomized Heuristics and the pure Greedy Heuristics. Prob-
abilities xz of methods l, l = 1, 2, ... are related to the proportions x(l) 
this way xz = x(l)/ Ej x(j). Figure 2.2 {bottom) shows the output page 
that opens when the computing is completed. Here Iteration means 
the iteration number where the best value was reached. F(x) defines 
the best value, "Monte Carlo." "Randomized Heuristics," and "Greedy 
Heuristics" show the optimal part of each of the three methods in the 
mixture. 
Figure 2.3 (top) shows how the best value of fK(x) changes subject 
to the iteration number. 

EXPLAINING BHA BY KNAPSACK EXAMPLE 
25 
don or Method tUtd T 
To:.>l e.g t 
URL of d ~ f1 t 
rt c lo 
R nd.mJ;:td llâ¢ur >liG 
Crt dy H< 
I !los 
GMJG Applet, Collection of Methods and T~ks 
I ~Mhod 'fJi$kY Opera ion \\...-----------------~ 
Iteration 
4 
F(Xl 
-13970.0 
Randomized Heurlstks 
3 75 
Greedy Heuristics 
3.75 
Figure 2.2. 
Input page (top) and output page {bottom). 
Figure 2.3 {bottom) shows how !K(x) changes subject to proportions 
of the Monte Carlo randomization. 

26 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
-1000 
-Â· 
-2000 
-3000 
-4000 
-sooo 
I 
_J_ 
-tÂ· I \ 
l ~-"Â· 
,~ - Â·Â·---
t -Â· 
I 
' 
1-
' 
-
~-
-liiOOt 
-7000 
-8000 
-9000 
0 
5 
15 
20 
25 
30 
35 
40 
45 
u. 
J Java Applet Window 
-1000 
0 
I 
a 
-2000 -I 
0 
-3000 -
<ll 
I 
0 
0 
-4000 -
0 
I 
0 
0 
-5000 l) 00 
-liiOOO ~ 
oo 
0 
-7000 -
-8000 0 
-9000 ., 
,o 
I 
I 
- ~ -- ~-0 -
t 
0 
t 
2 
3 
.. 
s 
Iii 
7 
8 
)( 
Monte Carlo 
Java Applet Window 
Figure 2.3. 
The best obtained value subject to iteration numbers (top), the objective 
function subject to proportions of the Monte Carlo randomization (bottom). 
Figure 2.4 (top) shows how fK(x) changes subject to proportions of 
the linear randomization. 

EXPLAINING BHA BY KNAPSACK EXAMPLE 
27 
Figure 2.4 (bottom) shows how !K(x) changes subject to proportions 
of the pure greedy heuristics. 
It is hard to notice any regularity in the Projection windows in Fig-
ures 2.3 (bottom), and 2.4. The reason is that all the variables change 
together during the optimization. To see good projections, one uses the 
method Exkor. Variables change one by one in this method (see Figures 
8.4 and 8.5). 
RESULTS 
Table 2.5 shows how the results of optimization depend on the op-
timization method (the first column), the number of iterations ( the 
second column), and the weight limit (the third column). The fourth 
column shows the iteration number where the best value was obtained, 
the fifth column shows the best value8. The sixth, the seventh, and 
the eighth column define the optimal mixture of three search methods. 
These mixtures can be expressed in percentage terms dividing each of 
the three numbers by their sum and multiplying by 100. 
The results suggest that 
â¢ doubling the iteration number (from 500 to 1000) we lower the aver-
age error just by 3%, 
â¢ if the weight limit g is high, the greedy heuristic is almost useless 
(the optimal mixture x = (7 /15, 7/15, 1/15) meaning that the greedy 
heuristics part x(oo) is just 1/15, 
â¢ if the weight limit g is low, the greedy heuristic is essential (the 
optimal mixture x = (1/6, 1/6, 4/6) because the greedy heuristics 
part is ten times greater. 
8The sign is minus, because by default GMJ reduces the objective of the Task object. 

28 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
0 
-3000 -b 
-~000-
_ b 
o 
I 
0 
-5ooo -0 
Q> 
-6000 -6> 
0 
bo 9 
-7000 -
0 
-8000 0 
-'3000 
0 
Randomized Heuristics 
Java .l\pplet Wmdow 
--t- o 
<o 
0 
<> 
0 
0 
0 
0 
8 
0 
~0 
0 
0 
0 
0 
0 
I 
o o 
-~ooo j 
O o--
0 
I 
- ooo ..., 
-=to 
o 
- 0 -
I 
7 
-q 
0 
occ, 
<Q 
+---t----+--o 
t----t--- ---
o<> 
0 0 
Oo 
-6ooo -<C<b 
-
c~o~ 0 o 
I 
I 
I 
OQQ 0 
::::: ~--EI : 
-'~ ? -+-0.;;._-t----+--~ 
0 
2 
3 
4 
5 
" 
Greedy Heuristics 
Java Applet Window 
Figure 2-4-
The objective function subject to proportions of the lineax randomization 
(top), the objective function subject to proportions of the pure greedy heuristics 
(bottom). 

EXPLAINING BHA BY KNAPSACK EXAMPLE 
29 
trlatllo4 Â· It~~~~ r~;;,;l Â· rÂ· Beot .... ~Â· Â·Â·~.tÂ·Â·Â·Â·-r Â·Â·e:;;~~ Â·- r~-;~ 
("'c~~; Â·Â·-: 
! J\\11110<:>1: 
1 """191\t 
. 1tt:atl011. 
Clulctl<m ! C'at:lo 
: X..U.n.~ttlclt ! XD'u.t:lctlce i 
: 
: 
! 
! 
: 
: 
. 
... rÂ· 
Â·Â·Â·Â·Â·rÂ·Â·Â· 
r .......... -... Â·Â·Â·Â·Â·Â·rÂ· 
i 
-Â·Â·- Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â· ........ 
--Â·' 
i 
: 
~u 
-u79 
, 
1 , 23 
1 
9 ,2Â·n 
1,141 
I 
! 
~ 
: 
I 
t 
I 
i 
1 100 
1 
-Â·Â·;Â·~~ ......... rÂ·Â·: Â·,~,-~-; .. -r-2Â·:Â·;:;-; .... Â·r-Â·Â·,Â·:-~4Â· ; .. Â·Â·-Â· .. rÂ·Â·Â·Â·Â·;: Â·, Â·~Â·;Â·Â·-Â·Â·Â· .. , 
~ 
= 
, ......... - . .......... , ...... Â·-Â·Â·Â·Â·-Â·Â·- , ..... -Â·Â·Â·Â·-Â·Â·Â·- Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â· 
Â·Â·Â·-Â· Â·Â·Â·Â·Â· Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â· -Â·Â·-Â·Â·Â·Â·Â·Â·-- = 
i 
! 
j 
90., 
i - u"o i 1 . n~ i 
9 , 211 
' 
7 , 112 
! 
i 
lUOO 
(Â·Â·Â·Â·-.............. :-............... '-Â·Â· ........... :.. ............. 
~....... ......... 
.. .. ~ .. -
.. Â·Â·Â·-Â·Â·Â·-~ 
i 
; 
i 
912 
â¢ -4n&u 1 o.on ! 
~ . 
! 
2,n9 
J 
~ 
! 
~-Â·Â· ........... Â·Â·Â·-~-... -Â·-Â·Â·Â· .. Â·Â· -Â·~Â·Â·Â·Â·Â· .. --......... ~ .............. Â·Â·Â·Â·-Â·-Â·Â·Â·Â· ~-Â·-Â·Â·Â·Â·Â·Â·-Â·Â· --Â·-Â·Â·; 
i 
! lOOO 
j 
"7H 
i -4 ~230 l O, O.Q-, 
~ 
l ,2" 
l 
O,.QU 
i 
! 
I 
: ....... ; ~ ... Â·-: .. Â·.:~;Â·:.~Â·;_Â·~-~-;~-~~- ;(;Â·-~Â·:Â·~ -~-, ..... , ...... 9 :Â·;:;-~ ...... r-Â·-;~:~-~-~ .. ~~1 
Ul<Jl r .................... j" .................. r .. m 
: -u 40 
' 
~-:;~~ ............. ; .. :Â·~~ -~-Â·-i-- , ,9u 
I 
â¢ 
r 
:Â·Â·--Â·Â·Â·Â·â¢ Â·-Â·Â·Â·Â· ;._., ............. 
:--Â·"Â·Â·Â·Â·Â·Â·-Â·Â·Â·Â·Â·~Â·Â·Â·Â·- Â·â¢Â·Â·Â·Â·Â·Â·Â· Â·-Â·â¢â¢Â·-Â· .. -Â·! ...... - .................... ; 
1,. 
1 G 0 
~ 
â¢â¢. :?.~ ......... ~ ... -.~ -~-~~-~--Â· ! .... ~.:~~~ ..... ~ ....... ~ .. :~.~:.. ..... ~ ...... ~ Â·~~~ ......... ! 
I 
i 
J!i') 
I - "703&0 l 4 , H4 l 
9
. ~21 
i 
~.ill 
j 
, .................. ! ---Â·Â· ...... 1"-- Â·Â·Â·Â·-Â·Â·Â·" .--Â·Â· ... Â·--Â· .. , .................. Â·Â·- tâ¢ Â·Â·--Â· .. _ 
-~ 
i 
, .ou 
1 -uu.oo i o , lOl i 
., , 12 
i 
1.so.o 
, 
i 
! 
: 
t 
. 
: 
! 
! 1000 r-Â· .. Â·;Â» ...... -~ .. :~-;;Â·;~~-r .. i-:;~ Â·~ .. Â·-!" ...... ~-~-;~~ .. -.... rÂ·Â· -~ Â·:-;Â·Â·~ ...... _1 
: 
: 
: 
: 
i 
: 
. 
~00 
! 
...... -
............... 1., __ , .............. : ........................ :''"''' ...,,_,_, .......... !'''"''-"'"" ............. : 
I 
i 
4]') 
I - 4131"70 j 2 , S42 
l 
6,119 
i 
G,il<l 
I 
â¢ 
: 
â¢ 
â¢ 
1 
â¢ 
: 
-.. -Â·-Â·Â·-rÂ·--....... T m Â·-r - ~-;.ov -["~':; 5 Â·i""T""";~Â·~.,~Â·-Â· 
'),519 --1 
! 
, 
-Â·~Â· .. i ---
Â·Â·---Â· 
~--Â·Â· Â·Â·-Â·Â·Â· Â·Â·rÂ· .. Â·Â· 
Â·Â·Â·Â·Â·~ .. -Â· .. Â·Â·~ 
............... 1 
1 
100 
~ ..... ~.~-~ -Â· ...... ~ .. ~.~-~~~-~---~ .... ~ 
.. ~~: ..... ! ....... ~.:.~ .~ ........ l--Â·Â·Â·.:.?.~ .~ ......... 1 
] 
i 
5.95. 
I - i7490 ! 1.21i~ i 
9. SOl 
i 
2,119 
i 
!"_ .......... _ cÂ·-Â·;4;-Â· ; .. :;')Â·;Â·;Â·~ i~ Â·. <l ;;-r-Â·; 
,;~~ .. Â·Â·-r .... Â·;: Â·,;~-] 
1 1000 
! 
~~~ -
- .. ~ -~ 
.. ~;Â· so~--Â·r Â·Â·~-:Â·;~; .... i ..... ;-:~];-Â·Â·-rÂ· Â·-l Â·:;;~ 
1 
l 
! 
: 
l 
! 
I 
! 
rÂ·---Â·Â·-.. --.. Â·-- i......... ............. ,....... ... ......... ~ ....... -u ........ _ 
.... _! .. _ ............... _ ........ ! 
l 
j 
4') 
! - 5051"70 l 0 , 0-,l 
I , U.l' 
l 
0,191 
i 
!'aJ'â¢~ 1rÂ·Â·-Â· .. -Â·-r .............. T 401 Â·-r Â·~ ;~ ~ -5~ ... T ;~~-~9 ..... r .. -:;~~;~Â·- ... r- ~-:;-~; Â· 
--Â·1, 
. 
l 
~r--Â·Â· 
....... Â·Â·Â·Â·-Â·Â· .. ~.-.... - ... _ ..... ;. 
1 
i 
100 
211 
1 -uno l o.o11 
! 
1 . 211 
i 
s.n9 
1 
! 
' ;Â·;Â·;" Â·Â·--~-~Â·;Â·;~4~ .. -[ .... ~ .. :;~~""' i ........ ;:~;Â·;Â·--.... i""""i':Â·-;,Â·Â·-.. -1 
[ .................... ;-.. -~-~-~-Â·Â· .. tÂ·:; Â·Â·Â· ~;-;~Â·"1"~Â·:Â·;:;-; Â· ... (""'~Â·:-~;Â·;"""-f"" -;~ 2Â·;;-Â·"Â·"1 
1000 
~0 0 
: 
â¢ 
... 
Â·Â·-:- Â·Â·Â·Â·--
-r ......... . ... , ... Â·--Â· ...... , ..... Â·--Â·Â· .... -~ 
i 10 o l 
n 
-uun ! o ,4n i 
~ . ., 
~ 
j 
0,219 
1 
: 
:Â·Â·Â·-Â·Â·Â·Â· ........ 
. ................................................. - ....................... , .................. _,,, .. , 
i 
i 
11"7 
! -U22i0 j O, OU i 
1 , H& 
; 
1,111 
1i 
: 
i 
! 
l 
: 
! 
Figure 2.5. 
Table of results 

II 
SOFTWARE FOR 
GLOBAL OPTIMIZATION 

Chapter 3 
INTRODUCTION TO SOFTWARE 
1. 
GENERAL DESCRIPTION 
1.1 
BACKGROUND 
The software system Global Minimizer {GM) was initiated in early 
eighties. An initial set of algorithms was selected considering results of 
the international "competition" of different global optimization meth-
ods {Dixon and Szego, 1978). The experience in real life optimization 
problems was used updating the set. The set of global optimization 
algorithms includes 
â¢ four versions of the Bayesian search, 
â¢ a version of clustering, 
â¢ a version of the uniform deterministic grid, 
â¢ a version of the pure Monte Carlo search. 
As usual, the global optimization is concuded by some local method. 
Exceptions are two global algorithms: the Torn version of clustering 
(Torn and Zilinskas, 1989), and the Zilinskas version of the Bayesian 
technique (Torn and Zilinskas, 1989). Both these algorithms contain 
some simple local search algorithms. The additional local search is not 
necessary for those two methods, but it may be useful. 
There are three local optimization methods: 
â¢ a method of sequential quadratic programming for constrained opti-
mization of smooth functions (Schittkowski, 1985), 
33 

34 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
â¢ a simplex type method of Neider and Mead with penalty functions 
for constrained optimization of non-differentiable functions (Himmel-
blau, 1972), 
â¢ a method of stochastic approximation type for "noisy" functions 
(Mockus, 1989a). 
1.2 
DESCRIPTION OF METHODS 
GLOBAL METHODS 
Bayesl is the Bayesian method (Mockus et al., 1997). 
Region : rectangular. 
Objective : continuous (possibly with "noise"). 
Convergence : to global minimum {in probability, if noisy). 
Comments: 
for "expensive" objectives using not too many observations. 
Migl is the Monte Carlo search. 
Region : rectangular. 
Objective : general. 
Convergence : in probability. 
Comments: 
for inexpensive and irregular objectives using great number of 
observations. 
Unt is the extrapolation type method (Torn and Zilinskas, 1989). 
Region : rectangular. 
Objective : continuous. 
Convergence : to global minimum. 
Comments: 
for expensive objectives using not too many observations. 
Exkor is the Bayesian coordinate line search method (Torn and Zilin-
skas, 1989). 
Region : rectangular. 
Objective : continuous. 
Convergence : to global minimum on the search line. 

INTRODUCTION 
35 
Comments: 
for approximately "separable" objectives and for preliminary ex-
ploration using the projection windows. 
Glopt is the clustering method (Torn and Zilinskas, 1989). 
Region : rectangular. 
Objective : continuous. 
Convergence : not provided. 
Comments: 
works well in many practical problems with a moderate number 
of local minima. 
Lpmin is the uniform deterministic search (Sobolj, 1967; Dzemyda et al., 
1984). 
Region : rectangular. 
Objective : general. 
Convergence : to global minimum. 
Comments: 
for inexpensive objectives using many observations. 
LOCAL METHODS 
Nlp is the non linear programming method (Schittkowski, 1985). 
Region : defined by linear and non-linear constraints. 
Objective : differentiable. 
Convergence : to local minimum. 
Flexi is the simplex method (Himmelblau, 1972). 
Region : defined by non-linear constraints. 
Objective : non differentiable. 
Convergence : not provided. 
Lbayes is the stochastic approximation method with the Bayesian step 
size control (Mockus, 1989a). 
Region : rectangular. 
Objective : continuous with noise. 
Convergence : to local minimum, in probability. 

36 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
1.3 
APPLICATION AREAS 
Each subroutine represents a global or a local method. The choice of 
methods follows the comparability idea. That means that the compu-
tational complexity of the method should roughly correspond to that of 
the objective function: 
â¢ The Bayesian methods are recommended for "expensive" 1 functions. 
Those methods need auxiliary calculations to make each observation 
more efficient. 
â¢ For "cheap" functions, simple grid methods, like the Monte Carlo or 
the uniform deterministic grid (Sobolj, 1967), can be better. Here 
observations are not so efficient, but auxiliary calculations are neg-
ligible. This explains the relative efficiency of simple methods when 
optimizing simple functions. 
â¢ The clustering techniques (Torn and Zilinskas, 1989) may be the best 
choice, if we expect the number of local minima to be small. 
â¢ A simple Bayesian technique is available (Torn and Zilinskas, 1989) 
for global optimization of one-dimensional functions. 
â¢ There are optimization problems where objective functions can be 
roughly represented as a sum of components depending on different 
variables. Here the Bayesian method doing a line search along each 
coordinate shows good results, as usual. This method globally opti-
mizes one variable at a time by the one-dimensional Bayesian search. 
Therefore, results depend on the starting point. This is the difference 
of this method from other methods of global optimization. 
However, a deviation from the global minimum can be made as 
small as desired by applying a multi-start search from different uni-
formly distributed starting points. The important advantage are 
good projections. They show how an objective function depends 
on different variables (see Figures 8.4 and 8.5). The other methods 
present messy projections (see Figures 2.3 (bottom), and 2.4). The 
reason is that all the variables change together. 
1.4 
CONSTRAINTS 
All the global methods optimize in rectangular regions. Therefore, 
one represents linear and non-linear inequality constraints as penalty 
1 In a sense of computing time. 

INTRODUCTION 
37 
functions. The same applies to the local method of stochastic approxi-
mation type. In the local methods of simplex and sequential quadratic 
programming type, the linear and non-linear constraints are defined di-
rectly. This is done by constraint subroutines, supplied by users in 
addition to the objective function. 
1.5 
COMPUTING ENVIRONMENT 
There are several versions of global optimization software 
â¢ a portable Fortran library, 
â¢ interactive software for Turbo C compilers and DOS operating sys-
tems, 
â¢ interactive software for C++ compilers and Unix operating systems, 
â¢ three versions of interactive software using Java ( for JDKl.O, for 
JDK1.1, and for JDK1.2). 
One may notice a cycle of portability in this sequence of software ver-
sions. The sequence is started by the portable Fortran library and is 
concluded by the Java systems. The systems between those two are more 
difficult to port. Fortran, Turbo C, and C++ versions are in {Mockus 
et al., 1997). All the software is on web-sites (see section 4. and Figure 
3.1). 
2. 
EARLY APPLICATIONS 
Besides examples of this book, we briefly mention the examples con-
sidered in early publications {Mockus, 1989a; Mockus et al., 1997). Many 
of them are related to the optimization of parameters of mathematical 
models, represented as some systems of non-linear differential equations. 
The objective function f(x) depends on a solution of these equations. 
Variables x represent the controlled parameters of the system. The fol-
lowing examples illustrate this family of problems. 
â¢ Maximization of general yield of differential amplifiers (Mockus, 1989a). 
â¢ Optimization of a mechanical system of shock-absorber (Mockus, 
1989a). 
â¢ Evaluation of parameters of non-linear regression of an immunological 
model (Mockus, 1989a). 
The last example suggests a broad area for applications of global op-
timization. It is well known that in non-linear regression the square 

38 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
Figure 3.1. 
The Software Systems page. 
deviation and the likelihood function could be multi-modal, for some 
data. The number of local minima may be very large, even in simple 
cases. An example is the evaluation of unknown parameters of ARMA 
models (Mockus et al., 1997). There are other important families of 
global optimization problems. 
â¢ The engineering design is a large source of difficult global optimiza-
tion problems. One optimizes parameters of some mathematical mod-
els, non-linear, as usual. The optimization of composite laminates 
{Mockus et al., 1997) serves as an example. 
â¢ Many laws of nature could be defined in terms of global optimization. 
An example is the "Disk" problem: minimization of the potential 
energy of organic molecules {Mockus et al., 1997). 
â¢ Often one cannot describe the behavior of new materials and tech-
nologies by mathematical models, because the information and knowl-
edge are not complete. Here one optimizes by changing control vari-

INTRODUCTION 
39 
abies and observing the results of direct experimentation. An exam-
ple is the planning of extremal experiments of thermostable polymeric 
compositions (Mockus et al., 1997). 
The Bayesian algorithms of the continuous global optimization are an 
essential part of BRA. One applies them to optimize the parameters of 
randomized heuristics while solving various discrete optimization prob-
lems (Mockus et al., 1997). 
3. 
DIFFERENT VERSIONS 
3.1 
FORTRAN LIBRARY, PORTABLE 
The description of the global optimization software starts from the 
Fortran library (see Chapter 4). In other versions, mostly the same al-
gorithms are used. Their parameters have a similar meaning. Therefore, 
the Turbo C, C++, and Java users may obtain some useful information 
by reading the Fortran library description. 
The portable Fortran version can run on any computer with a stan-
dard Fortran compiler. Users represent objective functions as 
FUNCTION FI(X,N). Here X is an array of variables and N is its di-
mension. The lower bound array A and the upper bound array B define 
rectangular constraints. Using local methods of simplex and sequential 
quadratic programming type, one represents constraints by the subrou-
tine 
CONSTR(X,N,G,MC). Here, G is an array of length MC that contains 
values of constraints at a point X. M C is the number of constraints. 
The advantage of the Fortran library is the portability. A disadvan-
tage is limited interactive possibilities. Therefore, this version can be 
conveniently used for some well-defined optimization problems. For pre-
liminary investigations of new problems, some interaction is essential. 
3.2 
TURBO C, INTREACTIVE 
This version is for objective functions represented in C. It needs a 
Turbo C compiler. Users represent the objective function f(x) as the C 
subroutine fi.c. Users can select a global or a local method by a menu 
system. Current results are observed in both, tabular and graphical, 
forms. There are two graphical forms. 
GRAPH : shows how the best value of an objective function depends 
on observation numbers, 
PROJECTION : shows how current objective function values depend 
on a variable. 

40 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
The set of methods, in both the Fortran and the Turbo C versions, re-
mains the same, except a non-linear programming method. The Biggs 
method (Biggs, 1975) is implemented in Fortran to solve non-linear pro-
gramming problems. In all other languages, the sequential quadratic 
programming (Schittkowski, 1985) is used for these problems. 
Good interactive facilities is an advantage of the Turbo C version. A 
disadvantage is that this version can be used only in the DOS-compatible 
environment. Often one prefers Unix systems while solving large scale 
optimization problems. 
3.3 
UNIX C++, INTERACTIVE 
This is a global optimization software designed for UNIX and X -
Window systems. It includes a usual set of interactive facilities. The 
main feature is the possibility to port to any environment that supports 
Unix and X-Window, including super computers and distributed com-
puting systems. 
3.4 
JAVA JDKl.O, INTERACTIVE 
This is a global optimization software in Java, designed for the JDKI.O 
tool kit. The graphical interface is similar to that of the Unix C++ 
version. It can be used as a standalone application, in a way similar to 
that of the C++ version. The software can be run directly by Internet 
as an applet, too. Any Internet browser works, if it supports JDKI.O. 
That includes older versions of Netscape and Internet Explorer. This is 
an advantage, because these versions are still used. 
3.5 
JAVA JDKl.l, INTERACTIVE 
This is a global optimization software in Java, designed for JDKI.l. 
The graphical interface is open and can be extended by including new 
methods, additional tasks and updated result analysis facilities. The 
software can be used as a standalone application or as an applet by 
the Internet browsers supporting JDKI.l. That excludes early browsers 
such as Netscape-3. Rectangular constraints are defined by the graphical 
interface. Other constraints are involved by adding the penalty functions 
that are defined by users. 
3.6 
JAVA JDK1.2, INTERACTIVE 
This is a new version of global optimization software. It exploits 
new possibilities of JDK1.2. This Java version works on browsers that 
support JDK1.2. Otherwise, the JDK1.2 kit should be installed. Then 
the command 

INTRODUCTION 
41 
appletviewer http://mockus.org/optimum/gmjg2j/gmj.html 
starts the applet gmj.html in the directory optimum of the server 
mockus.org. This way one bypasses a browser but must write the com-
plete path. 
The main new features: 
â¢ constraint functions can be involved by all optimization methods and 
other user defined functions, 
â¢ each objective function is accompanied by its own set of visualiza-
tion algorithms and graphical interfaces, they appear only when this 
objective function is chosen. 
The detail description of different software versions follows. Most ver-
sions use the same algorithms. Their parameters are similar. The soft-
ware is on the web-sites. 
4. 
WEB-SITES 
Convenient reading at any place is an obvious advantage of hard copy. 
The theoretical considerations, including descriptions of mathematical 
models and algorithms, are clear and understandable, on a printed page. 
The static presentation is a disadvantage. A hard copy cannot be up-
dated. Therefore, new results wait for the next edition. 
The aim of the web-sites is to supplement the models and algorithms 
by interactive software systems. These systems can be tested directly by 
users in different computing environments, using different languages and 
operating systems (see Figures 3.1, 3.2, 3.3). The dynamic presentation 
is the important advantage of web-sites. Results can be easily updated 
and made accessible for many readers, free of charge. Therefore, the 
author considers this book as a static introduction to dynamic web-sites. 
There are two of them 
1. http: I lmockus.orgloptimum 
2. http: I loptimum.mii.lt;-jonas 
The first web-site is designed for the international audience. Only se-
lected items are included in this site. The updates are done by replacing 
the existing items, only when obviously better results appear. Therefore, 
updating is less frequent. The site is available always. 
The second web-site is experimental. It is updated frequently, and 
has larger volume. The accompanying text, mostly in English, is in 
txt, html, pdf, or ps files. The site is used by graduate students of 

42 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
Figure 3.2. 
Examples of Global Optimization. 
Lithuanian universities. Therefore, a part of the text is both in English 
and in Lithuanian. Sometimes, during holidays this site is closed. 
In the future, the web-sites will be regularly updated by new develop-
ments. However, the software will remain compatible with the present 
description. 
Contact e-mail addresses: 
jonas@optimum.mii.lt 
jonas@mockus.org 
audris@bell-labs.com 

INTRODUCTION 
43 
COllection of ~aaples of Discre e opti 
sa ion, Dynaaic 
Proqraaainq, and Lin ar Pro<;~ra 
Â· nq 
l 
o 
d:i DOr& te opt Ill za tion 
â¢ 11n11 
- an 
pt aization 
woiÂ»Q bauristio~; ~ 
QtC. s;ygc.. 
exA!ql.!& of of op i 
of of 
J 
m .Java, 
. 
-~ 
- l PJ:'Oill 
e 
opU 
Figure 3.3. Examples of Discrete Optimization, Linear and Dynamic Programming. 

Chapter 4 
PORTABLE FORTRAN VERSION (GMF) 
1. 
INTRODUCTION 
The early Global Minimizer was in Fortran (GMF). Therefore, we 
describe the Fortran version as an introduction to later versions. The 
GMF system is to minimize a continuous function 
f(x), x = (x1, ... , Xn) 
{4.1) 
where x E A c Rn {Mockus et al., 1997). It is assumed for most methods 
that the set A is a rectangular parallelepiped 
A={z:aiSXiSbi, i=2, ... ,n}. 
{4.2) 
Other constraints are approximately reduced to ( 4.2) by the penalty 
function techniques. 
A feature of all versions of the Global Minimum software, including 
GMF, is the Bayesian approach. The Bayesian methods are optimal, in 
the sense of an average deviation. Here the next observation is defined 
by minimizing the risk function R(x). The risk is an expected devia-
tion from the global minimum. The minimization of the risk function 
is justified, if the objective function f(x) needs considerable computing. 
Otherwise, it could be better to do more observations, which need not 
to be planned optimally. In such a case, a good idea is to use a uniform 
search, for example, of LP type (Sobolj, 1967). Using the LP-search 
we lose some efficiency of observations but still have the convergence. 
However, the LP-search can be too expensive, if observations are very 
cheap. Then we apply the uniform random {Monte Carlo) search {Monte 
Carlo) which is very simple. Using the Monte Carlo we obtain the con-
vergence only in probability. The LP-search (LPMIN) and the uniform 
45 

46 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
random search (MIG1 and MIG2) algorithms. Both these algorithms 
are in GMF. 
The method of clustering (Torn, 1990) is included as a good heuristic 
technique under the title GLOPT. It usually works well, if the number 
of local minima is small and known in advance, and if the "attraction 
area" of the global minimum is large. GLOPT is comparable to LPMIN 
by the computing time. 
The global line search EXKOR is a "semi-global" method designed 
for approximately "additive" functions. EXKOR is convenient for visu-
alization. One see clearly how values of the objective function depend 
on variables. That is important for preliminary investigations. 
Global methods search the whole area, as usual. Otherwise, one can 
miss the global minimum. Obviously, the global search is not the most 
efficient way for local optimization. Therefore, in GM the global search 
is completed by the local one, as usual. The best result of a global search 
is defined by default as an initial point for a local search. 
Methods of variable metrics type are widely used for local optimiza-
tion of continuously differentiable functions without noise with non-
linear constraints. The local mathod, called Recursive Quadratic Pro-
gramming (Biggs, 1975), is included under the name REQP1â¢ 
A specific Variable Metrics version for rectangular constraints (Tiesis, 
1975) is called MIVAR4. For local optimization of non-differentiable 
functions with non-linear constraints the simplex type method (Him-
melblau, 1972) is used under the name FLEXI. 
Sometimes, one expects that the influence of some variables and their 
groups is considerably greater than that of others. Then the method 
LPMIN should be used for analysis of the structure before we start the 
regular optimization. The LPMIN orders variables by their "impor-
tance" using a sort of variance analysis techniques (Saltenis, 1989). 
LBAYES is a stochastic approximation type algorithm with the 
"Bayesian" step length control. It is designed for local optimization of 
uni-modal functions with a noise. 
In GMF, no machine-dependent routines are used. Therefore, the 
software can be adapted to any computer with a standard FORTRAN 
compiler by adjusting standard machine-dependent constants. 
1 In later versions a different algorithm (Schittkowski, 1985) is implemented under the name 
NLP. 

FORTRAN 
47 
2. 
GENERAL DISCUSSION 
2.1 
PARAMETERS 
The parameters X, A, B, N, FM, IPAR, PAR, IPA, IPAA are used in 
all subroutines. Here 
X is an array of length N which defines the coordinates of a point being 
considered (initial, optimal or current), 
A is an array of length N which defines the lower bounds of X, 
B is an array of length N which defines the upper bounds of X, 
N is the number of variables (dimension of X) usually N~ 20, 
FM is the value of the function FI(X, N) at the point X, 
IPAR is the array of length 30 which defines the real control parameters, 
IPA is a shift of integer control parameters, 
IPAA is a shift of real control parameters. If only one method is used, 
then both shifts are zero: IPA = 0 and IPAA = 0. If several methods 
are used sequentially, then a shift for the next method must be equal to 
the sum of numbers of control parameters used before by other meth-
ods. The number of control parameters of different methods is given in 
Table 4.1. For all the methods the first integer control parameter is the 
printing parameter: IPAR(IPA+l)=IPR 
(IPA=O if only one method is used). If IPR < 0, 
then only diagnostic messages are printed. 
lfiPR= 0, 
then the initial data, the final results and diagnostic messages are printed. 
If IPR > 0, 
then not only those but also the results of each IPR-th iteration are 
printed. The meaning of other control parameters will be explained 
when describing the corresponding subroutines. 

48 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
2.2 
LIST OF METHODS 
Table 4.1 shows parmeters to combine methods into different sequences 
Table 4.1 shows that to set the Â·algorithm parameters one performs 
Table 4-1. 
Table of Parameters. 
No 
Name 
Method 
No. of control 2arameters 
Integer IPAR Real PAR 
Global O];!timization with rectangular constants 
1 
BAYESl 
Bayesian 
3 
0 
2 
UNT 
Extrapolation 
4 
0 
3 
LPMIN 
Uniform deterministic 
N+3 
0 
4 
GLOPT 
Clustering 
3 
0 
5 
MIGl, MIG2 
Uniform random 
2 
0 
6 
EXTR 
Bayesian one-dimensional 
3 
2 
7 
EXKOR 
Extension of EXTR to 
multi-dimensional case 
5 
N+l 
Local O];!timization 
8 
MIVAR4 
Variable metric with rectangular 
constants 
4 
4 
9 
REQP 
Variable metrics with non-linear 
constraints 
4 
4 
10 
FLEX! 
simplex with non-linear constraints 
4 
2 
Local 011timization with noise 
11 
LBAYES 
stochastic approximation with 
Bayes step length and 
rectangular constraints 
3 
2 
many adjustments. This task is easy using "ready-made" examples. 
They include sequences of different algorithms. One selects needed algo-
rithms just by "commenting-out" the redundant ones. Fbr example, the 
file 'gmfl/ex8.f' in the enclosed disk includes seven algorithms named 
BAYES1, MIVAR4, LBAYES, FLEXI, REQP, UNT, GLOPT. The file 
'gmfl/ex9.f' includes only one algorithm EXKOR. The software is on 

FORTRAN 
49 
web-sites (see section 4.). Methods are described in (Mockus et aL, 
1997) and (Mockus, 1989a). 
3. 
PROGRAM DESCRIPTION 
3.1 
COMMON BLOCKS 
Values of the function FI(X, N) are in the array /BS1/Y(100). The 
array of variables X is defined by the array XN of length MN=N*M. 
In the array /STATIS/IFAIL, IT, IM, M: 
IFAIL is a control indicator: 
- if the initial data is not correct, then IFAIL = 10 and return to the 
main program, 
- if the initial data is correct, then IFAIL -::J 10 and shows the number 
defining the stopping rule, 
IT is the number of iterations, 
IM is the number of the optional iterations, 
M is the number of function evaluations (observations). 
3.2 
OBJECTIVE FUNCTIONS AND 
CONSTRAINTS 
The function to be minimized should be represented as a real function 
FI(X,N). In most methods, only the lower and upper bounds are fixed 
by arrays A and B. 
In methods with non-linear constraints, the subroutine 
CONSTR (X, N, G, MC) is used. Here 
G is a one-dimensional array of length MC that defines the constraints 
at the point X 
MC is the number of constraints. 
It is well known that local methods of optimization are sensitive to the 
scales of variables, as usuaL The parameters of local methods in GMF 
are adjusted to the case when A(I) = -1 and B(I) = 1, I= 1, N., as 
usual. Therefore, it is convenient to reduce the rectangular constraints 
A :S X :S B to theN-dimensional hypercube [-1, 1]N,. This can be 

50 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
done by the following reduction formulae2). 
2 
B(I) +A( I) 
X(I) = B(I)- A(I) XO(I)- B(I)- A( I)' I= 1' N . 
Here XO are original variables, and X are variables scaled to fit into 
[-1, 1JN. 
Example. In most of the following examples, this test function f(x) 3 
is used 
N 
f(x) = 2/NL (xr- cos(18xi)). 
(4.3) 
i=l 
Here N = 2, x1 E [ -0.25; 0.5], x2 E [ -0.125; 0.625] . The subroutine 
is FURASN. 
FUNCTION FURASN(X,N) 
DIMENSION X(N) 
NN=N 
F=O. 
DO 10 I=1,NN 
XI=X(I) 
10 F=F+XI*XI-COS(18.*XI) 
AN=NN 
FURASN=Fâ¢(2./AN) 
RETURN 
END 
Figure 4.1. 
Objective Function FURASN 
3.3 
MAIN PROGRAM 
The main program defines the input data and the sequence of meth-
ods. At the beginning, one selects ( using Table 4.1 or the ready-made 
2in LBAYES those formulae are included in the algorithm, therefore no additional reduction 
is needed. 
3This is the well known Rastrigin test function (Rastrigin, 1968). 

FORTRAN 
51 
example 'grnfljex8.f'), a desirable sequence of methods of optimization 
and analysis. Then a function FI(X, N) is written that evaluates the 
objective function at a fixed point X. 
If needed, the subroutine CONSTR(X, N, G, MC) is included. It 
evaluates the constraints at the point X. The length of arrays depends 
on the subroutines, as usual. The exception is the arrays IPAR and PAR. 
The length of these arrays is always thirty. The parameters of methods 
are included in the arrays IPAR and PAR by the given sequence of 
methods. Formal parameters IPA and IPAA are fixed using the rules 
that are given in the previous section. In the case, when only one method 
is used, IPA = IPAA = 0. 
3.4 
EXAMPLE OF THE MAIN PROGRAM 
The global minimum of test function (4.3) is determined using the 
global Bayesian method BAYESl. Then the results of the global search 
are corrected by the local method of variable metrics MIVAR4. 
The test function is represented as the function FURASN (X, N). 
The arrays are: X, A, B, XN, HES, IPAR, PAR 
It follows from Table 4.1 that, in the subroutine BAYESl, there are 
three integer parameters. In the subroutine MIVAR4, four integer pa-
rameters are used. In MIVAR4 four real parameters should be defined, 
too. This means that seven elements of IPAR and four elements of PAR 
should be fixed. 
The main program is in Figure 4.2 
3.5 
INSTALLATION 
MS DOS version of GMF. Installing: 
â¢ copy the file 'grnf.arj' (see section 4.). 
â¢ extract the GM files from the 'gmf.arj' archive 
> arj e gmf.arj 

52 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
program main 
dimension x(2),a(2),b(2),xn(200),hes(3), 
ipar(30),par(30) 
data n,nm,nh,ipa,ipaa/2,200,3,0,0/ 
data a/-0.25,-0.125/,b/0.5,0.625/ 
data ipar/0,100,5,0,100,2,100,23*0/ 
call bayes1(x,a,b,n,xn,nm,fm,ipar,ipa) 
ipa=3 
call mivar4(x,a,b,n,hes,nh,fm,ipar,par,ipa,ipaa) 
stop 
end 
function fi(x,n) 
dimension x(n) 
fi=furasn(x,n) 
return 
end 
Figure 4.2. 
Example of MAIN 
This version was tested using the Digital Research Fortran-77 Version 
4.1 and LINK-86 Linkage Editor Version 1.5f, Digital Research, Inc. The 
example: 
â¢ compile 
> f77 ex9.for 
> f77 i1mach1.for 
> f77 exkor.for 
â¢ link 
> link86 ex9,i1mach1,exkor 
â¢ run 
> ex9 
Here the file 'ex9.for' is an example of the Main program using EXKOR 
method to minimize FURASN function (see expression 4.3). 
The file 'exkor.for' is the source of EXKOR. 
The file 'ilmachl.for' contains portability codes and other service rou-
tines, such as independent random number generator, various test func-
tions, etc. 

Linux version of G MF. Installing: 
â¢ copy the file 'gmfi.tgz' (see section 4.) 
â¢ extract the GM files from the 'gmfi.tgz' archive 
> tar -zxf gm.fl. tgz 
FORTRAN 
53 
This version was tested using the standard Linux f77-style shell script 
'f77' to compile and load Fortran and assembly codes. The example: 
â¢ compile and load 
> f77 ex9.f i1mach1.f exkor.f 
â¢ run 
> a.out 
Note, that here the Fortran file extensions are 'f'. 

Chapter 5 
TURBO C VERSION (TCGM) 
1. 
GENERAL DISCUSSION 
A conceptual description of methods is given in (Mockus et al., 1997). 
Descriptions of real life examples of global optimization are in (Mockus 
et al., 1997) and in the next part of this book. 
1.1 
PURPOSE 
The Turbo C version of the Global Minimizer TCGM is to solve global 
optimization problems similar to those of the Fortran version GMF. The 
optimization problem is defined in terms of variables describing the pa-
rameters that we can change, an objective function of those variables and 
some constraints restricting the possible change of variables. Formally, 
that is a nonlinear programming problem 
min f(x), 
a:Sx:Sb 
gi(x) :::::; 0, i = 1, ... ,p 
gi(x) = 0, i = p + 1, ... , m. 
(5.1) 
Here x is a vector of n variables. f(x) is an objective function. a <= 
x <= b defines rectangular constraints. gi(x) :::::; 0, i = 1, ... ,p defines 
inequality constraints. gi(x) = 0, i = p + 1, ... , m defines equality con-
straints. The objective function is deterministic or stochastic (for some 
methods). Rectangular constraints are defined for all the methods. The 
55 

56 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
linear and non-linear constraints are defined just for two local methods: 
the Simplex by Neider and Mead Flexi {Himmelblau, 1972), and the 
non-linear programming by Schittkowski Nlp (Schittkowski, 1985). 
2. 
USER'S REFERENCE 
2.1 
REQUIREMENTS 
â¢ Thrbo C version 2.0 or above. 
â¢ An experience of writing simple C functions. 
2.2 
INSTALLATION 
â¢ Copy the file tcgm.arj from a web-site (see Section 4.). Extract the 
GM files from the tcgm.arj archive 
> arj e tcgm.arj 
2.3 
INITIALIZATION 
â¢ Run the batch file GM.BAT using the command GM, and enter the 
Thrbo C editor. 
â¢ Define the objective function as some C function with the name f. 
This function has two parameters: 
double array of values of each variable, 
the number of variables. 
â¢ Define the general linear or non-linear constraints as a C function 
named constr. It has four parameters: 
double array of values of variables, 
number of variables, 
double array of values of constraints, 
number of constraints. 
â¢ Compile file FI.C using directive Alt+C and correct possible errors. 
â¢ Link file FI.C to GLOBAL MINIMUM system using directive Alt+L. 

TURBO C 
57 
â¢ Exit Turbo C using directive Alt+X. 
Now the GLOBAL MINIMUM is ready to minimize the problem that 
is defined in the file FI.C. Descriptions of objective functions and con-
straints have to be in the same file. Running GM.BAT, the file FI.C is 
displayed on the screen by Turbo C editor. Rectangular constraints are 
defined using the screen. Two algorithms, Nlp and Flexi, are exceptions. 
Here the constraints are defined by C function constr in the file FI.C. 
The four basic steps of initialization are 
â¢ run GM.BAT, 
â¢ edit file FI.C, 
â¢ compile FI.C, 
â¢ link file FI.C to system GLOBAL MINIMUM. 
2.4 
MINIMIZATION 
The system will ask the following questions. 
â¢ Question: Number of variables. 
Action: Enter the number of variables of the problem. 
â¢ Question: Number of constraints. 
Action: Enter the number of linear and non-linear constraints of the 
problem (not counting the number of rectangular constraints that are 
defined interactively). 
Now one see the GLOBAL MINIMUM copyright notice. GLOBAL MIN-
IMUM is implemented as menu, dialog box and windows system. Each 
object can be either active or passive. There can be only one currently 
active object. A user can work only with active objects. There is a rect-
angular caption at the top of each object (menu, dialog box, or window). 
If this caption is bright, the object is active. 
2.5 
MENU SYSTEM 
â¢ Main Menu 

58 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
press any key and enter the MAIN MENU, 
select the type of optimization or exit the menu system selecting 
EXIT. 
â¢ Global Optimization Menu 
select the GLOBAL item from the main menu, 
select any of six available global optimization methods: LPMIN, 
MIGl, BAYESl, EXTR, UNT, GLOPT. 
â¢ Local Optimization Menu 
select LOCAL item from the main menu, 
select any of three available local optimization methods: NLP, 
FLEXI, or LBAYES. The initial point for local optimization is 
the result of previous global optimization, by default. 
â¢ Parameter Box 
display of the PARAMETER DIALOG BOX follows the selection 
of method, 
enter corresponding parameters of methods and press RETURN. 
Recommendations how to choose parameters are given in the de-
scription of methods (Mockus et al., 1997). 
â¢ Confirmation Menu 
CONFIRMATION MENU appears following the selection of pa-
rameters, 
RUN means run the method, 
EXIT means return to LOCAL or GLOBAL OPTIMIZATION 
MENU. 
â¢ Operation Menu 
OPERATION MENU appears following the selection of RUN 
item, 
RUN means run the method, in case if it was stopped by selecting 
STOP item, 
STOP means temporary stopping of the method and activating 
the OUTPUT DIALOG BOX, 
press ENTER to return to the OPERATION MENU and to make 
the OUTPUT DIALOG BOX inactive, 

TURBO C 
59 
EXIT means exit the method and return to GLOBAL or LOCAL 
in the OPTIMIZATION MENU, 
ENTER means return to GLOBAL or LOCAL in the OPTI-
MIZATION MENU, after the method finishes optimization, 
RECORD means turn RECORD WINDOW on/off, 
PROJECTION means turn PROJECTION WINDOW on/off. 
â¢ Information Display 
OUTPUT DIALOG BOX shows the results of each iteration ( usu-
ally best point and goal function value at this point) when the 
method runs (see Figure 5.1), 
L7 
0.20 
J..:5 
0.077 
0.26 
Figure 5.1. 
Table ofTCGM results. 
RECORD WINDOW shows how the best function value depends 
on the iteration number (see Figure 5.2), 
3.0 
0.26 
~ 
1 
200 
Figure 5.2. 
Graph of TCGM results. 
RECORD WINDOW is on when the method is started, 
if the graph on RECORD WINDOW is horizontal for a long time 
it can suggest that the minimum is reached or that the method 

60 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
exhausted itself for this problem and it is better to try another 
method, 
if one selects RECORD item in OPERATION MENU while run-
ning the method then the RECORD WINDOW becomes invisi-
ble, if it was visible, and vice versa, 
PROJECTION WINDOW shows the projection of the observed 
(calculated) objective function values, the numbers of projection 
planes correspond to the numbers of variables, 
if one selects a PROJECTION item in OPERATION MENU 
while running the method, then one will see projection menu 
consisting of two items: ON and OFF, meaning on/off the PRO-
JECTION WINDOW, 
if one selects ON then the projection dialog box appears and we 
can enter numbers defining the projection planes, 
select the number, press ENTER and one see how the observed 
values of the goal function depend on the corresponding values of 
the selected variable, the values of all other variables will not be 
seen. 
â¢ RESULT DIALOG BOX shows the results of calculations after the 
method finishes optimization. 
2.6 
NAVIGATION 
â¢ On Screen 
screen is divided into three areas: bottom, middle and top, the 
functionality of these areas is different, 
bottom area is for general information, such as description of 
variables, displaying error messages, displaying the state of an 
active object, 
middle area is only for displaying and editing variables, 
the top is a working area; menus, dialog boxes and windows are 
displayed here. 
â¢ On Menu 
if some menu item is invisible, one opens it using corresponding 
cursor keys: UP, DOWN, LEFT, RIGHT, 
the contents of the menu will scroll until the last available item 
will be reached. 

TURBO C 
61 
â¢ Dialog Box 
on the DIALOG BOX one can see such variables as the param-
eters of method, coordinates of the best and current point, best 
and current values of goal function and so on, to view a variable 
one selects the variables name, 
if the variable is a scalar, one see the corresponding value, next to 
the variable's name, the description of this variable is displayed 
at the bottom area of a screen, the exact value of the variable is 
displayed at the middle area, 
if the variable is a vector then, after selecting the variables name, 
one can select the corresponding component of the vector using 
keys LEFT and RIGHT, the value of the selected component will 
be in the middle area, the number of component will be in the 
bottom area, along with the description of variable, 
to see invisible components of the vector, use the keys LEFT and 
RIGHT, the vector scrolls, if there are invisible components, 
press SPACE, to edit a variable, press ENTER, to exit the editor. 
2.7 
MOVING 
â¢ Press the F3 functional key and the red border will appear, move the 
border with keys UP, DOWN, RIGHT, LEFT and press ENTER to 
stop. 
â¢ The previous image of the object will be deleted and the object will 
be placed inside the new border. 
2.8 
SIZING 
â¢ Press the F4 functional key, move the object and press ENTER. The 
red border appears. 
â¢ Size the border using the keys UP, DOWN, RIGHT, LEFT and press 
ENTER to stop. 
â¢ The previous image of the object is deleted and the object is placed 
into new borders. 
No changes happens, if borders are greater than maximal size of the 
object, or less than its minimal size. 

Chapter 6 
C++ VERSION (GMC) 
1. 
PURPOSE OF GMC 
The Global Minimizer's C++ version GMC is for continuous global 
optimization (Mockus et al., 1997). Users define their optimization prob-
lems describing 
â¢ parameters that can be changed (defined as variables x), 
â¢ function of those variables (defined as objective function f(x)), 
â¢ constraints restricting a possible change of variables (defined as in-
equalities gi(x) ::::; 0, i = 1, ... ,p, or equalities gi(x) = 0, i = p + 
l, ... ,m). 
Formally 
minf(x), 
a::;x::;b 
gi(x) ::::; 0, i = 1, ... ,p, 
gi(x) = 0, i = p + 1, ... , m. 
(6.1) 
(6.2) 
(6.3) 
(6.4) 
The objective function f(x) may be deterministic or (for some methods) 
with "noise." As usual, the optimization region is defined by rectangular 
constraints ( 4.2). For some methods, Nlp and Flexi, this region is defined 
by linear and non-linear constraints (6.3) and (6.4). 
63 

64 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
2. 
USER'S REFERENCE 
2.1 
REQUIREMENTS 
â¢ C++ compiler, for example, GNU g++ compiler or any ANSI C++ 
compliant compiler, 
â¢ X-Window system, 
â¢ UNIX (Linux, Solaris, AIX), 
â¢ experience in writing simple C, or C++ functions. 
2.2 
INSTALLATION 
Differences between various UNIX versions are reflected in the file 
'Makefi1e'. An example for individual Linux users is in Figure 6.1. An 
AIX version for individual users is in (Mockus et al., 1997). A classroom 
(collective user) version for Solaris is there, too. Using some other UNIX 
version, the Makefile has to be changed accordingly. Installing GMC one 
should 
â¢ copy the archive file gmc.tgz from the web-site (see section 4.) by the 
unix command 
> mcopy a: 
gmc.tgz 
â¢ extract GM files from the archive 'gmc.tgz' by the command 
> tar -zxf gmc.tgz 
2.3 
INITIALIZATION 
â¢ Define the objective as some function fi. The function fi has two 
parameters: an array of values of each variable and the number of 
variables. The function fi returns the value of objective, given the 
values of variables. 
â¢ Define "non-interactive" linear or non-linear constraints as a function 
named constr It has four parameters: an array of values of variables, 
the number of variables, an array of values of constraints, and the 

C++ 
65 
number of constraints. Values of constraints are returned by the 
function constr. 
A user can also define rectangular constraints interactively, during 
the optimization 
â¢ Describe objectives and constraints in a file named fi.C (see Figure 
6.2) 
the objective function is implemented by the routine 
double fi (const double â¢xx, int dim) 
the constraints are defined by the routine 
void constr (const double â¢x, int n, double *g, 
int ng) 
â¢ Start optimize the problem described in the file fi.C. 
â¢ set X-window 
â¢ compile 
> rm fi. o > make 
â¢ run 
> ./test 
2.4 
MENU SYSTEM 
The opening menu of GMC is in Figure 6.3 
â¢ The Main Menu: 
Global, Local, Operations, Quit, Parameters, Results, Output. 
â¢ Global Optimization Menu: 
Bayesl, Migl, Unt, Exkor, Glopt, Lpmin. 
â¢ Local Optimization Menu: 
Nip, Flexi, Lbayes. 
By default the initial point for local optimization is the result of 
previous global optimization. 

66 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
â¢ Operations Menu: 
Run, Stop, Exit. 
â¢ Quit Command. 
â¢ Parameter Box. 
Enter the parameters of methods and point O.K. 
An example of the parameter box is in Figure 6.3. 
â¢ Results Box: 
Shows the best objective Y and the best variables X(I). If no changes 
are needed, point O.K. 
â¢ Output Menu: 
Convergence, Projection, and Numeric Windows. 
Convergence window shows how the objective depends on the 
iteration number (see the Figure 6.4. 
Projection windows show how the objective depends on the differ-
ent variables. One defines the projection by entering the number 
of variable. Figures 6.5 and 6.6 show two projections. 
Numeric window shows the current values of objective and vari-
ables (see Figure 6.7). 
â¢ Using Menu: 
To see "invisible" components of a vector, point to 'down' or 'up' 
arrows. The vector scrolls, if there are invisible components. 
To edit a variable, touch BACKSPACE1 , then edit the variable 
and point to O.K. 
Enter the Parameter Box immediately after selecting a method. 
10ne should use the 'xmodmap' command to adapt the keymap, if the BACKSPACE key is 
not working. 

0++ 
67 
#this is for linux 2.0.0 
# C++ compiler. If error is "Can not load 
# (try CC or gee instead of g++) 
C++ = g++ -I$(INCDIR) -L$(LIBDIR) -02 
# pathname to X11/â¢.h files 
II 
# if compilation errors are "Can not find include file 
then 
# try /usr/local/include or /usr/include/X11R5 
INCDIR 
= /usr/include 
# pathname to libX11.a 
# If error is "Can not find library 
II 
# try /usr/local/lib or /usr/lib/X11R5 
LIBDIR 
= /usr/X11/lib 
CPP 
= /lib/cpp 
F77 
f77 
LIBS 
= -1X11 -lm 
OBJS 
= test.o WINDOW.o MENU_ITEM.o 
SMENU_ITEM.o 
work.o MENU.o DBOX.o CONTROL.o STATIC.o EDIT.o BUTTON.o 
LBOX_ITEM.o LBOX.o 
SCROLL_BAR.o SBBUTTON.o 
OUTPUT.o mig1.o MIG1.o exkor.o task.o 
bayes1.o SUBMENU.o BAYES1.o SHIT.o 
CLIENT.o lbayes.o PAR_DBOX.o ERROR.o 
PROJ.o VAR_DBOX.o unt.o UNT.o EXKOR.o RES_DBOX.o 
VEDIT.o CONV.o fi.o NUM.o shit.o IO_DBOX.o LBAYES.o 
lpmin.o LPMIN.o glopt.o GLOPT.o flexi.o FLEXI.o HELP.o 
RES 
= menu.res bayes1p.res nlpp.res var.res 
lbayesp.res 
res.res num.res mig1p.res untp.res exkorp.res 
lpminp.res 
gloptp.res flexip.res help.res 
TARGET 
test 
.SUFFIXES: .C .o .rc .res .f 
.f.o: 
$(F77) -c $â¢.f 
.C.o: 
$(C++) -c $â¢.C 
.rc.res: 
$(CPP) -P $â¢.rc > $â¢.res 
all: $(TARGET) $(RES) 
$(TARGET): $(0BJS) Makefile 
$(PURIFY) $(C++) -o $(TARGET) $(0BJS) $(LIBS) 
#DO NOT DELETE THIS LINE-- make depend depends on it. 
Figure 6.1. 
Example of 'Make:file' for Linux. 
II 

68 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
I* File: fi.C *I 
#include "fi.h" 
#include <math.h> 
int number_of_variables =2; 
I* Objective function*/ 
double fi (const double *x, int n) 
{ 
int 
i; 
double y 
OÂ· , 
for (i 
0; i < n; i++) { 
double Z = X [i] ; 
y += z * z - cos (18. * z); 
} 
return 2 * y I n; 
} 
/*Constraints *I 
void constr (const double *x, int n, double *g, int ng) 
{ 
I* 
ng > 0 - calculates all constraints 
ng < 0 
- calculates only constraint with number (-ng) 
(in this illustrative example there are no constraints, 
except interactively defined ones) 
*I 
} 
Figure 6.2. 
Example of the file 'fi.C.' 

C++ 
69 
'â¢ Global Mmrmum 
1!1[!] EJ 
Figure 6.3. 
An example of GMC opening menu and parameter box. 

70 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
~, Convergence 
l!llill a 
Figure 6.4. 
Convergence window. 

C++ 
71 
-t+ + + 
+ + 
Figure 6.5. 
Projection 1 (shows how f(x) depends on the first variable). 

72 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
+ 
+ + 
Figure 6.6. Projection 2 (shows how f(x) depends on the second variable). 

ITI10 
X( 
X( 
1) 
2) 
C++ 
73 
X 
0.9861 ~ 
0.3359 \] 
II 
Yl1.28 
I 
Figure 6. 7. 
Current numeric results. 

Chapter 7 
JAVA JDKl.O VERSION (GMJO ) 
1. 
INTRODUCTION 
The Global Minimizer GMJO (Krapauskas, 1997) implements in Java 
JDKl.O the C++ global optimization software GMC. That makes GMJO 
familiar to GMC users. GMJO includes all the global methods. Lbayes 
is the only local method. Implementation of the remaining two local 
methods, Nip and Flexi, is difficult. We need to introduce specific 'Con-
straints' objects1 to represent constraints, in these methods. The graph-
ical interface and the menu system both are similar to those of GMC. 
All 'java' and 'class' files are in the archive on web-sites (see section 
4.). The applet 'gm.html' is started by a browser. The command 
appletviewer (URL address)gm.html 
starts the applet, if JDKl.O.x2 is on, and one may reach the cor-
responding URL address. The applet optimizes the objective function 
defined by 'Task.java'. In the demonstration applet the 'Task.java' is 
sin. 
Users replace an illustrative function in the file 'Task.java' by his own 
objective function. Then the new 'Task.class' is made by the 'javac' 
1These objects are implemented in the JDK1.2 version (GMJ2). 
2The command 'appletviewer' may not work properly, if one uses JDKl.l or higher. That is 
a disadvantage of GMJO. 
75 

76 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
command. Graphical possibilities of GMJO include the convergence, 
projection and numeric parts, similar to those in GMC. 
2. 
RUNNING GMJO 
2.1 
DEFINING OBJECTIVE 
The file 'Task.java' represents the objective function. 
Figure 7.1 
shows the illustrative example with objective function sine. The file 
'Task.java' describes the Task class. The class variable NUMBER OF 
VARIABLES defines the number of optimization parameters. The ar-
rays 'lowerBounds' and 'upperBounds'3 define lower and upper bounds 
of optimization parameters. In the illustrative example, that means 
variation of parameters from minus two to plus two. 
The array 'initialPoints' defines the initial approximation needed by 
local methods and by some global ones, for example by 'Exkor'. The 
numbers -1.0 0.0 1.0 define default values of arrays 'lowerBounds', 
initialPoints', and 'uppperBounds' correspondingly4. The 'return' value 
is the objective function of two variables (see the illustrative example 
Figure 7.1). 
2.2 
COMPILING AND RUNNING 
One compiles when changes the objective function f(x). This function 
is defined by in the file 'Task. java'. The compiling command is 'javac 
Task.java'. To run the program by a local java JDKl.O.x interpreter, one 
uses the command 'java Gm'. The JDKl.O.x command 'appletviewer 
gm.html' is for running the applet 'gm.html' from the command line. 
To run by browser just open the web-site and start the applet 'gm.html' 
of the GMJO system (see section 4.). 
3 Zero element defines the first element, and so on. 
4N ote that the constructor of class Task can be deleted if one is satisfied by the default values. 

import java.lang.Object; 
II Task 
class Task extends Object 
{ 
II Number of variables 
public static final int NUMBER_OF_VARIABLES 
public double lowerBounds[]; 
public double upperBounds[]; 
public double initialPoints[]; 
public Task() 
{ 
JAVA 1.0 
77 
2Â· , 
II Initialize upper and lower bounds or initial points 
here: 
lowerBounds = 
upperBounds = 
initialPoints 
for ( int i = 
{ 
lower Bounds [i] 
upperBounds[i] 
new double[NUMBER_OF_VARIABLES]; 
new double[NUMBER_OF_VARIABLES]; 
=new double[NUMBER_OF_VARIABLES]; 
0; i < NUMBER_OF_VARIABLES; i++ ) 
-5.0; 
5.0; 
} 
initialPoints[O] 
initialPoints[1] 
} 
4;112; 
O;ll-4; 
static public final double f(double x[], int n) 
{ 
} 
} 
return Math.pow(x[0],2)+x[1]; 
Figure 7.1. 
Example of the 'Task.java.' 
2.3 
GRAPHICAL INTERFACE 
Starting the applet 'gm.html', a window with 'Show' and 'Hidden' 
buttons appears (see Figure 7.2). One starts the main program and 
opens the menu window (see Figure 7.3) by clicking the 'Show' button. 
The menu window controls the optimization process and is similar to 
that of the GMC (C++ version). To hide this window press 'Hide'. To 
delete, select the menu item 'File, Exit' and answer "yes." Then the 
'Restart' button appears, replacing the 'Show' and 'Hide'. One creates 

78 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
....... 
Global ,... lnimum: 
Tshovif I ~ 
liJ 
The. source. 
Figure 7.2. 
GMJO opening. 
Options 
H lp 
Figure 7.3. 
GMJO opening menu. 
a new menu window by clicking 'Restart'. One opens the menu window 
from the local interpreter by the command 'java Gm.' In this window, 
â¢ File provides the Exit possibility. 
â¢ Global provides the choice of global optimization methods: 
Bayesl, Unt, Migl , Exkar, Glopt, Lpmin. 
â¢ Local provides the choice of local methods: 
Nlp, Flexi, Lbayes (now only Lbayes is there). 

JAVA 1.0 
79 
â¢ Operation is for the computing control: 
Run is for starting or restarting, Stop is for temporary stopping, and 
Terminate ends the computing. 
â¢ Parameters is just for Set initial parameters that opens the pa-
rameter window. The window shape depends on the method chosen. 
One may change the parameters at any moment but the new settings 
will be ignored until the next 'run'. 
â¢ Results is for Watch Results. It opens the results window showing 
the best obtained objective function and the corresponding parame-
ters. 
â¢ Output is for choosing a visualization format. 
Numeric shows in numbers the current objective and parameters 
(see Figure 7.4). 
Iteration IT: 
10 
Â·----
Res u It '/=fO: 
-, l 
38111 061 .~ I 
Close 
Figure 7.4. 
Current results. 
Convergence shows how the best obtained objective value de-
pends on the iteration number (see Figure 7.5). 
Projection shows how the objective depends on some fixed pa-
rameter (see Figures 7.6 and 7.7). 

80 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
Java Applet \A/indov./ 
Figure 7.5. 
Best objective depending on iteration number. 
â¢ Options is for changing the form of points on the Projection window: 
Cross points or Circle points. 
â¢ Help just opens the window About. 
All the visual tools takes CPU time. Therefore, closing them speeds up 
the computing. 
2.4 
IMPLEMENTING NEW METHOD 
The class of a new method is created using the 'Method' class. The 
minimal class of a new method is shown in Figure 7.8. The parameters of 
the 'Method' constructor output is the object controlling a visual output. 
n defines computing parameters (lower and upper bounds, initial points 

Java .8.pplet VlindoÂ·vÂ·l + 
+ 
+ 
+ 
+ 
Figure 7. 6. 
Projection 1. 
JAVA 1.0 
81 
e.t.c.). r defines the results. fm and xn define the arrays of current 
results. 
An optimization algorithm is called by the method 'run()'. In the 
example, the method is 'newmethodcalculations ( ... ) ' . The name and 
parameters of this method may be fixed according to users needs. In the 
example, the internal values x, a, and b of the object created by the class 
'Method' are passed. Here x, a, and bare some arrays of initial points, 
lower and upper bounds, respectively. n is the number of variables. it 
is the number of iterations. fm and xn are arrays of current results. 
All these parameters are initialized by the constructor of the 'Method' 
class. In the 'Method' class, the internal variable r of the class 'Re-
sults' is defined. This variable is initiated by the constructor of the 
'Method' class. Using the variable r, we inform the program about the 

82 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
+ 
Java. Applet \Â·Vindovl 
+ 
+ 
Figure 7. 7. 
Projection 2. 
+ 
+ 
change of iteration (r.iteration=new.iteration), about new minimal value 
(r.y=new.min), about the change of the current best point 
(copy.array(r.x=new.x.n)). Here the integer 'new.iteration' shows the it-
eration number. The double array "new.min' defines the coordinates of 
the new best point. All these commands are in the method 'newmethod-
calculations'. Finishing the method 'run()', the method 'Finish()' of the 
class 'Method' is called. Then the program returns to the initial state. 
One may add a new method and extend the graphical possibilities of 
Java global optimization software in a simpler way by using other Java 
versions. These versions called as GMJl and GMJ2 are described in the 
next section. Note, that GMJl needs JDKl.l support and GMJ2 needs 
JDK1.2 support. Thus, GMJl does not work on some older browsers 
such as Netscape-3, for example. One installs the Java Developers Kit 
JDK1.2 to apply GMJ2. 

JAVA 1.0 
83 
import Method; 
class NewMethod extends Method 
{ 
} 
public NewMethod( Output output, Parameters p, Results r, 
double fm[], double xn(][] ) 
{ 
super( output, p, r, fm, xn ); 
} 
public void run() 
{ 
} 
newmethodcalculations(x, a, b, n, it, fm, xn); 
finish(); 
private void newmethodcalculations(double x[], double a[], 
double b[], int n, int it, double fm[], double xn[] []) 
{ 
//code 
} 
Figure 7.8. 
Example of the minimal class of the new method. 

Chapter 8 
JAVA JDKl.l AND JDK1.2 VERSIONS, 
GMJl AND GMJ2 
1. 
INTRODUCTION 
The Java JDKl.l and JDK1.2 versions (in short, GMJl and GMJ2) 
of global optimization software are class frameworks ( Grybauskas, 1998). 
Both GMJ versions implement: 
global optimization algorithms (METHODS), 
functions to be optimized (TASKS), 
objects to be represented visually (ANALYSIS). 
GMJ can be run as an applet or as a stand-alone application. One 
can run applet over the Web. This cannot be done by an application. 
Security restrictions is the disadvantage of applets. We need security 
permits to read/write files and to connect third parties (see Section 
4.6). 
These restrictions are lifted using stand-alone applications. Using 
stand-alone applications, the most recent Java features supported by the 
Java Development Kit (JDK) can be exploited. The reason is that web 
browsers are late adapting new Java Developer Kits (JDK), as usual. If 
JDK is installed, then applets can be loaded directly by appletviewers1. 
1 For example, by the command 
appletviewer http:/ joptimum.mii.lt/ jonasjgmj2jjgmj.html. 
85 

86 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
The JDK1.2 system provides new facilities as compared with JDKl.l. 
For example, Just-in-Time compilers (jitc) increase the speed several 
times2 . The 'policy' files of JDK1.2 exempts trusted users from some 
security restrictions. 
2. 
STARTING GMJ 
In this and flowing sections, the user guide of GMJ is described. First 
we consider the parts that are common for both JDKl.l and JDK1.2. 
Then the features of JDK1.2 are mentioned. 
2.1 
CONFIGURING APPLET 
The sample file gmj .html shows how to set configuration parameters 
of the gmj applet. The< applet >tag of GMJl looks like this: 
<html> 
<head> 
<META HTTP-EQUIV="Content-Language" 
CONTENT="LT"> 
<META HTTP-EQUIV="Content-Type" CONTENT= "text/html; 
charset=windows-1257; charset=IS0-8859-13"> 
<META NAME="Author" CONTENT="Modestas Grybauskas"> 
<title>GMJ Applet, 
Set of Methods, Tasks, and Analysis 
Objects</title> 
</head> 
<body bgcolor="#EOEOEO"> 
<h1>GMJ</h1> 
<p> 
<applet 
code="GMJext.class" 
> 
codebase= "Lib" height=1200 width=800 
archive= "gmjg_allnew. jar" 
<patram nam.e="TASKS" 
value="lt.ktu.gmj.tasks.Sinl 
Tvarkallt.ktu.gmj.tasks.Portfoliol 
lt.ktu.gmj.tasks.WalrasModelllt.ktu.gmj.tasks.Knapsack"> 
<param name="METHODS" value="lt.ktu.gmj.methods.Mig11 
lt.ktu.gmj.methods.Bayesllt.ktu.gmj.methods.Globtl 
2These compilers are available in JDKl.l, too, starting from JDK1.1.7. 

JAVA 1.2 
87 
lt.ktu.gmj.methods.Untllt.ktu.gmj.methods.LBayesl 
lt.ktu.gmj.methods.Exkorllt.ktu.gmj.methods.Flexil 
lt.ktu.gmj.methods.Lpmin"> 
<param name="ANALYSIS" 
value="lt.ktu.gmj.analysis.Convergencel 
lt.ktu.gmj.analysis.Spectruml 
lt.ktu.gmj.analysis.Projectionl 
TvarkaAnalyserllt.ktu.gmj.analysis.WalrasProfit"> 
<p>You need Java compatible browser 
to see this applet </p> 
</applet> 
</p> 
</body> 
</html> 
In this example, code specifies the applet class and should not be changed. 
codebase specifies the relative URL of the applet class archive file and 
user class files. The URL is relative to the location of the HTML file 
where the < applet > tag resides or is an absolute path. 
archive lists the class archive files. 
width and height specifies the applet size, as it appears on the HTML 
page. 
TASKS lists tasks which are available when the applet loads. Complete 
class names (package and class name) are separated by I symbol. 
METHODS lists methods which are supported when the applet loads. 
AN ALY SIS lists visual analysis classes which are supported when the 
applet loads. 
Here is the fragment of the GMJ2 < applet > tag, which differs from 
GMJl: 
<applet 
code="lt.ktu.gmj.ui.GMJ.class" 
codebase= "Lib" 
archive= "gmj20.jar" 
> 
<patram name="TASKS" 
value="lt.ktu.gmj.tasks.Sin"> 
<param name="METHODS" value="lt.ktu.gmj.methods.Bayes"> 
<param name="ANALYSIS" 
value="lt.ktu.gmj.analysis.Convergencel 
lt.ktu.gmj.analysis.Spectruml 

88 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
lt.ktu.gmj.analysis.Projection"> 
</applet> 
The difference is that less methods, tasks and analysis objects are in-
cluded in the GMJ2 example. Different archive file gmj20.jar is used. 
2.2 
CONFIGURING STAND-ALONE 
APPLICATION 
To run GMJ as a stand-alone application, the Java Runtime Environ-
ment (JRE) is required. First, CLASSPATH should be configured, so 
that the GMJ classes can be found by the JRE. An application is started 
by loading the lt.ktu.gmj.ui.GM J class. Using Linux the command is: 
java -classpath . 
:/usr/local/jdk1.2/lib/classes.zip: 
/home/jonas/public_html/gmj2j/Lib/gmj20.jar 
lt.ktu.gmj.ui.GMJ lt.ktu.gmj.tasks.Sin 
lt.ktu.gmj.methods.Bayes 
lt.ktu.gmj.analysis.Projection 
The application accepts three optional parameters: tasks, methods, and 
analysis objects. In the example, only one task Sin, one method Bayes 
and one analysis object Projection is included, for simplicity. 
3. 
RUNNING GMJ 
3.1 
DISPLAY AND CONTROL 
GMJ displays a tab control that has three choices: method, task, and 
operation. The appropriate pages can be selected by clicking on the 
page tabs. 
Figures 8.1,8.2, and 8.3 show the method, the task and the operation 
pages for the Exkor method and the Sin task using GMJl. 
Figure 8.4 shows how the function depends on the first variable x 
Figure 8.5 shows how the function depends on the second variable y. 

JAVA 1.2 
89 
Figure 8.1. 
Method page with parameter fields. 
Figure 8.2. 
Task page with input fields. 
Figure 8.3. 
Output page with results fields. 
Figures 8.4 and 8.5 show that using the Exkor method one gets clear 
projections defining how the objective function values depend on dif-
ferent variables. That provides a sort of "visualization" needed for the 
preliminary investigations. Using other methods, Projection windows 
show fuzzy "projections." The reason is that variables change together. 

90 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
f'(X ) 
0 
0.& .. 
0.7 
0.6 
0.5 -
o .â¢ -
0.3 
0.2 
0.1 -
~ 
0.0 
-1 .0 
I 
--
I 
--
0 
I 
â¢ 
-o.s 
)( Sin Arguruent ._. I 
Warn1ng: Applet W1ndow 
6 
-
0 
<> 
I 
0 
_ 00 8-o-0 
0.0 
o.s 
Figure 8 .. { 
x-projection. 
9 
Figures 2.3 {bottom), and 2.4 show projections obtained while opti-
mizing the randomization parameters for the knapsack problem by the 
method Bayes . 
Figure 2.3 (top) shows how the best current value of the knapsack de-
pends on iteration numbers. 
The Spectrum window3 shows how depends the frequency of the objec-
tive function f(x) values on iteration numbers. Different frequencies are 
represented by different colors. 
3.2 
TASK SELECTION 
The following tasks are installed in GMJL 
Sin 
the Sine Function. 
3This window can be open by selecting the Spectrum mode on the Convergence menu . 

JAVA 1.2 
91 
Warn1ng: Applet Window 
0.7 
0.6 
o.s . 
o.â¢ -
0 
( 
0., I 
0.2 
0.1 -
0.0 , --
I 
-< ) 
0 o8o 0 
I 
-1 .0 
-o.s 
0.0 
o.s 
V Sin Argu 
Figure 8. 5. 
y-projection. 
Tvarka : the School Scheduling. 
Portfolio : the Optimal Investment, the "Portfolio" problem. 
WalrasModel : the Walras Equilibrium. 
Knapsack : the Knapsack problem. 
H 
The detail description of these examples is the subject of the next part 
of this book. By clicking the tasks label, one opens a list of available 
tasks. The task is selected by clicking the label of this task. 
Figure 8.2 shows the selected task Sin. After selection, the tasks 
implementation class is loaded and the configuration window is opened. 
The configuration window depends on the actual task selected. 
Figure 8.2 shows the window for Sin. There are fields that define 
properties of tasks and the minimization domain. One can keep the 
default values or change them. If the entered value is invalid or out of 
bounds, the field turns red and the value is not stored. 

92 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
3.3 
OPERATION CONTROL 
The minimization process is controlled by the operation page (see 
bottom of Figure 8.3). There are three control buttons: run, pause, 
stop. The run button starts the optimization. The pause button 
interrupts the calculations. To abandon them completely, press the stop 
button. 
3.4 
ANALYSIS OF RESULTS 
The numerical optimization results are shown in the output table on 
Figure 8.3 displaying the following parameters: 
Iteration shows current iteration numbers, 
F(x) , shows current values of the objective function f(x), 
X, Y , show coordinates of current points. 
To select the form of graphical results, one clicks the 'Convergence' field 
that is at the right side on the top. Three analysis objects are installed. 
Convergence shows how the best obtained objective function value de-
pends on iteration number (see Figure 2.3), 
Projection shows how the objective function depends on the first vari-
able (see Figure 8.4), the variable number can be changed by clicking 
at the small button in the lower-left part of the window, 
Spectrum shows how depends the frequency4 of objective function val-
ues on the iteration number. 
3.5 
METHOD SELECTION 
In GMJl five global methods are installed: 
Migl : Monte Carlo. 
4 Defined by different colors. 

Bayes : Bayesian by Mockus. 
U nt : Extrapolation by Zilinskas. 
Globt : Clustering by Torn. 
Exkor : Bayesian coordinate search by Zilinskas. 
and two local methods: 
LBayes : Stochastic Approximation by Mockus. 
Flexi : Simplex Nonlinear by Neider and Mead5. 
For the detail descriptions see (Mockus et al., 1997). 
JAVA 1.2 
93 
One opens a list of available methods by clicking the methods label of 
the GMJ tab control. The method is selected by clicking the label of this 
method. Figure 8.1 shows the selected method Exkor. After the selec-
tion the method's implementation class is loaded and the configuration 
win4ow is opened. 
The configuration window depends on the actual method selected. 
As usual, there is the Iterations field where the number of iterations is 
defined, by keeping the default values or by changing them. The field 
Initialpoints (see Figure 8.1) shows the number of observations for a 
preliminary survey. The preliminary survey is done by some methods 
including Bayes. If the entered value is invalid or out of bounds, the 
field turns red and the value is not stored. 
4. 
UPDATING GMJ 
Compiling is needed to add new methods, new tasks, new analysis 
objects. One compiles, too, to change the data which is not on the 
graphical interface. For example, to add a new task 'NewTask.java', a 
new method 'NewMethod.java', and a new analysis object 
'NewAnalysis.java' one does these operations: 
5This is a reduced Flexi version. Only rectangular constraints are implemented. 

94 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
â¢ compile the 'NewTask.java' , 'NewMethod.java', 
and 'NewAnalysis.java' 
making the corresponding class files 
javac -verbose 
-g -classpath . : 
/home/jonas/public_html/gmjgallj 
/Lib/gmj_allnew.jar: 
/usr/local/jdk1.1.3/lib/classes.zip 
/home/jonas/public_html/gmjgallj 
/lt/ktu/gmj/tasks/NewTask.java 
/home/jonas/public_html/gmjgallj 
/lt/ktu/gmj/methods/NewMethod.java 
/home/jonas/public_html/gmjgallj 
/lt/ktu/gmj/analysis/NewAnalysis.java 
â¢ create the additional archive file 'gmjg_add.jar' by including the new 
class files 
jar -cvf 
/home/jonas/public_html/gmjgallj 
/Lib/gmjg_add.jar 
*class lt/* 
â¢ update the applet 'gmjall.html' by updating the TASKS, 
METHODS, and ANALYSIS parameters and by adding the new 
archive file 
<html> 
<head> 
<META HTTP-EQUIV="Content-Language" 
CONTENT="LT"> 
<META HTTP-EQUIV="Content-Type" CONTENT= 
"text/html; charset=windows-1257; charset=IS0-8859-13"> 
<META NAME="Author" CONTENT="Modestas Grybauskas"> 
<title>GMJ Applet, 
Set of Methods, Tasks, and Analysis Objects</title> 
</head> 
<body bgcolor="#EOEOEO"> 
<h1>GMJ</h1> 
<p> 
<applet 
code="GMJext.class" 
codebase= "Lib" height=1200 width=800 

JAVA 1.2 
95 
archive= 11gmjg_allnew.jar gmjg_add.jar 11 
> 
<patram. nam.e="TASKS" 
value= 11lt.ktu.gmj.tasks.Sinl 
Tvarkallt.ktu.gmj.tasks.Portfoliol 
lt.ktu.gmj.tasks.WalrasModelllt.ktu.gmj.tasks.Knapsackl 
lt.ktu.gmj.tasks.NewTask"> 
<param. nam.e="METHODS 11 value= 11lt.ktu.gmj.methods.Mig11 
lt.ktu.gmj.methods.Bayesllt.ktu.gmj.methods.Globtl 
lt.ktu.gmj.methods.Untllt.ktu.gmj.methods.LBayesl 
lt.ktu.gmj.methods.Exkorllt.ktu.gmj.methods.Lpminl 
lt.ktu.gmj.methods.Flexilllt.ktu.gmj.methods.NewMethod 11> 
<param. nam.e= 11ANALYSIS 11 
value= 11lt.ktu.gmj.analysis.Convergencel 
lt.ktu.gmj.analysis.Spectruml 
lt.ktu.gmj.analysis.Projectionl 
TvarkaAnalyserllt.ktu.gmj.analysis.WalrasProfitl 
lt.ktu.gmj.analysis.NewAnalysis 11> 
<p>You need Java compatible browser 
to see this applet </p> 
</applet> 
</p> 
</body> 
</html> 
4.1 
NEW TASKS 
The task class implements the Task interface: 
public interface Task extends Customizable 
{ 
Domain domain(); 
double f (Point pt); 
}; 
The interface Task is derived from Customizable. This means that it 
is configurable by users. Details are explained in Section 4.3. 
A user defined method double/ calculates values of the objective function 
at the Point pt 

96 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
The class Point pt defines the array of optimization variables belonging 
to the Domain. 
The object domain returns the class Domain, which defines a set of 
feasible decisions. 
In GMJl this is a rectangular region defined by the lower and upper 
bounds of optimization variables6â¢ 
The Domain is an abstract class: 
public abstract class Domain implements Customizable 
{public double min[]; public double max[]; 
public Point defaultPoint; 
public abstract String[] dimensions(); ..... }; 
The abstract function dimensions should be overridden to return the 
descriptions of the domain dimensions. These descriptions are in analy-
sis and configuration windows. 
Variables min, max and defaultPoint are created by the class Domain 
and initialized by the derived class, as required. The Point class imple-
ments a point in a n-dimensional set Domain. 
public class Point { public double x[]; public Point 
(Domain domain) ... }; 
The class Point constructs from a Dimension object. 
One does the following six steps to implement a new task: 
â¢ derive a class from the class Domain, 
â¢ provide the constructor to initialize the default dimension range and 
the default point, 
â¢ override the method dimensions and return descriptions of the di-
mensions of the domain, 
â¢ create the new class, which implements the interface Task, or extend 
an abstract class AbstractTask to make the code compatible with 
future GM.J releases, 
6 N ote, that in G MJ2 the feasible set is given by a user defined constraint function. Therefore, 
there are no restrictions on the shape of feasible set. 

â¢ override the method domain, 
â¢ override the method f. 
Example of Task Sine. 
class SinDomain extends Domain 
{ 
static final String [] dimensions= 
{"X Sin Argument"}; 
public String [] dimensions () 
{return dimensions 
} 
SinDomain () 
{ 
min [0]=-2; 
max [0]= 2; 
defaultPoint.x[O]=O; 
} 
}; 
public class Sin implements Task 
{ 
private SinDomain domain=new SinDomain (); 
public Domain domain () 
{return domain;} 
public double f (Point pt) 
{ 
return Math.sin (pt.x[O]); 
} 
}; 
4.2 
NEW METHODS 
JAVA 1.2 
97 
GMJ can be extended providing additional optimization methods, 
which may be more efficient or more flexible. The method class should 
implement the Method interface: 
public interface Method extends Customizable 
{ 
int iterations (); 
Result run (ResultLogger 1, Task t); 
}; 

98 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
The interface Method is derived from the interface Customizable, which 
requires it to be configurable by the user. iterations returns the total 
number of iterations. 
Most of the optimization methods have the configurable iterations 
property. Therefore, the M ethodBase abstract class is implemented 
on top of the Method interface. It overrides the iterations and the 
customize methods. The method run is overridden by inheriting from 
M ethodBase. The method run runs the optimization method on the 
selected Task, writes the results to the specified ResultLogger, and 
returns the best result. 
The ResultLogger interface gathers the generated results and stores 
them. The ResultLoger interface defines the following members: 
public interface ResultLogger {void log (Result r); 
ResultlogAt (int it); }; 
The method log is to log the resul~ of each iteration of the method. 
Usually, the class implementing the ResultLoger updates the user inter-
face objects reflecting the method's progress when log is called. Some 
methods need a history of optimization. The method logAt provides 
that by returning the Result logged previously in the iteration it using 
the method log. The class Result contains the iteration state: 
public final class Result { 
public int iteration; public Point 
point; public double value; ..... }; 
4.3 
CONFIGURING PROPERTY MANAGER 
Many objects are configured by users. For example, a user may want 
to change the number of iterations or the ranges of the optimization do-
main. PropertyM anager shows the properties, which may be changed. 
The PropertyM anager is a property list that is described by this inter-
face: 
public interface PropertyManager 
{ 
void removeAll (); 
void add (Property property); 

void validate (); 
}; 
JAVA 1.2 
99 
The method add is to add new Praperty objects to the list. The property 
consists of a property name or a label and a value editor. The value 
editor is for changing the value of the property. 
The important component of the Praperty object is the 
PrapertyProvider. This is an object, which knows how to retrieve the 
value of the property and how to store it after the changes made by the 
editor. The custom value retrieval and storage methods are implemented 
because in Java one cannot to pass primitive objects by reference. 
A set of property providers is in the GMJ package, including: 
â¢ the class DoubleArrayProvider accesses the double array elements 
â¢ the class FieldProvider uses the JDKl.l Reflection classes providing 
access to any field of a class 
Example. The following sample code shows how to add a property 
called the "Initial Speed" stored as the second element of the array 
customData. The initial speed can change in the range from 10 to 50 
kmjh. by this interface: 
manager.add 
{ 
nev DoubleProperty 
{"Initial Speed (lm./h)", 
nev DoubleArrayProvider (customData, 1), 10, 50} 
}; 
Here is an example how to add a property named "Offset" stored in a 
public variable off set of the calling class 
manager.add 
{ 
nev DoubleProperty 
{"Offset", 
nev FieldProvider (this, "offset"), 0, 1} 

100 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
}; 
Adding a property to the property manager, an editor of the appropriate 
type is created. If the user changes the value, the value is automati-
cally checked, validated and stored in the second element of the array. 
customData. 
WRITING CUSTOM PROPERTY PROVIDER 
When a property value is stored as a field, then a custom access 
class should be provided to reach that value. This class implements the 
PropertyProvider interface requiring many functions to be overridden. 
Most of them are implemented in the SimplePropertyProvider class, 
which can be used as a base. 
Example. This sample code shows how to provide an access to the 
field 
multiplier of the Sin class, which is double: 
class SinMultiplierProvider extends SimplePropertyProvider 
{ 
public Sin sin; 
public SinMultiplierProvider (Sin _sin) 
{sin = _sin;} 
public Object get () 
{return new Double (sin.multiplier);} 
public void set (Object value) 
throws InvalidPropertyException 
{sin.multiplier=((Double) value).doubleValue ();} 
}; 
Note, that in Java 1.2 reflection is always available. Therefore, applying 
GMJ2 one applies FieldProvider, instead of writing custom providers. 
4.4 
NEW ANALYSIS OBJECTS 
GMJ provides three analysis objects: Convergence, Projection and 
Spectrum (see section 3.4). The new tasks may need the new anal-

JAVA 1.2 
101 
ysis objects. The new analyzers may be derived from any base class. 
They can be implemented as some windows, or they may log data to 
some external files. The only requirement is to implement the following 
ResultAnalyser interface: 
public interface ResultAnalyser 
{ 
void prepare (ResultRepository r); 
void dispose () ; 
}; 
To construct analysis objects the method prepare is called. It asks the 
analysis objects to initialize. A ResultRepositary object is passed as a 
parameter. It contains information to initialize the analyzer. 
The method dispose is called when the analyzer is being deleted. It 
flush the open buffers or close associated windows. The data observer-
notifier pattern is to deliver the results of real time calculations to the 
analysis objects. The data notifier has a list of data observers, which 
are notified when new data is available. To receive these notifications, 
the object implements the ResultObserver interface and registers on 
the appropriate ResultRepositary class. The registration time is in the 
prepare method: before leaving. 
public interface ResultObserver 
{ 
void nevResult (ResultRepository 1); 
void nevProgressResult (ResultRepository 1); 
void finalResult (ResultRepository 1); 
void nevLog (ResultRepository 1); 
void oldLog (ResultRepository 1); 
}; 
The method logStarted signals that new calculations are going to be 
started. 
The method newResult signals, that a new result has just been added 
to the ResultLoger. 
The method newProgressResult signals that a method has made 
progress and did find the better point. 
The method finalResult signals that the optimization is over. 
The method logDisposed signals that the ResultLog is depreciated and 

102 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
cannot be used anymore. In such a case the observers should delete all 
the references to the ResultLogger objects. 
Example. Here is a simple analyzer to print the progress to console 
windows 
public class Demo 
ResultObserver implements ResultAnalyser, 
ResultObserver { 
protected ResultRepository results=null}; 
public void prepare {ResultRepository n} 
{ 
results=n; 
results.addObserver {this}; 
} 
public synchronized void logStarted (ResultRepository n) 
{ 
System.out.println {"START"}; 
} 
void newResult (ResultRepository 1) {} 
void finalResult (ResultRepository 1) {} 
void newProgressResult (ResultRepository 1) 
{ 
System.ot.println {"Progress was made at iteration " 
+ 1.lastResult ().iteration); 
} 
public void logDisposed (ResultRepository r) 
{ 
System.out.println ("STOP"); 
dispose (); 
} 
}; 

JAVA 1.2 
103 
4.5 
PROGRAMMING TIPS 
ABORTING CALCULATIONS 
If optimization lasts too long, a user wants to abort the calculations, as 
usual. When the STOP button is pressed or the applet is about to exit, 
then an interrupted flag is set for the calculation thread. Therefore, 
task and method writers are advised to test for 
if (Thread.interrupted ()) 
throw new ResultLogger.AbortedEror (); 
IMPLEMENTING INTERFACES 
Creating a custom method or task, the class implements a correspond-
ing interface, as usual. The better alternative is to extend an abstract 
class, if available. For example, "extend AbstractM ethod'' is better as 
compared with "implement Method." This makes a code more compat-
ible with future GMJ releases. 
URL ADDRESS 
The original web-sites are attached to the servers 'optimum.mii.lt' or 
'mockus.org'. Therefore, in some examples, the URL addresses should 
be updated to extract data from the local server . 
On the 'Task' menu of GMJl global optimization software the exam-
ples are: "Portfolio," "Tvarka," and "Knapsack." In the task of school 
scheduling 'Tvarka.java', the URL address of the applet host is defined 
automatically and is shown on the graphical interface. 
In the task 
"Knapsack", some URL address is shown on the screen. It should be 
updated by users. In the "Portfolio" task, the URL is defined in the file 
'Portfolio.java'. Therefore, recompiling is needed to extract the data. 

104 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
4.6 
SECURITY RESTRICTIONS 
STAND-ALONE APPLICATION 
Loading applets from their hosts, called as "applet hosts," one meets 
security restrictions. Applying GMJ one often needs to read/write a file 
on a client site or to connect to a strange host. A host that is different 
from the applet host is called as the "strange host." 
If GMJ is loaded as a stand-alone application, one can accomplish 
these tasks without security restrictions. Loading GMJ as an applet 
one is running in a "sand-box." That means: no reading/writing files on 
client sites, no connections to strange hosts. 
SIGNED APPLETS 
A way to escape the sand-box is to sign the applet. The signature is 
a guarantee to others that the applet is friendly. The signature does not 
prevent damage, but it serves as a stamp of good intention. It identifies 
the responsible party, if damage does occur. 
A way to guarantee that a signature is authentic is to notarize it by a 
Certificate Authority (CA). The Certificate Authority authenticates the 
identity of the applicant and then issues a signing certificate. 
Anything signed with a signing certificate will bear the name of CA 
besides the signer name. The signature can be traced, by way of CA, to 
the signer. 
"VeriSign,Inc." is the recognized CA. Signing certificates can be ob-
tained at: 
http : / fdigitalid.verisign.comf software_publishers.html 
For an individual, it costs $40 per year for both Netscape and Internet 
Explorer. The prices are expected to drop. Here is a fragment of a 
signed applet: 
<applet code="WriteFile.class" 
ARCHIVE=" signedWri teFile. jar" 
<param. nam.e="CABBASE" 
value="signedWriteFile.cab"> 
</applet> 

JAVA 1.2 
105 
The ARCHIVE parameter is parsed by Netscape. The CABBASE pa-
rameter is parsed by Internet Explorer. Different browsers use different 
signatures. 
For example, the "Netscape" requires to change some parts of Java 
software, besides signing jar files. 
Signing in "Sun Appletviewer" is simpler. The description is in the 
JDK documentation. Here a user needs the certificate and a "policy" 
file, where all his rights are listed. 
To sign "Internet Explorer" one downloads the Microsoft Java Devel-
oper Kit. The additional information is on web-sites: 
http: I lwww.fastlane.neCtlandryljavafaq.txt 
http: I lourworld.compuserve.comlhomepagesl 
jozartlarticlelindex.html 
Note, that one should not change the existing 'gmj20.jar' file in GMJ2. 
Otherwise, security restrictions might be violated. Therefore, extending 
GMJ a user creates his own jar files7â¢ 
5. 
FEATURES OF GMJ2 
5.1 
CUSTOM RESULT ANALYZERS 
Visualization is a convenient way to represent the input of tasks and 
the results. As usual, the different tasks need different visualization. 
For example, considering the school scheduling (see chapter 3.), one 
wants to see the best obtained schedule. Considering the existence of the 
equilibrium in the Walras model (see chapter 10), it is important to see 
how profit functions depend on prices, resources, and other parameters. 
In such cases the output is implemented as an analysis object (see 
section 4.4). However, we need many analysis objects to satisfy all the 
tasks. To show only task-specific analysis objects, in GMJ2 the Task 
class implements the yzersO interface 
public interface yzers 0 
7In the "applet.html" file one can list several jar files. 

106 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
extends Task 
{ 
Class () analyzers () throws dException 0 
}; 
The analyzers function returns a class list of custom analyzers of the 
task. 
Example. This is a sample task implementation. It states, that there 
exists a custom analyzer, called "Diagram". 
class Demo extends AbstractTask implements ers 0 
{ 
public Class () analyzers () throws ClassNotFoundException 
{ 
Class digramClass.forName ("lt.ktu.gmj.demo.Diagram"); 
return new Class() (diagramClass ); 
} 
}; 
5.2 
DOMAIN CONSTRAINT FUNCTION 
Using GMJl, the methods consider rectangular feasible regions. These 
regions are bounded by lower and upper limits defined on the screen. 
Therefore, in GMJl "non-rectangular" constraints8 are included using 
penalty functions. This is not always convenient. 
In GMJ2 the class Domain is extended to represent any 
non-rectangular domain. This domain includes the function. 
public double constraintAt {Point pt} 
8By "non-rectangular" we mean constraints defined as a system of linear and nonlinear 
equations and inequalities. 

JAVA 1.2 
107 
This function defines a constraint value at the point pt. It returns num-
ber 1 by default (see Figure 8.6). Writing new methods in GMJ2, one 
checks the constraint function before calling the objective function f of 
the Task. If a method does not support constraints, one multiplies the 
constraint value9 by f and minimizes the result. 
Implementing a task in GMJ2, the custom domain class can be derived 
from the DomainWithConstraint class. This enables a user to specify 
the constraint function at run time. DomainWithConstraint adds an 
entry field in the task configuration panel. In this panel, any algebraic 
expression can be entered and compiled at run time (see Figure 8.6). 
Here the constraint is entered by algebraic expression -X12 - X22 + 1 
meaning that -x~ -
x~ + 1 ~ 0. Using these tools, GMJ2 users can 
specify any constraint function. 
5.3 
RUNNING GMJ2 
The constraint function is included into the Tasks page of of GMJ2 
(see Figure 8.6). In this Figure the Sinn task is active. There are several 
different tasks: Tvarka, WalrasModel, DuelStarwars, FlowShop and 
four types of sine and cosine. Sinn is sine with a non-linear constraint. 
Sinl is sine with a linear constraint. Sine is sine without constraints and 
Cosc is cosine without constraints. The task Tvarka is for the school 
scheduling {Nemajunas and Remeikis, 1999). W alrasM odel is for the 
Walras problem and DuelStarwars is for the Duel problem. 
The Methods menu of GMJ2 is in Figure 8.7. There are five global 
methods: Mig1, Bayes, Exkor, Globt, and Unt and three local meth-
ods Shitk, Flexi, and Lbayes. The method Shitk is the Java version 
(Margelevicius, 1999) of the non-linear programming method by Schit-
tkowski (Schittkowski, 1985). Names of remaining methods are the same 
as in GMJL 
The Analysis menu of GMJ2 is in Figure 8.8. Three analysis objects: 
Convergence, Projection, and Spectrum are common for all tasks. Four 
analysis objects: Tvarka, W alrasProfit and DemoAnalyzer are task-
specific. Tvarka shows the initial and the optimized school schedules. 
W alrasProjit shows how the server profit depends on prices and other 
9The default value is 1. 

108 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
Method 'T"a.sk Operation 
S 
e t t 
Property, 
Mul 1plterÂ· 
n) 
tr3 (x 1 .â¢ n) 
Applet strted. 
n 
propert1e 
1 0 
Figure 8.6. 
Task page for the Sin task with one nonlinear constraint. 
... 
parameters. The task-specific analysis objects should be seen, if corre-
sponding tasks are on. Otherwise, they should be closed. The analysis 
object DemoAnalyzer satisfies this condition. DemoAnalyzer is the 
graphical interface of the duel problem. One see it, if the DuelStarwars 
task is on. Figure 8.9 shows this. 
Optimization results and the convergence line is in Figure 8.10. 

Propert~ 
JAVA 1.2 
109 
k roperation 1 
e ect method nd propertie 
'Shitk 
Migl 
~~~~~~~~=--JGiobt 
ount of In q 
ount of Equ 
e-mail: minda.ttgas.m~elsis.com 
Figure 8. 7. 
The method window of GMJ2. 
In the 'Spectrum' window there is an additional option. The window 
shows how depends the distribution of f(x) values on each variable Xi 
(see Figure 8.11). 

110 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
~arning: Rpplet 14indow I 
TvarkaAnalyser 
Wa rasProfit 
Convergence 
Projection 
Spect um 
Figure 8.8. 
The analysis menu. 
14arning: Applet 14indow 
TvarkaA nalyser 
Wa. asProfit 
Convergence 
Projectio 
DemoAnalyzer 
Figure 8.g. 
The analysis menu including the DuelStarwars task. 

X in Ar urn nt 
Y S1n A rgu1nent 
Dummy 
~:Â·~ 
Value 
2 
0.943 
-1.232 
-I .2 2 
0.0 
~arnine: Applet Uindow 
JAVA 1.2 
Ill 
::lu-~ .. ,_ . 1 ~---' -~ 
\ 
. 
-
0 
5 
10 
15 
20 
25 
:lO 
I nobon 
Figure 8.10. 
Optimization results and the convergence line. 

112 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
Figure 8.11. 
The distribution of !(x1,x2) values with respect to x1. 

III 
EXAMPLES OF MODELS 

Chapter 9 
COMPETITION MODEL 
WITH FIXED RESOURCE PRICES, 
NASH EQUILIBRIUM 
1. 
OPTIMIZATION PROBLEMS IN MARKET 
MODELS 
We consider two models of the theory of games and markets (Rosen-
muller, 1981). The Nash equilibrium (Nash, 1950) is applied. The "mar-
ket" is represented by a collection of independent servers. Each server 
tries to maximize its profit by setting optimal service prices and optimal 
server rates. The server rate is the average number of customers that 
would be served in nonstop operation. Thus, we can consider this rate 
as the server capacity. 
The profits of individual servers are maximized assuming that their 
partners respect some agreement about the service prices and rates. 
We call this the "Contract-Vector." Service prices and rates obtained 
by maximizing individual profits of the servers transform the Contract-
Vector into the "Fraud-Vector." The optimization problem is to search 
for such Contract-Vector that reduces the deviation of the Fraud-Vector 
from the Contract-Vector. That makes the fraud less relevant. The 
fraud is irrelevant and the Nash equilibrium is achieved, if this deviation 
is zero. Then servers cannot increase their profits by changing service 
prices and server rates agreed by the contract. 
The quality of service is defined by the average time lost by customers 
while waiting for services. Formal expressions of other quality measures 
are difficult. A customer prefers the server with lesser total service cost. 
115 

116 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
The total cost includes the service price plus waiting losses. A customer 
goes away, if the total cost exceeds a certain critical level. A flow of 
customers is stochastic. Service times are stochastic, too. There is no 
known analytical solution for this model. The results are obtained by 
Monte-Carlo simulation. 
The first market model considers a simple case. Here the server rate 
depends on a single resource that is freely obtainable at some market 
price. This model is the "Nash model," for short. In the second model, 
it is supposed that the server rates depend on several resources. Each 
server owns a fixed amount of single resource. Thus, the number of 
different resources is assumed to be equal to the number of servers. The 
resource limits are controlled using resource prices that are expressed as 
Lagrange multipliers1. This model is the "Walras model," for short. It 
is similar, but not identical, to the traditional Walras model (Walras, 
1874). 
In the Nash model, the servers rent their equipment at fixed price per 
unit of the server capacity. Therefore, in the Nash model we are looking 
for the equilibrium of server capacities and service prices. In the Walras 
model, the servers share each other resources. Therefore, here we are 
looking for the optimal prices charged for the shared resources. That is 
in addition to the search of equilibrium of server capacities and service 
prices. 
Here the market models are to illustrate the possibilities and limita-
tions of the optimization theory and numerical techniques in competitive 
environments. Both the models are developed as test functions for the 
Bayesian algorithms. However, these simple models may help to design 
more realistic ones describing the processes of competition better. Be-
sides, the simplified competitive models are convenient tools for teaching 
the Operations Research and the Theory of Games and Markets. 
2. 
NASH MODEL 
Let us consider m servers providing the same service 
1 Defined by minimizing the Lagrange function corresponding to each server. 

NASH EQUILIBRIUM 
117 
where Ui is the profit, Yi is the service price, ai is the rate of customers, 
Xi is the running cost, and i is the server index. Assume that a server 
capacity Wi is an increasing function of the running cost Xi: 
(9.2) 
A simple example of this function 
Wi = kz(1- exp( -kiOxi)). 
(9.3) 
Here ki defines the maximal server rate and kiO shows the efficiency of 
resource Xi. Then the total service cost 
ez = Yi +ri, 
(9.4) 
where /i is the average waiting cost. To simplify the expressions assume 
that the waiting cost is equal to an average waiting time. Suppose that 
arriving customers estimate the average waiting time as the relation of 
the number of waiting customers ni to the server capacity Wi 
A customer goes to the server i, if 
Ci ~ Cj, j = 1, ... , m, j =/: i, Ci ~COÂ· 
A customer goes away, if 
m~nci >co, 
z 
(9.5) 
(9.6) 
(9.7) 
where c0 is the critical cost. The rate a of incoming consumers is fixed 
m 
a= Lai, 
i=O 
(9.8) 
where ao is the rate oflost customers. Conditions (9.6) and (9. 7) separate 
the flow of incoming customers into m + 1 flows. This makes the problem 
very difficult for analytical solution. The separated flow is not simple 
one, even in the case when the incoming flow is Poisson (Gnedenko and 
Kovalenko, 1987). Thus, we need the Monte Carlo simulation, to define 
average rates of customers ai, i = 0, 1, ... , m, by conditions (9.6) (9. 7), 
and average profits Ui, i = 1, ... , m by expression (9.1). 

118 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
3. 
SEARCH FOR NASH EQUILIBRIUM 
First we fix the initial values, the "Contract-Vector" z0 = ( x~, yp, z = 
1, ... ,m). The transformed values, the "Fraud-Vector" z 1 = (x},yf, i = 
1, ... , m), is obtained by maximizing the profits of each server i. The 
maximization is performed under the assumption that all partners j-:/= i 
will honor the contract (xJ, yJ, j = 1, ... , m, j -1= i) 
â¢ 
( 1 
1) 
( 
0 
0 
. 
1 
. _J_ ") 
â¢ 
1 
.(9 9} 
xi,Yi =argmaxuiXi,Yi,xj,yj, J= , ... ,m, J-;-Z, z= , ... ,m . 
x;,y; 
Formally, condition {9.9) transforms the vector 
zn = (xf, yf, i = 1, ... , m) E B C R 2m, n = 0, 1, 2, ... into the vector 
zn+ 1. To make expressions shorter denote this transformation by T 
zn+1 = T(zn), n = 0, 1, 2, ... 
One may obtain the equilibrium at the fixed point zn, where 
zn = T(zn). 
(9.10) 
(9.11) 
The fixed point zn exists, if the feasible set B is convex and all the 
profit functions (9.1) are convex (Michael, 1976). We obtain the equilib-
rium directly by iterations (9.10), if the transformation Tis contracting 
(Neuman and Morgenstern, 1953). If not, then we minimize the square 
deviation 
min II z- T(z) 11 2 . 
zEB 
(9.12) 
The equilibrium is achieved, if the minimum (9.12) is zero. If the min-
imum (9.12) is positive then the equilibrium does not exist. That is 
a theoretical conclusion. In statistical modeling, some deviations are 
inevitable. Therefore, we assume that the equilibrium exists, if the min-
imum is not greater then modeling errors. 
One can minimize deviation (9.12) by the usual stochastic approxi-
mation techniques {Ermoljev and Wets, 1988), if square deviation (9.12) 
is an uni-modal function of z. If not, then the Bayesian techniques of 
global stochastic optimization (Mockus, 1989a) should be used. The 
global stochastic optimization may outperform the local one in the uni-
modal case, too. That happens, if the noise level is great because the 
Bayesian global stochastic optimization methods are less sensitive to 
large noise levels. 
The Equilibrium is stable, if transformation (9.10) is locally contract-
ing near a fixed point (9.11). If not, then some stabilizing conditions 

NASH EQUILIBRIUM 
119 
should be introduced. The transformation T(z) is referred to as locally 
contracting, if there exists a constant 0 ~ a < 1 such that 
(9.13) 
for all z1, z2 E Zâ¬. 
Here Zâ¬ is a ~;-vicinity defined by the "natural" 
deviations from the equilibrium. 
3.1 
EXISTENCE OF NASH EQUILIBRIUM 
The first existence theorem is due to Nash {Nash, 1951) and dates back 
to 1951. Many generalizations appeared since then. Finding less and 
less restrictive sufficient conditions have been an active field of research 
(Forgo et al., 1999). The proofs of these conditions are based on the 
various fixed point theorems (Brouwer, 1912; Kakutani, 1941; Browder, 
1968). Considering the examples of this book, we prefer simple existence 
conditions to the general ones. Testing the existence conditions, we 
express them in terms of the profit functions u instead of the operators 
T. 
For example, the equilibrium exists, if the profit u( z) is strictly convex 
function of all the components of its parameters z C Z, and Z is a convex 
set (Michael, 1976). In such cases, small changes of z components will 
not change the maximum points considerably. 
The situation would be different in the non-strictly-convex cases. Here 
even very small change of some parameters z, may change the maximum 
point z* of u(z) considerably. For example, in linear cases this point may 
jump from minimal to maximal limits. In multi-modal cases the point z* 
can jump from one local minimum to another one. These sharp changes 
violate the continuity of the transformation T. The continuity ofT is 
needed in the Brouwer's fixed point theorem {Brouwer, 1912). In other 
theorems, such as Kakutani's (Kakutani, 1941) or Browder's (Browder, 
1968), the fixed-point conditions are less restrictive. However, testing 
these conditions is not a trivial task. 
4. 
STABLE COALITION, CORE OF GAMES 
If m > 2, the formation and stability of a coalition S c M are impor-
tant issues. 
Denote by S = i a coalition of an individual server i. 

120 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
Denote by S = {i1, i2) a coalition of two servers i1 and i2. 
Denote by S = (i1, ... , im) = M a coalition of all m servers. 
Assume that service prices Yi = Yi(S), service rates Xi = Xi(S), and 
shares of profit Ui = ui(S) are determined by the coalition agreement 
for all the coalition members i E S . 
Denote by lSI the number of servers in the coalitionS and by u(S) = 
LiES Ui- Suppose that all the remaining servers form the opposite coali-
tion M\S. Assume that the profits Ui corresponds to equilibrium service 
prices and rates y(S), x(S), y(S), y(M \ S). This way we consider the 
m-server system as a set of two-server systems, where the first server is 
coalitionS and the second one is coalition M \ S. A coalitionS* c M 
is stable if there is no dominant coalition S c M such that 
ui(S) > ui(S*), for all i E S 
{9.14) 
The definition of the stable coalition is related to the definition of a game 
core C {Rosenmuller, 1981). It is well known that if 
u(M) > L ui(M), 
iEM 
u(S) + u(M \ S) = u(m) 
{9.15) 
{9.16) 
then the game core is empty C = 0 and there is no stable coalitionS. 
Inequality 9.15 means that a game is essential. Equality 9.16 defines 
a constant-sum game {Owen, 1968). The server system is clearly not a 
constant-sum game. Thus one of two "non-existence" conditions (9.16) 
is not satisfied meaning that a stable coalition S* may exist. If a stable 
coalition S* exists, one may determine it by testing 9.14 for all pairs 
of coalitions. The game core C is empty, if for any S' C M there is a 
dominant coalitionS. 
4.1 
EXAMPLE OF SERVER COALITION 
Consider a case of three servers m = 3. 
Denote by S 1 = i the coalition of an individual server i. 
Denote by S2 = (i1, i2) the coalition of two servers i1 and i2. 
Denote by S3 = (i1, i2, i3) the monopolistic coalition of all three servers. 
Subscripts k = 1, 2, 3 denote numbers of servers in the coalition SkÂ· 
Consider for simplicity the symmetric case. Here profit functions u and 
control parameters x, y depend only on the number of servers in the 
coalition but not on their "names." 

NASH EQUILIBRIUM 
121 
The symmetric case implicitly assumes equality of the control param-
eters and equal sharing of the coalition profit, meaning that in the case 
of s3 
Ui(S3) = (ui + Uj + Ut)/3, 
Xi(S3) = Xj = x,, Yi(S3) = Yi = Yj = YlÂ· 
In the case of S2 
In the case of individual servers S1 
(9.17) 
(9.18) 
(9.20) 
The monopolistic coalition S3 is stable if ui(S3) ~ ui(S2) and ui(S3) ~ 
Ui(Sl). 
The coalition s2 is stable if Ui(S2) ~ Ui(S3) and Ui(S2) ~ Ui(St). 
The coalition sl is stable if Ui(Sl) ~ Ui(S3) and Ui(Sl) ~ Ui(S2). 
There is no stable coalition if no of these condition are satisfied. 

Chapter 10 
COMPETITION MODEL 
WITH FREE RESOURCE PRICES, 
WALRAS EQUILIBRIUM 
1. 
WALRAS MODEL 
In the model called by the Nash name, the cost of a service capacity 
unit is supposed to be fixed. Each individual server i controls the capac-
ity Xi and the price Yi charged for services. Therefore, the Nash model 
illustrates the formation of competitive service prices, if the resource 
prices are fixed by some large external market. 
More complicated models, called by the Walras name, describe the 
formation of the competitive resource prices, too. In the Walras model, 
the capacity Wi of servers i = 1, ... , m depends on the resource vector 
Xi= (Xij, i,j = 1, ... , m) defining the consumption of different resources. 
Each server i owns a single resource bi and charges a price Pi for a unit 
of this resource to partner-servers and to himself. 
A server i controls the resource vector Xi = (Xij, j = 1, ... , m). The 
component Xij denotes the amount of resource bj used by the server i. 
The server i also controls the price Yi of services, as in the Nash model. 
Therefore we shall describe the Walras model in the terms similar to 
those of the Nash model (see expression (9.1)). 
In the Walras model, we introduce the notion of a "penalty" Vi for 
the missing resource bi. The penalty Vi is 
m 
Vi= -{1 + a)pi(bi- 2: Xki), i = 1, ... , m 
k=l 
123 
{10.1) 

124 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
Here Xki denotes the amount of resource bi used by the server k. That 
means that the server i pays penalty Vi if the system is short of the 
resource bi. Note, that the penalty turns into a premium if there is 
excess of this resource. 
In the two-server case from expression (10.1) 
(10.2) 
and 
(10.3) 
Using the multiplier 1 +a one can define different penalty scales. For 
example, this expression 
if Vi ~ 0 
if Vi < 0, 
(10.4) 
where a 1 > a 2 means, the server pays more for the missing resource 
comparing to what it gets for the excess one. Therefore, in the Walras 
model software a 1 is called as "credit rate" and a 2 is called as" deposits 
yield." 
The parameter f. ~ 0 introduces a small non-linear component of 
resource prices. The price of resource I is expressed as the product 
Pi(1 + EPi)Â· The parameter f. has no economical meaning. It helps to 
stabilize the computing process, sometimes. 
For unit scales, where a 1 = a 2 = f. = 0, the prices Pi are considered 
as Lagrange multipliers. Therefore, we assume that ai = 0 and f. = 0, 
as usual. We define the equilibrium resource prices Pi by minimizing 
the Lagrange function in the framework of the traditional method of 
Lagrange multipliers (Horst et al., 1995). 
Assume that the server capacity Wi is an increasing function of the 
resource vector Xi= (Xij,j = 1, ... , m). 
A simple example of this function 
m 
Wi = ki IT (1- exp( -kijXij)). 
j=l 
(10.5) 
(10.6) 

WALRAS EQUILIBRIUM 
125 
The resource component Xij denotes the amount of resource bj used by 
server i. The coefficient kij shows how useful is the resource bj for the 
server i. The coefficient ki defines the capacity limit when Xij --+ oo. 
Then the profit of the i-th server: 
Ui = Ui(Xj, Yj,pj, j = 1, ... , m) = 
aiYi- Vi- LPiXijÂ· 
#i 
(10.7) 
Here i is the server index. ai is the rate of customers. Yi is the service 
price. Vi is the penalty for overusing the resource bi. Xj = (Xjk, k = 
1, ... , m) is the resource vector determining the capacity Wj of server j. 
Xjk denotes the amount of resource bk used by the server j. Note, he 
profit Ui of each individual server i depends on the parameters Xj, Yj,pj 
of all m servers j = 1, ... , m. In the Lagrangian case where ai = 0 and 
f = 0, the profit 
m 
Ui = aiYi- Pi(L Xki- bi)- LPiXijÂ· 
(10.8) 
k=l 
#i 
Here the first component aiYi defines the income of a server i. The 
second component Pi(Lr=I Xki -
bi) defines the penalty for over-using 
the resource bi. The third component Lf:l=i PjXij shows the charge for 
resources obtained from other servers. In Lagrangian two-server cases 
and 
U! = UI(Xu,XI2,YI,PI,X22,X21,Y2,P2) = 
a1Y1- Pl(xu + X21- b1)- P2X12 
U2 = U2(X22,X21,Y2,P2,XU,Xl2,Yl,PI) = 
a2Y2 -
P2(x22 + X12 -
~) -
P1X21 
Assuming the lower and upper limits 
ap;,axii'ay.,bp.,bxii'by; i,j = 1, ... ,m we obtain the inequalities 
ap; :::;; Pi :::;; bp;, ax,i :::;; Xij :::;; bx;i, 
ay, :::;; Yi :::;; by; 
(10.9) 
(10.10) 
(10.11) 
Here the service cost, the waiting cost, and the customer behavior are 
similar to those of the Nash model. Namely, the service cost 
(10.12) 

126 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
where 'Yi is waiting cost 1 at the server i (see expression (9.5)) . A cus-
tomer goes to the server i, if 
Ci < Cj, j = 1, ... ,m, j =I i, Ci :S Co. 
A customer goes away, if 
m~nci >co, 
~ 
(10.13) 
(10.14) 
where c0 is the critical cost. The rate a of incoming consumers flow is 
fixed: 
(10.15) 
where a0 is the rate of lost customers. 
2. 
SEARCH FOR WALRAS EQUILIBRIUM 
We fix a contract-vector (x?, yp ,p?, i = 1, ... , m). Then the fraud-
vector (xi, yi1, pt, i = 1, ... , m) is obtained by maximizing the profits of 
each server i and by assuming that all the partners j =I i will respect 
h 
( 000Â·-1 
) 
t e contract xi,yi,Pi, t-
, ... ,m 
( 
1 
1 
1 ) 
xi' Yi ,pi' = 
argmin maxui(Xi, Yi,Pi, xJ, yJ,pJ, j = 1, ... , m, j =I i). 
(10.16) 
Pi 
x;,y; 
Here the profit function ui(xi,Yi,Pi, xJ,yJ,pJ, j = 1, ... ,m, j =I i) is 
defined by expression (10.8). Lagrange multipliers Pi are obtained by 
the minimization of the Lagrangian (10.8) under rectangular constraints 
(10.11). In the two-server case 
(10.17) 
and 
(10.18) 
1 It is. assumed for simplicity that the waiting cost is equal to an average waiting time. 

WALRAS EQUILIBRIUM 
127 
Condition (10.16) transforms vectors zn, n = 0, 1, 2, ... into vectors zn+l, 
wherezn = (xn,yn,pn), xn = (xf, ... ,x~), yn = (yf, ... ,y~), andpn = 
(pf, ... ,p~). Denote this transformation by T 
zn+l = T(zn), n = 0, 1, 2, ... 
(10.19) 
Here the vector z =(xi, Yi,Pi, Vii= 1, ... , m) E B C Rm2+2m. We reach 
the equilibrium2 at the fixed point zn, where 
(10.20) 
We may obtain the equilibrium directly by simple iterations (10.19), if 
the transformation Tis contracting (Neuman and Morgenstern, 1953). 
There are more sophisticated and efficient iterative procedures (Herings, 
1994). 
If the equilibrium exists but the transformation T is not contracting 
then we minimize the square deviation 
min II z- T(z) 11 2 . 
zEB 
(10.21) 
The equilibrium is achieved, if the minimum (10.21) is zero. The feature 
of the Walras model (Walras, 1874) is that there are no excess demand 
or surplus of resources Xi, if the resource prices Pi meet the equilibrium 
condition. We use this as second test of equilibrium, besides zero of 
minimum conditions (10.21). 
m 
m 
~)I LXij- bil) = 0. 
(10.22) 
i:=l 
j==l 
The constraints (10.11) limits the Walras model. Therefore, setting these 
constraints one should resolve the following contradiction. Wider lim-
its means more computing for optimization but less restriction for the 
Walras model, and vice versa. A way to get around this contradiction 
is to start with narrow bounds (10.11). One widens them later. Some 
of these bounds obviously restrict the profit maximum (see for example 
Figure 10.1). The figure shows that the lower limit x11 ~ 1 restricts the 
maximal profit. 
The equilibrium tests (10.21) and (10.22) fail, if there is no equi-
librium. That means the problem is ill-defined and the Walras model 
2If the equilibrium exists. 

128 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
C urr 99 
TestÂ· 0.07: Test: 8.3 
Serv 36 Serv 37 Gon 27 
U1 
170 -
Â·Â·---....... 
I 
-....... Â·--............. 
-----------
1&5 
1&0-
155 
................... -
:::..._.~ 
150 ... 
145 
1 
2 
1-st server profit (>< 11) 
J Java Applet Wmdow 
I 
3 
11 
Figure 10.1. 
The relation of the profit u1 on the resource xu . 
should be corrected. In such a case, additional testing of the existence 
conditions is needed. It is well known, that the equilibrium exists, if 
the profit u is a convex function of parameters y , x ,p (Michael, 1976). 
Therefore, the "non-convexity" of this function can be a reason of the 
failure to obtain the equilibrium. 
Another reason of the failure might be insufficient optimization. Here 
the equilibrium can be reached by increasing the number of iterations 
(if the optimization method converges). 
3. 
MONTE-CARLO SIMULATION 
3.1 
SEARCH FOR EQUILIBRIUM 
The analytical solution of both the described market models is not 
practical. Therefore, we briefly consider the basic steps of an algorithm 

WALRAS EQUILIBRIUM 
129 
of the statistical simulation using Monte-Carlo techniques. The algo-
rithm implements two basic tasks: 
â¢ generates the next event time t, 
â¢ updates the state of queuing system defined by the vector of waiting 
customers n(t) = (ni(t), i = 1, ... , m), 
â¢ updates the vector h(t) = (hi(t), i = 1, ... , m) of the service cost 
including the money charged and the time lost. 
There are 2m + 2 types of event times t: 
â¢ the time t when a customer arrives into the system, 
â¢ the timet when a customer arrives into the i-th server, i = 1, ... , m, 
â¢ the timet when a customer departs from the i-th server, 
â¢ the time t when a customer abandons the service (departs from the 
system without being served). 
Here i = 1, ... , m. The system state is updated at each event time t. 
Two vectors define the system state: 
â¢ a vector n = n(t) with m components n = (nr, ... , nm), where ni = 
ni(t) shows the number of customers waiting for the service of the 
i-th server, 
â¢ a vector h = h(t) with m components h = (h1, ... , hm), where hi(t) = 
Yi +/i, 'Yi = ni(t)/wi shows the total customer expenses, Yi is money 
charged for the service, and 'Yi is the time lost waiting for the service 
of the i-th server3â¢ 
There are no state changes between events. The basic steps of the Monte 
Carlo algorithm: 
1. fix the zero event time t = t0 = 0 when the first customer arrives, 
3For simplicity, it is assumed that "time-is-money'' and that a unit of time cost a unit of 
money, in the real life cases the corresponding coefficients should be included 

130 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
2. define the zero state vector nÂ° by the condition: n? = 0, i = 1, ... , m 
and the zero state vector h0 by the condition : h? = Yi = 0, i = 
1, ... ,m 
because there are no customers waiting for service yet, 
3. define the next arrival into the system by the expression 
Ta = -1/a ln(1- ry) 
(10.23) 
where 'TJ is a random number uniformly distributed in the interval 
[0,1], 
4. chose the best server i 0 for the first customer by the condition i 0 = 
arg milli=O, ... ,m hi where hi = Yi, because ri = 0, i = 1, ... , m since 
there are no customers waiting yet, i 0 = 0 means that the customer 
abandons the service, 
5. define the time of event when the first customer will be served by the 
server i 0 using the expression 
(10.24) 
6. define the next event t 1 by comparing the arrival time Ta and the 
service time Tio : 
if Ta < Tio then t1 = Ta, 
if Ta > Tio then t 1 = Tio, 
7. define the system state at the next event t 1 : 
if t1 = Ta then nio = 1 and ni = 0, i = 1, ... , m, i -=1- i 0, 
consequently hio = Yio + 1/wio and hi = Yi, i = 1, ... , m, i -=1- i 0 , 
ift1 = Tio then ni = 0, i = 1, ... ,m, and hi= Yi, i = 1, ... ,m, i -=1- i 0 . 
Definition of later events and system states is longer but the main idea 
remains the same. 
The algorithm can be directly adapted to the Monte-Carlo simulation 
of the Nash model with two servers, too. For example, that can be done 
this way: 
- set to unit both the resource charges Pi = 1, i = 1, 2, 
- set to zero resources exchanges x21 = X12 = 0, 
- assume that xu = x1, x22 = x2, where variables x1, x2 are from 
expression (9.1). 
If the number of severs m > 2 then some modification of the described 
algorithm is needed. 

WALRAS EQUILIBRIUM 
131 
3.2 
TESTING EQUILIBRIUM CONDITIONS 
In the Monte-Carlo simulation, equilibrium tests (10.21) and (10.22) 
should be relaxed by accepting some simulation errorE: 
and 
min II z- T(z) 11 2 ~ E, 
zEB 
m 
m 
L:<l L Xij- bil) ~f. 
i=l j=l 
(10.25) 
(10.26) 
Testing the convexity of profit functions, some smoothing is desirable. 
The smoothing eliminates the random deviations due to Monte-Carlo 
simulation. Both the convolution and the Wiener filters are applied for 
smoothing the profit functions (possibly multi-modal). The convolution 
filter defines the function at some fixed point as an average of values in 
the neighborhood of this point. The more sophisticated Wiener filter is 
implemented, too. 
3.3 
WIENER FILTER 
If the objective function f(x) is defined by Monte Carlo simulation, 
some noise is present. That means that one observes the sum 
Â¢(x) = f(x) + e, 
(10.27) 
where e is a random number called the noise. 
If finding the optimum of a convex function f ( x) is the only goal, we 
can apply some stochastic optimization algorithms (Ermoljev and Wets, 
1988). These algorithms converge to the optimum of f(x) by filtering 
the noise during the optimization process. 
To test properties of f(x), such as convexity, uni-modality e.t.c., 
we need specific smoothing algorithms that eliminate false local op-
tima. In one-dimensional cases, a convenient smoothing function is 
the conditional expectation of the Wiener process with noise (Kushner, 
1964b; Senkiene, 1980). It is assumed that the optimization parameter 
X E [0, 1], the Wiener parameter is a unit, and the noise e is Gaussian 
with zero mean and variance Si at the points xi E [0, 1], i = 1, ... , n. 

132 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
Then the conditional expectation f.Lk = f.Ln(xk) of the objective func-
tion Yk = f(xk) at some fixed point xk with respect to the observations 
results Yi =Â¢(xi), i = 1, ... , n, can be expressed this way 
Here 
'\'k 
bÂ·yÂ· + ~ '\'n 
r,yÂ· 
L..,i=l 
Z Z 
Cf< L..,i=k+l ~. Z 
f..Lk = 
'\'k 
bÂ· 
~ '\'n 
. 
L..,i=l 
Z + Cf< L..,i=k+l Cj 
b1 = 1, B1 = 1, 
St + r-1 2 
b2 = 
82 ' , B2 = B1 + b2, 
2 
Cn = 0, 
Sf+1ck+l + rk,k+lck+l C 
...[!-.. r,, 
Ck = 
52 
' 
k+ 1 = L.....J 
~, 
k 
i=k+l 
ri,j = lxi- xi!. 
It is convenient to assume that 
si = s, i = 1, ... , n, 
where Scan be considered as a smoothing parameter. 
(10.28) 
{10.29) 
(10.30) 
(10.31) 
(10.32) 
{10.33) 
(10.34) 
(10.35) 
If S = 0 then no smoothing occurs. The smoothing function (the 
conditional expectation) is the piece-wise line connecting the observed 
points (see Figure 1.1). 
If Sis large then one obtains a horizontal line corresponding to the aver-
age value of observed values YiÂ· That means a sort of" total smoothing." 
In modeling the yield of differential amplifiers, the best smoothing was 
achieved at S = 10 (Mockus et al., 1997). 
Figure 10.2 shows how the first server profit u 1 depends on the price 
p 1 charged for its resources. There are two samples of the same relation. 
They show the differences between two samples of random arrival times 
of fifty customers. 
The buttons 'smooth' and 'wiener' on the right side of Figure 10.9 are 
for switching on these filters. The button 'smooth' is for the convolution 
filter. The button 'wiener' is for the Wiener filter. 
The field denoted by 'S' at the top right corner, defines the smoothing 

WALRAS EQUILIBRIUM 
133 
Warning: Applet W1ndow 
F <x> = 23. 22 Best 5'3 
Cur 99 
Te-s+.l e. 352Test2 -e. 55S= 
s rvo 14 
s l"Vâ¢36 
Goneâ¢0 
ul= 110. u2= 335.!vl= 94. 1:v2= 111. Â· 
X11=6.4~V1= 13.EP1= 11.1X22=7.1:Y2= 12.4P2= 9.6~X12=8.3eX21=9.91 
Ul 
220 -
l 
t -
200 
ISO 
160 , 
' 
HO 
0 
~ 
-r-Â· 
/ \' 
T 
\ 
\ .\. 
\ 
\-t 
1-st se-l"Ver profit 
..... , 
/ 
"'\ 
f 
v 
\, 
( 
\./ 
. 
10 
---
PI 
Smooth 
l-liener 
Undo 
Refresh 
Warning: Applet Window 
F <x> = 23. 22 B st 53 
Servâ¢ 14 
Se-1"Vâ¢36 
Gone: a 
ul 
110. u2= 335. !v1= 84. l.v2= 
11 L Â· 
X11=6.4~V1= 13.~Pl= 11.1X22=7.1~Y2= 12.4P2= 9.6~X12=8.3eX21=9.91 
U1 
100, 
0 
1-st Se-l"V r profit (pl) 
10 
PI 
Smooth 
1-1111mer 
Undo 
Refresh 1 
Figure 10.2. 
The relation of the profit Ui on the resource price Pi (top), the "re-
freshed" relation of the profit Ui on the resource price Pi (bottom). 

134 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
Warn1ng: Applet W1ndow 
F<>>=23.22Best 53 
Curr 99 
Test10.352Test2-0.55S= 
Â·10 
Servo 14 
Servâ¢ 36 
Cone El 
ul= 110. u2= 
335 . ~v1= 84.1:v2= 111. : 
X11=6.4~Yl= 13.~Pl= 11.1X22=7.1~Y2= 12.4P2= 9.6~X12=8.3â¬X21=9.91 
U1 
220Â· 
210 ' 
200 
190 ~ 
180 
170 r 
160, 
0 ---
,/~ 
---~.,Â· 
_____ .... -
/',/ 
__ , 
5 
10 
1-st serv r prof i t 
(p 1) 
__.::j 
01 
Smooth J 
Wiener 
Undo 
Figure 1 0.3. The relation of the profit UI on the resource X2 2 smoothed by the Wiener 
filter. 
parameter S of the Wiener filter (see expression (10.35). 
One can increase the level of smoothing by pressing the 'smooth' or 
'wiener' buttons repeatedly. 
The 'refresh' button repeats the Monte-Carlo simulation of the same 
profit function. 
Figure 10.3 shows the graph shown in Figure 10.2 (bottom) smoothed 
by the Wiener filter. 
Figures 10.4 show the third sample of the 'refreshed' unsmoothed graph 
and the same sample smoothed by the convolution filter. 
The underlying profit function is the same in all the Figures, from 10.2 
up to 10.4. The repeated simulation defines different graphs because of 
the simulation errors. After smoothing, the level of these errors is lower. 

WALRAS EQUILIBRIUM 
135 
Warning: Applet W1ndow 
F (x.â¢ = 23. 22 B st 53 
Curr '.:19 
Test10.352Te 't2-0.55S: 
ul"' 110. u2= 335. !v1= 84.t:v2= 111. : 
X11=6.4:Y1= 13.~Pl= 11.iX22=7.1~Y2= 12.4P2= 9.6~X12=S.3CX21=9.91 
Ul 
2~0-
T 
190 i 
J. 
J--
170 
ISO 
0 
/\ 
\ 
/ 
\ 
/ 
:..\7 
/I 
/ 
\ 
\ 
\. 
[i 
=I ' 
. cL -'\ 
...... 
...... 
\ I 
. 
.f. 
~/-~~1 
Â·-~ . 
â¢ 
10 
PI 
(pl) 
Warning: Applet Window 
Cur 'il'3 
T stl e.352T t2-e.55S: 
Servo14 
Serv.36 
Gol"'eâ¢e 
ut: 110. u2= 335.!v1= 84. 1 v2= 111. : 
X11=6.4~Y1= 13.~P1= 11.iX22=7.1~Y2= 12.4P2= 9. 61X12=S.3eX21=9.91 
Ut 
220..,. 
210 â¢ 
200Â· 
190-
180â¢ 
170-
160 -
1so, 
0 
--
_... ...__ 
~-\ 
' 
Â·' 
'==--,~/ 
v 
Â·-Â· 
1-s't server profit <pl) 
/"-
/ 
â¢ 
10 
PI 
Figure 10.4. 
The third sample of the relation of the profit u1 on the resource PI 
(top), the relation of the profit u1 on the price p1, smoothed by the convolution filter 
(bottom). 

136 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
4. 
SOFTWARE EXAMPLE 
Java JDK1.1.3 implementation (Perlibakas, 1999) of the Walras model 
is on web-sites (see section 4.). Figures 10.5 and 10.6 show the input 
page. The method 'Bayes1' is set. The parameters: 
number of initial iterations lt is 5, 
number of iterations it is 30, 
stocks of server resources b1 and ~ is 16 
interest of "credit" and "yeld" of deposit a 1 and a2 both are zero (La-
grangian case) 
stabilizing non-linearity E is 0.01 
"run-away" threshold CO is 20 
customer rate A is 50, 
number of time units M is 1 
efficiency of first server z01 is 8 
efficiency of first server resource when used by first server z11 is 0.2 
efficiency of second server resource when used by first server z21 is 0.2 
efficiency of second server zo2 is 8 
efficiency of first server resource when used by second server z12 is 0.2 
efficiency of second server resource when used by second server z22 is 0.2 
steps of all parameter changes Step are 1.0, 
lower bounds min are 0.0, 
upper limits max for service charges are 36.0, 
the rest upper limits max are 12.0. 
Figure 10.7 shows the results of optimization. 
In this figure: 
it denotes the "best' iteration 
F(x) means the minimal deviation from the equilibrium point, 
xn,Yt,Pt,X22,Y2,P2,Xt2,X21 are the optimal values of the parameters. 
Figure 10.8 shows how the profits of first and second server change 
depending on the iteration number it. 
The Figure provides some additional information, too. 
"Best 20"denotes the best iteration. 
"Curr 29" denotes the last iteration, both counts from zero. 
"Test1 -0.50" means negative balance of first server resource. 
"Test2 0.59" means positive balance of second server resource (see ex-
pression (10.22)). 
"Serv 42" means that the first server served 42 customers. 
"Serv 8" means that the second one served only 8. 

WALRAS EQUILIBRIUM 
137 
r;. friDn .,. .. ,., â¢â¢ 
â¢ â¢ no 
â¢ d>-gn) 
Figure 10. 5. 
The table of initial parameters, the upper part. 
"Gone 0" means that no customer was lost'. 
"v1=99.2" and "v2=84.6" show the "penalty" functions (see expression 
(10.1)). 
The rest numbers just repeat the optimal parameters shown in the out-
put table (see Figure 10.7). Figure 10.9 shows how the profits of first 
and second server depend on the auxiliary resources xu and x22 
Figure 10.10 show how the profits of first and second server depend on 
the resources obtained from their partners x12 and x21Â· 
Figure 10.11 show how the profits of first and second server depend on 

138 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
.. .. 
Figure 10. 6. 
The table of initial parameters, the lower part. 
XII (( II""S 
re.......-ee '-'"d by t â¢I""S 
Sff"Ve1') 
yl ( 
ur 
â¢ P"'Yâ¢c.â¢s 
pi 
t â¢ 
v22 
,.,.. 
...... r) 
y.Z 
câ¢t> 
p2 
c.> 
Figure 10. 7. 
Optimization results using the method Bayes!. 
the service charges Y2 and Y2Â· 
The figures show that optimization is approaching the equilibrium. 
However, to obtain better accuracy more computing power is needed. 
Simulating fifty customers, one iteration needs five minutes of Pentium 
300 processor time. 

WALRAS EQUILIBRIUM 
139 
Warning: Applet W1ndow 
F <x> = 23.22 Best 53 
Curr 99 
T st1B.352Test2-0.55S= 
Servâ¢l4 
Se-rvâ¢36 
Goneâ¢0 
ul= 110. u2= 
335.~vl= 84.l:v2= 111. : 
X11=6.4~Yl= 13.~Pl= 11.1X22=7.1~Y2= 12.qP2= 9.6~X12=S.3eX21=9.91 
U1 
SOOâ¢ 
â¢oo-
300Â· 
- 200; 
0 
1-st server ptâ¢of' i t ( i terat ion> 
Warning: Applet Window 
F<x>=23.22Be t 53 
Câ¢Jrr 99 
Testl B. 352 Test2 -0.55 S= 
Setâ¢vÂ·l4 
Servo36 
Goneâ¢0 
ul= 110. u2= 
335.~vl= 84.1' v2= 111. : 
U2 
500-
â¢oo-
300-
-~r 
200Â· 
100Â· ~ 
o- Y li 
-100 -
! ,_ 
-200 -t --
ltJ 
â¢ 
~A 
n 1 
I 
I 
Â·-
y 
t f-
--
' 
0 
10 
20 
Â·\t!J~ 
~ 
f\-
F\f-
Â·--. 
! 
I 
r\ 
l 
111 
~ 
i 
I -
~~~ U-\Â· 11-
i1 
li 
Pv 
II--\i Â·. '--iVYJ_ 
[_ 
t( 
; 
' 
Â·-
â¢ 
1 
50 
60 
70 
80 
90 
it/ 
2-nd setâ¢ver prof i t (iteration> 
Figure 10.8. 
Relation of the profit Ut on the iteration number it (top), Relation of 
the profit u2 on the iteration number it (bottom). 

140 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
Warning: Applet Window 
F<x>= 3.22B.st 53 
Cvrr 99 
Testl 0.352Test2-0.55S= 
Serv. 14 
Serv.3G 
Goneâ¢O 
ul= 110. u2= 33S.!v1= 94.1 v2= 111. : 
Xll=6.4~Yl= 13.~P1= 11.1X2Z=7.1~Y2= 12.4P2= 9.6~Xl2=8.3eX21=9.91 
U1 
200 ~ 
150Â· 
100 
50 
o I 
-50 -t 
0 
,.._ 
.--
/7-
F <x> = 23. 22 B st 53 
/ 
--~~ IT 
Â·-
â¢ 
5 
10 
Hll 
<xlD 
Warning: Applet Window 
Curr 99 
Testl e. 352 Test2 -e. 55 S= 
Serv.l4 
ServÂ·36 
Goneâ¢O 
ul'" 110. u2= 33 . !v1= 94.t:v2= 111. : 
X11=6.4~Y1= 13.~P1= 11.1X22=7 .1 ~Y2= 12.4P2= 9.6~X12=8.3(X21=9.91 
U2 
300 
250 
200 
150 
100 
. 
I 
VÂ· 
50 
0 
-so 
0 
I-
2-nd 
// 
;::>'" 
,..... 
,/' 
â¢ 
-
L 
-
~,.,... ______ 
-
--
-
--Â· !----Â· 
-
10 
H22 
<x22> 
Figure 10.9. 
Relation of the profit u 1 on the auxiliary resource x 11 (top), Relation 
of the profit u2 on the auxiliary resource X22 (bottom). 

WALRAS EQUILIBRIUM 
141 
Warning: Applet Window 
F<x =23.228 s1: 53 
Curr 99 
T st1 B.352Te t2-0.S5S= 
Servol4 
Servo36 
Goneâ¢B 
ul= 110. u2= 
335.~vl"' 84.l.v2= 111.: 
X11=6 .4~Yl= 13.~P1= 11./X22=7.l~Y2= 12.4P2= 9 .6~X12=8.3â¬X21=9 .91 
Ul 
200 
150 
100 
50 
0 
-50 
. 
j 
l 
0 
/~ 
r ---
7 
F <x> = 23. 22 8â¬s1: 
53 
/'... 
' 
,.,..........\ 
I 
v 
\ 
/ 
I 
~ 
5 
10 
H12 
<xl2> 
Warning: Applet Window 
Curr 99 
T stHl.352Test2-0.SSS= 
.liB 
Sl!rVâ¢l4 
Servâ¢36 
Goneâ¢B 
ul= 110. u2= 
335.~vl"' 84.1:v2= 111.: 
X11=6.4~Y1= 13.~P1= 11./X22=7.1~Y2= 12.4P2= 9.6~X12= 
U2 
300 "-
250 -
200 Â· 
150 Â· 
/ 
100 . 
50 ~ .J 
' 
ol 
0 
10 
H21 
2-nd s rver profit <x21> 
Figure 10.1 0. 
Relation of the profit u1 on the resources obtained from second server 
X12 (top), Relation of the profit u2 on the resources obtained from first server x 21 
(bottom). 

142 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
Warning: Applet Window 
F (x) = 23.22 Best 53 
Cvrr 99 
Tes1:1 a. 352Test2 -13.55 S= 
.TP~ 
Servo36 
Goneâ¢O 
ul= 110. u2= 
335.~v1= 84.t:v2"' 111. : 
X11=6.4~Y1= 13.cPl= 11.iX22=7.l~Y2= 12.4P2= 9.6~Xl2=8.3eX21=9.91 
U1 
200 
150 
100 
50 
0 
-so 
-100 
. ===if-
r .... Â· 
.. ~ 
:-A 
I . 
1/ 
I 
I 
! 
â¢ 
Â·-
â¢ 
0 
10 
IS 
--
\ . - I 
' 
20 
25 
30 
1-st sP.rver profit <yl> 
J 
Warning: Applet W1ndow 
! 
Yl 
F <x> = 23. 22 Best 53 
Curr 99 
Te t10.352Te t2-0.5SS= 
Servo 14 
Servo36 
Goneâ¢(! 
ul= 110. u2= 
335.~v1= 84.1:v2: 111. Â· 
X11=6 .4~Yl = 13.cP1= ll.iX22=7.l~Y2= 12.4P2= 9.6~X12=8.3~X21=9.91 
U2 I 
I 50 
/; 
/; 
/, 
l 
I 
50 
-so J..t~ 
f 
-1 so~ 
0 
s 
_,.-.. 
I 
\ ~-
I \ ' \ 
\ 
f-Â· 
10 
15 
2-nd server profit (y2) 
Â·-
L--
llâ¢ 
20 
25 
30 
Figure 10.11. 
Relation of the profit u 1 on the service charge y1 (top), Relation of 
the profit u2 on the service charge Y2 {bottom). 

Chapter 11 
INSPECTION MODEL 
The Nash and Walras models illustrate the competition in economics. 
Both models define such prices and other production parameters that 
satisfy the Nash equilibrium. However, the market competition repre-
sents only a part of economical and social activities. Another part is the 
inspection that one needs to provide tax collection, health and environ-
ment protection, e.t.c .. We consider a simple model that illustrates the 
competition between inspector and violator. 
1. 
BIMATRIX GAME 
Denote by x = (x1, ... , Xm), Xi 2::: 0, Li Xi = 1 the inspection vector 
and by y = (y1, .. , Ym), Yi 2::: 0, Lj Yi = 1 the violation vector. Here Xi 
denotes the inspection probability of the area i. Yi means the violation 
probability in the area j. Denote by u( i, j) the inspection utility func-
tion when the object i is inspected and the object j is violated. Denote 
by v(i,j) the violation utility function when the object i is inspected and 
the object j is violated. FUnctions U(x, y) and V(x, y) denote expected 
values of the inspection and violation utility functions using inspection 
and violation vectors x, y. These vectors define probabilities of inspec-
tion and violation. For example, 
u(i,j) 
{ Pi9iQi, 
if i = j 
0, 
otherwise, 
{11.1) 
143 

144 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
and 
ifi = j 
otherwise. 
(11.2) 
Here Pi is the probability of detecting the violation, if it happens in the 
area i. qi is the probability of completing the violation1, if violation 
occurs in the area i. 9i is the utility of the completed violation in the 
area i. 
Expression {11.1) means that if the violation is completed and de-
tected2 then the inspector premium is equal to the utility of violation3 . 
Expression (11.2) shows that if the violation is completed and detected, 
the violator utility is negative. The utility is positive, if it is completed 
and not detected. 
The average utility functions at fixed inspection and violation vectors 
x andy 
U(x,y) = LXiu(i,j)yi, 
{11.3) 
i,j 
and 
V(x,y) = LXiv(i,j)YiÂ· 
(11.4) 
i,j 
Here U(x, y) =1- V(x, y). Therefore, the inspection model is a bimatrix 
game {Forgo et al., 1999). 
2. 
SEARCH FOR EQUILIBRIUM 
Denote the contract-vector as x0 = (x?, yp, i = 1, ... , m). Then the 
fraud-vector x1 = (xt,y{, i = 1, ... ,m), is obtained by maximizing the 
expected utilities U(x, y) and V(x, y) separately. It is assumed that the 
"partner" honors the contract (x?,y?, i = 1, ... ,m) 
x1 = argmaxU(x,y0 ), U = maxU(x,y0 ), 
X 
X 
y 1 = argmax:V(x0,y), V = maxV(x0,y). 
y 
y 
1 For example, killing prey. 
2Prey is killed and a poacher is caught. 
3The price of the killed prey. 
(11.5) 
(11.6) 

INSPECTION MODEL 
145 
These expressions define two linear programming problems that may 
be solved for any fixed contract vectors x0 = ( x?, Y?, i = 1, ... , m). 
However, using the standard simplex algorithm, one obtains the optimal 
base solution of linear programming problem, as usual. This solution 
represents the "best" vertex on some simplex. It follows from expressions 
(11.3)(11.4)(11.5) and (11.6) that the best vertex is defined by conditions 
and 
{ 1, 
if Ej u(i,j)yj < Ej u(k,j)yj, k -=F i, i = 1, ... , m 
0, 
otherwise, 
1 
{ 1, if "Ei v(i,j)xi < "Ei v(i, l)xi, l =/:. j, j = 1, ... , m 
Yt = 
0, 
otherwise, 
These conditions define a set of pure strategies (xl, y1). If the equilib-
rium point is in pure strategies, it can be obtained by the Direct Search 
Algorithm, too (see Section 2.1). 
It is well known (Forgo et al., 1999) that, in randomly generated 
large bimatrix games, the proportion of games having k pure strategy 
equilibriums is defined by the Poisson distribution 
e-1 /(k!) 
(11.7) 
That means that roughly two-thirds of randomly generated bimatrix 
games have at least one equilibrium point in pure strategies. This result 
holds for general randomly generated bimatrix games. In the inspector 
game, there is no equilibrium in pure strategies, as usual. 
2.1 
DIRECT SEARCH ALGORITHM (DSA) 
A simple way to obtain equilibrium in pure strategies is the Direct 
Search Algorithm (DSA). The set I J of equilibrium points in pure strate-
gies is the intersection of two sets I and J defined by the following 
conditions 
IJ=InJ, 
I= Uji(j), J = UiJ(i) 
I(j), ~ arg maxi u(i,j) 
J(i), ~ arg maxi v(i,j). 
(11.8) 
(11.9) 
(11.10) 
(11.11) 
Here I(j) is a set of maximal elements at each column of the matrix 
u(i,j). J(i) is a set of maximal elements at each row of the matrix 

146 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
v( i, j). If equilibrium exists and the intersection I J is empty, one needs 
mixed strategies to obtain the equilibrium (Owen, 1968). 
2.2 
NECESSARY AND SUFFICIENT 
CONDITIONS 
For a pair (x0 , y0 ) to be an equilibrium point of the bimatrix game 
(A, B), it is necessary and sufficient (Forgo et al., 1999) that there exist 
real numbers a0 , {3Â° such that (x0 , y0 , a 0 , {3Â°) satisfies the system 
xAx-a=O, 
xBy- f3 = 0, 
Ay- a.I ~ 0, 
xB- f3I ~ 0, 
x ~ 0, y ~ 0, Ix = 1,Iy = 1. 
(11.12) 
Here I denotes the unit vector. The condition (11.12) represents the 
bilinear problem because it involves products of different variables. The 
solution of bilinear problems is difficult. Therefore, we consider two 
apprximate algorithms to search for mixed strategies of the equilibrium. 
2.3 
IRRELEVANT FRAUD ALGORITHM 
(IFA) 
Often one obtains a mixed equilibrium strategy, if it exists, using a 
continuous set of all the solutions not just the base ones of the linear 
programming problems (11.5) and (11.6). Here the base solutions repre-
sent the pure strategies. The other solutions represent mixed strategies. 
The idea is to define such mixed strategies that makes the partner fraud 
irrelevant4â¢ The following expressions define these strategies 
m L u(i,j)yJ = U, i = 1, ... ,m, 
j=l 
m L v(i,j)x? = V, j = 1, ... , m, 
i=l 
(11.13) 
{11.14) 
4 The fraud is irrelevant, if average winnings of the partner does not depend on his pure 
strategy i = 1, ... ,m, and vice versa 

INSPECTION MODEL 
147 
m LYJ = 1, 
(11.15) 
j=l 
m L x? = 1, 
(11.16) 
i=l 
x? ~ 0, yJ ~ 0, i,j = 1, ... , m. 
(11.17) 
The expressions (11.13)- (11.17) define values of yJ providing the mul-
tiple "continuous" maximum of U ( x, y0 ). This means that any vector 
x 1, Li x} = 1, Xi ~ 0 maximizes the average utility at given y = y0, y0 = 
(y~, ... , y~), 
(11.18) 
and 
y 1 = argmaxV(x0,y), V = maxV(x0,y). 
y 
y 
(11.19) 
Any probability distribution x 1 satisfies the maximum condition,. There-
fore, one obtains the equilibrium just by setting 
(11.20) 
and 
(11.21) 
Expressions (11.13), (11.15, (11.17) include inequalities. Therefore, 
the linear programming (LP) is an appropriate method of solution. In 
LP all the variables are supposed to be nonnegative. Thus, variables U 
and V should be expressed as differences of two nonnegative variables 
U = Ut - u2 and V = Vt - v2. Then from expressions (11.13) (11.15 
(11.17) one obtains this LP problem 
max (ut - u2 + Vt - v2), (11.22) 
x,y,u,v 
m L u(i,j)yj = Ut- u2, i = 1, ... , m, (11.23) 
j=l 
m L v(i,j)xi = Vt- v2, j = 1, ... , m, (11.24) 
i=l 
m 2: yJ = 1, (11.25) 
j=l 

148 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
m L x? = 1, (11.26) 
i=l 
Xi 2: 0, Yj 2: 0, i, j = 1, ... , m, Ut 2: 0, U2 2: 0, V1 2: 0, V2 2: 0. (11.27) 
Here x = (x1, ... , Xm), y = (y1, ... , Ym), u = (u1, u2), v = (v1, v2). The 
solution of this linear programming problem exists not always. Then one 
searches for the equilibrium in pure strategies using the Direct Search 
algorithm ( 11.8). That complements the linear programming algorithm 
(11.25), (11.26),(11.27) and helps to define the equilibrium. An alterna-
tive is the strategy elimination algorithm. 
2.4 
STRATEGY ELIMINATION ALGORITHM 
(SEA) 
If no equilibrium is detected by both these algorithms, then following 
procedure is used: 
1. obtain a solution (x*, y*) of linear equations (11.13),(11.14),(11.15), 
and (11.16), while ignoring inequalities (11.17), 
2. set to zero all negative variables: Xi = 0, if xi ::; 0; Yj = 0, if yj ::; 0, 
3. reduce the system of linear equations by eliminating columns j and 
raws i with zero variables j : Yj = 0 and i :Xi = 0, 
4. if a solution of the reduced system is found, stop, and record the 
zero componentsas pure strategies, record the positive components 
Xi > 0, Yj > 0 as mixed equilibrium strategies, 
5. if the reduced system is not empty, go to step 1. 
This is the Strategy Elimination Algorithm (SEA). Sometimes (SEA) 
obtains solutions of bilinear problems (11.12). The algorithm defines 
both the pure and the mixed strategies. Therefore, SEA may replace 
both the Direct Search Algorithm {11.8) and the linear programming 
one {11.25), (11.26),(11.27). 
3. 
MATRIX GAME 
In some special cases, the Inspector problem is reduced to the Matrix 
Game. It is well known (Owen, 1968) that equilibrium is defined as 

INSPECTION MODEL 
149 
two linear programming problems, if Vij = -UijÂ· One reduces utilities 
{11.1) and {11.2) to the zero-sum case by subtracting the penalty terms 
{1- Pi)qj9j and Qi9i from the inspectors utilities. In such a case 
u( i, j) = { Pi9iQi - {1 - Pi)Qj9j, if i = j 
-Qi9i, 
otherwise, 
(11.28) 
and 
( Â· .) 
_ 
{ -QjPi9i + {1 - Pi)Qj9j, if i = j 
V Z,J 
-
h 
. 
Qj9j, 
ot erw1se. 
(11.29) 
It follows form expressions {11.28) and {11.29) that Vij = -urj- Here 
one obtains the equilibrium by solving two linear programming problems 
(Owen, 1968) 
and 
m 
max U, 
X 
LXiUij ~ U, j = 1, ... ,m, 
i==l 
m 
L 
Xi = 1, Xi ~ 0, 
i==l 
U = Ut -
U2, Ut ~ 0, U2 ~ 0, 
m 
min V, 
y 
- LYiUij :<:; V, i = 1, ... ,m, 
j==l 
m 
LYi = 1, Yi ~ 0, 
i==l 
V = Vt -
V2, Vi ~ 0, V2 ~ 0. 
(11.30) 
{11.31) 
The important feature the zero-sum games is the mini-max condition 
min V=max U. 
y 
X 
(11.32) 

Chapter 12 
"DUEL" PROBLEM ' 
DIFFERENTIAL GAME MODEL 
1. 
INTRODUCTION 
In all three competition models, the Nash, the Walras, and the Inspec-
tor, the steady-state conditions were considered, for simplicity. In real 
life competition processes, dynamics are essential. Dynamical competi-
tion models may be represented as differential games. They are difficult 
for numerical and visual analysis, as usual (Friedman, 1971; Galperin 
and Zheng, 1991; Hajek, 1975; Isaacs, 1965; Krasovski, 1970; von Neu-
mann and Morgenstern, 1953; Petrosyan, 1985; Petrosyan, 1993; Rodin, 
1987). Therefore, one tries to make the dynamic competition models as 
simple as possible. 
Consider, as a simple illustration, two objects in space trying to de-
stroy each other. Assume, as a first approximation, that the control 
parameters are: initial points z0 , w0, "climbing" rates a, b and firing 
times t1, t 2 â¢ These parameters are set before the start for both objects. 
Denote the control parameters by vectors x = (xi, i = 1, 2, 3) andy= 
(yi, i = 1,2,3), correspondingly. Denote by (af,af) the lower bounds 
of these parameters. Denote by (bf, bf) the upper bounds. In the illus-
trative example x1 = zo, x2 = a, X3 = h, and Yl = wo, Y2 = b, Y3 = t2, 
where -1 ~ z0 ~ 1,-1 ~ wo ~ 1,-1 ~a~ 1,-1 ~ b ~ 1. Movements 
of the objects are described in two-dimensional "hight-time" space by 
the first-order differential equations 
dz(t)jdt = az(t), 
dw(-r)Jd-r = bw(-r), T = 2- t. 
151 
(12.1) 
(12.2) 

152 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
The solution of these equations defines trajectories of the objects 
z(t) = zoeat, 
w(T) = woebt_ 
(12.3) 
(12.4) 
As usual, models of moving objects use second-order differential equa-
tions, at least 
d2z(t)jdt2 + gz(t)jdt 
d2w(t)jdt2 + hdw(T)jdT 
az(t), 
bw(T), T=2-t. 
(12.5) 
(12.6) 
We apply first-order linear differential equations (12.1) and (12.2) as 
a first approximation to test algorithms of optimization and modeling. 
Denote by d(t) a distance between objects at the moment t 
d(t) = ll(w(t), T)- (z(t), t)llÂ· 
(12.7) 
Denote by p(t) the hitting probability 
p(t) = 1- (d(t)/ ny:.. 
(12.8) 
Here D 2: maxt d(t) and a> 0. The expected utility function of the first 
object 
{ 
u1p(x3)- u2(1- p(x3))p(y3), 
if X3 < y3, 
U(x, y) = 
-u2p(y3) + u1 (1- p(y3) )p(x3), 
if X3 > y3, (12.9) 
u1p(x3) - u2p(y3), 
if X3 = Y3, 
The expected utility function of the second object 
{ 
V1P(Y3)- v2(1- p(y3))p(x3), 
if X3 > y3, 
V(x, y) = 
-v2p(x3) + v1 {1- p(x3))p(y3), 
if X3 < y3,{12.10) 
v1p(y3) - V2p(x3), 
if X3 = Y3Â· 
Expressions (12.9) and (12.10) of expected utilities follows from expres-
sion (12.8) of hitting probabilities. It is assumed that utilities to hit the 
hostile object are plus u1 and v1. Utilities to be hit are minus u2 and v2. 
Here u 1 , u2 denote utilities of the first object and v1 , v2 define utilities 
of the second one. 
2. 
CONVEX VERSION 
Expected utilities {12.9) and {12.10) are not convex functions of vari-
ables p(x3) and p(y3). The convex version may be obtained assuming 

DIFFERENTIAL GAME 
153 
that the object destroys the enemy, if it is not hit itself. Suppose that 
u1 = u2 = v1 = v2 = 1. Then it follows from expressions (12.9) and 
(12.10) that the expected utility function of the first object 
{ 
p(x3) - (1- p(x3)), 
if X3 < y3, 
U(x, y) = 
-p(y3) + (1- p(y3)), if X3 > y3, 
p(x3) - p(y3), 
if X3 = Y3, 
(12.11) 
The expected utility function of the second object 
{ p(y3)- (1- p(y3)), 
if X3 > Y3, 
V(x, y) = 
-p(x3) + (1- p(x3)), if X3 < y3, 
p(y3) - p(x3), 
if X3 = Y3Â· 
{12.12) 
Expected utilities (12.9) and (12.10) are convex functions of probabilities 
p(xs) and p(y3) at the equilibrium point 
p(x3) = 0.5, 
p(ys) = 0.5. 
(12.13) 
The convexity of expected utilities (12.9) and (12.10) as functions of 
probabilities p(x3) and p(y3) does not provide their convexity as func-
tions of firing times X3 and Y3 and other parameters. The convexity is 
a part of sufficient equilibrium conditions. Therefore, the equilibrium 
may not exist. 
Expected utilities reach the maximal values at the ends of intervals of 
parameters zo, a, wo, b, as usual. For the first object there are four pure 
strategies corresponding to various arrangements of these ends 
(zo = Zmin, a= amin), (zo = Zmin' a= amax), (zo = Zmax, a= amin), 
(zo = Zmax, a = amax)Â· 
The pure strategies for the second object: 
(wo = Wmin, b = bmin), (wo = Wmin, b = bmax), (wo = Wmax, b = bmin), 
(wo = Wmax, b = bmax)Â· 
We may search for the pure equilibrium of bimatrix games (12.11 )(12.12) 
corresponding to each fixed pair (x3.y3 ) of firing times using simple dis-
crete algorithm (11.8). However, the probability to obtain the pure 
equilibrium is high only for large bimatrix games (Forgo et al., 1999). 
Therefore, we consider mixed strategies, first. 
3. 
MIXED STRATEGIES 
If expected utilities reach the maximal values at the ends of intervals of 
parameters zo, a, wo, b then mixed strategies could be helpful. The mixed 

154 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
strategies mean that each object chooses at random a combination of 
lower and upper bounds. Define those bounds as zero-ones for simplicity. 
There are four events: 
(zo = 0, a = 0), (zo = 0, a = 1), (zo = 1, a = 0), (zo = 1, a = 1). 
Probabilities of these events are defined by first four components 
x(1), ... , x(4), x(i) ;:::: 0, Et=l x(i) = 1 of a vector 
x = (x(i), i = 1, ... , 5) 1 â¢ 
The fifth component x(5) = t1 defines the firing time. A vector 
y = (y(j), j = 1, ... , 5) has a similar meaning for the second object. 
Applying mixed strategies x =(xi, i = 1, ... , 5) and 
y = (yj, j = 1, ... , 5), the utility functions of the first and the second 
objects are 
Ua(x, y) = L L x(r)u(r, s)y(s), 
(12.14) 
rERsES 
Va(x, y) = L L x(r)u(r, s)y(s). 
(12.15) 
rERsES 
Here R = {1,2,3,4}, S = {1,2,3,4}, where 1,2,3,4 denotes the four 
events (zo = 0, a = 0), (zo = 0, a = 1), (zo = 1, a = 0), (zo = 1, a = 1). 
The matrix 
u(r, s) = Ut1.t2 (r, s) 
(12.16) 
is the winning of the first object, if the pure strategy denoted by the 
quadruple (t1,t2,r,s) is used. The matrix 
{12.17) 
is the winning of the second object, if the pure strategy (t1, t 2 , r, s) is 
used. Expanding expressions (12.14) 
Ua(x, y) = x(1)u(1, 1)y(1) + x(2)u(2, 1)y(1) + 
x(3)u(3, 1)y(1) + x(4)u(4, 1)y(1) + 
x(1)u(1, 2)y(2) + x(2)u(2, 2)y(2) + 
x(3)u(3, 2)y(2) + x( 4)u( 4, 2)y(2) + 
x(1)u(1, 3)y(3) + x(2)u(2, 3)y(3) + 
1The variables x,y obtain different meanings, if one uses mixed strategies. That reduces the 
number of symbols. To avoid confusion, the utilities U,.(x, y), V,.(x, y) are supplied with the 
subscript a. If the subscript a is absent then x,y defines the parameters z0 ,wo,a,b,tt,t2. 
Otherwise, x, y denotes mixed strategies. 

DIFFERENTIAL GAME 
155 
x(3)u(3, 3)y(3) + x(4)u(4, 3)y(3) + 
x(1)u(1, 4)y(4) + x(2)u(2, 4)y(4) + 
x(3)u(3, 4)y(4) + x(4)u(4, 4)y(4). 
(12.18) 
Here winnings u(r, s) are defined by expression (12.16). 
Expression 
(12.15) illustrates how the function Ua(x, y) is defined. The function 
Va(x, y) is defined similarly. 
One defines bimatrix games (12.14) and (12.15) for each pair of firing 
times (t1, t2). Therefore, for fixed pair (h, t2), the same methods of 
search for the equilibrium points may be used as in the inspector model 
(11.8) and (11.13)- (11.17). Here winnings u(r, s) and v(r, s) depend on 
firing times t1, b 
This is the important difference from the inspector 
game. One updates bimatrix games while changing firing times. 
Therefore, there are only two parameters t 1 and t 2 to be found by 
the fraud minimization (see section 4.1). One can do that by applying 
methods, such as the Bayes, to search for the pair (tr, t2 ) that minimizes 
the fraud. 
4. 
SEARCH FOR EQUILIBRIUM 
4.1 
BIMATRIX GAME ALGORITHM 
Consider the bimatrix game (12.14) and (12.15) defined by fixing a 
pair (tr, t2 ) of firing times. We search for the equilibrium of this game 
using conditions (11.8) and (11.13)- (11.17). Here the matrix is small 
thus the proportion of pure strategy equilibrium points will not be con-
siderable (Forgo et al., 1999). Therefore we start by looking for such a 
mixed strategy that makes all the partner strategies equally profitable 
for him. That makes the partner fraud irrelevant. At fixed pair (t1, t2) 
a mixed strategy x(r) of the first object is "fraud irrelevant" if 
L x(r)v(r, s) = V, s E S, 
{12.19) 
rER L x(r) = 1, x(r) ~ 0. 
rER 
There are four linear inequalities, five linear equations and five variables: 
V, x(r), r E R, because the set R has four elements. 

156 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
A mixed strategy y(s) of the second object is fraud irrelevant if 
L u(r, s)y(s) = U, r E R, 
(12.20) 
s inS 
LY(s) = l.y(s) ~ 0. 
sES 
These expressions include inequalities what is usual in the linear pro-
gramming (LP). Applying LP, the variables U and V should be expesed 
as differences of two non-negative variables U = u1- u2 and V = v1- v2. 
Then from the expressions (12.19), (12.20) one obtains the LP problem: 
max ( u1 - u2 + v1 - v2) (12.21) 
x,y,u,v 
m L u( i, j)yj = u1 - u2, i = 1, ... , m, (12.22) 
j=l 
m L v( i, j)xi = v1 - v2, j = 1, ... , m, (12.23) 
i=l 
m 
LYj = 1, (12.24) 
j=l 
m L Xi = 1 (12.25) 
i=l 
Xi ~ 0, Yj ~ 0, i, j = 1, ... , m, U1 ~ 0, U2 ~ 0, V1 ~ 0, V2 ~ 0 .. (12.26) 
Herex=(xl, ... ,xm), y=(yl,Â·Â·Â·,Ym), u=(u1,u2), v=(v1,v2). 
Similar linear fraud irrelevant equations were considered in the in-
spection problem (see expressions (11.23) and (11.24) ). Here the fraud 
irrelevant equations (12.22) and (12.23) depend on two unknown param-
eters it and t2â¢ Therefore, linear problems (12.22) and (12.23) are just 
a part of general non-linear problem. We use longer notations, such as 
U = U(t1, t2) and V = V(it, t2), to show that U, V depend on t1, t2. 
If there is no solution of fraud irrelevant equations, we search for the 
pure equilibrium strategies using condition (11.8). The Strategy Elim-
ination Algorithm (SEA) is a good alternative to obtain equilibrium. 
A general but difficult way to find the equilibrium is to solve the bi-
linear problem (11.12) defining the necessary and sufficient equilibrium 
conditions. 
Obtaining equilibrium in mixed strategies x(r), y(s), r E R, s E S 
or in pure strategies r, s, one reduces the six-dimensional optimization 

DIFFERENTIAL GAME 
157 
problem to the two-dimensional one. 
min II z- Tt(z) 112 . 
zEB 
(12.27) 
Here z = (t~, tg), where (t~, tg) are the "contract" firing times. The 
operator Tt is defined by the fraud condition 
ti = arg max U(t1, tg), 
tl 
t~ = argmaxV(t~,t2). 
t2 
(12.28) 
Here U(t1, tg) is the expected winning of the first object. It is the so-
lution of the corresponding bimatrix game at fixed firing times t1 and 
tg. V(t~, t2) is the expected winning of the second object defined as the 
solution of the bimatrix game at given firing times t~ and t2. For ex-
ample, winnings U(it, tg) and V(t~, t2) can be defined by LP problems 
(12.22)(12.23), or by the Direct Search Algorithm (DSA) (see Section 
2.1), or by Strategy Elimination Algorithm (SEA) (see Section 2.4). 
The equilibrium is achieved, if the minimum (12.27) is zero. The 
minimization of (12.27) is the task for global optimization algorithms, 
including the Bayesian ones. 
4.2 
MATRIX GAME ALGORITHM 
The bimatrix game algorithm can be applied to both the symmetric 
and the non-symmetric cases. In the symmetric case the utilities satisfy 
the zero-sum game condition U = - V. Here one obtains the equilibrium 
by solving the following linear programming problems 
and 
m 
max U 
X 
LXiUij 2: U, j = 1, ... ,m, 
i=l 
m 
"'xÂ· = 1 xÂ· > 0 
L...Jz 
, 
z_ 
i=l 
U = Ul -
U2, Ul 2: 0, U2 2: 0, 
min V, 
y 
(12.29) 
(12.30) 

158 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
m 
- L YjUij ~ V, i = 1, ... , m, 
j=I 
m 
LYi = 1, Yi ~ 0 
i=I 
V =VI -
V2, VI ~ 0, V2 ~ 0. 
Here mini-max condition (Owen, 1968) 
min V =max U 
y 
X 
(12.31) 
holds for all firing times fi, t2. Therefore, a search for the equilibrium is 
reduced to the condition 
(12.32) 
The zero-sum equilibrium is reached when the hitting probabilities are 
equal to 0.5 for both players and their winnings are zero (see the one-
dimensional example in the next section). 
5. 
ONE-DIMENSIONAL EXAMPLE 
Applying expressions (12.1)-{12.10) in one-dimensional space the tra-
jectories are 
z(t) 
w(r) 
and the hitting probability is 
t, 
2 -T, 
p(t) = 1- d(t)jD. 
(12.33) 
(12.34) 
(12.35) 
Here D ~ maxt d(t). The control parameters are the firing times x = fi 
andy= t2. Assuming that D = 2 and applying expression {12.11), the 
expected utility function of the first object is 
{
X- (1- x), 
if X< y, 
U(x, y) = 
-~ + {1- y), 
~f x > y, 
X 
y, 
If X- y. 
(12.36) 
The expected utility function of the second object follows from expres-
sion (12.12) 
{ y- {1- y), 
if X> y, 
V(x,y) = 
-x+ {1-x), 
~fx < y, 
y- X, 
Ify =X, 
{12.37) 

DIFFERENTIAL GAME 
159 
The equilibrium is reached at the firing moment x = y = 0.5. The one-
dimensional example helps to understand and to test the results of the 
two-dimensional case. 
6. 
ECONOMIC DUEL. NASH MODEL 
By the "Economic Duel" we mean a dynamic case of the Nash model. 
In Chapter 9, the static case was described. 
There are m servers providing the same service 
where Ui is the profit, Yi is the service price, ai is the rate of customers, 
Xi is the running cost, and i is the server index 
Suppose that arriving customers estimate the average waiting time as 
the relation of the number of waiting customers ni to the server capacity 
Xi that is assumed to be equal to the running cost 
ri = ndxi 
A customer goes to the server i, if 
Ci::; Cj, j = 1, ... ,m, j =f i, Ci ~ C(). 
A customer goes away, if 
where c0 is the critical cost. The rate a of incoming consumers is fixed 
To illustrate general ideas of the dynamic Nash model, we simplify 
the static one, first. 
6.1 
SIMPLIFIED NASH MODEL. STATIC 
CASE 
We express the customer estimate of the expected waiting time as 
{12.38) 

160 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
Assume the customer balance condition. 
(12.39) 
Here q is the customer balance factor. The balance condition follows 
from (9.4),(9.5), (9.6), if the number of customers is large. The condition 
is based on the observation that arriving customers prefer servers with 
lesser sum Yi + 'YiÂ· From expression (9.7) 
q:.::; c. 
(12.40) 
From (12.39) 
(12.41) 
and 
(12.42) 
Consider a monopolistic situation when only the ith server is there. In 
this case 
ai =a, if q :<:; c 
(12.43) 
and 
Yi +a/xi:<:; c. 
(12.44) 
Othervise, customers abandon services ai = 0. The maximal monopo-
listic profit 
max(ayi- xi), 
Xi,Yi 
Yi +a/xi:<:; c. 
(12.45) 
(12.46) 
Replacing inequality (12.46) by equality, we eliminate (12.46) and max-
imize the expression 
maxy;(ayi- aj(c- yi)). 
{12.47) 
Now one defines the optimal service price 
Yi = c -1, 
{12.48) 
the optimal service capacity, 
xi= a, 
{12.49) 
and the maximal monopolistic profit 
ui = a(c- 2). 
{12.50) 

DIFFERENTIAL GAME 
161 
6.2 
DYNAMIC NASH MODEL 
In the previous section, considering the static model, it was tacitly 
assumed that a server can operate steadily while making loss instead of 
profit. Now we consider a case of insolvency, too. Suppose that a server 
gets broken, if the accumulated losses exceed some credit threshold. Here 
the bankrupt server is eliminated and the remaining one assumes a mo-
nopolistic position. 
Denote by Ui(t) a profit accumulated by the ith server at a time t. 
Assume that 
Ui(t) = 1t Ui(t)dt, 
to 
(12.51) 
where ui(t) defines a profit at a moment t 
Ui(t) = ai(t)yi(t) - Xi(t). 
(12.52) 
Here ai(t) is a rate of customers of the ith server at a moment t. This 
rate is formally defined as a limit of the fraction 
(12.53) 
where Ai(t) is a total number of customers arrived during an interval 
(0, t), t ~ T. The zero denotes the starting time of the system. Tis the 
end of the operation period, the "horizon". In real life Ai(t) is defined 
at fixed moments, for example, minutes, hours, days e. t.c.. We consider 
it as a continuous parameter because we consider a continuous model. 
Denote the bankruptcy threshold of an ith server by Ut. Denote a 
bankruptcy moment (if it happens) of the ith server by ti. Then 
Otherwise, customer 
condition (12.41) 2 . 
{ a, ift2:tj, t~ti,i,j=1,2, i-#j, 
0, 
ift~tj, t2:ti i,j=1,2, i-#j. 
rates ai(t) are defined by the customer 
From (12.50) the profit 
{ ui, 
0, 
if t 2: tj' t ~ ti' i, j = 1, 2, i -=1 j' 
ift ~ tj, t 2: ti i,j = 1,2, i -#j. 
(12.54) 
balance 
(12.55) 
2This means that the customer balance follows the changes of parameters Yi(t) and xi(t) 
almost without delay. 

162 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
Otherwise, the profit Ui(t) is defined by (12.52). 
Assume that both servers are planning their dynamic competition in 
advance. Each server i defines trajectories of the service price Yi(t) and 
the service capacity Xi(t). These trajectories show how the service prices 
and capacities depend on the timet E (0, T). Objectives are to maximize 
profits 
(12.56) 
Here Ui(T) defines the accumulated profit (12.51) of ith server at the 
end of period t = T. 
We illustrate the idea by a simple example. Assume that servers con-
trol initial values Yi(O), Xi(O) and rates of change by;, bx; of parameters 
Yi(t) Xi(t). Then the trajectories are defined by differential equations 
(12.57) 
and 
dxi(t)jdt = bx;Xi(t). 
(12.58) 
The corresponding solutions are 
Yi(t) = yi(O) exp(by;Yi(t)), 
(12.59) 
and 
(12.60) 
SEARCH FOR NASH EQUILIBRIUM 
The search is similar to that in the Nash model (see Section 9). We 
fix the the initial values, the "Contract-Vector" 
z0 = 
(xi(0) 0 ,b~;,Yi(0) 0 ,bg;, i = 1, ... ,m). The transformed values, the 
"Fraud-Vector" 
z 1 = (xi(0) 1 , b~;, Yi(O)l, b~;' i = 1, 2), is obtained by maximizing the 
profits of each server i. The maximization is performed assuming that 
all partners j =f. i honors the contract 
(xi(0) 0 ,b~.,Yi(0) 0 ,by0 , j = 1,2 j i- i) 
J 
J 
(xi(0) 1 , b~;' Yi(O), b~J = 
arg 
max 
Ui(Xi(O), bx;, Yi (0), by;, Xj(0) 0 , b~., Yi(0) 0 , b~ , 
x;(O),bx; ,y;(O),by; 
1 
1 
j = 1, 2 j f i), i = 1, 2.(12.61) 

DIFFERENTIAL GAME 
163 
Here the symbol Ui denotes the accumulated profit (12.56). Formally, 
condition (12.61) transforms the vector 
zn = ((xi(o)n, b~;' Yi(o)n, b~i' i = 1, 2) E B C R 8 , n = 0, 1, 2, ... into the 
vector zn+ 1. To make expressions shorter denote this transformation by 
T 
zn+l = T(zn), n = 0, 1, 2, ... 
One may obtain the equilibrium at the fixed point zn, where 
zn = T(zn). 
{12.62) 
{12.63) 
The fixed point zn exists, if the feasible set B is convex and all the profit 
functions (9.1) are convex (Michael, 1976). We obtain the equilibrium 
directly by iterations {12.62) , if the transformation Tis contracting. If 
not, then we minimize the square deviation 
min II z- T(z) 11 2 . 
zEB 
The equilibrium is achieved, if the minimum (12.64) is zero. 
{12.64) 
One makes the model more flexible by introducing second derivatives 
of parameters Yi(t) and Xi(t). The second derivatives represent acceler-
ations. Assume that servers control the starting values Yi{O), Xi(O), the 
rates by;, bx; and accelerations 9yp 9x; of parameters Yi(t) Xi(t). Then 
trajectories are defined by differential equations 
d?yi(t)j dt2 = 9y;dYi(t)j dt + by;Yi(t), 
(12.65) 
and 
{12.66) 
Here the vector zn has twelve components. 
zn = (xi(o)n,b~;'9~;,Yi(o)n,b~;'9;; i = 1,2) E B c R 12 , n = 0,1,2, ... 
That means high dimension of the fraud minimization problem {12.64). 
In addition, one needs to test the convexity of accumulated profits Ui 
defined by expressions {12.56) as functions of parameters 
Xi(O), bx;â¢ Yi(O), by;, i = 1, 2. If they are convex then one obtains equilib-
rium by condition (12.64). Otherwise, some specific algorithms should 
be designed. An example is the inspector problem. 
7. 
SOFTWARE EXAMPLE 
An interactive duel model is implemented using Java JDK1.2 {Mat-
ulevicius, 1999). To run the Java applet go to web-sites (see section 4.), 

164 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
start GM J2 and select the task DuelStarwars (see Figure 8.6). 
The task window, in Figure 12.1, shows the domain of firing times 
0 :s: tl :s: 1, 0 :s: t2 :s: 1. 
Min 
~f.ault 
t.W. 
H~tÂ·Â·:d â¢I'J<'fllhl!ll b1 â¢:I oS HÂ·:<I..S 
)o;19nt1-: ~mor,tat!Vn b':' I' :Â·:â¢sta; GÂ·)'bo .s~'s 
;--alt 11 :.d;sta< _G1equo~:lt:om 
Figure 12.1. 
The duel task window. 
One selects the optimization method from the Methods menu (see 
Figure 8.7). The method Bayes is selected (see Figure 12.2). The total 
number of iterations is set to forty. The number of initial iterations is 
set to five. 
The optimization results are in Figure 12.3. 
To start the analysis of results one touches the Analysis button (see 
Figure 8.9). 

DIFFERENTIAL GAME 
165 
Appl~t 
rMethod Tsk}O'Per tion j 
Property 
App I et s't<~ol"'ted. 
40 
5 
t 
ho 
n 
Method algonthms by Jonas ~1ockus 
Desrgn&lmplementat1on by Modestas Grybauskas 
e-mail Modestas_G@equmoxlt com 
Figure 12.2. 
The Bayes method selection. 
The Convergence mode shows how the deviation from the equilibrium 
depends on the iteration number (see Figure 12.4). 
7.1 
OPERATING DUEL 
The duel starts by selecting DuelStarwars mode in the Analysis 
menu (see Figure 8.8). 

166 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
Applet 
Method "Task toperation 
un 
--------------------------~ 
~alue 
.69 
0. ZÂ«) 
0 748 
Method algonthms by Jonas ~. 1ockus 
Desrgn& Implementation by Modestas Gr{bauskas 
e-ma11 Modestas_G@equrnoxlt com 
I 
Applet started. 
Figure 12. 3. 
The results. 
To run duel press the Start button (see Figure 12.5). 
One selects the operation mode in the operation window (see Figure 
12.6). There are three operation modes: 
â¢ Person vs Person, 
â¢ Person vs Computer, 
â¢ Computer vs Computer. 

f(x) 
0 
-1 
-2 
-3 
-4 
-5 
-6 
-7 
-8 
0 
! 
5 
DIFFERENTIAL GAME 
167 
l 
~ 
I 
I 
I 
' 
10 
15 
20 
25 
30 
Iteration 
Figure 12.4. 
The convergence window. 
Figure 12.6 shows the Computer vs Computer mode. The 
Current situation field shows parameters z0 , w0 , a, b generated at ran-
dom using probabilities defined by equilibrium conditions. The firing 
times t1, t2 are decided by these conditions, directly. 
In the Person vs Computer game the person fix parameters zo, a, t1 
of the first object. A window to fix them is in the center of the top 
Figure 12.7. 

168 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
OemoAnalyzer 
Warnlr g: A plet Window 
'STAR WARS' 
differential game model 
Method algoritm by J 0 AS 1\.Â·1 0 KUS 
De ign & lmpl mentation by RAI 1U DAS MATUlEVICIUS 
Vytauta Magnu UnivetÂ· ita 
tart I 
I ntro I 
Figure 12.5. 
The starting window. 
Probabilities of parameters w0 , b of the second object and its fir-
ing time t2 are defined by equilibrium conditions (12.24),(12.23), and 
(12.27). Parameters wo, b of the second object, and the actual hitting, 
are defined by probabilities. Therefore, the outcome is random. 
Figure 12.8 shows the input of the Person vs Person game. In this 
game parameters of both objects are fixed by persons using the input 
window. The outcome of this game is shown in a form similar to the 
Person vs Computer game (see the bottom Figure 12.7). 
One sets the speed of moving objects in the Speed window (see Figure-
dueloutl). 
Figures 12.10 show help windows. 

DIFFERENTIAL GAME 
169 
~T R AR - dofl.,~nll I 0 mâ¢ mod~l 
0 
1.0 
bO- 0.0 
Current situation 
111 
1.0 
w0 
l.G 
RED 
BLUE 
Figure 12.6. 
The operation window in the Computer vs Computer game. 
7.2 
FUTURE DEVELOPMENÂ·TS 
In the example, one searches for equilibrium in mixed strategies using 
the Irrelevant Fraud Algorithm (IFA) which is described in section 2.3. 
This algorithm solves linear programming problems (12.22) and {12.23). 
If no solution is found, one searches for pure equilibrium strategies using 
the Direct Search Algorithm {DSA) {11.8). The Strategy Elimination 
Algorithm {SEA) (see section 2.3) helps, if both IFA and DSA fail. 
A general but difficult way is to use the necessary and sufficient equi-
librium conditions given as bilinear problem {11.12). This is a future 
task. The main future task is to implement flexible economic models. 
Another task is the implementation of second-order models. These tasks 
need additional theoretical investigations and software developments. 
Creation of entertaining graphical interfaces is important, too. 

170 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
-
-
-
-
-
-
..-;--
Figure 12. 7. The input (top) and the outcome (bottom) of the Person vs Computer 
game. 

DIFFERENTIAL GAME 
171 
Â· ~ 
r1. 
No Name 
' 
Warning: Applet Window 
ao = 
[ o. 11 
bu = 
0.4 
zo = 
0.14 
\Â¥0 = 
0.2~ 
>--Â· 
t1 -
0.24 
tL = 
0.33 
I 
Â·----
---Â· 
l 
Â·-
Figure 12.8. 
The input of the Person vs Person game. 
Enter the speed of obje ts 
1200 
: 
----~--'"' 
II 
Ok 
I Â·! Cancel 
Figure 12.9. 
The speed control window. 

172 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
o~am 
Obj cts coordinations and parameters: 
Fir I obJect: zo -lnltl htlgth. ao -Initial control parameter,tl- shooting time. 
econd object. wo - initial heigth, bo- initial control parameter, t2 - shooting time. 
All parameters Initials Intervals are [0 .. 1] 
Game pecific: 
vou can specify the fight of tht objects by their control parameters In three ways: 
1. Vou can choo e both object coordination . ('Per on â¢ Per on') 
2. You can choo e fir t objtct coordinations and computer will generate econd object 
coordinations by chance ('Per on 'S Computer') 
3. oth object coordination are generated by chance. ('Computer ~ Computer') 
'Game' menu command 
Game/ tart - tart e ecution of the duel. 
GiM'ne/ efresh - refresh positions of the objects in the 1lndow 
Game/Cio e - end of the Demo An vzer and do e the window. 
Game/tart - starts e. ecutlon of the duel. 
Game/Refre h- refre h po ltlon of the object In the 1lndow 
Game/ lo e - end of the Demo Analyzer and do e the window. 
'Option ' menu command 
Option /Current ituation. - di pia information about ob!'ect parameters. 
Options/Speed of objects - sets the speed of objects. The nterval is [10(1.1000] 
Option /Per on~ Person -allow to the u er to enter per on 
person simulation 
parameter. 
Options/Person vs Computer - allows to the user to enter person s computer imulation 
parameter. 
Option /Computer \1 Computer- set coordinate of imulation computer~ computer. 
'Help' m nu command 
Help/ tar war problem- e planation of the star wars problem. 
Help/Game control... 
help of the game. 
Help/ eplay Info 
- replay demon tration of the beginning. 
Help/About 
- hort information about the authers of the program. 
Figure 12.1 0. 
The help pages. 

Chapter 13 
"PORTFOLIO" PROBLEM, 
OPTIMAL INVESTMENT OF RESOURCES 
1. 
INTRODUCTION 
The previous examples illustrated competition and inspection pro-
cesses in economical, social and ecological problems. Here the optimal 
investment of available resources is considered. Investment problems de-
pend on the nature of resources to be invested. An important part of 
any investment problem is a proper definition of utility functions that 
determine the profit-to-risk relation. Here we consider an illustrative 
example how to invest some fixed capital in Certificates of Deposit (CD) 
and Stocks. 
The portfolio problem is to maximize the average utility of a wealth. 
That is obtained by optimal distribution of available capital between dif-
ferent objects with uncertain parameters (Mockus et al., 1997). Denote 
by Xi the part of the capital invested into an object i. The returned 
wealth is Yi = CiXiÂ· Here Ci = 1 + ai and ai > 0 is an interest rate. 
Denote by Pi = 1 - qi the reliability of investment. Here qi is the in-
solvency probability. u(y) is the utility the wealth y. Denote by U(x) 
the expected utility function. U(x) depends on the capital distribution 
x = (xi, ... , Xn), Li = 1, Xi ~ 0. If y is continuous, the expected utility 
function 
U(x) = Eu(y) = fooo u(y)p(y)dy. 
173 
{13.1) 

174 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
Here p(y) is probability density of wealth y. If the wealth is discrete 
y = yk, k = 1, ... , M, the expected utility function 
M 
U(x) = L u(yk)p(yk). 
(13.2) 
k=l 
Here M is the number of discrete values of wealth yk. Px (yk) is the 
probability that the wealth yk will be returned, if the capital distribution 
is x. We search for such capital distribution x which provides the greatest 
expected utility of the returned wealth: 
max U(x), 
X 
(13.3) 
n LXi = 1, 
(13.4) 
i=l 
2. 
EXPECTED UTILITY 
One may define probabilities p(yi) of discrete values of wealth yi, j = 
1, 2, .... by exact expressions. For example, 
Pl II Qi, 
#1 
P2 II Qi, 
i# 
Pn II Qi, 
#n 
P1P2 II Qi, 
i#,i# 
P1P3 II Qi 
i#,iof3 
Then from expression (13.5) 
M 
U(x) = L u(yk)p(yk). 
k=l 
HereM is the number of different values of wealthy. 
(13.5) 
(13.6) 

INVESTMENT PROBLEM 
175 
One determines U(x) approximately by the Monte Carlo approach: 
Here 
where 
K 
UK(x) = 1/K L u(yk). 
k 
-
Yi 
-
k=l 
n 
yk = LYf, 
i=l 
if 'Tif E [0, Pi] 
otherwise. 
(13.7) 
(13.8) 
(13.9) 
Here K is the number of Monte Carlo samples. 'Tif is a random number 
uniformly distributed on the unit interval. In this case 
U(x) = lim UK(x). 
K-HXl 
(13.10) 
3. 
OPTIMAL PORTFOLIO, SPECIAL CASES 
The optimal portfolio depends on the utility function u(y). Consider, 
for example, the optimal portfolio for three different utility functions. 
The first utility function is linear 
u(y) = cy. 
(13.11) 
This function is for "rich" persons. Rich persons want to maximize the 
average wealth. They are not emotional about accidental losses or gains. 
In the linear case {13.11), the optimal portfolio is to invest all the capital 
in an object with the highest product PiCiÂ· 
The second utility function is for "prudent" persons which averse risk 
( ) = { 0, 
if 0 ~ y < a 
u y 
1, 
if a~ y ~ c, Â· 
{13.12) 
Here a is a risk threshold. c = maxi CiXi denotes the maximal return of 
invested capital (see expression (13.4)). If a= 1/m mini CiXi then, in the 
risk-averse case {13.12), an optimal decision is xi = 1/m, i = 1, ... , m. 
Here one divides the capital equally between all the objects1. 
1The optimal decision x = 1/m is not unique, any decision satisfying the inequality C;Xi 2:: 
a, i = l, ... ,m minimizes the expected utility function U(y). 

176 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
The third utility function is for "risky" persons. Risky persons are 
ready to risk for the great win c. 
u(y) = { ~: if 0 ~ y < c, 
if y =c. 
(13.13) 
Here one invests all the capital in the object with highest wealth return. 
Therefore, Xi = 1, if Ci = maxj Cj =c. 
These examples are abstract. An average person behaves "risky," if 
only a small part of his resources is involved. The same person behaves 
prudently, if all his wealth is at stake. There is a point r between areas 
of risky and prudent behavior. At this point an average person behaves 
like the "rich" one. Here is an example 
u(y) < y, if 0 ~ y < r, 
u(y) = y, if y = r, 
u(y) > y, if r < y ~c. 
Here r is a boundary point between risky and prudent areas. 
4. 
UTILITY FUNCTIONS 
(13.14) 
Utility functions u(y) are different for different persons and organiza-
tions. An individual utility function is defined by a lottery 
L(A, B,p) = {pA + (1- p)B}. Here pis the probability to win the best 
event A. 
( 1-p) is the probability to get the worst one B. Denote by C the "ticket 
price" of this lottery. There are two possible decisions: 
â¢ keep the ticket money C, 
â¢ bay a ticket and risk losing this money while hoping to win a greater 
wealth A with probability p. 
Denote by p(C) a "hesitation" probability, when one cannot decide 
which decision to prefer. One defines the "hesitation" probability p( C) 
by this condition 
L(A,B, C,p(C)) = [C ~ {p(C)A + (1- p(C))B}]. 
(13.15) 
Here the symbol ~ denotes the "hesitation." If utilities u(A) = 1 and 
u(B) = 0, the utility of the "ticket" Cis equal to the hesitation proba-
bility u(C) = p(C) (Fishburn, 1964). 

INVESTMENT PROBLEM 
177 
Suppose, for example, that event C is to keep all the investment cap-
ital, y = 1, in a safe; no risk, no profit. Assume that the event A means 
doubling the capital, y = 2. The event B means losing all the capital, 
y=O. 
Denote by p(1) the hesitation probability. Then 
u(1) = u(O) +p(1)(u(2) -u(O)). If u(O) = 0 and u(2) = 1 then the utility 
of the capital u(1) = p(1). Here one obtained capital utilities at three 
points: y = 0, y = 1, andy= 2. 
To define a reasonable approximation of the utility function u(y), 
we need at least two additional points. For example, points y = 0.5 
and y = 1.5. One defines the corresponding utilities by the hesitation 
probabilities p(0.5) and p(1.5). These are obtained by two hesitation 
lotteries 
and 
L(l.O, 0.0, 0.5,p(0.5)) = 
[(y = 0.5) ~ {p(0.5)(y = 1) + (1- p(0.5))(y = 0)}] 
L(2.0, 1.0, 1.5,p(1.5)) = 
[(y = 1.0) ~ {p(1.5)(y = 2.0) + (1- p(1.5))(y = 1)}]. 
Here one obtains utility values 
(13.16) 
(13.17) 
u(O) = 0, u(0.5) = p(0.5), u(1) = p(1), u(1.5) = u(1) + p(1.5)(u(2) -
u(1)) u(2) = 1. The remaining capital utility values are defined by the 
linear interpolation 
u(y) = u(yi) + p(yi)(u(yi+I)- u(yi)), Yi:::; Y < Yi+l, 
i = 0, 1, ... ,4. 
(13.18) 
In consulting offices, the "psychological tests" defining capital utilities 
are not always convenient. Then one of the four "typical" utility func-
tions can be selected. The typical utility functions represent the risky, 
the average, the rich and the prudent persons. The selection depends on 
observable personal traits. 
The same capital utility function (13.14) could be used for all cus-
tomers. Then one defines customer differences by different border points, 
namely: 
Tprudent < Taverage < Trich < Trisky (see Figure 13.2). 

178 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
5. 
SOFTWARE EXAMPLE 
5.1 
RUNNING THE PROGRAM 
The software (Petrikis and Juodgalvyte, 1997) is on the web-site (see 
Section 4.) and is run by Internet 
1. open the line 'GMJ1' on the 'Software systems' page (see Figure 3.1), 
2. start the applet, 
3. open the 'Methods' menu, choose the method and its parameters (see 
Figure 13.1), 
4. open the 'Tasks' menu, chose the task 'Portfolio', 
5. select the character : prudent, rich, risky, average (see Figure 13.2), 
6. select the method: Monte Carlo, Deterministic (see Figure 13.2), 
7. fix the predicted stock rates by updating or keeping the default values 
determined using ARMA model (see Figure 13.2), 
8. click at the 'Operation' label at the top of page, 
9. click at the 'Run' button at the bottom of page, 
10. read results of the optimal investment, where 'Iteration' means the 
number of iterations to reach the optimal investment, 'F(x)' shows 
the expected utility with the minus sign, the following lines show the 
relative investments2 (see Figure 13.3), 
11. open the 'convergence' window (see Figure 13.4) which show how the 
best utility depends on the iteration number, 
12. open the 'projection' window (see Figure 13.5) showing how the util-
ity depends on the first variable, 
13. open the 'spectrum' window showing how a frequency of utilities 
depends on the iteration number3. 
The example of predicted stock rate of Vilnius Bankas is presented in 
the file 'onestep?VB.txt'. 
2The actual investment is the product of the total investment and the relative investment, 
divided by the sum of all the relative investments. 
3Different frequencies are is denoted by different colors. 

INVESTMENT PROBLEM 
179 
G MJ G Applet, Collection of Methods and Tasks 
Iterations 
I1 00 
Initial points 
Is 
Figure 13.1. 
The control window. 
GMJG Applet, Collection of Methods and Tasks 
~th~~~O~o~er~a~ti~on~\~----------------------------
SeiE 
Select Character; 0 -Prudent. 1 -Risky, 2 -Rich, 3 -Average 
Select Method: 1 -Monte Carlo, 2- Deterministic 
Vllnlaus Bankas, Shares 
Hermls Bankas, Shares 
:o.9937243~ 
Lith uan tan Savings Ban (L TB). Shares 
I0.7468632C 
lithuan1an Agricul ure Bank CLZUB). Shares 
!0.0970994~ 
Figure 13.2. 
The input fields. 
5.2 
A SET OF UTILITY FUNCTIONS 
Nine approximation points are used: yk[i] = 0.25 * i, i = 0, ... , 8. Four 
utility functions are available. They differ at the approximation points. 
They represent different persons. 

180 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
G 
I ration 
F(x) 
Viln 
s B n 
â¢ CO 
nor s B n . s. CO 
H rmls B n s. CO 
u lo Bankas, CO 
Figure 13.3. 
The output field. 
-o.731 
0.7 
0.2 
0.7 
0.7:J 
0.25 
0.75 
prudent person : /[0] = 0.0, f[l] = 0.3, f[2] = 0.5, f[3] = 0.7, f[4] = 
0.8, ![5] = 0.85, f[6] = 0.9, ![7] = 0.95, ![8] = 1.0, 
risky person : f[O] = 0.0, /[1] = 0.1, j[2] = 0.2, f[3] = 0.25, /[4] = 
0.3, ![5] = 0.4, ![6] = 0.7, ![7] = 0.9, ![8] = 1.0, 
rich person : f[O] = 0.0, f[l] = 0.125, f[2] = 0.25, f[3] = 0.325, f[4] = 
0.5, ![5] = 0.625, ![6] = 0.75, ![7] = 0.875, ![8] = 1.0, 
average person j[O] = 0.0, ![1] = 0.1, ![2] = 0.2, f[3] = 0.25, f[4] = 
0.5, ![5] = 0.7, ![6] = 0.85, ![7] = 0.95, ![8] = 1.0. 
Users select one of them. 
5.3 
PREDICTING INVESTMENT RESULTS 
Two investment possibilities are considered: Certificates of Deposit 
(CD) and shares. Considering CD, the two parameters should be fixed: 
the interest and the reliability (bank's survival probability). These pa-
rameters are defined in the file Portjolio.java. Considering shares, only 

INVESTMENT PROBLEM 
181 
-0.4 
-o.s 
-o.& 
I 
I 
-o.a , 
--
I --
I 
0 
1 
2 
3 
4 
Java Applet Window 
Figure 13.4, 
The convergence window. 
one parameter is used, the predicted stock rate at the time of CD ma-
turity. That is correct, if the investor is confident4 about the predicted 
stock rates at the maturity time. The default values of expected changes 
of stock rates are zero. The predicted stock rates are given in the files 
like this one: onestep?V B .txt. 
Input file = VB.txt 
Pradzia = 26.000000 Prognoze = 30.297932 </BODY></HTML> 
Here 'VB' denotes the Vilnius Bank stock rates. 'Pradzia' denotes the 
rates now. 'Prognoze' denotes the predicted rates. The difference be-
tween predicted and present stock rates, divided by the present stock 
rate and expressed in percents, is considered as a "stock interest." That 
is an important simplification. However, it helps to consider both shares 
and CD in the same way. That is convenient for calculations. 
4Without the "confidence" assumption one should consider stock rates predictions errors, 
too. 

182 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
f( ) 
-0.1 -
-0.2 -
-0Â·3 -
-0.4 -
1-Â·-Â· 
-0.5 -
-0.6 ..., Â·-
Â·-
--
0 
I 
0 - !.o-
I 
0 
I 
0 
I 
t 
1 
T 
I 
I 
I 
t 
-0.7-
-0.8 , 
o.o 
o.t 
o.2 
o.3 
o.4 
o.s 
o.6 
o.? 
o.a 
o.(J 
x 
Vi In iaus Ban kas, CD 
~~~------~---~~~-~~~--~~-
J Java Applet Window 
Figure 13.5. 
The projection window. 
Predicted rates in VB .txt files are obtained by the ARMA model using 
the Vilnius Bank data. The predicted values can be changed manually 
by clicking and writing on the corresponding fields of the 'Tasks' page. 
5.4 
DATA 
The stock rates of the following major Lithuanian joint-stock compa-
nies, including the banks, are considered. 
Bank "Vilniaus Bankas" : data file VB.txt, 
Bank "Snoras" : data file Snoras. txt, 
Bank "Hermis" : data file Hermis.txt, 
Savings bank "LTB" : data file LTB.txt, 
Agricultural bank "LZUB" : data file LZUB.txt, 
Bank "Siauliu Bankas" : data file Siauliu.txt, 

INVESTMENT PROBLEM 
183 
Economic bank "Ukio Banka.s" data file Ukio.txt, 
Dairy "Rokiskio Suris" : data file Rokiskio.txt, 
Brewery "Kalnapilis" data file Kalnapilis.txt, 
Dairy "Birzu Pienas" : data file BirzuAB.txt. 
The first record of the data files5 shows closing rates on January 01, 
1998. The last record defines closing rates on November 14, 1998. Two 
hundred twenty nine sessions of Lithuanian stock exchange are recorded 
in the data. Using this data ARMA model makes ninty day predictions 
what corresponds to three month CD. 
5.5 
RESULTS 
Optimization results are in Tables 13.1, 13.2, and 13.3. Tables 13.1 
and 13.2 both are for a prudent person. Table 13.1 is obtained by 
the Monte Carlo method. Table 13.2 shows results of the determin-
istic method. Table 13.3 is obtained by the deterministic method for a 
risky person. 
The "Optimal investment" column is just a copy of the output field 
(see Figure 13.3). The output field represents optimal values of internal 
variables. The internal variables are proportional to the optimal parts 
of the capital. Actual optimal parts are obtained by normalization 6 and 
are shown in the "Optimal part" column. 
Tables 13.1 and 13.2 show that the optimal distribution of capital 
obtained by the approximate method differ from that defined by the 
exact one. This is important disadvantage of the approximate Monte 
Carlo method. Note, that the best values of utility functions are close 
for both methods. They are 0. 773, for the Monte Carlo method, and 
0. 776, for the deterministic one. This means that the optimal values of 
utility functions are not very sensitive to moderate changes in the capital 
distribution. The reason is that here investment alternatives are not too 
different. 
5The data file is on the web-sites (see Section 4.). 
6Users make the normalization in this software version. 

184 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
Company 
Optimal investment 
Optimal part 
Vilniaus Bankas, CD 
0.157 
0.0251 
Snoras, CD 
0.354 
0.0566 
Hermis, CD 
0.402 
0.0643 
Litimpex, CD 
0.724 
0,1159 
Ukio Bankas, CD 
0.334 
0.0535 
Siauliu Bankas, CD 
0.842 
0.1348 
Medicinos Bankas, CD 
0.096 
0.0153 
State bonds 
0.318 
0.0509 
Vilniaus Bankas, shares 
0.626 
0.1002 
Snoras, shares 
0.677 
0.1083 
Hermis, shares 
0.293 
0.0469 
Ukio Bankas, shares 
0.466 
0.0746 
Siauliu Bankas, shares 
0.461 
0.0738 
Rokiskio Suris, shares 
0.108 
0.0169 
Birzu Pienas, shares 
0.061 
0.0097 
Ka.lnapilis, shares 
0.146 
0.02337 
Table 13.1. 
Monte Carlo method. Prudent person. Optimal portfolio obtained after 
892 iterations. The utility is 0.773. 
Comparing Table 13.2 representing the prudent person and Table 13.3 
representing the risky one, we see differences. The best value of utility 
function is equal to 0.776, for the "prudent." It is equal to 0.291, for 
the "risky." This difference is explained by assumptions made to nor-
malize utility functions. The normalization assumes that the maximal 
utility is a unit and the minimal one is zero. Therefore, the best value 
of utility function of the risky person happens to be less then that of the 
prudent one. However, lower utilities does not mean that risky persons 
are getting less satisfaction. One needs more sophisticated normaliza-
tion techniques to compare correctly the satisfaction scales of different 
persons by their utility functions. 
5.6 
FUTURE DEVELOPMENTS 
The first step is to drop the "confidence" assumption that one predicts 
the stock rates exactly. To do this, the variance of the predicted stock 
rates should be included into the updated Portfolio Model. 
The important future task is the sensibility analysis. For example, 
by considering three scenarios: pessimistic, optimistic and realistic. In 

INVESTMENT PROBLEM 
185 
Company 
Optimal investment 
Optimal part 
Vilniaus Bankas, CD 
0.699 
0.0755 
Snoras, CD 
0.453 
0.0489 
Hermis, CD 
0.836 
0.904 
Litimpex, CD 
0.795 
0,0859 
Ukio Bankas, CD 
0.366 
0.0395 
Siauliu Bankas, CD 
0.783 
0.0846 
Medicinos Bankas, CD 
0.926 
0.1001 
State bonds 
0.589 
0.0636 
Vilniaus Bankas, shares 
0.937 
0.1001 
Snoras, shares 
0.361 
0.0390 
Hermis, shares 
0.343 
0.0370 
Ukio Bankas, shares 
0.002 
0.0002 
Siauliu Bankas, shares 
0.944 
0.1020 
Rokiskio Suris, shares 
0.760 
0.0822 
Birzu Pienas, shares 
0.07 
0.00075 
Kalnapilis, shares 
0.052 
0.0056 
Table 19.2. 
Exact o method. Prudent person. Optimal portfolio obtained after 892 
iterations. The utility is 0.776. 
the pessimistic scenario lower probabilities Pi for CD's and lower interest 
rates for stocks are considered. In the optimistic case one sets higher val-
ues for these parameters. The realistic case is in the middle. Important 
task is to represent visually the "stability" of securities 7â¢ If the optimal 
values of some securities are not too different in all three scenarios, they 
are considered as stable. 
7 CD and Stocks. 

186 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
Company 
Optimal investment 
Optimal part 
Vilniaus Bankas, CD 
0.907 
0.107 
Snoras, CD 
0.083 
0.0098 
Hermis, CD 
0.857 
0.101 
Litimpex, CD 
0.438 
0,0517 
Ukio Bankas, CD 
0.024 
0.00283 
Siauliu Bankas, CD 
0.737 
0.0870 
Medicinos Bankas, CD 
0.739 
0.872 
State bonds 
0.656 
0.0774 
Vilniaus Bankas, shares 
0.762 
0.0899 
Snoras, shares 
0.179 
0.0211 
Hermis, shares 
0.894 
0.1055 
Ukio Bankas, shares 
0.451 
0.0532 
Siauliu Bankas, shares 
0.098 
0.011 
Rokiskio Suris, shares 
0.946 
0.112 
Birzu Pienas, shares 
0.019 
0.00224 
Kalnapilis, shares 
0.076 
0.0089 
Table 13.9. 
Exact method. Risky person. Optimal investment obtained after 159 
iterations. The utility is 0.291. 

Chapter 14 
EXCHANGE RATE PREDICTION, 
TIME SERIES MODEL 
1. 
INTRODUCTION 
Solutions of optimal investment problems, considered in the previ-
ous chapter, depend on predicted stock rates. Predictions are needed 
considering most of the investment problems, because the result of an 
investment depends on future values of various parameters. Predictions 
are an important part of scheduling problems, too. The optimal sched-
ules depend on the predicted demand, and supply. Time series models 
are common prediction tools. Here we investigate a well-known time 
series model. The so called, Auto Regressive Moving Average {ARMA) 
model. We briefly consider the Artificial Neural Network {ANN) and 
the Bilinear models, too. 
Mainly, the financial data is predicted. The prediction of call rates, us-
ing the same models, are briefly mentioned, just for comparison. The call 
rate prediction is described in detail considering call center optimization 
problems in Chapter 15. There the traditional ARMA is supplemented 
by an expert model. 
Modeling economic and financial time series by ARMA has attracted 
the attention of many researchers in recent years {Diebold and Rude-
busch, 1989; Cheung, 1993; Yin-Wong and Lai., 1993; Cheung and Lai, 
1993; Koop et al., 1994; Mockus and Soofi, 1995). Three approaches 
have been used to estimate the parameters of the ARMA models, : Max-
imum Likelihood (ML) (Sowel, 1992), approximate ML (Li and McLeod, 
187 

188 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
1986; Fox and Taqqu, 1986; Hosking, 1981; Hosking, 1984), and two-step 
procedures (Geweke and Porter-Hudak, 1983; Janacek, 1982). In all the 
cases local optimization techniques were applied. Here the optimization 
results depend on the initial values, what implies that one cannot be 
sure if the global maximum is found. 
The global optimization is very difficult in many cases1. The reason 
is a high complexity of multi-modal optimization problems. It is well 
known (Ko, 1991) that optimization of polynomial-time computable real 
functions cannot be done in polynomial-time, unless P = N P 2 . 
In 
practice, this means that we need an algorithm of exponential time to 
obtain the E-exact solution. The number of operations in exponential 
algorithms grows exponentially with the accuracy m of solution and 
dimension n of the optimization problem. The accuracy m means that 
E :::; 2-m. The dimension n means that one optimizes a function f(x) 
where x = (x1, ... , Xn)Â· 
The Least Squares (LS) method is a popular approach to estimate 
parameters of ARMA models. Using LS one minimizes the log-sum of 
square residuals using ARMA models and their extensions (Mockus and 
Soofi, 1995). In this chapter, the multi-modality problems are considered 
using different data. The data include: 
daily exchange rates of $j Â£ and DM/$ , 
closing rates of stocks of AT&T, Intel Co, and some Lithuanian banks, 
the London stock exchange index (Raudys and Mockus, 1999), 
call-rates of a commercial call-center. 
The graphical images and comparison of the average prediction results 
of ARMA and the Random Walk (RW) models are presented. 
1 By the term 'difficult' we mean the time measure of computational complexity, that is, the 
length of time would be needed for a standard universal computer to do a task. 
2The notation P = NP means the existence a polynomial-time algorithm P for solving 
N ?-complete problems. That is merely a theoretical possibility. 

EXCHANGE RATE PREDICTION 
189 
2. 
AUTO REGRESSIVE MOVING-AVERAGE 
MODELS {ARMA) 
2.1 
DEFINITIONS 
We define ARMA model as 
p 
q 
Wt = L aiWt-i + L biEt-i + EtÂ· 
{14.1) 
i=l 
i=l 
We assume that 
Zt-i = 0, Wt-i = 0, f.t-i = 0, if t :S: i. 
{14.2) 
2.2 
DEFINITION OF RESIDUALS 
An advantage of residual minimization is that one may see directly 
how the objective depends on unknown parameters. Using equalities 
{14.1) we define residuals by recurrent expressions 
{14.3) 
(14.4) 
Next the sum 
T 
f (X) = log f m (X), f m (X) = L EF 
(14.5) 
t=l 
is minimized. The logarithm is there to decrease the objective variation 
by improving the scales. 
3. 
MINIMIZATION OF RESIDUALS OF 
ARMA MODELS 
Here we consider an algorithm for optimization of parameters of the 
ARMA model. This model is simple and may be considered as a good 
first approximation. Denote by Yt the value of y at the time t. Denote 

190 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
by a= (a1, ... ,aq) a vector of auto-regression (AR) parameters, and by 
b = {b1, â¢.. , bq) a vector of moving-average {MA) parameters. 
p 
q 
Yt- L aiYt-i = ft- L bjft-j, t = 1, ... , T. 
{14.6) 
The residual 
or 
Here 
and 
i=1 
j=1 
p 
q 
ft = Yt- L aiYt-i + L bjft-j, 
i=1 
j=1 
p 
ft = Bt + L aiAt(i). 
i=1 
q 
Bt = Yt + L bjBt-j-1, 
j=1 
q 
At(i) = -Yt-i-1 + L bjAt-j-1, 
j=1 
where t - i > 0 and t - j > 0. 
(14.7) 
(14.8) 
(14.9) 
{14.10) 
3.1 
OPTIMIZATION OF AR PARAMETERS 
Denote 
T 
S(a,b) = LE2 , 
t=1 
{14.11) 
where a= (a1, ... , ap) and b = (b1, ... , bq)Â· From expressions (14.11) and 
{14.8) the minimum condition is 
as(a,b) 
2~ A(") o . 
1 
a . = 
L 
ft t J = , J = , ... , p, 
a:J 
t=1 
{14.12) 
or 
p L A(i,j)ai = -B(j), j = 1, ... ,p. 
{14.13) 
i=1 

EXCHANGE RATE PREDICTION 
191 
Here 
T 
A(i,j) = LAt(i)At(j), 
(14.14) 
t=l 
and 
T 
B(j) = L At(j)Bt. 
(14.15) 
t=l 
The minimum of expression (14.11) at fixed parameters b is defined by 
the system of linear equations 
(14.16) 
Here matrix A= (A(i,j), i,j = 1, ... p). Vector B = (B(j), j = 1, ... p), 
where elements A(i,j) are from (14.14), components B(j) are from 
{14.15), and A- 1 is an inverse matrix A. This way one define the vector 
a(b) = (ai(b), i = 1, ... ,p) that minimize sum (14.11) at fixed parameters 
b. 
3.2 
OPTIMIZATION OF MA PARAMETERS 
The sum of squared residuals (14.11) is a non-linear non-convex func-
tion of parameters b. Thus, we have to consider the global optimization 
algorithms. Denote 
f(x) =log S(a(x), x). 
(14.17) 
Here x = band S(a, b) is from (14.11) at optimal parameter a = a(b). 
Denote 
b0 = x 0 = argminf(x). 
X 
(14.18) 
3.3 
PREDICTING "NEXT-DAY" RATE 
Predicting "Next-Day" Rate, one minimizes the expected "next-day" 
squared deviation ft+l using the data available at the moment t 
Here 
o 
Â· E 2 
Yt+l = argmm 
ft+lÂ· 
Yt+l 
p 
Et:~+l = E {Bt+l + LAt+l(i)ai(b0 ))2 , 
i=l 
(14.19) 
(14.20) 

192 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
where the optimal parameter b0 was obtained using the data available 
at the day t. Variance (14.20) is minimal, if 
p 
Y~+l = Bt+l + LAt+I(i)ai(b0), 
(14.21) 
i=l 
because the expectation of Yt+I is Bt+l + L:f=1 At+I(i)ai(b0 ) under the 
assumptions. 
3.4 
EVALUATION OF ARMA PREDICTION 
ERRORS 
We compare the "next-day" ARMA prediction results and a simple 
Random Walk (RW) model. In RW model the next day value is Yt+l = 
Yt + t:t+I and the predicted value is equal to the conditional expectation 
of Yt+l = YtÂ· This means that the present value is the RW prediction 
for the next day. There are three reasons to consider RW models 
â¢ simplicity of RW, 
â¢ RW is a trivial case of ARMA where q = 0, p = 1, and a 1 = 1, 
â¢ RW represents unpredictable time series, because random numbers 
t:t+l are independent. 
Therefore, the difference of average prediction errors of ARMA and RW 
models can be regarded as some parameter of" ARMA-unpredictability" 
of the data. That means that if this difference is zero or negative, then 
the time series are not predictable by the ARMA model. Table 14.1 
shows the difference between the mean square deviations of ARMA and 
RW models. The table uses four data sets 
â¢ exchange rates ofDMj$, $jÂ£, Yenj$, and Frj$, 
â¢ closing rates of AT&T, Intel Co., and Hermis Bank stocks , 
â¢ index of the London Stock Exchange, 
â¢ call rates of a call center. 
In Table 14.1, the symbol M eanARM A denotes average prediction er-
rors of ARMA model. The symbol V ar Arma means the variance of 

EXCHANGE RATE PREDICTION 
193 
Table 14.1. 
The average "next-day" prediction results of ARMA and RW models. 
Data 
DeltaARMA% 
MeanARMA 
VarARMA 
$fÂ£) 
- 1. 779090e-01 
1. 293609e+OO 
8.454827e-02 
DMf$ 
- 1.191e-02 
1.092e-Ol 
9.985e-02 
Yen/$ 
- 1.086e+OO 
6.369e+00 
6.446505e+OO 
Frf$ 
- 3.029e-Ol 
4.285e-01 
3.395e-Ol 
AT&T 
-1.375e+OO 
4.554e+OO 
3.621e+00 
Intel Co 
+2.814e-01 
2.052e+Ol 
1.936e+OO 
Hermis Bank 
-4.280e+Ol 
2.374e+Ol 
1.998e+Ol 
London Stock Exchange 
-5.107e-01 
2.751e+02 
2.346e+Ol 
Call Center 
+3.076e+Ol 
8.453e+02 
7.llle+02 
ARMA predictions. The symbol DeltaARM A% denotes the relation 
(RW -ARM A)/ RW in percentages. Herte RW defines average errors 
of the Random Walk. DeltaARM A% > 0 means that the ARMA model 
predicts better. 
The data is divided into three equal parts. 
The first part is to estimate parameters a and b of an ARMA model 
using fixed numbers p and q. 
The best values of p and q are defined using the second part of data. 
The third part is to compare ARMA and RW models. The table shows 
the comparison results. 
Table 14.1 shows that the ARMA model predicts all the financial 
data not better than RW. However, ARMA predicts call rates thirty one 
percent better then RW. That is a statistically significant difference. 
The observed deviations between RW and ARMA models of financial 
data are too small for practical conclusions. Figure 14.1 shows optimal 
parameters band a. Here the optimal q = 1 and p = 12. The "multi-
day" predictions of call rates are shown in Figure 14.2. 
4. 
EXTERNAL FACTORS 
Often we have to predict one main factor that depends on some ex-
ternal factors. This means that we are not interested in future values of 
external factors while predicting the main one. For example, we predict 
the stock rate as the main factor depending on the GNP as the external 

194 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
b[O] = -2.888616e-01 
a[O] 
9.131314e+02 
a[1] 
4.565372e-02 
a[2] 
3.765721e+02 
a[3] = 1.129722e-01 
a[4] 
2.993138e+02 
a[5] 
3.935438e-02 
a[6] 
1.109620e+02 
a[7] 
2.491347e-02 
a[8] 
3.427414e+01 
a[9] 
-1.073026e-01 
a[10] 
-1.432491e+03 
a[11] = 8.030343e-01 
Figure 14.1. 
The optimal parameters of the ARMA model predicting call rates. 
15000.-------.-------.-------.-------.-------,------, 
10000 
5000 
0 
-5000 
-10000 
'call.rate.actual' -
'call.rate.min' ----Â· 
'call.rate.mean' .... .. 
'call.rate.max' .......... . 
----- -Â·Â· Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·-Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\J\_,~.Â·.Â·Â·Â·Â·Â·Â·Â·Â·-Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â· ----- ------
--
-- -- _,-â¢ 
Â·------.. _ .... _.-Â·Â·-' 
', .. ..,\ 
.. -
\I I \ '"\ 
,,,~ 
\./ 
-15000 L__ ______ ..__ ______ ..__ ______ -'----------'----------'---------' 
240 
260 
280 
300 
320 
340 
days 
Figure 14-2. 
Multi-day predictions of call rates. 
factor. We consider the cases when future values of all the factors are 

EXCHANGE RATE PREDICTION 
195 
not known. Considering the cases when future values of external factors 
are known3 the model should be modified accordingly. 
Different symbols are used in ARMA models with external factors. 
The predicted value is denoted by v(t) and the external factors are ry(t) = 
( 'f/1 ( t), 1)2 ( t), ... ) . An influence of some external factors may be delayed. 
For illustration, consider two-dimensional case, omitting the Moving 
Average (MA) part. This means the two-dimensional Auto Regressive 
(AR) model with an external factor ry(t) 
p 
v(t) = l:)aliv(t- i) + a2irJ(t- d- i)) + E(t), p + d < t < To.(14.22) 
i 
Here dis the delay parameter. First we minimize the squared deviation 
Lt E(t) 2 at fixed delay d and then chose the optimal delay d. The mini-
mum of a sum {14.22), as a function of parameters a, is defined by the 
system of linear equations. These are obtained from the condition that 
all the partial derivatives are zero 
To-1 
p 
L 
(v(t)- L(aiw(t- i) + a2irJ(t- d- i))v(t- i) 
t=p+d+l 
i 
= 0, i = 1, ... ,p. {14.23) 
To-1 
p 
L (v(t)- L(aiw(t- i) + a2irJ(t- d- i))ry(t- d- i) 
t=p+d+l 
i 
= 0, i = 1, ... ,p. (14.24) 
We have to solve 2p linear equations with 2p variables ali, a2i, i = 1, ... , p 
and obtain the least squares estimates a1i(d), a2i(d), i = 1, ... ,pat given 
d. 
Sum (14.25), as a function of delay parameter d, is not necessarily 
uni-modal one. Thus to define the exact minimum 
p 
v(t) = L(ali(d)v(t- i) + a2i(d)ry(t- d- i)) + E(t), 
(14.25) 
p+d < t <To. 
3For example, while predicting call rates we know in advance such "external" factors as 
holidays, vacation times, e.t.c. 

196 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
One should consider all the K (d) values of the integer d. Here K (d) is 
the number of "interesting" values of d. Therefore, expression (14.25) is 
an example of multi-modal function in AR models. We mentioned the 
delay time just to show a way how to include this important factor into 
a time series model. Later the delay factor is omitted, to simplify the 
expressions. 
4.1 
MISSING DATA 
Suppose that predicting v(t) we don't know some previous values 
v( s), s < t . Then we replace the missing data by the expected value 
v(s) defined as 
p 
v(s) = ~)aliv(s- i) + a2i1J(s- i)), p < t <To. 
(14.26) 
The least squares estimates of the regression parameters a 1i, a2i are 
obtained using observations before the missing one and minimizing ex-
pression (14.22). The same idea can be extended, if two or more values 
of the factor v are missing. 
This algorithm is to "fill" the missing data only for the predicted 
factor v. We replace missing values of the external factor 1J by the 
nearest previous value, because we do not predict the external factors in 
this model. 
5. 
APPLYING ARMA TO EXTERNAL 
FACTORS 
Omitting the delay din expression (14.22) we write 
p 
v(t) = ~)a1w(t- i) + a2irJ(t- i)) + E(t), p < t <To. 
(14.27) 
Including this expression into the ARMA model (14.6) one obtains the 
following expression 
p 
v(t) = ~)aliv(t- i) + a2irJ(t- i)) + 
i 
q L biEt-i + Et, p < t < To. 
i=l 
(14.28) 

EXCHANGE RATE PREDICTION 
197 
Extending expression (14.28) toM external factors 
M 
p 
wM(t) = L Laflwm(t- i) + 
m=l i 
q 
LbiEt-i + Et, p < t <To. 
i=l 
(14.29) 
In expression (14.29), the predicted and the external factors are denoted 
by the same letter w with different upper indices. All the factors are 
represented as one-dimensional time series of the special type 
M 
P 
w(Mt) = L LaMi-(M-m)w(M(t- i)- (M- m)) + 
m=l i 
q 
L biEM(t-i) + EMt, p < t < To. 
(14.30) 
i=l 
Here aMi-(M-m) = ar, w(M(t -i)- (M- m)) = wm(t), m = 1, ... ,M 
and the index mi = m * i. Using this expression one applies the software 
developed for the one-dimensional ARMA model to M external factors. 
The data file should correspond to the expression (14.30). 
6. 
ARTIFICIAL NEURAL NETWORKS 
MODELS (ANN) 
With respect to the Moving Average parameters b, the ARMA model 
is non-linear (see expression (14.29)). With respect to data, this model 
is linear. If we are interested in the non-linearities, then we may apply 
many other non-linear models, including the ones that are non-linear 
with respect to data. In this book, we discuss two of them. Here the 
ANN model will be considered. In the next chapter, we introduce a 
bilinear term into the ARMA model. 
6.1 
INVOLVING AUTO REGRESSION {AR) 
INTO ANN 
We apply ANN by involving the non-linear activation functionÂ¢ into 
the standard Auto-Regression (AR) model 
p 
Wt = Â¢(L aiWt-i) + Et. 
(14.31) 
i=l 

198 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
The idea lurking behind ANN-AR model is that the activation function 
Â¢ roughly represents the activation of a real neuron. We minimize the 
sum 
T 
fm(x) = LEFÂ· 
{14.32) 
t=l 
Here the objective fm(x) depends on l unknown parameters given as a 
[-dimensional vector x = (xk, k = 1, ... ,p) = (ai, i = 1, ... ,p). 
One see from expression {14.31) that residuals Et are non-linear func-
tions of parameters at4. This means that the minimum conditions 
8fm(x) 
. 
8 
= o, z = 1, ... , P 
ai 
{14.33) 
is a system of non-linear equations with multiple solutions. 
An interesting activation function is derived using the Gaussian dis-
tribution function 
(14.34) 
Here Wt(l) = :Ei=l aiWt-iÂ· {3 is a scale parameter. The function {14.34) is 
different from the activation of a real neuron5 but is convenient for anal-
ysis. Here sum {14.31) depends on the parameters {3, O", J.l., too. These 
parameters are unknown, as usual. Therefore, they should be optimized. 
Therefore, the objective fm(x) depends on p + 3 unknown parameters 
represented as a p + 3-dimensional vector x = (xk, k = 1, ... ,p + 3) = 
(ai,i = 1, ... ,p,{3,CT,f..l.). That is the main difference of model {14.34) 
from the traditional ANN models. 
In the traditional ANN models the activation functions are selected by 
their resemblance to the natural ones from biophysical experimentation. 
In this research the resemblance factor is neglected. The activation 
function {14.34) is considered just as a reasonable non-linearity that 
should be adapted to the available data. The multi-modality problems 
of ANN models are discussed in {Mockus et al., 1997). 
4This is true, if the activation function <Pis non-linear. The linear activation function reduces 
the ANN model to the standard Auto Regressive (AR)n model. 
5The output of the traditional activation function is supposed to be non-negative. 

EXCHANGE RATE PREDICTION 
199 
7. 
BILINEAR MODELS {BL) 
It is well known that for the adequate description of some phenomena 
additional non-linear terms of the time series should be included. A 
simple example is a bilinear term (see (Rao and Gabr, 1984; Liu, 1989) ). 
Here bilinear time series extend the ARMA model: 
p 
q 
s 
r 
Wt = L aiWt-i + L biEt-i + L L CijZt-iEt-j + EtÂ· 
(14.35) 
i=l 
i=l 
i=l j=l 
An illustrative example is in (Mockus et al., 1997). 
8. 
AUTO REGRESSIVE FRACTIONALLY 
INTEGRATED 
MOVING AVERAGE MODELS {ARFIMA) 
8.1 
DEFINITIONS 
ARMA, ANN, and BL models consider stationary time series. The 
stationarity of a model is a simplification of reality. A well-known source 
of non-stationary behavior is the linear component, the trend. One elim-
inates the trend by differentiation, since derivatives of linear functions 
are constant. The elegant extension of this idea is the Auto Regressive 
Fractionally Integrated Moving Average model (ARFIMA). 
We define an ARFIMA 6 process as the following time series Zt 7 
Here 
and 
p 
A(L)wt = Wt- LaiWt-i 
i=l 
q 
B(L)Et = ft- L biEt-i, 
i=l 
60ften the alternative title ARIMA(p,d,q) is used. 
(14.36) 
(14.37) 
(14.38) 
7Note that, contrary to the traditional practice, we do not assume the time series to be 
stationary. We allow the degree of integration of the series to be detected by direct estimate 
of the differentiation parameter d. 

200 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
where Et =Gaussian {0, a 2}. We define the transformation {1- L)d as 
follows: 
Here 
00 
Wt = {1- L)dzt = Zt- LdiZt-iÂ· 
i=1 
r(i- d) 
di = r(i + 1)r( -d)' 
{14.39) 
{14.40) 
where dis a fractional integration parameter, and r(.) is a gamma fnnc-
tion. We assume that 
Zt-i = 0, Wt-i = 0, Et-i = 0, if t ~ i. 
{14.41) 
We truncate sequence {14.39) 
di = 0, if i > R. 
{14.42) 
Here R is the trnncation parameter, the number of non-zero components. 
8.2 
MINIMIZATION OF RESIDUALS 
We define residuals by recurrent expressions: 
{14.43) 
Et 
Wt- a1Wt-1- Â·Â·Â·- apWt-p + b1Et-1 + Â·Â·Â· + bqEt-qÂ· 
{14.44) 
Next, the sum 
T 
f(x) = logfm(x), fm(x) = L E~ 
{14.45) 
t=1 
is minimized. 
The logarithm is used to decrease the objective variation by improv-
ing the scales. The objective fm(x) depends on m = p + q + 1 nn-
known parameters. They are represented as an m-dimensional vector 
x = (xk, k = 1, ... , m) = (ai, i = 1, ... ,p, bj,j = 1, ... , q, d). 

EXCHANGE RATE PREDICTION 
201 
It follows from (14.44), (14.39), and (14.37) that residuals Et are linear 
functions of the parameters at. This means that the minimum conditions 
8fm(x) 
. 
0 
=0, z=1, ... ,p 
aÂ· 
t 
(14.46) 
are given by a system of linear equations. They estimate linear param-
eters ai = ai ( b, d) as a function of non-linear ones bi, i = 1, ... , q, d. It 
reduces the number of parameters of non-linear optimization to n = q+ 1. 
The system 
8fm(x) 
. 
obi 
= o, z = 1, ... , q 
(14.47) 
may have a multiple solution, because the residuals Et depend on bi as 
polynomials of degree T - 1. 
The equation 
8fm(x) = O 
ad 
(14.48) 
may have multiple solutions, too, because the residuals depend on d as 
a polynomial of degree R, where R is a truncation parameter. 
The objective fm(x) is a multi modal function of parameters d and 
bi, i = 1, ... , q 8 . Therefore, one uses methods of global optimization (see, 
(Mockus et al., 1997)). Denote 
Here 
f(x) = logfq+l(x). 
/q+l(x) = fm(x), Xj = bj,j = 1, ... , q, Xj+l = d, 
Xj+l+i = ai(b, d), i = 1, ... ,p. 
(14.49) 
This means that condition (14.46) defines those x- components that 
represent parameters ai, i = 1, ... ,p. 
There is no variance a 2 in expressions (14.49) and (14.44). If neces-
sary, we have to estimate the variance by another well-known technique. 
8The same reasoning applies to the log-likelihood function, too. 

202 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
8.3 
DISCUSSIONS 
Table 14.2 shows results obtained using the ARFIMA model (Mockus 
et al., 1997). Parameters band d were estimated using daily exchange 
rates of $j Â£,and DM/$, and closing rates of AT&T and Intel Co shares. 
Table 14.2 shows that d's are very close to zero (see also Figures 14.3). 
Table 14.2. 
Estimated parameters b and d of ARFIMA models. 
Data 
bo 
bl 
d 
minlogf(x) 
$(Â£ 
-1.195 
-0.169 
0.0005 
1.51675 
DMf$ 
-1.019 
0.0120 
0.0007 
1.60065 
AT&T 
-1.017 
0.0118 
0.00005 
9.83208 
Intel Co 
0.9975 
0.0055 
0.012 
7.35681 
An exeption is Intel Co shares. 

EXCHANGE RATE PREDICTION 
203 
1.75 .----..... -----.,----....-----,-----.----~ 
relation on d -
1.7 
1.65 
1.6 
1.55 
1.5 
-0.1 
0 
0.1 
0.2 
0.3 
0.4 
0.5 
7.38 
relation on d -
7.37 
7.36 
7.35 
7.34 
7.33 
7.32 
7.31 
7.3 
7.29 
0 
0.1 
0.2 
0.3 
0.4 
0.5 
Figure 14.3. 
Log-sum (14.45) as a function of the parameter d E [-0.01, 0.5]. Top 
figure shows $/Â£ exchange rates. Bottom one shows Intel Co stocks closing rates. 
Hence, following the traditional approaches {Cheung, 1993; Yin-Wong 
and Lai., 1993; Cheung and Lai, 1993) one concludes that the underlying 

204 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
stochastic processes generating exchange rates do not exhibit persistence 
and are stationary. That contradicts the visual impression of the corre-
sponding data (see Figures 14.4 and 14.10). 
This apparent contradiction may be resolved by dropping the assump-
tion that the parameters a, b, d of the ARFIMA model remain constant. 
This assumption is common for most of the traditional methods. An 
alternative is the structural stabilization model described in Chapter 
10 .. 
9. 
MULTI-STEP PREDICTIONS 
Often one wants to predict for several days (hours, weeks, months, 
e.t.c) ahead. This is the Multi-Step Predictions (MSP). One can do 
that by using a Monte Carlo simulation. The residuals Et (see expression 
(14.44)) are determined up to the simulation starting moment t(s) using 
the observed data. The rest of residuals Et, t;::::: t(s) are generated by a 
Gaussian distribution with zero mean and variance a 2 . The simulation 
is repeated K times. Considering external factors one just replaces them 
by the nearest previous values (see Section 4.1). 
The illustration is in Figure 14.2. The line call.rate.actual shows the 
observed call rate. Lines 
call.rate.min, call.rate.mean, and call.rate.max show the minimal, the 
average, and the maximal results of MSP predictions. The "min" and 
"max" lines denote the lower and the upper values of simulation. There-
fore, these lines are called "MSP- confidence intervals," meaning that if 
the model is true, one may expect those "intervals" to cover the real 
data with some "MSP-confidence level" a(MSP). 
It is difficult to define a(MSP) exactly. If "interval deviations" may 
be considered as independent and uniformly distributed random vari-
ables, we obtain a(MSP) = 1- K. Here K is the number of Monte-
Carlo repetitions. In the example, K = 10, thus a(MSP) = 0.9. 
This assumption over-simplifies the statistical model. Therefore, the 
"MSP-confidence level" a(MSP) is just a Monte Carlo approximation. 

10. 
10.1 
EXCHANGE RATE PREDICTION 
205 
STRUCTURAL STABILIZATION 
STABILIZATION OF STRUCTURES OF 
TIME SERIES 
The traditional time series models assume that their parameters do 
not change. Examples are parameters a, b of the ARMA model, param-
eters a, b, d of the ARFIMA model, parameters a, b, c of the BL model, 
and parameters a, {3, a, f..t of the ANN model. Natural changes of econom-
ical conditions introduce a variability of parameters of models describing 
the financial data, such as stock rates or currency exchange rates. The 
variability remains in the stable economical conditions, too. The rea-
son is the "Feed-Back" processes. It is well known that the stock rate 
predictions may influence the supply and demand and consequently the 
future rates. In such cases the statistical best fit models should be com-
plemented by the game-theoretical equilibrium models. There is the 
possibility that the equilibrium model would be namely the Wiener pro-
cess. That means that market rates in economics are governed by models 
similar to the Brownian motion. In such a case market rates would be 
as unpredictable as movements of individual molecules in gases. This 
is a working hypothesis supported by available data. Table 14.1 shows 
that the predictions of the financial data by the simple Wiener process, 
called as the Random Walk {RW) model, are as good as that of the 
sophisticated ARMA models. 
The objective of traditional time series models is to define such pa-
rameters that minimize a deviation from the available data. One may 
call them as the best fit models. The goodness of fit is described by 
continuous parameters C called as state variables. For example, in the 
ARMA model (see expression {14.1)) the state variables are 
C = (ai, i = 1, ... ,p, bj, j = 1, ... ,q). 
If the parameters remain constant, then models that fit best to the 
past data will predict the future data as well. Otherwise, the best fit to 
the past data can be irrelevant or even harmful for predictions. There-
fore, one needs models which are not sensitive to the changes of parame-
ters. Such models may predict the uncertain future better by eliminating 
the nuisance parts from the structure of the model. 
Trying to solve this problem, one introduces a notion of the model 
structure. The model structure is determined by the Boolean parame-

206 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
ters S called as structural variables. A structural variable is equal to 
unit, if the corresponding component of time series model is included. 
Otherwise, the structural variable is equal to zero. 
For example, in the ARMA model S = (sf, i = 1, ... ,p, s~, j = 
1, ... , q). Here sf = 1, if the parameter ai is included into the ARMA 
model. Otherwise, s1 = 0 9 â¢ We search for such structure S of the model 
that minimizes the prediction errors in the changing environment. To 
achieve this we divide available data W = (wt, t = 1, ... , T) into two 
parts Wo = (wt, t = 1, .... To) and W1 = (wt t =To+ 1, ... , T). 
The first part Wo is to estimate continuous parameters C = C(S) 
that depends on Boolean structural parameters S. The estimates are 
obtained for a set of all feasible S by minimizing the least square devi-
ation using data Wo. 
The second part W1 is used to select such S that minimize the least 
square deviation. This means that the second part W1 is to estimate 
Boolean structural parameters. 
Denote by Rt(S, C, W) the predicted value of a model R with fixed 
parameters S, C using the data (w1, ... , Wt-d c W. The difference be-
tween the prediction and the actual data Wt is denoted by Et(S, C, W) = 
Wt- Rt(S, C, W). Denote by Co(S) the fitting parameters C which min-
imize the sum of squared deviations ~o,o( C, S) using the first data set 
Wo at fixed structure parameters S. 
To 
~o,o(C, S) = L EF(S, C, W), 
t=l 
Co(S) = argmjn~o,o(C, S). 
(14.50) 
(14.51) 
We stabilize the structure S by minimizing the sum of squared deviations 
~l,o(S) using the second data set W1 and the fitting parameters C0(S) 
that were obtained from the first data set 
T 
~l,o(S) = L 
EF(S, Co(S), W), 
(14.52) 
t=To+l 
81 = argmJn~l,o(S). 
(14.53) 
9 N ote that describing a real data one needs diverse structures including a number of different 
models, not just one specific model as in this illustrative example. 

EXCHANGE RATE PREDICTION 
207 
This is a way to reach a tradeoff between the fitting parameters and the 
structural ones. The fitting parameters C0(S) provide the best fit to the 
first data set Wo at fixed structure S. One stabilizes the structure S 
by minimizing the prediction errors for the second set of data W1 using 
the fitting parameters C0(S). Here stabilization is achieved because the 
fitting parameters are defined by the first set of data W0 â¢ The stabilized 
structure S = 81 of R is obtained by eliminating unstable10 parameters 
and parts of the time series. 
We consider two data sets Wo and W1 just for simplicity. One may 
partition the data W into many data subsets Wt E Wk, t E Tk, k = 
1, ... , K, UkWk = W, UkTk = T. In this case we minimize the sum 
SK = argmina(S), 
s 
(14.54) 
where 
a(s) = L: ak,z(S). 
(14.55) 
k,l 
Here 
ak,z(S) = L E~(S, Cz(S), W). 
(14.56) 
tETr. 
Note, that dividing the data W into many parts one may obtain se-
quences Tk too short for the meaningful estimate of parameters Ck, if T 
is not large. If T is large, one may expect that most of the fitting param-
eters Ck would be different in different data subsets Wk. Thus, they will 
be eliminated by the stabilization procedure {14.54). Therefore, K = 2 
seems a reasonable number, at the first stabilization attempt. One may 
try K > 2 later. 
The idea of the structural stabilization follows from the following ob-
servation. The best estimate of time series parameters, using a part Wo 
of the data W = Wo U W1, is optimal for another part W1 only if all 
the parameters remain the same. Otherwise, one may obtain a better 
estimate by elimination of the changing parameters from the model. For 
example, in the case of changing parameters (ai, i = 2, ... ,p, bj, j = 
1, ... , q) of the ARMA model, the best prediction is obtained by elimina-
tion of all these parameters, except a 1 = 1 (see Table 14.1). 
10The parameters are considered as unstable if they change too much in different data sets. 

208 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
10.2 
SIMPLE EXAMPLE 
Consider, for illustration, a simple example. 
(14.57) 
The observed values are w1 = -1, W2 = w 3 = 1, w4 = 2, w5 = 1. 
The first data set Wo = Wi, ... , W4 is to estimate continuous parameters 
C = (a1, a2). The second data set W1 = w5 is to estimate Boolean 
parameters 8 = (sy, s~), s~ = 0, 1. Equality to zeros~= 0 suggests the 
elimination of the continuous parameter ai. There are three feasible 8, 
namely 81 = (0, 1), 82 = (1, 0), 83 = (1, 1) 11 â¢ 
Assume that unknown parameters depend on t this way 
{ 
2, 
if t = 3, 
Ut(t) = 
1, ift=4, 
0, ift = 5, 
a2(t) = 1, 
E(t) = 0. 
(14.58) 
In the case 8 = 83, the least square estimates are a1 (83) = 1.5 and 
a2(83) = 0.5. The prediction is w5(83) = 3.5. 
If 8 = 8 1 , the least squares estimate of the only remaining parameter is 
a2(81) = 0.5. The prediction is w5(8t) = 0.5. 
In the case 8 = 82 , the least square estimate is a 1 (82) = 1.5 and the 
prediction is w5(82) = 3.0. 
The best prediction w5(8t) = 0.5 is provided by the structure 81 = 
(0, 1). The reason is obvious: this structure eliminates the highly unsta-
ble parameter a1. Applying the structural stabilization one eliminates 
the nuisance parameter a1(t) and simplifies AR model (14.57) 
Wt = a2(t)Wt-2 + ft, t = 3, 4, 5. 
(14.59) 
Note, that we eliminate the larger parameter a1 (at (82) = 1.5 > a2(82) = 
0.5) because it changes (see expression {14.58)). 
11The elimination of both continuous parameters a1 and a2 is unfeasible. 

10.3 
EXCHANGE RATE PREDICTION 
209 
EXAMPLES OF STRUCTURAL 
OPTIMIZATION WITH 
EXTERNAL FACTORS 
Various examples of structural optimization are described in {Mockus, 
1997). Here the structural optimization is considered in time series mod-
els with external factors. 
If predictions depend on several factors, the multi-dimensional ARMA 
should be used. Denote by v(Mt), t ~ pfM the main statistical compo-
nent and by v(Mt- i), i = 1, .. ,p -1 the external factors. One extends 
the traditional ARMA model this way 
p-1 
q-1 
v(Mt) = L aw(Mt- i- 1) + L bjE(M(t- j- 1)) + E{Mt),{14.60) 
i=O 
j=O 
pfM~t~TO 
Here the number of the Auto Regressive (AR) components is denoted by 
p and the number of the Moving Average (MA) ones is denoted by q. The 
continuous variables a and b define the state of the ARMA model. We 
call them the state variables. The discrete parameters p, q, and tO define 
the structure. One calls them the structural variables. The structural 
variable tO defines the time when one starts scanning the time series for 
the optimization of state variables a, b. Denote by TO the scanning end. 
One minimizes the squared deviation at fixed structural variables 
p,q,tO 
TO 
.6.oo{p, q, tO) = L E(Mt)2 , tO~ pfM. 
{14.61) 
t=tO 
Here TO < T1 < T and E(Mt)2 is from expression {14.60). Denote the 
optimal values a = a(p, q, tO) and b = b(p, q, tO). 
If b is fixed, the optimal values of a = ab are defined by a system 
of linear equations. These equations follows from the condition that 
all the partial derivatives of sum {14.60) are equal to zero 8.6.00/ oai = 
0, i = 0, ... , p -
1. Therefore, to obtain the least squares estimates 
ai =a~, i = 0, ... ,p- 1 at given bone solves p linear equations with p 
variables ai, i = 0, ... ,p- 1 (see Chapter 3. for details). 
To optimize discrete structural variables p, q, tO one uses another data 
set. It starts at TO and ends at Tl. During optimization of structural 

210 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
variables one keeps the best fitting values of state variables a = a(p, b, tO) 
and b = b(p, q, tO). These values are obtained by minimization of the sum 
~o1 (p, q, tO). The data is from tO to TO. Here the sum 
Tl 
~ot(p,q,tO) = L E(Mt)2 â¢ 
t=TO 
(14.62) 
11. 
EXAMPLES OF SQUARED RESIDUALS 
MINIMIZATION 
11.1 
MULTI-MODALITY EXAMPLES 
Consider these examples: 
â¢ exchange rates of $j Â£, DMj$, yenj$, and franc/$, 
â¢ closing rates of stocks of AT&T, Intel Corporation, and Hermis bank12, 
â¢ London stock exchange index, 
â¢ daily call rates of a call center. 
The following figures show the data and optimization results. The opti-
mization results show how least square deviations depend on parameters 
b of ARMA models. The 3D optimization results are in two forms: as 
surfaces and as contours. 
Figures 14.4, 14.5, and 14.6 consider exchange rates of $j Â£and DMj$. 
Figures 14.7, 14.8, and 14.9 consider exchange rates of yen/$ and francj$. 
Figures 14.10 reflect closing rates of AT&T (top) and Intel Co.(bottom) 
stocks. 
Figures 14.13 , 14.14, and 14.15 consider the London stock exchange 
index. 
Figures 14.16, 14.17, and 14.17 shows stock rates of the Hermis bank 
and optimization results. 
Figures 14.18 and 14.19 show the daily call rates of a call center and 
illustrate optimization results. 
12 A small Lithuanian bank. 

EXCHANGE RATE PREDICTION 
211 
1.66 ,-----,-----,---,----,----.---.---.---,----,-, 
$/lbrate-
50 
100 
150 
200 
250 
300 
350 
400 
450 
1.8 
OM/$ rate-
1.75 
I 
~ 
1.7 
1.65 
1.6 
1.55 
~\( 
1.5 
1.45 
1.4 
1.35 
50 
100 
150 
200 
250 
300 
350 
400 
450 
Figure 14.4. 
Daily exchange rate of $f Â£(top figure) and DM/$ (bottom figure) start-
ing from September 13, 1993. 
To estimate unknown ARMA parameters we minimize a log-sum of 
squared residuals defined by expression (14.45). Estimates of parameters 

212 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
80-
70 
~ 
-10 
-1.5 
-1.5 
b(PLOT1) 
-1.5 
Deviation function, Lb/$ ~ 
b(PLOT2) 
Deviation levels, Lb/$ -----
40 -----
20 
10 ---Â·-
1 -----
0 ------
-2 ------
-2.1 ------
Figure 14-5. 
Exchange rates ofÂ£/$: surface I depending on parameters bo, bt (top), 
contours of I depending on parameters bo, bt (bottom). 
a are from expression (14.13). In most of the cases, figures show the 
multi-modality of log-sum (14.45), as a function of parameters b0 , b1. 

80-
~8 
50 
~8 
~8 
-10 
-1.5 
b(PLOT1) 
-1.5 
b(PLOT1) 
EXCHANGE RATE PREDICTION 
213 
Deviation function, DM/$ -
-1.5 
b(PLOT2) 
Deviation levels, DM/$ .... Â· 
40 ... .. 
20 Â·-...... . 
10 -Â·-Â·-
1 -Â·-Â·-
0 ..... . 
-1.3 ..... . 
-1.5 .... .. 
-1.6-
-1.7 ----Â· 
-1.6 ..... 
-1.65 . 
-1.9 -Â·-Â·-
b(PLOT2) 
Figure 14.6. 
Exchange rates of DM/$: surface off depending on parameters bo, b1 
(top), contours off depending on parameters bo, b1 (bottom). 
Areas in vicinity of the global minima, often appear flat. A reason is 
that differences between values of the deviation function f in an area 

214 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
Yen 1\$ exchange rate 
114 
'yen.rate' -
112 
110 
108 
106 
104 
102 
100 
0 
20 
40 
60 
80 
100 
6 
Franc/\$ exchange rate 
\\r 
'franc.rate' -
5.9 
5.8 
~f\fj 
5.7 
5.6 
5.5 
5.4 
0 
20 
40 
60 
80 
100 
Figure 14. 7. 
Exchange rates: yen/$ (top), franc/$ (bottom). 
around the global minimum are smaller as compared with these outside 
this area (see Figures 14.15). 

~8-
~8 
~8 
~8 
-10 
-1.5 
-1.5 
b(PLOT1) 
b(PLOT1) 
EXCHANGE RATE PREDICTION 
215 
-1.5 
-1.5 
Deviation function, Fr/$ -
b(PLOT2) 
Deviation levels, Fr/$ Â·----
40 ..... 
20 
10 -Â·-Â·-
1 -Â·-Â·-
0 ..... . 
-0.3 Â·Â·Â·Â·--
-0.5 ..... . 
-0.6-
-0.7 ----Â· 
b(PLOT2) 
Figure 1/1.8. 
Exchange rates offr/$, surface f depending on parameters bo, b1 (top), 
contours off depending on parameters bo, b1 (bottom). 
11.2 
OPTIMIZATION RESULTS 
The ARMA model optimization results are the points b and a (see 
Figure 14.1). These results were defined using a sequence of two global 

216 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
-1.5 
b(PLOT1) 
-1.5 
Deviation function, Yen/$ ~ 
-1.5 
b(PLOT2) 
Deviation levels, Yen/$ -
~ 
80 . 
40 
20 --Â·-
1 0 -Â·-Â·-
5Â· 
3 
2.3 
Figure 14-9. 
Exchange rates of yen/$, surface f depending on parameters bo, b1 
(top), contours off depending on parameters bo, b1 (bottom). 
methods called BAY ES1 and EXKOR (Mockus et al., 1997). BAY ES1 
denotes a search by a multi-dimensional Bayesian model (Mockus et al., 
1997). The best result obtained by BAY ES1 after fifty iterations is a 
starting point for local optimization. The local optimization is by one-

EXCHANGE RATE PREDICTION 
217 
~~--~----~--~----~--~~--~----r---~----~ 
AT&T rate-
64 
62 
60 
58 
56 
54 
52 
50 
48 
48L----L----~--~----J_--~~---L----L---~----~ 
50 
100 
150 
200 
250 
300 
350 
400 
450 
80~--~----~--~----~----r---~----~--~----~ 
Intel Co r te -
75 
70 
65 
60 
55 
50 
45 
40 
35 
30 
25L---~----~--~----~----L----L----L---~----~ 
50 
100 
150 
200 
250 
300 
350 
400 
450 
Figure 14.10. 
AT&T (top) and Intel Co.(bottom) stocks closing rates starting from 
August 30, 1993. 
dimensional coordinate search EXKOR {Mockus et al., 1997), using 
sixty iterations. 
The maximal number of Auto Regressive {AR) parameters p was 10 * 
M. Here M = 1, if no external factors are involved. The optimal 
number pis defined by structural stabilization (see Chapter 10.). Only 
two Moving Average (MA) parameters q = 2 were considered while 

218 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
-1.5 
b(PLOT1) 
-1.5 
Deviation function, AT&T ~ 
b(PLOT2) 
Deviation levels AT&T -----
' 
40 -----
20 
10 -----
3 -----
1.7 ------
Figure 14.11. 
Closing rates of AT&T stocks: surface f depending on parameters 
bo, b1 (top), contours off depending on parameters bo, b1 (bottom). 
plotting surfaces and contours. The results of Table 14.1 were obtained 
by optimization of both structural variables p and q. 

-1.5 
b(PLOT1) 
-1.5 
b(PLOT1) 
EXCHANGE RATE PREDICTION 
219 
-1.5 
-1.5 
Deviation function, intel ~ 
b(PLOT2) 
Deviation levels, intel -
70 .... 
50. 
20 ---Â·-
15 
6 4 . 
2 .. 
1 ~ 
b(PLOT2) 
Figure 14-12. 
Closing rates oflntel Co stocks: surface off depending on parameters 
bo, bt (top) contours off depending on parameters bo, bt (bottom). 
The objective of this part of research is to show a multi-modality 
arising in the prediction problem. Therefore, to save the computing 
time, the global optimization is carried out approximately, using not 
many iterations. The results of global optimization are starting points 
for local optimization. The reason is that the squared deviation as a 

220 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
100 
0 
-100 
-200 
Figure 14.13. 
London stock exchange index. 
function of parameters b becomes uni-modal near the global minimum 
(see Figures 14.15). Therefore, the results are at least as good as those 
obtained by the traditional local optimization. 
The high-accuracy global optimization is very expensive. In the global 
optimization, the computing time is an exponential function of accuracy 
m, in the sense that E ::; 2-m. Terefore, the problem of future investiga-
tions is how to balance computing expenses and accuracy of estimates. 
This task is important in both the time series prediction and the global 
optimization. 
The investigation of multi-modality of squared deviation and variabil-
ity of the parameters is the natural first step. The multi- modality is 
involved in non-linear regression models, including the ARFIMA ones13 . 
13Meaning that the sum (14.45) of the ARFIMA model is a non-linear function of the pa-
rameters b and d. 

70-
60 
50 
40 
30 
20 
10 
0 
b(PLOT1) 
b(PLOT1) 
EXCHANGE RATE PREDICTION 
221 
Deviation function, stocks -
b(PLOT2) 
Deviation levels, stocks 
50-----
10-
9 -----
3.5 -----
3.4 ------
3.3 
3.25 
3.24-
3.23 -----
3.22 -----
3.21 
3.2 -----
3.19 -Â· ---
3.18 -----
3.17 
b(PLOT2) 
Figure 14.14-
London stock exchange index, surface off depending on parameters 
bo, br (top), contours off depending on parameters bo, br {bottom). 
12. 
12.1 
SOFTWARE EXAMPLES 
C VERSION OF ARMA SOFTWARE 
(ARMAC) 
The call rates depend on several factors what is usual in statistical 
prediction problems. That is the main difference from the traditional 

222 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
3.26 
3.25 
3.24 
3.23 
3.22 
3.21 
3.2 
3.19 
3.18 
3.17 
3.16 
-0.6 
80 
70 t:--1 
60 
50 
40 
30 
20 
10 
0 
-1.5 
-0.4 
-0.2 
0 
b(PLOT1) 
Deviation function. stocks -
0.4 
0.6 
Deviation function, stocks -
~~--------~--------~~ 
-1 
-o.5 
0 
b(PLOT1) 
0.5 
1.5 
Figure 14.15. 
London stock exchange index: deviation f depending on parameter 
bo, uni-modal part (top), multi-modal part {bottom). 
ARMA and ARFIMA software for the exchange rate prediction (Mockus 
et aL, 1997). The ARFIMA software and applications are described in 
(Mockus et aL, 1997). 

EXCHANGE RATE PREDICTION 
223 
320 
300 
280 
260 
240 
220 
200 
180 
160 
140 
120 
--" 
100 
0 
20 
40 
60 
80 
'bank.main' -
'bank.external' ----
100 
Figure 14-16. 
Closing rates of stocks of the Hermis bank (private) and the Lithuanian 
Savings bank (state owned). 
We consider a version of an extended ARMA model that includes ex-
ternal factors (see expressions 14.28 and 14.29). The programs are in the 
files 'main.C', 'fi.C', and 'fitimeb.h' on the web-site (see Section 4.). The 
first version of ARMA software is designed for data sets with no future 
data. That means that no future factors are not known. Therefore, the 
external factors are treated as missing data. It is assumed that future 
values of external factors are equal to the last ones. In the ARMA soft-
ware under development, this is considered as the default case. In the 
new software version, the known future values of external factors will 
replace the default ones. 
The results of a simple test are in the files 'test.out' and 'test. progn.out '. 
The data is in the file 'test. data', the initiation file is 'test.ini'. The re-
sults of the call rate example are in the files 'calLout' and 'call.progn.out'. 
The data is in the file 'call.data'. The initiation file is 'call2.ini'. The 
names of the data files are referred as INP in the initiation file INIFILE. 
The software is compiled and run this way: 
Compile by 'make onestep', 
Run by 'onestep > results.out' 

224 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
'I 
-1.5 
-1.5 
Deviation function, banks -
Deviation levels, banks -----
10 
8 
6 -Â·-Â·-
4 ---Â·-
3.4 Â·Â·Â·Â·-Â· 
3.31 
3.31 
Figure 1{17. 
Closing rates of Hermis bank stocks: surface off depending on pa-
rameters bo, b1 (top) contours off depending on parameters bo, b1 (bottom). 
ILLUSTRATIVE EXAMPLE OF ARMA SOFTWARE: 
STOCK RATE PREDICTION 
Figures 14-20 and 14.21 show the part of the file 'fitimeb.h' defining 
the control parameters and data files_ 

EXCHANGE RATE PREDICTION 
225 
8000 .-----,----~-------r------. 
6000 
~ l I 
I 
1 
11 
4000 
i 
;; 
i 
; 
; 
' 
f 
ll1l~~ 
! ~~' i\ ! \ h{l 
! ! li\d,~ ; ~ I )'~\ ~i i Il ;fÂ·Â·~f I ! 
fd 
1 Â·1 
i; trfl : 11: ;J! 
Â·: lHl 
i 
0o 
100 
200 
300 
400 
Figure 1/1.18. 
Call rates. 

226 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
70-
60 
50 
40 
30 
20 
10 
0 
-1.5 
-1.5 
b(PLOT1) 
-1.5 
b(PLOT1) 
-1.5 
Deviation function, calls -
b(PLOT2) 
Deviation levels calls -----
â¢ 
50 ..... 
20 
15 -Â·-Â·-
10 -Â·---
9 .... .. 
8 ..... . 
6.7 ..... . 
6.6-
6.5 -----
b(PLOT2) 
Figure 14.19. 
Call rates: surface off depending on parameters bo, b1 (top), contours 
off depending on parameters bo, b1 (bottom). 

EXCHANGE RATE PREDICTION 
227 
#define RAND() drand48() 
#define S 0 I* number of rows of matrix c *I 
#if s == 0 
#define S1 1 
#else 
#define S1 s 
#endif 
#define R 0 I* number of columns of matrix c *I 
#define K 5 /*number of "multi-step" repetitions*/ 
#define w 0 f*W 0 means the one-step 
structural optimization, 
W 1 defines the multi-step one*/ 
#define V 1 f*V 1 means with the multi-step prognoses, 
V 0 means without*/ 
#define F 
1 /*indicator of variance, 
F 1 involves variance*/ 
#define EPS 0/*indicator of residual printing*/ 
#define INP 
0 /*indicator of input control*/ 
#define SA 
0 /*indicator of simulated annealing *I 
#define PL 
0/*plotting dimension*/ 
#define PLOT1 0 /*first plotting coordinate is b[PLOT1}*/ 
#define PLOT2 1/*second plotting coordinate is b[PLOT2}*/ 
#define A1 -1.5 /*lower bound of 
b[PLOT1}*/ 
#define B1 1.5/*upper bound of b[PLOT2}*/ 
#define A2 -1.5 /*lower bound of b[PLOT2}*/ 
#define B2 1.5/*upper bound of b[PLOT2}*/ 
#define DN 50 /*number of plotting steps*/ 
#define ST 10000. /*temperature of simulated annealing *I 
#define SI 100 /*number of 
simulated annealing iterations*/ 
#define Ps M /*starting number of AR parameters*/ 
#define Qs 0 /*starting number of MA parameters*/ 
#define Pmin M /*minimal number of AR parameters*/ 
#define Qmin 0 /*minimal number of MA parameters*/ 
#define Pmax 2*M 
/*maximal number of AR parameters*/ 
#define Qmax 2 /*maximal number of MA parameters*/ 
Figure 14-20. 
Example of the file 'fitimeb.h', part 1. 

228 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
#define T 120â¢M Iâ¢ number of data entries in DATAFILE 
(divisible by M)â¢/ 
#define TO T/3 /â¢TO<T number of entries 
for a and b optimization (divisible by M)*/ 
#define T1 2*TO /â¢T1>=TO, number of entries 
for P and Q optimization(divisible by M)*/ 
#define TR -1â¢M /â¢TR <= T, TRIM is the number of 
the first line in DATAFILE 
used for simple regression 
(negative TR prints no regression)â¢/ 
#define TE 25â¢M/â¢TE>TR, TE/M is the number of 
the last line for regressionâ¢/ 
#define INIFILE 11bank2. ini 11 
#define M 2 /â¢number of factorsâ¢/ 
#define MAXCOLS 
120 
#define DM 200 /â¢array sizeâ¢/ 
#define MAX_B_BOUND 1.0 
I* -MAX_B_BOUND <= b[i] <= MAX_B_BOUND â¢I 
#define MAX_C_BOUND 1.0 I* -MAX_B_BOUND <= c[i] [j] 
<= MAX_B_BOUND â¢I 
//#define LOCAL_METH NLP 
#define LOCAL_METH EXKOR 
//#define GLOBAL_METH EXKOR 
//#define GLOBAL_METH GLOPT 
#define GLOBAL_METH BAYES! 
//#define LOCAL_METH GLOPT 
#define GLOPT_MAX_IT 800 I* glopt IT â¢/ 
#define GLOPT_LT 100 I* glopt LT â¢/ 
#define GLOPT_MAXL 200 /â¢ glopt MAIL â¢/ 
#define NLP_MAX_IT 10 I* nlp IT *I 
#define NLP_M 0 I* nlp M *I 
#define NLP_ME 0 I* nlp ME *I 
#define BAYES1_MAX_IT 
5*M I* bayes1 IT â¢I 
#define BAYES1_LT 
5 /â¢ bayes1 LT â¢/ 
#define EXKOR_MAX_IT 
6*M Iâ¢ exkor IT â¢I 
#define EXKOR_INIT_POINTS 6 I* exkor LT â¢/ 
Figure 111.21. 
Example of the file 'fitimeb.h', part 2. 

EXCHANGE RATE PREDICTION 
229 
The control parameters and the optimization results (in the case INP 
0) are shown in Figure 14.22. 

230 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
Number of Factors M 2 
Multi-step prognoses indicator V 1 
Number of prognoses repetitions K 5 
indicator of input control INP 0 
the first line in datafile for regression, TR -2 
the last line in datafile for regression, TE 
50 
starting number of AR parameters Ps 2 
minimal number of AR parameters Pmin 2 
minimal number of MA parameters Qmin 0 
maximal number of AR parameters Pmax 4 
maximal number of MA parameters Qmax 2 
number of data entries T 240 
number of entries for a and b optimization TO 80 
number of entries for P and Q optimization T1 160 
indicator of variance F 1 
Global Max Iterat 10 
Local Max Iterat 12 
b-Bounds 1.000000e+OO 
Diskret Para.ms Init 
(Ps-AR params, Qs-MA para.ms,ts-starting time) 
Ps Qs ts = 2 0 0 
Diskret Params Step : 
dP dQ dt = 2 1 1 
Diskret Params Max : 
Pmax Qmax tmax = 4 2 0 
Start AR: 
l=O_Ps a[l] 
-9.152631e-02 
Start AR: 
l=O_Ps a[l] = 
1.083756e+OO 
Start Results: opt delta_perc delta_mean= 
1.140519e+01 4.830240e+01 
6.171501e+OO 
Start 
2 0 0 
Start 
Start 
BAYES, 
EXKOR, 
Discret: Po Qo to 
opt 
delta_perc delta_mean = 
1.140519e+01 4.830240e+01 6.171501e+OO 
AR: 
l=O_Po a[l] 
-9.152631e-02 
AR: 
l=O_Po a[l] = 
1.083756e+OO 
Finish Discret: Po Qo toP Q tO opt delta_perc delta_mean= 
2 
0 
0 
2 
0 
0 
1.140519e+01 4.830240e+01 
6.171501e+OO 
Finish ARo: 
l=O_P a[l] = -9.152631e-02 
Finish ARo: 
l=O_P a[l] = 1.083756e+OO 
Finish: sigma 2.054141e+01 
Finish progn_err 2.438730e+01 
Figure 14.22. 
Example of the file 'results.out.' 

EXCHANGE RATE PREDICTION 
231 
The comments in Figures 14.20 and 14.20 are short. Here are some 
additional explanations 
â¢ #define RAND() drand48(), 
defines the random number generator 
â¢ #define S 0 I* number of rows of matrix c *I 
#define S 0 I* number of rows of matrix c â¢I 
defines the bilinear component (see expression 14.35) 
â¢ #define K 5 /â¢number of 
11multi-step 11 repetitionsâ¢/, 
K 5 means that the multi-step predictions is repeated 5 times (see 
Section 9. and Figure 14.23) 
â¢ #define W 0 /â¢W 0 means the one-step 
structural optimization, 
W 1 defines the multi-step oneâ¢/, 
one-step structural optimization minimizes the average error of the 
"next day" predictions (see Section 10.3), multi-step one minimizes 
the average error of predictions for longer periods of time 
â¢ #define V 1 /*V 1 means with the multi-step prognoses, 
V 0 means withoutâ¢/ 
the zero value of the indicator V switches off the multi-step prediction 
(see Section 9.) and switches on the next day prediction (see Section 
3.3 and Figure 14.23) 
â¢ #define F 
1 /â¢indicator of variance, 
F 1 involves varianceâ¢/, 
the unit value of the indicator F means that the variance of the errors 
f is estimated and included into the multi-step prediction process 
â¢ #define EPS 0/â¢indicator of residual printingâ¢/, 
not used in this version 
â¢ #define INP 
0 /â¢indicator of input displayâ¢/, 
if INP 1 then the input values of the predicted factor are printed with 
their numbers (see Figure 14.24) 
â¢ #define SA 
0 /â¢indicator of simulated annealing â¢/ 
if SA 1 then optimization of the parameters p and q are performed us-
ing the simulated annealing method, otherwise the exhaustive search 
is used 

232 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
progn t 
ymin[Mâ¢t] 
yav[Mâ¢t] 
ymax[Mâ¢t] 
80 
2.212638e+02 
2.415062e+02 
2.549196e+02 
progn t 
ymin[Mâ¢t] 
81 
2.479502e+02 
progn t 
ymin[Mâ¢t] 
82 
2.327805e+02 
progn t 
ymin[Mâ¢t] 
83 
1.911297e+02 
progn t 
ymin[Mâ¢t] 
84 
2.059219e+02 
progn t 
ymin[Mâ¢t] 
85 
1.989816e+02 
progn t 
ymin[Mâ¢t] 
86 
1.998928e+02 
progn t 
ymin[Mâ¢t] 
87 
1.946436e+02 
progn t 
ymin[Mâ¢t] 
88 
1.870341e+02 
progn t 
ymin[Mâ¢t] 
89 
1.647438e+02 
yav[Mâ¢t] 
ymax[Mâ¢t] 
2.657038e+02 
2.954255e+02 
yav[Mâ¢t] 
ymax[Mâ¢t] 
2.725516e+02 
3.380554e+02 
yav[Mâ¢t] 
ymax[Mâ¢t] 
2.686203e+02 
3.272436e+02 
yav[Mâ¢t] 
ymax[Mâ¢t] 
2.715981e+02 
3.346959e+02 
yav [Mâ¢t] 
ymax [Mâ¢t] 
_ 
2.731343e+02 
3.315979e+02 
yav[Mâ¢t] 
ymax[Mâ¢t] 
2.742784e+02 
3.425031e+02 
yav[Mâ¢t] 
ymax[Mâ¢t] 
2.708346e+02 
3.392612e+02 
yav[Mâ¢t] 
ymax[Mâ¢t] 
2.722931e+02 
3.534729e+02 
yav[Mâ¢t] 
ymax[Mâ¢t] 
2.618776e+02 
3.345000e+02 
Figure 14.23. 
A fragment of the file 'progn.out', ten day predictions. 
â¢ #define PL 0/â¢plotting dimensionâ¢/, 
if PL 1 then the values of objective function depending on the pa-
rameter b[PLOTl] will be written in the file 'plot.out', 
if PL 2 then the values of objective function depending on two param-
eters b[PLOTl] and b[PLOT2] will be written in the file 'plot.out' 
(see Figure 14.25) and plotted as Figures 14.17 using the "Gnuplot" 
system, 
if PL 0 there will be no file 'plot.out' 
â¢ #define PLOT1 0 /â¢first plotting coordinate is b[PLOT1}â¢/ 

EXCHANGE RATE PREDICTION 
233 
0 
165.00 
1 
110.00 
2 
165.00 
3 
110.00 
4 
181.00 
5 
110.00 
6 
200.00 
7 
110.00 
8 
200.00 
9 
110.00 
10 
200.00 
Figure 14.24. 
A fragment of input data the file 'bank.out' when INP is set to unit. 
-1.000000e+OO O.OOOOOOe+OO 3.323284e+OO 
-1.000000e+OO O:OOOOOOe+OO 3.323284e+OO 
-1.000000e+OO O.OOOOOOe+OO 3.323284e+OO 
-1.000000e+OO O.OOOOOOe+OO 3.323284e+OO 
-1.000000e+OO O.OOOOOOe+OO 3.323284e+OO 
-1.000000e+OO O.OOOOOOe+OO 3.323284e+OO 
-1.000000e+OO O.OOOOOOe+OO 3.323284e+OO 
-1.000000e+OO O.OOOOOOe+OO 3.323284e+OO 
-1.000000e+OO O.OOOOOOe+OO 3.323284e+OO 
-1.000000e+OO O.OOOOOOe+OO 3.323284e+OO 
Figure 14.25. 
A fragment of the ten entries the 'bank.plot.out' ille. 
#define PLOT2 1/â¢second plotting coordinate is b[PLOT2}â¢/, 
defines which components of vector-parameter bare considered 
â¢ #define A1 -1.5 /â¢lower bound of b[PLOT1}â¢/ 
#define B1 1.5/â¢upper bound of b[PLOT2}â¢/ 
#define A2 -1.5 /â¢lower bound of b[PLOT2}â¢/ 
#define B2 1.5/â¢upper bound of b[PLOT2}â¢/ 
#define DN 50 /â¢number of plotting stepsâ¢/ 
defines the range and the density of the plotting points 
â¢ #define ST 10000. /â¢temperature of simulated annealing â¢I 
#define SI 100 /â¢number 
of simulated annealing iterationsâ¢/ 

234 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
defines the parameters of simulated annealing method (if SA is ap-
plied) 
â¢ #define Ps M /â¢starting number of AR parametersâ¢/ 
#define Qs 0 /â¢starting number of MA parametersâ¢/ 
#define Pmin M /â¢minimal number of AR parametersâ¢/ 
#define Qmin 0 
/â¢minimal number of MA parametersâ¢/ 
#define Pmax 2â¢M 
/â¢maximal number of AR parametersâ¢/ 
#define Qmax 2 
/â¢maximal number of MA parametersâ¢/ 
defines the initial, the minimal and the maximal number of parame-
ters p and q in the structural optimization 
â¢ #define T 120â¢M Iâ¢ number of data entries in DATAFILE 
(divisible by M)â¢/, 
defines the total number of entries in DATAFILE 
â¢ #define TO T/3 /â¢TO<T number of entries 
for a and b optimization (divisible by M)â¢/ 
#define T1 2â¢TO /â¢T1>=TO, number of entries 
for P and Q optimization(divisible by M)â¢/, 
divides the DATAFILE (see Figures 14.26 and 14.16) into three parts: 
the first part for a, b optimization, the second part for p,q optimiza-
tion, and the third part for testing the results 
#define TR -1â¢M /â¢TR <= T, TR/M is the number of 
the first line in DATAFILE used for simple regression 
(negative TR prints no regression)â¢/ 
#define TE 25â¢M/â¢TE>TR, TE/M is the number of 
the last line for regressionâ¢/, 
is used only in the case when the ARMA model of time series pre-
diction is reduced to the linear regression model of diagnosis. 
â¢ #define INIFILE "bank2.ini", 
defines the input control file INIFILE (see Figure 14.27) 
â¢ #define M 2 /â¢number of factorsâ¢/, 
defines the number of factors, including the predicted and the exter-
nal ones 
â¢ #define LOCAL_METH EXKOR, 
means that the EXKOR method is used for local optimization 
â¢ #define GLOBAL_METH BAYES1 

EXCHANGE RATE PREDICTION 
235 
5786.09 
180.00 
224.00 
250.00 
40.00 
20.25 
85.00 
16.00 
5796.10 
180.00 
222.00 
225.00 
40.00 
20.25 
85.00 
16.00 
5806.11 
180.00 
222.00 
247.50 
40.00 
20.00 
80.00 
16.00 
5816.12 
181.00 
225.00 
247.00 
40.00 
20.00 
80.00 
15.99 
5826.13 
182.00 
225.00 
240.00 
40.00 
20.00 
84.50 
15.99 
5836.16 
185.00 
225.00 
238.00 
36.00 
20.00 
85.00 
15.95 
5846.17 
188.00 
220.00 
238.00 
36.00 
20.00 
85.00 
14.36 
5856.18 
188.00 
220.00 
236.00 
36.00 
20.00 
85.00 
14.30 
5866.19 
190.00 
228.00 
230.00 
36.00 
20.00 
85.00 
15.45 
5876.20 
195.00 
230.00 
230.00 
36.00 
20.00 
85.00 
15.00 
5886.23 
190.00 
230.00 
221.00 
36.00 
20.00 
85.00 
15.50 
Figure 14-26. 
A fragment of the ten recent days of the DATAFILE 'bank.data' in-
ckuding the date code and data of seven main Lithuanian commercial banks. 
I INP bank . data 
COL 3 
COL 4 
Figure 11,.27. 
Example of the INIFILE 'bank2.ini.' 
means that the BAYESl method is used for global optimization 
â¢ #define BAYES1_MAX_IT 
5*M I* bayes1 IT *I 
#define BAYES1_LT 
5 I* bayes1 LT *I 
means that 5*M iterations and 5 initial iterations of the BAYESl 
method are used 
â¢ #define EXKOR_MAX_IT 
6*M I* exkor IT *I 
#define EXKOR_INIT_POINTS 6 I* exkor LT *I 

236 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
means that 6*M iterations and 6 initial iterations of the EXKOR 
method are used 
ILLUSTRATIVE EXAMPLE OF ARMA SOFTWARE: 
SIMPLE TEST FILE 
The test file is defined by 'test.ini': 
INP test2 
COL 1 
COL 2 
Here INP defines the data file 'test2' 
1. 
1. 
2. 
1. 
1. 
1. 
2. 
1. 
1. 
1. 
2. 
1. 
1. 
1. 
2. 
1. 
1. 
1. 
Here COL 1 means that the first column of the file 'test2' should be 
considered as the factor to be predicted. COL 2 indicates the second 
column as an external factor. 
A fragment of the optimization results is shown in the Figure 14.28. 
Here 'delta_perc' denotes the error in percents of the "Random Walk" 
prediction. 'delta_mean' is the average error. The results of optimiza-
tion are printed as Po, Qo, ao, bo. Predicted results are in the file 
'progn.out.old' (see Figure 14.29). The minimal ymin, the average yav, 
and the maximal ymax predicted values are equal. Therefore, the pre-
diction variance progn is zero. 

EXCHANGE RATE PREDICTION 
237 
#define V 1 /â¢V 1 means with the multi-step prognoses, 
V 1 means withoutâ¢/ 
#define F 0 /â¢indicator of variance, 
F 1 involves varianceâ¢/ 
#define Ps M /â¢starting number of AR parametersâ¢/ 
#define Qs 0 /â¢starting number of MA parametersâ¢/ 
#define Pmin M /â¢minimal number of AR parametersâ¢/ 
#define Qmin 0 /â¢minimal number of MA parametersâ¢/ 
#define Pmax 2â¢M 
/â¢maximal number of AR parametersâ¢/ 
#define Qmax 0 /â¢maximal number of MA parametersâ¢/ 
#define T 16 Iâ¢ number of data entries in DATAFILE 
(divisible by M)â¢/ 
#define TO 6 Iâ¢ number of entries 
for a and b optimizationâ¢/ 
#define T1 12 I* number of entries 
for P and Q optimizationâ¢/ 
#define INIFILE 
11test.ini 11 
#define M 2 /â¢number of factorsâ¢/ 
Ps Qs ts = 2 0 0 
Diskret Params Step 
dP dQ dt = 2 1 1 
Diskret Params Max : 
Pmax Qmax tmax = 20 0 0 
Start AR: 
l=O_Ps a[l] 
3.000000e+OO 
Start AR: 
l=O_Ps a[l] = -1.000000e+OO 
Start Results: opt delta_perc delta_mean= O.OOOOOOe+OO 
-1.000000e+02 O.OOOOOOe+OO 
Start Discret: Po Qo to 
opt 
delta_perc delta_mean = 
2 0 0 
O.OOOOOOe+OO -1.000000e+02 O.OOOOOOe+OO 
Start AR: 
l=O_Po a[l] = 3.000000e+OO 
Start AR: 
l=O_Po a[l] = -1.000000e+OO 
Finish Discret: Po Qo toP Q tO opt delta_perc delta_mean= 
2 
0 
0 
2 0 
0 
O.OOOOOOe+OO 
-1.000000e+02 
O.OOOOOOe+OO 
Finish ARo: 
l=O_P a[l] = 3.000000e+OO 
Finish ARo: 
l=O_P a[l] = -1.000000e+OO 
Finish: sigma O.OOOOOOe+OO 
Finish progn O.OOOOOOe+OO 
Finish: sigma O.OOOOOOe+OO 
Figure 1/1.28. 
A fragment of the control parameters and optimization results of the 
simplest illustration. 

238 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
progn t 
ymin[Mâ¢t] 
yav[Mâ¢t] 
1.000000e+OO 
1.000000e+OO 
progn t 
ymin[Mâ¢t] 
yav[Mâ¢t] 
2.000000e+OO 
2.000000e+OO 
progn O.OOOOOOe+OO 
ymax[M*t] 
6 
1.000000e+OO 
ymax[Mâ¢t] 
7 
2.000000e+OO 
Figure 111.29. 
Example of the prediction results of the simplest illustration. 
12.2 
JAVA VERSION OF ARMA SOFTWARE 
(ARMAJ) 
The Java version of ARMA software (ARMAJ) (Kuzminaite, 1999) 
implements the same algorithms as the C++ version ARMAC. The AR-
MAJ is on the web-sites (see Section 4.) and can be run by remote users. 
USERS GUIDE 
The applet 'index.html' is started by a browser, for example, by 
Netscape 4.6, or by the appropriate appletviewer. One clicks the but-
ton 'Show' (see the top Figure 14.30) to open the main window 'ARMA 
Frame' (see the bottom Figure 14.30). There are four buttons: 'File,' 
'Input,' 'Options,' and 'Output' which open corresponding windows. 
File is for data input. 
There are two fields: 'INI File' and 'Working directory or URL.' 
There is the button 'Browse ... ' and two options: 
'Local file' and 'Local URL.' 
The option 'Local file' activates the 'Browse .. .' button to select some 
local file. 
The option 'Local URL' closes this button. Then the contents of 
fields 'INI File' and 'Working directory or URL' determine the data 
file. 
The file name, for example, 'arma.ini,' is in the field 'INI File.' 
The file 'arma.ini' controls the data input from the test file 'arma.test.' 
The directory is in the field 'Working directory or URL.' 
If the 'Local URL' option is on, then the directory is, for example, 
this: 

EXCHANGE RATE PREDICTION 
239 
http:/optimum.mii.lt/-jonas/armajavaj 
The default URL is the applet directory. 
Input is to change the default values of parameters (see the top Figures 
14.31). The list of parameters is the same as in the C file 'fitimeb.h.' 
Options are to select options (see the top Figure 14.32): 
Output options defines the output file, 
None means no output, 
System output means console output, 
Frame defines output into separate windows, 
File outputs data into local files14 
Graphic options involves graphics. 
Output is for data output (see the bottom Figure 14.32): 
one starts computations by clicking the button 'Calculate', 
the message 'ARMA Frame: calculated' inicates the end. 
Some input and output operations are not permitted by the 'Security 
Manager.' Using the 'appletviewer,' it is possible to bypass the 'Security 
Manager.' For example, in the file j.hotjavafproperties one writtes: 
acl.read=/home/jonas/public\_html/armajavaj/arma.ini 
acl.write=/home/jonas/public\_html/armajavaj/arma.out 
That permits to read from 'arma.ini' and to writte into 'arma.out.' 
The file arma_all.jar is the 'jar' archive including all the 'class' files. 
source.jar or source.zip are archives of 'java' files. 
'index.html' is a starting applet. 
'arma.ini' is the input control file. 
'armatest' is the test data file. 
14This operation is not permited by browsers, as usuall. 

240 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
ILLUSTRATIONS 
The top Figure 14.30 shows the applet sign with the 'Show' button 
that starts ARMAJ. The botom Figure 14.30 shows the initial window 
where the input file 'arma.ini' is defined. button that starts the ARMAJ. 
psed: 53s 
Applt 
..... 
Figure 14.30. 
The applet sign (top figure), and the initial window defining the input 
me 'arma.ini'(bottom figure). 
Figures 14.31 show the list of default values of control parameters, 
similar to those in the ARMA C++ version. The upper part of the list 
is on the top figure, the middle part is on the bottom one. 

EXCHANGE RATE PREDICTION 
241 
Figure 1!1.31. 
The list of default values of control parameters, the upper part is on 
the top figure, the middle part is on the bottom one. 
The top Figure 14.32 shows the option window. The botom Figure 
14.32 shows the last fragment of the output window. Here the results, 
similar to those in the ARMA C++ version, are written. 

242 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
F 
. 
., 
Cr~ c 
tons 
bOt op I c op--::"-, -:l-a-:[:":'l':'"j-â¢-:'2--":'14=":'18:".-:CJ8=70~9:":"1=79S=I::-3-----------------, F 
bof optl 
optâ¢ I 
a[l 
â¢ 3 -42.:533735199!514666 
t>otore opt! c ~Â· Po 
Qo 
to P 
Q 
til opt <H>Ita_porc: delta_Man optlâ¢ I 
2 
8 
:5 
2 
II 
bot optl c opt: ~ b k 
â¢ II 
11.11 
bOf op I c op : ~ 
I> k 
â¢ I 
bOt op I c op 1 I 
a I 
â¢ 
4 . 79'339571!182111196EI6 
bOt optl 
opt1 I 
a I 
â¢ I 
7.3311:5421126442736Â£11 
bot optl 
optâ¢ I 
a I 
â¢ 
2. 9' 
E8 
bOf optl c opt: I 
a I 
â¢ 3 
!58812. 7736971=36 
bOf optl c opt: I 
a I 
o 4 
16. 
576331l116321l6 
t>oforâ¢ 1 n op r.e -
ao â¢ â¢â¢ Po 
Oo 
to P 
Q 
1e op 
cwlt.a_pwc 
<WI a_wan op I opteo 
1< bfkj â¢ e e.e 
k 
b k 
â¢ 1 
11.11 
bo[k) â¢ 
â¢â¢ 
1< 
bo[l<) â¢ 1 e.e 
I a[l) â¢ II 
4. 79339571!182111196EI6 
1 ao(l} â¢ e 4. 79339571!182111196EI6 
Finish o.sc:retâ¢ Po 
Qo 
to 
P 
Q 
1e opt delta_pwc delta_wanâ¢ I 
2 
II 
I 
2 
II 
399~.~ 
Finish IIAo: k _a b~~ â¢ o.e 
Fonoll\ IIAo: 
oO Q 1> 
â¢ 8.8 
Finosh Mo1 loO-P a I 
â¢ -(,8,7.379'29301083 
Fino 
1 SlljOia 
M:5919. 499128:5618 
Ftnosh PI"'OI"'_.,..- 663343e.384137249 
u 
Â·~ 
Figure 14.32. The option window (top figure) and the last fragment of the output 
window. 

EXCHANGE RATE PREDICTION 
243 
12.3 
ANN SOFTWARE 
A version of the ANN model (see expressions 14.31 and 14.34) 1s m 
the file fi.C.anngauss on the web-site (see Section 4.). Ji.C.anngauss 
is designed as an objective function of the GMC global optimization 
system. 
The software is compiled and run this way: 
Extract files by 'tar -zxf gmc.tgz' 
Rename the file 'fi.C.anngauss' by 'cp fi.C.anngauss fi.C' 
Compile by 'make', 
Run by ' . /test' 

Chapter 15 
CALL CENTER MODEL 
1. 
INTRODUCTION 
1.1 
OUTLINE 
Call centers are important and rapidly developing commercial activ-
ities. Call centers serve customers by phone, by fax and by Internet. 
There are different call centers depending on their objectives and envi-
ronments. However, investigating the call centers one encounters three 
problems: 
â¢ modeling; 
queuing systems are common tools while modeling call centers, 
â¢ optimization; 
one needs methods of stochastic and global optimization are to opti-
mize these systems, 
â¢ prediction; parameters, which are needed for modeling and optimiza-
tion, depends on predictions, predictions involve both the observed 
data and the expert knowledge. 
245 

246 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
1.2 
ASSUMPTIONS, NOTATIONS, AND 
OBJECTIVES 
One models call centers as queuing systems. The modeling system 
includes features for call rate predictions and service optimization. One 
assumes that 
â¢ incoming calls are united into one stream with the call rate A, a call 
rate is the average number of calls in a time unit, 
â¢ there are m servers with the same service rate f-t, the service rate is 
the average number of calls that can be served in a time unit, 
â¢ each server can serve any call, one at a time, 
â¢ calls are Poisson with the rate A, 
â¢ service times are exponential with the rate f-t > 1/m A, in such a case 
A= 1/T>.., 
t-t = 1/Tf.l-, 
(15.1) 
(15.2) 
where T>. is an average time between the calls and Tp, is an average 
service time, 
â¢ arriving calls enter the first available server, if all the servers are busy 
then the call takes a free waiting place, 
â¢ there are r waiting places, that means that a call waits, if there are 
not more than r other calls waiting, otherwise, the call disappears, 
â¢ waiting places are common for all the calls 
â¢ the system is stationary, meaning that the parameters t-t and A are 
constant, 
â¢ 
Cm is the server running cost ( $ per time unit), 
â¢ 
Ct is the customer time cost ( $ per time unit), 
â¢ 
Cp is the lost customer cost ( $ per lost call), 
â¢ the optimal number of servers m = m(c, r) minimizes the total cost 
C(c, m) 1 per time unit, including the server running cost, the cus-
tomer time cost, and the lost customer cost at fixed parameters r 
and c = (c5 , Ct, cp), 
10nly two parameters c and mare in C(c, m). The reason is uncertainty of c, therefore, the 
optimization of m is repeated several times at different "scenarios" c. 

GALL CENTERS 
24 7 
â¢ results are presented as the waiting time distribution functions 
FJ."'â¢r ( t) = pm,r { T < t}, where pm,r { T < t} is the probability that 
the waiting time T will be less than t at fixed number of servers m 
and waiting places r, 
â¢ a family of functions F;â¢r ( t) is defined for different parameters c, r, 
these functions are presented in a simple format, assuming that the 
number of servers m = m(c, r) is obtained by minimizing the total 
cost C(c, m, r). 
2. 
CALCULATION OF STATIONARY 
PROBABILITIES 
Under these assumptions (Tijms, 1994), the probability of k calls in 
the system, including both, waiting calls and calls in services 
R ( 
>.) 
_ 
{ ~Po(J.t, >.), 
if 1 ~ k:::; m, 
(15_3) 
k J.t, 
-
pk 
( 
) 
m!mk m Po J.t, >. , if m < k :::; m + r, 
where p = >.j J.tÂ· The no-calls probability 
m-1 k 
m m+r 
Po(J.t, >.) = ( ~ 
~! + :! k~ 
(~ )k)-1 
follows from the condition 
m+r 
L Pk(J.t, >.) = 1. 
k=O 
The probability of losing a call at given numbers m, r, J.t, >. is 
pm+r 
Pm+r(J.t, >.) = - 1 -Po(J.t, >.). 
m.mr 
The average waiting time 
r-1 
(15.4) 
(15.5) 
(15.6) 
T(m, r, J.t, >.) = L Pm+l(J.t, >.) t1, r > 0, 
(15.7) 
l=O 
where Pk(J.t, >.) is defined by expression (15.3) and tz = ~- The waiting 
time distribution functions 
F;:nâ¢r(t) = pm,r(J.t, >.){T < t} = 1- 'll~Â·r(t), 
m+r-1 
'll~,r ( t) = L Pk (J.t, >.) Pk{ T > t}, 
(15.8) 
k=m 

248 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
Here Pk{ T > t} denotes the probability that waiting time T will exceed 
some fixed t under condition that there are k calls 
k-m 
Pk{r > t} = L q8(t), k ~ m. 
(15.9) 
s=O 
Here q8 (t) is the probability that s calls will be served during the time 
t and 
(t) -
-mp.t (mp.t)s 
- 0 1 
q8 
-
e 
1 
, s -
, , ... , r. 
s. 
(15.10) 
3. 
ASYMPTOTIC EXPRESSIONS 
If the number r of waiting places is very large, one considers asymp-
totic expressions ( r--+ oo, p < m) as a reasonable approximation. The 
asymptotic values are denoted by the index oo. They are used to test 
the software designed for finite r. The no-calls probability 
m-1 
k 
m 
PQ<'(p.,.\)=(Lpkl+( 
-1~1( -
))-1. 
k=O 
â¢ 
m 
. m 
p 
The average waiting time 
pm 
T(m,oo,p.,.\) = 
1 
( 1 
I )2 P<F(p.,.\). 
m.mp. -p m 
The waiting time distribution functions 
Here 
Fm,oo(t) = Pm,oo(P., .\){ T < t} 
= 1- Wm,oo(t), 
W 
(t) = 
1 
e-(mp.->.)t poo(u .\) 
m,oo 
1 
I 
m ,..,, 
Â· 
-p m 
m 
P~(p., .\) = f!..-.Pooo(p., .\). 
m. 
The asymptotic probability of losing a call is zero. 
4. 
"SURROGATE" SERVICES 
(15.11) 
(15.12) 
(15.13) 
(15.14) 
An incoming call gets a regular service by an agent, if the actual or 
estimated waiting time is less then T w sec. Otherwise, a call gets a "sur-
rogate" service by voice-mail. For simplicity, one replaces this service 

CALL CENTERS 
249 
system by a system with r = Tw/T8 , where the expected service time is 
T8 = 1/mf.J.. Then one can use all the expressions for the queuing system 
with r waiting places. Here, the call served by voice-mail is considered as 
the "lost" call. One considers calls of different type separately, because 
they are served by different agents. 
5. 
CALL RATE ESTIMATE 
The lost calls are not registered, as usual. Therefore, it is difficult 
to estimate the call rate >. directly, if r is limited. Then one uses least 
square estimates. The square deviations fl(t-t, >.) between stationary 
probabilities Pk(f.J., >.) and their estimates Pf are minimized. 
m+r 
fl(t-t, >.) = L (Pk(f.J., >.)- Pf)2â¢ 
(15.15) 
k=O 
The stationary probabilities that there are k calls in the system are 
defined by expression 
R ( 
>.) _ 
{ ~Po(f.J., >.), 
k f.J., 
-
PI< 
( 
) 
m!mk mPo f.J.,A' 
if1sksm 
ifm S k S m+r. 
The least squares estimate of the call rate 
A0 = argminfl(t-t, >.) . 
.A 
(15.16) 
{15.17) 
The estimates Pf are obtained by counting the numbers of waiting calls 
at different time moments. Additional errors are expected, if the average 
number of waiting calls in a time unit is counted, instead of moment 
numbers. 
6. 
OPTIMIZATION OF NUMBER OF 
SERVERS 
The total cost of a service system 
C(c, m) = Cmm + CtT(m, r, f.J., >.) + CpPm+r(f.J., >.). 
(15.18) 
One optimizes the server number m by simple comparison of different 
m within reasonable bounds mmin S m S mmax, fflmin > >.j f.1. 
m(c,r) = arg 
min 
C(c,m,r). 
flmin~m~mm""' 
(15.19) 

250 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
7. 
MONTE CARLO SIMULATION {MCS) 
The explicit steady-state solutions (15.6)-(15.13) are simple and exact, 
under the assumptions. However, there is no general explicit solution, if 
the call rate A, and/or the service rate f..t depends on time. That often 
happens in real service systems. The configuration and operating rules 
of real service systems are too complicated for the exact solution, as 
usual. 
Then the Monte Carlo Simulation (MCS) is needed. We start the dis-
cussion of MCS from the steady-state systems keeping all the assump-
tions described in Section 1.2. That helps to test both the analytical 
and the Monte Carlo solutions by comparing the results. Later, MCS 
is extended to more complicated configurations and to time-dependent 
cases. 
7.1 
EVENT GENERATION 
The events in a queuing system are the moments when a call arrives, 
when a call enters a server, and when a call leaves the system. To 
generate events, one needs two types of random number generators. The 
first type generates times until the next call. The second type generates 
service times. 
Denote by Fa ( t) = Pa { T < t} the distribution function, where Pa { T < 
t} is the probability that a random time T will be less then t. Here a 
is the expected value ofT. Denote by e E [0, 1] the random variable 
uniformly distributed between zero and one. Then 
In exponential cases 
Fa(t) = 1- e-1/at, 
T = -aln(1 -e). 
Here a= 1/ A8 , if times until the next call are generated. 
a= 1/(m8 f..t 8 ), if service times are generated. 
(15.20) 
(15.21) 
(15.22) 
The model defines moments when a call enters a server and leaves the 
system. These moments depend on the specific structure of the system. 
The model is designed trying to represent the actual operations as realis-
tically as possible. However, the are limits that depend on the available 
computing power. 

CALL CENTERS 
251 
Here is a description of an algorithm of modeling and optimization of 
call centers: 
â¢ denote by tn the "arriving" time of the nth call, then tn+l = tn + 
~n(.A), ~(.A)= -1/.A log(1-ry), where TJ is a random number, uniform 
in [0, 1], and >. is the average number of calls in a time unit, the 
moment of the first call moment t 1 = 0 is the start of MCS, 
â¢ denote by 7n the "departing" time of nth call, then 7n+l = 7n + 
~n(f..Ln), ~(f..Ln) = -1/ f..Ln log(1- ry), where f..Ln is the average number 
of calls which can be served in a time unit by all1 ~ mn ~ rn servers 
operating at the moment 7 n, thus f..Ln = mn f..L, and f..L is the average 
number of calls, served by single server in a unit time, 
â¢ count all calls in the system at the moment tn+l including those in 
m servers and r waiting places by this expression 
{ In - 1, 
if tn+l > 7n 
min(In + 1, rn + r), if tn+l < 7n, 
(15.23) 
where In is the number of calls in the system at the moment tn, 
â¢ define the number of servers mn operating at the moment 7 n by this 
condition 
â¢ count calls lost up to the moment tn+l by the expression 
if In + 1 > rn + r, tn+l < 7 n 
otherwise, 
(15.24) 
(15.25) 
where Ln is the number of calls lost up to the the moment tn, 
â¢ count the waiting time by this counter 
Tn+l = Tn +On, 
On= 7n- tn, 
(15.26) 
(15.27) 
â¢ count the number of calls qk that waited less than tk, tk+l > tk, k = 
1, ... ,K 
(15.28) 

252 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
â¢ define the distribution of the call numbers qk that waited less than 
tk, tk+1>tk, k=1, ... ,K 
{15.29) 
â¢ define the optimal number of servers m by simple comparison of dif-
ferent m within some reasonable bounds mmin ~ m ~ mmax 
m{c, r) = arg 
min 
C{c, m, r), 
mmin ~m~mmao: 
{15.30) 
â¢ compare the results with the corresponding steady-state explicit so-
lutions, including the average waiting time, the average of lost calls 
and the waiting time distribution functions. 
7.2 
MONTE CARLO ERRORS 
Under independence conditions, the standard deviation u{ K) of the 
results O(K) of a statistical model depends on the number of observations 
Kas 
u(K) = o-(1)/..fK. 
(15.31) 
Here o-{1) is the "initial" standard deviation 
o-{1) = VE(0(1)- 8{1))2, 
(15.32) 
where 8{1) = E0(1) and E is the expectation symbol. 
In Monte Carlo simulation, 8{1) cannot be estimated directly using 
the results 0{1) obtained by the 1-th observation. Many observations 
are needed, to reach a stationary state (one observation means one call). 
Therefore, we repeat the Monte Carlo simulation L times doing K ob-
servations each time. Then the error variance can be estimated as 
L 
L 
uf(K) = 1/{L -1) :~:)01(K) -1/L LOi(K))2 â¢ 
{15.33) 
l=l 
j=l 
Expression {15.33) is simpler, if the exact solution e = limK-+oo O(K) is 
known. Then 
L 
uf(K) = 1/(L- 1) L(Oz(K)- 8)2 
{15.34) 
1=1 
Therefore, to test a Monte Carlo procedure, one considers a model with 
exact solution, first. Then one applies MCS to more complicated models. 

CALL CENTERS 
253 
7.3 
STOPPING MONTE CARLO 
The Monte Carlo errors are important to define stopping rules. The 
traditional idea is that the computing errors should not be greater then 
the data gathering errors. In call centers, data errors depend on the 
errors of call rate predictions, as usual. Thus, the stopping rule is: 
- stop at the first observation k ~ K satisfying this inequality: 
u(K) < u. 
(15.35) 
Here u is a standard deviation of call rate predictions. 
8. 
COMMON WAITING 
The common waiting system is an example were one applies approxi-
mate models, including the Monte Carlo. By common waiting we define 
a system that serves calls of different type. One represents them as a 
call-vector A= (Al, ... , Az). Different calls are served by different servers. 
However, there are r(c) of common waiting places. There are no simple 
formulas, such as (15.16) and (15.15). Therefore, we consider two ap-
proximate solutions: the analytical "reservation" model, and the Monte 
Carlo one. 
8.1 
ANALYTICAL APPROXIMATION: 
RESERVATION MODEL 
One estimates A= (A1, ... , Az) by minimizing the square deviations 
ms+rs 
~s(J.t,A,rs)= L (Pk8 (J.ts,As,rs)-PÂ£J 2 â¢ 
(15.36) 
ks=O 
Here Pks (J.ts, As, rs) is the stationary probability that there are ks calls 
in the s-th server. This probability is defined by expressions similar to 
(15.3), assuming that there are rs waiting places reserved for the calls 
As- r = (r1, ... , rl) is the reservation vector and Ls r 8 = r(c). 
n 
( 
, 
) 
_ 
{ .frPo(J.ts, As, rs), 
if 1 ~ ks ~ ms, 
.Lk8 J.ts, As> T S 
-
pk 
ms!m! m 8 Po(J.ts, As, rs), if ms ~ ks ~ m 8 + r8 â¢ 
The estimates PÂ£s are obtained by counting the numbers of waiting 
s-calls at different time moments. The least square estimate of the call-

254 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
vector >. is as follows 
{15.37) 
The reservation model is simple and clear. However, one must test the 
reservation assumption by the Monte Carlo model. 
8.2 
STATISTICAL APPROXIMATION: 
MONTE CARLO MODEL 
8.3 
CALL RATE ESTIMATE 
The statistical model can be used to estimate the call rates >. in the 
same way as the analytical one. One estimates >. = (.>.1, ... , >.z) by min-
imizing the square deviations D..(p., >., r) between the probabilities and 
their estimates 
ms+r 
D..(p., >., r) = L L (PkJP., >., r)- P~J 2 â¢ 
(15.38) 
S 
k 8 =0 
Here Pks (p., >., r) is the probability2 that there are k8 calls in the s-th 
server3. The estimates P~s are obtained by counting the numbers of 
waiting s-calls at different time moments. 
The least squares estimate of the call-vector >. 
.A0 = arg min D..{p., >., r) ). 
>. 
The statistical model needs considerable computing power. 
8.4 
TESTING ANALYTICAL 
APPROXIMATION 
{15.39) 
The analytical approximation (see Chapter 8.1) is simpler. However, 
it is based on the reservation assumption. The statistical model may 
represent most of the important factors. However, it takes a long time 
2Estimated using the Monte Carlo techniques described in the previous chapter. 
3There are no reserved waiting places for the calls ..\8 , thus the symbols r8 are omitted. 

CALL CENTERS 
255 
to "filter out" the random deviations. In the on-line operations, this 
time is too long, as usual. 
To test analytical approximation, one compares estimates of call rates 
A= (A1, ... , Az) obtained by both the statistical and the reservation mod-
els. A small deviation means that the reservation model is acceptable. 
The large deviation means that the analytical approximation should be 
improved. 
9. 
TIME-DEPENDANT CASES 
Consider the MCS when the call rates A= A(t), the number of servers 
m = m(t), and the number of waiting places r = r(t) depend on time. 
Therefore, all the results should be represented as functions of time. 
One modifies algorithms, similar to those in the previous chapter, by 
including the time factor: 
â¢ denote by tn the "arriving" time of the nth call, then tn+l = tn + 
en(A(t)), e(A(t)) = -1/A(t) log(1-TJ), where 1] is a random number 
uniform in [0, 1] and A is the average number of calls arriving in a 
time unit that includes the moment t, 
â¢ denote by Tn the "departing" time of nth call, then Tn+l = Tn + 
en(JLn), e(JLn) = -1/ JLn log(1-TJ) where JLn is the average number of 
calls which can be served in a time unit by all the 1 :-:::; mn :-:::; m(Tn) 
servers operating at the moment Tn, thus JLn = mn JL and JL is the 
average number of calls served by single server in unit time, 
â¢ count the number of all the calls in the system at the moment tn+b 
including those in m(tn+l) servers and r(tn+l) waiting places 
L 
{In -1, 
n+l = 
min( In+ 1, m(tn+t) + r(tn+l) ), 
if tn+l > Tn 
if tn+l < Tn, 
where In is the number of calls in the system at the moment tn, 
â¢ count the number of servers mn operating at the moment T n 
(15.40) 
â¢ count the number of calls lost up to the moment tn+l 
L 
_ 
{Ln + 1, 
n+l 
-
Ln, 
if In+ 1 > m(tn+l) + r(tn+l), tn+l < Tn 
otherwise, 

256 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
where Ln is the munber of calls lost up to the the moment tn, 
â¢ define the waiting time 
Tn+l = Tn + dn, 
dn = Tn- tn, 
{15.41) 
{15.42) 
â¢ count the number of calls s qk that waited less than tk, tk+l > tk, k = 
1, ... ,K 
â¢ define the distribution of the call numbers qk that waited less than 
tk, tk+1 >tk, k=1, ... ,K 
{15.43) 
â¢ optimize the number of servers m( t) at different times t by solving 
the corresponding stochastic scheduling problem4 
â¢ define the difference between the steady-state and dynamic solutions 
by comparing the average results with the corresponding steady-state 
explicit solutions, including the waiting time distribution functions 
F;",r(t) = pm,r{T < t}, where pm,r{T < t} is the probability that 
the waiting time T will be less than t, 
â¢ define the iteration number N by Monte Carlo experimentation. 
9.1 
SIMPLE EXAMPLE 
Consider this simple example 
>.(t) =a+ b sin(Â¢+ 21rwt). 
{15.44) 
Here w = 1/24 andÂ¢= 8/24. tis caunted in hours. a is average number 
of calls in 24 hours. b is amplitude of daily variation of calls, r(t) = r. 
if sin(Â¢+ 21rwt) < 0, 
if sin(Â¢+ 21rwt) > 0. 
{15.45) 
4 Solution of this problem is difficult, thus, later on we shall consider some simple cases as 
illustrations. 

CALL CENTERS 
257 
One optimizes the numbers m 0 and m 1 of two different servers consider-
ing two periods. This is a short description of the optimization problem: 
â¢ there are two optimization parameters m0 and m 1 restricted by bounds 
mmin ::; m0 ::; m~ax and m:nin ::; m 1 ::; m:nax' 
â¢ one may obtain the optimal pair by direct comparison of all the fea-
sible pairs 
m* = {m*0 m*1) = arg min C(c0 c1 m0 m 1 r) 
' 
0 
1 
' 
' 
' 
' 
' 
m,m 
{15.46) 
â¢ the total system cost is defined as 
C(c0 c1 m0 m 1 r) = 
' ' 
' 
' 
o o 
1 
1 
T( o 
1 
b ,~.. 
) 
c m + c m + Ct 
m , m , r, p,, a, , 'r' w + 
r-Pmo ml r(J.t, a, b, Â¢,w). 
-p 
' 
' 
{15.47) 
10. 
CALL RATE PREDICTIONS 
10.1 
INTRODUCTION 
Consider ideas and models that supplement the ones described in 
chapter 14. The call rate depends on many factors (see Figures 15.1 
and 15.2). Therefore, one applies the extended version of the Auto-
Regression-Moving-Average {ARMA) model and software (see Chapter 
14). 
The results show that one does not improve predictions by including 
the external factors directly into the ARMA model. A reason is that 
in the ARMA framework it is difficult to estimate the delay time (see 
expression {14.22)) and the duration of impacts Special Events (SE)5 . 
The additional difficulty is that most of SE are rare (see Figure 15.1). 
Therefore, columns of date file are filled mostly by zeros. Most of the SE 
indicated in Figure 15.2 are predictable. For example, one can predict 
factor 6 ( public holidays, traditional celebrations) and factor 7 (last day 
for ordering) exactly. Other SE can be predicted approximately. The 
knowledge of future values of external factors helps to predict the main 
5While predicting call rates, we call the external factors as "Special Events" (SE). 

258 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
1 
10/1/96 Tue 
1607 
1607 
1.2 
1.2 
0 
0 
0 
0 
0 
0 
0 
0 
2 
10/2/96 Wed 
1431 
1431 
1.1 
1.1 
0 
0 
1 
0 
0 
0 
0 
0 
3 
10/3/96 Thu 
1400 
1400 
1.1 
1.1 
0 
0 
0 
0 
0 
0 
0 
0 
4 
10/4/96 Fri 
1194 
1194 
1.1 
1.1 
0 
0 
0 
0 
0 
0 
0 
0 
5 
10/5/96 Sat 
476 
476 
1.1 
1.1 
0 
0 
0 
0 
0 
0 
0 
0 
6 
10/7/96 Mon 
1553 
1553 
1 
1 
0 
1 
0 
0 
0 
0 
0 
0 
7 
10/8/96 Tue 
1421 
1421 
1 
1 
0 
0 
0 
0 
0 
0 
0 
0 
8 
10/9/96 Wed 
1486 
1486 
1.1 
1.1 
0 
0 
0 
0 
0 
0 
0 
0 
9 
10/10/96 Thu 
1339 
1339 
1.1 
1.1 
0 
0 
0 
0 
0 
0 
0 
0 
10 
10/11/96 Fri 
1106 
1106 
0.86 
0.86 
0 
0 
0 
0 
0 
0 
0 
0 
Figure 15.1. 
A fragment of the the DATAFILE 'call.d.ata' including the number, the 
date, the call rate (repeated twice) , the real-valued external factor (repeated twice) 
and the indicators of eight Boolean external factors. 
Events 
index 
code 
description 
1 
Cp 
2 
Cr 
3 
D 
4 
Ep 
5 
Er 
6 
H 
7 
L 
8 
Op 
Postage of main catalogue 
Members receive main catalogue 
Selecting members for dunning 
Postage of extra catalogue 
Members receive extra catalogue 
Public Holidays, traditional celebrations 
Last day for ordering 
Postage of Order-reminder 
Figure 15.2. 
Eight Boolean external factors related to call rate. 

CALL CENTERS 
259 
one. However, the present software version cannot use this possibility 
yet. 
Here, we consider call rates .A(t) as a sum of two stochastic functions 
.A(t) = z(t) + v(t). 
(15.48) 
Often the rate .A(t) has several components .A(t) = (.At(t), ... , .At(t)) cor-
responding to different types of calls. In expression (15.48) v(t) denotes 
a "stationary" component which is described by the ARMA model. A 
"non-stationary" component is denoted by z(t). This way we separate 
the stationary part from the non-stationary one. 
The theoretical analysis of non-stationary stochastic functions is dif-
ficult. Therefore, the separation of non-stationary component is impor-
tant. The non-stationary component is defined by a local expert, as 
usual. The expert applies his knowledge while using the previous data 
and making the future predictions. Thus, we call z(t) as the "expert" 
component and v(t) as the "statistical" one. The estimate of the sta-
tistical component v(t) is investigated in Chapter 14, considering the 
ARMA model. An alternative is "Scale" models. They predict the 
expert component z(t) by estimated scales. The scales express the dif-
ferences between different SE and different times. 
10.2 
CALL RATE PREDICTION BY SCALE 
MODELS 
The ARMA models considered in Chapter 10. reflect non-stationarity 
by eliminating unstable parameters applying the structural stabilization 
techniques. This way some data and some model parameters ai, bj are 
eliminated. The estimates of the remaining ones are obtained. There-
fore, one may regard ARMA parameters ai, bj as some scales, too. These 
scales reflect the influence of the corresponding data sets by minimiza-
tion of prediction errors. No expert knowledge is involved. 
Now we shall consider the scale models, where the expert opinion is 
involved. This is done by choosing data sets and scales reflecting the 
expert opinion. Two versions of scales models are considered. 

260 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
In the first model it is supposed that the prediction Zi is a product of 
the present call rate Zi- 1 and some scale Si 
{15.49) 
Here Zi is a predicted call rate, called a "prediction." Zi-1 is an observed 
call rate, called a" data set." The index i- 1 defines the data set used to 
predict Zi. The parameter Si is the "scale" to predict Zi by the data set 
Zi_ 1. Expression (15.49) is a time scale model. In this model the scale 
is estimated as 
Zp(i) 
Si = --. 
(15.50) 
Zp(i-1) 
In (15.50) the subscript p(i) defines a period which precedes i. The 
subscript p(i- 1) denotes a period preceding i- 1. The term "preced-
ing" means the nearest previous period of the same type. For example, 
Saturdays, Sundays, holidays, Christmas weeks, sporting events, days of 
marketing messages, e.t.c., all are different types. 
In the second model 
Zi = Zp(i) Si-1Â· 
Here the scale is estimated as 
(15.51) 
Sp(i) = 
Zi-l . 
(15.52) 
Zp(i-1) 
Both expressions(15.49) and (15.51) predicts the same call rates. That 
means that one obtains the same results by the event scales (15.50) and 
the time scales (15.52). Only the interpretation differs, in scalar cases. 
In the vector case, expressions (15.49) and (15.51) predict different 
call rate graphs. One represents these graphs as vectors Zi = (Zij, j = 
1, ... , J). The components Zij denote call rates of different parts j of a 
period i. For example, hours if we predict next day call rates. 
The assumption of the first model (15.49) is that the next day graph 
Zi = (zij, j = 1, ... , J) is equal to the present one Zi- 1 = (zij, j = 1, ... , J) 
multiplied by scales Si 
Zp(i) 
Si = 
Zp(i-1) 
(15.53) 
Here Zi = 1/ J ~f= 1 Zij denotes the average call rates of the period i. 
Expression (15.53) means that the shapes of the next and the present 
graphs remains the same. Only the scales differ. 

CALL CENTERS 
261 
The second model (15.51) assumes that the next day graph is equal to 
the graph of the preceding period Zp(i) = (zp(i),jâ¢ j = 1, ... , J) multiplied 
by scales 
Zi-1 
Sp(i) = Z 
) . 
p(i-1 
(15.54) 
This means that the shapes of the next graph and the preceding one are 
the same. Only the scales differ. The numerator Zp(i) of scales Si of the 
first model depends on the Special Events (SE) of the next period i. We 
call the first model (15.49) as the event scale model. 
The numerator Zp(i) of scales Si of the first model depends on the 
Special Events (SE) of the next period i. By definition, the preceding 
period p( i) depends on the type of next one. The period type is defined 
by the Special Event (SE) which is active in the period. Examples of 
SE are Saturdays, Sundays, holidays, Christmas weeks, sporting events, 
days of marketing messages e.t.c .. 
The numerator Zi-1 of scales Bp(i) of the second model depends on the 
average call rate now i- 1. Therefore, we call the second model (15.51) 
as the time scale model. 
Using the event scale model (15.49), the next day event SE defines 
the next day scale. The shape of the next day graph remains the same 
as today. Therefore, this model reflects the changes of the graph shapes 
without delay. 
Using the time scale model {15.51 ), the shape of the next day graph is 
the same as the shape of the preceding one. Here the graph changes, but 
with some delay. The interval between the next period and the previous 
period of the same type defines the delay time. 
10.3 
EXPERT MODEL, EVENT SCALE 
VERSION 
DEFINITION OF SPECIAL EVENTS 
Here the call rate in the next period (15.49) is the same as in the 
present one multiplied by the scale BiÂ· The scale depends on the Special 
Event (SE) which is expected to be active in the next period. The 
periods where no special events are active, we consider as periods with 

262 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
"neutral" special events. Scales Si determine the impact of SE to the 
call rate Zi of next period. 
The scale Si reflecting the impact of a special event is estimated using 
empirical data by expressions (15.50), (15.53) and/or directly by expert 
opinions. The impact of some special events, such as Saturdays, Sun-
days, holidays, Christmas week e.t.c .. is well defined and instant. One 
calls them Instant Special Events (ISE). 
The impact of some others, such as marketing messages, is delayed. 
Call rates react to these events with some delay. Therefore, one calls 
them Delay Special Events (DSE). The starts and the durations of DSE 
are fixed. The delay times d and the durations T of DSE impacts are 
estimated using the observed data and expert knowledge. In some peri-
ods several DSE may be active simultaneously. One calls these Multiple 
Special Event (MSE). 
The starts and the durations of ISE and their impacts are equal to 
starts and durations of the corresponding periods. Beginnings and du-
rations of DSE impacts are not necessarily equal to the beginnings and 
durations of the periods. Therefore, a special sorts ofDSE appear, called 
Partial Special Events (PSE). In PSE the impact of a special event is 
active only during some part of the period. The delay times d, the du-
rations T of the impacts of DSE, and the scales s defining the impact 
of all the special events, are estimated using the available data and the 
expert know ledge. 
PROCEDURES 
We consider three expert procedures and the method of least squares, 
while defining estimates of scales SiÂ· The first procedure is the empirical 
one. The scales s describing the impact of all sorts of events, including 
the partial and the multiple ones, are estimated by expressions (15.50) 
or (15.53). These expressions define the relation of the call rates in the 
pair of periods p(i- 1) and p(i). A period p(i- 1) precedes the present 
period i -1. Denote by p( i) a period that precedes the next one, denoted 
i. The numerator Zp(i) is the call rate6 of the period preceding the next 
6In vector predictions that is an average call rate Zp(i). 

CALL CENTERS 
263 
one. The denominator Zp(i-l) is the call rate of the period preceding the 
present one. 
Using the empirical procedure, partial and multiple special events are 
considered as different SE. Here scales s are defined separately for each 
of them. Therefore, the empirical procedure is convenient, if the data 
is available for all types of periods, including the partial and multiple 
ones. In such a case, estimate of the delays d and durations T of DSE is 
not needed. It is supposed that an identical situation 7 is in the available 
data. One needs large data sets for that. 
The second direct procedure is the subjective one. All unknown pa-
rameters of the expert model, such as the scales s, the delay times d 
and the duration times T, are defined by the expert opinion. This is a 
reasonable way to start a new system, when no data is available. 
The third direct procedure is a mixture of the empirical and the sub-
jective ones. We use empirical estimates, if the corresponding data is 
available8 . Otherwise, one uses subjective estimates. Using the method 
of least squares, we search for such scales s, such delay and duration 
times d, t that minimize the sum of squared deviations. The deviations 
are differences between the call rates predicted by the expert model and 
the observed call rates ZijÂ· All four procedures are applied to different 
times: hours, days, weeks and seasons. First, we consider the scalar 
case. 
SCALAR PREDICTION 
In the scalar case, one predicts a single number, the average call rate of 
the next period. In the formal terms, one considers the call rate function 
Zi as a sample of some non-stationary stochastic process. Four different 
periods; hours, days, weeks, and seasons, are considered independently. 
Let us start by describing hours. 
7That means, there exist periods in the data file, with the identical combinations of impacts. 
Besides, these combinations are the same as that of the new and the present periods. 
8 If a pair of periods, identical to the pair of the present and the next one, can be found. 

264 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
Hourly Prediction. Using the event scale model, a call rate Zi of the 
next hour i is expressed this way 
{15.55) 
Here Zi-l is the present call rate. Si is a scale of the next hour i. The 
hourly scales Si differ depending on the impact of SE felt at the day 
i. For example, working days, weekends, Christmas days, marketing 
messages days, e.t.c. 
Zp(i) 
Si = --. 
{15.56) 
Zp(i-1) 
Here p(i) is a subscript of the hour preceding the next one. p(i- 1) is 
a subscript of the hour preceding the present one. Following examples 
illustrate what one means by the term "preceding." 
Examples of Multiple Special Events (MSE). Suppose that the 
impact of the special event "marketing messages send" starts at the next 
houri, that is the second one of a working day. Assume that the present 
hour i - 1 is the first one of a working day. Then 
Zp(i) 
Si = ---. 
Zp(i-1) 
(15.57) 
Here p( i) is the subscript of the most recent previous second hour of a 
working day with the same impact SE. p( i - 1) is the subscript of the 
most recent previous first hour of a working day with no SE. In this 
example, we consider a multiple SE as two single SE. The first single SE 
means the first working hour without the impact of marketing messages. 
The second single SE defines the second working hour with the impact 
of marketing messages. 
Another way is to consider the impacts of those two SE separately. 
Then one defines the scale Si as a product of two scales 
(15.58) 
Here 
s} = 
Zpl(i) 
, 
{15.59) 
Zpl(i-1) 
where p 1 ( i) is the index of the first hour and p 1 ( i- 1) is the index of the 
second hour. Both indices denote the previous working day. 
(15.60) 

CALL CENTERS 
265 
where p2(i) is the index of the most recent hour with "marketing" and 
p 1(i -1) is the index the most recent hour with no "marketing." Expres-
sion (15.58) needs less data. However, it is based on the assumption that 
scales are multiplicative. Expression (15.58) involves expert opinion by 
assuming multiplicativity of scales. Expression (15.57) is an example 
of empirical approach; multiple SE are considered as different special 
events. 
Examples of Partial Special Events (PSE). The only difference 
from the previous example is that the impact of "marketing messages" 
starts at the 20-th minute of the next hour i. Supose that PSE is a 
special sort of SE with the scale 
Zp(i) 
Si = --. 
(15.61) 
Zp(i-l) 
Here p(i) is the subscript of the most recent previous day when the 
"marketing" starts at the 20-th minute of second working hour. p(i- 1) 
is the subscript of the most recent previous first hour of a working day 
with no marketing. Another way is to consider the impact of PSE by 
setting the scale Si of marketing messages, in proportion to the duration 
of their impact 
(15.62) 
where 
Zp(i) 
Si = ---. 
(15.63) 
Zp(i-l) 
Here p(i) is the subscript of the most recent previous day when the 
"marketing" starts at the second working hour. p(i- 1) is the subscript 
of the most recent previous first hour of a working day with no marketing. 
Expression (15.62) needs less data. However, it is based on the as-
sumption that scales are proportional to the impact duration. Expres-
sion (15.62) involves expert opinion by assuming the proportionality of 
scales. Expression (15.61) is an example of the empirical approach where 
a PSE is considered as a different special event. 
METHOD OF LEAST SQUARES 
Denote by 'l/Ji(s, d, T) the call rate prediction by an expert model with 
fixed parameters s, d, T. One predicts call rates of the next period i, 

266 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
using data up to the period i - 1. The parameters of the model include 
scales s and delay and duration times d, r. We minimize the sum 
T 
min L (zi- 'I/Ji(s,d,r))2 â¢ 
s,d,r . '7' 
~=.LO 
Here Tis the end and T0 is the beginning of the "learning" set. 
(15.64) 
One minimizes (15.64) by various global and local optimization meth-
ods. That means that estimates of parameters of expert scale models are 
obtained in the same way as estimates of ARMA parameters (see Section 
14). The difference of (15.64), is that parameters s, d, r of the expert 
model EM are optimized, instead of ARMA parameters b. The opti-
mization problem {15.64) is very difficult. Here, the number of variables 
is great and the objective function is multi-modal. 
VECTOR PREDICTION, EVENT SCALE VERSION 
One often predicts the graph of call rates of the next perid. The graph 
is represented as call rates of different parts of the next period. These 
call rates are components of some vector. That justifies the term "vector 
prediction" 9â¢ 
The only difference from the scalar prediction is that we predict not 
a single call rate Zi of the next period i, but some vector Zi = (Zij, j = 
1, ... , J). Here the component Zij definines the call rate of the part j of 
the period i. First, we consider daily predictions, where index i denotes 
days and the index j denotes hours. 
Daily Vector Prediction. We predict the hourly call rates for the 
next day. The predicted call rate Zij of the hour j of the day i is 
Zij = Zi-l,j SiÂ· 
{15.65) 
Here Zi-t,j is the call rate of the hour j of the present day i- 1. Si is a 
scale of the next day i. The scales Si depend on the impact of SE felt at 
the day i. For example, working day, Saturday, Sunday, Christmas day, 
9In section 10. the terms "one-step" and "multi-step" were used instead of "scalar" and 
"vector." 

CALL CENTERS 
267 
marketing day, e. t.c. 
Zp(i) 
Si = -=-''--'--"-
Zp(i-1) 
(15.66) 
Denote by p( i) the subscript of the nearest previous day, similar to the 
next one. Denote by p( i - 1) the subscript of the nearest previous day, 
similar to the present one. The meaning of" nearest previous day similar 
to" is illustrated by following examples. 
Examples of MSE. Suppose that the impact of theSE "marketing 
messages send" starts at the next day i. That is Tuesday. The present 
day i - 1 is Monday with no additional special events. Then the scale 
zp(i) 
Si = 
. 
zp(i-t) 
(15.67) 
Here p( i) is the subscript of the most recent previous Tuesday with the 
same SE. p( i - 1) is the subscript of the most recent previous Monday 
with no SE. In this example we considered a multiple SE as two single 
SE: Monday without marketing, and Tuesday with marketing. 
Another way is to consider the impacts of those two SE by defining 
the scale Si as a product of two scales. 
(15.68) 
Here 
1 
Zpl(i) 
si = 
' 
Zpl(i-1) 
(15.69) 
where p1(i) is the index of Monday, p1(i- 1) is the index of Tuesday of 
the previous week, and 
s~ = 
Zp2(i) 
ZZp2(i-1). 
{15.70) 
p2(i) is the index of the most recent day with "marketing." Index p 1(i-1) 
denotes the most recent day with no "marketing." Expression (15.67) is 
an example of empirical approach. Here multiple SE are regarded as 
different special events. Expression (15.68) needs less data but is based 
on an expert assumption that scales are multiplicative. 

268 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
Examples of PSE. 
One feels the impact of the special event, called 
"marketing," next day i on the sixth working hour. That is the only 
difference from the previous example. Let us to consider PSE as another 
SE. Then 
zp(i) 
Si = 
zp(i-1) 
(15.71) 
Here p(i) is the subscript of the most recent previous week when the 
"marketing" starts Thesday at the sixth working hour. p(i- 1) is the 
subscript of the most recent previous Monday with no marketing. 
Another way is to regard PSE as a reduced SE. Then, the scale Si is 
proportional to the impact duration 
s? = 1/4 SiÂ· 
{15. 72) 
Here 
zp(i) 
Si = z 
, 
Zp(i-1) 
{15.73) 
p(i) is the subscript of the most recent previous week, such that "mar-
keting" starts Tuesday on the sixth hour, and p(i- 1) is the subscript 
of the most recent previous Monday with no marketing. 
Expression (15.71) is an example of empirical approach when aPSE 
is regarded as a different special event. Expression {15.72) needs less 
data. However, it is based on an expert assumption that scales are 
proportional to the impact duration. 
METHOD OF LEAST SQUARES 
Denote by 'l/Jij ( s, d, T) the call rate prediction by an expert model with 
fixed parameters s, d, T. One predicts call rates of the part j of the next 
period i using data up to the period i - 1. The parameters of the expert 
model include scales s and delay and duration times d, T. All special 
events, including DSE and PSE, are regarded. We minimize the sum 
T 
J 
min L 
L(Zij- 'l/Jij(s, d, 7))2. 
s,d,r. ,..,.. . 1 
Z=10 J= 
Here Tis the end and To is the beginning of the "learning" set. 
{15.74) 

CALL CENTERS 
269 
Define the expression (15.74) as a function 'fi' in the file 'fi.C'. Then 
one minimizes (15. 74) by various global and local optimization methods. 
That means that estimates of parameters of expert scale models are 
obtained in the same way as estimates of ARMA parameters (see Section 
14). 
10.4 
TIME SCALE VERSION, VECTOR 
PREDICTION 
Scalar predictions by time scales are identical to those using event 
scales. Vector predictions by time scale models (15.51) are different from 
those using event scale models (15.49). Here the shape z1 = (zij, j = 
1, ... , J) of the next day graph remains the same as that on the preceding 
day p(i). Only scales Si-1 change. This follows from (15.52). Scales Si-1 
of the present period i - 1 reflect changes of average call rates between 
the present period and the preceding one. The scales are estimated using 
empirical data and/or expert opinion. The definitions and examples of 
all the special events are the same as in the Event Scale case (see Section 
10.3). 
PROCEDURES 
We shall consider four procedures to obtain estimates: empirical, sub-
jective, mixed, and least squares. The estimates are similar to those in 
the Event Scale Model (see Section 10.3). Only scales and preceding pe-
riods are different. One predicts a vector Zi = (Zij, j = 1, ... , J). Here Zij 
means the call rate of the part j of the period i. First, we consider daily 
predictions. Then the index i denotes days, and the index j denotes 
hours. 
DAILY VECTOR PREDICTION 
We predict the hourly call rates of the next day. The predicted call 
rate Zij of the hour j of the next day i is 
Zij = Zp(i)j Si-1Â· 
(15.75) 
Here Zp(i)j is the call rate of the hour j of the day preceding the next 
one. Si-1 is a scale of today i- 1. Scales Si-l depend on the impact 

270 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
of SE felt at the day i. For example, working day, Saturday, Sunday, 
Christmas day, marketing day, e.t.c. 
{15. 76) 
Here p( i - 1) is a subscript of the day preceding the present one. The 
term "preceding" is illustrated by the following examples. 
Examples of MSE. Suppose that the impact of theSE "marketing 
messages send" begins and ends today i -1, which is Monday. The next 
day i is Thesday with no additional special events. Then the scale 
zi-1) 
Si = 
Â· 
zp(i-1) 
{15.77) 
The index p( i -1) denotes the day, which precedes the present one. Here, 
we regard a multiple SE as two single SE. First single SE is Monday with 
marketing. The second single SE is Thesday without marketing. 
Another way is to regard the impacts of those two SE by defining a 
scale Si-1 as a product of two scales. 
(15.78) 
Here 
{15.79) 
p 1 ( i - 1) is the index of the day preceding Monday without marketing. 
p(p1 ( i - 1)) is the index of the day preceding p 1 ( i - 1). 
{15.80) 
p2(i -
1) is the index of the day preceding the day with marketing. 
(p(p2 ( i - 1)) is the index of the day preceding p2 ( i - 1 ). 
Expression (15.77) is an example of empirical approach when multiple 
SE are regarded as different special events. Expression (15.78) needs less 
data but is based on the assumption that scales are multiplicative. 

CALL CENTERS 
271 
Examples of PSE. Here, the impact of "marketing" starts at the 
second working hour of the present Monday i -
1. Regarding PSE as 
another SE the scale is 
Zi-1 
Si-1 = ---. 
Zp(i-1) 
Here p( i - 1) is the index of the day preceding the present one. 
{15.81) 
Another way is to regard the PSE as a reduced SE. Then the scale 
Si-1 is proportional to the impact duration 
sL1 = 1/4 Si-1Â· 
{15.82) 
Here 
{15.83) 
p3(i -1) is the index of the preceding marketing Monday. p{p3(i -1)) is 
the index of the day preceding p3(i-1). Applying expression (15.82) one 
requires less data. However, this expression is based on the assumption 
that scales are proportional to the impact duration. 
Expression {15.82) involves expert opinion indirectly, by assuming 
proportional scales. Expression {15.81) is an example of empirical ap-
proach when a PSE is regarded as another SE. 
METHOD OF LEAST SQUARES 
Denote by '1/Jii { s, d, r) the call rate prediction by an expert model with 
fixed parameters s, d, r. One predicts call rates of the part j of the next 
period i using data up to the period i - 1. The parameters of the expert 
model include scales s and delay and duration times d, r. All special 
events, including DSE and PSE are regarded. We minimize the sum 
{15.84) 
Here T is the end and To is the beginning of the "learning" set. One 
minimizes {15.64) by corresponding global and local optimization meth-
ods. 

272 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
REMARKS 
As usual, expert models predict the weekly and the seasonal graphs. 
The weekly graphs are given in a form of average calls for each of seven 
days. In the seasonal graphs, weeks are represented by weekly averages. 
Often "observed" values of the call rates Zi cannot be defined directly. 
Then their estimates are used (see Section 5.). Missing or uncertain data 
is replaced by expert estimates. This is important for the first year of 
operation. 
10.5 
TIME SERIES MODEL (ARMA) 
SCALAR PREDICTION 
Here we consider how to apply the ARMA model to predict the errors 
vi of the expert scale modeh/Ji(s, d, r), where vi= '1/Ji(s, d, r)-zi (Mockus 
et al., 1997). The formal description of the ARMA model is in Chapter 
14. The software is on the web-site (see Section 4.). If predicting vi we do 
not know some values of v8 , s = i-1, i-2, ... then we replace the missing 
data by the expected values of the unknown v 8 defined recurrently (see 
Section 10.). 
ARMA models predict only the difference between the expert models 
(EM) and the data. Therefore, in the first step, EM models are adapted 
to the data by defining the right scales. Only then, the parameters 
a, b of ARMA models are optimized. This means that one minimizes 
a squared difference between the adapted EM model and the observed 
data. Predicting the data, the results of both EM and AH models are 
summed up. 
VECTOR PREDICTION 
The vector prediction of EM errors Vi is performed using multi-step 
ARMA predictions described in Sect.ion 9. "Confidence cones" could be 
useful for preliminary evaluation of prediction errors. They estimate 
probable deviations from expected values with some "confidence level," 
say ninety percent or ninety nine percent. These cones are defined em-
pirically as upper and lower limits of the results obtained by repetition 
of Monte Carlo procedures (see Section 9.). 

CALL CENTERS 
273 
10.6 
APPLICATION EXAMPLES 
In the call center example, both the Expert and ARMA models were 
tested separately. Figure 14.18 shows daily call rates of this center. 
Table 14.1 illustrates some results of the ARMA model. Results of the 
expert model are not available, for publication. 
11. 
CALL CENTER SCHEDULING 
There are "Of-the-Shelf' tools for the scheduling of single-skill agents. 
The scheduling of multi-skill agents is theoretically possible using Monte 
Carlo simulation (see Section 7.). However, the simulation time is too 
large for on-line scheduling. A convenient approximation to multi-skill 
scheduling is the reduction of multi-skill problems to the single-skill ones. 
One can do that by representing each multi-skill agent as a "weighted" 
single-skill one 
Nsingle = V * NmultiÂ· 
(15.85) 
Then, one estimates the unknown weight v by minimizing the sum of 
squared deviations. The deviations are differences between results of 
approximate single-skill model and the multi-skill one 
K 
~in 1/ K L ( 
Qk().., Nmulti) -
Qk().., Nsingle) )2 Â· 
(15.86) 
k=l 
Here Qk denotes the results of the k iteration of a Monte Carlo simulation 
of the multi-skill system. ).. is the call rate. Nmulti is the number of 
multi-skill agents. Qk is the result of the k iteration of a Monte Carlo 
simulation of a single-skill system. Nsingle is the number of single-skill 
agents, which replace the multi-skill ones. 
Another way is to extend the single-skill simulation (see Section 11.) 
to the multi-skill case. Here one needs more computing time to estimate 
the "optimal" weights v for different call rates. For example, the method 
Exkor is used to obtain the best values of v (see Section 4.). 

Chapter 16 
OPTIMAL SCHEDULING 
1. 
INTRODUCTION 
Industrial, financial, commercial or any kinds of activity have at least 
one common feature: the better organized they are, the higher the profit, 
the better the quality or the lower the cost. Everyone makes a schedule 
to organize his or her own life. Making a schedule for any organized 
activities, one considers a sequence of tasks and a list of resources. Re-
sources include tools, machines, materials, work force e.t.c. Of course, 
making a schedule for organization is far more difficult than making a 
schedule for our everyday life. 
A failure to make a schedule or devising a wrong schedule can result 
in delay of a deadline and can cost much of the money. An example 
of early formal scheduling technique is the Harmonygraph developed in 
1931 by Karol Adamiecki (Adamiecki, 1931). The review of network 
based scheduling techniques is in (Hajdu, 1997). 
First we consider an example of a simple scheduling problem. Here 
the sequence of tools is fixed by technology. One minimizes the make-
span, which is the time from the beginning of the first task until the end 
of the last one. 
The second example is a school scheduling problem. Here the sequence 
of teaching subjects, regarded as tools, can be changed. One needs to 
reduce the sum of" empty" hours for teachers. There should be no empty 
275 

276 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
hours for classes. Different classes are considered as different tasks. The 
classrooms, including the computer and physics rooms and studies, are 
the limited resources. 
2. 
FLOW-SHOP PROBLEM 
The flow-shop problem is a simple case of the large and important 
family of scheduling problems. We denote the sets of jobs and machines 
by J and S. Denote by Tj,s the duration of operation (j, s). Here j E J 
denotes a job and s E S denotes a machine1. 
Suppose that the sequence of machines s is fixed for each job j. One 
machine can do only one job at a time. Several machines cannot do the 
same job at the same moment. The decision di(j) E Di means starting 
the job j E Ji at the stage i. We define the set of feasible decisions Di 
as the set Ji of all the jobs available at the stage i and conforming to 
the flow-shop rules. 
The objective function vis the make-span2 . Denote by Tj(d) the time 
when we complete the job j (including the gaps between operations) 
using the decision sequence d = (d1, ... , dK ), where K the number of 
decision stages. Then the make-span of this d is 
v(d) = HJtJ7'i(d). 
(16.1) 
2.1 
PERMUTATION SCHEDULE 
The number of feasible decisions for the flow-shop can be very large. 
One reduces this number, if one considers only the so-called permutation 
schedules that are subsets of all feasible schedules. The permutation 
schedule is a schedule with the same job order on all machines. Here 
one defines a permutation schedule by fixing a sequence of job indices, for 
example, 1, 2, ... , n. The schedule is transformed by a single permutation 
of job indices. As usual, permutation schedules describe the optimal 
decision well and are easier to implement (Baker, 1974). 
1 Describing the scheduling problems we use the terms machine and tool and the terms job 
and task as synonyms. 
2The time to complete all the jobs. 

OPTIMAL SCHEDULING 
277 
Denote 
JSJ 
Tj = L:rj,s, 
s=l 
where I S I stands for the number of machines. We define Tj as the 
length of the job j. 
2.2 
HEURISTICS 
Define Longer-Job heuristics 
Here 
rÂ·-AÂ· 
hi(j) = Ji- A: +a. 
AÂ·= minrÂ· Ai = maxrÂ· a> 0. 
z 
jEJi 3' 
jEJi 3' 
The priority rule {16.2) prefer a longer job. 
2.3 
RESULTS 
(16.2) 
{16.3) 
Table 16.1 illustrates results of BHA after 100 iterations using the 
Longer-Job heuristic {16.2) and different randomization procedures. The 
objective is a stochastic function. This function defines the shortest 
make-span found after K repetitions. 
In the example, J = S = 0 = 10, where J, S, 0 are numbers of jobs, 
machines, and operations, respectively. Lengths and sequences of opera-
tions are generated as random numbers uniformly distributed from zero 
to ninety-nine. The expectations and standard deviations are estimated 
by repeating forty times the optimization of a randomly generated prob-
lem. In Table 16.1 the symbol !B denotes a mean, and dB denotes a 
standard deviation of the make-span. "Delta" denotes randomization 
including terms l = 0, 1, 2, oo {see expressions {2.6) and {2.7)). "Taylor 
3" denotes randomization {2.6) where the number of terms is L = 3. 
"CPLEX" denotes the results of the well known general discrete opti-
mization software after twenty hundred iterations {one CPLEX iteration 
is comparable to a Bayesian observation). The bad results of CPLEX 
show that the standard MILP technique is not efficient in solving this 
specific problem of discrete optimization. It is not yet clear how much 
one improve the results using specifically tailored B&B. 

278 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
Table 16.1. 
The results of Bayesian methods using Longer-Job heuristics (16.2). 
R = 100, K = 1, J = 10, S = 10, and 0 = 10 
Algorithm 
/B 
dB 
xo 
Xl 
X2 
Delta 
6.183 
0.133 
0.283 
0.451 
0.266 
Taylor 3 
6.173 
0.083 
0.304 
0.276 
0.420 
CPLEX 
12.234 
0.00 
2.4 
GMC SOFTWARE EXAMPLE 
One applies the C++ optimization system GMC to search for such 
BHA parameters that reduce the average deviation on a set of ran-
domly generated Flow-Shop problems. The corresponding file fi.G = 
fi_flow.G is on the web-site (see section 4.). Figure 16.1 shows how to 
define data in the file 'gmcjfi_flow.C'. 
#include <stdio.h> #include <math.h> #include <malloc.h> 
#include <string.h> #include "task.h" #define DIM 
3 #define NUMBER...OF JOBS 
7 #define NUMBER...OF _MACHINES 
40 #define NUMBER...OF ..FCALC 
0 #define TRUE 
DIM; 
100 #define FALSE 
1 int number_of_variables = 
Figure 16.1. 
Example of the file 'gmc/fiJI.ow.C.' 
2.5 
GMJ SOFTWARE EXAMPLE 
To optimize BHA parameters for a given Flow-Shop problem, one 
applies the Java optimization system GMJ2 that reduce the average 
deviation (Greicius and Luksys, 1999). The operation times are in the 
file 'jobtimes.txt.' (see Figure 16.2) The local URL address of this file 
apears opening the GMJ2 task 'FlowShop' (see Figure 16.3). 
The optimal proportions of three heuristics: the Monte Carlo, the 
linear randomization and the "Select-the-Best" are on the output page 

OPTIMAL SCHEDULING 
279 
71.7 62.49 28.65 95.08 51.64 63.97 33.16 36.55 79.05 78.27 
67.23 20.99 62.67 4.84 90.02 61.71 24.2 52.85 47.93 99.57 
63.54 96.69 33.24 12.29 90.57 57.8 78.79 41.46 46.3 36.32 
98.03 22.24 75.09 23.02 22.59 86.13 82.82 16.06 28.36 18.93 
76.73 55.52 96.98 43.28 79.6 77.63 99.86 74.95 97.97 20.55 
6.68 89.5 5.57 33.93 52.86 29.59 85.1 82.08 25.36 4.96 
82.59 82.45 57.4 55.37 75.92 82.6 72.11 77.67 11.6 64.46 
94.04 79.15 61.23 86.6 91.56 74.14 56.59 13.99 69.36 45.29 
27.89 100.0 77.67 89.27 53.73 47.77 26.92 88.15 74.75 66.31 
40.45 97.05 11.04 80.41 25.69 53.58 53.58 31.25 20.52 74.24 
22.01 48.93 37.08 11.84 78.14 18.6 15.65 26.69 7.1 
32.79 
86.37 39.95 71.2 91.72 65.96 87.97 36.91 73.99 85.83 63.97 
82.57 98.22 24.91 32.01 64.8 51.18 91.13 62.33 54.05 20.01 
7.99 44.9 18.89 4.72 68.69 51.26 49.48 74.39 6.4 
71.21 
22.39 13.52 75.85 29.9 49.92 57.91 2.81 21.7 26.41 95.1 
46.36 95.85 70.24 76.65 47.85 70.24 83.76 59.61 89.51 39.43 
97.34 0.15 21.85 48.26 43.36 89.73 85.58 55.82 32.46 80.32 
50.56 34.31 93.92 83.44 22.87 20.22 20.37 42.22 90.48 33.84 
23.57 9.15 64.97 97.43 77.75 28.3 62.62 56.54 39.98 62.86 
83.08 3.45 45.67 36.15 70.0 93.57 2.72 67.69 65.12 42.86 
71.17 33.78 90.33 30.31 93.17 76.25 79.7 25.37 61.52 31.51 
25.08 27.8 95.49 60.6 3.46 74.63 8.41 98.74 29.05 22.22 
98.46 78.16 3.53 65.04 96.55 21.63 49.43 44.92 5.52 8.98 
83.61 92.02 90.76 19.81 42.02 40.49 18.65 22.17 87.21 83.77 
5.4 
54.84 99.76 5.28 14.26 97.87 89.89 80.65 0.46 42.48 
82.97 1.61 23.78 11.0 94.76 0.16 55.0 54.76 60.04 74.3 
72.16 62.06 42.7 43.16 85.64 68.6 70.22 94.0 4.99 99.76 
99.92 54.92 9.68 69.71 44.01 16.17 78.23 20.93 64.09 49.73 
Figure 16.2. 
Example of the file 'jobtimes.txt' defining the operation times. 
(see Figure 16.4). The convergence line is there, too. These are results 
of one hundred iterations by the 'Bayes' method. 
Figure 16.5 shows how the flow-shop make-span depends on the pro-
portion of the Monte Carlo algorithm. The metod 'Bayes' changes all 
variables together. Therefore, the projection that depends on one vari-
able is not informative. The 'Projection' menu presents three choices: 
Monte Carlo, Randomized Heuristics, and Greedy Heuristics. 

280 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
Appl~t 
Â·I Method T sk Operation 
se ect t 
nd propertie 
PropertY. 
., 
Â· 
Dimension 
R ndomi ed HeueÂ·isti<Â· (x 
Greedy 1-leuri tic (x3) 
J 1.0 _ 
___, 
Method algonthms by Jonas rvlockus 
Design~. Implementation by Modestas G rlba uskas 
e-mail 
~.lodestas_G@equmoxll com 
Applet started. 
Figure 16.3. 
Opening the 'FlowShop' task. 

OPTIMAL SCHEDULING 
281 
rio 
Randomized lleuri~tics 
Gre dy H uri tic 
99 
2894.67 
0.04 
0.687 
0.01 s 
Uarnine: Applet Uindou 
f(x) 
3200 
3150 
3100 
-Â· 
3050 ""' 
3000 
'-.. 
2050 
'--
I 
r-- - Â·---. 
- 0~ 
r----.., 
2000 
~50+---~--~---r---r--~---4----~--T-------~ 
0 
10 
20 
30 
40 
50 
60 
70 
80 
Analysi 
Figure 16.4. 
Numerical results and convergence line, the 'FlowShop' task. 

282 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
28 4. 7 
0.04 
0.687 
0.01 . 
2800+----.....--.....--......-----------------~ 
00 
01 
02 
03 
04 
0~ 
0~ 
07 
rio 
tic 
Figure 16.5. 
Relation of f(x) to the proportiom of Monte Carlo algorithm and the 
'Projection' menu. 
3. 
SCHOOL SCHEDULING 
School scheduling is the well-known example of a general schedul-
ing problem. Consider the case where the objective is the number of 
"empty" hours when the teachers wait for the next scheduled lectures. 
We will call these hours as "teacher windows." We search for such sched-
ules that reduce the sum of teacher windows considering the schedules 

OPTIMAL SCHEDULING 
283 
of fifth to twelfth class of the public high school. Other factors are 
school-specific and should be included adapting the software to specific 
schools. 
3.1 
CONSTRAINTS 
There are five constraints: 
â¢ no "student windows" are allowed, 
â¢ at any given moment a teacher can deliver only one lesson, 
â¢ at any given moment a student can take part at only one lesson, 
â¢ the "double" lectures (the sequence of two lectures of the same sub-
ject) are not allowed {there are some strictly limited exceptions), 
â¢ the number of lecture hours per day is limited. 
3.2 
DATA STRUCTURE 
The optimization starts from the existing school schedule. The top 
picture in Figure 16.11 shows a fragment of the existing weakly schedule 
of some Lithuanian school. 
â¢ the schedule is defined as a string array M okytojai[64][38], 
â¢ the string Mokytojai[i][l] defines the name of the i-th teacher, for 
example, L.Dalinkeviciene, V.Vilkiene, e.t.c. 
â¢ the string M okytojai[i][2] defines the subject of the i-th teacher, 
for example, lietuviu_k means Lithuanian, rusu_k means Russian, 
anglu_k means English, matematika means Mathematics, 
inf ormatika means Informatics, e. t.c. 
â¢ the string M okytojai[i][3] defines the code of the classroom of the 
i-th teacher, for example, 0 means no special study, A means a study 
for Informatics, e.t.c. 
â¢ the sequence of strings M okytojai[i][j], j = 4, ... , 38 define the class 
codes of the i-th teacher for all weak, for example, in the class code 

284 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
P19c, the first symbol P means Monday3, the second symbol1 defines 
the first lesson, and the third symbol 9c means the class 9c, teacher 
windows are denoted by symbols X, symbols Q denote "convenient" 
lessons, a lesson is called "convenient", if a teacher is free before or 
after this lesson (see Figures 16.11)4 â¢ 
3.3 
PERMUTATION AND EVALUATION 
ALGORITHM 
The algorithm follows a general pattern of permutation algorithms 
related to the Bayesian Heuristic Approach (see, for example, section 
2.4) 
1. record the current schedule MokytojaiO 
by reading the data file Mokytojai[64][38], 
2. record the current number JO of teacher windows5, 
3. set the initial iteration number it = 0, 
4. set the current iteration number it= it+ 1, it< K, 
5. if it= K, stop and print the current schedule, 
6. set the initial teacher number i = -1, 
7. set the current teacher number i = i + 1, 
8. if i > 63 go to the step 4, 
9. generate uniformly distributed random number { E [0, 1], 
10. go to the step 7, if { < x, 
11. select a window of the teacher i, 
go to step 7, if there are no windows, 
12. select a convenient lesson of the i-th teacher, 
go to step 7, if there are no convenient lessons, 
13. make a permutation by exchanging the window class6 with the 
convenient one, 
14. test the feasibility conditions listed in section 3.1, 
go to the step 16, if the permutation is feasible, 
3The complete list is P for Monday, A for Thesday, T for Wednesday, K for Thursday, and 
N for Friday. 
4ln Figures 16.11 there are other symbols, too, such as Y, W, e.t.c .. These figures illustrate an 
old version of the algorithm (Marcinkevicius, 1999; Dvirmickiene and Zakasauskaite, 1998). 
Here the new version is described. 
5 A number of windows in the current schedule M okytojaiO. 
6 A window class is the class in the teacher window. 

OPTIMAL SCHEDULING 
285 
15. restore the feasibility by restoring the teacher window and go to 
the step 7, 
16. count the teacher windows in the permuted schedule, 
17. compare the number of the teacher windows in the current sched-
ule with the permuted one, 
18. replace the current schedule by the permuted one, 
if the current number of teacher windows is less then that in the 
permuted schedule, 
go to step 7 
The algorithm is very simple and natural. It mimics, in a sense, the 
usual ways to improve existing schedules. There are negative sides, 
too. There is no proof yet that the algorithm satisfies the convergence 
conditions (Mockus et al., 1997). To satisfy these conditions the 
probability to reach any schedule should be positive. Note, that 
replacing a window class by the convenient one, defined in the step 
thirteen, a new window for another teacher is opened, as usual. 
3.4 
SOFTWARE EXAMPLE 
The file 'Tvarka.java' (see web-site described in section 4.) imple-
ments an algorithm described in (Marcinkevicius, 1999; Dvirmickiene 
and Zakasauskaite, 1998). This algorithm does similar permutations 
but is different from the described one. Figure 16.6 shows a fragment 
of the 'Tvarka.java' file. 
One may change the initial data file 'mokytojai.txt' to the new file 
of the same size without recompiling. The default URL address 
shows the path of data file in the host server (see Figure 16.6). The 
URL address can be changed from the screen. One recompiles the 
Tvarka.java file, to change the size of the data file 'mokytojai.txt.' 
Users data files can be uploaded by a browser {Venclovas, 1999). 
Figure 16.7 shows an example using 
http: j joptimum.mii.ltjcgi- bin/ fupj fup.cgi?uzdl. Here the host 
server optimum.mii.lt applies the CGI script to allow users to load 
their data. 
3.5 
RUNNING SOFTWARE 
The GMJ1 and GMJ2 systems described in Chapter 8) are used for 
optimization of BHA parameters following these steps: 
-
select the method and its parameters (see Figure 16.8), 

286 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
public class Tvarka implements Task 
{ 
private int eMo=64; int sMo=38; 
private int firsttime=O; 
private int iii=O; 
private String url=new String 
(
11http://optimum.mii.lt;-jonas/school4j/mokytojai.txt 11 ); 
private String[][] Mokytojai=new String[eMo] [sMo]; 
private String[][] MokytojaiO=new String[eMo] [sMo]; 
private int Sdiena; 
private int sdiena; 
private double L0=1000.; 
public int K; 
public void customize (PropertyManager manager) 
{ 
manager.add (new IntProperty ( 11K number of repetitions 11 , 
new TvarkaProvider (this),1,100)); 
} 
Figure 16.6. 
A fragment of the school scheduling program. 
select the task 'Tvarka' and its parameters including the iteration 
number K, the lower and upper bounds for the randomization 
parameter x, the default value of x (see Figure 16.9), 
observe the results (see Figure 16.10). 
The output page shows the optimal munber of teacher windows. To 
observe the optimal schedule an additional 'analysis object' should 
be made. That is done clicking the button 'TvarkaAnalyser.' Figures 
16.11 show a fragment of school schedules. The top figure is a frag-
ment of the initial schedule7â¢ The bottom figure is the corresponding 
fragment of the schedule optimized using the 'Bayes1" method after 
five hundred iterations. 
7In this fragment, the window lessons and the convenient ones are denoted by letters different 
from those described in Section 3.3, a slightly different algorithm is implemented now. 

OPTIMAL SCHEDULING 
287 
ttp://opt~mum.m~~.lt/09~-b~n/fup/fup.Q91?uzdl 
Lo ding data file 
l es S-) 
wtth LOADED da 
Figure 16. 7. 
Uploading data file. 
---- --
. 
-
JlliÂ· 
Figure 16.8. 
Input window of method selection. 

288 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
Figure 16.g. 
Input window of school scheduling . 
Figure 16.10. 
...... 
16.â¢ -
Output window of school scheduling. 

OPTIMAL SCHEDULING 
289 
-
- --
-
Â·-- -------
-
----
~ ~~
-.. 
' 
. 
... , .... .,, 
lrl 
1P4 
lP'S 
I 
Â·~ 
â¢â¢ k 
â¢ 
2 
P212b 
PU2o 
.... ~ 
) 
Pll>. 
P4 v 
........ 
â¢ 
P:t'\a 
.. 
.. 
â¢ 
.. 
~ 
P27b 
P']"Jb 
rt7â¢ 
.. 
.. 
â¢ 
P2'1d ..,... 
P4 
z .. ,. 
â¢ 
, 
â¢ P'JlOâ¢ , .. ,. ~u. ,..,,. 
... 
â¢ 
t'JUI:t 
r)la ,.,. ...... r610c 
" 
â¢ 
.. 
Pnd 
.. 
PS7o .... P1'11o 
10 
... 
r11c:. 
P'l>d 
PUb 
.. 
.. 
.. 
II 
. ., .. 
â¢ ... ,, . ~ 
" ... 
ll 
fli.to 
Pl .. â¢ 
PUO. 
PS 
.. 
â¢ 
I 
1J 
" 
Pl 
........ 
.... ~. ...., .. 
.. ' 
rlLOa 
r:Ula 
P]llh 
P"Â·4lle 
~ .... Ht:lh 
.. ... 
â¢ 
.. -Â· 
â¢â¢'~â¢ 
.... , . .. 
.. 
r.to 
Pl11a 
P)Ub 
.. 
P'>U 
.. 
1'1 
â¢â¢ 
r 
.... ...., . 
.. 
â¢ â¢ 
ruo. . , .. 
P>W 
.. 
PSA. 
" 
I 
r. 
P'llo â¢ 
PUb ...... .. .. 
.. â¢ 
.. .. , 
lil'tJ .. t ..... 
.. 
â¢ â¢ 
~ 
r17b â¢Â»â¢ ,. .... 1"\lZo ... 10c r?uo â¢ 
c 
PUla 
P:U2& 
..,llo PUlb 
PSlOo HUd 
.. ... 
Q 
Pl 
Pl7a 
p 
.. .... 1,. Klh: 
.. 
c 
~lllâ¢ 
Â·~ 
r 
,. .... 
P'\100. ...... 
~ 
1'1h ..... 
Pno 
PO 'flo 
PS7d . 
" 
c 
"'"" ., .... 
,.,~. 
P4Sol 
.... .. ... 
.. 
c 
.. 
.. 
.. .. 
....... 
.. 
c 
..... 
Pltb 
" ,..,. .... ... r610â¢ 
.. 
0 
Â·~ ... 
y 
.. 
y 
y 
â¢ 
y ... 
" ..... "' 
,.,. ... 
.. 
.. 
.. 
.. 
.. 
" 
c 
.. 
.. 
.. 
.. 
.. 
I 
.. 
.. 
.. 
.. 
.. 
lOa 
P'\11 
PU14 
.. 
.. 
.. 
l<l 
'"" ... 
0 
.. . 
0 
.. 
0 
0 
.. 
.. 
0 
.. 
â¢ 
., ....... 
0 
o.a...-.n.e., ..... .w 
0 
â¢â¢ 
,., 
â¢â¢ 
.. 
â¢â¢ 
â¢â¢ 
R.~. 
0 
.. 
P"llOb . 
,,.. , ... 
(I 
... ~ 
.... ..,. 
0 
.. 
" 
rlllle 
at , K.a......_lc..,-..-.. 
0 
â¢â¢ 
.. 
.. 
1 ... -.o. 
0 
.. 
â¢â¢ 
... 
n 
n 
.. 
V.Luru._.. 
0 
Plio .... 
PJ 
.. 
0 
.. ,., .. 
P1'\o 
(I 
(I 
0 
PliOâ¢ 
P)ilâ¢ 
P'llll, PUll 
Pl4lla 
0 
.. 
.. .... . 
.. 
.. 
0 
Pl 
.. 
0 
P17b 
Pllâ¢ 
P] 
.. 
0 
,..,o. 
..lila 
(I 
.. 
0 
..... 
l"l7o ... 
0 
a 
.. 
Pl7o 
P'lJ"hJ 
.. 
0 
Pl '~ 
P.;i9a 
PJ1a 
a 
Pilla Pllla 
,.,12o 
~ 
a 
(I 
K.v ... u Â·-Â· 
0 
P'Ula ., ..... 
V, Ka.â¢lâ¢â¢ 
a 
â¢â¢â¢ 
.. 
H,J:a_~~J.~.l't.* 
0 
Â·Â·"' 
Pl,_o ,.,,.. 
P4'!4 
Ho 
'-Â·"" 
â¢â¢hiâ¢ 
a 
.. 
.. 
.. .... 
.. 
Â·-
....... .an._... 
0 
0 
0 
0 
0 
0 
0 
I:.T..,l,:u-.â¢ 
a 
y 
y 
y 
I:.T-.lyn.Jo,...._. 
c 
y 
PJ711b ...... 
P4 
â¢â¢ 
1),'\l'a&W.U.,â¢ 
.. 
.. 
.. 
.. 
.. 
.. 
.. 
.. 
a 
. 
â¢ 
.. 
.. 
â¢ 
â¢ 
.. 
.. . . . . 
â¢ 
f'l10b 
Plllet 
PllOv 
PC10â¢ 
..... llb 
" 
.. 
0 
.. 
.. 
.. 
.. 
.. 
.. 
0 
PI 
(I 
(I 
â¢ 
.. 
.. 
.. 
, 
0 
â¢ 
.. 
.. 
.. 
.. 
.. 
...... 
Â·Â·]Â·Â·Â·Â· 
-...,., ... 
Figure 16.11-
A fragment of school schedules, the initial schedule (the top figure), 
the optimized schedule (the bottom figure). 

Chapter 17 
SEQUENTIAL STATISTICAL DECISIONS 
MODEL, "BRIDE PROBLEM" 
1. 
INTRODUCTION 
Most of the decisions in a personal life and in organizations are made 
sequentially. That means that, at any given moment, one either makes 
the final decision, or postpones it hoping for better times. Statistical 
part of sequential decisions represents uncertainties of future events and 
a limited reliability of our observations. 
The Bride problem is a good example of sequential statistical decisions 
{Wald, 1947; Wald, 1950). The dynamic programming is a conventional 
technique to optimize sequential decisions (Bellman, 1957). Applying 
the dynamic programming to specific problems, one develops specific 
algorithms, as usual. The algorithms, similar to these of bride's decision 
making, can be applied choosing the optimal time to buy durable goods, 
such as cars, houses, computers, to start new business, e.t.c .. 
Typical industrial applications of sequential decisions are the optimal 
stopping rules. For example, one can consider stopping of some nuclear 
plant as a marriage. One can evaluate stopping cost directly. Risks 
involved in running the plant, when one observes some deviations from 
the normal routine, can be considered as risks of waiting for the next 
proposal. That means that one hopes for something better while risking 
a bad outcome. 
291 

292 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
2. 
AVERAGE UTILITY 
The Bride problem is to maximize the average utility of marriage 
by the optimal choice of a groom. Denote the actual goodness of a 
groom i by WiÂ· Denote by Si the bride's impression about the groom 
i. p(wi is a prior probability density of goodness WiÂ· 
p8 (silwi) is a 
probability density of impression SiÂ· Assume that goodness of different 
grooms are independent and identically distributed. This means that a 
prior probability density of goodness is 
p(Wi,Wj) = p(wi)P(Wj), 
(17.1) 
p(wi) = p(wj) = p(w). 
Suppose that impressions about the goodness of grooms are independent 
and identically distributed. Then the probability density of an impres-
sion si, given the goodness Wi, is 
Ps(Si, Sjlw) = Ps(silw)ps(sjlw), 
Ps(silw) = Ps(sjlw) = p(slw). 
Assume the Gaussian prior probability density of goodness 
p(w)= 
1 
e-1/2(w~;o)2 
v'21rao 
(17.2) 
{17.3) 
Here ao is a prior variance and ao is a prior mean of goodness. For 
example, ao > 0 shows an optimistic bride. ao < 0 shows that a bride 
is pessimistic. Suppose, that a prior probability density of bride impres-
sions is 
( I ) 
1 
-1/2(!.=.!!1.)2 
p sw = rn= e 
17 
â¢ 
v27ra 
(17.4) 
Here a 2 is a variance of impressions around the true goodness w. 
Assume that both the groom goodness and the bride impression are 
random variables depending on many independent factors. This ex-
plains the Gaussian distributions (17.3) and (17.4). One defines a pos-
terior probability density of goodness w, given the impression s, by the 
Bayesian formula (Bayes, 1783) 
( I ) _ p(slw)p(w) 
pws-
(). 
Ps 8 
{17.5) 
Here 
Ps(s) = /_: p(slw)p(w)dw. 
{17.6) 

SEQUENTIAL DECISIONS 
293 
3. 
SINGLE-MARRIAGE CASE 
Denote by di the bride's decision about the groom i 
dÂ· = { 1, 
if bride marry the groom i, 
z 
0, 
otherwise. 
Suppose that 
(17.7) 
(17.8) 
The last condition means that brides marry, and marry only once. For-
mally condition (17.8) defines the set of feasible decisions when the nth 
groom proposes 
D 
_ 
{ 0 and 1, 
if 9N-n = 0 
N-n -
0 
"f 
1 
' 
1 9N-n = 
, 
Here 9N-n is the marriage index 
N-n-1 
9N-n = 1- L 
i=l 
(17.9) 
(17.10) 
The marriage index is zero, if the bride is marred. This prevents repeated 
marriages. 
3.1 
BELLMAN'S EQUATIONS 
The expected utility function is u(s). Here s is the impression made 
by the successful groom1. 
u(s) = f: wp(wis)dw. 
(17.11) 
Denote by uN(s) the expected utility function, if the impression of the 
last groom is s 
UN(s) = L: wp(wis)dw. 
Comparing (17.11) and (17.12) one observes that 
u(s) = uN(s). 
1 By the "successful groom" we mean the groom that a bride marries. 
(17.12) 
(17.13) 

294 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
This follows from independence assumptions (17.1} and {17.2). Denote 
by UN- 1 the expected utility, if the impression of the (N- 1}th groom 
iss and a bride is making the optimal decision d = dN-1(s} E DN-1 
Here 
UN_l(s} = max(du(s} + (1- d}uN}, 
d 
dN-1(s} = argmax(du(s} + (1- d}uN}Â· 
d 
(17.14} 
(17.15} 
(17.16} 
Following the same pattern, we define the expected utility, if the impres-
sion of the (N- n}th groom is s and the bride is making the optimal 
decision d = dN-n(s} E DN-n 
UN-n(s) = max(du(s} + (1- d}UN-n+d, 
(17.17} 
d 
dN-n(s) = argmax(du(s) + (1- d)uN-n+l)Â· 
(17.18) 
d 
Here 
(17.19} 
Note, that the utility u(s) of accepting a proposal in expressions (17.17) 
and (17.18} is a function only of impression s. It does not depend on 
the proposal number N - n. That follows from independence assump-
tions (17.1} and (17.2). Solving these recurrent equations one defines 
the sequence of optimal decision functions dN-n(s) E DN-n and the 
expected utilities UN-n(s). This should be done for all possible impres-
sions s E ( -oo, oo) and for all numbers n = 1, ... , N - 1. One cannot do 
that in continuous case. Therefore, one uses a discrete approximation 
3.2 
DISCRETE APPROXIMATION 
From expressions (17.11) and {17.12), replacing the integrals by sums 
one obtains that 
K 
UN(s) = u(s) =2M/ K L wkp(wkls). 
(17.20) 
k=1 
From expression (17.16) 
K 
UN= 2M/K L UN(sk)Ps(sk)Â· 
(17.21) 
k=1 

SEQUENTIAL DECISIONS 
295 
From expression ( 17.19) 
K 
UN-n+l = 2M/K L UN-n+l(sk)Ps(sk)Â· 
{17.22) 
k=l 
Here Wk E [-M, M], w1 = -M, WK = M and sk E [-M, M], s1 = 
-M, SK = M. That is a discrete approximation of the recurrent 
equations. All possible impressions sk E [-M, M] and all numbers 
n = 1, ... , N - 1 are considered. One sets the number of iterations K by 
the accuracy needed. 
The results are sequences of optimal decision functions dN-n(sk) and 
the expected utilities UN-n(sk)Â· These sequences are stored in a set 
of arrays which define how the optimal decisions d and the expected 
utilities u depend on the possible impressions sk, k = 1, ... , K. Doing 
this, one avoids the repeated calculations. Large arrays is a disadvantage 
of this procedure. 
3.3 
INCLUDING THE WAITING COST 
The waiting losses are important in many real-life sequential decision 
problems. Denote by c the loss of waiting for the next groom. Including 
this parameter into Bellman equations one obtains 
UN-l(s) = max(duN(s) + {1- d)(uN- c)), 
d 
dN-l(s) = argmax(duN(s) + {1- d)(uN- c)). 
d 
(17.23) 
(17.24) 
In a similar way one defines the expected utility if the impression of 
the (N- n)-th groom iss and the bride is making the optimal decision 
dN-n(s) 
UN-n(s) = max(duN(s) + (1- d)(uN-n+l- c)), 
d 
dN-n(s) = argmax(duN(s) + {1- d)(uN-n+l- c)). 
d 
The other expressions remains the same. 
3.4 
NON-LINEAR CASE 
(17.25) 
(17.26) 
Expression {17.12) was defined assuming the linear bride's utility func-
tion. It was supposed that bride's utility is equal to the goodness of 

296 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
groom u(w) = w. In the real life, utility functions are nonlinear (see 
chapter 13) and non-convex, as usual. Then expression {17.12) is re-
placed by this integral 
UN(s) = /_: u(w)p(wls)dw. 
(17.27) 
4. 
MULTI-MARRIAGE CASE 
Condition {17.8) implies that brides marry and marry only once. No 
divorce is permitted. That is wrong, if the "marriage" represents baying 
a Personal Computer {PC). We illustrate this by a simple "Buy-a-PC" 
example. 
4.1 
" BUY -A-PC" EXAMPLE 
Define PC parameters by a vector 9 = (91, 92, 93). Here 91 is the speed 
of CPU in M Hz, 92 is the volume of RAM in M B, and 93 is the volume 
of HD in GB. Express a subjective utility of PC by the weighted sum 
w = a191 + a292 + a393Â· Here ai are expressed in$ per unit. 
Assume that a prior probability density of PC utilities is Gaussian 
1 
e-1/2( w:o"'t )2 
Pt(w) = --==-
-
v"21ruo 
Â· 
{17.28) 
Here uo is a prior variance and O:t is a prior mean of PC utilities. Suppose 
that uo =constant and that O:t = o:o + o:1t. This means that expected 
PC utility is increasing linearly. The expected diversity remains the 
same. 
The PC price in $ is denoted by l. Suppose that the price of PC 
depends linearly on the weighted sum 
{17.29) 
Here parameters bi are defined in $ per unit and reflect the market prices 
of CPU, RAM, and HD. Expressing the price l as a function of utility 
w: 
l =how. 
{17.30) 

Here 
SEQUENTIAL DECISIONS 
297 
ho = b1g1 + ~g2 + b3g3 . 
a1g1 + a2g2 + a3g3 
(17.31) 
Asswne that one observes the utility w exactly. This means that the 
impressions= w and that impression errors u = 0 in expression (17.2). 
That simplifies the problem. 
4.2 
BELLMAN'S EQUATIONS 
The expected utility function is u(w, q). Here w is the utility of a 
new PC. q is the utility of the old PC, to be replaced by the new one. 
Consider a "horizon" of N years. During a year one can change PC only 
once, if one wishes. 
Denote by UN(w, q) the maximal expected utility in the yearN 
uN(w, q) = max(dw + {1- d)uN+l)Â· 
(17.32) 
d 
There are two possible decisions d = {0, 1}. The decision d = 1 means 
to bay a new PC. The utility of the new PC is w. The utility of the old 
one is q. The utility of the decision d = 0 to keep the old PC is u = q + l. 
Here l is the price of the new PC defined by {17.30). It is asswned that 
we abandon the old PC as soon as we obtain the new one. Therefore, 
one "wins" the price l of the new PC by using the old PC. The optimal 
decision 
dN(r) = { 1, 
~fr ~ 0, 
0, 
1f r < 0. 
(17.33) 
Here w = WN is the utility of the new PC available in the year N. 
UN+l = QN + lN is the utility of keeping the old PC in the yearN. 
r =WN- UN+l 
(17.34) 
is the difference between the utility WN of baying new PC and the utility 
UN+l = QN + lN of keeping the old one. 
Denote by UN-l(w, q) the maximal expected utility in the yearN -1. 
UN-l(w, q) = max(dw + (1- d)uN(q). 
(17.35) 
d 
Here UN(q) is the maximal expected utility in the yearN, if the utility 
of the old PC is q. 
UN(q) = E UN(w,q) = i: 
UN(w,q)pN(w)dw. 
(17.36) 

298 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
PN(w) is a prior probability density of w defined by expression (17.28) 
at a time t = N. 
q = {WN-1, ifr2':0, 
QN-1, 
if r < 0. 
(17.37) 
r = WN-1- UN(q) is the difference between the utility WN-1 of baying 
and the expected utility UN(q) of keeping . 
The parameter r depends on two variables w and q. Therefore, the 
"One-Step-Ahead" approximation is suggested where r = WN-1-QN-1-
l N -1Â· Here one assumes that the next step is the last one. Thus, r is 
expressed by the last step formula (17.34). The approximation error 
depends on many factors. One estimates it by experimentation. 
The optimal decision 
dN_ 1(r) 
= 
{ 1, 
if r 2': 0, 
0, 
if r < 0. 
(17.38) 
Following the same pattern, one defines the maximal expected utility in 
(N- n)th year 
where 
UN-n(w, q) = max(dwN-n + (1- d)uN-n+1(q)), 
d 
UN-n+I(q) = E UN-n+I(w, q) = 
l: 
UN-n+1(w,q)PN-n+I(w)dw. 
(17.39) 
(17.40) 
Here the utility of new PC is w, and the utility of the old one is q 
The optimal decision 
q = 
{ WN -I, if r 2': 0, 
QN-1, 
if r < 0. 
d 
( ) = 
{ 1, 
if r 2': 0, 
N-n r 
0 
"f 
0 
, 
1 r < . 
(17.41) 
(17.42) 
The optimal decision dn ( r) is a function of difference r 
w N -n -
UN-n+I(q) that depends on two parameters w and q. Therefore, one 
defines it as a function of critical pairs (w, q) depending on timet= n. 
Solving these recurrent equations one defines the sequence of optimal 
decision functions dN -n (r) and the expected utilities UN -n (w, q). This 
should be done for all possible values of wand q. 

SEQUENTIAL DECISIONS 
299 
One applies the discrete approximation such as in Section 3.2. The 
optimal decision functions depend on two variables wand q. Therefore, 
one needs K times more calculations to obtain the same accuracy as in 
the single marriage case (see Section 3.2). 
The "One-Step-Ahead" approximation, assuming that r = WN-n-
QN-n -lN-n, reduces the computing time to a level of single marriage 
case. However, one needs to estimate the approximation error. 
To solve real life problems the "directly unobservable" factors should 
be included into the "Buy-a-PC" modeL For example , one can esti-
mate the expected life-span T(s) of PC, given the impression s, by the 
Bayesian formula 
T = /_: Tp( Tl s )dT, 
(17.43) 
( I ) _ p(siT)p(T) 
pTS-
(). 
Ps S 
(17.44) 
Here T is the life-span of PC and s is the user's impression about its 
reliability. The impression s depends on the warranty, the reputation of 
the manufacturer and on some subjective factors, too. 
5. 
SOFTWARE EXAMPLES 
Two interactive versions of the Bride problem are implemented as 
Java applets. These, and the corresponding C++ software are on web-
sites (see section 4.). 
Figure 17.1 shows the input window of the Bride problem (Kajokas, 
1997) 
Figure 17.2 shows simulated results of the "optimal marriage". 
Figure 17.3 shows the optimal decision function defining how the critical 
"goodness" of a groom depends on his number. 
Figure 17.4 shows the help window of the "Buy-a-Car" version of the 
Bride problem (Mikenas, 1998). 
Figure 17.5 shows the input window of the "Buy-a-Car" problem. 
Figure 17.6 shows the output window of the "Buy-a-Car" problem. 
Figure 17.7 shows the optimal decision function of the "Buy-a-Car" prob-
lem. 
The "Buy-a-Car" algorithm is just a first approximation. It should 
be improved. For example, improving the By-a-PC model one should 

300 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
)( 
elp 
1100 
Dis lbu 
no 
~.25 
~.OS 
r d solutions 
c d ss of 
blue 
.I 
00 
;J 
orossk> s 
, 
Or 
n bet..,..e r l:r 
.J 
br 
gr m goodn 
Qu 
Figure 17.1. 
The input window of the Bride problem . 
-â¢ O . Sl2909~9:!6Hl9:Z8 r 
...... ~ '
0.~ 
Figure 17.2. 
The result of statistical simulation of the Bride problem. 
â¢ remove the "single marriage" condition (17.8), 
â¢ add "Change-a-Car" cost, 
â¢ express desirable car properties (see Figure 17.5), using conditions of 
Pareto optimality (Mockus, 1989b), 
â¢ extend the property list by including properties that are not directly 
observable, such as the reliability of a car, 
â¢ keep the "No-Return" rule. 

SEQUENTIAL DECISIONS 
301 
\, 
\ 
0.0 
100 
-0 .&999999999999999 
jJa~Â·a Apple! Wi dow 
Figure 17.3. 
The optimal decision function of the Bride problem. 

302 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
sers el ct seven car param ters 
such as 
1 Color, 
z Type, 
3 Fuel, 
4 Engine, 
5 Cabin. 
6 Pnce. 
7 Number or Doors 
Users select par meters by mar ng 
users may s lee 
number or cars 
choos (from 1 :o 1 00) 
sers may select tne vanance o rmpress1ons (nuo 0.1 1 0.01). and the cost o warbng 
0 er.,.lse these parameters are d fined by defaul va.lu s 
To start the program. press the buton 'Start' 
Tn 
opens he r suit wtndow lnformrng about the pre~ rable and 
ne best car 
The buHon 'Graph'. 
open the graphrcal rm ge 
Red point denote Imp es Ions obt~1nea by Mon e Carlo slmula!Jon 
Green line denotes the opt mal dec1s1on functton 
Blue poin shows 
e optrm 
solutJon 
Figure 17.4. 
The help window solving the "Buy-a-Car" problem. 
"No-Return" means that one cannot return to a situation which he or 
she rejected previously. The "No-Return" rule is essential in the dy-
namic programming. One considers "Return" cases in the framework of 
discrete or non-linear programming. That requires more computing, as 
usual. 

.. 
Figure 17. 5. 
SEQUENTIAL DECISIONS 
303 
( ..... 
1.5111' 
I~ 
The input window solving the "Buy-a-Car" problem. 

304 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
Warning: Applet Window 
The optimal decision Nr.13 
1 . Color light 
2. Type sedan 
3. Fuel gasoline 
4. Engine less than 1 .5 ltr 
5. cabin light 
6 . Price up to 5 ,000 
7. 
2 
.A.ctual quality: 1 .0 
Impression: 1 .0324 991 41 242083 
The best car Nr. 13 
.A.ctual quality: 1 .0 
ln1pression: 1 .0324 991 41 242083 
Figure 17.6. 
The output window of the "Buy-a-Car" problem. 

SEQUENTIAL DECISIONS 
305 
Warning: Applet Window 
a 
D 
a 
D 
D 
D 
D 
D 
a 
D 
a 
a 
D 
a 
D 
a 
D 
QJ 
a 
D 
D 
Figure 17. 7. 
The optimal decision function of the "Buy-a-Car" problem. 

References 
Adamiecki, K. (1931). Harmonygraph. Przeglad Organizaciji. 
Androulakis, I. and Venkatasubramanian, V. (1991). A genetic algo-
rithm: Framework for process design and optimization. Computers in 
Chemical Engineering, 15:217-228. 
Baker, K. R. (1974). Introduction to Sequencing and Scheduling. John 
Wiley & Sons, New York. 
Bayes, T. (1783). An essay towards solving a problem in the doctrine of 
chances. Phil. Transactions of Royal Society, 53:37G-418. 
Bellman, R. (1957). Dynamic Programming. Princeton University Press, 
Princeton, New Jersey. 
Biggs, M. C. (1975). Constrained minimisation using recursive quadratic 
programming: some alternative subproblem formulations. In Towards 
global optimisation. North Holland, Amsterdam. 
Brouwer, L. (1912). Uber abbildung von mannigfaltigkeiten. Math. Ann., 
71:97-115. 
Browder, F. (1968). The fixed point theory of multivalued mappings in 
topological vector spaces. Math. Ann., 177:283-302. 
Cheung, Y.-W. (1993). Long memory in foreign exchange rates. Journal 
of Business and Economic Statistics, 1:93-101. 
307 

308 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
Cheung, Y.-W. and Lai, K. (1993). Fractional co-integration analysis of 
purchasing power parity. Journal of Business and Economic Statistics, 
1:103-112. 
DeGroot, M. (1970). Optimal Statistical Decisions. McGraw-Hill, New 
York. 
Diaconis, P. {1988). Bayesian numerical analysis. In Statistical Decision 
Theory and Related Topics, pages 163-175. Springer Verlag. 
Diebold, F. X. and Rudebusch, G. D. (1989). Long memory and persis-
tence in aggregate output. Journal of Monetary Economics, 24:189-
209. 
Dixon, L. and Szego, G. (1978). Towards global optimisation 2. North 
Holland, Amsterdam. 
Dvirmickiene, D. and Zakasauskaite, A. {1998). School scheduling prob-
lem. Technical report, Vytautas Magnus University, Faculty of Infor-
matics, Lithuania, Kaunas. (in Lithuanian). 
Dzemyda, G. and Senkiene, E. (1990). Simulated annealing for parame-
ter grouping. In Transactions. Information Theory Statistical Decision 
Theory Random Processes, pages 373-383, Praque. 
Dzemyda, G., Vaitiekunas, F., Valincius, G., Vysniauskas, J., Juzefovic, 
D., Kurcerenko, V., Kuziakin, 0., and Filatov, N. (1984). Solution of 
problems of optimal design and selection of model parameters using 
the package of applied programs minimum. Optimal Decision Theory, 
Institute of Mathematics and Cybernetics, Vilnius, Lithuania, 10:77-
98. (in Russian). 
Ermoljev, Y. and Wets, R.-B. {1988). Numerical Techniques for Stochas-
tic Optimization. Springer-Verlag, Berlin- New York-London. 
Fishburn, P. (1964). Decision and Value Theory. Wiley, New York. 
Floudas, C., Pardalos, P., Adjiman, C., Esposito, W., Z.H. Gu, u., Hard-
ing, S., Klepeis, J., Meyer, C., and Schweiger, C. {1999). Handbook of 
test problems in local and global optimization. Kluwer Academic Pub-
lishers, Dordrecht-Boston-London. 

References 
309 
Forgo, F., Szep, J., and Szidarovszky, F. {1999). Introduction to the The-
ory of Games. Kluwer Academic Publishers. 
Fox, R. and Taqqu, M. {1986). Large-sample properties of parameter es-
timates for strongly dependent stationary gaussian time series. Annals 
of Statistics, 14:517-532. 
Friedman, A. {1971). Dfferential Games. Wiley-Interscience, New York. 
Galperin, E. and Zheng, Q. {1991). Global Solutions in Optimal Control 
and Games. Presses de l'Universite du Quebec a Montreal, Montreal. 
Geweke, J. and Porter-Hudak, S. {1983). The estimation and application 
of long memory time series models. Journal of Time Series Analysis, 
4:221-238. 
Glover, F. {1994). Tabu search: improved solution alternatives. In Math-
ematical Programming. State of the Art 1994, pages 64-92. University 
of Michigan. 
Gnedenko, B. and Kovalenko, I. {1987). Introduction to the Theory of 
Queuing. Nauka, Moscow. {in Russian). 
Goldberg, D. E. {1989). Genetic Algorithms in Search, Optimization, 
and Machine Learning. Addison-Wesley, Reading, MA. 
Greicius, A. and Luksys, R. {1999). Conversion from c++ to java of 
the flow-shop model. Technical report, Vytautas Magnus University, 
Faculty of Informatics, Kaunas, Lithuania. 
Grybauskas, M. {1998). Global minimizer for java {gmj) version 1.1. 
Technical report, Institute of Mathematics and Informatics, Akademi-
jos 5, Vilnius, Lithuania. 
Hajdu, M. {1997). Network Scheduling Techniques for Construction Project 
Management. Kluwer Academic Publishers. 
Hajek, 0. {1975). Pursuit Games. Academic Press, New York. 
Helman, P., Moret, B., and Shapiro, H. {1993). An exact characterization 
of greedy structures. SIAM Journal of Discrete Mathematics, 6:274-
283. 

310 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
Herings, P. {1994). A gobally and universally stable price ajustment pr<>-
cess. Technical Report 9452, Center for Economic Research, Tilburg 
University, The Netherlands, Tilburg. 
Himmelblau {1972). Applied Nonlinear Progmmming. McGraw-Hill. 
Roland, J. {1975). Adaptation in Natuml and Artificial Systems. Univer-
sity of Michigan Press, An Arbor, MI. 
Horst, R., Pardalos, P. M., and Thoai, N. V. {1995). Introduction to 
Global Optimization. Kluwer Academic Publishers, Dordrecht. 
Hosking, J. {1981). Fractional differencing. Biometrika, 68:165-176. 
Hosking, J. ( 1984). Modeling persistence in hydrological time series using 
fractional differencing. Water Resources Research, 20:1898-1908. 
Isaacs, R. {1965). Dfferential Games. Wiley, New York. 
Janacek, G. {1982). Determining the degree of differencing for time series 
via the long spectrum. Journal of Time Series Analysis, 3:177-188. 
Kajokas, V. {1997). Javal.1 software for the bride problem. Technical 
report, Kaunas Technological University, Faculty of Informatics, Kau-
nas, Lithuania. {in Lithuanian). 
Kakutani, S. (1941). A generalization of brouwer's fixed point theorem. 
Duke Journal of Mathematics, 8:457-459. 
Ko, K.-I. {1991). Complexity Theory of Real Functions. Birkhauser, Boston. 
Koop, G., Ley, E., Osiewalski, J., and Steel, M. F. {1994). Bayesian anal-
ysis of long memory and persistence using arfi.ma models. Technical 
report, Department of Economics, University of Toronto. 
Krapauskas, M. {1997). Javal.O software for global optimization. Tech-
nical report, Kaunas Technological University, Faculty of Informatics, 
Kaunas, Lithuania. {in Lithuanian). 
Krasovski, N. {1970). Game Problems on the encounter motions. Nauka, 
Moscow. {in Russian). 

References 
311 
Kushner, H. {1964a). A new method of locating the maximum point of 
an arbitrary multi-peak curve in the presence of noise. J. of Basic 
Engineering, 86:97-100. 
Kushner, H. {1964b). A versatile stochastic model of a function of un-
known and varying form. J. of Mathematical Analysis and Applica-
tions, 5:150-167. 
Kuzminaite, V. (1999). Conversion from c++ to java of the algorithm 
of the arma model. Technical report, Vytautas Magnus University, 
Faculty of Informatics, Kaunas, Lithuania. 
Li, W. and McLeod, A. I. {1986). Fractional time series modeling. Bio-
metrica, 73:217-221. 
Liu, J. (1989). On the existence of general multiple bilinear time series. 
Journal of Time Series Analysis, 10:341-355. 
Malisauskas, V. (1998). Software for the knapsack problem. Technical 
report, Kaunas Technological University, Faculty of Informatics, Kau-
nas, Lithuania. (in Lithuanian). 
Marcinkevicius, V. (1999). Improving the school scheduling problem. 
Technical report, Kaunas Technological University, Faculty of Infor-
matics, Kaunas, Lithuania. (in Lithuanian). 
Margelevicius, M. (1999). Conversion from c++ to java of the algorithm 
of nonlinear programming. Technical report, Kaunas Technological 
University, Faculty of Informatics, Kaunas, Lithuania. 
Matulevicius, R. (1999). Differential game model. Technical report, Vy-
tautas Magnus University, Faculty of Informatics, Kaunas, Lithuania. 
Mavridou, T., Pardalos, P., Pitsoulis, L., and Resende, M. (1998). A 
GRASP for the biquadratic assignment problem. European Journal 
of Operations Research, 105:613-621. 
Michael, J. (1976). The Computation of Fixed Points and Applications. 
Springer-Verlag, Berlin. 

312 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
Mikenas, M. (1998). Java1.1 software for the bay-a-car version of the 
bride problem. Technical report, Kaunas Technological University, 
Faculty of Informatics, Kaunas, Lithuania. (in Lithuanian). 
Mockus, A. and Mockus, L. (1990). Design of software for global opti-
mization. Informatica, 1:71-88. 
Mockus, J. (1967). Multi-modal Problems in Engineering Design. Nauka, 
Moscow. (in Russian). 
Mockus, J. (1989a). Bayesian approach to global optimization. Kluwer 
Academic Publishers, Dordrecht-London-Boston. 
Mockus, J. (1989b). Bayesian approach to global optimization and ap-
plication to constrained and multi-objective problems. In Abstracts, 
the Fifth International Conference on Stochastic Programming in Ann 
Arbor, August 13-18, 1989. 
Mockus, J. (1997). A set of examples of global and discrete optimization: 
application of bayesian heuristic approach ii. Informatica, 8(4):495-
526. 
Mockus, J., Eddy, W., Mockus, A., Mockus, L., and Reklaitis, G. (1997). 
Bayesian Heuristic Approach to Discrete and Global Optimization. 
Kluwer Academic Publishers, Dordrecht-London-Boston. 
Mockus, J. and Soofi, A. (1995). The long-run economic relationships: 
An optimization approach to fractional integrated and bilinear time 
series. INFORMATICA, 6:61-70. 
Nash, J. (1950). Equilibrium points inn-person games. Proc. Nat. Acad. 
Sci. USA, 36:48-49. 
Nash, J. (1951). Noncooperative games. Annals of Mathematics, 54:286-
295. 
Nemajunas, I. and Remeikis, N. (1999). Conversion from c++ to java 
of the school scheduling model. Technical report, Vytautas Magnus 
University, Faculty of Informatics, Kaunas, Lithuania. 
Neuman, J. and Morgenstern, 0. (1953). Theory of Games and Economic 
Behavior. Princeton University Press, Princeton. 

References 
313 
Owen, G. (1968). Game Theory. W.B. Saunders, Philadelphia, PA. 
Perlibakas, V. (1999). Software for the walras problem. Technical re-
port, Kaunas Technological University, Faculty of Informatics, Kau-
nas, Lithuania. (in Lithuanian). 
Petrikis, S. and Juodgalvyte, J. (1997). Java1.1 software for the portfolio 
problem. Technical report, Vytautas Nagnus University, Faculty of 
Informatics, Lithuania, Kaunas. (in Lithuanian). 
Petrosyan, L. (1985). Cooperative Dfferential Games. Tomsk University 
Publishing, Tomsk, Russia. (in Russian). 
Petrosyan, L. (1993). Dfferential Games of Pursuit. Worls Scientific Pub-
lishing Co., River Edge, N J. 
Rao, T. S. and Gabr, M. (1984). An introduction to bispectral anal-
ysis and bilinear time series models. In Lecture Notes in Statistics, 
number 24. Springer- Verlag, Berlin. 
Rastrigin, L. (1968). Statistical Methods of Search. Nauka, Moscow. (in 
Russian). 
Raudys, A. and Mockus, J. (1999). Comparison of arma and multi-
layer perceptron based methods for economic time series. Informatica, 
10(2):231-243. 
Rodin, E. Y. (1987). A pursuit-evasion bibliography. International Jour-
nal of Computers and Mathematics with Applications, 13:275-340. 
Rosenmuller, J. (1981). The Theory of Games and Markets. North-
Roland, Amsterdam. 
Saltenis, V. (1971). On a method of multi-extremal optimization. Au-
tomatics and Computers (Avtomatika i Vychislitelnayya Tekchnika), 
(3):33-38. (in Russian). 
Saltenis, V. (1989). Analysis of Structure of Multi-modal problems. Mok-
slas, Vilnius, Lithuania. (in Russian). 

314 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
Schittkowski, K. (1985). A fortran subroutine solving constrained non-
linear programming problems. Annals of Operations Research, 5:485-
500. 
Senkiene, E. (1980). Properties of conditional mean and variance of 
the wiener process in the presence of noise, and the convergence of 
bayesian optimization algorithms. In Theory of Optimal Decision. In-
stitute of Mathematics and Cybernetics, Akademia Nauk Lithuanian 
SSR, Vilnius, Lithuania. (in Russian). 
Sobolj, I. (1967). On a systematic search in a hypercube. SIAM Journal 
on Numerical Analysis, 16:790-793. 
Sowel, F. (1992). Maximum likelihood estimation of stationary univari-
ate fractionally integrated models. Journal of Econometrics, 53:165-
188. 
Tiesis, V. (1975). The method of variable metrics for local optimiza-
tion of functions of many variables with rectangular constraints. In 
Proceedings of the Conference on Computers, pages 111-114, Kaunas, 
Lithuania. (in Russian). 
Tijms, H. (1994). Stochastic Models. An Algorithmic Approach. Wiley, 
New York. 
Torn, A. and Zilinskas, A. (1989). Global optimization. Springer-Verlag, 
Berlin. 
Torn, A. A. (1990). Topographical global optimization. Technical report, 
Abo Akademi University, Dept. of Computer Science, Turku, Finland. 
Venclovas, A. (1999). Applying cgi scripts to upload users data in school 
scheduling models implemented in java. Technical report, Vytautas 
Magnus University, Faculty of Informatics, Kaunas, Lithuania. 
von Neumann, J. and Morgenstern, 0. (1953). Theory of Games and 
Economic Behaviour. Princeton University Press, Princeton, New Jer-
sey. 
Wald, A. (1947). Sequential Analysis. J. Wiley, New York. 
Wald, A. (1950). Statistical Decision Functions. J. Wiley, New York. 

References 
315 
Walras, L. (1874). Elements d'Economie Politique Pure. LKorbaz and 
Company, Lausanne. 
Yin-Wong, C. and Lai., K. (1993). Long-run purchasing power parity 
during the recent float. Journal of International Economics, 34:181-
192. 

Index 
active objects, 57 
Contract-Vector, 115 
convex function, 128 
electrical tools, 23 
external factors, 193 
financial data, 187 
knapsack problem, 6 
missing resource, 123 
risk function, 45 
stochastic optimization, 131 
variable metrics, 46 
activation function, 198 
additive functions, 46 
AIX, 64 
analysis object, 88 
Analysis of Results, 92 
ANN model, 187 
applet, 75, 85 
application, 85 
Approximate Algorithms, 13 
ARFIMA, 199 
ARMA model, 38, 187 
ARMA models, 188 
arriving customers, 117, 159 
Artificial Neural Network, 187 
asymptotic properties, 5 
Auto Regressive, 187 
auxiliary calculations, 36 
average case analysis, 3 
average error, 4 
average person, 176 
average prediction results, 188 
average profits, 117 
average service time, 246 
Average Utility, 292 
average waiting time, 117, 126, 159 
averse risk, 175 
317 
batch scheduling, 11 
Bayesian algorithm, 22 
Bayesian Aproach, 3 
Bayesian decisions, 5 
Bayesian formula, 292 
Bayesian Heuristic Approach, 4, 5, 11 
Bayesian method, 22, 34 
Bayesian risk, 3 
Bellman's Equations, 293, 297 
Bilinear model, 187 
Bilinear Models, 199 
bilinear problem, 146 
Bimatrix Game, 143 
Bimatrix Game Algorithm, 155 
bimatrix games, 155 
Boolean parameters, 206 
Boolean variables, 12 
Branch & Bound, 12 
Bride Problem, 291 
browser, 40, 75 
browsers, 82, 85 
C++, 21 
C++ Implementation, 22 
C++ Version, 63 
Call Center Model, 245 
Call Center Scheduling, 273 
call rate, 204 
Call Rate Estimate, 249 
Call Rate Predictions, 257 
call.rates prediction, 187 
call-center, 188 
changing environment, 206 
class, 87 
clustering method, 35 
clustering method , 46 
coalition, 120 
Common Blocks, 49 

318 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
Common Waiting, 253 
complexity, 188 
composite laminates, 5, 38 
Computing Environment, 37 
conditional expectation, 3, 131 
conditional variance, 4 
constant-sum game, 120 
constrained optimization, 33 
constraints, 55, 57, 75 
convergence, 13, 76 
convergence conditions, 4 
convergence in probability, 45 
convolution filter, 132 
Core, 119 
crossover, 18 
crossover rate, 21 
Daily Vector Prediction, 266 
decision making, 291 
deterministic, 55 
differential amplifiers, 5 
Differential Game, 151 
Direct Bayesian Approach, 3, 4 
Direct Search Algorithm, 145 
Discrete Approximation, 294 
discrete optimization, 39 
discrete variables, 4 
distributed computing, 40 
dominant coalition, 120 
DOS, 37 
Duel Problem, 151 
dynamic competition, 162 
Dynamic Nash Model, 161 
dynamic presentation, 41 
dynamic programming, 291 
engineering design, 38 
environment protection, 143 
equality constraints, 55 
equilibrium, 118 
essential game, 120 
Estimate of Scales, 259 
Event Generation, 250 
event scale model, 261 
exact algorithms, 3 
Exchange Rate Prediction, 187 
exchange rates, 188 
Exhaustive Search, 12 
existence conditions, 119 
expected deviation, 5 
expected utilities, 153 
expected utility, 178, 294, 297 
expert knowledge, 6 
expert opinion, 6 
external factors, 257 
extrapolation method, 34 
extremal experiments, 5, 39 
false local optima, 131 
filtering noise, 131 
fitness proportional reproduction, 18 
fitting parameters, 207 
fixed point, 127 
fixed point theorem, 119 
Flow-Shop Problem, 276 
Flow-shop problem, 278 
flow-shop problem, 7 
Fortran, 55 
Fortran Library, 45 
Fortran library, 37, 39 
Fractionally Integrated Models, 199 
Fraud-Vector, 115 
frequency, 90 
game core, 120 
Gaussian, 3, 131 
Gaussian distribution, 292 
Gaussian distribution function, 198 
Genetic Algorithms, 7, 18 
Global Methods, 34 
global methods, 75 
global minimum, 3, 45 
global optimization software, 39 
global optimum, 5 
global stochastic optimization, 118 
GMC, 63 
GMJ, 85 
GMJ1, 85 
GMJ2, 85 
GNU, 64 
graphical images, 188 
graphical interface, 23, 40, 75, 77, 169 
GRASP, 7 
greedy heuristic , 11 
Greedy Heuristics, 16 
Greedy Heuristics Algorithms, 14 
hesitation probability, 176 
heuristic techniques, 6 
Heuristics, 6 
hitting probability, 152 
hostile object, 152 
immunological model, 37 
immunological models, 5 
incoming call, 248 
individual utility function, 176 
inequality constraints, 55 
initial temperature, 6 
Inspection Model, 143 
inspection utility function, 143 
inspection vector, 143 
Interactive DOS software, 39 
Interactive Java software, 40 
Interactive Java, JDK1.1 software, 40 

Interactive JDK1.2 software, 40 
Interactive UNIX software, 40 
interest, 180 
Internet Explorer, 40 
invested capital, 175 
irrelevant fraud algorithm, 146 
Java, 21, 75 
Java Developer Kit, 85 
Java Implementation, 23 
JDKLO, 37 
JDKl.l, 37, 85 
JDK1.2, 37, 85 
knapsack problem, 11 
Kolmogorov consistency conditions, 4 
Lagrange function, 116, 124 
Lagrange multipliers, 124 
likelihood function, 38 
linear programming, 145, 146 
Linear Randomization, 14 
Linux, 53, 64 
List of Methods, 48 
Lithuanian stock exchange, 183 
Local Methods, 35 
local methods, 75 
local optimization, 46, 188 
lost call, 24 9 
lost customers, 117 
low order mutations, 21 
lower bound array, 39 
machine-dependent routines, 46 
Main Program, 51 
Main program, 52 
make-span, 276 
marketing messages, 264 
Markets, 116 
Markovian processes, 4 
Markovian property, 4 
mathematical models, 37 
Matrix Game, 148 
Matrix Game Algorithm, 157 
Menu System, 65 
menu system, 75 
Method selection, 92 
Missing Data, 196 
Mixed Randomization, 16 
mixed strategies, 146, 154 
mixture of algorithms, 16 
mixtures, 6 
model structure, 205 
monopolistic position, 161 
Monte Carlo, 13, 129 
Monte Carlo Errors, 252 
Monte Carlo simulation, 117 
Index 
319 
Monte-Carlo simulation, 116 
Moving Average, 187 
multi-modal, 38 
multi-modal optimization, 188 
mutation, 18 
Nash equilibrium, 115 
Nash model, 116, 162 
Netscape, 40 
network optimization, 21 
neuron, 198 
new method, 82 
noise, 131 
noise level, 118 
noisy functions, 34 
non-differentiable, 34 
non-differentiable functions, 46 
non-linear constraints, 35, 46, 49, 56, 63 
non-linear differential equations, 37 
non-linear programming, 56, 107 
non-linear regression, 37 
nonlinear time series, 5 
nuisance parts, 205 
Objective Function, 49 
objective function, 57, 76 
observed points, 132 
one-dimensional, 131 
one-dimensional array, 49 
operating systems, 37 
Operation Control, 92 
Operations Research, 116 
Optimal Investment, 173 
optimal investment problems, 187 
optimal portfolio, 175 
Optimal Scheduling, 275 
optimization, 77 
optimization algorithm, 81 
parallel computing, 6 
parameter grouping, 21 
Partial Special Events, 265 
penalty function, 34, 137 
penalty functions, 37, 40 
permutation algorithm, 17 
Permutation Algorithms, 16 
permutation heuristics, 17 
Permutation Schedule, 276 
Person vs Computer game, 170 
Person vs Person game, 168 
personal traits, 177 
piece-wise line, 132 
Poisson, 117, 246 
Poisson distribution, 145 
policy file, 105 
polynomial-time, 188 
polynomial-time algorithm, 188 
Portable Fortran Library, 39 

320 
EXAMPLES OF GLOBAL AND DISCRETE OPTIMIZATION 
Portfolio Problem, 173 
predicted stock rates, 187 
prediction errors, 206 
prior distribution, 3, 6 
priority rule, 277 
profit function, 134 
profit functions, 119 
Projection, 66 
projection, 76, 89 
prudent person, 175 
psychological tests, 177 
pure heuristics, 7 
pure strategies, 145 
quadratic randomization, 21 
queuing system, 249 
Queuing systems, 245 
random number, 131 
random numbers, 192 
Random Walk, 188 
randomization algorithms, 6 
Randomized Heuristic Algorithms, 14 
rectangular, 34 
rectangular constraints, 39, 40, 55, 57, 63, 
126 
recurrent equations, 294, 298 
Recursive Quadratic Programming, 46 
reliability, 180 
reproductive plan, 18 
Reservation Model, 253 
residual minimization, 189 
resource price, 124 
resource vector, 123 
rich person, 175, 177 
risk function, 3 
risk threshold, 175 
risky person, 176 
RW models, 192 
sampling with replacement, 13 
Scalar Prediction, 263 
scheduling problems, 187, 276 
School Scheduling, 282 
second-order models, 169 
Security Restrictions, 104 
security restrictions, 85 
separable objectives, 35 
sequential quadratic programming, 33, 39 
Sequential Statistical Decisions, 291 
Server Coalition, 120 
server rates, 115 
service cost, 125 
service prices, 115, 162 
service system, 249 
shock absorber, 5 
signing certificate, 104 
simplex method, 35, 46 
Simulated Annealing, 18 
simulated annealing, 5 
smooth functions, 33 
smoothing algorithms, 131 
smoothing function, 131 
Software Global Optimization Software , 
33 
Software Initialization, 64 
Software Installation, 51, 64 
Software Requirements, 64 
Solaris, 64 
Special Events, 261 
Spectrum, 90 
square deviation, 118 
square residuals, 188 
Stable Coalition, 119 
stand-alone Application, 104 
stand-alone application, 85 
standalone application, 40 
Stationary Probabilities, 247 
stochastic, 55 
stochastic approximation, 35, 46 
stochastic model, 3 
stochastic optimization, 118 
stock exchange index, 188 
Stopping Monte Carlo, 253 
Strategy Elimination Algorithm, 148 
strictly convex function, 119 
Structural Stabilization, 205 
structural variables, 206 
sufficient equilibrium conditions, 153 
Tabu Search, 7 
task object, 88 
Task Selection, 90 
tax collection, 143 
Theory of Games, 116 
thermostable polymeric compositions, 5 
thermostable polymeric compositions., 39 
time scale model, 261 
Time Series Model, 187 
time series model, 187 
Time-Dependant Cases, 255 
truncation parameter, 201 
Turbo C, 37, 56 
uncertain future, 205 
uni-modal function, 46, 118 
uniform deterministic search, 35 
uniform random, 46 
uniformly distributed, 6 
Unix, 37 
unstable parameters, 207 
Users Reference, 64 
utility function, 175 
variance, 131 

Vector Prediction, 266 
violation utility function, 143 
violation vector, 143 
waiting calls, 249 
waiting cost, 125 
waiting customers, 129 
waiting losses, 295 
waiting place, 246 
waiting time, 248 
Walras Equilibrium, 123 
Walras model, 116, 123 
web, 85 
web-site, 37, 41, 76, 163 
Wiener Filter, 131 
Wiener filter, 132 
Wiener model, 4, 9 
Wiener process, 4, 131 
worst case analysis, 3 
Index 
321 

