A ï¬rst-order optimization algorithm for statistical learning
with hierarchical sparsity structure
Dewei Zhang1, Yin Liu1, Sam Davanloo Tajbakhsh1âˆ—
{zhang.8705,liu.6630,davanloo.1}@osu.edu
1Department of Integrated Systems Engineering
The Ohio State University
October 20, 2020
Abstract
In many statistical learning problems, it is desired that the optimal solution con-
forms to an a priori known sparsity structure represented by a directed acyclic graph.
Inducing such structures by means of convex regularizers requires nonsmooth penalty
functions that exploit group overlapping. Our study focuses on evaluating the proximal
operator of the Latent Overlapping Group lasso developed by Jacob et al. [21]. We
implemented an Alternating Direction Method of Multiplier with a sharing scheme to
solve large-scale instances of the underlying optimization problem eï¬ƒciently. In the
absence of strong convexity, global linear convergence of the algorithm is established
using the error bound theory. More speciï¬cally, the paper contributes to establishing
primal and dual error bounds when the nonsmooth component in the objective func-
tion does not have a polyhedral epigraph. We also investigate the eï¬€ect of the graph
structure on the speed of convergence of the algorithm. Detailed numerical simula-
tion studies over diï¬€erent graph structures supporting the proposed algorithm and two
applications in learning are provided.
Keywordsâ€” Proximal methods, error bound theory, Alternating Direction Method of Multi-
pliers, hierarchical sparsity structure, latent overlapping group lasso.
1
Introduction
Convex sparsity-inducing regularization functions play an important role in diï¬€erent ï¬elds including
machine learning, statistics, and signal processing [17]. Some well-known regularizers e.g. lasso [43]
or group lasso [52] are commonly used in diï¬€erent learning frameworks to induce sparsity which
allows simultaneous model ï¬tting and feature selection. In contrast to lasso which assumes no a
priori knowledge on sparsity pattern, group lasso assumes that variables belong to a priori known
âˆ—Corresponding author
1
arXiv:2001.03322v3  [math.OC]  18 Oct 2020

groups and the variables within a group tend to aï¬€ect response similarly, i.e., all are simultane-
ously zero or nonzero. This introduced more elaborate forms of zero/nonzero patterns, known as
structured sparsity, to the literature [2]. The focus of this paper is to address structured sparsities
represented by a Directed Acyclic Graph (DAG) and the convex Latent Overlapping Group (LOG)
lasso regularizer of [21] to induce such structure. To be more speciï¬c, we develop an optimiza-
tion framework that allows incorporating this regularizer in large-scale learning problems for huge
DAGs. In the remainder of this section, we discuss hierarchical structured sparsity following a
DAG, convex regularizers to induce hierarchical sparsity structures, and the proximal mapping of
the LOG lasso regularizer.
1.1
Hierarchical structured sparsity
Let D = (S, E) be a DAG where S = {s1, ..., sN} is the index set of nodes, and E is the set of
ordered pairs of node indices with an edge from the ï¬rst to second element, e.g. (si, siâ€²) is an edge
from si to siâ€². Furthermore, let each node i of the graph contains a set of di variables where their
indices are contained in si. We will refer to the variables in node i by Î²si.
The graph structure contains the sparsity structure between groups of variables in each node.
For instance, consider the following two DAGs and assume the variables in a single node will be all
s1 
s2 
(a) A DAG with two nodes
s1 
s2 
s3 
s4 
(b) A DAG with four nodes
Figure 1: Two Directed Acyclic Graphs (DAG)
simultaneously non-zero or all zero. The sparsity hierarchy introduced by the graph in Figure 1a
is (s1 = 0) â‡’(s2 = 0) and (s2 Ì¸= 0) â‡’(s1 Ì¸= 0). Note that sj = 0 means that all of the variables in
sj are equal to zero; similarly, (sj Ì¸= 0) means all of the variables in sj are nonzero. However, there
are scenarios where a node has more than one ancestor, e.g. node s3 in Figure 1b. Such scenarios
can potentially be interpreted in two diï¬€erent ways. Under strong hierarchy assumption, all of
the immediate ancestor nodes need to be nonzero for their descendent node to be nonzero, e.g., in
Figure 1b, (s3 Ì¸= 0) â‡’(s1 Ì¸= 0, s2 Ì¸= 0), and (s1 = 0 or s2 = 0) â‡’(s3 = 0). Under weak hierarchy
assumption, for a descendent node to be nonzero it suï¬ƒces that any of its immediate ancestors be
nonzero, e.g., in Figure 1b, (s3 Ì¸= 0) â‡’(s1 Ì¸= 0 or s2 Ì¸= 0), and (s1 = 0, s2 = 0) â‡’(s3 = 0) [10].
We are interested in statistical learning problems that require their solutions to follow given
sparsity structures in form of DAGs. To be more speciï¬c, given a DAG D, there is a learning
problem of the form
min
Î²

L(Î²)
s.t.
Î² âˆˆB, supp(Î²) âˆˆD
	
(1)
where L : Rd â†’R is a smooth, convex or nonconvex loss function with d = PN
i=1 di being the
problem dimension, B âŠ†Rd is a closed set, and with a slight abuse of notation, supp(Î²) âˆˆD
denotes that the support of Î² (index set of its nonzero elements) follows D in the strong sense.
2

One way to formulate supp(Î²) âˆˆD, explicitly, is by introducing binary variables. For instance,
assuming one variable per node, formulating the hierarchy in Figure 1a shall be performed as
zÏµ â‰¤|Î²1|,
|Î²2| â‰¤zÂµ,
z âˆˆ{0, 1},
where Ïµ and Âµ are reasonably small and large numbers, respectively. Introduction of binary variables
makes the optimization problem a Mixed Integer Program (MIP) [50] - see also [3, 4]. Finding the
global optimal solution of large-scale MIPs for large DAGs is generally computationally challenging.
We, however, would like to note some signiï¬cant advances in MIP algorithms for statistical learning,
speciï¬cally for feature selection â€“ see e.g.
[8, 29, 1, 30, 7, 9].
Similar to using â„“1 norm as a
convex approximation to â„“0 (pseudo) norm to induce sparsity, there are convex regularizers that
promote hierarchical sparsity structures. Needless to mention, these approximation methods do
not guarantee exact conformance of their solutions to given hierarchies, but, they allow solving
high-dimensional problems.
1.2
Group Lasso with overlaps vs. Latent Overlapping Group lasso
There are mainly two convex regularizers to introduce hierarchical structured sparsity: 1. Group
Lasso (GL) 2. Latent Overlapping Group Lasso (LOG) [51]. Given a set of groups of variables G,
the GL regularizer is deï¬ned as
â„¦GL(Î²) =
X
gâˆˆG
wgâˆ¥Î²gâˆ¥
(2)
where wg is a positive weight corresponding to group g and Î²g âˆˆR|g| is equal to Î² for ele-
ments whose indices belongs to g and zero for other elements, and the âˆ¥Â· âˆ¥is either an â„“2 or
â„“âˆnorm. To induce hierarchical sparsity structure using the GL penalty, the groups should be
deï¬ned in a descendants form, for instance, for the graph in Figure 1b the groups should be
G = {s3, s4, {s1, s3}, {s2, s3, s4}} where s3 = descendants(D; s3), {s1, s3} = descendants(D; s1),
s4 = descendants(D; s4), and {s2, s3, s4} = descendants(D; s2).
The group lasso sets to zero a
union of a subset of groups introduced in G. However, since there are overlaps between the groups
deï¬ned in G, the support of the solution induced by GL is not necessarily a union of the groups.
This is because of the fact that the complement of a union of a subset of groups is not necessarily
a union of groups.
As an alternative to GL, Jacob et al. [21] introduced LOG regularizer which is deï¬ned as
â„¦LOG(Î²) =
inf
Î½(g), gâˆˆG
ï£±
ï£²
ï£³
X
gâˆˆG
wgâˆ¥Î½(g)âˆ¥2 s.t.
X
gâˆˆG
Î½(g) = Î², Î½(g)
gc = 0
ï£¼
ï£½
ï£¾
(3)
which sets to zero a subset of groups. Since Î² is the sum of latent variables Î½(g) âˆˆRd, its support
is the union of the groups of nonzero latent variables. Given a DAG D with N nodes, there exist
N groups in G (i.e., N = |G|). To induce a hierarchical sparsity using the LOG penalty the group
corresponding to each node contains the node indices of all its ancestors, i.e., G = ancestors(D).
For instance, the group set for the graph in Figure 1b is G = {s1, s2, {s1, s2, s3}, {s2, s4}} where s1 =
ancestors(D; s1), s2 = ancestors(D; s2), {s1, s2, s3} = ancestors(D; s3), and {s2, s4} = ancestors(D; s4).
Figure 2a shows a simple tree with three nodes, and the ancestor grouping scheme; Figure 2b shows
the latent variables within the constraint in the LOG penalty. Recently, Yan et al. [51] performed
a detailed comparison of GL vs. LOG regularizers. They showed that compared to LOG, GL sets
3

1 
2 
3 
(a) A tree with three nodes. Red dashed
lines show the groups.
Î½1{1}
0
Î½1{1,2}
Î½2{1,2}
Î½1{1,3}
Î½3{1,3}
0
0
0
Î²2
Î²3
Î²1
(b) The constraint within the LOG penalty cor-
responding to the tree in 2a
Figure 2: LOG penalty and the required groups to induce a tree structure
to zero parameters which are deeper in the hierarchy. Hence, for DAGs with deep hierarchies it is
very probable that GL sets to zero deeper variables which is undesirable. Furthermore, with LOG
penalty, one has control over the solution support as it is a subset of columns of latent variables.
In the next section, we discuss solving statistical learning problems in the regularized form using
the nonsmooth LOG penalty and propose solving them using proximal methods.
1.3
Proximal operator of the LOG penalty
Given a hierarchical sparsity structure represented by a graph D, an approximate convex optimiza-
tion problem to (1) is
min
Î²

L(Î²) + Î»â„¦LOG(Î²)
s.t.
Î² âˆˆB
	
(4)
where â„¦LOG(.) is the LOG penalty introduced in (3) with appropriately chosen groups, and Î» > 0 is
a parameter that controls the tradeoï¬€between the loss function and the penalty. Indeed, problem
(4) is a convex nonsmooth program; hence, proximal methods are suitable to solve large instances
of this problem [31, 5, 34].
Similar to gradient methods that require iterative evaluation of the gradient, proximal methods
require iterative evaluation of the proximal operator [34]. The proximal operator of a function
Î»â„¦(Î²) in general (Î»â„¦LOG(Î²) in this case) evaluated at b âˆˆRd is deï¬ned as
proxÎ»â„¦(b) â‰œargmin
Î²âˆˆRd

Î»â„¦LOG(Î²) + 1
2âˆ¥Î² âˆ’bâˆ¥2
2

.
(5)
Using the deï¬nition of â„¦LOG, evaluating the proximal operator of the LOG penalty requires solving
min
Î½(g)âˆˆRd
ï£±
ï£²
ï£³Î»
X
gâˆˆG
wgâˆ¥Î½(g)âˆ¥2 + 1
2âˆ¥
X
gâˆˆG
Î½(g) âˆ’bâˆ¥2
2 s.t. Î½(g)
gc = 0, âˆ€g âˆˆG
ï£¼
ï£½
ï£¾.
(6)
over the latent variables Î½(g), g âˆˆG. A classical method to solve (6) is some implementation of
the proximal Block Coordinate Descent (BCD) algorithm [48] â€“ see e.g. Algorithm 1. Provided
an algorithm to evaluate proxÎ»â„¦LOG eï¬ƒciently, one may use a proximal optimization method e.g.
proximal gradient method [5, 31, 34] to solve (4). The main challenge is to evaluate the proximal
operator of the LOG penalty (5) for large DAGs with large |G|. The main drawbacks of the BCD
4

Algorithm 1 Block Coordinate Descent (BCD) to solve proxÎ»â„¦LOG(b)
Require: b, Î», w, G
1: Î² = 0
2: Î½(g) = 0, âˆ€g âˆˆG
3: while stopping criterion not met do
4:
for g âˆˆG do
5:
Î² â†Î² âˆ’Î½(g)
6:
Î½(g) â†SG(bg âˆ’Î²g, Î»wg) â‰œ(bg âˆ’Î²g) max{1 âˆ’
Î»wg
âˆ¥bgâˆ’Î²gâˆ¥, 0},
7:
Î² â†Î² + Î½(g)
8:
end for
9: end while
Output: Î²
algorithm to solve (5) are as follows. First, even though convergence of the BCD algorithm for
nondiï¬€rentiable but separable functions has been established [44], to the best of our knowledge,
the convergence rate of the algorithm for nonsmooth optimization is sublinear [46, 37]. Second,
the BCD algorithm follows a Gauss-Siedel update rule and hence it cannot be parallelized. In this
work, we introduce an eï¬ƒcient ï¬rst-order method, based on Douglas-Rachford operator splitting,
that can solve (5) over large graphs with fast, i.e., linear, rate of convergence.
Remark 1. The intent of this work is to propose an eï¬ƒcient optimization algorithm to solve
the proximal mapping of the LOG penalty (5). The resulting standalone algorithm can then be
embedded in any prox-based optimization algorithm to solve (1) for convex or nonconvex settings.
Hence, solving (1) is not the purpose of our paper which is the reason why we do not specify any
structures on L(Â·) or B, e.g., convexity or etc.
1.4
Contributions
We propose an ADMM algorithm with a sharing scheme to solve proxâ„¦LOG deï¬ned over large DAGs.
The underlying DAG may have any general structure (e.g. not necessary to be a path graph) and
the algorithm is guaranteed to converge to its optimal solution. Furthermore, the computationally
challenging subproblem of the algorithm (step 4 in Algorithm 3) can be run fully in parallel.
We proved linear convergence of the algorithm given a suï¬ƒciently small stepsize in the absence
of strong convexity. Establishing the linear convergence rate is based on the error bound theory
(see e.g.[45, 25, 53, 20]), and our contributions are as follows:
1. The dual error bound is established in the presence of â„“2-norm in the nonsmooth component
of the objective function. A common key assumption in previous works requires the nonsmooth
component to have a polyhedral epigraph. Our proof shows an approach to escape such assumption
and enables further extension.
2. On the primal side, we rigorously prove the error bound for the augmented Lagrangian
function. The main challenges are the presence of the dual variable y and the splitting of x into
two blocks , i.e., x1 and x2, which requires a number of technical details, e.g., comparing the limiting
behavior of x1,k and x2,k. To the best of our knowledge, this is the ï¬rst work showing error bound
5

for augmented Lagrangian function with block structured variables.
3. As an auxiliary result needed to show the linear rate of convergence of the algorithm, and
by using the proof in [15], we formally show the uniform boundedness (with respect to the stepsize)
of both primal and dual updates generated by the algorithm.
4. We looked into the eï¬€ect of the graph structure on the O(1) constant of the convergence
rate; furthermore, we performed detailed numerical experiments on six diï¬€erent graphs comparing
the proposed method against ï¬ve other state-of-the-art optimization techniques for this problem.
1.5
Related work
As discussed above, hierarchical sparsity structures are generally enforced by either introducing
constraints to the underlying optimization problem or adding regularizers to its objective function.
We discuss the relevant work in the later category with convex regularizers which are directly related
to our work.
Zhao & Yu [54] proposed composite absolute penalty to express grouping and hierarchical
structures and used a stage-wise lasso algorithm to approximate the regularization path for convex
problems. Radchenko & James [36] proposed an adaptive nonlinear interaction structure for least-
square regression with two-way interaction for high-dimensional problems. Schmidt & Murphy [39]
enforced the hierarchical constraints using grouped â„“1 regularization with overlapping groups for log-
linear models of any order and proposed an active set method to solve the underlying problem. Haris
et al. [16] proposed a general framework for variable selection problems regularized with group lasso
with overlaps and proposed to solve the underlying problem by the ADMM algorithm. Jenatton
et al. [23] explored the relationship between the groups deï¬ning the norm and the resulting nonzero
patterns and provided forward and backward algorithms to go back and forth between groups and
patterns. Furthermore, Jenatton et al. [22] considered ï¬nding the proximal mapping of the group
lasso penalty through its dual problem and showed that a BCD algorithm solves the dual in one
pass for tree graphs. Mairal et al. [27] showed that the proximal operator of the overlapping group
lasso under â„“âˆnorm can be computed in polynomial time by solving a quadratic min cost-ï¬‚ow
problem and used proximal splitting to solve the problem in higher dimensions. She et al. [40]
considered group lasso with overlap penalty and provide the minimax lower bounds for strong and
weak hierarchical models and showed their proposed estimators enjoy sharp rate oracle inequalities.
Hazimeh & Mazumder [18] proposed a scalable algorithm based on proximal gradient descent to
solve the underlying problem. Their method enjoys a proximal screening step that identiï¬es many
of the zero variables and groups and also allows to solve the problem in parallel; furthermore, they
proposed an eï¬ƒcient active set method based on gradient screening.
Jacob et al. [21], ï¬rst, proposed the LOG penalty and studied its theoretical properties - see also
Obozinski et al. [32] for theoretical discussions on choice of the weights. Villa et al. [48] proposed
accelerated proximal method and proved the convergence of the overall learning problem for the
least-square loss function. Furthermore, they developed an active set method to compute the inner
proximal mapping relatively fast. Lim & Hastie [24] imposed strong hierarchy through a constrained
optimization problem for which they found an equivalent unconstrained problem. Chouldechova
& Hastie [12] incorporated a LOG-like penalty to ï¬t generalized additive models. Finally, Yan
et al. [51] compared statistical properties of GL and LOG lasso penalties. They also proposed a
ï¬nite-step algorithm to compute the proximal operator of the LOG penalty for path graphs and
extended it to general DAGs with an ADMM framework. However, their extension for general
DAGs (1) highly depends on how DAG is decomposed into diï¬€erent path graphs, and (2) it lacks
6

theoretical convergence and convergence rate analysis. Compared to their method, we formulated
the proximal map for the original DAG directly into an ADMM framework with a sharing scheme
and established global linear convergence of the algorithm. We compare the convergence time of
our algorithm with their path-based ADMM in Section 4.1.
Notation. Vectors are denoted by lowercase bold letter while matrices are denoted by uppercase
letters. The identity matrix is denoted by I. Let G be a set, then its cardinality is denoted by |G|.
Given a vector Î² âˆˆRd and g âŠ†{1, ..., d}, Î²g âˆˆR|g| subsets Î² over the set g. We denote the j-th
column of the matrix A by A.j, similarly we denote its i-th row by Ai.. Furthermore, similar to the
vector case, if g âŠ†{1, ..., n}, then A.g âˆˆRmÃ—|g| subsets A over the columns indexed by g. Inner
product of two vectors is deï¬ned as âŸ¨a, bâŸ©= aâŠ¤b.
The rest of the paper is organized as follows. In Section 2, we propose an ADMM algorithm
with the sharing scheme to evaluate the proximal operator of the LOG penalty. Section 3 provides
detailed convergence analysis of the proposed algorithm while proofs are relegated to the Appendix.
Section 4 provides some numerical simulation studies conï¬rming our theoretical complexity bound
and compares the ADMM algorithm with other methods. Furthermore, Section 4 contains two
applications that use LOG penalty to induce sparsity structure related to topic modeling and
breast cancer classiï¬cation. Finally, Section 5 provides some concluding remarks.
2
Evaluating the proximal operator of the LOG
Consider the optimization problem (6) to ï¬nd the proximal operator of the LOG penalty. Given a
general DAG D, each iteration of the BCD algorithm requires updating Î½(g), âˆ€g âˆˆG. If |G| is a
large number, then per iteration complexity of the algorithm O(P
gâˆˆG |g|) is costly. Furthermore,
to the best of authors knowledge, convergence rates of the BCD algorithm for general nonsmooth
optimization problems have not been well studied.
However, convergence of the algorithm for
problems where the nondiï¬€rentiable part is separable is established, cf. [44].
In this paper, we develop an Alternating Direction Method of Multiplier (ADMM) to solve the
proximal operator of the LOG penalty. The algorithm is parallelizable which makes it suitable
when the number of groups is very large. Deï¬ne x = [Î½(g)
g ]gâˆˆG âˆˆRn, n = P
gâˆˆG |g|, be a long
vector that contains the nonzero elements of Î½(g), g âˆˆG, for some random order P of the groups.
Furthermore, let j(Â·) : G â†’{1, ..., n} be the set map that associates a group g âˆˆG to its indices in
vector x given an order of the groups. For instance, for G = {{1}, {1, 2}, {1, 3}} ordered as P from
left-to-right: 1. n = 5, 2. jP({1}) = {1}, jP({1, 2}) = {2, 3}, and jP({1, 3}) = {4, 5}. To simplify
the notation, the group ordering P is omitted. Finally, (6) can equivalently be written as
min
xâˆˆRn Î»
X
gâˆˆG
âˆ¥W gxâˆ¥2 + 1
2âˆ¥Mx âˆ’bâˆ¥2
2,
(7)
where W g = wgU j(g), U j(g) âˆˆR|g|Ã—n such that [U j(g)âŠ¤]gâˆˆG = I âˆˆRnÃ—n, and M âˆˆBdÃ—n sums
elements of x along each coordinate. Or, equivalently, (6) can be written as
min
xâˆˆRn f(x) â‰œÎ»
X
gâˆˆG
wgâˆ¥xj(g)âˆ¥2 + 1
2âˆ¥Mx âˆ’bâˆ¥2
2.
(8)
7

Problem (8) is a convex (not strongly convex since M is not a full-column rank matrix), nonsmooth
optimization program. This problem can also be solved using the proximal gradient method [53, 45].
We propose to solve this problem using the Alternating Direction Method of Multipliers (ADMM).
First, splitting the problem into two blocks [11], we have
min
x1,x2âˆˆRn
ï£±
ï£²
ï£³F(x1, x2) â‰œÎ»
X
gâˆˆG
wgâˆ¥x1
j(g)âˆ¥2 + 1
2âˆ¥Mx2 âˆ’bâˆ¥2
2,
s.t. x1 = x2
ï£¼
ï£½
ï£¾.
(9)
The augmented Lagrangian function for (9) is
LÏ(x1, x2; y) = Î»
X
gâˆˆG
wgâˆ¥x1
j(g)âˆ¥2 + 1
2âˆ¥Mx2 âˆ’bâˆ¥2
2 +

y, x1 âˆ’x2
+ Ï
2âˆ¥x1 âˆ’x2âˆ¥2
2,
(10)
where y âˆˆRn is the Lagrange multiplier for the linear constraint x1 = x2, and Ï â‰¥0 is a constant.
Furthermore, the augmented dual function is given by
gÏ(y) =
min
x1,x2âˆˆRn Î»
X
gâˆˆG
wgâˆ¥x1
j(g)âˆ¥2 + 1
2âˆ¥Mx2 âˆ’bâˆ¥2
2 +

y, x1 âˆ’x2
+ Ï
2âˆ¥x1 âˆ’x2âˆ¥2
2,
(11)
which results into the the dual problem
max
yâˆˆRn
gÏ(y).
(12)
The ADMM iterates in the unscaled form [11] are
x1,k+1
j(g)
â†argmin
x1
j(g)âˆˆR|g| Î»wgâˆ¥x1
j(g)âˆ¥2 + Ï
2âˆ¥x1
j(g) âˆ’x2,k
j(g) + 1
Ïyk
j(g)âˆ¥2
2,
âˆ€g âˆˆG,
(13)
x2,k+1 â†argmin
x2âˆˆRn
1
2âˆ¥Mx2 âˆ’bâˆ¥2
2 + Ï
2âˆ¥x2 âˆ’x1,k+1 âˆ’1
Ïykâˆ¥2
2,
(14)
yk+1
j(g) â†yk
j(g) + Î±(x1,k+1
j(g)
âˆ’x2,k+1
j(g) ),
âˆ€g âˆˆG,
(15)
where Î± is the dual stepsize. Algorithm 2 illustrates the resulting (unscaled) ADMM algorithm to
evaluate the proximal map of the LOG penalty. Note that the subproblem (13) is parallelizable
across groups, and the solution to each subproblem is available in the closed from. However, even
though the update (14) has a closed-form solution, it involves inverting an n Ã— n matrix which
generally requires O(n3) operations, per iteration. Hence, for large DAGs where |G| and hence n is
large, the second update is very slow.
To deal with this issue, below we propose a sharing scheme that helps solving the second
subproblem eï¬ƒciently. First, we put the variables in the matrix form. Deï¬ne X âˆˆRdÃ—|G| be a
matrix that stacks Î½(g), g âˆˆG where its columns are indexed by g âˆˆG. Problem (6) can be written
in the matrix form as
min
XâˆˆRdÃ—|G|
ï£±
ï£²
ï£³Î»
X
gâˆˆG
wgâˆ¥X.gâˆ¥2 + 1
2âˆ¥
X
gâˆˆG
X.g âˆ’bâˆ¥2
2, s.t. (X.g)gc = 0 âˆ€g âˆˆG
ï£¼
ï£½
ï£¾.
(16)
8

Algorithm 2 ADMM to solve proxÎ»â„¦LOG(b) in the unscaled form
Require: b, Î», Î±, wg âˆ€g âˆˆG, j(.) : G â†’[n]
1: k = 0, y0 = 0, x2,0 = 0
2: while stopping criterion not met do
3:
k â†k + 1
4:
x1,k+1
j(g)
â†proxÎ»wgâˆ¥Â·âˆ¥2(x2,k
j(g) âˆ’1
Ïyk
j(g)),
âˆ€g âˆˆG
5:
x2,k+1 â†(MâŠ¤M + ÏI)âˆ’1(MâŠ¤b + Ïx1,k+1 + yk)
6:
yk+1
j(g) â†yk
j(g) + Î±(x1,k+1
j(g)
âˆ’x2,k+1
j(g) ),
âˆ€g âˆˆG
7: end while
8: Î² = Mx1,k
Output: Î²
Splitting the problem into two blocks, the problem is equivalent to
min
X1,X2âˆˆRdÃ—|G|
ï£±
ï£²
ï£³Î»
X
gâˆˆG
wgâˆ¥X1
.gâˆ¥2 + 1
2âˆ¥
X
gâˆˆG
X2
.g âˆ’bâˆ¥2
2, s.t. X1 = X2, (X1
.g)gc = 0 âˆ€g âˆˆG
ï£¼
ï£½
ï£¾.
(17)
The ADMM iterates in the scaled form (through deï¬ning U := (1/Ï)Y where Y is the dual variable
in the matrix form - see [11] for details) to solve (17) are
X1,k+1
.g
â†argmin
X1.gâˆˆRd
n
Î»wgâˆ¥X1
.gâˆ¥2 + Ï
2âˆ¥X1
.g âˆ’X2,k
.g
+ U k
.gâˆ¥2
2 s.t. (X1
.g)gc = 0
o
, âˆ€g âˆˆG,
(18)
X2,k+1 â†argmin
X2âˆˆRdÃ—|G|
1
2âˆ¥
X
gâˆˆG
X2
.g âˆ’bâˆ¥2
2 + Ï
2
X
gâˆˆG
âˆ¥X2
.g âˆ’X1,k+1
.g
âˆ’U k
.gâˆ¥2
2,
(19)
U k+1
.g
â†U k
.g + (Î±/Ï)(X1,k+1
.g
âˆ’X2,k+1
.g
), âˆ€g âˆˆG,
(20)
Similar to the vector form, the solution to subproblem (18) is provided by the proximal map of
the â„“2-norm and can be parallelized across groups, see step 4 in Algorithm 3. Subproblem (19)
is potentially a large problem in d|G| variables for a large DAG (equivalent to the second update
in the above algorithm in the vector form); however, it is possible to decrease its size to only d
variables. Subproblem (19) is equivalent to
min
X2âˆˆRdÃ—|G|, Â¯x2âˆˆRd
ï£±
ï£²
ï£³
1
2âˆ¥|G|Â¯x2 âˆ’bâˆ¥2
2 + Ï
2
X
gâˆˆG
âˆ¥X2
.g âˆ’X1,k+1
.g
âˆ’U k
.gâˆ¥2
2 s.t. Â¯x2 = (1/|G|)
X
gâˆˆG
X2
.g
ï£¼
ï£½
ï£¾.
(21)
Minimizing over X2
.g with Â¯x2 ï¬xed and using optimality conditions, we get
X2
.g = Â¯x2 + X1,k+1
.g
+ U k
.g âˆ’(1/|G|)
X
gâˆˆG
(X1,k+1
.g
+ U k
.g), âˆ€g âˆˆG.
(22)
Using (22) to solve (19) we get
Â¯x2 =
1
|G| + Ï

b + Ï
|G|
X
gâˆˆG
(X1,k+1
.g
+ U k
.g)

.
(23)
9

Furthermore, using (22) in (20), we get
U k+1
.g
= U k
.g + (Î±/Ï)
  1
|G|
X
gâˆˆG
(X1,k+1
.g
+ U k
.g) âˆ’Â¯x2 âˆ’U k
.g

, âˆ€g âˆˆG.
(24)
The sharing implementation of the proposed ADMM algorithm is illustrated in Algorithm 3.
Algorithm 3 ADMM to solve proxÎ»â„¦LOG(b) in the scaled form with the sharing scheme
Require: b, Î», Î±, wg âˆ€g âˆˆG
1: k = 0, Â¯u0 = 0, Â¯x2,0 = 0
2: while stopping criterion not met do
3:
k â†k + 1
4:
X1,k+1
gg
â†proxÎ»wgâˆ¥Â·âˆ¥2(X1,k
gg + Â¯x2,k
g
âˆ’Â¯uk
g âˆ’Â¯x1,k
g ),
âˆ€g âˆˆG
5:
X1,k+1
gcg
â†0,
âˆ€g âˆˆG
6:
Â¯x1,k+1 â†
1
|G|
P
gâˆˆG X1,k+1
.g
7:
Â¯x2,k+1 â†
1
|G|+Ï
 b + Ï(Â¯x1,k+1 + Â¯uk)

8:
Â¯uk+1 = Â¯uk + (Î±/Ï)
 Â¯x1,k+1 âˆ’Â¯x2,k+1
.
9: end while
10: Î² = P
gâˆˆG X1,k+1
.g
Output: Î²
3
Convergence analysis
Eckstein & Yao [14] showed the iterates generated by two-block ADMM converges to some limiting
points under certain conditions. Our setting follows their proposition. It is also straightforward to
show such limiting points are optimal solutions. In this section, we establish linear convergence rate
of the ADMM algorithm to solve the proximal operator of the LOG penalty (8) given a suï¬ƒciently
small stepsize using the error bound theory.
3.1
Rate of convergence
Note that the objective function of (8) is not strongly convex since M is not full column rank. To
establish the linear convergence rate, we will use the error bound theory which is well-established
for primal methods â€“ see [45] and references therein. For a dual method, one needs to show that
both primal and dual error bounds hold for the problem under investigation. As mentioned in the
contributions, showing the dual error bound in the presence of â„“2-norm in the objective function
(which results in a second-order cone epigraph) is not trivial. Furthermore, in the absence of a
bounded feasible region, boundedness of the iterates needs to be established. Finally, establishing
primal error bound in the presence of the dual variable and under 2-block splitting is elaborate. All
of these challenges are addressed in this section.
Let Xâˆ—âŠ†R2n and Yâˆ—âŠ†Rn denote the primal and dual optimal solution sets to (9) and (12),
respectively. Let X(y) âŠ†R2n denote the optimal solution set to the problem of minimizing the
10

augmented Lagrangian function (11) given y âˆˆRn. Note the augmented Lagrangian (10) is strongly
convex in x1 or x2, but not jointly strongly convex. We use x(y) = (x1âŠ¤(y), x2âŠ¤(y))âŠ¤âˆˆX(y) to
represent a minimizer of (10) given y. Let E â‰œ[I, âˆ’I] âˆˆRnÃ—2n and M as in (8), and deï¬ne
â„“(x1, x2) â‰œÏ†b(Mx2) + ÏˆÏ(Ex)
(25)
where the functions Ï†b :
Rn â†’R and ÏˆÏ :
Rn â†’R are deï¬ned as Ï†b(z) â‰œ
1
2âˆ¥z âˆ’bâˆ¥2
2 and
ÏˆÏ(z) â‰œ
Ï
2âˆ¥zâˆ¥2
2.
For the simplicity of notation, the subscripts b and Ï are eliminated in the
remainder of the manuscript. The following two properties are used in the subsequent analysis:
âˆ¥âˆ‡x2Ï†(Mx2(y)) âˆ’âˆ‡x2Ï†(Mx2(Â¯y))âˆ¥2 = âˆ¥M âŠ¤M(x2(y) âˆ’x2(Â¯y))âˆ¥2 â‰¤LÏ†âˆ¥Mx2(y) âˆ’Mx2(Â¯y)âˆ¥2,
(26)
âˆ¥âˆ‡xÏˆ(Ex(y)) âˆ’âˆ‡xÏˆ(Ex(Â¯y))âˆ¥2 = Ïâˆ¥EâŠ¤E(x(y) âˆ’x(Â¯y))âˆ¥2 â‰¤LÏˆâˆ¥Ex(y) âˆ’Ex(Â¯y)âˆ¥2,
(27)
where LÏ† = âˆ¥M T âˆ¥2 and LÏˆ = Ï
âˆš
2.
Given y âˆˆRn, the optimization problem in (11) can equivalently be written as
min
x1âˆˆRn,x2âˆˆRn,sâˆˆR|G|Î»
X
gâˆˆG
sg + 1
2âˆ¥Mx2 âˆ’bâˆ¥2
2 +

y, x1 âˆ’x2
+ Ï
2âˆ¥x1 âˆ’x2âˆ¥2
2,
s.t. wgâˆ¥x1
j(g)âˆ¥2 â‰¤sg,
âˆ€g âˆˆG.
(28)
The constraints in (28) are indeed second-order cones Qg = {(xg, sg) âˆˆR|G| Ã—R+ : wgâˆ¥xgâˆ¥2 â‰¤sg}.
The KKT system for the problem (28) is
yj(g) âˆ’wgÂµg + Ï(x1
j(g) âˆ’x2
j(g)) = 0
âˆ€g âˆˆG,
(29a)
M âŠ¤(Mx2 âˆ’b) + Ï(x2 âˆ’x1) âˆ’y = 0,
(29b)
Î» âˆ’Î½g = 0
âˆ€g âˆˆG,
(29c)
wgâˆ¥x1
j(g)âˆ¥2 â‰¤sg
âˆ€g âˆˆG,
(29d)
âˆ¥Âµgâˆ¥2 â‰¤Î½g
âˆ€g âˆˆG,
(29e)
ÂµâŠ¤
g x1
j(g) + sg
wg
Î½g = 0
âˆ€g âˆˆG,
(29f)
where (Âµg, Î½g) âˆˆR|G|Ã—R+ is the dual variable for the conic constraint. Hence, a pair
 (x1, x2, s), (Âµ, Î½)

is an optimal primal-dual pair if it satisï¬es (29). Using the KKT conditions, ï¬rst we provide the
dual error bound in Lemma 3.1.
Lemma 3.1. There exists Ï„d > 0 such that
dist(y, Y âˆ—) â‰¤Ï„dâˆ¥âˆ‡gÏ(y)âˆ¥2,
(30)
where gÏ(y) is the augmented dual function deï¬ned in (11).
Proof. Check Appendix A.
From the proof of Lemma 3.1, we see that Ï„d is indeed a xfunction of Ï and M. Next, in
Lemma 3.2 below, we show the existence of a ï¬nite saddle point to the augmented Lagrangian
function and that the sequence generated by the algorithm is uniformly bounded.
11

Lemma 3.2. Given the existence of a ï¬nite saddle point to the augmented Lagrangian function
(10), for any Ï and Î± such that 0 < Î± < Ï, the sequence {x1,k}, {x2,k} and {yk} generated by the
algorithm (13)-(15) is uniformly bounded.
Proof. Check Appendix B.
We also need to establish the primal error bound. Unlike the dual error bound, where the
gradient of the augmented gÏ(y) nicely bounds the â€œerrorâ€, i.e., the distance of a point to the
optimal solution set, the primal function is not smooth and diï¬€erentiable. Quantifying the error
bound for nonsmooth functions is generally performed by the proximal gradient. For general surveys
on error bounds, see [33, 55] and references therein.
Deï¬nition 3.1. Assume a convex function f is decomposable as f(x) = g(Ax) + h(x), where g is
a strongly convex and diï¬€erentiable function and h is a convex (possibly nonsmooth) function, then
we can deï¬ne the proximal gradient of f with respect to h as
Ëœâˆ‡f(x) := x âˆ’proxh(x âˆ’âˆ‡(f(x) âˆ’h(x))) = x âˆ’proxh
 x âˆ’AâŠ¤âˆ‡g(Ax)

If h = 0 then the proximal gradient Ëœâˆ‡f(x) is equal to the gradient âˆ‡f(x). In general, Ëœâˆ‡f(x)
can be used as the (extended) gradient for nonsmooth minimization minxâˆˆRn f(x). For instance, we
have Ëœâˆ‡f (xâˆ—) = 0 if and only if xâˆ—is a minimizer. For the Lagrangian function (10), the proximal
gradient w.r.t. x = (x1, x2) is deï¬ned as
Ëœâˆ‡xLÏ(x1, x2; y) := xâˆ’proxÎ» P
gâˆˆG wgâˆ¥x1
j(g)âˆ¥2

x âˆ’âˆ‡x(1
2âˆ¥Mx2 âˆ’bâˆ¥2
2 +

y, x1 âˆ’x2
+ Ï
2âˆ¥x1 âˆ’x2âˆ¥2
2)

,
which we split into Ëœâˆ‡x1LÏ and Ëœâˆ‡x2LÏ in the proof of Lemma 3.3.
Lemma 3.3. Assume that (x1, x2; y) is in a compact set, then there exist 0 < Ï„p < +âˆand Î´ > 0
such that
dist(x, X(y)) â‰¤Ï„pâˆ¥Ëœâˆ‡xLÏ(x1, x2; y)âˆ¥2,
(31)
for all (x1, x2; y) such that âˆ¥Ëœâˆ‡xLÏ(x1, x2; y)âˆ¥2 â‰¤Î´. Furthermore, Ï„p and Î´ are independent of y.
Proof. Check Appendix C.
Remark 2. In Lemma 3.3, the condition âˆ¥Ëœâˆ‡xLÏ(x1, x2; y)âˆ¥2 â‰¤Î´ can be relaxed.
Note that
dist(x,X(y))
âˆ¥Ëœâˆ‡xLÏ(x1,x2;y)âˆ¥2 is a continuous and well-deï¬ned function for all (x1, x2; y) such that âˆ¥Ëœâˆ‡xLÏ(x1, x2; y)âˆ¥2
â‰¥Î´. From the uniform boundedness of the sequence in Lemma 3.2, it implies that there exists an
upper bound Ï„ such that
dist(x,X(y))
âˆ¥Ëœâˆ‡xLÏ(x1,x2;y)âˆ¥2 â‰¤Ï„, for all (x1, x2; y) where âˆ¥Ëœâˆ‡xLÏ(x1, x2; y)âˆ¥2 â‰¥Î´.
Choosing Ï„p to be the maximum of Ï„p (in (31)) and Ï„, we have dist(x, X(y)) â‰¤Ï„pâˆ¥Ëœâˆ‡xLÏ(x1, x2; y)âˆ¥2
for all (x1, x2; y).
Theorem 3.1. Let {(xk, yk)} be the sequence generated by Algorithm 3 with stepsize Î± â‰¤
Ï
2Ï„ 2
pÏƒ2 ,
where Ï is the augmented Lagrangian parameter, Ï„p is the primal error bound parameter and Ïƒ is
deï¬ned in the proof. Furthermore, let âˆ†k
p = LÏ(xk+1; yk) âˆ’gÏ(yk) and âˆ†k
d = gâˆ—
Ï âˆ’gÏ(yk) be the
primal and dual optimality gaps at the k-th iteration, respectively. Then, we have
[âˆ†k
p + âˆ†k
d] â‰¤(
1
Î» + 1)k[âˆ†0
p + âˆ†0
d],
12

where Î» = min{
Ïâˆ’2Î±Ï„ 2
pÏƒ2
Î¶+Î¶â€²Ï„ 2
pÏƒ2 , Î±
Ï„ â€² } > 0, and Ïƒ, Î¶, Î¶â€², Ï„ â€² are deï¬ned in the proof, which shows that the
sequence [âˆ†k
p + âˆ†k
d] converges to zero Q-linearly1.
Proof. Check Appendix E.
Remark 3. Theorem 3.1 proves that with the stepsize small enough such that Î± â‰¤0.5ÏÏ„ âˆ’2
p Ïƒâˆ’2, we
have âˆ†k
p + âˆ†k
d â‰¤Ïµ after k â‰¥(log(1 + Î»))âˆ’1 log(
âˆ†0
p+âˆ†0
d
Ïµ
) iterates, where Î» is deï¬ned in the statement
of the theorem, i.e., an Ïµ-optimal solution is obtained in k â‰¥O(log(1/Ïµ)) iterates.
Remark 4. If the stepsize Î± is small enough such that Î± â‰¤0.5ÏÏ„ âˆ’2
p Ïƒâˆ’2 and
Ïâˆ’2Î±Ï„ 2
pÏƒ2
Î¶+Î¶â€²Ï„ 2
pÏƒ2 > Î±
Ï„ â€² , then
Î» = Î±/Ï„ â€² = Î±Ï/Ï„ 2
d. Hence, the O(1) constant in the convergence rate of the algorithm would be
(log(1 + Î±Ï/Ï„ 2
d))âˆ’1. Note that this scenario happens if the stepsize Î± is small enough. In this
scenario, since Ï„d = max{âˆ¥M âŠ¤âˆ¥2, 2Ï} (see the proof of Theorem 3.1), if Ï < (1/2)âˆ¥M âŠ¤âˆ¥2, then the
O(1) constant is (log(1 + Î±Ï/âˆ¥M âŠ¤âˆ¥4))âˆ’1 which is an increasing function of âˆ¥M âŠ¤âˆ¥. Furthermore,
since âˆ¥Mâˆ¥F /d â‰¤âˆ¥M âŠ¤âˆ¥and given the binary structure of M, âˆ¥Mâˆ¥F = m where m is the number
of nonzero elements of M. Hence, the O(1) constant is larger (i.e, worst-case convergence is slower
but still linear) when m is larger. This mainly happens for longer DAGs compared to wider ones
(given equal number of nodes), i.e., those with more ancestry structures.
Furthermore, in the
same scenario, smaller Ï makes the constant larger, and the convergence slower.
Otherwise, if
Ï â‰¥(1/2)âˆ¥M âŠ¤âˆ¥2, then the O(1) constant is (log(1 + Î±/(4Ï)))âˆ’1 which gets larger, i.e. convergence
is slower, for larger values of Ï. Finally, in both scenarios, bigger stepsize Î± (up to the linear rate
upper bound of 0.5ÏÏ„ âˆ’2
p Ïƒâˆ’2) makes the constant smaller and, the worst-case convergence faster.
4
Numerical experiments
4.1
Simulation studies
This section provides our numerical studies on the performance of the proposed algorithm to eval-
uate the proximal operator of the LOG penalty. We compare the convergence rate of the proposed
ADMM algorithm with the sharing scheme, i.e. Algorithm 3, with ï¬ve other other algorithms in-
cluding the Cyclic Block Coordinate Descent (C-BCD), shown in Algorithm 1, and its randomized
version (R-BCD) (see [38]), Proximal Gradient Descent (PGM) with backtracking (which is the
ISTA algorithm in [5]), Accelerated PGM (ACC-PGM) with backtracking (which is the FISTA
algorithm in [5]), and Hierarchical Sparse Modeling (HSM) by Yan et al. [51] to ï¬nd the proximal
mapping of the LOG penalty for the six DAGs shown in Figure 3 on simulated data.
From the six diï¬€erent graphs shown in Figure 3, four DAGs are indeed tree graphs with diï¬€erent
structures with 101, 101, 127, 201 nodes (DAGs (a)-(c) and DAG (e)); one reverse binary tree (DAG
(d)), and one random DAG with 100 nodes and 98 edges (DAG (e)) are also considered in the study.
Note that each node represents a single parameter, i.e. d = N.
In each simulation b âˆˆRd is sampled from N(0, Id). Considering problem (8), the parameters
are set as Î» = 0.1 and wg = |g|1/2. The step sizes of the PGM and ACC-PGM methods are selected
by backtracking. The Ï parameter in the ADMM algorithm is set to be a number between 1 and
1â€œQâ€ stands for Quotient. A sequence {âˆ†k} converges Q-linearly to Â¯âˆ†for a given norm âˆ¥Â· âˆ¥if âˆ¥âˆ†k+1 âˆ’
Â¯âˆ†âˆ¥/âˆ¥âˆ†k âˆ’Â¯âˆ†âˆ¥â‰¤Âµ for all k, for some Âµ âˆˆ(0, 1).
13

20 and Î± is set to 1. All simulations in this section are run on a laptop with 2.4 GHz Intel Core
i9 CPU and 32 GB memory using only one thread. The simulation is replicated 10 times and
the convergence plots are obtained over their averages. Figures 4 and 5 show the relative error
of the objective function versus iteration and time, respectively. The optimal objective function
value f âˆ—is taken to be the minimum objective function value of the converging solution over the
six diï¬€erent methods. Note that the C-BCD and R-BCD methods are not included in Figure 4,
as the notion of iteration for block coordinate methods is diï¬€erent and not comparable with the
other methods. All of the implementations and the corresponding codes are available at https:
//github.com/samdavanloo/ProxLOG.
As we can see in Figure 4, Algorithm 3 shows linear convergence for all graphs which matches
our theoretical upper bound in Section 3.1. We want to reiterate that the objective function of the
LOG penalty, i.e. (8), is not strongly convex, but the algorithm still converges linearly. The HSM
algorithm converges in ï¬nite-steps for DAG (b) which matches the theory proposed in their paper
[51], given the path structure of this graph. However, HSMâ€™s convergence becomes slower as the
graph grows in width, e.g., DAG (a), where ADMM and ACC-PGM are the fastest methods. As
expected, ACC-PGM converges faster compared to PGM for all graphs. We also note that ADMM
achieves the best objective function value f âˆ—in most of the experiments for all of the graphs.
With respect to the time, as shown in Figure 5, we compare the convergence speed of all six
methods for the six graphs shown in Figure 3. R-BCD algorithm has the fastest convergence for
DAGs (a) and (c), which are instances of two wide graphs, and ADMM and ACC-PGM are at the
second place. For DAG (b), which is a tree with two long path graphs, after HSM which provably
converges in ï¬nite steps, C-BCD and ADMM are at the second place. In the asymmetric DAG
(e), C-BCD decreases the function values fast at the beginning; however, its convergence becomes
slower (maybe sublinear), while ADMM continues its linear convergence trend.
In the random
DAG (e), C-BCD is the fastest algorithm and ADMM is at the second place. We should note that
BCD algorithms cannot be parallelized given the sequential nature of their computations; hence,
they cannot beneï¬t from parallel computing resources. In general, across diï¬€erent graph topologies,
ADMM has the most robust performance from the convergence speed perspective; furthermore, in
many instances, it produces the best ï¬nal (minimum) objective function value.
4.2
Two Applications
The proposed algorithm allows eï¬ƒcient evaluation of the proximal operator of the LOG penalty.
Evaluating the proximal operator is generally needed iteratively within a master optimization algo-
rithm that tries to solve an underlying statistical learning problem. Note that the master problem
might be a convex or nonconvex optimization problem. To demonstrate practicality of the pro-
posed algorithm, in this section, we consider two statistical learning problems on topic modeling
and classiï¬cation. The topic modeling application is a dictionary learning problem for NeurIPS
proceedings. The second application relates to a breast cancer classiï¬cation problem using gene
expression data.
4.2.1
Topic modeling of NeurIPS proceedings.
We are interested in solving the topic modeling problem represented as the dictionary learning
problem (32) penalized with the LOG penalty. Introduction of the LOG penalty is to force the
resulting topics to form a tree structure [22]. The underlying statistical learning problem can be
14

s0
s1
s2
s100
s3
. . .
(a) Two-layer tree, d = 101
s0
s1
s51
s50
s100
. . .
. . .
(b) One root two paths tree, d = 101
s0
s1
s2
. . .
. . .
. . .
. . .
(c) Binary tree, d = 127
â€¦
â€¦
â€¦
â€¦
S1
S2
S63
S64
S65
S96
S125
S126
S127
(d) Reverse binary tree, d = 127
s1
s0
s100
s101
s200
â€¦
â€¦
(e) Asymmetric tree, d = 201
(f) Random DAG, d = 100
Figure 3: Six diï¬€erent DAGs considered in the simulation study
15

0
1000
2000
3000
iteration k
10-15
10-10
10-5
100
ADMM
ACC-PGM
PGM
HSM
(a) Two-layer tree, d = 101
0
1000
2000
3000
iteration k
10-10
10-5
100
ADMM
ACC-PGM
PGM
HSM
(b) One root two paths tree, d = 101
0
1000
2000
3000
iteration k
10-10
10-5
100
ADMM
ACC-PGM
PGM
HSM
(c) Binary tree, d = 127
0
1000
2000
3000
iteration k
10-10
10-5
100
ADMM
ACC-PGM
PGM
HSM
(d) Reverse binary tree, d = 127
0
1000
2000
3000
iteration k
10-6
10-4
10-2
100
ADMM
ACC-PGM
PGM
HSM
(e) Asymmetric tree, d = 201
0
1000
2000
3000
iteration k
10-15
10-10
10-5
100
ADMM
ACC-PGM
PGM
HSM
(f) Random DAG, d = 100
Figure 4: Convergence of the proposed ADMM, Proximal Gradient Method (PGM), and
Accelerated PGM (ACC-PGM), Hierarchical Sparse Modeling (HSM) algorithms versus
iteration for the six DAGs in Figure 3.
16

0
0.2
0.4
0.6
0.8
1
time (seconds)
10-15
10-10
10-5
100
ADMM
ACC-PGM
PGM
C-BCD
R-BCD
HSM
(a) Two-layer tree, d = 101
0
0.5
1
1.5
time (seconds)
10-10
10-5
100
ADMM
ACC-PGM
PGM
C-BCD
R-BCD
HSM
(b) One root two paths tree, d = 101
0
0.2
0.4
0.6
0.8
1
time (seconds)
10-5
100
ADMM
ACC-PGM
PGM
C-BCD
R-BCD
HSM
(c) Binary tree, d = 127
0
0.2
0.4
0.6
0.8
1
time (seconds)
10-10
10-5
100
ADMM
ACC-PGM
PGM
C-BCD
R-BCD
HSM
(d) Reverse binary tree, d = 127
0
1
2
3
time (seconds)
10-6
10-4
10-2
100
ADMM
ACC-PGM
PGM
C-BCD
R-BCD
HSM
(e) Asymmetric tree, d = 201
0
0.2
0.4
0.6
0.8
1
time (seconds)
10-10
10-5
100
ADMM
ACC-PGM
PGM
C-BCD
R-BCD
HSM
(f) Random DAG, d = 100
Figure 5: Convergence of the proposed ADMM, Proximal Gradient Method (PGM), Ac-
celerated PGM (ACC-PGM), Cyclic BCD (C-BCD), Randomized BCD (R-BCD), and
Hierarchical Sparse Modeling (HSM) algorithms over time for the six DAGs shown in
Figure 3.
17

written as
min
DâˆˆD+
1 ,AâˆˆRkÃ—n
+
n
X
j=1
1
2âˆ¥xj âˆ’DÎ±jâˆ¥2
2 + Î»â„¦LOG(Î±j)

(32)
where X = [x1, x2, Â· Â· Â· , xn] âˆˆRmÃ—n represents frequencies of m words in n articles and the i-th
element of xj is the frequency of the i-th word in the j-th article. D = [d1, d2, Â· Â· Â· , dk] âˆˆD+
1 is
the dictionary of k topics to be learnt where D+
1 â‰œ{D âˆˆRmÃ—k
+
:
âˆ¥djâˆ¥1 â‰¤1, j = 1, 2, Â· Â· Â· , k}.
Furthermore, A â‰œ[Î±1, Î±2, Â· Â· Â· , Î±n] âˆˆRkÃ—n
+
is the corresponding coeï¬ƒcients for each article such
that xj â‰ˆDÎ±j.
Following the framework of [22], we solve (32) using an alternating minimization scheme, i.e.,
updating D and A one at a time while keeping the other one ï¬xed. The D update is performed
using C-BCD algorithm, taking its columns as the blocks, using the algorithm of [26].
The A
update is performed by the accelerated proximal gradient method ACC-PGM [5]. To evaluate the
proximal operator of the LOG penalty, we implemented the proposed ADMM (with and without
parallelization), R-BCD, and C-BCD algorithms. Given that the number of groups for this appli-
cation is |G| = 13, the ï¬rst block update of the (parallel) ADMM (lines 4 and 5 of Algorithm 3) for
each Î±j is parallelized over 13 processing nodes. We also included unparallelized ADMM algorithm
for comparison. Note that BCD algorithms cannot be parallelized.
These three nested algorithms are implemented for the NeurIPS proceedings from 1996 to
2015 [35]. The dataset contains n = 1846 articles with m = 11463 words that excludes stop words
and words occurring less than 50 times. We set k = 13, Î» = 2âˆ’15, and followed the hierarchical
structure proposed by [22] to induce a tree of topics - see Figure 7. The experiment is run on a
cluster with 2.4GHz CPU and 128GB memory using 28 threads. Note that the columns of the A
matrix, i.e. Î±j, can be updated in parallel over n = 1846 articles for all three methods.
Figure 6 shows the convergence behavior of the algorithms discussed above using the norm of
the proximal gradient (see Deï¬nition 3.1) and (1/n)âˆ¥Ak âˆ’Akâˆ’1âˆ¥F + (1/m)âˆ¥Dk âˆ’Dkâˆ’1âˆ¥F as two
convergence measures. Evaluating the proximal operator of the columns of the A matrix using the
C-BCD and parallelized ADMM are the two fastest methods, but the quality of the C-BCD solution
seems to be better. Even though the number of groups is relatively small |G| = 13, parallelization
is signiï¬cantly reducing the convergence time. Reduction of the convergence time by parallelization
of ADMM will even be more signiï¬cant when the number of groups is bigger â€“ see the application
in Section 4.2.2. Figure 7 depicts the learnt hierarchal topics with the 7 most frequent words. The
root is a general topic while the leafs are more speciï¬c and narrower topics.
4.2.2
Breast cancer classiï¬cation.
This section discusses ï¬tting a logistic regression model penalized with the LOG penalty to classify
breast cancer based on gene expression levels. It is known that genes functionalities are highly
aï¬€ected by their two-way interactions which might be a priori known based on a protein-protein
network. Hence, to identify contributing genes for cancer metastasis, it is important to consider
such structures.
We use the breast cancer dataset of [47] that consists of 8141 gene expression data for 78
metastatic and 217 non-metastatic patients. Following the experimental settings in [32], we build
groups of genes based on the protein-protein network of [13]. Every two genes connected directly
by an edge in the network are assigned as a group. The total number of groups for this application
is |G| = 522. Given that groups have overlaps on many nodes, LOG penalty is used to capture the
18

0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
2
time (seconds)
105
10-6
10-5
10-4
10-3
10-2
10-1
100
101
102
Figure 6: Convergence of the algorithm for the topic modeling application on two diï¬€erent
convergence measures.
The A-update is performed by ACC-PGM algorithm where its
proximal operator is evaluated by the ADMM (with/without parallelization), R-BCD, and
C-BCD methods.
relationship within groups. The genes that are not contained in the network are eliminated and the
500 most correlated genes are selected.
The learning problem involves minimizing the logistic loss function regularized with the LOG
penalty that can be written as
min
Î¸ f(Î¸) = âˆ’1
m
m
X
i=1
{y(i) log hÎ¸(x(i)) + (1 âˆ’y(i)) log(1 âˆ’hÎ¸(x(i)))} + Î»â„¦LOG(Î¸),
(33)
where (x(i), y(i)) is the input data, y(i) is either 0 or 1, and hÎ¸(x) â‰œ
1
1+eâˆ’Î¸T x . The underlying learn-
ing problem is solved by ACC-PGM algorithm while the proximal operator of the LOG penalty is
evaluated by the proposed ADMM (with/without parallelization), R-BCD, and C-BCD algorithms.
The Î» parameter is set equal to 10âˆ’3. The experiment is run on a cluster with 2.4GHz CPU and
128GB memory using 28 threads.
Validation of the classiï¬cation performance with the LOG penalty for such a problem is per-
formed e.g. in [32]; so, we only focus on the convergence behavior of the proposed algorithm. The
left plot in Figure 8 shows the convergence of ACC-PGM with diï¬€erent proximal evaluators. While
the ADMM method without parallelization is faster than R-BCD and C-BCD methods, paralleliza-
tion of its ï¬rst block over the available 28 nodes signiï¬cantly decrease its convergence time. Note
that such parallelization theoretically reduces the time further up to 522 nodes which is the number
of groups |G|.
We also examine the eï¬€ect of the LOG penalty for gene selection.
For visual convenience,
we increase Î» to from 0.001 to 0.05 to make the regression coeï¬ƒcients sparser and evaluate the
relationships of selected and unselected genes. The right plot in Figure 8 is a subset of the network
19

'data'
'points'
'set'
'number'
'time'
'clustering'
'kernel'
'theorem'
'bound'
'probability'
'distribution'
'let'
'error'
'sample'
'matrix'
'rank'
'norm'
'low'
'matrices'
'sparse'
'problem'
'function'
'functions'
'problem'
'set'
'loss'
'optimization'
'convex'
'network'
'time'
'neural'
'networks'
'neurons'
'input'
'layer'
'image'
'images'
'features'
'object'
'training'
'feature'
'using'
'algorithm'
'regret'
'algorithms'
'bound'
'time'
'problem'
'online'
'learning'
'training'
'label'
'loss'
'task'
'classification'
'examples'
'graph'
'nodes'
'tree'
'node'
'graphs'
'set'
'algorithm'
'policy'
'state'
'action'
'value'
'reward'
'time'
'function'
'model'
'models'
'data'
'latent'
'parameters'
'topic'
'structure'
'gradient'
'convergence'
'method'
'convex'
'optimization'
'methods'
'stochastic'
'distribution'
'inference'
'gaussian'
'posterior'
â€˜Bayesian'
'sampling'
'variational'
Figure 7: Hierarchical topics of NeurIPS from 1996 to 2015
of 500 genes. Each node represents a gene and the edges are known a priori from the protein-
protein network. Nonzero coeï¬ƒcients in the ï¬nal model identify genes which are correlated with
breast cancer metastasis. From this result, it is clear that connected genes are prone to be selected
simultaneously which supports the rationality of the LOG penalty for this application.
5
Concluding remarks
The paper discusses an eï¬ƒcient algorithm to ï¬nd the proximal mapping of the Latent Overlapping
Group (LOG) lasso penalty to induce hierarchical sparsity structure represented by any general
DAG. The sharing scheme for the underlying ADMM algorithm allows maximum parallelization over
(potentially) many number of groups which allows solving large-scale instances of the underlying
optimization problems which could be convex or nonconvex loss function. On the theoretical side,
the paper establishes global linear rate of convergence in the absence of strong convexity. The rate
analysis is performed through the elegant error bound theory. Furthermore, the paper investigates
the eï¬€ect of graph structure on the speed of convergence of the algorithm. The numerical results
conï¬rms our theoretical convergence rate for diï¬€erent directed acyclic graphs with diï¬€erent sizes.
20

0
500
1000
1500
2000
2500
time (seconds)
10-3
10-2
10-1
100
101
f(3k) ! f $=jf $j
ADMM
ADMM (parallelized)
R-BCD
C-BCD
selected parameters
unselected parameters
Figure 8: Breast cancer classiï¬cation: (Left) Convergence of the ACC-PGM method where
the proximal map is evaluated using ADMM (with/without parallelization), R-BCD, and
C-BCD methods.(Right) Part of the gene network: red nodes are nonzero genes while blue
nodes are zero ones. Edge structures are known a priori from the protein-protein network
- see [13].
References
[1] AtamtÂ¨urk, Alper, & GÂ´omez, AndrÂ´es. 2018. Strong formulations for quadratic optimization with
M-matrices and indicator variables. Mathematical Programming, 170(1), 141â€“176.
[2] Bach, Francis, Jenatton, Rodolphe, Mairal, Julien, Obozinski, Guillaume, et al. 2012. Structured
sparsity through convex optimization. Statistical Science, 27(4), 450â€“468.
[3] Bach, Francis, et al. 2013. Learning with submodular functions: A convex optimization per-
spective. Foundations and TrendsÂ® in Machine Learning, 6(2-3), 145â€“373.
[4] Bach, Francis R. 2010.
Structured sparsity-inducing norms through submodular functions.
Pages 118â€“126 of: Advances in Neural Information Processing Systems.
[5] Beck, Amir, & Teboulle, Marc. 2009. A fast iterative shrinkage-thresholding algorithm for linear
inverse problems. SIAM journal on imaging sciences, 2(1), 183â€“202.
[6] Bertsekas, Dimitri P. 1999. Nonlinear programming. Athena scientiï¬c Belmont.
[7] Bertsimas, Dimitris, & Van Parys, Bart. 2017.
Sparse high-dimensional regression: Exact
scalable algorithms and phase transitions. arXiv preprint arXiv:1709.10029.
[8] Bertsimas, Dimitris, King, Angela, Mazumder, Rahul, et al. 2016. Best subset selection via a
modern optimization lens. The Annals of Statistics, 44(2), 813â€“852.
21

[9] Bertsimas, Dimitris, Cory-Wright, Ryan, & Pauphilet, Jean. 2019.
A uniï¬ed approach to
mixed-integer optimization: Nonlinear formulations and scalable algorithms.
arXiv preprint
arXiv:1907.02109.
[10] Bien, Jacob, Taylor, Jonathan, & Tibshirani, Robert. 2013. A lasso for hierarchical interactions.
Annals of statistics, 41(3), 1111.
[11] Boyd, Stephen, Parikh, Neal, Chu, Eric, Peleato, Borja, & Eckstein, Jonathan. 2011. Dis-
tributed optimization and statistical learning via the alternating direction method of multipliers.
Foundations and TrendsÂ® in Machine Learning, 3(1), 1â€“122.
[12] Chouldechova, Alexandra, & Hastie, Trevor. 2015. Generalized additive model selection. arXiv
preprint arXiv:1506.03850.
[13] Chuang, Han-Yu, Lee, Eunjung, Liu, Yu-Tsueng, Lee, Doheon, & Ideker, Trey. 2007. Network-
based classiï¬cation of breast cancer metastasis. Molecular systems biology, 3(1), 140.
[14] Eckstein, Jonathan, & Yao, Wang. 2012. Augmented Lagrangian and Alternating Direction
Methods for Convex Optimization: A Tutorial and Some Illustrative Computational Results.
RUTCOR Research Reports, 32(Suppl. 3).
[15] Glowinski, Roland. 1984. Numerical methods for nonlinear variational problems. Springer.
[16] Haris, Asad, Witten, Daniela, & Simon, Noah. 2016. Convex modeling of interactions with
strong heredity. Journal of Computational and Graphical Statistics, 25(4), 981â€“1004.
[17] Hastie, Trevor, Tibshirani, Robert, & Wainwright, Martin. 2015.
Statistical learning with
sparsity. CRC press.
[18] Hazimeh, Hussein, & Mazumder, Rahul. 2019. Learning Hierarchical Interactions at Scale: A
Convex Optimization Approach. arXiv preprint arXiv:1902.01542.
[19] Hoï¬€man, Alan J. 1952. On approximate solutions of systems of linear inequalities. Journal of
Research of the National Bureau of Standards, 49(4), 263â€“265.
[20] Hong, Mingyi, & Luo, Zhi-Quan. 2017. On the linear convergence of the alternating direction
method of multipliers. Mathematical Programming, 162(1-2), 165â€“199.
[21] Jacob, Laurent, Obozinski, Guillaume, & Vert, Jean-Philippe. 2009. Group lasso with overlap
and graph lasso. Pages 433â€“440 of: Proceedings of the 26th annual international conference on
machine learning. ACM.
[22] Jenatton, Rodolphe, Mairal, Julien, Obozinski, Guillaume, & Bach, Francis. 2011a. Proximal
methods for hierarchical sparse coding. Journal of Machine Learning Research, 12(Jul), 2297â€“
2334.
[23] Jenatton, Rodolphe, Audibert, Jean-Yves, & Bach, Francis. 2011b. Structured variable selec-
tion with sparsity-inducing norms. Journal of Machine Learning Research, 12(Oct), 2777â€“2824.
[24] Lim, Michael, & Hastie, Trevor. 2015. Learning interactions via hierarchical group-lasso regu-
larization. Journal of Computational and Graphical Statistics, 24(3), 627â€“654.
22

[25] Luo, Zhi-quan, & Tseng, Paul. 1993. On the convergence rate of dual ascent methods for
linearly constrained convex minimization. Mathematics of Operations Research, 18(4), 846â€“867.
[26] Mairal, Julien, Bach, Francis, Ponce, Jean, & Sapiro, Guillermo. 2010. Online learning for
matrix factorization and sparse coding. Journal of Machine Learning Research, 11(Jan), 19â€“60.
[27] Mairal, Julien, Jenatton, Rodolphe, Obozinski, Guillaume, & Bach, Francis. 2011. Convex
and network ï¬‚ow optimization for structured sparsity. Journal of Machine Learning Research,
12(Sep), 2681â€“2720.
[28] Mangasarian, O. L., & Shiau, T-H. 1987. Lipschitz continuity of solutions of linear inequalities,
programs and complementarity problems. SIAM Journal on Control and Optimization, 25(3),
583â€“595.
[29] Manzour, Hasan, KÂ¨uÂ¸cÂ¨ukyavuz, Simge, & Shojaie, Ali. 2019. Integer Programming for Learning
Directed Acyclic Graphs from Continuous Data. arXiv preprint arXiv:1904.10574.
[30] Mazumder, Rahul, & Radchenko, Peter. 2017.
TheDiscrete Dantzig Selector: Estimating
Sparse Linear Models via Mixed Integer Linear Optimization. IEEE Transactions on Information
Theory, 63(5), 3053â€“3075.
[31] Nesterov, Yu. 2013.
Gradient methods for minimizing composite functions.
Mathematical
Programming, 140(1), 125â€“161.
[32] Obozinski, Guillaume, Jacob, Laurent, & Vert, Jean-Philippe. 2011. Group lasso with overlaps:
the latent group lasso approach. arXiv preprint arXiv:1110.0413.
[33] Pang, Jong-Shi. 1997. Error bounds in mathematical programming. Mathematical Program-
ming, 79(1-3), 299â€“332.
[34] Parikh, Neal, Boyd, Stephen, et al. 2014. Proximal algorithms. Foundations and TrendsÂ® in
Optimization, 1(3), 127â€“239.
[35] Perrone, Valerio, Jenkins, Paul A, Spano, Dario, & Teh, Yee Whye. 2016. Poisson random
ï¬elds for dynamic feature models. arXiv preprint arXiv:1611.07460.
[36] Radchenko, Peter, & James, Gareth M. 2010. Variable selection using adaptive nonlinear inter-
action structures in high dimensions. Journal of the American Statistical Association, 105(492),
1541â€“1553.
[37] Razaviyayn, Meisam, Hong, Mingyi, & Luo, Zhi-Quan. 2013. A uniï¬ed convergence analy-
sis of block successive minimization methods for nonsmooth optimization. SIAM Journal on
Optimization, 23(2), 1126â€“1153.
[38] RichtÂ´arik, Peter, & TakÂ´aË‡c, Martin. 2014. Iteration complexity of randomized block-coordinate
descent methods for minimizing a composite function. Mathematical Programming, 144(1-2),
1â€“38.
[39] Schmidt, Mark, & Murphy, Kevin. 2010.
Convex structure learning in log-linear models:
Beyond pairwise potentials. Pages 709â€“716 of: Proceedings of the Thirteenth International Con-
ference on Artiï¬cial Intelligence and Statistics.
23

[40] She, Yiyuan, Wang, Zhifeng, & Jiang, He. 2018. Group regularized estimation under structural
hierarchy. Journal of the American Statistical Association, 113(521), 445â€“454.
[41] Stephen M., Robinson. 1973. Bounds for error in the solution set of a linear perturbed linear
program. Linear Algebra and Its Applications, 6, 69â€“81.
[42] Stephen M., Robinson. 1981. Some continuity properties polyhedral multifunctions. Mathe-
matical Programming Study, 14, 206â€“214.
[43] Tibshirani, Robert. 1996. Regression shrinkage and selection via the lasso. Journal of the
Royal Statistical Society. Series B (Methodological), 267â€“288.
[44] Tseng, Paul. 2001. Convergence of a block coordinate descent method for nondiï¬€erentiable
minimization. Journal of optimization theory and applications, 109(3), 475â€“494.
[45] Tseng, Paul. 2010. Approximation accuracy, gradient methods, and error bound for structured
convex optimization. Mathematical Programming, 125(2), 263â€“295.
[46] Tseng, Paul, & Yun, Sangwoon. 2009. A coordinate gradient descent method for nonsmooth
separable minimization. Mathematical Programming, 117(1-2), 387â€“423.
[47] Van De Vijver, Marc J, He, Yudong D, Vanâ€™t Veer, Laura J, Dai, Hongyue, Hart, Augusti-
nus AM, Voskuil, Dorien W, Schreiber, George J, Peterse, Johannes L, Roberts, Chris, Marton,
Matthew J, et al. 2002. A gene-expression signature as a predictor of survival in breast cancer.
New England Journal of Medicine, 347(25), 1999â€“2009.
[48] Villa, Silvia, Rosasco, Lorenzo, Mosci, Soï¬a, & Verri, Alessandro. 2014. Proximal methods for
the latent group lasso penalty. Computational Optimization and Applications, 58(2), 381â€“407.
[49] Walkup, David W., & Wets, Roger J.-B. 1969.
A lipschitzian characterization of convex
polyhedra. Proceedings of the American Mathematical Society, 23(1), 167â€“173.
[50] Wolsey, Laurence A, & Nemhauser, George L. 2014. Integer and combinatorial optimization.
John Wiley & Sons.
[51] Yan, Xiaohan, Bien, Jacob, et al. 2017. Hierarchical Sparse Modeling: A Choice of Two Group
Lasso Formulations. Statistical Science, 32(4), 531â€“560.
[52] Yuan, Ming, & Lin, Yi. 2006.
Model selection and estimation in regression with grouped
variables. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 68(1),
49â€“67.
[53] Zhang, Haibin, Jiang, Jiaojiao, & Luo, Zhi-Quan. 2013. On the linear convergence of a prox-
imal gradient method for a class of nonsmooth convex minimization problems. Journal of the
Operations Research Society of China, 1(2), 163â€“186.
[54] Zhao, Peng, & Yu, Bin. 2006. On model selection consistency of Lasso. Journal of Machine
learning research, 7(Nov), 2541â€“2563.
[55] Zhou, Zirui, & Man-Cho So, Anthony. 2019. A Uniï¬ed Approach to Error Bounds for Struc-
tured Convex Optimization Problems. Mathematical Programming, 165(2), 689â€”-728.
24

A
Proof of of the dual error bound - Lemma 3.1
The framework of the proof was ï¬rst proposed in [25] and also applied in [20] and requires â€œlocally
upper Lipschitzianâ€ property of polyhedral multifunction for the map induced by KKT conditionsâ€“
see also [42, 49, 41, 28, 19]. However, due to the presence of the conic constraints in (28), the
resulting multifunction is not polyhedral anymore. Indeed, [49] showed that having a polyhedral
graph is a necessary condition for the upper Lipschitzian property of the multifunction.
The
following proof uses the speciï¬c structure of this problem to establish the dual error bound condition.
For any y âˆˆRn and yâˆ—âˆˆY âˆ—, considering the KKT conditions (29), we have
âˆ¥y âˆ’yâˆ—âˆ¥2
2 = âˆ¥M âŠ¤M(x2(y) âˆ’x2(yâˆ—)) + Ï(x2(y) âˆ’x1(y)) âˆ’Ï(x2(yâˆ—) âˆ’x1(yâˆ—))âˆ¥2
2
= âˆ¥âˆ‡x2Ï†(Mx2(y)) âˆ’âˆ‡x2Ï†(Mx2(yâˆ—)) + âˆ‡x2Ïˆ(Ex(y)) âˆ’âˆ‡x2Ïˆ(Ex(yâˆ—))âˆ¥2
2
â‰¤âˆ¥âˆ‡x2Ï†(Mx2(y)) âˆ’âˆ‡x2Ï†(Mx2(yâˆ—))âˆ¥2
2 + âˆ¥âˆ‡xÏˆ(Ex(y)) âˆ’âˆ‡xÏˆ(Ex(yâˆ—))âˆ¥2
2,
where the ï¬rst equality follows from (29b), the second equality follows from the deï¬nition of Ï†(Â·)
and Ïˆ(Â·) (deï¬ned below (25)), the third inequality follows from the triangle inequality. Hence, using
(26) and (27), we have
âˆ¥y âˆ’yâˆ—âˆ¥2
2 â‰¤L2
Ï†âˆ¥Mx2(y) âˆ’Mx2(yâˆ—)âˆ¥2
2 + L2
Ïˆâˆ¥Ex(y) âˆ’Ex(yâˆ—)âˆ¥2
2.
(34)
Next, consider
âˆ¥Mx2(y) âˆ’Mx2(yâˆ—)âˆ¥2
2 + Ïâˆ¥Ex(y) âˆ’Ex(yâˆ—)âˆ¥2
2
=

M âŠ¤Mx2(y) âˆ’M âŠ¤Mx2(yâˆ—), x2(y) âˆ’x2(yâˆ—)

+ Ï

EâŠ¤Ex(y) âˆ’M âŠ¤Mx(yâˆ—), x(y) âˆ’x(yâˆ—)

=

âˆ‡xÏ†(Mx2(y)) âˆ’âˆ‡xÏ†(Mx2(yâˆ—)), x(y) âˆ’x(yâˆ—)

+ âŸ¨âˆ‡xÏˆ(Ex(y)) âˆ’âˆ‡xÏˆ(Ex(yâˆ—)), x(y) âˆ’x(yâˆ—)âŸ©
= âŸ¨âˆ‡xâ„“(x(y)) âˆ’âˆ‡xâ„“(x(yâˆ—)), x(y) âˆ’x(yâˆ—)âŸ©
=

âˆ‡x1â„“(x(y)) âˆ’âˆ‡x1â„“(x(yâˆ—)), x1(y) âˆ’x1(yâˆ—)

+

âˆ‡x2â„“(x(y)) âˆ’âˆ‡x2â„“(x(yâˆ—)), x2(y) âˆ’x2(yâˆ—)

=
X
gâˆˆG
D
âˆ‡x1
j(g)â„“(x(y)) âˆ’âˆ‡x1
j(g)â„“(x(yâˆ—)), x1
j(g)(y) âˆ’x1
j(g)(yâˆ—)
E
+
X
gâˆˆG
D
âˆ‡x2
j(g)â„“(x(y)) âˆ’âˆ‡x2
j(g)â„“(x(yâˆ—)), x2
j(g)(y) âˆ’x2
j(g)(yâˆ—)
E
=
X
gâˆˆG
D
wgÂµg(y) âˆ’yj(g) âˆ’wgÂµg(yâˆ—) + yâˆ—
j(g), x1
j(g)(y) âˆ’x1
j(g)(yâˆ—)
E
+
X
gâˆˆG
D
yj(g) âˆ’yâˆ—
j(g), x2
j(g)(y) âˆ’x2
j(g)(yâˆ—)
E
where the second and third equalities follow from the deï¬nitions of Ï†, Ïˆ, and â„“, in the forth and
ï¬fth equalities the gradient is expanded over each x1 and x2, and the last equality follows from
(29a),(29b). Rearranging the terms in the last line above and using x1
j(g)(yâˆ—) = x2
j(g)(yâˆ—) âˆ€g âˆˆG,
we get
âˆ¥Mx2(y) âˆ’Mx2(yâˆ—)âˆ¥2
2 + Ïâˆ¥Ex(y) âˆ’Ex(yâˆ—)âˆ¥2
2
=
X
gâˆˆG
D
wgÂµg(y) âˆ’wgÂµg(yâˆ—), x1
j(g)(y) âˆ’x1
j(g)(yâˆ—)
E
+
X
gâˆˆG
D
yj(g) âˆ’yâˆ—
j(g), x2
j(g)(y) âˆ’x1
j(g)(y)
E
,
(35)
25

For all g âˆˆG, we have
D
wgÂµg(y) âˆ’wgÂµg(yâˆ—), x1
j(g)(y) âˆ’x1
j(g)(yâˆ—)
E
= wgÂµg(y)âŠ¤x1
j(g)(y) âˆ’wgÂµg(yâˆ—)âŠ¤x1
j(g)(y) âˆ’wgÂµg(y)âŠ¤x1
j(g)(yâˆ—) + wgÂµg(yâˆ—)âŠ¤x1
j(g)(yâˆ—)
= âˆ’wg(sg/wg)Î» âˆ’wgÂµg(yâˆ—)âŠ¤x1
j(g)(y) âˆ’wgÂµg(y)âŠ¤x1
j(g)(yâˆ—) âˆ’wg(sg/wg)Î»
â‰¤wgâˆ¥Âµg(yâˆ—)âˆ¥2âˆ¥x1
j(g)(y)âˆ¥2 + wgâˆ¥Âµg(y)âˆ¥2âˆ¥x1
j(g)(yâˆ—)âˆ¥2 âˆ’2sgÎ»
â‰¤0,
where the second equality follows from (29c) and (29f), the third inequality uses Cauchy-Schwarz
inequality, and the last inequality follows from (29c), (29d), and (29e). Hence, we have
âˆ¥Mx2(y) âˆ’Mx2(yâˆ—)âˆ¥2
2 + Ïâˆ¥Ex(y) âˆ’Ex(yâˆ—)âˆ¥2
2 â‰¤
X
gâˆˆG
D
yj(g) âˆ’yâˆ—
j(g), x2
j(g)(y) âˆ’x1
j(g)(y)
E
(36)
â‰¤âˆ¥y âˆ’yâˆ—âˆ¥âˆ¥âˆ‡gÏ(y)âˆ¥,
(37)
where (36) uses nonpositivity of the ï¬rst term in (35) (shown above), and (37) follows from Cauchy-
Schwarz inequality and the fact that âˆ‡gÏ(y) = x1(y) âˆ’x2(y) â€“ see e.g. [20] - Lemma 2.1. Finally,
using (37) and (34), we get
âˆ¥y âˆ’yâˆ—âˆ¥2
2 â‰¤max{L2
Ï†, L2
Ïˆ/Ï}

âˆ¥Mx2(y) âˆ’Mx2(yâˆ—)âˆ¥2
2 + Ïâˆ¥Ex(y) âˆ’Ex(yâˆ—)âˆ¥2
2

(38)
â‰¤max{L2
Ï†, L2
Ïˆ/Ï}âˆ¥y âˆ’yâˆ—âˆ¥2âˆ¥âˆ‡gÏ(y)âˆ¥2.
(39)
Hence, we have
dist(y, Y âˆ—) â‰¤âˆ¥y âˆ’yâˆ—âˆ¥â‰¤max{L2
Ï†, L2
Ïˆ/Ï}âˆ¥âˆ‡gÏ(y)âˆ¥2.
(40)
B
Proof of Lemma 3.2
Before proceeding with the proof of the boundedness of the iterates, we show the existence of a
ï¬nite saddle point by the following argument. Consider
min
x1,x2âˆˆRn
ï£±
ï£²
ï£³
ËœF(x1, x2) = Î»
X
gâˆˆG
wgâˆ¥x1
j(g)âˆ¥2 + 1
2âˆ¥Mx2 âˆ’bâˆ¥2
2 + Ï
2âˆ¥x1 âˆ’x2âˆ¥2
2,
s.t. x1 = x2
ï£¼
ï£½
ï£¾.
(41)
The above problem is equivalent to (8) whose objective function is coercive and continuous. By
Weierstrassâ€™s Theorem (see e.g. [6]), we have certain ï¬nite optimal solution to (41) (x1,âˆ—, x2,âˆ—),
i.e. ËœF âˆ—= infx1=x2âˆˆRn ËœF(x1, x2) = ËœF(x1,âˆ—, x2,âˆ—). Especially, x1,âˆ—= x2,âˆ—. Consider LÏ(x1, x2; y) =
ËœF(x1, x2)+

y, x1 âˆ’x2
and the corresponding dual function gÏ(y). First, we have LÏ(x1,âˆ—, x2,âˆ—; y) =
ËœF(x1,âˆ—, x2,âˆ—), for âˆ€y. By strong duality (see e.g. Prop. 5.2.1 in [6]), we know there is no duality gap.
Furthermore, there exists at least one Lagrange multiplier yâˆ—, i.e. ËœF âˆ—= infx1,x2âˆˆR LÏ(x1, x2; yâˆ—) =
gÏ(yâˆ—). We conclude (x1,âˆ—, x2,âˆ—; y) is a ï¬nite saddle point.
The idea for the proof of boundedness of the iterates is similar to Theorem 5.1 in [15]; however,
we do not have the strong convexity assumption. Given a ï¬nite saddle point ((x1,âˆ—, x2,âˆ—); yâˆ—), deï¬ne
26

Ëœx1,k â‰œx1,k âˆ’x1,âˆ—, Ëœx2,k â‰œx2,k âˆ’x2,âˆ—, Ëœyk â‰œyk âˆ’yâˆ—where x1,âˆ—= x2,âˆ—. Establishing the boundedness
of the sequence is equivalent to showing that the sequence {âˆ¥Ëœykâˆ¥2
2 + Î±Ïâˆ¥Ëœx2,kâˆ¥2
2 + Î±(Ï âˆ’Î±)âˆ¥Ëœx1,k âˆ’
Ëœx2,kâˆ¥2
2}âˆ
k=1 is non-increasing. From the convexity of the augmented Lagrangian function (10) in x1,
we have

yâˆ—+ Ï(x1,âˆ—âˆ’x2,âˆ—), x1 âˆ’x1,âˆ—
+ Î»
X
gâˆˆG
wgâˆ¥x1
j(g)âˆ¥2 âˆ’Î»
X
gâˆˆG
wgâˆ¥x1,âˆ—
j(g)âˆ¥2 â‰¥0, âˆ€x1.
(42)
Furthermore, from the convexity of the augmented Lagrangian (10) in x2, we have

M âŠ¤(Mx2,âˆ—âˆ’b) âˆ’yâˆ—+ Ï(x2,âˆ—âˆ’x1,âˆ—), x2 âˆ’x2,âˆ—
â‰¥0, âˆ€x2.
(43)
From the fact that LÏ(x1,âˆ—, x2,âˆ—; yâˆ—) â©½LÏ(x1, x2; yâˆ—), âˆ€x1, x2, we have
yâˆ—= yâˆ—+ Î±(x1,âˆ—âˆ’x2,âˆ—).
(44)
Similar to the arguments for (42)-(44), from (13)-(15), we have
D
Ï(x1,k+1
j(g)
âˆ’x2,k
j(g)) + yk
j(g), x1
j(g) âˆ’x1,k+1
j(g)
E
+ Î»wgâˆ¥x1
j(g)âˆ¥2 âˆ’Î»wgâˆ¥x1,k+1
j(g) âˆ¥2 â‰¥0,
âˆ€g âˆˆG, âˆ€x1
j(g),
(45)

M âŠ¤(Mx2,k+1 âˆ’b) + Ï(x2,k+1 âˆ’x1,k+1) âˆ’yk, x2 âˆ’x2,k+1
â‰¥0,
âˆ€x2,
(46)
yk+1
j(g) = yk
j(g) + Î±(x1,k+1
j(g)
âˆ’x2,k+1
j(g) ),
âˆ€g âˆˆG.
(47)
Since j(g) âˆ©j(Â¯g) = âˆ…for all g, Â¯g âˆˆG such that g Ì¸= Â¯g, from (45) and (47), we have:

Ï(x1,k+1 âˆ’x2,k) + yk, x1 âˆ’x1,k+1
+ Î»
X
gâˆˆG
wgâˆ¥x1
j(g)âˆ¥2 âˆ’Î»
X
gâˆˆG
wgâˆ¥x1,k+1
j(g) âˆ¥2 â‰¥0,
âˆ€x1,
(48)
yk+1 = yk + Î±(x1,k+1 âˆ’x2,k+1).
(49)
Setting x1 = x1,k+1 in (42), and x1 = x1,âˆ—in (48) and adding them, we get

âˆ’Ëœyk + Ï(Ëœx2,k âˆ’Ëœx1,k+1), Ëœx1,k+1
â‰¥0
(50)
Similarly, setting x2 = x2,k+1 in (43), and x2 = x2,âˆ—in (46) and adding them, we get

M âŠ¤M Ëœx2,k+1 âˆ’Ëœyk âˆ’Ï(Ëœx1,k+1 âˆ’Ëœx2,k+1), âˆ’Ëœx2,k+1
â‰¥0
(51)
Adding the left-hand-sides of (50) to (51) and rearranging the terms, we have,

âˆ’Ëœyk, Ëœx1,k+1 âˆ’Ëœx2,k+1
+ Ï

Ëœx2,k âˆ’Ëœx1,k+1, Ëœx1,k+1
+ Ï

Ëœx1,k+1 âˆ’Ëœx2,k+1, Ëœx2,k+1
âˆ’âˆ¥M Ëœx2,k+1âˆ¥2
2
=

âˆ’Ëœyk, Ëœx1,k+1 âˆ’Ëœx2,k+1
+ Ï

Ëœx2,k âˆ’Ëœx1,k+1 + Ëœx2,k+1 âˆ’Ëœx2,k+1, Ëœx1,k+1
+ Ï

Ëœx1,k+1 âˆ’Ëœx2,k+1), Ëœx2,k+1
âˆ’âˆ¥M Ëœx2,k+1âˆ¥2
2
Hence, we have
Ï

Ëœx2,k âˆ’Ëœx2,k+1, Ëœx1,k+1
âˆ’âˆ¥M Ëœx2,k+1âˆ¥2
2 âˆ’Ïâˆ¥Ëœx2,k+1 âˆ’Ëœx1,k+1âˆ¥2
2 â‰¥

Ëœx1,k+1 âˆ’Ëœx2,k+1, Ëœyk
.
(52)
27

From (49), we have the following two inequalities:
Ëœyk+1 âˆ’Ëœyk = Î±(Ëœx1,k+1 âˆ’Ëœx2,k+1)
Ëœyk+1 + Ëœyk = Î±(Ëœx1,k+1 âˆ’Ëœx2,k+1) + 2Ëœyk
Taking the inner product of the left terms together and the right terms together, we obtain
âˆ¥Ëœyk+1âˆ¥2
2 âˆ’âˆ¥Ëœykâˆ¥2
2 = Î±2âˆ¥Ëœx1,k+1 âˆ’Ëœx2,k+1âˆ¥+ 2Î±

Ëœx1,k+1 âˆ’Ëœx2,k+1, Ëœyk
(53)
â‰¤Î±(Î± âˆ’2Ï)âˆ¥Ëœx1,k+1 âˆ’Ëœx2,k+1âˆ¥2
2 âˆ’2Î±âˆ¥M Ëœx2,k+1âˆ¥2
2 + 2Î±Ï

Ëœx2,k âˆ’Ëœx2,k+1, Ëœx1,k+1
(54)
where the inequality uses (52). Next, we will upper bound

Ëœx2,k âˆ’Ëœx2,k+1, Ëœx1,k+1
. Setting x2 = x2,k
in (46), we have

M âŠ¤(Mx2,k+1 âˆ’b) + Ï(x2,k+1 âˆ’x1,k+1) âˆ’yk, x2,k âˆ’x2,k+1
â‰¥0.
(55)
Setting k + 1 in (46) to k, and x2 = x2,k+1, we have

M âŠ¤(Mx2,k âˆ’b) + Ï(x2,k âˆ’x1,k) âˆ’ykâˆ’1, x2,k+1 âˆ’x2,k
â‰¥0.
(56)
Adding (55) and (56), we have

yk âˆ’ykâˆ’1, x2,k+1 âˆ’x2,k
âˆ’Ïâˆ¥x2,k+1 âˆ’x2,kâˆ¥2
2 + Ï

x1,k+1 âˆ’x1,k, x2,k+1 âˆ’x2,k
â‰¥âˆ¥M(x2,k+1 âˆ’x2,k)âˆ¥2
2 â‰¥0.
(57)
From (49), we have yk âˆ’ykâˆ’1 = Î±(x1,k âˆ’x2,k). Using it in (57) and rearranging terms, we obtain
Ï

x1,k+1 âˆ’x1,k, x2,k+1 âˆ’x2,k
â‰¥Ïâˆ¥x2,k+1 âˆ’x2,kâˆ¥2
2 âˆ’Î±

x1,k âˆ’x2,k, x2,k+1 âˆ’x2,k
.
Adding and subtracting x1,âˆ—and x2,âˆ—into each argument in (B) as needed, we have
Ï

Ëœx1,k+1 âˆ’Ëœx1,k, Ëœx2,k+1 âˆ’Ëœx2,k
â‰¥Ïâˆ¥Ëœx2,k+1 âˆ’Ëœx2,kâˆ¥2
2 âˆ’Î±

Ëœx1,k âˆ’Ëœx2,k, Ëœx2,k+1 âˆ’Ëœx2,k
.
(58)
The term

Ëœx2,k âˆ’Ëœx2,k+1, Ëœx1,k+1
can be transformed as following:

Ëœx2,k âˆ’Ëœx2,k+1, Ëœx1,k+1
=

Ëœx2,k âˆ’Ëœx2,k+1, Ëœx1,k+1 âˆ’Ëœx1,k + Ëœx1,k âˆ’Ëœx2,k + Ëœx2,k
=

Ëœx2,k âˆ’Ëœx2,k+1, Ëœx1,k+1 âˆ’Ëœx1,k
+

Ëœx2,k âˆ’Ëœx2,k+1, Ëœx1,k âˆ’Ëœx2,k
+

Ëœx2,k âˆ’Ëœx2,k+1, Ëœx2,k
=

Ëœx2,k âˆ’Ëœx2,k+1, Ëœx1,k+1 âˆ’Ëœx1,k
+

Ëœx2,k âˆ’Ëœx2,k+1, Ëœx1,k âˆ’Ëœx2,k
+ 1
2(âˆ¥Ëœx2,kâˆ¥2
2 âˆ’âˆ¥Ëœx2,k+1âˆ¥2
2 + âˆ¥Ëœx2,k âˆ’Ëœx2,k+1âˆ¥2
2)
â‰¤1
2(âˆ¥Ëœx2,kâˆ¥2
2 âˆ’âˆ¥Ëœx2,k+1âˆ¥2
2 âˆ’âˆ¥Ëœx2,k âˆ’Ëœx2,k+1âˆ¥2
2) + (1 âˆ’Î±
Ï )

Ëœx2,k âˆ’Ëœx2,k+1, Ëœx1,k âˆ’Ëœx2,k
,
(59)
where the last inequality follows from (58). Combining (53) and (59) and rearranging the terms,
we obtain
âˆ¥Ëœyk+1âˆ¥2
2 + Î±Ïâˆ¥Ëœx2,k+1âˆ¥2
2 + Î±(Ï âˆ’Î±)âˆ¥Ëœx1,k+1 âˆ’Ëœx2,k+1âˆ¥2
2 âˆ’(âˆ¥Ëœykâˆ¥2
2 + Î±Ïâˆ¥Ëœx2,kâˆ¥2
2)
â‰¤âˆ’Î±Ïâˆ¥Ëœx1,k+1 âˆ’Ëœx2,k+1âˆ¥2
2 âˆ’2Î±âˆ¥M Ëœx2,k+1âˆ¥2
2 âˆ’Î±Ïâˆ¥Ëœx2,k âˆ’Ëœx2,k+1âˆ¥2
2 + 2Î±(Ï âˆ’Î±)

Ëœx2,k âˆ’Ëœx2,k+1, Ëœx1,k âˆ’Ëœx2,k
(60)
28

By upper bounding the last term in (60) by the identity 2 âŸ¨a, bâŸ©â‰¤âˆ¥aâˆ¥2
2 + âˆ¥bâˆ¥2
2, we get
âˆ¥Ëœyk+1âˆ¥2
2 + Î±Ïâˆ¥Ëœx2,k+1âˆ¥2
2 + Î±(Ï âˆ’Î±)âˆ¥Ëœx1,k+1 âˆ’Ëœx2,k+1âˆ¥2
2 âˆ’(âˆ¥Ëœykâˆ¥2
2 + Î±Ïâˆ¥Ëœx2,kâˆ¥2
2 + Î±(Ï âˆ’Î±)âˆ¥Ëœx1,k âˆ’Ëœx2,kâˆ¥2
2)
â‰¤âˆ’Î±Ïâˆ¥Ëœx1,k+1 âˆ’Ëœx2,k+1âˆ¥2
2 âˆ’2Î±âˆ¥M Ëœx2,k+1âˆ¥2
2 âˆ’Î±2âˆ¥Ëœx2,k âˆ’Ëœx2,k+1âˆ¥2
2 â‰¤0.
(61)
We have shown that the sequence {âˆ¥Ëœykâˆ¥2
2+Î±Ïâˆ¥Ëœx2,kâˆ¥2
2+Î±(Ïâˆ’Î±)âˆ¥Ëœx1,kâˆ’Ëœx2,kâˆ¥2
2}âˆ
k=1 is non-increasing.
Once the initial point and saddle point are ï¬xed, which are not related to Î±, then {âˆ¥Ëœykâˆ¥2
2 +
Î±Ïâˆ¥Ëœx2,kâˆ¥2
2 + Î±(Ï âˆ’Î±)âˆ¥Ëœx1,k âˆ’Ëœx2,kâˆ¥2
2}âˆ
k=1 is bounded by âˆ¥Ëœy0âˆ¥2
2 + Ï2âˆ¥Ëœx2,0âˆ¥2
2 + Ï2
4 âˆ¥Ëœx1,0 âˆ’Ëœx2,0âˆ¥2
2. We
concluded that the sequence {x1,k}, {x2,k} and {yk} generated by (15) is uniformly bounded for
any 0 < Î± < Ï.
C
Proof of Lemma 3.3
The proof extends the analysis of [45] and [53]. Since both works discuss primal methods, there
are mainly two new ingredients in our proof: 1) dealing with the dual variable y, and 2) splitting
x into x1 and x2, where neither step is trivial.
Given y, note that X(y) can be written as (X1(y), X2(y)). For a ï¬xed y, and for any sequence
{(x1,k, x2,k; y) : x2,k Ì¸âˆˆX2(y)}kâ‰¥0, we deï¬ne
r1,k â‰œËœâˆ‡x1LÏ(x1,k, x2,k; y),
(62)
r2,k â‰œËœâˆ‡x2LÏ(x1,k, x2,k; y) = M T (Mx2,k âˆ’b) âˆ’y + Ï(x2,k âˆ’x1,k),
(63)
Î´k â‰œâˆ¥x2,k âˆ’Â¯x2,kâˆ¥2,
where Â¯x2,k â‰œargmin
x2âˆˆX2(y)
âˆ¥x2,k âˆ’x2âˆ¥2,
(64)
Â¯x1,k â‰œargmin
x1
LÏ(x1, Â¯x2,k; y),
(65)
uk â‰œx2,k âˆ’Â¯x2,k
Î´k
.
(66)
Note that
Ëœâˆ‡x1LÏ(x1, x2; y) = x1 âˆ’proxÎ» P
gâˆˆG wgâˆ¥Ëœdj(g)âˆ¥2(x1 âˆ’y âˆ’Ï(x1 âˆ’x2))
(67)
= x1 âˆ’argmin
Ëœd
Î»
X
gâˆˆG
wgâˆ¥Ëœdj(g)âˆ¥2 + 1
2âˆ¥Ëœd âˆ’(x1 âˆ’y + Ï(x1 âˆ’x2))âˆ¥2
2
(68)
= argmin
d
Î»
X
gâˆˆG
wgâˆ¥dj(g) âˆ’x1
j(g)âˆ¥2 + 1
2âˆ¥d âˆ’y âˆ’Ï(x1 âˆ’x2)âˆ¥2
2,
(69)
where the second equality follows from the deï¬nition of the proximal operator and the third equality
uses the transformation d â‰œx1 âˆ’Ëœd. Furthermore, for any group g âˆˆG, we have

Ëœâˆ‡x1LÏ(x1, x2; y)

j(g) = argmin
dj(g)
Î»wgâˆ¥dj(g) âˆ’x1
j(g)âˆ¥2 + 1
2âˆ¥dj(g) âˆ’yj(g) âˆ’Ï(x1
j(g) âˆ’x2
j(g))âˆ¥2
2 (70)
=
(
x1
j(g),
if âˆ¥x1
j(g) âˆ’yj(g) âˆ’Ï(x1
j(g) âˆ’x2
j(g))âˆ¥2 â‰¤Î»wg,
Î³gx1
j(g) + (1 âˆ’Î³g)(yj(g) + Ï(x1
j(g) âˆ’x2
j(g))),
otherwise.
(71)
29

where Î³g = Î»wg/âˆ¥x1
j(g) âˆ’yj(g) âˆ’Ï(x1
j(g) âˆ’x2
j(g))âˆ¥2.
Note that the two cases from the soft-
thresholding operator in (71) yield x1
j(g) at the boundary âˆ¥x1
j(g) âˆ’yj(g) âˆ’Ï(x1
j(g) âˆ’x2
j(g))âˆ¥2 = Î»wg,
i.e., Ëœâˆ‡x1LÏ(x1, x2; y)j(g) is continuous in (x1, x2, y).
To prove this lemma, we will ï¬rst prove that it suï¬ƒces to show that there exists 0 < Ï„ â€² < +âˆ
and Î´ > 0 such that
dist(x2, X2(y)) â‰¤Ï„ â€²âˆ¥Ëœâˆ‡xLÏ(x1, x2; y)âˆ¥2,
(72)
for all (x1, x2; y) such that âˆ¥Ëœâˆ‡xLÏ(x1, x2; y)âˆ¥2 â‰¤Î´. Second, we will show (72).
Assume (72) holds.
Given (x1, x2; y), pick (x1,âˆ—, x2,âˆ—) âˆˆX(y), such that dist(x2, x2,âˆ—) =
dist(x2, X2(y)), and x1,âˆ—such that it satisï¬es the optimality condition (74). Recall that
Ëœâˆ‡x2LÏ(x1, x2; y) = M T (Mx2 âˆ’b) âˆ’y + Ï(x2 âˆ’x1).
(73)
Hence, from the optimality condition, we have
Ëœâˆ‡x2LÏ(x1,âˆ—, x2,âˆ—; y) = M T (Mx2,âˆ—âˆ’b) âˆ’y + Ï(x2,âˆ—âˆ’x1,âˆ—) = 0
(74)
Subtracting (74) from (73) and rearranging the terms, we obtain
x1 âˆ’x1,âˆ—= (1
ÏM T M + I)(x2 âˆ’x2,âˆ—) âˆ’1
Ï
Ëœâˆ‡x2LÏ(x1, x2; y).
(75)
Thus,
dist(x, X(y))2 â‰¤âˆ¥x1 âˆ’x1,âˆ—âˆ¥2
2 + âˆ¥x2 âˆ’x2,âˆ—âˆ¥2
2
(76)
â‰¤âˆ¥(1
ÏM T M + I)(x2 âˆ’x2,âˆ—)âˆ¥2
2 + âˆ¥1
Ï
Ëœâˆ‡x2LÏ(x1, x2; y)âˆ¥2
2 + âˆ¥x2 âˆ’x2,âˆ—âˆ¥2
2.
(77)
Upper bounding âˆ¥x2 âˆ’x2,âˆ—âˆ¥2
2 in (77) with (72), we have (31).
Next, we will show (72) by contradiction.
Suppose (72) does not hold, then there exists a
sequence {(x1,k, x2,k; y) : x2,k Ì¸âˆˆX2(y)}kâ‰¥0 satisfying
âˆ¥Ëœâˆ‡xLÏ(x1,k, x2,k, y)âˆ¥2/Î´k â†’0,
and
âˆ¥Ëœâˆ‡xLÏ(x1,k, x2,k, y)âˆ¥2 â†’0.
(78)
Note that
âˆ¥r1,kâˆ¥+ âˆ¥r2,kâˆ¥
âˆš
2
â‰¤âˆ¥Ëœâˆ‡xLÏ(x1,k, x2,k; y)âˆ¥â‰¤âˆ¥r1,kâˆ¥+ âˆ¥r2,kâˆ¥
(79)
where r1,k and r2,k are deï¬ned in (62) and (63), respectively. Hence, using the left inequality in
(79), (78) implies
{r1,k} â†’0,
{r2,k} â†’0,
{âˆ¥r1,kâˆ¥+ âˆ¥r2,kâˆ¥
Î´k
} â†’0.
(80)
We will show that (80) does not hold.
Since (x1,k, x2,k) is in a compact set, by passing to a
subsequence if necessary, we can assume that {(x1,k, x2,k) â†’(Â¯x1, Â¯x2)}. Since {r1,k} â†’0, and
{r2,k} â†’0, then by the right inequality in (79), Ëœâˆ‡xLÏ(x1,k, x2,k; y) â†’0.
Furthermore, since
Ëœâˆ‡xLÏ(x1, x2; y) is continuous, this implies Ëœâˆ‡xLÏ(Â¯x1, Â¯x2; y) = 0. It further implies that (Â¯x1, Â¯x2) âˆˆ
X(y). Hence Î´k â‰¤âˆ¥x2,k âˆ’Â¯x2âˆ¥â†’0, as k â†’âˆ, so that {Â¯x2,k} â†’Â¯x2. And based on (75), we have
{Â¯x1,k} â†’Â¯x1.
(81)
30

Next, we claim there exists Îº > 0 such that,
âˆ¥x2,k âˆ’Â¯x2,kâˆ¥â‰¤Îºâˆ¥Mx2,k âˆ’M Â¯x2,kâˆ¥,
âˆ€k
(82)
Again, we argue (82) by contraction. Suppose (82) does not hold, then by passing to a subsequence
if necessary, we can assume
{âˆ¥Mx2,k âˆ’M Â¯x2,kâˆ¥
âˆ¥x2,k âˆ’Â¯x2,kâˆ¥
} â†’0.
(83)
This implies that {Muk} â†’0, where uk is deï¬ned in (66). Note that âˆ¥ukâˆ¥= 1, we can assume
uk â†’Â¯u Ì¸= 0 (by further passing to a subsequence if necessary); hence, we have M Â¯u = 0 by
continuity. Combining (73) and (80), we have
M T (Mx2,k âˆ’b) âˆ’y + Ï(x2,k âˆ’x1,k) = o(Î´k).
Furthermore,
M T (M Â¯x2,k âˆ’b) âˆ’y + Ï(Â¯x2,k âˆ’Â¯x1,k) = 0.
Subtracting the above two equalities and using (83), we get
x2,k âˆ’Â¯x2,k = x1,k âˆ’Â¯x1,k + o(Î´k).
(84)
Thus,
Â¯u = lim
kâ†’âˆ
x2,k âˆ’Â¯x2,k
Î´k
= lim
kâ†’âˆ
x1,k âˆ’Â¯x1,k
Î´k
.
Since uk â†’Â¯u Ì¸= 0, we have

uk, Â¯u

> 0 for k suï¬ƒciently large. Select k such that

uk, Â¯u

> 0 and
let
Ë†x2,k â‰œÂ¯x2,k + ÏµÂ¯u
(85)
for some Ïµ > 0. We can show that for Ïµ > 0 suï¬ƒciently small
Ë†x2,k âˆˆX2(y),
(86)
whose proof is relegated to Appendix D. Now, assume Ë†x2,k âˆˆX2(yk) for Ïµ > 0 suï¬ƒciently small.
This leads to the following contradiction:
âˆ¥x2,k âˆ’Ë†x2,kâˆ¥2 = âˆ¥x2,k âˆ’Â¯x2,k âˆ’ÏµÂ¯uâˆ¥2 = Î´k + Ïµ2 âˆ’2Ïµ

uk, Â¯u

< Î´k
(87)
for Ïµ suï¬ƒciently small, which contradicts the deï¬nition of Â¯x2,k in (64). So (82) holds.
By (69), we have
0 âˆˆÎ»âˆ‚
X
gâˆˆG
wgâˆ¥r1,k
j(g) âˆ’x1,k
j(g)âˆ¥2 + (r1,k âˆ’y âˆ’Ï(x1,k âˆ’x2,k)),
(88)
which is the optimal condition to
r1,k âˆˆargmin
d
Î»
X
gâˆˆG
wgâˆ¥dj(g) âˆ’x1,k
j(g)âˆ¥2 +

r1,k âˆ’y âˆ’Ï(x1,k âˆ’x2,k), d

.
(89)
31

From (89), we have
Î»
X
gâˆˆG
wgâˆ¥r1,k
j(g) âˆ’x1,k
j(g)âˆ¥2 +

r1,k âˆ’y âˆ’Ï(x1,k âˆ’x2,k), r1,k
â‰¤Î»
X
gâˆˆG
wgâˆ¥Â¯x1,kâˆ¥2 +

r1,k âˆ’y âˆ’Ï(x1,k âˆ’x2,k), x1,k âˆ’Â¯x1,k
.
(90)
From Ëœâˆ‡x1LÏ(Â¯x1,k, Â¯x2,k; y) = 0, we have
0 = argmin
d
Î»
X
gâˆˆG
wgâˆ¥dj(g) âˆ’Â¯x1
j(g)âˆ¥2 + 1
2âˆ¥d âˆ’y âˆ’Ï(Â¯x1 âˆ’Â¯x2)âˆ¥2
2.
(91)
Similar to (88), we have
0 âˆˆÎ»âˆ‚
X
gâˆˆG
wgâˆ¥Â¯x1,k
j(g)âˆ¥2 + (âˆ’y âˆ’Ï(Â¯x1,k âˆ’Â¯x2,k)),
(92)
which is the optimal condition to
0 âˆˆargmin
d
Î»
X
gâˆˆG
wgâˆ¥dj(g) âˆ’Â¯x1,k
j(g)âˆ¥2 +

âˆ’y âˆ’Ï(Â¯x1,k âˆ’Â¯x2,k), d

.
(93)
From (93), we have
Î»
X
gâˆˆG
wgâˆ¥Â¯x1,k
j(g)âˆ¥2
â‰¤Î»
X
gâˆˆG
wgâˆ¥r1,k
j(g) âˆ’x1,k
j(g)âˆ¥2 +

âˆ’y âˆ’Ï(Â¯x1,k âˆ’Â¯x2,k), Â¯x1,k + r1,k âˆ’x1,k
.
(94)
Adding (90) and (94), and using (63), we obtain

r1,k + r2,k, r1,k
+

M T M(x2,k âˆ’Â¯x2,k), x1,k âˆ’Â¯x1,k
â‰¤

r1,k + r2,k, x1,k âˆ’Â¯x1,k
+

M T M(x2,k âˆ’Â¯x2,k), r1,k
.
(95)
From (63), we have
x1,k âˆ’Â¯x1,k = (1
ÏM T M + I)(x2,k âˆ’Â¯x2,k) âˆ’1
Ïr2,k.
(96)
Deï¬ning A â‰œ1
ÏM T M + I and using (96) in (95) and rearranging the terms, we obtain

r1,k + r2,k, r1,k + 1
Ïr2,k

+

M T M(x2,k âˆ’Â¯x2,k), A(x2,k âˆ’Â¯x2,k)

â‰¤

r1,k + r2,k, A(x2,k âˆ’Â¯x2,k)

+

M T M(x2,k âˆ’Â¯x2,k), r1,k + 1
Ïr2,k

.
(97)
Let us consider term by term. We have

r1,k + r2,k, r1,k + 1
Ïr2,k

â‰¥âˆ¥r1,kâˆ¥2
2 + 1
Ïâˆ¥r2,kâˆ¥2
2 âˆ’(1
Ï + 1)âˆ¥r1,kâˆ¥2âˆ¥r2,kâˆ¥2.
(98)
32

Next, using (82), we have

M T M(x2,k âˆ’Â¯x2,k), A(x2,k âˆ’Â¯x2,k)

= 1
Ïâˆ¥M T M(x2,k âˆ’Â¯x2,k)âˆ¥2
2 + âˆ¥M(x2,k âˆ’Â¯x2,k)âˆ¥2
2
(99)
â‰¥Îº2âˆ¥x2,k âˆ’Â¯x2,kâˆ¥2
2.
(100)
Denote the largest eigenvalue of matrix A by L1, we have

r1,k + r2,k, A(x2,k âˆ’Â¯x2,k)

â‰¤L1âˆ¥r1,k + r2,kâˆ¥2âˆ¥x2,k âˆ’Â¯x2,kâˆ¥2.
(101)
Denote L2 â‰œmaxâˆ¥dâˆ¥=1 âˆ¥Mdâˆ¥,

M T M(x2,k âˆ’Â¯x2,k), r1,k + 1
Ïr2,k

â‰¤L2
2âˆ¥r1,k + 1
Ïr2,kâˆ¥2âˆ¥x2,k âˆ’Â¯x2,kâˆ¥2.
(102)
Combining the four inequalities above, we have
Îº2âˆ¥x2,k âˆ’Â¯x2,kâˆ¥2
2 + âˆ¥r1,kâˆ¥2
2 + 1
Ïâˆ¥r2,kâˆ¥2
2 âˆ’(1
Ï + 1)âˆ¥r1,kâˆ¥2âˆ¥r2,kâˆ¥2
â‰¤(L1âˆ¥r1,k + r2,kâˆ¥2 + L2
2âˆ¥r1,k + 1
Ïr2,kâˆ¥2)âˆ¥x2,k âˆ’Â¯x2,kâˆ¥2.
(103)
Denote b â‰œL1âˆ¥r1,k + r2,kâˆ¥2 + L2
2âˆ¥r1,k + 1
Ïr2,kâˆ¥2, c â‰œâˆ¥r1,kâˆ¥2
2 + 1
Ïâˆ¥r2,kâˆ¥2
2 âˆ’( 1
Ï + 1)âˆ¥r1,kâˆ¥2âˆ¥r2,kâˆ¥2.
Using quadratic formula, (103) implies
âˆ¥x2,k âˆ’Â¯x2,kâˆ¥2 â‰¤b +
âˆš
b2 âˆ’4Îº2c
2Îº2
.
(104)
Note that the right-hand-side of (104) is O(âˆ¥r1,kâˆ¥+ âˆ¥r2,kâˆ¥), so (104) contradicts (80), which says
âˆ¥r1,kâˆ¥+ âˆ¥r2,kâˆ¥= o(âˆ¥x2,k âˆ’Â¯x2,kâˆ¥).
So far, we have shown that for a ï¬xed y, there exist Ï„ and Î´ satisfying (31) and the inequality
below it, accordingly. From (70) and (63), we know Ëœâˆ‡xLÏ(x1, x2; y) is continuous in y. Since X(y)
is characterized by Ëœâˆ‡xLÏ(x1, x2; y) = 0, so dist(x, X(y)) is also continuous in y, which implies that
we can deï¬ne a continuous mapping from y to Ï„ and Î´. Note that from the above proof, we know
that for any y, Ï„ is ï¬nite, i.e., Ï„ < âˆ, and Î´ > 0. Hence, since y is in a compact set, we can ï¬nd
Â¯Ï„ â‰œsup{Ï„} < âˆand Â¯Î´ â‰œinf{Î´} > 0. This ï¬nishes the proof of the lemma.
D
Proof of (86) in Lemma 3.3
The following proof is inspired by [45] and [53]. Denote tk â‰œy + Ï(x1,k âˆ’x2,k). Note that if we
write (10) as a function of x2 and z â‰œx1 âˆ’x2, then the last term is strongly convex in z. This
implies that the value of Â¯t â‰œy + Ï(x1 âˆ’x2) is unique for âˆ€(x1, x2) âˆˆX(y). Recall the deï¬nition in
(65) and (85), we will show (86) is equivalent to
0 âˆˆÎ»âˆ‚wgâˆ¥(Â¯x1,k + ÏµÂ¯u)j(g)âˆ¥+ Â¯tj(g),
âˆ€g.
(105)
33

From the optimality condition of (10), we know Ë†x2,k âˆˆX2(y) is equivalent to
(
0 âˆˆÎ»âˆ‚P
gâˆˆG wgâˆ¥x1
j(g)âˆ¥2 + (y + Ï(x1 âˆ’Ë†x2))j(g), âˆ€g
0 = M T (M Ë†x2,k âˆ’b) âˆ’(y + Ï(x1 âˆ’Ë†x2)),
(106)
is satisï¬ed for some x1. From (85), we have
M Ë†x2 = M Â¯x2
(107)
since M Â¯u = 0. So the second equality of (106) holds if and only if x1 = Â¯x1 + ÏµÂ¯u.2 Since 0 =
M T (M Â¯x2,k âˆ’b) âˆ’(y + Ï(Â¯x1 âˆ’Â¯x2)) holds by deï¬nitions (65) and (64), (106) is equivalent to
0 âˆˆÎ»âˆ‚
X
gâˆˆG
wgâˆ¥Â¯x1
j(g) + ÏµÂ¯uâˆ¥2 + (y + Ï(Â¯x1 âˆ’Â¯x2))j(g) âˆ€g.
(108)
Using Â¯t to replace (y + Ï(Â¯x1 âˆ’Â¯x2)), we have (105).
Based on (80) and (83), we have
tk âˆ’Â¯t = M T M(x2,k âˆ’Â¯x2,k) âˆ’r2,k = o(Î´k).
(109)
By further passing to a subsequence if necessary, we can assume that, for each g âˆˆG, either
1. âˆ¥x1,k
j(g) âˆ’tk
j(g)âˆ¥2 â‰¤Î»wg,
âˆ€k, or,
2. âˆ¥x1,k
j(g) âˆ’tk
j(g)âˆ¥2 > Î»wg, and Â¯x1,k
j(g) Ì¸= 0,
âˆ€k, or,
3. âˆ¥x1,k
j(g) âˆ’tk
j(g)âˆ¥2 > Î»wg, and Â¯x1,k
j(g) = 0,
âˆ€k,
is true. We will show that in any of the three above cases, Â¯uj(g) is a certain multiple of Â¯tj(g) and
then (105) is satisï¬ed.
1. In this case, from (71), we know
Â¯uj(g) = lim
kâ†’âˆ
x1,k
j(g) âˆ’Â¯x1,k
j(g)
Î´k
= lim
kâ†’âˆ
r1,k
j(g) âˆ’Â¯x1,k
j(g)
Î´k
= lim
kâ†’âˆ
âˆ’Â¯x1,k
j(g)
Î´k
(110)
where the last equation comes from (80). Suppose that Â¯uj(g) Ì¸= 0. (Otherwise, Ë†x2,k = Â¯x2,k.)
Then Â¯x1,k
j(g) Ì¸= 0 for all k suï¬ƒciently large. From the optimality condition for (10), we have
0 = Î»wg
Â¯x1,k
j(g)
âˆ¥Â¯x1,k
j(g)âˆ¥2
+ Â¯tj(g),
(111)
for k suï¬ƒciently large. By continuity, we have Â¯uj(g) is a positive multiple of Â¯tj(g). Fur-
thermore, Â¯x1,k
j(g) is a negative multiple of Â¯tj(g). Therefore, for Ïµ suï¬ƒciently small, (105) is
satisï¬ed.
2In fact, from our discussion on the uniqueness of y + Ï(x1 âˆ’x2) for âˆ€(x1, x2) âˆˆX(y), we can also
conclude that x1 must be Â¯x1 + ÏµÂ¯u.
34

2. In this case, since we assumed Â¯x1,k
j(g) Ì¸= 0 âˆ€k, (111) is always satisï¬ed. It implies
Â¯tj(g) = Î»wg
Â¯tj(g) âˆ’Â¯x1,k
j(g)
âˆ¥Â¯tj(g) âˆ’Â¯x1,k
j(g)âˆ¥2
.
(112)
From (71), we have
r1,k
j(g) =
Î»wg
âˆ¥x1,k
j (g) âˆ’tk
j(g)âˆ¥2
x1,k
j(g) + (
âˆ¥x1,k
j (g) âˆ’tk
j(g))âˆ¥2 âˆ’Î»wg
âˆ¥x1,k
j (g) âˆ’tk
j(g)âˆ¥2
)tk
j(g)
=
Î»wg
âˆ¥x1,k
j (g) âˆ’tk
j(g)âˆ¥2
(Â¯x1,k
j(g) + Î´kuk
j(g) + o(Î´k)) + (
âˆ¥x1,k
j (g) âˆ’tk
j(g))âˆ¥2 âˆ’Î»wg
âˆ¥x1,k
j(g) âˆ’tk
j(g)âˆ¥2
)(Â¯tj(g) + o(Î´k))
=
Î»wgÎ´k
âˆ¥x1,k
j(g) âˆ’tk
j(g)âˆ¥2
uk
j(g) +
Î»wg
âˆ¥x1,k
j(g) âˆ’tk
j(g)âˆ¥2
(Â¯x1,k
j(g) âˆ’Â¯tj(g)) + Â¯tj(g) + o(Î´k)
=
Î»wgÎ´k
âˆ¥x1,k
j(g) âˆ’tk
j(g)âˆ¥2
uk
j(g) + (
Î»wg
âˆ¥Â¯tj(g) âˆ’Â¯x1,k
j(g)âˆ¥2
âˆ’
Î»wg
âˆ¥tk
j(g) âˆ’x1,k
j(g)âˆ¥2
)(Â¯tj(g) âˆ’Â¯x1,k
j(g)) + o(Î´k)
=
Î»wgÎ´k
âˆ¥Â¯tj(g) âˆ’Â¯x1,k
j(g) âˆ’Î´kuk
j(g) + o(Î´k)âˆ¥2
uk
j(g)
+ (
Î»wg
âˆ¥Â¯tj(g) âˆ’Â¯x1,k
j(g)âˆ¥2
âˆ’
Î»wg
âˆ¥Â¯tj(g) âˆ’Â¯x1,k
j(g) âˆ’Î´kuk
j(g) + o(Î´k)âˆ¥2
)(Â¯tj(g) âˆ’Â¯x1,k
j(g)) + o(Î´k)
where the second equality comes from (84) and (109). The forth equality follows from (112).
Finally, we use (84) and (109) in the last equality. From the Taylor expansion of âˆ¥Â· âˆ¥âˆ’1
2
and
given that âˆ‡xâˆ¥xâˆ¥âˆ’1
2
= âˆ’x/âˆ¥xâˆ¥3
2, we have
1
âˆ¥Â¯tj(g) âˆ’Â¯x1,k
j(g) âˆ’Î´kuk
j(g) + o(Î´k)âˆ¥2
=
1
âˆ¥Â¯tj(g) âˆ’Â¯x1,k
j(g)âˆ¥2
âˆ’
D
Â¯tj(g) âˆ’Â¯x1,k
j(g), âˆ’Î´kuk
j(g) + o(Î´k)
E
âˆ¥Â¯tj(g) âˆ’Â¯x1,k
j(g)âˆ¥3
2
+ o(âˆ¥âˆ’Î´kuk
j(g) + o(Î´k)âˆ¥2)
=
1
âˆ¥Â¯tj(g) âˆ’Â¯x1,k
j(g)âˆ¥2
+
D
Â¯tj(g) âˆ’Â¯x1,k
j(g), Î´kuk
j(g)
E
âˆ¥Â¯tj(g) âˆ’Â¯x1,k
j(g)âˆ¥3
2
+ o(Î´k).
Using this back in the last equation for r1,k
j(g) and rearranging the terms, we have
r1,k
j(g) =
Î»wgÎ´k
âˆ¥Â¯tj(g) âˆ’Â¯x1,k
j(g)âˆ¥2
uk
j(g) âˆ’
Î»wg
D
Â¯tj(g) âˆ’Â¯x1,k
j(g), Î´kuk
j(g)
E
âˆ¥Â¯tj(g) âˆ’Â¯x1,k
j(g)âˆ¥3
2
(Â¯tj(g) âˆ’Â¯x1,k
j(g)) + o(Î´k)
=
Î»wgÎ´k
âˆ¥Â¯tj(g) âˆ’Â¯x1,k
j(g)âˆ¥2
uk
j(g) âˆ’
D
Â¯tj(g), Î´kuk
j(g)
E
âˆ¥Â¯tj(g) âˆ’Â¯x1,k
j(g)âˆ¥2
(
Â¯tj(g)
Î»wg
) + o(Î´k),
35

where the second equality uses (112).
Multiplying both sides by
âˆ¥Â¯tj(g)âˆ’Â¯x1,k
j(g)âˆ¥2
Î»wgÎ´k
and using
(80),(81) and âˆ¥Â¯tj(g)âˆ¥2 = Î»wg (from (112)) yields in the limit
0 = Â¯uj(g) âˆ’

Â¯tj(g), Â¯uj(g)

âˆ¥Â¯tj(g)âˆ¥2
2
Â¯tj(g).
(113)
Thus Â¯uj(g) is a nonzero multiple of Â¯tj(g). In this case, since we assume Â¯x1,k
j(g) Ì¸= 0, from (111),
we know Â¯x1,k
j(g) is a negative multiple of Â¯tj(g). So (105) is satisï¬ed for Ïµ suï¬ƒciently small.
3. In this case, we assume Â¯x1,k
j(g) = 0, âˆ€k, from (81), we have Â¯x1
j(g) = 0. We also assume that
âˆ¥x1,k
j(g) âˆ’tk
j(g)âˆ¥2 > Î»wg for all k, this implies âˆ¥Â¯tj(g)âˆ¥2 â‰¥Î»wg. From the optimality condition
for (10) for x1 we have
0 = Â¯tj(g) + Î»wgâˆ‚âˆ¥0âˆ¥2,
which implies âˆ¥Â¯tj(g)âˆ¥2 â‰¤Î»wg. Thus âˆ¥Â¯tj(g)âˆ¥2 = Î»wg. Then (71) implies
r1,k
j(g) =
Î»wg
âˆ¥x1,k
j (g) âˆ’tk
j(g)âˆ¥2
x1,k
j(g) + (
Î»wg
âˆ¥Â¯tj(g)âˆ¥2
âˆ’
Î»wg
âˆ¥x1,k
j (g) âˆ’tk
j(g)âˆ¥2
)tk
j(g)
=
Î»wg
âˆ¥x1,k
j (g) âˆ’tk
j(g)âˆ¥2
x1,k
j(g) +
Î»wg
D
Â¯tj(g), tk
j(g) âˆ’x1,k
j(g) âˆ’Â¯tj(g)
E
âˆ¥Â¯tj(g)âˆ¥3
2
tj(g)
+ o(âˆ¥tk
j(g) âˆ’x1,k
j (g) âˆ’Â¯tj(g)âˆ¥2)
=
Î»wg
âˆ¥x1,k
j (g) âˆ’tk
j(g)âˆ¥2
x1,k
j(g) âˆ’
Î»wg
D
Â¯tj(g), x1,k
j(g)
E
âˆ¥Â¯tj(g)âˆ¥3
2
tj(g) + o(Î´k)
where the second equality uses Taylor expansion similar to the case 2. The third equality
follows from (109) and {x1,k
j(g)} â†’0. Dividing both sides by Î´k yield in the limit (113), where
it uses
{
x1,k
j(g)
Î´k } = {uk
j(g) + o(Î´k)
Î´k
} â†’Â¯uj(g).
Since we assume âˆ¥x1,k
j(g) âˆ’tk
j(g)âˆ¥2 > Î»wg for all k, we have the following equality from (70)
0 = Î»wg
r1,k
j(g) âˆ’x1,k
j(g)
âˆ¥r1,k
j(g) âˆ’x1,k
j(g)âˆ¥2
+ r1,k
j(g) âˆ’tk
j(g).
(114)
Suppose Â¯uj(g) Ì¸= 0. Then uk
j(g) =
x1,k
j(g)
Î´k
+ o(Î´k)
Î´k
Ì¸= 0, for k suï¬ƒciently large. It implies that
x1,k
j(g) Ì¸= 0, for k suï¬ƒciently large. Hence,
36


Â¯tj(g), Â¯uj(g)

=
lim
kâ†’+âˆ
D
tk
j(g), uk
j(g)
E
=
lim
kâ†’+âˆ
*
r1,k
j(g),
x1,k
j(g)
Î´k
+
+
*
Î»wg
r1,k
j(g) âˆ’x1,k
j(g)
âˆ¥r1,k
j(g) âˆ’x1,k
j(g)âˆ¥2
,
x1,k
j(g)
Î´k
+
=
lim
kâ†’+âˆ
Î»wg
âˆ¥r1,k
j(g) âˆ’x1,k
j(g)âˆ¥2
(
D
r1,k
j(g), x1,k
j(g)
E
Î´k
âˆ’
âˆ¥x1,k
j(g)âˆ¥2
2
Î´k
)
=
lim
kâ†’+âˆ
Î»wg
âˆ¥
r1,k
j(g)
âˆ¥x1,k
j(g)âˆ¥2 âˆ’
x1,k
j(g)
âˆ¥x1,k
j(g)âˆ¥2 âˆ¥2
(
*
r1,k
j(g)
Î´k ,
x1,k
j(g)
âˆ¥x1,k
j(g)âˆ¥2
+
âˆ’âˆ¥uk
j(g)âˆ¥2)
= âˆ’Î»wgâˆ¥uk
j(g)âˆ¥2 < 0,
where the second equality is based on (114) and limkâ†’+âˆuk
j(g) = limkâ†’+âˆ
x1,k
j(g)
Î´k , the third
equality is based on
r1,k
j(g)
Î´k
â†’0 (by (80)), the forth equality is based on x1,k
j(g) Ì¸= 0 and
limkâ†’+âˆuk
j(g) = limkâ†’+âˆ
x1,k
j(g)
Î´k , and, the ï¬fth equality is based on r1,k
j(g) â†’0 and
r1,k
j(g)
Î´k
â†’0
(by (80)). Finally, combined with (113), we obtain Â¯uj(g) is a negative multiplier of Â¯tj(g).
Since Â¯x1
j(g) = 0 in this case, (105) is satisï¬ed.
E
Proof of Theorem 3.1
From Lemmas 2.4 and 2.5 in [20], we have the following two identities, respectively:
L(xk; yk) âˆ’L(xk+1; yk) â‰¥Ïâˆ¥xk âˆ’xk+1âˆ¥2,
(115)
âˆ¥Ëœâˆ‡L(xk; yk)âˆ¥â‰¤Ïƒâˆ¥xk âˆ’xk+1âˆ¥,
(116)
where Ïƒ =
âˆš
2(max{1 + âˆ¥M T âˆ¥âˆ¥Mâˆ¥, Ï} + 1).
Lemma 3.2 in our paper establishes the uniform boundedness of iterates {(xk, yk)}, based on
which the compactness condition of Lemma 3.3 is satisï¬ed. Lemma 3.3 quantiï¬es the primal error
bound with the proximal gradient of the Lagrangian function as
âˆ¥xk âˆ’Â¯xkâˆ¥â‰¤Ï„pâˆ¥Ëœâˆ‡L(xk; yk)âˆ¥â‰¤Ï„pÏƒâˆ¥xk âˆ’xk+1âˆ¥,
(117)
where Â¯xk = argminÂ¯xâˆˆX(yk) âˆ¥Â¯x âˆ’xkâˆ¥and the second inequality comes from (116).
In Lemma 3.1, we show
dist(y, Y âˆ—) â‰¤Ï„dâˆ¥âˆ‡gÏ(y)âˆ¥2,
(118)
where Ï„d = max{âˆ¥M T âˆ¥2, 2Ï} as shown in the proof of Lemma 3.1. Based on the dual error bound
(118) and following Lemma 3.1 in [20], we have
âˆ†k
d â‰¤Ï„ â€²âˆ¥âˆ‡gÏ(yk)âˆ¥2 = Ï„ â€²âˆ¥Â¯x1,k âˆ’Â¯x2,kâˆ¥2,
(119)
âˆ†k
p â‰¤Î¶âˆ¥xk âˆ’xk+1âˆ¥2 + Î¶â€²âˆ¥xk âˆ’Â¯xkâˆ¥2 â‰¤(Î¾ + Î¾â€²Ï„ 2
pÏƒ2)âˆ¥xk+1 âˆ’xkâˆ¥2,
(120)
37

where Â¯x1,k and Â¯x2,k represent the upper half and lower half of the vector Â¯xk, correspondingly,
Ï„ â€² = Ï„ 2
d/Ï, and
Î¶ = 2A + 3
âˆš
2
2 (Ïƒ âˆ’1),
(121)
Î¶â€² = 2A + 1
2 +
âˆš
2
2 (Ïƒ âˆ’1),
(122)
where A = âˆ¥M T âˆ¥âˆ¥Mâˆ¥+
âˆš
2Ï.
Following Lemmas 3.2 and 3.3 in [20], we have
âˆ†k
d âˆ’âˆ†kâˆ’1
d
â‰¤âˆ’Î±(x1,k âˆ’x2,k)T (Â¯x1,k âˆ’Â¯x2,k),
(123)
âˆ†k
p âˆ’âˆ†kâˆ’1
p
â‰¤Î±âˆ¥x1,k âˆ’x2,kâˆ¥2 âˆ’Î³âˆ¥xk+1 âˆ’xkâˆ¥2 âˆ’Î±(x1,k âˆ’x2,k)T (Â¯x1,k âˆ’Â¯x2,k),
(124)
where âˆ†k
p and âˆ†k
d are primal and dual optimality gaps at iteration k (deï¬ned in the statement of
Theorem 3.1), Î± is the stepsize, and in (124), we have used (115). Adding (123) and (124), we have
[âˆ†k
d + âˆ†k
p] âˆ’[âˆ†kâˆ’1
d
+ âˆ†kâˆ’1
p
] â‰¤Î±âˆ¥x1,k âˆ’x2,kâˆ¥2 âˆ’Î³âˆ¥xk+1 âˆ’xkâˆ¥2 âˆ’2Î±(x1,k âˆ’x2,k)T (Â¯x1,k âˆ’Â¯x2,k)
(125)
= Î±âˆ¥x1,k âˆ’x2,k âˆ’Â¯x1,k + Â¯x2,kâˆ¥2 âˆ’Î±âˆ¥Â¯x1,k âˆ’Â¯x2,kâˆ¥2 âˆ’Ïâˆ¥xk+1 âˆ’xkâˆ¥2
(126)
â‰¤(2Î±Ï„ 2
pÏƒ2 âˆ’Ï)âˆ¥xk+1 âˆ’xkâˆ¥2 âˆ’Î±âˆ¥Â¯x1,k âˆ’Â¯x2,kâˆ¥2,
(127)
where the last inequality comes from (117) and the Cauchy-Schwarz inequality.
Assuming that the stepsize Î± is chosen suï¬ƒcient small such that 0 < Î± <
Ï
2Ï„ 2
pÏƒ2 , and substituting
(119) and (120) into (127), we have
[âˆ†k
d + âˆ†k
p] âˆ’[âˆ†kâˆ’1
d
+ âˆ†kâˆ’1
p
] â‰¤âˆ’Ï âˆ’2Î±Ï„ 2
pÏƒ2
Î¾ + Î¾â€²Ï„pÏƒ2 âˆ†k
p âˆ’Î±
Ï„ â€² âˆ†k
d
(128)
â‰¤âˆ’min{Ï âˆ’2Î±Ï„ 2
pÏƒ2
Î¾ + Î¾â€²Ï„pÏƒ2 , Î±
Ï„ â€² }[âˆ†k
d + âˆ†k
p].
(129)
Therefore, we have
0 â‰¤[âˆ†k
p + âˆ†k
d] â‰¤
1
Î» + 1[âˆ†kâˆ’1
p
+ âˆ†kâˆ’1
d
],
(130)
where Î» = min{
Ïâˆ’2Î±Ï„ 2
pÏƒ2
Î¶+Î¶â€²Ï„ 2
pÏƒ2 , Î±
Ï„ â€² } > 0. Therefore, [âˆ†k
p + âˆ†k
d] â‰¤(
1
Î»+1)k[âˆ†0
p + âˆ†0
d], implying that âˆ†k
p and
âˆ†k
d converges to zero Q-linearly.
38

