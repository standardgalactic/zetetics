FIELDS ET AL, CONTROL FLOW IN ACTIVE INFERENCE SYSTEMS, PART I
1
Control ﬂow in active inference systems
Part I:
Classical and quantum formulations of active
inference
Chris Fields, Filippo Fabrocini, Karl Friston, James F. Glazebrook, Hananel Hazan, Michael Levin and
Antonino Marcian`o
Abstract—Living systems face both environmental complexity
and limited access to free-energy resources. Survival under these
conditions requires a control system that can activate, or deploy,
available perception and action resources in a context speciﬁc
way. In this Part I, we introduce the free-energy principle
(FEP) and the idea of active inference as Bayesian prediction-
error minimization, and show how the control problem arises in
active inference systems. We then review classical and quantum
formulations of the FEP, with the former being the classical limit
of the latter. In the accompanying Part II, we show that when
systems are described as executing active inference driven by
the FEP, their control ﬂow systems can always be represented
as tensor networks (TNs). We show how TNs as control systems
can be implemented within the general framework of quantum
topological neural networks, and discuss the implications of these
results for modeling biological systems at multiple scales.
Index Terms—Bayesian mechanics, Dynamic attractor, Free-
energy principle, Quantum reference frame, Scale-free model,
Topological quantum ﬁeld theory.
I. INTRODUCTION
L
IVING things offer remarkable examples of complex,
multi-level control policies that guide adaptive function at
several scales. At the same time, they are made of components
which are usually thought of as physical objects obeying
simple rules; how can these two perspectives be uniﬁed in a
rigorous manner? The framework of active inference answers
Chris Fields and Hananel Hazan are with the Allen Discovery Cen-
ter, Tufts University, Medford, MA, USA; emails: ﬁeldsres@gmail.com,
Hananel.Hazan@tufts.edu
Filippo Fabrocini is with the College of Design and Innovation, Tongji
University, Shanghai, CHINA, and the Institute for Computing Applications
“Mario Picone”, Italy National Research Council, Rome, ITALY; email:
ﬁlippo.fabrocini@gmail.com
Karl Friston is with the Wellcome Centre for Human Neuroimaging,
University College London, London, UK, and VERSES Research Lab, Los
Angeles, CA, USA; email: k.friston@ucl.ac.uk
James F. Glazebrook is with the Department of Mathematics and Computer
Science, Eastern Illinois University, Charleston, IL, USA and is Adjunct
Faculty at the Department of Mathematics, University of Illinois at Urbana-
Champaign, Urbana, IL, USA; email: jfglazebrook@eiu.edu
Michael Levin is with the Allen Discovery Center, Tufts University, Med-
ford, MA, USA, and the Wyss Institute for Biologically Inspired Engineering
at Harvard University, Boston, MA, USA; email: michael.levin@tufts.edu
Antonino Marcian`o is with the Center for Field Theory and Particle Physics
& Department of Physics, Fudan University, Shanghai, CHINA, and the
Laboratori Nazionali di Frascati INFN, Frascati (Rome), ITALY, and the INFN
sezione Roma “Tor Vergata”, Rome, ITALY; email: marciano@fudan.edu.cn
Manuscript received XXXXX; revised XXXXX.
this question, by providing a completely general, scale-free
formal framework for describing interactions between physical
systems in cognitive terms. It is based on the Free Energy
Principle (FEP), ﬁrst introduced in neuroscience [1]–[5] before
being extended to living systems in general [6]–[9] and then to
all self-organizing systems [10]–[13]. The FEP states that any
system that interacts with its environment weakly enough to
maintain its identiﬁability over time 1) has a Markov blanket
(MB) that separates its internal states from the states of its
environment [14]–[18] and 2) behaves over time in a way
that asymptotically minimizes a variational free energy (VFE)
measured at its MB. Equivalently, the FEP states that any
system with a non-equilibrium steady-state (NESS) solution
to its density dynamics (and hence an MB) will act so as
to maintain its state in the vicinity of its NESS. Any system
compliant with the FEP can be described as engaging, at all
times, in active inference: a cyclic process in which the system
observes its environment, updates its probabilistic “Bayesian
beliefs” (i.e., posterior or conditional probability densities)
over future behaviors, and acts on its environment so as to test
its predictions and gain additional information. The internal
dynamics of such a system can be described as inverting
a generative model (GM) of its environment that furnishes
predictions of the consequences of its actions on its MB.
As a fully-general principle, the FEP applies to all phys-
ical systems, not just to behaviorally interesting, plausibly
cognitive systems, such as organisms or autonomous robots
[10]. Intuitively, behavior is interesting – to external observers
and, we can assume, to the behaving system itself – when
it is complex, situation-appropriate, and robust in the face
of changing environmental conditions. Friston et al. [13]
characterize interesting systems as “strange particles”, whose
internal (i.e., cognitive) states are inﬂuenced by their actions
only via perceived environmental responses; such systems
have to “ask questions” of their environments in order to get
answers [19]. Such systems, even bacteria and other basal
organisms [20]–[23], have multiple ways of observing and
acting upon their environments and deploy these resources in
context-sensitive ways. In operations-research language, they
exhibit situational awareness, i.e., awareness of the context of
actions [24], and deploy attention systems to manage the infor-
mational, thermodynamic, and metabolic costs of maintaining
such awareness [12], [22]. Situational awareness is dependent
This article has been accepted for publication in IEEE Transactions on Molecular, Biological, and Multi-Scale Communications . This is the author's version which has not been fully edited a
content may change prior to final publication. Citation information: DOI 10.1109/TMBMC.2023.3272150
© 2023 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See https://www.ieee.org/publications/rights/index.html for more information.
Authorized licensed use limited to: University College London. Downloaded on June 12,2023 at 15:16:58 UTC from IEEE Xplore.  Restrictions apply. 

FIELDS ET AL, CONTROL FLOW IN ACTIVE INFERENCE SYSTEMS, PART I
2
on both short- and long-term memory, or more technically,
on the period of time over which precise (Bayesian) beliefs
exist, sometimes referred to as the temporal depth or horizon
of the GM [20], [21]. Upper limits can, therefore, be placed on
behavioral complexity by examining the capacity and control
of memory systems from the cellular scale [25] upwards. Liv-
ing systems from microbial mats to human societies employ
stigmergic memories [22] and hence have “extended minds”
[26] in the sense of the literature on embodied, embedded,
enactive, extended, and affective (4EA) cognition [27], [28].
Such memories must be both readable and writable; hence
any system using them must have dedicated, memory-speciﬁc
perception–action capabilities.
Any system with multiple perception–action (or stimulus–
response) capabilities requires a control system that enables
context-guided perception and action and precluding the con-
tinuous, simultaneous deployment of all available perception–
action capabilities. Such self organization entails the selection
of a particular course of action – i.e., policy – from all
plausible policies entertained by the system’s GM. In the
active inference framework, the system’s internal states –
hence its GM – can be read as encoding posterior probability
densities (i.e., Bayesian beliefs) over the causes of its sensory
states, including, crucially, its own actions. This leads to the
notion of planning and control as inference [29]–[31], with
the ensuing selection of an action given by the most likely
policy. In bacteria such as E. coli, for example, mutual inhi-
bition between gene regulatory networks (GRNs) for different
metabolic operons permit the expression of speciﬁc carbon-
source (e.g., sugar) metabolism pathways only when the target
carbon source is detected in the environment [32]. The control
of foraging behavior via chemotaxis employs a similar, in
this case bistable, mechanism [33]. Such mechanisms are
active in multicellular morphogenesis, for example, in the
head-versus-tail morphology decision in planaria [34]. In the
human brain, mutual inhibition between competing visual
processing streams is evident in binocular rivalry (switching
between distinct scenes presented to left and right eyes) or
in the changing interpretations of ambiguous ﬁgures such as
the Necker cube [35], [36]; similar competitive effects are
observed in other sensory pathways [37]. It also characterizes
the competitive interaction between the dorsal and ventral
attention systems, which implement top-down and bottom-
up targeting of sensory resources, respectively [38]. It is
invoked at a still larger scale in global workspace models of
conscious processing, in which incoming information streams
must compete, with each inhibiting the others, for “access to
consciousness” [39], [40]. Mutual inhibition creates an ener-
getic barrier that the control system that implements switching
must expend free-energy resources to overcome; the controller
must not only turn “on” the preferred system, but also turn
“off” the inhibition. The required free energy expenditure
in turn induces hysteresis and hence the non-linear, winner-
takes-all “switch” behavior in the time regime. Such barriers
and their temporal consequences persist in more complex
control systems whenever two perception–action capabilities
are either functionally incompatible or too expensive to deploy
simultaneously.
Switching between perception–action capabilities can be
regarded, from a theoretical, FEP perspective, as selecting
a plausible policy, or plan, supported by the GM. Techni-
cally, the probability distribution over policies or plans can
be computed from a free energy functional expected under
the posterior predictive density over possible outcomes, as
described in §II-A below. The control system that implements
the switching process can be considered to employ the GM to
predict, or assign a probability distribution to, each perception-
action capability (i.e., policy) as a function of context [41],
[42]. We can consider the GM to generate probabilistic
“beliefs” about the consequences of actions, where here a
“belief” is just a mathematically-described structure, e.g., a
classical conditional probability density or a quantum state
with an assigned amplitude. “Planning” or “control” can,
therefore, always be cast as inference – again in the basal
sense of computation – implemented by variational message
passing or “belief propagation” on a (normal style) factor
graph: a graph with nodes corresponding to the factors of
a probability distribution and undirected edges corresponding
to message-passing channels. Factor graphs can be combined
with message passing schemes, with the messages generally
corresponding to sufﬁcient statistics of the factors in question,
to provide an efﬁcient computation of functions such as
marginal densities [43], [44]. Hence one can formalize control
– under the FEP – in terms of control as inference, which
implies that there is a description of control in terms of
message passing on a factor graph. When the GM is over
discrete states, this implies a description of control in terms
of tensor operators.
Nearly all simulations of planning – under discrete state
space GMs – use the factor-graph formalism. Crucially, the
structure of the factor graph embodies the structure of the
GM and, effectively, the way that any system represents the
(apparent causes of) data on its MB; i.e., the way it “carves
nature at its joints,” into states, objects and categorical features.
Under the (classical) FEP, the factors that constitute the nodes
of the factor graph correspond to the state-space factoriza-
tion in a mean ﬁeld approximation, as used by physicists,
or by statisticians to implement variational Bayesian (a.k.a.,
approximate Bayesian) inference [45]. See [46] for technical
details, [47] for an application to the brain, and Supplementary
Information, Table 1 for a list of selected applications.
We show in Parts I and II of this paper that control ﬂow in
such systems can always be formally described as a tensor
network, a factorization of some overall tensor (i.e., high-
dimensional matrix) operator into multiple component tensor
operators that are pairwise contracted on shared degrees of
freedom [48]. In particular, we show that the factorization
conditions that allow the construction of a TN are exactly the
same as those that allow the identiﬁcation of distinct, mutually
conditionally independent (in quantum terms, decoherent),
sets of data on the MB, and hence allow the identiﬁcation
of distinct “objects” or “features” in the environment. This
equivalence allows the topological structures of TNs – many
of which have been well-characterized in applications of the
TN formalism to other domains [48] – to be employed as a
classiﬁcation of control structures in active inference systems;
This article has been accepted for publication in IEEE Transactions on Molecular, Biological, and Multi-Scale Communications . This is the author's version which has not been fully edited a
content may change prior to final publication. Citation information: DOI 10.1109/TMBMC.2023.3272150
© 2023 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See https://www.ieee.org/publications/rights/index.html for more information.
Authorized licensed use limited to: University College London. Downloaded on June 12,2023 at 15:16:58 UTC from IEEE Xplore.  Restrictions apply. 

FIELDS ET AL, CONTROL FLOW IN ACTIVE INFERENCE SYSTEMS, PART I
3
including cells, organisms, and multi-organism communities.
It allows, in particular, a principled approach to the question
of whether, and to what extent, a cognitive system can
impose a decompositional or mereological (i.e., part-whole)
structure on its environment. Such structures naturally invoke
a notion of locality, and hence of geometry. The geometry
of spacetime itself has been described as a particular TN
– a multiscale entanglement renormalization ansatz (MERA)
[49]–[51] – suggesting a deep link between control ﬂow
in systems capable of observing spacetime (i.e., capable of
implementing internal representations of spacetime) and the
deep structure of spacetime as a physical construct.
We begin in this Part I, §II by analyzing the control-ﬂow
problem in three different representations of active inference.
First, we employ the classical, statistical formulation of the
FEP [10], [11] in §II-A to describe control ﬂow as imple-
menting discrete, probabilistic transitions between dynamical
attractors on a manifold of computational states. We then
reformulate the physical interaction in quantum information-
theoretic terms in §II-B; in this formulation [12], components
of the GM can be considered to be distinct quantum reference
frames (QRFs) [52], [53] and represented by hierarchical
networks of Barwise-Seligman classiﬁers [54] as developed in
[55]–[58]. Control ﬂow then implements discrete transitions
between QRFs. The third step, in §II-C, employs the mapping
between hierarchies of classiﬁers and topological quantum
ﬁeld theories (TQFTs) developed in [59]. Here, control ﬂow is
implemented by a TQFT, with transition amplitudes given by
a path integral. The second and third of these representations
provide formal characterizations of intrinsic (or “quantum”)
context effects that are consistent with both the sheaf-theoretic
treatment of contextuality in [60], [61] and the Contextuality
by Default (CbD) approach of [62], [63]; see also the dis-
cussion in [57] and [59, §7.2]. The underlying theme is that
contextuality arises due to the non-existence of any globally
deﬁnable (maximally connected) conditional probability dis-
tribution across all possible observations (see e.g., [64] for a
review from a more general physics perspective). Extending
our earlier analysis [57], we discuss reasons to expect that
active inference systems will generically exhibit such context
effects.
In Part II, we develop a fully-general tensor representation
of control ﬂow, and prove that this tensor can be factored into
a TN if, and only if, the separability (or conditional statistical
independence) conditions needed to identify distinct features
of, or objects in, the environment are met. We show how TN
architecture allows classiﬁcation of control ﬂows, and give
two illustrative examples. We then discuss several established
relationships between TNs and artiﬁcial neural network (ANN)
architectures, and how these generalize to topological quantum
neural networks [59], [65], of which standard deep-learning
(DL) architectures are a classical limit [66]. Having developed
these formal results, we turn to implications of these results
for biology, and discuss how TN architectures correlate with
the observational capabilities of the system being modeled,
particularly as regards abilities to detect spatial locality and
mereology. We consider how to classify known control path-
ways in terms of TN architecture and how to employ the
TN representation of control ﬂow in experimental design. We
conclude by looking forward to how these FEP-based tools
can further integrate the physical and life sciences.
II. FORMAL DESCRIPTION OF THE CONTROL PROBLEM
A. The attractor picture
Let U be a random dynamical system that can be de-
composed into subsystems with states µ(t), b(t), and η(t)
such that the dependence of the µ(t) on the η(t), and vice-
versa, is only via the b(t). In this case, the b(t) form an MB
separating the µ(t) from the η(t). We will refer to the µ(t) as
“internal” states, to the η(t) as “environment” states, and to
the combined π(t) = (b(t), µ(t)) as “particular” (or “particle”)
states [10]. The FEP is a variational or least-action principle
stating that any system – that interacts sufﬁciently weakly with
its environment – can be considered to be enclosed by an MB,
i.e. any “particle” with states π(t) = (b(t), µ(t)), will evolve
in a way that tends to minimize a variational free energy (VFE)
F(π) that is an upper bound on (Bayesian) surprisal. This free
energy is effectively the divergence between the variational
density encoded by internal states and the density over external
states conditioned on the MB states. It can be written [10, Eq.
2.3],
F(π) = Eq(η)[ln qµ(η) −ln p(η, b)]
|
{z
}
Variational free energy
= Eq[−ln p(b|η) −ln p(η)]
|
{z
}
Energy constraint (likelihood & prior)
−Eq[−ln qµ(η)]
|
{z
}
Entropy
= DKL[qµ(η)|p(η)]
|
{z
}
Complexity
−Eq[ln p(b|η)]
|
{z
}
Accuracy
= DKL[qµ(η)||p(η|b)]
|
{z
}
Divergence
−ln p(b)
|
{z
}
Log evidence
≥−ln p(b)
(1)
The VFE functional F(π) is an upper bound on surprisal
(a.k.a. self-information) I(π) = −ln p(π) > −ln p(b) be-
cause the Kullback-Leibler divergence term (DKL) is always
non-negative. This KL divergence is between the density over
external states η, given the MB state b, and a variational
density qµ(η) over external states parameterized by the internal
state µ. If we view the internal state µ as encoding a posterior
over the external state η, minimizing VFE is, effectively,
minimizing a prediction error, under a GM encoded by the
NESS density. In this treatment, the NESS density becomes a
probabilistic speciﬁcation of the relationship between external
or environmental states and particular (i.e., “self”) states. We
can interpret the internal and active MB states in terms of
active inference, i.e., a Bayesian mechanics [11], in which
their expected ﬂow can be read as perception and action,
respectively. Here “active” states are a subset of the MB
states that are not inﬂuenced by environmental states and –
for the kinds of particles considered here – do not inﬂuence
internal states. In other words, active inference is a process of
Bayesian belief updating that incorporates active exploration
of the environment. It is one way of interpreting a generalized
synchrony between two random dynamical systems that are
coupled via an MB.
This article has been accepted for publication in IEEE Transactions on Molecular, Biological, and Multi-Scale Communications . This is the author's version which has not been fully edited a
content may change prior to final publication. Citation information: DOI 10.1109/TMBMC.2023.3272150
© 2023 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See https://www.ieee.org/publications/rights/index.html for more information.
Authorized licensed use limited to: University College London. Downloaded on June 12,2023 at 15:16:58 UTC from IEEE Xplore.  Restrictions apply. 

FIELDS ET AL, CONTROL FLOW IN ACTIVE INFERENCE SYSTEMS, PART I
4
If the “particle” π is a biological cell, it is natural to
consider the MB b to be implemented by the cell membrane
and the “internal” states µ to be the internal macromolecular or
biochemical states of the cell; indeed, it is this association that
motivated the application of the FEP to cellular life [5]. In this
case, the NESS corresponds to the state, or neighborhood of
states, that maintain homeostasis (or more broadly, allostasis
[67]–[69]) and hence maintain the structural and functional
integrity of π as a living cell. This activity of self-maintenance
has been termed “self-evidencing” [70]; systems compliant
with the FEP can be considered to be continually generating
evidence of – or for – their continued existence [10].
In the terminology of [13] cells are “strange particles” –
their signal transduction pathways monitor (components of)
the states of their environments, but do not directly monitor
their actions on their environments (i.e., their own active
states). The consequences of any action can only, therefore,
be deduced from the response of the environment. In this
situation, causation is always uncertain: whether an action
by the environment on the cell – what the cell detects as an
environmental state change – is a causal consequence of an
action the cell has taken in the past cannot be determined by
the data available to the cell. Every action, therefore, increases
VFE, while every observation (potentially) decreases it. The
(apparent) task of the cell’s GM is to minimize the increases,
on average, while maximizing the decreases.
The Bayesian mechanics afforded by the FEP implies a
(classical) thermodynamics; indeed, the FEP can be read as
a constrained maximum entropy or caliber principle [71],
[72]. This follows from the fact that inference, i.e., self
evidencing, entails belief updating and belief updating incurs a
thermodynamic cost via the Jarzynski equality [73]–[75]. This
cost provides a lower bound on the thermodynamic free energy
required for metabolic maintenance. For example, a cell’s
actions on its environment – e.g., chemotactic locomotion
– are largely driven by the need to acquire thermodynamic
free energy. The cell’s GM cannot, therefore, minimize VFE
by minimizing action [76]; instead, it must successfully pre-
dict which actions will replenish its free-energy supply. As
actions are energetically expensive, this requires trading off
short-term costs against long-term goals. As shown in [41],
selective pressures operating on different timescales favor the
development of metaprocessors that control lower-level actions
in a context-dependent way; these are often implemented via
a hierarchical GM [77]. Such meta-level control provides
probabilistic models of risk-sensitive actions in context.
While such systems may be described as regulating free-
energy seeking actions, they also regulate information-seeking
actions, i.e., curiosity-driven exploration [78]–[80]. This fol-
lows because VFE provides an upper bound on complexity
minus accuracy [81]. The expected free energy (EFE), con-
ditioned upon any action, can therefore be scored in terms
of expected complexity and expected inaccuracy. Expected
complexity is “risk” and corresponds to the degree of belief
updating that incurs a thermodynamic cost; leading to risk-
sensitive control (e.g., phototropism). Expected inaccuracy
corresponds to “ambiguity” leading to epistemic behaviors
(e.g., searching for lost keys under a streetlamp) [42].
When context-dependent control is considered, the neigh-
borhood of the NESS resolves into a network of local minima
corresponding to ﬁxed perception-action loops separated by
energetic barriers that the control system must overcome to
switch between loops. For example, in a cell, this energetic
barrier comprises the energy required to activate one pathway
while de-activating another, which may include the energetic
costs of phosphorylation, other chemical modiﬁcations, ad-
ditional gene expression, etc. Different pairs of pathways
can be expected to be separated by energetic barriers of
different heights, generating a topographically-complex free
energy landscape that coarse-grains, in a long-time average,
to the neighborhood of the NESS, i.e., to the maintenance of
allostasis [68], [69], [82].
As noted earlier, we can think of controllable perception-
action loops as nodes on a factor graph, with the edges
corresponding to pathways for control ﬂow, and the transition
probabilities labeling the edges as inversely proportional to the
energetic barrier between loops. This allows representing the
GM for meta-level (i.e., hierarchical) control as a message-
passing system as described in [47]. The presence of very
high energetic barriers can render such a GM effectively one-
way, as seen in the context-dependent switches between signal
transduction pathways and GRNs that characterize cellular
differentiation during morphogenesis. Biological examples of
these include modiﬁcations of bioelectric pattern memories in
planaria, which can create alternative-species head shapes that
eventually remodel back to normal [83], or produce 2-headed
worms which are permanent, and regenerate as 2-headed in
perpetuity [84].
B. The QRF picture
Cellular information processing has traditionally been
treated as completely classical, i.e., as implemented by causal
networks of macromolecules, each of which undergoes clas-
sical state transitions via local dynamical processes that are
conditionally independent of the states of other parts of
the network. While the “quantum” nature of proteins and
other macromolecules is broadly acknowledged, the scale at
which quantum effects are important remains controversial,
with straightforward single-molecule decoherence models pre-
dicting decoherence times of attoseconds (10−18 s) or less
[85], [86]: several orders of magnitude below the timescales
of processes involved in molecular information processing
[87]. While functional roles for quantum coherence in in-
tramolecular information processing have been demonstrated,
intermolecular coherence remains experimentally elusive [88]–
[91].
The free-energy budgets of both prokaryotic and eukaryotic
cells are, however, orders of magnitude smaller than would
be required to support fully-classical information processing
at the molecular scale, suggesting that cells employ quantum
coherence as a computational resource [92]. Indirect evidence
of longer-range, tissue-scale coherence in brains has also been
reported [93]. Reformulating the FEP in quantum information-
theoretic terms enables it to describe situations in which long-
range coherence, and hence quantum computation, cannot be
neglected.
This article has been accepted for publication in IEEE Transactions on Molecular, Biological, and Multi-Scale Communications . This is the author's version which has not been fully edited a
content may change prior to final publication. Citation information: DOI 10.1109/TMBMC.2023.3272150
© 2023 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See https://www.ieee.org/publications/rights/index.html for more information.
Authorized licensed use limited to: University College London. Downloaded on June 12,2023 at 15:16:58 UTC from IEEE Xplore.  Restrictions apply. 

FIELDS ET AL, CONTROL FLOW IN ACTIVE INFERENCE SYSTEMS, PART I
5
Following the development in [12], we consider a bipartite
decomposition U = AB of a ﬁnite, isolated system U for
which the interaction Hamiltonian HAB = HU −(HA + HB)
is sufﬁciently weak over the time period of interest that the
joint state |U⟩is separable (i.e., factors) as |U⟩= |A⟩|B⟩. In
this case, we can choose orthogonal basis vectors |ik⟩so that:
HAB = βkKB Tk
N
X
i
αk
i M k
i ,
(2)
where KB denotes Boltzmann’s constant, T is the absolute
temperature of the environment, k =
A or B, the M k
i are
N mutually-orthogonal Hermitian operators with eigenvalues
in {−1, 1}, the αk
i
∈[0, 1] are such that PN
i αk
i
= 1,
and βk ≥ln 2 is an inverse measure of k’s thermodynamic
efﬁciency that depends on the internal dynamics Hk; see
[56], [58], [94], [95] for further motivation and details of
this construction and [96] for a pedagogical review. This
description is purely topological, attributing no geometry to
either U or B; hence it allows the “embedding space” of
perceived “objects” to be an observer-dependent construct. It
has several relevant consequences:
• We can regard A and B as separated, and determined
by independent measures. They are separated by – and
interact via – a holographic screen B that can be rep-
resented, without loss of generality, by an array of N
non-interacting qubits, where N is the dimension of HAB
[94], [95].
• A and B can be regarded as exchanging ﬁnite N-bit
strings, each of which encodes one eigenvalue of HAB
[94].
• A and B have free choice of basis for HAB, correspond-
ing to free choice of local frames at B, e.g., free choice,
for each qubit qi on B, of the local z axis and hence the
z-spin operator sz that acts on qi [96].
• Choice of basis corresponds to choosing the zero-point
of total energy by each of A and B. The systems A and
B are, therefore, in general at informational, but not at
thermal equilibrium [12].
• As A and B must obtain from B or A, respectively,
whatever thermodynamic free energy is required, by Lan-
dauer’s principle [73], [99], [100], to fund the encoding
of classical bits on B (as well as any other irreversible
classical computation), A and B must each devote some
sector F of B to free-energy acquisition. The bits in F
are “burned as fuel” and so do not contribute input data
to computations. Waste-heat dissipation by one system
is free energy acquisition by the other. The free-energy
sectors FA and FB of A and B need not align as subsets
of qubits on B; that is, qubits that A regards as free-
energy sources may be regarded by B as informative
outputs and vice-versa [56], [58].
• The actions of the internal dynamics HA and HB on B
can be represented by A- and B-speciﬁc sets of QRFs,
each of which both “measures” and “prepares” qubits on
B. Each QRF acts on the qubits in some speciﬁc sector of
B, breaking the permutation symmetry of Eq. (2) [56],
[58], [59]. Only QRFs acting on sectors other than F
implement informative computations; we will therefore
restrict attention to these QRFs.
• Each “computational” QRF can, without loss of general-
ity, be represented by a cone-cocone diagram (CCCD)
comprising Barwise-Seligman classiﬁers and infomor-
phisms between them [54], [55]. The apex of each
such CCCD is, by deﬁnition, both the category-theoretic
limit and colimit of the “input/output” classiﬁers that
correspond, formally, to the operators M k
i in Eq. (2) [56],
[58], [59].
Typically, a CCCD is structured as a distributed information
ﬂow in the form:
A1
g12
g21
/ A2
o
g23
g32
/ . . . Ak
o
C′
h1
h
h2
O
hk
5
A1
f1
6
g12
g21
/ A2
o
f2
O
g23
g32
/ . . . Ak
o
fk
i
(3)
incorporating sets of classiﬁers {Aα} and (logic) infomor-
phisms {fi, gjk} [54, Ch 12] over suitable index ranges.
As a memory-write system, Diagram (3) depicts a generic
blueprint for a bow-tie or variational autoencoder (VAE) net-
work amenable to describing a hierarchical Bayesian network
with belief-updating as discussed in e.g. [12], [57], [59].
Crucially, it is the non-commutativity of CCCDs of this form
that speciﬁes intrinsic or quantum contextuality, as occurs, for
instance, when the colimit core C′ is undeﬁnable [57, §7, §8]
[59, §7.2]. Consequences of such contextuality are discussed
via examples in Part II.
The holographic screen B functions as an MB separating
A from B. It can be regarded as having an N-dimensional,
N-qubit Hilbert space Hqi = Q
i qi. While Hqi is strictly
ancillary to HU = HA ⊗HB, the classical situation can be
recovered in the limit in which the entanglement entropies
S(|A⟩), S(|B⟩) →0 by considering the products HA ⊗Hqi
and HB ⊗Hqi to be “particle” state spaces for A and B,
respectively. In this classical limit, the states of Hqi become
the blanket states of an MB that functions as a classical
information channel [94]–[96]. In quantum holographic cod-
ing, for example, B is often represented by a polygonal
tessellation of the hyperbolic disc, with qubits represented
by polygonal centroids. A speciﬁc TN model of a pentagon
code is developed in [97]; see in particular their Fig. 4.
The geometric description of B as implementing holographic
coding, and its classical limit as an MB structured as a direct
acyclic graph (DAG), is further explored in the setting of
TQNNs in [98].
In this quantum-theoretic picture, “systems” or “objects”
observed and manipulated by A or B correspond to sectors
on B that are the domains of particular QRFs deployed by
A or B, respectively [12], [58], [59]. To simplify notation,
we use the same symbol, e.g., ‘Q’ to denote both a QRF
Q and the sector dom(Q) on B. Any identiﬁable system X
This article has been accepted for publication in IEEE Transactions on Molecular, Biological, and Multi-Scale Communications . This is the author's version which has not been fully edited a
content may change prior to final publication. Citation information: DOI 10.1109/TMBMC.2023.3272150
© 2023 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See https://www.ieee.org/publications/rights/index.html for more information.
Authorized licensed use limited to: University College London. Downloaded on June 12,2023 at 15:16:58 UTC from IEEE Xplore.  Restrictions apply. 

FIELDS ET AL, CONTROL FLOW IN ACTIVE INFERENCE SYSTEMS, PART I
6
factors into a “reference” component R that maintains a time-
invariant state |R⟩or more generally, state density ρR, that
allows re-identiﬁcation and hence sequential measurements
over extended time, and a “pointer” component P with a time-
varying state |P⟩or density ρP . It is this pointer component,
named for the pointer of an analog instrument, which is
the “state of interest” for measurements. The QRFs R and
P clearly must commute, and the sectors R and P clearly
must be mutually decoherent [12], [58], [59]. All “system”
sectors must be components of some overall sector E that
corresponds to the “observable environment.” The recording of
measurement outcomes to a classical memory and the reading
of previously-recorded outcomes from memory can similarly
be represented by a QRF Y . As dom(Y ) is a sector on B,
recorded memories of A are exposed to and hence subject
to modiﬁcation by B and vice-versa. Both the observable
environment E and the memory sector Y must be disjoint
from, and decoherent with, the free-energy sector F.
As actions on B encode classical data, they have an asso-
ciated free energy cost of at least ln2 KBT per bit [73], [99],
[100] that must originate from the source at F. Time-energy
complementary associates a minimum time of h/[ln2(KBT)],
with h being Planck’s constant, to this energy expenditure.
We can, therefore, associate actions on B, including memory
writes, with “ticks” of an internal time QRF, which we denote
tA and tB for A and B, respectively. Assuming all observa-
tional outcomes are written to memory, we can represent the
situation as in Fig. 1. The time QRF is effectively an outgoing
bit counter that can be represented by a groupoid operator
Gij : ti →tj [56]. As outgoing bits are oriented in opposite
directions with respect to B for A and B, the time “arrows”
tA and tB point in opposite directions. Hence A and B can
both be regarded as “interacting with their own futures” as
discussed in [96].
Measurements of a system X can be considered sequential
if: 1) they are separated in time according to the internal
time QRF, and 2) their outcomes are recorded to memory
to enable comparability across time. We show in [59] that
sequential measurements can always be represented by one of
two schemata. Using the compact notation:
S
(4)
to represent a QRF S, we can represent measurements of
a physical situation in which one system divides into two,
possibly entangled, systems with a diagram of the form:
S
S1
S2
S
(5)
Fig. 1. Cartoon illustration of QRFs required to observe and write a readable
memory of an environmental state |E⟩. The QRFs E and Y read the state
from E and write it to the memory Y respectively. Any identiﬁed system
S must be part of E. The clock Gij is a time QRF that deﬁnes the time
coordinate tA. The dashed arrow indicates the observer’s thermodynamic
process that converts free energy obtained from the unobserved sector F of
B to waste heat exhausted through F. Adapted from [58], CC-BY license.
Parametric down-conversion of a photon exempliﬁes this kind
of process. The reverse process can be added to yield:
S
S1
S2
S
S
(6)
In the second type of sequential measurement process, the
pointer-state QRF P is replaced with an alternative QRF Q
with which it does not commute. Sequences in which position
and momentum, or spins sz and sx, are measured alternately
are examples. These can be represented by the diagram:
S
P
R
S
S
Q
R
S
(7)
As both P and Q must commute with R, the commutativity
requirements for S are satisﬁed.
The sequences of operations depicted in Diagrams (6) and
(7) clearly raise the questions of how control is implemented,
This article has been accepted for publication in IEEE Transactions on Molecular, Biological, and Multi-Scale Communications . This is the author's version which has not been fully edited a
content may change prior to final publication. Citation information: DOI 10.1109/TMBMC.2023.3272150
© 2023 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See https://www.ieee.org/publications/rights/index.html for more information.
Authorized licensed use limited to: University College London. Downloaded on June 12,2023 at 15:16:58 UTC from IEEE Xplore.  Restrictions apply. 

FIELDS ET AL, CONTROL FLOW IN ACTIVE INFERENCE SYSTEMS, PART I
7
and of how the context changes that drive control ﬂow are
detected. Before turning to these questions in Part II, we
review a path-integral representation of QRFs, show that the
same representation also captures the behavior of any system
X identiﬁed by a QRF, and discuss the questions of multiple
observers and quantum contextuality.
C. The TQFT picture
As a least-action principle, the FEP is fundamentally a
statement about the paths followed by the joint system U
through its state space. The classical FEP is amenable to
a path-integral formulation [13] that expresses the expected
value of any observable (functional) Ω[x(t)] of paths x(t)
through the relevant state space as ( [101], Eq. 6):
⟨Ω[x(t)]⟩=
Z
dx0
Z
d[x(t)]Ω[x(t)]p(x(t)|x0)p0(x0)
(8)
where x0 is the initial state and p(x(t)|x0) is the conditional
probability of the path x(t). Quantum theory generalizes this
expression by, effectively. replacing Ω[x(t)] with an auto-
morphism on the relevant Hilbert space and p(x(t)|x0) with
an amplitude for x(t) given the initial state x0. For some
ﬁnite-dimensional Hilbert space H, the manifold of all such
automorphisms is a cobordism on H, which is by deﬁnition a
TQFT on H [102].
We show in [59] that any sequential measurement of any
sector X of B induces a TQFT on X, considered as a
projection of the N-dimensional boundary Hilbert space Hqi
associated with B. In particular, measurement sequences of
the form of Diagram (6) can be mapped to cobordisms, i.e.,
to manifolds of maps between two designated boundaries, of
the form:
B
S
B
S
S1
S2
S
S1
S2
F(i)
F(k)
F
(9)
while sequences of the form of Diagram (7) can be mapped
to cobordisms of the form:
B
P
R
B
S
Q
R
P
R
S
Q
R
F(i)
F(k)
F
(10)
In either case, F : CCCD →Cob is the functor from
the category CCCD of CCCDs (and hence of QRFs) to the
category Cob of ﬁnite cobordisms required to deﬁne a TQFT.
In general, we can state:
Theorem 1 ( [59] Thm. 1). For any morphism F of CCCDs
in CCCD, there is a cobordism S such that a diagram of
the form of Diagram (9) or (10) commutes.
referring to [59] for the proof.
Theorem 1 applies to any sequential measurement; there-
fore, it applies to measurements of a sector X followed
by measurements of the associated memory sector Y , or
vice versa. Assuming for convenience that the dimension
dim(X) = dim(Y ), we can consider a composite operation
Q = (−→
Q, ←−
Q), where −→
Q = QXQY and ←−
Q = QY QX. This Q
is a pair of QRF sequences that can be identiﬁed with TQFTs
that measure and record an outcome, mapping HX →HY ,
and dually use an outcome read from memory to prepare a
state, mapping HY →HX, respectively, as in Diagram 11:
B
Q
(11)
This article has been accepted for publication in IEEE Transactions on Molecular, Biological, and Multi-Scale Communications . This is the author's version which has not been fully edited a
content may change prior to final publication. Citation information: DOI 10.1109/TMBMC.2023.3272150
© 2023 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See https://www.ieee.org/publications/rights/index.html for more information.
Authorized licensed use limited to: University College London. Downloaded on June 12,2023 at 15:16:58 UTC from IEEE Xplore.  Restrictions apply. 

FIELDS ET AL, CONTROL FLOW IN ACTIVE INFERENCE SYSTEMS, PART I
8
This composite operator Q is, by Theorem 1, itself a TQFT
[98]. Hence the operation of recording observational outcomes
for a sector X made at t to memory, and then comparing
them to later observations at t + ∆t, is formally equivalent to
propagating the “system” X forward in time from t to t+∆t.
Identifying QRFs as “internal” TQFTs allows a general
analysis of information exchange between multiple QRFs
deployed by a single system, e.g., A. Because all QRFs act on
B, information exchange between QRFs requires a channel
that traverses B. Any such channel is itself a QRF, one
deployed by B. Considering A to comprise two observers,
one deploying Q1 and the other deploying Q2, that interact
via a local operations, classical communication (LOCC [103])
protocol provides an example:
B
A
B
Q1
Q2
Classical channel
Quantum channel
(12)
In a LOCC protocol, one channel is considered “classical”
while the other is considered “quantum”; however, this lan-
guage masks the fact that both channels are physical. As
pointed out in [104], all media supporting classical commu-
nication are physical, and interactions with these media are
always local measurements or preparations. Hence the two
channels in a LOCC protocol are physically equivalent – both
are TQFTs implemented by B – although their conventional
semantics are different.
Diagram
(12)
can,
clearly,
also
represent
externally-
mediated communication between any two functional com-
ponents of a system, e.g., macromolecular pathways within
a cell or functional networks within a brain. We show in
[98] that whenever Q1 and Q2 are deployed by distinct –
technically, separable or mutually decoherent – “observers”
or “systems,” they fail to commute, i.e., the commutator
[Q1, Q2] = Q1Q2 −Q2Q1 ≥h/2, where again h is Planck’s
constant. As shown in [57], Theorem 3.4 using the CCCD
representation, non-commutativity of QRFs induces quantum
contextuality, i.e., dependence of measurement results on
“non-local hidden variables” that characterize the measure-
ment context [105]–[107]. In the current context, such hidden
variables characterize the action of HB on B, affecting what
A will observe next in every cycle of A-B interaction.
As shown in [63], such context dependence can, in prin-
ciple, be captured classically if sufﬁcient measurements of
the context can be implemented. Such measurements would,
however, have to access all of B. The existence of an MB
prevents such access; in the current setting, A has access
to B only via B. The ﬁnite energetic cost of measurement,
and consequent requirement for a thermodynamic sector F,
prevents measurement even of all of B by any ﬁnite physical
system. Hence, we can expect physical systems, including all
biological systems, to employ only local context-dependent
control to switch between mutually non-commuting (sets of)
QRFs. How context switches implemented by QRF switches
induce evolution, development and learning was introduced
in [22]. Some speciﬁc examples of context switching in
biological systems will be discussed Part II.
III. CONCLUSION
We have shown in this Part I how the problem of deﬁning
control ﬂow arises in active inference systems, and provided
three formal representations of the problem. Control ﬂow can,
in particular, be represented as switching between classical
dynamical attractors, between deployed QRFs, and between
computational processes represented by TQFTs. Implementing
control ﬂow has a free-energy cost; hence any control-ﬂow
system must trade off its own processing costs against the
expected beneﬁts of switching between input/ouput modes.
The time and memory dependence of control ﬂow can, more-
over, be expected to lead generically to context effects on both
perception and action.
In the accompanying Part II of this paper, we will ﬁrst prove
that control ﬂows in active inference systems can always be
represented as TNs, and show how TN architectures provide
a convenient classiﬁcation control ﬂows. We then show how
these can be implemented by TQNNs, and discuss applications
of this formalism to the problem of characterizing control ﬂow
in biological systems.
ACKNOWLEDGEMENTS
K.F. is supported by funding for the Wellcome Centre for
Human Neuroimaging (Ref: 205103/Z/16/Z), a Canada-UK
Artiﬁcial Intelligence Initiative (Ref: ES/T01279X/1) and the
European Union’s Horizon 2020 Framework Programme for
Research and Innovation under the Speciﬁc Grant Agreement
No. 945539 (Human Brain Project SGA3). M.L. gratefully
acknowledges funding from the Guy Foundation and the
John Templeton Foundation, Grant 62230. A.M. wishes to
acknowledge support by the Shanghai Municipality, through
the grant No. KBH1512299, by Fudan University, through
the grant No. JJH1512105, the Natural Science Foundation
of China, through the grant No. 11875113, and by the Depart-
ment of Physics at Fudan University, through the grant No.
IDH1512092/001.
CONFLICT OF INTEREST
The authors declare no competing, ﬁnancial, or commercial
interests in this research.
REFERENCES
[1] K. J. Friston, “A theory of cortical responses,” Philos. Trans. R. Soc. B,
vol 360, pp.815–36, 2005.
This article has been accepted for publication in IEEE Transactions on Molecular, Biological, and Multi-Scale Communications . This is the author's version which has not been fully edited a
content may change prior to final publication. Citation information: DOI 10.1109/TMBMC.2023.3272150
© 2023 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See https://www.ieee.org/publications/rights/index.html for more information.
Authorized licensed use limited to: University College London. Downloaded on June 12,2023 at 15:16:58 UTC from IEEE Xplore.  Restrictions apply. 

FIELDS ET AL, CONTROL FLOW IN ACTIVE INFERENCE SYSTEMS, PART I
9
[2] K. J. Friston, J. Kilner, and L. Harrison, “A free energy principle for the
brain, . J. Physiol. (Paris), vol. 100, pp. 70–87, 2006.
[3] K. J, Friston and K. E. Stephan, “Free-energy and the brain,” Synthese,
vol. 159, pp.417–458, 2007.
[4] K. J. Friston, “The free-energy principle: A uniﬁed brain theory?” Nature
Rev. Neurosci., vol. 11, pp. 127–138, 2010.
[5] K. J. Friston, “Life as we know it,” J. R. Soc. Interface, vol. 10, art.
20130475, 2013.
[6] K. J. Friston, T. FitzGerald, F. Rigoli, P. Schwartenbeck, and G. Pezzulo,
“Active inference: A process theory,” Neural Comput., vol. 29, pp. 1–49,
2017.
[7] M. J. Ramstead, P. B. Badcock, and K. J. Friston, “Answering
Schr¨odinger’s question: A free-energy formulation, Phys. Life Rev,, vol.
24, pp. 1–16, 2018.
[8] M. J. Ramstead, A. Constant, P. B. Badcock, and K. J. Friston, “Varia-
tional ecology and the physics of sentient systems,” Phys. Life Rev. vol.
31, pp. 188–205, 2019.
[9] F. Kuchling, K. Friston, G. Georgiev, and M. Levin, “Morphogenesis
as Bayesian inference: A variational approach to pattern formation and
control in complex biological systems,” Phys. Life Rev. vol. 33, pp. 88–
108, 2020.
[10] K. J. Friston, “A free energy principle for a particular physics,” Preprint
arxiv:1906.10184 [q-bio.NC], 2019.
[11] M. J. Ramstead, D. A. R. Sakthivadivel, C. Heins, M. Koudahl, B.
Millidge, L. Da Costa, B. Klein, and K. J. Friston, “On Bayesian
mechanics: A physics of and by beliefs,” Interface Focus 13, 2022.0029.
[12] C. Fields, K. Friston, J. F. Glazebrook, and M. Levin, “A free energy
principle for generic quantum systems,” Prog. Biophys. Mol. Biol. vol.
173, pp. 36–59, 2022.
[13] K. Friston, L. Da Costa, D. A. R. Sakthivadivel, C. Heins, G. A. Pavli-
otis, M. J. Ramstead, and T. Parr, “Path integrals, particular kinds, and
strange things,” Preprint arxiv:2210.12761 [cond-mat.stat-mech], 2022.
[14] J. Pearl, Probabilistic Reasoning in Intelligent Systems: Networks of
Plausible Inference. San Mateo, CA, Morgan Kaufmann, 1988. .
[15] A. Clark, “How to knit your own Markov blanket: Resisting the second
law with metamorphic minds,” in Philosophy and Predictive Processing,
vol. 3. Frankfurt am Main: Mind Group, 2017.
[16] M. Kirchhoff, T. Parr, E. Palacios, K. Friston, and J. Kiverstein, “The
Markov blankets of life: Autonomy, active inference and the free energy
principle,” J. R. Soc. Interface vol. 15, art. 20170792, 2018.
[17] T. Parr, L. Da Costa, and K. Friston, “Markov blankets, information
geometry and stochastic thermodynamics,” Philos. Trans. A: Math. Phys.
Eng. Sci. vol. 378, art. 20190159, 2020.
[18] D.A.R. Sakthivadivel, “Weak Markov blankets in high-dimensional,
sparsely-coupled random dynamical systems’ Preprint arXiv:2207.07620,
2022.
[19] J. H. Wheeler, “Information, physics, quantum: The search for links,”
in Complexity, Entropy, and the Physics of Information. Boca Raton, FL,
CRC Press, pp. 3–28, 1989.
[20] M. Levin, “The computational boundary of a “self”: Developmental
bioelectricity drives multicellularity and scale-free cognition,” Front.
Psychol., vol. 10, art. 1688, 2019.
[21] M. Levin, “Life, death, and self: Fundamental questions of primitive
cognition viewed through the lens of body plasticity and synthetic
organisms,” Biochem. Biophys. Res. Commun., vol. 564, pp. 114–133,
2021.
[22] C. Fields, J. F. Glazebrook, and M. Levin, “Minimal physicalism as a
scale-free substrate for cognition and consciousness,” Neurosci. Cons.,
vol. 7, no. 2, art. niab013, 2021.
[23] M. Levin, M. 2022 “Technological approach to mind everywhere: An
experimentally-grounded framework for understanding diverse bodies and
minds,” Front. Syst. Neurosci., vol. 16, art. 768201, 2022.
[24] M. R. Endsley, “Situational awareness,” in Handbook of Human Factors
and Ergonomics, 4th Ed. Hoboken, NJ, John Wiley, pp. 553–568 2012.
[25] C. Fields and M. Levin, M. 2018 “Multiscale memory and bioelectric
error correction in the cytoplasm-cytoskeleton-membrane system,” WIRES
Syst. Biol. Med., vol. 10, art. e1410, 2017.
[26] A. Clark and D. Chalmers, “The extended mind (Active externalism),”
Analysis vol. 58, no. 1, pp. 7–19, 1998.
[27] M. L. Anderson, “Embodied cognition: A ﬁeld guide,” Artif. Intell.,
vol.149, pp. 91–130, 2003.
[28] T. Froese and T. Ziemke, “Enactive artiﬁcial intelligence: Investigating
the systemic organization of life and mind,” Artif. Intell. vol. 173, pp.
466–500, 2009.
[29] H. Attias, “Planning by probabilistic inference,” in Proc. of the 9th
Int. Workshop on Artiﬁcial Intelligence and Statistics in Proc. Machine
Learning Res. vol. R4, pp. 9–16, 2003.
[30] M. Botvinickand M. Toussaint, “Planning as inference,” Trends Cogn.
Sci. vol. 16, no. 10, 485–488, 2012.
[31] P. Lanillos, C. Mio, C. Pezzato, et al., “Active inference in robotics
and artiﬁcial agents: Survey and challenges,” Preprint arXiv:2112.01871,
2021.
[32] V. Chubukov, L. Gerosa, K. Kochanowski, and U. Sauer, “Coordination
of microbial metabolism,” Nat. Rev. Microbiol., vol. 12, pp. 327–340,
2014.
[33] G. Micali and R. G. Endres, “Bacterial chemotaxis: Information pro-
cessing, thermodynamics, and behavior,” Curr. Opin. Microbiol., vol. 30,
pp. 8–15, 2016.
[34] G. Pezzulo, J. LaPalme, F. Durant, and M. Levin, “Bistability of somatic
pattern memories: Stochastic outcomes in bioelectric circuits underlying
regeneration,” Philos. Trans. R. Soc. Lond. B vol. 376, no. 1821, art.
20190765, 2021.
[35] R. Blake and N. K. Logothetis, “Visual competition,” Nat. Rev. Neurosci.
vol. 3, pp. 1–11, 2002.
[36] P. Stertzer, A. Kleinschmidt, and G. Rees, “The neural bases of multi-
stable perception,” Trends Cogn. Sci. vol. 13, pp. 310–318, 2009.
[37] J.-L. Schwartz, N. Grimault, J.-M. Hup´e, B. C. J. Moore, and D.
Pressnitzer, “Multistability in perception: bindingsensory modalities, An
overview,” Phil. Trans. R. Soc. Lond. B vol. 367, pp. 896–905, 2012.
[38] S. Vossel, J. J. Geng, and G. R. Fink, G. R. 2014 “Dorsal and
ventral attention systems: Distinct neural circuits but collaborative roles,”
Neuroscientist vol. 20, pp. 150–159, 2014.
[39] B. J. Baars and S. Franklin, “How conscious experience and working
memory interact,” Trends Cogn. Sci. vol. 7, pp. 166–172, 2003.
[40] B. J. Baars, S. Franklin, and T. Z. Ramsoy, “Global workspace dynamics:
Cortical “binding and propagation” enables conscious contents,” Front.
Psychol. vol. 4, art. 200, 2013.
[41] F. Kuchling, C. Fields, and M. Levin,“Metacognition as a consequence
of competing evolutionary time scales,” Entropy, vol. 24, art. 601, 2022.
[42] T. Parr and K. J. Friston, “Generalised free energy and active inference,”
Biol. Cybern., vol. 113, no. 5-6, pp. 495–513, 2019.
[43] J. Winn and C. M. Bishop, “Variational message passing,” J. Mach.
Learn. Res., vol. 6, pp. 661–694, 2005.
[44] J. Dauwels, “On variational message passing on factor graphs,” in 2007
IEEE International Symposium on Information Theory, Nice, France,
2007.
[45] T. Parr, N. Sajid, and K. J. Friston, “Modules or mean-ﬁelds?” Entropy,
vol. 22, no. 5, art. 552, 2020.
[46] L. Da Costa, T. Parr, N. Sajid, S. Veselic, V. Neacsu, and K. Friston,
“Active inference on discrete state-spaces: A synthesis,” J. Math. Psychol.,
vol. 99, art. 102447, 2020.
[47] K. Friston, T. Parr, and B. de Vries, “The graphical brain: Belief
propagation and active inference,” Netw. Neurosci., vol. 1, no. 4, pp.
381–414, 2017.
[48] R. Or´us, “Tensor networks for complex quantum systems,” Nat. Rev.
Phys., vol. 1, pp. 538–550, 2019.
[49] N. Bao, C.-J. Cao, S. M. Carroll, and A. Chatwin-Davies, “de Sitter
space as a tensor network: Cosmic no-hair, complementarity, and com-
plexity,” Phys. Rev. D vol. 96, art. 123536, 2017.
[50] Q. Hu and G. Vidal, “Spacetime symmetries and conformal data in the
continuous Multiscale Entanglement Renormalization Ansatz,” Phys. Rev.
Lett., vol. 119, art. 010603, 2017.
[51] A. R. Chandra, J. de Boer, M. Flory, M. P. Heller, S. H¨ortner,and A.
Rolph, “Spacetime as a quantum circuit,” J. High Energy Phys., vol. 2021,
art. 207, 2021.
[52] Y. Aharonov and T. Kaufherr, “Quantum frames of reference,” Phys.
Rev. D, vol. 30, pp. 368–385, 1984.
[53] S. D. Bartlett, T. Rudolph, and R. W. Spekkens, “Reference frames,
super-selection rules, and quantum information,” Rev. Mod. Phys., vol.
79, 555–609, 2007.
[54] J. Barwise and J. Seligman, Information Flow: The Logic of Distributed
Systems (Cambridge Tracts in Theoretical Computer Science 44). Cam-
bridge, UK, Cambridge University Press, 1997.
[55] C. Fields and J. F. Glazebrook, “A mosaic of Chu spaces and Channel
Theory I: Category-theoretic concepts and tools,” J. Expt. Theor. Artif.
Intell., vol. 31, pp. 177–213, 2019.
[56] C. Fields and J. F. Glazebrook, “Representing measurement as a ther-
modynamic symmetry breaking,” Symmetry, vol. 12, art. 810, 2020.
[57] C. Fields and J. F. Glazebrook, “Information ﬂow in context-dependent
hierarchical Bayesian inference, ” J. Expt. Theor. Artif. intell., vol. 34,
pp. 111–142, 2022.
[58] C. Fields and J. F. Glazebrook, and A. Marcian`o, “Reference frame
induced symmetry breaking on holographic screens,” Symmetry, vol. 13,
art. 408, 2021.
This article has been accepted for publication in IEEE Transactions on Molecular, Biological, and Multi-Scale Communications . This is the author's version which has not been fully edited a
content may change prior to final publication. Citation information: DOI 10.1109/TMBMC.2023.3272150
© 2023 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See https://www.ieee.org/publications/rights/index.html for more information.
Authorized licensed use limited to: University College London. Downloaded on June 12,2023 at 15:16:58 UTC from IEEE Xplore.  Restrictions apply. 

FIELDS ET AL, CONTROL FLOW IN ACTIVE INFERENCE SYSTEMS, PART I
10
[59] C. Fields and J. F. Glazebrook, and A. Marcian`o, “Sequential measure-
ments, topological quantum ﬁeld theories, and topological quantum neural
networks,” Fortschr. Phys., vol. 70, art. 2200104, 2022.
[60] S. Abramsky and A. Brandenburger, “The sheaf-theoretic structure of
non-locality and contextuality,” New J. Phys., vol. 13, art. 113036, 2011.
[61] S. Abramsky, R. S. Barbosa, and S. Mansﬁeld, “Contextual fraction as
a measure of contextuality,” Phys. Rev. Lett., vol. 119, art. 050504, 2017.
[62] E. N. Dzhafarov and J. V. Kujala, “Contextuality-by-Default 2.0: Sys-
tems with binary random variables,” in Lecture Notes in Computer
Science, vol. 10106. Berlin, Springer, pp. 16–32, 2017.
[63] E. N. Dzharfarov and M. Kon, “On universality of classical probability
with contextually labeled random varaibles,” J. Math. Psychol., vol. 85,
pp. 17–24, 2018.
[64] E. Adlam, “Contextuality, ﬁne-tuning and teleological explanation,”
Found. Phys. 51, 106.
[65] A. Marcian`o, D. Chen, F. Fabrocini, C. Fields, E. Greco, N. Gresnigt, K.
Jinklub, M. Lulli, K. Terzidis, and E. Zappala, “Quantum neural networks
and topological quantum ﬁeld theories,” Neural Networks, vol. 153, pp.
164–178, 2022.
[66] A. Marcian`o, D. Chen, F. Fabrocini, C. Fields, M. Lulli,and E. Zap-
pala, “Deep neural networks as the semi-classical Limit of topologi-
cal quantum neural networks: The problem of generalisation,” Preprint
arXiv:2210.13741, 2022.
[67] P. Sterling and J. Eyer, “Allostasis: A new paradigm to explain arousal
pathology,” in Handbook of Life Stress, Cognition and Health. New York,
NY, John Wiley & Sons, pp. 629–649, 1988.
[68] L. F. Barrett, K. S. Quigley, and P. Hamilton, “An active inference theory
of allostasis and interoception in depression,” Philos. Trans. R. Soc. Lond.
B, vol. 371, no. 1708, art. 20160011, 2016.
[69] A. W. Corcoran, G. Pezzulo, and J. Hohwy, “From allostatic agents to
counterfactual cognisers: Active inference, biological regulation, and the
origins of cognition,” Biol. Philos., vol. 35, no. 3, art. 32, 2020.
[70] J. Hohwy, “The self-evidencing brain,” Noˆus, vol. 50, no. 2, 259–285,
2016.
[71] D. A. R. Sakthivadivel, “A constraint geometry for inference and
integration,” Preprint arXiv:2203.08119, 2022.
[72] D. A. R. Sakthivadivel, “Towards a geometry and analysis for Bayesian
mechanics,” Preprint arXiv:2204.11900, 2022.
[73] R. Landauer, “Irreversibility and heat generation in the computing
process,” IBM J. Res. Dev., vol. 5, pp. 183–195, 1961.
[74] C. Jarzynski, “Nonequilibrium equality for free energy differences,”
Phys. Rev. Lett., vol. 78, pp. 2690–2693, 1997.
[75] D. J. Evans, “A non-equilibrium free energy theorem for deterministic
systems,” Molec. Phys, vol. 101, no. 10, pp. 1551–1554, 2003.
[76] K. Friston, C. Thornton, and A. Clark, “Free-energy minimization and
the dark-room problem,” Front. Psychol., vol. 3, art. 130, 2012.
[77] G. Pezzulo, F. Rigoli, and K. Friston, “Active Inference, homeostatic
regulation and adaptive behavioural control,” Prog. Neurobiol., vol. 134,
pp. 17–35, 2015.
[78] K. Friston, F. Rigole, D. Ognibene, C. Mathys, T. Fitzgerald, and G.
Pezzulo, “Active inference and epistemic value,” Cogn. Neurosci., vol. 6,
pp. 187–214, 2015.
[79] J. Schmidhuber, “Curious model-building control-systems,” in 1991
IEEE International Joint Conference on Neural Networks, vol. 2, pp.
1458–1463, 1991.
[80] Y. Sun, F. Gomez, and J. Schmidhuber, “Planning to be surprised:
Optimal Bayesian exploration in dynamic environments,” in Artiﬁcial
General Intelligence. Berlin, Heidelberg, Springer, pp. 41–51, 2011.
[81] B. Sengupta and K. Friston, “How robust are deep neural networks?”
Preprint arXiv:1804.11313, 2018.
[82] A. K. Seth and K. J. Friston, “Active interoceptive inference and the
emotional brain.” Philos. Trans. R. Soc. Lond. B, vol. 371, no. 1708, art.
20160007, 2016.
[83] M. Emmons-Bell,F. Durant, J. Hammelman, et al., “Gap junctional
blockade stochastically induces different species-speciﬁc head anatomies
in genetically wild-type Girardia dorotocephala ﬂatworms,” Int. J. Mol.
Sci., vol. 16, pp. 27865–27896, 2015.
[84] N. J. Oviedo, J. Morokuma, P. Walentek, et al., “Long-range neural
and gap junction protein-mediated cues control polarity during planarian
regeneration,” Dev. Biol., vol. 339, pp. 188–199, 2010.
[85] M. Tegmark, “Importance of quantum decoherence in brain processes,”
Phys. Rev. E, vol. 61,. pp. 4194–4206, 2000.
[86] M. Schlosshauer, Decohenece and the Quantum to Classical Transition.
Berlin, Springer, 2007.
[87] M. C. Zweir and L. T. Chong, “Reaching biological timescales with
all-atom molecular dynamics simulations,” Curr. Opin. Pharmacol., vol.
10, pp. 745–752, 2010.
[88] A. Marais, et al., “The future of quantum biology,” J. R. Soc. Interface,
vol. 15, art. 20180640, 2018.
[89] J. Cao, et al., “Quantum biology revisited,” Science Adv., vol. 6, art.
eaaz4888, 2020.
[90] Y. Kim, F. Bertagna, E. M. D’Souza, D. J. Heyes, L. O. Johannissen,
and E. T. Nery, “Quantum biology: An update and perspective,” Quant.
Rep., vol. 3, pp. 1–48, 2021.
[91] A. Baiardi, M. Christandl, and M. Reiher, “Quantum computing for
molecular biology,” Preprint arxiv:2212.12220, 2022.
[92] C. Fields and M. Levin, “Metabolic limits on classical information
processing by biological cells,” BioSystems, vol. 209, art. 104513, 2021.
[93] C. M. Kerskens and D. L. P´erez, “Experimental indications of non-
classical brain functions,” J. Phys. Commun., vol. 6, art. 105001, 2022.
[94] C. Fields and A. Marcian`o, “Holographic screens are classical informa-
tion channels,” Quant. Rep., vol. 2, pp. 326–336, 2020.
[95] A. Addazi, P. Chen, F. Fabrocini, C. Fields, E. Greco, M. Lulli, A.
Marcian`o, and R. Pasechnik, “Generalized holographic principle, gauge
invariance and the emergence of gravity `a la Wilczek,” Front. Astron.
Space Sci., vol. 8, art. 563450, 2021.
[96] C. Fields, J. F. Glazebrook, and A. Marcian`o, “The physical meaning
of the holographic principle,” Quanta, vol. 11, pp. 72–96, 2022.
[97] F. Pastawski, B. Yoshida, D. Harlow, and J. Preskill, “Holographic
quantum error-correcting codes: Toy models for the bulk/boundary cor-
respondence,” J. High Energy Phys., vol. 6, art. 149, 2015.
[98] C. Fields, J. F. Glazebrook, and A. Marcian`o, “Communication protocols
and quantum error-correcting codes from the perspective of topological
quantum ﬁeld theory.” Preprint arxiv:2303.16461 [hep-th].
[99] R. Landauer, “Information is a physical entity,” Physica A, vol. 263, pp.
63–67, 1999.
[100] C. H. Bennett, “The thermodynamics of computation,” Int. J. Theor.
Phys., vol. 21, pp. 905–940, 1982.
[101] U. Seifert, “Stochastic thermodynamics, ﬂuctuation theorems and
molecular machines,” Rep. Prog. Phys., vol. 75, art. 126001, 2012.
[102] M. Atiyah, “Topological quantum ﬁeld theory,” Pub. Math. IH `ES, vol.
68, pp. 175–186, 1988.
[103] E. Chitambar, D. Leung, L. Manˇcinska, M. Ozols, and A. Winter,
“Everything you always wanted to know about LOCC (but were afraid
to ask),” Comms. Math. Phys., vol. 328, pp. 303–326, 2014.
[104] F. Tipler, “Quantum nonlocality does not exist,” Proc. Natl. Acad. Sci.
USA, vol. 111, pp. 11281–11286, 2014.
[105] J. S. Bell, “On the problem of hidden variables in quantum mechanics,”
Rev. Mod. Phys., vol. 38, pp. 447–452, 1966.
[106] S. Kochen and E. P Specker, “The problem of hidden variables in
quantum mechanics,” J. Math. Mech., vol. 17, pp. 59–87, 1967.
[107] N. D. Mermin, “Hidden variables and the two theorems of John Bell,”
Rev. Mod. Phys., vol. 65, pp. 803–815, 1993.
This article has been accepted for publication in IEEE Transactions on Molecular, Biological, and Multi-Scale Communications . This is the author's version which has not been fully edited a
content may change prior to final publication. Citation information: DOI 10.1109/TMBMC.2023.3272150
© 2023 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See https://www.ieee.org/publications/rights/index.html for more information.
Authorized licensed use limited to: University College London. Downloaded on June 12,2023 at 15:16:58 UTC from IEEE Xplore.  Restrictions apply. 

FIELDS ET AL, CONTROL FLOW IN ACTIVE INFERENCE SYSTEMS, PART I
11
IV. BIOGRAPHY SECTION
Chris Fields (ﬁeldsres@gmail.com) is an information theorist. He has worked
in AI applications, neuromorphic computing, and the bioinformatics. He
currently focuses on the interface between quantum information, computing,
and the life sciences.
Filippo Fabrocini is Professor in the College of Design & Innovation at
Tongji University, Director of the Tongji Sustainable AI Lab, and among the
founders of the Tongji AI Art Lab. Filippo Fabrocini is also afﬁliated with
the Italy National Research Council (Institute for Computing Applications).
His main areas of interest are Machine Learning, Quantum Neural Networks,
Ethical AI, and AI Art.
Karl Friston (k.friston@ucl.ac.uk) is a theoretical neuroscientist and authority
on brain imaging. He invented statistical parametric mapping, voxel-based
morphometry, and dynamic causal modelling. He is the architect of the free
energy principle and active inference. He was elected a fellow of the Royal
Society in 2006 and received the Weldon Memorial Prize and Medal in 2013.
James F. Glazebrook (jfglazebrook@eiu.edu) is Professor Emeritus of
Eastern Illinois University, and member of the Adjunct Faculty (Mathematics)
of the University of Illinois at Urbana-Champaign, USA. Current research
interests include mathematical methods in the cognitive sciences involving
scale-free architectures, information theory from the categorical perspective
as applied to contextuality and active inference. Pastimes include music,
literature, theatre, and travelling.
Hananel Hazan (Hananel.Hazan@tufts.edu) is a research scientist at the
Allen Discovery Center at Tufts University, where he focuses on biologically-
inspired computing and neurocomputation. With a strong background in
machine learning and an interdisciplinary approach to his research, Dr. Hazan
explores the computational properties of both neuronal and non-neuronal
systems to advance our understanding of biological systems and improve ma-
chine learning algorithms. His research interests include biologically-inspired
computing, neuronal and non-neuronal computation, emergent behavior from
complex systems, and noisy reinforcement learning.
Michael Levin (michael.levin@tufts.edu) is Distinguished Professor and
Vannevar Bush Chair at the Department of Biology at Tufts University,
director of the Allen Discovery Center at Tufts, and an Associate Faculty
at the Wyss Institute for Biologically Inspired Engineering at Harvard. His
lab works at the intersection of developmental biology, computer science, and
behavioral science to understand cognition in diverse evolved, designed, and
hybrid complex systems.
Antonino Marcian`o is currently tenured professor of physics at Fudan
University and member of the Italian Institute of Nuclear Physics (INFN). He
currently focuses on a variety of topics in theoretical physics, ranging mainly
from quantum ﬁeld theories and theories of gravity, to their neighboring
research areas as well as analogous applications to solid state physics, artiﬁcial
intelligence and quantum computation.
This article has been accepted for publication in IEEE Transactions on Molecular, Biological, and Multi-Scale Communications . This is the author's version which has not been fully edited a
content may change prior to final publication. Citation information: DOI 10.1109/TMBMC.2023.3272150
© 2023 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See https://www.ieee.org/publications/rights/index.html for more information.
Authorized licensed use limited to: University College London. Downloaded on June 12,2023 at 15:16:58 UTC from IEEE Xplore.  Restrictions apply. 

