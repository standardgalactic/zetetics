Lecture Notes in Networks and Systems 672
V. Suma
Pascal Lorenz
Zubair Baig   Editors
Inventive 
Systems 
and Control
Proceedings of ICISC 2023

Lecture Notes in Networks and Systems
Volume 672
Series Editor
Janusz Kacprzyk, Systems Research Institute, Polish Academy of Sciences,
Warsaw, Poland
Advisory Editors
Fernando Gomide, Department of Computer Engineering and Automation—DCA,
School of Electrical and Computer Engineering—FEEC, University of
Campinas—UNICAMP, São Paulo, Brazil
Okyay Kaynak, Department of Electrical and Electronic Engineering,
Bogazici University, Istanbul, Türkiye
Derong Liu, Department of Electrical and Computer Engineering, University of
Illinois at Chicago, Chicago, USA
Institute of Automation, Chinese Academy of Sciences, Beijing, China
Witold Pedrycz, Department of Electrical and Computer Engineering, University of
Alberta, Alberta, Canada
Systems Research Institute, Polish Academy of Sciences, Warsaw, Poland
Marios M. Polycarpou, Department of Electrical and Computer Engineering,
KIOS Research Center for Intelligent Systems and Networks, University of Cyprus,
Nicosia, Cyprus
Imre J. Rudas, Óbuda University, Budapest, Hungary
Jun Wang, Department of Computer Science, City University of Hong Kong,
Kowloon, Hong Kong

The series “Lecture Notes in Networks and Systems” publishes the latest
developments in Networks and Systems—quickly, informally and with high quality.
Original research reported in proceedings and post-proceedings represents the core
of LNNS.
Volumes published in LNNS embrace all aspects and subﬁelds of, as well as new
challenges in, Networks and Systems.
The series contains proceedings and edited volumes in systems and networks,
spanning the areas of Cyber-Physical Systems, Autonomous Systems, Sensor
Networks, Control Systems, Energy Systems, Automotive Systems, Biological
Systems, Vehicular Networking and Connected Vehicles, Aerospace Systems,
Automation, Manufacturing, Smart Grids, Nonlinear Systems, Power Systems,
Robotics, Social Systems, Economic Systems and other. Of particular value to
both the contributors and the readership are the short publication timeframe and
the world-wide distribution and exposure which enable both a wide and rapid
dissemination of research output.
The series covers the theory, applications, and perspectives on the state of the art
and future developments relevant to systems and networks, decision making, control,
complex processes and related areas, as embedded in the ﬁelds of interdisciplinary
and applied sciences, engineering, computer science, physics, economics, social, and
life sciences, as well as the paradigms and methodologies behind them.
Indexed by SCOPUS, INSPEC, WTI Frankfurt eG, zbMATH, SCImago.
All books published in the series are submitted for consideration in Web of Science.
For proposals from Asia please contact Aninda Bose (aninda.bose@springer.com).

V. Suma · Pascal Lorenz · Zubair Baig
Editors
Inventive Systems
and Control
Proceedings of ICISC 2023

Editors
V. Suma
Department of Computer Science
and Design
Dayananda Sagar College of Engineering
Bengaluru, India
Zubair Baig
School of Information Technology
Deakin University
Geelong, VIC, Australia
Pascal Lorenz
Université de Haute-Alsace
Mulhouse, France
ISSN 2367-3370
ISSN 2367-3389 (electronic)
Lecture Notes in Networks and Systems
ISBN 978-981-99-1623-8
ISBN 978-981-99-1624-5 (eBook)
https://doi.org/10.1007/978-981-99-1624-5
© The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature
Singapore Pte Ltd. 2023
This work is subject to copyright. All rights are solely and exclusively licensed by the Publisher, whether
the whole or part of the material is concerned, speciﬁcally the rights of translation, reprinting, reuse
of illustrations, recitation, broadcasting, reproduction on microﬁlms or in any other physical way, and
transmission or information storage and retrieval, electronic adaptation, computer software, or by similar
or dissimilar methodology now known or hereafter developed.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this publication
does not imply, even in the absence of a speciﬁc statement, that such names are exempt from the relevant
protective laws and regulations and therefore free for general use.
The publisher, the authors, and the editors are safe to assume that the advice and information in this book
are believed to be true and accurate at the date of publication. Neither the publisher nor the authors or
the editors give a warranty, expressed or implied, with respect to the material contained herein or for any
errors or omissions that may have been made. The publisher remains neutral with regard to jurisdictional
claims in published maps and institutional afﬁliations.
This Springer imprint is published by the registered company Springer Nature Singapore Pte Ltd.
The registered company address is: 152 Beach Road, #21-01/04 Gateway East, Singapore 189721,
Singapore

We are privileged to dedicate the proceedings
of ICISC 2023 to all the participants and
editors of ICISC 2023.

Preface
We are pleased to introduce you to the proceedings of the 7th International Confer-
ence on Inventive Systems and Control [ICISC 2023], successfully held on January
30–31, 2023. ICISC 2023 has gathered the research experts, scholars, and indus-
trialists across the globe to disseminate and explore the recent advanced research
works carried out in the ﬁeld of intelligent systems and their control to establish an
innovative academic exchange among computing and communication researchers.
The geographically distributed ICISC 2023 committee consists of various experts,
reviewers, and authors, hailing from the areas of computing, communication, and
controlfromdifferentpartsoftheworld.Withitsprofessionalandsigniﬁcantresearch
inﬂuence, ICISC is honored to invite three renowned research experts as keynote
speakers.Wearegladthatoutof323submissions,65submissionsofveryhighquality
were selected. The selected submissions were further compiled into proceedings after
rigorous reviewing each manuscript. Moreover, the committee always ensured every
paper has gone through the peer-review process to meet the international research
publication standard.
We wish to extend our gratitude to the organizing committee members, distin-
guished keynote speakers, internal/external reviewers, and all the authors for their
continued support toward the conference. We would also be very thankful to the
Springer publications for publishing these proceedings. The readers will be highly
beneﬁtted by gaining state-of-the-art research knowledge from the ICISC 2023
proceedings. We also expect the same overwhelming response from scholars and
vii

viii
Preface
experts across the globe to join the international conference, which will be organized
in the upcoming years.
Dr. V. Suma
Vice Principal and Professor and Head
Department of Computer Science
and Design
Dayananda Sagar College
of Engineering
Bengaluru, India
Dr. Pascal Lorenz
Professor, Université de Haute-Alsace
Mulhouse, France
Dr. Zubair Baig
School of Information Technology
Deakin University
Geelong, VIC, Australia

Contents
Optimal Placement of Phasor Measurement Units Considering
Channel Limits Under Various Contingencies . . . . . . . . . . . . . . . . . . . . . . . .
1
K. Banumalar, B. V. Manikandan, and S. Muralidharan
Adaptive Deep Recurrent Neural Network-Based COVID-19
Healthcare Data Prediction for Early Risk Prediction . . . . . . . . . . . . . . . . .
25
A. Asha, B. Dhiyanesh, G. Kiruthiga, L. Shakkeera, Y. Sharmasth Vali,
and K. Karthick
Maximum Decision Support Regression-Based Advance Secure
Data Encrypt Transmission for Healthcare Data Sharing
in the Cloud Computing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
39
V. Anusuya, B. J. Bejoy, M. Ramkumar, P. Shanmugaraja,
B. Dhiyanesh, and G. Kiruthiga
Routing Integrity Mechanism to Prevent Wormhole Attacks
in Vehicular Adhoc Networks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
53
R. Prathap Kumar, U. Srilakshmi, and K. Ganesh Reddy
A Detailed Analysis on Spam Emails and Detection Using Machine
Learning Algorithms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
65
Razia Sulthana, Avani Verma, and A. K. Jaithunbi
Advanced Encryption Standard-Based Encryption for Secured
Transmission of Data in Cognitive Radio with Multi-channels . . . . . . . . .
77
Kiran P. More and Rajendrakumar A. Patil
Multi Energy-Harvesting Smart Water Meter Design
for Underground Water Pipeline Leakage Detection . . . . . . . . . . . . . . . . . .
95
Hari Prakash Athinarayanan and Muthupavithran Selvam
Tensor Flow Model with Hybrid Optimization Algorithm
for Solving Vehicle Routing Problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
113
Jai Keerthy Chowlur Revanna and Nushwan Yousif B. Al-Nakash
ix

x
Contents
Authentication Key Generator for Data Sharing on
Cloud—A Review . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
129
B. V. Santhosh Krishna, B. Rajalakshmi,
Esikala Nithish Mani krishna, Gundre Sai sruthi,
Gangireddy Ramya sri, and K. Ashok
Restaurant Quality Analysis: A Machine Learning Approach . . . . . . . . . .
143
Rohit B. Diwane, Kavita S. Oza, and Varsha P. Desai
Towards the Implementation of Trafﬁc Engineering in SDN:
A Practical Approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
155
U. Prabu and V. Geetha
Real-Time Intrusion Detection in Connected Autonomous Vehicles . . . . .
163
Anjanee Kumar and Tanmoy Kanti Das
Physical Architecture of Linear Feedback Shift Register Using
Clock Tree Synthesis for Cyber-Physical System . . . . . . . . . . . . . . . . . . . . . .
177
B. Muthu Nisha, V. Nithya, and J. Selvakumar
Detection of Arrhythmia via Electrical Activity of the Heart Using
AI Techniques . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
189
J. Pramitha and X. Anitha Mary
Utilizing Deep Convolutional Neural Networks for Image-Based
Plant Disease Detection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
201
Saha Reno, Marzia Khan Turna, Sheikh Tasﬁa, Md. Abir,
and Anusha Aziz
Detection of Covid-19 Using an Infrared Fever Screening System
(IFSS) Based on Deep Learning Technology . . . . . . . . . . . . . . . . . . . . . . . . . .
217
V. Muthu and S. Kavitha
Improving the Power Quality of Wind Turbines Under Unbalance
Voltage Conditions Using the SMC Approach . . . . . . . . . . . . . . . . . . . . . . . .
229
B. Hariprasad, G. Sreenivasan, D. Mahesh Kumar,
and T. Lakshmi Swapna
NAML—A Novel Approach of Machine Learning Implementation
in the Hospitality Industry . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
243
C. S. Ashwin, Sheela Thavasi, and K. R. Rangarajan
A Novel Dynamic Energy Amendment Control for Solar Fed
Brushless DC Motor for Water Pumping System . . . . . . . . . . . . . . . . . . . . .
253
U. Arun Kumar, K. S. Chandraguptamauryan, K. Chandru,
and W. Rajan Babu

Contents
xi
A Hybrid Model Built on VGG16 and Random Forest Algorithm
for Land Classiﬁcation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
267
Mohammed Junaid Ahmed, Ashutosh Satapathy, Ch. Raga Madhuri,
K. Yashwanth Chowdary, and A. Naveen Sai
Facial Expression Recognition Using Transfer Learning with
ResNet50 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
281
Shantala S. Hiremath, Jayaprada Hiremath, Vaishnavi V. Kulkarni,
B. C. Harshit, Sujith Kumar, and Mrutyunjaya S. Hiremath
Classiﬁcation of Microorganisms from Sparsely Limited Data
Using a Proposed Deep Learning Ensemble . . . . . . . . . . . . . . . . . . . . . . . . . .
301
Gautam Chettiar, Amogh Shukla, Hemprasad Patil, and Sumit Jindal
Assiduous Study of the Hyperparameters’ Inﬂuence on CNN
Using COVID-19 CT Images . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
315
Srinivasa L. Chakravarthy, Varun Mallela, Vedula Sai Sarvanth,
Rohith Sunkara, and Srimurari Dachepalli
Academic Dishonesty Detection in Exams Using Pose Extraction . . . . . . .
329
Dhanush Binu and Sivaiah Bellamkonda
Dynamic Wireless Charging System for Electric Vehicles Based
on Segmented Zinc Alloy Plates . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
339
Anurag A. Gadgil, Arya Bairoliya, J. L. Febin Daya, and P. Balamurugan
Iterative Reﬁnement Versus Generative Adversarial Networks
for Super-Resolution Towards Licence Plate Detection . . . . . . . . . . . . . . . .
349
Alden Boby, Dane Brown, and James Connan
An IoT-Based Smart Health Monitoring System . . . . . . . . . . . . . . . . . . . . . .
363
R. Lakshmi, M. Mridula, G. Sri Gayathri, and V. Srividhyasakthi
Multi-Stage Fruit Grading System . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
377
S. Anjali, Vinny Pious, Joel J. Sebastian, J. Krishnanunni,
Joveal K. Johnson, and Ashik Mujeeb
Sentiment Analysis on Feedback Data of E-commerce Products
Based on NLP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
387
K. Sumathi and Kundhavai Santharam
Univariate Individual Household Energy Forecasting by Tuned
Long Short-Term Memory Network . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
403
Marko Stankovic, Luka Jovanovic, Milos Antonijevic,
Aleksandra Bozovic, Nebojsa Bacanin, and Miodrag Zivkovic
Interpreting Doctor’s Handwritten Prescription Using Deep
Learning Techniques . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
419
Rizwanullah Mohammad, Ajay Kumar Varma Nagaraju,
and Suneetha Manne

xii
Contents
Abductive Inference of Conclusions with Check of Additional
Premises Literals Correctness Interpretation . . . . . . . . . . . . . . . . . . . . . . . . .
431
Vasily Meltsov, Dmitry Strabykin, and Alexander Krutikov
An Investigation and Observational Remarks on Conventional
Sign Language Recognition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
445
Thouseef Ulla Khan and M. R. Dileep
Exploratory Project of Digital Twin Technology in Cyber-Physical
Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
461
Irony Nunes de Oliveira, Hanameel Carlos Vieira Gomes,
Kelipys da Silva Firmino, Antonio Eduardo Carrilho da Cunha,
and Cícero Roberto Garcez
Abstractive Text Summarization for Tamil Language Using m-T5 . . . . . .
479
C. Saraswathi, V. Prinitha, and J. Briskilal
Sentiment Component Extraction from Dependency Parse for Hindi . . .
495
Remya Panicker, Ramchandra Bhavsar, and B. V. Pawar
Change Detection Algorithm for Vegetation Mapping Using
Multispectral Image Processing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
511
Neelam B. V. D. Soujitha, Mohammad Neelofar Jaha,
Mahali Tirumala Raju, Kakumanu Christy Victor, and Radhesyam Vaddi
Real-Time Sign Language Detection Using OpenCV . . . . . . . . . . . . . . . . . .
523
Pavan Kumar Meka, Yesu Raju Parusu, and Radhesyam Vaddi
Efﬁcient Plant Disease Detection and Classiﬁcation for Android . . . . . . .
535
Dane Brown and Siﬁsokuhle Mazibuko
Resume Analysis Using NLP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
551
Rakhi Bharadwaj, Divya Mahajan, Meenal Bharsakle,
Kashish Meshram, and Himaja Pujari
The Adoption of Artiﬁcial Intelligence Technology in Parking
Security System . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
563
Muhammad Rifqi Alhaﬁzh, Albertus Baskara Yunandito Adriawan,
Darryl Fernaldy, Ford Lumban Gaol, and Tokuro Matsuo
A Self-organizing Map with Neural Networks Classiﬁer Technique
for Face and Handwritten Signature Recognition System in DIP . . . . . . .
575
V. Karthi, S. Nithyasai, P. Parthasarathy, and U. Arun Kumar
CISUM: Novel Research on Cloud Computing Simulators
and Future Scope for Computational Research . . . . . . . . . . . . . . . . . . . . . . .
589
C. S. Ashwin, V. K. G. Kalaiselvi, and K. R. Rangarajan
Arabic Sentiment Analysis of YouTube Comments Using Deep
Learning Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
599
Mohammed Alkoli and B. Sharada

Contents
xiii
Learning Movement Patterns for Improving the Skills of Beginner
Level Players in Competitive MOBAs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
613
Dane Brown and Jonah Bischof
An Effective Multi-exposure Fusion Approach Using Exposure
Correction and Recursive Filter . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
625
C. R. Jishnu and S. Vishnukumar
Social Media as the Most Effective Means of Business Promotion
Today with Using Social Media Advertising Technology . . . . . . . . . . . . . . .
639
Aldo Saputra, Ingwen Tannaris, Kelby Hubert, Ford Lumban Gaol,
and Tokuro Matsuo
Text-to-Speech and Speech-to-Text Converter—Voice Assistant . . . . . . . .
653
Sagar Janokar, Soham Ratnaparkhi, Manas Rathi, and Alkesh Rathod
CNN Combined with FC Classiﬁer to Combat Artiﬁcial
Penta-Digit Text-Based Captcha . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
665
S. Abhishek, S. Sanjana, Mahima Chowdary Mannava, and T. Anjali
Basil Leaf Disease Detection and Classiﬁcation Using Customized
Convolutional Neural Network
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
677
Deepak Mane, Sunil Sangve, Shaila Jadhav, Disha Patil, Rohan Kakde,
and Varad Marudwar
Segmentation of Brain Tumours from MRI Images Using CNN . . . . . . . .
693
Dhakshina Ilango and Razia Sulthana
Distributed Training of Large-Scale Deep Learning Models
in Commodity Hardware . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
707
Jubaer Ahmad, Tahsin Elahi Navin, Fahim Al Awsaf,
Md. Yasir Arafat, Md. Shahadat Hossain, and Md. Motaharul Islam
Blockchain-Driven Cloud Service: A Survey . . . . . . . . . . . . . . . . . . . . . . . . .
723
Hamed Taherdoost
Interaction Analysis of a Multivariable Process in a Manufacturing
industry—A Review . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
729
P. K. Juneja, T. Anand, P. Saini, Rajeev Gupta, F. S. Gill, and S. Sunori
Machine Learning Approaches for Educational Data Mining . . . . . . . . . .
737
Mahesh Bapusaheb Toradmal, Mita Mehta, and Smita Mehendale
Trafﬁc Surveillance and Vehicle Detection YOLO
and MobileNet-Based ML Pipeline Transfer Learning . . . . . . . . . . . . . . . .
749
Rakhi Bharadwaj, Aditya Thombre, Umesh Patekar, Yash Gaikwad,
and Sushil Suri

xiv
Contents
Perceptors: A Real Time Object Detection System with Voice
Feedback and Distance Approximation for Blind . . . . . . . . . . . . . . . . . . . . .
763
Rakhi Bharadwaj, Harshal Sonawane, Manasi Patil, Shashank Patil,
and Vedant Jadhav
Automated Histogram Binning-Based Fuzzy K-Means Clustering
for COVID-19 Chest CT Image Segmentation . . . . . . . . . . . . . . . . . . . . . . . .
777
S. Nivetha and H. Hannah Inbarani
Darknet Trafﬁc Detection Using Histogram-Based Gradient
Boosting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
795
Dane Brown and Chikondi Sepula
Investing in Products with the Greatest Demand on Online Stores
During the Pandemic . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
809
Titan Hassya, Muhammad Fauzi Hanif, Alvian, Ford Lumban Gaol,
and Tokuro Matsuo
Estimation of Queuing System Incoming Flow Intensity . . . . . . . . . . . . . . .
817
Alexander Zyulkov, Yury Kutoyants, Svyatoslav Perelevsky,
and Larisa Korableva
Statistical Characteristics of the Adjacent Information Signals
Amplitude Ratio . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
825
Oleg Chernoyarov, Alexey Glushkov, Vladimir Litvinenko,
Alexandra Salnikova, and Kaung Myat San
Predicting Severity Levels of Parkinson’s Disease
from Telemonitoring Voice Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
839
Aryan Vats, Aryan Blouria, and R. Sasikala
Attendance Management System Using Face Recognition . . . . . . . . . . . . .
855
I. G. Vishnu Vardhan, M. Ajay Kumar, P. Nithin Kalyan, V. Spandana,
and J. Ebenezer
Diabetes Classiﬁcation Using ML Algorithms . . . . . . . . . . . . . . . . . . . . . . . .
867
G. G. Rajput and Ashvini Alashetty
Author Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
879

Editors and Contributors
About the Editors
V. Suma has obtained her B.E., M.S., and Ph.D. in Computer Science and Engi-
neering. She in addition being Professor in Information Science and Engineering is
also holding a position of Dean in Research and Industry Incubation Centre. She is
also associated with leading software industries such as Wipro and was associated
to Infosys and Exilant Technologies for training their software developers toward
development of customer-satisﬁed products. She is further Consultant and Research
Advisor at National Foundation for Entrepreneurship Development (NFED) which
is an NGO whose objective is to uplift women and downtrodden community. She
was associated with Hochschule Hof University, Germany, as a mentor for foreign
exchange programs since 2007. She was Single Point of Contact for Infosys Campus
Connect program from February 2011 to June 2016. She was also a recognized
mentor in ACM MentorNet where she was mentoring an international student from
Sate Mississippi University for the doctoral degree. She has guided several doctoral
students from universities such as VTU, JNTU, Bharathiar, and Jain and in the panel
of Ph.D. examiners in universities such as Jain, Anna, JNTU, University of Madras,
University of North Maharashtra, University of Botswana, University of Johannes-
burg, Dr. M. G. R. University, Periyar University, Karpagam University, and so on.
She has successfully guided 11 Ph.D. scholars from various universities till now,
and many are in the pipeline. She is responsible for several MOU’s for DSCE with
industries such as Aero IT, QSIT, Envids Technologies LLP, and Avam Consulting
and with other universities.
Pascal Lorenz received his M.Sc. (1990) and Ph.D. (1994) from the University of
Nancy, France. Between 1990 and 1995, he was a research engineer at WorldFIP
Europe and at Alcatel-Alsthom. He is Professor at the University of Haute-Alsace,
France, since 1995. His research interests include QoS, wireless networks, and
high-speed networks. He is the author/co-author of three books, three patents, and
xv

xvi
Editors and Contributors
200 international publications in refereed journals and conferences. He was Tech-
nical Editor of the IEEE Communications Magazine Editorial Board (2000–2006),
IEEE Networks Magazine since 2015, IEEE Transactions on Vehicular Technology
since 2017, Chair of IEEE ComSoc France (2014–2020), Financial chair of IEEE
France (2017–2022), Chair of Vertical Issues in Communication Systems Technical
Committee Cluster (2008–2009), Chair of the Communications Systems Integra-
tion and Modeling Technical Committee (2003–2009), Chair of the Communi-
cations Software Technical Committee (2008–2010), and Chair of the Technical
Committee on Information Infrastructure and Networking (2016–2017). He has
served as Co-program Chair of IEEE WCNC’2012 and ICC’2004, Executive Vice
Chair of ICC’2017, TPC Vice Chair of Globecom’2018, Panel session’s Co-chair for
Globecom’16, Tutorial Chair of VTC’2013 Spring and WCNC’2010, Track Chair
of PIMRC’2012 and WCNC’2014, and Symposium Co-chair at Globecom 2007–
2011, Globecom’2019, ICC 2008–2010, ICC’2014, and ’2016. He has served as
Co-guest Editor for special issues of IEEE Communications Magazine, Networks
Magazine, Wireless Communications Magazine, Telecommunications Systems, and
LNCS. He is Associate Editor for International Journal of Communication Systems
(IJCS-Wiley), Journal on Security and Communication Networks (SCN-Wiley), and
International Journal of Business Data Communications and Networking, Journal
of Network and Computer Applications (JNCA-Elsevier). He is Senior Member of
the IEEE, IARIA Fellow, and Member of many international program committees.
He has organized many conferences, chaired several technical sessions, and gave
tutorials at major international conferences. He was IEEE ComSoc Distinguished
Lecturer Tour during 2013–2014.
Zubair Baig is currently Senior Lecturer in Cyber Security with the School of
Information Technology, Deakin University, Geelong, VIC, Australia. He is also
Co-director of the Security and Privacy in IoT (SPYRiT) Research Lab and Division
Lead, IoT, Critical Infrastructure and CPS Security, and Centre for Cyber Secu-
rity Research and Innovation (CSRI). He has authored/co-authored over 85 journal
and conference papers and book chapters. His research interests are in the areas
of cyber-security, the IoT, artiﬁcial intelligence, and optimization algorithms. He is
serving as Editor for the IET Wireless Sensor Systems Journal and PSU—A Review—
Journal. He has served on numerous technical program committees of international
conferences and has delivered more than 15 keynote talks on cyber-security.
Contributors
S. Abhishek Department of Computer Science and Engineering, Amrita School of
Computing, Amrita Vishwa Vidyapeetham, Amritapuri, India
Md. Abir University of Erlangen Nuremberg, Erlangen and Nuremberg, Bavaria,
Germany

Editors and Contributors
xvii
Albertus Baskara Yunandito Adriawan Computer Science Department, BINUS
Graduate Program—Doctor of Computer Science, Bina Nusantara University,
Jakarta, Indonesia
Jubaer Ahmad Department of Computer Science and Engineering, United Inter-
national University, Dhaka, Bangladesh
Mohammed Junaid Ahmed Velagapudi Ramakrishna Siddhartha Engineering
College, Vijayawada, India
M. Ajay Kumar Velagapudi
Ramakrishna
Siddhartha
Engineering
College,
Vijayawada, Andhra Pradesh, India
Fahim Al Awsaf Department of Computer Science and Engineering, United Inter-
national University, Dhaka, Bangladesh
Nushwan Yousif B. Al-Nakash Information Systems Engineering and Manage-
ment, Harrisburg University of Science and Technology, Harrisburg, PA, USA
Ashvini Alashetty Department of Computer Science, Karnataka State Akkama-
hadevi Women’s University, Vijayapura, Karnataka, India
Muhammad Rifqi Alhaﬁzh Information Systems Department, School of Informa-
tion Systems, Bina Nusantara University, Jakarta, Indonesia
Mohammed Alkoli Department of Studies in Computer Science, University of
Mysore, Mysuru, Karnataka, India
Alvian Information Systems Department, School of Information Systems, Bina
Nusantara University, Jakarta, Indonesia
T. Anand Department of PDP, Graphic Era Deemed to be University, Dehradun,
Uttarakhand, India
X. Anitha Mary Department of Robotics Engineering, Karunya Institute of Tech-
nology and Sciences, Coimbatore, India
S. Anjali Mar Baselios College of Engineering and Technology, Thiruvanantha-
puram, Kerala, India
T. Anjali Department of Computer Science and Engineering, Amrita School of
Computing, Amrita Vishwa Vidyapeetham, Amritapuri, India
Milos Antonijevic Singidunum University, Belgrade, Serbia
V. Anusuya Associate
Professor/CSE,
Ramco
Institute
of
Technology,
Rajapalayam, India
Md. Yasir Arafat Department of Computer Science and Engineering, United
International University, Dhaka, Bangladesh

xviii
Editors and Contributors
U. Arun Kumar Department of Electrical and Electronics Engineering, SRM Insti-
tute of Science and Technology, Ramapuram Campus, Chennai, Tamil Nadu,
India
A. Asha Professor/ECE, Rajalakshmi Engineering College, Chennai, India
K. Ashok New Horizon College of Engineering, Bengaluru, Karnataka, India
C. S. Ashwin Information Systems, Sri Sai Ram Engineering College, Chennai,
Tamil Nadu, India
Hari Prakash Athinarayanan Newcastle University, Newcastle upon Tyne, UK
Anusha Aziz Bangladesh
University
of
Business
and
Technology,
Dhaka,
Bangladesh
Nebojsa Bacanin Singidunum University, Belgrade, Serbia
Arya Bairoliya VIT Bhopal University, Bhopal, India
P. Balamurugan Vellore Institute of Technology, Chennai, India
K. Banumalar Department of Electrical and Electronics Engineering, Mepco
Schlenk Engineering College, Sivakasi, Tamil Nadu, India
B. J. Bejoy Assistant Professor/CSE, CHRIST (Deemed to Be University), Banga-
lore, India
Sivaiah Bellamkonda Department of Computer Science and Engineering, Indian
Institute of Information Technology Kottayam, Kottayam, Kerala, India
Rakhi Bharadwaj Department of Computer Science, Vishwakarma Institute of
Technology, Pune, India;
Department of Computer Engineering, Vishwakarma Institute of Technology, Pune,
India
Meenal Bharsakle Vishwakarma Institute of Technology, Pune, India
Ramchandra Bhavsar School of Computer Sciences, KBC North Maharashtra
University, Jalgaon, Maharashtra, India
Dhanush Binu Department of Computer Science and Engineering, Indian Institute
of Information Technology Kottayam, Kottayam, Kerala, India
Jonah Bischof Rhodes University, Grahamstown, South Africa
Aryan Blouria Vellore Institute of Technology, Vellore, Tamil Nadu, India
Alden Boby Department of Computer Science, Rhodes University, Grahamstown,
South Africa
Aleksandra Bozovic Academy of Applied Technical Studies, Belgrade, Serbia
J. Briskilal Department of Computing Technologies, SRM Institute of Science and
Technology, Kattankulathur, Chengalpattu, Tamil Nadu, India

Editors and Contributors
xix
Dane Brown Department of Computer Science, Rhodes University, Grahamstown,
South Africa
Srinivasa L. Chakravarthy Department of CSE, GITAM University, Visakhap-
atnam, India
K. S. Chandraguptamauryan Department of Electrical and Electronics Engi-
neering, Guru Nanak Institutions Technical Campus, Hyderabad, India
K. Chandru Department of Electrical and Electronics Engineering, EASA College
of Engineering and Technology, Coimbatore, Tamil Nadu, India
Oleg Chernoyarov National Research University “MPEI”, Moscow, Russia
Gautam Chettiar Department of Communication Engineering, Vellore Institute of
Technology, Vellore, Tamil Nadu, India
Jai Keerthy Chowlur Revanna Information Systems Engineering and Manage-
ment, Harrisburg University of Science and Technology, Harrisburg, PA, USA
James Connan Department of Computer Science, Rhodes University, Graham-
stown, South Africa
Antonio Eduardo Carrilho da Cunha Laboratório de Segurança Cibernética de
Sistemas Ciberfísicos, Instituto Militar de Engenharia, Rio de Janeiro (RJ), Brazil
Kelipys da Silva Firmino Laboratório de Segurança Cibernética de Sistemas
Ciberfísicos, Instituto Militar de Engenharia, Rio de Janeiro (RJ), Brazil
Srimurari Dachepalli Department of CSE, GITAM University, Visakhapatnam,
India
Tanmoy Kanti Das Department of Computer Applications, National Institute of
Technology Raipur, Raipur, Chhatisgarh, India
Irony Nunes de Oliveira Laboratório de Segurança Cibernética de Sistemas Ciber-
físicos, Instituto Militar de Engenharia, Rio de Janeiro (RJ), Brazil
Varsha P. Desai Computer Science & Engineering Department, D. Y. Patil Agri-
culture and Technical University, Talsande, Kolhapur, Maharashtra, India
B. Dhiyanesh Associate Professor/CSE, Dr. N.G.P. Institute of Technology, Coim-
batore, India
M. R. Dileep Department of Master of Computer Applications, Nitte Meenakshi
Institute of Technology, Yelahanka, Bengaluru, Karnataka, India
Rohit B. Diwane Department of Computer Science, Shivaji University, Kolhapur,
Maharashtra, India
J. Ebenezer Velagapudi
Ramakrishna
Siddhartha
Engineering
College,
Vijayawada, Andhra Pradesh, India
J. L. Febin Daya Vellore Institute of Technology, Chennai, India

xx
Editors and Contributors
Darryl Fernaldy Information
Systems
Department,
School
of
Information
Systems, Bina Nusantara University, Jakarta, Indonesia
Anurag A. Gadgil VIT Bhopal University, Bhopal, India
Yash Gaikwad Department of Computer Science, Vishwakarma Institute of Tech-
nology, Pune, India
K. Ganesh Reddy VIT-AP Universtiy, Amaravati, Andhra Pradesh, India
Ford Lumban Gaol Computer Science Department, BINUS Graduate Program—
Doctor of Computer Science, Bina Nusantara University, Jakarta, Indonesia;
Information Systems Department, School of Information Systems, Bina Nusantara
University, Jakarta, Indonesia
Cícero Roberto Garcez Laboratório de Segurança Cibernética de Sistemas Ciber-
físicos, Instituto Militar de Engenharia, Rio de Janeiro (RJ), Brazil
V. Geetha Department of Information Technology, Pondicherry Engineering
College, Puducherry, India
F. S. Gill Department of Physics, Graphic Era Deemed to be University, Dehradun,
Uttarakhand, India
Alexey Glushkov Zhukovsky-Gagarin Air Force Academy, Voronezh, Russia
Hanameel Carlos Vieira Gomes Laboratório
de
Segurança
Cibernética
de
Sistemas Ciberfísicos, Instituto Militar de Engenharia, Rio de Janeiro (RJ), Brazil
Rajeev Gupta Department of Electronics and Communication Engineering,
Graphic Era Hill University, Dehradun, Uttarakhand, India
Muhammad Fauzi Hanif Information Systems Department, School of Informa-
tion Systems, Bina Nusantara University, Jakarta, Indonesia
H. Hannah Inbarani Department of Computer Science, Periyar University, Salem,
Tamil Nadu, India
B. Hariprasad Research scholar, Department of Electrical & Electronics Engi-
neering, JNTUA, Anantapuramu, Anathapur, A.P., India
B. C. Harshit Department of Image Processing, eMath Technology, Pvt. Ltd.,
Bangalore, Karnataka, India
Titan Hassya Information Systems Department, School of Information Systems,
Bina Nusantara University, Jakarta, Indonesia
Jayaprada Hiremath Department of Computer Science and Engineering, Visves-
varaya Technological University, Belgaum, India
Mrutyunjaya S. Hiremath Department of Image Processing, eMath Technology,
Pvt. Ltd., Bangalore, Karnataka, India

Editors and Contributors
xxi
Shantala S. Hiremath Image Processing, Sony India Software Centre, Pvt. Ltd.,
Bangalore, Karnataka, India
Md. Shahadat Hossain Department of Computer Science and Engineering, United
International University, Dhaka, Bangladesh
Kelby Hubert Information Systems Department, Nusantara University, Jakarta,
Indonesia
Dhakshina Ilango Department of Computer Science, Birla Institute of Technology
and Science, Dubai, United Arab Emirates
Md. Motaharul Islam Department of Computer Science and Engineering, United
International University, Dhaka, Bangladesh
Shaila Jadhav JSPM’s Rajarshi Shahu College of Engineering, Pune, India
Vedant Jadhav Department of Computer Engineering, Vishwakarma Institute of
Technology, Pune, India
Mohammad Neelofar Jaha Department of IT, VR Siddhartha Engineering
College, JNTU-Kakinada, Vijayawada, India
A. K. Jaithunbi Department of Computer Science, RMD Engineering College,
Kavaraipettai, Tamil Nadu, India
Sagar Janokar Department of Engineering, Sciences and Humanities (DESH),
Vishwakarma Institute of Technology, Pune, Maharashtra, India
Sumit Jindal Department of Embedded Technology, Vellore Institute of Tech-
nology, Vellore, Tamil Nadu, India
C. R. Jishnu Department of Computer Applications, Cochin University of Science
and Technology, Kochi, Kerala, India
Joveal K. Johnson Mar Baselios College of Engineering and Technology, Thiru-
vananthapuram, Kerala, India
Luka Jovanovic Singidunum University, Belgrade, Serbia
P. K. Juneja Department of Electronics and Communication Engineering, Graphic
Era Deemed to be University, Dehradun, Uttarakhand, India
Rohan Kakde JSPM’s Rajarshi Shahu College of Engineering, Pune, India
V. K. G. Kalaiselvi Associate Professor, Sri Sai Ram Engineering College,
Chennai, Tamil Nadu, India
V. Karthi Department of Electrical and Electronics Engineering, Builders Engi-
neering College, Kangeyam, Tamil Nadu, India
K. Karthick Assistant Professor/IT, Sona College of Technology, Salem, India

xxii
Editors and Contributors
S. Kavitha Department of Computing Technologies, SRM Institute of Science and
Technology, Kattankulathur, Tamil Nadu, India
Thouseef Ulla Khan Department of Master of Computer Applications, Vidya
Vikas Institute of Engineering and Technology, Mysuru, Karnataka, India;
Department of Master of Computer Applications, VTU—Research Centre, Nitte
Meenakshi Institute of Technology, Yelahanka, Bengaluru, Karnataka, India
G. Kiruthiga Associate Professor/CSE, IES College of Engineering, Thrissur,
India
Larisa Korableva Moscow State University, Moscow, Russia
J. Krishnanunni Mar Baselios College of Engineering and Technology, Thiru-
vananthapuram, Kerala, India
Alexander Krutikov Institute of Mathematics and Information Systems, Vyatka
State University, Kirov, Russia
Vaishnavi V. Kulkarni Department of CSE, Alvas Institute of Engineering and
Technology, Moodbidri, Karnataka, India
Anjanee Kumar Department of Computer Applications, National Institute of
Technology Raipur, Raipur, Chhatisgarh, India
Sujith Kumar Artiﬁcial Intelligence and Machine Learning, VVDN Technologies
Pvt. Ltd., Bangalore, Karnataka, India
Yury Kutoyants Le Mans University, Le Mans, France;
National Research University “MPEI”, Moscow, Russia;
National Research Tomsk State University, Tomsk, Russia
R. Lakshmi Department of Biomedical Engineering, Sri Ramakrishna Engineering
College, Coimbatore, India
T. Lakshmi Swapna Research scholar, Department of Electrical & Electronics
Engineering, JNTUA, Anantapuramu, Anathapur, A.P., India
Vladimir Litvinenko Voronezh State Technical University, Voronezh, Russia
Divya Mahajan Vishwakarma Institute of Technology, Pune, India
D. Mahesh Kumar Research scholar, Department of Electrical & Electronics
Engineering, JNTUA, Anantapuramu, Anathapur, A.P., India
Varun Mallela Department of CSE, GITAM University, Visakhapatnam, India
Deepak Mane Vishwakarma Institute of Technology, Pune, Maharashtra, India
Esikala Nithish Mani krishna New Horizon College of Engineering, Bengaluru,
Karnataka, India
B. V. Manikandan Department of Electrical and Electronics Engineering, Mepco
Schlenk Engineering College, Sivakasi, Tamil Nadu, India

Editors and Contributors
xxiii
Mahima Chowdary Mannava Department of Computer Science and Engineering,
Amrita School of Computing, Amrita Vishwa Vidyapeetham, Amritapuri, India
Suneetha Manne IT Department, Velagapudi Ramakrishna Siddhartha Engi-
neering College, Vijayawada, Andhra Pradesh, India
Varad Marudwar JSPM’s Rajarshi Shahu College of Engineering, Pune, India
Tokuro Matsuo Advanced Institute of Industrial Technology, Tokyo, Japan
Siﬁsokuhle Mazibuko Rhodes University, Grahamstown, South Africa
Smita Mehendale Symbiosis Institute of Management Studies, Symbiosis Interna-
tional (Deemed University), Pune, India
Mita Mehta Symbiosis Institute of Business Management - Pune, Symbiosis
International (Deemed University), Pune, India
Pavan Kumar Meka Department of IT, VR Siddhartha Engineering College,
JNTU-Kakinada, Vijayawada, India
Vasily Meltsov Department of Electronic Computers, Vyatka State University,
Kirov, Russia
Kashish Meshram Vishwakarma Institute of Technology, Pune, India
Rizwanullah Mohammad IT Department, Velagapudi Ramakrishna Siddhartha
Engineering College, Vijayawada, Andhra Pradesh, India
Kiran P. More Department of Electronics and Telecommunication Engineering,
College of Engineering Pune, Pune, India
M. Mridula Department of Biomedical Engineering, Sri Ramakrishna Engineering
College, Coimbatore, India
Ashik Mujeeb Mar Baselios College of Engineering and Technology, Thiruvanan-
thapuram, Kerala, India
S. Muralidharan Department of Electrical and Electronics Engineering, Mepco
Schlenk Engineering College, Sivakasi, Tamil Nadu, India
V. Muthu Department of Computing Technologies, SRM Institute of Science and
Technology, Kattankulathur, Tamil Nadu, India
B. Muthu Nisha Department of Electronics and Communication Engineering,
SRMIST, Kattankulathur, Tamil Nadu, India
Ajay Kumar Varma Nagaraju IT
Department,
Velagapudi
Ramakrishna
Siddhartha Engineering College, Vijayawada, Andhra Pradesh, India
A. Naveen Sai Velagapudi
Ramakrishna
Siddhartha
Engineering
College,
Vijayawada, India

xxiv
Editors and Contributors
Tahsin Elahi Navin Department of Computer Science and Engineering, United
International University, Dhaka, Bangladesh
P. Nithin Kalyan Velagapudi
Ramakrishna
Siddhartha
Engineering
College,
Vijayawada, Andhra Pradesh, India
V. Nithya Department of Electronics and Communication Engineering, SRMIST,
Kattankulathur, Tamil Nadu, India
S. Nithyasai Department of Electronics and Communication Engineering, Kathir
College of Engineering, Coimbatore, Tamil Nadu, India
S. Nivetha Department of Computer Science, Periyar University, Salem, Tamil
Nadu, India
Kavita S. Oza Department of Computer Science, Shivaji University, Kolhapur,
Maharashtra, India
Remya Panicker School of Computer Sciences, KBC North Maharashtra Univer-
sity, Jalgaon, Maharashtra, India
P. Parthasarathy Department of Electronics and Communication Engineering,
CMR Institute of Technology, Bengaluru, India
Yesu Raju Parusu Department of IT, VR Siddhartha Engineering College, JNTU-
Kakinada, Vijayawada, India
Umesh Patekar Department of Computer Science, Vishwakarma Institute of Tech-
nology, Pune, India
Disha Patil JSPM’s Rajarshi Shahu College of Engineering, Pune, India
Hemprasad Patil Department of Embedded Technology, Vellore Institute of Tech-
nology, Vellore, Tamil Nadu, India
Manasi Patil Department of Computer Engineering, Vishwakarma Institute of
Technology, Pune, India
Rajendrakumar A. Patil Department of Electronics and Telecommunication
Engineering, College of Engineering Pune, Pune, India
Shashank Patil Department of Computer Engineering, Vishwakarma Institute of
Technology, Pune, India
B. V. Pawar School of Computer Sciences, KBC North Maharashtra University,
Jalgaon, Maharashtra, India
Svyatoslav Perelevsky National Research Tomsk State University, Tomsk, Russia
Vinny Pious Mar Baselios College of Engineering and Technology, Thiruvanan-
thapuram, Kerala, India
U. Prabu Department of Computer Science and Engineering, Pondicherry Engi-
neering College, Puducherry, India

Editors and Contributors
xxv
J. Pramitha Department of Robotics Engineering, Karunya Institute of Technology
and Sciences, Coimbatore, India
R. Prathap Kumar VFSTR Deemed to be University, Guntur, Andhra Pradesh,
India
V. Prinitha Department of Computing Technologies, SRM Institute of Science and
Technology, Kattankulathur, Chengalpattu, Tamil Nadu, India
Himaja Pujari Vishwakarma Institute of Technology, Pune, India
Ch. Raga Madhuri Velagapudi Ramakrishna Siddhartha Engineering College,
Vijayawada, India
B. Rajalakshmi NewHorizonCollegeofEngineering,Bengaluru,Karnataka,India
W. Rajan Babu Department of Electrical and Electronics Engineering, Sri Eshwar
College of Engineering, Coimbatore, Tamil Nadu, India
G. G. Rajput Department of Computer Science, Karnataka State Akkamahadevi
Women’s University, Vijayapura, Karnataka, India
Mahali Tirumala Raju Department of IT, VR Siddhartha Engineering College,
JNTU-Kakinada, Vijayawada, India
M. Ramkumar Associate Professor/CSBS, Knowledge Institute of Technology,
Salem, India
Gangireddy Ramya sri New
Horizon
College
of
Engineering,
Bengaluru,
Karnataka, India
K. R. Rangarajan Information Technology, Sri Sai Ram Engineering College,
Chennai, Tamil Nadu, India
Manas Rathi Department of Engineering, Sciences and Humanities (DESH),
Vishwakarma Institute of Technology, Pune, Maharashtra, India
Alkesh Rathod Department of Engineering, Sciences and Humanities (DESH),
Vishwakarma Institute of Technology, Pune, Maharashtra, India
Soham Ratnaparkhi Department of Engineering, Sciences and Humanities
(DESH), Vishwakarma Institute of Technology, Pune, Maharashtra, India
Saha Reno Bangladesh Army International University of Science and Technology,
Cumilla, Bangladesh
Vedula Sai Sarvanth Department of CSE, GITAM University, Visakhapatnam,
India
Gundre Sai sruthi New Horizon College of Engineering, Bengaluru, Karnataka,
India
P. Saini Department of Electrical Engineering, Graphic Era Deemed to be Univer-
sity, Dehradun, Uttarakhand, India

xxvi
Editors and Contributors
Alexandra Salnikova National Research University “MPEI”, Moscow, Russia
Kaung Myat San National Research University “MPEI”, Moscow, Russia
Sunil Sangve JSPM’s Rajarshi Shahu College of Engineering, Pune, India
S. Sanjana Department of Computer Science and Engineering, Amrita School of
Computing, Amrita Vishwa Vidyapeetham, Amritapuri, India
Kundhavai Santharam Department of Business Administration, Kalasalingam
Academy of Research and Education, Krishnan Koil, Tamil Nadu, India
B. V. Santhosh Krishna New
Horizon
College
of
Engineering,
Bengaluru,
Karnataka, India
Aldo Saputra Information Systems Department, Nusantara University, Jakarta,
Indonesia
C. Saraswathi Department of Computing Technologies, SRM Institute of Science
and Technology, Kattankulathur, Chengalpattu, Tamil Nadu, India
R. Sasikala School of Computer Science and Engineering, Vellore Institute of
Technology, Vellore, Tamil Nadu, India
Ashutosh Satapathy Velagapudi Ramakrishna Siddhartha Engineering College,
Vijayawada, India
Joel J. Sebastian Mar Baselios College of Engineering and Technology, Thiru-
vananthapuram, Kerala, India
J. Selvakumar Department of Electronics and Communication Engineering,
SRMIST, Kattankulathur, Tamil Nadu, India
Muthupavithran Selvam De Montfort University, Leicester, UK
Chikondi Sepula Rhodes University, Grahamstown, South Africa
L. Shakkeera Associate Professor/CSE, Presidency University, Bengaluru, India
P. Shanmugaraja Associate Professor/IT, Sona College of Technology, Salem,
India
B. Sharada Department of Studies in Computer Science, University of Mysore,
Mysuru, Karnataka, India
Y. Sharmasth Vali Associate Professor/CSE, Presidency University, Bengaluru,
India
Amogh Shukla Department of Software Systems, Vellore Institute of Technology,
Vellore, Tamil Nadu, India
Harshal Sonawane Department of Computer Engineering, Vishwakarma Institute
of Technology, Pune, India

Editors and Contributors
xxvii
Neelam B. V. D. Soujitha Department of IT, VR Siddhartha Engineering College,
JNTU-Kakinada, Vijayawada, India
V. Spandana Velagapudi
Ramakrishna
Siddhartha
Engineering
College,
Vijayawada, Andhra Pradesh, India
G. Sreenivasan Research scholar, Department of Electrical & Electronics Engi-
neering, JNTUA, Anantapuramu, Anathapur, A.P., India
G. Sri Gayathri Department of Biomedical Engineering, Sri Ramakrishna Engi-
neering College, Coimbatore, India
U. Srilakshmi VFSTR Deemed to be University, Guntur, Andhra Pradesh, India
V. Srividhyasakthi DepartmentofBiomedicalEngineering,SriRamakrishnaEngi-
neering College, Coimbatore, India
Marko Stankovic Singidunum University, Belgrade, Serbia
Dmitry Strabykin Department of Electronic Computers, Vyatka State University,
Kirov, Russia
Razia Sulthana Department of Computing and Mathematical Sciences, University
of Greenwich, Old Naval Royal College, London, UK
K. Sumathi Department of BCA, The American College (Autonomous), Madurai,
Tamil Nadu, India
Rohith Sunkara Department of CSE, GITAM University, Visakhapatnam, India
S. Sunori Department of Electronics and Communication Engineering, Graphic Era
Hill University, Bhimtal, Uttarakhand, India
Sushil Suri Department of Computer Science, Vishwakarma Institute of Tech-
nology, Pune, India
Hamed Taherdoost Departement of Arts, Communications and Social Sciences,
University Canada West (UCW), Vancouver, Canada
Ingwen Tannaris Information Systems Department, Nusantara University, Jakarta,
Indonesia
Sheikh Tasﬁa Military Institute of Science and Technology, Dhaka, Bangladesh
Sheela Thavasi Head of the Department, Sri Sai Ram Engineering College,
Chennai, Tamil Nadu, India
Aditya Thombre Department of Computer Science, Vishwakarma Institute of
Technology, Pune, India
Mahesh Bapusaheb Toradmal Symbiosis Institute of Business Management -
Pune, Symbiosis International (Deemed University), Pune, India

xxviii
Editors and Contributors
Marzia Khan Turna Bangladesh Army International University of Science and
Technology, Cumilla, Bangladesh
Radhesyam Vaddi Department of IT, VR Siddhartha Engineering College, JNTU-
Kakinada, Vijayawada, India
Aryan Vats Vellore Institute of Technology, Vellore, Tamil Nadu, India
Avani Verma Department of Computer Science, Birla Institute of Technology &
Science, Pilani, Dubai, United Arab Emirates
Kakumanu Christy Victor Department
of
IT,
VR
Siddhartha
Engineering
College, JNTU-Kakinada, Vijayawada, India
I. G. Vishnu Vardhan Velagapudi Ramakrishna Siddhartha Engineering College,
Vijayawada, Andhra Pradesh, India
S. Vishnukumar Department of Computer Applications, Cochin University of
Science and Technology, Kochi, Kerala, India
K. Yashwanth Chowdary Velagapudi
Ramakrishna
Siddhartha
Engineering
College, Vijayawada, India
Miodrag Zivkovic Singidunum University, Belgrade, Serbia
Alexander Zyulkov Voronezh State University, Voronezh, Russia

Optimal Placement of Phasor
Measurement Units Considering Channel
Limits Under Various Contingencies
K. Banumalar, B. V. Manikandan, and S. Muralidharan
Abstract Phasor measurement units (PMUs) are becoming increasingly important
for real-time monitoring, protection, analysis, and control of modern power systems.
The sine cosine algorithm (SCA) is proposed in this work to solve the optimal PMUs
placement problem formulation under various restrictions, including the presence of
a zero injection bus, channel limits, single line outage, and single PMU loss. The
objective is to reduce the number of PMU installations while increasing measure-
ment redundancy, under full network observability. The proposed OPP problem was
tested and compared against existing techniques on IEEE 14-bus, IEEE 30-bus, IEEE
39-bus, IEEE 57-bus, and IEEE 118-bus test systems. When compared to existing
literature, the results show that the suggested algorithm is simple and accurate in
determining the number of PMU installations that are less or equal under various
contingencies.
Keywords Phasor measurement units · Channel limits · Measurement
redundancy · Zero injection buses · Single line outage · Single PMU loss · Zero
injection buses
1
Introduction
Phasor measurement units (PMUs) are frequently utilised in electrical system for
monitoring,safety,andcontrol,butitrequiredsuitablenumberofPMUinthenetwork
to improve full observability. However, due to ﬁnancial constraints, the number of
PMUs must be kept to a minimum [1]. Zero injection buses are initially considered
to reduce PMU requirements while maintaining network observability [2–4]. Proper
PMU issue formulation modelling eliminates contingencies like single line interrup-
tion and single PMU loss, improving network dependability [5]. Aside from that, a
K. Banumalar (B) · B. V. Manikandan · S. Muralidharan
Department of Electrical and Electronics Engineering, Mepco Schlenk Engineering College,
Sivakasi, Tamil Nadu, India
e-mail: kbanumalar@mepcoeng.ac.in
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_1
1

2
K. Banumalar et al.
few studies [6, 7] explore full network observability when there is ZIB and PMU
channel constraints under various scenarios.
Various methods have been reported to solve optimal placement and number of
PMU in order to improve the system completely observable, including mathemat-
ical methods like integer linear programming (ILP) [8], binary ILP (BILP) [9], as
well as metaheuristic methods like tabu search [10], genetic algorithm[11], ﬁreﬂy
algorithm [12], particle swarm optimization [13], and mixed integer linear program-
ming (MILP) [13]. The author in [14, 15] proposes an evaluation of the bit error
rate (BER) performance for a massive multi-input multi-output (M-MIMO) system
using a spatial time shift keying (STSK) scheme over a three-dimensional (3D) fading
model.
Inapriorwork,weusedthesinecosinealgorithm(SCA)inapartialshadingMPPT
issue [16]. Following successful completion, an effort is made to solve optimal PMU
placement using the sine cosine algorithm for four cases: base case, ZIBs, single
PMU failure, and single line outage under various channel restrictions. The rest of
this article is in structured as follows: The mathematical formulation of the PMU
placement problem with ZIBs and observability criteria, loss of one PMU, and single
line outage are discussed in Sect. 2. Section 3 shows how to use the SCA technique
to solve an optimal placement problem. The use of SCA to tackle the OPP problem
is discussed in Sect. 4. Finally, in Sect. 5, the simulation ﬁndings are reported, and
Sect. 6 concludes the results.
2
Problem Formulation
The goal of the PMU placement problem is to reduce the number of PMUs in an
electric network, as stated in [17].
Min F(z) =
N

i=1
cizi
(1)
Subjected to
f = AcmZ ≥b
(2)
The cost (ci), binary state (zi) of the PMU deployed at bus I, connectivity matrix
(ACM), and observability of corresponding bus (f ) can be deﬁned as follows:
zi =
1, if PMU installed at bus I
0 otherwise
(3)
ACM =

ai j

N×N
(4)

Optimal Placement of Phasor Measurement Units Considering Channel …
3
Z = [x1, . . . , xN]T
N×1
(5)
b = [1, . . . , 1]T
N×1
(6)
f =

f1, f2, . . . , fNB
T
N×1
(7)
2.1
Measurement Redundancy
All of the buses in an electrical system must be observable for the system to be fully
observable [17]. The following is a description of measurement redundancy (MR),
which is an important aspect in monitoring the electrical network and solving the
OPP problem.
Measurement redundancy = sum(AcmZ)
(8)
2.2
Zero Injection Bus
When the power system is observable and meets the following requirements [17],
the zero injection bus minimises the number of PMU required.
i.
Unobserved bus is observed by observable ZIB which is linked to it by using
KCL at ZIB.
ii. If unobserved ZIBs are linked to all the observable buses, then ZIB is observable
by using KCL.
2.3
Single PMU Loss or Single Line Outage
Any contingencies must not disrupt the electrical system’s monitoring. Any single
PMU failure caused the entire electrical network to go down. To solve this difﬁculty,
all buses were observed twice to ensure that the system was completely observable
[17], as follows:
bn × 1 =

2 2 2 . . . . . . . . . . . . .
T
(9)

4
K. Banumalar et al.
2.4
Channel Limits
Manufacturers usually keep the channel number of PMUs ﬁxed. A limited number
of PMUs are employed to track the number of branch currents and bus voltages at
any given moment. PMU numbers (Nk) change when channel numbers (L) change,
and the two are inversely proportional. The channel limitations (Ck) are taken into
account for solving this OPP problem, as shown in Eq. (10).
Ck =

Nk!
(Nk−L)!L! . . . Nk > L
1 . . . NK ≤L
(10)
3
Optimal Placement of Phasor Measurement Unit
Sine cosine algorithm (SCA) is a stochastic optimization approach that proposes
many initial random candidate solutions based on a mathematical model of sine and
cosine functions [18]. The exploration and exploitation phases are the two phases of
SCA. Exploration deals with random change in random solutions, while exploitation
deals with random selection to produce a set of solutions. The steps of SCA’s opera-
tion are listed below. Using the equation to update the position during the exploration
and exploitation phase,
Xt+1
i
=
 Xt
i + r1 × sin(r2) ×
r3Pt
i −Xt
i
,r4 < 0.5
Xt
i + r1 × cos(r2) ×
r3Pt
i −Xt
i
,r4 ≥0.5
(11)
r1 = a −t a
T
(12)
where
Xit—current position(i) at t-th iteration
Pit—position (i) of destination at t-th iteration,
r4—random number [0,1],
r1 r2 r3—random numbers,
t—current iteration,
T—maximum number of iterations, and
a—constant.
The parameter r1 determines whether the next position is inside or outside of
space, and the value r2 determines whether the movement is towards or away from
the destination. The parameter adds a random weight to the destination in order to
stochastically accentuate and deemphasize the role of destination in deﬁning the
distance when r3. Finally, in Eq. 11, r4 shifts equally between the sine and cosine
components.

Optimal Placement of Phasor Measurement Units Considering Channel …
5
4
Result Analysis
The performance of the proposed optimization algorithm is evaluated by testing
on the IEEE 14-bus, 30-bus, 39-bus, 57-bus, and 118-bus test systems under ﬁve
cases—(1) With and without considering zero injection, (2) normal condition, (3)
single PMU failure, (4) single line outage, and (5) channel limit up to ﬁve using
MATLAB software.
Figure 1 shows the implementation of the sine cosine method in the PMU place-
ment problem. The IEEE standard test system speciﬁcations are shown in Table 1.
For IEEE 14-bus, 30-bus, 39-bus, 57-bus, and 118-bus test systems, Tables 2, 3, 4, 5,
6, and 7 illustrate the optimum PMU number and position, redundancy, installation
cost, execution time in normal mode, single line outage, and single PMU loss contin-
gency without and with ZIB, as well as various channel limits. Table 8 compares the
proposed SCA to the existing PSO and MILP [13].
Tables 2 and 3 demonstrate the ideal number of PMU necessary to achieve full
observability, installation cost, and execution time for IEEE 14-bus without and
with ZIB along various channel limits under normal and contingency conditions.
In all three cases, the ratio of necessary PMU to total number of buses decreased,
as indicated in Tables 2 and 3. At the same time, the necessary number of PMU
grew when channel limitations were increased with full network observability for all
optimization approaches and then decreased as channel limits were increased.
Figure 2 shows the PMU placement in 30 trials. Figure 2 and Tables 2 and 3
show that when SCA is combined with CF-PSO and MILP for a 14-bus system, it is
more common to attain the lowest number of PMUs with the maximum measurement
redundancy value.
Similarly, for IEEE 30-bus, 39-bus, 57-bus, and 118-bus test systems, Tables 4,
5, 6, 7, and 8 highlight the same observations as Table 3. When comparing the
suggested optimization methodology to CF-PSO [13], MILP [13] method, and refer-
ence [19], it is found that the proposed algorithm reduces the number of PMU as
the number of PMU channels increases. When compared to alternative ways, full
network observability was achieved with the same number of PMU deployments. As
a consequence of the ﬁndings, we can conclude that installing PMUs with more than
four channels will not reduce the required number of PMUs while also increasing
the installation cost. There is no need to install additional PMUs than four-channel
from a cost-effective standpoint.

6
K. Banumalar et al.
Fig. 1 Flowchart for
proposed algorithm in OPP
problem

Optimal Placement of Phasor Measurement Units Considering Channel …
7
Table 1 IEEE standard systems speciﬁcations
IEEE system
Number of ZIBs
Location of ZIBs
No. of radial bus
Location of radial
bus
14-bus
1
7
1
8
30-bus
6
6, 9, 22, 25, 27, 28
3
11, 13, 26
39-bus
12
1, 2, 5, 6, 9, 10, 11,
13, 14, 17, 19, 22
9
30, 31, 32, 33, 34,
35, 36, 37, 38
57-bus
15
4, 7, 11, 21, 22, 24,
26, 34, 36, 37, 39,
40, 45, 46, 48
1
33
118-bus
10
5, 9, 30, 37, 38, 63,
64, 68, 71, 81
7
10, 73, 87, 111,
112, 116, 117
5
Conclusion
The study provides a sine cosine technique for achieving full network observability
under normal and contingency conditions such as single line outage and single PMU
loss, while taking channel availability into account. The OPP problem was validated
using IEEE 14-bus, 30-bus, 39-bus, 57-bus, and 118-bus test systems, and the results
were compared to the existing algorithm. The suggested SCA approach outperforms
thenPSOandMILPandaccuratefordetectingPMUinstallationnumberwithreduced
computing time, as shown by the results. As a continuation of this work, the hybrid
observability of the power system networks can be used to implement the OPP
problem.

8
K. Banumalar et al.
Table 2 Number of PMU and locations without considering ZIB
Test system
Type
No. of PMU
Location of PMU
Redundancy
% between min. no.
to total no. of PMUs
Installation Cost
(unit)
Execution time (s)
14-bus
Normal
4
2, 6, 7, 9
19
28.57
3.62
0.03
Single line outage
8
2, 4, 5, 6, 7, 9, 11, 13
37
57.14
7.19
0.04
Single PMU loss
9
2, 4, 5, 6, 9, 10, 13
39
64.28
8.22
0.03
30-bus
Normal
10
1, 6, 7, 9, 10, 12, 15,
19, 25, 27
48
33.33
9.3
0.05
Single line outage
18
1, 2, 4, 5, 6, 9, 10, 12,
15, 17, 19, 20, 22, 24,
25, 27, 28, 29
79
60
17.3
0.05
Single PMU loss
21
1, 2, 4, 5, 6, 9, 10, 12,
13, 15, 16, 18, 20, 22,
24, 25, 26, 27, 28, 29
85
70
20.17
0.01
39-bus
Normal
13
2, 6, 9, 10, 13, 14, 17,
19, 20, 22, 23, 25, 29
52
33.33
12.7
0.03
Single line outage
19
2, 3, 6, 8, 9, 10, 11, 13,
14, 16, 17, 19, 20, 22,
23, 25, 26, 29, 39
78
48.71
17.9
0.04
Single PMU loss
28
2, 3, 6, 8, 9, 10, 11, 13,
14, 16, 17, 19, 20, 22,
23, 25, 26, 29, 30, 31,
32, 33, 34, 35, 36, 37,
38, 39
96
71.79
27.1
0.03
(continued)

Optimal Placement of Phasor Measurement Units Considering Channel …
9
Table 2 (continued)
Test system
Type
No. of PMU
Location of PMU
Redundancy
% between min. no.
to total no. of PMUs
Installation Cost
(unit)
Execution time (s)
57-bus
Normal
17
1, 4, 6, 9, 15, 20, 24,
25, 28, 32, 36, 38, 41,
46, 50, 53, 57
72
29.82
15.4
0.05
Single line outage
32
1, 3, 4, 6, 9, 11, 12, 15,
19, 20, 22, 24, 25, 26,
28, 29, 30, 32, 34, 36,
37, 38, 39, 41, 44, 46,
47, 50, 51, 53, 54, 56
128
56.14
30.7
0.03
Single PMU loss
33
1, 3, 4, 6, 9, 11, 12, 15,
19, 20, 22, 24, 25, 27,
28, 29, 30, 32, 33, 35,
36, 37, 38, 39, 41, 44,
46, 47, 50, 51, 53, 54,
56
127
57.89
31.8
0.04
118-bus
Normal
32
2, 5, 10, 12, 15, 17, 21,
25, 29, 34, 37, 41, 45,
49, 53, 56, 62, 64, 72,
73, 75, 77, 80, 85, 87,
91, 94, 101, 105, 110,
114, 116
151
27.11
31.6
0.04
(continued)

10
K. Banumalar et al.
Table 2 (continued)
Test system
Type
No. of PMU
Location of PMU
Redundancy
% between min. no.
to total no. of PMUs
Installation Cost
(unit)
Execution time (s)
Single line outage
62
1, 2, 5, 7, 9, 10, 11, 12,
15, 17, 19, 21, 22, 25,
26, 28, 29, 34, 35, 37,
41, 42, 43, 45, 46, 49,
50, 52, 53, 56, 59, 62,
63, 65, 67, , 68, 70, 71,
72, 75, 76, 77, 79, 80,
84, 85, 87, 89, 91, 92,
94, 96, 100, 101, 105,
107, 109, 110, 113,
114, 115
276
52.54
62.6
0.04
Single PMU loss
68
1, 2, 5, 7, 9, 10, 11, 12,
15, 17, 19, 21, 22, 25,
26, 28, 29, , 32, 34, 35,
37, 40, 41, 44, 45, 46,
49, 52, 53, 56, 57, 58,
59, 62, 63, 65, 67, , 68,
70, 71, 72, 75, 76, 77,
79, 80, 84, 85, 86, 87,
89, 92, 94, 96, 100,
101, 105, 107, 109,
110, 111, 112, 114,
115, 116, 117, 118
309
57.62
67.1
0.05

Optimal Placement of Phasor Measurement Units Considering Channel …
11
Table 3 Number of PMU and locations for IEEE 14-bus with considering ZIB
Channel limit
Type
No. of PMU
Location of PMU
Redundancy
% between min. no. to
total no. of PMUs
Installation Cost
Execution time (s)
–
Normal
3
2, 6, 9
55
21.43
2.857
0.04
Single line outage
7
2, 4, 5, 6, 9, 11, 13
33
50
6.5
0.039
Single PMU loss
7
2, 4, 5, 6, 9, 10, 13
33
50
6.5
0.043
1
Normal
7
1, 2, 3, 4, 10, 12, 13
19
50
7.8
0.045
Single line outage
13
1, 2, 3, 4, 5, 6, 8, 9, 10,
11, 12, 13, 14
37
92
14.1
0.04
Single PMU loss
12
1, 2, 3, 5, 6, 7, 9, 10,
11, 12, 13, 14
33
85.71
14.1
0.06
2
Normal
5
2, 3, 4, 11, 13
22
35.71
5.9
0.1
Single line outage
9
2, 4, 5, 6, 7, 9, 11, 13,
14
26
64.28
10.5
0.12
Single PMU loss
9
2, 4, 5, 6, 7, 9, 11, 13,
14
26
64.28
10.5
0.12
3
Normal
4
2, 2, 6, 9
16
28.57
5.1
0.21
Single line outage
7
2, 4, 5, 6, 9, 10, 13
25
50
9
0.19
Single PMU loss
7
2, 2, 5, 6, 9, 10, 13
28
50
9
0.18
4
Normal
4
2, 2, 6, 9
16
28.57
4.2
0.36
(continued)

12
K. Banumalar et al.
Table 3 (continued)
Channel limit
Type
No. of PMU
Location of PMU
Redundancy
% between min. no. to
total no. of PMUs
Installation Cost
Execution time (s)
Single line outage
7
2, 4, 5, 6, 9, 11, 13
26
50
9.6
0.34
Single PMU loss
7
2, 2, 2, 6, 9, 10, 13
27
50
9.6
0.36
5
Normal
3
2, 6, 9
15
21.43
4.5
0.52
Single line outage
7
1, 2, 3, 6, 9, 10, 13
32
50
10.5
0.54
Single PMU loss
7
1, 2, 3, 6, 9, 10, 13
33
50
10.5
0.56

Optimal Placement of Phasor Measurement Units Considering Channel …
13
Table 4 Number of PMU and locations for IEEE 30-bus considering ZIB
Channel limit Type
No. of PMU Location of PMU
Redundancy Installation cost Execution time (s)
–
Normal
6
2, 4, 10, 12, 15, 19
31
5.8
0.05
Single line outage 12
1, 2, 4, 5, 6, 10, 12, 15, 17, 19, 20, 24
55
11.8
0.03
Single PMU loss
13
2, 3, 4, 6, 7, 10, 12, 13, 15, 16, 19, 20, 24
57
12.8
0.1
1
Normal
12
1, 2, 2, 2, 3, 4, 12, 15, 17, 18, 20, 24
48
12.9
0.1
Single line outage 23
1, 2, 2, 2, 3, 4, 7, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20,
23, 24, 28, 29, 29, 30
84
24.8
0.11
Single PMU loss
21
1, 2, 3, 5, 6, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20,
22, 23, 24, 27, 29
88
26.2
0.14
2
Normal
8
2, 2, 4, 12, 15, 17, 20, 24
32
9.3
0.18
Single line outage 15
1, 2, 4, 5, 6, 7, 10, 12, 13, 15, 17, 18, 20, 22, 24
56
18
0.24
Single PMU loss
14
1, 2, 4, 5, 6, 10, 12, 12, 15, 17, 18, 19, 24, 27
54
20
0.3
3
Normal
7
1, 2, 10, 11, 12, 18, 24
24
8.8
0.3
Single line outage 13
1, 2, 4, 7, 10, 12, 13, 15, 17, 18, 20, 22, 24
48
16.4
0.3
Single PMU loss
13
1, 2, 3, 7, 10, 10, 12, 12, 15, 18, 19, 24, 27
48
17.5
0.35
4
Normal
6
2, 4, 10, 12, 15, 19
25
8.1
0.51
Single line outage 12
1, 2, 3, 5, 10, 12, 13, 15, 16, 18, 19, 24, 27
48
15.9
0.51
Single PMU loss
12
1, 2, 3, 5, 10, 12, 13, 15, 16, 18, 19, 24, 27
51
16.9
0.4
5
Normal
6
1, 5, 10, 12, 19, 24
26
8.6
0.71
Single line outage 11
1, 2, 4, 7, 10, 12, 15, 17, 19, 20, 24
48
15.7
0.75
Single PMU loss
12
1, 2, 3, 5, 10, 12, 13, 15, 16, 18, 19, 24, 27
50
18
0.64

14
K. Banumalar et al.
Table 5 Number of PMU and locations for IEEE 39-bus considering ZIB
No. of channel limit
Type
No. of PMU
Location of PMU
Redundancy
Installation cost (unit)
Execution time (s)
Without channel limit
–
Normal
7
2, 3, 16, 20, 23, 25, 29
31
6.8
0.03
Single line outage
12
2, 6, 13, 14, 16, 19, 20, 22, 23, 25,
26, 29
52
11.8
0.03
Single PMU loss
16
2, 3, 6, 14, 15, 16, 20, 21, 23, 25,
26, 29, 34, 36, 37, 38
58
15.8
0.06
1
Normal
14
1, 3, 4, 5, 6, 18, 19, 20, 23, 23, 24,
25, 28, 29
52
15.1
0.2
Single line outage
27
1, 1, 2, 4, 4, 5, 5, 6, 6, 7, 16, 16,
17, 19, 20, 22, 23, 23, 24, 25, 26,
26, 28, 29, 34, 36, 37, 38
54
25.1
0.15
Single PMU loss
27
14, 14, 14, 15, 19, 20, 20, 23, 23,
24, 25, 25, 26, 27, 28, 28, 30, 31,
32, 33, 34, 35, 36, 37, 38, 39
54
29
0.14
2
Normal
9
4, 4, 9, 20, 21, 25, 27, 29
34
10.5
0.36
Single line outage
15
2, 3, 6, 14, 15, 16, 20, 21, 23, 25,
26, 29, 34, 36, 38
54
18
0.35
Single PMU loss
19
1, 3, 4, 4, 5, 5, 16, 17, 20, 22, 23,
23, 25, 26, 29, 29, 34, 37
57
22
0.38
3
Normal
8
3, 4, 15, 16, 20, 23, 25, 29
31
10.1
0.6
(continued)

Optimal Placement of Phasor Measurement Units Considering Channel …
15
Table 5 (continued)
No. of channel limit
Type
No. of PMU
Location of PMU
Redundancy
Installation cost (unit)
Execution time (s)
Single line outage
12
2, 6, 8, 15, 16, 17, 20, 23, 25, 26,
29, 35
51
15.2
0.52
Single PMU loss
16
2, 5, 6, 6, 16, 16, 16, 20, 23, 25,
26, 29, 34, 36, 37, 38
55
18.3
0.5
4
Normal
7
3, 6, 16, 20, 23, 25, 29
29
9.2
0.75
Single line outage
12
2, 6, 8, 15, 16, 17, 20, 23, 25, 26,
29, 35
52
15.9
0.8
Single PMU loss
16
2, 5, 6, 14, 16, 17, 20, 22, 23, 25,
26, 29, 34, 36, 37, 38
62
21.3
1.01
5
Normal
7
6, 16, 20, 23, 25, 29, 39
31
10.1
1.02
Single line outage
12
2, 6, 8, 15, 16, 17, 20, 23, 25, 26,
29, 35
52
17.4
1.06
Single PMU loss
16
2, 5, 6, 8, 16, 19, 20, 21, 23, 25,
26, 29, 34, 36, 37, 38
60
23.7
1.27

16
K. Banumalar et al.
Table 6 Number of PMU and locations for IEEE 57-bus considering ZIB
Channel limit
Type
No. of PMU
Location of PMU
Redundancy
Installation cost
Execution time (s)
–
Normal
11
1, 6, 9, 19, 29, 30, 32, 38, 51, 54, 56
48
10.8
0.04
Single line outage
21
1, 3, 4, 9, 12, 15, 19, 20, 25, 28, 29, 31, 32, 38, 42,
48, 50, 51, 53, 54, 56
86
20.8
0.07
Single PMU loss
22
1, 3, 4, 9, 12, 15, 19, 20, 25, 27, 29, 30, 32, 33, 38,
41, 49, 50, 53, 54, 56
88
21.8
0.3
1
Normal
21
3, 3, 4, 9, 10, 11, 15, 16, 17, 19, 23, 24, 28, 31, 33,
34, 47, 50, 53, 54, 56
46
22.6
0.4
Single line outage
22
1, 3, 4, 9, 12, 15, 19, 20, 25, 27, 29, 31, 32, 33, 37,
38, 42, 50, 51, 53, 54, 56
88
30.2
0.25
Single PMU loss
42
2, 3, 3, 8, 9, 10, 12, 16, 16, 17, 18, 19, 20, 23, 28, 29,
29, 30, 31, 32, 33, 38, 41, 41, 43, 43, 45, 45, 48, 48,
49, 49, 51, 52, 53, 54, 55, 56, 56, 56, 57, 57
84
43.6
0.5
2
Normal
14
1, 3, 15, 20, 25, 29, 29, 32, 37, 41, 49, 54
41
16.3
0.65
Single line outage
23
1, 1, 6, 9, 12, 12, 18, 20, 25, 27, 29, 30, 32, 32, 36,
38, 41, 46, 50, 51, 53, 54, 56
82
28.1
0.67
Single PMU loss
23
1, 1, 6, 9, 12, 12, 18, 20, 25, 27, 29, 30, 32, 32, 36,
38, 41, 46, 50, 51, 53, 54, 56
82
28.1
0.67
3
Normal
12
1, 4, 10, 15, 20, 25, 29, 32, 38, 41, 49, 54
45
15.3
0.96
Single line outage
22
1, 3, 7, 10, 12, 15, 19, 20, 25, 28, 29, 30, 32, 33, 38,
41, 49, 50, 52, 54, 55, 56
84
28.6
0.99
Single PMU loss
22
1, 1, 4, 9, 12, 18, 20, 25, 27, 29, 30, 32, 33, 36, 38,
41, 46, 50, 51, 53, 54, 56
86
28.6
0.99
4
Normal
11
1, 4, 10, 18, 25, 29, 32, 38, 41, 49, 54
45
14.9
1.06
Single line outage
21
1, 3, 6, 9, 10, 12, 15, 19, 20, 25, 27, 29, 31, 32, 38,
41, 49, 50, 53, 54, 56
84
28.5
1.02
(continued)

Optimal Placement of Phasor Measurement Units Considering Channel …
17
Table 6 (continued)
Channel limit
Type
No. of PMU
Location of PMU
Redundancy
Installation cost
Execution time (s)
Single PMU loss
22
1, 2, 4, 9, 12, 18, 20, 25, 27, 29, 30, 32, 33, 37, 38,
41, 46, 50, 51, 53, 54, 56
86
29.8
1.1
5
Normal
11
1, 4, 10, 20, 25, 29, 32, 38, 41, 49, 54
47
16.5
1.26
Single line outage
21
1, 3, 6, 9, 10, 12, 15, 19, 20, 25, 27, 29, 31, 32, 38,
41, 49, 50, 53, 54, 56
87
30.9
1.3
Single PMU loss
22
1, 2, 4, 9, 12, 18, 20, 25, 27, 29, 30, 32, 36, 38, 41,
46, 50, 51, 53, 54, 56
89
32.3
1.33

18
K. Banumalar et al.
Table 7 Number of PMU and locations for IEEE 118-bus considering ZIB
Channel limit Type
No. of PMU Location of PMU
Redundancy Installation cost Execution time (s)
–
Normal
26
2, 11, 12, 17, 21, 23, 28, 34, 40, 45, 49, 52, 56, 62, 71,
75, 77, 80, 85, 87, 90, 94, 102, 105, 110, 115
257
34.2
1.7
Single line outage 53
2, 3, 6, 11, 12, 15, 17, 19, 20, 21, 23, 27, 28, 31, 32,
34, 35, 40, 42, 44, 45, 46, 49, 51, 52, 54, 56, 57, 59,
62, 66, 70, 71, 75, 77, 78, 80, 83, 85, 86, 89, 90, 92,
94, 96, 100, 101, 105, 106, 109, 110, 115, 118
260
36.6
0.15
Single PMU loss
57
1, 3, 7, 11, 12, 15, 17, 19, 21, 22, 23, 27, 28, 31, 32,
34, 36, 40, 42, 43, 45, 46, 49, 50, 51, 52, 53, 56, 59,
62, 66, 70, 71, 75, 77, 79, 80, 84, 85, 86, 87, 89, 90,
92, 94, 96, 100, 102, 105, 107, 109, 110, 111, 112,
115, 117, 118
265
36.5
1.5
1
Normal
55
1, 3, 4, 4, 7, 12, 13, 15, 16, 18, 21, 23, 24, 26, 28, 31,
32, 34, 41, 42, 43, 45, 47, 48, 50, 51, 54, 56, 59, 59,
62, 67, 72, 74, 76, 77, 78, 80, 80, 84, 87, 88, 90, 91,
94, 95, 98, 101, 103, 106, 107, 108, 110, 111, 115
260
58.3
0.7
Single line outage 103
1, 2, 3, 6, 7, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,
21, 22, 23, 25, 26, 27, 28, 29, 31, 32, 34, 35, 37, 41,
42, 43, 44, 45, 46, 48, 49, 49, 50, 51, 52, 53, 55, 55,
56, 57, 58, 60, 62, 64, 65, 66, 67, 68, 69, 70, 71, 74,
75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 88,
90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102,
103, 105, 106, 107, 108, 109, 110, 110, 111, 112, 113,
114, 115, 117, 118
212
112.8
0.97
(continued)

Optimal Placement of Phasor Measurement Units Considering Channel …
19
Table 7 (continued)
Channel limit Type
No. of PMU Location of PMU
Redundancy Installation cost Execution time (s)
Single PMU loss
109
1, 2, 6, 7, 11, 12, 13, 14, 15, 16, 17, 17, 19, 19, 21, 22,
23, 24, 25, 25, 27, 29, 29, 32, 36, 36, 41, 42, 43, 44, 44,
46, 47, 47, 48, 49, 50, 51, 52, 53, 55, 56, 56, 57, 58,
60, 62, 65, 65, 66, 67, 68, 68, 68, 68, 69, 72, 72, 73,
74, 75, 75, 76, 77, 78, 79, 80, 80, 81, 81, 83, 83, 85,
85, 86, 87, 88, 89, 90, 92, 92, 94, 94, 95, 97, 97, 98,
99, 100, 101, 102, 103, 104, 106, 106, 107, 108, 109,
110, 110, 111, 112, 113, 113, 114, 115, 116, 117, 118
218
118.1
0.71
2
Normal
36
1, 6, 12, 15, 17, 18, 21, 25, 29, 36, 40, 40, 44, 46, 51,
54, 57, 62, 64, 65, 69, 72, 75, 77, 80, 80, 82, 85, 86,
90, 94, 100, 102, 105, 109, 110, 114
142
43.2
0.9
Single line outage 57
1, 3, 11, 12, 12, 13, 17, 18, 20, 21, 23, 27, 28, 29, 30,
32, 34, 36, 40, 41, 43, 45, 46, 49, 52, 53, 56, 57, 58,
59, 62, 67, 70, 71, 75, 77, 78, 80, 84, 85, 86, 87, 89,
90, 92, 94, 96, 100, 101, 105, 105, 107, 109, 110, 111,
112, 115, 118
211
64.2
0.75
Single PMU loss
69
1, 2, 6, 8, 11, 12, 12, 15, 15, 17, 19, 20, 22, 23, 27, 28,
29, 32, 32, 34, 35, 41, 42, 44, 45, 46, 49, 51, 52, 54,
54, 56, 57, 61, 62, 62, 65, 69, 70, 72, 75, 77, 78, 80,
80, 80, 82, 83, 85, 86, 87, 89, 90, 92, 92, 94, 96, 100,
100, 102, 105, 105, 106, 109, 110, 110, 110, 115, 118
209
80.6
0.82
3
Normal
29
1, 11, 12, 15, 17, 21, 27, 31, 32, 34, 40, 45, 49, 52, 56,
59, 66, 70, 75, 77, 80, 85, 86, 90, 92, 96, 100, 105, 110
110
37.3
1.5
Single line outage 57
1, 3, 11, 12, 12, 13, 17, 18, 20, 21, 23, 27, 28, 29, 30,
32, 34, 36, 40, 41, 43, 45, 46, 49, 52, 53, 56, 57, 58,
59, 62, 67, 70, 71, 75, 77, 78, 80, 84, 85, 86, 87, 89,
90, 92, 94, 96, 100, 101, 105, 105, 107, 109, 110, 111,
112, 115, 118
217
73.3
1.7
(continued)

20
K. Banumalar et al.
Table 7 (continued)
Channel limit Type
No. of PMU Location of PMU
Redundancy Installation cost Execution time (s)
Single PMU loss
58
1, 2, 8, 11, 12, 12, 15, 17, 17, 20, 21, 23, 27, 29, 31,
32, 34, 34, 40, 41, 43, 45, 46, 49, 49, 52, 53, 54, 56,
56, 62, 62, 65, 72, 75, 75, 77, 77, 80, 80, 83, 85, 86,
87, 89, 90, 92, 94, 96, 100, 100, 101, 105, 105, 110,
110, 110, 115
221
72.8
1.82
4
Normal
27
1, 12, 15, 17, 21, 24, 26, 29, 34, 40, 45, 49, 53, 56, 62,
75, 77, 80, 85, 86, 90, 94, 102, 105, 110, 114, 115
111
37.6
2.09
Single line outage 53
1, 3, 6, 11, 12, 15, 17, 19, 22, 24, 26, 27, 29, 31, 32,
34, 36, 40, 42, 43, 45, 46, 49, 50, 51, 52, 54, 56, 59,
62, 66, 70, 75, 76, 77, 79, 80, 83, 85, 86, 89, 90, 92,
94, 96, 100, 101, 105, 107, 109, 110, 114
219
80.3
3.07
Single PMU loss
57
1, 3, 11, 12, 12, 15, 17, 17, 20, 21, 23, 27, 28, 31, 32,
34, 36, 37, 40, 41, 43, 45, 46, 49, 49, 52, 53, 56, 59,
62, 66, 70, 71, 75, 77, 78, 80, 85, 85, 86, 87, 90, 91,
92, 94, 96, 100, 102, 105, 105, 108, 110, 111, 112,
115, 118
230
80.6
3.05
5
Normal
26
3, 12, 15, 17, 21, 24, 26, 28, 34, 40, 45, 49, 52, 56, 62,
75, 77, 80, 85, 86, 90, 94, 102, 105, 110, 114
120
37.8
4.72
Single line outage 53
1, 3, 6, 11, 12, 15, 17, 19, 21, 22, 24, 26, 27, 29, 31,
32, 34, 36, 40, 42, 43, 45, 46, 49, 50, 51, 52, 54, 56,
59, 62, 66, 70, 75, 76, 77, 79, 83, 85, 86, 89, 90, 92,
94, 96, 100, 101, 105, 107, 109, 110, 114
233
81.7
4.85
Single PMU loss
57
1, 3, 11, 12, 12, 15, 17, 17, 20, 21, 23, 27, 28, 31, 32,
34, 36, 37, 40, 41, 43, 45, 46, 49, 51, 52, 54, 56, 57,
61, 62, 66, 70, 71, 75, 76, 77, 79, 80, 83, 85, 86, 87,
89, 90, 92, 94, 96, 100, 102, 105, 105, 107, 109, 110,
111, 112, 114
243
84.3
4.51

Optimal Placement of Phasor Measurement Units Considering Channel …
21
Table 8 Optimal number of PMUs in IEEE system—comparison with existing methods
Method
*CL
IEEE 14
IEEE 30
IEEE 39
IEEE 57
*N
*SLO
*SPMUL
*N
*SLO
*SPMUL
*N
*SLO
*SPMUL
*N
*SLO
*SPMUL
SCA
-
3
7
7
6
12
13
7
12
16
11
21
22
PSO
3
7
7
6
12
13
7
12
16
11
21
22
MILP
3
7
7
6
12
13
7
12
16
11
21
22
R [19]
–
–
–
–
–
–
–
–
–
–
–
–
SCA
1
7
13
12
12
23
21
14
27
27
21
22
42
PSO
–
–
13
–
–
24
–
–
27
–
–
42
MILP
–
–
13
–
–
24
–
–
27
–
–
42
R [19]
7
13
13
12
23
24
14
23
27
21
42
42
SCA
2
5
9
9
8
15
14
9
15
19
14
23
23
PSO
–
–
–
–
–
–
–
–
–
–
–
–
MILP
–
–
–
–
–
–
–
–
–
–
–
–
R [19]
5
9
9
8
15
17
9
15
20
14
28
29
SCA
3
4
7
7
7
13
13
8
12
16
12
22
22
PSO
4
7
7
7
13
13
8
13
16
12
23
24
MILP
4
7
7
7
13
13
8
13
16
12
23
24
R [19]
4
7
7
7
13
14
8
12
17
12
23
24
SCA
4
3
7
7
6
12
12
7
12
16
11
21
22
PSO
3
7
7
6
12
12
7
12
16
11
21
22
MILP
3
7
7
6
12
12
7
12
16
11
21
22
R [19]
3
7
7
6
12
13
7
12
16
11
21
22
(continued)

22
K. Banumalar et al.
Table 8 (continued)
Method
*CL
IEEE 14
IEEE 30
IEEE 39
IEEE 57
*N
*SLO
*SPMUL
*N
*SLO
*SPMUL
*N
*SLO
*SPMUL
*N
*SLO
*SPMUL
SCA
5
3
7
7
6
11
12
7
12
16
11
21
22
PSO
3
7
7
6
12
13
7
12
16
11
21
22
MILP
3
7
7
6
12
13
7
12
16
11
21
22
R [19]
3
7
7
6
11
13
7
12
16
11
21
22
*CL—Channel limit, *N—Normal, *SLO—Single line outage, *SPMUL—Single PMU loss

Optimal Placement of Phasor Measurement Units Considering Channel …
23
Fig. 2 PMU placement in
30 trials—IEEE14-bus
0
2
4
6
8
0
5
10
15
20
25
30
PMUs
Trial Number
PMUs locaon
SCA
CF-PSO
MILP
References
1. Mohammed AAI, Abido M (2014) A fully adaptive PMU based fault location algorithm for
series compensated lines. IEEE Trans Power Syst 29:2129–2137
2. Georges D (2014) Optimal PMU based monitoring architecture design for power systems.
Control Eng Pract 30:150–159
3. Banumalar K, Manikandan BV, Chandrasekaran K, Arul Jeyaraj K (2018) Optimal placement
of phasor measurement units using clustered gravitational search algorithm. J Intell Fuzzy Syst
34(6):4315–4330
4. Saravanakumar R, Banumalar K, Chandrasekaran K, Manikandan BV (2022) Realistic method
for placement of phasor measurement units through optimization problem formulation with
conﬂicting objectives. Electric Power Components Syst 49(4–5):474–487
5. Abiri E, Rashidi F, Niknam T (2015) An optimal PMU placement method for power system
observability under various contingencies. Int Trans Electrical Energy Syst 25(4): 589–606
6. Kamyabi L, Esmaeili S, Koochi MHR (2018) Power quality monitor placement in power
systems considering channel limits and estimation error at unobservable buses using a bi-level
approach. Int J Elect Power Energy Syst 102:302–311
7. Shaﬁullah H, Abido F, Mantawy (2019) A modiﬁed optimal PMU placement problem formu-
lation considering channel limits under various contingencies. Measurement 135:875–885
8. Manousakis NM, Korres GN (2016) Optimal PMU placement for numerical observability
considering ﬁxed channel capacity—a semi deﬁnite programming approach. IEEE Trans Power
Syst 31(4)
9. Gou B (2008) Generalized integer linear programming formulation for optimal PMU
placement. IEEE Trans Power Syst 23:1099–1104
10. Koutsoukis NC, Manousakis NM, Georgilakis PS, Korres GN (2013) Numerical observability
method for optimal phasor measurement units placement using recursive tabu search method.
IET Generation Trans Dist 7:1–10
11. Marin FJ, Garcia-Lagos F, Joya G, Sandoval F (2003) Genetic algorithms for optimal placement
of phasor measurement units in electric networks. Electron Lett 39(19):1403–1405
12. Arul Jeyaraj K, Rajasekaran V, Nandhakumar SK, Chandrasekaran KK (2005) A multi-
objective placement of phasor measurement units considering observability and measurement
redundancy using ﬁreﬂy algorithm. J ElectrEng Technol 10(2):474–486
13. Abiri E, Rashidi F, Niknam T, Salehi MR (2014) Optimal PMU placement method for
complete topological observability of power system under various contingencies. Electrical
Power Energy Syst 61:585–593
14. Chen JI-Z (2019) The evaluatıon of performance for a mass-mımo system wıth the stsk scheme
over 3-d α-λ-μ fadıng channel. IRO J Sustain Wireless Syst 1:1–19
15. Bashar A, Smys S (2021) Physical layer protection against sensor eavesdropper channels in
wireless sensor networks. IRO J Sustain Wireless Syst 3(2):59–67
16. Chandrasekaran K, Sankar S, Banumalar K (2021) Partial shading detection for PV arrays
in a maximum power tracking system using the sine-cosine algorithm. Energy Sustain Dev
55:105–121

24
K. Banumalar et al.
17. Rahman NHA, Zobaa AF (2017) Integrated mutation strategy with modiﬁed binary PSO
algorithm for optimal PMUs placement. IEEE Trans Ind Inf 13(6):3124–3133
18. Mirjalili S (2016) SCA: a sine cosine algorithm for solving optimization problems. Knowl-
Based Syst 96:120–133
19. Rashidi F, Abiri E, Niknam T, Salehi MR (2015) Optimal placement of PMUs with limited
number of channels for complete topological observability of power systems under various
contingencies. Int J Electr Power Energy Syst 67:125–137

Adaptive Deep Recurrent Neural
Network-Based COVID-19 Healthcare
Data Prediction for Early Risk Prediction
A. Asha, B. Dhiyanesh, G. Kiruthiga, L. Shakkeera, Y. Sharmasth Vali,
and K. Karthick
Abstract The Covid-19 pandemic has spread rapidly across the globe and is now
one of the leading causes of death and illness worldwide. Existing approaches for
controlling coronavirus disease are challenging because, the improper solutions,
medications, and data are irregular to analyze. This paper proposes adaptive deep
recurrent neural network-based Covid-19 healthcare data prediction, where the risk
prediction algorithm is made to detect the Covid-19 disease when it is typically
premature. The initially collected Covid-19 sample test dataset is trained in the
preprocessing step to remove irrelevant data. The margins of features are estimated
using threshold values to ﬁnd the defect rate based on the Intrinsic Covid Defect
Rate. The trained data are processed for feature selection using a threshold value
to identify the best features using Relative Cluster-Intensive Feature Selection. The
selected features are introduced to an Adaptive Deep vectorized Recursive Neural
Network (ADVRNN) to predict the coronavirus affected rate. The results of the
proposed ADVRNN experiment improve prediction accuracy, recall, f-measure, and
A. Asha
Professor/ECE, Rajalakshmi Engineering College, Chennai, India
e-mail: ngash78@gmail.com
B. Dhiyanesh
Associate Professor/CSE, Dr. N.G.P. Institute of Technology, Coimbatore, India
e-mail: dhiyanu87@gmail.com
G. Kiruthiga (B)
Associate Professor/CSE, IES College of Engineering, Thrissur, India
e-mail: kirthikacsehod@gmail.com
L. Shakkeera · Y. Sharmasth Vali
Associate Professor/CSE, Presidency University, Bengaluru, India
e-mail: shakkeera.l@presidencyuniversity.in
Y. Sharmasth Vali
e-mail: sharmasth.vali@presidencyuniversity.in
K. Karthick
Assistant Professor/IT, Sona College of Technology, Salem, India
e-mail: karthickk@sonatech.ac.in
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_2
25

26
A. Asha et al.
precision rate to enhance the early detection prediction performance compared to the
existing systems.
Keywords Covid prediction · Feature selection · Classiﬁcation · Deep neural
network · RNN · ICDR · PHR data analysis
1
Introduction
Cloud computing provides various services to the user based on the service infras-
tructure. The medical information process with data analysis provides more excellent
centralized service. Because of the centralized process, information is more signiﬁ-
cant in higher personalized healthcare processing (PHR). The main goal is to provide
services analyzed based on feature selection and medical healthcare data analysis
classiﬁcation. When the evaluation index of the Covid-19 epidemic was constructed
using multi-source data, the old district’s risk level was much higher than in the new
community. Population density is the most critical determinant of infectious diseases.
To carefully evaluate the disease prediction used for early detection and fore-
casting based on providing the dataset, increasing the quick development report and
analysis, and providing treatment is the ﬁnest and most effective way to inhibit the
production of a new type of coronavirus pneumonia. Presently, clinical data mainte-
nance is a signiﬁcant issue in the clinical ﬁeld because of time series data in highly
dependable various differential feature evaluation. Healthcare should offer quality
support of patient data covering illness-related information and predictive analysis.
So clinical data mining is to such an extent that puts away information that cannot
contain missing qualities and excess information. Enormous information creation
and information reduction are fundamental before applying an information handling
calculation that can inﬂuence detection results. Precise and predictable error-free
information makes fast and simple diagnosis.
A new neural network structure is proposed for Covid-19 detection based on
feature extraction and function-based conﬁdence classiﬁcation module rotation
network data. Machine learning (ML) is the science of training a machine that
uses a mathematical model to analyze the learned data. ML has been implemented
to analyze the data and detect interest patterns. Then, veriﬁed data are classiﬁed
following the learning patterns during the learning process. Feature selection in data
processing technology that minimizes data generation begins to function efﬁciently
with dimensionality reduction. The recurrent neural networks (RNNs) display an
exquisitemethodofprovidingregularhealthinformation.Nonetheless,onedisadvan-
tage of RNNs is that forecast execution diminishes when the line length is excessively
high. To conquer this deﬁciency, two-way bidirectional recurrent neural networks
(BRNNs) are assigned in this proposed model as an adaptive model that can be
prepared to utilize all available users’ data from the two headings to improve ﬁgure
execution. RNNs refer to any recurrent neural network with an activation function
to predict the class.

Adaptive Deep Recurrent Neural Network-Based COVID-19 …
27
2
Related Works
The survey aims to provide state-of-the-art methods for introducing researchers’
information, which will clarify how machine learning and deep learning, as well
as data, enhance the Covid-19 state in a broader health community. It delves into
considerable details about the obstacles and the way forward.
Nandakumar et al. [1], described that the modern Covid-19 mathematical models,
such as box models, statistical models, and machine learning models, help to under-
stand which models are better suited for disease prevalence analysis. Marmarelis
et al. [2] proposed a new Adaptive Phase-Space Approach (APSA) method based
on a data-based detection layer and contagious wave layer. Each of these layers was
described by the Riccati equation with adaptive estimated parameters.
Gao et al. [3] developed mean ﬁeld evolutionary dynamics (MFED). It was
inﬂuenced by graph mean ﬁeld games and optimum transport theory, which were
employed in MFED to regulate the evolution of fads by deriving multiple individual
state gain functions from frequently used replication dynamics. Arti [4] proposed a
mathematical model for describing the Covid-19 disease and predicting future waves
of the illness. Forecasting was crucial for the health system’s readiness and the action
plan to be carried out. It was suggested that the Covid-19 disease be described using
Gaussian mixture models.
Tutsoy et al. [5] introduced a new comprehensive, high-order, multidimensional,
robust correlative, and parametric suspected infectious disease mortality model. A
mathematical analysis of Turkey’s death toll shows that the dynamics of Covid-
19 ﬂuctuate little in a stable (limited) state. However, some dynamics are near the
unstable region (inﬁnity). Alvarez et al. [6] proposed the mathematical model for
analyzing the behavior of Argentina’s power system when considering the impact of
Covid-19 on the population. The model achieved an accurate solution achievable in
a short computation time.
Friji et al. [7] proposed the generalized dynamic model with eight states to describe
the progression of the Covid-19 epidemic from vulnerable to displaced conditions
through isolation and hospitalization. Model parameters were determined using the
three observable inputs to solve an appropriate optimization problem (infections,
deaths, and reported cases). The work of Riquelme et al. [8] was particularly inter-
ested in the various datasets and epidemiological models used. The search strategy
included four combined searches on Google Scholar from January 2020 to January
2021. The results showed 30 data sources and 11 marine and terrestrial data sources
used to collect air travel.
The report by Kumari et al. [9] summarized the comprehensive review of newly
developed predictive models and predictions for the number of Covid-19 cases
all over the country, including conﬁrmed, recovered, and fatal cases. Multiple
linear regressions, autocorrelations, and correlation coefﬁcients were employed for
improving accuracy and predictive ability. An efﬁcient method by using an unsuper-
vised Deep Generative Learning-based 1-SVM (DGL-ISVM) data-driven technique
to detect Covid-19 infection from blood test results was presented by Dairi et al. [10].

28
A. Asha et al.
By applying an unsupervised deep mixed model to a blood test, Covid-19 infection
was detected.
A model using ordinary differential equations was described by Giamberardino
et al. [11] as being speciﬁcally developed to describe Covid-19’s evolution in Italy. In
the case of an Italian population distribution model based on national data, obtaining
a numerical solution effectively reproduces the accurate data. Rustam et al. [12]
demonstrated that the ML model could forecast the future number of patients infected
with Covid-19. Speciﬁcally, the study used four standard predictive methods: support
vector machine (SVM), least absolute sum, linear regression, exponential smoothing,
and selection operator to measure the predictability of the Covid-19 factor.
Sear et al. [13] explained that machine learning measures the Covid-19 content of
online institutional health guidance, especially for those who oppose vaccines (anti-
vaccination). The Covid-19 debate focused on the pro-vaccine (pro-vax) community
rather than the anti-vaccine community. Rahman et al. [14] illustrated that the Covid-
19 lockdowns signiﬁcantly improved air quality and reduced respiratory conditions
and illnesses as a result of Covid-19. For solving complex and intractable problems,
like global pandemics, machine learning proved to be a powerful, convenient, and
robust analytical paradigm.
de Oliveira et al. [15] assessed the correlation between laboratory parameters and
Covid-19 test results. Two classiﬁcation models were developed: the ﬁrst for the test
results in Covid-19 patients and the second for test parameters in hospitalized patients
for cell classiﬁcation. Zhan et al. [16] proposed that the ML method for Covid-19
forecasting was based on broad learning system (BLS). Random forest (RF) was
used to show salient features. An RF-packed BLS method was developed combining
packing strategies and BLS, to forecast the course of the Covid-19 epidemic.
Gomes et al. [17] described an interval type 2 fuzzy clustering algorithm
with adaptive similarity distance mechanisms. A relationship between behavior
and epidemiological uncertainty appears to be the mechanism of interval type 2.
Observer/Kalman ﬁlter identiﬁcation and real-time prediction were incorporated into
an ambiguous version of adaptive monitoring based on unobservable components
determined by recursive spectrum decomposition of experimental, epidemiological
data. Wu et al. [18] proposed a framework for optimizing RF and SVM models,
primarily using the Slim Mold algorithm (SMA). Training optimal SVM and RF
models based on SMA to identify critical factors was conducted. Comparative exper-
iments were conducted using RF-SMA and some well-known ML techniques based
on Covid-19 data.
According to Dlamini et al. [19], whole-genome sequencing data from eight
pathogenic strains, including SARS-CoV-2, were analyzed for endogenous dinu-
cleotide gene signatures. By using the extreme gradient boosting model (XGBoost),
DNA sequences were converted into biased dinucleotide frequencies. Capiansoghi
et al. [20] developed a computerized system to extract clinical, radiological, and
laboratory variables pertinent to patient risk prediction, which was analyzed by clin-
icians when assessing the patient’s risk. Using simple decision criteria, the system
was intended to produce an interpretable machine learning system.

Adaptive Deep Recurrent Neural Network-Based COVID-19 …
29
2.1
Problem Identiﬁcation Factors
• The main problem is that improper feature selection leads to high dimen-
sion invariant scaling level; hence, the classiﬁcation does not produce the best
performance.
• Due to learning progress weights, lower precision, and recall rate, it is irregular
to train in the neural network.
• Irrelevant grouping of clusters does not mean the absolute threshold margins to
choose the features.
• The false rate and time complexity are increased due to the back rotation threshold
values. So, the low prediction accuracy causes failure of the Covid ratio.
3
Proposed Method
The proposed method to detect Covid is based on data analysis on an adaptive
deep learning model. It aims to contribute to early risk prediction by analyzing
the feature to classify the risk. In the proposed method, an Adaptive Deep vectorized
Recursive Neural Network (ADVRNN) efﬁciently handles the large dataset values
and improves the performance accuracy and prediction results without complexity.
Proposed architecture RCIFS-ADVRNN is shown in Fig. 1.
Anadaptivedeeprecurrentneuralnetwork-basedCovid-19healthcaredatapredic-
tion for early risk detection has been designed to predict the Covid ratio. The
signiﬁcance of information determination depends on a streamlined set from the
collected dataset from PHR records. It is critical to highlight the decision ratio
from medical margins and choose the time series that are regularly drawn nearer
to increase or decrease margins from the scaling rate, to develop the feature selection
and classiﬁcation based on the optimized neural variety in deep models.
Fig. 1 Proposed architecture RCIFS-ADVRNN

30
A. Asha et al.
The proposed method has been trained to detect Covid-19 infections more
quickly by examining defect levels of relative feature margins to get closer to
improving feature selection and classiﬁcation accuracy. The implementation deﬁnes
the ADVRNN algorithm and trains the testing and training on the medical margins
having the intrinsic rate depending on Intrinsic Covid Defect Rate (ICDR) level to
select the feature. Then the evaluation is in ICDR to choose the threshold margins.
A further preliminary processed dataset is trained into the feature selection process
to identify the best features of Covid-19 using Relative Cluster-Intensive Feature
Selection (RCIFS). The selected features get introduced to an ADVRNN.
3.1
Preprocessing
The augmented reality of the dataset was ﬁrst processed with dataset preparation, as
noise and feature edges are checked at this stage. This support conﬁrms the medical
margins and the presence of the dataset. Initially, the dataset is imported to identify
the missing values and irrelevant data to categorize in the dataset. Then the feature
scaling or selection process is performed.
Algorithm Input: Initialize Covid-19 dataset- Cds.
Output: Preprocessed dataset (Cov-Pd).
Step 1: ˙Initialize to read X →{Cds1, Cds2,…..}
Step 2: Process X(I, J) for all read data to check ﬁelds (Feature).
Step 3: Index Feature counts and List Fl.
Check id Null and empty for all records.
Compute If Fl ←X(I,j) null free.
Reorder index Fl for all X.
Check margins and scaling range of PHR obtained from attributes.
End For.
Step 4: Return Fl ←Ordered sling veriﬁed index.
Step 5: Cov-Pd(Fl).
The algorithm returns the preprocessed values of feature sets from the PHR
dataset. Here, Cds—Covid-19 dataset, Cov-Pd—preprocessed dataset, X—read the
weight, I,j—dataset feature values, and Fl—feature index which is indexed to get the
feature limits and veriﬁcation of scaling levels presented and described in medical
margins. It returns the noise free dataset for identifying the Covid defect rate.
3.2
Intrinsic Covid Defect Rate
In this phase, Covid infection dependencies were estimated from the preprocessed
Covid-19 dataset. This identiﬁes the current margin and time series deﬁciency,

Adaptive Deep Recurrent Neural Network-Based COVID-19 …
31
increasing rate of the feature margins, and their variations. Also, this estimate of the
interrelationship coefﬁcient is of variation scaling of feature limits and the feature
coefﬁcient that determines the defect affected range. This selects the feature margins
for maximum subset of features, combined with the defect rate coordinated feature
limits for feature evaluation.
Algorithm for ICDR
Input: Preprocessed dataset Cov-Pd (Fl)
Output: Covid defect rate (Cdr)
Begin
Step 1: Process the index records Cdr
Step 2: Estimate the Feature margins (Fm) for all records
Select max scale medical feature (Mf) limits (F.I.)
Compare the margins (Mf) and (F.I.)
FI ←(Mf) Max (F.I.)
Evaluate Ec distance for al Fl
End For
Return different scale Choose max limits (Fl (Maxl))
Step 3: If max weight sustains to Compute the Coordinated feature deﬁciency, Cﬁ
Repeat Fi
Process For each Fi(Cﬁ)
Compute Feature margin Level==medical margin
Find the coordinated feature cross limit (m f )
End for
Select subset index weight W(R) of feature relation average
For R = 1 to choose mean weight W(R)
W(R) = W(R) −
n

a=1
di f f (R, Ws, D)/(mX I)
+

R̸=class(F)
[
m(R)
1 −m(class(F))
n

a=1
di f f (R, Ws, D)/(mX I)
End For
Step 4: Estimate the absolute integrated mean rate (Amir)
For each feature ((m f 1 U (m f 2))
Return (Amir f ) ←W(.R.)
End for
Step 5: Select the maximum deﬁciency for each class Cdr ←(Amir f )
End if
The algorithm above provides the feature deﬁcit rate obtained by sub tapping the
feature boundaries. Here, Cov-Pd (Fl)—preprocessed dataset, Fm—feature margins,
mf —medical feature, R—relation average, AMIR—absolute integrated mean rate,
and Ec—Euclidean distance which is the difference between two values limits, and

32
A. Asha et al.
it reduces the unaffected index edges compared to the medical thresholds to improve
the feature score. This way, the deﬁcit level is categorized by class based on the
deﬁcit margins.
3.3
Relative Cluster-Intensive Feature Selection
This relative feature has been selected based on the threshold deﬁnition attained by
medical margins. This chooses the coordinated scaled value by the disease relevance
y, measured based on the ﬁtness evaluation. This determines the best ﬁt case feature
margins to scale the feature dependencies relative to the similarity level. And the
margin range is estimated for coefﬁcient scaling of feature limits, and the defect
affected range determines the feature coefﬁcient.
It groups the search dependencies, establishes integrated comparisons to ﬁnd
similar features, and groups them into cluster indexes. The evaluation was carried
out to predict the feature index by estimating the best-case similarity at an intensive
level.
For choosing max scale Mx ←Fsi, the best match case feature limits are chosen
by getting Fsi samples from Cdr →x = xi wij which deﬁnes integration, where Zij
is the best-case feature evaluation from each threshold margin.
Zi j = xiwi j; Z j =

i Zi j + X j = g

Z j

(1)
Similar features are grouped into cluster Fci as F at each feature. For choosing
the relative index cluster at centroid ‘r’ at the closest mean weight,
f (x f ci) =

iri
(2)
To choose the best-case relevance feature based on kernel attention to get support
value using kernel Function KL, new scaling features are obtained.
Class st = 1
2n
n

i=1

xi
 −xi
2 + β
m

j=1
K L

p
p j

+ λ
2
n

i=1
m

j=1
θ2
i j
⎞
⎠
(3)
By grouping the best-case process at ‘p’ class index,
P(Fmax→c) = Xω∈Ap(ω)
(4)
similarity in the relative margin p(ω) ≥0, as same feature levels are grouped by
centroid value to return group weighted Max class.
The decision is carried out to group the relative features based on max margins to
recommend the suggestive class. These are grouped into cluster index margins and

Adaptive Deep Recurrent Neural Network-Based COVID-19 …
33
scale the weights of comparable groups combined with others to form ascending
index. This reduces the non-related features and increases the feature selection
accuracy for further classiﬁcation.
3.4
Adaptive Deep Vectorized Recursive Neural Network
In this phase, feature selection cluster groups are trained into the proposed adap-
tive vectorization and scaling model deep recurrent neural network. The proposed
ADVRNN algorithm identiﬁes the feature limits’ importance with a re-activated
logical deﬁnition. It constructs a 16 * 16 scaling iteration feed-forward layer to
train the feature cluster with an analytical linearity learning model. It trains the
feature dependencies and logical decisions by activating the conditional deﬁnition
with scaled medical margins based on the threshold limits. It reduces the negative
impactofnon-relationfeaturestopredicttheriskbydeﬁnitionandincreasesaccuracy.
Algorithm for Adaptive Deep vectorized Recursive Neural Network
Input: Preprocessed dataset Cov-Pd (Fl)
Input: Feature cluster group ‘St’
Output: Predicted class by risk
Begin
Initialize the relational cluster index St →Fs
Evaluate the vector coloration based on matrix index Vmt
Set the initial layers based on the feature weights
Set the modiﬁed iterative RNN limitations ε, μ, β (Vmt)
Set feature Clusters Fs(Vmt)
Train the consequences of the feature in feed-forward In neural weights
For ε = 1 cluster class, Vmt to ∈do
For each cluster class to form iteration Let accept μ refers to presentation
rate, ε—repetition phase ε ←0(1 + a)n = 1 +
 na
1!

+
	
n(n−1)a2
1!

.
Compute the loss ranges a lr →∈—maximum number of iterations
β—number of images covered iterations
Compute progressive decision on each margining medical scale ω∗at
n cluster class
Chose the Max scale to feature weight compared to medical margin
Select the index scale by class by preference
End
The ADVRNN predicted the Covid defect rate based on the training class, and the
margins are ﬁtted through threshold margins. The best-case measure validates this by
testing the medical margin comparison to predict the class. μ refers to performance
rate, ε—iteration stage ε ←0 (1 + a)n = 1 +
 na
1!

+
	
n(n−1)a2
1!

, ∈—maximum
number of iterations, and β-number of images covered iterations. The classiﬁcation

34
A. Asha et al.
results also show the prediction accuracy based on the margin classes to point from
different threshold margins depending on risk by category.
4
Experimental Results and Discussion
The implementation was simulated to prove the result performance, and the UCI
database was used to test the performance of various classiﬁers. In this Covid-19
test, samples have 30 features to handle classiﬁcation prediction. Features are (day
wise, month wise, patient name, affected date, temperature, gender, Spo2, etc.).
These attributes are included in Covid-19 data samples dataset. Confusion matrix
rules are to be followed to understand the version of the model for training and
testing. Table 1 shows the proposed implementation environment consideration and
its values. The proposed approach is implemented under various parameters, and
performance is evaluated with a Covid-19 dataset from healthcare monitoring data.
This method measures efﬁciency in the prognosis of a disease based on multiple
functions and their values. The evaluation results are compared to those of other
approaches like Deep Generative Learning-based 1-SVM (DGL-ISVM), Adaptive
Phase-Space Approach (APSA), and Adaptive Synthetic approach (ADASYN).
The performance of routing in the network is measured at different nodes with
different numbers and is illustrated in Fig. 2. The proposed RCIFS-ADVRNN system
has a higher precision and recall rate efﬁciency than other methods at all levels.
Figure 3 shows the clustering performance generated by different methods. The
proposed RCIFS-ADVRNN approach has developed high clustering accuracy under
several other diseases.
The accuracy of the prognosis generated by the various methods was measured
and is shown in Fig. 4. The proposed hybrid approach improved disease outcomes
compared to other approaches in each class.
Figure 5 illustrates the accuracy of disease prognosis based on different tech-
niques. A higher disease prognosis was demonstrated by the proposed RCIFS-
ADVRNN approach than by the approaches from other classes.
Table 1 Environment and
parameters processed
Parameters
Values
Cloud environment
Amazon web service (AWS)
Storage
EBS
Conﬁguration
Txlarge core2
Language, tool used
Python, Jupiter notebook
Dataset used
Covid-19 test samples data

Adaptive Deep Recurrent Neural Network-Based COVID-19 …
35
0
20
40
60
80
100
ADASYN
APSA
DGL-ISVM
RCIFS-ADVRNN
Precison and recall
Performance %
Precision And Recall Rate 
50
100
200
Fig. 2 Performance in precision and recall rate
0
20
40
60
80
100
ADASYN
APSA
DGL-ISVM
RCIFS-ADVRNN
Methods
Clustering Accuracy
50 records
100 records
200 records
Fig. 3 Accuracy in clustering
0
20
40
60
80
100
ADASYN
APSA
DGL-ISVM
RCIFS-ADVRNN
Disease Prediction Accuracy %
Disease Prediction Accuracy
50 records
100 records
200 records
Fig. 4 Analysis of disease prediction accuracy

36
A. Asha et al.
0
10
20
30
40
50 records
100 records
200 records
False Ratio %
False Ratio
ADASYN
APSA
DGL-ISVM
RCIFS-ADVRNN
Fig. 5 Analysis of false classiﬁcation ratio
5
Conclusion
The proposed adaptive deep recurrent neural network is based on Covid-19 health-
care data prediction for early detection. The proposed Relative Cluster-Intensive
Feature Selection (RCIFS) selects the critical feature to reduce the dimension ratio.
The chosen elements are trained with Adaptive Deep vectorized Recursive Neural
Network (ADVRNN) to accurately predict the Covid affected rate based on medical
threshold margins. The proposed RCIFS-ADVRNN system attains high performance
compared to the existing systems. This proves high classiﬁcation and feature selec-
tion accuracy with a precision rate of 97.2%, recall rate of 97.6%, and classiﬁcation
cluster accuracy of 98.2%, which are best compared to other systems. Future work
will include exploring the model with a massive dataset and evaluating the model with
an external dataset deep learning model to be optimized with adaptive methodologies.
References
1. Nandakumar R, Ponnusamy V, Sriharipriya KC, Clement JC (2022) A survey on mathematical,
machine learning and deep learning models for COVID-19 transmission and diagnosis. IEEE
Rev Biomed Eng 15
2. Marmarelis VZ (2020) Predictive modeling of Covid-19 data in the U.S.: adaptive phase-space
approach. IEEE Open J Eng Med Biol 1
3. Gao H, Li W, Pan M, Han Z, Poor HV (2021) Modeling COVID-19 with mean ﬁeld evolutionary
dynamics: social distancing and seasonality. J Commun Netw 23(5)
4. Arti MK (2022) Mathematical modeling of COVID-19 and prediction of upcoming wave. IEEE
J Selected Topics Signal Process 16(2)
5. Tutsoy O, Çolak ¸S, Polat A, Balikci K (2020) A novel parametric model for the prediction and
analysis of the COVID-19 casualties. IEEE Access 8
6. Alvarez GE, Sarli JL (2021) Mathematical model to control the Argentine energy system during
the COVID 19 pandemic. IEEE Latin Am Trans 19(6)
7. Friji H, Hamadi R, Ghazzai H, Besbes H, Massoud Y (2021) A generalized mechanistic model
for assessing and forecasting the spread of the COVID-19 pandemic. IEEE Access 9
8. Riquelme F, Aguilera A, Inostrosa-Psijas A (2021) Contagion modeling and simulation in
transport and air travel networks during the COVID-19 pandemic: a survey. IEEE Access 9

Adaptive Deep Recurrent Neural Network-Based COVID-19 …
37
9. Kumari R et al (2021) Analysis and predictions of spread, recovery, and death caused by
COVID-19 in India. Big Data Mining Anal 4(2)
10. Dairi A, Harrow F, Sun Y (2022) Deep generative learning-based 1-SVM detectors for
unsupervised COVID-19 infection detection using blood tests. IEEE Trans Instrumentation
Measurement 71
11. Giamberardino PD, Iacoviello D, Papa F, Sinisgalli C (2021) Dynamical evolution of COVID-
19 in Italy with an evaluation of the size of the asymptomatic infective population. IEEE J
Biomed Health Inf 25(4)
12. Rustam F et al (2020) COVID-19 future forecasting using supervised machine learning models.
IEEE Access 8:101489–101499
13. Sear RF et al (2020) Quantifying COVID-19 content in the online health opinion war using
machine learning. IEEE Access 8:91886–91893
14. Rahman MM, Paul KC, Hossain MA, Ali GGMN, Rahman MS, Thill J-C (2021) Machine
learning on the COVID-19 pandemic, human mobility and air quality: a review. IEEE Access
9
15. de Oliveira RFAP, Bastos Filho CJA, de Medeiros ACAMVF, Buarque Lins dos Santos PJ,
Lopes Freire D (2021) Machine learning applied in SARS-CoV-2 COVID 19 screening using
clinical analysis parameters. IEEE Latin Am Trans 19(6)
16. Zhan C, Zheng Y, Zhang H, Wen Q (2021) Random-forest-bagging broad learning system with
applications for COVID-19 pandemic. IEEE Internet Things J 8(21)
17. Gomes DCS, Serra GLO (2021) Machine learning model for computational tracking and
forecasting the COVID-19 dynamic propagation. IEEE J Biomed Health Inf 25(3)
18. Wu P et al (2021) An effective machine learning approach for identifying non-severe and severe
coronavirus disease 2019 patients in a rural Chinese population: the Wenzhou retrospective
study. IEEE Access 9
19. Dlamini GS et al (2020) Classiﬁcation of COVID-19 and other pathogenic sequences: a
dinucleotide frequency and machine learning approach. IEEE Access 8
20. Casiraghi E et al (2020) Explainable machine learning for early assessment of COVID-19 risk
prediction in emergency departments. IEEE Access 8

Maximum Decision Support
Regression-Based Advance Secure Data
Encrypt Transmission for Healthcare
Data Sharing in the Cloud Computing
V. Anusuya, B. J. Bejoy, M. Ramkumar, P. Shanmugaraja, B. Dhiyanesh,
and G. Kiruthiga
Abstract The recent growth of cloud computing has led to most companies storing
their data in the cloud and sharing it efﬁciently with authorized users. Health care is
one of the initiatives to adopt cloud computing for services. Both patients and health-
care providers need to have access to patient health information. Healthcare data must
be shared and maintained more securely. While transmitting health data from sender
to receiver through intermediate nodes, intruders can create falsiﬁed data at interme-
diate nodes. Therefore, security is a primary concern when sharing sensitive medical
data. It is thus challenging to share sensitive data in the cloud because of limitations
in resource availability and concerns about data privacy. Healthcare records struggle
to meet the needs of security, privacy, and other regulatory constraints. To address
these difﬁculties, this novel proposes a machine learning-based Maximum Decision
Support Regression (MDSR)-based Advanced Secure Data Encrypt Transmission
(ASDET) approach for efﬁcient data communication in cloud storage. Initially, the
proposed method analyzed the node’s trust, energy, delay, and mobility using Node
V. Anusuya
Associate Professor/CSE, Ramco Institute of Technology, Rajapalayam, India
e-mail: pgkrishanu@gmail.com
B. J. Bejoy (B)
Assistant Professor/CSE, CHRIST (Deemed to Be University), Bangalore, India
e-mail: bejoybj@gmail.com
M. Ramkumar
Associate Professor/CSBS, Knowledge Institute of Technology, Salem, India
e-mail: hod.csbs@kiot.ac.in
P. Shanmugaraja
Associate Professor/IT, Sona College of Technology, Salem, India
e-mail: shanmugarajap@gmail.com
B. Dhiyanesh
Associate Professor/CSE, Dr. N.G.P. Institute of Technology, Coimbatore, India
e-mail: dhiyanu87@gmail.com
G. Kiruthiga
Associate Professor/CSE, IES College of Engineering, Thrissur, India
e-mail: kirthikacsehod@gmail.com
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_3
39

40
V. Anusuya et al.
Efﬁciency Hit Rate (NEHR) method. Then identify the efﬁcient route using an Efﬁ-
cient Spider Optimization Scheme (ESOS) for healthcare data sharing. After that,
MDSR analyzes the malicious node for efﬁcient data transmission in the cloud.
The proposed Advanced Secure Data Encrypt Transmission (ASDET) algorithm
is used to encrypt the data. ASDET achieved 92% in security performance. The
proposed simulation result produces better performance compared with PPDT and
FAHP methods.
Keywords Health care · Cloud computing · Machine learning · Security ·
MDSR · NEHR · ASDET · Malicious node · Energy · Delay
1
Introduction
Manually storing health records and retaining them for future reference is challenging
in managing large amounts of data. The problem with the traditional system of
storing all data manually or on paper is the difﬁculty of locating patient data in
record rooms with large numbers of health records. Finding patient-speciﬁc medical
records requires a lot of time and effort. Data is plain text and easily stolen. Therefore,
anyone can easily access the data in the form to read, write, or modify it. In the
modern world, electronic medical records are widely stored in the cloud. Cloud
computing is a growing technology that frees users from the burden of hardware
maintenance and provides dynamically adaptable and scalable computing resources
that can be accessed anywhere a network is available. On tight budgets, organizations
andthehealthcareindustrycanbeneﬁtfromadvancedcomputingandstorageservices
without investing in infrastructure and maintenance.
However, the loss of control over data and computing raises several security
concerns for organizations and hinders the broader applicability of the public cloud.
However, data sharing in the cloud requires advanced security measures because data
can easily be lost, leaked, or stolen. While transmitting health data from sender to
receiverthroughintermediatenodes,intruderscancreatefalsiﬁeddataatintermediate
nodes. Therefore, security is a primary concern when sharing sensitive medical data.
Data privacy and lightweight operations on resource-constrained sensor nodes are
two challenges associated with sharing sensitive data in the cloud.
Health data includes information about an individual’s medical history, records,
and other personal data. Traindata .csv—File containing features of each case related
to patient, hospital, and duration of stay traindata_dictonary .csv—File containing
information about feature training ﬁles. The test set: Testdata .csv—ﬁle containing
patient and hospital-related characteristics. Need to predict the length of stay for each
case I.D.

Maximum Decision Support Regression-Based Advance Secure Data …
41
1.1
The Novelty of This Paper
• To solve the above problems, the proposed method initially analyzes the node’s
trust, energy, delay, and mobility using Node Efﬁciency Hit Rate (NEHR) method.
• Then identify the efﬁcient route using an Efﬁcient Spider Optimization Scheme
(ESOS) for healthcare data sharing.
• After that, MDSR analyzes the malicious node for efﬁcient data transmission in
the cloud. The proposed Advanced Secure Data Encrypt Transmission (ASDET)
algorithm is used to encrypt the data.
• The proposed simulation result produces better performance compared to with
PPDT and FAHP methods.
2
Related Work
J. Liang et al. (2021) propose that the efﬁcient scheme for monitoring the healthcare
systems is the Privacy-Preserving Decision Tree (PPDT). First, the clinical decision
tree will be changed as a Boolean vector. The PPDT is used to get by search the
encrypted indices and encrypted tokens. PPDT is more effective in evaluating, trans-
mitting, and storing performance analysis. However, this method does not produce
healthcare records.
Jindal et al. [1] propose that the data classiﬁcation method for efﬁcient decision-
making in fuzzy rules-based classiﬁers is designed. A cloud computing environment
gives effective results in different performance evaluation metrics. It is very chal-
lenging to store extensive data in the dataset. Li et al. [2] describe the cloud-based
medical storage system as the Efﬁcient Privacy-Preserving Public Auditing Protocol
(EPPPAP). That information is under the deﬁned security model in detailed security
analysis. The challenge is recovering the oldest data is difﬁcult.
Agrawal et al. [3], the stated that fuzzy AHP-TOPSIS can be used to select an
order of preference based on similarity to an ideal solution. Similarly, Wang et al. [4]
describe the method AHP-TOPSIS. This method suggests future use of the Internet
of Health Things (IoMT).
Zarour et al. [5] present a method for computing blockchain technology’s impact
and a new direction for future research. Criteria weights are calculated using the fuzzy
Analytical Network Process (F-ANP). H. Abrar et al. [6] propose identifying the
essential assets of the Healthcare Information System (HIS) for the security purpose
of cloud computing models. And the HIS impacts the assessing the similarity.
More et al. [7] proposed that image estimation amounts are measured using
Peak Signal Noise Ratios (SNRs), Structural Similarity Indexes (SSIs), and Mean
Squared Errors (MSEs). It increases the image’s potential and improves the image’s
visualization.
Saheed et al. [8] implemented the IoMT method in Deep Recurrent Neural
Network (DRNN). The DRNN method is used to supervise machine learning

42
V. Anusuya et al.
methods, and then the IoMT has random forest, decision tree, and ridge classiﬁer.
Then IoMT environment generates a powerful and well-organized IDS for DRNN.
Niu et al. [9] proposed that data transmitting is reinforced, communication
systems were designed rationally, and all essential data was utilized. Wang et al.
[10] suggested the Diverse Keyword Searchable Encryption (DKSE) method. The
method obtains many practical applications for Multidimensional Numeric Vector
Range Queries (MDDVRQ) and Textual Multi-Keyword Ranking Search (TMKRS).
Su et al. [11] proposed that the platform was tested on different Remote Patient
Monitoring (RPM), providing AI-based anomaly detecting symptoms. This model
achieves fast and accurate treatment for the patient and ensures the information is
conﬁdential. Vargheese [12] describe Cisco’s Cloud Web Security (CWS) method. In
CWS, Cisco Global Threat Intelligence (CGTI), Advanced Threat Defense (ATPC),
and Roamer Protection (RUP) are used to protect users from anywhere, anytime in
the distributed enterprise.
Jain et al. [13] propose securing and retrieving data access for Biometric Signature
Authentication (BSA) scheme being presented using a Recurrent Neural Network
(RNN). Shrihari et al. [14] describe that the method does not need human help
to produce the result. A powerful machine learning method extracts meaningful
information for understanding big data.
Aruna et al. [15] propose the Cloud-based Intelligent Health Monitoring System
(CIHMS) for disputes involving parties and manipulating sensitive records. Yau et al.
[16] describe using the pattern-based data sensitivity framework (PBDSF) method.
The machine learning algorithm can recognize speciﬁc patient data, data frequency,
and different pattern codes identiﬁed under particular conditions to protect critical
records.
Yao et al. [17] propose a neural network (NN) computational approach that is
applied to this model-based electronic health information system in the privacy-
preserving Non-Collusive Dual Cloud (NCDC). Xi et al. [18] concentrate on intro-
ducing hidden backdoor functionality for a collaborative training framework to any
local hospital in joint with the global model.
Chenetal.[19],basedonamulti-classsupportvectormachine(MCSVM)scheme,
proposed a privacy-preserving medical diagnosis scheme (PBMD). Two encryp-
tion systems use this method: Trapdoors Public Key Cryptosystems (DT-PKCs) and
Boneh-Goh-Nissim (BGNs). Hoang et al. [20], propose that the HoloCare system
provides permission and remote access to health record data from another EMR,
giving evidence from a patient’s PHR for authentication.
2.1
Problem Factors
• Essential privacy concerns, clinical decision samples, and biomedical data have
been protected as risks.

Maximum Decision Support Regression-Based Advance Secure Data …
43
• The amount, speed, variety, completeness, and value of patient data collected
through telehealth applications make their big data. Dealing with a collection of
heterogeneous data is one of the biggest challenges.
• Healthcare organizations face a series of data breaches targeting their most
vulnerable medical records.
• It is very challenging to store extensive data in the dataset. It does not produce
healthcare records.
3
Proposed Method
This section explains a machine learning-based Maximum Decision Support
Regression (MDSR)-based Advanced Secure Data Encrypt Transmission (ASDET)
approach for efﬁcient data communication in cloud storage. Our method improves
health care by protecting the privacy and conﬁdentiality of sensitive data and
preventing threats.
Figure 1 deﬁnes the proposed diagram for secure healthcare data sharing in the
cloud environment. The proposed method initially analyzes the node’s trust, energy,
delay, and mobility using the Node Efﬁciency Hit Rate (NEHR) method and then
identify the efﬁcient route using an Efﬁcient Spider Optimization Scheme (ESOS)
for healthcare data sharing. After that, MDSR analyzes the malicious node for efﬁ-
cient data transmission in the cloud. The proposed Advanced Secure Data Encrypt
Transmission (ASDET) algorithm is used to encrypt the data.
Fig. 1 Cloud-based secure data sharing for health care

44
V. Anusuya et al.
3.1
Node Efﬁciency Hit Rate (NEHR)
Inthisphase,theproposedNEHRtechniqueanalyzesthenodetrust,energyconsump-
tion, delay, and bandwidth. Every node calculates when sharing patient information
in the cloud. The hit rate is the number of cache hits divided by the total number
of memory requests for a given time interval. The NEHR algorithm ﬁrst establishes
various conﬁdence factors based on the correlation between adjacent nodes, which
observe each other. The node efﬁciency evaluation is based on the shared information
between sources to destination without path trafﬁc. And the energy consumption is
found based on the total time and the total number of node energy. First, we analyze
the trusted node calculation in Eq. 1.
T n = α1 ∗CPF(T ) + α2 ∗DP(T )
(1)
Let us assume α1 and α2 denotes weights allocated to control forward packet ratio
(CP) and forward data ratio (DPF) at time T. If it is between [0.80 to1], it is considered
a conﬁdence node, and less than that is regarded as a less conﬁdence node.
ECons = ETransmit ∗ERece
β
(2)
Here, the equation is used to calculate the node’s energy consumption, where ETransmit
which refers to transmission and ERece denotes receiver energy and β refers to
normalizing factor.
TraDelay =
 Size(H D)
n
(3)
The above equation is used to identify the healthcare data transmission delay
TraDelay. Here, H D refers to healthcare data size, and n refers to number of nodes.
T mobility =

Esmobility + ECons
(4)
Here, the equation is used to analyze the trusted mobility T mobility based on estimation
of mobility Esmobility and Energy consumption ECons.
T reliable =

D f + ECons
(5)
Here, the equation is used to ﬁnd the trust node reliability T reliable based on data fusion
D f and energy consumption ECons. This section calculates each node’s reliability,
mobility, latency, and energy consumption while sharing healthcare data in the cloud.

Maximum Decision Support Regression-Based Advance Secure Data …
45
3.2
Efﬁcient Spider Optimization Scheme
In this module, based on the spider optimization scheme, we ﬁnd the node’s energy
consumption, distance, rate of sending packets, rate of received packets, and node
availability, thereby designing the routing to share health data in the cloud. The
proposed ESOS is an optimization technique inspired by the foraging behavior of
spiders. Spider optimization is ﬁnding the next vibration based on the following
maximum nearest weights of the features and estimated the information in the feature
selection part. The spider moves to a new node position and the resulting vibrations
travel through the web. This vibration is generated by each spider and stored as node
information, and other spiders on the web receive information based on the vibrations
created by PPDT and FAHP spiders.
Disnode =

|l1 −l2|2 + |O1 −O2|2
(6)
The above equation is used to ﬁnd the distance between two nodes using Euclidean
distance. The initial location of two nodes angel (l1,l2) and (O1, O2), respectively.
EResi = I Energy −ECons
I Energy
(7)
The above equation ﬁnds each node’s residential energy

EResi
. Let us assume
I Energy represents initial energy and ECons energy consumption.
SW = Fitnessi −Wt
bt −Wt
(8)
The above equation is used to ﬁnd the spider weightage Wt, Fitnessi which denotes
ﬁtness of i-th spider position and Wt, bt denotes worst and best ﬁtness, respectively.
Svibration = SW ∗eDisnode(y,z)
(9)
Theaboveequationﬁndsspidervibration(Svibration)tochoosebestnodeforhealth-
care data sharing in the cloud environment. Here, we assume x and z denote two
neighbor nodes.
RPrate =
 N

Rp

y,z(T ) −

Rp

y,z(T −1)
N

Rp

y,z(T ) +

Rp

y,z(T −1)
(10)
The above equation analyzes the packet received rate RPrate at time T, where N
refers to number nodes and Rp Denotes healthcare data received nodes.
SPrate =
SPN(y,z)(T )
SPN(y,z)(T ) + SPry,z(T )
(11)

46
V. Anusuya et al.
The above equation is used for healthcare data sending rate (SPrate) based on
needing several sent packets SPN and a repeated number of transmitted packets SPr.
N avail =
Ackyz(T )
Ackyz(T ) + NAckyz(T )
(12)
The above equation is used to analyze node availability (N avail) acknowledgment
at time T. Here, assume Ack is the responding node, and NAck is the non-respond
node at time T. This module efﬁciently creates the route for healthcare data sharing
in a cloud environment using ESOS. This method proﬁciently analyzes the route
based on spider vibration, and this vibration has an essential feature of the node.
3.3
Maximum Decision Support Regression
The proposed Maximum Decision Support Regression (MDSR) detects the essential
features of the node in this section. It considers the packet delivery rate, efﬁciency,
and ﬁtness function as important aspects of the node. This method takes only the
most supported results. Then the proposed method identiﬁes whether the node is
malicious or not.
Algorithm for Maximum Decision Support Regression (MDSR).
Begin function
Import the node population
For each node Ny,z = 1 do
Calculate the packet delivery ratio (Pratio)
Pratio =
 Reced
sentd
Calculate throughput performance (ThroughP)
ThroughP =
 ST
T
If identify the intruder node Intrudernode
Intrudernode = 1 −
Recenode −Comnode
Rn

End if.
Compute node ﬁtness function NodeFit
NodeFit = α1Enode + α2
1
TraDelay + α3
1
Disnode

Maximum Decision Support Regression-Based Advance Secure Data …
47
End for
End function
The proposed algorithm steps identify the node features based on throughput
ThroughP, packet delivery ratio (Pratio), and check malicious node during health-
care data sharing in the cloud. Here, we assume Recenode denotes the received node,
Comnode compromised node, and Rn is the round number. ST denotes packet success-
fully sent at time T. Then α1, α2, α3 weight coefﬁcients and Enode is the energy
node.
3.4
Advanced Secure Data Encrypt Transmission (ASDET)
The proposed Advanced Secure Data Encrypt Transmission (ASDET) method in this
module facilitates the secure transport of health data. First, it reads the health data
as input, generates a key for it, converts it into a binary value corresponding to the
characters in the data, and then converts it into ASCII values. The proposed method
transforms that data into an unreadable format. The proposed Advanced Secure Data
Encrypt Transmission (ASDET) technique is used to convert plain healthcare data
into cipher text CText proﬁciently.
Algorithm Steps for Advanced Secure Data Encrypt Transmission (ASDET)
Begin function
Read input healthcare data (Hd)
For each node N(y,z) = 1 do
Randomly Generate key Gk = (pk,sk)
Separate the plaintext into two and calculate the Binary value
Compute equivalent values
CText = Hd + Gk mod 256
Sort the CText
End for
Stop function
Here, assume that pk,sk are private key and public key, respectively. This proposed
technique efﬁciently secures the healthcare data in the cloud environment.
4
Result and Discussion
This section describes the simulation results of the proposed and existing algorithms
by analyzing and evaluating them. The proposed algorithm Maximum Decision
Support Regression-based Advanced Secure Data Encrypt Transmission (MDSR-
ASDET) and the existing algorithms such as Privacy-Preserving Decision Tree
(PPDT) and Fuzzy Analytical Hierarchy Process (FAHP) simulation parameters have
been evaluated.

48
V. Anusuya et al.
Table 1 Simulation
parameters
Parameters
Values
Tool name
Visual Studio 2012
Front end
Asp.Net
Number of data
40
Trafﬁc
Constant Bit Rate (CBR)
Cloud type
AWS
File size
25 GB, 50 GB and 75 GB
Table 1 deﬁnes the simulation parameters of the proposed implementation in
Visual Studio 2012. The proposed algorithm parameters are throughput performance,
latency performance, security and cloud storage. Based on the health data attribute,
several data is counted, so the count takes from 10 to 40.
Figure 2 illustrates the performance of the OBS network when it comes to
throughput. According to our analysis, the proposed MDSR-ASDET algorithm
achieves 89% throughput performance. In addition, the current algorithms perform
better than the existing algorithms in terms of
Throughput Performance = (number of data requests)/(total time)
The throughput performance evaluates the packet delivery ratio based on the
number of packets sent to the destination divided by the overall packet count. The
proposed method is 89% the same as the throughput and delivery ratio in throughput
performance.
Figure 3 deﬁnes the latency performance for healthcare data sharing in the cloud
via nodes. The proposed MDSR-ASDET algorithm result is 14 ms. Additionally, the
existing algorithm results are 20 ms for the PPDT and 17 ms for FAHP, respectively.
Figure 4 deﬁnes the graph’s comparison of healthcare data sharing security perfor-
mance results. In the chart analysis, the proposed method produces better security
0
20
40
60
80
100
10
20
30
40
Throughput in %
Node count
Throughput performance
PPDT
FAHP
MDSR-ASDET
Fig. 2 Analysis of throughput performance

Maximum Decision Support Regression-Based Advance Secure Data …
49
0
5
10
15
20
25
30
35
40
0
5
10
15
20
25
30
35
40
45
Delay Performanance in ms
Node count
Latency Performance
PPDT
FAHP
MDSR-ASDET
Fig. 3 Analysis latency performance
0
20
40
60
80
100
10
20
30
40
Security in %
Node count
Security performance
PPDT
FAHP
MDSR-ASDET
Fig. 4 Comparison of security performance
performance than previous methods. The proposed MDSR-ASDET technique has a
security result is 92%.
Figure 5 explores the healthcare cloud storage data performance of the proposed
and existing performance shown in the graph. The proposed method cloud storage
result has 43% for 75 GB ﬁles. Similarly, the existing PPDT result was 80%, and the
FAHP result was 74% for 75 GB ﬁles.
5
Conclusion
To conclude, this paper introduced a machine learning-based Maximum Decision
Support Regression (MDSR)-based Advanced Secure Data Encrypt Transmission
(ASDET) approach for efﬁcient data communication in cloud storage. Initially, the
proposed method analyzes the node’s trust, energy, delay, and mobility using Node

50
V. Anusuya et al.
0
20
40
60
80
100
0
20
40
60
80
100
Storage in %
File size in GB
Cloud Stroage Performance
PPDT
FAHP
MDSR-ASDET
Fig. 5 Result of cloud storage
Efﬁciency Hit Rate (NEHR) method. Then identify the efﬁcient route using an Efﬁ-
cient Spider Optimization Scheme (ESOS) for healthcare data sharing. After that,
MDSR analyzes the malicious node for efﬁcient data transmission in the cloud. The
proposed Advanced Secure Data Encrypt Transmission (ASDET) algorithm is used
to encrypt the data. Simulation results produced by the proposed method are superior
to previous methods.
References
1. JindalA,DuaA,KumarN,DasAK,VasilakosAv,RodriguesJJPC(2018)Providinghealthcare-
as-a-service using fuzzy rule based big data analytics in cloud computing. IEEE J Biomed
Health Inf 22:1605–1618
2. Li X, Liu S, Lu R, Khan MK, Gu K, Zhang X (2022) An efﬁcient privacy-preserving public
auditing protocol for cloud-based medical storage system. IEEE J Biomed Health Inf 26:2020–
2031
3. Agrawal et al (2020) Evaluating the security impact of healthcare web applications through
fuzzy based hybrid approach of multi-criteria decision-making analysis. IEEE Access
8:135770–135783
4. Wang L, Ali Y, Nazir S, Niazi M (2020) ISA evaluation framework for security of internet of
health things system using AHP-TOPSIS Methods. IEEE Access 8:152316–152332
5. Zarour M et al (2020) Evaluating the impact of blockchain models for secure and trust-worthy
electronic healthcare records. IEEE Access 8:157959–157973
6. Abrar H et al (2018) Risk analysis of cloud sourcing in healthcare and public health industry.
IEEE Access 6:19140–19150
7. More S et al (2020) Security assured CNN-based model for reconstruction of medical images
on the internet of healthcare things. IEEE Access 8:126333–126346
8. Saheed YK, Arowolo MO (2021) Efﬁcient cyber attack detection on the internet of medical
things-smart environment based on deep recurrent neural network and machine learning
algorithms. IEEE Access 9:161546–161554
9. Niu W, Huang J, Xing Z, Chen J (2019) Knowledge spillovers of medical big data under
hierarchical medical system and patients’ medical treatment decisions. IEEE Access 7:55770–
55779

Maximum Decision Support Regression-Based Advance Secure Data …
51
10. Wang X, Ma J, Miao Y, Liu X, Yang R (2022) Privacy-preserving diverse keyword search and
online pre-diagnosis in cloud computing. IEEE Trans Services Comput 15:710–723
11. Su H et al (2021) Cloud computing management architecture for digital health remote patient
monitoring. In: 2021 IEEE International Conference on Smart Computing (SMARTCOMP),
pp 209–214
12. Vargheese R (2014) Dynamic protection for critical health care systems using Cisco CWS:
unleashing the power of big data analytics. In: 2014 ﬁfth international conference on computing
for geospatial research and application, pp 77–81
13. Jain, Tripathi K (2018) Biometric signature authentication scheme with RNN (BIOSIG_RNN)
machine learning approach. In: 2018 3rd international conference on Contemporary Computing
and Informatics (IC3I), pp 298–305
14. Shrihari MR, Manjunath TN, Archana RA, Hegadi RS (2022) Enhanced efﬁcient and security in
big data using TDES and machine learning technique. In: 2022 IEEE International Conference
on Distributed Computing and Electrical Circuits and Electronics (ICDCECE), pp 1–6
15. Aruna M, Arulkumar V, Deepa M, Latha GCP (2022) Medical healthcare system with hybrid
block based predictive models for quality preserving in medical images using machine learning
techniques. In: 2022 International Conference on Advanced Computing Technologies and
Applications (ICACTA), pp 1–10
16. Yau YC, Khethavath p, Figueroa JA (2019) Secure pattern-based data sensitivity framework for
big data in healthcare. In: 2019 IEEE international conference on big data, cloud computing,
data science & engineering (BCD), pp 65–70
17. Yao Y, Zhao Z, Chang X, Miši´c J, Miši´c VB, Wang J (2021) A novel privacy-preserving
neural network computing approach for E-Health information system. In: ICC 2021—IEEE
international conference on communications, pp 1–6
18. Xi B, Li S, Li J, Liu H, Liu H, Zhu H (2021) BatFL: backdoor detection on federated learning in
e-health. In: 2021 IEEE/ACM 29th international symposium on Quality of Service (IWQOS),
pp 1–10
19. Chen Y, Mao Q, Wang B, Duan P, Zhang B, Hong Z (2022) Privacy-preserving multi-class
support vector machine model on medical diagnosis. IEEE J Biomed Health Inf 26:3342–3353
20. Zheng X, Mukkamala RR, Vatrapu R, Ordieres-Mere J (2018) Blockchain-based personal
health data sharing system using cloud storage. In: 2018 IEEE 20th international conference
on e-Health networking, applications and services (Healthcom), pp 1–6

Routing Integrity Mechanism to Prevent
Wormhole Attacks in Vehicular Adhoc
Networks
R. Prathap Kumar, U. Srilakshmi, and K. Ganesh Reddy
Abstract The ﬁeld is experiencing an increase in research ﬁnding due to the signiﬁ-
canceofVANETsinthecontemporaryworld.Routingisessentialforvehiclecommu-
nication in a VANET, but choosing the best route can be challenging given how
quickly cars move. On these routing paths, it is still challenging to prevent attacks
like wormhole, greyhole, and sinkhole attacks. Researchers have created defensive
mechanisms, but because routing packets frequently lack message integrity, they are
insufﬁcient. In this paper, we have proposed a delay-sensitive routing parameters
with integrity mechanism to detect and prevent the wormhole attack. In this study,
we found vulnerable routing parameters for wormhole attack detection and secured
them with hash functions. Our tests demonstrate that vehicle communication protect
against wormhole attacks. This implies that throughput is higher and more packets
are delivered even in hostile environments.
Keywords Vehicular ad hoc networks · Vehicle to vehicle · Vehicle to
infrastructure · Wormhole attack · Source · Destination · Throughput · Round-trip
time
1
Introduction
According to the WHO, vehicle accidents are among the top ﬁve causes of mortality
and property damage (World Health Organization). According to the World Health
Organization, 1.35 million people are killed in road accidents each year, with an
additional 20–50 million wounded in varying degrees of seriousness. The world is
split into three parts: The three economic kinds are high-income nations, middle-
income countries, and low-income countries. Accidents are highly prevalent in the
R. Prathap Kumar (B) · U. Srilakshmi
VFSTR Deemed to be University, Vadlamudi, Guntur, Andhra Pradesh 522213, India
e-mail: rpk_cse@vigann.ac.in
K. Ganesh Reddy
VIT-AP Universtiy, Amaravati, Andhra Pradesh, India
e-mail: ganesh.reddy@vitap.ac.in
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_4
53

54
R. Prathap Kumar et al.
Fig. 1 Types of WANET
low and middle classes (approx 93%). Trafﬁc accidents have taken thousands of
lives and billions of dollars throughout the world, forcing the improvement of new
technology and techniques to help in their prevention.
Several attempts in the literature have been made to ﬁnd technology that can
prevent accidents, and VANET solutions have been advocated. Due to its security,
VANET has risen in popularity. ITS, MANET, and IoT are all part of the system.
While several wireless network research topics have been explored, VANET has
emerged as the key ﬁeld of study. Types of WANET are shown in Fig. 1.
The network is made of many vehicles and other devices that may communicate
with one another and exchange information. VANET has emerged as a viable subclass
or variation with the advent of the MANET class. A VANET secures the safety of
both the driver and the passengers, as well as a pleasant ride for both. VANETs
link with roadside devices and other cars by using real automobiles as nodes. The
communication protocols V2V and V2I are utilized in VANET. The network is made
up of several cars and other equipment that may communicate and share data with one
another. utilizing MANET concepts, but with the automobiles doing additional func-
tions such as nodes. The data of each vehicle will be kept and shared by all vehicles.
After all network nodes have exchanged information, the information is collected
and combined before being sent to all connected devices. You can join and exit the
VARENT network whenever you choose. While VANET has mostly been utilized for
safety purposes, it is sometimes used for non-safety purposes. Riders can be advised
and warned of a range of concerns, such as an accident, detour, or avoidable collision.
There is a shortage of data on trafﬁc, parking, gas stations, and hotels. The whole
network architecture is represented. The whole network architecture is represented
in the Proceedings in Information and Communication Technology (PICT).

Routing Integrity Mechanism to Prevent Wormhole Attacks in Vehicular …
55
Fig. 2 VANET architecture
VANET Architecture
The VANET design aims to deliver pertinent information to the network’s nodes and
routers. Every piece of data needed to create and sustain a vehicle is kept in each
one, updated anytime something changes, and distributed throughout the network.
Each car acts as a sender, receiver, or router in this scenario. V2V, V2I, V2V, and
V2I constitute one of the four categories for VANET architecture [1–7]. Informa-
tion can be sent via a variety of methods, which the transmitter and receiver of the
communication exchange back and forth [8]. You must incorporate the following in
order to create a VANET network: “application unit”, “on-board unit”, and “remote
support unit”) (roadside unit). VANET architecture is shown in Fig. 2.
External wormhole attack in VANET
An external wormhole attack attempts to induce network nodes to route their trafﬁc
through a long, malicious tunnel that is broadcast across the network with low laten-
cies and a low hop count. At least, two attacker nodes with an illegitimate long
communication link are required to carry out this attack. The attacker node at one
end of the malicious tunnel receives data from its neighbouring nodes and sends it
to the attacker at the other end of the tunnel. Rather than forwarding these packets,
the attacker drops/injects malicious packets into the data trafﬁc. External malicious
vehicles formed the wormhole is shown in Fig. 3.
Internal Wormhole attack in VANET
The goal of an internal wormhole attack is to attract network nodes to forward
their trafﬁc through a long, malicious tunnel that is broadcast over the network
with low latencies and less hop count. In order to carry out this attack, at least two
attacker nodes are required. One attacker node encapsulates the request packet, and

56
R. Prathap Kumar et al.
Fig. 3 External malicious vehicles formed the wormhole
the other attacker node decapsulates it. The actual hop count and latency of the packet
are not updated by the other intermediate node(s) in the routing path throughout
the encapsulation and decapsulation operations. Here, internal wormhole attackers
exploit the attack on the integrity of the route request and reply messages.
Compared to external wormhole attacks, internal wormhole attacks are easy
to create without any special resources like long-distance communication links.
However, internal wormhole attacks are difﬁcult to detect because of the nodes’
mobilityandtheattacker’sabilitytoencapsulateorencapsulatetheroutemessages.In
this paper, we address both internal and external wormhole attacks. Internal malicious
vehicles formed the wormhole is shown in Fig. 4.
Fig. 4 Internal malicious vehicles formed the wormhole

Routing Integrity Mechanism to Prevent Wormhole Attacks in Vehicular …
57
2
Literature
We have studied the VANET security mechanisms under three categories in this
section. First one is detection mechanisms, second one is prevention mechanisms,
and third one is both prevention and detection mechanism.
AlFarraj et al. [9] proposed the dependable neighbouring group nodes on their
work with the activation function. The plan’s goal was to strengthen the security
measures that were already in place. The authors used energy consumption to calcu-
late the signiﬁcance of the weight of conﬁdence. We were able to estimate the
node using an additive measure without jeopardizing the dependability of the node’s
neighbouring nodes.
Ahmed et al. [10] proposed TESRP, which stands for Trust and Energy-aware
Secure Routing Protocol. In this method, the authors used a distributed trust model
to identify bad actors. When it comes to routing, a strategy that incorporates a number
of different factors has been shown to be the most successful. The authors were able
to signiﬁcantly improve the network’s energy efﬁciency. Mehetre and colleagues
[11] proposed a method for secure routing that is based on mutual trust between
network nodes. The authors recommend using a two-level security and two-level
trust planning system to select the node and to encrypt the data packet. For the
reliable communication, authors used cuckoo search algorithm.
Innovative technological solutions put forward by Tyagi et al. [12] to evaluate
the effectiveness of VANET safety measures The AODV protocol has been altered
in response to the ﬁndings of the investigation into the blackhole attack. The RREP
packet has been altered to improve its ability to detect blackhole attacks, and all of
the data pertaining to route replies has been moved to a lookup table. A cross-layer
detection strategy that is based on the link state routing (LSR) protocol was developed
by Baiad et al. [13] with the intention of improving the quality of service (QoS). A
monitoring node is used in order to determine whether or not a data packet is valid.
As a consequence, it was discovered that the protocol outperforms previous ways of
detecting black holes while also lowering the amount of false positives.
According to Parmar Amish et al idea’s a wormhole attack may be thwarted
provided each node stores crucial information about its neighbours in its routing. If
a route cannot be found, the node will search for the information in the route table
it keeps, send out a response packet, and wait for a response. A node will resend
a request packet along the same path that it originally sent it along after receiving
it at that node. The sender will conclude that there is a substantial amount of road
available if sender receives more than one reply packet. When the estimated round-
trip time (RTT) is below the threshold, the sending node will launch a wormhole
attack by dropping those routes [14].
The presented scheme uses AODV. Simulations with 100 nodes showed high
detection accuracy without storage needs. The study cited in Reference (Ref.) [15]
presented its ﬁndings as an energy-saving wormhole defence scheme (EPSMAW).
EPSMAW reduces end-to-end delay, energy use, and trafﬁc overhead. The proposed

58
R. Prathap Kumar et al.
solution uses AODV routing and is based on neighbour and connectivity information.
Simulations with 150 nodes showed high throughput and low false positives.
Hanif et al. [16] presented a software-deﬁned network-based method for worm-
hole detection. It uses neighbour similarities. Replicas Python-written method tested
on 100,000-node network After computing the NSI and ACI, the K-means clustering
method was used. SWAN can detect wormholes with low communication overhead,
FPR, and FNR.
Bai et al. [17] presented a wormhole detection scheme for 3D networks. This
scheme was based solely on node connectivity. The MAXIS algorithm is greedy. The
suggested method is simple. Detection rate was calculated using different node densi-
ties. The ﬁndings showed the method’s 90% accuracy. Greedy algorithms cannot ﬁnd
the best solution. According to Reference [16], NIAPC was proposed as a solution
that offers high accuracy, PDR, and throughput.
A cluster-based model has been proposed as a MANET defence mechanism
against wormhole attacks [18]. In particular, a location-based geo-casting and
forwarding (LGF) protocol and a k++ means clustering algorithm were used to ensure
the highest level of conﬁdentiality and to ﬁnd the most time and resource-efﬁcient
route. Load balancing, delivery ratio, and delay from beginning to end were used to
evaluate performance. Furthermore, the AODV protocol’s dynamic routing resulted
in an unprotected send and receive. Wormholes posed a signiﬁcant challenge due
to the possibility of node intrusion during the dynamic routing request process. An
energy model [19] was implemented to help in the detection of wormhole attacks.
We determined how much power could be transmitted at once and how much energy
each node had during this stage of the process.
In [20], deep learning is proposed to be used in the development of an intrusion
detection system (IDS) for on-board units. A PCAP ﬁle is created to store data before
it is processed. Deep learning techniques such as LSTM and CNN are used here.
After the data has been extracted using a CNN, machine learning is performed using
a three-layered LSTM while taking the temporal context of the data into account.
The LSTM uses the results generated by the CNN as its data source. DeepVCM
is composed of two layers of convolutional neural networks (CNN), two layers of
max-pooling, two layers of local response normalization, and three layers of long
short-term memory (LSTM). Max-pooling receives the results generated by the CNN
layer as an input. The most recent version of DeepVCM can be downloaded and
installed automatically. Despite having to work within a limited set of constraints,
the proposed model produced impressive results.
As part of their intrusion detection system (IDS) proposal, the authors of [21]
employ a dynamic neuro-fuzzy system to search for evidence of routing attacks.
The scalability of individual nodes as well as the overall network reach is being
investigated and analysed. The simulations are run using the software MATLAB. In
terms of throughput, average download relay, end-to-end delay, and packet loss rate,
the proposed method outperforms the existing methods.
In [22], a novel clustering-based optimization technique is proposed. It has been
observed that it will improve the effectiveness of V2V communication even further.
In this paper, the vehicle nodes are clustered using the K-Medoid clustering model

Routing Integrity Mechanism to Prevent Wormhole Attacks in Vehicular …
59
and then used to improve energy efﬁciency. To establish an energy efﬁcient commu-
nication methodology, a metaheuristic algorithm is used. Based on the simulation
analysis, it is clear that this methodology requires less execution time and improves
the energy efﬁciency of the nodes.
Based on our study, we observed that existing detection mechanisms for worm-
hole attacks in VANET have a high false positive and false negative rate. Most
existing security mechanisms do not consider vehicle location and message integrity
when identifying malicious functionalities, resulting in inadequate detection and
prevention of wormhole attacks on VANET.
3
Delay-Sensitive Message Integrity Mechanism to Isolate
the Wormhole Attacks
Detect and prevent wormhole attack, we have added the timestamp-based message
integrity in the route request message. Initially, nodes need to identify the average
communication link delay (avg_del) in VANET,
Avgdelay = (n−1
i=1 (pi + ti))
n −1
+
n
i=1(proi + qi

)
n
(1)
where n is the number of nodes, pi propagation delay, ti transmission delay, Proi
processing delay, and qi queuing delay.
We have considered the source IP address, destination IP address, and timestamp
of route request/ reply message to create message digest. We use SHA-256 algorithm
to create message digest by considering these three parameters.
H(M) = {Source IP, Destination IP, Timestamp}
(2)
Route Request (RREQ)/Route Reply (RREQ) packet: General ﬁelds in the route
request and reply packets are source IP, destination IP, sequence number, hop_count,
timestamp, and time to live (TTL). In addition to that, we have added the message
digest to provide message integrity.
Source IP
Destination IP
Sequence number
Hop_count
Timestamp
TTL
H(M)
RREQ and RREP packets use H(M) for veriﬁcation
When the source vehicle (S) needs to form a route to the destination vehicle (D) in
our proposed algorithm, S must ﬁrst ﬁnd the path to D. S broadcasts the route request
packet in order to ﬁnd the route to the destination node. Request packets contain the
request packet’s timestamp and message digest, which cannot be changed by any
other network vehicle. Before broadcasting into the network, all intermediate nodes
update the hop count. In our proposed work, intermediate vehicles do not need to
perform request message veriﬁcation, which reduces the computational overhead at

60
R. Prathap Kumar et al.
intermediate vehicles. When the D receives a request packet, it veriﬁes the integrity
of the request packet (RREQ) using a hash function and the minimum hop count in
relation to time. If both conditions are met, D generates a reply message and forwards
it to S via the reverse path. If one or both of the conditions are not met, D drops the
RREQ packet due to a wormhole attacker in the path. Similarly, upon receiving the
reply packet, S veriﬁes the replay packet integrity using a hash function and the
minimum hop count in relation to time. If both conditions are met, S chooses the
path to forward the data packets, as explained in algorithm 1.
Algorithm: Delay-sensitive message integrity mechanism to isolate the wormhole
attacks
Inputs: Route request and replay messages, number of vehicles(n), malicious
tunnels, and legitimate links
Output: detect and isolate malicious tunnels
1. Source vehicle broadcast RREQ packet to ﬁnd the route to destination
2. If(source IP = Receiver IP)
3.
Drop the RREP packet
4.
else if (Source IP ̸= Receiver IP && Destination IP ̸= Receiver IP)
5. Hopcout&#xF0DF; +1
6.
broadcast the RREQ packet
7.
else if (Destination IP = Receiver IP)
8. if (Avgdelay > (rtimestamp-timestamp)/n)
9.
Current path between source and destination contains wormhole attack
10.
Drop the RREQ packet
11. else
12. Destination vehicle sends RREP to source vehicle in the reverse path
13. /*Reply packet*/
14. if (Source IP ̸= Receiver IP)
15. Forword the RREP packet to next router
16. else if (Source IP = Receiver IP)
17. if (Avgdelay > (rtimestamp-timestamp)/n)
18.
Current path between source and destination contains wormhole attack
19. Drop the RREP packet
20.
else
21. NO internal worm hole existing between source and destination path
4
Result Analysis
We have created a VANET scenario using SUMO tool then the code converts in to tcl
ﬁle which is directly executed in the network simulator (ns2). NS2 environment was
used to run VANET scenario and test our proposed notion in a hostile environment. In
a network, we believe there are ﬁfty valid nodes. UDP trafﬁc is used by network nodes
to communicate. Eight rushing attackers will attack the UDP trafﬁc. According to the
network dimensions, all vehicles are conﬁgured with 802.11p MAC protocol. Table

Routing Integrity Mechanism to Prevent Wormhole Attacks in Vehicular …
61
Table 1 Simulation
parameters
Parameter
Value
Non-malicious nodes
50
Routing protocol
AODV
MAC
802.11p
Queue type
Drop-tail
Packet Size
512 bytes
Transport protocol
UDP
Network area
5000 m × 5000 m
Mobility
Random-way point
Number of wormhole attackers
8
Simulation time
100 s
1 shows a number of network setups. We have considered the ad hoc on-demand
distance vector routing protocol for path selection, and to avoid the congestion, we
used drop-tail queue. The vehicles move in the 5000 m × 5000 m coverage area.
The vehicles use a random-way point mobility model, and the total simulation time
is 100 s for attack, non-attack, and proposed systems.
We have implemented the wormhole attacks in which the one end of the wormhole
tunnel attacker receives the packets from the source vehicles and forward these
packets to the other end wormhole attacker. Upon receiving the packets, the attacker
performs the
• Dropping all packets
• Dropping selective packets
• Reordering packets
• Injecting malicious packets
• Increase the queuing delay of each packet.
Throughput: The throughput is deﬁned as the number of data packets success-
fully transmitted per unit time. We have compared our proposed delay-sensitive
routing parameter with integrity throughput with the round-trip time (RTT) mech-
anism [7] and attacks scenarios [12] which is shown in Fig. 5. Based on our results,
our proposed mechanism has better throughput then attack scenario, and some our
proposed approach has shown better performance than non-attack scenario due to
selecting best paths.
Packet Delivery Ratio (PDR): We also checked the network performance in terms
of PDR. We observed that the PDR value is 3% in the attack scenario and 41% for
RTT approaches. The PDR value in our proposed approach is 87%. This shows our
proposed approach outperforms the attack and RTT approaches. This is because of
prevention of long-distance paths and isolating the more collision prone links in the
communication, and these analysis results are shown in above Fig. 6.

62
R. Prathap Kumar et al.
Fig. 5 Throughput comparison analysis
Fig. 6 PDR comparison analysis
5
Conclusions
In this paper, we have identiﬁed the shortcomings of existing wormhole detection
mechanisms and propose delay-sensitive routing parameters with an integrity mech-
anism to prevent internal wormhole attacks in VANET. Internal wormhole attacks are
more efﬁciently detected and isolated in our proposed mechanism because both route
request and reply messages are veriﬁed with minimum delay values and any modi-
ﬁcation of routing parameters at each node in the active path. In our experimental
analysis, we compared our proposed mechanism to the existing solutions, and we
discovered that our proposed mechanism isolates the wormhole attacks immediately
after they happen. As a result, our proposed approach provides ﬁve times better
throughput than existing mechanisms and an 87% packet delivery ratio in an attack
environment. In our future work, we need to consider cross-layer metrics like vehicle
communication range, channel error rate from the physical layer, and queue size from
the MAC layer to detect wormhole attacks.

Routing Integrity Mechanism to Prevent Wormhole Attacks in Vehicular …
63
References
1. Vamshi Krishna K, Ganesh Reddy (2021) A delay sensitive multi-path selection to prevent
the rushing attack in VANET. In: 5th ınternational conference on Information Systems and
Computer Networks (ISCON), IEEE Conference ,India
2. Ganesh Reddy K, Santhi Thilagam P (2019) Trust-based hybrid ids for rushing attacks in
wireless mesh networks. In: Recent advances in computer based systems, processes and
applications: proceedings of recent advances in computer based systems, processes and
applications
3. Tyagi P, Dembla D (2017) Performance analysis and implementation of proposed mechanism
for detection and prevention of security attacks in routing protocols of vehicular ad- hoc network
(VANET). Egyptian Inf J 18(2):133–139. ISSN 1110-8665
4. Ravula PK, Shanmugam M (2020) A detailed case study on VANET security requirements,
attacks and challenges, advances in modelling and analysis B, IIETA, Scopus,Unpaid, vol 62,
no 2–4, pp 48–52. ISSN NO:1240-4543
5. Prathap Kumar R, Murli Krishna Reddy D, Parimala G, Deva Kumar S (2021) Impacts of
wormhole and black hole attacks ın VANETS. In: Design engineering , ISSN: 0011-9342,
issue 7, pp 2128–2146
6. Garnepudi P, Vesalapu S, Vidyullatha P, Mayuri AVR, Prathap Kumar R (2021) An efﬁcient
algorithm for enhancing QOS in VANET. Turkish Online J Qual Inquiry (TOJQI) 12(3):4420–
4430. ISSN: 1309-6591
7. Taleb (2018) VANET routing protocols and architectures: an overview. J Comput Sci
14(3):423–434
8. Tomar R, Prateek M, Sastry H (2016) Vehicular Adhoc Network (VANET)—an introduction,
vol 9, pp 8883–8888
9. Osama A, AlZubi A, Tolba A (2018) Trust-based neighbor selection using activation function
for secure routing in wireless sensor networks. J Ambient Intell Humanized Comput 1–11
10. Ahmed A, Bakar K, Channa M, Khan (2016) A secure routing protocol with trust and energy
awareness for wireless sensor network. Mobile Netw Appl 21(2):272–285
11. Mehetre, Roslin, Wagh (2018) Detection and prevention of black hole and selective forwarding
attack in clustered WSN with Active Trust. Cluster Comput 22:1313
12. Tyagi P, Dembla (2017) Performance analysis and implementation of proposed mechanism for
detection and prevention of security attacks in routing protocols of vehicular adhoc network.
Egyptian Inf J 18(2):133–139
13. Baiad R, Alhussein, Otrok, Muhaidat (2016) Novel cross layer detection schemes to detect
black hole attack against qos-olsr protocol in vanet, Veh Commun 5:9–17
14. Amish P, Vaghela (2016) Detection and prevention of wormhole attack in wireless sensor
network using AOMDV protocol. In: 7th international conference on communication,
computing and virtualization, pp 700–707
15. Shahid H, Ashraf H, Ullah A, Band SS, Elnaffar (2022) Wormhole attack mitigation strategies
and their impact on wireless sensor network performance: a literature survey. Int J Commun
Syst e5311
16. Hanif M et al (2022) AI-based wormhole attack detection techniques in wireless sensor
networks. Electronics 11(15):2324
17. Bai S et al (2019) Detecting wormhole attacks in 3D wireless ad hoc networks via 3D forbidden
substructures. Comput Netw 150:190–200
18. Spurthy K, Shankar (2020) An eﬁcient cluster-based approach to thwart wormhole attack in
adhoc networks. Int J Adv Comput Sci Appl 11(9):312–316
19. Gayathri S, Subramanian P, Viswanathan, Chandru (2019) Wormhole attack detection using
energy model in MANETs. In: 2nd international conference on power and embedded drive
control (ICPEDC), IEEE, pp 264–268
20. Zeng Y, Qiu M, Zhu D, Xue Z, Xiong J, Liu M (2019) Deepvcm: a deep learning based intrusion
detection method in vanet. In: IEEE 5th internationall conference on big data security on cloud

64
R. Prathap Kumar et al.
21. Kaur J, Singh T, Lakhwani (2019) An enhanced approach for attack detection in vanets using
adaptive neuro-fuzzy system, ICACTM, IEEE, pp 191–197
22. Chen JLZ, Hengjinda P (2021) Enhanced dragonﬂy algorithm based K-Medoid clustering
model for VANET. J ISMAC 3(01):50–59

A Detailed Analysis on Spam Emails
and Detection Using Machine Learning
Algorithms
Razia Sulthana
, Avani Verma
, and A. K. Jaithunbi
Abstract Spam email is the unwanted junk and solicited email sent in bulk to the
receivers, using botnets, spambots, or a network of infected computers. These spam
emails can be phishing emails that trick users to get their sensitive information,
download malware into the user devices or scam the users stealing conﬁdential data.
This paper shows a systematic analysis of spam and its types. It also details the
procedure of how the spammers get the email addresses of the receivers. It analyses
the problems with spamming. A detailed state of the art on spam ﬁlters and the factors
that put an email into the spam or ham category is also explained. The paper also
discusses spam ﬁltering methods of Gmail, Yahoo and Outlook. Finally, it brings
out several solutions to detect spam using principles of Machine Learning and Data
Mining.
Keywords Spam email · Security breach · Naive Bayes · Logistic Regression ·
Machine Learning
1
Introduction
Spam email is unwanted junk and unsolicited mail sent in bulk to the receiver through
an email system like a network of infected computers and botnets. It can also be sent
via text messages, phone calls and social media. It can be sent by businesses for
R. Sulthana (B)
Department of Computing and Mathematical Sciences, University of Greenwich,
Old Royal Naval College, London SE10 9LS, UK
e-mail: razia.sulthana@greenwich.ac.uk
A. Verma
Department of Computer Science, Birla Institute of Technology & Science, Pilani, Dubai
Campus, 345055 Dubai, United Arab Emirates
e-mail: f20190077@dubai.bits-pilani.ac.in
A. K. Jaithunbi
Department of Computer Science, RMD Engineering College, Kavaraipettai, TamilNadu 601206,
India
e-mail: akj.cse@rmd.ac.in
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_5
65

66
Razia Sulthana et al.
commercial reasons. It can also be a malicious attempt to gain access to the user’s
computer. Since these emails are sent from botnets, they are very difﬁcult to trace
and stop.
The links or attachments in the mail might include malicious information. Gen-
erally, the hackers use the links or attachments to check the legitimacy of the email
addresses or go to malicious websites or downloads which can instal the malware in
the computer. The users have their email addresses recognized by spambots. Spam-
bots are automated programs that search the Internet for email addresses. Thus,
spammers use spambots for generating an email distribution list. Emails are gener-
ally sent to millions of users. However, only a small number of users react to these
emails.
Thenumber of peoplecommunicatingwitheachother onlineis increasingbecause
of the Internet. People depend on emails for general or business related issues. It is a
very effective tool for communication as it saves cost and time. In recent years, emails
are affected by attacks like spam emails, phishing emails, etc. Spam ﬂoods receivers
inboxes with mimicked messages, or with documents or links which can pass on
malware to the device or can trick the receivers to reveal their sensitive information.
Thus, spam ﬁlters are needed to avoid these. The spam ﬁlters should provide high
Accuracy and have minimal errors and should be efﬁcient too. The objectives of the
paper include:
• Understanding the meaning and types of spam emails.
• To analyse the working of spam email ﬁlters.
• To discuss case studies of Gmail, Yahoo and Outlook spam ﬁlters.
• To provide solutions to detect spam emails using Machine Learning (ML) algo-
rithms (Naive Bayes (NB) and Logistic Regression (LoR)).
2
Types of Spam
Spam can be used for the marketing of goods and services or can be malicious. Types
of spam are
1. Phishing Emails—these are sent by cyber attacker to many people which trick
people into giving their personal information like bank and credit card details.
Phishing is an online scam based on social engineering, i.e. malicious activities
performed through human interactions. The scammer creates links to click where
users can put the sensitive information or download malware into the device.
2. Email Spooﬁng—the email spoofs an email that resembles the original so that
the user can believe the authenticity. The message may be to request payment or
to verify/ reset the account or update billing information.
3. Tech Support Scams—these emails explain that the user has some technical issue
and provide the phone number of the tech support or a link to click. These emails

A Detailed Analysis on Spam Emails and Detection …
67
mimic being a large and reputed company. If the user gives the details of the
devices, they can be hacked.
4. Current Event Scams—these emails depend on the current news. For example,
during COVID-19, scammers sent messages for work from home that paid in
bitcoin or donations to fake organizations.
5. Advance Fee Scams—these scam emails promise a reward, generally ﬁnancial
if some amount of cash is provided in advance for some processing or transfer
of money/goods. Once the user pays, they either ask more or disappear.
6. Malware Spam—it is a spam email that delivers malware to the devices. These
emails have links or attachments. When the user clicks these, malware like
Ransomware, Trojan Horses, Bots, viruses, Spyware, etc., are downloaded to
the device. Generally, the attachments are in the form of a Word document,
PowerPoint presentation or PDF ﬁle.
Spam ﬁlters can be implemented on all layers—ﬁrewalls in front of an email server
or at Message Transfer Agent (MTA), email server to provide integrated anti-spam
and antivirus solution which provides complete email protection at the network level.
At the MDA level, spam ﬁlters can be installed.
2.1
Understanding How Spammers Gets Address
Ways in which spammers get the email addresses:
1. There are thousands of companies that sell CDs containing millions of email
addresses. These addresses can be easily formatted and copy-pasted in the ‘To’
section of the email. The companies get the email addresses from several primary
sources like newsgroups and chat rooms. The users generally leave their email
addresses in these groups. Software can be used to extract these screen names
and email addresses.
2. Secondly, these email addresses can be found on the web. The ‘@’ symbol can
be searched on the Internet to get the email addresses. This can be done by using
a web crawler.
3. Thirdly, the spammer can create sites for winning the lottery in which the user
has to type the email address. If they accept receiving the email newsletters, then
their email addresses are sold to the spammer.
4. Next, performing a dictionary attack on the email hosting websites can also
generate email addresses.
2.2
Problems with Spamming
According to Statistica, the global daily spam volume from October 2020 to Septem-
ber 2021 was 1980.58 billion spam emails from 2346.05 billion emails, which

68
Razia Sulthana et al.
Table 1 Global daily spam volume from October 2020 to September 2021
Spam emails
Total emails
242.42
286.41
210.54
248.7
140.56
166.38
122.33
144.76
150.93
178.3
138.09
163.87
88.21
104.2
200.24
236.74
249.95
296.81
282.93
336.41
65.5
77.8
88.88
105.67
Source Statistica
Fig. 1 Global daily spam volume from October 2020 to September 2021. Source Statistica
accounted for 84.42%.The number of global daily spam volumes in July 2021 had
the highest value of 283 billion spam emails out of 336.41 billion emails sent from
October 2020 to September 2021 (Table1 & Fig.1).
Every Internet Service Provider (ISP) pays to use the Internet by the purchase
of bandwidth. When the volume of spam that is directed to the ISP increases, the
bandwidth becomes crowded, and this reduces the speed of Internet access. To avoid
this situation, the ISP pays to the ﬁltering software or to increase the bandwidth. This
expense is often passed to the buyers of ISP.
Some spam emails allow the user to remove themselves from the subscriber list
but when the users respond to the email, they verify that their email accounts are
active. This might lead to getting more spam emails.

A Detailed Analysis on Spam Emails and Detection …
69
2.3
Types of Spam Filters
1. Third-Party or Cloud-based and Gateway spam ﬁlters—several companies use
cloud-based or gateway spam ﬁlters for the suspicious inbound and outbound
emails. These gateway spam ﬁlters are installed on servers, whereas cloud-based
spam ﬁlters are run on third-party servers. They are entirely digital. These cloud-
based and gateway spam ﬁlters provide the network admin to have extra control
over in and out trafﬁc of the network.
2. Desktop spam ﬁlters—live on the user’s device and allow for 1-1 conﬁguration
and personalisation. Example: G-Lock, SpamCombat, Microsoft Smart Screen.
3. Email Service Provider (ESP) built-in spam ﬁlters—for Business to Customer or
Business to Business senders, Google, Yahoo and Microsoft have inbuilt spam
ﬁlters and inbox sorting technologies.
2.4
Factors to Determine if Email Is Spam or Ham
A ham is generally an email that is not a spam.
1. SourceInternetProtocol(IP)Address—ifaspeciﬁcIPaddresshasreceivedmany
complaints in the past, email from that address is more likely to be identiﬁed as
spam. An email with a poor IP reputation might not be accepted by the server
because the IP address is an important factor in delivering an email. Therefore,
many companies set up dedicated IP addresses for their users.
If there is no dedicated IP address, the emails will be sent through the marketing
automation platform shared IP. Thus, the emails are sent from the same servers
as the other customers through these platforms. If any user misbehaves, all other
users who are using that platform are affected and the IP reputation decreases.
For dedicated sending IP addresses, the reputation can be checked by using
Sender Score, Talos Intelligence and Reputation Authority services. For shared
IP, it is important to determine if the email is spam or ham, which will be decided
by the domain reputation.
2. Sender’s Domain—the ESP looks for the sender’s originating IP address, sending
domain and the sender’s alias. If emails of a company’s domain are marked
as spam, there is a high possibility that these emails are not a priority for the
receivers. If ESP labels them as spam, these emails will be missed. The reputation
of the domain is not good, whereas if the emails are whitelisted, the reputation
of the domain is good.
3. Spam Traps—if emails are sent to the spam traps, the domain and IP reputation
decreases. If an email account is not used for a speciﬁc period of time, the email
providers disable it. The ESP might recycle it and convert it to a spam trap.
The senders who send spam emails to that account will be ﬁned. Therefore,
such email addresses should be removed from the email list. ESP might put fake
email addresses so that the bots ﬁnd them and put them into the mailing list. If
the spammers use such mailing lists, they’ll be penalized and put on a blacklist.

70
Razia Sulthana et al.
4. Blacklists are lists of IP addresses that are owned by known spammers or people
who let spammers use their devices. Some of the known blacklists are Return
PathReputationNetworkBlacklist(RNBL),Sbl.spamhaus.org(SBL),SpamCop
(SCBL), etc.
5. Sending Rate—emails can fail to reach the inbox because too many emails
are being sent to that server at a time. The gateway ﬁlters allow the admin
to rate control the bulk email deliveries. Also, if the email is sent to multiple
contacts at the same domain, the email might not be delivered. Thus, spreading
out of sending email over time can increase the deliverability. The emails can
be delivered over a window over time with each recipient getting the email at
the predicted time. Throttling follows send time optimization which reduces the
probability of the email being labelled as bulk delivery.
6. Content—ESP sorts email using Content and IP. Recent spam ﬁlter models work
on patterns rather than speciﬁc words to avoid. The content of the email plays
a major role in user engagement. If the email has poorly qualiﬁed content, the
user might directly mark it as a spam approach and ignore it. Thus, the email
should be made keeping the text, images and HTML in mind.
7. Authentication—this is used for ESP to verify the senders and to prevent spam
from reaching the inbox. The emails that don’t clear these protocols are consid-
ered spam.
Types of authentication protocols:
– Domain Keys Identiﬁed Mail (DKIM)—uses EDS to verify if the emails are
from the actual domain or spoofed.
– Sender Policy Framework (SPF)—lets the sender specify the authorization of
the mail servers to send email to the receiver’s domain.
– Domain-Based
Message
Authentication,
Reporting
and
Conformance
(DMARC)—gives options to receivers to handle emails if it fails the SPF and
DKIM protocols. It also gives information about the senders from the domain.
2.5
Working of Gmail Spam Filter
Morethan1billionpeopleuseGmailinamonth.Gmailusesseveralrule-basedﬁlters,
integrating tensor ﬂow and artiﬁcial intelligence into the spam ﬁlters. It focuses on
IP and Domain Reputation, User Engagement, Content and Sending History.
Gmail looks at both the domain and IP address of the senders to distinguish email
between spam and ham. The algorithms check the user response when distinguishing
between ham and spam. The content of the email—header, body, link, images, etc.,
determine if the email is spam or inbox. The ﬁltering depends on the words that are
blacklisted as spam words.
Gmail has a database of blacklisted domains. An email is ﬁrst checked in this
database. If the email or domain is not known, it checks if any links present in the
email are malicious or not by comparing them with the database. It will also check

A Detailed Analysis on Spam Emails and Detection …
71
for any spelling or grammatical errors by comparing the words in the email with the
list of trigger words that are mostly featured in the spam emails.
2.6
Working of Outlook Spam Filter
Microsoft relies on Sender Reputation Data Network (SRDN) along with engage-
ment, spam traps and complaints to ﬁlter spam. SRDN uses a panel of voters from
different users to train the spam ﬁlters. Emails received can be resent asking the users
to vote if the email sent was spam or ham. Higher spam votes will lead the future
emails to mostly go to the spam folder. It is harder to lower the complaint rate by
sending a large volume of emails using SRDN.
2.7
Working of Yahoo Spam Filter
Yahoo checks the IP address, Domain, Sender and Uniform Resource Locator (URL)
reputation, along with DKIM and DMARC protocols. If emails have a certain sending
rate, and there is a sudden increase in activity, the email can be marked as spam. It
follows the same practices as Gmail and Outlook.
3
Literature Review
Based on ML and Data Mining, the following literature review has been done
(Table2). In [16], P. Sharma et al. have focused on the ML [4, 13, 18] by imple-
menting NB and J48 for spam email detection. The data set is divided into different
sets and given as input to each algorithm. Total three experiments are performed,
and the results obtained are compared in terms of Precision, Recall, Accuracy, F1-
score, True Positive (TP) rate, True Negative (TN) rate, False Positive (FP) rate and
False Negative (FN) rate. The two experiments are performed using individual Naive
Bayes (NB) and J48 algorithms. Pandey et al. [8] have examined the ML strategies:
NB, Support Vector Machine (SVM) relevance to the issue of spam email detection.
Email ﬁltration depends on the data classiﬁcation approach. For data classiﬁcation,
choosing the best performing classiﬁer is the base. Data set used is of Ling Spam
Corpus. Firstly, data is accumulated and represented. Next, dimensionality is reduced
by email feature choice.
Sethietal.[15]haveproposedaworkthatfocusesonNaturalLanguageProcessing
(NLP) [3]. The technique used for detection is the NB and Artiﬁcial Neural Network
ANN [19]. The steps involved are data set reading and inspection, text preprocessing,
feature set and vectorization, pipeline. Martino et al. [7] have given information about
legitimacy to detect spam. The data set is from Bruce Guenter Project. The algorithms

72
Razia Sulthana et al.
Table 2 Literature analysis
References
Algorithm
Performance metrics
[16]
Naive Bayes, J48
Precision, Accuracy, F1-score
[8]
Naive Bayes, Support Vector Machines,
Logistic Regression
Accuracy
[15]
Naive Bayes, Artiﬁcial Neural Network Precision, Accuracy, F1-score
[7]
Naive Bayes, Logistic Regression,
Support Vector Machines
Accuracy
[2]
Naive Bayes
Accuracy
used are NB, LoR, RFC and SVM. The methodology is ﬁrst deﬁning classes and
features,buildingadatasetandusingvectorsforfeedingtheclassiﬁer.Huangetal.[9]
have used NB for the classiﬁcation of emails. The data set is from Ling Spam Corpus.
The methodology used is to preprocess data, searching common spam keywords. The
advantage is that the testing has been carried out on spam encryptions.
Shah et al. [2] have used LoR, k-Nearest Neighbour (K-NN) [14] and Decision
Trees (DT) for spam detection. The data set used is of SMS spam collection. There
were 4900 ham samples and 672 spam samples. The advantage is that the proposed
method performance is good as compared with the existing state-of-the-art methods.
The limitations is that the research is limited to few algorithms. The work can be
improved by comparing more algorithms [23]. Singh et al. [17] have used SVM
[1, 12, 20] classiﬁer for SMD. Nonlinear SVM is used with two kernel functions—
linear and Gaussian kernel. The data set is of Spam Assassin Public Corpus. Taylor
et al. [5] have used SVM and RFC models. The data set used was of the UCL spam
base. The methodology is used to preprocess data and split it into train and test data.
It is then checked for Accuracy by implementing the algorithms, and ﬁnally, it is
classiﬁed into ham/spam. The limitation is that only two algorithms were compared.
Naem et al. [6] have used k-NN, SVM, Bagging, Boosting and approaches for
spam email detection. The data set used is CS-DMC2010 and SpamAssassin. The
advantageisthatthemethodgetsalownumberofselectedfeaturesandarchivesahigh
degree of classiﬁcation Precision. Text mining is used to extract textual signatures
in [10]. LoR and DT are applied for spam detection [11, 21, 22].
4
Analysis of Machine Learning Algorithms
According to Literature Review, hybrid Naive Bayes and Logistic Regression model
are most accurate. Naive Bayes is based on Bayes Theorem (Eq.1) with the assump-
tion of strong independence. It is a Probability-Based Classiﬁer. The combinational
and frequency values of the data set are calculated under a probability set. The class
that is nearer to the rear end is picked by the classiﬁer.

A Detailed Analysis on Spam Emails and Detection …
73
Fig. 2 Architecture diagram
P(a
b ) = P( b
a )P(a)
P(b)
(1)
b = set of feature vectors
a = class variable
P(a/b) = posterior probability that depends on the likelihood of attribute value of
class P(b/a)
P(a) = prior probability
P(b) = probability of known attribute value
Logistic is an analysis method to model the data and explain the relation between the
Binary Response Variable and Explanatory Variable. The result is the probability of
assigning a value to a particular class, which is in the range of 0–1.
1. Initially,datacollectionandpreprocessingisdonebyremovingundeﬁnedvalues,
gaps and duplicates. This helps to reduce errors and improve the quality of
classiﬁcation.
2. Secondly, text processing is done to remove unwanted noise and characters like
punctuation and numbers. This is done by converting all letters to lowercase,

74
Razia Sulthana et al.
deleting numbers and removing punctuation marks and stop words like prepo-
sitions and pronouns, etc.
3. Tokenization is performed by splitting sentences into words separated by a
comma.
4. Finally, the quality of the classiﬁcation is accessed. Model training is performed
by the metrics, namely Accuracy and Precision (Fig.2).
The data set used for spam ﬁltering is Ling spam data set. It includes 1000 emails.
The data set is divided into 80:20 split ratio and are subjected to Naive Bayes and
Logistic Regression. The training and testing results are given in Tables 3 and 4,
respectively.
The results are shown in Fig.3. The Precision, Accuracy and F1-score of Naive
bayes and Logistic Regression are recorded. The training and testing results show
a trivial difference which is because of the behaviour of the model to the test data
is unpredictable. However, the performance of the Naive Bayes system is slightly
better than Logistic Regression in testing data and is vice versa in test data.
Table 3 Training results for the Naive Bayes and Logistic Regression
Algorithm
Precision
Accuracy
F1-score
Naive Bayes
96.5
97.3
96.8
Logistic Regression
97.1
96.2
97.04
Table 4 Testing results for the Naive Bayes and Logistic Regression
Algorithm
Precision
Accuracy
F1-score
Naive Bayes
95.5
94.1
95.02
Logistic Regression
93.6
94.5
93.7
Fig. 3 Result analysis

A Detailed Analysis on Spam Emails and Detection …
75
5
Conclusion
Spam email detection helps to detect the unwanted emails and threats. Many
researchers are working in this ﬁeld to ﬁnd out the best classiﬁer that is efﬁcient
and provides high Accuracy in detecting spam emails and ﬁltering them. Gmail,
Outlook, Yahoo and other email service providers use ML algorithms integrated
with AI and Data Mining to build their spam ﬁlter models. For ML-based methods,
NB and LoR prove to be the most efﬁcient algorithms used to detect spam email. For
Data Mining, the best method is RT which proved to be the most accurate method
with high Accuracy.
References
1. Chauhan A, Agarwal A, Sulthana R (2021) Genetic algorithm and ensemble learning aided
text classiﬁcation using support vector machines. Int J Adv Comput Sci Appl 12(8)
2. GuangJun L, Nazir S, Khan HU, Haq AU (2020) Spam detection approach for secure mobile
message communication using machine learning algorithms. In: Security and communication
networks
3. Kontsewaya Y, Antonov E, Artamonov A (2021) Evaluating the effectiveness of machine
learning methods for spam detection. Proc Comput Sci 190:479–486
4. Mathur A, Sultana R (2021) A study of machine learning algorithms in speech recognition and
language identiﬁcation system. In: Innovations in computer science and engineering. Springer,
Heidelberg, pp 503–513
5. Naem AA, Ghali NI, Saleh AA (2018) Antlion optimization and boosting classiﬁer for spam
email detection. Future Comput Inf J 3(2):436–442
6. Naem AA, Ghali NI, Saleh AA (2018) Antlion optimization and boosting classiﬁer for spam
email detection. Future Comput Inf J 3(2):436–442
7. Nidhya M, Jayanthi L, Sekar R, Jeyabharathi J, Poonam M (2021) Analysis of machine learning
algorithms for spam ﬁltering. Ann Romanian Soc Cell Biol 3469–3476
8. Pandey P, Agrawal C, Ansari TN (2018) A hybrid algorithm for malicious spam detection in
email through machine learning. Int J Appl Eng Res 13(24):16971–16979
9. Peng W, Huang L, Jia J, Ingram E (2018) Enhancing the Naive Bayes spam ﬁlter through
intelligent text modiﬁcation detection. In: 2018 17th IEEE international conference on trust,
security and privacy in computing and communications/12th IEEE international conference on
big data science and engineering (TrustCom/BigDataSE). IEEE, pp 849–854
10. Qian F, Pathak A, Hu YC, Mao ZM, Xie Y (2010) A case for unsupervised-learning-based
spam ﬁltering. ACM SIGMETRICS Performance Eval Rev 38(1):367–368
11. Rathi M, Pareek V (2013) Spam mail detection through data mining-a comparative performance
analysis. Int J Modern Educ Comput Sci 5(12)
12. Razia SA, Pranav R (2022) Predicting the import and export of commodities using support
vector regression and long short-term prediction models. Int J Comput Digital Syst 11(1):635–
648
13. Razia Sulthana A, Mathur A (2021) A state of art of machine learning algorithms applied over
language identiﬁcation and speech recognition models. In: International virtual conference on
industry 4.0. Springer, Heidelberg, pp 123–132 (2021)
14. Sajedi H, Parast GZ, Akbari F (2016) Sms spam ﬁltering using machine learning techniques:
a survey. Mach Learn Res 1(1):1–14
15. Sethi M, Chandra S, Chaudhary V (2021) Email spam detection using machine learning and
neural networks. Int Res J Eng Technol 8:349–355

76
Razia Sulthana et al.
16. Sharma P, Bhardwaj U (2018) Machine learning based spam e-mail detection. Int J Intell Eng
Syst 11(3):1–10
17. Singh M, Pamula R et al (2018) Email spam classiﬁcation by support vector machine. In: 2018
international conference on computing, power and communication technologies (GUCON).
IEEE, pp 878–882
18. Sulthana AR, Jaithunbi A (2022) Varying combination of feature extraction and modiﬁed
support vector machines based prediction of myocardial infarction. In: Evolving systems, pp
1–18
19. Sulthana AR, Jaithunbi A, Ramesh LS (2018) Sentiment analysis in twitter data using data
analytic techniques for predictive modelling. J Phys: Conf Ser 1000:012130 (IOP Publishing)
20. Trivedi SK (2016) A study of machine learning classiﬁers for spam detection. In: 2016 4th
international symposium on computational and business intelligence (ISCBI). IEEE, pp 176–
180
21. Vivekanandam B et al (2022) Spam email classiﬁcation by hybrid feature selection with
advanced machine learning algorithm-future perspective. J Soft Comput Paradigm 4(2):58–
68
22. Wijaya A, Bisri A (2016) Hybrid decision tree and logistic regression classiﬁer for email
spam detection. In: 2016 8th international conference on information technology and electrical
engineering (ICITEE). IEEE, pp 1–4
23. Yasin A, Abuhasan A (2016) An intelligent classiﬁcation model for phishing email detection.
arXiv preprint arXiv:1608.02196

Advanced Encryption Standard-Based
Encryption for Secured Transmission
of Data in Cognitive Radio
with Multi-channels
Kiran P. More and Rajendrakumar A. Patil
Abstract CRN is hyped as a powerful tool for advancing 5G networks that can
signiﬁcantly increase SE by allowing unlicensed users to access the inactive licensed
spectra without interfering with licensed PUs. Moreover, CRN becomes more chal-
lenging due to the difﬁculty in accessing and detecting the channel. In this study, a
Self-Upgraded Spider Monkey Optimization (SU-SMO)-based LSTM algorithm is
used to predict the channel state. Additionally, it aims to carry out secure commu-
nication over the foreseen spectrum channels. The advanced encryption standard
(AES) guarantees the security level of data frames to enable safe communication.
Finally, an analysis was conducted to show how the model could be improved.
Keywords Self-Upgraded Spider Monkey Optimization (SU-SMO) · Spectrum
efﬁciency · Cognitive radio · Long short-term memory (LSTM) · Advanced
encryption standard concept
Abbreviations
Acronym
Description
MSS
Multi-Band Spectrum-Sensing
M-AES
Modiﬁed Advanced Encryption Standard
VANET
Vehicular Network
CRSN
Cognitive Radio Sensor Network
ACD
Auto-correlation-based Detector
ROC
Receiver Operating Characteristics
CR
Cognitive Radio
K. P. More (B) · R. A. Patil
Department of Electronics and Telecommunication Engineering, College of Engineering Pune,
Pune, India
e-mail: kiran.more@vit.edu
R. A. Patil
e-mail: rap.extc@coep.ac.in
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_6
77

78
K. P. More and R. A. Patil
LSTM
Long Short-Term Memory
Pus
Primary Users
DBN
Deep Belief Network
MHTP
Multichannel Hidden Terminal Problem
ProMAC
Proactive Medium Access Control protocol
APS-MAC
Adaptive Preamble Sampling-based MAC
CRV
Cognitive Radio for VANET
CTS
Clear To Send
MME
Maximum–Minimum Eigen value detectors
DCNN
Deep Convolutional Neural Network
SNR
Signal-To-Noise Ratio
CS-GOA
Cuckoo Search-Grasshopper Optimization Algorithm
SM
Spider Monkey
RARE
SpectRum-Aware cRoss-layEr
MPC
Model Predictive Control
SUs
Secondary Users
MA
Multiple Access
MAC
Medium Access Control
SVD
Singular Value-based Detector
SDR
Software Deﬁned Radio
CFD
Cyclostationary Feature-based Detector
RTS
Request To Send
CRN
Cognitive Radio Networks
FMAC
Fairness-based MAC
ED
Energy Detector
SE
Spectrum Efﬁciency
ECC
Elliptic Curve Cryptography
RSA
Rivest–Shamir–Adleman
DSA
Dynamic Spectrum Access
1
Introduction
Currently, the ﬁxed spectrum distribution technique is widely used. Though, the
majority of available bandwidth is not used as the requirements of bandwidth by
apps or devices are constantly changing [1, 2]. The spectrum remains inactive while
a licensed band is not used by a licensed user (also known as PU) since it cannot
be used by several other unlicensed clients [3, 4]. According to the measurements, a
ﬁxed allocation scheme’s usual value of spectrum utilization ranges from 15 to 85%
[5, 6]. These current spectrum efﬁciency problems are resolved using a technique
known as DSA. Also, the method called CRN might be used to enable the DSA
[7, 8].

Advanced Encryption Standard-Based Encryption for Secured …
79
In the DSA technique, the primary user’s uninterrupted operation is maintained
while the licensed band is made accessible to unlicensed users. SUs are devices with
CR technology capabilities [9]. DSA comes in two varieties, including spectrum
overlay and underlay. SU maximum transmission parameters allow SUs to transmit
beneath the conﬂicting temperature limit of PUs in spectrum underlay. Spectrum
overlay, however, does not apply any power constraints on SUs [10]. SUs are able
to identify and utilize available channels thanks to spectrum overlay. An SDR called
CRN has the ability to modify its transmission/reception restrictions depending on
the state of the surrounding environment. The cognitive cycle is a factor in CRN
functions. The following list summarizes this work’s main contribution:
• Presents the SU-SMO-based LSTM technique for detecting the presence of
channel states.
• Suggests the usage of AES to maintain the data securely across the licensed
spectrum channel.
The remaining work is organized as follows: Sect. 2 examined a review on a
related subject. The system modeling is shown in Sect. 3, and the suggested MPC
channel allocation procedure is shown in Sect. 4. Section 5 describes the suggested
AES protocol for secure data transport. The results and conclusion are explained in
Sects. 5 and 6.
2
Literature Survey
2.1
Related Works
In 2018, Nafees et al. [11] created a technique that divides a network into several
groups as well as the layout of the clusters appears to be a bigger challenge for edge
biclique. Moreover, super-frame architecture was suggested to maintain network
dependability. A delay-aware protocol from the accepted RARE was still a problem
with the weighted graph. It was veriﬁed that RARE-modiﬁed clusters oriented on
node mobility and spectrum availability.
In 2018, Li and Han [12] have developed a plan to reduce congestion by allocating
time and channels as efﬁciently as possible. In contrast, the handshaking process for
establishing a data link received very little attention. With this strategy, a novel
conﬁguration that incorporated CRAHN features was demonstrated for CTS and
RTS frames. As a result, an FMAC method was also made available that dealt with
the distribution of data links among SUs.
In 2018, Manyi et al. [13] created an APS-MAC framework that enabled the eval-
uation of opportunistic spectra and addressed CRSN energy efﬁciency. The proposed
layout that enabled the duty cycle on CRSN had preamble sampling as a key compo-
nent. Additionally, because each CRSN sets its own wake-up and sleep schedule
through sampling, it is possible for them to remain in a drowsy state indeﬁnitely.

80
K. P. More and R. A. Patil
Table 1 Examining conventional CRV protocols
Author [citation]
Adopted model
Features
Challenges
Nafees et al. (2018)
[11]
RARE protocol
• Does not cluster as
much
• Delivers reliable
communication
• Finding neighbors is
not possible
Li and Han (2018)
[12]
FMAC protocol
• Enhanced link
distribution
• An extended window
for rendezvous
success
• Disorders develop
once data allocation is
ﬁnished on schedule
Manyi et al. (2018)
[13]
APS-MAC protocol
• Greater energy
efﬁciency
• High throughput
• Threats cause
injustice to happen
Moayad et al. (2020)
[14]
MAC protocol
• Excellent spectral
efﬁciency
• High throughput
• Only a ﬁxed basic
rate is supported by
each channel
Stahya et al. (2016)
[15]
ProMAC
• Provides efﬁcient
channel assignment
• Difﬁcult assessment
procedure
In 2020, Moayad et al. [14] emphasized the multi-stage channel assignment
problem as a spectrum accessing challenge. The goal was to increase the acquired
sum rate on CR-IoT nodes in order to increase the overall network throughput. An
innovative resource-oriented channel allocation approach that provided appropriate
use of the provided time–frequency unit was primarily used.
In 2016, Sathya et al. [15] proposed an MPC-focused ProMAC in CRN for SUs,
the ﬁrst proMAC model to be created. When compared to existing systems described
in the literature, ProMAC deployment with ﬁxed SU and PU counts led to enhanced
channel usage as well as the best sensing lag and backoff rate (Table 1).
Various methods have been focused on predicting the channel states (busy or idle)
using prediction models. However, there exist an issues such as identifying neighbors
is impossible, problems arise after data allocation is completed on schedule, threats
result in injustice, each channel only supports a ﬁxed basic rate, and the assessment
process is challenging. Therefore, in order to rectify the abovementioned issues,
this study develops a novel model for detecting the presence of channel states. The
proposed model is described in the following section.
3
Proposed MPC Protocol for Channel Allocation
MPC model [16] includes ﬁve major steps. Step I of the MPC model explains the
variable boundaries, while Step II predicts the values of the prediction variables. Step
III conducts system construction and takes decisions based on the predictions. Step
IV is concerned with using Step II’s predictions to generate the values of variables.

Advanced Encryption Standard-Based Encryption for Secured …
81
The results of Steps IV and III are evaluated in Step V. When SU needs a channel
in a VANET, the MPC architecture is then implemented like a control system. The
ﬂow process of ProMAC-based framework is shown in Fig. 1.
The major goal is to address the following issue:
• The ProMAC predicts the condition of transmission (active or idle) of PU for
subsequent ST time slots using the PU channel list and its prior Tr transmission
states.
• Additionally, the busy or idle state of the PU channel is determined based on
whether the associated PU is transferring or not.
• Considering E channelsconnectedtoPUs,whichareindicatedby{F1, F2, ....FE}.
Here, hi
j = Fi location in jtime slot.
• A history polynomial HisPi connected to Fi for the designated tp time period is
shown in Eq. (1).
HisPi(x) =
tp−1

j=tp−h
hi
j ∗x j−tp+h,
h j ∈{0, 1}
hi
j =
1, if Fiis busy at timeslot tp
0, Otherwise

(1)
The work that has been developed focuses on secure data transfer on the expected
channel conditions. Additionally, as a further development, this work uses SU-SMO-
based LSTM to predict the state of transfer.
Set point Calculation
Error correction
Control channels 
and predictions
Real-time 
process
Set point
Upgraded 
set-point
Predicted 
values
Output
Fig. 1 Flow diagram for ProMAC

82
K. P. More and R. A. Patil
3.1
Optimized LSTM Classiﬁer
Three units, such as the forget gate, an input gate, as well as the output gate, make
up every LSTM cell. Letting L and Q stand for hidden and cell state, respectively,
in that order. Here, (Gt, Qt−1, Lt−1),(Mt, Ct) = input, output layers.
An output, input, and forgets gate at a time t, signiﬁes It, lt, ot, respectively. ot
is mostly used by LSTM to categorize the information into irrelevant categories. ot
is given in Eq. (2).
ot = ♦(TloGt + Olo + TLoLt−1 + OLo)
(2)
where(TLo, OLo),(Tlo, Olo) = weight and bias parameters to mapping hidden layers
and forget gate’s input layers, ♦= activation function.
LSTM uses the input gate as demonstrated in Eqs. (3) and (4) and (5).
Here, (TL X, OL X),(TlX, OlX) = cell gate’s hidden and input layers are mapped
using the weight and bias parameter. (JLl, BLl),(Jll, Bll) = mapping hidden and
input layers to lt using weight and bias parameter. tanh has traditionally been used
as an activation function. This approach is unique in that it uses leaky ReLu as the
activation function rather than tanh. Additionally, as shown in Eqs. (6) and (7), the
LSTM cell acquires the output hidden layer via the output gate.
Xt = leaky ReLu(TlXGt + OlX + TL X Lt−1 + OL X)
(3)
lt = ♦(TllGt + Oll + TLl Lt−1 + OLl)
(4)
Qt = ot Qt−1 + lt Xt
(5)
It = ♦(TlI Gt + OlI + TLI Lt−1 + OLI)
(6)
Lt = Itleaky ReLu(Qt)
(7)
Here, (TLI, OLI),(TlI, OlI) = weight and bias to transfer the input layer’s hidden
values to It. Also, Tlo + TLo + TL X + TLl + TlX + Tll = T were ﬁne-tuned by
SU-SMO approach.
Solution encoding: As noted previously, the SU-SMO technique is used to select
the LSTM weights denoted by (T ). The depiction for solutions is shown in Fig. 2.
Where N = LSTM weights total. The proposed work’s objective is to reduce the
error (err) as given in Eq. (8).
Fig. 2 Solution encoding
1T
2T
N
T
I
S
O
M
S
−
...

Advanced Encryption Standard-Based Encryption for Secured …
83
obj = min (err)
(8)
3.2
SU-SMO Algorithm
This study proposes an innovative and effective strategy employing the Spider
Monkey Optimization method to solve a complicated optimization issue. The newly
suggested method is self-upgraded in that it changes the role of the local leader in
accordance with its existing situation.
In order to get rid of complex optimization problem this paper presents a novel
and efﬁcient approach using Spider Monkey Optimization algorithm. The newly
proposed strategy is self-adaptive in nature as it modify the position of local leader
based on its current position.
The suggested SU-SMO algorithm operates in the way described below:
Initialization: During the initial phase, SMO generates a uniformly distributed
beginning swarm of M spider monkeys. Here, Si Mi = i-th SM in swarm. Si Mi
was initialized as per Eq. (9):
Si Mi j = Si Mmin j + Z ×

Si Mmax j −Si Mmin j

(9)
Here, Si Mmin j, Si Mmax j = lower/upper bound Search region, Z = random numbers
with an even distribution
Modiﬁed Local Leader Phase (LLP): In Eq. (10), the LLP position update
solution is shown.
Si Mnewi j = Si Mmin j + Z1 ×

lolkj −Si Mi j

+ Z2 ×

Si Mr j −Si Mi j

(10)
Here,Si Mi j = i-th SM’s j-th dimension, lolsj = s-th set local leader’s j-th
dimension, Si Mr j = SM’s j-th dimension which was randomly selected.
As per the upgraded logic, LLP position update is carried out as in Eq. (11)
Si Mnewi j = Si Mmin j + Z1 ×

lolkj −Si Mi j

+ Z2 ×

Si Mr j −Si Mi j

+ O ∗(Si Mbest −Si Mworst)
(11)
Here, O = O1+O2
2
, which was adaptive search factor
where
O1 = e + ( f −e) ∗δ, e = −1.2
O2 = f + ( f −e) ∗δ, f = 1.2

84
K. P. More and R. A. Patil
δ = 0.618, which was a scaling factor.
Modiﬁed Global Leader Phase (GLP): It is possible to assess ﬁtness Fi from
objective function f ci. The accompanying Eq. (12) is used to calculate i - th SM’s
likelihood of being selected for the GLP if Fi is its ﬁtness:
prbi =
Fni
N
i=1 Fni
(12)
Here, prbi = selection probability. The standard position update formula is displayed
in this phase as Eq. (13):
Si Mnewi j = Si Mi j + Z1 ×

gl j −Si Mi j

+ Z2 ×

Si Mr j −Si Mi j

(13)
As per the upgraded model, SU-SMO, the GLP update is carried out in Eq. (14).
Si Mnewi j = Si Mi j + Z1 ×

gl j −Si Mi j

+ Z2 ×

Si Mr j −Si Mi j

∗c
(14)
where c = inertia weight, evaluated in Eq. (15)
c = cmax −cmax −cmin
Imax
∗I
(15)
where
cmax = 1, cmin = 0, I = current iteration, Imax = maximum iteration.
4
Suggested Secure Data Transmission Using AES Protocol
4.1
Channel Sensing Phase
The channel sensing step is responsible for identifying the band gaps that will be
used in the communication between Tx-Rx pairs. It is assumed that the SUs employ
energy recognition to sense spectra. ProMAC combines channel sensing on favor of
the MAC layer to receive the most recent sensing data before starting transmission
[17]. Be aware that due to hardware constraints, it may not be possible to examine
all available data channels within a given sensing time. Using both the DCRN and
CCRN systems, the proposed model identiﬁed a collection of idle channels that were
sensed voluntarily.

Advanced Encryption Standard-Based Encryption for Secured …
85
4.2
Contention Phase
Depending on the MA mechanism described in “IEEE 802.11 DCF,” [18] the SUs
compete for and avoid an inactive PU channel throughout this stage. Each Tx-Rx
pair reserves a maximum of one data channel. The MHTP issue is handled as a result
of the implementation of the CTS/RTS mechanism for generating communication
as described in IEEE 802.11 DCF. The projections produced by the MPC-oriented
ProMAC system are being tested at this level. ProMAC is speciﬁcally given the condi-
tion of each sensing channel as input. After detecting PU state channel, data trans-
mission is decided according to the detected state (busy or idle). As a consequence,
the ProMAC learns whether its predictions are consistent with the actual situation
and advances toward increased predictive accuracy in the future. In the conclusion,
it lowers the likelihood that similar disputes may arise during the following beacon
time period.
4.3
Data Transmission Phase
Every transmitter SU node that successfully retains PU channel during the contention
stage starts to transmit data to its anticipated receiver node using that channel during
the data transmission stage. As every Tx-Rx pair is communicating on a different
channel, every such data transfer occurs concurrently. As a result, it is presumptive
that a single packet or many packets may be broadcast, and that the datagram of a
MACpackethasapredeterminedsize.IfafewTx-RxpairsencounterPUintervention
at any point during this phase, the broadcasting will be stopped as well as the SU
node will back off. A smash with PU could occur in this step if the Tx-Rx pair has
any sensing errors throughout the sensing stage. In the following beacon period, the
collision-affected Tx-Rx couples would proceed through the contention and sensing
phases. As a result, only one beacon time is wasted after collisions.
The proposed work uses AES to transmit data securely.
4.4
AES
AES is one of the encryption methods used to safeguard internet data from harmful
threats. It is the most reliable security protocol because it is used in both hardware
and software. For encryption, it employs longer key sizes, including 128, 192, and
256 bits. As a result, the AES algorithm is more secure against hackers. This makes
it extremely challenging to hack, making it a really safe protocol. AES has four
modiﬁcations that quickly interrupt plain text in order to increase security. Due to
its lower expenses, it might be made simpler on any paradigm as well. AES uses a
key size of 128, 192, and 256 bits and a block size of 128 bits, with related cycle

86
K. P. More and R. A. Patil
counts of 10, 12, and 14, respectively. Mix columns and add round key is two of the
four types of transformations that are included. AES is speedy in both hardware and
software and is dependent on a design approach called as a substitution–permutation
system, which combines both substitution as well as permutation.
4.5
Encryption
The steps that must be taken in the encryption method:
• Divide a 128-bit key into 8 equally sized halves.
• Evaluate Ua′,Ub′ as per Eqs. (16), (17), and (18).
Ua′ =

f −a2
0 + b0

+

f −a2
2 + b2

+

f −a2
4 + b4

+

f −a2
6 + b6

(16)
Uz′ = 4 f −
6

n=0

a2
2n −b2n

(17)
Ub′ = g
7

n=0
a2n+1
(18)
• To cause confusion, the 128-bit key

Ua′
would be XORed well with 128-bit
block data.
• Mix the output rows.
• Mix output columns.
• Mix columnoutput was XORed with Ub′.
• As a result, cipher text is formed as per Eqs. (19) and (20).
Cipher(Cip) =

pl ⊕Ua′
RW

CL

⊕Ub′
(19)
Plain(Pl) =

Cip ⊕Ub′
CL

RW

⊕Ua′
(20)
Here,
Pl = plain text
Cip = cipher text
RW = rows
CL = mixcolumn.
• The ﬁrst key would be the output of Ua′, which is XORed to 128-bit data blocks.
• Both mix rows and mix column steps of the XORed output are performed
successively.

Advanced Encryption Standard-Based Encryption for Secured …
87
• Therefore, Ua′ and Ub′ are generated using the Henon map.
4.6
Decryption
• The steps that are taken in the decryption algorithm is as follows:
• Divide cipher as 128 bits.
• Split secret key as 8 divisions.
• Form Ua′,Ub′ keys.
• Use key Ub′ to reverse XOR the cipher.
• Inverse mix rows as output.
• Inverse mix column as output.
• As seen in Eq. (20), plain text is generated.
5
Results and Discussion
5.1
Simulation Procedure
The proposed Self-Upgraded Spider Monkey Optimization (SU-SMO) model was
executed in NS-2, and the outcomes of the experiments were examined. Here,
two experiments had been conducted; the ﬁrst experiment incorporate with 100
nodes and the second experiment incorporate with 200 nodes. Furthermore, the
suggested model’s performance analysis was contrasted with those of more tradi-
tional approaches, includingDeepConvolutional Neural Network(DCNN), Butterﬂy
Optimization Algorithm (BOA), Deep Belief Network (DBN), Seagull Optimization
Algorithm (SOA), Rock Hyraxes Swarm Optimization (RHSO), Spider Monkey
Optimization-based Long Short-Term Memory (SMO-based LSTM), and Shark
Smell Optimization Algorithm (SSOA), in terms of average backoff, sensing delay,
throughput, and channel utilization. The simulation outcomes for the suggested
model were displayed in Fig. 3. The simulation parameters implemented in this
experiment are depicted in Table 2.
5.2
Performance Evaluation with Regard to Average Backoff
Figure 4 provides a more detailed illustration of the suggested SU-SMO model’s
effectiveness compared to the DCNN, BOA, DBN, SOA, RHSO, and SMO-based
LSTM and SSOA in terms of average backoff. The average backoff obtained by the
suggested model under 80 PUs is (~)0.375, outperforming the values attained by the
following models: DCNN (0.436), BOA (0.474), DBN (0.416), SOA (0.429), RHSO
(0.415), SMO-based LSTM (0.371), and SSOA (0.398), respectively. Considering

88
K. P. More and R. A. Patil
(a)
(b)
(c)
Fig. 3 Sample picture of a Starting stage, b, c Mid stage while communicating with SU
Table 2 Simulation
parameters implemented for
evaluation
Parameters
Values
Number of nodes
50
Number of rounds
100
Simulation time
15
Number of nodes
50
Number of rounds
100
90 SUs, BOA and SOA exhibit the lowest performance (0.482 and 0.445 of average
backoff), meanwhile the suggested model accomplished 0.379 of average backoff.
The proposed work was then performed at 100 SUs with a minimal average backoff
of 0.394, although this is substantially greater than the extant approaches like BOA
= 0.512, SOA = 0.489, and DCNN = 0.458.
In a similar manner, the proposed model accomplished with low average backoff in
experiment 2 is portrayed in Fig. 4b. This follows the same procedure as experiment 1.
Fig. 4 Evaluation on average backoff of the proposed SU-SMO model in contrast to the
conventional approaches by varying the Pus. a Experiment 1, b Experiment 2

Advanced Encryption Standard-Based Encryption for Secured …
89
The suggested technique achieved the required average backoff of 0.345, 0.348, and
0.389inthe20,40,and60PUs.Theproposedworkproduces0.386ofaveragebackoff
under the ﬁnal analysis of 100 SUs, which is signiﬁcantly better than the maximum
average backoff that is held by the conventional models, CNN (0.463), BOA (0.549),
DBN (0.432), SOA (0.433), RHSO (0.458), SMO-based LSTM (0.465), and SSOA
(0.459), respectively. The ﬁgures make it abundantly clear that the suggested tech-
nique has demonstrated superior results to the other models, in recent times. There-
fore, the proposed SU-SMO approach is unique in that it is thought to be the optimum
strategy for secure data transfer in CRNS.
5.3
Performance Evaluation with Regard to Sensing Delay
Figure 5 compares the performance of the suggested SU-SMOwork to the established
methods with respect to sensing delay. When analyzing the results of the sensing
delay, it is fascinating to observe that the proposed task was accomplished with less
sensing delay than the traditional ways. The CNN, BOA, and DBN have sensing
delays of 0.539, 0.621, and 0.556 respectively, which is signiﬁcantly higher than the
suggested task (0.362 of sensing delay). The enhanced sensing delay results for the
SOA, DBN, and RHSO models are 0.211, 0.234, and 0.236, respectively. Likewise,
the CNN and SMO-based LSTM model exhibits considerable effectiveness having
sensing delays of 0.254 and 0.268. However, the presented technique has exceeded
the compared techniques by establishing a minimal sensing delay of 0.134 (under
the 100 PUs).
A review of the comparison result analysis is shown in Fig. 5b, to ensure the safe
transfer of data for the suggested model. The ﬁndings indicate that the SSOA, CNN,
and LSTM technique based on SMO has produced ineffectual results with sensing
delays of 0.238, 0.217, and 0.198, while the proposed recorded the lowest sensing
Fig. 5 Evaluation on sensing delay of the proposed SU-SMO model in contrast to the conventional
approaches by varying the Pus. a Experiment 1, b Experiment 2

90
K. P. More and R. A. Patil
delay of 0.121. The proposed SU-SMO model proved that it has a minimal sensing
delay than the conventional approaches. Altogether, it serves as a suitable tool for
CRNS safe data transmission.
5.4
Performance Evaluation with Regard to Throughput
The proposed SU-SMO model’s throughput analysis for both experiments is
presented in Fig. 6a, b, in comparison to the traditional approaches. According to
the examination of the suggested technique, the throughput value decreases as the
number of PUs rises. However, even at 100 PUs, the proposed work performed better
than the alternative methods. Additionally, for 20 SUs, the suggested model has a
throughput of 89.13, while other existing approaches, such as SMO-based LSTM,
RHSO, and CNN, get throughputs of 88.54, 97.95, and 87.32. Furthermore, analysis
has been taken and it is discovered that the proposed approach gained a throughput
of 84.63; in the 100 SUs, this is extremely high than the throughput of other existing
works.
In Fig. 6b, the conventional models, such as SMO-based LSTM, DBN, and
RHSO, achieved moderately improved results with throughputs of 85.67, 85.28,
and 84.92, under the 80 PUs. Nevertheless, the adopted work has reached the highest
throughput (87.84) than the other models. At the 100 PUs, the proposed model
gained a throughput of 86.91, outperforming the DBN (85.32) and SSOA (85.16).
The exhibited outcome afﬁrms the reliability of the suggested SU-SMO work for
secured data transmission in CRNS at maximum throughput.
Fig. 6 Evaluation on throughput of the proposed SU-SMO model in contrast to the conventional
approaches by varying the Pus. a Experiment 1, b Experiment 2

Advanced Encryption Standard-Based Encryption for Secured …
91
Fig. 7 Evaluation on channel utilization of the proposed SU-SMO model in contrast to the
conventional approaches by varying the Pus. a Experiment 1, b Experiment 2
5.5
Performance Evaluation with Regard to Channel
Utilization
The comparison between the suggested SU-SMO model and conventional models
based on channel usage is illustrated in Fig. 7. Overall analysis shows that the
suggested model outperformed other existing strategies in terms of high channel
utilization. For the 60 PUs, the proposed method gained with highest channel utiliza-
tion as 88.27%; therefore, it is preferable to the other extant models such as RHSO
= 88.27%, SSOA = 86.92%, DBN = 86.18%, CNN = 85.68%, SOA = 85.12%,
SMO-based LSTM = 84.21% and SSOA = 83.34%, respectively. Similar to this,
under the 100 PUs, the minimal channel is consumed by the BOA method (83.14%),
after that SSOA (84.08%) and SOA (84.81%), though the proposed method acquired
the channel utilization as 89.23%.
Simultaneously, when examining Fig. 7b, the suggested model once more showed
that it has the capacity to safely transfer the data in CRNS. The channel utilization
under the 20, 40, 60, and 80 PUs of the suggested model is 90.98%, 90.32%, 92%, and
91.48%, respectively. Furthermore, with 100 PUs, the RHSO and SOA have recorded
channel usage of 90.67% and 98.33%, respectively, but the proposed work recorded
the maximum channel usage of 91.26%. Moreover, the suggested SU-SMO method
is evaluated against other methods, and the results demonstrate that our adopted
method has a higher channel usage.
5.6
Convergence Analysis
Figure 8 depicts the convergence (cost) study of the suggested SU-SMO model for
severaliterationscomparedtoconservativetechniqueslikeBOA,SOA,DBN,RHSO,
SMO and CNN. The analysis is therefore performed by changing the iterations from

92
K. P. More and R. A. Patil
Fig. 8 Convergence analysis
of suggested SU-SMO model
over extant approaches
0, 5, 10, 15, 20, and 25. In reality, for greater system performance, the cost values must
be at a minimal. The SU-SMO model achieves a better convergence, nevertheless, as
the number of iterations rises. That is, utilizing the SU-SMO strategy, a substantially
lower cost value of 0.1 is seen from the 20th to the 25th iteration, which is much
better than the existing BOA, SOA, DBN, RHSO, SMO and CNN approaches. The
SU-SMO model’s evolution is supported by the overall evaluations.
6
Conclusion
This work focuses on securing data packet delivery by foreseeing channel states (idle
or busy). In this case, a SU-SMO-oriented LSTM algorithm was used to predict the
channel state. Additionally, the AES technique was used to transmit data securely
in the accessible spectrum channels. Finally, analysis was carried out to show how
the model could be improved. Particularly, the proposed model outperforms the
following models in terms of average backoff, under 80 PUs: DCNN (0.436), BOA
(0.474), DBN (0.416), SOA (0.429), RHSO (0.415), SMO-based LSTM (0.371), and
SSOA (0.398), while the proposed SU-SMO method achieves (~)0.375. Additionally,
for 100 PUs, the RHSO and SOA reported channel utilization of 90.67% and 98.33%,
respectively, but the suggested scheme showed maximum channel usage of 91.26%.
In the future, the accuracy and performance of the suggested estimator are evaluated
using various cyclic preﬁx lengths and types.

Advanced Encryption Standard-Based Encryption for Secured …
93
References
1. Deka SK, Sarma N (2017) Opportunity prediction at MAC-layer sensing for ad-hoc cognitive
radio networks. J Netw Comput Appl 82:140–151
2. Cao X, Song Z, Yang B (2018) Multi-slot reservation-based multi-channel MAC protocol for
dense wireless ad-hoc networks. IET Commun 12(10):1263–1271
3. Rajput RS, Gupta R, Trivedi A (2020) An adaptive covariance matrix based on combined
fully blind self adapted method for cognitive radio spectrum sensing. Wireless Pers Commun
114:93–111. https://doi.org/10.1007/s11277-020-07352-9
4. Liu S, Han B, Peng W (2018) A polling-based trafﬁc-aware MAC protocol for centralized
full-duplex wireless networks. IEEE Access 6:28225–28238
5. Mourougayane K, Amgothu B, Bhagat S, Srikanth S (2019) A robust multistage spectrum
sensing model for cognitive radio applications. AEU-Int J Electronics Commun 110:152876
6. Le LB (2015) Design and optimal conﬁguration of full-duplex MAC protocol for cognitive
radio networks considering self-interference. IEEE Access 3:2715–2729
7. Xu X, Zhang N, Song H, Liu A, Zhao M, Zeng Z (2018) Adaptive beaconing based MAC
protocol for sensor based wearable system. IEEE Access 6:29700–29714
8. Patel JB, Collins S, Sirkeci-Mergen B (2020) A framework to analyze decision strategies for
multi-band spectrum sensing in cognitive radios. Phys Commun 42:101139
9. Cheng YC, Wu EH, Chen GH (2016) A decentralized MAC protocol for unfairness problems
in coexistent heterogeneous cognitive radio networks scenarios with collision-based primary
users. IEEE Syst J 10(1):346–357
10. Guirguis A, Karmoose M, Habak K, El-Nainay M, Youssef M (2018) Cooperation-based multi-
hop routing protocol for cognitive radio networks. J Netw Comput Appl 110:27–42
11. Mansoor N, Islam AM, Zareei M, Vargas-Rosales C (2018) RARE: a spectrum aware cross-
layer MAC protocol for cognitive radio ad-hoc networks. IEEE Access 6:22210–22227
12. Li A, Han G (2018) A fairness-based MAC protocol for 5G cognitive radio ad hoc networks.
J Netw Comput Appl 111:28–34
13. Du M, Zheng M, Song M (2018) An adaptive preamble sampling based MAC protocol for
cognitive radio sensor networks. IEEE Sensors Lett 2(1):1–4
14. Aloqaily M, Salameh HB, Al Ridhawi I, Batieha K, Othman JB (2020) A multi-stage resource-
constrained spectrum access mechanism for cognitive radio IoT networks: time-spectrum block
utilization. Futur Gener Comput Syst 110:254–266
15. Narayanan NS, Patnaik M, Kamakoti V (2016) ProMAC: a proactive model predictive control
based MAC protocol for cognitive radio vehicular networks. Comput Commun 93:27–38
16. Patnaik M, Garg C, Roy A, Devanathan VR, Balachandran S, Kamakoti V (2015) Prowatch:
a proactive cross-layer workload-aware temperature management framework for low-power
chip multi- processors. ACM J Emerg Technol Comput Syst (JETC) 12(3)
17. Jha SC, Phuyal U, Rashid MM, Bhargava VK (2011) Design of OMC-MAC: an opportunistic
multi-channel MAC with QoS provisioning for distributed cognitive radio networks. IEEE
Trans Wireless Commun 10(10):3414–3425
18. Tobagi F, Kleinrock L (1975) Packet switching in radio channels: part II—the hidden terminal
problem in carrier sense multiple-access and the busy-tone solution. IEEE Trans Commun
23(12):1417–1433

Multi Energy-Harvesting Smart Water
Meter Design for Underground Water
Pipeline Leakage Detection
Hari Prakash Athinarayanan and Muthupavithran Selvam
Abstract The water leakage detection on pipelines has improved with the advent
of remote environmental wireless sensor network (WSN) and Internet of Things
(IoT) technologies over the past few years. Leakage detection in underground water
pipelines involves algorithms to predict leakage and estimate its location, in which
accuracy depends signiﬁcantly on the distance between the water meters stationed
at district water stations. This research proposes to deploy smart wireless water
meter nodes at intermediate distances to enhance the accuracy sharply. This requires
water meters to operate autonomously, harvesting energy from surroundings, to be
self-sufﬁcient. This research proposes a heterogeneous communication with smart
water meters that focuses on transferring data and reducing energy consumption
by establishing communication with wireless sensor nodes for smart water meter
applications.
Keywords Environmental monitoring · Autonomous smart water meter · Energy
harvesting · Thermoelectric power · Energy storage · Wireless sensor network ·
Internet of Things · Long-Range Wide Area Network (LoRaWAN)
1
Introduction
Energy harvesting (EH) is one of the active researches in electronics, where the
products aim to attain self-sufﬁciency by harvesting energy from ambient sources.
This project’s main initiative is to probe into the energy harvesting for low-power
operating smart water meters to detect leakages in underground water distribution
pipelines. This research focuses on the non-invasive harvesting of energy [1] with a
H. P. Athinarayanan (B)
Newcastle University, Newcastle upon Tyne, UK
e-mail: harish091198@gmail.com
M. Selvam
De Montfort University, Leicester, UK
e-mail: p2519525@alumni365.dmu.ac.uk
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_7
95

96
H. P. Athinarayanan and M. Selvam
multi-source energy harvester to scavenge energy to power the smart water meters. It
uses WSN and IoT infrastructures to communicate [2], and it can be deployed at any
remote location. The wireless sensor network technologies interconnect the individ-
ual smart water meters in the pipelines to form a network of meters that can log real-
time data [3]. Generally, E-WSNs are deployed far from inhabited centers and thus
without access to electricity. To attain autonomous operation [4], the device cannot
consume more power than a harvested source that can provide. Otherwise, when con-
sumption exceeds the limit of energy production, the device will eventually deplete
its energy reserve and cease working. The empty energy reserve leads to undesir-
able system performance. Moreover, the theory of energy-neutral operation [5], and
similar works have been expressed, where the main improvement is the non-ideals
of energy storage devices are considered, yielding an enhanced theory. The energy
consumption was compensated in operating low-power devices with EH techniques
for autonomous operation. The (EH) techniques related to several sources can be
implemented simultaneously to harvest more energy using multi-energy harvesters
or multi-source energy harvesters [6] to meet the energy consumption demand in
low-powered devices. Moreover, the proposed self-powered water meter designs [7]
made the water distribution system more sophisticated and enhanced data manage-
ment. Further, the possibilities of harvesting energy from different available energy
sources were analyzed to explore EH methods.
2
Ambient Energy Sources
2.1
Energy Sources in the Underground
The underground facility of water transmission pipelines has an unlimited energy
source for ambient energy harvesting, including indoor solar, piezo-electricity, air
current ﬂow, acoustic noise, and thermoelectricity. The presence of water pipelines
also allows harvesting energy from the water ﬂow in the pipes, vibration on the pipe
surface, triboelectric energy, temperature variations in the outer metallic surface,
and acoustic noise caused by the pipes. These energy harvesting sources can be used
by considering the project scenario. The preliminary analysis unfolded that a single
energy source is insufﬁcient for attaining self-sufﬁciency. The selection of energy
sources must be considered signiﬁcantly based on the application characteristics and
environment. Moreover, various energy sources exist in the same environment, which
supports improving the harvested energy for operating the device like smart water
meters. As the energy sources coexist in nature, it is inefﬁcient to consider only one
primary source as a suitable source while designing an autonomous powered system.
This negligence of not considering multiple sources limits the quantity of energy
harvested from the ambient sources, resulting in a fallback of device efﬁciency due
to insufﬁcient power. The actual ambient energy harvesting implementation involves
multiple energy source harvesting methodologies to extract as much energy from the

Multi Energy-Harvesting Smart Water Meter Design for Underground …
97
environment to meet the load demand of the smart devices [8]. Multi-source energy
harvesting is a potential solution to attain self-sufﬁciency, as it compensates for the
ﬂuctuations in ambient sources caused by natural phenomena.
2.2
Selection of Sources for Harvesting
The presence of an energy source and availability of a harvesting technology does not
imply that the harvesting can be efﬁcient. The energy harvester should be compact,
energy conversion efﬁcient and cost-efﬁcient to deploy for harvesting energy from the
available sources. Certain factors should be considered while selecting the sources for
multi-source energy harvesting [9], such as power density, the energy source’s nature
of deploying environment, cost-effectiveness, the efﬁcacy of energy harvesting, and
the size of the overall harvester [10]. These factors are signiﬁcant while selecting
sources for self-powered systems during design considerations. Considering these
factorsovertheenergysources,thepotentialsourcestoharvestenergyinunderground
water pipelines are water ﬂow in pipes, thermoelectric energy, piezoelectric energy,
and indoor photovoltaic energy. The energy sources such as airﬂow, triboelectric
energy and acoustic energy are not considered as they are inefﬁcient and not cost-
effective to implement in the project deployment environment. Moreover, the aim
to harvest energy by a non-invasive approach in an underground pipeline limits the
consideration of energy harvesting from the water ﬂow inside the pipelines and
the general photovoltaic harvesting for multi-source energy harvesters. Indoor solar
harvesting is not efﬁcient to implement because the presence of indoor lights in an
underground pipe facility is an uncertain factor. Hence, the potential sources that can
be abundant and suitable are shortlisted, which are thermoelectric and vibrational
energy [11]. As a ﬁrst stage approach, this project implements the thermoelectric
energy harvesting of a multi-source energy harvester in a water pipeline, considering
the underground environmental factors.
3
Proposed Architecture
3.1
Network Architecture Design
The core idea of this research is to deploy sensor nodes at intermittent distances,
which are connected by ZigBee and LoRaWAN wireless communication networks
with the gateway device, as shown in Fig.1. The architecture diagram provides a
design consideration to interconnect the smart water meters to IoT web server for
monitoring and detecting leakages more efﬁciently. The proposed architecture con-
sists of three segments: end nodes, gateway, and network server. The end nodes are
the clusters formed by interconnecting sensor nodes (smart water meter), in which
each cluster has several sensor nodes and a cluster head node.

98
H. P. Athinarayanan and M. Selvam
Fig. 1 Network architecture of smart water meter
The sensor nodes of each cluster are powered by energy harvested from multiple
ambient energy sources to make the sensor nodes work in autonomous mode. These
sources’ energy density is dependent on multiple uncertain factors. Hence, the cluster
nodes are powered from an energy storage device attached to the harvester unit of
the smart water meter. The cluster heads transmit the collected data to the gateway
device, which further sends the data to the IoT web server. The leakage prediction
and estimation algorithms are performed over the data stored in the server.
3.2
Energy Harvester Architecture Design
The environmental factors favor harvesting energy in the outdoor environment while
providing limited support in the underground environment. So, suitable and proﬁtable
energy sources must be harvested by using the multi-source energy harvester to
support the smart water meters. The identiﬁed sources include thermoelectric energy
sources, vibration energy sources and indoor light sources. These sources contribute
to the operation of the autonomous smart water meter, where the thermoelectric
source dominates as a signiﬁcant energy contributor. The thermoelectric energy is
predominant as it is abundant and can be harvested more by increasing the number
of transducers, whereas the indoor light dependent PV cell-based energy transducer
is limited by the availability of lighting device and its brightness, and the vibrational

Multi Energy-Harvesting Smart Water Meter Design for Underground …
99
Fig. 2 Multi-source energy harvester design topology
energy harvesting is highly limited as the pipelines are ﬁxed stably by mechanical
structuresforstability.Figure2showsthetopologydesignforthemulti-sourceenergy
harvester in terms of block diagram.
Thermoelectric converters can be realized as alternating current sources combined
with an energy-storing capacitor. The thermoelectric energy is harvested with ther-
moelectric harvester (TEH) cells attached to the outer surface of the pipeline. The
current generated is solely dependent on the temperature changes in the harvester
material, as related by the following equation:
I (t) = a0 AdT
dt
(1)
where I (t) is the current generated by the TEH device at the time instance t, a0 is
the thermoelectric material coefﬁcient vector, A is the surface area of the material
plates, and dT/dt represents the change of temperature over time. The TEH cells
are connected in series and parallel combinations to attain the necessary voltage
threshold for the energy storage device to store the harvested energy. The MEMS
piezo vibration energy harvester converts the micro-vibrations into valuable electrical
energy, which further can be conditioned by the harvester circuit. The indoor light
energy harvester is a special consideration, as it is only used where the indoor lights
are available.
The energy harvested from ambient energy sources has different energy densi-
ties. Hence, the energy harvested is stored in an energy storage device such as a
large capacitor. The energy storage capacitor accumulates the harvested energy and
provides the stored energy to the microcontroller in the burst mode.
The smart water meter master nodes have several internal components in the
circuitry, as shown in Fig.3, to harvest ambient energy to meet the power demand for
datatransmission.Theenergyestimationmethodologieshelpincalculatingthepower
requirements to operate the node in burst mode, which helps in selecting storage
device, microcontroller and in implementing energy-efﬁcient methodologies to save

100
H. P. Athinarayanan and M. Selvam
Fig. 3 Smart water meter cluster head node—single perspective block diagram
power during the operational time of the device. The speciﬁc research challenges are
concentrated in the energy transfer process from multiple energy harvesting sources
to the energy storage device.
3.3
Heterogeneous Data Propagation Wireless Network
Model
The wireless network formed by the smart water meter nodes with a homogeneous
network structure has less efﬁcacy in data transmission. Figure4 represents a hetero-
geneous communication architecture of the design, where the devices are connected
with a microcontroller through a short-range protocol such as IEEE 802.15.4. Fur-
ther, the microcontroller communicates with devices at a distance of kilometers by
employing the LoRaWAN protocol, specialized for low-power systems to decrease
the power consumption of the water meter. LoRa protocol is a ﬁtting technology
that achieves our work’s purpose to deploy low-power performance for long-range
communication.
Short-range Data Communication Network The short-range communication is
achieved by a microcontroller node with an XBee-S2 module conﬁgured as end
devices and a coordinator device, and thus forming wireless sensor nodes and a
cluster head. The XBee-S2 wireless device supports point-to-point communication
to exchange data within 120m. Therefore, the nodes are ﬁxed within the rage of
100m for a better operation of data transmission. The nodes within the cluster range
will send data to the nearby cluster head, in which cluster nodes and cluster head are
assigned and identiﬁed by a device address.
Long-range Data Communication Network A heterogeneous communication
structure with a long-range protocol, such as the LoRa, presents a trade-off between
energy consumption, signal strength, and latency. The network structure has several

Multi Energy-Harvesting Smart Water Meter Design for Underground …
101
Fig. 4 Network architecture of smart water meter system
clusters located at around a few kilometers between them. The cluster nodes transmit
data to the corresponding head node, which operates as a secondary gateway device
in the network. The range of the long range communication of the wireless sensor
nodes is between 100 and 5000m.
Long-short Data Communication Network The long-short network protocol is
an efﬁcient combination of Zigbee and LoRaWAN based on the requirement of the
deployment scenario. The short-range protocol (Zigbee) is implemented only within
the clusters formed by the smart water meter nodes, and the long-range protocol
(LoRaWAN) is used to transmit telemetries data to a gateway device which is located

102
H. P. Athinarayanan and M. Selvam
Fig. 5 LoRaWAN network of smart water meters
at a far distance from clusters and is considered as a shared resource in the network
architecture as shown in Fig.5. Each wireless node acknowledges the presence of
itself by intimating its presence to the cluster head at ﬁxed intervals. The data transfer
frequency depends on the availability of the energy in the energy storage device.
When the sufﬁcient energy is harvested, the microcontroller is woken up from sleep
mode and will start initiating data transfer process. The microcontroller initiates a
data read and data transfer processes, when the energy in the storage is sufﬁcient for
performing a data communication. The cluster head collects the data from its cluster
nodes and transmit the data to the gateway using LoRaWAN protocol. The gateway
device located at the district water station receives the data from the cluster heads of
different clusters.
3.4
Web Server
The telemetric data from different nodes located at intermittent distances between the
district water stations are sent to the IoT web server using HTTP or MQTT protocol
from gateway device to process and predict water leakage using the algorithms.
Generally, the network server has a database where the telemetric data are stored.
The method of deploying nodes in-between may increase the data stack, but these
data are signiﬁcant for improving leakage prediction accuracy as the analysis is
performed over each virtually segmented water pipeline. The corresponding API
can be used to access these data. The rule engine allows the analysis of telemetric
data and provides the estimation results.

Multi Energy-Harvesting Smart Water Meter Design for Underground …
103
4
Electric Energy Harvesting from Water Pipelines
The thermoelectric energy harvesting method [12, 13] mainly depends on the ther-
moelectric generator (TEG), which acts as a transducer device for converting thermal
energy into electrical energy. The thermoelectric energy harvesting technology is for-
mulated based on the Seebeck effect. This effect describes the conversion process
of temperature gradient into electric power that occurs at the junctions of the ther-
moelectric elements of a thermoelectric harvester (TEH) device. TEH device is a
portable and reliable energy converter that can generate electrical energy in appli-
cations where the heat is dissipated unproﬁtably. The TEH as an energy harvesting
module is used in many potential applications such as medical devices, wireless
devices, and consumer electronics.
4.1
TEG Power Harvesting System
The thermoelectric energy harvesting system [14] is a collection of subunits inter-
connected procedurally and tuned to extract energy efﬁciently from the source. It
consists of four major subsystems, as shown in Fig.6, comprising heat sources, ther-
mal harvesters, DC/DC converter, control unit, and an energy storage unit.
The project uses the TEH cells having a dimension of 30 × 30 × 3.4 cm with
a semi-ﬂexible material structure to harvest energy from the pipeline. Eight TEG
modules are connected to form a TEG harvester grid (as shown in Fig.7). This
arrangement in the grid can be altered anytime to match the load demand. Connecting
the TEG devices in series gives the higher scaled output voltage. The scaling is
based on the number of devices connected to the grid. The TEG device connected
in a parallel connection produces a higher current at a ﬁxed voltage, thus providing
sufﬁcient power to drive the load. The TEG produces unregulated output power,
Fig. 6 Block diagram of thermoelectric energy harvesting system with a TEH stacks

104
H. P. Athinarayanan and M. Selvam
Fig. 7 Cross-section view of
TEG harvester grid
positioning over pipeline
and it must be regulated to use it directly or to store it in energy storage devices.
To improve both the parameters, namely voltage and current, to match the load
input and operating requirement, the TEG devices can be connected appropriately in
series and parallel to form a hybrid TEG grid. Here, eight TEH cells are connected
together, forming two parallel circuit lines, with each line consisting of four TEH
cells in series. The DC/DC converters regulate the output DC power by stepping
down or stepping up the voltage to match the output load requirements. Since the
output voltage of the TEG is lower than the load requirements and not constant, the
DC/DC converter becomes signiﬁcant in the TEG harvester system. The DC/DC
boost converter requires a controlling unit to control the transistors’ ﬁring period
and thereby control the duty cycle of the converter component (MOSFET). Hence,
to obtain maximum power from the available input energy from the TEG device, an
algorithm has to be implemented to keep track of instantaneous power and ﬁne-tune
the converter’s duty ratio. The Maximum Power Point Tracking (MPPT) algorithm is
implemented to tune the duty cycle on the operating time dynamically. The harvested
energy is stored in the energy storage device, either a battery type or a storage
capacitor-type device that can store energy to be retrieved to power the load. The
stored energy can then be used directly to power the devices. This stored energy
can be released instantaneously from the capacitor with low internal resistance, or
released slowly with energy buffer circuits.
The output of the DC/DC converter is adjusted to match the input requirements of
the storage element. For example, the input of a 5V capacitor must be allowed utmost
till 4.8V to protect the capacitor from the device’s failure caused by overcharging. It
is acceptable to supply 5V input as the storage devices have its tolerance limit. So, the
device’s output should be lower than or equal to 5V to charge the 5V storage device.

Multi Energy-Harvesting Smart Water Meter Design for Underground …
105
The energy storage subsystem is a crucial component of a sensor node, signiﬁcantly
affecting its overall efﬁciency. The choice of energy storage technology also affects
a smart device’s size, cost, and operating life [15].
4.2
Harvested Energy Management
The power management circuit is signiﬁcant in managing the power stored in the
energy storage device by efﬁciently regulating the input and output power and pro-
tecting the primary circuit. In this prototype, the energy obtained from the harvester
grid (TEG) is stored in the energy storage capacitor. The energy harvested from the
sources is ﬂuctuating based on the water temperature. The capacitor charges to its
maximum voltage unless restricted by an external circuit. Charging the capacitor to
its fully charged state may cause permanent damage to the capacitor due to over-
charge. Hence, the energy storage device requires a power management device and
circuits to manage the power. It allows the DC/DC converter to regulate the input
power by adjusting its duty ratio by implementing the MPPT algorithm to scavenge
maximum available energy. It also protects the energy storage device from overvolt-
age and undervoltage to maintain its health. The power management circuit uses the
BQ25570 ic, an ultralow-power power management integrated controller (PMIC) for
power management, which has an in-built DC/DC boost converter controlled by an
MPPT controller unit, a cold start circuit, and a buck converter.
4.3
Experimental Design and Setup
The experimental prototype consists of energy harvesters, power management hard-
ware, a storage device, and a load. The hardware devices used in the project pro-
totype include THE device (8 cells) as ambient thermoelectric energy harvesters,
BQ25570EVM-206 as power management hardware, and capacitor (5V, 100uF) as
a storage device and MSP430fr5994 Ic circuit with water ﬂow sensor together as
load. The power management circuit with BQ25570 manages the power obtained
from the TEG harvesters. The harvested energy is stored within the capacitor storage
device, and the MSP430fr5994 device with wireless communication device acts as
a load device. The input voltage rating of the Msp430fr5994 device is 1.8–3.6V.
Hence, it is sufﬁcient to provide the voltage directly from the output terminal with-
out activating the buck converter in the BQ25570 IC. The test setup was made by
attaching the TEG module, and the heat sinks to the water pipeline. The harvester’s
output is measured using a digital oscilloscope connected to the output terminal of
the BQ25570 hardware circuit.

106
H. P. Athinarayanan and M. Selvam
Steps to assemble the hardware are:
1. The TEG devices should be connected in series electrically, and the output ter-
minals are connected to Vin and GN D terminals of the J1 connector.
2. The capacitor is connected to VBat and GN D terminals at the J8 connector.
3. At J P2 set of pins, enable pin should be connected to the ground pin using wire
or a shunt.
4. At J P3 sets of pins, the Vout E N pin is connected to the GN D pin using a wire
or a shunt.
5. Fix the shunt between the Voc−sample and 50% in the J P4 pins.
6. Disconnect the shunt between the J P1 set of pins.
7. The output is obtained from the J P11 connector.
In step 3, the enable pin is connected to the ground to enable the IC. The Vout−E N
pin is connected to ground at step 4 to disable the buck converter and get output
directly from the capacitor, bypassing the buck converter. In step 5, the Voc−sample is
connected to a 50% pin because the maximum power point lies around 50 percent
of the open-circuit voltage for the TEG device.
Buck Converter ‘On’ Mode The Buck converter from the BQ25570 chip can be
enabled by connecting the Vout−En with the bat −ok pin in the J P6 pins. The output
of the buck converter is the scaled-down value of the capacitor voltage. The regulated
buck converter output is helpful for the operating systems at a very low voltage like
1.5V.Ahigh-efﬁciencyPFM-basedcontrollercontrolsthebuckconverter.Theoutput
of the buck converter is always maintained at 1.8V at the output terminals.
Buck Converter ‘Off’ Mode The results of the steps in turning off the buck converter
and connecting the output ports directly to the capacitor storage. In this mode of
operation, the buck converter is switched off to get a higher output voltage. At
this mode of operation, the TEG modules are connected in series and ﬁt the water
pipeline, and the output of the harvester is measured using a digital oscilloscope
device. Further, the output of the BQ25570 circuit is 3.17V, which can be directly
fed to the Msp430fr5994 ic as its input requirement is met at this voltage level.
4.4
Simulation
The energy harvester model for thermoelectric harvesting was developed in MAT-
LAB simulation software to observe the system at various temperatures and with
increased TEG devices. This harvester model also includes the process within the
PMIC hardware. It consists of subsystems such as the TEG model, overvoltage and
undervoltage protection models, boost converter model, and capacitor storage model.
To estimate the coefﬁcients of the harvester, the number of cells in series is set to 1,
and the hot and cold temperatures are ﬁxed to 49.7 and 33.2 ◦C, respectively (given
by the manufacturer in the datasheet for a standard reference value) and simulated. A
similar circuit consisting of the same conﬁguration but with four cells is connected
in parallel and four cells in series with the simulation circuit. The model and the

Multi Energy-Harvesting Smart Water Meter Design for Underground …
107
simulation waveforms are obtained from simulating the setup. The output of the
TEG model is connected to the overvoltage protection model of capacitor. Further,
the output is given to the DC/DC boost converter circuit controlled by an MPPT
controller model [16], providing the duty ratio for the converter. Further, the boost
converter’s output is fed to capacitor storage as input. Then, there is an undervoltage
protection model to monitor the voltage level of the capacitor and a trigger circuit
that triggers a switching device that connects the load to the capacitor when its volt-
age level reaches a value of 3.2V. In the case of overvoltage situations or under the
absence of load, a separate parallel circuit with a shunt resistor is connected to the
TEH array.
5
Result
The geometrical shape and structure of the heat sink also greatly inﬂuence maintain-
ing a thermal gradient in the TEG device. The proposed system that insulates the
inner side heat sink by a thermal insulator will help maintain the temperature at that
side without the interference of surrounding air. This will improve the output of the
TEG device signiﬁcantly. The TEG stack formed by sandwiching the TEG device
between heatsinks and ﬁtting to the water pipeline by connecting TEG devices in
series to scale up the terminal voltage will help the capacitor charge quickly, thereby
providing power to the load device. The output produced by a single TEG device
might not have been more helpful, but the array of TEG devices drastically improves
the energy harvested and thus making it a potential harvesting energy source.
The PMIC hardware circuit (BQ25570) supports burst power mode powered by
a storage capacitor. The energy harvester built with TEG devices, BQ25570-based
power management circuit and capacitor, harvests energy with the usage of MPPT
controller for boost controller operations to meet the load demand of smart wireless
device loads. The energy harvested from the TEG array containing TEG stacks con-
nected in series is continuously fed to the storage capacitor via boost convertor and
is further supplied to the load device. The boost converter duty ratio is tuned by the
MPPT controller circuit every 16s. The MPPT controller circuit interrupts the cir-
cuit every 16s and updates the maximum power point by storing the corresponding
voltage to the reference voltage capacitor, which is used as a reference for adjusting
the duty ratio of the boost converter. The output buck converter is turned off, as it
does not require in the project scenario. The data obtained from the practical exper-
imentation is simulated in the simulation model to validate the simulation results.
The simulation model used the same process ﬂow from the hardware to design the
equivalent thermoelectric harvesting model. The simulation model could produce an
output as nearly as the physical experiment readings.
The hardware setup is ﬁtted over the outer surface of the water pipeline to log the
data for experimentation. The energy storage device accumulates energy obtained
from the transducer belt containing TEH cells, which is conditioned by the PMIC
circuit. The PMIC charges the energy storage device until the preset voltage threshold

108
H. P. Athinarayanan and M. Selvam
Fig. 8 Waveform showing charging and discharging of the energy storage capacitor
Fig. 9 Output graph of a simulation showing input, output and capacitor voltages
of 3.2V. Once the sufﬁcient energy is available, the main microcontroller reads the
data from the sensors and transfer the processed data to the cluster head. Figure8
shows the waveform displaying the voltage across the capacitor while charging and
discharging occur in the PMIC hardware circuit. The voltage gets built in capacitor
in steps up to 3.2V, then the PMIC hardware circuit connects the microcontroller of
smart water meter to the energy storage capacitor, causing a drastic drop in voltage
across the capacitor.
The simulation model waveforms shown in Fig.9 can also be observed to infer
that the output generated is nearly the same as the physical readings obtained by the
experiment. The simulated harvester produces a ﬁxed output voltage level of 3.2V
(ideal case) in its output, and the real-time measurement obtained is 3.17V when the
capacitor value is above the threshold voltage of 3.2V, which can be observed from

Multi Energy-Harvesting Smart Water Meter Design for Underground …
109
Fig. 10 Output waveforms of the simulation
Fig.10. Thus, the harvester prototype helps attain self-sufﬁciency in terms of power
by adding different energy source harvesters and the present harvester or by scaling
up the number of TEG devices.
6
Conclusion
The research aims to deal with the challenges of harvesting energy from underground
water pipelines without a non-invasive approach to the pipelines. The deploying
location of the system restricts access to primary harvest sources of energy. So, the
project aims to develop a multi-source energy harvester to overcome unfavorable
environmental factors. The multi-source energy harvesting is a suitable solution to
compensate for the absence of quality energy sources like light sources. It tries to
compensate for quality by utilizing quantity. The project implements the thermoelec-
tric harvesting process in the water pipelines, considering the underground scenario
with a non-invasive approach.
The TEG devices were studied to harvest energy from the thermal gradient by
ﬁxing them to the pipes. Every minor increase in the output power inside the under-
ground facility is advantageous for the system to operate with high efﬁcacy. After
considering the effects of thermal buffers, all the TEG modules were equipped with
heat sinks. Now, the TEG modules are connected to form an array in which the TEG
conﬁgurationswereinvestigated,andseriesmodealoneisimplementedinthisproject
due to the unavailability of more TEG devices. As investigated, the TEG modules
can be interconnected in series or parallel or hybrid ways based on load require-
ments. These conﬁgurations also inﬂuence the charging action of the capacitor. The
BQ25570 power management circuit is used to harvest energy efﬁciently, manage
the power effectively, and protect the storage element. This hardware containing
an MPPT controller automatically implements the MPPT algorithm to improve the
output harvested energy.
The practical experiments were conducted to study the working of this power
management device. The device was made to operate by switching off its buck
converter. Thetest results wererecordedseparately. Thesimulationwas performedby
creating an equivalent model of the physical system. The output waveforms validate

110
H. P. Athinarayanan and M. Selvam
the model’s correctness by providing nearly the same output as the recorded data
in practical experiment, which further validates the research approach. The project
achieved its aims and objectives thoroughly with the prototype. It was able to cross
some of the stepping stones to create an autonomously powered system.
7
Future Works
The project dealt with a single power source for the initial approach stage, but could
adapt to any energy source by slight modiﬁcation in its harvester unit. The challenges
inharvestingotherambientenergysourceswillbestudied,andtheirharvesterswillbe
added to the circuitry to develop a full-ﬂedged self-powered system in underground
water pipelines. On combining various energy harvesters, voltage imbalance can
occur in the circuit due to uneven energy generation. This will be studied and solved
before implementation in the underground water pipelines. The wireless network
architecture proposed in this paper will be implemented further to upload and analyze
the telemetric data in the IoT cloud server.
References
1. Sharma RR (2021) Gas leakage detection in pipeline by SVM classiﬁer with automatic eddy
current based defect recognition method. J Ubiquitous Comput Commun Technol (UCCT)
3(3):196–212
2. Shaikh F, Zeadally S (2016) Energy harvesting in wireless sensor networks: a comprehensive
review. Renew Sustain Energy Rev 55:1041–1054
3. Stoianov I, Nachman L, Madden S, Tokmouline T (2007) PIPENET a wireless sensor network
for pipeline monitoring. In: Proceedings of the 6th international conference on Information
processing in sensor networks—IPSN ’07
4. Ozel O, Tutuncuoglu K, Ulukus S, Yener A (2015) Fundamental limits of energy harvesting
communications. IEEE Commun Mag 53(4):126–132
5. Kansal A, Potter D, Srivastava M (2004) Performance aware tasking for environmentally pow-
ered sensor networks. ACM SIGMETRICS Performance Eval Rev 32(1):223–234
6. Colomer-Farrarons J, Miribel-Catala P, Saiz-Vela A, Samitier J (2011) A multiharvested
self-powered system in a low-voltage low-power technology. IEEE Trans Ind Electronics
58(9):4250–4263
7. Garg R, Garg N (2020) Energy management in a multi-source energy harvesting IoT system.
J Inf Technol Res 13(2):42–59
8. Tuna G, Gungor V (2016) Energy harvesting and battery technologies for powering wireless
sensor networks. In: Industrial wireless sensor networks, pp 25–38
9. Prauzek M, Konecny J, Borova M, Janosova K, Hlavica J, Musilek P (2018) Energy harvesting
sources, storage devices and system topologies for environmental wireless sensor networks: a
review. Sensors 18(8):2446
10. Randriantsoa A, Fakra D, Rakotondrajaona L, Van Der Merwe Steyn W (2022) Recent advances
in hybrid energy harvesting technologies using roadway pavements: a review of the technical
possibility of using piezo-thermoelectrical combinations. Int J Pavement Res Technol

Multi Energy-Harvesting Smart Water Meter Design for Underground …
111
11. Shah N, Sundar S (2018) Smart electric meter using LoRA protocols and lot applications.
In: Second international conference on electronics, communication and aerospace technology
(ICECA)
12. Enescu D (2019) Thermoelectric energy harvesting: basic principles and applications. In: Green
energy advances
13. Akhtar F, Rehmani M (2015) Energy replenishment using renewable and traditional energy
resources for sustainable wireless sensor networks: a review. Renew Sustain Energy Rev
45:769–784
14. Kim S, Chou P (2015) Energy harvesting with supercapacitor-based energy storage. In: Smart
sensors and systems, pp 215–241
15. YajimaT,TanakaK,YazawaK(2018)Thermoelectricon-spotenergyharvestingfordiagnostics
of water service pipelines. In: 17th IEEE intersociety conference on thermal and thermome-
chanical phenomena in electronic systems (ITherm)
16. Mamur H, Çoban Y (2020) Detailed modeling of a thermoelectric generator for maximum
power point tracking. Turkish J Electrical Sci Comput Sci 28(1):124–139

Tensor Flow Model with Hybrid
Optimization Algorithm for Solving
Vehicle Routing Problem
Jai Keerthy Chowlur Revanna and Nushwan Yousif B. Al-Nakash
Abstract Vehicle routing and path management system improves the best key point
of selecting the path of the vehicle to move. The applications that are used for
delivering the products utilize Google data to organize the vehicle movement and its
coordinate positions. The trafﬁc level indicator and the speed of vehicle movement
validate the Vehicle Routing Problem (VRP)- route. Since there is another important
parameter that needs to consider for the delivery process. In that, the application
needs to validate the amount of traveling time and the length through which the
vehicle can travel to deliver the products. This requires a better prediction model
to estimate the multiple parameters of vehicle routing problems. In the proposed
study, a Tensor Flow-based routing path prediction approach was chosen to train and
predict the best route using the attribute weight matrix. From the parameters of the
distance between the coordinates with the amount of trafﬁc range and other related
attributes, the Tensor Flow model forms the rule to train the machine for predicting
the route for vehicle movement. This model updates the learning model based on
the change in parameter value and its range. The experimental result compares the
suggested work to the current model of optimum VRP prediction approaches.
Keywords Vehicle routing problem (VRP) · Ant colony optimization (ACO) ·
Tensor ﬂow model (TF) · Optimal routing path and multi-objective learning
1
Introduction
The vehicle path identiﬁcation and prediction process in area of coordinate position
and grouping represents a dynamic update of data from the database to analyze the
state of routing path prediction in coordinates and mining system for VRP dataset.
J. K. Chowlur Revanna (B) · N. Y. B. Al-Nakash
Information Systems Engineering and Management, Harrisburg University of Science and
Technology, 326 Market Street, Harrisburg, PA 17101, USA
e-mail: JChowlur@my.harrisburgu.edu
N. Y. B. Al-Nakash
e-mail: nal-nakash@harrisburgu.edu
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_8
113

114
J. K. Chowlur Revanna and N. Y. B. Al-Nakash
This will be updated for a period interval that is processed in frequent order. There
are several methods in classiﬁcation and analyze the database contents like neural
techniques and other machine learning technics. In that, sequence pattern method
with the several neural network were most used to classify and match the relevant
features from database [1]. Since, for the huge amount of node characteristics in
data, it struggles in predicting class with proper attributes of feature vector. This
searching process predicts the relevant feature that compares the input query with
the database in high-speed analysis of large path data. In the recent research work,
the matching prediction is complicated due to more irrelevant features present in the
database [2]. To improve the performance of feature identiﬁcation in the searching
process, machine learning technique helps to predict the best matching between the
query data and feature sets in database. There are several type of machine learning
techniques like support vector machine (SVM), relevant vector machine (SVM),
and other methods. Since, in the recent days, the neural network and deep learning
technique takes place a major role of data analysis and match prediction among the
bulk amount of raw data.
For this condition, it directs into the routing-based data monitoring and controlling
system by remote locations [3]. This is to provide data management and optimized
travel to database of hospital management. In the data travel process, it needs to
travel through the worldwide connectivity [4]. In that, there are lot of data patterns
that can capture and identify the data which can change the database information
about the user path parameters and about medicinal value that are ordered by people.
This needs to be prevented by highly optimized data travel and storage systems
in the cloud environment [5]. For data management and predicting there are lot of
prediction and re-routing techniques available to optimize the data that can protect
data who doesn’t have the encryption technique. Still, there are some limitations that
are in the data storage and even to retrieve the database.
To solve this management and predicting problem in routing environment, this
work proposes a novel routing management and predicting system integrated with
Tensor Flow (TF) model. In this model, the TF manage the path that vehicle can
travel by identifying the properties/features of data from routing path trafﬁc level
to predict the normal/range of trafﬁc pattern by using the Ant Colony Optimization
with Genetic Algorithm (ACO–GA). If this was identiﬁed as normal, then the normal
ﬂow of data travel will take care. If this was identiﬁed as pattern type of the trafﬁc
range, then this was reported to controlling system or to the routing systems to
predict the data pattern at the stage of initial ﬂow. Then this was also forward to the
training model of TF to update the characteristics of the data pattern and arrange the
features of it. This will enhance the feature learning of TF and the characteristics
and parameters of data pattern up to time instant. This can be achieved by the Spatial
Pattern Super Learning (SPSL) method. This analyses the parameters by probabilistic
distributional features to update the learning model. This can identify the multiple
combination of parameters to group it and form as the cluster for better prediction
process.

Tensor Flow Model with Hybrid Optimization Algorithm for Solving …
115
The primary objectives of this paper are.
1. By carefully choosing the best route for data forecasting, to improve the
prediction performance of routing.
2. To increase the speed of vehicle movement and the reliability data processing on
vehicle, optimization method using ACO–GA was designed.
3. To estimate the location of users based on the routing properties for improved
data analysis and forecasting.
4. Tensor Flow is introduced into the process of generating parameters to facilitate
the analysis of the multi-objective parameters of the optimization model.
The rest of the other sub-sections are organized and elaborated as mentioned
below. Section 2 gave a study and review of the current VRP model, along with
its beneﬁts and drawbacks, based on the proposed enhancements. Section 3 explains
about the proposed optimal routing path selection system based on the ACO–GA with
Tensor Flow model. Section 4 evaluates the effectiveness of suggested VRP model
with the prediction rate, and it contrasts the estimated ﬁndings with the conventional
methods to demonstrate the superiority of this new implementation. In Sect. 5, which
concludes the paper and summarizes the future recommendations on this work.
2
Related Works
Here a critical review is performed on different optimization models and the routing
algorithms that are to optimize the vehicle routing problems. In that, the merits and
the demerits of each model were explained and validated.
The beneﬁt of this plan was that it guaranteed the vehicle’s reliability and routing.
An adaptive technique for effectively boosting the accuracy of safety message fore-
casting on the vehicle was introduced in [6]. Here, the error recovery probability
rate of data forecasting was calculated using the Adaptive Byte Hybrid Automatic
Repeat Request (AB-HARQ) approach [7]. A dynamic virtual bat algorithm [7]. In
the development of a method for supplying routing to VRP with a reduced latency
frequency. The objective here is to combine the beneﬁts of Simulated Annealing
(SA) and Particle Swarm Optimization (PSO) to improve the performance of opti-
mization during path selection. A new data forwarding strategy was suggested in [8]
for raising the VRP’s overall performance rate. Here, trafﬁc information was used
to guarantee accurate vehicle forecasts. A sensor clustering strategy was developed
in [9] to address the vehicle’s concealed terminal problem, reliability, and resource
scarcity problems. The applications of privacy preservation, target tracking, and
misbehavior detection may be appropriate for this clustering technique.
A summary of data dissemination techniques and the signiﬁcance of QoS for VRP
are given in [10]. The difﬁculties with connection stability and energy consumption
have been examined in this paper, along with the best methods for enhancing VRP
performance. A unique algorithm for decreasing the broad-cast storms on VRP was
devised in [11]. This work’s strength was that it established the emergency message

116
J. K. Chowlur Revanna and N. Y. B. Al-Nakash
forecasting in the simplest possible way. A new V2VR approach for ensuring VRP
routing was introduced in [12]. In this case, a routing choice system based on the
Manhattan mobility model was used to shorten the longer predicted distance. In this
paper[13],adatadistributionstrategyforenhancingtheefﬁciencyofdatadeliveryvia
VRP is suggested. To distribute the data among the users, a probabilistic forwarding
mechanism was used [14]. This work’s beneﬁts were less message latency.
In [15] the author a Batch Veriﬁcation Certiﬁcateless Ring Signature (BV-CLES)
technique for making sure reliable navigation and dependable information fore-
casting on VRP. The primary objective of this research was to effectively reduce
the computational overhead and delay of the vehicle for VRP connection. In addi-
tion, the transportation of the vehicle was accelerated by implementing a signature
veriﬁcation method. The most important contribution of this research was that it
offered a faster routing system for automobiles and lowered computing expenses.
A decentralized parameters control system was suggested in [15] to enhance VRP’s
information forecasting. This work used a lightweight mutually relevant prediction
approach to raise the vehicle’s routing level. The following is a list of the main
factors that this work took into account: licensed parameter storage, licensed param-
eter management, mutual relevant prediction, updated parameters, and revocation.
Additionally, distinct categories of missing data, such as those caused by collusion,
DoS, and resisting internal missing data, were identiﬁed in this work based on the
routing analysis. The need to lower computational overhead, computational cost, and
storage overhead still exists.
For improving the routing of VRP [16] used a hybrid conditional privacy preser-
vation approach. This work’s main goal was to use a privacy-relevant prediction
algorithm to address the identity revocation problem and lessen computational over-
head. In this instance, this anonymous identity was considered the local short-term
identiﬁer accountable for signing the safety-related communication. In addition, a
bilinear pairing based on the cyclic groups of the bilinear map was performed [17].
This technique’s design objectives included efﬁciency, pertinent prediction, conﬁ-
dentiality, revocation, and privacy. This mechanism’s beneﬁts included improved
speed and robustness with effective message-relevant prediction. Reliable commu-
nication over VRP can be established by using an improved routing method that uses
the Multipoint Relay (MPR) scheme, as described in [17]. The goal of utilizing the
OLSR algorithm in this case was to enhance the MPR selection strategy to prevent
data reforecasting. Additionally, several metrics including delivery ratio, throughput,
and vehicle delay were estimated.
A self-checking procedure was used in [18] to increase the routing VRP data
transfer. This system was divided into four stages: registration, relevant prediction,
missing data detection, and self-checking. By assuring randomization, this approach
primarily aims to safeguard the vehicle from missing data users. For the purpose
of ensuring the routing and conﬁdentiality of VRP, [19] adopted a Comprehensive
Identity Relevant Prediction Scheme (CIAS). In this study, asymmetric processing
and pertinent prediction procedures were used to build trust amongst the entities [19].
Finding a damaging lacking data against the automobile and offering appropriate,
pertinent prediction solutions were the main focuses of this work. Blockchain and

Tensor Flow Model with Hybrid Optimization Algorithm for Solving …
117
trafﬁc ﬂow computation procedures were used to build an effective routing architec-
ture for VRP in [20]. This architecture includes the service the road trafﬁc computing
layer, service layer and the perception layer [21]. In which the perception layer was
used to enhance the routing of the vehicle during data transfer. The drawback of this
architecture was that it necessitated increasing the vehicle’s overall routing and data
forecasting pace.
Here prediction models are used based on the Confusion matrix. The primary
classiﬁers are F1 score, precision, accuracy, and recall which are used as prediction
model in the paper [22]. The confusion matrix is necessary to determine the clas-
siﬁcation accuracy of the machine learning algorithm while categorizing input into
their respective labels. Below is the deﬁnition of each terms:
Accuracy: It is the ratio of occurrences of correctly categorized data to the total
number of instances of data.
Precision: A strong classiﬁer must preferably have a precision value of 1 (high).
When the numerator and denominator are identical does precision equal 1.
Recall: Recall must preferably equal 1 (high) for a classiﬁer to be effective. When
the numerator and denominator are equal does recall equal 1.
F1 score: The F1 score is only good if both accuracy and recall are indeed high.
F1 score is the arithmetic average of recall and precision and is a more accurate
measurement than precision.
3
Methodology
This section discussed optimal vehicle routing models with the optimization func-
tions and the other related parameter-based categorizations. In this, the overall
process was segmented as the following stages:
• Preprocessing
• Optimization
• Tensor Flow Prediction
Figure 1 shows the architecture of ACO used with Tensor Flow which is the
proposed work in this paper. In this, the preprocessing covers the initial cluster of
data to organize the coordinate position of users and the initial weight estimation
[23]. Then from that, the optimization functions retrieve the best routing path and
the minimum distance-based path selection. Since, the optimization models are tuned
to select the best routing path for vehicles based on their objective function design
and the weight calculation of each path attributes. The capacity and demand are
decided based on the customer needs in the area. The capacity is estimated based
on Solomon benchmark data set for each case [24]. For example, in Case C101 the
capacity is estimated based on the number of customers. In this paper the capacity is
estimated for 100 customers and the demand is served according to the customer’s

118
J. K. Chowlur Revanna and N. Y. B. Al-Nakash
needs. Similarly, for R101, RC101, R103, and all the cases shown below in the
ﬁgures are deﬁned. The demand is the number of locations requested to be delivered.
The demand is the number of locations requested to be delivered. Once the capacity
estimation is performed, demand is served.
The following sub-sections explain the detail structure of routing path selection.
The parameters are deﬁned by time interval, no. of iterations, no. of customers. All
the above parameters are based by counting the number of vehicles and locations.
The parameters are initialized as shown by algorithm 1 below from p to 1, that starts
the loop from 1 and by repeating the iterations it selects the best path. As shown
in Table 1 different parameters were also compared with ACO–GA and it is shown
Fig. 1 Proposed work

Tensor Flow Model with Hybrid Optimization Algorithm for Solving …
119
Table 1 Results of different
parameters for proposed work
Parameters
Value
ACC macro
0.99326
Conditional entropy
0.20469
Kappa
0.96153
Hamming loss
0.02359
Overall ACC
0.97641
Overall MCC
0.96171
Overall RACC
0.38682
PPV (macro–micro)
0.93204–0.97641
Reference entropy
1.69515
TNR (macro–micro)
0.99584–0.99607
Zero–one loss
4449
Response entropy
1.73724
Standard error
0.00035
TPR (macro–micro)
0.9769–0.97641
by the Tensor Flow output in Table 2 that ACO–GA has increased the performance
compared to other methods. Regarding crossover and mutation for the GA algorithm,
crossover is the primary operation, mutation is the secondary. As mentioned above
crossover is primary which is 90% and mutation is 10%. Mutation alters the value of
parameters here just like the genes and crossover is a special process that is employed
to alter the sequencing of chromosomes through one generation to the next.
Once the parameters are fed, it combines with the ACO parameters, and two
different genes are crossed. Here genes are nothing but destination routes. In this
way the best parameter is mutated and fed into the channel till it yields the best route
after multiple iterations. Lastly, the ACO–GA is integrated with google maps API.
Once the ACO–GA results are provided, the results are calculated by Tensor Flow
Table 2 Detection rate comparison of proposed vs. state of art methods
Methods
F1 score (%)
Accuracy (%)
Recall (%)
Precision (%)
PSO-SVM
19.3
48.8
14.8
27.9
ACO-SVM
23.1
72.9
15.7
43.3
GA-SVM
28.6
51.9
19.9
50.5
ACO–GA
73.6
67.7
75.2
71.3
Neural Network
76.8
74.7
76.3
77.3
Proposed
83.6
81.4
84.2
84.3
ANN
74.2
71.9
75.4
73
PNN
76.8
74.7
76.3
77.3
Proposed
83.6
81.4
84.2
84.3

120
J. K. Chowlur Revanna and N. Y. B. Al-Nakash
model and the best route is decided, it veriﬁes the current route with google maps
and overwrites the best path on google maps which then updates the correct path.
3.1
Preprocessing
Data preprocessing or ﬁltering is one of the most essential stages in data processing
application systems, because the performance of classiﬁcation system is highly
dependent on the quality enhanced data. Filtering techniques are mainly used to
remove noise/artifacts, improve contrast, improve quality, and smooth data. To this
end, attribute collaboration and ﬁltering techniques were used to remove noisy
content present in the original data. This is one of the ﬁltering approaches widely
used in many data processing systems. The main reason for using this technique
is to efﬁciently deblur the data with a better smoothing effect. Computes a ﬁlter
function based on averaging neighboring pixels to remove noisy pixels. The primary
reason for preprocessing the dataset is to ﬁlter the non-essential data. Here missing
values which are the vehicle stops were inserted into the dataset values. Without
merging values, it could not be merged with google maps and performance cannot
be measured without this. By merging the data with google maps, the data integration
worked here. Data preprocessing also helped in selecting the best attributes from the
Solomon benchmark dataset to improve performance.
3.2
Optimization
The optimization model of this paper is to focus on the hybrid model of ACO and GA
optimization algorithm that are fused to perform the routing path selection for the
vehicle database. In this the optimization helps in analyzing the cost value with the
hybrid model of objective function to estimate the convergence of cost value for each
iteration count. In this, the ACO selects the possible paths for the vehicle to travel
in the way. The ACO–GA, when hybridized, provides the best path by performing
the max number of iterations [25]. When different paths are analyzed repeatedly, the
algorithm chooses the shortest path with the least constraints and is chosen as the
best path. Then, the GA estimates the acceptable level of the similarity and based
on the cost value, the best path among the listed path was selected and justiﬁed as
the best selection of routing path. Algorithm 1 explains the steps involved in hybrid
ACO–GA optimization algorithm.

Tensor Flow Model with Hybrid Optimization Algorithm for Solving …
121
3.3
Tensor Flow Model
Following the extraction of the route patterns, the TF classiﬁcation technique—which
involves the processes of data training and testing—is used to precisely identify the
occluded item. The TF is developed based on the machine learning model of trained
feature set, where the classiﬁcation has been done by splitting the features into blocks.
The main intention of this technique is processing the paths based on the separate
blocks of featured paths, which helps to increase both the prediction accuracy and
efﬁciency of classiﬁcation. In this architecture, it has three layers mainly input,
output, and hidden layers where the input patterns are gained by using the input
layer [26]. After this hidden layer starts processing the patterns of path. Algorithm 1
explains the steps involved in Tensor Flow prediction algorithm. In the tensor ﬂow
model, the matrix used is F1 score, precision, accuracy, and recall.
3.4
Algorithm [3, 7, 23]
Input: Data {Ni}, , ﬂow link cost (FLC) ci j
Output: Efﬁcient routing selection process and security technique
For iteration = 1 to p
//Looping for ‘p’ number of data links in a database
Invoke γ be the data link’s load value, which may be expressed
γ = {N, L}
// where ‘N’ deﬁnes the number of database records and ‘L’ deﬁnes the distance
between each record.
For i = 1 to n
//’n’ is data count
For j = 1 to l
// ‘l’ is no. of connections.
Create network trafﬁc

f k
i, j

for ‘k’ no. of attempts
Update γ k
(i, j) = γ(i, j)( f k
(i, j)), ∀(i, j) ∈L
Calculate route selection probability {yk
i, j} in the database design as

yk
i, j

=

s,d

t
hs,d × P(r|Cn)

vs,d

f k
i, j

× ar
i, j

122
J. K. Chowlur Revanna and N. Y. B. Al-Nakash
where (s, d) represent the pair between source and destination.
vs,d–Vulnerability weight of Docker path
ar
i, j–is the no. of transmissions to data in (i, j) as shown in the architecture
for the territory of ‘r’.
Update ﬂow pattern,
f k+1
i, j
= f k
i, j + αn ×

yk
i, j −f k
i, j

Verify closure for every k+1 value
Calculate G(y) = max(yk
(i, j)).
// Find maximum potential point for determining selected duration
Calculate L( j) = 1
n
n
(x=1)
		N( f k
(i, j)) −G(y)
		
//Find the distance vector between each data.
If λ < L, then
// λ deﬁnes the security strength of data
Data transmission.
Calculate ( j) =  j−1 + μ × ∂L/∂W l
i .
// From the data index, ﬁnd the best data with the nearest distance property.
Calculate ci, j = W l
j + ( j).
// Adjust the vulnerability cost value
Continue.
Else
Afﬁrm the path
Use data parameters to evaluate risk parameters
Continue loop.
End If
End For ‘j’
End For ‘i’
From the updated table, pick the best option. ‘yk
i, j’
Update database weight and design architecture.
End For.

Tensor Flow Model with Hybrid Optimization Algorithm for Solving …
123
4
Results and Discussion
Here in this section, simulation results discusses and the comparative analysis of
ACO–GA with Tensor Flow model and other optimization algorithm of the vehicle
routing system. The overall test analysis was experimented with the standard dataset
of Solomon’s benchmark dataset which is publicly available and referred from the
existing work of the routing system [26], there are 100 records taken for Solomon
benchmark. The overall work was implemented in the PYTHON 3.8 tool in terms of
‘.py’ scripts and related libraries. In this test analysis, the results can be compared
with the other existing optimization methods that are referred to in [27].
In that, the dataset contains the several position and coordinate information about
the user that are in the coverage area. In that, the dataset is divided into three different
categories of ‘R’, ‘C’, and the combination of both as ‘RC’.
Figure 2 shows the simulation result for the sample of data combination of C101,
R105, for all the 100 number of users available in the dataset. In these graph result,
the X and Y-axis represent the ‘X’ and ‘Y’ coordinate position of users, respectively.
Similarly, the Fig. 3 shows the simulation result for RC105.
This simulation step concentrates on the output graphical result of ACO–GA
optimization for VRP. In that graph, the title displays the number of vehicles that are
optimized and the amount of area that covered by those vehicles are mentioned for
the 10th iteration of simulation result.
The maximum number of iteration was initialized as 100 to search for the 100
number of users that are to be linked. In that, the vehicle was started from the center
of that are coverage and serves the link combination between users and the vehicle.
Table 1 it discusses about results of different parameters for proposed work and its
values.
We can see the execution time taken for each simulation result is 5.491 s. We have
multi-objective, along with cost, we have distance reduction, etc. Cost function–It is
Fig. 2 Simulation results for instance C101-100 Users and R105-100 Users

124
J. K. Chowlur Revanna and N. Y. B. Al-Nakash
Fig. 3 Simulation results for instance RC105-100 Users
typically viewed as a single-purpose optimal solution that reduces the overall ship-
ping costs of vehicles, which are the combination of their ﬁxed costs plus expenses
proportional to the distance traveled.
Figure 4 above shows for C103, C104, R103, and R104 cases. The above experi-
ment uses Tensor Flow (TF) model prediction for the results prediction of ACO–GA.
The TF is created based on a machine learning model of a trained functionality, in
which the categorization is accomplished by slicing the features into blocks. The
primary objective of this approach is to analyze pathways based on distinct blocks
of featured paths, which improves both prediction accuracy and classiﬁcation efﬁ-
ciency. The results show here have improved the accuracy, precision, recall, and
F1 score [27] as shown in Table 2. Tensor Flow–This is because the hybridization
model performance is calculated from Tensor Flow model as the algorithm learnt
from previous cases C101, R101, and measured the future responses.
Table 2 it discusses detection rate, this is used to predict the best routing path
mentioned in Fig. 1 where it chooses the best routing path.
In the above table we have used C, R, RC which represent cases. Here the data
sets have been used from Solomon benchmark and is used for 100 customers for all
cases.

Tensor Flow Model with Hybrid Optimization Algorithm for Solving …
125
Fig. 4 Simulation plot for 100 users of instance a C103, b C104, c R103, and d R104
5
Conclusion
The paper work proposed the Tensor Flow-based vehicle routing prediction along
with the optimal routing path selection of ACO–GA. By referring to the parameters of
path distance and the number of vehicles that need to traverse the region, the routing
path is generated from the data of vehicle coordinates and the delivery point. This
also reduces the fuel cost and the time consumption of overall system. The Tensor
Flow predicts the path that are best along with ACO–GA by estimating the cluster
of the relevancy that are trained with the feature patterns of data. The experimental
result and the graph shows the traveling distance and the amount of area that the
vehicle can travel with minimum number of vehicle count. These type of TF-based
VRP system improves the prediction performance and the process of optimal path
selection compare to other existing model of VRP.
For future papers we can implement optimized VRP paper for different structure
of data combination and can integrate with the AI model to update the training model
based on the feature update from time instant.

126
J. K. Chowlur Revanna and N. Y. B. Al-Nakash
References
1. Qiu M et al (2018) A tabu search algorithm for the vehicle routing problem with discrete split
deliveries and pickups. Comput Operat Res 100(2018):102–116
2. Min J, Jin C, Lu L (2018) A three-stage approach for split delivery vehicle routing problem
solving. In: 2018 8th international conference on logistics, ınformatics and service sciences
(LISS). IEEE
3. Koç Ç, Laporte G (2018) Vehicle routing with backhauls: review and research perspectives.
Comput Oper Res 91:79–91
4. Neves-Moreira F et al (2018) The time window assignment vehicle routing problem with
product dependent deliveries. Transp Res Part E: Log Transp Rev 116(2018):163–183
5. Madankumar S, Rajendran C (2018) Mathematical models for green vehicle routing problems
with pickup and delivery: a case of semiconductor supply chain. Comput Oper Res 89:183–192
6. Gschwind T, Bianchessi N, Irnich S (2019) Stabilized branch-price-and-cut for the commodity-
constrained split delivery vehicle routing problem. Eur J Oper Res 278(1):91–104
7. Marques A et al (2020) Integrated planning of inbound and outbound logistics with a rich
vehicle routing problem with backhauls. Omega 92:102172
8. Sitek P, Wikarek J (2019) Capacitated vehicle routing problem with pick-up and alterna-
tive delivery (CVRPPAD): model and implementation using hybrid approach. Ann Oper Res
273(1):257–277
9. Liu D et al (2020) Two-echelon vehicle-routing problem: optimization of autonomous delivery
vehicle-assisted E-grocery distribution. IEEE Access 8:108705–108719
10. Hornstra RP et al (2020) The vehicle routing problem with simultaneous pickup and delivery
and handling costs. Comput Operat Res 115:104858
11. Li J et al (2020) Branch-and-price-and-cut for the synchronized vehicle routing problem with
split delivery, proportional service time and multiple time windows. Transp Res Part E: Log
Transp Rev 140:101955
12. Wang Y et al (2020) Collaboration and resource sharing in the multidepot multiperiod vehicle
routing problem with pickups and deliveries. Sustainability 12(15):5966
13. Gayialis SP, Konstantakopoulos GD, Tatsiopoulos IP (2019) Vehicle routing problem for urban
freight transportation: a review of the recent literature. Operat Res Dig Era–ICT Challenges
89–104
14. Dumez D, Lehuédé F, Péton O (2021) A large neighborhood search approach to the vehicle
routing problem with delivery options. Transp Res Part B: Methodol 144:103–132
15. Samra B, Semchedine F (2020) A certiﬁcateless ring signature scheme with batch veriﬁcation
for applications in VANET. J Inf Secur Appl 55. https://doi.org/10.1016/j.jisa.2020.102669
16. Euchi J, Sadok A (2021) Hybrid genetic-sweep algorithm to solve the vehicle routing problem
with drones. Phys Commun 44:101236
17. Liu W et al (2021) A hybrid ACS-VTM algorithm for the vehicle routing problem with
simultaneous delivery and pickup and real-time trafﬁc condition. Comput Ind Eng 162:107747
18. Balasubramaniam V (2021) Design an adaptive hybrid approach for genetic algorithm to detect
effective malware detection in android division. J Ubiquitous Comput Commun Technol 3:135–
149
19. Konstantakopoulos GD, Gayialis SP, Kechagias EP (2022) Vehicle routing problem and related
algorithms for logistics distribution: a literature review and classiﬁcation. Oper Res Int J
22(3):2033–2062
20. Huang S-H et al (2022) Solving the vehicle routing problem with drone for delivery services
using an ant colony optimization algorithm. Adv Eng Inf 51:101536
21. International Conference on Automation and Computing Yu H. Chinese Automation and
Computing Society in the UK University of Lancaster and Institute of Electrical and Electronics
Engineers. Improving productivity through automation and computing: 2019 25th international
conference on automation & computing: lancaster University UK IEEE (2019)

Tensor Flow Model with Hybrid Optimization Algorithm for Solving …
127
22. Sokolova M, Japkowicz N, Szpakowicz S (2006) Beyond accuracy, F-score and ROC: a family
of discriminant measures for performance evaluation. In: Australasian joint conference on
artiﬁcial intelligence. Springer, Berlin, Heidelberg, pp 1015–1021
23. Min J, Lu L, Jin C (2022) A two-stage heuristic approach for split vehicle routing problem
with deliveries and pickups. LISS 2021. Springer, Singapore, pp 478–490
24. Solomon MM (1987) Algorithms for the vehicle routing and scheduling problems with time
window constraints. Oper Res 35(2):254–265
25. Revanna JKC, Al-Nakash NYB (2022) Analysis of optimal design model in vehicle routing
problem based on hybrid optimization algorithm. In: 2022 4th International conference on
advances in computing, communication control and networking (ICAC3N–22). IEEE
26. ZhaoF,YaoZ,LuanJ,SongX(2016)Anovelfusedoptimizationalgorithmofgeneticalgorithm
and ant colony optimization. Math Prob Eng
27. Revanna JKC, Al-Nakash NYB (2022) Vehicle routing problem with time window constrain
using KMeans clustering to obtain the closest customer. Global J Comp Sci Technol 22(D1):25–
37

Authentication Key Generator for Data
Sharing on Cloud—A Review
B. V. Santhosh Krishna, B. Rajalakshmi, Esikala Nithish Mani krishna,
Gundre Sai sruthi, Gangireddy Ramya sri, and K. Ashok
Abstract With the help of a sizable quantity of virtual storage, cloud computing
provides services through the Internet on demand. The primary beneﬁt of cloud
computing is that it relieves users of the need to invest in pricey computer equipment.
Lower expenses are related with infrastructure. Researchers are looking at new,
relevant technologies as a result of recent breakthroughs in cloud computing and
other sectors. Due to its accessibility and scalability for computer operations, both
private users and companies upload their software, data, and services into the cloud
storage. While switching from local to remote computing provides advantages, there
are also a number of security issues and difﬁculties for both the supplier and the
customer. There are many cloud services offered by reputable third parties, which
are raising security concerns. The cloud service provider offers its services over the
Internet and makes use of numerous online technologies, which raises fresh security
concerns. One of the most important requirements for today is online data exchange
for greater productivity and efﬁciency. In this work, we have done a detailed analysis
on cloud-based security issues and possible solutions. With this, data owners can
save and share the data through online.
Keywords Cloud protection · Framework for cloud computing · Security issues ·
Threats and attacks
B. V. Santhosh Krishna · B. Rajalakshmi · E. N. Mani krishna · G. Sai sruthi · G. Ramya sri (B) ·
K. Ashok
New Horizon College of Engineering, Bengaluru, Karnataka, India
e-mail: ramya.1nh19cs053.bsec@gmail.com
B. V. Santhosh Krishna
e-mail: santhoshkrishna1987@gmail.com
E. N. Mani krishna
e-mail: 1nh19cs047.nithish@gmail.com
G. Sai sruthi
e-mail: 1nh19cs056.saisruthigundre@gmail.com
K. Ashok
e-mail: kashok16@gmail.com
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_9
129

130
B. V. Santhosh Krishna et al.
1
Introduction
With the recent emergence of cloud computing, countless applications that span
international boundaries and include millions of users have seen their ability to share
data stretched to the limit. Today, governments and businesses view data sharing
as a crucial instrument for increased efﬁciency. Social networking, health care, and
education have all been transformed through cloud computing. The capacity of cloud
computing to enable global data sharing and exchange between numerous users
without the pains of manual data transfers and without the production of redun-
dant or outdated documents may be its most intriguing use case. Social networking
sites have made the globe more interconnected by utilising the cloud to enable the
sharing of text and multimedia. Cloud platforms frequently feature collaborative
tools, which are very well-liked since they increase productivity and effort synchro-
nisation. The result of cloud computing has spread all over to the healthcare industry
as well, with mobile applications enabling remote patient monitoring. In summary,
cloud computing is drastically altering many facets of our existence. Despite all of
its beneﬁts, the cloud is vulnerable to security and privacy breaches, which pose a
serious obstacle to its widespread adoption as the main method of data sharing in
today’s society. In a poll conducted by IDC Enterprise Panel [1], cloud customers
ranked security as their top difﬁculty, with 75% of people concerned about the secu-
rity of their vital IT and business systems. Unknown service providers can also be
considered, notwithstanding the prevalence of security risks from outside agents.
It is not simple to guarantee security and privacy on the cloud because online data
almost always occupy in shared environments (for example, many virtual computers
running on the same physical device). Setting down the speciﬁcations that a data
sharing service must meet in order to be considered secure is crucial when discussing
the protection of data privacy and protection in the cloud.
2
The Architectural Framework for Cloud Computing
The fundamental architectural framework for cloud computing is provided. The
fundamental idea and architecture of cloud computing must ﬁrst be understood in
order to comprehend the security concerns. The widely used NIST provides four
deployment models, ﬁve basic characteristics, and three service delivery models [2].
2.1
Fundamental Qualities
There are many attributes of cloud computing, and these key attributes make the
technology in demand; the key attributes are as follows [2].

Authentication Key Generator for Data Sharing on Cloud—A Review
131
2.2
On-Demand Self-service
Itallowscustomerstousewebservicesandadministrationinterfacestodirectrequest,
manages, and access services without interacting with any human beings.
2.3
Access to a Large Network
Any standard device, including smartphones, PCs, desktop computers, and laptops,
must be able to access data and services that provided in cloud. These devices
operate using some common technologies and protocols. Because of its nature, cloud
computing ought to accommodate all established protocols.
2.4
Resource Pooling
Large physical or virtual computer resources are made available by the cloud provider
and are distributed among numerous consumers. In a multi-tenant setting, these
resources are assigned in a dynamic manner.
2.5
Rapid Elasticity
One crucial characteristic of the cloud is elasticity. The resources used for this prop-
erty are scaled based on consumer needs. Customers have inﬁnite resources that they
can pay for on a pay-per-use basis as needed.
2.6
Measured Service
The cloud system’s metering functionality allows the resources to be automatically
controlled and scaled in accordance with user demand and paid services.
2.7
Service Paradigms
A set of services is supplied by the service model; the consumer uses these services,
which are given by the provider.

132
B. V. Santhosh Krishna et al.
2.8
SaaS
The SaaS gives its clients’ online software services to access the applications and
transfer the details related to the work and programmes to remote storage servers
(IDE). Salesforce and customer relationship management are two examples that
match the SaaS paradigm.
2.9
IaaS
The term “IaaS” refers to virtualizes resource, such as compute, storage, network,
memory, and processor, that the cloud service provider makes ad hoc and on-demand
available. The ﬁnest IaaS example is Amazon Web Service [3], which offered EC2
services like that are virtual machines with a software stack.
2.9.1
PaaS
PaaS, a more complicated programmable platform, is offered by the platform-
oriented cloud. Cloud users can utilise a variety of models, an IDE, specialised
services, OS, and platform-level resources on an easily programmable cloud platform
to design, run, deploy, and manage their applications.
2.10
Cloud Deployment of Private
A company or a TPA service internally controls and manages an exclusive cloud.
2.11
Cloud Deployment of Public
The CSP operates and manages a public cloud, and the user’s off-site location may
host the actual infrastructure. The resources in the cloud are shared by many users,
who pay the cloud provider for the services they utilise.

Authentication Key Generator for Data Sharing on Cloud—A Review
133
Fig. 1 Architectural framework for cloud computing
2.12
Hybrid Cloud
Two or more clouds with the same architecture and capabilities can be combined to
create a hybrid cloud. The architectural framework for cloud computing is shown in
Fig. 1.
3
Methods of Cloud Securıty Issues
3.1
Storing of Data in Cloud Security
Since the cloud computing paradigm does not permit the control over the data and
makes it difﬁcult to verify data integrity and conﬁdentiality, loss of control in the
storage problem is a severe concern. The user of cloud computing is geographically
separated from the server that stores their data and does processing. A network of
computers for storing cloud data is made available by using cloud computing. The
cloud service provider is in charge of and oversees the server pool, whose location
is unknown. The abstraction of the virtual layer makes ﬁnding the real layer more
challenging. Data pooling, data locality several locations, remote data storage, loss
of control, and sophisticated models for integrity verifying the solution are some
examples of security challenges with data storage.

134
B. V. Santhosh Krishna et al.
3.2
Untrusted Computing
The front-end interface for SaaS applications is often what security services want
to provide when users request a web service or an HTML page. These programmes
can be modiﬁed or adjusted to ﬁt a certain pattern of behaviour. The session state
manager, extra services, and any possible reference data that the request may call
make up this pattern of behaviour. The request is simply forwarded from one service
to another and so on, building a service tree whenever one application or service
calls another. Due to server misconﬁguration and criminal behaviour, a computing
framework which computes enormous datasets in distributed systems may provide
the unintended, unreliable, and dishonest conclusion. Security issues with untrusted
computing are top-down SLAs. Dishonest computing, malicious users, outages,
slowness, and others leads to untrusted computing [4–9]. Inadequate computer model
security measures, root-level backup errors [10], migration and restoration chal-
lenges, sluggishness and outages Data and service accessibility utilising phoney
resources [11].
3.3
Service and Data Availability
The real and virtual resources of the cloud’s database and processing servers are
extremely accessible. At the application and infrastructure levels, architectural modi-
ﬁcations are required to provide high availability and scalability of services and data.
Running applications on many servers are one strategy. This technique facilitates DoS
assaults. This method has the advantage of providing a backup application server in
the event that the primary one fails, ensuring the availability of data and services.
The server could also be working on a particularly demanding application job, in
which case he will consume more power, resources, and time. The cost of further
calculations and application availability are probably increasing as a result resource
utilisation and Cloud disruption are becoming security concerns with data and service
availability [12, 13, 14].
3.4
Cryptography
Information and data stored in the cloud are protected using cryptographic tech-
niques. The concept behind achieving cloud security is simple. It changes standard
text into cypher text and other types of text. The idea is based on the assumption
that it would be difﬁcult to determine the value of the plain text data in the case
that a cypher text was accessible. They must carefully and robustly construct cryp-
tography systems since the encryption key is what determines the overall level of
security. The prime factorisation of big integers makes the Rivest Shamir Adleman

Authentication Key Generator for Data Sharing on Cloud—A Review
135
(RSA)-based encryption more safe. Hardware availability is one of the cryptog-
raphy’s security concerns (hardware fault). Ineffective key management [15], ﬂawed
cryptography algorithms, brute force, and dictionary attacks are all examples of
insecure cryptography mechanisms [16].
3.5
Data Recycling
Reusing the cloud space after the data had been effectively used and disposed of
was a smart idea. But, the next user must be prevented from accessing the data
that were used by the preceding user. Sanitisation is the process of clearing out or
eliminating speciﬁc pieces of data from a resource. People can access updated data
in a dispersed manner following sanitisation. Data sanitisation is a critical activity in
distributed systems because it allows for the proper data disposal and data selection
when data are sent to the trash. Because the hard drive can be erasing some crucial
data, incorrect sanitisation leads to data leakage and loss. The ineffective application
of data destruction policies [17], the disposal of unused hard drives [14], the use of
hard discs by many tenants [15], and resource recycling [15, 18, 19] are security
concerns with cloud data recycling.
3.6
Malware
It is active and performs activities at every three minutes at a single business. An
online data storage system is MediaFire and SugarSync cloud-based service provider
which generates a distinct security issue; they either copy the features and data
properties of the many devices. The primary issue there is that if one system contains,
then because of inheritance, the malware spreads throughout the cloud. Malware also
poses a serious threat to cloud devices so that it can be used to corrupt or erase the
details. Methods of cloud security issues are shown in Fig. 2.
Fig. 2 Methods of cloud security issues

136
B. V. Santhosh Krishna et al.
4
Cloud Protection
Computer security includes cloud security. It speciﬁes a system of regulations,
controls, and technologies that are useful for safeguarding data and services. Threats
and attacks have an effect on the cloud system. New security issues might arise
as a result of the cloud resources’ integrity, availability, and conﬁdentiality being
compromised, as well as the services offered at different levels. In this part, we will
look at a few security concepts in order to have a better knowledge of cloud issues.
4.1
Concepts for Security of Cloud
Numerous security problems and risks are addressed by cloud security. To assist
readers to comprehend the idea of cloud security, the study emphasises the sources
of the risk and threats. To better understand the security challenges which are preva-
lent in the cloud, this section examines a few cloud-speciﬁc topics, including virtu-
alisation, multitenancy, cloud platforms, data outsourcing, and trust management
[20].
4.2
A Virtualisation-Related Issue
The idea of virtualisation is the division of services, programmes, computing
resources, and operating systems from the actual physical hardware on which they
are executed. The virtual machine (VM) and virtual machine manager (VMM) are
elements of virtualisation.
4.3
Multi-tenancy
It is a feature of the computing environment that enables one or more users to
share each operating process, introducing the concept of sharing instance. It gives
consumers the choice to share a single cloud platform with other users. Consider an
IaaS company. A VMM is a platform for multi-tenancy sharing, and instances are
referred to as VMs.

Authentication Key Generator for Data Sharing on Cloud—A Review
137
4.4
Threat Agents
Threatagentsareatypeofentitythatcanfendoffanattackandcreatethreats.Whether
it occurs internally or externally, this threat is caused by a person or any software
programme. A network level attack is sent by an external software programme or
external person known as an anonymous attacker via a public network. Those who
live in the cloud environment without the administrator’s authorisation are considered
untrusted cloud service users.
5
Threats to Cloud Computing
Anything that has the potential to seriously harm a computer system is considered as
a threat in the context of computer security. Threats might lead to potential attacks
on the system or network infrastructure.
5.1
Different Service Delivery
Both the business model and the cloud computing model use unique methods for
delivering and receiving services. Therefore, cloud computing has the ﬂexibility to
alter its own method of service delivery. The ﬁrm must evaluate all the risks associated
with losing control of the cloud because the cloud service provider has transferred
all services and applications to a remote location. When sending cloud data between
two locations, security rules speciﬁc to each location must be followed. This is one
of the key risks that are brought about by using something. To eliminate such threats,
one needs robust end-to-end encryption, globally recognised security regulations,
and a trust application.
5.2
Misuse and Criminal Application of Cloud Computing
Provision of information—these utilities are provided by vendors, including bound-
less network, storage, and bandwidth. Some service providers let customers try out
their products for a set amount of time. This is typically used in conjunction with a
simple registration process that enables anybody to register and access cloud services
without having to go through a security process. They now lack the power to make an
impact on the user for the duration of the trial. Additional potential concerns include
the hosting of potentially harmful materials, password and key ﬁnding, captcha
solving, and distributed denial of service (DDoS) assaults. Spammers, creators of

138
B. V. Santhosh Krishna et al.
harmful programmes, and other criminals may now carry out their assault. These
weaknesses endanger the infrastructure for PaaS and IaaS.
5.3
Unsecured Software Interfaces and APIs
Customers can utilise a number of software interfaces and APIs that the cloud
provider offers to communicate with cloud services. The complexity of the cloud
is increased by the interfaces’ layer-like deployment on top of the cloud base.
These interfaces offer their customers full provisioning, management, and moni-
toring capabilities. As a result, the security of these APIs is crucial to the cloud’s
availability and security. But occasionally, both deliberate and unintentional attempts
can compromised the security to these APIs. PaaS, IaaS, and SaaS service models
may be impacted by these kinds of API attacks. As other parties frequently use these
interfaces to deliver services, there is also the possibility of another form of risk.
5.4
Malicious Insiders
Malicious software one of the main dangers of cloud computing. internal dangers, as a
result of many organisations’ lack of details regarding her access level and employee
hiring process for their workers of internal resources. Mostly, this threat is carried
out, because of the clients’ use of IT services, lack of transparency, and collaborating
inside a single management domain. Somehow, a worker a greater amount of access
as a result, the conﬁdentiality of Services and data are compromised. This also leads
to a circumstance in which an insider attacker could acquire sensitive information
and impact the cloud.
5.5
Issues with Shared Technology in a Multi-tenancy Setting
Information as a service providers leverage the virtualisation idea to deliver the
services in a multi-tenant environment. Through virtualisation, it is feasible for more
users to share the resource. Hypervisor in the multi-tenant system could divulge user
information to an unauthorised user. Because the infrastructure was not designed to
effectively offer isolation in a multitenant context, there is a signiﬁcant risk involved.
Sharing could affect the cloud architecture as a whole by enabling single user to
access data over another user. Access restriction and stronger authentication are two
strategies for resolving this problem.

Authentication Key Generator for Data Sharing on Cloud—A Review
139
5.6
Data Leakage and Loss
The collaborative and productive nature of computing in cloud, data loss can also
result from the loss of an encoding key. Theft, modiﬁcation, and examples of data
loss include data deletion without a backup of the original data. The primary reasons
of data loss and leakage include weak encryption methods, weak keys, association
risk, unstable data centres, and a lack of disaster recovery. Weak access control,
authorisation, and authentication are other contributing causes. All service model
types are vulnerable to these dangers. Safe APIs, data backups, powerful encryption
keys, secure storage, and data integrity are a few prevention strategies.
5.7
Hijack Service
The customer may be forcibly steered to a risky website during the service hijacking
process. Fraud, phishing, and the usage of software bugs are all methods that can be
used to accomplish this. Reusing login credentials and passwords frequently results
in these attacks. In cloud computing, if a hacker gets hold of someone’s login infor-
mation, they can record actions, alter data, provide false information back to the
customer, or direct the client to hacked accounts and unauthorised websites.
5.8
Risk Proﬁling
Cloud services are less involved in owning and maintaining infrastructure and soft-
ware because of the high workload. The cloud offers contracts to businesses for the
upkeep of their software and infrastructure. This ignorance leads to greater threats
and dangers. The cloud should have a mechanism in place for keeping an eye on
and making changes to logs, data, and infrastructure-related information in order to
eliminate threats.
5.9
Theft of Identity
Theft is variety of fraud in which a perpetrator uses another person’s name, creden-
tials, resources, or other service beneﬁts in order to get access to protected infor-
mation. The victim suffers several unpleasant consequences and ﬁnancial loss as a
result of these threats. Keyloggers, phishing scams, and inefﬁcient password recovery
techniques, among other things, may all contribute to this danger. The security idea
includes both strong multi-tier authentication techniques and a trustworthy password
recovery procedure.

140
B. V. Santhosh Krishna et al.
Threats:
Different types of threats, their effects, and solutions are shown in Table 1.
Attacks:
Different types of attacks, their effects, and solutions are shown in Table 2.
Table 1 Different types of threats, their effects, and solutions
Threats
Effects
Solutions
Different service delivery
Loss of control over the
infrastructure of the cloud
Provided services that were
controlled and supervised
Misuse and criminal
application of cloud
computing
Due to unclear sign-ups, there
is a loss of validation, service
fraud, and a stronger attack
Observe the state of the
network and use strong
registration, authentication
methods
Unsecured software interfaces
and APIs:
Incorrect transfer of the
content, improper,
authentication, and
authorisation
Strong access control and
authentication measures are
used, and data transfer is
secured
Malicious insiders
Resource penetration, asset
damage, productivity loss, and
operational impact
Utilisation reporting and
breach alerts. As well as open
security and management
procedures
Issues with shared technology
in a multi-tenancy setting:
By exploiting the hypervisor,
interfere with one user service
and other user services
Audit conﬁguration and
vulnerabilities, and utilise
strong authentication and
access control procedures for
administrative tasks
Data leakage and loss
Data that are personally
sensitive may be altered,
destroyed, damaged, or erased
Provide systems for data
backup and storage
Service hijacking
Stolen user account credentials
give access to a crucial region
of the cloud, putting the
security of the services at risk
Use of powerful
authentication techniques,
security guidelines, and
encrypted communication
Risk proﬁling
Operations involving internal
security, security guidelines,
conﬁguration breaches,
patching, auditing, and logging
Recognise incomplete logs,
infrastructure, and data
aspects in order to safeguard
the data use monitoring and
altering system
Identity theft
To access that user’s resources
and obtain credits or other
beneﬁts under that user name,
an aggressor can obtain the
identity of a legitimate user
Authentication methods and
strong multi-tier passwords
should be used

Authentication Key Generator for Data Sharing on Cloud—A Review
141
Table 2 Different types of attacks, their effects, and solutions
Attacks
Effects
Solutions
Zombie attack
Affected service availability;
possibility of creating a phoney
service
Robust authorisation and
authentication
Attack using service injection
Service integrity is
compromised, and users are
given malicious services in
place of legitimate services
Service integrity is
compromised, and users are
given malicious services in
place of legitimate services
Port checking
Unusual service behaviour
reduces service availability
Strong port security is
necessary
Phishing attack
Affect the user’s private
information that should not be
shared
Employee a secure web link
(HTTPS)
Attack through the backdoor
Has an impact on the service’s
accessibility and data privacy
and offers rights for accessing
legitimate user resources
Strong authentication,
identiﬁcation, and isolation
procedures are necessary
6
Conclusion
Cloud computing includes rapid system implementation, low costs, abundant storage,
and simple system access from anywhere at any time. As a result, cloud computing
is becoming more and more apparent in recent technical developments and a widely
utilised computer environment everywhere. Several security and privacy issues make
it difﬁcult to use cloud computing. The security weaknesses, dangers, and assaults
that the cloud already has should be known to all users. If businesses are aware
of security threats and attacks, they can adopt the cloud more swiftly. Utilising
both traditional and cutting-edge techniques and technology, cloud computing is
introduced in various ﬁelds. Multiple clouds can be produced using this innovative
technique. Particular security concerns utilise the same resources physically located
at the cloud from several places to virtualisation and multi-tenancy features. The
security of the system may be hampered by improperly segregated VMs. We can
increase cloud security and lessen risks and assaults by creating the keys.
References
1. IDC Enterprise Panel (2008) It cloud services user survey, what users want from cloud services
providers
2. O’Neill M (2013) NIST: the NIST deﬁnition of cloud computing. Accessed Sept 2013
3. Amazon: Amazon Web Services: Overview of Security Processes. Accessed Nov 2015
4. Syam Kumar P, Subramanian R (2011) An efﬁcient and secure protocol for ensuring data
storage security in cloud computing. IJCSI Int J Comput Sci 8(6)

142
B. V. Santhosh Krishna et al.
5. Santhosh Krishna BV, Sharma S, Devika K, Sahana Y, Sharanya KN, Indraja C (2022) Review
of fake product review detection techniques. In: 2022 second international conference on artiﬁ-
cial ıntelligence and smart energy (ICAIS), pp 771–776. https://doi.org/10.1109/ICAIS53314.
2022.9742735
6. Bangari S, Rachana P, Gupta N, Sudi PS, KK Baniya (2022)A survey on disease detection of a
potato leaf using CNN. In: 2022 second ınternational conference on artiﬁcial ıntelligence and
smart energy (ICAIS), pp 144–149
7. Zhou M, Zhang R, Xie W, Qian W, Zhou A (2010) Security and privacy in cloud computing:
a survey. In: Semantics Knowledge and Grid ”, 2010 proceedings of the sixth ınternational
conference on Nov 1. IEEE, pp 105–112
8. Subashini S, Kavitha V (2011) A survey on security issues in service delivery models of cloud
computing. J Netw Comput Appl 34(1):1–11
9. Meenakshi Sundaram B, Rajalakshmi B, Aman Singh B, Kumar RS, Arsha R (2022) Disaster
relief compensation computational framework. In: 2022 second ınternational conference on
artiﬁcial ıntelligence and smart energy (ICAIS). https://doi.org/10.1109/ICAIS53314.2022.
9742829
10. Uma N, Prashanth CSR (2020) A detailed analysis of the various frequent itemset mining
algorithms. J Adv Res Dynam Cont Syst 12(2 Special Issue):448–454
11. Rong C, Nguyen ST, Jaatun MG (2013) Beyond lightning: a survey on security challenges in
cloud computing. Comput Electr Eng 39(1):47–54
12. Rimal BP, Jukan A, Katsaros D, Goeleven Y (2011) Architectural requirements for cloud
computing systems: an enterprise cloud approach. J Grid Comput 9(1):3–26
13. Vijayan A, Meenaskshi B, Pandey A, Patel A, Jain A (2020) Video anomaly detection in surveil-
lance cameras. In: 2022 International conference for advancement in technology (ICONAT).
https://doi.org/10.1109/ICONAT53423.2022.9726078
14. Armbrust M, Fox A, Grifﬁth R, Joseph AD, Katz R, Konwinski A, Lee G, Patterson D, Rabkin
A, Stoica I, Zaharia M (2010) A view of cloud computing. Commun ACM 53(4):50–58
15. Ashok K, Gurulakshmi AB, Prakash MB, Poornima R, Sneha NS, Gowtham V (2022)A survey
on design and application approaches in women-safety systems. In: 2022 8th International
conference on advanced computing and communication systems (ICACCS), pp 101–110.
https://doi.org/10.1109/ICACCS54159.2022.9784981
16. Thorsheim P (2015) The ﬁnal word on the linkedın leak. Accessed Sept 2015
17. Boampong PA, Wahsheh LA (2012) Different facets of security in the cloud. In: Proceedings of
the15thcommunicationsandnetworkingsimulationsymposium,Mar26,SocietyforComputer
Simulation International, p 5
18. Casale A (2013) The dangers of recycling in the cloud
19. Pearson S (2013) Privacy, security and trust in cloud computing. Springer, London, pp 3–42
20. Ahmed M, Ansari MD, Singh N, Gunjan VK, Santhosh Krishna BV, Khan M (2022) Rating-
based recommender system based on textual reviews using IoT smart devices. Mob Inf Syst
2022, Article ID 2854741, 18p. https://doi.org/10.1155/2022/2854741

Restaurant Quality Analysis: A Machine
Learning Approach
Rohit B. Diwane, Kavita S. Oza, and Varsha P. Desai
Abstract Managing customer’s happiness has emerged as a signiﬁcant business
trend, particularly in the restaurant industry. The purpose of this study is to determine
how K-Means algorithms can be used to measure customer satisfaction at a family
restaurant in Kolhapur. A survey is carried out related to services and ambiguous
at the restaurant. What makes restaurants popular is the main focus of the survey.
Data collected through online survey are clustered using the elbow method as well
as the K-Means clustering. This study presents the results of the customer satisfac-
tion measurement and offers improvement and recommendations to the concerned
restaurant.
Keywords K-Means algorithms · Elbow method · Principal Component
Analysis · Clustering · Restaurant
1
Introduction
The restaurant sector is among the most important economic contributors in the Asia.
Asian-style restaurants can be found all over the world, from small, cheap street
vendors to luxurious, expensive hotels and shopping areas [1]. Almost every day, a
large variety of new food items are released. In this regard, the restaurants depend
on the qualities of customer service needed to be consistently maintained in order to
stand out in the severe business competitions. Preferences for services among very
speciﬁc demographic groups also need to be addressed [2].
R. B. Diwane (B) · K. S. Oza
Department of Computer Science, Shivaji University, Kolhapur, Maharashtra, India
e-mail: rohitdiwane111@gmail.com
K. S. Oza
e-mail: kso_csd@unishivaji.ac.in
V. P. Desai
Computer Science & Engineering Department, D. Y. Patil Agriculture and Technical University,
Talsande, Kolhapur, Maharashtra, India
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_10
143

144
R. B. Diwane et al.
People from various cultures likely to go to some speciﬁc restaurant as they
have speciﬁc taste. The restaurant recommendation system is currently the most
important recommendation system in the modern world, where all families visit
various restaurants to spend some time together peacefully. For a family, a single
individual, or a couple to pick where to go based on convenience, the restaurant
recommendation is essential [3].
For many various sorts of businesses, especially restaurants, managing customer
happiness has emerged as a major issue. This would allow the restaurant to identify
the area that needs improvement and would keep them competitive itself. The quality
of the meal, the price, and many other factors can all be used to measure consumer
happiness [4]. Because it will have an impact on the analysis results, the choice
of features is also crucial in managing customer happiness. When the purpose is
to organise data samples into clusters based on some measure of similarity, this
procedure is known as clustering. Clustering differs from classiﬁcation in that it is
performed without supervision; therefore, no class labels are given, and sometimes,
even the number of clusters is unknown beforehand [5].
The primary goal of clustering is to group comparable data points together. Many
applications in data analysis and data visualisation depend on having well-deﬁned
clusters of data points. Researchers today have the option of using data clustering
to analyse and extract information from the data. With the aid of the numerous
algorithms employed in data clustering, researchers can identify patterns in the data,
analyse it, and predict a phenomenon. This approach has been used to address a wide
range of daily issues in sectors like restaurants, pharmaceutical, management, and
safety. Because raw input databases are used by data clustering systems, this poses
issues. For instance, databases frequently exhibit volatile, partial, noisy, and large
characteristics. Implementing data clustering difﬁculties requires some incomplete
information, misﬁts, and prediction accuracy [6, 7].
In this survey, we investigated the customer service in restaurants. The clus-
tering approach is used to cluster survey data collected from Kolhapur city restau-
rant. We have using clustering to read patterns of customer feedback depending on
some measurement data about the restaurant. PCA or Principal Component Anal-
ysis was used in high-dimensional data (no. of questions) which should be placed into
smaller dimension. Additionally, we looked for a parameter that played a signiﬁcant
impact on the outcomes. This work is really important, because we are committed
to preserving customer service rarely do in our daily lives. We evaluated the level
of customer instruction given and made recommendations for improvement to the
restaurant.
2
Review of Literature
Research shows that essentially, the work in this paper focuses on the usage of
SVM as a machine learning algorithm along with implementation of this method
utilising decision trees, K-nearest neighbours, Naïve Bayes, and random forests.

Restaurant Quality Analysis: A Machine Learning Approach
145
This research uses a machine learning strategy to analyse and categorise restaurants
using sentiment. The methodology used in this work included data preprocessing,
word preparation, training and test data segmentation, implementation, and perfor-
mance analysis. The study’s analysis of restaurants with the best performance is done
utilising decision trees and SVM techniques [8].
Agglomerativeclustering, customer satisfaction, datamining, K-Means, andspec-
tral clustering algorithms are all discussed in this research as they relate to customer
happiness in restaurants. In a paper, prediction using clustering and data mining are
used as the framework for the study. Data collection, preprocessing, and a clustering
model are all parts of the procedure. The major interest is on collecting informa-
tion from the restaurant and creating clusters to meet consumer expectations in the
restaurant [9].
This research uses machine learning, random forest, and decision tree techniques
to examine the literature on tree-based machine learning. According to the paper,
restaurants are divided into various classes based on their service standards. In
the study, random forest and decision tree both go through the same data collec-
tion, preprocessing, ML algorithm application, interpretation, and data visualisa-
tion processes. The primary concern is comparing decision tree and random forest
efﬁciency in terms of class prediction [10].
This paper had work on sentimental analysis for restaurant recommender.
However, analysis performs static information like price, qualities, and services.
However, static analysis is performed on features like price, qualities, and services. A
semantic approach is also included to create good clusters. The research of main focus
is ﬁnding comments of restaurant from online. Using natural language processing
extracts the qualities of that restaurants. The clustering carried out using Wu-palmer
method gave highest accuracy [11].
A better strategy to maximise efﬁciency and ensure that everyone has access
to nutritious food is to adopt sustainability. In this study, the primary focus is
on restaurant reviews using Fuzzy Domain Ontology (FDO) and Support Vector
Machines (SVM) to predict emotive and eating aspects [12]. Karuppusamy,
et al. have elaborated the recurrent neural networks with the ability to predict
consumerbehaviourwhichenablesorganisationsandmarketerstodevelopsuccessful
marketing campaigns and forecasts [13].
In “Machine Learning Algorithms—A Review,” [14] have stated that there are
many algorithms. We can use data in datasets for supervised an unsupervised algo-
rithm in different ways for better results and performances. A study on “Unsupervised
machine learning via transfer learning and k-Means clustering to classify materials
image data” [15] has used unsupervised learning algorithm that is K-Means for unsu-
pervised machine learning gives better possibilities for improving machine learning
performance and for deducing knowledge from unlabelled datasets [16].

146
R. B. Diwane et al.
3
Methodology
There are three different parts:
• Data collection.
• Data preprocessing.
• Cluster creation.
A Python programme has been created, and Jupyter Notebook is used to run the
programme after importing the appropriate library. Pandas—loading and prepro-
cessing of data, Numpy—numeric data calculation. Scikit—learn machine learning
library, IPython-matplotlib—visualisation.
3.1
Data Collection
The primary data used in this study are collected through the survey. A total of
320 responses were collected for analysis. All of the responses in this study were
collected through randomly selected restaurant customers. This study is based on
local family restaurant situated at Kolhapur city, of Maharashtra State. This restaurant
was established in the year 1997 and is one of the popular family restaurants in the
city.
The survey was carried out over a period of three months, from June to August
2022. Six important factors are examined in this study that are addressed in the ques-
tionnaire: Ambient, Meal quality, Information system, Responsiveness, Empathy,
andAssurance.Thisprocedureprovidesmoreaccurateresponsestoourquestionnaire
and aids respondents in understanding the measure in detail.
Following are some sample questions from the survey:
• Which type of food you liked in the restaurant?
• Which service you liked most in the restaurant?
• What you liked the best in the restaurant?
• Are you satisﬁed with the food quality and service?
• Which type of ordering mode you prefer for ordering food from restaurant?
These some questions were asked in the Google Form with option of Likert scale
format requested in order to get feedback.
We have used a method of data collection using online forms to complete. Above
mentioned ﬁve questions were selected for the clustering prediction in the current
investigation. Additionally, data cleaning techniques are used to check for missing
values in the data processes. We have used OpenReﬁne for data cleaning. OpenReﬁne
is an open-source desktop software for data preparation, which is the process of
cleaning up data and transforming it into different formats. It can handle spreadsheet
ﬁle types like CSV and is similar to spreadsheet programmes. Data cleaning steps

Restaurant Quality Analysis: A Machine Learning Approach
147
like removing duplicate or irrelevant observations, ﬁxing structural errors, ﬁltering
unwanted outliers, and handling missing data, from the survey dataset.
3.2
Data Preprocessing
In data preprocessing Fig. 1 shows the speciﬁc question and its relevant elements.
Each user only received one Google Form including 20 questions during the data
collection. Figure 1 shows that a variety of features can be used to evaluate the
restaurant’s quality. The factors in this study were measured using a 4 (four) point
scale, with 1 denoting poor, 2 adequate, 3 good, and 4 excellent (excellent). The
solutions to questions 6, 7, 8, 10, and 18 were allowed.
The dataset which is an CSV ﬁle is imported using Pandas.
The data from the entire document were exported to a CSV ﬁle and given some
null values. The responses to questions 1–20 were transformed into a number ranging
from 1 to 4, which represents level of customer satisfaction. Due to the type of answer
being “String,” many questions were skipped not be addressed for the following step.
We import only those questions where the answer is in numeric form as shown
in Fig. 1. According to the Likert scale, which has a scale of 1–4, poor, adequate,
good, and exceptional, the factors in this study were measured. In Fig. 2 shows the
question which served as the basic for clustering.
Fig. 1 Dataset loaded using Pandas

148
R. B. Diwane et al.
Fig. 2 Questions importing
3.3
Cluster Creation
Clustering is an unsupervised learning method that is used to look for natural group-
ings of data and patterns within the data. The hierarchical technique, the expecta-
tion–maximisation technique, and the K-Means technique are all examples of clus-
tering techniques. Cluster creation beneﬁts when elements are clustered, productivity
increases, decision-making is simpliﬁed, and new opportunities are produced.
First, we import K-Means from sklearn cluster and plot a graph. We use the elbow
approach in Fig. 3 to select K number of clusters. The model we used to analyse our
preprocessed data was K-Means clustering. Also, used the Elbow method to calcu-
late number of clusters. Every clustering result’s data visualisation used the Prin-
cipal Component Analysis (PCA). An unsupervised learning method for lowering
the dimensionality of data is Principal Component Analysis. While minimising infor-
mation loss, it simultaneously improves interpretability. It makes data easier to plot
in 2D and 3D and aids in identifying the dataset’s most important properties. One
of the most used clustering methods is K-Means, due to a suitable remedy that has
been put to use for many challenging tasks. Formula (1) illustrates how the distance
is calculated in K-Means clustering.

Restaurant Quality Analysis: A Machine Learning Approach
149
Fig. 3 Import K-Means and plot elbow graph used for K
(A) Label 0
Label 0 cluster 1 has 208 customers who are very happy with services provided
by the restaurant. Most of the customers in this cluster have visited the restaurant
for ﬁrst time. Here, customers are satisﬁed with the ambience, seating arrangement,
and food quality. Lots of customers are interested for ordering food in the restaurant.
Customers are satisﬁed with the hygiene condition of every part in the restaurant.

150
R. B. Diwane et al.
(B) Label 1
Cluster 2 is related to satisﬁed with the services. 96 of the customers in Label 1.
Many of the customers in this cluster are happy with the service’s availability for all
customers. The majority of customers want to collect their items from the restaurant.
However, a huge percentage of customers are new arrivals, while some are regulars.
The variety of foods attracts customers’ interest.

Restaurant Quality Analysis: A Machine Learning Approach
151
(C) Label 2
Here16customersarelesssatisﬁedwiththerestaurantserviceinLabel2ofCluster
3, which means only the hygienic condition makes these customers satisﬁed. Only
the hygienic condition makes these customers satisﬁed. These speciﬁc customers
are simply interested in quality services. The majority of these customers are doing
online food orders.
4
Result and Discussion
In the form, 320 questionnaires with 20 features and 2 Boolean features were obtained
from this survey. Twenty-two questions were answered by the questionnaire’s respon-
dent. There are ﬁve questions selected for clustering. The most common data were
used to ﬁll in the missing values to resolve this issue. The size of the cluster for
each methodology is shown in Table 1. We can observe that K-Means splits the data
properly equally among each cluster in the case of scale. So, there are three clusters
made, identiﬁed as clusters 1, 2, and 3.
Table 1 displays the principal component clustering of the results using K-Means.
The results of the data are already successfully clustered visually, as seen by the
relatively even distribution of the data in each cluster. The results are consistent with
the claim that the K-Means approach’s ability to group a large number of data points
depends on the number of deﬁned groups.
The Euclidean distance measures the difference between two vectors with real
values.Whenmeasuringthedistancebetweentworowsofdatathatcontainnumerical
values, such as ﬂoating point or integer values, Euclidean distance is most frequently
used. It is typical to normalise or standardise the numerical values across all columns
if columns contain values with different scales before ﬁguring out the Euclidean
distance. Otherwise, the distance measure will be dominated by columns with high
values. Therefore, distance from the centroids is calculated using Euclidean distance
by using the Formula (1), for measuring distance of the centroids as given below.
distances = centroids.apply(lambda x : np.sqrt(((data −x) ∗∗2).sum(axis = 1))) (1)
Formula (1): Calculating distance of centroids.
The elbow method is used to ﬁnd clusters using centroids. These are the centroids
of the features utilised in the dataset’s K-Means computation of Euclidean distance.
Euclidean distance is used in machine learning algorithms as a default distance metric
Table 1 Records of clusters
Cluster model
Cluster 1 (Label 0)
Cluster 2 (Label 1)
Cluster 3 (Label 2)
Total
K-Means clustering
208
96
16
320

152
R. B. Diwane et al.
Fig. 4 Centroids of clusters
to measure the similarity between two recorded observations. Additionally, each row
represents a feature and each column has centroids. Basically, iteration is used for
better result of cluster creation.
Here, three clusters are made of based on the various K clusters using iterations
for better result, a cluster-predict approach evaluation could be carried out. For the
clustering method shown in Fig. 5, we ran our experiment with K = 3.
Fig. 5 Result of cluster
using K-Means

Restaurant Quality Analysis: A Machine Learning Approach
153
5
Conclusion
Dataset is created using survey data. A survey was carried out to collect feedback
of the restaurant. This restaurant dataset was partitioned into three clusters using K-
Means algorithm. The ﬁrst cluster has all the customers who visited the restaurant for
ﬁrst time and are very happy with the service and food quality. Many of customers are
interested in placing food orders at the restaurant. Customers are impressed with the
hygiene of every aspect of the restaurant. The second cluster has all the customers
who are happy with the service’s availability for all customers. The majority of
customers want to collect their remaining food items from the restaurant. While
some customers are regulars, a substantial percentage of them is newcomers. The
good variety of food attracted most customers. The third cluster customers are only
satisﬁed by a hygienic condition. These speciﬁc customers are only concerned with
getting only good services. The majority of these customers order food in online
mode.
So, restaurants can review these clusters and accordingly carry out the manage-
ment of food quality, service, ambiance, etc., in order to identify the qualities
of restaurant that match customer expectations as well as required improvement.
The ﬁndings of this study will be helpful in providing advice and suggestions on
the hierarchy and priority for the growth and enhancement of restaurants in the
future. Additionally, the recommended clustering method can also be improved by
collecting more samples and developing a more relevant questionnaire that focuses
on a particular area of restaurant marketing strategies.
References
1. ClaypoN,JaiyenS(2015)OpinionminingforThairestaurantreviewsusingK-meansclustering
and MRF feature selection, 978-1-4799-6049-1
2. Sathish K, Ramasubbareddy S, Govinda K, Swetha E (2019) Restaurant Recommendation
system using clustering techniques. IJRTE
3. Shina SS, Singla A (2018) A study of tree based machine learning techniques for restaurant
reviews. ICCCA
4. Alghamdi A (2022) A hybrid method for customer segmentation in Saudi Arabia restaurants
using clustering, neural networks and optimization learning techniques. Arab J Sci Eng
5. Károly AI, Fullér R, Galambos P (2018) Unsupervised clustering for deep learning: A tutorial
survey. Acta Polytechnica Hungarica 15(8)
6. Asani E, Vahdat-Nejad H, Sadri J (2021) Restaurant recommender system based on sentiment
analysis. Elsevier Ltd
7. Aljalbout E et al (2018) Clustering with deep learning: taxonomy and new methods
8. Krishna A, Akhilesh V, Aich A, Hegde C (2019) Sentiment analysis of restaurant reviews
using machine learning techniques, emerging research in electronics, computer science and
technology. Lect Notes Electr Eng 545
9. Purwandari K, Sigalingging J, Fhadli M et al (2020) Data mining for predicting customer
satisfaction using clustering techniques. ICIMTech 13–14
10. Shina SS, Singla A (2018) A study of tree based machine learning techniques for restaurant
reviews. In: International conference on computing communication and automation

154
R. B. Diwane et al.
11. Asani E, Vahdat-Nejad H, Sadri J (2021) Restaurant recommender system based on sentiment
analysis. Elsevier Ltd.
12. Luo Y, Xu X (2019) Predicting the helpfulness of online restaurant reviews using different
machine learning algorithms: a case study of yelp. Sustainability
13. Karuppusamy P (2020) Artiﬁcial recurrent neural network architecture in customer consump-
tion prediction for business development. J Art Intell Capsule Netw 2
14. Mahesh B (2020) Machine learning algorithms-a review Int J Sci Res (IJSR).[Internet] 9
15. Cohn R, Holm E (2021) Unsupervised machine learning via transfer learning and k-means
clustering to classify materials image data. Int Mater Manuf Innovat 10(2)
16. Sinaga KP, Yang M-S (2020) Unsupervised K-means clustering algorithm. IEEE Access 8

Towards the Implementation of Trafﬁc
Engineering in SDN: A Practical
Approach
U. Prabu and V. Geetha
Abstract The advancement of software-deﬁned networks (SDNs) plays a major
role in the next generation of networks. It has laid its root in the cloud, data center,
and the Internet of things. SDN separates the data and control plane. Through this, it
provides greater ﬂexibility, cost-effective conﬁguration, and improved functioning of
advanced design of networks. Trafﬁc engineering (TE) is one of the major strengths of
software-deﬁnednetworks.Itsmaingoalistomanagetheﬂowsinthenetwork,update
topologies, analyze the trafﬁc, and be fault tolerant. Apart from that, it performs load
balancing, congestion control, trafﬁc rerouting, and updating policies. This article is
intended to provide a detailed description of the types of TE techniques, formulation
of TE problems, different ways to implement TE in SDN, and different topologies
to be considered for the performance evaluation of the algorithms. The overview of
the above-mentioned things might be beneﬁcial for beginners and future researchers
to have a clear understanding and go ahead with the implementation of TE in SDN.
Keywords Software-deﬁned networks · Mininet · Controllers · Linear
programming · Topology
1
Introduction
Software-deﬁned network (SDN) is a network structure that separates the control
function and data forwarding functions. It centralizes intelligence and abstracts the
underlying structure from services and applications. It comprises layers such as
infrastructure, control, and application. The infrastructure layer consists of either
physical or virtual switches. These switches just forward the packets. The control
U. Prabu (B)
Department of Computer Science and Engineering, Pondicherry Engineering College,
Puducherry, India
e-mail: uprabu28@gmail.com
V. Geetha
Department of Information Technology, Pondicherry Engineering College, Puducherry, India
e-mail: vgeetha@ptuniv.edu.in
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_11
155

156
U. Prabu and V. Geetha
Fig. 1 SDN architecture [1]
layer acts as an instructor to take all decisions, i.e., routing algorithm, etc. The
application layer comprises various applications for network management, analysis,
and other business functions. The SDN architecture is shown in Fig. 1.
The processing of ﬂow in SDN is given as follows [2]: Whenever the switch
receives the initial packet, it forwards it to the controller, and the controller decides
the forwarding path. Then, the ﬂow tables get installed at every switch. Thereafter,
all the successive packets get forwarded without any intervention from the controller.
During such an operation there occurs considerable overhead due to more number
of new ﬂows and even the time taken for framing the forwarding rules. Hence, to
resolve these challenges, trafﬁc engineering techniques should be devised.
The structure of the article is as follows: Sect. 2 details the concepts of TE in
SDN, Sect. 3 provides the problem formulation, Sect. 4 describes different ways
to implement TE in SDN, Sect. 5 offers topology for performance evaluation, and
Sect. 6 concludes the article.
2
Trafﬁc Engineering in SDN
Trafﬁc engineering (TE) is one of the signiﬁcant features of SDN. It is employed in
the control plane. It is system-oriented, and its task is to decide the routing of the
trafﬁc and balance the load for the given topology and trafﬁc matrix (TM) with less

Towards the Implementation of Trafﬁc Engineering in SDN: A Practical …
157
loss rate and latency. The load balancing enhances the performance of the networks
by minimizing congestion, reducing operational costs, and distributing the bandwidth
efﬁciently. The trafﬁc in the network will keep on changing and to deal with such
trafﬁc, the TE is classiﬁed as static, dynamic, and semi-static [3]. In static, the TMs
are observed over a while to reconﬁgure based on the trafﬁc. Dynamic is used for
predicting the consequent state through the previous TMs. Semi-static combines both
static and dynamic for optimal conﬁgurations. Efﬁcient TE methods are important
for utilizing network resources and providing better performance. It also allots the
bandwidth and modiﬁes the trafﬁc route to optimize the network.
3
Problem Formulation
Initially, the network may be represented as either a directed or undirected graph
that consists of nodes and edges. Then, there are different ways to formulate the
problem for trafﬁc engineering in SDN. The problem is formulated based on the
type of issue addressed. The different ways to formulate the problem are listed based
on the literature.
• To minimize the maximum link utilization for accomplishing optimal trafﬁc engi-
neering and to ensure the quality of services such as scalability, packet loss ratio,
and latency for multicasting and streaming applications, the problem may be
formulated as an integer linear programming problem.
• The scenarios involving the optimization of trafﬁc ﬂows may be formulated as a
mixed integer linear programming problem.
• To decide the reconﬁguration of the network based on the evolution of trafﬁc, the
problem may be formulated as a mixed integer nonlinear programming problem.
• To determine the improved mapping of the switch and controller, the problem
may be formulated as an optimization problem.
• Once the addressed issue involves multicast routing, cost, and multimedia
applications, the problem may be formulated as a delay constraint least cost
problem.
4
Different Ways to Implement Trafﬁc Engineering in SDN
Trafﬁc engineering in SDN can be implemented in two ways: simulation/emulation
and optimization.

158
U. Prabu and V. Geetha
4.1
Mininet Emulator
The most basic way to implement trafﬁc engineering in SDN is via the usage of
Mininet with custom topologies. It can generate a virtual OpenFlow network with
hosts, links, switches, and controllers. The trafﬁc ﬂows are captured through the
Wireshark analyzer. Apart from the Mininet, there are also other emulators, simu-
lators, and tools available for SDN such as Mininet CE, Mininet-HiFi, OMNeT++ ,
NS-3, EstiNet 8.0, and SDN Cloud.
4.2
Controllers
A controller is a program that performs the logic and directs the data plane. There
are various controllers available. Before going ahead with the usage of controllers
various things to be considered such as the learning curve, community support,
programming language (as it may affect the performance), and policy layer for APIs
such as southbound API and northbound API [4].
NOX
NOX [5] was the ﬁrst generation controller of OpenFlow which was open-source and
widely used. It has two ﬂavors namely NOX-classic and the new NOX. NOX-classic
came with C++ , Python as the programming language, and later the support was
stopped. The new NOX has only C++ as the programming language. It had a clean
codebase and was fast. It was used when the requirements are of low-level facilities
and has the semantics of OpenFlow.
POX
The Python version of NOX is called POX [6]. It supported only OpenFlow V1.0. It
was widely used, well-maintained, and had good support. But it lacks in performance.
It may be used for experimentation and rapid prototyping.
RYU
RYU [7] is an open-source Python controller. The name RYU is originated from the
Japanese word which means ﬂow. It supports OpenFlow versions 1.0 to 1.4. It has
well-deﬁned application programming interfaces. It is very useful for OpenStack
integration. It supports the extensions of nicira.
Floodlight
Floodlight [8] is an open-source Java controller which supports OpenFlow version
1.0. It is maintained by big switch networks. It can be integrated with REST API. It
can be used at the production level and for multi-tenant clouds.

Towards the Implementation of Trafﬁc Engineering in SDN: A Practical …
159
OpenDaylight
OpenDaylight [9] is also a Java controller which is robust and has an extendable
codebase. It can be integrated with OpenStack and cloud applications. But it is
complex to use. Maestro is a Java-based controller which supports OpenFlow version
1.0. It has a web-based interface and is widely used for research purposes.
Open MUL
Open MUL [10] is a C language-based controller and provides a multithreaded
environment. It supports up to OpenFlow version 1.4. It also provides a web-based
interface. It can be used for data center applications. It is good for reliability and
performance-based scenarios.
Trema
Trema [11] is C and Ruby-based controller. It supports OpenFlow versions 1.0 and
1.3. It is used for research purposes. It provides rich library support.
Beacon
Beacon [12] is Java-based controller. It supports OpenFlow version 1.0. It provides a
web-based interface. Iris is Java-based controller which supports OpenFlow versions
1.0 and 1.3.
Rosemary
Rosemary [13] is a C language-based controller. It supports OpenFlow versions 1.0
and 1.3. It can be used for research purposes within the campus. ParaFlow is a C++
-based controller.
All the aforementioned controllers are centralized. There are also many distributed
SDN controllers namely ONOS, Onix, B4, Kandoo, Expresso, Ravana, ODL,
DISCO, Hydra, IRIS-HiSA, ElastiCon, and Orion.
Another way of implementation is by considering the network as a graph and
framing the problem as a linear programming problem. In this case, the problems
are solved by using GNU Linear Programming Kit (GLPK) [14] and optimization
software such as the Gurobi solver [15] and CPLEX optimizer [16].
5
Topology for Performance Evaluation
Table 1 provides the real and standard network topology considered for evaluation
of the algorithms in the literature which are part of Internet zoo topology [17] and
others.

160
U. Prabu and V. Geetha
Table 1 Network topologies
Network
Nodes
Links
18-node EON
18
33
20-node ring
20
20
AARNET
19
24
Abilene
11/11/12
28/14/30
Abovenet
15/17/23
60/74/31
ARPANET
24
100
AT&T
166
189
Atlanta
15
22
BellSouth
50
264
Bestel
80
404
BHVAC
19
46
Biznetworks
29
33
Brite10
10
40
Brite15
15
90
Brite20
20
160
BTNA
36
76
Cernet
14/41
32/59
Claranet
15
18
Cogent
196
980
Columbus
70
85
Di-yuan
11
42
Ebone
18/28
66/66
EON
19
74
Exodus
21/22
72/51
Geant
23/38
74/104
Geant-2
34
54
German backbone network
14/17
21/26
Germany50
50
88
Internet2
10
13
IRIS
51
64
METRO
11
84
Nobel-germany
17
26
Nobel-us
14
21
NSF
8
20
PACBELL
15
42
Pdh
11
34
Polska
12
18
(continued)

Towards the Implementation of Trafﬁc Engineering in SDN: A Practical …
161
Table 1 (continued)
Network
Nodes
Links
Sprint
11/27/30
18/126/138
SURFNET
50
73
Ta2
65
108
Tiscali
28
132
USNET
24
43
VNSL
9
22
6
Conclusion
SDN has revolutionized the design of the network. It has also acquired extraordinary
attention from industry and research ﬁrms. The forthcoming network architectures
are dependent on the SDN. Due to the evolving trafﬁc, TE requires a major concen-
tration. So based on this perspective, an in-depth analysis has been done on the
implementation strategies of TE in SDN right from the problem formulation to the
selection of topology for performance evaluation of the algorithms.
References
1. Fundation, Open Networking. Software-deﬁned networking: The new norm for networks. ONF
White Paper 2.2-6, 11 (2012)
2. AkyildizIFetal(2014)AroadmapfortrafﬁcengineeringinSDN-OpenFlownetworks.Comput
Netw 71:1–30
3. Sanvito D et al (2019) Clustered robust routing for trafﬁc engineering in software-deﬁned
networks. Comput Commun 144:175–187
4. Ahmad S, Hussain Mir A (2021) Scalability, consistency, reliability and security in SDN
controllers: a survey of diverse SDN controllers. J Netw Syst Manage 29(1):1–59
5. Gude N et al (2008) NOX: towards an operating system for networks. ACM SIGCOMM
computer communication review 38(3):105–110
6. POX. https://noxrepo.github.io/pox-doc/html/
7. RYU. https://ryu-sdn.org/
8. Floodlight. https://github.com/ﬂoodlight/loxigen
9. OpenDaylight. https://www.opendaylight.org/
10. Open MUL. https://www.openmul.org/
11. Trema. https://trema.github.io/trema/
12. Erickson D (2013) The beacon openﬂow controller. In: Proceedings of the second ACM
SIGCOMM workshop on Hot topics in software deﬁned networking
13. ShinSetal(2014)Rosemary:arobust,secure,andhigh-performancenetworkoperatingsystem.
InProceedingsof the 2014ACM SIGSAC conference oncomputerandcommunicationssecurity
14. GLPK. https://www.gnu.org/software/glpk/
15. Gurobi Solver. https://www.gurobi.com/
16. CPLEX Optimizer. http://ibmdecisionoptimization.github.io/docplex-doc/mp.html
17. Knight, S et al (2011) The internet topology zoo. IEEE J Selected Areas Commun 29(9),
1765–1775

Real-Time Intrusion Detection
in Connected Autonomous Vehicles
Anjanee Kumar and Tanmoy Kanti Das
Abstract Connectedautonomousvehicles(a.k.aCAVs)haveshownanewparadigm
in the transportation ﬁeld by reducing cost, managing trafﬁc and efﬁciently use of
fuels. These developments have revolutionized not only the transportation ﬁeld but
also impacted our daily lives. However, growth in the ﬁeld of automation has given
rise to various security issues. Now, CAVs are using many sensors to perform automa-
tion. For proper navigation of vehicles, these sensor information must be commu-
nicated in a safe environment. In CAVs, these sensor information communicates
through In-Vehicle-Network (IVN) to various parts of the vehicle, including differ-
ent ECUs. But the network environment that has been used for communication is
not always safe and can be inﬁltrated easily if proper security measures have not
been taken. We are proposing a new intrusion detection system (IDS) to detect intru-
sions in real time in the network ﬁeld of CAVs that is based on logical analysis of
data (a.k.a LAD). For this, we have used the CAV-KDD dataset, which has been
developed from a benchmark dataset KDDCUP’99 and resembles an actual network
environment of CAVs. Our results have shown better performance than the existing
results on CAV-KDD dataset.
Keywords Logical analysis of data (LAD) · Intrusion detection system ·
Connected autonomous vehicles · Security
1
Introduction
From purely mechanical devices, the CAVs have emerged as cyber-physical devices
with many connected components. There are multiple processors embedded in the
A. Kumar (B) · T. K. Das
Department of Computer Applications, National Institute of Technology Raipur, G.E. Road,
Raipur, Chhatisgarh 492010, India
e-mail: akumar.phd2021.mca@nitrr.ac.in
T. K. Das
e-mail: tkdas.mca@nitrr.ac.in
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_12
163

164
A. Kumar and T. K. Das
CAVs which communicate over the network in the car, known as In-Vehicle-Network
(IVN). The different components in CAVs are connected to the outside world via a
wire or wireless network. There are different ways of communication in CAVs, like
intra-communication, which includes communication between different components
within the vehicles and inter-communication, which includes communication with
other CAVs. There are various components in CAVs, including sensors, actuators
and different Electronic Control Units (ECUs), which are connected to communicate
over IVN. Most of these IVNs have securities issues like a lack of authentication and
encryption. One such IVN is Controller Area Network (CAN), which is the de facto
standard for in-vehicle communication in CAVs. The automotive industry’s evolu-
tion has also given rise to cyber-attacks as vehicles were exposed to the external
world via different network environments. There have been a number of successful
attacks against CAVs, which have had devastating effects on public safety. As the
automotive industry has been reached every corner of the world and growing contin-
ually at an exponential rate, they have become a most likely target for attackers. In
2015, researchers found the vulnerability in the vehicle by hijacking it. This remote
exploitation of cars was demonstrated in a seminal paper [13], where the white hat
hackers successfully took control of the Jeep Cherokee and exploited it. It has been
found in a study that the automobile industry could lose approximately 1.1 billion
for a single attack. And before 2023, the entire industry is estimated to lose up to 24
billion. These numbers are scary if proper security measures have not been adopted.
Although there are many methods to deal with cyber-attacks in the system, an
intrusion detection system (IDS) is one such method that a number of researchers
has used. As described in [11], IDS detects unauthorized intruders and attacks in
the network (In-Vehicle-network in case of CAVs). There are two categories of IDS
as mentioned in [11]: online IDS, where the detection and analysis of trafﬁc are
performed in real-time and ofﬂine IDS, where the detection and analysis of logs
are performed sometime after the network operation. Here in this paper, we have
focussed on a real-time intrusion detection system. CAVs are safety critical cyber-
physical system where a delay in detecting attacks may have devastating effect on
public safety. One of the most important points while considering the IDS system for
CAVs is that the commercial vehicle has limited computation capability. Therefore,
most of the recent methods are incompatible with the current scenario. For example,
methods involving Deep Learning has excellent detection result [8, 17]. Still, it
requires a huge amount of processing power and high computing resources, which
may not be available in the CAVs. Therefore, we are proposing a real-time (online)
intrusion detection method based on logical analysis of data.
LAD is a binary classiﬁer method proposed by Hammer et al. [2] to ﬁnd the
behavioural patterns of normal and abnormal activities in a system. These abnormal
activities may include any cyber-attacks to discover any anomalies or intrusions. The
process of extracting patterns requires signiﬁcant knowledge of the domain. These
patterns must differentiate the normal activity from the abnormal activity even in
any sensor noise in a system network. In general, LAD is a method to generate such
patterns from historical observations. In LAD, a historical observation dataset D
consists of two disjoint datasets: D+ and D−. They represent two different classes,

Real-Time Intrusion Detection in Connected Autonomous Vehicles
165
the positive class and the negative class. In LAD, we mainly extract prime patterns
which can classify any given new observation as either a member of D+ or D−class.
In this paper, we have developed a real-time intrusion detection system based on the
LAD method for network systems in CAVs with optimal computing efﬁciency. For
our proposed method, we have chosen CAV-KDD dataset [7], which is generated
from a well-known KDDCUP99 dataset. This dataset is chosen because it resembles
a general network environment which has all possible attacks of CAVs. The main
contributions of this paper are as follows:
• Computationally efﬁcient algorithm: As mentioned, vehicles may not have the
computational resources; therefore, we have proposed a computationally efﬁcient
method that can be achieved by using laptop-class processing power.
• Real-time IDS: We have proposed an online real-time IDS which can detect intru-
sions in real time. The intrusions in safety-critical systems like CAVs must be
detected in real time to avoid any accidents. The detection time in our method
shows that our system is a real-time IDS.
• The effectiveness of the proposed method is analysed using different performance
metrics, including accuracy, false positive rate, F1-score and detection time.
The paper is organized as follows: In Sect.2, we have presented related work.
In Sect.3, there is a complete description of dataset. A complete description of
our proposed method is presented in Sect.4. Then, the experiment and results were
discussed in Sect.5. Finally, we have concluded the paper in Sect.6.
2
Related Work
The study in the ﬁeld of IDS in CAVs is quite vast, and many researchers have
contributed to this ﬁeld by adopting different approaches [9, 19]. Some of them have
adopted the concept of time arrival of CAN-BUS messages. In [16], the researchers
have analysed each CAN-BUS message and measured the time of arrival of the CAN-
BUS message to detect a DDoS attack. They have achieved accuracy up to 100% for
DDoS attacks. In comparison with spooﬁng attacks, DDoS is quite easy to detect.
In [14], the researcher has analysed that the distribution of the inter-arrival times
has discriminating power in detecting attacks. Some authors have also adopted the
slidingwindowmethodtoCAVsIDS.In[15],theauthorshavecomparedtheShannon
entropy-based method to similarity-based IDS and concluded that the similarity-
based IDS has low computation complexity. In [12], the authors have detected replay
and fuzzy attacks by using Shannon entropy. They have adopted a sliding window
approach and also addressed the spooﬁng attacks. In [10], authors have also used the
time interval of the CAN-BUS messages to detect spooﬁng attacks. They have used
the time interval information and the correlation coefﬁcient between offsets to detect
various attacks.
In [18], to determine the presence of attacks, the authors have evaluated the impact
of different window sizes. They have also used the CAN-ID feature. Finally, they

166
A. Kumar and T. K. Das
have shown that spooﬁng attacks are hard to detect. In [6], the authors have applied
an improved isolation forest method with data mass for the detection of attacks,
whereas for the isolation forest algorithm, data mass is used as a base function. Also,
in [17], a ﬁxed sliding window has been used to transform the in-vehicle trafﬁc to
images which are then passed as input in Convolutional Neural Network (CNN) for
classiﬁcation. Finally, the paper [7] has results on the same dataset that we have used.
In this paper, the authors have used Uniﬁed Modelling Language (UML) framework
to generate the CAV-KDD dataset from a well-known KDDCUP’99 dataset. And
then, they applied Naïve Bayes and the Decision Tree algorithm to calculate different
performance metrics.
3
Description of Dataset
3.1
CAV-KDD Dataset
For the generation of CAV-KDD dataset, the authors in the paper [7] have adapted
KDD99 dataset on intrusion detection system and created a CAV communication-
based cyber-attack dataset which is termed as CAV-KDD dataset. They have used
UML-based CAV framework which is explained in [7] to ﬁnd out the possible attacks
in CAVs system. Out of total 39 sub-attacks present in KDD99 dataset, they have
selected 14 sub-attacks that are possible in CAVs system. For preparation of CAV-
KDD dataset, they have used 10% of the KDD99 training and testing dataset and
carved out CAV-KDD dataset based on the discussed UML framework of CAVs sys-
tem. The authors in the paper [7] have provided the number of records of CAV-KDD
test and CAV-KDD train dataset that we have used in this paper. All the exlanation of
CAV-KDD dataset can be found in paper [7]. The details of the CAV-KDD training
and testing dataset are given in Table1.
The description of sub-attacks in the CAV-KDD dataset is given in Table2.
Table 1 Description of CAV-KDD dataset
Dataset
Number of
Attacks
Normal
Total
CAV-KDD training
data
13,284
58,716
72,000
CAV-KDD testing data 23,349
47,913
71,262

Real-Time Intrusion Detection in Connected Autonomous Vehicles
167
Table 2 Description of sub-attacks in CAV-KDD dataset
Attack type
Sub-attack
Training dataset
Testing dataset
0
Normal
58,716
47,913
PROBE
1
ipsweep
341
155
2
nmap
158
80
DoS
3
mailbomb
_
308
4
neptune
12,281
20,332
5
pod
40
45
6
smurf
199
936
7
teardrop
199
12
8
udpstorm
_
2
U2R
9
buffer overﬂow
5
22
10
httptunnel
_
146
R2L
11
ftp write
8
3
12
Guess passwd
53
1302
13
worm
_
2
14
xsnoop
_
4
3.2
Data Preprocessing
The method of LAD can be only applied to the numerical data. Therefore, we have
pre-processed the dataset to use in our proposed method. The following steps have
been taken in order to preprocess the dataset:
• Conversion to numerical form: There are total 39 input features and one output
feature in the CAV-KDD dataset as given in paper [7]. Out of 39 features, there are
three categorical features, namely ‘Protocol_Type’, ‘Service’ and ‘Flag’. We have
converted these categorical features into numerical form using one-hot-encoding
method. After conversion, we have got 115 features.
• In the output column, we have converted all attacks into anomaly as our proposed
method works on binary classiﬁaction. Finally, in the output column, we have only
two entries, i.e. ‘anomaly’ and ‘normal’. We have changed ‘anomaly’ to ‘1’ and
‘normal’ to ‘0’ to ﬁnally convert the dataset into numerical form.
4
Introduction to LAD
Logical analysis of data (a.k.a LAD) is one of the effective Boolean-based method
which is based on Boolean logic and discrete optimization [3]. The LAD techniques
were ﬁrst developed for binary data [4], and later, it was extended for non-binary
data. LAD is a method which ﬁnds out the minimal features from the dataset, which

168
A. Kumar and T. K. Das
is capable of explaining all the observations and can classify the observation into
negative and positive observations. The positive and negative observation is based
on the classes to which the observation belongs. To apply the method of LAD, all
the input variables (explanatory variables) must be converted into binary by means
of a discretization process called binarization. The binarized dataset D contains two
subsets D+ representing a positive class of data and D−, which represent a negative
class of the dataset. LAD extracts meaningful patterns(rules) from binary dataset D.
The binarized data D can be expressed as a Boolean function f as f : {0, 1}n→{0, 1}.
LAD uses the concept of partially def ined Boolean f unction. The observations
belonging to the positive class (negative class), i.e. D+ (D−), are termed as True
Points (False Points) and denoted as T (F). The dataset D (D = D+ ∪D−) can be
represented as partially deﬁned Boolean function (pdBf) φ as φ: D →{0, 1}. The
main objective of the LAD method is to ﬁnd out the extension T of pdBf φ such
that it can classify any new observation. Generally, the LAD functions in ﬁve stages,
including
1. Binarization of dataset
2. Support set generation
3. Pattern generation
4. Theory Formation
5. Classiﬁer Design.
Although, we have not applied the Theory Formation step as explained in the
advanced version of LAD in [5].
4.1
Binarization of Dataset
LAD method begins with the process of binarization where each column ci is con-
verted to binary attributes with the help of cut points. The value n is converted into
binary using a threshold value (cut points) h as if n is greater than h; it is converted
to 1 else 0.
The numerical value n with threshold value hi is converted to binary and is rep-
resented by:
ζ(n, h) =
1, if n ≥hi
0, otherwise
We can ﬁnd out the cut points of a particular column to convert numerical values
to binary form with the following steps:
1. Sort the data in ascending order, including the class column.
2. Ignore all the observation if it has the same value and keeps only one with a class
label value other than 1 and 0.
3. Repeat step 2 until all observations are distinct.
4. Cut point (h) can be calculated as h j = 1
2(ni + ni+1)

Real-Time Intrusion Detection in Connected Autonomous Vehicles
169
4.2
Support Set Generation
In the second step, after getting the binarized data, we need to remove redundant
features from the dataset. The process of selecting minimal features that can classify
the observation into different classes, such as the intersection of these two classes,
gives null value as D+ ∩D- = φ is termed as support set generation. The set of
minimal features is known as the support set. To select this set of minimal features,
we have used the ‘Mutual Information Greedy’ algorithm [1]. The elements in our
support set are arranged according to their discriminating power.
4.3
Pattern Generation
The third step is where we generate meaningful patterns to classify the maximum
observation as possible. We have generated these meaningful patterns with the help
of binary varibles obtained in support set generation step. The term M is deﬁned
as the conjunction of literals and is said to cover any observation if M(b) = 1. The
binary variables from the support set are written as a term and are said to be a pattern
if the conjuction of these binary variables covers observations in the given dataset. If
a pattern covers only positive observation (negative observation) but not any negative
observation (positive observation) is termed as pure positive pattern (pure negative
pattern). And if this pattern has minimum number of literals, then it is called prime
pattern. In our implementation, we have also considered a positive impure pattern,
which is deﬁned as a pattern which covers maximum positive observations but very
few negative observations.
4.4
Classiﬁer Design
In our approach, we have skipped the Theory formation step as explained in [5]. Based
on the set of patterns that we have obtained from the pattern generation step, we have
deﬁned a rule-based-classiﬁer, using if-else if statement. In our implementation, we
have grouped all positive pure and positive impure patterns using if-else if statement
to make a classiﬁer.
4.5
Workﬂow
For our model, we have pre-processed our historical dataset, which involves the
conversion of categorical to numerical form. Also, we are working for the binary
classiﬁer, so we have considered only two classes in a class label, i.e. normal and

170
A. Kumar and T. K. Das
Fig. 1 Workﬂow of proposed method
anomaly. All the attacks are put into the anomaly class. The processed dataset is then
applied to create a rule-based classiﬁer following the steps as depicted in Fig.1. All
the steps are well explained in Algorithm 1.
Algorithm 1 Steps to design a rule-based Classiﬁer
Input: Historical dataset D.
Output: Rule-based classiﬁer.
1: Convert the categorical column of the historical dataset D into numerical form.
2: Binarize the processed dataset obtained in step 1 using the process explained in section 4.1.
3: Generate the minimal set of binary attributes using the process explained in section 4.2.
4: Extract positive pattern using the support set obtained in step 3.
5: Design Classiﬁer from the extracted patterns.
5
Performance Evaluations
The LAD-based intrusion detection system for the connected autonomous vehicle
has been evaluated on the CAV-KDD dataset [7]. We have performed our experiments
on a PC with a core i5 processor and RAM of 20GB.

Real-Time Intrusion Detection in Connected Autonomous Vehicles
171
5.1
Performance Metrics
To validate our proposed model, we have calculated and compared the results using
following metrics:
The meaning of acronym used in deﬁnition of metrics:
• TP (True Positive): The examples which are actually positive and predicted posi-
tive.
• TN (True Negative): The examples which are actually negative and also predicted
negative.
• FP (False Positive): The examples which are predicted positive but actually neg-
ative.
• FN (False Negative): The examples which are actually positive but predicted neg-
ative.
1. Accuracy: It is deﬁnedas ratioof correctlyclassiﬁedexamples tothetotal number
of examples.
Accuracy =
(TP + TN)
(TP + TN + FP + FN)
2. Precision: Precision is deﬁned as fraction of truly positive data out of total
predicted positive data and is given by
Precision =
(TP)
(TP + FP)
3. F1 Score: F1_score shows the balanced value of precision and recall and deﬁned
as harmonic mean of recall and precision. It is deﬁned as
F1 Score = 2 ∗(Precision ∗Recall)
(Precision + Recall)
4. False positive rate: It is deﬁned as ratio of false positive data to the actual negative
data and is given by
False Positive rate =
(FP)
(FP + TN)
5.2
Experimental Setup and Results
There is a total of 41 explanatory variables and one dependent variable, i.e. attack
label, in both the training and testing dataset. In the pre-processing stage, all the
categorical columns have been converted to numerical form, and the attack label is
labelled as 1 for attack and 0 for normal. In our experiment, we considered attack as

172
A. Kumar and T. K. Das
a positive class and normal as a negative class. Then, we applied LAD to the training
dataset and followed all the steps described in Algorithm 1. The following results
have been summarized step by step:
1. Binarization : In this step, we have got a total of 1491 binary variables.
2. Support Set Generation : In the Support set, we have got a total of 25 binary
variables.
3. Pattern Generation : In this stage, we have got a total of 10 positive patterns,
out of which 8 were pure patterns, and two of them were impure.
4. Classi f ier Design : Based on the patterns generated from the previous step,
we have designed a rule-based IDS using i f −else −i f statement. The details
of the rules have been summarized in deﬁned Classiﬁer 1 .
Classiﬁer 1: Classiﬁer to distinguish attack and normal
1: if row[′wrong_ f ragment′] >= 0.5 then
2:
′attack′
3: else if row[′count′] >= 48.5 and row[′ f lag_SF′] <= 0.5 then
4:
′attack′
5: else if row[′count′] >= 48.5 and row[′service_ecr_i′] >= 0.5 then
6:
′attack′
7: else if row[′ f lag_SF′] <= 0.5 and row[′service_private′] >= 0.5 then
8:
′attack′
9: else if row[′srv_count′] >= 3.5 and row[′service_eco_i′] >= 0.5 then
10:
′attack′
11: else if
row[′dst_host_srv_count′] >= 153.5 and row[′dst_host_srv_di f f _host_rate′] >=
0.07500000000000001 and row[′ protocol_type_icmp′] >= 0.5 then
12:
′attack′
13: else if row[′dst_host_srv_di f f _host_rate′] >=
0.07500000000000001 and row[′ protocol_type_icmp′] >=
0.5 and row[′dst_host_count′] <= 2.5 then
14:
′attack′
15: else if row[′dst_host_di f f _srv_rate′] <= 0.015 and row[′hot′] >=
0.5 and row[′logged_in′] <= 0.5 then
16:
′attack′
17: else if row[′ f lag_SF′] <= 0.5 and row[′srv_count′] >=
3.5 and row[′dst_host_srv_count′] <= 19.5 then
18:
′attack′
19: else if row[′dst_host_srv_di f f _host_rate′] >=
0.07500000000000001 and row[′ protocol_type_icmp′] >=
0.5 and row[′dst_host_count′] <= 4.5 then
20:
′attack′
21: else
22:
′normal′
Based on the rule-based classiﬁer, we have calculated different performance met-
rics on the training and testing dataset. The results have been summarized in Tables3
and 4.

Real-Time Intrusion Detection in Connected Autonomous Vehicles
173
Table 3 Accuracy and detection time in CAV-KDD dataset
Dataset
Accuracy (%)
Detection time (µs)
Training dataset
99.90
34.86
Testing dataset
97.34
31.15
Table 4 Precision, F1-score and FPR on CAV-KDD dataset
Dataset
Precision (%)
F1-score (%)
False positive rate (%)
Training dataset
99.98
99.73
0.003
Testing dataset
99.75
95.79
0.1
Table 5 Comparison with the existing literature on CAV-KDD dataset
Reference
Method
Accuracy (%)
Precision (%)
F1-score (%)
False positive
rate (%)
This study
LAD
97.34
99.75
95.79
0.1
[7]
Decision_tree
97.04
94.64
NA
5.6
[7]
Naive_Bayes
95.66
94.84
NA
5.2
On applying the obtained classiﬁer on the testing dataset, we have got the accuracy
of 97.34% and precision of 99.75%. The detection time of our rule-based classiﬁer is
only 31.15 microsecond which is good enough to ﬁnd the intrusions in real time. The
F1_Score and the False_Positive_Rate obtained are 95.79 and 0.1%. All the results
are tabulated in Tables3 and 4.
5.3
Comaprison with Existing Result
The existing result from the paper [7] was based on Decision Tree and Naive Bayes. In
the paper, they have achieved an accuracy of 97.14% which is less than our obtained
result as stated in Table3. We have achieved a precision of about 99.75% which is far
better than the existing result of 94.84%. In terms of the false positive rate, our model
has performed very well by achieving 0.1% as compared to the existing result, which
is 5.6%. All the existing results and the obtained result are tabulated in Table5.
6
Conclusion
The presented work mainly aims to ﬁnd out the intrusion in autonomous vehicles as
the network system in an autonomous vehicle is not much secure. To prevent cyber-
physical systems like autonomous vehicles need continuous research as any loophole

174
A. Kumar and T. K. Das
in the security may be devastating to public safety. The attacks need to be detected in
real time so as to have fewer consequences of it. Our model, which is based on LAD
that involves binarization and selection of important features, provides a real-time
detection approach. The lower false positive rate obtained in the dataset suggests that
the LAD method is one of the efﬁcient methods of detecting intrusions. Autonomous
vehicles involve multiple network systems, and our method is effective and low cost
in case of identifying attacks in any network.
References
1. Almuallim H, Dietterich TG (1994) Learning boolean concepts in the presence of many irrel-
evant features. Artif Intell 69(1–2):279–305
2. Boros E, Hammer PL, Ibaraki T, Kogan A, Mayoraz E, Muchnik I (2000) An implementation
of logical analysis of data. IEEE Trans Knowl Data Eng 12(2):292–306
3. Bruni R, Bianchi G, Dolente C, Leporelli C (2019) Logical analysis of data as a tool for the
analysis of probabilistic discrete choice behavior. Comput Operat Res 106:191–201
4. CramaY,HammerPL,IbarakiT(1988)Cause-effectrelationshipsandpartiallydeﬁnedboolean
functions. Ann Operat Res 16(1):299–325
5. Das TK, Adepu S, Zhou J (2020) Anomaly detection in industrial control systems using logical
analysis of data. Comput Secur 96:101935
6. Duan X, Yan H, Tian D, Zhou J, Su J, Hao W (2021) In-vehicle can bus tampering attacks
detection for connected and autonomous vehicles using an improved isolation forest method.
IEEE Trans Intell Transp Syst (2021)
7. He Q, Meng X, Qu R, Xi R (2020) Machine learning-based detection for cyber security attacks
on connected and autonomous vehicles. Mathematics 8(8):1311
8. Kang MJ, Kang JW (2016) Intrusion detection system using deep neural network for in-vehicle
network security. PloS One 11(6):e0155781
9. Karopoulos G, Kambourakis G, Chatzoglou E, Hernández-Ramos JL, Kouliaridis V (2022)
Demystifying in-vehicle intrusion detection systems: a survey of surveys and a meta-taxonomy.
Electronics 11(7):1072
10. Lee H, Jeong SH, Kim HK (2017) Otids: a novel intrusion detection system for in-vehicle
network by using remote frame. In: 2017 15th annual conference on privacy, security and trust
(PST). IEEE, pp 57–5709
11. Lunt TF (1993) A survey of intrusion detection techniques. Comput Secur 12(4):405–418
12. Marchetti M, Stabili D, Guido A, Colajanni M (2016) Evaluation of anomaly detection for in-
vehicle networks through information-theoretic algorithms. In: 2016 IEEE 2nd international
forum on research and technologies for society and industry leveraging a better tomorrow
(RTSI). IEEE, pp 1–6
13. Miller C, Valasek C (2015) Remote exploitation of an unaltered passenger vehicle. Black Hat
USA 2015(S 91)
14. Moore MR, Bridges RA, Combs FL, Starr MS, Prowell SJ (2017) Modeling inter-signal arrival
times for accurate detection of can bus signal injection attacks: a data-driven approach to
in-vehicle intrusion detection. In: Proceedings of the 12th annual conference on cyber and
information security research, pp 1–4
15. Ohira S, Desta AK, Arai I, Inoue H, Fujikawa K (2020) Normal and malicious sliding windows
similarity analysis method for fast and accurate ids against dos attacks on in-vehicle networks.
IEEE Access 8:42422–42435
16. Song HM, Kim HR, Kim HK (2016) Intrusion detection system based on the analysis of
time intervals of can messages for in-vehicle network. In: 2016 international conference on
information networking (ICOIN). IEEE, pp 63–68

Real-Time Intrusion Detection in Connected Autonomous Vehicles
175
17. Song HM, Woo J, Kim HK (2020) In-vehicle network intrusion detection using deep convolu-
tional neural network. Veh Commun 21:100198
18. Wu W, Huang Y, Kurachi R, Zeng G, Xie G, Li R, Li K (2018) Sliding window optimized
information entropy analysis method for intrusion detection on in-vehicle networks. IEEE
Access 6:45233–45245
19. Young C, Zambreno J, Olufowobi H, Bloom G (2019) Survey of automotive controller area
network intrusion detection systems. IEEE Des Test 36(6):48–55

Physical Architecture of Linear Feedback
Shift Register Using Clock Tree Synthesis
for Cyber-Physical System
B. Muthu Nisha, V. Nithya, and J. Selvakumar
Abstract Every cyber-physical system must have a linear feedback shift register to
produce keys for every encryption method. The physical design of a shift register
operating at 500 MHz with linear feedback was examined in this work. Three design
aspects from this physical architecture are thoroughly investigated for usage in
application-speciﬁc integrated circuits. The worst negative slack timing path between
registers was studied for clock frequency consumption performance to comprehend
the signiﬁcance of clock tree synthesis. This system transmits the synchronous signal
to each succeeding cell via a clock tree. The needed speciﬁcation is appropriate for
a Random Number Generator with Multibit LFSR, Physically Unclonable Function,
and Fibonacci and Galois Number Theory in cyber-physical systems.
Keywords Cyber-physical system · Worst negative slack · Clock tree synthesis ·
Random Number Generator · Physically Unclonable Function
1
Introduction
Physical architecture is the process of turning a design into physical shapes. Some
of the phases include ﬂoor layout, placement, clock tree synthesis, and routing [1].
The construction of a netlist from the Register Transfer Level (RTL) is the ﬁrst
stage in physical design. The netlist comprises speciﬁcations of a circuit’s parts and
connections. Floor planning is the essential initial action. Choosing which structures
B. Muthu Nisha (B) · V. Nithya · J. Selvakumar
Department of Electronics and Communication Engineering, SRMIST, Kattankulathur, Tamil
Nadu, India
e-mail: mb1850@srmist.edu.in
V. Nithya
e-mail: nithyav@srmist.edu.in
J. Selvakumar
e-mail: selvakuj@srmist.edu.in
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_13
177

178
B. Muthu Nisha et al.
to place adjacent to one another while taking into account space limitations, travel
distances, and other component-related constraints is entailed [2].
When assembling each component or block on the die, timing and interconnect
length are taken into account. Clock tree synthesis reduces skew by evenly sharing
the clock throughout a system’s succeeding pieces by adding buffers or inverters
[3]. Clock tree synthesis (CTS) is the method by which buffers and inverters along
the clock routes of the Application-Speciﬁc Integrated Circuit (ASIC) architecture
synchronize the clock delay to all clock inputs [4]. CTS is therefore deployed to
balance the skew and lessen insertion latency.
Worst-case negative slack is the parameter used to analyze the most negative of
any single slack of the timing paths that failed at any design constraint. The duration
of time expected for the intake to a ﬂip-ﬂop to be stable before a clock edge is termed
as setup time. In contradiction to setup time, hold time addresses events that occur
after a clock edge. The hold time is the shortest period necessary for the intake to a
ﬂip-ﬂop to stay steady following a clock edge [5].
Tomaintainandmonitorthephysicalenvironment,cyber-physicalsystems(CPSs)
typicallyincorporateembeddedcomputerswithsensorconnectivity.Encryptionmust
remain a part of this system for data security in that particular case. To generate
keys for every encryption technique, each cyber-physical system must have a linear
feedback shift register [6].
This study takes into account setup and holds time analysis on the chosen design’s
worst-case negative slack time route. This proposed 500 MHz clock frequency linear
feedback shift register (LFSR) design operates for the required clock frequency
without slack according to a pre- and post-clock tree synthesis (pre-CTS and post-
CTS) performance report analyzed. Figure 1 depicts the critical steps that must be
taken to attain clock tree synthesis before the implementation of Graphic Data System
II (GDS II) for ASICs.
1.1
Contribution of this Paper
• Based on the design aspect perspective, this study introduces and names the key
principles of the linear feedback shift register.
• This paper discovers the consequence of clock tree synthesis.
• To adhere to timing limitations, setup and hold time analyses are also explored.
This research study is organized in the following order: Sect. 2 is about the liter-
ature review. Sect. 3 describes the proposed design speciﬁcation of the linear feed-
back shift register (LFSR). Section 4 presents the physical design stream. Section 5
demonstrates the results and analysis. Finally, Sect. 6 concludes the paper with future
directions.

Physical Architecture of Linear Feedback Shift Register Using Clock …
179
Fig. 1 Stream for clock tree synthesis
2
Literature Review
Application-speciﬁc integrated circuits beneﬁt from timing-aware integration.
Quality of integrated circuit enhanced using reduce insertion delay, skew balance,
duty cycle, pulse width, clock tree power consumption, signal integrity, and cross-talk
via clock tree synthesis [3, 7]. Time impact affects optimization technique, place-
ment, and global routing power consumption [8]. Latency and the transition in the
timing path are two crucial factors that affect clock tree power; if latency is low,
power consumption is also less. Power usage recovers with smooth transitions [9].
The time frame required for the input to a ﬂip-ﬂop to be stable before a clock edge
is known as setup time. In comparison to setup time, hold time covers events that
take place after a clock edge. The hold time is the minimum period necessary for the
input to a ﬂip-ﬂop to stay constant following a clock edge [10, 11]. According to this
study, after routing the design, there is zero worst negative slack during the assigned
time period. This timing analysis is inﬂuenced by clock lags, skew, cell distribution
throughout the path, slew, fan out, wire length, and net delay [12]. Optimization of

180
B. Muthu Nisha et al.
physical design is concerning result quality and clock net routing in a design process
[13]. Innovative techniques can be used in system on chip to ensure accurate clocking
and synchronization at all levels of abstraction [14, 15].
3
Design Speciﬁcation of Linear Feedback Shift Register
In this research study, a shift register called a linear feedback shift register (LFSR)
has an input bit whose value is linearly correlated to its prior state. The most popular
type of linear is used in this physical architecture for cyber-physical systems. As an
outcome, an LFSR is typically a shift register whose input bit is driven by the XNOR
of some of the shift register’s entire value. An LFSR ﬁts into the state machine CPS
class. The input bit of the shift register is a linear function of the preceding state.
XOR and XNOR are solitary linear operations on single bits. The physical archi-
tecture of linear feedback shift register (LFSR) with 500 MHz clock frequency, 1
voltage amplitude with maximum input and output delay 1.0 ns, and clock transition
of rise and fall edge 0.1 v having 8-bit register was designed. The output of the ﬁfth
and sixth register with XNOR operation form feedback path. Table 1 displays the
speciﬁcation of LFSR, and Fig. 2 displays the functional veriﬁcation of LFSR.
Table 1 Requirement for the
design of LFSR
S. No.
Speciﬁcation
Values
1
Clock frequency
500 MHz
2
Amplitude
1 V
3
Maximum input delay
1.0 ns
4
Maximum output delay
1.0 ns
5
Rise clock transition
0.1 V
6
Fall clock transition
0.1 V
Fig. 2 Functional veriﬁcation of 8-bit linear feedback shift register

Physical Architecture of Linear Feedback Shift Register Using Clock …
181
3.1
RTL Design and Veriﬁcation
Transferring
a
higher
level
of
abstraction
to
a
lower
level
of
abstrac-
tion that can be implemented during the synthesis stage which can be opti-
mized for speed (timing), area, testability, and power. The operating parameters
used in this design are process 1 ns, voltage 0.9 V, and temperature 125 °C. Three
channel lengths are listed in Table 2 for examining lower-level abstraction. Figure 3
shows the LFSR’s schematic diagram.
To select any one of the channel length constraints, 90 nm speciﬁcation is used for
proceeding with a physical architecture in this study. The following timing statement
applies to the 90 nm channel length MOSFET technology design and is shown in
Table 3. The physical design of the LFSR was furthered using this report.
Table 2 Description of lower-level abstraction
S. No.
Channel length (nm)
Technology
A ﬁgure of merit (power parameter)
1
90
MOSFET
Leakage power—3.580 nW
Dynamic power—3122.096 nW
Total power—3125.677 nW
2
45
MOSFET
Leakage power—789.399 nW
Dynamic power—3874.508 nW
Total power—4663.907 nW
3
180
CMOS
Leakage power—15.46 nW
Dynamic power—17639.649 nW
Total power—17655.113 nW
Fig. 3 Schematic diagram of LFSR
Table 3 Statement of timing report
S. No.
Pin
Fan out
Load (fF)
Slew (ps)
Delay (ps)
Arrival (ps)
1
Out_reg [5]/CK
NA
NA
0
NA
0
2
Out_reg [5]/QN
1
2.8
45
+ 390
390
3
Out_reg [0] /D
NA
NA
NA
+ 0
390
4
Out_reg [0]/CK
NA
NA
0
+ 260
650

182
B. Muthu Nisha et al.
Table 4 Speciﬁcation of the
ﬂoor planning
S. No.
Requirement
Values (µm)
1
Aspect ratio
0.8573
2
Core utilization
0.6999
3
Core margin I/O boundary
8 [core to left, right, top,
bottom]
4
Physical Design Stream
4.1
Floor Planning
The physical design is essential because as technology advances, the intricacy of the
designs and the size of the circuits both increase [16]. Floor planning is the ﬁrst phase
in the VLSI physical design pipeline. It determines the location and arrangement of
each block on a chip to minimize chip area and connecting wire lengths. In this paper,
the chip area is reduced by the core usage parameter. The ﬂoor planning speciﬁcations
are provided in Table 4.
Figure 4a shows how the core occupies the whole ﬂoor planning area, with the
design using roughly 70% of the core.
4.2
Power Planning
The core has been given power VDD and VSS pins for adding power rings and stripes
with ring arrangement. With a width of 1.8 µm and a layer spacing of 0.5 µm, the
top and bottom power rings in this design are made of Metal9(9), while the left and
right power rings are made of Metal8(8). The design’s power planning is depicted in
Fig. 4b. Speciﬁcations for the power planning are listed in Table 5.
4.3
Placement Design
The process of placing circuit devices on a die surface is described as placement.
It is a crucial step in the design process for Very Large-Scale Integration (VLSI).
Standard cells are placed on the core area as shown in Fig. 4c. Since placement has
an impact on a design’s routability, performance, heat distribution, and to a lesser
extent, power consumption, it is typically utilized following the synthesis phase and
before the routing phase. The location has emerged as the key factor in circuit latency
[17].
Because of these criteria, placement design was used for this research study.
To improve circuit performance, placement information is crucial, especially in the

Physical Architecture of Linear Feedback Shift Register Using Clock …
183
Fig. 4 a Core utilization of the ﬂoor plan b power planning of the design c placement design

184
B. Muthu Nisha et al.
Table 5 Speciﬁcation of the power planning
S. No.
Ring
Layer
Width (µm)
Spacing (µm)
1
Top
Metal9(9) (Horizontal)
1.8
0.5
2
Bottom
Metal9(9) (Horizontal)
1.8
0.5
3
Left
Metal 8(8) (Vertical)
1.8
0.5
4
Right
Metal 8(8) (Vertical)
1.8
0.5
early design phases. Placement techniques have recently been incorporated into the
stages of logic synthesis and architecture design to perform physical synthesis and
physical-aware architecture design [18], respectively. According to the Synopsys
Design Constraint ﬁle (SDC ﬁle), which includes the required design attributes for
each block’s placement on the chip and its organization in the cadence tool.
4.4
Clock Tree Synthesis
To balance the clock delay to all clock inputs, the clock tree synthesis (CTS) approach
comprises the instinctive addition of buffers and inverters along the clock frequencies
of the ASIC design. This is used to improve clock supply to all standard cells. CTS
is used to diminish insertion latency and balance clock skew. A method for evenly
dividing the clock throughout all sequential components of a VLSI design is called
clock tree synthesis.
Clock tree synthesis works to reduce skew and latency. Figure 5 illustrates the
clock tree synthesis of LFSR physical architecture.
Fig. 5 Clock tree synthesis

Physical Architecture of Linear Feedback Shift Register Using Clock …
185
Fig. 6 Final power-routed design
4.5
Routed Power Design
There is an effect on the routed power design that provides power to the LFSR
standard cell. To enhance the timing path, it is essential to look at clock tree synthesis
in this area [19, 20]. The ﬁnal power routing architecture is shown in Fig. 6.
5
Result and Analysis
The clock tree has a considerable impact on power consumption. Power consumption
is inﬂuenced by the design’s rise and fall times.
• Placement design or timing design which has an impact on typical cell respects
clock.
• Special routing design has an impact on clock skew.

186
B. Muthu Nisha et al.
Table 6 Report of pre- and post-clock tree synthesis
S. No.
Clock tree synthesis (CTS)
Worst negative slack (WNS) of timing path (ns)
(register to register)
Placement
design
Routing design
Optimized
design
Setup
Hold
Setup
Hold
Setup
Hold
Worst
Best
Worst
Best
Worst
Best
1
Pre-CTS
1.339
0.011
1.332
0.010
1.333
0.010
2
Post-CTS
1.339
0.011
1.332
0.010
1.333
0.010
• After physical routing, optimized design was obtained. It is necessary to reevaluate
the clock delay on this design.
As a result of the Cadence Innovus tool, clock tree synthesis is crucial to these
designs. The parameters for this synthesis are listed with setup time with worst-case
and hold time with best-case scenarios in Table 6.
Table 6 implies that the zero slack on the worst-case timing path among these
three designs provides clock tree synthesis which is used to ensure that the operating
clock frequency was applied to all of the design’s standard cells.
6
Conclusion and Future Directions
In this work, the clock tree synthesis for an 8-bit LFSR physical architecture
is inspected. From the report, it is observed that the clock frequency is used in
each LFSR cell without any slack. This architecture is suited for developing Field
Programmable Gate Arrays in the future from a machine learning perspective, as well
as a Random Number Generator with Fibonacci and Galois number theory, Multibit
LFSR, and Physically Unclonable Functions in cyber-physical systems.
References
1. Chakravarthi VS (2022) SoC physical design. In: A practical approach to VLSI system on chip
(SoC) Design. Springer, Cham
2. Circuit Modeling with Hardware Description Languages. In: Kaeslin H (ed) Top-Down digital
VLSI design. Morgan Kaufmann, pp 179–300 (2015)
3. Shan W, Dai W, Wan L, Lu M, Shi L, Seok M, Yang J (2020) A bi-directional, zero-latency
adaptive clocking circuit in a 28-nm wide AVFS system IEEE. J Solıd-State Circuıts 55(3)
4. Clock tree synthesis in VLSI physical design (http://www.ivlsi.com)
5. Kahng AB (2018) New directions for learning-based IC design tools and methodologies. In:
2018 23rd Asia and South paciﬁc design automation conference (ASP-DAC), pp 405–410
6. Lee EA (2015) The past, present and future of cyber-physical systems: a focus on models.
Sensors 15:4837–4869

Physical Architecture of Linear Feedback Shift Register Using Clock …
187
7. Kahng AB, Kim M, Kim S, Woo M (2022) RosettaStone: connecting the past, present, and
future of physical design research. IEEE Des Test 39(5):70–78
8. Cheng C-K, Kahng AB, Kang I, Wang L (2019) RePlAce: advancing solution quality and
Routability validation in global placement. IEEE Trans Comput-Aided Des Integr Circ Syst
38(9):1717–1730
9. Geng H, Chen T, Ma Y, Zhu B, Yu B (2022) PTPT: physical design tool parameter tuning
via multi-objective bayesian optimization. In: IEEE transactions on computer-aided design of
integrated circuits and systems
10. Ahmed MV, Kariyappa BS (2022) Optimization of cloning in clock gating cells for high-
performance clock networks. In: Mallick PK, Bhoi AK, Barsocchi P, de Albuquerque VHC
(eds) Cognitive informatics and soft computing. lecture notes in networks and systems, vol 375
11. Du N, Schmidt H, Polian I (2021) Low-power emerging memristive designs towards secure
hardware systems for applications in internet of things. Nano Mater Sci 3(2):186–204. ISSN
2589-9651
12. Roy S, Ma Y, Miao J, Yu B (2017) A learning bridge from architectural synthesis to physical
design for exploring power efﬁcient high-performance adders. In: Proceeding of ISLPED, pp
1–6
13. Murugan K, Baulkani S (2019) VLSI implementation of ultra power optimized adiabatic logic
based full adder cell. Microprocessors and Microsystems 70:15–20. ISSN 0141–9331
14. Zhuo C, Unda K, Shi Y, Shih W-K (2018) From layout to system: early stage power delivery
and architecture coexploration. IEEE TCAD 38(7):1291–1304
15. Hou S, Guo Y, Li S (2019) A Lightweight LFSR-based strong physical unclonable function
design on FPGA. IEEE Access 7:64778–64787
16. Srinivasan B, Venkatesan R (2021) Multi-objective optimization for energy and heat-aware
VLSI ﬂoorplanning using enhanced ﬁreﬂy optimization. Soft Comput 25:4159–4174
17. Lin Y, Li W, Gu J, Ren H, Khailany B, Pan DZ (2020) ABCD place: accelerated batch-based
concurrent detailed placement on multithreaded CPUs and GPUs. In: IEEE transactions on
computer-aided design of integrated circuits and systems, vol 39, no 12, pp 5083–5096
18. Ma Y, Yu Z, Yu B (2019) CAD tool design space exploration via Bayesian optimization. In:
Proceeding of MLCAD, pp 1–6
19. Chen X, Liu G, Xiong N, Su Y, Chen G (2020) A survey of swarm intelligence techniques in
VLSI routing problems. IEEE Access 8:26266–26292
20. Zhan T, Fatmi SZ, Guraya S, Kassiri H (2019) A resource-optimized VLSI implementation of
a patient-speciﬁc seizure detection algorithm on a custom-made 2.2 cm2 wireless device for
ambulatory epilepsy diagnostics. IEEE Trans Biomed Circ Syst 13(6):1175–1185

Detection of Arrhythmia via Electrical
Activity of the Heart Using AI Techniques
J. Pramitha and X. Anitha Mary
Abstract Electrocardiogram (ECG) consists of several waveforms such as the P
wave, QRS complex, and T-wave. Various heart diseases can be diagnosed by
observing the variations in the shape of each waveform and the distance between
different peaks. There are 15 suggested classes for arrhythmia which are divided
into 5 super classes: Normal (N), Supraventricular ectopic beat (SVEB), Ventricular
ectopic beat (VEB), Fusion beat (F), and Unknown beat (Q). The input signal is
classiﬁed into these 5 categories using 1D Convolution Neural Network, Random
Forrest Classiﬁer, Decision Tree Classiﬁer, and MPL Classiﬁer. In the clinical diag-
nosis of cardiac illness, the ECG classiﬁcation is crucial. The three main perfor-
mance metrics—precision, recall, and F1 score are calculated for all 4 models and
compared. The accuracy of the four models is also computed and compared. The
One-Dimensional Convolution Neural Network achieved 98% accuracy, 90% macro
average, and 98% weighted average. The Decision Tree Classiﬁer achieved 95%
accuracy, 80% macro average, and 95% weighted average. The Random Forest Clas-
siﬁer achieved 97% accuracy, 86% macro average, and 97% weighted average. The
MLP Classiﬁer achieved 98% accuracy, 87% macro average, and 97% weighted
average.
Keywords Electrocardiogram · Classes · Machine learning algorithm ·
Performance metrics
1
Introduction
Cardiovascular disease is caused due to various conditions. Some of these conditions
might be a heart attack, stroke, heart failure, arrhythmia, and other such conditions.
Arrhythmia is caused when the heartbeats too slowly, too quickly, or irregularly.
Detection of arrhythmia at an early stage helps greatly with the treatment [1, 2].
J. Pramitha · X. Anitha Mary (B)
Department of Robotics Engineering, Karunya Institute of Technology and Sciences, Coimbatore,
India
e-mail: anithamary@karunya.edu
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_14
189

190
J. Pramitha and X. Anitha Mary
An electrocardiogram (ECG) records the electrical activity of the heart. The elec-
trodes are placed on the skin to record the electrical changes brought on by the heart
muscle’s depolarization and repolarization during each cardiac cycle. These signals
are recorded by a machine and are looked at by a doctor to see if they’re unusual.
The deﬂections in each cardiac cycle are represented in the form of the P wave,
QRS complex, and the T-wave. The P wave represents the arterial depolarization, the
QRS complex represents the ventricular depolarization, and the T-wave represents
the ventricular repolarization.
• P wave—atrial depolarization—atria contracts
• QRS complex—ventricles depolarization—ventricles contracts
• T-wave—ventricular repolarization—ventricles relax.
Previously,manymethodshavebeenputforthtoﬁndarrhythmia.Majorityofthese
methods relied on classiﬁcation algorithms like Support Vector Machines (SVMs)
[3] and digital signal processing (DSP) techniques. Deep Neural Network-based
Machine Learning algorithms have proliferated across all ﬁelds and can also be used
in detecting arrhythmia.
2
Related Works
The different kinds of techniques and classiﬁcation algorithms for the classiﬁcation
of arrhythmia are reviewed from selected articles as shown in Table 1.
Table 1 Literature review
Sl. No.
Author
Inference
1
Celin and Vasanth [3]
Results show that the accuracy of the SVM, Adaboost, and
ANN classiﬁer is 87.5, 93, and 94%
2
Luz et al. [4]
MIT-BIH database’s heartbeats were suggested to be split
into two sets so that the database would be more consistent
with reality
3
Romdhane et al. [5]
Classiﬁcation is done through 1D Convolutional Neural
Network
4
Martinez-Useros et al. [6]
Higher accuracy was given for aortic disease detection
5
Wu et al. [7]
The R–R peak is detected and is used for classiﬁcation

Detection of Arrhythmia via Electrical Activity of the Heart Using AI …
191
Fig. 1 ECG classiﬁcation using various machine learning algorithms
3
Methodology
3.1
Objective
To detect cardiovascular diseases, the identiﬁcation and classiﬁcation of ECG signals
are necessary. Manual identiﬁcation of ECG heartbeat classes by cardiologists is
time-consuming. Therefore, various artiﬁcial intelligence techniques are being used
for identifying ECG characteristics. The primary goal is to categorize the ECG into
its ﬁve main classes. The following are the main design objectives:
1. Classify the ECG into its 5 classes (N, SVEB, VEB, F, Q).
2. Use 1D Convolution Neural Network, Random Forrest Classiﬁer, Decision Tree
Classiﬁer, and MPL Classiﬁer to classify the ECG.
Figure 1 shows the generalized diagram of proposed work for ECG classiﬁcation.
3.2
Dataset
The dataset for MIT-BIH arrhythmias is used in this study. The dataset compiles
48 patients’ 30-min raw ECG recordings, 25 of who are female and 22 of whom
are male. Each record is made up of two lead signals: the upper signal, which is a
modiﬁed limb lead II produced by placing lead on the chest, and the bottom signal,
which is normally a modiﬁed lead V1 [4]. The dataset’s records are each sampled
once per 360 Hz. Signiﬁcant QRS complexes can be seen in the upper signal MLII,

192
J. Pramitha and X. Anitha Mary
and the database is primarily split into 15 subclasses and ﬁve super classes of heart
arrhythmias [8]. The details are given below.
• 109,446 samples are available in the database [9]
• These samples are classiﬁed into 5 categories
• The sampling frequency is125 Hz
• The data source is Physionet’s MIT-BIH arrhythmia dataset
• Super classes: (Normal beat ‘N’: 0, Supraventricular ectopic beat ‘S’: 1,
Ventricular ectopic beat ‘V’: 2, Fusion beat ‘F’: 3, Unknown beat ‘Q’: 4).
3.3
Pre-processing and Feature Extraction
The dataset’s raw ECG signals are added together with interferences such as EMG,
power frequency, and noise. The data must be free of these interferences to accurately
detect heartbeats with arrhythmias. To achieve this, the raw ECG signals have been
de-noised using the Discrete-Wavelet-Transform. The denoising ﬁlter lessens the
QRS complex’s signal distortion, allowing for a clearer expression of the complex’s
signal in the detection of RR intervals [10]. Additionally, the preprocessed dataset
was split into 20% of the data for testing and 80% for training the model [11] to
accurately examine the proposed approach. The collection consists of 48 records,
each of which represents a distinct patient.
4
Arrhythmia Classiﬁcation
The main goal of this study is to present four algorithms to classify arrhythmia with
the available MIT-BIH database using artiﬁcial intelligence techniques.
4.1
Convolutional Neural Network (CNN)
Convolutional neural network (CNN) is one of the ﬁrst effective deep learning algo-
rithms, mostly used for the classiﬁcation of images, video, texts, and speech. The
three layers present in CNN are convolution, pooling layers, and activation layers
[2]. The main advantage of CNN is that it automatically observes and extracts the
most important feature from the given set of inputs.

Detection of Arrhythmia via Electrical Activity of the Heart Using AI …
193
4.2
MLP Classiﬁer
A multilayer perceptron (MLP) is an artiﬁcial neural network that generates outputs
from a set of inputs. A neural network is used by the multilayer perceptron classiﬁer
to carry out the classiﬁcation operation. MLP makes use of back propagation for
training the network.
4.3
Random Forest Algorithm
Random Forest is a machine learning algorithm that falls under the supervised
learning technique. Random Forest is a classiﬁer that uses numerous decision trees
on different subsets of the provided dataset and considers the average to increase the
dataset’s predictive accuracy. The Random Forest decides based on the results from
each decision tree instead of relying on just one, and the ultimate result is determined
by the majority of predictions. The greater number of trees in the forest, the higher
the accuracy. When each tree in the forest casts a unit vote for the most predicted
class, classiﬁcation takes place. The categorization with the greatest votes among
all the trees is then selected by the Random Forest classiﬁer. The Random Forest
technique is suitable for long-term ECG beat categorization since it is fast, performs
well, and requires no cross-validation. It exhibits good performance on a variety of
real-world issues since it is not overﬁtted and is not sensitive to data set noise. An
overﬁt model observes all the features of the training dataset and performs well but
produces very poor results for the testing dataset.
4.4
Decision tree
A decision tree is a tree-structured classiﬁer. The features of a dataset are described
by the internal nodes, the decision rules are described by the branches and the results
are represented by each leaf node. Decision Node and Leaf Node are the two types of
nodes present in this classiﬁer. The decisions are made by the decision node and they
have multiple branches [12], whereas the leaf nodes hold those results and have no
further branches. The results of the decisions are generated based on the features of
the dataset given. A question is asked and based on the answer (Yes/No), the decision
tree branches and forms a tree-like structure.

194
J. Pramitha and X. Anitha Mary
5
Results and Discussion
It is inferred that the accuracy of One-Dimensional Convolutional Neural Network
is 98%, the Decision Tree Classiﬁer is 95%, Random Forest Classiﬁer is 97%, and
MLP Classiﬁer is 98%. Further, the precision, recall, and F1 score for every model
have also been tabulated and plotted.
The 1D CNN achieved 98% accuracy, 90% macro average, and 98% weighted
average. The Decision Tree Classiﬁer achieved 95% accuracy, 80% macro average,
and 95% weighted average. The Random Forest Classiﬁer achieved 97% accuracy,
86% macro average, and 97% weighted average. The MLP Classiﬁer achieved 98%
accuracy, 87% macro average and 97% weighted average.
5.1
Interpretation of Performance
Prediction made
Actual result
True positive (TP)
False positive (FP)
False negative (FN)
True negative (TN)
True Positive (TP): These accurately predicted positive values show that both the
actual result and the prediction made are true.
True Negative (TN): These accurately predicted negative values show that both
the actual result and the prediction made are true.
False Positive (FP): This occurs when the actual result is false but the prediction
made suggests that it is true.
False Negative (FN): This occurs when the actual result is true but the prediction
made suggests that it is true.
Accuracy:
Accuracy is the sum of all the accurately predicted values to the total number of
observations [13].
Accuracy = Accurately predicted values
Total number of observations
Accuracy =
TP + TN
TP + TN + FP + FN
Precision:
Precision is given by accurately predicting positive values to the total predicted
positive values.

Detection of Arrhythmia via Electrical Activity of the Heart Using AI …
195
Precision = Accurately predicted positive values
Total predicted positive values
Precision = TP + TN
TP + FP
Recall:
The recall is given by the total number of accurately predicted positive values to the
total number of values in the actual results.
Recall = Accurately predicted positive values
Actual results
Recall =
TP
TP + FN
F1 Score:
To calculate the F1 score, the average precision and recall are considered.
F1 Score = 2 ∗Precision ∗Recall
Precision + Recall
Table 2 shows the performance metrics for 1D CNN. It is observed that precision,
recall, and F1 score values are high for [Q].
Table 3 shows the performance metrics for the Decision Tree. It is observed that
precision, recall, and F1 score values are high for [N].
Table 4 shows the performance metrics for Random Forest. It is observed that
precision, recall, and F1 score values are high for [N] and [Q].
Table 2 Performance report
of 1D CNN
Classes of Arrhythmia
Precision
Recall
F1-score
[N] 0
0.98
1
0.99
[S] 1
0.91
0.73
0.81
[V] 2
0.99
0.88
0.93
[F] 3
0.75
0.81
0.78
[Q] 4
0.99
0.98
0.99
Table 3 Performance report
of decision tree
Classes of Arrhythmia
Precision
Recall
F1-score
[N] 0
0.98
1
0.99
[S] 1
0.62
0.63
0.63
[V] 2
0.86
0.86
0.86
[F] 3
0.58
0.62
0.6
[Q] 4
0.94
0.94
0.94

196
J. Pramitha and X. Anitha Mary
Table 4 Performance report
of Random Forest
Classes of Arrhythmia
Precision
Recall
F1-score
[N] 0
0.97
1
0.98
[S] 1
0.99
0.58
0.73
[V] 2
0.98
0.86
0.92
[F] 3
0.88
0.59
0.7
[Q] 4
1.00
0.94
0.96
Table 5 Performance report
of MLP classiﬁer
Classes of Arrhythmia
Precision
Recall
F1-score
[N] 0
0.98
1
0.99
[S] 1
0.89
0.64
0.75
[V] 2
0.96
0.9
0.93
[F] 3
0.87
0.6
0.71
[Q] 4
0.99
0.96
0.98
Table 5 shows the performance metrics for MLP. It is observed that precision,
recall, and F1 score values are high for [N] and [Q].
Figure 2 shows the graphical representation of performance metrics for 1D CNN,
Decision Tree (Fig. 3), Random Forest (Fig. 4), MLP Classiﬁer (Fig. 5).
Table 6 and Fig. 6 show that the accuracy of the 1D-CNN is 98% as they auto-
matically learn the key features of the given training dataset. It is based on three
Fig. 2 Graphical view of performance report of 1D CNN

Detection of Arrhythmia via Electrical Activity of the Heart Using AI …
197
Fig. 3 Graphical view of performance report of decision tree
Fig. 4 Graphical view of performance report of Random Forest
convolution, max pooling, and dense layers which automatically extract distinguish-
able nonlinear features from the ECG signals and automatically classify them into
ﬁve different classes. The accuracy of Decision Tree and Random Forest Classiﬁers
are 95% and 97%, respectively. The MLP Classiﬁer has achieved an accuracy of 98%
because of its hidden layers and uses the back propagation technique for its training.

198
J. Pramitha and X. Anitha Mary
Fig. 5 Graphical view of performance report of MLP classiﬁer
Table 6 Comparative study
on the accuracy of various
ML models
Model
Accuracy
1D CNN
98
Decision tree
95
Random forest
97
MLP classiﬁer
98
Fig. 6 Graphical view of accuracy report of various ML algorithms

Detection of Arrhythmia via Electrical Activity of the Heart Using AI …
199
6
Conclusion
The precise analysis of heartbeats via ECG is crucial for treating cardiovascular
disorders since they constitute a serious threat to human life. Medical professionals
must invest a lot of time and money in manually analyzing ECG readings. To do
this, the emphasis has switched from manual analysis to automatic identiﬁcation of
anomalies in heartbeat.
Four models have been used for classifying ECG signals—One-Dimensional
Convolution Neural Network, Decision Tree Classiﬁcation, Random Forest Clas-
siﬁer, and MLP Classiﬁer. One major obstacle to developing a completely automatic
classiﬁcation of heartbeats using ECG is that the database availability is limited.
Arrhythmias (especially ventricular arrhythmias) were majorly detected in patients
diagnosed with aortic stenosis, pulmonary stenosis, or ventricular septal defect.
“Serious arrhythmias” were most frequently seen in patients with aortic stenosis
who also had a higher chance of sudden death. Severe ventricular arrhythmias in
aortic stenosis may be associated with left ventricular dysfunction and should be
taken into account when deciding if surgery should be performed. Thus, this study
can be extended to train the models to extract more features to detect ventricular
arrhythmias that can also be used to detect aortic stenosis. The suggested method
can be improved and tested in the future to cope with real-time data. Additionally,
the model can be made simpler to be used with embedded systems.
References
1. Mohebbanaaz et al (2021) Classiﬁcation of ECG beats using optimized decision tree and
adaptive boosted optimized decision tree. Signal Image Video Process. https://doi.org/10.1007/
s11760-021-02009-x
2. Zhang D et al (2021) An ECG heartbeat classiﬁcation method based on deep convolutional
neural network. J Healthc Eng 2021:1–9. https://doi.org/10.1155/2021/7167891
3. Celin S, Vasanth K (2018) ECG signal classiﬁcation using various machine learning techniques.
J Med Syst 42:241
4. Luz EJ da S et al (2016) ECG-based heartbeat classiﬁcation for arrhythmia detection: a
survey. Comput Methods Programs Biomed 127:144–164. https://doi.org/10.1016/j.cmpb.
2015.12.008
5. Romdhane TF et al (2020) Electrocardiogram heartbeat classiﬁcation based on a deep convo-
lutional neural network and focal loss. Comput Biol Med 123:103866. https://doi.org/10.1016/
j.compbiomed.2020.103866
6. Martínez-Useros C et al (20222) Ventricular arrhythmias in aortic valve disease: a further
marker of impaired left ventricular function. Int J Cardiol 34(1):49–56. https://doi.org/10.
1016/0167-5273(92)90081-d
7. Wu M et al (2021) A study on arrhythmia via ECG signal classiﬁcation using the convolutional
neural network. Front Comput Neurosci 14. https://doi.org/10.3389/fncom.2020.564015
8. Kanani P, Padole M (2020) Electrocardiogram heartbeat classiﬁcation based on a deep
convolutional neural network and focal loss. Comput Biol Med 123:103866. ISSN 0010-4825
9. de Chazal P, O’Dwyer M, Reilly RB (2004) Automatic classiﬁcation of heartbeats using ECG
morphology and heartbeat interval features. IEEE Trans Biomed Eng 51(7):1196–1206

200
J. Pramitha and X. Anitha Mary
10. Pandey SK et al (2020) Patient-speciﬁc machine learning models for ECG signal classiﬁcation.
Procedia Comput Sci 167(2020):2181–2190. https://doi.org/10.1016/j.procs.2020.03.269
11. Kanani P, Padole M (2020) ECG heartbeat arrhythmia classiﬁcation using time-series
augmented signals and deep learning approach. Procedia Comput Sci 171(2020):524–531.
https://doi.org/10.1016/j.procs.2020.04.056
12. Lu P et al (2021) Identiﬁcation of arrhythmia by using a decision tree and gated network fusion
model. Comput Math Methods Med 2021:1–13. https://doi.org/10.1155/2021/6665357
13. Das MK, Ari S (2014) ECG beats classiﬁcation using mixture of features. Int Sch Res Not
2014:1–12. https://doi.org/10.1155/2014/178436

Utilizing Deep Convolutional Neural
Networks for Image-Based Plant
Disease Detection
Saha Reno
, Marzia Khan Turna
, Sheikh Tasﬁa
, Md. Abir
,
and Anusha Aziz
Abstract Automatic leaf disease detection is a challenging problem in smart agri-
culture due to the variations in appearance and the complicated backgrounds of
plant diseases. Designing a deep convolutional neural network model that extracts
visual illness features from the photos and then recognizes the diseases based on
the retrieved features is a standard solution to this problem. This method works well
when the background is simple, but it has poor accuracy and robustness when the
background is complex. The primary factor in identifying leaf-based plant diseases
is the color information of sick leaves. Most existing approaches for diagnosing plant
diseases depend on the expert diagnosis, which inevitably results in ﬁeld management
and crop disease control behind the times. In this paper, our methodology is based on
deep CNN which can be applied to solve these problems to improve the speed and
accuracy of disease classiﬁcation and recognition of plant diseases. We mainly focus
on a deep CNN-based model with ﬁne-tuning vegetable leaf diseases dataset. Trans-
fer learning models implemented with famous pre-trained models such as VGG-16
and ResNet-50 are compared with our proposed model. Our proposed model outper-
forms various existing solutions with an Mean Average Precision (mAP) accuracy
of 99.80%.
Keywords Plant disease detection · Deep convolutional neural network · Object
detection · Machine learning · ResNet-50 · VGG-16 · YOLOv5
S. Reno (B) · M. K. Turna
Bangladesh Army International University of Science and Technology, Cumilla, Bangladesh
e-mail: reno.saha39@gmail.com
S. Tasﬁa
Military Institute of Science and Technology, Dhaka, Bangladesh
Md. Abir
University of Erlangen Nuremberg, Erlangen and Nuremberg, Bavaria, Germany
A. Aziz
Bangladesh University of Business and Technology, Dhaka, Bangladesh
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_15
201

202
S. Reno et al.
1
Introduction
Plant disease symptoms often appear on leaves, buds, fruits, and young twigs. Fruit is
destroyed or wasted as a result. Additionally, these diseases cause the development of
fresh infections and the spread of the illness due to factors including seasonal weather.
Due to this, it is crucial to identify the disease beforehand and take the appropriate
measures to prevent it from spreading to other trees. As a result, the primary concern
in agriculture is the ﬁght against plant pests and diseases. Different plant diseases
exist, and they can all cause harm to the economy, society, and environment. In this
situation, a fast and correct diagnosis of plant diseases is crucial to preventing the loss
of agricultural output and quantity. Plant disease detection is typically done by hand.
These procedures are carried out by specialists such as agricultural engineers and
researchers, ﬁrst by visualization and then in the research lab. These conventional
techniques are complex and time-consuming procedures as these techniques are
computationally costly, the training takes a large amount of training data, and each
training example demands extensive calculations and space.
Deep convolutional neural networks (CNNs) have recently made signiﬁcant
advancements in these ﬁelds with deep learning and visual object recognition. The
ability to extract features without using segmented approaches is one of the leading
facilities of architecture and methods developed in those areas. As a result, using these
methodologies and models in practical applications is simple. Numerous research on
the detection of plant diseases has found excellent efﬁciency when CNNs are utilized
as fundamental deep learning methods. CNN employs convolution and pooling tech-
niques to subsample the input prior to implementing an activation function, in which
all of the levels are partly linked and buried, with the last layer being the output layer.
In summary, research on plant disease can be said to have used conventional image
processing techniques for recognition and have obtained speciﬁc outcomes and good
disease accuracy acknowledgment. However, there are still ﬂaws and restrictions,
such as follows:
1. The relationships and procedures used in research are complex, highly individu-
alized, labor-intensive, and time-consuming.
2. It is extremely reliant on the spot segment.
3. Largely dependent on the extraction of the artiﬁcial feature. Extraction of artiﬁcial
featurescanbedoneinfourmethods:(i)SuperPoint:Self-supervisedinterestpoint
detection and description, (ii) D2-Net: A trainable CNN for joint description and
detection of local features, (iii) image feature matching based on deep learning,
and (iv) deep graphical feature learning for the feature matching problem.
4. The disease recognition performance is quite challenging to test.
Plant diseases greatly inﬂuence the productivity and quality of plants and pests
[13].Deeplearningtechnologyhasemergedinrecentyearstostudytherecognitionof
plantdiseasesandhassigniﬁcantlyoutperformedconventionalapproachesintheﬁeld
of digital image processing in recent years [16]. Researchers’ top research concerns
now center on identifying plant diseases and pests using deep learning technologies

Utilizing Deep Convolutional Neural Networks …
203
[12]. We need to put a lot of effort into classiﬁer design, expressing innovative end-
to-end qualities in the picture [3]. To begin, we must provide the neural network’s
input layer with arrays representing the image’s pixels. The extraction of features
from the image is done by a number of hidden layers, including the convolution layer,
the ReLU layer, and the pooling layer. The object in the image is ﬁnally identiﬁed
by a fully connected layer. Due to these qualities, deep learning technology is the
extensive emphasis given to detecting plant diseases, and it is becoming a popular
subject for investigation [7].
Deep CNN techniques are currently widely used in many computer vision applica-
tions, and predicting plant diseases is typically considered a specialized agricultural
application [6]. The number of agricultural crop pests and disease samples needs
to be improved. Self-collected data sources are less than open standard sources and
require laborious labeling [4]. The problem of tiny samples is the most pressing in
detecting plant diseases in contrast to more than 14 million sample data in ImageNet
datasets [15]. Only a few or a dozen training data are often obtained due to the low
incidence and expensive cost of various plant diseases, which restricts the use of
deep CNN techniques in detecting plant diseases [10]. There are now three possible
solutions to the small sample problem.
In this study, a deep CNN-based system for plant disease classiﬁcation is proposed
and implemented along with the evaluation.
1. A deep CNN-based system for plant disease classiﬁcation is proposed and imple-
mented along with the evaluation.
2. We used a dataset consisting of actual plant disease images collected from various
online sources like Kaggle and Google Scholar.
3. First, we extract deep features from this dataset using deep learning architectures:
YOLOv5, VGG-16, and ResNet-50.
4. After that, we used epoch=100 to evaluate the implementation.
5. Finally, we compare each of the algorithms. We get the best result in the YOLOv5
algorithm compared to VGG-16 and ResNet-50.
2
Literature Review
Numerous research articles have been written about the use of deep learning in
agriculture, which is crucial to the well-being of plants and crops, deep learning
literature review:
After the algorithm completed the test to ensure, Joshi, R. C. proposed VirLeafNet:
Automatic analysis and viral disease diagnosis using deep learning in the Vigna
mungo plant. All the models achieved high validation accuracy and produced testing
accuracy for VirLeafNet-1, VirLeafNet-2, and VirLeafNet-3 as 91.234, 96.429, and
97.403% on different leaf images, respectively. However, several bacterial, fungal,
and viral illnesses were not considered [5].

204
S. Reno et al.
Saumya Yadav; Analysis of peach leaf bacteriosis with deep CNN for dis-
ease prediction. This project contrasts the outcomes of the CNN technique with
the imaging methodology. This study’s model architectures created using vari-
ous deep learning techniques performed best, correctly detecting the associated
peach leaf [bacteria-free and healthy] in 0.185s for each image. An accuracy of
98.75% is achieved but our system increases the accuracy to 99.80% using YOLOv5
[19].
Vaibhav Tiwari created a paper on multiclass plant disease recognition and clas-
siﬁcation using dense CNN based on a leaf image dataset. The proposed model of
DADCNN-5 outperforms the current Ml architecture and conventional CNN designs,
according to experimental results presented in this research, and obtained 97.33%
accuracy. The results were 96.57%, 99.94%, and 0.063% for sensitivity, speciﬁcity,
and false positive rates, respectively. The module completes the training procedure
in around 3235min and achieves an accuracy rate of 99.86%. Corn Blight, Corn
Common Rus, Corn Gray Spot and Corn Healthy were not included and considered
in their research [18].
M. Lv, Maize utilizes DMS-Robust Alexnet and leaf disease identiﬁcation based
on feature enhancement. In this study, Alexnet’s recognition accuracy reaches
91.83%, demonstrating a trend for accuracy to converge. DMS-Robust Alexnet has
a recognition accuracy of 98.62%. Only diseases related to corn leaf are considered
and classiﬁed using Alexnet and DMS-Alexnet falls under the original CNN hence
cannot perform better than deep CNN [8].
Ishrat Zahan Mukti’s research focuses on using ResNet-50 to detect plant diseases
by transfer learning. The most remarkable performance of their suggested model
was 99.80% training accuracy and 100% validation accuracy. The proposed model
is based on ResNet-50 which cannot outperform YOLOv5 with respect to training
loss and training time per epoch. Also, YOLOv5 requires much less computational
power compared to ResNet-50 [9].
Xiao Zhang detecting diseases on maize leaves with enhanced deep convolu-
tional neural networks. In this research, improved Cifar-10 and GoogleNet models
are provided, and their performance is compared to AlexNet and VGG to achieve
better/more transparent detection of plant diseases. Updated versions of these models
delivered a remarkable accuracy of 98.9%. This research focuses only on detecting
maize leaf disease while our system considers a wide range of plant diseases and
achieves almost similar accuracy [20].
Su, J. suggested multispectral UAV aerial images to monitor wheat yellow rust.
The accuracy of the Random Forest (RF) classiﬁer combined with the multispectral
imaging approach employed in this study to detect wheat illness was 89.3%. Ran-
dom Forest is considered less efﬁcient and performs poorly compared to deep CNN
architectures [14].
This research used pre-trained weights from the popular YOLOv5 model to build
a deep convolutional neural network utilizing the transfer learning methodology.
These additional layers in our suggested model primarily aid in feature extraction
with minimal computational expense. Additionally, adjustments have been made to

Utilizing Deep Convolutional Neural Networks …
205
improve the detection’s accuracy. The dataset for our research shows an image of 11
different types of diseases combined with images of plant leaves. Our method for
recognizing plant diseases is described in the subsection that follows.
3
Methodology
Numerousfeatureshavebeenproposedtoincreasedeepconvolutionalneuralnetwork
(CNN) accuracy. It is necessary to evaluate these feature combinations in practice
on massive datasets and to support the outcome theoretically. In CNN and deep
CNN, every model architecture, dataset, and tasks have some aspects, such as batch,
residual connections, and normalization, which are relevant to ﬁxed models with
speciﬁc issues. Data normalization is achieved by 1NFm, which makes sure that
no items within a group are repeated, every record is distinct, and each entry must
contain only one value for each cell.
3.1
Dataset
There are three categories of plants represented in our research dataset. We have
collected plant disease datasets from the Roboﬂow universe, Kaggle, and articles
from Google Scholar [1, 2, 11]. An image dataset contains images of both healthy
and diseased plants. Different classes of leaves were used to train the proposed model.
A CNN model was trained to learn more about the traits and to be able to determine
between one class and another and their respective health status. 5261 training images
and 1510 validation images of diseased and healthy plants image were used for this
research. Sample statistics of our dataset can be found in Fig.1.
3.2
Image Preprocessing and Labeling
In image preprocessing, the image data needed for images to be classiﬁed is gener-
ated. A method for automating and processing many transactions as a homogeneous
group is batch processing. In this process, large volumes of data must be handled
all at once. Batch processing techniques employ geometric adjustments to images,
such as image rotation, translation, and scaling. We utilize Roboﬂow for labeling
and picture preprocessing on our dataset, which is illustrated in Fig.2.
We have scaled all photos down to a resolution of 416*416 pixels during the
preprocessing processes. It must guarantee that each image has the exact resolution.
We must label or classify images using a keyword search to search them quickly. All
transcribed images were taken out of the dataset during this time.

206
S. Reno et al.
Fig. 1 Samples of image-based dataset for vegetable leaf diseases
3.3
Augmentation Process
Our vegetable leaf diseases prediction dataset is extended using different methods
to add more images. It aids in preventing the issue of overﬁtting during the training
procedure. When we train our dataset, our proposed model learns the data from the
overall pattern of the dataset, and overﬁtting is the issue. Applying speciﬁc modiﬁ-
cations to the images such as rotation, width shift, shear range, height shifting and
horizontal ﬂipping, noise addition, and gray scaling from original image augmen-
tations were carried out. Figure3 illustrates a sample augmentation of the dataset
utilized in our research.
3.4
Disease Classiﬁcation Using YOLOv5
The structure of the developed YOLOv5 model, as shown in Fig.4, was divided into
two parts for this article. A training model is one, while a detection model is another.
5261 images from the dataset of vegetable leaf diseases were applied to the training

Utilizing Deep Convolutional Neural Networks …
207
Fig. 2 Class instances based on vegetable leaf diseases dataset labeling
Fig. 3 Sample augmentation of the image-based dataset

208
S. Reno et al.
model. The detection method analyzed input images from the vegetable leaf disease
dataset and processed a prediction score of eleven classes: corn blight disease, corn
gray leaf spot disease, corn common rust, potato early blight, corn healthy, potato
healthy, potato late blight, tomato early blight rotation, tomato healthy rotation,
tomato late blight rotation, and tomato mosaic virus rotation. The output images
were then provided with their predicted classes and detection value.
YOLO is a quick object detection model. In relation to its size, it performs well
and keeps improving. The most recent version of YOLOv4 is YOLOv5. YOLOv3
is an expansion of the YOLOv5 repository. According to [17], YOLOv5 is faster
than its earlier iterations, YOLOv4 and YOLOv3. YOLOv5 is simple to use, con-
ﬁgure, implement, and test, yet substantial research has been done on it. YOLO is a
real-time object identiﬁcation model that recognizes video and image objects. The
YOLOv5 recognizes and categorizes the images and may ﬁnd several images inside
of one image. The YOLO debuted in 2015 and is extremely fast in real-time object
identiﬁcation.
A use case for which YOLOv5 is intended involves the creation of features from
input images for disease prediction. First off, an image is divided into n × n cells,
wheren >3.Eachcellgeneratesavectorwithdimensionsof#num_anchor_boxes ×
(5 + m). Following that, a prediction system is given these features to create boxes
around objects which include the data (pc, bx, by, bw, h, c1, ..., cm) and determine
their classes. pc represents the likelihood that an item falling into any of the categories
c1, ..., cm is contained within our anticipated bounding box and bx, by, bw, bh rep-
resents its dimensions.
It deﬁnes EfﬁcientNet as the main backbone of deep CNN, the feature networks
BiFPN, and gives feedback with class/box prediction. This is a prediction tool for
vegetable leaf disease that takes an input image, develops and feeds image charac-
teristics through a prediction system, draws bounding boxes around the image, and
predicts the classes.
This object detector combines the class labels from various networks with the
bounding boxes. In Fig.4, three components are illustrated which are necessary for
YOLO Network: the backbone is CSP Darknet, the neck is for PANet, and the head
is for YOLO. Before the data is sent to PANet for feature fusion, it is ﬁrst passed
Fig. 4 Architecture of YOLOv5 EfﬁcientNet

Utilizing Deep Convolutional Neural Networks …
209
Fig. 5 Workﬂow of YOLOv5 model for plant disease prediction
to CSP Darknet for feature extraction. As followed in Fig.5, the YOLOv5 output
results per unit are Class, Score, Position, and Size.
3.5
Performed Tests
To evaluate the performances of the suggested model, we conducted several tests in
various experimental conﬁgurations. The instructions given to the model changed
several network parameters.
The complete dataset has been divided into 20% for validation and 80% for
training. The dataset was then tested using the proposed mode. Some other models
have been implemented using the pre-trained model, like VGG-16 and ResNet-50.
4
Result Analysis
In this deep CNN model, the instruction was given to start the training with the
training dataset, which contained both the original and augmented images. Then, a
validation test was implemented to hypothesize the YOLOv5 model. The proposed
network displays good convergence in the training phases, as seen in Table1.

210
S. Reno et al.
Table 1 Performance matrices of the proposed classiﬁer based on detecting classes/various plant diseases
Metrices
Corn_
Blight_
Disease
Corn_
Common_
Rust
Corn_ Gray_
Leaf_
Spot_Disease
Corn_
Healthy
Potato_
Early_
Blight
Potato_
Healthy
Tomato_
Late_
Blightrota-
tion
Potato_
Late_
Blight
Tomato_
Early_
Blightrota-
tion
Tomato_
Healthyro-
tation
Tomato_
Mosiac_
Virusrota-
tion
Precision
0.823
0.964
0.891
0.989
0.998
0.985
0.895
0.995
0.785
0.857
0.983
Recall
0.664
0.86
0.887
1
1
1
0.887
1
0.833
0.802
0.785
Mean
average
precision
0.795
0.949
0.931
0.995
0.995
0.995
0.932
0.995
0.886
0.88
0.886

Utilizing Deep Convolutional Neural Networks …
211
Like other single-stage object detectors, YOLOv5 was developed with three com-
ponents since it is a single-stage disease detector. The primary purpose of our pro-
posed model backbone is to extract unique characteristics from an input picture. To
extract detailed, informative characteristics from an input picture in YOLOv5, the
Cross Stage Partial (CSP) Networks are dedicated as the backbone.
Precision indicates how many positive classes the model properly predicted is
positive. We divide the number of successfully classiﬁed positive cases by the num-
ber of anticipated positive examples to get the precision value. The equation is
Precision = TP ÷ TP + FP.
Recall measures how well the model foresaw all sorts of positive data. The recall
rateisknownastheproportionofallpositivelyclassiﬁedexamplesthatwerecorrectly
classiﬁed to all positively classiﬁed instances. The equation is Recall = TP ÷ TP +
FN.
WegettheproposedmodelusingYOLOv5-basedprecision–recallresultsinFig.6.
For 200 epochs with batch 40, precision gets 80% above accuracy, and recall gets
90% above accuracy.
In Fig.7, precision vs. conﬁdence represents that for 200 epochs, every image in
our vegetable leaf diseases dataset gets a mean conﬁdence of 1.00 at 0.42 for every
class. Still, precision gets 100% for the maximum class for our dataset. On the other
hand, the YOLOv5-based f1 score versus conﬁdence curve is illustrated using Fig.8.
Comparative and transferable performance measures are necessary to determine
how effective an algorithm or strategy is. Adopting training and testing sets, which
might cause inconsistency in model performance, is the main challenge for evaluating
any approach. The confusion matrix in Fig.9, which includes true-positive (TP), true-
negative (TN), false-positive (FP), and false-negative (FN) values, is the foundation
for the majority of performance indicators. Depending on how the performance
review is conducted, the importance of these components may change.
ResNet-50 makes it possible to train the network on thousands of layers with-
out affecting performance. It is one of the several variations that can operate with
Fig. 6 Validation testing on YOLOv5 model (precision–recall curve)

212
S. Reno et al.
Fig. 7 Validation testing on YOLOv5 model (precision–conﬁdence curve)
Fig. 8 Validation testing on YOLOv5 model (f1–conﬁdence curve)
50 neural network layers. Figure10 represents ResNet-50-based accuracy against
Epoch 100 for training accuracy, training loss, validation accuracy, and validation
loss.
VGG-16 is a convolutional neural network that is 16 layers deep and is considered
the basis of ground-breaking object recognition models. VGG-16-based accuracy
against Epoch 100 for training and validation accuracy is represented in Fig.11.
To compare the networks’ output for the class of leaf diseases, we can refer to the
accuracy and loss curves of both ResNet-50 (Fig.10) and VGG-16 (Fig.11 for the
accuracy curve and Fig.12 for the loss curve). We get the accuracy of 96.57% for
ResNet-50 and 98.03% for VGG-16. To put it another way, both networks routinely
offer accurate classiﬁcations. The categorization accuracy for each image across
all categories may be seen by looking at all the ﬁgures. While VGG-16 predicts
tomato_early_bright_rotation as the top prediction for the class, ResNet-50 essen-

Utilizing Deep Convolutional Neural Networks …
213
Fig. 9 Validation testing on YOLOv5 model (confusion matrix)
Fig. 10 Accuracy and loss
curve (ResNet-50 accuracy
and loss with respect to
training and validation steps)
Fig. 11 Accuracy curve
(VGG-16 accuracy of
training and validation)

214
S. Reno et al.
Fig. 12 Loss curve
(VGG-16 loss of training and
validation)
tially sees potato_late_blight disease as the top prediction. There is still a signiﬁcant
overlap between various categories for other, less common classiﬁcations.
So, after implementing the VGG-16 and ResNet-50 pre-trained model, we
assumed that the VGG-16 model gained the highest accuracy rate. We also see that
losses and convergence time are less than any other pre-trained models.
ResNet-50 has an overall 96% accuracy of detecting the right items in the dataset
of vegetable leaf disease detection, according to a real-time investigation of convo-
lutional neural network performance. The classiﬁcation accuracy for VGG-16 and
our suggested model, respectively, is 98% and 99%. CNN’s performance on photos
varies signiﬁcantly from the outcomes of live testing. CNNs frequently misclassify
a small number of objects during live testing; ResNet-50, for instance, frequently
struggles to distinguish between dogs and deer. In the majority of the scenes, it
recognizes them as horses. The accuracy ﬁndings demonstrate that, in comparison
with all other CNN algorithms, our model performs better and has the best detection
accuracy.
5
Conclusion
In this study, we applied the theory of transfer learning and created an automated
system to identify and categorize 11 illnesses in leaves. Our method can aid farmers
in boosting crop yields and spotting illnesses in their early stages. YOLOv5’s deep
learning model is addressed in our work as the primary model, and ResNet-50 and
VGG-16 are also discussed to compare the results with those of YOLOv5. To ﬁnd
11 distinct types of leaf disease, all algorithms are used. A dataset of 5261 featuring
images of healthy–unhealthy is used to train the YOLOv5 model. The trained model
is tested on images of the diseases: tomato early blight rotation, tomato healthy
rotation, tomato late blight rotation, and tomato mosaic varus rotation. The model has
the highest accuracy, recall, and mAP and has a signiﬁcantly higher recognition rate.

Utilizing Deep Convolutional Neural Networks …
215
To improve production and the quality of the crop, it is crucial in the future work
to identify a disease in a plant when it is in the budding stage. Since disease diagnosis
requires a great deal of skill, it would be beneﬁcial if this system could be put in
place on smartphones so that farmers could take a photo of a leaf and upload it to
the server. The server will automatically recognize and categorize the ailment kind
and transmit the results and recommended medications back to the smartphone. By
implementing the suggested technique on a smart embedded system, this model may
be utilized for real-time object identiﬁcation to help farmers in the agricultural sector
increase crop productivity.
References
1. Bhattarai S (2018) New plant diseases dataset. https://www.kaggle.com/datasets/vipoooool/
new-plant-diseases-dataset
2. Fenu G, Malloci FM (2021) Diamos plant: a dataset for diagnosis and monitoring plant disease.
Agronomy 11(11):2107
3. Fuentes A, Yoon S, Kim SC, Park DS (2017) A robust deep-learning-based detector for real-
time tomato plant diseases and pests recognition. Sensors 17(9):2022
4. Ghazi MM, Yanikoglu B, Aptoula E (2017) Plant identiﬁcation using deep neural networks
via optimization of transfer learning parameters. Neurocomputing 235:228–235
5. Joshi RC, Kaushik M, Dutta MK, Srivastava A, Choudhary N (2021) Virleafnet: automatic
analysis and viral disease diagnosis using deep-learning in vigna mungo plant. Ecolog Inf
61:101197
6. Krizhevsky A, Sutskever I, Hinton GE (2017) Imagenet classiﬁcation with deep convolutional
neural networks. Commun ACM 60(6):84–90
7. Lee SH, Chan CS, Mayo SJ, Remagnino P (2017) How deep learning extracts and learns leaf
features for plant classiﬁcation. Pattern Recogn 71:1–13
8. Lv M, Zhou G, He M, Chen A, Zhang W, Hu Y (2020) Maize leaf disease identiﬁcation based
on feature enhancement and dms-robust alexnet. IEEE Access 8:57952–57966. https://doi.org/
10.1109/ACCESS.2020.2982443
9. Mukti IZ, Biswas D (2019) Transfer learning based plant diseases detection using resnet50.
In: 2019 4th International conference on electrical information and communication technology
(EICT). IEEE, pp 1–6 (2019)
10. Simonyan K, Zisserman A (2014) Very deep convolutional networks for large-scale image
recognition. arXiv preprint arXiv:1409.1556
11. Singh D, Jain N, Jain P, Kayal P, Kumawat S, Batra N (2020) Plantdoc: a dataset for visual
plant disease detection. In: Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, pp
249–253 (2020)
12. Sinha A, Shekhawat RS (2020) Review of image processing approaches for detecting plant
diseases. IET Image Proc 14(8):1427–1439
13. Sladojevic S, Arsenovic M, Anderla A, Culibrk D, Stefanovic D (2016) Deep neural networks
based recognition of plant diseases by leaf image classiﬁcation. Comput Intell Neurosc (2016)
14. Su J, Liu C, Coombes M, Hu X, Wang C, Xu X, Li Q, Guo L, Chen WH (2018) Wheat yellow
rust monitoring by learning from multispectral UAV aerial imagery. Computers and electronics
in agriculture 155:157–166
15. Szegedy C, Liu W, Jia Y, Sermanet P, Reed S, Anguelov D, Erhan D, Vanhoucke V, Rabinovich
A (2015) Going deeper with convolutions. In: Proceedings of the IEEE conference on computer
vision and pattern recognition, pp. 1–9 (2015)

216
S. Reno et al.
16. Tan M, Pang R, Le QV (2020) EfﬁcientDet: scalable and efﬁcient object detection. In: Proceed-
ings of the IEEE/CVF conference on computer vision and pattern recognition, pp 10781–10790
(2020)
17. Thuan D (2021) Evolution of yolo algorithm and yolov5: the state-of-the-art object detention
algorithm
18. Tiwari V, Joshi RC, Dutta MK (2021) Dense convolutional neural networks based multiclass
plant disease detection and classiﬁcation using leaf images. Ecolog Inf 63:101289
19. Yadav S, Sengar N, Singh A, Singh A, Dutta MK (2021) Identiﬁcation of disease using deep
learning and evaluation of bacteriosis in peach leaf. Ecolog Inf 61:101247
20. Zhang X, Qiao Y, Meng F, Fan C, Zhang M (2018) Identiﬁcation of maize leaf diseases using
improved deep convolutional neural networks. IEEE Access 6:30370–30377

Detection of Covid-19 Using an Infrared
Fever Screening System (IFSS) Based
on Deep Learning Technology
V. Muthu and S. Kavitha
Abstract Treatment for the new Coronavirus is both expensive and challenging,
preventing infections may have a signiﬁcant impact on healthcare costs and quality
of life. This research presents a novel paradigm for identifying people displaying
symptoms of COVID-19 infection in public settings, one that makes use of Convolu-
tion Neural Network (CNN) and deep machine learning methods. Infection with the
COVID-19 virus is characterized by a high temperature, or fever. Accordingly, the
goal of this research is to develop a prototype for an automated system that can detect
and isolate COVID-19 carriers in public settings. The study’s suggested prototype
is novel and cutting-edge in many ways: Our system consists of three components:
(1) An Infrared Fever Screening System that automatically detects thermal signals
and measures temperature to check whether an individual has a fever or not; (2) HD
visual/facial auto-calibration system that provides accurate and presides facial land-
marks that help track people and measure their temperature at various regions; (3) A
real-time sensor fusion of visual and thermal camera data that forms a single model
with multiple lidars, racial recognition. The proposed prototype accurately detects
people with temperatures above average, even when an individual has a face mask.
It balances the strengths of different sensors that can detect human body temperature
from facial landmarks such as the forehead and the eyes.
Keywords Convolutional neural network · COVID-19 · Deep learning · Face
detection · Fever screening · Image processing · IR sensor · Thermal imaging
V. Muthu (B) · S. Kavitha
Department of Computing Technologies, SRM Institute of Science and Technology,
Kattankulathur, Tamil Nadu, India
e-mail: muthutech77@gmail.com
S. Kavitha
e-mail: kavithas@srmist.edu.in
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_16
217

218
V. Muthu and S. Kavitha
1
Introduction
Since the outbreak of COVID-19 in 2019 and its spreading into a pandemic, different
governments in different countries have been putting countermeasures in place, such
as quarantine to curb the transmission of this disease. Since fever is a key sign
and symptom of this disease, many temperature sensors and detection systems have
been developed to help identify people with this disease and isolate them from the
uninfected population. Most devices today use non-contact temperature sensors to
detect and measure human temperature to reduce the risk of transmitting Coronavirus
through contact. Nonetheless, technology is also advancing rapidly, and new and
more advanced devices and systems are developed daily. These devices play a critical
role in detecting and controlling the spread of the current COVID-19 pandemic.
This article presents an Infrared Fever Screening System (IFSS) that screens
people with fever in real-time as they do their business in an airport check point. The
proposed prototype uses motion and facial detection technology to automatically
track each individual who enters an airport and screen them for fever [6]. The system
uses automated motion and facial sensor to detect and screen each individual getting
in to the airport checkpoint. This eliminates the need for of an individual having
to stop for their body temperature to be checked or place their hand near a non-
contact temperature detector. It allows free movement of people in an airport and
reduces overcrowding at the checkpoint. It also makes it easier to screen travelers
and reduces the risk of transmitting the Coronavirus among travelers [6]. The system
uses infrared thermography and thermal image processing to capture human facial
images and measure their temperature using the infrared radiation emitted from
different facial regions, such as the forehead and the inner canthus of the eyes.
Figure 1 shows a checkpoint where people need to manually check their temperature
and another checkpoint where people can move freely in an airport checkpoint as
their temperature is measured automatically while maintaining social distance.
Fig. 1 Manual temperature detection (left) versus automated infrared temperature detection (right)

Detection of Covid-19 Using an Infrared Fever Screening System (IFSS) …
219
The proposed automated Infrared Fever Screening System will allow staff at the
airport checkpoint to measure the temperature of their client from a safe distance and
eliminate the need for human intervention. At airport checkpoints, staff deal with
multiple people, bringing a major concern for COVID-19 since the disease can easily
spread from one person to another when in close contact [11, 14]. IFSS eliminates
this problem by taking advantage of the security camera at the airport checkpoint to
perform sensor fusion of thermal and visual data in real-time and in a free movement
of travelers in and out of the airport. The system is also connected to cloud servers that
collect thermal data, analytics processes, and future references. IFSS is an advanced
system based on deep machine learning technology. It offers different beneﬁts and
advantages in the process of curbing the transmission of Coronavirus through air
travel by:
1. Provides a novel screening solution that uses simultaneous techniques to measure
the temperature of multiple travelers in real-time from a distance without human
intervention.
2. Providinganovelsensorfusiontechniquefusesthermalandvisualframes/images
to detect and measure travelers’ temperature at various distances, and even then,
travelers have hats, sunglasses, and masks.
3. Providing a novel screening solution that is safer for travelers and airport staff
at the airport checkpoint reduces the need to come into contact during the
temperature screening process.
2
Background and Challenges
Infrared Fever Screening System (IFSS) is one of the most advanced systems in the
market today, which allows huge organizations with a high trafﬁc ﬂow of people in
and out of the premises to measure temperature and warn when an individual shows
abnormal temperature. The system is designed to identify and locate an individual
with a temperature above a predetermined threshold. According to the Center for
Disease Control and Prevention, an individual with a body temperature above 38 °C
or 100.4 °F is considered to have a fever. The normal skin temperature for a human
being is about 33 °C or 91 °F.
Although the body temperature is not equally distributed, it is possible to measure
the average body temperature from different facial landmarks such as the eyes using
visual and thermal imaging and processing technology. Measuring the human body
temperature through facial screening thermography is one of the most researched
topics today. Most research studies reveal that it is an accurate and effective way
to detect human fever and diseases. Figure 2 shows how an individual can use this
technology to detect and measure human body temperature from different facial
landmarks.
Nonetheless, there are several challenges that IFSS is still yet to address to achieve
its capability to detect and measure human body temperature automatically and in
real-time. First, the reliability of measuring the core temperature of many people

220
V. Muthu and S. Kavitha
Fig. 2 A thermal image with different temperatures in different facial landmarks
simultaneously can be limited since people in a crowded place can occlude each
other [15]. Secondly, people can have to obstruct objects on their faces, such as
masks, glasses, and caps, which can interrupt the input of thermal and visual images
used to measure human body temperature.
2.1
Related Work and Research Gap
Due to the unprecedented COVID-19 pandemic, many researchers and scientists have
become very interested in ﬁnding ways to help the government, organizations, and
individuals adopt and mitigate the risks of getting infected or spreading the virus.
Many studies show that most of the challenges and problems related to COVID-
19 are still not well addressed, and this disease is a problem that will continue to
impact business and human activities now and in the future [4, 7]. The transportation
industry, such as the airport, is most affected by these outbreaks and continuing
pandemics. Most airports use temperature detectors that need human intervention to
screen travelers for potential COVID-19 infection. The approach allows staff at the
checkpoint to accurately detect and identify people with abnormal body temperature
or fever and isolate them from other travelers to reduce the risk of them spreading
COVID-19 if infected.
However, this approach has also been proven impractical due to the high trafﬁc
situation at most airports’ checkpoints. Due to this problem, many researchers have
proposed and recommended using contactless Infrared Fever Screening Systems
integrated with visual and thermal cameras. These systems are also integrated with
data collection applications that produce a dataset from which a machine can learn to
detect and identify people with fever and signs of COVID-19 infection [2, 4]. Tradi-
tionally, thermal-only and optical-thermal detectors can use infrared images to detect
facial features such as eye canthus and measure human body temperature. Machine
learning technology is also critical in providing facial algorithms that help machines
learn and use statistical models to analyze and draw inferences from infrared images.
Through this technology, machines are becoming more accurate in analyzing facial

Detection of Covid-19 Using an Infrared Fever Screening System (IFSS) …
221
infrared images and predicting input data output. Katte et al. [9] reveal that through
open-source datasets, individuals can use machine learning models to train machines
to detect visual images such as facial landmarks and automatically screen people for
COVID-19 in public places.
Although machine learning technology has paved the way for using infrared
imaging and fever screening, making it easier to identify people with COVID-19
in places with high trafﬁc ﬂow, its application has some major limitations. For
instance, an IFSS model based on machine learning has poor transfer learning
ability and limited reusability of the modules. The system relies entirely on human
input to learn, so its performance cannot be guaranteed for consistent accuracy
and precession, especially in a dynamic environment. In general, IFSS based on
machine learning technology and requires a lot of human input and supervision to
learn, which makes it impractical for real-time detection of people infected with
COVID-19 in an environment with a fast trafﬁc ﬂow of people, such as an airport
checkpoint. In contrast, the deep learning model uses artiﬁcial neural networks with
multiple layers of processing data. It allows the machine to automatically adopt and
develop new features for analyzing infrared images to identify individuals infected
with COVID-19 by measuring human body temperature.
Deep learning technology is good for developing practical and affordable modali-
ties and techniques for COVID-19 diagnosis [10]. He also suggests that through arti-
ﬁcial intelligence, an individual enhances image character and improves the accuracy
and capability of the machine in anticipating the COVID-19 virus. He studies how
different deep learning models are. He reveals that deep learning techniques that use
conventional neural networks to train and detect COVID-19 outperform traditional
techniques that use other methods such as machine learning [5]. Suggest that deep
learning techniques can assist computers in analyzing lungs ultrasound imagery and
enablescreeningtoolstodiagnosepeopleforCOVID-19virus.Theresearchersinthis
study reveal that a screening system based on deep learning can detect the COVID-19
virus using ultrasound data with a signiﬁcantly high level of accuracy and consistency
[3]. My proposed an automated deep learning-based classiﬁcation model based on
convolutional neural network (CNN) [1] and conducted a study to test its efﬁciency.
The result of the study shows that the proposed model produced the highest accuracy
in classiﬁcation and identiﬁcation of the symptoms of COVID-19 from X-ray images
than other existing models. All these studies show a screening system based on deep
learning technology. CNN has a high potential to accurately classify and identify
a symptom of COVID-19 from X-ray and CTR images/pictures. However, none of
this study focuses on how a screening system based on deep learning technology and
CNN can use facial thermal images to identify symptoms and detect COVID-19.

222
V. Muthu and S. Kavitha
2.2
Overview of the Proposed IFSS Based on the Deep
Learning Model
The proposed Infrared Fever Screening System in this article is designed to operate
in a free-ﬂow manner where people are not required to stop or pause as they enter the
airport checkpoint for their temperature to be checked. It also does not require the
staff at the check port to contact the travelers to ensure they measure their temper-
ature. Instead, it has a motion sensor that detects humans moving in and out of the
checkpoint section and a thermal sensor that automatically measures the tempera-
ture of each person at the checkpoint and provides their temperature on a screen. The
major aspect of this system is that it is countless and hence increases the safety of the
staff at the checkpoint. It also works in real-time and can measure the temperature of
many individuals simultaneously, allowing an airport to save time at the checkpoint.
Figure 3 shows a setup of the deployment of the IFSS system at an airport check-
point. The image on the left shows how the IFSS system can be integrated into the
CCTV security system to form a 2 in 1 system that can measure the temperature of
travelers automatically while recording the camera security footage. The camera is
located at a designated point where it can detect their motion, capture their facial
image and measure their temperature automatically when people enter the entrance.
It also has wide ﬁelds of view, allowing the system to capture many people simulta-
neously, even in motion [15]. After capturing and processing the visual and thermal
images, the system displays the data on the screen, where an operator can evaluate
and monitor each individual. Suppose the system detects an individual among the
crowd has a fever or abnormal temperature. In that case, it identiﬁes that individual
through a facial recognition sensor which helps the staff monitor the screen to isolate
them from the crowd for further assessment.
The proposed IFSS work similarly to the CCTV system, where people suspected
of having COVID-19 are requested to step aside where the ﬁnal assessment is done
by a healthcare professional with proper personal protective equipment. This makes
it easier to control and maintain physical contact between the checkpoint staff and
travelers since the screening process is done automatically and with minimum need
for close contact [15]. In addition, the entire process can be controlled from a central
Fig. 3 IFSS deployment

Detection of Covid-19 Using an Infrared Fever Screening System (IFSS) …
223
room where the operator at the checkpoint can request an individual to step aside
from the crowd using audio speakers without coming in contact with the travelers.
3
IFSS Convolution Neural Network (CNN) Design
The proposed IFSS system in this study is based on CNN, which forms the entire
model’s primary architecture components. The system consists of multiple layers
with different functions that classify the visual and thermal images as input data and
then process it to provide the screening data for each individual as output [12].
3.1
Convolutional
The system extracts feature from the input images through a convolution process
that involves ﬁltering and feature mapping to learn and produce output data. It has
a kernel that uses the matrix number processes over the input images to transform
images into a feature map [12].
The subsequent feature maps are computed through O[m, n] = (1 ∗F)[m, n] =
  F[i, j]I[m + i, n + j) as the general formula, and in this formula I denotes
the Input Image. F denotes the kernel while the indexes (m, n) are the rows and
column, respectively, and (m * n) denote the dimension or pixel of the ﬁlters [13].
The convolution process also uses a nonlinear operation to eliminate negative pixel
values based on the ReLu activation function. Background Subtraction’s schematic
diagram is shown in Fig. 4.
3.2
Pooling Layers
Generally, a pooling layer is a subsequent layer after the convolutional layer that
reduces the feature maps’ dimensions, allowing the machine to automatically learn
different computations in the network. The proposed IFSS system in this study uses
this layer after the nonlinear ReLu activation function to summarize the features
present in the region of the feature map generated by the convolution layer [16].
There are three types of pooling layers: max pooling, average pooling, and global
pooling. Max pooling is a pooling layer and an operation in CNN that selects the
maximum element from the region of the feature map in a ﬁlter. This operation allows
a CNN-based system to produce a feature map that contains prominent features of
the feature map from the convolutional layer. Unlike the max pooling operation,
the average pooling operation provides the average feature present in a respective
patch. The global pooling operation, on the other hand, reduces each operation in a
CNN-based system to a single value.

224
V. Muthu and S. Kavitha
Fig. 4 Schematic diagram of background subtraction
3.3
Fully Connected Layer
The output from the pooling layer becomes the input for the full connected layer,
which forms a feed-forward network and the last pooling layer of the convolutional
layer. IT is a three-dimensional matrix based on an artiﬁcial neural network that
performs the same mathematical operations. In the proposed IFSS system, the artiﬁ-
cial neural network computes the g(Wx + b) calculation in each layer. In this calcu-
lation, X is the input vector with dimension [p_1, 1], and W is the weight matrix
with dimensions [p_l, n_l], where p_l is the value of neurons in the previous layer
and n_l is the value of neuron in the current layer [8]. The initial b is the bias vector
with dimension [p_l, 1], and g is the activation function base on the ReLu activa-
tion function. This calculation helps the system to predict the classiﬁcation of the
visual and thermal images and produce based on the interconnected neurons of the
feature map [8]. The system also uses extensive thermal data images, which form the
pre-trained network that the system learns from, and mask the features in the input

Detection of Covid-19 Using an Infrared Fever Screening System (IFSS) …
225
Fig. 5 Schematic diagram of CNN
patch to detect human temperature based on the thermal video frames. In general,
the above-stated work provides a signiﬁcant result which depicts that the proposed
system in this study has a chance to provide reliable and valid results. Figure 5 shows
a schematic diagram that outlines CNN’s building block.
4
Experimental Setup, Methodology, and Result
The proposed system uses visual and thermal data as the input frames fed to the
CNN for feature mapping, extraction, and pooling processes. The study also intro-
duces a traditional-handheld-contact-thermometer with manual measurement. It then
collects the result of each system to evaluate the effectiveness of the proposed system
compared to the existing system in most airports today.
The researcher in this study assumes that since the proposed system uses advanced
technology, it will be more accurate and highly efﬁcient in detecting travelers with
COVID-19 [7]. For experimental purposes, the study has two datasets, PRODUC-
TION A and PRODUCTION B, as shown in Table 1. All the two datasets are in the
same lab and the same environment. The same entrance is used for the screening
process, and at the same time way two service desks are provided for the screening
process.
One desk uses the traditional-handheld-contact-thermometer, and the other uses
the Infrared Fever Screening and contactless system. The total number of people
screened, both those with a fever and those without a fever, is recorded as shown in
Table 1 Dataset used in the experiment
Dataset
Number of traveler’s
screened with negative
results
Number of traveler’s
screened with positive
results
Total
Time take for the
screening process (h)
Production A
270
20
290
12
Production B
520
50
578
12

226
V. Muthu and S. Kavitha
0
200
400
600
800
TradiƟonal hand
held contact
thermometer
Infrared fever
screening
contactless system
Infected Travellers
non-infected travellers
Total number of
travellers screened
Fig. 6 Efﬁciency of the traditional-handheld-contact-thermometer versus infrared screening
contactless screening system
Table 2 Infrared Fever Screening System verse traditional-handheld-contact-thermometer
Comparative feature
Traditional-handheld-contact-thermometer
Infrared fever screening
system (IFSS)
1. Application
Manual
Automated
2. Accuracy
Moderate
Moderate
3. Speed
Low
High
4. Effectiveness
Low
High
Table one below. The traditional-handheld-contact-thermometer uses the PRODUC-
TION A dataset, while the Infrared Fever Screening and contactless system use the
PRODUCTION B dataset. Both systems use a thermal sensor for the screening
process, and we assume the result of each system is accurate. Efﬁciency of
the traditional-handheld-contact-thermometer versus Infrared Screening contactless
screening system is shown in Fig. 6.
Comparative Analysis
When the research compared the proposed Infrared Fever Screening System (IFSS)
against the Traditional-handheld-contact-thermometer (the Traditional-handheld-
contact-thermometer is identiﬁed as the existing system in this case) the results
were as shown in Table 2. This analysis reveals that the ISS system was better than
the traditional-handheld-contact-thermometer in terms of application, speed, and
effectiveness. Unlike the existing model the proposed model is automated which
eliminates the need for physical human intervention. The deep learning technology,
embedded in the system also allow it to perform computations processes faster and
more effectively than the existing system.
5
Discussion
Research studies have been carried out to support the perspective that the proposed
model can be implemented in places with a high trafﬁc ﬂow of people, like

Detection of Covid-19 Using an Infrared Fever Screening System (IFSS) …
227
airport checkpoints. The result of the deployed experimental system reveals that
implementing the proposed Infrared Fever Screening System in an airport check-
point can reduce the risk of spreading COVID-19 by detecting infected travelers
and isolating them from no-infected travelers [4]. It also can provide a safer
system for the airport checkpoint to screen travelers for COVID-19. The proposed
system can detect COVID-19 using a thermal sensor more effectively than the
traditional-handheld-thermometer with a thermal sensor.
The CNN in the proposed IFSS system, is based on multiclass layers with subse-
quent feature maps and mathematical algorithms achieved through visual and thermal
sensors to measure human temperature and detect people infected with Coron-
avirus automatically. The trained network automatically screens fever in real-time by
displaying the human body temperature based on the predetermined threshold and
alerting the staff at the checkpoint of individuals suspected of being infected with the
Coronavirus. It combines the security system with the thermal camera hence provide
better uses the resources at the airport checkpoint. The experiments also show that
one individual can perform security and screening roles simultaneously using the
same screen display.
6
Conclusion
The purpose of this study was to conduct an experimental study to determine the
effectiveness of the proposed Infrared Fever Screening System (IFSS) as compared
to the traditional-handheld-thermometer. The result reveals that proposed model,
Infrared Fever Screening System (IFSS), is a more effective system for has the
potential to screen human body temperature automatically and simultaneously. It
requires less human intervention and allow check point ofﬁcer to carry out their
tasks at a safer instance which reduce risk of infection. The automated technology
in the propose system also increase the speed at which travelers get screened at the
airport checkpoint which reduce the risk of overcrowding by allow individuals to
move freely without the need of queuing and waiting to screened. The IFSS model
also has moderate rate of accuracy which although not high, is signiﬁcant given that
IFSS model has more advantages over the traditional-handheld-thermometer.
References
1. Aishwarya T, Ravi Kumar V (2021) Machine learning and deep learning approaches to analyze
and detect COVID-19: a review. SN Comput Sci 2(3):1–9
2. Ahn S (2016) Deep learning architectures and applications. J Intell Inf Syst 22(2):127–142
3. Akter S, Shamrat FJM, Chakraborty S, Karim A, Azam S (2021) COVID-19 detection using
deep learning algorithm on chest X-ray images. Biology 10(11):1174
4. Brzezinski RY, Rabin N, Lewis N, Peled R, Kerpel A, Tsur AM et al (2021) Automated
processing of thermal imaging to detect COVID-19. Sci Rep 11(1):1–10

228
V. Muthu and S. Kavitha
5. Diaz-Escobar J, Ordóñez-Guillén NE, Villarreal-Reyes S, Galaviz-Mosqueda A, Kober V,
Rivera-Rodriguez R, Rizk JEL (2021) Deep-learning-based detection of COVID-19 using lung
ultrasound imagery. PLoS ONE 16(8):e0255886
6. Ghassemi P, Pfefer TJ, Casamento JP, Simpson R, Wang Q (2018) Best practices for standard-
ized performance testing of infrared thermographs intended for fever screening. PLoS ONE
13(9):e0203302
7. Grewe L, Choudhary S, Gallegos E, Jain DP, Aguilera P (2021, May) Low-resolution infrared
temperature analysis for disease situation awareness via machine learning on a mobile platform.
In: Signal processing, sensor/information fusion, and target recognition XXX, vol 11756. SPIE,
pp 287–299
8. Huang C, Fan J, Li W, Chen X, Zhu Q (2019) Reach reachability analysis of neural-network
controlled systems. ACM Trans Embed Comput Syst (TECS) 18(5s):1–22
9. Katte P, Kakileti ST, Madhu HJ, Manjunath G (2022) Automated thermal screening for COVID-
19 using machine learning. arXiv preprint arXiv:2203.14128
10. Kumar M, Atalla S, Almuraqab N, Moonesar IA (2022) Detection of COVID-19 using deep
learning techniques and cost effectiveness evaluation: a survey. Front Artif Intell 5
11. Martinez-Jimenez MA, Loza-Gonzalez VM, Kolosovas-Machuca ES, Yanes-Lane ME,
Ramirez-GarciaLuna AS, Ramirez-GarciaLuna JL (2021) Diagnostic accuracy of infrared
thermal imaging for detecting COVID-19 infection in minimally symptomatic patients. Eur J
Clin Invest 51(3):e13474
12. Müller D, Ehlen A, Valeske B (2021) Convolutional neural networks for semantic segmentation
as a tool for multiclass face analysis in thermal infrared. J Nondestr Eval 40(1):1–10
13. Peddinti B, Shaikh A, Bhavya KR, Nithin Kumar KC (2021) Framework for real-time detection
and Identiﬁcation of possible patients of COVID-19 in public places. Biomed Signal Process
Control 68, 102605
14. Pool R (2022) Flying in the COVID-19 era: science-based risk assessments and mitigation
strategies on the ground and air. In: Proceedings of a workshop
15. Tan YH, Teo CW, Ong E, Tan LB, Soo MJ (2004, April) Development and deployment of
infrared fever screening systems. In: Thermosense XXVI, vol 5405. SPIE, pp 68–78
16. Zulkiﬂey MA, Abdani SR, Zulkiﬂey NH (2020) COVID-19 screening using a lightweight
convolutional neural network with generative adversarial network data augmentation.
Symmetry 12(9):1530

Improving the Power Quality of Wind
Turbines Under Unbalance Voltage
Conditions Using the SMC Approach
B. Hariprasad, G. Sreenivasan, D. Mahesh Kumar, and T. Lakshmi Swapna
Abstract At the moment, one of wind energy’s most challenging problems is grid
integration. The technical speciﬁcations for wind turbines vary, and they must be
connected to networks with various voltage disturbances, such as voltage imbal-
ances and harmonics. Additionally, the standards have a limit on how much total
harmonic current the wind turbine can introduce into the grid. Variable speed turbines
frequently use doubly fed induction generators (DFIG). However, one issue with
DFIGs is that they are very sensitive to changes in grid voltage. Wind turbine output
quality can be decreased and DFIG parameters can change as a result of even slight
changes in grid voltage, which can result in signiﬁcant increases in stator and rotor
currents. Wind turbines have historically been shielded from voltage ﬂuctuations
using a variety of techniques. Stem channels are one of the most popular techniques.
However,DFIGsconsumeasigniﬁcantamountofreactivepowerduringgridoutages,
and the resulting blocking circuitry exacerbates the issue. Numerous control strate-
gies have been put forth in compiled works to successfully control the grid side
(GSC), rotor side (RSC) controllers of DFIGs and improve the power quality.
Keywords Wind turbine · Power quality · Unbalanced voltage · Integral terminal
sliding mode control
1
Introduction
Wind is a popular renewable energy resource of power that has lesser impact on
environment compared to burning of fossil fuels. But the wind energy penetration
into the grid network is the main problem with this wind energy. Though there are
many disturbances like harmonics and unbalances, the wind turbines are needed to
cooperate with technical essentials during such conditions to suppress the bad effects
B. Hariprasad (B) · G. Sreenivasan · D. Mahesh Kumar · T. Lakshmi Swapna
Research scholar, Department of Electrical & Electronics Engineering, JNTUA, Anantapuramu,
Anathapur, A.P., India
e-mail: vanoorhari@gmail.com
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_17
229

230
B. Hariprasad et al.
and remain connected to the grid. Furthermore, the harmonic current injected by wind
turbine into the grid is limited by the standard value [1–3].
Generally, in variable speed wind turbines, DFIG are used. The problem with
DFIG’s is that they are sensitive to voltage ﬂuctuations, for instance though there are
slight grid voltage variations cause increase in rotor and stator currents which lead to
damage of converters of DFIG and the power quality of wind turbine output power
worsens. For the protection of the wind turbines from variations of voltage, several
approaches were proposed and used. Among several approaches crowbar circuits are
most commonly used. But these circuits rise the problem of absorption of reactive
power during faults. To reduce the voltage sag problems Series dynamic resistors
(SDR) were used. But SDR reduces the ability of DFIG’s reactive power supply to
grid.Thoughdynamicvoltagerestorers(DVR)andseriesgridsideconverters(SGSC)
are able to mitigate voltage unbalances, these requires extra energy storage equipment
which increases the capital outlay. To control DFIGs the grid side converters (GSC)
and rotor side converters (RSC) and to reduce voltage unbalances of grid several
approaches are introduced. Generally normal PI controllers are used to mitigate sag
and to control RSC, GSC. But these PI controllers cannot provide robustness to
parametric variation and external disturbances.
Sliding mode control (SMC) of ﬁrst order for DFIG wind turbine (WT) was devel-
oped in. To DFIG wind generator connected to the microgrid for regulation of voltage
a sliding mode controller is explained in. But this standard SMC high-frequency
switching phenomenon, that in return is capable of exciting unmodeled dynamics
of system, overheating the DFIG and lead to mechanical parts damage. Conven-
tional SMC convergence time of system dynamics is not ﬁnite. Integral terminal
sliding mode control (TSMC) approach was designed for DFIG grid side converter.
But TSMC is not effective because of singularity problem. To overcome this singu-
larity problem ITSMC approaches are proposed instead. For tuning of parameters of
ITSMC controller automatically so as to achieve self-adaption a fuzzy controller is
used Your contribution should be prepared in Microsoft Word.
2
DFIG-Based Wınd Turbıne Modeling
DFIGs are mainly employed in the variable speed wind turbine applications. DFIG-
based wind turbine (WT) connected to microgrid is represented diagrammatically
as shown in Fig. 1. Here RSC and GSC are connected with a coupling capacitor
in between them. The RSC and GSC are done separately with different controllers
each.

Improving the Power Quality of Wind Turbines Under Unbalance …
231
Fig. 1 DFIG-based wind turbine schematic diagram
2.1
RSC Modeling
The state space model representation is made by assuming the system as systematic
and balanced one in a synchronously rotating frame. DFIG of the state space model
is rotating in d–q frame [4] is given by:
˙X = f (x, t) + g(x, t)
(1)
where
f (x, t) = −Rr
σ L2r

σ Lrir,d + MVs,q
ωsLs

+ Rr Mϕs,q
Ls

σ L2r
 + ωr
σ Ls

σ Lrir,d + MVs,q
ωsLs

and
g(x, t) =

1
σ Lr
0
0
1
σ Lr

here Lr and Rr rotor inductance and resistance, Ls is inductance of stator, M is
mutual inductance, ωs is synchronous speed, ird and irq are rotor currents in d, q axis,
respectively, ϕs,d and ϕs,q are stator ﬂux in d, q axis, respectively, V s,d and V s,q are
stator voltage in d, q axis, respectively.
2.2
GSC Modeling
GSCs are generally involved in maintaining the DFIGs of DC link voltage and mini-
mizing the total reactive power and active power oscillations and supplied to the grid.
Hence because of above mentioned reasons there should be proper GSC controlling in
order to provide ﬁxed DC voltage and improve quality of wind turbine power output
under grid unbalanced conditions. The modeling of GSC in decoupling scheme is as

232
B. Hariprasad et al.
follows:
dig,q
dt
= 1
Lg

Vs,q −Rgig,q + ωsLgig,d

−1
Lg
Vg,q
(2)
where ig,d and ig,q are grid current parts in d, q axis, respectively, Rg, Lg are GSC
resistance and inductance, V g,d and V g,q are grid voltage components in d, q axis,
respectively, ωs is synchronous speed of DFIG.
2.3
ITSMC Design for GSC and RSC
ITSMC design for GSC and RSC The grid and rotor side currents are transformed
into d–q frame as d–q components of currents sk,j. Now the tracking errors of the d,
q components of the grid and rotor side currents sk,j are calculated as follows:
˙sk, j(t) = ˙ik, j-ref −˙ik, j
(3)
where Sk,j-ref, j = d, q; k = r, g are the reference values of d, q components for the
rotor side current and grid side current. Since the operation of converter is in d, q
frame [4] model. Therefore for this reason the stator and rotor currents are divided
into real power part which is called d component and a reactive power part which is
called q component. The difference between actual value of real power of generator
and reference value set by speed of wind is given to the controller. This difference
value is used to produce ir,d-ref, i.e., d component of rotor current reference value.
In the same way, the difference between actual value of reactive power of generator
and reference value (generally zero) is given to the controller. This difference value
is used to produce ir,q-ref, i.e., q component of rotor current reference value. The rotor
current Sk,j are given as follows:
Sk, j = sk, j + β1,k, je1,k, jsk, j + β2,k, j

s2
k, j
−αkSk, je−λkt
(4)
where αk, λk, β1,k, j, and β2,k, j are positive constants.
Fuzzy Logic Controller
Fuzzy logic is multivalued logic that logically allows for any real number between 0
and 1, inclusive, as the true value of each variable. The idea of partial truth, where the
truth value can range from completely true to completely false, is accommodated by
it. In contrast, in Boolean logic, variables can only have one of two possible integer
values 0 or 1. LotﬁZadeh coined the phrase fuzzy logic in 1998 [5]. Fuzzy logic,
but primarily Lukasiewicz and Tarski since the 1920s as Finite Value Logic. False
reasoning is based on the idea that people tend to base their decisions on vague,
non-statistical information. A mathematical method for representing ambiguous and

Improving the Power Quality of Wind Turbines Under Unbalance …
233
imprecise data is to use fuzzy models or sets. These models can recognize, represent,
control, and interpret.
Classical logic only allows true or false conclusions. However, there are also ideas
with variable responses, such as when a group of people is asked to identify a color.
In such cases, when the sample responses are plotted on a spectrum, the truth is the
result of a judgment based on inaccurate or partial knowledge [6]. Both the truth
level and the probability range from 0 to 1.
The base program can reference various dynamic components. For example, a
temperature gauge for antilock brakes may have several different member functions
that specify the speciﬁc temperature required to operate the brakes correctly. The
same temperature value is set by each function to a truth value between 0 and 1. To
decide how to manage the fruit, one can use this truth value. A method for expressing
uncertainty is offered by fuzzy set theory [7, 8].
Fuzzy logic works utilizing fuzzy set theory, in which a variable is individual from
at least one sets. Every variable is characterized with a degree of membership. This
fuzzy logic licenses us to imitate the human psyche thinking measure in PCs, uncer-
tain data evaluation, settle on choice dependent on dubious and deﬁcient information,
yet by applying a “defuzziﬁcation” measure, come to clear end results.
The FLC mainly consists of three blocks.
• Fuzziﬁcation
• Inference mechanism
• Defuzziﬁcation.
Fuzziﬁcation
There are two ways in changing a crisp set into fuzzy set.
Support fuzziﬁcation method:
The equation shown below,
A = μ1q(x1) + μ2q(x2) + · · · + μnq(xn)
(5)
Here q (xi) is part of fuzziﬁcation
fully set q(xi).
Grade fuzziﬁcation method:
In this μi is a fuzzy set, xi is constant.
Defuzziﬁcation
Inference gives the fussy set as output. This fuzzy output must be converted to
the crisp set. This method of conversion is called defuzziﬁcation. The methods of
defuzziﬁcation are.
The Max criterion method:
It gives the point where the membership control action arrives at a peak point.
The height method:
The average of each centroid, weighted by height, is used to calculate the ﬁnal
Lo, which is expressed as follows:

234
B. Hariprasad et al.
Lo =
	n
i=1 uiμ(ui)
	n
i=1 μ(ui)
(6)
Centroid method or Center of Area method (COA):
This method is widely used. In this method the centroid of the area formed by the
membership function is given as fuzzy output.
Y =

μy(y)ydy

μy(y)dy
(7)
Fuzzy logic-based ITSMC
The RSC and GSC of DFIG is controlled using ITSMC. This ITSMC control block
parameters are to be chosen carefully and they are required to be auto tuned according
to system status. This auto tuning helps in timely control of system under severe
disturbances thereby avoiding the aggregation of system deterioration. For tuning
of the ITSMC controller parameters automatically and to ensure self-adaptation, a
FLC is used. The parameters of the ITSMC controller ηi, i = 1 to 8 (β1,k,j, β2,k,j)
were adjusted and tuned by 	ηi as illustrated in Fig. 2. The controller parameters
are corrected by using the errors of the d–q components of the rotor currents (Sdq).
The adjusted variables are estimated and tuned as follows:
Tuned Variable = ηi + 	ηi,
i = 1, . . . , 8
The fuzzy structure used to control ITSMC consists of two inputs and one output.
Here the input 1 is sj, input 2 is 	s j, and output is 	ηi. The fuzzy inference
system used here is MAMDANI as shown in Fig. 3. Here the centroid method of
defuzziﬁcation is used (Fig. 4).
The fuzzy logic controller [9–11] inputs sj, 	s j, and output 	ηi and their
membership functions are illustrated in Figs. 5, 6 and 7, respectively.
This membership function has seven segments. They are large positive (PB),
medium positive (PM), small positive (PS), zero (ZE), small negative (NS), medium
negative (NM), and large negative (NB). It is shown in Table 1.
Fig. 2 Block diagram of fuzzy logic controller

Improving the Power Quality of Wind Turbines Under Unbalance …
235
Fig. 3 Block diagram of fuzzy approach
Fig. 4 Fuzzy logic structure
In this we are using 49 fuzzy rules to implement the ITSMC controller in the
DFIG wind turbine. Some of the rules used in the simulation results are shown in
Table 1.

236
B. Hariprasad et al.
Fig. 5 Input 1 sj
Fig. 6 Input 2 	s j
Fig. 7 Output 	ηi

Improving the Power Quality of Wind Turbines Under Unbalance …
237
Table 1 Control rules for 	ηi
S
PB
PM
PS
ZE
NS
NM
NB
	S
PB
NB
NB
NM
NM
NM
ZE
ZE
PM
PB
PB
PM
PS
PS
ZE
ZE
PS
PB
PM
PS
PS
ZE
NS
NM
ZE
PM
PM
PS
ZE
NS
NM
NM
NS
PS
PS
ZE
NS
NS
NM
NB
NM
ZE
ZE
NS
NS
NM
NB
NB
NB
ZE
ZE
NS
NM
NM
NB
NB
3
Simulation Results
The topography of a DFIG-based wind turbine (WT) connected to the microgrid is
describedinITSMCcontrolledsystemofDFIGconnectedtomicrogridisrepresented
diagrammatically as shown in Fig. 8. The wind turbine parameters considered are
tabulated in Table 2.
Performance evaluation of fuzzy controller-based ITSMC approach (Fig. 9)
Fig. 8 Performance evaluation of fuzzy based

238
B. Hariprasad et al.
Table 2 Parameters of DFIG
Parameter
Range
Power
4.5 MW
Voltage
575 V
Frequency
60 Hz
Rs/Ls/M
0.00706 (pu)/0.171 (pu)/2.6 (pu)
Lr/Rr
0.156 (pu)/0.005 (pu)
Lg/Rg
0.0622 (mH)/0.1732 (m
)
DC link voltage
1200 V
Dc link capacitor
0.03 F
Fig. 9 Simulink block diagram of DFIG-based WT connected to microgrid
Performance evaluation of Robustness to parametric variations: In this section testing
and comparing the performance of the DFIG under fuzzy-based ITSMC, SSMC
approaches due to parametric variations was made. The rotor, stator inductance and
resistance values of DFIG were allowed to a 20% increase in their corresponding
original values already given in Table 2. The variations in DFIG’s voltage of DC link
and real power due to parameter variations are compared. In Fig. 10a–b comparisons
are made among normal parameters, fuzzy-based ITSMC due to parametric varia-
tion. In Fig. 11a–b comparisons are made among normal parameters, SSMC due to
parametric variation.
From Fig. 10a when 20% parametric variations are made in DFIG in wind turbine
the variations in electromagnetic torque between normal and when parametric vari-
ations occur the limits of variations are within the limit in the fuzzy-based ITSMC
approach like variations are within small limits. So if small variations are occur in
the parameters of DFIG we don’t need to disconnect the wind turbine from the grid
since the variations are within the limit.
From Fig. 10b when 20% parametric variations are made in DFIG in wind turbine
the variations in DC link voltage which is the output this variations between normal

Improving the Power Quality of Wind Turbines Under Unbalance …
239
Fig. 10 a Comparison between the normal and parametric variations of electromagnetic torque
using fuzzy-based ITSMC. b Comparison between the normal and parameter variations of DC link
voltage while using fuzzy-based ITSMC controller
and when parametric variations occur the limits of variations are within the limit in
the fuzzy-based ITSMC approach like variations are within small limits. So if small
variations are occur in the parameters of DFIG we don’t need to remove the wind
turbine from the grid since the variations are within the limit.
When we done the parameter variations in the SSMC controller by 20% variations
in the DFIG wind turbine parameters the variations of electromagnetic torque and the
DC link voltages are not in acceptable limit so that the converters which are present
near to the wind turbine may get damage. So we need to disconnect the wind turbine
from the grid it may causes the interruption of power generation in the grid and also
causes the failure of DFIG.
In Fig. 11a the variations are occurred in the electromagnetic torque due to 20%
parametric variations in the DFIG when we compare this two cases in SSMC the
variations between the normal and SSMC controller in parametric variations the
limits of electromagnetic torque are not within the acceptable limits so it is not
suitable to continuously connecting the DFIG to the grid, so we need to disconnect
from the grid while we are using the SSMC controller.

240
B. Hariprasad et al.
Fig. 11 a Comparison between the normal and parameter variations of electromagnetic torque
while using SSMC controller. b Comparison between the normal and parameter variations of DC
link voltage while using SSMC controller
Similarly in Fig. 11b the variations are occurred in the DC link voltage due to
20% parametric variations in the DFIG when we compare this two cases in SSMC
the variations between the normal and SSMC controller in parametric variations the
limits of DC link voltage are not within the acceptable limits so it is not suitable to
continuously connecting the DFIG to the grid, so we need to disconnect from the
grid while we are using the SSMC controller.
4
Conclusion
To improve the power quality of wind turbines under unbalance voltage conditions, an
integrated ﬁnal sliding mode controller design is presented. The design combines the
interferometers’ evaluation capabilities with the integrated sliding mode controller of
the terminal’s robustness, quick response, and short-term high-resolution properties.
Both RSC and GSC have successfully used DFIG-based wind turbines. A fuzzy logic
technique is used to automatically set the controller gain. Performance was assessed

Improving the Power Quality of Wind Turbines Under Unbalance …
241
in a variety of settings, including those with a signiﬁcant voltage drop. Its dynamic
response was contrasted with an ordinary SMC’s. Results from performance analysis
and simulation demonstrated that it can maintain electromagnetic pairs, active power,
currents, and DC link voltages within acceptable bounds even under the most extreme
unbalanced voltage conditions.
References
1. Ackermann ST, Morthorst PE (2005) Economic aspects of wind power in power systems. In:
Wind power in power systems, p 383
2. Tsili M, Papathanassiou S (2009) A review of grid code technical requirements for wind farms.
IET Renew Power Gener 3(3):308–332
3. Yao J, Li H, Chen Z, Xia X, Chen X, Li Q, Liao Y (2013) Enhanced control of a DFIG-based
wind-power generation system with series grid-side converter under unbalanced grid voltage
conditions. IEEE Trans Power Electron 28(7):3167–3181
4. Hariprasad B, Bharat Kumar P, Sujatha P, Sreenivasan G (2021) A novel adaptive rule-based
ıslanding detection technique for voltage source ınverter-based distribution generation. J Green
Eng (JGE) 11:511–529. Online ISSN: 1904-4720
5. Seman S, Niiranen J, Arkkio A (2006) Ride-through analysis of doubly fed induction
wind-power generator under unsymmetrical network disturbance. IEEE Trans Power Syst
21(4):1782–1789
6. Hariprasad B, Bharat Kumar P, Sujatha P, Sreenivasan G (2022) Island detection ın ınverter
based distributed generation using a hybrid method. In: Second international conference on
artiﬁcial intelligence and smart energy (ICAIS-2022). IEEE Xplore. Part number: CFP22OAB-
ART; ISBN: 978-1-6654-0052-7; https://doi.org/10.1109/ICAIS53314.2022.9742815
7. Zhang S, Tseng K, Choi SS, Nguyen TD, Yao DL (2012) Advanced control of series voltage
compensation to enhance wind turbine ride through. EEE Trans Power Electron 27(2):763–772
8. Mohod SW, Aware MV (2010) A STATCOM-control scheme for grid connected wind energy
system for power quality improvement. IEEE Syst J 4(3):346–352
9. Hariprasad B, Bharat Kumar P, Sujatha P, Sreenivasan G (2022) Review of ıslanding detection
methods for distribution generation. In: International conference on breakthrough in heuristics
and reciprocation of advanced technologies, BHARAT 2022. IEEE Xplore. ISBN: 978-1-6654-
3626-7; https://doi.org/10.1109/BHARAT53139.2022.00029
10. Edrah M, Lo KL, Anaya-Lara O (2015) Impacts of high penetration of DFIG wind turbines on
rotor angle stability of power systems. IEEE Trans Sustain Energy 6(3):759–766
11. Hariprasad B, Bharat Kumar P, Sujatha P, Sreenivasan G (2022) A novel hybrid (active &
passive) islanding detection method for distributed generation. Int Trans J Eng Manag Appl
Sci Technol 13(9):1–16. https://doi.org/10.14456/ITJEMAST.2022.174

NAML—A Novel Approach of Machine
Learning Implementation
in the Hospitality Industry
C. S. Ashwin, Sheela Thavasi, and K. R. Rangarajan
Abstract Machine learning has been utilized for the improvement of consumer
experience, operational analytics, and revenue management in the hospitality
industry. The paper discusses the use of ML in engaging the customers in the industry.
ML also improves the ways people make decisions in the hospitality industry.
Keywords Machine learning · Hospitality · Algorithms · Automation
1
Introduction
The hospitality industry is moving continuously. Not many industries are as customer
centric as the hospitality industry, with all types of businesses trying to develop a
valuable journey for customers from beginning to end. The utilization of machine
learning has the capability of transforming the hospitality industry. Harnessing the
power of machine learning via data science platforms assists in creating a more
personalized view of all customers that support associating them on a deep level
than before. Machine learning technology aims at assembling the arrangement of
collecting data and learning from the data and improves self-capacity via experiences
without the engagement of humans and reprogramming [1].
Machine learning has been utilized for the improvement of consumer experience,
operational analytics, and revenue management in the hospitality industry. Data
aids organizations in fulﬁlling the increasing expectations of the customers when
presented with new, unexpected problems in the hospitality industry. Capturing data
C. S. Ashwin (B)
Information Systems, Sri Sai Ram Engineering College, Chennai, Tamil Nadu 600044, India
e-mail: tocsashwin@gmail.com
S. Thavasi
Head of the Department, Sri Sai Ram Engineering College, Chennai, Tamil Nadu 600044, India
e-mail: hod.it@sairam.edu.in
K. R. Rangarajan
Information Technology, Sri Sai Ram Engineering College, Chennai, Tamil Nadu 600044, India
e-mail: ranga1290@gmail.com
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_18
243

244
C. S. Ashwin et al.
regarding consumer purchases, consumer experience inquiries, travel patterns, and
location preferences also assist in increasing the efﬁciency of the analytics being
utilized. Engaging with the customers and informing them regarding the various
offers and felicitating them on any special day can be an approach for involving
consumers [2].
Machine learning improves consumer services. So, hotels have installed machine
learning for smoothly doing this job. Today, robots take place in that position to assist
humans in completing any task as quickly as possible, including concierge services,
room services, and housekeeping are performed by robots. Modern technology has
modiﬁed human employment. Hotels nowadays provide self-service approaches to
consumers. In this article, the use of ML in the hospitality industry and its innovative
approaches in data analysis and modeling are discussed. The improvement in the
industry with machine learning is also discussed with proper examples and justiﬁca-
tion. It is also proved that machine learning improves the revenue of the hospitality
industry [2].
2
Related Work
2.1
Usefulness of Machine Learning in the Hospitality
Industry
Users generate a vast amount of data during the search for destinations, hotels, and
ﬂights for travel. These are metadata (browser, device, location, referral source, and
duration), behavioral data (search enquiries, travel booking history, email subscrip-
tion, destination searches, and other online activities), CRM data (service preference,
purchasing details), social media data (ratings, service feedbacks, geo-tagged loca-
tions, shared photos, and social media comments). Machine learning is very efﬁcient
in gathering and processing this data to help a company and the hospitality industry
in different ways [2].
Automated processes and services: It is known to everyone that it is so frustrating
when half an hour is taken to reach customer service to reschedule a booking. Gener-
ally, customers change their choice while facing this type of issue. By using AI-based
assistants, that is, chatbots, the hospitality industry can reduce the average time of
response to just a few minutes [3]. Automated system in hospitality industry is shown
in Fig. 1.
The data layer is composed of third-party, social data, airline data, and frequent
ﬂyer data. Data shows that most hospitality businesses are eager to implement this
type of self-service technology to manage customer support and repetitive tasks. AI-
based solutions are also helpful for resource planning and revenue accounting using
data layer [3].

NAML—A Novel Approach of Machine Learning Implementation …
245
Fig. 1 Automated system in hospitality industry
Personalization of customer experiences: Lots of random travel offers cannot be
sent to a user with an email which is also embarrassing. Implementation of AI in the
hospitality industry provides insight into customer behavior which gives the company
the opportunity to tailor-made deals according to the family status of the customer,
favorite cities, the purpose of visit, and hotel location preference. The chances of
catching customers’ attention increase multiply. On the other hand, people love to
express their views online. Adoption of ML in hospitality industry is shown in Fig. 2.
The technology, organization, and environment of the ML system is described
in the diagram. AI-powered software analyzes guest preferences with their tracking
patterns of them, and staffs get real-time recommendations from the software. This
results in the improvement of customer satisfaction and building loyalty [4].
Improvement of staff efﬁciency: Customers love the service when the staff of
the hotel remembers them and their preferences. The whole customer management
system of a company gets a personal touch when a company utilizes the capacity of
machine learning in it. Natural language processing and speech analytics apps can be
used to extract meaningful data from customers and support staff voice interactions.
Employees can also improve their work efﬁciency in their free time, generated using
machine learning tools [4].
Detecting fraudulent activities: Many hotels face the issue of being scammed by
customers who demand a chargeback from the bank as they claim one of their cards
was stolen, or their other credentials were stolen. Billions of monetary funds, which
are invested in dollars, or any other currency can be saved by the hospitality industry

246
C. S. Ashwin et al.
Fig. 2 Adoption of ML in hospitality industry
by using artiﬁcial intelligence to ﬁnd out the illegal activity by evaluating transactions
[5].
Optimization of expenses: Everyday technical malfunctions and natural disasters
cause lots of delays in the hospitality industry. Thanks to the advanced algorithm of
machine learning, predictions can possibly be made about travel disruptions based
on ﬂight delay and weather information. This helps to reduce losses for carriers
and travelers. Many hospitality management companies use machine learning and
artiﬁcial intelligence combined with trackers to plan regular activities [5].
Creating more value: A suitable algorithm can help to provide better service with
an increase in proﬁt by analyzing the customer activities at the hotel, such as room
preference and room service choices. Analysis of travel goals, value and price pref-
erence, destination, and time spent on the hotel by algorithms gives the whole hospi-
tality management system more value with better customer satisfaction, timesaving,
and cost reduction. The management’s insight into customers’ demand and choices
improve. Thus, the management can invest time and effort in other business sections
[8].

NAML—A Novel Approach of Machine Learning Implementation …
247
3
Proposed Work
3.1
High-Tech Innovation in Hospitality Industry Using
Machine Learning
In the hospitality industry, there is a demand of innovative technology that improves
success in handling operations. The fundamental requirement of the industry is to
analyze customer behavior that requires huge statistics. With the help of machine
learning algorithms and techniques, it is possible to access huge amount of data
associated with the hospitality business. ML helps in collecting and analyze tourist’s
behavior by evaluating their data. This includes monitoring their stay, relevancy of
the service in the hospitality industry, and so on. In the era of Internet, collection
and monitoring of such data is very easy. However, with the intervention of machine
learning algorithms, the evaluation of the data using.
ML models can be possible. The models create networking between the user and
the industry as well which is a great form of innovation. Currently, the industry is
looking forward innovation through mobile apps, online user reviews, video investi-
gations, etc. After using a service, people generally put review in form of ratings and
comments [8]. This user data is collected automatically by the machine learning algo-
rithms and run it with the help of effective models to make decisions in the industry.
The revelations of the innovation started explicitly in 1970s when the computer
reservation system has started. With the intervention of global distribution system,
it became possible to develop innovation in the hospitality industry [7]. Systematic
evaluation of ML components in hospitality industry is shown in Fig. 3.
The machine learning types are classiﬁed in this diagram. Sentimental Analysis
Technologies and Natural Language Processing can analyze this vast amount of
user reviews from social media and websites. An efﬁcient software can also identify
these posts’ emotional backgrounds. Thus, a company can notice both the negative
and positive sides of its business and improve its service accordingly [3]. Machine
learning is associated with the innovative data science technique that introduces
Fig. 3 Systematic evaluation of ML components in hospitality industry

248
C. S. Ashwin et al.
maximum tangible service to the hospitality industry. It helps in categorizing the
input objects and estimate the output as a statistical model. The use of training and
testing of data through models and algorithms help in dividing data and analyzing
trends. For example, analyzing sales and customer behavior becomes very easy.
Usually, the machine learning algorithm is applied in four ordinary forms, namely
supervised, unsupervised, semi-supervised, and reinforcement learning. In this way,
focus is given to the customer’s engagement and loyalty. Machine learning helps the
consumers in the industry to engage customers and loyalty for the businesses. This
improves the overall industry’s performance. So, it can be said that machine learning
brings high-tech innovation to the industry [7].
ML is convenient in every way. Even new users can use it as it is user-friendly
and environment-friendly. It is a convenient way of providing accurate information
by sourcing data from several companies. The tourist’s reviews and comments are
evaluated suing modern models that are coming into the industry every day. With new
interventions, the machine learning algorithm brings new techniques of evaluating
data and makes the system completely automatic. Moreover, machine learning brings
automation which is a high-tech innovation in today’s world [10].
By evaluating the historic data in the industry, it is important to innovation automa-
tion. ML helps in high level of decision making. ML improves customer service,
customer experience and relieves the industry from extra pressure and wrong deci-
sion making. The system helps in innovating the booking and occupancy system,
which improves segmentation and demand of the customers. With high-tech inno-
vation, ML can improve the management and operations. It also helps in brand
monitoring and uses advanced competition analysis in the industry. The employees
are associated with technological support as well that improves their pricing and
performance statistics. ML in the tourism industry is most valuable for a company
when it analyzes the competition in the market [9].
ML is based on the hyperparameters as the machine starts learning in a better way.
In the hospitality industry, there is a need of mechanized system that is advantageous
for both the customers and the service providers. The design of ML algorithm is done
to solve different actions in the hospitality industry. It helps in the future predictions
of the company’s trends. Data is analyzed with structured and semi-structured pattern
for future predictions. Artiﬁcial intelligence helps in designing and development of
algorithms as well. High-tech innovations like clustering and classiﬁcation algo-
rithms help the hospitality industry to grow. ML also improves the pre-processing of
data [8]. State of AI in hospitality industry is shown in Fig. 4.
The diagram describes the state of AI in the hospitality industry.
Machine learning facilitates check-out and check-in with facial recognition. Facial
recognition permits them to check out and check in easily without any waste of time.
So, there is no requirement for waiting at the front desk. Machine learning techniques
permit employees in being part of automated management systems, where managers
and employees predict the future of any business condition via consumer reviews
or collected data and plan the preparation for the future operations [8]. Machine
learning can support associating hotel management and consumers from one view-
point, where both understand and recognize the existing reactions and smart services.

NAML—A Novel Approach of Machine Learning Implementation …
249
Fig. 4 State of AI in hospitality industry
It allows them in ﬁnding out undiscovered information from collected data. So, hotels
involve machine learning systems for accurately doing tasks, including occupancy,
and booking, segmentation, revenue management, yields management, demand fore-
casting, pricing, competitive analysis, brand monitoring, performance evaluation,
and data collection from external and internal sources for understanding consumer
behaviors. Nowadays, machine learning has been at the state of the art of practices
of revenue management in the hospitality industry. The basic concept of machine
learning is that the computer learns from data and develops a model automatically
by normalizing the pattern identiﬁed from the data. Machine learning algorithms
develop a model dependent on sample data, referred to as training data, for making
decisions or predictions without being programmed for doing so. Machine learning
is computer algorithms that learn automatically from data to discover insights or
hidden patterns [9].

250
C. S. Ashwin et al.
Fig. 5 ML revenue management in hospitality industry
4
Result Analysis
4.1
ML in Revenue Management in the Hospitality Industry
For an organization in the hospitality industry, it is important to improve the revenue
collection by shaping the demand in the market. The complex activity of revenue
management deals in customer segmentation, demand forecasting, pricing tech-
niques, and yield management. With such techniques, the application of ML becomes
highly innovative and dynamic. There are several components of ML that improves
the revenue of the company, such as analyzing customer behavior and demographics.
With the help of data collection of the customers, the company can improve demand
in the market for the hotels [12]. ML revenue management in hospitality industry is
shown in Fig. 5.
Advanced revenue management systems can utilize machine learning models
in different areas of revenue management, such as pricing, demand forecasting,
customized guest services, and market segmentation, with recent development in
machine learning technologies supported by big data [13]. Machine learning methods
are broadly utilized in several application areas, including speech recognition and
image processing, whereas conventional algorithms cannot be capable of solving
the larger scale, often complex issues. Revenue managers do not require to put any
number into a spreadsheet with machine-recommended pricing and data-driven fore-
casts of consumer demands. Revenue management systems can greatly be automated
by leveraging advancement in machine learning technology. Machine learning proce-
dures manage the operations, and the organizations investigate new data regarding
consumer demands, behaviors, and future trends in the hospitality industry [10].
In the hotel industry, dynamic pricing is applied by advanced machine learning
strategies. ML uses different technologies to innovate the use of models for revenue
analysis. It helps in analyzing the competition by using trends analysis. The revenue

NAML—A Novel Approach of Machine Learning Implementation …
251
management principles remain the same regardless of the underlying software used in
the standard industry. A tangible quality shift can be seen in this case where science-
based techniques are used in the revenue management system. Machine learning also
entails the training and testing of statistical models. It helps in forecasting the values
in a supervised as well as unsupervised ways [10].
ML uses new generation solutions like maintaining accuracy, autonomy, and
integrity. The real-time data processing system helps the hospitality company to rede-
ﬁne revenue management. It also enables customer segmentation in an automated
way. Machine learning helps in modernizing underlying techniques in a tangible
way that improves the efﬁciency of the company. ML improves revenue by demand
forecasting [11–13].
5
Conclusion
Theuseofmachinelearning(ML)algorithmisincreasingdaybydayinthehospitality
industry because of its effectiveness in automating the system. ML is also very
informative to the hospitality industry. It is learned from the article that machine
learning supports associating hotel management and consumers from one viewpoint,
where both understand and recognize the existing reactions and smart services. ML
provides top beneﬁts to the hospitality industry by revenue analysis, building models
for detection of trends, forecasting data, etc.
References
1. Alotaibi E (2020) Application of machine learning in the hotel industry: a critical review. J
Assoc Arab Univ Tourism Hospitality 18(3):78–96
2. Aluri A, Price BS, McIntyre NH (2019) Using machine learning to cocreate value through
dynamic customer engagement in a brand loyalty program. J Hospitality Tourism Res 43(1):78–
100
3. Antonio N, de Almeida A, Nunes L (2017) Predicting hotel bookings cancellation with a
machine learning classiﬁcation model. In: 2017 16th IEEE International conference on machine
learning and applications (ICMLA). IEEE, pp 1049–1054
4. Caicedo-Torres W, Payares F(2016) Amachine learning model for occupancy rates and demand
forecasting in the hospitality industry. In: Ibero-American conference on artiﬁcial intelligence.
Springer, Cham, pp 201–211
5. Go H, Kang M, Suh SBC (2020) Machine learning of robots in tourism and hospitality:
interactive technology acceptance model (iTAM)—cutting edge. Tourism Rev
6. Mahesh B (2020) Machine learning algorithms—a review. Int J Sci Res (IJSR) [Internet]
9:381–386
7. Mbunge E, Muchemwa B (2022) Deep learning and machine learning techniques for analyzing
travelers’ online reviews: a review. In: Optimizing digital solutions for hyper-personalization
in tourism and hospitality, pp 20–39
8. Park EO, Chae B, Kwon J (2018) Toward understanding the topical structure of hospitality
literature:applyingmachinelearningandtraditionalstatistics.IntJContempHospitalityManag

252
C. S. Ashwin et al.
9. Parvez MO (2020) Use of machine learning technology for tourist and organizational services:
high-tech innovation in the hospitality industry. J Tourism Futures
10. Satu MdS, Ahammed K, Abedin MZ (2020) Performance analysis of machine learning tech-
niques to predict hotel booking cancellations in hospitality industry. In: 2020 23rd International
conference on computer and information technology (ICCIT). IEEE, pp 1–6
11. Vargas-CalderónV,OchoaAM,NietoGYC,CamargoJE(2021)Machinelearningforassessing
quality of service in the hospitality sector based on customer reviews. Inf Technol Tourism
23(3):351–379
12. Zhou Z-H (2021) Machine learning. Springer Nature, Berlin
13. Qu K, Guo F, Liu X, Lin Y, Zou Q (2019) Application of machine learning in microbiology.
Front Microbiol 10:827

A Novel Dynamic Energy Amendment
Control for Solar Fed Brushless DC
Motor for Water Pumping System
U. Arun Kumar, K. S. Chandraguptamauryan, K. Chandru,
and W. Rajan Babu
Abstract This study optimizes solar PV power for a brushless DC motor (BLDC)-
driven water pumping system utilizing Dynamic Energy Amendment Control
(DEAC). The improved isolated DC–DC converter with an Adaptive Perturb and
Observe (APO) algorithm-based Maximum Power Point Tracking (MPPT) tech-
nology generates steady DC power alternating current, generally by a Brushless
Direct Current Motor (BLDCM) motor, to enhance solar Photovoltaic (PV). BLDCM
needs solar-powered water pumping. Power conversion causes varying sizes, cost,
complexity, and efﬁciency loss. A single-stage operating solar PV system and BLDC
electric pump eliminate the isolated DC–DC converter phase to create a stand-
alone solution. A BLDC motor may be controlled using a Voltage Source Inverter
(VSI) to drive a solar photovoltaic array at peak power. Dynamic Energy Amend-
ment Control (DEAC) decreases BLDC motor phase current sensing. The DEAC
controller automatically regulates the inverter’s PWM based on load ﬂuctuation,
therefore speed control is not needed. BLDCM speed control needs are greater
because rotor position analysis requires continual self-synchronization feedback.
High homeostatic functions absolute or incremental encoders are usually utilized
with the BLDCM. BLDCM modelling and simulation should address motor steady-
state characteristics, speed reversal, and load tolerance. The DEAC controller simu-
lations offer accurate results under all operating situations. Test results are compared
U. Arun Kumar (B)
Department of Electrical and Electronics Engineering, SRM Institute of Science and Technology,
Ramapuram Campus, Chennai, Tamil Nadu 600089, India
e-mail: arun.udayakumarn@gmail.com
K. S. Chandraguptamauryan
Department of Electrical and Electronics Engineering, Guru Nanak Institutions Technical
Campus, Hyderabad 501506, India
K. Chandru
Department of Electrical and Electronics Engineering, EASA College of Engineering and
Technology, Coimbatore, Tamil Nadu 641105, India
W. Rajan Babu
Department of Electrical and Electronics Engineering, Sri Eshwar College of Engineering,
Coimbatore, Tamil Nadu 641202, India
e-mail: rajanbabu.w@sece.ac.in
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_19
253

254
U. Arun Kumar et al.
to MATLAB/Simulink results and experimentally veriﬁed under real operating
circumstances.
Keywords Solar photovoltaic (SPV) · Adaptive perturb and observe (APO)
algorithm · MPPT · Dynamic energy amendment control (DEAC) · BLDC · Field
programmable gate array (FPGA)
1
Introduction
There has been a worldwide shift in the previous several decades with regards to
energy usage, the amount of help given, and environmental concerns. Mitigation is
a major issue that has to be addressed. There has been signiﬁcant progress made in
addressing the issue, thanks in large part to the use of renewable energy sources, elec-
tric motors with low noise pollution characteristics, and high-efﬁciency power trans-
mission systems. A system of electric motor pumps is one of the most common uses
of solar energy. Household uses, agricultural irrigation, and rural water consumption
are just some of the various uses for solar pumping systems in outlying locations.
The beneﬁts of a water pump based on a PV system include minimal maintenance,
simple installation, and dependability. The DC–DC converter employs the Adaptive
Perturb and Observe (APO) algorithm to maintain consistent solar output. Figure 1
is a simpliﬁed version of the basic block diagram used to execute the stability speed
control of the brushless DC motor (BLDC) and the state-of-the-art Dynamic Energy
Amendment Control (DEAC).
Photovoltaic arrays power water pumps using BLDC motors. DC–DC converters
employ Maximum Power Point Tracking (MPPD) technology to stabilize solar power
from photovoltaic arrays and feed it to the inverter for BLDC electric pumps for agri-
cultural application. APO-MPPT simpliﬁes direct duty cycle control. This solution
removes the APO controller and duty cycle control settings directly. Noise and duty
rotation have little direct effect, thus rotation is stable and energy efﬁcient without
vibration. The greater the interference rate, the higher and more steady the system’s
Fig. 1 Fundamental block diagram for the solar fed BLDC motor

A Novel Dynamic Energy Amendment Control for Solar Fed Brushless …
255
worldwide utilization PWM rate. Without oscillation metres, dynamic circumstances
near the ideal operating point and minimal optimal monitoring performance are
attained. The initial duty cycle and interrupt range gently boost the VSI DC bus
voltage to start the smooth BLDC motor.
This study analyses energy’s dynamic response characteristics, offering
ﬁxed/constant irradiance corrective control APO to stabilize PV power and DEAC
to improve the BLDC drive system. The controller controls the APO algorithm
to dynamically track BLDC drive system power input. The boost converter tracks
maximum power point for this. This powers the BLDC motor’s voltage source
inverter. DEAC simulations operated the BLDC drive system at a constant speed
at varied irradiation levels.
2
Literature Survey
Due to the BLDC drive’s thinning and structural beneﬁts, household applications
employ BLDC motors. It reduces computational complexity and application driver
controller integrated circuit size, which is beneﬁcial. Latest Dual Duty Modulation
technique [1, 2]. The BLDC motor uses a novel commutation error-based correction
approach to reduce phase distortion between current and post-EMF [3]. To minimize
irregular driving control and boost system dependability, an online-level pulse signal
fault detection software with rapid fault tracking is needed [4]. The author suggests
quick commutation error correction to increase accuracy and decrease cost. The
BLDC motor control topography is ﬁrst tested with no load, then gradually increased
to analyse performance. The Electromotive Force (EMF) DC Connection Extended
State Observer (ESO) system for voltage sources re-evaluates the new conductor.
Finally, EMF redirection error is compensated [5–11].
In order to test BLDC motor drives with a single-phase power supply, one FPGA
implementation employs a Single-Ended Primary-Inductor Converter (SEPIC)
converter based on an induction bridge. From the three-phase VSI, the converter
provides a variable DC connection voltage for the electronic commutator motor
BLDC [12, 14]. A single-phase brushless DC (BLDC) motor is most suited for this
taskbecauseofitshighoperatingspeed[15,16].Thespeed-independentinter-linkage
ﬂux function is preferable for sensorless BLDC motor control at lower speeds. An
enhanced closed-loop system was shown based on full-speed changes [17–21].
The electromechanical control system is used to display an event-driven oper-
ating system implemented in FPGA. The supervisor provides a powerful, secure,
transparent control that deﬁnes all possible directions for a Finite-State Machine
(FSM) to optimize [22]. The potential stability problem of this investigation is due
to various conditions of load disturbance and the ease of such control under reduced
processor power. This criterion has been used to an analysis of Lyapunov stability in
closed-loop systems [23, 24]. The BLDC motor’s dynamic speed control stability is
improved by implementing and testing an adaptive control technique under a variety
of loads.

256
U. Arun Kumar et al.
3
Proposed System
In this paper, we present the design and analysis of a controller for speed regulation
of a BLDCM that uses corrected Dynamic Energy Amendment Control (DEAC).
When operating a solar fed BLDC motor, the user may rapidly adjust the magnetic
ﬂux and torque components thanks to the motor’s direct drive torque. To get the
highest possible dynamic performance from the proposed drive system, the Dynamic
Energy Amendment Control (DEAC) controller is implemented.
Figure 2 shows the proposed architectural structure of a solar-powered BLDC
motor. The BLDC motor operates a VSI or voltage source inverter to generate
magnetic ﬂux. It adjusts the “θ” angle of the motor to facilitate its operation and
plays a key role. According to the policy of the BLDC motor, there is a supply
between the two stages. EMF and the margin are formed at one point. Back-EMF
has a basic sensitivity function, which then helps to detect zero cross-sections; it
creates pulses with a level code. Based on the switch function in the switch table, it
can be controlled. To achieve this cycle, an Advanced Dynamic Energy Amendment
Control (DEAC) controller effectively stabilizes the overall operation.
3.1
Isolated DC–DC Converter
Figure 3 illustrates the DC–DC converter’s proposed single-switching circuit design.
A High Voltage Side (HVS) circuit and a High Voltage Side (HVS) circuit are linked
together by a High Frequency (HF) transformer to produce the isolation converter.
Fig. 2 Proposed methodology

A Novel Dynamic Energy Amendment Control for Solar Fed Brushless …
257
Fig. 3 Proposed Isolated DC–DC converter
The LVS has a primary winding transformer, a storage capacitor CS, a switch S1, and
an induction L1. The secondary transformer incorporates a complete bridge rectiﬁer
and a low-frequency LC ﬁlter coupled to the diodes DS-1 through HVS-dissolved
DS4. The ratio of the torque produced by the main and secondary windings of a
transformer is denoted by n = NS/NP. As described above, the converter performs
two functions: varying the input voltage V1 High and constant output voltage Vdc
and Monitoring photovoltaic panel Maximum power point (MPP) Low adjustment.
A single switch S1 controls the converter to simplify the operational analysis;
the capacitors of all the transformers are considered to be adequate so that the DC
voltage becomes low compared to the voltage surge across them. The semiconductor
is also considered to be load resistant fully and a supplied converter. The converter
state switch operates in two stages according to S1.
3.2
Proposed APO-MPPT Technique
Optimal performance of the combined solar/wind/fuel cell system is maintained by
the use of APO-MPPT technology. For technical purposes, the power slope is ﬂat
when DP/DV = 0, and it is empty when the slope is positive or negative. Here is the
MPPT method that uses APOs:
Ppv = Ppv × ipv
(1)
∂Ppv
∂Vpv
= ipv + vpv × ∂ipv/∂vpv = 0
(2)
∂ipv/∂vpv = −i pv
vpv at MPP
(3)
∂ipv/∂vpv > −ipv/vpv at the left of MPP
(4)

258
U. Arun Kumar et al.
Fig. 4 Flow chart for APO-MPPT technique
∂ipv/∂vpv < −ipv/vpv at the right of MPP
(5)
The APO-based MPPT technique is used to improve the output efﬁciency of
photovoltaic panels. Figure 4 shows the ﬂow chart of the algorithm.
3.3
Optimization Steps of Proposed DEAC Controller
Step 1: The quadrature-axis stator current reference i∗
qs is computed from torque
reference T ∗
e as
Iqs = (2/3)(2/P)(Lr/Lm)

T ∗e
r

(6)
where
T
torque
Lr
rotor self-inductance
Lm
stator self-inductance
Iqs
axis stator current reference.

A Novel Dynamic Energy Amendment Control for Solar Fed Brushless …
259
where r = |r| lest is the evaluated value of rotor ﬂux linkage known by,
r =
 Lmids
1 + τrs

(7)
where
τr =
 Lr
Rr

rotor time constant
(8)
Step 2: The direct-axis stator current reference i∗
ds is gained from reference rotor
ﬂux response |r|∗
i∗
ds = |r|∗
Lm
(9)
Step 3: The rotor ﬂux position θe required for Dynamic Energy Amendment
Control (DEAC) is acquired from the rotor speed ωr and slip frequency ωs.θe
calculated as,
θe =

(ωr + ωsl.)dt = θr + θsl.
(10)
where
θe
rotor ﬂux position
ωr
rotor speed
ωs
Slip frequency
dt
differential time.
Step 4: The slip frequency stator reference is estimated from the current i∗
qs and
motor parameters
ωsl. =
 Lm Rr
r Lr

i∗
qs
(11)
The three-phase BLDC motor current (ABC-axis) of the elements of the two-
stage conversion (dq-axis) can be equal to the current elements,
 Iqs
Ids

= 2/3

sin θe sin

θe −2ρ
3

cos θe cos(θe −2π/3)

(12)
The three-phase current component of the ias, ibs, and ics, and the space within
the rotation frame are completely in a blocked position. In contrast, the two-phase
current components ids, iqs, and synchronous system are nevertheless in place to
direct and quadrature axis at a constant speed.

260
U. Arun Kumar et al.
Step 5: The FPGA’s motor’s internal conﬁguration memory is then set to the
reference speed.
Step 6: By applying the error and the change in the measurement error between
the motor speed and the output of the reference model to the motor inverter, the
suggested FPGA controller could keep the motor running at the desired speed.
4
Results and Discussion
This MATLAB2017b-based BLDC Driver system, which is based on the suggested
Dynamic Energy Amendment Control (DEAC) approach, is the result of extensive
research and development. The coordinated system will verify the functioning of
the suggested model while the simulation of the system’s function will verify the
model’s accuracy. This image depicts the proposed BLDCM model’s implementation
in MATLAB/Simulink, its usage, and its capacity to present libraries of SIM power
supply system-wide setups.
Table 1 describes the Speciﬁcation of the proposed solar fed BLDC model;
based on the Speciﬁcation, the proposed prototype is developed and tested with
the simulation results. Figure 5 represents the proposed Dynamic Energy Amend-
ment Control (DEAC) strategy-based speed control of the BLDCM. Based on the
different torque-speed of the BLDCM, performance is veriﬁed, and the results are
given below.
Figure 6 shows the solar power output voltage of the proposed model. In this
system, an SPV generates the maximum voltage of 90 V. Figure 7 shows the DC–DC
converter output voltage for the essential needs to run the BLDCM. The inverter
Table 1 Speciﬁcation of the
proposed solar fed BLDC
model
System speciﬁcations
Device rating
SPV panel
Maximum power =
0.6 kW
Open circuit voltage =
32 V
Short circuit current =
19 A
Isolated converter switching
frequency
24 kHz
DC link capacitor
372 µF
Inverter
Three-phase MOSFET
module, 600 V, 10 A
Field programmable gate array
(FPGA)
SPARTAN-3E XC3S100E
controller
BLDC motor
½ hp, 3000 rpm, 230 V,
1.6 A
Pump
Centrifugal pump

A Novel Dynamic Energy Amendment Control for Solar Fed Brushless …
261
Fig. 5 Final proposed system Simulink model
needs the stabilized DC voltage, and the solar voltage will be improved by using the
boost converter. The above waveform represents the solar power voltage which is
increased up to 440 V. The proposed APO controller will stabilize the solar voltage
at the time (0.15) s.
Load torque ﬂuctuation is shown in Fig. 8 by the current waveform for the BLDC
motor; the initial current variation is large during the time period (0–2).
Torque output from a brushless DC motor is seen in Fig. 9. Applying the load
torque for 0.2 s allows for a differential speed study of the suggested model. The
torque value is used to adjust the speed and stator current.
In order to keep the BLDC motor running at a constant speed, the suggested
Dynamic Energy Amendment Control (DEAC) Controller would automatically
adjust the PWM based on the load torque ﬂuctuation. Figure 9 illustrates the varying
torqueunderload,whileFig.10showsPWMpulsessuperimposedontheload.Ascan
be shown in Fig. 11, the suggested Dynamic Energy Amendment Control (DEAC)
Fig. 6 Solar output voltage

262
U. Arun Kumar et al.
Fig. 7 DC–DC converter waveform
Fig. 8 Output current of the proposed system
Fig. 9 BLDC motor torque

A Novel Dynamic Energy Amendment Control for Solar Fed Brushless …
263
controller is able to analyse the speed stability of BLDC motors. Considering these
factors, we determine that a driving cycle speed of 1500 rpm with a simultaneous
torque of 1 N-m (0–0–1) is optimal.
The accompanying diagram illustrates the ideal speed that can be maintained
with the help of the suggested DEAC controller by providing the proper feedback to
the inverter. The performance of BLDCM is analysed by comparing many distinct
metrics, such as the steady-state error, the recovery time, and the peak overshoot
time, as shown in Fig. 12. Simulation results are organized in Table 2; it is clear
that the DEAC-based controller outperforms the conventional Proportional Integral
Derivative (PID) controller.
Fig. 10 PWM waveform of the proposed controller
Fig. 11 BLDC motor speed

264
U. Arun Kumar et al.
0.9564
0.5663
0.845
0.423
0.88
0.41
6.6
4.2
0.66
0.36
PID
DEAC
PERFORMANCE  ANALYSIS(%)
CONTROL METHOD 
COMPARISION ANALYSIS 
Peak time(sec)
Recovery
Overshoot (%)
Recovery
Time(sec)
Steady
State
Error
Value(rpm)
Steady
State
Error
(%)
Fig. 12 Comparison analysis
Table 2 The performance
analysis of the BLDC motor
Parameters
PID
DEAC
Reference value (rpm)
1500
1500
Peak overshoot time (s)
0.9564
0.5663
Recovery overshoot (%)
0.845
0.423
Recovery time (s)
0.88
0.41
Steady state error value (rpm)
6.6
4.2
Steady state error (%)
0.66
0.36
5
Conclusion
This paper presents a prototype model for controlling the speed of BLDCM through
the Dynamic Energy Amendment Control (DEAC) method, and it is based on a
controller based on the Field Programmable Gate Array (FPGA) (SPARTAN-3E
XC3S100E). Using the Mat Lab 2017b software environment, the performance of
each controller parameter has been checked and analysed in depth. The simulation
results with this model show that the operating conditions for BLDC speed control
are improved with the controller, leading to a steady-state value of 5.8% that is
superior to that achieved with conventional controllers. The ﬁndings suggest that
the proposed DEAC controllers’ standout qualities include their ability to eliminate
errors and drastically reduce steady-state error. Several load torque circumstances are
used to validate the continuous and constant speed operations. The optimal steady-
state value (rpm) for water pumping is achieved with the help of the cutting-edge
Dynamic Energy Amendment Control (DEAC) control.

A Novel Dynamic Energy Amendment Control for Solar Fed Brushless …
265
References
1. Mishra P, Banerjee A, Ghosh M (2020) FPGA-based real-time implementation of quadral-
duty digital-PWM-controlled permanent magnet BLDC drive. IEEE/ASME Trans Mechatron
25(3):1456–1467. https://doi.org/10.1109/TMECH.2020.2977859
2. Sen A, Singh B (2021) Peak current detection starting based position sensorless control of
BLDC motor drive for PV array fed irrigation pump. IEEE Trans Ind Appl 57(3):2569–2577.
https://doi.org/10.1109/TIA.2021.3066831
3. Wang L, Zhu ZQ, Bin H, Gong L (2021) A commutation error compensation strategy for high-
speed brushless DC drive based on Adaline ﬁlter. IEEE Trans Ind Electron 68(5):3728–3738.
https://doi.org/10.1109/TIE.2020.2984445
4. Cai J, Zhao X (2021) Synthetic hybrid-integral-threshold logic-based position fault diagnosis
scheme for SRM & BLDC drives. IEEE Trans Instrum Meas 70:1–8, Art no. 1500608. https://
doi.org/10.1109/TIM.2020.3031357
5. Zhang H, Li H (2021) Fast commutation error compensation method of sensorless control for
MSCMG BLDC motor with nonideal back EMF. IEEE Trans Power Electron 36(7):8044–8054.
https://doi.org/10.1109/TPEL.2020.3030777
6. Yang L, Zhu ZQ, Bin H, Zhang Z, Gong L (2021) Virtual third harmonic back EMF-based
sensorless drive for high-speed BLDC motors considering machine parameter asymmetries.
IEEE Trans Ind Appl 57(1):306–315. https://doi.org/10.1109/TIA.2020.3033821
7. Trivedi MS, Keshri RK (2020) Evaluation of predictive current control techniques for PM
BLDC motor in stationary plane. IEEE Access 8:46217–46228. https://doi.org/10.1109/ACC
ESS.2020.2978695
8. Arunkumar U, Radhakrishnan G, Boobalan S, Kishore J (2020) Power factor correction using
sensorless brushless DC motor with bridgeless converter topology. J Comput Theor Nanosci
17(4):1796–1803
9. de Almeida PM, Valle RL, Barbosa PG, Montagner VF, ´Cuk V, Ribeiro PF (2021) Robust
control of a variable-speed BLDC motor drive. IEEE J Emerg Sel Top Ind Electron 2(1):32–41.
https://doi.org/10.1109/JESTIE.2020.3035055
10. Arunkumar U, Kavya G, Harini R, Krithikaa CA (2017) Intelligent controller based sensorless
brushless drive. Adv Nat Appl Sci 11(6 SI):716–722
11. Tian B, An Q, Molinas M (2019) High-frequency injection-based sensorless control for a
general ﬁve-phase BLDC motor incorporating system delay and phase resistance. IEEE Access
7:162862–162873. https://doi.org/10.1109/ACCESS.2019.2950256
12. Pavana, Vinatha U (2020) FPGA based experimental evaluation of BLDC motor drive fed from
coupled inductor based bridgeless SEPIC. In: 2020 IEEE International conference on power
electronics, smart grid and renewable energy (PESGRE2020), pp 1–6. https://doi.org/10.1109/
PESGRE45664.2020.9070453
13. Alqahtani AS et al (2022) Solar PV fed brushless drive with optical encoder for agriculture
applications using IoT and FPGA. Opt Quant Electron 54(11):1–14
14. Pereira F, Gomes L (2017) The IOPT-ﬂow modeling framework applied to power electronics
controllers. IEEE Trans Ind Electron 64(3):2363–2372. https://doi.org/10.1109/TIE.2016.262
0101
15. Lee W, Kim JH, Choi W, Sarlioglu B (2018) Torque ripple minimization control technique of
high-speed single-phase brushless DC motor for electric turbocharger. IEEE Trans Veh Technol
67(11):10357–10365. https://doi.org/10.1109/TVT.2018.2866779
16. Megalingam RK, Vadivel SRR, Pula BT, Reddy Sathi S, Gupta USC (2019) Motor control
design for position measurement and speed control. In: 2019 International conference on
communication and signal processing (ICCSP), pp 0405–0409. https://doi.org/10.1109/ICCSP.
2019.8698016
17. Chen S, Liu G, Zhu L (2017) Sensorless control strategy of a 315 kW high-speed BLDC motor
based on a speed-independent ﬂux linkage function. IEEE Trans Ind Electron 64(11):8607–
8617. https://doi.org/10.1109/TIE.2017.2698373

266
U. Arun Kumar et al.
18. Darba A, De Belie F, D’haese P, Melkebeek JA (2016) Improved dynamic behavior in BLDC
drives using model predictive speed and current control. IEEE Trans Ind Electron 63(2):728–
740. https://doi.org/10.1109/TIE.2015.2477262
19. Li W, Fang J, Li H, Tang J (2016) Position sensorless control without phase shifter for high-
speed BLDC motors with low inductance and nonideal back EMF. IEEE Trans Power Electron
31(2):1354–1366. https://doi.org/10.1109/TPEL.2015.2413593
20. Das D, Kumaresan N, Nayanar V, Navin Sam K, Ammasai Gounden N (2016) Development of
BLDC motor-based elevator system suitable for DC microgrid. IEEE/ASME Trans Mechatron
21(3):1552–1560. https://doi.org/10.1109/TMECH.2015.2506818
21. Baszynski M, Pirog S (2014) A novel speed measurement method for a high-speed BLDC
motor based on the signals from the rotor position sensor. IEEE Trans Ind Inf 10(1):84–91.
https://doi.org/10.1109/TII.2013.2243740
22. Horvat R, Jezernik K, ˇCurkoviˇc M (2014) An event-driven approach to the current control of
a BLDC motor using FPGA. IEEE Trans Ind Electron 61(7):3719–3726. https://doi.org/10.
1109/TIE.2013.2276776
23. Milivojevic N, Krishnamurthy M, Gurkaynak Y, Sathyan A, Lee Y, Emadi A (2012) Stability
analysis of FPGA-based control of brushless DC motors and generators using digital PWM
technique.IEEETransIndElectron59(1):343–351.https://doi.org/10.1109/TIE.2011.2146220
24. Kumar UA, Ravichandran CS (2022) Upgrading the quality of power using TVSS device and
PFC converter fed SBLDC motor. Arab J Sci Eng 47(8):9345–9359

A Hybrid Model Built on VGG16
and Random Forest Algorithm for Land
Classiﬁcation
Mohammed Junaid Ahmed, Ashutosh Satapathy, Ch. Raga Madhuri,
K. Yashwanth Chowdary, and A. Naveen Sai
Abstract Working with satellite images using deep learning or machine learning
approaches would be exceedingly complex, as each satellite image consists of
numerous characteristics. The use of ensemble learning with two different types
of machine learning techniques to process images has been a trend in recent times.
In this paper, we present a hybrid model that combines the convolutional neural
network model (Visual Geometry Group 16) with an ensemble classiﬁer such as the
Random Forest classiﬁer. Our hybrid approach categorizes the Sentinel-2 satellite-
collected EuroSAT dataset. Several data augmentation techniques are used to process
these images. In order to classify the terrain, characteristics from the spatially linked
picture are extracted using the VGG16 model. The RF classiﬁer categorizes the
images once the features have been passed on to the instantiated RF classiﬁer. The
implementation of the hybrid model has achieved an accuracy of 94.88%, with the
major advantage of requiring less time to train and test the EuroSAT dataset.
Keywords Remote sensing data · Convolution neural network · Visual Geometry
Group 16 · Random Forest · Sentinel-2A EuroSAT images
1
Introduction
Satellite images are one of the most powerful and important tools which are used
by meteorologists to detect the changes on and over the surface of the Earth. These
images reassure forecasters about the behavior of the atmosphere as they give a
clear, concise, and accurate representation of how events are unfolding. The land
cover describes about the various features on the Earth’s surface. Land cover classi-
ﬁcation techniques have been used to identify coastal, agricultural, forest, and urban
M. J. Ahmed · A. Satapathy (B) · Ch. Raga Madhuri · K. Yashwanth Chowdary · A. Naveen Sai
Velagapudi Ramakrishna Siddhartha Engineering College, Vijayawada, India
e-mail: ashutosh.satapathy1990@gmail.com
Ch. Raga Madhuri
e-mail: chragamadhuri@vrsiddhartha.ac.in
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_20
267

268
M. J. Ahmed et al.
areas; these techniques are very helpful for the government organizations to obtain
information about inaccessible remote regions. For example, in the past few years,
land classiﬁcation techniques have been used to understand the agricultural activ-
ities over the regions of Brazil in 2003 and urban expansions in Bangladesh. This
research examines the study of classifying land cover which is one of the promising
and required remote sensing subjects [1]. The socioeconomic purpose of a piece of
land is described by its land use.
The study of land cover and land use images has arisen due to the signiﬁcant
impact that human occupancy has on the environment, which mainly focuses on
land use and changes in the land cover. Applications for precise land cover maps
includeresourcemanagement,environmentalmonitoring,andtheplanningofdiverse
operations over the existing or projected land cover. Large land cover maps required
to identify, track human activity, and map land biogeography are being captured
using satellites such as Sentinel-1, Sentinel-2, and Landsat [2, 3]. The availability of
satellite data has driven the development of novel methods to map land cover using
remotely sensed data. Data from the Sentinel-2 satellite have been frequently used
to calculate urban changes, agricultural changes, and terrestrial changes. Sentinel-2
imageshavebeenavailablesince1972,makingthemidealformappingthelandcover.
Numerous automated and semi-automatic categorization approaches have recently
been developed, yielding precise results for land cover mapping [4]. An essential
approach in remote sensing analysis is image classiﬁcation, which distinguishes
pixels based on their contribution to land cover. However, classifying land cover
images has always been difﬁcult, and gathering training data is quite expensive and
complicated. Image preprocessing techniques have to be more concentrated on the
geometrical, textural, and contextual properties surrounding each pixel, but at the
same time, classifying land cover images at the pixelized level is a hefty task [5].
This article offers a new method for categorizing land use and land changes
using convolutional neural network (CNN) models [6]. EuroSAT, Sentinel-2 satellite-
based images were used as an input dataset in this study. EuroSAT is the UK’s
largest satellite and aerial equipment distributor to the trade, with eight regional
branches [7]. In order to determine the land cover, we have used VGG16 to extract the
features, and these features have been passed to an instantiated Random Forest (RF)
for classiﬁcation [8]. The suggested land classiﬁcation hybrid model’s scope includes
classifying data on land use types, environmental implications, and possible land use
alternatives. It also contains data on the type of human habitation in land use. Land
use classiﬁcation describes the useful potential land alternatives, including land cover
and land changes, natural resource management, types of human habitation involved
in land use, environmental impact assessment, and evaluation of urban expansions.
A CNN model automatically retrieves image features by altering the convolutional
layer and pooling layer parameters. Certain machine learning models, such as K
Nearest Neighbors (k-NN) and logistic regression, are not typically appropriate for
applications with large datasets and many variables, whereas CNN models can be
used for large and complex datasets. Convolution, batch normalization, pooling, fully
connected layers are the four main layers in a CNN, as shown in Fig. 1.

A Hybrid Model Built on VGG16 and Random Forest Algorithm …
269
Fig. 1 Architecture of a CNN
At the University of Oxford, K. Simonyan and A. Zisserman implemented one of
the popular CNN models [9], VGG16, whose error rate was 8.1%, and placed it as one
of the top ﬁve classiﬁers in ILSCRC 2014 [10]. Figure 2 shows the whole network
consists of 13 convolution layers of different stack sizes (two 224 × 224/64, two 112
× 112/128, three 56 × 56/256, three 28 × 28/512, and three 14 × 14/512) and three
fully connected layers. It uses an RGB image of size 224 × 224/3 as input to generate
the class label at its ﬁnal layer. The max pooling layer reduces the size of feature
maps after the second, fourth, seventh, tenth, and thirteenth convolutional layers, as
well as the ReLU activation function, are used with the ﬁrst 15 layers to ﬁlter out
required features while reducing computational cost. The Softmax function after the
last layer computes the probable value for each class, while a 0.5 dropout rate reduces
the issues of overﬁtting or underﬁtting and provides the ﬁnest results to the Softmax
function for classiﬁcation. At last, a stochastic gradient descent optimizer with a
learning rate tunes the network’s weights by minimizing the classiﬁcation error rate
in every epoch as the training proceeds. On the other hand, it requires a huge amount
of computational resources to train 138 million trainable parameters. Features from
the last pooling layer of VGG16 are taken out and given to the RF algorithm for land
classiﬁcation. This not only cuts down on training time, but also on the overall cost
of computing. In the next section, we will discuss different algorithms or models that
were suggested by different authors and tested on different standard datasets.
Fig. 2 VGG16 architecture

270
M. J. Ahmed et al.
2
Related Work
Jacob et al. proposed a supervised method using the RF algorithm for classifying land
use and land change that detects changes in two stages [11]. This study examines the
interferometric mapping of the Sentinel-1 satellite for vegetation and land use. The
research areas in the European regions were selected for the 2015–2016 campaigns
to maximize the range of land cover. The abovementioned strategy trained on the
Sentinel-1 image intensities and the smallest temporal baseline features from 9 to 15
classes, which achieved an overall training accuracy of between 70 and 90%.
Jalayer et al. focused on the Donana Wetlands National Park in Spain, a ﬂat
region, for land use and land cover change using multitemporal Landsat imagery
[12]. It aimed at identifying temporal and geographical modiﬁcations in the land use
and land cover change patterns of the Chalus watershed region during the last two
decades and forecasting the land use and land cover modiﬁcations along with the
patterns in the Chalus watershed in 2040. Three Landsat images were used from the
ETM, and 200 sensors have been employed in this work. To compare closely the
land use and land cover change maps for 2021 and 2040, the support vector machine
method and another model, the Markov chain, produced the transition maps and
plotted the probability matrices between the land use and land cover change types.
The success rate of this LULC research project was 90%.
Gómez and Meoni had demonstrated MSMatch, the ﬁrst semi-supervised learning
algorithm for scene categorization [13]. It appeared to be the best when compared
with other supervised methods on the benchmark land use datasets from EuroSAT
and UC Merced. The key contributions of this study are the extension of current
developments in nearest neighbor designs and the use of semi-supervised learning
techniques to multi-spectral and remote sensing. The analysis of crucial pipeline
elements through ablation studies focuses on the discovery of heterogeneous charac-
teristics of EuroSAT and UCM classes. In terms of robustness against Gaussian noise
with spectral distortions, this approach was trained on EuroSAT and UC Merced land
use datasets. On these datasets, a trained nearest neighbor algorithm outperforms the
past techniques by up to 19.76% and 5.59%, respectively. This work has achieved
90.71% and 95.86% accuracy on the UC Merced land use dataset and EuroSAT,
respectively, using just ﬁve image samples per class.
Jain et al. proposed a study that offers “Remote Sensing Bootstrap Your Own
Latent” (RSBYOL), which improves the classiﬁcation techniques in the remote
sensing areas where the data are non-trivially different from natural RGB images
[14]. However, the remote sensing community is plagued by two signiﬁcant issues:
multi-sensor and the nature of multimodal data acquired from several satellites and
labeled data scarcity. In contrast to conventional RGB pre-trained models, they
have examined the values of pre-trained models with RSBYOL. They had done this
by contrasting their own RSBYOL weights with well-known ImageNet pre-trained
weights. They have trained the RSBYOL using Multi-Spectral Synthetic Aperture
Radar (MS-SAR) and multi-spectral-only data, demonstrating the value of learning
invariant characteristics from MS-SAR data. This work showed that using MS and

A Hybrid Model Built on VGG16 and Random Forest Algorithm …
271
SAR as different ways to look at a network for training was better than just using
MS data, with an accuracy of 98.30%.
Liu et al. had proposed a model that built on a dual-channel network for classifying
the land cover using an encoder–decoder architecture [15]. The authors have acquired
a new dataset with 30,000 pictures and a spatial resolution of 256 × 256 for grid
sampling and data augmentation. Using a random division approach, the dataset
has been split into two parts: training data consisting of 22,500 images and test
data consisting of 7500 images. The existing dataset was improved and cropped
to create a custom dataset with a spatial dimension of 256 × 256, having 9600
images for training and 2400 images for testing. The overall accuracy of the Deep
Fully Connected Neural Network (D-FCN) increased to around 6.67% compared to
other models, and the Kappa coefﬁcient rose by 0.0944, 0.0534, 0.0576, and 0.0753,
respectively. Locally speaking, the D-FCN has a signiﬁcantly better extraction effect
on these categories, resulting in precision values of 89.06 and 85.55%.
Pleiades et al. had implemented an advanced CNN model in conjunction with
object-based image analysis (OBIA) to map the land use and land classiﬁcation over
the coastal region of Ain Témouchent, western Algeria [16]. At ﬁrst, training and test
samples were segregated, and spectral features were generated from these samples.
The proposed model was based on a combined approach of CNN deep modeling
with OBIA for land use and land classiﬁcation. Land use and land classiﬁcation
utilized OBIA and pixel-based techniques using RF and SVM classiﬁers, and the
accuracy of land use and land classiﬁcation maps was evaluated. For both OBIA
and pixel-based techniques, the results obtained with RF were signiﬁcantly better
than those obtained with SVM. RF outperformed SVM regardless of the method
used. RF-OBIA and SVM-OBIA obtained 91% and 72% success rates, respectively,
whereas RF-Pixel and SVM-Pixel obtained 80.1% and 77.4%, respectively.
Kang et al. had implemented the land change detection system, which includes the
use of the complementary properties of the two sensors [17]. They presented a novel
modular and fully convolutional network for improving land cover classiﬁcation
accuracy by fully utilizing the complementary features of the two sensors. They
expected joint classiﬁcation using optical and SAR images to achieve higher accuracy
than the classiﬁcation models using single-sensor images. For this purpose, they
designed a modular model that consists of three modules: an encoder, a multiscale
module, and a decoder. These modules could be replaced with any other modules,
and fusion approaches could be changed. As a result, the accuracy and precision
scores were 80.85% and 84.38%, respectively.
Busquier et al. had proposed an approach that focuses on two types of mapping,
namely land cover and crop vegetation [18]. These classiﬁcation studies were
conducted using a series of images obtained by TanDEM-X Sentinel-1 using the
C-band and EuroSAT using the L-band. The classiﬁcation study’s primary objec-
tive was to investigate how well feature and band combinations perform when used
to categorize data. In this regard, these frequency bands can be used individually
or simultaneously. The RF algorithm performs the categorization process. It was
a cutting-edge supervised classiﬁer with a solid reputation for performance. When
only one frequency band was used, L-band had the best overall accuracy of 81%,

272
M. J. Ahmed et al.
followed closely by C-band, while X-band only had 70%. The accuracy of the land
cover categorization using 20 intensity pictures in the C- and X-bands is 61.49% and
77.62%, respectively. The C-band had the most signiﬁcant classiﬁcation accuracy of
the three bands when used with all intensity channels in all bands.
3
Proposed Methodology
Figure 3 depicts the work ﬂow of our proposed model. Each image is 64 × 64
pixels in size. Four-class labels are one-hot encoded and are stored in respective
lists. Once the preprocessing is done, the images are passed on to the VGG16 model.
The VGG16 model had already been trained using the ImageNet dataset, which
consists of 14 million images categorized into 10,000 class labels [19]. The VGG16
model is used to only extract the features of the images, and approximately 269
characteristics are retrieved from these 12,000 pictures. Once the VGG16 model has
extracted the features, an RF classiﬁer is instantiated, and these extracted features are
trained against the one-hot encoded class labels. Once the classiﬁer has been trained,
the model is prepared for the testing step. During the testing phase, approximately
2400 images are used as testing data.
The data processing stage prepares the raw data for training the ML or DL models.
Before building a deep learning model, preprocessing the data is crucial. One-hot
encoding is a critical stage in improving prediction accuracy; it is the process of
changing the categorical data variables to be fed to ML and DL models. The cate-
gorical features for DL models are processed frequently using one-hot encoder. This
process generates binary numbered values, which can categorize each class label.
A total of four categories of class label have been one-hot encoded. The VGG16
input layer, which takes in images of size 224 × 224 pixels with three channels,
was developed based on the AlexNet model. Around 14 million images from the
ImageNet dataset, consisting of 10,000 categories, were used to train the VGG16
model, whose trainable parameters were ﬁne-tuned at each layer [20]. 269 features
are extracted from each image from the EuroSAT dataset during the training phase.
The extracted features are used to train the RF classiﬁer once it has been initial-
ized with 50 trees. The hybrid model currently consists of 13 convolutional layers of
VGG16 and RF, where the RF classiﬁer is substituted for three fully connected layers
of the naive VGG16 model. Training and validating a Random Forest classiﬁer with
fewer features take less time than training and validating a fully connected neural
network with 4096 neurons with a larger number of features.
Figure 4 shows the sequence diagram of the land classiﬁcation system, in which
the developer gathers the satellite data, pre-processes it using scikit modules, and
then extracts the features using the pre-trained weights of the VGG16 model. These
characteristics are assigned to the RF classiﬁer, which is used in place of the VGG16
fully connected dense layers. This model is evaluated against the images when it has
beenfullytrained.Whenthelevelofaccuracyisacceptable,themodelisdeployedand
made available for the user to categorize the photos. If the accuracy is unsatisfactory,

A Hybrid Model Built on VGG16 and Random Forest Algorithm …
273
Fig. 3 Process ﬂow diagram of land classiﬁcation
the model is retrained by adjusting hyper-parameter values, and the procedure is
repeated until the accuracy is satisfactory. The architecture of the proposed hybrid
model is shown in Fig. 5. Deep learning algorithms are widely used in image and
video recognition systems since they have the capability of automatically generating
features from the time series data and frequency representation images. These try to
learn high-level features from data in an incremental manner. This diagram shows that
the features extracted using VGG16 are given to RF for classiﬁcation into different
classes.
In the above ﬁgure, the architecture diagram consists of 13 layers of the VGG16
model. The convolutional layers are the fundamental components of VGG16, which
typically consist of a combination of linear and non-linear operations such as convo-
lutional operations and activation functions. The Random Forest algorithm is one of
the most widely used image classiﬁcation algorithms. Among all radios, RF has the

274
M. J. Ahmed et al.
Fig. 4 Sequence diagram of land classiﬁcation system
Fig. 5 Architecture of the proposed hybrid model VGG16–RF
highest accuracy and can handle massive amounts of data with thousands of vari-
ables. As we have used a huge dataset in this research, it is obvious that it can lead
to an overﬁtting issue; thus, using an algorithm that can handle this issue on its own
would be the most appropriate step. The RF classiﬁer doesn’t face the overﬁtting
issue because it takes the average of all predictions, canceling out the biases and thus
ﬁxing the overﬁtting problem. Features are obtained using these 13 layers, which act
as a feature extractor in the VGG16 model. The extracted features are used to train
an RF classiﬁer against the one-hot encoded class labels.

A Hybrid Model Built on VGG16 and Random Forest Algorithm …
275
4
Results and Analysis
EuroSAT dataset contains 12,000 images of four different types of land. Figure 6
shows sample land images from the dataset. Each picture is 64 × 64 and occupies a
100-m2, with a cloud cover of 1.505%. A total of 13 bands were used in the Sentinel-2
satellite.
Figure 6 represents four different categories of images; each category consists of
4000 images, for a total of 12,000 images. These have been used in our land classi-
ﬁcation hybrid model. In the above ﬁgure, images from (a–e), (f–j), (k–o), and (p–t)
belong to crop land, industrial land, residential land, and forest land, respectively.
Table 1 depicts the precision, recall, F-score, and accuracy of the proposed hybrid
model trained on the EuroSAT dataset. Precision is the total number of correctly
classiﬁed image samples to their actual classes divided by the sum of all correctly
classiﬁed image samples to their actual classes and the sum of samples of different
Fig. 6 Sample images from EuroSAT dataset: a–e crop land; f–j industrial land; k–o residential
land; p–t forest land

276
M. J. Ahmed et al.
Table 1 Performance score
of the proposed hybrid model
on the EuroSAT dataset
Metric
Score
Precision
0.940990407
Recall
0.940833333
F-Score
0.940820619
Accuracy
0.9488
classes are incorrectly classiﬁed to each class. This measure of precision is given in
Eq. 1.
Precision =
4
i=1 TPi
4
i=1 TPi + 4
i=1 FPi
(1)
Recall is the total number of correctly classiﬁed image samples for their actual
classes, divided by the sum of all correctly classiﬁed image samples for their actual
classes and the sum of image samples of each class incorrectly classiﬁed for other
classes. This measure of recall is given in Eq. 2.
Recall =
4
i=1 TPi
4
i=1 TPi + 4
i=1 FNi
(2)
The F-score, also known as the F1-score of F-measure, is used to assess the
performance of a machine learning model using the precision and recall scores,
calculated using the formula shown in Eq. 3. Its range is between 0 and 1, and a higher
value indicates better performance. It is used to balance the precision and recall score
and will be useful when the number of image samples per class is inadequate.
F-Score = 2 ∗Precision ∗Recall
Precision + Recall
(3)
VGG16 uses a stochastic gradient descent optimization function with batch size,
momentum, and weight decay set to 128, 0.9, and 0.0005, respectively, and all the
layers use an equal learning rate of 0.001. Table 1 explains the precision score,
recall score, and F-score achieved by our hybrid model, whose precision, recall, and
F-score are 0.94099407, 0.940833333 and 0.940820619, respectively.
Figure 7 shows the outputs that are classiﬁed by our hybrid model when these eight
images are randomly given as an input to the system. Each piece of land image in the
above ﬁgure is given as an input to our hybrid model, and the subsequent classiﬁed
label has been described in the image caption. For example, (a, b), (c, d), (e, f), and
(g, h) have been accurately classiﬁed as crop land, industrial land, residential land,
and forest land. The model’s successes and failures can be plotted using a confusion
matrix. It rows represent a predicted class, and each column of the matrix represents
an actual class. For each class, all diagonal cell values are true positive, whereas cells

A Hybrid Model Built on VGG16 and Random Forest Algorithm …
277
in black along each column and row are false negative and false positive for each
class, respectively.
Figure 8 shows how the proposed hybrid model accurately predicted all four
classes. In the above ﬁgure, the (0, 0), (1, 1), (2, 2), (3, 3) cells in the matrix represent
a total of 5.4E+2, 6E+02, 5.7E+02, and 5.5E+02 images that have been accurately
classiﬁed as crop land, industrial land, residential land, and forest land. A small
percentage of images were not correctly classiﬁed in all four classes, which has been
reﬂected in the model’s accuracy decreasing by 5.12% in Table 1.
Table 2 presents a comparison between the previous works that have been executed
on the same dataset. Each model was either fully CNN-based or a traditional machine
Fig. 7 Output images classiﬁed by the system: a, b crop land, c, d industrial land e, f residential
land, g, h forest land
Fig. 8 Confusion matrix of
the proposed hybrid model
on the EuroSAT dataset

278
M. J. Ahmed et al.
Table 2 Comparison between accuracies of proposed model with respect to previous work
S. No.
Literature
Classiﬁer
Accuracy (%)
1
Jacob et al. [11]
RF
92.4
2
Jalayer et al. [12]
SVM
77.62
3
Gómez and Meoni [13]
CNN
70–90
4
Jain et al. [14]
ResNet
90.2
5
Liu et al. [15]
D-FCN
95.7
6
Zaabar et al. [16]
SVM
99.30
7
Kang et al. [17]
CFNet
85.55
8
Busquier et al. [18]
RF
80.1
9
Proposed hybrid model
VGG16-RF
94.88
learning classiﬁcation model, which had shown relatively greater accuracy. The work
publishedbyGomezandMeoniachievedaccuracyintherangeof70–90%[13].Kang
and Xiang achieved an accuracy of 85.5% [16]. On the other hand, Busquier achieved
an accuracy of 80.1%. Few of the published work had worked with RGB images,
and even fewer had worked with the spectral bands of the dataset and obtained
decent accuracy [17]. We can clearly see from the above table that D-FCN and SVM
models achieved greater accuracy when compared to only CNN-based models. In
this work, our hybrid model using the VGG16-RF classiﬁer has achieved an accuracy
of 94.88%.
5
Conclusion
In this study, we discussed how difﬁcult it is to categorize land cover and its uses
over time. The EuroSAT dataset, acquired using the Sentinel-2 satellite, has been
used for the proposed system. In all, 12,000 annotated images, categorized into four
different classes covering 13 different spectral bands, are included in the training and
test sets. We utilized the most highly trained model, VGG16, to extract 269 features
from each image sample in this dataset and supplied them to the RF algorithm for
training and testing purposes. Aside from that, we then evaluated the proposed hybrid
model using remote sensing datasets and compared the results to methods that had
previously been reported. The proposed model is built on the ensemble learning of
CNN and machine learning classiﬁers. The proposed study could lead to a number
of useful results, such as changes in land cover and use, urban growth, monitoring
agricultural activities, and so on.
The result shows that the custom hybrid DL model performed signiﬁcantly better
than other ML models, and its performance on a four-class dataset is 94.88%. When
the model is used in real-time applications, it will not only help us ﬁnd out what’s
going on in agricultural, industrial, forest, and residential areas, but it will also help

A Hybrid Model Built on VGG16 and Random Forest Algorithm …
279
us ﬁnd problems in dangerous or hard-to-reach places and manage and keep an eye on
them without having to drive there. In the future, we plan to validate the performance
of the proposed model on large-scale datasets and cross-sample datasets. To meet
current demands, extensive work must be done to develop sophisticated, lightweight
deep learning models that incorporate a wide range of features for land use and land
classiﬁcation with greater accuracy and minimize the computation time.
References
1. Chang Y et al (2018, Feb) Review of land use and land cover change research progress. In: IOP
Conference series: earth and environmental science, vol 113, no 1. IOP Publishing, p 012087
2. Cihlar J (2000) Land cover mapping of large areas from satellites: status and research priorities.
Int J Remote Sens 21(6–7):1093–1114
3. Drusch M et al (2012) Sentinel-2: ESA’s optical high-resolution mission for GMES operational
services. Remote Sens Environ 120:25–36
4. Jiang D et al (2012) A simple semi-automatic approach for land cover classiﬁcation from
multispectral remote sensing imagery, e45889
5. Deepthi S, Sandeep K, Suresh L (2021) Detection and classiﬁcation of objects in satellite
images using custom CNN. Int J Eng Res Technol 10(6):629–635
6. Albawi S, Mohammed TA, Al-Zawi S (2017, Aug) Understanding of a convolutional neural
network. In: 2017 International conference on engineering and technology (ICET). IEEE, pp
1–6
7. Helber P et al (2019) Eurosat: a novel dataset and deep learning benchmark for land use and
land cover classiﬁcation. IEEE J Sel Top Appl Earth Obs Remote Sens 12(7):2217–2226
8. Pal M (2005) Random forest classiﬁer for remote sensing classiﬁcation. Int J Remote Sens
26(1):217–222
9. MascarenhasS,AgarwalM(2021,Nov)AcomparisonbetweenVGG16,VGG19andResNet50
architecture frameworks for image classiﬁcation. In: 2021 International conference on disrup-
tive technologies for multi-disciplinary research and applications (CENTCON), vol 1. IEEE,
pp 96–99
10. (2014) ILSVRC2014 results. Retrieved 24 Jan 2023, from https://image-net.org/challenges/
LSVRC/2014/results
11. Jacob AW et al (2020) Sentinel-1 InSAR coherence for land cover mapping: a comparison of
multiple feature-based classiﬁers. IEEE J Sel Top Appl Earth Obs Remote Sens 13:535–552
12. Jalayer S et al (2022) Modeling and predicting land use land cover spatiotemporal changes: a
case study in Chalus Watershed, Iran. IEEE J Sel Top Appl Earth Obs Remote Sens 15:5496–
5513
13. Gómez P, Meoni G (2021) MSMatch: semisupervised multispectral scene classiﬁcation with
few labels. IEEE J Sel Top Appl Earth Obs Remote Sens 14:11643–11654
14. Jain P, Schoen-Phelan B, Ross R (2022) Self-supervised learning for ınvariant representations
from multi-spectral and SAR images. arXiv preprint arXiv:2205.02049
15. Liu Z et al (2022) A dual-channel fully convolutional network for land cover classiﬁcation
using multifeature information. IEEE J Sel Top Appl Earth Obs Remote Sens 15:2099–2109
16. Zaabar N, Niculescu S, Kamel MM (2022) Application of convolutional neural networks with
object-based image analysis for land cover and land use mapping in coastal areas: a case study
in Ain Témouchent, Algeria. IEEE J Sel Top Appl Earth Obs Remote Sens 15:5177–5189
17. Kang W, Xiang Y, Wang F, You H (2022) CFNet: a cross fusion network for joint land cover
classiﬁcation using optical and SAR images. IEEE J Sel Top Appl Earth Obs Remote Sens
15:1562–1574

280
M. J. Ahmed et al.
18. Busquier M, Lopez-Sanchez JM, Ticconi F, Floury N (2022) Combination of time series of L-,
C-, and X-band SAR images for land cover and crop classiﬁcation. IEEE J Sel Top Appl Earth
Obs Remote Sens 15:8266–8286
19. Deng J, Dong W, Socher R, Li LJ, Li K, Fei-Fei L (2009, June) Imagenet: a large-scale hierar-
chical image database. In: 2009 IEEE Conference on computer vision and pattern recognition.
IEEE, pp 248–255
20. Team, K. Keras documentation: VGG16 and VGG19. Keras. io. Retrieved 24 Jan 2023, from
https://keras.io/api/applications/vgg/

Facial Expression Recognition Using
Transfer Learning with ResNet50
Shantala S. Hiremath, Jayaprada Hiremath, Vaishnavi V. Kulkarni,
B. C. Harshit, Sujith Kumar, and Mrutyunjaya S. Hiremath
Abstract Facial expression recognition mimics human coding abilities and delivers
non-verbal human–robot communication cues. Machine learning and deep learning
techniques enable real-world computer vision applications. Deep learning-based
facial emotion recognition models have under-ﬁtted or over-ﬁtted due to inade-
quate training data. They are using FER2013’s 7 picture categories. Face detection
using AdaBoost, scaling with OpenCV, and contrast improvement with histogram
equalization preprocess these pictures. These pre-processed pictures are given to the
ResNet50 pre-trained network, which obtained 77.3% accuracy. Transfer learning
improves this outcome. By running pre-processed pictures through ResNet50’s
FC1000 layer, features are retrieved and trained using a multiclass nonlinear support
vector machine (SVM) classiﬁer with seven classes. Training with 89.923% accu-
racy creates a knowledge base. Emotion recognition techniques let robots understand
people, which can improve HCI.
Keywords Expression recognition · Transfer learning · Histogram equalization ·
Multiclass classiﬁcation · Support vector machine · ResNet50 · Deep learning
S. S. Hiremath
Image Processing, Sony India Software Centre, Pvt. Ltd., Bangalore, Karnataka 560103, India
J. Hiremath
Department of Computer Science and Engineering, Visvesvaraya Technological University,
Belgaum 590018, India
V. V. Kulkarni
Department of CSE, Alvas Institute of Engineering and Technology, Mijar, Moodbidri,
Karnataka 574225, India
B. C. Harshit · M. S. Hiremath (B)
Department of Image Processing, eMath Technology, Pvt. Ltd., Bangalore, Karnataka 560072,
India
e-mail: mrutyunjaya.publications@gmail.com
S. Kumar
Artiﬁcial Intelligence and Machine Learning, VVDN Technologies Pvt. Ltd., Bangalore,
Karnataka 560066, India
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_21
281

282
S. S. Hiremath et al.
1
Introduction
Emotions are not stored [1]. Computers cannot recognize facial expressions [2].
Studies [3] show that facial expressions can identify simple and complicated
emotions. Primary emotions are anger, contempt, fear, pleasure, sadness, and
surprise. No one needs to be taught the six fundamental emotions. Complex
emotions are not innate; everyone has them. Beliefs and morals produce compli-
cated emotions. Emotions reveal the mind, attitude, and behavior. Emotion-reading
machines improve communication. Emotion detection can detect interrogator lies
and enhance gameplay. In education, it can measure student engagement [4].
DeeplearningsurpassesDIYmethods,studiessuggest.Computervisionleverages
deep learning [5]. Deep network training is time- and data-intensive. Rare are large
datasets and robust systems. A neural network’s architecture resembles a brain. Pre-
trained on millions of images, it can do several tasks. Data and actions are ﬁrst-layer
features. CNN layers gather abstract visual information to build a noteworthy feature
and customize data-collection layers. GoogleNet, ResNet, VGGNet [6], and DeepNet
are pre-trained. Using the dataset, these networks may provide task-speciﬁc outputs.
A trained network is needed for CNN image categorization. Test accuracy lowers
with non-network-class photos, moreover, retrain the network. This requires millions
of images and a strong GPU [7]—transfer learning. Transfer learning impacts
fully linked layers. Learned layer weights are entirely related. SVM transfers ﬂat-
tened convolutional basis values. A pre-trained network classiﬁed dataset photos
into seven emotions. Second, a hybrid technique collects information from a pre-
trained network’s FC1000 layer and trains a multiclass nonlinear SVM classiﬁer.
Experiments show that the hybrid method works—block diagram in Fig. 1.
Fig. 1 Block diagram

Facial Expression Recognition Using Transfer Learning with ResNet50
283
2
Literature Survey
CNNs need many data to train. Using millions of photos, researchers trained CNN
for transfer learning. CNN-trained AlexNet research suggests transfer learning alone
might be sluggish. Time-saving SVM classiﬁed AlexNet picture characteristics.
Custom CNNs stink. Visible and thermal imaging was tested. NVIE has a 99.3%
accurate thermal database. CK+’s visual accuracy was 98.3% [1].
Two expression-recognition methods were developed. Classify AlexNet using
transfer learning and VGG19. SVM identiﬁed AlexNet and Vgg19 features. Tech-
niques JAFFE-tested. The proposed system matches the best existing system’s 94%
accuracy. Small datasets are key. CNN-deep shines. CNN learns SVM. VGG19-SVM
cascade is 94% accurate. Train the four JAFFE models and improve the JAFFE Data
[7].
This article improves FaceLiveNet’s emotions on the FER2013 model and
achieved 70%. Transfer learning enhances test accuracy by 12.9% using the FER2013
basic emotion recognition model. The rebuilt model learns map outputs from
eyebrows, chins, and closed eyelids. Integrating image data with the original learning
emotion database boosted the model’s accuracy [8].
This article discusses EmotiW 2017s group-level emotion challenge. We got face
feature vectors from a CNN trained for face recognition, not emotion. An emotion-
predicting random forest classiﬁer ensemble was trained. The method employs Viola-
Jones cascades, HOG features, facial landmarks, and a deep CNN trained for face
recognition to identify faces in a group picture and compute their median attributes.
Determine and Train the RFs with vibrant visuals. EmotiW 2017 is not big enough
to build a feature extractor. Pipeline data accuracy was 75.4%, 23% over the baseline
78.53 [9].
This article describes 2015s static facial expression recognition in the wild sub-
challenge. We ﬁne-tuned an ImageNet-trained network incorporating face expression
and contest data. Cascaded ﬁne-tuning using linked datasets improves results. The
top submission had 48.5% validation and 55.6% test accuracy, versus 35.96% and
39.13% for baseline. CNN’s trained using supplemental facial expression datasets,
and EmotiW can enhance accuracy by 16%. Finally, labeling faces with sensitive
emotions were complex [10].
This document describes state-of-the-art AI solutions (datasets and algorithms).
This study examined detection, extraction, and classiﬁcation with computing
resources. By addressing present and future research difﬁculties, we concluded that
further work is needed, such as FER in 3D face shape models and emotion recognition
in obstructed photos. Real-time FER is difﬁcult [11].
Deep learning emotion recognition framework is discussed. The recommended
strategy speeds up and enhances CNN training with Gabor ﬁlters. Gabor ﬁlters
boost system learning. Gabor ﬁlters extract NN subfeatures. This helps CNN detect
emotions [12].
This study proposes a real-world emotion detection model. VGG13 has more
parameters than LER. FERFIN is quieter and labels better than FERPLUS. This
paper presents a lightweight emotion recognition (LER) model using a convolution

284
S. S. Hiremath et al.
layer and model compression. DenseNet-3 scored 71.73% on FER2013, 0.57% more
than the ﬁrst team. FERPLUS’ validation set gave DenseNet-2 85.58%. DenseNet-
3 is 41-times simpler than VGG13. FERFIN’s 0.21 million-parameter DenseNet-2
model was 85.89% accurate [13].
This paper presents a CNN-KNN hybrid FER model for Raspberry Pi 4. Fully
connected layer, loss function, loss optimizer, learning rate, class weights, and KNN
distance are optimized. The hybrid CNN-KNN model achieved 75.3% accuracy
on Raspberry Pi hardware with limited processing power, memory, and storage, a
0.6% increase over the CNN model, and a 0.1% improvement over state-of-the-
art FER models. The preferred model is 0.7526 and 0.9393. We integrated JAFFE,
KDEF, and FER2013 training data to boost the sample size. We compared pre-trained
EfﬁcientNet FER models. KNN helps CNN [14].
Continuous-dimension face databases are rare (e.g., valence and arousal). We
gathered and recorded spontaneous facial expressions (called AffectNet). Affected
identiﬁes 1,000,000 face photos using 1250 emotion-related keywords in six
languages. Affected is the most extensive facial expression, valence, and arousal
database in the wild. Two baseline DNNs predict valence and arousal. Deep neural
networks surpass machine learning and face emotion recognition. Existing facial
affect datasets cover one model, a few persons, or emotions. Affected-trained DNN
baselines outperformed machine learning [15].
3
Methodology
Figure 1 demonstrates the proposed approach’s workﬂow, including preprocessing,
feature extraction from a pre-trained network, and face emotion classiﬁcation
training. Preprocessing eliminates noise and undesirable pixels from photos in three
phases (Sect. 3.1). These pre-processed pictures are given to the pre-trained network,
andtheFC1000layerfeaturesareretrieved(Sect.3.2).ThistechniqueusesResNet50,
and after extracting features, they are trained using a multiclass nonlinear SVM
classiﬁer to classify emotions, as detailed in Sect. 3.3.
3.1
Preprocessing
Preprocessing enhances image quality for better analysis. By preprocessing, we
may minimize unwanted distortions and increase application-speciﬁc characteris-
tics. Features may vary by application. Face detection, image resizing, and contrast
improvement utilizing histogram equalization are explored in this technique. Figure 2
depicts preprocessing.
Face Detection. Face detection is the initial stage in preprocessing; the face is recog-
nized using the AdaBoost classiﬁer and then cropped. AdaBoost learns multiple weak

Facial Expression Recognition Using Transfer Learning with ResNet50
285
Fig. 2 Preprocessing
ﬂowchart
Input      
Image
Face 
Detection
Image   
Resize
Contrast 
Enhancement
Pre-Processed 
Image
classiﬁers for the training set and combines them into solid classiﬁers. Combining
classiﬁers improves accuracy. AdaBoost classiﬁer employs Haar features for classi-
ﬁcation, as illustrated in Fig. 3. It can differentiate false positives and true negatives
in the data, allowing for a highly accurate model.
Haar Features. Haar wavelets were used in the ﬁrst real-time face detection. These
features compare pixel brightness in adjacent window rectangles by dividing image
subsections. These face detection characteristics are eye and cheek rectangles.
These rectangles are positioned relative to the target’s detection window. The Viola-
Jones object identiﬁcation system drags a target-sized window over the input image
Fig. 3 Haar features [16]
Edge Features
Line  Features
Corner  Features

286
S. S. Hiremath et al.
Fig. 4 Bilinear interpolation
[17]
and generates Haar-like features for each subsection. This is an object-nonobject
threshold.
Resizing. Resizing affects a model’s accuracy and training speed. The face picture
clipped in the previous stage is enlarged to 224 × 224 pixels using OpenCV, which
is required for the ResNet50 input layer. The interpolation method used to resize an
image is INTER LINEAR. Figure 4 and Eq. 1 demonstrate how INTER LINEAR
resizes images using bilinear interpolation.
f (x, y) =
1
(x2 −x1)(y2 −y1)[x2 −xx −x1]
 f (Q11) f (Q12)
f (Q21) f (Q22)
 y2 −y
y −y1

(1)
where
xi, yi = co-ordinates of pixel
Q11 = (x1, y1)
Q12 = (x1, y2)
Q21 = (x2, y1)
Q22 = (x2, y2).
Contrast Enhancement by Histogram Equalization. Histogram equalization
adjusts the contrast to improve visual contrast. Adjusting an image’s intensity
histogram changes its dynamic range and contrast. Equation 2 describes the equal-
ization of the histogram. Figure 5 shows before-and-after histogram equalization; in
Fig. 5a, it can be observed that pixels have low contrast, and in Fig. 5b, these pixels
are moved to high contrast. Table 1 shows the process of face detection and resizing.
h(v) = round
 cdf(v) −cdfmin
(M × N) −cdfmin
× (L −1)

(2)

Facial Expression Recognition Using Transfer Learning with ResNet50
287
Fig. 5 Contrast enhancement using histogram equalization
Table 1 Face detection process and resizing
Input image
Face detected image
Cropped image
Resized image
Size 48 × 48
Size 41 × 41
Size 224 × 224
Size 48 × 48
Size 36 × 36
Size 224 × 224

288
S. S. Hiremath et al.
where
v = value
cdfmin = minimum non-zero value of the cumulative distribution function
(M × N) = image’s number of pixels
L = number of gray levels used.
Algorithm of Contrast Enhancement using Histogram Equalization
Inputs: Resized facial image
Output: Enhanced image with equalized histograms
Step 1. Consider a discrete grayscale image {x} and let ni be the number
of occurrences of gray level i. The probability of an occurrence of
a pixel of level i in the image is
px(i) = p(x = i) = ni
n , 0 ≤i ≤L
where
L = total number of gray levels in the image
n = total number of pixels in the image
px(i) = image’s histogram for pixel value i.
Step 2. The normalized sum of the histogram is calculated using the
cumulative distribution function
cdfx(i) =
i
j=0
px(x = j),
Step 3. The histograms in the input images are equalized using Eq. 2.
3.2
Feature Extraction
Figure 6 depicts feature extraction. Feature extraction is a type of dimensionality
reduction where a considerable number of pixels are efﬁciently represented to capture
exciting elements of the image, which helps determine a person’s expression. Pre-
trained ResNet50 network from the latest FC1000 layer delivers 2048 features per
picture.

Facial Expression Recognition Using Transfer Learning with ResNet50
289
Fig. 6 Process of feature
extraction
Pre-Processed 
Image
Pre-Trained 
ResNet50
FC1000
3.3
Training
Figure 7 depicts the suggested categorization ﬂow. Training incorporates pre-trained
ResNet50 network and multiclass nonlinear SVM with seven classes.
Transfer learning involves ﬁnding parallels between known and unfamiliar infor-
mation to gain new knowledge. This learning focuses on transferring knowledge
between the source and target domains. Figure 8 demonstrates the model’s training
and validation accuracy.
ResNet50 Network. ResNet50 network’s 49 convolution layers for training are
layered into three layers and one fully linked layer. The network receives pre-
processed training pictures. Transfer learning is superior. FC1000 layer features
from the pre-trained network are used for nonlinear SVM classiﬁcation utilizing
radial basis function (RBF) kernel. Figure 9 and Table 2 exhibit ResNet50 details.
Equations 3, 4, and 5 demonstrate convolution, ReLu, and SoftMax.
Equation 3 describes the convolution layer in a pre-trained network.
( f ∗g)(t) =
∞

−∞
f (τ)g(t −τ)dτ
(3)
where
f = signal
g = impulse function
t = time series
τ = deviation.
Equation 4 describes the ReLu layer in a pre-trained network.
f (x) = max(0, x)
(4)
where
x = input to a neuron.

290
S. S. Hiremath et al.
Read the 
Database Path
Load the 
Images
Split the Images 
into Training/
Validation/Testing 
(0.7/0.1/0.2)
Load the Pre-
Trained 
Network
Create Augmented 
Training Dataset
Extract Features 
from FC layer with 
Training Dataset
Train using 
Multiclass SVM 
Classifier
Knowledge     
Base
Perform 
Prediction
Calculate Evaluation 
Parameters & 
Confusion Matrix
Create Augmented 
Testing Dataset
Extract Features 
from FC layer with 
Testing Dataset
Fig. 7 Classiﬁcation ﬂowchart
Equation 5 describes the SoftMax layer in a pre-trained network.
σ(z)i =
ezi
K
j=1 ez j = for i = 1, . . . , K and z = (z1, . . . , zK) ∈RK
(5)
where
z = input vector
K = real number.

Facial Expression Recognition Using Transfer Learning with ResNet50
291
Fig. 8 Training curve
SVM. SVM is a standard supervised classiﬁcation and regression method. Classiﬁers
like it. It isolates n-dimensional or multidimensional target classes. SVM’s primary
purpose is to construct the optimum decision boundary (with the most signiﬁcant
margin) to categorize new data points. Multiple lines/decision boundaries may exist
in n-dimensional space. We still want the most straightforward data-categorizing
decision boundary. SVM hyperplane is introduced. Dataset characteristics determine
hyperplane dimensions. Margin-maximizing hyperplanes are created. This margin
restrictsdata-pointdistance.Findahyperplanethatdividesn-dimensionaldatapoints.
The kernel calculates x–n and x–m distances. Datapoints closer together score higher.
Figure 10 depicts SVM’s kernel.
RBF kernel, similar to K-nearest neighborhood algorithm, is utilized. It beneﬁts
KNNandavoidsthespacecomplexityproblembyonlystoringsupportvectorsduring
training. RBF kernels are employed in several kernelized machine learning methods
like SVM classiﬁcation. Equation 6 demonstrates RBF kernel math.
k
	
⃗xi, ⃗x j

= exp

−γ
⃗xi −⃗x j
2
for γ > 0
(6)
where
⃗xi, ⃗x j = feature vectors
γ =
1
2σ 2
σ = free parameter.
Training’s knowledge base is developed. The classiﬁcation performance parame-
ters are measured using test data or pictures. The testing data goes via preprocessing,
feature extraction, and knowledge base.

292
S. S. Hiremath et al.
Fig. 9 Architecture of
ResNet50

Facial Expression Recognition Using Transfer Learning with ResNet50
293
Table 2 ResNet50
architecture details
Layer name
Output size
Layers
Conv1
112 × 112
7 × 7, 64, stride 2
Conv2
56 × 56
3 × 3 Max pool, stride 2
[1 × 1, 64
3 × 3, 64
1 × 1, 256] × 3
Conv3
28 × 28
[1 × 1, 128
3 × 3, 128
1 × 1, 512] × 4
Conv4
14 × 14
[1 × 1, 256
3 × 3, 256
1 × 1, 1024] × 6
Conv5
7 × 7
[1 × 1, 512
3 × 3, 512
1 × 1, 2048] × 3
1 × 1
Average pool
1000-d fully connected
SoftMax
Fig. 10 Linear and nonlinear SVM
4
Experimental Results
4.1
Dataset
The data are 48 × 48 grayscale faces. Faces are automatically registered, so they
are centered and occupy the same area in each shot. Figure 11 depicts the 7-class
database.
This method uses Kaggle’s 7-category dataset. The dataset is 70:10:20 for training,
validation, and testing, respectively. All sets have seven category data, including
the training set used to train the model, the testing set to assess its accuracy, and

294
S. S. Hiremath et al.
Fig. 11 Confusion matrix
the validation set to select and optimize the best model. Table 3 illustrates various
database pictures, while Table 4 provides an overview.
The aim is to categorize each face by emotion (0 = angry, 1 = disgust, 2 = fear,
3 = happy, 4 = sad, 5 = surprise, 6 = neutral). The training set has 28,709 samples,
and the test set has 3589; however, only training set photos were evaluated.
4.2
Experimental Setup
This model has a 10th-generation i-7 CPU, Windows-10 64-bit OS, 6 GB Nvidia
GTX, and 8 GB RAM.
4.3
Performance Evaluation
The model’s performance is measured by speciﬁcity, accuracy, precision, recall,
F1-score, and ROC curve. Speciﬁcity, accuracy, precision, recall, and F1-score are
expressed mathematically in Eqs. 7, 8, 9, 10, and 11—Fig. 11 displays the confusion
matrix, a classiﬁcation performance evaluation using expected and actual values.
Table 5 shows the parameter measures.

Facial Expression Recognition Using Transfer Learning with ResNet50
295
Table 3 Database images
Classes
Images
Angry
Disgust
Fear
Happy
Neutral
(continued)

296
S. S. Hiremath et al.
Table 3 (continued)
Classes
Images
Sad
Surprise

Facial Expression Recognition Using Transfer Learning with ResNet50
297
Table 4 Detailed overview of dataset
Classes
Image size
Number of
images
Training images
After
augmentation
Testing images
Angry
48 × 48
3995
3196
5772
799
Disgust
48 × 48
436
348
5772
88
Fear
48 × 48
4097
3277
5772
820
Happy
48 × 48
7215
5772
5772
1443
Neutral
48 × 48
4965
3972
5772
993
Sad
48 × 48
4830
3864
5772
966
Surprise
48 × 48
3171
2536
5772
635
Speciﬁcity =
True Negatives
True Negatives + False Positives
(7)
Accuracy = Total number of Correct Predictions
Total number of Predictions
(8)
Precision =
True Positives
True Positives + False Positives
(9)
Recall =
True Positives
True Positives + False Negatives
(10)
F1 score = 2 ∗
 precision ∗recall
precision + recall

(11)
Figure 12 plots the true positive rate (TPR) against the false positive rate (FPR)
to construct the ROC curve. Table 6 provides a comparison with other methods for
the FER2013 database.
Table 5 Performance
parameter measures
Parameters
Results
Speciﬁcity
98.806
Accuracy
89.923
Precision
98.368
Recall
89.862
F1-score
93.932

298
S. S. Hiremath et al.
Fig. 12 ROC curve
Table 6 Comparison with
other methods for the
FER2013 dataset
Methods
Accuracy (%)
Ensemble approach [18]
73.73
Ensemble approach [19]
71.236
VGG16 [20]
67.2
Proposed approach
89.923
5
Conclusion and Future Scope
Comparing detection, extraction, and classiﬁcation techniques employing transfer
learning with a pre-trained ResNet50 network and multiclass nonlinear SVM clas-
siﬁer with seven classes yields good results and increased training speed for face
emotion identiﬁcation. After categorization using pre-processed data or pictures,
ResNet50 network accuracy is 77.3%. After implementing transfer learning by
training extracted features from pre-trained ResNet50 network by passing pre-
processed photos to identify the expression using multiclass nonlinear SVM algo-
rithm, accuracy increased to 89.923%. Transfer learning increases model correct-
ness. More reliable results can be achieved in the future by using videos and 3D
architecture.

Facial Expression Recognition Using Transfer Learning with ResNet50
299
References
1. Shaees S, Naeem MR, Naeem H, Syed H, Arslan M, Aldabbas H (2020) Facial emotion
recognition using transfer learning. https://doi.org/10.1109/ICCIT-144147971.2020.9213757
2. Hablani R, Chaudhari N, Tanwani S (2013) Recognition of facial expressions using local binary
patterns of ımportant facial parts. Int J Image Process (IJIP) IJIP-738 7(2). ISSN (online)
1985-2304
3. Ekman P, Davidson RJ (1994) The nature of emotion: fundamental questions
4. Cao X, Wang Z, Yan P, Li X (2013) Transfer learning for pedestrian detection. Neurocomputing
100:51–57
5. Li S, Deng W (2018) Deep facial expression recognition: a survey. arXiv preprint arXiv:1804.
08348
6. Swapna M, Sharma YK, Prasad B (2020) CNN architectures: AlexNet, LeNet, VGG,
GoogleNet, ResNet. Int J Recent Technol Eng (IJRTE) 8(6):953–959. https://doi.org/10.35940/
ijrte.f9532.038620
7. Hablani R (2020) Facial expression recognition using transfer learning on deep convolutional
network. Biosci Biotechnol Res Commun 13:185–188. https://doi.org/10.21786/bbrc/13.14/44
8. Hung J, Lin K-C, Lai N-X (2019) Recognizing learning emotion based on convolutional neural
networks and transfer learning. Appl Soft Comput 84:105724. https://doi.org/10.1016/j.asoc.
2019.105724
9. Rassadin A, Gruzdev A, Savchenko A (2017) Group-level emotion recognition using transfer
learning from face identiﬁcation. In: Proceedings of the 19th ACM international conference
on multimodal interaction (ICMI’17). Association for Computing Machinery, New York, NY,
USA, pp 544–548. https://doi.org/10.1145/3136755.3143007
10. Ng H-W, Nguyen VD, Vonikakis V, Winkler S (2015) Deep learning for emotion recognition
on small datasets using transfer learning. In: Proceedings of the 2015 ACM on ınternational
conference on multimodal ınteraction (ICMI’15). Association for Computing Machinery, New
York, NY, USA, pp 443–449. https://doi.org/10.1145/2818346.2830593
11. Patel K et al (2020) Facial sentiment analysis using AI techniques: state-of-the-art, taxonomies,
andchallenges.IEEEAccess8:90495–90519.https://doi.org/10.1109/ACCESS.2020.2993803
12. Taghi Zadeh MM, Imani M, Majidi B (2019) Fast facial emotion recognition using convo-
lutional neural networks and gabor ﬁlters. In: 2019 5th Conference on knowledge-based
engineering and ınnovation (KBEI), pp 577–581. https://doi.org/10.1109/KBEI.2019.8734943
13. Zhao G, Yang H, Yu M (2020) Expression recognition method based on a lightweight convolu-
tional neural network. IEEE Access 8:38528–38537. https://doi.org/10.1109/ACCESS.2020.
2964752
14. Ab Wahab MN, Nazir A, Zhen Ren AT, Mohd Noor MH, Akbar MF, Mohamed ASA
(2021) Efﬁcientnet-lite and hybrid CNN-KNN ımplementation for facial expression recogni-
tion on Raspberry Pi. IEEE Access 9:134065–134080. https://doi.org/10.1109/ACCESS.2021.
3113337
15. Mollahosseini A, Hasani B, Mahoor MH (2019) AffectNet: a database for facial expression,
valence, and arousal computing in the wild. IEEE Trans Affect Comput 10(1):18–31. https://
doi.org/10.1109/TAFFC.2017.2740923
16. Viola P, Jones M (2001) Rapid object detection using a boosted cascade of simple features. In:
Proceedings of the 2001 IEEE computer society conference on computer vision and pattern
recognition, CVPR 2001, vol 1. IEEE

300
S. S. Hiremath et al.
17. Khosravi MR, Samadi S (2021) BL-ALM: a blind scalable edge-guided reconstruction ﬁlter
for smart environmental monitoring through green IoMT-UAV networks. IEEE Trans Green
Commun Network 5(2):727–736
18. Gan Y, Chen J, Xu L (2019) Facial expression recognition boosted by the soft label with a
diverse ensemble. Pattern Recogn Lett 125:105–112
19. Renda A, Barsacchi M, Bechini A, Marcelloni F (2019) Comparing ensemble strategies for
deep learning: an application to facial expression recognition. Expert Syst Appl 136:1–11
20. Dhankhar P (2019) Resnet-50 and Vgg-16 for recognizing facial emotions

Classiﬁcation of Microorganisms
from Sparsely Limited Data Using
a Proposed Deep Learning Ensemble
Gautam Chettiar, Amogh Shukla, Hemprasad Patil, and Sumit Jindal
Abstract With the recent advancements in medicine and biotechnology, there is
always a growing need for more sophisticated decision systems to aid in certain
biological factors, such as detecting a pathogen or microscopic organism and its
accurate classiﬁcation. In such a domain, there is very little tolerance for error, and
the highest priority must be given to creating intelligent systems capable of doing
so. Advancements in computer vision and other state-of-the-art image processing
techniques enable computation systems to extract and analyze principal features
from a specimen that even a trained eye may otherwise miss. There has also been
an upsurge in the research on the applications of machine learning to aid in speciﬁc
surgical procedures and diagnostic tests. Classifying organisms at the micro-scale is
an essential stepping stone for their long-term success. The study aims to ensembling
the best machine learning techniques and models in the computer vision domain, such
as transfer learning, top-performing models, and image preprocessing methods, to
maximize the capabilities of a typical image classiﬁcation model for a sparse and
limited multi-labeled class dataset containing microscopic images and hence shed
light and explore into how more excellent performance can be obtained while facing
classical dataset limitations.
Keywords Image preprocessing · Transfer learning · Microorganism dataset ·
Ensemble models · TensorFlow · Computer vision
G. Chettiar (B)
Department of Communication Engineering,Vellore Institute of Technology,
Vellore, Tamil Nadu 632014, India
e-mail: chettiargautam@gmail.com
A. Shukla
Department of Software Systems,Vellore Institute of Technology,
Vellore, Tamil Nadu 632014, India
H. Patil · S. Jindal
Department of Embedded Technology,Vellore Institute of Technology,
Vellore, Tamil Nadu 632014, India
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_22
301

302
G. Chettiar et al.
1
Introduction
Microorganisms are ubiquitous. They are present all around us and are mostly imper-
ceptible to the naked eye. They can be generally divided into two subcategories,
namely harmful and benign. The ones considered at the diagnostics level are gener-
ally the harmful ones, and timely and accurate detection can save the patient from
fatality. The benign ones are all around us, such as the food we consume, the water
we drink, and so on. Yeast, probiotics, antibiotics, etc., are typical examples of
such microorganisms in our daily lives. Advancements in computer vision prompt
lesser dependence on the morphology of such microorganism data sources and more
reliance on automated decision systems to discriminate such data.
This domain has had increasing amounts of research for a long time. The applica-
tion of Multi-Layer Perceptrons (MLP) began this endeavor, and signiﬁcantly, more
advanced Convolutional Neural Networks (CNN) architectures were introduced for
the classiﬁcation task.
The critical factor in the success of multi-class labeled datasets is the quantity of
available data. For instance, the Environment Microorganism Image Dataset (EMDS-
5) [2] consists of well-captured images of microorganisms, which contain original
photos and the ground truth of those images. This allows signiﬁcantly better perfor-
mance due to the preprocessed segmentation feature that can be implemented using
ground truth images. It contains 21 types of Environment Microorganisms (EM),
with each class containing 20 kinds of original images per each EM and 20 Ground
Truth (GT) images.
However, with the sample space of such EM’s increasing rapidly, today being at
around 1012 specimens in the species, the need for a model which can adapt to more
speciﬁc datasets without any signiﬁcant structure or preprocessing and which can
carry out classiﬁcations on such EM’s which may have been captured from diverse
sources is critical, and having sparse datasets combined to form another dataset based
on labels alone simulates such a case very well. A very accurate representation of a
dataset for EMs where multiple images within each class have signiﬁcant variance
yet belong to the same species is the Microorganism Image Classiﬁcation dataset [2]
obtained from a Kaggle repository.
Similar datasets have been explored, and image classiﬁcation tasks are carried out
using optimal CNN architectures such as LeNet-5, VGG-16, ResNet-18, AlexNet,
VGG-19, ResNet-34, and so on [3]. Another study also applied the computation-
ally intensive DenseNet-201 model to classify EMs from the EMDS dataset while
carrying out hyperparameter optimization for generating an optimally ﬁne-tuned
DenseNet-201 model called optimally ﬁne-tuned DenseNet-201 (OFTD) [4].
Another recent study has implemented optimized deep-learning image models for
a similar use case. The testing was conducted on computationally limited devices
(Android phones) [5] and found signiﬁcant performance due to model ﬁne-tuning and
pruning to handle the version and inferential time capabilities. The scope for research
in this domain is still plentiful, and developments at any scale can signiﬁcantly shape

Classiﬁcation of Microorganisms from Sparsely Limited Data …
303
the future toward more intelligent systems that reduce morphology and ultimately
depend on computing systems to nullify the scope for error. At the same time, the
designs are practical for deployment at a civil level for general public use.
Multilayered Perceptrons (MLP) also have seen good results when coupled with
higher-ordered features [6] for classiﬁcation tasks for tabulated data. Transforma-
tions for some 1D and 2D signals [7] may also be applied to generate better results
depending on the nature of the data. However, generally, CNN models perform best
[8] for image data, even for different types of biomedical image data. Some image
processing techniques, such as CLAHE [9], can signiﬁcantly boost the performance
of even simple CNN models.
2
Literature Survey
Wang et al. [10] explore conjugate polymer-based approaches for pathogen sensing
and detection based on structural variations at the peripheral level. This provides
a signiﬁcant advantage in the pathogenic discrimination process. The authors aim
to extrapolate the approach in the discrimination of microscopic organisms in the
detection and discrimination of pathogens such as the SaRS-COVID-19 virus.
Ma et al. [11] carry out an elaborative survey of the detection techniques,
which cover the breadth of image processing techniques and classical deep-learning
approaches that have been worked upon in the domain of microorganism image
analytics. They rightly note the complications of the detection task due to the cornu-
copia of such species (1011–1012) and the acquisition complexity with accurate image
representations from sources such as microscopes. Their survey encompasses tech-
niques such as segmentation, image fusion, image transformation, and other critical
methods in the detection process.
Kulwa et al. [12] propose a segmentation-based approach for classifying micro-
scopic images christened PDLF-Net. The authors explore the RGB images following
ground truth analysis and identify critical points used in patch generation. Transfer
learning is then used via the application of VGG-16 on the generated patches, which
is then used to create pairwise feature maps. Stacked over the base model is the
SEGNet, which trains on the feature maps to develop segmented images of the
ground truth. The imposed preprocessing techniques were applied to limited vis-
ibility microorganism images to produce higher-signiﬁcance feature maps for the
classiﬁcation task.
Zhang et al. [13] propose an SEM-RCNN model for classifying multi-class
microorganisms. They introduce novelty in the multi-class detection of EM by com-
bining on top of the ResNet architecture a SENet block which instantiates a self-
attention mechanism for optimal feature extraction. The approach includes a region
proposal framework post-feature map selection. Transfer learning was implemented
on the SENet model, which was pretrained. The authors ﬁnally used hyperparameter
optimization to obtain suitable learning rates and epochs for maximum accuracy.

304
G. Chettiar et al.
Prada et al. [14] review the recent advancements in methods of discrimination
and detection of microorganisms. They explore a variety of bioprocesses as well
as computation methods such as Raman Spectroscopy and the application of deep
CNN models in identifying complex microorganism samples. They also signify that
ﬂuorescent nanoparticles that attach themselves at localized target particle sites and
post-ﬂuorescence-inducing processes make the classiﬁcation task signiﬁcantly more
straightforward due to conspicuous lamination.
Shao et al. [15] propose a novel architecture based on compiling a vision trans-
former and CNN structure. They carry out Environmental Microorganism (EM)
classiﬁcation. Their proposed HTEM model is deployed in four stages, which begin
with token embeddings, followed by a feature embedding layer, which is then fed
into the transformer encoders and ﬁnally fed into a local Feed Forward Network
(FFN) block. They outperform other CNN-based models and the Xception network
by 9.02%.
Zhang et al. [16] explore applications of ANNs in recognizing microorganism
images. Their review consists of the most popular Image Net models starting from
MLP to CNN models and ﬁnally coming to the current vision transformers in the
biological detection ﬁeld, which aims to apply ML to supersede microorganism
morphology. They explore publicly available datasets such as SIPPER, EMDS, and
WHOI-Plankton.
Rani et al. [17] reviewed different automated methods for detecting microorgan-
isms from image data. The authors also emphasize the performance of CLAHE and
region extraction methods, such as the RF method, during the testing phase. They
also generally support using Support Vector Machines with a linear kernel for the
classiﬁcation task. However, they recommend CNN-based models in the end.
Kulwa et al. [18] carried out a review of various segmentation techniques for
image data for the detection of microorganisms. They employ different edge-based
segmentation techniques such as Canny edge detection, etc. They also use binariza-
tion techniques such as Otsu Binarization for the ground truth analysis, which is
later used in segmentation and helps provide proposed regions. They ﬁnd promise
in using models such as VGG-16 and U-Net.
Narain Ponraj et al. [19] conducted a comprehensive survey of image prepro-
cessing techniques for a biomedical image data use case. The authors explored the
applicability of enhancement techniques such as CLAHE and operators such as
Sobel, Gaussian, Laplacian, Prewitt, etc., for edge detection of the image data. They
also explored image transforms such as the Gabor transform, wavelet transforms,
curvelet transforms, etc.
3
Methodology
A model is proposed, which is an ensemble of optimally ﬁne-tuned and pruned
EfﬁcientNetB7 via a transfer learning approach, the architecture of InceptionV3 with
small amounts of pruning, and a custom deep CNN architecture that is ensembled into

Classiﬁcation of Microorganisms from Sparsely Limited Data …
305
one classical stacking structure which is topped off with a voting ensemble structure
to take the best of three predictions which will act as the ﬁnal decision of the whole
ensemble. Even before the model description and creation, a signiﬁcant amount of
preprocessing is carried out on the microorganism dataset [2]. Transfer learning is
highly successful in the classiﬁcation task and preprocessing of the dataset images.
3.1
Dataset
The Microorganism Image Classiﬁcation dataset consists of around 800 images of
variable resolutions belonging to one of the eight labels: Amoeba, Yeast, Euglena,
Spiral Bacteria, Hydra, Rod Bacteria, and Paramecium. There is an unequal distribu-
tion of data on each of the labels. The dataset used may be less impressive regarding
the universe of discourse, the number of samples, or the quality of the pieces. The
dataset images are of varying brightness, color saturation, noise levels, resolution,
and intra-class correlative relevance. The requirement of preprocessing for obtain-
ing image coherence for optimal model training is key to such data limited tasks. Its
primitive nature and the high level of variance on a small subset of images make it
challenging to train a model on it. Still, it is a good representation of how classiﬁca-
tions would take place in real life, giving it signiﬁcance for this purpose. The uneven
class distribution is shown in Figs.1 and 2.
Fig. 1 Class distribution of the images in the dataset based on proportions

306
G. Chettiar et al.
Fig. 2 Class distribution of the images in the dataset based on the count
As mentioned in the Introduction section, even images with the same labels have
high variability and variance. It becomes a task to train a model under such data
characteristics, especially given the small dataset size. An example training batch
from the dataset is shown in Fig.3.
Figure3 shows the sample batch from the training data. A model that can gen-
erate unique features for each label to distinguish the classes accurately while data
limitation is a unique research aspect.
The sparseness of dataset can be seen by viewing multiple images within the same
class. It is conspicuous that these RGB images, while under a single class, are weak
representations of each other. Hence, sparsely limited data stems from the idea of
having a small sample size that is not signiﬁcantly intra-class correlated.
3.2
Data Prepossessing
Data Preprocessing The images in the dataset are limited in number. Hence, they must
be appropriately preprocessed to utilize each of the microorganisms’ components and
generate signiﬁcant feature maps during model training. For image preprocessing,
multiple techniques are used.
First, the image is fed into a custom ﬁlter bank which consists of a Mean, Median,
and Gaussian Filter. This proposed ﬁlter ensemble conjointly averages and elimi-
nates the noise present in the 2D image data. Following this step, the image then
undergoes saturation modulation to enhance the color vibrancy and sharpness by
adaptively increasing the saturation of the image data. The saturation increment fur-
ther intensiﬁes the power of each of the color channels and hence results in a brighter

Classiﬁcation of Microorganisms from Sparsely Limited Data …
307
Fig. 3 Sample batch from the training data
and more vivid colored image, hence increasing vibrancy. After this step, to tackle
the lower resolution images, the highly efﬁcient Super Resolution CNN (SR-CNN)
model is used [20] with a transfer learning setup, and the resolutions of the images are
signiﬁcantly improved. The application of the SR-CNN model is necessary for the
dataset being used as some of the images present have lower resolution and quality
and can provide more meaningful features during training if reconstructed properly.
Finally, CLAHE is used to get sharper edges in the ﬁnal stage of the picture. The
entire preprocessing block is shown in Fig.4.
For ﬁltering the unwanted noise in the image, the proposed approach uses a
custom ﬁltering ensemble. Some of the mathematical operations used are below.
The equations for the Mean ﬁlter, Median Filter, and Gaussian Filter are given in (1),
(2), and (3), respectively for each pixel Pi, j.
This preprocessing process ﬂow is then tested against sample images to juxtapose
their intermediate outputs at relevant stages to see the signiﬁcance of the various
blocks included in the process. The results of the preprocessing are shown in Fig.5a
and b.

308
G. Chettiar et al.
Fig. 4 Preprocessing setup
for image data
From Fig.5a and b, it’s clear that the preprocessing block is generating signiﬁ-
cantly better images from the original rudimentary image data. These preprocessed
images were then fed into model training and testing. This concludes the preprocess-
ing carried out in the proposed approach.
All the class labels are converted into their One-Hot Encoded form to create a
multi-class classiﬁcation problem. This transforms the task into a probability selec-
tionproblemwheretheclasswiththehighestprobabilityisdeemedtheclassobtained.
3.3
Model Creation
The approach aims at creating a model that can utilize the best of all types of learning.
It can be seen that there are cases that two images within the same class are dras-
tically different, but may not differ a lot from images from other classes. To tackle

Classiﬁcation of Microorganisms from Sparsely Limited Data …
309
Fig. 5 Filter bank application, saturation modulation, SR-CNN resolution modulation, and CLAHE
output juxtaposed against the original image for a Euglena and b Amoeba
this classical problem, there is a need for a complex, robust, and feature sensitive
imageclassiﬁcationmodel.Toovercomethis,theproposedapproachadoptsastacked
ensemble structure and employs a Voting Classiﬁer module as the ﬁnal decision unit
for the model. The model consists of three pipelines. The ﬁrst is a transfer learning-
based EfﬁcientNetB7 model. The EfﬁcientNetB7 consistently ranked well on the
benchmarking tests on the MNIST dataset and is also computationally not too ambi-
tious, making it a viable option after signiﬁcant pruning to run on computationally
weaker devices such as smartphones or other edge devices.
The second pipeline has an instantiation of an adapted version of the InceptionV3
architecture. The Inception model is better in some cases due to its smaller and
factorized convolutions, which may take a little time for the training but require lesser
computation resources for the model ﬁtting and testing. The standalone InceptionV3
model also performs well on similar datasets as well.
Finally, the third pipeline is a distilled and pruned version of a VGG model, with
much lesser layers and starts from smaller convolutions and builds up to medium
size ﬁlters. It is computationally very inexpensive, has fewer features at the pooling
stage, and produces signiﬁcant overall performance results.

310
G. Chettiar et al.
Fig. 6 Implemented architectures of a EfﬁcientNetB7 and b custom deep CNN
The EfﬁcientNetB7 implemented architecture is shown in Fig.6a. The standard
InceptionV3 architecture is used from the original description. The custom deep
CNN is shown in Fig.6b.
All the models use the Adam optimizer with the Sparse Categorical Cross-Entropy
loss function during model compilation. Each of the standalone models is initially
trained separately with 50 epochs and a batch size of 32. In the ﬁnal ensemble, these
models are then put in a Voting Classiﬁer framework which uses hard voting for
classiﬁcation.
From Fig.5a and b, it’s clear that the preprocessing block is generating signiﬁ-
cantly better images from the original rudimentary image data. These preprocessed
images were then fed into model training and testing. This concludes the preprocess-
ing carried out in the proposed approach.

Classiﬁcation of Microorganisms from Sparsely Limited Data …
311
Fig. 7 Proposed
classiﬁcation ensemble
With all the base models and processing in place, the study proposed its complete
ensembledmodelforthemicroorganismdataﬁttingadtesting.Theentirearchitecture
is shown in Fig.7.
3.4
Results
The model was trained and tested on the image data from the dataset. Two hundred
images were kept aside for testing purposes. Initially, the standalone models were
evaluated to test for performance, and ﬁnally, the ensemble model’s accuracy was
compared to individual components. The results found are given in Table1.
The results from Table1 show the proposed ensemble’s performance and viability.
The reason behind the model’s performance was the preprocessing techniques, the
choice of supporting base models, and having a reliable Voting Classiﬁer with the
Softmax nature of predictions.
The ﬁnal accuracy, loss, parameter, and time quantum metrics of the individual
and ensembled models can be seen from the box plots in Fig.8a–d.

312
G. Chettiar et al.
Table 1 Performance metrics of the standalone and the proposed ensemble models
Model
Parameters (M)
Accuracy (%)
Loss
Time per step
(ms)
EfﬁcientNet B7
69
96.50
0.1005
101
InceptionV3
24
95.50
0.1063
127
Custom deep CNN
5
95.00
0.1670
14
Proposed ensemble
100
97.50
0.0865
137
Fig. 8 Performance metrics in terms of a accuracy, b loss, c number of parameters, and d time per
step
4
Conclusion
There is a signiﬁcant requirement for reliable and sustainable algorithms and meth-
ods in biomedical data, speciﬁcally the microorganism detection domain. The study
only explores one of the many possibilities while considering a highly pragmatic

Classiﬁcation of Microorganisms from Sparsely Limited Data …
313
dataset having high variability even for the data belonging to the same class. The
proposed ensemble is not computationally too expensive, having just a little over
100 M parameters as shown in Fig.8c, and making predictions within a period of
about 150ms. It can also deliver signiﬁcant results with minimal model training and
a minimal data sample space and get up to 97.50% accuracy due to its inherent voting
nature. The development of more advanced image preprocessing techniques based
on either edge detection or region proposition or exploring more sophisticated mod-
els such as vision transformers poses higher accuracies and performance metrics for
even sparser datasets having even more limited data. While it is traditionally believed
that high-quality data with superior images is required to train a good-performance
machine learning model, this approach shows that even sparse and limited data with
the appropriate processing can obtain signiﬁcant results. The goal of such research
is to provide the medicine and biotechnology industry with pragmatic advancements
and methods to aid in their morphology process, avoid any scope for human errors,
and potentially save plenty of lives.
References
1. Li Z, Li C, Yao Y, Zhang J, Rahaman MM, Xu H et al (2021) Environmental microorganism
image dataset ﬁfth version for multiple image analysis tasks. PLoS ONE 16(5):99–110. https://
doi.org/10.10007/1234567890
2. Waquar (2022) Micro-organism image classiﬁcation. Kaggle. https://doi.org/10.34740/
KAGGLE/DSV/4032122
3. Poomrittigul S, Chomkwah W, Tanpatanan T, Sakorntanant S, Treebupachatsakul T (2022)
A comparison of deep learning CNN architecture models for classifying bacteria. In: 2022
37th International technical conference on circuits/systems, computers and communications
(ITC-CSCC), pp 290–293. https://doi.org/10.1109/ITC-CSCC55581.2022.9894986
4. Chen W, Liu P, Lai C, Lin Y (2022) Identiﬁcation of environmental microorganism using
optimally ﬁne-tuned convolutional neural network. Environ Res 206:112610. ISSN 0013-9351,
https://doi.org/10.1016/j.envres.2021.112610
5. Kim HE, Maros ME, Siegel F, Ganslandt T (2022) Rapid convolutional neural net-
works for gram-stained image classiﬁcation at inference time on mobile devices: empirical
study from transfer learning to optimization. Biomedicines 10:2808. https://doi.org/10.3390/
biomedicines10112808
6. Uma Venkata Ravi Teja K, Pavan Venkat Reddy B, Likith Preetham A, Patil HY (2021) Poorna
Chandra T (2021) Prediction of diabetes at early stage with supplementary polynomial features.
In: Smart technologies, communication and robotics (STCR), pp 1–5. https://doi.org/10.1109/
STCR51658.2021.9588849
7. Uma Venkata Ravi Teja K, Pavan Venkat Reddy B, Alla LP, Patil HY (2021) Parkinson’s disease
classiﬁcation using quantile transformation and RFE. In: 2021 12th International conference
on computing communication and networking technologies (ICCCNT), pp 01–05. https://doi.
org/10.1109/ICCCNT51525.2021.9580024
8. Hebbar N, Patil HY, Agarwal K (2020) Web powered CT scan diagnosis for brain hemor-
rhage using deep learning. In: 2020 IEEE 4th Conference on information & communication
technology (CICT), pp 1–5. https://doi.org/10.1109/CICT51604.2020.9312098
9. Patil P, Patil H (2020) X-ray imagining based pneumonia classiﬁcation using deep learning
and adaptive clip limit based CLAHE algorithm. In: 2020 IEEE 4th Conference on informa-

314
G. Chettiar et al.
tion & communication technology (CICT), pp 1–4. https://doi.org/10.1109/CICT51604.2020.
9312089
10. Wang F, Ma M, Cao H, Chai X, Huang M, Liu L (2022) Conjugated polymer materials for
detection and discrimination of pathogenic microorganisms: guarantee of biosafety. Biosaf
Health 4(2):79–86. ISSN 2590-0536, https://doi.org/10.1016/j.bsheal.2022.03.006
11. Ma P, Li C, Rahaman MM et al (2022) A state-of-the-art survey of object detection techniques
in microorganism image analysis: from classical methods to deep learning approaches. Artif
Intell Rev. https://doi.org/10.1007/s10462-022-10209-1
12. Kulwa F, Li C, Grzegorzek M, Rahaman M, Shirahama K, Kosov S (2023) Segmentation of
weakly visible environmental microorganism images using pair-wise deep learning features.
Biomed Signal Process Control 79(Part 2):104168. ISSN 1746–8094. https://doi.org/10.1016/
j.bspc.2022.104168
13. Zhang J, Ma P, Jiang T, Zhao X, Tan W, Zhang J, Zou S, Huang X, Grzegorzek M, Li C
(2022) SEM-RCNN: a squeeze-and-excitation-based mask region convolutional neural net-
work for multi-class environmental microorganism detection. Appl Sci 12:9902. https://doi.
org/10.3390/app12199902
14. Prada P, Brunel B, Reffuveille F, Gangloff SC (2022) Technique evolutions for microor-
ganism detection in complex samples: a review. Appl Sci 12:5892. https://doi.org/10.3390/
app12125892
15. Shao R, Bi X-J, Chen Z (2022) A novel hybrid transformer-CNN architecture for environmental
microorganism classiﬁcation. PLoS ONE 17(11):e0277557. https://doi.org/10.1371/journal.
pone.0277557
16. Zhang J, Li C, Yin Y et al (2022) Applications of artiﬁcial neural networks in microorganism
image analysis: a comprehensive review from conventional multilayer perceptron to popular
convolutional neural network and potential visual transformer. Artif Intell Rev. https://doi.org/
10.1007/s10462-022-10192-7
17. Rani P, Kotwal S, Manhas J et al (2022) Machine learning and deep learning based com-
putational approaches in automatic microorganisms image recognition: methodologies, chal-
lenges, and developments. Arch Comput Methods Eng 29:1801–1837. https://doi.org/10.1007/
s11831-021-09639-x
18. Kulwa F et al (2019) A state-of-the-art survey for microorganism image segmentation methods
and future potential. IEEE Access 7:100243–100269. https://doi.org/10.1109/ACCESS.2019.
2930111
19. Narain Ponraj D et al (2011) A survey on the preprocessing techniques of mammogram for the
detection of breast cancer. J Emerg Trends Comput Inf Sci 2(12):656–664
20. Chao D, Loy Change C, Kaiming H, Xiaoou T (2014) Image super-resolution using deep
convolutional networks. IEEE Trans Pattern Anal Mach Intell 38. https://doi.org/10.1109/
TPAMI.2015.2439281

Assiduous Study
of the Hyperparameters’ Inﬂuence
on CNN Using COVID-19 CT Images
Srinivasa L. Chakravarthy
, Varun Mallela, Vedula Sai Sarvanth,
Rohith Sunkara, and Srimurari Dachepalli
Abstract The SARS-CoV-2 virus causes the infectious COVID-19 disease. It is
rapidly spread, and resulted in a global pandemic. Every disease should be diagnosed
so that the process of diagnosis can avoid long-term complications and also have a
chance to increase the efﬁciency of the treatment. Similarly, COVID-19 should also
be diagnosed and can be done in several ways. One of many ways is the Nucleic Acid
Ampliﬁcation Tests (NAAT). Due to some deﬁciencies in those tools or methods,
experts have recommended CT images as a diagnostic tool for detecting the COVID-
19 virus more accurately and quickly. This study has used a dataset consisting of
349 COVID-19-affected CT scans and 463 regular CT scans. In classical computers,
neural networks remain as the powerful classiﬁcation models. So, this study has built
a Convolution Neural Network (CNN) model and achieved an accuracy of 98.6% and
also tested the impact of various hyperparameters on the model, such as activation
function, input shape, image rotation, number of layers, and epochs. We plotted
different accuracy graphs for each parameter and found an optimal solution to be
used in the model to improve the accuracy.
Keywords COVID-19 · Convolution Neural Network · CT scans ·
Hyperparameters · Classical computers
1
Introduction
COVID-19 is a dreadful disease that can cause mild to severe respiratory illness
and even death, resulting in a global pandemic. Many people now believe that
they can resume to normal lives as the virus spread minimize, but new variants
are emerging. So this research study has taken COVID-19 data for analysis [1].
For manual diagnosis of COVID-19, molecular tests need to be performed. Molec-
ular tests are also referred to as Reverse Transcription Polymerase Chain Reaction
(RT-PCR) test, Nucleic Acid Ampliﬁcation Test (NAAT), and Reverse Transcription
S. L. Chakravarthy (B) · V. Mallela · V. Sai Sarvanth · R. Sunkara · S. Dachepalli
Department of CSE, GITAM University, Visakhapatnam, India
e-mail: chakri.ls@gmail.com
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_23
315

316
S. L. Chakravarthy et al.
Loop-Mediated Isothermal Ampliﬁcation (RT-LAMP) test. These tests involve the
collection of samples from the nasal or throat, which some people are not comfort-
able with and even from collecting samples, one may have a chance to get infection
if there is no hygiene followed in the process. RT-PCR test is valuable and func-
tional but there are some chances of getting false results. Also, if there are excessive
samples, it will take more time to get results. So, another alternative for diagnosing
COVID-19 is using CT scans and X-rays [2]. CT scan is also not completely efﬁcient
and advisable as it emits X-ray radiation but it can be used as an alternate method
[3, 4].
Deep learning (DL) is a subﬁeld of data science. Deep learning incorporates
predictive analysis modeling and statistics. It is a neural network that tries to simulate
the human brain, and this network usually has a minimum of three layers or more.
It still works for single or two layers but by adding more layers, an optimal solution
and accuracy can be obtained [5]. In this ﬁeld, the system learns from experience
and trains its network [6]. At every stage, the amount of data keeps increasing, which
increases system accuracy by training the model to more data. In deep learning, many
types of neural networks exist, like convolutional, recurrent, and artiﬁcial networks.
This research work mainly involves the recognition of CT images, its classiﬁcation
and results prediction by observing the image patterns [7, 8]. All these tasks poses
the signiﬁcant functionality of a convolutional neural network (CNN). An essential
feature of CNN is that it can discover image features and extract them without any
manual help. In CNN, ﬁrst, the simple image patterns, like surroundings, edges, and
lines are identiﬁed followed by complex crux patterns. CNN will be valid for this
research study by extracting patterns from COVID-19 and non-COVID-19 CT scans,
and this classiﬁcation model will be trained to diagnose the virus.
The proposed objective is to build and train a model to identify the presence of
COVID or not using CT scans of lungs and improve the model’s performance by
ﬁnding the best value for various input parameters. This study has considered layers,
activation functions, epochs, input shape, and resize.
2
Related Work
Erdi ACAR and Ihsan YILMAZ [9] performed COVID-19 detection on various
quantum real processors like IBMQx2, IBMQ-London, and IBMQ-Rome using the
quantum transfer learning method. In this study, the ResNet18 convolutional network
has been used as a feature extractor to obtain a ﬁnal result of a 90% success rate in
classical computers and 94–100% in quantum computers. In this study [10], the
authors developed a deep learning-based automated classiﬁcation model based on
a convolutional neural network that exhibits a high COVID-19 detection rate. They
used a data set that contains 3616 COVID-19 chest X-ray pictures and 10,192 images
of healthy chest images. They have trained the data by using various CNN models.
Among all the deployed CNN models, MobileNetV2 produced an accuracy of 98%
for classifying COVID-19 and healthy chest X-rays.

Assiduous Study of the Hyperparameters’ Inﬂuence on CNN Using …
317
In this study [11], chest X-rays are used for detection instead of PCR tests. The
dataset the authors have considered is inadequate to train deep neural networks.
So, they used a concept called Domain Extension Transfer Learning (DETL). They
employed DETL with a pre-trained deep convolution neural network on a large chest
X-ray dataset. In this paper [12], they have described pneumonia cases with chest
X-rays or CT scans. The dataset they used is used to study the progress of COVID-
19 and how its radiological ﬁnding varies from other pneumonia such as MERS,
SARS, and ARDS. They used the dataset to build tools that predict pneumonia
and its outcome. The authors have conducted a study [13] to analyze the CT scans
over time in COVID-affected patients. They have considered 90 patients with an
average age of 45. A total of 366 CT scans have been acquired and studied by two
radiologists for patterns, abnormalities, and CT scores. Their observation is that the
lung abnormalities have peaked during the 6–11th days of infection.
To overcome the absence of professional doctors in distant regions and effectively
identify COVID-19, Ozturk et al. [14] developed a novel method for the automated
detection of COVID-19 using unprocessed chest radiography images. The authors of
this work have used the DarkNet model as their classiﬁer and created 17 convolutional
layers with various ﬁlters. The proposed model has been developed to offer precise
diagnostics for binary and multi-class classiﬁcation; the accuracies obtained are
98.08% and 87.02%, respectively. The authors, Chauhan et al. [15], developed CNN
models on image recognition and detection datasets to assess their performance. They
used MNIST and CIFAR-10 datasets for recognition. The MNIST model’s accuracy
is 99.6%, and CIFAR-10’s accuracy is 80.17%.
Authors Kang et al. proposed to use a set of traits generated from CT scans
to diagnose COVID-19 [16]. The suggested multi-view representation learning
approach yielded 95.5%, 96.6%, and 93.2% in accuracy, sensitivity, and speciﬁcity,
respectively. The author Guefrechi et al. [17] has utilized three robust networks,
namely InceptionV3, VGG16, and ResNet50 have all been ﬁne-tuned using compiled
COVID-19 and standard casket X-ray pictures from several open databases. The
experimental results show promise for the suggested models; they classiﬁed the X-
ray pictures as normal or COVID-19 with an accuracy of 97.20 for Resnet50, 98.10
for InceptionV3, and 98.30 for VGG16.
Narin et al. [18] proposed ﬁve pre-trained convolutional neural network-based
modelsinthisstudy(ResNet50,ResNet101,ResNet152,InceptionV3,andInception-
ResNetV2) for the detection of coronavirus pneumonia infected patients utilizing
chest X-ray radiographs. According to the performance ﬁndings, the pre-trained
ResNet50 model outperforms the other four models’ classiﬁcation performance.
Apostolopoulos et al. [19] examined the issue of automatically categorizing lung
disorders from X-ray scans, including the recently discovered COVID-19. They
used Mobile Net to imply that training CNNs from scratch may disclose important
biomarkers connected to the COVID-19 disease but not exclusively. The overall
classiﬁcation accuracy of the seven classes is 87.66%.

318
S. L. Chakravarthy et al.
3
Methodology
This study trains and validates a CNN model to classify CT images into COVID-19
and non-COVID-19 [4, 6]. Figure 1 provides an overview of the method of this study.
To build a CNN, ﬁrst, we added convolutional layers to work with a 2D image. Next,
we added a pooling layer to reduce the size of the feature map by 2. We have taken
the minimum size of the pool to retain the information in the image. Later we added
several convolutions and pooling layers to improve the model’s accuracy. We have
added a ﬂattening step to get the input node of connected layers. We also added a
hidden and drop-out layer to prevent overﬁtting and implemented the output layer.
Figure 1 illustrates an implementation of the CNN model for the binary classiﬁcation
of COVID-19 [20].
3.1
Data Set
We have used an open-source dataset named ‘COVID-CT’ [21] to train and validate
the model. This dataset contains 349 CT images of COVID positive from 216 patients
and 463 non-COVID-19 CT images. A senior radiologist has conﬁrmed the utility of
this dataset in Tongji Hospital, Wuhan, China, and has diagnosed and treated many
COVID-19 patients during the outbreak of this disease between January and April.
We have also referred to various other COVID-CT image datasets [22]. Figure 2
illustrates two examples of CT images taken from the dataset.
3.2
Input Parameters
We have tested various values for different parameter inputs to improve the model’s
training and validation accuracy [25]. We tried multiple parameters like the number
of layers, epochs, input shape, and image orientation. The goal was to observe the
model’s behavior with changes in the values of different hyperparameters.
Fig. 1 CNN model implementation for classiﬁcation of COVID-19 and non-COVID-19

Assiduous Study of the Hyperparameters’ Inﬂuence on CNN Using …
319
Fig. 2 a COVID-19 CT image, b non-CT image
3.2.1
Layers and Epochs
A neural network is a collection of input and output units that are connected, and
in which each node has a weight. Each neural network model comprises one input
layer, one output layer, and several hidden layers. The inputs go through the input
layer before being simultaneously weighted and fed to the hidden layers. The inputs
to the output layer are the weighted outputs of the ﬁnal hidden layer.
Here, we have implemented several neural network models with a different
number of layers in each model. At ﬁrst, we implemented the neural network model
with only one layer (no hidden layers), then we added a hidden layer. We continued
this approach till we got similar values. We observed that as the number of layers
increases, the time taken to run the model decreases. The number of layers is inversely
proportional to the time taken or the model’s speed.
We have also considered the epochs. The term epoch is the number of passes the
machine learning algorithm has made across the training dataset. Here, an epoch is
how often the algorithm came across each image. We have kept the model in the for
loop where the epoch gets incremented by 10 in each iteration.
The methodology adopted is being implemented in both aspects together. At ﬁrst,
we considered the neural network model with only one layer. We have ﬁt the model
in the for loop where the number of epochs changes per iteration. In the ﬁrst iteration,
we have considered ten epochs; in the 2nd iteration, we have considered 20 epochs,
and this process continues till the 50 epochs (5 iterations). The exact process is
implemented on the models by increasing the layers.
3.2.2
Activation Function
Another parameter that we analyzed is activation functions. We employed three
activation functions for the input layer, whereas we used two for the output layer.
In total, we got 6 cases only for this parameter. We tested for all six cases at the
same values for batch_size, steps_per_epoch, and the same number of epochs. Our
objective for this parameter is to obtain an optimal activation function. We can get
an optimal solution when accuracy is high, and there is no signiﬁcant overﬁtting. We

320
S. L. Chakravarthy et al.
have calculated the training and validation accuracy of various activation functions
for 20 epochs with 50 steps_per_epochs and ten validation_steps.
The most common functions used are ReLU for the input layer and sigmoid for
the output layer. We have observed better accuracy (training and validation) for this
case than in other cases. Even for the Tanh function, we got high accuracy but some
overﬁtting. We got low accuracy for the sigmoid activation function (for the input
layer), i.e., ﬁfty percent. We got the same accuracy for all three input functions when
we used the softmax function for the output layer. Compared to other scenarios, the
time required to train the model using the ReLU activation function for 20 epochs is
long.
ReLU is the most used activation function as it is simple and fast. It returns 0 for
negative value input and returns the same value when it receives a positive value.
Simply we can write it as f (x) = max(0, x). The sigmoid activation function is also
known as the logistic function. Input for this function can be any real value, and
output values will be 0 to 1. It is used for both input and output layers. Tanh function
is also called a hyperbolic tangent function. It is the same as the sigmoid function of
input values, but this output will be from −1 to 1.
3.2.3
Input Shape
Input shape is the dimension of the input image, which is given as input to the convo-
lutional neural network (CNN). This image data is processed in various layers to
detect important features of the image. The input dimension contains three parame-
ters—width, height, and number of channels. Here, channel three is used and tested
all images. This study has tested different values of input shapes like (100, 100, 3),
(200, 200, 3), (250, 250, 3), (300, 300, 3), (400, 400, 3), (500, 500, 3). For all the
results, we have used 20 epochs with every 32 steps.
3.2.4
Image Orientation
The image orientation is a value representing the degree of rotation of the image. This
study is experimented with different degrees, such as 0, 45, 90, 135, 180. The training
accuracy and validation accuracy are different for other degrees. They sometimes
increase and sometimes decrease, and time varies with an increase in degrees. Here,
horizontal ﬂips are implemented to randomly ﬂip images horizontally. The proposed
model is trained by using 30 epochs, each consisting of 50 steps.
4
Results
We have divided the dataset into three groups. We have allocated 500 (71%) images
for training, 100 (15%) images for validation, and 96 (14%) images for testing. We

Assiduous Study of the Hyperparameters’ Inﬂuence on CNN Using …
321
Fig. 3 The plot of training
and validation accuracy of
the model
initially used a CNN model with four convolutional and four max pool layers to get
accurate results. The activation function used was ReLU, and the input shape was
(150, 150, 3). This study has used 20 epochs and 32 steps per epoch. Using these
inputs, a training accuracy of 98.6% and a validation accuracy of 69% are obtained.
The plot of training and validation accuracies of the model can be viewed in Fig. 3.
4.1
Effect on the Model for Change in Epochs and Layers
As said earlier, this study has considered the model with one layer and then created
different models by incrementing the layers. In each model, 150 epochs are consid-
ered; instead of taking all 150 epochs in a single iteration, ten epochs are considered
in the ﬁrst iteration, 20 in the second, and so on to 50, which took ﬁve iterations in
total. This study has considered it in ﬁve iterations to calculate the time taken by the
model for each iteration. As the layers increases, the time taken will be decreased;
that is, the speed of the model increases. It took nearly 2 h and 40 min to run a model
with one layer, and time gets better as the number of layers increase. It took only 1 h
and 20 min to run all 150 epochs in a 5-layer model, and as the number of epochs
increases, the model’s accuracy improves. The presented observations revealed that
ﬁve layers and 50 epochs have yielded optimal results. Table 1 presents the accu-
racies for various layers and epochs. Figure 4 illustrates the training and validation
accuracies for an optimal number of layers and epochs.

322
S. L. Chakravarthy et al.
Table 1 Accuracies for various values of the number of layers and epoch
Layers
Epochs
Training ACC
Validation ACC
Time taken (s)
1
10
0.7960
0.7300
0525.178
1
20
0.9960
0.7300
1307.459
1
30
0.9900
0.7300
1865.404
1
40
0.9920
0.7300
2752.529
1
50
0.9920
0.7400
3104.194
2
10
0.8380
0.7000
0377.077
2
20
0.9600
0.7500
0754.744
2
30
0.9680
0.7500
01,122.74
2
40
0.9800
0.7500
1524.468
2
50
0.990
0.7600
1919.499
3
10
0.7340
0.7100
0324.433
3
20
0.8660
0.7800
0676.332
3
30
0.9300
0.7500
1057.160
3
40
0.9660
0.7500
1449.042
3
50
0.9700
0.8400
1714.577
4
10
0.5940
0.5500
0330.513
4
20
0.7220
0.7500
0704.983
4
30
0.8220
0.8100
0918.060
4
40
0.8960
0.8100
1327.355
4
50
0.9620
0.8000
1620.744
5
10
0.4640
0.5300
0326.641
5
20
0.6180
0.6500
0684.216
5
30
0.7780
0.7800
0909.295
5
40
0.9400
0.8400
1300.090
5
50
0.9880
0.8000
1525.510
Fig. 4 The plot of training
and validation accuracy for
ﬁve layers and 50 epochs

Assiduous Study of the Hyperparameters’ Inﬂuence on CNN Using …
323
4.2
Effect on the Model for Changes in the Activation
Function
ReLU has shown to be more accurate than sigmoid and Tanh in training and valida-
tion. We obtained good accuracy even for the Tanh function, albeit with considerable
overﬁtting. We got 50% accuracy for the sigmoid activation function (for the input
layer). When we applied the SoftMax function for the output layer, we acquired an
accuracy of about 50% for all three input functions. Compared to other examples, the
time needed to train the model using the ReLU activation function for 20 epochs is
high at 753 s. Therefore, ReLU and Sigmoid are the best activation functions for the
input and output layers, respectively. Figure 5 illustrates the training and validation
accuracies for the optimal input and output activation functions. Table 2 presents all
the accuracies for different activation functions.
Fig. 5 Plots of training and
validation accuracy when
input and output activation
function are ReLU and
Sigmoid
Table 2 Accuracies for various activation functions
S. No
I/P function
O/P function
Training ACC
Validation ACC
Time taken (s)
1
ReLU
Sigmoid
0.7560
0.7600
753.24
2
ReLU
SoftMax
0.5000
0.5100
693.75
3
Sigmoid
Sigmoid
0.5020
0.4900
699.72
4
Sigmoid
SoftMax
0.5000
0.5100
716.41
5
Tanh
Sigmoid
0.8340
0.7200
706.30
6
Tanh
SoftMax
0.5000
0.4800
697.02

324
S. L. Chakravarthy et al.
Fig. 6 Plots of training and
validation accuracy when
input shape is (250, 250, 3)
Table 3 Accuracies for various values of input size
S. No
Input shape
Training ACC
Validation ACC
Time taken (s)
1
(100, 100, 3)
0.9020
0.6700
325
2
(200, 200, 3)
0.9840
0.6900
1529
3
(250, 250, 3)
0.9860
0.6700
1597
4
(300, 300, 3)
0.9900
0.6500
2767
5
(400, 400, 3)
0.9840
0.7700
3768
6
(500, 500, 3)
1.0000
0.7900
4893
4.3
Effect on the Model for Change in Input Shape
To check the effect of various values of input size on the model, we have used 20
epochs for each value and 32 step sizes. It was observed that training accuracy and
execution time increased as the dimension of the input shape increased. Maximum
accuracy was seen when the input shape was (500, 500, 3), taking around 4900 s
for execution. It was also observed that the accuracy values remained the same
beyond the input (500, 500, 3). The optimal input shape found was (250, 250, 3).
This input shape produced an accuracy of 98.6% taking around 1597 s, as it has a
high accuracy enough for the model validity. Figure 6 illustrates the training and
validation accuracies for optimal dimension of the input shape. Table 3 presents all
the accuracies for various values of inputs values of input size.
4.4
Effect on the Model for Change in Image Orientation
These are the results obtained for the parameter’s different rotation ranges. The
model with four layers is considered and then created other models with varying

Assiduous Study of the Hyperparameters’ Inﬂuence on CNN Using …
325
Fig. 7 Plots of training and
validation accuracy when
image orientation is 135°
Table 4 Accuracies for various values of image orientations
S. No
Angle of rotation (°)
Training ACC
Validation ACC
Time taken (s)
1
0
0.6300
0.5800
1093
2
45
0.6400
0.6600
1024
3
90
0.7000
0.6500
995
4
135
0.7300
0.6600
1017
5
180
0.7400
0.6400
1080
rotation ranges. In each model, 30 epochs are considered. We have considered it in
ﬁve iterations to calculate the time taken by the model for each iteration. We have
found that the accuracy continuously increases with an increase in rotation range. As
the rotation range increases, the time taken will also decrease; that is, the model’s
speed increases. The model’s execution took maximum time, i.e., 17 min, with a
rotation range of 180°. Through the proposed research work, we found that 135°
rotation of the image has yielded the optimal results. Figure 7 illustrates the training
and validation accuracies for the optimal CT image orientation. Table 4 presents all
the accuracies for various values of image orientation.
5
Conclusion
The accurate testing of COVID-19 can be done through CT scans. This article has
designed and developed a CNN model for diagnosing COVID-19 using CT images
to be run in a classical machine. We have taken the data required for modeling from
an open-source COVID-CT dataset. Initially, we made and trained a CNN model to
obtain a training accuracy of 98.6% and a validation accuracy of 69%. This obtained
accuracy shows that the proposed model can accurately diagnose COVID-19 and
is suitable for clinical purposes. We have continued our research by observing the

326
S. L. Chakravarthy et al.
impact of various hyperparameter values like activation function, input shape, image
orientation, number of epochs, and layers on the model. We have found optimal
solutions for each parameter to improve the model’s accuracy. According to our
observations, we found that using ﬁve input layers, 50 epochs, ReLU as input layer
activation function, and sigmoid as output layer function, (250, 250, 3) as the input
shape and 135° rotation of the CT image have yielded the best optimal results. In the
future, we wish to implement and run this model in GPUs and Quantum Machines
and compare its performance to classical computers.
References
1. Bernheim A, Mei X, Huang M, Yang Y, Fayad Z, Zhang N, Diao K, Lin B, Zhu X, Li K et al
(20202) Chest CT ﬁndings in coronavirus disease-19 (covid-19): relationship to duration of
infection. Radiology 200463
2. Ai T et al (2020) Correlation of chest CT and RT-PCR testing in coronavirus disease 2019
(COVID-19) in China: a report of 1014 cases. Radiology 200642
3. Shan F, Gao Y, Wang J, Shi W, Shi N, Han M, Xue Z, Shen D, Shi Y (2020) Lung infection
quantiﬁcation of covid-19 in CT images with deep learning. arXiv preprint arxiv:2003.04655
4. Wang S, Kang B, Ma J, Zeng X, Xiao M, Guo J, Cai M, Yang J, Li Y, Meng X et al (2020)
A deep learning algorithm using CT images to screen for corona virus disease (covid-19).
medRxiv
5. Chen J, Wu L, Zhang J, Zhang L, Gong D, Zhao Y, Hu S, Wang Y, Hu X, Zheng B et al (2020)
Deep learning-based model for detecting 2019 novel coronavirus pneumonia on high-resolution
computed tomography: a prospective study. medRxiv
6. Gozes O, Frid-Adar M, Greenspan H, Browning PD, Zhang H, Ji W, Bernheim A, Siegel E
(2020) Rapid AI development cycle for the coronavirus (covid-19) pandemic: initial results
for automated detection and patient monitoring using deep learning CT image analysis. arXiv
preprint arxiv:2003.05037
7. Xu X, Jiang X, Ma C, Du P, Li X, Lv S, Yu L, Chen Y, Su J, Lang G et al (2020) Deep learning
system to screen coronavirus disease 2019 pneumonia. arXiv preprint arXiv:2002.09334
8. Chowdhury ME, Rahman T, Khandakar A, Mazhar R, Kadir MA, Mahbub ZB, Islam KR, Khan
MS, Iqbal A, Al-Emadi N et al (2020) Can AI help in screening viral and covid-19 pneumonia?
arXiv preprint arxiv:2003.13145
9. Acar E, Yilmaz I (2021) COVID-19 detection on IBM quantum computer with classical-
quantum transferlearning. Tur J Electr Eng Comput Sci 29(1). Article 4
10. Akter S, Javed Mehedi Shamrat FM, Chakraborty S, Karim A, Azam S (2021) COVID-19
detection using deep learning algorithm on chest X-ray images. Biology 10(11):1174. https://
doi.org/10.3390/biology10111174
11. Basu S, Mitra S, Saha N (2020) Deep learning for screening COVID-19 using chest X-ray
images
12. Cohen JP, Morrison P, Dao L (2020) COVID-19 image data collection. arXiv:2003.11597
13. Wang Y, Dong C, Hu Y, Li C, Ren Q, Zhang X, Shi H, Zhou M (2020) Temporal changes of CT
ﬁndings in 90 patients with COVID-19 pneumonia: a longitudinal study. Radiology 200843.
PMID: 32191587
14. Ozturk T, Talo M, Yildirim EA, Baloglu UB, Yildirim O, Acharya UR (2020) Automated
detection of COVID-19 cases using deep neural networks with X-ray images. Comput Biol
Med 121:103792
15. Rahul C, Kamal Kumar G, Joshi RC (2018) Convolutional neural network (CNN) for image
detection and recognition. https://doi.org/10.1109/ICSCCC.2018.8703316

Assiduous Study of the Hyperparameters’ Inﬂuence on CNN Using …
327
16. Kang H, Xia L, Yan F, Wan Z, Shi F et al (2020) Diagnosis of coronavirus disease 2019
(COVID-19) with structured latent multi-view representation learning. IEEE Trans Med
Imaging 39(8):2606–2614. https://doi.org/10.1109/TMI.2020.2992546
17. Guefrechi S, Jabra MB, Ammar A, Koubaa A, Hamam H (2021) Deep learning based detec-
tion of COVID-19 from chest X-ray images. Multimed Tools Appl 80(21–23):31803–31820.
https://doi.org/10.1007/s11042-021-11192-5, Epub 2021 Jul 19. PMID: 34305440; PMCID:
PMC8286881
18. Narin A, Kaya C, Pamuk Z (2021) Automatic detection of coronavirus disease (COVID-19)
using X-ray images and deep convolutional neural networks. Pattern Anal Appl 24:1207–1220.
https://doi.org/10.1007/s10044-021-00984-y
19. Apostolopoulos ID, Apostolopoulos DJ, Papathanasiou ND (2022) Deep learning methods to
reveal important X-ray features in COVID-19 detection: investigation of explain ability and
feature reproducibility. Reports 5(2):20. https://doi.org/10.3390/reports5020020
20. Hamza H, Salim N, Nasser M, Saeed F (2020) Meramalnet: a deep learning convolutional
neural network for bioactivity prediction in structure-based drug discovery. 21–37. https://doi.
org/10.5121/csit.2020.100203
21. https://github.com/UCSD-AI4H/COVID-CT
22. Cohen JP, Morrison P, Dao L (2020) Covid-19 image data collection. arXiv preprint arxiv:
2003.11597

Academic Dishonesty Detection in Exams
Using Pose Extraction
Dhanush Binu and Sivaiah Bellamkonda
Abstract Academic dishonesty has been a signiﬁcant setback to the proper func-
tioning of educational institutions worldwide, as cheating in examinations is a signif-
icant and persistent issue contributing to academic dishonesty. With cases of cheating
in examinations increasing year after year, it can be asserted that traditional invigila-
tion and monitoring methods are ineffective. This work proposes a method to analyze
cheating behavior in examination halls through pose estimation. First, we analyze the
frame for any movement using a motion detection algorithm. The marked frame is
sent to the pose extraction phase, where the pose of the person/persons present in the
frame is extracted and given to the machine learning model, which identiﬁes whether
a student has been cheating. Furthermore, the frame marked with face recognition
is stored for later use, along with the time and name of the student, in a separate ﬁle
for reference.
Keywords Pose extraction · Computer vision · Inter-frame difference method ·
Machine learning
1
Introduction
Every year, thousands of examinations are conducted worldwide, ranging from small
class tests to more prominent ones such as civil services examinations, entrance
examinations, and many more. More than 60.8% admitted to cheating on tests, but
only 95% of students are caught, and most students engaging in these acts have high
grades. This issue could evolve into a signiﬁcant issue as it could cause a decrease
in the grades of motivated students, causing them to have lower percentile scores.
Teachers have a hard time trying to catch those deceptive students. Hence, in most
cases, they are relieved with little to no consequences due to professors/teachers
having little to no evidence. In order to counter this, video-based surveillance has
D. Binu (B) · S. Bellamkonda
Department of Computer Science and Engineering, Indian Institute of Information Technology
Kottayam, Kottayam, Kerala, India
e-mail: dhanush2019@iiitkottayam.ac.in
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_24
329

330
D. Binu and S. Bellamkonda
been proposed. Christopher et al. [1] try to answer several questions about video-
based surveillance systems’ efﬁcacy. It was concluded that video surveillance is
helpful since it provides investigative evidence, dissuading students from copying
since they are being watched. Making efﬁcient use of this conventional technology
method of video surveillance is not advised since it is also prone to human errors. The
paper concluded that the efﬁciency of automated Closed Circuit Television (CCTV)
systems would be signiﬁcantly improved to conventional usage.
Before the emergence of deep learning techniques, most research papers used IoT
methods for cheating detection. Hoque et al. [2] use a high-sensitive microphone
and 360° CCTV cameras to monitor and control the examinations. It also makes
use of biometric readers for authentication purposes. With the proposed system,
the number of invigilators can be severely reduced, and the examination can be
controlled more conveniently. Fang et al. [3] use a monitoring and seat calibration
module with an alarm that goes off if any suspicious activity is detected. This article
proposes an improved model that can extract and analyze the scene of unusual infor-
mation features and provide a threshold algorithm to ﬁne-tune the alarm to detect
any abnormalities in the examination hall.
The development of Computer Vision has led to intelligent video surveillance
systems [4, 5]. Intelligent video surveillance has been in commercial use for a
long time. Nevertheless, intelligent video surveillance in classrooms has yet to be
implemented, even though researchers are doing relevant research.
Exam cheating mainly involves students taking the help of some external source
to solve exam questions. The techniques for cheating differ between an online and
an ofﬂine (on-site) exam, but the most common cheating techniques are writing on
hand or referring to small pieces of paper. Students tend to hide these papers in their
pockets. After they are done referring to these papers, they discard them, or in the
case of hand-writings, they rub them off. Most prefer to look into their other paper by
turning their head, trading papers that contain answers and communication through
gestures since these are much easier and have comparatively low risk as opposed to
writing on pieces of paper. Douglas et al. [6] analyze all the different techniques by
which a student tries to cheat. The most prominent methods detailed in this paper are
through the use of (i) body, (ii) seating arrangement, (iii) by use of foreign materials,
and (iv) by use of technological devices. Since, in most cases, the student actively
moves some parts of the body, analyzing one’s posture can yield valuable insights
into how a student copies. Human pose estimation is a ﬁeld in computer vision that
has seen tremendous amounts of research in recent years. Cao et al. [7] proposed a
human pose estimation system to identify and track the key points of a person. These
key points can be stored and used to monitor changes in a person’s body. Human
pose estimation has been used in many applications such as Fall Detection, Activity
or ﬁtness monitoring systems. Research in human pose has reached a point where
libraries such as TensorFlow and P5 are used to implement pose estimation and gait
analysis in browsers, as described in [8]. This paper investigates different ways to
predict and analyze different methods to detect cheating and proposes a novel method
using human pose detection.

Academic Dishonesty Detection in Exams Using Pose Extraction
331
2
Related Work
Samir et al. [9] implement a multi-person proctoring system. The model ﬁrst takes
inputfromthewebcam.Theinputmayconsistofsingleormultiplepeople.Themodel
then decides whether to single or multiple pose estimation. Pose extraction is done
using the Tensorﬂow-PoseNet model on the input footage. The key points extracted
are analyzed using a complex algorithm that considers the essential keypoints: the
nose, eyes, and ears. The algorithm then applies equidistance formulas to these
key points to calculate abnormal positions. The algorithm applies the equidistance
formula since the key points scale with distance off-camera. The model also tracks
hand position using the x-axis and y-axis position of the wrist keypoints. If the x-axis
of the wrist keypoints is far from the head, and the y-axis is not exceeding the head
level, then abnormality is reported. The model was tested in varying environments
and with different cheating variables that can be controlled. The model performed
well in both experiments, with an average detection accuracy of 95 and 92.3% in
abnormal head and hand movement.
Maniar et al. [10] combine various models, such as Eye Gaze tracking, Mouth
movement detection, Head Pose Estimation, Object detection, and Person counting
model, to detect if a student has engaged in malpractice. Once the student is ﬂagged
twice, he/she will be warned. If the student continues to get ﬂagged, the exam will
stop, and she will not be able to continue writing the exam. The system will send the
user data to the cloud so the teacher can cross-check the candidate. Sometimes, the
user may be ﬂagged due to technical issues and false model predictions. In that case,
invigilators can manually check each candidate. Face detection is the key feature
since it depends on eye tracking and mouth movement detection. Hence several
models were compared, and the DNN module in OpenCV provided the best result.
For Eye Gaze detection Dlib is utilized since it can make predictions in real-time. As
far as Mouth movement detection is concerned, the distance between the key points
of the lips is recorded and measured.
For object detection, pre-trained yolov3 is used. For head pose detection, the angle
of the head is recorded. There is also an audio-to-text converter that uses Google’s
speech recognition API to record audio and convert it into text. Words spoken by
the examinee are compared with the question paper, and the common words are
reported to the invigilator. Nishchal et al. [11] propose a model that consists of posture
detection using OpenPose, ALEXNET model for detecting the type of cheating,
emotion analysis, face recognition, and ﬁnally, report generation. A custom dataset
was created with over 1000 normalized images of size 224*224. There are four
main types of classes (Bending back, stretching the arms behind, bending down, and
facing the camera). Kohli et al. [12] implement a 3D convolutional neural network to
classify abnormal gestures and objects from a training sample of size 7638. The paper
also draws a comparison between LSTM and RNN networks. Riaz et al. [13] apply
a pre-trained model for pose detection and key point extraction. These key points
are then passed on to a high-dimension convolutional neural network. Mahmood
et al. [14] implement a cheating detection algorithm using a regional convolutional

332
D. Binu and S. Bellamkonda
neural network. This neural network detects if the examinees are cheating using head
movements and are mainly used for detecting the students in the examination hall.
The paper also implements a face detection and recognition system using Multi-
Task Cascaded Neural Network. The model is trained exclusively to monitor and
control many students in a single frame. With the onset of the pandemic, research on
online exam proctors has accelerated. Razan et al. [15] implement an online exam
supervision system that uses eye-tracking software to calculate the student’s gaze.
The student has cheated if any abnormality is detected in the values obtained from
the eye-tracker [16].
3
Proposed Work
3.1
Dataset
The surveillance video of the examination room is typically unavailable to the public
due to reasons concerning applicants’ privacy. As a result, the related data cannot
be collected in publicly available datasets. Hence, a custom dataset is prepared and
used in this work, consisting of images taken with different angles and lighting with
an equal number of images for each of the ﬁve labels. Image augmentation has been
done on the dataset using the augmentor library to increase the training samples so
that the model can diversify between minute details. The dataset was created with
images of a single person for more accurate key point extraction. Every image is then
scaled to a height of 800 with the aspect ratio preserved.
3.2
System Overview
The input from the video surveillance camera is passed through a motion detector,
which captures frame samples of where the movement has occurred. This frame is
passed through a face detection algorithm, which helps identify the student. The
frame is then passed through a pose extraction pipeline which outputs the key points.
Working pipeline of the system is shown in Fig. 1.
These key points are then analyzed to determine if the student has cheated, then
the student’s name and the time are noted on an excel sheet. The following sections
explain each of the above models in detail.

Academic Dishonesty Detection in Exams Using Pose Extraction
333
Fig. 1 Working pipeline of the system
3.3
Inter-Frame Difference Method
Inter-frame difference method is used to detect any motion that has happened in the
video input. In practice, the current and previous frames is taken and the absdiff
method in OpenCV is used to ﬁnd the difference and then dilute it. The output
obtained is then passed through a threshold function, where the minimum and
maximum threshold values. A threshold value can be adjusted so that small amounts
of unnecessary motion get ﬁltered out. Finally, the algorithm checks for any contours
which could suggest if any motion was captured on the frame, and if the amount of
contours in the image is greater than one, then the image is passed on to the pose
extraction stage. Nakashima et al. [16] describe how to detect motion using the inter-
frame difference method. They ﬁrst determine the difference between the present and
previous frames and binarize the resultant. The binarized image is then expanded and
contracted for better processing. Using the careful observation of the histogram, the
model can determine if any motion was present in the frame and also calculate the
object’s position in motion.
3.4
Face Recognition
Face recognition was implemented using the face recognition module in python. This
module provides functions to retrieve the face encodings and the location of each face
in the image. This encoding is then compared with the encoding of the faces stored
in the project directory, and if it matches, then the model stores this information. It is
easy to use and provides 99.38% accuracy on the Labeled Faces in the Wild Dataset.
With this module, the tolerance/sensitivity. Real-time face recognition can also be
performed using this module. The snapshot of the person found cheating is captured

334
D. Binu and S. Bellamkonda
Fig. 2 Working demonstration of face recognition system
and stored in a separate directory. The model takes these images and compares them
in real-time. If the person matches, the frame is stored in another directory for later
inspection. The person’s name and the occurrence’s time are recorded and stored as
a comma-separated value (CSV) ﬁle.
Working demonstration of face recognition system is shown in Fig. 2.
3.5
Pose Extraction
After several experiments, it was found that MediaPipe provided the best results.
Hence MediaPipe is used for pose extraction to extract the person’s pose in the image.
When all the landmark points are connected, a human pose is a set of coordinates
describing a person’s pose. MediaPipe uses a high-ﬁdelity pose-tracking model that
extracts approximately 33 different landmarks. This model was used since it is a
widely popular model for pose extraction. First, the MediaPipe model is declared
with minimum detection conﬁdence of 0.5 and minimum tracking conﬁdence of 0.5.
The model returns each key point as a list of the x-axis, y-axis, z-axis, and visibility
values. These values are ﬂattened using the ﬂatten() function and concatenated into
a single array. The array contains 132 elements. MediaPipe also has functions that
help draw the key points over the image. This model can also be used when more
than one person is in the frame. Demonstration of pose extraction model is shown in
Fig. 3.
3.6
Model Training
The images in the dataset are resized into common values. The images are then
marked into ﬁve categories. If the person turns behind, then the image is marked as
0. If the person looks down to cheat, then the person is marked as 1. If the person
looks into his hands, the image is marked as 2. If the person looks to the left, the image
is marked as 3. Normal behavior is marked as 4. If the person looks to the right, the

Academic Dishonesty Detection in Exams Using Pose Extraction
335
Fig. 3 Demonstration of pose extraction model
image is marked as 5. The pose arrays for all the images in the dataset are extracted
and stored in a list. The dataset is divided into training and testing sets according
to the 80:20 ratio. After exclusive testing, it was found that ExtraTrees Classiﬁer
and Linear Discriminant Analysis (LDA) provide the best result. Both models were
evaluated, and the default parameters gave the best results. In the results section, both
the models were compared with the SVM model with Linear Kernel using classical
parameters.
4
Result Analysis
The proposed model achieves modest results in all situations with varied lighting.
Figures 4, 5, 6 and 7, prove that the model can accurately detect head movements.
The model also exhibit exceptional results in the testing dataset with an accuracy
of 95.9% using the ExtraTrees Classiﬁer as shown in Table 1 and LDA as shown in
Table 2. The classiﬁcation reports are shown in Figs. 8 and 9, respectively.
If any person moves or changes their pose to cheat, the model will ﬁrst alert the
invigilator and simultaneously store the name and time at which the student attempted
to cheat. Moreover, the model also stores all the frames for future reference units.
Fig. 4 Looking right

336
D. Binu and S. Bellamkonda
Fig. 5 Looking left
Fig. 6 Cheating through
notes written on hand
Fig. 7 Looking down
Table 1 Evaluation matrix
for ExtraTree classiﬁer
Parameter
Value (in %)
Precision score
95.9
Recall score
95.9
F1 score
95.9

Academic Dishonesty Detection in Exams Using Pose Extraction
337
Table 2 Evaluation matrix
for LDA
Parameter
Value (in %)
Precision score
95.1
Recall score
95.1
F1 score
95.1
Fig. 8 Classiﬁcation report
for ExtraTree classiﬁer
Fig. 9 Classiﬁcation report
for LDA
A common trend for this problem was that the models which could perform
feature selection extremely well yielded the best results. Also, models that could
handle noisy data were more likely to generate good results. It is also known that
the feature vectors have a certain degree of noise. This noise is why the ExtraTree
classiﬁer achieved the best results since it is better at dealing with noisy features.
Also, it is a Tree-based method, which is more robust. ExtraTree uses randomization
to decrease the variance compared to more classical models, such as random forest
and decision tree models.
5
Conclusion
This paper proposes a model to help the proctors during the examination using
computer vision. The model helps ensure examinations’ fairness and solve traditional
invigilators’problems.Theproposedmodelwarnsthestudentsandprovidesevidence

338
D. Binu and S. Bellamkonda
if further investigations require. A robust pose detection system is proposed as the
accuracy of the model is deeply affected by the accuracy of the pose detection system.
The model can withstand adversarial attacks and make the model more resilient to
cyber-attacks. The model was deployed in the cloud to ensure safety and for faster
computations. More audio-based detection algorithms can also be implemented to
catch students cheating through oral means.
References
1. Shana L, Christopher CS (2019) Video surveillance using deep learning—a review. In: Interna-
tional conference on recent advances in energy-efﬁcient computing and communication. IEEE,
pp 1–5
2. Jiabul Hoque MD, Ahmed MR, Uddin MJ, Faisal MMA (2020) Automation of traditional exam
invigilation using CCTV and bio-metric. Int J Adv Comput Sci Appl 11(6):392–399
3. Fang Y, Ye J, Wang H (2020) Realization of intelligent invigilation system based on adaptive
threshold. In: 5th international conference on computer and communication systems. IEEE, pp
201–205
4. Ke S-R, Thuc H, Lee Y-J, Hwang J-N, Yoo J-H, Choi K-H (2013) A review on video-based
human activity recognition. Computers 2(2):88–131
5. VishwakarmaS,AgrawalA(2013)Asurveyonactivityrecognitionandbehaviorunderstanding
in video surveillance. Vis Comput 29:983–1009
6. Odongo DA, Agyemang E, Forkuor JB (2021) Innovative approaches to cheating: an
exploration of examination cheating techniques among tertiary students. Educ Res Int 2021:1–7
7. Cao Z, Simon T, Wei S-E, Sheikh Y (2017) Realtime multi-person 2D pose estimation using part
afﬁnity ﬁelds. In: IEEE conference on computer vision and pattern recognition, pp 1302–1310
8. Suryadevara N (2021) Human pose estimation in the browser. In: Beginning machine learning
in the browser. Apress, Berkeley, CA
9. Samir MA, Maged Y, Atia A (2021) Exam cheating detection system with multiple-human
pose estimation. In: IEEE international conference on computing, pp 236–240
10. Maniar S, Sukhani K, Shah K, Dhage S (2021) Automated proctoring system using computer
vision techniques. In: International conference on system, computation, automation and
networking, pp 1–6
11. Nishchal J, Reddy S, Navya PN (2020) Automated cheating detection in exams using posture
and emotion analysis. In: IEEE international conference on electronics, computing and
communication technologies. IEEE, pp 1–6
12. Kohli S, Jannaj Y, Maanan M, Rhinane H (2022) Deep learning: new approach for detecting
scholar exams fraud. In: The international archives of the photogrammetry, remote sensing and
spatial information sciences, vol XLVI-4/W3-2021, pp 103–107
13. Riaz H, Uzair M, Ullah H, Ullah M (2021) Anomalous human action detection using a
cascade of deep learning models. In: Proceedings of European workshop on visual information
processing, EUVIP. IEEE, US
14. Mahmood F, Arshad J, Othman M, Hayat M, Bhatti N, Jaffery M, Rehman A, Hamam H (2022)
Implementation of an intelligent exam supervision system using deep learning algorithms.
Sensors 22:6389
15. Bawarith R, Basuhail A, Fattouh A, Gamalel-Din S (2017) E-exam cheating detection system.
Int J Adv Comput Sci Appl 8(4)
16. Nakashima T, Yabuta Y (2018) Object detection by using interframe difference algorithm. In:
12th France–Japan and 10th Europe–Asia congress on mechatronics, pp 98–102

Dynamic Wireless Charging System
for Electric Vehicles Based on Segmented
Zinc Alloy Plates
Anurag A. Gadgil, Arya Bairoliya, J. L. Febin Daya, and P. Balamurugan
Abstract This paper proposes a dynamic wireless charging system based on
segmented alloy plates for charging electric vehicles on the go. With the rise and
development of electric vehicles (EVs), there is an increase in demand for charging
infrastructure for batteries. Wireless charging on EV eliminates the need for wires and
connectors to charge the vehicle, thereby making the charging easy and hassle-free.
Dynamic charging is an incremental addition over static wireless charging where the
battery in EV is charged when the vehicle is in motion. This also reduces the battery
capacity required, thereby making EV much cheaper. Considering the EV sector, a
dynamic charger that will charge the vehicle on the go will not only eliminate the old
conventional need for stopping for long hours but also increase travel efﬁciency to
a whole new level. In this proposed work, the dynamic charging system is designed
and simulated using MATLAB. The thermal modeling and analysis of the charger
are done using solid works, and the results are presented.
Keywords Dynamic charging · Resonance frequency · Charge plates · Thermal
analysis
1
Introduction
Electric vehicle adoption is gaining momentum in recent days. The sale of 2 wheelers
and 4 wheelers EV are on the rise as per the Parivahan Sewa data by Ministry
of Road Transport and Highway, India. However, deployment of public charging
infrastructure is not at the same pace when compared to EV sales. The rising electric
carmarketfuelsthedemandformoreconvenientanddependablemethodsofcharging
electric vehicle [1]. The conventional charging method uses on-board chargers or the
A. A. Gadgil · A. Bairoliya
VIT Bhopal University, Bhopal, India
J. L. Febin Daya (B) · P. Balamurugan
Vellore Institute of Technology, Chennai Campus, Chennai, India
e-mail: febindaya.jl@vit.ac.in
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_25
339

340
A. A. Gadgil et al.
Fig. 1 Schematic of dynamic wireless power transfer system for EV
high power chargers available in charging stations to recharge the battery in EV. In
addition, incompatible plug receptacles generate complications among EV models,
limiting the rapid adaptation of EVs. Wireless charging is an alternative option to
build this gap and fuel the rapid adoption of EV. Dynamic wireless charging allows
the vehicle to be charged on the go [2–4]. This can reduce the battery capacity by
1/5th time which in turn contributes to vehicle efﬁciency (wh/km) and the overall
cost of the vehicle. Dynamic wireless charging of electric vehicles could become a
preferred method since it would enable power exchange between the vehicle and the
grid while the vehicle is moving ubiquitously. Hence, there was a growing interest
in charging of vehicles on the move. In dynamic charging, on-board inductive units
are used to pick up charge from power sources buried in the road or located above
the surface. Dynamic charging has the inherent advantage of addressing some of the
major challenges of EV battery charging such as charging time, battery capacity,
battery size and travel range. The schematic of dynamic power transfer system for
EV is shown in Fig. 1.
2
Literature Review
Research articles in the area of dynamic wireless charging of EV are also reported
in recent literature. Omar et al. proposed a technique for transferring power through
a wireless medium for a considerably larger distance. The proposed method also
included a dynamic positioning system which enhanced the efﬁciency of power
transfer between the coils [5]. The vehicle position tracking and self-alignment
feature further enhanced the overall performance of the wireless charging system.
Hutchinson et al. studied the impact of dynamic wireless charging systems in terms of
vehicle cost, range, battery life, user convenience and charging infrastructure for EV

Dynamic Wireless Charging System for Electric Vehicles Based …
341
market penetration [6–8]. This study also gave insight into the inﬂuential parameters
of dynamic wireless charging. Some of the recent notable improvements in dynamic
charging were presented. Dai et al. proposed a multi-excitation unit conﬁguration
for EV dynamical charging [9]. This method will be useful for improving the power
capacity of the charger coils. The high power capability of the primary and secondary
coil is achieved by using more excitation units in the area where coils are embedded,
thereby reducing the voltage stress on the converters. Azad et al. presented a detailed
study on the different types of coil structures used for dynamic power transfer. The
coil size, efﬁciency and power transfer capability are compared for various cases.
Dynamic charging needs separate road/pathway wherein there are provisions for
embedding the coils, coil connections with supply system, mechanism for avoiding
foreign object interventions [10, 11]. Sooraj et al. have proposed a dual side control
mechanism for wireless charging of electric vehicle. High power transfer efﬁciency
was achieved using this technique [12]. They have also proposed an algorithm for
estimating the optimal frequency for minimum power transfer under misalignment
condition. The optimal frequency maintains resonance between the coils, there my
ensuring maximum power transfer [13]. Sooraj et al. have proposed a dynamic model
for wireless power transfer system when the coils are loosely coupled [14]. They have
also proposed a high gain LCL topology for efﬁcient wireless transfer. The high gain
topology eliminated the need of intermittent DC-DC converter in the wireless power
transfer system [15]. A detailed review on power converter topologies is presented
by Sooraj et al. The advantages of different converter topologies, power level, oper-
ating frequency, power transfer efﬁciency and misalignment analysis are studied in
detail [16]. The paper then facilitates a comparison of the various inductive pads,
rails and compensation systems developed to date. Additionally highlighted are the
static and dynamic charging methods and their traits. The function and signiﬁcance
of different types of power electronics and converters utilized in applications are
explained. Additionally discussed are the batteries and their management systems
as well as several WPT-related issues. A variety of trades are investigated, including
cyber security, economic consequences, health and safety, identiﬁcation of foreign
objects and effects on the distribution grid.
In the proposed work, a wireless power transfer system for EV is presented. It
offers a signiﬁcant advantage of power transfer, to prevent physical touch and being
plugged in regularly. The coil shape, dimensions, gap between coil pads and magnetic
core material used plays a critical role in deciding the performance of the wireless
power transfer system. In the case of dynamic power transfer systems, a large number
of coil pads are embedded on the road surface which acts as the primary coil for power
transmission. A limped coil pad arrangement is proposed in this work for dynamic
power transfer. The coils are arranged using segmented alloy plates. The proposed
design is simulated, and the thermal aspects are studied and presented.

342
A. A. Gadgil et al.
Fig. 2 Circuit diagram of wireless battery charger
Table 1 Coil parameters
Component
Quantity
Number of turns
25
Coil diameter
760 mm
Primary coil resistance
0.0714 
Secondary coil resistance
0.1428 
Mutual coupling (k)
0.1–0.5
Primary coil inductance
0.07343 mH
Secondary coil inductance
0.07343 mH
Resonance frequency
41.53 kHz
3
System Modeling and Design
The schematic diagram of the wireless charging system is shown in Fig. 2. The
single-phase AC input is given as input to the rectiﬁer. After rectiﬁcation, the inverter
switches at a high frequency and generated a high-frequency signal, which is given
as input to the primary coil pads. In the primary coil, the compensating networks are
present, to make the circuit operate at the resonant frequency. The secondary coil
pads are connected through a high-frequency rectiﬁer and ﬁlter to the load. The li-ion
battery is considered as load. The circuit parameters design using suitable equations
[4] are given in Table 1.
4
Thermal Modeling and Design
The CAD model of the charger pads for dynamic charging is prepared using Solid-
works. The idea behind this wireless charger is that it be installed 2 inches below the
road and charge the vehicles dynamically. The coils are arranged in such a way that
the magnetic leakage in minimum so that maximum ﬂux linkage yields maximum
efﬁciency [17]. The power transfer efﬁciency and packaging efﬁciency are taken

Dynamic Wireless Charging System for Electric Vehicles Based …
343
into considerations while arranging the coils. The plates are segmented with each
segment having a distance of 1 m between them. The width of the plate as whole is
3.75 m which matches the standard size of road lane. The length of the plate can be
varied as per requirement. The advised length of the single plate should not exceed
15 m as this might cause an issue for current dissipation in whole. Given the charging
plate will be installed under the road which generally is made up of tar or concrete it
must endure higher temperatures and cyclic stress. The constant movement of vehi-
cles over it will induce several tons of force every second. On top of that it must
endure blistering temperatures. For the same reason, the segmented charging plate
was tested in Solidworks at a maximum environmental temperature of 100 °C [18].
The internal temperature of the plate was not taken into consideration since zinc is a
moderately good conductor of heat and the movement of electrons will not cause it
to rise to temperatures above 30°–40°. The 3D model of the charger installed under
the road is shown in Fig. 3.
Solid Bodies
Document Name and 
Reference
Treated As
Volumetric Properties
Fillet1
Solid Body
Mass:80,103.8 kg
Volume:12.1369 m^3
Density:6,600 kg/m^3
Weight:785,017 N
Fig. 3 3D model of the charger that will be installed under the road

344
A. A. Gadgil et al.
Model Reference
Properties
Name:
Zinc Alloy 7; 
AG40B; Zn-4Al-
0.015Mg
Model type:
Linear Elastic 
Isotropic
Default failure 
criterion:
Unknown
Thermal 
conductivity:
113 W/(m.K)
Specific heat:
418.7 J/(kg.K)
Mass density:
6,600 kg/m^3
Fig. 4 Material properties of the charger
4.1
Material Properties and Thermal Load
The charger material properties simulation is shown in Fig. 4. Zinc was the primary
candidate since it is a good conductor of electricity and a moderate conductor of
heat. Being highly anisotropic in nature it had to be alloyed with other materials like
aluminum which increase durability, rigidity and performance [19]. It is a sought after
alloy above aluminum, magnesium and bronze. Alloyed with aluminum it tends
to follow the linear elastic isotropic model. This model assumes a linear relation
between the stress and strain there by making the model simple and easy to analyse.
This model shows that the properties of the alloy do not vary with direction and the
properties at generally predictable at different stresses at different load axis like X,
Y and Z-axis. The ultimate tensile strength of the zinc alloy is 352 MPa, and the
electrical conductivity of the same is 25 s/m [11]. Figure 5 shows the simulation
result, when the heat is applied on the faces of the segmented plates.
5
Results and Discussion
The wireless charging system is simulated using MATLAB/Simulink. The simulation
results are shown in Fig. 6. The wireless charger was able to charge the li-ion battery
and the SoC of the battery started increasing from 80%. The simulation results of

Dynamic Wireless Charging System for Electric Vehicles Based …
345
Load name
Load Image
Load Details
Temperature
Entities:
14 face(s)
Temperature:
373 Kelvin
Fig. 5 Application of heat on the faces of the charger
the charger for different temperature ranges are shown in Fig. 6. In the simulation
model, a single-phase AC input of 230 V, 50 Hz is given as input to the rectiﬁer.
After rectiﬁcation, the inverter switches at a high frequency and generated a high-
frequency signal, which is given as input to the primary coil pads which are having
self-impedance parameters as 0.0714  and 73.43 uH.
In the primary coil, the compensating networks are present, to make the circuit
operate at the resonant frequency. The secondary coil pads are having self-impedance
parameters as 0.0714  and 73.43 µH which are connected through a high-frequency
rectiﬁer and ﬁlter to the load. The mutual impedance parameters of the primary and
secondary coils are 0.142  and 14.6 µH. The li-ion battery is considered as load,
which is having the speciﬁcations as 12 V, 20 Ah. The voltage, current and SOC are
measured through scope in MATLAB. The output shows that the battery is charging
to a maximum voltage of 13 V, the corresponding ﬂow in current thereby the SOC
is increasing that depicts that the battery pack is charging. The plate temperature is
tested at various instances, and the results are consolidated. The simulation results
are shown in Fig. 7. The analysis output was satisfactory and as per requirement.
The plate maintains its original temperature and does not result in overheating which
could have caused a problem.
6
Conclusion
This paper proposed the dynamic charger with segmented alloy plates for electric
vehicle. The charger was designed and simulated. The SoC of the li-ion battery
started increasing, when the secondary pad was in close proximity with the primary.
The SoC of the battery raised at a faster when the gap between the coil pads is
lesser. The vehicle range and overall performance is improved to a greater extent.
A suitable control algorithm is to be deployed to perform dual side control of the
overall system. Preliminary simulations show that applying some form of intelligent
control technique can further improve the performance.

346
A. A. Gadgil et al.
Fig. 6 Output graph—this graph on MATLAB shows the ripples generated by the charger while
charging resulting in lower frequency and accurate charging
Future research will focus on the electromagnetic interference (EMI) that the
transmitter coils emit. The transferrable power in real use must be increased with
further EMI reduction. The efﬁciency of the system can be increased to ensure more
amount of power transfer. Future work also includes a study on the bidirectional
power ﬂow between the infrastructure and the on-board battery, which is necessary
to support a vehicle-to-grid (V2G) concept.

Dynamic Wireless Charging System for Electric Vehicles Based …
347
Name
Type
Min
Max
Thermal 1
TEMP: 
Temperature
3.730e+02 Kelvin
Node: 1
3.730e+02 Kelvin
Node: 1
EV Dynamic Charger
Fig. 7 Charge distribution across the charger plates
References
1. Song S, Dong S, Zhang Q (2021) Receiver current-stress mitigation for a dynamic wireless
charging system employing constant resistance control. IEEE Trans Power Electron 36:3883–
3893
2. Omar N, Santos ED, Yago A (2021) Wide range highly efﬁcient dynamic wireless power
transfer system. In: IEEE transportation electriﬁcation conference and expo (ITEC). IEEE
Press, New York
3. Hutchinson L, Waterson B, Anvari B, Naberezhnykh D (2019) Potential of wireless power
transfer for dynamic charging of electric vehicles. IET Intel Transport Syst 13:3–12
4. Qui C, Chau KT, Liu C (2014) Overview of wireless charging technologies for electric vehicles.
J Asian Electr Vehic 12:1679–1685
5. Liu C, Chau KT, Qui C, Lin F (2014) Investigation of energy harvesting for magnetic sensor
arrays on Mars by wireless power transmission. J Appl Phys 115:1–3
6. Zhang Z, Chau KT, Qui C, Lin C (2015) Energy encryption for wireless power transfer. IEEE
Trans Power Elct 30:5237–5246
7. Liu C, Chau KT, Zhang Z, Qui C, Lin F, Ching TW (2015) Multiplereceptor wireless power
transfer for magnetic sensors charging on Mars via magnetic resonant coupling. J Appl Phys
117(17A743):1–3

348
A. A. Gadgil et al.
8. Chen W, Liu C, Lee CHT, Shan Z (2016) Cost-effectiveness comparison of coupler designs of
wireless power transfer for electric vehicle dynamic charging. Energies 11:906–918
9. Dai X, Jiang JC, Wu JQ (2019) Charging area determining and power enhancement method
for multi excitation unit conﬁguration of wirelessly dynamic charging EV system. IEEE Trans
Ind Electron 66:4086–4096
10. Liu C, Chau KT, Zhang Z, Qui C, Li W, Ching TW (2015) Wireless power transfer and fault
diagnosis of high-voltage power line via robotic bird. J Appl Phys 117(17D521):1–4
11. Jiang CQ, Chang KT, Liu C, Han W (2017) Wireless dc motor drives with selectability and
controllability. Energies 10:1–15
12. Sooraj V, Febin Daya JL (2020) Compact pulse position-based high efﬁcient IPT system for
wireless charging of EV. IET Power Electron 13:85–96
13. Sooraj V, Febin Daya JL (2019) Estimation of optimal operating frequency for wireless EV
charging system under misalignment. Electronics 8
14. Sooraj V, Febin Daya JL (2018) A large signal dynamic model of loosely coupled IPT system
for EV based on laplace phasor transform. In: IEEE power electronics, drives and energy
systems conference. IEEE Press, New York, pp 1–6
15. Sooraj V, Febin Daya JL (2019) A high gain LCL architecture based IPT system for wireless
charging of EV. IET Power Electron 12:195–203
16. Sooraj V, Febin Daya JL, Mohan Krishna S, Williamson S, Ramani K, Lila II (2022) Role of
power converters in ınductive power transfer system for public transport—a comprehensive
review. Symmetry 14
17. Bosshard R, Kolar JW (2016) Inductive power transfer for electric vehicle charging: technical
challenges and tradeoffs. IEEE Power Electron Mag 3:22–30
18. Knecht O, Kolar JW (2019) Performance evaluation of series-compensated IPT systems for
transcutaneous energy transfer. IEEE Trans Power Electron 34:438–451
19. Mohamed AAS, Meintz A, Schrafel P, Calabro A (2019) Testing and assessment of EMFs
and touch currents from 25-KW IPT system for medium-duty EVs. IEEE Trans Veh Technol
68:7477–7487

Iterative Reﬁnement Versus
Generative Adversarial Networks
for Super-Resolution Towards Licence
Plate Detection
Alden Boby
, Dane Brown
, and James Connan
Abstract Licence plate detection in unconstrained scenarios can be difﬁcult because
of the medium used to capture the data. Such data is not captured at very high resolu-
tion for practical reasons. Super-resolution can be used to improve the resolution of
an image with ﬁdelity beyond that of non-machine learning-based image upscaling
algorithms such as bilinear or bicubic upscaling. Technological advances have intro-
duced more than one way to perform super-resolution, with the best results coming
from generative adversarial networks and iterative reﬁnement with diffusion-based
models. This paper puts the two best-performing super-resolution models against
each other to see which is best for licence plate super-resolution. Quantitative results
favour the generative adversarial network, while qualitative results lean towards the
iterative reﬁnement model.
Keywords Character recognition · Diffusion probabilistic models · Licence plate
recognition · Object detection · Super-resolution
1
Introduction
The number of vehicles on the road is rapidly increasing, and the demand for vehicles
creates a need for more robust road management and trafﬁc regulation. There is a
need to monitor vehicles and introduce regulations which combat congestion on the
roads and promote safety for pedestrians and drivers alike. Advances in technology
can supplement these rules and regulations already in place. These are referred to as
intelligent transport systems (ITS) [21].
A. Boby (B) · D. Brown · J. Connan
Department of Computer Science, Rhodes University, Grahamstown, South Africa
e-mail: boby.alden128@gmail.com
D. Brown
e-mail: d.brown@ru.ac.za
J. Connan
e-mail: j.connan@ru.ac.za
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_26
349

350
A. Boby et al.
Vehicles are required by law to have a licence plate. Although it maintains a
uniform shape and size from vehicle to vehicle, these licence plates have a set of
characters that are uniquely arranged and can be used to identify: the owner, the
registration, the class of the vehicle and other related information. This informa-
tion is speciﬁcally important to government agencies such as trafﬁc police and law
enforcement as it can aid their daily jobs.
The need to track vehicles extends past law enforcement, although them being
the primary users, insurance companies, and customers could beneﬁt from these
advancements when investigating a claim. Provided that there is footage of an acci-
dent, the company could identify the vehicle in the wrong through the licence plate
and pass this information to the trafﬁc enforcers, who can identify the vehicle’s
owner.
A major obstacle with licence plate recognition is the medium on which the data
has been captured. Images or videos could have a low resolution, making it hard
to identify objects of interest. This is especially true with licence plates, as they
typically occupy a tiny portion of an image. This results in a loss of information
or distortion of the image, making characters in the image or frame unidentiﬁable.
Figure 1 demonstrates this problem.
A myriad of problems makes licence plate detection difﬁcult besides a low reso-
lution. Once a licence plate has been extracted, it can only be given context once the
characters on the licence plate are correctly identiﬁed. One incorrect character can
render the whole licence plate invalid. A solution to this problem is super-resolution
(SR) to improve the quality of an image before further processing it for character
recognition.
Fig. 1 Highlighted licence plates only occupy a small portion of the entire image

Iterative Reﬁnement Versus Generative Adversarial Networks
351
Fig. 2 Deep learning methods produce much sharper upscaled images [18]
2
Super-Resolution
Super-resolution is applicable across many domains [1]. In the licence plate detection
ﬁeld, it would be beneﬁcial to use this upscaling method to improve accuracy when
detecting characters on a licence plate. The advantage of using a fully computational
model is that expensive hardware costs are mitigated. For example, police vehicles
are ﬁtted with expensive camera systems consisting of telephoto and infrared cam-
eras speciﬁcally conﬁgured to capture licence plates. Although that is a working
solution, it would be beneﬁcial to create a software-based solution with compara-
ble performance that can be deployed as a more affordable solution, whether for a
government organisation or a private entity.
This is where SR can be applied. Unlike standard upscaling methods like bilinear
or bicubic upscaling, the use of SR improves the quality of an image without prior
knowledge of the ground truth image. SR produces superior-quality images that have
been upscaled with standard sharpening and deblurring ﬁlters. Figure2 demonstrates
the superiority of SR as an upscaling method.
This is perfect for what is trying to be achieved as it eliminates specialised hard-
ware. Super-resolution models work through partially supervised machine learning;
they are fed images mapped to each other to inform the system. The models then
extrapolate the information from the training samples to upscale unseen images; this
is referred to as blind SR. Super-resolution can be achieved through deep learning
models, speciﬁcally generative adversarial networks (GANs) and diffusion models,
which will be the focus of this paper. GANs do not perform exceptionally well on
ﬁnite details like text. The use of an alternative, such as iterative reﬁnement, may
prove to be better.
2.1
Diffusion Probabilistic Model
A diffusion probabilistic model, or diffusion model for short, works with an iterative
process that performs particularly well for image generation. For machine learning

352
A. Boby et al.
Fig. 3 Each image in the progression is a less noisy version of xt, xt−1
models such as diffusion probabilistic models and GANs alike, a new high-resolution
image is essentially a newly generated image. Hence, the models can be further
tweaked, allowing them to be exploited for SR.
The diffusion model is a Markov chain that slowly adds noise to an image [7].
An input image is taken, and Gaussian noise is applied to it, then, it is denoised in
an iterative process creating a high-resolution image as the resulting output. Figure3
shows an example of this process and how it takes place, each time-step, t, relies
on the previous step creating a less noisy image at each time step (xt−1, xt−2, . . .).
Generally, the more iterations the model performs, the better the quality of the ﬁnal
output image.
A current limitation of these diffusion models is their ability to run in real time.
They have a linear time complexity, and the more iterations the model has to go
through, the longer the image will take to produce.
2.2
Generative Adversarial Networks
Generative adversarial networks have been the most popular model for image genera-
tion prior to advancements in the diffusion model space. A GAN is comprised of two
networks, which are a discriminator and a generator. To train a GAN, these networks
work together in an opposing manner to improve model performance. The generator
generates some image, and the discriminator is supposed to discern whether the out-
put from the generator is a fake or an actual image [3]. Depending on the outcome,
the weights of the model will be updated according to the loss function. Eventually,
the generator becomes good enough to fool the discriminator each time, allowing
the generator to be used on its own to produce its own images or upscale images in
the context of this research. GANs are unsupervised machine learning models that
can be supplied with unlabelled training data. A GAN needs to be able to produce
a diverse set of images. GANs can suffer from mode collapse, which causes them
to produce the same or similar image each time which is undesirable if one wants
to upscale or create more than one image [17]. Mode collapse can occur during the
training process, causing the generator to link several input points to one output,
resulting in similar output images for a range of varied data—which is undesirable.

Iterative Reﬁnement Versus Generative Adversarial Networks
353
3
Object Detection
Character recognition is an important stage for licence plate recognition as this is the
stage where data turns into information that can be used to look up vehicles that have
been recognised. The use of an object detector can be used to detect these characters
with relatively high accuracy. Supplemented by the use of SR, the detection rate of
the models should have a noticeable increase, especially on images where the quality
of the image affects the look of certain characters. The You Only Look Once (YOLO)
object detector can be used for this.
4
Related Studies
The ﬁrst step in licence plate recognition requires extracting a licence plate. YOLO
has been successful in this regard, being used as the go-to deep learning method,
surpassing other object detectors such as region-based convolutional neural networks
(R-CNN), detecting an object and its class in one pass [5]. Many authors such as Lee
et al. [9], Silva and Jung [16], and Boby and Brown [2] all achieved success through
the use of YOLO for licence plate extraction. Silvia and Jung further improved
the performance of YOLO by creating a specialised architecture heavily based on
YOLO called the warped planar object detection network (WPOD-net) [15]. This
model introduced bounding parallelograms, which are more suited to the varied
angles present in real-world data.
Convolutional neural networks (CNNs) are at the base of most computer vision
tasks, originally creating SR images through end-to-end mapped training data. The
Super-Resolution Convolutional Neural Network (SRCNN) was one of the ﬁrst suc-
cessful deep learning models for super-resolution [1]. The model surpassed the qual-
ity of images upsized with bicubic upscaling [6].
GANs were quickly adopted and used in place of CNNs due to their superior
image quality. In the current literature, GANs have been the more popular choice for
SR with licence plates. Lee et al. [9] used GANs to upscale low-resolution licence
plates and successfully reduced false positives at the character recognition stage.
Similarly, Boby and Brown [2] succeeded by using an ESRGAN to enhance low-
resolution licence plate images resulting in increased character recognition accuracy.
These positive results from using SR mean that trying other SR methods may further
accelerate progress in this ﬁeld.
Diffusion models have recently started gaining traction for a number of applica-
tions such as image synthesis [10–12] as well as SR [13]. The new advancements
in diffusion models mean there needs to be more application in the licence plate
detection ﬁeld. This may be due to real-time requirements of licence plate detec-
tion, and these diffusion models cannot upscale or generate an image in real time.
Regardless of this, diffusion-based SR models have very impressive results. Figure4
shows an image generated by SR3, a diffusion model developed by a team at Google.

354
A. Boby et al.
Input
SR3 Output
Reference
Fig. 4 Close similarity between the synthetic image and the ground truth image present a case for
diffusion models as a substitute for SR [13]
This is still advancing as most diffusion models have only been released in 2022; this
includes DALLE-2 [10], Imagen [12], and Stable Diffusion [11]. Although Imagen
and DALLE-2 are explicitly built for image synthesis, they have a SR component
within them, demonstrating that diffusion models are an alternative to GANs for SR.
Figure4 shows the potential of SR with diffusion-based models.
Dhariwal and Nichol [4] present a paper on how diffusion models outperform
GANs for image synthesis. Describing GANs as the current state-of-the-art regarding
image generation and how diffusion models outperform them in the same task. In the
case of SR, the output from the model is still synthesised and should carry over to
that space. Other authors share the same sentiment and compare the performance of
their diffusion models to GANs reporting more satisfactory results from the diffusion
models [11, 13].
It is difﬁcult to quantify image quality, and ﬁnding a suitable measure to evaluate
the output from a SR model is necessary. This inspection can be done visually as well
as mathematically. A mathematical representation makes assessing image quality
difﬁcult, as qualitative results allow for a way to measure a model’s performance
[20]. Mean squared error (MSE) can be used to measure the quality of an image, but
as described by Wang and Bovik [19], MSE for an image does sufﬁciently represent
the human perception of an image. For example, Fig. 5 shows the same image with
an MSE of 309; however, the images vary drastically in quality.
This demonstrates that MSE is not the best measure to evaluate images. To date,
literature is still using the peak-signal-to-noise ratio (PSNR) and structural similarity
index (SSIM) to measure the quality of an image. Looking back at Fig.5, although
they have the same MSE, their SSIM is different, showing that it is a much better
metrictouse.However,visualinspectionisstillhelpfulasnometriccanfullyquantify
human perception when viewing images [14]. This informs the methodology that a
human should qualitatively analyse some samples to compare the outputs from a
diffusion model and a GAN.
Speciﬁcally for SR, the SR model tries to re-imagine an image based on the
training data supplied. Metrics like SSIM and PSNR measure the similarity between
images with image synthesis the SR output will always differ from the original.

Iterative Reﬁnement Versus Generative Adversarial Networks
355
(a) Noticeable degradation and colour
banding in the image.
(b) No easily noticeable ﬂaws in the im-
age.
Fig. 5 Images are perceivably different quality, however, have the same MSE [19]
In this case, the goal of the SR is to make characters appear clearer so that they can
be detected clearly [2]. Regardless, SSIM is currently the best way to evaluate image
quality considering human perception [14].
With recent literature exploring its use, YOLO is a strong candidate for character
recognition. Kim et al. [8] used YOLOv2 as a substitute for OCR and found that
YOLO performed much better for character recognition. Silvia used CR-NET and
observed a similar outcome, with a 1.71% increase in accuracy from using the deep
learning model compared to a commercially available system [16]. Insight from these
papers informs the experiments conducted in this research, making YOLO a suitable
candidate for character recognition.
5
Proposed Work
This paper uses a diffusion model implementation based on the super-resolution
via iterative reﬁnement model created by Google [13]. The implementation in use
does not match the performance levels of those shown in the research paper as it
is a reconstruction of the model based on information from the publication, which
omitted some details to create the exact system. The model,1 however, is sufﬁcient
enough to use. The second model is the Real-ESRGAN [18], a state-of-the-art GAN-
based SR model.
The SR model is trained with relevant LP data to perform better in the licence
plate domain. The majority of SR models are tuned to work on faces; supplementing
it with speciﬁc training data should boost performance for licence plates as certain
features on licence plates are not found in natural scenes.
The models will take a low-resolution 64 × 64 image and then upscale it by a
factor of 8 to 512 × 512. Both models will be supplied with the same dataset so
1 https://github.com/Janspiry/Image-Super-Resolution-via-Iterative-Reﬁnement.

356
A. Boby et al.
Fig. 6 High level overview of the proposed LPR system
that the output from the models is directly comparable. Diffusion models require
the input image to be the same size as the output image. So the diffusion model
is supplied with a 64 × 64 image upscaled to 512 × 512 with bicubic interpolation
as an intermediate prepossessing step before being upscaled via super-resolution.
Figure6 shows a high-level overview of the methodology.
The high-resolution output from both models is compared both quantitatively
using performance metrics speciﬁc to image quality and qualitatively through visual
inspection.
5.1
Measuring Image Quality
The paper will use both qualitative and quantitative methods to inspect SR outputs
from two SR models: the Real-ESRGAN and a diffusion model. The quantitative
metricsdiscussedintherelatedstudiessectionaredescribedinthefollowingsections.
SSIM
Structural Similarity is a metric used to measure the similarity between two images.
By measuring the SSIM of a ground truth high-resolution image compared against a
SR image, it is possible to estimate how well the upscaling model performed. SSIM
is the metric closest to describing human perception.
PSNR
PSNR is an image quality assessment metric that uses signals within an image to
assess to what extent noise distorts an image. The ratio is used to compare the
similarity between two images. PSNR is measured in decibels, where a higher value
is preferable. Equation1 shows how to calculate PSNR.
PSNR = 10 log10

peakval2
/MSE
(1)
Peakval represents the highest value in the input image (peak value).

Iterative Reﬁnement Versus Generative Adversarial Networks
357
5.2
Model Training
The super-resolution models were trained on a device with the following specs:
• GPU: 2080TI (11GB RAM)
• CPU: AMD Ryzen 9 3950X 16-Core (4.7GHz)
• RAM: 128GB
Training the diffusion model takes a considerable amount of VRAM, so the batch
size was set to one to allow the training to occur with the available amount of VRAM.
The model was trained on a set of one hundred images; diffusion models have
the added beneﬁt of being easier to train than GANs. The images contained licence
plates with a variety of different text colours and background colours. Ensuring the
training data is diverse directly affects the quality of the end results from the model.
The model was trained for 60,000 epochs, and 2000 iterations were used for each
epoch.
5.3
Test Models
A series of experiments will be conducted to compare the performance of the two
super-resolution models and, ultimately, which model helps to improve character
recognition the most.
Experiment 1
A quantitative evaluation of the SR images produced by both models using SSIM
and PSNR, which are the current standard to measure an images quality.
Experiment 2
A qualitative analysis of SR images produced by both models as the PSNR and SSIM
metrics cannot fully quantify human perception.
Experiment 3
Performing character recognition on images upscaled by the Real-ESRGAN and the
diffusion model to analyse how well each model reconstructed characters.
6
Result Analysis
6.1
Experiment 1
The PSNR and SSIM for both models are given in Table1. The Real-ESRGAN had
better results for both SSIM and PSNR, with the difference between SSIM being
almost double. Quantitatively, the Real-ESRGAN performed better, meaning the

358
A. Boby et al.
Table 1 Image quality assessment scores for the SR models
Metric
Real-ESRGAN
Diffusion model
PSNR
22.086
16.876
SSIM
0.67072
0.34417
results from this model should have a more signiﬁcant effect on character recognition
than the diffusion model. The following experiment will examine the extent to which
the qualitative and quantitative results correlate.
6.2
Experiment 2
Figure7 shows the SR image from the diffusion model with the lowest PSNR and
SSIM. Upon visual inspection, the image is indeed the worst quality out of all the
images output from the diffusion model. Conversely, the same image from the Real-
ESRGAN has a much higher PSNR and SSIM values, but the licence plate in the
image is still illegible. It appears colour takes high precedence with these evaluation
metrics, as between the diffusion model output and the Real-ESRGAN output, the
GAN has a more accurate colour when compared to the original image. In contrast,
the diffusion model output lacks vibrance.
A limitation is that certain patterns become affected when an image’s resolution
is too low. Patterns become interpreted differently when upscaled, producing an
erroneous SR image, for example in Fig.7, the rear vents of the Porsche appear to
collapse on each other, and that is then extrapolated to the SR and mismatching the
ground truth. This often occurs with sets of parallel lines.
Original image
(PSNR/SSIM)
Diﬀusion Model
(8.2044/0.0373)
Real-ESRGAN
(25.3203/0.7408)
Fig. 7 Worst quality image from the diffusion model compared against the original HR image and
the Real-ESRGAN output

Iterative Reﬁnement Versus Generative Adversarial Networks
359
(a) Original HR image.
(b) Real-ESRGAN output.
Fig. 8 Image 8b has reduced ﬁne details and is very smooth in appearance. Textures like grains in
the road have been lost in the SR process
Ground truth
BICUBIC
Real-ESRGAN
Diﬀusion
Fig. 9 Close up at the letter ‘M’ to see how each model reconstructed characters on a licence plate
The Real-ESRGAN smoothes out ﬁne details in an image giving the output a water
oroil-paintinglook,more-sothanresemblinganaturalimage.Thisappearancemakes
it easily distinguishable to the human eye. Figure8 demonstrates how the output from
the Real-ESRGAN is missing some ﬁner details that have been washed out.
The diffusion-based model produced some promising results but was very incon-
sistent. Some samples produced images with noticeable Gaussian noise, while others
had increased quality and legibility of distorted and unclear characters. The zoomed
image in Fig.9 shows that the unclear characters have been cleared up after the
diffusion process.
Figure9 demonstrates both the weak and strong points of the diffusion model. The
Real-ESRGAN has made the character ‘M’ ambiguous and could be misinterpreted
as an ‘N’, while the diffusion model has recovered some detail making the blurry
character in the bicubic image look more like an ‘M’. However, the SR image from
the diffusion model has visible noise, an issue that can be solved by increasing the
number of iterations. However, the increase in quality from double the amount of
iterations is negligible when the increase in time is considered. Figure10 shows
another example of how both models reconstructed characters.
Images with licence plates occupying a small portion of the image could not be
restored by any model, the amount of information in such images was too little to
extrapolate.

360
A. Boby et al.
Ground truth
BICUBIC
Real-ESRGAN
Diﬀusion
Fig. 10 ‘S’ can be seen to have exaggerated features when upscaled with the Real-ESRGAN when
compared to the more readable diffusion model upscale
Table 2 Character recognition results on upscaled images
Upscaling method
Precision
Recall
Bicubic
0.714
0.351
Real-ESRGAN
0.745
0.44
Diffusion
0.692
0.357
6.3
Experiment 3
The upscaled images were used to perform character recognition with a trained
YOLOmodel.TheresultsaregiveninTable2.Thebestperformancecamefromusing
the Real-ESRGAN as the upscaler, with precision and recall going up. A correlation
between the quantitative results can be found here, as the Real-ESRGAN also had
the highest scores when the SSIM and PSNR were measured. Although performing
worse in all quantitative tests, the diffusion model still had some promising upscaled
results.
The YOLO model makes use of convolutional layers to make character predic-
tions. One explanation as to why the Real-ESRGAN performed better despite being
less visually appealing to the human eye is that the noise in an image is much more
signiﬁcant quantitatively due to these analyses using pixel values and similarity.
Gaussian noise in an image can signiﬁcantly alter the spread of this data. Conversely,
the human eye can still perceive an image under minimal Gaussian noise. Examples
of this can be seen in Figs. 9 and 10 in earlier sections.
A limitation is the size of the dataset used for training, state-of-the-art models
such as DALLE-2 [10], Imagen [12], and Stable Diffusion [11] were trained with
billions of images. General imaging data is not speciﬁc towards the detection of
licence plates.

Iterative Reﬁnement Versus Generative Adversarial Networks
361
7
Conclusion
The Real-ESRGAN model proved to be the better model of the two regarding SR. It
is currently still the superior upscaling method of choice for LPR. However, there are
trade-offs when it comes to using each of the models. The output from the diffusion
model lacks consistency, some images have a considerable amount of noise, and
some images are very clear. The biggest problem with adopting diffusion models in
their current state is that the iterative nature of the model means they cannot operate
in real time, making it a more viable option when technology advances in future.
The real-ESRGAN images are usable but look more artiﬁcial than the diffusion ones.
The Real-ESRGAN beats the diffusion model outright when evaluated with PSNR
and SSIM. Although the ESRGAN outperformed the diffusion model quantitatively,
further analysis of the images showed that the diffusion models were more appealing
and accurate. It was noted from the results that in images at t0, the ﬁnal output, still
contained some noise. Future works could explore adding a ﬁnal pre-processing step
to eliminate the remaining noise, as it was evident from the results that noise affected
character recognition. The ﬁdelity of diffusion model output can be used to generate
training sets. In this manner, the time it takes to generate outweighs the time it takes
to collect a signiﬁcant amount of data. This can be explored in future works.
References
1. Anwar S, Khan S, Barnes N (2020) A deep journey into super-resolution: a survey. ACM
Comput Surv (CSUR) 53(3):1–34
2. Boby A, Brown D (2022) Improving licence plate detection using generative adversarial net-
works. In: Iberian conference on pattern recognition and image analysis. Springer, Berlin, pp
588–601
3. Brock A, Donahue J, Simonyan K (2018) Large scale GAN training for high ﬁdelity natural
image synthesis. arXiv preprint arXiv:1809.11096
4. Dhariwal P, Nichol A (2021) Diffusion models beat GANs on image synthesis. In: Advances
in neural information processing systems, vol 34, pp 8780–8794
5. Diwan T, Anirudh G, Tembhurne JV (2022) Object detection using YOLO: challenges, archi-
tectural successors, datasets and applications. Multimedia Tools Appl 1–33
6. Dong C, Loy CC, He K, Tang X (2014) Learning a deep convolutional network for image
super-resolution. In: European conference on computer vision. Springer, Berlin, pp 184–199
7. Ho J, Jain A, Abbeel P (2020) Denoising diffusion probabilistic models. In: Advances in neural
information processing systems, vol 33, pp 6840–6851
8. Kim TG, Yun BJ, Kim TH, Lee JY, Park KH, Jeong Y, Kim HD (2021) Recognition of vehicle
license plates based on image processing. Appl Sci 11(14):6292
9. Lee Y, Yun J, Hong Y, Lee J, Jeon M (2018) Accurate license plate recognition and super-
resolution using a generative adversarial networks on trafﬁc surveillance video. In: 2018 IEEE
International conference on consumer electronics-Asia (ICCE-Asia). IEEE, pp 1–4
10. Ramesh A, Dhariwal P, Nichol A, Chu C, Chen M (2022) Hierarchical text-conditional image
generation with clip latents. arXiv preprint arXiv:2204.06125
11. RombachR,BlattmannA,LorenzD,EsserP,OmmerB(2022)High-resolutionimagesynthesis
with latent diffusion models. In: Proceedings of the IEEE/CVF conference on computer vision
and pattern recognition, pp 10684–10695

362
A. Boby et al.
12. Saharia C, Chan W, Saxena S, Li L, Whang J, Denton E, Ghasemipour SKS, Ayan BK, Mahdavi
SS, Lopes RG et al (2022) Photorealistic text-to-image diffusion models with deep language
understanding. arXiv preprint arXiv:2205.11487
13. Saharia C, Ho J, Chan W, Salimans T, Fleet DJ, Norouzi M (2022) Image super-resolution via
iterative reﬁnement. IEEE Trans Pattern Anal Mach Intell
14. Sara U, Akter M, Uddin MS (2019) Image quality assessment through FSIM, SSIM, MSE and
PSNR—a comparative study. J Comput Commun 7(3):8–18
15. Silva SM, Jung CR (2021) A ﬂexible approach for automatic license plate recognition in
unconstrained scenarios. IEEE Trans Intell Transp Syst
16. Silva SM, Jung CR (2020) Real-time license plate detection and recognition using deep con-
volutional neural networks. J Vis Commun Image Representation 71:102773
17. Srivastava A, Valkov L, Russell C, Gutmann MU, Sutton C (2017) Veegan: reducing mode
collapse in GANs using implicit variational learning. In: Advances in neural information pro-
cessing systems, vol 30
18. Wang X, Xie L, Dong C, Shan Y (2021) Real-ESRGAN: training real-world blind super-
resolution with pure synthetic data. In: Proceedings of the IEEE/CVF international conference
on computer vision, pp 1905–1914
19. Wang Z, Bovik AC (2009) Mean squared error: love it or leave it? A new look at signal ﬁdelity
measures. IEEE Signal Process Mag 26(1):98–117
20. Wang Z, Bovik AC, Lu L (2002) Why is image quality assessment so difﬁcult? In: 2002 IEEE
International conference on acoustics, speech, and signal processing, vol 4. IEEE, pp IV–3313
21. Zou Y, Zhang Y, Yan J, Jiang X, Huang T, Fan H, Cui Z (2021) License plate detection and
recognition based on YOLOv3 and ILPRNET. Signal Image Video Process 1–8

An IoT-Based Smart Health Monitoring
System
R. Lakshmi, M. Mridula, G. Sri Gayathri, and V. Srividhyasakthi
Abstract As per the grandview healthcare research report published in 2022, the
wearable healthcare market in India is expected to reach US$ 372 million owing
to an increase in lifestyle disorders and better awareness of healthcare. As per the
World Health Organization (WHO) guidelines, the essential parameters to be moni-
tored for COVID-19 patients are temperature, heart rate, SpO2, and perfusion index.
Recent wearable watches such as Apple, Samsung Gear, and Fitbit produce inac-
curate and unreliable SpO2 results due to movement of the skin and insufﬁcient
skin contact. People affected by acute conditions as well as patients in critical care
having chronic conditions require continuous monitoring of vital parameters, which
results in increased production of wearables in the healthcare market. The proposed
real-time vital monitor is the cost-effective, accurate, IoT-enabled, bioimpedance
analysis [BIA] integrated, and two-way communication device that is capable of
monitoring as well as recording the vitals of patients, such as temperature, oxygen
saturation (SpO2), heart rate, respiratory rate, perfusion index, and hydration status.
The obtained patient status is displayed in real-time using the mobile application.
This is an effective and reliable way of minimizing the fatality rate and clinical
admission of patients, by retaining lives in the golden hour.
Keywords Real-time vital monitoring · Respiratory diseases · Alert system ·
Temperature · SpO2 · Heart rate · Bioimpedance analysis
R. Lakshmi · M. Mridula · G. Sri Gayathri · V. Srividhyasakthi (B)
Department of Biomedical Engineering, Sri Ramakrishna Engineering College, Coimbatore, India
e-mail: srividhyasakthi.v@srec.ac.in
R. Lakshmi
e-mail: lakshmi.1907023@srec.ac.in
M. Mridula
e-mail: mridula.1907031@srec.ac.in
G. Sri Gayathri
e-mail: srigayathri.1907045@srec.ac.in
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_27
363

364
R. Lakshmi et al.
1
Introduction
In accordance with a health survey conducted by the World Health Organization
(WHO), nearly 260 million people suffered from asthma, and over 3 million deaths
happened due to chronic obstructive pulmonary disorder [1]. In many hospitals, due
to shortages of healthcare workers and poor monitoring facilities, vital parameters of
the patients could not be continuously monitored. According to the retrospective
cohort study conducted by Peru public hospital in Lima concluded that oxygen
saturation (SpO2) levels below 90% act as an effective predictor for COVID-19
patients [2]. Dehydration is the second leading cause of death in infants and children
[3]. Loss of 2–3% of body water content can cause physical and cognitive defects
[4]. Overhydration causes lower mental ability, tachycardia, acute renal failure, and
oedema. The consequences of overhydration are myocardial infarction, hypertension,
oedema, and seizure. Hydration status is determined by clinical symptoms which can
be interpreted by doctors only.
The methods available for assessing hydration status aim to measure body ﬂuid
compartments either directly or indirectly which are as follows:
1. Biomarkers assessment—which estimate the solute concentration in body ﬂuids.
2. Neutron activation analysis—which is a non-invasive technique that uses
electromagnetic radiation emission to estimate the elements of ﬂuid.
3. Hematological indices assessment which is an invasive method that uses blood
samples to estimate the hydration status.
4. Urine speciﬁc gravity test—measure hydration status by collecting urine samples
and analyzing its concentration level.
The limitations of the above-mentioned methods are expensive and invasive,
require biological samples, and require trained personnel and time consuming.
Body ﬂuids maintain skin elasticity. In the case of dehydration, the patient’s skin
loses its elasticity nature, and it will take more time to regain its normal position. The
skin pinch test (Fig. 1) is one of the simplest methods for accessing the dehydration
Fig. 1 Skin pinch test

An IoT-Based Smart Health Monitoring System
365
Fig. 2 Architecture of smart health monitoring system
state of patients. This assessment is not an effective method for measuring hydration
status in serious malnutrition patients and geriatric patients, and this method is also
subjective.
So, a device for monitoring hydration status is essential. To achieve this, wear-
able and non-invasive devices play a crucial role in long-term vital monitoring of the
human body’s imperative parameters in real-time. In case of any emergency situa-
tion, it alerts the caretakers as well as healthcare professionals. The Internet of things
technology provides global network infrastructure with quantiﬁed-self capabilities.
By using IoT technology (Fig. 2), this device provides an effective two-way commu-
nication system. The clinical decision support system aids patients with arrhythmia,
respiratory diseases, dialysis, geriatric, athletes, farmers, and ICU patients.
2
Problems with Existing System
The current systems (Table 1) only measure foremost vitals such as temperature,
SpO2, and heart rate. Most of the existing devices measure SpO2 in wrist using green
LED. So, it is absorbed by non-vascular tissues and provides inaccurate readings. In
existing system, there is a lack of
• Two-way communication between healthcare professionals and patient.
• Alert system—to indicate users, healthcare professionals.
• Clinical decision support system (CDSS).
• Hydration monitoring.
• Storing data in downloadable format for NABH accreditation.
3
Comparison of Proposed System with Existing Products
See Table 1.

366
R. Lakshmi et al.
Table 1 Comparison of proposed solution with existing products
Proposed
system
Product 1
(Noise colour
ﬁt)
Product 2
(Boat ﬂash
watch)
Product 3
(Honour
smart watch)
Product 4
(GOQII)
Battery
Rechargeable
battery
Rechargeable
battery
(lithium
polymer)
Rechargeable
battery
(lithium
polymer)
Rechargeable
battery
(lithium ion)
Rechargeable
battery
(lithium
polymer)
Shape
Rectangle
Rectangle
Rectangle
Rectangle
Rectangle
Width (mm)
26.5
36
36
36
36
Ambulance
alert
✓
✕
✕
✕
✕
Water
resistance
✓
✓
✓
✓
✓
Display size
(mm)
24
38
33
36
37
Parameters to
be monitored
Heart rate ✓
SpO2 ✓
Temperature
✓
Respiratory
rate ✓
Perfusion
index ✓
Hydration
level ✓
Heart rate ✓
SpO2 ✓
Temperature
✕
Respiratory
rate ✕
Perfusion
index ✕
Hydration
level ✕
Heart rate ✓
SpO2 ✓
Temperature
✕
Respiratory
rate ✕
Perfusion
index ✕
Hydration
level ✕
Heart rate ✓
SpO2 ✓
Temperature
✕
Respiratory
rate ✕
Perfusion
index ✕
Hydration
level ✕
Heart rate ✓
SpO2 ✓
Temperature
✕
Respiratory
rate ✕
Perfusion
index ✕
Hydration
level ✕
Power supply
(V)
3.7
4.2
4.2
3.0–4.2
4.2
4
Materials and Method
4.1
Temperature Measurement
Body temperature is one of the body’s ﬁrst reaction to most of the illness and infec-
tions. Temperature measurement is carried out to measure the fever spread in the
human body [5]. It helps to maintain the homeostasis body condition. It is one of
the key vital signs of all diseases. The requirement for temperature measurement is
measurement of core body temperature which ranges from 35 to 40 °C, high accuracy,
high precision, high resolution, good sensitivity, and long durability. The selected
sensor has the above-mentioned requirements in order to get appropriate results.

An IoT-Based Smart Health Monitoring System
367
5
Working Principle
The working principle of selected temperature sensor (Fig. 3) is the resistance
temperature detector (RTD). It will have a positive temperature coefﬁcient, i.e.
as the temperature of the body increases, corresponding resistance also increases
[3]. By measuring the resistance, we calculated the temperature of the patient body.
This method of measuring temperature provides accurate and reliable results with a
wide range of temperature. Advantage of the selected sensor (Fig. 4) is that it does
not require any calibration circuit and meets standard such as American Standard for
Testing and Materials (ASTM E1112) and International Standard for Organization
(ISO) standards and also suitable for remote applications. By measuring that resis-
tance, we obtained the temperature of the patient body. Based on price/performance,
we have selected the sensor that meets the above requirements.
5.1
Temperature Sensor
Temperature sensor speciﬁcations are shown in Table 2.
Fig. 3 Block diagram of temperature sensor

368
R. Lakshmi et al.
Fig. 4 Temperature sensor
Table 2 Temperature sensor
speciﬁcations
Operating temperature range
−55° to 150 °C
Supply voltage
1.8–5.5 V
Supply current
5 mA
Accuracy
±0.1 °C
Resolution
0.0078 °C
6
Blood Oxygen Saturation
SpO2 is the measure of the amount of haemoglobin saturated with oxygen as it shows
the monitoring of the overall health person [6]. The SpO2 of a patient’s blood and
heart rate is calculated using a SpO2 sensor. It uses photoplethysmography (Fig. 5)
to measure heart rate and SpO2. It uses infrared at 940 nm (absorbed by haemoglobin)
and red light at 660 nm (absorbed by deoxyhaemoglobin) [7]. At the receiving end, it
has a photodiode to detect how much light is absorbed. A portion of the light passes
through the tissues being absorbed and remaining light strikes the photodetector.
It creates a stable and non-pulsatile “DC current”. Veins and capillaries become
constant throughout the cardiac cycle. The variability in light absorption inﬂuences
PPG data (Fig. 6), and it is measured using the PPG sensor [8].
A healthy person should have SpO2 lying between 94 and 100% and a heart rate
lying between 60 and 100 beats per minute. The requirement of the sensor is accurate
measurement irrespective of skin pigmentation, skin thickness, and rejection of stray
light absorption. We can achieve these features through this sensor. This sensor
(Fig. 8) contains the following components (Fig. 7) such as optical elements, e.g.
LEDs (red and infrared), photodetectors, and low noise ﬁlters with the rejection of
Fig. 5
Photoplethysmography
principle

An IoT-Based Smart Health Monitoring System
369
Fig. 6 PPG waveform
ambient light. Beneﬁts of the selected sensor are that it has ultra-low power heart rate
monitor (1 mW) which improves its battery life, ultra-low shutdown mode (0.7 A)
which permits the voltage source to remain powered at any time, and it is efﬁcient
to be used in wearable devices.
Fig. 7 Block diagram of SpO2 sensor
Fig. 8 SpO2 sensor

370
R. Lakshmi et al.
Table 3 SpO2 and heart rate sensor speciﬁcations
Power supply
3.3 V
SNR ratio
High
Special features
Ultra-low shutdown current (0.7 uA), Low-power rate monitor (<1 mW)
6.1
SpO2 and Heart Rate Sensor
SpO2 and heart rate sensor speciﬁcations are shown in Table 3.
7
Hydration Measurement
Body hydration state measurement is essential to maintain body temperature, lubri-
cation of joints, prevention of infections, and proper function of organs. The level
of hydration impacted the exercise, blood thickness, and body ﬁtness activity [9].
Bioimpedance analysis is a non-invasive, objective, faster, cost-efﬁcient, and quan-
titative analysis method for assessment of hydration status in human body [10].
Dehydration is the second leading cause of death in infants and for 69% of geri-
atric patients. It causes deep vein thrombosis (DVT) [10], difﬁculty/failure in
continuous monitoring of dialysis patients for dehydration during intra, post, and
inter dialytic sessions, difﬁculty in objective monitoring of dehydration in severe
acute malnutrition patients. Bioimpedance analysis method is the simplest way of
acquiring patient’s hydration status by injecting high frequency, less amount of alter-
nating current into the patient’s body which adheres with the IEC60601-1 standard.
Impedance value is calculated, and by using this value, we can measure intracellular
water (ICW), extracellular water (ECW), and total body water (TBW) accurately.
Passing current ﬂow through tissues is shown in Fig. 9.
7.1
Wi-Fi Cum Microcontroller
Wi-Fi cum microcontroller is shown in Fig. 10. Microcontroller and its speciﬁcations
are shown in Table 4.
Cloud
Cloud database is shown in Table 5.

An IoT-Based Smart Health Monitoring System
371
Fig. 9
Current ﬂow in tissue at different frequencies
Fig. 10 Wi-Fi cum
microcontroller
Table 4 Microcontroller and
its speciﬁcations
Microcontroller
Tensilica 32-bit RISC CPU
Operating voltage
3.3 V
Input voltage
7–12 V
Digital I/O pins (DIO)
16
Clock speed
80 MHz

372
R. Lakshmi et al.
Table 5 Cloud database
Database
Real-time, accessed from a mobile device or Web browser, secure transmission of
data
Fig. 11 Block diagram of proposed solution
Fig. 12 Proposed solution
8
Methodology
Block diagram of proposed solution is shown in Fig. 11, and proposed solution is
shown in Fig. 12.
9
Features
1. Real-time monitoring (temperature, SpO2, heart rate, respiration rate, perfusion
index, hydration level)
2. Non-invasive
3. Portable

An IoT-Based Smart Health Monitoring System
373
Fig. 13 App display for nurse
4. Data security and privacy
5. Affordable
6. Ambulatory alert
7. Telemedicine
8. Two-way communication mobile application.
Figure 13 depicts how the mobile application works from the nurse’s point of
view. Once the mobile application is opened or started, the mobile application would
display all the patient’s vital information in a row-vice manner with colour indi-
cations, like red—for critical, yellow/orange—for vitals ﬂuctuation, and green for
normal condition. The nurse will be able to forward the alert to the doctor if the
condition of the patient is in a critical condition, and the nurse would be able to alert
an ambulance in case of an emergency situation.
Figure 14 depicts how the mobile application works from the patient’s point of
view. Once the mobile application is opened or started, the mobile application would
display all the values of the patient’s vitals that are being monitored if patient worn the
smart watch properly, otherwise feedback system sent the alert message to the patient.
The patient will be able to view his vital values, view the medicines if prescribed, and
see the ambulance location if the ambulance is being sent to the patient’s location.
Figure 15 depicts how the mobile application works from the doctor’s point of
view. Once the mobile application is opened or started, the mobile application would
display alert messages which is forwarded from the nurse that will appear in a row-
vice manner with colour indications, like red—for critical and yellow/orange—for
vitals ﬂuctuation. The doctor will be able to prescribe medications to a patient in
a virtual mode, meet the patient virtually, and send an ambulance to the patient’s
location in an adverse situation.

374
R. Lakshmi et al.
Fig. 14 App display for patient
Fig. 15 App display for doctor
10
Result
A wearable monitoring device is designed to continuously monitor the health symp-
toms from remote locations. The temperature, heart rate, and SpO2 of the patients
are successfully obtained with an accuracy of 98.4%, 97%, and 97.6%, respectively.
The hydration status is displayed with an accuracy of 98.3%. The obtained result
is successfully displayed using mobile application featured with effective two-way

An IoT-Based Smart Health Monitoring System
375
Fig. 16 Comparison with
gold standard method
communication system. The accuracies are validated using gold standard methods.
The medical data of corresponding patients are sent to clinicians, nurses, and patients
and informed to the respondents of the family to minimize the stress. Comparison
with gold standard method is shown in Fig. 16.
11
Future Work
• Making ﬂexible electronics
• Integrated with existing respiratory devices such as ventilator and oxygen
conservative device
• Monitoring ECG by using electrodes inside wearable t-shirts.
References
1. https://www.who.int/health-topics/chronic-respiratory-diseases#tab=tab_1
2. Mejía F, Medina C, Cornejo E, Morello E, Vásquez S, Alave J, Schwalb A, Málaga G (2020)
Oxygen saturation as a predictor of mortality in hospitalized adult patients with COVID-19 in
a public hospital in Lima, Peru. PLoS ONE 15(12):e0244171
3. https://www.who.int/news-room/fact-sheets/detail/diarrhoeal-disease
4. Khalil SF, Mohktar MS, Ibrahim F (2014) The theory and fundamentals of bioimpedance
analysis in clinical status monitoring and diagnosis of diseases. Sensors 14(6):10895–10928
5. Al Bassam N, Hussain SA, Al Qaraghuli A, Khan J, Sumesh EP, Lavanya V (2021) IoT based
wearable device to monitor the signs of quarantined remote patients of COVID-19. Inform
Med Unlocked 24:100588
6. Sabukunze ID, Setyohadi DB, Sulistyoningsih M et al (2021) Designing an Iot based smart
monitoring and emergency alert system for Covid19 patients. IEEE, April 2021
7. Chan ED, Chan MM, Chan MM (2013) Pulse oximetry: understanding its basic principles
facilitates appreciation of its limitations. Respir Med 107(6):789–799
8. Guk K, Han G, Lim J, Jeong K, Kang T, Lim E-K, Jung J (2019) Evolution of wearable devices
with real-time disease monitoring for personalized healthcare. Nanomaterials 9(6):813

376
R. Lakshmi et al.
9. (2019) A comparative study of body hydration measurement techniques for health moni-
toring. In: 2019 6th international conference on computing for sustainable global development
(INDIACom). IEEE, pp 1101–1105
10. Moonen HPFX, Van Zanten ARH (2021) Bioelectric impedance analysis for body composition
measurement and other potential clinical applications in critical illness. Curr Opin Crit Care
27(4):344
11. https://www.grandviewresearch.com/industry-analysis/wearable-medical-devices-market
12. Nemcova A, Jordanova I, Varecka M, Smisek R, Marsanova L, Smital L, Vitek M (2020)
Monitoring of heart rate, blood oxygen saturation, and blood pressure using a smartphone.
Biomed Sig Process Control 59:101928
13. Whitehead FJ, Couper RTL, Moore L, Bourne AJ, Byard RW (1996) Dehydration deaths in
infants and young children. Am J Forensic Med Pathol 17(1):73–78
14. https://apps.who.int/iris/bitstream/handle/10665/338882/WHO-2019-nCoV-clinical-2021.1-
eng.pdf
15. Phillips C, Liaqat D, Gabel M, de Lara E (2021) WristO2: reliable peripheral oxygen saturation
readings from wrist-worn pulse oximeters. In: 2021 IEEE international conference on pervasive
computing and communications workshops and other afﬁliated events (PerCom Workshops).
IEEE, pp 623–629
16. Agcayazi T, Hong GJ, Maione B, Woodard E (2016) Wearable infant hydration monitor. In:
2016 IEEE virtual conference on applications of commercial sensors (VCACS). IEEE, pp 1–10
17. Muneer A, Fati SM, Fuddah S (2020) Smart health monitoring system using IoT based smart
ﬁtness mirror. In: TELKOMNIKA (Telecommunication computing electronics and control),
vol 18(1), pp 317–331
18. Tham OY, Markom MA, Abu Bakar AH, Mohd Muslim Tan ES, Markom AM (2020) IoT
health monitoring device of oxygen saturation (SPO2) and heart rate level. In: 2020 1st interna-
tional conference on information technology, advanced mechanical and electrical engineering
(ICITAMEE). IEEE, pp 128–133

Multi-Stage Fruit Grading System
S. Anjali, Vinny Pious, Joel J. Sebastian, J. Krishnanunni, Joveal K. Johnson,
and Ashik Mujeeb
Abstract Fruit classiﬁcation and grading is an important task in many industrial
applications. Fruit grading is a crucial step for producers that has an impact on the
assessment of fruit quality and the export market. Even while humans are capable of
grading and sorting, it is a long, labour-intensive, error-prone, and tiresome process.
Consequently, a sophisticated method of fruit grading is required. Researchers have
recently created a variety of computer vision-based fruit sorting systems. But they
have had some shortcomings like they does not use the best classiﬁcation model
with the best possible accuracy or that they either classify the fruit based on type or
classify fruits based on ripeness. In this paper, we propose a multi-stage fruit grading
system using deep learning. This system has three phases:
1. Classiﬁcation of fruits based on if it is a banana or not.
2. Classiﬁcation of banana based on freshness.
3. Classiﬁcation of fresh banana based on ripeness. We have used different pretrained
CNN models and identiﬁed the best ones in the different phases of the system. The
experimental result shows that MobileNet, Resnet 50, and Inception V2 produce
higher accuracy for phase 1, phase 2, and phase 3, respectively.
Keywords Deep learning · Convolutional neural network · MobileNet · Resnet ·
Visual geometric Group
1
Introduction
India annually produces 75 million tonnes of fresh fruit and 146 million tonnes of
vegetables. The perishability, seasonality, and size of fruits and vegetables make
marketing them more difﬁcult than with many industrial items. Marketing for fruits
Supported by Mar Baselios College of Engineering and Technology.
S. Anjali (B) · V. Pious · J. J. Sebastian · J. Krishnanunni · J. K. Johnson · A. Mujeeb
Mar Baselios College of Engineering and Technology, Mar Ivanios Vidya Nagar, Nalanchira,
Thiruvananthapuram, Kerala 695015, India
e-mail: anjali.s@mbcet.ac.in
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_28
377

378
S. Anjali et al.
Fig. 1 Architecture diagram
and vegetables is made more challenging by the diverse consumption habits of Indian
customers and a weak supply chain infrastructure. The maintenance of the supply
chain depends on efﬁcient warehouse management.
Hence, we concentrated on the warehouse part of the supply chain. A fruit clas-
siﬁcation system may be used to identify the fruit species and identify defective
fruits. It may also be used to help people decide whether speciﬁc fruit species meet
their dietary requirements [6–10]. India is the largest producer of bananas in the
world, with a production of 297 lakh MT. Therefore, we concentrated on effective
ways to manage banana fruit in a warehouse. We propose a three-step approach in
classifying bananas, for their efﬁcient storage in a warehouse. In the ﬁrst step, we
separate bananas from other fruits. In the second step, we separate the fresh bananas
from the rotten ones [4], and in the third one, we classify the bananas into four
categories based on their ripeness level [2]. The different steps in our system are
shown in Fig.1. Based on the literature survey that was conducted, we were able
to identify that CNN-based models were able to produce better results than other
proposed methods. For this project, we used some of the best-performing models to
build an effective system to classify bananas. Warehouse management can use this
information in organizing and managing related warehouse activities. The general
block diagram of the process is shown in Fig.1.
2
Related Works
Karakaya et al. [3] conducted a study to comparatively analyse an image dataset
containing samples of three types of fruits to distinguish fresh samples from those of

Multi-Stage Fruit Grading System
379
rotten.Theyalsoproposedavision-basedframeworkwhichutilizeshistograms,grey-
level co-occurrence matrices, bag of features, and convolutional neural networks for
feature extraction. Well-known classiﬁers based on support vector machines are used
for the classiﬁcation process. The implementation of convolutional neural network-
based features consistently yields the highest success rates, according to testing of
several experimental situations, including binary and multi-class classiﬁcation tasks.
Chakraborty et al. [4] used three deep learning methods: max pooling, average
pooling, and mobile net, to classify fruits based on whether they are rotten or fresh.
Mobilenethadthebestaccuracywith99.06%whilemaxpoolingandaveragepooling
had an accuracy of 94.49 and 93.06% respectively.
Supekar and Wakode [5] classiﬁed mangoes into different grades based on differ-
ent parameters such as colour, size, and shape. They used a pretrained random forest
classiﬁer for this purpose which gave an accuracy of 99.5%.
3
Proposed Work
3.1
Problem Statement
To develop, compare, and analyse different deep learning models for identifying if
the fruit is a banana, the quality of the banana, and also grading it into different
ripening levels.
3.2
Methodology
Automatic classiﬁcation of fruit freshness plays an important role in the food indus-
try. But the traditional methods that detect the freshness of fruits are slow, laborious,
and time-consuming. Therefore, we propose an approach for fruit freshness classiﬁ-
cation which can potentially reduce human efforts. This can also reduce the cost by
identifying the defects in the fruits. In this approach, we classify banana based on
their freshness level and also grade them based on their ripening levels. The sample
input image given to the model is shown in Fig.2.
Level 1 The pretrained MobileNet models were used in phase 1. MobileNet can
classify about 1000 different objects. Here, V2 and V3 are improvements over the
version 1. Before feeding the image of object, they are ﬁrst preprocessed. Prepro-
cessing includes resizing to target size 224 * 224 and then they are converted to an
array and then expanded to ﬁt the model. The image pixel values are mapped from
(0, 255) to (−1, 1). The image is classiﬁed as banana or not based on the highest
value from the result array. The experimental result of level 1 classiﬁcation is shown
in Fig.3.

380
S. Anjali et al.
Fig. 2 Input image
Fig. 3 Result of level 1
classiﬁcation
Fig. 4 Accuracy and loss of
Resnet 50
Level 2 After comparing various models such as VGG-16, MobileNet V2 and V3,
Inception V2, and Resnet 50, we found out that Resnet 50 gives the best performance.
The training and validation accuracy of Level 2 is shown in Fig.4.
Level 3 After comparing different models, the best one was found out to be Inception
V2. Figure5 shows the training and validation accuracy of Level 3.

Multi-Stage Fruit Grading System
381
Fig. 5 Accuracy and loss of
Inception V2
4
Result Analysis
After trying out aforementioned models by varying the epochs, batch sizes, and
optimizers, the following conclusions can be made:
At stage 1, for identifying whether the fruit is banana or not, both MobileNet
V1 and MobileNet V2 have shown the best performance. At stage 2, for classifying
rotten bananas from fresh ones, Resnet50 and Resnet50 V2 have proven to be the best
with accuracy 100% at epoch 20 with adam as optimizer. At stage 3, for classifying
fresh bananas to green, yellow, and over ripen, Inception V2 has come out as the best
model with accuracy of 99.8% with adam as optimizer (Fig. 6).
Performance of various models is as follows.
4.1
Based on Number of Epochs
See Figs. 7, 8 and 9.

382
S. Anjali et al.
Fig. 6 Best models
Fig. 7 Level 1
Fig. 8 Level 2
Fig. 9 Level 3

Multi-Stage Fruit Grading System
383
4.2
Based on Batch Size
See Figs. 10 and 11.
4.3
Based on Optimizer Used
See Fig. 12 and 13.
4.4
Conclusion and Future Scope
A three-phase architecture based on computer vision and various deep learning
methods such as Inception V2, Inception V3, Resnet50, Resnet50 V2, MobileNet,
MobileNet V3, VGG-16, and MobileNet V2 for fruit classiﬁcation, freshness check-
ing, and ripeness classiﬁcation was proposed in this paper. We came to the conclusion
that some of the model showed better results than others such as MobileNet for check-
Fig. 10 Level 2
Fig. 11 Level 3

384
S. Anjali et al.
Fig. 12 Level 2
Fig. 13 Level 3
ing whether the fruit was a banana or not, Resnet 50 for classifying fruit based on
freshness, and Inception V2 to classify the fruit based on ripeness. Excellent accuracy
was noted during all three phases.
As for future work, a fourth phase will be added to the framework which will
classify the fruit based on the mode of ripening whether the fruit was artiﬁcially
ripened using chemicals or not.
This method of three-phased approach is targeted at a warehouse facility in the
hopes that it brings about a deeper insight to the future researchers and entrepreneurs
who wants to engage in the thriving business of banana market and export.
References
1. Shamim Hossain M, Al-Hammadi A, Muhammad G (2019) Automatic fruit classiﬁcation using
deep learning for industrial applications. IEEE Trans Ind Inform 15(2)
2. Mazen FMA, Nashat AA (2019) Ripeness classiﬁcation of Bananas using an artiﬁcial neural
network. Arab J Sci Eng 44:6901–6910. https://doi.org/10.1007/s13369-018-03695-5
3. Karakaya D, Ulucan O, Turkan M (2020) A comparative analysis on fruit freshness classiﬁca-
tion. In: Innovations in intelligent systems and applications conference, pp 1–4
4. Chakraborty S, Shamrat FMJM, Billah MM, Jubair MA, Alauddin M, Ranjan R (2021) Imple-
mentation of deep learning methods to identify rotten fruits. In: 2021 5th international confer-
ence on trends in electronics and informatics (ICOEI), pp 1207–1212
5. Supekar A, Wakode M (2020) Multi-parameter based mango grading using image processing
and machine learning. INFOCOMP 19(2):175–187
6. Vaviya H, Yadav A, Vishwakarma V, Shah N (2019) Identiﬁcation of artiﬁcially ripened fruits
using machine learning. In: 2nd international conference on advances in science and technology
(ICAST), April 2019

Multi-Stage Fruit Grading System
385
7. Dang H, Song J, Guo Q (2010) A fruit size detecting and grading system based on image
processing. In: 2010 second international conference on intelligent human-machine systems
and cybernetics
8. Vibha V, Vinamra, Sampada KS (2021) Fruit grading to assist selection of fresh fruits. In: 2021
international conference on circuits, controls and communications (CCUBE)
9. Wu H-K, Wang J-S, Chen Y-H (2020) Development of fruit grading system based on image
recognition. In: 2020 IEEE 2nd international conference on architecture, construction, envi-
ronment and hydraulics (ICACEH)
10. Shamim Hossain M, Al-Hammadi M, Muhammad G (2019) Automatic fruit classiﬁcation
using deep learning for industrial applications. IEEE Trans Ind Inform 15(2)

Sentiment Analysis on Feedback Data
of E-commerce Products Based on NLP
K. Sumathi and Kundhavai Santharam
Abstract In today’s competitive business world, companies seek strategies to
keep their existing customer base satisﬁed while also attracting new customers by
launching new offers or products with a mix of chosen marketing mix. It has become
necessary to keep track of whether customers like or dislike a product and how
they react to a particular offering in order to improve the service and stay ahead of
competitors. The focus of this paper will be on using NLP technique-sentiment anal-
ysis, which analyzes the customer sentiments based on customer reviews/feedback
data for a product, which beneﬁts businesses by keeping track of consolidated review
on a product. In this paper, we used Amazon product review datasets form Kaggle,
dataworldandperformedsentimentanalysistounderstandtheoverallcustomersenti-
ments based on customer reviews in a better and reﬁned manner. The current study’s
dataset includes 30,653 customer reviews for various products. Python NLTK Library
has been used for pre-processing and to generate a model using the Regression
Algorithm. The model performs well with F1-Score 0.87.
Keywords Natural language processing for sentiment analysis · Analysis of
product reviews · Customer feedback analysis
1
Introduction
Today the evidence of natural language processing (NLP)’s cutting-edge impact is
realized by many decision makers in corporate and other sectors. In every wink of
a moment, each and everyone seeks to turn toward resolving issues at one point of
time or the other in their ﬁled. Every individual is unique by their own ways and their
opinions vary from one person to another in varied circumstances. There arises a need
K. Sumathi (B)
Department of BCA, The American College (Autonomous), Madurai, Tamil Nadu, India
e-mail: Sumathirajkumar2006@gmail.com
K. Santharam
Department of Business Administration, Kalasalingam Academy of Research and Education,
Krishnan Koil, Tamil Nadu, India
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_29
387

388
K. Sumathi and K. Santharam
to search for a process that enables one to help categorize the opinions of people. The
process of computationally identifying opinions and categorizing can be expressed
in a piece of text, particularly in order to determine whether the writer’s attitude
toward a particular topic, product, etc., is positive, negative, or neutral, is known as
sentiment analysis. Sentiment analysis, also known as opinion mining, is a natural
language processing (NLP) technique that identiﬁes the emotional tone of a body of
text. This is a popular method for businesses to determine and categorize customer
opinions about a product, service, or idea. Sentiment analysis is a powerful marketing
tool that allows product managers to understand customer emotions and incorporate
them into marketing campaigns. It is an important factor in product and brand recog-
nition, customer loyalty, customer satisfaction, advertising and promotion success,
and product acceptance. Any corporate company would always look out to choose
a benchmarking strategy to acquire its customers, and in this study, the opinions of
the customers recorded in social media platform are taken into consideration.
This is an era with a buzz word ‘online shopping’ and writing instant reviews of
their shopping experience. The reviews and ratings play a vital role for a product
life cycle in the market irrespective of its sector. The ratings and reviews are
taking the form of emotions being expressed by the customers. On the basis of the
review,theproductmanufacturerspredicttheirlikelysalesalternatingtheirmarketing
mix. In the current study, the researchers have identiﬁed a solution to measure the
emotions/opinions which is recorded online through the forms of reviews/a set of
texts. In the view of extracting information for sentiment analysis, a machine learning
(ML) and natural language processing (NLP) engine is used in the study. In general,
machine learning enables the software to improve its ability to predict the results of
analyses without being explicitly coded. In essence, it gives the program the ability
to ‘learn’ from the experience and develop over time. NLP is used to examine human
language and decipher its meaning. This includes terminology extraction, gram-
matical analysis, and text segmentation. While we analyze the suitable algorithmic
technique for the sentiment analysis, the ML and NLP are used as tools to derive
the ﬁnal inferences and ﬁndings. Three categories of algorithms are typically used
namely—role-based, automatic, and hybrid, respectively.
• Rule-based—This is the simplest and most straightforward strategy to use. It
evolves manual predictions with set of rules created, which aid the system in
analyzing the content it reads. The limitation of relying on manual inputs is that
when the numbers increases and evolves in lots, it becomes difﬁcult unlike an
automated one.
• Automatic—This is the most sophisticated method, combining ML and NPL.
Thousandsofphrasesthathavealreadybeenclassiﬁedasnegative,neutral,orposi-
tive are initially fed into the system which is the phase known as ‘training.’ Then,
armed with its newly acquired information, it may go to the next stage—“predic-
tion,” comprehend brand-new terminologies, and properly categorize them. But
the drawback which is inevitable is that the algorithm tends to commit errors,
and it might often be a challenging and herculean task to determine the reason
underlying the committing of errors.

Sentiment Analysis on Feedback Data of E-commerce Products Based …
389
• Hybrid—This algorithm combines the greatest features of both worlds. This
method quickly runs through new phrases and expressions while utilizing the
rule-based algorithm’s at a high level of accuracy.
The sentiment analysis tool can review the unending content and rate it based
on its negative, neutral, or positive sentiment, and the decision makers would be
thankful for its existence as a sophisticated algorithm in place.
2
Review of Literature
Whileweinvestigatetherelatedwork,itisnotedthatinrecentpastvariousresearchers
in the ﬁeld of information technology and marketing are keen in investigating into
the opinions recorded by the customers and sentiment analysis/opinion mining is
utilized widely. Ozan et al. [12] attempt to resolve the problem that is faced by the
company in terms of data segmentation using various machine learning methods.
Bhatnagar and Bhatia [1], in their study, have evolved the sentiment analysis and
have highlighted that it not only enables one to segregate the information from the
demographic perspective but also from the subjective perspective of handling the
information as well. The process highlighted is that the use of spectral clustering and
extraction through cluster labels in order to perform supervisory-based classiﬁcation
with the help of supervised algorithms. The accuracy level has also been checked in
their study. In our current study, the model is being run to check the accuracy level,
and the ﬁndings and conclusions are arrived at facilitating effective decision making.
While citing the work by Cambria et al. [3], it is noted that ‘both ﬁelds use data
mining and natural language processing (NLP) techniques to discover, retrieve, and
distillinformationandopinionsfromtheWorldWideWeb’svasttextualinformation.’
The also indicates that it is critical and has mentioned the task of analyzing the
textual information available on worldwide web to be a challenging one. Especially,
the aspects such as explicit, implicit, regular, irregular, syntactical, and semantic
language rules are very difﬁcult, and one has to be meticulous. In the current study,
the researchers have meticulously taken into consideration the above aspects while
analyzing the textual information.
Batra [7] in competition forum has published a work related to CX—which is
customer experience. The customer experience is witnessed with the interaction(s)
one makes with that of the company. The interactions may be either through oral
reviews, printed ones, textual information shared or recorded in an open forum, etc.
In their study, it is indicated that the customer experience-based study shall help
both the companies by paving a way to achieve customer service excellence and
academicians by way of formulating a research agenda about the emerging trend or
forecasts related to customer experience topics. In the paper, the challenging aspects
of the companies such as calculating the return on investment with the customer
experience are highlighted. Hence, the opinion mining and sentiment analysis help

390
K. Sumathi and K. Santharam
the companies to convert the ﬁndings and inferences in terms of monetary value and
calculate the return on investment.
Another study conducted by Xu et al. [14] has utilized word clouds, and cluster and
word association analyses for understanding the unstructured textual data available
on brand-owned social media. The current study also with the sentiment analysis has
takenintoconsiderationthedatasets availablethroughKaggle—themachinelearning
and data science community. The paper indicates that the customer sentiments are
expressed at varied levels of mindsets of customers based on the perceived brand’s
coreposition.Hence,itisclearlyindicativethatthecustomersentimentstakedifferent
stance from varied experiences, which makes the analysis task to be a challenging
one.
Simkin [11] in the report compiled reﬂects that the analytics has gone a long
way where from the level of directors, company leadership teams are used to getting
updates through the market intelligence and other advanced methods of customer
updates. Therefore, the sentiment analysis the prime step toward the level of advanced
methods of market intelligence and getting customer updates. It has also tapped upon
the aspect of CRM systems that harnesses the associated customer data.
Sharef et al. [10] have shared insights based on the big data availability being vast
due to decreased cost in data storage and computing power especially and previously
we were in an era of depending on the transactional data wherein with the current
scenario—evolves big data and ensures delivery of business value. Hence, the current
study also validates the point that add to business value to the current setup when
these sentiment analysis is performed and taken toward the step of big data analysis
and analytics-based initiatives for the companies.
The data from social media platform—twitter has been taken into consideration
for using sentiment analysis elaborated in a conference paper by Hasan et al. [9].
They have also highlighted that the analysis helps the business entity to have an
effective product marketing. In their study, they have incorporated bag of words
(BoW), Term Frequency-Inverse Document Frequency (TF-IDF) model concept to
analyze sentiment. In the current study, the textual information has been extracted
from machine learning and data science platforms that are available online and as
an open source. The use of Term Frequency-Inverse Document Frequency (TF-IDF)
model concept to analyze sentiment has also been evolved, and the accuracy has been
improved with the use of the model.
Analyzing in general a qualitative data is a crucial task; in recent past NLP is used
to analyze qualitative data. Crowston et al. [6] in their paper had initiated to take the
human natural language processing and tried to automate content analysis by means
of extracting theoretical evidence in an effective manner. The paper is an effective
contribution as it is the ﬁrst to attempt the data which is qualitative in nature. Hence,
with this concept of taking into consideration the qualitative data as the basis of the
study, the current study also has taken the qualitative data that is recorded in the
forms of set of texts on the social media reviews.
Hsu et al. [2], in their work, have taken the scanned documents of electronic health
records which has been a challenge that is faced by many and analyzed using NLP and
other image pre-processing methods. Almost taking seven machine learning models

Sentiment Analysis on Feedback Data of E-commerce Products Based …
391
into consideration, the study has initiated the analysis. Hence, in our study, the pre-
processing and other steps are followed to ensure the accuracy level. Indrawati and
Alamsyah [4], in their conference paper, have highlighted about the data analytics
use for market segmentation in telecommunication industry in Indonesia, and they
had called their analysis work to be social network data analytics-based community
detection method. The segregated groups and their views and responses or topics are
analyzed, and the attitude toward the product is found out [1–14].
3
Proposed Work
The process of performing sentiment analysis on a dataset containing product reviews
and data labels such as ‘Positive,’ ‘Neutral,’ and ‘Negative’ sentiment for these
reviews consists of several steps, such as (i) data collection, (ii) pre-processing using
NLP Techniques, (iii) selecting the appropriate algorithm for classiﬁcation, and (iv)
determining the metrics of analytical model, respectively. The data ﬂow diagram of
sentiment analysis on customer reviews is shown in Fig. 1.
3.1
Data Collection
The dataset, which includes various product reviews for sentiment analysis, was
obtained from kaggle and data world. The obtained dataset contains 30,653 instances,
Fig. 1 Sentiment analysis on customer reviews—workﬂow

392
K. Sumathi and K. Santharam
Fig. 2 Data set—preview
each with 20 attributes that include product and customer details in various aspects.
The preview of the dataset is shown in Fig. 2.
Only three relevant features were extracted and saved in a separate Excel ﬁle for
analysis by the researchers: ‘Brand Name,’ ‘Sentiment,’ and ‘Reviews.’ This ﬁle
has been uploaded to Google Drive so that it can be easily accessed from Google
Colab. Kulkarni et al. [5] attempted to analyze viral advertising and demonstrate that
sentiment analysis is a promising tool for quantifying customer responses. The text
data was pre-processed using NLP techniques, and the samples were classiﬁed using
the Random Forest classiﬁer. The procedure for performing sentiment analysis is as
follows: pre-processing of text, converting text to vectors, and classiﬁcation.
3.2
Pre-processing of Text
To remove extraneous information from the text, which may result in a less accurate
model, data pre-processing is required. Lower casing, Tokenization, Special Charac-
ters Removal, Lemmatization, and Stop Word Removal must all be performed during
the text pre-processing phase. Virmani et al. [13] have conducted a study with the
help of extracted information from social media using NLP, and they have postulated
mainly on the aspect that NLP is evolved to enhance the accuracy of visualizing the
structured data available. Therefore, in our study to the data pre-processing has been
evolved.

Sentiment Analysis on Feedback Data of E-commerce Products Based …
393
Fig. 3 Lower casing
(a) Lower casing
Lower casing is a common text pre-processing step that is applied based on the
problem statement. When the dataset contains text that is used to recognize people’s
emotions, this step can be skipped because doing so will result in information loss,
such as using upper case words to show anger or excitement. Reviews after lower
casing is displayed in Fig. 3.
(b) Tokenization
Tokenization is the next step in pre-processing text data. It involves breaking each
sentence down into individual words. Tokenization assists in interpreting the meaning
of the text by analyzing the word sequence. However, it is a common method for
analyzing large amounts of text data. It is efﬁcient and convenient for computers to
analyze text data by examining what words appear in an article and how many times
these words appear, and it is sufﬁcient to provide insightful results. The output of
Tokenization process is shown in Fig. 4.
(c) Special Characters Removal
Special characters such as brackets, commas, and so on add no value to the text
information and can be removed. The built-in library in Python named ‘string’ which
includes an attribute string.punctuation with a predeﬁned list of punctuations that can
be used to remove punctuation. Word tokens before and after punctuation removal
is shown in Fig. 5.
(d) Lemmatization
Lemmatization necessitates the word’s part of speech tag value within the sentence.
The lemmatization with NLTK will be ineffective unless you know whether the
word is used as a verb, noun, or adjective. To perform lemmatization effectively
with NLTK, use the ‘wordnet’ and ‘pos’ parameters. We have used WordNetLem-
matizer.lemmatize. The output of lemmatization is given in Fig. 6.

394
K. Sumathi and K. Santharam
Fig. 4 Tokenization
Fig. 5 Punctuation removal
(e) Stop Word Removal
Stop Word removal is supported by NLTK, and the list of stop words is available
in the corpus module. To remove stop words from a sentence, divide it into words
and then remove the word if it appears in NLTK’s list of stop words. A stop word
is a commonly used word such as ‘the,’ ‘a,’ ‘an,’ or ‘in’ that a search engine has
been programmed to ignore, both when indexing entries for searching and retrieving
them as the result of a search query. These words are not required to take up valuable
database space or processing time. These words can be easily removed by keeping
a list of words that you consider stop words. Python’s Natural Language Toolkit
(NLTK) has a list of stop words stored in 16 different languages. They are located
in the NLTK data directory. Product reviews after removing stopwords are shown in
Fig. 7.

Sentiment Analysis on Feedback Data of E-commerce Products Based …
395
Fig. 6 Lemmatization
Fig. 7 Stop word removal
3.3
Converting Text to Vectors
Basically, the raw text is not directly understood by ML models. As a result, text
data must be converted into vectors that encode the contextual meaning of words and
keep similar words together in dimensional space. Words like phone, mobile, and cell
phone, for example, will appear closer to each other in dimensional space and further
away from unrelated words like ‘nice,’ ‘good,’ and so on. The process of converting
text into vectors is known as word embedding, and the Word2Vec algorithm is used
to generate these embeddings as shown in Fig. 8.

396
K. Sumathi and K. Santharam
Fig. 8 Word embedding
Word2Vec employs a neural network with a single hidden layer to predict the
likelihood of each word in a text corpus being closer to the input word in dimensional
space. The intuition here is that similar words are used in similar contexts and appear
closer to each other in dimensional space, so the probability for similar words should
be higher, but the goal of training a neural network in the Word2Vec algorithm is to
learn weights of the hidden layer rather than using resulting neural network itself.
These weights are our word vectors, which provide us with the location of words
in a three-dimensional space. Genism is an open-source Python natural language
processing (NLP) library that provides Word2Vec model algorithms for learning
word associations from a large corpus of text.
3.4
Classiﬁcation
Now that we have vectors for each word in our corpus, we will take the average
of all the vectors in a sentence, resulting in an average array of 100 dimensions for
that review statement. The features of our statement will be represented by this 100-
dimension average array, which will be used by the classiﬁcation model to predict
sentiments and used by the classiﬁcation model to categorize the sentiments.
Dataset is split into training and test dataset. Percentage split used for this analysis
is20.Trainingdatasetisusedtotrainthemodelwhereastestdatasetisusedtoevaluate
the performance of the model. Classiﬁcation model has been trained on the data to
predict sentiments once we have the features of reviews (Fig. 9).
4
Evaluation of Trained Model
In order to evaluate the model’s performance, a classiﬁcation report and confu-
sion matrix was created. For the text classiﬁcation problem, the Gensim Word2vec
embedding method and Random Forest classiﬁcation model produced high accuracy.
Random Forest was selected for this problem statement because it outperforms other
classiﬁcation algorithms (Support Vector Machines, Logistic Regression) across all
evaluation metrics, including Precision, Recall, and F1.

Sentiment Analysis on Feedback Data of E-commerce Products Based …
397
Fig. 9 Model training
Classiﬁcation Report—Training Dataset
The number of instances used for analysis is 30,653, and the split between train and
test data is 80%. The model is trained on 80% of the dataset; approximately 24,521
instances are used to train the model, and approximately 6131 instances are used to
evaluate the model’s performance. Once the model has been trained, its performance
is evaluated using the same training dataset. Figure 10 shows the F1-score of the
model for the training dataset, and Fig. 11 shows the model’s confusion matrix.
Fig. 10 Classiﬁcation report—training dataset

398
K. Sumathi and K. Santharam
Fig. 11 Confusion
matrix—training dataset
Classiﬁcation Report—Test Dataset
The performance of the same model is evaluated using the test dataset, which contains
the remaining 6131 instances of the obtained dataset. Figure 12 shows the model’s
F1-score for the test dataset, which is 86%, and Fig. 13 shows the model’s confusion
matrix for the test dataset.
The total number of Amazon products available in the test dataset is 3202. 209
reviews are neutral, indicating that customers are satisﬁed with the product, 2755
reviews are positive, indicating that customers like the product, and 238 reviews are
negative, indicating that customers dislike the product. We can accomplish this by
creating a word cloud of positive feedback that is shown in Figs. 14 and 15.
Fig. 12 Classiﬁcation report—test dataset

Sentiment Analysis on Feedback Data of E-commerce Products Based …
399
Fig. 13 Confusion matrix—test dataset
Fig. 14 Sentiment predicted for Amazon products
5
Conclusion
While we assume that a company of yours which has launched recently a product and
wishes to learn about market reaction—it is at that juncture the current model will
assist you in predicting sentiments by leveraging product reviews and determining
how many people have given positive reviews and how many have given negative

400
K. Sumathi and K. Santharam
Fig. 15 Word cloud image
reviewsononehand.Ontheotherhand,ingeneralthetechniquethatevolvesNLPand
performed with sentiment analysis it paves a way for NLP researchers to progress
in their ﬁeld of study and witness huge impact. The current study enables one to
understand the goal of performing the sentiment analysis using NLP technique that
categorizescustomerreviewsbasedoncustomersentimentsforaproductandbeneﬁts
businesses by tracking customer reviews on a product. The downloaded datasets from
datasets are from Kaggle which were used to perform sentiment analysis in order
to better understand customer behavior based on reviews submitted by them. The
Python NLTK Library was used to perform various pre-processing techniques, and
the Regression Algorithm was used for classiﬁcation. The model performs well, with
F1-Score0.86asevidencedbythemodel’saccuracymatrix.Offlate,manycompanies
are using opinion mining to gauge the emotions of the customers connected through
their reviews on social media; hence, the current study also enables the market to
forecast the trend and also strategizes their positioning of their products in an effective
manner. When the strategies are streamlined as per the customer expectation, the
companies shall achieve a level of excellence in their quality. The reviews recorded
as textual information about a service is a major indicator for service quality and
ultimatelyleadingtoserviceexcellence.Hence,thecurrentstudyincludesthereviews
as dataset of products wherein the services is not taken into consideration. Therefore,
the future researchers can take service points into consideration to gauge the textual
information.
The study enables to enrich the quality of the products offered by the company
in case the corporates initiate suitable customer focused strategies rather than mere
product focused strategies. As a result, the overall product or service market reaps the
fruits of customer experience excellence. The emerging area of CX investment areas
are highlighted in the work done by Batra [8]—they are overall CX, contact center
investment customer insight investment, digital, social and marketing investment,
respectively. Therefore, the current study also paves a way to explore the possibilities
of such areas in corporate or service arenas. Moreover, the study can be helpful
at positioning the product or service excellence at an International level too. In
the future, the customer relationship management system can also be taken into

Sentiment Analysis on Feedback Data of E-commerce Products Based …
401
consideration at an advanced level and pitch in a suitable model through the sentiment
analysis and opinion mining.
References
1. Bhatnagar A, Bhatia M (2022) A sentiment analysis based approach for customer segmentation.
Rec Patents Eng 16(2):32–42(11)
2. Hsu E, Malagaris I, Kuo Y-F, Sultana R, Roberts K (2022) Deep learning-based NLP data
pipeline for EHR-scanned document information extraction. JAMIA Open 5(2):1–12
3. Cambria E, Schuller B, Xia Y, Havasi C (2013) New avenues in opinion mining and sentiment
analysis. IEEE Intell Syst 28(2):15–21
4. Indrawati, Alamsyah A (2017) Social network data analytics for market segmentation in
Indonesian telecommunications industry. In: International conference on information and
communication technology (ICoIC7) paper. IAN: 17261950
5. Kulkarni KK, Kalro AD, Sharma D, Sharma P (2020) A typology of viral ad sharers using
sentiment analysis. J Retail Consum Serv 53:101739
6. Crowston K, Allen EE, Heckman R (2011) Using natural language processing technology for
qualitative data analysis. Int J Soc Res Methodol 15(6):523–543
7. Batra MM (2017) Customer experience—an emerging frontier in customer service excellence.
Competition Forum 198–207
8. Batra MM (2017a) Customer experience—an emerging frontier in customer service excellence.
Competition Forum 198–207
9. Hasan MdR, Maliha M, Arifuzzaman M (2019) Sentiment analysis with NLP on Twitter data.
In: International conference on computer, communication, chemical, materials and electronic
engineering (IC4ME2)
10. Sharef NM, Zin HM, Nadali S (2016) Overview and future opportunities of sentiment analysis
approaches for big data. J Comput Sci 12(3):153–168
11. Simkin L (2013) To boardrooms and sustainability: the changing nature of segmentation.
CentAUR Report, pp 1–48
12. Ozan ¸S et al (2018) A case study on customer segmentation by using machine learning
methods. In: International conference on artiﬁcial intelligence and data processing (IDAP).
IAN: 18411438
13. Virmani C, Pillai A, Juneja D (2017) Extracting information from social network using NLP.
Int J Comput Intell Res 13(4):621–630
14. Xu Z, Vail C, Kohli AS, Tajdini S (2021) Understanding changes in a brand’s core positioning
and customer engagement: a sentiment analysis of a brand-owned Facebook site J Mark Anal
9:3–16

Univariate Individual Household Energy
Forecasting by Tuned Long Short-Term
Memory Network
Marko Stankovic
, Luka Jovanovic
, Milos Antonijevic
,
Aleksandra Bozovic
, Nebojsa Bacanin
, and Miodrag Zivkovic
Abstract Accurate forecast of energy consumption has proven to be invaluable to
many nodes of the energy sector, enabling an efﬁcient and cost-effective distribu-
tion of energy among consumers. However, the nonlinear and non-stationary nature
of household energy usage challenges contemporary machine learning algorithms,
where there is potential to yet develop robust and dependable technologies. In this
work presents a novel, hybrid long short-term memory (LSTM) model tuned by
Best Guided Search-Arithmetic Optimization Algorithm (BGS-AOA), that employs
quasi-reﬂection-based learning (QRL) to overcome the exploration–exploitation
imbalance of the original AOA. The introduced approach was tested on the publicly
available dataset capturing energy consumption of individual London households.
Due to the stochastic nature of optimizers, all experiments were carried out over the
course of ﬁve independent runs. In order to evaluate metaheuristics solutions, the
total MSE was utilized as the objective function for 3-step ahead forecast. Results of
the experiments demonstrated superior performance of our model when compared
to other metaheuristics frequently encountered in literature (ABC, FA, SSA, ChOA).
Keywords Univariate forecasting · Long short-term memory · Machine learning ·
Energy consumption forecasting · Metaheuristics
M. Stankovic · L. Jovanovic · M. Antonijevic · N. Bacanin (B) · M. Zivkovic
Singidunum University, Danijelova 32, 11010 Belgrade, Serbia
e-mail: nbacanin@singidunum.ac.rs
M. Stankovic
e-mail: marko.stankovic.201@singimail.rs
L. Jovanovic
e-mail: luka.jovanovic.191@singimail.rs
M. Antonijevic
e-mail: mantonijevic@singidunum.ac.rs
M. Zivkovic
e-mail: mzivkovic@singidunum.ac.rs
A. Bozovic
Academy of Applied Technical Studies, 11000 Belgrade, Serbia
e-mail: abozovic@atssb.edu.rs
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_30
403

404
M. Stankovic et al.
1
Introduction
Energy has been fundamental to the advancement of society given that it is a cru-
cial aspect of human activity. The energy problem, however, has gained signiﬁcant
attention from academics both domestically and internationally due to economy’s
continued and substantial growth. Predicting energy consumption is arduous since
it depends heavily on a number of variables, including economic growth, national
energy legislation, environmental circumstances, and the ability to produce energy
[18]. In addition, given the considerable ﬂuctuation and ambiguity involved, predict-
ing individual household electric loads is a rather problematic venture.
The administration, servicing, and functions of the electrical network may all
beneﬁt greatly from an efﬁcient projection of the electrical load. Since electricity
cannot be deposited in large quantities, there needs to be a reasonable equilibrium
between consumption and production [19]. The energy produced and the electricity
load must be properly predicted in order to schedule energy activities in an efﬁcient
and cost-effective manner. According to the ﬁndings of prior research papers, deep
learning and machine learning systems are not particularly robust for making pre-
dictions [40]. The full scope of these methods for energy use prediction tasks has not
been investigated enough, and there remains potential for development of dependable
technologies.
Therefore, to ﬁll in existing research gap in the domain of energy consumption
forecasting, this work puts forth a proposal for a hybrid long short-term memory
(LSTM) tuned by metaheuristics for univariate individual households energy con-
sumption forecasting. The LSTM is a robust model for time-series predictions [23,
26]; however, it should be tuned (optimizer) for each particular challenge in order
to obtain satisfying performance. Since there are many LSTM hyperparameters that
may be subjected to optimization process, this task is non-deterministic polynomial
hard (NP-hard) by nature. However, no single method works equally well when
addressing every task, as outlined by the no free lunch (NFL) theorem of optimiza-
tion [39]; hence experimentation is needed to determine more suitable methods and
therefore more powerful models.
The LSTM tuning was performing by using metaheuristics methods that exhibit
outstanding performance for addressing NP-hard problems. For example, meta-
heuristic algorithms simulating mating rituals of ﬁreﬂy’s have been capable of
addressing complex tasks [8]. Algorithms simulating the swarming behaviors of
dragonﬂies have similarly attained promising performance [50].
For the purpose of this research, an improved version of recently emerged arith-
metic optimization algorithm (AOA) is introduced and subjected to a compara-
tive analysis against cutting-edge methods for LSTM tuning. The AOA has been
selected for optimization due the admirable performance shown by the base approach
when applied to optimization tasks. However, practical testing suggests that further
improvements are possible. Since the LSTM requires substantial amount of com-
putational resources, supplementary objective of this work is the development of a
light LSTM structure that consists of maximum 2 LSTM layers, yet achieves solid
performance.

Univariate Individual Household Energy Forecasting by Tuned LSTM
405
The LSTM was evolved by the proposed improved AOA approach and validated
against electricity consumption measurements dataset consisting of data on 5567
households in London between November 2011 and February 2014.
The rest of this study is structured as per following: Sect.2 introduces some basic
background information related to employed methods, Sect.3 provides overview
of the basic AOA as well as devised improved method, dataset description used in
experiments, simulation setup, results and discussion are presented in Sect.4, while
closing notes on the conducted study are given in Sect.5.
2
Background and Related Works
The relevant academic literature on forecasting models and methods is included in
this chapter. Concerns about the dependability, consistency, efﬁciency, and precision
of the forecasting models are the key obstacles to the subject of forecasting energy
use. Forecasting methodologies can be viewed as two separated general classes: (i)
model-based,statisticalapproachesand(ii)data-drivenmethodspoweredbymachine
learning (ML) algorithms [14]. Improving prediction accuracy while reducing the
cost function is the common objective of the two.
Classical methods often employ deﬁned standard models and techniques includ-
ing linear regression, moving average, simple exponential smoothing, Gaussian pro-
cesses (GP), to mention a few. They achieve a high degree of accuracy while pro-
cessing a univariate dataset with bounded, quantiﬁable, and explainable predictors
with relatively minimal computer resources. However, it is probable that conven-
tional time-series approaches cannot detect the nonlinear characteristics of the data
and therefore fail to produce accurate predictions. To overcome this limitation, tradi-
tional methods may be hybridized with machine learning approaches. Such a model
has been proposed by Yuan et al. [42], where the forecast of wind power is achieved
with excellent precision by combining the forecast outputs of the least square support
vector machine with well-established ML techniques.
Particularly, the characteristics of residential energy usage are nonlinear and non-
stationary [38]. Therefore, the focus of this research is on developing an improved,
ML-based strategy for forecasting household energy consumption in context of these
two factors. Nevertheless, two perplexities persist to be the fundamental barriers to
the widespread application of the current data-driven forecasting methodologies [40].
The ﬁrst factor is that the energy consumption habits of individual households might
be highly inconsistent, effectively producing a negative impact on the precision of
nonlinear data predictions. This volatility is inﬂuenced by human behavior [30].
Secondly, as deep learning systems demand multi-dimensional inputs to attain high
forecasting accuracy, prediction of univariate time series data is a daunting challenge
for these systems. Moreover, the training methods for data-driven models come at
a considerable computing time expense. Due to the nonlinear properties of energy
consumption datasets, developing precise energy prediction technologies remains a

406
M. Stankovic et al.
challenge for researchers. Hence, ML models that can discover long-term dependen-
cies in the data and forecast aberrant, rapid changes are necessary [1].
Arguably, the most prominent AI techniques come in the form of long short-term
memory (LSTM) networks due to its ability to discern patterns in a long stream
of sequential data. According to a review of the literature, hybrid LSTM models
typically generate predictions with a superior degree of precision than the singu-
lar paradigm. Marino et al. [29] applied LSTM sequence-to-sequence architecture
to predict the electricity demand on the basis of an arbitrary number of previously
obtainable load measurements. Single LSTM’s predicting performance when pro-
cessing one-minute resolution dataset was insufﬁcient. Researchers have in previous
works [4] developed a combined CNN-LSTM model to forecast energy usage of a
single household with both normal and volatile consumption patterns. Moradzadeh
et al. [32] performed a batch training of a Variational Autoencoder Bidirectional
LSTM (VAEBiLSTM) to attain high R values and minimal error calculations when
compared to well-established techniques. A CNN-LSTM model suggested by Kim
and Cho [28] offers consistent and fast prediction of irregular patterns in household
power demand that preceding ML approaches could not accurately anticipate.
2.1
LSTM Overview
A LSTM network relies on a complex internal structure to process interrelated time-
series inputs by learning long-term dependencies [17]. Unlike conventional RNNs,
LSTM is speciﬁcally designed not to succumb to the vanishing gradient problem [16],
where initial signals attenuate as they advance through the propagation chain, pre-
venting the neural network from learning successfully from past information. LSTM
has proven to be superior to other contemporary strategies [15, 37]. By using a com-
plex four-layer gating structure within its cells, LSTM can successfully achieve long-
term memorization via dynamic and individual selection, reﬁnement, and removal
of cell’s inputs.
The cell state serves the purpose of a memory unit—preserving and transferring
meaningful information down the propagation chain. A forget gate controls what
data is discard from cell memory in order to declutter it from irrelevant information,
according to Eq.1.
ft = σ(W f xt + U f ht−1 + b f )
(1)
where ft denotes the forget gate that takes a new input of xt and old hidden state
ht−1, and outputs a value within (0, 1) range, having been compressed by the sigmoid
function σ. The corresponding weight matrices are denoted by W f and U f , while
b f represents the bias vector. The time step is indicated by the index t.
The following step is selecting new data that will be kept in cell memory. The
input gate acts as a sigmoid layer that decides upon which value to update in the cell
state, according to Eq.2.

Univariate Individual Household Energy Forecasting by Tuned LSTM
407
it = σ(Wixt + Uiht−1 + bi)
(2)
where it signiﬁes the input gate with a value in the interval (0, 1), Wi and Ui are
weight matrices, while bi denotes the bias vector.
The tanh layer generates a vector of new candidate values, ˜Ct, as shown in Eq.3.
˜Ct = tanh(Wcxt + Ucht−1 + bc)
(3)
where Wc, Uc and bc denote learnable parameters.
In order to update the cell state with actual values, data to be forgotten is ﬁrst
discarded by multiplying the forget gate ft with the old cell state Ct−1, then the new
candidate values ˜Ct are scaled by it, and added to the former, using Eq.4.
Ct = ft ⊙Ct−1 + it ⊙˜Ct
(4)
with Ct being the updated cell state, and ⊙signifying the entry-wise product.
The ﬁltered version of the output is generated based on the cell state, as demon-
strated in Eq.5, then further processed by a tanh layer to produce the new hidden
state (Eq.6).
ot = σ(Woxt + Uoht−1 + bo)
(5)
ht = ot ⊙tanh(Ct)
(6)
where ot denotes the output of the sigmoid layer within (0, 1) interval, with Wo, Uo
and bo being learnable parameters.
2.2
Metaheuristics Optimization
Conventional artiﬁcial neural networks (ANNs) use a gradient-based method for
training, and in effect suffer from slow convergence, vanishing gradient, and getting
trapped in the local minimum, resulting in suboptimal generalization. Furthermore,
the stagnant convergence rate of ANN-based forecasting systems makes them sus-
ceptible to over-ﬁtting. Designing a desirable network topology, known as hyperpa-
rameter optimization, is a challenging problem due to the requirement that nodes be
manually conﬁgured by the researcher. A further concern is feature selection, which
involves ﬁnding the appropriate subgroup of parameters from a larger set, removing
irrelevant ones. Academics refer to this collection of challenges as non-deterministic
polynomial (NP)-hard problems. Swarm intelligence models commonly facilitate
solutions to these obstacles.
Metaheuristics have seen a booming proliferation in contemporary studies. They
were shown to successfully deal with problems of NP-hard complexity by offering
a gradient-free approach and avoidance of premature convergence [43]. Oliva et al.

408
M. Stankovic et al.
[33] applied a swarm intelligence algorithm to precisely determine the parameters of
photovoltaic cell performance. The method demonstrated reliability and precision in
complex real-world issues. Other very successful use cases range from COVID-19
cases forecasting and related applications [12, 46, 49], cloud computing optimization
[11, 48], wireless sensor network optimization [45, 47, 50], feature selection problem
[10], image classiﬁcation in medical and other domains [13, 24, 35, 44], credit card
fraud detecting task [20, 34], pollution forecasting [6], general network security [9,
21, 36] and the general tuning of a variety of machine learning models including
LSTM [3, 7, 22, 23].
3
Proposed Method
3.1
Original AOA
The AOA [2] utilized a population of agents and stochastic mechanisms to tackle
search problems. The principal optimization stages include exploration and exploita-
tion shared by all metaheuristics. During exploration the algorithm is exploring
the problem space looking from promising regions, whereas during exploitation
the goal is focusing on the regions that have already been investigated. Addi-
tionally, the AOA excludes the need for derivation when solving optimization
tasks.
Basic search procedure of AOA is modeled in Eq (7)
MOA (C−Iter ) = Min + C−Iter ×
 Max −Min
M−Iter

(7)
xi, j (C−Iter + 1) =
 best

x j

÷ (MOP + ϵ) ×

UB j −LB j

× μ + LB j

, r2 < 0.5
best

x j

× MOP ×

UB j −LB j

× μ + LB j

,
otherwise
(8)
MOP (C−Iter ) = 1 −C−Iter 1/α
M−Iter 1/α
(9)
xi, j (C−Iter + 1) =
 best

x j

−MOP ×

UB j −LB j

× μ + LB j

, r3 < 0.5
best

x j

+ MOP ×

UB j −LB j

× μ + LB j

, otherwise ,
(10)
in which MOA(C−Iter) represents the function value in the current cycle, spanning
between Min and Max, the M−Iter and [1, (M−Iter)] denote maximum iterations
in the run and current iteration in the range, respectively, r1,r2,r3 denote arbitrary
numbers selected from a uniform distribution within the range [−1, 1], ϵ is small
integer, x denotes solution, while i and j represent individual number and parameter
number, respectively. Finally, LB j, UB j denote jth position’s lower and upper limit,

Univariate Individual Household Energy Forecasting by Tuned LSTM
409
respectively, while MOP and α stand for the math optimizer probability and constant
parameter evaluation exploitation accuracy, respectively.
More details about basic AOA can be captured from [2].
3.2
Enhanced AOA Metaheuristics
Notwithstanding satisfying AOA performance for real-world NP-hard challenges
[2], during practical observations basic AOA inner workings, some issues that need
to be addressed are noticed. It happens in some runs that the ﬁnal outputs are not
satisfying because the search process tends to be biased more toward exploitation
or exploration. It seems that MO A and MO P operators are not robust enough to
guarantee exploitation–exploration balance in all runs.
Therefore, to overcome above-mentioned deﬁciencies, proposed method intro-
duces best-guided search (BSG) mechanism that executes in two models, in the
original AOA. In early iterations, with the assumption that problem space region
where an possible best (suboptimum) solution can be found has not yet been dis-
covered, the worst solution is replaced with the quasi-reﬂective opposite individual
bestxqrl of the current best solution, which is generated by applying quasi-reﬂection-
based learning (QRL) mechanism. It was shown in previous studies that the QRL
effectively positions agents in opposing parts of the problem space [5].
However, in subsequent iterations, when an optimum region in the problem space
is found, the worst agent is replaced with the solution xu, that is derived by applying
uniform crossover operator between two best individual from the population. These
two behaviors are controlled with hard-coded control parameter best-guided search
mode (bsgm) which is set to Miter/2. This value was determined empirically.
Finally, devised approach is dubbed BSG-AOA. The process ﬂowchart is shown
below followed by the pseudo-code (Fig. 1).
Fig. 1 Enhanced AOA algorithm ﬂowchart

410
M. Stankovic et al.
4
Experiments and Discussion
This section presents a discussion of the dataset employed for experimentation fol-
lowed by the basics of the experimental setup. Afterward, the attained results are
presented and discussed.
4.1
Dataset
The data utilized for this research originates from the London Data Store and encom-
passes electricity demand measurements for 5567 city households and covers a time
period from 01.11.2011 to 01.02.2014. The data has been captured using smart
power meters and has a daily resolution with a total of 19,752 samples. This dataset
is publicly available on Kaggle1. Individual households’ measurements of electricity
usage over the course of 829d were aggregated and employed as the target variable
for univariate time-series predictions. The available data is split with 70% used for
the training process, 10% for validation, while the ﬁnal remaining 20% is used to
test the proposed approach as shown in Fig.2.
Algorithm 1 The BSG-AOA pseudo-code
Initiate α and μ variable values.
Arbitrarily create a population of potential solutions (i = 1, ..., N).
while C−Iter < M−Iter do
Calculate ﬁtness of each agent in population using the objective function.
Select best performing agent.
Determine new value of MOA with Eq. 7.
Determine new value of MOP with Eq. 9.
for i = 1 to Solutions do
for j = 1 to Positions do
Set random values of parameters (r1,r2,r3) in range [0, 1].
if r1 > MO A then
Exploration stage
if r2 > 0.5 then
Apply Division (D, "÷")
Determine the location of ith agent through Eq. 8.
else
Apply Multiplication (M, "×")
Determine the location of ith agent through the second rule of Eq. 8.
end if
else
Exploitation stage
if r3 > 0.5 then
Apply Subtraction (S, "−")
Determine the location of ith agent through the ﬁrst rule in Eq. 10.
else
Apply Addition (A, "+")
Determine the location of ith agent through the second rule in Eq. 10.
end if
end if
end for
end for
if bsg < Mi ter then
Replace worstx with bestxqrl
else
Replace worstx with xu
end if
C−Iter = C−Iter + 1
end while
Present the best attained individual.
1 https://www.kaggle.com/code/rheajgurung/energy-consumption-forecast/notebook.

Univariate Individual Household Energy Forecasting by Tuned LSTM
411
Fig. 2 Electricity consumption dataset split
4.2
Experiments, Attained Results and Discussion
All tested models where independently implemented in Python, using TensorFlow
and Keras. The prediction model used six input steps, representing six days worth
of data, used to predict energy consumption three 3 (days) ahead.
The proposed BGS-AOA was compared against the ABC [25], FA [41], SSA [31],
and chimp swarm optimization algorithm (ChOA) [27]. In the results summary, all
algorithms adopted for LSTM tuning have preﬁx ‘LSTM’. Throughout testing, all
algorithms employed a population of ﬁve individuals, which were improved over 5
iterations. All experiments were carried out in 5 independent executions to account
for the stochastic nature of optimizers.
Every metaheuristics individual represents an array of 6 LSTM hyperparameters
which were optimized. Parameters taken into account along with its boundaries
are as follows: neuron count of the ﬁrst layer (nn1) [100, 200], learning rate (lr)
[0.0001, 0.01], maximum training epoch limit (epochs) [300, 600], dropout (dp)
[0.001, 0.01], layer count (ln) [1, 2], neuron count of in the second layer (nn2)
[100, 200]. Former parameter was only used if the generated ln value is 2. The tested
models applied the Adam optimizer and used mean square error (MSE) as the loss
function.
Throughout experiments the following metrics were captured for each prediction
step separately, but also calculated as the overall results for each 3 steps: coefﬁcient of
determination R2, MSE, mean absolute error (MAE), MSE and root MSE (RMSE).
The overall MSE was used as objective function for metaheuristics solutions’ eval-
uation. It is noted that since the LSTM is neural network, all values in the dataset
were scaled within the range [0, 1].
The overall objective function (MSE) over 5 independent runs for the best, worst,
mean, median, standard deviation and variance is shown in Table1. Tables 2 and 3

412
M. Stankovic et al.
Table 1 Overall objective function metrics over 5 runs for 3-steps ahead forecast
Method
Best
Worst
Mean
Median
Std
Var
LSTM-
BGS-AOA
9.942E−04
1.011E−03
9.984E−04
9.957E−04
6.248E−06
3.904E−11
LSTM-
ABC
1.001E−03
1.004E−03
1.003E−03
1.004E−03
1.567E−06
2.456E−12
LSTM-FA
1.002E−03
1.021E−03
1.008E−03
1.005E−03
6.811E−06
4.639E−11
LSTM-SSA 9.966E−04
1.003E−03
9.988E−04
9.978E−04
2.471E−06
6.105E−12
LSTM-
ChOA
9.970E−04
9.979E−04
9.973E−04
9.973E−04
3.183E−07
1.013E−13
Table 2 R2, MAE, MSE and RMSE normalized metrics of best-generated LSTM with 3-steps
ahead forecast
Performance
indicator
LSTM-
BGS-AOA
LSTM-
ABC
LSTM-FA
LSTM-
SSA
LSTM-
ChOA
One-step
ahead
R2
0.740888
0.739594
0.739939
0.740399
0.741392
MAE
0.024895
0.025172
0.025266
0.024931
0.025047
MSE
0.001002
0.001007
0.001006
0.001004
0.001000
RMSE
0.031660
0.031739
0.031718
0.031690
0.031629
Two-step
ahead
R2
0.743426
0.740904
0.740356
0.742037
0.743008
MAE
0.024784
0.025199
0.025286
0.024876
0.024969
MSE
0.000993
0.001002
0.001004
0.000998
0.000994
RMSE
0.031505
0.031659
0.031693
0.031590
0.031530
Three-step
ahead
R2
0.744724
0.743581
0.742627
0.744684
0.742455
MAE
0.024781
0.025006
0.025144
0.024728
0.025131
MSE
0.000988
0.000992
0.000996
0.000988
0.000996
RMSE
0.031425
0.031495
0.031554
0.031427
0.031564
Overall
results
R2
0.743013
0.741360
0.740974
0.742373
0.742285
MAE
0.024820
0.025126
0.025232
0.024845
0.025049
MSE
0.000994
0.001001
0.001002
0.000997
0.000997
RMSE
0.031530
0.031631
0.031655
0.031569
0.031575
exhibit normalized and denormalized results attained for the best execution, respec-
tively and the best obtained LSTM hyperparameters are shown in Table4.
From the shown tables it may be clearly deduced that the introduced LSTM-BSG-
AOA demonstrates the best performance, for overall as for the individual metrics.
It achieved the best scores for the best and median results, followed by the LSTM-
ChOA on the second place, as seen in Table1. It also achieved superior scores with

Univariate Individual Household Energy Forecasting by Tuned LSTM
413
Table 3 R2, MAE, MSE and RMSE denormalized metrics of best-generated LSTM with 3-steps
ahead forecast
Error
indicator
LSTM-
BGS-AOA
LSTM-
ABC
LSTM-FA
LSTM-SSA LSTM-
ChOA
One-step
ahead
R2
0.741
0.739
0.739
0.740
0.741
MAE
747.939
756.259
759.078
749.023
752.511
MSE
904,768.060 909,284.129 908,080.324 906,475.095 903,006.692
RMSE
951.193
953.564
952.932
952.089
950.267
Two-step
ahead
R2
0.743
0.741
0.740
0.742
0.743008
MAE
744.593
757.079
759.687507
747.358
750.149
MSE
895,906.215 904,710.219 906,626.395 900,756.874 897,364.470
RMSE
946.523
951.162
952.169
949.082
947.293
Three-step
ahead
R2
0.745
0.743
0.743
0.744
0.742455
MAE
744.529
751.276
755.427
742.934
755.027
MSE
891,371.669 895,365.385 898,695.052 891,511.448 899,295.819
RMSE
944.125
946.237
947.995
944.199
948.312
Overall
results
R2
0.743
0.741
0.741
0.742
0.742285
MAE
745.687
754.871
758.064
746.438
752.562
MSE
897,348.648 903,119.911 904,467.257 899,581.139 899,888.994
RMSE
947.285
950.326
951.035
948.462
948.625
Table 4 Parameters of best solutions for each metaheuristics
Method
nn1
lr
epochs
dp
ln
nn2
LSTM-
BGS-AOA
157
0.005108
533
0.095663
2
103
LSTM-
ABC
159
0.007818
491
0.118743
1
190
LSTM-FA
100
0.010000
500
0.050000
1
176
LSTM-SSA 102
0.008604
591
0.077705
2
174
LSTM-
ChOA
156
0.010000
502
0.150209
1
119
respect to the detailed metrics of the best produced LSTM, as given in Tables2
and 3. Finally, the best set of hyperparameters determined by the LSTM-BSG-AOA
approach was: 155 neurons in the ﬁrst layer, learning rate of 0.005108, 533 epochs,
dropout value of 0.095663, 2 layers total and 103 neurons in the second layer.
To visualize results of all metaheuristics, kernel density estimation (KDE) plots
for objective function over 5 runs and the best LSTM-BSG-AOA results are depicted

414
M. Stankovic et al.
Fig. 3 KDE plot for objective function over 5 runs (top), best predicted results by LSTM-BSG-AOA
(bottom)
in Fig.3. Following the KDE plots is the graph showing recorded one, two and three
step predictions made by the best performing networks compared to actual values in
the dataset once given 6 input variables from a never before seen set of testing data.
5
Conclusion
The conducted research discussed in this manuscript covers a novel LSTM-based
approach for time-series forecasting of individual household electrical power con-
sumption. To more efﬁciently tackle this task, a novel improved version of the AOA
metaheuristic algorithms is proposed so as to overcome certain known shortcom-
ings of the original. The proposed algorithms have been dubbed the BSG-AOA, and

Univariate Individual Household Energy Forecasting by Tuned LSTM
415
applied to optimizing LSTM networks structures to better address the given problem.
The novel proposed metaheuristic has been tasked with optimizing hyperparameters
withing a LSTM network, and appropriately named LSTM-BSG-AOA. The perfor-
mance of which has been juxtaposed against four other well-established modern
algorithms including: ABC, FA, SSA and ChOA, applied to the same task. While
high computational demands present a limitation when testing all LSTM models the
conducted simulation outcomes for one-, two- and three-step ahead forecast, as well
as the overall results evidently show the superiority of the suggested LSTM-BSG-
AOA for the given forecasting task.
In future works, the focus will be on further exploring the potential of the proposed
approach on other energy related time-series prediction problems, as well as explor-
ing the potential in real-time applications. Additionally, authors plan on exploring
the potential of other ML models optimized by emerging metaheuristics in hopes of
further improving performance on the energy consumption forecasting tasks.
References
1. Highly accurate energy consumption forecasting model based on parallel LSTM neural net-
works. Adv Eng Inform 51:101442. https://doi.org/10.1016/J.AEI.2021.101442
2. Abualigah L, Diabat A, Mirjalili S, Elsayed Abd Elaziz M, Gandomi A (2021) The arithmetic
optimization algorithm. Comput Methods Appl Mech Eng 376:113609. https://doi.org/10.
1016/j.cma.2020.113609
3. AlHosni N, Jovanovic L, Antonijevic M, Bukumira M, Zivkovic M, Strumberger I, Mani JP,
Bacanin N (2022) The xgboost model for network intrusion detection boosted by enhanced
sine cosine algorithm. In: International conference on image processing and capsule networks.
Springer, pp 213–228
4. Alhussein M, Khursheed K, Haider S (2020) Hybrid CNN-LSTM model for short-term indi-
vidual household load forecasting. IEEE Access 8:180544–180557. https://doi.org/10.1109/
ACCESS.2020.3028281
5. Bacanin N, Bezdan T, Venkatachalam K, Zivkovic M, Strumberger I, Abouhawwash M, Ahmed
AB (2021) Artiﬁcial neural networks hidden unit and weight connection optimization by quasi-
refection-based learning artiﬁcial bee colony algorithm. IEEE Access 9:169135–169155
6. BacaninN,SaracM,BudimirovicN,ZivkovicM,AlZubiAA,BashirAK(2022)Smartwireless
health care system using graph LSTM pollution prediction and dragonﬂy node localization.
Sustain Comput Inform Syst 35:100711
7. Bacanin N, Stoean C, Zivkovic M, Jovanovic D, Antonijevic M, Mladenovic D (2022) Multi-
swarm algorithm for extreme learning machine optimization. Sensors 22(11):4204
8. Bacanin N, Stoean R, Zivkovic M, Petrovic A, Rashid TA, Bezdan T (2021) Performance of
a novel chaotic ﬁreﬂy algorithm with enhanced exploration for tackling global optimization
problems: application for dropout regularization. Mathematics 9(21):2705
9. Bacanin N, Zivkovic M, Stoean C, Antonijevic M, Janicijevic S, Sarac M, Strumberger I
(2022) Application of natural language processing and machine learning boosted with swarm
intelligence for spam email ﬁltering. Mathematics 10(22):4173
10. Bezdan T, Cvetnic D, Gajic L, Zivkovic M, Strumberger I, Bacanin N (2021) Feature selection
by ﬁreﬂy algorithm with improved initialization strategy. In: 7th conference on the engineering
of computer based systems, pp 1–8
11. Bezdan T, Zivkovic M, Tuba E, Strumberger I, Bacanin N, Tuba M (2020) Multi-objective
task scheduling in cloud computing environment by hybridized bat algorithm. In: International
conference on intelligent and fuzzy systems. Springer, pp 718–725

416
M. Stankovic et al.
12. Budimirovic N, Prabhu E, Antonijevic M, Zivkovic M, Bacanin N, Strumberger I, Venkat-
achalam K (2022) Covid-19 severity prediction using enhanced whale with salp swarm feature
classiﬁcation. Comput Mater Continua 1685–1698
13. Bukumira M, Antonijevic M, Jovanovic D, Zivkovic M, Mladenovic D, Kunjadic G (2022)
Carrot grading system using computer vision feature parameters and a cascaded graph convo-
lutional neural network. J Electron Imaging 31(6):061815
14. Cao X, Dong S, Wu Z, Jing Y (2015) A data-driven hybrid optimization model for short-term
residential load forecasting, pp 283–287. https://doi.org/10.1109/CIT/IUCC/DASC/PICOM.
2015.41
15. He W (2017) Load forecasting via deep neural networks. Procedia Comput Sci 122:308–314.
https://doi.org/10.1016/j.procs.2017.11.374
16. Hochreiter S, Schmidhuber J (1997) Long short-term memory. Neural Comput 9(8):1735–1780
Nov
17. Hochreiter S (1991) Studies on dynamic neural networks, vol 1. Master’s thesis, Institute for
Computer Science, Technical University, Munich, pp 1–150
18. Hu H, Wang L, Lv SX (2020) Forecasting energy consumption and wind power generation
using deep echo state network. Renew Energ 154:598–613
19. Jetcheva JG, Majidpour M, Chen WP (2014) Neural network model ensembles for building-
level electricity load forecasts. Energ Build 84:214–223
20. Jovanovic D, Antonijevic M, Stankovic M, Zivkovic M, Tanaskovic M, Bacanin N (2022)
Tuning machine learning models using a group search ﬁreﬂy algorithm for credit card fraud
detection. Mathematics 10(13):2272
21. Jovanovic D, Marjanovic M, Antonijevic M, Zivkovic M, Budimirovic N, Bacanin N (2022)
Feature selection by improved sand cat swarm optimizer for intrusion detection. In: 2022
international conference on artiﬁcial intelligence in everything (AIE). IEEE, pp 685–690
22. Jovanovic L, Antonijevic M, Zivkovic M, Jovanovic D, Marjanovic M, Bacanin N (2023)
Sine cosine algorithm with tangent search for neural networks dropout regularization. In: Data
intelligence and cognitive informatics. Springer, pp 789–802
23. Jovanovic L, Jovanovic D, Bacanin N, Jovancai Stakic A, Antonijevic M, Magd H, Thiru-
malaisamyR,ZivkovicM(2022)Multi-stepcrudeoilpricepredictionbasedonLSTMapproach
tuned by salp swarm algorithm with disputation operator. Sustainability 14(21):14616
24. Jovanovic L, Zivkovic M, Antonijevic M, Jovanovic D, Ivanovic M, Jassim HS (2022) An
emperor penguin optimizer application for medical diagnostics. In: 2022 IEEE zooming inno-
vation in consumer technologies conference (ZINC). IEEE, pp 191–196
25. Karaboga D, Basturk B (2007) A powerful and efﬁcient algorithm for numerical function
optimization: artiﬁcial bee colony (ABC) algorithm. J Glob Optim 39(3):459–471
26. Karevan Z, Suykens JA (2020) Transductive LSTM for time-series prediction: an application
to weather forecasting. Neural Netw 125:1–9
27. Khishe M, Mosavi MR (2020) Chimp optimization algorithm. Exp Syst Appl 149:113338
28. Kim TY, Cho SB (2019) Predicting residential energy consumption using CNN-LSTM neural
networks. Energy 182. https://doi.org/10.1016/j.energy.2019.05.230
29. Marino D, Amarasinghe K, Manic M (2016) Building energy load forecasting using deep neural
networks. https://doi.org/10.1109/IECON.2016.7793413
30. Masson V, Hidalgo J, Amossé A, Bélaïd F, Bocher E, Bonhomme M, Bourgeois A, Bretagne
G, Caillerez S, Cordeau E, Demazeux C, Faraut S, Gallato C, Haouès-Jouve S, Lambert ML,
Lemonsu A, Lestringant R, Lévy JP, Long N, Vye D (2015) Urban climate, human behavior
and energy consumption: from LCZ mapping to simulation and urban planning (the mapuce
project)
31. Mirjalili S, Gandomi AH, Mirjalili SZ, Saremi S, Faris H, Mirjalili SM (2017) Salp swarm
algorithm: a bio-inspired optimizer for engineering design problems. Adv Eng Softw 114:163–
191
32. Moradzadeh A, Moayyed H, Zare K, Mohammadi-ivatloo B (2022) Short-term electricity
demand forecasting via variational autoencoders and batch training-based bidirectional long
short-term memory. Sustain Energ Technol Assess 52:102209. https://doi.org/10.1016/j.seta.
2022.102209

Univariate Individual Household Energy Forecasting by Tuned LSTM
417
33. Oliva D, Cuevas E, Pajares G (2014) Parameter identiﬁcation of solar cells using artiﬁcial bee
colony optimization. Energy 72:93–102
34. Petrovic A, Bacanin N, Zivkovic M, Marjanovic M, Antonijevic M, Strumberger I (2022) The
adaboost approach tuned by ﬁreﬂy metaheuristics for fraud detection. In: 2022 IEEE world
conference on applied intelligence and computing (AIC). IEEE, pp 834–839
35. Prakash S, Kumar MV, Ram SR, Zivkovic M, Bacanin N, Antonijevic M (2022) Hybrid GLFIL
enhancement and encoder animal migration classiﬁcation for breast cancer detection. Comput
Syst Sci Eng 41(2):735–749
36. Stankovic M, Antonijevic M, Bacanin N, Zivkovic M, Tanaskovic M, Jovanovic D (2022)
Feature selection by hybrid artiﬁcial bee colony algorithm for intrusion detection. In: 2022
international conference on edge computing and applications (ICECAA). IEEE, pp 500–505
37. Wei N, Li C, Duan J, Liu J, Zeng F (2019) Daily natural gas load forecasting based on a hybrid
deep learning model. Energies 12:15. https://doi.org/10.3390/en12020218
38. Wei S, Bai X (2022) Multi-step short-term building energy consumption forecasting based on
singular spectrum analysis and hybrid neural network. Energies 15:1743. https://doi.org/10.
3390/en15051743
39. Wolpert DH, Macready WG (1997) No free lunch theorems for optimization. IEEE Trans Evol
Comput 1(1):67–82
40. Yan K, Li W, Ji Z, Qi M, Du Y (2019) A hybrid LSTM neural network for energy consumption
forecasting of individual households. IEEE Access 7:157633–157642. https://doi.org/10.1109/
ACCESS.2019.2949065
41. Yang XS, Slowik A (2020) Fireﬂy algorithm. In: Swarm intelligence algorithms. CRC Press,
pp 163–174
42. Yuan X, Tan Q, Yuan Y, Wu X (2017) Wind power prediction using hybrid autoregressive
fractionally integrated moving average and least square support vector machine. Energy 129.
https://doi.org/10.1016/j.energy.2017.04.094
43. Zhang J, Xiao M, Gao L, Pan QK (2018) Queuing search algorithm: a novel metaheuristic
algorithm for solving engineering optimization problems. Appl Math Model 63. https://doi.
org/10.1016/j.apm.2018.06.036
44. Zivkovic M, Bacanin N, Antonijevic M, Nikolic B, Kvascev G, Marjanovic M, Savanovic N
(2022) Hybrid CNN and XGBoost model tuned by modiﬁed arithmetic optimization algorithm
for covid-19 early diagnostics from X-ray images. Electronics 11(22):3798
45. Zivkovic M, Bacanin N, Tuba E, Strumberger I, Bezdan T, Tuba M (2020) Wireless sensor
networks life time optimization based on the improved ﬁreﬂy algorithm. In: 2020 international
wireless communications and mobile computing (IWCMC). IEEE, pp 1176–1181
46. Zivkovic M, Bacanin N, Venkatachalam K, Nayyar A, Djordjevic A, Strumberger I, Al-Turjman
F (2021) Covid-19 cases prediction by using hybrid machine learning and beetle antennae
search approach. Sustain Cities Soc 66:102669
47. Zivkovic M, Bacanin N, Zivkovic T, Strumberger I, Tuba E, Tuba M (2020) Enhanced grey
wolf algorithm for energy efﬁcient wireless sensor networks. In: 2020 zooming innovation in
consumer technologies conference (ZINC). IEEE, pp 87–92
48. Zivkovic M, Bezdan T, Strumberger I, Bacanin N, Venkatachalam K (2021) Improved Harris
hawks optimization algorithm for workﬂow scheduling challenge in cloud-edge environment.
In: Computer networks, big data and IoT. Springer, pp 87–102
49. Zivkovic M, Venkatachalam K, Bacanin N, Djordjevic A, Antonijevic M, Strumberger I, Rashid
TA (2021) Hybrid genetic algorithm and machine learning method for covid-19 cases predic-
tion. In: Proceedings of international conference on sustainable expert systems: ICSES 2020,
vol 176. Springer Nature, p 169
50. Zivkovic M, Zivkovic T, Venkatachalam K, Bacanin N (2021) Enhanced dragonﬂy algorithm
adapted for wireless sensor network lifetime optimization. In: Data intelligence and cognitive
informatics. Springer, pp 803–817

Interpreting Doctor’s Handwritten
Prescription Using Deep Learning
Techniques
Rizwanullah Mohammad, Ajay Kumar Varma Nagaraju,
and Suneetha Manne
Abstract A Doctor’s Handwriting Recognition model can predict (recognize) the
text present in the doctor’s prescription, by feeding image of that medicine name
to the model, and it predicts the text present in the image and it gives the ﬁnal
medicine name as digital text. This model is suitable only for text written in English
language and not suitable for other languages of texts written in prescription. The
model based on training dataset the output it produces may get varied and based on
training images count. Both convolution layers and Bi-Directional LSTM layers can
be used for feature extraction and recognizing text, respectively.
Keywords Bi-Directional LSTM units · Bi-Directional gated recurrent units ·
Convolution layers · Adam optimizer · ReLU activation function
1
Introduction
It is most common that people cannot understand and interpret the doctor’s hand-
writing. The calligraphy they follow is always challenging for ordinary people and
even for pharmacist to understand doctor’s handwriting [1–3]. Until and unless they
understand the medicine name correctly, they cannot give correct medicine to patient.
Duetotheusageof wrongmedicines, theymayfacesevereconsequences withrespect
to their health. This problem need to be solved with the latest technologies those are
present [4]. The solution for this is deep learning models [5]. A deep learning model
can take large data input and can process with help of neural network and layers
R. Mohammad (B) · A. K. V. Nagaraju · S. Manne
IT Department, Velagapudi Ramakrishna Siddhartha Engineering College, Vijayawada, Andhra
Pradesh, India
e-mail: mailtorizwanullah@gmail.com
A. K. V. Nagaraju
e-mail: 208w1a12a1@vrsec.ac.in
S. Manne
e-mail: hodit@vrsiddhartha.ac.in
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_31
419

420
R. Mohammad et al.
[6]. They can give high accuracy and more reliable. By utilizing the available deep
learning algorithms, involving all the terms in deep learning to provide a optimal
solution for this [7, 8]. The Bi-Directional LSTM model can provide a solution
which can predict text present in doctor’s prescription’s image which are passed as
input to our model. The comparison was made between Bi-Directional LSTM and
Bi-Directional GRU [9–12]. For this application of interpreting doctor’s handwritten
prescriptions, either one of the architectures between Bi-LSTM and Bi-GRU will be
chosen and implemented [13–15]. IAM is a dataset which contains handwritings of
many people. The two algorithms, Bi-Directional LSTM and Bi-Directional GRU,
are trained using images from the IAM dataset, and the accuracy results are compared
and examined. This paper provides a brief explanation of how the performance of
model is affected by the purity and amount size of the dataset.
2
Literature Study
Here are the available models, that researchers proposed and developed. They
proposed different methodologies to recognize text in an image and showcase their
performance.
Jain et al. [1] presented a model employing the BI-LSTM model for the recogni-
tion of a doctor’s handwriting. They have only created a model; no mobile or web
applications have been created to execute the model in real time. In order to minimize
overﬁtting and increase the model’s resistance to noise, they employed data augmen-
tation approaches. Changing network topologies increases accuracy and reduces
complexity.
Tabassum et al. [2] presented a model for the identiﬁcation of doctors’ hand-
writing. After employing the SRP augmentation approach, they achieved an accu-
racy of 89%. Some of the participating physicians’ prescription pictures were made
available. They made a dataset called handwritten corpus. The introduction of SRP
increased the size of the datasets. For predicting the handwriting of doctors, an
online character recognition system utilizing Bi-LSTM was employed. Variable
handwriting styles should be added in the dataset to improve the model’s knowledge
and prediction abilities.
Fajardo et al. [3] presented that a model for interpreting the doctor’s handwriting
was developed. They employed CRNN model. The accuracy of the tests conducted
using the mobile application was 72%. The model is implemented through the use of
a mobile application called DCHRS and aims to recognize the name of the medication
inside prescription that has been captured, as well as to provide the digital text of the
handwriting. Low image count and precision are insufﬁcient for medical applications.
Espana-Boquera et al. [16] presented a public dataset, named SPA sentences and
also provided indicators at level of sentences, proposed methodology of combining
convolutional blocks with LSTM and CTC blocks. Unidirectional LSTM is less
accurate than Bi-Directional LSTM.

Interpreting Doctor’s Handwritten Prescription Using Deep Learning …
421
Maalej et al. [4] proposed a methodology which replaces 1-D LSTM with multi-
LSTM blocks. They connected MDLSTM blocks with CTC-Maxout block, and they
performed data augmentation which increases accuracy. MDLIST increases model
complexity, and the interpretability will get reduced.
Harikrishnan et al. [17] presented their model for handwritten numbers’ recogni-
tion with CNN and MLP architectures. The model was employed with CNN and MLP
architectures. The results are that CNN achieved 99% accuracy and MLP achieved
97% accuracy. CNN performance is more than MLP. According to the proposed
model, if the number of CNN layers is increased, then it may give better accuracy.
Nikitha et al. [18] proposed a handwritten text recognition system which uses word
error rate instead of character error rate. The two-dimensional LSTM architecture
is used for model. The model was not evaluated on character error rate, a crucial
criterion for making it more robust and efﬁcient.
Hassan et al. [19] presented a methodology for recognition of handwritten text
for any script. Their proposed model achieved an average accuracy of 83%. The
proposed architecture’s network topology must be adjusted to raise the number of
ﬁlters to 1024 for better results.
Ul Sehr Zia et al. [20] presented a handwritten text recognition model based
on CRNN. This model was trained with NUST Urdu handwriting dataset and
they demonstrated how model can be trained with English and Urdu bilingual
handwriting.
Alrobah et al. [5] proposed applying of robust methodologies to handle challenges
in recognition of different language handwriting data, mainly, the Arabic handwritten
data. The methods that should be used and how to make feature extractions in most
effective way, can help the model to be more Robust and Perform well.
Shaw et al. [21] proposed a model which can recognize poor legible handwriting
and provide a digital text. OCR was used in order to recognize handwriting. The
model was trained with MNIST dataset. Generally, for handwriting recognition, the
model should be trained with dataset containing alphabets rather than numbers.
Sharma et al. [6] demonstrated the usage of various scripts like Devanagari,
Gurmukhi, and other language datasets to train the model. A model was devel-
oped with CNN architecture. RNNs are recommended for successful model feature
decoding.
Sethy et al. [22] demonstrated the CNN architecture usage for efﬁcient feature
extraction and pattern recognition. The system was trained with Odia and Bangla
handwritten data. These data were trained with CNN architecture. RNN architecture
must be employed to recognize text.
Haboubi et al. [9] presented a model for Urdu handwriting recognition. They
demonstrated how the Bi-GRUs are giving better accuracy with less complexity and
consuming less memory. Bi-GRU is LSTM’s rival.
Abdallah et al. [15] presented handwriting recognition model for Russian scripts.
They implemented CNN for feature extraction and multi-dimensional GRU for
feature decoding. They conﬁrmed multi-dimensional GRU’s good performance.

422
R. Mohammad et al.
Fig. 1 Distortion-free image
preprocessing
The above methods and presentations give us an in-depth grasp of their models,
performance, and design approaches. By understanding their approaches, better ones
can be devised to overcome obstacles and design a better model.
3
Proposed Work
3.1
Dataset
The suggested model used 86,800 grayscale pictures. IAM dataset contains different
handwriting scripts [23]. The dataset is split into 90:5:5 ratio (Train_Validate_Test).
3.2
Preprocessing
In this preprocessing phase, the images will get reshaped to width of 128 and height
of 32 and padding to 99. And then, the datatype will be changed to ﬂoat32 which is
called as casting. Thıs may increase the model performance. This is distortion-free
image processing. Initial, using tf.image is the ﬁrst stage in the resizing process. The
image path should be sent along with width and height to the resize() function while
maintaining the aspect ratio. Following this, the additional padding is added to resized
image. Padding can be added to image by subtracting width and height values (128
and 32, respectively) with image shape which image wants to add padding to, with
help of tf.shape() function. With tf.transpose() function by giving perm = [1, 0, 2].
This is nothing but setting up the required tensor dimensions. Perform ﬂip_left_right
of image in order to get image ﬂipped along with width dimensions. Figure 1 shows
the distortion-free image preprocessing.
3.3
Design Methodology
A brief description of proposed methodology

Interpreting Doctor’s Handwritten Prescription Using Deep Learning …
423
The cropped images from the IAM dataset are being utilized, and also few images
from other medical datasets are used in addition to train our model. The training
dataset, validation dataset, and testing datasets have been divided in a ratio of 90:5:5.
The network has a sophisticated design that includes seven convolutional layers,
optional batch normalization layers, max pooling layers, ReLU activation functions,
a Bi-Directional LSTM layer, and a CTC layer [1]. The procedure increases the
number of channels in the ﬁrst convolution layer from 1 to 64 which, after several
layers, is raised to 128.
Figure 2 describes architecture of our work.
The architecture design of the proposed work is shown in Fig. 2. The Bi-LSTM
layer aids in decoding of the convolution layer-generated feature mapping. Next,
create a layer for label input for the appropriate images, followed by a thick layer. To
ﬁnd the CTC loss, the last layer would be the CTC layer. The next step is to determine
thecallbackdistance.Duringthisstage,CTCdecodingwillbedoneusingpredictions.
Then, using tf.sparse.from_dense and dtype as an int64, sparse the predictions made
from dense. Identify a point when an increase in epoch values leads to a rise in loss
value and the model will no longer improve performance at which point training
may be stopped. Next, build the model and train it with various rising epoch values,
setting checkpoints as necessary. The count variable can be used to determine the
model’s accuracy by passing some data as input, checking the total count of right
predictions, and calculating the percentage of right predictions. The accuracy will
Fig. 2 Architecture design for our work

424
R. Mohammad et al.
be proportional to the initial weights which are being established in the input layer.
Setting appropriate starting weight values for the input layer and subsequent layers,
as well as choosing an appropriate activation function, is required. ReLU inside a
convolution layer and dense layer is typically utilized as activation functions for
models like CNN and LSTMs.
StringLookup Layer
This is proposed preprocessing layer which is being used. It converts characters in
each word while training into integers. It converts each character in a vocabulary
to an integer. StringLookup layer converts integers to characters during prediction.
During the conversion of num back to character, the invert should be set as True. If
the training label is ‘crocin,’ then the vocabulary will be {c, r, o, c, i, n}.
CNN + Bi-LSTM
Figure 3 shows model design for Bi-LSTM Model. The Bi-Directional layer in Fig. 3
represents the Bi-LSTM layer. The initial layer is input layer of height 32, width 128,
and the channel is 1 because it is a grayscale image. The proposed model with Bi-
LSTM contains ﬁve convolutional layers with ﬁlters 32, 128, 256, 1024, and 64. For
three Bi-LSTM layers, number of hidden cells are 512, 1024, and 64. The CTC layer
computes the character-wise error rate instead of word-wise error rate and returns
loss value for every step per epoch.
CTC Layer
The proposed CTC layer merges repeated related characters. The ﬁrst phase in this
layer is predicting the tokens in a sequential order. Second phase is to merge repetitive
characters and drop noisy tokens. CTC layer provides ﬁnal output after phases 1 and
2. This layer offers a loss function to compare anticipated and actual values.
Figure 4 shows CTC layer’s operation. It does not use any traditional aligning
methods, instead it will eliminate the process of alignment. Bi-LSTM or Bi-GRU may
output ‘Amlopin’ as a series of characters. The custom CTC layer ﬁlters characters
in each word. In the proposed network design, CTC layer input and output shapes
are (None, 32, 81) itself. Every training step calculates CTC loss. CTC batch cost’s
Fig. 3 Model topology for Bi-LSTM

Interpreting Doctor’s Handwritten Prescription Using Deep Learning …
425
Fig. 4 Functionality of CTC layer
arguments are y pred, y true, label length, and input length. It returns each element’s
loss. Image input determines this argument’s value.
CNN + Bi-Directional GRU
Figure 5 demonstrates Bi-Directional GRU model building. Input layer shape is
(128, 32, 1) with width, height, and channel. Dropout layers between convolutional
and pooling layers prevent overﬁtting. The dropout value used is 0.25. In total 5
convolution layers with ﬁlter sizes 32, 128, 256, 512, 1024 are used. The next three
Bi-Directional GRU layers have 128, 128, and 512 hidden cells. The CTC layer
works similarly to the prior Bi-LSTM model (Fig. 4).
After comparing the both models, Bi-LSTM has more training parameters than Bi-
GRU. The model’s hidden units determine the total number of trainable parameters.
The total trainable parameters are 6,907,025. Consider character error rate for an
effective model.
Fig. 5 Model architecture for Bi-Directional GRU

426
R. Mohammad et al.
3.4
Selection of Algorithm
The implementation of proposed model is done with two different algorithms, and
they are Bi-LSTM and Bi-GRU. The CNN is common in both models. But, the
type of RNN used is different. The model uses algorithms of CNN + Bi-Directional
LSTM [1] in ﬁrst model and CNN + Bi-Directional GRU [9] in second model.
Here, the comparison is done in order to determine which model is performing well.
From Fig. 2 in medicine name recognition phase, the algorithms used are different,
but other steps remain same. Both LSTM and GRU are recurrent neural networks,
but the difference is the size of data they can handle and gates present. Using IAM
dataset, the training dataset size is 86,800 images. Bi-Directional LSTM is excellent
at handling huge data, followed by GRU. GRU is preferred for small datasets. Input,
Output, Forget are LSTM gates. GRU only has update and reset gates. GRU is simpler
than LSTM. So, it is better to use GRU for small-sized data and LSTM for large-sized
data. The selection of these two algorithms is done in order to test which algorithm
will perform well.
The mathematical notation of Bi-Directional LSTM is as follows:
ˆpt = g

Wx

⃗a⟨t⟩, ←−
a ⟨t⟩
+ bx

(1)
From Eq. (1), ˆp is used for representation of output, ˆpt will represent output at
tth unit of time. The g represents the hidden layer function. Wx denotes the hidden
layer weights matrix. And similarly, bx denotes hidden layer vector for bias values.
⃗a⟨t⟩gives the forward hidden sequence, and ←−
a ⟨t⟩gives the backward sequence. As
the employment of Bi-directional layers is being done, the two directional sequences
can be obtained. Here, the iterations are done on forward and backward sequences,
and then, the output will get updated when concatenation is done for each word in
forward and backward sequences.
The mathematical notation of Bi-Directional GRU is as follows:
ht = Gforward

xt, −−→
ht−1

⊕Gbackward

xt, ←−−
ht+1

(2)
Equation (2) Similar to Bi-Directional LSTM, the Bi-Directional GRU also allows
data sequence in two directions forward and backward. From Eq. (2), Gforward is a
GRU function that denotes the data sequence ﬂow in forward direction, and Gbackward
is a GRU function that denotes the data sequence ﬂow in backward direction. ⊕
is vector concatenation operator for Gforward and Gbackward data sequence ﬂows.
Gforward

xt, −−→
ht−1

denotes forward GRU’s state, and Gbackward

xt, ←−−
ht+1

denotes
backward GRU’s state. xt denotes input vector. ht denotes output of cell at time t. By
performing concatenation in between forward and backward states of GRU gives the
required output ht. From Eq. (2), the concatenation of both forward and backward
sequences makes the model to access previous states as well.

Interpreting Doctor’s Handwritten Prescription Using Deep Learning …
427
Fig. 6 Output test case predicted by the model
4
Result and Observations
4.1
Test Case Results
Test case results are below. Model predicts based on custom image inputs. Predictions
Figure 6 displays IAM testing test case results. Figure 6 shows the model’s predic-
tions after 25 epochs of training. All three testing dataset images were successfully
predicted by the model. First, the image was preprocessed and passed to the model
for prediction.
4.2
Observations and Analysis
Accuracy observations for Bi-Directional LSTM and Bi-Directional GRU at different
epochs are shown below.
From Table 1, two models (one with Bi-LSTM and another with Bi-GRU)
are trained and tested to compare accuracy. At 30th epoch, Bi-Directional LSTM
had 81% accuracy and Bi-Directional GRU 77%. Bi-Directional LSTM algorithm
training took 5 h and Bi-Directional GRU training took 3 h. Bi-Directional GRU, a
less sophisticated model, trained 30 epochs in less time than Bi-Directional LSTM,
but had lower accuracy. Bi-Directional LSTMs outperform Bi-Directional GRUs on
larger datasets.
Bi-Directional GRU has 88% training data, while Bi-Directional LSTM has
90%. To avoid overﬁtting, control validation loss. By adding enough dropout value,
overﬁtting can be controlled, and data quantity can affect validation loss.
Figure 7 plots epochs versus loss. Loss values are achieved after 40 epochs of
training and saving the best weights with checkpoints. Training and validation losses
Table 1 Comparison of
Bi-LSTM and Bi-GRU
accuracies
Epochs
Accuracy (%)
BI-LSTM
BI-GRU
20
75
69
25
78
74
30
81
77

428
R. Mohammad et al.
Fig. 7 Loss versus epochs with Bi-Directional LSTM
are minimal at 30th epoch. The training loss is 0.6 and validation loss is 1.24. Training
loss and validation loss are close together on the graph, indicating no overﬁtting. If
validationlossincreaseswhiletraininglossdoesnot,thatismodeloverﬁtting.Adding
a dropout layer helps to avoid overﬁtting. The number of neurons to be dropped from
each hidden layer is dropout percentage. In proposed architecture, all the dropout
layers are having 25% of dropout.
Figure 8 shows Bi-Directional GRU loss versus epochs’ graph. Model was trained
for 35 epochs, and best weights are restored. At 30th epoch, model has minimal
training and validation losses. Bi-Directional GRU has 1.5 and 1.3 training and
validation losses, respectively. Bi-Directional LSTM model has 81% accuracy, 0.96
precision, 0.83 recall, and 0.89 F-score. Bi-Directional GRU has 77% accuracy, 0.95
precision, 0.80 recall, and 0.86 F-score.
This metric shows that Bi-Directional LSTM performs well with large training and
validation datasets. As LSTMs have more gates than GRUs, the suggested method is
more complex but can perform better than alternatives with fewer gates. For real-time
use case, maintain quality of dataset used for training model. The current handwriting
recognition model should be trained with 50 doctors’ handwriting styles. This lets
the model to detect any handwriting and to make more accurate predictions. Training
and validation datasets should have diverse calligraphy styles. This makes the model
more resilient, so it can properly predict most inputs.
5
Conclusion and Future Work
This model helps pharmacists and normal people to recognize the medicine name
accurately which is present in the Doctor’s Handwritten Prescription. This effectively

Interpreting Doctor’s Handwritten Prescription Using Deep Learning …
429
Fig. 8 Loss versus epochs with Bi-Directional GRU
offers text in all handwriting typefaces. The feature extraction is carried out by
Convolutional Neural Networks with many layers, and the decoding of the extracted
features into English letters is assisted by Bi-LSTMs. The CTC is employed to
circumvent the fact that the true alignment between the input and the output is
unknown. To accurately identify language speciﬁc to prescriptions provided by the
doctors, more bias is applied to words that are present in a manually produced
corpus. More data increase model accuracy. Compared to Bi-Directional GRU, Bi-
Directional LSTMs perform better and are more accurate with large datasets.
Future work: Training and validation dataset sizes can be increased, and diverse
handwriting images can be used for training in order to improve model’s recognizing
ability. Advanced algorithms can boost model performance. Pre-trained models can
be used which may boost model’s performance.
References
1. Jain T, Sharma R, Malhotra R (2021) Handwriting recognition for medical prescriptions using
a CNN-Bi-LSTM model. In: 2021 6th International conference for convergence in technology
(I2CT), pp 1–4 (T. Jain, 2021)
2. Tabassum et al. S (2021) Recognition of doctors’ cursive handwritten medical words by using
bidirectional LSTM and SRP data augmentation. In: 2021 IEEE technology & engineering
management conference—Europe (TEMSCON-EUR), pp 1–6
3. Fajardo LJ et al. (2019) Doctor’s cursive handwriting recognition system using deep learning.
In: 2019 IEEE 11th International conference on humanoid, nanotechnology, ınformation
technology, communication and control, environment, and management (HNICEM), pp 1–6
4. Maalej R, Kherallah M (2022) New MDLSTM-based designs with data augmentation for
ofﬂine Arabic handwriting recognition. Multimed Tools Appl 81:10243–10260

430
R. Mohammad et al.
5. Alrobah N, Albahli S (2022) Arabic handwritten recognition using deep learning: a survey.
Arab J Sci Eng 47:9943–9963
6. Sharma S, Gupta S (2021) Recognition of various scripts using machine learning and deep
learning techniques—a review. In: 2021 6th International conference on signal processing,
computing and control (ISPCC 2021), pp 84–89
7. SwindallMIetal.(2021)ExploringlearningapproachesforancientGreekcharacterrecognition
with citizen science data. In: 2021 IEEE 17th International conference on eScience (eScience)
8. Altwaijry N, Al-Turaiki I (2021) Arabic handwriting recognition system using convolutional
neural network. Neural Comput Appl 33:2249–2261
9. Haboubi S, Guesmi T, Alshammari BM, Alqunun K, Alshammari AS et al (2022) Improving
CNN-BGRU hybrid network for Arabic handwritten text recognition. Comput Mater Continua
73(3):5385–5397
10. Lamtougui H, Moubtahij HE, Fouadi H, Satori K (2022) An efﬁcient hybrid model for Arabic
text recognition. Comput Mater Continua 74(2):2871–2888
11. Ahmed G, Alyas T, Waseem Iqbal M, Usman Ashraf M, Mohammed Alghamdi A et al. (2022)
Recognition of Urdu handwritten alphabet using convolutional neural network (CNN). Comput
Mater Continua 73(2):2967–2984
12. Mohammed Aarif KO, Sivakumar P (2022) Multi-domain deep convolutional neural network
for ancient Urdu text recognition system. Intell Autom Soft Comput 33(1):275–289
13. Abbas S, Alhwaiti Y, Fatima A, Khan MA, Adnan Khan M et al. (2022) Convolutional
neural network based intelligent handwritten document recognition. Comput Mater Continua
70(3):4563–4581
14. Xue Y, Tong Y, Yuan Z, Su S, Slowik A et al (2021) Handwritten character recognition based
on improved convolutional neural network. Intell Autom Soft Comput 29(2):497–509
15. Abdallah A, Hamada M, Nurseitov D (2020) Attention-based fully gated CNN-BGRU for
Russian handwritten text. J Imaging 6(12):141
16. Espana-Boquera S, Castro-Bleda MJ (2022) A Spanish dataset for reproducible benchmarked
ofﬂine handwriting recognition. Lang Res Eval 56:1009–1022
17. Harikrishnan A, Sethi S, Pandey R (2020) Handwritten digit recognition with feed-forward
multi-layer perceptron and convolutional neural network architectures. In: 2020 2nd Inter-
national conference on ınnovative mechanisms for ındustry applications (ICIMIA), pp
398–402
18. Nikitha A, Geetha J, JayaLakshmi DS (2020) Handwritten text recognition using deep
learning. In: 2020 International conference on recent trends on electronics, ınformation,
communication & technology (RTEICT)
19. Hassan S, Irfan A, Mirza A, Siddiqi I (2019) Cursive handwritten text recognition using bi-
directional LSTMs: a case study on Urdu handwriting. In: 2019 International conference on
deep learning and machine learning in emerging applications (Deep-ML)
20. ul Sehr Zia N, Naeem MF, Raza SMK et al. (2022) A convolutional recursive deep architecture
for unconstrained Urdu handwriting recognition. Neural Comput Appl 34:1635–1648
21. Shaw U, Mamgai TR, Malhotra I (2021) Medical handwritten prescription recognition and
information retrieval using neural network. In: 2021 6th International conference on signal
processing, computing and control (ISPCC), pp 46–50
22. Sethy A, Patra PK, Nayak SR (2022) A deep convolutional neural network-based approach for
handwritten recognition system. In: Das AK, Nayak J, Naik B, Dutta S, Pelusi D (eds) Compu-
tational ıntelligence in pattern recognition. Advances in Intelligent Systems and Computing,
vol 1349. Springer, Singapore
23. Gupta D, Bag S (2020) CNN-based multilingual handwritten numeral recognition: a fusion-free
approach. Expert Syst Appl, pp 1–14

Abductive Inference of Conclusions
with Check of Additional Premises
Literals Correctness Interpretation
Vasily Meltsov, Dmitry Strabykin, and Alexander Krutikov
Abstract At the present stage of the development of computer technology and infor-
mation technology, the theory and methods of reasoning modeling play an important
role in creating artiﬁcial intelligence systems. Reasoning modeling can be used,
for example, in managing the functioning of complex intelligent information and
control systems in order to explain and justify the decisions they recommend. The
article considers a special method of abductive logical inference with checking the
correctness of the interpretation of literals of additional premises. The method under
consideration, in addition to explaining the course of inference with the help of
schemes, allows you to check the correctness of the interpretation of new “facts”
formed in the process of inference, taking into account the ontology of a particular
subject area. The main advantage of the proposed method is the parallel execution
of disjunctive division operations in the inference procedure.
Keywords Knowledge processing · Intelligent systems · Abductive inference ·
Predicate calculus · Additional premises
1
Introduction
The rapid development of information technology and computer technology in recent
years has allowed the transition to the creation of high-performance artiﬁcial intelli-
gence systems [1]. The use of such systems is particularly effective in solving prob-
lems in such areas as business management [2], medical and technical diagnostics [3],
V. Meltsov (B) · D. Strabykin
Department of Electronic Computers, Vyatka State University, Kirov, Russia
e-mail: meltsov@vyatsu.ru
D. Strabykin
e-mail: strabykin@vyatsu.ru
A. Krutikov
Institute of Mathematics and Information Systems, Vyatka State University, Kirov, Russia
e-mail: usr09603@vyatsu.ru
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_32
431

432
V. Meltsov et al.
transportation logistics, image processing, logical forecasting, semantic analysis of
texts. Along with the successful application of artiﬁcial neural networks and various
machine learning algorithms [4], theory and methods of reasoning modeling play
an important role in the design of high-performance knowledge processing systems
[5, 6].
Reasoning modeling can be used, for example, in monitoring the functioning of
complex intelligent information and control systems in order to explain and justify
the solutions recommended by them [7]. Representation of knowledge in the form of
logical formulas and deductive logical inference allow to guarantee the validity of the
recommended solutions, provided the validity of the initial statements (premises).
In the process of deductive logical inference, new statements are formed as conse-
quences of already existing statements, and their truthfulness is conditioned by the
truthfulness of previous statements [8]. To simplify the explanation and justiﬁcation
of the recommended solution, the process of logical deduction is visualized in the
form of a special inference scheme, reﬂecting the used statements and their relation-
ship, and allowing to analyze the course of reasoning, generated by logical inference
[9].
When intelligent information and control systems operate under conditions of
incomplete or incorrect information, it is of interest to model plausible reasoning
to explain and justify the recommended solutions [10]. In this case, methods of
abductive logical inference can be used, allowing to determine the missing secondary
premises and obtain a successful deductive logical inference [11].
Deductive and abductive logical inference can be explained by the following
example (Table 1) [12].
Deduction is the derivation of goal 3 from premises 1 and 2. Abduction in the
above example would mean deriving premise 2 from premise 1 and purpose 3.
In general, the process of abductive inference may fail because it does not allow
obtaining a formula for an additional premise or the obtained additional premise
will contradict the existing main premise. At the same time, even if the formula of
an additional premise does not lead to inconsistency in the knowledge base, it can
contain literals that have no correct interpretation in the subject area and are therefore
unacceptable.
Obviously, the presence of unacceptable literals in the additional premises can be
determined by a user of intelligent information control system when analyzing the
literals for the possibility of their interpretation in the subject area [13]. However, this
Table 1 Example of a logical task
No.
Initial premises
Interpretation
In predicate logic
1
Rule (main premise)
[All people are mortal]
∀(x)HUMAN(x)⇒MORTAL(x)
2
Fact (minor premise)
[Socrates is a man]
HUMAN(SOCRAT)
3
Purpose (conclusion)
[Socrates is mortal]
MORTAL(SOCRAT)

Abductive Inference of Conclusions with Check of Additional Premises …
433
approach has serious drawbacks: it slows down the process of controlling the func-
tioning of an intelligent information-management system and risks the appearance
of user errors.
In this connection, it is of interest to automatically check all literals of additional
premises in order to correctly interpret them in the subject area on the basis of a
special knowledge base containing unacceptable facts and rules.
2
Method of Abductive Logical Inference
2.1
Formal Problem Statement
The task of abductive logical inference can be formulated as follows. There are
initial consistent premises given as a set of disjuncts M = {D1, D2, …, DK}. There
is also a conclusion represented by the set of deducible disjuncts m = {d1, …, dT}.
If the deductive inference is not successful, then it is necessary to: deﬁne the set
of additional premises MD, supplementation of which to the set of initial premises
M ensures a successful deductive inference: M′ ⇒dt, gde M′ = M ∪M D, t =
1, ..., T . The new set of premises M′ should be consistent.
2.2
Method of Abductive Inference
The method special abductive inference of the conclusion is based on the abductive
inference procedure (w-procedure) and the procedures of full (-procedure) and
partial division of disjuncts (ω-procedure) [11].
Partial disjuncts division. Partial disjunct division is performed using a special
procedure:
ω = ⟨b, d, q, n⟩,
where
b
remainder-dividend (disjunct of premise) used to
obtain the remainders;
d
remainder-divisor (disjunct of conclusion) involved
in the formation of remainders;
q
is a particular attribute of the solution having three
values: “0”—at least one zero remainder is obtained,
“1”—all obtained remainders are equal to one, “g”—
more than one remainder unequal to one is obtained
in the absence of zero remainders;

434
V. Meltsov et al.
n = {⟨bt, dt⟩, t = 1, . . . , T } the set of pairs consisting of the new remainder-
dividend bt and its corresponding remainder-divisor
dt.
In the process of disjunct division, the literals that coincide after uniﬁcation with
the literals of the disjunct-divisor are excluded from the disjunct-divisor. If the last
literal is excluded from the disjunct-divisible, the remainder is “0”; if the literals are
not uniﬁed, the remainder is “1.” In other cases, the remainder consists of the literals
of the disjunct-divident obtained after applying a unifying substitution to them and
excluding the matching literal. Since a unifying substitution can also change the
variable values in the literals of the disjunct-divisor, each new residual corresponds
to a new modiﬁed version of the disjunct-divisor. A detailed description of the partial
disjuncts division procedure can be found in [11].
Complete disjunct division. Complete disjunct division is aimed at obtaining so
called ﬁnite remainders. A remainder-dividend b is ﬁnite for a remainder-divisor d
if applying the procedure ω to it does not produce new remainders other than “1.”
A ﬁnite remainder b or a new remainder bt can be a consummate remainder. When
disjuncts are completely divided, the resulting set of remainders includes principal
remainders, which include uniliterate ﬁnal remainders as well as ﬁnal remainders
with two or more nonvariable literals.
The complete division of disjunct D into disjunct d is performed considering the
facts (single-literal initial disjuncts) with the help of a special procedure:
 = ⟨D, d, Q, N⟩,
where
Q
the solution ﬂag having three values: “0”—the solution is found, “1”—the
disjunct D has no d remainders other than unity, “G”—the set of ﬁnite remainders
is obtained;
N
set consisting of ﬁnite remainders E j

N =

E j, j = 1, . . . , J

At Q = 0 N =
{0}, and at Q = 1 N = {1}.
The formation of a set of residuals is done by repeated application of ω-procedures
and consists of a series of steps. At each step, ω-procedures are applied to the existing
divisible and divisible residuals, forming new divisible residuals and new divisible
residuals that are used as input in the next step. The process ends when the next step
reveals a ω-procedure that has produced zero residuals (q = 0), or all ω-procedures
of this step have produced traits that indicate the ﬁnal residuals (q = 1).
The abductive inference procedure. The procedure allows you to make a step
of inference, converting the inferred disjunct into a set of new disjuncts needed to
continue inference in the next step, and also calculate an auxiliary disjunct that is
used to form additional premises. We deﬁne the abductive inference procedure w as:
w = ⟨M, d, o, q, p, m,⟩,

Abductive Inference of Conclusions with Check of Additional Premises …
435
where
M
=
{D1, D2, . . . , Di, . . . , DI}
set of initial disjuncts (initial premises);
d = L1∨L2∨. . .∨Lk∨. . .∨LK
inferred disjunct (conclusion);
o = < c, C >
a pair of current remainder sets consisting of the
sets of residuals formed before (c) and after (C)
procedure w;
q
attribute of the solution, which has two values:
0—there is a solution and 1—no solution;
p
attribute of the inference termination, which has
two values: 0—continuation of the inference is
possible and 1—continuation of the inference is
impossible;
m = {dg, g = 1, . . . , G}
is the set of new inferred disjuncts dg. If p = 1 m
= ∅;
∂
is the complement, which is an auxiliary
remainder used in forming disjuncts of additional
initial premises. The augment is computed by
means of partial disjunct group division ϖ oper-
ation which is performed by partial division of
disjunct d into a subset of initial disjuncts M0
(M0 ⊆M) that have nonunit remains after divi-
sionbydisjunctd.Attheﬁrststepoftheinference
for dϖM0 = 1, we take ∂= 1, and at later steps
∂= d.
The inference procedure uses the previously discussed complete disjunction
division -procedure as a subprocedure.
The abductive inference procedure is applicable if M ̸= ∅and Ji, K ≥1 (i =
1,…,I); otherwise, the attribute p = 1 is immediately set. When the procedure is
used for the ﬁrst time, the input set of current remainders includes inversions of
literals of the conclusion d: c = {Lk, k = 1, . . . , K}. In the inference procedure, the
following actions are performed.
1. Remainders of initial disjuncts are formed:
• disjuncts of initial premises are divided by -procedure into conclusion:
Did = ∧r=1
Ri bir, i = 1, . . . , I. And if at least one remainder bir = 0 (at
least in one -procedure Q = 0), then q = 0 is taken and proceeds to step 4,
otherwise the following action is performed.
• residuals bir = 1 are excluded. If all remainders are equal to 1 (in all -
procedures Q = 1), no inference is possible; take p = 1 and proceed to step
4; otherwise, the following action is performed.
• the set E of remainders of initial disjuncts is formed: E = {bs, s = 1,…,S},
which includes only remainders bir that differ from each other. Remainders
that coincide with or are absorbed by the remainders of c are excluded from

436
V. Meltsov et al.
this set. This results in a set e of remainders of the original sequences that
does not contain the previously obtained remainders. If e = ∅, no inference is
possible; p = 1 is taken, and we proceed to step 4; otherwise, the next step is
executed.
2. The conjunctive condition of the inference termination is checked. The output
set of current remainders is formed: C = c ∪e, C = {bn, n = 1,…,N}. An
expression ∧n=1
N
bn composed, which is simpliﬁed by multiplying the residuals
and excluding conjunctions containing L ⌉L (0L) type factors. If the expression
thus transformed equals zero, the inference is successfully completed (q = 0)
and proceeds to step 4; otherwise, the next item is executed.
3. New disjuncts are formed. The expression, ∧v=1
V
bv, is left from the remainders of
the set e = {bv, v = 1,…,V}, which is simpliﬁed by multiplying the remainders
andexcludingconjunctionsthatcontainL ⌉L (0L).Typedoublers.Theexpression
obtained after multiplication of disjuncts and simpliﬁcation is a disjunctive form
of the form: X1∨X2∨…∨Xg∨…∨XG, where Xg = Lg
1Lg
2 . . . Lg
Hg. Inversions
of conjunctions Xg form new derivable disjuncts Lg
1 ∨Lg
2 ∨. . . ∨Lg
Hg, g = 1,
2, …, G. New conclusions are included in the set m. Attribute of the inference
termination p = 0 is set.
4. End of procedure
Method of abductive inference. The inference is represented by a set of disjuncts.
Logical inference is reduced to multiple application of w-procedures and consists of
a number of steps. At each step of inference w, procedures are applied to existing
inferred and initial disjuncts forming new inferred disjuncts that are used at the next
step. Besides on each step with help of w-procedures, add-ons are calculated which
serve as a basis for formulae of  additional premises used for forming of set MD
of additional assumption disjuncts. In the process of logical inference, two ﬂags are
formed at the end of the step:
Q—solution general ﬂag (Q = 0—there are solutions, Q = 1—no solutions);
P—inference continuation general ﬂag (P = 0—inference continuation is
possible, P = 1—inference continuation is impossible). The inference process ends
when Q = 0 (no additional premises are required) or P = 1.
The inference process can also be terminated when a given number of inference
steps is reached. The method is applicable if the inferred disjuncts are not tautologies
and their conjunction is a contradiction.
Foramorecompletedescriptionofthemethod,wewilluseaspecialindexfunction
that provides unique identiﬁcation of each procedure and its parameters at the h-th
step of the inference (h = 1,…,H).
The index function i(h) is deﬁned for the index variable t inductively as follows:
• i(1) = t, t = 1, . . . , T ;
• i(2) = t.tt = i(1).ti(1), ti(1) = 1, . . . , Ti(1);
• i(3) = t.tt.tE(E = t.tt), i(3) = i(2).ti(2), ti(2) = 1, . . . , Ti(2);
• etc.

Abductive Inference of Conclusions with Check of Additional Premises …
437
In general case: i(h + 1) = i(h).ti(h), ti(h)=1,…,T i(h). Let us assume that i(0) means
that there is no index for the indexed variable, e.g., T i(0) = T, and that i(1) = i(0).ti(0)
= t. Then the description of the method can be represented as follows.
1. Initial values are deﬁned: h = 1, hmax = H, M = {D1, . . . , DK}, m =
{d1, . . . , dT },i(1) = t;t = 1, . . . , T ,whereT isthenumberofinferreddisjuncts;
o = ⟨c, C⟩, c = C = ∅.
2. The w-procedures of the current (h-th) step are executed. For derived disjuncts
of set m on the ﬁrst step (h = 1) and on the next step (h > 1) for disjuncts of sets
mi(h−1), obtained in the procedures of the previous step, characterized by features
pi(h−1) = 0 and qi(h−1) = 1, the following w-procedures are executed:
wi(h) =

M, di(h), oi(h), qi(h), pi(h), mi(h), ∂i(h)

,
i(h) = i(h −1).ti(h−1), ti(h−1) = 1, . . . , Ti(h−1).
3. The solution general ﬂag (Qh) and the inference continuation general ﬂag (Ph)
are formed; the formula () of the additional premises is constructed:
Qh =
B∨
A=1 qi(h) ∨Si(h−1), Ph =
B∧
A=1

⌉qi(h) ∨pi(h)

∨Si(h−1);
i(h−1) = ⌉Si(h−1)
A=1
∧
B

∂i(h) ∨⌉pi(h)i(h) ∨⌉qi(h)

∨Si(h−1)
A=1
∧
B di(h);
where
A = ti(h−1) and B = T i(h−1);
Si(h−1) is a ﬂag of consistency of values of common variables in subsets mi(h−1) of
derived disjuncts di(h), which these variables took after performing procedures wi(h)
(Si(h-1) = 0—values are consistent or disjuncts have no common variables, Si(h-1) =
1—values of common variables are not consistent).
4. The values of the general signs of the solution (Qh) and the inference continuation
general ﬂag (Ph) are checked. If Qh = 0, the inference is completed successfully.
In this case Q = 0, P = Ph, MD = ∅are set, and the next step is executed. If Qh
= 1, the sign Ph. is analyzed. If Ph = 0, then at h < hmax h is increased by one
and executed step 2 (the process continues). If Ph = 1 or h = hmax, then P = 1
is set and the next step is executed.
5. The inference process is completed. Moreover, at Q = 0 the inference is
completed successfully, and no additional premises are required (MD = ∅). At Q
= 1 (no solution) the inference is unsuccessful, but as a result of the inference the
formula of additional premises  is constructed. If  ̸= 1 and  ̸= 0, then the
set of disjuncts of additional premises MD is formed. Additional disjuncts are
obtained by converting the formula of additional propositions into conjunctive
normative form:

438
V. Meltsov et al.
Table 2 Set of initial premises and conclusion
D
Knowledge
Premises/conclusion
Clauses (disjuncts)
D1
Fact 1
directs(Serge, Boris)
D1 = P(c, b)
D2
Fact 2
directs(Boris, Anna)
D2 = P(b, a)
D3
Fact 3
directs(Anna, Alex)
D3 = P(a, e)
D4
Rule 1
directs(x, y) →reports(y, x)
D4 = ¬P(x, y)∨O(y, x)
D5
Rule 2
directs(z, u)&reports(s, u) →reports(s,
z)
D5 = ¬P(z, u)∨¬O(s, u)∨O(s, z)
r
Conclusion
“Does Alex report to Serge?”
d = O(e, c)?
 = DK+1DK+2 . . . DK+n . . . DK+N, M D = {DK+n, n = 1, . . . , N}.
6. The literals of additional premises are checked for the correctness of interpreta-
tion in the domain. The literals representing unacceptable statements according
to the conditions of the problem are excluded from the disjuncts of additional
premises of the MD set. To determine the correctness of interpretation of literals
of additional premises in the domain, one can use a special knowledge base
containing unacceptable facts and rules. The logical following of literal of an
additional premise from the facts of the speciﬁed knowledge base will mean its
unacceptability.
2.3
Example of Abductive ˙Inference
As an example of abductive logical inference, consider solving the following problem
(Table 2) [14]. Initially, the knowledge base contains 3 facts and 2 rules-disjuncts.
For the given initial data, the problem is solved by means of deductive logical
inference, which ends successfully: the conclusion is a consequence of the premises.
The scheme of logical deduction of the conclusion is shown in Fig. 1.
Let us exclude fact 2 and its corresponding disjunct D2 = P(b, a) from the original
data. After excluding this fact, deductive logical inference becomes impossible. The
construction of abductive explanations, which is carried out by abductive logical
inference, makes it possible to ensure successful deductive inference.
Abductive logical inference in this example consists of three steps (h = 1, 2, 3)
where one deduction procedure (w1 i w1.1) is executed on the ﬁrst and second steps
and two procedures on the third step (w1.1.1 i w1.1.2). Table 3 summarizes the main
results of the procedures and the formulae of additional premises by steps. At the
third step of derivation after matching the values of common variable u2, the formula
for additional premises takes the following form:  = P(c, e)∨P(b, a).

Abductive Inference of Conclusions with Check of Additional Premises …
439
Fig. 1 Scheme of inference
to conclusion «reports(Alex,
Serge)»
F3 
R1
F2
R2
F1
R2
P(a,e)
directs(Anna,Alex)
directs(Boris,Anna)
directs(Serge,Boris) 
reports(Alex,Anna)
reports(Alex,Boris)
reports(Alex,Serge)
O(e,a)
O(e,b)
O(e,c)
P(b,a)
P(c,b)
Table 3 Process of abductive logical inference
h w
d
q
p m
∂
Q P
S

1 w1 = < M,d1,o1,
q1,p1,m1,∂1 >
O(e, c)
1
0 {d1}
0
1
0
0
1
2 w1.1 = < M,d1.1,o1.1,
q1.1,p1.1,m1.1,∂1.1 >
P(c, e)∨O(e, b) 1
0 {d1.1.1,
d1.1.2}
P(c, e)
1
0
0
P(c, e)∨1.1
3 w1.1.1 = <
M,d1.1.1,o1.1.1,
q1.1.1,p1.1.1,m1.1.1,∂1.1.1 >
P(b, u2)
1
1 ∅
P(b, u2)
w1.1.2 = <
M,d1.1.2,o1.1.2,
q1.1.2,p1.1.2,m1.1.2,∂1.1.2 >
O(e, u2)
0
1 ∅
0
1
1
0
P(c, e)∨P(b, a)
Thus, in the process of abductive inference of the intermediate conclusion d1 =
O(e, c), we obtain a set of additional premises MD = {D6}, where D6 = P(c, e)∨P(b,
a) is formed by performing the operation of disjunct division in three inference’s
steps.
The resulting complementary premise does not contradict the main premises of
D1–D5. However, it is necessary to check the literals of the additional premise for
the correctness of interpretation in the domain [15]. The literals representing unac-
ceptable statements according to the conditions of the problem should be excluded
from the disjunct of the additional premise [8].
3
Checking the Correctness of Literal Interpretation
In principle, the user of the intelligent information and control system himself can
carry out the necessary check. In the example, the analysis of the literals of the

440
V. Meltsov et al.
supplementary premise shows that the literal P(c, e)—“directs(Serge, Alex)” cannot
be used in the supplementary premise based on the meaning of the problem, because
the base contains the fact D3 = P(a, e)—Alex is already under the direct control of
Anna (two direct leaders of one subordinate are not allowed). However, it is more
effective to check the literals of the additional premise for the correct interpretation
in the subject area can be carried out on the basis of a special knowledge base in
automatic mode. Then the successful logical conclusion of the additional premise
literal from this special knowledge base will mean its unacceptability.
In the example under consideration for formal determination of correctness of
interpretation of literals of an additional premise in the subject domain can be used
special knowledge base, containing the following premises: D*1 = P(c, b); D*2
= P(a, e); D*3 = ⌉P(u, w)∨P(v, w) (the presence of two direct managers for one
subordinate). Deductive logical inference of literals of the additional premise P(c, e)
and P(b, a) from the special knowledge base D*1, D*2, D*3 is performed by means
of partial (ω) and complete () disjunct division procedures.
Figure 2 shows the logical inference of literals P(c, e) and P(b, a) using complete
disjunct division procedure 1 =

D∗
3, P(c, e), Q1, N1

, and Fig. 3 shows the logical
inference of literals P(c, e) and P(b, a) using complete disjunct division procedure
2 =

D∗
3, P(b, a), Q2, N2

.
The procedure of complete division of disjuncts 1 =

D∗
3, P(c, e), Q1, N1

terminates successfully with a remainder “0” indicating that the literal P(c, e) is
logically deducible from the special knowledge base premises. Thus, the literal P(c,
ω1 =<
∗
3,
( , ),
1,
1 >
ω1
⎤P(u,w) 
P(v,w) 
P(c,e) 
1 
Δ12
Considering ο12 = { / , / }, we get:  Δ12=⎤P(u,e)=b1; q1=g; n1={<b1,d1>}
Compare Δ12 with the negations of the facts: d1
+=⎤P(c,b)v⎤P(a,e) 
ω1.1 =<
1,
1+,
1.1,
1.1 >
ω1.1
⎤P(u,e) 
⎤P(c,b) 
1 
⎤P(a,e) 
0 
Considering λ12={a/u}: Δ21=b1.1=0; q1.1=0;  n1.1={<0,1>} and  d1.1=1
Then: Q1=0; N1={E1}, E1=0
Fig. 2 Procedures of complete disjunct division: 1 =

D∗
3, P(c, e), Q1, N1


Abductive Inference of Conclusions with Check of Additional Premises …
441
ω1 =<
∗
3,
( , ),
1,
1 >
ω1
⎤P(u,w) 
P(v,w) 
P(b,a) 
1 
Δ12
Considering λ12={b/v, a/w}, we get:  Δ12=⎤P(u,a)=b1; q1=g; n1={<b1,d1>}
Compare Δ12 with the negations of the facts: d1
+=⎤P(c,b)v⎤P(a,e) 
ω1.1 =<
1,
1+,
1.1,
1.1 >
ω1.1
⎤P(u,a) 
⎤P(c,b) 
1 
⎤P(a,e) 
1 
b1.1=1; q1.1=1;  n1.1={<1,0>} and  d1.1=0
Then: Q2=1; N2={1}, E2=1
Fig. 3 Procedures of complete disjunct division: 2 =

D∗
3, P(b, a), Q2, N2

e) is unacceptable and is excluded from the disjunct of the additional premise, which
takes the following form: D′6 = P(b, a).
The procedure of complete division of disjuncts 2 =

D∗
3, P(b, a), Q2, N2

fails (with formation of “singular” remainders), so the literal P(b, a) is not a logical
consequence of the initial knowledge base. Thus, the literal P(b, a) is considered
acceptable for specifying it as a complementary premise: D′6 = P(b, a). In other
words, if it is added to the initial premise base, then the deductive conclusion d1 =
O(e, c) will be successful.
4
Conclusion
Methods of deductive and abductive reasoning are indispensable for designing
high-performance knowledge processing systems in general and complex intelli-
gent information-management systems in particular. Such mechanisms, in contrast
to the widespread neural network approach, allow the module of explanation of the
process of formation of the resulting “reasoning” by the artiﬁcial intelligence system
to be implemented. Besides, abductive methods form necessary additional premises,
extending the knowledge base, developed by expert.
The abductive logical inference considered in the article, in addition to explaining
the course of the logical inference with the help of inference schemes, allows you
to check the correctness of interpretation of literals of additional premises. At the

442
V. Meltsov et al.
same time, the mechanism of inability to add “illogical” statements to the base is
implemented, taking into account the existing ontology of a particular domain.
A special knowledge base for checking the correctness of interpretation of literal
additional premises generated by abductive logical inference is formed in the process
of additional analysis of the domain and its formal description by a knowledge
expert. In particular, for problems similar to the one considered in the example, the
following premises can be included in the auxiliary knowledge base: D8 = P(x, x)
(“self-direct”); D9 = O(y, y) (self-report) and others.
It is reasonable to limit the deductive logical inference of additional premises
literalsfromthespecialknowledgebasebydepthbyspecifyingthemaximumpermis-
sible number of inference steps. At the same time, it should be taken into account that
in this case the determination of the literal (additional premises) conclusion impos-
sibility from a special knowledge base is determined only at an inference depth not
exceeding the speciﬁed one.
Abductive logical inference by division of disjuncts allows one to form additional
premises that are not only separate literals (facts), but also multiliterals (private
rules). Private rules consist of literals where variables are replaced by constants.
Rules generated by abductive logical inference and consisting of several literals may
describe certain relations between subjects. There may be situations where each of
the literals of an additional premise has a correct interpretation, but the rule it deﬁnes
is unacceptable for the problem being solved. In this case, it may be expert necessary
to check the correctness of the rules generated by abductive logical inference in a
given domain.
References
1. Thacker J (2020) The age of AI: artiﬁcial ıntelligence and the future of humanity. Zondervan
2. Chen Y, Duong TQ (2017) Industrial networks and intelligent systems. In: Proceeding of 3rd
ınternational conference, INISCOM 2017, Ho Chi Minh City
3. Al-Emran M, Shaalan H, Hassanien A (2020) Recent advances in intelligent systems and smart
applications. SSDC, vol 295, pp 46–54. Springer, Cham
4. Szczerbicki E, Sanin C (2020) Knowledge management and engineering with decisional DNA.
Springer International Publishing, Switzerland
5. Putzky P, Welling M (2017) Recurrent inference machines for solving inverse problems: Under
review as a conference paper at ICLR 2017. University of Amsterdam
6. Czarnowski I, Howlett R, Jain L (2019) Intelligent decision technologies 2019. Springer,
Singapore
7. Khemani D (2022) Artiﬁcial intelligence: knowledge representation and reasoning. IIT Madras.
https://swayam.gov.in/nd1_noc20_cs30/preview. Last accessed 16 Oct 2022
8. Rahman SA, Haron H, Nordin S, Bakar AA, Rahmad F, Amin ZM, Seman MR (2017) The
decision processes of deductive inference. Adv Sci Lett 23(1):532–536
9. Meltsov V, Zhukova N, Strabykin D (2021) Logical inference in predicate calculus with the
deﬁnition of previous statements. In: Sharma H, Saraswat M, Yadav A, Kim JH, Bansal JC (eds)
Congress on ıntelligent systems. CIS 2020. Advances in Intelligent Systems and Computing,
vol 1334. Springer, Singapore
10. Vagin V, Derevyanko A, Kutepov V (2018) Parallel-inference algorithms and research of their
efﬁciency on computer systems. Sci Tech Inf Process 45(5):368–373

Abductive Inference of Conclusions with Check of Additional Premises …
443
11. Strabykin DA (2013) Logical method for predicting situation development based on abductive
inference. J Comput Syst Sci Int 52(5):759–763
12. Schaeken W, De Vooght G, Vandierendonck A, D’Ydewalle G (2014) Deductive reasoning and
strategies. Taylor & Francis eBooks, New Jersey
13. Meltsov V, Kuvaev A, Zhukova N (2020) Knowledge processing method with calculated func-
tors. In: Arseniev D, Overmeyer L, Kälviäinen H, Katalini´c B (eds) Cyber-physical systems
and control. CPS&C 2019. LNNS, vol 95. Springer, Cham
14. Dolgenkova ML, Chistyakov GA (2007) Sequences inference method out of new facts by
disjuncts division in predicate calculus (Example). https://zenodo.org/record/57859
15. Czarnowski I, Howlett R, Jain L (2019) Intelligent decision technologies 2019. Springer,
Singapore. https://doi.org/10.1007/978-981-13-8303-8

An Investigation and Observational
Remarks on Conventional Sign Language
Recognition
Thouseef Ulla Khan and M. R. Dileep
Abstract In today’s world, communication of speech and hearing impaired person
has been facilitated with different technologies. In the world, there are about 300
million people are deaf, 285 million are blind and 1 million are dumb, as per the World
Health Organization. Sign language is a tool to communicate with speech and hearing
impaired people. Recognition of sign language is a challenge for researchers from
many years that have to be implemented as a system for various sign languages. Each
systemhasitsownlimitationsanddifﬁculttobeusedcommercially.Researchershave
done their research in various ways to simplify the recognizing of sign languages with
limited database. Researchers are trying to do research with their own large database.
Through this paper, we review the different sign language recognition approaches
and try to ﬁnd the best method that has been used. This helps the researchers to
retrieve more information to develop the sign language recognition systems using
current and advanced technologies in future.
Keywords Sign language · Image processing · Convolutional neural network ·
Support vector machine · Deep learning · Machine learning
1
Introduction
The system consists of image processing, sign languages and sign language recog-
nition steps. Firstly, image processing consists of image acquisition, enhancement,
restoration, segmentation and object recognition stages. Sign languages are the way
T. U. Khan (B)
Department of Master of Computer Applications, Vidya Vikas Institute of Engineering and
Technology, Mysuru, Karnataka, India
e-mail: thouseef588@gmail.com
Department of Master of Computer Applications, VTU—Research Centre, Nitte Meenakshi
Institute of Technology, Yelahanka, Bengaluru, Karnataka, India
M. R. Dileep
Department of Master of Computer Applications, Nitte Meenakshi Institute of Technology,
Yelahanka, Bengaluru, Karnataka, India
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_33
445

446
T. U. Khan and M. R. Dileep
of communication among speech and hear impaired persons, which are represented
in different languages in different geographical areas. Sign language recognition is a
process of recognizing hand gestures through the systems developed using different
technologies. Sections 1.1 through 1.3 explains the stages involved in the process of
sign languages recognition.
1.1
Image Processing
Manipulation of digital images using computer is called digital image processing. It
concentrates on constructing computer system which is capable of image processing.
Digital image is an input of the system, it processes image as an input using different
algorithms and produces an image as an output. Images are processed using different
formats like grey scale, RGB and RGBA. Digital image processing involves the
following steps as shown in Fig. 1 image acquisition deﬁnes the position and intensity
quantization with conversion to binary digits; image enhancement deﬁnes manip-
ulation of image pixel or wavelet transform; image restoration deﬁnes removing
sensor noise; image segmentation deﬁnes partition an image into its constituent
parts; representation deﬁnes the ﬁnal output as a raw pixel data.
1.2
Sign Language
Around the world, more than 300 sign languages are there. They differ from nation
to nation. The same language is spoken in the countries, but the sign language can
have various regional accents which bring variations to use and understanding of
signs among the people. Presently, sign language recognized as a formal language in
41 countries of the world. International Day of Sign Languages has been celebrated
on 23 September. Sign languages are available for alphabets, numbers, words and
sentences. It can be differentiated by one-hand or two hands gestures, for instance,
ASL is one-hand gesture where as ISL is two hands gestures. Universal sign language
is not available, because it differs based on countries or regions such as America,
India, Britain, France, Arab, Spain, China, Australia and Tanzania. Human feelings,
thoughts and expressions can be expressed by using sign language, also to fortify the
data obtained in everyday discussions through gestures and facial expressions.
Communication is the foundation for both personal and professional relationships
of all human beings. It is essential for survival in a society. For the successful verbal
communication, we required a well-deﬁned language which can be understandable
by all the parties. In India, sign language is used for communication of around 26% of
the disabled population. There are 6.3% of hearing impaired people in India, WHO.
They use hand gestures for communication. Unfortunately, the semantics of these
hand gestures are not known to majority of Indians.

An Investigation and Observational Remarks on Conventional Sign …
447
Fig. 1 Steps in digital ımage processing
Sign language recognition (SLR) system acts as a bridge to ﬁll the gap of commu-
nication among the normal and the dumb and deaf people. Efﬁcient sign language
recognition (SLR) system helps to communicate among normal people and speech
and hearing impaired people. The majority of the normal people do not recognize
sign language, so this particular dumb and deaf population is overlooked in the world.
The signs of American Sign Language alphabets is shown in Fig. 2.
1.3
Sign Language Recognition
The different techniques are used to recognize the sign languages like convolutional
neural network, deep neural network, decision tree, artiﬁcial neural network, Arduino
circuit boards, K-nearest neighbour, Raspberry Pi and support vector machine.

448
T. U. Khan and M. R. Dileep
Fig. 2 Signs of American Sign Language alphabets
The different technologies are used to recognize the sign languages like machine
learning, Python, Django, artiﬁcial intelligence, deep learning, discrete wavelet
transform (DWT), Keras, discrete cosine transform (DCT), random forest (RF) and
histograms of oriented gradient (HOG). Figure 3 displays the model for sign language
recognition.
2
Literature Survey
2.1
Image Processing Techniques
Collection of data is the basic step of the system, where sensors and cameras are used
by many researchers to capture the hand gestures. Ajay et al. [1] used sensor gloves
pair to detect hand gestures. Fakhar et al. [2] achieved the communication objective
by using dynamic and static gestures which are identiﬁed in video-based recognition
system and converted into text. There are redundant key frames present in videos,
which have to be reduced by additional processing. It is a challenging task to select
speciﬁc key frames without missing needed information.
Microsoft Kinect Sensor, ﬂex sensors, touch sensors, nano microcontrollers, iner-
tial measurement units (IMUs) and Bluetooth are used. Mohammad and Mehreen
[3] used web camera to capture hand gesture images, and the system predicts and
displays the image name. Radha et al. [4] used web camera to capture the hand
gesture.

An Investigation and Observational Remarks on Conventional Sign …
449
Fig. 3 Sign language recognition model
Sharma et al. [5] used tri-axis gyroscopes, multichannel surface electromyo-
gram and tri-axis accelerometers placed on forearms of the signers to capture the
gestures. The sensor glove will convert the gestures. Sharad et al. [6] developed the
SHAROJAN BRIDGE that will make use of the wearable technology.
Two types of feature extraction methods are available from the images captured
by web camera in recognition of sign that are contour-based and region-based shape
representation and description methods. Skin colour modelling technique, whose
range is predetermined from non-pixels (background) and extract pixels (hand).
Lean et al. [7] demonstrated about how sample datasets are captured using vision-
based technique as shown in Fig. 4.
Mahesh [8] demonstrated about image preprocessing by image segmentation and
morphological ﬁltering as shown in Fig. 5.
2.2
Sign Language Recognition Techniques
Abdelbasset et al. [9] demonstrated how deep learning architecture to correlate sign
language video sequences, which includes two methods 2DCRNN and 3DCNN. To

450
T. U. Khan and M. R. Dileep
Fig. 4 Hand signs are captured using web camera
Fig. 5 Image segmentation and morphological ﬁltered image
build the relationship between frames, they isolate features with a recurring network
pattern using 2DCRNN. Ajay et al. [1] used sensor gloves to capture the motion
and values are passed to machine learning algorithm for classiﬁcation to ﬁnd the
gestures. Ashish et al. [10] investigated the three models: a pre-trained VGG-16
including ﬁne tuning, a VGG-16 including transfer learning and hierarchical neural
network are examined based on trainable vectors count. A conversation model was
built to convert concurrent gestures to speech and speech to gestures in Django.
Bineet et al. [11] used Krawtchouk moment-based shape features to understand
the different shapes of hand gestures. Emely et al. [12] demonstrated the system that
recognizes manual gestures, facial expressions and other markers, which uses action
units (AUs) recognition architecture that merges SqueezeNet and features based on
geometry. Fakhar et al. [2] utilized DWT, DCT and HOG for unique key frames
of video extraction. SVM, KVM, bagged tree and boosted tree ensemble method
are used for classiﬁcation of hand gestures. Jayesh and Jyothi [13] employed an
algorithm designed using Microsoft Kinect Sensor to identify and segment the hand
region. CNN implemented to develop features from sign language automatically.

An Investigation and Observational Remarks on Conventional Sign …
451
Jayesh et al. [14] used supervised machine learning for extracting and training the
image features. Oriented fast and rotated brief (ORB) is used for comparing the
images with various classiﬁcation techniques to gain optimum results.
Kasian and Hassan [15] explained sign language translation can be achieve by
machine learning techniques. By using combined 5 × 2cv F test, the performance
of CNN and SVM is compared through image recognition by converting the sign
language. Lean et al. [7] demonstrated convolutional neural network used to classify
the images, where Keras is used to train the images. Mahesh [8] has made detailed
study on eigenvalues and eigenvectors which are extracted using linear discriminant
analysis (LDA) algorithm for gesture recognition. Mitali et al. [16] explained several
machine learning algorithm techniques are used in ISLR system, where RF algo-
rithm gives highest efﬁciency out of six machine learning algorithms. Mohammad
and Mehreen [3] designed HSV colour algorithm to identify hand gestures with
background black; CNN for training and classifying the images.
Neha et al. [17] constructed NAO humanoid robot is used to communicate with
deaf person, which extracts uniform shape feature of hand gestures using wavelet
descriptorandclassifyingthosegesturesusingpossibilitytheory,whicharecombined
for generating text sentences. These sentences are further converted to speech using
NAO robot. Qazi and Mohammad [18] described that deep learning is a subset
of machine learning used to ﬁnd hand gestures in a collection of video frames.
VGG-16 and RNN-LSTM model is used to recognize the sign language. Radha
et al. [4] explained linear kernel multiclass SVM algorithm used to differentiate
the one-handed and two-handed alphabets gestures. Rajyashree et al. [19] explained
Raspberry Pi identiﬁes and converts the sign languages into text and audio sounds.
Sharma et al. [5] used transfer learning algorithm such as Trbaggboost and conven-
tional machine learning algorithms such as RF, SVM, decision trees as main learners.
The outcomes for distinguish of signs by Trbaggboost, yields highest accuracy
includingthelabelleddata.Sharmaetal.[20]collecteddatausing6degreeoffreedom
inertial measurement units (IMUs) on both hands. Deep transfer learning consists of
CNN, two (Bi-LSTM) layers and CTC to sentence recognition.
Sakshi and Sukhwinder [21] developed a computer-vision-based model which
uses CNN for feature extraction and classiﬁcation of gestures. Sharad et al. [6]
designed Arduino circuit boards and Texas instrumentation circuitry that are used
to recognize sign language. Raghuveera et al. [22] demonstrated that a system uses
Microsoft Kinect with RGB images to capture the gestures with ﬁnger spelling,
double and single-handed signs. To extract the hand features, HOG and local binary
patterns are used.
Mahesh[8]demonstratedthesignlanguagerecognitionprocessasshowninFig.6.
From this, we can learn that many technologies are used to identify the sign
languages and to convert them, so that it will facilitate the communication among
dumb and deaf people with normal people.

452
T. U. Khan and M. R. Dileep
Fig. 6 Sign language recognition process
3
Comparative Analysis
The research work has been done on different sign languages with different tech-
nologies, which results in different accuracies. The accuracy of the sign language
recognition systems using CNN is 99.3%, CNN with computer vision is 90%, CNN
with recursive neural network is 92%, CNN with SVM is 96%, deep learning is
98%, deep neural network is 93.67%, Trbaggboost is 97.04%, facial action is 88%
and key-frame selection is 97.5%. This comparative analysis is explained in detail.
3.1
Efﬁciency Comparisons with Various Parameters
Abdelbasset et al. [9] concluded the results achieved with accuracy of 92% by
2DCRNN and 99% by 3DCNN through the fourfold cross-validation technique,
F1-score and AUROC. Ashish et al. [10] designed the model with 98.52% accuracy
for one-hand and 97% accuracy for two-hand gestures. Emely et al. [12] applied the
model which achieved an accuracy of 88% for 119 classes, with the combination of
art of gesture recognition.
Fakhar et al. [2] obtained accuracy of 95.6% on 100 common words with overall
accuracy of 97.5% on 37 Urdu alphabets. Jayesh and Jyothi [13] developed the
system that achieves 99.3% of accuracy to recognize the gestures. Jayesh et al. [14]
achieved 93.26% of recognition accuracy by ORB tuning with KNN classiﬁcation.
Kasian and Hassan [15] valued the system, in which CNN scored 96% in three
parameters such as precision, accuracy and recall, while SVM got same rate in
precision but poor on accuracy and recall parameters. Lean et al. [7] analysed that
system has achieved a testing accuracy of 93.67% on an average, of which alphabet
recognition accuracy is 90.04%, number recognition accuracy is 93.44% and static
word recognition accuracy is 97.52%.
Mitali et al. [16] established that RF machine learning algorithm has given the
maximum accuracy of 98.44% out of six machine learning algorithms. Mohammad
and Mehreen [3], system has achieved above 90% of accuracy. Qazi and Mohammad

An Investigation and Observational Remarks on Conventional Sign …
453
[18] evolved the model that achieved 98% accuracy on dataset of sign language hand
gestures. Radha et al. [4] designed a model with 95% accuracy. Trained linear kernel
multiclass SVM models were used to distinguish the one-handed alphabets with 56%
accuracy and two-handed alphabets with 60% accuracy.
Sharma et al. [5] admitted that from the new subject when two observations of
labelled data are included with existing system’s training data, we get an average
accuracies of TrAdaboost is 71.07%, TrResampling is 72.92%, TrBagg is 76.10%
and RF is 76.79% for classiﬁcations. If the number of labelled data is same, then
Trbaggboost yields 80.44% of an average classiﬁcation accuracy. If we increase the
number of labelled data, then Trbaggboost yields up to 97.04% of classiﬁcation
accuracy.
Sharma et al. [20] demonstrated that when the number of observations reduced
from 10 to just 3 of each sentence available for training the model, where noted
degradation in an average is 54% of accuracies obtained without transfer learning.
But, with deep transfer learning approach the degradation will be reduced up to
11.5%. Sakshi and Sukhwinder [21] achieved accuracies of 92.43%, 88.01% and
99.52% by using three sets of data, respectively. The terms like recall, precision,
time consumption and f-score are used to evaluate the efﬁciency of the method.
The proposed method has achieved good results comparing to the existing method.
Raghuveera et al. [22] achieved an accuracy of 100% on 9, A, F, G, H, N, P signs
and 71.85% as an average accuracy improved by the SVM trained three feature
classiﬁers.
Lean et al. [7] discussed about calculation of accuracy by using the formula
Accuracy rate = Total nos. of correct recognized letters from users
(Total no. of users)(No. of Trails)
They calculated the accuracy rate of each letter by using the above formula, where
the total number of the correctly recognized letters from all the users from all the
trials was totaled and divided by the total number of samples, which is the number
of users (30) multiplied by the number of trials as shown in Table 1.
4
Observations and Discussions
The research to develop the system for sign language recognition has been limited to
alphabets, numbers and words. It has been translated from sign language to text or
viceversa.Eachsystemhasbeenobservedanddiscussedbycomparingtheaccuracies
developed based on different methodologies as shown in Table 2. The observation
extended to different sign languages with accuracies as shown in Table 3. From this,
we can ﬁnd the efﬁciencies of the systems.

454
T. U. Khan and M. R. Dileep
Table 1 Letter recognition accuracy
Letter
Correctly recognized
gestures
Incorrect recognized
gestures
Accuracy (%)
Ave. time (s)
A
90
0
100
2.02
B
82
8
91.11
4.01
C
90
0
100
2.2
D
90
0
100
2.46
E
87
3
96.67
3.59
F
84
6
93.33
4.95
G
89
1
98.89
2.85
H
76
14
84.44
5.39
I
85
5
94.44
3.37
J
81
9
90
4.57
K
85
5
94.44
4.06
L
89
1
98.89
2.38
M
74
16
82.22
5.98
N
81
9
90
3.92
O
81
9
90
3.62
P
78
12
86.67
4.97
Q
86
4
95.56
3.76
R
71
19
78.89
6.24
S
78
12
86.67
4.6
T
67
23
74.44
7.62
U
77
13
85.56
5.11
V
76
14
84.44
5.07
W
87
3
96.67
2.46
X
78
12
86.67
4.98
Y
84
6
93.33
3.5
Z
81
9
67.78
8.31
Overall rating
90.04
4.31
4.1
Comparison of an Accuracy Based on Different Sign
Languages
The accuracies of the different methods and the different languages are shown in
Figs. 7 and 8, respectively.

An Investigation and Observational Remarks on Conventional Sign …
455
Table 2 Comparison of accuracies based on different methodologies
Author
Method
Accuracy (%)
Publication year
1
CNN, recursive neural network
92
2021
3
Deep neural network
98.52
2020
5
Facial action
88
2021
6
Key-frame selection
97.5
2020
7
CNN
99.3
2020
8
Kinect sensor, ORB, KNN
93.26
2020
9
SVM, CNN
96
2021
10
Deep learning-CNN and Keras
93.67
2019
12
Machine learning
98.44
2021
13
3 layers CNN and computer vision
90
2020
15
Deep learning
98
2021
16
Machine learning-multiclass SVM
95
2020
18
Trbaggboost
97.04
2020
19
Deep transfer learning
54
2021
20
Deep learning
92.43
2021
22
Microsoft Kinect
71.85
2020
Table 3 Comparison of
accuracies based on different
sign languages
Sign language
Accuracy (%)
Indian
98.52
American
93.67
Tanzanian
96
Arabic
92
Pakistan
97.5
Brazilian
88
5
Proposed Method
Deep feed forward network concept called multilayer perceptrons (MLPs) will be
used for sign recognition. The ﬂowchart of a proposed method to recognize sign
language is shown in Fig. 9.
Image Acquisition
This is the ﬁrst step of the process. It can be achieved by using web camera.
Image Tracking
Image preprocessing will be performed to improvise the image for the further process
like image enhancement, ﬁltering, smoothing, sharpening and compression.

456
T. U. Khan and M. R. Dileep
0.00%
20.00%
40.00%
60.00%
80.00%
100.00%
120.00%
CNN & Keras
Microsoft Kinect
CNN & CV
ORB, KNN
Multiclass SVM
Trbaggboost
Key Frame Selection
CNN
Deep Neural Network
Deep Transfer Learning
Facial Action
CNN , RNN
Deep Learning
SVM , CNN
Deep Learning
Machine Learning
2019202020202020202020202020202020202021202120212021202120212021
Accuracy Comparison
Fig. 7 Graph representation of accuracies comparison
80.00%
85.00%
90.00%
95.00%
100.00%
Indian Sign
Language
American
Sign
Language
Tanzanian
Sign
Language
Arabic Sign
Language
Pakistan
Sign
Language
Brazilian
Sign
Language
Accuracy
Fig. 8 Graph of accuracies of different sign languages
Fig. 9 Block diagram of proposed system
Feature Extraction
There are mainly two types of feature extraction methods are contour-based shape
recognition and region-based shape recognition popularly used in sign recognition.

An Investigation and Observational Remarks on Conventional Sign …
457
Fig. 10 Multilayer perceptrons
Image segmentation, morphology, object representation and description are used to
extract features of an image.
Sign Recognition
Multilayer perceptrons is a deep feedforward neural network with multiple layers of
perceptrons that have activation functions such as, ReLu, sigmoid functions and tanh.
It consists of input layers, output layers and hidden layers which help to recognize
the images as shown in Fig. 10.
MSE loss function is evaluated on the whole training set by using the below
formula, for the given function f (x, θ) with the target function f *(x)
J(θ) = 1
4

x∈X

f ∗(x) −f (x; θ)
2.
The proposed system would perform with 91% of accuracy with limitations of
datasets on different sign languages.
6
Conclusion
Several efforts have been made to develop the system for sign language recogni-
tion with improving efﬁciencies by using different technologies on different sign
languages.
Only alphabets and static signs were classiﬁed by the sign language recognition
system. It has been motivating towards the system recognizing the dynamic gestures.
Additionally, researchers are ﬁnding the large database of different sign language
signs. Researchers are working on their own database with small vocabulary. There
is a deﬁciency of large database of sign languages in some of the countries. The
classiﬁcation methods for recognize the signs differ from one researcher to another.
It is still subjective for comparing one method to another for the researchers by using
their own innovative ideas and limitations to identify the sign languages. In most
of the counties, there is a variation of sign languages due to variation in gestures
and grammar. So it is difﬁcult to the researcher to have straightforward comparison

458
T. U. Khan and M. R. Dileep
between different approaches using different technologies. But still we have to do
investigation for developing more efﬁcient systems with emerging technologies. This
system can be used in the schools, colleges, ofﬁces and public places. It facilitates the
communication between dumb and deaf person and normal person more efﬁciently.
It increases teaching/learning capability of speech and hearing impaired person, so
that they can easily communicate with the society and live a better life in future.
7
Future Scope
By using current advanced technologies, we can improve the efﬁciencies of current
systems and explore to different sign languages. It can be extended to conversion
of sign language to oral language or vice versa, to improve the communication
between general person and speech and hearing impaired person. The sign language
recognition system that can translate sign language to text, sign language to audio,
audio to sign language, text to sign language. This system helps to communicate
with speech and hearing impaired person in public places like airport, railway station,
hospital, police station, education, court, government ofﬁce; and to handle the devices
like smart television, smart phone, computer, laptop and tablet by implementing
advanced technologies on different sign languages. The mobile applications, desktop
applications and web applications could be developed for easy communication of
speech and hearing impaired person in public places.
References
1. Ajay S, Potluri A, George SM, Gaurav R, Anusri S (2021) Indian sign language recognition
using random forest classiﬁer
2. Mangla FU, Bashir A, Lali I, Bukhari AC, Shahzad B (2020) A novel key-frame selection-based
sign language recognition framework for the video data
3. Walizad ME, Hurroo M (2020) Sign language recognition system using convolutional neural
network and computer vision
4. Shirbhate RS, Shinde VD, Metkari SA, Borkar PU, Khandge MA (2020) Sign language
recognition using machine learning algorithm
5. Sharma S, Gupta R, Kumar A (2020) Trbaggboost: an ensemble-based transfer learning method
applied to Indian sign language recognition
6. Agarwal S, Patel F, Chaturvedi P, Asha S (2018) A novel approach for communication among
blind, deaf and dumb people
7. Tolentino LKS, Juan ROS, Thio-ac AC, Pamahoy MAB, Forteza JRR, Garcia XJO (2019)
Static sign language recognition using deep learning
8. Mahesh Kumar NB (2018) Conversion of sign language into text
9. Boukdir A, Benaddy M, Ellahyani A, Meslouhi OE, Kardouchi M (2021) Isolated video-based
Arabic sign language recognition using convolutional and recursive neural networks
10. Sharma A, Sharma N, Saxena Y, Singh A, Sadhya D (2020) Benchmarking deep neural network
approaches for Indian sign language recognition
11. Kaur B, Joshi G, Vig R (2017) Indian sign language recognition using Krawtchouk moment-
based local features

An Investigation and Observational Remarks on Conventional Sign …
459
12. da Silva EP, Costa PD, Kumada KM, De Martino JM (2021) Facial action unit detection
methodology with application in Brazilian sign language recognition
13. Gangrade J, Bharti J (2020) Vision-based hand gesture recognition for Indian sign language
using convolution neural network
14. Gangrade J, Bharti J, Mulye A (2020) Recognition of Indian sign language using ORB with
bag of visual words by Kinect sensor
15. MyagilaK,KilavoH(2021)AcomparativestudyonperformanceofSVMandCNNinTanzania
sign language translation using image recognition
16. Potnis M, Raul D, Inamdar M (2021) Recognition of Indian sign language using machine
learning algorithms
17. Baranwal N, Singh AK, Nandi GC (2017) Development of a framework for human–robot
interactions with Indian sign language using possibility theory
18. Areeb QM, Nadeem M (2021) Deep learning based hand gesture recognition for emergency
situation: a study on Indian sign language
19. Rajyashree, Deepak O, Rengaswamy N, Vishal KS (2019) Communication assistant for deaf,
dumb and blind
20. Sharma S, Gupta R, Kumar A (2021) Continuous sign language recognition using isolated
signs data and deep transfer learning
21. Sharma S, Singh S (2021) Recognition of Indian sign language (ISL) using deep learning model
22. Raghuveera T, Deepthi R, Mangalashri R, Akshaya R (2020) A depth-based Indian sign
language recognition using Microsoft Kinect

Exploratory Project of Digital Twin
Technology in Cyber-Physical Systems
Irony Nunes de Oliveira, Hanameel Carlos Vieira Gomes,
Kelipys da Silva Firmino, Antonio Eduardo Carrilho da Cunha,
and Cícero Roberto Garcez
Abstract We have arrived at the age of Industry 4.0 in the timeline of technological
evolution. Artiﬁcial intelligence, robotics, Internet of Things (IoT), cloud computing,
cyber-physical systems, and digital twins are all a part of this era. Digital twins are
used to perform simulations, analysis, and decision-making, as well as creating indus-
trial optimization scenarios and malicious attacks on major global entities. This study
focuses on the analysis of the cyber-security of Cyber-physical Systems Laboratory
(LaSC), located within the Instituto Militar de Engenharia (IME) and also to other
institutions that make use of its high technological capacity concerning the applica-
tion of digital twins in cyber-physical systems through a system engineering-based
experimental analysis.
Keywords Digital twin · Cyber-physical system · Industry 4.0 · Cybernetics
I. N. de Oliveira (B) · H. C. V. Gomes · K. da Silva Firmino · A. E. C. da Cunha · C. R. Garcez
Laboratório de Segurança Cibernética de Sistemas Ciberfísicos, Instituto Militar de Engenharia,
Praça General Tibúrcio no 80, Rio de Janeiro (RJ), Brazil
e-mail: nunes.irony@ime.eb.br
H. C. V. Gomes
e-mail: gomes.hanameel@ime.eb.br
K. da Silva Firmino
e-mail: kelipys.silva@ime.eb.br
A. E. C. da Cunha
e-mail: carrilho@ime.eb.br
C. R. Garcez
e-mail: garcez@ime.eb.br
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_34
461

462
I. N. de Oliveira et al.
1
Introduction
The First Industrial Revolution began at the end of the eighteenth century. It has
the characteristic of bringing technologies such as steam engine, spinneret, spin-
ning machine, and the process of reﬁning iron, which has to be used in metal-
lurgy developed by Henry cut. In summary, this period replaced manual tools with
machines.
The Second Industrial Revolution began around a hundred years later. The devel-
opment of electricity marked it, the expansion of the telegraph, the manufacturing
of chemical products guided by science, the emergence of the combustion engine,
and the invention of the automobile and the plane, technologies that permeated
industrialization worldwide [1].
The Third Industrial Revolution appeared in the twentieth century as strengths
advance in the ﬁeld of electronics, in the development of computers for personal use,
robots in production lines, and the emergence of the world wide web, the Internet.
At this point in history, the works people once did now have robots [1].
The beginning of the Fourth Industrial Revolution comes from the introduction
of Internet of Things (IoT) in manufacturing environments. Companies worldwide
are building their machines, storage systems, and production facilities with cyber-
physical systems (CPS). Making an intelligent system appears in which consumers,
factories, and devices form a single dynamic and organized network based on
information available on the web brings the philosophy of innovation into the
industry.
Cyber-physical systems are computational and collaborative systems whose oper-
ations are monitored, coordinated, controlled, and integrated by communication and
computing cores. Just as the Internet has transformed the way humans interact with
each other, cyber-physical systems will change how we interact with the physical
world around us. Many signiﬁcant challenges are in economically vital domains such
as transportation, healthcare, manufacturing, agriculture, livestock, energy, defense,
construction, and others.
Nowadays, the best decisions are made based on digitizing and treating large
volumes of data. One of the technologies that help in making the best decisions
is the digital twin. In general, a digital twin is a model that emulates in real-time
the behavior of a given physical entity for observations, simulations, analyses, and
decision-making [2].
With this context, this work brings, with a broader view, an exploratory project
about the use of digital twins in cyber-physical systems. The study focuses on using
such technologies by the Cybernetic Security Laboratory of Cyber-physical Systems
(LaSC), located at the Instituto Militar de Engenharia (IME).

ExploratoryProject ofDigital TwinTechnologyinCyber-Physical Systems
463
2
Conceptual Foundation
This chapter presents the main deﬁnitions and concepts involved with digital twin
technology and cyber-physical systems. From the understanding that the exploratory
approach of digital twin technology in cyber-physical systems is a system of systems,
it is initially necessary to consider systems engineering.
2.1
System Engineering
Systems engineering consists of an interdisciplinary approach to mastering the tech-
nical and managerial effort required to transform a set of stakeholder needs and
expectations, and constraints from a problem into a solution and the support of this
solution during its life cycle, which comprises from design to disposal [3]. It is not the
only deﬁnition of systems engineering, but it agrees with the deﬁnition given by the
International Council on Systems Engineering (INCOSE): System engineering is a
multidisciplinary and integrative approach that enables the design, use, and closure of
successful complex systems, using system principles and concepts and management,
scientiﬁc and technological methods [4].
INCOSE is a non-proﬁt organization created to develop and disseminate trans-
disciplinary principles and practices that allow successful systems operation.
Connecting systems engineering professionals with educational, networking, and
career advancement opportunities aimed at developing the global community of
systems engineers and systems approaches to problems based on the conception of
the work [4].
The relationship between systems, the need for models and digital representations
of physical products, the dawn of Industry 4.0 and society 5.0, as well as the growth
of cybernetics and intelligent systems [4] all this set gives rise in engineering to the
need for tools capable of better responding to such demands. Systems engineering
is, in this context, adding all these capacities.
Through the Uniﬁed Modeling Language (UML), software engineering provides a
graphical organization of several essential points for understanding a system through
the elaboration of standardized graphic diagrams capable of demonstrating impor-
tant characteristics of numerous system attributes. Originating from the UML came
the Systems Modeling Language (SysML). SysML is a language whose graphical
representation is essential in translating systems engineering based on model-based
systems engineering (MBSE) models. SysML uses diagrams and tables to express
system information through a standard set of nine types of diagrams, as shown in
Fig. 1, which can organize information in a complex system.
Given the above, systems engineering provides this research with tools capable
of assisting the preparation, design, and presentation. The following chapters and
sections of this work will present the SysML diagrams used to understand and
explore digital twin technology in cyber-physical systems. SysML allows to express

464
I. N. de Oliveira et al.
Fig. 1 SysML metadiagram (Source [5])
the requirements, structure, and behavior of the system of systems using standard-
ized images and language. As cyber-physical systems combine more than one engi-
neering discipline, SysML seems to be a proper means of modeling complex systems
and supports an interdisciplinary engineering approach. A better organization of
the research, knowledge, and management domains, as well as the presentation
of diagrams related to research management, technical, and scientiﬁc knowledge
domains, as well as the respective diagrams, will be developed in the continuation
of the conceptual foundation and in Chap. 3, which deals with the broad vision of
LaSC.
2.2
Digital Twin
As every action reacts, there is at least one motivating event for evolution until the
solution is developed. As each action reacts, there is at least one motivating event
for evolution until the solution is developed. It is ideal for addressing issues such
as the absence of machines due to maintenance, a lack of cooling, a lack of raw
materials, an interruption in the supply of electricity, and process monitoring, which
cansometimesdelayproduction.Theindustryispromptedvariousadverseconditions
to reduce costs in its processes.
Through technology, the industry received the willingness to make industrial
processes viable and optimize production. According to the company Effortech,
pioneer in developing IoT solutions, the digital transformation took place in the
1960s by National Aeronautics and Space Administration (NASA), which created a
digital replica of Apollo 13.
However, after all, what is the digital twin? According to [6] in the book Digital
Twin: Possibilities of the new Digital twin technology, the digital twin is, by deﬁ-
nition, a virtual entity identical to an equipment or process of an industry. Another
deﬁnition is from general electric (GE), which deﬁnes the digital twin as the software

ExploratoryProject ofDigital TwinTechnologyinCyber-Physical Systems
465
Fig. 2 Digital twin of an
electric car (Source [7])
representation of an asset, system, or physical process designed to detect, prevent,
predict, and optimize through analysis in real-time to deliver business value.
With the digital twin, a real-time simulation in the natural environment with the
project variables is now possible. The application is not only restricted to industry,
as at Itaipu Binacional with its virtualized environment at the Instituto Militar de
Engenharia (IME), but also in the daily lives of human beings on the factory ﬂoor,
such as a BMW ergonomics project for the assembly line. The creation of Ericsson
around a model to identify the best locations focused on installing 5G technology.
The Brazilian startup MedRoom helped health professionals with 3D technology in
the separation of conjoined twins and continues to be active in the market for actual
training purposes virtual, among other projects. At [7], according to the website, the
multinationalbelievesthattheuseofthedigitaltwincreatesaconsistentimprovement
in effectiveness, minimizes failure rates, shortens development cycles, and opens up
new business opportunities. In other words, it creates a lasting competitive advantage.
Figure 2 illustrates that young electromechanical engineers designed, simulated,
and manufactured their new electric car in two years, thanks to the digital twin.
Figure 3 highlights, in the construction of the digital twin, the understanding of
the block diagram with a ﬁlled diamond that indicates that every structure will carry
resources, technologies, and infrastructures, which will compose the digital twin.
2.3
Cyber-Physical Systems
To discuss cyber-physical systems, it is necessary to go back in time and involve
the concepts of traditional industry and the principle of the Internet of Things (IoT).
With the artisans, the manufacturer sought constant improvements in processes with
the labor of workers and machines to expand its production. Consequently, proﬁts
increased, and production methods became, at the time, more complex but more efﬁ-
cient with the use of automation and control. Thus, starting from traditional methods,
development such as motorize, mass production, digitalization, and consequently, the
Fourth Industrial Revolution—Industry 4.0, has been provided over the years.

466
I. N. de Oliveira et al.
Fig. 3 Digital twin technology block diagram (Source The Authors, 2022)
This concept ﬁrst appeared in 2011, cited by the German government as shown
on the website of the State University of Maranhão (UEMA, 2018). In 2015, the
(Reference Architectural Model for Industries—RAMI 4.0), created by engineers
and presented at the Hannover World Fair in Germany, was mentioned, considered
the new concept of Industry 4.0 until today.
In 1999, incredibly before the emergence of the concept of Industry 4.0, the term
Internet of Things (IoT) was used by the British Kevin Ashton in his presentation to
call the attention of a company about the Radio Frequency Identiﬁcation Tag (RFID)
[8].
The entry of IoT in Industry 4.0 made possible the intelligent connection in real-
time of CEOs, Directors, Managers, and Distributors, keeping them aware of the
productions carried out on the factory ﬂoor without their permanence in loco. There-
fore, the Internet of Things (IoT) consists of the connection between a network of
physical objects, environments, vehicles, and machines through electronic devices,
allowing the collection and exchange of information [9].
Still, reference [9] states that a cyber-physical system integrates computing
and physical manufacturing processes. The relationship between communication
networks, IoT sensors, actuators, computing, and storage deﬁnes cyber-physical
systems. This interaction provides the reality of the physical world in digital
environments.
In this research, a willingness to associate with the industrial revolution 4.0, efﬁ-
ciency, effectiveness, and effectiveness was perceived, which establishes a massive
motivation for integrating cyber-physical systems, big data, and artiﬁcial intelligence
(AI), making productions highly productive and qualitative [9].

ExploratoryProject ofDigital TwinTechnologyinCyber-Physical Systems
467
2.4
Cybernetics and Simulations
The evolution of science considers cybernetics as an evolution, where to know some-
thing is to produce a model of how the object or system works. To know is to simulate
a particular form of a model that consists of reproducing the functioning of a system
[10]. Nevertheless, cybernetics deals with information, a general science of particular
simulation systems [11].
In 1948, Nobert Wiener published a book entitled “Cybernetics: the control and
communication in the animal and the machine.” This book presents ideas that start
from the hypothesis to the way systems respond to messages from the environment,
which is equivalent and reducible to mathematical models [12].
Cybernetics attempts to understand the communication and control of machines,
living beings, and social groups through electronic devices [13]. It focuses on how
(digital, mechanical, or biological) information is processed and accept changes or
can be changed to perform the assigned tasks in a better way.
Cybernetics has inﬂuenced many scientiﬁc ﬁelds, including the study of humans.
Several scientists were inspired to consider computer technology as an extension of
human capabilities. The vast area of cybernetics includes the study of language, forms
of communication, messages between humans and between humans and machines,
modeling of the man–machine prototype, nervous system, and others.
Computers represent the world in machines and signiﬁcantly changed human’s
perspective on technology. The development of Cybernetics led scientists to develop
new mathematical models.
In a more succinct deﬁnition, a communication interaction between human and
machine characterizes a cybernetic event. Any natural or suspected unauthorized
access to the system, such as electronic attacks or violation of privacy, including, for
example, denial of service attack (DoS or DDoS); cyber-terrorism; hacker attack;
Trojan Horse; phishing attack; man-in-the-middle attack (MITM); application layer
attack; compromised critical attack; malware (including spyware or ransomware) or
computer virus infection; and cyber-attack, also characterizes a cybernetic event.
After discussing cybernetics and cybernetic events, this study proceeds to
discuss simulation, speciﬁcally real-time simulation, which is the technology used
in a digital twin platform and the representation of a cyber-physical system.
Simulation is one of the most reliable tools for system design and operation
analysis. It enables the system’s operation to be accelerated over time. It allows for the
prediction of the almost unavoidable errors that occur when implementing a natural
system, while saving economic resources by eliminating the need to build prototypes
for testing. Simulation is useful at any stage of a product’s or system’s lifecycle,
from problem analysis and requirements deﬁnition to design, implementation, and
operation [14]. It is critical to conduct a simulation study before implementing the
existing system. Real-time simulation applied to electrical power systems considers
some aspects that justify its use, they are:
• A controlled environment (laboratory) for realistic simulation;

468
I. N. de Oliveira et al.
• Absolutetestcontrol,protection,ormonitoringequipmentusedinelectricalpower
systems; and
• Operations training for users of the electrical power system.
Thus, the simulation of electrical power systems plays a strategic role in the
planning and operation of these systems and in designing the equipment. Network
operators, equipment manufacturers, and researchers use a broad portfolio of simu-
lation tools to carry out studies. These studies allow investigation of the impacts
caused by connecting a new subsystem to the network or by adjusting the parameters
of existing equipment to ensure that the system’s reliability, efﬁciency, effectiveness,
and effectiveness have not deteriorated [15].
Simulation in real-time means that the time executed in a simulation step corre-
sponds precisely to the time of the operation simulated in real-time. That is, the
real-time simulation imposes restrictions on the simulated model so that the execu-
tion time of each step of the simulation must be less than or equal to the period of
the real-time operation to guarantee synchronization between the simulation and the
actual simulated event [16].
Figure 4 illustrates two situations that can arise depending on the time required
for the simulation platform to complete the calculation of the state outputs for each
time step:
1. If the execution time for the system simulation is less than or equal to the selected
time step, the simulation is considered in real-time; and
2. Iftheexecutiontimeismoresigniﬁcantthanitstimestepsizeforoneormore-time
steps, overruns occur, and the simulation is said to be ofﬂine [16].
Fig. 4 Real-time simulation and ofﬂine simulation. a Real-time simulation. b Ofﬂine simulation
(Source [16])

ExploratoryProject ofDigital TwinTechnologyinCyber-Physical Systems
469
The continuous evolution of computing technologies allowed, in the 1990s, the
development of real-time digital simulators, also known as real-time digital simu-
lator (RTDS). An RTDS of an electrical power system reproduces output waveforms
(voltage or current) with the desired accuracy, representing the behavior of the simu-
lated natural power system. To achieve this goal, an RTDS needs to solve the simu-
lated model’s equations of state in one execution time step within the same time
frame as a real-world clock. In this way, the RTDS produces outputs in discrete time
intervals, where it is possible to calculate the system states using a ﬁxed time step
[16].
Therefore,RTDSisatechniqueforthetransientsimulationofpowersystemsusing
a digital computer time-domain solution. It performs physical protection, control,
and monitoring equipment tests in a closed loop through hardware and software.
The RTDS is the hardware, and the software can be, for example, the RSCAD. It is
possible to model the representative systems by taking advantage of the component
models available in the RSCAD software tool library through a graphical interface
and simulating on a hardware platform (RTDS) using parallel computing [16].
Real-time digital simulation applied to the power systems domain can be classiﬁed
as [16]:
1. Fully digital real-time simulation (model-in-the-loop, software-in-the-loop and
processor-in-the-loop); and
2. Real-time simulation with a simple interface (hardware-in-the-loop).
The primary motivation for using real-time simulation, as mentioned at the begin-
ningofthesection,istotestactualequipmentinacontrolledenvironment(laboratory)
for realistic simulations of simulated electrical power systems, but representative of
the system that connects the hardware under test. The name of this conﬁguration
is hardware-in-the-loop (HIL) in the real world. In this exploratory project, we will
only address the hardware-in-the-loop technique, as LaSC uses it.
In the simulation environment of electric power systems, the HIL conﬁguration
uses the insertion of actual equipment in the simulation information ﬂow, where the
performance of this equipment depends on the signals received from the simulation,
as well as the simulation data are inﬂuenced by the real equipment sign. Figure 5
represents the basic schematic of a real-time HIL simulation test.
Fig. 5 Basic scheme of HIL systems (Source [15])

470
I. N. de Oliveira et al.
Fig. 6 CHIL and PHIL basics concepts (Source [16])
There are two types of HIL simulations: controller hardware-in-the-loop (CHIL)
and power hardware-in-the-loop (PHIL). In the CHIL model, the real-time model
represents the entire power system, and the hardware under test (HUT) is control
equipment where there is no power ﬂow. In the PHIL conﬁguration, the HUT is
a part of the electrical power system, which exchanges power with the modeled
electrical system. As the RTDS is an electronic device, the interface between the
simulated model and the HUT uses power ampliﬁers in the PHIL conﬁguration.
Figure 6 illustrates the basic concepts of CHIL and PHIL [16].
3
An Overview of LaSC
The Cybernetic Security Laboratory of Cyber-physical Systems (LaSC) has state-of-
the-art technology to add to the industrial needs of national and international compa-
nies, comprising the sectors that cover technical-operational behavior according to
market demand.
According to the required project, building interactive virtual platforms in real-
time is possible by linking their physical structure, thus giving rise to the simulation
model of cybernetic events and establishing the digital twin concept. Now available
for testing, mainly with internal and external malware attacks. There is also the
possibility of changing the communication networks, databases, operating systems,
communication ports, and mechanisms by inserting or removing them according to
the demand for the feasibility study, regardless of academic or professional nature.
LaSC has conceived within the scope of a Tripartite Partnership Agreement signed
between ITAIPU Binacional, the Brazilian Army Command, through its Department
of Science and Technology, and the ITAIPU-Brasil Technological Park Foundation.

ExploratoryProject ofDigital TwinTechnologyinCyber-Physical Systems
471
3.1
LaSC Structure
The Cybernetic Security Laboratory of Cyber-physical Systems (LaSC) has a divided
structure according to the ANSI/ISA-95 technical standard. In composition, the
model is composed as shown in Fig. 7.
LaSC has an application server for developing the graphical interface and
programming objects through OpenCIM Manager. As well as, a database server,
ethernet, USB, and serial data communication networks for integrating the commu-
nication between the mechanisms that make up the structure RFIDs, infrared
sensors, precision scanners, programmable logic controllers (PLCs), robotic arms,
and human–machine interface (HMI). The HMI, or computers for industrial use as
they are also known, aims to integrate man’s communication with the cyber-physical
system, making production intelligent.
In addition, as a preventive action to simulate the production environment,
the laboratory has intrusion sensors, which guarantee the safety of students and
professionals on the production line.
According to ISA-95, which structures the organization of automation internation-
ally, the digital twin interoperability layers are presented, considering the viability of
the physical skeleton of a laboratory concomitant with industrial construction. That
is, any project based on the concepts used in the composition of this research and its
development regarding cyber-security standards and the use of information security
policies. In layer 0, the physical structure is where the data transfer and simulation of
dynamic events occur. Layer one is the supervision and monitoring method, layer two
is the control of processes, and layer three is the set of all meshing for management
training, which establishes the execution of the concepts gathered in the development
of the project. In addition to cyber-security composition, to protect the database at
layer 0, there is also the failover server, a redundant server for application and the
database, to guarantee the production of large businesses. Figure 8 illustrates this
arrangement.
Fig. 7 LaSC general
conception (Source The
Authors, 2022)

472
I. N. de Oliveira et al.
Fig. 8 Structure of a laboratory, based on LaSC (Source The Authors, 2022)
Based on the structure of LaSC, it is possible to describe the behavior and perfor-
mance of the laboratory, with emphasis on the main functionalities. A use case can be
viewed and understood as a system utility performed through the interaction between
the system and its actors [17]. The use case diagram describes how the actors use the
system to reach a goal. Figure 9 illustrates each use case, represented by an ellipse,

ExploratoryProject ofDigital TwinTechnologyinCyber-Physical Systems
473
Fig. 9 LaSC use cases diagram (Source The Authors, 2022)
and describes a system behavior with interactions between actors. The user “Partner
Institutions” in Fig. 9 represents the external entities located in Fig. 11, namely:
“sector of research, development, and innovation,” “defense sector of the Brazilian
Army,” “opportunities,” and “electrical sector.”
Exploring the use case “testing equipment for cyber-security” shown in Fig. 9,
it is possible to trace a ﬂow of activities oriented toward studying and testing elec-
trical systems in cybernetic environments. Figure 10 shows a real-time hardware-
in-the-loop test and simulation plan of a stabilizer for an electrical power system
(PSS—power system stabilizer). The PSS acts to mitigate unwished electromechan-
ical oscillations in an electrical power system, making the system more stable. The
tests aim to evaluate the contribution of the PSS to the safety, performance, and
integrity of the electrical power system.
Based on the demands, the requirements are established, and the electric power
system model is designed. The functions of the electrical power system are repro-
duced through representation and modeling in software, such as RSCAD, which
operates together with the RTDS hardware. Before the hardware-in-the-loop simu-
lation, the modeling of the electric system is made together with the control system
programming, in this case, the PSS. As the stabilizer attenuates power and frequency
variations,itisnecessarytoprogramafrequencyreadingsystemandavoltagereading
interface to verify the correct performance of the stabilizer. In this ﬁrst stage of the
simulation plan, the PSS is non-commercial hardware used in benchtop testing.

474
I. N. de Oliveira et al.
Fig. 10 LaSC activities diagram (Source The Authors, 2022)
Fig. 11 Context diagram outline (Source The Authors, 2022)

ExploratoryProject ofDigital TwinTechnologyinCyber-Physical Systems
475
Next, a commercial PSS is programmed, once this PSS will be installed in the real
plant of the electrical power system. Non-commercial hardware PSS programming
can be done using software such as LabView together with RSCAD and RTDS. In
the implementation of the commercial PSS that will be installed in the real plant, the
programming depends on software compatible with the hardware of the commercial
PSS. After modeling the real plant in RSCAD and programming the control system
based on the commercial equipment that will be installed in the real plant, the elec-
trical power system operating parameters are entered to perform a closed-loop test
with the RTDS.
The organization of LaSC in Fig. 11 uses technological capabilities. According to
[18], technological capability is using specialized knowledge effectively. This ability
to use technical knowledge and skills not only in the improvement and development
of products and processes but also in the improvement of existing technologies,
in addition to generating new knowledge and skills in response to the competitive
business environment [19].
Thus, it is possible to say that technological capacity is a stock of resources based
on specialized knowledge, segmented into at least four components: technical and
physical systems (physical capital), expertise and qualiﬁcation of people (human
capital), organizational system (organizational capital), and products and services,
which represent the most visible part of technological capacity [20].
According to the structure noted throughout the research, it is possible to see in the
diagram of Fig. 11 that the laboratory comprises a set of technological resources and
utilities to be explored by educational institutions, governmental organizations, and
private companies as a laboratory. It also presents the defense sectors of the Brazilian
Army that interact with the multidisciplinary capacity of related exchanges, business
opportunities, and intellectual development.
3.2
Simulation of Cyber-Physical Events
The concepts of digital twin and Cyber-Physical Power System (CPPS) are relatively
new, and about which much is said within the context of digital transformation in
industries. The sectors that involve large critical infrastructures have beneﬁted from
the creation of Cyber-Physical Power System, such as the oil and gas industry and
electric power systems (generation, transmission, and distribution), among others.
Among the signiﬁcant challenges of CPPS technology, we can mention the urgent
need to protect data against threats and attacks. After all, cyber-connectivity broadens
the vulnerability surface of devices induced by network connectivity characteristics,
for instance.
In a large-scale Cyber-Physical Power System (CPPS), a cyberattack alters the
information ﬂow in the cyber-system, jeopardizing the secure operation of the
physical power system. This may occur in a cascading failure throughout the CPPS.

476
I. N. de Oliveira et al.
The function of cyber-security for monitoring, protection, and control purposes in
any organization with industrial secrets is to promote preventive actions such as simu-
lating cybernetic events and building defense mechanisms against attacks. In Brazil,
the Cyber-Defense Command (ComDCiber), a military organization subordinated to
the Brazilian Army, organizes the Cyber-Guardian Exercise (CGE) every year. The
CGE is a mega simulation of attacks on strategic National Defense infrastructures
such as energy, communication, and transport, among other sectors. Through the
simulation of cybernetic events, integrated response strategies are developed among
divisions to combat possible cybernetic threats. This action, through collaborative
action among the Armed Forces and civilians from academia and private companies,
develops simulation techniques to protect against cyber-threats.
It has been estimated that 63 different forms of advanced cyberattacks are being
developed for CPPSs to attack monitoring, protection, and control functions.
LaSC focuses on studies and analyzes in the ﬁeld of cyber-security of critical
industrial infrastructures subjected to real malware attacks. An example of an elec-
trical power system (EPS) comprises two environments, one electrical and the other
cybernetic, thus representing a cyber-physical system. Both simulated systems are
expected to be virtually connected through an encrypted Internet connection to
transfer simulated variables related to the electromechanical dynamics of the plants
in real-time, creating a co-simulation environment. In summary, the LaSC enables
simulations in controlled environments to test electrical and cybernetic equipment,
allowing operators to practice processes in the real world that do not bring risks to
people, equipment, or plants in general. This capability represents savings and safety
for the company and the operators, greater mastery and ability to operate the systems,
supporting the growing and complex decision-making quickly and accurately, and
preserving the safety of the industrial processes when facing cyber-threats.
Therefore, it is suggested for a simulation of cybernetic events the machine virtu-
alization in various operating systems to evaluate the damage caused by malicious
agents associated with different hardware and network architectures, applications,
and communications protocols. Thus, in a virtual environment for high-stress testing
with attacks and external interactions, without dismissing the internal ones, those
generated by actors in loco, it will be possible during the simulation to observe in an
advanced way, the behavior of malware, ransomware, and data exﬁltration, enabling
the development of defense mechanisms and protection preventive actions.
4
Conclusion
This work has performed an experimental analysis of the digital twin technology in
cyber-physical systems. Some SysML and UML architectures guided the preparation
of this article.
The diagrams listed were use cases, block diagrams, context diagrams, and activ-
ities diagrams. These diagrams make it possible to easily understand the operation
of the technology used in the Laboratory of Cyber-physical Systems (LaSC). This

ExploratoryProject ofDigital TwinTechnologyinCyber-Physical Systems
477
research study has met the initially proposed goal of realizing the digital twin tech-
nology in cyber-physical systems. In future, more detailed diagrams of use cases
will be created by showcasing the interactions carried out internally by the labora-
tory components. It will also be beneﬁcial to create a sequence diagram for project
implementation that shows more details, such as the dynamics between the demands
made by the laboratory and the methods used to meet those demands. Furthermore,
the metaverse could be investigated as an additional theme in digital twin technology
for future research proposal.
Complex systems are becoming a part of everyday life as technology advances.
As a result, it is critical to constantly research the methodologies used to evaluate,
test, and improve the increasingly common complex systems.
References
1. Cardoso RCM (2016) Caminhos da Manufatura—Uma Abordagem à Manufatura Digital.
[S.l.]: eBook Kindle
2. Alam M, Saddik A (2017) C2PS: a digital twin architecture reference model for the cloud-based
cyber-physical systems. IEEE Access 5:2050–2062
3. ISO;IEC;IEEE(2015)ISO/IEC/IEEE15288:2015Systemsandsoftwareengineering—system
life cycle processes. Genera
4. INCOSE. https://www.incose.org/
5. Abordagem: Engenharia de Sistemas na Concepção, Implementação e Gestão dos Projetos de
Sistemas de Engenharia (Matemática, Esboços, Planejamento). https://sites.google.com/ime.
eb.br/engsistemasturma2021/abordagens-esboço-matemática-planejamento-e-gestão
6. Iyer A (2017) Digital twin: possibilities of the new digital twin technology. Edição do Kindle
7. Siemens. https://www.siemens.com
8. Siebel TM (2021) Transformação Digital. Editora Alta Books, Rio de Janeiro, 2021. E-book.
ISBN 9788550816876
9. Almeida PSD (2019) Indústria 4.0—Princípios Básicos, Aplicabilidade e Implantação na Área
Industrial. Editora Saraiva, São Paulo, 2019. E-book. ISBN 9788536530451
10. Masaro L. https://ﬁles.cercomp.ufg.br/weby/up/410/o/Disserta%C3%A7%C3%A3o_-_Cib
ernetica__Ciencia_e_T%C3%A9cnica.pdf
11. Dupuy JP (1995) Nas Origens das Ciências Cognitivas. Tradução Roberto Leal Ferreira. Editora
UNESP, São Paulo
12. Wiener N (1961) Cybernetics: or control and communication in the animal and the machine.
Cambridge, Massachusetts. MIT Press. 1ª Ed: 1948. 2ª Ed
13. Chaves VHC (2015) A Revolução Cibernética: A Nova Cultura. XIX EBRAPEM
14. Lobão EC, Porto AJV (1999) Evolução das Técnicas de Simulação. PRODUÇÃO, vol 9, no 1,
pp 13–22, ABEPRO, Rio de Janeiro
15. Rueda OAS (2019) Simulador em Tempo Real Baseado na Integração de Módulo FPGA e
Cpus para Avaliação de Controladores Embarcados de Conversores Eletrônicos de Potência.
UFRJ, Rio de Janeiro
16. Faruque MDO et al (2015) Real-time simulation technologies for power systems design, testing,
and analysis. IEEE Power Energy Technol Syst J 2(2):63–73. https://doi.org/10.1109/JPETS.
2015.2427370
17. OMG Systems Modeling Language. https://sysml.org/.res/docs/specs/OMGSysML-v1.4-15-
06-03.pdf
18. Kim L (1999) Building technological capability for industrialization: analytical frameworks
and Korea´S experience. Oxford, vol 8, no 1

478
I. N. de Oliveira et al.
19. Jin J, Von ZM (2008) Technological capability development in China’s mobile phone industry.
Technovation 28(6):327–334
20. Figueiredo PN (2015) Gestão da Inovação: Conceitos, Métricas e Experiências de Empresas
No Brasil. 2ed. LTC, Rio de Janeiro

Abstractive Text Summarization
for Tamil Language Using m-T5
C. Saraswathi, V. Prinitha, and J. Briskilal
Abstract Summarizationistheactofreducingalongformoftexttoashorterversion
by lowering the length of the original text while retaining and keeping the summary’s
core and the informational parts which conveys the content’s meaning. Summarizing
lengthy papers by hand is difﬁcult and prone to inaccuracy. The exponential rise of
information and data has made automatic text summarization crucial. It leads to a
summary generated by a summarizing system that enables users to understand the
document’scontents.Abstractiveandextractivesummarizationarethetwocategories
into which summarization falls. We can see that there are not many automatic text
summarizers available for Indian languages. Our main goal in this direction is to
create an automatic abstractive text summarizer for Tamil using the m-T5 transformer
model. We have also used manual dataset of Tamil Kid’s stories for training and
testing.
Keywords Automatic text summarization · Abstractive summarization ·
Transformer model · m-T5 model · Tamil language
1
Introduction
The amount of textual content has signiﬁcantly increased in recent years, making
it a fantastic resource for information extraction and analysis from diverse sources.
It is necessary to summarize the information in order to quickly identify important
information from a huge text content. Text summarization has emerged as one of
the most crucial and useful tools among all contemporary technologies enabling
consumers to quickly comprehend a massive amount of information. The task of
C. Saraswathi (B) · V. Prinitha · J. Briskilal
Department of Computing Technologies, SRM Institute of Science and Technology,
Kattankulathur, Chengalpattu, Tamil Nadu 603203, India
e-mail: sc8272@srmist.edu.in
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_35
479

480
C. Saraswathi et al.
condensing a lengthy text’s contents into a manageable length is known as summa-
rization. Summarization is mostly used to condense the original text while main-
taining the essential informational components and meaning of the content. Auto-
matic text summarization system, one of the specialized data mining tools, aids in this
work by providing a brief summary of the material because manual summarization
of documents frequently involves errors. The exponential explosion of information
and data has made automatic text summarization a signiﬁcant boon. There are many
different summarizing methods available in natural language processing. Abstrac-
tive text summarization is a challenging problem in natural language processing.
Furthermore, little research has been conducted in regional tongues. In contrast to
other summarization techniques like the extractive one that reuses the words and
phrases from the original text, the abstractive text summarization method creates a
succinct and to the point summary of a lengthy text document. Here, none of the
words or sentences from the original paper are used.
Till now no pre-existing research works have been done for abstractive text
summarization for Tamil language. Only extractive approaches like semantic graph
method and centroid approaches are available for Tamil language which are more
human like rather than algorithmic and robotic. This is because they merely take
high priority sentences from the source text that is depicted in the summary instead
of creating new terms. This means that sentence coherence, consecutive sentence
relationships, and paragraph structure are not taken into account, which gives the
summary a robotic form. Our suggested effort aims to create an easily understandable
abstractive summary of a Tamil document. Tamil is a Dravidian language primarily
spoken in India. Tamil Nadu, an Indian state, as well as Pondicherry, a union territory,
both have Tamil as their ofﬁcial language. There are sizable populations of speakers
in Fiji, Malaysia, South Africa, and Mauritius, and it is also an ofﬁcial language in
Sri Lanka and Singapore. Two things set Tamil apart from many other languages:
(1) Tamil lacks articles and (2) Tamil is a null subject language. Not every Tamil
sentence have a subject, verb, and object. In Tamil, it is also feasible to create mean-
ingful sentences using simply a verb. Therefore, the foundation of our project is
creating an automatic text summarizer for Tamil.
Here, for example, we have taken a Tamil story:

Abstractive Text Summarization for Tamil Language Using m-T5
481
The given text is summarized as:

482
C. Saraswathi et al.
2
Literature Survey
Extraction and abstraction are the two basic divisions of automatic text synthesis
methods. Extractive methods produce summaries by extracting phrases and words
from the source text. Statistical, conceptual, optimizational, topical, graphical,
sentence centrality, semantic, and deep learning-based approaches are different types
of methodology.
Fidalgo and Joshi [1] made a proposal Ranksum, as part of a method for
obtaining text summaries from single documents, four multidimensional sentence
aspects—subject information, semantic content, signiﬁcant keywords, and posi-
tion—are recovered for each phrase. They have used numerous extractor types to
rank sentences. Latent Dirichlet Allocation (LDA) was used in topic rank extractor
to ﬁnd the topic vectors using the training dataset. Sentence embeddings are utilized
in embedding-based to locate meaningful sentences based on their semantics, use
semantic rank extractor-next. They have used SBERT. In order to determine the
important phrases in a document, keyword rank extractor uses lemmatization to
compute the set of keywords. Position rank extractors produce position rank vectors
by assigning phrases a rank depending on their position. A weighted rank fusion
from all four derived ranks is calculated.
Zhao and Yang [2] proposed the heterogeneous tree structure-based extractive
summarization (HetreSum) model, which learns the links between phrases by repre-
senting each text as a tree structure. The tree structure also includes the structural
information from the original document, giving it a broad view of the entire content.
First, a heterogeneous document tree is built (where each word is represented as a
leaf node of the tree structure, sentences, and sections as branch nodes of the tree
structure). The three components that make up the heterogeneous document tree are
the tree initializer, tree transformer layer, and sentence selector.
Dua and Li [3] introduced a novel model called BioBERTSum which has been
introduced to, better capture token-level and sentence-level contextual representa-
tion. It employs a domain-aware bidirectional language model that has been further
reﬁned for extractive text summarization tasks on a single biomedical document.
This language model has been pre-trained on large biomedical corpora.
Verma and Verma [4] described a two-stage hybrid methodology for text summa-
rization that combines the advantages of various methodologies. Using a partitional
clustering technique, they categorize the sentences in a document according to how
similartheyareintheﬁrststage.Then,todistinguishbetweentwotexts,theyemploya
linear combination of the normalized Google distance and the word mover’s distance.
To ﬁnd keywords that are semantically similar, they use the Normalized Google
Distance(NGD)semanticsimilaritymetric.Thesigniﬁcantphrasesarethenextracted
from each cluster based on the revised text feature scores from the second step
(partition). The best weights for the sentence are currently being determined using a
teaching–learning-basedoptimizationtechnique.Thesigniﬁcantsentencesarerecov-
ered using the optimal weights. A fuzzy interference system with a human-created
knowledge base is also used to calculate the sentence’s ﬁnal score.

Abstractive Text Summarization for Tamil Language Using m-T5
483
Mourad Oussalah and Mohamed [5] Mohamed proposed an approach for text
summarization called SRL-ESA-TextSum, which is based on semantic role labeling
and explicit semantic analysis. A unique framework for the text summary of single
and multiple texts using graphs is provided in this research. Using SRL, each word
having semantic roles is recognized by its corresponding semantic role tags. In phrase
level semantic parsing, each sentence is represented as a multi-node vertex that
contains Wikipedia concepts for semantic arguments. The summarization system is
evaluated using the standard publicly accessible dataset from the 2002 Document
Understanding Conference (DUC 2002).
Rush et al. [6] proposed a neural attention model for abstractive sentence summa-
rization. Abstractive techniques are used to create summaries by condensing phrases
into shorter terms and using words that do not appear in the original text. Even though
extractive summarizing of phrases has generated a sizable body of study, abstractive
summarization has gotten much less attention. For the ﬁrst time in 2015, Rush et al.
applied deep learning to abstractive text summarization. The Rush et al. model used
three different types of encoders: convolution, bag-of-words, and attention-based
encoders. Deep learning algorithms have recently been frequently used in abstractive
text summarization due to their positive outcomes.
Suleiman and Awajan [7] proposed an abstractive method for summarizing Arabic
text and it primarily uses the sequence-to-sequence RNN architecture. It is made
up of a multilayer encoder and a single-layer decoder. The decoder builds the
summary words using a global attention method that takes into account all of the
input hidden states. In addition to ROUGE-1, three additional evaluation metrics,
known as ROUGE1-NOORDER, ROUGE1-STEM, and ROUGE1-CONTEXT, are
recommended.
Baykara and Gungor [8] proposed an abstractive text summarization for the
Turkish and Hungarian languages, they created two signiﬁcant datasets, TR-News
and HU-News. Both the pointer-generator model and the BERT + Transformer
model have been applied to text summarization in this work. The pointer-generator
model has been chosen as the default model. An encoder-decoder network can choose
whether to highlight a word from the input sequence or to produce a new term from
the vocabulary. The decoder is a unidirectional LSTM with attention mechanism,
while the encoder is a bidirectional LSTM. Their encoder-decoder system, known
as BERT + Transformer, uses BERT as the encoder and a 6-layered transformer
network as the decoder. Because meaning in these agglutinative languages is mostly
held within the morphemes of the words, morphology is crucial. Modern abstractive
summarization models are utilized to assess how well the proposed linguistically-
focused tokenization algorithms (separate sufﬁx and combined sufﬁx) function. The
two techniques used in this study are separate sufﬁx and combined sufﬁx, and both
are based on the roots of the nouns and their sufﬁxes. On the TR-News and HU-
News datasets, they discovered that the multilingual cased BERT model beat the
monolingual BERT models (BERTurk and huBERT) in terms of ROUGE score. On
the TR-News dataset, the separate sufﬁx approach produces the greatest ROUGE-1
score, and the HU-News dataset shows promising results.

484
C. Saraswathi et al.
Cai and Shi [9] created an attentional neural model based on HITS that treats the
sentences and words in the original manuscript as hubs and authorities in order to
properly utilize sentence-level and word-level information. The sentence and words
with the highest likelihood are selected throughout this process after the sentences’
attention values are assessed using Kullback–Leibler divergence. KL divergence
allows us to quantify the amount of information we lose when selecting an approxi-
mation. They have proposed a comparison method using the hierarchical beam search
algorithm to further improve the summarization performance.
Cai and Liu [10] proposed COVIDSum, a SciBERT-based summarization tech-
nique for COVID-19 scientiﬁc papers. On the basis of the chosen sentences, co-
occurrence graphs are constructed to depict the linguistic features of these phrases.
They used CORD-19 heuristic techniques to extract pertinent sentences from the
source articles. Following that, the sentences and word co-occurrence graphs were
encoded using SciBERT and a graph encoder based on a graph attention network
(GAT), respectively. Highway networks, which also incorporated linguistic knowl-
edge into the contextual embeddings of scientiﬁc publications, were subsequently
used to combine the two encodings mentioned above. Then, for each scientiﬁc paper,
an abstractive summary was produced using a transformer decoder. Multiple heads
of attention, a point-wise feed-forward layer, residual connections, and other features
are present in the transformer decoder. At the t-th time step, this layer ground-truth
word should be expected.
2.1
Existing System and Novelty
For Tamil language, only extractive text summarizations techniques are available.
Till now there are no research works done on Tamil abstractive text summarization.
Tamil summarization using extractive approaches like semantic graph and
centroid approach generate summaries that are more robotic and algorithmic rather
than human like. This is because they merely take high priority sentences from the
source text that is depicted in the summary instead of creating new terms. This means
that sentence coherence, consecutive sentence relationships, and paragraph structure
are not taken into account, which gives the summary a robotic form. In centroid
approach, each sentence within a document is treated as a vector in a multidimen-
sional space. The sentences that are closest to the value of the centroid are regarded
the most important [11]. LF Parser is used in the semantic graph approach to iden-
tify the text’s semantic properties. Coreference, feature extraction, and named entity
resolution are carried out as much as is required for summarization [12].
So we have proposed a method of abstractive summarization for Tamil language
using m-T5. We have created an inhouse dataset named Tamil kids stories which
contains 100 Tamil kids’ stories. The proposed dataset has title, story, and reference
summary in it. Each story approximately contains 854 words and 772 words in refer-
ence summary. These stories are scrapped from Tamil article site, and the reference

Abstractive Text Summarization for Tamil Language Using m-T5
485
summary has been manually created for each story in order to get an efﬁcient output
and for the better performance of m-T5 model.
3
Proposed Work
Our idea is based on a ﬁeld of artiﬁcial intelligence known as natural language
processing, which enables machines to read, comprehend, pick up on, and derive
meaning from human language. Using m-T5, we have proposed an abstractive text
summarizingmethodfortheTamillanguage.UsinganoveldesignknownasNLP,this
m-T5 transformer model promises to solve sequence-to-sequence issues while deftly
addressing long-distance dependencies. m-T5 is a multilingual version of Google’s
T5 model that has between 300 million and 13 billion parameters and was pre-trained
using a dataset of 101 languages [13]. The m-T5 model’s architecture and training
were closely modeled by those of the T5 model. To train m-T5, we introduce a
multilingual variant of the C4 dataset called mC4. The massive clean crawled corpus
(mC4) comprises natural text in 101 languages drawn from the public common crawl
web scrape.
T5 is short for “text-to-text transfer transformer”. As the name implies, it is an
encoder-decoder paradigm that uses transformers for text production [14].
Similar to the transformer model [15], the T5 model has a full encoder-decoder
design. The job of the encoder is to convert the input from a series of discrete
representations to a series of continuous representations, which is then supplied
into a decoder. Transformer architecture does not use recursion; therefore, it cannot
by nature capture any information about the relative placements of words in the
sequence. By adding positional encodings to the input embeddings, this data must
be injected.
Prior to being fed into the neural network, the input is ﬁrst delivered to positional
encoding, which assigns numbers to each word in a sentence based on its position in
the phrase. The network then learns how to decode such positional encodings as we
train it on a large amount of text input.
Encoder Stack
The encoder consists of a stack of N = 6 identical layers. Each layer has two sub-
layers. The multi-head self-attention technique is implemented in the ﬁrst sublayer. In
general, paying attention to all the other words in context is the only way to determine
a word’s real meaning (representation). One method for doing that is through self-
attention. In order to decide how to translate a word in the output, the text model can
now examine every word in the source phrase. The purpose of this is to provide the
attention function access to information that would otherwise be inaccessible to it
when using a single attention head.
An attention function can be described as mapping a query and a set of key-value
pairs to an output, where the query, keys, values, and output are all vectors. The
input consists of queries and keys of dimension dk, and values of dimension dv. To

486
C. Saraswathi et al.
determine the weights on the values, we compute the dot products of the query with
each key, divide them by dk, and then use the softmax algorithm.
The input is made of queries and keys of dimension dk, and values of dimension
dv. The dot products of the query are computed with all keys, divided each by √dk,
and apply a softmax function to obtain the weights on the values. In practice, we
simultaneously compute the attention function on a set of queries that are grouped
into a matrix Q.
The keys and values are also packed together into matrices K and V. The matrix
of outputs is computed as
Attention(Q, K, V ) = softmax

QK T/√dk

V
(1)
It was found useful to linearly project the queries, keys, and values h times with
different, learned linear projections to dq, dk and dv dimensions, respectively.
The projected copies of the queries, keys, and values are then each simultaneously
subjected to the attention function to provide dv-dimensional output values. The ﬁnal
values are created by concatenating these and then projecting them once more.
Multi-head attention allows the model to jointly attend to information from
different representation subspaces at different positions. With a single attention head,
averaging inhibits this.
MultiHead(Q, K, V ) = Concat(head1, . . . , headh)W O
where headi = Attention

QW Q
i , K W K
i , V W V
i

where the projections are parameter matrices W Q
i
∈
Rdmodel×dk, W K
i
∈
Rdmodel×dk, W V
i
∈Rdmodel×dv and W O ∈Rhdv×dmodel.
In this work, we employ h = 8 parallel attention layers, or heads. For each of
these, we use dk = dv = dmodel/h = 64.
Layer normalization is applied to the input of each subcomponent. A simpliﬁed
version of layer normalization is used where the activations are only rescaled and no
additive bias is applied. After layer normalization, each subcomponent’s input and
output are combined via a residual skip connection. Dropout is used at the input and
output of the entire stack, on the skip connection, within the feed-forward network,
and on the attention weights.
Afeed-forwardnetworkwithcompleteconnectivitymakesupthesecondsublayer.
The information only goes in one direction in a feed-forward network, which serves
this purpose. It is transmitted from the input nodes to the output node, passing through
any hidden nodes (if any). This consists of two linear transformations with a ReLU
activation in between.
FFN(x) = max(0, xW1 + b1)W2 + b2
(2)
The encoder sends the features to each block of the decoder. The encoder and
decoder are comparable in many ways.

Abstractive Text Summarization for Tamil Language Using m-T5
487
Decoder Stack
Additionally, the decoder consists of a stack of six similar layers, each of which
is made up of three lower layers: The information is delivered to the ﬁrst sublayer,
which then applies masked multi-head self-attention to it.
The decoder has been altered to focus just on the words that came before. In
the ﬁrst sublayer, masking is used to prevent the decoder from focusing on words
that follow. A multi-head self-attention technique, identical to the one used in the
ﬁrst sublayer of the encoder, is implemented in the second layer. This multi-head
mechanism gets the keys and values from the encoder’s output as well as the queries
from the previous decoder sublayer on the decoder side. As a result, the decoder can
focus on every word in the input sequence. A fully connected feed-forward network,
identical to the one used in the second sublayer of the encoder, is implemented in
the third layer.
Finally, a fully connected layer, followed by a softmax layer, is applied to the
decoder’s output to produce a prediction for the following word in the output
sequence.
Our model in Fig. 1 is trained on a variety of tasks that require it to create text
after being provided text for conditioning or context. Our model was trained using
Tamil kid’s stories dataset which we have manually created using web scrapping
techniques.
4
Implementation
T5 is short for “text-to-text transfer transformer”. As the name implies, it is an
encoder-decoder paradigm that uses transformers for text production. m-T5 is multi-
lingual version of t5. It has been pre-trained using mC4 corpus of 101 languages.
Similar to the transformer model, the T5 model has a full encoder-decoder design.
Our model was trained using Tamil Kids Stories dataset. There are 100 stories in
the dataset. For validation purposes, 20% of the data are used. We have used 80%
of data for training purposes. The m-T5 model has a maximum sequence length
of 512, a batch size of 128 sequences, and has been pre-trained on C4 for 219 =
524,288 steps. When ﬁne-tuning, we employ a constant learning rate of 0.001. A
batch size of 150 sequences and a maximum sequence length of 512 are used for
ﬁne-tuning. Our models are trained for a single period. For our project, we are using
the Adam optimizer. We have used beam search decoding method. By maintaining
the most likely num beams of hypotheses at each time step and eventually selecting
the hypothesis with the highest overall probability, beam search lowers the danger
of missing hidden high probability word sequences. To ensure that generation is
complete when all beam hypotheses have reached the EOS token, we set num beams
= 2 and early stopping = True.

488
C. Saraswathi et al.
Fig. 1 Architecture of transformer model

Abstractive Text Summarization for Tamil Language Using m-T5
489
5
Result Discussion
Using the m-T5 model, text summarization is performed. We have employed the
ROUGE scoring metrics. A collection of metrics and software program called
ROUGE, or Recall-Oriented Understudy for Gisting Evaluation, is used to assess
automatic summarization and machine translation software in natural language
processing. The metrics compare an automatically generated summary or translation
with a reference summary or translation.
We have found out F1-score, recall, and precision of Rouge-1, Rouge-2, and
Rouge-L.
ROUGE-1
ROUGE-1 precision can be computed as the ratio of the number of unigrams in gener-
ated summary that appear also in reference summary, over the number of unigrams
in generated summary.
ROUGE-1 recall can be computed as the ratio of the number of unigrams in refer-
ence summary that appear also in generated summary, over the number of unigrams
in reference summary.
ROUGE-1 F1-score can be directly obtained from the ROUGE-1 precision and
recall using the standard F1-score formula.
We got rouge-1 recall, precision, F1-score as 0.4076, 0.78024, and 0.5219.
ROUGE-2
ROUGE-2 precision is the ratio of the number of 2-g in generated summary that
appear also in reference summary, over the number of 2-g in generated summary.
ROUGE-2 recall is the ratio of the number of 2-g in reference summary that
appear also in generated summary, over the number of 2-g in reference summary.
F1 - score = 2 ∗(precision ∗recall)/(precision + recall)
(3)
We got rouge-1 recall, precision, F1-score as 0.5551, 0.7393, and 0.6719.
ROUGE-L
ROUGE-L is based on the longest common subsequence (LCS), which is the largest
sequence of words (not necessarily consecutive, but still in order) that both our model
output and reference share.
ROUGE-L precision is the ratio of the length of the LCS, over the number of
unigrams in generated summary.

490
C. Saraswathi et al.
Fig. 2 Bar chart
representing the rouge scores
0
0.2
0.4
0.6
0.8
1
Rouge 1
Rouge 2
Rouge L
Precision
Recall
F1 Score
Table 1 Rouge scoring for
summary generated
Rouge score
Precision
Recall
F1-score
ROUGE-1
0.78024
0.4076
0.5219
ROUGE-2
0.7393
0.5551
0.6719
ROUGE-L
0.7802
0.4076
0.5219
ROUGE-L recall is the ratio of the length of the LCS, over the number of unigrams
in reference summary.
We got rouge-L recall, precision, F1-score as 0.4076, 0.7802 and 0.5219. The bar
chart representation of the rouge score summary is displayed in Fig. 2.
Table 1 represents the results of the proposed work.
Example predictions on Tamil kids story dataset:
To show that our model is generating ﬂuent summaries, we include a few example
decodes from our model on the validation set along with the actual summary.
Here by we have given below few lines of a single story.
Actual Summary

Abstractive Text Summarization for Tamil Language Using m-T5
491
GENERATED SUMMARY

492
C. Saraswathi et al.
6
Conclusion and Future Scope
Abstractive text summarization is still in its infancy in the Indian language when
compared to languages like English, French, Chinese, Arabic, German, and Spanish.
For Tamil language, only extractive text summarizations techniques are available.
Till now there are no research works done on Tamil abstractive text summarization.
In this article, we have proposed an abstractive text summarization for Tamil using

Abstractive Text Summarization for Tamil Language Using m-T5
493
the m-T5 model. Model was trained on our inhouse dataset Tamil Kid’s Stories which
we have created. Proposed system was evaluated using rouge metrics such as Rouge-
1, Rouge-2, and Rouge-L. The challenges of putting the techniques forth and their
solutions were investigated and evaluated. Our insight for future work is to test our
model on large documents such as Tamil literature books. Further we plan to train our
model by increasing more data on our dataset to get better performance and results.
References
1. Joshi A, Fidalgo E, Alegre E, Alaiz-Rodriguez R (2022) RankSum—an unsupervised extractive
text summarization based on rank fusion. Expert Syst Appl 200:116846
2. Zhao J, Yang L, Cai X (2022) HetTreeSum: a heterogeneous tree structure-based extractive
summarization model for scientiﬁc papers. Expert Syst Appl 210:118335
3. Du Y, Li Q, Wang L, He Y (2020) Biomedical-domain pre-trained language model for extractive
summarization. Knowl-Based Syst 199:105964
4. Verma P, Verma A, Pal S (2022) An approach for extractive text summarization using fuzzy
evolutionary and clustering algorithms. Appl Soft Comput 120:108670
5. Mohamed M, Oussalah M (2016) An iterative graph-based generic single and multi docu-
ment summarization approach using semantic role labeling and wikipedia concepts. In:
2016 IEEE second international conference on big data computing service and applications
(BigDataService), pp 117–120. IEEE
6. Rush AM, Chopra S, Weston J (2015) A neural attention model for abstractive sentence
summarization. arXiv preprint aXiv:1509.00685
7. Suleiman D, Awajan A (2022) Multilayer encoder and single-layer decoder for abstractive
Arabic text summarization. Knowl-Based Syst 237:107791
8. Baykara B, Güngör T (2022) Abstractive text summarization and new large-scale datasets for
agglutinative languages Turkish and Hungarian. Lang Resour Eval, pp 1–35
9. Cai X, Shi K, Jiang Y, Yang L, Liu S (2021) HITS-based attentional neural model for abstractive
summarization. Knowl-Based Syst 222:106996
10. Cai X, Liu S, Yang L, Lu Y, Zhao J, Shen D, Liu T (2022) COVIDSum: a linguistically
enriched SciBERT-based summarization model for COVID-19 scientiﬁc papers. J Biomed
Inform 127:103999
11. Mohamed SS, Hariharan S (2016) A summarizer for Tamil language using centroid approach.
Int J Inf Retrieval Res (IJIRR) 6(1):1–15
12. Banu M, Karthika C, Sudarmani P, Geetha TV (2007) Tamil document summarization
using semantic graph method. In: International conference on computational intelligence and
multimedia applications (ICCIMA 2007), vol 2, pp 128–134. IEEE
13. Xue L, Constant N, Roberts A, Kale M, Al-Rfou R, Siddhant A, Barua A, Raffel C (2020)
mT5: a massively multilingual pre-trained text-to-text transformer. arXiv preprint arXiv:2010.
11934
14. Raffel C, Shazeer N, Roberts A, Lee K, Narang S, Matena M, Zhou Y, Li W, Liu PJ (2020)
Exploring the limits of transfer learning with a uniﬁed text-to-text transformer. J Mach Learn
Res 21(140):1–67
15. Vaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez AN, Kaiser Ł, Polosukhin I
(2017) Attention is all you need. In: Advances in neural information processing systems, vol
30

495
Sentiment Component Extraction 
from Dependency Parse for Hindi
Remya Panicker, Ramchandra Bhavsar, and B.V. Pawar
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023 
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks and 
Systems 672, https://doi.org/10.1007/978-981-99-1624-5_36
Abstract  With the advent of Web 2.0, Natural Language Processing (NLP) gained 
attention and a new dimension in the NLP application arena. Sentiment analysis 
is one such popular modern NLP application that tries to extract the feeling, emo-
tions, opinions, etc., expressed in digital text using NLP techniques. Sentiment 
analysis has become a subtle application over the last decade and found a firm 
foundation in AI applications. This is especially applicable to product services, 
reviews, and recommendations domains. It tries to quantify the sentiment better 
and helps understand the views expressed in a text leading to better decision-mak-
ing. There is a variety of approaches available for carrying out sentiment analysis 
ranging from naive to sophisticated machine learning approaches. However, less 
attention is being paid to linguistics aspects. We undertook a study to project sen-
timent analysis concerning linguistic dimensions of natural language text which 
is the least-explored approach to sentiment analysis. Sentiment components of a 
text are deeply rooted in its syntactic constituents. The only way to figure out the 
syntactic constituents is parsing. We have tried to portray the use of dependency 
parsing for extracting the sentiment components from Hindi input text. We have 
explored the applications of various dependency relations to derive the possible 
sentiment compositionality from Hindi sentences. Our study and findings related 
to sentiment components extraction from dependency parse are presented in this 
paper with a linguistic insight.
R. Panicker (*) · R. Bhavsar · B. V. Pawar 
School of Computer Sciences, KBC North Maharashtra University, Jalgaon, Maharashtra, 
India
e-mail: remya.panicker@gmail.com
R. Bhavsar 
e-mail: rpbhavsar@nmu.ac.in
B.V. Pawar 
e-mail: bvpawar@nmu.ac.in

496
R. Panicker et al.
Keywords  Sentiment analysis  ·  Sentiment components  ·  Dependency pars-
ing  ·  Natural Language Processing (NLP)
1  Introduction
With the emergence of the participative web, i.e., Web 2.0, there was a deluge 
of user-generated content on the Internet. Social media flourished with user-gen-
erated digital content like a post, tweets, images, videos, blogs, etc. With this, 
there was an urge to extract the sentiments hidden inside this huge data. Multiple 
areas like Business, Marketing, Political, Social, etc., motivated to perform senti-
ment analysis on the digital text to extract the feelings, opinions, and sentiments 
expressed in the digital text. Sentiment analysis finds its application in product 
review analysis on various shopping sites, recommendation systems, virtual chat-
bots, political campaigning, natural language understanding, etc.
Sentiment analysis [1, 2] is the mechanism of classifying a piece of text accord-
ing to the sentiment polarity (viz. negative, positive, neutral). The text can be a 
phrase, sentence, or document which contains some opinions, feelings, senti-
ments, etc. There exist various approaches to Sentiment Classification; among 
them, Lexicon-based approach and learning-based approach are widely used. 
These approaches rely on a bag of word mechanisms, part of speech tagging, fea-
ture extraction, dictionaries, corpus, etc. The existing approaches mainly focus on 
polarity identification, but identifying the extent of emotions, feelings, compari-
sons, opinions, the strength of sentiment, etc., is still a challenge. This challenge 
can be overcome by accurately identifying the sentiment compositions that exist 
among the different words of a text. Present approaches least care about the senti-
ment compositions; they rather focus on only marking text as positive or negative. 
Sentiment analysis is performed at two scales fine-grained and coarse-grained. 
Fine-grained sentiment analysis aims extraction of micro-level sentiment compo-
sitions from each word of a sentence. Coarse-grained extracts sentiment on docu-
ment level or sentence level.
For accurate sentiment analysis, it is necessary to identify the various sen-
timent components present in any text that contributes to the sentiment orienta-
tion. Components of sentiment may be opinions or sentiments expressed in the 
sentence, the object or entity about which some sentiment is expressed, the fea-
ture or attribute of any object, the person who is expressing the sentiment, feel-
ings expressed, emotions, etc. It is difficult to identify these components while 
performing traditional sentiment analysis which just relies on a bag of word 
mechanisms.
The NLP pipeline activities, viz.
Segmentation, tokenization, part of speech (POS) tagging, lemmatization, and 
parsing [3], can be modified accordingly to extract sentiment composition. In this 

497
Sentiment Component Extraction from Dependency Parse for Hindi
pipeline, POS taggers can be used to identify the underlying part of speech of the 
word. These POS categories can be employed to identify the sentiment compo-
nents, e.g., adjectives denote the sentiment; noun denotes the holder of sentiment 
or an entity about which sentiments are expressed. These methods lack when there 
is a need to figure out the sentiment relationships that exist among the words of 
a sentence. Parsing is an important pipeline activity that involves the process of 
breaking the sentence into various parts of speech (POS) and understanding the 
meaning and relationship among the various POS components. Parsing is a pro-
cess of determining whether a sentence is accepted by a given grammar or not. 
It is an important stage in the pipeline of NLP activities. The output of parsing is 
used for information extraction, word sense disambiguation, etc.
We bring to light that parsing can also help in understanding the sense, opinion, 
and sentiment expressed in the sentence. The output of the parser is a sentence dia-
gram or parse representation which generally is a tree. Dependency parsing [4–6] 
is a parsing technique that can perform syntactic and semantic analysis. In depend-
ency parsing, a syntactic structure of a sentence is described in terms of words 
with an associated set of binary relations between words of the sentence known as 
dependency relations.
In this paper, we have put forth a novel approach to performing sentiment 
analysis by identifying sentiment components and establishing the relationship 
between these components. The main contributions of the presented work are as 
follows:
1.	 Concept of sentiment components.
2.	 Identifying the correlation between sentiment components at the syntactic and 
semantic parsing stages by analyzing the output of the dependency parser for 
the Hindi language.
3.	 Identification of sentiment components and formulation of sentiment relations.
4.	 Employing POS category ‘verb’ for sentiment extraction, i.e., deriving senti-
ments from action statements in Hindi.
5.	 The paper put forward an algorithm that takes the output of dependency pars-
ers, i.e., the dependency relations as input and identifies the various sentiment 
components and relations that exist in a sentiment expression for Hindi.
The paper is organized into 6 sections, Sect. 1 is the introduction, Sect. 2 describes 
how parsing contributes to sentiment analysis and related work, Sect. 3 gives a 
brief description of various sentiment components and sentiment relations, Sect. 4 
presents details of dependency relations that help us to derive a particular senti-
ment attribute and components, Sect. 5 depicts the algorithms and empirical test-
ing used to implement this approach, and Sect. 6 highlights the limitation and 
amendments that have to be done in dependency parsing for in-depth sentiment 
analysis.

498
R. Panicker et al.
2  Related Work
Di Caro and Grella [7] proposed a method that performs sentiment analysis 
based on propagation rules that work at syntactic level. They used a Stanford 
Dependency Parser [8] for the English language and Tule [9] for the Italian lan-
guage. It defines a syntactic-based propagation rules that transfer sentiment values 
of the words to each other in the dependency parse tree.
Socher et al. [10] introduced a sentiment treebank that expresses the phrase 
or sentence into a fully labeled parse tree. They used Recursive Neural Tensor 
Network to address the problem of sentiment compositionality.
Artemy et al. [11] developed a semantic parser that constructed syntactic trees 
and a semantic representation frame (set of valencies with semantic markers). 
This representation is used to identify the sentiment in the sentence by a computer 
agent. This method is devised only for the Russian language.
Agarwal et al. [12] employed a concept extraction algorithm based on a con-
cept parser. They used a ConceptNet ontology which provides the semantic of the 
text. This method had efficiently implemented common sense reasoning using 
common sense ontology and reasoning algorithms.
Dong et al. [13] presented a statistical parsing method for analyzing the senti-
ment structure of sentences directly. Here, a sentiment grammar is built like con-
text-free grammar.
Zhang et al. [14] presented a neural network-based model for sentiment anal-
ysis by using deep sentiment representation, Gaussian mixture vectors, sentiment 
grammar models, and EMLo Embedding.
3  Sentiment Components and Sentiment Relations
Sentiment Components: S Sentiment components are the words or groups of 
words that contribute to the sentiment structure formation of sentence/phrase/text.
In-depth sentiment analysis means performing a granular analysis of every 
word affecting the polarity of a sentence or phrase. It can be performed at the sen-
tence or phrase level. Sentiment components extraction involves (a) extracting the 
entities, i.e., the object/thing/subject for which sentiments are expressed, (b) iden-
tifying the aspects/features/properties of the entities, (c) determining the sentiment 
relationship that exists between an aspect and its entity, and (d) identifying the 
holders and targets of a sentiment. This provides a broader insight into sentiment 
orientations in a text. It gives the relationship that exists among the words of a sen-
tence or phrase. For instance, the most important application of sentiment compo-
nent extraction is that it mines the opinion, i.e., to identify what is being told about 
a particular entity, who is the holder of the sentiment, what is the polarity of the 
sentiment, etc.
A similar concept was put forth by Bing Liu, [1]. He has represented opinions 
as a quintuple (entity, aspect, sentiment, holder, time). It is represented as (ei, 

499
Sentiment Component Extraction from Dependency Parse for Hindi
aij, sijkl, hk, tl), where ei: name of the entity, aij: an aspect of ei, sijkl: sentiment 
expression on aspect aij of an entity ei, hk: is the holder of opinion, and tl: Time 
when the sentiment was expressed. The important task of fine-grained sentiment 
analysis is to identify all five components of the quintuples. This paper focuses 
on identifying those quintuples elements along with some other components. 
Following are the important remark about all five components of quintuples by 
considering an example:
E.g. 1: रमेश को सोनी मोबाइल का कैमरा उत्तम लगा|
Transliteration: Ramesh ko sonī mobāil kā kaimarā uttam lagā
Translation: Ramesh liked the Sony mobile camera
The quintuple will be (सोनी मोबाइल, कैमरा, उत्तम, रमेश, Present time)
There are various types of sentiment expressions other than the above. 
Sentiment analysis can be classified as opinion analysis, intent analysis, emotion 
analysis, etc., which constitutes a Sentiment Taxonomy [15], which includes vari-
ous types of sentiment expression. Each type of sentiment expression is composed 
of various types of sentiment components. We will discuss only the Feedback and 
Opinion Analysis in this paper. The scope of the paper considers components like 
entity, aspect, sentiment, time, holder, etc. Other than the abovementioned com-
ponents, many other components contribute to the overall sentiment analysis, viz. 
emotions (Joy, anger, love, care, etc.), reaction to an action, sarcasm, comparison, 
negations, intensifications, point of view, etc. Following are some of the important 
sentiment components identified for Feedback/Opinion Analysis:
Entity: Entity broadly refers to an object, person, place, topic, issue, event, etc., 
about which something is expressed in the text. It is similar to Name Entity 
Recognition (NER) in NLP. In E.g. 1, सोनी मोबाइल्स is the entity. It is usually noun or 
noun phrase. It is also referred to as objects.
Aspect: Aspect denotes the attribute of an entity. They are also referred to as 
features, attributes, facets, etc. It implies the characteristics of an entity. It is usu-
ally a noun and a noun phrase, but it can be a verb or adjective too. In above exam-
ple, ‘कैमरा’ is the aspect of entity ‘सोनी मोबाइल्स’.
Qualifier: It is the feature of the aspect. It is the characteristics of any aspect of 
an entity.
Sentiment: The sentiment is the opinionated word that denotes the polarity 
(positive, negative, or neutral). It is usually an adjective or an adverb, sometimes 
verb too denotes sentiment. In E.g. 1, ‘उत्तम’ is the sentiment denoting the word.
Holder: Holders of sentiment are the person who is expressing the sentiment or 
conveying the opinion. It becomes vital to justify a sentiment from the perspective 
of a holder, so identifying a holder is an important task. In the above example, 
‘रमेश’ is the holder of the sentiment expressed.
Time: Time denotes the time (date) or tense when the opinion or sentiment was 
expressed. Sometimes tense and time is used to justify the sentiment and opinion 
so time extraction becomes important.

500
R. Panicker et al.
Intensifier: Intensifiers are responsible for the escalation of the extent of senti-
ments in a word. For E.g. 2., रमेश बहुत अच्छा विद्यार्थी है पर ख़राब खिलाडी है. Transliteration: 
Ramesh bahut achchhā vidyārthī hai par khrāb khilāḍī hai. Translation: Ramesh is 
a very good student but a bad player). Here, ‘बहुत’ is increasing the intensity of the 
sentiment word ‘अच्छा’ which converts a positive statement into a highly positive 
one.
Sometimes action-denoting sentences too denotes sentiments. POS category 
verb too affects the overall sentiment composition of a sentence. Most of the sen-
timent analysis approaches just rely on adjective and adverbial words; they ignore 
the significance of verbs or action-denoting words while extracting the sentiments. 
We have identified some sentiment components that are related to action-denoting 
statements; some of them are discussed below.
Consider an example:
E.g.3. डाकू ने घर जलाया|
Transliteration: Ḍākū ne ghar jalāyā
Translation: The robber burnt the house
Action: The verb in the sentence which denotes some action/activity is an 
action component. In E.g. 3, ‘जलाया’ is the action components. Which conveys a 
negative sentiment.
Action Subject/Agent: The doer/initiator of an action is the action subject. In 
E.g. 3, ‘डाकू’ is the doer or responsible for action 2 ‘जलाया’.
Action Object/Patient: Action Object represents the recipient of the action. It is 
the entity which is affected by the action. In E.g.3, ‘घर’ is the entity affected by the 
action ‘जलाया’.
Sentiment Relation: The relationship that exists between sentiment compo-
nents is referred to as sentiment relation. It is the same like dependency relation 
but they denote the sentiment relationship that contributes to the sentiment extrac-
tion and helps in understanding the sentiment orientations among the words. We 
have identified some of the common relationships that exist in opinioned state-
ments which are discussed below:
Entity and Root: Root Entity about which sentiment/feedback/Opinion is 
expressed.
Attribute and Entity: Feature/Property/Attribute of Entity.
Aspect and Attribute: Feature/Aspect/Property of Attribute.

501
Sentiment Component Extraction from Dependency Parse for Hindi
Aspect and Qualifier/Aspect and Sentiment: Quality/Sentiment of Entity, 
Attribute or Aspect.
Qualifier and its Descriptor: Descriptor of Qualifier.
Qualifier and its Holder: Holder or Person expressing opinion or feedback.
Qualifier and Time: Time at which the opinion or feedback was expressed.
Following are the relations for action-denoting statements:
Subject of Action: It is the action doer/initiator.
Object of Action: Recipient of the action.
4  Employing Parsers for Sentiment Component 
Extraction
In Natural Language Processing (NLP), parsing involves the process of break-
ing the sentence into various parts of speech and understanding the meaning and 
relationship among the various POS components. It is the process of determin-
ing whether a sentence is accepted by a given grammar. It is also called syntactic 
analysis. Syntactic analysis is an important stage in the pipeline of NLP activi-
ties. The output of parsing is used for information extraction, word sense disam-
biguation, etc. It also helps in understanding the sense and sentiment expressed 
in the sentence. The outputs of the parser are a sentence diagram or parse rep-
resentation which generally is a tree. Parsing requires grammar to produce parse 
trees or graph. There are various techniques of Parsing: Deep Parsing: This tech-
nique of parsing aims to create the complete syntactic structure of a sentence. It 
is used in complex NLP applications. It is also known as Full Parsing. Shallow 
Parsing/Partial Parsing: Many times, it is not desired to have a complex and 
complete parse tree for all inputs; for this, partial parse or shallow parse is suffi-
cient. Chunking: It is similar to partial parsing; it identifies and classifies the flat, 
non-overlapping segments of a sentence. Dependency parsing: In dependency 
parsing, a syntactic structure of a sentence is described in terms of words with an 
associated set of binary relations between words of the sentence.
Sentiment analysis is mainly carried out by the bag of word approach. To 
identify the sentiment compositionality, it is necessary to understand the seman-
tic organization of a sentence. Parsing can contribute to deriving the relationships 
that exist among the words and POS categories. Dependency parsing is one such 
important method. Dependency parsing [5] is a parsing technique in which the 
output of the parser is a directed graph. The directed graph has directed arcs from 
headword to dependent word showing the relations that exist between the words. 
These relations give a better understanding of the various words that makes a sen-
tence. The major advantage of using a dependency parser for Hindi is the ability of 
dependency parsers to efficiently deal with the free word order nature of the lan-
guage. Some of the work reported that performs sentiment analysis at the parsing 
stage is discussed in the following section.

502
R. Panicker et al.
5  Sentiment Analysis Based on Dependency Parsing
The output of a dependency parser [5] is a directed graph with directed arcs from 
head to dependent. It is also called typed dependencies. Dependency relations are 
binary grammatical relations that exist between two words. The syntax of writ-
ing the dependency relation is the relation name (head, dependent). Dependencies 
are pairs of the head (known as governor or regent) and dependent. The advantage 
of using a dependency parser for Hindi is its ability to deal with free word order 
languages.
Consider the following example:
E.g. 4.: जवान ने दुश्मन को मारा|
Transliteration: Javān ne dushman ko mārā
Translation: Soldier kills enemy
The POS (part of speech) categories for each word in above example are:
•	 (जवान, NOUN),
•	 (ने, Adpostion),
•	 (दुश्मन, NOUN),
•	 (को, Adpostion),
•	 (मारा, VERB).
The dependency relations that occur in above example are:
•	 Root Word: root(root, मारा)
•	 Nominal Subject: nsubj(‘मारा’, ‘जवान’)
•	 Prepositions/Postpositions: case(‘जवान’, ‘ने’), case(‘दुश्मन’, ‘को’)
•	 Object: obj(‘मारा’, ‘दुश्मन’)
From the dependency relation, we can figure out the subject, object, and action.
We performed a deep study of these dependency relations. This study helped 
us to identify the dependency relations that contributed to sentiment component 
extractions. From this study, we figured out the combinations of dependency rela-
tions, and POS categories (of Head and Dependent) which helped us to extract the 
sentiment components and their relationship. From this, we framed multiple rules 
which contributed to in-depth sentiment analysis.
The Universal Dependency (UD) Project undertaken by Nivre et al. [16] devel-
oped a cross-lingual Universal Dependency Tree Bank for more than 50 lan-
guages. This Universal Dependency Project consists of data sources and performs 
segmentation, tokenization, POS tagging, lemmatization, and dependency parsing. 
We used the dependency relation from the UD project to analyze the sentiment 
component.

503
Sentiment Component Extraction from Dependency Parse for Hindi
The following section describes the various dependency relations [17] that help 
in extracting the various sentiment components like entity, aspect, holder, senti-
ment, and time from a Hindi sentence. Table 1 shows some of the relations and its 
sentiment derivations.
6  Experiment and Empirical Testing
Approach: For the experimental setup, we have implemented a dependency 
parser from the Universal Dependency (UD) Project (Nivre et al. [16]) for the 
Hindi language, used ufal.udpipe package to implement the model. The output of 
this is dependency parse relation. This relation is given input to the ‘Sentiment 
Component Extraction Algorithm’, which after execution classifies the words from 
the input text into their corresponding sentiment components. The output of the 
algorithm is the Sentiment Component List (Related Sentiment Components) and 
Sentiment Component Relation List (Sentiment Relationships among words).
Table 1   Sentiment components extracted from dependency/syntactic relation
Syntactic relation
POS of head
POS of 
dependent
Sentiment com-
ponent denoted 
by head
Sentiment compo-
nent denoted by 
dependent
nsubj:Nominal 
Subject
Verb
Noun/Pronoun
Action Sentiment
Action Subject/
Doer/Agent
Adjective
Noun/Pronoun
Sentiment/
opinion
Entity/Aspect
Noun
Noun/Pronoun
Aspect
Entity/Object
obj:Object
Verb
Noun/Pronoun
Action Sentiment
Action Object/
Receiver/Patient
iobj:Indirect 
Object
Verb
Noun/Pronoun
Action Sentiment
Action Addressee
xcomp: 
open clausal 
complement
Verb
Adjective
Action Sentiment
Feature of 
Sentiment 
(Sentiment 
Modifier)
obl:oblique 
nominal
Verb
Noun/Pronoun
Aspect
Entity
nmod:Nominal 
Modifier
Noun
Noun/Pronoun
Aspect
Entity
Adjective
Noun/Pronoun
Sentiment/
Opinion
Aspect/Entity
advcl: Adverbial 
clause modifier
Verb
Verb
Sentiment 
Reaction
Sentiment Action

504
R. Panicker et al.
Sentiment Component Extraction Algorithm: A rule-based algorithm is devised 
to identify the type of each word (POS Category). It helps in the identification of 
sentiment components by using the following aspects:
•	 Type of dependency relation.
•	 Head and Dependent words from dependency relation.
•	 POS categories of Head and Dependent words.
Data Structures used in Algorithm
•	 QUALIFIERS: List of sentiment-denoting words from given text.
•	 ASPECT: List of aspect-denoting words from given text.
•	 AGENT: List of doer/agent of an action.
•	 ACTION: List of action-denoting words from given text.
•	 ENTITY: List of entity-denoting words from given text.
•	 HOLDER: List of words denoting holder of sentiment from a given text.
•	 INTENSIFIER: List of intensifiers from the given text.
•	 OBJECT: List of receiver/patient of some action/verb from a given text.
•	 SENTIMENT COMPONENT LIST: Related sentiment components.
•	 SENTIMENT COMPONENT RELATION’S LIST: Sentiment relationships 
among words.
Sentiment Component Extraction Rules: Using combinations shown in Table. 
1, the Sentiment Component Extraction Rules are crafted to figure out the senti-
ment compositions. It is not limited to the combinations mentioned in the table, 
but there is a scope for the addition of newly identified rules.
Example of Sentiment Component Extraction Rules:
IF Relation equals NSUBJ Then
   IF HEAD’s POS category is ADJECTIVE Then
    Add Dependent word in ‘QUALIFIER’ list.
    Add Head word in ‘ASPECT’ list
    Create a sentiment relation ENTITY_QUALIFIER (Head word, Dependent 
word)
   ELSE IF HEAD’s POS category is VERB Then
    Add Dependent word in AGENT list
    Add Head word in ACTION list
    Create a sentiment relation ACTION_AGENT (Head word, Dependent word)
   ELSE
    Add Dependent word in ‘ENTITY list.
    Add Head word in ‘ASPECT’ list
    Create a sentiment relation ENTITY_ASPECT (Head word, Dependent word)
END IF

505
Sentiment Component Extraction from Dependency Parse for Hindi
Algorithm
Input: Dependency relations (From Dependency Parsers).
Output: Sentiment Component List: Related Sentiment Components, Sentiment 
Component Relation’s List: Sentiment Relationships among words.
Step 1: Read the relations from dependency parser
Step  2:  Identify the Relation type and POS Category of Head and Dependent 
words
Step 3: Apply the ‘Sentiment Component Extraction Rules’
Step 4: Populate the respective ‘Sentiment Component Lists’
Step 5: Populate the respective ‘Sentiment Component Relation’s List’
Step 7: Print the relation
Step 8: End
Experimental Setup: Dataset of 100 manually annotated simple Hindi sen-
tences (sentiment-denoting sentences) was created for evaluating this approach. 
Dependency parser from the Universal Dependency (UD) Project (Nivre et al. 
[16]) for the Hindi language (ufal.udpipe package) was used to derive dependency 
relation pairs. These relations were provided to ‘Sentiment Component Extraction 
Algorithm’.
The output of the algorithm is the Sentiment Component List (Related 
Sentiment Components) and Sentiment Component Relation List (Sentiment 
Relationships among words). The following sample example denotes this process:
Sample
Sentence: ‘रमेश बहुत अच्छा विद्यार्थी है पर ख़राब खिलाडी है’.
Transliteration: Ramesh bahut achchhā vidyārthī hai par kharāb khilāḍī hai
Translation: Ramesh is a very good student but a bad player.
The above sentence is fed to the parsing module, which gives the set of follow-
ing relations:
•	 [((None, ‘TOP’), ‘root’, (‘विद्यार्थी’, ‘NOUN’)),
•	 ((‘विद्यार्थी’, ‘NOUN’), ‘nsubj’, (‘रमेश’, ‘PROPN’)),
•	 ((‘विद्यार्थी’, ‘NOUN’), ‘amod’, (‘अच्छा’, ‘ADJ’)),
•	 ((‘अच्छा’, ‘ADJ’), ‘advmod’, (‘बहुत’, ‘ADV’)),
•	 ((‘विद्यार्थी’, ‘NOUN’), ‘cop’, (‘है’, ‘AUX’)),
•	 ((‘विद्यार्थी’, ‘NOUN’), ‘conj’, (‘खिलाडी’, ‘NOUN’)),
•	 ((‘खिलाडी’, ‘NOUN’), ‘cc’, (‘पर’, ‘CCONJ’)),
•	 ((‘खिलाडी’, ‘NOUN’), ‘amod’, (‘ख़राब’, ‘ADJ’)),
•	 ((‘खिलाडी’, ‘NOUN’), ‘cop’, (‘है’, ‘AUX’))]

506
R. Panicker et al.
These relations comprise the words, its POS category, and name of the syntactic 
relation that exists between the two words. These relations are given as an input to 
the algorithm. The algorithm produces the following output.
Output of Sample: The output is a sentiment relation pair. Its interpretation is 
described below:
•	 ENTITY_ASPECT (विद्यार्थी, रमेश): विद्यार्थी is Aspect of Entity रमेश
•	 ASPECT_QUALIFIER (अच्छा, विद्यार्थी): अच्छा is qualifier/sentiment of/by Aspect 
विद्यार्थी
•	 ASPECT_QUALIFIER (ख़राब, खिलाडी): ख़राब is qualifier/sentiment of/by Aspect 
खिलाडी
•	 QUALIFIER _INTESIFIER (अच्छा, बहुत): अच्छा is intensified/described/बहुत→
Evaluation
Similar to above sample, some 100 sentences were fed to the model. The output 
was evaluated using the metrics discussed below. The common evaluation met-
rics evaluate the conceptual ‘distance’ between the candidate parse generated by 
the parser and the correctly annotated solution (the ‘gold standard’). For evalua-
tion, we are using Gold Standard; here, sentences are annotated by hand. Table 2 
denotes the Exact Match (EM) metrics which is 70%, i.e., about 70 sentences were 
correctly labeled by the model.
About 380 relations (identified manually) were there in 100 sentences. Labeled 
attachment Score (LAS) refers to the proper assignment of a word to its sentiment 
components along with the correct sentiment relation. Table 3 denotes the LAS 
score; out of 380 relations 330 relations were correctly identified.
Table 4 denotes the precision, recall, and F-score for total sentences, consider-
ing average of total labeled sentences. Table 5 denotes metrics for each relation, 
considering average of total labeled sentiment relations.
Exact Match (EM) Metrics
Precision, Recall, and F-score
For total sentences: Considering average of total labeled sentences.
For each relation: Considering average of total labeled sentiment relations.
Table 2   EM metrics
Total number of sentence correctly labeled
Total number of sentence
Accuracy (%)
70
100
70
Table 3   Labeled attachment score
Total sentiment relations
Correctly labeled relations
LAS
380
330
0.86

507
Sentiment Component Extraction from Dependency Parse for Hindi
7  Limitations of This Approach
From the study of the various work undertaken in the field of syntactic, semantic, 
and statistical parsing, it is observed that the output of a parser only deals with the 
deriving relationship between the grammatical structures of the sentence. Once the 
parse tree or parse representation is generated, then the sentiment analysis task is 
performed. This restricts us from performing in-depth sentiment analysis of a text. 
The above study helps us to derive only the sentiment that is explicitly mentioned 
in the text, i.e., terms reflecting sentiment are present in the sentence. It works 
efficiently with simple sentences. It may fail in many instances where sentiment 
compositionality is complex. There may exist sentences that cannot be processed 
merely by a dependency parser.
An implicit sentiment-denoting sentences is difficult to process with a depend-
ency parser. In these types of sentences, the words do not reflect any sentiment 
directly.
E.g., पिक्चर देकते ही मुझे नींद आ गयी| (Pikchar dekate hī muze nīanda ā gayī/ I fell 
asleep as soon as I saw the picture).
Sarcastic sentence is a sentence in which words are used to express the opposite 
of what you want to say, especially to insult someone, to show irritation, or just to 
be funny. E.g., क्या बढ़िया कार है, दो दिनों में ही बंद हो गयी! (Kyā badhiyā kār hai, do dinoan 
mean hī banda ho gayī/ what a great car it was stopped in two days).
Comparative sentence is a type of sentence in which a comparison is made 
between two objects and entities. E. g.:सोनी का मोबाइल सॅमसंग से अधिक अछा है| (Sonī kā 
mobāil saॅmasanga se adhik achhā hai|/ Sony’s mobile is better than Samsung).
Feeling, Emotion; Emotion-based Expressions are difficult to analyze. Various 
emotions like anger, joy, fear, anxiety, love, jealousy, etc., cannot be fully covered 
by dependency parsing. E.g., पिता अपनी बेटी की करतूत पर हैरान है और उसे शाप देते हैं| (Pitā 
apanī beṭī kī karatūt par hairān hai aur use shāp dete haian /Father is shocked at his 
daughter’s handiwork and curses her)shows anger but there’s no way to classify it 
as negative.
Table 4   Precision, recall, and F-score for total sentences
Accuracy
Precision
Recall
F-score
0.88
0.87
0.76
0.80
Table 5   Precision, recall, and F-score for sentiment relations
Sentiment relation
Accuracy
Precision
Recall
F-score
Entity root
0.80
0.75
0.60
0.67
Attribute entity
0.70
0.86
0.60
0.71
Aspect attribute
0.83
0.80
0.70
0.75
Aspect qualifier
0.80
0.88
0.70
0.78
Qualifier descriptor
1
1
1
1

508
R. Panicker et al.
8  Future Scope and Conclusion
The dependency parsers just depict the bigram dependencies. The output of 
dependency parsers is insufficient to represent the overall sentiment relations 
among words in a text. The Hindi language sentiment expression consists of var-
ied relationships and emotional expression, that has to be modeled into proper 
sentiment-based typed dependencies. Hence, there is a need for devising and for-
mulating sentiment-based typed dependencies. It is also important to decide the 
hierarchy of sentiment-based typed dependencies to incorporate all sentiment 
expressions. Designing styles of representation for typed relations using a suita-
ble data structure is also crucial in sentiment analysis. Parsers dedicatedly to sen-
timent extraction can be designed to facilitate sentiment analysis and language 
understanding. Most of the cited work is done in English language or foreign lan-
guages. There is a scarcity of such approaches in regional languages like Hindi, 
Marathi, etc. So, there is a scope for such research in these languages. Also, such 
parsers can reduce the flaws and errors in currently used techniques by providing a 
correctly interpreted sentence as an output of the parsing phase.
References
	 1.	 Liu B (2012) Sentiment analysis and opinion mining. Morgan & Claypool Publishers
	 2.	 Bo P, Lee L (2008) Opinion mining and sentiment analysis. Found Trends Inf Retr 
2(1–2):1–135
	 3.	 Aho AV, Sethi R, Ullman JD (2007) Compilers: principles, techniques and tools. 2nd ed. 
Pearson Addison Wesley
	 4.	 Daniel J, James M (2009) Speech and language processing: an introduction to natural lan-
guage processing, computational linguistics and speech recognition. Second Impression, 
Pearson Education Inc
	 5.	 K¨ubler S, McDonald R, Nivre J (2009) “Dependency Parsing”: synthesis lectures human 
language technologies. 1:1–127
	 6.	 Milan S, Jana S (2017) Tokenizing, POS tagging, lemmatizing and parsing UD 2.0 with 
UDPipe. In: Proceedings of CoNLL 2017 shared task: multilingual parsing from raw text to 
universal dependencies, vol 1, pp 1–127
	 7.	 Di Caro L, Grella M (2013) Sentiment analysis via dependency parsing. Comput Stand 
Interfaces 35(5C):442–453
	 8.	 de Marneffe MC, MacCartney B, Manning CD (2006) Generating typed dependency parses 
from phrase structure trees. In: Proceedings of LREC, vol 6
	 9.	 Lesmo L (2009) The Turin University parser. In: Proceedings of EVALITA, vol 9
	10.	 Socher R, Alex P, Jean W, Jason C, Christopher M, Andrew N, Potts C ((2013)) Recursive 
deep models for semantic compositionality over a sentiment treebank. In : Proceedings of 
EMNLP 2013, pp 1631–1642
	11.	 Artemy K, Anna Z, Alexander F (2015) Semantic parser for sentiment analysis and the emo-
tional computer agents. In: Porc AINL-ISMW FRUCT
	12.	 Agarwal B, Poria S, Mittal N, Gelbukh A, Hussain A (2015) Concept-level sentiment anal-
ysis with dependency-based semantic parsing: a novel approach. Cognitive Computation, 
ISSN: 1866-9956, pp 487–499

509
Sentiment Component Extraction from Dependency Parse for Hindi
	13.	 Dong L, Wei F, Liu S, Zhou M, Xu K (2015) A statistical parsing framework for sentiment 
classification. Comput Linguist 41(2):293–336
	14.	 Zhang L, Tu K, Zhang Y (2019) Latent variable sentiment grammar. In: The 57th annual 
meeting of the association for computational linguistics (ACL 2019), Florence, Italy, July 
28–August 2
	15.	 Panikar R, Bhavsar R, Pawar BV (2022) Sentiment analysis: a cognitive perspective. 
In: 2022 8th International Conference on advanced computing and communication systems 
(ICACCS), pp 1258–1262. https://doi.org/10.1109/ICACCS54159.2022.9785027
	16.	 Nivre J, de Marneffe M-C, Ginter F, Goldberg Y, Hajiˇc J, Manning C, McDonald R, Petrov 
S, Pyysalo S, Silveira N, Tsarfaty R, Zeman D (2016) Universal dependencies v1: a mul-
tilingual treebank collection. In: Proceedings of the 10th international conference on lan-
guage resources and evaluation (LREC 2016), pp 1659–1666
	17.	 Universal Dependency. https://universaldependencies.org/u/dep0/. Accessed on 14 Nov 
2022

Change Detection Algorithm
for Vegetation Mapping Using
Multispectral Image Processing
Neelam B. V. D. Soujitha, Mohammad Neelofar Jaha,
Mahali Tirumala Raju, Kakumanu Christy Victor, and Radhesyam Vaddi
Abstract Agriculture is an important sector of the world. Agriculture’s contribution
to the nation’s prosperity cannot be overlooked, despite the industry’s signiﬁcant role
in the global economy. Agriculture in any geographic area is constantly changing.
Changes are detected to build a knowledge base in a bid to ensure that certain agricul-
tural traits are preserved in particular location. The process of identifying differences
in two different places is known as change detection. This method is typically used
to change the earth’s surface two or more times. Here, the primary source of data
is geographic which is taken from Google Earth Engine (GEE) and is typically in
digital (e.g., satellite imagery) can be used. The history of change detection begins
with the history of remote sensing.
Keywords Change detection · Quantum geographic information system · Google
Earth Engine · Remote sensing images · Google colab · Multispectral images
1
Introduction
Remote sensing data has been widely used as a primary resource for change detec-
tion in the recent decades. Understanding the connections and interactions between
human and natural events is critical for making better decisions, and accurate detec-
tion of features on earth is required. The method of ﬁnding differences between
scenes of the same location taken at several periods is known as remote sensing
change detection (RSCD). Change detection is a method that assesses how a certain
area’s characteristics have evolved over the course of two or more time periods. Aerial
or satellite images of the area obtained at various dates are frequently compared in
order to discover changes. Recognizing the type and location of changes, quanti-
fying changes, and evaluating the accuracy of change. The general goals of change
detection in remote sensing are results. Absolute and relative change detection are
the two types of change detection. Absolute change detection draws attention to the
N. B. V. D. Soujitha (B) · M. N. Jaha · M. T. Raju · K. C. Victor · R. Vaddi
Department of IT, VR Siddhartha Engineering College, JNTU-Kakinada, Vijayawada, India
e-mail: durgasoujitha234@gmail.com
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_37
511

512
N. B. V. D. Soujitha et al.
speciﬁc changes, such as the transition from forest to grassland. Although something
has changed, relative change detection does not identify what that change is.
Utilizing several temporal datasets, change detection entails quantifying temporal
impacts. Satellite data is frequently employed when someone is interested in tracking
changes over vast areas and at frequent intervals. Executing checks against two
states—the new state and the current state—is the main change detection technique.
One of these states must be rendered if it diverges from the other, indicating that
something has changed. Change detection is of two different forms. The ﬁrst is
supervised change detection, and the second is unsupervised change detection. The
outcomes of the GIS study demonstrate the use of change detection information in
crop insurance by assisting in the assessment of ﬁeld damage. In order to conserve
crops and reduce yield losses, farm management decisions can ultimately beneﬁt
from the GIS information gathered.
Due to its ability to quantitatively analyze the geographical dispersion of the
target population, change detection is a crucial procedure in the management and
monitoring of natural resources and urban growth. Change detection is useful in
many areas, including assessing deforestation, monitoring shifting cultivation.
1.1
Applications of Remote Sensing
In order to determine, measure, and analyze speciﬁc items, areas, or phenomena prop-
erties without coming into contact with them directly, remote sensing is the science
and technology that enables this. Land use mapping, weather forecasting, environ-
mental research, studying natural hazards, and resource exploration are some of
the uses for remote sensing. The electromagnetic radiations that an object emits or
reﬂects serve as the source of remote sensing data, which is subsequently used to
identify and categorize the object. Its data can be used to track changes over time
and receive the most recent land use patterns over broad areas at any one time. It can
be used to update wetland delineation, asphalt conditions, and road maps. Regional
planners and administrators utilize this data to frame policy decisions for the region’s
overall development.
2
Related Work
Deep Belief Network Land Cover Clustering for Change Detection (2022) [1]:
Authors make use of unlabeled data clustering, deep brief network (deep learning
model) for change detection. It complicates the entire clustering process, and as a
result, the accuracy of change detection sometimes suffers.

Change Detection Algorithm for Vegetation Mapping Using …
513
Detection of Optical Satellite Image Changes Using a Transformer-Based Siamese
Network (2022) [2]:
Convolutional neural networks (CNNs), natural language processing (NLP), and
vision transformation (ViT) are employed. Siamese extensions of ViT networks that
outperform in tests on two open change detection datasets. The effectiveness and
superiority are demonstrated by experimental results on real datasets.
Detecting Changes in Multispectral Images Using Hyperspectral Reconstruction
(2022) [3]:
The multispectral data is used to generate hyperspectral data that contains more spec-
tral information and is then used to detect changes. For image reconstruction, they
employ reconstruction algorithms. Experiment results show that the hyperspectral
reconstruction method increases the accuracy of multispectral images.
A CNN-Transformer Network for Fine-Grained Cropland Change Detection Using
Multiscale Context Aggregation (2022) [4]:
The feature extractor used by the authors is a CNN-transformer network, multiscale
context aggregation (MSCANet). All results clearly exhibited the MSCANet’s ability
in detecting agriculture changes in an efﬁcient and effective manner.
Unsupervised Change Detection Using Style Transformation-Based Spatial-Spectral
Feature Learning (2022) [5]:
Authors employ a style transition-based change detection algorithm with spatial-
spectral feature learning (STFL-CD), a detection network with an attention mecha-
nism, and convolutional neural networks (CNNs).They tried to remove the inﬂuence
of “same object with different spectra” and had some shortcomings.
Deep Learning-Based changing Detection from Rising Remote Sensing Images: A
Survey (2022) [6]:
Detecting changes in high-resolution images using deep learning. It goes over the
most popular extraction of features deep neural networks in addition to the mech-
anisms used to build them describes the change detection framework at ﬁrst. After
that, the methods are classiﬁed based on the deep network architectures used.
Sentinel-2 Image Detect the presence of Urban Built Area Change Utilizing Multi-
band Temporal Surface and One Random Forest (2021) [7]:
The suggested multitemporal image classiﬁcation model (iOCRF) is based on one-
class random forest and focuses on the change in built-up area. It is data embedding
insensitiveandsuitablealsoformultibandtemporaltexture.Moreresearchisrequired
to assess the proposed method’s performance in other areas of study and changes of
interest.
Land Cover Classiﬁcation Using Images for Remote Application Areas (2021) [8]:

514
N. B. V. D. Soujitha et al.
They deals with convolution neural network (CNN) in deep learning, supervised,
and unsupervised classiﬁcation methods.
Classiﬁcation of Land Utilization and Land Cover Utilizing Recurrent Artiﬁcial
Neural Networks with Common Layered Architecture (2021) [9]:
Authors uses recurrent neural network (RNN). SLRNN outperforms others in terms
of accuracy. Not all pixels considered by SLRNN were correctly classiﬁed, but some
were incorrectly classiﬁed.
Deep Learning Approaches to Earth Observation Change Detection(2021) [6]:
Two distinct approaches to detecting change (semantic segmentation and classiﬁca-
tion). Both use convolutional neural networks to address these speciﬁc requirements.
Further developed and applied in post-processing workﬂows for a wide range of
applications.
Recent Landsat 8/OLI Applications for Land Utilization and Land Cover Mapping:
A Comprehensive Assessment (2020) [10]:
Providing scientiﬁc advice to the scientiﬁc world on how to use L8/OLI data to gain
an in-depth understanding of land utilization land cover (LULC) mapping. Detecting
changes in various cityscapes, especially agricultural and natural plant communities
scenarios. Classiﬁcation models achieve higher accuracies when using representative
samples.
A Method for Detecting Land Cover Changes Using Spectral Values and Conditional
Probabilities (2020) [11]:
The spectral-based direct comparison (SDC) and category possibility direct compar-
ison (CPDC) methods are employed in this case.
Deep Learning for identifying changes in images from remote sensing (2020) [12]:
Using a huge number of hierarchical layers, discover advanced structures of remote
sensing imagery automatically. Among all classiﬁers, the random forest classiﬁer
has the highest accuracy. The artiﬁcial neural network (ANN) predicted soil fertility,
crop yield, and crop yield with the highest accuracy.
Neural Network-based for Detecting Land Cover Change (2020) [13]:
The presented approaches for long short-term memory (LSTM) are capable of
adapting to a variable number of sequences. The preprocessing method chosen
improves water classiﬁcation while ignoring the dataset.
A Supervised Learning Layout for Detecting Visual Change (2018) [14]:
Change-Net is a deep architecture for detecting differences between pairs of images.
Change-Net outperforms the competition.

Change Detection Algorithm for Vegetation Mapping Using …
515
Fig. 1 Images of Switzerland from Google Earth Engine(2012)
Fig. 2 Images of Switzerland from Google Earth Engine(2015)
3
Proposed Work
3.1
Datasets
We have used Google Earth Engine (GEE) for taking the input satellite images.
Google Earth Engine enables users to visualize and analyze satellite images of our
planet. It is a platform for geospatial analysis in the cloud that allows users to see
and examine satellite photos of our world (Figs. 1 and 2).
3.2
System Architecture
Deep active learning is supported in the implementation of the Siamese U-Net model
with the pre-trained ResNet34 architecture as an encoder for the change detection
task on the remote sensing dataset (Fig. 3).

516
N. B. V. D. Soujitha et al.
Fig. 3 Architecture diagram of Siamese neural network [1]
A Siamese neural network uses ResNet34 as an encoder. Time stamp T1’s image
X1 generates the feature vector f (X1) that corresponds to image X1. The picture X2
of timestamp T2 similarly generates the feature vector f (X2) corresponding to image
X2. The identical convolution layers receive both X1 and X2 simultaneously. The
sent convolution layers have the same parameters. The feature vector is a 128-bit
encoded vector. Our Siamese neural network’s output is a difference vector of both
the feature vectors.
4
Algorithm and Its Description
A precomputed version of one of the output vectors frequently serves as a benchmark
for comparison with the other output vector. These networks compare the feature
vectors of the inputs to determine how similar they are. We conduct veriﬁcation,
identiﬁcation, or recognition tasks using Siamese networks; the most well-known
applications are face recognition and signature veriﬁcation.
A Siamese network consists of two comparable neural networks that each take
one of the two input images. The contrastive loss function uses the ﬁnal layers from
both networks to determine how similar the two images are. The Siamese architecture
seeks to distinguish between input images rather than categorize them (Fig. 4).
The two sister networks that are identical neural networks with the same weights.
One of these networks receives a feed of each image in the image pair. It optimizes
the networks using a contrastive loss function.
The contrastive loss function is given as follows:
(1 −Y)1/2(Dw)2 + (Y)1/2{max(0, m −Dw)}2
(1)

Change Detection Algorithm for Vegetation Mapping Using …
517
Fig. 4 Dataﬂow diagram of Siamese detector, here the white indicates the presence of change,
whereas black indicates the absence of change [4]
Dw referred to as Euclidean distance between the sibling Siamese networks’
outputs.
Mathematically, the Euclidean distance is:
({Gw(X1)−Gw(X2)})1/2
(2)
where Gw is one of the sister networks’ outputs. The data pair for input is X1 and
X2.
Algorithm: Siamese Neural Network
Input: High-Resolution satellite images
Output: Change map
1. Begin
2. Assume that Q = (cQ, tQ) and R = are the two input images (cR, tR)
3. DeterminetheEuclideanseparationbetweenthetwomatrixportrayalsasfollows:
D φ(Q, R) = ∥{φ(CQ) ⊕φ(tQ)} −{φ(CR) ⊕φ(tR)}∥2, to determine how
semantically linked the two matrices are.
The caption determines query and candidate matrix is (cQ) and (cR), respectively,
and the matrix representations are (tQ) and (tR), respectively.
4. To ensure that D(Q, R) is modest, The contrastive loss function is deﬁned as a
quadratic equation of table couple ranges.(close to zero)
5. If margin m is equal to or more than zero else and R is comparable to Q.
L(y, φ, Q, R) = 12(1 −y)Dφ2(Q, R) + 12y{max(0, m −Dφ(Q, R))}2 (3)
6. The pair’s genuine label is y.
7. The pairs with greater distance scores are judged dissimilar.
8. Output is the Images’ Difference Label. L (Q, R) (Q, R).

518
N. B. V. D. Soujitha et al.
As everything evolves through time, it can be quite beneﬁcial to comprehend and
measure this change. For instance, examining the infrastructural development of a
city or town over time can be used to estimate its level of economic success. Every
model has to be having the ability to recognize the changes in which we are interested
while being able to ignore those that are not relevant to our use case. To detect changes
in structures over time, it may be necessary to ignore changes in things like roads,
trees, and water bodies. This is more of a data normalization issue because images
taken over time would have variations that would be difﬁcult to constantly account
for. When capturing facial photos with a smartphone, the lighting and orientation
settings will never be the same. Photos acquired by satellites may be affected by
changes in cloud cover, sunlight reﬂection, and the azimuthal and elevational angles
of the satellite itself.
The simplest and most direct way to measure change, using a pixel difference
between elements, is no longer an option. There are more clever ways to do this,
but the results are still quite subpar. Two photos (taken at two separate timestamps)
are fed into a Siamese neural network, which uses a series of convolutional layers to
create higher-order feature vectors for each image. The magnitude of change is then
determined by comparing the feature vectors using the Euclidean norm. According
to the hypothesis, comparing two images when there has been no obvious change
would lead to similar vectors in the feature vector’s dimensional space.
It attempts to reduce the distinction between two different extracted features if
there is no change and vice versa. The illustration that follows makes an attempt to
illustrate it using a scenario involving two classes. If neither of the two photographs
showed the modiﬁcations we were practicing for, the real label would be 1.
The strengths of this algorithm are well-paired with the best classiﬁer, learning
from semantic similarity, more resistant to class inequality. Weakness of this method
are requires longer training than typical networks, avoid producing probabilities.
5
Result Analysis and Observations
From the Google Earth Engine, satellite pictures are downloaded. It provides us with
multispectral images of Switzerland. Images with two different time stamps were
acquired in order to identify the changes. The output of remote sensing identiﬁes the
locations of Land Use and Land Cover (LULC) changes.
The Siamese neural network generates accurate results. The confusion matrix is
created via the suggested approach. A table that gives how many predictions a model
got right and wrong is called a confusion matrix. It is used to assess the efﬁcacy
of a categorization model. When the expected value and the actual value are both
positive, TP takes place. When the actual and projected values are both negative, TN
happens. When an optimistic prediction is made but the actual is adverse referred to
as the Type 1 error as well. FN is the outcome when both the fact and the prediction
are true referred to as the Type 2 error as well.

Change Detection Algorithm for Vegetation Mapping Using …
519
Figures 5 and 6 show the satellite image at time stamp T1, i.e., (a), the satellite
image at time stamp T2, i.e., (b), and the third image is the change map we obtained,
i.e., (c) (Table 1).
The Siamese neural network produces the metrics shown below. The basic
metric for model evaluation is widely used to measure accuracy, which counts the
percentage of accurate forecasts over all other predictions. Precision is measured
by the frequency of correct positive forecasts (true positives). A measurement that
combines recall and precision is the F1-Score (Table 2).
• F-Measure offers a single score that integrates precision and memory problems
into a single value.
Fig. 5 Impact on agricultural land took place as a result of urban expansion [1]
(a)
(b)
(c)
Fig. 6 Changes occurred in agricultural land due to construction of building [1]
Table 1 Confusion matrix
Change
No change
Change
90
1
No change
12
106

520
N. B. V. D. Soujitha et al.
Table 2 Metrics
Metrics
Formula
Values
Accuracy
(TP + TN)/(total)
0.938
• It was noted that a binary image was generated, with the white portion
corresponding to the change and the black portion corresponding to no change.
• It was found that the model had a 93.8% accuracy rate.
• The model’s accuracy was found to be 98.9%.
• Recall quantiﬁes the number of times the dataset’s valid examples were used to
make accurate class predictions. The model’s accuracy was demonstrated to be
88.2%.
6
Conclusion
In this project, Switzerland was chosen as a speciﬁc place from Google Earth Engine,
and we utilized two different timestamps to check for changes. These photos, which
were taken using multispectral remote sensing technology, were used in our investi-
gation. We used a Siamese neural network to achieve change detection of the input
location. Through the Siamese neural network, featured vectors of the two input
images are calculated and the Euclidean distance between the two featured vectors
are computed. In the change map, the white color denotes the change and the black
color denotes there is no change. Several acquisition functions and methods for calcu-
lating prediction uncertainty have performed admirably in our tests. All qualiﬁed
strategies signiﬁcantly outperform a naive random baseline.
7
Future Scope
The project’s objective is to identify changes in agricultural areas using remote
sensing photographs. Consequently, there is a chance for change in agricultural
areas. Our future research will include calculating the percentage change and
percentage change in water bodies, mountains, before and after natural disasters,
and other characteristics.
References
1. Vít R˚užiˇcka SD, Wegner JD, Schindler K (2020) Deep active learning in remote sensing for
data efﬁcient change detection. Int J Remote Sens [v1] Tue
2. Ma L, Liu Y, Zhang X, Ye Y, Yin G, Johnson BA (2019) Deep active learning in remote sensing
for data efﬁcient change detection. ISPRS J Photogramm Remote Sens 152:166–177

Change Detection Algorithm for Vegetation Mapping Using …
521
3. Zhang L, Du B (2016) Deep learning for remote sensing data: a technical tutorial on the state
of the art. IEEE Geosci Remote Sens Mag 4(2):22–40
4. De Jong KL, Bosman AS (2018) Unsupervised change detection in satellite images using
convolutional neural networks
5. Kadhim N, Mourshed M, Bray M (2016) Advances in remote sensing applications for urban
sustainability. Euro-Medit J Environ Integr 1(7):1–22
6. Wen L, Matsuoka M, Adriano B (2019) Damage detection due to the typhoon Haiyan from high-
resolution SAR images. IEEE J Select Topics Appl Earth Observ Remote Sens 3(1):123–133.
https://doi.org/8.1207/MGRS.2019.2931830
7. Tough RJA, Blacknell D, Quegan S (2019) A statistical description of polarimetric and inter-
ferometric synthetic aperture radar. IEEE J Select Topics Appl Earth Observ Remote Sens
7(1):67–93. https://doi.org/6.1107/MGRS.2019.1431430
8. de Jong KL, Bosman AS (2019) Unsupervised change detection in unlabeled optical remote
sensing using CNN. IEEE Trans Geosci Remote Sens 2(1):102–114. https://doi.org/6.1219/
MGRS.2019.1214110
9. Bovolo F, Bruzzone L (2007) A theoretical framework for unsupervised change detection based
on change vector analysis in the polar domain. IEEE Trans Geosci Remote Sens 45(1):218–236
10. Zhang W, Fan H (2020) Application of ısolated forest algorithm in deep learning change
detection of high resolution remote sensing ımage. In: 2020 IEEE ınternational conference on
artiﬁcial ıntelligence and computer applications (ICAICA), Dalian, China, pp 753–756. https://
doi.org/10.1109/ICAICA50127.2020.9181873
11. Shang R, Xie K, Okoth MA, Jiao L (2019) Sar ımage change detection based on mean shift
pre-classiﬁcation and fuzzy C-means. In: IGARSS 2019—2019 IEEE ınternational geoscience
and remote sensing symposium, Yokohama, Japan, pp 2358–2361. https://doi.org/10.1109/IGA
RSS.2019.8898464
12. Li S, Huo L (2021) Remote sensing ımage change detection based on fully convolutional
network with pyramid attention. In: 2021 IEEE ınternational geoscience and remote sensing
symposium IGARSS, Brussels, Belgium, pp 4352–4355. https://doi.org/10.1109/IGARSS
47720.2021.9554522
13. Huang J, Fu Q, Wang X, Ji Y (2022) Remote sensing building change detection based on
improved U-Net. In: 2022 3rd ınternational conference on big data, artiﬁcial ıntelligence and
ınternet of things engineering (ICBAIE), Xi’an, China, pp 772–775. https://doi.org/10.1109/
ICBAIE56435.2022.9985853
14. Huang L, Zhang G, Li Y (2010) An object-based change detection approach by integrating
intensity and texture differences.In: 2010 2nd ınternational asia conference on ınformatics in
control, automation and robotics (CAR 2010), Wuhan, pp 258–261. https://doi.org/10.1109/
CAR.2010.5456680

Real-Time Sign Language Detection
Using OpenCV
Pavan Kumar Meka, Yesu Raju Parusu, and Radhesyam Vaddi
Abstract Sign language is a communication commonly used by people, who are
deaf and dumb. They communicate with hand gestures within their community and
with the remaining people in the world. Real-time sign language detection is the
solution that enables communication between normal people and those who are deaf
and dumb. It deals with image acquisition and continues until text generation. Previ-
ously provided solutions are sensor based, and they do not result in good accuracy.
The existing models are customized with limited gestures. In order to overcome this
problem, this study has developed a model to detect the 40 different classes of signs,
which include alphabets, numbers and some special symbols. This model can effec-
tively recognize gestures. The dataset is created in a well-planned manner to include
ten numbers, 24 alphabets and six special symbols. The sign language recognition
steps include data collection, image preprocessing and segmentation, training model
and at last classiﬁcation and result recognition. The captured images are preprocessed
to remove the extra background. A Convolutional Neural Network (CNN) algorithm
is used to train the model and perform multi-class classiﬁcation on image data. The
results are then displayed in the monitor along with text recognition. Some future
improvements are also suggested.
Keywords Sign language · Classiﬁcation · Convolutional Neural Networks
(CNNs) · Hand gestures · Communication · Real time
P. K. Meka · Y. R. Parusu (B) · R. Vaddi
Department of IT, VR Siddhartha Engineering College, JNTU-Kakinada, Vijayawada, India
e-mail: yesurajuparusu@gmail.com
P. K. Meka
e-mail: pavanmeka74@gmail.com
R. Vaddi
e-mail: syam.radhe@gmail.com
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_38
523

524
P. K. Meka et al.
1
Introduction
Communication plays a signiﬁcant role in sharing the information and expressing
oneself. Deaf and dumb people use sign language to express their ideas and thoughts
with their community and with remaining world. Sign language is actually a hand
gesture that conveys the meaning of the message. Around 450 different classes
of sign languages are used globally; in India, there are around 250 certiﬁed sign
language interpreters for deaf people, and still, it is a very difﬁcult task to teach the
sign language for all the deaf and dumb people due to the limited availability of
interpreters.
To overcome this problem, a model has to be developed to detect the signs auto-
matically. Previously developed models are all sensor based, and they need gloves
and high-resolution cameras to capture and identify the hand gesture. They are all
limited to certain hand gestures only. Some models are able to detect only statics
images; when it comes to dynamic images, they do not work properly. These are all
drawbacks of the previously developed models.
For images, Convolutional Neural Networks remain as the most popular neural
networks. The Convolutional Neural Network (CNN) algorithm is basically a three-
layer network, including a convolutional layer, pooling layer and fully connected
layer. The proposed dataset includes 40 different classes, which include 24 alphabets,
nine numbers and six special symbols. With the help of deep learning model, we
can easily identify the gestures. So, this system will help deaf and dumb people to
communicate easily with remaining people in the world.
2
Literature Study
This section initiates a study on various previously available models, methodologies
and techniques to sign language, which were referenced to develop the proposed
model.
Hand Gesture Recognition Using PCA (2020) [1]:
Authors mainly concentrated on the static hand sign gesture detection system using
image processing. For hand signs, a vector called SIFT algorithm is used. Authors
proposed a model which helps the deaf and dumb people while communicating with
rest of the world. And this model is completely based on traditional methods. Model
not works well for dynamic signs and gives output with less accuracy.
An Automated System for Indian Sign Language Recognition (2018) [2]:
Here a model is developed that detects signs based on the shape and particular
features of the object presented. Features of segmented hand gestures are calculated
using Hu’s invariant method that are given as input to Artiﬁcial Neural Network for
classiﬁcation.

Real-Time Sign Language Detection Using OpenCV
525
Design of ANFIS system for recognition of single hand and two hand signs (2019)
[3]:
Author developed a model that helps the deaf and dumb people to communicate
with the rest of the world using hand gesture detection. The important thing in this
system is conversion of real-time hand sign into text format. They have used the
neural networks and histogram of gradients (HOG) for building their model, and it
has the capacity to recognize up to 20 signs that contain the mixture of both numbers
and some alphabets.
Finding relevant image content for mobile sign language recognition: Signal
Processing, Pattern Recognition and Application [4]:
This work deals with deep learning algorithms like CNN, RNN which work better
on image data. The algorithms like CNN have better ability and better understanding
of the image and perform the better classiﬁcation among different classes of signs.
But, the accuracy for this model is not up to the mark. It works well for the static
images.
Learning to Estimate 3D Hand Gesture from RGB images [5]:
In this paper, the author mainly concentrated on the estimating 3D hand gesture
from single Red Green Blue (RGB) or Colored images. And ﬁnally, he developed
a deep model that understands or recognizes the network 3D articulation. The main
drawback is its ambiguities because of blank depth details.
Vision-based hand gesture recognition. (2021) [6]:
A real-time vision-based system is proposed to perform hand gesture recognition to
perform human–computer interaction in many applications. The system can recog-
nize 35 different Indian hand gestures as well as American Sign Language with less
accuracy.
American Sign Language Translator [7]:
The author has researched 5 years to build an automated sign language translator
and ﬁnally developed a model based on Convolutional Neural Networks (CNNs)
and Support Vector Machine (SVM). These two algorithms work well for comparing
images and perform better classiﬁcation. The standard video camera is used to obtain
the data. The obtained data are provided as an input for the model.
Fingerspelling detection in the wild with iteration visual attention [8]:
This research work focuses on ﬁngerspelling patterns in American Sign Language
(ASL) videos, which are gathered from various resources like social media, YouTube
and many other wild life channels. They proposed a model based on an iterative
mechanism.
Sign Language detection via Skeleton-Aware Multi-Model [9]:

526
P. K. Meka et al.
The authors developed a model to extract main features in the image via deep neural
networks. It performs well in detecting body postures, hand sings and facial expres-
sions. The major drawback in this model is it suffers a lot with inadequate and noisy
data.
Neural Sign Language Translation [10]:
A model has been developed to generate the spoken language from videos that contain
sign languages. It continuously detects sign, but the only drawback is it ignores the
linguistic and grammatical structures of sign language.
Sign Language generation, recognition and translation [11]:
This project requires information about various ﬁelds like computer vision, natural
language processing, deaf culture and computer graphics. And, results produced by
this model were displayed at workshops. They have used a CNN model.
A comprehensive study on deep learning model for sign language detection [12]:
Here, authors conducted a comparative analysis of computer vision-based methods,
especially for sign recognitions. And, this entire study is focused on giving insights
on sign recognition and mapping non-segmented streams of videos. And, this also
provides the speech-to-text recognition.
Hand gesture recognition using image processing and feature extraction techniques
[13]:
This paper is mostly focused on use of traditional preprocessing techniques to detect
the correct hand gesture effectively. K-nearest neighbor (k-NN) is the algorithm used
in this model. Basically, this algorithm stores all the data and classiﬁes them based
on their highest similarity. And, this model works well for static images, whereas in
the case of dynamic images, model does not work properly.
3
Proposed Work
The proposed model uses the OpenCV to read and capture the hand gestures using
webcam. After that, we will preprocess image to remove the extra background from
the image so that the model will focus on the main part of the gesture. A model is
trained by using Convolutional Neural Network (CNN) to classify different classes
of hand gestures. Convolutional Neural Networks work well for the images rather
than any other neural networks. It classiﬁes the hand gestures in a more accurate and
effective way whenever the gestures are shown to webcam.

Real-Time Sign Language Detection Using OpenCV
527
Table 1 Dataset structure
Gesture type
No. of data samples
Alphabets
(A–Z)
Each gesture contains 200 images
26 * 200 = 5200
Numbers
(1–9)
Each gesture contains 200 images
9 * 200 = 1800
Okay
200
Call me
200
Rock
200
Smile
200
Thumbs down
200
Thumbs up
200
3.1
Dataset
The proposed model was trained on 8000 color images of different classes of hand
gestures, which include 26 alphabets, nine numbers and six special symbols or
English phrases. This model has created own dataset by capturing different classes
of hand gestures in different angles and light adjustments.
Table 1 shows gestures’ type and number of copies made for each type. Actually,
this model runs mainly on two different programs one for data creation and another
one for testing model. The datasets are created by using data creation program. For
each sign, 200 images are created at different angles. The same dataset will be used
to train the proposed model. The type of the gestures above mentioned are alphabets,
numbers and six specials like call me, Rock, Thumbs up, etc., so at last we have 8000
images of different classes of hand symbols to train the model.
3.2
Preprocessing
The captured images were preprocessed to remove the additional background in the
hand gestures by using image ﬁltering and segmentation. So, this will modify or
enhance image properties and extract the valuable information from the images such
as corners, edges. A ﬁlter is nothing but kernel or some particular pattern, which is
applied to each pixel and its neighbors within an image.
A total of 200 images shown in Fig. 1 were preprocessed to enhance the image
properties.
These are all the different hand signs created, which have also mentioned their
respective meaning in the sign language. For example, you can see for the digit 1
symbol or sign is showing index ﬁnger. So, we have created dataset for all alphabets,
numbers and some special symbols. We have taken all these hand signs from ˙Indian
Sign Language (ISL).

528
P. K. Meka et al.
Fig. 1 Created dataset
3.3
Design Methodology
This model mainly uses the Convolutional Neural Networks (CNNs) and TensorFlow
(as Keras uses the TensorFlow as their backend) for training purpose. The design
methodology of the proposed model has been described below in Fig. 2.
The ﬁrst step is to capture hand gestures of different classes using different angles.
After that, each image is preprocessed to enhance the image properties. Then, all the
images are stored in database with labeling. Further, these images are used to train
the model. A CNN model has been developed by including three main layers, named
convolutional layer, pooling layer and fully connected layers.
This deep learning model is completely trained and tested using our own dataset.
Once the required accuracy is obtained, the model can be used to make predictions
based on the hand gestures.
3.4
Hand Gesture Extraction from Images
As this research work focuses on sign language detection, hand gestures are mainly
focused. The inputs are taken with the help of webcam. When it comes to the model,
it only needs the valuable information (hand gestures) from the given picture to detect
a particular sign. When we are running the model, two outputs will be displayed.

Real-Time Sign Language Detection Using OpenCV
529
Fig. 2 Architecture diagram
One is original pictures and other one is white image also called as preprocessed
image. ˙In the preprocessed image, extra background will be removed and some rays
will be added to the hand gestures which are the main base for the classiﬁcation.
Figure3showsthatwhateverthepictureistakenbythewebcam,itwillbefurtherly
modiﬁed and only hand gesture part will be given to the model as an input. This
image will then be given as input to image preprocessing to remove the background
of the image and enhance the image quality. Finally, all preprocessed images will be
used to perform model training.
Algorithm:
Step 1: Create a separate ﬁle for dataset in project folder.
Fig. 3 Extraction hand gestures from pictures

530
P. K. Meka et al.
Step 2: Create required dataset by capturing images of hand gestures using webcam.
Step 3: Add labels to each image and store them in a database (separate ﬁle).
Step 4: Perform image pre-processing to each image that is captured.
Step 5: BuildaCNN(convolutional Neural Networks) model usingour owndataset.
Step 6: Train and test the model using customised dataset.
Output image using pooling layer =N −F + 1.
Output image using convolutional layer = N + 2P −F + 1, S = 2, P =
2.
Where n = size of input, F = size of kernel/ﬁlter, P = padding, S =
stride.
Step 7: Use this model to detect the sign language.
Step 8: Use the webcam to test the trained sign language recognition model.
The algorithm used for this model is Convolutional Neural Networks (CNNs).
There are many neural networks and algorithms for detecting various signs and
gestures. But, CNN has better ability to compare images and efﬁciently classify
various types of hand gestures than any other neural networks algorithm. That is
why we have chosen CNN algorithm for our project. And, this CNN mainly contains
three layers. They are convolutional layer, pooling layer and fully connected layer.
These three layers are core of the CNN, and during this process, the input image
is passing through these layers. ˙In each layer, the input image will be converted
into speciﬁc format after it passes through different layers of CNN. So, that image
will be used as input for the next layer in the CNN. The formulas and mathematical
expressions of these layers are mentioned in the above algorithm format. A teachable
machine is used for building the proposed model with our own dataset. Based on our
datasets, the teachable machine will build a machine learning model and we have
used this model for testing purpose in order to detect the sign. The inputs for the
model are given with the help of webcam so that it will detect sign and displays its
correct meaning as a output.
The trained model gives the accuracy of overall 90.56%.
4
Results and Observations
Figure 4 presents the outputs produced by the proposed model. After training the
model, we have tested it with different signs at different angles.
The model has been executed for 40 different signs, and some signs have almost
same hand structure, for example, symbol “2” and symbol “v” have almost same hand
structure. Due to this reason, the model sometimes produces the incorrect outputs.
The model was executed for 20 spans until required accuracy was obtained. The
Interpretation Standards like precision, recall and F1-score of the model are displayed
in Table 2. These are all various output parameters of our model. The main accuracy
we got for this model is 90.56%.

Real-Time Sign Language Detection Using OpenCV
531
Fig. 4 Outputs produced by model

532
P. K. Meka et al.
Table 2 Interpretation
standards of the model
Interpretation standards
Proposed model
Precision
0.89
F1-score
0.85
Recall
0.91
Support
91.62
Testing accuracy
90.56
Weighted average
89.43
Figure 5 is the confusion matrices produced for both alphabets and numbers type
of hand signs. As you can see in the most of the times, model detects the correct sign
andthatisindicatedwithdarkgreenboxesintheconfusionmatrix.Thereisadiagonal
line in the confusion matrix. ˙In this line, predicted sign is same as actual data or sign.
The diagonal in the Confusion matrix represents the model predicted value and actual
value are same. This shows that if there is dark green in the diagonal, then the accuracy
of the model will be high and vice-versa. Otherwise, it will result in low accuracy.
Small deviations from dark green boxes show that the incorrect sign detected by
the model exists due to ambiguity of same hand structures of signs. Sometimes,
the model’s detection maybe false; in that cases, the confusion matrix shows some
deviations from dark green diagonal boxes, but the model executes exceptionally
well as the training progresses. The validation set loss ﬂuctuates heavily during the
entire training period.
The testing accuracy is of 90.56%, precision of 0.89, recall of 0.91 and an F1-score
of 0.85.
Fig. 5 Confusion matrix

Real-Time Sign Language Detection Using OpenCV
533
5
Advantages
i.
It helps the children who have autism spectrum disorder (ASD).
ii.
It gives the literacy for dumb and deaf people.
iii. Elderly people beneﬁted greatly from the use of sign language detection model.
iv.
Sign language model gives efﬁcient and accurate way to convert sign language
into text in real time.
6
Conclusion
˙In this study, a real-time sign language detection model has been developed to recog-
nize various signs and ﬁnally helps deaf and dumb communities to interact with
remaining people in the society. This model plays an important role in the society
to help people, who are suffering with autism spectrum disorder (ASD). The aim
of the model is to recognize various sign language signs and transform them into
text. It gives high accuracy of 90.56%, precision of 0.89 good response time when
applied on practical scenarios. There are many traditional models available, but they
are sensor based and they do not work well in all the cases. Sometimes, they are
only restricted to static hand gestures. In contrast, the proposed model can detect up
to 40 different signs including alphabets, number and even some special signs. In
future, apps can be developed based on these models to assist deaf and dumb children
in their studies. It can also be deployed as an API using cloud such that it can be
integrated with other applications easily and ﬁnally maintain a good communication
among deaf and dumb communities.
7
Future Scope
1. We can make this project as mobile application so that people can easily under-
stand sign language using their mobiles. Mobile camera will be used as input for
the model and model will recognize hand sign and put the recognized result in
the mobile screen.
2. We can develop a model that directly converts sign language into voice. We need
to attach speaker to the model. And, the outputs will come from the speaker
(voice form) when model recognizes that particular sign.
References
1. Agrawal SC, Jalal AS, Tripathi RK (2016) A survey on manual and non-manual sign language
recognition for isolated and continuous sign. Int J Appl Pattern Recogn 3(2):99–134

534
P. K. Meka et al.
2. Cheok MJ, Omar Z, Jaward MH (2019) A review on hand signs and sign language dectection
techniques. Int J Mach Learn Cybern 10(1):131–153
3. Kausar S, Younus Javed M (2011) A survey on sign language recognition. In: 2011 frontiers
of ınformation technology. IEEE, pp 95–98
4. Rastgoo R et al (2021) Sign language production: a review. In: Proceedings of the IEEE/CVF
conference on computer vision and pattern recognition
5. Ahmed MA et al (2018) A review on systems-based sensory gloves for sign language
recognition state of the art between 2007 and 2017. Sensors 18(7):2208
6. https://www.youtube.com/watch?v=wa2ARoUUdU8&t=2547s&ab_channel=Murtaza%27s
Workshop-RoboticsandAI
7. Aloysius N, Geetha M (2020) Understanding vision-based continuous sign language recogni-
tion. Multimedia Tools Appl 79(31):22177–2220
8. World-wide deep sign La.nguage detection from Video: a large datasets and Methods
comparision by Dongxu Li, Cristian Rodrigues (2019)
9. Ghanem S, Conly C, Athitsos V (2017) A survey on sign language recognition using smart-
phones. In: Proceedings of the 10th ınternational conference on pervasive technologies related
to assistive environments
10. Viswanathan DM, Idicula SM (2015) Recent developments in Indian sign language recognition:
an analysis. Int J Comput Sci Inf Technol 6(1):289–293
11. Jiang X et al (2020) A survey on artiﬁcial intelligence in Chinese sign language recognition.
Arabian J Sci Eng 45(12):9859–9894
12. https://towardsdatascience.com/sign-language-recognition-with-advanced-computer-vision-
7b74f20f3442
13. Mohandes M, Deriche M, Liu J (2014) Image-based and sensor-based approaches to Arabic
sign language recognition. IEEE Trans Human-Mach Syst 44(4):551–557

Efﬁcient Plant Disease Detection
and Classiﬁcation for Android
Dane Brown
and Siﬁsokuhle Mazibuko
Abstract This paper investigates the feasibility of using a CNN model to diagnose
plant diseases in the wild. Plant diseases are a major risk to ecosystems, human
and animal health, and the quality of life overall. They may reduce farm productiv-
ity drastically, leaving farmers with ﬁnancial losses and food insecurity. Small-scale
farmersandproducerscannotpayforanexperttolookattheirplantsforplantdiseases
because it would cost too much. A mobile solution is thus built for the Android plat-
form that utilises a uniﬁed deep learning model to diagnose plant diseases and provide
farmers with treatment information. The literature-recommended CNN architectures
were ﬁrst analysed on the PlantVillage dataset, and the best-performing model was
trained for integration into the application. While training on the tomato subset of
the PlantVillage dataset, the VGG16 and InceptionV3 networks achieved a higher
F1-score of 94.49% than the MobileNetsV3Large and EfﬁcientNetB0 networks
(without parameter tuning). The VGG model achieved 94.43% accuracy and 0.24
loss on the RGB PlantVillage dataset, outperforming the segmented and greyscaled
datasets, and was therefore chosen for use in the application. When tested on com-
plex data collected in the wild, the VGG16 model trained on the RGB dataset yielded
an accuracy of 63.02%. Thus, this research revealed the discrepancy between sim-
ple and real-world data, as well as the viability of present methodologies for future
research.
Keywords Android · CNN architecture · Classiﬁcation · Deep learning · Plant
disease
This work was undertaken in the Distributed Multimedia CoE at Rhodes University.
D. Brown (B) · S. Mazibuko
Rhodes University, Drosty Road, Grahamstown 6140, South Africa
e-mail: d.brown@ru.ac.za
URL: https://www.ru.ac.za/computerscience/people/academicstaff/drdanebrown/
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_39
535

536
D. Brown and S. Mazibuko
1
Introduction
Climate change inﬂuences food supply chains and increases the incidence of plant
disease, which has detrimental effects on the surrounding environment and results
in lower yields, therefore harming the economy, human health, and ecosystems [8].
As a result of agricultural practices such as monoculture and the production of
pathogen-vulnerable plants, the destructiveness of plant diseases increases. Increase
their rate of dissemination in accordance with contemporary worldwide commerce
[20]. Misdiagnosis of plant diseases may result in a number of unfavourable results,
including major effects on human health and the surrounding environment if pesti-
cides are carelessly sprayed in excessive amounts. It also increases costs for farmers
due to crop losses and inadequate disease control techniques [22].
Plant disease monitoring systems are also required to monitor pathogens through-
out a vast territory in order to reduce the risk that a pathogen would cause signiﬁcant
crop damage, thus reducing the infection’s impact on productivity, ecosystems, and
humans [20]. The Program for Monitoring Emerging Diseases (ProMED) is a global
diseasemonitoringorganisationthatstudiesillnessoccurrencestoanticipateprospec-
tive epidemics in order to limit disease transmission and serve as a warning system
for people.
The use of convolutional neural networks (CNNs) for autonomous plant disease
detection, as noted by [21], makes disease detection easier, cheaper, and more acces-
sible to farmers. Farmers now have more access to information, enabling them to
conduct crop loss prevention strategies and provide more data to disease monitoring
organisations.
CNNs are employed because they are robust and efﬁcient when processing large
image collections [17]. In this research, different CNN architectures and settings for
the datasets are looked at to ﬁnd the best architecture and settings for the built system.
The PlantVillage dataset is used to train models during testing and to make the ﬁnal
model for the system. It contains 54,305 images of 24 diseases on 14 different plant
species.
Theoptimummodelcanidentifyandcategoriseplantdiseasesinamobilesituation
with limited resources by evaluating alternative models.
Contributions were made as guided by these objectives:
1. A labelled dataset of plant leaves, including both healthy leaves and leaves with
disease signs. Implement several image processing algorithms for input images
utilised by the ﬁnal model for detection.
2. To select an architecture for future research, compare several CNN architectures
on a subset of the plant image dataset using the appropriate statistic.
3. Compare the results of the various dataset settings for the selected CNN archi-
tecture.
4. Evaluate the model’s performance using real-world data to see whether it can be
applied to new data with complex histories.

Efﬁcient Plant Disease Detection and Classiﬁcation for Android
537
2
Literature Review
Mohanty et al. [15] have studied the use of deep learning in a smartphone application
to diagnose and classify agricultural disease. Due to improvements in smartphone
processing speeds and cameras, widespread smartphone use makes deep learning
accessible to a broader range of consumers.
CNNs outperform other deep learning and machine learning techniques, such as
recurrent neural networks (RNNs) and support vector machines (SVMs), for plant
disease diagnosis [14]. CNNs are time-consuming to train, but they can classify
images rather rapidly, making them suitable for use in Android apps [15]. Contrary to
CNNs, machine learning approaches need data preprocessing and feature extraction
prior to model training, but CNN designs just necessitate complex preparation.
Machine learning algorithms perform better when the data is more organised. To
improve the performance of models trained on a limited structured dataset, it might
be supplemented.
As explained by Fang et al. [9], the DCGAN utilises convolutional and deconvo-
lutional layers in their discriminator and generator, respectively, incorporating the
advantages of CNN feature extraction and therefore enhancing image analysis abil-
ities. Moreover, it serves as a form of data augmentation that can allow classiﬁers to
train on more varied data for better inference in the wild.
Fang et al. [9] trained a CNN model with both actual and DCGAN samples and
subsequently trained another model using only genuine cases. The model trained
using a mixed dataset increased in accuracy, converging at 89.37% after 30 epochs.
Because noise may signiﬁcantly affect the look of a leaf in an image, picture
preprocessing reduces noise and enhances detection accuracy [16]. To accommodate
for harsh lighting conditions, we can apply the Retinex algorithm and investigate
colour spaces [2] that enhance the image.
Iniyan et al. [14] examined the feasibility of edge detection and blob detection for
feature extraction using artiﬁcial neural network (ANN) and SVM models. These
strategies somewhat enhanced the ANN and SVMs accuracy. In the identiﬁcation of
plant diseases, SVMs were unable to beat neural networks such as convolutional or
recurrent neural networks, even with feature extraction.
Elizabeth and Baulkani [7] used ImageNet weights to examine alternative colour-
space transformation algorithms on four CNN architectures: VGG, InceptionV3,
ResNet, and DenseNet. The images were RGB, HSI, and other colourspace trans-
formed using the CINIC dataset [3]. For all models, the CIVIC and SVHN RGB
colourspace datasets fared the best, with the least loss and the highest accuracy.
These results support the conclusion reached by [15] that the RGB dataset delivers
the highest degree of accuracy. This drop in performance might be attributed to data
loss in the greyscaled dataset.
Poole and Brown [18] explored the use of VIS-IR imaging and if it enables deep
learning algorithms to classify plant stress and disease with much more accuracy than
visible imaging. They found that VIS-IR imaging was signiﬁcantly better at detecting
plant stresses (Brown and Poole [2]; Poole and Brown [19]), but that visible imagery
can also be successful with sufﬁcient data and effective augmentation strategies.

538
D. Brown and S. Mazibuko
Table 1 Goncharov et al.’s
PlantVillage-trained models
tested on real-world data
Architecture
Accuracy (%)
VGG16
19.73
InceptionV3
30.78
InceptionResNetV2
39.87
De Silva and Brown [4] collected images of 10 species of agricultural plants
in their natural environments for disease categorisation. The images were captured
using a Canon EOS 700D camera equipped with a Kolari Vision Hot Mirror ﬁlter
for RGB photographs and a Kolari Vision K665 ﬁlter for NIR images. ResNet-50V2
outperformed other deep learning models on both the VIS and NIR datasets, with
test accuracy rates of 98.35 and 94.01%, respectively. Examining eight CNN models
with train-test splits ranging from 10:90 to 90:10 using the same NIR dataset [6].
Aditya et al. [1] created a sequential model using the Keras API. They trained the
model from scratch using a dataset of 56,725 pictures, without considering whether
the model was modest and efﬁcient enough for a mobile application. An accuracy
rating of 96.84% was achieved using batch normalisation to enhance learning and
a regularisation tool to minimise overﬁtting data using the Keras image processing
module that builds batches of tensors from the dataset.
Francis and Deisy [10]’s CNN architecture comprised of four convolutional lay-
ers activated by ReLU and two fully connected layers activated by Softmax. The
objective was to create a small model for mobile and embedded applications. The 44
KB model has an accuracy of 88.7%. The smallest model was trained by the authors.
Mohanty et al. [15], unlike Francis and Deisy [10], used ImageNet-pretrained
AlexNet and GoogleNet architectures and trained models from scratch. The accuracy
of the RGB image PlantVillage dataset was 99.34% when using the GoogleNet
transfer learning model. With transfer learning and RGB data, CNNs performed
best.
Hassan et al. [12] compared the CNN architectures InceptionResnetV2, Incep-
tionV3, MobileNetV2, and EfﬁcientNetB0. EfﬁcientNetB0 outperformed the other
three models in terms of accuracy, recall, and F1-score, with 99.56% accuracy. It
had fewer parameters and took less time to train than the other models, but it needed
considerable parameter tweaking, which was outside the scope of this research.
Goncharov et al. [11] investigated the applicability of a model trained on the
PlantVillage dataset in a real-world setting. This research looks at the VGG16, Incep-
tionV3, and InceptionResNetV2 models, which were pretrained on imageNet data,
then trained on PlantVillage data, and ﬁnally assessed on real-world pictures. Gon-
charov et al. obtained the results shown in Table1 for the aforementioned models;
the low accuracy was attributed to background noise, the presence of leaves on an
image as opposed to having a leaf as in the PlantVillage data, and the low resolution
of the real-world images used for testing.

Efﬁcient Plant Disease Detection and Classiﬁcation for Android
539
3
Methodology
The proposed end-to-end system can be summarised as XML code that generates
the front-end visual aspects designed in incision studiom while Kotlin code runs
the interactions between different aspects and pages that call the machine learning
model. The interested reader is referred to Github page and encouraged to reference
this paper.
3.1
Dataset Collection
Hughes and Salathé [13] compiled the PlantVillage dataset of plant diseases, and
Mohanty et al. [15] curated the PlantVillage dataset used in this work. The pho-
tographs depict a single plant leaf set on a white/light blue background. The collec-
tion consists of 54,305 photographs organised into three sets: RGB, segmented, and
greyscale.
De Silva and Brown [5] collected a real-world dataset consisting of pictures of
plant leaves in a complex natural ecosystem without being separated from the rest
of the plant, as is the case with the PlantVillage dataset. This dataset is much closer
to data in the wild and can be used to show the gap between modelling simple and
real-world data.
3.2
Image Processing
To handle the application’s diverse lighting conditions, the Retinex image enhancing
technology was used. This application employs the single-scale Retinex algorithm. It
is based on centre-surround [2]. It is the difference in logarithms between the image
at (x, y) and its centre-surround average at (x, y) (x, y). The Gaussian distribution is
used to calculate the centre-surround average of an image at certain locations (x, y).
3.3
Image Segmentation
The image segmentation technique removes the background of the leaf image, leav-
ing just the leaf and disease spots. A green, yellow, and brown mask is constructed
using an HSV image of the plant’s leaf and the bitwise_or operation. The Retinex
algorithm was used to minimise image noise and improve identiﬁcation in challeng-
ing circumstances. The approach fails when the background of a picture is green,
yellow, or brown because it assumes it is a leaf.

540
D. Brown and S. Mazibuko
Table 2 ADAM optimiser
parameters
Learning rate
0.001
Beta_1
0.5
3.4
Dataset Augmentation
The dataset’s different classes were sampled unequally, and several dataset augmen-
tation procedures were tested to reduce the inaccuracy induced by unequal sampling.
The TensorFlow ImageDataGenerator Keras class is used to rotate and ﬂip images
vertically and horizontally. This class is used to distinguish the photographs in each
sample class, enabling the model to train on images that are more dissimilar.
A deep convolutional neural network (DCGAN) was considered to augment the
dataset in order to compensate for unequal sampling across classes and to improve
the dataset of photographs from the natural world. The DCGAN’s discriminator and
generator networks use batch normalisation1 layers and the ADAM.2 Optimise using
the values from Table2.
The discriminator computes loss using BinaryCrossentropy. As shown in Listing
39.1, the total loss for the model is derived by adding the model’s real and ﬁcti-
tious losses. The real loss is retrieved from an image in the training dataset, while
the fake loss is derived from the image that was produced. The loss evaluates the
discriminator’s ability to discern between actual and artiﬁcial images.
1
def
discriminator_loss ( real_output ,
fake_output ):
2
real_loss
=
cross_entropy (tf. ones_like ( real_output ),
real_output )
3
fake_loss
=
cross_entropy (tf. zeros_like ( fake_output ),
fake_output )
4
total_loss
=
real_loss
+
fake_loss
5
return
total_loss
Listing 39.1 Discriminator Loss.
The Conv2DTranspose operation and the LeakyReLU activation function are used
by each of the generator’s six hidden layers to scale the input image to 256×256
pixels. The generator’s output layer constructs a tensor of outputs using the Conv2D
operation and tanh activation. The loss evaluates the generator’s deceit by comparing
the discriminator’s judgements against the real output. The generator’s fake output
is computed as shown in Listing 39.2.
1
def
generator_loss ( fake_output ):
2
return
cross_entropy (tf. ones_like ( fake_output ),
fake_output )
Listing 39.2 Genarator Loss.
1 Normalises weights for faster training.
2 Adaptive Moment Estimation is a backpropagation approach for efﬁcient gradient descent.

Efﬁcient Plant Disease Detection and Classiﬁcation for Android
541
Fig. 1 Plant disease detection and identiﬁcation system: a high-level view
3.5
Convolutional Neural Network Architecture
CNN performs feature extraction and classiﬁcation with high accuracy without prior
data processing or feature engineering. CNN architectures considered were VGG16,
InceptionV3, EfﬁcientNetsB0, and MobileNetV3Large. According to the literature,
thesearethebeststructuresforcategorisingplantpicturesinamobilecontext.Among
the architectures tested, the VGG16 and InceptionV3 models received the highest
scores for accuracy, precision, and F1. Because it was designed to perform well under
severe constraints and a constrained computational budget [23], the VGG architecture
uses less RAM and has fewer parameters than the tested Inception network.
4
Disease Detection and Classiﬁcation Back-End System
Figure1 depicts a diagram with components of the machine learning backend system
for identifying and categorising plant diseases. The objectives direct the system
design based on Sect.1 and the methodologies concepts explained above.
TheTensorFlowKeraslibraryisutilisedtoconstructthemodelsthatwillbeusedto
analyse the different dataset conﬁgurations and the efﬁcacy of converting the dataset
using the TensorFlow ImageDataGenerator class to enhance model performance.
Additionally, the Keras library is used to construct the model for the ﬁnal system and
to conduct testing using real-world data.

542
D. Brown and S. Mazibuko
Image preparation procedures are performed on the ﬁnal system input in order
to make the input photos to be as similar as possible to the images that are used
for prediction in the wild. This adds extra variation in order to improve accuracy on
unseen data and complex backgrounds.
5
Experiments Conducted
Each CNN architecture described in Sect.3.5 was modelled. For the ﬁnal model
selection, further testing with a subset of the dataset was undertaken to assess model
performance and compare the models to one another. Model ﬁne-tuning was not as
robust as indicated by the literature.
The following is an overview of each of the experiments conducted:
• Using the ﬁndings of this experiment, choose a model for further study based on
the performance of the model on the tomato dataset, which has 10 classes.
• Evaluate the efﬁciency of changing the dataset using the TensorFlow ImageData-
Generator class in order to enhance model performance.
• Examine the different dataset combinations to see which combination produces
the highest performance.
• After picking a model, its performance on the whole dataset must be assessed.
item A small dataset including four classes was collected from the real world, and
the chosen model will be trained and assessed using this dataset.
6
Results and Discussion
6.1
Model Testing on Tomato Dataset
Each design was tested using a subset of the PlantVillage dataset, which contained
nine leaf diseases and nine healthy tomato species. The dataset consists of 16,011
photographs separated into three sets: training, validation, and testing (60:20:20).
All models are trained using transfer learning with ImageNet weights and a 0.001
learning rate. The batch size in this experiment was ten, each model was trained for
ten epochs, and the prediction time is the average of ten tests.
According to Table3, MobileNetV3Large and EfﬁcientNetB0 require less mem-
ory, making them ideal for usage in a low-resource mobile context. However, they
have the lowest F1-score, suggesting that they are not as exact and robust as VGG16
and InceptionV3, offsetting their beneﬁt of using less memory.
The MobileNetV3Large model has poor precision and recall, resulting in a low
F1-score, but good accuracy, suggesting that the model is underﬁtting due to the
unequal sampling across classes in the dataset used in this experiment.

Efﬁcient Plant Disease Detection and Classiﬁcation for Android
543
Table 3 Architecture testing
Architecture
Memory taken
(mb)
F1-score
Time to predict
(s)
Accuracy (%)
MobileNetV3Large
33.6
3.4
0.051
86
EfﬁcientNetB0
20
0.0
0.047
20
VGG16
367.7
94.49
0.041
94
InceptionV3
994.5
91.49
0.060
91
Validation losses for the EfﬁcientNetB0, InceptionV3, and VGG16 models con-
verge at 2.2, 0.3, and 0.5, respectively, with the InceptionV3 and VGG16 models
having somewhat higher validation losses than the training loss, indicating that they
are underﬁtting the training data. The losses of the MobileNetV3Large model had
not stabilised by the ninth epoch, and the training loss was much more than the vali-
dation loss. This demonstrates that MobileNetV3Large does not generalise well and
needs additional training epochs and training data to reach convergence and decrease
losses.
Among the models tested, the VGG16 and InceptionV3 models performed the
best. They have higher F1-scores and lower training and validation losses, suggest-
ing that they are more robust models with lower error rates. EfﬁcientNetB0 and
MobileNetV3Large have substantial losses, suggesting that they create erroneous
output, which explains their extremely low F1-scores; hence, they are not robust
models and need further data and parameter change to improve. They were not further
investigated since parameter change was beyond the scope of this inquiry. Because
of their greater performance, the VGG16 and InceptionV3 models are employed for
future exploration.
6.2
Comparing Datasets
The use of models trained on a single dataset is examined in this section, and the
various colourspaces are assessed on images from a different dataset in order to
discover a model that generalises successfully across image colourspaces. A model
that performs well on both segmented and traditional RGB datasets is ideal for the
application. Furthermore, the greyscale dataset is analysed for comparison purposes.
To train the models, the parameters in Table4 are utilised.
Table 4 Training parameters
for comparing datasets
Learning rate
0.001
Epochs
10
Batch size
60

544
D. Brown and S. Mazibuko
Table 5 VGG16 and Inception RGB model test results
Model
Test dataset
Accuracy (%)
Loss
Precision (%)
Recall (%)
VGG16
RGB
94.43
0.24
94.43
94.02
Segmented
69.53
2.53
69.53
68.50
Greyscale
63.64
2.25
65.31
62.69
InceptionV3
RGB
89.63
0.87
89.90
89.57
Segmented
75.44
2.26
76.11
75.18
Greyscale
71.25
3.28
71.84
71.05
InceptionV3 and VGG16 Models Trained on RGB Data: The performance of
models trained on the RGB dataset on images in RGB, greyscale, and segmented
colour spaces was examined in this experiment.
Although their training losses are equal and stabilise at the same low point, the
InceptionV3 model has a higher validation loss than the VGG16 model. The valida-
tion loss of the InceptionV3 model rises from a low point, indicating that the model
overﬁts the training data. The validation loss of the VGG16 model does not stabilise
and does not increase in the same way as the InceptionV3 model does.
The RGB training results are summarised in Table5, revealing that the model
performs well on images in the colourspace in which it was trained, with the mod-
els performing best on RGB images. The VGG16 model performed best, but the
InceptionV3 model performed better on segmented and greyscaled images, although
with a bigger loss than the VGG16 model, indicating that greyscale images created
more inaccurate output. More training is needed to discover the overall trend of
both models’ losses in order to determine if the models have been overﬁtted; this
test determines whether image colourspace is adequate for this application without
attempting to improve model performance.
InceptionV3 and VGG16 Models Trained on Segmented Data: In this experiment,
segmented dataset-trained models were assessed on RGB and greyscale photographs,
in addition to segmented pictures.
The model’s training losses had stabilised at a low value, which was somewhat
greater than the models trained on RGB data in the previous section. As noted in
the preceding section, the validation loss for the InceptionV3 model is growing,
indicating that the model overﬁts the training data. It is necessary to stabilise the
validation loss of the VGG16 model, which may be achieved by training for extra
epochs.
When tested on photographs in the colour space in which it was taught, the VGG16
model performed the best across all criteria, as shown in Table6. It was tested with
segmented photographs in this case and functioned better with RGB images. Despite
a high loss rate indicating incorrect output, the InceptionV3 performed best with
greyscale images. The segmented dataset outperforms the VGG16 model.

Efﬁcient Plant Disease Detection and Classiﬁcation for Android
545
Table 6 VGG16 and Inception segmented model test results
Model
Test dataset
Accuracy (%)
Loss
Precision (%)
Recall
VGG16
RGB
72.37
2.13
73.51
71.85
Segmented
93.28
0.31
93.77
93.07
Greyscale
39.74
5.87
41.31
38.88
InceptionV3
RGB
71.90
3.10
72.37
71.59
Segmented
89.34
0.79
89.57
89.23
Greyscale
47.93
9.07
48.44
47.64
Table 7 VGG16 and Inception greyscale model test results
Model
Test dataset
Accuracy (%)
Loss
Precision (%)
Recall (%)
VGG16
RGB
78.43
1.24
79.71
77.91
Segmented
59.50
3.30
60.48
58.97
greyscale
89.27
0.46
90.29
88.79
InceptionV3
RGB
68.54
3.14
69.20
68.35
Segmented
40.26
7.72
40.73
39.90
Greyscale
87.18
1.08
87.47
87.05
InceptionV3 and VGG16 Models Trained on greyscale Data The performance of
models trained on the greyscale dataset on images in RGB, greyscale, and segmented
colour spaces was tested in this experiment.
As additional epochs are trained, the InceptionV3 validation loss continuously
rises; this implies that the model may be overﬁtting on training data, but further
training is needed to determine the overall trend of the loss curve. Both models’
training losses stabilised at a modest level, as they have in previous research. In
contrast to the loss seen with RGB data, the validation loss for the VGG16 model is
rather stable. It is larger than the training loss, and additional training is necessary
to ﬁnd the long-term trend, similar to the validation loss for the Inception model.
Compared to its counterparts from preceding sections, the greyscaled model fared
the worst across all criteria, as shown in Table7. CNN models prefer extra informa-
tion, such as richer colour, to draw more features from in order to differentiate objects,
therefore this decrease in performance is to be expected.
Comparing RGB Trained InceptionV3 and VGG16 Models With RGB data
Further: InceptionV3 and VGG16 models are compared using the same model
parameters, including a hidden layer of 1024 nodes and the rectiﬁed linear unit
activation function, which makes the model easier to train and frequently leads to
the model performing better.
The models’ performances are similar as seen in Fig.2, with VGG16 producing
somewhat better outcomes. The training accuracy of both models starts to decrease
after seven epochs, dropping from 98.5% for the VGG16 model to 98.5 and 97.7%
for the InceptionV3 model, respectively. Table3 shows that the VGG16 model uses

546
D. Brown and S. Mazibuko
Fig. 2 VGG16 versus InceptionV3 training accuracy
less storage space and makes predictions at comparable rates when trained with the
tomato dataset.
According to Table5, the VGG16 model demonstrated improved accuracy, preci-
sion, and recall on unseen test data, as well as a lower testing loss. On segmented and
grayscale data, the performance of the Inception model is superior. The bulk of the
model’s RGB images utilised in this application will not be separated. The VGG16
architecture was chosen for the application and future study.
Testing Model on Real-World Data: Utilising the information in Tables8 and 9, a
VGG16 model was trained for ﬁve iterations. The VGG16 model’s performance and
robustness are tested using RGB PlantVillage-trained real-world plant data. Table10
displays the test results for PlantVillage.
Testing using PlantVillage RGB data reveals in Table10 that the model achieves
good accuracy with substantial loss. This demonstrates that the model works effec-
tively when evaluated against the PlantVillage dataset. As the classes are not uni-
formly sampled, the high loss and high accuracy may potentially imply that the
model overﬁts the data. The very low training loss of 2.4495e−05 compared to the
comparatively large testing loss of 1.29 is another indication of overﬁtting.
Table 8 Dataset used to train model for real-world usage testing
Dataset categories
Tomato healthy
1591
Tomato yellow leaf curl virus
5357
Potato healthy
152
Peach healthy
360

Efﬁcient Plant Disease Detection and Classiﬁcation for Android
547
Table 9 Real-world dataset used to test model
Dataset categories
Tomato healthy
100
Tomato yellow leaf curl virus
62
Potato healthy
74
Peach healthy
79
Table 10 Test with
PlantVillage data
Accuracy
Loss
97.79%
1.29
Table 11 Test with
real-world data
Accuracy
Loss
63.02%
33.93
As seen in Table11, the real-world test results in a very big loss, indicating that the
model generates considerably inaccurate output. In contrast, [11] trained a VGG16
model using PlantVillage data, achieving a 15.08% accuracy rate on unseen real-
world images, resulting in a model with a rather high degree of plant recognition
accuracy.
Discussion of Results The best-performing model was the VGG16, which was
trained over 10 epochs using the whole PlantVillage RGB dataset. As a result, it is
used across the system. Because it creates fewer wrong outputs, the VGG16 model
consistently obtained the lowest loss across all datasets. Furthermore, the training
loss was lower than the validation loss, showing that the model generalises well.
The programme sends the image to the backend, which is a RESTful API devel-
oped using the Flask Python framework and processes it. The Retinex and segmen-
tation algorithms are applied on the image separately. The original and segmented
photographs are then used for prediction. The prediction is based on the most conﬁ-
dent outcome, which is then conveyed to the programme and shown to the user.
The real-world data test shows that the PlantVillage VGG16 RGB model is durable
and can work with real-world data; nevertheless, more data is needed to prevent over-
ﬁtting and regularise the model. This test illustrates that an application can run with
high accuracy in real-world conditions while employing a VGG16 model without
image processing. When evaluated with real-world data, the model’s accuracy drops
due to background noise and the complexity of pictures with several leaves [11].
7
Concluding Remarks
The model with the best performance is the VGG16 model, which was trained over
10 epochs using the whole PlantVillage RGB dataset. As a result, it is used across

548
D. Brown and S. Mazibuko
the system. Because it delivers less incorrect output, the VGG16 model consistently
received the lowest loss across all datasets. Furthermore, the training loss was less
than the validation loss, indicating that the model generalises well.
The picture is sent by the application to the backend, which is a RESTful API
built using the Flask Python module that processes the image. The Retinex and
segmentation algorithms are applied individually to the picture. Forecasting is then
done using the segmented and original photos. The prediction is based on the most
conﬁdent result, which is subsequently submitted to the programme and shown to
the user.
The test with real-world data shows that the PlantVillage VGG16 RGB model is
resilient and can operate with real-world data; however, further data is required to
avoidoverﬁttingandregularisethemodel.Thistest,whichusesaVGG16modelwith-
out image processing, suggests that an application can perform properly in real-world
circumstances. When compared to real-world data, the model’s accuracy decreases
due to background noise and the complexity of photos that include multiple leaves.
This is thus a promising approach for future research dealing with plant image data
in the wild.
References
1. Aditya D, Manvitha R, Mouli CR (2021) Detect-o-thon: identiﬁcation of infected plants by
using deep learning. Glob Trans Proc 2(2):336–343
2. Brown D, Poole L (2023) Enhanced plant species and early water stress detection using visible
and near-infrared spectra. In: Computational vision and bio-inspired computing. Advances in
intelligent systems and computing, vol 1439(1). Springer, Singapore. https://doi.org/10.1007/
978-981-19-9819-5_55
3. Darlow LN, Crowley EJ, Antoniou A, Storkey AJ (2018) Cinic-10 is not imagenet or cifar-10.
University of Edinburgh
4. De Silva M, Brown D (2022) Plant disease detection using deep learning on natural environment
images. In: 2022 international conference on artiﬁcial intelligence, big data, computing and
data communication systems (icABCD), pp 1–5. https://doi.org/10.1109/icABCD54961.2022.
9855925
5. De Silva M, Brown D (2022) Plant disease detection using deep learning on natural environment
images. In: 2022 international conference on artiﬁcial intelligence, big data, computing and
data communication systems (icABCD). IEEE, pp 1–5
6. De Silva M, Brown D (2022) Plant disease detection using multispectral imaging. In: Advanced
computing. In Press, Springer(1)
7. Elizabeth CB, Baulkani S (2022) A color space blending with deep learning networks in the
identiﬁcation of plant leaves. Plant Arch 22(2):431–436
8. Fan S (2016) Global food policy report. International Food Policy Research Institute
9. Fang W, Zhang F, Sheng VS, Ding Y (2018) A method for improving CNN-based image
recognition using DCGAN. Comput Mater Continua 57(1):167–178
10. Francis M, Deisy C (2019) Disease detection and classiﬁcation in agricultural plants using
convolutional neural networks—a visual understanding. In: 2019 6th international conference
on signal processing and integrated networks (SPIN). IEEE, pp 1063–1068
11. Goncharov P, Ososkov G, Nechaevskiy A, Uzhinskiy A, Nestsiarenia I (2018) Disease detection
on the plant leaves by deep learning. In: International conference on neuroinformatics. Springer,
pp 151–159

Efﬁcient Plant Disease Detection and Classiﬁcation for Android
549
12. Hassan SM, Maji AK, Jasi´nski M, Leonowicz Z, Jasi´nska E (2021) Identiﬁcation of plant-leaf
diseases using CNN and transfer-learning approach. Electronics 10(12):1388
13. Hughes DP, Salathé M (2015) An open access repository of images on plant health to enable
the development of mobile disease diagnostics through machine learning and crowdsourcing.
CoRR abs/1511.08060. http://arxiv.org/abs/1511.08060
14. Iniyan S, Jebakumar R, Mangalraj P, Mohit M, Nanda A (2020) Plant disease identiﬁcation and
detection using support vector machines and artiﬁcial neural networks. In: Artiﬁcial intelligence
and evolutionary computations in engineering systems. Springer, pp 15–27
15. Mohanty SP, Hughes DP, Salathé M (2016) Using deep learning for image-based plant disease
detection. Frontiers Plant Sci 7:1419
16. Neelakantan P (2021) Analyzing the best machine learning algorithm for plant disease classi-
ﬁcation. Mater Today Proc 2214–7853
17. Panchal AV, Patel SC, Bagyalakshmi K, Kumar P, Khan IR, Soni M (2021) Image-based plant
diseases detection using deep learning. Mater Today Proc
18. Poole L, Brown D (2021) Early dehydration detection using infrared imaging. In: 23rd Southern
Africa telecommunication networks and applications conference (SATNAC). IEEE, pp 1–6
19. Poole L, Brown D (2021) Investigating popular CNN architectures for plant disease detec-
tion. In: 2021 international conference on artiﬁcial intelligence, big data, computing and data
communication systems (icABCD). IEEE, pp 1–5
20. Ristaino JB, Anderson PK, Bebber DP, Brauman KA, Cunniffe NJ, Fedoroff NV, Finegold C,
Garrett KA, Gilligan CA, Jones CM et al (2021) The persistent threat of emerging plant disease
pandemics to global food security. Proc Natl Acad Sci 118(23):e2022239118
21. Singh V, Misra AK (2017) Detection of plant leaf diseases using image segmentation and soft
computing techniques. Inform Proc Agric 4(1):41–49
22. Sun J, Yang Y, He X, Wu X (2020) Northern maize leaf blight detection under complex ﬁeld
environment based on deep learning. IEEE Access 8:33679–33688
23. Szegedy C, Vanhoucke V, Ioffe S, Shlens J, Wojna Z (2016) Rethinking the inception archi-
tecture for computer vision. In: Proceedings of the IEEE conference on computer vision and
pattern recognition, pp 2818–2826

Resume Analysis Using NLP
Rakhi Bharadwaj, Divya Mahajan, Meenal Bharsakle, Kashish Meshram,
and Himaja Pujari
Abstract Job recruitment is one of the main activities for individuals, and it might
be difﬁcult to discover a fruitful talent. Our suggested model’s main elements include
the extraction of statistics and information from the resume and the evaluation of the
resume in line with the preferences of the associated ﬁrm and its criteria for natural
language processing (NLP). The hiring process is simpliﬁed and made more effective
by parsing and ranking the resume. Any reputable parser must be able to extract the
different tiny pieces of information contained in a resume, including information on
education, experience, projects, addresses, and other things. So, in essence, we will
create a job platform where employees and candidates may upload their resumes
for every available position. The required information will be parsed with NLP.
Additionally, the corporate skill requirements and the talents of the employees in the
provided CV will be taken into consideration when ranking the employee resumes.
Keywords Natural language processing · Parser · Ranking · Resumes · Skillset
1
Introduction
Many resumes are processed everyday by corporate organizations and recruitment
ﬁrms. This task is not easy for humans. It takes an automated, intelligent system to
R. Bharadwaj (B) · D. Mahajan · M. Bharsakle · K. Meshram · H. Pujari
Vishwakarma Institute of Technology, Pune, India
e-mail: rakhi.bharadwaj@vit.edu
D. Mahajan
e-mail: divya.mahajan21@vit.edu
M. Bharsakle
e-mail: meenal.bharsakle21@vit.edu
K. Meshram
e-mail: kashish.meshram21@vit.edu
H. Pujari
e-mail: himaja.pujari21@vit.edu
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_40
551

552
R. Bharadwaj et al.
extract all the relevant data from resumes and ranked for a position. Many individuals
send their resumes to apply for a particular position, and the multinational businesses
receive thousands of emails from them each day. The actual difﬁculty now is deter-
mining which resumes should be sorted and shortlisted based on the requirements.
The resume can be manually examined and sorted as one approach.
Due to human participation, this method is currently the most time-consuming
and has a high potential for errors. Additionally, people cannot work continuously.
Consequently, there is also a problem with efﬁciency.
The following information is parsed: name, email address, social media accounts,
personal websites, years of employment, employment experiences, years of educa-
tion, educational experiences, publications, certiﬁcates, volunteer experiences,
keywords, and ﬁnally, the cluster of the resume. Discrete sets are used to store
data. Each set includes information on a person’s contact information, job history,
and educational background. Despite this, it can be challenging to parse resumes.
This is due to the fact that they have different informational types, orderings, writing
styles, etc. They can be written in a number of different formats. They include “.txt”
and “.pdf” and are the most often used ones. In order to correctly and effectively
understand the data from various types of resumes, the model must not be dependent
on the order or type of data.
2
Literature Review
The research articles that we have read and examined demonstrate the necessity for
both candidates and recruiters to review resumes. Sufﬁcient database is signiﬁcant
for the model. Accuracy of the model is always a concern. Also, skillsets and job
description play a vital role in resume analysis. Keeping the user interface of the
website simple would be encouraging more users to visit the website.
The work by Shubham Bhor, et al. depicted the use of NLP for parsing the resume
according to particular company [1].
The system proposed by Sroison Pornphat and Jonathan H. consisted of three steps
to parse resume: ﬁrstly, receive resume ﬁles from candidate, then convert resume ﬁle
to text format, and ﬁnally, extracting necessary information [2].
Yi-Chi Chou and Han-Yen Yu have proposed an AI model which analyzes resume
of different candidates and gives them a score based on the skills that are mentioned
[3].
A methodological approach for processing and analyzing data collected by
scraping from online job portals using AI is proposed by Alena Vankevich and Iryna
Kalinouskaya [4].
The system by V. V. Dixit, et al. uses AI to ﬁnd required skillset by scanning
resume and also sorts it [5].
The proposed CV parser by Papiya Das, et al., system provides entity extraction
method from the uploaded CVs [6].

Resume Analysis Using NLP
553
The system by Yanyuan Su Jian and Zhang Jianhao Lu performs a series of
experiments to train and estimate several neural network models on it [7].
This system proposed by Ashif Mohamed, et al., uses NLP and pattern matching
technique to extract details of the candidate [8].
Major problems faced in the previous works are the unavailability of proper
database and they could not ﬁgure out which parameters should be used to compare
and rank the resumes. Table 1 shows the summary of some research papers reviewed.
3
Methodology
The system architecture, preprocessing steps, and generating response steps are
displayed in Figs. 1, 2, and 3.
3.1
Flowchart
3.2
Components
An interface between the recruiter and the candidates may be found on the site. A
completely working website is made using Flask, HTML, CSS, JavaScript, and other
tools. Making the website user-friendly is the aim. It may be used by applicants and
recruiters for many purposes. The website is quite easy to navigate.
Flask is a web framework developed in Python that is used to offer a backend to
a website and add functionality to it. We wrote our AI model in Python, and using
Flask made it easy for us to put the code on a website.
3.3
Algorithm
In this study, natural language processing (NLP) is employed. NLP enables
computers to comprehend human language and process it accordingly. The Natural
Language Toolkit (nltk) library is utilized for this. Other libraries are imported and
installed in addition to nltk. It is a good library when a speciﬁc combination of
algorithms is required.
A web application with two ends, the applicant and the recruiter, is where the
model is deployed. NLP techniques are signiﬁcantly portrayed at each ﬁnish. The
modules that follow will demonstrate this.
The applicant module:
• Resume Parser

554
R. Bharadwaj et al.
Table 1 Summary of literature review
Paper title
Authors
Future scope
Resume Parser Using Natural
Language Processing
Techniques (2021)
Shubham Bhor, Vivek Gupta,
Vishak Nair, Harish Shinde
To parse resumes from
different websites and
applications like LinkedIn,
GitHub, Naukri.com, etc.
Resume Parser with Natural
Language Processing (2021)
Sroison Pornphat, Jonathan H
A system that provides more
datasets for training in the
future as the existing datasets
are inadequate
Based on the application of
AI technology in resume
analysis and job
recommendation (2020)
Yi-Chi Chou, Han-Yen Yu
The accuracy of the system can
be enhanced, and this study
only examined the feedback of
applicant who used the job
vacancy recommendation
systems
Ensuring sustainable growth
based on the artiﬁcial
intelligence analysis and
forecast of in demand skills
(2020)
Alena Vankevich, Iryna
Kalinouskaya
To identify the skills and
competencies in demand and
compare them with those
offered on the labor market
Resume Sorting using
Artiﬁcial Intelligence (2019)
V. V. Dixit, Trisha Patel, Nidhi
Deshpande, Kamini Sonawane
To use augmented intelligence
technology to determine
applicant’s culture ﬁt and
improve relationship with
hiring executives
A CV Parser Model using
Entity Extraction Process and
Big Data Tools (2018)
Papiya Das, Manjusha Pandey,
Siddharth Rautaray
To implement and deliver a
brief analysis in real-time
database to attain the analysis
with present models
The Resume Corpus: A large
Dataset for Research in
information Extraction
System (2018)
Yanyuan Su Jian, Zhang
Jianhao Lu
To design a series of
information extraction models
based on the corpus
Smart Talents
Recruiters—Resume Ranking
and Recommendation System
(2018)
Ashif Mohamed, Shahik
Samarth, Anuradha Jayakody,
Usama Iqbal
To examine important data
about job recruiting and extract
more information to
implement enriched applicant
recommendation system and
enlarge the database
By utilizing the Python module pdfminer, which is used in NLP, the text from the
resume is extracted. The resume parser extracts email IDs, phone numbers, skills,
and education using regular expressions (REs) and Name Entity Recognition (NER).
1. Email IDs
Email IDs are collected from the resume using pattern matching and the following
regular expression. The re library is utilized for this operation.

Resume Analysis Using NLP
555
Fig. 1 System architecture
Fig. 2 Preprocessing steps
Fig. 3 Generating response steps
RE =
∧@
\s] + @[∧@]+\.[∧@
\s

+

.
2. Phone number
Similar to email IDs, the phone number is obtained using another regular expression.
3. Skills
It makes use of a dataset that is in .csv format and comprises a variety of skills. The
column values in the dataset are compared to the tokens in resume. A match clearly
shows that the skill is present in the resume if one is identiﬁed. Consequently, the
talents can be taken from the CV.
4. Education

556
R. Bharadwaj et al.
The text from the resume is compared with the list of educational qualiﬁcations, and
thus, if a match is found, it is returned.
• Resume Evaluator
Thecandidatecanselectthejobcategorywithwhichtheywanttocompareandupload
their CV. The resume analyzer will review the document and report the percentage
of similarity between it and the selected category’s job description.
Before the real procedure is carried out, the resume needs to go through some
preprocessing.
1. Preprocessing
The information collected from the user is preprocessed using a variety of NLP
algorithms. The ﬁrst step is using the pdfminer library to convert the resume to plain
text. The following techniques are used to process it after that:
a. Tokenization—data are divided into chunks by the tokenizer so that they can be
handled as discrete parts in subsequent phases. It uses the Multi-Word Expression
Tokenizer (MWETokenizer).
b. Lemmatization—the terms are condensed by lemmatizer to their simplest
versions. The Wordnet lemmatizer is employed in this work.
c. Stop word removal—it eliminates all the unnecessary and frequent words. In
simple word, it helps get rid of all the words that are unnecessary and overused.
2. Generating Response
The only thing left over when preprocessing is completed is the clean text. The
following procedures are then used to process this further.
a. The TF-IDF methodology—it counts the frequency of each character and divides
it by the total number of words, which is used to determine the Term Frequency
(TF) of each word. The Inverse Document Frequency (IDF) of the vector is then
calculated using the following formula, and the two terms are multiplied. With
the use of this technology, each word in the text is transformed into a vector. Both
the CV and the job description go through this process. TF-IDF vectorization is
used in the model since it reduces the importance of the common words unlike
bag-of-words approach which simply counts the number of occurrences.
E(t, d) =
Number of occurences of t in d
Total number of characters/terms in d ,
where t is the term and d is the data.
IDF(t) = log
Total number of documents
1 + Number of documents containing t ,
where t is the term.
TF-IDF (t, d) = TF(t, d) * IDF(t).

Resume Analysis Using NLP
557
b. Cosine Similarity—by utilizing cosine similarity, the vectors derived from the
job description and resume are compared.
Cosine Similarity(d1, d2) = Dot Product(d1, d2)
||d1||∗||d2||
,
where there are two non-zero vectors, d1 and d2.
• Job Suggester
We scrapped a website named Glassdoor to obtain information about various job
opportunities that are open to candidates. Web scraping is a method of collecting
data from webpages and converting it into a structured format. Scrapy and beautiful
soup are Python libraries that are used for web scraping.
1. N-gram
Continuous word, symbol, or token sequences in a document are known as n-grams.
Technically speaking, they might be referred to as the adjacent item sequences in a
document. The entire text is divided into clusters of size n by this approach. Through
the TF-IDF approach, these clusters are tokenized and then further vectorized. This
makes it easier to understand the context in which a term is used.
2. K-Nearest Neighbor
Thek-nearestneighboralgorithm,orKNNforshort,isasupervisedlearningclassiﬁer
that relies on closeness to generate classiﬁcations or forecasts for how a certain data
point will be categorized. In this study, KNN determines the closeness between the
job description vector and the vector produced by the N-gram approach, resulting in
a similarity between both.
The Admin Module:
The compared resumes are stored in the database. These resumes are displayed on
the Admin portal.
4
Results and Discussion
The model is successful in analyzing the resumes and ranking them according to the
job description provided by the recruiter. The education of the applicant, experience,
projects covered, etc. are considered during the analysis. Other important details
such as name of the applicant, email ID, skillset are extracted from the resume. In
comparison to other models, our model is useful for both the recruiter and candidates
as it compares the resume for the recruiters and gives job suggestions to the candidates
based on their skills. Figures 4, 5, 6, 7, 8, and 9 illustrate the code and resulting output
of the project.

558
R. Bharadwaj et al.
Fig. 4 Home page
Fig. 5 Candidate portal
Fig. 6 Resume comparison

Resume Analysis Using NLP
559
Fig. 7 Resume parser
Fig. 8 Job suggester
5
Future Scope
Our project’s primary area of future work will be to parse resumes from many appli-
cations and websites, like LinkedIn, GitHub, Naukri.com, etc. This system can be
expanded in the future to include a wide variety of psychometric exams. The future
work will involve expanding the resume collection and enhancing the functionality
of the suggested system.

560
R. Bharadwaj et al.
Fig. 9 Admin portal
6
Conclusion
Each day, countless resumes are managed by different corporate organizations and
job agencies. A computerized intelligence system ranks the resumes based on the
pertinentdatathataretakenfromthemandrankedforaparticularjobopportunity.The
data that were studied comprise name, email address, social media accounts, personal
websites, years of work, employment experiences, years of education, educational
experiences, publications, certiﬁcations, volunteer experiences, and keywords. The
employmentprocess’ssimpliﬁcationisourprimaryobjective.Businesseswillreceive
eligible applications as a result of this process. There will be fewer of the unfair and
discriminatory behaviors throughout the process.
Acknowledgements We are extremely grateful to the project guide, Prof. Rakhi Bharadwaj, who
guided us well in the completion of our project. We are also thankful for the opportunity provided
by the Head of Computer Science Department, Prof. Dr. Sandip Shinde. This project would not
have been possible without their guidance. Because of the moral support and ideas, this project
emerged successful.
References
1. Bhor S et al (2021) Resume parser using natural language processing techniques. Int J Res Eng
Sci 9(6)
2. Sroison P, Chan JH (2023) Resume parser with natural language processing. Web. 30 Jan 2023
3. Chou, Y-C, Yu H-Y (2020) Based on the application of AI technology in resume analysis and job
recommendation. In: 2020 IEEE international conference on computational electromagnetics
(ICCEM). IEEE

Resume Analysis Using NLP
561
4. Vankevich A, Kalinouskaya I (2020) Ensuring sustainable growth based on the artiﬁcial intel-
ligence analysis and forecast of in-demand skills. In: E3S web of conferences, vol 208. EDP
Sciences
5. Dixit VV et al (2019) Résumé sorting using artiﬁcial intelligence. Int J Res Eng Sci Manag
2(4):423–425
6. Das P, Pandey M, Rautaray SS (2018) A CV parser model using entity extraction process and
big data tools. IJ Inf Technol Comput Sci 9:21–31
7. Su Y, Zhang J, Lu J (2019) The resume corpus: a large dataset for research in information
extraction systems. In: 2019 15th international conference on computational intelligence and
security (CIS). IEEE
8. Mohamed A et al (2018) Smart talents recruiter-resume ranking and recommendation system.
In: 2018 IEEE international conference on information and automation for sustainability
(ICIAfS). IEEE

The Adoption of Artiﬁcial Intelligence
Technology in Parking Security System
Muhammad Rifqi Alhaﬁzh, Albertus Baskara Yunandito Adriawan,
Darryl Fernaldy, Ford Lumban Gaol, and Tokuro Matsuo
Abstract Artiﬁcial intelligence (AI) refers to human-like intelligence exhibited by
computers, robots, or other machines. In popular use, artiﬁcial intelligence refers
to the ability of a computer or machine to mimic the ability of the human mind to
learn from examples and experiences, recognize objects, understand and respond
to language, make decisions, solve problems, and combine these and other abilities
to perform functions that humans might perform. Artiﬁcial intelligence requires
experience and data to smarten up the technology. The most important things in
making artiﬁcial intelligence are learning, reasoning, and self-correction. At the
learning stage, AI gives machines the ability to learn tasks without requiring a deﬁned
programming language. Then, the reasoning stage is the stage where the reason AI is
applied in a technology. The self-correction stage is the stage where the AI is reﬁning
itself from and learning from experience in order to minimize errors or problems that
exist. Then, this matter is concerned with the parking lot to be discussed. Parking can
be interpreted as public facilities available in agencies or ofﬁces that serve to store
vehicles. Vehicles entering the parking area become tens or even thousands, because
it requires a parking system and management area. Such arrangements are capable of
parkingproceduresandevenothersupportsystemssuchasadequateparkingfacilities
and infrastructure, and another function is to create and develop parking systems in
M. R. Alhaﬁzh · D. Fernaldy
Information Systems Department, School of Information Systems, Bina Nusantara University,
Jakarta 11480, Indonesia
e-mail: muhammad.alhaﬁzh@binus.ac.id
D. Fernaldy
e-mail: darryl.fernaldy@binus.ac.id
A. B. Y. Adriawan · F. L. Gaol (B)
Computer Science Department, BINUS Graduate Program—Doctor of Computer Science, Bina
Nusantara University, Jakarta 11480, Indonesia
e-mail: fgaol@binus.edu
A. B. Y. Adriawan
e-mail: albertus.adriawan@binus.ac.id
T. Matsuo
Advanced Institute of Industrial Technology, Tokyo, Japan
e-mail: matsuo@aiit.ac.jp
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_41
563

564
M. R. Alhaﬁzh et al.
general to provide safety and comfort. The methodology obtained from this problem
is checking the research model to check and ﬁnd out the comparison of vehicle user’s
Parking System Security between cars or motorcycles, as well as the usual parking
lots visited. Then, we created a questionnaire. This study used questionnaires with
the aim to get respondents’ results about the Parking Security System. Our sampling
method is based on respondents aged 17–20 years. Questionnaires are submitted
through the Google Form.
Keywords Artiﬁcial intelligence · Parking security system · Information systems
1
Introduction
In this modern era, most people have their own parking systems and facilities. Parking
lots usually use the services of vendors or providers of parking facilities and still use
paper as a receipt for parking receipts. Today’s parking systems still have their own
drawbacks; although they use a high-level ticketing system and cameras, they are still
lacking in data collection of the number of vehicles entering due to manual techniques
in data collection [1]. The solution to the problem can be done by creating a system
capable of recording a large number of vehicles entering when entering the parking
area [2].
This system can be applied using image recognition technology and OCR algo-
rithm (Optical Character Recognition Technique), data from vehicle plate images
is converted into text or numbers and can be stored in a database, and data from
vehicle plates that has been stored and then matched with photos of vehicles, with
the help of the system, can be integrated with the camera so that the system can
know the duration of its parking [3]. As noted in [4], this technology can improve
the safety system by reading the vehicle’s license plate. Parking Security Systems
that use artiﬁcial intelligence (AI) have a unique way of working. This technology
can reduce excessive paper usage and can reduce congestion to get into the parking
lot. Research question is a clear, focused, short, complex question that plays a major
role in a research [5]. There are seven research questions that we ask respondents.
The ﬁrst is that we ask about the vehicles used by respondents [6]. The second is
that we ask how often respondents use vehicles. Thirdly, we asked how often respon-
dents parked their vehicles in public places [7]. The fourth is that we asked for a
long time to queue while picking up a parking ticket. Fifth, we asked for efﬁciency
when queuing while picking up parking tickets. The sixth question is that we ask
respondents what they think about the waste of paper on parking tickets. And, the
last question we asked was the opinion in implementing artiﬁcial intelligence (AI)
systems to replace the current parking method [8].

The Adoption of Artiﬁcial Intelligence Technology in Parking Security …
565
2
Literature Review
Artiﬁcial intelligence (AI) refers to human-like intelligence exhibited by computers,
robots, or other machines. As noted in [9] in popular use, artiﬁcial intelligence refers
to the ability of a computer or machine to mimic the ability of the human mind to
learn from examples and experiences, recognize objects, understand and respond to
language, make decisions, solve problems, and combine these and other abilities to
perform functions that humans might perform.
As seen in [10], AI can analyze more and deeper data using neural networks that
have many hidden layers. Building a fraud detection system with ﬁve hidden layers
was almost impossible for a few years ago. With the power of computers and big
data, everything can be done easily.
AI can add intelligence to existing products. Typically, products commonly used
by users can be improved using AI capabilities, such as siri examples that are added as
features in Apple products. Smart machines can be combined with big data to improve
many technologies at home and at work, from security intelligence to investment
analysis [11].
Optical Character Recognition or optical character reader (OCR) is the elec-
tronic or mechanical conversion of images of typed, handwritten, or printed text into
machine-encoded text, whether from a scanned document, a photo of a document, a
scene-photo (for example, the text on signs and billboards in a landscape photo), or
subtitle text superimposed on an image (for example: from a television broadcast)
[12]. As seen in The way OCR works, namely leveling the image according to its
slope, analyzing the part of the image analyzed in accordance with the software.
OCR automatically identiﬁes and adjusts the direction of the image. Then, OCR can
separate each character and letter [13].
Parking spaces in the current era already have advances in technology. As seen
in [14], almost all parking spaces at the time of entry no longer require humans to
provide proof of vehicle entry, and the technology used only uses photos of license
plates and proof of vehicle entry which will appear after the driver presses the button
on the engine. This makes it easy for parking lots not to have to write license plates
and hours of entry manually, but it makes paper wasted for free and still creates
congestion [15]. By applying AI to the parking lot, the driver just goes into the
parking lot, and then, the license plate will be in the photo with AI and the data and
photos will be saved automatically. This will reduce the use of paper and can reduce
congestion that occurs in search of parking spaces [14].
Image processing are mathematical or statistical algorithms that change the visual
appearance or geometric properties of an image or transform it into another type
of dataset. Image processing and analysis often require ﬁxed sequences of local
operations to be performed at each pixel of an image, as seen in [16].
Vendors are parties that provide raw materials, services, and products resold by
other companies. Vendors themselves are individually conducted companies. The
resulting product will be sold to the end consumer. Then, vendors not only sell raw

566
M. R. Alhaﬁzh et al.
materials, but vendors also sell semi-ﬁnished products or components to make a
ﬁnished product. Vendors are very important for the smooth operation of a business.
Vendors are also sometimes used in events such as concerts or weddings. Vendors
also have such duties and responsibilities, meeting every demand from consumers.
Then, vendors make sure that every product sold to consumers is a quality product
and worth using. Also, vendors make sure that the delivery of goods/services is in
accordance with the deadline. Lastly, vendors are obliged to provide the best service
to their customers.
The deﬁnition of a database itself is a collection of data stored systematically on a
computer operated using software or applications that can generate information. This
database includes several speciﬁcations, such as data type, data structure, and also
restrictions on the data to be stored. Databases have databases that are very important
aspects because they serve as processed data warehouses. The database itself orga-
nizes data, delivers duplication of data, avoids relationships between unclear data
and also somewhat complicated updates.
The process of entering and retrieving data from a database requires software such
as database management systems or commonly said (DBMS). DBMS is a software
system that allows users to control, access data practically and efﬁciently. There are
several DBMS functions that can be handled such as data deﬁnition, handling user
requests to access data, checking data security and integrity deﬁned by Database
Administrator (DBA), handling failures in accessing data caused by system and
storage media (disk), and also handling the performance of all functions efﬁciently.
The main purpose of DBMS is to provide an abstract review of the data to the user,
so that the system can hide information about how it can be stored, maintained, and
accessed efﬁciently.
Information system is a formal, sociotechnical, organizational system designed
to collect, process, store, and distribute information. In a sociotechnical perspective,
information systems are composed of four components: task, people, structure (or
roles), and technology. As noted in [4], information systems can be deﬁned as an
integration of components for collection, storage, and processing of data of which
the data is used to provide information, contribute to knowledge as well as digital
products.
As seen in [13], information systems can be viewed as having ﬁve major compo-
nents: hardware, software, data, people, and processes. The ﬁrst three are technology.
These are probably what you thought of when deﬁning information systems. The last
two components, people and processes, separate the idea of information systems from
more technical ﬁelds, such as computer science.
The source of the information system is data. Data is a reality that describes an
event and real unity. Data is a form that is still raw, so it needs to be processed further.
Data is processed through a method to produce information, and data can be in the
form of symbols such as letters, numbers, sound forms, images, and so on.

The Adoption of Artiﬁcial Intelligence Technology in Parking Security …
567
3
Methodology
3.1
Research Methods
This journal examines research models to examine and to ﬁnd out the comparison of
Parking System Security user vehicles between cars or motorcycles, as well as the
usual parking lots visited (Table 1).
Based on the data from the chart in Fig. 1, vehicles parked in the parking lots are
trucks (2.8%), buses (1.1%), cars (43.7%), and the most parked vehicle is motorcy-
cles (52.4%). From Table 1, it can be shown that the result of the answer is more
motorcycle users in Indonesia. The detailed information can be seen in Table 1.
Table 1 Comparison of
parking security
No.
Vehicle types
Number of vehicles parked
Week 1
Week 2
1
Car
4000
5994
2
Motorcycle
6000
5999
3
Truck
300
350
4
Bus
100
150
Fig. 1 Comparison chart of vehicle parked

568
M. R. Alhaﬁzh et al.
3.2
Data Gathering Methods
This study used questionnaires with the aim to get respondents’ results about the
Parking Security System. Our sampling method is based on respondents aged 17–
20 years. Questionnaires are submitted through the Google Form as shown in Fig. 3.
Based on the data that obtained from the questionnaires, the respondents obtained
are 17 years old as many as one respondent (4%), 18 years old as many as three
respondents (12%), 19 years old as many as nine respondents (36%), and the 20 years
old as many as 12 respondents (48%) as shown in Table 2. Besides the age of the
respondents, there is also the respondents’ waiting time as shown in Fig. 2. The data
Fig. 2 Comparison chart of respondents’ waiting time
Fig. 3 Comparison chart of respondents’ age

The Adoption of Artiﬁcial Intelligence Technology in Parking Security …
569
Table 2 List of artiﬁcial intelligence’s role in changing parking ticket
No.
Age
Waiting time
Vehicle
Number of respondent
1
19
30 s
Motorcycle
9
2
20
3 min
Motorcycle
12
3
18
1 min
Public transportation
3
4
17
5 min
Car
1
Total
25
obtained are nine respondents who wait for 30 s (36%), three respondents who wait
for 1 min (12%), 12 respondents who wait for 3 min (48%), and one respondent who
waits for 5 min (4%). The detailed information can be seen in Table 2 (Fig. 3).
3.3
Data Analysis Methods
There are two methods in analyzing a data, namely qualitative data and quantitative
data. Qualitative data method is data in research that explains a phenomenon based on
things that generally cannot be calculated. Therefore, this data is called qualitative
data because it is based on the quality of an object or phenomenon. This data is
explained in the form of numbers and statistics, and qualitative data is generally
presented using descriptive explanations. In addition to qualitative data, there is also
quantitative data which is a type of data in research that can be measured, calculated,
and can be described using numbers. Generally, data like this is used to explain clear
phenomena, and there are already measuring instruments. Quantitative data is usually
obtained when conducting statistical research. This research is like collecting a lot
of data that will then be analyzed using statistical analysis to interpret the data into
a statistic.
The data we get when analyzing artiﬁcial intelligence technology in Parking
Security System is qualitative data. Because, from the research results and from
the answers of the respondents, we asked about this technology, we get data in the
form of numbers. Like the data from the comparison of vehicles that are usually
parked in public places. Then, secondly, we get comparison data from the number of
respondents waiting while waiting in line to pick up a parking ticket. Furthermore,
we get comparison data from our respondents who have answered questions in the
form of questionnaires that we provide, and such data is age comparison. Another
thing why we mention that our data is qualitative data is because there are too many
motorcycle users in Jakarta, Indonesia. The number of motorcycle users ranges from
more than 6000 units.

570
M. R. Alhaﬁzh et al.
4
Research Results
The results of the overall questionnaire from the title Artiﬁcial Intelligence Tech-
nology in Parking Security System Based on Information System that has been
distributed to 25 respondents. Sampling method is done through Google Form from
December 2 to 4, 2020. The results of the questionnaire found that 66.6% were
19 years old, 28.6% were 20 years old, and 14.3% were 18 years old as shown in
Fig. 4.
Next, we get data on how long it takes when the driver is queuing up while picking
up a parking ticket. The result showed that 42.9% chose more than 5 min and 28.6%
chose 1 min at queuing up while picking up a parking ticket. This can be seen in Table
3 in data gathering methods. Then, the comparisons of motorcycle and car users also
show that most of the respondents used car vehicles more often than the motorcycle.
From this result, it can be concluded that respondents who use car vehicles queue
longer to take parking tickets, and according to the respondents, it is very inefﬁcient
and a waste of their time.
The results of the respondents conﬁrmed that there was a problem of waste of
time as well as the use of parking ticket paper. Many respondents responded that
excessive paper consumption is very wasteful and damaging to the environment. By
implementing the artiﬁcial intelligence or AI system that is useful to replace ticket
Fig. 4 Results of questionnaire percentage on artiﬁcial intelligence technology in parking security
system based on information system
Table 3 Results of
questionnaire on artiﬁcial
intelligence technology in
parking security system based
on information system
No.
Age
Vehicle
Percentage of respondent
(%)
1
18
Public transportation
14.3
2
19
Motorcycle
66.6
3
20
Motorcycle
14.3

The Adoption of Artiﬁcial Intelligence Technology in Parking Security …
571
tickets and can save driver time, the implementation will have a positive impact on
vehicle users who often park in public places.
5
Discussion
The opinion we got from the results of the questionnaire given to respondents is
statistical data calculations which show that the average result of the comparison
between parking securities is motorcycle more users in the ﬁrst week than in the
second week. Then, for car vehicles, the comparison is more in the second week
than the ﬁrst week. Then, for truck users, the comparison is more in the second week
than the ﬁrst week. And, lastly for bus vehicle types, the comparison is more in the
second week than the ﬁrst week.
Inthesecondtable,thereisanaveragelifespanof17–20years,andrespondentsuse
motorcycles, cars, and public transportation. The results of statistical data calculation
showed that on average from the list of artiﬁcial intelligence (AI) role in changing
parking tickets, the number of respondents showed that the total of all respondents
there were 25 respondents. It can be explained that the ﬁrst motorcycle user who spent
30 s waiting amounted to nine respondents, then for the second motorcycle user who
spent 3 min waiting for 12 respondents. Furthermore, public transportation users
need a waiting time of 1 min and the calculation is obtained from three respondents.
For the latter, the results of respondents who are 17 years old require a waiting time of
5 min. Of the total respondents, motorcycle users outnet public transportation users
and 12 cars.
6
Conclusion
Artiﬁcial intelligence (AI) refers to human-like intelligence exhibited by computers,
robots, or other machines. At the learning stage, AI gives machines the ability to
learn tasks without requiring a deﬁned programming language. Then, this matter is
concerned with the parking lot to be discussed. Parking can be interpreted as public
facilities available in agencies or ofﬁces that serve to store vehicles. Today’s parking
systems still have their own drawbacks; although they use a high-level ticketing
system and cameras, they are still lacking in data collection of the number of vehicles
entering due to manual techniques in data collection. The solution to the problem can
be done by creating a system capable of recording a large number of vehicles entering
when entering the parking area. This system can be applied using image recognition
technology and OCR algorithm (Optical Character Recognition Technique), data
from vehicle plate images is converted into text or numbers and can be stored in a
database, and data from vehicle plates that have been stored and then matched with
photos of vehicles, with the help of the system, can be integrated with the camera so
that the system can know the duration of its parking. This technology can improve

572
M. R. Alhaﬁzh et al.
the safety system by reading the vehicle’s license plate. The results of the overall
questionnaire from the title Artiﬁcial Intelligence Technology in Parking Security
System Based on Information System and has been distributed to 25 respondents.
Then, comparisons of motorcycle and car users showed that many respondents used
car vehicles more often. This can be concluded that respondents who use car vehicles
longer queue to take parking tickets, and according to the respondents, it is very
inefﬁcient. The results of the respondents conﬁrmed that there was a problem of
waste of time as well as the use of parking ticket paper. Then, there are seven research
questions asked to the respondents. Of the seven research questions, there are six
questions that are optional and one question that asks for opinions from respondents.
References
1. Suhendri H, Heri, Wahyu, AP (2019) Improvement of parking security system using artiﬁcial
intelligence imaging technology. Bandung : J Inf Technol STMIK “AMIKBANDUNG” 1(2)
2. Potabuga RMS (2016) Analisis Biaya Pengelolaan Parkir Kendaraan Pengunjung Pusat
Perbelanjaan, vol 1. Ria Mentari Saidi Potabuga, Yogyakarta
3. Sfenrianto S, Wijaya T, Wang G (2017) Assessing the buyer trust and satisfaction factors. J
Theor Appl Electron Commer Res 13:718–1876
4. Valacich J, Schneider C (2010) Information systems today—managing in the digital world, vol
4. Prentice-Hall, Upper Saddle River, New Jersey
5. Acharya D, Yan W, Khoshelham K (2018) Real-time image-based parking occupancy detection
using deep learning. In Research@ Locate, pp 33–40. Amazon. (n.d.). Amazon Web Services,
https://aws.amazon.com
6. Ichihashi H, Notsu A, Honda K, Katada T, Fujiyoshi M (2009) Vacant parking space detector
for outdoor parking lot by using surveillance camera and FCM classiﬁer. In: 2009 IEEE
international conference on fuzzy systems, pp 127–134
7. RedmonJ,DivvalaS,GirshickR,FarhadiA(2016)Youonlylookonce:uniﬁed,real-timeobject
detection. In: Proceedings of the IEEE conference on computer vision and pattern recognition,
pp 779–788
8. Redmon J, Farhadi A (2017) YOLO9000: better, faster, stronger. In: Proceedings of the IEEE
conference on computer vision and pattern recognition, pp 7263–7271
9. Redmon J, Farhadi A (2018) Yolov3: an incremental improvement. arXiv preprint arXiv:1804.
02767
10. True N (2007) Vacant parking space detection in static images, vol 17. University of California,
San Diego, pp 659–662
11. Yu YJ, Moon SH, Sim SJ, Park SH (2020) Recognition of license plate number for web
camera input using deep learning technique. J Next-Generation Convergence Technol Assoc
4(6):565–572
12. Bong D, Ting K, Lai K (2008) Integrated approach in the design of car park occupancy
information system (coins). IAENG Int J Comput Sci 35(1):7–14
13. Reddy PS, Kumar GSN, Ritish B, Saiswetha C, Abhilash KB (2013) Intelligent parking space
detection system based on image segmentation. Int J Sci Res Dev 1(6):1310–1312
14. Rashid MM, Musa A, Rahman MA, Farahana N, Farhana A (2012) Automatic parking manage-
ment system and parking fee collection based on number plate recognition. Int J Mach Learn
Comput 2(2)
15. Chen M, Chang T (2011) A parking guidance and information system based on wireless sensor
network. In: 2011 IEEE international conference on information and automation, pp 601–605

The Adoption of Artiﬁcial Intelligence Technology in Parking Security …
573
16. Salma RFO, Arman MM (2019) Smart parking guidance system using 360° camera and Haar-
Cascade classiﬁer on IoT system. Int J Recent Technol Eng 8(2):864–872

A Self-organizing Map with Neural
Networks Classiﬁer Technique for Face
and Handwritten Signature Recognition
System in DIP
V. Karthi, S. Nithyasai, P. Parthasarathy, and U. Arun Kumar
Abstract Automatic biometric recognition for individuals is a challenging problem,
which has become increasingly popular in recent years by various purposes in
different ﬁelds. Face and signature identiﬁcation is the main issues, and until the
date, no methods deliver a powerful solution to all circumstances. In this work
presentsanadvancedtechniqueisusedforbothhandwrittensignatureandhumanface
recognition. Some of the most common methods used in image-based approaches
are 2D-DCT, data removal from images, and self-organizing maps utilising neural
networks. The discrete cosine extracts method extracts the feature in face and hand-
written signature based on the image color. The construct feature vectors calculate
the DCT coefﬁcients. A neural network classiﬁer with SOM is used to categorize
feature vectors based on the DCT which are used to classify the problem is present or
not in the database. Both of the biometrics images are accomplished with the power
rates of the grayscale pixels into many groups, and it also trained with the neural
network classiﬁer. The obtained result was evaluated and executed in MATLAB envi-
ronment using a various image database of the face and handwritten images which
consist of different dimensional images. Also, it observes the variation of efﬁciencies
of the system for multiple numbers of deep layers and epochs to make comparison
and contract along with a high recognition rate of 83.06% for every ﬁve trails. This
technological advantage is both memory and speed usage, which makes high-speed
performance and less computational requirement.
V. Karthi
Department of Electrical and Electronics Engineering, Builders Engineering College, Kangeyam,
Tamil Nadu 638108, India
S. Nithyasai
Department of Electronics and Communication Engineering, Kathir College of Engineering,
Coimbatore, Tamil Nadu 641062, India
P. Parthasarathy
Department of Electronics and Communication Engineering, CMR Institute of Technology,
Bengaluru 560037, India
U. Arun Kumar (B)
Department of EEE, SRM Institute of Science and Technology, Ramapuram Campus, Chennai,
Tamil Nadu 600089, India
e-mail: arun.udayakumarn@gmail.com
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_42
575

576
V. Karthi et al.
Keywords Signature recognition system · Self-organizing map (SOM) · Neural
network · Digital image processing · Discrete cosine transform
1
Introduction
Biometric security demands and its intrinsic economic and law enforcement appli-
cations have emerged as the most active ﬁeld of research in recent years. In the past
decade, it has been developed, such as Interaction of Human-Computer, analysis
of biometric, coding on the content of videos and images, and monitoring signiﬁ-
cance has shown dramatic improvement in this area. Although the human brain is an
important task, the identiﬁcation of the face has been demonstrated to be very hard
to follow a different type of color, skin, age, and gender. The various image attributes
problem is, facial furniture, facial expressions, background, and light requirements
are more complex. Represent a face image and signature veriﬁcation system is shown
in Fig. 1. A unique method of identifying the face that this work is obtained from an
concept. In its calculation, they represent the preprocessing step they were attempting
to determine the relative pixels connected with the face-described features freely.
This method designs a dramatic decrease in computational designations over earlier
methods. Because skin color is unique in humans, research suggests that the inves-
tigation is more critical than colorful intensity. An intensiﬁcation (grayscale) repre-
sentation using the 2D-DCT image of the accreditation platform is the most common
process.
Fig. 1 Face recognition based on generic representation

A Self-organizing Map with Neural Networks Classiﬁer Technique …
577
2
Literature Survey
Recently, single- and multi-model biometric systems research has been analyzed.
Below are recent multi- and unimodal biometric system studies. Skin pixel intensities
are in this grayscale rendition. A face identiﬁcation system approach block diagram
is shown. 2D-DCT is used to evaluate all input pictures, using DCT coefﬁcients as
feature vectors and value. The self-arranging map (SOM) classiﬁes identiﬁer vectors
as “present” or “not present” in the picture database using supervised learning. This
topic is structured and shows superior picture matching in the database training
system, which shows that the database image’s subject is not discovered. It clariﬁes
SOM network setup and design. The model discusses viable improvements and
improves system output.
Thesuper-resolutiontechniquehasresultedinconsiderableidentiﬁcationstandard
development [1]. This approach evaluates two sections for visual quality, and practice
and analysis face image detection differ [2]. To identify system-helpful faces, a face
image feature assessor uses two sections [3]. The discovered feature spots and their
balanced geometrical patterns are compared and created. Face recognition system
mustconsidertwins,similarfaces,age,sameindividual,etc.Thisarticledistinguishes
similar twins and faces using algorithms [4].
Yawing and pitching face images may show neutral, displeasure, scream, grin,
squint, and surprise emotions. This system evaluates our suggested approach utilizing
CMU PIE database. Our strategy improves facial recognition [5]. Face recognition
accuracy depends on data complexity and extracting fundamental facial elements.
LBP peculiarity space examined face image block signiﬁcance [6]. The efﬁcient face
detection and identiﬁcation system can recognize single and numerous face photos
in a real-time database. The suggested Framework preprocesses color pictures by
removing noise and ﬁlling holes [7]. Therefore, each has distinct anatomical features.
Face identiﬁcation biometrics are getting increasingly prevalent [8].
This method recognizes students’ faces, but they may leave the classroom and the
polling information can be inaccurate [9]. The best fusion level is related to the rating
level, resulting in soft biometric systems [10]. This system’s phase identiﬁcation
employs a protocol and its performance-based recognition ratio. Applied sensor
level fusion continues, the condition [11] In addition to facial photos with variable
lighting and backdrops, detecting the human face from hazy noise, color images, and
photographs is difﬁcult. Gabor Build Representation [12]. Fuzzy logic categorization
is better than classes for categorizing faces quickly. This study uses tool modeling
to fuzzy identify sequences in detection and video displays [13]. Clarifying video
faces requires multiple stages.
Approved multi-tool approaches avoid processing and reduce decision time. Diag-
nostic and facial classiﬁcation process is two-step. First, the system color and gigantic
face are used to generate the faces [14]. Computers worry about soft processes to
detect secured systems from the computer age [15]. After the big dispute, the cate-
gorization procedure has adjusted to address Internet security and cloud service
acceptance [16]. Most online methods utilize the longest ID for user/password [17].

578
V. Karthi et al.
Electronic certiﬁcates, personal identity documents, and pin codes through phone text
messages are among the new user access techniques that will soon be commonplace
[18–21].
Over the last two decades, biometric technology has challenged identiﬁcation as
an alternative [22–24]. They are studying Biometric Data from Biometric Science
Individuals to Possible Diseases and Its Effects for Private Activities. Provide unique
sufﬁcient qualities that make some biometrics measurements an authentication
system [25–27].
3
Proposed System
The proposed method can deal with the low-presentation difﬁculty because the
Discrete Cosine Transform-based self-organizing map (SOM) formation is to receive
low-quality images from attribution information directly. For the exact neural
network-based classiﬁcation system, the operating procedures are categories into
two types. At the ﬁrst method is provides the complete solution exploring the total
structure associated with the face and signature-less frequency domain. The resolu-
tion difference between high- and low-resolution pictures used for metric learning is
recommended to be changed. These comprehensive approaches often call for well-
adjusted pictures, and in order to maximize their performance, it is often required to
dampen the linear disorder in real-world contexts. It reveals that the low-frequency
domain local phase quantization information is mostly unaffected, making it appro-
priate for recognizing a lower-resolution face. To begin, local phase quantization
(LPQ) discards magnitude information, despite the fact that magnitude is crucial to
facial identiﬁcation. For the second part, LPQ necessitates the point spread function
(PSF)thatmakestheblurimpactpositive.Theproposedmethoduseshigh-level,area-
and frequency-speciﬁc information. This explanation uses level and grid information
rather than the LPQ.
Figure 2 describes the proposed block diagram for the face and handwritten based
signature analysis with the differential dataset. Mainly a self-organizing map (SOM)-
based neural network accurately classiﬁes the trained face images from the dataset
images.
3.1
Self-organizing Feature Map and 2D DCT is a New Face
Detection Technique
Faces reveal the ACE identiﬁcation difﬁculty. This face-to-face, face-monitoring, and
human–computerinteraction(HCI)iscrucial.Facedetectionworksaggressivelyover
a decade, but orientation, brightness, obstacles, and skin color disparities complicate.

A Self-organizing Map with Neural Networks Classiﬁer Technique …
579
Fig. 2 Proposed methodology
This study introduces low-based face detection. They discuss the preprocessing tech-
nique to detect face-related pixels freely in its computation. It dramatically reduces
processing needs for multi-resolution picture pyramids, but these pyramids no longer
require skin color testing before a multi-system candidate prepares a list of candidate
face regions. Pixel- or region-based skin region extraction is possible. Studies show
that skin color is more unique than the primary character. Because the following
phase is a gradient (grayscale) representation of the segmented picture, color space
is less important. This grayscale “skin diagram” shows skin pixel intensities on a
black backdrop. Skin diagram from color input. For ease, pre-processed VT-AAST
skin maps. This study uses the database.
Our proposed technique is provided with a block diagram. Including a segmented
image as an input, the ﬁrst level of the region will be adjusted, and the large areas were
attached to the narrow connections, the subdivision will apply to an image opening.
The performance of the region labeling is done so that each section can be different
from the others. In the second phase, the two-dimensional (2D) standalone cosine is
calculated for each region (DCT), and the DCT coefﬁcients as feature vectors.
The platform uses a self-arranging map (SOM) to analyze every aspect of the
vector as either “face” or “not face.” The yield is having been predictable by the
association faces. So, the group of locations in the original image is in the group.
Rankingandevaluatingthisnewtechnology,anewmodeliscompiledforinformation
training and testing purposes. The database containing 286 images a total of 1027
faces. Each image is available in four styles. Images are characterized not only by
their original hue but also by the color of the subjects’ skin. These GIF images are
of size 200 × 125 pixels.
3.2
Handwritten Feature Recognition
An automatic signature veriﬁcation system has been proposed. This work focuses
on handwritten signature features and aims to synchronize and verify the signature.

580
V. Karthi et al.
Signatures process data and information are collected. An image is obtained in the
data sets are the sealed signature process using the signature of scan data. Initially,
two data are undergoing preprocessing operations. The features are based on the pen
endingtrackingfeaturesonlineandarebasedongradientandproject-basedextraction
where the connection is used in case the Internet connection is inaccurate. Then the
signature checks the system individually, and ﬁnally, their results are synchronized
and checked using the signature neural classiﬁer. The paper also compares the results
of the approach to coordinating training data and information system.
3.3
Two-Dimensional Discrete Cosine Transform
The 2DPCA method consists of the covariance matrix of deﬁnitions of the S of N
training images Ai of dimensions m × n (where I = 1 to N) in 2D. The covariance
matrix S of n × n dimension is calculated by (1).
S = 1
N
N

i=1

Ai −A
T 
Ai −A

(1)
where:
A is the average matrix in the training N images. The consisting set of the k
eigenvectors related to the largest eigen values of the covariance matrix, V = [V1,
V2…Vk], of size n × k, is obtained so that the prediction of the training images about
V provides the best dispersion. V is used to obtain the feature of each training image
Ai. The feature vectors are obtained by (2).
y j,i = AiVj j = 1, 2, . . . , ki = 1, . . . , N
(2)
In the classiﬁcation proposed the similarity between the feature matrices of the
images was obtained.
When it comes to classiﬁcation, the class of the test pattern is the one that is
determined by the one that has the smallest distance between the test pattern and the
neurons of the SOMs, as seen in Figs. 3 and 4.
The most successful system recognition has been used for various problems, such
as to test an image of neural networks, and the introduction of the skin color vector
classiﬁcation test in the presence of each DCT-based feature. Using neural networks
based on several image detectors one face or face is one. Neural networks use this
paperback spread because of their ability to choose simplicity and supervised type
matching. A three-layer neural network design is used, with the input layer receiving
either a face picture or a non-face image, the hidden layers housing single neurons in
an area with a 1 × N DCT coefﬁcient vector, and the output layer having two distinct
weights of 0.9 and 0.1.

A Self-organizing Map with Neural Networks Classiﬁer Technique …
581
Fig. 3 SOM training model
Fig. 4 Neural network-based SOM system
Skinfacecolor is acquiredviatheDCTcoefﬁcient feature, andtheneural networks
are bound to carve 18 × 27 pixels from DC, with each volume 8 × 8 pixels in size.
Facial features are classiﬁed as having a velocity of 0.9 after training, whereas non-
facial features have a velocity of 0.1 after training (Va Ktar). A color image skin
color information face detection is a very popular and useful technique. This method
has the simplicity of the skin detection rules that leads to a very rapid assortment of
clear beneﬁts. The color information is used as a feature to detect from background

582
V. Karthi et al.
objects, even if not entirely because the faces of human faces differ in the human
face in a picture.
3.4
Self-organizing Map with Neural Networks Classiﬁer
Algorithm
Suppose a feed-forward the neural network is whose input (or predicted variables)
whose output (or response) is indicated without the loss of the vector X and any
general force of the output is used to approximate a resilient function when revealing
the scalar YA regression surface (input–output function) When attempting to char-
acterize the bond between X and Y, Fj is used. This association may be represented
via the training and application of a feed-forward neural network.
The SNNC algorithm is as follows:
Step 1: Read the intensity corrected image.
Step 2: Improved versions of the associated pictures that may be used in
preprocessing.
Step 3: Figure out the cutoff at each neural network iteration.
T = max(r(T ))
(4)
• Where r(T) = E(X′ −X), where X is the image and X′ is the generalized defeat
identiﬁcation.
• Perform directional diagram.
• If convergence reached, then go to step 3, else step 2 is repeated.
Step 4: Output de-noised image.
Step 5: Back-multiplication of fault at the output layer, the error between the
desired output Sk and Zk output is measured by:
Ek = Zk(Zk−1)(sk −Zk)
(5)
The error value calculation is generated on the hidden layer using the following
formula:
dx
dt = A T g(Fj)Fj
(6)
Step 6: Speciﬁcally, we use a correction for the ﬁxed attachment weights between
the input layer and the hidden layer.
DWji = nX, Fj
(7)

A Self-organizing Map with Neural Networks Classiﬁer Technique …
583
DYo = nx, fj
(8)
DYo is the after removing blurring images nx is the intensities’ function.
Then change connections between the input layer and the output layer by:
DWkj = nyjEk
(9)
N is considered to be determined empirically.
Where Ek the power energy functional static position optimization is can be
written as follows.
Step 7: Loop to st continuously a stop to deﬁne criterion (varied the parameters
clusters).
Step 8: End
4
Results and Discussion
MATLAB 2013a is the most used manipulation and operating program in the 2D, 3D
data, and picture advancing. Relevant approaches to observe and analyze simulation
outcomes in image processing are implemented based on the speciﬁc operation and
creative situation. This program will provide users with the ability to manipulate and
ﬁlter images in a wide variety of ways. Here the picture analysis uses precise color
photos and ﬁlter for additional variation.
Testıng Data 1: Recognızed
Testıng Data 2 Not Recognızed
The image recognized and not recognized signature & face veriﬁcation have been
shown in Figs. 5 and 6. The test takes the same meaning as input. Input image
and signal begins to operate using adaptive average ﬁlter and practice using LF.
Then, an algorithm based on self-organizing maps is used to do the necessary picture
preprocessing. In the end, picture and non-accredited image were used to determine
if SNNC could be recognized (Table 1).
4.1
Analysis of Various Metrics
Correlation Table 2 shows that the proposed SMNN method outperforms more tradi-
tional approaches, such as (SSF)-MNN, LFNN, PCA, and ICA, on a variety of
metrics. These metrics include accuracy, recall, precision, speciﬁcity, and sensitivity.
Furthermore, the false ratio is lowered to 0.08 using the suggested strategy, making
our system very effective. In addition to reducing the True Positive Rate, the False

584
V. Karthi et al.
Fig. 5 Detection using SNNC
Fig. 6 Detection using SNNC
Negative Rate, and the False Rejection Rate are all greatly reduced in comparison to
the current ICA and PCA technique. The comparison graph is given below.
Figure 7 compares the suggested strategy. SMNN outperforms SSF-MNN, LFNN,
PCA, ICA in sensitivity, accuracy, precision, speciﬁcity, recall, and FM. Table

A Self-organizing Map with Neural Networks Classiﬁer Technique …
585
Table 1 Evaluation parameters analysis
Performance
Value
Data set
ORL
No of persons
40 persons
No of face images
40 persons of 248 images; every person has 10 face images
No of signature
248 different signatures collected from 40 people’s signatures
Tool used
MATLAB 2013 a
Data set
ORL
Table 2 Performance comparison of data set 1
Measures
Proposed SMNN
Synthesis score
fusion-based
SSF-MNN
LFNN
Exıstıng (PCA)
Exıstıng (CA)
Precision
0.94
0.93
0.92
0.82
0.86
Recall
0.58
0.57
0.55
0.52
0.54
F measure
0.76
0.70
0.68
0.64
0.66
Accuracy
0.71
0.68
0.62
0.53
0.569
Sensitivity
0.72
0.57
0.55
0.52
0.54
Speciﬁcity
0.77
0.74
0.72
0.58
0.66
2 compares multiple recognition models. Figure 8 illustrates that the proposed
technique delays time less than alternative strategies.
0
20
40
60
80
100
Accuracy SensiƟvity Speciﬁcity precision
Recall
Fmeasure
percentage (%)
Axis Title
Performance comparison
SSF-MNN
LFNN
PCA
ICA
SMNN
Fig. 7 Comparison graph

586
V. Karthi et al.
0
20
40
60
80
ICA
PCA
 LFNN
Proposed
SCNN
Time Complexity in  
Nanoseconds
Time Complexity
Fig. 8 Comparison of time complexity
5
Conclusion
In this system the conjunction with a SOM-based classiﬁer, and the network identi-
ﬁcation technique that uses features derived from DCT coefﬁcients. The MATLAB
is used to evaluate the system was 25 face images database and signature analysis; it
consisting of ﬁve subjects and subjected to having ﬁve models and the various facial
appearances. The training about 850 eras, the organization, received an accredited
rate of 83.06% with 10 consecutive tests. The feature space is reduced to described
above test 2; the reduced computational demands once compared to the standard DCT
feature extraction methods. With this low cost, real-time hardware is much better on
our system to implement. There is no commercial implementation of this strategy at
present. However, it is assumed that a useful SOM-based face identiﬁcation system
may be possible in the future.
References
1. Mahood A, Sobh T, Elsayed A (2017) Effect of super resolution on high dimensional features
for unsupervised face recognition in the wild. IEEE Recogn. Appl. Imagery Pattern Workshop
1–5
2. Lee H-I, SH, Ro YM, Kim (2015) Face image assessment lea grant with the objective and
reactive face image qualities for improved face recognition. In: IEEE conference on image
processing, pp 4021–4031
3. Chen, Huang Y-S, S-Y (2015) Ageometrical model based face identiﬁcation. In: IEEE
conference on image processing, pp 3106–311
4. Shamugapriya P, Prema R (2017) A review face recognition techniques for differentiating
the faces and twin faces. In: Conferences on data analytics, energy, communication, and soft
computing, pp 2899–2902
5. Madarasmi S, Chamnongthai K, Petpairote C (2017) A pose and expression face recognition
using transfer based on single face neutral references. In: Global wireless summit, pp 123–126

A Self-organizing Map with Neural Networks Classiﬁer Technique …
587
6. Pavlovicova J, Oravec M, Loaderer M, Mazanec J (2015) Face parts importance in the face and
expression recognition. In: International conferences on system, signals and image processing,
pp 188–191
7. Santhoshkumar SP, Beaulah HL, Alqahtani AS, Parthasarathy P, Mubarakali AA, Remote
diagnosis of Parkinson’s ailment using artiﬁcial intelligence based BPNN framework and
cloud based storage architecture for securing data in cloud environment for the application
of telecommunication technologies. Comput Intell
8. Qasim T, Bakhat K, Sammem MSI (2016) Real image recognition of human faces. In:
International conference on open source system and technologies, pp 62–65
9. Varol A, Haji S, (2016) Real Ti Me face recognition system (RTFRS). In: International
symposium on digital forensic and security, pp 107–111
10. Tanriverdi MS (2017) Face recognition—based mobile automatic classroom attendances
management system. In: International conferences on cyber words (Cw)
11. Chawla S, Arrora S (2015) An intensiﬁed approach to face recognition through the average
half face. In: IEEE India conferences, pp 1–6
12. Kumar A, Punyani P (2017) Evaluation of fusion at different levels for face analysis. In:
International conference communication, and automation, pp 1052–1055
13. Gholami V, Khaleghi MR, Pirasteh S, Booij MJ (2022) Comparison of self-organizing map,
artiﬁcial neural network, and co-active neuro-fuzzy inference system methods in simulating
groundwater quality: geospatial artiﬁcial intelligence. Water Res Manag 1–19
14. Amin MA, Yan H, Poon B (2016) Gabor phase analysis on human face recognition for distorted
image. In: International conference on wavelet analysis and pattern recognition, pp 276–281
15. Abadianto, Wait DAR (2017) Design of classiﬁcation system and face detection for smart
home security application. International conference on information technology In: Information
system and electrical engineering, pp 342–3347
16. Fakir M, Chabi M, Hatimi H, (2016) Face recognition using a fuzzy approach and a multi-model
system from video sequence. In: International conference on computer graphics, visualization
and imaging, pp 442–447
17. Vijayarajeswari R, Parthasarathy P, Vivekanandan S, Basha AA (2019) Classiﬁcation of
mammogram for early detection of breast cancer using SVM classiﬁer and Hough transform.
Measurement 146:800–805
18. Rajesh KM, Naveen Kumar M (2016) A robust method for face recognition and face emotion
detection system using support vector machines. In: 2016 international conference on electrical,
electronics, communication, computer and optimization techniques (ICEECCOT), pp 1–5.
https://doi.org/10.1109/ICEECCOT.2016.7955175
19. Travieso CM, Dutta MK, Pitters-Figueroa FA, Singh A (2017) Biometric identiﬁer-based on
hand and hand-written signature classiﬁcation and contour information. In: Tenth international
conference on contemporary computing, pp 1–6
20. Kumar U, Kavya G, Kishore J, Raj KAN (2018) BL-CSC converter fed BLDC Motor drive
with sensorless control. In: 2018 4th international conference on electrical energy systems
(ICEES), pp 449–453. https://doi.org/10.1109/ICEES.2018.8443286
21. Parthasarathy P, Vivekanandan S (2020) A typical IoT architecture-based regular monitoring
of arthritis disease using time wrapping algorithm. Int J Comput Appl 42(3):222–232
22. Basavaraj L, Prathiba MK (2017) Signature veriﬁcation system based on wavelets. In: Inter-
national conferences on recent advances in electronic and communication technology, pp
149–153
23. Seakar VC, Viswanath (2017) A style preserving shape representation scheme sor handwritten
gesture recognition. In: Ninth conference on advances in pattern recognition, pp 1–6
24. Jahan MV, Farimani SA, Jahan MV (2018) A hmm for online signature veriﬁcation based on
movement directions and velocity. In: Iranian joint congress on fuzzy and intelligent system,
pp 205–209
25. Kumar UA, Ravichandran CS (2021) Upgrading the quality of power using TVSS device and
PFC converter fed SBLDC motor. Arab J Sci Eng. https://doi.org/10.1007/s13369-021-056
00-z

588
V. Karthi et al.
26. ZhangR,Ritchie M,Li G,GrifﬁthsH(2017)Sparsitybaseddynamic handgesture identiﬁcation
using micro-doppler signatures. In: IEEE radar conference, pp 1258–1260
27. Matrouk K, et al (2022) Energy efﬁcient data transmission in ıntelligent transportation system
(ıts): millimeter (mm wave) based routing algorithm for connected vehicles. Optik 170374
28. Vincent Paul SM, Balasubramaniam S, Panchatcharam P, Malarvizhi Kumar P, Mubarakali A
(2022) Intelligent framework for prediction of heart disease using deep learning. Arab J Sci
Eng 47(2):2159–2169

CISUM: Novel Research on Cloud
Computing Simulators and Future Scope
for Computational Research
C. S. Ashwin, V. K. G. Kalaiselvi, and K. R. Rangarajan
Abstract For the primary purpose of this research, key emphasis is on comprehen-
sively reviewing existing literature on the usage of cloud computing simulators. For
concluding this research, several types of cloud simulators are identiﬁed, reviewed,
and compared with one another based on speciﬁc criteria of technical features. As
concluded in the research, the most crucial aspects related to cloud simulation are
the scope of accessing it from any location, and hence, presenting enhanced ﬂex-
ibility for the users, delocalising staff training, and ensuring learning on basis of
collaborative and dynamic learning. Hence, the future scope of simulation lies in the
system of cloud computing with a possibility that all engineering simulations will
be conducted using cloud computing.
Keywords Cloud computing · Cloud computing simulation · Simulators · And
computation
1
Introduction
Cloud computing broadly refers to the services and applications that run on a
distributed network using internet protocols and virtualised resources, which are key
requisites for it to operate [1]. Since recent times, cloud computing has rapidly devel-
oped while gaining the attention of several researchers, practitioners, and investors.
This can be regarded as an outcome of the evolution of distributed client-server
computing from centralised mainframe computers [1]. However, even though the
C. S. Ashwin (B)
Information Systems, Sri Sai Ram Engineering College, Chennai, Tamil Nadu 600044, India
e-mail: tocsashwin@gmail.com
V. K. G. Kalaiselvi
Associate Professor, Sri Sai Ram Engineering College, Chennai, Tamil Nadu 600044, India
e-mail: Kalaiselvi.IT@sairam.edu.in
K. R. Rangarajan
Information Technology, Sri Sai Ram Engineering College, Chennai, Tamil Nadu 600044, India
e-mail: ranga1290@gmail.com
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_43
589

590
C. S. Ashwin et al.
commencement of cloud computing has taken place since the past decade, it is still
inits earlystages, consideringthechallengedencounteredinit. Moreover, settingupa
physical cloud for experiments and research on cloud computing may not be feasible
and economical for industries and research institutions [2]. Therefore, simulations
have emerged as a common tool to infer the knowledge of impact design choices in
systems, as straightforward experiments may not be realistic and extremely expen-
sive. Hence, simulators play an important role in reducing costs, efforts, and chances
of malfunction, while boosting conﬁdence [2]. The usage of computing simula-
tors assists in designing and foreseeing the performance of systems, structures, and
machines, without actually building components in the real world.
Cloud simulators help to model different types of cloud applications by creating
virtual machines, data centres, as well as other utilities that can be properly
constructed. There are several cloud simulators that have been proposed and devel-
oped by different institutions for conducting cloud research [3]. These simulators
have variety of features that differentiate them from each other, such as user interface,
base programming language, licensing, and extensibility [3]. The aim of this research
istocomprehensivelyreviewexistingliteratureontheuseofcloudcomputingsimula-
tors, thereby focusing on their features, and analysing their strengths and drawbacks.
Several simulators of cloud computing are compared on the basis of speciﬁc criteria.
2
Related Works
Since the last few years, cloud computing has been gaining signiﬁcant popularity
as it presents an efﬁcient and ﬂexible solution for several services by using the
internet [4]. Cloud is an extremely complex and large system as it comprises various
storage technologies, internet latencies, bandwidths, algorithms of task scheduling,
service brokers, physical machines, service providers, and several users. On the
contrary, there is a need for several conﬁgurations in order to succeed in cloud-
based implementations [4]. Therefore, it is extremely challenging for researchers to
successfully assess policy performances in the actual cloud environment. The tool of
cloud simulation is an attractive and viable solutions for the challenge as it provides
scope to analyse system behaviour and consider components in several scenarios [5].
The environments of cloud computing have certain attributes such as scalability,
dynamicity, and heterogeneity which hold the requirement of speciﬁc resource tools.
Thereal performanceof cloudexperiments is challenges bycertainlimitations related
to hardware and software rescaling and reconﬁguration. These end up impeding the
performance delivered by the entire system [6]. Service researchers and providers
should be tuning their proposed method of cloud computing in various scenarios with
several resources for realising its full potential prior to its use across the real envi-
ronment. Simulation is a technique and science used for making a process model or
system, designed speciﬁcally for the purpose of testing and evaluating the strategies.
Simulation focuses on studying and understanding system behaviour or considering
the evaluation of several strategies [6]. Simulators play a crucial role to design the

CISUM: Novel Research on Cloud Computing Simulators and Future …
591
model of the entire system and conduct model experiments. The model can be used
further ahead in order to understand system behaviour or evaluate several strategies
for system operability.
Traditional system simulators cannot model the community of cloud computing,
and hence, several researchers focus on this concern while designing toolkits of
simulation for cloud computing [7]. Nevertheless, as several cloud simulators are
available, it is crucial to evaluate these tools for selecting the most suitable ones for
future systems in computational research [7]. Several cloud tools have been surveyed
in the past, and majority of the researchers investigated the high-level attributes and
architecture of all of these simulators.
2.1
Beneﬁts of Cloud Simulation
The utilisation of cloud simulator assists to model various types of cloud applica-
tion by creating virtual machines, data centres, and additional utilities for proper
construction. Therefore, it makes a stress-free environment for analysis. Till the
current scenario, several cloud simulators are developed, proposed, and used by
several institutions for computing research [8]. These developed and proposed simu-
lators have various features which differentiate all of them from one another. Some
of these features are extensibility, base language of programming, licensing, and user
interface. There are several researchers in existing literature investigating different
types of cloud simulators. The utilisation of simulator comes with a number of bene-
ﬁts like minimised cost; in such a manner that rather than purchasing costly software
and hardware, there is availability of various simulators free of cost [8]. In addition,
the utilisation of simulator helps in easy controllable and repeatable experiments.
Since there is simulation of experiments, there is no speciﬁc requirement to set up
the entire physical system. Simulators also create a friendly environment for easily
evaluating performance in several scenarios involved various conditions.
2.2
Challenges in Cloud Simulation
Majority of the challenges faced during the development of cloud computing by
software architects are also faced by cloud simulators. These challenges are to deter-
mine approaches for routing requests of networking and rerouting for the reduction
of delayed arrival [9]. Therefore, cloud simulators have to emphasise upon proposing
alternates in order to solve trafﬁc concerns such as the ones existing in data centres of
real cloud. Utilisation of relay switches, management of trafﬁc with central control,
routing on the basis of service, or enabling decision-making for user can include
such alternates [10]. Other challenges involved in the network model of cloud simu-
lation are signiﬁcant to the selection of ﬂexible and ﬁxed mechanism of bandwidth
allocation. In addition, the simulation design should be considering the topology

592
C. S. Ashwin et al.
of interconnection. In the real environment of cloud computing, a well-connected
model is unusual, and hence, simulators should be modelling realistic networks by
the addition of access level, aggregate, and additional root level switches. There can
also be several internal and external challenges in designing the method of resource
allocation for the cloud environment [11]. External challenges include dynamic users
in demand of resources, geographical challenges, and optimisation of cost model for
maximising revenue. Hence, such challenges can result in limiting the location of
virtual machine.
3
Proposed Work
For the purpose of presenting this research, key emphasis is laid upon comprehen-
sively reviewing existing literature on the usage of cloud computing simulators.
For concluding this research, several types of cloud simulators will be identiﬁed,
reviewed, and compared with one another based on speciﬁc criteria of technical
features. An online desk-based research is conducted for reviewing existing liter-
ature related to different types of cloud simulators. Secondary data are the data
collected by others and using them in context with a speciﬁc research topic.
Hence, a qualitative methodology has been adopted in this research for achieving
the research aim and presenting relevant discussion regarding the same. In qualitative
methodology, descriptive texts and data are used rather than using numerical data and
statistical analysis for collecting and analysing data. Credible sources will be used in
the research for ensuring reliable and valid information which is collected in accor-
dance with usage of cloud computing simulators. The comparison of data collected
on different cloud simulators will be done on the basis of four factors: underlying
platform, companionship of hardware or software, programming language, and the
types of services (SaaS, PaaS, and IaaS).
4
Results Analysis
4.1
Comparison of Cloud Simulators
S. No.
Cloud computing
simulators
Underlying
platform
Software/hardware
companionship
Programming
language
Types of
services
(SaaS,
PaaS, and
IaaS)
1
CloudSim
SimJava
Software
Java
IaaS
2
CloudAnalyst
CloudSim
Software
Java
IaaS
(continued)

CISUM: Novel Research on Cloud Computing Simulators and Future …
593
(continued)
S. No.
Cloud computing
simulators
Underlying
platform
Software/hardware
companionship
Programming
language
Types of
services
(SaaS,
PaaS, and
IaaS)
3
GreenCloud
NS2
Both
C++/oTcl
IaaS
4
iCanCloud
SIMCAN,
OMNET, MPI
Software
C++
IaaS
5
MDCSim
CSIM
Software
C++/Java
–
6
NetworkCloudSim
CloudSim
Software
Java
IaaS
7
EMUSIM
CloudSim and
AEF
Both
Java
IaaS
8
CloudReport
CloudSim
Software
Java
IaaS and
SaaS
9
CloudSched
–
Software
Java
IaaS
10
CloudExp
CloudSim
Software
Java
IaaS,
SaaS, and
PaaS
11
DCSim
–
Software
Java
IaaS and
PaaS
12
ICARO
–
Software
Java
IaaS and
PaaS
13
SPECI
SimKit
Software
Java
IaaS
14
GroudSim
–
Software
Java
IaaS
15
SmartSim
CloudSim
Software
Java
IaaS
16
SimIC
SimJava
Software
Java
–
17
DynamicCloudSim
CloudSim
Software
Java
IaaS
18
CloudSimSDN
CloudSim
Software
Java
IaaS
19
SecCloudSim
iCanCloud
Software
C++
IaaS
20
CEPSim
CloudSim
Software
Java
IaaS
21
PICS
–
Software
Python
IaaS
22
TeachCloud
CloudSim
Software
Java
IaaS
23
CDOSim
CloudSim
Software
Java
IaaS
24
CloudNetSim++
CloudSim
Software
Java
IaaS
25
DartCSim +
CloudSim
Software
Java
IaaS
26
GDCSim
Bluetool
Software
C++/XML
IaaS
27
FlexCloud
–
Software
Java
IaaS
28
VirtualCloud
–
Software
XML
IaaS
29
Cloud2Sim
CloudSim
Software
Java
IaaS
30
DesktopCloudSim
CloudSim
Software
Java
IaaS
31
WorkﬂowSim
CloudSim
Software
Java
IaaS
(continued)

594
C. S. Ashwin et al.
(continued)
S. No.
Cloud computing
simulators
Underlying
platform
Software/hardware
companionship
Programming
language
Types of
services
(SaaS,
PaaS, and
IaaS)
32
CloudMIG
CloudSim
Software
Java
IaaS and
PaaS
33
EduCloud
–
Both
Java
IaaS
4.2
Comparative Discussion
All of the compared simulators are clearly supporting various quality metrics. All
the simulators support a combination of quality metrics which are different from
other simulators but share the scope to implement extension of quality metrics with
additionalmetricsonthebasisofrequiredproblemstobeaddress[12].Thesimulators
also suggest optimum conﬁguration in the elements of cloud for supporting the
environment under investigation. All of the investigated simulators relate dynamic
operabilityofexperimentsthatprovidetheabilitytousersforchangingtheconﬁgured
elements while conducting the experiments [12]. There is also strong support of user
preferences for the parameters of experiments so that users can keep them for the
future operability of the experiments.
Only 50% of the cloud simulators have graphical interface of user. Researchers
show preference towards simulators for supporting the graphical interface so that
there is easy conﬁguration and operability of experiments. All of the compared
simulators support operability of experiments for long durations with the save pref-
erences of users so that average experiment results can be obtained [13]. Fifty-two
% of the cloud simulators are developed on the simulator of CloudSim (see Fig. 1
for CloudSim architecture). This indicates why Java is among the most common
language of programming utilised for the development of cloud simulators. The
second base language of programming is C++. Only one simulator, PICS was devel-
oped by the use of Python. EduCloud, EMUSIM, and GreenCloud are among the
sole simulators that involve the combination of hardware modelling and simulation
by simulating the cloud software [13].
Ninety-ﬁve % of simulators support the simulation of IaaS, while some of them
are supported by the simulation of SaaS and PaaS. Approximately 76% of the cloud
simulators under investigation are present under the licensing of download through
open-source code. Approximately 80% of the cloud simulators compared support
modelling on the basis of cost [14]. This is crucial for cloud providers for the exami-
nation of new pricing strategies and plans. Some of the simulators do not support the
placement of communication for interacting with the cloud components. Majority of
the simulators are fast and clearly express results of experiments at an extremely fast

CISUM: Novel Research on Cloud Computing Simulators and Future …
595
Fig. 1 CloudSim architecture
pace [14]. Sixty % of the simulators support modelling of energy through modelling
devices, servers, and networks. Approximately 70% of the investigated simulators
support the modes of power saving or event to collect information related to the
power consumer of devices. Approximately 40% of the cloud simulators support the
simulator of federation policy as the requirement of studying by the connection of
multiple clouds [15]. iCanCloud architecture is shown in Fig. 2.
Out of all of the simulators, iCanCloud is the sole simulator which plans for
obtaining features to operate various independent experiments parallel to the utilisa-
tionofresourcesavailableforthesimulator.Allofthecomparedsimulatorsareknown
for supporting applicable model by the parameterisation of data transfer, computa-
tion, and deadlines for support execution [16]. All of the simulators related to network
simulation are related to the simulation of packets communicated across the elements
of cloud. SecCloudSim and CloudExp are the key simulators that support features
of security while modelling communication between cloud components.

596
C. S. Ashwin et al.
Fig. 2 iCanCloud architecture
4.3
Future Scope of Cloud Simulation
Cloud computing is a crucial technology that consolidates great levers for the promo-
tion of innovation and consolidation of digitalisation across businesses [16]. The
most crucial aspects related to cloud simulation is the scope of accessing it from any
location, and hence, presenting enhanced ﬂexibility for the users, delocalising staff
training, and ensuring learning on basis of collaborative and dynamic learning. In
a way, it facilitates co-existence with uncertain situations caused as a result of the
pandemic, where it is impossible for making necessary predictions [18]. In addition,
by the integration of teams from various locations, cloud simulators are tools used
for encouraging team development and promoting group learning.
The utilisation of cloud simulator will further signify reduced costs of personnel
mobilisation and travels [17]. It affects several costs as the same simulator is utilised
by several business in a delocalised manner, without the transportation of physical
simulator to every site. Thus, operations and applications are optimised without the
sacriﬁce of performance in comparison with a simulator of full scope [19]. Hence,
the future scope of simulation lies in the system of cloud computing with a possibility
that all engineering simulations will be conducted using cloud computing due to its
beneﬁts and potential.

CISUM: Novel Research on Cloud Computing Simulators and Future …
597
5
Conclusion
The utilisation of cloud simulator assists to model various types of cloud applica-
tion by creating virtual machines, data centres, and additional utilities for proper
construction. Therefore, it makes a stress-free environment for analysis. Till the
current scenario, several cloud simulators are developed, proposed, and used by
several institutions for computing research. These developed and proposed simula-
tors have various features which differentiate all of them from one another. As per the
data analysed in this research, it can be concluded that all of the compared simulators
are known for supporting applicable model by the parameterisation of data transfer,
computation, and deadlines for support execution. All of the simulators related to
network simulation are related to the simulation of packets communicated across the
elements of cloud. SecCloudSim and CloudExp are the key simulators that support
features of security while modelling communication between cloud components.
References
1. Mansouri N, Ghafari R, Zade BM (2020) Cloud computing simulators: a comprehensive review.
Simulat Model Pract Theor 104:102–144
2. Lin W, Xu S, He L, Li J (2017) Multi-resource scheduling and power simulation for cloud
computing. Inf Sci 397:168–86
3. Silva Filho MC, Oliveira RL, Monteiro CC, Inácio PR, Freire MM (2017) CloudSim Plus: a
cloud computing simulation framework pursuing software engineering principles for improved
modularity,extensibilityandcorrectness.In:2017IFIP/IEEEsymposiumonintegratednetwork
and service management (IM). IEEE, pp 400–406
4. Kumar P, Kumar R (2019) Issues and challenges of load balancing techniques in cloud
computing: a survey. ACM Comput Surv (CSUR) 51(6):1–35
5. Yadav R, Zhang W, Kaiwartya O, Singh PR, Elgendy IA, Tian YC (2018) Adaptive energy-
aware algorithms for minimizing energy consumption and SLA violation in cloud computing.
IEEE Access 6:55923–36
6. Subramanian N, Jeyaraj A (2018) Recent security challenges in cloud computing. Comput
Electr Eng 71:28–42
7. Zhang X, Wu T, Chen M, Wei T, Zhou J, Hu S, Buyya R (2019) Energy-aware virtual machine
allocation for cloud with resource reservation. J Syst Softw 147:147–161
8. Mansouri N, Mohammad Hasani Zade B, Javidi MM (2019) Hybrid task scheduling strategy
for cloud computing by modiﬁed particle swarm optimization and fuzzy theory. Comput Ind
Eng 130:597–633
9. Suh YK, Lee KY (2018) A survey of simulation provenance systems: modeling, capturing,
querying, visualization, and advanced utilization. Hum Centric Comput Inf Sci 8:1–29
10. Devesh SS, Jinwala C, Garg S (2017) A survey of simulators for P2P overlay networks with
a case study of the P2P tree overlay using an event-driven simulator. Eng Sci Technol Int J
20(2):705–720
11. Zeng X, Garg SK, Strazdins P, Jayaraman PP, Georgakopoulos D, Ranjan R (2017) IOTSim: a
simulator for analysing IoT applications. J Syst Archit 72:93–107
12. Piraghaj SF, Dastjerdi AV, Calheiros RN, Buyya R (2017) ContainerCloudSim: an environment
for modeling and simulation of containers in cloud data centers. Software: Pract Exp 47(4):505–
521

598
C. S. Ashwin et al.
13. Son J, Buyya R (2018) A taxonomy of software-deﬁned networking (SDN)-enabled cloud
computing. ACM Comput Surv (CSUR) 51(3):1–36
14. Arunarani AR, Manjula D, Sugumaran V (2019) Task scheduling techniques in cloud
computing: a literature survey. Future Gen Comput Syst 91:407–415
15. Strumberger BN, Tuba M, Tuba E (2019) Resource scheduling in cloud computing based on a
hybridized whale optimization algorithm. Appl Sci 9(22):4893
16. ChaﬁSE, Balboul Y, Mazer S, Fattah M, Bekkali ME, Bernoussi B (2021) Cloud computing
services, models and simulation tools. Int J Cloud Comput 10(5–6):533–547
17. Kratzke N, Siegfried R (2021) Towards cloud-native simulations–lessons learned from the
front-line of cloud computing. J Defense Model Simul 18(1):39–58
18. Sefati S, Mousavinasab M, Zareh Farkhady R (2022) Load balancing in cloud computing
environment using the Grey wolf optimization algorithm based on the reliability: performance
evaluation. J Supercomput 78(1):18–42
19. Yu H (2021) Evaluation of cloud computing resource scheduling based on improved
optimization algorithm. Complex Intell Syst 7(4):1817–1822

Arabic Sentiment Analysis of YouTube
Comments Using Deep Learning Model
Mohammed Alkoli and B. Sharada
Abstract With the present prevalence of social media websites, acquiring user prior-
ities has become an essential chore for assessing their online habits and behaviors.
Because Arabic is among the most prevalent languages throughout the globe as
well as the quickest expanding language on the Internet, we are motivated to create
dependable automated technologies. We developed a sentiment analysis on YouTube
comments premised on manually collected Arabic comments in this research. This
work was divided into four stages: preprocessing, feature extraction, optimum feature
selection, as well as classiﬁcation. Tokenization, stemming, and stop word removal
are all part of the preprocessing process. We designed two unique features, Proposed
Term Frequency Inverse Document Frequency (Proposed TD-IDF) and improved
word2vect-based features, to improve feature extraction with the conventional bag-
of-words feature extraction. In addition, for optimal feature selection, we introduced
a new optimization technique called the Self-Improved Honey Badger Algorithm
(SIHBA).
Keywords Term frequency inverse document frequency (TD-IDF) · Improved
Honey Badger Algorithm (SIHBA) · Bidirectional-LSTM
1
Introduction
The volume of Arabic material produced for websites as well as social media plat-
formshasincreaseddramaticallyduringthepastcoupleofyears[1].Currently,people
interact online and express their thoughts through comments on online networking
platforms like Facebook, Instagram, as well as Google + . In terms of video distri-
bution, YouTube is generally regarded as the best. It is the world’s biggest platform
where users may upload and make suggestions on videos to convey their opinions
[2]. Sentiment analysis seems to be vital in social networking surveillance due to the
M. Alkoli (B) · B. Sharada
Department of Studies in Computer Science, University of Mysore, Manasa Gangothiri, Mysuru,
Karnataka 570006, India
e-mail: alkolim528@gmail.com
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_44
599

600
M. Alkoli and B. Sharada
impact of media blogs on democratic governance, advancement, diplomacy, as well
as enterprise. It does this by allowing an insight into the general public’s view on
subjects that show up in a diverse range of posts, from blogs about politicians to user
reviews. Recognizing the motivation and perspective behind a comment on any topic
makes it simple to plan and strategize, which improves services [3]. Advanced quan-
titative as well as machine learning frameworks have been used in sentiment analysis
(SA), a crucial location of Natural Language Processing (NLP), to evaluate feelings,
moods, as well as thoughts in a diverse array of contexts, along with consumer
fulﬁllment, market reach, price trends, and public support for democratic choices
and events. Systems for sentiment analysis have lately received increased attention
as social media as well as web applications have grown in popularity. According to
the rising number of Netizens who use Arabic, which makes up approximately 5%
of all users globally [4–6], the emphasis is on feelings conveyed in that language.
According to SA, it is generally vital to recognize the four components that make
up an entity: its perspective, the viewpoint holders, and their feeling [7]. Finding
the sentiment (positivity, negativity, or neutrality) of an author is the goal of Arabic
sentiment analysis (ASA), also known as opinion extraction. Tweets on various social
media sites including Fb page, YouTube, Insta, as well as Twitter reﬂect a wide range
of perspectives. Recent years have seen a rise in interest in this area of study, partic-
ularly in English. Only a few works have utilized ASA thus far, despite the Arabic
language being considered the most helpful language on social networking sites
[8, 9]. A lot of studies have been performed on Arabic sentiment analysis (ASA)
during the past few years. Technologies for sentiment analysis were conducted in
many distinct ﬁelds utilizing a variety of strategies and machine learning techniques
[10]. Regarding the diversity of preceding attempts, these are generally limited by the
corpora size and restrict the generalization of the machine learning model, especially
while deep neural networks are being used [11, 12].
Despite these, we have developed an Arabic sentiment analysis of YouTube
comments, which uses Bi-LSTM to classify the comments based on the selected
optimal features and the contributions of our proposed work, as given below.
• Arabic sentiment analysis was conducted on manually collected YouTube
comments which use Bi-LSTM to provide better classiﬁcation results.
• With the conventional bag-of-words feature extraction, two novel features such
as proposed TD-IDF and improved word2vec-based features were developed to
get higher classiﬁcation results.
• A Self-Improved Honey Badger Algorithm was developed in this work, which
reduces the computational time by selecting the optimal features from those
extracted features.
The following is how this paper was structured: Sect. 2 contains several papers
relevant to Arabic sentiment analysis (ASA). Section 3 has a brief overview of our
proposed methodology, Sect. 4 comprises the ﬁndings of our work, Sect. 5 contains
the conclusion of our work, and the following section contains the references to this
work.

Arabic Sentiment Analysis of YouTube Comments Using Deep …
601
2
Literature Survey
Some of the works which are related to the ASA were reviewed here.
Hasna et al. [13] proposed an Arabic sentiment analysis approach that integrates
an Arabic BERT tokenizer instead of using a basic BERT tokenizer. For hyperpa-
rameter optimization, this work uses the random search method. Abdullah et al. [14]
suggested a machine learning (ML) strategy for analyzing Twitter Arabic postings.
Word2Vec was utilized in this approach for the embedding of the word that was the
signiﬁcant supply of characteristics.
A unique deep learning framework for Arabic language sentiment analysis was
offered by Abubakr et al. [15] and is built on two layers of LSTM to preserve long-
termconnectivityandonelayerofCNNarchitectureforextractingfeatures.TheSVM
classiﬁer delivers the end categorization utilizing the feature maps learned by CNN as
well as LSTM. To optimize Arabic sentiment analysis, Hanane et al. [16] created an
effective bidirectional LSTM network (Bi-LSTM) by employing Forward–Backward
encapsulation of contextualized data from Arabic characteristic sets. A unique deep
learning-dependentapproachthatconcurrentlycomputescontextualizedembeddings
at the character, phrase, as well as sentence levels, as presented by Mohammed et al.
[17], employs a basic positional binary embedding scheme (PBES).
Since Arabic is the fourth most widely spoken language and the language with the
fastestexpandinguserbaseontheInternet,whereusageisincreasingatapaceof6.6%
annually, Arabic sentiment analysis is regarded as a signiﬁcant research endeavor in
the ﬁeld of sentiment analysis. However, it is thought to be a difﬁcult challenge to
perform sentiment analysis for Arabic as a Morphological Rich Language (MRL).
Each Arabic root term has numerous derivatives, each of which has virtually entirely
distinct connotations and polarities depending on the locality and dialect. Derivatives
can occasionally have various interpretations and polarities.
3
Methodology
With the current level of ubiquity of social media websites, obtaining the user’s pref-
erences automatically became a crucial task to assess their tendencies and behaviors
online. Arabic language as one of the most spoken languages in the world and the
fastest growing language on the Internet motivates us to provide reliable automated
tools that can perform sentiment analysis to reveal users’ opinions. In this research
work, a novel Arabic sentiment analysis technique on YouTube comments will be
developed. The projected model encapsulates four major phases.
In the preprocessing step, stop words, stemming, and tokenization will be used to
preprocess the acquired raw data. The second phase involved extracting features from
the preprocessed data, including bag-of-words, Proposed Term Frequency Inverse
DocumentFrequency(TD-IDF),andimprovedword2vect-basedfeatures.Inthethird
phase, the Self-improved Honey Badger Algorithm (SIHBA) will be used to choose

602
M. Alkoli and B. Sharada
the features that are most ideal from those that have already been chosen. Finally,
the bidirectional long short-term memory will be used for the review classiﬁcation
(Bi-LSTM). The SIHBA model’s optimally chosen features will be used to train
the Bi-LSTM classiﬁer. Bidirectional long-term dependencies between time steps of
time series or sequence data are learned via a bidirectional LSTM (Bi-LSTM) layer.
When you want the network to learn from the entire time series at each time step,
these dependencies can be helpful. The ﬁnal results will show whether the collected
feedback is positive, neutral, or negative.
Figure 1 manifests the architecture of our proposed work.
Fig. 1 Architecture of the proposed Arabic sentiment analysis method

Arabic Sentiment Analysis of YouTube Comments Using Deep …
603
3.1
Preprocessing
Preprocessing is indeed a vital step in computer vision. To render the input infor-
mation convenient to read and utilize, we used three preprocessing strategies in our
research: tokenization, stemming, as well as stop word removal. Each process would
be described in full below.
3.1.1
Tokenization
This stage partitions the ﬁles into words/terms and then turns those into a bag of
words. This would be accomplished through the use of unigrams and bigrams,
including trigrams, which are described as patterns of just one, two, or three
contiguous words drawn from a list of tokens. We primarily employed unigrams,
except in a few cases where two-word phrases were required.
3.1.2
Stemming
Stemming has been used to lessen the count of words (dimension reduction), compu-
tation difﬁculty, and overall operating speed. Stemming technologies function by
deleting words’ sufﬁxes as well as preﬁxes.
3.1.3
Stop Word Removal
Stop words are ﬁrst compiled into a list, after which they are eliminated. Even though
they are used more often, these terms typically have no clear meaning. Stop words
should be eliminated so that we may focus on the words that have the most signiﬁcant
meanings.
3.2
Feature Extraction
This feature extraction approach minimizes the count of characteristics in a dataset by
generating new ones from existing ones, which enhances both training speed as well
as accuracy. Bag-of-words, Proposed Term Frequency Inverse Document Frequency
(TD-IDF)-based, as well as improved word2vect-based features have been extracted
to decrease overﬁtting and training time.

604
M. Alkoli and B. Sharada
3.2.1
Bag of Words (BoW)
A bag of words seems to be a text-structuring approach in Natural Language
Processing. In technical words, it is a feature retrieval approach using text data.
This method is indeed a basic yet adaptable method of retrieving characteristics
from documents. The bag of— words is a textual portrayal of the incidence of words
inside a document. We only count words and ignore grammatical subtleties and
word order. The term “bag of words” refers to the fact that any data on the sequence
or structure of words in the document are deleted. The model simply cares about
whether identiﬁable terms appear in the document, not where they appear.
One of the most signiﬁcant issues with text is that it is very chaotic as well as
unorganized, while machine learning schemes favor organized, well-deﬁned ﬁxed-
length input data. Fortunately, we can turn variable-length texts into ﬁxed-length
vectors by using the bag-of-words approach. Furthermore, the ML algorithms deal
with mathematical information instead of textual information at a much ﬁner level. To
be more exact, we turn a sentence into its vector of integers utilizing the bag-of-words
(BoW) mechanism.
3.2.2
Proposed Term Frequency Inverse Document Frequency-Based
Features
In the present vector space design, the TF-IDF methodology is by far the most often
utilized feature word weight computation tool. It is split into two parts: the frequency
of words as well as the frequency of inverted texts. The number of repetitions of a
speciﬁc term in the document is referred to as its word frequency. The reverse ﬁle
frequency indicates the measurement of a word’s overall relevance. The frequency
of a word’s inverse gets split by the overall count of ﬁles, which would be divided by
the count of ﬁles having the phrase, as well as the quotient logarithmic is calculated.
The word frequency (TF), as well as inverse text frequency (IDF) equations, would
be as follows:
tfa,b =
Na,b

c Nc,b
.
(1)
Na,b indicates the count of instances of the term Ta in the ﬁle db, while 
c Nc,b
represents the total of all instances in the ﬁle db.
idfa = log
|Dcount|
|{b : Ta ∈db}|.
(2)
|Dcount| denotes the total count of documents in the corpora, and {b : Ta ∈db}
signiﬁes the count of ﬁles that include the term ti, whereas if the term was not in the
corpora, the dividend will be 0. Generally, employ 1 + |{b : Ta ∈db}|.

Arabic Sentiment Analysis of YouTube Comments Using Deep …
605
tﬁdfa,b =
tfa,b × idfa

Ta∈db

tfa,b × idfa
2 .
(3)
tﬁdfa,b represents the weight of the term Ta. It is shown that a large word frequency
in a speciﬁc document, as well as a lower word frequency in the overall ﬁle group,
can result in a higher-weight TF-IDF.
We have proposed the following formula to overcome the limitations of the
conventional TF-IDF, and our proposed TF-IDF was given in (4)
TFIDF = log Ndoc
Nb
×
tf × idf

T ∈d [tf × idf]2 .
(4)
Ndoc indicates the overall count of documents.
Nb seems to be the count of documents containing the feature phrase.
d seems to be the total count of documents in the corpora.
T represents the count of documents that include the term.
TF = word frequency of word, IDF = inverse text frequency.
3.2.3
Improved Word2vect-based Features
Word2vec seems to be a linguistic model founded on neural networks. There are two
trainingtopologiesavailable:continuousbag-of-words(CBOW)aswellasskip-gram
(SG). CBOW’s training speed was quicker than skip-gram’s; hence, we employed
an improved CBOW in our work. CBOW anticipates target words depending on the
context of the text. Contextual text is indeed a word series with a certain window
size:
CT

ω j

=

ω j−k, ω j−k+1, ...., ω j−1, ω j+1, ω j+2, ..ω j+k
	
(5)
The following steps demonstrate how our improved word2vec functions:
1. Determine the window size and vector space dimension. The window size is 5
and the vector dimension is calculated by using word2vector.
2. Scanning all of the training corpus articles to construct the vocabulary.
3. Set up the word vector as well as a neural network.
4. Retrieve the training sequences from the article sentences.
5. Train the neural net with the improved CBOW algorithm and then use cosine
similarity to compare the similarity of two sentences.
CT

ω j

=

ω j−k, ω j−k+1, ..., ω j−1, ω j+1, ω j+2, ...ω j+k
	
cos(y, z)
.
(6)

606
M. Alkoli and B. Sharada
Cosine similarity is indeed a statistic that may be used to determine how identical
data items are regardless of size. Data items in a dataset were regarded as vectors in
cosine similarity. Another equation for calculating the cosine similarity of 2 vectors
was
Cos(y, z) = y.z/∥y∥∗∥z∥,
(7)
where
y.z denotes the dot product of ‘y’ as well as ‘z’ vectors.
∥y∥, ∥z∥signiﬁes the sum of the lengths of the two vectors ‘y’ as well as ‘z’.
∥y∥∗∥z∥denotes the product of two vectors ‘y’ as well as ‘z’.
k represents the window size.
The target word gets denoted by ω j.
ωi signiﬁes the weight function calculated via the sine map. For the sine map,
kl+1 = sin(πkl).
3.3
Optimal Feature Selection
The effectiveness of feature selection has a substantial impact on classiﬁcation
outcomes; hence, it is a signiﬁcant concern in sentiment classiﬁcation. The Self-
Improved Honey Badger Algorithm was used in the work for optimum feature
selection.
In theory, HBA is indeed a global optimization method since it includes both
global search stages. Method 1 presents a pseudo-code for the proposed proce-
dure, which includes population initialization, population assessment, then parameter
updates. The steps of the Self-Improved HBA (SIHBA) are outlined mathematically
as follows:
Step 1: Set the parameters maximum iteration (Mmax), population size (N),
constant (c), β.
Step 2: Initialize population with random positions.
Step 3: Compute the ﬁtness of each honey badger position.
Step 4: Save the best position pprey and assign ﬁtness to fprey.
Step 5: While M ≤Mmax do
Step 6: As per proposed methodology, update the density factor using the Eq. (8).
Where Dcircle = Diameter of the circles’ used area by the honey badger.
δ = c × exp ×Dcircle

 −M
Mmax

(8)
Step 7: For i = 1 to N do.

Arabic Sentiment Analysis of YouTube Comments Using Deep …
607
Step 8: Compute the intensity by using the Eq. (9). Here,R2 denotes a random
number between 0 and1 and dq represents the distance between both the prey as
well as the qth badger.
Iq = R2 ×
s
4πd2q
,
(9)
Step 9: if e < 0.5, then (e is a random number among 0 and 1).
Step 10: Update the position using Eq. (10).
pnew = pprey + f × β × I × pprey + f × R3 × δ × dq
× |cos(2π R4) × [1 −cos(2π R5)]|
(10)
where, pprey represents the prey’s perfect location identiﬁed thus far—in other
words, the global perfect locationβ ≥1 (default = 6) represents the honey badger’s
capacity to obtain food. The term, R3, R4, and R5 are the three separate random
integers ranging from 0 to 1, and f serves as a ﬂag that changes the search position.
It is decided by Eq. (11).
f =
1
if R6 ≤0.5
−1 else
R6 is a random number between 0 and 1.
(11)
A honey badger depends substantially on scent strength I of prey pprey, prox-
imity between the badger as well as prey dq, and time-varying exploration impact
factor α during digging. Furthermore, while digging, a badger may encounter any
disruption F, allowing it to locate even greater prey.
Step 11: else
Step 12: As per proposed contribution, update the position using Eqs. (12) and
(13).
pnew = pprey + f × R7 × δ × dq
m
× ηϖ
(12)
Median = lm + NF

2 −CF
m f
× ϖ
(13)
Here, lm denotes the lower limit of the median class, NF denotes the sum of all
frequencies, m f indicates the median class frequency, ϖ symbolizes the median
class width, CF signiﬁes the cumulative frequency of the class pending the median
class, ηϖ = Weight integer randomly selected between 0 to 2, R7 = Random
number between 0 and 1 and this randomness is estimated by using a circle map
cK+1 = cK + 0.5 −1.1
π sin(2πcK), and δ denotes the form of time-varying search
inﬂuence.
Step 12: end if
Step 13: Compute new positions and assign to fnew.

608
M. Alkoli and B. Sharada
Step 14: Set pi = pnew and fi = fnew.
Step 15: end if
Step 16: if fnew ≤fprey then
Step 17: Set pprey = pnew and fprey = fnew.
Step 18: end if
Step 19: end for
Step 20: end while stopping criteria satisﬁed.
Step 21: Return pprey.
3.4
Sentimental Classiﬁcation
The ﬁnal stage of our research is classiﬁcation, which categorizes comments as
positive, negative, or neutral depending on the speciﬁed features. In our work, the Bi-
LSTM classiﬁer will be trained using the SIHBA model’s optimally selected features.
By incorporating memory Z as well as the gate architecture, the LSTM network
overcomes the long-term dependence issue which occurs in traditional RNNs. An
input gate determines which information may be sent to the cell and is described as
follows:
iX = α

Wi.

h X−1, xX

+ bX

.
(14)
The forget gate determines whether input data should be ignored from prior
memory and also is speciﬁed as:
fX = α

W f .

h X−1, xX

+ b f

.
(15)
Depending on Eqs. (16) as well as (17), the control gate regulates the updating of
cell conditions from Z X−1 to Z X.
∼
Z X = tanh

WZ.

h X−1, xZ

+ bC

,
(16)
Z X = fX ∗Z X−1 + iX ∗
∼
Z X.
(17)
The output gate seems to be in charge of producing output while updating the
concealed vector ht −1. This procedure is as follows:
oX = α

Wo.

h X−1, xX

+ bo

(18)
h X = oX ∗tanh(CX).

Arabic Sentiment Analysis of YouTube Comments Using Deep …
609
In Eqs. (14)–(18),α is indeed the sigmoid activating function, Ws seem to be the
appropriate weight matrices, while tanh is being utilized to adjust the values between
−1 and 1.
We looked at a single LSTM layer, one bidirectional LSTM layer, plus 3
completelylinkedlayerswith8,64,aswellas8units,correspondingly.TheBi-LSTM
output layer determines if the comment is positive, negative, or neutral.
4
Results and Discussion
This proposed work is implemented in Python 3.7 and PyCharm 2021.3. The manu-
ally collected dataset was used in our work, and the number of samples considered
in this work are 433. The performance of our proposed SIHBA was compared with
the conventional algorithms such as HBA, DHOA, DO, SSOA, and DOX, and the
results were given. Table 1 shows the Bi-LSTM classiﬁer hyperparameter.
The positive performance matrices such as accuracy, precision, sensitivity, and
speciﬁcity of our Self-Improved Honey Badger optimization were estimated for (60–
90) learning percentages and are compared with existing techniques such as HBA,
DHOA, DO, SSOA, and DOX which are shown in Fig. 2.
When HBA achieves the accuracy rate of 0.88, 0.79, 0.8, and 0.6 for 60–90 LPs,
while our Self-Improved Honey Badger Algorithm (SIHBA) achieves the rate of 0.9,
0.96, 0.95, 0.97. When conventional HBA achieves the precision rate of 0.81, 0.7,
Table 1 Bi-LSTM
hyperparameter
Hyperparameter
Value
Batch_size
10
Verbose
1
Epochs
6
Fig. 2 Comparison of performance measures such as a accuracy and b precision

610
M. Alkoli and B. Sharada
0.76, 0.5, our SIHBA achieves a rate of 0.88, 0.94, 0.9, 0.92, for 60–90 LPs, which
is higher than other techniques.
The cost function for 0–25 iterations was also calculated for our proposed SIHBA
and the results were compared with conventional techniques, which are shown in
Fig. 3a. Although the cost function of our proposed SIHBA was 1.34 for 0–5 iter-
ations, which is higher than DHOA, for 5–15 iterations, its value gets reduced and
reaches the rate of 1.05 for iterations 20–25, which proves the effectiveness of our
proposed SIHBA. With that, F-measure values for 60–100LPs were also calculated
for our proposed SIHBA, which is compared with conventional techniques, which is
shown in Fig. 3b. For 90 LP, HBA and DHOA achieve a lower rate of 0.43 and 0.74,
while our SIHBA achieves a higher value of 0.94.
The analysis such as best, worst, mean, median, and standard deviation (std)
was calculated for our proposed SIHBA, and the results were compared with the
conventional algorithms such as HBA, DHOA, DO, SSOA, DOX which are shown
in Table 1. When conventional HBA achieves the best and worst values of 0.122 and
0.366, our proposed SI-BHA method achieves the lower values of 0.05 and 0.09.
Similarly, the mean and std values of our proposed SIHBA were low compared to
other methods, which shows that our method can provide higher performance. To
evaluate the effectiveness of our proposed SIHBA, it is worked in different scenarios,
which are shown in Table 2. While using the conventional TD-IDF method, the
accuracy level was only 0.804, while our proposed SIHBA achieves values of 0.94
and 0.913.
The performances of the classiﬁers such as SVM, Naïve Bayes, decision tree,
RNN, and LSTM were calculated and the results were compared with our proposed
SIHBA, which are shown in Table 3. When SVM, Naïve Bayes classiﬁers achieve the
accuracy and precision rates of 0.725, 0.587 and 0.623, 0.435, our proposed SIHBA
achieves the rate of 0.942 and 0.913.
(a) Cost Function
(b) F-Measure 
Fig. 3 Comparison of the measures such as a cost function and b F-measure

Arabic Sentiment Analysis of YouTube Comments Using Deep …
611
Table 2 Performance matrix comparison of the proposed method with different scenarios
Performance
matrices
Proposed method
with conventional
TD-IDF
Proposed method
with
ConvWord2Vec
Proposed method
without
optimization
Proposed SIHBA
Accuracy
0.804598
0.850575
0.835249
0.942529
Precision
0.706897
0.775862
0.752874
0.913793
F_measure
0.706897
0.775862
0.752874
0.913793
Table 3 Performance matrices’ comparison of different classiﬁers with proposed SIHBA
Performance
matrices
SVM
Naïve Bayes
Decision tree
RNN
LSTM
SIHBA
Accuracy
0.725264
0.623439
0.623439
0.717579
0.846302
0.942529
Precision
0.587896
0.435159
0.435159
0.576369
0.769452
0.913793
F-measure
0.587896
0.435159
0.435159
0.576369
0.769452
0.913793
5
Conclusion
The sentiment analysis in texts has mostly concentrated on the English language.
Because of the intricacy of the Arabic language as well as its grammatical elements
that differ from those present in English, existing research has been unable to be
applied to Arabic situations, restricting progress in Arabic sentiment analysis. In
this paper, we created an Arabic sentiment analysis based on manually gathered
YouTube comments. Our study was divided into four stages: preprocessing, feature
extraction, optimum feature selection, and classiﬁcation. Tokenization, stemming,
and stop word removal are all part of this preprocessing stage. To reduce the training
and computational times, optimal features were selected from these extracted features
by proposing a Self-Improved Honey Badger Algorithm (SIHBA). The limitation of
the proposed work is to concentrate on the large dataset. In the future work, larger
dataset can be considered.
References
1. Alhumoud SO, Al Wazrah AA (2021) Arabic sentiment analysis using recurrent neural
networks: a review. Artif Intell Rev 1–42
2. Wadhwani S, Richhariya P, Soni A (2022) Analysis and implementation of sentiment analysis
of user YouTube comments
3. Babu NV, Kanaga E (2022) Sentiment analysis in social media data for depression detection
using artiﬁcial intelligence: a review. SN Comput Sci 3:1–20
4. Alharbi A, Taileb M, Kalkatawi M (2021) Deep learning in Arabic sentiment analysis: an
overview. J Inf Sci 47:129–140
5. Li W, Shao W, Ji S, Cambria E (2022) BiERU: bidirectional emotional recurrent unit for
conversational sentiment analysis. Neurocomputing 467:73–82

612
M. Alkoli and B. Sharada
6. Farha IA, Magdy WA (2021) comparative study of effective approaches for Arabic sentiment
analysis. Inf Process Manage 58:102438
7. Ghallab A, Mohsen A, Ali Y (2020) Arabic sentiment analysis: a systematic literature review.
Appl Comput Intell Soft Comput
8. Zahidi Y, El Younoussi Y, Al-Amrani Y (2021) A powerful comparison of deep learning
frameworks for Arabic sentiment analysis. Int J Electric Comput Eng 11
9. Oussous A, Benjelloun FZ, Lahcen AA, Belfkih S (2020) ASA: a framework for Arabic
sentiment analysis. J Inf Sci 46:544–559
10. Alsayat A, Elmitwally N (2020) A comprehensive study for Arabic sentiment analysis
(challenges and applications). Egypt Inf J 21:7–12
11. Alroobaea R (2022) Sentiment analysis on amazon product reviews using therecurrent neural
network (RNN). Int J Adv Comput Sci Appl 13
12. Mohammed A, Kora R (2019) Deep learning approaches for Arabic sentiment analysis. Soc
Netw Anal Min 9:1–12
13. Chouikhi H, Chniter H, Jarray F (2021) Arabic sentiment analysis using BERT model.
In International conference on computational collective intelligence, pp 621–632
14. Al-Hashedi A, Al-Fuhaidi B, Mohsen AM, Ali Y, Gamal Al-Kaf HA, Al-Sorori W, Maqtary
N (2022) Ensemble classiﬁers for Arabic sentiment analysis of social network (Twitter data)
towards COVID-19-related conspiracy theories. Appl Comput Intell Soft Comput
15. Ombabi AH, Ouarda W, Alimi AM (2020) Deep learning CNN–LSTM framework for Arabic
sentiment analysis using textual information shared in social networks. Soc Netw Anal Min
10:1–13
16. Elfaik H (2021) Deep bidirectional LSTM network learning-based sentiment analysis for
Arabic text. J Intell Syst 30:395–412
17. El-Affendi MA, Alrajhi K, Hussain A (2021) A novel deep learning-based multilevel parallel
attention neural (MPAN) model for multidomain arabic sentiment analysis. IEEE Access
9:7508–7518

Learning Movement Patterns
for Improving the Skills of Beginner
Level Players in Competitive MOBAs
Dane Brown
and Jonah Bischof
Abstract League of Legends is a massively multiplayer online battle arena
(MOBA)—a form of online competitive game in which teams of ﬁve players battle
to demolish the opponent’s base. Expert players are aware of when to target, how to
maximise their gold, and how to make choices. These are some of the talents that dis-
tinguish them from novices. The Riot API enables the retrieval of current League of
Legends game data. This data is used to construct machine learning models that can
beneﬁt amateur players. Kills and goals can assist seasoned players understand how
to take advantage of micro- and macro-teams. By understanding how professional
players differ from novices, we may build tools to assist novices’ decision-making.
19 of 20 games for training a random forest (RF) and decision tree (DT) regressor
produced encouraging results. An unseen game was utilised to evaluate the impar-
tiality of the ﬁndings. RF and DT correctly predicted the locations of all game events
in Experiment 1 with MSEs of 9.5 and 10.6. The purpose of the previous experiment
was to ﬁne-tune when novice players deviate from professional player behaviour and
establish a solid commencement for battles. Based on this discrepancy, the system
provided the player with reliable recommendations on which quadrant they should be
in and which event/objective they should complete. This has shown to be a beneﬁcial
method for modelling player behaviour in future research.
Keywords Regression · Random forest · Decision tree · Massively multiplayer
online battle arena · League of legends
This work was undertaken in the Distributed Multimedia CoE at Rhodes University.
D. Brown (B) · J. Bischof
Rhodes University, Drosty Road, Grahamstown 6140, South Africa
e-mail: d.brown@ru.ac.za
URL: https://www.ru.ac.za/computerscience/people/academicstaff/drdanebrown/
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_45
613

614
D. Brown and J. Bischof
1
Introduction
League of Legends (LoL) is a team-based strategy game in which two teams of ﬁve
players compete to eliminate their opponents’ bases [1]. The game is played on a
map with three lanes that players occupy according to their responsibilities. Before
accessing the base, each lane contains three turrets that must be destroyed. Between
the three lanes are camps of monsters that players may conquer; some camps provide
a bonus to the person who kills them, while others reward money. Three jungle
team objectives (Drakes, Rift Herald, and Baron Nashor) grant major beneﬁts to the
capturing team. As the game advances, players earn money by demolishing towers,
killing opposing champions1, and killing minions.2 Gold may be spent to purchase
goods that provide an edge over the opposing side.3
Recognising the actions taken by experienced players in the aftermath of major
events and providing advice on how novice players can do better is critical for captur-
ing their attention in the gaming community. Human behaviour may be analysed with
the use of machine learning, which can also be utilised to create gaming training apps.
While deep learning methods can solve several time-based problems using recurrent
models [2, 3], this research focuses on present events rather than looking at the past.
This study uses machine learning to examine how low-rank players depart from
professional players in order to design a system that may assist rookie players in
increasing their skills. The primary contributions address this broad research asser-
tion by:
• using robust machine learning models trained on data gathered during and after
matches. Despite carrying large quantities of relevant information, this in-game
data has not yet been used in the academic literature.
• Analysing game data to learn how amateur and professional players differ.
• Based on expert player data gleaned from the best games, suggest movement
patterns using visual cues.
This paper is structured as follows. The literature review is covered in Sect.2,
while Sect.3 describes the methodology used. The experiments that were carried out
and their outcomes are described in Sect. 4, and the conclusion and future work are
in Sect.5.
2
Literature Review
Previous research has investigated how experienced players perform differently than
inexperienced players and what they do differently to achieve victory [1, 4, 5], how
machine learning can be used to predict the outcomes of multiplayer online battle
1 Champions are the characters that players use.
2 Creatures that move up each lane and attack enemy minions, champions and tower.
3 https://www.leagueoﬂegends.com/en-gb/how-to-play/.

Learning Movement Patterns for Improving the Skills …
615
arena (MOBA) games [6, 7], how to create tutoring agents for new players [8], and
predicting player skill learning [9]. League of Legends match timeline data has not
yet been used to train machine learning models that can predict what pro players will
do during matches.
Cavadenti et al. [10] monitored player positions throughout a Defense of the
Ancients 2 match (DotA2). Player traces included POI and purchases. The CHARM
algorithm, for discovering frequent closed itemsets in a transaction database, per-
formed regular itemset mining on player traces to identify aberrant behaviour.
Experiments were carried out in both quantitative and qualitative formats. The
reference model was created for the quantitative tests utilising the traces of any
player playing the hero Invoker.4 The analysed traces were collected from the most
active Invoker player. The majority of the patterns encompassed regular behaviours,
whereas a minor fraction indicated aberrant behaviours.
The qualitative trials employed the same traces as the quantitative ones. Traces,
characterised by things bought, were made in 135 games (69 defeats and 66 wins).
With a minimum frequency criterion of θ = 1%, the CHARM algorithm was applied
to the generated database. It was discovered that the itemsets utilised in 60% of the
games were roughly equally represented in both victories and losses.
Drachen et al. [1] investigated how experienced DotA2 players travelled about the
map in contrast to rookie players. Coordinate-based behaviour was divided into three
categories: zone modiﬁcations, team member distribution, and time-series clustering.
The ﬁrst behaviour was assessed by observing how players moved across the map.
The objective was to observe whether experienced players travelled about the map
more. A one-way ANOVA was used to determine the average team distance during
the course of a match. According to the data, experienced gamers roamed across the
map more than novices.
The second behaviour was explored in order to determine the team dispersion
over the map, which might be used to quantify teamwork. A one-way ANOVA was
performed again to determine the average team distance across matches. Experienced
players were found to be more consistent with their team spread and to have a smaller
team spread.
The third behaviour experimented with unsupervised learning and time-series
clustering of the mean distance between players each second. The goal was to locate
matches where players had comparable movement patterns as well as variables that
may cause movement patterns to diverge. The permutation distribution was employed
in the research to determine the similarity between time series. In these studies,
experienced players had a much lower average team distance in shorter games. The
disparities in trends across skill levels were less apparent as game durations grew.
da Nascimento Junior et al. [4] proﬁled successful and failed team behaviours in
LoL matches. To choose the most useful data from all of the matches, a variety of
studies were performed, including data cleaning, near-zero variance analysis, outlier
analysis, data transformation, normalisation, and redundancy analysis. The converted
data was placed into a K-means clustering algorithm to identify behavioural patterns
4 Invoker is a playable character in DotA2.

616
D. Brown and J. Bischof
and group comparable teams. Exploratory data analysis was used to characterise each
cluster. The ﬁndings revealed that certain team behaviours led to victory, identifying
successful and failed team behaviours.
Aung et al. [9] investigated the correlation between early learning rates and the
long-term success of League of Legends players. The data was collected directly
from Riot Games, and it is possible to access the same data via the Riot Games API.
The data were preprocessed and analysed in a Python environment using the Pandas,
Numpy, and SciPy programmes. The ML framework was built using the Scikit-learn
package.
Wang [7] used decision tree (DT) and logistic regression to predict LoL game
results. Both models were proven to be effective in forecasting match outcomes
based on in-game characteristics such as ﬁrst tower, ﬁrst Dragon, ﬁrst Baron, and ﬁrst
Rift Herald, as well as player performance. Although the DT and logistic regression
are efﬁcient, the research found that a model capable of higher generalisation, such
as random forest (RT), would need to be adopted to forecast outcomes utilising
champion selection information.
AdaBoost is a technique for enhancing classiﬁcation or regression models that
involves running numerous weak ML models on various training data distributions
and merging the results [11]. AdaBoost combines numerous weak machine learning
models into a single strong machine learning model. However, it is susceptible to
noisy data [6].
RF and AdaBoost were employed in a study by Ani et al. [6] to increase the
accuracy of predicting LoL match results using data acquired before and during the
match.
3
Methodology
The method was broken down into three stages: data collection and processing,
training using professional player match data, and event prediction using low-rank
player data and feedback. Figure1 depicts the suggested technique.
3.1
Dataset Collection and Construction
The data was gathered by SELECTING the top 20 rated matches of the world-
renowned professional player known as Doublelift and utilising the timeline_by_
match() function from the Riotwatcher Python module. The coding process is shown
in the Listing 45.1.
1
api_key
=
"RGAPI - XXXX "
2
watcher
=
LolWatcher ( api_key )
3
region_v4
=
" NA1"
4
region_v5
=
" AMERICAS "
5

Learning Movement Patterns for Improving the Skills …
617
Fig. 1 High-level overview of the proposed approach
6
player
=
watcher . summoner . by_name ( region_v4 ,
’ Doublelift ’)
7
8
matches
=
watcher . match . matchlist_by_puuid ( region_v5 ,
player [’puuid ’],
count
=
20)
9
Listing 45.1 Collecting match IDs from a speciﬁc player using riotwatcher
The method returned a dictionary containing each match’s events. The selected
events from dictionaries include
• CHAMPION_KILL; event data for when a champion is killed.
• CHAMPION_SPECIAL_KILL; event data for when a special kill occurs (dou-
ble kill, ﬁrst blood, etc.)
• TURRET_PLATE_DESTROYED; event data for when a tower plate5 is taken.
• ELITE_MONSTER_KILL; event data for when an elite monster is killed.
• BUILDING_KILL; event data for when a building is killed (tower, inhibitor,
nexus).
The event data was further analysed to acquire the following attributes:
• timestamp; the time that the event occurred.
• killerId; the ID of the player who performed the event.
• killerTeam; the team of the player who performed the event.
• type; the event type.
• killType; the sub-event type (the building type, the ID of the player that was killed,
the type of elite monster, etc.)
• x coordinate; where the event occurred.
• y coordinate; where the event occurred.
5 Tower plating are armoured plates that towers have before 14min of game time has passed. After
14min, the plating falls away.

618
D. Brown and J. Bischof
The data were encoded for modelling by converting categorical data to integers,
and the x and y coordinates were arranged into 49 quadrants so that regression
models could predict quadrants as opposed to the precise x and y coordinates. This
was done because coordinates are seldom identical, even for identical events; e.g.
a 1920 × 1080 screen monitor has around 14,000 x and y coordinates, making the
total number of potential x and y coordinate combinations 196,000,000.
3.2
New Player Training System
Asystemwascreatedtodeterminethemagnitudeofthedeviation.Ifaplayerdeparted
from the pros by more than a quadrant, a ﬂag was raised. The model maintained
track of the deviations caused by players staying in their lane for the whole of the
match. After analysing the occurrences, the algorithm determined the proportion of
deviations caused by the player remaining in their lane. If 50% of deviations were the
result of the player staying in their lane, a message was shown to notify the player.
4
Experimental Setup
Initially, four models were trained: linear regression (LR), decision tree (DT), random
forest (RF), and support vector machine (SVM) (SVM). The models were assessed
using ﬁvefold cross-validation and AdaBoost regression throughout training. R2,
MSE, and MAE were used to evaluate the models’ dependability.
As shown in Listing 45.2, the Scikit API [12] was used to develop and train
the four selected regression models using AdaBoost for a better ﬁt. According to
recommended practices, the default settings for the regression models were used.
1
2
def
support_vector_machine (X,
y,
scores ):
3
svm
=
AdaBoostRegressor (SVR( gamma
=
’auto ’,
kernel =’rbf ’),
n_estimators =300 ,
random_state =42)
4
print (" Support
Vector
Machine :")
5
cross_validation (svm ,
X,
y,
scores )
6
7
def
decision_tree (X,
y,
scores ):
8
dt
=
AdaBoostRegressor ( DecisionTreeRegressor (
random_state
=
42) ,
n_estimators =300 ,
random_state =42)
9
cross_validation (dt ,
X,
y,
scores )
10
11
def
random_forest (X,
y,
scores ):
12
rf
=
AdaBoostRegressor ( RandomForestRegressor ( max_depth
=
2,
random_state
=
42) ,
n_estimators =300 ,
random_state =42)
13
cross_validation (rf ,
X,
y,
scores )
14
15
def
linear_regression (X,
y,
scores ):
16
lr
=
AdaBoostRegressor ( LinearRegression () ,
n_estimators =300 ,
random_state =42)
17
cross_validation (lr ,
X,
y,
scores )
18
19
Listing 45.2 Model setup

Learning Movement Patterns for Improving the Skills …
619
The interested reader should reference this article and refer to this a Github page
for a complete functional system.
4.1
Experiment 1
Experiment 1 used regression models to predict the quadrant of an occurrence. The
training was completed using data from 19 of the 20 games, with the ﬁnal game
serving as the test. The ﬁvefold cross-validation ﬁndings are shown in Table1, and
the ﬁnal test results for this experiment are shown in Table2. MSE indicates that the
DT best ﬁts the data among the four models. Even if the DT best matches the data,
the MAE indicates that it also makes substantial predictions that deviate from the
data. R2 provides little information outside the fact that RF generalises training data
best.
4.2
Experiment 2
Experiment 2 used the models trained on data from individual roles. The results of
the ﬁvefold cross-validation and testing for each role indicated that data reduction
improved the dependability in the majority of instances. Tables 3 and 4 illustrate
the results achieved while training and testing on top lane data, respectively. These
outcomes demonstrated that DT is either very reliable or unreliable. RF generated
Table 1 Results of ﬁvefold cross-validation during training
Model
R2
MSE
MAE
DT
0.099 (0.078)
8.855 (0.291)
159.145 (10.618)
RF
0.198 (0.015)
10.057 (0.469)
142.325 (11.352)
SVM
0.146 (0.019)
10.388 (0.325)
151.249 (7.443)
LR
0.148 (0.014)
10.432 (0.427)
150.993 (9.820)
Table 2 Results from Experiment 1 on the test set that is unseen by the model
Model
R2
MSE
MAE
DT
−0.436
10.600
211.316
RF
0.051
9.537
139.680
SVM
−0.150
10.393
169.311
LR
−0.341
11.256
197.321

620
D. Brown and J. Bischof
Table 3 Cross-validation scores for top lane
Model
R2
MSE
MAE
DT
−0.100 (0.199)
9.444 (0.536)
177.326 (15.797)
RF
0.189 (0.139)
9.203 (0.395)
131.666 (18.310)
SVM
0.134 (0.124)
9.879 (0.701)
141.205 (20.928)
LR
0.164 (0.148)
9.462 (0.567)
135.676 (19.513)
Table 4 Test scores for top lane
Model
R2
MSE
MAE
DT
0.319
6.000
52.500
RF
0.117
6.107
68.066
SVM
0.015
6.884
75.910
LR
−0.063
7.512
81.956
Table 5 Test scores for blue top laner
Model
R2
MSE
MAE
RF
0.211
8.094
87.465
DT
0.847
2.600
17.000
Table 6 Test scores for red top laner
Model
R2
MSE
MAE
RF
0.103
4.786
38.189
DT
−2.946
9.429
168.000
the most reliable ﬁndings, indicating that it recognises broad patterns in the data
better than the other three models. The number of models was decreased to DT and
RF once these ﬁndings were made.
4.3
Experiment 3
Experiment 3 examined whether the DT and RF models were adequate for forecasting
the occurrences of a single player using data from a single participant in a match.
Tables5 and 6 provide the results of testing DT and RF using data from the top
laners on the blue and red teams, respectively. These data demonstrate how the DT
may operate very well or terribly, whereas RF performs consistently well.
Graphs representing the real event’s quadrant and model ﬁtting line were gener-
ated. Figure2 shows the plots generated by training the models for this experiment.

Learning Movement Patterns for Improving the Skills …
621
Fig. 2 Top two ﬁgures: the results from training DT (left) and RF (right) on the blue team top
laners game data. Bottom two ﬁgures: the results from training DT (left) and RF (right) on the red
team top laners game data
This demonstrates that DT and RF can accurately forecast the actions of a single
player throughout a match. Hence, they can determine where novice players differ
from professionals. After evaluating each role, it was determined that the models
accurately anticipated the happenings of the top lane.
4.4
Experiment 4
Experiment 4 evaluated the DT and RF models using data from low-rank player
matches. In prior tests, it was shown that the models could accurately anticipate
events when evaluated on data from professional players; hence, when tested on data
from low-rank players, they could identify the areas in which the new players depart
from pros. Figure3 draws visual cues for the predictions of DT and RF based on new
player data from the top lane of the blue team. The models reveal how a professional
player would have moved throughout a game, whereas the actual occurrences reveal
how a novice player deviates from this—thus suggesting a move.

622
D. Brown and J. Bischof
Fig. 3 Predictions of DT (left) and RF (right) on new player game data
Fig. 4 Depiction of the new player movements (blue) versus the prediction for a professional player
(red). The predictions were made by the DT

Learning Movement Patterns for Improving the Skills …
623
Figure4 depicts the movements of the new player used in this experiment and the
predictions for professional movements made by the DT.
Furthermore, the new player spent the majority of their time in the top lane, but a
professional player would have spent far more time assisting the rest of the team by
travelling across the map. This is only one example of how the system may provide
gamers with ideas. Moreover, the system may be adapted for other positions, and
observations could be collected about their movement habits.
5
Concluding Remarks
This study studied how machine learning can anticipate League of Legends in-game
events. The most successful machine learning regression models for the data used
in this study were DT and RF. They successfully forecasted where LoL game events
wouldoccur.Usingthepredictionsandcomparingthemtoactualeventsmayillustrate
how the performance of inexperienced players varies from that of experts. This
strategy may be utilised to identify areas in which new players can improve their
in-game decision-making and help new players learn to play more like pros by
emphasising their differences. Training on 19 of the 20 games with RF and DT
regression produced encouraging improvements. On the unseen game, RF and DT
predicted all game event locations with mean squared errors (MSE) of 9.5 and 10.6,
respectively. The system provided players with continual recommendations in the
form of visual cues based on the difference between novice and expert player data, as
it accurately anticipated the best quadrants players should occupy and the event/goal
they should pursue. This modelling approach for player behaviour can prove valuable
for further studies.
In addition, recommendations for future research include the acquisition of a
larger dataset of professional player statistics from a greater number of top-ranked
games so as to:
• A recurrent neural network (RNN) and other time-series techniques for improved
pattern recognition in diverse gaming tournaments.
• Without ground-truth training data, unsupervised methods may also aid in identi-
fying plausible explanations for deviations from overall patterns.
• To offer additional capabilities to the new player training system and help in
the determination of player movements with greater precision. Potentially, the
technology might be included in the game by injecting a customisable overlay that
delivers real-time feedback to novice or inexperienced players.

624
D. Brown and J. Bischof
References
1. Drachen A, Yancey M, Maguire J, Chu D, Wang IY, Mahlmann T, Schubert M, Klabajan D
(2014) Skill-based differences in spatio-temporal team behaviour in defence of the ancients 2
(DotA 2). In: 2014 IEEE Games media entertainment. IEEE, pp 1–8
2. Chindove H, Brown D (2021) Adaptive machine learning based network intrusion detection.
In: Proceedings of the international conference on artiﬁcial intelligence and its applications.
ACM, pp 1–6
3. Yu Y, Si X, Hu C, Zhang J (2019) A review of recurrent neural networks: LSTM cells and
network architectures. Neural Comput 31(7):1235–1270
4. da Nascimento Junior FF, da Costa Melo AS, da Costa IB, Marinho LB (2017) Proﬁling suc-
cessful team behaviors in league of legends. In: Proceedings of the 23rd Brazillian symposium
on multimedia and the web, pp 261–268
5. Xia B, Wang H, Zhou R (2019) What contributes to success in MOBA games? An empirical
study of defense of the ancients 2. Games Culture 14(5):498–522
6. Ani R, Harikumar V, Devan AK, Deepa O (2019) Victory prediction in league of legends
using feature selection and ensemble methods. In: 2019 International conference on intelligent
computing and control systems (ICCS). IEEE, pp 74–77
7. Wang T (2018) Predictive analysis on eSports games: a case study on league of legends (LoL)
eSports tournaments. Master’s thesis, University of Toronto
8. do Nascimento Silva V, Chaimowicz L (2017) A tutor agent for MOBA games. arXiv preprint
arXiv:1706.02832
9. Aung M, Bonometti V, Drachen A, Cowling P, Kokkinakis AV, Yoder C, Wade A (2018)
Predicting skill learning in a large, longitudinal MOBA dataset. In: 2018 IEEE Conference on
computational intelligence and games (CIG). IEEE, pp 1–7
10. Cavadenti O, Codocedo V, Boulicaut JF, Kaytoue M (2016) What did i do wrong in my MOBA
game? Mining patterns discriminating deviant behaviours. In: International conference on data
science and advanced analytics
11. Solomatine DP, Shrestha DL (2004) AdaBoost.RT: a boosting algorithm for regression prob-
lems. In: 2004 IEEE International joint conference on neural networks (IEEE Cat. No.
04CH37541), vol 2. IEEE, pp 1163–1168
12. Pedregosa F, Varoquaux G, Gramfort A, Michel V, Thirion B, Grisel O, Blondel M, Pretten-
hofer P, Weiss R, Dubourg V, Vanderplas J, Passos A, Cournapeau D, Brucher M, Perrot M,
Duchesnay E (2011) Scikit-learn: machine learning in Python. J Mach Learn Res 12:2825–2830

An Effective Multi-exposure Fusion
Approach Using Exposure Correction
and Recursive Filter
C. R. Jishnu and S. Vishnukumar
Abstract The visual quality of a natural scene is constantly degraded when using
conventional imaging sensors. The dynamic range is the factor that limits the sensors
to capture more information as it is limited to a speciﬁc range during capturing.
Multi-exposure image fusion (MEF) is a technique for creating a well-exposed,
high dynamic range (HDR)-like image from a collection of inconsistently exposed,
low dynamic range (LDR) images. The fused image may still have image arti-
facts and lose information, nevertheless. To overcome this, we propose an MEF
approach using an effective exposure correction mechanism. The technical strategy
for the proposed method is to initially improve the source images using an exposure
correction strategy, followed by merging the images using pyramidal decomposi-
tion to produce HDR-like images. Experimental comparison with existing methods
demonstrates that the proposed procedure produces positive statistical and visual
outcomes.
Keywords Multi-exposure image fusion · Exposure correction · Recursive ﬁlter ·
Dynamic range · Exposure value
1
Introduction
This work’s overarching goal is to create an image that is aesthetically beautiful,
rich in details, and has vibrant colors using a few input images. There are a couple
of ways to develop a well-exposed highly detailed image starting with illuminating
the image. Image illumination, even though the term sounds convincing and easy to
perform, the outcome could always deviate from the original scene and could end
C. R. Jishnu (B) · S. Vishnukumar
Department of Computer Applications, Cochin University of Science and Technology, Kochi,
Kerala 682022, India
e-mail: jishnudca@cusat.ac.in
S. Vishnukumar
e-mail: vks@cusat.ac.in
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_46
625

626
C. R. Jishnu and S. Vishnukumar
up being more artiﬁcial than natural. Other well-known methods for producing well-
exposed images from LDR images include tone mapping [1] and multi-exposure
image fusion [2]. Tone mapping operation is often compromised at times due to the
fact that the process requires an intermediate HDR image. Due to its ability to develop
effective well-exposed images, the MEF has claimed wide attention throughout the
years. MEF strategies are the ones that provide promising outcomes with more detail
and better visual quality, in addition to being hardware independent and not needing
the camera response ﬁgures. The paper contains a brief study of the existing MEF
methods in Sect. 2. A demonstration of the proposed multi-exposure image fusion
technique is described on Sect. 3. The comparative study’s ﬁndings are examined
and the results are displayed at Sect. 4. A brief summary with potential paths for the
future work is mentioned in Sect. 5.
2
Literature Review
There have been studies on MEF for the past few decades. One of the ﬁrst researchers
in the ﬁeld of MEF was Burt et al. [3], who presented a pyramid-based approach
to carry out the image fusion operation. Then Goshtasby et al. [4] recommended an
MEF method in which the input images are separated into uniform blocks, followed
by a blending function to blend the ones with more details. However, the object
boundaries in the fused images were poor. Mertens et al. [5] proposed an approach in
2007 for fusing a collection of images with variable exposure using straightforward
quality indicators like saturation and contrast known as weight terms.
Later on, Liu et al. [6] suggested a method that studies the impact of weight terms
on fused images and used a dense scale-invariant transform descriptor for developing
the contrast term. An adaptive weights-based MEF technique that represents global
gradient and the relative pixel intensity to construct an adaptive rule for the individual
images was put forwarded by Lee et al. [7]. Hayat et al. [8] performed a multi-
exposure image fusion by pyramidal decomposition of weight maps. In addition to
contrast and saturation, a color dissimilarity measure is used to measure the ghost
artifacts in the images. A fast-guided ﬁlter is used for the weight map reﬁnement.
The approach of Li et al. [9] uses pyramidal decomposition and coefﬁcient atten-
uation on each level to condense the dynamic range. Fang et al. [10] developed an
objective quality model for MEF. Here, similarities between subjects are identiﬁed
from two alternative forced choices (2AFC), with this an objective quality model is
observed for quantifying the ghosting artifacts. Edge-preserving smoothing-based
multi-scale exposure fusion is a technique Wang et al. [11] designed to preserve the
details from the darkest and brightest region from an HDR picture. Karakaya et al.
[12] introduced a method that involves the development of a fused image with the
combined weight map creation from saliency maps, principal component analysis,
and adaptive well-exposedness, followed by reﬁnement using a guided ﬁlter.
The major problem with most of the available MEF approaches is the presence of
halo artifacts in the fused image. Other common problems faced by the fused results

An Effective Multi-exposure Fusion Approach Using Exposure …
627
include color distortions and detail loss. To overcome these problems, we propose
an MEF approach with exposure correction and pyramidal decomposition for more
enhanced and prominent fused images.
3
Proposed Method
The method begins with evaluating the source images using an exposure value
(EV) parameter to identify the underexposed and overexposed images. The expo-
sure correction strategy is implemented on the classiﬁed input images to develop
the individual exposure-corrected image. Even though the quality of the original
image is greatly improved by exposure correction, some areas may still have incon-
sistencies and color distortions. This is resolved using the recursive ﬁlter by reﬁning
the original images with their exposure-corrected counterpart, thereby developing an
intermediate reﬁned exposure stack. Weight maps are produced by utilizing contrast,
saturation, and well-exposedness from the intermediate reﬁned exposure stack. These
weights and the reﬁned inputs are then combined to create the fused image using a
pyramidal decomposition. The workﬂow of the proposed MEF approach is shown
in Fig. 1.
3.1
Input Reﬁnement Using Exposure Correction
and Recursive Filter
Here, an effective exposure correction mechanism is used for reﬁning the input
images. The objective is to perform respective exposure correction strategies on the
Fig. 1 Overview of the proposed MEF approach

628
C. R. Jishnu and S. Vishnukumar
underexposed and overexposed images. For this, the input images are initially clas-
siﬁed into underexposed and overexposed images based on their intensity exposure.
This is accomplished by taking the exposure value (EV) of the input images [13]
and designating 0.5 as the threshold, where images with exposure value less than
or equal to the threshold are deemed underexposed and images with more than the
threshold are considered overexposed.
The image exposure value is determined by
exposure value(EV) = 1
L
L
i=1 h(i)i
L
i=1 h(i)
(1)
L denotes total gray levels, whereas h(i) denotes image’s histogram.
Both underexposure correction and overexposure correction methods adhere to
the Retinex-based image enhancement tenet [14–16], which states that an image
I is determined as the pixel-wise multiplication of its enhanced version I’ and the
illumination map M [17],
I = I ′ × M
(2)
Initially, the input image is normalized to set the image range to [0,1]. The
maximum RGB color channels are used as the illumination values at each pixel
of the normalized image to create the initial illumination map,
M′
P = max

I C
P

(3)
where P stands for the pixel and C is the color channel. To prevent the color channel
of the recovered image from straying outside of the color gamut, the maximum value
of the pixel is chosen. However, because of the additional textures acquired, the
initial illumination map can turn out to be inaccurate and unrealistic.
As a result, improving the illumination map is required to preserve the noticeable
structure, which is performed using the following objective function:
arg min

P

MP−M′
P
2 + λ

wa,p(∂aM)2
P + wb,p(∂bM)2
P

(4)
where ∂a and ∂b are special derivatives in horizontal and vertical directions, respec-
tively, and w is the spatially varying smoothening weights. Together with the spatial
derivatives, the redundant details are removed. To make sure the structure is main-
tained, the ﬁrst term

MP−M′
P

is invoked to make the ﬁnal illumination map as
identical to the initial illumination map. λ is a weight assigned for balancing the two
terms.
This improved and reﬁned illumination map allows to recover the enhanced
version I′, which is the desired exposure-corrected image as follows:

An Effective Multi-exposure Fusion Approach Using Exposure …
629
Fig. 2 Exposure correction mechanism on underexposed images
I ′ = I × M−1
(5)
The aforementioned steps are strictly followed for the underexposed images, as
represented in Fig. 2. For overexposed images, their inverted image is taken for the
abovementionedprocedure.Afteracquiringtheenhancedinvertedimage,theoverex-
posed image’s exposure is rectiﬁed by ﬂipping the image back to its normal format.
Once this is done, the exposure-corrected variants of both the underexposed and
overexposed images are obtained, namely underexposed corrected and overexposed
corrected images.
Although these developed images after exposure correction are noticeably sharper
and more detailed, the overall authenticity of the natural scene will be jeopardized by
the excessive brightness. The proposed solution is a traditional way for keeping edges
and texture information using edge-preserving ﬁlters [18, 19]. Among them, an edge-
preserving recursive ﬁlter is used to create an intermediate reﬁned exposure stack
with ﬁne edges and less noise by taking advantage of both the input and exposure-
corrected images. The key idea is to ensure that the pixels in the images fed onto
the ﬁlter have comparative weights. The recursive ﬁlter [20] provides much more
visually pleasing results and claims to have higher computational efﬁciency with a
promising success rate among multi-exposure fusion techniques.
A recursive edge-preserving [21] ﬁlter is executed as follows:
R[i] =

1 −cd
I[i] + cd R[i−1]
(6)
where c is the feedback coefﬁcient [0, 1] and d represents the distance between
pixels. As the distance increases, the coefﬁcient goes to 0. I[i] is the value of the ith
pixel of the input image, and R[i] is the ith pixel of the reﬁned image.

630
C. R. Jishnu and S. Vishnukumar
3.2
Pyramidal Decomposition on the Reﬁned Exposure Stack
The best elements of the reﬁned images are combined to create a globally well-
exposed image. The proposed method fuses the intermediate results obtained after
the edge-preserving reﬁnement for obtaining the resultant image. In addition to a set
of quality metrics, weighted blending is used in the procedure. The idea is to assign
fewer weights to the ﬂat colorless regions and more weights to the richer regions.
Let IUR and IOR be the underexposed reﬁned and overexposed reﬁned images
obtained. For the intermediate reﬁned exposure stack {IUR, IOR}, a weight map
is generated using the qualitative measures of contrast, saturation, and well-
exposedness [5].
Contrast measurement aids in identifying the input image’s textures and edges.
The value is acquired by taking the absolute value of the Laplacian ﬁlter response of
the image’s grayscale variant [22] as follows:
C(x, y) =
Igray(x, y) ∗l(x, y)|

(7)
where, Igray stands for the grayscale version of reﬁned images, ∗is a convolution
operator, C is for the contrast, and l points to the Laplacian ﬁlter.
The saturation gives the image’s colors a more vibrant appearance, and a vivid
image is crucial. The colors produced by lengthy exposures will ultimately clip
and become desaturated. The standard deviation of the RGB color space is used to
compute the saturation value S, as follows:
S(x, y) =
	
(R −μ)2 + (G −μ)2 + (B −μ)2
3
(8)
where
μ = R + G + B
3
(9)
Well-exposedness aids in removing overexposed and underexposed areas from
the source images. The measure is calculated by taking the Gaussian curve of each
channel and selecting the pixels that have values close to 0.5 as follows:
E(x, y) = Rg × Gg × Bg
(10)
where Rg, Gg, and Bg are the Gaussian curves of the bold, italic, and bold italic
channel of the reﬁned images, respectively, and which are obtained by
exp

−(i −0.5)2
2σ 2

(11)

An Effective Multi-exposure Fusion Approach Using Exposure …
631
Here, the value of σ is 0.2. For each exposure-corrected image, a single reﬁned map
is created after characterizing all three weight maps as follows:
W(x, y) = C(x, y) × S(x, y) × E(x, y)
(12)
A pyramidal decomposition is now used to merge the reﬁned exposures, ensuring
that the ﬁnal image is devoid of artifacts at color shifts and has sharp texturing [3].
Here,thecorrectedexposurestackisdividedintollevelsofdifferentresolutionsusing
the Laplacian pyramid (L). On fused weights, a Gaussian pyramid (G) is utilized for
the similar process. Each level of these pyramids undergoes the blending operation,
resulting in the formation of a Laplacian pyramid from the combined image, as
follows:
L

f l
=
N

n=1
G

W l
n

× L

I l
n

(13)
where W represents the fused weight and I represents the reﬁned image. In order to
obtain the ﬁnal fused image F, the fused pyramid L

f l
is eventually collapsed.
4
Results and Analysis
The performance of the proposed approach is assessed both qualitatively and quan-
titatively by conducting various experiments on test images taken from datasets in
[2, 23–26].
The proposed method’s outcomes are compared with 8 existing methods which
include, Mertens [5], Liu [6], Lee [7], Hayat [8], Li [9], Fang [10], Wang [11],
and Karakaya [12]. The experiments were performed in a Core i9-equipped CPU
clocked at 3.70 GHz supported by 32 GB RAM. All fused images are generated under
default settings without any optimizations with the publicly available implementa-
tions. Statistical analysis is performed using a Structural Similarity Index Metric for
MEF (MEF-SSIM) [27] and Peak Signal-to-Noise Ratio (PSNR) [28] over 15 test
images. MEF-SSIM is a structural similarity-based metric that generates results by
taking brightness, global consistency, and structure preservation into account. An
outcome closer to 1 denotes a greater structural similarity. PSNR is a commonly
used information theory-based metric, calculated by dividing the number of gray
levels in the image with the corresponding pixels in fused and reference images. A
higher PSNR value denotes a stronger relationship between the reference and fused
images, denoting a superior fusion.
The results of the statistical analysis using, PSNR and MEF-SSIM, are shown in
Tables 1 and 2, respectively. The average accuracy is shown in the bottom rows of
both tables, and it is clear that the given strategy performs better than the compared
state-of-the-art MEF approaches.

632
C. R. Jishnu and S. Vishnukumar
Table 1 Quantitative methods of different MEF algorithms using PSNR
Mertens09
Liu15
Lee18
Hayat19
Li20
Fang20
Wang20
Karakaya22
Proposed method
Arno
55.7303
55.5498
55.7403
55.7155
55.6729
55.7503
55.6731
55.743
55.7459
House
54.0031
53.7052
53.8625
53.836
53.6219
53.9169
53.6865
53.8713
53.99
Kluki
55.379
55.0229
55.6258
55.3423
55.3096
55.3417
55.1474
55.4054
55.4238
Landscape
56.2406
55.8549
56.2722
56.2255
56.2744
56.259
55.9825
56.2675
56.3206
Lighthouse
55.1125
54.793
54.9861
55.1118
54.9586
55.0924
54.7418
55.0702
55.1664
Venice
55.7405
55.4963
55.8662
55.7273
55.6711
55.6628
55.3307
55.6695
55.8288
AirBellowsGap
55.3297
55.0839
54.9355
55.2971
55.0443
55.2971
54.8165
55.7227
55.3547
BarHarborSunrise
55.552
55.1161
55.5395
55.4729
55.3549
55.6172
55.4636
55.6621
55.5572
BloomingGorse
54.8485
54.3895
54.7604
54.7994
54.5843
54.8361
54.5414
55.0464
54.9006
Exploratorium
54.8103
54.477
54.6486
54.7342
54.6165
54.7772
54.3793
54.5398
54.8544
Knossos6
55.2642
54.9017
55.1868
55.2035
55.1434
55.1977
54.9694
55.1646
55.2279
Museum1
54.3245
54.0713
54.3208
54.2773
54.3133
54.3215
54.2779
54.34
54.3275
Stream
55.6513
55.4341
55.5132
55.5816
55.3485
55.6259
55.3036
56.0038
55.6422
Chair
53.6458
53.6949
53.7172
53.6255
53.1284
53.7656
53.6869
53.6486
53.7627
WindowTrim
55.9436
55.62
55.9125
55.8081
55.7469
55.8419
55.7361
55.898
55.9512
Average
55.1717
54.8807
55.1258
55.1172
54.9859
55.1536
54.9158
55.2035
55.2036
The best scores are shown in bold

An Effective Multi-exposure Fusion Approach Using Exposure …
633
Table 2 Quantitative methods of different MEF algorithms using MEF-SSIM
Mertens09
Liu15
Lee18
Hayat19
Li20
Fang20
Wang20
Karakaya22
Proposed method
Arno
0.9878
0.943
0.9818
0.9849
0.9798
0.9857
0.9748
0.9735
0.9882
House
0.9723
0.9429
0.9654
0.9706
0.9541
0.9725
0.9458
0.9601
0.9667
Kluki
0.9801
0.9605
0.965
0.9849
0.98
0.9844
0.9668
0.9742
0.978
Landscape
0.9734
0.9493
0.971
0.9726
0.9743
0.9735
0.9531
0.974
0.9782
Lighthouse
0.9754
0.9499
0.9687
0.9777
0.9372
0.974
0.956
0.9749
0.9758
Venice
0.9818
0.9495
0.9747
0.9825
0.927
0.9868
0.9632
0.9843
0.9828
AirBellowsGap
0.9673
0.9447
0.9507
0.9658
0.9429
0.9644
0.9405
0.9461
0.97
BarHarborSunrise
0.9747
0.9471
0.9639
0.9763
0.9637
0.9824
0.9429
0.8998
0.9771
BloomingGorse
0.9763
0.9022
0.9638
0.958
0.9513
0.9717
0.9183
0.9623
0.9795
Exploratorium
0.9687
0.9146
0.9664
0.9617
0.8843
0.967
0.9608
0.972
0.9737
Knossos6
0.9734
0.9156
0.9609
0.9708
0.9663
0.974
0.9313
0.9635
0.974
Museum1
0.9933
0.9494
0.988
0.9882
0.9891
0.9928
0.9636
0.9891
0.9934
Stream
0.9755
0.9262
0.95
0.9759
0.9004
0.9749
0.9207
0.9326
0.9758
Chair
0.9472
0.9301
0.95
0.9431
0.6028
0.9319
0.9172
0.9372
0.9474
WindowTrim
0.9673
0.9173
0.9557
0.9638
0.9346
0.9695
0.9202
0.9424
0.9624
Average
0.9743
0.9362
0.9651
0.9718
0.9259
0.9737
0.945
0.9591
0.9749
The best scores are shown in bold

634
C. R. Jishnu and S. Vishnukumar
Figure 3 shows the result of different MEF algorithms including the proposed
method on ‘exploratorium’ image sequence. In the proposed method, the transition
between the buildings and the sky component is smoothly blended with improved
contrast, but for the others, this connected area is distorted. The textural elements of
the building were lost in the outcomes depicted by Fang and Wang. Liu’s fused image
shows relatively few edge details at the junction between the river and the building.
The overall quality of the image suffers as a result. The result shown by Hayat
also shows similar detail loss at the building part. Lee’s fused image has brighter
sections that are prone to losing detail, whereas Karakaya provided outcomes that
were slightly darker.
Figure 4 shows the results of different MEF algorithms including the proposed
work on ‘AirBellowsGap’ image sequence. The proposed method exhibits standard
visual quality, with strong color saturation and texture information in the tree section.
The sky appears to be excessively bright and has lost details in the resultant image of
(g) Lee 
 
 
                  (h) Mertens
  
 
        (i) Fang 
 
   
                (j) Karakaya
 (k) Proposed method 
(a) Underexposed  
 
          (b) Overexposed 
  
                      (c)  Wang
 (d) Liu  
 
 
      (e) Li 
 
 
         (f) Hayat
Fig. 3 Qualitative performance comparison using the ‘exploratorium’ image sequence

An Effective Multi-exposure Fusion Approach Using Exposure …
635
(a) Underexposed  
 
 
 (b) Overexposed 
  
                   (c)  Wang
 (d) Liu 
 
 
 
     (e) Li 
 
 
      (f) Hayat
(g) Lee 
 
 
                  (h) Mertens
  
 
        (i) Fang 
        
 
 (j) Karakaya
 (k) Proposed method 
 
Fig. 4 Qualitative performance comparison using ‘AirBellowsGap’ image sequence
Karakaya. Fang and Mertens display the fused image with comparable contrast and
sufﬁcient edge details. Wang and Liu’s fused images seem to fade out with lower
quality. From Figs. 3 and 4, it is evident that the proposed method outperforms the
existing methods.
5
Conclusion
MEF is frequently used to create high-quality, HDR-like images from a collection
of LDR images. In the proposed method, the input image is enhanced using an
exposure correction approach before going through the pyramidal fusion. This tech-
nique enhances the quality of input images in order to produce a fused image with
improved edge, texture, and contrast ﬁgures. Initially, the input images are reﬁned

636
C. R. Jishnu and S. Vishnukumar
using a recursive ﬁlter with the exposure-corrected variants of the input images.
Image fusion on these reﬁned images is carried out using a pyramidal decomposi-
tion. The experimental comparisons reveal the superiority of the proposed method
over a number of state-of-the-art MEF methods. In the future, the performance of the
fusion can further be improved by setting the proposed strategy into practice with
the aid of deep learning. The goal is to focus on particular areas of an image rather
than assuming that an entire image qualiﬁes as being underexposed or overexposed.
This will hopefully give more pleasing results and higher accuracy.
References
1. Reinhard E, Heidrich W, Debevec P, Pattanaik S, Ward G, Myszkowski K (2010) High dynamic
range imaging: acquisition, display, and image-based lighting. Morgan Kaufmann
2. Zhang X (2021) Benchmarking and comparing multi-exposure image fusion algorithms. Inf.
Fusion 74:111–131
3. Burt PJ, Kolczynski RJ (1993) Enhanced image capture through fusion. In: 1993 (4th)
international conference on computer vision. IEEE, pp 173–182
4. Goshtasby AA (2005) Fusion of multi-exposure images. Image Vis Comput 23(6):611–618
5. Mertens T, Kautz J, Van Reeth F (2007) Exposure fusion. In: 15th Paciﬁc conference on
computer graphics and applications (PG’07). IEEE, pp 382–390
6. Liu Y, Wang Z (2015) Dense SIFT for ghost-free multi-exposure fusion. J Vis Commun Image
Represent 31:208–224
7. Lee SH, Park JS, Cho NI (2018) A multi-exposure image fusion based on the adaptive weights
reﬂecting the relative pixel intensity and global gradient. In: 2018 25th IEEE international
conference on image processing (ICIP). IEEE, pp 1737–1741
8. Hayat N, Imran M (2019) Ghost-free multi exposure image fusion technique using dense SIFT
descriptor and guided ﬁlter. J Vis Commun Image Represent 62:295–308
9. Li H, Ma K, Yong H, Zhang L (2020) Fast multi-scale structural patch decomposition for
multi-exposure image fusion. IEEE Trans Image Process 29:5805–5816
10. Fang Y, Zhu H, Ma K, Wang Z, Li S (2019) Perceptual evaluation for multi-exposure image
fusion of dynamic scenes. IEEE Trans Image Process 29:1127–1138
11. Wang Q, Chen W, Wu X, Li Z (2019) Detail-enhanced multi-scale exposure fusion in YUV
color space. IEEE Trans Circ Syst Video Technol 30(8):2418–2429
12. Karakaya D, Ulucan O, Turkan M (2022) PAS-MEF: multi-exposure image fusion based on
principal component analysis, adaptive well-exposedness and saliency map. In: ICASSP 2022–
2022 IEEE international conference on acoustics, speech and signal processing (ICASSP).
IEEE, pp 2345–2349
13. Hanmandlu M, Verma OP, Kumar NK, Kulkarni M (2009) A novel optimal fuzzy system for
color image enhancement using bacterial foraging. IEEE Trans Instrum Meas 58(8):2867–2879
14. Wang S, Zheng J, Hu HM, Li B (2013) Naturalness preserved enhancement algorithm for
non-uniform illumination images. IEEE Trans Image Process 22(9):3538–3548
15. Guo X, Li Y, Ling H (2016) LIME: Low-light image enhancement via illumination map
estimation. IEEE Trans Image Process 26(2):982–993
16. Zhang Q, Yuan G, Xiao C, Zhu L, Zheng WS (2018) High-quality exposure correction of under-
exposed photos. In: Proceedings of the 26th ACM international conference on Multimedia, pp
582–590
17. Zhang Q, Nie Y, Zheng WS (2019) Dual illumination estimation for robust exposure correction.
In: Computer graphics forum, vol 38, no 7, pp 243–252
18. Biradar N, Dewal ML, Rohit MK (2014) Edge preserved speckle noise reduction using
integrated fuzzy ﬁlters. Int Sch Res Not

An Effective Multi-exposure Fusion Approach Using Exposure …
637
19. Jain P, Tyagi V (2016) A survey of edge-preserving image denoising methods. Inf Syst Front
18(1):159–170
20. Li S, Kang X (2012) Fast multi-exposure image fusion with median ﬁlter and recursive ﬁlter.
IEEE Trans Consum Electron 58(2):626–632
21. Gastal ES, Oliveira MM (2011) Domain transform for edge-aware image and video processing.
In: ACM SIGGRAPH 2011 papers, pp 1–12
22. Malik J, Perona P (1990) Preattentive texture discrimination with early vision mechanisms.
JOSA A 7(5):923–932
23. Ma K, Zeng K, Wang Z (2015) Perceptual quality assessment for multi-exposure image fusion.
IEEE Trans Image Proc 24(11):3345–3356
24. Ma K, Duanmu Z, Yeganeh H, Wang Z (2017) Multi-exposure image fusion by optimizing a
structural similarity index. IEEE Trans Comput Imaging 4(1):60–72
25. Ram Prabhakar K, Sai Srikar V, Venkatesh Babu R (2017) Deepfuse: a deep unsupervised
approach for exposure fusion with extreme exposure image pairs. In: Proceedings of the IEEE
international conference on computer vision, pp 4714–4722
26. Zeng K, Ma K, Hassen R, Wang Z (2014, September) Perceptual evaluation of multi-exposure
image fusion algorithms. In: 2014 Sixth international workshop on quality of multimedia
experience (QoMEX). IEEE, pp 7–12
27. Ma K, Zeng K, Wang Z (2015) Perceptual quality assessment for multi-exposure image fusion.
IEEE Trans Image Process 24(11):3345–3356
28. Jagalingam P, Hegde AV (2015) A review of quality metrics for fused image. Aquatic Procedia
4:133–142

Social Media as the Most Effective Means
of Business Promotion Today with Using
Social Media Advertising Technology
Aldo Saputra, Ingwen Tannaris, Kelby Hubert, Ford Lumban Gaol,
and Tokuro Matsuo
Abstract Indonesia has the largest number of people that are active in social media
and Indonesia is a country with the most social media users in the world. Social media
in general is used to socialize (relate, both, personally, in groups and so on) between
users. The users of social media in Indonesia already has reached 160 million in
January 2020. and this number of social media users in Indonesia increased up to
12 million (8.1%) from April 2019 to January 2020. Firstly, social media was used
by users to connect with each other through community. However, now social media
is not only used as a means of virtual community for interaction but is also used
as a channel for doing business. There are still many people who do not realize
that social media has the advantage of being a very efﬁcient and effective business,
and many company that still confused about to choose which social media platform
that suitable with their business promotion. Therefore, we want to show and tell
them one of the advantages of social media in the ﬁeld of promotion. Based on the
surveys, there are four most popular social media in Indonesia such as YouTube,
WhatsApp, Facebook, and Instagram. However, there still very few studies can be
found to understand that social media is effective or not for business promotion. For
this reason, this article will examine the advantages that social media have that can
support business promotion. This article will utilize the questioners method to assess
A. Saputra · I. Tannaris · K. Hubert
Information Systems Department, Nusantara University, Jakarta, Indonesia
e-mail: aldo.saputra1@binus.ac.id
I. Tannaris
e-mail: ingwen.tannaris1@binus.ac.id
K. Hubert
e-mail: Kelby.Hubert1@binus.ac.id
F. L. Gaol (B)
Computer Science Department, BINUS Graduate Program—Doctor of Computer Science, Bina
Nusantara University, Jakarta, Indonesia 11480
e-mail: fgaol@binus.edu
T. Matsuo
Advanced Institute of Industrial Technology, Tokyo, Japan
e-mail: matsuo@aiit.ac.jp
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_47
639

640
A. Saputra et al.
the important factors of social media users such as user satisfaction factors in using
social media and what social media are often used by user to promote their business.
The research result is expected to provide valuable guidance for user to understand
about function social media for business promotion.
Keywords Social media · Users · Trust · Satisfaction
1
Introduction
Today social media has been used by many people in Indonesia because it is fun to
see other people’s activities, watch some funny or cool stuff, learn something from
social media, and many more. The more fun stuff we can do in social media, the more
social media becomes popular and the more effectives for social media to promote
products or businesses [1].
Many big companies have realized that social media is the best way to promote
a product or businesses. Many big companies used social media to promote their
products or businesses because they know that they can reach people from very far
away from them very easily [2]. However, there are still many companies who didn’t
use the advantage of social media to promote their business because they didn’t know.
Also many companies nowadays confuse choosing which social media platform they
think is suitable to use for their business promotions tools. Therefore, we are now
doing research about what social media are currently in great demand and use by the
public. From the research, we will show what are the beneﬁts that can be obtained
from using social media as a means of doing business and which social media that
suitable for use as a means of promotion. Figure 1 denotes the percentage of internet
and social media users.
We got a result after doing research on the internet and we found the fact as we can
see from the graphic above it explains that 90% of all internet users use social media.
In Indonesia, there are 267.7 million people based on population data, it means that
social media users reach 60% of total population in Indonesia, and it is still increasing
rapidly [3].
Fig. 1 Number of Internet users and social media users [1]

Social Media as the Most Effective Means of Business Promotion Today …
641
The Internet provides new ways to interact between humans. It destroyed walls
that limit human direct interaction with other humans and changed human interaction
patterns. Technology makes us don’t need space and time to interact with other people
[4]. The large number of Internet uses and the high need for interaction make the
use of social media very much needed, especially among young people. Companies
must take advantage of this condition. Through social media, companies can expand
their business widely. Therefore, we are interested in researching how effective social
media is for promoting business [5].
From all the explanations above, we conclude there are some questions that are
most asked about social media from people, the question is like how effective social
media impacts business growth? Which social media that support business promotion
or have features for supporting business? Which social media type that is most
suitable for business promotion?
2
Literature Review
2.1
Social Media
SocialmediaisatechnologythatusestheInternettofacilitateallpeopletoshareideas,
thoughts, and information to each other so all people can connect with each other.
Social media used to interact with friends and family but by time social media used for
businesses that want to reach many people effectively through this popular commu-
nication method that social media serves. Social media’s role in helping businesses
is signiﬁcant. It made business easy to communicate with customers [6].
With the gathering information advantages, we can improve our marketing and
market research to another level. It is easier to promote our products because we
can determine our market target, time, and duration perfectly. And then, with social
media we can build customer relationships through customer’s trusts in our social
media account [7].
1. Social Media According to Antony Mayﬁeld
According to Antony Mayﬁeld who provides his ideas in the form of a deﬁnition
of media social where according to him social media is a media with user conve-
nience participate, share and create roles, on speciﬁc blogs, social networks, online
wiki/encyclopedia, virtual forums [8].
2. Social Media According to Andreas Kaplan and Michael Haenlien
According to Andreas Kaplan and Michael Haenlien, deﬁning the meaning of social
is a group of Internet that have a foundation based with the Internet. Ideology and
technology of Web 2.0 enable the user to create and exchange some content [9].
3. Social Media According to Lisa Buyer

642
A. Saputra et al.
According to Lisa Buyer, the deﬁnition of social media is a form of public relations
that most transparent, attractive, and interactive today [10].
4. Social Media According to Sam Decker
According to Sam Decker, social media is content digital and the interactions created
by and between each other [11].
5. Social Media According to Marjorie Clayman
According to Marjorie Clayman, the deﬁnition of social media is a new marketing
tool that make it possible to know customers and potential customers in a way that
was not possible before [12].
Types of Social Media
• Online communities groups have come in all types and sizes, many of them are
created by people or a group of people without any company afﬁliations. Many
log or groups in social media were created for a speciﬁc purpose, e.g., in line
application, there were many groups that were created by groups of people that
used to help other people to search for a part time job. There also another group
that have another purpose like a group for promotion their business, etc.
• Blogs, the users of the blog are very diverse, some blogs are personal to close
friends and family, and there are also other blogs that are designed to reach and
also inﬂuence a wide audience with their blog. There is also a blog that created
to inform an information.
• Socialnetworkshaveanimportantroleinbothconsumerbusinessandbusiness-to-
business marketing. One of them is from Facebook, Messenger, and Twitter. These
different networks have offered different beneﬁts according to their platform.
2.2
Business
The ﬁrst thing to make a business is assign the business concept. Depending on the
business, extensive market research may be needed to determine whether turning an
idea into a business is viable, determining how to promote business products and
whether the product has value for customers. A business must know how to give
customers the best experience when seeing a business product and can make the
customer have his best satisfaction to buy the product [13].
2.3
Advertising
1. Advertising
Advertising is a way of communication with many people through various kinds of
media that are held by companies, non-proﬁt organizations, or individuals. The main

Social Media as the Most Effective Means of Business Promotion Today …
643
purpose of advertising is to share our product or services to many people so it can
increase our demand of product that being advertised [14].
2. Public Relation
Publicity is the total of information that is shared to many people through certain
media about a person, item, or organization. Public relations, building good relations
with the public is a branding effort very effective. Participating in social activities
using company attributes also products have a positive value in the eyes of society.
They (society) give positive assessment of your company, the most important of
which is all “brand image” the company is getting stronger and stronger [14–16].
3. Sales Promotion
Sales promotion is marketing activity to encourage customers about the effectiveness
or quality of an item through some demonstration, exhibition, or discount.
2.4
The Most Popular Social Media that Suitable
for Business
Advertising is a marketing tactic or method that involves paying for some space to
promote a product, service, or cause. The actual promotional messages are called
advertisements, or ads for short. The goal of advertising is to reach people most
likely to be willing to pay for a company’s products or services and entice them to
buy. Now advertising product can be everywhere like from television, newspaper, or
billboard but now mostly product is advertise at social media because most people
active at social media.
1. YouTube
YouTube is a website or application that provides a free video sharing that can make
it easy to watch online videos. Everyone can create and upload their own videos to
share with others as creators. YouTube has become very popular because everyone
can watch a video according to their likes, there are also many people that want to be
creators on YouTube because now we can get money from YouTube by accepting the
adsense according to your view in your video. We can also promote some business
on YouTube by adding ads in some videos.
The advantages of YouTube for business:
• Marketing in YouTube is very easy you only have to paid to YouTube to add a adds
in their video or you also can paid the content creator to promote your business.
• Your content will never be deleted as long as it doesn’t violate YouTube policies.
• You can grow your audience worldwide by upload your video in YouTube.
• You can grab the audience attention to your business using short video or adds.
2. Instagram

644
A. Saputra et al.
Table 1 Research variables and indicators
No
Variable(s)
Indicator(s)
Reference(s)
1
Active user
Total of use using social media
[3]
2
Popular social media
Social media mostly use by people and have most
active user
[4]
3
Advertising type
Type of advertising in the social media, example
video ads, picture ads, and more
[5]
4
Advertising target
Target audience with certain traits
[7]
5
Active ads
Total of the ads show to user in one day
[8]
Instagram is a free application that allows user to share their expressions through
photo or video to other people.
Instagram allows people to edit and share their photo or short video through the
application with some hashtag or geotags that make the post searchable by other
people. Each post that is made by a user will appear on their follower’s feed and
public when the post is tagged with hashtag or geotags.
The advantage of Instagram for business:
• Connect with customers across multiple channels.
• Reuse marketing materials.
• Attract engaged trafﬁc with a community.
• Boost your marketing with ucg like photos from customers.
3
Methodology
3.1
Research Model
The research variables and indicators are given in Table.1
3.2
Data Gathering Method
The method used in this study is questioner, where this questionnaire contains some
questions that are related to social media, the respondent will answer according to
their opinion and feelings about social media. The questionnaire also will ask about
how social media can be used as a means of business promotion.
Here are some of the questions we ask to respondents:
• How often do you use social media.
• Social media is used most often.
• Where you see most ads.

Social Media as the Most Effective Means of Business Promotion Today …
645
• Have you ever been interested in advertisements on social media?
• If you have a business, what media will you choose to promote?
• In your opinion, is social media effective for promotion? Why?
This study uses phenomenology method because this research requires observing
the reality that occurs daily in human life. This research will observe the reality
through questionnaires that will be shared to many people. We can dig up data from
people’s answers through the questionnaires and draw conclusions from it.
3.3
Data Analysis Method
In this research, we used Google form technology to collect respondents that we
distributed via the line application. We get respondents as many as about twenty
people that we will use to draw a conclusion. This research shows that social media
is very widely used by people every day so that social media is not only a place to
express yourself but also as a place to promote a product that is very effective today.
This study uses a qualitative phenomenological method. Phenomenology word
derived from the Greek word, phainomeno which means appearance of oneself and
logos which means reason, phenomenological study is a study that specializes in
visible phenomena and reality to examine the explanations in them. Phenomenology
itself has two meanings, namely as a philosophy of science and also a research
method, which aims to ﬁnd the meaning or meaning of the experiences that exist in
life.
4
Result and Discussion
4.1
Chart of Age of Respondent
From the Fig. 2, it is found that most respondents are 18–26 years old who are adoles-
cents to early adulthood. We can conclude that the range of age from millennium
ages.
4.2
Chart of Social Media Users
From the Fig. 3, we can see if 50% of users are very often using social media, 25%
often, 15% ordinary, and 10% rarely. From this chart, we can know how often users
use social media.

646
A. Saputra et al.
Fig. 2 Range of age
Fig. 3 Social media users
4.3
Chart of Social Media that Used by User
From the Fig. 4, we will get the information of social media that is often used by
users, in this question, we give 5 options of social media such as YouTube, Instagram,
Facebook, line, and telegram. We can see if Instagram is the most widely used by
users by 50%, second is YouTube by 30%, third is line by 10%, and last Facebook
and telegram by 5%.

Social Media as the Most Effective Means of Business Promotion Today …
647
Fig. 4 Social media users
From this information, we can know what social media that often use and being
see by users so we can analysis what social media that suitable for business.
4.4
Chart of Advertising
Figure 5 shows that users frequently view adverts in social media by 90% since social
media is now widely and easily used by users. In social media, we may see a lot of
information and advertise. We can now see social media on a variety of platforms.
4.5
The Respondent Interest from Ads
According to Fig. 6, the majority of respondents were interested in the advertise-
ments; 90% were interested in the product and 10% were not.
This leads to the conclusion that social media advertisements can attract more
customers.
4.6
Chart of Best Social Media for Promotion Business
According to Fig. 7, all respondents chose social media as a venue to promote busi-
ness products, implying that social media is extremely effective for promotion. We
might conclude from this experiment that social media has become an alternative

648
A. Saputra et al.
Fig. 5 Adds on the social
media users
Fig. 6 Respondent interest from ads
for advertising. Social media has become the most apparent way to advertise in the
digital age.

Social Media as the Most Effective Means of Business Promotion Today …
649
Fig. 7 Respondent of social media for promotion business
4.7
Chart Rate About How Often User Using Social Media
Figure 8 depicts the rate of social media users, with 21 respondents, the majority of
whom use social media frequently, and only two respondents who use it infrequently.
Fig. 8 Respondent of social media for promotion business

650
A. Saputra et al.
Fig. 9 Respondent of using social media to promote
4.8
Chart of User Who Have Ever Using Social Media
to Promote
From Fig. 9 57.1%, users ever use social media to promote their business, and 42.9
never. There is possibility why some people in this chart don’t use social media for
their business, is because all respondent who answer this questionnaire are in 18–26
ages, so it is likely that not everyone in this age owns their business.
5
Discussion
Here are the result answer of respondent for our research with using Google form:
• Very effective, because many people are now more engaged on social media,
especially when they have downtime. An appealing social media presence piques
the user’s curiosity.
• Very effective, because now all social media platforms that offer free services,
such as YouTube, will undoubtedly catch adverts every time a video opens, which
is very useful in attracting new users.
• Very effective, because now many people have social media and cannot be
separated from it, especially since everyone uses social media 3–4 h a day.
It is particularly effective since everyone uses social media, and with social media
promotion, people learn about the promotion more rapidly.

Social Media as the Most Effective Means of Business Promotion Today …
651
Because individuals are more active and use the app more frequently in today’s
period, promotions can be delivered more effectively on Instagram and YouTube.
Effective because youngsters are now more focused on social media than those who
look around to be interested in the promotions supplied since social media is available
where everyone who uses the internet can access and see it.
Very effective since practically everyone nowadays utilizes social media, and its
dissemination is rapid and extensive. Social media is a powerful tool for promoting
a product, especially if it is new. Because social media is so widespread and easy to
distribute information on.
For all respondents, the majority responded that social media is extremely useful
for product promotion since it has a large number of active users, is easy to share,
and attracts new customers.
6
Conclusion
Most individuals spend their time interacting with social media, and some cannot get
away from it because they believe it is a part of their lives. Because most people
are engaged in social media, most people will view all content in social media
that includes commercial product advertising. People use a variety of social media
platforms, including Facebook, Instagram, WhatsApp, YouTube, and others.
Instagram, YouTube, and Line are the most popular social networking platforms.
It is possible to infer that Instagram, YouTube, and Line are the most successful
social media platforms for business promotion. Furthermore, individuals today are
far more interested in social media than they are in television and print media. Young
people also prefer to advertise their businesses on social media rather than other
forms of media since social media is thought to be more successful and efﬁcient in
its execution.
As a result, social media might be considered the most effective promotional
medium. According to our research, the type of social media that is best suited
for business promotion is using a video or a picture, such as platforms YouTube and
Instagram. YouTube uses a short video in ads to promote the business, and Instagram
uses a short video and a picture of the product, as well as a link for users to get through
the product.
References
1. Bimo P (2017) Perkembangan Media Sosial di Indonesia. Retrieved 04 Dec 2020, from https://
pakarkomunikasi.com/perkembangan-media-sosial-di-indonesia
2. Media Sosial, Tak Sekadar Jaringan Pertemanan – Bebas Akses. Bebas Akses. (2020).
Retrieved 3 Dec 2020, from https://bebas.kompas.id/baca/riset/2020/06/17/media-sosial-tak-
sekadar-jaringan-pertemanan/

652
A. Saputra et al.
3. What is an Active User? How does DAU and MAU ﬁt in? | Adjust. Adjust.com. (2020).
Retrieved 4 Dec 2020, from https://www.adjust.com/glossary/active-user/
4. The 7 Biggest Social Media Sites in 2020. Search Engine Journal (2020). Retrieved 4 Dec
2020, from https://www.searchenginejournal.com/social-media/biggest-social-media-sites/
5. 10 Kinds of Advertising. Bizﬂuent (2020). Retrieved 4 December 2020, from https://bizﬂuent.
com/info-7736409-10-kinds-advertising.html
6. The Now: What is Targeted Advertising?. GCFGlobal.org (2020). Retrieved 4 Dec 2020, from
https://edu.gcfglobal.org/en/thenow/what-is-targeted-advertising/1/
7. Passive vs Active Advertising: Which One Is Right for Your Brand. Instapage.com (2020).
Retrieved 4 Dec 2020, from https://instapage.com/blog/passive-vs-active-advertising
8. What is Instagram?—Deﬁnition from WhatIs.com. SearchCIO (2020). Retrieved 26 Dec 2020,
from https://searchcio.techtarget.com/definition/Instagram
9. Inglis A (2020) 8 Massive beneﬁts of using YouTube for business. Grow. Retrieved 26 Dec
2020, from https://wearegrow.com/8-massive-beneﬁts-of-using-youtube-for-business/
10. Explained: What is YouTube?. Webwise.ie (2020). Retrieved 26 Dec 2020, from https://www.
webwise.ie/parents/what-is-youtube/
11. Millwood A (2016) 5 most signiﬁcant Instagram beneﬁts for businesses. Yotpo. https://www.
yotpo.com/resources/instagram-pics-better/
12. ResearchGate (2021) Effectiveness of advertisements in social media. [online] Available
at: https://www.researchgate.net/publication/330855222_EFFECTIVENESS_OF_ADVERTI
SEMENTS_IN_SOCIAL_MEDIA. Accessed 20 Jan 2021
13. Taylor & Francis (2021) Engagement with social media and social media advertising: the
differentiating role of platform type. [online] Available at: https://www.tandfonline.com/doi/
full/10.1080/00913367.2017.1405754. Accessed 20 Jan 2021
14. Globaljournals.org (2021) [online] Available at: https://globaljournals.org/GJMBR_Vol
ume18/2-Social-Media-Advertising-Response.pdf. Accessed 20 Jan 2021
15. Wright E, Khanfar N, Harrington C, Kizer L (2010) The lasting effects of social media trends
on advertising. J Bus Econ Res (JBER) 8(11)
16. Ford J (2019) What do we know about social-media marketing? Retrieved 20 Jan 2021, from
http://www.journalofadvertisingresearch.com/content/59/4/383

Text-to-Speech and Speech-to-Text
Converter—Voice Assistant
Sagar Janokar, Soham Ratnaparkhi, Manas Rathi, and Alkesh Rathod
Abstract According to the International Agency for Prevention of Blindness’s
Vision, there are around 32 million people who live with avoidable blindness and
a further 259 million with preventable visual impairment that is decent to acute.
Though there may be a few existing solutions to this problem, none of the solutions
provide an all-in-one experience like this voice assistant does. Our proposed model
uses automatic speech recognition (ASR) to recognize to user’s speech and convert
it into text format. For converting text-to-speech, we are using google text-to-speech
(gTTS) engine and Microsoft’s SAPI5 which provides voice to our model. This voice
assistant can not only be used to read a Word document or a PDF ﬁle but also search
content on Google or Wikipedia.
Keywords Voice assistant · Automatic speech recognition · gTTS · Microsoft’s
SAPI5 · Read · Search
1
Introduction
In recent times, the growth of artiﬁcial intelligence and human–machine interfaces is
huge. Virtual assistants, especially voice assistants, have contributed to this growth
immensely. These voice assistants not only aid the blind but are also a boon to
specially abled people. Voice assistants are intelligent software that can run on any
S. Janokar (B) · S. Ratnaparkhi · M. Rathi · A. Rathod
Department of Engineering, Sciences and Humanities (DESH), Vishwakarma Institute of
Technology, Pune, Maharashtra, India
e-mail: sagar.janokar@vit.edu
S. Ratnaparkhi
e-mail: soham.ratnaparkhi21@vit.edu
M. Rathi
e-mail: manas.rathi21@vit.edu
A. Rathod
e-mail: alkesh.rathod21@vit.edu
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_48
653

654
S. Janokar et al.
device and respond to voice commands. These devices include computers, gaming
consoles, mobile phones, smart gadgets, TV consoles, virtual reality (VR) headsets,
cars, and Internet of things (IoT) devices. Voice assistants can also be referred to as
personal digital assistants (PDAs) or virtual assistants.
This year, 123.5 million adults in the USA will use voice assistants at least once
per month, and that base will continue to grow over the course of the following
several years. The number of people who use voice assistants will continue to rise,
eventually reaching over half of the adult population in the USA. Even though the
number of users is expected to rise at a slower rate through the conclusion of our
prediction period in 2025, we anticipate that in the next three years, slightly over
48% of adults in the USA will be monthly users of this technology.
It should not come as a surprise that younger members of the millennial generation
are the ones most likely to employ a voice assistant. This year, we anticipate that
close to two-thirds of people in the age range of 25–34 will use voice assistants
every month. This number falls below 50% among members of Gen X (those aged
42–57), and it is slightly around 30% for members of the baby boomer generation
(ages 58–76).
However, still, this technology has some disadvantages. The method needs
massive databases and hard coding to construct words. Speech synthesis uses more
CPU. Speech is unnatural and impersonal. It is difﬁcult to capture all conceiv-
able words, emotions, prosody, tension, etc. Text-based pronunciation analysis is
important. Perfect systems are hard to develop. Humans may have trouble ﬁltering
background noise.
2
Literature Review
Digital speech recognition technology has been embedded in personal computers
since the start of this century with Microsoft, Apple, Philips, etc., continuously
working on it. Many top ﬁrms use oral dialog systems for designing such system
devices as Microsoft Cortana, Amazon Alexa, Alphabet’s Ok Google, Apple Siri, etc.
Vocal recognition, voice language apprehension, dialogue manager, natural language
production, text-to-speech converter, and knowledge base are the six components of
a general conversation system. However, there are some major issues with these
voice assistants as either they are multifunctional but very expensive or lack the
functionalities to make a cheap product. This paper proposes a voice assistant which
is not only a multifunctional software but also a free and open-source application
that can be used by anyone. Lately, a lot of research has been done on voice assis-
tants and various new technologies have come up. Text-to-speech conversion using
different speech syntheses. Text-to-speech consists of two phases, i.e., the ﬁrst phase
is text analysis and the second one is the generation of speech waveforms [1]. Few
researchers integrated image processing algorithms, OCR, and text-to-speech (TTS)
synthesis to build a voice assistant [2]. The Raspberry Pi module connected to a
camera was often used to capture the input image and this input image was further

Text-to-Speech and Speech-to-Text Converter—Voice Assistant
655
processed and utilized using OCR [3]. It was proposed in [4], a software named
eSpeak which read out the audio formatted ﬁle and delivered it as an output with the
help of a speaker.
Zaman et al. [5] proposes the using an Optical Character Recognition (OCR)-
based smart book reviewer for the visually impaired. The unique method of creating
a local voice assistant without using cloud services was put forth in [6].
During our research, we found that one of the technologies for natural language
interactions with virtual personal assistant systems is a computing device conﬁgured
to receive audio input, distort the audio input to generate several distorted audio
variants, and perform speech recognition on the audio input and the distorted audio
variants [7]. We came to the conclusion that more investigation into the voice personal
assistant, also known as a VPA, is required. A VPA is a digital assistant that uses
voice recognition, natural language processing, and speech synthesis to assist users
of voice recognition applications [8]. Further in our research, we found that there is
a need for a system that can build voice and face recognition for student attendance
systems. While this has a range of positive effects, the most essential one is that it
provides lecturers with assistance in effectively monitoring the attendance of their
students. In this particular method, the marking of pupils’ attendance is accomplished
by the use of human biometrics [9, 10].
The automatic speech-to-text and speech-to-speech summarization methods
presented in [11] is based on speech unit extraction and concatenation. A two-stage
summarizing method using important sentence extraction and word-based sentence
compaction is examined for the ﬁrst scenario [12]. The speech recognition results
are extracted and concatenated to create sentence and word units that optimize the
weighted total of linguistic probability, amount of information, conﬁdence measure,
and grammatical likelihood of concatenated units [13]. We all have a profound under-
standing of the reading norms of our native language, which is mostly unconscious.
In elementary school, they were taught to us in a reduced manner, and we reﬁned
them year by year. However, it would be rather audacious to assert that it is just a
matter of time until the computer would likely surpass the human in this regard [14].
Despite the current level of our knowledge and skills, as well as the recent advance-
ments made in signal processing and artiﬁcial intelligence, we must raise misgivings.
In actuality, the reading process utilizes the furthest, sometimes unconsidered depths
of human mind [15].
3
Methodology
The voice assistant has been coded using Python3. Microsoft’s SAPI5 and pyttsx3
library enables the voice assistant to speak and comprehend the speech of the user.
We have used the recognize google() method present in the recognizer class of the
speech recognizer library which empowers the voice assistant to convert speech-
to-text. To convert text-to-speech, we use the methods in pyttsx3 and win32com
libraries. Figure 1 shows the ﬂowchart for working with this voice assistant. Python’s

656
S. Janokar et al.
Fig. 1 Flowchart of stated methodology
pyttsx3 module is capable of converting text into spoken language. In contrast to other
libraries, it may be used without an Internet connection and is compatible with Python
versions 2 and 3. To obtain a reference to a pyttsx3. Engine instance, an application,
must ﬁrst call the pyttsx3.init() factory method. It is a straightforward process to
transform written words into spoken words with this program. The “sapi5” program
for Windows is responsible for providing both the female and male voices that are
supported by the pyttsx3 module. The ﬁrst voice is female. It is compatible with the
following TTS engines: sapi5—SAPI5 on Windows nsss—NSSpeechSynthesizer on
Mac OS X and espeak—eSpeak on every other platform. Our tool greatly focuses
on two major spheres, i.e., speech-to-text conversion and text-to-speech conversion.
3.1
Speech-to-Text Conversion
• Initially, the voice assistant records the speech. It requires a certain threshold
frequency value (300 units) for recording the voice successfully.
• It then converts the raw speech into a string datatype. This string is then assessed
by the voice assistant.
• Once the commands are received by the voice assistant, it checks the commands
provided by the user with the list of commands present in its database.
• If the command matches, then the assistant will perform the desired task or else
it gives the corresponding error message.

Text-to-Speech and Speech-to-Text Converter—Voice Assistant
657
The voice assistant generally records for 9 s, but this duration can be changed
as per the user’s requirement. The overriding theory behind the working of this AI-
based voice assistant is automatic speech recognition. Automatic speech recognition,
abbreviated to ASR for its more common name, is the technology that enables people
to use their voices to communicate with a hardware electronic system in a manner
that, in its most advanced iterations, is remarkably similar to how people speak to
one another in everyday life.
Our program converts speech-to-text operated by ﬁrst playing an audio ﬁle and
then producing a verbatim transcript that may be edited on the device in question.
Voice recognition allows the program to do this task. Computer software separates
auditory information from spoken words and transfers those signals into text using
characters called Unicode relies on linguistic algorithms.
The process of converting voice to text is accomplished by the use of a sophis-
ticated machine learning model that is comprised of numerous stages. Words are
created when a succession of sounds are expelled from someone’s lips, which also
results in a series of vibrations. For speech-to-text technology to function, it must
ﬁrst detect these vibrations and then use an analog-to-digital converter to turn them
into a digital language. The sounds from an audio ﬁle are read by an analog-to-digital
converter, which then analyzes the waves by measuring them in high detail and ﬁlters
them so that only the necessary sounds are heard. After the sounds have been split
into hundredths or thousandths of seconds, the phonemes may ﬁnally be matched
to them. In every given language, the unit of sound that is used to differentiate one
word from another is referred to as a phoneme. For instance, the English language
has something in the neighborhood of 44 phonemes. After that, the phonemes are put
through a network that is based on a mathematical model, and the model compares
the phonemes to well-known sentences, words, and phrases.
Natural language processing, sometimes known by its abbreviated form NLP,
is at the center of the most cutting-edge version of the ASR technologies that are
now being developed. Even though there is still a long way to go before reaching
the pinnacle of development, we are already seeing some remarkable results in the
form of intelligent smartphone interfaces such as the Siri program on the iPhone and
other systems used in business and advanced technology contexts. Despite the fact
that there is still a long way to go before reaching the pinnacle of development, we
are already seeing some remarkable results. This particular implementation of ASR
gets the closest to enabling a genuine dialogue to take place between human beings
and artiﬁcial intelligence. However, despite having an “accuracy” of approximately
96–99%, these NLP programs can only achieve these kinds of results under ideal
conditions. These ideal conditions include that the questions that are posed to them
by humans are of a straightforward yes or no type, or that there are only a restricted
number of possible response options based on the keywords that have been chosen.
The basic events that cause any automatic speech recognition program to work as
shown in Fig. 2 go as follows:
1. The audio feed is recorded.
2. Of the recorded audio ﬁle, a wave ﬁle is created of your speech.

658
S. Janokar et al.
Fig. 2 Working of ASR
3. Background noise is removed from the wave ﬁle, and the loudness is normalized.
4. The resulting ﬁltered waveform is then dilapidated into phonemes. (Phonemes
are the fundamental sounds that makeup language and words. There are 44 of
them in English, and they are made up of sound blocks like “wh,” “the,” “ka,”
and “t.”)
5. Each phoneme is like a link in a chain, and by studying them in order, you
may learn more about them. Starting with the ﬁrst phoneme, the ASR algorithm
uses statistical probability analysis to create whole phrases and eventually whole
sentences.
6. ASR as shown in Fig. 2 now having “understood” your words, can respond to you
in a meaningful way which in our case is being assessed by the voice assistant
to give a meaningful response.
3.2
Text-to-Speech Conversion
Deep learning research advances have made it possible for us to produce voices that
sound human. Our research revolved around few terminologies which are
• Phenome—The smallest unit of sound, or phoneme, is what distinguishes one
word’s pronunciation and meaning from another.
• Mel-spectrogram—It is created by reducing the dimensionality of the audio’s
short-time Fourier transform (STFT) by applying a nonlinear treatment to the
frequency axis. It highlights low-frequency characteristics that are crucial for
identifyingspeechanddownplayshigh-frequencyinformationthatareoftennoise.
• Prosody—The rhyme schemes and sound patterns utilized in poetry.
Figure 3 shows the basic workﬂow of text-to-speech conversion model.

Text-to-Speech and Speech-to-Text Converter—Voice Assistant
659
Fig. 3 Workﬂow of TTS engine
Text is the input to our model, which passes through various blocks before being
translated to audio. Let us examine how each of these building elements adds to the
process.
• Preprocessor
– Tokenize: Tokenize a statement into words
– Phonemes/Pronunciation: It divides text input into phonemes according to their
pronunciation.
– Phoneme duration: Represents the entire amount of time each phoneme in an
audio recording takes up. Pitch is a crucial characteristic for conveying emotion,
and it has a substantial impact on the prosody of speech.
– Energy: Indicates the magnitude of frame-level mel-spectrograms and impacts
the volume and prosody of speech directly.
The linguistic characteristic contains just phonemes. In actuality, energy, pitch,
and duration are used to train the energy predictor, pitch predictor, and duration
predictor, which are employed by the model to generate a more natural output.
• Encoder
The encoder accepts linguistic information (phonemes) as input and generates an
n-dimensional embedding as output. This embedding between encoder and decoder
is referred to as the latent feature. Other aspects, such as speaker embedding (which
will be detailed in the following blog), are concatenated with these and provided to
the decoder. In addition, the latent features are utilized to forecast the audio’s energy,
pitch, and length, which play a signiﬁcant part in determining the audio’s naturalness.
• Decoder
The decoder converts information embedded in the latent processed feature to the
acoustic feature, i.e., mel-spectrogram.
We are using mel-spectrograms output instead of the speech/audio directly from
the decoder. This is due to the fact that audio contains more variation information
(such as phase) than mel-spectrograms. This results in a greater information gap
between the input and output for text-to-audio creation than for text-to-spectrogram
generation. Mel-spectrograms are therefore recommended.
• Vocoder

660
S. Janokar et al.
It transforms the acoustic characteristic (mel-spectrogram) into waveform output
(audio). It is possible to use a mathematical model, such as that of Grifﬁn Lim,
or to train a neural network to learn the mapping between mel-spectrogram and
waveforms. In actuality, learning-based strategies typically perform better than the
Grifﬁn Lim method.
Instead of immediately predicting waveform using the decoder, we divided this
hard and intricate operation into two parts, ﬁrst predicting the mel-spectrogram from
latent processed data and then creating audio using mel-spectrogram.
Directed dialogue dialogues and natural language conversations make up the
two primary categories of varieties seen in automatic speech recognition software.
Conversations in directed dialogue are a simpliﬁed kind of automatic speech recog-
nition in action. They are made up of machine interfaces that speak to you and
instruct you to respond verbally with a particular word chosen from a restricted list
of options. This is how they form their response to your speciﬁcally deﬁned request.
ASR may be utilized in a variety of ways, one of which is through directed dialogue
dialogues. Directed conversation automatic speech recognition software is utilized
rather frequently in a variety of customer service interfaces, including automated tele-
phone banking systems. Natural language conversations are much more advanced
variants of ASR. Rather than providing you with heavily restricted menus of words
you are permitted to use, these variants attempt to simulate real conversation by
allowing you to communicate with them in an open-ended chat format. One of the
most cutting-edge instances of these kinds of technologies is the Siri interface seen
on Apple’s iPhone.
4
Results
The source code has been administered in Python 3. x. Underneath are a few outputs
that we got from the voice assistant. Saying “Hello Python” will activate the voice
assistant. Then the table in Fig. 4 will be displayed on the screen. It shows the tasks
and their corresponding commands that voice assistant can perform. Saying “close
Python” will deactivate the voice assistant system. After performing the task, the
voice assistant (VA) will ask the user whether he/she wants to continue. Depending
on the user’s answer, it will decide whether to continue or not!
Figure 4 indicates the tasks that the tool can do. The following is a brief description
of the tasks that the proposed research does.
• Text-to-speech output: When we type out a sentence, the voice assistant will speak
it out. For this, the text is processed by using the underlying principles of ASR
and NLP.
• Search on google output: As shown in Figs. 5 and 6. When the user asks the voice
assistant to search “voice assistant,” it acts by searching on google. It receives the
request through google and then performs this task. For this, the user’s speech is
ﬁrst processed into text and then this text is queried by Google. Similarly, the voice

Text-to-Speech and Speech-to-Text Converter—Voice Assistant
661
Fig. 4 Tasks that the tool can do
assistant searches the text on Wikipedia too, but the only difference here is that
it speaks out and prints a few lines of “summary” of the query to be searched on
Wikipedia. It then asks the user whether he wants to open the respective webpage.
• Read an MS Word(.docx) or PDF ﬁle: Once the respective command to do this is
called, the voice assistant will ask the user the location of the document to read.
In the case of reading a pdf ﬁle, voice assistant will also read out the number of
pages, author, and title of the document if possible and then give certain interactive
options to the user related to reading the document. Figure 7 shows the output
after calling the “read a book command.”
• Convert speech-to-text: Once this command is executed, the voice assistant acts
like a dictator and prints the sentence spoken by the user. This dictation feature
converts your voice into the written word.
5
Conclusion
Thisinitiative’sprimarygoalistoprovidelow-costsoftwaretounderdeservedgroups
in society, such as the blind, visually impaired, and differently abled. This project
was created using a variety of open-source libraries and packages. It can be used to
search the web, as a dictator, and as a Word or PDF ﬁle reader. The main feature that

662
S. Janokar et al.
Fig. 5 Asking voice assistant to search “voice assistant” on Google
Fig. 6 Search results produced by the voice assistant
distinguishes this voice assistant from others is its interaction with the user. Speech-
to-text technology, like all other types of technology, provides several beneﬁts that
help us improve the procedures we use on a daily basis. Automatic speech recognition
technology saves users time by producing accurate transcripts in real time, allowing
for more efﬁcient technology use. It takes minimal effort to say a few words than
type them on a small smartphone screen in a handsfree manner without keeping
your hands occupied when using our tool. This enables users to perform multiple
tasks concurrently. Natural language processing is used to streamline the customer
experience by providing convenience, accessibility, and seamlessness in the customer
experience transformation.

Text-to-Speech and Speech-to-Text Converter—Voice Assistant
663
Fig. 7 Results of the “Read a book” command
6
Limitation and Future Scope
Dictation technology is powerful, but it is still developing, so it is not perfect. It only
creates literal text, so you risk a clunky, inaccurate transcript. Voice recognition soft-
ware can only produce a high-quality transcript from clear, accent-free recordings.
The tool does not recognize breakpoints or tone changes, so you must speak punctu-
ation. Intelligibility is sound quality. If words are mispronounced, output sentences
may have errors. In future, background noise cancelation can be integrated to improve
results accuracy.
References
1. Htun HM, Zin T, Tun HM (2015) Text to speech conversion using different speech synthesis.
Int J Sci Technol Res 4(7):104–108
2. South S, Kallimani JS (2017) OCR based facilitator for the visually challenged. In: 2017
International conference on electrical, electronics, communication, computer and optimization
techniques (ICEECCOT)
3. Polyakov EV, Mazhanov MS et al (2018) Investigation and development of the intelligent voice
assistant for the internet of things using machine learning. In: Moscow workshop on electronic
and networking technologies (MWENT)

664
S. Janokar et al.
4. Zaman HU, Mahmood S, Hossain S, Shovon II (2018) Python based portable virtual text reader
5. Subhash H, Srivastava PN et al (2020) Artiﬁcial intelligence-based voice assistant. In: 2020
Fourth World conference on smart trends in systems, security and sustainability (WorldS4)
6. Manage P, Kulkarni RM et al (2020) An intelligent text reader based on python
7. Yadav AV, Verma SS, Singh DD (2021) Virtual assistant for blind people. Int J Adv Sci Res
Eng Trends 6(5)
8. Porwal R, Tomar U, Dubey V, Mishra A, Mandloi G (2021) Voice assistant
9. Muthumari M, Akash V, Prudhvi Charan K, Akhil P, Deepak V, Phani Praveen S (2022) Smart
and multi-way attendance tracking system using an image-processing technique. In: 2022 4th
International conference on smart systems and inventive technology (ICSSIT), pp 1805–1812.
IEEE
10. Furui S, Kikuchi T, Shinnaka Y, Hori C (2004) Speech-to-text and speech-to-speech summa-
rization of spontaneous speech. IEEE Trans Speech Audio Process 12(4):401–408. https://doi.
org/10.1109/TSA.2004.828699
11. Allen J, Hunnicutt MS, Klatt DH, Armstrong RC, Pisoni DB (1987) From text to speech: the
MITalk system. Cambridge University Press
12. Ren Y, Ruan Y, Tan X, Qin T, Zhao S, Zhao Z, Liu T-T (2019) Fastspeech: Fast, robust and
controllable text to speech. Advances in Neural Information Processing Systems, vol 32
13. Dutoit T (1997) High-quality text-to-speech synthesis: an overview. J Electr Electron Eng Aust
17(1):25–36
14. Zen H, Dang V, Clark R, Zhang Y, Weiss RJ, Jia Y, Chen Z, Wu Y (2019) LibriTTS: a corpus
derived from LibriSpeech for text-to-speech. arXiv preprint arXiv:1904.02882
15. Poushneh A (2021) Humanizing voice assistant: The impact of voice assistant personality on
consumers’ attitudes and behaviors. J Retail Consum Serv 58:102283

CNN Combined with FC Classiﬁer
to Combat Artiﬁcial Penta-Digit
Text-Based Captcha
S. Abhishek, S. Sanjana, Mahima Chowdary Mannava, and T. Anjali
Abstract Captcha technology has grown in popularity along with the growth of the
Internet. The completely automated public Turing test to tell computers and humans
apart uses captcha technology to discriminate between humans and robots. The most
common type of CAPTCHA is text-based. The majority of CAPTCHAs that use
text have been broken. However, prior research has primarily relied on complex and
ineffective preparation methods to attack text CAPTCHAs. This study builds a deep
CNN network model that can recognize a 5-character text captcha by researching
captcha recognition technology.
Keywords Captcha · Convolutional layer · Fully connected · Connectionist
temporal classiﬁcation · Long short-term memory
1
Introduction
Scientiﬁc research today regularly makes use of deep learning network which is
a great success in several ﬁelds, including detection systems, speech recognition,
image identiﬁcation, and natural-language processing. Deep learning’s capacity to
actively learn characteristics without the aid of artiﬁcial design is its main advantage
over conventional pattern recognition. A test known as CAPTCHA was developed to
prevent websites from being regularly and quickly visited by an autonomous program
S. Abhishek (B) · S. Sanjana · M. C. Mannava · T. Anjali
Department of Computer Science and Engineering, Amrita School of Computing, Amrita Vishwa
Vidyapeetham, Amritapuri, India
e-mail: abhishekabi2002@gmail.com
S. Sanjana
e-mail: sanjana.suresh.iyer@gmail.com
M. C. Mannava
e-mail: mannavamahima@gmail.com
T. Anjali
e-mail: anjaliraj87@gmail.com
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_49
665

666
S. Abhishek et al.
and squandering network resources. Most companies that offer online services utilize
CAPTCHA tests to stop users from performing speciﬁc actions, such as ﬁlling out
forms.
A collection of coarse resolution, distorted texts with character contractures and
backgroundnoise—standardCAPTCHAs—mustbesuccessfullyreadandenteredby
the user into an input area. Computers ﬁnd it difﬁcult due to the noise, which makes
it difﬁcult for software to distinguish between the characters. With convolutional
neural networks (CNNs), computers could perform these CAPTCHA tasks rapidly
and correctly [1].
The development of novel, higher-security CAPTCHAs and the assessment of the
robustness of existing CAPTCHA types can beneﬁt from an easy-to-use, effective
and precise approach to identifying CAPTCHAs. The same method employed for
CAPTCHA identiﬁcation may be used in various ﬁelds, such as forensic investigation
and license plate analysis, among many others. This work focuses on CAPTCHA,
which basically mixes English characters and random digits for security purposes. It
is easy to make, independent of the user’s language and culture, and challenging to
break by raw force. Using standard computer languages, we can create a visual with
numbers and characters. To make the characters more challenging for computers
to decipher, the CAPTCHAs must analyse their twisting conglutination and add
background noise [2]. This research also conducted extensive tests to evaluate the
security of most text-based Captchas resistance mechanisms.
2
Related Works
In early research, pre-processing, segmentation and recognition were the three
primary phases of segmentation-based assaults. As a result of their distinctive designs
and generating algorithms, several CAPTCHA schemes may have various proper-
ties. Therefore, attackers must develop different pre-processing and segmentation
techniques. There is no doubt that the entire assault procedure is time-consuming
and incapable of generalization. Nevertheless, the general approaches that several
earlier research purported to present have certain drawbacks [3].
The image’s characters are recognized using these two processes. As an illustra-
tion, Yan and Ahmad effectively segmented Microsoft CAPTCHAs and recognized
them using several models, with a detection accuracy of 60%. Mori and Malik can
use a form context technique to identify CAPTCHAs in photographs [4].
Through character segmentation and recognition, Chellapilla and Simard are also
able to crack CAPTCHAs. The segmentation approach is also used in domestic
academic studies on CAPTCHA recognition. The k-nearest neighbour (KNN) tech-
nique was proposed by Wang Yang et al. to be used for identiﬁcation veriﬁcation
codes. The digits in the modern CAPTCHAs will partially overlap, making it exceed-
ingly challenging to divide the single character, damaging the recognition accuracy
and hindering the computer from automatically identifying the CAPTCHAs and
boosting network security [5].

CNN Combined with FC Classiﬁer to Combat Artiﬁcial Penta-Digit …
667
LeCun et al. advocated using deep learning approaches to recognize handwritten
digits to address the earlier issues in light of the limits of conventional image
processing techniques. They must all split the photographs, though. Instead, we
immediatelyobtaintheresultusingtheentiresetofphotographsasinput[6,7].Tanget
et al. stated that they implemented a CNN and offered a general technique in 2018.
However, most of these systems relied on time-consuming, ineffective pre-processing
and segmentation techniques [8].
This research suggests a straightforward, all-purpose strategy for defeating text
CAPTCHAs. This approach makes use of a CNN-based attention-based paradigm.
The experimental ﬁndings showed that our model achieved excellent success rates
without the need for segmentation or any other pre-processing methods. The efﬁ-
ciency of all popular defensive methods against deep learning assaults was also
thoroughly examined.
According to the analysis, deep learning assaults may render the segmentation-
resistance concept inapplicable. Several unusual CAPTCHAs were also discussed
in this chapter to assess their security. Our methodology is general for different
CAPTCHA schemes since all objective CAPTCHAs were defeated with excellent
success rates.
3
Dataset
The dataset for the research of Captcha recognition consisted of 1070 text-based
CAPTCHA pictures in PNG format. Rodrigo Wilhelmy and Horacio Rosas provided
the data (2013). The photographs contain ﬁve-letter words that may or may not
contain numbers. Noise has been added to the photos (blur and a line). There are 19
characters, with a character range of ﬁve for each dataset picture. Digits (2, 3, 4, 5,
6, 7 and 8) and certain lowercase English alphabets (b, c, d, e, f, g, m, n, p, w, x,
y) were used. Except for the character n, which is used twice as frequently as other
characters, each character is used almost equally frequently. They are PNG ﬁles with
dimensions of 200 × 50. It would be ideal for creating OCR algorithms using this
dataset. Despite being in greyscale, they nonetheless have three dimensions.
4
Proposed System Design
4.1
Architecture
This identiﬁcation model has an advantage over earlier captcha recognition tech-
niques. It does not require pre-treatment of the original captcha picture and may
perform effective captcha recognition without undergoing the time-consuming
pre-treatment procedure.

668
S. Abhishek et al.
The CNN network design serves as the foundation for the recognition model. The
CNN design initially uses the CNN network structure to extract the characteristics of
the input pictures. The ﬁve-character captcha may be recognized by the model that
was built in this study. We may immediately obtain the network’s outcome by using
decoding techniques.
Using convolutional recurrent neural networks (CRNNs) is recommended while
developing optical character readers. Now that the neural network has been trained,
we must utilize this matrix to decode its output and train the neural network, which
entailscomputingitsloss.BothgoalsareaccomplishedwiththeaidofCTCoperation.
The suggested system’s design and workﬂow are shown in Fig. 1.
Data Pre-processing
Initially, the picture was read in a greyscale for the 5-letter word captcha images
as in Fig. 2. These strategies are used to limit the number of properties from the
initial feature set to decrease model complexity, reduce model overﬁtting, increase
the efﬁciency of model computation, and decrease generalization error. The core
feature extraction concept is data compression while retaining pertinent information.
Following that, further pre-processing procedures were carried out:
Adaptive Thresholding
Adaptive thresholding techniques were used to choose a pixel’s threshold depending
on the dataset’s surrounding portions of the picture. We got good performance for
photographs with a range of brightness levels because we obtained varying thresholds
for distinct portions of the same image as in Fig. 3.
Closing
The closing procedure, which includes dilation and erosion, was used to enlarge the
dataset’s pictures and erode the expanded versions, expanding and contracting the
images to improve their clarity as in Fig. 4.
Dilation
Dilation was performed by running a kernel across the whole picture. The kernel
region’s maximum pixel value was established, and the anchor point of the kernel
was modiﬁed to coincide with the value. The outcome was an enlargement of the
white region in the photograph as in Fig. 5.
Smoothing
Convoluting the picture with a low-pass ﬁlter kernel produces an image blur. Noise
may be removed with it. This ﬁlter blurs the edges of the image by eliminating high-
frequency material (such as noise and edges). There are blurring methods avail-
able that won’t obscure the edges, though. While Gaussian blurring is similar to
average blurring, it uses a weighted mean instead than an essential mean. This means
neighbourhood pixels nearer the centre pixel give the average more “weight”.
Gaussian smoothing is used to eliminate noise that roughly corresponds to a
Gaussian distribution. The ultimate effect is that, compared to the standard procedure,

CNN Combined with FC Classiﬁer to Combat Artiﬁcial Penta-Digit …
669
Fig. 1 Architecture

670
S. Abhishek et al.
Fig. 2 Image before
pre-processing
Fig. 3 Image after adaptive
thresholding
Fig. 4 Image after closing
Fig. 5 Image after dilation
our image is less blurred but more “naturally blurred”. We will be able to retain
more of the image’s edges with this weighting as in Fig. 6. The kernel for Gaussian
smoothing is M x N, where M and N are both odd numbers, just like for average
blurring.
Partitioning
The OpenCV rectangle() function is dedicated to creating algorithms that can address
issues with computer vision. With the help of the OpenCV rectangle function, a
rectangular-shaped hollow box may be drawn on any picture the user provides as in
Fig. 7.
Fig. 6 Image after
smoothing (blurring)

CNN Combined with FC Classiﬁer to Combat Artiﬁcial Penta-Digit …
671
Fig. 7 Image after batch
partitioning
Fig. 8 Label distribution in captchas
More instances of this character will be contained in the test set since label n has a
nearly two times higher count than any other label as shown in Fig. 8. Now, one can
see that just 19 characters—2, 3, 4, 5, 6, 7, 8, and b, c, d, e, f, g, m, n, p, w, x, y—are
utilized in the CAPTCHA pictures. Apart from n, which is used twice as frequently
as other characters, each character is used nearly equally frequently.
Feature Extraction and Selection
The goal of feature extraction is to build a new feature subspace by extracting or
extracting from the original features. Due to the stringent security measures used,
including the thick noise lines, varied foreground and background colours, and a
wider variety of character classes used in the CAPTCHA scheme, even humans ﬁnd
it challenging to recognize the image. Each element of the CAPTCHA picture has a
speciﬁc form, size and orientation [9].
The essential method in character recognition is feature extraction. Recognizing
the CAPTCHA characters requires recovered characteristics. We can distinguish
between the characters thanks to these traits. The structure is built based on the
character’s physical characteristics. Quantities of horizontal and vertical lines, cross
points, endpoints, top and bottom horizontal curves, etc., are a few examples of
structural components. The character’s shape is then decided to utilize these traits.
Data Splitting
The random state parameter, set to the value 42, divides the dataset into the training
set and the validation set. The data that will be used to train the neural network
and evaluate the model’s effectiveness are split into two sets: the training set, which

672
S. Abhishek et al.
contains 90% of the data, and the validation set, which includes the remaining 10%
of the data.
Model Training and Development
The model is constructed using convolutional neural networks to ﬁnd the CAPTCHA
intheimage.ThemodelwascreatedusingthePyTorchmoduleforthe5-lettercaptcha
pictures. This was accomplished by pre-processing the training sample dataset, after
which a model with potentially effective performance layers was built [10]. The batch
size is 32, ﬁve epochs are utilized, and four layers are in each batch.
Dropout layers, convolutional layers, max pooling layers, dense layers and layers
with maximum pooling follow the input layer. The number of epochs used for CNN’s
model development of Captcha images is 150, the batch size is 32, and there are eight
layers overall. CNN with FC classiﬁer uses ﬁve epochs, the batch size is 30, and there
are 13 layers total. CNN LSTM with CTC operation uses ﬁve epochs, the batch size
is 100, and there are 11 layers total.
Input Layer: The ﬁrst layer used in a CNN is the input layer. A Keras tensor is built
using the input layer, which also serves to take input in the form of images.
Conv Layer: The kernel or CNN layer is an alternative term for this layer. CNN’s base
layer is the layer that takes the input attributes from the image and extracts them.
The presence of different convolutional layers is possible; the ﬁrst layer captures
the low-level characteristics of the picture, while the successive layers retrieve the
high-level information [11, 12].
Fully Connected Layer: The convolutional neural network’s last layer is the FC
layer. In this layer, afﬁne and nonlinear functions are combined. The fully linked
input layer (ﬂatten) takes the result of the preceding layers and “ﬂattens” it. With the
help of weights applied to the feature analysis inputs, the ﬁrst utterly connected layer
predicts the proper label. The fully linked output layer provides the ﬁnal probabilities
for each label.
Max Pooling Layer: The max pooling layer delivers its maximum value for the
convolutional layer’s chunk of the picture it covers. With the help of this layer’s
dimensionality reduction, all of the input features are compiled into feature maps.
Dense Layer: In our architecture, the neural network’s lower half consists entirely
of dense layers. A dense layer in a neural network is one whose previous layers are
intimately coupled, meaning that each layer’s neurons are connected to every other
layer’s neuron [13].
Flatten Layer: The pooled feature map obtained from the highest pooling layer
is ﬂattened in this layer or converted into a lengthy vector suitable for additional
processing by the artiﬁcial neural network. This makes back propagation easier.
Dropout Layer: This layer, which primarily makes use of regularization strate-
gies, is included to prevent the model from getting excessively ﬁtted. An overﬁtted

CNN Combined with FC Classiﬁer to Combat Artiﬁcial Penta-Digit …
673
model performs poorly in predictions outside of the training set because it can better
understand the noise in the data [14, 15].
CTC: CTC is designed to need the text that appears in the image. The dimensions and
placement of the characters inside a picture are equally irrelevant. CTC makes the
training procedure simpler since it guarantees that an aligned dataset is not required.
LSTM: For storing long-term memories, LSTM networks are excellent. According
to the statistics, the network might or might not save memory. The network’s
gating mechanisms are responsible for maintaining long-term dependencies. Using
a gating mechanism, the network may instantly release or retain memory. Short-term
memory impairment plagues recurrent neural networks. They need help to facilitate
communication from previous age steps to the latter when a sequence is lengthy
enough.
5
Model Evaluation
The best model weights in terms of validation accuracy for predictions during training
have been saved using model checkpoint, which we utilized to track the performance
of our model. It is feasible to evaluate the model’s present status while it is being
trained at each phase of the process [16]. Using the training dataset, the model may
be evaluated to see how well it is “learning”.
As can be seen in Figs. 9 and 10, dual learning curves for a CNN model with
FC classiﬁer are typically generated throughout training using both the train and test
datasets. A bar graph shown in Fig. 11 depicts the effectiveness of the algorithms
used for the research of captcha image recognition and the outcomes of the different
methods utilized in this work.
Fig. 9 Accuracy curve

674
S. Abhishek et al.
Fig. 10 Loss curves
Fig. 11 Accuracies of classiﬁers
The graph displays each method’s accuracy in the order of lowest to highest,
as can be seen. CNN and LSTM with CTC operation have a performance of 98%
accuracy, making it the best model. The bars’ height represents each technique’s
average accuracy. The accuracy rates of the CNN model and the CNN with FC
model are 89% and 94%, respectively.
6
Conclusion
A test technique called a CAPTCHA is used in network environments to distin-
guish between people and robots. Studies on CAPTCHA recognition can help iden-
tify security vulnerabilities in the CAPTCHA, avoiding hostile network entry. This

CNN Combined with FC Classiﬁer to Combat Artiﬁcial Penta-Digit …
675
studysuggestsaconvolutionalneuralnetwork-basedCAPTCHAsidentiﬁcationtech-
nology in accordance with the CAPTCHA of pictures character distortion. The exper-
imental study demonstrates that the model developed in this work may improve
captcha recognition effects. Although several methods have been put in place to
make it more challenging to locate each text in a Captcha picture, and even though
the segmentation approach we utilized can only partially divide characters from one
another, our detection method was effective against all targeted schemes. This study
proposes a method for identifying CAPTCHAs using convolutional neural networks
in line with the CAPTCHA of photographs, and all letters in the images can be
recognized. Finally, a few points are raised that need more investigation.
7
Future Recommendation
Future development will add the Captchas credit of Chinese characters. It is helpful
to improve feature extraction precision and deep learning network training methods
to avoid incorrectly classifying characters. The model has many parameters, training
takes a long time, and there are limits to how much optimization can be done. When
using a deep learning network to extract character attributes automatically, characters
with similar traits are easily confused. The resilience of other Captcha alternatives
and the capacity of new Captcha models to be simultaneously secure and usable are
open problems that will be the subject of our future study.
References
1. Gossweiler R, Kamvar M, Baluja S (2009) What’s up CAPTCHA? a CAPTCHA based on
image orientation. In: Proceedings of the 18th international conference on World wide web
(WWW’09). Association for Computing Machinery, New York, NY, USA, pp 841–850. https://
doi.org/10.1145/1526709.1526822
2. Dhar A, Kandasamy K, Srinivas S (2014) Capturing the captcha: a novel technique to build self
updating multi-domain training dataset for researchers. In: Proceedings of the 2014 interna-
tional conference on interdisciplinary advances in applied computing (ICONIAAC’14). Asso-
ciation for Computing Machinery, New York, NY, USA, Article 26, pp 1–7. https://doi.org/10.
1145/2660859.2660935
3. Kingma DP, Ba J (2014) Adam: a method for stochastic optimization. arXiv preprint. arXiv:
1412.6980
4. Lin R, Huang S-Y, Bell GB, Lee Y-K (2011) A new CAPTCHA interface design for mobile
devices. In: Proceedings of the twelfth Australasian user interface conference—volume 117
(AUIC’11). Australian Computer Society, Inc., AUS, pp 3–8
5. Poornachandran P, Hrudya P, Reghunadh J (2014) Human vs. Machine: analyzing the robust-
ness of advertisement based captchas. In: Thampi S, Gelbukh A, Mukhopadhyay J (eds)
Advances in signal processing and intelligent recognition systems. Advances in Intelligent
Systems and Computing, vol 264. Springer, Cham. https://doi.org/10.1007/978-3-319-04960-
1_42

676
S. Abhishek et al.
6. Lecun Y, Bottou L, Bengio Y, Haffner P (1998) Gradient-based learning applied to document
recognition. Proc IEEE 86(11):2278–2324. https://doi.org/10.1109/5.726791
7. Krishna R, Chami I, Bernstein M, Fei-Fei L (2018) Referring relationships. In: Proceedings of
the IEEE conference on computer vision and pattern recognition, pp 6867–6876
8. Dharneeshkar J, Aniruthan SA, Karthika R, Parameswaran L (2020) Deep learning based detec-
tion of potholes in Indian roads using YOLO. In: 2020 International conference on inventive
computation technologies (ICICT), Coimbatore, India, pp 381–385. https://doi.org/10.1109/
ICICT48043.2020.9112424
9. Wang Y, Lu M (2016) A self-adaptive algorithm to defeat text-based CAPTCHA. In: 2016
IEEE international conference on industrial technology (ICIT), Taipei, Taiwan, pp 720–725.
https://doi.org/10.1109/ICIT.2016.7474839
10. Kirkbride P, Akber Dewan MA, Lin F (2020) Game-like captchas for intrusion detection.
In: 2020 IEEE international conference on dependable, autonomic and secure computing,
international conference on pervasive intelligence and computing, international conference
on cloud and big data computing, international conference on cyber science and technology
congress (DASC/PiCom/CBDCom/CyberSciTech), Calgary, AB, Canada, pp 312–315. https://
doi.org/10.1109/DASC-PICom-CBDCom-CyberSciTech49142.2020.00061
11. Akshay S, Mytravarun TK, Manohar N, Pranav MA (2020) Satellite image classiﬁcation for
detecting unused landscape using CNN. In: 2020 International conference on electronics and
sustainable communication systems (ICESC), Coimbatore, India, pp 215–222. https://doi.org/
10.1109/ICESC48915.2020.9155859
12. Abhishek S, Sathish H, Kumar A, Anjali T (2022) Aiding the visually impaired using artiﬁ-
cial intelligence and speech recognition technology. In: 2022 4th International conference on
inventive research in computing applications (ICIRCA), Coimbatore, India, pp 1356–1362.
https://doi.org/10.1109/ICIRCA54612.2022.9985659
13. Manoj R, Abhishek S, Anjali T (2022) A strategy for identiﬁcation and prevention of crime
using various classiﬁers. In: 2022 13th International conference on computing communication
and networking technologies (ICCCNT), Kharagpur, India, pp 1–6. https://doi.org/10.1109/
ICCCNT54827.2022.9984364
14. Ravindran R, Abhishek S, Ravindran R, Anjali T (2022) A dynamically calibrated suspension
system. In: 2022 13th International conference on computing communication and networking
technologies (ICCCNT), Kharagpur, India, pp 1–6. https://doi.org/10.1109/ICCCNT54827.
2022.9984619
15. Mannava MC, Tadigadapa B, Anil D, Dev AS, Anjali T, Vidyapeetham AV (2022) CNN
comparative analysis for skin cancer classiﬁcation. In: 2022 13th International conference on
computing communication and networking technologies (ICCCNT), Kharagpur, India, pp 1–6.
https://doi.org/10.1109/ICCCNT54827.2022.9984324
16. Abhishek S, Sathish H, Kumar A, Anjali T (2022) A strategy for detecting malicious spam
emails using various classiﬁers. In: 2022 4th International conference on inventive research in
computing applications (ICIRCA), Coimbatore

Basil Leaf Disease Detection
and Classiﬁcation Using Customized
Convolutional Neural Network
Deepak Mane, Sunil Sangve, Shaila Jadhav, Disha Patil, Rohan Kakde,
and Varad Marudwar
Abstract Farming is the mainstream of the Indian economy. Plant leaf disease
detection mainly focuses on the health of leaf plants and detecting diseases in their
early stages is a tedious task. In this paper, we proposed the customized convo-
lutional neural network (CCNN) model for predicting diseases of leaves of basil
plants. We modiﬁed the traditional CNN model in a way that it deals efﬁciently with
n-dimensional features data as well as unbalanced class data. Here, we predicted
diseases of leaves of basil plants in four categories as fungal, downy mildew, fusarium
wilt, and healthy. No such standard dataset is available for basil leaves so here we
prepared our own 916 image dataset, and the model is trained and tested by different
machine learning approaches However, CCNN has given more accurate results than
other existing algorithms. The model detects diseases of leaves with an accuracy of
94.24% for four classes of basil plant leaves.
Keywords Plant leaf diseases · Image processing · Deep learning · Machine
learning · Convolutional neural network
1
Introduction
Basil (Ocimum basilicum) is a popular herb used in many cuisines around the world. It
isgrownforitsfragrantleavesandisanimportantcommercialcropinmanycountries.
However, basil plants are susceptible to a number of diseases that can affect their
growth and reduce their yield. Early detection of basil leaf diseases is crucial for
controlling and managing these diseases. Traditional methods of disease detection,
such as visual inspection and laboratory testing, can be time-consuming and labor-
intensive. In recent years, there has been increasing interest in using machine learning
D. Mane (B)
Vishwakarma Institute of Technology, Pune, Maharashtra 411037, India
e-mail: dtmane@gmail.com
S. Sangve · S. Jadhav · D. Patil · R. Kakde · V. Marudwar
JSPM’s Rajarshi Shahu College of Engineering, Pune 411033, India
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_50
677

678
D. Mane et al.
techniques, particularly CNNs, to automate the detection of basil leaf diseases. CNNs
are a type of DL algorithm that is particularly well-suited for image classiﬁcation
tasks. They have the ability to learn complex features and patterns from images and
have achieved state-of-the-art results in a variety of image classiﬁcation tasks. In
the context of basil leaf disease detection, CNNs can be trained to recognize the
characteristic patterns and symptoms of different diseases.
In this introduction, we will discuss the importance of early detection of basil leaf
diseases and the potential of using CNNs [1] for this task. In the southeast of Asia,
basil is frequently used in cooking as a fresh or dried herb and is also widely utilized
in beverages. The leaves can be utilized to extract essential oil, which is then used
in fragrances, dental treatments, and cosmetics. Basil also has a number of other
beneﬁts, as shown in Fig. 1. Basil plant leaf diseases detection and its classiﬁcation
are complex tasks. Very few researchers did experiment on medical plant also no such
standard dataset is available for basil plant. Therefore, we collect and prepared our
own basil plant leaf dataset for detection and classiﬁcation of leaf diseases. Here, we
proposed CCNN model to recognize diseases in four categories. Till date no one has
tried to detect diseases in four categories. The proposed model detects and classiﬁes
basil leaf diseases into four categories such as fungal, downy mildew, fusarium wilt
(yellow leaf), and healthy. Main goals of the proposed CCNN algorithm are
• Creating a dataset for Indian basil plant.
• Developing customized CNN for model building.
• Detection and classiﬁcation of basil leaf disease in four categories.
Overview of this paper runs as follows: In Sect. 2, it describes related work. In
Sect. 3, it describes system architecture and CCNN model and its working, and in
Sect. 4, it describes experimental results, and in the last section, i.e., Section 5, we
have concluded.
2
Related Work
Numerous researchers have used various machine learning algorithms to identify
plant diseases and work on Indian plant leaf detection and classiﬁcation is still
ongoing. In 2012, Chaudhary et al. proposed a solution to detect diseases on plant
leaves. To prepare this model, they have used image processing. They have also used
color models like YcbCr, HSI, and CIELB, and this model succeeded in identifying
the diseases on plant leaves. Image processing and customized machine learning
algorithms used to detect diseases on blueberry plants [2]. The technique used by the
author is deep learning in which they used convolutional neural network (CNN). To
enhance and modify, an image they used different image ﬁltering techniques. They
were able to perceive whether a blueberry plant leaf is affected by any disease or not.
The accuracy of the system is 84%. Sladojevic et al. proposed a system which recog-
nizes plant diseases by classiﬁcation of leaves images in deep neural networks. They

Basil Leaf Disease Detection and Classiﬁcation Using Customized …
679
Fig. 1 Beneﬁts of basil
develop models which recognize 13 different types of plant disease. This experiment
shows the accuracy from 91 to 98% [3]. In paper [4], developed a deep CNN model
in which ﬁve different diseases of tomato leaves were identiﬁed after conducting
extensive research. The model proposed by Belal et al. infected tomato leaves were
clearly distinguished from healthy tomato leaves using the newly created model,
which had 99.84% accuracy. For sugar beet disease detection and differentiation,
the author used support vector machine algorithms in [5]. According to different
types and stages of disease, the average accuracy of the model is between 65 and
90%. There are various complicated problems in exploration of different areas like
in the biology sector, biomedicines. Plant disease classiﬁcation and detection by
using convolutional neural network (CNN) is a type of deep learning algorithm that
utilizes machine learning (ML). CNN model is proposed by Saleem et al. in [6].
They use a plant village dataset and experimental accuracy of the model is 90%.
In [7], the authors used CNN architecture on a plant village dataset of sugarcane.
YOLOv3 and Faster-RCNN algorithms are used for getting more accuracy. The result
of the sugarcane leaf disease detection model is 93.20%. In [8], Nagaraju used deep

680
D. Mane et al.
learning convolutional neural network, artiﬁcial intelligence, DCNN, ANN tech-
niques to design a system which detects plant leaf disease. They used plant village,
real ﬁeld dataset, and average accuracy of model is 91.53%. In [9], authors used three
methods: (1) single image prediction, (2) graphical interface (GUI) method, and (3)
through local host disease detection. Plant leaf is detected with overall accuracy of
95%. In [10], Rinu and Manjula have proposed a system which detects the plant
leaf disease with accuracy of 94.8%. System also works in unfavorable conditions
using convolutional neural network. Real-life leaf images were captured and used to
train the model based on CNN by authors in [11]. To divide the leaf into unhealthy
and healthy category, additional preprocessing techniques are used and the accuracy
achieved by Rishiikeshwer et al. is 95% on actual leaf images and 98% on standard
dataset. In [12], Hari et al. proposed a model which detects the plant disease of
multiple plants, like apple, maize, tomato, grape, potato in early stages. Technique
used by the authors is CNN, and accuracy achieved is 86.00%. In [13], Militante
et al. have proposed a model which has achieved 96.5% rate of accuracy, using
deep learning, computer vision, CNN on plant village dataset. Tomato plant diseases
are identiﬁed by authors in [14], using the image processing as the techniques and
CNN algorithm. The accuracy achieved is 98%. In [15], deep learning-based disease
recognition models for plants include a variety of qualities, including the fact that
they are unsupervised, have high accuracy, have strong universality, and have great
training efﬁciency. The accuracy of the model is on average 83.75%. In [16], in order
to classify and identify basil leaves disease, the survival of ﬁttest approach was used
along with three class data, i.e., two diseased classes that are downy mildew, leave
spot and one healthy class they have got accuracy of 95%.
3
System Architecture
The entire accomplishment procedure is broken down into the essential stages in the
subsections below.
3.1
Dataset Preparation
At every stage of illness identiﬁcation research, from the training phase to assessing
the effectiveness of classiﬁcation algorithms, an appropriate dataset is very necessary.
It should be noted that there has been very limited work done on basil plant leaf and
whatever work that has been done, they have not offered access to their dataset, so
due to the lack of a dataset to train the proposed model. As a result of this study, a
self-made basil leaf image dataset has been created and used. A sample collection of
916 basil leaf samples has been taken from a variety of locations including farms and
houses. There are four classes in the dataset: fungal, downy mildew, fusarium wilt
(yellow leaf), and healthy leaves. The RGB image is then converted into grayscaled

Basil Leaf Disease Detection and Classiﬁcation Using Customized …
681
images by converting it from RGB to grayscale. At ﬁrst, each image was cropped
separately. Each of these cropped samples is then re-sized to a 256 × 256 size image.
The images are renamed and saved separately for each of them. In order to increase
the size of the dataset, various transformations have been performed via scaling:
every image is. Due to these transformations, the dataset size has increased by four
times. Some sample images from our dataset are represented in Table 1, and its types
of diseases with symptoms are represented in Table 2. Dataset is classiﬁed into four
classes as three diseased and one healthy. In order to classify leaf images, we use their
symptoms as criteria for classifying them. During the creation of the basil dataset,
images were divided into different groups based on the symptoms they displayed.
Images are categorized as fungal, downy mildew, fusarium wilt (yellow leaf), and
healthy leaves in four classes. Every class contains a different number of images
which are as follows:
• Fungal: 253
• Downy mildew: 175
• Fusarium wilt (yellow leaf): 212
Table 1 Dataset sample
Samples of Healthy leaf Images 
Samples of Fusarium wilt leaf Images 
Samples of Fungal leaf Images 
Samples of Downey Mildew leaf Images 

682
D. Mane et al.
Table 2 Types of disease and symptoms
Leaf
Image 
Diseas
es & its 
Sympt
oms 
Fungal :The 
dark spots on 
leaves can be 
circular or of 
any shape with 
a light center or 
a dark center. It 
causes a fungus 
on leaves. 
Downy mildew : 
Plants may get dark 
to black angular 
necrotic areas, grey 
fuzzy on the 
underside of the 
leaves, and 
discoloration 
around the main 
vein that spreads 
outward. 
Fusarium wilt 
:
A plant with 
dark streaks on 
the lower side 
of the leaf, 
yellow, 
withering leaf, 
and stunted 
growth. 
Healthy
Leaf : 
Healthy 
leaves are 
green in 
color and do 
not exhibit 
any dark 
spots. 
• Healthy: 276
3.2
Experimental Process of the Model
Three layers are included in the proposed model, namely the convolution layer,
the pooling layer, and the fully connected layer. As in Fig. 2, there are two more
key parameters in addition to these three layers, namely the dropout layer and the
activation function. Block diagram for the working is shown in Fig. 2. When it comes
to solving classiﬁcation problems, CNN is probably one of the most powerful and
accurate methods [17, 18]. We achieved the high accuracy for model by following
some tuning parameters like by collecting more data, more layers can be added by
adding more ﬁlters, by increasing or decreasing the size of the image and in order to
increase or decrease the number of epochs.
3.3
System Architecture
Due to the large number of parameters in a leaf image, CNNs are very effective for
image classiﬁcation. Using CNNs to reduce parameter numbers without compro-
mising model quality is an extremely effective method. In order to reduce the dimen-
sions of the input matrix, a sliding window of smaller size is used. Creating models
with CNN is a straightforward process, especially when it comes to n-dimensional
data and big data. Quite a few researchers have experimented with basil as a medic-
inal plant, but there is no standard dataset for it. To detect and classify leaf diseases,

Basil Leaf Disease Detection and Classiﬁcation Using Customized …
683
Fig. 2 Workﬂow block diagram
here we collected and prepared our own basil leaf dataset. In this paper, we proposed
a CCNN model to classify diseases into four categories. Until now, no one has
attempted to detect diseases in four categories.
Proposed CCNN model is predicting diseases of leaves of basil plants. Proposed
model efﬁciently deals with n-dimensional features data as well as unbalance class
data. Firstly, we are providing the basil plant leaf dataset to the system and input
image of disease leaf. In feature extraction, it will draw out characteristics from an
image that can be used to interpret it. Then, during feature selection, a subset of
relevant features (variables, predictors) will be chosen for use in building the model.
We will explore deep learning techniques to automatically classify and identify plant
diseases using leaf photographs. Comparison of diseases will identify the presence of
leaves and distinguish between healthy leaves and various diseases. Then a speciﬁc
plant disease will appear. Architecture diagram for the proposed model is shown in
Fig. 3.
3.4
Methodology
The following steps are used to detect leaf diseases using an input image.

684
D. Mane et al.
Fig. 3 Architecture diagram
3.4.1
Image Acquisition
Image acquisition (data preparation) is retrieving an image from some source. Any
vision system starts with the acquisition of images. The process of taking an image
with a digital camera and saving it in a digital format is known as image loading.
Using a camera, we typically take images of both healthy and unhealthy. Images are
captured from the agricultural ﬁeld as we have built our own dataset. The images are
of red, green, and blue (RGB) format.
3.4.2
Image Preprocessing
The image data is improved through image preprocessing, which reduces unwanted
distortions. We perform image processing in order to remove unwanted distortion and
noise which enhances the image by using techniques like image enhancement, RGB
to Lab conversion, and ﬁltering. Preprocessing includes image clipping, smoothing,
and enhancement. Denoising can be performed using a variety of reduction tech-
niques. With the right threshold, medium ﬁlters perform better with salt-and-pepper
noise.

Basil Leaf Disease Detection and Classiﬁcation Using Customized …
685
3.4.3
Image Segmentation
Image segmentation involves dividing an image into sections with similar pixel
compositions. The segmentation of the image into several segments will depend
on the area of interest. Image segmentation is the process of dividing an image into
similar areas. There are many ways to segment data, including Otsu’s approach, k-
means clustering, and transforming RGB images into HIS models. For each set of
characteristics, the k-means cluster algorithmic rule is used to categorize objects into
K different categories. By reducing the sum of the squares of the distance between
the object and the matching cluster, objects are classiﬁed.
3.4.4
Feature Extraction
Feature extraction extracts features that can be used to determine the meaning of
a given image. After the image segmentation, the disease portion of the image
is extracted. Color, texture, shape, edges, and morphology are characteristics that
can be used in plant disease detection. For feature extraction, the GrayLevel Co-
occurrence Matrix (GLCM), which depicts spatial arrangements and separation
between features, is used. The statistical features that were extracted are mean, vari-
ance, skewness, kurtosis, eccentricity, contrast, energy, perimeter, homogeneity, area,
standard deviation, centroid, aspect ratio, entropy, and sum of entropy.
3.4.5
Classiﬁcation and Detection of Diseases
Classiﬁcation is correctly predicting the value of a discrete class variable or attributes.
Since most green pixels refer to the healthy leaf and are of no use for disease identiﬁ-
cation procedures, this method, which is used to shorten processing time by deleting
the green pixels from the leaf, is used. Computing the intensity value of the green
pixels allows for the masking of those pixels. The RGB component of a given pixel
is given a value of zero if the intensity is below a predetermined threshold value.
3.5
Forward Steps for CCNN Learning
Here, CCNN model involves ﬁve layers, that is, convolutional layer, pooling layer,
ﬂatten layer, dropout layer, and dense layer.

686
D. Mane et al.
3.5.1
Convolutional Layer
The ﬁrst layer is used to extract the different features from the input images convolu-
tional layer. Layers of convolutional neural networks are responsible for storing the
output of the prior layer’s kernels, which consist of weights and biases for learning.
As a fundamental component of CNN architecture, convolution layers are used.
A combination of linear and nonlinear operations is used to extract features in this
method. The activation function is used in conjunction with convolution to extract
features. Feature extraction from leaves is carried out by a convolution layer in the
CNN.
xl
i j =
a−1

m=0
a−1

n=0
ωmnyl−1
(i+m)( j+n)
(1)
3.5.2
Pooling Layer
An initial layer of convolution is followed by an additional layer of pooling. The
purpose of this layer is to reduce overﬁtting and also reduce the feature map size and
training time.
Rectiﬁed linear unit (ReLU) is used as an activation function in the pooling layer.
In ReLU, negative pixels are set to zero element-by-element. A rectiﬁed feature map
is generated as a result of introducing nonlinearity to the network. In comparison
with sigmoid and tanh functions, ReLU is considered to be six times faster in its
convergence. The ReLU function reduces the amount of time it takes to calculate
because no exponential terms are incorporated into the formula.
ReLU function : R(z) = max(0, z)
(2)
A stride of k can be used to transform an input image A (n1 x n2) into an output
image by applying either the max function fmax or the average function favg to each
k x k block in the image. The max function fmax returns the maximum value in
each block, while the average function favg returns the average value of the pixels
in each block. This process reduces the size of the image while retaining important
information.
P Ai, j = max
⎡
⎢⎢⎢⎣
Aki,kj
Aki+1,kj
Aki,kj+1
Aki+1,kj+1
. . .
. . .
Aki,kj+k−1
Aki+1,kj+k−1
...
...
. . .
...
Aki+k−1,kj Aki+k−1,kj+1 . . . Aki+k−1,kj+k−1
⎤
⎥⎥⎥⎦
(3)

Basil Leaf Disease Detection and Classiﬁcation Using Customized …
687
3.5.3
Dropout Layer
As a result of connecting all features to the fully connected layer, the training dataset
tends to overﬁt. An overﬁtted model performs very well on training data but it fails on
testingdatawhichisanegativeimpactonthemodel.Forovercomingthisproblem,we
have to use dropout layer which drops some neurons during training which reduces
size of the model. For instance, when the neural network passes a dropout of 0.2, 20%
of the nodes are randomly removed. A dropout layer enhances a machine learning
model’s performance by preventing overﬁtting by simplifying the network.
3.5.4
Flatten Layer
The ﬂatten layer is used to convert the 28*28*50 output of the convolutional layer
into a single one-dimensional vector which is used for input to the dense layer. The
most parameters are in the ﬁnal dense layer. Each and every output ‘pixel’ from the
convolutional layer is connected to the ten output classes via this layer.
3.5.5
Dense Layer
In dense layer, each neuron receives input from every neuron in the previous layer,
giving the layer its name as dense. Based on the results of convolutional layers,
pictures are categorized using dense layers.
4
Experimental Results
In [16], the authors propose a model for the detection of basil leaf disease, using their
self-made dataset of basil plant leaves, The model they have developed is capable
of detecting both healthy leaves and two different basil diseases, including downy
mildew and leaf spot. Their trained model has an overall accuracy of 95.73%. We have
created our own basil dataset with 916 leaf images since the basil plant leaf dataset
is not available as an open source. In the proposed method, the average accuracy
achieved is 96.66% with three basil leaf classes and 94.24% with four basil leaf
classes. There are three types of healthy leaves and two types of unhealthy diseases,
downy mildew, and fusarium wilt. The four classes are divided into one healthy class
and three different leaf diseases, downy mildew, fusarium wilt, and fungal wilt. The
proposed model can detect three different varieties of basil leaf disease, as well as
normal leaf. This makes it more effective and ﬂexible enough to be used for a wide
range of diseases. Table 3 depicts comparison between existing set of model and our
proposed model.
A comparison of the proposed CCNN basil plant leaf disease detection model
with contemporary methodologies [16].

688
D. Mane et al.
Table 3 Analyses of
comparison between the
proposed model and the
existing classiﬁcation model
Classiﬁcation models [16]
Test set accuracy (%)
Random Forest
94.31
Naive Bayes
91.86
KNN
92.43
Support Vector Machine
92.89
Discriminant Analysis
92.30
Bayesian Generalized Linear
72.04
Gaussian Process
89.57
Extreme Gradient Boosting
93.87
Conditional Inference Tree
93.36
Flexible Discriminant Analysis
92.42
Proposed Model-CCNN
94.24
Results on different models
During the development of this model, multiple transfer learning techniques and
models were used to detect basil plant leaf disease. We obtained different kinds of
results with varying levels of accuracy. Accordingly, we conclude that the customized
CNN model provides the highest accuracy of all. Figure 4 compares the results of
transfer learning models with those of CCNN model.
Four (fungal, downy mildew, fusarium, healthy) diseases got 94.24% accuracy and
on three (downy mildew, fusarium wilt, healthy) got 96.6% accuracy. Performance
between training versus validation loss graph represented in Fig. 5 and classiﬁcation
report represented in Fig. 6. From the confusion matrix, it is clearly evident that the
Fig. 4 Results comparison with different transfer learning approaches

Basil Leaf Disease Detection and Classiﬁcation Using Customized …
689
Fig. 5 Performance graph between training versus validation
Fig. 6 Classiﬁcation report
dataset and the model which we have built are giving great results as we can see
for downy mildew disease 32 samples of 35 were predicted correctly, similarly for
fungal 21 samples out of 25 were predicted correctly, whereas for fusarium wilt 16
of 16 were predicted correctly and for healthy class 62 out of 63 were predicted
correctly. Confusion matrix is represented in Fig. 7.
5
Conclusion
This paper includes implementation procedure, materials, techniques of plant leaf
disease detection model on basil leaf using CNN technique, and for implementing
the proposed model, we have created our own dataset using images of basil plants.
Convolutional neural networks (CNNs) have shown to be effective in the detection
of plant leaf diseases as we have achieved accuracy of 94.4% for basil plant using

690
D. Mane et al.
Fig. 7 Confusion matrix
our own dataset. They have the ability to learn complex features and patterns from
images, which makes them well-suited for basil plant disease detection. In recent
years, numerous studies have demonstrated the effectiveness of CNNs in detecting
various plant diseases, including diseases of fruits, vegetables, and grains. These
studies have used a variety of CNN architectures, including VGG, ResNet, and
Inception, and have achieved high accuracy rates in their respective datasets. One of
the main advantages of using CNNs for plant leaf disease detection is their ability
to handle large amounts of data and to automatically learn features from the images.
This can signiﬁcantly reduce the need for manual feature engineering and make the
process more efﬁcient. Overall, CNNs have proven to be a powerful tool for basil
plant disease detection and have the potential to greatly improve the efﬁciency and
accuracy of disease detection in agriculture.
References
1. Chaudhary P, Chaudhari AK, Cheeran AN, Godara S (2012) Colour transform based approach
for disease spotdetection on plant leaf. Int J Comput Sci Telecommun 3(6):65–69
2. Aziz S et al (2019) Image pattern classiﬁcation for plant disease identiﬁcation using local
tri-directional features. In: IEEE 10th annual information technology, electronic and mobile
communication conference (IEMCON, 2019)
3. Sladojevic S et al (2016) Deep neural networks based recognition of plant diseases by leaf
image classiﬁcation. Comput Intell Neurosci, vol 11
4. Ashqar BAM, Abu-Naser SS (2018) Image based tomato leaves diseases detection using deep
learning. Int J Acad Eng Res (IJAER) 2(12):10–16
5. Rumpf T, Mahlein AK, Steiner U, Oerke EC, Dehne HW, Plümer L (2010) Early detection and
classiﬁcation of plant diseases with support vector machines based on hyperspectral reﬂectance
6. Saleem MH, Potgieter J, Mahmoodrif K (2019) Plant disease detection and classiﬁcation by
deep learning. Plants, vol 8, p 468

Basil Leaf Disease Detection and Classiﬁcation Using Customized …
691
7. Malik HS et al (2020) Disease recognition in sugarcane crop using deep learning. In: Advances
in artiﬁcial intelligence and data engineering, pp 189–206
8. Nagaraju M, Chwla P (2020) Systematic review of deep learning techniques in plant disease
detection. Int J Syst Assur Eng Manag 11(3):547–560
9. Bansal M et al (2021) Plant leaf disease detection and recognition. Int J Res Educ Sci Methods,
9(6)
10. Rinu R, Manjula SH (2021) Plant disease detection and classiﬁcation using CNN. (IJRTE)
ISSN: 2277-3878 (Online), 10(3)
11. Rishiikeshwer BS, AswinShriram T, Sanjay Raju J, Hari M, Santhi B, Brindha GR (2019)
Farmer-friendly mobile application for automated leaf disease detection of real-time augmented
data set using convolution neural networks
12. Hari SS et al (2019) Detection of plant disease by leaﬁmage using convolutional neural network.
In: 2019 International conference on vision towards emerging trends in communication and
networking (ViTECoN)
13. Militante SV, Gerardo BD, Dionisio NV (2019) Plant leaf detection and disease recogni-
tion using deep learning. In: 2019 IEEE Eurasia conference on IOT, communication and
engineering, ISBN: 978-1-7281-2501-5
14. Ashok S et al (2020) Tomato leaf disease detection using deep learning techniques. In: IEEE
Conference Record # 48766; IEEE Xplore ISBN: 978-1-7281-5371-1
15. Guo Y et al (2020) Plant disease identiﬁcation based on deep learning algorithm in smart
farming. Hindawi Discrete Dynamics in Nature and Society, vol 2020
16. Dhingra G, Kumar V, Joshi HD (2019) Basil leaves disease classiﬁcation and identiﬁcation by
incorporating survival of ﬁttest approach. Elsevier
17. Mane DT, Kulkarni UV (2020) A survey on supervised convolutional neural network and ıts
major applications. In: Deep learning and neural networks: concepts, methodologies, tools,
and applications, edited by Information Resources Management Association. IGI Global, pp
1058–1071. https://doi.org/10.4018/978-1-7998-0414-7.ch059
18. Mane D et al (2022) Detection of anomaly using machine learning: a comprehensive survey.
Int J Emerg Technol Adv Eng 12(11):134–152. https://doi.org/10.46338/ijetae1122_15

Segmentation of Brain Tumours
from MRI Images Using CNN
Dhakshina Ilango and Razia Sulthana
Abstract Identiﬁcation of brain tumours in the early stage is key to proper treatment
and diagnosis. It can be classiﬁed as malignant or benign based on the aggressiveness
of the tumour. To diagnose a patient, an MRI imaging device is used to obtain scans
of the brain. Due to the large quantity of data produced, radiologists must perform the
tedious task of going through each MRI image to identify the brain tumour’s location,
size, and origin. This process is prone to human error and is also time-consuming.
Therefore, this paper proposes a methodology to accurately diagnose and segment
the brain tumours from the MRI images using convolutional neural networks (CNNs)
speciﬁcally U-NET architecture.
Keywords Machine learning · Biomedical image segmentation · Brain Tumours ·
Convolutional neural networks
1
Introduction
Brain tumours occur due to an abnormal division of cells in the brain. Some of
the main symptoms of brain tumours are fatigue, difﬁculty in coordination, speech
difﬁculties, confusion, seizures, headaches, nausea or vomiting, issues in vision, etc.
They can be classiﬁed as primary and metastatic brain tumours. Primary is when
cancer originates from the brain and does not transmit to any other parts of the body.
Metastatic brain tumours are when cancer proceeds to the brain from some other part
of the body. Tumours can also be benign which means non-cancerous or malignant
which means the brain tumour is cancerous in nature [1].
D. Ilango (B)
Department of Computer Science, Birla Institute of Technology and Science, Pilani–Dubai
Campus, Dubai, United Arab Emirates
e-mail: f20190003@dubai.bits-pilani.ac.in
R. Sulthana
Department of Computing and Mathematical Sciences, University of Greenwich, Old Naval Royal
College, London SE10 9LS, UK
e-mail: razia.sulthana@greenwich.ac.uk
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_51
693

694
D. Ilango and R. Sulthana
There are many kinds of brain tumours depending on location, origin, size, etc.
Some of the common types of brain tumours are as follows:
1. Glioma—It originates from the brain, and it is a common type of brain tumour.
The tumour arises from the aggressive division of glial cells that surround
neurons. These can be malignant or benign depending on the spread rate. About
33% of brain tumours are gliomas.
2. Meningioma—This is also a very common brain tumour that originates from the
brain and 30% of brain tumours are meningiomas. It originates in the meninges
which consist of the layer of tissues that surround and cover the brain just under
the skull. Most meningiomas are benign, but some can be persistent and return
even after treatment [2].
3. Gliosarcoma—These tumours are connected with other supportive tissues. They
are mostly benign but can spread to other areas. They are also usually aggressive
and resistant to chemotherapy [2].
To detect and diagnose a patient with brain tumours usually, MRI imagining
devices are utilized as they provide better results with respect to soft brain tissue
as compared to other types of imaging devices. The MRI device makes use of the
hydrogen molecules present in our body, and as per the principles of electromagnetic
imaging, any moving charge has its own magnetic ﬁeld. Therefore, an MRI device
with the help of powerful magnets and external radiofrequency and sensors connected
toacomputercanobtainimagesofthebrain.Radiologistsmustsiftthroughnumerous
MRI sequences to precisely diagnose the origin, type, and size of the patient’s brain
tumour. The various MRI sequences are T1, T1C, T2, and Flair. Each sequence
provides additional information about the tumour [3].
To avoid manual segmentation of brain tumours in MRI images, the proposed
methodology uses a deep learning model to automate the process. Neural networks
are a set of supervised learning algorithms that mimics the human brain in the way it
operates. The nodes simulate the neurons in the brain and the connections between
them act like synapses in the brain. It comprises of 3 main layers input, hidden, and
output layers. Neural network becomes a deep learning model when it has several
hidden layers in it. Speciﬁcally, convolutional neural networks (CNNs) are achieving
great results in the ﬁeld of biomedical image processing and computer vision. An
image is considered as input in the form of a matrix of pixels. The model makes use of
ﬁltersforexampleofsize3×3andslidesthemacrossimagesforautomaticextraction
of features. For each pixel, a value is computed using a convolutional operation. This
process drastically reduces the number of inputs and weights required [4]. The output
of the convolution operation is passed to an activation function which determines the
presence of the essential feature required. In a similar manner, the number of layers
implemented can be increased to check the presence of nuanced features [5].
This paper aims to solve the tedious task of manual segmentation of brain tumours
from MRI images. This process can be automated by using CNN. In the literature
survey, this model had the greatest accuracy amongst all the other segmentation
methods. It was also found that using a less complex CNN can decrease the compu-
tational overhead of training a deep learning (DL) model as well as increase the

Segmentation of Brain Tumours from MRI Images Using CNN
695
accuracy compared to other machine learning algorithms. The issue of diagnosing
brain tumours with variable sizes, shapes, and structures was also achieved [5].
2
Related Work
The ﬁrst study [6] proposed an approach for the segmentation of brain tumours
using a thresholding algorithm which classiﬁes voxels above a speciﬁc threshold
as containing tumours. The proposed method can be condensed into 3 stages. The
ﬁrst stage is pre-processing which improves the quality of the MRI image by using
techniques such as morphological and pixel subtraction operations. The second stage
is the segmentation stage which is a threshold-based segmentation. Its main function
is to transform grey-scale images into binary images. The third stage is the image
ﬁltering stage which uses a median ﬁlter to eliminate noise from the images. Finally,
this approach has a success rate of 94.28% and an overall accuracy of 96% [6].
This study [7] provided an approach that enhanced the DL algorithm which is a
kernel-based CNN with M-SVM. In the pre-processing stage, the LoG and CLAHE
methods are used to detect the edges of images. They are also used to remove
unwanted noise and parts of the background from the MRI images. Feature extraction
is done using the SGLDM method. It is rooted in the spatial dispersal of levels of
grey in the regions of interest which focussed on the construct, site, and overall shape
of the tumour in the image. The M-SVM algorithm is used to classify the image as
either ordinary or unusual. The images in the unusual class are passed as input to the
kernel-based CNN which isolates the tumour in the image. Finally, this segmented
image is classiﬁed as either malignant or benign [7].
This paper proposed [8] a two-step veriﬁcation method for brain tumour image
segmentation, wherein 2 algorithms are used. The watershed algorithm and SIFT
together are called as watershed-matching algorithm. Brain tumour image segmen-
tation is done using the classical watershed algorithm. SIFT is used to match the
segmented brain tumour image to the original image. This is the ﬁrst veriﬁcation
step. Next, the volume of the tumour is calculated to differentiate between benign
and malignant tumours. The area of the tumour is calculated, and on detection of
white pixels greater than 500, the tumour is classiﬁed as being in the critical stage
else the initial stage. Hence, the paper uses a two-step veriﬁcation process for brain
tumour image segmentation [8].
This paper [9] detailed an improved approach to brain tumour image segmenta-
tion using the fuzzy C mean algorithm and multiobjective optimization. The fuzzy
clustering algorithm is used to cluster a set of data points so that it has more similarity
with one group than the other. Segmentation of brain tumours from MRI images is
done using fuzzy C-means and genetic algorithm. To extract objects from the back-
ground, thresholding segmentation is done. Finally, classiﬁcation is performed by
using an ensemble of decision trees [9].
In this paper [10], a novel dominant grey-level-based K-means algorithm is used
as opposed to a standard K-means algorithm which randomly chooses k number

696
D. Ilango and R. Sulthana
of pixels as the centroid. The proposed methodology ﬁrst uses pre-processing tech-
niques to convert red, green, and blue images of the MRI brain image dataset to
greyscale images. The algorithm is utilized to discover the probabilities of indi-
vidual pixels. In this K-means clustering algorithm, the top 16 pixels with the highest
probabilities are chosen as centroids initially [10].
In [11], the aim was to perform automatic brain tumour segmentation in MRI
images using contour-based algorithm, less computational costs, and a texture. The
ﬁrst stage is the detection of tumour slices. This is done by creating a histogram
for each hemisphere of the brain and determining which hemisphere would likely
contain tumours. Feature extraction is done using AM-CWT and DT-CWT and other
statistical techniques. Feature selection is done using a modiﬁed regularized winnow
algorithm. Finally, the tumour region is segmented by using an active contour model
Skippy greedy snake algorithm [11].
In [12], a multi-atlas-based adaptive active contour model was used in MRI and
CT images for brain tumour image segmentation. The method utilizes theoretical
information for the segmentation of brain tumours. It consists of reference images
and label maps. The STAPLE algorithm is used to combine the label maps into a more
accurate brain tumour contour. Active contour models are classiﬁed as either edge
or region-based models. The proposed AELR active contour model is implemented
using the DRLSE algorithm [12].
In [13], multi-modality MRI imaging scans were used to perform brain tumour
image segmentation. Firstly, feature extraction is performed on pre-processed
images. All the features combined are given as input to the RF classiﬁer to
predict ﬁve classes, namely background, enhancing tumour, non-enhancing tumour,
oedema, and necrosis. Finally, the class labels are used to calculate three regions
hierarchically—active tumour, enhancing tumour, and complete tumour [13].
This study [14] presented a comparison of various dimensionality reduction PCA
algorithmssuchasPPCA,EM-PCA,GHA,andAPEXwithtwoclusteringalgorithms
K-means and fuzzy C-means algorithm. PCA is essential to decrease the complexity
of the image dataset as well as combat the curse of dimensionality issue. It was
observed that PPCA achieved the best results out of all the clustering methods, and
the combination of EM-PCA and the PPCA with the K-means algorithm obtained
the best results for clustering and segmentation [14].
This research paper [15] focussed on the identiﬁcation, segmentation, and early
detection of brain tumours by using feature extraction methods such as DWT, GLCM,
and probabilistic neural networks as a classiﬁer. The ﬁrst stage is the pre-processing
of images which included segmentation and region growth. The feature extraction
is executed by using DWT for extracting coefﬁcients of wavelets and GLCM for
extraction of statistical features. Finally, the images are given as input to the PNN
for the grouping of abnormal and normal brain tissues. The location of the tumours
is also identiﬁed [15].
This study [16] aimed to implement deep learning neural networks to distinguish
between ordinary brain tissues and different types of tumour tissues using brain
MRI scans. In the recommended approach, image segmentation is achieved using the
fuzzy C-means algorithm. Feature extraction is done using DWT, and dimensionality

Segmentation of Brain Tumours from MRI Images Using CNN
697
is reduced using PCA. Finally, the classiﬁcation of the brain tumours is done using
deep neural networks (DNNs) [16].
This [17] research paper focussed on the fusion of various MRI sequences to
provide an accurate analysis of the brain tumour. They are combined using DWT
andDaubechieswaveletkernelintoasingleMRIimage.Next,PDDFisperformedfor
noisereductionandglobal thresholding. Lastly, theimages areclassiﬁedusingaCNN
which consisted of 23 layers. These layers include convolutional, batch normaliza-
tion, rectiﬁed linear unit function, max pooling for downsampling, fully connected,
and softmax layers to detect images with the presence of tumours [17].
The central idea of this study [18] was to improve the existing CNN model by using
the BAT algorithm which is used for the automatic segmentation of brain tumours
from images. An optimized loss function is used to attain this. The two phases of
this model are pre-processing and segmentation. A hybrid CNN model is used, and
the loss function is optimized by making use of the BAT algorithm [18].
In [19], prior knowledge is introduced in the CNN model. The information given
was that most of the tumour regions in the images are of left–right symmetry. This
prior knowledge is ignored by most of the existing CNN models. Therefore, by
using DCSNN, brain tumour image segmentation is performed by using multiple
symmetric masks in the layers. The model is computationally efﬁcient as it took
only 10.8 s to segment an image. There are many stages in the proposed method.
The ﬁrst stage is data pre-processing. Next is the baseline network which integrates
a bottom-up and top-down pathway. The DCSNN takes four modal MRI images,
so the left–right similarity mask (LRSM) presents a broad asymmetrical situation
of four MRI sequences. The DCSNN is a ﬁve-classiﬁcation task model. Finally,
post-processing is done to remove segments with sparse voxels [19].
Research paper [20] aimed to present a CNN model that is less complex and has
greater picture clarity and accuracy. The backpropagation method is used to classify
brain tumours. The objective is to check if the model can classify test cases effectively
into regular or irregular classes. To achieve this, the ﬁnal layer was executed only
in the training phase. The convolutional layers consider the local spatial constructs
in the previous layers. The forward pass is when multiple layers of neurons are
interlinked in a way that each consecutive layer just relays the information from the
previous layer which is what takes place in a feed-forward network. The backward
pass is when the weight or bias is modiﬁed, and the shift is propagated backwards all
throughout the network for changing the weights and biases. The last layer consists
of a softmax function [20]. Table 1 shows a summary of all of the various algorithms
that can be used for brain tumour image segmentation.
3
Proposed Work
The brain tumour image segmentation is done using T1w MRI scans from the RSNA
MICCAI PNG dataset from Kaggle which consists of training and testing data [21].

698
D. Ilango and R. Sulthana
Table 1 Different methods used for brain tumour image segmentation
References
Problem statement
Dataset
Algorithm
Advantage
Performance measure
value
[6]
To achieve clear
segmentations of brain
tumours that can be used by
a medical professional to
gain more insight about the
tumours to aid with their
diagnosis
TCIA (The Cancer
Imaging Archive, 2017)
Thresholding algorithm
Easy and efﬁcient
implementation
96%
[7]
Difﬁculty in brain tumour
segmentation in an MRI
image due to non-uniform
boundaries of tumours and
location of tumours in the
brain
Not mentioned
Laplacian of Gaussian
ﬁltering method (LoG) with
contrast limited adaptive
histogram equalization
(CLAHE)
convolutional neural
networks (CNNs) with
multiclass-support vector
machine (M-SVM)
Effective segmentation
increased accuracy and
low time complexity
84%
[8]
Issues with diagnosing
brain tumours present in the
soft tissues of the brain as
biopsy of tumour tissues are
required which is
time-consuming as well as
prone to errors
BRATS 2012 dataset
Watershed algorithm and
scale-invariant feature
transform (SIFT) algorithm
Computationally less
complex and non-invasive
98.5% accuracy
(continued)

Segmentation of Brain Tumours from MRI Images Using CNN
699
Table 1 (continued)
References
Problem statement
Dataset
Algorithm
Advantage
Performance measure
value
[9]
Challenges regarding
accurate segmentation of
brain tumours in MRI
images due to spatial and
structural differences. Hard
to isolate a region of interest
DICOM MRI database
Fuzzy C-means algorithm,
genetic algorithm, and
decision trees
Improvement in the centre
of cluster detection and
increased convergence
time
92%
[10]
Addresses the issue of
selecting a random point as
centroids for clustering
which results in imprecise
brain tumour image
segmentation
MRI brain image
database
Dominant grey-level-based
K-means clustering
algorithm
Able to characterize
regions with increased
accuracy and less
computational complexity
95.37%
[11]
The huge computational
cost issue with
implementation of existing
techniques for the
automatic detection of brain
tumours is addressed
NCI-MICCAI, 2013
database
Regularized winnow, KNN
classiﬁer, and Skippy
greedy snake algorithm
Increased segmentation
accuracy, and reduced
computational costs
93.82%
[12]
The difﬁculties with respect
to exact delineation and the
introduction of
interobserver and
intraobserver variability of
brain tumours in
radiotherapy
Shandong Cancer
Hospital and Institute
(Shandong, China) in
2019
Simultaneous truth and
performance level
estimation (STAPLE) and
the distance regularized
level set evolution (DRLSE)
algorithm
Time-saving and accurate
segmentation
87.19%
(continued)

700
D. Ilango and R. Sulthana
Table 1 (continued)
References
Problem statement
Dataset
Algorithm
Advantage
Performance measure
value
[13]
Usage of multi-modality
images to classify brain
tumours
MICCAI
BraTS 2013
Random forest classiﬁer
algorithm
Multi-modality MRI
images are used to give an
accurate account of the
location and size of the
tumour and increase
classiﬁcation accuracy
88%—complete tumour
region, 75%—core
tumour region and
95%—enhancing tumour
region
[14]
Image segmentation
increases the number of
features selected which
leads to curse of
dimensionality problem and
affects the overall
performance of the
algorithm
Dataset of T1w
MRI images was
obtained from a patient
who suffered from a
brain tumour
Conventional principal
component analysis (PCA),
probabilistic principal
component analysis
(PPCA), expectation
maximization-based
principal component
analysis (EM-PCA),
generalize Hebbian
algorithm (GHA), and
adaptive principal
component extraction
(APEX)
algorithms, K-means, and
fuzzy C-means algorithms
Comparison of various
PCA algorithms in
combination with FCM
and K-means algorithm,
less time-consuming and
less complex image data
Error rates for 512 × 512
images for
PCA—3.7993,
EM-PCA—3.7430,
PPCA—3.7991,
GHA—4.7339 AND
APEX—4.5778
[15]
Difﬁculty in identiﬁcation,
segmentation, and
discovery of affected areas
in brain tumour MRI
images at an early stage
Digital imaging and
communications in
medicine (DICOM)
dataset
Discrete wavelet transform
(DWT), grey-level
co-occurrence matrix
(GLCM), and probabilistic
neural networks (PNNs)
Fast and high accuracy in
the detection of brain
tumours at early stages
95% accuracy
(continued)

Segmentation of Brain Tumours from MRI Images Using CNN
701
Table 1 (continued)
References
Problem statement
Dataset
Algorithm
Advantage
Performance measure
value
[16]
Issues differentiating
between normal brain
tissues and brain tumour
tissues
Dataset obtained from
Harvard Medical School
Website
Fuzzy C-means (FCM),
discrete wavelet transform
(DWT) and deep learning
neural networks algorithms
Differentiate between
different types of brain
tissues and able to identify
complex relationships in
the dataset
96.97%
[17]
Single MRI sequences do
not provide enough
information for accurate
diagnosis of the type, shape,
and severity of brain tumour
BRATS
2012, BRATS 2013,
BRATS 2015, BRATS
2013 Leader board and
BRATS 2018
Discrete wavelet transform
(DWT), Daubechies wavelet
kernel, PDDF, global
thresholding algorithm, and
convolutional neural
networks (CNNs)
More information is
provided due to the fusion
of 4 MRI sequences, high
accuracy, and large dataset
0.97 ACC—on BRATS
2012 Image, 0.98
ACC—BRATS 2013
Challenge, 0.96
ACC—BRATS 2013
Leader board, 1.00
ACC—BRATS 2015
Challenge and 0.97
ACC—BRATS 2018
Challenge datasets
[18]
The structure of tissues
adjacent to the tumours is
changed by the tumour
mass effect. Therefore, an
improved CNN model is
required which produces
optimized MRI images
Brain tumour
segmentation
challenge 2015 database
(BRATS 2015)
Enhanced convolutional
neural networks (ECNN)
and BAT algorithms
Increased accuracy
compared to that of a
regular CNN model
92%
[19]
The changing nature of
brain tumours with respect
to size, shape, and location
affects the accuracy of
segmentation
BRATS 2015
Deep convolutional
symmetric neural network
(DCSNN)
Complex function
mapping achieved which
learns features by itself,
less computation time
0.852 dice similarity
index
(continued)

702
D. Ilango and R. Sulthana
Table 1 (continued)
References
Problem statement
Dataset
Algorithm
Advantage
Performance measure
value
[20]
A less complex CNN model
with high accuracy and
precision
Radiopaedia 2013 and
BRATS 2015
Convolutional neural
network (CNN)
Training data are not
corrupted by outliers, are
less complex, and have
high accuracy
97.5% accuracy

Segmentation of Brain Tumours from MRI Images Using CNN
703
The algorithm used is convolutional neural networks speciﬁcally U-NET architec-
ture. This is done by using transfer learning. The U-NET model has been trained on
the BraTs 2020 dataset [22–24].
The U-NET model is speciﬁcally used for biomedical image segmentation. The
advantage of using this algorithm is that it can be trained end to end using very few
images compared to other CNN architectures. It is U-shaped and symmetric and
works by using an encoder—decoder path or is also known as a contracting and
expansive path. The encoder half works by reducing the spatial dimensions of the
image as it passes through each layer [25–28].
The encoder path is responsible for feature extraction. With each convolution
operation, detailed features are extracted, and the input size of the image is reduced. In
theencoderpath,theconvolutionaloperationtakesplacebyconvolvingtheinputMRI
scans using an n × n size ﬁlter to give an output feature map, and batch normalization
normalizes the output of the convolution layer, that is, it brings the mean to 0 and
standard deviation to 1. Finally, the output from the batch layer is passed onto the
rectiﬁed linear unit function (ReLU) activation function.
The max pooling layer present in the encoder path is used to calculate the
maximum value from each 2 × 2 size window of the feature map. The convolu-
tion method which consists of the convolution layer is called multiple times with
different number of ﬁlters starting from 32, 64, 128, and 256.
The decoder path is responsible for the reconstruction of the segmented masks
from the extracted features. In the decoder path, the spatial dimensions of the image
are increased, and the value of the number of channels is reduced. This includes
calling the convolution method using different number of ﬁlters but in this case,
the number of channels gradually decreases as opposed to max pooling where it
gradually increases in number. Upsampling is done each time after the convolution
method is called. It is done to preserve the input volume size at the end of each
convolutional operation. The feature maps of the encoder are concatenated with the
decoder so that the model can segment the brain tumours from the MRI scans using
detailed and general features. Finally, the input is passed to the ﬁnal convolutional
layer with kernel size 1 × 1 and with the sigmoid function as an activation function.
In this project, the U-NET model is implemented by using the concept of transfer
learning which is using prior knowledge of the model when solving one problem and
using that information to solve a similar application. Figure 1 gives an overview of
the proposed methodology.
Brain Tumour Image Segmentation:
The prediction of the tumour is done by ﬁrst resizing the image to 240 × 240, and
then, the model is used to predict the mask using the resized image, and the dimension
of the image is reversed by using the transpose method. The noise from the image is
removed by using morphological functions by using OpenCV library. Opening which
is erosion followed by dilation was performed to remove unnecessary minute objects
from the image and to smoothen the boundary of the tumour. The function to predict
the tumour is the ﬁnd_tumour function which ﬁnds the path of the target image on
which the prediction should be made and passes it to the prediction function. It also

704
D. Ilango and R. Sulthana
Fig. 1 Architecture diagram
returns the path to the tumour slice if the tumour pixel is greater than max_detected.
Then, a display function is used to display the image of the brain in greyscale and
the tumour in red.
4
Results Analysis
The model was able to predict the region of the brain tumour accurately from the
MRI image as the accuracy of the U-NET model is 98%. The presence of a tumour
in the MRI scan was predicted by using a red mask as shown in Fig. 2. The model
was able to precisely segment tumours of varying boundaries and edges.
5
Conclusion
In conclusion, it is found that deep learning architectures, speciﬁcally U-NET archi-
tecture, can be used in biomedical image segmentation to produce accurate results.
Using this method, variable size, shape, and structure tumours can be easily diag-
nosed. And there will be no requirement for manual segmentation by radiologists
as well. In the future, the model can be further optimized by trying different loss
functions and optimizers as well as testing the model on different modalities of MRI
scans.

Segmentation of Brain Tumours from MRI Images Using CNN
705
Fig. 2 Brain tumour image
segmentation using MRI
scans
References
1. Mayo Clinic Staff, Brain Tumour, Retrieved 15th Oct 2021, from https://www.mayoclinic.org/
diseases-conditions/brain-tumor/symptoms-causes/syc-20350084
2. The John Hopkins University, Types of Brain Tumours. Retrieved 15th Oct 2021, from https://
www.hopkinsmedicine.org/health/conditions-and-diseases/brain-tumor/brain-tumor-types#
malignant
3. National Institute of Biomedical Imaging and Biomedical Engineering, Magnetic Resonance
Imaging (MRI). Retrieved 15th Oct 2021, form https://www.nibib.nih.gov/science-education/
science-topics/magnetic-resonance-imaging-mri
4. Stewart M Simple ıntroduction to convolutional neural networks. Retrieved 20th Oct
2021, from https://towardsdatascience.com/simple-introduction-to-convolutional-neural-net
works-cdf8d3077bac
5. Lang R, Zhao L, Jia K (2016, October) Brain tumor image segmentation based on convolution
neural network. In: 2016 9th ınternational congress on image and signal processing, biomedical
engineering, and ınformatics (CISP-BMEI). IEEE, pp 1402–1406
6. Ilhan U, Ilhan A (2017) Brain tumor segmentation based on a new threshold approach. Procedia
Comput Sci 120:580–587
7. Thillaikkarasi R, Saravanan S (2019) An enhancement of deep learning algorithm for brain
tumor segmentation using kernel based CNN with M-SVM. J Med Syst 43(4):1–7
8. Hasan SM, Ahmad M (2018) Two-step veriﬁcation of brain tumor segmentation using
watershed-matching algorithm. Brain Inform 5(2):1–11
9. Rodríguez-Méndez IA, Ureña R, Herrera-Viedma E (2019) Fuzzy clustering approach for brain
tumor tissue segmentation in magnetic resonance images. Soft Comput 23(20):10105–10117
10. Nitta GR, Sravani T, Nitta S, Muthu B (2020) Dominant gray level based K-means algorithm
for MRI images. Heal Technol 10(1):281–287
11. Nabizadeh N, Kubat M (2017) Automatic tumor segmentation in single-spectral MRI using a
texture-based and contour-based algorithm. Exp Syst Appl 77:1–10
12. Zhang Y, Duan J, Sa Y, Guo Y (2020) Multi-atlas based adaptive active contour model with
application to organs at risk segmentation in brain MR ımages. IRBM

706
D. Ilango and R. Sulthana
13. Usman K, Rajpoot K (2017) Brain tumor classiﬁcation from multi-modality MRI using
wavelets and machine learning. Pattern Anal Appl 20(3):871–881
14. Kaya IE, Pehlivanlı AÇ, Sekizkarde¸s EG, Ibrikci T (2017) PCA based clustering for brain
tumor segmentation of T1w MRI images. Comput Methods Prog Biomed 140:19–28
15. Shree NV, Kumar TNR (2018) Identiﬁcation and classiﬁcation of brain tumor MRI images
with feature extraction using DWT and probabilistic neural network. Brain Inform 5(1):23–30
16. Mohsen H, El-Dahshan ESA, El-Horbaty ESM, Salem ABM (2018) Classiﬁcation using deep
learning neural networks for brain tumors. Future Comput Inform J 3(1):68–71
17. Amin J, Sharif M, Gul N, Yasmin M, Shad SA (2020) Brain tumor classiﬁcation based on DWT
fusion of MRI sequences using convolutional neural network. Pattern Recogn Lett 129:115–122
18. Thaha MM, Kumar KPM, Murugan BS, Dhanasekeran S, Vijayakarthick P, Selvi AS (2019)
Brain tumor segmentation using convolutional neural networks in MRI images. J Med Syst
43(9):1–10
19. Chen H, Qin Z, Ding Y, Tian L, Qin Z (2020) Brain tumor segmentation with deep convolutional
symmetric neural network. Neurocomputing 392:305–313
20. Suneetha B, Rani AJ, Padmaja M, Madhavi G, Prasuna K (2021) Brain tumour image
classiﬁcation using improved convolution neural networks. Appl Nanosci 1–9
21. Baid U et al (2021) The RSNA-ASNR-MICCAI BraTS 2021 benchmark on brain tumor
segmentation and radiogenomic classiﬁcation. arXiv:2107.02314 [cs], Sep. 2021. [Online].
Available https://arxiv.org/abs/2107.02314
22. Menze BH et al (2015) The multimodal brain tumor image segmentation benchmark (BRATS).
IEEE Trans Med Imaging 34(10):1993–2024. https://doi.org/10.1109/tmi.2014.2377694
23. Bakas S et al (2017) Advancing the cancer genome atlas glioma MRI collections with expert
segmentation labels and radiomic features. Sci Data 4(1). https://doi.org/10.1038/sdata.201
7.117
24. Bakas S et al (2019) Identifying the best machine learning algorithms for brain tumor segmen-
tation, progression assessment, and overall survival prediction in the BRATS challenge. arXiv:
1811.02629 [cs, stat], Apr. 2019. [Online]. Available https://arxiv.org/abs/1811.02629
25. Ronneberger O, Fischer P, Brox T (2015) U-Net: convolutional networks for biomedical image
segmentation. arXiv.org, May 18, 2015. https://arxiv.org/abs/1505.04597
26. Sulthana AR, Jaithunbi AK (2022) Varying combination of feature extraction and modiﬁed
support vector machines based prediction of myocardial infarction. Evol Syst. https://doi.org/
10.1007/s12530-021-09410-4
27. Pitchai R, Supraja P, Razia Sulthana A, Veeramakali T (2021) Brain tumor segmentation and
prediction using fuzzy neighborhood learning approach for 3D MRI ımages. https://doi.org/
10.21203/rs.3.rs-497725/v1
28. Pitchai R, Supraja P, Sulthana AR, Veeramakali T, Babu ChM (2022) MRI image analysis for
cerebrum tumor detection and feature extraction using 2D U-ConvNet and SVM classiﬁcation.
Pers Ubiquit Comput.https://doi.org/10.1007/s00779-022-01676-y

Distributed Training of Large-Scale Deep
Learning Models in Commodity
Hardware
Jubaer Ahmad, Tahsin Elahi Navin, Fahim Al Awsaf, Md. Yasir Arafat,
Md. Shahadat Hossain, and Md. Motaharul Islam
Abstract Running deep learning models on a computer is often resource intensive
and time-consuming. Deep learning models require high-performance GPUs to train
on big data. It might take days and months to train models with large datasets, even
with the help of high-performance GPUs. This paper provides an affordable solu-
tion for executing models within a reasonable time interval. We propose a system
which is perfect to distribute large-scale deep learning models in commodity hard-
ware. Our model consists of creating distributed computing clusters using only open-
source software which can provide comparable performance to High-Performance
Computing clusters even with the absence of GPUs. Hadoop clusters are created
by connecting servers with a SSH network to interconnect computers and enable
continuous data transfer between them. We then set up Apache Spark on our Hadoop
cluster. Then, we run BigDL on top of Spark. It is a high-performance Spark library
that helps us scale to massive datasets. BigDL helps us run large deep learning models
locally in Jupyter Notebook and simpliﬁes cluster computing and resource manage-
ment. This environment provides computation performance up to 70% faster than a
single machine execution with the option of scaling in case of model training, data
throughput, hyperparameter search, and resource utilization.
J. Ahmad · T. E. Navin · F. Al Awsaf · Md. Y. Arafat · Md. S. Hossain · Md. M. Islam (B)
Department of Computer Science and Engineering, United International University, Dhaka,
Bangladesh
e-mail: motaharul@cse.uiu.ac.bd
J. Ahmad
e-mail: jahmad181023@bscse.uiu.ac.bd
T. E. Navin
e-mail: tnavin191056@bscse.uiu.ac.bd
F. Al Awsaf
e-mail: fawsaf181253@bscse.uiu.ac.bd
Md. Y. Arafat
e-mail: marafat183030@bscse.uiu.ac.bd
Md. S. Hossain
e-mail: mhossain173032@bscse.uiu.ac.bd
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_52
707

708
J. Ahmad et al.
Keywords Hadoop · Apache Spark · BigDL · Secure Shell
1
Introduction
The amount of data produced each day is only increasing. Around 41 billions of
devices will be interconnected, producing 79 zettabytes of data [1]. To handle such a
big amount of data, high-performance GPUs will play a vital role. GPU prices are on
the rise, and the shortage of GPUs continues to increase. Under such circumstances,
an affordable alternative for data processing can play a vital role in the management
of big data [2]. The concept of sharing processing and storage power among multiple
devices to execute huge datasets is getting popular each day. Over the past few years
quite, a few projects such as in [3, 4] on cluster computing have been launched.
We chose Hadoop cluster for our computer clusters because of its capacity to
manage large amounts of data. Hadoop clusters are affordable, and they can simply
be scaled up by adding more cluster nodes without requiring changes to the appli-
cation logic. Hadoop clusters are also resilient due to their replication feature. With
commodity hardware, any corporation may build up a robust Hadoop cluster. The
basic role of a Hadoop cluster is to store data on worker nodes.
The master node will store metadata and manage the cluster system as a whole.
Apache Spark is a fast and general processing framework compatible with Hadoop
clusters. We must execute it on top of the Hadoop cluster to process data in HDFS.
We will run Spark on standalone mode where the master and each worker have
their own web UI that displays cluster and job information. Spark offers machine
learning and deep learning with advanced analytics features. Because of its low-
latencyin-memorydataprocessingcapacity[5], it cantackleawiderangeof analytics
challenges. BigDL [6] is a distributed deep learning package that runs on Apache
Spark and will be used for our research. It uses existing Spark clusters to execute deep
learning computations and makes data loading from large Hadoop datasets easier.
The following points summarize the major contributions of our paper:
• We have developed an automated system that allows users to effortlessly divide
deep learning workloads over numerous computers for enhanced performance in
deep learning. The cluster communication will execute via LAN connectivity.
• This system allows consumers to obtain a performance boost with the addition of
extra logical cores.
• This automationsystemenables customers torunlarge-scaledeeplearningmodels
on available and affordable commodity hardware.
• Our system can speed up deep learning research by 20% for users who do not
have access to expensive hardware such as GPU.
• We have developed an automatic bash script generator to develop highly complex
scripts and created a novel architecture for distributed training deep learning
models using CPU only architecture.

Distributed Training of Large-Scale Deep Learning Models …
709
The rest of the paper is organized as follows: in Sect. 2, we address the literature
review, in Sect. 3, we suggest a methodology, in Sect. 4, we include simulations and
evaluations, and in Sect. 5, we conclude the paper.
2
Literature Reviews
For the execution of large data analysis or deep learning models, distributed
computing is an emerging technology. This technology enables large data processing
and management in the workplace without the use of physical high-performance
computers. By using this technology, some low-performance computers can be
connected together and become a powerful computing machine.
LadonSpark is a free and open-source method for automatically conﬁguring and
deploying Spark cluster. In this system, Hadoop-distributed ﬁle systems can be
deployed automatically [1]. DeepSpark [2] is a distributed and parallel deep learning
system that uses both Apache Spark and Caffe. They used Apache Spark to create
the deep learning framework interface and parameter exchanger. Hadoop and Spark
are assessed and compared in this paper in terms of runtime, memory and network
utilization, and central processor efﬁciency [3]. SystemML is used for expressing
machine learning algorithms in a higher-level language and compiling and running
them in a MapReduce environment [4].
BigDL is a framework, and they [5] introduce it including its distributed execution
approach, compute performance, training scalability, and real-world use cases. MLlib
[6] is Spark’s-distributed machine learning library with implementations of common
learning methods such as classiﬁcation, regression, collaborative ﬁltering, clustering,
and dimensionality reduction. In [7] introduces MPCA SGD, a method for distributed
deep neural network training on top of the Apache Spark. DeepSpark [8] is a DL
framework built on Spark and developed an asynchronous stochastic gradient descent
(SGD) for better DNN training.
They [9] show how to improve ML on Apache Spark by employing MapRDD
and the newly developed asynchronous stochastic gradient descent (SGD) method. In
[10], they deployed a framework for DNN training using Spark which can train large-
scale deep networks using computer clusters with thousands of devices. They present
a unique multimodal [11] DNN based on the CNN architecture for remote sensing
observation classiﬁcation. In [12], they compare all deep learning frameworks,
conduct experiments, and assess the outcomes with a comprehensive table.
3
Proposed Methodology
Using BigDL with Apache Spark and Hadoop, training of large-scale deep learning
models can be distributed among the computers in a cluster. First, we create a user

710
J. Ahmad et al.
interface where we have the option to write host IP, hostname to conﬁgure host-
name, and host ﬁle of each PC. Then, we designate Master and workers. Then,
install OpenSSH server automatically on each PC and generate SSH key for each PC
pairs and check SSH passwordless connectivity. After the connection is established,
user will install Python and install Jupyter Notebooks by himself on master node.
Then, we conﬁgure Hadoop ﬁles, Spark, and BigDL, and the script will be generated
automatically.
According to Fig. 1, ﬁrst, we establish a cluster of machines over a secure shell
connection in our proposed approach. Using encryption and hashing techniques, a
secure shell connection ensures data integrity and privacy. It connects computers
and allows them to interact using hypertext, similar to web pages. It authenticates
users by issuing each node with a unique SSH key. Following the completion of the
connection between PCs, we use HDFS to store our data in a distributed manner.
We create a multi-node Hadoop cluster that includes a master node and two worker
nodes. Apache Spark is used for data analysis and processing. The master node
monitors and controls the worker nodes as they process data in parallel. Spark jobs
created by the context are distributed to worker nodes by the driver. Each worker
node’s executor executes tasks based on job instructions. Spark incorporates outputs
created by the executor in each node via Spark driver in addition to data processing.
The BigDL library is then installed on Apache Spark. We can use the BigDL library
to execute deep learning models.
3.1
Graphical User Interface Using Automation Scripts
We create a GUI for setup automation of all the software and packages. This makes
the setup easy for users who are not familiar with conﬁguration using XML and other
text-based conﬁguration ﬁles. We use Zenity to create GUI-based bash automation
scripts [20]. A single shell script is run to complete the whole setup without directly
having to edit any conﬁguration ﬁles. The shell script starts running in the backend
[21]. Users are prompted by Zenity to provide network details for each computer in
the cluster, such as device hostname and IP address, as well as other parameters such
as the number of master and worker devices and each of their unique conﬁguration
details, such as DataNodes, master nodes, secondary master nodes, and resource
managers.
After collecting details from the GUI, they are stored in a SQLite database for
backup. These details are then used as variables to be placed into other conﬁguration
ﬁles which are automatically accessed through the original shell script.
3.2
Secure Cluster Management
Data transfer between network devices must be managed in order for devices to
communicate appropriately. A set of rules known as a network protocol regulates the

Distributed Training of Large-Scale Deep Learning Models …
711
Fig. 1 Implementation architecture
communication. Telnet and remote shell (RSH) were early network protocols that
did not provide enough security against malicious cybersecurity threats. The SSH
protocol was prompted by the demand for a more secure network communication
technique. SSH, also known as Secure Shell or Secure Socket Shell, is a network
protocol that allows us to safely access and communicate with remote computers
(mostly remote servers) [16]. SSH creates a cryptographically secure connection

712
J. Ahmad et al.
between the client and server, authenticating each side and transferring commands
and output back and forth. We create RSA key-based passwordless connectivity
between each devices in the cluster to ensure secure and uninterrupted connectivity
between them. This enables only the devices which have authorized each other’s
keys to access the network without password.
3.3
Distributed File Management
Our suggested approach needs Apache Spark to analyze the data by dividing the
duties among each node by creating JVM tasks and Hadoop’s HDFS to serve as
a distributed data repository. Because Hadoop’s HDFS is a wonderful solution for
storing massive volumes of data in distributed storage conﬁgurations, we are storing
data in a Hadoop cluster. When the ﬁle sizes are huge and the amount of data is
signiﬁcant, it offers very good throughput [19]. With growing data blocks, Hadoop
clusters may swiftly add nodes and are easily scalable. Commodity hardware can
be used to set up Hadoop clusters, making them a cheap alternative to a distributed
ﬁle system. Additionally, it duplicates the data across several nodes to lower the
likelihood of a cluster failure.
As shown in Fig. 2, a collection of computers is required before we can establish
a system of interconnected nodes that aid in the operation of an application by
cooperating. An HDFS cluster is made up of a single NameNode, a master server
that manages the ﬁle system namespace and controls client access to ﬁles. A number
of DataNodes, typically one per node in the cluster, also manage storage that is
connected to the nodes that they run on. The HDFS protocol allows for the storage of
user data in ﬁles and provides a ﬁle system namespace. A ﬁle is divided into one or
more blocks and kept inside a collection of DataNodes. The NameNode handles tasks
relatedtotheﬁlesystemnamespace,suchasopening,shutting,andrenamingﬁlesand
directories. Additionally, it affects how blocks are assigned to DataNodes. Serving
read and write requests from the ﬁle system’s customers is the responsibility of the
DataNodes. The DataNodes also manage block formation, deletion, and replication
when given instructions by the NameNode.
3.4
Spark Process Management
We can use Hadoop MapReduce to run deep learning models directly on a cluster
using frameworks such as DeepLearning4J, but we will use Apache Spark on top of
Hadoop because it outperforms the Hadoop MapReduce system and it is much more
user friendly [15]. We will go through why Spark is utilized and how it works to run
massive data processing tasks and deep learning models.
Spark is a big data processing framework that utilizes “In-Memory” cluster
computing. In-memory computing refers to the use of middleware software that

Distributed Training of Large-Scale Deep Learning Models …
713
Fig. 2 HDFS ﬁle storage using Hadoop cluster
enables data to be stored in RAM across a cluster of machines and processed in
parallel.
Figure 3 shows the relation between Hadoop and Spark in a cluster setup. First,
we set up HDFS to store data in the cluster. Then, we use Spark as a standalone
cluster manager. The Spark Core serves as the backbone of the entire Spark project.
It includes a variety of functionality, such as task management, scheduling, and
input–output procedures. BigDL and Spark MLlib help Spark Core for training deep
learning. BigDL solves the deep learning dependency problem. Different parts of
Fig. 3 are described below:
Spark Standalone and Spark Core: It denotes that Spark is built on top of HDFS
and that HDFS is given special consideration. In this case, Spark and MapReduce
will run in parallel to cover all Spark jobs on the cluster.
Data Sharing using Spark RDD: Spark’s concurrent and fault-tolerant data format
is the Resilient Distributed Dataset (RDD). Spark sends RDD data to the cluster
automatically and executes concurrent actions on it.
BigDL: Users can create any deep learning applications as ordinary Spark programs
using BigDL, which is constructed as a library on top of Spark [17].
In the following Fig. 4, we have the control panel master, Spark driver, and Python
IDE which is inside the master node. Using the control panel master, we manage the
data distribution and execution among local machines, and the Spark driver commu-
nicates with the DataNodes to keep track of the information about the executors at all
times. The cluster manager creates a number of Spark workers. The Spark executor

714
J. Ahmad et al.
Fig. 3 Spark on top of Hadoop
is a part of the Spark Core residing in each DataNode that executes local machine
data individually.
Fig. 4 Spark execution model

Distributed Training of Large-Scale Deep Learning Models …
715
Fig. 5 BigDL in relation to Apache Spark components
3.5
Distributed Deep Learning Management
BigDL is a distributed deep learning library developed by Intel and provided to the
open-source community with the goal of bringing large data processing and deep
learning together. BigDL’s purpose is to make deep learning more accessible to the
big data community by allowing them to construct deep learning applications using
common tools and infrastructure.
BigDL [18] is implemented as a library on top of Spark, as seen in Fig. 5, allowing
users to construct deep learning applications as ordinary Spark programs. As a result,
it can work in tandem with other Spark libraries (such as Spark SQL and Dataframes,
Spark ML pipelines, [13, 14] Spark Streaming, Structured Streaming, and so on) and
run on existing Spark or Hadoop clusters.
A variety of machine learning algorithms in Spark MLlib are based on
synchronous mini-batch Stochastic Gradient Descent (SGD). These algorithms
leverage Spark’s reduce or tree Aggregate methods to aggregate parameters.
4
Simulations and Evaluations
We divide this section into two parts. First, we describe our experimentation
environment. Then, we describe our experimentation results.
4.1
Simulation Setup
We have based our experiments on three types of environment setups, which are most
commonly used and accessible by students. The competition of our setup is Google
Colab (Free Tier), which is most commonly used by students and also anyone who
does not have access to expensive computational resources. The other competition
is a simple local machine setup, comparable to a single laptop or a desktop machine.

716
J. Ahmad et al.
Table 1 Experimentation environment conﬁgurations
Device type
Processor
GPU
RAM
Physical core
Three-node
cluster
Intel i7—8th Gen
None
8 × 3 = 24 GB
8 × 3 = 24 @
2.4 GHz
Google Colab
Intel Xeon
NVIDIA
P100—16 GB
13 GB
1@2.4 GHz
Single server
Intel i7—8th Gen
None
8 GB
8@2.4 GHz
Our model is implemented on a three-node cluster, which is one of the best ways to
train large-scale deep learning models in our opinion, because distributed computing
can be easily implemented by students in their computer labs or even connecting
their personal computers together so that they can make better use of the resources
already available to them. Increase the data size. Table 1 shows a comprehensive
conﬁguration of our three test environments.
4.2
Evaluation Result
As we see in the following comparisons between the three setup environments previ-
ously mentioned, the three-node cluster is using Apache Spark and Intel BigDL. Our
experimentation focuses on two common metrics: hyperparameter tuning and model
training performance.
Hyperparameter Tuning Performance: Hyperparameter tuning is a common step
for improving machine learning pipelines. The traditional method of hyperparam-
eters’ optimization is a grid search, which simply makes a complete search over a
given subset of the hyperparameters’ space of the training algorithm. In this work, we
have used Spark to speed up this step. Spark allows training multiple models with
different parameters concurrently on a cluster, with the result of speeding up the
hyperparameter tuning step. Performance of hyperparameter tuning with grid search
runs multiple training jobs in parallel; therefore, it is expected to scale well when run
in parallel, as it was the case in our work (see also the paragraph on hyperparameter
tuning). This is conﬁrmed by measurements, as shown in Fig. 6, by adding execu-
tors, i.e., the number of models trained in parallel, the time required to scan all the
parameters decreases, as expected. For a single number of execution, elapsed time is
more than 8 min and it decreases with the increment of the executor and it reduces
time with 4, 2, and 0.9 min for nodes 2, 3, and 4, respectively.
CPU utilization: The MNIST classiﬁer is appropriate for training on desktop
computers due to the training dataset size being small in scale. However, the model
complexity is high for the B-RNN model. Figure 7 depicts the CPU usage while
training the MNIST classiﬁer on a Spark cluster using BigDL, utilizing four execu-
tors and training with a batch size of 32. Notably, Fig. 7 shows that the training

Distributed Training of Large-Scale Deep Learning Models …
717
Fig. 6 Hyperparameter optimization performance using GridSearch
took place over the course of 9 min and required the use of 32 cores in total as each
executor has eight cores. Spark monitoring instrumentation has been used to measure
the executor CPU utilization by JVM.
Model Training Performance: Figure 8 describes the training time of all the models
in our experimentation. We can see that in the case of the CNN (inception) model,
the Colab and BigDL cluster perform close to 2 min, but the local computer takes
around 4 min. When compared to CNN, the time disparity between BigDL and Colab
for RNN increases. It takes about 3 min in BigDL and about 5 min in Colab. In the
Fig. 7 CPU utilization by JVM during training task

718
J. Ahmad et al.
local environment, the model consumes most time. The BigDL and Colab models
for B-RNN take about 8 min, but the local PC takes almost 10 min. BigDL and Colab
differ in time by about two minutes in LSTM. In the case of an autoencoder and a
feedforward network, the time difference in various environments is comparable, but
both models are much faster than LSTM. Speciﬁcally, the feedforward network is
the fastest one. From the chart, it is evident that our environment runs faster for all
models except B-RNN. It is to be noted that for local CPU, we used 5000 × 10 linear
classiﬁer structure by downscaling the images. Evaluations show that on average,
Google Colab performs 15% and local PC performs 72% less efﬁciently than our
BigDL cluster for training.
Communication Overhead: Figure 9 describes the communication overhead in our
test environments. The BigDL cluster has the largest overhead due to the distributed
nature of the data, and there is more communication between the servers to retrieve
data. In the graph, the BigDL cluster has more communication overhead compared
to the Google Colab VM. Because of the Gbps LAN connection we have established
the data transformation. In fact we have completed data transformation, the time it
takes to transport 275 80 GB of data is almost 10s. The local machine setup has the
least overhead ranging from 0.79 to 10 s because there is no outside communication
delay with any other machine for data transfer.
Fig. 8 Training time comparison of different deep learning models in different architectures

Distributed Training of Large-Scale Deep Learning Models …
719
Fig. 9 Communication overhead with different data sizes
5
Conclusions
For the proposed technique, we trained different deep learning models using our
BigDL cluster. The cluster gave us very comparable performance to GPU-based
setups such as Google Colab or Kaggle Notebooks, even better in some models. This
cluster provided almost twice the performance of a standalone computer. Users can
easily create clusters like this by connecting devices via a LAN switch using the
automated setup GUI in our model. This model is very useful for researchers and
students who use computational resources such as GPUs. By using the Apache Spark
and BigDL stack, users can also gain a huge boost in data throughput and transfer
rates. As BigDL is still a relatively new framework, more features should be added
to make it more compact. More research should be done to optimize factors such
as Communication Overhead, Energy Consumption. Future work should apply the
following design concepts to make it simple for data scientists to create large-scale,
distributed AI applications: common APIs, complete pipeline, transparent scaling
and acceleration with straightforward, and well-known APIs for the data scientists;
the toolkit should be able to scale out end-to-end Artiﬁcial Intelligence pipelines
(distributed data-parallel processing, training, tuning, and inference).

720
J. Ahmad et al.
References
1. Fernández AM, Gutiérrez-Avilés D, Troncoso A, Martínez-Álvarez F (2020) Automated
deployment of a spark cluster with machine learning algorithm integration. Big Data Res
19:100135
2. Kim H, Park J, Jang J, Yoon S (2016) Deepspark: spark-based deep learning supporting
asynchronous updates and caffe compatibility
3. Mostafaeipour A, Jahangard Rafsanjani A, Ahmadi M, Arockia Dhanraj J (2021) Investi-
gating the performance of Hadoop and Spark platforms on machine learning algorithms. J
Supercomput 77(2):1273–1300
4. Ghoting A, Krishnamurthy R, Pednault E, Reinwald B, Sindhwani V, Tatikonda S, Tian Y,
Vaithyanathan S (2011) SystemML: declarative machine learning on MapReduce. In: 2011
IEEE 27th international conference on data engineering. IEEE, pp 231–242
5. Dai JJ, Wang Y, Qiu X, Ding D, Zhang Y, Wang Y, Jia X, Zhang CL, Wan Y, Li Z, Wang J,
Huang S, Wu Z, Wang Y, Yang Y, She B, Shi D, Lu Q, Huang K, Song G (2019) BigDL: a
distributed deep learning framework for big data. In: Proceedings of the ACM symposium on
cloud computing (SoCC ’19)
6. Meng X, Bradley J, Yavuz B, Sparks E, Venkataraman S, Liu D, Freeman J, Tsai DB, Amde
M, Owen S, Xin D, Xin R, Franklin MJ, Zadeh R, Zaharia M, Talwalkar A (2016) MLlib:
machine learning in apache spark. J Mach Learn Res 17(1):1235–1241
7. Langer M, Hall A, He Z, Rahayu W (2018) MPCA SGD—a method for distributed training of
deep learning models on spark. IEEE Trans Parallel Distrib Syst 29(11):2540–2556
8. Kim H, Park J, Jang J, Yoon S (2016) DeepSpark: a spark-based distributed deep learning
framework for commodity clusters
9. Li Z, Davis J, Jarvis SA (2018) Optimizing machine learning on apache spark in HPC
environments. In: 2018 IEEE/ACM machine learning in HPC environments (MLHPC), pp
95–105
10. Khumoyun A, Cui Y, Hanku L (2016) Spark based distributed Deep Learning framework
for Big Data applications. In: 2016 international conference on information science and
communications technologies (ICISCT), pp 1–5
11. Aspri M, Tsagkatakis G, Tsakalides P (2020) Distributed training and inference of deep learning
models for multi-modal land cover classiﬁcation. Rem Sens
12. Venkatesan NJ, Nam CS, Shin DR (2018) Deep learning frameworks on apache spark: a review.
IETE Tech Rev
13. Lecun Y, Bottou L, Bengio Y, Haffner P (1998) Gradient-based learning applied to document
recognition. Proc IEEE 86(11):2278–2324
14. Nguyen TQ, Weitekamp D, Anderson D, Castello R, Cerri O, Pierini M et al (2019) Topology
classiﬁcation with deep learning to improve real-time event selection at the LHC. Comput
Softw Big Sci 3(1):1–14
15. Jonnalagadda VS, Srikanth P, Thumati K, Nallamala SH, Dist K (2016) A review study of
apache spark in big data processing. Int J Comput Sci Trends Technol (IJCST) 4(3):93–98
16. Fiter˘au-Bro¸steanP,LenaertsT,PollE,deRuiterJ,VaandragerF,VerlegP(2017)Modellearning
and model checking of SSH implementations. In: Proceedings of the 24th ACM SIGSOFT
international SPIN symposium on model checking of software (SPIN 2017). Association for
Computing Machinery, New York, NY, USA, pp 142–151
17. Dai JJ, Wang Y, Qiu X, Ding D, Zhang Y, Wang Y et al (2019, November) Bigdl: a distributed
deep learning framework for big data. In: Proceedings of the ACM symposium on cloud
computing, pp 50–60
18. Aftab MO, Awan MJ, Khalid S, Javed R, Shabir H (2021, April) Executing spark BigDL for
leukemia detection from microscopic images using transfer learning. In: 2021 1st international
conference on artiﬁcial intelligence and data analytics (CAIDA). IEEE, pp 216–220
19. Borthakur D (2008) HDFS architecture guide. Hadoop Apache Project 53(1–13):2

Distributed Training of Large-Scale Deep Learning Models …
721
20. Jain M (2018) Advanced techniques in shell scripting. In: Beginning modern unix. Apress,
Berkeley, CA, pp 283–312
21. Liashchynskyi P, Liashchynskyi P (2019) Grid search, random search, genetic algorithm: a big
comparison for NAS

Blockchain-Driven Cloud Service:
A Survey
Hamed Taherdoost
Abstract Cloud services run centrally and store data before making it available to
customersthroughsoftwareanduselargeservers.Whenemployingthesecentralized-
based methods, organizations often have to make compromises in the areas of autho-
rization, privacy, and security. Due to the fact that once data is recorded, it cannot
be amended without also affecting the data in all preceding blocks, blockchains may
restrict the modiﬁcation of any data in any of the blocks. The key beneﬁt of integrating
blockchain into cloud services is increased data security. When cloud services and
blockchain are merged, it is like having the best of both worlds in one convenient
package. Cloud services powered by blockchain will be covered in this survey, along
with their uses, difﬁculties, and prospects for the future.
Keywords Blockchain · Cloud service · Cloud computing · Security · Privacy
1
Introduction
Large servers are used in cloud services, which operate in a centralized manner
and store data before making it accessible to users via software [1]. Organizations
often have to compromise on authorization, privacy, and security when using these
centralized-based approaches [2]. Because the information stored may be accessed
by anyone, even unlawfully by hackers and viruses, cloud services often lack trust
and frequently result in the data leakage of particularly sensitive information [3].
Cloud architecture is how technological components combine to form a cloud, in
which resources are pooled and shared through virtualization technologies and a
network [4].
A blockchain is an ever-expanding, linked list-like structure of data that comprises
blocks connected by links and saved via encryption [5]. Each “block” on a blockchain
has a timestamp, a cryptographic hash of the prior block, and data relevant to a
H. Taherdoost (B)
Departement of Arts, Communications and Social Sciences, University Canada West (UCW),
Vancouver, Canada
e-mail: hamed.taherdoost@gmail.com
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_53
723

724
H. Taherdoost
speciﬁc transaction [5, 6]. Since each block contains a link to and information about
its predecessor, the previous block cannot be edited or destroyed [7]. Once data is
stored in a block, it cannot be modiﬁed without also modifying the data in every
block before it [8].
Increasing data security is one of the main advantages of using blockchain tech-
nology in cloud services [9, 10]. It is like getting the best of both worlds in a single
package when blockchain technology and cloud services are combined. This survey
will include cloud services powered by blockchain from applications to challenges
and future perspectives.
2
Using Blockchain Technology in Cloud Services: The
Range of Applications
Due to its unique characteristics, the blockchain system might signiﬁcantly enhance
functionality or performance. As a decentralized system, blockchain could be of great
assistance in developing an architecture in which multiple computers can operate
concurrently on a single task, such as data processing or storage, thereby reducing
the total duration of the operation and accelerating data processing and uploading
[11].
In addition, the security of cloud services has increased. As cloud services often
manage vast quantities of data, there is always a danger of data compromise. In
addition, since cloud services depend on a centralized design, hackers may breach
the central server, causing the whole system to fail with no backup of any lost data.
Therefore, there is the possibility of implementing blockchain in cloud services to
overcome these issues (Fig. 1). Table 1 provides examples of some relevant research
that were released in 2022. In the following domains, blockchain can surpass existing
cloud solutions:
• Higher Data Security: Internet of Things (IoT) data kept in the cloud is frequently
associated with the homeowner’s personal information, including personal habits,
real estate, household products, voice recordings, and video footage. Leaks of
sensitive data may compromise personal security by facilitating thefts, assaults,
and the illicit selling of personal information for monetary gain [12]. In light
of these conditions, the cloud infrastructure is in jeopardy. The solution to this
problem is the use of blockchain in cloud services, which may increase the security
of the whole architecture.
• Scalability: Large-scale blockchain applications may subject blockchain
networks to extraordinarily high transaction volumes. To offer scalable blockchain
systems, it is essential to have robust data processing services with fast transac-
tion execution speeds. In this sector, the cloud may deliver on-demand services
to blockchain operations due to its scalability possibilities. In other words,
integrating blockchain with cloud services may result in a very scalable solution.

Blockchain-Driven Cloud Service: A Survey
725
Fig. 1 Beneﬁts of blockchain-powered cloud services
Table 1 Some related studies were published in 2022
System
Feature
References
Blockchain-based multi-cloud
searchable encryption scheme
High performance and security
[13]
Platform for integrated cloud services in
the energy market
Energy trading’s simplicity and security,
as well as energy delivery’s
effectiveness and intelligence
[14]
Novel service-level agreement paradigm
based on blockchain and smart contracts
Data security
[15]
Blockchain- and cloud service-based
smart home
Good applicability
[16]
• More Effective Goods and Service Ownership Tracking: The logistics industry
has a basic challenge in regularly keeping track of all the vehicles in its network,
their current locations, theamount of timeeachvehiclespends at acertainlocation,
and how to establish communication between many vehicles. Similar to complete
testing for packages, software products face challenges due to their centralized
architecture. Blockchain has considerable potential for monitoring these goods
and services.
• Decentralization: The dependence on a single server for managing data and
decision-making is a basic concern with cloud services and IoT. A central server
failure, for instance, could disrupt the whole system and lead to the loss of vital
data stored on the server. Additionally, the primary server is subject to hacker
assaults. The blockchain may offer a solution to this problem since it employs
a decentralized design that precludes the failure of the whole system if a single
server goes down by keeping several copies of identical data on many computer

726
H. Taherdoost
nodes. Additionally, data loss is not a concern since there are several versions of
the data on separate nodes.
• Tolerance for Faults: It may help with fault tolerance if blockchain data is repli-
cated in the cloud over a network of computers that are tightly connected through
collaborative clouds. As a consequence, there will be less chance of a single
failure brought on by the disruption of any cloud node, allowing for uninterrupted
services.
3
Challenges and Future Direction
The cloud services model varies from centralized data centers in terms of security
issues. The cloud offers some advantages over conventional data centers, but it also
has several disadvantages, including user administration and device management.
Combining blockchain technology with the cloud services idea may increase cloud
services security. The cloud platform improves scalability and extensive analysis.
Cloud service might become more dependable and safe thanks to blockchain tech-
nology. The computational power and storage capabilities of cloud services can meet
the needs of the blockchain. In the context of cloud services, several blockchain secu-
rity services are being categorized and debated. Blockchain and cloud services may
combine their strengths to get beyond the most frequent obstacles. Study limitations
include high hardware needs and extreme energy usage. Additionally, the transaction
takes up a lot of time. This is a serious issue that has to be addressed. The mining
industry may beneﬁt from increased revenue due to more efﬁcient currency creation,
but blockchain adoption may also accelerate as a result. Many businesses may reduce
their carbon footprints by integrating blockchain into all areas of the economy.
In today’s business context, a heavy reliance on the cloud and associated risks
may be risky and harmful [17]. The cloud’s centralized, compliant, and secure nature
poses a serious risk. Blockchain technology is used to enhance data storage security,
transaction speed, reliability, and corporate processes. One of the best courses of
action is to combine blockchain with cloud services since it offers more security
and decentralization while enabling better authorization and privacy [18]. As the
blockchain confronts new problems in the future, such as more security and data
storage at every node, it will be required to keep working on these challenges [19].
When it comes to protecting their data, which is essential to their capacity to function
and make decisions in today’s world of constant competition, organizations may
beneﬁt from research on how to employ this combination.
4
Conclusion
In conclusion, blockchain may be very advantageous for cloud services. It is a useful
technique for providing security and privacy in a cloud setting. Thanks to technology,

Blockchain-Driven Cloud Service: A Survey
727
the cost of acquiring cloud resources might be reduced. It also offers a platform
for individuals to develop trust with one another. This poll addressed blockchain-
powered cloud services, as well as their beneﬁts for better data security, scalability,
tracking the ownership of products and services, decentralization, and fault toler-
ance. Various blockchain security services are being classiﬁed and discussed in the
context of cloud services. Blockchain technology and cloud services could combine
to solve the most frequent problems. It will be necessary to continue working on
these difﬁculties when the blockchain faces additional issues in the future, such as
increased security and data storage at every node. Organizations may proﬁt from a
study on how to use this combination when it comes to preserving their data, which
is crucial to their ability to operate and make choices in today’s world of continual
competition.
References
1. Shawish A, Salama M (2014) Cloud computing: paradigms and technologies. Inter-cooperative
Collective Intelligence: Techniques and Applications. Springer, pp 39–67
2. Taherdoost H (2022) Understanding cybersecurity frameworks and information security
standards—a review and comprehensive overview. Electronics 11(14):2181
3. Barona R, Anita EM (2017) A survey on data breach challenges in cloud computing secu-
rity: issues and threats. In: 2017 international conference on circuit, power and computing
technologies (ICCPCT). IEEE
4. Ibrahim AS, Hamlyn-Harris J, Grundy J (2016) Emerging security challenges of cloud virtual
infrastructure. arXiv preprint arXiv:1612.09059
5. Pahlajani S, Kshirsagar A, Pachghare V (2019) Survey on private blockchain consensus algo-
rithms. In: 2019 1st international conference on innovations in information and communication
technology (ICIICT). IEEE
6. Krishnapriya S, Sarath G (2020) Securing land registration using blockchain. Procedia Comput
Sci 171:1708–1715
7. TaherdoostH(2022)Blockchaintechnologyandartiﬁcialintelligencetogether:acriticalreview
on applications. Appl Sci 12(24):12948
8. Hanifatunnisa R, Rahardjo B (2017) Blockchain based e-voting recording system design. In:
2017 11th international conference on telecommunication systems services and applications
(TSSA). IEEE
9. Esposito C et al (2018) Blockchain: a panacea for healthcare cloud-based data security and
privacy? IEEE Cloud Comput 5(1):31–37
10. Taherdoost H (2022) A critical review of blockchain acceptance models—blockchain tech-
nology adoption frameworks and applications. Computers 11(2):24
11. Moosavi N, Taherdoost H (2022) Blockchain-enabled network for 6G wireless communication
systems.In:Internationalconferenceonintelligentcyberphysicalsystemsandinternetofthings
(ICoICI 2022), Engineering Cyber-Physical Systems and Critical Infrastructures, Coimbatore,
India. Springer
12. Moosavi N, Taherdoost H (2022) Blockchain and internet of things (IoT): a disruptive inte-
gration. In: 2nd international conference on emerging technologies and intelligent systems
(ICETIS 2022). Lecture notes in networks and systems. Springer: virtual conference
13. Fu S, Zhang C, Ao W (2022) Searchable encryption scheme for multiple cloud storage using
double-layer blockchain. Concurrency Comput Prac Exp 34(16):e5860
14. Wang L et al (2022) Design of integrated energy market cloud service platform based on
blockchain smart contract. Int J Electr Power Energ Syst 135:107515

728
H. Taherdoost
15. Tan W et al (2022) A novel service level agreement model using blockchain and smart contract
for cloud manufacturing in industry 4.0. Enterprise Inform Syst 16(12):1939426
16. Liao K (2022) Design of the secure smart home system based on the blockchain and cloud
service. Wirel Commun Mob Comput 2022
17. Taherdoost H (2021) A review on risk management in information systems: risk policy, control
and fraud detection. Electronics 10(24):3065
18. Gong J, Navimipour NJ (2021) An in-depth and systematic literature review on the blockchain-
based approaches for cloud computing. Cluster Comput 2021:1–18
19. Peng L et al (2021) Privacy preservation in permissionless blockchain: a survey. Dig Commun
Netw 7(3):295–307

Interaction Analysis of a Multivariable
Process in a Manufacturing
industry—A Review
P. K. Juneja, T. Anand, P. Saini, Rajeev Gupta, F. S. Gill, and S. Sunori
Abstract It is important to perform interaction analysis in case of multivariable
(MV) control system to determine the best loop pairing recommendation. Non-
desirable couplings can be decreased with the help of incorporation of suitable
decouplers designed but only after determining suitable loop pairing. The present
work extensively reviews the literature survey pertaining to the interaction anal-
ysis and loop pairing recommendation in a multivariable control system. Multivari-
able interaction techniques like relative gain array (RGA), effective RGA (ERGA),
dynamicRGA(DRGA),inputrelativegainarray(IRGA),normalizedRGA(NRGA),
normalized effective RGA (NERGA), relative omega array (ROmA), etc. and their
applications in various industrial processes are highlighted in brief.
Keywords MIMO · RGA · Interaction analysis · Loop pairing · Process control
P. K. Juneja
Department of Electronics and Communication Engineering, Graphic Era Deemed to be
University, Dehradun, Uttarakhand, India
T. Anand
Department of PDP, Graphic Era Deemed to be University, Dehradun, Uttarakhand, India
P. Saini (B)
Department of Electrical Engineering, Graphic Era Deemed to be University, Dehradun,
Uttarakhand, India
e-mail: parvesh.saini.eee@gmail.com
R. Gupta
Department of Electronics and Communication Engineering, Graphic Era Hill University,
Dehradun, Uttarakhand, India
F. S. Gill
Department of Physics, Graphic Era Deemed to be University, Dehradun, Uttarakhand, India
S. Sunori
Department of Electronics and Communication Engineering, Graphic Era Hill University,
Bhimtal, Uttarakhand, India
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_54
729

730
P. K. Juneja et al.
Fig. 1 Block representation
of a MIMO system [1]
1
Introduction
Process industries mostly have multivariable process along with undesirable cross-
couplings. The performance of the multi-input multi-output (MIMO) process is
affected because of these interactions. A good process control is required in these
process industries to increase product rate and enhance product quality along with
less energy consumption and less release of pollutant by-products in the form of ﬂue
gases.
This requires proﬁcient design of equipment, process optimization, application of
recovery and recycling techniques, and appropriate control system design. A typical
MIMO system is represented in Fig. 1.
2
Literature Review
Lieslehto and Koivo [1] demonstrated the expert system pertaining to loop pairing
analysis of linear multivariable (MV) process. Feng and Grimble [2] proposed a
new performance index for transient and steady state that improves stability and
robustness of the selected linear MV system. Luan et al. [3] investigated RNGA
index for complex MV systems subjected to step and ramp inputs. Also, average
residence time is calculated for complex process models.
Samuelsson et al. [4] compared RGA and HIIA for ﬁnding interactions in a
wastewater treatment plant. Liao et al. [5] presented a loop pairing method for multi-
variable process which provides more accuracy in comparison to RNGA method. Le
Brun et al. [6] implemented modeling of turboprop engine and applied decentralized
control design with full compensator on it.
Wang et al. [7] obtained the coupling degree inﬂuenced by ac induction motor
speed and demonstrated that with the increase of the motor speed, the degree of
coupling will increase too. Khaki-Sedigh and Moaveni [8] proposed a test for identi-
ﬁcation of variation in input–output pairing under parametric uncertainties’ presence.

Interaction Analysis of a Multivariable Process in a Manufacturing …
731
Jiang et al. [9] presented DRGA technique based on state feedback predictive control
(SFPC).
Liang et al. [10] developed a DRGA method to select an input for a particular
output in model order reduction (MOR) process. In DRGA method, steady state
and transient responses are involved in the process of loop pairing. In case of RLC
networks, DRGA-based MOR technique is more accurate in comparison to classical
MOR methods. Hofmann et al. [11] considered a biomass pyrolysis process and used
RGA, DRGA, and singular value analysis (SVA) for interaction analysis for system
with unmeasurable disturbances or dead time. Chen et al. [12] studied deviations
in properties (open-loop) under modeling uncertainties. An example is constructed
to show that it is difﬁcult to control plants having large values of condition number
(CN) and RGA.
Zhang et al. [13] introduced an IRGA to the design of Tornambe’s controller to ﬁnd
a proper match between the inputs and outputs. Komathi et al. [14] considered a four-
tank system and applied RGA method and decoupling control. Hu et al. [15] proposed
atechniquetoovercomelimitationsofclassicaltechniquesforamultivariableprocess
containing differentiators or integrators or both.
He et al. [16] studied coupling in a maglev bogie using ERGA and validated it
experimentally. Tsai et al. [17] presented a predictive proportional integrator temper-
ature control using PSO technique for molding modules in semiconductor die pack-
aging machines. Moezzi et al. [18] introduced NERGA and applied in an adaptive
decentralized PID control technique.
Juneja et al. [19] presented a systematic steps pertaining to multivariable control
system analysis through the ﬂowchart. Muntean et al. [20] showed that applying
RGA analysis for a ﬁrst principle model, a decentralized control strategy using PI
controllerscanbeeasilydeveloped.FatehiandShariati[21]introducedNRGAmatrix
and emphasized that pairing problem is similar to an assignment problem.
Avvalabadi and Shahmansourian [22] presented a new easy-to-interpret strategy
which gives suitable pairing recommendations. Choobkar et al. [23] applied
minimum variance (MV) index for loop pairing. Balestrino and Landi [24] presented
ROmA which retains the simplicity of RGA but includes dynamic interactions.
Braccia and Zumoffen [25] suggested technique which utilizes RGA approach
within a deterministic MILP formulation. Bristol et al. [26] presented results
concerning dynamic effects, relating decoupling, and optimal control. Hofman et al.
[27] applied participation matrix for pairing recommendation of the falling evapo-
rator process. Balestrino et al. [28] addressed the problem of pairing for a nonlinear
and time-varying system. ARGA is proposed for solving both integrity problems.
Table 1 shows the literature review in tabulated form.
3
Conclusion
The present literature review covers the important aspects in any manufacturing
industry relevant to interaction analysis of various variables in a multivariable

732
P. K. Juneja et al.
Table 1 Literature review
S. No
Authors and year
System
selected/developed
Analysis
1
J. Lieslehto and H. N.
Koivo, 1987
LTIVMV
IA
2
W. Feng and M. J. Grimble,
1989
Ss response and transient
response of stable and
robust system
Proposed performance
interaction measure
3
X. Luan, Q. Chen and F.
Liu, 2017
Non-square processes
RNGA
Relative normalized gain
array
4
P. Samuelsson et al., 2005
Wastewater treatment
plant
RGA and HIIA
5
Q. -F. Liao et al., 2013
Type-2T-S fuzzy models
RNGA
6
C. Le Brun et al., 2015
Turboprop engine
Coupling analysis and
decentralized control
7
B. Wang, Q. Zhu, H. Zang,
S. Kou and J. Ke, 2018
AC induction motor
Coupling degree inﬂuence
by motor speed calculation
8
A. Khaki-Sedigh and B.
Moaveni, 2003
Uncertain multivariable
plants
RGA
9
H. Jiang et al., 2012
MV case study
DRGA
10
W. Liang et al., 2020
RLC networks
DRGA, MOR
11
J. Hofmann et al., 2019
Biomass pyrolysis process
RGA, DRGA, SVA
12
J. Chen et al., 1992
Example model
RGA, condition number
13
Y. Zhang et al., 2011
Tornambe’s controller
IRGA
14
C. Komathi, S. Durgadevi,
K. Thirupura Sundari, K.
Abirami, and R.
Vidyathmikaa, 2021
Four-tank system
RGA
IMC
PSO-based decoupling
SCADA
15
W. Hu et al., 2010
MIMO process containing
integrators and/or
differentiators
Proposed new method
16
G. He et al., 2013
Maglev bogie linearized
model
ERGA
17
C. C. Tsai et al., 2017
Molding process in
semiconductor die
packaging machine
PSO-RGA
18
M. A. Moezzi et al
High-dimensional system
NERGA
19
P. Juneja et al
MV system
RGA, NI, MRI
20
I. Muntean et al., 2015
Wastewater treatment
plant
RGA
21
A. Fatehi and A. Shariati
MIMO plant
NRGA
(continued)

Interaction Analysis of a Multivariable Process in a Manufacturing …
733
Table 1 (continued)
S. No
Authors and year
System
selected/developed
Analysis
22
A. Avvalabadi and A.
Shahmansourian
Several examples
Proposed method
23
S. Choobkar et al
MV system
RGA, minimum variance
(MV) index
24
A. Balestrino and A. Landi
Examples
ROmA
25
L. Braccia and D. Zumoffen Industrial process
RGA, mixed integer linear
programming
26
E. H. Bristol, 1977
Examples
RGA
27
J. Hofmann et al., 2021
Falling ﬁlm evaporator
process
Participation matrix and
HIIA
28
A. Balestrino et al., 2008
Examples
Absolute RGA
process. Review is exhaustive in nature, and it not only covers relative gain array
(the commonly used interaction measuring index) but also includes all the updated,
hybrid, modiﬁed, or proposed interaction index.
References
1. Lieslehto J, Koivo HN (1987) An expert system for ınteraction analysis of multivariable
systems. In: 1987 American control conference, pp 961–962
2. Feng W, Grimble MJ (1989) A new procedure to account for performance ınteraction in multi-
variable systems. In: 1989 American control conference, pp 1280–1285. https://doi.org/10.
23919/ACC.1989.4790385
3. Luan X, Chen Q, Liu F (2017) Interaction measurement for complex multivariable models with
various reference inputs based on RNGA. In: 2017 11th Asian control conference (ASCC), pp
2411–2416. https://doi.org/10.1109/ASCC.2017.8287552
4. Samuelsson P, Halvarsson B, Carlsson B (2005) Interaction analysis and control structure
selection in a wastewater treatment plant model. IEEE Trans Control Syst Technol 13(6):955–
964. https://doi.org/10.1109/TCST.2005.854322
5. Liao Q-F, Cai W-J, Wang Y-Y (2013)Interaction analysis and loop pairing for MIMO processes
described by type-2 T-S fuzzy models. In: 2013 IEEE 8th conference on ındustrial electronics
and applications (ICIEA), pp 622–627. https://doi.org/10.1109/ICIEA.2013.6566443
6. Le Brun C, Godoy E, Beauvois D, Liacu B, Noguera R (2015) Coupling analysis and control of a
turboprop engine. In: 2015 12th ınternational conference on ınformatics in control, automation
and robotics (ICINCO), pp 420–427
7. Wang B, Zhu Q, Zang H, Kou S, Ke J (2018) Coupling analysis of AC motors based on relative
gain array. In: 2018 IEEE 3rd advanced ınformation technology, electronic and automation
control conference (IAEAC), pp 2473–2476. https://doi.org/10.1109/IAEAC.2018.8577826
8. Khaki-Sedigh A, Moaveni B (2003) Relative gain array analysis of uncertain multivariable
plants. In: 2003 European control conference (ECC), pp 2862–2866. https://doi.org/10.23919/
ECC.2003.7086474

734
P. K. Juneja et al.
9. Jiang H, Wei M, Xu F, Luo X (2012) A dynamic relative gain array based on model predictive
control. In: Proceedings of the 10th world congress on ıntelligent control and automation, pp
3340–3344. https://doi.org/10.1109/WCICA.2012.6358450
10. Liang W, Chen H-B, He G, Chen J (2020) Model order reduction based on dynamic relative
gain array for MIMO systems. IEEE Trans Circ Syst II Ex Briefs 67(11):2507–2511. https://
doi.org/10.1109/TCSII.2019.2962709
11. Hofmann J, Holz H-C, Gröll L (2019) Relative gain array and singular value analysis to ımprove
the control in a biomass pyrolysis process. In: 2019 IEEE 15th ınternational conference on
control and automation (ICCA), pp 596–603. https://doi.org/10.1109/ICCA.2019.8900025
12. Chen J, Freudenberg JS, Nett CN (1992) On relative gain array and condition number. In:
Proceedings of the 31st IEEE conference on decision and control, vol 1, pp 219–224. https://
doi.org/10.1109/CDC.1992.371751
13. Zhang Y, Li D, Lao D (2011) IRGA for MIMO systems based on TC. In: Proceedings of the
30th Chinese control conference, pp 3803–3808
14. Komathi C, Durgadevi S, Thirupura Sundari K, Abirami K, Vidyathmikaa R (2021) RGA
analysis and hardware ımplementation of PSO based decoupled mimo system. In: 2021 4th
ınternational conference on computing and communications technologies (ICCCT), pp 448–
452. https://doi.org/10.1109/ICCCT53315.2021.9711818
15. Hu W, Cai W-J, Xiao G (2010) Relative gain array for MIMO processes containing integrators
and/or differentiators. In: 2010 11th ınternational conference on control automation robotics
and vision, pp 231–235. https://doi.org/10.1109/ICARCV.2010.5707220
16. He G, Li J, Li Y, Cui P (2013) Interactions analysis in the maglev bogie with decentralized
controllers using an effective relative gain array measure. In: 2013 10th IEEE ınternational
conference on control and automation (ICCA), pp 1070–1075. https://doi.org/10.1109/ICCA.
2013.6564922
17. Tsai C-C, Tai F-C, Liu R-S (2017) Intelligent predictive temperature control using PSO-RGA
for transfer mold heating processes in semiconductor die packaging machines. In: 2017 ınter-
national conference on system science and engineering (ICSSE), pp 510–514. https://doi.org/
10.1109/ICSSE.2017.8030926
18. Moezzi M-A, Fatehi A, Nekoui MA (2008) A novel automatic method for multivariable process
pairing and control. In: 2008 annual IEEE India conference, pp 262–267. https://doi.org/10.
1109/INDCON.2008.4768837
19. JunejaP,SharmaA,JoshiV,PathakH,SunoriSK,SharmaA(2020)Delayedcomplexmultivari-
able constrained process control—a review. In: 2020 2nd ınternational conference on advances
in computing, communication control and networking (ICACCCN), pp 569–573. https://doi.
org/10.1109/ICACCCN51052.2020.9362800
20. Muntean I, Both R, Crisan R, Nascu I (2015) RGA analysis and decentralized control for a
wastewater treatment plant. In: 2015 IEEE ınternational conference on ındustrial technology
(ICIT), pp 453–458. https://doi.org/10.1109/ICIT.2015.7125140
21. Fatehi A, Shariati A (2007) Automatic pairing of MIMO plants using normalized RGA. In:
2007 mediterranean conference on control and automation, pp 1–6. https://doi.org/10.1109/
MED.2007.4433929
22. Avvalabadi A, Shahmansourian A (2014) A new mathematical approach for input-output
pairing in MIMO square systems. In: 2014 22nd Iranian conference on electrical engineering
(ICEE), pp 1244–1247. https://doi.org/10.1109/IranianCEE.2014.6999725
23. Choobkar S, Khaki Sedigh A, Fatehi A (2010) Input-output pairing based on the control perfor-
mance assessment index. In: 2010 2nd ınternational conference on advanced computer control,
pp 492–496. https://doi.org/10.1109/ICACC.2010.5486691
24. Balestrino A, Landi A (2007) ROmA loop pairing criteria for multivariable processes. In: 2007
European control conference (ECC), pp 4765–4771. https://doi.org/10.23919/ECC.2007.706
8387
25. Braccia L, Zumoffen D (2015) The input-output pairing problem: an optimization based
approach. In: 2015 XVI workshop on ınformation processing and control (RPIC), pp 1–6.
https://doi.org/10.1109/RPIC.2015.7497058

Interaction Analysis of a Multivariable Process in a Manufacturing …
735
26. Bristol EH (1977) RGA 1977: dynamic effects of interaction. In: 1977 IEEE conference on
decision and control including the 16th symposium on adaptive processes and a special sympo-
sium on fuzzy set theory and applications, pp 1096–1100. https://doi.org/10.1109/CDC.1977.
271734
27. Hofmann J, Gröll L, Hagenmeyer V (2021) Control loop pairing and ınteraction analyses of
the falling ﬁlm evaporator process. In: 2021 23rd ınternational conference on process control
(PC), pp 186–193. https://doi.org/10.1109/PC52310.2021.9447487
28. Balestrino A, Crisostomi E, Landi A, Menicagli A (2008) ARGA loop pairing criteria for
multivariable systems. In: 2008 47th IEEE conference on decision and control, pp 5668–5673.
https://doi.org/10.1109/CDC.2008.4738840

Machine Learning Approaches
for Educational Data Mining
Mahesh Bapusaheb Toradmal, Mita Mehta
, and Smita Mehendale
Abstract Educational data mining (EDM) has enhanced one of the essential ﬁelds
nowadays because, with technology improvement, students’ difﬁculties are also
expanding. To grab these difﬁculties and encourage students, educational data mining
has come into continuation. Educational data mining is the process to evaluate the
student’s academic performance. Learning analytics apply machine learning tech-
niques to have better and accurate interpretation out of it. Several researchers used
it as a prediction system to predict student performance. This article focuses on
various techniques used in EDM for classiﬁcation and analysing of this data to build
strong recommendation system. Numerous machine learning algorithm has used in
different existing systems and predicts the classiﬁcation accordingly. Moreover, it
also analysed the challenges identiﬁed when EDM deals with large datasets. In this
discussion, we evaluate the few algorithms and tried to propose new methodology
to generate better classiﬁcation and recommendation.
Keywords Educational data mining · Web mining · Machine learning · Data
pre-processing · Feature extraction
1
Introduction
Education data mining as a research topic is still ‘young’. Past studies have shown
the signiﬁcant potential in the topic from various parts of the world. Various aspects
of education related gaps like curriculum design, time management of the course,
students behavioural, and learning pattern can be analysed using educational data
mining concept. Every change in educational environment and in its delivery methods
M. B. Toradmal · M. Mehta (B)
Symbiosis Institute of Business Management - Pune, Symbiosis International (Deemed
University), Pune, India
e-mail: mitamehta@sibmpune.edu.in
S. Mehendale
Symbiosis Institute of Management Studies, Symbiosis International (Deemed University), Pune,
India
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_55
737

738
M. B. Toradmal et al.
is focused on providing better education quality to learners. Appropriate knowledge
is required for teaching institution to evaluate and enhance the learning process.
Students are considered the critical assets rather than liability of any institution.
Studentistheproductwhichinstitutesproduce.Theroleofmeasuringandforecasting
students’ potential to succeed in life is part of the quality improvement of learning
processes.
The unpredictable processing of academic knowledge is one of the enormous
absolutes of higher educational frameworks. Every higher educational institution’s
primaryaimistoimprovetheessenceoforganizationaldecisionsandprovidetraining
programmes. One path to achieving the highest proﬁt in the advanced education
system is a reasonable forecast of understudy’s accomplishment in secondary educa-
tion organizations. It is of extraordinary talent to the higher learning administrators
to predict the execution of an assistant. It is a testing activity to predict the imple-
mentation of both the accomplices. Specialized schools are productive because they
have digniﬁed understudies and employees and a measure certiﬁcation system that
continuously improves them.
In the open-source software Weka 3.8 setting, this work evaluates EDM classiﬁca-
tionondifferentsyntheticdatasets.Thedataminingmethodofinformationdisclosure
is carried out. As the Weka tool setting for information analysis, WEKA is extended.
For online information mining operations, it is an aggregation of machine learning
necessary calculations. System can either connect the calculations-based straight-
forward to a dataset or call them from a Java code. The WEKA tool contains functions
such as Data Pre-processing, Grouping, Regression, Clustering, Correlation.
2
Literature Review
There are already various attempts by academics and authorities to mine students’
information, hence the need to use the dimensionality of data in educational repos-
itories for improved delivery of education institutions. Improvement is continuous
process and for which we require continuous data mining as culture to see changes
in trend of how students learn things and gain information. Purpose of this study is
to study existing data mining methods used for EDM and see which one we could
adopt for our ﬁeld study further.
Krishna et al. [1] proposed tree logistic regression method of EDM with the help
of statistics from a Moodle-based cohesive learning course to develop a module for
the students which could predict performance. It uses credentials and regression trees
(CART) decision [2] tree algorithm to prediction students at risk in early stage. This is
based on the inﬂuence of four online actions and behaviours like sharing of message,
development of some web-based content, opening course ﬁles, and conducting some
quiz online. In other study by Juan et al. [3] where author used machine learning
methods and approach as one of the EDM technique to predict student’s success
based on raw data collected. Supervised learning techniques were used to predict
student’s behaviour to generate more precise and reliable results. Unambiguously,

Machine Learning Approaches for Educational Data Mining
739
the authors used the support vector machine (SVM) algorithm to produce reliable
predictions. Apart from SVM other algorithms like decision tree (DT), Naïve Bytes
(NB), and random forest (RF) were also well explored in this study.
Different techniques used in EDM already helped to improve student experience.
One of the studies conducted by Cen et al. [4] in which award-winning mobile
education programme developed as outcome programme. It was designed for the
students studying in high school for their chemistry subject. This introduced new
know-how to help the students understand complex concepts in chemistry like molec-
ular studies in better way. Use of interactive 3D simulation and visuals are used to
improve learning experience of students while studying chemical reactions. This
is also one kind of outcome of how we could use educational data to build better
learning experience for students. Another study carried out by Chaki et al. [5] in
which data collected from student’s inputs for improvement of teaching strategy from
speciﬁc teachers. Data was more focused on teacher’s teaching attitude and skills.
This was conducted to improve decision-making quality improvement of teaching.
They proposed automated decision-making framework to improve teaching strategy.
Study was conducted by Tsiakmaki et al. [6] around students from higher educa-
tion level. In this study, author used deep neural networks to examine the learning
of student’s success. This study is important step in the ﬁeld of EDM. It is reusing
the pre-trained model for new tasks. We call it as transfer learning (TR) in machine
learning methods.
Arorra et al. [7] in her study used both linear and logistic regression as EDM
techniques to predict educational performance. This study performed two distinct
investigations using these regressions. This study was conducted on the data collected
from Delhi university college students. This was real-time dataset to predict the
performance of the individual students. Proposed system in this study acquires 71
and 85% classiﬁcation accuracy.
Babu et al. [8], this study used higher secondary score, intellectual quotient (IQ),
and emotional quotient (EQ) levels of students as a data to predict their academic
success by using modern algorithms. Experiment setup was asking students to enter
their marks in system and appear for IQ and EQ tests with certain psychologist’s
guidance. Prediction model was formed in binary format. It predicts either student
will pass or fail.
Agustianto and Destarianto [9], this study focused on class misbalancing problem
and proposed some balancing methods. This study driven on sampling sizes like the
cycle of balancing is divided into three methods: under sampling, oversampling,
and oversampling and under sampling combination. The method also focuses on
integrating the educational data using the neighbourhood cleaning code (NCL) under
sampling methodology to achieve correct student modelling. Data that are under
sampled using NCL was then categorized using the C4.5 algorithm for the decision
tree.
Ajibade et al. [10], heuristic function used in this study for student performance
assessment. Purpose of study is to test the performance of students using a heuristic
technique called as differential evolution for feature selection algorithms. In this
participant, dataset used along with other feature selection algorithms that were never

740
M. B. Toradmal et al.
used before. Classiﬁcation methods such as NB, DT, K-nearest neighbour (KNN),
and discriminant analysis (DISC) have also been used for evaluation purpose in this
study as EDM techniques.
Al-Omar et al. [11] explore the usability of the LMS at King Abdulaziz University
using certain predeﬁned usability criteria, such as a questionnaire on device usability
scale (SUS). Another research used data mining techniques (sentiment analysis and
clustering) to ﬁnd out the speciﬁcs of any usability problems.
Baker [12], this researched done research in the ﬁeld of EDM since from 1995.
In his study, he explained different challenges in it. This article discusses about how
to eliminate the bugs from traditional data mining approaches.
These all studies conducted gives idea that there are many ways of implementing
machine learning tools and techniques in EDM to predict the dependent variable
under study. Precision and accuracy of prediction are driven by how we train the
module and use the test data.
3
Methodologies
Literature review conducted shown that wide variety of EDM techniques has
appeared over the last numerous years. Unusual is like these observed in data mining
in different regions, whereas others are unusual to informative data mining. The
four essential aspects of processes that are in especially repeatedly use by the EDM
are forecast patterns, composition discovery, relationship mining, and discovery with
standards.EDM’simperativefactorsareinformativestakeholders,dataminingmech-
anisms and techniques, educational goals, acquiring setting and purpose, and how
these circumstances help realize full educational potential.
3.1
Classiﬁcation
It is the multiple usually applied data mining method. It is the process of supervised
learning that drafts data into various predeﬁned classes. The analysis notions have
been used for divining student attainment, achievement, experience, prophesying
student failure, and identifying uncertain student’s performance in EDM.
3.2
Clustering
It is the naming or classiﬁcation of object groups that are related. It aims to display
large databases to create useful assumptions for decision-making in the creation of
other relationships, correlations, or groups. The use of educational segmentation

Machine Learning Approaches for Educational Data Mining
741
is primarily intended to encourage the engagement of students in various learning
circumstances, to suggest services and programmes to users in a similar manner.
3.3
Statistics
Statistics is a mathematical framework that aims to use statistical methods to capture,
analyses, interpret, or demonstrates graphical results. It could be used to determine
different learning patterns required to direct teaching style creation using data from
the web existing owners for instructional design.
3.4
Prediction
It is a highly beneﬁcial in pushing forward in the educational system with new
technologies. It is a tool that forecasts, instead of a present state, a potential state.
This approach helps determine the success rate, fall-out, and maximum support of
students.
3.5
Association Rule Mining
The association rule is a unique process for a speciﬁc input vector to explore relation-
ships among variables and reference classes. In addition to making the courseware
most effective, it is used to discover the type of smart based on students’ features
and knowledge and skills. This, due to it, helps teachers evaluate students’ learning
habits and more effectively arrange the course content. It can also be used to facilitate
active learning, in addition to.
3.6
Regression
Regression is a forecasting tool used to evaluate the associations between the
predictor variable (speciﬁed ﬁeld) and one or more predictor variables and decide
how such associations can lead to entities’ educational goals.

742
M. B. Toradmal et al.
3.7
Sequential Pattern
The concurrent pattern is a data mining method used to classify the associations
among simultaneous occurrences, primarily to ﬁnd some order throughout such
incidents.
3.8
Text Mining
In various forms of both the web-based education system, this technique was success-
fully applied, often in group work, to provide automated process assessment that is
supposed to carry out even in comment threads. Machine learning may increase
educators’ ability to evaluate the progress of both the group discussion and promote
the process of generating instructional materials spent on user forum conversations.
3.9
Correlation
Correlation extraction is a test of the association of the two vectors of variables.
It would be used in the educational system to estimate the success of students
with regards to their ﬁnal examination score and experiences in online homework
mentoring, predict student progress in a university, deﬁne the main formative eval-
uation rules according to a speciﬁc learner’s web-based learning portfolios, and
construct designers will tell that provide a more realistic image of prerequisite skills.
3.10
Outlier Detection
Outlier testing is a process used from a broad dataset and identiﬁes the intended
curriculum or successful activities. New, new, odd conduct, unexpected, or noisy
responses can be original.
4
Proposed System Design
The open-source environment ‘WEKA 3.7’ has prepared the proposed implemen-
tation which is formally conducted, and intensive testing is performed to expose
mistakes and imperfections in the examiner suspension. Numerous validation exper-
iments are conducted thoroughly in the test condition. Several experiments may
be authorized to conﬁrm documentation, guiding, probability projections, disaster

Machine Learning Approaches for Educational Data Mining
743
retrieval, and demonstration relying on this system’s appropriate circumstances. The
test period ends with an examination to determine status to proceed to the application
state.
4.1
Data Collection
We created some questionnaire surveys by using Google Forms and some printing
material. We collected almost 300+ samples for student evaluation data for analysis
of proposed research.
4.2
Pre-processing and Normalization
For this stage, we will do data reduction and use techniques for example data
balancing, data minimization, and data cleaning to balance the data.
4.3
Extraction of Feature and Their Selection
In this progression, we will use balanced and normalized data to extract the various
feature from input data. We will use feature threshold to remove redundant as well
as worst features for training the module.
4.4
Module Training
In this process, we will use machine learning classiﬁer on extracted feature with the
module will focus on supervised learning approach.
4.5
Testing of Module
For this step, the individual instance process or may be entire test gets tested again to
get the accuracy of the data. In this phase, we will evaluate the efﬁcacy of the system
with the numerous datasets. This is to improve accuracy of module to do predictions
near to actuals.

744
M. B. Toradmal et al.
Fig. 1 Experiment design ﬂow
4.6
Prediction Analysis
Finally evaluate the arrangement accuracy of entire system using confusion metrics.
The dataset would be used to evaluate the proposed classiﬁcation system. The
qualities have considered based on standing like basic, intermediate and important,
etc. Below is the ﬂow of the overall experiment explaining how the overall experiment
will progress (Fig. 1).
5
Design of Experiment
For the proposed implementation of the original few progressive distribution tasks,
we become used Weka workbench environment. Investigations are handled in four

Machine Learning Approaches for Educational Data Mining
745
Fig. 2 EDM classiﬁcation accuracy of various machine learning algorithms
sequential measures. In measure one, attribute evaluation is implemented utilizing
the numerous managed distribution algorithms to interpret which attribute has the
several meaningful implied inﬂuence on each class in the dataset.
Various methods and procedures of DM are appropriately designed in entire exper-
imental analysis. The dataset is tested and analysed using multiple data classiﬁers,
which are J48 DT, MLP, NB, and ANN. A measurement of the correctness of all
algorithms is conducted during the execution process. It is determined that utilizing
the characteristic evaluation classiﬁcation on the dataset maintains system realiza-
tion. The essential attributes in the dataset are selected, then the suggested superior
algorithms are operated on the dataset (Fig. 2).
Different fascinating problem is perceived by the decisions, which show that the
number of taught courses determines an evaluation performance. Table 1 also desig-
nates that all sorting algorithms achieved lower prediction efﬁciency when operating
on a dataset ﬁle than those algorithms’ forecast accuracy of predicting dependant
variable under study while run on numerous cross-validation. By examining of all
classiﬁers, NB, SVM, and MLP algorithms implemented best among all classiﬁers
with efﬁciencies of throughout 85% for all validation tests.
Furthermore, we will do recognition, classiﬁcation, analysis, forecasting, and
identiﬁcation with the help of artiﬁcial intelligence. In Table 2, we demonstrate
some classiﬁcation results.
The present experiment highlights the numerous machine learning processes
presentation on large students’ data synthesized (Fig. 3).
FindingsshowthatBayesandartiﬁcialneuralnetwork(ANN)havereliabledataset
performance and predict robust prediction model. Authors argues that machine
learning application in context to reinforcement learning theory can augment the
learning processes effectively. Reinforcement learning theory can solve many prob-
lems across the ﬁeld be it manufacturing, supply chain, logistics, air control to swarm
intelligence. Present study supports the reinforcement learning theory concepts and
augmentation thereof by applying machine learning application through data mining
in education.

746
M. B. Toradmal et al.
Table 1 Existing methods
evaluation of EDM
Algorithms used
Accuracy (%)
J48, NB, MLP, SMO
83.0, 82.8, 83.5, 83.8
MOOC
81.16
KDD and RAD
80.2
C45, CART, NB
96.30, 92.60, 91.60
Neighbourhood cleaning rule
(NCL)
91.37
NB, DT, KNN
73.61, 81.94, 80.56
J48, C4.5, random tree and
REPTree
44.10
SVM, QDA, KNN, LR and RF
82.57
J48, decision tree, RT
85.60
NB, BN, ID3, J48, NN
93
NB, KNN, RF, NN, DT,
Xmeans
83.65
ID3, C4.5, KNN, NB
43.18
J48, REPTree, RT
62.30
LR, SVM
76.67
PNN, RF, DT, NB, TE, LR
89.15
LR, NN, ANN, RNN, DNN
80.20, 80.50, 80.63, 95.50
Table 2 Accuracy classiﬁcation of different machine learning algorithms in Weka state
Algorithm
Accuracy
Precision
Recall
F-score
SVM
0.93
0.94
0.95
0.95
ANN
0.92
0.91
0.89
0.9
Naïve Bayes
0.89
0.88
0.93
0.91
Random forest
0.87
0.86
0.92
0.89
J48
0.9
0.92
0.85
0.88
Fig. 3 Results of data classiﬁcation

Machine Learning Approaches for Educational Data Mining
747
6
Conclusion
Educational data mining is an important computational tool for producing recom-
mendations on educational practices. From the analysis, it can be concluded that both
Bayes and artiﬁcial neural network (ANN) have reliable dataset performance. The
ANN, furthermore, demonstrates greater consistency in results than in the Bayes
theorem. In ANN, precision improved as the hidden layers improved. The study
outcomes will help educational administrators recognize students at increased risk
of not qualifying early for corrections measures. A comparative analysis of various
architectures (NB, ANN, SVM, and J48) on data from participants to predict grad-
uate higher education students was carried out throughout the research. The ANN
and Bayes classiﬁcation are both appropriate architectures for dataset processing and
enhanced efﬁciency in RNN, DNN, etc. In the area of machine learning, researchers
have applied various set of data for different purpose [13]. Starting from health
sector to space the data mining tool is taking leap in the research world. Education
being one of the prominent sectors impacting overall other sector and skill measure-
ment aspect has greater advantage of applying machine learning applications [14].
Applying the data mining in this sector will be boom for predicting learning patten
[15] and related aspects of learning pattern across the disciplines. Future study can
be built based on the results produced by authors in this study. Empirical testing
using statical technique would render insightful outcomes.
References
1. Kumar M, Singh AJ (2019) Performance analysis of students using machine learning and data
mining approach. Int J Eng Adv Technol 8(3):75–79 (2019)
2. Patil JM, Gupta SR (2021) Extracting knowledge in large synthetic datasets using educational
data mining and machine learning models. Soft Comput Intell Syst 167–175. https://doi.org/
10.1007/978-981-16-1048-6_13
3. Rastrollo-Guerrero JL, Gomez-Pulido JA, Duran-Dominguez A (2020) Analyzing and
predicting students’ performance by means of machine learning: a review. Appl Sci 10(3):1042
4. Cen L, Ruta D, Qassem LMMSA, Ng J (2020) Augmented immersive reality (AIR) for
improved learning performance: a quantitative evaluation. IEEE Trans Learn Technol. https://
doi.org/10.1109/TLT.2019.2937525
5. Chaki PK, Sazal MMH, Barua B, Hossain MS, Mohammad KS (2019) An approach of teachers’
quality improvement by analyzing teaching evaluations data. In: 2019 second international
conference on advanced computational and communication paradigms (ICACCP). IEEE, pp
1–5
6. Tsiakmaki M, Kotsiopoulos GK, Kotsiantis S (2020) Transfer learning from deep neural
networks for predicting student performance. Appl Sci 10(6):2145. https://doi.org/10.3390/
app10062145
7. Arora S, Agarwal M, Kawatra R (2020) Prediction of educationist’s performance using regres-
sion model. In: 2020 7th international conference on computing for sustainable global devel-
opment (INDIACom). IEEE, pp 88–93. https://doi.org/10.23919/INDIACom49435.2020.908
3708

748
M. B. Toradmal et al.
8. Babu I, Siva Balan RV, Mathai PP (2019) Envisaging the academic performance of student.
In: 2019 international conference on computing, communication, and intelligent systems
(ICCCIS). IEEE, pp 90–94. https://doi.org/10.1109/ICCCIS48478.2019.8974531
9. Agustianto K, Destarianto P (2019) Imbalance data handling using neighborhood cleaning rule
(NCL) sampling method for precision student modeling. In: 2019 international conference on
computer science, information technology, and electrical engineering (ICOMITEE). IEEE
10. Ajibade S-SM, Ahmad NB, Shamsuddin SM (2019) A heuristic feature selection algorithm to
evaluate academic performance of students. In: 2019 IEEE 10th control and system graduate
research colloquium (ICSGRC). IEEE
11. Al-Omar K (2018) Evaluating the usability and learnability of the blackboard LMS using SUS
and data mining. In: 2018 second international conference on computing methodologies and
communication (ICCMC). IEEE
12. Baker RS (2019) Challenges for the future of educational data mining: the Baker learning
analytics prizes. JEDM J Educ Data Mining 11(1):1–17
13. SarkerIH(2021)Machinelearning:algorithms,real-worldapplicationsandresearchdirections.
SN Comput Sci 2. https://doi.org/10.1007/s42979-021-00592-x
14. Yousafzai BK, Hayat M, Afzal S (2020) Application of machine learning and data mining in
predicting the performance of intermediate and secondary education level student. Educ Inf
Technol 25:4677–4697. https://doi.org/10.1007/s10639-020-10189-1
15. Zhang Y, Yun Y, An R, Cui J, Dai H, Shang X (2021) Educational data mining techniques for
student performance prediction: method review and comparison analysis. Frontiers Psychol
12. https://doi.org/10.3389/fpsyg.2021.698490

Trafﬁc Surveillance and Vehicle
Detection YOLO and MobileNet-Based
ML Pipeline Transfer Learning
Rakhi Bharadwaj, Aditya Thombre, Umesh Patekar, Yash Gaikwad,
and Sushil Suri
Abstract In today’s complex and interconnected transportation ecosystem, real-
time vehicle sensing is critical for a complex and interconnected transportation
ecosystem built on advanced technology networks of intelligent systems spanning
a wide range of applications such as autonomous vehicles, trafﬁc monitoring, and
advanced driver assistance systems. This study utilizes machine learning approaches
to create a pipeline for vehicle identiﬁcation and classiﬁcation. Count the number of
cars in a frame and divide them into two categories: SUVs and sedans. This article
requires knowledge of machine learning fundamentals, deep learning, convolutional
networks, and transfer learning. In this paper the pipeline is broken down in order to
build and implement a computer vision pipeline.
Keywords MobileNet · Trafﬁc surveillance · Transfer learning · Trafﬁc
surveillance · Vehicle detection
1
Introduction
In recent years, video cameras are often used in trafﬁc surveillance systems as they
are an important source of trafﬁc ﬂow data. Rapid advances in computer vision,
computing, and camera technologies, as well as advances in automated video analysis
R. Bharadwaj (B) · A. Thombre · U. Patekar · Y. Gaikwad · S. Suri
Department of Computer Science, Vishwakarma Institute of Technology, Pune 411037, India
e-mail: rakhi.bharadwaj@vit.edu
A. Thombre
e-mail: aditya.thombre20@vit.edu
U. Patekar
e-mail: umesh.patekar21@vit.edu
Y. Gaikwad
e-mail: yash.gaikwad20@vit.edu
S. Suri
e-mail: sushil.suri20@vit.edu
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_56
749

750
R. Bharadwaj et al.
and processing, have increased interest in video-based trafﬁc surveillance applica-
tions. For intelligent transportation systems, the use of computer vision technology
for trafﬁc monitoring is becoming increasingly important. For incident detection,
behavior analysis, and comprehension, these systems leverage visual appearance in
vehicle identiﬁcation, recognition, and tracking. Additionally, it offers characteristics
for trafﬁc ﬂow, such as vehicle type, count, trajectory.
Even though there has been a lot of research done to enhance video-based
trafﬁc surveillance systems, there are still several problems with actual applica-
tions. In a recent assessment, the state-of-the-art networked and hierarchical surveil-
lance architecture for vehicles was described, along with a thorough examination of
unique computer vision difﬁculties. Contains a poll on vehicle recognition, tracking,
and on-road behavior analysis. A review of computer vision methods focused on
infrastructure-side urban trafﬁc analysis. The important concepts of computer vision
and pattern recognition have been addressed, along with a thorough explanation of
the technical difﬁculties and a comparison of the available solutions. This study
provides a thorough analysis of several video-based trafﬁc monitoring approaches
from a computer vision perspective. It includes several methods for detecting, identi-
fying, and tracking vehicles. Improvements and alterations are also discussed, along
with the beneﬁts and drawbacks.
2
Literature Review
This paper presents a study on a multi-camera system to block a speciﬁc section of
the road in order to analyze the trafﬁc situation in 3 sections. The second section is
a detailed review of the literature on multi-chamber systems. The third section here
is the proposed system using a two-chamber experimental setup with adjustments.
Deep neural networks are used in trafﬁc behavior analysis experiments. The focus
of this paper is the physical design, calibration, and advantages/disadvantages of
multi-chamber systems. In conclusion, future developments and improvements in
the ﬁeld of trafﬁc analysis using multi-camera systems are discussed [1].
In this paper, contemporary visual tracking emerges from the traditional math-
ematical approaches of neural networks as an active automated research area in
computer vision. In this study, a new modiﬁed neural network method is presented for
object detection and classiﬁcation of input images and videos from multiple cameras
with overlapping regions of interest. The modiﬁed neural network approach provides
a multilayer architecture as input, preprocessing, and manipulation layers to simplify
the processing required to prepare the neural networks for training. This strategy uses
predeﬁned tasks to delegate tasks to shifts, simplifying training, reducing compu-
tational requirements, and helping to deliver performance. Its two neural network
modules process the input. The ﬁrst module is a modiﬁed neural network, which
differs from traditional neural networks in the connections between neurons and
their tasks. It’s still a neural network that splits the data and shares thresholds to
show the difference. This means that there are markers between the two inputs and

Trafﬁc Surveillance and Vehicle Detection YOLO …
751
the simpliﬁed training. The second module is a conventional recognition and clas-
siﬁcation neural network that tracks recognized objects. In this paper, we propose a
system that provides composite images from the outputs of multiple cameras using
unconventional mathematical and algorithmic approaches [2].
This article introduces a system-wide reliable mechanism for real-time vehicle
detection. This approach combines the MOG2 background subtraction model (Gaus-
sian blend) with a modiﬁed SqueezeNet (H-SqueezeNet) model. Generate scale-
independent regions of interest (RoIs) using the MOG2 model from video frames.
H-SqueezeNet is provided for reliable vehicle classiﬁcation identiﬁcation. The effec-
tiveness of this method was validated using the CDnet2014 dataset, the UA-DETRAC
dataset and video footage from Suzhou Intersection. Test results show that this
approach can provide a high detection accuracy and average detection rate of 39.1
frames per second in a trafﬁc monitoring system [3].
This document refers to license plates in image or video collections as ALPR or
AutomaticLicensePlateRecognition(ALPR)(ANPR).ANPRtechnologyusesintel-
ligent transportation systems to minimize the need for human contact. The purpose
of this research is to ﬁnd an optimal license plate recognition algorithm. In this study,
we use four deep neural networks, including CNN, VGG16, VGG19, and YOLOV3,
to detect license plates, evaluate model accuracy, and select the best model. This
article refers to license plates in an image or video collection as ALPR or Automatic
License Plate Recognition (ALPR) (ANPR). ANPR technology enables intelligent
transportation systems and minimizes the need for human contact. The goal of this
research is to discover an optimal license plate recognition algorithm. This study
uses four deep neural networks, including CNN, VGG16, VGG19, and YOU LOV3,
to recognize license plates, evaluate model accuracy, and select the best model [4].
In this work, FCN was used to extract lane marking features. Individual classiﬁca-
tion experiments can be performed on each pixel of the input image. After removing
the original complete convolutional layer, the loaded feature maps were immediately
restored. The Tusimple dataset was used to train the network parameters. Use the
Hough transform to specify the tuning interval and the smallest track tuning inside
the tuning interval to accomplish multi-band tuning by combining it with the least
squares approach. There is now a net. The experimental ﬁndings demonstrate that
FCN is superior to other neural networks in terms of lane edge pixel extraction, and
that its lane identiﬁcation rate is superior to that of other techniques [5].
Video is particularly important in this context. In recent years, it has been exten-
sively employed in trafﬁc monitoring and control systems. A signiﬁcant amount of
research is being undertaken on trafﬁc control systems. Examples of these appli-
cations where video is processed include early warning or information extraction
in real-time, as well as analytics through vehicle identiﬁcation and categorization.
Vehicle detection and categorization are discussed in this article [6].
This paper presented a vehicle detection algorithm that can identify automobiles
as well as trafﬁc offenses. Most computers and artiﬁcial intelligence (AI) vision
systems require the capacity to recognize objects. The acquired results are examined
and tabulated. It has a 91% accuracy on the NIR picture and an 88% accuracy on
the blurred image dataset. The detection time is reduced by seconds for high-density

752
R. Bharadwaj et al.
trafﬁc ﬂows. As a result, system operating speed is affected by trafﬁc density. It may
also be used on bigger datasets by training on GPUs and high-end FPGA packages
[7].
This report outlines a vehicle detection algorithm that can identify automobiles
as well as trafﬁc offenses. Most computers and artiﬁcial intelligence (AI) vision
systems require the capacity to recognize objects. The acquired results are examined
and tabulated. It has a 91% accuracy on the NIR picture and an 88% accuracy on
the blurred image dataset. The detection time is reduced by seconds for high-density
trafﬁc ﬂows. As a result, system operating speed is affected by trafﬁc density. It may
also be used on bigger datasets by training on GPUs and high-end FPGA packages
[8].
In this research, they aim to improve road safety by using monocular cameras to
estimate the speed of vehicles in real-time. This is achieved through the use of arti-
ﬁcial intelligence, videos, and statistical and machine learning methods. Generated
a dataset of 532 vehicle samples from a highway video and used it to evaluate the
accuracy of various speed estimation methods. The best results were obtained using
the Linear Regression Model, which achieved 1.694 km/h Mean Absolute Error for
the center lane and 0.956 km/h for the last lane. This method is fast and requires
low computational resources, making it suitable for hardware implementation in
the future. Our work is competitive with existing state-of-the-art approaches and
contributes to the ﬁeld of transit studies and road safety [9].
A new approach for identifying moving vehicles in trafﬁc scenes is introduced
in this study. It involves a combination of an artiﬁcial neural network and the oppo-
sitional gravitational search optimization algorithm. The system has two phases,
ﬁrst is generating a background, which is designed to be efﬁcient, and second is
vehicle detection using the ANN-OGSA model. The optimization of weight values
is carried out using the OGSA algorithm. The proposed method was compared to
existingalgorithmsandevaluatedonthreevideotypes.Demonstratethattheproposed
ANN-OGSA method offers better precision compared to existing methods, with an
improvement of 3–6%, and has a maximum recall of 89, 91, and 91% for video1,
video2, and video3, respectively [10].
The rise in the number of vehicles on the roads each year highlights the need
for effective and efﬁcient vehicle detection. As per the data from the road trans-
port department in Malaysia, there were approximately 31.2 million motor vehicles
in the country by the end of 2019, which is an increase from the 28.18 million
recorded in mid-2017. This project aims to improve vehicle detection by incorpo-
rating TensorFlow and YOLO, an object detection algorithm. The study employs the
latest YOLOv4 algorithm and the DeepSORT algorithm. The results demonstrate
that YOLOv4 is the most effective model with 82.08% AP50 and a real-time speed
of approximately 14 FPS on a GTX 1660ti [11].
A novel vehicle detection system is introduced in this paper. It combines the Haar-
like image descriptor with artiﬁcial neural networks for classiﬁcation. The system
employstheconceptofintegralimageforfastfeatureextractionbythedescriptor.The
training of the system was done using positive images (vehicles) and negative images
(non-vehicles), and then evaluated on a separate set of images. The performance was

Trafﬁc Surveillance and Vehicle Detection YOLO …
753
evaluated by altering the number of neurons in the hidden layer and the results
indicate that the proposed system is efﬁcient and effective in detecting vehicles [12].
Highway trafﬁc management, planning, and prevention rely heavily on real-time
trafﬁc monitoring technologies to avoid frequent trafﬁc snarls, moving violations,
and fatal car accidents. These systems rely only on data from time-dependent vehicle
trajectories used to predict online trafﬁc ﬂow. From vehicle recognition and tracking
data created by processing roadside camera photos, vehicle trajectories are derived.
Yolo, SSD, and EfﬁcientNet are all general-purpose object detectors that have been
heavily used for real-time object detection tasks, but Yolo is favored in theory since it
offers a high frame rate (FPS) performance and reliable object localization function-
ality. However, the average vehicle categorization accuracy of this system is less than
57%, which is insufﬁcient for monitoring trafﬁc ﬂow. In this study, it is suggested that
Yolo’s vehicle categorization accuracy be increased and a brand-new bounding box
(Bbox)-based vehicle tracking method be created. A new car dataset is created for
this purpose by adding 123,831 object patterns to 7216 photos that were taken from
movies of highways. A CNN-based classiﬁer and nine machine learning-based clas-
siﬁers were chosen. After that, the dataset was used to train the classiﬁers. The most
accurate classiﬁer out of 10 was chosen to be combined with Yolo. By doing this,
the Yolo-based vehicle detector’s categorization accuracy rose from 57 to 95.45%.
Yolo-based vehicle detectors 1 and 2 were used, as well as vehicle trackers 1 and 2
based on the Kalman ﬁlter and the Bbox, respectively. These techniques were used
for categorical/total vehicle counts [13].
In urban areas, trafﬁc congestion is a major issue and is often exacerbated by
blocked intersections. To address this problem, a research project is proposed that
utilizes machine vision technology to identify and categorize trafﬁc violations at
city road crossings. The system consists of three main components: output, video
analysis, and video capture. This paper focuses on the development of a vehicle
recognition and tracking system that uses corner feature point detection and artiﬁcial
neural networks for front-end processing in the video analysis subsystem. The goal
is to improve trafﬁc violation management and enhance the efﬁciency of the system
[14].
This study explores the potential for advancements in computer vision and intel-
ligent transportation systems by focusing on the detection of multiple vehicles. Most
existing systems only use bounding box models and do not provide vehicle posi-
tion information, which is crucial for real-time applications such as tracking the
movement of cars on the road. In this study, we propose an updated version of the
You Only Look Once (YOLOv3) algorithm and a better visual background extrac-
tion technique for the detection of multiple types of vehicles in an input video. The
Kalman ﬁltering and particle ﬁltering methods are utilized to accurately track the
movement of vehicles. The suggested method, known as multiple vehicle tracking
algorithms, is evaluated in a variety of weather and illumination circumstances. The
technique’s performance is assessed using 10 distinct input movies and benchmark
datasets such as KITTI and DETRAC. This study’s research topics address real-world
issues in the realm of intelligent transportation systems such as occlusions, camera
motions, backdrop changes, cluttering, camouﬂage, and variable lighting variations.

754
R. Bharadwaj et al.
For automated feature extraction and annotation, the top eight high-level features are
examined [15].
This research offers a real-time trafﬁc monitoring system that recognizes and
categorizes autos in trafﬁc ﬂows by employing convolutional neural networks and
you only look once (YOLO). The system counts and categorizes cars using a virtual
detection zone, a Gaussian mixture model (GMM), and YOLO, and it calculates
speed based on vehicle distance and transit time. To assess the proposed technique,
the Montevideo Audio and Video Dataset (MAVD), GARM Road-Trafﬁc Monitoring
Dataset (GRAM-RTM), and other acquired datasets were employed. The approach
adopting YOLOv4 performed well in a range of illumination conditions and had the
highest classiﬁcation accuracy, with scores of 98.91 and 99.5% in the MAVD and
GRAM-RTM datasets, respectively. On average, vehicle speed estimate errors were
7.6% [16].
This paper presents a framework for real-time trafﬁc assessment on highways
utilizing data from the Vehicle Infrastructure Integrated System (VII) and AI methods
such as SVM and ANN. The VII-SVM framework was tested in a trafﬁc simulation
in South Carolina and showed improved incident detection compared to the VII-
ANN framework and traditional detection. Methods for detection rate, false alarm
rate, and detection time. The framework also provides additional information such as
incident location and affected lane count, useful in emergency response. The study
concludes that the VII-AI framework can be a trustworthy substitute for traditional
trafﬁc sensors for trafﬁc situation evaluation [17].
The study describes a trafﬁc speed estimation model that uses data from vehicle
detection systems and dedicated near-ﬁeld communications. The model consists of
three perceptron models and a fusion model to combine the output from the other
two. Evaluation showed that the proposed model outperformed the arithmetic mean
model with an accuracy of 90.5 and 92% at peak. The model has advantages such
as high accuracy from using multiple sensors, robustness over time, and real-time
processing capabilities through fast computation [18].
In this paper, a modiﬁcation to the YOLOv4 Tiny Object Detector is presented to
reduce memory consumption and improve image processing speed. The modiﬁca-
tion focuses on improving the detector’s backbone to minimize ﬂoating-point opera-
tions while retaining important vehicle feature information. The proposed model was
evaluated by comparing its performance on a vehicle dataset with other well-known
models in the same category, resulting in 7.9% more FPS and 0.5% lower memory
consumption than the original YOLOv4 Tiny model while maintaining comparable
accuracy [19].
In this research, three methods for car detection and tracking are presented using
artiﬁcial neural networks and various sensory inputs. The preprocessing step is
tailored to each speciﬁc problem. The neural networks utilized in these approaches
process visual and time series-based inputs to achieve real-time performance on
German highways [20].

Trafﬁc Surveillance and Vehicle Detection YOLO …
755
3
Methodology
To implement and design a computer vision pipeline. Perform these tasks:
1. Reading Video:
To read video frames we used Opencv and the original video has been shown, then
a queue of the frames passed to the next task.
2. Detecting Object:
TinyYOLO is used for object detection. TinyYOLO is a pre-trained model on the
COCO dataset. YOLO’s job is to recognize the car outside its frame.
3. Classifying Car Types:
Once we get cars using the bounding box for each frame, we have to classify them as
SUVs or sedans. For performing this task, MobileNetV2 classiﬁer is used and applies
the concept of transfer learning to modify the model according to the functionality.
Figure 1 displays the computer vision pipeline.
3.1
Pipeline Design, Model Conﬁgurations, and Working
• OpenCV was used for reading the video from the video frames with the rate of
30 FPS.
• Preparation of dataset: images of the two classes are included in the dataset, these
classes are SUV and Sedan. There are total 1748 images of sedan and 1432 images
of SUV in the dataset. Images are collected from the Stanford car dataset and the
Google images web scraping. It is included in the data preparation.
• TinyYOLO is preferred over the YOLO for object detection in the video. Because
it is faster and lighter than the latter. TinyYOLO can handle 220 FPS, while YOLO
handles 20–40 FPS. Since we need real-time detection.
Fig. 1 Computer vision pipeline

756
R. Bharadwaj et al.
• After reading all frames in OpenCV, the queue of frames is passed to the detection
function. For detecting classes in a given frame. The detection function uses
YOLO’s detect_image function.
• In the end, the location of detected cars in particular frames are passed to classi-
ﬁcation function, to classify the cars into speciﬁed classes. Model trained using
MobileNet model was used in this function.
3.2
Transfer Learning and MobileNet Model
• In Fig. 2 basic structure of MobileNet model is shown and reused this model using
transfer learning concept.
• The MobileNet model was used as a starting point, we added our own layers and
discarded the last layer which is shown in Fig. 3. In this model a single output
layer is present with 2 additional hidden layers of 512 neurons and 1 hidden
layer with 256 neurons. Finally single output layer was added. Due to its binary
classiﬁcation problem.
Fig. 2 Structure of original MobileNetV2 model

Trafﬁc Surveillance and Vehicle Detection YOLO …
757
Fig. 3 Structure of modiﬁed model
3.3
Model Tuning and Hyperparameters
A. Dropout: A new layer dropout using A regularization method with probability
0.2 was used. This helped reduce model overﬁtting that could be investigated
due to the gaps between validation and training error and validation accuracy.
B.
Data augmentation: An attempt was made to use data extensions to perform
different operations such as zooming, panning, but this operation was discarded
as the results were not satisfactory. Machine learning applications, especially
deep learning applications, continue to diversify and grow rapidly. Data-centric
approaches to model development, such as data augmentation techniques, can be
excellent tools for the challenges facing the world of artiﬁcial intelligence. Data
augmentation helps improve the performance and results of machine learning
models by forming new and different examples for training datasets. When the
dataset is included in a machine learning model.
C.
Epochs: 20 epochs were set. This is because a large number of epochs may lead
to unsatisfactory results in terms of poor accuracy improvement, ground truth,
and overﬁtting.
D. L1/L2 regularization: We tried adjusting weights for L1 and L2, with very large
validation errors and poor accuracy. We got bad results including poor accuracy
and large validation errors.
E.
Model compilation: As a progress metric, binary cross-entropy with accuracy
used in the loss function. Finally, with the correct name model weights are saved.
F.
Gradient descent optimization algorithms: Two optimization algorithms were
tried, Adam optimizer and RMSProp. For our project, Adam gave better results
than RMSProp, so we used it. 0.0001 was the learning rate. Because a low
learning rate requires a higher epoch and slows down learning.
3.4
Number of the Epoch Versus Accuracy
and Cross-Entropy
In Fig. 4, the time/epoch for Adam and RMSProp optimizations versus the variation
of accuracy and cross-entropy is shown. Adam was preferred over RMSProp due

758
R. Bharadwaj et al.
Fig. 4 wrt to time/epoch, variation of accuracy and cross-entropy (left) for Adam (right) and
RMSProp (lower)
to, difference between validation accuracy and training accuracy is smaller than
RMSProp, resulting in less overﬁtting models. As expected, it outperforms F1 in the
number of sedans and SUVs, and also proves to be a better model overall.
4
Result and Discussion
4.1
Deep Learning Models Final Accuracy
Tables 1 and 2 presents the Training loss, Training accuracy, Validation loss, and the
Validation accuracy of the Adam optimizer and the RMSProp optimizer.
Table 1 Adam optimizer (lr
= 0.0001)
Training loss = 0.0075
Training accuracy = 0.9994
Validation loss = 0.3485
Validation accuracy = 0.9148
Table 2 RMSProp optimizer
(lr = 0.0001)
Training loss = 0.0077
Training accuracy = 0.9981
Validation loss = 0.4031
Validation precision = 0.9125

Trafﬁc Surveillance and Vehicle Detection YOLO …
759
4.2
Pipeline Optimization
• For Intersection over Union Threshold (IOU) and the Non-Maximal Suppres-
sion (NMS) parameters of the YOLO model for better results various experi-
ments were performed. The threshold for object selection removes all boxes with
low probabilities and intersection probabilities are modiﬁed by this parameter. In
the TinyYOLO, an IOU of 0.2 and NMS score of 0.2 gives better result, which
improves the F1 score to ground truth.
• Experiment with different hyperparameters for our deep learning model, including
epochs, optimizers, regularization, dropout, and data augmentation focused on
providing a well-deﬁned and accurate input dataset to our training model.
• We have incorporated a fast processing approach that uses a thread pool (executor
framework) to process frames in parallel, reducing execution time by a factor of 1.
It will be more useful in the future when you need to process longer videos. Even
so, it currently takes about 3 min to process (recognize and classify) a 900-frame
video, so the pipeline needs to be sped up a bit more.
Training Loss = 0.0075, Training Accuracy = 0.9994, Validation Loss = 0.3485,
Validation Accuracy = 0.9148, Training Loss = 0.0077, Training Accuracy =
0.9981, Validation Loss = 0.4031, and Validation Accuracy = 0.9125.
• Early, hair cascades were used to detect cars but did not get better results, so
YOLO was used for object detection because it gives much better results than the
ﬁrst method.
4.3
Output of Pipeline
In Fig. 5, the video displayed to the user and output contains detected cars and their
types in the pipeline. Output of the system also stored in the excel sheet. Includes
tables like comparing Sedan, SUV, and total F1 score with number of cars per frame.
Which is shown in Fig. 6.
4.4
Execution Time
This system processed 900 frames in 460 s. Comparing the time taken by the ML
model to classify objects and time taken by YOLO to process the object detection is
shown in Fig. 7.

760
R. Bharadwaj et al.
Fig. 5 Output with the number of cars with their types
Fig. 6 The F1 score for total cars
Fig. 7 Detection and classiﬁcation time for each frame

Trafﬁc Surveillance and Vehicle Detection YOLO …
761
5
Conclusion and Future Scope
Although it is a computer vision pipeline, the implementation of the code is in
object-oriented-based approach and has separate classes for video reading, object
identiﬁcation, automatic classiﬁcation, etc., allowing for programming reuse. And
contributing to the extension of this project.
In security systems such as trafﬁc monitoring, the goal is to get the desired infor-
mation quickly. Our goal is to push the limited capabilities of computer systems to
higher levels using distributed systems and parallel operations. Additionally, it can
be implemented on larger datasets by training on GPUs and high-end FPGA kits.
Acknowledgements It would be our utmost pleasure to express our sincere thanks to our guide
Prof. Rakhi Bharadwaj who gave us the opportunity to do more research on the topic “Trafﬁc
Surveillance and Vehicle Detection ML pipeline using YOLO and MobileNet transfer learning”,
which also helped us in doing plenty of ideas and that we came to understand about such a lot of
new things.
References
1. Bhardwaj RJ, Rao DS (2022) Deep learning-based trafﬁc behavior analysis under multiple
camera environment. Int J Next-Gener Comput. https://doi.org/10.47164/ijngc.v13i3.719
2. Bhardwaj RJ, Rao DS (2022) Modiﬁed neural network-based object classiﬁcation in video
surveillance system. Int J Next-Gener Comput. https://doi.org/10.47164/ijngc.v13i3.890
3. Wang Z, Huang J, Xiong NN, Zhou X, Lin X, Ward TL (2020) A robust vehicle detection
scheme for intelligent trafﬁc surveillance systems in smart cities. IEEE Access 8:139299–312.
https://doi.org/10.1109/access.2020.3012995
4. Ganga Krishnan G, Natheera Beevi M A comparative study of four deep neural networks for
automatic license number plate recognition system. IJERT
5. Chao F, Yu-Pei S, Ya-Jie J (2019) Multi-lane detection based on deep convolutional neural
network. IEEE Access 7:150833–150841
6. Kul S, Eken S, Sayar A (2017) A concise review on vehicle detection and classiﬁcation. In:
2017 international conference on engineering and technology (ICET). IEEE, pp 1–4
7. Kumar C, Punitha R (2020) Performance analysis of object detection algorithm for intelligent
trafﬁc surveillance system. In: 2020 second international conference on inventive research in
computing applications (ICIRCA). IEEE, pp 573–579
8. Kim K-J, Kim P-K, Chung Y-S, Choi D-H (2019) Multi-scale detector for accurate vehicle
detection in trafﬁc surveillance data. IEEE Access 7:78311–78319
9. Rodríguez-Rangel H, Morales-Rosales LA, Imperial-Rojo R, Roman-Garay MA, Peralta-
PeñuñuriGE,Lobato-BáezM(2022)Analysisofstatisticalandartiﬁcialintelligencealgorithms
for real-time speed estimation based on vehicle detection with YOLO. Appl Sci 12(6):2907
10. Appathurai A, Sundarasekar R, Raja C, John Alex E, Anna Palagan C, Nithya A (2019) An
efﬁcient optimal neural network-based moving vehicle detection in trafﬁc video surveillance
system. Circuits Syst Sig Process 39(2):734–56. https://doi.org/10.1007/s00034-019-01224-9
11. Zuraimi MAB, Zaman FHK (2021) Vehicle detection and tracking using YOLO and Deep-
SORT. In: 2021 IEEE 11th IEEE symposium on computer applications and industrial
electronics (ISCAIE). IEEE, pp 23–29
12. Mohamed A, Issam A, Mohamed B, Abdellatif B (2015) Real-time detection of vehicles using
the haar-like features and artiﬁcial neuron networks. Procedia Comput Sci 73:24–31

762
R. Bharadwaj et al.
13. Azimjon J, Özmen A (2021) A real-time vehicle detection and novel vehicle tracking systems
for estimating and monitoring trafﬁc ﬂow on highways. Adv Eng Inform 50:101393
14. Billones RKC, Bandala AA, Sybingco E, Gan Lim LA, Fillone AD, Dadios EP (2017) Vehicle
detection and tracking using corner feature points and artiﬁcial neural networks for a vision-
based contactless apprehension system. In: 2017 computing conference. IEEE, pp 688–691
15. Sudha D, Priyadarshini J (2020) An intelligent multiple vehicle detection and tracking using
modiﬁed vibe algorithm and deep learning algorithm. Soft Comput 24(22):17417–17429
16. Lin C-J, Jeng S-Y, Lioa H-W (2021) A real-time vehicle counting, speed estimation, and
classiﬁcation system based on virtual detection zone and YOLO. Math Prob Eng
17. Ma Y, Chowdhury M, Sadek A, Jeihani M (2009) Real-time highway trafﬁc condition assess-
ment framework using vehicle–infrastructure integration (VII) with artiﬁcial intelligence (AI).
IEEE Trans Intell Transp Syst 10(4):615–627
18. Min JH, Ham SW, Kim D-K, Lee EH (2022) Deep multimodal learning for trafﬁc speed
estimation combining dedicated short-range communication and vehicle detection system data.
Transp Res Rec. 03611981221130026
19. Alsanabani AA, Saeed SA, Al-MkhlaﬁM, Albishari M (2021) A low cost and real time vehicle
detection using enhanced YOLOv4-Tiny. In: 2021 IEEE international conference on artiﬁcial
intelligence and computer applications (ICAICA). IEEE, pp 372–377
20. Goerick C, Noll D, Werner M (1996) Artiﬁcial neural networks in real-time car detection and
tracking applications. Pattern Recogn Lett 17(4):335–343

Perceptors: A Real Time Object
Detection System with Voice Feedback
and Distance Approximation for Blind
Rakhi Bharadwaj, Harshal Sonawane, Manasi Patil, Shashank Patil,
and Vedant Jadhav
Abstract Engineering solutions have impacted everyone’s lives, but those designed
to aid people with disabilities have been especially signiﬁcant. However, the current
pricing of modern assistive gadgets does not match the market’s needs. In its latest
study, WHO puts the number of visually impaired people at 285 million. Of these,
246 million are blind and an estimated 39 million are visually impaired. Blind people
face many problems and difﬁculties in business and social activities. It also has the
potential to contribute to society if the opportunity arises. In this paper we propose to
you “Perceptors”—An A.I. powered smart glasses that can detect objects in real time
and alert users when objects are nearby. This research is an attempt to give visually
impaired people a chance to experience a moderately normal life by warning users
in advance of approaching objects and helps users identify objects in real time.
Keywords Raspberry Pi · Python · Object detection · Voice processing · Distance
approximation
1
Introduction
For the past few decades, visual impairments have been one of the most common
issues. Devices used by the blind to navigate are not sufﬁciently accessible since
R. Bharadwaj · H. Sonawane · M. Patil (B) · S. Patil · V. Jadhav
Department of Computer Engineering, Vishwakarma Institute of Technology, Pune, India
e-mail: manasi.patil21@vit.edu
R. Bharadwaj
e-mail: rakhi.bharadwaj@vit.edu
H. Sonawane
e-mail: harshal.sonawane21@vit.edu
S. Patil
e-mail: shashank.patil21@vit.edu
V. Jadhav
e-mail: vedant.jadhav20@vit.edu
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_57
763

764
R. Bharadwaj et al.
they primarily rely on infrastructural needs. The most widely used is a simple stick
or cane. Blind people swing the stick back and forth to use it to perceive obstacles,
but unfortunately blind people may notice obstacles too late. With this, recent tech-
nological advances have changed the normal cane to a stick which is attached with
an ultrasonic sensor for object detection and distance proximation. Then too there
are some restrictions.
Visually impaired people may ﬁnd it difﬁcult to move through rooms or different
types of roads without their vision. Most shocking thing is that 75% of these blind
people have preventable eyesight. There are not enough opticians and very few people
take an initiative and sign a contract for eye donation after their death in order to
treat corneal sight. The main goal of “Perceptors” is to help blind people to move
like normal people. This design is based on a preliminary study of visually impaired
individuals. This research uses camera-based glasses, a methodology that people can
use while walking. It has object detection technology that recognizes nearby objects.
Whenanobject is recognized, it converts text intospeech, whichcanbeheardbyblind
people. The purpose of “Perceptors” is to assist these people in various areas of life.
For example, these glasses are effective for pedestrians. Helps pedestrians recognize
approaching objects. Ultrasonic sensors can also be used to calculate distances and
send alerts when objects are approaching. With the help of this system, they can walk
alone through streets, trafﬁc areas, or parks without depending on anyone. Because
you are interested, you can enjoy your life with the help of this system. This wearable
device is designed to assist the visually impaired in their mobility. Most commercial
devices lack some necessary features, but these devices conveniently overcome them.
The device also warns the blind if there are obstacles and guides the blind through
streets and different areas via voice support (Fig. 1).
2
Literature Review
In a rapidly growing country like ours, multiple attempts have been made with
the welfare in mind of specially abled persons in surroundings. Operation “Project
Prakash” is one of these endeavors [1], which aims to help blind children by gaining
knowledge of a set of obstacles around them by using their intelligence. Sheth et al.
[2] worked on ﬁnding various ways on how a blind person may be used to ﬁnd any
kind of pits, potholes, and several other things by using a smart stick where they
have used ultrasonic sensors for object detection. This gadget has a multinational
audio system. Feedback cannot be used because it has a limitation of recording only
680 s. The research in [3] has a pits sensor, an ultrasonic sensor, as well as a water
sensor. As well has a GPS system, but this requires the user to enter their location
themselves. Instructions for doing so are not mentioned here. In [4] we see that the
frame itself consists of a video camera, a CPU with appropriate size, and software
that takes pictures of nearby objects with transparency. eyepiece. The main limitation
of this device is that it is completely unsuitable for visionless people. This is only
recommended for blind people or a person with night blindness. There is another

Perceptors: A Real Time Object Detection System with Voice Feedback …
765
Fig. 1 Experimental setup
upcoming attempt to assist the visually impaired called Haptic Assisted Location of
Hurdles, or H.A.L.O. [5]. It includes a rangeﬁnder that receives data from an ultra-
sonic sensor and outputs feedback by vibrating motor placed on a visionless person’s
head.
S. No
Title
Findings
Year of publication
1
Smart Glasses for Blind
People [6]
In this paper, authors discussed a
device that can detect an object
and convert an image to speech
2021
2
Real Distance Measurement
Using Object Detection of
Artiﬁcial Intelligence [7]
The idea behind this paper is to
measure the distance to an object
2021
3
IoT Enabled Automated
Object Recognition for the
Visually Impaired [8]
To recognize objects, this system
employs Tensorﬂow Lite’s Single
Shot Detector (SSD) architecture
with MobileNet
2021
4
Custom object detection
in browser using TensorFlow.js
(BLOG) [9]
This blog post demonstrates how
to train a bespoke object detection
model using TensorFlow to create
an end-to-end approach
2021
5
Object Detection for Blind
Users [10]
This study describes a technology
that would enable blind persons
to sight using object-like pictures
and video scenes
2020
(continued)

766
R. Bharadwaj et al.
(continued)
S. No
Title
Findings
Year of publication
6
A review on methods for
speech-to-text and
text-to-speech conversion [11]
Through this paper authors aim to
study the different methodology
for text-to-speech conversion
2020
7
Distance Measurement using
Sensors and Arduino [12]
The primary goal of this research
was to create a distance system of
measurement that interconnected
with an Arduino and used
ultrasonic waves
2017
8
Design and Implementation of
text-to-speech conversion for
Visually Impaired [13]
Text-to-speech using NLP, DSP,
and reads out to the user
2014
9
Implementation of
text-to-speech conversion [14]
In this study, a text-to-speech
conversion system that can get
the text through image using
Optical Character Recognition
(OCR) in MATLAB
2014
3
Problem Statement
Having a visual impairment limits the way you interact with others, access infor-
mation, and develop your own knowledge and experiences, so you can multitask to
cope with a variety of situations. The need for tools is a key issue. The tools and
technologies currently on the market are expensive for the average or low-income
people who make up the majority of users, so new, cheaper devices with similar tasks
are needed. The existing systems failed to detect objects in real time. Few systems
used the object detection models to detect static objects from images. There was no
system present that could sense the distance between the object and the concerned
person. Existing systems failed to achieve fast computation and failed to present
accurate results. Cost of the system is a major concern; Existing systems are costly
as compared to the proposed system.
Smart Cane: Uses an ultrasonic sensor to detect any obstacles above chest level and
warns the user via a vibrating handle. No object detection capabilities.
InnoMake shoes: Includes a pair of ultrasonic sensors at the tip of each shoe that
vibrates and makes noises to warn the individual of the obstacle in front of them.
Costs around e3200 which is very expensive to average people.
OrCam MyEye Pro: Glasses that capture image when user clicks button and then
communicate the info audibly through a tiny speaker that rests above the ear. No real
time object detection, an image is clicked ﬁrst and then objects are detected thus it
increases the response time and computation overhead.

Perceptors: A Real Time Object Detection System with Voice Feedback …
767
The main goal of the proposed system is to offer a dependable, economical,
and low-power solution that allows visually impaired people to walk normally as a
pedestrian would. A sizable section of society can afford the price of such a system,
providing a disposable device and ensuring excellent guidance.
4
Proposed Methodology
The functioning of proposed system can be understood by these four main sub
module:
A. Object Detection
B.
Object Recognition
C.
Distance Approximation
D. Voice Processing (Text-To-Audio).
A. Object Detection
The previous object detection techniques rely on palm functions and ﬂat, train-
able systems. By building sophisticated ensembles that blend numerous poor visual
features of high context via features extracted and scenario classiﬁcations, their
performances could be simply drowned out. As machine learning quickly advances,
more potent methods for learning meanings and richer, more ﬂexible functions are
deﬁned to tackle problems with old architectures. For the purpose of object detection
the proposed system uses Tensor ﬂow Lite Open Source Library. TensorFlow Lite is
used to help TensorFlow models convert them to a much more compact deep learning
(DL) model structure. Additionally, you can alter which was before models that are
already in TensorFlow Lite or build your own TensorFlow models and then export it
in TensorFlow Lite form. Images, videos, audio, and texts may all be used as inputs
in TensorFlow models to perform tasks like object recognition, language processing,
pattern matching, and more. Proposed system implements the TensorFlow Lite model
for the purpose of object detection. TensorFlow Lite is a lightweight model specially
designed for embedded applications having less computation power. Along with the
TensorFlow Lite, the Single Shot Detector (SSD) model with MobileNet is used.
The proposed system can also detect objects from pictures provided that the
images are of good quality. The proposed system marks the area of interest with a
rectangular grid and then the SSD MobilNet model recognizes the object present in
the image using an array of detection summary info, name—detection_out, shape—
1, 1, 100, 7 in the format 1, 1, N, 7, where N is the number of detected bounding
boxes.
For each detection, the description has the format: [image_id, label, conf, x_min,
y_min, x_max, y_max].
B. Object Recognition

768
R. Bharadwaj et al.
Various methods could be used for object identiﬁcation. Computational modeling
and machine learning methods have recently gained popularity as solutions to object
identiﬁcation issues. Both methods teach users how to recognize items in pictures,
but they operate in different ways. One of the quickest and most dependable versions
of MobileNets is mobilenet-v3-large-1.0-224-tf (MobileNets V3). It is built on a
creative architectural design and a blend of several search strategies. The increased
resource application scenarios are satisﬁed by mobilenet-v3-large-1.0-224-tf.
Image, name: input, shape: [1x3x224x224], format: [BxCxHxW], where:
• B—batch size
• C—number of channels
• H—image height
• W—image width.
Faster R-CNN 7 FPS with mAP 73.2% or YOLO 45 FPS with mAP 63.4% were
both slower than the SSD method’s 59 FPS with mAP 74.3% on the VOC2007 test.
It aggregates detections at various sizes by using several image features from of the
later stages of the network and small convolution ﬁlters to forecast item categories
and thresholded positions for various aspect ratios. The suggested model can identify
roughly 10–15 frames per second. There is room for advancement by using a cutting-
edge microprocessor. (Pi4) Raspberry.
C. Distance Approximation
Manual distance measurement always comes at the expense of human error. An ultra-
sonic sensor contains a transducer that, when the transducer element vibrates, emits
inaudible, high-frequency sound waves in one direction. When a wave hits an object
and bounces off it, the transducer receives an echo signal. The sensor then uses the
time between the ﬁrst sound burst and the return of the echo to determine the distance
to the object. Various sensors were considered for distance approximation, out of
these sensors, ultrasonic sensors showed promising results while barring minimum
cost. In our research, we have used ultrasonic sensors for distance approximation. We
chose ultrasonic sensor instead of IR sensor, because in case of transparent objects,
IR sensor lacks in reﬂecting the waves backs. Hence, ultrasonic sensors are better
and more reliable than any of the contemporary. Proposed system implements the
TensorFlow Lite model for the purpose of object detection. TensorFlow Lite is a
lightweight model specially designed for embedded applications having less compu-
tation power. Along with the TensorFlow Lite, the Single Shot Detector (SSD) model
with MobileNet is used.
The average speed of sound is around 340 m/s, or 29.412 ms/cm. The formula
Distance = (time × speed of sound)/2 is used to detect the length that sound travels.
Since sound must travel equally backward and forward, the number “2” is included in
the equation. The sound leaves the sensors ﬁrst, then leaves the surface and recovers.
The equation centimeters = ((microseconds/2)/29) can be used to quickly read the
distance in centimeters. For instance, if an ultrasonic sound bounces after 100 s
(microseconds), the range is ((100/2)/29) centimeters, or approximately 1.7 cm.

Perceptors: A Real Time Object Detection System with Voice Feedback …
769
Distance (d) = (Speed * Time)/2
Example:
Distance = (34 ms * 1.5 ms)/2
d = 25.2 cm, where 1.5 ms = receiver pulse duration, 34 m/s is speed of sound.
D. Voice Processing Method
gTTs is an API to convert text in audio in Python. Several languages, including
English, Hindi, Tamil, French, German, etc., are supported by the gTTS Apis. The
speech is subsequently presented in one of multiple audio rates of speed or slow—
that are offered. gTTS has some of the best features like being customizable, can read
unlimited length of text, all while keeping proper intonation, abbreviations, decimals,
and more and can also provide pronunciation corrections wherever required. These
features make it the best choice for our research.
As mentioned in Fig. 2, shows the overall execution and working of the proposed
system. It shows the various items used such as headphones, Raspberry Pi circuits,
and sensors. It is based on the TF Lite model as well as SSD Mobnet object detection.
The proposed system would be equipped with ultrasonic sensors deployed that
would continuously sense the distance between the subject and the object if any
object is in front of the subject. If the object is within the deﬁned threshold (150
cm) then the system would alert the camera module to start detecting objects using
the object detection model. The camera model would then detect and recognize the
Fig. 2 Architecture of
proposed system

770
R. Bharadwaj et al.
approaching object along with the distance at which it is approaching. After sensing
the object, the camera module would generate a label. The generated label would
have details such as the identiﬁed object, conﬁdence rate of the detected object, the
distance between the subject and object. The system would then send the label for
voice simulation. The voice simulation module in turn would convert the labels into a
speech which could be heard by the subject thus alerting the user of any approaching
object by identifying it.
5
Technological Requirements
1. Hardware Requirement
A. Raspberry Pi 3 Model B+
The Raspberry Pi, a simple Mastercard measurement PC that can be connected to
a PC screen or TV and uses a standard console and mouse. It is a credit card sized
computer. You need to plug in a keyboard, mouse, display, power supply, SD card,
and a system software that is already installed. The Raspberry Pi is an affordable 8-bit
microcontroller that can complete a variety of crucial functions. It can run as a small
PC, a portable computer which is capable of coding, a hub for homebrew hardware,
and much more. Contains general purpose input/output (GPOI) pins for controlling
electronics. It’s also a great machine to help kids learn how the computer works,
improve their programming skills, and nurture the next generation of developers.
This project uses the latest version of the ‘Raspberry Pi 3 Model B+’ which has a
more powerful quad-core processor. The Raspberry Pi 3 ofﬁcially uses a 5.1 V micro
USB power supply. It comes with 4 GB. RAM. It offers performance that is 3× better
than previous versions. In addition it provides 2 micro HDMI ports, micro SD card
slot, Display Serial Interface (DSI), Camera Serial Interface (CSI), and convenient
storage (Fig. 3).
B. Raspberry Pi Camera
The Raspberry Pi Foundation created the Raspberry Pi Camera Module. The camera
on a Raspberry Pi board can connect directly to the Raspberry Pi’s Camera Serial
Interface (CSI) connector. The 3.3 V power up the ribbon cable is permanently
applied for camera. It features 5 MP resolution with an Omni vision sensor in a
ﬁxed focus module. Connect them to Raspberry Pi Foundation created the Camera
Module for the Raspberry Pi. Camera made using a Raspberry Pi. It is small and
weighs about 3 g. The purpose of the camera is to capture images and save them to
the Raspberry Pi (Fig. 4).
C. Ultrasonic Sensor
An A transducer known as an ultrasonic sensor makes use of the physical features
and several additional impacts of ultrasonic waves that can send or receive ultrasonic

Perceptors: A Real Time Object Detection System with Voice Feedback …
771
Fig. 3 Raspberry Pi 3 Model B+
Fig. 4 Raspberry Pi camera
signals of a certain strength at a certain frequency. They come in piezo or electromag-
netic versions. Piezo type is typically selected since it is less expensive and easier to
use than other varieties [15]. The model is primarily based on the ultrasonic distance
sensor principle, or simply the ultrasonic sensor. With a range precision that can reach
up to 3 mm, this affordable sensor offers non-contact measurement capability from
2 to 400 cm (about 13 feet). It uses 5 V to work. It works with 40 kHz ultrasound
and when triggered by the transmitting module, the receiving module receives an
echoing of the activated signal with a detection tilt of 30° (Fig. 5).

772
R. Bharadwaj et al.
Fig. 5 Ultrasonic sensor
D. Headphones
The headphones are used to help the blind person to hear what is the detected object.
The headphones are connected to the Raspberry Pi circuit and help the blind person
to easily detect the object by hearing the sound (Table 1).
2. Software Requirement
a. Raspberry Pi Imager
Raspberry Pi Imager is a tool developed by Raspberry Pi Foundation that permits
you to easily install an operating system (OS) on your Raspberry Pi step-by-step.
A one-stop shop for downloading, conﬁguring, SD card formatting, and operating
system ﬂashing for the operating system of your choice. All you need is an SD card
reader to write your operating system to an SD card. Most modern computers have
a built-in SD card reader.
Table 1 Product cost
estimation
S. No
Component
Approx. cost
1
Raspberry Pi 3
Rs. 5000/–
2
Ultrasonic Sensor
Rs. 80/–
3
SD Card
Rs. 250/–
4
Raspberry Pi Cam
Rs. 300/–
5
Headphones
Rs. 200/–
6
Glasses
Rs. 300/–
7
Total
Rs. 6130/–

Perceptors: A Real Time Object Detection System with Voice Feedback …
773
b. MS Visual Studio Code
Visual Studio Code, also commonly known as Microsoft, has developed the source
programming environment VS Code for Windows, Linux, and macOS leveraging
the Electron Framework. Debugging, syntax highlighting, intelligent code ﬁnishing,
excerpts, script refactoring, and built-in Git compatibility are among the features.
c. Python 3.10.6
Python 3.10.6 is the latest major release of the Python programming language and
includes many new features and optimizations.
d. Raspbian Operating System
For such a Raspberry Pi line of affordable single-board computers, the Raspberry Pi
OS is a Linux operating system that relies on the Debian Version of Linux.
e. Git Version Control
Git is a version control system, it is widely used by the developers all over the world.
It helps multiple developers to collaborate and work together remotely.
6
Results and Discussion
As seen in Fig. 6, the ultrasonic sensor is able to detect objects rapidly. For objects
that are not in the declared threshold range (150 cm), the system is not initiating
the Camera module thus saving computational power and allowing the system to
function for a long time. As for objects falling within a distance of 150 cm, the
system would initiate a camera detection module in order to detect and recognize
objects in real time.
Figure 7 is the prototype that we have designed, where the Raspberry pi, ultrasonic
sensor, pi cam are mounted on the glasses.
7
Conclusion and Future Scope
In conclusion, these smart glasses are especially designed for visually impaired
people. So that they can have a more conﬁdent and independent life. This glass
can help them move around safely as it can detect nearby objects. In our upcoming
work, we’ll add more capabilities to the text proposed technique and handle the ui
problems that come with text comprehension for blind users. Also converting the text
to local language which would help people who know only a speciﬁc language. This
portable device does not require Internet connection and can be used independently
by people.

774
R. Bharadwaj et al.
Fig. 6 Ultrasonic sensor
distance approximation
Fig. 7 Prototype
References
1. Sheth R, Rajandekar S, Laddha S, Chaudhari R (2014) Am J Eng 03(10):84–89. [Online].
Available http://www.ajer.org/papers/v3(10)/L031084089.pdf
2. Gayathri G, Vishnupriya M, Nandhini R, Banupriya M (2014, March) Int J Eng Comput Sci
03(03):4057–4061. [Online]. Available http://ijecs.in/issue/v3-i3/8%20ijecs.Pdf
3. Grifﬁths S, Macrae F (2014, June) Smart glasses for the BLIND: display turns the world
into outlines to help people with poor vision ‘see’ obstacles andfaces. [Online]. Avail-
able http://www.dailymail.co.uk/sciencetech/article-2659993/Smart-glasses-BLIND-Device-
transforms-world-outlines-shapes-help-partially-sighted-navigate.html
4. Steve (2010, Dec) HALO-haptic feedback system for blind/visually-impaired. [Online].
Available http://www.polymythic.com/2010/12/teaser-haptic-feedback-for-visuallyimpaired
5. Shrivastava K, Verma A, Singh SP (2010) Distance measurement of an object or obstacle by
ultrasound sensors using P89C51RD2. Int J Comput Theor Eng 02(01):1793–8201. [Online].
Available http://ijcte.org/papers/118-G227.pdf
6. https://ijirt.org/master/publishedpaper/IJIRT151189_PAPER.pdf

Perceptors: A Real Time Object Detection System with Voice Feedback …
775
7. https://turcomat.org/index.php/turkbilmat/article/view/1979
8. https://www.sciencedirect.com/science/article/pii/S2666990021000148
9. https://blog.tensorﬂow.org/2021/01/custom-object-detection-in-browser.html
10. https://www.irjet.net/archives/V7/i6/IRJET-V7I6577.pdf.
11. https://www.irjet.net/archives/V7/i5/IRJET-V7I5854.pdf
12. https://circuitdigest.com/microcontroller-projects/arduino-ultrasonic-sensor-based-distance-
measurement
13. https://core.ac.uk/download/pdf/83592918.pdf
14. https://www.ijert.org/implementation-of-text-to-speech-conversion
15. Jacobs IS, Bean CP (1963) Fine particles, thin ﬁlms and exchange anisotropy. In: Rado GT,
Suhl H (eds) Magnetism, vol III. Academic, New York, pp 271–350
16. https://nei.nih.gov/news/scienceadvances/discovery/project_prakash.
http://www.who.int/
mediacentre/factsheets/fs282/en/
17. Yorozu Y, Hirano M, Oka K, Tagawa Y (2010) Electron spectroscopy studies on magneto-
optical media and plastic substrate interface. IEEE Transl J Magn Japan 2:740–741. August
1987 [Digests 9th Annual Conf. Magnetics Japan, p 301, 1982]
18. Girshick R (2015) Fast R-CNN. In: 2015 IEEE international conference on computer vision
(ICCV)
19. Redmon J, Divvala S, Girshick R, Farhadi A (2016) You Only Look Once: uniﬁed, real-time
object detection. In: 2016 IEEE conference on computer vision and pattern recognition (CVPR)
20. Gupta S, Girshick R, Arbeláez P, Malik J (2014) Learning rich features from RGB-D images
for object detection and segmentation. In: Computer vision—ECCV 2014 lecture notes in
computer science, pp 345–360
21. An introduction to Text-To-Speech in Android. Android Developers Blog, 23-Sep-2009.
[Online]. Available https://androiddevelopers.googleblog.com/2009/09/introduction-totextto-
speech-in.html. Accessed: 24-Mar-2019
22. Bhardwaj RJ, Rao D (2022) Deep learning-based trafﬁc behavior analysis under multiple
camera environment. Int J Next-Gener Comput 13(3)
23. Bhardwaj RJ, Rao D (2022) Modiﬁed neural network-based object classiﬁcation in video
surveillance system. Int J Next-Gener Comput 13(3)

Automated Histogram Binning-Based
Fuzzy K-Means Clustering
for COVID-19 Chest CT Image
Segmentation
S. Nivetha and H. Hannah Inbarani
Abstract The greatest threat to humanity is COVID-19, which has a global impact
on billions of people. For important judgment and disease control, therapeutic
imaging, such as Computed Tomography (CT), has a lot of potential as an alterna-
tive to the Real Time Reverse Transcription–Polymerase Chain Reaction (RT-PCR)
test. Automatic image segmentation is therefore highly sought after as a decision
support system. Image dissection is dividing a ﬁgure into sections entrenched on
a set of criteria. In this study, a dataset on COVID CT scan is analyzed using
the proposed method of Histogram Binning-Based on Fuzzy K-Means Clustering
(HBFKM) with the existing two main cluster methods namely Fuzzy_K-Means
(FKM) and Possibilistic_Fuzzy_C-Means (PFCM) and are utilized throughout the
segmentation step to segment the images. The ﬁndings specify that related to the
other approaches under study, the suggested method Histogram Binning-Based on
Fuzzy K-Means Clustering offers the highest accuracy and reliability with 85.08
and 85.28% precision. Additionally, the outcomes demonstrate that the proposed
approach has the maximum accuracy with a speciﬁcity rate of 85.18% ratio. And
lastly,theproposedtechniqueoutperformstheotherswithanF1-scorerateof85.47%.
Keywords COVID-19 · Histogram binning-based fuzzy K-means clustering ·
Fuzzy_K-Means (FKM) · Possibilistic_Fuzzy_C-Means (PFCM) · Image
segmentation
1
Introduction
Segmentation is the division of an image’s pixels into nonoverlapping, regular areas
that seem to be identical regarding certain factors relating to gray-level luminance or
S. Nivetha · H. Hannah Inbarani (B)
Department of Computer Science, Periyar University, Salem, Tamil Nadu, India
e-mail: hhinba@periyaruniversity.ac.in
S. Nivetha
e-mail: nivethas@periyaruniversity.ac.in
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_58
777

778
S. Nivetha and H. Hannah Inbarani
appearance is known as segmentation. There are several key problems in the ﬁeld of
image processing that are considered heavily researched areas. With consideration of
machine learning methodologies, each level of image segmentation is required and
plays a role in some of the many applications in the study of computer sight and image
processing. Throughout the present and near future, image data will continue to grow
in both volume and impact. Image processing techniques are commonly used when
working with image data and are considered necessary tools. Medical imaging is
one of the world’s most ground-breaking medical breakthroughs. Medical diagnosis
and intervention create a visual representation of the interior of the body. Medical
imaging techniques, however, do not create ﬂawless images, and many aberrations,
such as noise, and the complex architecture of particular biological tissues. The
Fuzzy_K-Means (FKM) algorithm is incredibly effectively utilized in data similarity
techniques.
Image segmentation is based on two fundamental image properties. One is discon-
tinuity, which denotes quick or sudden vicissitudes in luminance as edges, and
the other is similarity, which states grouping digitized imagery into areas based
on certain preconceived resemblance conditions. Image analysis takes recently
sparked a lot of attention, and it is becoming increasingly important. In this aspect,
Histogram_Thresholding [1], Edge_Detection [2], Region_Growing [3], Water-
shed_Transformation [4], Clustering, and Soft_Computing approaches have all been
investigated in the literature. Image segmentation utilizing Genetic algorithms [5],
Fuzzy_Logic_techniques [6], and Neural_Network_based approaches [7] are all
instances of Soft Computing techniques.
2
Related Work
Dhruv et al. [8] proposed Hybrid_Particle_Swarm_Optimised_Fuzzy C_Means
Clustering which was used to develop a hybrid technique for effective COVID-
19 screening utilizing chest CT images. The suggested method was evaluated on
15 individuals with torso CT images of COVID-19 infection, and the ﬁndings
were quantitatively conﬁrmed using metrics including entropy, contrast, and stan-
dard deviation, revealing that it exceeds traditional Fuzzy C-Means Clustering. In
[9], SUFMACS (Superpixel based_Fuzzy_Memetic_Advanced_Cuckoo_Search) is
a unique unsupervised machine learning-based method for quickly analyzing and
sectioning COVID-19 medical images. This method adapts the superpixel method
to compress vast spatial data. The Luus-Jaakola heuristic method is merged with
McCulloch’s methodology, and the original cuckoo search method is modiﬁed. The
fuzzy modiﬁed objective function is optimized using cuckoo search method. This
objective function takes advantage of the superpixel advantages. The Fast Fuzzy
C-Means Clustering approach is suggested in [10] for the purpose of COVID-19
disease prediction in CT scan images. The ROI extractor result generated by the
Fast FCM technique, which is focused on histogram evaluation, are efﬁcient and
have low computational complexity. Prior to RT-PCR lab testing, CT is regarded as

Automated Histogram Binning-Based Fuzzy K-Means Clustering …
779
a signiﬁcant COVID-19 diagnostic approach, and ROI extraction is becoming more
crucial. Compared to the results of the traditional segmentation algorithm, the Fast
Fuzzy C-Means Clustering methodology is an automated ROI extraction method.
In [11], study is an image processing-based technique for diagnosing COVID-19.
The proposed Fuzzy C-Means (FCM) is then employed as a novel approach for
segmenting COVID-19 chest X-rays. The system classiﬁcation, using the Enhanced
Capsule Network (ECN), was accomplished. The method relies on deep learning
and has different levels, with the ﬁrst stage being the processing of original informa-
tion and the last being the presentation of the model categorization. To enhance the
ECN, the MayFly Optimization (MFO) method was applied. To make the COVID-19
radiological images clearer, Chakraborty et al. [12] presented a special approach for
segmenting radiological images. The suggested strategy combines a type 2 fuzzy
segmentation method with SuFMoFPA (Superpixel-based Fuzzy-Modiﬁed Flower
Pollination Algorithm) to provide a more segmented outcome. The idea of pixels in
the image makes the process simpler, eliminating the need for processing a signif-
icant quantity of positional information. This proposed method is used with a type
2 fuzzy system to produce a more differentiated outcome. The suggested strategy
might involve using a computer-aided device to stop the coronavirus growth. Table
1 depicts the summary of related works.
3
Fuzzy K-Means Clustering
Dunn invented Fuzzy K-means clustering in 1973 as a member of binary or more
sets of data elements [13]. This benchmark is commonly used in image analysis and
pattern recognition images from medical, geological, and satellite sources, etc. The
FKM algorithm is primarily concerned with reducing the estimates of the objective
function. The objective function evaluates that the cluster’s quality divides the data
and splits it into c clusters.
Concerning some given criterion, the FKM algorithm tries to divide a ﬁxed group
of n component X = {x1, . . . , xn} into a gathering of c fuzzy clusters. The algorithm
returns a partition matrix and a listing of c group midpoints U = ui, j ∈[0, 1], i =
1, 2, . . . , n; j = 1, 2, . . . , c then C = {c1, . . . , cc}, where each element ui j indicates
the degree which element xi is a member of cluster c j. In hard clusters, an object’s
membership in a cluster is Boolean. In other words, the object both ﬁts to the cluster
or it does not. Rather, fuzzy clustering enables every item to belong to a number of
clusters, with degree of membership ranging from 0 to 1, depending on the distance
between the object and the cluster centers. The objective function is used continually
in an attempt to minimize the distance. The following objective function,
J =
n

i=1
K

j=1
U m
i j
xi −c j
2
1 ≤m < ∞
(1)

780
S. Nivetha and H. Hannah Inbarani
Table 1 Summary of related work
S. No
Modality
Authors
Dataset
Method
Outcomes and metrics
[8]
CT
Dhruv, B., et al.
15 Chest CT Imageries
Hybrid_Particle_Swarm_Optimized
and Fuzzy-C-Means_Clustering_based
segmentation
COVID-19 Lesion Image.
Metrics are entropy,
contrast, and standard
deviation
[9]
X-ray and CT
Chakraborty, S., et al.
Among COVID-19-positive
individuals in Italy, China, Iran,
Taiwan, Korea, and other
nations, 250 CT and 250 X-ray
images were collected
SUFMACS (SUperpixel-based Fuzzy
Memetic Advanced Cuckoo Search)
COVID-19 Segmented
Image. Based on the
number of cluster
calculated metrics are
Davies–Bouldin index,
Xie-Beni index, Dunn
index, β index
[10]
CT
Kumar, S. N., et al.
http://coronacases.org
Fast_Fuzzy_C means clustering
algorithm
Automatic ROI
extraction. Measures are
Partition Coefﬁcient (PC)
and Partition Entropy
(PE) measures
[11]
X-ray
Farki, A.,
Salekshahrezaee et al.
Wuhan University’s Renmin
Hospital and two important
hospitals in Guangzhou, Sun
Yat-sen Memorial Hospital and
Third Afﬁliated Hospital of
Sun Yat-sen University with 12
and 76 patients, respectively
Enhanced variation of the
Enhanced_Capsule_Network (ECN)
and an improved
Fuzzy_C-Ordered_Means (FCOM)
Segmented Image.
Metrics are 97.08%
Accuracy 97.29%
Precision, 97.18%,
Sensitivity, 97.47%
F1-Score
(continued)

Automated Histogram Binning-Based Fuzzy K-Means Clustering …
781
Table 1 (continued)
S. No
Modality
Authors
Dataset
Method
Outcomes and metrics
[12]
CT and X-ray
Shouvik Chakraborty
et al.
115 chest-related CT scanning
results
Superpixel-based_Fuzzy
_Modiﬁed_Flower
Pollination_Algorithm
Segmented COVID-19
Image. Metrics are
Davies–Bouldin index,
Xie-Beni index, Dunn
index, β index
Based on the number of
cluster

782
S. Nivetha and H. Hannah Inbarani
where K is the number of clusters, Ui j is the degree of participation of pixel xi
in the i-th group, ci is the cluster j’s centroid, and ||*|| is the Euclidean distance
between each pixel and the centroid, m is a constant value termed fuzziﬁer that exists
and regulates the solution set’s fuzziness. Fuzzy K-Means Clustering is explained
in [14]. Fuzzy partitioning is accomplished by iteratively optimizing the objective
function described above, with membership ui j and cluster centers vi updated as
follows,
ui j =
1
K
j=1
∥xi−c j∥
∥xi−ck∥

2
m−1
i = 1, 2, . . . , n
(2)
The membership functions and cluster centroids are updated using,
ci =
M
j=1 U m
i j .x j
M
j=1 U m
i j
(3)
4
Possibilistic Fuzzy C-Means Clustering
A work by Pal [15] suggested novel technique called Possibilistic Fuzzy C-Means
(PFCM), which combined PCM and FKM and solved numerous issues with PCM,
FKM, and PFCM. When executing classiﬁcation tests, J. C. and N. R. Bezdek Pal
proposed PFCM as a good clustering technique since it can inﬂuence the membership
value or canonical value signiﬁcantly. The noise sensitivity is determined by PFCM.
Possibilistic Fuzzy C-Means Clustering is explained in [14].
The usage of PFCM has been widespread in many different areas [16, 17] such as
“shell clustering”, “boundary detection”, and “surface and function approximations”
and has successfully solved a number of problems. Because a and b had been actually
ﬁxed to 1, it may be concluded that while computing centroids, both belonging and
probability, were equally important. Certain clustering conclusions lost some of their
clarity because PFCM incorporated variables a and b for belonging and probability
that showed the key importance in the formation of cluster centers.
Assume the following unlabeled datasets: X = {x1, . . . , xn} ⊂Rp_(p = n × s)
will be grouped into c(1 < c < n) clusters, a fuzzy subset. Here, n denotes the total
number of data points, and s, their individual dimensions. The following objective
functions are minimized to meet the goal of clustering X into c clusters.
j =
n

k=1
c

i=1

∝um
ik + βtτ
ik

d2
ik +
c

i=1
δi
n

k=1
(1 −tik)−τ
(4)

Automated Histogram Binning-Based Fuzzy K-Means Clustering …
783
Parameters α and β determine the relative importance of membership values
and typicality values. tik determines possibilistic membership degree. The Euclidean
distance between the j-th data and the i-th cluster center vector is given by the formula
d2
ik = ∥xk −vi∥. Cluster center vector is stated by V = {v1, v2, . . . , vc}, vi ∈Rs,
where δi > 0 is the typical possibilistic value. Here, the weighting exponents m >
1 and > 1 are used. Fix m > 1, τ > 1, ϵ > 0, and 1 < c < n. Pick v(0) ∈Rs, v(0)
can be preferred arbitrarily since X = {x1, x2, . . . , xn} ∈Rp. Using the following,
determine the fuzzy membership degree (uik), which decreases the objective function
Jm,τ.
u(l)
ik =
⎛
⎝
c

j=1

d2
ik
d2
jk

1
m−1 ⎞
⎠
−1
(5)
With the following formula, determine the probabilistic typical δi that minimizes
the objective function Jm,τ.
δ(l)
i
=
n
k=1

u(l)
ik
m
d2
ik
n
k=1

u(l)
ik
m
1 ≤k ≤n
(6)
With the following formula, determine the probabilistic typical tik that minimizes
the objective function Jm,τ.
t(l)
ik =

1 +
 β
δi
d2
ik

1
τ−1 −1
1 ≤i ≤c; 1 ≤k ≤n
(7)
Use the following to update cluster center vi, which minimizes the objective
function Jm,τ. Apply v(l)
i
to v(l−1)
i
using
v(l)
i
−v(l−1)
i
 < ϵ. If it is correct, stop.
Otherwise, set l = l + 1
v(l)
i
=
n
k=1

∝u(l)
ik
m
+

βt(l)
ik
τ
xk
n
k=1

∝u(l)
ik
m
+

βt(l)
ik
τ
1 ≤k ≤n
(8)
5
Proposed Histogram Binning-Based Fuzzy K-Means
Clustering (HBFKMC)
The separation of objects within an image might be mentioned as segmentation.
Clustering is generally employed to identify boundaries or objects within an image.

784
S. Nivetha and H. Hannah Inbarani
Deﬁning and examining the image at the end of the process would be simpler.
Nonparametric density estimators, such as histograms, are widely used for data visu-
alization and obtaining summary numbers. An image’s histogram, however, displays
the frequency of pixel intensity values. While segmenting images using the fuzzy
K-means clustering approach, the quantity of groups into which the image is to be
segmented must be speciﬁed to make the segmentation process automatic. The quan-
tity of groups in an image can be determined by looking at the histogram of the image.
Figure 1 depicts the proposed methodology for Histogram Binning-Based on Fuzzy
K-Means Clustering. Algorithm 1 depicts the pseudocode for Histogram Binning-
Based on Fuzzy K-Means Clustering. In this work, number of bins is computed
automatically based on the structure of the image using Struge’s rule.
Fig. 1 Proposed methodology for HBFKMC

Automated Histogram Binning-Based Fuzzy K-Means Clustering …
785
6
Performance Measure of Segmentation
To estimate the effectiveness of performance of each algorithm, the ratios of success-
fully recognized objects and regions are used. Several metrics are used to deter-
mine the efﬁciency across an entire set of images and then to measure how efﬁ-
cient the segmentation process is. These metrics include Accuracy, Precision, Recall,
Speciﬁcity, and F1-Score [18–20].
Input: Segmented Mask Image, D(x, y) = Input_Image, K = Bin_Value, m
= Fuzziﬁcation Value, ε = Threshold
Output: Clustered Image
Step 1: Input Segmented Mask Image as source D(x, y) Image.
Step 2: Apply Histogram-Based Equal Frequency Binning Method.
Step 3: Compute Number of Bins using Struge’s Rule, K = 1 + 3.322 logN.
K = Number of Bins, N = Number of Observations, Log = Logarithm of N.
Step 4: Create Histogram Width Frequency Binning (K = BINS = Number of
Clusters).
Step 5: Obtain number of bins K from the histogram.
Step 6: Compute each bin’s centroid value and set them as cluster centroids.
C = {c1, . . . , ck}
Step 7: Initialize Membership ui j.
ui j =
1
K
j=1
∥xi−c j∥
∥xi−ck∥

2
m−1
Step 8: Compute Distance
xi −c j
 between each pixel and the centroid.
J =
n

i=1
K

j=1
U m
i j
xi −c j
2
Step 9: Update Membership.
Step 10: Update Cluster Center.

786
S. Nivetha and H. Hannah Inbarani
vi =
M
j=1 U m
i j .xi
M
j=1 U m
i j
Step 11: Update Distance between clusters centers and pixels.
Step 13: Compute Objective Function as J′.
Step 14: If ||J −J′|| < ε Until the condition is satisﬁed.
Step 15: Reshape cluster pixels into an image.
Factors are used to evaluate the algorithm and the equations are given beneath,
Accuracy =
TP + TN
TP + FP + TN + FN
(9)
Precision =
TP
TP + FP
(10)
Recall =
TP
TP + FN
(11)
Speciﬁcity =
TN
FP + TN
(12)
F1-Score = 2 ∗Precision ∗Recall
Precision + Recall
(13)
where TP refers to True Positive; FP refers to False Positive; FN refers to False
Negative; TN refers to True Negative.
Structural Similarity Index Method
The structural similarity index is a method for determining exactly similar two images
seem [21].
SSIM(A, B) =
(2μAμB + C1)(2σ + C2)

μ2
A + μ2
B + C1

σ 2
A + σ 2
B + C2

(14)
where μA and μB denote the mean values of original and distorted images. And σA
and σB denote the standard deviation of original and distorted images, and σAB is the
covariance of both images and C1 and C2 are constants. For the proposed method-
ology, the loss of visual structure, brightness, contrast, and structure similarity are
measured. SSIM can serve as a second opinion to boost radiologists’ self-assurance.

Automated Histogram Binning-Based Fuzzy K-Means Clustering …
787
7
Results and Discussion
Anaconda3 is used to implement the proposed Histogram Binning-Based on Fuzzy
K-Means Clustering (HBFKMC) approach. For algorithm study and evaluation,
medical images of COVID have been considered source images. The dataset is avail-
able at the GitHub repository https://github.com/UCSD-AI4H/COVID-CT [22]. The
performance of the three algorithms Proposed HBFKM, FKM, and PFCM is shown
and compared in this section in terms of the ﬁndings. The values have been set to
modest values in several sets of original images: α = 1, β = 4, nc = 2, and max_iter
= 1000. In comparison with the traditional algorithms Fuzzy K-Means Clustering
(FKM), and Possibilistic Fuzzy C-Means (PFCM) that are frequently employed for
processing medical images and clustering ﬁelds, the results of the proposed approach
are shown in this part. The comparison compares the methods using COVID images
and ﬁve metrics: Accuracy, Precision, Recall, Speciﬁcity, and F1-Score [23, 24].
As shown in Table 2, the FKM and PFCM only reached 76.38 and 79.18% of the
Precision, respectively, and recall 76.03 and 79.02 for FKM and PFCM. It is evident
from Fig. 2 that the Proposed HBFCMC performs better at classifying attacks than
the current segmentation algorithm. The average of precision, recall, and F-measure
for all classes is used to specify the quantitative outcomes of precision, recall, and
F-measure.
Figure 3 shows the original image in the ﬁrst column, the proposed clustered
image in the second column to help determine how many clusters there are as (K),
the clustered image in the third column, and the extracted lungs in the fourth column
and infection of COVID-19 in the last column. It has been noted that better segmenta-
tion results are obtained in the proposed segmentation method. The original images
and the segmented outcomes of the FKM and PFCM are shown in Figs. 4 and
5. To present some of the images, the images are separated into ﬁgures as clus-
tered images, extracted lungs, and infection of the lungs as separate ﬁgures. These
outcomes demonstrate that the proposed model may effectively slice the chest CT
imageries using COVID-19.
Table 2 Comparison of the
proposed approach with
standard Fuzzy C-Means
algorithm and PFCM on
segmented images
Proposed HBFKMC
FKM
PFCM
Accuracy
85.08
76.05
79.00
Precision
85.28
76.38
79.18
Recall
85.00
76.03
79.02
Speciﬁcity
85.18
76.25
79.16
F1-Score
85.47
76.57
79.67

788
S. Nivetha and H. Hannah Inbarani
Fig. 2 Relative quantitative measures for COVID-19 segmentation
8
Conclusion
This study suggested a technique for segmenting lung infection regions from
a CT volume of a COVID-19 patient. In this study, the effectiveness of three
machine learning approaches Histogram Binning-Based on Fuzzy K-Means Clus-
tering (HBFKM), the Fuzzy K-Means (FKM), and Possibilistic Fuzzy C-Means
(PFCM) was evaluated for the detection of diseased regions in images of the lungs
taken from COVID-19 patients. The results of Healthy and diseased tissues may
be distinguished in COVID and NON-COVID images utilising Histogram Binning-
Based on Fuzzy K-Means Clustering (HBFKM). The supplied algorithm’s perfor-
mance was assessed using metrics including accuracy, sensitivity, F-measure, preci-
sion, and speciﬁcity, and metrics including the supplied algorithm’s performance
were assessed. The proposed method, followed by FKM and PFCM, respectively,
had the greatest accuracy 85.08% in COVID images. This indicates that, compared
to other algorithms, the proposed method may achieve the highest accuracy rate with
the original images. The proposed work can measure the COVID-19 lesion, depict
the infected region, and promptly help assess changes in the images. Additionally,
the suggested method can identify abnormal areas with minimal contrast between
lesions and healthy tissues.

Automated Histogram Binning-Based Fuzzy K-Means Clustering …
789
Fig. 3 Segmentation of the proposed HBFKMC for COVID images. a Actual imagery, b clustered
picture, c segmented picture, d segmented lung picture, e infection picture

790
S. Nivetha and H. Hannah Inbarani
Fig. 4 Segmentation of the Fuzzy K-Means Clustering for COVID picture. a Actual image, b
clustered picture, c segmented picture, d segmented lung picture, e infection picture

Automated Histogram Binning-Based Fuzzy K-Means Clustering …
791
Fig. 5 Segmentation of the Possibilistic Fuzzy C-Means Clustering for COVID images. a Actual
picture, b clustered picture, c segmented picture, d segmented lung picture, e infection picture
Acknowledgements The authors would like to thank UGC, New Delhi, for the ﬁnancial support
received under UGC-SAP No. F.5-6/2018/DRS-II (SAP-II).

792
S. Nivetha and H. Hannah Inbarani
References
1. Pal SK, King RA, Hashim AA (1983) Automatic grey level thresholding through index of
fuzziness and entropy. Pattern Recogn Lett 1:141–146
2. Batista J, Freitas R (1999) An adaptive gradient-based boundary detector for MRI images of
the brain. In: Image processing and its applications, Seventh international conference, vol 1,
pp 440–444, July 1999
3. Fan JP, Yau DKY, Elmagarmid AK (2001) Automatic image segmentation by integrating color
edge extraction and seeded region growing. IEEE Trans Image Process 10(10):1454–1466
4. Bleau A, Leon LJ (2000) Watershed-based segmentation and region merging. CVIU 77(3):317–
370
5. Abdulghafour M (2003) Image segmentation using fuzzy logic and genetic algorithms. J WSCG
11(1)
6. DeshmukhK,ShindeGN(2006)Anadaptiveneuro-fuzzysystemforcolorimagesegmentation.
J Indian Inst Sci 86:493–506
7. Moreira J, Da Fontoura Costa L (1996) Neural-based color image segmentation and classiﬁ-
cation using self-organizing maps. In: Anais do IX SIBGRAPI, pp 47–54
8. Dhruv B, Mittal N, Modi M (2022) Hybrid particle swarm optimized and fuzzy C mean
clustering based segmentation technique for investigation of COVID-19 infected chest CT. In:
Computer methods in biomechanics and biomedical engineering: imaging and visualization,
pp 1–8
9. Chakraborty S, Mali K (2021) SUFMACS: a machine learning-based robust image segmenta-
tion framework for COVID-19 radiological image interpretation. Exp Syst Appl 178:115069
10. Kumar SN, Ahilan A, Fred AL, Kumar HA (2021) ROI extraction in CT lung images of COVID-
19 using Fast Fuzzy C means clustering. In: Biomedical engineering tools for management for
patients with COVID-19. Academic Press, pp 103–119
11. Farki A, Salekshahrezaee Z, Toﬁgh AM, Ghanavati R, Arandian B, Chapnevis A (2021)
COVID-19 diagnosis using capsule network and fuzzy-means and mayﬂy optimization
algorithm. BioMed Res Int
12. Chakraborty S, Mali K (2021) SuFMoFPA: a superpixel and meta-heuristic based fuzzy image
segmentation approach to explicate COVID-19 radiological images. Exp Syst Appl 167:114142
13. Bezdek JC, Ehrlich R, Full W (1984) FCM: the fuzzy c-means clustering algorithm. Comput
Geosci 10(2–3):191–203
14. Yang Y, Zheng C, Lin P (2005) Fuzzy C-means clustering algorithm with a novel penalty term
for image segmentation. Optoelectron Rev 13(4):309
15. Pal NR, Pal KH, James MK (2005) A possibilistic fuzzy c-means clustering algorithm. IEEE
TFS 13(1):517–530
16. ChowdharyCL,Acharjya DP(2018)Segmentationofmammogramsusinga novel intuitionistic
possibilistic fuzzy c-mean clustering algorithm. Nat Inspired Comput 652:75–82
17. Askari S, Montazerin N, Zarandi MHF, Hakimi E (2017) Generalized entropy-based possi-
bilistic fuzzy C-Means for clustering noisy data and its convergence proof. Neurocomputing
219:186–202
18. Gite S, Mishra A, Kotecha K (2022) Enhanced lung image segmentation using deep learning.
Neural Comput Appl 1–15
19. Monteiro FC, Campilho AC (2006, September) Performance evaluation of image segmentation.
In: International conference image analysis and recognition. Springer, Berlin, Heidelberg, pp
248–259
20. Nivetha S, Hannah Inbarani H (2022) Neighborhood rough neural network approach for
COVID-19 image classiﬁcation. In: Neural processing letters. Springer, pp 1–23
21. Hore A, Ziou D (2010, August) Image quality metrics: PSNR vs. SSIM. In: 2010 20th
international conference on pattern recognition. IEEE, pp 2366–2369
22. https://github.com/UCSD-AI4H/COVID-CT.

Automated Histogram Binning-Based Fuzzy K-Means Clustering …
793
23. Nivetha S, Hannah Inbarani H (2022) Classiﬁcation of COVID-19 CT scan images using novel
tolerance rough set approach. In: Machine learning for critical internet of medical things.
Springer, Cham, pp 55–80
24. NivethaS,HannahInbaraniH(2021)PredictionofCOVID-19fatalitycasesbasedonregression
techniques. Eur J Molecular Clin Med 7(3):696–719

Darknet Trafﬁc Detection Using
Histogram-Based Gradient Boosting
Dane Brown
and Chikondi Sepula
Abstract The network security sector has observed a rise in severe attacks ema-
nating from the darknet or encrypted networks in recent years. Network intrusion
detection systems (NIDS) capable of detecting darknet or encrypted trafﬁc must be
developed to increase system security. Machine learning algorithms can effectively
detect darknet activities when trained on encrypted and conventional network data.
However, the performance of the system may be inﬂuenced, among other things,
by the choice of machine learning models, data preparation techniques, and feature
selection methodologies. The histogram-based gradient boosting strategy known as
categorical boosting (CatBoost) was tested to see how well it could ﬁnd darknet
trafﬁc. The performance of the model was examined using feature selection strate-
gies such as correlation coefﬁcient, variance threshold, SelectKBest, and recursive
feature removal (RFE). Following the categorization of trafﬁc as “darknet” or “reg-
ular”, a multi-class classiﬁcation was used to determine the software application
associated with the trafﬁc. Further study was carried out on well-known machine
learning methods such as random forests (RF), decision trees (DT), linear support
vector classiﬁer (SVC Linear), and long-short term memory (LST) (LSTM). The
proposed model achieved good results with 98.51% binary classiﬁcation accuracy
and 88% multi-class classiﬁcation accuracy.
Keywords Darknet · Boosting · Classiﬁcation · Feature selection · Network
security
https://www.ru.ac.za/computerscience/people/academicstaff/drdanebrown/. This work was under-
taken in the Distributed Multimedia CoE at Rhodes University.
D. Brown (B) · C. Sepula
Rhodes University, Drosty Rd, Grahamstown, 6140, South Africa
e-mail: d.brown@ru.ac.za
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_59
795

796
D. Brown and C. Sepula
1
Introduction
Hackers that conduct destructive attacks use the darknet or encrypted networks since
communication on these networks is anonymous. In contrast to traditional network
trafﬁc routing, in which sender identities such as IP addresses and port numbers
are public, the darknet utilises protocols that conceal user data, including identities,
location, preferences, and browsing behaviours. Tor and VPN are standard darknet
routing protocols (VPN) [1]. This darknet anonymity feature makes it more difﬁcult
for security professionals to track down cybercriminals. Consequently, preventing
darknet trafﬁc from accessing a network system is an effective and proactive method
for repelling darknet-based attacks.
The most common way to ﬁnd darknet trafﬁc is to use a database with signatures
of known darknet activity. If the signature of the incoming network trafﬁc matches
one of the known signatures in the database, a darknet ﬂag is set and access is limited.
When there is darknet trafﬁc whose signature is not in the database or has not yet
been identiﬁed, no darknet ﬂag is given, and hazardous darknet trafﬁc is allowed
access.
Since machine learning models are built using normal network data to ﬁnd trafﬁc
that is different from the norm, they may be able to ﬁnd both known and unknown
darknet trafﬁc. However, the performance of these systems remains an important
area of research, and the network security community continues to advocate machine
learning techniques for performance development. Literature indicates that boosting
algorithms perform pretty well in network data classiﬁcation [2–4, 10, 11, 14].
CatBoost is used in this study to classify darknet trafﬁc. A recent darknet dataset,
CIC-Darknet 2020, was used to evaluate the model. Other models such as RF, DT,
SVC Linear, and LSTM were examined to assess the comparative performance of
the proposed model.
The premise is that histogram-based gradient boosting ensembles may provide
more accurate classiﬁcations of darknet trafﬁc than well-known machine learning
methods.
The following are the most signiﬁcant contributions and aims attained by this
research.
1. A histogram-based gradient boosting approach for identifying darknet trafﬁc is
evaluated.
2. The performance of a darknet trafﬁc classiﬁer is tested using feature selection
algorithms.
3. A comparison of darknet trafﬁc classiﬁcation algorithms such as boosting, bag-
ging, distance-based, and deep learning.
4. Analysing how the synthetic minority oversampling approach (SMOTE) affects
the classiﬁcation of minority classes in the darknet dataset.

Darknet Trafﬁc Detection Using Histogram-Based Gradient Boosting
797
2
Literature Review
Several machine learning algorithms for categorising network trafﬁc have been pro-
posed. Deep learning models supplement traditional machine learning models such
as distance-based, bagging, and boosting. This article is about darknet trafﬁc.
Bakhareva et al. [2] determined the classiﬁcation effectiveness of CatBoost, SVC
Linear, light gradient boosting machine (LightGBM), and logistic regression models
on the CICIDS2017 network dataset. The trafﬁc was originally classiﬁed as “nor-
mal” or “malicious”, and then by the kind of assault, which included brute force, web
attack, bot, inﬁltration, portscan, and denial-of-service (DoS) attack. Data samples
wererandomlysplitinto50%trainand50%testsets.Modelparameterswerechanged
using grid search and ﬁvefold cross-validation. The CatBoost and LightGBM clas-
siﬁers were near-perfect: 99.98% and 99.96%, respectively. Precision scores were
lower for both linear SVC and logistic regression.
Extreme gradient boosting (XGBOOST) was suggested by Bansal and Kaur [3]
as an effective means of network data categorization. The Bakhareva et al. [2] attack
utilised the same CICIDS2017. The suggested model was assessed and compared to
MLP, k-nearest neighbour (KNN), Naive Bayes, and adaptive boosting (AdaBoost).
Initially, the data were preprocessed by giving numerical values to class labels. Nor-
malised sample values ranged from 0 to 1. With a score of 99.54%, the suggested
XGBOOST model has the best accuracy.
A machine learning-based NIDS system with NSL-KDD network training was
developed by Khafajeh [10]. The system was evaluated using the DT, RF, AdaBoost,
KNN, SVC Linear, logistic regression, and MLP algorithms. Attacks included probe,
root-to-local (R2L), denial-of-service(DoS), andunauthorised-to-root (U2R). Model
parameters were adjusted to increase performance. The most effective technique was
LightGBM’s 98.30% accuracy approach.
A deep learning darknet trafﬁc detection system was created using CIC-Darknet
2020 data. Habibi Lashkari et al. [8] updated and integrated the ISCXVPN2016 and
ISCXTor2017 databases to create the former data. This CIC-Darknet 2020 dataset
was shown to be highly representative of the real world and is thus used in this
research. Signiﬁcant properties were identiﬁed and chosen prior to feeding the data
to the deep learning classiﬁer. While multi-class classiﬁcation identiﬁed the trafﬁc
application, binary classiﬁcation classiﬁed the data as “normal” or “darknet”. The
application classes included surﬁng, email, ﬁle sharing, P2P, chat, streaming audio
and video, and voice-over-Internet (VOIP). Accuracy, recall, precision, and f1-score
for binary classiﬁcation were all 86%.
Deep learning was used by Sarwar et al. [14] to detect darknet activity on the
same CIC-Darknet 2020 darknet dataset. They contrasted DT with RF. Missing,
redundant, and undeﬁnable data sample rows were eliminated during data cleaning.
SMOTE was utilised to resolved class imbalances for the dataset as disparities in
classes samples were large. 20 important characteristics were retrieved using PCA
for classiﬁcation, and the model was modiﬁed to perform better. The model has 89%
f1-score, 95% accuracy, 90% precision, and 88% recall.

798
D. Brown and C. Sepula
Fig. 1 The darknet trafﬁc detection system design
The CIC-Darknet 2020 dataset was again evaluated on darknet trafﬁc. Gupta et
al. [7] produced a detection system trained using XGBOOST. Trafﬁc types included
standard,Tor,andVPNcontrastingtheNaiveBayes,LSTM,KNN,andRFclassiﬁers.
The data were scaled from 0 to 1 and undeﬁned and inﬁnite values were changed to
−1. Correlation coefﬁcients eliminated extraneous traits. The model’s accuracy was
98%.
In spite of the fact that boosting algorithms outperform other common machine
learning models, they have not been exhaustively examined for nighttime trafﬁc
detection. Due to this deﬁciency, this research studies CatBoost ensemble for darknet
trafﬁc identiﬁcation further.
3
The Proposed System
Based on the standard design in the literature [5, 6, 12, 13, 15], the proposed
darknet trafﬁc detection system has three primary stages: data preprocessing, fea-
ture engineering, and model testing and tuning. Data preparation consists of cleans-
ing, formatting, sampling, and scaling data. Following this is feature engineering,
which removes redundant and useless features in order to choose important traits
that improve model performance. Use was made of correlation coefﬁcient, variance
threshold, exploratory data analysis (EDA), SelectKBest, and RFE feature selection
techniques. Figure1 illustrates the proposed technique for detecting darknet trafﬁc.

Darknet Trafﬁc Detection Using Histogram-Based Gradient Boosting
799
3.1
Data Preprocessing
The Canadian Institute of Cyber-Security website1 was used to get the CIC-Darknet
2020dataset.Ithastwotargetclasses,79characteristics,and158,659samplesintotal.
Non-Tor, Tor, non-VPN, and VPN are the four labels for the ﬁrst target class. Audio-
streaming, browsing, chat, email, ﬁle-transfer, video-streaming, P2P, and VOIP are
the eight application labels for the second target class.
Data Cleaning: The darknet dataset had 47 samples with missing, duplicate, or unde-
ﬁned values, much as typical network data. These samples were excluded because
their percentage is small; hence, their removal would have no effect on the training
of the model.
In Listing 1, the code to detect and discard samples with missing or undeﬁned
values is provided.
1
is_na_cols
=
df_2 . columns [ df_2 . isna ().sum ()
>
0]
2
df_2
=
df_2 . dropna ()
Listing 1 Dropping samples with “nan” values
Data Formatting: For binary classiﬁcation, the four classes in the ﬁrst target vari-
able were reduced to two classes. The labels “Non-Tor” and “Non-VPN” have been
changed to “Normal”, while the labels “Tor” and “VPN” have been changed to
“Darknet”. Several misspelt class names in the second target class were rectiﬁed.
Listing 2 provides the code required to delete the four columns. These columns
are deleted because they are features that are not independent or reliable.
1
df_3
=
df_2 . copy ()
2
3
del
df_3 [" Flow
ID"]
4
del
df_3 [" Timestamp "]
5
del
df_3 ["Src
IP"]
6
del
df_3 ["Dst
IP"]
Listing 2 Deleting irrelevant columns from the dataset
For binary classiﬁcation, the labels were coded as “Benign” for “Non-Tor” and
“Non-VPN” trafﬁc and “Darknet” for “VPN” and “Tor” trafﬁc as shown in Listing 3.
1
df_2 [" Label "]. loc [( df_2 [" Label "]
==
"Non - Tor")
|
( df_2 [" Label "
]
==
" NonVPN ")]
=
" Benign "
2
df_2 [" Label "]. loc [( df_2 [" Label "]
==
"Tor")
|
( df_2 [" Label "]
==
"VPN")]
=
" Darknet "
Listing 3 Reducing the target class labels to binary
Listing 4, on the other hand, deﬁnes multi-class labels by using the map function
to deﬁne the applications that each relate to a binary class.
1 https://www.unb.ca/cic/datasets/darknet2020.html-Accessed 23 October 2022.

800
D. Brown and C. Sepula
1
df_3 [" Label "]
=
df_3 [" Label "]. map ({" Benign ":1," Darknet " :0})
2
3
df_3 [" Label .1"]
=
df_3 [" Label .1"]. map ({"Audio - Streaming ":1,"
Browsing ":2," Chat ":3,
4
" Email ":4,"File - Transfer ":5,"P2P":6,"Video - Streaming ":7,"
VOIP " :8})
Listing 4 Target class label encoding
Data Sampling: Random samples of the data were divided into 80% training and
20% testing. A substantial amount of data is given to the training split in order to
develop a model that generalises effectively to unknown data.
Data Scaling: Different scales of feature values had little effect on the majority
of models, notably the tree-based ones assessed in this research. MinMaxScaler of
Scikit, which is identical to Data Normalisation, was used to scale the sample values
for improved data analysis and display.
3.2
Feature Selection
The effect of feature engineering on model performance was investigated using a
variety of feature selection strategies. Initially, redundant characteristics were deleted
based on a correlation coefﬁcient criterion of 0.80. When two characteristics have a
correlation coefﬁcient close to 1, they have the same effect on the target class and are
thus redundant. Using a variance threshold of 0.00001, a collection of weak features
was discarded. Close to zero variance features consist of constant values that cannot
determine or aid in predicting the target class.
The code for these eliminated features based on the obtained correlation coefﬁ-
cients and variance is shown in the following Listing 5.
1
corr_matrix
=
df_train . corr (). abs ()
2
thresh
=
0.8
3
4
upper
=
corr_matrix . where (np. triu (np. ones ( corr_matrix . shape ),
k=1). astype ( bool ))
5
to_drop_corr
=
[ column
for
column
in
upper . columns
if
any(
upper [ column ]> thresh )]
6
7
var_thr
=
VarianceThreshold ( threshold
=
0.00001)
8
var_thr .fit ( X_train_mms )
9
var_thr . get_support ()
10
to_drop_thresh
=
[ column
for
column
in
X_train_mms . columns
if
column
not
in
X_train_mms . columns [ var_thr . get_support () ]]
11
12
X_train_d
=
X_train_mms . drop ( to_drop_corr ,
axis =1)
13
X_train_d
=
X_train_d . drop ( to_drop_thresh ,
axis =1)
14
X_test_d
=
X_test_mms . drop ( to_drop_corr ,
axis =1)
15
X_test_d
=
X_test_d . drop ( to_drop_thresh ,
axis =1)
Listing 5 Dropping redundant and weak features based on correlation coefﬁcient and variance
threshold
The data was plotted using EDA techniques like as violinplots, swarmplots, and
heatmaps in order to identify and further minimise features that were determined to

Darknet Trafﬁc Detection Using Histogram-Based Gradient Boosting
801
Table 1 Features selected based on correlation coefﬁcient, variance, and EDA techniques
No.
Selected features
1
Src port
2
Dst port
3
Protocol
4
Flow duration
5
Fwd packet length max
6
Fwd packet length min
7
Bwd packet length min
8
Bwd packet length mean
9
Flow packets/s
10
Flow IAT mean
11
Fwd IAT std
12
Bwd IAT std
13
Fwd PSH ﬂags
14
FIN ﬂag count
15
RST ﬂag count
16
PSH ﬂag count
17
Subﬂow Fwd packets
18
FWD Init win bytes
19
Idle mean
20
Idle std
be redundant and ineffective at discriminating target groups. As shown in the Table1,
20 important features were ultimately selected for the categorising procedure.
To determine which method of feature selection provides the most accurate model,
SelectKBest and RFE were applied to choose 20 features independently. SelectKBest
was used to choose the best features from the list produced by an ANOVA function,
and the RF estimator was implemented in the RFE.
3.3
Model Training and Tuning
Since tuning many parameters of the suggested model did not enhance performance,
the default values were kept. According to the CatBoost docs, the model’s param-
eters may be adjusted automatically; thus, tweaking is not necessary to get good
performance.

802
D. Brown and C. Sepula
Table 2 CatBoost accuracy scores and training time on different input data dimensions
No. of Features
Accuracy (%)
Training time (s)
79 features
98.70
61
20 features
98.51
41
3.4
Hardware and Software
The machine learning models for the system were developed and deployed using
the following platform. The system was built using a locally sourced desktop PC
with CPU: Intel(R) Core(TM) 3.60GHz 6 Cores, RAM: 16GB, and GPU: NVIDIA
GeForce GTX 750 Ti.
The packages and requirements for the utilised software platform were as follows:
Microsoft Windows 10 Education OS, Python 3.10.6, Tensorﬂow 2.6.3, Sklearn
1.0.2, and Keras 2.6.0).
4
Experimentation and Results
Four experiments were carried out in order to test the hypothesis and achieve the
study’s objectives. The system’s performance was evaluated using accuracy, preci-
sion, recall, f1-score, and model training time. When there are no class imbalances,
accuracy, which assesses the overall accuracy of the system, is primarily utilised
in binary classiﬁcation. However, during multi-class classiﬁcation, only precision,
recall,andf1-scorewererecordedsinceaccuracywasunabletoofferareﬂectivescore
due to class imbalances in the second target class. The computational performance
of the system was assessed by collecting the training time.
4.1
Experiment 1
The purpose of this experiment was to see how feature selection inﬂuences model
performance. First, the model was trained on all 79 attributes, and the training time
and accuracy were recorded. Second, the model was trained on the 20 important
characteristics, and the same metrics were gathered. Training the model on the input
data prior to feature selection resulted in a slightly better accuracy score of 98.70%
compared to 98.51%, as shown in Table2. Training the model with reduced input
data dimensions, on the other hand, took 41s to 61s less time. As a result, feature
selection improved the model’s computational efﬁciency, allowing it to be used in
circumstances where system computing is critical.

Darknet Trafﬁc Detection Using Histogram-Based Gradient Boosting
803
Table 3 CatBoost model accuracy scores based on the three feature selection techniques
Feature selection technique
Accuracy (%)
EDA-based
98.45
SelectKBest
98.25
RFE
98.51
4.2
Experiment 2
Thesecondexperiment’sobjectivewastoassessthethreefeatureselectionapproaches
used in this research. The model was trained and evaluated independently using the
input features picked by each of the three feature selection procedures. The initial set
of characteristics was chosen based on the correlation coefﬁcient, variance threshold,
and EDAs. The remaining two sets were chosen using SelectKBest and RFE. The
following accuracy scores were reported in Table3.
With an accuracy score of 98.51%, the RFE approach surpassed the other two
feature selection procedures. This might be because RFE applies an estimate on a
set of features in order to calculate a signiﬁcance score and exclude weak features.
The univariate approach of seleckbest, on the other hand, examines the relevance of
individual traits.
4.3
Experiment 3
The hypothesis of this research was evaluated in Experiment 3. With the exception
of LSTM, which does not need feature selection, the proposed CatBoost algorithm
and other well-known machine learning algorithms were assessed using 20 carefully
chosen characteristics. As demonstrated in Table4, the CatBoost model surpassed all
other models with a 98.51% accuracy rate, as expected. The beneﬁt of this algorithm
is that it is an ensemble, a collection of weak learners that operate sequentially,
each increasing the performance of the preceding learner [9]. The second high-
performing algorithm is an RF algorithm that is also an ensemble. SVC Linear had
the lowest accuracy score of 85.94%. This low performance might be attributable to
the nonlinearity of darknet data. SVC Linear is a linear model that might fail to ﬁt
well on nonlinear data, resulting to poor generalisation on unknown data.
As its tree structure is more basic than that of an ensemble, which is a collection
of trees, the DT model needed the least amount of time to train.

804
D. Brown and C. Sepula
Table 4 Accuracy scores and training time for all the models
Model
Train accuracy (%)
Test accuracy (%)
Train time (s)
DT
97.87
98.04
1
RF
98.22
98.34
21
SVC linear
68.54
85.94
20
LSTM
95.67
96.85
180
CatBoost
98.33
98.51
30
Fig. 2 Second target class data distributions of the darknet trafﬁc before SMOTE
4.4
Experiment 4
In this experiment, trafﬁc was characterised and the application linked with the
trafﬁc was discovered. As a result of class disparities, SMOTE was implemented to
oversample the minority classes. Figure2 illustrates the distribution of data among
the minority classes of the second target class. This chart demonstrates that the
class disparities are large and, if not corrected, will lead to biased ﬁndings. When
categorising data, the model tends to choose or favour the majority classes.
Before and after the use of SMOTE, the CatBoost model was examined to deter-
mine its inﬂuence on model prediction. Table5 displays the accuracy, recall, and
f1-score performance values of the model before to the application of SMOTE. The
model achieved an overall accuracy of 89.99%, while individual accuracies are shown
in Table5.
The model was assessed again after applying SMOTE, and performance scores
were collected, as shown in Table6, with an average class accuracy of 87.96%.
The improvement in accuracy and f1-score of almost all minority groups is a major
ﬁnding from the Tables5 and6 shown. Precision has evolved tremendously, making
it very sensitive to class disparities. Prior to the oversampling of minority classes,

Darknet Trafﬁc Detection Using Histogram-Based Gradient Boosting
805
Table 5 Trafﬁc characterisation scores before SMOTE
Class (1–8)
Precision (%)
Recall (%)
F1-score (%)
Audio-streaming
91.15
88.10
89.60
Browsing
95.96
89.15
92.43
Chat
84.59
72.31
77.97
Email
51.92
79.03
62.67
File-transfer
79.44
91.84
85.19
Video-streaming
97.96
97.62
97.79
P2P
69.76
80.70
74.83
VOIP
53.90
58.46
56.09
Table 6 Trafﬁc characterisation scores after SMOTE
Class (1–8)
Precision (%)
Recall (%)
F1-score (%)
Audio-streaming
85.92
93.08
89.35
Browsing
92.73
90.74
91.72
Chat
63.52
91.47
74.97
Email
61.37
68.33
64.66
File-transfer
83.72
83.18
83.45
Video-streaming
96.83
98.26
97.54
P2P
81.98
72.16
76.76
VOIP
89.08
41.21
56.35
the model was biassed towards classes with more samples in the dataset; hence, the
accuracy score for majority classes declined as predicted. With the use of SMOTE,
the total accuracy decreases, proving that accuracy is not an acceptable measure
for data with class imbalances. The initial accuracy score was high; however, it did
not accurately represent the model’s performance. The model categorised video-
streaming application-related trafﬁc with good accuracy, recall, and f1-score.
In multi-class classiﬁcation, the model’s total accuracy of 87.96% is greater than
the 86% attained by Habibi Lashkari et al. [8] in a comparable investigation. Simi-
larly, the suggested model’s 98.51% accuracy for binary classiﬁcation beats previous
experiments presented in this study [7, 8, 14] supporting the hypothesis.
5
Discussion
Multiple feature selection strategies were used to increase system performance.
To assess the system, four tests were carried out. The ﬁrst experiment measured
system accuracy and training duration to see whether feature selection approaches
were necessary. The second experiment compared the system performance differ-

806
D. Brown and C. Sepula
ences between the feature selection approaches used. In the third experiment, sev-
eral machine learning algorithms, including the suggested CatBoost, were assessed.
The previous experiment used multi-class classiﬁcation to classify network trafﬁc
depending on the linked trafﬁc application. Due to class imbalances, however, an
oversampling strategy was applied to avoid biassed ﬁndings.
The suggested machine learning method scored the best in terms of accuracy.
When it came to categorising darknet trafﬁc, the DT and RF algorithms performed
marginally worse than the former. All of the tree-based models in our study required
the least amount of training time. The distance-based and deep learning models, on
the other hand, achieved poor accuracy scores with the longest training period. It
was also revealed that the feature selection approaches used in this study increased
system efﬁciency but not accuracy. Finally, despite applying oversampling to minor-
ity classes to correct class imbalances, the model still produced poor performance in
minority classes, which should be examined further in the future.
6
Concluding Remarks
The CIC-Darknet 2020 dataset was used to evaluate a darknet trafﬁc identiﬁcation
system created utilising a histogram-based gradient boosting algorithm. There were
three main stages to the system: data preparation, feature engineering, and model
testing and ﬁne-tuning. The following ﬁndings have been derived from the many
experiments conducted as part of this investigation: (1) Feature selection improved
the system’s computational performance by requiring less time to train. (2) When
compared to SelectKBest and other univariate procedures, the RFE feature selection
strategy delivers better results for the model. (3) In terms of detecting darknet traf-
ﬁc, the CatBoost model outperformed bagging, tree-based, linear, and deep learning
models. (4) Tree-based algorithms have comparable performance ratings in dark-
net trafﬁc detection. (5) While SMOTE improves model classiﬁcation, the darknet
dataset’s large class imbalances impair model performance. Still, improvements are
noticed in the unrepresented classes.
References
1. Abu Al-Haija Q, Krichen M, Abu Elhaija W (2022) Machine-learning-based darknet trafﬁc
detection system for IoT applications. Electronics 11(4):556
2. Bakhareva N, Shukhman A, Matveev A, Polezhaev P, Ushakov Y, Legashev L (2019) Attack
detection in enterprise networks by machine learning methods. In: 2019 international Russian
automation conference (RusAutoCon). IEEE, pp 1–6
3. Bansal A, Kaur S (2018) Extreme gradient boosting based tuning for classiﬁcation in intrusion
detection systems. In: International conference on advances in computing and data sciences.
Springer, pp 372–380

Darknet Trafﬁc Detection Using Histogram-Based Gradient Boosting
807
4. Bhati BS, Chugh G, Al-Turjman F, Bhati NS (2021) An improved ensemble based intrusion
detection technique using XGBOOST. Trans Emerg Telecommun Technol 32(6):e4076
5. Chindove H, Brown D (2021) Adaptive machine learning based network intrusion detection.
In: Proceedings of the international conference on artiﬁcial intelligence and its applications.
ACM, pp 1–6
6. Chindove H, Brown D (2021) Adaptive network intrusion detection using optimised machine
learning models. In: Southern Africa telecommunication networks and applications conference,
pp 1–6
7. Gupta N, Jindal V, Bedi P (2022) Encrypted trafﬁc classiﬁcation using extreme gradient boost-
ing algorithm. In: International conference on innovative computing and communications.
Springer, pp 225–232
8. Habibi Lashkari A, Kaur G, Rahali A (2020) Didarknet: a contemporary approach to detect
and characterize the darknet trafﬁc using deep image learning. In: 2020 the 10th international
conference on communication and network security, pp 1–13
9. Ke G, Meng Q, Finley T, Wang T, Chen W, Ma W, Ye Q, Liu TY (2017) Lightgbm: a highly
efﬁcient gradient boosting decision tree. Adv Neural Inf Process Syst 30
10. Khafajeh H (2020) An efﬁcient intrusion detection approach using light gradient boosting. J
Theor Appl Inf Technol 98(5):825–835
11. Kumar S, Vranken H, van Dijk J, Hamalainen T (2019) Deep in the dark: a novel threat detection
system using darknet trafﬁc. In: 2019 IEEE international conference on big data (big data).
IEEE, pp 4273–4279
12. Le Jeune L, Goedemé T, Mentens N (2021) Machine learning for misuse-based network intru-
sion detection: overview, uniﬁed evaluation and feature choice comparison framework. IEEE
Access
13. Mohan L, Jain S, Suyal P, Kumar A (2020) Data mining classiﬁcation techniques for intrusion
detection system. In: 2020 12th international conference on computational intelligence and
communication networks (CICN). IEEE, pp 351–355
14. Sarwar MB, Hanif MK, Talib R, Younas M, Sarwar MU (2021) Darkdetect: Darknet trafﬁc
detectionandcategorizationusingmodiﬁedconvolution-longshort-termmemory.IEEEAccess
9:113705–113713
15. Seniaray S, Jindal R (2022) Machine learning-based network intrusion detection system. In:
Computer networks and inventive communication technologies. Springer, pp 175–187

Investing in Products with the Greatest
Demand on Online Stores During
the Pandemic
Titan Hassya, Muhammad Fauzi Hanif, Alvian, Ford Lumban Gaol,
and Tokuro Matsuo
Abstract From the year 2019, every aspect of our lives has been negatively impacted
as a result of the spread of a deadly disease known as COVID-19, particularly
the health and business domains. The primary goal of this study is to develop a
solution, or at the very least an overall analysis, to the readers on how to overcome
the economic crisis during pandemic.
Keywords Investing · Greatest demand · Online stores
1
Introduction
On December 31, 2019, reports from civilians regarding diseases occurring in the
lungs were discovered in Wuhan City, which is located in the capital of Hubei
Province, China, resulting the Chinese health department to report an outbreak of a
new disease, called COVID-19 [1]. The disease started to spread across other loca-
tions of the country in only a matter of a few days. On the beginning of April 2020, the
pandemic began to be regulated in China by taking a number of preventive measures,
for example patient isolation, usage of protective suits, and medical control. Albeit
these efforts, the disease quickly spread, resulting the total COVID-19 cases to exceed
1 million and increasing rapidly afterward.
Nowadays, online shopping has become a popular way of shopping for everyone
all over the world [2]. This technology assists vendors to interact with consumers will
T. Hassya · M. F. Hanif · Alvian · F. L. Gaol (B)
Information Systems Department, School of Information Systems, Bina Nusantara University,
Jakarta, Indonesia 11480
e-mail: fgaol@binus.edu
F. L. Gaol
Computer Science Department, BINUS Graduate Program—Doctor of Computer Science, Bina
Nusantara University, Jakarta, Indonesia 11480
T. Matsuo
Advanced Institute of Industrial Technology, Tokyo, Japan
e-mail: matsuo@aiit.ac.jp
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_60
809

810
T. Hassya et al.
not only generate a large number and variety of merchandise to potential consumers
but also skyrockets numerous business activities.
Due to various advantages, people always mentioned that they prefer online
shopping over the conventional in-store shopping nowadays. Online shopping or
marketing via Internet is the use of technology via computer to increase the sales [3].
Online shopping is a type of electronic commerce that allows buyers and sellers
to transact directly from a vendor via the Internet, a website, or a mobile application.
Consumers begin the transaction by identifying a product that interests them by
visiting the company’s website directly or by using a search engine to locate third-
party vendors or dropshippers; the search engine then displays the product’s current
stock and pricing at various vendors [4]. Customers will be able to shop online using
a variety of unique gadgets and devices such as smartphones, Smart TVs, and desktop
computers [5, 6].
During the pandemic, people preferred online stores to purchase their necessities
remotely without visiting the store physically [7, 8].
2
Literature Review
Online stores have recently been a topic of discussion, and during the COVID-
19 pandemic, the discussions about online stores have skyrocketed. According to
a Netcomm Suisse Observatory report on COVID-19 and e-commerce, consumers
tend to focus their purchases on essential products, shop more frequently online, and
prefer to browse and spend more time on digital store and entertainment sites [9, 10].
1. COVID-19 and E-commerce by UNCTAD
According to the study, participants from every country show sign of lowering their
average expenditures per online transaction for the majority of the categories [11,
12]. Media, food, beverage, and gardening are the only categories that have seen a
visible increase. The decline rates are visible for categories that involve recreation,
such as travel tourism, consumer electronics, and fashion, exhibiting a great example
of why the pandemic has affected many parts of the economy, some of which have
been negatively impacted.
This study analyzes how many people have started to rely on online shopping and
incorporated it into their daily lives. This study helps to learn more about the data
and provide readers with solutions, which they may ﬁnd useful [13, 14].
Thisstudyintendstoguideanymainplayersinonlineshopping,suchasmarketers,
directors or even customers and ﬁnd different ways to effectively utilize their role
in online shops [15]. The information in this article will be useful for further
analyzing the consumer demand and thus improving the system used in online shop
applications/websites.
2. E-commerce trends during COVID-19 Pandemic

Investing in Products with the Greatest Demand on Online Stores During …
811
The literature concludes that they have reviewed and investigated the effects and risks
of the currently ongoing outbreak. The literature states that the authors are interested
in how coronavirus spreads worldwide and how it affects the e-commerce not only in
China rather how it affects globally. Making others aware of the problem will allow
readers to gain more information and knowledge about how the pandemic is affecting
e-commerce, business, and national economies [16]. How it affects e-commerce will
encourage other researchers to gain more insights on this area, such as e-commerce
trends and how they are affected by the pandemic, as well as trends in the upcoming
generation [17].
The existing research studies are only focused on which category product has the
highest demand for investors and data analysts to study, but the proposed research
study will not be limited to that aspect; this does not mean that other categories
outside of online shops cannot beneﬁt from this research.
3
Research Design and Methods
Since the performed research study theoretically has an unspeciﬁed scope that is done
onpurposetoanalyzeandobtainageneralconclusion,thedatamustbeextractedfrom
consumers from various regions around the world by performing online quantita-
tive research from countries all over the world. This study is conducted during the
COVID-19 period; hence, no face-to-face interviews were possible. The best way
to obtain accurate data is to obtain it from reliable secondary sources, and the data
utilized in this study is obtained from UNCTAD [18].
UNCTAD is a division of the United Nations that manages and is responsible for
various departments such as trade, investment, and economic problems [19]. Their
goal is to increase trade, investment, and other forms of assistance to developing
countries to develop a global economy. UNCTAD conducted the following survey
in collaboration with several companies, including Netcomm Suisse eCommerce
Association, Inveon, and the Brazilian Network Information Center (NIC.br) [20].
Brazil, China, Germany, Italy, the Republic of Korea, the Russian Federa-
tion, South Africa, Switzerland, Indonesia, and Turkey were among the countries
surveyed. As for secondary sources, we will use the Indonesia Data.
Our main concerns are mostly on what consumers prefer to buy nowadays, but
they are not limited to the time when COVID-19 began to strike around March 2020.
Our sample will be collected in Indonesia, where the data was collected.
The graphs above in Figs. 1 and 2 show the percentage of different types of goods
purchased by online shoppers, as well as their age. We can see that food and beverages
are in high demand during the pandemic, but this does not necessarily mean that this
is the best category for investors to invest in. Other categories, such as household
goods, cosmetics, and electronics, do not appear to be far behind in terms of demand.
Table 1 lists the top ten most popular online websites in descending order based
on the number of users. Table 1 does not necessarily provide a solution to which good
category is best to invest in but rather serves as a useful information. Information

812
T. Hassya et al.
Fig. 1 Active online shoppers during COVID-19 [21]
Fig. 2 Result of the tendency of shopping on the COVID-19 outbreak [18]
analysts make recommendations for how the organization should proceed and predict
the future consumer demand.

Investing in Products with the Greatest Demand on Online Stores During …
813
Table 1 Top ten website that
most online websites used
[20]
Sr.no.
Retail website
Millions
1
Amazon.com
4059M
2
Ebay.com
1227M
3
Rakuten.co.jp
804M
4
Samsung.com
648M
5
Walmart.com
614M
6
Appel.com
562M
7
Aliexpress.com
532M
8
Etsy.com
395M
9
Homedepot.com
292M
10
Allegro.pl
272M
(Andrienko, 2020)
4
Conclusion
COVID-19 has created a negative impact on global business; even though it mostly
has a negative impact, there are a few cases where it has a positive impact. Overall,
the pandemic is causing an increase in e-commerce. Coronavirus has compelled
consumers and sellers to engage in any type of interaction via internet and consider
it as a part of their daily routine. Aside from that, vendors in e-commerce will face
numerous challenges, including longer delivery time, social distance, and lockdown.
E-commerce players are experiencing a signiﬁcant increase in volume and
vendors must be prepared to overcome any obstacles in their power to keep their
new customers and visitors through various interactions such as promotions and
product range expansion. Consumers can now use price engines and referral sites as
a feature within the store to ﬁnd the best deals online, increasing competition.
5
Implications and Contributions to Knowledge
The proposed research work is very essential for any type of readers, especially the
ones who are looking to invest on selling goods in online shops. However, this is
only available for non-investors such as those who play a role in an online shop (or
those who is planning to) to adjust their view on consumers, since they are mostly
not relying on the conventional methods anymore.
Readers can also utilize this research to further improve their performance and
gain a signiﬁcant advantage in understanding what their clients and consumers want
to have their hands on by providing the most effective user-friendly approach.

814
T. Hassya et al.
There are several practical implications that readers can obtain in this research,
such as improving conventional methods of shopping to online shopping or prior-
itizing the reader’s funds or main attention to another category that may seem
ﬁt.
According to the study, the greatest shift in people migrating to online shopping
has occurred among consumers and retailers in emerging economies, particularly
in developing countries. Consumer transactions in the most product categories have
increased by 6–10%, with information and communications technology, pharmaceu-
ticals, education, household products, and cosmetics showing the greatest gains thus
far. With the conclusions in mind, this study has provided indispensable facts that are
not limited to the source of the data. According to the study, in the current epidemic,
users are more likely to order food and beverages from online stores. It is recom-
mended that the government maintain and prioritize regulations to ensure the hygiene
of food sold online. This study demonstrates the overall effects and the silver lining
of how successful online shops at the country level, based on either private or public
cooperation, have been critical in responding quickly to the pandemic disaster and
limiting its negative consequences. It investigates the protocol measures on which the
private sector has the most global inﬂuence in order to support COVID-19 restoration
plans.
References
1. Adika R, Subandrio S (2021) The effect of electronic commerce and brand awareness on
purchasing decisions at shopee online shopping. BIMA J: Bus Manage Account J 2(1):53–66.
https://doi.org/10.37638/bima.2.1.53-66
2. Afrianto AP, Irwansyah I (2021) Exploration of community conditions in choosing online
shopping through shopee during the covid-19 pandemic in Indonesia [Eksplorasi Kondisi
Masyarakat dalam Memilih Belanja Online melalui Shopee Selama masa Pandemi Covid-
19 di Indonesia]. Jurnal Teknologi Dan Sistem Informasi Bisnis 3(1):10–29. https://doi.org/
10.47233/jteksis.v3i1.181
3. Agustini P (2021) Netizens increase, Indonesia needs to increase cultural values
on
the
internet
[Warganet
Meningkat,
Indonesia
Perlu
Tingkatkan
Nilai
Budaya
di Internet]. Kominfo. https://aptika.kominfo.go.id/2021/09/warganet-meningkat-indonesia-
perlu-tingkatkan-nilai-budaya-di-internet/
4. Amrullah MF (2021) The effect of celebrity endorser, brand image, and electronic word of
mouth on purchases of shopee E-commerce users in Indonesia [Pengaruh Celebrity Endorser,
Brand Image, dan Elektronic Word of Mouth terhadap Pembelian Pada Pengguna E-Commerce
Shopee di Indonesia]. J Econ Bus Entrepreneurship 2(1):1–5. https://doi.org/10.29303/alexan
dria.v2i1.28
5. Batubara BS, Rini ES, Lubis AN (2021) Effect of customer trust, tagline, ﬂash sale, and ease
of use on purchasing decisions (case study on shopee marketplace users in Medan City). Int J
Res 8(2):107–112. https://doi.org/10.52403/ijrr.20210218
6. iPrice (2021) Explore the competition of online stores in Indonesia (Telusuri Persaingan Toko
Online di Indonesia). iPrice Group Sdn Bhd. https://iprice.co.id/insights/mapofecommerce/
7. Baubonien˙e Ž, Guleviˇci¯ut˙e G (2015) E-commerce factors inﬂuencing customers’ online
shopping decision. Socialn˙es Technologijos 5(1):62–73. https://doi.org/10.13165/ST-15-5-
1-06

Investing in Products with the Greatest Demand on Online Stores During …
815
8. Javadi MHM, Dolatabadi HR, Nourbakhsh M, Poursaeedi A, Asadollahi AR (2012) An analysis
of factors affecting on online shopping behavior of customers. Int J Mark Stud 4(5):81. https://
doi.org/10.5539/ijms.v4n5p81
9. hatti A, Rehman SU, Kamal AZ, Akram H (2021) Factors effecting online shopping behaviour
with trust as moderation. Jurnal Pengurusan, 60:109–122. https://doi.org/10.17576/pengur
usan-2020-60-09
10. Javed SA, Javed S (2015) The impact of product’s packaging color on customers’ buying
preferences under time pressure. Mark Branding Res 2(1):4–14. https://doi.org/10.33844/mbr.
2015.60293
11. Ching KC, Hasan ZRA, Hasan NA (2021) Factors inﬂuencing customers in using shopee for
online purchase intention in East Coast Malaysia. UMT J Undergraduate Res 3(1). https://doi.
org/10.46754/umtjur.2021.01.006
12. Neger M, Uddin B (2020) Factors affecting consumers’ internet shopping behavior during the
covid-19 pandemic: evidence from Bangladesh. Chin Bus Rev 19(3):91–104. https://doi.org/
10.17265/1537-1506/2020.03.003
13. Cho YC, Sagynov E (2015) Exploring factors that affect usefulness, ease of use, trust, and
purchase intention in the online environment. Int J Manage Inf Syst 19(1):21–36. https://doi.
org/10.19030/ijmis.v19i1.9086
14. Bhatti A, Akram H (2020) E-commerce trends during COVID-19 Pandemic. https://www.res
earchgate.net/publication/342736799_E-commerce_trends_during_COVID-19_Pandemic
15. Gupta P (2011) Shopping impulses, online vs off. The New York Times. https://www.nyt
imes.com/roomfordebate/2011/12/01/save-america-shop-at-work/shopping-impulses-online-
vs-off. Accessed on 23 Oct 2021
16. Handayani NT, Usman O (2021) The effect of online customer review, inﬂuencer marketing,
quality website on purchase decisions online on online marketplace shopee. SSRN. https://doi.
org/10.2139/ssrn.3768483
17. Hermawan DJ (2021) Factors affecting interest in buying online [Faktor-Faktor Yang Mempen-
garuhi Minat Beli Online]. Jurnal Ilmiah Ecobuss, 9(2):100–110. https://doi.org/10.51747/eco
buss.v9i2.848
18. Hertanto AD, Sulhaini HLE (2020) Effect of ﬂash sale method, product knowledge and in
home shopping tendency toward customer online purchase decisions. RJOAS, 6(102):2020–06.
https://doi.org/10.18551/rjoas.2020-06.12
19. Huseynov F, Yıldırım SÖ (2016) Internet users’ attitudes toward business-to-customer online
shopping: a survey. Inf Dev 32(3):452–465. https://doi.org/10.1177/0266666914554812
20. Husti I, Mahyarni M (2019) Islamic leadership, innovation, competitive advantages, and perfor-
mance of SMEs in Indonesia. East Asia 36(4):369–383. https://doi.org/10.1007/s12140-019-
09325-7
21. UNCTAD (2020) Covid-19 and E-commerce ﬁndings from a survey of online consumers in 9
countries, 21. https://unctad.org/system/ﬁles/official-document/dtlstictinf2020d1_en.pdf

Estimation of Queuing System Incoming
Flow Intensity
Alexander Zyulkov, Yury Kutoyants, Svyatoslav Perelevsky,
and Larisa Korableva
Abstract An estimation of the intensity of the incoming ﬂow of requests and
its statistical properties using maximum likelihood method is made based on the
provided basic probabilistic model of the utilization factor of a single-channel
queuing system. It is shown that the synthesized estimate can be explicitly repre-
sented analytically and allows a technically much simpler implementation compared
to its common analogues, with comparable or better accuracy and shorter observation
time intervals. The obtained theoretical results are conﬁrmed experimentally during
simulation by means of AnyLogic software.
Keywords Queuing system · Flow intensity · Utilization factor · Probabilistic
model · Probabilistic mixture · Maximum likelihood estimate · AnyLogic
environment · Reinforcement learning
1
Introduction
When choosing the number of CPUs and memory capacity during the system design
phase, developers must evaluate the performance of the computer systems in order to
A. Zyulkov (B)
Voronezh State University, Voronezh, Russia
e-mail: a.v.zyulkov@mail.ru
Y. Kutoyants
Le Mans University, Le Mans, France
e-mail: youri.koutoyants@univ-lemans.fr
National Research University “MPEI”, Moscow, Russia
Y. Kutoyants · S. Perelevsky
National Research Tomsk State University, Tomsk, Russia
e-mail: s.perelevskiy@mail.ru
L. Korableva
Moscow State University, Moscow, Russia
e-mail: mail@mse-msu.ru
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_61
817

818
A. Zyulkov et al.
select the best conﬁguration. Queuing systems and networks are frequently employed
for this purpose as models in order to simulate stochastic dynamic behaviour and
quantify system performance. It entails simulating incoming and servicing process
requests. Based on the observation of the other system characteristics, their intensity
must be set.
In [1], the arrival rate and service rate in a straightforward queue are estimated
after observing a sequence of incoming and outgoing requests at a predetermined
time. Based on the data on the waiting time in the queue, [2] estimates the service
time and waiting time in the GI|G|1 system. The examination of the estimated arrival
and service rates is the main topic of [3]. In a M|M|K system, it is applied to data
on queue length at subsequent time periods. One takes into account the estimated
arrival and service rates in the M|M|1 system in [4]. In [5], it is discussed how to
use the data on the arrival and service times of requests to calculate the M|M|1
queuing system’s arrival and service rates. An empirical Bayesian technique is used
to complete this task. Based on the data on the M|M|1 system load, the volume of
trafﬁc is approximated in [6].
It is assumed in [2, 3] and [7] that the arrival time and the number of arrivals
throughout the period are observable, i.e. that the precise job arrival time and service
time are known. The observational data that can be used for evaluation in the analysis
of computer system arrival processes, however, is relatively constrained.
Utilization data, which is deﬁned as time series data consisting of time fractions
of busy times in the predeﬁned time intervals, is one of the observable system char-
acteristics of systems. They are used in real life to describe server conditions like
CPU use. According to the deﬁnition of usage data, data collection only takes place
during a sequence of discrete time intervals, and there is a gap in the data between
two adjacent time intervals. The only data available for computer systems is usage
data.
It is shown in [8] that the numerical maximum likelihood estimate (MLE) of the
intensity of the incoming ﬂow of requests can be found based on the utilization data
by using the EM algorithm, which is a popular method for iterative calculation of
the MLE based on the observed data and is presented in [9, 10]. However, both the
algorithm and its execution are quite challenging. Even so, using [8] as a starting
point, it is possible to create a straightforward probabilistic model of the system
utilization factor (UF) that may be used to summarize and later analyse the intensity
estimation procedure.
The goal of this work is to identify the probabilistic and statistical properties of the
MLE of the intensity of the incoming ﬂow of requests, which enables a signiﬁcantly
more practical implementation than typical counterparts. They can be assessed by
contrasting them with the simulation results of the synthesized estimation technique.

Estimation of Queuing System Incoming Flow Intensity
819
2
Incoming Flow Intensity Estimate
The presented model of the probability density of the random UF variable is made
of a mixture of discrete and uniform continuous probability densities. It has been
studied in detail and substantiated in a number of studies taking the form [11]:
w(u) = P0δ(u) + P01 + P1δ(u −1),
(1)
P0 = P(U = 0), P01 = P(0 < U < 1), P1 = P(U = 1)
P0(λ, μ) =

μ exp(−λ(1 −d)) −λ exp(−μ(1 −d))
+λ −μ]/(λ −μ)(1 −exp(−λ)),
P1(λ, μ) = λ(exp(−μ) −exp(−λ))/(λ −μ)(1 −exp(−λ)),
P01(λ, μ) = exp[−μ(1 −d)] −exp[−λ(1 −d)] −λ exp(−μ) −μ exp(−λ)
(λ −μ)

1 −exp(−λ)

.
Only the weight parameters of this mixture depend on the intensity of the incoming
ﬂow λ, the intensity of service μ and the fraction of the time of the UF calculating d.
It can be shown that they contain complete information about the value of λ, and in
the considered range of its values under the ﬁxed μ and d, they can be approximated
with high accuracy by second-order polynomials.
It is possible to estimate λ from the observed data
• using analytical expressions for the probabilities P0, P01, P1 ﬁnding the estimates
of the parameter λ for each of them, and then—their weighted sum;
• by the method of moments;
• by the maximum likelihood method.
The ﬁrst two listed methods are actually the implementation of the method of
moments. Therefore, they have all the disadvantages inherent in this method [12].
When they are applied, the estimates can be found easily, but they are extremely
sensitive to the ﬂuctuations in the observed data and, accordingly, to the accuracy of
estimating the probabilities P0, P01, P1. In view of this, in our work, the MLE will be
used as an estimate of the intensity λ, taking into account its many advantages. The
MLE is found as the position of the absolute maximum of the likelihood function
L(λ). This estimate is sufﬁcient and also asymptotically (with an increasing sample
size) efﬁcient, unbiased and normal [13, 14].
In [11], it was shown that the observed data (the number of the zero, intermediate
and unit values of utilization—N0, N01 and N1, respectively) has a polynomial distri-
bution. As a result, the likelihood function L(λ) and its logarithm M(λ) = ln L(λ) for
the data set with the volume N = N0 + N01 + N1 allow the following representation:
L(λ) = P N0
0 (λ)P N01
01 (λ)P N1
1 (λ),
(2)

820
A. Zyulkov et al.
Fig. 1 Form of the logarithm of the likelihood function (3) for λ0 = 1 and one of the simulation
realizations plotted following the exact formulas for P0, P01, P1 (1) (the curve 1) and its quadratic
approximation applied (the curve 2)
M(λ) = N0 ln P0(λ) + N01 ln P01(λ) + N1 ln P1(λ),
(3)
Taking into account, following [8], the possible low values of the parameter λ,
to ﬁnd the MLE one can apply the quadratic approximation of the logarithm of the
likelihood function.
In Fig. 1, as an illustration, the diagrams of the logarithm of the likelihood func-
tion M(λ) are presented for the one of the realizations obtained by simulating the
system with the real value of the intensity of the incoming ﬂow of requests λ0 = 1.
The dependences M(λ) are plotted according to the Formula (3) using the obtained
exact relations for P0, P01, P1 (the curve 1) and the quadratic approximation of the
likelihood function (curve 2).
Figure 1 demonstrates that these functions change smoothly in the considered
range of values of the parameter λ. This allows concluding that simple approximation
formulas for estimating λ can be reasonably accurate. In addition, it can be noted
that for this particular realization of the observed data, the MLE value λ (the position
of the M(λ) maximum) differs from the real value of the parameter λ0.
The explicit analytical expression for the MLE, found from the solution of the
probability equation for the chosen parameter values (μ = 10, d = 0.05), takes the
form:
λm ≈(22.37N0 −1.25N1 −18.94N)/(−2.42N0 + 0.0091N1 + 3.34N)
(4)
This relation is given for the ﬁxed parameters μ and d due to the cumbersomeness
of the general formula. The value obtained by replacing the frequencies N0/N and
N1/N in (3) by the probabilities P0(λ, μ), P1(λ, μ) (1), on average, does not differ
signiﬁcantly from the real value of λ due to the good accuracy of the quadratic
approximation of probabilities.

Estimation of Queuing System Incoming Flow Intensity
821
Table 1 Real values of the parameter λ, sample means λm and sample mean square deviations σ
of the MLE λm
λ
0.2
0.5
1.0
1.5
2.0
2.2
λm
0.190 ± 0.006
0.520 ± 0.009
1.01 ± 0.01
1.48 ± 0.014
1.99 ± 0.018
2.215 ± 0.0019
σ
0.097 ± 0.004
0.140 ± 0.006
0.160 ± 0.008
0.21 ± 0.06
0.27 ± 0.017
0.30 ± 0.02
Statistical characteristics of the MLE λm can be determined by averaging
according to the multinomial distribution (3) that the sample of the observed data
(UF values) obeys
P(N0 = n0, N01 = n01, N1 = n1) =
n!
n0!n01!n1! Pn0
0 (λ, μ)Pn01
01 (λ, μ)Pn1
1 (λ, μ).
Table 1 shows the sample means λm and mean square deviations σ of the MLE
(3) resulting from the AnyLogic software-based [15] simulation including 1000 runs
of 200 one-second observation intervals at μ = 10, d = 0.05. The parameters are
speciﬁcally chosen for the comparison with the results from [8]. The values in Table
1 are given with errors calculated in the ±2σ.
In Table 1, one can see that the estimate has a small bias and a relatively small
mean square error. The form of its probability density changes with λ. Since all the
expansions in the approximations used to obtain (3) have been performed in the
neighbourhood of λ = 1, then, at this point, the characteristics of the approximate
MLE should coincide with the properties of a reliable estimate. Indeed, according
to the simulation results, the MLE distribution coincides with the Gaussian one with
a signiﬁcance level of 0.57. With a change in λ, the signiﬁcance value decreases
substantially.
In Fig. 2, there are
• the relative error δ1(λ) =

λm −λ

/λ expressed represented as rectangles and
Fig. 2 Expressed as percentage, the relative error (rectangles) and the relative mean square error
(circles) of the incoming ﬂow intensity MLE, in their dependence on λ

822
A. Zyulkov et al.
• the relative mean square error δ2(λ) = 0.1σ

λ represented as circles, both are
expressed as percentage and dependent on λ.
The given estimate characteristics can be compared with the results [8] obtained
using the Markov approach [16] to the synthesis of the likelihood function and the EM
algorithm for determining the incoming ﬂow intensity MLE at intervals. It follows
from this comparative analysis that the proposed approach, being much simpler, has
similar (at least not worse) accuracy characteristics. In addition, it is possible to
write down an analytical expression for the desired MLE, which also simpliﬁes its
technical implementation.
3
Conclusion
The M|M|1 queuing system’s utilization factor is represented by the approximate
analytical probabilistic model (1), which is shown as a distribution mixture. Its advan-
tages are (1) it is easily implemented, (2) it has great accuracy, and (3) it is supported
by the outcomes of the simulation. Based on the information that is now accessible
regarding the use of this model, it can be used as a fundamental tool for synthesizing
the system parameter estimation techniques.
The simple maximum likelihood estimate synthesized with its help is unbiased and
relatively easy to implement in practice. The possibility of applying this estimate for
determining the intensity of the incoming ﬂow of requests by the system utilization
factor at short observation time intervals is conﬁrmed by the results of simulation.
Thus, the approach realized includes the following stages: (1) simulation of the
initial problem; (2) developing the theoretical model of the observed data following
the results of the simulation; (3) synthesizing approximate MLE according to the
simulation model; (4) analysing the statistical characteristics of the estimate in terms
of its simulation model. This approach allows producing relations for the estimate of
the intensity of the incoming ﬂow of requests that are quite accurate and relatively
simple, compared with the ones introduced in the common studies.
The approach and results presented in this study are partially valid for a non-
uniform Poisson ﬂow of requests arriving for servicing. Since only a small part of
the observation interval is used to measure the UF, the ﬂow in this interval can often
be considered uniform.
In previous studies, the conditions for the validity of the model considered in the
work were formulated. When they are realized, no more than one event is observed
associated with the beginning or end of servicing the request in a short sub-interval
of each one-second interval. If the formulated conditions are satisﬁed, then the model
remains valid for several demand service devices.
The possibility of interfacing the simulation in the AnyLogic environment with
the reinforcement learning (the Bonsai platform) opens up the prospects for obtaining
stable functional structures in the problem under consideration in the case when a
priori assumptions about the initial parameters are violated.

Estimation of Queuing System Incoming Flow Intensity
823
Acknowledgements This research was ﬁnancially supported by the Russian Science Foundation
(research project No. 20-61-47043).
References
1. Thiruvaiyaru D, Basawa IV, Bhat UN (1991) Estimation for a class of simple queueing
networks. Queueing Syst 9:301–312
2. Basawa IV, Bhat UN, Lund R (1996) Maximum likelihood estimation for single server queues
from waiting time data. Queueing Syst 24:155–167
3. Ross JV, Taimre T, Pollett PK (2007) Estimation for queues from queue length data. Queueing
Syst 55:131–138
4. Pant AP, Ghimire RP (2015) M(t)/M/1 queueing system with sinusoidal arrival rate. J Inst Eng
11:120–127
5. Thiruvaiyaru D, Basawa IV (1992) Empirical Bayes estimation for queueing systems and
networks. Queueing Syst 11:179–202
6. Choudhury A, Basak A (2018) Statistical ınference on trafﬁc ıntensity in an M/M/1 queueing
system. Int J Manag Sci Eng Manag 13:274–279
7. Dharmaraja S, Trivedi K, Logothetis D (2003) Performance modeling of wireless networks
with generally distributed handoff interarrival times. Comput Commun 26:1747–1755
8. Li C, Okamura H, Dohi T (2019) Parameter estimation of M-t/M/1/K queueing systems with
utilization data. IEEE Access 7:42664–42671
9. Hastie T, Tibshirani R, Friedman J (2001) The elements of statistical learning. Data mining,
ınference, and prediction. Springer, New York
10. McLachlan GJ, Krishnan T (2008) The EM algorithm and extensions. Wiley-Interscience,
Cambridge
11. Zyulkov A, Kutoyants Y, Perelevskiy S, Korableva L (2022) Single channel queuing system
utilization factor model. J Phys Conf Ser 2388:1–7
12. Cramer G (1951) Mathematical methods of statistics. Princeton University Press, Princeton
13. Ibragimov IA, Has’minskii RZ (1981) Statistical estimation. Asymptotic theory. Springer,
NewYork (1981)
14. Van Trees HL, Bell KL, Tian Z (2013) Detection, estimation and modulation theory, Part I.
Detection, estimation, and ﬁltering theory. Wiley, New York
15. Borshchev A, Grigoryev I (2020) The big book of simulation modeling. Multimethod modeling
with AnyLogic 8. AnyLogic North America, Oakbrook Terrace
16. Okamura H, Dohi T, Trivedi KS (2009) Markovian arrival process parameter estimation with
group data. IEEE/ACM Trans Networking 17:1326–1339

Statistical Characteristics of the Adjacent
Information Signals Amplitude Ratio
Oleg Chernoyarov, Alexey Glushkov, Vladimir Litvinenko,
Alexandra Salnikova, and Kaung Myat San
Abstract When the phase-shift keyed signals (PSK and DPSK) are detected, the
ratio of the amplitudes of adjacent information symbols at the demodulator’s output
is used to process the differential amplitude and phase-shift keyed signals (DAPSK),
among other things. It is also used to evaluate the quality of a functioning communi-
cation channel and measure the channel signal-to-noise ratio. It is suggested to apply
the logarithm of the adjacent information symbol amplitude ratio as a decision-
making statistic because, in the absence of a signal, its properties only depend on
the signal-to-noise ratio, while, in the presence of a signal, its probabilistic charac-
teristics do not depend on the level of interferences. Consideration is given to the
proposed statistics’ probabilistic properties and their potential applications. Statis-
tical simulation is implemented for the PSK signal when the relevant calculation
relations are achieved.
Keywords Phase-shift keyed signal · Decision determining statistics · Adjacent
symbol amplitude ratio · Probability of exceeding the threshold · Signal detection ·
False alarm and missing probabilities
1
Introduction
In the case of phase-shift (PSK) and frequency-shift keyed (FSK) signals, the pulse
shape deviates from a rectangular one at the output of a narrowband transmission line,
however in this situation, the relationship between the received symbol amplitude and
receiver response level is linear. In the case of the amplitude and phase-shift keyed
O. Chernoyarov (B) · A. Salnikova · K. M. San
National Research University “MPEI”, Moscow, Russia
e-mail: chernoyarovov@mpei.ru
A. Glushkov
Zhukovsky-Gagarin Air Force Academy, Voronezh, Russia
V. Litvinenko
Voronezh State Technical University, Voronezh, Russia
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_62
825

826
O. Chernoyarov et al.
(APSK) signals, the symbol amplitudes change, but their ratio a remains unchanged
(for example, 3 or 1/3 [1, 2] or other options 2.5, 1.4 [3–5]) at different gains of the
receiving path. In these applications, the ratio of the adjacent symbol amplitudes can
be used to demodulate a signal or control a demodulator.
When a signal is detected (for example, the PSK one) [6–8], it is necessary to
establish its presence in a noisy channel. In the absence of a signal, the responses
of the amplitude estimation channel obey a Rayleigh probability distribution [9] and
the ratios of their neighboring values are characterized by a signiﬁcant statistical
variation. In the presence of a signal, this variation decreases with the increasing
signal-to-noise ratio (SNR), which can be used to determine if a signal is present.
The efﬁciency of detectors depends on the amount of a priori information about
the levels and properties of signals and noise [9–11]. In this case, the actual task is to
develop detection algorithms providing a false alarm probability that is independent
of the noise level. It can be solved using the amplitude ratio of the adjacent symbols.
Using a sampling of the amplitude ratios ensures a speciﬁed reliability of the obtained
solutions and allows controlling the quality of the operating communication channel
and estimating the SNR.
A similar approach using the ratio of the energy parameters of the two adjacent
symbols can be used in the processing and demodulation of statistical signals with
relative modulation formats [12].
The choice of the logarithm of the ratio of the amplitudes of the adjacent symbols
as a sign of the presence of a signal or a characteristic of the levels of relative
amplitude keying is due to the simplicity of implementation and the absence of the
need to interfere with the data ﬂow.
Thus, the study of the probabilistic properties of the ratio of the symbol amplitudes
is quite relevant.
2
Signal and Noise Models
Here the discrete signals, i.e., PSK and FSK signals, whose amplitudes are
independent of the transmitted information, are investigated. They take the form
s(t) = S cos[2π f0t + ψ(t)]
with the constant amplitude S, the carrier frequency f0, and current phase ψ(t).
Although the pulse shape is modiﬁed at the transmission path output, the magnitude
of the response at the symbol end in the absence of interference is still unrelated
to the transmitted messages [6]. The presence of interference affects the amplitudes
of the adjacent symbols, and their dissimilarity, calculated from the ratio of their
amplitudes, can be used to assess the SNR in the communication channel without
affecting the data transmission process.
When there is Gaussian noise n(t) or there are both noise and signal at the demod-
ulator input, the response samples ξk of the amplitude estimation channel (where k is

Statistical Characteristics of the Adjacent Information Signals …
827
the number of the current symbol) at the end of each symbol reception is determined
by the clock synchronization signal. When only noise is present, such samples obey
the Rayleigh law of distribution with the probability density [7–11]
wn(x) = x exp

−x2/2σ 2
n

/σ 2
n ,
x ≥0.
(1)
But they obey the Rice law of distribution with the probability density [7–11]
ws(x) = x exp

−

x2 + S2
/2σ 2
n

I0

xS/σ 2
n

/σ 2
n ,
x ≥0
(2)
in the presence of both information signal and noise. Here σ 2
n is the noise dispersion
at the receiver input and I0(x) is the zero-order modiﬁed Bessel function.
3
Symbol Amplitude Ratio
The ratio of the amplitudes of the adjacent symbols at the output of the amplitude
estimation channel is
Yk = ξk/ξk−1.
(3)
But, as the decision determining statistics it is more expedient to use the logarithm
of this magnitude
Gk = loga Yk = loga(ξk/ξk−1).
(4)
For the DAPSK signals, the base a of the logarithm can be chosen equal to the ratio
of the maximum and minimum symbol amplitudes (for example, a = 3 [1, 2]). As
for the signals with a constant symbol amplitude, it is advisable to take the logarithm
in (4) as the natural one, that is,
Gk = ln(ξk/ξk−1).
(5)
Decisions about the received signals (for example, about their detection) can be
made by the sampling Gk (5), of the size N, and k = 1, N. It is obvious that the
neighboring values Yk and Yk−1 are dependent, since they include the same value
ξk−1. To ensure the independence of the amplitude ratios, they must be determined for
the individual pairs of ξk samples, but in this case, the sampling size of Gk samples
is halved. For independent values of Gk, a binomial probability distribution can be
used, and for dependent ones a model based on a simple Markov chain [13] is true.

828
O. Chernoyarov et al.
4
The Properties of the Amplitude Ratio in the Absence
of a Signal
According to [14], the probability density u(y) of the ratio (3) of the random variables
ξk and ξk−1 with the same probability densities w(x) (1) or (2) is
u(y) =
∞

0
w(x)w(yx)|x|dx
(6)
and then, correspondingly, the probability density f (g) of the values Gk (5) can be
obtained as
f (g) = exp(g)u(exp(g)).
(7)
Accounting for (1) and based on (6), and in the presence of noise only, after
calculating the integral, the probability density un(y) of the ratio (3) takes the form
un(y) = 2y/

1 + y22,
y ≥0
(8)
and from (7) and (8), for fn(g), one gets respectively:
fn(g) = 2 exp(2g)/

1 + exp(2g)
2.
One can see that these probability densities—un(y) and fn(g)—are independent
of the noise dispersion, their graphs are presented in Fig. 1a, b.
Fig. 1 The probability densities of the adjacent symbol amplitude ratio (a) and its logarithm (b) in
the absence of a signal

Statistical Characteristics of the Adjacent Information Signals …
829
The mean value of the ratio Yk (3) is Ymean =
 ∞
0
yun(y)dy = π/2, while the
variance tends to inﬁnity. For the logarithmic measure Gk (5), the mean value is
equal to 0, while the variance is
σ 2
G =
∞

−∞
g2 fn(g)dg = π2/12 = 0.822.
(9)
The curve fn(g) is symmetric to the y-axis and more feasible for use in comparison
with un(y). Positive values of g correspond to the region of relations y > 1, and the
negative values of g correspond to y < 1, respectively.
Now it is time to determine the probability pn(b) that the modulus of the logarithm
of the ratio of amplitudes |Gk| exceeds the speciﬁed threshold b:
pn(b) = 1 −
b

−b
fn(g)dg = 2/

1 + exp(2b)

.
(10)
This dependence is represented in Fig. 2. As it can be seen, at b < 0.5, the
probability (10) is quite high, meaning that it can serve as an indicator of the absence
of a signal that is independent of the noise dispersion.
Since the neighboring samples of the amplitude ratio Yk and Yk−1 are dependent,
it is necessary to consider their joint probability density.
Now, the notation is
Zk = Yk−1Yk,
(11)
then, accounting for (3),
Fig. 2 The probability of exceeding the threshold by the modulus of the logarithm of the adjacent
symbol ratio in the absence of a signal

830
O. Chernoyarov et al.
Zk = ξk−1
ξk−2
ξk
ξk−1
=
ξk
ξk−2
.
(12)
The magnitude Zk is, on the one hand, the product of the amplitude ratio, and, on
the other hand, it is the amplitude ratio with the probability density (8). According
to [14], the probability density of the product Z = Y1Y2 of the random variables Y1
and Y2 with the joint probability density wn(y1, y2) is
w(z) =
∞

−∞
w

y1, z
y1
	 1
|y1|dy1.
(13)
For the conditional probability density wn( yk|yk−1), based on (8) and accounting for
(11) and (13), one can write
wn( yk|yk−1) = 2y2
k−1yk/

1 + (yk−1yk)22.
(14)
Then for the joint probability density of the amplitude ratio in the absence of a
signal, accounting for (8), (14), one gets:
wn(yk−1, yk) = un(yk−1)wn( yk|yk−1) =
4y3
k−1yk

1 + y2
k−1
2
1 + (yk−1yk)22 .
(15)
It easy to see that
∞

0
∞

0
wn(yk−1, yk) = 1
and also, following from (13), (14), the probability density of the random variable
(11), (12) takes the form
wn(z) =
∞

0
wn

yk−1,
z
yk−1
	
1
|yk−1|dyk−1 =
2z
(1 = z)2
and coincides with that in (8).
According to (7), (15) the joint probability density of the neighboring logarithmic
measures Gk−1, Gk (5) is
wn(gk−1, gk) =
4 exp(4gk−1) exp(2gk)

1 + exp(2gk−1) exp(2gk)
2
1 + exp(2gk−1)
2 ,
(16)
its three-dimensional diagram is shown in Fig. 3.

Statistical Characteristics of the Adjacent Information Signals …
831
Fig. 3 Two-dimensional probability density of the logarithm of the ratio of amplitudes (5) in the
absence of a signal
It follows from (16) that the correlation coefﬁcient of the values Gk−1 and Gk (5)
is equal to −1, and the sequence of Gk forms a simple Markov chain.
5
The Properties of the Amplitude Ratio in the Presence
of a Signal
In the presence of a signal, the probability density ws(x) of the signal amplitudes is
described by the Rice formula (2) and the probability density us(y) of their ratio (3),
following (6) is
us(y) =
∞

0
ws(x)ws(yx)|x|dx.
(17)
After setting the SNR as
h2 = S2/2σ 2
n .
(18)
and changing the variables v = x/σn, from (17), one gets
us(y) =
∞

−∞
yv3 exp

−

v2 + (yv)2 + 4h2
/2

I0

vh
√
2

I0

yvh
√
2

dv.
(19)
Based on (7), the expression for the probability density of the logarithm of the
adjacent symbol amplitude ratio (5) is now produced:

832
O. Chernoyarov et al.
fs(g) = exp(g)us(exp(g)).
(20)
The integrals (19) and (20) are calculated numerically only. But, if h ≫1 (18),
then using Gaussian approximation of the Rice distribution (2) and following (19),
(20), one obtains
us(y) = h (1 + y) exp

−h2(1 −y)2/

1 + y2
/

π

1 + y23,
(21)
fs(g) = h exp(g)(1 + exp(g))

π(1 + exp(2g))3
exp

−h2(1 −exp(g))2/(1 + exp(2g))

.
(22)
As it can be seen, the one-dimensional probability densities us(y), fs(g) depend
only on SNR (18). Their diagrams are shown in Fig. 4a and b, respectively, for the
case when h2 = 10. The solid lines describe the exact dependences (17), (20), and the
dashed lines—the approximate ones (21), (22), and that, as the graphs demonstrate,
have satisfactory accuracy for h2 ≥10.
According to the outcomes of numerical calculations, the mean value of the
random variable (5) can practically be taken equal to zero, then its variance is
determined by the expression
σ 2
G =
∞

−∞
g2 fs(g)dg.
(23)
The dependence of σ 2
G (23) on SNR h2 (expressed in dB) is represented by the
solid line in Fig. 5, with the dashed line demonstrating the value of the variance σ 2
G
Fig. 4 The probability densities of the adjacent symbol amplitude ratio (a) and its logarithm (b) in
the presence of a signal

Statistical Characteristics of the Adjacent Information Signals …
833
(9) in the absence of a signal being 0.822. One can see that an increase in the signal
level results in a decrease in the variance of the logarithm of the adjacent symbol
amplitude ratio, and that can be used to detect a signal or to estimate SNR in an
operating channel.
It is of interest to calculate the probability ps(b) that the modulus of the logarithm
of the ratio of the amplitudes |Gk| will exceed the speciﬁed threshold b in the presence
of a signal. Taking into account (22), one gets
ps(b) = 1 −
b

−b
fs(g)dg.
(24)
The dependences (24) for various SNR (18) are plotted in Fig. 6. There, the curve
1 corresponds to h2 = 10, the curve 2—to h2 = 20, the curve 3—to h2 = 30, the
curve 4—to h2 = 40. The dashed line represents the curve in the absence of a signal
(Fig. 2).
It follows from (19), (20), (24) and Fig. 6 that the probability of exceeding the
threshold decreases with the increase in the SNR, and it is independent of the
noise level, meaning that its estimate can be used to control the quality of the
communication channel.
In the presence of a signal, the neighboring values of the amplitude ratios are
interdependent, and introducing their product
Zk = Yk−1Yk,
(25)
by analogy with (13)–(15), one can write the expression for the conditional
probability density
ws( yk|yk−1) =
hyk−1(1 + yk−1yk)

π

1 + (yk−1yk)23 exp

−h2(1 −yk−1yk)2
1 + (yk−1yk)2

.
Fig. 5 The variance of the logarithm of the adjacent symbol ratio

834
O. Chernoyarov et al.
Fig. 6 The probability of exceeding the threshold by the modulus of the logarithm of the adjacent
symbol ratio in the presence and absence of a signal
while for the joint probability density of the amplitude relations one gets
ws(yk−1, yk) =
h2yk−1(1 + yk−1)(1 + yk−1yk)
π

1 + y2
k−1
3
1 + (yk−1yk)23
exp

−h2

(1 −yk−1yk)2
1 + (yk−1yk)2 + (1 −yk−1)2
1 + y2
k−1

.
(26)
It
easy
to
see
(for
example,
by
the
numerical
integration)
that
 ∞
0
 ∞
0 ws(yk−1, yk)dyk−1dyk
= 1 and the probability density of the random
variable (25) which can be found as
us(z) =
∞

0
ws

yk−1,
z
yk−1
	
1
|yk−1|dyk−1
coincides with (21).
From (26), it follows that the joint probability density of the logarithmic measures
Gk−1 and Gk, accounting for (20), is
ws(gk−1, gk) = h2
π
exp(2gk−1 + gk)

1 + exp(gk−1)

1 + exp(gk−1 + gk)


1 + exp(2gk−1)
3
1 + exp(2(gk−1 + gk))
3
× exp

−h2
 (1 −exp(gk−1 + gk))2
1 + exp(2(gk−1 + gk)) + (1 −exp(gk−1))2
1 + exp(2gk−1)
	
.
(27)

Statistical Characteristics of the Adjacent Information Signals …
835
Fig. 7 Two-dimensional probability density of the logarithm of the ratio of the amplitudes (5) in
the presence of a signal
The three-dimensional diagram of ws(gk−1, gk) (27) at h2 = 40 (that is, 16 dB)
is shown in Fig. 7.
It is demonstrated there that the presence of a signal signiﬁcantly “narrows” the
surface compared to that shown in Fig. 3 (that is, the variance of the logarithmic ratio
(5) decreases, as one can see in Fig. 5). But, it should be noted that the neighboring
values of Gk−1 and Gk remain correlated. For example, at h2 = 40, their correlation
coefﬁcient RG = ⟨Gk−1Gk⟩is equal to −0.807. However, the value of RG decreases
with the increase in the SNR and tends to zero when h →∞.
Thus, in the presence and absence of a signal, adjacent amplitude ratios Gk−1
and Gk are statistically interrelated, while the correlation coefﬁcient in the area of
working SNRs is in the range from −0.807 to −0.5.
6
The Sequence of Values of the Logarithm of the Adjacent
Symbol Amplitude Ratio
In the simplest case, the decision about the properties of the signal should be taken
even by one value (sample) of the measure (5). For example, when a signal is detected,
the following algorithm can be used: the signal is absent if Gk > b, and if Gk ≤b,
then the signal is detected. In this case, following (10), the probability of the false
alarm PF is
PF = 1 −pn(b).
(28)
and, based on (24), the signal missing probability PM is, correspondingly
PM = ps(b).
(29)

836
O. Chernoyarov et al.
Thus, for the speciﬁed value of PF, the required threshold b is determined from
the Eq. (28), and then, from (29), the value of PM is determined for the selected SNR
h2 (18). For example, when PF = 0.1, then, following (28) and taking into account
(10) and Fig. 2, one gets b ≈0.1, while from (24), at h2 = 272 (24.3 dB), according
to (29), one gets PM ≈0.1.
It means that it is impossible to carry out a reliable detection based one sample,
and thus it is necessary to use the sampling Gk, k = 1, N for the sequence of
N + 1 information symbols (where the value of N should be taken as the maximum
possible).
To estimate the signal properties one can use the sample estimate of the variance
(23):
σ 2
G =
1
N −1
N

k=1
G2
k,
based on which as well as on Fig. 5, the decisions can be made. High estimation
accuracy is ensured by a large size of the sample N ≫1. It should be noted that the
estimates of the correlation coefﬁcient are unsuitable for this, since its signiﬁcant
module decrease occurs at a high SNR.
If the values of Gk are independent (for example, only even samples are selected,
while the sample size is halved), then the probability Pn(M0) that in a sampling made
of N samples, the threshold b is exceeded no more than M0 times, is equal to in the
absence of a signal [15]
Pn(M0) =
M0

m=0
 N
m
	
pm
n (1 −pn)N−m.
(30)
where pn = pn(b) following (10). This probability decreases with M0 which allows
providing the required level of false alarms.
A similar probability Ps(M0), in the presence of a signal, can be determined by
replacing pn in (30) by ps = ps(b) from (24) and then the signal missing probability
can be found.
In the full sampling Gk, the neighboring values are strongly correlated and the
binomial model (30) becomes approximate. In this case, it is advisable to describe
the sampling using a simple Markov chain. Two events are considered: the sample
that is lower than the speciﬁed threshold b (index 0) and higher than it (index 1),
with the four combinations of these events including the corresponding transition
probabilitiespi j, i, j = 0, 1 from the event i to event j for the previous, that is
Gk−1, and the current, that is Gk, values of the samples. The matrix of transition
probabilities has the form [13]

pi j

=
 p00 p01
p10 p11

=

α
1 −α
1 −β
β

.

Statistical Characteristics of the Adjacent Information Signals …
837
and contains two parameters α and β calculated based on the two-dimensional prob-
ability density ws(gk−1, gk) (27). The possibilities of applying the Markov model for
the solution of the problem under consideration require additional research.
Thus, the considered approaches enable the researcher to make decisions about
the presence of a signal and the SNR value in an operating channel without the need
to estimate the noise and signal levels.
7
Conclusion
It is proven that the logarithm of the adjacent information symbol amplitude ratio is
an effective measure for estimating the properties of the received discrete signal and
the communication channel as a whole, and it is independent of the absolute level
of the channel noise and is SNR determined only. For this purpose, the probabilistic
properties of the proposed measure are considered, the necessary calculation rela-
tionships are obtained, and both one-dimensional and two-dimensional probability
densities are found. It is demonstrated that the statistical characteristics of the intro-
duced measure, as well as the probabilities of exceeding the speciﬁed threshold by
the measure, regardless of the levels of noise and signal, can be obtained analyti-
cally. It is established that the variance of the logarithm of the amplitude ratio in the
absence of a signal is independent of the noise level and is equal to 0.822, while in
the presence of a signal it decreases with the SNR increase.
The properties of the sequence of the measure samples are considered, including
taking into account the correlation of the neighboring values. Based on them, it is
proposed to simulate the sequence of the samples of the logarithm of the amplitude
ratio by a simple Markov chain.
The obtained probabilistic characteristics can be used when ﬁnding solutions
for the problems of detecting a signal with a noise level-independent false alarm
probability and in SNR estimating.
Acknowledgements The work was supported by the Ministry of Education and Science of the
Russian Federation (research project No. FSWF-2023-0012).
References
1. Sklar B, Harris FJ (2020) Digital communications: fundamentals and applications. Pearson,
London
2. Proakis JG, Salehi M (2007) Digital communications. McGraw-Hill Higher Education, New
York
3. Liang D, Ng SX, Hanzo L (2013) Near-capacity turbo coded soft-decision aided DAPSK/Star-
QAM for amplify-and-forward based cooperative communications. IEEE Trans Commun
61:1080–1087

838
O. Chernoyarov et al.
4. Genç F, Yengel E, Sava¸sçihabe¸s A, Ertuˇg Ö (2014) On the optimum ring ratio determina-
tion for 16-DAPSK modulation in OFDM systems. In: 2014 22nd Signal processing and
communications applications conference. IEEE Press, Trabzon, pp 742–745
5. Chernoyarov O, Litvinenko V, San KM, Glushkov A, Litvinenko Y (2022) On the demodula-
tion of the ADPSK signals. In: 14th International conference “ELEKTRO2022”. IEEE Press,
Krakow, pp 1–5
6. Litvinenko VP, Litvinenko YV, Matveev BV, Chernoyarov OV, Makarov AA (2016) The new
detection technique of phase-shift keyed signals. In: 2016 International conference on applied
mathematics, simulation and modelling. Atlantis Press, Zhengzhou, pp 355–358
7. Urkowitz H (1967) Energy detection of unknown deterministic signals. Proc IEEE 55:523–531
8. Chernoyarov OV, Golpaiegani LA, Glushkov AN, Litvinenko VP, Matveev BV (2019) Digital
binary phase-shift keyed signal detector. Int J Eng Trans A Basics 32:510–518
9. Van Trees HL, Bell KL, Tian Z (2013) Detection, estimation and modulation theory, Part I.
Detection, estimation, and ﬁltering theory. Wiley, New York
10. Kay S (1998) Fundamentals of statistical signal processing: detection theory, vol 2. Pearson,
London
11. Levin BR (1968) Theoretical principles of radioengineering statistics. Defense Technical
Information Center, Virginia
12. Didkowsky RM, Pervuninskii SM, Bokla NI (2013) Basic methods of stochastic signal
modulation. Doklady BGUIR 20:50–55
13. Kirkwood JR (2015) Markov processes. CRC Press, Boca Raton
14. Grami A (2019) Probability, random variables, statistics, and random processes: fundamen-
tals & applications. Wiley, New York
15. Johnson NL, Kotz S, Balakrishnan N (1997) Discrete multivariate distributions. Wiley-
Interscience, New York

Predicting Severity Levels of Parkinson’s
Disease from Telemonitoring Voice Data
Aryan Vats
, Aryan Blouria
, and R. Sasikala
Abstract Parkinson’s disease is an age-related degenerative brain disorder that
affects the nervous system causing symptoms such as tremors, stiffness and slowing
of movement that begin gradually and worsen over time. As severity increases, prob-
lems such as mental and behavioral changes, memory issues, depression and fatigue
arise. As such, to be able to successfully diagnose and cure patients of Parkinson’s, we
need an accurate and reliable means to identify the severity of the disease. This paper
proposes a method of severity prediction using neural networks, with the adequate
number of severitylevels backedbystatistical proofs. This paper focuses onobtaining
an accurate number of clusters using the telemonitoring voice dataset of patients, and
through our experiments, we arrive at four severity levels. In the proposed approach,
emphasis was given to consider more parameters for prediction and the exactness of
the values obtained by our strategy to be better when contrasted with the precision
acquired in past research. The system proposed can classify Parkinson patients into
more severity levels than just ‘severe’ and ‘non-severe’ and consequently can help
clinical professionals in medical care diagnose Parkinson illness.
Keywords Parkinson’s disease · Severity ranking · Uniﬁed Parkinson’s disease
rating scale · Parkinson’s telemonitoring · Clustering · Neural networks
A. Vats (B) · A. Blouria
Vellore Institute of Technology, Vellore, Tamil Nadu 632014, India
e-mail: avats101@gmail.com
A. Blouria
e-mail: aryan.blouria2019@vitstudent.ac.in
R. Sasikala
School of Computer Science and Engineering, Vellore Institute of Technology, Vellore, Tamil
Nadu 632014, India
e-mail: sasikala.ra@vit.ac.in
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_63
839

840
A. Vats et al.
1
Introduction
The Parkinson’s disease is a progressive neurological condition occurring by the
degeneration happening in the nerve cells of the brain that control movement by
producing a chemical called dopamine. As these cells are impaired, they lose
the ability to produce dopamine, and hence, the patient develops symptoms of
Parkinson’s disease. Although the exact causes are unknown, it is believed to be
caused due to multiple factors such as genetics and environmental toxins. Symp-
toms of this disease include loss of movement and balance, tremors, depression, etc.
Parkinson disease patients also show substantial difference in voice attributes, thus
vocal recordings are an important noninvasive procedure for having diagnosis. Voice
recordings passed through signal processing algorithms with regression methods
forecast a value on the uniﬁed Parkinson’s disease rating scale (UPDRS) [1]. The
analogy obtained from the work conducted in [2] suggests classifying the severity
of PD into three levels based on the outputs obtained from the UPDRS score, giving
to the concept of deriving severity levels for better diagnosis of PD. These levels set
a baseline threshold for all voice features, deﬁning a boundary. The use of neural
networks for efﬁcacious analysis of speech signals is not archaic, having techniques
involving multiple layers stacked together to produce a classiﬁer. This paper builds
a classiﬁer on the dataset worked in [1] and uses clustering algorithms to devise the
number of levels. These clusters are visualized using t-SNE [3], giving an effective
representation for the clusters generated using the highly dimensional data. This
technique emphasizes on using total UPDRS and motor UPDRS along with the
voice features, giving a higher dimensional set for the levels to classify rather than
considering only scale values as done in [4].
2
Related Work
To come up with a reliable and accurate approach for predicting severity of
Parkinson’s in a patient, a lot of research was undertaken. In [2], a goal of trying to
determine severity levels based on the UPDRS scores was achieved with a classiﬁ-
cation into ‘mild’, ‘moderate’ or ‘severe’. They made use of concepts involved in
data analytics for their study, involving central tendency, dispersion measures and
concordance. In [4], a neural net was implemented to predict the disease severity into
two classes (‘severe’ and ‘non-severe’) setting a foundation for our methodology. A
lot of weightage was given to UPDRS scores in prediction of the severity. Another
approach for severity estimation is attempted in [5], the ﬁndings of which proved
that acoustic analysis of speech signals had great potential in diagnosing Parkinson’s.
It used regression analysis made on regularized random forests to ﬁnd statistical
scores based on different speech tasks like words, sentences, texts, monologues and
combination of them.

Predicting Severity Levels of Parkinson’s Disease from Telemonitoring …
841
In [6], various machine learning approaches were employed to predict the UPDRS
scores based on 16 voice features and the performance of the neural network was
found to be desirable, when compared with support vector regression, decision tree
regression and linear regression on basis of the RMSE scores. The same result is
reinforced in [7] where multiple classiﬁcation approaches are tried for prediction
of Parkinson’s, and the deep neural network seems to perform the best. The perfor-
mance of the classiﬁers was judged on the basis of the results of the confusion matrix
of these algorithms. The work done in [8] makes clusters using expectation maxi-
mization and then applies principal component analysis to the clusters obtained to
address multicollinearity problems. These features are then trained on support vector
regression and adaptive neuro-fuzzy inference system models to provide regressional
values of the Parkinson disease progression (which is UPDRS scale), bolstering the
idea of using clusters to identify the alike data points and then provide a regression or
a classifying analysis to it. It was claimed by the authors that it was the ﬁrst time that
dimensionality reduction and clustering method with EM was used in the context of
Parkinson diagnosis.
In [9], there was a discussion and comparative analysis on the methodology of
selection of K-value in K-means clustering using four different K-value selection
algorithms, which were the silhouette coefﬁcient, canopy algorithm, gap statistic
and the elbow method. The paper concludes that all four methods are suitable when
performing clustering for small datasets. The study done in [10, 11] discusses the high
potential of the usage of Gaussian mixture clustering models in multidimensional
data on speech features. The algorithm is tested on varying multifaceted data derived
from the sales of a global video game. The results of the experiments highlight the
strengths and limitations of the Gaussian mixture model for clustering relatively
large data. The methods described in [12] give a well laid foundation on deciding the
right total optimum clusters using hierarchical clustering on different datasets, such
as convex, manifold, linear and annular structures using a novel clustering validity
index approach. There were speciﬁc guidelines demonstrated for the eps parameter
estimation of DBSCAN clustering algorithm in [13]. It provides an improvement on
the self-adaptive selection of parameters. The result is far better clustering results at
the cost of computational complexity.
To ﬁnd the total optimum clusters using any clustering technique, multiple metrics
or scores can be used in conjunction with them. In [14], the criterion of silhouette
width is discussed for deciding the optimum clusters in the context of selecting
image features from satellite forest image data in Japan. It concludes that the usage
of this metric helps select a discriminative set of features, hence leading to a highly
accurate classiﬁcation model. Another metric called Calinski-Harabasz score works
on dispersion degree between the clusters is discussed in [15] where it is used along
with silhouette score to develop a new improved metric based on both of them called
peak weight index. Calinski-Harabasz index proves to be important as it demonstrates
the ability to improve the variations in results for clustering in the dataset. Davies-
Bouldin metric for evaluation of clustering performance is introduced in [16] that
can be integrated with a clustering algorithm to ﬁnd the optimal number of clusters
with low cost. The Davies-Bouldin index-based hierarchical initialization K-means

842
A. Vats et al.
algorithm proposed in the paper achieves on Gaussian distributions that are extremely
normal in real-world use cases and thus demonstrates its effectiveness.
Our proposed methodology builds on this literature and improves upon it to build a
more robust and reliable means of diagnosing Parkinson’s and identifying its severity
levels.
3
Proposed Work
The dataset has been extracted from [1], published in UCI ML repository. After
performing some essential preprocessing operations, using four clustering algo-
rithms K-means, agglomerative hierarchical, Gaussian mixture and DBSCAN the
total optimum clusters are discovered. Using metrics like Calinski-Harabasz, Silhou-
ette and Davies-Bouldin score elbows help to identify the total optimum clusters
according to each algorithm and by making use of a comparative analysis the optimal
clusters for these data points is suggested to be four. After considering silhouette,
Calinski-Harabasz and Davies-Bouldin scores on each algorithm K-means, agglom-
erative hierarchical, Gaussian mixture and DBSCAN with 4 clusters, the chief algo-
rithm is used (Gaussian mixture in this case) to generate clusters for the data points.
Using t-SNE these clusters could be expressed visually in a two-dimensional repre-
sentation. A multilayer stacked neural network is then constructed, with the prepro-
cessed dataset at the input layer and the four severity layers set at the output layer.
There are three hidden layers considered, given the dimensionality and the proce-
dures adopted in [4]. This system then acts as a classiﬁer for the four severity levels-
‘Level 1’, ‘Level 2’, ‘Level 3’ and ‘Level 4’. After normalizing, data is used for
training and testing of the modeled neural network (Fig. 1).
3.1
Data Collection
The Parkinson’s Disease: Oxford Telemonitoring Dataset from UCI ML Repository
has been used to build our model. This consists of the collection of biomedical voice
data points for nearly 42 Parkinson’s’ patients in early stages that were monitored
remotely for symptom progression. This contains data points having 22 features
including the subject number, subject age, subject gender, time interval (in days) from
subjects’ recruitment, motor UPDRS, total UPDRS and 16 different biomedical voice
attributes. There are 5875 instances in total, each corresponding to a voice recording
from these patients, and there are around 200 recordings per patient. The dataset is
in ASCII comma-separated values (CSV) format. The attributes used to build this
dataset are shown in Table 1.

Predicting Severity Levels of Parkinson’s Disease from Telemonitoring …
843
Fig. 1 System’s proposed
methodology has been
outlined in the form of a ﬂow
chart
3.2
Data Preprocessing
Using Pandas library to drop the data points having missing values and making use
of principal component selection for selecting the relevant attributes of the dataset.
The irrelevant columns like the ‘subject#’ and ‘test_time’ are ﬁltered out, leaving 20
attributes to train on. The data is considered for normalization, changing the shape
of distribution of the multidimensional data to eliminate redundancy for efﬁcient
clustering methods.

844
A. Vats et al.
Table 1 Attributes used in the Parkinson’s disease: Oxford Telemonitoring Dataset
Features
Description of the features
subject#
Identiﬁcation number for each test subject
age
Age of the subject
sex
Gender of the subject where ‘0’ stands for
male, ‘1’ stands for female
test_time
The number of days passed from the
recruitment day to the trial
motor_UPDRS
Motor UPDRS score by the clinician (linearly
interpolated)
total_UPDRS
Total UPDRS score by the clinician (linearly
interpolated)
Jitter (%), Jitter (Abs), Jitter: RAP, Jitter:
PPQ5, Jitter: DDP
Various attributes for measuring variation
happening in the fundamental frequency. RAP:
relative average perturbation, the average
absolute difference between a period and the
average of it and its two neighbors; PPQ:
ﬁve-point period perturbation quotient; DDP:
average absolute difference of differences
between cycles, divided by the average period
Shimmer, Shimmer (dB), Shimmer: APQ3,
Shimmer: APQ5, Shimmer: APQ11, Shimmer:
DDA
Various attributes for measuring variation
happening in the amplitude. APQ: three, ﬁve,
eleven point amplitude perturbation quotients;
DDA: average absolute difference between
consecutive differences between the
amplitudes of consecutive periods
NHR, HNR
Harmonics-to-noise and noise-to-harmonics
ratio for the tonal components measured in
voice
RPDE
Recurrence period density entropy is a
complexity measure that is dynamic
DFA
Detrended ﬂuctuation analysis exponent in
signal waves
PPE
Pitch period entropy for ﬁnding variation in
fundamental frequency
3.3
Clustering Techniques
Four different clustering techniques have been employed to estimate the optimal
number of clusters, namely K-means clustering, agglomerative clustering, DBSCAN
and Gaussian mixture.
K-Means Clustering
It is an unsupervised algorithm that learns to cluster a dataset into k partitions. It
works on an algorithm that is centroid based, where each cluster is associated with a
corresponding centroid and the objective is to reduce the sum of distances between

Predicting Severity Levels of Parkinson’s Disease from Telemonitoring …
845
points and its belonging clusters. Based on the Python implementation, these clusters
could vary based on the initialization, random state and algorithm to be followed
(‘lloyd’, ‘elkan’, ‘auto’, ‘full’).
Agglomerative Clustering
Also known as hierarchical agglomerative clustering, has the feature of not pre-
specifying the total clusters. It works by considering a singleton cluster and then
repeatedly agglomerating pairs of clusters to the point that all clusters are combined
into a single large cluster containing the complete data. There are several parameters
to deﬁne them like afﬁnity, linkage.
DBSCAN
Stands for density-based spatial clustering of applications with noise is an algorithm
that clusters by identifying dense regions by grouping together data elements that are
measured based on distance to be close to each other. This focuses in each cluster
point having the least number of points in its neighborhood for a given radius. The
number of clusters obtained depends on the minimum samples taken for the model,
showing its dependence on metrics and ‘eps’ epsilon value identiﬁed using the knee
locator method.
Gaussian Mixture
The Gaussian mixture model is a distribution-based clustering algorithm. A prob-
abilistic model that expects all data points are produced from a combination of a
limited number of Gaussian distributions with unknown variables. The probability
for each data point in a set of data points belonging to each of the distributions is
identiﬁed. These models vary based on covariance types (‘spherical’, ‘tied’, ‘diag’,
‘full’) and random state considered while training it on Python.
To evaluate the optimal clusters suggested by each of these algorithms, this work
makes use of the silhouette, Calinski-Harabasz and Davies-Bouldin scores which
provide elbow on the optimal clusters to be used and respective scores for using
these optimal clusters. The theoretical implications and reasoning of these statistical
scores could be expressed as follows.
Silhouette Coefﬁcient
A metric to calculate the coherence of a clustering model. It has an upper limit from 1
to the lower limit of −1, and its calculation for each sample is based on the means of
intra-cluster distance, nearest-cluster distance. For a point i, the silhouette coefﬁcient
is as (1).
S(i) =
b(i) −a(i)
max{a(i), b(i)},
(1)
where b(i) represents the smallest average of distances from point i to all points in
any other cluster and a(i) represents the average of distances from point i to all other
points in its own cluster. The silhouette coefﬁcient identiﬁes the correct assigning
for individual points to their clusters.

846
A. Vats et al.
• Having S(i) nearer to 0 means the point is between two clusters.
• Having it nearer to −1, implies to assign it to the other clusters for better accuracy.
• Having S(i) nearer to 1, implies the point belonging to the ‘correct’ cluster.
So, in a given dataset, the score with the local maximum silhouette coefﬁcient is
considered to have the optimal clusters.
Calinski-Harabasz Index
According to this index, good clusters are those which are well spaced from each
other. By dividing the variation of the distances of individual objects to their cluster
center by the sum of squares of distances between cluster centers, it is calculated.
Having a higher Calinski-Harabasz Index value, results in better clustering. Calinski-
Harabasz Index is formulated as (2)
CHk = BCSM
k −1 · n −k
WCSM.
(2)
Here k is the number of clusters, n is the number of records in data, BCSM
(between cluster scatter matrix) calculates separation between clusters and WCSM
(within cluster scatter matrix) calculates compactness within clusters.
Davies-Bouldin Index
The Davies-Bouldin index is used for assessing clustering algorithms. It is an internal
assessment scheme, where the wellness of the clustering has been done using quan-
tities and attributes implicit to the dataset. It is determined by the average likeness of
each cluster with a most similar cluster to it. Having lower average likeness is results
in better clustering. The formula for Davies-Bouldin index is (3)
DB = 1
N
N

i=1
Di,
(3)
where N represents the total cluster number,
Di ≡max
j̸=i Ri, j,
(4)
Ri, j = Si + Sj
Mi, j
,
(5)
where
Si
represents the intra-cluster dispersion for cluster i,
Sj
represents the intra-cluster dispersion for cluster j,
Mij
represents the distance between centroids for clusters i and j.

Predicting Severity Levels of Parkinson’s Disease from Telemonitoring …
847
These scores can be calculated using the sklearn.metrics library in Python for
ﬁnding values for each cluster. Once the number of clusters proposed by each algo-
rithm is considered for voting, a consensus for the optimal clusters is gained. Using
the optimal clusters with the parameters used in testing, the most optimal clustering
algorithms are produced which are then again compared on these scores to get the
most optimal clustering algorithm, with the resultant clusters.
3.4
Classiﬁer Neural Network
These clusters are then trained on our neural network classiﬁer built using Keras.
The model contains 20 features for the input layer, 10 neurons are set for the ﬁrst
hidden layer, 20 neurons are set for the second hidden layer, 10 neurons are set for
the third hidden layer, and ﬁnally, the output layer is set to 4 neurons for each level
of severity. The split ratio used on training and testing sets is 80:20. The input along
with the hidden layers use the activation function rectiﬁed linear unit (ReLU) that
outputs directly if it is positive and zero otherwise. The range of this function is thus 0
to positive inﬁnity. The activation function Softmax is used for the output layer, as it
is useful for multi-class classiﬁcation problems where there are more than two class
labels. The range of this function is 0 to 1. Overall, it is compiled on the optimizer
Adam and the loss function categorical cross entropy, training it for 15 epochs and
a batch size of ﬁve then assessing against its accuracy, to judge the reliability of the
built classiﬁer. Once trained, the model is ready to classify input data into any of the
four possible severity levels of Parkinson’s disease (Fig. 2).
4
Results Analysis
Python 3.10 was used to simulate the results of our experiments. From the dataset
parameters discussed in the data collection section, the columns irrelevant to our work
like the ‘subject#’ and ‘test_time’ were ﬁltered out before moving on to the clustering
of the individual data points. In this paper, four kinds of clustering algorithms K-
means, agglomerative, DBSCAN and Gaussian mixture model clustering alongside
evaluation metrics such as silhouette score, Calinski-Harabasz score and Davies-
Bouldin score are used for this experiment. The optimum clusters obtained using
each of these clustering techniques with each scoring metric have been shown in
Figs. 3, 4 and 5. KElbowVisualizer, matplotlib and pyplot have been used to visualize
these graphs.
These representations are given in Table 2.
Based on the values in Table 2, it is observed that K-means clustering results in
4 clusters based on all the scores, agglomerative clustering results in 4 or 5 clusters,
DBSCAN results in different number of clusters for each metric used ranging from
4 to 9, and ﬁnally, Gaussian mixture model results in 4 or 8 clusters. Based on the

848
A. Vats et al.
Fig. 2 Multilayered neural network classiﬁer architecture diagram
observations, 4 seems to be the most logical choice for the number of clusters. To
be able to decide which clustering technique is to be relied upon for clustering into
4 clusters, we need to compare each of these techniques based on their scores for 4
clusters.
To decide the best clustering technique for 4 clusters, we calculate the silhouette,
Calinski-Harabasz as well as the Davies-Bouldin score for four clusters with each of
the four clustering techniques and compare them here using Table 3.
For deciding the optimal clustering technique, the one with a higher silhouette
score is deemed to be a better performing algorithm, its range being from −1 to + 1.
Similarly, a higher Calinski-Harabasz score is desirable when choosing a technique.
On the contrary, a lower Davies-Bouldin score corresponds to algorithms with good
clusteringperformance,withitsminimumbeing0.Basedonthesefactors,theoptimal
clustering technique should be one with a higher silhouette score, a higher Calinski-
Harabasz score and a lower Davies-Bouldin score. The Gaussian mixture model
satisﬁes these conditions the best and thus should be the best clustering technique
for our purpose.
Using T-distributed neighbor embedding (t-SNE), a dimensionality reduction
technique that helps visualize high-dimensional datasets. The original data is entered

Predicting Severity Levels of Parkinson’s Disease from Telemonitoring …
849
Fig. 3 Plots of silhouette scores versus number of clusters for different clustering algorithms
Fig. 4 Plots of Calinski-Harabasz scores versus number of clusters for different clustering
algorithms

850
A. Vats et al.
Fig. 5 Plots of Davies-Bouldin scores versus number of clusters for different clustering algorithms
Table 2 Clustering techniques and optimal clusters advised by each score
S. No.
Clustering technique
Optimum clusters based on
Silhouette score
Calinski-Harabasz
score
Davies-Bouldin score
1.
K-means
4
4
4
2.
Agglomerative
5
4
5
3.
DBSCAN
8, 9
7
4
4.
Gaussian mixture
4
4
8
Table 3 Clustering techniques and scores for four clusters
S. No.
Clustering technique
For 4 clusters
Silhouette score
Calinski-Harabasz
score
Davies-Bouldin score
1.
K-means
0.3636
4465.4721
0.9385
2.
Agglomerative
0.3462
3566.2552
0.8998
3.
DBSCAN
−0.0372
474.2215
1.0734
4.
Gaussian mixture
0.3675
4479.8375
0.9296

Predicting Severity Levels of Parkinson’s Disease from Telemonitoring …
851
intoanalgorithm,andthebestmatchrepresentationusingfewerdimensionsofcluster
data is generated. In Fig. 6, using 2 dimensions TC1 (a component of the components)
and TC2, this high-dimensional data is represented with a perplexity (parametric term
used in t-SNE) of 150.
Based on Figs. 7 and 8, it is inferred that using 0.01 as learning rate for the
constructed neural network provides minimal overﬁtting. There is 95.8% accuracy
and 0.1001 loss of the training data by the end of 15 epochs and 94.4% accuracy and
0.1146 loss of the testing data.
Fig. 6 Cluster visualization using t-SNE
Fig. 7 Epoch versus model
accuracy for train and test
sets

852
A. Vats et al.
Fig. 8 Epoch versus model
loss for train and test sets
5
Conclusion
In this paper, we have implemented various clustering algorithms and used various
scoring techniques to calculate the optimal number of severity levels of Parkinson’s
disease needed for a telemonitoring voice data. A deep neural network has been
implemented to classify these data points into levels providing a severity rating
for Parkinson’s disease. These ratings have an indirect relation to the parameters,
without any implied observation with the attributes individually. The accuracy of the
constructed neural network is 94.4% with a loss of 0.1146. This is a good accuracy
for our purpose. Thus, using the constructed neural networks, a data point could be
ranked into a severity level. Although the dataset has 5875 instances, the precision
of our methodology could be additionally improved by implementing it on a bigger
dataset, having more cases of each severity class in combination with a dataset of
patients’ voice information and supplementary patient highlights like handwriting
and gait attributes.
References
1. Tsanas A, Little M, McSharry P, Ramig L (2009) Accurate telemonitoring of Parkinson’s
disease progression by non-invasive speech tests. Nat Proc 1–1
2. Martínez-Martín P, Rodríguez-Blázquez C, Alvarez M, Arakaki T, Arillo VC, Chaná P,
Fernández W et al (2015) Parkinson’s disease severity levels and MDS-Uniﬁed Parkinson’s
disease rating scale. Parkinsonism Relat Disord 21(1):50–54
3. Cai TT, Ma R (2021) Theoretical foundations of t-SNE for visualizing high-dimensional
clustered data. arXiv preprint arXiv:2105.07536
4. Grover S, Bhartia S, Yadav A, Seeja KR (2018) Predicting severity of Parkinson’s disease using
deep learning. Procedia Comput Sci 132:1788–1794
5. Galaz Z, Mzourek Z, Mekyska J, Smekal Z, Kiska T, Rektorova I, Orozco-Arroyave JR, Daoudi
K (2016) Degree of Parkinson’s disease severity estimation based on speech signal processing.

Predicting Severity Levels of Parkinson’s Disease from Telemonitoring …
853
In: 2016 39th International conference on telecommunications and signal processing (TSP).
IEEE, pp 503–506
6. Varghese BK, Amali D, Devi KS (2019) Prediction of Parkinson’s disease using machine
learning techniques on speech dataset. Res J Pharm Technol 12(2):644–648
7. Ul Haq A, Li J, Memon MH, Khan J, Ud Din S, Ahad I, Sun R, Lai Z (2018) Comparative
analysis of the classiﬁcation performance of machine learning classiﬁers and deep neural
network classiﬁer for prediction of Parkinson disease. In: 2018 15th International computer
conference on wavelet active media technology and information processing (ICCWAMTIP).
IEEE, pp 101–106
8. Nilashi M, Ibrahim O, Ahani A (2016) Accuracy improvement for predicting Parkinson’s
disease progression. Sci Rep 6(1):1–18
9. Yuan C, Yang H (2019) Research on K-value selection method of K-means clustering algorithm.
J 2(2):226–235
10. Ahmed SRA, Al Barazanchi I, Jaaz ZA, Abdulshaheed HR (2019) Clustering algorithms
subjected to K-mean and Gaussian mixture model on multidimensional data set. Periodicals
Eng Nat Sci (PEN) 7(2):448–457
11. Kuresan H, Masunda S, Samiappan D (2019) Analysis of Jitter and Shimmer for Parkinson’s
disease diagnosis using telehealth. In: Cognitive informatics and soft computing. Springer,
Singapore, pp 711–721
12. Zhou S, Xu Z, Liu F (2016)Method for determining the optimal number of clusters based on
agglomerative hierarchical clustering. IEEE Trans Neural Networks Learn Syst 28(12):3007–
3017
13. Zhu L, Zhu J, Bao C, Zhou L, Wang C, Kong B (2018) Improvement of DBSCAN algo-
rithm based on adaptive Eps parameter estimation. In: Proceedings of the 2018 international
conference on algorithms, computing and artiﬁcial intelligence, pp 1–7
14. Kaoungku N, Suksut K, Chanklan R, Kerdprasop K, Kerdprasop N (2018) The silhouette
width criterion for clustering and association mining to select image features. Int J Mach Learn
Comput 8(1):69–73
15. Wang X, Xu Y (2019) An improved index for clustering validation based on the Silhouette
index and Calinski-Harabasz index. IOP Conf Ser Mater Sci Eng 569(5), 052024
16. Xiao J, Lu J, Li X (2017) Davies Bouldin Index based hierarchical initialization K-means.
Intell Data Anal 21(6):1327–1338

Attendance Management System Using
Face Recognition
I. G. Vishnu Vardhan, M. Ajay Kumar, P. Nithin Kalyan, V. Spandana,
and J. Ebenezer
Abstract Today’s educational institutions are concerned with students’ ongoing
performance. One problem causing the reduction in student performance is the insuf-
ﬁcient attendance. The most well-known methods of recording attendance include
calling or signaling the students. It got harder and took longer. It is now necessary to
have a computer-based student attendance monitoring system that enables the teacher
to keep attendance records. In this project, we employed a clever face recognition-
based attendance system. We have recommended setting up a “multi-use attendance
management system using face recognition” in the area. Face permission allows for
facial recognition in modern implementations, which reduces time and eliminates
the possibility of proxy attendance. Additionally, this establishes when a particular
predeﬁned order was inserted, information on their presence. This project is imple-
mented using Python, and development is done using PyCharm. The face landmark
estimation set of guidelines is used in our work. Finding their faces and recording
their attendance is the difﬁcult part. This method eliminates the possibility of fake
attendance because it uses the face as a biometric for authentication.
Keywords Authorization · Face recognition · Identiﬁcation · OpenCV
(open-source computer vision library) · Dlib (digital library) · cv2 · Operating
system (OS) and some Python modules
1
Introduction
This depicts our project’s overall scope and outline. In today’s networked society,
it is more important than ever to ensure the security of data or physical assets.
While we occasionally hear about crimes like credit card fraud, computer hacker
attacks, or security breaches in business or governmental structures, the majority of
these crimes were committed by individuals exploiting a critical ﬂaw in conventional
I. G. Vishnu Vardhan · M. Ajay Kumar · P. Nithin Kalyan · V. Spandana · J. Ebenezer (B)
Velagapudi Ramakrishna Siddhartha Engineering College, Vijayawada, Andhra Pradesh 520007,
India
e-mail: ebenezer.jangam@gmail.com
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_64
855

856
I. G. Vishnu Vardhan et al.
access control systems that grant access based on what we have, like a key, such as
this innovation is called biometrics. The term “biometric access control” refers to
automated methods for verifying or identifying a living person based on physical
characteristics like ﬁngerprints or facial features or behavioral characteristics like a
person’s handwriting or keyboard routines [1, 2]. Since biological characteristics are
used in biometric systems to identify individuals, they are difﬁcult to forge. Since the
early 1970s, academics in a variety of ﬁelds, including security psychology, image
processing, and computer vision, have been interested in face recognition. Kelly 1970
2 Today, attendance is the most important factor to success. Face recognition is one
of the few biometric techniques that has the advantages of high accuracy and minimal
intrusion. Keep a record of each organization’s contact with a person [3]. A person’s
attendance at a facility or group serves as proof that they are honoring their pledge
to do so. Typically, collecting attendance is done manually; it can be expedited by
individual yells or signed forms. There needs to be a change from this absence in this
digital age. Face recognition technology makes it possible to record attendance for
every person present in a space. To do so, a number of methods, including machine
learning, are used to analyze and take photos of a person’s face. Using an algorithm,
the system can quickly and accurately identify a person and record their attendance.
2
Review of Literature
Survey 1
Face characteristics, or face implementation, are used in this study as biomet-
rics, according to [4, 5]. This system proposed a technique based on OpenCV
that combines a camera that takes a picture of the input, a face recognition algo-
rithm, encoding and identifying the faces, and recording the attendance. The local
binary pattern histogram (LBPH) and principal component analysis techniques are
employed in this article (PCA). The feature extraction method is the LBPH tech-
nique. Additionally, it employs the PCA methodology, which analyzes the test and
training images to determine who is present and who is absent and is based on the
Eigen face technique. This method is time and effort-efﬁcient when there are many
of pupils in a lecture. The attendance is kept in an Excel spreadsheet.
Survey 2
The system in this study uses Fisher face and Eigen face techniques, as shown in
[6]. The dimensionality of the images is decreased using the PCA-based Eigen faces
method. The Fisher face is built on the LDA methodology. LBP was used because
of its adaptability to changes in position and lighting. These eigenvectors are used to
quantify the differences between various faces. This system has dependable results
for posture variance, lighting, and processing the full image after getting positive
results from multiple trial tests of this technique [7]. Additionally, it takes less time
to process the complete image.

Attendance Management System Using Face Recognition
857
Survey 3
This real-time system was developed using principal component analysis (PCA) in
[8], and utilizing the Olivetti dataset, the research compares PCA with linear discrim-
inant analysis (LDA) as facial recognition methods. The dataset is ﬁrst converted into
a NumPy array before being stored in CSV format. This system recommends using
approach for facial recognition that is based on features. These methods look at the
geometric connections between various facial features. These methods are developed
using statistical tools including SVM, LDA, and PCA.
Survey 4
The Open CV-based face recognition approach has been presented in this study,
according to [9]. This model includes a camera that captures an input image, a
face detection technique, face identiﬁcation and encoding, recording attendance in
a spreadsheet, and exporting the spreadsheet as a PDF ﬁle. The training database
is created by educating the system using the faces of the authorized students. After
that, a database with the cropped images is produced and labeled appropriately [10].
To extract the features, the LBPH algorithm is applied. The ﬁndings of this paper
may enable the recognition of images under various lighting and viewing angles.
Students’ photographs that are recognized are marked in real time and imported into
an Excel sheet.
3
Proposed Architecture and Methodology
Proposed Architecture
See Fig. 1.
Proposed Methodology of the Work
Preprocessing of Data
An essential component in our approach is data pretreatment. In this step, we can
store student photos in our system together with their names or registration numbers.
We gave the dataset a name. Then, using the face recognition module, the faces in
front of the camera are detected; next, using the face landmark estimation algorithm,
each face can be divided into sixty-eight measurements; ﬁnally, if any of the faces
match those that are stored in our dataset, that student is given attendance.
Algorithm
The following is the algorithm used for attendance management system using face
recognition project.
Algorithm: Face Landmark Estimation Algorithm.
After detecting a face in an image, the face landmark estimation set of rules
identiﬁes key factors at the detected face, which includes the end of the nostril and
the center of the eye. After this, the recognized face might be in comparison with
the face this is saved in our scholar database, and if each the faces are matched, then
that scholar receives attendance (Fig. 2).

858
I. G. Vishnu Vardhan et al.
Fig. 1 Architecture of the
ﬁgure methodology used for
face detection and
recognition
4
Description of Datasets, Requirements, and Tools
Dataset
The dataset is very important to our project. We captured the images of our classmates
and created a real-time dataset [11]. It entails gathering student images and storing
them in our database.
After that, veriﬁcation of detected images and stored images should be done.
Finally, dataset means it contains images of students.
First step is to take images of students through high-deﬁnition cameras like DSLR
or mobiles like high pixel cameras [12]. And take two images of each student such
that they are in different positions.
The overall procedure of taking and storing images in our database is shown as
Figs. 3, 4 and 5.
PyCharm
The capabilities of PyCharm, a source-code editor for Windows, Linux, and Mac OS,
include assistance with debugging syntax highlighting intelligent code completion
snippets. Users of embedded git and code refactoring can customize the theme’s
keyboard shortcuts and install extensions to provide new features [13]. Like many
other code editors, PyCharm is a text editor. PyCharm has an unconventional layout
for its user interface, with an editor on the right showing the text of the documents

Attendance Management System Using Face Recognition
859
Fig. 2 Working procedure of face landmark estimation algorithm
Fig. 3 Field photo 1

860
I. G. Vishnu Vardhan et al.
Fig. 4 Field photo 2
Fig. 5 Real-time dataset images collected
you have opened and an explorer on the left showing all the ﬁles and directories you
have access to (Fig. 6).
Python
Finding hidden insights and predicting future trends can be done with the help of
machine learning [14]. You will be provided with all of the tools necessary to get
started with advice systems by following this machine learning with Python instruc-
tion. Python is a high level interpreted interactive and object-oriented scripting

Attendance Management System Using Face Recognition
861
Fig. 6 Code regarding the project
language that employs English terms frequently rather than punctuation and has
less syntactical constructions than other languages. Python is also supposed to be
very readable.
Dlib (Digital Library)
Dlib is a state-of-the-art C toolkit that incorporates machine learning methods and
resources for creating complex software to solve real-world problems. Robots,
embedded technology, mobile phones, and sizable high-performance computing
environments in both industry and academics are just a few of the applications for it
[15]. Dlib’s open-source licensing makes it free to use in any application.
Implementation Steps:
1.
Collecting images of students and storing them in our database.
2.
Install the libraries or packages in PyCharm which are useful to our project.
3.
And import all the packages that are installed in step 2.
4.
And write the Python code for face detection, comparing, and for displaying
time in Excel sheet.
5.
In this step, images of students could be captured by camera in appropriate
sizes.
6.
The stored photos will then be compared to the detected images, and if the
stored image matches the detected image, steps 7 and 8 will be performed.
7.
If the captured student is present in our database, then that student gets
attendance.
8.
If not present, just ignore that student.

862
I. G. Vishnu Vardhan et al.
Fig. 7 Images while testing the model
9.
If step 7 is done successfully, then details of that student will be displayed in
the Excel sheet.
10. That is how implementation is done.
Result Analysis
The overall window conﬁguration of the attendance management system is shown
in Fig. 7.
Face Recognition
The input image is captured by the camera and matches to the features that are
extracted earlier and detected the name and identity of the person (Figs. 8 and 9).
Marking Attendance in Excel Sheet
The student’s attendance was noted and recorded in a csv ﬁle with their name, date,
and time of attendance (Fig. 10).
The attendance of a select few students in our class, as shown in the Excel sheet,
is shown in Fig. 11.
5
Conclusion
We chose the project, face recognition-based attendance management system,
bearing in mind the demands of the society’s daily needs and desires. The devel-
opment of technology encourages us to think creatively and generate ideas that may
change the world. The most essential possession that every individual should have is

Attendance Management System Using Face Recognition
863
Fig. 8 Images while testing the model 1
Fig. 9 Image while testing the model 2

864
I. G. Vishnu Vardhan et al.
Fig. 10 Output of the model
Fig. 11 Output in the Excel sheet

Attendance Management System Using Face Recognition
865
education, as it serves as the foundation for a better way of life and will undoubtedly
raise the level of living in a community. The participation of students in the schools,
colleges, and universities is what our educational system lacks. They choose to stay
outofclassandstayactiveusingthesedevicesratherthanattendinglecturesanddoing
their homework. Low enrollment indicates that the students are absent to obtain the
knowledge that they are required to obtain, which is important to them and can help
them have a brighter future.
References
1. Vishwanadha Reddy N, Roshini K, Mishra P, Thirumaleswari T, Chandhu DS (2021) Smart
attendance system using face recognition. Int J (IJRACSE) 2454–4221
2. Preethi K, Vodithala S (2021) Automated smart attendance system using face recognition. In:
2021 5th International conference on intelligent computing and control systems (ICICCS).
IEEE, pp 1552–1555
3. Karthick S, Selva Kumarasamy S, Arun C, Agrawal P (2021) Automatic attendance monitoring
system using facial recognition through feature-based methods (PCA, LDA). Mater Today Proc
4. Bussa S, Mani A, Bharuka S, Kaushik S (2020) Smart attendance system using OPENCV
based on facial recognition. Int J Eng Res Technol 9(3):54–59
5. Sudhakar Reddy N, Sumanth MV, Suresh Babu S (2018) The counterpart approach to atten-
dance and feedback system uses machine learning techniques. J Emerg Technol Innov Res
(JETIR) 5(12)
6. Wang D, Fu R, Luo Z (2017) Classroom attendance auto-management based on deep learning.
In: Social sciences development, humanities education and research, vol 123, ICESAME
7. Jadhav A, Jadhav A, Ladhe T, Yeolekar K (2017) Automatic travel system using face
recognition. Int Res J Eng Technol (IRJET) 4(1)
8. Prabhavathi B, Tanuja V, Madhu Viswanatham V, Rajashekhara Babu M (2017) A clever system
of presence to see the face in the same way. IOP Conf Ser Mater Sci Eng 263
9. Md Akbar S et al (2018) Face recognition and RFID veriﬁed attendance system. In: 2018
International conference on computing, electronics & communications engineering (ICCECE).
IEEE
10. Lad P, More S, Parkhe S, Nikam P, Chaudhari D (2017) Student travel program using iris
discovery. IJARIIE 3(2). ISSN (O)-2395-4396
11. Bhise A, Khichi R, Korde A, Lokare D (2015) Navigation system using NFC technology and
camera embedded on mobile device
12. Senthamil Selvi K, Chitrakala P, Antony Jenitha A (2014) Marking capture marking system
based on face recognition. JCSMC 3, story 2
13. Yadav DK, Singh S, Pujari S, Mishra P (2015) A train system based on ﬁngerprints using a
small controller and LabView
14. Anitha VP, Krishna A, Kshama PM, Correa M (2016) Web service for student attendance
management system 5(3). www.ijarse.com
15. Gangagowri G, Muthuselvi J, Sujitha S. Attendance management system

Diabetes Classiﬁcation Using ML
Algorithms
G. G. Rajput and Ashvini Alashetty
Abstract Electronic health records, images, and text are a few examples of the types
of data collected by healthcare organizations, but it is still difﬁcult to comprehend this
information. New machine learning (ML) techniques can be used to reveal hidden
patterns that might one day help in diabetes diagnosis in its earliest stages. This work
presents a method for predicting diabetes using a number of ML algorithms, such
as the support vector classiﬁer (SVC), decision tree classiﬁer (DTC), K-neighbors
classiﬁer (KNC), logistic regression (LR), random forest classiﬁer (RFC), AdaBoost
classiﬁer (ABC), and gradient boosting classiﬁer (GBC) by analyzing the PIMA
Indian dataset. Due to the proposed system, healthcare providers have access to
a potent prognostic tool. SVC and RFC have been demonstrated to be the most
precise classiﬁcation strategies for the PIMA Indian Diabetes Dataset (PIDD), with
an accuracy of 79.3%.
Keywords Machine learning · Decision tree classiﬁer · Diabetes prediction ·
PIMA Indian dataset · GBC
1
Introduction
In India, diabetes is a major health concern. Diabetes develops either when the
pancreas fails to create sufﬁcient insulin or when the body is unable to utilize the
insulin produced [1]. For energy, muscle and tissue cells rely heavily on glucose. For
its metabolic functions, the brain is primarily dependent on glucose. Different types
of diabetes have distinct underlying causes. However, high blood sugar levels can
accompany any type of diabetes. High blood sugar levels are hazardous. Diabetes
types 1 and 2 are both considered chronic conditions [2]. Diabetes problems include
G. G. Rajput · A. Alashetty (B)
Department of Computer Science, Karnataka State Akkamahadevi Women’s University,
Vijayapura, Karnataka 586108, India
e-mail: ashwinialashetty@gmail.com
G. G. Rajput
e-mail: ggrajput@yahoo.co.in
© The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5_65
867

868
G. G. Rajput and A. Alashetty
pre-diabetes and gestational diabetes. Pre-diabetes causes high blood sugar. Nonethe-
less, it was obvious that the blood glucose level was not high enough to indicate
diabetes. If no action is taken to halt its progression, pre-diabetes can develop into
full-blown diabetes. Gestational diabetes, on the other hand, only affects pregnant
women. Approximately 77.2 million Indians have pre-diabetes [3]. In 2030, nearly
one million Indians perished due to diabetes. In Chennai’s urban slums, the preva-
lence of diabetes is approximately three times the national average, at 7%. Three out
of ten deaths in India are caused by illnesses that cannot be transmitted from person to
person. Changes in lifestyle are associated with quantiﬁable health declines increased
insulin and cortisol levels, in addition to an increase in calories from fat, sugar, and
physical activity [4]. The link between being overweight and injury vulnerability is
weak at best. Early diagnosis relies on the physician’s knowledge and experience,
which are not infallible and are subject to error. Although healthcare organizations
amass vast amounts of data, they often lack the pattern recognition expertise needed
to use it effectively [5]. Due to the inherent risks associated with relying on the
subjective observations and judgment of a healthcare provider to make crucial early
stage disease diagnoses. Unseen patterns may exist, and they may inﬂuence the
observed outcomes. The patients receive substandard care; consequently, a more
sophisticated mechanism for early disease detection is required, ideally one that is
both automated and highly accurate [6]. As a result of the need to uncover previously
unseen errors and hidden patterns, data mining and machine learning algorithms [7]
have evolved, enabling more precise and effective conclusions to be drawn. Data
mining algorithms for uncovering previously unseen patterns in healthcare data have
proliferated in response to diabetes’s constantly expanding impact. Additionally, the
information can be used for automated diabetes prediction and feature selection [8].
This research aimed to build a diagnostic tool that may diagnose diabetes early and
more accurately. The PIMA Indian dataset [9] (PID) employed in this work is a
popular example. The PID covers eight factors, including pregnancy history, BMI,
plasma glucose, diastolic blood pressure, systolic blood pressure, skin fold thickness,
diabetic pedigree function, and class 0 or 1 (0 means non-diabetic while 1 means
diabetic patient). DTC, K-NNC, LR, RFC, ABC, and GBC were used to study the
PIMA Indian datasets. This work shows how various algorithms can give superior
outcomes.
2
Literature Review
Khanam and Foo [10] created a model that accurately predicted diabetes risk. This
experimentusesDT,SVM,andNBtodiagnosediabetesearly.Foruseinexperimental
settings, the UCI machine learning repository provides access to the PIDD. Precision,
accuracy, F-measure, and recall are just some of the metrics used to evaluate the
relative strengths and weaknesses of the three algorithms. To calculate accuracy, the
proportion of correctly and incorrectly labeled examples is utilized. Naive Bayes

Diabetes Classiﬁcation Using ML Algorithms
869
performs best, with 76.30% accuracy, compared to other algorithms. These ﬁndings
are conﬁrmed using ROC curves.
Kumari et al. [11] showed that diabetic pathology has grown. We suggest a system
for classifying diabetes patients based on WHO criteria, which should speed up the
diagnostic process. The Hoeffding tree algorithm obtains 0.770 precision and 0.375
recall when analyzing real-world data.
Kavakiotis et al. [12] reviewed the usage of artiﬁcial intelligence (AI) in diabetes
diagnosis. The diagnosis of diabetes has been the subject of over thirty-ﬁve selected
papers. Numerous online datasets can aid in a diabetes diagnosis. The most popular
diabetes prediction dataset is the PIDD. Unlike competing datasets, it contains crucial
variablesthataidinthediagnosisofdiabetes.Thisanalysisalsorevealsthelimitations
of current methods that render them unsuitable for diabetes diagnosis. Deep learning
techniques in AI are prevalent, and heart rate is becoming an increasing focus of
medical research. Deep learning and other algorithms improve diabetes diagnosis.
Naz and Ahuja [13] evaluate machine learning algorithms that can help detect
diabetes early. This study predicts diabetes using machine learning and the PIMA
dataset. As classiﬁers, ANNs, NBs, DTs, and DL attain 90–98% accuracy. Diabetic
nephropathy, myocardial stroke, and other illnesses are leading causes of death,
although most people are unaware of the risks, as reported by Bala et al. [14].
Early diabetes detection is crucial for health and longevity. Deep learning can
predict diabetes as well as humans. This study uses an unsupervised deep neural
network (DNN) classiﬁer and a feature importance model, a combination of deci-
sion trees and random forest, to select relevant features for predicting PIMA Indian
Diabetes. UCI archived PIMA Indian Diabetes data (PID). On the current dataset,
train-test splits are tested. Assessing the model’s accuracy, speciﬁcity, sensitivity,
recall, and precision. The model achieved 98.16% accuracy with a random train-test
split.
3
Proposed Methodology
The two primary components of the proposed methodology are (1) the means by
which accuracy is achieved through the use of multiple classiﬁcation models, and
(2) the model validation procedure. Several machine learning methods can analyze
previously unknown patterns in diabetes risk assessment. Utilizing machine learning
for anomaly detection has been the subject of extensive research in the healthcare
industry.
Machine learning approaches can analyze diabetes risk patterns. Various clas-
siﬁers, including SVC, DTC, KNC, LR, RFC, ABC, and GBC, are applied to the
PIMA dataset to measure efﬁciency, which is proportional to decision quality. Our
proposed model work ﬂow is shown in Fig. 1. Our SVC and RFC model using PIMA
dataset predicted diabetes with 79.33% accuracy.

870
G. G. Rajput and A. Alashetty
Fig. 1 Workﬂow of the ML models
3.1
Workﬂow Diagram
Key components of the structure are as follows:
• Dataset selection.
• Data pre-processing.
• Resampling ﬁlter.
• Learning by classiﬁer (training).
• Obtaining a highly accurate trained model.
• Making predictions based on the trained model.

Diabetes Classiﬁcation Using ML Algorithms
871
3.2
Dataset Selection
Data selection in machine learning involves choosing the most relevant data from
a domain to obtain informative values and facilitate learning. We learned how to
predict a woman’s risk of developing gestational diabetes using a database of diabetes
cases. This dataset contained eight unique variables. This dataset of benchmarks was
retrieved from the UCI repository. Classiﬁers are trained to determine whether a
diabetes test result is positive or negative based on a variety of previously recorded
demographic and health-related factors. The PIMA diabetes dataset exclusively
includes 21-year-old women of Indian heritage. Every attribute is numeric.
3.3
PIMA Indian Dataset (PID)
Open-source PIMA Indian dataset can be used for machine learning categorization.
This used NIDDK’s PID. Most of the world’s population maintains a sedentary
lifestyle with growing reliance on processed meals and less physical activity. The
NIDDK has been conducting the PID study since 1965 due to the high prevalence of
diabetes. Certain diagnostic parameters and measurements were incorporated into
the dataset, enabling the early detection of chronic diseases and diabetes in patients.
There are no men in PID; all participants are over the age of 21 and female with
268 of 768 PID cases were diabetic, and 500 were not. The top eight predictors of
diabetes are pregnancy history, body mass index, insulin levels, ages, blood pressure,
skin thickness (ST), glucose, and diabetes. An implementation of pedigree function
(PF) that returns a label. Cross-validation was utilized to determine its statistical
performance. It conducts testing and training as its two primary functions. First, in
the training phase, a model is trained, and then, in the testing phase, the trained model
is applied and evaluated for its efﬁcacy. PIMA has developed a high prevalence of
diabetes due to their sudden transition away from traditional crops and toward.
3.4
Real-Time Dataset Availability and Training
This section provides an in-depth explanation of the PIMA Indian dataset, which
includes 768 female patients, aged 21 to 25. There are 268 diabetics among them,
and the rest are in generally good health. Figure 2 contains parameters and their
ranges.

872
G. G. Rajput and A. Alashetty
Fig. 2 Input parameters of PIMA Indian dataset
3.5
Data Preparation
Preparation the data is the most important step. The majority of healthcare data
is impure, with missing values and other defects that diminish its utility. Data
pre-processing improves data mining’s quality and effectiveness. This procedure is
required for machine learning techniques to generate accurate results and predictions
from a dataset. The PIMA Indian diabetes dataset requires a two-step pre-processing
procedure.
• Using the “Missing Values Removal” technique eliminates all cases where no
value was provided. Zero cannot exist as a value. Therefore, we can rule out this
speciﬁc instance. Selecting a subset of features for future analysis reduces data
dimensionality and speeds up processing.
• Data partitioning—After data cleaning, training, and testing data are normalized.
The algorithm is trained using the output data and tested with the test data. The
training procedure is centered on the feature values and associated logic and
algorithms. Normalization is intended to standardize the values of all variables.

Diabetes Classiﬁcation Using ML Algorithms
873
3.6
Classiﬁers
Classiﬁers are fundamental in machine learning. It receives as input a set of data
representing the objects to be classiﬁed and generates as output a prediction of the
class to which the new data belongs. Increasing the accuracy of classiﬁcation using
ML classiﬁers and determining which classiﬁer is best suited for use in diabetes
research are among the objectives of this study. Classiﬁers that are consistently
ranked among the best of their kind, such as the support vector classiﬁer we have
chosen to use in this investigation, have been selected. These classiﬁers were selected
not only because of the merits that will be described below, but also because they
have been widely used in previous research.
3.7
Correlation Matrix
It is possible to gain some insight into the nature of the connection that exists between
two variables by examining the correlation that exists between them. The plotting of
a correlation matrix in Fig. 3 gives us the ability to see which variables are highly
correlated with one another and which are only weakly correlated. We create a corre-
lation matrix for the dataset that is comprised of PIMA Indians who have diabetes.
The output correlation matrix that can be found below is symmetrical; for example,
the bottom left corner of the matrix is identical to the top right corner. It has also been
established that there is a positive correlation between all of the different variables.
A positive correlation can be found between glucose levels and our primary outcome
variable, while the body mass index comes in a close second. However, here is not
much of a connection between blood pressure and the thickness of the epidermis.
3.8
Confusion Matrix
Inordertoprovideaconcisesummaryoftheresultsofamachinelearningexperiment,
the relationship between the label and the model’s classiﬁcation should be displayed
in Table 1. We can see by looking at the confusion matrix that out of a total of 150
cases, my SVC model correctly identiﬁed 87 of them as diabetic patients (TP). In a
similar manner, 12 (TN) people who did not have diabetes were correctly classiﬁed
and wrongly identiﬁed 22 of them who have diabetes (FP) and 32 of them are in
(FN).

874
G. G. Rajput and A. Alashetty
Fig. 3 Correlation matrix of PIMA dataset
Table 1 Confusion matrix
Condition positive
Condition negative
Predicted condition
positive
87
12
Predicted condition
negative
22
32
4
Result and Discussions
Here are the system’s results and analyzes. First, machine learning methods are
compared. Comparing ML models using precision, recall, F1-score, and classiﬁ-
cation accuracy. When we consider the concepts of measurement precision, recall,
and the F1-score, we can characterize accuracy as mean average precision. The
mathematical justiﬁcation for the conclusion is as follows:
Precision was achieved if the total number of correctly predicted cases were
positive. In Eq. 1, the precision value could be used to evaluate the model’s reliability

Diabetes Classiﬁcation Using ML Algorithms
875
Precision =
TP
TP + FP.
(1)
In Eq. 2, recall indicates the accuracy of a model, or the number of correct
predictions the model was able to make
Recall =
TP
TP + FN.
(2)
To get a combined idea about those two values, we used F1-score in Eq. 3. In order
to get the harmonic mean, we must ﬁrst calculate the precision and recall values
F1 = 2 ∗precision ∗recall
precision + recall .
(3)
In Eq. 4, we used to calculate the accuracy of a model
Accuracy =
TP + TN
TP + EN + FP + TN.
(4)
TP means the model predicts a positive result, and the actual value is positive.
Model projected favorable outcome, but it was negative. This is denoted with the
letter FP. TN indicates that the model is making a negative prediction, which is
supported by the outcome. FN means the model predicts a negative value, but it
is positive. Table 2 compares PIMA Indian classiﬁer performance indicators. The
support vector classiﬁer performed best overall with 79% accuracy, 0.78 F1-score,
and 0.79 precision.
In Table 3 compares different research works with our proposed model, the SVC
obtained better accuracy than the existing works.
Table 2 Comparing the effectiveness of different classiﬁer methods on the PIMA dataset
Classiﬁer
Precision
Recall
F1-score
Accuracy
Support vector
0.79
0.78
0.78
79%
Logistic regression
0.78
0.77
0.77
78%
Decision tree
0.74
0.73
0.73
74%
Random forest
0.77
0.76
0.76
77%
AdaBoost
0.77
0.75
0.75
77%
Gradient boosting
0.78
0.77
0.77
78%
K-neighbor
0.78
0.77
0.77
78%

876
G. G. Rajput and A. Alashetty
Table 3 Comparing the
PIMA Indian dataset to recent
research on diabetes detection
Authors
Methods
Accuracy obtained
(in %)
Kumari and Chitra
[15]
SVM
77.3
Patil and Patil [16]
PCA, K-means
algorithm
72
Proposed work
SVC ML model
79.33
5
Conclusion
Diabetes can shorten people’s lives and diminish their quality of life as a result of
its complications. By identifying this chronic disorder at an early stage, numerous
other diseases and their associated risks and complications can be reduced. This work
provides a system for diabetes prediction based on a number of machine learning
approaches. The dataset of female patients from the PIMA Indian community is
utilized for this study. Using pre-processing strategies, problems with asymmetrical
class composition have been resolved. The proposed work reported measures of
machine learning and ensemble performance, including precision, recall, accuracy,
and F1-score. With an F1-score of 0.79 and an accuracy of 79%, the support vector
classiﬁer emerged victorious.
References
1. LarabiS,AburahmahL,AlmohainiR,SabaT(2019)Currenttechniquesfordiabetesprediction:
review and case study. Appl Sci 9(21):4604
2. Agarwal B, Balas VE, Jain LC, Poonia RC, Sharma M (eds). Deep learning techniques for
biomedical and health informatics. Academic Press, Cambridge, pp 327–339
3. Chowdary PBK, Kumar RU (2021) An effective approach for detecting diabetes using deep
learning techniques based on convolutional LSTM networks. Int J Adv Comput Sci Appl
12:519–525
4. Pham T, Tran T, Phung D, Venkatesh S (2017) Predicting healthcare trajectories from medical
records: a deep learning approach. J Biomed Inform 69:218–229
5. Tigga NP, Garg S (2020) Prediction of type 2 diabetes using machine learning classiﬁcation
methods. Procedia Comput Sci 167:706–716
6. Komi M, Li J, Zhai Y, Zhang X (2017) Application of data mining methods in diabetes predic-
tion. In: 2017 2nd International conference on image, vision and computing (ICIVC), Chengdu,
China, pp 1006–1010. https://doi.org/10.1109/ICIVC.2017.7984706
7. Abdar M, Nasarian E, Zhou X, Bargshady G, Wijayaningrum VN, Hussain S (2019) Perfor-
mance improvement of decision trees for diagnosis of coronary artery disease using multi
ﬁltering approach. In: 2019 IEEE 4th International conference on computer and communication
systems (ICCCS), Singapore, pp 26–30
8. Kaur G, Chhabra A (2014) Improved J48 classiﬁcation algorithm for the prediction of diabetes.
Int J Comput Appl 98:13–17
9. Machine learning: Pima Indians diabetes, 14 Apr 2018. Available at: https://www.andreagra
ndi.it/2018/04/14/machine-learning-pima-indians-diabetes/

Diabetes Classiﬁcation Using ML Algorithms
877
10. Khanam JJ, Foo SY (2021) A comparison of machine learning algorithms for diabetes
prediction. ICT Express 7:432–439
11. Kumari S, Kumar D, Mittal M (2021) An ensemble approach for classiﬁcation and prediction
of diabetes mellitus using soft voting classiﬁer. Int J Cogn Comput Eng 2:40–46
12. Kavakiotis I, Tsave O, Salifoglou A, Maglaveras N, Vlahavas I, Chouvarda I (2017) Machine
learning and data mining methods in diabetes research. Comput Struct Biotechnol J 15:104–116
13. Naz H, Ahuja S (2020) Deep learning approach for diabetes prediction using PIMA Indian
dataset. J Diab Metab Disord 19:391–403
14. BalaMKP,SrinivasaPR,NadeshRK,ArivuselvanK(2020)Type2:diabetesmellitusprediction
using deep neural networks classiﬁer. Int J Cogn Comput Eng 1:55–61
15. Kumari VA, Chitra R (2013) Classiﬁcation of diabetes disease using support vector machine.
Int J Eng Res Appl 3(2):1797–1801
16. Patil RN, Patil RN. A novel scheme for predicting type 2 diabetes in women: using K-means
with PCA as dimensionality reduction. Int J Comput Eng Appl 9(8):76–87

Author Index
A
Abhishek, S., 665
Abir, Md., 201
Adriawan, Albertus Baskara Yunandito,
563
Ahmad, Jubaer, 707
Ahmed, Mohammed Junaid, 267
Ajay Kumar, M., 855
Alashetty, Ashvini, 867
Alhaﬁzh, Muhammad Rifqi, 563
Alkoli, Mohammed, 599
Al-Nakash, Nushwan Yousif B., 113
Alvian, 809
Anand, T., 729
Anitha Mary, X., 189
Anjali, S., 377
Anjali, T., 665
Antonijevic, Milos, 403
Anusuya, V., 39
Arafat, Md. Yasir, 707
Arun Kumar, U., 253, 575
Asha, A., 25
Ashok, K., 129
Ashwin, C. S., 243, 589
Athinarayanan, Hari Prakash, 95
Awsaf Al, Fahim, 707
Aziz, Anusha, 201
B
Bacanin, Nebojsa, 403
Bairoliya, Arya, 339
Balamurugan, P., 339
Banumalar, K., 1
Bejoy, B. J., 39
Bellamkonda, Sivaiah, 329
Bharadwaj, Rakhi, 749, 763
Bhardwaj, Rakhi, 551
Bharsakle, Meenal, 551
Bhavsar, Ramchandra, 495
Binu, Dhanush, 329
Bischof, Jonah, 613
Blouria, Aryan, 839
Boby, Alden, 349
Bozovic, Aleksandra, 403
Briskilal, J., 479
Brown, Dane, 349, 535, 613, 795
C
Chakravarthy, Srinivasa L., 315
Chandraguptamauryan, K. S., 253
Chandru, K., 253
Chernoyarov, Oleg, 825
Chettiar, Gautam, 301
Chowlur Revanna, Jai Keerthy, 113
Connan, James, 349
Cunha da, Antonio Eduardo Carrilho, 461
D
Dachepalli, Srimurari, 315
Das, Tanmoy Kanti, 163
Desai, Varsha P., 143
Dhiyanesh, B., 25, 39
Dileep, M. R., 445
Diwane, Rohit B., 143
E
Ebenezer, J., 855
© The Editor(s) (if applicable) and The Author(s), under exclusive license
to Springer Nature Singapore Pte Ltd. 2023
V. Suma et al. (eds.), Inventive Systems and Control, Lecture Notes in Networks
and Systems 672, https://doi.org/10.1007/978-981-99-1624-5
879

880
Author Index
F
Febin Daya, J. L., 339
Fernaldy, Darryl, 563
G
Gadgil, Anurag A., 339
Gaikwad, Yash, 749
Ganesh Reddy, K., 53
Gaol, Ford Lumban, 563, 639, 809
Garcez, Cícero Roberto, 461
Geetha, V., 155
Gill, F. S., 729
Glushkov, Alexey, 825
Gomes, Hanameel Carlos Vieira, 461
Gupta, Rajeev, 729
H
Hanif, Muhammad Fauzi, 809
Hannah Inbarani, H., 777
Hariprasad, B., 229
Harshit, B. C., 281
Hassya, Titan, 809
Hiremath, Jayaprada, 281
Hiremath, Mrutyunjaya S., 281
Hiremath, Shantala S., 281
Hossain, Md. Shahadat, 707
Hubert, Kelby, 639
I
Ilango, Dhakshina, 693
Islam, Md. Motaharul, 707
J
Jadhav, Shaila, 677
Jadhav, Vedant, 763
Jaha, Mohammad Neelofar, 511
Jaithunbi, A. K., 65
Janokar, Sagar, 653
Jindal, Sumit, 301
Jishnu, C. R., 625
Johnson, Joveal K., 377
Jovanovic, Luka, 403
Juneja, P. K., 729
K
Kakde, Rohan, 677
Kalaiselvi, V. K. G., 589
Karthick, K., 25
Karthi, V., 575
Kavitha, S., 217
Khan, Thouseef Ulla, 445
Kiruthiga, G., 25, 39
Korableva, Larisa, 817
Krishnanunni, J., 377
Krutikov, Alexander, 431
Kulkarni, Vaishnavi V., 281
Kumar, Anjanee, 163
Kumar, Sujith, 281
Kutoyants, Yury, 817
L
Lakshmi, R., 363
Lakshmi Swapna, T., 229
Litvinenko, Vladimir, 825
M
Mahajan, Divya, 551
Mahesh Kumar, D., 229
Mallela, Varun, 315
Mane, Deepak, 677
Manikandan, B. V., 1
Mani krishna, Esikala Nithish, 129
Mannava, Mahima Chowdary, 665
Manne, Suneetha, 419
Marudwar, Varad, 677
Matsuo, Tokuro, 563, 639, 809
Mazibuko, Siﬁsokuhle, 535
Mehendale, Smita, 737
Mehta, Mita, 737
Meka, Pavan Kumar, 523
Meltsov, Vasily, 431
Meshram, Kashish, 551
Mohammad, Rizwanullah, 419
More, Kiran P., 77
Mridula, M., 363
Mujeeb, Ashik, 377
Muralidharan, S., 1
Muthu Nisha, B., 177
Muthu, V., 217
N
Nagaraju, Ajay Kumar Varma, 419
Naveen Sai, A., 267
Navin, Tahsin Elahi, 707
Nithin Kalyan, P., 855
Nithyasai, S., 575
Nithya, V., 177
Nivetha, S., 777

Author Index
881
O
Oliveira de, Irony Nunes, 461
Oza, Kavita S., 143
P
Panicker, Remya, 495
Parthasarathy, P., 575
Parusu, Yesu Raju, 523
Patekar, Umesh, 749
Patil, Disha, 677
Patil, Hemprasad, 301
Patil, Manasi, 763
Patil, Rajendrakumar A., 77
Patil, Shashank, 763
Pawar, B. V., 495
Perelevsky, Svyatoslav, 817
Pious, Vinny, 377
Prabu, U., 155
Pramitha, J., 189
Prathap Kumar, R., 53
Prinitha, V., 479
Pujari, Himaja, 551
R
Raga Madhuri, Ch., 267
Rajalakshmi, B., 129
Rajan Babu, W., 253
Rajput, G. G., 867
Raju, Mahali Tirumala, 511
Ramkumar, M., 39
Ramya sri, Gangireddy, 129
Rangarajan, K. R., 243, 589
Rathi, Manas, 653
Rathod, Alkesh, 653
Ratnaparkhi, Soham, 653
Razia Sulthana, A., 65
Reno, Saha, 201
S
Saini, P., 729
Sai Sarvanth, Vedula, 315
Sai sruthi, Gundre, 129
Salnikova, Alexandra, 825
Sangve, Sunil, 677
Sanjana, S., 665
San, Kaung Myat, 825
Santharam, Kundhavai, 387
Santhosh Krishna, B. V., 129
Saputra, Aldo, 639
Saraswathi, C., 479
Sasikala, R., 839
Satapathy, Ashutosh, 267
Sebastian, Joel J., 377
Selvakumar, J., 177
Selvam, Muthupavithran, 95
Sepula, Chikondi, 795
Shakkeera, L., 25
Shanmugaraja, P., 39
Sharada, B., 599
Sharmasth Vali, Y., 25
Shukla, Amogh, 301
Silva Firmino da, Kelipys, 461
Sonawane, Harshal, 763
Soujitha, Neelam B. V. D., 511
Spandana, V., 855
Sreenivasan, G., 229
Sri Gayathri, G., 363
Srilakshmi, U., 53
Srividhyasakthi, V., 363
Stankovic, Marko, 403
Strabykin, Dmitry, 431
Sulthana, Razia, 693
Sumathi, K., 387
Sunkara, Rohith, 315
Sunori, S., 729
Suri, Sushil, 749
T
Taherdoost, Hamed, 723
Tannaris, Ingwen, 639
Tasﬁa, Sheikh, 201
Thavasi, Sheela, 243
Thombre, Aditya, 749
Toradmal, Mahesh Bapusaheb, 737
Turna, Marzia Khan, 201
V
Vaddi, Radhesyam, 511, 523
Vats, Aryan, 839
Verma, Avani, 65
Victor, Kakumanu Christy, 511
Vishnukumar, S., 625
Vishnu Vardhan, I. G., 855
Y
Yashwanth Chowdary, K., 267
Z
Zivkovic, Miodrag, 403
Zyulkov, Alexander, 817

