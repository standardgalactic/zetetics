Analysis of
Single-Cell Data
ODE Constrained Mixture
Modeling and Approximate
Bayesian Computation
Carolin Loos

BestMasters

Springer awards „BestMasters“ to the best master’s theses which have been com-
pleted at renowned universities in Germany, Austria, and Switzerland. 
The studies received highest marks and were recommended for publication by 
supervisors. They address current issues from various fields of research in natural 
sciences, psychology, technology, and economics.
The series addresses practitioners as well as scientists and, in particular, offers 
guid­ance for early stage researchers.

Carolin Loos
Analysis of  
Single-Cell Data
ODE Constrained Mixture ­ 
Modeling and Approximate  
Bayesian Computation

Carolin Loos
München, Germany
BestMasters
ISBN 978-3-658-13233-0	
ISBN 978-3-658-13234-7 (eBook)
DOI 10.1007/978-3-658-13234-7
Library of Congress Control Number: 2016935216
Springer Spektrum
© Springer Fachmedien Wiesbaden 2016
This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part 
of the material is concerned, specifically the rights of translation, reprinting, reuse of illustrations, 
recitation, broadcasting, reproduction on microfilms or in any other physical way, and transmission 
or information storage and retrieval, electronic adaptation, computer software, or by similar or 
dissimilar methodology now known or hereafter developed.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this 
publication does not imply, even in the absence of a specific statement, that such names are exempt 
from the relevant protective laws and regulations and therefore free for general use.
The publisher, the authors and the editors are safe to assume that the advice and information in this 
book are believed to be true and accurate at the date of publication. Neither the publisher nor the 
authors or the editors give a warranty, express or implied, with respect to the material contained 
herein or for any errors or omissions that may have been made.
Printed on acid-free paper
This Springer Spektrum imprint is published by Springer Nature  
The registered company is Springer Fachmedien Wiesbaden GmbH

Acknowledgements
I would like to begin by oﬀering my sincerest gratitude to my supervisor Dr. Jan Hase-
nauer for his immense support, advice and encouragement, and for truly inspiring my
interest in this ﬁeld of research.
I also gratefully acknowledge Dr.
Carsten Marr for
always taking the time to answer my questions and help me with my problems. Fur-
thermore, I would like to thank the members of the groups Data-driven Computational
Modeling and Quantitative Single Cell Dynamics for their feedback, explanations and
interesting discussions. I am highly indebted to Prof. Dr. Dr. Fabian Theis for giving
me the opportunity to work on this interesting project at the ICB. It was a pleasure
to explore this fascinating ﬁeld of research and to write my thesis in such an inspiring
working environment. Last, but not least, I would like to thank my family and friends
for their company and constant support throughout the years.
Carolin Loos

Abstract
Investigating cellular heterogeneity is of great importance for a holistic understanding of
biological processes and is therefore a focus of systems biology. This task requires sophis-
ticated models of single-cell data, which in turn need parameter estimation approaches
that are able to ﬁt these models to given measurement data.
The ﬁrst part of this thesis focuses on using ODE constrained mixture models (ODE-
MMs) for the analysis of single-cell snapshot data. With these models subpopulations can
be identiﬁed and even the source of diﬀerences between subpopulations can be detected.
We investigate the method’s applicability to the study of the alteration of subpopulation
response by the cellular environment with novel data of NGF-induced Erk signaling, a
process relevant in pain sensitization. We enhance the method by providing a mechanistic
description of the variability of the subpopulations using moment equations. In addition,
we propose ODE-MMs for the analysis of multivariate measurements, which accounts for
correlations among the measurands. Applying our method to artiﬁcial data of a con-
version process and to real multivariate data for NGF-induced phosphorylation of Erk
enables an improved insight into the underlying system.
In the second part of this thesis, we study stochastic dynamics of individuals cells that
are modeled with continuous time Markov chains (CTMCs). We introduce a likelihood-
free approximate Bayesian computation (ABC) approach for single-cell time-lapse data.
This method uses multivariate statistics on the distribution of single-cell trajectories. We
evaluate our method for samples of a bivariate normal distribution and for artiﬁcial equi-
librium and non-equilibrium single-cell time-series of a one-stage model of gene expression.
In addition, we assess our method by applying it to data generated with parameter vari-
ability and to tree-structured time-series data. A comparison with an existing method
using statistics reveals an improved parameter identiﬁability using multivariate statistics.
In summary, this thesis introduces two novel approaches for the analysis of multivari-
ate data that can be used to study cellular heterogeneity based on single-cell data.

Kurzfassung
Ein tiefgehendes Verst¨andnis f¨ur die Mechanismen von biologischen Prozessen erfordert
die Erforschung der Heterogeneit¨at von Zellpopulationen. Aus diesem Grund bildet die
Untersuchung heterogener Zellpopulationen aktuell einen Forschungsschwerpunkt in der
Systembiologie. Hierf¨ur werden komplexe mathematische Modelle ben¨otigt, welche wie-
derum Parametersch¨atzungsmethoden erfordern, die in der Lage, sind diese Modelle mit
gegebenen Messdaten zusammenzuf¨uhren.
Der erste Teil dieser Arbeit befasst sich mit der Analyse von Einzelzelldaten, f¨ur welche je-
weils die Verteilungen der gemessenen Konzentrationen in den Zellen zu einem bestimmten
Zeitpunkt gegeben sind. F¨ur diese Analyse nutzen wir ODE constrained mixture models
(ODE-MMs), sogenannte Mischmodelle, welche durch gew¨ohnliche Diﬀerentialgleichungen
beschr¨ankt sind. Mit diesen Modellen k¨onnen Subpopulationen innerhalb einer Zellpo-
pulation ermittelt, und sogar die Ursache f¨ur den Unterschied zwischen den Subpopu-
lationen identiﬁziert werden. Wir verwenden diese Methode erstmals zur Untersuchung
von Ver¨anderung von Subpopulationsreaktionen aufgrund der Zellumgebung. Diese Ana-
lyse erfolgt auf neuen Daten f¨ur die durch NGF induzierte Phosphorylierung von Erk, ein
f¨ur die Schmerzsensitivierung relevanter Prozess. Wir verbessern die Methode, indem wir
Momentengleichungen f¨ur die mechanistische Beschreibung der Subpopulationen verwen-
den. Dar¨uber hinaus entwickeln wir ODE-MMs zur Analyse von multivariaten Messungen,
wodurch Korrelationen zwischen Messungen ber¨ucksichtigt werden. Wir testen unsere Me-
thode anhand von artiﬁziellen Daten eines Konversionsprozesses und anhand multivariater
Messungen f¨ur NGF induzierte Erk-Phosphorylierung. Es zeigt sich, dass unsere Methode
einen genaueren Einblick in das zugrundeliegende biologische System erm¨oglicht.
Im zweiten Teil dieser Arbeit analysieren wir stochastische Dynamiken von individuellen
Zellen, welche durch Markovketten in stetiger Zeit modelliert werden. Hierf¨ur stellen wir
eine auf Approximate Bayesian Computation (ABC) basierende, Likelihood-freie Methode
zur Parametersch¨atzung von Einzellzellzeitreihen vor. Diese Methode nutzt multivariate
Statistiken auf der Verteilung von Einzellzelltrajektorien. Wir evaluieren unsere Methode

X
Kurzfassung
sowohl f¨ur Daten, die durch eine bivariate Normalverteilung generiert wurden als auch
f¨ur artiﬁzielle Einzellzellzeitreihen eines einstuﬁgen Genexpressionmodells, welche sich in
und außerhalb ihres station¨aren Gleichgewichts beﬁnden. Der Vergleich mit einer exis-
tierenden Method, die Statistiken verwendet, verdeutlicht, dass durch eine multivariate
Betrachtung die Modellparameter besser identiﬁziert werden k¨onnen.
Zusammenfassend werden in dieser Arbeit zwei neuartige Methoden zur Analyse von
multivariaten Daten entwickelt. Diese sind geeignet, um heterogene Zellpopulationen ba-
sierend auf Einzelzelldaten zu untersuchen.

Contents
List of Figures
XIII
List of Tables
XV
List of Abbreviations
XVII
List of Symbols
XIX
1
Introduction
1
1.1
Modeling and Parameter Estimation for Single-Cell Data . . . . . . . . . .
1
1.2
Contribution of this Thesis . . . . . . . . . . . . . . . . . . . . . . . . . . .
2
2
Background
5
2.1
Experimental Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5
2.2
Modeling Chemical Kinetics . . . . . . . . . . . . . . . . . . . . . . . . . .
6
2.3
Parameter Inference
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
11
3
ODE Constrained Mixture Modeling for Multivariate Data
15
3.1
Introduction and Problem Statement . . . . . . . . . . . . . . . . . . . . .
15
3.2
Assessment of ODE-MMs Using Novel Data for NGF-Induced Erk Signaling 17
3.3
Modeling Variability within a Subpopulation . . . . . . . . . . . . . . . . .
25
3.4
Simultaneous Analysis of Multivariate Measurements . . . . . . . . . . . .
40
3.5
Application Example: NGF-Induced Erk Signaling . . . . . . . . . . . . . .
50
3.6
Discussion and Outlook
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
54
4
Approximate Bayesian Computation Using Multivariate Statistics
57
4.1
Introduction and Problem Statement . . . . . . . . . . . . . . . . . . . . .
57
4.2
Extended Introduction to Approximate Bayesian Computation . . . . . . .
59
4.3
Approximate Bayesian Computation with Multivariate Test Statistics . . .
65
4.4
Simulation Example: Single-Cell Time-Series of a One-Stage Model of Gene
Expression . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
74

XII
Contents
4.5
Discussion and Outlook
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
82
5
Summary and Discussion
85
Bibliography
87

List of Figures
2.1
Experimental single-cell data. . . . . . . . . . . . . . . . . . . . . . . . . .
6
2.2
Illustration of SSA, MEs and RREs. . . . . . . . . . . . . . . . . . . . . . .
11
3.1
Illustration of ODE constrained mixture modeling.
. . . . . . . . . . . . .
18
3.2
Model for NGF-induced Erk phosphorylation.
. . . . . . . . . . . . . . . .
20
3.3
Snapshot data of NGF-induced Erk signaling under two diﬀerent experi-
mental conditions.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
21
3.4
Hypothesis testing for NGF-induced Erk signaling under two diﬀerent ex-
perimental conditions.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
23
3.5
Fitted data for optimal model MH4. . . . . . . . . . . . . . . . . . . . . . .
24
3.6
Schematic representation of a conversion process between species A and B.
29
3.7
Artiﬁcial data for diﬀerent scenarios of a conversion process. . . . . . . . .
30
3.8
Fitted data and comparison of proﬁle likelihoods for ODE-MMs with RREs
and MEs.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
34
3.9
Fitted data and proﬁle likelihoods for Scenarios 2 and 3.
. . . . . . . . . .
39
3.10 Scatterplot and marginals of measurands A and B with positiv and negative
correlation.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
40
3.11 Performance comparison for the numerically more stable and the classical
calculation of the likelihood. . . . . . . . . . . . . . . . . . . . . . . . . . .
46
3.12 Artiﬁcial multivariate data of a conversion process of A and B with cell-to-
cell variability in the total number of molecules N0. . . . . . . . . . . . . .
47
3.13 Fitted data and proﬁle likelihoods for the univariate and multivariate case.
49
3.14 Experimental data of NGF-induced Erk phosphorylation. . . . . . . . . . .
51
3.15 Fitted data of NGF-induced Erk phosphorylation for the optimal model.
.
56
4.1
Illustration of the cross-match test. . . . . . . . . . . . . . . . . . . . . . .
68
4.2
Function ˆf∗witnesses the MMD.
. . . . . . . . . . . . . . . . . . . . . . .
69
4.3
ABC SMC using test statistics to estimate the mean of a bivariate normal
distribution. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
73

XIV
List of Figures
4.4
ABC SMC using test statistics to estimate entries of the covariance matrix
of a bivariate normal distribution. . . . . . . . . . . . . . . . . . . . . . . .
74
4.5
Illustration of artiﬁcial single-cell time-lapse data. . . . . . . . . . . . . . .
76
4.6
ABC SMC for out of steady state time-series data.
. . . . . . . . . . . . .
78
4.7
ABC SMC for steady state time-series data. . . . . . . . . . . . . . . . . .
80
4.8
ABC SMC for cells aﬀected by extrinsic noise. . . . . . . . . . . . . . . . .
81
4.9
ABC SMC for tree-structured data. . . . . . . . . . . . . . . . . . . . . . .
82

List of Tables
3.1
Hypothesis testing for two experimental conditions using AIC and BIC. . .
24
3.2
Results of parameter estimation and model selection for Scenario 1 using
ODE-MMs with RREs.
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
35
3.3
Results of parameter estimation and model selection for Scenario 1 using
ODE-MMs with MEs.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
35
3.4
Results for model selection for Scenario 2.
. . . . . . . . . . . . . . . . . .
37
3.5
Results for model selection for Scenario 3.
. . . . . . . . . . . . . . . . . .
38
3.6
Results for model selection for NGF-induced Erk signaling. . . . . . . . . .
53

List of Abbreviations
ABC
approximate Bayesian computation
ABC SMC
approximate Bayesian Computation with sequential Monte Carlo
AIC
Akaike information criterion
BIC
Bayesian information criterion
CM
cross-match test
CME
chemical master equation
CTMC
continuous time Markov chain
FSP
ﬁnite state projection
KS
Kolmorgorov-Smirnov
MAP
maximum a posteriori
MCMC
Markov chain Monte Carlo
ME
moment equation
MLE
maximum likelihood estimate
MME
maximum mean discrepancy
ODE
ordinary diﬀerential equation
ODE-MM
ODE constrained mixture model
RRE
reaction rate equation
SSA
stochastic simulation algorithm

List of Symbols
Chapter 2
θ
parameter vector
D
data
νij
stochiometric coeﬃcient
aj(x)
propensity function for reaction j
L(θ)
likelihood function of θ given D (conditional probability)
p(θ)
prior probability of θ
p(θ|D)
posterior probability of θ given D
Chapter 3
ψ
parameters of a subpopulation
log N(y|μ, Σ) multivariate log-normal distribution
log N(y|μ, σ2) univariate log-normal distribution
N(y|μ, Σ)
multivariate normal distribution
N(y|μ, σ2)
univariate normal distribution
C
covariances of the species of the system
m
means of the species of the system
x
state vector of the moments of the species
Cy, Cy
(co)variance(s) of the measurand(s)
f
function describing time evolution of the moments

XX
List of Symbols
h
linking function of mixture parameters and state vector of the moments
my, my
mean(s) of the measurand(s)
ns
number of subpopulations
p(y|ϕ)
mixture probability
u
external stimulus
we
s
weight of subpopulation s under experiment e
Chapter 4
α
conﬁdence level
ϵt
threshold for population t
ϵend
threshold for ﬁnal population
γ
mRNA degradation rate
ˆFX
empirical cumulative distribution
λ
mRNA synthesis rate
Dobs
observed data
Dsim
simulated data
S(D)
summary statistic of data D
X
samples of Dobs
Y
samples of Dsim
Al
random variable counting pairs with exactly l nodes of observed samples
cmax
number of cross-matches for ﬁnal population
dKS(·, ·)
Kolmogorov-Smirnov distance
k(·, ·)
Gaussian kernel

List of Symbols
XXI
Kt(·|·)
perturbation kernel
m
number of simulated data points
n
number of observed data points
nt
number of measured time points
P
number of particles per populations
p(Dsim|θ)
simulation function
p, q
underlying distributions of X and Y
T
number of populations
w(t)
i
weight of particle θ(t)
i
in population t

1 Introduction
The goal of systems biology is to understand biochemical processes as a whole (Kitano,
2002). This is accomplished by analyzing biological experimental data with computational
models that describe the dynamical behavior of the system (Cho & Wolkenhauer, 2005).
Often population averaged data is considered, which only contains information about the
mean behavior of the cells. Such data is for example produced by microarrays (Malone
& Oliver, 2011) or Western blots (Renart et al., 1979). Using population averaged data,
cellular heterogeneity, i.e., diﬀerences among isogenic cells, can not be captured and sub-
population structures remain concealed (Altschuler & Wu, 2010).
Eludicating heterogeneity is a goal of current research, as it has been shown to have
important implications for cell fate decisions. The consequences of heterogeneity have
been studied for several types of cells, ranging from stem cells (e.g. (Torres-Padilla &
Chambers, 2014)) to cancer cells (e.g. (Michor & Polyak, 2010)).
1.1 Modeling and Parameter Estimation for Single-Cell
Data
Analysis of heterogeneity requires measurements performed at the single-cell level, which
can be obtained using techniques such as ﬂow cytometry (Pyne et al., 2009) or ﬂuores-
cent microscopy (Muzzey & Oudenaarden, 2009; Schroeder, 2011; Miyashiro & Goulian,
2007). Elowitz et al. (2002) placed two identically regulated reporter genes in the same
cell and identiﬁed diﬀerent sources of heterogeneity by analyzing the corresponding single-
cell data. The overall variation of gene expression can be partitioned into extrinsic and
intrinsic noise. Variability that aﬀects both reporter genes equally corresponds to extrin-
sic noise. Diﬀerences in gene expression arising due to random births and deaths of single
molecules are called intrinsic noise.
While most models only describe the mean behavior of the cells (Resat et al., 2009),
studying heterogeneity requires more detailed models, which take the single-cell nature of
© Springer Fachmedien Wiesbaden 2016
C. Loos, Analysis of Single-Cell Data, BestMasters, 
DOI 10.1007/978-3-658-13234-7_1

2
1 Introduction
the data into account. A possibility to incorporate intrinsic noise is to model birth and
death processes of individual molecules as continuous time Markov chains (CTMCs) with
stochastic chemical kinetics (Gillespie, 2007). There are also deterministic approaches,
which describe statistics of CTMCs and account for variability instead of only considering
the mean behavior. An example of such an approach is the method of moments (Engblom,
2006).
Appropriate models for experimental data should not only capture important properties
of the system that are being investigated but should also consider the trade-oﬀbetween
simplicity and accuracy. When the dimension of the parameter space increases, the model
generally loses predictive power. Moreover, when the model gets more detailed the simu-
lation of the model gets more complex (Wilkinson, 2009).
Understanding heterogeneity requires eﬃcient parameter inference, since studying a data-
based model requires knowledge of the model parameters such as kinetic rates and ini-
tial conditions. However, most of these parameters can not be measured experimentally
and need to be estimated from the available data (Lillacci & Khammash, 2010). While
standard approaches to estimate parameters from observed data maximize the likelihood
function, a function that represents the probability of observing a data set given some
parameters, this approach is intractable for many stochastic models as the likelihood
function is computationally too costly. This problem is tackled by using likelihood-free
methods, which are also called approximate Bayesian computation (ABC) methods (Mar-
joram et al., 2003). These methods circumvent the evaluation of the likelihood function
by comparing observed and simulated data sets. Unfortunately, inferring the model pa-
rameters based on experimental data in general gets more challenging for stochastic mod-
els (Wilkinson, 2009).
1.2 Contribution of this Thesis
In this thesis, we study computational models that account for heterogeneity in cell popu-
lations. We calibrate these models to artiﬁcial and real experimental data at the single-cell
level with parameter estimation techniques that are suited to the complexity of the mod-
els. This thesis is structured as follows:

1.2 Contribution of this Thesis
3
Chapter 2 introduces two types of single-cell data and presents the key concepts needed for
their analysis. This comprises computational modeling of the data, which uses stochastic
chemical kinetics. Experimental data and the derived models are ﬁtted by performing
parameter inference.
In Chapter 3, we focus on ODE constrained mixture modeling (ODE-MM), an approach
that combines mixture probabilities and a mechanistic description for the behavior of
individual subpopulations of a cell population. We evaluate the method of ODE-MMs
by using it for the detection of altered subpopulation responses under diﬀerent experi-
mental conditions. For this, we consider novel single-cell snapshot data of NGF-induced
Erk phosphorylation. In addition, we enhance the method by using moment equations
for the description of the underlying biological process. Moreover, in order to gain even
more information from the data we develop the method for the analysis of multivariate
measurements. We assess our method by applying it to artiﬁcial data of a conversion
process and to real experimental data of NGF-induced phosporylation of Erk.
In Chapter 4, we develop an ABC method using multivariate test statistics for single-
cell time-lapse data that are modeled with CTMCs. We introduce two multivariate test
statistics and evaluate the respective ABC methods on a bivariate normal distribution.
In addition, we apply our method to artiﬁcial single-cell time-lapse data of a one-stage
model of gene expression, accounting for extrinsic cell-to-cell variability and cell division.
In Chapter 5 we summarize our results and draw conclusions.

2 Background
This chapter introduces the key concepts that are needed to understand this thesis. First,
we describe the diﬀerent types of experimental data that are analyzed. Afterwards, the
principles of modeling of chemical kinetics are introduced with a focus on the chemical
master equation (CME) and its approximations.
Finally, we show how experimental
data and biological models can be brought together with inference. Inference consists of
parameter optimization, identiﬁability and uncertainty analysis, and model selection.
2.1 Experimental Data
In this thesis, we consider and distinguish two diﬀerent types of single-cell data D that
provide information about cell-to-cell variability and are frequently collected in biological
research.
Single-cell snapshot data D = {{yj(tk)}j}nt
k=1 provide single-cell measurements for nt
time instances tk (see Figure 2.1A). Common approaches to generate these data are, e.g.,
ﬂow cytometry (Davey & Kell, 1996) or single-cell microscopy (Miyashiro & Goulian,
2007). A key advantage of these technologies is the possibility of measuring many genes
of plenty of single-cells with low costs. As the cells are not tracked over time, no infor-
mation about the time-course of an individual cell is available.
To obtain temporal information single-cell time-lapse data D = {{yj(tk)}nt
k=1}j (see Fig-
ure 2.1B) are required. Single-cell time-lapse data are typically obtained by conducting
ﬂuorescent time-lapse microscopy (Muzzey & Oudenaarden, 2009) followed by single-cell
tracking (Schroeder, 2011) and image analysis. This approach provides a smaller number
of cells than the technologies described before and the generation of single-cell time series
is expensive and time-consuming. On the other hand, cells are tracked over time yielding
a higher information content of the data.
© Springer Fachmedien Wiesbaden 2016
C. Loos, Analysis of Single-Cell Data, BestMasters, 
DOI 10.1007/978-3-658-13234-7_2

6
2 Background
A
B
Figure 2.1: Measurement data at the single-cell level adopted from Hasenauer (2013):
(A) Illustration of single-cell snapshot data of some measurement y. (B) Il-
lustration of single-cell time-lapse data for ﬁve individual cells.
2.2 Modeling Chemical Kinetics
For the detailed analysis of single-cell data, mechanistic mathematical models are used.
One possibility is the use of stochastic chemical kinetics, which model biochemical reaction
networks as continuous-time discrete-state Markov chains (CTMCs). The time evolution
of a CTMC is governed by the CME. A process deﬁned by the CME can either be simulated
with the stochastic simulation algorithm (SSA) or its solution can be approximated e.g.
with the moment equations (ME). While stochastic modeling is especially important in the
case of low-copy numbers, we assume that for high numbers of molecules the system can
be described by its average behavior. This can be modeled in a deterministic way by ﬁrst
order ordinary diﬀerential equations (ODEs) describing the evolution of concentrations of
the species.
2.2.1 Stochastic Chemical Kinetics
Stochastic models are mostly used to describe a biological process, when it is important
to consider that molecules only appear in whole numbers (Wilkinson, 2009; Resat et al.,
2009). This discreteness yields a stochasticity in the dynamics of the molecules and espe-
cially has to be taken into account if only few numbers of molecules are present.
Stochastic chemical kinetics describe the time evolution of a chemical system consist-
ing of L chemical species x1, . . . , xL that interact inside a volume Ω through M reactions
R1, . . . , RM. A reaction Rj has the form

2.2 Modeling Chemical Kinetics
7
ν−
1jx1 + . . . + ν−
LjxL
kj
−→ν+
1jc1 + . . . + ν+
LjxL,
with stochiometric coeﬃcients ν+
ij, ν−
ij ∈N0 and reaction rate kj. A state of the system is
represented by a vector x(t) ∈NL
0 . Each entry of the vector is the number of molecules of
the corresponding species. The stochiometric matrix S = (s1, . . . , sM) ∈RL×M is deﬁned
by {Sij} = 
ν+
ij −ν−
ij

:= {νij}. Each entry of the matrix describes the change in the
number of molecules of species xi due to a reaction of type j, i.e., the state x changes to
x + sj after reaction Rj took place. The probability that reaction Rj happens in the next
inﬁnitesimal time interval [t, t + dt) is aj(x)dt, with propensity function aj(x).
Several assumptions are typically made when deriving a model of a biological process,
e.g. that the system has a constant volume Ω and is well-stirred, i.e., the probability
of some molecules of a species being in one particular region is uniform over the vol-
ume (Gillespie, 2007). We consider zero-order reactions, which are independent of the
number of molecules, unimolecular reactions, in which just a single molecule is necessary
to conduct the reaction, and bimolecular reactions, for which two molecules need to col-
lide. Higher order reactions can easily be integrated into the methods proposed in this
thesis.
2.2.2 Chemical Master Equation
The CME governs the evolution of the probability that the stochastic process is in a
particular state, given by p(x, t), over time (Gillespie, 1992). The probability p(x, t|x0, t0)
is conditioned on the system being in state x0 at time t0. To obtain an evolution equation
the probability p(x, t + dt|x0, t0) is ﬁrst derived in terms of p(x, t|x0, t0), by assuming dt
is small enough that at most one reaction can occur in the time interval [t, t + dt). One
possibility for the system being in state x at time t + dt is that it already has been in
this state and no reaction has taken place since time t, which happens with probability
1 −M
j=1 aj(x)dt + O(dt). Another scenario is that the system has been in state x −sj
and a reaction of type j occurred with probability aj(x −sj)dt, which yields M more
possibilities. After summing up the probabilities and taking the limit dt →0, we obtain
the CME

8
2 Background
dp(x, t|x0, t0)
dt
=
M

j=1
[p(x −sj, t|x0, t0)aj(x −sj) −aj(x)p(x, t|x0, t0)] ,
with initial condition
p(x, t = t0|x0, t0) =
⎧
⎨
⎩
1,
x = x0
0,
x ̸= x0
.
If we neglect x0 and t0 for a simpler notation we obtain
dp(x, t)
dt
=
M

j=1
[p(x −sj, t)aj(x −sj) −aj(x)p(x, t)] ,
with initial condition p(x, t0) = p0(x).
The CME indeed completely determines the
probability p(x, t|x0, t0) and thus totally describes the system. However, it consists of
a system of coupled ordinary diﬀerential equations (ODEs), with one ODE for every
possible state of the system. Since the state space of a biological system is mostly high
dimensional or even inﬁnite dimensional, the CME can only be solved analytically or in
a feasible numerical way for a few simple cases (e.g. (Jahnke & Huisinga, 2007)).
2.2.3 Stochastic Simulation Algorithm
Instead of solving the CME, it is possible to simulate samples in form of trajectories and
thereby recover the underlying probability distribution. This is motivated by the fact
that the chance of a particular trajectory being simulated corresponds to the probabil-
ity given by the CME. A possibility to obtain trajectories is the SSA (Gillespie, 1977).
This algorithm enables an exact simulation of trajectories consistent with the probability
distribution and the transition probabilities that are associated with the CME. For the
direct method of stochastic simulation we deﬁne
• the sum over all reaction propensities a0(x) = M
j=1 aj(x),
• the time τ to the next reaction,
• the index j of the next reaction.
It can be shown that τ is exponentially distributed with rate a0(x) and j has density
aj(x)
a0(x), which yields the following algorithm:

2.2 Modeling Chemical Kinetics
9
Algorithm 2.1: Direct method
Input: Initial condition x0 ∈NL
0 ,
ﬁnal simulation time tend,
reaction propensity functions aj(x), j = 1, . . . , M,
stochiometric matrix S = (s1, . . . , sM) ∈ZLxM.
Result: Time trajectory of state vector x(t).
Set t ←0 and x ←x0.
while t < tend do
Evaluate reaction propensity functions aj(x) and calculate
a0(x) = M
j=1 aj(x).
Generate two uniformly distributed independent random numbers r1 and r2.
Calculate the time until the next reaction takes places by τ =
1
a0(x) log(1/r1).
Find the index j of the next reaction that satisﬁes M
j=1 aj(x) > r2a0(x).
Update the state of the system x ←x + sj.
Update the time t ←t + τ.
end
An example of trajectories obtained by this method is shown in Figure 2.2 for a conversion
process (see Section 3.3.2). The computation can be ineﬃcient if lots of events have to be
simulated. Therefore, approximations such as τ-leaping have been introduced (for further
information see (Gillespie, 2007)).
2.2.4 Method of Moments
A possibility to approximate the solution of the CME and thereby avoid the computational
costs of the SSA is the method of moments (Engblom, 2006). This method computes the
moments of p(x, t), i.e., the mean
mi(t) =

x∈Ω
xip(x, t),
i = 1, . . . , L ,
of species xi, and higher order moments such as the covariance
Cij(t) =

x∈Ω
(xi −mi(t))(xj −mj(t))p(x, t),
i, j = 1, . . . , L ,

10
2 Background
of species xi and xj. The time evolution of the moments is described by a set of ODEs,
the so-called moment equations (MEs). If the system comprises bimolecular reactions,
the calculation of higher order moments is recursive, i.e., the evolution of a moment of
order k depends on moments of order k + 1. In this case moment closure techniques
must be applied, introducing an approximation error (Lee et al., 2009). Formulas for
the ﬁrst and second order moments of system with at most bimolecular reactions, can
be found in (Engblom, 2006, Proposition 2.5.). The ﬁrst and second order moments,
namely mean and variance, of the solution statistics for a conversion process are depicted
in Figure 2.2. If a system comprises low- and medium/high-copy species the method
of conditional moments (Hasenauer et al., 2014a) can be used. This method conditions
the moments of species with medium or higher abundance on the states of species that
are only present in low-copy numbers.
Therefore, it accounts for the stochasticity of
the processes, arising due to the discreteness of the low-abundance species. The method
avoids the computational costs arising from a full stochastic description of the system
using MEs for the medium and high-copy species.
2.2.5 Reaction Rate Equation
In the limit of large numbers of molecules, the system behaves in a more deterministic way
and the importance of considering single molecules vanishes. Therefore, measurements
are at a continuous level, in contrast to the discrete state space of stochastic modeling.
The evolution of the system is captured by the reaction rate equations (RREs) (Resat
et al., 2009; Gillespie, 2007)
dx(t)
dt
=
M

j=1
sjaj(x(t)) .
For some simple systems an explicit formula for the solution of the RREs can be derived,
but mostly numerical integration is need. Nevertheless, deterministic simulations of a
system are generally faster than a stochastic simulation (Szekely & Burrage, 2014).

2.3 Parameter Inference
11
time
t1
t2
t3
t4
t5
t6
number of molecules
trajectories
ME mean
ME mean±std.dev.
RRE
Figure 2.2: Example of trajectories of one species of a conversion process obtained by
the SSA (gray), the corresponding approximation with MEs (red) and RREs
(blue), where the mean described by ME and the RRE coincident.
2.3 Parameter Inference
The idea of parameter inference is to combine observed data D and a model M, which
for example has been derived with techniques presented in the previous section. Such
a model comprises parameters, for example kinetic rates or initial conditions, and some
of these parameters denoted by θ ∈Rnθ may be unknown, because either they are not
measured or it is impossible to measure them.
2.3.1 Parameter Estimation
A common approach to estimate the parameters of a model is to maximize the likelihood
function
L(θ) = p(D|θ) ,
which describes the conditional probability of observing D given θ. Due to better numer-
ical properties for optimization, usually the negative log-likelihood function
J(θ) = −log L(θ)
is minimized. The parameters θML that maximize the likelihood function (or minimize the
negative (log-)likelihood function) are called the maximum likelihood estimates (MLE).

12
2 Background
In a Bayesian framework we can additionally incorporate prior knowledge about the pa-
rameters using the prior distribution p(θ) (Hastie et al., 2009). Applying Bayes’ theorem
yields the posterior distribution of the parameters
p(θ|D) = p(D|θ)p(θ)
p(D)
∝p(D|θ)p(θ) .
The parameters θMAP that maximize the posterior distribution are the maximum a poste-
riori estimate (MAP), the Bayesian counterpart of the MLE. The evaluation of the normal-
izing constant p(D) = 	
p(D|θ)p(θ)dθ can be computationally expensive or unfeasible.
However, this constant can be neglected for optimization and uncertainty analysis, as it is
only needed for model selection based on Bayes factors (Raftery, 1999). The minimization
of the negative log-likelihood function can be eﬃciently performed using multi-start local
optimization. For this, the initial values for the optimizer are e.g. obtained by Latin
hypercube sampling and then are chosen in a sequential way, such that the correspond-
ing objective function values are decreasing (Raue et al., 2013). For the optimization
procedure the calculation of the gradient is of great importance, as the derivative of the
objective function is used to determine the next parameter value. For the calculation
of the derivatives ﬁnite diﬀerences or sensitivity analysis can be used (Sengupta et al.,
2014). Sensitivity analysis describes the derivatives of the objective function with respect
to the parameters. Using them, the gradient can be calculated numerically more robustly.
Additionally, we use log-transformed parameters ξ = log(θ) due to better convergence
properties.
If the likelihood cannot be expressed analytically or is computationally too costly to
evaluate, so-called likelihood-free parameter estimation methods are required. This class
of methods circumvents the calculation of the likelihood function and is also known under
the name approximate Bayesian computing (ABC) (Csill´ery et al., 2010). We explain
these methods in more detail in Section 4.2, as they are the focal point of the work
described in Chapter 4.
2.3.2 Identiﬁability and Uncertainty Analysis
Due to the structure of the examined system and limitations of the available data some
parameters can be non-identiﬁable (Raue et al., 2009), i.e., the parameter can not be

2.3 Parameter Inference
13
determined from the data. If this is the case even for perfect data, the parameter is
structurally non-identiﬁable. If the parameter can not be identiﬁed due to measurement
noise or too little data, the parameter is practically non-identiﬁable. Studying these un-
certainties is an important step of parameter inference and explained in the following.
A common approach to analyze uncertainties of the parameters is to calculate conﬁdence
intervals, e.g. asymptotic conﬁdence intervals based on the curvature of the likelihood,
such as the hessian, or ﬁnite sample conﬁdence intervals based on proﬁle likelihoods (for
further information see (Raue et al., 2009)). A parameter θ is practically identiﬁable from
the corresponding data, if the corresponding conﬁdence intervals are ﬁnite.
In a Bayesian context, in which parameters are treated as random variables, we can
get information about the uncertainty of the estimates by considering the whole posterior
distribution. Because of a possibly high dimension of the parameter space or the lack of
a closed form for the posterior, the use of numerical sampling from the posterior distri-
bution is required. Samples from the posterior distribution can be obtained by Markov
chain Monte Carlo (MCMC) methods (Gilks et al., 1996).
2.3.3 Model Selection
The last step of parameter inference is to select an optimal model of out a given set
of candidate models M1, . . . , Ml that have been derived for some data D. On the one
hand, the chosen model should ﬁt the data very well, which can be easily improved by
increasing the number of parameters. On the other hand, the model should be as simple
as possible to provide reliable predictions and avoid unnecessary uncertainties. We intro-
duce two existing criteria for model selection that try to solve the trade-oﬀbetween over-
and underﬁtting of the data. Both criteria consist of a term with the likelihood value of
the maximum likelihood estimate and a penalization term for a higher complexity of the
model.
The Akaike information criterion (AIC) is based on information theoretical concepts
(Akaike, 1998). It gives an estimate for Kullback-Leibler divergence between the den-
sities of the true unknown model and of a candidate model Mk by

14
2 Background
AICk = −2 log(p(D|θML,k)) + 2nθ,k ,
with θML,k denoting the MLE for model Mk and nθ,k denoting the number of parame-
ters of the model. A low value of the AIC indicates that less information has been lost
considering the candidate model and therefore a higher reliability. We reject models with
ΔAIC = AICk −AICmin > 10 as proposed by Burnham & Anderson (2002).
A Bayesian criterion for model selection can be derived by examining the posterior prob-
ability p(k|D) of model Mk (see (Schwarz et al., 1978) for further information). This
criterion is called the Bayesian information criterion (BIC),
BICk = −2 log(p(D|θML,k) + log(nD)nθ,k ,
with nD denoting the number of data points. As with the AIC, the model with the lowest
BIC is chosen and we reject models with ΔBIC = BICk −BICmin > 10 (Raftery, 1999).
In summary, this chapter outlined the key principles that are used in the following chap-
ters of this thesis. We introduced single-cell snapshot data and single-cell time-lapse data,
which possess diﬀerent information contents and number of data points. We discussed
diﬀerent approaches to solve the CME, ranging from exact solutions obtained with the
SSA to approximations with MEs and showed the link to deterministic modeling by RREs.
Moreover, this chapter contains an introduction to parameter inference, including parame-
ter estimation, identiﬁability and uncertainty analysis, and model selection. We presented
the approach of maximum likelihood estimation using multi-start local optimization, and
deﬁned the posterior distribution that is used in a Bayesian context. For identiﬁability
and uncertainty analysis, proﬁle likelihoods and MCMC sampling schemes can be used.
Finally, we introduced the AIC and BIC, two criteria used for model selection.

3 ODE Constrained Mixture Modeling
for Multivariate Data Using Moment
Equations
The focus of this chapter is to assess, improve and extend ODE constrained mixture model-
ing (ODE-MM) (Hasenauer et al., 2014b), a method for studying dynamics and structures
of subpopulations. In Section 3.1, we introduce the underlying method and formulate the
problems that are subsequently addressed in the following sections. In Section 3.2, we
apply ODE-MMs to novel single-cell snapshot data for NGF-induced Erk signaling. We
evaluate the applicability of ODE-MMs to unravel alteration of subpopulation response
by cellular environment. In addition, we increase the insight into the underlying biological
system that can be gained using ODE-MMs. In Section 3.3, we present ODE-MMs with
moment equations (Engblom, 2006) for the mechanistic description of a biological pro-
cess, which yields the ability to account for variability within a subpopulation. Additional
knowledge of the system can also be gained by considering multivariate measurements si-
multaneously. For this, Section 3.4 provides a likelihood for ODE-MMs that is able to
take correlations between the measurements into account. Our method is validated for
the example of a conversion process and applied to real experimental multivariate data
of NGF-induced Erk signaling (Section 3.5). The results are summarized in Section 3.6,
in which we outline possible further extensions and improvements of our method.
3.1 Introduction and Problem Statement
Cell populations exhibit diﬀerent degrees of heterogeneity caused by cell-to-cell variability.
Even cells with similar cell types can respond diﬀerently to identically stimuli. Studying
cell heterogeneity and its sources is important for a holistic understanding of the underly-
ing biological processes and cellular mechanisms. Therefore, this task comprises not only
the identiﬁcation of subpopulations, but also the detection of how the subpopulations
diﬀer.
© Springer Fachmedien Wiesbaden 2016
C. Loos, Analysis of Single-Cell Data, BestMasters, 
DOI 10.1007/978-3-658-13234-7_3

16
3 ODE Constrained Mixture Modeling for Multivariate Data
3.1.1 ODE Constrained Mixture Modeling
A recently presented method using ODE constrained mixture models (ODE-MM) (Hase-
nauer et al., 2014b) can describe the mechanisms of a process and at the same time is
able to exploit subpopulation structures. This is achieved by modeling subpopulation
dynamics with RREs and treating diﬀerent subpopulations as individual components of
a mixture distribution. Combining these two approaches, the method beneﬁts from both,
the possibility to include distributional information and from getting mechanistic insights
using ODEs. Using ODE-MMs, population snapshot data can be analyzed across diﬀerent
experimental conditions. Moreover, it has been shown that even the causal diﬀerences
between subpopulations can be revealed.
Based on single-cell snapshot data {De
k}e,k the unknown parameters θ = {(we
s, ψe
s, σe
s)}s,e
of properties of the ns subpopulations can be estimated maximizing the likelihood function
L(θ) :=

e,k,j
ns

s=1
we
sp

ye,k
j |ϕe
s (tk)

(3.1)
s.t. ˙xe
s = f (xe
s, ψe
s, ue) , xe
s(0) = x0(ψe
s, ue) ,
ϕe
s = h(xe
s, ψe
s, ue) .
The indices e, k and j are for the experimental conditions, the time point and the single-
cells, respectively. Moreover, p

yk,e
j |ϕe(tk)

is a mixture distribution, e.g. a normal or
log-normal distribution with mixture parameters ϕe
s = (μe
s, σe
s) and mixture weights we
s
that sum up to 1. The ODE model given by reaction rate equations (RREs) is denoted
by f. The means are linked to the RRE model by the function h. The variances needs
to be estimated from the data and therefore are listed in the parameter vector θ. The
parameters ψe
s = 
ξ0, ξe
0, ξ0
s, ξe
s

are e.g. kinetic parameters or initial conditions. Here, ξ0
are the parameters that are the same for all conditions and subpopulations, ξe
0 and ξ0
s the
parameters that are diﬀerent across experiments or subpopulations, respectively, and ξe
s
the parameters that diﬀer between experiments and subpopulation. We added the index
e to the subpopulation parameters ψe
s and the mixture weights we
s to allow the parameter
to diﬀer between experiments, since we use ODE-MMs to detect diﬀerences between
experimental conditions. The system is stimulated with an external, possibly experiment
speciﬁc stimulus denoted by ue. For an illustration of the method see Figure 3.1.

3.2 Assessment of ODE-MMs Using Novel Data for NGF-Induced Erk Signaling
17
3.1.2 Problem Statement
Despite the successes achieved using ODE-MM, there are several open issues. So far, only
the means of the subpopulations are described by ODEs and the variances are treated
as additional parameters. If many time points and experimental conditions are observed,
the unknown variances increase the dimension of the parameter space signiﬁcantly. As
the predictive power of a model generally decreases with its complexity, it is desirable
to reduce the number of its parameters. Moreover, RREs provide only a description of
the averaged behavior of a subpopulation. They are neither able to describe intrinsic
noise, arising due to stochasticity of births and deaths of single molecules, nor extrinsic
noise, emerging from stochastic variability of parameters. Furthermore, it is not possible
to exploit correlation structures among multivariate measurements, as they only can be
analyzed independently. Even if subpopulations can be identiﬁed, correlation structures
among the measurements may not be detected analyzing one measurement at a time. In
particular, this chapter addresses the following problems:
Problem 1 High dimension of the parameter space.
Problem 2 No mechanistic description of intrinsic variability of subpopulations.
Problem 3 No accounting for extrinsic noise in a subpopulation.
Problem 4 No consideration and detection of correlations between multivariate mea-
surements.
Problem 5 Numerical instability arising due to mixture modeling.
In the following, we will address these problems by extending ODE-MM. Furthermore,
as there are merely two assessments of ODE-MM, will provide additional evaluations on
artiﬁcial as well as real experimental data.
3.2 Assessment of ODE-MMs Using Novel Data for
NGF-Induced Erk Signaling
Understanding intracellular signaling mechanisms that regulate pain sensitization is of
great importance for pain research. Therefore, the underlying processes of NGF-induced
Erk phosphorylation are studied. ODE-MMs have been used to investigate this pathway

18
3 ODE Constrained Mixture Modeling for Multivariate Data
stimulus
subpopulation 1

subpopulation 2

time
stimulus
subpopulation 1
subpopulation 2
t0
t1
t2
t0
t1
t2
ODE-MM 
= 
mixture modeling of the 
distribution at t0, t1 and t2 
+ 
modeling of subpopulation 
mean by ODE mechanistic model 
(e.g. reaction rate equation)  
u
˙μ1 = f(μ1, ξ1, u)
˙μ2 = f(μ2, ξ2, u)
Φ = w1φ(y|μ1, σ1)
+ w2φ(y|μ2, σ2)
Signaling pathway
⇒˙μ = f(μ, ξ, u)
l
+ assumption 
about source 
of cell-to-cell 
variability
measured quantity y
time
measured quantity y
Figure 3.1: Illustration of ODE constrained mixture modeling. The combination of mix-
ture modeling of experimental data and pathway information allows us im-
proved aquisition of subpopulation structures and mechanistics. This ﬁgure
has been adopted from (Hasenauer et al., 2014b).
in primary sensory neurons (Hasenauer et al., 2014b). These cells are used to study pain
sensitization and provide a suitable application for ODE-MM due to their high hetero-
geneity.
In this section we evaluate the usage of ODE-MMs to study not only diﬀerences among
individual subpopulations, but also diﬀerences between experimental conditions. We in-
vestigate the alteration of subpopulation response by cellular environment. Therefore,
we describe a simple pathway model of NGF-induced Erk activation introduced by Hase-
nauer et al. (2014b), which builds the basis for further analysis. We analyze experimental
data of NGF-induced Erk signaling that has been generated under several experimental

3.2 Assessment of ODE-MMs Using Novel Data for NGF-Induced Erk Signaling
19
conditions by Katharina M¨oller and Tim Hucho1. Here, we present the analysis of two of
these conditions by applying ODE-MMs with RREs with the aim to detect the source of
diﬀerence between the conditions.
3.2.1 Pathway Model for NGF-Induced Erk Phosphorylation
The pathway model of NGF-induced Erk phosporylation proposed by Hasenauer et al.
(2014b) states that binding of NGF and the receptor TrkA results in a complex TrkA:NGF,
which induces phosporylation of Erk. This process can be described with the reactions
R1 :
TrkA + NGF →TrkA:NGF ,
rate = k1[TrkA][NGF] ,
R2 :
TrkA →TrkA + NGF ,
rate = k2[TrkA:NGF] ,
R3 :
Erk →pErk ,
rate = k3[TrkA:NGF][Erk] ,
R4 :
Erk →pErk ,
rate = k4[Erk] ,
R5 :
pErk →Erk ,
rate = k5[pErk] .
Assuming conservation of mass yields
[TrkA] + [TrkA:NGF] = [TrkA]0 ,
[NGF] + [TrkA:NGF] = [NGF]0 ,
[Erk] + [pErk] = [Erk]0 .
To eliminate structurally non-identiﬁable parameters, the model can be reparametrized.
The ﬁnal RREs are (see (Hasenauer et al., 2014b) for further details)
dx1
dt = k1[NGF]0(k3[TrkA]0 −x1) −k2x1 ,
dx2
dt = (x1 + k4)(s[Erk]0 −x2) −k5x2 ,
y = x2 ,
with x1 = k3[TrkA:NGF] and x2 = s[pErk]. The measurand y = s[pErk] can only be
measured up to some scaling constant s. This pathway model has been studied using
1Division of Experimental Anesthesiology and Pain Research at the Department of Anesthesi-
ology and Intensive Care Medicine at the University Hospital Cologne

20
3 ODE Constrained Mixture Modeling for Multivariate Data
pErk
rk
Er
TrkAA
NGF
pEr
Erk
Trk
Trk
Trk
Trk
Er
Er
Er
Erk
pEr
pEr
pErk
rk
subpopulation 1 
         (low TrkA) 
subpopulation 2 
(high TrkA) 
TrkA
NGF
NGF
NGF
NGF
NGF
NGF
NGF
NGF
TrkA
TrkA NGF
NGF
NGF
NGF
Mek
Raf
Ras
Mek
Raf
Ras
Figure 3.2: Model for NGF-induced Erk phosphorylation. Low and high responsiveness
of the subpopulations to NGF stimulation can be explained by diﬀerent lev-
els of the NGF receptor TrkA. The signaling intermediates Ras, Raf and
Mek are not modeled in this simple pathway model. Thicker arrows, cor-
responding to the inﬂuence of TrkA:NGF on the Erk phosphorylation, and
the higher abundance of TrkA in subpopulation 2, visualize the diﬀerence
between the subpopulations. This ﬁgure has been adopted from (Hasenauer
et al., 2014b).
several ODE-MMs with RREs based on single-cell data of NGF-stimulated primary sen-
sory neurons. This revealed that the cell population consists of two subpopulations that
diﬀer in TrkA levels and therefore show a diﬀerent response to NGF stimulation (see
Figure 3.2).
3.2.2 Experimental Data and Problem Statement
A goal of pain research is to fully understand the mechanism of pain sensitization.
Therefore, it is studied how diﬀerent conditions inﬂuence the pathways mediating pain-
sensitivity. The data analyzed in this section is generated under two diﬀerent experimental
conditions and each experiment has been repeated three times. Cells are stimulated with
NGF and the concentration of pErk is measured after 1, 5, 30, 60 and 120 minutes. The
data is visualized in Figure 3.3, with histograms for every time point (Figure 3.3A), the
average concentrations of pErk (Figure 3.3B) and the mean number of cells per time point
(Figure 3.3C). Two main diﬀerences between the conditions can be observed:
• The mean concentration of pErk is lower for condition 1.
• The number of cells is higher under condition 1.
These observations give rise to the question, where the diﬀerences in average pErk con-
centrations comes from: Is the relative size of the responsive subpopulation higher under
condition 2 or does it have a higher response to NGF stimulation?

3.2 Assessment of ODE-MMs Using Novel Data for NGF-Induced Erk Signaling
21
A
frequency
0
0.05
0.1
0.15
 t = 0 min
data (condition 1)
data (condition 2)
 t = 1 min
 t = 5 min
pErk level [UI]
0.1
1
10
frequency
0
0.05
0.1
0.15
 t = 15 min
pErk level [UI]
0.1
1
10
 t = 30 min
pErk level [UI]
0.1
1
10
 t = 60 min
pErk level [UI]
0.1
1
10
 t = 120 min
B
time [min]
0 5
15
30
60
120
pErk level [UI]
0.5
1
1.5
2
2.5
3
3.5
mean (condition 1)
mean (condition 2)
C
time [min]
0  
1  
5  
15 
30 
60 
120
number of cells
0
100
200
300
400
500
600
condition 1
condition 2
Figure 3.3: Snapshot data of NGF-induced Erk signaling under two diﬀerent experi-
mental conditions. (A) Histograms of experimental data for 7 time points.
(B) Mean and standard deviation of pErk levels for three biological repli-
cates.
Levels of pErk are given in arbitrary units of intensity [UI]. The
average amount of pErk is higher under condition 2. (C) The mean over the
number of cells per time point for every replicate shows that there are more
cells under condition 1.

22
3 ODE Constrained Mixture Modeling for Multivariate Data
3.2.3 Hypothesis Testing
We perform hypothesis testing to answer the question of the source of diﬀerence between
the experimental conditions. Hasenauer et al. (2014b) showed that at least two subpop-
ulations are present that diﬀer in TrkA levels. Therefore, we assume a subpopulation
structure, which arises due to diﬀerences in TrkA levels for the following hypotheses (see
Figure 3.4):
H1 No diﬀerence between the conditions.
H2 Higher relative size of the high responsive subpopulation under condition 2.
H3 Higher response to NGF stimulation of the high responsive cells under condition 2.
H4 Higher response to NGF stimulation of both subpopulations under condition 2.
In accordance to the optimal model selected in the studies of Hasenauer et al. (2014b),
we assume a log-normal distribution parameterized by the median of the subpopulations.
H2 explains the diﬀerence by assuming that less cells of the low responsive subpopulation
exist in condition 2 and therefore the average concentration of pErk is higher. Under H3
and H4, the weighting of the subpopulations stays the same, but the response to NGF
stimulation is changed in condition 2. While H3 only allows a higher response for the
high responsive subpopulations, the responsiveness for all cells is higher under H4. H2
considers diﬀerent weightings for the experimental condition, while H3 and H4 include
diﬀerent responses to stimulation with NGF. The higher response is modeled by multi-
plying parameter k3[TrkA]0 by a parameter κ, which describes the stimulus-dependent
response.
To obtain estimates of the parameters we perform multi-start local optimization with
100 multi-starts. If the optimizer ﬁnds the same (possibly local) optimum less than 5
times, we increase the number of multi-starts and repeat the optimization. We restrict
the kinetic parameters to the interval [10−10, 1010], the variances to [10−1, 10], the weights
to [0, 1] and the additional parameter κ, which is used in H3 and H4 to [10−10, 1010]. Model
selection using AIC and BIC selects H3 and H4 for the pooled data, as shown in Table 3.1.
The ﬁtted data of the optimal model is depicted in Figure 3.5. Repeating the procedure
for the single replicates shows that the signiﬁcance is not as high as for the pooled data,
but nevertheless, H4 is not rejected for any replicate (see last columns of Table 3.1).

3.2 Assessment of ODE-MMs Using Novel Data for NGF-Induced Erk Signaling
23
condition 1
pErk
rk
Er
TrkAA
NGF
pEr
Erk
Trk
Trk
Trk
Trk
Er
Er
Er
Erk
pEr
pEr
pErk
rk
subpop. 1 
subpop. 2 
TrkA
H1
NGF
NGF
NGF
NGF
NGF
NGF
NGF
NGF
TrkA
TrkA NGF
NGF
NGF
NGF
condition 2
pErk
rk
Er
TrkAA
NGF
pEr
Erk
Trk
Trk
Trk
Trk
Er
Er
Er
Erk
pEr
pEr
pErk
rk
subpop. 1 
subpop. 2 
TrkA
NGF
NGF
NGF
NGF
NGF
NGF
NGF
NGF
TrkA
TrkA NGF
NGF
NGF
NGF
condition 1
pErk
rk
Er
TrkAA
NGF
pEr
Erk
Trk
Trk
Trk
Trk
Er
Er
Er
Erk
pEr
pEr
pErk
rk
subpop. 1 
subpop. 2 
TrkA
H2
NGF
NGF
NGF
NGF
NGF
NGF
NGF
NGF
TrkA
TrkA NGF
NGF
NGF
NGF
condition 2
pErk
Er
TrkAA
NGF
pEr
Erk
Trk
Trk
Trk
Trk
Er
Er
Erk
pEr
pEr
pErk
rk
subpop. 1 
subpop. 2 
TrkA
NGF
NGF
NGF
NGF
NGF
NGF
NGF
NGF
TrkA
TrkA NGF
NGF
NGF
NGF
condition 1
pErk
rk
Er
TrkAA
NGF
pEr
Erk
Trk
Trk
Trk
Trk
Er
Er
Er
Erk
pEr
pEr
pErk
rk
subpop. 1 
subpop. 2 
TrkA
H3
NGF
NGF
NGF
NGF
NGF
NGF
NGF
NGF
TrkA
TrkA NGF
NGF
NGF
NGF
condition 2
pErk
rk
Er
TrkAA
NGF
pEr
Erk
Trk
Trk
Trk
Er
Er
Er
Erk
pEr
pEr
pErk
rk
subpop. 1 
subpop. 2 
TrkA
NGF
NGF
NGF
NGF
NGF
NGF
NGF
TrkA
NGF
NGF
NGF
N
TrkA NGF
NN
T kA
TrkA
T kA N
TrkA NGF
condition 1
pErk
rk
Er
TrkAA
NGF
pEr
Erk
Trk
Trk
Trk
Trk
Er
Er
Er
Erk
pEr
pEr
pErk
rk
subpop. 1 
subpop. 2 
TrkA
H4
NGF
NGF
NGF
NGF
NGF
NGF
NGF
NGF
TrkA
TrkA NGF
NGF
NGF
NGF
condition 2
pErk
rk
Er
TrkA
NGF
pEr
Erk
Trk
Trk
Trk
Er
Er
Er
Erk
pEr
pEr
pErk
rk
subpop. 1 
subpop. 2 
TrkA
NGF
NGF
NGF
NGF
NGF
NGF
TrkA
NGF
NGF
NGF
N
TrkA NGF
NN
T kA
TrkA
T kA N
TrkA NGF
A
TrkA
T kAA N
TrkA NGF
Figure 3.4: Hypothesis testing:
H1 No diﬀerence between experimental conditions.
H2 Higher relative size of responsive subpopulation for condition 2.
H3 Higher response to NGF stimulation of the high responsive cells for
condition 2. H4 Higher response to NGF stimulation of both subpopula-
tions for condition 2. Diﬀerences are visualized by thickness of arrows and
abundance of species.

24
3 ODE Constrained Mixture Modeling for Multivariate Data
Table 3.1: Hypothesis testing for two experimental condition based on pooled data of
three biological replicates. Both criteria, AIC (lower table) and BIC (upper
table), select hypotheses H3 and H4. The last colums show the results for the
model selection based on the single replicates R1, R2 and R3.  indicates
that the model is not rejected and  that it has been rejected using AIC or
BIC for ΔBIC or ΔAIC > 10. The maximum likelihood estimate is denoted by
θML.
hypothesis
nθ
log L(θML)(104)
BIC (104)
rank
ΔBIC
decision
R1
R2
R3
MH1
22
−2.2061
4.4337
4
> 10
rejected



MH2
23
−2.2052
4.4329
3
> 10
rejected



MH3
23
−2.2029
4.4281
2
3.808
not rejected



MH4
23
−2.2027
4.4277
1
0
optimal



hypothesis
nθ
log L(θML)(104)
AIC (104)
rank
ΔAIC
decision
R1
R2
R3
MH1
22
−2.2061
4.4167
4
> 10
rejected



MH2
23
−2.2052
4.4151
3
> 10
rejected



MH3
23
−2.2029
4.4103
2
3.808
not rejected



MH4
23
−2.2027
4.4099
1
0
optimal



frequency
0
0.05
0.1
0.15
t = 0 min
data (condition 1)
model (condition 1)
data (condition 2)
model (condition 2)
t = 1 min
t = 5 min
pErk level [UI]
0.1
1
10
frequency
0
0.05
0.1
0.15
t = 15 min
pErk level [UI]
0.1
1
10
t = 30 min
pErk level [UI]
0.1
1
10
t = 60 min
pErk level [UI]
0.1
1
10
t = 120 min
Figure 3.5: Fit for the optimal model MH4 based on pooled data of three biological
replicates. The high responsive subpopulation is shifted to the right, due to
the higher response to NGF stimulation.
In summary, we assessed how ODE-MMs with RREs can be applied to analyze data
obtained under diﬀerent experimental conditions simultaneously at the example of NGF-

3.3 Modeling Variability within a Subpopulation
25
induced Erk signaling. We formulated several hypotheses about the diﬀerence between
conditions that yields a diﬀerence in mean levels of pErk. To test the hypotheses we
performed parameter estimation and model selection using a simple pathway model of
NGF-induced phosphorylation of Erk. Based on pooled data consisting of three replicates,
both BIC and AIC select models that consider a changed intracellular signaling under the
second condition. These models incorporate a higher response to NGF stimulation under
condition 2. A model that assumes a diﬀerent weighting under the conditions, which
was motivated by the fact that the number of cells diﬀers signiﬁcantly under the two
conditions, has been rejected based on the pooled data. Repeating model selection for
the single replicates, the model, which assumes a higher phosphorylation of Erk in both
subpopulations under condition 2, can not be rejected for any replicate neither by AIC nor
by BIC. In the future, we will further analyze dose-response data to validate the results
of the model selection.
3.3 Modeling Variability within a Subpopulation
Considering only the averaged behavior of a cell population might not represent the be-
havior of cells at the tail of the cell distribution (Altschuler & Wu, 2010). This gets even
worse for cell populations that consist of two or more subpopulations and therefore show
a bimodal or multimodal distribution of the cells. In addition, it has been shown that
variability of measured properties carries information about the underlying biological sys-
tem (Munsky et al., 2009). These facts motivate the usage of a mechanistic description
of the variability of a system.
The previously introduced method of ODE-MMs with RREs accounts for diﬀerences be-
tween subpopulations (Hasenauer et al., 2014b). Nevertheless, modeling subpopulation
dynamics by RREs gives no mechanistic description of the cell-to-cell variability within
a subpopulation. A possibility to exploit higher order moments of the subpopulations
is to describe the dynamics of a subpopulation by moment equations (MEs) (Engblom,
2006). In this section we use ODE-MMs with MEs to solve the Problems 1-3 that have
been addressed in Section 3.1.2. First, we propose in Section 3.3.1 a likelihood function
for ODE-MMs with MEs to study univariate measurements y ∈R. Additionally, we
describe how the MEs can be linked to a normal and log-normal mixture distribution.

26
3 ODE Constrained Mixture Modeling for Multivariate Data
In Section 3.3.2, we validate the method for diﬀerent scenarios of a conversion process.
Besides that, we compare the results of the method with those obtained using RREs for
the description of the mechanisms of the system.
3.3.1 Likelihood Function
The likelihood function of mixture modeling that is constrained by MEs is given by
L(θ) =

e,k,j
ns

s=1
we
s p

¯ye,k
j |ϕe
s (tk)

(3.2)
with
˙xe
s = f(xe
s, ψe
s, ue) ,
xe
s(0) = x0(ψe
s, ue) ,
ϕe
s = h(xe
s, ψe
s, ue) .
In the following we neglect the indices k for the time point, and j for the single-cells. The
likelihood describes the probability of observing the measurement ¯ye ∈R as weighted sum
of mixture probabilities p(¯y|ϕe
s) with parameters ϕe
s for subpopulation s in experiment
e. Each of the ns subpopulations has a weight denoted by we
s corresponding to its size.
The parameters ψe
s = 
ξ0, ξe
0, ξ0
s, ξe
s

are e.g. kinetic parameters or initial conditions that
are partitioned into experiment speciﬁc and identical parameters between conditions as
in (3.1). The cells are stimulated with an experiment speciﬁc external stimulus denoted
by ue. The time evolution of the moments xe
s of the system are described by a function f.
The moments can be linked to the mixture parameters with function h. We also neglect
the indices e and s in the following. Since a mechanistic description of the variability
is provided by the MEs, measurement noise e.g. normal additive measurement noise or
log-normal multiplicative measurement noise
¯y = y + ϵ , ϵ ∼N(0, σ2
ϵ ) ,
(3.3)
¯y = yϵ ,
ϵ ∼log N(0, σ2
ϵ ) ,
(3.4)
can be considererd separately.
In this thesis, we consider second order moments.
The state vector of the moments
comprises mean and variances of the L species:

3.3 Modeling Variability within a Subpopulation
27
x =
⎛
⎝m
C
⎞
⎠,
m = (m1, . . . , mL) ,
(C)ij = Cij , i, j = 1, . . . , L .
If we assume to have at most quadratic propensities ar(m) for the M reactions and if we
neglect higher order moments, the MEs are (Engblom, 2006)
dmi
dt =
M

r=1
νir

ar(m) + 1
2

l1,l2
∂2ar(m)
∂xl1∂xl2
Cl1l2

,
dCij
dt
=
M

r=1

νir

l
∂ar(m)
∂xl
Cjl + νjr

l
∂ar(m)
∂xl
Cil +
νirνjr

ar(m) + 1
2

l1,l2
∂2ar(m)
∂xl1∂xl2
Cl1l2

,
with νij being the entries of the stochiometric matrix. These moments can be linked to
the measurand without measurement noise y to obtain its mean my and variance Cy.
Example.
If the output is given by y = bxl, i.e., y is proportional to the amount of xl,
we obtain the mean ml and the variance Cll from the corresponding entries of the state
vector of the moments. Thus, we can calculate the mean of the output my = bml and its
variance Cy = b2Cll.
By describing subpopulation dynamics with MEs, extrinsic noise of the cells in a sub-
population that arises due to diﬀerences e.g. in kinetic parameters, can be incorporated.
The variable parameters can be deﬁned as states and corresponding moment equations
can be derived and simulated. We use normal and log-normal mixture distributions de-
ﬁned by its mixture parameters ϕe
s = (μe
s, σe
s). Using second order moments, we can link
both parameters to the ME, which we will explain in the following. However, this yields
a reduced number of unknown parameters θ = {{we
s, ψe
s}s , σe
ϵ}e, since no additional
parameters for the variances needs to be introduced and estimated as in (3.1).

28
3 ODE Constrained Mixture Modeling for Multivariate Data
Mixture of Normal Distributions
Both moments of the measurand, my and Cy and their corresponding sensitivities dmy
dθ , dCy
dθ
can directly be linked to mixture parameters of a normal distribution by
μ = my,
σ2 = Cy + σ2
ϵ ,
dμ
dθ = dmy
dθ
and
dσ
dθ = 1
2σ

dCy
dθ + dσ2
ϵ
dθ

.
Here, σ2
ϵ is the variance of additive normally distributed measurement noise (3.3).
Mixture of Log-Normal Distributions
Another mixture distribution used in this thesis is the log-normal distribution. If the
mean of a log-normal distribution is linked to the mean of the moment equations, we
need to following calculations:
μ = log(my) −1
2σ2 ,
σ2 = log

1 + Cy
m2y

+ σ2
ϵ ,
dμ
dθ = 1
my
dmy
dθ −1
2
d log

Cy
m2y + 1

dθ
−1
2
dσ2
ϵ
dθ ,
dσ
dθ = 1
2σ

d log( Cy
m2y + 1)
dθ
+ dσ2
ϵ
dθ

,
with
d log

Cy
m2y + 1

dθ
=
1
Cy
m2y + 1
m2
y
dCy
dθ −2Cymy
dmy
dθ
m4y
.
Here, σ2
ϵ is the mixture parameter of multiplicative log-normally distributed measurement
noise (3.4). The median of the distribution can be described in a similar way by the means
of the MEs.
3.3.2 Simulation Example: Conversion Reaction
To assess the method of ODE-MMs with MEs we study a conversion reaction between
some biochemical species A and B, a frequently occurring process in biology. A schematic
of the process is shown in Figure 3.6. The reaction system describing this process is

3.3 Modeling Variability within a Subpopulation
29
R1 :
A →B,
rate = k1u
A
,
R2 :
A →B,
rate = k2

A
,
R3 :
B →A,
rate = k3

B
.
For the conversion of A to B we denote a time dependent stimulus by u and distinguish
two diﬀerent reactions.
First, a stimulus dependent reaction R1 occurring with rate
k1u[A], where [A] denotes the concentration of species A, and second, a basal, stimulus
independent reaction R2. In reaction R3 species B is converted to A with kinetic parameter
k3. Due to conservation of mass, the sum of concentrations [A] + [B] remains constant.
Artiﬁcial Data
We generate artiﬁcial data for an external stimulus u(t) = 0 for t ≤0 and u(t) = 1 for
t > 0, i.e., the system is in steady state without stimulus at initial time. We generate
trajectories of 1000 cells in a volume Ω = 1000, which have a total number of molecules
N0 = 1000 using the SSA. A certain fraction of the cells shows higher response to stimulus
u. This diﬀerence is modeled with the subpopulation speciﬁc parameter k1. For every
time series we measure B at t = 0, 0.1, 0.2, 0.3, 0.5 and 1 minutes. As the use of MEs also
provides information about variability in parameters we consider three scenarios:
Scenario 1 Kinetic parameters are ﬁxed across individual cells of a subpopulation.
Scenario 2 Kinetic parameters vary little between individual cells of a subpopulation.
Scenario 3 Kinetic parameters vary strongly between individual cells of a subpopula-
tion.
The scenarios are depicted in Figure 3.7. For every scenario we simulate two subpop-
ulations that respond diﬀerently to stimulus u, i.e., one subpopulation has a stimulus-
B
A
stimulus u
measurand
Figure 3.6: Schematic representation of a conversion process between species A and B,
for which B can be measured. This ﬁgure has been adopted from (Hasenauer
et al., 2014b).

30
3 ODE Constrained Mixture Modeling for Multivariate Data
dependent conversion with parameter k1,s1 = 0.75, while the other shows a lower response
with parameter k1,s2 = 0.1. For Scenarios 2 and 3 we assume that the parameters are
log-normally distributed with mean μki and variance σ2
ki. The variance for Scenario 2
(σ2
ki = 0.0016) is smaller than for Scenario 3 (σ2
ki = 0.005). We want to emphasize that
by μki and σ2
ki, we denote the means and variances of the parameters instead of the
corresponding parameters of the log-normal distribution.
A
frequency
0
0.1
0.2  t = 0 min
data
t = 0.1 min
frequency
0
0.1
0.2 t = 0.2 min
t = 0.3 min
conc. of B [nM]
0.1
1
frequency
0
0.1
0.2 t = 0.5 min
conc. of B [nM]
0.1
1
t = 1 min
B
frequency
0
0.06
0.12  t = 0 min
data
t = 0.1 min
frequency
0
0.06
0.12
t = 0.2 min
t = 0.3 min
conc. of B [nM]
0.1
1
frequency
0
0.06
0.12
t = 0.5 min
conc. of B [nM]
0.1
1
t = 1 min
C
frequency
0
0.04
0.08  t = 0 min
data
t = 0.1 min
frequency
0
0.04
0.08
t = 0.2 min
t = 0.3 min
conc. of B [nM]
0.1
1
frequency
0
0.04
0.08
t = 0.5 min
conc. of B [nM]
0.1
1
t = 1 min
Figure 3.7: Artiﬁcial data for diﬀerent scenarios of a conversion process of A and B with
two subpopulations that diﬀer in the response to a stimulus: Scenarios with
(A) no parameter variability, (B) low parameter variability and (C) high
parameter variability between individual cells.

3.3 Modeling Variability within a Subpopulation
31
Moment Equations for The Conversion Process without Variability in Parameters
The MEs for the conversion process are generated and simulated using the toolbox CER-
ENA developed by Kazeroonian et al. (2016). Given the system size Ω = 1000, we obtain
the following equations for the mean and variance of the concentration of B
dmB
dt
= −k3mB −(k1 + k2)(mB −1) ,
dCB,B
dt
= k3mB −(k1 + k2)(mB −1)
Ω
−2CB,B(k1 + k2 + k3) .
Based on these equations and the initial steady state assumption, we derive the initial
conditions for the MEs
mB(0) =
k2
k2 + k3
and
CB,B(0) =
k2k3
Ω(k2 + k3)2 .
Moment Equations for The Conversion Process with Variability in Parameters
The MEs for the conversion process with accounting for additional variability in the
parameters are presented in the following. Given the means μki and standard deviations
σki of the parameters for i = 1, 2, 3, we obtain
dmB
dt
= (mB −1)(mk3 −mk1) + mBmk2 −CB,k1 + CB,k2 + CB,k3 ,
dmki
dt
= 0 for i = 1, 2, 3 ,
dCB,B
dt
= (mB −1)(mk3 −mk1) + mBmk2 −CB,k1 + CB,k2 + CB,k3
Ω
+
2(CB,k3 −CB,k1)(mB −1) + 2CB,k2mB + 2CB,B(mk3 + mk2 −mk1) ,
dCB,k1
dt
= CB,k1(mk2 + mk3 −mk1) + Ck1,k2mB −Ck1,k1(mB −1) + Ck1,k3mB −1 ,
dCB,k2
dt
= CB,k2(mk2 + mk3 −mk1) + Ck2,k2mB −Ck1,k2(mB −1) + Ck2,k3mB −1 ,
dCB,k3
dt
= CB,k3(mk2 + mk3 −mk1) + Ck2,k3mB −Ck1,k3(mB −1) + Ck3,k3mB −1 ,
dCki,kj
dt
= 0 for i, j = 1, 2, 3.

32
3 ODE Constrained Mixture Modeling for Multivariate Data
By exploiting the steady state assumption, we obtain the initial conditions
mB(0) = Ω
μ2
k2 + μk2μk3 −σ2
k2
μ2
k2 + μk2μk3 + μ2
k3 −σ2
k2 −σ2
k3
,
mki(0) = μki ,
CB,k1(0) = 0 ,
CB,k2(0) =
Ωσ2
k2(μ2
k3 + μk3μk2 −σ2
k3)
(μk2 + μk3)(μ2
k2 + 2μk2μk3 + μ2
k3 −σ2
k2 −σ2
k3) ,
CB,k3(0) =
−Ωσ2
k3(μ2
k2 + μk3μk2 −σ2
k2)
(μk2 + μk3)(μ2
k2 + 2μk2μk3 + μ2
k3 −σ2
k2 −σ2
k3) ,
CB,B(0) = (Ω −1)CB,k2(0) + CB,k3(0) + Ωμk2
2(μk2 + μk3)
+
mB(0)(μk3 −μk2) −2CB,k2(0) −2CB,k3(0)
2(μk2 + μk3)
,
Cki,ki(0) = σ2
ki .
Hypothesis Testing for Scenario 1
To assess the extension and compare ODE-MM with RREs and with MEs, we perform
hypothesis testing for both methods based on the generated data of Scenario 1 (see Fig-
ure 3.7A):
H1 No subpopulations.
H2 Two subpopulations diﬀering in k1.
H3 Two subpopulations diﬀering in k2.
H4 Two subpopulations diﬀering in k3.
The kinetic parameters are restricted to the interval [10−6, 104] and the weighting of
the subpopulations needed for H2-4 to the interval [0, 1]. As the variances need to be
estimated when using RREs, we restrict them to [10−2.5, 102.5]. Moreover, we use three
diﬀerent distributions assumptions for every hypothesis, a normal distribution, for which
the mean is described by the ODEs, and a log-normal distribution, for which either the
mean or the median is parameterized by the ODE model. This yields 12 models that
are tested with multi-start local optimization and model selection using AIC and BIC.

3.3 Modeling Variability within a Subpopulation
33
We perform parameter estimation with a toolbox that is internally used by the Data-
driven Computational Modeling group of the Institute of Computational Biology at the
Helmholtz Zentrum M¨unchen. The results are shown in Table 3.2 for ODE-MMs with
RREs and in Table 3.3 for ODE-MMS with MEs. Both select the same optimal model,
which detects the true diﬀerences between the subpopulations. The ﬁt of the optimal
model MH2,1 is shown in Figure 3.8A. Furthermore, we computed the proﬁle likelihoods of
the kinetic parameters and weights of the optimal models, which are shown in Figure 3.8B.
All parameters are identiﬁable and the proﬁles are almost indistinguishable. The number
of parameters can be reduced by at least a factor of two using MEs with nθ = 5 for MEs
and nθ = 17 using RREs. Moreover, model selection between ODE-MM with RRE and
ME yields BICRRE
min −BICME
min > 10, i.e., the model using MEs is selected in favor of the
RRE model.
Measurements at Less Time Points in Scenario 1
Additionally, we compare the performance of ODE-MMs with ME and RRE for the case
that less measurements are available. Thus, we repeat the parameter estimation for the
optimal model based on only three time points t = 0, 0.1 and 0.5 minutes. As the MEs also
can extract information from the variance of the subpopulation, the conﬁdence intervals
are narrower for the case of using MEs instead of RREs (see Figure 3.8C). We expect
that for some other systems the uncertainties of the parameters for ODE-MMs with MEs
is much lower than using RREs. Munsky et al. (2009) already showed for some processes
that measurements at less time points are needed to obtain identiﬁable parameters if
second order moments are measured besides the means.

34
3 ODE Constrained Mixture Modeling for Multivariate Data
A
frequency
0
0.1
0.2
 t = 0 min
data
model
 t = 0.1 min
frequency
0
0.1
0.2
 t = 0.2 min
 t = 0.3 min
conc. of B [nM]
0.1
1
frequency
0
0.1
0.2
 t = 0.5 min
conc. of B [nM]
0.1
1
 t = 1 min
B
log10(k2)
-0.2
-0.3
-0.28
likelihood ratio
0
0.5
1
log10(k3)
0.16
0.18
0.2
log10(k1,s2)
-0.14
-0.12
-0.1
ME
RRE
true param.
log10(k1,s1)
-1.05
-1
-0.95
likelihood ratio
0
0.5
1
w
0.45
0.5
0.55
likelihood ratio
0.5
1
C
log10(k2)
-0.6
-0.4
-0.2
-0.6
likelihood ratio
0
0.5
1
log10(k3)
0
0.1
0.2
0.3
log10(k1,s1)
-1.1
-1
-0.9
likelihood ratio
0
0.5
1
log10(k1,s2)
-0.2
-0.15
-0.1
w
0.45
0.5
0.55
likelihood ratio
0
0.5
1
ME
RRE
true parameter
values
Figure 3.8: Results for Scenario 1. (A) Fitted data of the optimal model MH2,1 using
ODE-MMs with MEs. (B, C) Comparison of proﬁle likelihoods for ODE-
MMs with RREs (red line) and MEs (dotted dark red line) for diﬀerent
numbers of measurements. (B) For the case of 7 time points, almost no
diﬀerence can be detected between the proﬁles. (C) If measurements of less
time points (t = 0, 0.1, 0.5 min) are available, ODE-MMs with ME yields
higher conﬁdence in the estimates.

3.3 Modeling Variability within a Subpopulation
35
Table 3.2: Results of parameter estimation and model selection for Scenario 1 using
ODE-MMs with RREs.
ns
distribution
ODE const.
diﬀ.
nθ
log L(θML)(104)
BIC (104)
rank
ΔBIC
decision
MH1,1
1
normal
mean
-
9
1.0821
−2.1563
12
> 10
rejected
MH1,2
1
log-normal
mean
-
9
1.0837
−2.1597
10
> 10
rejected
MH1,3
1
log-normal
median
-
9
1.0837
−2.1596
11
> 10
rejected
MH2,1
2
normal
mean
k1
17
1.3562
−2.6975
1
0
optimal
MH2,2
2
log-normal
mean
k1
17
1.3556
−2.6963
2
> 10
rejected
MH2,3
2
log-normal
median
k1
17
1.3556
−2.6963
3
> 10
rejected
MH3,1
2
normal
mean
k2
17
1.1233
−2.2318
8
> 10
rejected
MH3,2
2
log-normal
mean
k2
17
1.1296
−2.2445
7
> 10
rejected
MH3,3
2
log-normal
median
k2
17
1.1208
−2.2267
9
> 10
rejected
MH4,1
2
normal
mean
k3
17
1.1968
−2.3787
4
> 10
rejected
MH4,2
2
log-normal
mean
k3
17
1.1855
−2.3563
6
> 10
rejected
MH4,3
2
log-normal
median
k3
17
1.1900
−2.3652
5
> 10
rejected
Table 3.3: Results of parameter estimation and model selection for Scenario 1 using
ODE-MMs with MEs.
ns
distribution
ODE const.
diﬀ.
nθ
log L(θML)(104)
BIC (104)
rank
ΔBIC
decision
MH1,1
1
normal
mean
-
3
−1.6347
3.2721
12
> 10
rejected
MH1,2
1
log-normal
mean
-
3
−1.5787
3.1600
11
> 10
rejected
MH1,3
1
log-normal
median
-
3
−1.5736
3.1498
10
> 10
rejected
MH2,1
2
normal
mean
k1
5
1.3556
−2.7069
1
0
optimal
MH2,2
2
log-normal
mean
k1
5
1.3550
−2.7057
3
> 10
rejected
MH2,3
2
log-normal
median
k1
5
1.3551
−2.7058
2
> 10
rejected
MH3,1
2
normal
mean
k2
5
0.7804
−1.5564
9
> 10
rejected
MH3,2
2
log-normal
mean
k2
5
0.7920
−1.5796
8
> 10
rejected
MH3,3
2
log-normal
median
k2
5
0.7928
−1.5813
7
> 10
rejected
MH4,1
2
normal
mean
k3
5
1.0548
−2.1053
4
> 10
rejected
MH4,2
2
log-normal
mean
k3
5
1.0531
−2.1019
6
> 10
rejected
MH4,3
2
log-normal
median
k3
5
1.0541
−2.1038
5
> 10
rejected

36
3 ODE Constrained Mixture Modeling for Multivariate Data
Hypothesis Testing for Scenario 2 and 3
For Scenario 2 and 3 we assess the ability of ODE-MMs with MEs to detect extrinsic
noise in a subpopulation. We perform hypothesis testing based on data that has been
generated with variable parameters (see Figures 3.7B and C) for the following hypotheses
H1 Two subpopulations that diﬀer in k1 and ﬁxed parameters between individual cells
of a subpopulation.
H2 Two subpopulations that diﬀer in k1 and variability of parameters between individ-
ual cells of a subpopulation.
In this case the ground truth is H2, which assumes an additional cell-to-cell variability.
We model the data using ODE-MMs with MEs and a normal mixture distribution that
is constrained by its mean. For parameter estimation for H1 we use the same restrictions
in parameters as before. For the models of H2 the means of the kinetic parameters are
restricted to the interval [10−6, 104] and the coeﬃcient of variation of the parameters
cvki = σki/μki to [10−6, 100].
The results are shown in Table 3.4 for low parameter variabilty (Scenario 2) and in
Table 3.5 for high parameter variability (Scenario 3). Our method is able to detect the
true model with high signiﬁcance for both cases. Figures 3.9A and B show the ﬁts of
model MH1, which allows no additional variability in parameters, and MH2, which ac-
counts for cell-to-cell variability in kinetic parameters. The ﬁts of MH1 MH2 shows the
importance of accounting for extrinsic noise. The proﬁles corresponding to the optimal
model are shown in Figures 3.9C and D. The subpopulation weight and the means of
the kinetic parameters are identiﬁable. For the case of low parameter variability also the
coeﬃcient of variation of k3, cvk3, can be estimated with high conﬁdence. As the MEs
give no exact representation of the system, it can happen that the true parameters lie
outside the conﬁdence intervals. This is the case for cvk2 and cvk1,s1 in Scenario 2 and cvk2,
cvk3 and cvk1,s2 for Scenario 3. As expected, the results are better for lower variability in
parameters.
In summary, we combined ODE constrained mixture modeling with MEs for the descrip-
tion of the mechanisms of a biological process. As variances are linked to the MEs the

3.3 Modeling Variability within a Subpopulation
37
Table 3.4: Model selection for data of Scenario 2 that includes low parameter variabil-
ity. Both criteria, AIC and BIC, select the true model MH2, which allows
parameters to vary between individual cells.
nθ
log L(θML)(104)
AIC (104)
rank
ΔAIC
decision
MH1
5
0.6504
−1.2998
2
> 10
rejected
MH2
9
1.0280
−2.0542
1
0
optimal
nθ
log L(θML)(104)
BIC (104)
rank
ΔBIC
decision
MH1
5
0.6504
−1.2965
2
> 10
rejected
MH2
9
1.0280
−2.0481
1
0
optimal
dimension of the parameter space is reduced. No additional parameters need to be intro-
duced for every time point, yielding that the availability of measurements at more time
points or more experiments, does not increase the number of parameters. Furthermore,
the proposed method provides additional insight into variability within a subpopulation.
Intrinsic noise, arising due to the inherent stochasticity of the underlying biological pro-
cesses, and extrinsic noise, which emerges, for example, from diﬀerences in parameters
of the cells in a subpopulation, can now be taken into account. Therefore, not only dif-
ferences between supopulations, but also heterogeneity of the individual subpopulations
can be studied. In addition, measurement noise can now be treated separately from the
variability of the subpopulations. Moreover, the evolution of the variability of a subpop-
ulation can be predicted, as variances at time points for which no measurements exist
can be simulated by the MEs. We validated the method on the example of a conversion
process between two species for diﬀerent scenarios. We showed that the method is able
to detect the origin of diﬀerence between subpopulations and the existence of additional
parameter variability. The conﬁdence intervals using MEs are narrower for the case of
measurements at less time points. We expect even more conﬁdence in the estimates by
using ODE-MMs with MEs for other processes, in which more information is carried in
the variances.

38
3 ODE Constrained Mixture Modeling for Multivariate Data
Table 3.5: Model selection for data of Scenario 3 that includes high parameter variabil-
ity. Both criteria, AIC and BIC, select the true model MH2, which allows
parameters to vary between individual cells
.
nθ
log L(θML)(104)
AIC (104)
rank
ΔAIC
decision
MH1
5
−0.4511
0.9032
2
> 10
rejected
MH2
9
0.8392
−1.6766
1
0
optimal
nθ
log L(θML)(104)
BIC (104)
rank
ΔBIC
decision
MH1
5
−0.4511
0.9065
2
> 10
rejected
MH2
9
0.8392
−1.6706
1
0
optimal

3.3 Modeling Variability within a Subpopulation
39
A
frequency
0
0.1
0.2  t = 0 min
data
MH1
MH2
 t = 0.1 min
frequency
0
0.1
0.2  t = 0.2 min
 t = 0.3 min
conc. of B [nM]
0.1
1
frequency
0
0.1
0.2  t = 0.5 min
conc. of B [nM]
0.1
1
 t = 1 min
B
frequency
0
0.1
0.2  t = 0 min
data
MH1
MH2
 t = 0.1 min
frequency
0
0.1
0.2  t = 0.2 min
 t = 0.3 min
conc. of B [nM]
0.1
1
frequency
0
0.1
0.2  t = 0.5 min
conc. of B [nM]
0.1
1
 t = 1 min
C
log10(μk2)
-0.4
-0.3
-0.2
likelihood
 ratio    
0
0.5
1
log10(cvk2)
-4
-2
0
log10(μk3)
0.1
0.15
0.2
log10(cvk3)
-1.6
-1.4
-1.2  
likelihood
 ratio    
0
0.5
1
log10(μk1,s1)
-0.2
-0.15
-0.1
log10(cvk1,s1)
-4
-2
0
log10(μk1,s2)
-1.2
-1
-0.8
likelihood
ratio     
0
0.5
1
log10(cvk1,s2)
-4
-2
0
w
0.45
0.5
0.55
D
log10(μk2)
-0.4
-0.3
-0.2
likelihood
ratio     
0
0.5
1
log10(cvk2)
-4
-2
0
log10(μk3)
0.1
0.2
0.3
log10(cvk3)
-1.6
-1
likelihood
ratio     
0
0.5
1
log10(μk1,s1)
-1.2
-1
-0.8
log10(cvk1,s1)
-4
-2
0
log10(μk1,s2)
-0.2
-0.1
0
likelihood 
ratio      
0
0.5
1
log10(cvk1,s2)
-4
-2
0
w
0.45
0.5
0.55
Figure 3.9: Results for Scenario 2 and 3. (A) Fitted data for Scenario 2 for both models
MH1, allowing no additional parameter variability and MH2, which considers
cell-to-cell variability in the kinetic parameters. (B) Fitted data for Scenario
3 for MH1 and MH2. The true model MH2 has been selected correctly by
AIC and BIC for both scenarios.
(C, D) Proﬁles corresponding to the
optimal model for Scenario 2 (C) and Scenario 3 (D). The true values of the
parameters, which have been used to generate the data, are indicated by a
green line.

40
3 ODE Constrained Mixture Modeling for Multivariate Data
3.4 Simultaneous Analysis of Multivariate Measurements
In the previous section we presented ODE-MMs with MEs, which are able to capture vari-
ability within a subpopulation. However, correlations between the measurements can still
not be detected and taken into account (Problem 4). By just considering the univariate
measurements, corresponding to the marginal distributions in Figure 3.10, correlations
between the measurands cannot be detected. Figure 3.10A shows positive correlation
between measurand A and B, while Figure 3.10B shows negative correlation between the
measurements. In the following, we propose ODE-MMs, which can simultaneously analyze
multivariate measurements and therefore account for correlated behavior. Additionally,
we demonstrate and tackle the numerically instability of the likelihood calculation arising
due to the use of mixture probabilities (Problem 5).
3.4.1 Likelihood Function
The likelihood function for ODE-MMs based on multivariate measurement data is given
in a general form by
L (θ) =

e,k,j
ns

s=1
we
s p

¯ye,k
j |ϕe
s (tk)

(3.5)
with
˙xe
s = f (xe
s, ψe
s, ue) ,
xe
s(0) = x0 (ψe
s, ue) ,
ϕe
s = h (xe
s, ψe
s, ue) .
A
B [a.u.]
A [a.u.]
B
B [a.u.]
A [a.u.]
Figure 3.10: Scatterplot and marginals of measurands A and B with (A) positive correla-
tion and (B) negative correlation. The measurements are given in arbitrary
units.

3.4 Simultaneous Analysis of Multivariate Measurements
41
For a simpler notation, we further neglect the indices e, k and j, corresponding to the
experiment, time point and single-cell, respectively. While (3.1) and (3.2) consider a uni-
variate measurement ¯y ∈R, (3.5) gives the probability to observe a multivariate vector
¯y ∈Rd. The ns subpopulations with parameters ψs and weights ws are simulated with an
external stimulus u. The multivariate mixture distribution is deﬁned by the parameters
ϕs. Function h links the state vector xs of the moments of the species of the system, for
which the time evolution is described by f, to the mixture parameters.
For simplicity, we further neglect the subpopulation index s. We use second order mo-
ments to describe the mechanisms of the system as in Section 3.3. The measurement is
possibly aﬀected by some measurement noise e.g. additive normally distributed measure-
ment noise
¯y = y + ϵ,
ϵ ∼N (0, Γ) ,
(3.6)
or multiplicative log-normally distributed measurement noise
¯y = yϵ,
ϵ ∼log N (0, Γ) .
(3.7)
The entries of Γ are incorporated in the parameter vector. The moments of the measurand
without measurement noise are denoted by my = (my,1, . . . , my,d) and Cy and can be
calculated from x.
3.4.2 Multivariate Mixture of Normal and Log-Normal Distributions
In this thesis we focus on the mixture of d-dimensional multivariate normal distributions
N(y|μ, Σ) =
1
(2π)
d
2 det (Σ)
1
2
e−1
2(y−μ)T Σ−1(y−μ),
and multivariate log-normal distributions
logN (y|μ, Σ) =
1
(2π)
d
2 det (Σ)
1
2
d
i=1 yi
e−1
2(log(y)−μ)T Σ−1(log(y)−μ).
with mixture parameters ϕ = (μ, Σ).

42
3 ODE Constrained Mixture Modeling for Multivariate Data
Gradient of Multivariate Normal and Log-Normal Distribution
The gradient of a multivariate normal distribution N(y|μ(θ), Σ(θ)) with respect to θ is
known to be
∂
∂θN (y|μ, Σ) = −1
2N (y|μ, Σ) ·

Tr

Σ−1∂Σ
∂θ

+ (μ −y)T Σ−1

∂μ
∂θ
T
+

∂μ
∂θ
T
Σ−1 (μ −y) + (μ −y)T ∂Σ−1
∂θ
(μ −y)

.
For simplicity we write μ = μ(θ) and Σ = Σ(θ). The derivative for the multivariate
log-normal distribution can be obtained using the relation
logN (y|μ, Σ) = N (log(y)|μ, Σ)
 d

i=1
yi
−1
.
To simplify and speed up the calculation of the gradient we use the identity
Tr 
ATB
=

i,j
(A ◦B) ,
with (A ◦B)ij = (AijBij) being the Hadamard product.
Mixture of Multivariate Normal Distributions
We now present the calculations needed to constrain the mean and covariance of a mul-
tivariate normal distribution by MEs.
Given the means my, covariances Cy and the
corresponding sensitivities ∂my
∂θ
and ∂Cy
∂θ , we can directly deﬁne μ = my, Σ = Cy and
the derivatives
∂μ
∂θ = ∂my
∂θ , and

∂Σ
∂θ

ij
=

∂Cy
∂θ

ij
= ∂Cy,ij
∂θ
.
The multivariate normal distributions can e.g. be used together with additive normal
measurement noise Σ = Cy + Γ as in (3.6).
An example for assuming independent
measurement noise is given by

3.4 Simultaneous Analysis of Multivariate Measurements
43
Γ =
⎛
⎜
⎜
⎝
σ2
ϵ,1
0
0
0
...
0
0
0
σ2
ϵ,d
⎞
⎟
⎟
⎠.
Other considerations, such as correlated behavior of the measurement noise for the dif-
ferent measurements, can also be included.
Mixture of Multivariate Log-Normal Distributions
For the log-normal distribution we use two diﬀerent parametrizations. If the mean ob-
tained by the MEs describes the mean of the log-normal distribution, we use
my,i = eμi+ 1
2Σii ,
Cy,ij = eμi+μj+ 1
2(Σii+Σjj)(eΣij −1) ,
for i, j = 1, . . . , d. This yields the mixture parameters
μi = log(my,i) −1
2Σii ,
Σij = log(
Cy,ij
my,imy,j
+ 1) ,
and their derivatives
∂μi
∂θ =
1
my,i
∂my,i
∂θ
−1
2
∂Σii
∂θ ,
∂Σij
∂θ
=
1
Cy,ij
my,imy,j + 1
∂

Cy,ij
my,imy,j

∂θ
=
1
Cy,ij
my,imy,j + 1
my,imy,j
∂Cy,ij
∂θ
−Cy,ij(my,i
∂my,j
∂θ
+ my,j
∂my,i
∂θ )
(my,imy,j)2
.
Another parametrization is given by assuming that the mean obtained by the MEs de-
scribes the median of the log-normal distribution. This distribution assumption is com-
bined with log-normally distributed measurement noise (3.7).

44
3 ODE Constrained Mixture Modeling for Multivariate Data
3.4.3 Robust Computation of Mixture Probabilities
When using mixture models, the calculation of the likelihood is generally unstable (Prob-
lem 5). We explain and address this problem in the following. We are interested in the
likelihood function of a mixture model with ns mixture components given by
p(y|θ) =
ns

s=1
wsp(y|ϕs), with θ = {(ws, ϕs)}ns
s=1 .
For simplicity we denote p(y|θ) by p and the probabilities p(y|ϕs) for the individual
components by ps. The goal is to calculate the log-likelihood
log(p) = log
 ns

s=1
wsps

in a numerically stable way, which can be achieved by the following reformulation. Let
qs = log(ps) for s = 1 . . . , ns, then
smax = arg max
s
qs ,
log(p) = log
 ns

s=1
wseqs

= log
(ns
s=1 wseqs)wsmaxeqsmax
wsmaxeqsmax

= log
ns
s=1 wseqs
wsmaxeqsmax

+ log (wsmaxeqsmax)
= log
⎛
⎝1 +

s̸=smax
ws
wsmax

eqs−qsmax
⎞
⎠+ log(wsmax) + qsmax .
As 0 ≤eqs−qsmax ≤1 the reformulation gives better numerical properties than the direct
computation of log(p), which gets unstable for p close to 0. For the calculation of the
gradient, we have
d log(p)
dθ
= 1
p
dp
dθ =
ns

s=1
ps
ns
j=1 wjpj
Hs ,

3.4 Simultaneous Analysis of Multivariate Measurements
45
with Hs such that
psHs = dwsps
dθ
= ps
dws
dθ + ws
dps
dθ .
(3.8)
This is again unstable for p close to 0 and needs to be reformulated. Using
ps
ns
j=1 wjpj
=
ps
psmax
ns
j=1 wj
pj
psmax
=
eqs−qsmax
ns
j=1 wjeqj−qsmax ,
we obtain
d log(p)
dθ
=
1
ns
j=1 wjeqj−qsmax
ns

s=1
eqs−qsmaxHs .
(3.9)
Example (Normal Distribution).
For a normal distribution N(μs, σ2
s) with parameters
ϕs = (μs, σs) and ws that depend on θ, we calculate
qs(y|ϕs) = −1
2

y −μs
σs
2
−log(
√
2π) −log(σs) .
The term Hs deﬁned in (3.8) is
Hs = dws
dθ + ws
σs

y −μs
σs
dμs
dθ +

y −μs
σs
2
−1

dσs
dθ

.
and can be used for the stable calculation of the gradient according to (3.9).
Comparison of Calculations of The Log-Likelihood Function
To evaluate the recalculation, we performed the parameter estimation in the next section
for the multivariate case with and without the reformulation above. Both procedures ﬁnd
the same optimum. While the optimizer has a convergence rate of 0.71 using the robust
calculation, the convergence rate without the reformulation is 0.01. The corresponding
log-likelihood values are shown in Figure 3.11.

46
3 ODE Constrained Mixture Modeling for Multivariate Data
A
start
20
40
60
80
100
log-likelihood
×105
-2.5
-2
-1.5
-1
-0.5
B
start
20
40
60
log-likelihood
×104
-5.9796
-5.9795
C
start
20
40
60
80
100
log-likelihood
×104
-5.9796
-5.9795
Figure 3.11: Performance comparison for the numerically more stable and the classical
calculation of the likelihood. The red circles mark the value of the log-
likelihood function corresponding to the ML estimate. (A, B) show the
optimizer output for the robust calculation. (A) All (local) optima found
by the optimizer. (B) The best log-likelihood value is found in 71 out of
100 runs. The diﬀerence of the values is below 10−10. (C) Only 1 initial
value of 100 has a probabilty greater than 0 using the classical calculation.
3.4.4 Simulation Example: Conversion Reaction
For the validation of the method we generate data of a conversion process as in Sec-
tion 3.3.2, comprising the conversion between two species A and B.
Artiﬁcial Data
As we want to analyze multivariate data, we measure both species A and B. We generate
trajectories of 1000 cells in some volume Ω = 1000.
The total number of molecules
N0 = A + B is log-normally distributed with mean μN0 = 1000 and variance σ2
N0 = 2500.
The cell population has a subpopulation structure due to diﬀerences in the response to
stimulus u.
The parameter k1, describing the stimulus dependent conversion of A to
B, is set to k1,s1 = 0.1 for the low responsive subpopulation and to k1,s2 = 0.75 for
the high responsive subpopulation. Both subpopulations have the same size (w = 0.5).
The parameters shared by the subpopulations are given by k2 = 0.5 and k3 = 1.5.
Measurements y of the absolute numbers of A and B are assumed to be recorded at
t = 0, 0.1, 0.2, 0.3, 0.5 and 1 minutes. The parameter vector that needs to be estimated
from the data is given by θ = (k1,s1, k1,s2, k2, k3, μN0, σN0, w)T.

3.4 Simultaneous Analysis of Multivariate Measurements
47
A [number of mol.]
500
900  t = 0 min
data
 t = 0.1 min
 t = 0.2 min
B [number of mol.]
  200
500 
A [number of mol.]
500
900  t = 0.3 min
B [number of mol.]
  200
500 
 t = 0.5 min
B [number of mol.]
  200
500 
 t = 1 min
Figure 3.12: Artiﬁcial multivariate data of a conversion process of A and B with cell-
to-cell variability in the total number of molecules N0.
Moment Equations for a Conversion Process with Variability in N0
To obtain the MEs, we assume to have three species A, B and N0 = A + B. The number
of molecules for species A and B changes according to the reactions of the conversion
process introduced in Section 3.3.2. The total number of molecules N0 is assumed to be
distributed with some mean μN0 and variance σN0 across the cells. Within an individual
cell, the number of molecules is constant. This yields the MEs (Kazeroonian et al., 2016)
dmB
dt
= (k1 + k3)mA −k2mB ,
dmA
dt
= k2mB −(k1 + k3)mA ,
dmN0
dt
= 0 ,
dCB,B
dt
= (k1 + k3)mB + k2mA + 2(k1 + k3)CB,A −2k2CB,B ,
dCB,A
dt
= −(k1 + k3)mB −k2mA −(k1 + k2 + k3)CB,A + k1CA,A + k2CB,B ,
CB,N0
dt
= (k1 + k3)CA,N0 −k2CB,N0 ,
CA,A
dt
= (k1 + k3)mA + k2mB + 2k2CB,A −2(k1 + k3)CA,A ,
CA,N0
dt
= −(k1 + k3)CA,N0 + k2CB,N0 ,
CN0,N0
dt
= 0 .

48
3 ODE Constrained Mixture Modeling for Multivariate Data
Using conservation of mass and calculation rules for covariances we obtain the following
initial conditions
mB(0) =
k2
k2 + k3
μN0 ,
mA(0) =

1 −
k2
k2 + k3

μN0 ,
mN0(0) = μN0 ,
CA,A(0) = σ2
N0 −2CB,N0 + CB,B(0) ,
CB,B(0) = k2mA(0) + k3mB(0) + 2k2CB,N0
2(k2 + k3)
,
CA,N0(0) =
k2
k2 + k3
σ2
N0 ,
CB,N0(0) =
k3
k2 + k3
σ2
N0 ,
CN0,N0 = σ2
N0 .
Comparison of Multivariate and Univariate Analysis of Measurements
To analyze how much information is gained by considering multivariate measurements,
we perform parameter estimation ﬁrst by simultaneously analyzing both measurements
and then by analyzing one measurement at a time. The parameter restrictions are the
same for both cases, namely the kinetic parameters and mean number of molecules μN0
are assumed to lie in [10−6, 104], the weight within [0, 1] and the coeﬃcient of varia-
tion for the number of molecules cvN0 = σN0/μN0 within [10−6, 104]. For the univariate
case we analyze the measurements of A and B independently, while we simultaneously
use both measurements in the likelihood (3.5) for the multivariate case. The ﬁts corre-
sponding to the best parameters of 100 multi-start local optimization runs are depicted
in Figures 3.13A-C. The model can explain the data quite well. The comparison of the
likelihoods in Figure 3.13D shows that information is gained by using both measurements
at the same time.
We presented a method, which considers multivariate measurements simultaneously to
infer parameters. This allows to capture correlated behavior between the measurements,
which would not be possible if the measurements are considered separately. More in-
formation can be extracted from the data yielding higher conﬁdence in the estimates.

3.4 Simultaneous Analysis of Multivariate Measurements
49
Furthermore, we proposed a reformulation of the likelihood of mixture probabilities to
obtain a robust computation, which cannot only be used within ODE-MM, but can be
applied to other approaches that require the calculation of mixture probabilities.
A
frequency
0
0.03
0.06
 t = 0 min
data
model
 t = 0.1 min
frequency
0
0.03
0.06
 t = 0.2 min
 t = 0.3 min
A [number of mol.]
500
800
frequency
0
0.03
0.06
 t = 0.5 min
A [number of mol.]
500
800
 t = 1 min
B
frequency
0
0.05
0.1
 t = 0 min
data
model
 t = 0.1 min
frequency
0
0.05
0.1
 t = 0.2 min
 t = 0.3 min
B [number of mol.]
200
500
frequency
0
0.05
0.1
 t = 0.5 min
B [number of mol.]
200
500
 t = 1 min
C
500
900  t = 0 min
data
model
frequency
×10-4
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
 t = 0.1 min
A [number of mol.]
500
900  t = 0.2 min
 t = 0.3 min
B [number of mol.]
200
500
500
900  t = 0.5 min
B [number of mol.]
200
500
 t = 1 min
D
log10(k2)
-0.35
-0.3 -0.25  
likelihood
ratio     
0
0.5
1
log10(k3)
0.1
0.15
0.2
log10(k1,s2)
-1.1
-1
-0.9  
likelihood
ratio     
0
0.5
1
log10(μN
0
)
     2.999
3
3.001     
log10(cvN
0
)
-1.32
-1.3
-1.28
w
0.45
0.5
0.55
likelihood
ratio     
0
0.5
1
univariate
true param.
multivariate
log10(k1,s1)
-0.14-0.12 -0.1
Figure 3.13: Results of parameter estimation and identiﬁability analysis. (A, B) Fitted
data for species A and B using the univariate implementation of ODE-MMs.
(C) Fitted multivariate measurements of A and B. The level sets of the
multivariate normal mixture distribution are visualized. (D) Comparison
of the proﬁle likelihoods for both cases. The conﬁdence intervals are wider
if the measurements are considered seperately.

50
3 ODE Constrained Mixture Modeling for Multivariate Data
3.5 Application Example: NGF-Induced Erk Signaling
In the previous sections, we implemented a method based on ODE-MMs, which is able to
capture variability within a subpopulation and analyze multivariate measurements. We
apply our method to data of NGF-induced Erk signaling in primary sensory neurons, a
process that has already been explained and studied in Section 3.2.1.
3.5.1 Experimental Data
We investigate three experiments, comprising kinetics and dose responses. For experiment
1 and 2, only the pErk concentration has been measured (see Figures 3.14A and B). For
experiment 3, multivariate measurements of pErk and total Erk levels are available (see
Figure 3.14C). For details of the collection of the data we refer to (Hasenauer et al., 2014b),
in which the ﬁrst two experiments have been analyzed with ODE-MMs using RREs. As
this method is not able to analyze multivariate data simultaneously, the two-dimensional
measurements have not yet been included into the parameter estimation procedure and
have only been used to validate the results obtained based on the univariate measurements.
3.5.2 Moment Equations for The Simple Pathway Model of
NGF-Induced Erk Signaling with Variability in Total Erk Levels
Since the data visualized in Figure 3.14C shows that the total Erk levels vary between
individual cells, our model assumes total Erk levels to be distributed with some mean
and variance.
As we use MEs that describe the evolution of the concentrations, we
assume a volume of Ω = 500μm3 for a neuron. We scale the system with ΩAv = 301.1,
with Av being Avogadros constant. The concentration, which is obtained by dividing
the number of molecules by ΩAv, is given in units of nM. The concentration of the
complex TrkA:NGF is denoted by C, [pErk] by P, [Erk]0 by E0 and [TrkA]0 by T0. The
system is stimulated with [NGF]0 denoted by NGF0, corresponding to u in (3.5). Given
the parameters k1, k2, k3, k4, k5, T0, μE0 and σE0, we obtain the following MEs using the
toolbox CERENA (Kazeroonian et al., 2016):
dmC
dt
= −k2mC + k1
CC,C + (ΩAvNGF0 −mC)(T0 −mC)
ΩAv
,
dmP
dt
= −k5mP −k4(mP −mE0) + k3
CC,E0 −CC,P −mC(mP −mE0)
ΩAv
,
dmE0
dt
= 0 ,

3.5 Application Example: NGF-Induced Erk Signaling
51
A
frequency
0
0.05
0.1  t = 0 min
Kinetic for [NGF]0 = 1nM
data
 t = 5 min
frequency
0
0.05
0.1  t = 15 min
pErk level [UI]
100
102  
 t = 30 min
pErk level [UI]
100
102  
frequency
0
0.05
0.1  t = 60 min
B
frequency
0
0.05
0.1  [NGF]0 = 0 nM
Dose response for t = 30 min
data
 [NGF]0 = 0.001 nM
frequency
0
0.05
0.1  [NGF]0 = 0.01 nM
 [NGF]0 = 0.1 nM
pErk level [UI]
100
102  
frequency
0
0.05
0.1  [NGF]0 = 1 nM
pErk level [UI]
100
102  
 [NGF]0 = 10 nM
C
pErk level [UI]
10-1
100
 [NGF]0 = 0 nM
Dose response for t = 30 min
data
pErk level [UI]
10-1
100
total Erk level [UI]
10-1
100
 [NGF]0 = 1 nM
Figure 3.14: Experimental data of NGF-induced Erk phosphorylation. (A) Univariate
kinetic measurements of pErk for 18797 cells. (B) Univariate dose response
measurements of pErk for 12205 cells.
(C) Multivariate dose response
measurements of pErk and total concentration of Erk for 4134 cells.

52
3 ODE Constrained Mixture Modeling for Multivariate Data
dCC,C
dt
= k2(mC −2CC,C) + k1
CC,C + (ΩAvNGF0 −mC)(T0 −mC)
ΩAv
−
2CC,C(ΩAvNGF0 + T0 −2mC)
ΩAv
,
dCC,P
dt
= k4(CC,E0 −CC,P) −k5CC,P −k2CC,P+
k3
CC,E0mC −CC,PmC −CC,C(mP −mE0)
ΩAv
−k1
CC,Pk1(ΩAvNGF0 + T0 −2mC)
ΩAv
,
dCC,E0
dt
= −k2CC,E0 −k1
CC,E0(ΩAvNGF0 + T0 −2mC)
ΩAv
,
dCP,P
dt
= k4(2CP,E0 −2CP,P −(mP −mE0)) + k5(mP −2CP,P) +
k3
CC,E0 −CC,P −2CP,PmC + 2CP,E0mC −2CC,P(mP −mE0) −mC(mP −mE0)
ΩAv
,
dCP,E0
dt
= k4(CE0E0 −CP,E0) −k5CP,E0 + k3
CE0,E0mC −CP,E0mC −CC,E0(mP −mE0)
ΩAv
,
dCE0,E0
dt
= 0 .
The initial condition is the steady state of the system without stimulus, i.e., NGF0 = 0,
mP(0) =
k4
k4 + k5
μE0 ,
mE0(0) = μE0 ,
CP,P(0) =
2k2
4σ2
E0 + 2k4k5μE0
2(k4 + k5)2
,
CP,E0(0) =
k4
k4 + k5
σ2
E0 ,
CE0,E0(0) = σ2
E0 ,
mC(0) = 0, CC,C(0) = 0 , CC,P(0) = 0 , CC,E0(0) = 0 .
The measurements ye for the univariate kinetic (e = 1) and dose response (e = 2) data,
and the multivariate dose response data (e = 3) are then given in concentrations by
ye = s1P = s1[pErk] ,
for e = 1, 2 ,
ye =
⎛
⎝s2P + b
s3E0
⎞
⎠=
⎛
⎝s2[pErk] + b
s3[Erk]0
⎞
⎠,
for e = 3 ,
with additional experiment-speciﬁc scaling parameters s1, s2, s3 and oﬀset parameter de-
noted by b.

3.5 Application Example: NGF-Induced Erk Signaling
53
Table 3.6: Results for model selection for NGF-induced Erk signaling.
ns
nθ
log L(θML)(104)
AIC (104)
ΔAIC
BIC (104)
ΔBIC
rank
decision
MH1
1
13
−4.1263
8.2252
> 10
8.2662
> 10
3
rejected
MH2
2
15
−3.9135
7.8300
> 10
7.8427
> 10
2
rejected
MH3
2
16
−3.9079
7.8190
0
7.8325
0
1
optimal
3.5.3 Hypothesis Testing
To assess our method for real experimental data, we test the following hypotheses:
H1 No diﬀerence between subpopulations.
H2 Diﬀerent levels of TrkA (TrkA0,i for subpopulation i).
H3 Diﬀerent levels of TrkA and diﬀerent mean concentrations of Erk (TrkA0,i and μE0,i
for subpopulation i).
As the log-normal distribution parametrized by its median has been selected as the op-
timal distribution by Hasenauer et al. (2014b) based on the univariate data, we use a
multivariate log-normal distribution as mixture distribution and constrain the median by
the MEs. H1 includes variability in total Erk levels, but assumes that the cell population
consist of only one population. H2 and H3 consider a subpopulation structure, emerging
due to diﬀerent levels of TrkA. For H3, also the parameter μE0,i describing the mean of
total Erk levels diﬀers between the subpopulations. We parametrize the variance σ2
E0,i
by the coeﬃcient of variation cvE0,i. In addition, we assume independent log-normally
distributed multiplicative measurement noise. All parameters besides the subpopulation
weight, which is assumed to lie within [0, 1], are restricted to the interval [10−10, 1010].
The results for parameter estimation with 1000 multi-starts and model selection using
AIC and BIC are shown in Figure 3.15 and Table 3.6. The ﬁts indicate that the model
can explain the data. Both criteria select MH3, indicating that the origin of diﬀerence
are not only TrkA levels, but also diﬀerent means of total levels Erk.
We applied ODE-MMs to kinetic and dose response experiments of NGF-induced Erk
signaling, comprising diﬀerent dimensions of measurements. Using not only the measure-
ments of pErk, but also the two-dimensional measurements of pErk and total Erk levels

54
3 ODE Constrained Mixture Modeling for Multivariate Data
gives a more detailed insight into the underlying system. By performing parameter es-
timation and model selection with our proposed method, it was possible to account for
variability in total Erk levels and to identify a further diﬀerence between the subpopula-
tions, namely the mean of total Erk levels.
3.6 Discussion and Outlook
In this chapter, we used and extended ODE-MMs to study subpopulation structures and
dynamics. Based on novel data for NGF-induced Erk signaling, we evaluated the methods
applicability to unravel diﬀerences in subpopulation response between experimental con-
ditions. A mechanistic description of the subpopulation by MEs yields not only a reduced
number of parameters, it also enables us to capture intrinsic and extrinsic variability of
a subpopulation. In addition, we enhanced the method to analyze multivariate measure-
ments and therefore account for correlations between the measurands. We successfully
tackled numerical instability, which not only arises for ODE-MMs but for other methods
using mixture distributions. The application of our method to examples for a conversion
process and real data of NGF-induced Erk signaling revealed an improved acquisition of
the data.
In this thesis, we used the normal and log-normal distribution to mix the subpopulations.
Other distributions, for example the t-distribution and the skew-t distribution (Pyne et
al., 2009) can also be used within ODE-MMs. For distributions that are deﬁned by more
than their ﬁrst two moments, higher order MEs can be used to describe the system and
be linked to the mixture distributions.
Not only the mixture distribution can be exchanged. Other representations of the sys-
tem, which also account for variability within the subpopulations can be studied, e.g. the
linear noise approximation (Kampen, 2007, Chapter X). If the system comprises species
of low- and high-copy numbers, the method of conditional moment equations described
in Section 2.2.4 can be incorporated into ODE-MMs.
So far, the number of subpopulations needs to be predeﬁned and can be chosen by perform-
ing model selection for diﬀerent numbers of mixture components . An adaptive approach

3.6 Discussion and Outlook
55
to choose this number would be a Bayesian version of the method that uses reversible
jump Markov chain Monte Carlo techniques (Murphy, 2012). These methods are able
to select an appropriate number of subpopulations by performing parameter estimation
across parameter spaces of diﬀerent dimensions.
In summary, our results prove that ODE-MMs are a ﬂexible tool for the analysis of
heterogeneous populations. Our extensions facilitate to extract more information from
the data and therefore provide an improved insight into the mechanisms of the biological
processes.

56
3 ODE Constrained Mixture Modeling for Multivariate Data
A
frequency
0
0.05
0.1  t = 0 min
Kinetic for [NGF]0 = 1nM
data
model
 t = 5 min
frequency
0
0.05
0.1  t = 15 min
pErk level [UI]
100
102
t = 30 min
pErk level [UI]
100
102
frequency
0
0.05
0.1  t = 60 min
B
frequency
0
0.05
0.1  [NGF]0 = 0 nM
Dose response for t = 30 min
data
model
[NGF]0 = 0.001 nM
frequency
0
0.05
0.1  [NGF]0 = 0.01 nM
[NGF]0 = 0.1 nM
pErk level [UI]
100
102
frequency
0
0.05
0.1  [NGF]0 = 1 nM
pErk level [UI]
100
102
[NGF]0 = 10 nM
C
pErk level [UI]
10-1
100
[NGF]0 = 0 nM
Dose response for t = 30 min
data
model
frequency
1
1.5
2
2.5
3
3.5
4
4.5
5
pErk level [UI]
10-1
100
total Erk level [UI]
10-1
100
[NGF]0 = 1 nM
Figure 3.15: Fitted data of NGF-induced Erk phosphorylation for model MH3. (A) Uni-
variate ﬁt of kinetic measurements of pErk.
(B) Univariate ﬁt of dose
response measurements of pErk.
(C) Multivariate ﬁt for dose response
measurements of pErk and total concentration of Erk. The model is rep-
resented by level sets of the frequency, given by a multivariate log-normal
distribution.

4 Approximate Bayesian Computation
for Single-Cell Time-Lapse Data
Using Multivariate Statistics
In the previous chapter we focused on modeling and parameter estimation for single-cell
snapshot data. We provided and assessed a method, which not only considers the mean
behavior of the cell population, but also the second order moments. In this chapter we
go one step further in the direction of treating cells as individuals by modeling single-cell
time-lapse data with continuous time Markov chains (CTMCs) (Gillespie, 2007).
In Section 4.1, we formulate the key problems that arise in parameter inference for single-
cell time-lapse data and that are addressed in this chapter. Section 4.2 introduces approx-
imate Bayesian computation (ABC), a method used for parameter estimation without the
usage of a likelihood function. An essential step of ABC is the comparison of two data
sets. Therefore, we present in Section 4.3 two multivariate test statistics that are suitable
for the task of comparing time-series. We study how these statistics can be incorporated
into the ABC scheme. Diﬀerent approaches are evaluated on a bivariate normal distribu-
tion. In Section 4.4, our method is applied to artiﬁcial time-series of a one-stage model of
gene expression. Here, we assess our method for equilibrium and non-equilibrium data as
well as for data including parameter variability and tree-structured data. In Section 4.5,
we summarize and discuss our results.
4.1 Introduction and Problem Statement
For small molecule numbers stochastic eﬀects may complicate the analysis on the popu-
lation level. Thus, the system should be modeled in a stochastic way accounting for the
randomness of the underlying processes (Wilkinson, 2009). CTMCs model the births and
deaths of single molecules and therefore capture intrinsic noise.
© Springer Fachmedien Wiesbaden 2016
C. Loos, Analysis of Single-Cell Data, BestMasters, 
DOI 10.1007/978-3-658-13234-7_4

58
4 Approximate Bayesian Computation Using Multivariate Statistics
To estimate parameters of a CTMC, likelihood-based methods can be applied. These
methods consider all possible paths of the stochastic process by evaluating the transition
density, e.g. using the ﬁnite state projection (FSP) (Munsky & Khammash, 2006). As
this is computationally demanding and merely tractable for simple processes and mod-
erate system sizes, likelihood-free approaches have been developed, which are also called
approximate Bayesian computation (ABC) methods (Marin et al., 2012). ABC meth-
ods circumvent the evaluation of the likelihood. A parameter is accepted if the distance
between simulated and measured data is suﬃciently small, and rejected otherwise. The
performance and convergence of ABC depends crucially on the employed distance mea-
sure.
Single-cell time-lapse data are highly multivariate, especially if measurements at several
time points exist. While it is possible to collect thousands of measurements e.g. ﬂow cy-
tometry, the generation of single-cell time-series is time-consuming, as its requires several
steps and the cell tracking often has to be done manually. On the other hand, information
is gained as cells are tracked over time, and this source of information should be taken
into account in the parameter estimation procedure. When inferring the parameters for
single-cell time-lapse data, the following problems arise:
Problem 1 Single-cell time-series are multivariate and appropriate distance measures
are not yet available.
Problem 2 The sample size of single-cell time-series is small.
In this thesis, we will take a population perspective rather than ﬁtting trajectories individ-
ually (Dargatz, 2010). Trajectories of individual cells are samples from a high-dimensional
path distribution. Accordingly, distance measures for ABC are provided by multivariate
test statistics.

4.2 Extended Introduction to Approximate Bayesian Computation
59
4.2 Extended Introduction to Approximate Bayesian
Computation
Approximate Bayesian computation (ABC) has ﬁrst been introduced by Pritchard et al.
(1999). The method has been extended and improved continuously (see e.g. (Marin et al.,
2012)) and covers a broad range of applications (see (Csill´ery et al., 2010) for an overview).
4.2.1 Algorithms
The most basic ABC algorithm is the ABC rejection sampler, which is explained in Algo-
rithm 4.1. The goal is to obtain samples from the posterior distribution p(θ|Dobs) of the
parameters based on observed data Dobs. Therefore, a data set Dsim is simulated with
respect to a parameter θ that has been sampled from the prior distribution p(θ). This
data set is then compared to the experimental data set. The comparison is carried out by
calculating some distance d(Dobs, Dsim) between both data sets. If the distance is below
a certain predeﬁned threshold ϵ, the sampled parameter is accepted as a sample of the
posterior distribution. Otherwise, the sample is rejected and another parameter is sam-
pled from the prior until it produces a distance below the desired threshold. This whole
procedure is repeated several times to obtain P samples of the posterior approximation
of interest. The approximated posterior then converges to the true posterior for ϵ →0.
The main drawback of ABC rejection is that the acceptance rate can be low if prior
and posterior distribution are very diﬀerent.
Some extensions tackle this problem by
combining ABC with other methods such as Markov chain Monte Carlo (Marjoram et al.,
2003) or sequential Monte Carlo methods (Toni et al., 2009). The latter algorithm, ABC
with sequential Monte Carlo (ABC SMC) is explained in Algorithm 4.2. The ﬁrst step
is basically an ABC rejection step, in which the particles are sampled from the prior
and are accepted if the corresponding simulated data set produces a distance below the
ﬁrst threshold ϵ1. Every particle obtains a weight w(t)
i , which is used to sample the next
population. For intermediate populations with an index t > 2, the particles are sampled
from the previous population and additionally perturbed with respect to the perturbation
kernel Kt(·|·). The particles of the ﬁnal population are then the desired samples of the
approximated posterior distribution.

60
4 Approximate Bayesian Computation Using Multivariate Statistics
Algorithm 4.1: ABC rejection
Input: Data set Dobs, prior p(θ), threshold ϵ, simulation function p(D|θ), number
of particles P.
Result: Samples of p(θ|d(Dobs, Dsim) ≤ϵ).
for i = 1, . . . , P do
repeat
Draw θ(1)
i
∼p(θ) and simulate Dsim ∼p(D|θi).
until d(Dobs, Dsim) < ϵ
end
Algorithm 4.2: ABC SMC (Toni et al., 2009)
Input: Data set Dobs, prior p(θ), perturbation kernel Kt(·|·), threshold schedule
ϵ1 > . . . > ϵT for the T populations, simulation function p(D|θ), number
of particles P
Result: Samples of p(θ|d(Dobs, Dsim) ≤ϵ).
Set population index t = 1.
for i = 1, . . . , P do
repeat
Draw θ(1)
i
∼p(θ) and simulate Dsim ∼p(D|θ(1)
i )
until d(Dobs, Dsim) < ϵ1
Set w(t)
i
= 1/P, the weight of particle θ(t)
i .
for t = 2, . . . , T do
for i = 1, . . . , P do
repeat
Pick θ∗
i from the θ(t−1)
j
’s with probabilities w(t−1)
j
.
until p(θ∗
i ) > 0
repeat
Draw θ(t)
i
∼Kt(θ(t)
i |θ∗
i ) and simulate Dsim ∼p(D|θ(t)
i ).
until d(Dobs, Dsim) < ϵt
Compute new weights as w(t)
i
=
p(θ(t)
i )

j w(t−1)
j
Kt(θ(t)
i |θ(t−1)
j
).
end
Normalize w(t)
i
over i = 1, . . . , P.
end
end

4.2 Extended Introduction to Approximate Bayesian Computation
61
4.2.2 Conﬁgurations of The Algorithm
There are several user-speciﬁed aspects and algorithm settings that have a major inﬂuence
on the performance and accuracy of the algorithm. Thus, the conﬁguration need to be
chosen carefully, but for most of them no general rule of thumb exists. In the following, we
discuss the diﬀerent tuning parameters and settings, their inﬂuence on the performance
and accuracy of the algorithm, and possible choices of the parameters.
Summary Statistics
The eﬃciency of the algorithm crucially depends on the marginal probability to observe
the data set. Low probabilities of p(Dobs) have the consequence that the acceptance rate
of the parameters is also low. Therefore, the calculation of the distances between the data
sets d(Dobs, Dsim) is often replaced by the calculation of the distances d(S(Dobs), S(Dsim))
between summaries. As p(S(Dobs)) is usually larger than p(Dobs), this results in a higher
acceptance rate. If it holds for the summary statistics that p(θ|D) = p(θ|S(D)), meaning
that the statistic is suﬃcient, the true posterior can be obtained for ϵ →0 (Nunes &
Balding, 2010).
Examples for summary statistics are e.g.
moments (see e.g. (Wegmann et al., 2009;
Beaumont et al., 2002)) of the data. Other approaches that are based on concepts of hy-
pothesis testing are proposed by Lillacci & Khammash (2013) and Ratmann et al. (2013).
Given a predeﬁned set of summary statistics, methods to choose summary statistics exist
in the literature (see (Blum et al., 2013) for a detailed comparison of methods to select
summary statistics). As they mostly need a candidate set of statistics, this has the con-
sequence that the eﬃciency of these methods depends on this initial choice of summary
statistics.
Using summary statistics has some drawbacks. If the statistic does not capture enough
information about the data, i.e. if its not suﬃcient, the diﬀerence between approximated
and true posterior distribution is unknown (Marjoram & Tavar´e, 2006). If the likelihood
is unknown, it is not possible to identify whether a summary statistic is suﬃcient (Wilkin-
son, 2013).

62
4 Approximate Bayesian Computation Using Multivariate Statistics
Stopping Criterion
The decision whether the algorithm has converged or the approximation is good enough
can be diﬃcult. If the ﬁnal tolerance level is too high, the approximation can be quite
diﬀerent from the true posterior. Conversely, if the tolerance level is too low, the compu-
tation time is longer than needed to obtain a reasonable approximation.
One possibility is to determine the minimal distance between observed and simulated
data ϵend data-driven for example by subsampling. Assume there are n observed samples,
then the following procedure can be repeated several times
• Randomly pick two equally-sized subsets D1, D2 ⊂Dobs (e.g. with replacement)
• Calculate ϵ = d(S(D1), S(D2))
and e.g. a certain percentile of the calculated ϵ values is chosen as ﬁnal distance that needs
to be achieved. This has the disadvantage that if the distance function depends on the
number of samples n, the determined value may not represent the true minimal distance
between observed and simulated data. Lenormand et al. (2013) presented an adaptive
population Monte Carlo ABC scheme which additionally gives a stopping criterion based
on the acceptance rate. But still, a minimal value for the acceptance rate needs to be
deﬁned.
Threshold Schedule
The choice of the ϵ-schedule is crucial for the performance of the algorithm. If the se-
quence decreases too slowly the computation time will be quite long until a reasonable
approximation is achieved. On the other hand if it decreases too fast the acceptance rate
will be too low which also results in a high computation time. The tolerances should
always be determined considering the data, model and prior (Silk et al., 2013).
The most common approach is a quantile selection scheme. This approach determines ϵt
at the beginning of the sampling of population t by calculating ϵt in a way that a given
percentage of the particles in population t −1 generated a smaller distance (Drovandi &
Pettitt, 2011; Del Moral et al., 2012; Lenormand et al., 2013; Beaumont et al., 2009).

4.2 Extended Introduction to Approximate Bayesian Computation
63
Silk et al. (2013) proposed to choose the next threshold based on an estimation of the
acceptance rate curve.
Perturbation Kernel
The particles that are sampled for the intermediate and ﬁnal distributions are additionally
perturbed with respect to some perturbation kernel Kt(·|·). For large numbers of param-
eters that need to be estimated from the data, or computational expensive models, the
acceptance rate can drastically decrease if no suitable perturbation kernel is used (Filippi
et al., 2013). The trade-oﬀbetween the acceptance rate, which tends to be better if the
particles are not moved a lot, and the exploration of the parameter space, which needs a
higher perturbation of the particle, has to be considered.
Filippi et al. (2013) listed several perturbation kernels, which aim to resemble the true
posterior distribution. This list comprises e.g. component-wise kernels such as a uniform
kernel and multivariate kernels such as a multivariate normal kernel. The former uses the
width of the previous population that already fulﬁll the tolerance criterion for the current
population to calculate the width of the kernel. The latter is based on the covariance of
the particles of the previous population. A quite ﬂexible and more local kernel is a multi-
variate normal kernel with k-nearest neighbors. This kernel uses a multivariate Gaussian
distribution centered around the sampled parameter. The covariance is given by the em-
pirical covariance of the k-nearest neighbors of the parameter, e.g. the k parameters that
have the smallest euclidean distance to the sampled parameter.
Number of Particles Per Population
One advantage of ABC SMC is that it is able to obtained better approximations of
multimodal posteriors than ABC rejection (Toni et al., 2009). For this, it is necessary to
ﬁnd an appropriate number of particles P. The approximation gets better if more samples
are used. But especially for the last populations the acceptance rates can be really low,
which potentially results in a long computation time until the desired number of samples
is obtained. Mostly, the number is predetermined by intuition and increased if the results
are not reproducible.

64
4 Approximate Bayesian Computation Using Multivariate Statistics
Number of Samples to Generate for The Simulated Data Sets
Another parameter that needs to be chosen is the number of samples in the simulated
data set denoted by m. Since the main idea is to reproduce the observed data set, an
intuitive choice for m is to set it equal to the number of observed data points n. For large
values of n this can result in long simulation times. Therefore, Lillacci & Khammash
(2013) calculate within the method INSIGHT (see Section 4.2.3) the number of samples
needed to decide whether to accept or reject an particles at a conﬁdence level α.
The main advantage of ABC methods is that they are applicable to any stochastic model
for which a forward simulation is possible. However, the methods have a lot of tuning pa-
rameters and conﬁgurations that have a great inﬂuence on the accuracy and performance
of the algorithm. This can be seen as a huge disadvantage of the method, especially, as
for most of the conﬁgurations no general applicable approach exists.
4.2.3 State-of-The-Art: ABC for Stochastic Models of Single-Cell
Snapshot Data
ABC methods have been successfully applied for the analysis of single-cell snapshot data
collected e.g. using ﬂow cytometry. The Inference for Networks of Stochastic Interactions
among Genes using High-Throughput data (INSIGHT) algorithm has already been used
for high-dimensional models (Lillacci & Khammash, 2013). Since cells are discarded after
being measured in ﬂow cytometry, the measurements at the nt diﬀerent time points are
independent. The distance between observed and simulated data sets can be calculated
in the ABC rejection step using the maximal Kolmogorov-Smirnov (KS) distance:
dKS(Dobs, Dsim) := max
k
∥ˆFXk −ˆGYk∥∞,
(4.1)
with Dobs = {Xk}nt
k=1, Dsim = {Yk}nt
k=1 , and ˆFXk, ˆGYk being the corresponding empir-
ical cumulative distributions. Here, a sample Xk contains the ﬂuorescence levels of the
n single-cells for a time point that is indexed by k and each Yk comprises m samples.
INSIGHT achieves good results, beneﬁting from large sample sizes provided by ﬂow cy-
tometry, from using the two-sample Kolmogorov-Smirnov test to compare the data sets,
and from exploiting relationships between conﬁgurations of the ABC algorithm and the

4.3 Approximate Bayesian Computation with Multivariate Test Statistics
65
test statistic. Given some threshold ϵ, the critical value of m(c)
KS(α, ϵ), needed to decide
whether to accept or reject the particle at a conﬁdence level α, can be calculated by
investigating properties of the KS distance (see (Lillacci & Khammash, 2013, Supplemen-
tary Information)):
m(c)
KS(α, ϵ) =
⎡
⎢⎢⎢⎢⎢⎢
−log(1−√1−α
2
)
2

ϵ −

−1
2n log(1−√1−α
2
)
2
⎤
⎥⎥⎥⎥⎥⎥
.
(4.2)
Given a ﬁxed value for m, the critical value ϵ(c)
KS(α, m) can be computed:
ϵ(c)
KS(α, m) =
!
−1
2n log

1 −√1 −α
2

+
!
−1
2m log

1 −√1 −α
2

.
(4.3)
We will adapt the idea of using test statistics for the development of an ABC SMC method
for single-cell time-lapse data, which we later will compare with INSIGHT.
4.3 Approximate Bayesian Computation with
Multivariate Test Statistics
One of the problems arising when inferring parameters from single-cell time-lapse data is
the dimensionality of the time-series (Problem 1). This requires to study, how ABC can be
used to infer parameters based on multivariate data. In the following, we develop an ABC
method for single-cell time-lapse data using hypothesis testing (Lillacci & Khammash,
2013; Ratmann et al., 2013).
4.3.1 Multivariate Test Statistics
The goal is to decide whether to accept or reject a parameter based on the observed data
and the data set that has been generated with respect to the parameter. In the context
of test statistics, this can be done using a two-sample test. If the test indicates that
both underlying distributions are equal, the parameter is accepted as sample from the
posterior approximation. For the case of data sets that comprise only one-dimensional

66
4 Approximate Bayesian Computation Using Multivariate Statistics
samples, tests relying on the KS distance can be used as proceeded in INSIGHT (Lillacci &
Khammash, 2013). Since we want to apply ABC SMC with test statistics to multivariate
data, we need to ﬁnd an appropriate multivariate test statistic for the two-sample problem
(see (Gretton et al., 2012, Section 3.3.3) for an overview of multivariate two-sample tests).
In the following we introduce the cross-match test, which compares two distributions
based on distances between samples, and the maximum mean discrepancy, which calcu-
lates the largest diﬀerence in expectation over functions in the unit ball of a reproducing
kernel Hilbert space.
Cross-Match Test
Rosenbaum (2005) presented an exact and distribution-free test to compare two multivari-
ate distributions based on multivariate samples, which for example consist of continuous
or discrete vectors of possibly inﬁnite dimension. For the test, which is named cross-match
test, a complete graph is deﬁned, in which nodes correspond to samples and edge weights
correspond to distances between the samples. To obtain the test statistic a minimum
weight non-bipartite matching is performed, i.e., the set of edges is found under the con-
dition that every node is incident to exactly one edge of this set and the sum of weights
of these edges is minimal. The number of cross-matches A1, i.e., the matched pairs that
comprising one observed and one simulated sample, then indicates, whether all samples
are drawn from the same distribution. The null distribution of A1 is
Pr(A1 = a1) =
2a1 n+m
2

!
n+m
n

a0!a1!a2!
,
(4.4)
with al being the number of matches with exactly l observed samples. For the case of
n + m being uneven see (Rosenbaum, 2005). Note that the distribution only depends on
the numbers of observed and simulated samples.
We want to decide whether to reject or accept the null hypothesis, based on c obtained
cross-matches. If the probability to observe c or less cross-matches under the null hy-
pothesis is greater than the conﬁdence level α, we cannot reject the hypothesis. If the
probability is smaller, we conclude that the samples are drawn from diﬀerent distribu-
tions. Given

4.3 Approximate Bayesian Computation with Multivariate Test Statistics
67
Pr(A1 ≤c) =
c

i=0
2i n+m
2 !
n+m
n

(n+m
2
−n+i
2 )!i!(n−i
2 )!
≤α,
(4.5)
we can ﬁx m and α and ﬁnd numerically the critical value c(c)
CM(α, m), the minimum num-
ber of cross-matches, which has to be exceeded to reject the null hypothesis. Moreover,
we can ﬁx α and c to ﬁnd the minimum number of samples m(c)
CM(α, c) needed to decide
whether A1 > c.
We implemented the cross-match test in MATLAB. For this, we integrated a blossom
V algorithm1 Kolmogorov, 2009 to perform the minimum-weight non-bipartite match-
ing, which requires O((n + m)3) arithmetic operations. Moreover, we use the euclidean
distance for the calculation of the distances between the nodes. The cross-match test is
visualized in Figure 4.1.
The main advantage of the cross-match test is that it is distribution-free and exact, i.e.,
it does not make assumptions about the underlying distribution and the null distribution
is known in closed form.
Maximum Mean Discrepancy
An alternative multivariate test statistic for the two-sample problem is based on the
maximum mean discrepancy (MMD), which has ﬁrst been introduced by Borgwardt et al.
(2006)
MMD[F, p, q] := sup
f∈F
(Ep[f(x)] −Eq[f(y)]) .
If the distributions p and q are equal, the MMD is zero. Moreover, F is a class of functions
f : X →R that is chosen to be the unit ball in a universal reproducing kernel Hilbert
space H, to achieve a trade-oﬀbetween over- and underﬁtting. If F comprises not enough
functions, the MMD may not be able to detect diﬀerences between the distributions p and
q. Contrarily, if the class is to powerful, for p = q the MMD may be signiﬁcantly greater
than zero for ﬁnite sample sizes. Given samples X = (x1, . . . , xn) and Y = (y1, . . . , ym)
of p and q, respectively, an empirical estimate of the MMD is
1Available at http://pub.ist.ac.at/~vnk/software.html.

68
4 Approximate Bayesian Computation Using Multivariate Statistics
A
-1
0
1
2
3
4
2
3
4
5
6
7
observed data
simulated data
 cross-match
 no cross-match
x2
x1
B
-1
0
1
2
3
4
2
3
4
5
6
7
x2
x1
Figure 4.1: Illustration of the cross-match test. The blue dots mark the observed data
Dobs, which has been generated by a bivariate normal distribution with co-
variance matrix Σ = I2 and mean μ = (2, 5)T. The red dots mark the simu-
lated data Dsim. The connected points are matched together by a minimum-
weight non-bipartite matching. Bold lines highlight the cross-matches. (A)
A higher number of cross-matches indicating a higher similarity of the data
sets. The parameter would be accepted. (B) The particles produces a sim-
ulated data set, which is less similar to the observed data set in terms of
number of cross-matches, and thus would be rejected.
MMD[F, X, Y] := sup
f∈F

1
n
n

i=1
f(xi) −1
m
m

j=1
f(yj)

.
Using a kernel k(x, y) = Φ(x)TΦ(y) with nonlinear feature space mapping Φ(x) (see (Bishop,
2006) for further information), the MMD can be rewritten in terms of the mean embedding
μp := Ep[Φ(x)] as
MMD[F, p, q] = sup
f∈F
⟨μp −μq, f⟩= ∥μp −μq∥H .
With μX = 1
n
n
i=1 Φ(xi) and k(x, y) = ⟨Φ(x), Φ(y)⟩the empirical estimate of MMD is
MMD[F, X, Y] =
 1
n2
n

i̸=j
k(xi, xj) + 1
m2
m

i̸=j
k(yi, yj) −2
nm
n,m

i,j=1
k(xi, yj)
 1
2 .
(4.6)

4.3 Approximate Bayesian Computation with Multivariate Test Statistics
69
Figure 4.2: Function ˆf ∗witnesses the MMD between a Gaussian and Laplace distribu-
tion. This ﬁgure has been adopted from (Gretton et al., 2012).
For the incorporation of the MMD into the ABC scheme, we exploit the following bound-
ary (Gretton et al., 2012, Corollary 9)
MMD[F, X, Y] < ϵ(c)
MMD(α, m) :=
"
2/m

1 +
"
2 log α−1

,
(4.7)
that assumes m = n. We use a MATLAB implementation of the MMD2 that has been
developed by Gretton et al. (2012). The computational costs for the evaluation of (4.6)
are O((n + m)2) and the test has shown to perform good even for low sample sizes and
high dimensional data. A connection to summary statistics is given by the fact, that a
feature map of a kernel is a suﬃcient statistic for the exponential family (Song, 2008).
4.3.2 Comparison of Test Statistics in ABC for Samples of a
Bivariate Normal Random Variable
In the following, we assess the properties of the aforementioned multivariate test statistics
and ABC SMC methods using them. We generate n = 100 samples x of a bivariate
normal random variable with mean μ = (μ1, μ2)T = (0, 0)T and the identity covariance
matrix Σ = I2 (see Figure 4.3A). We assume the covariance to be known, which yields two
unknown parameters θ = (μ1, μ2)T that are estimated from the data. Using a multivariate
normal conjugate prior with location parameter μ0 and covariance Σ0 (Murphy, 2012)
2Available at http://www.gatsby.ucl.ac.uk/~gretton/mmd/mmd.htm.

70
4 Approximate Bayesian Computation Using Multivariate Statistics
p(θ) = N(θ|μ0, Σ0) ,
the posterior distribution is given by
p(θ|Dobs, Σ) = N(θ|μn, Σn) ,
Σ−1
n
= Σ−1
0
+ nΣ−1 ,
(4.8)
μn = Σn

Σ−1(n¯x) + Σ−1
0 μ0

.
Here, ¯x is the sample mean of the data. This posterior can be compared to the posterior
approximation obtained by ABC SMC sampling. We implemented the ABC SMC Algo-
rithm 4.2 in MATLAB, using a k-nearest neighbor perturbation kernel with k = P/5 and
a 25th percentile approach for the selection of the threshold for the next population. The
parameters for the prior are chosen as
μ0 =
⎛
⎝0
0
⎞
⎠
and Σ0 =
⎛
⎝100
0
0
100
⎞
⎠,
yielding the posterior parameters
μn =
⎛
⎝
0.0195
−0.0202
⎞
⎠and Σn =
⎛
⎝0.01
0
0
0.01
⎞
⎠.
(4.9)
Since the eﬃciency of the algorithm depends on conﬁgurations such as the threshold
schedule, we only compare the approaches in terms of convergence, i.e., whether it is
possible to obtain a reasonable approximation, and not in terms of performance.
Fixed Number of Simulations and Final Threshold Calculated by Test Statistic
Inequalities
As there exists no general stopping criterion, we study, whether a ﬁnal threshold can be
determined by exploiting the relationship between distance value and number of simu-
lations. We calculate the desired threshold of the last population corresponding to the
given number of simulations m = n according to (4.3), (4.5) and (4.7) and compare:

4.3 Approximate Bayesian Computation with Multivariate Test Statistics
71
• Cross-match test (CM) with cend = c(c)
CM(0.05, 100) = 40.
• Maximum mean discrepancy (MMD) with ϵend = ϵ(c)
MMD(0.05, 100) = 0.4876.
• Kolmogorov-Smirnov distance (KS) with ϵend = ϵ(c)
KS(0.05, 100) = 0.2956.
Note that in contrast to MMD and KS, a high value for the CM indicates a good agree-
ment. The resulting posterior approximations are shown in Figure 4.3B. The approxima-
tions of the posterior are much wider than the true posterior, which has been calculated
using (4.8) and (4.9). This means that for this simple example, the critical threshold
values can not be used as stopping criterion. We expect this approach to give an even
worse threshold for higher dimensions and more complex examples.
Fixed Number of Simulations and Lower Final Tolerance
To study, whether a reasonable approximation of the posterior can be obtained with the
distance calculations, we increased the desired number of cross-matches (cend = 56) and
decreased the ﬁnal distances (ϵMMD,end = 0.0664, ϵKS,end = 0.11). We chose these values
according to the 10th percentile of the distances obtained by simulating 10000 data sets
with the true parameters and calculating the corresponding test statistics. Figure 4.3C
shows the distributions of the test statistics. The gray shaded area indicates for which
values of the statistic a parameter is accepted in the ﬁnal population of ABC SMC.
For CM, additionally the exact null distribution is visualized calculated with (4.4). We
repeated the ABC SMC sampling for all distances, again for a ﬁxed number of simulated
samples m = n. The results are shown in Figure 4.3D. ABC with MMD and KS give
a reasonable approximation of the posterior, while the posterior using the cross-match
test is much wider than the true posterior distribution. Decreasing the tolerance did not
improve the approximation signiﬁcantly.
Adaptive Number of Simulations and Corresponding Threshold Schedule Using
The KS Distance
The inequality for the KS distance can also be used if n and m are diﬀerent. Therefore,
we want to study, whether the method beneﬁts from using an adaptive determination
of m given some pre-deﬁned threshold schedule, as proceeded in INSIGHT. We ﬁxed the
threshold schedule to ϵ = 0.99, 0.7, 0.5, 0.4, 0.2 and 0.17 and calculated the corresponding
critical values of m = 4, 8, 18, 35, 802, and 4435 using (4.2). The value of m for the last

72
4 Approximate Bayesian Computation Using Multivariate Statistics
population in the adaptive approach is much higher than for m = n. Moreover, using the
adaptive selection of m yields a total number of simulations in the ABC SMC algorithm
which is more than twice as much as for m = n. The approximation obtained for this
threshold value is much wider than the true posterior (see Figure 4.3D). An even lower
ﬁnal threshold ϵend increases the number of simulations for the last population drastically,
since the value approaches the pol of (4.2) at ϵ =
#
−1
2n log

1−√1−α
2

. Crossing this
value yields a decreasing sequence for m which violates the assumptions of INSIGHT.
Inferring Parameters of The Covariance Matrix of a Bivariate Normal Distribution
We evaluate ABC SMC with MMD, CM and KS for a second data set comprising n = 100
samples (see Figure 4.4A). We generate samples of a bivariate normal distribution with
known mean μ = (0, 0)T and a covariance matrix of the form
Σ =
⎛
⎝θ1
θ2
θ2
θ1
⎞
⎠.
As the covariance matrix needs to be positive deﬁnite, both eigenvalues λ1 = θ1 + θ2 and
λ2 = θ1 −θ2 need to be greater than zero. This yields the restrictions θ1 + θ2 > 0 and
θ1 −θ2 > 0. Therefore, we use the following prior
p(θ) =
⎧
⎨
⎩
1
100
, for 0 < θ1 < 10, 0 ≤θ2 < θ1
0
, otherwise
,
for the parameters θ = (θ1, θ2)T, which are estimated in the following.
The ﬁnal tolerances, cend = 56, ϵMMD,end = 0.055 and ϵKS,end = 0.99 are chosen with
respect to the distances obtained by simulating data and calculating the statistics with
the ground truth. The results of ABC SMC are visualized in Figure 4.4B. ABC SMC
with MMD and CM is able to estimate the parameters. The conﬁdence obtained using
MMD is much higher than for CM. The KS approach provides an estimation of θ1 only.
The posterior approximation for θ2 is much wider and only restricted by the relationship
|θ2| ≤θ1. The diﬀerence can be explained by the lack of information included in the
marginal distributions that are examined using KS. Information about θ1 can only be

4.3 Approximate Bayesian Computation with Multivariate Test Statistics
73
A
x1
-3
0
3
x2
-3
0
3
data
B
density
0
5
density
0
5
true value
true posterior
CM
MMD
KS
μ1
-2
0
2
μ2
-2
-1
0
1
2
C
cross-matches
40
60
density
0
0.1
0.2
CM
exact null dist.
MMDs
0
0.1
0.2
MMD
KS distances
0
0.1
0.2
0.3 
KS
region of acceptance
D
density
0
5
density
0
5
true value
true posterior
CM
MMD
KS
KS adaptive
μ1
-0.5
0
0.5
μ2
-0.5
0
0.5
Figure 4.3: ABC SMC using test statistics to estimate the mean of a bivariate nor-
mal distribution.
(A) Data generated from a bivariate normal distribu-
tion. (B) Posterior approximations for m = n simulations for every popula-
tion and ﬁnal threshold calculated using inequalities for the test statistics.
(C) Distributions of CM, MMD and KS statistics. The gray shaded area
shows the region for which the parameters are accepted. (D) Posterior ap-
proximations with m = n simulations for CM, MMD and KS with a lower
tolerance to accept the corresponding parameters than in (B). The dotted
line shows the marginal distribution for the case of an adaptive number of
simulations m with KS.

74
4 Approximate Bayesian Computation Using Multivariate Statistics
A
x1
-3
0
3
x2
-3
0
3
data
B
density
0
5
density
0
2
4
true value
true posterior
CM
MMD
KS
θ1
0.7
1.2
1.7
θ2
-1.6
0
1.6
Figure 4.4: ABC SMC using test statistics to estimate entries of the covariance matrix of
a bivariate normal distribution. (A) Depiction of 100 samples x ∼N2 (μ, Σ),
with μ = (0, 0)T and Σ =
 θ1 θ2
θ2 θ1

, with θ1 = 1 and θ2 = 0.5. (B) Results
of ABC with CM, MMD and KS. The yellow shaded are shows the region,
where the prior p(θ) > 0.
gained by investigating the correlations among the measurements. The quality of the
approximation did not improve signiﬁcantly for lower tolerances.
We assessed ABC SMC with diﬀerent approaches to incorporate CM, MMD and KS. For
the estimation of the entries of the covariance matrix, only ABC SMC with multivariate
statistics, CM and MMD, was able to estimate the parameters. The CM test requires a
higher computation time than the MMD and yields less accurate approximations of the
true posterior distribution for the example of a bivariate normal distribution. Accordingly,
we use the MMD for our subsequent studies.
4.4 Simulation Example: Single-Cell Time-Series of a
One-Stage Model of Gene Expression
In this section we apply the ABC SMC scheme described before to simulation examples
of a one-stage model of gene expression (see Figure 4.5A).

4.4 Simulation Example: Single-Cell Time-Series of a One-Stage Model of Gene Expression 75
4.4.1 Implementation
For the generation of artiﬁcial data of the one-stage model of gene expression we use a C
implementation of the stochastic simulation algorithm (SSA) developed by Dennis Rickert.
We implemented the ABC SMC algorithm in MATLAB according to Algorithm 4.2 and
use the following settings:
• We sample from the posterior distribution of the log10-transformed parameters.
• For all scenarios, we use an uninformative component-wise uniform prior distribution
U[−6, 4] for the log10-transformed parameters.
• To compare simulated and observed data sets, we use a multivariate statistic, the
MMD (4.6) and a univariate statistic, the maximal Kolmogorov-Smirnov distance
(4.1).
• For the threshold schedule we use an adaptive quantile approach with the 25th
percentile.
• We use a multivariate k-nearest neighbor perturbation kernel with k = P/5.
• We sample P = 500 particles per population.
• The ﬁnal threshold ϵend is chosen in a data-driven fashion.
Since stochastic simulations can be computationally expensive for some proposed param-
eter combinations, we try to avoid a too high perturbation of the proposed particle, but
still want to have enough ﬂexibility to explore the parameters space. This is achieved
by using a k-nearest neighbor perturbation kernel. We increase the number of particles
and repeat the approximation if the result are not reproducible, i.e., if we do not obtain
a similar approximation of the posterior within three repetitions. As we know the true
parameters for the simulation study, we generate 1000 data sets using the true values of
the parameters and calculate the corresponding distances. We use a threshold below the
5th percentile of those distances.
In the following, we consider two scenarios:
Scenario 1 The initial mRNA number is zero for all cells.
Scenario 2 The initial mRNA number is sampled from the steady state distribution.

76
4 Approximate Bayesian Computation Using Multivariate Statistics
A
∅
DNA
mRNA
λ
γ
B
time [h]
0
10
20
mRNA [number of mol.]
0
10
20
30
C
time [h]
0
10
20
mRNA [number of mol.]
0
10
20
30
Figure 4.5: Illustration of artiﬁcial single-cell time-lapse data. (A) One stage model
of gene expression with mRNA synthesis rate λ and degradation rate γ.
(B) Artiﬁcial non-equilibrium time-series of n = 10 cells sampled every 1
5 h.
(C) Equilibrium time-series of n = 10 cells measured at nt = 100 time
points.
For both scenarios we generate n = 10, 100 and 1000 single-cell time-series for the synthesis
rate λ = 5 h−1 and degradation rate γ = 0.3 h−1 using the SSA. The initial conditions
are [mRNA](0) = 0 for Scenario 1 and [mRNA](0) ∼Poi(λ/γ) for Scenario 2 (Shahrezaei
& Swain, 2008). We simulate the system for 20 h and record the mRNA at nt = 100
equidistant time points.
The data sets are visualized for the case of n = 10 cells in
Figures 4.5B-C. For the evaluation of our method we assume λ and γ to be unknown and
estimate them from the data.
4.4.2 Out of Steady State Time-Series
In the following, we describe the results for Scenario 1, in which the population exhibits
transient behavior and the data comprises non-equilibrium time-series. Performing ABC
SMC with the settings described in Section 4.4.1, we obtain the posterior approximations
shown in Figures 4.6A and B. As expected, increasing the number of cells yields a more
narrow posterior distribution. The scatter plot of the samples shows that the parameters
are highly correlated. Moreover, the results are reproducible, indicated by the fact that
three repetitions of the sampling with the same parameter settings yield almost the same
approximation of the posterior distribution.
For the case of 100 cells and 100 measurements, the MAP estimates are given by θMAP
MMD =
(4.8259, 0.2945)T and θMAP
KS
= (5.0069, 0.3078)T. We generated 1000 time-series based on
the MAP estimates and compared the mean and variance of the molecule numbers (see

4.4 Simulation Example: Single-Cell Time-Series of a One-Stage Model of Gene Expression 77
Figure 4.6C) as well as mean and variance of the corresponding autocorrelation function
(see Figure 4.6D). The ﬁts and the corresponding properties of the data are almost indis-
tinguishable.
We additionally compare the approximations with those obtained by the ﬁnite state pro-
jection (FSP) (Munsky & Khammash, 2006). This approach truncates the state space of
the species and can be used for small and medium-sized systems. We sample from the
posterior using a FSP-based likelihood and the MCMC toolbox DRAM (Haario et al.,
2006). The results are shown in Figure 4.6. The approximations obtained by the ABC
sampler are wider than the approximation using the FSP. ABC with MMD and KS yield
similar results. To study the inﬂuence of the dimension of the time-series, we generated
a scenario, in which 10 cells are measured at only 10 time points. While the approxi-
mation does not signiﬁcantly improve compared to the FSP-based approximation for an
increasing numbers of cells, the algorithm produces a better approximation for the case
of measurements at nt = 10 time points.
4.4.3 Steady State Time-Series
The results for Scenario 2 are shown in Figure 4.7. ABC SMC using KS is only able to
estimate the fraction λ/γ (Figure 4.7B). This is explained by the fact that the marginals
analyzed using the KS distance do not change over time.
In contrast, the proposed
multivariate methods using MMD exploits the temporal ﬂuctuations and can infer both
parameters (Figure 4.7A). The posterior distribution illustrated in Figure 4.7B diﬀers only
slightly from the initial uniform prior distribution. Surprisingly, the posterior distribution
is shifted towards smaller parameter values and the true values are only at the boundary
of the posterior approximations.
The ﬁts for the case of n = 100 cells and nt = 100 are shown in Figures 4.7C and D. The
corresponding MAP estimates are θMAP
MMD = (4.4388, 0.2650)T and θMAP
KS
= (0.0005, 0.0003)T.
As the kinetic rates estimated by the univariate consideration of the trajectories are much
smaller than the true values, the corresponding number of molecules does not change
within the simulation time of 20 h. Therefore, the autocorrelation function is not deﬁned,
since the corresponding time-series are constant.

78
4 Approximate Bayesian Computation Using Multivariate Statistics
A
density
0
20
40
60
MMD
true value
n=10
n=100
n=1000
density
0
20
40
60
log10(λ)
0.6
0.7
0.8
0.9
log10(γ)
-0.6
-0.5
-0.4
-0.3
B
density
0
20
40
60
KS
true value
n=10
n=100
n=1000
density
0
20
40
60
log10(λ)
0.6
0.7
0.8
0.9
log10(γ)
-0.6
-0.5
-0.4
-0.3
C
time [h]
0
5
10
15
20
mRNA [number of mol.]
0
10
20
30
data
MMD fit
KS fit
D
lag
0
5
10
15
20
sample autocorrelation
-0.2
0
0.2
0.4
0.6
0.8
1
data
MMD fit
KS fit
E
log10(λ)
0
1
2
density
0
5
10
log10(γ)
-1
0
1
density
0
5
10
n=10, nt=10
log10(λ)
0
0.5
1
0
10
20
log10(γ)
-1
-0.5
0
0
10
20
n=10, nt=100
log10(λ)
0.6
0.7
0.8
0
50
100
log10(γ)
-0.8
-0.6
-0.4
0
20
40
60
n=100, nt=100
log10(λ)
0.65
0.7
0.75
0
100
200
log10(γ)
-0.6
-0.5
-0.4
0
50
100
150
n=1000, nt=100
true value
FSP
MMD
KS
MMD
KS
Figure 4.6: Results of ABC SMC for non-equilibrium time-series data. (A, B) Posterior
approximations obtained by ABC SMC with (A) MMD and (B) KS. (C)
Fitted mean and variance of molecule numbers for 1000 simulation generated
with the MAP estimates. Single trajectories are illustrated in gray. (D) Fit-
ted mean and variance of the autocorrelation function for 1000 simulation
generated with the MAP estimates. The observed and simulated means and
variances are nearly indistinguishable for both, MMD and KS. (E) Com-
parison of marginals and FSP results for 10 cells and 10 time points (left),
and 10, 100, 1000 cells with 100 measurements. The diﬀerent lines show the
marginals for diﬀerent repetitions of the sampling procedure.

4.4 Simulation Example: Single-Cell Time-Series of a One-Stage Model of Gene Expression 79
Comparing the results with those obtained by the FSP (see Figure 4.7E) shows that ABC
SMC with MMD produces a much wider approximation of the posterior distribution. The
approximation is not as good as for Scenario 1, which can be explained by the fact that a
lot of information about the parameters can be extracted by the MMD from the dynamics
of the cells. The results for the case of less measurements (nt = 10) are better than for the
case of 100 measurements. This has also been observed for Scenario 1 (see Figure 4.6E).
4.4.4 Parameter Variability
Cell-to-cell variability of gene expression can be partitioned into intrinsic and extrinsic
noise (Elowitz et al., 2002). So far, only intrinsic noise has been considered, but the
proposed approach can in principle also be used to infer extrinsic sources of cell-to-cell
variability. In the following example, we model extrinsic noise by assuming variability in
the mRNA synthesis and degradation rates. The parameters λ and γ are assumed to be
log-normally distributed with means μλ, μγ and variances σ2
λ, σ2
γ. The data comprises
n = 100 time-series measured at nt = 100 time points. The true parameters used for
the data generation are θ = (μλ, σ2
λ, μγ, σ2
γ)T = (5, 0.1, 0.3, 0.05)T. The time-series are
depicted in Figure 4.8A. The overall variability is higher than in the scenarios without
additional variability, e.g. as shown in Figure 4.5B and 4.6C.
The results obtained for the ABC SMC are depicted in Figure 4.8B. Here, also the inter-
mediate distributions corresponding to diﬀerent tolerance values are visualized showing
the convergence of the algorithm. It reveals that the posterior distributions of the pa-
rameters μλ, μγ and σ2
γ are narrow, indicating identiﬁability. The posterior distribution
for σ2
λ is wider and merely an upper bound can be determined. Accordingly, our analysis
shows that in principle stochastic and deterministic variability can be reconstructed from
single-cell time-lapse data.
4.4.5 Tree Structure
Single-cell time-lapse data often contain information about the ancestors of a cell (Et-
zrodt et al., 2014). Using this information, ABC has e.g. been used to infer parameters
by comparing diﬀerentiation probabilities (Marr et al., 2012). We propose an approach
to include tree-structured data in our ABC SMC sampler that uses the MMD to compare

80
4 Approximate Bayesian Computation Using Multivariate Statistics
A
density
0
10
20
MMD
true value
n=10
n=100
n=1000
density
0
10
20
log10(λ)
0.2
0.4
0.6
0.8
log10(γ)
-1
-0.8
-0.6
-0.4
B
density
0
0.5
KS
true value
n=10
n=100
n=1000
prior
density
0
0.5
log10(λ)
-4
-2
0
2
log10(γ)
-4
-2
0
C
time [h]
0
5
10
15
20
mRNA [number of mol.]
0
10
20
30
data
MMD fit
KS fit
D
lag
0
5
10
15
20
sample autocorrelation
-0.4
-0.2
0
0.2
0.4
0.6
0.8
data
MMD fit
E
log10(λ)
-1
0
1
2
density
0
2
4
6
log10(γ)
-2
-1
0
1
density
0
2
4
6
n=10, nt=10
log10(λ)
0
0.5
1
0
10
20
log10(γ)
-1.5
-1
-0.5
0
10
20
n=10, nt=100
log10(λ)
0.5
1
0
20
40
60
log10(γ)
-1
-0.5
0
0
20
40
60
n=100, nt=100
log10(λ)
0.6
0.7
0.8
0
100
200
log10(γ)
-0.6
-0.5
-0.4
0
100
200
n=1000, nt=100
true value
FSP
MMD
KS
MMD
KS
Figure 4.7: Results of ABC SMC for steady state time-series data. (A, B) Posterior
approximations obtained by ABC SMC with (A) MMD and (B) KS. (C)
Fitted mean and variance of number of molecules for 1000 simulation gen-
erated with the MAP estimates. The single trajectories are illustrated in
gray. (D) Fitted mean and variance of the autocorrelation function for 1000
simulation generated with the MAP estimates of the MMD. (E) Comparison
of marginals to results obtained by FSP for 10 cells and 10 time points (left),
and 10, 100, 1000 cells with 100 measurements. The diﬀerent lines show the
marginals for diﬀerent repetitions of the sampling procedure.

4.4 Simulation Example: Single-Cell Time-Series of a One-Stage Model of Gene Expression 81
A
time [h]
0
5
10
15
20
mRNA [number of mol.]
0
10
20
30
40
50
60
70
B







	
	
μλ
 	




σ
λ



μγ

	 	
σ
γ



ϵ

ϵ
	
ϵ


Figure 4.8: ABC SMC for cells aﬀected by extrinsic noise. (A) Time-series of cells with
parameter variability. (B) Results obtained by ABC SMC with MMD. On
the diagonal, the marginal posterior distributions for the parameters are
shown. The oﬀdiagonals provide scatter plots. The colours indicate the
population corresponding to diﬀerent tolerances ϵ and illustrate the conver-
gence.
individual time-series. For this, we assume that a simple tree comprises one mother and
its two daughter cells. One sample is given by xi = (xi,mother, xi,daughter1, xi,daughter2), as
visualized in Figure 4.9A. Since the samples need to have the same dimension when using
the MMD, we consider a ﬁxed time interval before and after cell division. This is further
motivated by the fact that the time-series exhibit transient dynamics after division before
reaching the equilibrium, and therefore have a higher information content. Time-series of
diﬀerent lengths could also be interpolated and scaled to the same interval. To assess the
method, we generate n = 50 simple trees (Figure 4.9B) that each includes one division
process. A cell, which is measured at 50 time points, divides after 10 h. The molecules are
equally split among its daughter cells. Both daughters are simulated for 10 h and mea-
sured at 50 time points. In the sample vector, the time-series of the mother is followed
by the time-series of the cell, which has the higher molecule content at the end of the
simulation.
Figure 4.9C visualizes the posterior approximations for three repetitions of the ABC
sampling with MMD. As the posterior distributions are quite narrow, the parameters can
be estimated with high conﬁdence. This demonstrates the applicability of our method to
not only time-series, but also single-cell time-lapse data with additional tree structure.

82
4 Approximate Bayesian Computation Using Multivariate Statistics
A
time [h]
mRNA [number of mol.]
xi = (xi,mother, xi,daughter1, xi,daughter2)
B
time [h]
0
5
10
15
20
mRNA [number of mol.]
0
10
20
30
C
density
0
10
20
true value
approx. post.
density
0
5
10
15
log10(λ)
0.6
0.65
0.7
log10(γ)
-0.65
-0.6
-0.55
-0.5
Figure 4.9: ABC SMC for tree structured data. (A) Sample comprising time-series of
a mother and its two daughter cells. (B) Artiﬁcal data of n = 50 simple
trees. (C) Posterior approximations for ABC SMC with MMD. The joint
posterior as well as the marginal posteriors of the parameters λ and γ are
shown for three repetitions of the sampling.
This approach, accounting for connections between the time-series of the mother and
the daughter cells, might improve the insight gained into the underlying process. For
example, parameters of the partitioning process could be estimated.
4.5 Discussion and Outlook
In this chapter, we introduced and evaluated an ABC SMC method to infer parameters
of CTMCs. The method uses multivariate test statistics on the distribution of single-cell
trajectories. We assessed our method for data from a bivariate normal distribution and
for artiﬁcial single-cell time-series. We studied the use of diﬀerent test statistics, com-
prising the multivariate statistics MMD and CM, and the univariate KS distance as used
in INSIGHT (Lillacci & Khammash, 2013). For several examples, identiﬁability for the
parameters was only achieved using multivariate statistics and ABC with MMD provided
the best approximations of the posterior distributions. We found that for equilibrium
single-cell time-lapse data the tracking information is important to identify the individual
parameters.
A drawback of the method is the high computation time arising due to computation-
ally expensive stochastic simulations.
Thus, eﬃcient simulation methods, such as τ-
leaping (Gillespie, 2007) or the method of conditional moments (Hasenauer et al., 2014a)

4.5 Discussion and Outlook
83
could be used instead of the SSA. These should be combined with appropriate threshold
schedules (Silk et al., 2013) and stopping criteria.
Using the acceptance region of the hypothesis test based on a given conﬁdence level did
not yield suitable approximations. This could arise due to low sample sizes, the higher
dimension of the samples and imprecise boundaries for the test statistics. Thus it should
be studied, whether better results can be achieved by considering more precise bound-
aries. It would probably also be worth to study how computation time can be saved by
adapting the method to diﬀerent numbers of observed and simulated samples (m < n).
Furthermore, as more and more lineage information becomes available, its information
content should be evaluated.
In summary, the proposed ABC SMC method using multivariate test statistics seems
promising for the analysis of time-lapse single-cell data. It provides a general and ﬂexible
framework, which can easily be extended to similar data types. Using model selection,
even sources of cell-to-cell variability might be unraveled.

5 Summary and Discussion
In this thesis, we studied models and parameter estimation methods for single-cell data
that are able to account for cellular heterogeneity. We developed two methods, ODE-MMs
with MEs for multivariate measurements (Chapter 3) and ABC SMC using multivariate
test statistics (Chapter 4). While ODE-MMs have merely been used for single-cell snap-
shot data, the latter method, ABC SMC with multivariate statistics, can be applied to
single-cell time-lapse data. Both of our methods can account for intrinsic and extrinsic
noise sources and therefore are suitable tools for the elucidation of cell heterogeneity.
Two main extensions for ODE-MMs enable us on the one hand to account for cell-to-cell
variability, and on the other hand to exploit correlations between multivariate measure-
ments. Since the MEs that are used for the description of the subpopulation dynamics
govern the evolution of the second order moments, the variances do not have to be esti-
mated from the data. This yields a reduced number of parameters. Taking into account
multivariate information of the data revealed a higher conﬁdence in the estimates. In ad-
dition, we successfully tackled problems that arise when performing parameter estimation
for advanced models. We proposed a numerically stable way to calculate the likelihood
function of mixture probabilities and its gradient.
For the case of inferring parameters from single-cell time-lapse data, a key problem is
the lack of a computational tractable likelihood function, which can be tackled by using
likelihood-free ABC methods. We included temporal information of the data by consider-
ing single-cell trajectories as samples of a higher dimensional space. The distance between
time-series needed for the ABC SMC algorithm is given by multivariate test statistics,
which yields an improved parameter identiﬁability.
In conclusion, using more sophisticated modeling approaches rather than deterministic
models enables us to extract more information from single-cell data. Since these models
generally complicate parameter estimation, eﬃcient and suitable methods are required.
However, we presented two ﬂexible methods for the analysis of single-cell snapshot and
© Springer Fachmedien Wiesbaden 2016
C. Loos, Analysis of Single-Cell Data, BestMasters, 
DOI 10.1007/978-3-658-13234-7_5

86
5 Summary and Discussion
single-cell time-lapse data.
They consider both, appropriate models that account for
cell-to-cell variability and suitable approaches to calibrate those models to measurement
data. Therefore, applying our methods to experimental data could help to obtain a deeper
understanding of cell heterogeneity and the underlying biological processes.

Bibliography
Akaike, H. (1998). Information theory and an extension of the maximum likelihood prin-
ciple. Selected Papers of Hirotugu Akaike. Springer, 199–213.
Altschuler, S. J. & Wu, L. F. (2010). Cellular heterogeneity: do diﬀerences make a diﬀer-
ence?. Cell 141(4), 559–563.
Beaumont, M. A., Zhang, W. & Balding, D. J. (2002). Approximate Bayesian computation
in population genetics. Genetics 162(4), 2025–2035.
Beaumont, M. A., Cornuet, J.-M., Marin, J.-M. & Robert, C. P. (2009). Adaptive ap-
proximate Bayesian computation. Biometrika, 1–8.
Bishop, C. M. (2006). Pattern recognition and machine learning. Vol. 4. 4. Springer New
York.
Blum, M. G., Nunes, M. A., Prangle, D., Sisson, S. A., et al. (2013). A comparative re-
view of dimension reduction methods in approximate Bayesian computation. Statistical
Science 28(2), 189–208.
Borgwardt, K. M., Gretton, A., Rasch, M. J., Kriegel, H.-P., Sch¨olkopf, B. & Smola, A. J.
(2006). Integrating structured biological data by kernel maximum mean discrepancy.
Bioinformatics 22(14), 49–57.
Burnham, K. P. & Anderson, D. R. (2002). Model selection and multimodel inference: a
practical information-theoretic approach. Springer Science & Business Media.
Cho, K.-H. & Wolkenhauer, O. (2005). Systems Biology: Discovering the dynamic be-
haviour of biochemical networks. BioSystems Review 1(1), 9–17.
Csill´ery, K., Blum, M. G., Gaggiotti, O. E. & Fran¸cois, O. (2010). Approximate Bayesian
computation (ABC) in practice. Trends in Ecology & Evolution 25(7), 410–418.
Dargatz, C. (2010). Bayesian inference for diﬀusion processes with application in life
sciences. PhD thesis. LMU Munich.
Davey, H. M. & Kell, D. B. (1996). Flow cytometry and cell sorting of heterogeneous
microbial populations: the importance of single-cell analyses. Microbiological Reviews
60(4), 641–696.
© Springer Fachmedien Wiesbaden 2016
C. Loos, Analysis of Single-Cell Data, BestMasters, 
DOI 10.1007/978-3-658-13234-7

88
Bibliography
Del Moral, P., Doucet, A. & Jasra, A. (2012). An adaptive sequential Monte Carlo method
for approximate Bayesian computation. Statistics and Computing 22(5), 1009–1020.
Drovandi, C. C. & Pettitt, A. N. (2011). Estimation of parameters for macroparasite
population evolution using approximate Bayesian computation. Biometrics 67(1), 225–
233.
Elowitz, M. B., Levine, A. J., Siggia, E. D. & Swain, P. S. (2002). Stochastic gene expres-
sion in a single cell. Science 297(5584), 1183–1186.
Engblom, S. (2006). Computing the moments of high dimensional solutions of the master
equation. Applied Mathematics and Computation 180(2), 498–515.
Etzrodt, M., Endele, M. & Schroeder, T. (2014). Quantitative Single-Cell Approaches to
Stem Cell Research. Cell Stem Cell 15(5), 546–558.
Filippi, S., Barnes, C. P., Cornebise, J. & Stumpf, M. P. (2013). On optimality of ker-
nels for approximate Bayesian computation using sequential Monte Carlo. Statistical
Applications in Genetics and Molecular Biology 12(1), 87–107.
Gilks, W. R., Richardson, S. & Spiegelhalter, D. J. (1996). Introducing markov chain
monte carlo. Markov Chain Monte Carlo in Practice.
Gillespie, D. T. (1977). Exact stochastic simulation of coupled chemical reactions. The
Journal of Physical Chemistry 81(25), 2340–2361.
Gillespie, D. T. (1992). A rigorous derivation of the chemical master equation. Physica
A: Statistical Mechanics and its Applications 188(1), 404–425.
Gillespie, D. T. (2007). Stochastic simulation of chemical kinetics. Annual Review of
Physical Chemistry 58, 35–55.
Gretton, A., Borgwardt, K. M., Rasch, M. J., Sch¨olkopf, B. & Smola, A. (2012). A kernel
two-sample test. The Journal of Machine Learning Research 13(1), 723–773.
Haario, H., Laine, M., Mira, A. & Saksman, E. (2006). DRAM: eﬃcient adaptive MCMC.
Statistics and Computing 16(4), 339–354.
Hasenauer, J. (2013). Modeling and parameter estimation for heterogeneous cell popula-
tions. PhD thesis. Universit¨at Stuttgart.
Hasenauer, J., Wolf, V., Kazeroonian, A. & Theis, F. J. (2014a). Method of condi-
tional moments (MCM) for the Chemical Master Equation: a uniﬁed framework for

Bibliography
89
the method of moments and hybrid stochastic-deterministic models. Journal of Math-
ematical Biology 69(3), 687–735.
Hasenauer, J., Hasenauer, C., Hucho, T. & Theis, F. J. (2014b). ODE Constrained Mixture
Modelling: A Method for Unraveling Subpopulation Structures and Dynamics. PLoS
Computational Biology 10(7), e1003686.
Hastie, T., Tibshirani, R. & Friedman, J. (2009). The elements of statistical learning.
Vol. 2. 1. Springer.
Jahnke, T. & Huisinga, W. (2007). Solving the chemical master equation for monomolec-
ular reaction systems analytically. Journal of Mathematical Biology 54(1), 1–26.
Kampen, N. van (2007). Stochastic processes in physics and chemistry. Amsterdam: North
Holland, 3rd revised edition ed.
Kazeroonian, A., Fr¨ohlich, F., Raue, A., Theis, F. J. & Hasenauer, J. (2016). CERENA:
ChEmical REaction Network Analyzer - a toolbox for the simulation and analysis of
stochastic chemical kinetics. PLoS One (accepted).
Kitano, H. (2002). Computational systems biology. Nature 420(6912), 206–210.
Kolmogorov, V. (2009). Blossom V: a new implementation of a minimum cost perfect
matching algorithm. Mathematical Programming Computation 1(1), 43–67.
Lee, C. H., Kim, K.-H. & Kim, P. (2009). A moment closure method for stochastic reaction
networks. The Journal of Chemical Physics 130(13), 134107.
Lenormand, M., Jabot, F. & Deﬀuant, G. (2013). Adaptive approximate Bayesian com-
putation for complex models. Computational Statistics 28(6), 2777–2796.
Lillacci, G. & Khammash, M. (2010). Parameter estimation and model selection in com-
putational biology. PLoS Computational Biology 6(3), e1000696.
Lillacci, G. & Khammash, M. (2013). The signal within the noise: eﬃcient inference of
stochastic gene regulation models using ﬂuorescence histograms and stochastic simula-
tions. Bioinformatics, 2311–2319.
Malone, J. H. & Oliver, B. (2011). Microarrays, deep sequencing and the true measure of
the transcriptome. BMC Biology 9(1), 34.
Marin, J.-M., Pudlo, P., Robert, C. P. & Ryder, R. J. (2012). Approximate Bayesian
computational methods. Statistics and Computing 22(6), 1167–1180.

90
Bibliography
Marjoram, P. & Tavar´e, S. (2006). Modern computational approaches for analysing molec-
ular genetic variation data. Nature Reviews Genetics 7(10), 759–770.
Marjoram, P., Molitor, J., Plagnol, V. & Tavar´e, S. (2003). Markov chain Monte Carlo
without likelihoods. Proceedings of the National Academy of Sciences 100(26), 15324–
15328.
Marr, C., Strasser, M., Schwarzﬁscher, M., Schroeder, T. & Theis, F. J. (2012). Multi-
scale modeling of GMP diﬀerentiation based on single-cell genealogies. FEBS Journal
279(18), 3488–3500.
Michor, F. & Polyak, K. (2010). The origins and implications of intratumor heterogeneity.
Cancer Prevention Research 3(11), 1361–1364.
Miyashiro, T & Goulian, M (2007). Single-cell analysis of gene expression by ﬂuorescence
microscopy. Methods in Enzymology 423, 458–475.
Munsky, B. & Khammash, M. (2006). The ﬁnite state projection algorithm for the solution
of the chemical master equation. The Journal of Chemical Physics 124(4), 044104.
Munsky, B., Trinh, B. & Khammash, M. (2009). Listening to the noise: random ﬂuctua-
tions reveal gene network parameters. Molecular Systems Biology 5(318).
Murphy, K. P. (2012). Machine learning: a probabilistic perspective. MIT press.
Muzzey, D. & Oudenaarden, A. van (2009). Quantitative time-lapse ﬂuorescence mi-
croscopy in single cells. Annual Review of Cell and Developmental Biology 25, 301–
327.
Nunes, M. A. & Balding, D. J. (2010). On optimal selection of summary statistics for
approximate Bayesian computation. Statistical Applications in Genetics and Molecular
Biology 9(1).
Pritchard, J. K., Seielstad, M. T., Perez-Lezaun, A. & Feldman, M. W. (1999). Population
growth of human Y chromosomes: a study of Y chromosome microsatellites.. Molecular
Biology and Evolution 16(12), 1791–1798.
Pyne, S., Hu, X., Wang, K., Rossin, E., Lin, T.-I., Maier, L. M., Baecher-Allan, C.,
McLachlan, G. J., Tamayo, P., Haﬂer, D. A., et al. (2009). Automated high-dimensional
ﬂow cytometric data analysis. Proceedings of the National Academy of Sciences 106(21),
8519–8524.

Bibliography
91
Raftery, A. E. (1999). Bayes factors and BIC. Sociological Methods & Research 27(3), 411–
417.
Ratmann, O., Camacho, A., Meijer, A. & Donker, G. (2013). Statistical modelling of
summary values leads to accurate Approximate Bayesian Computations. arXiv preprint
arXiv:1305.4283.
Raue, A., Kreutz, C., Maiwald, T., Bachmann, J., Schilling, M., Klingm¨uller, U. & Tim-
mer, J. (2009). Structural and practical identiﬁability analysis of partially observed
dynamical models by exploiting the proﬁle likelihood. Bioinformatics 25(15), 1923–
1929.
Raue, A., Schilling, M., Bachmann, J., Matteson, A., Schelke, M., Kaschek, D., Hug, S.,
Kreutz, C., Harms, B. D., Theis, F. J., et al. (2013). Lessons learned from quantitative
dynamical modeling in systems biology. PLoS ONE 8(9), e74335.
Renart, J., Reiser, J. & Stark, G. R. (1979). Transfer of proteins from gels to
diazobenzyloxymethyl-paper and detection with antisera: a method for studying anti-
body speciﬁcity and antigen structure. Proceedings of the National Academy of Sciences
76(7), 3116–3120.
Resat, H., Petzold, L. & Pettigrew, M. F. (2009). Kinetic modeling of biological systems.
Computational Systems Biology. Springer, 311–335.
Rosenbaum, P. R. (2005). An exact distribution-free test comparing two multivariate
distributions based on adjacency. Journal of the Royal Statistical Society: Series B
(Statistical Methodology) 67(4), 515–530.
Schroeder, T. (2011). Long-term single-cell imaging of mammalian stem cells. Nature
Methods 8(4), 30–35.
Schwarz, G. et al. (1978). Estimating the dimension of a model. The Annals of Statistics
6(2), 461–464.
Sengupta, B, Friston, K. & Penny, W. (2014). Eﬃcient gradient computation for dynam-
ical models. NeuroImage 98, 521–527.
Shahrezaei, V. & Swain, P. S. (2008). Analytical distributions for stochastic gene expres-
sion. Proceedings of the National Academy of Sciences 105(45), 17256–17261.

92
Bibliography
Silk, D., Filippi, S. & Stumpf, M. P. (2013). Optimizing threshold-schedules for sequen-
tial approximate Bayesian computation: applications to molecular systems. Statistical
Applications in Genetics and Molecular Biology 12(5), 603–618.
Song, L. (2008). Learning via Hilbert space embedding of distributions. PhD thesis. Uni-
versity of Sydney.
Szekely, T. & Burrage, K. (2014). Stochastic simulation in systems biology. Computational
and Structural Biotechnology Journal 12(20), 14–25.
Toni, T., Welch, D., Strelkowa, N., Ipsen, A. & Stumpf, M. P. (2009). Approximate
Bayesian computation scheme for parameter inference and model selection in dynamical
systems. Journal of the Royal Society Interface 6(31), 187–202.
Torres-Padilla, M.-E. & Chambers, I. (2014). Transcription factor heterogeneity in pluripo-
tent stem cells: a stochastic advantage. Development 141(11), 2173–2181.
Wegmann, D., Leuenberger, C. & Excoﬃer, L. (2009). Eﬃcient approximate Bayesian
computation coupled with Markov chain Monte Carlo without likelihood. Genetics
182(4), 1207–1218.
Wilkinson, D. J. (2009). Stochastic modelling for quantitative description of heterogeneous
biological systems. Nature Reviews Genetics 10(2), 122–33.
Wilkinson, R. D. (2013). Approximate Bayesian computation (ABC) gives exact results
under the assumption of model error. Statistical Applications in Genetics and Molecular
Biology 12(2), 129–141.

