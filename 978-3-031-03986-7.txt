Emergence, Complexity and Computation ECC
Sukanta Das
Souvik Roy
Kamalika Bhattacharjee   Editors
The Mathematical 
Artist
A Tribute To John Horton Conway

Emergence, Complexity and Computation
Volume 45
Series Editors
Ivan Zelinka, Technical University of Ostrava, Ostrava, Czech Republic
Andrew Adamatzky, University of the West of England, Bristol, UK
Guanrong Chen, City University of Hong Kong, Hong Kong, China
Editorial Board
Ajith Abraham, MirLabs, USA
Ana Lucia, Universidade Federal do Rio Grande do Sul, Porto Alegre, Rio Grande
do Sul, Brazil
Juan C. Burguillo, University of Vigo, Spain
Sergej ˇCelikovský, Academy of Sciences of the Czech Republic, Czech Republic
Mohammed Chadli, University of Jules Verne, France
Emilio Corchado, University of Salamanca, Spain
Donald Davendra, Technical University of Ostrava, Czech Republic
Andrew Ilachinski, Center for Naval Analyses, USA
Jouni Lampinen, University of Vaasa, Finland
Martin Middendorf, University of Leipzig, Germany
Edward Ott, University of Maryland, USA
Linqiang Pan, Huazhong University of Science and Technology, Wuhan, China
Gheorghe P˘aun, Romanian Academy, Bucharest, Romania
Hendrik Richter, HTWK Leipzig University of Applied Sciences, Germany
Juan A. Rodriguez-Aguilar
, IIIA-CSIC, Spain
Otto Rössler, Institute of Physical and Theoretical Chemistry, Tübingen, Germany
Vaclav Snasel, Technical University of Ostrava, Czech Republic
Ivo Vondrák, Technical University of Ostrava, Czech Republic
Hector Zenil, Karolinska Institute, Sweden

The Emergence, Complexity and Computation (ECC) series publishes new devel-
opments, advancements and selected topics in the ﬁelds of complexity, computa-
tion and emergence. The series focuses on all aspects of reality-based computation
approaches from an interdisciplinary point of view especially from applied sciences,
biology, physics, or chemistry. It presents new ideas and interdisciplinary insight on
the mutual intersection of subareas of computation, complexity and emergence and
its impact and limits to any computing based on physical limits (thermodynamic and
quantum limits, Bremermann’s limit, Seth Lloyd limits…) as well as algorithmic
limits (Gödel’s proof and its impact on calculation, algorithmic complexity, the
Chaitin’s Omega number and Kolmogorov complexity, non-traditional calculations
like Turing machine process and its consequences,…) and limitations arising in arti-
ﬁcial intelligence. The topics are (but not limited to) membrane computing, DNA
computing, immune computing, quantum computing, swarm computing, analogic
computing, chaos computing and computing on the edge of chaos, computational
aspects of dynamics of complex systems (systems with self-organization, multiagent
systems, cellular automata, artiﬁcial life,…), emergence of complex systems and its
computational aspects, and agent based computation. The main aim of this series is
to discuss the above mentioned topics from an interdisciplinary point of view and
present new ideas coming from mutual intersection of classical as well as modern
methods of computation. Within the scope of the series are monographs, lecture
notes, selected contributions from specialized conferences and workshops, special
contribution from international experts.
Indexed by zbMATH.
More information about this series at https://link.springer.com/bookseries/10624

Sukanta Das · Souvik Roy · Kamalika Bhattacharjee
Editors
The Mathematical Artist
A Tribute To John Horton Conway

Editors
Sukanta Das
Department of Information Technology
Indian Institute of Engineering Science
and Technology
Howrah, India
Kamalika Bhattacharjee
Department of Computer Science
and Engineering
National Institute of Technology
Tiruchirappalli, India
Souvik Roy
C3iHub
Indian Institute of Technology
Kanpur, India
ISSN 2194-7287
ISSN 2194-7295 (electronic)
Emergence, Complexity and Computation
ISBN 978-3-031-03985-0
ISBN 978-3-031-03986-7 (eBook)
https://doi.org/10.1007/978-3-031-03986-7
© The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature
Switzerland AG 2022
This work is subject to copyright. All rights are solely and exclusively licensed by the Publisher, whether
the whole or part of the material is concerned, speciﬁcally the rights of translation, reprinting, reuse
of illustrations, recitation, broadcasting, reproduction on microﬁlms or in any other physical way, and
transmission or information storage and retrieval, electronic adaptation, computer software, or by similar
or dissimilar methodology now known or hereafter developed.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this publication
does not imply, even in the absence of a speciﬁc statement, that such names are exempt from the relevant
protective laws and regulations and therefore free for general use.
The publisher, the authors and the editors are safe to assume that the advice and information in this book
are believed to be true and accurate at the date of publication. Neither the publisher nor the authors or
the editors give a warranty, expressed or implied, with respect to the material contained herein or for any
errors or omissions that may have been made. The publisher remains neutral with regard to jurisdictional
claims in published maps and institutional afﬁliations.
This Springer imprint is published by the registered company Springer Nature Switzerland AG
The registered company address is: Gewerbestrasse 11, 6330 Cham, Switzerland

John Horton Conway
December 26, 1937–April 11, 2020
[Image Courtesy: Denise Applewhite, Princeton Ofﬁce of Communications, Princeton University]

Preface
The beginning of the year 2020 had seen the sudden appearance of an unknown virus,
named as SARS-CoV-2, which caused Coronavirus disease (COVID-19) and started
wreaking havoc over the globe within a few months, resulting in a pandemic. The
world literally stalled under this wrath of nature. This was the time when we lost
John Horton Conway.
Who is John Conway to us? We are the students, researchers, and practitioners of
Cellular Automata (CAs). All of us were practically introduced to cellular automaton
(CA) through the Game of Life by our teachers. This Game of Life, sometimes simply
known as Life, is a zero-player game developed by John Conway in 1970. Although
historically CA was initiated by John von Neumann and Stanislaw Ulam in the 1940s,
it was Conway’s Game of Life which popularized CA to the people beyond academia.
The power of its simple rule to create an inﬁnite world of possible complex patterns
is bound to make everyone like us charmed and intrigued to know more about CAs
and advertently come to do research on CAs.
However, John Conway was not limited to only Game of Life. In fact, it is a
very small shade of his life ﬁlled with contributions in different areas forming a
colorful palette. Be it the Combinatorial game theory, Group theory, Number theory,
Geometry, Geometric topology, Algebra, or Theoretical Physics, whatever area he
had touched, a remarkable contribution on his name has remained there. We lost the
legacy of this math luminary on Saturday, April 11, 2020, in New Brunswick, New
Jersey, USA, from complications related to COVID-19.
Nevertheless, civilization cannot be stopped by a pandemic. It created a new
normal situation—the use of online meetings to continue work from home. Classes,
meetings, conferences, etc. were ﬁnally resumed in virtual mode. During this time
(August 2020), we, some of the Indian researchers on cellular automata, took an
initiative to create a virtual platform where the people doing research in different
shades of Theoretical Computer Science, especially on Cellular Automata, can get to
know each other’s work, participate and interact in lively discussions on a common
platform. In this discourse, we started Series of Webinars on Cellular Automata
where eminent scientists over the globe in the ﬁeld of theoretical computer science,
in general, and cellular automata, in particular, joined us in enlightening dialogues.
vii

viii
Preface
As an outcome of this initiative, an informal research group Cellular Automata India
was born which now has over 130 members from all over the world.
This virtual podium also gave us a chance to think about paying homage to our
beloved John Conway in the way we desired. So, we started planning from December
2020 to organize a lecture series in memory of Conway on his ﬁrst death anniversary.
Our plan was to have weekly lectures for the month of April 2021 starting on April
10, 2021. We wanted to listen about other aspects of Conway as well as on Game of
Life and cellular automata. And, our wish was if someone close to Conway could talk
to us about his personal feelings, experience, memories, and learnings from Conway.
We approached a few of such and after some unsuccessful attempts, we got a reply
from Prof. Robert Wilson, an eminent group theorist and doctoral student of John
Conway. That letter was almost like an extract of pages from his diary through which
we were visualizing several scenes from Conway’s life. Professor Wilson interacted
with us on 10th April and it was such a fascinating event for us. We are grateful to
Prof. Robert Wilson for sharing his invaluable experience with us.
Two other speakers also benevolently agreed to give lectures the next week, Prof.
R. Ramanujam and Prof. Genaro J. Martinez. Professor Ramanujam, a renowned
theoretical computer scientist and activist, talked to us about Conway’s contribu-
tion in different ﬁelds, especially on Combinatorial Game Theory, whereas Prof.
Martinez, a noteworthy scientist in the ﬁeld of Cellular Automata, gave us a mesmer-
izing overview of Game of Life, its historical evolution through the eyes of an excel-
lent researcher. Finally, in the last week, we had among us Stephen Wolfram, a
pioneering scientist, physicist, and author of A New Kind of Science whose work
created a paradigm shift in cellular automata research. We were enlightened by the
richness of his dialogues and his experience. We are indebted to all of them for their
time, effort, and indulgence.
Duringthislectureseries,Prof.MihirK.Chakrabortyproposedtothinkofcreating
an edited book with the transcripts of these excellent talks and some invited papers.
Thanks to Springer which readily accepted our proposal to publish the book under
the series “Emergence, Complexity and Computing”. Souvik Roy, an editor of this
book, took upon himself the gigantic task of transcription for the three lectures given
by Prof. Wilson, Prof. Ramanujam, and Stephen Wolfram. We are thankful to the
three of them for checking and approving their own transcripts. The ﬁrst part of the
book contains these transcripts. Professor Martinez agreed to write a complete article
on his talk with two of his collaborators. This article is added just after the transcripts
as part of the invited articles (Part II).
Further, we invited some eminent scientists to contribute to this book. We are
especially grateful to Prof. Kenichi Morita who agreed to write for us on such short
notice and gave us an excellent research article. We also want to thank Prof. Carter
Bays, Prof. Pedro Paulo Balbi de Oliveira and his collaborators, Prof. Hector Zenil
and his collaborator for contributing to our book. One of us, Sukanta Das, has also
contributed an article. Each of the invited articles has gone through a rigorous peer-
review process as per the requirement of Springer. We are indebted to all the reviewers
for indulging our request for prompt reviews as well as their time and effort.

Preface
ix
We would like to take this opportunity to express our deep gratitude to Prof. Mihir
K. Chakraborty who ﬁrst encouraged us to take this initiative. We also thank our small
team of cellular automata researchers—Supreeti Kamilya, Sumit Adak, Sukanya
Mukherjee, Raju Hazari, Nazma Naskar, Debopriya Barman, and Biswanath Sethi
as well as the Cellular Automata India community as a whole without whose support
this book would have remained only in dreams.
Kolkata, India
February 2022
Sukanta Das
Souvik Roy
Kamalika Bhattacharjee

John Horton Conway
A Playful Master of Games who transformed Mathematics
(December 26, 1937–April 11, 2020)
John Horton Conway was a legendary mathematician who was distinguished for his
love of games and for bringing mathematics to the common people. He was one
of the most multifaceted mathematicians of the past century, a wizard, polymath,
storyteller, and a natural problem-solver whose unaided accomplishments often made
his colleagues spell-bound.
Conway became renowned during his stay at Cambridge University (as a student
and professor from 1957 to 1987). However, he claimed to never have worked a single
day in his life. Instead, “he purported to have frittered away reams and reams of time
doing nothing, being lazy, playing games”. Yet he was Princeton University’s pres-
tigious John von Neumann Professor in Applied and Computational Mathematics
since 1987 which position he held until 2013 when he was transferred to emeritus
status.
Conway received the Berwick Prize in 1971 and the Pólya Prize in 1987 (ﬁrst
recipient). He was awarded the Nemmers Prize in Mathematics (1998) and the Leroy
P. Steele Prize for Mathematical Exposition of the American Mathematical Society
in 2000. He was elected as a Fellow of the Royal Society (1981), and Fellow of the
American Academy of Arts and Sciences (1992). For his contributions, he received
honorary degrees from the University of Liverpool in 2001 and Alexandru Ioan
Cuza University in 2014 and honorary membership of the British Mathematical
Association in 2017.
Known for his playful approach, swift computation, and natural problem-solving
skills, John Horton Conway has been called a “magical genius”. For several years, he
fretted that his obsession with playing silly games was wasting his career—until he
recognized, it could steer astounding discoveries! His fascination with games gave
birth to a theory of partisan games—combinatorial game theory, which he originated
with Elwyn Berlekamp and Richard Guy. The famous book series Winning Ways for
your Mathematical Plays is an outcome of this collaboration. In fact, his book On
Numbers and Games (1976) gives the mathematical foundations of this theory. He
also developed and analyzed many other puzzles and games, such as Conway’s
soldiers, peg solitaire, Soma cube, and philosopher’s football.
xi

xii
John Horton Conway
He had the unparalleled tendency of jumping into an area of mathematics and
completely changing it. On the suggestion of John McKay, he tried to prove some-
thing about the properties of the Leech lattice and came up with the symmetry group
of Leech lattice. He contributed to sphere packing—ﬁnding the most efﬁcient way
to pack as many spheres in as little space as possible. He collaborated with Robert
Curtis and Simon P. Norton to contrive the ﬁrst concrete representations of some of
the sporadic groups, which have been named as the Conway groups. Conway and
Norton formulated the complex conjecture—monstrous moonshine which is based
on an observation (1978) by John McKay. Conway also collaborated with Curtis,
Norton, Richard Parker, and Robert Wilson in writing the book ATLAS of Finite
Groups.
In knot theory, Conway came up with a new variant of Alexander polynomial and
produced the Conway polynomial. He invented a system of notation for tabulating
knots, known as Conway notation and also developed tangle theory. In the mid-
1960s, along with Michael Guy, Conway proved that there are sixty-four convex
uniform polychora.
Inspired by Lewis Carroll’s perpetual calendar algorithm, Conway devised the
algorithm for mental calculation in 1973. His famous Doomsday algorithm can be
used to calculate the day of the week. In his ﬁnal years, he was working on theoretical
physics and also contributed in that ﬁeld. He and Simon B. Kochen proved the free
will theorem (2004), an astounding version of the “no hidden variables” principle of
quantum mechanics.
Though he made inﬂuential contributions to number theory, group theory, algebra,
geometry, topology, analysis, and combinatorial game theory, perhaps he is best
known for inventing the Game of Life, an enthralling cellular automaton-based “no-
player never-ending” game where a collection of cells continuously evolves into
new conﬁguration depending on a few very simple rules. Since the 1970s, this
Game of Life has been inspiring people from different ages to further explore the
different versions and variations of it and cellular automata in general. Its mass appeal
has created a community of engineers, mathematicians, and researchers, popularly
known as the Life community, who has been actively working on Game of Life and
its complex behavior.
Known for his boundless curiosity and zeal for subjects much beyond mathe-
matics, Conway was an adored ﬁgure in the hallways of Princeton’s mathematics
building and at the Small World coffee shop on Nassau Street, where he actively
engrossed with faculties, students, as well as any mathematical enthusiasts with
equal interest. He was an active researcher and was attached to the common room of
the mathematics department of Princeton well into his 70s. However, three years ago,
a major stroke conﬁned him to a nursing home. Even then he was regularly visited by
his colleagues until the pandemic of COVID-19 made such visits impossible which
forced him to discuss his ideas only over the phone. On Saturday, April 11, 2020, he
succumbed to complications related to COVID-19. At that time, he was 82.
We conclude with a copy of the ﬁrst email received from Prof. Robert Wilson as
a response of the invitation mail for interacting with us on Conway:

John Horton Conway
xiii
“Conway was a remarkable man. He made his own rules, and lived by them. He almost
never answered letters or emails, and rarely even read them. In the 35 years between the
time he left Cambridge, and his death, he replied to *one* of my emails. And that was only
because, after nearly 30 years of effort, I had ﬁnally “solved” a problem he had told me was
impossible.
He never talked about cellular automata. If someone mentioned the subject, he dismissed it
as history, no longer interesting. He delighted in doing the opposite of what was expected.
When introduced to someone at a party who was a mathematician, he is supposed to have
said “I was no good at mathematics at school” which is probably both true and the ultimate
put-down.
I don’t know what it is you want from me, but I can imagine that it may not be quite what
I can provide. I can tell you very little about Conway, but what he taught me about how to
approach problems, and how to ensure that you are in charge, not the problem, has never left
me.” – Robert Wilson
Sukanta Das
Souvik Roy
Kamalika Bhattacharjee

Contents
Transcript from Conway Memorial Lecture Series
John Horton Conway: A Master of All Trades . . . . . . . . . . . . . . . . . . . . . . . .
3
Robert Wilson
Two Different Directions: John Conway and Stephen Wolfram . . . . . . . .
21
Stephen Wolfram
Conway Memorial Series: The Mathematical Artist of Play . . . . . . . . . . .
73
R. Ramanujam
Invited Articles
Some Notes About the Game of Life Cellular Automaton . . . . . . . . . . . . . .
93
Genaro J. Martínez, Andrew Adamatzky, and Juan C. Seck-Tuoh-Mora
Gliders in the Game of Life and in a Reversible Cellular Automaton . . .
105
Kenichi Morita
From Multiple to Single Updates Per Cell in Elementary Cellular
Automata with Neighbourhood Based Priority . . . . . . . . . . . . . . . . . . . . . . .
139
Pedro Paulo Balbi, Thiago de Mattos, and Eurico Ruivo
Game of Life, Athenian Democracy and Computation . . . . . . . . . . . . . . . .
159
Sukanta Das
Algorithmic Information Dynamics of Cellular Automata . . . . . . . . . . . . .
171
Hector Zenil and Alyssa Adams
The Game of Life in Three Dimensions, and Other Tessellations . . . . . . .
191
Carter Bays
xv

Contributors
Andrew Adamatzky Unconventional Computing Lab, University of the West of
England, Bristol, United Kingdom
Alyssa Adams Algorithmic Nature Group, LABORES, Paris, France;
Morgridge Institute of Research and Department of Bacteriology, University of
Wisconsin-Madison, Madison, WI, USA
Pedro Paulo Balbi Faculdade de Computação & Informática e Pós-Graduação em
Engenharia Elétrica e Computação, Universidade Presbiteriana Mackenzie, São
Paulo, SP, Brazil
Carter Bays Distinguished Professor Emeritus, Computer Science and Engi-
neering, University of South Carolina, Columbia, SC, USA
Sukanta Das Department of Information Technology, Indian Institute of Engi-
neering Science and Technology, Shibpur, India
Thiago de Mattos Pós-Graduação em Engenharia Elétrica e Computação, Univer-
sidade Presbiteriana Mackenzie, São Paulo, SP, Brazil
Genaro J. Martínez Artiﬁcial Life Robotics Lab, Escuela Superior de Cómputo,
Instituto Politécnico Nacional, Mexico City, Mexico;
Unconventional Computing Lab, University of the West of England, Bristol, United
Kingdom
Kenichi Morita Hiroshima University, Higashi-Hiroshima, Japan
R. Ramanujam The Institute of Mathematical Sciences, Chennai, India
Eurico Ruivo Faculdade de Computação e Informática, Universidade Presbiteriana
Mackenzie, São Paulo, SP, Brazil
Juan C. Seck-Tuoh-Mora Area Académica de Ingeniería y Arquitectura, ICBI,
Universidad Autónoma del Estado de Hidalgo, Hidalgo, Mexico
Robert Wilson Queen Mary University of London, London, UK
xvii

xviii
Contributors
Stephen Wolfram Wolfram Research, Champaign, IL, USA
Hector Zenil Oxford Immune Algorithmics, Reading, UK;
The Alan Turing Institute, British Library, London, UK;
Algorithmic Dynamics Lab, Karolinska Institute, Stockholm, Sweden;
Algorithmic Nature Group, LABORES, Paris, France

Transcript from Conway Memorial
Lecture Series
We, on behalf of a non-institutional platform named “Cellular Automata India”,
organized a webinar series during April 2021, the month of the ﬁrst death anniversary
of John Conway to pay our tribute to the legendary mathematician. In that webinar
series, Robert Wilson, a Doctoral student of Prof. Conway and a great mathematician,
shared his memories on Conway and his working style. Stephen Wolfram, an eminent
scientist, delivered an elaborated talk in the series. R. Ramanujam (IMSc, Chennai,
India) and Genaro Juarez Martinez (Computer Science Laboratory, IPN, Mexico)
also gave talks in the series. This part of the book includes the transcript of the
ﬁrst three talks along with the various questions-answers and associated discussions.
Based on his talk, Genaro along with his co-researchers contributed an article, which
is included in the other part of this book.

John Horton Conway: A Master of All
Trades
Robert Wilson
1
A Personal Remembrance
I really only knew Conway for about 11 years from when I went to Cambridge as
a student in 1975 to when he (Conway) left Cambridge to go to Princeton in 1986.
So I’ll just say a few words about how I interacted with him in those 11 years. Of
course as an undergraduate student, I went to his lectures, I didn’t talk to him, or
interact directly with him but I went to a course he gave in the ﬁrst year, which was
an optional course, no exams, on formal logic and set theory. And then in the second
year he gave a course called Algebra III, on things like—linear maps1 and quadratic
forms2—things like that. And what I most remember about it, was the revision notes
that he provided for this course. At the end of the course, he handed out to every
member of the audience one sheet of paper. That one sheet of paper contained the
entire course including all proofs, all the examples, everything, the entire course. It
was typed on two sides of one sheet of paper and had everything in it. He worked a
lot really to get 24 lectures on to one piece of paper. And I think what inspired me
most to work with him is mostly the fourth year course he gave on sporadic simple
1In mathematics, a linear map (also called a linear mapping, linear transformation, vector space
homomorphism, or in some contexts linear function) is a mapping V →W between two vector
spaces that preserves the operations of vector addition and scalar multiplication.
2 In mathematics, a quadratic form is a polynomial with terms all of degree two (“form” is another
name for a homogeneous polynomial). For example, 4x2 + 2xy −3y2 is a quadratic form in the
variables x and y.
R. Wilson (B)
Queen Mary University of London, London, UK
e-mail: r.a.wilson@qmul.ac.uk
© The Author(s), under exclusive license to Springer Nature Switzerland AG 2022
S. Das et al. (eds.), The Mathematical Artist, Emergence,
Complexity and Computation 45, https://doi.org/10.1007/978-3-031-03986-7_1
3

4
R. Wilson
groups.3 Which was really exactly what I wanted to do, as I found it so fascinating
that I knew, I wanted to do that.
“At the end of the course, he handed out to every member of the audience one sheet of paper.
That one sheet of paper contained the entire course including all proofs, all the examples,
everything, the entire course. It was typed on two sides of one sheet of paper and had
everything in it. He worked a lot really to get 24 lectures on to one piece of paper.”
Then at the end of the fourth year, it’s a very brutal system in Cambridge, they
have the exam which is absolutely brutal. Every separate exam has three questions—
the ﬁrst question is ‘write out everything in the ﬁrst eight lectures of the course’; the
second question is ‘write out everything in the second eight lectures of the course’;
and the last question is ‘write out everything in the last eight lectures of the course’.
And you got three hours to do this. And at the end of this you were ranked, and the
ﬁrst however many people it is, however many places they’ve got, the ﬁrst so many
people can do a Ph.D. in Cambridge.
I had thought there is no way I’m going to have done well enough, but I was
‘just’ lucky enough. I was, I think, in the very bottom of the list. The same day you
have to go and ﬁnd a supervisor. So I went to Conway and I said would you be my
supervisor. I want to do sporadic groups. And he said, well you know I am not a
group theorist. And then he tried other ways of putting me off by saying well you
know many of my students never ﬁnish their Ph.D.’s. So we had a bit of a discussion
and eventually he agreed to take me on as his student. And when I started, he gave
me a few things to read which were not about group theory at all, they were all
about lattices. And I read several recent papers on lattices. And eventually I found
some groups, the lattices took me towards the groups. And they took me towards
the quaternionic reﬂection groups,4 in particular the Hall–Janko group.5 Just one of
the sporadic groups and it is contained in the Conway group6 which is related to the
Leech lattice.7 So that’s how I went towards another version of Leech lattice—the
3 In group theory, a sporadic group is one of the 26 exceptional groups found in the classiﬁcation of
ﬁnite simple groups. A simple group is a group G that does not have any normal subgroups except
for the trivial group and G itself. The classiﬁcation theorem states that the list of ﬁnite simple groups
consists of 18 countably inﬁnite families plus 26 exceptions that do not follow such a systematic
pattern. These 26 exceptions are the sporadic groups. They are also known as the sporadic simple
groups, or the sporadic ﬁnite groups. Because it is not strictly a group of Lie type, the Tits group is
sometimes regarded as a sporadic group, in which case there would be 27 sporadic groups.
4 It is a group of linear transformations in a quaternionic vector space of dimension n < ∞generated
by elements that ﬁx an (n −1)-dimensional subspace pointwise.
5 In the area of modern algebra known as group theory, the Janko group J2 or the Hall-Janko group
H J is a sporadic simple group of order 27 · 33 · 52 · 7 = 604800 ≈6 × 105.
6 In the area of modern algebra known as group theory, the Conway groups are the three sporadic
simple groups Co1, Co2 and Co3 along with the related ﬁnite group Co0 introduced by (Conway
1968, 1969). The largest of the Conway groups, Co0, is the group of automorphisms of the Leech
lattice ∧with respect to addition and inner product. It has order 8, 315, 553, 613, 086, 720, 000, but
it is not a simple group. The simple group Co1 of order 4, 157, 776, 806, 543, 360, 000 is deﬁned
as the quotient of Co0 by its center, which consists of the scalar matrices ±1.
7 In mathematics, the Leech lattice is an even unimodular lattice ∧24 in 24-dimensional Euclidean
space, which is one of the best models for the kissing number problem. It was discovered by John

John Horton Conway: A Master of All Trades
5
quaternionic version of the Leech lattice. And so I studied that. That was what my
ﬁrst paper8 was about, the group theory associated to this quaternionic Leech lattice.
Then I thought, well if there is a real Leech lattice and a complex Leech lattice, and
two different quaternionic Leech lattices, what about the octonionic Leech lattice?
what about Cayley numbers?9 I did lots of calculations and nothing worked. And
Conway said “it’s impossible”. You can’t do octonionic lattices, because they are not
associative, so there is no linear algebra, there is no lattice, nothing you can do, it’s
impossible.
Well, let me tell you another thing about Conway’s attitude towards problems.
Many supervisors will say you should work on an easy problem and on a hard
problem. So if you can’t solve the hard problem, at least you’ve got the easy problem
for backup. Conway said you should have four problems—you should have one easy
problem and one hard problem. You should also have a trivial problem. So if you
can’t do the easy problem, you can still do the trivial problem. And you should have
one impossible problem. Because if you get really lucky and you solve the impossible
problem then you’ve really made it. So you should have the four problems—from
trivial to impossible. In fact, I think, that was the version of few years before, I
perhaps got a later version that he has expanded this to six problems—you should
have, as well as trivial—easy—hard—impossible problems, you should also have
moderately easy and moderately hard in between. And he really put this into practice.
He was always working on six different things at the same time. And making work,
yes, making progress on most of them—not necessarily always the impossible ones.
“Conway said you should have four problems - you should have one easy problem and one
hard problem. You should also have a trivial problem. So if you can’t do the easy problem,
you can still do the trivial problem. And you should have one impossible problem. Because
if you get really lucky and you solve the impossible problem then you’ve really made it.”
So anyway, what I mean is how versatile he was. I didn’t make progress on the
impossible problem of an octonionic Leech lattice. And it took me 20 years, then
eventually I succeeded, working out how it had to work. At that point I thought, that
was I think in 2009, and so I thought I’d better contact Conway and tell him about
this. Now of course, Conway didn’t have an email address that he read. I mean, he
got thousands and thousands of emails, that he couldn’t possibly keep a count. So,
Leech (1967). It may also have been discovered (but not published) by Ernst Witt in 1940. The
Leech lattice ∧24 is the unique lattice in 24-dimensional Euclidean space, E24, with the following
list of properties:
• It is unimodular; i.e., it can be generated by the columns of a certain 24 × 24 matrix with
determinant 1.
• It is even; i.e., the square of the length of each vector in ∧24 is an even integer.
• The length of every non-zero vector in ∧24 is at least 2.
8 The quaternionic lattice for 2G2(4) and its maximal subgroups, J. Algebra, 77 (1982), 449–466.
9 There are two completely different deﬁnitions of Cayley numbers. The ﬁrst and most commonly
encountered type of Cayley number is the eight elements in a Cayley algebra, more commonly
known as octonions. A quantity which describes a Del Pezzo surface is sometimes also called a
Cayley number.

6
R. Wilson
anyhow, he had a secret account. So what I did was this—I emailed the ofﬁce in the
Princeton mathematics department to say—‘I’ve got something really exciting to tell
Conway, I think, he will really be interested, can you forward this email him’. So,
they did. And the next day, I got reply from Conway saying in capital letters—“I
think that is FANTASTIC”. So it took me twenty years but I got there in the end.
So, anyway, let’s perhaps go back to my Ph.D. and how I was working with
Conway for the Ph.D. I told you, he gave me these papers and said read them.
He never gave me a problem. He might have done eventually but I found my own
problems. I said about this quaternionic Leech lattice. I said I worked on the maximal
subgroup problem. The breakthrough came when, at some point in my third year I
think, Conway went on sabbatical for a month or two. He didn’t tell me before he
went he was going away. So I had a month without a supervisor. And, that’s the
time I started having talk to other people and I talked to Simon Norton and John
Thompson. And they gave me some ideas, that I was missing. So they enabled me to
actually study the Leech lattice in a deeper way than I had before and to understand
the maximal subgroups10 problem in a deeper way and make progress. And then I
eventually managed to get a postdoc after my Ph.D. I suppose the other thing that
really helped me to get a job was that I worked on the ‘Atlas of ﬁnite groups’ which
was a project that Conway started probably about 10 years before with Robert Curtis.
And getting my name on the front of that book11 was very important for my career.
What else should I say, probably I should not say so much about myself more about
Conway.
As I said I went to many of his lecture courses. And he often gave the impression,
the lectures were not prepared because he talked as though he was just talking to you
in a cafe or something. He wouldn’t talk as if he was reading a prepared script of
the lectures. And often he would say well—we could do it like this, we could do it
like that, which do you want—things like this. And later on when he gave research
seminars to audiences he would say I’ve got six talks which one do you want me to
give. And eventually I realized that it wasn’t that the talks were not prepared. They
were very well prepared. But they weren’t written down. They were prepared in his
head. And so, because they were in his head, they vary slightly from one performance
to another just like a piece of music might. Sometimes he would go off in a different
direction or do things differently and so on. He’d play the music in a different way.
That was what gave the impression of it being spontaneous. When it really wasn’t.
I just made a mistake at one point of thinking that it is possible to give lectures like
this without preparation. I very quickly found that it was not. It is quite possible to
10 In group theory, a maximal subgroup H of a group G is a proper subgroup, such that no proper
subgroup K contains H strictly. In other words, H is a maximal element of the partially ordered
set of subgroups of G that are not equal to G. Maximal subgroups are of interest because of their
direct connection with primitive permutation representations of G. They are also much studied for
the purposes of ﬁnite group theory.
11 “Atlas of ﬁnite groups” by JH Conway, RT Curtis, SP Norton, RA Parker and RA Wilson; Oxford
University Press, 1985. Reprint with corrections, 2004.

John Horton Conway: A Master of All Trades
7
go up and talk for an hour without notes and go through the subject matter but it
is absolutely essential to prepare very thoroughly. Ok, I think that’s probably about
everything that I prepared. So, what would you like to know about Conway?
2
Interaction with Robert Wilson
Kamalika Bhattacharjee: You were talking about experience of working under
Prof. Conway. He was already very famous while you went to him for your
doctoral research. So did you feel some kind of extra pressure? You said that he
had also tried to discourage you beforehand that you shouldn’t take him as a
superviser. How much pressure you felt at that time to make Conway satisﬁed
about your work?
That’s a good question. I don’t remember feeling any extra pressure I think it
was just the same with any supervisor. Also I didn’t actually know very much about
Conway. I didn’t know how famous he was for all these different things. I don’t
think I knew about the Game of Life. I didn’t know about his work on foundations in
numbers and games. I didn’t know anything about him apart from the Conway group.
He wasn’t a professor at that stage. He was just Dr. Conway. He became a Fellow of
the Royal Society while I was doing my Ph.D. And then he became a professor. By
that stage it became a bit more obvious that he was a really powerful mathematician.
It’s the breadth of his mathematics that is so impressive. Not just group theory, but
cellular automata and physics as well. He was interested in everything. And he read
an enormous amount of stuff. One of the ways he used to work, he would go to
the local coffee shop, in Cambridge and he would go there every morning for his
breakfast, and work in these noisy surroundings. And depending on what he was
working on, he would be using napkins, piece of paper, or reading books. And these
books would be about the history of important problems in mathematics, or physics,
or something else. So he was learning around the subjects all the time. Very wide
reading, so he knew an enormous amount about an enormous amount of different
things. And if you caught him in the right mood which was not difﬁcult actually he
would tell you about any of these things. If you showed interest about any of these
things, he would tell you about it. And I learned a lot that way, just from listening to
him talk, in the common room, in the bar, in the evening, he had an enormous number
of stories. Mostly mathematical, not all of it. And he taught mathematics not in a
lecture room but in the pub. I couldn’t keep up because, we would go to the pub after
the seminar, drink beer. Conway drank a lot of strong beer. After two beers, I couldn’t
keep up anymore. It was impossible. But still, I learnt a huge amount of background
material that way that I probably wouldn’t have learnt otherwise. Conway never said,
go and read that book to learn it. Instead he said, I will tell you about it. Here is how

8
R. Wilson
you do it. And he sat down for an hour and explained. It would take probably a week
to read a book. From that point of view, he was an ideal supervisor.
“And if you caught him in the right mood which was not difﬁcult actually he would tell you
about any of these things. If you showed interest about any of these things, he would tell you
about it. And I learned a lot that way, just from listening to him talk, in the common room,
in the bar, in the evening, he had an enormous number of stories. · · · Conway never said, go
and read that book to learn it. Instead he said, I will tell you about it. Here is how you do it.”
Kamalika Bhattacharjee: You said that he gave you one page content of the
whole course in your graduation year. He had this fascination about making
things very precise.
–Exactly. He was never satisﬁed with any version of anything until he had made
it as simple as possible. It had to be as simple as possible, exactly what Einstein
said. It must be as simple as possible but not more so. That was Conway’s attitude
in everything. So when he was working on a research problem, it was very difﬁcult
for the rest of us to keep up because every day he would have a new simpler version
than he had the day before. So we had to start all over again from scratch because
everything could change. And in the end if you couldn’t ﬁt it on one sheet of paper it
wasn’t worth doing. I remember one particular example, I was quite involved in this,
one of the sporadic groups, the Janko third group (J3).12 It was really the work of
Richard Parker, who was doing some computing work with this particular group. And
he discovered a new representation. So instead of having 18 dimensional complex
representations, he found a 9 dimensional representation over the ﬁeld of order 4. And
so Richard Parker proved that the Janko group is a subgroup of the unitary group,13
in dimension 9. As soon as Conway got hold of that fact, he started scribbling on
bits of paper. Now I know I can do it with 9 by 9 matrices. I want to ﬁnd these nine
by nine matrices by hand, on pieces of paper and tell you what they are. And he did
that and every day he made a change from the day before, it got simpler. Until at
the end of the day, at the end of a few days of this he had one piece of paper with
completely new notation. Conway always is inventing new notations for everything.
Completely new notation which had on one piece of paper, the entire construction
of J3. I don’t know if he ever actually published that. It appeared in the atlas but I
don’t think he published a paper on it. But that taught me a way of working that has
been very useful to me later on. For example, I told you about this octonionic Leech
lattice. I did the same thing. I said there must be an octonionic Leech lattice. Let’s
try and write it down. It took me over a month and several hundreds pieces of paper,
12 In the area of modern algebra known as group theory, the Janko group J3 or the Higman–Janko–
McKay group H J M is a sporadic simple group of order 27 · 35 · 5 · 17 · 19 = 50232960. J3 is one
of the 26 Sporadic groups and was predicted by Zvonimir Janko in 1969 as one of two new simple
groups having 21+4:A5 as a centralizer of an involution (the other is the Janko group J2). J3 was
shown to exist by Graham Higman and John McKay (1969).
13 In mathematics, the unitary group of degree n, denoted U(n), is the group of n × n unitary
matrices, with the group operation of matrix multiplication. The unitary group is a subgroup of the
general linear group GL(n, C). Hyperorthogonal group is an archaic name for the unitary group,
especially over ﬁnite ﬁelds.

John Horton Conway: A Master of All Trades
9
but each time I got a version which was simpler than the previous version. And then
I went back to the beginning and said that this isn’t simple enough, let’s simplify
it some more. And I kept going around that loop as Conway told and eventually it
was simple enough that I could not simplify it anymore. It was obviously at that
stage of Einstein’s point “of being as simple as possible but not simpler”. These two
ways of working, ﬁrst of all of having a complete range of problems from trivial
to impossible. And secondly, simplify, simplify, simplify. Never make things more
complicated, always simplify. I’ve been trying, since I retired, I’ve been trying to do
this for the group theory that exists in physics. I think this may be related to cellular
automata at some point. Because again I went back to Conway’s methods, I went
back to Einstein’s thoughts as well. And one of things Einstein said about physics
was, quantum mechanics in particular, there should be a discrete theory of quantum
mechanics. It shouldn’t be a continuous theory of Lie groups14 and so on. It should
be discrete, it should be like the Game of Life. It should be completely discrete
and completely deterministic, a cellular automaton in fact. So that’s my impossible
problem to create a ﬁnite and discrete theory of quantum mechanics. Though Einstein
wasn’t able to create it, so perhaps it doesn’t exist. If Einstein couldn’t do it, that’s
clearly an impossible problem, wouldn’t you say? But just because Einstein couldn’t
do it, I’m not going to give up. I know it’s an impossible problem. And I think I
have been preparing for it for 10 years. I’ve been working on it speciﬁcally. I haven’t
succeeded, but I have gone round Conway’s simpliﬁcation loop about 20 times now.
And it’s getting simpler and simpler every time. Not only that, each simpliﬁcation
loop has whole loads of simpliﬁcation steps on it. So it’s getting simpler and simpler.
Before too long, I may be able to write down a cellular automaton that does quantum
mechanics in the way that Einstein would have wanted it. Well no one will believe
me until I’ve ﬁnished it, the whole thing is done.
“He was never satisﬁed with any version of anything until he had made it as simple as
possible. It had to be as simple as possible, exactly what Einstein said. It must be as simple
as possible but not more so. That was Conway’s attitude in everything. So when he was
working on a research problem, it was very difﬁcult for the rest of us to keep up because
every day he would have a new simpler version than he had the day before.”
It’s no good going round this simpliﬁcation loops 19 times if it needs 20. And it’s
an impossible problem so it’s still one of my 6 problems and I divided down into
smaller problems. I am looking at some easy problems and some hard problems and
so on, and hoping that they will come together at the end of the day to make this
new theory of quantum mechanics. Well, it might not work. But, it might work. I
think it might have been another saying of Conway’s or might come from somewhere
else which Richard Parker said to me, never discount the possibility of success. In
14 In mathematics, a Lie group is a group that is also a differentiable manifold. A manifold is a
space that locally resembles Euclidean space, whereas groups deﬁne the abstract, generic concept
of multiplication and the taking of inverses (division). Combining these two ideas, one obtains a
continuous group where points can be multiplied together, and their inverse can be taken. If, in
addition, the multiplication and taking of inverses are deﬁned to be smooth (differentiable), one
obtains a Lie group.

10
R. Wilson
another words, even though your problem appears to be impossible, don’t dismiss
the possibility that you might actually be able to solve it. Anyway I’m talking too
much about my own work now.
Sukanta Das: As I have understood, when you were at Cambridge, then you
were on touch with Conway. And during that time, Conway was developing the
Game of Life which is very beautiful but very simple. So to reach to this simple
rule for Game of Life, did he use any kind of computer simulation?
No no, he did all of it on a Go board. And he experimented with lots of different
versions of the rule. Before he came up with the one that actually works in the end
he tried all sorts of possibilities.
And I didn’t see him do this but people I know did see him do it and he would spend
some days on one particular version using lots of Go stones to see what happens and
when nothing interesting happens he tried to analyze why and modify the rules to see
and try something else and he tried these possibilities until eventually, suddenly the
right one was there. Obviously this is the right one because he tried all the possibilities
and it’s the only possibility. It’s the only one that does anything interesting. In the
physical world, in the 3 dimensional version of the Game of Life, and in quantum
mechanics, it is a little bit more complicated than saying this is just alive or dead
(states). It is not much more complicated than that, it is little bit more complicated.
I recognized that each individual cell has 48 states. I’d like to simplify it below 48.
Well actually it’s really just a cube. Just imagine dividing the whole space into a
cubic lattice. Now look at each individual cube. What’s the symmetry group15 of the
cube. Well we should only be able to rotate it, we shouldn’t be able to reﬂect it. In
real space you can’t reﬂect. Well that’s a group of order 24. Now you just need to
double it to get the spin. spin up—spin down. So 48 is what you need. But you do
need 48. My previous version had 24. It didn’t work. Why doesn’t it work? Because
it’s too simple. I simpliﬁed it too much, doesn’t work. The 48 I think does. So now
you’ve just got to look at these cubes. Colour the faces like a Rubik’s cube16 so
you can tell which one’s which, and spin them. So spin up—spin down, inside and
outside, whatever you want to call it. And it seems to me that is simpliﬁed as far as
it possibly could be. But not more. So if there is a cellular automaton that works to
describe quantum mechanics, this must essentially be it. You’ve got to divide space
into cubes. Have a look at the individual cubes with these 48 different states that
each cube has. So, maybe next week I’ll be able to tell you what the 48 states are
and how to do it but this week I can’t.
15 In group theory, the symmetry group of a geometric object is the group of all transformations
under which the object is invariant, endowed with the group operation of composition. Such a
transformation is an invertible mapping of the ambient space which takes the object to itself, and
which preserves all the relevant structure of the object. A frequent notation for the symmetry group
of an object X is G = Sym(X).
16 The Rubik’s Cube is a 3-D combination puzzle invented in 1974 by Hungarian sculptor and
professor of architecture Ern˝o Rubik. Originally called the Magic Cube.

John Horton Conway: A Master of All Trades
11
“he would spend some days on one particular version using lots of Go stones to see what
happens and when nothing interesting happens he tried to analyze why and modify the rules
to see and try something else and he tried these possibilities until eventually, suddenly the
right one was there. Obviously this is the right one because he tried all the possibilities and
it’s the only possibility.”
Ville Salo: So I’m guessing that the answer is a simple ‘No’. Anyway, cellular
automata are of course the models of physical systems and other dynamical sys-
tems. These systems have connection with group theory. So I would be interested
to know whether Conway ever tried to make any kind of connections between
group theory and cellular automaton, given that he obviously knew both.
I don’t think that he did. I mean, he did study automata of very different types,
not just cellular automata. But he created a Turing machine out of anything he could.
He produced a list of eleven rational numbers which was a Turing machine. I think
he also may have done the same thing with the Game of Life. But maybe someone
else did it.
Kamalika Bhattacharjee: You were saying that whenever Conway was asked
about cellular automata, he discouraged that discussion saying it as history.
Why he used to say like that?
The point is that Conway was interested in everything. But most people only know
about the Game of Life. So when a random person wants to talk to Conway, they
want to talk about Game of Life. And he just got bored of it.
Supreeti Kamilya: Is there any impact of Life in pure mathematics?
That’s a difﬁcult question. I think the Game of Life has had such a big impact on
so many things that the answer must be yes. In some way, it may be hard to point
to any particular direct application. But the way I see it, the way of thinking that
created this game has inﬂuenced so many people. And the fact that it’s, well this is
going back to physics again with the fact that cellular automata have inspired people
to create physical theories based on it. Within pure mathematics, it certainly has an
impact in logic, in Turing machines and so on. In algebra, probably not. No, I can’t
think of anything speciﬁc.
Supreeti Kamilya: Does the Game of Life motivate you some way in your
research ﬁeld?
It inspired me in physics very much. Physics must be discrete. It must be a cellular
automaton. The question is which one, and how.

12
R. Wilson
KamalikaBhattacharjee:Hehastouchedsomanyﬁeldsandmaderemarkable
contribution everywhere. According to you, what is Conway’s biggest contribu-
tion in mathematics, and in physics?
I don’t know that I can actually choose one to be the biggest. Because he had major
impacts in so many different areas in mathematics. And to me when I was his Ph.D.
student obviously it was the Conway group and his work on the Leech lattice, that to
me was most important. But to other people, other things were more important. And
his work on knot theory17 for example was very inspirational. Numbers and games,
the foundation of numbers, how to create numbers out of nothing. It was different
from what anyone else has done. And I’m not sure that people will use it but it’s
what you can do if you think really differently from anybody else about a problem
completely from scratch without being bound by anyone else’s rules. And that’s the
same in every area that he worked on. So I was just going to say again I think his
work is important in lots of areas. You can’t say which ones are most important. It
depends on your own priorities, not on him.
“I don’t know that I can actually choose one to be the biggest. Because he had major impacts
in so many different areas in mathematics. And to me when I was his Ph.D. student obviously
it was the Conway group and his work on the Leech lattice, that to me was most important.
But to other people, other things were more important.”
Kamalika Bhattacharjee: What has been the greatest impact of him on you.
You have been telling that he taught you how to solve problems, or, how to
approach to solve problems. Whether that is the only impact he had on you,
or he touched you somehow in personal level on the simplicity of his lifestyle,
or on the way he approached problems that has impacted you in your future
research which was continued after leaving Cambridge? You were in touch with
him while he was in Cambridge. After that, how that inﬂuence carried on you,
can you tell us?
Well of course. I worked closely with him for three or four years during my Ph.D.
and less after that. After my Ph.D. I worked more or less on my own. But of course he
was always around and the way that he worked was very clear. To see him working
and how he was doing it and how he was thinking. I kind of modelled my work on the
way that he did things. Do everything for yourself. Don’t take anyone else’s word for
it. If someone comes along and says the Janko group is a subgroup of U9(2), don’t
ask which way they did it. Do it yourself. Start again from scratch. This was his
method, start again from scratch. And so that’s my method. It doesn’t work as well it
did with Conway but there is a certain amount that you can learn from the way that
other people have approached problems. But at the end of the day you have to think
17 In topology, knot theory is the study of mathematical knots. While inspired by knots which
appear in daily life, such as those in shoelaces and rope, a mathematical knot differs in that the ends
are joined together so that it cannot be undone, the simplest knot being a ring (or “unknot”). In
mathematical language, a knot is an embedding of a circle in 3-dimensional Euclidean space, R3 (in
topology, a circle isn’t bound to the classical geometric concept, but to all of its homeomorphisms).

John Horton Conway: A Master of All Trades
13
for yourself. And if there is an unsolved problem, it’s because the way that other
people thought about it isn’t good enough to solve that problem. You have to think
about it in a different way in order to solve it. That means you should not take too
much notice about how other people approached the problem. Yes, learn a bit about
about how people approached the problem. But don’t think how can I go further with
this way of thinking, but what is wrong with that way of thinking. How can I think
about the whole problem in a better way. What assumptions they are making that
are not necessary to make, or there might even be wrong assumptions. And right at
the beginning start thinking about the assumptions. Are the assumptions correct. If
not, how can we change them. The same with the Game of Life, we start with some
assumptions. You work on it, nothing happens. You go back to the assumptions,
assume something else, try again, that doesn’t work, go back to the assumptions and
change the assumptions, start again.
“To see him working and how he was doing it and how he was thinking. I kind of modelled
my work on the way that he did things. Do everything for yourself. Don’t take anyone else’s
word for it. · · · And if there is an unsolved problem, it’s because the way other people thought
about it isn’t good enough to solve that problem. You have to think about it in a different way
in order to solve it.”
Ville Salo: You mentioned that you have a cellular automaton that you’re
cooking up. Is this a reversible cellular automaton or is it in the standard cellular
automaton models under local rules? I know you don’t want to talk to people,
maybe it’s not ﬁnished but I’m just interested in whether you are talking about
the same model that Game of Life ﬁxed or it’s generalized model.
I have no idea. I don’t know anything about cellular automata.
Well as I say I’ve learned from Conway that I should learn as much of other
people’s work as I feel is necessary to learn, which is usually much less than other
people think it’s necessary to learn. And then I start thinking from scratch. Make my
own assumptions. Try it and see what works and what doesn’t. That way you really
understand why certain things that work. That said, you know it’s a lesson of life
isn’t it? You learn so much better from your own mistakes than you do from other
people’s mistakes. You can spend your life reading about other people’s mistakes and
trying to learn from them. Doesn’t work. You make your own mistakes you know
exactly why it doesn’t work. You know exactly how to put it right. You know where
the mistake is, where to concentrate on.
And this particular model, you can read as much as you like on my blog. A paper
I am writing this week, but it won’t be there till next week. Somebody said to one
of their students, don’t worry about other people stealing your ideas. If your ideas
are any good, you have to ram them down other people’s throats. In other words, if
your ideas really solve the problem, then you should not be in the mode that other
people will do it, other people won’t be interested in them, unless you ram them
down people’s throats.

14
R. Wilson
Sukanta Das: I was reading your recent blog. You began on March 15 named
amateur group theory and it was interesting and what you have mentioned and
I have seen in a recent paper. You were saying that group theory is extremely
powerful and we can understand many things of this universe of physics with
group theory. So my simple query to you as an expert of mathematics and
physics. What we understand about group theory is a study of symmetrical
systems. What do you think , that the nature and universe is very symmetrical
one and can we able to understand many things using group theory?
Yes, yes I do. I almost told you what the group is by taking a symmetric group
of a cube and taking double cover to get the spin. Well there are actually 2 double
covers so I have to tell you which one. But if you have watched my blog you already
know which is the right one. So that is the group of order 48 that I think is the key to
the symmetry of the entire universe. So I’m just trying to develop the mathematical
models to make it work, and especially comparing this particular group to what’s in
the standard model. So that’s what’s in the paper I am writing, I am trying to do.
This group of order 48, how does it compare to the group of order 64, the group
generated by the Dirac matrices or gamma matrices.18 That’s a group of order 64
which underlies the whole of the standard model of particle physics. It doesn’t do
everything but it does a lot. So I want to compare my group of order 48 with Dirac’s
group of order 64, where they differ, why they differ, which one is right. Well last
night I started thinking about this, how do I match my group of order 48 to the
Dirac group. And by the time I woke up this morning, I could see the answer, I
could see what’s wrong with the Dirac group and how this group (my group of order
48) corrects it. It’s just pure mathematics, it is just group theory, just looking at the
relations between the gamma matrices. We have to square, some of them square to
plus one, some of them square to minus one, they have to anti-commute with each
other. In one relation which is wrong, you have to swap two of the gamma matrices
in one of the relations. And then it works, then you get 3 generations of electrons.
Then you get the symmetry that actually exists in the real world.
Sukanta Das: Is the nature very symmetrical? In the nature, we see so many
asymmetries. So, can we model all these things to the symmetry?
I believe so. I’m starting at the bottom and I’m trying to work my way up.
Supreeti Kamilya: You have worked with monster groups that deals with so
many data. So can you relate monster group with cellular automata somehow?
18 In mathematical physics, the gamma matrices, { γ 0, γ 1, γ 2, γ 3 }, also known as the Dirac
matrices, are a set of conventional matrices with speciﬁc anticommutation relations that ensure
they generate a matrix representation of the Clifford algebra Cl1,3(R). It is also possible to deﬁne
higher-dimensional gamma matrices.

John Horton Conway: A Master of All Trades
15
I don’t think so. The monster19 is of course an extremely interesting group and has
connections to all sorts of parts of mathematics. Some people say it has connections
to physics. I don’t think it has any connections to physics. But one of the important
things that Conway did of course was the work on monstrous moonshine (moonshine
theory)20 which was happening at the time when I was a Ph.D. student, and which
was connecting the monster group and its character table, and its representation
theory with some analytic number theory, which is a completely different subject
and shouldn’t have been connected at all. And yet, they are connected. So this is an
extremely important connection between two different parts of mathematics.
What it means for physics, I think it means nothing to physics. But there are still
people who think it does have some impact on physics. And I think it’s the cellular
automata that describe physics, not the monster. And that there is no connection
between the monster and cellular automata. And therefore there is no connection
between the monsters and physics. That’s my opinion.
Souvik Roy: So my question to Prof Wilson, both as a mathematician and
a musician also. So, I am speciﬁcally a researcher of cellular automata, I’m
very much interested in the beauty of cellular automata and pattern generated
by it, as a art form. Also, many people work on music generation by cellular
automata. So, other ﬁelds of mathematics have also been used in music and
other art formation. And, also a topic of research, algorithmic art has been
developed in last decade. So, as a mathematician and musician, I want to know
your opinion on the impact of mathematics in music and art.
Well, when I was younger I used to look at some of these things and try and use
mathematics, to analyze music or to write music, something like that. I think that’s
the wrong way to look at it. Now, I ﬁnd that, as a western classical musician, my
training is very mathematical. Training to play the notes. You have to play one note
after another, you have play it in the right order, you have play in the right speed.
Very very mathematical technique.
But you completely forget that there is music. One of my friends who plays the
double bass, in the orchestra, said to me one day when he started to play in a jazz
band. I think being trained as a classical musician, the other people of the band said
to him, you play the notes, but you’re not playing the music. I think that art or music,
it’s about the soul, it’s not about mathematics. So I play music rather differently from
how I did when I was younger. And it also partly relates to learning this kora, I found
a teacher in Birmingham, an African who plays this who learnt it when he was a
19 In the area of abstract algebra known as group theory, the monster group M (also
known as the Fischer-Griess monster, or the friendly giant) is the largest sporadic sim-
ple group, having order 246· 320· 59· 76· 112· 133· 17 · 19 · 23 · 29 · 31 · 41 · 47 · 59 · 71
= 808, 017, 424, 794, 512, 875, 886, 459, 904, 961, 710, 757, 005, 754, 368, 000, 000, 000 ≈8 ×
1053.
20 In mathematics, monstrous moonshine, or moonshine theory, is the unexpected connection
between the monster group M and modular functions, in particular, the j function. The term was
coined by John Conway and Simon P. Norton in 1979.

16
R. Wilson
child and he taught me some of it. And again, I’m trying to analyze it mathematically
and it doesn’t work. Doesn’t work mathematically. It has to be played as music. I
think that’s why he’s frustrated with me as a player because I want him to teach me
the notes. For him it’s not about the notes. It’s about the music. And in that tradition
of music actually, it doesn’t really matter what notes you play. Apart from a few
basic rules. It’s more about your imagination and what you feel and how you want
to express yourself. Well this kind of mathematical music seems to be fashionable
these days. But I don’t ﬁnd any music at all, just mathematics. That’s my view.
“I think that art or music, it’s about the soul, it’s not about mathematics.”
Mihir K. Chakraborty: I had a query about Prof Conway’s philosophical atti-
tude towards mathematics. Actually we all know that he gave different inter-
pretation to numbers. In game theory interpretations and so on, that’s fantastic.
And Prof Wilson, what do you say about his philosophical position about the
ontology of mathematics. Because if numbers are interpreted differently then
what remains then? Was he really “realist” in mathematics? If there are differ-
ent interpretations possible, then how you will account for that? Overall, what
was his attitude towards the philosophy of mathematics?
I actually don’t know. He was doing mathematics, or rather he was playing math-
ematics. It was a game to him.
Mihir K. Chakraborty: So, if one plays mathematics, he doesn’t look for truth.
I suppose that’s right, yes. It is an interesting game, a useful game, that’s the point.
Mihir K. Chakraborty: May be useful, may not be useful sometimes but it
is a game after all. I mean if somebody accepts that it is a game. I would like
to know what was Prof Conway’s attitude towards that. For instance Godel’s
incompleteness theorem. Did he ever comment on this incompleteness or things
like that.
Not to me. I don’t remember him ever talking about things like that. I don’t think
he really found them that interesting. It wasn’t the right sort of game for him. It was
some kind of restriction on what sort of games you can play. But Conway was just
interested in playing the games.
Mihir K. Chakraborty: But you mentioned at the beginning of the lecture that
you attended one of his logic courses. What was his attitude towards logic when
he was introducing logic. Do you remember?
Well I was very young at the time, a ﬁrst year student.
I mean he taught a syllabus. There were things that you are supposed to teach
and he taught what he was supposed to teach and so he taught the formal system of

John Horton Conway: A Master of All Trades
17
set theory, starting from the empty sets and building the various · · · , I forget. But
it was the standard theory of building the entities from the empty set. I never took
much interest in it myself but he taught something like how to build set theory out
of nothing. That’s what you are taught. But I didn’t get any sense of any attitude that
he might have had towards these things. He was just teaching what he had to teach.
Mihir K. Chakraborty: Another question about what you remark about
physics that things should be discrete, discretized in any case, as I understand.
But on the other hand, our feeling about world, for example space and time—
two fundamental things, is continuous, and Zeno’s paradox21 is still there in our
head, we can not remove at all. So how do you account for that physics should
be discrete but reality is continuous.
I don’t think reality is continuous. I think that continuous reality is an illusion. If
you take a large enough number of small enough things it appears to be continuous.
And so one of the things that I’ve been thinking hard about for a year or so is how does
the appearance of continuity in our world arise from something that’s fundamentally
discrete.AndI’vecometotheconclusionit’stherepresentationtheoryofﬁnitegroups
that does this. The discreteness comes from the ﬁnite group itself, the spin group
on the cube. And the continuity comes from taking the representation theory over
real numbers. So when you measure things, you are not measuring the actual cube.
You’re measuring continuous things—your cube is embedded in an environment and
it is the environment that gives you the illusion of continuous variables. It’s like the
demonstration we saw earlier of the Game of Life. If you take a big enough model,
you can’t see the individual squares anymore. It starts to look continuous and it starts
to look like life. And the same thing works in physics and in general.
“I don’t think reality is continuous. I think that continuous reality is an illusion. · · · There
is no duality between the continuous and the discrete. · · · My philosophy is, that general
relativity and particle physics are not contradictory. They are simply two different ways
of looking at what is actually the same thing. The continuous version of general relativity
and the discrete version of quantum mechanics are actually the same thing. That’s what I
believe.”
Mihir K. Chakraborty: What you say seems like the Buddhist ontological
position that we live through existence in moments. So discretized existence in
moments. That is one Buddhist standpoint. They don’t believe in continuity, on
the other hand the other thinkers, they consider continuity more fundamental
and discretization is only our way of knowing it as much as possible. Taking
a position in one of two is okay but if you claim that continuity as such is an
illusion, the maybe people will differ.
21 Zeno’s paradoxes are a set of philosophical problems generally thought to have been devised by
Greek philosopher Zeno of Elea (490–430 BC) to support Parmenides’ doctrine that contrary to
the evidence of one’s senses, the belief in plurality and change is mistaken, and in particular that
motion is nothing but an illusion. It is usually assumed, based on Plato’s Parmenides, that Zeno
took on the project of creating these paradoxes because other philosophers had created paradoxes
against Parmenides’ view.

18
R. Wilson
Well I think the Buddhist philosophy is very revealing here. Especially, that the
duality between the continuous and discrete is an illusion. There is no duality between
the continuous and the discrete. They are the same thing. I take it as a very Buddhist
point of view. And that’s my attitude to physics. Whether there is a contradiction
between the standard model of particle physics and general relativity, it’s a dualist
attitude. On the one hand we have got the standard model of particle physics which
is a kind of discrete model. On the other hand we got this continuous model of
gravity and relativity and they don’t ﬁt together. Well. My philosophy is, that general
relativity and particle physics are not contradictory. They are simply two different
ways of looking at what is actually the same thing. The continuous version of general
relativity and the discrete version of quantum mechanics are actually the same thing.
That’s what I believe. That’s what I’m working towards. So call me a Buddhist if
you want to. I think I probably am.
R Ramanujam: Conway talked about many many problems, but I’ve never
seen him talking about complexity theory (P-NP question). So, I wanted to know
if he had considered problems on computationally hard problems, lower bound
etc. What is your own views on that?
He must have mentioned it—I don’t really remember where actually.
R Ramanujam: I remember, a remark in an interview where he said that we
don’t know how to prove things to be hard and we don’t have techniques but by
the time we do it, it will be just a footnote. It was an intriguing comment in the
middle of many things. I don’t know if he had said anything else on complexity
theory in anywhere else.
Well as I said, I don’t really know what he thought about that sort of thing. Sorry.
“We don’t know how to prove things to be hard and we don’t have techniques but by the
time we do it, it will be just a footnote.”
Sumit Adak: Is there any relation between monster group and Galois group.
It is known is that the monster group is a Galois group22 over the rationals.
That’s known. But more than that, I don’t know. I am afraid I rather lost touch with
mathematics in the last few years. I am doing physics nowadays. I know that people
still want me to work on the monster, but I’ve lost interest in it.
“He was interested in one thing for a period of time and then he moved on to something
else. So he was interested in group theory when he was in Cambridge. And as soon as he
22 In mathematics, in the area of abstract algebra known as Galois theory, the Galois group of a
certain type of ﬁeld extension is a speciﬁc group associated with the ﬁeld extension. The study of
ﬁeld extensions and their relationship to the polynomials that give rise to them via Galois groups is
called Galois theory, so named in honor of Évariste Galois who ﬁrst discovered them.

John Horton Conway: A Master of All Trades
19
left Cambridge he completely lost interest in group theory. He never really did any group
theory again after that.”
I think in some ways Conway was rather the same. He was interested in one thing
for a period of time and then he moved on to something else. So he was interested
in group theory when he was in Cambridge. And as soon as he left Cambridge he
completely lost interest in group theory. He never did any group theory again after
that. And he was very much inﬂuenced by who is around him and who he talked
to and what problems other people had and how he could help with these other
problems.
Sukanya Mukherjee: Just one more question Sir. Actually nowadays we are
ﬁndinglargegroupofresearchersaredoingthereresearchindomainofmachine
learning and data science. We are not ﬁnding mathematical development nowa-
days. Mainly it is data driven kind of things. What’s your views on that?
I have no interest in data science at all. I don’t count it as mathematics.
Robert Wilson is a retired Professor in Algebra and Combinatorics, in the School of Mathe-
matical Sciences at Queen Mary University of London, 2004−2016 from whre he took his early
retirement at the end of 2016. He has done his B.A., M.A., Ph.D., and was a Rouse Ball Student
from Trinity College, Cambridge, 1975–1983. His doctoral advisor was Prof. John Conway.
His research is mainly in ﬁnite group theory, and related areas such as representation theory,
some aspects of combinatorics, and computational techniques and algorithms applicable to ﬁnite
groups. He is best known for his work on classifying the maximal subgroups of ﬁnite simple
groups and for the work in the Monster group, a group with 808017424794512875886459904961
710757005754368000000000 elements.
He started his career as Research Fellow, Jesus College, Cambridge, 1983–1986, followed by
Ofﬁcial Fellow and College Lecturer, Girton College, Cambridge. 1986–1987 and Lecturer, Senior
Lecturer, Reader and Professor, The University of Birmingham. 1987–2004.
Prof. Wilson is also an accomplished violin, viola and piano player, having played as the prin-
cipal viola in the Sinfonia of Birmingham. Due to a damaged ﬁnger, he now principally plays the
kora.

Two Different Directions: John Conway
and Stephen Wolfram
Stephen Wolfram
1
Conway—The Mathematical Engineer
This is, I gather, part of a series honoring John Conway, who I knew fairly well. I
think we were interested in many of the same things, but often for different reasons.
I remember at some point being very curious about the origins of the Game of Life
cellular automaton, and I spent several hours on the phone with John Conway—
drilling and drilling and drilling, “Why did you come up with this? What are you
doing?” And he kept on explaining it was a game, it was this, it was that. Eventually, I
think I wore him down. And he explained that the real point was he had recently been
hired as a professor of logic, which was not his primary ﬁeld. His primary ﬁeld had
been number theory. And he wanted to do something interesting in the ﬁeld of logic,
and so he wanted to ﬁnd a good enumeration of the recursive functions. And that was
what led him to start studying things like cellular automata. And I was like—that’s
really interesting, that’s much more interesting than—that was something to do with
some game with Go pieces and things like that.
I remember at some point being very curious about the origins of the Game of Life cellular
automaton, and I spent several hours on the phone with John Conway – drilling and drilling
and drilling, “Why did you come up with this? What are you doing?” And he kept on
explaining it was a game, it was this, it was that. Eventually, I think I wore him down. And
he explained that the real point was he had recently been hired as a professor of logic, which
was not his primary ﬁeld. And he wanted to do something interesting in the ﬁeld of logic,
and so he wanted to ﬁnd a good enumeration of the recursive functions.
But his motivations were rather different from mine. I think one of the places
where but, nevertheless, he was interested in the question of how simple rules—
what simple rules can do. And particularly in ﬁguring out what can you make with
simple rules. And so that led him to cellular automata, led him to various kinds of
S. Wolfram (B)
Wolfram Research, Champaign, IL, USA
e-mail: s.wolfram@wolfram.com
© The Author(s), under exclusive license to Springer Nature Switzerland AG 2022
S. Das et al. (eds.), The Mathematical Artist, Emergence,
Complexity and Computation 45, https://doi.org/10.1007/978-3-031-03986-7_2
21

22
S. Wolfram
number theoretic systems, led him to various sorts of generalizations of the 3n + 1
problem,1 and more kinds of things like this.
His goal, I think, was always, in a sense, a goal of mathematical engineering in
some sense. To ﬁgure out, given these rules, what could you make from them? Not
what would they naturally make, not if they were the rules for some system in nature
what would they do, but what with the cleverness of a human could you make those
rules do? And what I think is ultimately one of the most interesting things about
the Game of Life—maybe I’ll talk about this a bit more—is what it tells us about
what humans can make from mathematical structures, what humans can make from
simple programs—I think different from my interests, which have been primarily
what can simple programs do themselves.
What I think is ultimately one of the most interesting things about the Game of Life... is
what it tells us about what humans can make from mathematical structures, what humans can
make from simple programs – I think different from my interests, which have been primarily
what can simple programs do themselves.
Maybe I should say a little bit about both of those directions. I would say the
thing which I have been remiss in actually following up on—but to me the Game
of Life is the best example we have of meta engineering. What do I mean by that?
In the Game of Life, you have these simple rules, you know the gliders2 and things
like that sort of arise fairly randomly easily from soups of initial conditions. But we
also know that in the 50 years that the Game of Life has been out and about, people
have managed to construct all kinds of amazing structures. What’s been interesting
is I started a few years ago to catalog all these structures that have been produced in
50 years. By this point, people are able to make elaborate kinds of prime generators
and computers and all kinds of things in the Game of Life using huge structures.
And every so often, every few years, there’s been an innovation made. You know,
how to get streams of gliders to be deﬂected in this way or that way—these kinds
of things. What’s interesting about that is the same thing has happened in physical
engineering.
When we look at microprocessor design, for example, there’s been for a long
time Moore’s law3 out and about and in operation, that you know, every 18 months
or something, the speed of computers was doubled. Why was that happening? It
1 The 3n + 1 problem (Collatz conjecture) is a conjecture in mathematics that concerns sequences
deﬁned as follows: start with any positive integer n. Then each term is obtained from the previous
term as follows: if the previous term is even, the next term is one half of the previous term. If the
previous term is odd, the next term is 3 times the previous term plus 1. The conjecture is that no
matter what value of n, the sequence will always reach 1.
2 In a cellular automaton, a glider gun is a pattern with a main part that repeats periodically, like
an oscillator, and that also periodically emits spaceships. There are then two periods that may be
considered: the period of the spaceship output, and the period of the gun itself, which is necessarily
a multiple of the spaceship output’s period.
3 Moore’s law is the observation that the number of transistors in a dense integrated circuit (IC)
doubles about every two years. Moore’s law is an observation and projection of a historical trend.
Rather than a law of physics, it is an empirical relationship linked to gains from experience in
production.

Two Different Directions: John Conway and Stephen Wolfram
23
was happening because of all sorts of engineering advances. We can ﬁgure out this
particular detail of how these gates can be combined to make this thing or that thing,
whatever else, but these were details of engineering, which are dependent on the
physics of semiconductors. But what we see in the Game of Life is a very pure
play example of that. How does something, how does engineering and its purest
form advance over a period of 50 years? How do innovations and engineering—at
what point is a paradigm shift in engineering? Does it happen? And at what point
is a particular discovery made that then has a big fan-out of consequences? What is
the ﬂow of the process of engineering? So I started to analyze this, and I started to
try to understand to what extent there were things like Moore’s law. To what extent
something like Moore’s law might be a universal law of meta engineering, as opposed
to just a detailed law of the properties of semiconductor engineering. I didn’t ﬁnish
that study, but maybe I’ll talk about that a little bit more later. But to me, that’s what
you get from this kind of mathematical engineering now.
2
Program as Model for the World
Another thing that I’ve been more interested in is given these simple systems, just
ﬁnd out what they naturally do. Look at all possible cases and ﬁnd the behavior for
these kinds of systems. And the way that I came to this rather differently from the
way John Conway came to this was in trying to do natural science. In natural science,
what you’re interested in, you look at what happens in nature, and you ask, “What
is the essence of what’s underneath? What’s happening in nature?”
For that, you try to make models of the natural world. About three hundred years
ago, there was this big advancement: to use that, the idea that you could use math-
ematics to make models of the natural world. And that’s what led to the advances
of physics and all those kinds of things over the course of several hundred years.
So back in the beginning of the 1980s, I had been working in physics and so on.
And I got interested in this general question of how does nature make complicated
things. And that question is one that the traditional mathematical methods of physics
don’t really tell me much about—they don’t really tell me anything about that. So the
question that I asked is, how can we generalize this idea of making formal models
of things, which is an essential idea of theoretical science that you have the natural
world and you can make a formal model—a model that is just an abstract model of
the natural world. Well, how can we generalize the idea of making abstract models
out of the speciﬁc domain of mathematics to something else? So I realized that one
could start to think about programs as models for the world. So then the obvious
question is, okay, if we think that there are programs that are models of the natural
world, then what do simple programs typically do? What is the natural history of sim-
ple programs? What’s out there in the computational universe of possible programs?
And that got me into studying the experimental investigation of the computational
universe: I viewed my efforts as being like this: There’s this computational universe
out there of all possible programs. Let’s turn our computational telescope out there,

24
S. Wolfram
and see what’s going on out there. That led me to start looking at cellular automata.
The standard setup, which I think you probably all know about, uses a set of black
and white cells. I came to cellular automata sort of independently—I knew about the
Game of Life, but I came to cellular automata actually myself as an effort to simplify
the theories of nature.
So back in the beginning of the 1980s, I had been working in physics and so on. And I got
interested in this general question of how does nature make complicated things. And that
question is one that the traditional mathematical methods of physics don’t really tell me
much about, they don’t really tell me anything about that.... So I realized that one could start
to think about programs as models for the world.... That led me to to start looking at our
friends cellular automaton.... I came to cellular automata independently – I knew about the
Game of Life, but I came to cellular automata actually myself as an effort to simplify the
theories of nature.
Actually, I had two models that I was trying to achieve. I was trying to study
two things: self-gravitating gases and neural networks. And it turns out cellular
automata are good models for many things, but those are two things for which they
are profoundly bad models. But nevertheless, what I was interested in was taking
models that I knew about a natural science and drilling down to what were the
essential primitives underneath these models. And I had the experience, I had built
the pre-version, sort of the idea of languages, to have this computational language
that can represent things in the world computationally. And kind of what we need to
build such a language is to sort of drill down from things in the world and ﬁgure out
what their sort of underlying computational primitives are, so that was what I was
trying to do. For models of nature, also drilling down what were the fundamental
primitives. So I came up with these things which I later discovered were called one-
dimensional cellular automata. Then I very quickly realized that’s the same thing as
the Game of Life in two dimensions.
Now, the typical situation here in cellular automata, we just have a line of cells.
Each one is black or white. And we have a rule here that says given each cell,
what value will you get on the next step based on the neighbors of that cell? So the
thing that is probably here everybody knows well. You can just start enumerating
all these possible rules, and many of them do very simple things. Some make nice
nestedpatterns. Someyoucaninterpret usingtraditional mathematics, as youknow—
binomial coefﬁcients may do things like that. My all-time favorite is rule 30 here
(see Fig.1).4 And this is what it does. There’s its rule started off with just one
black cell, continue it, and here’s the result you get. And for me, this was my little
personal Galileo moment, so to speak, of look at, you know, turn the telescope to
the computational universe and see something extremely surprising. Because, for
me, this was intuitionally very unexpected that such a simple rule could produce
such complicated behavior. It’s a little different again, it’s a different objective than
what one was seeing in something like the Game of Life, where we can construct
these things which follow these rules and manage to do something complicated like a
glider gun or some such other thing. But for me, this was something very surprising,
4 Rule 30: 111 →0, 110 →0, 101 →0, 100 →1, 011 →1, 010 →1, 001 →1, 000 →0.

Two Different Directions: John Conway and Stephen Wolfram
25
Fig. 1 Dynamics of rule 30
starting from a single black
cell
Fig. 2 Localized structure
of class IV cellular automata,
rule 110.
and what I realized is there’s a fundamental principle about what happens in the
computational universe. That simple programs don’t necessarily have to produce
simple behavior. And, so I started looking around the computational universe that
different kinds of programs, whether they’re cellular automata or other kinds of
things—I started looking at Turing machine, a register machine, recursive functions,
even things like partial differential equations. Let’s sample the universe of possible
such systems: you quickly discover that many of these systems don’t show very
complicated behavior. So it’s something we weren’t aware of. Because in traditional
science, we tended to, for example in doing engineering, we always wanted to build
systems where we could see what was going to happen. We didn’t want a system
where some very complicated thing would happen. We want a system where we can
readily predict what’s going to go on.
So, many different things that you see in cellular automata: it is a typical one-
dimensional cellular automaton, one of my class IV cellular automata. That has the
feature that it generates these localized structures (Fig.2). It’s interesting; there’s in
one-dimensional cellular automata, if you do something, this is the Game of Life,
and this is a spacetime slice through the Game of Life, and you see (Fig.3), that
actually the same phenomena of these localized structures are being produced, so

26
S. Wolfram
Fig. 3 Game of Life and
one-dimensional cellular
automata
the same thing that you see in one-dimensional cellular automata. Although it’s a
little easier to understand what’s going on in one-dimensional cellular automata,
what you see is this spacetime behavior. So you can go, and one thing that happens
in these one-dimensional cellular automata is that you can, for example—look, you
can start saying what are all the possible structures that are produced. You just go
and look experimentally. And what possible structures are generated are sometimes
things that are just periodic, sometimes they move. But then what very often happens
is they’ll be a surprise, so in this case, there’s a surprise. It’s kind of a glider gun thing
that produces an inﬁnite growth pattern from simple initial conditions (Fig.2). Here’s
a case where you might have thought this particular cellular automaton was always
going to be some very elaborate kind of sort of organic-looking thing, but actually
for a sufﬁciently large initial condition, you suddenly get this very boring behavior.
So, in any case, the things you start realizing when you explore this computational
universe of possible programs is even though the programs are simple, the behavior
can be very complicated.
3
Computational Equivalence
The question then is that sort of studying the natural history of these things, like one
might visit lots of different islands and ﬁnd lots of different animals and plants and
so on? The question is what general principles can one ﬁnd that just described these
kinds of systems? So, the most important general principle that I came up with for
this thing, I call the Principle of Computational Equivalence. And it has to do with the
question, “How do we characterize what’s happening in a system like this?” Well, we
can think about a system like this as doing a computation. It starts off from some initial
condition here, and then it progressively successively applies these rules, generating
some output. We can think of that process of generating output as being like the doing

Two Different Directions: John Conway and Stephen Wolfram
27
of computation. So then the question is how sophisticated is that computation? Is
that computation something where simple rules produce simple computations, more
complicated rules make a more complicated computations, and so on. The thing
which I realized is—that I call the Principle of Computational Equivalence—that
says as soon as you’ve got above a very low threshold, you immediately get systems
that can do computations that are as sophisticated as anything. So what that means
is when you have a system that isn’t obviously trivial behavior, that system will be
capable of universal computation.
Actually, there’s a place where John Conway and I differed. It was very strange
because when I ﬁrst met John Conway in the early to mid-1980s, I was talking about
these precursors of this principle. And he was like, no, it’s not true, you have to
go through a lot of effort, you have to do this mathematical engineering to create a
system that is capable of universal computation. And I’m like, look, I think these
things are just always going to be capable of universal computation. In later years,
and a not-uncharacteristic move of John Conway, he forgot what he said before and
thought that he’d said the opposite of what he said before. But it was interesting that
he took the point of view that universal computation is a special thing and you won’t
get to it with typical simple rules.
Well, we have now at least two very nice pieces of evidence for the Principle
of Computational Equivalence from one-dimensional cellular automata. There’s a
nice rule 1105 cellular automaton; this one is computation universal. It’s one of the
simplest cellular automata.
[W]henIﬁrstmetJohnConwayintheearlytomid-1980s,Iwastalkingabouttheseprecursors
of this principle. And he was like, no, it’s not true, you have to go to a lot of effort, you
have to do this mathematical engineering to create a system that is capable of universal
computation. And I’m like, look, I think these things are just always going to be capable of
universal computation.... But it was interesting that he took the point of view that universal
computation is a special thing and you won’t get to it with typical simple rules.
A number of years ago, I looked at Turing machines. And I just enumerated all
possible Turing machines and asked the question, given all those possible Turing
machines, what’s the simplest one that could conceivably be universal that has just
two states and three colors?6 And I put up a prize for somebody to prove or disprove
that this was universal. And the young child called Alex Smith showed that, in fact,
this Turing machine is universal. So, it’s another piece of evidence for this Principle
of Computational Equivalence that any system that is obviously simple in its behav-
ior will turn out to be as computationally sophisticated as it could be. It has many
implications about understanding the prevalence of undecidability of systems and
so on. One of the fundamental implications is a phenomenon I call computational
irreducibility. One of the questions that you could ask about a system like this is,
given that you know the rules and you know the initial condition, just tell me what’s
going to happen a billion steps in the future. And in traditional mathematical science,
5 Rule 110: 111 →0, 110 →1, 101 →1, 100 →0, 011 →0, 010 →1, 001 →1, 000 →0.
6 “The Wolfram 2, 3 Turing Machine Research Prize” (https://www.wolframscience.com/prizes/
tm23/).

28
S. Wolfram
one can use the idea, the achievement of mathematical sciences, to make predictions,
to be able to say, “We can jump ahead, we don’t need to follow each step, we can
just say after a million steps what’s going to happen.” But the point of computational
irreducibility is that in general, common phenomena of the computational universe,
you can’t do that. There’s no better way to ﬁnd out what the system will do than
essentially just by following each step by applying this rule. And, in a sense, you can
understand why that’s the case, by thinking about the Principle of Computational
Equivalence, because if we are observers, predictors of the system and if we want
to predict the system, we’re trying to outrun the system, we’re trying to be smarter
about the computation system itself is, but the Principle of Computational Equiva-
lence tells us that our brains, our computers, our mathematics and so on, is really no
more computationally capable than the simple system itself. And so that’s why we
can’t expect to outrun the system, why the system must show computational irre-
ducibility. So, there are all sorts of implications for understanding the natural world,
for understanding what it takes to do various kinds of engineering and so on. But
maybe I should talk a little bit about a couple of other things here ﬁrst.
One direction is talking about—so what can you do with these simple programs?
What kinds of things can you, for example, reproduce in the natural world? I was
interested when I was writing my big New Kind of Science book; I started exploring
all different systems, understanding the growth of snowﬂakes, or understanding ﬂuid
dynamics, or understanding biological growth processes, or ﬁnding even things like
cellular automata printed out on the shells of seashells from the dynamics of their
biology and so on. One of the things that I was interested in is whether we can
make these models of the natural world, we can capture the essence of how lots of
things in the natural world get produced, what about our whole universe, what about
fundamental physics. Can we use this idea of simple programs to actually make a
model of the fundamental physics of our universe? I certainly talked to John Conway
about this, and we didn’t see eye to eye entirely on that topic, either. I think John did
some work in recent years on quantum mechanics which I don’t think was really in
the right direction. But the idea that of trying to understand what simple programs
can do, that’s an important theme and that’s something that we both shared, although
with somewhat different objectives.
4
Cellular Automata and Physics
So one of the ultimate questions on “what can simple programs do” is, could our
whole universe be made from some simple programs? To think about that, in the
universe, we need the most prominent features of the universe of things like space
and time. In a cellular automaton, we’ve already decided how space and time work.
In a cellular automaton, we have a deﬁnite set of cells laid out in space; in a series of
steps, they evolve in time. So, in the sense of cellular automata, we’ve already locked
in how space and time work. But let’s ask the question: how does space and time
work in the actual universe? What might be underneath space and time in our actual

Two Different Directions: John Conway and Stephen Wolfram
29
Fig. 4 Rule {{x, y},{x, z}}→{{x, y},{x, w},{y, w},{z, w}}. The results for 10 steps
universe? You know, it’s funny to ask about what’s underneath space, for example,
because, in a sense, in the history of mathematics, we haven’t thought about space
being made of anything. We’ve just thought about space as being a background
in which things operate. I mean, from Euclid on, we just thought of space as this
manifold, where we could just say there’s a position here in space and there’s another
position here in space, we can discuss what happens and so on. But the question of
what space is wasn’t really addressed.
And you could say the same thing about material substances like water or some-
thing. For a long time, people didn’t know what water was. They just thought it was a
thing and it had certain properties and so on, but then, 150 years ago, people realized,
yes, water is actually made of something. It’s made of discrete molecules bouncing
around. But for space, we hadn’t come to that conclusion. We still thought of space
as being this kind of mathematical background in which physics operated. So, one of
the things that I started thinking about in the 1990s, actually, was what could space
be made of. And so what I ended up with was the idea that space is just made of a
bunch of discrete elements and all you know about those discrete elements is how
they’re connected to each other. So you can think about this as atoms of space, like
disembodied geometrical points, and the only thing we know about them is how they
are connected to other points. For example, we might have something where we can
represent atoms of space as nodes, and we can make a graph—or actually, it’s more
convenient to make hypergraphs, that show the relations between these elements,
these atoms of space. So then if that’s what space is made of, how does time work?
Well, you can imagine doing something a little bit like what you’re doing in a
cellular automaton, you can say whenever we see a particular pattern—particular
collection of atoms of space arranged in a certain way with certain connections will
transform them into something else. Let’s say, we have a rule {{x, y},{x, z}}→
{{x, y},{x, w},{y, w},{z, w}} (Fig.4). So you can just apply that rule and you can
say what does that do, starting with this initial condition and you see it makes some-
thing like this (Fig.4). And you see again that it’s very typical that even from very

30
S. Wolfram
Fig. 5 Rule {{x, y, y}, {z, x, u}} →{{y, v, y }, {y, z, v}, {u, v, v}}
Fig. 6 Rule {{x, y, z}} →{{x, u, w}, {y, v, u}, {z, w, v}}—a recognizable fractal kind of thing
simple rules, very simple initial conditions, just like cellular automata, just like rule
30 you get these very elaborate structures produced.
Now the question is, what is that? What is the limiting form of that structure?
What does it do in the end? And you can—just like cellular automata—you can look
at the exotic zoo of different possibilities. But sometimes you get some clues, like
here’s an example of a particular rule, that’s another one of these very simple rules.
There’s the speciﬁcation of the rule {{x, y, y}, {z, x, u }} →{{y, v, y}, {y, z, v},
{u, v, v}}. This is what that rule does when you just keep applying it, and if you
keep applying it long enough, you see it’s forming this thing (Fig.5). So remember
what I’m showing here is just graphs, and there’s nothing that’s predeﬁned about
the positions of nodes in this graph. It’s all that we know about—is how they’re
connected, and the layout is just for the convenience of the human observer. So what
we see here is that that particular rule effectively knits a two-dimensional manifold.
It knits something which limits to two-dimensional Euclidean space.
So the ﬁrst question is, given these simple rules, what kinds of space can they
make? We can characterize things: if we take a given connectivity of nodes, we

Two Different Directions: John Conway and Stephen Wolfram
31
can draw them in lots of different ways. But we can try and ﬁnd a more robust
characterization. For example, we can say, “What’s the effect of dimension of the
limiting space that we get?” And we can measure that by just saying, “Start from a
given node, and just go R nodes away from that node in the graph. How many nodes
do we get?” We build a Z D sequel of nodes, and we just ask how rapidly does that Z D
sequel grow with our nodes. So, in general, we’re in something which is behaving
like two-dimensional space. It’ll go like R2; three-dimensional space will go like R3.
In general, we can say it grows like order of the D (dimension). We can say, that
gives us a characterization of the effect of dimension of this limiting structure built
by applying these simple rules. We can actually make measurements of these things,
so we can just ask, “How big does this Z D sequel get?” We can measure dimension.
We could say, for example, this is an example of a rule {{x, y, z}} →{{x, u, w},
{y, v, u}, {z, w, v}} (Fig.6) that makes a recognizable fractal kind of thing, and we
can measure the dimension there and ﬁnd out its standard fractal dimension, and so
on. So, this gives us a characterization of what this limiting space looks like. Now,
in fact, there’s a little bit more that we can get out of it. Just by saying “what’s the
dimension”, if we look at the growth rate of this Z D sequel, the leading term is out of
the D as a subleading term, which depends on the curvature of that space, and so it’s
proportional to the Ricci scalar of curvature7 from differential geometry. Just like if
we draw a circle on a sphere, the area of the circle is not exactly π R2; it has a direction
term that depends on the radius of the big sphere. So we can start to characterize
not just the effective dimension of our limiting hypergraphs, but also their effective
curvature. Well, the big factors, if we look at the time evolution of that effective
curvature (I have to say a little bit about what we mean by “time evolution”)—but if
we look at the evolution of those things, it turns out that the continuum limit follows
the Einstein equations. So I discovered some simple cellular automata where, with
certain low-level conservation laws in the large-scale limit, the cellular automata
will show behavior that corresponds to ﬂuid dynamics, in this case, these hypergraph
rewriting systems—there, large-scale limit is not ﬂuid dynamics, it’s the Einstein
equations for the structure of spacetime. Now, one thing that’s a bit surprising in
these models is that space is dealt with in terms of this extension of the spatial
hypergraph, but time is a very different kind of thing from space. Time is described
by the progressive computational process of rewriting the structure of the spatial
hypergraph. So, it’s not an obvious fact that you would get something like relativity
with its standard relationship between space and time. Basically, what happens is
that, as soon as you as an observer are embedded within the system, you realize
the only thing you can actually be sensitive to is the network of causal relationships
between updating events. So, we’re looking at these different little updating events
that are occurring in this network, and we’re asking what are the causal relationships
between those updating events. One of these updating events involves certain edges
in this network, that an updating event can affect other updating events. There’s a
7 In differential geometry, the Ricci curvature tensor, named after Gregorio Ricci-Curbastro, is a
geometric object which is determined by a choice of Riemannian or pseudo-Riemannian metric on
a manifold.

32
S. Wolfram
Fig. 7 Causal relationships, rule BA →AB
network, a graph that shows how one updating event affects other updating events.
That’s a causal graph that represents that relationship.
Now let’s take a simpler case. Let’s look at just a string of As and Bs, and our
rule here is just “BA” goes to “AB” (Fig.7, left). These yellow things represent the
events that correspond to those updates. We can draw this graph that shows what is
the set of causal relationships between those events: this event can’t happen unless
the output from that event is already available and so on.
The big fact is, this thing we call causal invariance,8 which is a property of certain
rewrite rules, that causes it to be the case that, even though we can choose which
update to do when, the network of causal relationships between updating events is
always the same. And it turns out that phenomenon is what gives us relativity. We
can start thinking about how do we characterize this network of updating events,
and how do we say what corresponds to simultaneity in time? We can start making
palliation of this causal graph: let’s choose a different palliation which corresponds
to a different reference frame, and we can then see that it turns out that all the standard
results of relativity apply about this.
5
Multiway Graphs
One thing perhaps interesting to see is—one common phenomenon of relativity is
time dilation. And perhaps interesting to see, I have a good example of that. Let’s look
at this case here. This is a reference frame in which basically as much as possible is
8 “Causal invariance” means that no matter which evolution is chosen for a system, the history is
the same in the sense that the same events occur and they have the same causal relationships.

Two Different Directions: John Conway and Stephen Wolfram
33
getting updated at the same time, and we could think of it as being we’re just staying
in one place and we’re keeping on updating things (Fig.7, right). But let’s imagine
that instead we have a reference frame in which we’re actually moving in the space,
as well as doing this updating. If we want to move in the space, we make a reference
frame which is tilted in the space. And so what we see here is basically the classic
relativistic phenomenon of time dilation. It takes longer to get to the result because
we are basically moving in space at the same time as this computation is happening.
Kind of the way to understand what time dilation is, if you are an observer operating
inside this computational universe, you have a certain computational budget. You
can either use that budget to do computations at a particular place in space, or you
can use some of that budget to move and sort of update yourself in different places in
space—in which case you have less budget to use for the evolution, and time appears
to run more slowly as a result. One thing I should explain is that, in these models,
the only thing that exists in the universe is space, so it’s like cellular automata, like
rule 110: the only thing that exists is just the pattern of cells here. But in the rule 110
cellular automaton, we can see that these particle-like structures arise, that have all
kinds of complicated dynamics. What we imagine, is that in the universe, the same
thing happens with the particles, like electrons and quarks9 and so on. Those are
essentially the same topological defects in the structure of space that these particles
are in the pattern of the background here (rule 110 cellular automaton).
And, the sort of a challenge of my Physics Project right now is understanding
what the analog of these kinds of particle-like structures in this updating hypergraph
actually are, and it’s a big adventure in generalizing differential geometry. One of
the things that happens in these hypergraphs is that you can construct these kinds of
things like parallel transport10 and ﬁber bundles11 and all kinds of other things. But
they’re a bit different from the way they work even in discrete differential geometry,
because in standard calculus-based approaches to things you always have an integer
number of variables, whereas in this, you’re doing calculus in one variable, two
variables, whatever. What we need here is something that goes below the notion of
variables, and essentially as a sort of a generalization of calculus that works with
fractional numbers of variables, or something that goes below the idea of variables.
So that’s the challenge that exists there. So, in any case, we can look at all these
features of spacetime that emerged from these writings of hypergraphs and so on.
One of the things that’s a feature of the rewriting of the hypergraphs is that all the
rule says is when you see a little piece of hypergraph that looks like this, rewrite it to
9 A quark is a type of elementary particle and a fundamental constituent of matter. Quarks combine
to form composite particles called hadrons, the most stable of which are protons and neutrons, the
components of atomic nuclei.
10 In geometry, parallel transport is a way of transporting geometrical data along smooth curves
in a manifold. If the manifold is equipped with an afﬁne connection, then this connection allows
one to transport vectors of the manifold along curves so that they stay parallel with respect to the
connection.
11 In mathematics, and particularly topology, a ﬁber bundle is a space that is locally a product space,
but globally may have a different topological structure.

34
S. Wolfram
Fig. 8 Multiway graph
be something like that. It doesn’t tell you in what order, or where to do these things,
and this is a big difference from cellular automata.
In cellular automata, we’re dealing with some synchronous updates where every
cell is updated at the same time in lockstep, but in these models we’re just saying,
“Update wherever you feel like”. And the result of that is we get this multiway graph
that represents all possible updating. So, here’s the initial condition. These are two
possible outputs from that initial condition. These are more outputs from there, and
so on (Fig.8). We build up this multiway graph that involves branching, where one
state can turn into many, and also merging where many states can merge into an
identical ﬁnal state. So what is the signiﬁcance of this multiway graph? Basically
the signiﬁcance is it gives us quantum mechanics.
In classical physics, the big point is, things do deﬁnite stuff. So you throw a
ball, and it goes in a deﬁnite trajectory. But in quantum mechanics, the idea is
you are saying things follow many possible paths, and we only get to see what the
probabilities of different outcomes are. That’s an inevitable feature of these models
because what’s happening here is that there are these many possible paths, and these
correspond to what happens in quantum mechanics. I can ﬁll in a little bit more
detail. One of the things to understand is if we look at these multiway graphs, we
could ask the question, “How do we lay out these different states that exists here?
How are they related to each other? Can we think of them as living in some space?”
It turns out, we can—we call it branchial space,12 the space of quantum branches.
And essentially what happens is you can make a map where these things are in space
by asking which ones have common ancestors, and whenever they have common
ancestors, you join them. So this is an example of successive slices of the multiway
12 Whereas causal graphs capture relationships between events at different steps in the evolution
of a system, branchial graphs capture relationships between states on different branches at a given
step. And in a sense, they deﬁne a map for exploring branchial space in a multiway system.

Two Different Directions: John Conway and Stephen Wolfram
35
Fig. 9 The branchial relationship between different states of the multiway graph
graph, successive slices of time showing the branchial relationship between different
states of the multiway graph (Fig.9). So this is essentially a map; actually, it’s a map
of quantum entanglements,13 it’s a map of entanglement between states induced by
the structure of the multiway graph. So what is this? This is something that’s not
like physical space, it’s not like a layout of physical space, it’s a space of quantum
entanglement. But it’s a space in which we can also think about motion, just as we can
think about motion in physical space. In physical space, we think about Z D sequels
as being the parts the particles will take in physical space, and when space is curved,
those parts will be curved, and that corresponds to the force of gravity and so on. The
description of the deﬂection of those parts is the story in the Einstein equations and
physical space. Well, it turns out, we can do the same exact thing in branchial space.
There is a direct analog of the equations of deﬂection in branchial space—but now,
what are those equations? Those equations turn out to correspond to a core feature of
quantum mechanics. They’re basically the Feynman’s path integral.14 And it tells one
how these Z D sequel in the multiway graph are deﬂected by the presence of energy, in
13 Quantum entanglement is a physical phenomenon that occurs when a group of particles is gen-
erated, interacts or shares spatial proximity in a way such that the quantum state of each particle of
the group cannot be described independently of the state of the others, including when the particles
are separated by a large distance.
14 Feynman’s approach is particularly suggestive, as it creates a bridge between the classical
Lagrangian description of the physical world and the quantum one, reintroducing in quantum
mechanics the classical concept of trajectory, which had been banned by the traditional formulation
of the theory. It allows, at least heuristically, to associate a quantum evolution to each classical
Lagrangian.

36
S. Wolfram
the same way that once deﬂected by the presence of mass energy in physical space. So
the remarkable realization is that in these models, the the structure of spacetime, the
Einstein equations, are the same. They come from the same place as the path integral
of quantum mechanics. So in a sense, general relativity and quantum mechanics are
the same theory. Except general relativity is operating in physical space and quantum
mechanics is operating in this branchial space and multiway graphs.
So that’s a big deal in the theory of physics, and there’s a lot that can be said about,
kind of, quantum measurement. I think John Conway worked on this quantum free
will idea15 which I think didn’t quite go in the right direction. I think that the story
of quantum measurement is a story of reference frames. Basically, in the multiway
graph, you are forming palliation and, when you make a quantum measurement,
you’re essentially deﬁning a reference frame. And it’s a little bit of a bizarre thing
because what’s happening is we as observers are actually embedded in the quantum
system, so the quantum system is full of these branches. Our brains effectively are
branching in the same way as the system itself is branching. So the story of quantum
measurement is a story of how does a branching brain perceive a branching universe.
You can untangle that using a bunch of methods actually from automated theorem
proving, a directly analogous system—the reasons analogous. Look at this multiway
graph. You can imagine that each one of these nodes is an expression of a math-
ematical expression, and each edge corresponds to the application of some axiom
that transforms that expression. So, a theorem that some expression is equal to some
other expression becomes the statement. There is a path in the multiway graph from
one node (from one expression) to another one. Then these questions about quan-
tum measurement end up being questions about making computations and lemmas
and so on in this graph that you get. What I ﬁnd interesting is that from the idea of
simple rules, we’re getting this fundamental approach to physics. It’s turning out the
formalism that we have for physics is also applicable to a bunch of other areas. It’s
certainly applicable to distributed computing because what we have here is just a
cellular automaton of the minimal models of synchronous parallel computation, and
these models are essentially the minimal models of asynchronous distributed com-
putation. So it’s been very difﬁcult for us to understand how do we do programming
in distributed computation. I think that we can learn a lot from physics, we can learn
about programming in reference frames, and things like this.
There are also other areas where the formalism of our Physics Project seems
to be very relevant, particularly, words relevant to metamathematics. If we look at
mathematical theorems that have been studied in the history of mathematics, there’s
a few million of such theorems, and they have formed this big sort of a multiway
graph—type network of what theorem can be proved from what other theorem.
And there’s a question, then, what the overall structure of the multiway graph, what
the overall structure of metamathematics, is—what the limit of mathematics is. In
15 The free will theorem of John H. Conway and Simon B. Kochen states that if we have free will
in the sense that our choices are not a function of the past, then, subject to certain assumptions,
so must some elementary particles. Conway and Kochen’s paper was published in Foundations of
Physics in 2006.

Two Different Directions: John Conway and Stephen Wolfram
37
mathematics, we think about particular theorems, but if we think about the network
of all possible theorems, what is the limit as you take the continuum limits,16 and how
does that continuum limit compare to the continuum limit of physics and features like
space and time? Actually, I’ve just been ﬁguring out a bunch of this, and it requires
me going into a couple more layers of abstraction here, which I’m not sure people
here will be interested in. But a very recent realization is, when you try and make a
theory of physics, one of the questions is, you might say, well, in the end, our universe
is based on this particular rule for upgrading hypergraphs, but you say, “Well, why
that rule and not another rule?” Well, what we realize is you can go multiway, but
even more extremely, we can make what we call a rulial multiway system where
in addition to saying we apply the rule, that every place we could apply the rule,
we also say we apply all rules we could imagine applying, so we apply all possible
rules. And so, we get this thing which is this rulial multiway graph which is a very
complicated structure—which you might think, if we apply all possible rules, how
can we ever say anything? Why isn’t that just going to have no structure at all? But
it turns out, it has a very interesting structure.
We can look at, for example, this study I did about Turing machines, and the
rulial space of Turing machines. So there’s just an ordinary Turing machine. We can
consider a nondeterministic Turing machine where from a single initial state it can
generate multiple states, and what we can do that we can consider a rulial Turing
machine in which it applies all possible Turing machine rules. So what we get here
is this rulial multiway graph that represents this sort of ultimately nondeterministic
Turing machine that’s doing all the possible things a Turing machine can do. But that
graph has a deﬁnite structure, because states that are generated there may be branches,
but they’re also mergers, and so what we end up with in the end is, we actually get very
deﬁnite structures from these rulial multiway graphs. These represent the sort of full
structure of all possible abstract Turing machines. It’s interesting. I might make the
comment that this is a story of deterministic versus nondeterministic computation,
if one’s interested in things like the P versus NP problem. One sees in this space of
rulial multiway system a particular Turing machine evolution is just this one path, but
this whole structure represents what you can reach with all possible nondeterministic
Turingmachines.Andso,thequestionofPversusNPbecomesageometricalquestion
about how do you compare this rulial graph with what you can reach with all possible
deterministic individual parts. And I might say that this rulial graph has a very
deﬁnite structure, and that structure is the ultimate limit of physics. It has many
interpretations. That graph has the ultimate limit of physics in this all possible rules
are being run. So then what happens is, there’s a relativistic invariance17 that causes
differentreferenceframesinrulialspacetoallconcludethesamekindsofthings.And,
in a sense, we are, as sort of observers of this rulial universe, picking out a particular
reference frame and observing particular things. So one of the surprising things is
that the ultimate limit of physics is the same as the ultimate limit of mathematics,
16 This is the square of the displacement of the particle.
17 Relativistic invariance (Lorentz invariance): The laws of physics are invariant under a transfor-
mation between two coordinate frames moving at constant.

38
S. Wolfram
both essentially these rulial multiway systems that correspond to the application of
all possible sorts of formal rules. In mathematics, this rulial multiway system has
been studied a bit; it’s a limit of higher category theory, called inﬁnity groupoids,
studied by people like Grothendieck.18
6
Limits of Physics and Mathematics
So the strange thing that happens is that the ultimate limit of physics is the same as
the ultimate limit of mathematics. And we can start to talk about lots of different
features of mathematics in cost analogy to features of physics in that way. I’ve just
been exploring this actually, and it’s today’s project trying to understand the question
of the Platonic view19 of mathematics. Mathematics is a deﬁnite thing that exists that
we choose to construct from particular axiom systems. I think in these ways, one can
understand that mathematics exists in the same way that the physical universe exists.
So lots of things to say about that. What we’re realizing is that this idea of simple
programs producing complicated behavior leading us to things like computational
irreducibility20—the Principle of Computational Equivalence. That’s an important
standard development. Another standard development that we’ve learned is that, one
of the surprises of the universe is like this, and is full of computational irreducibility.
How come there are any laws of the universe that we can identify? How come
there are any things that we can say about the universe? This is a place where
there’s a surprising thing that there are these slices of computational reducibility
within any computational irreducibility system, and those slices of computational
reducibility turn out to correspond to the laws of physics that we know. So, this kind
of question—how do you generically identify slices of computational reducibility
within computationally irreducible systems?—this is an interesting question. This is
something that, I think, is leading us to a really new understanding of how systems
have simple—how simple programs—simple rules and so on, how that really works.
We both have this layer of computational irreducibility, and on top of that we can have
these slices of computational reducibility, and those are the things that we humans
kind of lock into when we try and make sense of the physical universe. I think, it’s
18 Maltsiniotis, Georges (2010), “Grothendieck ∞-groupoids, and still another deﬁnition of ∞-
categories”, arXiv:1009.2331.
19 Platonism is the view that there exist such things as abstract objects—where an abstract object
is an object that does not exist in space or time and which is therefore entirely non-physical and
non-mental.
20 Wolfram terms the inability to shortcut a program (e.g. a system), or otherwise describe its
behavior in a simple way, “computational irreducibility.” The world of simple programs contains
a great diversity of behavior, but because of undecidability, it is impossible to predict what they
will do before essentially running them. The idea demonstrates that there are occurrences where a
theory’s predictions are effectively not possible. Wolfram states several phenomena are normally
computationally irreducible. Computational irreducibility explains observed limitations of existing
mainstream science. In cases of computational irreducibility, only observation and experiment can
be used.

Two Different Directions: John Conway and Stephen Wolfram
39
going to turn out that idea of ﬁnding these slices of computational—it’s going to turn
out that is actually what’s needed to crack a whole bunch of problems, a whole bunch
of areas of science and elsewhere that have been long-running issues. Well, you can
apply this thinking to lots of different kinds of things. I’ve been recently thinking
about it in terms of economics, actually, and the thing which is exciting is that you
have the same underlying formalism. You’ve got to import some of the discoveries
of physics into these areas, and get intuition from that.
I’llmentiononeotherthingaboutcomputation.Oneofthethingsthatwe’retalking
about is this idea of multiway systems. And I mentioned multiway Turing machines,
and there’s a whole theory of multiway Turing machines. And what the thing is that,
normally when we think about computation, we think about computation where you
have something, where you give an input, you compute, you get an output. But for
multiway systems, it doesn’t work in that way. Instead, there is this whole collection
of different behaviors that are occurring. And the question is, can one think about
that when we’re trying to understand computation and how it works? For example,
systems in nature—is that relevant? And I have a suspicion that it will turn out that a
core thing that you need to understand is to understand biology, is this phenomenon
of multiway computation. The model that we have, that a deﬁnite input produces
deﬁnite output, people try to decompose biological systems that way, but it doesn’t
really work that well. My guess is that we will need to understand the phenomena of
multiway computation to understand how that works in biological systems. I think
also that if we want to make molecular-scale computations, one of the ways to do
that is to use chemical processes. These pictures of multiway Turing machines, they
remind us for good reason of chemical reaction networks. Because, in a sense, what’s
happening in, typically, synthetic chemistry, you are interested in ﬁnding a particular
path through the sequence of chemical reactions, that produces a particular product.
But, the thing is to think about, sort of, the set of all possible paths, and to try to
understand what is the computation that can be done by following that set of all
possible parts.
Well, looping back a little bit: as I say, John Conway and I shared this interest in
what do simple programs actually do, what can simple programs do. And some of the
questions, for example—I might just mention something that I discovered recently
that is very Conway-esque. So I was interested in the 3n + 1 problem, and I was
interested in that for a reason I can explain. And John Conway was interested in the
3n + 1 problem, and the question was, sort of, what is the computational essence
of the 3n + 1 problem? How computationally sophisticated is it? When can it be
a universal computer? And so on. Well, this is a story of the generalized 3n + 1
problem, and its relationship to known problems of mathematics, and so on. And
this is—I just discovered this few weeks ago—this is a new generalization of the
3n + 1 problem that I think has a hope of being able to be a very simple version
of the 3n + 1 problem that’s capable of being proved to be computation universal.
I might mention this is something that is a very Conway-esque study. I don’t know

40
S. Wolfram
whether John actually studied tag systems.21 Everybody had systems very much like
this. This is a system that was invented by Emil Leon Post about one hundred years
ago, where you just have a sequence of symbols, and at every step you chop off the
ﬁrst three symbols, and then depending on whether the ﬁrst symbol was a 0 or 1 you
either print 00 or 1101 (0 →00, 1 →1101). And (Emil Leon) Post was very proud
of the fact that he’d reduced the structure of Principia Mathematica,22 the structure
of Russell and Whitehead’s work on the foundations of mathematics, to being just a
story of string rewriting. And he thought he could only solve the problem of string
rewriting. He would solve all of mathematics, but he got stuck on this particular
example. We’ve done a big analysis of this example, and the big question is, does it
always hold or not? Is it something where you can always ﬁnd, you know, in this case
it holds after four hundred steps? You can see the behavior that produces, and these
are state transition graphs for it. Here it’s holding off to 25,000 steps. Here, it’s all
holding onto a quarter million steps. And we’ve found now examples where I think
the record breaker now is 12.7 trillion steps. But what’s interesting about this is, it’s
a challenge for the Principle of Computational Equivalence is, is it always going to
hold? The prediction from the Principle of Computational Equivalence will be, it
will not always hold. Eventually, we will ﬁnd an initial condition which suddenly
escapes to inﬁnity. And what’s strange about this is these patterns of the size of the
string as a function of a number of steps, are precisely followed random walks. So far
as we can tell, they are indistinguishable from random walks. They have all the same
sort of statistical properties as random walks, yet they are produced by completely
deterministic systems. And the question is, is this system one that is always going to
hold, or is it that we can eventually ﬁnd an initial condition that doesn’t hold?
In a sense, what we’re doing here—this is a big glider gun23 search. In the Game
of Life, for example, this relates to John’s original idea of the use of the Game of
Life as a way of enumerating the recursive functions. The Game of Life in a ﬁrst
approximation is something where it always holds; the simple conﬁgurations always
hold. But then Bill Gosper found this glider gun, which is the ﬁrst conﬁguration
that doesn’t always hold, that grows forever. So now, we have another example here
with these tag systems—we have a much more challenging case—a challenge of
this Principle of Computational Equivalence. Is it going to always hold or not? I
think not, but we’re at 12.7 trillion steps so far, and we haven’t found an example
yet. It’s interesting to ask the question how would we even imagine proving when
21 A tag system is a deterministic computational model published by Emil Leon Post in 1943 as a
simple form of a Post canonical system. A tag system may also be viewed as an abstract machine,
called a Post tag machine (not to be confused with Post—Turing machines)—brieﬂy, a ﬁnite-state
machine whose only tape is a FIFO queue of unbounded length, such that in each transition the
machine reads the symbol at the head of the queue, deletes a constant number of symbols from the
head, and appends to the tail a symbol-string that depends solely on the ﬁrst symbol read in this
transition.
22 Principia Mathematica, the landmark work in formal logic written by Alfred North Whitehead
and Bertrand Russell, was ﬁrst published in three volumes in 1910, 1912 and 1913.
23 In a cellular automaton, a gun is a pattern with a main part that repeats periodically, like an
oscillator, and that also periodically emits spaceships.

Two Different Directions: John Conway and Stephen Wolfram
41
there wasn’t such an example, (would we be able to prove it using Khan arithmetic),
will we be able to prove it using mathematical induction, will we need transﬁnite
induction,24 set theory, to be able to prove it? How does this all ﬁt together with
these different approaches and so on? I think, if John Conway was still alive, and we
were in good communication, I think it would be an interesting conversation, given
his interests in his efforts of being a professor of logic to ask this question. What is
the relationship between these proof systems, these logical systems, and what can
be reached with these very simple programs?
That was a a quick survey of some of the thinking about simple programs, and
places where things that I’ve been interested in intersecting with things John Conway
was interested in. I haven’t talked at all about how we harness the power of the
computational universe, and the whole story of computational language, and our
effortstobuildWolframLanguage.JohnConwaywasalongtimeuserofMathematica
and Wolfram Language.
I don’t think I ever saw any code he wrote. I think maybe he got other people to
write the code, I’m not sure. It’s always an interesting thing because a lot of leaders of
science, many of them, most of them, use our technology. Every so often, I get to see
a piece of code written by one of these people, and somehow it’s an thing interesting
for me, because I understand this language well. It’s like seeing the style how of
somebody is writing in English or something, and it gives one an understanding of
a personality that is a little different than what one might get by other means.
7
Interaction with Stephen Wolfram
Mihir K. Chakraborty: You made kind of a similarity between mathematics and
physics. To me it seems this: mathematics as it stands now doesn’t have any
goal. On the other hand, physics—or, to say, any natural science—has got some
kind of goal, in the sense that there is some universe outside us, and we have
to understand that universe or model that universe in some way or another. So
that is the kind of goal as I understand about physics. Maybe a physicist may
disagree. But I am sure about mathematics. Mathematics doesn’t have any goal,
because it is not to discover anything; it doesn’t have any target. So my question
is precisely this: do you agree with this view? Because as it seems, that you don’t
agree with this.
I think this is a very interesting question. Let me show you something that perhaps
is a response to that question, a little bit. I was curious about Euclid, and Euclid has a
deﬁnite model of how mathematics progresses. It starts with, you know, 10 axioms,
basically proves 460 theorems. So you can ask, “What is the metamathematics?
What is the empirical metamathematics to Euclid?” That’s a sort of chart that shows,
what theorems were used in the proof of a given theorem. You can make this whole
24 Transﬁnite induction is an extension of mathematical induction to well-ordered sets, for example
to sets of ordinal numbers or cardinal numbers.

42
S. Wolfram
Fig. 10 What is the full interdependence graph for all the theorems in Euclid? The axioms are at
the top, and show how theorems below are derived from them
graph, the metamathematical structure of Euclid. So you can ask the question; there
are many possible theorems that could have been proved from those axioms. This
is the network of theorems that Euclid chose to pick out of the space of all possible
theorems (Fig.10). So what I see is this as being—is the kind of human geography
of metamathematical space. There is an ultimate metamathematical space of all
possible theorems that can be proved from those axioms, and this is the kind of human
geography of what theorems humans chose to prove from that underlying structure.
So the question you could ask is, well, there is this metamathematical space given,
even if you imagine that mathematics starts from particular axiom systems—I’m not
sure as to the right model of mathematics, but let’s assume you start from that. Given
those axioms, you can build out all possible theorems, and then you can ask the
question, “What’s the goal of mathematics?” Well, the goal of mathematics might
be to know, you know, it’s like what’s the goal of space exploration, or something.
It’s like, go to places that we humans think are worth going to.
So I think it’s really an interesting question. What, you know, to set the goals
of mathematics have to do with where in metamathematical space do we humans
want to go. There are two levels of that question: what does metamathematical space
intrinsically look like, what is intrinsically out there in the space of possible theorems
and which theorems do we think are interesting enough to explore? And you can look,
needless to say, and you can generate branchial graphs and the whole story of physics-
likestuff.Icanshowyouhere,justforinterest,theanalogybetweenmetamathematics
and physics, as a little bit clearer when you look at the formalization of mathematics.
This is Pythagoras’s theorem (Fig.11), in a formal proof assistant system.25 And
25 Proof assistants are computer systems that allow a user to do mathematics on a computer, but not
so much the computing (numerical or symbolical) aspect of mathematics but the aspects of proving

Two Different Directions: John Conway and Stephen Wolfram
43
Fig. 11 Pythagoras’s theorem in a formal proof assistant system
this is looking, essentially what’s happening is, at the very lowest level, it’s like
my atoms of space and so on—the very lowest level you’re dealing with these very
microscopic kind of order relations and all kinds of very low-level mathematical
things, but then you build up to something which is more human interesting like
Pythagoras’s theorem. It takes about 10 thousand of these microscopic mathematical
steps to build up to Pythagoras’s theorem.
So, I think it’s an interesting question: what is the mathematics that we choose to
study? I’ve been changing my mind little bit, actually, very recently about how this all
ﬁts together. And what I think is the case—my speculation, which may be incorrect,
is the big story of mathematics is that there is ultimately this kind of rulial universe,
I’m calling it—the consequences of all possible formal rules. It’s that structure, I was
showing for Turing machines, you can build the same kind of thing for other kinds
of rules. And then, what we’re doing is, we’re sampling that with various reference
frames. What does that mean in mathematics? What that means is we’ve got some
underlying thing in mathematics and we are using different description languages to
describe pieces of that thing. So it might be that those description languages are like
algebra, it might be those description languages are like geometry. What this suggests
is that there is a fundamental equivalence between the things we’re getting with those
different description languages. And that fundamental equivalence is similar to a
relativistic invariance in physics. In other words, these different reference frames for
sampling the sort of underlying, you know, ultimate metamathematics, and we get
to make different samples of that, and if there is equivalence between those things,
what is the analog of relativity and mathematics. Is it, for example, something related
to category theory,26 or something like that describes a structure independent of the
and deﬁning. So a user can set up a mathematical theory, deﬁne properties and do logical reasoning
with them.
26 Category theory formalizes mathematical structure and its concepts in terms of a labeled directed
graph called a category, whose nodes are called objects, and whose labeled directed edges are called
arrows (or morphisms). A category has two basic properties: the ability to compose the arrows
associatively, and the existence of an identity arrow for each object. The language of category

44
S. Wolfram
description language? I don’t know the answer of this, but that’s my current level
of thinking about what’s the analog. And you say, what’s the goal of mathematics?
I think that’s a terriﬁc question. I think we know what has been achieved in human
mathematics. There are a few million theorems that exist in the published literature of
mathematics, and you can ask what do we know from the human geography of those
theorems, and that’s what things like these pictures of metamathematics—empirical
metamathematics of Euclid—I am trying to talk about.
But I’d love to know what is the limit of mathematics. Consider mathematics,
and look at its limit. You know, an inﬁnite number of years from now, what will
mathematicians have done? And you might say what mathematicians have done
will be pure historical accident. In other words, people might have studied this area
just because somebody thought it was important, and so they went off and studied
it. That’s theory number one about mathematics: it’s all historical accident. The-
ory number two is there something intrinsic about what’s there in the structure of
mathematics. And I’m increasingly suspecting that there’s something intrinsically
there—there’s an intrinsic structure to metamathematics, and there are strong con-
straints. We can explore it with different essentially reference frames in different
directions, but there will be commonalities between these different ﬁelds that will
reﬂect the fundamental structure of metamathematical space.
This is an active project for me. I’m trying to make this kind of bulk limiting theory
of metamathematics. And then, in answer to your question, what does mathematics
have as its goal, I might say it is the exploration of the mathematical universe, which is
this ultimate metamathematical space. That essentially what we’re doing is we prove
theorems in a particular area. We are developing a certain reference frame, in which
we can explore what is the ultimate metamathematical space. I don’t know, I think
most mathematicians today would not say that was the objective of mathematics. But
if you look at the history of mathematics, with people like Hilbert, there was this idea
that mathematics is really going to be the exploration of arbitrary axiom systems. And
thatideahadsomedegreeofsuccess,butit’snotwhatmostpracticingmathematicians
would say they’re doing in mathematics. And so, this is an alternative approach to
thinking about what you’re fundamentally doing in mathematics. I mean, I might say
on the subject of axiom systems, one of the things that I found interesting, what the
space of all possible axiom systems looks like. So, this is saying given different axiom
systems, what theorems are true in those axiom systems. We’re asking this kind of
ultimate desiccated mathematics. These are possible axiom systems (y axis), these
are possible theorems (x axis). The ﬁeld of mathematics is characterized by whether
black dots—which theorems is true given those axioms (Fig.12). And so, one thing
I was interested in for a while was, how did mathematics picks its axiom systems? Is
there something special about the metamathematical level about the axiom systems
that got picked? That seemed to be about something, as opposed to just being abstract
axiom systems, and I couldn’t ﬁgure that out. What I did ﬁgure out was, if you look
theory has been used to formalize concepts of other high-level abstractions such as sets, rings and
groups. Informally, category theory is a general theory of functions.

Two Different Directions: John Conway and Stephen Wolfram
45
Fig. 12 The ﬁeld of mathematics is characterized by black dots, and which theorems are true given
those axioms (picture from NKS book)
at these axiom systems, where in the space of all possible axiom systems, the axiom
systems that we actually use, end up being.
And my biggest achievement there was doing that for Boolean algebra. So I was
interested in, if you just look at all possible axiom systems, where is Boolean algebra?
How far out is Boolean algebra? And the answer is it’s about the 50 thousandth
axiom system you get to. This is the simplest axiom system for Boolean algebra—
((p.q).r).(p.((p.r).p)) = r.27 There are several things that are interesting about that.
First, where are the axiom systems that we’ve chosen to study? How far out are they?
Second, a thing that I was particularly interested in here, is the proof that is a correct
axiom system for Boolean algebra I found by automated theorem proving. The proof
is absolutely incomprehensible.
And one of the questions that’s interesting to me is, what is mathematics? A lot
of people are interested in mathematics as kind of giving proofs that explain why
things are true. But this is a case where we have a proof that explains nothing. It
is pure machine code, effectively. So I was interested in—how do you—this is a
representation of the proof, and the lemma structure of the proof, and the question
is, what can you do? How do you make that proof explainable? How do you think
27 “Logic, Explainability and the Future of Understanding,” by Stephen Wolfram, Novem-
ber 6, 2018, https://writings.stephenwolfram.com/2018/11/logic-explainability-and-the-future-of-
understanding/.

46
S. Wolfram
about what mathematics is, if mathematics is based on proofs, and proofs are a way
of explaining things to people? How do you get to the point where proofs can be
explained to people?
Mihir K. Chakraborty: It is almost impossible to explain to people a mathe-
matical proof in general.
So these automated theorem proofs, the way I think about it is, if we knew that
there was a lemma here that was really, really popular, we would give it a name,
and then people would gradually get used to that lemma. They’d be able to think in
terms of that lemma. This is basically the same story as with natural language. When
we talk about things, if we didn’t have a name for a chair or something, we would
have a hard time reasoning about chairs, and the reason we have a name for a chair
is because chairs are common. And I think it’s the same thing with mathematical
theorems and mathematics. If something becomes common, we humans give it a
name, and we can reason in terms of it. But the difﬁculty is, the question really is,
as you start proving theorems, how diverse are the intermediate lemmas that you
produce, what are the best lemmas to use, so to speak, to get the furthest to doing
mathematics and so on. I think this problem of how do you make a proof explainable
is part of my day job of building Wolfram|Alpha. In my Wolfram|Alpha, you know,
if you go, if you type some random integral, you’ll get some answer for this integral,
but then you say show me the step-by-step solution. This is something where the
computer is synthesizing a kind of human-explainable proof of a result. But look, I
really liked your question. Do you think you have a further answer to this question,
I mean of what is mathematics?
Richard Gordon: Show patterns, have you looked at the inverse problem? In
other words, given a pattern, can you?
There’s a simple level at which you can do that. In a sense, the effort of studying
simple programs and what they do is like the forward problem, it’s like the calculus
problem. The inverse problem is kind of like the statistics problem: how do you
ﬁnd the parameters that match something? Now the interesting new game in town is
machine learning, because basically what machine learning is doing, it’s taking the
programs that correspond to neural networks and showing us that by bashing those
things really hard with training, we can deduce kind of what the parameters of the
neural network should be, and actually people have done a bunch of work recently
on connecting neural networks to cellular automata. In fact, a bunch of work now has
been done on precisely biological permutation patterns using combinatorial neural
networks and cellular automata to try and use training of neural nets as a way to
effectively reduce the rule. But, it’s to me—we don’t have a very satisfactory way
to think about that yet, because the trick in neural nets is to use calculus, to use
incremental improvement of these parameters. We don’t have a way to do incremental
improvement of things like in cellular automata. But, you know, the space of cellular
automata is like, it’s a long way from one rule for the next. We don’t know what
the structure of that space is well enough to do incremental improvement. In the

Two Different Directions: John Conway and Stephen Wolfram
47
case of mollusc shells, I have looked at this in a bit more detail—there is a difﬁcult
geometrical problem of unrolling the mollusc, because the mollusc made itself in a
spiral, and we’ve done some work on using image processing and Wolfram Language
to unroll the spirals of a mollusc shell. But that was never really ﬁnished, and once
you’ve unrolled the spiral, then you can start asking, can you put the thing on a grid,
and how do you align the thing, and so on. I think that’s an inadequately answered
question at this point. I think the inverse problem is kind of the generalized statistical
problem, because in statistics, you got the distribution of results. Do they ﬁt more or
less a Gaussian? Can I put these couple of parameters into the Gaussian to ﬁt them?
And what you’re doing in the case of the simple programs is, can I ﬁt a program to
this data? Known that’s a part of the data, can I ﬁt this continuously parameterized
function to this data? What we need to do for simple programs is, can we ﬁnd a
way to do sort of ﬁtting simple programs to data? This is a very interesting topic,
I think—some of the things that we’re doing, actually, sort of some of the Physics
Project—may give us some further hints about that, because in a sense, the story
of these different possible rules is partly a story of this branchial space in multiway
systems, and so on. But I don’t have good things to say about this yet, and hopefully
we will.
Richard Gordon: It’s part of reverse-engineering the embryo, is a small prob-
lem of the general problem, doing it.
The only thing I might comment about embryos is that we realized recently that
our models of physics are also pretty interesting models of biological growth. And the
reason for that is because we have dynamic structure of space. It’s like when you have
cell divisions and so on, normally you’re doing ﬁnite element analysis or something.
It’s a big pain to have the underlying geometry of the space change, but in our models
of physics, that isn’t a problem. In fact, we’ve realized, we’ve already done solving
the Einstein equations as a piece of numerical relativity, doing that using our models,
and we were about to embark on solving continuous mechanics equations using the
same approach. And what’s interesting about it is, you can solve the continuous
mechanics equations, including cell division. So you can have something where
there’s mechanical stresses and there’s cell division, and that might be interesting for
embryology.28 And I mean, in other words, it gives you a way to know—I don’t know
how you do that right now, but I know people have done lots of ﬁnite element methods,
but it’s very painful because the geometry of the underlying space is changing, and
you have to add all kinds of weird pieces to the ﬁnal element methods to be able to
deal with that.
Richard Gordon: But don’t see cellular automata very much—their contin-
uous interactions between global and local phenomena in the embryo-genesis.
Yes, but I think part of the reason for that is because of this geometry thing,
something like gas relation or something like dramatic, but that globality—that’s
28 Embryology is the branch of biology that studies the prenatal development of gametes (sex cells),
fertilization and the development of embryos and fetuses.

48
S. Wolfram
interesting. I don’t understand it for embryology at all, but it will be interesting to
try to understand this in physics. In physics, our models of these hypergraphs are
completely local to the hypergraph, yet we see global phenomena like black holes,
event horizons,29 all those kinds of things. And it’s interesting that, from the local
you get the global by virtue of the fact that the local is producing geometry and
topology, which has a global aspect to it. And, actually, I think about it, I bet the
same thing would happen in embryology. And the question I never understood—I
remember Tammo Tom was always fond of talking about algebraic topology and its
relationship to embryo-genesis—I always felt for the audience of his book, I thought,
I should be at least one data point—people who understand a little bit about topology,
I think, I end up being the zero data point, because I never really understood it. But
I wonder whether there are relationships that one could draw between the growth
processes and the way globality arises, similar to the way globality arises in physics.
I don’t know, the question is, is the mechanics of the globality purely a consequence
of geometry, or do you imagine ﬁbers or something that actually pull from one thing
to another, or is it just because of the geometry?
Richard Gordon: Well, I’m not sure if I can put it in your context, but I’ve
been working on this problem a long time, and come to the conclusion that
embryo-genesis is basically—in that the cell respond to a global phenomenon
and the global phenomena are set up by the cells, and this occurs in a branching
process, and it happens over and over again until you get the adult.
So, the question is, instead of the reaction-diffusion approach, you have some
long-range interaction from some morphogens. That’s one way you can imagine
something more global happening, although that’s still somewhat local, I mean.
Richard Gordon: I published a book30 on the inadequacy of the theory. It’s
great for one step of differentiation cells, but it doesn’t work for multiple steps.
That’s interesting. I would say that we just started looking at continuum mechan-
ics, and whether we can use the same mathematical structure for continuum mechan-
ics. We thought about embryo-genesis, because, we thought, that’s a case where you
have this change of geometry and change of topology. If we’ve got students who
think about these kinds of things, we should get in to look at this, because I think
there might be something really wonderful.
Richard Gordon: I read your whole book a number of years ago; you might
read mine to get this.
29 The “event horizon” is the boundary deﬁning the region of space around a black hole from which
nothing (not even light) can escape. In other words, the escape velocity for an object within the
event horizon exceeds the speed of light.
30 Gordon, N.K. and R. Gordon (2016). Embryogenesis Explained. Singapore, World Scientiﬁc
Publishing.

Two Different Directions: John Conway and Stephen Wolfram
49
Fig. 13 A rapidly rotating black hole modeled with Wolfram model evolution
I think, it is relevant. There is a recent paper31 about solving Einstein equations
using our models. This is basically saying we can model the structure of spacetime,
this is looking at black hole mergers, and things like that, in our models.
The thing that, I think—the most relevant is that essentially what’s happening is,
we’re just solving a PDE. So, this is a picture (Fig.13) of a rapidly rotating black hole
modeled with our kind of methodology. And the thing that’s interesting is in standard
Einstein equations, if you solve this numerical relativity, the code will get confused,
because what actually happens is a piece of the universe breaks off, and you can’t
represent that in a standard PDE, and sort of standard continuous PDE models. But
you can in these models that have this discrete structure of spacetime. Again, I think,
there’s something interesting here. I may be wrong, but I think there’s something
really interesting for biology in analyzing this some kind of relationship between
them. And I don’t know the differentiation process—I’m not sure how that so much
relates—Hox genes32 and all that kind of thing—I’m not sure how much that relates.
But the thing that I do think we understand something about is mechanical stresses
and geometry, and the result of growth on geometry. Anyway, interesting topic.
Richard Gordon: Well, there are mechanical waves which seem to trigger the
cells to change types.
Interesting, probably has a lot of medical implications of that. I will look at this.
R. Ramanujam: All your explanations of physics are all descriptive in some
sense, whereas for systems with goals, like artiﬁcial intelligence, the use of neural
nets in machine learning—for these, do you see similar possibilities for cellular
automata?
People always say, “I’ve got a cellular automaton, but I really want a cellular
automaton whose rules can change.” It’s a very, very common thing for people to
31“Hypergraph Discretization of the Cauchy Problem in General Relativity via Wolfram Model
Evolution,” by Jonathan Gorard.
32 Hox genes, a subset of homeobox genes, are a group of related genes that specify regions of the
body plan of an embryo along the head-tail axis of animals. Hox proteins encode and specify the
characteristics of “position,” ensuring that the correct structures form in the correct places of the
body.

50
S. Wolfram
Fig. 14 Five layers of the neural nets starting with a picture of Stephen Wolfram
ask. The thing to realize is, as soon as you have a universal system, that isn’t a
question you really need to ask, because a universal system has the feature that, you
know, it can encode any rule it wants. So to say, I’ve got another level, I’m putting
in rules, is not really the right thing. So the question is, then, in the systems, to what
extent do their dynamics explore these?
What can I say about that? I mean, the problem of today’s machine learning, the
most standard problem is, how can you give us global description of what’s going
on inside the neural nets? Let’s pick up a picture of me (Fig.14). Now, we could
say something like image identiﬁer—if we’re lucky, it’s going to say “human,” and I
could say, “Let me look not at the ﬁnal result, but let me look at the result of just, let’s
say, ﬁve layers of the neural nets” (Fig.14). So the question is, what was the neural net
thinking when it generated these forms? And that is question similar to this question
about automated theorem proving: how do we ﬁnd a human-understandable way of
representing what’s going on here? So one question is, can we use, for example,
ideas from the Physics Project to analyze things like machine learning? The answer
is, we think there may be a way of doing that.
Normally in machine learning, if I do a training, say nettrain. If we—say we
wanted to train that network, and let’s say we have some standard training set, say a
random sample. Say we have ﬁve hundred pieces of that training set. We say, “Train
that model with that training set,” so this is the standard neural network thing that
we would do. But notice that what we’re doing is, we’re just dealing with a single
instance where there’s all kinds of randomness involved in doing this training, but
the point is, we’re looking at a single path of doing this training.
So the crazy thing that we can consider doing is to look at the multiway graph
of all possible training paths. That’s something that, as a practical matter, may be
quite hard. It’s very hard to do because that training probably involved—that would
be a giant multiway graph with 1020 nodes or something. But the question is, can we
in fact analyze? Can we say something about machine learning by looking at these
multiway graphs of all possible training paths? I don’t know the answer to that yet.
But this is the thing that we’ve been thinking about. For example, when you look at

Two Different Directions: John Conway and Stephen Wolfram
51
nearby training paths, nobody has done that, nobody has looked at, essentially, the
quantum analog to know that training, where you’ve built up this whole multiway
graph. And you’re looking at what do nearby training paths do—no idea. Whether
that will tell on things about robustness of neural nets, or other kinds of things, I
don’t know, but that’s the closest I can see.
But I think you’re asking about cellular automata and so on. One of the things
about neural nets is, it probably isn’t the case that all of the details of neural nets—the
16-bit ﬂoating-point numbers and so on—that probably is completely unnecessary
in operation of neural nets. The question is sort of a trade-off between these things
where the model, as you run, it is very simple and efﬁcient, and the thing is readily
trainable. We don’t understand what that trade-off really looks like. What models are
both sort of structurally simple and easy to train, or is it the case that ease of training
is necessarily sort of correlated with them with having a complicated model? So we
don’t know how that works.
Genaro J. Martinez: 1. Can you decide, given a random plot, what Turing
machine belongs, and if this plot refers to a universal Turing machine? 2. What
is the limit of your Physics Project with respect to universal constructors?
Given some picture of the behavior of a Turing machine, can we guess whether
that Turing machine is universal or not? No, that’s a horrible, undecidable problem.
I think, as a sort of intuitive matter, I’ve gotten pretty good at guessing that—I don’t
think we have a systematic way to do that yet. We’ve done a bunch of experiments
with machine learning to try to identify, for example, with those tag systems, we’ve
tried using machine learning to understand about the halting times of tag systems.
So far, that was not very successful. But I think there’s more that can be done. I
don’t think that’s an exhausted kind of thing. I think machine learning is pretty bad
at identifying deep computational processes. It’s pretty good at identifying things
that we thought were hard for computers that are pretty easy for humans—in fact,
turn out to be fairly shallow computational processes, like object identiﬁcation, and
images and so on.
Another question about the limitation of our Physics Project with respect to uni-
versal constructors, I don’t know if we’ve ever talked about them, but I’ve been
interested in universal constructors for a long time. And I’m particularly interested
in practical universal constructors made of molecules. And one of the goals asks,
can we produce a thing that will make an arbitrary structure out of carbon atoms?
And I’m thinking that some of this multiway computation stuff might be relevant
to that, because that’s essentially, you know, what is the relationship between a uni-
versal constructor and universal synthetic chemistry. Chemistry is a story of trying
to construct structures: you make certain moves, can you construct this particular
structure? That’s what synthetic chemistry is about. And so, universal constructors
in a sense, it’s like, can we mimic that kind of thing computationally? Maybe I really
have not thought about this. It’s an interesting question whether with graphs we can
do better at universal construction than we’ve been able to do with things like cellular
automata. That is an interesting question. It’s a good question, should look at that.

52
S. Wolfram
A thing that I have done a little bit along these lines as I’ve been interested in
universal robotics. It’s not an easy observation about computing; computing really
took off when they were general-purpose computers. The question is, there isn’t yet
general-purpose robotics. Is there a way that we can imagine making something that
has a small number of fundamental components and that can do general-purpose
mechanical tasks?
And I for years have been interested in that question. And there was a person in
our Summer School last year who made some progress on that question, a mechani-
cal engineer from South Africa who made some progress of answering the question:
can we have these simple component parts whereby appropriate planning and pro-
gramming we can get them to perform a variety of different mechanical tasks? But
actually, you guys are asking good questions today, this is fun. That’s a good ques-
tion, whether there is a better way to think about universal construction in the case
of graphs than the case of cellular automata. There is an area of quantum mechanics
called constructor theory33 that David Deutsch has been pushing, I think. We recently
understood it’s not quite the same thing as universal constructors; it’s about how do
you construct things out of quantum-mechanical components. I think, we understand
how that works in our models. That’s a different question.
Sukanta Das: You are taking about rule 110, and you are talking about the
universal computation. But in all the cases you have considered, the lattice
size is inﬁnite. But in real cases, if you want to do computation, you have to
consider the CA size as ﬁnite. Some people, like us, we do research on cellular
automata considering the lattice size as ﬁnite. So what is your comment on the
relationship of cellular automata with ﬁnite lattice size and inﬁnite lattice size?
Universal computation and all the things you have shown in your talk, and in
your research—can you achieve all these things or some of these things using
ﬁnite cellular automata?
A Turing machine with a ﬁnite tape cannot be universal in a formal sense. The
good question is, what is the junior version of universal computation when you have
a ﬁnite tape? What does it look like, what can you do? It’s like more computational
complexity theory than computation theory. You’re asking, given a ﬁnite size, what
kinds of computations can you do? We’ve studied that a bit for some kinds of systems.
I’ve studied ﬁnite cellular automata quite a bit, studied ﬁnite Turing machines a fair
amount now. I would say that we don’t have a general theory. So this question, how
the ﬁnite-inﬁnite limit works, we don’t have a general theory of that. We can certainly
look at, for example, state transition graphs which are easy to produce in a ﬁnite case,
and we can say, “What is the limit of the state transition graph as you take the size
33 Constructor theory is a proposal for a new mode of explanation in fundamental physics, ﬁrst
sketchedoutbyDavidDeutsch,aquantumphysicistattheUniversityofOxford,in2012.Constructor
theory expresses physical laws exclusively in terms of what physical transformations, or tasks,
are possible versus which are impossible, and why. By allowing such counterfactual statements
into fundamental physics, it allows new physical laws to be expressed, for instance those of the
constructor theory of information.

Two Different Directions: John Conway and Stephen Wolfram
53
to inﬁnity?” Not very well understood—really interesting area, not particularly well
understood.
Now, I’ll show you an example of something that I was looking at recently. I was
studying combinators.34 Combinators are a simple model of computation that were
invented before Turing machines. They were invented on December 7, 1920. These
particular rewrite rules—
– s[x_][y_][z_] →x[z][y[z]];
– k[x_][y_] →x35
Combinators are very abstract things. I realized after the fact that I’ve used com-
binators in the design of Wolfram Language, and its predecessor years before, but I
haven’t really internalized combinators. So combinators, you can think of them as
being transformation rules for trees. The rule was again very simple: you can imple-
ment them in Wolfram Language. It’s a trivial one-line program. That’s the rule for
the s combinator—
– s[x_][y_][z_] →x[z][y[z]]
You can think of that as a transformation rule for a tree. So now, this is a question,
the same kind of universal computation question, we can start asking: what do these
combinators do for different initial conditions? And this is a case where what we’re
essentially doing is growing trees, and this is showing the sizes of the trees (Fig.15).
And they’re really funky cases where that’s showing tree size and so on. There are
combinators where how quickly you get these bizarre pieces of number theory that
show up (Fig.16). This is a very Conway-esque thing—going back to John Conway,
these just completely weird mathematical number-theoretical constructs coming out
of this kind of simple program.
There is a question again: is universal computation as pure as combinators? What’s
interesting about that, it’s like the rule 110 case, like the 2–3 Turing machine case.
This case can be a universal computer, but it must be operating on inﬁnite conﬁgu-
rations and inﬁnite trees. I don’t consider it. Ultimately, the universal computation
is a story of inﬁnite things. It’s a limiting story of inﬁnite things. So a good question
here, which I have not looked at is, is there a ﬁnite-size analog of combinator? Good
question, something to study, I don’t know. Combinators, unlike having a lattice,
combinators grow trees, so the question is, how do you constrain a tree to be a ﬁnite
size, and then what would it do? I don’t know. That would be a good project for
somebody at our Summer School, to look at ﬁnite combinators. It’s just something
that hasn’t been studied.
Sukanta Das: ECA (elementary cellular automata), can model so many things
in nature—you have studied and so many people have studied. But there are
34 “Combinators: A Centennial View,” by Stephen Wolfram, December 6, 2020.
35 In their original form from 1920, there were two basic combinators, s and k, which followed the
simple replacement rules. The idea was that any symbolic structure could be generated from some
combination of s’s and k’s.

54
S. Wolfram
Fig. 15 Combinators for different initial conditions
0
500
1000
1500
2000
0
10000
20000
30000
40000
50000
Fig. 16 Combinators with bizarre pieces of number theory. There are systematic peaks in the size
difference, with the nth peak having height 16487 + 3320n and occurring at step 14n2 + 59n + 284
some problems, like the ﬁring squad problem, that can’t be solved by ECA. So,
do you think that to understand the nature, or natural thing or physical system,
ECA is sufﬁcient or should we go beyond of that, maybe like ECA with more
states or dimensions?
The issue really is a trade off. I think that the 256 rules get as far as they do
in modeling systems in nature is totally remarkable to me—it’s bizarre, in fact. I’m

Two Different Directions: John Conway and Stephen Wolfram
55
standing in a room here that has a bunch of ﬁle cabinets. These ﬁle cabinets contained
papers that I used to collect on different applications of cellular automata. I had a
ﬁle folder for each rule. And, you know, all of these different rules, they’ve gotten
applications, like rule 184 model for trafﬁc ﬂow, rule 90 model for catalysis36 etc.,
etc., etc. It’s bizarre that it’s been possible to get so far with such simple rules. Can
it get everywhere? Absolutely not—not in a useful way. For example, our models
of physics have nothing to do with elementary cellular automata. There are different
kinds of model. I think that’s always a trade off. It’s like doing pure mathematics ver-
sus applied mathematics. The elementary cellular automata I was studying because
they’re the simplest case. It’s like studying pure mathematics, it’s like studying the
general theory of simple algebraic equations. Even though the equations that may
show up in some very practical situation may need to be 10 different equations, but
it’s still worth doing the pure mathematics of studying the individual simple equa-
tion. As I say, it’s remarkable how far the elementary cellular automata have been
able to get in modeling practical things. It’s kind of, they’ll more successful if you
compare them with, for example, let’s say cubic equations.37 Cubic equations have
been used to model a bunch of things. I suspect for elementary cellular automata,
you just count the number of phenomena that can be modeled; probably they win
relative to cubic equations, which is completely remarkable. But no, it will not get
you everything.
It is a very useful piece of pure mathematics in some sense, pure computational
universe science to do that. That is really amazing to me. You know, I started seeing
elementary cellular automata 40 years ago. I am amazed that there are still things that
I discover now about elementary cellular automata, which is just the craziest thing.
There’s so much depth. I’ll show you something—might be kind of fun here—the
elementarycellularautomatathatIneverlookedat,thisislookingattherulialspaceof
elementary cellular automata (Fig.17).38 So it’s looking at—if you allow all possible
rules, it’s kind of a nondeterministic cellular automaton. You allow all possible rules,
and you ask the question, starting from a single black cell what conﬁgurations can
you get to by following all possible rules? This structures I’ve never seen before,
and it’s kind of a different thing to look at cellular automata. And I didn’t really
ﬁnish looking at this. This is just the beginning of what one can do with this, but it’s
remarkable there’s that much depth. In the systems still after 40 years, there’s lots to
study, and lots of people doing interesting things on them. So I think, even though
they might not be the story of the particular way to model a particular thing, they’re
super interesting in terms of the pure basic science of what’s going on.
36 Catalysis is the process of increasing the rate of a chemical reaction by adding a substance known
as a catalyst. Catalysts are not consumed in the catalyzed reaction but can act repeatedly.
37 A cubic equation is an algebraic equation of third degree. The general form of a cubic function
is: f (x) = ax3 + bx2 + cx1 + d. And the cubic equation has the form of ax3 + bx2 + cx + d = 0,
where a, b and c are the coefﬁcients and d is the constant.
38 “Exploring Rulial Space: The Case of Turing Machines,” by Stephen Wolfram, Wolfram Physics
Bulletin, June 9, 2020.

56
S. Wolfram
Fig. 17 The rulial space of elementary cellular automata
Sukanta Das: After the late 80s, some people started working on nonuniform
cellular automata or hybrid cellular automata, where the cells in the lattice
follow different rules. We have found that most of the works on nonuniform
cellular automata, consider ECA rules. Additionally, what we have observed
under ﬁnite settings, they show some interesting property which the classical
(uniform) cellular automata can’t. Do you think this kind of nonuniformity can
handle situations which the classical ECA can’t?
It seems like an interesting thing to study. I looked at this years ago: a very, very
old paper I wrote probably 35 years back.39 This was about inhomogeneous cellular
automata. This was about cellular automata where there are combinations of different
rules. I actually looked at this in the New Kind of Science book as well.
Look, it’s a way of parameterizing. For example, you’re picking both the initial
value of a cell and which rule you use at that position, where you have a kind of a spin
glass40 of a frozen version of what rule to use at each cell. I think that’s a perfectly
39 “Approaches to Complexity Engineering,” by Stephen Wolfram, Physica D, Vol. 2, No. 1–3,
1986.
40 In condensed matter physics, a spin glass is a magnetic state characterized by randomness,
besides cooperative behavior in freezing of spins at a temperature called “freezing temperature”
Tf. Magnetic spins are, roughly speaking, the orientation of the north and south magnetic poles in
three-dimensional space.

Two Different Directions: John Conway and Stephen Wolfram
57
interesting thing to study. I’ll give you a very immediate use case. For various reasons,
I’ve been studying distributed consensus for blockchains and so on. There’s a big
trend in using cellular automata models. In particular, there’s a blockchain called
NKN (Network Infrastructure for Decentralized Internet)41 which, needless to say,
sort of aligns with NKS (A New Kind of Science). This uses a cellular automaton
approach to consensus to achieving. You mentioned the ﬁring squad problem. I
haven’t studied that particular problem very much, but this consensus problem is kind
of a junior version of that problem, so I think these questions about inhomogeneous
cellular automata may turn out to be quite interesting for distributed consensus.
I’m also interested in asynchronous graph-based models of sort of interactions that
happen there. That’s a place where these things might be applicable. Interesting stuff.
Keep studying, if you’ve been studying elementary cellular automata. There’s just
so much to ﬁgure out about them, they’re just amazing. I’m continually surprised by
things.
Supreeti Kamilya: Do you think by adding nonuniformity in a cellular
automaton, it can lose any of its properties?
It can lose its properties as a result of nonuniformity. In some sense, it behaves
differently from others. The thing I don’t understand is, using different rules is really
no different from having one rule and changing the states. You can’t do it within
elementary cellular automata but with more complicated cellular automata. Let’s
imagine we have a two-bit state at each cell, and we use one of those bits as a
control bit. And that control bit just says which rule we’re going to use. It just picks
between two rules. Then we can say, let’s have a master rule which works with both
of those rules. But we’re picking between the subcases, this master rule based on
that control bit, so we no longer have an inhomogeneous system. We now have a
system which has a single rule. But we have slightly more complicated state, slightly
more complicated rule. So I also looked at this in the NKS (A New Kind of Science)
book, actually. It’s partly a question of when can one cellular automaton behave like
another cellular automaton.
This is a possible example. You could say I’ll have a rule that is just rule 90,
basically, and they will make that pattern (Fig.18, the third one); another rule is rule
45 (Fig.18, the fourth one)—it will make that kind of pattern. But by changing the
initial conditions, we can effectively make rule 45 behave like rule 90 here (Fig.18).
So there’s the question of when can you just, by changing the initial conditions, make
one rule behave like another one? And the answer is, I’ve worked out some networks
of when one rule can behave like another. It isn’t the case that to get this sort of
inhomogeneous behavior, you have to make a more complicated rule in which you
picked different rules at different cells; it can be the case that you can get another
inhomogeneous behavior just by ﬁnding the right initial condition. So the effective
41 NKN is a new kind of peer-to-peer network connectivity protocol and ecosystem powered by a
novel public blockchain. It uses economic incentives to motivate internet users to share network
connections and utilize unused bandwidth.

58
S. Wolfram
Fig. 18 Pictures of rule 45 by changing the initial conditions (NKS book)
rule encodes this thing that has more bits. That’s something very similar to what
happens with normalization in condensed matter physics.
It’s kind of this question, when you block things together, can you get a dif-
ferent rule encoded when you’re at the lowest level of bits? The question I never
looked at: elementary cellular automata emulating elementary cellular automata. It
will be a good question: when can an elementary cellular automaton, by changing
its initial condition, emulate a four-state cellular automaton that has a control bit,
basically? That would be to try to analyze the question about inhomogeneous versus
homogeneous rules.
Supreeti Kamilya: I have seen that any nonuniform CA can be simulated by
uniform CA by increasing the number of states per cell. But there are some
uniform CA which cannot simulate any nonuniform CA. So we are confused to
declare that uniform CAs are less powerful than nonuniform CAs.
You’re saying there exist uniform cellular automata that cannot emulate any
nonuniform cellular automata. I’m going to say something outrageous, which is that
I don’t believe you could possibly prove that. Here’s why: to know that you cannot
have a block of any length in the initial data that can lead to something, I think, that
will be undecidable, whether that’s possible. That is, there will be no upper bound
on this. If you don’t have an upper bound on the size of blocks that you’re using to
encode every individual bit, I don’t think you can know what an upper bound is on
the size of block you might need to use to get an emulation. So this is a network of
which elementary cellular automata can emulate which elementary cellular automata
with blocks up to length 8 (Fig.19). I have no idea—if I allow blocks up to length
100, I have no idea what this picture would look like, and I claim you don’t know.
Because, I think, it’s an undecidable problem. For example, if you ask the question,
can some particular rule here, can rule 54 ever emulate rule 110 with blocks of any
size, I don’t think that’s a question that is readily answerable. I mean, if you ﬁnd an
emulation, then yes, you got the answer, but to prove that it can’t emulate, I think it’s
very hard. So maybe I misunderstood. I suspect your result will be something where
you require blocks of only a ﬁxed size. By the way, that’s a terriﬁc topic, I’m glad
you’ve studied it, because it’s a very interesting topic. I think extending this picture
for larger block sizes will be interesting—and I will try to make, in fact, now I think

Two Different Directions: John Conway and Stephen Wolfram
59
Fig. 19 A network of which elementary cellular automata can emulate which elementary cellular
automata with blocks up to length 8 (NKS book)
about it, I bet we could use automated theorem proving42 to try and establish—that’s
a good idea.
Kamalika Bhattacharjee: What is your view, whether nonuniform CA can be
less powerful than uniform CA—the ﬁnite case we’re talking about?
What do we mean by “more powerful”? Look, I really haven’t looked at nonuni-
form cellular automata. I think the built-in CellularAutomaton function in Wolfram
Language is not going to do a good job. Let’s see—can we make a nonuniform CA
quickly? Here’s a question for you. The state transition graphs for ﬁnite nonuniform
cellular automata—I’ve never looked at those, probably you guys have looked at
those. What can you say about the structures that arise?
So, that is rule 30 on its own (Fig.20, left) that’s showing there are many identical
states. It’s kind of, it’s got many copies. But what’s happening here is, we’re saying
it’s an inhomogeneous cellular automaton, but the inhomogeneity is not really an
inhomogeneity because every state works the same. Now what we’re doing is, we’re
42 Automated theorem proving (also known as ATP or automated deduction) is a subﬁeld of auto-
mated reasoning and mathematical logic dealing with proving mathematical theorems by computer
programs. Automated reasoning over mathematical proof was a major impetus for the development
of computer science.

60
S. Wolfram
Fig. 20 A state transition diagram: homogeneous rule 30 (left), inhomogeneous rule 30 and 90
(right). CA size 4
Fig. 21 A state transition diagram: inhomogeneous rules 30 and 90, CA size 5 (left), CA size 6
(right)
looking at two different rules, 30 and 90, and we’re asking what does the state
transition graph look like in that case (Fig.20, right). Let’s do the obvious thing—for
example, we can try looking at it for size n. I don’t know how big we can get it, but
let’s just try with n = 5. So, that’s now the inhomogeneous cellular automata. Kind
of interesting, actually, that you get from rule 30 and 90 (Fig.21, left).
Let’s try one more level up. This is going to give us the cycles (inhomogeneous
rules 30 and 90, CA size 6, Fig.21, right). Now, if we did this for rule 30 itself, that’s
the structure, and it’s sort of interesting. If we did this for rule 30 on its own, we will
get a lot of identical elements. So this is the ordinary state transition graph for rule 30,
CA size 6 (Fig.22, left). We go to much larger sizes, size 12. One thing we see here is
there are multiple identical copies of the same structure (Fig.22, right), whereas here

Two Different Directions: John Conway and Stephen Wolfram
61
Fig. 22 A state transition diagram: homogeneous rule 30, CA size 6 (left), CA size 12 (right)
Fig. 23 Partial state transition diagrams for all possible inhomogeneous cellular automata on a
size-5 lattice using two different rules
in this inhomogeneous case (Fig.21, right), it looks like we’re not getting identical
copies, and the reason for that must be the symmetry breaking. There’s some group
operation that we can’t do in this case.
Let’s look at—just for fun, let’s look at what happens for all possible cases. So this
is now the state transition diagram for all possible inhomogeneous cellular automata
on a size-5 lattice that use two different rules (Fig.23). So here, when the two rules
are the same, we see lots of symmetry, and when the rules are different, we’re seeing
less symmetry. So that’s kind of a ﬁrst observation, I don’t know what else. This is
how I would start to analyze these inhomogeneous cellular automata. This is periodic
boundary conditions that I was using here. I’m sort of assuming that what’s going to
happen here is that, there’s lots of group symmetries in these cases here, and those

62
S. Wolfram
Fig. 24 Partial state transition diagrams for inhomogeneous cellular automata with rules 90, 18,
22, 30, 110 and 73 on a size-5 lattice using two different rules
symmetries get broken when they’re inhomogeneous systems. You could kind of
analyze—one thing that might be interesting to analyze is the way that symmetry
breaks down as you add inhomogeneity. I’ve never looked at these before. This is
cool. These are very trivial—perhaps we could look at some favorite rules. Let’s just
look for fun. Let’s look at rules 90, 18, 22, 30, 110, 73. Let’s look at those—those
are pairs of rules. This is not too exciting (Fig.24). This is just the ﬁve minute start,
but has a much more interesting project to do for real.
Fasel Qadir: In binary ECA, there are 256 rules. Those lead to 256 patterns.
Is there any way to have only 256 rules to get a similar 256 patterns of binary
ECA in color version? And if we get that, what will be its impact on CA? Or
binary ECA is sufﬁcient.
I have looked at that a bit. The question is, if you want a given pattern, what is the
minimal rule that you need to get that pattern? So, for example, I looked at that—let
me show you that.
By the way, this is an interesting case. This is different cellular automata that
all achieve the objective of doubling the size of their input (Fig.25). They’re like
many different cellular automata—all in a sense do the same thing, but their rules
are different.

Two Different Directions: John Conway and Stephen Wolfram
63
Fig. 25 Different cellular automata that all achieve the objective of doubling the size of their input
(NKS book)
But what I was looking for is—this is kind of interesting and deserves more
study—so this is asking (Fig.26). if you want to get a particular sequence of values
on the center column, what is the minimal rule that you have to use to get that
particular sequence of values? This is sort of asking the question, if you are going
to get the same kinds of values as you get in elementary cellular automata, what are
the minimal, let’s say, three-color rules that will give you that?
Ashish Kumar: Are the pockets of computational reducibility in the sea of
computational irreducibility reducing with time? So will the heat death of the
universe be a completely irreducible state? Are there explanations for dark
matter and dark energy in your theory of physics, and also some experimen-
tally testable predictions? How is it we humans as computationally irreducible
systems are able to, in a sense, navigate this landscape of reducibility?
The heat death of the universe is misunderstood. See, what happens is, people
say, you’ve got all these atoms bouncing around, and they get to a state that seems
completely random to us. So we say it’s the heat death of the universe. But that’s
completely wrong. The only reason the atoms look boring and there was no structure
to them, because the only thing we’re measuring is something like the overall pressure
of the gas. If we tracked every single molecule, we wouldn’t conclude there was any
heat death at all. We would just say, look at all these interesting things that are
happening in these particular atoms. So in a sense, the idea of the heat death of the
universe is given our current view of the large-scale structure of gases. But will we

64
S. Wolfram
Fig. 26 Minimal cellular automata for sequences (NKS book)
see interesting things for all time? The answer is no. But the thing is that, if we look
at different features, we will see continuously interesting things.
But maybe you’re asking a slightly different question, you’re asking a more
sophisticated question. I apologize, you’re asking questions—right now, we think
that the gas is getting less interesting, because we’re looking at certain computation-
ally reducible features of it. The question you’re asking is, I think—will the set of
reducible features drill down to nothing after a sufﬁciently long time? And the answer
is, I don’t know, because I don’t know what the set of possible reducible features is.
That’s really a question of what are the set of all possible perception mechanisms,
and I don’t yet have a way to think about that, but it’s a really good question.
The other explanations, for dark matter and dark energy in your theory of physics
and also some experimentally testable predictions—I actually wrote about that at
some length. I wrote a blog post last week on the ﬁrst anniversary of our Physics
Project, where I explored these questions about experimental implications. There’s
a whole bunch of experimental implications, and I refer you to that.
Now, “How is it we humans as computationally irreducible systems are able to in
a sense navigate this landscape of reducibility?” I think the fact that we can predict

Two Different Directions: John Conway and Stephen Wolfram
65
anything about what’s going to happen is a consequence of the fact that we are
slicing our way into these areas of reducibility. So just to give a sense of that, I wrote
something very recently about it. This is a post about consciousness and its role in
understanding fundamental physics and its relationship to that.43 The notion that we
have—there is a deﬁnite thread of experience with time that turns out to seep into a
lot of understanding of physics.
Nazma Naskar: The CA that converges to a single point has various appli-
cations in computer technology. Can convergence study of ECAs be a study of
the convergence phenomenon of nature? Can we get a better understanding of
physical systems by adding nonuniformity?
We talked a bit about this. I think this whole question about some ﬁxed points,
that would be an obvious thing to ask for nonuniform cellular automata, we see a
little bit of that. Let’s look at one particular case. Let’s look at this (Figs.23 and
24). So, almost all of these go to ﬁxed points. Almost none of these seem to go to
cycle—one goes to cycle there, but almost all of these are going to ﬁxed points. I
don’t know whether that’s an interesting question—whether it’s more common to
get ﬁxed points with inhomogeneous cellular automata. Good question to answer. I
don’t know the answer.
Sreeya Ghosh: Is there any ECA rule to represent DNA evolution?
DNA evolution. In the modern version of Wolfram Language, there’s lots of data
of bio sequences, a lot of capability to deal with bio-sequences. That would be a good
place to start to explore. My guess is that people believe that DNA sequences are
randomly mutated. Probably that’s not true. But I’ve never seen a good study from
all of the different pieces of the tree of life, to the extent there’s randomness or not.
Sumit Adak: My research area is maximal-length CAs that are ﬁnite CAs of
length n which can generate a cycle of length 2n−1. A special such CA is CA
(90′), where the ﬁrst cell follows rule 150 and the rest of the cells follow rule
90. However, we can get the same-type cycle structure of CA(90′) with size n
for uniform rule 90 of size 2n. As an example, the cycle structure of a 3-cell
CA (90′) (rule vector = (150, 90, 90)) is similar to that of 6-cell uniform rule
90 (rule vector = (90, 90, 90, 90, 90, 90)). For some speciﬁc n, the characteristic
polynomial of CA (90′) is primitive. My question is whether ECA 90 under a
null boundary condition can also generate a primitive polynomial?
That’s very interesting. Cool, I have not looked at that. I hope you publish that; it
sounds like a very useful thing. Because, for example, for generating random numbers
you want to have longer cycle lengths. I know that people have looked at this. But
43 “What
Is
Consciousness?
Some
New
Perspectives
from
Our
Physics
Project,”
by
Stephen Wolfram, https://writings.stephenwolfram.com/2021/03/what-is-consciousness-some-
new-perspectives-from-our-physics-project.

66
S. Wolfram
using inhomogeneous cellular automata as random number generators might be an
interesting thing to do. And you’re telling me something which I didn’t know, which
is by adding just one inhomogeneous cell, effectively one weird boundary condition
cell, you can make the thing maximal length. I think what you’re asking here—I
made this algebraic analysis of cellular automata for rule 90 and things like that—
I think maybe you’re asking the inhomogeneous case. Well, you know, usually in
the algebraic analysis, the way you implement the boundary conditions, it is with
polynomial modulus—type stuff. I would guess that there will be a way of doing
that, there will be a way of representing inhomogeneity and algebraic formulation.
Sukanya Mukherjee: Actually, from the experimental observations, we found
that for a given n, n-cell non-uniform cellular automata can generate all primes
as cycle lengths. Can classical CAs also show the same behavior? We have
checked for nonuniform CAs.
That brings me to something which I was interested in for a long time. In the
theory of iterative maps, there’s thing called Sharkovskii’s theorem.44 Sharkovskii’s
theorem says in an interactive map, if you have a certain sequence of periods, that
you can get an interactive map, and as soon as you have a period of length 3, you
have all other possible periods.
The question for different cellular automata (Fig.27), given a particular period 1,
2, 3, 4, . . . whatever, does there exist an initial condition which gives that period?
Which is your question—in a given size, is that a cycle of that given period? So
the question is, can we generalize Sharkovskii’s theorem to cellular automata, and
can we show that, if there exists a given set of periods, there must necessarily exist
certain other periods? That will be the question.
You’re telling something I certainly didn’t know: you can generate all primes
as cycle lengths. I didn’t know that. That sounds like something Sharkovskii’s
theorem—I tried to prove a generalization Sharkovskii’s theorem for cellular
automata. I didn’t succeed. I think it can be done, I just wasn’t able to do it.
Kamalika Bhattacharjee: One of the applications of randomness is pseudo-
random number generators (PRNGs). These are ﬁnite systems, and there are
several statistical test-beds that can detect nonrandomness in the sequence gen-
erated by such a PRNG. I had tested rule 30 on such test-beds, and I have
observed that it fails in certain tests. However, if we take the case of Mersenne
twisters and its variants, they are passing some of these tests. So do you think
local computation in CA is creating a hindrance to its randomness quality? Can
a locally interactive simple system be really random? There exist some CAs,
e.g. decimal CAs, which pass those tests. Our hypothesis is by increasing the
44 In mathematics, Sharkovskii’s theorem, named after Oleksandr Mykolaiovych Sharkovskii, who
published it in 1964, is a result about discrete dynamical systems. One of the implications of the
theorem is that if a discrete dynamical system on the real line has a periodic point of period 3, then
it must have periodic points of every other period.

Two Different Directions: John Conway and Stephen Wolfram
67
Fig. 27 Cellular automata with particular period 1, 2, 3, 4, . . . (NKS book)
number of states of the CAs, we can improve the randomness quality. What is
your comment on that?
You’ve looked at rule 30 and it fails certain tests for pseudorandomness. It will be
interesting to see that because in all the tests we’ve ever done, we’ve never found one
that failed. So, when we thought it had failed, the mistake was in our test, and not in
the rule. If you found one that fails, you found something very interesting, because
you found a regularity. We’ve never found a regularity in that sequence.
Raju Hazari: The implication of conservation law in a physical system is
well known—whether the conservative CAs can play a more important role in
studying universal computability?

68
S. Wolfram
Conservation laws in cellular automata—I’ve studied those a bit, and more to be
done on those for sure. I did discuss that conservation law in the NKS (A New Kind of
Science) book. But Noether’s theorem for continuous symmetries and conservation
laws45—that will be interesting to look at the analog of that in cellular automata.
I am pretty sure that there is such a thing, but I wasn’t able to ﬁnd it. I found
certain conservation laws, I was looking for what rules conserve—for example, total
value and things like that, but there’s so much more to do with this. Studying what
conservation laws exist is something really interesting to do.
Souvik Roy: During the last decade, the CA researchers have proposed
different kinds of asynchronism, like fully asynchronous cellular automata,
α-β-γ asynchronous cellular automata, delay sensitive cellular automata, m-
asynchronouscellularautomata.Moreover,non-uniformcellularautomata(dif-
ferent rules with different probability) can also be viewed as asynchronous ones.
Now, for me and many others, one of the greatest motivations of doing research
on asynchronous cellular automata or choosing models of asynchronous cellu-
lar automata is—it feels that asynchronous versions of cellular automata are
more close to nature. So, what do you think? What kind of asynchronous model
of cellular automata is able to capture the natural system more closely? Or are
synchronous cellular automata as powerful at capturing this natural system?
The issue with asynchronous cellular automata—I would recommend for asyn-
chronous cellular automata, look at the multiway case of cellular automata. I started
doing just a tiny bit with this. One thing is, asynchronous words just randomly
updates, but the multiway cases, looking at all possible sequences of updates, I
think that will be very interesting—and I did. This is one of our hypergraph systems
(Fig.28), made to emulate a cellular automaton. In this case, it’s completely deter-
ministic, and we can look at all of the stuff with causal graphs and foliation and all
this kind of thing. But all we have to do is add another case to the rule, and this will
become a nondeterministic cellular automaton, and then we can study the multiway
graph of nondeterministic cellular automata. I very strongly recommend looking at
that. I think, you know, the problem with asynchronous things, it’s sort of just picking
randomly; you’re just spraying a bunch of randomness into the system. I think it’s
more interesting. I would recommend looking at this multiway case.
Kamalika Bhattacharjee: In your work, you chose rule 30 over rule 45. Now,
both these two ECAs are surjective for inﬁnite conﬁgurations, but not injective.
Whereas, if we take ﬁnite size, then rule 30 is irreversible, but rule 45 is reversible
45 Noether’s theorem, or Noether’s ﬁrst theorem, states that every differentiable symmetry of the
action of a physical system with conservative forces has a corresponding conservation law. The
theorem was proven by mathematician Emmy Noether in 1915 and published in 1918, after a
special case was proven by E. Cosserat and F. Cosserat in 1909. The action of a physical system is
the integral over time of a Lagrangian function, from which the system’s behavior can be determined
by the principle of least action. This theorem only applies to continuous and smooth symmetries
over physical space.

Two Different Directions: John Conway and Stephen Wolfram
69
Fig. 28 Hypergraph systems made to emulate a cellular automaton (deterministic)
for odd lattice sizes. We call such CAs as semi-reversible CAs. The CAs which
are reversible for all CA sizes are very simple CAs, belonging to class II, I guess.
Whereas the semi-reversible CAs and surjective-but-irreversible CAs are not
that simple. Do you think going from reversible toward strictly irreversible (but
surjective off-course) CAs improves randomness quality, making the CAs more
chaotic in some sense?
I chose rule 30 over rule 45—that’s just because it doesn’t have the stripy back-
ground, it’s not for a good reason.
I don’t know, I mean one of the issues is, if you have a system which is forced to
go on a longest-possible cycle, probably induces some regularities. I don’t entirely
understand how those regularities work, but my feeling is, for example, a linear
feedback shift register, a maximal-length feedback shift register, we know that there
are lots of regularities, and they are probably the result of the fact that it’s maximal
length. But it will be very interesting to study the relationship between maximal
length and local regularities in the sequence. My intuition would be that, as you
get really close to maximal length, you will start getting other regularities in the
sequence. There is a sweet spot between longer periods, but not yet hitting sort of
regularity, and having something that is much more irreversible. I don’t know.
Kamalika Bhattacharjee: In the case of reversibility, we have observed that
if an ECA is reversible for some ﬁnite lattice sizes, say 1–8, we can predict
what will be its reversibility behavior for inﬁnite lattice size. This observation
is true for any other CAs. But we have not been able to prove it yet. But for the
number conservation property of CAs, a similar kind of theorem is there. Now,
we want your comment on this: from observation of behavior of ﬁnite CAs, can
we predict about the behavior of inﬁnite CAs for the same rule?
Yes, there is a proof of this in the NKS (A New Kind of Science) book of this
fact. So this is a proof that, if you test ﬁnite blocks up to a certain size, that will
be sufﬁcient to test reversibility for all sizes. That’s true for one dimension; it’s not
true for two dimensions. In two dimensions, this is undecidable—reversibility is
undecidable because there’s no upper bound on the size of the block.
Sukanya Mukherjee: Is the problem of ﬁnding out cycle structure of any
arbitrary CA NP-complete? Give your comment.

70
S. Wolfram
I think it’s a PSPACE-complete46—if I remember correctly, it’s been a long time
since I thought about this. I did discuss this also in the NKS (A New Kind of Science)
book. I think the problem of inverting a cellular automaton is in general NP-complete,
and the problem of ﬁnding cycle structure, I’m pretty sure, is PSPACE-complete.
Souvik Roy: During the last two decades, starting with the work of Zielonka,
many CA researchers have explored distributed system problems (the leader
election problem, the spanning tree problem, the shortest path problem) as a CA
computational task or modeling distributed systems by using cellular automata.
But most of the time, the algorithms or CA are complex: d-state, complex rules.
Is this a problem of human centralized thinking? In general, What you think
about the “nature of computation”? Does nature follow the way rule 110 does,
or the classical way?
Look, this point about the fact that people have found very complicated cellular
automata that do things, they probably built those in an engineering way. The question
of what’s the minimal cellular automaton that does these things is a really interesting
one. We see, for example, even in the case of sorting networks,47 the minimal sorting
network for a size 11—you know, a size-11 sorting network is very complicated.
The question of what the minimal such thing is, the algorithmic complexity minimal
program is a different question for “can you construct a program for doing this”?
And that’s a sort of a separate issue.
8
Concluding Remarks
Keep on studying cellular automata, because there’s an inﬁnite amount to learn about
them. I just want to say that one of the amazing things about cellular automata—
even though I’m into cellular automata—is that they’re minimal models, and you
can be basically guarantee that at some point in the future, if you ﬁnd an interesting
property of a minimal model, someday somebody’s going to need that result. And the
only challenge that we have is organizing those results well enough that people will
ﬁnd them when they need them. I think this is something that perhaps the cellular
automaton community could do a better job of. I’ve thought about making these
various archives of cellular automata, properties and things; I’ve done a little bit
on that. It’s like, you know, you’ll discover something this year, and 20 years from
46 In computational complexity theory, a decision problem is PSPACE-complete if it can be solved
using an amount of memory that is polynomial in the input length (polynomial space) and if every
other problem that can be solved in polynomial space can be transformed to it in polynomial time.
47 In computer science, comparator networks are abstract devices built up of a ﬁxed number of
“wires” carrying values, and comparator modules that connect pairs of wires, swapping the values
on the wires if they are not in a desired order. Such networks are typically designed to perform
sorting on ﬁxed numbers of values, in which case they are called sorting networks.

Two Different Directions: John Conway and Stephen Wolfram
71
now somebody will be studying some VLSI48 or other related problem, and they’ll
be going to use some elementary cellular automata to do that, and they wonder—
somebody has studied the question of under what circumstances they are reversible,
somesortofthinglikethat.Youknow,it’ssortofinevitablethat,whenyou’restudying
these minimal models, they’re going to be important at some point in the future. The
only question is to make sure you write about them in a clear enough way that they
can be understood later and found, because it may not be the case—it’s just like pure
mathematics. You know, a bunch of the mathematics that we’re using right now in
our Physics Project, some of it is very modern, but some of it is from one hundred
years ago, and that mathematics didn’t get used, it didn’t get applied any time from
one hundred years ago to till now, and now we’re applying it. In some cases, it’s very
challenging to ﬁnd that mathematics that was quite hidden. For example, the theory
of combinators, a big, big effort to understand everything that people have written
about that over the last hundred years, and make use of that. But again, these minimal
things are inexorably important, and that’s the great thing about cellular automata.
Stephen Wolfram is a pioneering scientist, physicist and author of A New Kind of Science whose
work created a paradigm shift in cellular automata research.
He published his ﬁrst scientiﬁc paper at the age of 15, and received his Ph.D. in theoretical
physics from the California Institute of Technology on November 19, 1979, at the age of 20. In
recognition of his early work in physics and computing, Wolfram became the youngest recipient
of the MacArthur Fellowship in 1981.
Stephen Wolfram is the founder and CEO Wolfram Research, and the creator of Mathemat-
ica, Wolfram|Alpha and the Wolfram Language. In 2013, he was named a fellow of the American
Mathematical Society. He writes regularly about his activities and thinking on his Stephen Wol-
fram Writings site.
48 Very large-scale integration (VLSI) is the process of creating an integrated circuit (IC) by combin-
ing millions of MOS transistors onto a single chip. VLSI began in the 1970s when MOS-integrated
circuit chips were widely adopted, enabling complex semiconductor and telecommunication tech-
nologies to be developed.

Conway Memorial Series: The
Mathematical Artist of Play
R. Ramanujam
Last year when Conway passed away, I wrote an article in ‘At Right Angles’ with
title “The Mathematical Artist of Play: A Tribute to John Horton Conway”.1 I am
not an expert on Conway, rather I put myself in the Conway Fan Club.
Therewereacoupleof occasions whereI couldtalktochildrenandschool teachers
about Conway. Since there is a lot of discussion on the Game of Life and Cellular
automaton in other talks of this lecture series, I am not going to talk about Game
of Life here. Rather, I thought I would talk about the other things about Conway. In
particular, Combinatorial Game Theory,2 which I didn’t see as one of the topics in
this lecture series, so I am going to talk about that.
1
A Personal Encounter
Let me begin with a personal encounter. It was in 1996, when I was spending a month
in Rutgers University at New Brunswick campus, New Jersey. There was a workshop
happening on partial order based veriﬁcation in Princeton, and I was participating
1R. Ramanujam. The Mathematical Artist of Play: A Tribute to John Horton Conway. At Right
Angles, pp. 6–10. Azim Premji University, July 2020.
2 Combinatorial game theory (CGT) is a branch of mathematics and theoretical computer science
that typically studies sequential games with perfect information. Study has been largely conﬁned
to two-player games that have a position that the players take turns changing in deﬁned ways or
moves to achieve a deﬁned winning condition. CGT has not traditionally studied games of chance
or those that use imperfect or incomplete information, favoring games that offer perfect information
in which the state of the game and the set of available moves is always known by both players.
R. Ramanujam (B)
The Institute of Mathematical Sciences, Chennai, India
e-mail: jam@imsc.res.in
© The Author(s), under exclusive license to Springer Nature Switzerland AG 2022
S. Das et al. (eds.), The Mathematical Artist, Emergence,
Complexity and Computation 45, https://doi.org/10.1007/978-3-031-03986-7_3
73

74
R. Ramanujam
in that workshop. I was staying at Rutgers and I had to go to the workshop. So, I
was standing around one of the bus stops, waiting for a bus. It was some Sunday
morning, and I was standing and reading some book, waiting for a bus. Nothing
happened, bus was not coming. I could see people passing by looking at me. And
then, suddenly one car stopped, asked “Hey, are you waiting for a bus?”, I said “Yes”,
he said “Well, no service on Sundays”. The gentleman looked at me and said “Can
I drop you somewhere?” That’s great, so I got in and said “If you can drop me at
the railway station”, it’s just outside the Rutgers campus, New Brunswick railway
station, “that will be great”. He said “OK, I will do that, but where are you going to
go?” I said “Well, I will take a train to Princeton junction”. He said “Princeton? Are
you going for the University?”. I said “Yes, that’s where I am going”. He said “You
are in luck, that’s where I am going too. So I will give you a ride”. I said “That’s
great”, and then he turned around and said, “I am John Conway”.
That was the encounter. It was a tremendous pleasure for me; I was completely
stunned to encounter John Conway like that. It was a wonderful forty ﬁve minutes
ride, and all he talked about was the problems. After I introduced myself that I am
from Theoretical Computer Science, he started talking about graph theory and some
problems. I asked him about partial orders, I was working on that at that time. So
he started talking about partial order. It was a lot of fun. And he dropped me at the
workshop in Princeton, and told me about a couple of lectures he would be giving
that week. I had an opportunity; in fact, I bunked the next day’s workshop to attend
Conway’s lecture in Princeton.
That was a personal introduction. A very warm and a very interesting personality,
completely open, and I mean, since, I read a lot about Conway’s work, his life, talk
to other people who have worked with him, as a personality quite amazing. He is
always willing to interact with any one—you just approach him with problems and
the problem should be interesting.
Here is a quotation, the quote I like very much from Stephen Miller, one of tributes
after Conway passed away last year.
People said he was the only mathematician who could do things with his own bare hands –
Stephen Miller, Rutgers University.
What he is talking about is the fact that Conway always liked to start from the ﬁrst
principles, with very very few concepts and build mathematical ediﬁces. And he was
very good at that. Unlike mathematicians who like to work on very deep theorems,
Conway worked on many things which are very low, to the sense that to understand
a question it does not need, kind of, deep mathematics. Many mathematicians call
this—Elementary techniques but here elementary does not mean ‘easy’. It means
techniques where, you know, Conway always likes to jump in, look at things, this
is something Robert Wilson talked about last week,3 how he insisted on looking at
something in a very very simple manner and building stuff by own hands. This was
an amazing characteristic of John Conway. Here, he is (Fig.1), you can see a branch
of magnetic rods put together in some particular fashion. In fact the lecture I had
3 Chapter 1.

Conway Memorial Series: The Mathematical Artist of Play
75
Fig. 1 John Conway (Credit: Dith Pran/NYT/Redux/eyevine)
attended at Princeton, the ﬁrst one that I had attended, he worked with something like
this(Fig.1).Hejustputtheminfrontoftheaudience,askedquestionsaboutit,andone
such object is the beginning of the talk. And the lecture was about the construction
of the mathematical object. But in the process, there is so much combinatorics,
probability, number theory, so many things that came in, again this is very special
about Conway.
He was famous for, you know, (he) loved to play games, including analysis games
and real games—children’s games. He would go around during summer attending
mathematics camps for children, school children, discuss problems with them, pose
and solve puzzles. He would carry decks of cards, dice, ropes, coins, coat hangers,
some-times a slinky, even a miniature toy bicycle. That is another great thing about
Conway.
2
The Nim Game
He is one of the founders of Combinatorial Game Theory. Now, we are talking about
not only playing games, but reasoning about games. He starts with real games that
people play, and this is very important for combinatorial games. Combinatorial game
theory typically talks about two-player games, turn-based games (one after another,

76
R. Ramanujam
players taking turns) of perfect information, not like cards, and are often bipartisan
games, where the set of choices available to both players is identical. Let us brieﬂy
discuss one such game. This is what, in the name of Sprague and Grundy, called
“Sprague Grundy Theory”,4 and sort of games that Conway liked a lot.
There is a ﬁlm called “Last Year at Marienbad” by Alan Resnais. In this ﬁlm,
there is a character called ‘M’, who carries a branch of cards, and is always trying
to persuade another to play a card with him.
– Cards are arranged in rows of 1-card, 3-cards, 5-cards, 7-cards etc.
– The idea is, they take turns. What you do is, when it is your turn, you pick any
row, say you take 5-cards row, and you can remove any number of cards. You can
remove all ﬁve cards, you can remove one card, two cards, three cards, whatever.
And, then it is, my turn. I take. We keep doing this, and the one who takes the last
card wins.
– Now, M is always polite, lets the other person start. The other person always loses.
This is the Nim game. Nim is from the German word nehmen, it was analyzed in
1904 by C. L. Bouton of Havard University. That is how the game goes.
– Two players I and II move alternatively.
– and, instead of cards, lets take piles of counters, there are m piles of counters.
– and, what a player does is, when the other moves, she picks a pile, and removes
some non-zero many counters from that pile. You have to remove some number
of counters from the pile.
– and when a player can not move, he loses, and the other person wins.
It is a very simple win-loss game of two players, how do you play the game like
that? Of course game should be played, but unfortunately, with this online platform,
it’s difﬁcult, so I am not going to do that. But mathematically, how do you represent
the game?
Every game has three main ingredients.
– The set of players, often {I, II}. In general [n] = {1, 2, . . . , n}.
– Now, what will be the rules of the game? Rules of the game specify at any game
position, whose turn it is to move. You can say, ﬁrst is player I’s turn, then player
II, then again player I, after that II, like that. So, at each time, what are the all
moves which are applicable? For instance, there are ﬁve piles, you can pick one
of the piles, that’s a choice you have, and after that, in that pile if there are ki
counters, you remove some non-zero number from that, and that results in a new
game decision.
4 In combinatorial game theory, the Sprague–Grundy theorem states that every impartial game under
the normal play convention is equivalent to a one-heap game of Nim, or to an inﬁnite generalization
of Nim. It can therefore be represented as a natural number, the size of the heap in its equivalent game
of Nim, as an ordinal number in the inﬁnite generalization, or alternatively as a nimber, the value
of that one-heap game in an algebraic system whose addition operation combines multiple heaps
to form a single equivalent heap in Nim. The Sprague–Grundy theorem and its proof encapsulate
the main results of a theory discovered independently by R. P. Sprague (1935) and P. M. Grundy
(1939).

Conway Memorial Series: The Mathematical Artist of Play
77
– Keep doing this. Then outcomes or wining conditions, specify at which position
the game is over, and perhaps depending on the course of play, the outcome at
those position.
Now, I am talking about a win-loss game—how do we represent a game like this?
The most natural representation you can think about is, as a tree, right?
You can think of it as a tree, where nodes of the tree are game positions, and when
a player makes a move, that is an edge of the tree. The root is the initial game position,
and the branching degree tells you, ﬁrst Player I’s choice of moves, each of them
resulting in a new position, and then at each node Player II’s move is in the branches,
it keeps going down. Notice that, since you are forced to move a non-zero number
of counters at every point, and you started with m piles, each having k1, k2, . . . , km
counters, every path (in tree) the number is going to decrease, and the leaf node is
decorated with who wins, Player I or II. So, a ﬁnite tree, completely describes the
moves of the players.
This is the idea. Every such game can be represented as a ﬁnite tree. Every tree
non-leaf node is labeled with Player I or II because one of them is making a move,
and every leaf node says the outcome. Now once you have tree representation like
this, there is a theorem by Zermelo (1913), which says, in every ﬁnite extensive form
game of perfect information, we can compute whether the player I can win (or not).
It is fairly simple because, by backward induction, we already know at leaf node
who wins. Now look at node which is just above leaf node, take any non-leaf node
whose all children are leaves, take that non-leaf node, suppose that’s Player I’s turn
to move, now, any one of the children is winning for Player I, Player I can chose that
particular edge, and can win. If all the children of that node says Player II wins, no
matter what Player I does, Player II will win. So, I can decide these non-leaf nodes
as a win for either Player I or Player II. That’s it. Inductively when you pick any
non-leaf node, for all the children of them, you are having a decision, therefore for
that particular node also you are having a decision. Keep going up to the root, you
will ﬁnd who will win—Player I or II. So, backward induction shows who wins,
gives a winning strategy in the case of win/lose games. As it is a ﬁnite tree, therefore
backward induction applies.
This is a fantastic thing because you have an algorithm to compute the winning
strategy, and the algorithm is of linear time, because we just have to visit up tall
nodes only once. Backward induction completely solves ﬁnite extensive form games
of perfect information—we might as well go home. So, the Nim game is completely
solved, isn’t it?
Now, this is a point, if we are only interested in the existence of winning strategy,
this sufﬁces. If we also wish to look at the structure of strategies, this leaves us quite
unsatisﬁed. In fact, in the case of Nim, if you just do some combinatorial analysis,
you ﬁnd that there is so much more.
Now, consider the game, let’s say (1, 1, 2), that means, here is a heap which has
only one counter, another heap with one counter, and a third heap with two counters.
Now, your turn, what will you do?

78
R. Ramanujam
If I take two, then you will take one, then the last card will be taken by me. So, I
will win.
Suppose you remove one of two, now, it’s left with (1, 1, 1). Now my turn, I will
remove one of them, which means you left with (1, 1, −), if you remove one of them,
Yes, I am the winner. I am the last person.
– Basically, it is easy to see that removing one from the heap with two counters is
not a good idea.
– But removing all counters from the heap works.
– We can call—(1, 1, 2) is a winning position (for whoever plays) and (1, 1) is
a losing position (for whoever plays). If you are faced with (1, 1,), no matter,
whatever you take, you will lose. So, we don’t have to worry about whose turn to
move, we can simply label position as winning position and losing position.
Similarly, we can see (1, 1, 1) is a winning position and (1, 1) is a losing posi-
tion. Now, what about k-tuples (1, 1, . . . , 1). Suppose I am giving you a k tuples
of (1, 1, . . . , 1), it is easy to see, it is a winning position if k is odd: the fact that
(1, 1, 1) is a winning position and (1, 1,) is a losing position, the same argument in
fact applies for any tuple of 1’s where number of 1 is odd and number of 1 is even.
So, exactly the same logic applies. This is the joy of combinatorics.
Now, consider the case of two heaps (m, n) where you have, (it’s a special case,) m
counters and n counters, suppose m = n = 4, whatever move Player I plays on one
heap, Player II can copy that move on the other heap, (4, 4,). Suppose you remove 2,
I will respond with removing 2, i.e (2, 2). You keep on doing this, and at some point
it comes to (1, 1). This is a losing position for Player I. It is clear that by copying
each strategy, when m = n, you can show it’s losing for Player I. On the other hand,
suppose m > n. If it’s my turn to move, what’s my strategy? I just remove larger
numbers from one of them, and represent you as an equal size which, I know, is a
losing position. So, you will lose. That means, if the two heaps are equal, Player II
has a winning strategy, if two heaps are unequal, Player I has a winning strategy.
Let’s state this as a Lemma.
Lemma 1 For all m, n ⩾0, (m, n) is winning if and only if m ̸= n.
Now, if I am with three or more heaps, analysis becomes difﬁcult. Suppose, look
at (2, 3, 6) for instance, horrible, too many choices. But then, a little lemma, we had.
– Observe that every ﬁnite extensive form game (say Nim) is of the form 0 or there
are several, you know, you have a choice of m subgames, g1 + g2 + · · · + gm. It is
a tree with no node at all or it has got a root node with m subgames. So, the move
I make, it’s going to be put into one of the m subgames. Let me think of it as 0 to
represent the root node, and the choice into the m subgames as g1 + g2 + · · · + gm
where they are all subgames.
– 0 can be thought of as the empty game in which no player can make any move.
This is using numbers, and talking about games as numbers is something Con-
way did. There is a lot more to this. Now, choosing between subgames has a very

Conway Memorial Series: The Mathematical Artist of Play
79
interesting algebraic structure. Suppose you have a game g with m subgames and a
game h with another n subgames.
– Suppose g = g1 + g2 + · · · + gm
– Also suppose h = h1 + h2 + · · · + hn
Now, I can deﬁne an ‘addition’ operation on the two games, I build a new game
where I can make a choice to go into game g or game h, going to play both games.
What does it mean? Either I go into the left game, in which case, I am going into one
of g1 or g2 or gm and keeping h alive, or going into the h game, in which case, I am
going into one of the subgames of h1 to hn, and keeping g alive. That’s come out—
g + h = (g1 + h) + · · · + (gm + h) + (g + h1) + · · · + (g + hn)
This is a very interesting sum operation. This suggests the notation (1, 3, 6) for
the Nim game I am able to write as 1 + 3 + 6. Another notation, I will use—say g
is a subgame of h, we write g ⩽h because these are things we are familiar with.
We are familiar with using additions, numbers, using ordering, let’s see them in the
games. Once we have game expressions, we are writing ‘x plus this plus that etc.’, a
natural question arises—when do we consider two games g and g′ to be equivalent?
I want to write equations on these, and solve them, that’s what we usually do, right?
Let’s focus on Nim. The deﬁnition is this.
Deﬁnition 1 g1 ≡g2 if for all h, g1 + h is winning (losing) if and only if g2 + h is
winning (losing).
Basically, two games are equivalent if whenever placed in the context of any game
at all, the winning and losing behavior does not change. Why, this particular thing?
You really have to spend time thinking of many deﬁnitions and theorems, and ﬁnally
you will see that this is in fact the right deﬁnition. Another thing I will talk about on
Conway is, he spent lots of lots of time with deﬁnitions, playing around with them.
– You can check, ≡is indeed an equivalence relation.
– You can check, g + 0 = g.
Therefore, if g1 ≡g2 then g1 is winning if and only if g2 is winning. But the
converse is not true. However, all losing games are equivalent to 0. This is something
called Loser’s lemma.
Lemma 2 If g is losing then g ≡0.
Now, ﬁx a losing game g, (1, 1) is a losing game or (m, m). We will prove that,
for all h, g + h is losing if and only if h is losing.
– We prove by induction on h that whenever h is losing, that is, if you take a losing
game and add something to it, it remains a losing game, that is g + h.

80
R. Ramanujam
– Assuming this, the other direction is easy. Suppose h is winning. Then there is a
move to h′ that’s losing, right? We know that. By above claim, g + h′ is losing.
Hence, there is a winning move in g + h, and hence g + h is winning. So, very
simple argument tells you that.
What is this we have got? We have got, if h is a losing game for all g, g + h = g.
This means that every losing subgame can be ignored. That’s the beauty. If we have
a losing subgame that is there, intuitively it makes sense right? I am at a node of
a game and I know there is a subtree which is losing. Who cares! going into that
subgame is of no interest for me at all.
Let us use this knowledge to analyze 1 + 2 + 3 + 4 + 5. We have no idea how
to solve this game. Now, consider 1 + 2 + 3. This is a subgame right? Now, in this,
removing an entire heap leads to a winning position because we know that, in two
heaps the numbers are unequal. Reducing any heap leads to two equal heaps which
are losing and can be ignored. Therefore, no point of reducing any heap at all, right?
Whereas, removing an entire heap leads to a winning position. Therefore, the position
1 + 2 + 3 is a losing position. Now we have got a subtree which is losing, and we
can ignore it.
We know that 4 + 5 is winning, we already see, in two heap games where the
numbers are unequal is a winning position, so 4 + 5 is a winning position, 1 + 2 + 3
is a losing position, and can be ignored. Therefore, 1 + 2 + 3 + 4 + 5 is winning.
Can we get some more general mileage than analyzing simple Nim heaps. Can we
go beyond this? Now, there is a strategy that works for this and for that you have to
answer a question.
– How do you ensure that you do not lose in a chess game against a Grandmaster?
– Do you have any strategy for that?
I mean, if you want to play a game against Carlsen (Magnus Carlsen), what will
you do? You want some strategy to make sure that you will play well. At least, try
for a draw. So, what I will do if I challenge Viswanathan Anand in a game, and I
play two games simultaneously. One game I am playing with Anand, and the other
game I am playing with Carlsen.
Let’s say Carlsen makes the a ﬁrst move, he placed white, now I have to respond
black, right? Now I play white in the game against Anand, what is the move I will
play?ImovewhatCarlsenmade,soIplaythatmove.Now,Anandisgoingtoresponse
with something, here, in black, I play that black piece move to Carlsen. Carlsen must
respond something with on that, in white, which I play to Anand. Basically, Anand
and Carlsen are killing each other. This is called a Copycat strategy.
The Copycat strategy is using one’s strategy from one game, using it on another.
Now, that’s a very interesting strategy. That exactly what is needed to simplify the
analysis of Nim. We can now enunciate an important principle of bipartisan games.
Actually, this type of copycat strategy works beautifully on any bipartition game.
Bipartition means both player have the same set of choices. The following lemma is
very simple, it says,
Lemma 3 g + g ≡0

Conway Memorial Series: The Mathematical Artist of Play
81
That is, here is an addition. What does it mean? You take any game g, assume
that the claim holds for all subgames g′ ⩽g. Now, what does a move in g + g look
like? It is of the form of some subgames, g′ + g, right? Any move will take you to
g′ + g because one of them you make a move, g′ + g or g + g′. Now, we know this is
winning because the move to the subgame g′ + g′ is losing by induction hypothesis.
Why? Because in g′ + g, you can always copy the move that you took for g to g′.
That move I can copy as the other game is also from g. Therefore I can reduce it to
g′, and present with a losing position. If g′ + g is a winning position, the original
game g + g is a losing position. And we know all losing games are equivalent to 0.
Therefore, g + g ≡0. That is, g + g a losing and by loser’s lemma, equivalent to 0.
Therefore, g + g ≡0. This is it.
So, basically the class of games with addition forms an Abelian group. Here,
commutativity and associativity are very easy to see. And, 0 is the natural element.
We have also seen, every element has an inverse, and as we have just seen, has itself
as inverse. Now, the beautiful algebraic structure here, I hope, is reminiscent of some
very familiar algebraic structure!
Now, I hope you can see that once you brought this (g + g ≡0), you can simplify
the analysis of any game. The Nim game can be completely solved. That’s what we
have seen in a glimpse of the Spraque—Grundy theorem of impartial games, and
Conway took this much further. There is a beautiful book called “On Numbers and
Games” by Conway. So what he shows is that,
– There is a distinguished sub groups of game called numbers which can also be
multiplicative. That’s a more complicated operation, I shall not take it up. Actually
what you get is a ﬁeld. So, you get not only addition, you also get multiplication,
and you get a ﬁeld.
– And, this ﬁeld contains both the real numbers and the ordinal numbers.
– In fact, Conway’s deﬁnition generalizes both Dedekind cuts5 and von-Neumann
ordinals.6
5 In mathematics, Dedekind cuts, named after German mathematician Richard Dedekind but pre-
viously considered by Joseph Bertrand, are a method of construction of the real numbers from the
rational numbers. A Dedekind cut is a partition of the rational numbers into two sets A and B, such
that all elements of A are less than all elements of B, and A contains no greatest element. The set
B may or may not have a smallest element among the rationals. If B has a smallest element among
the rationals, the cut corresponds to that rational. Otherwise, that cut deﬁnes a unique irrational
number which, loosely speaking, ﬁlls the “gap” between A and B. In other words, A contains every
rational number less than the cut, and B contains every rational number greater than or equal to the
cut. An irrational cut is equated to an irrational number which is in neither set. Every real number,
rational or not, is equated to one and only one cut of rationals.
6 The von Neumann ordinal α is deﬁned to be the well-ordered set containing the von Neumann
ordinals which precede α. The set of ﬁnite von Neumann ordinals is known as the von Neumann
integers. Every well-ordered set is isomorphic to a von Neumann ordinal. They can be constructed
by transﬁnite recursion as follows:
– The empty set is 0.
– Given any ordinal α, the ordinal α + 1 (the successor of α) is deﬁned to be α∪{ α }.
– Given a set A of ordinals, 
a∈A a is an ordinal.

82
R. Ramanujam
– In this little book called “On Numbers and Gamers”, he built an entire universe
of beautiful micro-cosmos of numbers and games. So, what are called numbers
here, are games there. Equivalent classes of games are called numbers, and in
that he sets up the entire von-Neumann ordinal construction—numbers which are
inﬁnitesimally close to zero, ones which are inﬁnitely large.
– Donald Knuth wrote a novel called ‘Surreal Numbers’, he called them ‘surreal’
because in this, Conway’s numbers, every real number is surrounded by a whole
lot of new numbers that lie closer to it than any other ‘real’ value does.
The construction is absolutely fabulous. Again, I remember, I was in New York, I
saw this slim book in the library for the ﬁrst time, games and numbers, ten years ago.
It’s beautiful construction, and one of the brilliant pieces of work that Conway did
on the foundation of Mathematics, and he did it purely for the joy of construction, to
show it is possible. Now, can we do analysis on it, this particular Universe? I don’t
know how you do analysis, but the point is, it is rich. Knuth’s novel is also something
I enjoy reading. I strongly recommend that.
3
Beyond Combinatorial Game Theory
Other things that Conway did, (let’s) just (have) a quick journey to many things.
Another beautiful problem Conway worked on 1960s, he worked on Sphere packing.
The question is, I take a region on the Euclidean plane, and I want to ﬁt as many
circles as possible into that region. How do you go about it? The idea that turns out
the best way, you just divide the plane into one big hexagonal grid, and circumscribe
the largest possible circle inside each hexagon. This gives the hexagonal lattice.
Now, you can generalize this to a sphere, that is the sphere packing problem in
three dimensions. Now, Leech in 1960s deﬁned a lattice, which he showed was the
most efﬁcient in packing of 24-dimensional spheres in 24-dimensional space. We
are talking about circles in two dimensions, spheres in three dimensions, it’s about
24 dimension. What can you think about the 24-dimension? But what Conway did.
Conway studied the symmetry group of the Leech lattice,7 and he came up with,
which is known as the Conway group8 now. Conway’s writing and interviews, if you
7 In mathematics, the Leech lattice is an even unimodular lattice ∧24 in 24-dimensional Euclidean
space, which is one of the best models for the kissing number problem. It was discovered by John
Leech (1967). It may also have been discovered (but not published) by Ernst Witt in 1940. The
Leech lattice ∧24 is the unique lattice in 24-dimensional Euclidean space, E24, with the following
list of properties:
• It is unimodular; i.e., it can be generated by the columns of a certain 24 × 24 matrix with
determinant 1.
• It is even; i.e., the square of the length of each vector in ∧24 is an even integer.
• The length of every non-zero vector in ∧24 is at least 2.
8 In the area of modern algebra known as group theory, the Conway groups are the three sporadic
simple groups Co1, Co2 and Co3 along with the related ﬁnite group Co0 introduced by (Conway

Conway Memorial Series: The Mathematical Artist of Play
83
see, there is a sense of wonder at that group, he said, this is something not beautiful
because, this kind of symmetry is never seen. He said, how do you even ambition
such a thing in 24-dimensional space.
I think Prof. Robert Wilson talked about this last week, this is the Monster group.9
In 1979, Conway and Norton wrote a conjecture on the relationship between proper-
ties of the so-called Monster group and j-function. Now, it’s a collection of symme-
tries that appear in 196, 883-dimensional space, and the paper was called Monstrous
Moonshine, and later Conway got Borcherds Fields Medal in 1998 for providing the
conjecture.
Conway’s contribution to knot theory,10 knot can be thought of as a closed loop
of string. The fundamental problem in Knot theory is that, if I take two knots, can I
apply ﬁnitely many allowed operations to obtain one from another? and we can call
it equivalent. Now, mathematics has come up with many tests, which is, if applying
it on a pair of knots leads to different knots, then the pair is not equivalent. Alexander
polynomials give you an efﬁcient procedure but not unique. Then Conway came up
with a procedure both efﬁcient and unique and these are called Conway Polynomials.
There is the whole theory around this, and Conway also gave an arrangement of
fundamental Knots which makes it easier to study.
But, Conway toured to many many different areas. Last week Prof. Robert Wilson
talked about Quantum mechanics and Free Will Theorem, an amazing piece of work
again that Conway was involved in. This Free Will Theorem says, even if you had
the information about the states of every particle in the universe up to this point, you
would not be able to predict what their state will be a second from now. I don’t even
know enough about it to explain things.
To sum up, Conway contributed to many many areas of mathematics:
– Theory of ﬁnite groups, classiﬁcation of ﬁnite groups, number theory.
– Combinatorial game theory, as I mentioned, he is one of the founders of combi-
natorial game theory, coding theory.
– Geometry, geometric topology, algebra, analysis.
– Graph theory, algorithms
1968, 1969). The largest of the Conway groups, Co0, is the group of automorphisms of the Leech
lattice ∧with respect to addition and inner product. It has order 8, 315, 553, 613, 086, 720, 000, but
it is not a simple group. The simple group Co1 of order 4, 157, 776, 806, 543, 360, 000 is deﬁned
as the quotient of Co0 by its center, which consists of the scalar matrices ±1.
9 In the area of abstract algebra known as group theory, the monster group M (also
known as the Fischer-Griess monster, or the friendly giant) is the largest sporadic sim-
ple group, having order 246· 320· 59· 76· 112· 133· 17 · 19 · 23 · 29 · 31 · 41 · 47 · 59 · 71
= 808, 017, 424, 794, 512, 875, 886, 459, 904, 961, 710, 757, 005, 754, 368, 000, 000, 000 ≈8 ×
1053.
10 In topology, knot theory is the study of mathematical knots. While inspired by knots which
appear in daily life, such as those in shoelaces and rope, a mathematical knot differs in that the ends
are joined together so that it cannot be undone, the simplest knot being a ring (or “unknot”). In
mathematical language, a knot is an embedding of a circle in 3-dimensional Euclidean space, R3 (in
topology, a circle isn’t bound to the classical geometric concept, but to all of its homeomorphisms).

84
R. Ramanujam
– Quantum Mechanics
– And, last but not the least, Cellular Automata, in fact Game of Life.
Surprising range of contribution in one lifetime for any mathematician, such a
repute, that Conway has done.
One thing that I want to end with: Conway was known for this obsession for
reducing proofs to the simplest term. Again, Prof. Robert Wilson focuses on that,
you know, uncompromising insistence on simplicity. One paper that I like a lot
is by Karamzadeh in 2014 where he tries to argue that Conway proves not only
theorems, in fact his target was towards the simplest possible proofs. How do you
prove that it’s the simplest possible proof? He (Karamzadeh) actually undertakes this
task that Conway’s proof of Morley’s theorem11 is the “simplest possible” proof.
Conway and Shipman wrote a beautiful article called ‘Extreme Proofs’.12 Look at
the kind of values which you can associate with a proof, they talk about brevity,
generality, constructiveness, visuality, nonvisuality, surprise, elementarity and so on.
Theyactuallygivesevenproofsofirrationalityof
√
2.Istronglyencourageeverybody
to read this. Amazing paper. We all learned that
√
2 is irrational. There was one proof
that every child in school can repeat, suppose it is rational, then there are no common
devices, and you go through this whole exercise, but what are the other ways of doing
it? They want to look at what are the simplest proofs possible, and in the sense that
they used—the least number of axioms, least axioms, and it’s very interesting, I will
quote from that paper.
Indeed, because at any given time there are only ﬁnitely many known proofs, we may think
of them as lying in a polyhedron (in our pictures, a polygon), and the value functions as
linear functionals, as in optimization theory, so that any value function must be maximized
at some vertex. We shall call the proofs at the vertices of this polygon the extreme proofs. –
Conway and Shipman, 2013
Finally, they have deﬁned it, they attached values, which are linear functionals,
and give you some way of measuring proofs. Let me end with quote from Siobhan
Roberts, Conway’s biographer, I also recommend everybody to read this biography,
basically in an interview, where both of them are present,
John bills himself at once as a “know-at-all” – he wants to know absolutely everything, that
is his goal in life – and as a “professional non-understander”, since on most subjects he starts
from a place of not knowing. But the nature of his pursuit is very meandering, following one
tangent after another in his playfully circuitous way. – Siobhan Roberts.
So this playful approach is very very characteristic of Conway, playing with
notions, playing with deﬁnition, playing with ideas. That’s all. Thank you. Time for
discussion.
11 In plane geometry, Morley’s trisector theorem states that in any triangle, the three points of
intersection of the adjacent angle trisectors form an equilateral triangle, called the ﬁrst Morley
triangle or simply the Morley triangle. The theorem was discovered in 1899 by Anglo-American
mathematician Frank Morley. It has various generalizations; in particular, if all of the trisectors are
intersected, one obtains four other equilateral triangles.
12 Conway, J.H., Shipman, J. Extreme Proofs I: The Irrationality of
√
2. Math Intelligencer 35, 2–7
(2013). https://doi.org/10.1007/s00283-013-9373-9.

Conway Memorial Series: The Mathematical Artist of Play
85
4
Interaction with R. Ramanujam
Kamalika Bhattacharjee: When you met Conway for the ﬁrst time, you said
that you didn’t know him, right? you didn’t know his face. From his interview,
he seems like a very sophisticated person, was he very sophisticated in real
life?
I had never seen a picture of him, and also I think, at that time, the book ‘On
Numbers and Games’ I almost fell in love with. That was the ‘80s probably. I had
seen some papers, I heard some of Conway’s work, but not very much.
I should say, he was someone I never saw, and he was giving me a ride, right? and
basically, it started with—‘Where are you going?’ and I was telling him about the
workshop, and the moment he heard ‘theoretical computer science’, then he said you
should be interested in problems, then it was just problems, discussing problems. I
think, he loved discussing problems with school children to anybody—anybody who
is interested in problems.
Kamalika Bhattacharjee: Jam, in your lecture, you have used this term math-
ematical artist, why do you call Conway a mathematical artist?
Actually, that’s from Conway’s one interview, I think that came out in New York
Times, he didn’t call himself a mathematical artist, but then he tries to argue that
you would think mathematics as an art, much more an art than a science. And doing
mathematics is like doing art, and so, he strongly believes that a mathematician is an
artist, that comes through so much from his work, and aesthetics is very very impor-
tant for him, symmetry is very important, the constructions are very very elegant,
and the simplicity—there is much of similarity between an artist and him.
Mihir K. Chakraborty: You remember I asked Prof. Wilson about Conway’s
philosophical position, he really didn’t answer, but what you said, he def-
initely, perhaps not that explicitly, but deﬁnitely, he had some philosophy
about mathematics.
On the philosophical front, in fact, Conway described himself as a philosophi-
cal mathematician; I can’t remember precisely where he said that. The interviewer
says, you describe yourself as a philosophical mathematician, what do you think
of this?—there the whole thing starts. But, last week one asked about the course
that Conway taught on philosophical mathematics. In fact, I have read article of
another mathematician, he is from Cambridge, when Conway passed away there
was a tribute Princeton organized, one said he attended that course. It was basically
Forcing13 remember this was late 60s, Paul Cohen’s result had come out, mathemati-
cian were very much interested on that. Basically Conway wanted to teach forcing,
13 In the mathematical discipline of set theory, forcing is a technique for proving consistency and
independence results. It was ﬁrst used by Paul Cohen in 1963, to prove the independence of the
axiom of choice and the continuum hypothesis from Zermelo–Fraenkel set theory.
Forcing has been considerably reworked and simpliﬁed in the following years, and has since
served as a powerful technique, both in set theory and in areas of mathematical logic such as

86
R. Ramanujam
Conway used this opportunity to try and understand forcing. But, I told you about
’On Numbers and Games’, that is not the foundation of mathematics, right? He actu-
ally developed the entire system. For him, the foundation is again mathematical in
that sense—you don’t have philosophies about it, it should be again mathematical. I
think that spirit should come across.
Comment by Mihir K. Chakraborty: We can perhaps derive some philosophy out
of his work. Though he explicitly did not say, but because of doing numbers that
way, somebody can derive anything. He is actually playing with numbers in an
unusual way, very unusual way. Actually, I know Conway really from some of
the philosophical writing by somebody who had written about the foundation of
mathematics, interpreting numbers in a different way.
But art is something he does talk about at least, that doing mathematics is art to
him that he talks about.
Comment by Mihir K. Chakraborty: That, of course, deﬁnitely, is a different kind
of art. But when it is an art, it doesn’t have necessary connection with truth,
that is the issue, you know, with the philosophy of foundation. It was connected
to the philosophy of mathematics, those who were unrealistic that way in the
philosophical position, want to have some mathematics generally different from
usual facts. That means, the mathematical statements being true or false make
something different from truth and falsehood of other kind of statements. For
instance, if somebody says, angle sum of a triangle is two right angles, what is the
meaning of the truth of this statement? So, I most probably read about Conway
through some such writing where the author mentioned Conway’s game theoretic
interpretation of numbers. That is how I got to know about Conway for the ﬁrst
time.
Souvik Roy: Conway loved to attend the mathematics camps with school chil-
dren (one for 12−13 years old and another for 17−19 years old, every year).
As far as I know, you are also very much interested in working with school
children on mathematics. So, what is your comment on the impact of orga-
nizing mathematics camps for school children in a mathematician’s life? If
you share your personal experience.
The thing is that, I think that kind of interaction is precisely enriching, for me
at least, I can talk about my personal experience of many many years. Now, I have
been interacting with school children of different age group in mathematics camp,
science camp, science fair. You know, children project a sudden freshness, a sudden
new approach which we forget, we all have in us, but we forget because we are
trained in a very particular way, and it’s very hard for us to think about problems in a
different way. Bare hand approach, I have mentioned. I work in a particular area—I
recursion theory. Descriptive set theory uses the notions of forcing from both recursion theory and
set theory. Forcing has also been used in model theory, but it is common in model theory to deﬁne
genericity directly without mention of forcing.

Conway Memorial Series: The Mathematical Artist of Play
87
am very comfortable with logic and automata theory, I try to attempt automata and
logical mechanisms in all problems. I think that’s natural. Then what happened to
all that bit of number theory I learned, bit of this I learned, bit of that I learned, it’s
all there somewhere, right? Now, when you start with geometry with children, doing
algebra or number theory, coding theory, I remember doing any of these, it opens
up pathways that are completely new, I am not saying it immediately gives you new
problems for tomorrow. That may not happen, but when you do very quickly come
across problems that are very hard, very difﬁcult, and kind of insight that are needed
to solve the problem.
My favorite example that I like to take, is one of these things suddenly relevant
to class nine child is also a problem to me, he found, show that ﬁve thousand ﬁve
hundred and ﬁfty ﬁve rise to two thousand two hundred and twenty two plus two
thousand two hundred and twenty two rise to ﬁve thousand ﬁve hundred and ﬁfty
ﬁve is divisible by seven.
Show that 55552222 + 22225555 is divisible by 7
This is what I mean, when you do. Now this is not a hard problem, but it’s a difﬁcult
problem. When you look at a problem like that, how do you approach a problem?
Of course you realize that nobody expect you to compute the numbers, and to ﬁnd
out it is divisible by seven, you have to use some general function. What is the form
you are going to use at that point? First write ab + ba, well that will take you very
far, but if you are looking at an + bn then there is some construction pushing your
head. Now, somebody tries these problems, tries various things, now what other thing
you can try? This is what I mean—working out problems like this (is how) actually
children work on, freeze your mind, and it makes you accept lots of ideas, makes
you accept many many technique, and after all, in all mathematical works ﬁnally you
are always grappling this—in between forms and context, right? Looking at form
and context, and then looking at many different forms, I think that precisely working
with children helps. I don’t know if this is a good answer, I have no idea for Conway,
but he said, you know, Conway was very much interested in posing puzzles, creating
new puzzles, then solving them, and asking children to pose puzzle to him. I have
no idea how he felt during that, but that clearly he enjoyed that, is very very clear.
Souvik Roy: What you think about the computational ability of the thought
process of children? When we think about problems, we somehow think in a
centralized manner like the Turing machine or shored instruction set archi-
tecture. Is there any possibility of any other computational model or point of
view to explore from the children thought process. Obviously, if we consider
Game of Life or cellular automata, there is no centralized control, when chil-
dren try to solve a problem, is there any decentralized computation going on
in the background.
I think that’s an extremely difﬁcult question to answer. I think analyzing how
strategies are used by children is something that we know very little about. From
experience I can say many things, but in terms of doing science from that, to actually

88
R. Ramanujam
understand the space of strategies, and how they analyze. By the way, in general
when it comes to game theory, understanding strategy spaces is something we have
for very very small class of combinatorial games. In general game theory is very
hard, for most of the games we only talk about existence of optimal strategies. What
you are talking about is actually composing those strategies in the head, we know
very little about that, we know very little about the mathematics of that. That’s one
comment.
When it comes to real human beings and how they do, in fact we know very
little about that. Even with all the advances of neuroscience, I hear about people
doing some experiments, but I must say that they are quite primitive, we don’t know
anything sophisticated enough to talk about any kind of computational model, we
can hypothesize some.
But on decentralized control, even if we start with Turing machine, even if we
break up the cells of Turing machine to just autonomous entity, and we came up,
there is a theorem, we can proof that what they can compute is exactly Turing
machine can compute, Turing machine is so robust, that in terms of computational
power we can not change very much, but part of the learning that we had during
last 70-80 years, it just that it might be better to have such forms of machines where
in terms of computational power may not change, but in the mechanism, the way
they operate, they may give you insight., like cellular automata give you insight,
the circuit model of computation equivalent to Turing machine with very different
kind of insights. It depends on what you want to prove. I would say, if you talking
about navigating strategy spaces, what kind of computational model appropriate for
it, I don’t know a answer to this, not even seen any answer in the literature. But I
understand something, the way you compose things, basically those are algebraic
structures, where those operators we understand very less—strategy composition is
something we understand very less.
Sukanta Das: What you are saying is that, Conway was interested in work-
ing with children in mathematics camp. The point Souvik was asking, as I
understood, is, the children, say Class I school children, they learned some
mathematics—like addition, subtraction, then learned GCD, etc. They have
some learning process, and what they do—we observed they have some kind
of computational ability. They learned addition, subtraction in a special way,
and they applied that knowledge to ﬁnd some other thing, like when they
learned GCD, they used the previous knowledge of division, multiplication,
addition etc., in this way, step by step they learned. Now, if somebody asks
me to ﬁnd some GCD, what we do, we just recall the procedure.
I understand what you are saying. I was talking about the problem solving strate-
gies of children, and I was saying the space of strategies that children used for solving
problems, that’s something very difﬁcult and needs to be explored.
What about computational algorithm that children use? Now, I did lot of work on
what we call folk mathematics, the informal mathematics used in everyday life of
ordinary people. Hope you know that farmers look at the ﬁeld and estimate, like, right
now, for instance in March or April in India, it’s very common to observe Mangoes,

Conway Memorial Series: The Mathematical Artist of Play
89
before the mangoes starts fruiting, they actually take the lease, and offer a quote. How
do you quote? You look at the trees and make an estimate—how many mangoes you
are likely to get, look at the ﬂowers, the ﬂowering tree, and you make a guess, you
use an algorithm because it’s money after all. You don’t quote randomly, because if
you quote too much and get too few, then you will make a loss. If you quote too low,
you get the extra. So you have to quote optimally, and people follow algorithms to
answer. This one is called folk mathematics. If we go to a shop for instance, you buy
something for sixty two rupees, and you give a hundred rupees note, the shopkeeper
doesn’t subtract and give you thirty eight rupees. He starts giving you some money,
say ok seventy, then ten, then twenty, then say hundred. Now, if I ask the person
how much you gave, he doesn’t know, but he knows it’s correct, he gave. So, people
follow many different algorithms.
But for children it’s a little complicated because what we do in school is to give
privilege a particular algorithm, and make you forget all other algorithms that you
have in mind. In fact, the moment you got to school. In fact, ask somebody in the
streets what is twenty time six, the person may think, twenty time ﬁve is hundred,
plus twenty, hundred and twenty may be, do something like that, but once you go to
school, you realize if it is twenty times six, you must put twenty in the top, write six
in the bottom, then start following the algorithm. I afraid, in fact, the sad part is that
the computational algorithm you ﬁnd from children associated with school become
very limited, because you are trained to follow the textbook, one algorithm that has
been taught. That’s one. Of course many children think of their own, they came up
with new, but new algorithm, I have seen some, very few, computational algorithm
of various kinds, I have not seen one which follows decentralized control.
Sukanta Das: What you have said is, the algorithms children do in school is
in one way, and Game of Life’s working principle is, as I understood, a bit
different. So my question is how do people like Conway, who works with chil-
dren, who tries to understand the thought process of children, and invented
the Game of Life, how they match? In case of Game of Life, traditional algo-
rithms do not work. Do you have any comments on this?
I think that, in some sense, you have to take a game for what it is, right? If you start
doing games with hidden agenda, it will illustrate at some point, so do not worry,
you can not go very far with that. It should be a game, playing the game should be
interesting for its own sake, and puzzles should be worthwhile solving for its own
sake. And that’s the golden principle because they are trained to smell this hidden
agenda. So, that only disturbs the original thinking process. But the point is that
game playing is mathematics, because after all game playing involves strategizing,
and coming up with strategies that applied in many different context. If you can
articulated it inside your head, and actually perform that, that’s really, I don’t know
what Conway think, that’s really the link, and that moment you are really playing
with ideas, playing with numbers, playing with formulas, playing with shapes and
forms, playing with geometry, and some of them have the power to encapsulate the
whole universe, like Game of Life.

90
R. Ramanujam
Genaro J. Martinez: In combinatorial game theory, what about undecidable
problems?
There are lots of undecidable problems. The Nim game is very very simple, but
there are many games that are very easy to set up, you can practically take any
of those two player games that you see on mobiles. For, almost all of them, you
can try to do combinatorial analysis, and very often you will ﬁnd a word problem,
which is undecidable. If I take two game expressions and ask if they are equal, that’s
undecidable. In fact, it is very easy to come up with games which are associated with
group structures where the problem is undecidable. Many of those challenges are
to come up with simple ones that you can solve. Of Course Conway was a genius,
coming up with that kind of simplicity, I don’t know where he got this from. But the
rules very often become very hard, there is a project internationally to classify these.
Let me talk about problems complete for NP, P-space, and so on classes. Games are
also complete for different numbers of classes. So, you not only have at the top level
of beauty and incompatibility, but all the way down, we are very far from that and it
is very interesting.
R. Ramanujam is a retired Professor in the Theoretical Computer Science wing of The Insti-
tute of Mathematical Sciences, Chennai, India. His research interests include mathematical and
philosophical logic in computer science, theory of computation and their applications to theory
of distributed systems, game theory and security. He is currently on the editorial board of ACM
Transactions on Computational Logic. Homepage: https://www.imsc.res.in/r_ramanujam.

Invited Articles
This part includes ﬁve articles on cellular automata (CAs), Game of Life, and Algo-
rithmic Information Dynamics (AID). It starts with the article by Genaro J. Martinez
and his collaborators which is based on his talk in our lecture series. The next article,
written by Kenichi Morita, depicts several fantastic phenomena and properties of the
glider in Game of Life and how using them a reversible Turing machine can be formed
inthecellularspaceofanelementarytriangularpartitionedcellularautomaton (CA),
named ETPCA 0347. In the following article, Pedro P B d Oliveira, Thiago de Mattos,
and Eurico Ruivo propose a new kind of deterministic asynchronism, where the cells
of a CA are necessarily updated just once during any time step, and show a complete
characterization of the resultant unique dynamics for elementary cellular automata.
Sukanta Das contributed an article where Game of Life, a computational system, and
Athenian democracy, an ancient direct democracy, are compared from an abstract
point of view, ﬁnally proposing an abstract idea of a new model of computation. The
next article is from Hector Zenil and Alyssa Adams, where they beautifully describe
an application of AID to CA demonstrating how this digital calculus is able to quan-
tify change in discrete dynamical systems. This section ends with an article by Carter
Bays where Game of Life and its properties are explored over three dimensions along
with two-dimensional versions in the triangular and hexagonal grids.

Some Notes About the Game of Life
Cellular Automaton
Genaro J. Martínez, Andrew Adamatzky, and Juan C. Seck-Tuoh-Mora
Abstract This is a short review of selected results related to John Conway’s Game of
Life cellular automaton. The review is based on our participation in the “A Tribute to
Conway: A Lectures Series on the Memory of John Horton Conway” (https://youtu.
be/WqKkmfOt9Ww), celebrated virtually in India and organized by Sukanta Das
and Kamalika Bhattacharjee in 2020. Additional contributions are made by Andrew
Adamatzky and Juan C. Seck-Tuoh-Mora.
Keywords John H. Conway · Game of Life · Life-like rules · Cellular automata ·
Gliders
1
The Game of Life
The Game of Life is an elegant, simple and compact semi-totalistic function that
brings together artiﬁcial life, complex system, emergent behavior and non-linear
systems. The Game of Life cellular automaton is the most famous rule into the
cellular automata literature and one of the most researched during most of 50 years.
There are two excellent repositories where you can explore any Life objects and
recently discovered Life patterns and complex structures: Conway’s Game of Life
http://www.conwaylife.com/ and LifeWiki https://www.conwaylife.com/wiki/.
G. J. Martínez (B)
Artiﬁcial Life Robotics Lab, Escuela Superior de Cómputo, Instituto Politécnico Nacional,
Mexico City, Mexico
e-mail: gjuarezm@ipn.mx; genaro.martinez@uwe.ac.uk
G. J. Martínez · A. Adamatzky
Unconventional Computing Lab, University of the West of England, Bristol, United Kingdom
e-mail: andrew.adamatzky@uwe.ac.uk
J. C. Seck-Tuoh-Mora
Area Académica de Ingeniería y Arquitectura, ICBI, Universidad Autónoma del Estado de
Hidalgo, Hidalgo, Mexico
e-mail: jseck@uaeh.edu.mx
© The Author(s), under exclusive license to Springer Nature Switzerland AG 2022
S. Das et al. (eds.), The Mathematical Artist, Emergence,
Complexity and Computation 45, https://doi.org/10.1007/978-3-031-03986-7_4
93

94
G. J. Martínez et al.
Between 1969 and 1970 Conway designed and published his famous two-
dimensional cellular automaton “The Game of Life” in the popular column of Sci-
entiﬁc American edited by Martin Garden [14].
The Game of Life is recognized as the second important stage in the cellular
automata literature after John von Neumann self-assembling machines (see [23]).
Main difference between von Neumann and Conway automata is the kind of function,
while von Neumann used an orthogonal neighbourhood, Conways used an isotropic
relation in two dimensions, it is the Moore neighbourhood. The Game of Life uses
a binary alphabet  = {0, 1}, where state one depicts alive organisms and state zero
nothingness (empty space).
The Game of Life is the evolution (semi-totalistic) rule R(2333) (Carter Bays
notation) or B3/S23. The rule belongs satisﬁes the following conditions.
Birth:
an empty cell adjacent to exactly 3 neighbours is a birth cell the next
time.
Survival:
a live cell with 2 or 3 neighbouring counters survives for the next gen-
eration.
Death:
a cell with 4 or more neighbours dies (becomes empty) from overpopu-
lation. Every live cell counter with 1 neighbour or none dies (becomes
empty) from isolation.
Conwayproposedtwocharacteristicsthatwerekeytoinducenon-trivialbehaviour
in the Game of Life.
• The function will not disappear quickly (equilibrium).
• The function will grow forever (expansion).
This combination would produce a number of active cells with possibilities of
interacting in different landscapes. So, several patterns were proposed and the acorn1
pattern was one of the most interesting conﬁgurations, found in 1971. A role of the
acornpatternishistoricallyimportantinthesearchofuniverseofsmallconﬁgurations
with unpredictable evolution.
Acorn is an excellent example where a simple (compact) pattern can evolve to
patterns with a non-trivial behaviour in long span of time. Figure1a illustrates the
acorn pattern shaped by seven cells in state one in the lattice of 3 × 7 cells. In Fig.1b
we can see the density history during its evolution which grew quasi-constantly
before reaching its stability. So, Fig.1c presents a three-dimensional projection of
this acorn evolution concatenating every two-dimensional plane successively, where
chaotic regions do not stop or emerge and some few gliders escape from the central
area. Acorn evolution reached its stability in generation 5206 with a ﬁnal population
of 633 cells.
Particularly, David Eppstein speciﬁes that Wolfram’s classes can be related as
patterns [11].
1 https://www.conwaylife.com/wiki/Acorn.

Some Notes About the Game of Life Cellular Automaton
95
(a)
(b)
(c)
Fig. 1 a Acorn pattern shaped by seven cells in state one. b History density evolution of acorn. c
Three-dimensional projection of acorn evolution (a video of this evolution is available from https://
youtu.be/NADVWj1-KS4)
1. Evolution leads to a homogeneous state.
2. Evolution leads to a set of separated simple stable or periodic structures.
3. Evolution leads to a chaotic pattern.
4. Evolution leads to complex localized structures, sometimes long-lived.
In this direction, the Game of Life belongs to class 4 where well-deﬁned mobile,
periodic or stable localized structures emerge during evolution. A way to try to
understand this characterization is with the mean ﬁeld approximation proposed by

96
G. J. Martínez et al.
Fig. 2 Mean ﬁeld curve for
the Game of Life
pt
pt+1
Howard Gutowitz [17]. Mean ﬁeld approximation is a useful tool which calculates
averages of intervals assigningprobabilities toeachelement of thealphabet expressed
as a polynomial. This approximation assumes that the elements are independent.
This way, across the number of ﬁxed points Harold V. McIntosh characterized this
classiﬁcation as follows [22]:
1. Monotonic, entirely on one side of the diagonal.
2. Horizontal tangency, curve never reaches diagonal.
3. No tangencies, curves cross diagonal.
4. Horizontal plus diagonal tangency, no crossing.
The Game of Life polynomial is the following: pt+1 = 84 p3
t q6
t + 56 p4
t q5
t . So,
its graphical curve is illustrated in Fig.2. The ﬁrst stable ﬁxed point at the origin
guarantees its stable state pt+1 = 0, the second unstable point pt+1 = 0.1986 relates
to areas of densities where the space–time dynamic is unknown. The last stable
point in pt+1 = 0.37 indicates that the Game of Life will converge almost surely to
conﬁgurations with small densities of states one.
Some relevant results in the Game of Life are enumerated below. The history of
relevant results in the Game of Life is ﬁlled with accumulative results from a large
number of researchers, which begins with the famous newsletter Lifeline [27] which
reincarnated in a very-well organized and specialized site Forums for Conway’s
Game of Life.2
1. Register machine (Conway, 1982) [6].
2. Turing machine (Paul Rendell, 2001) [26].
3. Life universal computer (Paul Chapman, 2002) [7].
4. Algorithms to ﬁnd complex patterns (David Eppstein, 2002) [12].
5. Still life theory (Matthew Cook, 2003) [10].
2 https://www.conwaylife.com/forums/.

Some Notes About the Game of Life Cellular Automaton
97
6. Spartan universal computer-constructor (Adam P. Goucher, 2009) [16].
Newsletters and books dedicated to the Game of Life (chronological order).
1. Lifeline newsletter (Robert Wainwright, 1971) [27].
2. The Recursive Universe (William Poundstone, 1985) [25].
3. New Constructions in Cellular Automata (David Griffeath, Cris Moore (Eds.),
2003) [15].
4. Game of Life Automata (Andrew Adamatzky (Ed.), 2010) [1].
5. Universal Turing machine (Paul Rendell, 2016) [26].
Some particular patterns (chronological order).
1. Glider (Richard K. Guy, 1969) https://www.conwaylife.com/wiki/Glider.
2. Glidergun(BillGosper,1970)https://www.conwaylife.com/wiki/Gosper_glider_
gun.
3. Puffer train (Gosper, 1971) https://www.conwaylife.com/wiki/Puffer_1.
4. Eater (Gosper, 1971) https://www.conwaylife.com/wiki/Eater_1.
5. Garden of Eden (Roger Banks, 1971) https://www.conwaylife.com/wiki/Garden_
of_Eden.
6. Self-replicator (Dave Greene, 2013) https://www.conwaylife.com/wiki/Linear_
propagator.
Some semi-totalistic functions, variants, and projections (chronological order).
1. Inkspot, renamed as Life without Dead (Tommaso Toffoli, Norman Margolus,
1987) https://www.conwaylife.com/wiki/OCA:Life_without_death.
2. Three dimensions (Bays, 1987) [4].
3. HighLife (Nathan Thompson, 1994) https://www.conwaylife.com/wiki/OCA:
HighLife.
4. Triangular, Pentagonal, Hexagonal (Bays, 1994) https://cse.sc.edu/~bays/CA
homePage.
5. Hexagonal (Paul Callahan, 1997) http://www.radicaleye.com/lifepage/hexrule.
txt.
6. Seeds (Brian Silverman, 1996) https://www.conwaylife.com/wiki/OCA:Seeds.
7. Larger-than-Life (Kellie Michele Evans, 1996) https://www.conwaylife.com/
wiki/Larger_than_Life.
8. Penrose (M. Hill, S. Stepney, F. Wan, 2005) https://www-users.cs.york.ac.uk/
susan/bib/ss/nonstd/penroselife.htm.
9. Four dimensions (Bays, 2009) [5].
Some systematic characterizations in the Life-like rules were reported initially by
Magnier et al. in 1997 [24], some years later Adamatzky et al. in 2010 explore the
full range of semi-totalistic rules [2].
In [2] we represent dynamical complements as illustrated in Fig.3 morphology-
based classiﬁcation. Stable orbit matches uniform behavior with nill density of cells

98
G. J. Martínez et al.
Fig. 3 Diagram of
dynamical complements of
morphological classiﬁcation
in state 1. The periodic orbit is typical for conﬁgurations that are usually dom-
inated by stationary localizations, still life and cycle life. Quasi-stable density is
a class where cellular space is dominated by quasi-periodic density regions, they
have very close density values although they are not exactly in the same position. It
is known as collective behaviour [8]. Unstructured and unstable density represents
chaotic behaviour. The last class is characterized by “indeﬁnite” density and complex
behavior (Fig.3).
The Game of Life is a robust complex rule. A cellular automaton has robust
dynamics with respect to a composition function if such dynamics preserve emergent
behaviour later of such composition (for details see [18]). We compose the Game
of Life function with a function of memory. Particularly, we use the majority and
minority memory functions (Fig.4).
Cellular automata with memory are an extension of the original model in such
a way that every cell xi is allowed to remember its states during some ﬁxed period
of its evolution. Cellular automata with memory have been proposed originally by
Alonso-Sanz [3]. This way, we implement a memory function φ, as follows: s(t)
i
=
φ(xt−τ+1
i
, . . . , xt−1
i
, xt
i ), where 1 ≤τ ≤t determines the degree of memory. Thus,
τ = 1means nomemory(or conventional evolution), whereasτ = t means unlimited
trailing memory. Each cell’s trait si ∈ is a state function of the series of states of the
cell i with memory backward up to a speciﬁc value τ. In the memory implementations
run here, commences to act as soon as t reaches the τ time-step. Initially, i.e., t < τ,
the automaton evolves in the conventional way. Later the original rule is applied
on the cell states s as: ϕ(. . . , s(t)
i−1, s(t)
i , s(t)
i+1, . . .) →xt+1
i
to get an evolution with
memory. Thus in cellular automata with memory, while the mapping ϕ remains
unaltered, historic memory of all past iterations is retained by featuring each cell as
a summary of its past states from φ. We can say that cells canalises memory to the
map ϕ [3].
Other research done by Nazim Fatés shown that the Game of Life is robust from
asynchronous version, for details see [13].

Some Notes About the Game of Life Cellular Automaton
99
Fig. 4 The Game of Life is a robust complex rule. The Game of Life is composed with a majority
memory function, starting with a random initial condition to 50% and running to 10,000 steps
(snapshots) in an evolution space of 400×400 cells. The memory function uses a range from τ =
2 to 5. The density history is followed to reach a periodic state or not

100
G. J. Martínez et al.
2
The Game of Life and Its Connection in One Dimension
Rule 22 is the natural projection to one dimension and initially studied by McIntosh
in 1990 [23]. Rule 110 is proposed as LeftLife by Cook in 1999 [9].
Elementary cellular automaton rule 22 is one dimensional projection of the Game
of Life automaton(for details see [23]). Although the Rule 22’s global behaviour
does not show outstandingly complex dynamics, rule 22 is classiﬁed as a chaotic
rule (class 3) in the Wolfram’s classiﬁcation [28].
Rule 22 can be seen as a natural projection to the Game of Life [6] given in the
next conditions [23]:
Birth:
a dead cell xi at the time t will be born in t + 1 if there is just one live
neighbour.
Survival:
an alive cell xi at the time t will survive in t + 1 if there are no live
neighbours
Death:
an alive cell xi at the time t will be dead in t + 1 if there are just two or
one live neighbours, it is dead by overcrowding.
Such a relation covers conditions of the Game of Life. Nevertheless, from a quick
exploration in the one-dimensional dynamics, it does not exhibit complex behaviour.
Rule 22 is an elementary cellular automaton evolving in one dimension of order
|| = 2 and neighbourhood radius r = 1. Thus the local rule ϕ is deﬁned as follows:
ϕR22 =
1 if 100, 010, 001
0 if 111, 110, 101, 011, 000 .
(1)
The local function ϕR22 has a probability of 37.5% to get states 1 in the next
generation and consequently a higher probability to get state 0 in the next generation.
Of course, it is the same ﬁxed point value for the Game of Life.
Recently in [21] it was demonstrated that rule 22 is able to support complex
behaviour, including non-trivial travelling patterns, as gliders. Figure5 illustrates
the collisions between two fractals propagating in one dimension. The probability
to get this initial conﬁguration is very slow because typical evolution is chaotic in
this rule. To reproduce the collisions between fractals emerging in rule 22 we need
the symbolic equation: e∗−11 −e11 −11 −e∗, where the symbol ‘–’ means a con-
catenation operation, the periodic background (or ether) is determined by the string
11101110111011100000. Figure5a shows the original evolution on a ring of 1,164
cells where both fractals start at the center of the window and evolve during 1,049
generations. Here it is possible to distinguish that the composition of both fractals
preserves its structure yielding a reaction between multiple fractals. Another kind of
fractals and collisions can be explored in [21]. Figure5b shows the same evolution
but ﬁltered, this technique permits to separate the mosaic with most frequency in the
evolution space and the patterns are more clear to see. Also, we can see that these
fractals evolve with two stationary particles that travel with small displacements
produced by perturbations when they collide with the fractal structures.

Some Notes About the Game of Life Cellular Automaton
101
Fig. 5 A non-typical
evolution of elementary
cellular automaton rule 22,
two fractals evolve and
collide on a periodic
background. a This initial
condition is determined by
the regular expression
e∗−11 −e11 −11 −e∗in a
ring of 1,164 cells evolving
in 1,049 steps. b The
evolution is the same a in (a)
but a ﬁlter is selected to
visualise non-trivial complex
patterns emerging in this
automaton [21]
(a)
(b)

102
G. J. Martínez et al.
Fig. 6 Evolution of a
pentomino ‘I’ conﬁguration
in the elementary cellular
automaton rule 110, running
in 5,000 steps. The periodic
background is ﬁltered in one
colour for a better view of
gliders and collisions
Research in progress reports a number of interesting reactions however, a glider
gun is not discovered in this domain, moreover a glider gun in rule 22 with memory
is reported in [18]. Thus, phenotypically we can see that rule 22 has a connection
with the Game of Life.
In [9] Cook proposed that elementary cellular automaton rule 110 can be called
as LeftLife. However, the relation between the Game of Life and rule 110 is only
phenotypical because rule 110 is not tangential to the identity and it does not have
unstable ﬁxed points that equilibrate stable ﬁxed points. Rule 110 increases close to
double the probability to get states 1s in the next generation with respect to the Game
of Life. The local rule ϕ is deﬁned as follows:

Some Notes About the Game of Life Cellular Automaton
103
ϕR110 =
1 if 110, 101, 011, 010, 001
0 if 111, 1000, 000
.
(2)
Also, rule 110 evolves with a periodic background and not a stable state. Which
is interesting is that rule 110 has a glider gun and here it is possible to produce
extensible glider guns between a diversity of rule 110 objects [19, 20]. From random
initial conditions typically the attractors are dominated by gliders moving to the left
(E gliders3). On the other hand, if we start a small conﬁguration hence the rule 110
evolves always to the left. In Fig.6 a pentomino ‘I’ is codiﬁed in the initial condition
and it evolves during 3,000 generations before reaching its periodic pattern moving
to the left, the frequency of gliders moving to the left is most of 80% and a barrier
to the right prevents any perturbation coming to the left.
3
Final Notes
The Game of Life without question is the most studied cellular automaton, explored
by a wider range and rich spectrum of researchers. The experts in Life constructions
design very large and complex patterns to reach some limits of the rule. The number
of complex patterns increases and a very specialized simulator is created to explore
these huge spaces, such as Golly (http://golly.sourceforge.net/) where a number of
sophisticated constructions have been designed. Golly is the most complete and
powerful simulator to run Life and other cellular automata. What is the limit? When
one of authors asked this question to Harold McIntosh in Puebla years ago, Harold
responded: well, the limit is the Ackermann function.
A small repository about the Game of Life is accessible from https://www.
comunidad.escom.ipn.mx/genaro/Cellular_Automata_Repository/Life.html.
References
1. Adamatzky A (ed) (2010) Game of life cellular automata. Springer, London
2. Adamatzky A, Martínez GJ, Seck-Tuoh-Mora JC (2006) Phenomenology of reaction-diffusion
binary-state cellular automata. Int J Bifurc Chaos 16(10):1–21
3. Alonso-Sanz R (2018) Cellular automata with memory. Old City Publishing, Inc, Philadelphia
4. Bays C (1987) Candidates for the game of life in three dimensions. Complex Syst 1:373–400
5. Bays C (2009) Gliders in cellular automata. In: Meyers R (ed) Encyclopedia of complexity and
systems science. Springer, New York
6. Berlekamp ER, Conway JH, Guy RK (1982) Winning Ways for your mathematical plays (Chap
25), vol 2. Academic, Cambridge
7. Chapman P (2002) Life universal computer. http://www.igblan.free-online.co.uk/igblan/ca/
8. Chaté H, Manneville P (1991) Evidence of collective behaviour in cellular automata. Europhys
Lett 14:409–413
3 Gliders in rule 110. https://www.comunidad.escom.ipn.mx/genaro/rule110/glidersRule110.html.

104
G. J. Martínez et al.
9. Cook M (1999) Introduction to the activity of rule 110 (copyright 1994-1998 Matthew Cook).
http://w3.datanet.hu/~cook/Workshop/CellAut/Elementary/Rule110/110pics.html. Accessed
January 1999
10. Cook M (2003) Still life theory. In: Griffeath D, Moore C (eds) New constructions in cellular
automata, vol 226, pp 93–118
11. Eppstein D (1999) Wolfram’s classiﬁcation of cellular automata. https://www.ics.uci.edu/
~eppstein/ca/wolfram.html
12. Eppstein D (2002) Searching for spaceships. MSRI Publ 42:433–452
13. Fatès N, Morvan M (2004) Perturbing the topology of the game of life increases its robustness
to asynchrony. In: International conference on cellular automata ACRI 2004. pp 111–120.
Springer, Berlin
14. Gardner M (1970) Mathematical Games – the fantastic combinations of John H. Conway’s
new solitaire game Life. Sci Amer 223:120–123
15. Griffeath D, Moore C (eds) (2003) New constructions in cellular automata, (Santa Fe Institute
Studies on the Sciences of Complexity). Oxford University Press, Oxford
16. Goucher AP (2010) Universal computation and construction. In: Adamatzky A (ed) Game of
life cellular automata. Springer, London, pp 505–517
17. Gutowitz HA, Victor JD (1987) Local structure theory in more that one dimension. Complex
Syst 1:57–68
18. Martínez GJ, Adamatzky A, Alonso-Sanz R (2013) Designing complex dynamics in cellular
automata with memory. Int J Bifur Chaos 23(10):1330035
19. Martínez GJ, McIntosh HV, Seck-Tuoh-Mora JC (2006) Gliders in rule 110. Int J Unconv
Comput 2(1):1–49
20. Martínez GJ, McIntosh HV, Seck-Tuoh-Mora JC, Chapa-Vergara SV (2007) Rule 110 objects
and other constructions based-collisions. J Cell Autom 2(3):219–242
21. Martínez GJ, Adamatzky A, Hoffmann R, Désérable D, Zelinka I (2019) On patterns and
dynamics of Rule 22 cellular automaton. Complex Syst 28(2):125–174
22. McIntosh HV (1990) Wolfram’s class IV and a good life. Physica D 45:105–121
23. McIntosh HV (2009) One Dimensional Cellular Automata. Luniver Press, United Kingdom
24. Magnier M, Lattaud C, Heudin J-K (1997) Complexity classes in the two-dimensional life
cellular automata subspace. Complex Syst 11(6):419–436
25. Poundstone W (1985) The recursive universe: cosmic complexity and the limits of scientiﬁc
knowledge. William Morrow and Company, Inc., New York
26. Rendell P (2016) Turing machine universality of the game of life. Springer, Berlin
27. Wainwright R (ed) Lifeline - a quaterly newsletter for enthusiasts of John Conway’s game of
life, Issues 1 to 11, March 1971 to September 1973. https://www.conwaylife.com/wiki/Lifeline
28. Wolfram S (2002) A new kind of science. Wolfram Media Inc, Champaign
Genaro J. Martínez is a professor at the School of Computer Sciences, National Polytechnic
Institute, Mexico City, Mexico and visiting fellow at the Unconventional Computing Centre, Uni-
versity of the West of England, Bristol, UK. He does research in cellular automata, unconventional
computing, artiﬁcial life, complex systems, and swarm robotics.
Andrew Adamatzky is a professor at the Department of Computer Science and Director of the
Unconventional Computing Centre, University of the West of England, Bristol, UK. He does
research in reaction-diffusion computing, cellular automata, massive parallel computation, collec-
tive intelligence, bionics, complexity, non-linear science, novel hardware.
Juan C. Seck-Tuoh-Mora received the M.S. and Ph.D. degrees in computer science from the
Center for Research and Advanced Studies, National Polytechnic Institute, Mexico, in 1999 and
2002, respectively. He is currently a Professor-Researcher of the academic area of engineering
with the Autonomous University of the State of Hidalgo. His current research interests include
cellular automata, metaheuristics, evolutionary algorithms, and neural networks to model, design,
optimize, and control engineering systems.

Gliders in the Game of Life and in a
Reversible Cellular Automaton
Kenichi Morita
Abstract The glider is the most important pattern in the Conway’s Game of Life
(GoL). It not only ﬂies in the cellular space, but also shows a variety of fantastic phe-
nomena caused by the interactions with other patterns or other gliders. Using these
phenomena, complex functional objects, such as universal computers, were con-
structed. On the other hand, space-moving patterns like the glider can also exist even
in some very simple reversible cellular automata. Reversibility is one of the funda-
mental microscopic physical law of nature, and thus a reversible cellular automaton
is an abstract model of a reversible world. Here we use a particular reversible ele-
mentary triangular partitioned cellular automaton ETPCA0347, where 0347 is an
identiﬁcation number in the class of 256 ETPCAs. We can see that a fascinating
glider also exists in ETPCA0347. We compare it with the glider in GoL, and discuss
similarities and differences of their properties. As in the case of GoL, ETPCA0347
has many interesting and useful phenomena related to gliders. However, because of
reversibility some features are very different. One of such differences in ETPCA0347
is the property of time-symmetry, by which “backward functional modules” can be
easily designed. By the useful phenomena and properties of the glider, we can com-
pose reversible Turing machines in the cellular space of ETPCA0347.
Keywords Game of Life · Glider · Reversible cellular automaton · Elementary
triangular partitioned cellular automaton · Time-symmetry · Reversible logic
element with memory · Reversible Turing machine
Currently, Professor Emeritus of Hiroshima University.
K. Morita (B)
Hiroshima University, Higashi-Hiroshima 739-8527, Japan
e-mail: km@hiroshima-u.ac.jp
© The Author(s), under exclusive license to Springer Nature Switzerland AG 2022
S. Das et al. (eds.), The Mathematical Artist, Emergence,
Complexity and Computation 45, https://doi.org/10.1007/978-3-031-03986-7_5
105

106
K. Morita
1
Game of Life and the Glider
Since J. H. Conway’s Game of Life (GoL) was introduced by Gardner [5], a great
deal of investigations have been made on it. One of the reasons why it attracted
many people is the existence of a space-moving pattern called the glider. After the
introduction of the glider in [5] various fascinating phenomena related to it have been
found one after another. The glider gun by Gosper [6] was the ﬁrst surprise among
them, and many others followed it.
GoL is a two-dimensional CA with the Moore neighborhood having two states,
which are the live state and the dead state. The local transition function is described
shortly as follows [2].
Just 3 for BIRTH, 2 or 3 for SURVIVAL
It says that a dead cell will become live at the next time step if and only if the number
of live cells among 8 neighboring cells is just 3, and a live cell will keep live if and
only if the number of live cells among 8 neighboring cells is 2 or 3. By this local
transition function, conﬁgurations of GoL show fantastic behavior.
In this section we discuss some characteristic features of the glider in GoL, and
in Sect.3 we compare it with a glider in a particular reversible cellular automaton
(RCA). However, since an enormous number of properties have been known on
the glider in GoL so far, it is not possible to give a comprehensive survey on it
here. Therefore, we pick up only a few from them that are related to the following
sections. See LifeWiki [8] for other topics and for more details, since it contains a
large number of GoL patterns and data.
1.1
Irreversibility of the Game of Life (GoL)
A CA is called reversible if there is no pair of distinct conﬁgurations that goes to
the same conﬁguration. We can see that GoL is not reversible. Look at an evolution
process in GoL shown in Fig.1. The pattern that appears at t = 1 is a stable pattern
called a block. Hence the pattern at t = 0 and a block itself go to a block at the next
step. Therefore, GoL is an irreversible CA.
If we start from a random pattern in GoL, then, in most cases, it ﬁrst becomes a
conﬁguration that contains actively changing regions. However, ﬁnally such active
regions disappear, and it goes to a conﬁguration containing only stable patterns
Fig. 1 The pattern at t = 0
goes to a stable pattern called
a block at t = 1 in GoL
t = 0
•
•
••
t = 1
••
••
t = 2
••
••

Gliders in the Game of Life and in a Reversible Cellular Automaton
107
t = 0
••
••• •
• •
••
•
••••
••
• ••••
••
••
•• • ••
•• •• • •
•
••
•••
•••
•• • • ••
t = 70
•
•
•
• •
• •
• •
•
••••
••• •
••
•••
•••••
••
••
•
• • ••••
•• ••
• •
•• •
•
•
••
•
••
•
•
•
•••
•
•
•
•
••
• •
•
•••••
• ••
•• •• •
•
•
••
• •
•
•• •
•• • ••
• •
••
•
••
• •
•
•
••
•
t = 140
••••
•
••
••
••
•••
•
•
• •• •
••
• • ••
••
•• ••
•
••
• ••
•
•
•
•
•
•
••••
•
••••
•••
•
•
•••••
••
•••
•
•
•
• ••
•
•
• ••
•
• ••
• •••
•
• • ••
•••
•
•••
• •
•
•
• •
•
•••
t = 210
••
• ••
••
••
•••
••
••
••
••
••
•
•
• •
• •
•
••
• •
••
•
• •
••
•
•
•
•
•
••
Fig. 2 Example of a typical evolution process in GoL. It starts from a random pattern of size 10 × 10
(t = 0). First, actively changing regions appear and spread (t = 70). Then, some stable, periodic
and space-moving patterns are created (t = 140). Finally, actively changing regions disappear, and
only stable, periodic and space-moving patterns remain (t = 210)
(called still lifes), periodic patterns (called oscillators), and space-moving patterns
(called spaceships) (see Fig.2). Such an evolution process, in particular, disappearing
process of active regions, also comes from irreversibility of GoL.
1.2
The Glider, Spaceships and a Glider Gun
The glider in GoL consists of ﬁve live cells, and it evolves as shown in Fig.3. It
moves through a distance of one cell diagonally in 4 steps, which form one period.
It can be used as a signal when constructing a universal computer.
It is known that there are many space-moving patterns called spaceships other
than the glider (see the page “Spaceship” of [8]). For example, Fig.4 is a lightweight
spaceship [2]. Note that, in GoL, space-moving patterns are generally called space-
ships, and thus the glider is a particular spaceship having the minimum number of
live cells. (In some literature, space-moving patterns are generally called gliders, but
here we employ the above terminology.)
t = 0
••
•••
t = 1
• •
••
•
t = 2
•
• •
••
t = 3
•••
••
t = 4
••
•••
Fig. 3 The glider in GoL [5]

108
K. Morita
t = 0
•
••
•
•
••••
t = 1
••
•• ••
••••
••
t = 2
••••
•
••
•
•
t = 3
••
••••
•• ••
••
t = 4
•
••
•
•
••••
Fig. 4 Lightweight spaceship [2]
Fig. 5 The glider gun by
Gosper (the upper pattern)
[6], and an eater that erases
gliders (the lower right
pattern) [2]
•
••••
•
•
••••
•
• •
•
•
••
••
•
••
••••
••
••
•
••
••••
•
••
•
• •
•
• •
••
•
•••
••
••
• ••••
Figure5 shows the glider gun found by Gosper in 1970 [6]. It generates a glider
every 30 time steps. After that many kinds of glider guns have been designed (see
“Category: Guns” of [8]). The lower right pattern in Fig.5 is called an eater [2] that
eats gliders. Unused signals can be erased in this way.
1.3
Controlling a Glider
Since both the size and the period of the glider are small, it is easier to control the
movement of a glider than other spaceships. It is known that there are many kinds of
patterns for reﬂecting a glider. By placing reﬂectors suitably the move direction and
the timing of a glider can be freely adjusted (see “Reﬂector” of [8]). Figure6 is one
of the stable reﬂectors called snark proposed by M. Playle in 2013 (see “Snark” of
[8]). Note that 90◦-left-turn is possible by the mirror image of the pattern in Fig.6.
1.4
Collisions of Gliders
Collisionsofglidersalsoshowinterestingevolutionprocesses.Ifwemaketwogliders
collide as in Fig.7, both of them disappear [2]. If the collision is as in Fig.8, one
of them goes back and the other disappears [2]. By changing the positions and the

Gliders in the Game of Life and in a Reversible Cellular Automaton
109
t = 0
••
••
••
• •••
•
•
•••• ••
•
•
• • • ••
• • • •
•• • •
•
•••
••
• •
••
••
••
••
•
• •
•••
•
•
t = 46
••
••
••
• •••
•
•
•••• ••
•
•
• • • ••
• • • •
•• • •
••
•
•••
•••
• • •
• ••
•• ••
•
••
••
•
•••• ••
•
•••••
•
•
•• •
•••
••
••
•••••
t = 58
••
••
••
• •••
•
•
•••• ••
•
•
• • • ••
• • • •
•• • •
•
•••
••
• •
••
••
••
•••
••
•••••
Fig. 6 90◦-right-turn of a glider by the pattern snark (see “Snark” of [8])
t = 0
• •
••
•
•
•
•••
t = 1
•• •
••
• •
••
•
t = 2
•
••
•••
••
• •
••
t = 3
•
• •
••
••
t = 4
•
•
t = 5
Fig. 7 If two gliders collide in this way, both of them disappear [2]
t = 0
•• •
••
•••
••
t = 1
•
••••
•••
•••
t = 2
•
• •
••••
• •
••
•
t = 3
•
•• •
•
•
• •
••
t = 4
••••••
• ••
••
t = 5
••••
• •
•••
t = 6
••••
•
•
••
t = 7
•••
• •
••
t = 8
••
• ••
Fig. 8 If two gliders collide in this way, one goes back and the other disappears. This process is
called the kickback reaction [2]
timing of gliders, various patterns appear after collision. Products of the collisions
are: nothing (as in Fig.7), one glider (as in Fig.8), a stable pattern, a periodic pattern,
and others (see “2-glider collision” of [8]).
In [2] it is shown that combining the glider collision shown in Fig.7 and the glider
gun in Fig.5, logical operations NOT, AND and OR are realized.
1.5
Collisions of Gliders with a Block
Making two gliders collide with a block as in Fig.9, the block is pulled to the north-
west direction by (−3, 3) and the gliders are dissolved [2]. It is also possible to push
a block by gliders. Such phenomena can be used as a memory, where the memory
states are distinguished by the positions of the block (see “Sliding block memory”
of [8]).

110
K. Morita
Fig. 9 Pulling a block by
two gliders [2]. It is used to
realize a sliding block
memory
t = 0
•
•
•
•
•••
•••
••
••
t = 27
••
••
••
••
2
Elementary Triangular Partitioned Cellular Automaton
A reversible cellular automaton (RCA) is a spatiotemporal model having reversible
dynamics. It can be regarded as an abstract model of a physical world that obeys a
reversible microscopic law. In this section we consider a class of two-dimensional
cellular automata called an elementary triangular partitioned cellular automaton
(ETPCA) to give a very simple reversible cellular automaton. After giving deﬁ-
nitions of a reversible ETPCA, its basic properties on reversibility, dualities, and
time-symmetries are discussed.
In Sect.3 we shall see that a fascinating glider also exists in a particular reversible
ETPCA. We examine the behavior of the glider, and compare it with the glider in
GoL. Useful phenomena are modularized as gadgets for making functional modules.
In Sect.4 a reversible logic element with memory is composed using these gadgets,
and then reversible Turing machines are constructed by assembling them. Note that
readers can go to Sect.3 directly, skipping Sect.2 for the ﬁrst reading.
2.1
Triangular Partitioned Cellular Automaton
Atriangularpartitionedcellularautomaton (TPCA)isatwo-dimensionalCAhaving
equilateral triangle cells. Each cell is further divided into three parts as shown in
Fig.10. The three parts are the left, downward, and right parts, which have their own
state sets L, D and R, respectively. All the cells are identical, but the directions of
the cells are not the same, i.e., there are up-triangle cells and down-triangle cells
as in Fig.11a and b. Here, we assume that a down-triangle cell is one obtained by
rotating an up-triangle cell by 180◦. Therefore, for an up-triangle cell of the state
(l, d,r) ∈L × D × R, there is a down-triangular cell of the state (l, d,r) in which
the positions of the states l, d, and r are as shown in Fig.11b.
The next state of a cell of a TPCA is determined by the present states of the three
adjacent parts of the neighbor cells (not by the whole states of the three adjacent
cells) as shown in Fig.12. Note that for a down-triangle cell, the rule obtained by
rotating the both sides of the original rule by 180◦is applied.
We place cells of a TPCA on Z2 as in Fig.13, where Z is the set of all integers. We
assume that if the coordinates of an up-triangle cell (down-triangle cell, respectively)

Gliders in the Game of Life and in a Reversible Cellular Automaton
111
Fig. 10 Cellular space of a
triangular partitioned cellular
automaton (TPCA)
Fig. 11
a An up-triangle
cell, and b a down-triangle
cell of TPCA
r
d
l
l
d
r
(a)
(b)
Fig. 12 Local transition rule
of TPCA
r
d
l
r′
d′
l′
Fig. 13 x-y coordinates in
the cellular space of TPCA
x−3 x−2 x−1
x
x+1 x+2 x+3
y+1
y
y−1
(x−2,
y+1)
(x,
y+1)
(x+2,
y+1)
(x−3,
y+1)
(x−1,
y+1)
(x+1,
y+1)
(x+3,
y+1)
(x−3,
y)
(x−1,
y)
(x+1,
y)
(x+3,
y)
(x−2,
y)
(x, y)
(x+2,
y)
(x−2,
y−1)
(x,
y−1)
(x+2,
y−1)
(x−3,
y−1)
(x−1,
y−1)
(x+1,
y−1)
(x+3,
y−1)
is (x, y), then x + y is even (odd). Note that, if we deﬁne a TPCA on Z2, then the
neighborhood is slightly non-uniform. Namely, for an up-triangle cell, its neighbors
are the west, south and east adjacent cells, while for a down-triangle cell, the neigh-
bors are the east, north and west adjacent cells. Although such non-uniformity can
be dissolved by deﬁning a TPCA on a Cayley graph, here we deﬁne a TPCA on Z2
for simplicity.
The reason why we use a TPCA is as follows. First, since the number of edge-
adjacent cells of each cell is only three, its local function can be much simpler than
that of a CA with square cells. Second, the framework of PCA makes it feasible to
design a reversible CA (see Lemma1 below). Hence, TPCA is suited for studying
the problem how simple a computationally universal RCA can be. The framework
of reversible PCA is also useful to study time-symmetry of RCAs (see Sect.2.5).
We now give a formal deﬁnition of a TPCA.

112
K. Morita
Deﬁnition 1 A triangular partitioned cellular automaton (TPCA) is a system
deﬁned by
T = (Z2, (L, D, R), ((−1, 0), (0, −1), (1, 0)), ((1, 0), (0, 1), (−1, 0)), f, (#, #, #)).
Here, Z2 is the set of all two-dimensional points with integer coordinates at which
cells are placed, and L, D and R are non-empty ﬁnite sets of states of the left,
downward and right parts of a cell. The state set Q of a cell is thus given by Q =
L × D × R. The triplet ((−1, 0), (0, −1), (1, 0)) is a neighborhood for up-triangle
cells, and ((1, 0), (0, 1), (−1, 0)) is a neighborhood for down-triangle cells. The item
f : Q →Q is a local (transition) function, and (#, #, #) ∈Q is a quiescent state that
satisﬁes f (#, #, #) = (#, #, #). We also allow a TPCA that has no quiescent state.
If f (l, d,r) = (l′, d′,r′) holds for (l, d,r), (l′, d′,r′) ∈Q, then this relation is
called a local transition rule of the TPCA T . It is written pictorially as in Fig.12.
The local function f is thus deﬁned by a set of local transition rules.
Conﬁgurations of a TPCA, and the global function induced by the local function
are deﬁned as below.
Deﬁnition 2 Let T be a TPCA:
T = (Z2, (L, D, R), ((−1, 0), (0, −1), (1, 0)), ((1, 0), (0, 1), (−1, 0)), f, (#, #, #))
A conﬁguration of T is a function α : Z2 →Q. The set of all conﬁgurations of
T is denoted by Conf(T ), i.e., Conf(T ) = {α | α : Z2 →Q}. Let prL : Q →L be
the projection function such that prL(l, d,r) = l for all (l, d,r) ∈Q. The projection
functions prD : Q →D and prR : Q →R are deﬁned similarly. The global function
F : Conf(T ) →Conf(T ) of T is deﬁned as the one that satisﬁes the following.
∀α ∈Conf(T ), ∀(x, y) ∈Z2 :
F(α)(x, y)
=
 f (prL(α(x −1, y)), prD(α(x, y −1)), prR(α(x + 1, y))) if x + y is even
f (prL(α(x + 1, y)), prD(α(x, y + 1)), prR(α(x −1, y))) if x + y is odd
For a TPCA T with a quiescent state, we can deﬁne ﬁnite and inﬁnite conﬁgu-
rations. A conﬁguration α is called ﬁnite if the set {(x, y) | α(x, y) ̸= (#, #, #)} is
ﬁnite. Otherwise, α is called inﬁnite.
Next, we deﬁne reversibility of a TPCA.
Deﬁnition 3 A TPCA T is called reversible if its global function F is injective.
The next Lemma shows that injectivity of the global function is equivalent to
injectivity of the local function in a TPCA. Note that this lemma was ﬁrst shown in
[15] for a one-dimensional PCA. The lemma for TPCA is found in [11]. Actually,
this property holds for any PCA.

Gliders in the Game of Life and in a Reversible Cellular Automaton
113
Lemma 1 Let T be a TPCA. Its global function F is injective if and only if its local
function f is injective.
By this Lemma we can easily obtain an RCA, since it is sufﬁcient to design a PCA
whose local function is injective.
2.2
Elementary Triangular Partitioned Cellular Automaton
(ETPCA)
Next we deﬁne an elementary triangular partitioned cellular automaton (ETPCA).
It is the simplest subclass of TPCAs such that it is rotation-symmetric, and each of
three parts of a cell has only two states. Hence, it is called an elementary TPCA as
in the case of a one-dimensional elementary cellular automaton (ECA) [18, 19]. We
ﬁrst deﬁne the notion of rotation-symmetry.
Deﬁnition 4 Let T be a TPCA:
T = (Z2, (L, D, R), ((−1, 0), (0, −1), (1, 0)), ((1, 0), (0, 1), (−1, 0)), f, (#, #, #))
The TPCA T is called rotation-symmetric (or isotropic) if the following conditions
(1) and (2) holds.
(1)
L = D = R
(2)
∀(l, d,r), (l′, d′,r′) ∈L × D × R :
f (l, d,r) = (l′, d′,r′) ⇒f (d,r,l) =
(d′,r′,l′)
Deﬁnition 5 Let T be a TPCA:
T = (Z2, (L, D, R), ((−1, 0), (0, −1), (1, 0)), ((1, 0), (0, 1), (−1, 0)), f )
T is called an elementary triangular partitioned cellular automaton (ETPCA), if
L = D = R = {0, 1}, and it is rotation-symmetric.
When drawing ﬁgures of ETPCA’s local transition rules and conﬁgurations, we
indicate the states 0 and 1 by a blank and a particle (i.e., •), respectively.
Since an ETPCA is rotation-symmetric, its local function f : {0, 1}3 →{0, 1}3
is described by only four local transition rules, which are obtained by giving the
following four values.
f (0, 0, 0), f (0, 1, 0), f (1, 0, 1), f (1, 1, 1)
Here,
f (0, 1, 0), f (1, 0, 1) ∈{0, 1}3,
but
f (0, 0, 0), f (1, 1, 1) ∈{(0, 0, 0), (1,
1, 1)} since it is rotation-symmetric. The reason is as follows. For example, if
we assume f (0, 0, 0) = (0, 0, 1), then from Deﬁnition4 f (0, 0, 0) = (0, 1, 0) must
hold. Thus a contradiction occurs. Other cases are also similar.

114
K. Morita
Fig. 14 Expressing an ETPCA by a 4-digit octal ID number wxyz. Vertical bars indicate alternatives
of the right-hand side of each local transition rule
Fig. 15 Local transition rules of ETPCA0137, which deﬁne the local function f0137
Reading the values of f (0, 0, 0), f (0, 1, 0), f (1, 0, 1) and f (1, 1, 1) as four
binary numbers, we can express an ETPCA by a 4-digit octal identiﬁcation number
wxyz as shown in Fig.14. Thus there are 256 ETPCAs in total.
An ETPCA with the ID number wxyz is denoted by ETPCAwxyz. Its local func-
tion and global function are represented by fwxyz and Fwxyz, respectively. Figure15
shows the set of local transition rules of ETPCA0137.
2.3
Reversible ETPCA and Conservative ETPCA
From Deﬁnition3 and Lemma1 it is easy to see the following Proposition [11]. Thus,
there are 36 reversible ETPCAs. For example, ETPCA0137 having the local function
shown in Fig.15 is reversible.
Proposition 1 ETPCAwxyz is reversible if and only if (1) and (2) hold.
(1)
(w, z) ∈{(0, 7), (7, 0)}
(2)
(x, y) ∈{1, 2, 4} × {3, 5, 6} ∪{3, 5, 6} × {1, 2, 4}
An ETPCA is called conservative if the number of particles (i.e., state 1) is con-
served in each local transition rule. It corresponds to conservation laws in physics,
such as conservation of mass, energy, and so on. From this deﬁnition the following
Proposition holds [11]. Therefore, there are 9 conservative ETPCAs.

Gliders in the Game of Life and in a Reversible Cellular Automaton
115
Proposition 2 ETPCAwxyz is conservative if and only if (1) and (2) hold.
(1)
(w, z) ∈{(0, 7)}
(2)
(x, y) ∈{1, 2, 4} × {3, 5, 6}
From Propositions1 and 2, we can see conservative ETPCAs are reversible. For
example, ETPCA0137 (Fig.15) is a reversible and conservative ETPCA.
2.4
Dualities in ETPCAs
We introduce two kinds of dualities among ETPCAs. They are the dualities under
reﬂection and complementation. These notions are given in [18] for one-dimensional
ECAs. Note that in [11] the duality under odd-step complementation is also deﬁned,
but we omit it here, since it is for a small subclass of ETPCAs. The dual ETPCA
is essentially the same as the original one in the sense that any evolution process
is simulated in the dual ETPCA after taking a simple transformation to the initial
conﬁguration.
Deﬁnition 6 Let T be an ETPCA and f : {0, 1}3 →{0, 1}3 be its local function.
Deﬁne f r : {0, 1}3 →{0, 1}3 as follows.
∀(l, d,r), (l′, d′,r′) ∈{0, 1}3 : f (l, d,r) = (l′, d′,r′) ⇔f r(r, d,l) = (r′, d′,l′)
Then, the ETPCA T r having the local function f r is called the dual ETPCA of T
under reﬂection.
From this deﬁnition, we can see that the local transition rules of T r are the mirror
images of those of T . Therefore, any evolution process in T is simulated in T r in a
straightforward manner by taking the mirror image of the initial conﬁguration (see
also Lemma2).
Deﬁnition 7 Let T be an ETPCA and f : {0, 1}3 →{0, 1}3 be its local function. For
x ∈{0, 1},let x = 1 −x,i.e., x isthecomplementof x.Deﬁne f c : {0, 1}3 →{0, 1}3
as follows.
∀(l, d,r), (l′, d′,r′) ∈{0, 1}3 : f (l, d,r) = (l′, d′,r′) ⇔f c(r, d,l) = (r′, d′,l′)
Then, the ETPCA T c having the local function f c is called the dual ETPCA of T
under complementation.
From this deﬁnition, we can see that the local transition rules of T c are obtained
from those of T by exchanging 0 and 1. Therefore, any evolution process in T is
simulated in T c in a straightforward manner by taking the complement of the initial
conﬁguration. There is also a dual ETPCA whose local function is ( f r)c = ( f c)r.
We write it by f rc shortly.

116
K. Morita
Table 1 Identiﬁcation numbers of 36 reversible ETPCAs, their dual ones (under reﬂection, com-
plementation, and both), and their inverses
f
f r
f c
f rc
f −1
f
f r
f c
f rc
f −1
0137
0467
0467
0137
0467
7130
7460
7460
7130
7460
0157
0457
0267
0237
0457
7150
7450
7260
7230
7450
0167
0437
0167
0437
0437
7160
7430
7160
7430
7430
0237
0267
0457
0157
0267
7230
7260
7450
7150
7260
0257
0257
0257
0257
0257
7250
7250
7250
7250
7250
0267
0237
0157
0457
0237
7260
7230
7150
7450
7230
0317
0647
0647
0317
0317
7310
7640
7640
7310
7310
0327
0627
0547
0517
0517
7320
7620
7540
7510
7510
0347
0617
0347
0617
0617
7340
7610
7340
7610
7610
0437
0167
0437
0167
0167
7430
7160
7430
7160
7160
0457
0157
0237
0267
0157
7450
7150
7230
7260
7150
0467
0137
0137
0467
0137
7460
7130
7130
7460
7130
0517
0547
0627
0327
0327
7510
7540
7620
7320
7320
0527
0527
0527
0527
0527
7520
7520
7520
7520
7520
0547
0517
0327
0627
0627
7540
7510
7320
7620
7620
0617
0347
0617
0347
0347
7610
7340
7610
7340
7340
0627
0327
0517
0547
0547
7620
7320
7510
7540
7540
0647
0317
0317
0647
0647
7640
7310
7310
7640
7640
We denote the ID numbers of f r
wxyz, f c
wxyz, f rc
wxyz, and f −1
wxyz by r(wxyz), c(wxyz),
rc(wxyz), and inv(wxyz), respectively. Namely, f r
wxyz = fr(wxyz), f c
wxyz = fc(wxyz),
f rc
wxyz = frc(wxyz), and f −1
wxyz = finv(wxyz).
Table1 shows the list of ID numbers of local functions ( f ) of 36 reversible ETP-
CAs, their dual ones ( f r, f c and f rc), and their inverses ( f −1). For example, if
we consider ETPCA0157, then f r
0157 = fr(0157) = f0457, f c
0157 = fc(0157) = f0267,
f rc
0157 = frc(0157) = f0237 and f −1
0157 = finv(0157) = f0457 (see Fig.16). Note that the
inverse local functions will be used in Sect.2.5.
Computational universality of ETPCAs was studied in [7, 11–13], and it has been
shown that ETPCAs 0137, 0157, and 0347 are universal. Hence, their dual ETPCAs
are also universal.
2.5
Time-Symmetry in Reversible ETPCAs
Time-symmetry (or time-reversal symmetry) in a certain reversible CA is the property
in which the forward and the backward time evolutions are governed by the same law
[4]. Irreversible CAs like GoL do not have this property. If the backward evolution

Gliders in the Game of Life and in a Reversible Cellular Automaton
117
Fig.16 LocalfunctionsofETPCA0157anditsdualones,wherer(0157) = 0457,c(0157) = 0267,
and rc(0157) = 0237
Fig. 17 Local function of ETPCA0257 by which Hrev is deﬁned. The involution Hrev makes every
particle turn backward
in a reversible CA is governed by exactly the same law as the forward one, then
we cannot tell whether a given process is evolving forward or backward. This is the
time-symmetry in the strict sense. On the other hand, if the backward one is governed
by a similar law, then it may be possible to tell whether it is evolving forward or
backward by ﬁnding a difference between two evolutions, though the difference may
be very small. This is the time-symmetry in the weak sense. Note that the meaning
of “similar” will be given later.
Here, we consider both versions of time-symmetry. The weaker version of time-
symmetry holds for a wide variety of reversible PCAs, and it is useful for designing
a backward functional module that undoes the operations performed by a given
forward functional module.
LetConfE = {α | α : Z2 →{0, 1}3}denotethesetofallconﬁgurationsofETPCA.
A function H is called an involution, if H ◦H is an identity function. We deﬁne the
involution H rev : ConfE →ConfE by the reversible ETPCA0257: i.e., H rev = F0257.
As shown in Fig.17, the involution H rev is interpreted as the one that reverses the
moving direction of all the particles in the cellular space.
We deﬁne the notion of strict time-symmetry for reversible ETPCAs as below
basically following the deﬁnition in [4].
Deﬁnition 8 Let T be a reversible ETPCAwxyz whose global function is Fwxyz. If
F−1
wxyz = H rev ◦Fwxyz ◦H rev, then T is called strictly time-symmetric.
The notion of strict time-symmetry means that a backward evolution is carried out by
exactly the same global function as the one for the forward evolution after applying
only H rev. The involution H rev is an analog of the operation of reversing the velocity
vectors of all the moving particles in a system of Newtonian mechanics.

118
K. Morita
Fig. 18 Process of the state-changes around the cell at (x, y) in Proposition3
A weaker version of time-symmetry is deﬁned next. Note that the notion of weak
time-symmetry in this deﬁnition is expressed by the phrase “under the involution H,”
where H is extended to any involution. Here, we do not restrict the involution H,
though preferably it is simple.
Deﬁnition 9 Let T be a reversible ETPCAwxyz whose global function is Fwxyz.
If there is an involution H : ConfE →ConfE that satisﬁes F−1
wxyz = H ◦Fwxyz ◦H,
then T is called time-symmetric under the involution H.
We newly show the following Proposition in this paper.
Proposition 3 Let T be a reversible ETPCAwxyz with the local function fwxyz
and the global function Fwxyz. Let T ′ be a reversible ETPCA having the ID number
inv(wxyz). Hence, the local and global functions of T ′ are finv(wxyz) = f −1
wxyz and
Finv(wxyz), respectively. Then, the following holds.
F−1
wxyz = H rev ◦Finv(wxyz) ◦H rev
Proof Let α1 ∈ConfE be any conﬁguration. Let (x, y) ∈Z2 be any point, and
(l1, d1,r1) ∈{0, 1}3 be as follows: α1(x, y) = (l1, d1,r1). See Fig.18 that shows the
process of state-changes by the operations given below. We consider only the case
where x + y is even, since the other case is similar. First, we can see the following
relations.
prL(H rev(α1)(x −1, y)) = l1
prD(H rev(α1)(x, y −1)) = d1
prR(H rev(α1)(x + 1, y)) = r1
Assume f −1
wxyz(l1, d1,r1) = (l0, d0,r0) (thus, fwxyz(l0, d0,r0) = (l1, d1,r1)). Then,
(Finv(wxyz) ◦H rev(α1))(x, y) = (l0, d0,r0).
Let α0 = Finv(wxyz) ◦H rev(α1). Then, the following relations hold.
prL(H rev(α0)(x −1, y)) = l0
prD(H rev(α0)(x, y −1)) = d0
prR(H rev(α0)(x + 1, y)) = r0
Hence,

Gliders in the Game of Life and in a Reversible Cellular Automaton
119
(Fwxyz ◦H rev(α0))(x, y) = (l1, d1,r1) = α1(x, y).
By above, the following holds for all (x, y) ∈Z2.
(Fwxyz ◦H rev ◦Finv(wxyz) ◦H rev(α1))(x, y) = α1(x, y)
Thus, Fwxyz ◦H rev ◦Finv(wxyz) ◦H rev(α1) = α1. Therefore,
F−1
wxyz = H rev ◦Finv(wxyz) ◦H rev.
This completes the proof.
□
This Proposition says that a backward evolution of ETPCAwxyz is carried out
by Finv(wxyz) applying H rev just before and after Finv(wxyz). By this Proposition, if
inv(wxyz) = wxyz, then ETPCAwxyz is strictly time-symmetric. From Table1, we
obtain the following Corollary.
Corollary 1 The 8 reversible ETPCAs w25z, w31z, w52z and w64z are strictly
time-symmetric, where (w, z) ∈{(0, 7), (7, 0)}.
Other reversible ETPCAs are not strictly time-symmetric, however their backward
evolution is simulated by “similar” ETPCAs. For example, consider ETPCA0157.
Since inv(0157) = 0457 = r(0157), it is simulated by ETPCA0457 that is a dual
ETPCA under reﬂection. Though ETPCAs 0157 and 0457 are similar, we can distin-
guish forward evolutions and backward evolutions. For example, in ETPCA0157 a
single particle rotates clockwise, while in ETPCA0457 it rotates counter-clockwise
(see the second rules of them in Fig.16).
Here, we newly show Lemma2 stating that ETPCAwxyz satisfying inv(wxyz) =
r(wxyz) is time-symmetric under a suitable involution H. First, deﬁne a func-
tion reﬂ3 : {0, 1}3 →{0, 1}3 as follows: reﬂ3(l, d,r) = (r, d,l) for any (l, d,r) ∈
{0, 1}3. Next deﬁne an involution H reﬂ: ConfE →ConfE as follows: H reﬂ(α)(x, y)
= reﬂ3(α(−x, y)) for all α ∈ConfE and (x, y) ∈Z2. The involution H reﬂgives the
mirror image of a conﬁguration with respect to the y-axis.
Lemma 2 The next relation holds for any ETPCAwxyz.
Fr(wxyz) = H reﬂ◦Fwxyz ◦H reﬂ
Proof First, we show Fwxyz = H reﬂ◦Fr(wxyz) ◦H reﬂ. Let α ∈ConfE be any con-
ﬁguration, and (x, y) ∈Z2 be any point. We consider only the case where x + y is
even. Let (l0, d0,r0) ∈{0, 1}3 be as follows.
prL(α(x −1, y)) = l0
prD(α(x, y −1)) = d0
prR(α(x + 1, y)) = r0

120
K. Morita
Fig. 19 Process of the state-changes around the cells at (x, y) and (−x, y) in Lemma2
See Fig.19 that shows the process of state-changes by the operations given below.
In the next step, we have the following.
prL(H reﬂ(α)(−x −1, y)) = r0
prD(H reﬂ(α)(−x, y −1)) = d0
prR(H reﬂ(α)(−x + 1, y)) = l0
Assume fwxyz(l0, d0,r0) = (l1, d1,r1). Since fr(wxyz)(r0, d0,l0) = (r1, d1,l1),
(Fr(wxyz) ◦H reﬂ(α))(−x, y) = (r1, d1,l1).
Finally, we have the following relation for all α and (x, y).
(H reﬂ◦Fr(wxyz) ◦H reﬂ(α))(x, y) = (l1, d1,r1) = Fwxyz(α)(x, y)
Therefore, Fwxyz = H reﬂ◦Fr(wxyz) ◦H reﬂholds, and thus
H reﬂ◦Fwxyz ◦H reﬂ= H reﬂ◦H reﬂ◦Fr(wxyz) ◦H reﬂ◦H reﬂ= Fr(wxyz).
This completes the proof.
□
From Proposition3 and Lemma2 the next Proposition is easily proved. Note that
apparently H rev ◦H reﬂ= H reﬂ◦H rev holds.
Proposition 4 Let T be a reversible ETPCA with the ID number wxyz. If inv(wxyz)
= r(wxyz), then the following holds.
F−1
wxyz = H rev ◦H reﬂ◦Fwxyz ◦H reﬂ◦H rev
Hence, T is time-symmetric under the involution H reﬂ◦H rev.
From Proposition4 and Table1 we have the following.
Corollary 2 The 20 reversible ETPCAs w13z, w15z, w16z, w23z, w26z, w34z,
w43z, w45z, w46z and w61z are time-symmetric under the involution H reﬂ◦H rev,
where (w, z) ∈{(0, 7), (7, 0)}.
By Proposition4 (or Corollary2) it is possible to obtain a backward pattern from a
given forward pattern for ETPCA wxyz that satisfy inv(wxyz) = r(wxyz) as shown

Gliders in the Game of Life and in a Reversible Cellular Automaton
121
Fig. 20 Time-symmetry under the involution Hreﬂ◦Hrev in ETPCA0347
in Fig.20. Namely, if the conﬁguration containing the forward pattern is α, then the
backward pattern is contained in H reﬂ◦H rev(α), which goes back the evolution of α.
This method is useful and often applied to conﬁgurations of ETPCA0347 to obtain
a backward module in the next section.
It is also possible to show time-symmetry of the remaining 8 reversible ETPCAs
that satisfy inv(wxyz) = rc(wxyz) (see Table1) using a suitable involution. It is
shown similarly as in Lemma2 and Proposition4, but it is omitted here.
3
The Glider in the Reversible ETPCA0347
In this section we focus on the reversible (but not conservative) ETPCA0347 having
the local function f0347 (Fig.21). The reason why we study ETPCA0347 is that it is
the most interesting CA in the class of ETPCAs (except its dual ones). In particular,
a glider exists in this cellular space, and, as in the case of GoL, it shows fascinating
behavior when it interacts with other patterns.
Despite the simplicity of the local function f0347, time evolutions in ETPCA0347
are generally very complex. Therefore, it is very hard to follow evolution processes
by paper and pencil. We developed an emulator for ETPCA0347 that works on a
general-purpose CA simulator Golly [17]. The emulator ﬁle and many pattern ﬁles
are available in [10] (though its new version has not yet been uploaded).
Fig. 21 Local function f0347 of ETPCA0347

122
K. Morita
3.1
Evolution from a One-Particle Pattern
Before discussing the glider, we examine how a one-particle pattern evolves in
ETPCA0347. Figure22 shows its evolution process. If we start from a one-particle
conﬁguration (t = 0) a disordered conﬁguration appears (t = 66), and it grows big-
ger and bigger (t = 350) as if an explosion occurs.
If we start from the conﬁguration of t = −66 in this ﬁgure, it ﬁrst shrinks, and
then becomes the one-particle conﬁguration at t = 0. After that it expands as in
the previous case. We can observe that the backward evolution of conﬁgurations
from t = 0 to t = −66 looks like the evolution from t = 0 to t = 66. It is explained
as follows. Let αt denote the conﬁguration at time t, where α0 is the one-particle
conﬁguration. Then, by the time-symmetry of ETPCA0347 (Proposition4), α−t =
H ◦(F0347)t ◦H(α0) holds, where H = H reﬂ◦H rev. Since H(α0) is a one-particle
conﬁguration obtained by rotating α0 by 60◦counter-clockwise, α−t is the rotated
conﬁguration of H(αt), and hence similar to αt in this sense. Thus, in the case of
one-particle conﬁguration, the evolution to the negative time direction from t = 0
looks very similar to the evolution to the positive time direction from t = 0.
It should be noted that if we start from a randomly chosen pattern rather than a
one-particle pattern, then, in most cases, an explosion similar to Fig.22 occurs even
if the starting pattern is very small. This feature of ETPCA0347 is very different
from that of GoL. In GoL, ever-growing patterns are very rare except the ones like
Fig. 22 Evolution process that goes through a one-particle pattern in ETPCA0347 [12]

Gliders in the Game of Life and in a Reversible Cellular Automaton
123
glider guns. Therefore, in ETPCA0347, we should ﬁnd patterns that do not cause
an explosion, and carefully combine them to construct larger functional modules. In
the rest of this section, such a type of useful patterns and phenomena are given.
3.2
The Glider and Useful Patterns
Figure23 shows the glider in ETPCA0347. It swims like a ﬁsh or an eel in the cellular
space. It has the period 6, and travels a unit distance, the side-length of a triangle,
in one period. The pattern at t (0 ≤t ≤5) is called a phase t glider. Rotating the
pattern by a multiple of 60◦, it can swim to any of the six directions. Note that the
backward pattern of a glider obtained by Proposition4 is again a glider of a different
phase (see Fig.20). So far, no space-moving pattern other than it has been found.
Figure24 shows a stable pattern called a block. It consists of nine particles. It will
be used to change the moving direction and to shift the phase of a glider.
Figure 25 shows a periodic pattern of period 6 called a ﬁn. It rotates around the
point indicated by ◦. The pattern at t (0 ≤t ≤5) is called a phase t ﬁn. It will be
used as a “sliding ﬁn memory” (Sect.3.5). It also appears when a glider collides with
a block (Sect.3.3).
In ETPCA0347 there are many small periodic patterns besides a ﬁn. However,
we do not describe them here, since reversible computers can be composed only of
a glider, a block and a ﬁn (Sect.4).
t = 0
•
•
••
••
t = 1
•
•
••
••
t = 2
••
•
••
•
t = 3
••
•
•
••
t = 4
•
••
••
•
t = 5
•
••
•
••
t = 6
•
•
••
••
Fig. 23 The glider in ETPCA 0347 [12]
Fig. 24 A stable pattern
called a block in ETPCA
0347 [12]
••• •
••• ••

124
K. Morita
t = 0
•
••
t = 1
•
••
t = 2
•
••
t = 3
••
•
t = 4
••
•
t = 5
••
•
t = 6
•
••
Fig. 25 A periodic pattern called a ﬁn in ETPCA 0347 [12]
3.3
Controlling a Glider
We can see that the moving direction and the phase of the glider in ETPCA0347 are
controllable by placing blocks appropriately.
Figure26 shows that 60◦-right-turn of a glider is possible by a simple pattern
consisting of two blocks. This pattern is modularized as a 60◦-right-turn gadget for
composing larger modules.
In GoL, a more complex pattern is required to realize a 90◦-right-turn as shown
in Fig.6. However, since the local function of GoL has the property of reﬂection-
symmetry, 90◦-left-turn is possible by taking the mirror image of this pattern. On
the other hand, it is not possible to have a 60◦-left-turn gadget from the 60◦-right-
turn gadget by the time-symmetric property of ETPCA0347 (Corollary2). This is
because the “backward gadget” obtained by this method is again a 60◦-right-turn
gadget, since the involution H reﬂ◦H rev contains H reﬂthat gives the mirror image
of the conﬁguration.
Figure27a is a 120◦-right-turn gadget. Assume a glider collides with this gadget
as in the ﬁgure at t = 0. Then, the glider is decomposed into a rotator (left), which
may be regarded as a body of the glider, and a ﬁn (right) (t = 56). The rotator
(i.e., body) rotates around the small circle with the period 42, while the ﬁn moves
around the sequence of blocks four times. Finally, the ﬁn is attached to the body,
and a glider is reconstructed. Then, it can swim again, and goes to the south-west
t = 0
••• •
••• •• ••• •
•
•
••
••• ••
••
t = 17
••• •
••• •• ••• •
•
•• ••
•
••
t = 18
••• •
••• •• •••• •
•
•• ••• ••
••
t = 19
••• •
••• • ••• •
•• ••
•
•
t = 20
••• •
•••• •• •••• •
••
••• ••
••
t = 21
••• •
••• • ••• •
•
••• ••
•
••
t = 22
••• •
•••• •• ••• •
•
••• ••
••
••
t = 23
••• •
••• •• ••• •
•
••• ••
••
•
••
Fig. 26 60◦-right-turn gadget for a glider composed of two blocks [14]

Gliders in the Game of Life and in a Reversible Cellular Automaton
125
t = 0
•
•
••
••• •
••• •
••
••• ••
••• ••
t = 56
••
••••••
••• •
••
••
••••••
••• ••
•
••
t = 334
••• •
••• •
••• ••
••• ••
••
•
•
••
(a)
t = 0
•
•
••
••• •
••• •
••• •
••
••• ••
••• ••
••• ••
t = 250
••• •
••• •
••• •
••• ••
••• ••
••• ••
••
•
•
••
(b)
Fig. 27 120◦-right-turn gadgets for gliders composed of a two blocks, and b three blocks [12]
Input
Output
Bidirectional signal path
••• •
••• •
••• •
••• ••
••• ••
••• ••
Fig. 28 Interface gadget between bidirectional and unidirectional signal paths [12]
direction (t = 334). The turn gadgets given in Figs.27, 28 and 29 also employ such
a mechanism.
Sequences of three and ﬁve blocks also act as 120◦-right-turn gadgets. Figure27b
shows the case of three blocks. They have shorter delays than the case of two blocks
(Fig.27a).
It should be noted that 120◦-right-turn can be realized by two successive 60◦-
right-turns (Fig.26). The latter is more useful, since it has a shorter delay than those
of 120◦-right-turn gadgets. However, as shown in Fig.28, a 120◦-right-turn gadget
can be used as an interface between bidirectional and unidirectional signal paths. We
need such a mechanism in the glider gun/absorber (Fig.34), and in the gadget for
shifting a ﬁn (Fig.36).
Figure29a is a 120◦-left-turn gadget, which is more complex than the 120◦-right-
turn gadgets. Figure29b is a backward-turn gadget consisting only of one block, and
Fig.29c is a U-turn gadget.

126
K. Morita
t = 0
•
•
••
••• •
••
••• ••
•• •••
•• •••
••• •
• •••
• •••
••• ••
••• •
•• •••
••• •
•• •••
••• ••
• •••
••• ••
• •••
•• •••
••• •
•• •••
••• •
• •••
••• ••
• •••
••• ••
t = 366
••
•
••
•
••• •
••• ••
•• •••
•• •••
••• •
• •••
• •••
••• ••
••• •
•• •••
••• •
•• •••
••• ••
• •••
••• ••
• •••
•• •••
••• •
•• •••
••• •
• •••
••• ••
• •••
••• ••
(a)
t = 0
•
•
••
••• •
••
••• ••
t = 97
••
••• •
••
•
•
••• ••
(b)
t = 0
••• •
•
•
••
••• •
••• ••
••
••• ••
•• •••
••• •
• •••
••• •• ••• •
••• ••
t = 113
••• •
••• •
••• ••
••• ••
•• •••
••
••• •
• •••
••
•
•
••• •• ••• •
••• ••
(c)
Fig. 29 a 120◦-left-turn gadget, b backward-turn gadget, and c U-turn gadget for a glider [12]
Table2 shows the net delay and the phase shift of each of seven turn gadgets. The
net delay d is the additional delay caused by a turn gadget. For example, consider the
120◦-right-turn gadget composed of two blocks (Fig.27a). The travelling distance of
the glider from t = 0 to t = 334 along the arrow line is 5 (note that the glider is in
the phase 0 both at t = 0 and t = 334). If the glider travels this distance in a vacant
space, it takes 6 × 5 = 30 steps. Hence, the net delay is d = 334 −30 = 304. The
phase shift s is the shift value of the phase of a glider by the gadget. It is calculated
by s = (−d) mod 6. In the above case, s = (−304) mod 6 = 2.
If we want to control only the move direction of a glider, it is performed by using
only 60◦and 120◦-right-turn gadgets. However, shifting the phase is not possible
only by them. It is achieved by using at least one of the left-turn, backward-turn and
U-turn gadgets besides the right-turn gadgets (see [11] for the details).

Gliders in the Game of Life and in a Reversible Cellular Automaton
127
Table 2 Net delay and phase shift of turn gadgets [12]
Gadget
Net delay d
Phase shift s
Right-turn (60◦) by 2 blocks
5
+1
Right-turn (120◦) by 2 blocks
304
+2
Right-turn (120◦) by 3 blocks
220
+2
Right-turn (120◦) by 5 blocks
178
+2
Left-turn (120◦)
342
0
Backward-turn
73
+5
U-turn
77
+1
3.4
Collisions of Gliders
Here we observe how conﬁgurations evolve when two gliders collide. First, consider
the collision with an angle of 60◦as in Fig.30. In this collision the upper glider moves
straight ahead to the south-east direction, while the glider from the west makes a
120◦-right turn. This phenomenon can be used as a kind of logical operation.
A switch gate is a 2-input 3-output reversible logic gate that realizes the logical
function (c, x) →(c, cx, cx) [3]. If the control signal c is 0, then the other input
signal x comes out from the second output port. On the other hand, if c is 1, then the
signal x comes out from the third output port. We can see that the phenomenon shown
in Fig.30 just realizes such a switching operation. However, to make it easy to use the
phenomenon as a logical device, some additional mechanisms are needed. Figure31a
is a switch gate module that contains many turn gadgets for controlling the moving
directions and adjusting the phases of gliders. Around the center of this pattern two
gliders can collide, by which the switching operation is performed. Furthermore, the
delay between the input ports and the output ports is kept constant. In this case it is
894 steps. By above, it becomes a easily usable module.
An inverse switch gate is a 3-input 2-output reversible logic gate, which undoes the
operation of a switch gate [3]. It realizes the logical function (y1, y2, y3) →(c, x),
t = 0
c
x
•
••
•
••
•
•
•• ••
t = 24 c
x
•
••
•
• ••
•
•• ••
t = 48 c
x
cx
cx
c
• •
•
••
••
•
••
••
Fig. 30 Switching operation in ETPCA 0347 [12]

128
K. Morita
t = 894
c
x
c
cx
cx
••
•
•
••
••
•
•
••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••••
••••
••• ••
•• •••
••••
••• ••
••••
•• •••
••••
••• •• ••••
•• •••
••••
••••
••• ••
••••
••• ••
•• •••
••••
••• •• ••••
••• ••
••••
••••
••••
••• ••
••••
••• ••
••• ••
••• ••
••••
••••
•• •••
••••
••• ••
••• ••
••••
•• •••
••••
••• ••
••••
••• ••
••••
•
• ••
••• ••
•• •••
••
••••
••••
••••
•• •••
••••
••••
••• ••
•• •••
••• •• ••••
•• •••
••••
••• •• ••••
••• ••
••••
•• •••
•••• •• •••
••• ••
••••
••• ••
••••
••••
••• ••
•• •••
••••
••••
••• •• ••••
••• ••
••••
••••
••• ••
••••
••• •• ••••
••• ••
••••
••• ••
••••
•• •••
••••
••• •• ••••
••••
••• ••
•• •••
••••
••• ••
••••
••• ••
••••
••••
••• •• ••••
••••
••••
•• •••
••••
•
• ••
••• ••
••• •• ••••
••• ••
••• ••
••• ••
••• ••
•• •••
•••• ••••
••
••• ••
•• •••
••••
••••
•• •••
•••• •• •••
•• •••
••• ••
•• •••
••••
•• •••
••••
••• ••
••• ••
••••
••••
•••• ••••
••••
••• ••
••••
••••
•• •••
•• •••
••••
••• ••
•• •••
••••
••• ••
•• •••
•• •••
•••• •• •••
••••
••• ••
••••
••• ••
••••
••••
••••
••••
••••
••• ••
•• •••
••••
•• •••
••••
•• •••
••••
••• ••
••••
•••• •• •••
••••
••• ••
•• •••
••••
••• ••
•••• •• •••
••••
••• ••
••••
••• ••
••••
••• ••
•• •••
••••
••••
••• ••
••• ••
••••
••••
••• ••
••••
••••
••• ••
••••
••• ••
••••
••• ••
••••
••• ••
••••
••• ••
•• •••
••••
••• ••
••••
•••• •• •••
••••
••• ••
••••
••• ••
••••
••• ••
••• ••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
(a)
t = 894
••
•
•
••
••
•
•
••
y1
y2
y3
c
x
•• •••
•• •••
•• •••
•• •••
•• •••
•• •••
•• •••
•• •••
•• •••
•• •••
•• •••
•• •••
•• •••
•• •••
•• •••
•• •••
•• •••
•• •••
•• •••
•• •••
•• •••
•• •••
•• •••
•• •••
•• •••
•• •••
•• •••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
•• •••
•• •••
••••
•• •••
••••
••••
•• •••
•• •••
••••
•• •••
••••
••• •• ••••
•• •••
••••
•• •••
••••
••• •• ••••
••••
••• ••
••••
•• •••
••••
••• ••
•• •••
•• •••
••••
••••
••••
•• •••
••••
•• •••
•• •••
••••
••• •• ••••
•• •••
••••
••••
••• ••
•••• •• •••
•
• ••
••••
••••
••
•• •••
•• •••
••••
••• ••
•• •••
•• •••
••••
•• •••
••••
••• •• ••••
•• •••
••••
••••
••••
•• •••
•• •••
••••
••• ••
••••
••••
••• ••
••••
•• •••
••••
•• •••
••••
••• ••
••• •• ••••
••••
•• •••
••••
••• ••
•• •••
••••
•• •••
••••
•• •••
••••
•• •••
•••• •• •••
••••
••• •• ••••
••••
•• •••
•• •••
••••
••• ••
••••
•• •••
•• •••
•• •••
•••• •• •••
•• •••
•••• •• •••
•• •••
••• ••
••••
••••
••••
••••
••••
•• •••
••••
••••
•• •••
••••
•••• ••••
••••
••• •• ••••
•• •••
•• •••
••••
••••
•
• ••
••••
••• ••
•• •••
••• ••
••• ••
••• ••
••••
••••
••• ••
••••
••
•• •••
••••
••••
•• •••
••••
••••
••• ••
•• •••
••••
••• ••
••••
••• ••
••••
••• •• ••••
••••
••••
•• •••
••• ••
••• ••
••• ••
•• •••
••••
•• •••
••••
•• •••
••••
•• •••
••••
••••
•• •••
•••• •• •••
••••
••• ••
••••
••• ••
••••
•••• •• •••
••••
••• ••
•• •••
••••
••••
••• ••
••• •• ••••
••••
••• ••
••••
••• ••
•• •••
•• •••
••••
•• •••
••••
•• •••
••••
•• •••
••••
•• •••
••••
•• •••
••••
•• •••
••••
••••
•• •••
•••• •• •••
••••
••• ••
•• •••
••••
••••
••• ••
••••
•• •••
•• •••
•• •••
•• •••
•• •••
•• •••
•• •••
•• •••
•• •••
•• •••
•• •••
•• •••
•• •••
•• •••
•• •••
•• •••
•• •••
•• •••
•• •••
•• •••
•• •••
•• •••
•• •••
•• •••
•• •••
•• •••
•• •••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
(b)
Fig. 31 a Switch gate module, and b inverse switch gate module implemented in ETPCA 0347.
In b, c = y1 and x = y2 + y3 assuming that (y2 →y1) ∧(y3 →y1). These patterns are revised
versions of the ones in [12]
where c = y1 and x = y2 + y3 under the assumption (y2 →y1) ∧(y3 →y1). Hence
it is not totally deﬁned on the set {0, 1}3. By the time-symmetry of ETPCA0347
(Corollary2), we can obtain an inverse switch gate module by applying H reﬂ◦H rev
to the switch gate module (see Fig.20). The resulting pattern is shown in Fig.31b.
A Fredkin gate proposed by Fredkin and Toffoli [3] is a 3-input 3-output universal
reversible logic gate. It realizes the logical function (c, p, q) →(c, x, y), where
x = cp + cq and y = cq + cp. It is known that a Fredkin gate is composed of two
switch gates and two inverse switch gates [3]. Figure32 is a Fredkin gate constructed
by this method.
Since a Fredkin gate is universal, reversible computers, such as reversible Turing
machines, can be constructed using only this gate. However, if we do so, the resulting
pattern becomes very complex and huge, because two or more signals must arrive at

Gliders in the Game of Life and in a Reversible Cellular Automaton
129
each gate at exactly the same time, and hence adjustment of signal timing is necessary.
This problem is discussed in [14]. In Sect.4 we use a reversible logic element with
one-bit memory (RLEM) rather than reversible logic gates to compose reversible
Turing machines concisely.
Next, we consider other cases of collisions of gliders. In GoL, we saw that it is
possible to produce no glider or one glider by a collision of two gliders (see Figs.7 and
8). In ETPCA0347, such a process is impossible because of its reversibility. Namely,
if two or more gliders collide in ETPCA0347, and only gliders are generated in this
process, the number of the generated gliders must be two or more.
In fact, it is possible to produce three gliders by a head-on collision of two gliders
(Fig.33a). By the time-symmetry (Corollary2), it is also possible to produce two
gliders by a collision of three gliders (Fig.33b). The conﬁguration at t = 0 in Fig.33b
is obtained from the one at t = 30 in Fig.33a by applying H reﬂ◦H rev. On the other
hand, the conﬁguration at t = 0 in Fig.33a is obtained from the one at t = 30 in
Fig.33b by H reﬂ◦H rev. Note that application of H reﬂ◦H rev to a glider gives a
glider of a different phase (see Fig.20). In this way, we can increase or decrease the
number of gliders.
Using these phenomena, we compose a glider gun and a glider absorber as in
Fig.34. The glider gun (absorber, respectively) generates (absorbs) gliders every 834
steps. In the case of GoL, erasing gliders is simply done by an eater shown in the
lower right part of Fig.5, because it is an irreversible CA. In ETPCA0347, however,
such a simple erasure is not possible. We need a glider absorber, which is a backward
pattern of a glider gun, to reversibly erase gliders.
3.5
Collisions of a Glider with a Fin
We can observe interesting and useful phenomena by collisions of a glider with a
ﬁn. Figure35 shows that a three-way glider gun is obtained by a collision of a glider
and a ﬁn. It generates three gliders every 24 steps.
Patterns in Fig.36 are more useful, where the position of a ﬁn is pulled or pushed
by colliding a glider. Similar to the sliding block memory in GoL (Fig.9), a ﬁn can
be used as a memory in ETPCA0347, which may be called the sliding ﬁn memory.
It will be used to compose a reversible logic element with memory (RLEM) in
Sect.4.1 Note that evolutions in Fig.36a and b are mutually time-symmetric under
the involution H reﬂ◦H rev (but rotated by 180◦).

130
K. Morita
Fig. 32 Fredkin gate
module in ETPCA 0347.
Here, x = cp + cq and
y = cq + cp. It is composed
of two switch gates and two
inverse switch gates. It is a
revised version of the one in
[12]
t = 3840
c
p
q
c
x
y
••
•
•
••
••
•
•
••
••
•
•
••
•• •••
••••
•• •••
••••
••• •• ••••
••••
••• ••
•• •••
••••
•• •••
••••
••••
••• ••
••••
••• ••
•• •••
••••
•• •••
••••
••••
•• •••
••••
•• •••
••••
••• ••
•• •••
••••
•• •••
••••
••• •• ••••
•• •••
••••
••••
•• •••
••••
••• •• ••••
•• •••
••••
•• •••
••••
•• •••
••••
••• •• ••••
•• •••
•• •••
••••
•• •••
••••
••• •• ••••
••••
••• ••
•• •••
••••
••• •• ••••
••• ••
••••
••• ••
•• •••
••••
••• •• ••••
•• •••
••••
••• •• ••••
••••
••• ••
••••
•• •••
••••
••• •• ••••
••••
••• ••
••••
••••
••• ••
••••
••••
••••
••• ••
••••
••• ••
•• •••
•• •••
••••
••• ••
•• •••
••• ••
••• ••
••• ••
••••
••••
••••
••••
•• •••
••••
•• •••
••••
•• •••
••••
•• •••
••• ••
••••
•• •••
••••
••• ••
••••
•• •••
••••
••• •• ••••
•• •••
••••
••• •• ••••
•• •••
••••
••••
••• ••
••••
••••
••• ••
••••
••• ••
•••• •• •••
••• ••
•••• •• •••
•
• ••
••• ••
•• •••
••• ••
•• •••
••••
••••
••••
••••
••
••••
••••
•• •••
••••
••••
•• •••
••••
••••
•• •••
••••
•• •••
••••
••• ••
•• •••
••••
•• •••
•• •••
••••
••• ••
•• •••
•• •••
••• •• ••••
•• •••
••••
••• •• ••••
••• ••
••••
•• •••
••• •• ••••
•• •••
••••
••• •• ••••
•• •••
••••
••• •• ••••
•• •••
••••
••••
••• ••
••••
•• •••
••••
••• •• ••••
•• •••
••••
••••
•• •••
•••• •• •••
••• ••
••••
••• ••
••••
••••
•• •••
•• •••
•••• •• •••
••• ••
••••
••• ••
••••
•• •••
••••
••• ••
••••
••••
••• ••
••••
••••
•• •••
•• •••
••••
••• ••
••••
••••
••• ••
••••
•• •••
••••
••••
••• •• ••••
••• ••
••••
•• •••
••••
••••
••• •• ••••
•• •••
••••
••• ••
••• •• ••••
••• ••
••••
•• •••
••••
••• ••
••• •• ••••
••••
••• ••
•• •••
••••
••••
••• ••
••••
••• ••
•• •••
••••
••••
••• ••
••••
•••• •• •••
••••
••• ••
••••
•• •••
•••• •• •••
••••
••• ••
•• •••
••• ••
••••
•• •••
••••
••••
••• ••
••• ••
••••
•• •••
••••
•• •••
••••
••••
•• •••
••• ••
••••
•• •••
••••
••••
••••
••• ••
•• •••
••••
••• •• ••••
••••
••••
••• ••
•• •••
••••
••• •• ••••
••••
•• •••
•• •••
•• •••
••••
••• •• ••••
••••
•• •••
•• •••
••• ••
••••
••••
••• •• ••••
••••
••••
•• •••
••••
••• ••
•• •••
••• ••
••••
••••
••• •• ••••
••••
••••
•• •••
••••
••• ••
••••
•• •••
•• •••
•• •••
•••• •• •••
•• •••
•••• ••••
••••
••• ••
••••
•• •••
•• •••
•• •••
•••• •• •••
•• •••
••••
••• •• ••••
••• ••
••• ••
••• ••
••• ••
•• •••
•••• ••••
•• •••
•• •••
••••
••• •• ••••
••• ••
••• ••
••• ••
••• ••
•• •••
•••• ••••
•• •••
••• ••
••••
••••
••••
••••
••••
•• •••
••••
••• •• ••••
••••
•• •••
••• ••
••••
••••
••••
••••
••••
•• •••
••••
••• ••
•• •••
••••
••••
•• •••
•••• •• •••
•• •••
••• ••
•• •••
••••
••••
••••
••• ••
•• •••
••••
••••
•• •••
•••• •• •••
•• •••
••• ••
•• •••
••••
•••• ••••
••••
••• •• ••••
•• •••
•• •••
••••
••••
••• ••
••• ••
•• •••
••••
•••• ••••
••••
••• •• ••••
•• •••
•• •••
••••
••••
•
• ••
•• •••
••••
••• ••
••• ••
••••
••••
•••• ••••
••••
••• ••
•• •••
•• •••
••••
••• ••
••• ••
••••
••••
•••• ••••
••••
••• ••
•• •••
••• ••
••• ••
••• ••
••••
••••
••• ••
••••
••••
••••
••• ••
•• •••
••• ••
••• ••
••• ••
••••
••••
••• ••
••••
••
••••
•• •••
•• •••
••••
••• ••
•• •••
••••
••••
••••
•• •••
•• •••
••••
••• ••
•• •••
••••
••••
•• •••
••••
••••
••• ••
••• ••
•• •••
••••
••••
•• •••
••••
••••
••• ••
•• •••
•• •••
•••• •• •••
••••
••• ••
••••
••• ••
•• •••
•• •••
•••• •• •••
••••
••• ••
••••
••• ••
••••
••• ••
••••
••• •• ••••
••••
••••
••• ••
••••
••• ••
••••
••• •• ••••
••••
••••
••••
••••
•• •••
••••
••••
••••
••••
••• ••
••• ••
••• ••
•• •••
••••
••• ••
••• ••
••• ••
•• •••
••••
•• •••
••••
•• •••
••••
•••• •• •••
••••
••• ••
•• •••
••••
•• •••
••••
•• •••
••••
•• •••
••••
•• •••
••••
•• •••
••••
•••• •• •••
••••
••• ••
•• •••
••••
•• •••
••••
•• •••
••••
•••• •• •••
••••
••• ••
•• •••
••••
••• ••
•••• •• •••
••••
••• ••
••••
••••
••• ••
•••• •• •••
••••
••• ••
•• •••
••••
••• ••
•••• •• •••
••••
••• ••
••••
•• •••
•••• •• •••
••••
••• ••
••••
••• ••
••••
•••• •• •••
••••
••• ••
••••
••• ••
•• •••
•••• •• •••
••••
••• ••
••••
••• ••
••••
•••• •• •••
••••
••• ••
••••
••• ••
•• •••
••••
••••
••• ••
••• •• ••••
••••
••• ••
•• •••
••••
••••
••• ••
••• •• ••••
•• •••
••••
••••
••• ••
••• •• ••••
••••
••• ••
•• •••
••••
••••
••• ••
••• •• ••••
••••
••• ••
••••
••• ••
••••
••• ••
••••
••• ••
••••
••• ••
••••
••••
••••
•• •••
•• •••
•• •••
••••
••• ••
••• ••
••• ••
••••
••••
••••
•• •••
••• •• ••••
••••
••••
••••
•• •••
•• •••
•• •••
•• •••
••••
••• ••
••• ••
••• ••
••• ••
•• •••
••••
••••
••••
••••
••••
•
• ••
•• •••
••••
•• •••
••••
••••
••• ••
•• •••
••••
•• •••
••••
••
•• •••
•••• •• •••
••••
••• ••
•••• •• •••
••••
••• ••
•• •••
••••
•••• •• •••
••••
••• ••
•••• •• •••
••••
••• ••
••••
••••
••••
••• ••
••••
••• ••
••••
••• ••
••••
••• ••
••••
••• ••
••• ••
•• •••
•• •••
••••
•• •••
••••
••••
•• •••
••••
••••
••• •• ••••
•• •••
••••
••• ••
••• •• ••••
••••
••• ••
••••
••• ••
••••
•• •••
••••
•• •••
••• ••
••••
••• ••
••••
••••
•• •••
••••
•• •••
••• ••
•• •••
••••
••• ••
••••
••••
•• •••
••••
••••
•• •••
••••
•• •••
••••
••• ••
•• •••
••••
•••• •• •••
••••
••• ••
•• •••
•• •••
•••• •• •••
••••
••• ••
••••
•••• •• •••
••••
••• ••
••••
•••• •• •••
••••
••• ••
••••
••• ••
•• •••
••••
••••
••••
••• ••
••• •• ••••
••••
••• ••
••• ••
••••
••• ••
••••
••• ••
••••
••• ••
•• •••
••••
••••
•• •••
••••
••• •• ••••
••• ••
••••
••• ••
••••
•• •••
•• •••
••••
••• ••
•• •••
••••
•••• •• •••
••••
••• ••
••••
••••
•• •••
••••
••• ••
••• ••
•• •••
••••
••••
•• •••
••••
•• •••
••••
•• •••
••••
•••• •• •••
••••
••• ••
•••• •• •••
••••
••• ••
•••• •• •••
••••
••• ••
••••
••• ••
••••
••• ••
••••
••• ••

Gliders in the Game of Life and in a Reversible Cellular Automaton
131
t = 0
•
•
••
••
•
•
••
••
t = 30
••
•
••
•
••
•
••
•
••
•
•
••
(a)
t = 0
•
•
••
•
••
•
••
••
••
•
••
•
t = 30
••
••
••
•
•
•
•
••
(b)
Fig. 33 a Generating three gliders by a collision of two gliders, and b generating two gliders by a
collision of three gliders [12]. Each of these processes is obtained from the other by the property
of time-symmetry
••• •
•• •••
••• ••
• •••
••• •
•• •••
••• ••
• •••
••• •
•• •••
••• ••
• •••
••• •
•• •••
••• ••
• •••
••• •
•• •••
••• ••
• •••
•• •••
••• •
•• •••
••• •
•• •••
••• •
•• •••
••• •
•• •••
• •••
••• •• ••• •
•• •••
• •••
••• •• ••• •
•• •••
• •••
••• •• ••• •
•• •••
• •••
••• •• ••• •
• •••
••• ••
• •••
••• ••
• •••
••• ••
• •••
••• ••
••• •
•• •••
••• •
•• •••
••• ••
• •••
••• ••
• •••
••• •
•• •••
••• •
•• •••
••• ••
• •••
••• ••
• •••
•• •••
••• •
•• •••
••• •
•• •••
• ••• •• •••
••• •
••• ••
• ••• •• •••
••• •
••• ••
••
•
••• •
•• •••
• •••
• •••
••• ••
• •••
••• ••
•
••• •• ••• •
• •••
•
••
••
••
••
•
••• •
•• •••
••
•
••
••• ••
•
•
••• ••
• •••
••
•
••• •
•• •••
••• •
•• •••
••• ••
••• •
• •••
••• ••
•• •••
••
•
• •••
••• •
••• •• ••• •
•• •••
••• •
•• •••
• ••• •• •••
••
••• ••
••• ••
• •••
••• ••
• •••
• •••
•
•• •••
••• •
•• •••
••• •
•• •••
••• •
••• •
•• •••
• •••
••• ••
• •••
••• ••
• •••
••• ••
••• •
•• •••
••• ••
• •••
•• •••
••• •
••• ••
• •••
••• •
•• •••
• •••
••• ••
••• •
•• •••
••• ••
• •••
••• ••
• •••
••• •
•• •••
••• •
••• •
•• •••
•• •••
••• •
•• •••
••• ••
• •••
••• ••
••• ••
• •••
• •••
••• ••
• •••
Fig. 34 Glider gun (left) and absorber (right). These are revised versions of the ones in [12]

132
K. Morita
t = 0
•
•
••
••
•
••
t = 96
•
•
••
••
•
•
••
••
•
•
••
••
•
•
••
•
•
••
•
•
••
••
•••
••
••
••
••
•
••
••
•
•
••
••
•
•
••
••
Fig. 35 Three-way glider gun obtained by a collision of a glider with a ﬁn [12]
t = 0
••
•
•
••
••
•
t = 54

••
••
•
•
•
••
(a)
t = 0
•
••
•
•
••
••
t = 72
j
••
•
•
••
••
•
(b)
Fig. 36 Sliding ﬁn memory. a Pulling, and b pushing a ﬁn is possible by colliding a glider with a
ﬁn [9]
4
Composing Reversible Computers in ETPCA 0347 Using
a Glider
Using a glider and useful phenomena found in Sect.3, we can construct reversible
Turing machines (RTMs). In this section we show its outline. Gadgets that are used
to construct RTMs are turn gadgets given in Sect.3.3 and the gadget for the sliding
ﬁn memory (Fig.36). No other phenomenon is used here.

Gliders in the Game of Life and in a Reversible Cellular Automaton
133
4.1
Making a Reversible Logic Element with Memory
We use a reversible logic element with memory (RLEM) rather than a reversible logic
gate as a logical primitive for constructing RTMs. If we use a logic gate, two or more
input signals must arrive at each gate at exactly the same time, and thus adjustment
of signal timing is necessary. By this, patterns that simulate RTMs become quite
huge. On the other hand, if we use an RLEM, there is no such timing problem, and
hence the resulting patterns become much smaller. Note that a comparison of these
two methods is found in [14].
An RLEM is a kind of a reversible ﬁnite automaton having an output port as
well as an input port, which is sometimes called a reversible sequential machine. A
sequential machine M is deﬁned by M = (Q, , , δ), where Q is a ﬁnite set of
states,  and  are ﬁnite sets of input and output symbols, and δ : Q ×  →Q × 
is a move function (Fig.37). If δ is injective, it is called a reversible sequential
machine (RSM).
A reversible logic element with memory (RLEM) is an RSM that satisﬁes || =
||. A 2-state RLEM (i.e., |Q| = 2) is particularly important, since it is simple yet
powerful. It is known that every RLEMs that satisﬁes || = || ≥3 is universal,
which means any RSM is composed only of it (see, e.g., [11]). In the following we
use a speciﬁc 2-state 4-symbol universal RLEM No. 4-31.
The move function δ of RLEM 4-31 is represented in a graphical form as shown
in Fig.38. Two rectangles in the ﬁgure correspond to the two states 0 and 1. Solid
and dotted lines show the input-output relation in each state. If an input signal goes
through a dotted line, then the state does not change (Fig.39a). On the other hand, if
a signal goes through a solid line, then the state changes (Fig.39b).
It is possible to implement RLEM 4-31 in the cellular space of ETPCA0347.
Figure40 shows the complete pattern that simulates RLEM 4-31. Two circles in the
middle of the pattern show possible positions of a ﬁn. In this ﬁgure, the ﬁn is at the
lower position, which indicates the state of the RLEM 4-31 is 0. Many blocks are
placed to form various turn gadgets shown in Figs.26, 27, 28 and 29. They are for
controlling the direction and the phase of a glider.
Fig. 37 Sequential machine
with the move function δ
such that δ(p, ai) = (q, s j)
Fig. 38 A four-symbol
two-state RLEM 4-31

134
K. Morita
Fig. 39 Operations of RLEM 4-31. a A case where a signal goes through a dotted line, and b a
case where it goes through a solid line
a
b
c
d
w
x
y
z
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••••
••••
••• ••
••••
•• •••
••• ••
••••
••• ••
••••
••••
••• ••
••••
•• •••
••• ••
••••
••••
••• ••
••••
•• •••
••••
•• •••
••••
••• ••
••• •• ••••
••••
••• •• ••••
•• •••
••••
•• •••
•• •••
••••
••• ••
••• ••
••• ••
••• ••
••••
••••
••••
••••
••••
••• ••
•• •••
••••
•• •••
••••
••• ••
••••
••••
••• ••
••••
••• ••
••••
••• ••
••••
•• •••
••• ••
••••
••• ••
••••
••••
••• ••
•• •••
••••
••••
•• •••
••• ••
••••
•• •••
••••
••• •• ••••
••• ••
••••
••••
••• ••
••••
••• ••
••••
•• •••
••• ••
••••
••••
•• •••
••• ••
••••
•• •••
••••
••••
••••
••• ••
••• ••
••••
••••
••••
••• ••
••• •• ••••
••• ••
••••
••••
•• •••
••• ••
••• ••
••••
••• ••
••• ••
••••
••• ••
••••
••••
•• •••
••••
••••
•• •••
••••
••••
••• ••
••• ••
•••• •• •••
••••
••• ••
••••
••• ••
••••
••• ••
••• ••
••••
••••
••••
••• ••
••• •• ••••
•• •••
••••
•• •••
••••
••• ••
••• ••
••••
••• ••
••••
••• ••
•• •••
••••
••• ••
••••
••• ••
••••
••••
•• •••
••••
••• ••
•• •••
••• ••
••• ••
••••
••••
••••
••••
••••
••••
••••
••• ••
•• •••
••• •• ••••
••• ••
•• •••
••• ••
••• ••
••••
•••• •• •••
••• ••
••••
••••
••••
••••
••• ••
••••
•• •••
••• ••
•• •••
••••
•• •••
••• ••
••••
••• ••
••••
•• •••
••••
••••
••• ••
••••
••• •• ••••
••••
••• ••
••••
••• ••
••• ••
••••
•• •••
••••
••••
••• ••
••••
••• ••
•• •••
••• ••
••••
•• •••
••••
•• •••
••••
••• ••
•• •••
••••
••••
•• •••
•• •••
•••• •• •••
••• ••
••••
•••• •• •••
••••
••••
••••
•• •••
••••
••• ••
••••
••••
••••
••••
••• ••
••••
••••
••• ••
••• ••
••• ••
•• •••
••••
••• ••
•• •••
••••
••• ••
••••
••• ••
•• •••
••••
• ••
••••
••••
••••
••••
••• ••
••••
••• ••
•• •••
••••
••••
••• ••
••• ••
••• ••
••• ••
••••
••••
•• •••
••••
••••
••••
••• ••
••••
••••
••• ••
••••
••• ••
••• ••
••• ••
••• •• ••••
•• •••
••• ••
••• ••
•••• •• •••
••••
••••
••••
••••
••••
••••
••• ••
•• •••
••••
••• ••
••• ••
••• ••
••• ••
•• •••
••••
••••
••• ••
••••
••••
••••
••••
••••
••••
••• ••
••••
••• ••
••• ••
••• ••
••• ••
••• ••
•• •••
••••
••• ••
••••
••••
••••
••••
•• •••
••••
••• •• ••••
••••
••• ••
••• ••
••• ••
••• ••
••••
••• ••
••• ••
••••
••••
••••
••••
•• •••
•• •••
••••
••• ••
••• ••
•• •••
••••
•• •••
••• ••
••• ••
••••
••••
••• ••
••••
••••
••• ••
••••
••••
••••
•• •••
•• •••
••••
••• ••
••••
••••
•• •••
•• •••
••• ••
••• ••
••••
••••
••••
••• ••
••••
••• •• ••••
••• ••
••••
••••
••••
••• •• ••••
••••
••• ••
••• ••
•• •••
••• ••
••• ••
••• ••
••••
••••
•• •••
•• •••
••••
••••
••• ••
••••
••••
••••
••• ••
••• ••
••••
•• •••
••• ••
•• •••
•• •••
••••
••• ••
••••
•••• •• •••
••••
•• •••
••••
••• ••
•
• ••
••••
••• ••
••••
••••
••
••• ••
•• •••
••••
••••
•• •••
•• •••
•• •••
••••
••••
•• •••
•• •••
••• ••
••••
••• ••
••••
••••
••••
••• •• ••••
•••• •• •••
••••
••••
••••
••• ••
••••
••• ••
•• •••
••••
••• ••
•• •••
••• ••
••••
••• ••
••••
••••
••••
••••
••••
•• •••
••••
••• ••
••••
•• •••
••• ••
••••
••• ••
••• ••
•• •••
•••• •• •••
••••
••• ••
••••
••• ••
••••
••••
••• ••
••••
••••
••• ••
••• ••
••••
•• •••
•• •••
••• ••
••••
••• ••
•••• •• •••
••••
••••
••• ••
••••
••••
••••
••• ••
•• •••
•• •••
••••
••• ••
••• ••
•• •••
•••• •• •••
••••
••• ••
••••
•• •••
••••
••••
••••
•• •••
••••
••• ••
••••
••••
••• ••
••••
••• ••
••••
•• •••
•• •••
••••
••••
••• ••
•• •••
••••
••• ••
••••
••••
••• ••
••••
••• ••
••••
••• ••
••••
••• ••
••••
••• ••
••• ••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
••• ••
Fig. 40 RLEM 4-31 implemented in ETPCA 0347 [14]. In this ﬁgure, the glider given to the input
port d shifts the ﬁn from the position of the lower circle to that of the upper circle, and ﬁnally goes
out from the output port w. By this, the state of the RLEM changes from 0 to 1
In Fig.40, a glider is given to the input port d. The path from d to the output port
w shows the trajectory of the glider. The glider ﬁrst goes to the north-east position.
From there the glider moves to the south-west direction, and collides with the ﬁn.
By this, the ﬁn is pulled upward by the operation shown in Fig.36a. Then the glider
goes to the south-east position. From there, it pushes the ﬁn (Fig.36b). By this, the
ﬁn moves to the position of the upper circle, which means the state changes from 0
to 1. The glider ﬁnally goes out from the port w. The whole process above simulates
the one step move δ(0, d) = (1, w) of RLEM 4-31. Other cases are also simulated
similarly.

Gliders in the Game of Life and in a Reversible Cellular Automaton
135
4.2
Making Reversible Turing Machines
A reversible Turing machine (RTM) is a TM that is deterministic both to the forward
and backward time directions (see, e.g., [11] for its detailed deﬁnition). It is known
that any (irreversible) TM can be simulated by an RTM without generating garbage
information [1]. Hence, RTMs are computationally universal.
In [16] it is shown that any RTM can be systematically constructed out of RLEM 4-
31.Figure41showsthecircuitthatsimulatesanRTM Tparity,whichhasthesetofquin-
tuples {[q0, 0, 1, R, q1], [q1, 0, 1, L, qacc], [q1, 1, 0, R, q2], [q2, 0, 1, L, qrej], [q2, 1,
0, R, q1]}. It is the following RTM. Assume a symbol string 0 1n 0 (n = 0, 1, . . .)
is given as an input. Then, Tparity halts in the accepting state qacc if and only if n is
even, and all the read symbols are complemented. In the circuit shown in Fig.41, if
a signal is given to the “Begin” port, it starts to compute. Its answer will be obtained
at “Accept” or “Reject” port.
Putting copies of the pattern of RLEM 4-31 given in Fig.40 at the positions
corresponding to the RLEMs in Fig.41, and connecting them appropriately, we have
a complete conﬁguration of ETPCA 0347 that simulates Tparity. Figure42 shows the
conﬁguration simulated on Golly. Giving a glider to “Begin” port, its computation
starts. Whole computing processes of RTMs embedded in ETPCA0347 can be seen
on Golly using its emulator [10].
Fig. 41 Example of a circuit composed of RLEM 4-31 that simulates RTM Tparity [16]

136
K. Morita
5
Concluding Remarks and Open Problems
In this chapter, we investigated ETPCA0347, a very simple reversible CA, and com-
pared it with GoL. We saw that a glider exists also in ETPCA0347, and interesting
evolution processes are observed by interacting it with other patterns as in GoL.
However, useful patterns and phenomena are not so many compared with GoL, since
interaction of patterns often causes an explosion like Fig.22 in ETPCA0347. Even
so, we can create sufﬁciently many kinds of gadgets from these phenomena, which
are used for composing reversible logic gates and a reversible logic element with
memory (RLEM). Time-symmetry, a characteristic property of reversible ETPCAs,
also helps to compose a backward module that undoes the operation of the forward
module. Reversible Turing machines can be constructed out of RLEMs in the cellular
space of ETPCA0347 concisely.
So far it is not known whether there are other (reversible) ETPCAs in which useful
space-moving patterns exist. In the reversible and conservative ETPCAs 0137 and
0157 (Figs.15 and 16), there exist many space-moving patterns. If we start from a
randomly chosen pattern in these ETPCAs, we can ﬁnd space-moving patterns very
often, since they are conservative ETPCAs. However, their periods are generally
very long as shown in Figs.43 and 44, and hence it is quite difﬁcult to control their
movements. It is an open problem whether there is a space-moving pattern whose
period is very short (preferably 10 or less) in ETPCA0137, 0157, or in other ETPCA.
Note that in [7, 13] computational universality of ETPCAs 0137 and 0157 was shown
using a signal that travels along a transmission wire rather than a space-moving
pattern.
There are many open problems on ETPCA0347. Some of them are listed below
for the future research.
1. Is there a ﬁnite conﬁguration that simulates a universal computer?
The conﬁguration that simulates an RTM given in Sect.4.2 (Fig.42) is inﬁnite
Fig. 42 RTM Tparity implemented in ETPCA 0347 simulated on Golly [14]
t = 0
•
•
•
•
•
•
t = 1581
•
••
•
•
•
t = 3162
•
•
•
•
•
•
Fig. 43 A space-moving pattern of period 3162 in ETPCA0137 [13]

Gliders in the Game of Life and in a Reversible Cellular Automaton
137
t = 0
•
•
•
•
•
•
t = 508
•
•
•
•
•
•
t = 1016
•
•
•
•
•
•
Fig. 44 A space-moving pattern of period 1016 in ETPCA0157
(but ultimately periodic). Is it possible to simulate a universal computer (such as
a reversible 2-counter machine) in a ﬁnite conﬁguration?
2. Is ETPCA 0347 construction universal?
It is a problem of giving a universal constructor that creates any pattern in some
speciﬁed class of patterns (e.g., the class of patterns consisting of blocks and ﬁns),
if its description is given.
3. Is there a space-moving pattern other than the glider?
It is not known whether there exists a space-moving pattern that are essentially
different from the glider. Here, “essentially different” means that the pattern is
not composed only of two or more gliders.
4. Are there interesting phenomena caused by colliding three gliders?
So far very little is known on the collisions of three or more gliders. Hence, there
is a possibility that interesting phenomena are found in them.
References
1. Bennett CH (1973) Logical reversibility of computation. IBM J Res Dev 17:525–532. https://
doi.org/10.1147/rd.176.0525
2. Berlekamp E, Conway J, Guy R (1982) Winning ways for your mathematical plays, vol 2.
Academic, New York
3. Fredkin E, Toffoli T (1982) Conservative logic. Int J Theor Phys 21:219–253. https://doi.org/
10.1007/BF01857727
4. Gajardo A, Kari J, Moreira M (2012) On time-symmetry in cellular automata. J Comput Syst
Sci 78:1115–1126. https://doi.org/10.1016/j.jcss.2012.01.006
5. Gardner M (1970) Mathematical games: the fantastic combinations of John Conway’s new soli-
taire game “Life”. Sci Amer 223(4):120–123. https://doi.org/10.1038/scientiﬁcamerican1070-
120
6. Gardner M (1971) Mathematical games: on cellular automata, self-reproduction, the Gar-
den of Eden and the game “Life”. Sci Amer 224(2):112–117. https://doi.org/10.1038/
scientiﬁcamerican0271-112
7. Imai K, Morita K (2000) A computation-universal two-dimensional 8-state triangular
reversiblecellularautomaton.TheorComputSci231:181–191. https://doi.org/10.1016/S0304-
3975(99)00099-7
8. LifeWiki: The wiki for Conway’s Game of Life. https://www.conwaylife.com/wiki/
9. Morita K (2017) Finding a pathway from reversible microscopic laws to reversible computers.
Int J Unconv Comput 13:203–213

138
K. Morita
10. Morita K (2017) Reversible world: data set for simulating a reversible elementary triangular
partitioned cellular automaton on Golly. Hiroshima University Institutional Repository. http://
ir.lib.hiroshima-u.ac.jp/00042655
11. Morita K (2017) Theory of reversible computing. Springer, Tokyo. https://doi.org/10.1007/
978-4-431-56606-9
12. Morita K (2019) A universal non-conservative reversible elementary triangular partitioned
cellular automaton that shows complex behavior. Nat Comput 18(3):413–428. https://doi.org/
10.1007/s11047-017-9655-9
13. Morita K (2021) Constructing reversible Turing machines in a reversible and conservative
elementary triangular cellular automaton. J Autom Lang Comb 26:125–144. https://doi.org/
10.25596/jalc-2021-125
14. Morita K (2021) How can we construct reversible Turing machines in a very simple reversible
cellular automaton? In: Yamashita S, Yokoyama T (eds) Proceedings of the RC 2021, LNCS
12805, pp 3–21. https://doi.org/10.1007/978-3-030-79837-6_1
15. Morita K, Harao M (1989) Computation universality of one-dimensional reversible (injective)
cellular automata. Trans IEICE Jpn E72(6):758–762. http://ir.lib.hiroshima-u.ac.jp/00048449
16. Morita K, Suyama R (2014) Compact realization of reversible Turing machines by 2-state
reversible logic elements. In: Ibarra OH, Kari L, Kopecki S (eds) Proceedings of the UCNC
2014. LNCS 8553, pp 280–292. https://doi.org/10.1007/978-3-319-08123-6_23
17. Trevorrow A, Rokicki T, Hutton T et al (2005) Golly: an open source, cross-platform application
for exploring Conway’s Game of Life and other cellular automata. http://golly.sourceforge.net/
18. Wolfram S (1986) Theory and applications of cellular automata. World Scientiﬁc Publishing,
Singapore
19. Wolfram S (2002) A new kind of science. Wolfram Media Inc., Champaign
Kenichi Morita is a professor emeritus of Hiroshima University. He received his B. Eng., M.
Eng., and Dr. Eng. degrees from Osaka University in 1971, 1973, and 1978, respectively. From
1974 to 1987, he was a research associate of the Faculty of Engineering Science, Osaka Univer-
sity. From 1987 to 1990, he was an associate professor, and from 1990 to 1993 a professor of
the Faculty of Engineering, Yamagata University. From 1993 to 2013, he was a professor of the
Graduate School of Engineering, Hiroshima University. He has been engaged in the research of
automata theory, theory of computing, and formal language theory. In particular, reversible com-
puting and cellular automata are the main topics of his study. He studied various models of simple
reversible computing systems and cellular automata, and clariﬁed their computational universality.

From Multiple to Single Updates Per Cell
in Elementary Cellular Automata with
Neighbourhood Based Priority
Pedro Paulo Balbi, Thiago de Mattos, and Eurico Ruivo
Abstract The local function of cellular automata is usually applied to all cells in
the lattice in just one single time step. Such a synchronous update may lead to limita-
tions, as when models for real-world systems are being created. As a counterbalance,
asynchronous forms of update have been more and more explored in the literature,
as they can provide an extra degree of freedom. The standard way to deﬁne deter-
ministic asynchronism by setting an update priority to each cell depends totally on
the cell position in the lattice. In a previous work, we proposed a new way to address
deterministic asynchronism, where the update priority would rely on the state transi-
tions underlying the local function, in a way that any cell might be updated multiple
times during the same iteration. Here, we consider a restricted version of the latter, by
which the cells are necessarily updated just once during any time step. By focussing
on the elementary cellular automata space, we provide a complete characterisation
of the resulting number of distinct dynamics of the entire space, out of all possible
independent updates, and contrast it with the case of multiple updates.
P. P. Balbi (B)
Faculdade de Computação & Informática e Pós-Graduação em Engenharia Elétrica e
Computação, Universidade Presbiteriana Mackenzie, Rua da Consolação 896, Consolação,
São Paulo, SP 01302-907, Brazil
e-mail: pedrob@mackenzie.br
T. de Mattos
Pós-Graduação em Engenharia Elétrica e Computação, Universidade Presbiteriana Mackenzie,
Rua da Consolação 896, Consolação, São Paulo, SP 01302-907, Brazil
e-mail: thiagode.mattos@mackenzista.com.br
E. Ruivo
Faculdade de Computação e Informática, Universidade Presbiteriana Mackenzie,
Rua da Consolação 896, Consolação, São Paulo, SP 01302-907, Brazil
e-mail: eurico.ruivo@mackenzie.br
© The Author(s), under exclusive license to Springer Nature Switzerland AG 2022
S. Das et al. (eds.), The Mathematical Artist, Emergence,
Complexity and Computation 45, https://doi.org/10.1007/978-3-031-03986-7_6
139

140
P. P. Balbi et al.
1
Introduction
Cellular automata (CAs) are discrete dynamical systems, made up of cells connected
in a regular lattice, whose states evolve through a number of time steps according to a
localrule.Sucharuleactsonthecurrentcellstatetogetherwiththoseofitsneighbour-
ing cells [9, 19]. Even with simply deﬁned local interactions, cellular automata may
be capable of displaying arbitrarily complex global emergent behaviours and have
been studied both from the point of view of their mathematical and computational
properties as well as systems capable of simulating various real-world phenomena
[1, 8, 12, 17].
Althoughthelocalrulethatgovernsthetemporalevolutionofcellularautomataare
more frequently applied synchronously over the cells, asynchronous update schemes
can be used, by which the cells have an associated priority, deﬁned in deterministic
or stochastic fashion [6].
Regarding the capability of simulating real-world complex systems, asynchronous
updates are more natural than synchronous ones [10], since they generally result from
the parts of the system interacting asynchronously based upon action and reaction.
From a computational standpoint, some dynamical properties of cellular automata
rules depend more on the synchronism than on the rule itself [5, 7], leading to the
question of which might be the new capabilities of a rule when allowing asynchronous
update schedules [16]. In fact, asynchronism has the power to reduce the complexity
of a rule required to solve a problem synchronously [14], as well as to allow the
solution of problems that could not be solved with synchronous update [13].
Deterministic asynchronous updates have been usually deﬁned in terms of the
update priority of each cell in terms of its position in the CA lattice [2, 3]. That is, in
order to specify an asynchronous update schedule, one must ﬁrst know the number
of cells in the lattice, then specify a priority to each one of them. The number of
non-equivalent update schedules deﬁned in that way increases at least exponentially
with the number of cells [3] and many of them cannot be generalised for an arbitrary
lattice size. The literature usually refers to this kind of positional asynchronism as
block-sequential asynchronism.
As an alternative to the positional asynchronism, in [4] we proposed a scheme by
which the update priorities are based on the neighbourhood conﬁguration of a cell,
rather than on its position in the lattice, so that the priorities would become totally
based on the local information of each cell. We then provided a complete character-
isation of the resulting dynamics for the elementary cellular space, according to all
possible independent updates, such that, as shown, the possible dynamics could be
understood in terms of a set of synchronous binary rules with radii up to 8. One of the
motivations for neighbourhood based priority comes from the fact that block sequen-
tial updates require some sort of global control that would trigger the cell updates at
the correct time, whereas our scheme is more local in a sense, since the trigger comes
directly from the neighbourhood conﬁgurations; as a free analogy, if we imagine a
biological cell, the local triggers might be associated with local chemical reactions
which, by their own nature, could be faster to occur than others.

From Multiple to Single Updates Per Cell in Elementary Cellular …
141
However, the way the scheme was deﬁned, with no restriction other than that
the updates should be valid, any cell might be updated multiple times during the
same iteration. Here, we extend the previous investigations, also in the context of the
elementary space, but this time by imposing that the cells would be allowed a single
update at any time step. We contrast the two cases and show that the set of all possible
dynamics can now be understood in terms of a set of synchronous quaternary rules
(also within the same radii range). Because this paper builds upon [4], parts of it are
reproduced here for easier reference.
The next section provides the deﬁnitions of the concepts the paper relies on,
and the next introduces the notion of deterministic asynchronism by neighbourhood
based priority. Section3 introduces neighbourhood based priority update, focussing
on the one-dimensional cellular automata rules. Section4 constitutes the core of the
paper, with the analysis of the elementary space under the case of single update per
cell, and with its contrast with the case of multiple updates. The subsequent section
closes the paper, by providing concluding remarks.
2
Fundamentals
2.1
Deﬁnitions
Deﬁnition 1 (Cellular Automaton) A (synchronous) cellular automaton (CA) A is
a 4-tuple A = (S, N, f, d) [9] where:
• S = {i ∈Z : 0 ≤i ≤k −1} for some k ∈Z+ is the state set;
• N = (v1, . . . , vn) with v j ∈Zd, ∀1 ≤j ≤n is the neighbourhood vector;
• f : Sn −→S is the local transition function or local rule; and
• d ∈Z+ is the dimension.
Given a CA, its local rule f acts locally in conﬁgurations. A d-dimensional, k-ary
conﬁguration c is a mapping c : Zd −→S. Each i ∈Zd is a cell of the conﬁguration
and c(i) is the state of cell i in conﬁguration c, which will be written ci from now
on. We denote the set of all d-dimensional, k-ary conﬁgurations by C(k,d).
The CA local rule f induces a global transition function F : C(k,d) −→C(k,d) on
the set C(k,d) as follows: (F(c))i = f (ci + v1, . . . , ci + vn).
The vector (ci + v1, . . . , ci + vn) is the neighbourhood of cell i for rule f and
each ci + v j from above is a neighbour of the cell i.
Given a conﬁguration c and a global function F, the orbit of c by F (or the time-
evolution of c by F) is the sequence c, F(c), F2(c), . . . , Ft(c), . . . where Ft(c) is
the conﬁguration obtained by applying F t times over c.
A particularly relevant class of CAs is that of the one-dimensional cellular
automata, that is, the CAs for which d=1. Given r ∈{ 1
2, 1, 3
2, 2 · · · } a radius-r one-
dimensional CA has a neighbourhood vector of the form N=(−⌈r⌉, . . . , 0, . . . , ⌊r⌋).

142
P. P. Balbi et al.
Fig. 1 Elementary rule 30, with the 8 state transitions that deﬁne it, and its binary representation.
Black nodes are in 1-state and white nodes are in 0-state
Notice that for a radius-r one-dimensional CA, each cell in a conﬁguration
has ⌈2r⌉+ 1 neighbours. In the remainder of the text we will only address one-
dimensional CAs.
Deﬁnition 2 (Elementary Cellular Automaton) An elementary cellular automaton
(ECA) [19] is a radius-1 one-dimensional CA in which |S| = 2.
Elementary cellular automata are the simplest class of one-dimensional cellular
automata which still displays rich behaviours [19]. Each cellular automaton cell has
two next-nearest neighbours (to the left and to the right), which can take on either 0 or
1 state values. This implies each neighbourhood conﬁguration has 3 cells, yielding 8
possible binary conﬁgurations, and resulting in a total of 256 possible local rules. The
rulesareindexedbyan8-bitbinarynumber,organisedinthedecreasinglexicographic
orderingofthecorrespondingneighbourhoodconﬁgurations,asexempliﬁedinFig.1,
regarding ECA rule 30, which is represented as 00011110 in binary form.
Deﬁnition 3 (Composition of Local Rules) Given f and g k-ary local rules of
radius r f and rg, respectively, then the composed local rule f ◦g : {0, 1, . . . , k −
1}2(r f +rg)+1 →{0, 1, . . . , k −1} is given by
( f ◦g)(x1, x2, . . . , x2(r f +rg)+1) =
f (g(x1, . . . , x2rg+1), g(x2, . . . , x2rg+2), . . . , g(x2r f +rg+1, . . . , x2(r f +rg)+1)),
∀{(x1, . . . , x2(r f +rg)+1) ∈{0, . . . , k −1}2(r f +rg)+1}.
Notice that f ◦g is a radius-(r f + rg) k-ary local rule.
If F and G are the global rules induced by f and g deﬁned as above, then the
global rule induced by f ◦g is exactly F ◦G.
Deﬁnition 4 (Local Rule Active Transitions) Given a radius-r local rule f , a neigh-
bourhood conﬁguration (x−⌈r⌉. . . , x0, . . . , x⌊r⌋) is said to be active when
f (x−⌈r⌉. . . , x0, . . . , x⌊r⌋) ̸= x0.
That is, a neighbourhood conﬁguration is said to be active when the state of its
central cell changes when the rule is applied.
For instance, if f : {0, 1}3 →{0, 1} is given by f (x, y, z) = (x + y + z) mod 2,
its active neighbourhood conﬁgurations are (1, 1, 0), (1, 0, 0), (0, 1, 1) and (0, 0, 1).

From Multiple to Single Updates Per Cell in Elementary Cellular …
143
Deﬁnition 5 (Cellular automata with neighbourhood priority based updates, with
multiple updates per cell per iteration)
The one-dimensional radius-r cellular
automaton based on neighbourhood based priority updates [4] can be deﬁned as
a 4-tuple C = (S,r, f, σ) in which:
• (S, (−⌈r⌉, . . . , 0, . . . , ⌊r⌋), f, 1) is a one-dimensional radius-r CA;
• σ : {0, . . . , k −1}⌈2r⌉+1 →{1, . . . , k⌈2r⌉+1} with
σ({0, . . . , k −1}⌈2r⌉+1) = {1, . . . , max(σ)}, in which
max(σ) = max{σ(x1, . . . , x⌈2r⌉+1) : (x1, . . . , x⌈2r⌉+1) ∈{0, . . . , k −1}⌈2r⌉+1} is
its neighbourhood update schedule.
The restriction regarding σ({0, . . . , k −1}⌈2r⌉+1) is given in order to remove
‘gaps’ between consecutive priorities and in order to ensure they are at their minimal
values. In order to clarify that, consider σ1, σ2 : {0, 1}2 →{1, . . . , 4} given by:
σ1(1, 1) = 1; σ1(1, 0) = 2; σ1(0, 1) = 2; σ1(0, 0) = 3; and
σ2(1, 1) = 2; σ2(1, 0) = 3; σ2(0, 1) = 3; σ2(0, 0) = 4.
By looking at the relative priorities contained in σ, both σ1 and σ2 should act
the same way in a given conﬁguration: cells with neighbourhood (1, 1) are updated
ﬁrst, then cells with neighbourhoods (1, 0) and (0, 1) are updated synchronously
and, ﬁnally, cells with neighbouhood (0, 0) are updated last. With the restriction
mentioned above, only σ1 should be taken into account.
In order to deﬁne the global action of this type of cellular automaton, we deﬁne
the synchronous decomposition of ( f, σ) into synchronous radius-r local rules as
follows:
• For i ∈{1, . . . , max(σ)}, we deﬁne the set
A ( f,σ)
i
= {(x1, . . . , x⌈2r⌉+1) ∈{0, . . . , k −1}⌈2r⌉+1 :
σ(x1, . . . , x⌈2r⌉+1) = i and (x1, . . . , x⌈2r⌉+1) is active}.
In other words, A ( f,σ)
i
is the set of active neighbourhoods of f with priority i
under σ;
• The local radius-r rule f(σ,i) is given by
f(σ,i)(x1, . . . , x⌈2r⌉+1) =

f (x1, . . . , x⌈2r⌉+1) , if (x1, . . . , x⌈2r⌉+1) ∈A ( f,σ)
i
x⌈r⌉
, otherwise (i.e., the state of the central cell) .
Then, we can regard the local action of local rule f under the asynchronous
neighbourhood update schedule σ as the action of the composition f(σ,max(σ)) ◦· · · ◦
f(σ,1).
Therefore, we can formally deﬁne the global rule Fσ induced by ( f, σ) as
Fσ = F(σ,max(σ)) ◦· · · ◦F(σ,1).

144
P. P. Balbi et al.
Notice that if A ( f,σ)
i
= ∅for a particular i, then F(σ,i) (and also fσ,i) may be
dropped from the above expression(s), since they would be identity functions.
Given any neighbourhood update schedule σ, it is possible to identify it by a
vector vσ as follows: if (x1, . . . , x⌈2r⌉+1) is the ith vector in the decreasing lexico-
graphical ordering of the set {0, . . . , k −1}, then we deﬁne vi = σ(x1, . . . , x⌈2r⌉+1).
For instance, if σ : {0, 1}2 →{1, 2, 3, 4} is given by σ(1, 1) = 1, σ(1, 0) = 2,
σ(0, 1) = 2 and σ(0, 0) = 3, then vσ = (1, 2, 2, 3).
2.2
Independent Neighbourhood Updates and Active State
Transitions
The number of distinct neighbourhood update schedules cannot be assumed to be
the total number of priority combinations, since there are neighbourhood update
scheduleswithequivalentmeaning,sincetherearerestrictionstothewayσ isdeﬁned,
as noted above.
For example, vσ1 = (1, 1, 1, 1, 1, 1, 1, 1) and vσ2 = (2, 2, 2, 2, 2, 2, 2, 2) both
represent a synchronous update, but only the ﬁrst is possible to obtain from a neigh-
bourhood update schedule. Hence, the number of distinct neighbourhood update
schedules is given by getting all ‘weak orderings’ [11] on a set of k⌈2r⌉+1 elements,
in this case 23 = 8 neighbourhood conﬁgurations. In other words, it is given by the
Fubini number Fn:
Fn =
n

k=1
n
k

Fn−k .
Therefore, the number of distinct ECA neighbourhood update schedules would
be the Fubini number F8 = 545835. Fubini numbers represent the number of ways
n competitors can rank in a competition, allowing for the possibility of ties.
However, depending on the ECA neighbourhood conﬁgurations, some of the
545835 update schedules can possibly share the same dynamics, even if they are dif-
ferent. For instance, let us consider ECA rule 128 (100000002), whose active transi-
tions (Deﬁnition4)arepresentattheneighbourhoodconﬁgurations110, 011and010.
Although the update schedules identiﬁed by the vectors vσ1 = (1, 1, 1, 1, 1, 2, 3, 3)
and vσ2 = (2, 1, 2, 2, 1, 2, 2, 1) are different, they indeed have the same dynamics,
because both share the same priorities for neighbourhood conﬁgurations associated
to the rule’s active state transitions (110, 011 and 010) (Fig.2). Hence, vσ1 and vσ2
can both be represented as (_, 1, _, _, 1, 2, _, _), where “_” is a don’t care symbol
representing an inactive neighbourhood conﬁguration. Such an aspect contributes to
reducing the total number of update schedules for a speciﬁc ECA rule, except, natu-
rally, for ECA rule 51 (001100112) that has active transitions at all 8 neighbourhood
conﬁgurations.

From Multiple to Single Updates Per Cell in Elementary Cellular …
145
Fig. 2 Both update schedules vσ1 and vσ2 can be represented by the update schedule
(_, 1, _, _, 1, 2, _, _). The neighbourhood conﬁgurations with active state transitions are in dashed
line and are the only ones that should be considered. The neighbourhood conﬁgurations with inactive
state transitions are represented with a don’t care symbol (“_”), and can be ignored
As a consequence, the effective number of independent neighbourhood updates
in an ECA rule is governed by the number of its active neighbourhoods, as given
by the Fubini numbers Fn, with n ∈{0, 1, . . . , 8}, respectively: 1, 1, 3, 13, 75, 541,
4683, 47293 and 545835.
3
From Multiple to Single Updates Per Cell Per Iteration
3.1
Overview of the Idea
A consequence of the previous characterisation of neighbourhood based priority
update is that any cell may undergo multiple updates at any time step, up to the
maximum number of priorities. So, one might ask about the inﬂuence of a such a
feature on the dynamics of the rules, if the cells would be prevented from multiple
updates, i.e., they would be restricted to a single update per iteration. This is exactly
the aim of this paper and, as explained below, a useful way to handle the single update
per cell is to regard it from the perspective of a transformation of the original ECA
rules to others with four states and same radius, that is, from the ECA space to the
quaternary space of radius 1.
The way we go about it is by adding two auxiliary states, each one associated to
the original binary states. So, the original binary states S = {0, 1} give rise to the
quaternary states S∗= {0, 1, 0∗, 1∗}, with the auxiliary states 0∗and 1∗referring to
the original states 0 and 1, respectively. The idea is that, during an iteration of the
quaternary rule, all state transitions that would change the state of a cell to 0 (resp.
1), would actually entail a change to 0∗(resp. 1∗) and these would remain the same
until the end of the iteration. In other words, the auxiliary states are associated with
inactive state transitions in the quaternary rule.

146
P. P. Balbi et al.
Fig. 3 The original active state transitions of ECA 90 give rise to the active state transitions of its
corresponding quaternary rule
Furthermore, the original active state transitions of the binary rule give rise to an
extended set of active state transitions in its corresponding quaternary rule, since the
auxiliary states can now be present in the neighbourhoods of the quaternary rule.
Figure3 illustrates the process, showing how the 4 original active state transitions of
ECA rule 90 give rise to 16 active state transitions in its corresponding quaternary
rule.
The combined consequence of the two processes of creating the sets of active and
inactive quaternary state transitions is illustrated for ECA rule 90 in Fig.4, where
the 4-state, radius-1, rule number 112984725815866422233953223566440809540
is obtained from the latter.
Finally, notice that, once the binary rule is transformed into its corresponding
quaternary counterpart, every iteration of a conﬁguration then indeed happens in 4
states but, at its end, has to return back to binary, as depicted in Fig.5 (as will be
explained in the next section, this can be regarded as the application of the additional
4-state, radius-0 rule number 68).
3.2
Formalisation
Given f an ECA local function and σ a neighbourhood update schedule, it is possible
to obtain a synchronous binary local rule that yields the same dynamics of ( f, σ)
according to this new deﬁnition, used to deﬁne the global action of ( f, σ).
In order to do so, we will deﬁne the synchronous decomposition of ( f, σ) using
quaternary radius-1 CA local rules as follows:

From Multiple to Single Updates Per Cell in Elementary Cellular …
147
Fig. 4 The quaternary, radius-1 rule (at the bottom) corresponding to ECA rule 90 (at the top).
Each of the 8 state transitions of ECA 90 gives rise to 4 state transitions in its quaternary version
Fig. 5 Representation of one iteration of a CA with asynchronism by neighbourhood priority with
single update per cell: the original binary conﬁgurations are processed by a quaternary rule and, at
the end, have to return to binary, which is achieved by means of quaternary rule 68 (with radius 0),
that simply turns the auxiliary states 0∗and 1∗back to, respectively, states 0 and 1
• Let S∗= {0, 1, 0∗, 1∗} be the set of states. States 0∗and 1∗will work as placehold-
ers for cells that have been previously updated during an iteration and, therefore,
should not be updated again until the end of such an iteration.
• Deﬁne η : S∗→S by η(0) = η(0∗) = 0 and η(1) = η(1∗) = 1 and let f ∗:
(S∗)3 →S be given by
f ∗(x1, x2, x3) =

f (η(x1), η(x2), η(x3)), if x2 /∈{0∗, 1∗}
x2, otherwise
.
This quaternary extension of f updates exactly as f (as if the binary states and
their “starred” versions were the same) when the central cell is 0 or 1, and acts as

148
P. P. Balbi et al.
the identity if the central cell is 0∗or 1∗, avoiding updates of previously updated
cells.
• For i ∈{1, . . . , max(σ)}, deﬁne the set
A ∗f,σ
i
= {(x1, x2, x3) ∈S∗3 : f ∗(x1, x2, x3) = 1 −x2 and σ(η(x1), η(x2), η(x3)) = i}
That is, A ∗f,σ
i
is the set of active neighbourhoods of f ∗with priority i.
• For each i ∈{1, . . . , max(σ)}, deﬁne the following quaternary radius-1 local rule:
f ∗
(σ,i)(x1, x2, x3) =

f ∗(x1, x2, x3), if (x1, x2, x3) ∈A ∗f,σ
i
x2, otherwise
.
• The local action of ( f, σ) can be regarded as the action of the following compo-
sition of synchronous CA rules over binary neighbourhoods:
f s
σ = η ◦f ∗
(σ,max(σ)) ◦· · · ◦f ∗
(σ,1),
with f s
σ being a radius-(max(σ)) binary local rule, deﬁned as the synchronous
equivalent of ( f, σ).
• Let N be the global rule induced by η and F∗
(σ,i) the global rule induced by
f ∗
(σ,max(σ)) for each i ∈{1, . . . , max(σ)}. Then the global rule induced by ( f, σ)
is given by
Fσ(c) = (N ◦F∗
(σ,max(σ)) ◦· · · ◦F∗
(σ,1))(c),
for any binary conﬁguration c.
Notice that Fσ is a binary global rule, since N : {0, 1, 0∗, 1∗} →{0, 1} .
Since f s
σ is a binary synchronous rule, the classical dynamical equivalence trans-
forms (conjugation, reﬂection and reﬂected conjugation) apply to it, as it is further
discussed in Sect.4.1.
4
Analysis of the Elementary Space with Neighbourhood
Based Priority Asynchronism with Single Updates Per
Cell
4.1
Dynamical Equivalence Classes
Given any binary (synchronous) radius-r local rule g, let g, g′ and g′ be, respectively,
the conjugate, reﬂection and reﬂected conjugate of g, given by
• g(x1, . . . , x2r+1) = 1 −g(1 −x1, . . . , 1 −x2r+1);

From Multiple to Single Updates Per Cell in Elementary Cellular …
149
• g′(x1, . . . , x2r+1) = g(x2r+1, . . . , x1);
• g′(x1, . . . , x2r+1) = 1 −g(1 −x2r+1, . . . , 1 −x1)
Also, as deﬁned in [4], given σ a radius-1 neighbourhood update schedule, deﬁne
σ, σ ′ and σ ′ respectively the conjugate, reﬂection and reﬂected conjugate of σ by
• σ(x1, x2, x3) = σ(1 −x1, 1 −x2, 1 −x3), for all (x1, x2, x3) ∈{0, 1}3;
• σ ′(x1, x2, x3) = σ(x3, x2, x1), for all (x1, x2, x3) ∈{0, 1}3;
• σ ′(x1, x2, x3) = σ(1 −x3, 1 −x2, 1 −x1), for all (x1, x2, x3) ∈{0, 1}3
Then, by a completely analogous reasoning to the one detailed in [4], it is pos-
sible to show that f sσ , ( f s
σ )′ and ( f sσ )′ are the synchronous equivalent forms of
( f , σ), ( f ′, σ ′) and ( f ′, σ ′), respectively. That is, the notion of dynamical equiva-
lence classes present for synchronous ECA rules also applies to the ECA rules with
asynchronous neighbourhood updates with single updates per cell.
4.2
Identifying Dynamical Classes
As shown in [4], the 256 ECA rules and their corresponding neighbourhood priority
updates give rise to a large number of (ECA rule, neighbourhood update) pairs.
So, one can ask about their features, such as their dynamical characterisation. The
natural way to carry out such analysis is from the standpoint of each corresponding
synchronous cellular automaton rule entailed by each pair. Such a process was ﬁrst
presented in [4], and is based on the fact that every (ECA rule, neighbourhood update)
pair has an equivalent synchronous cellular automaton rule. In other words, applying
a neighbourhood update schedule has the same effect as applying synchronously
speciﬁc ECA rules in sequence.
For instance, consider the pair (ECA50, (1, 1, 1, 1, 1, 1, 2, _)), whose active
state transitions refer to the neighbourhoods 111, 110, 101, 100, 011, 010 and 001.
According to that update schedule, the neighbourhoods 111, 110, 101, 100, 011 and
010 must be taken into account ﬁrst, and together they constitute the set of the active
state transitions of ECA rule 48 (001100002). As for the remaining neighbourhood
001, it turns out it is the single active state transition of ECA 206 (110011102). So,
the synchronous rule to be associated with the pair (ECA50, (1, 1, 1, 1, 1, 1, 2, _))
results from a composition of ECA rules 48 and 206; but the actual way the com-
position is to be handled depends on whether multiple or single updates per cell are
being considered.
In the multiple version [4], those two binary synchronous rules would be translated
into the direct rule composition 206 ◦48 (Deﬁnition3), which results in the binary
radius-2 rule with Wolfram number 1056980784.
However, with single updates, the composition must rely on the quaternary rules
corresponding to ECA rules 48 and 206, and an additional quaternary, radius-0
rule, number 68, whose role is to turn the quaternary temporal evolution back
to binary, by turning auxiliary states 0∗and 1∗back to 0 and 1, respectively (as

150
P. P. Balbi et al.
depicted in Fig.5). Accordingly, in the neighbourhood priority with single updates
the pair (ECA50, (1, 1, 1, 1, 1, 1, 2, _)) ends up corresponding to the synchronous
quaternary, radius 2 rule that results from the composition: (radius-0 rule 68)
◦(radius-1 rule 339837553475045378755793965393415656908) ◦(radius-1 rule
339839297683043527923201434700281981440).
So,theprocessforperformingthedynamicalanalysisoftheelementaryspacewith
single neighbourhood based updates per cell is then implemented in two phases. In
the ﬁrst, depicted in Fig.7, each (ECA rule, neighbourhood update) pair is translated
into a composition of synchronous cellular automata rules, each one represented by
its unique number (Fig.6).
After translating each (ECA rule, neighbourhood update) pair into a composi-
tion of synchronous cellular automata quaternary rules, all remaining rules have
their dummy neighbours [15] identiﬁed, in order to reduce their radii (Fig.6), thus
providing a common ground for comparing the rules.
An important point to highlight is the situation when rule radius reduction would
lead to a rule with an asymmetrical neighbourhood, which would impair the possi-
bility of handling dynamical equivalence of the ECA rules (as required in the second
phase); the point is that reﬂection is ill-deﬁned for asymmetrical neighbourhoods. In
order to cope with that, it is required to balance the neighbourhood in those cases, by
adding dummy neighbours that would then turn the rule back to being symmetrical.
For instance, rule 4294955007 with radius 2 admits radius reduction, down to rule
65471 with asymmetric radius 3/2, but ends up being balanced to radius-2, by adding
one dummy neighbour (to the right-hand side of the asymmetric neighbourhoods).
Next, the dynamical equivalence classes of each synchronous rule are derived—by
means of the quaternary version of the symmetry operations of conjugation, reﬂection
and their composition, in tune with Sect.4.1—each class being represented by the
Fig. 6 Example of dummy neighbour removal and consequent rule radius reduction. ECA rule 195
has a dummy neighbour that can be suppressed: since the right-hand neighbour (highlighted in red)
does not play any role in the state transition output, it can be suppressed, reducing the rule radius
by 1/2 and resulting in ECA rule 9 with radius equal to 1/2

From Multiple to Single Updates Per Cell in Elementary Cellular …
151
Fig. 7 Process diagram illustrating the ﬁrst phase of the dynamical analysis of the elementary space
with single neighbourhood based updates per cell. All 256 elementary rules and their respective
independent updates are processed, resulting in a rule set that describes the possible dynamics of
each individual ECA
Fig. 8 Representation of the second phase of the dynamical analysis of the elementary space with
single neighbourhood based updates per cell. The synchronous rules that describe the dynamics
of each individual ECA are grouped into the 88 cellular automata dynamical classes. Possible
duplicates are identiﬁed and removed
rule with the smallest number. After removing duplicates, the ﬁnal result is the set
of synchronous rules that characterise the dynamics of each individual ECA rule (or
NP-dynamics, as referred to in [4]).
In the second phase of the process, as represented in Fig.8, the synchronous rules
that describe the dynamics of each individual ECA obtained in the previous phase
are grouped into the 88 cellular automata dynamical classes [18]. Possible duplicates
are then identiﬁed and removed.

152
P. P. Balbi et al.
4.3
An Example of the Full Process
As an illustration of the full process, let us consider again ECA rule 50 with its
neighbourhood update schedule (1, 1, 1, 1, 1, 1, 2, _).
Following Sect.4.2, the pair (ECA 50, (1, 1, 1, 1, 1, 1, 2, _)) gives rise to the
quaternary rule composition (radius-0 rule 68) ◦(radius-1 rule 3398375534750453
78755793965393415656908) ◦(radius-1 rule 33983929768304352792320143470
0281981440), resulting in the quaternary radius-2 rule with Wolfram number 1077
233535459553932538850741302185141860706779633770769564942932102217
254849180817921624533686768205090795467381463260023544825807555805
302277100276005710327990003288530403205151209720152787733239633379
541223794985257521271231734746903483888076458753238974784650597279
894518633209168641087912607954597317677447468314574382635955694056
807738196177020590318389585420317789330453440387171595636855380723
654130514360950600036490541181385397557671330188115787409023966916
585267611592636897395630201604983913049997287096369177970618958829
664835672847301251622285505352395118500571831991191565259817823562
9234969662686494720.
Next, the resulting composed rule would undergo radius reduction. In this
case, only one dummy neighbour has been identiﬁed, resulting in the quaternary
radius-3/2 rule 445181149312389784018339599023310469340902363888242576
228194125564753971967319875938139556548721223402537526440928111516
0946555171581487310303250884853824. But because the dummy neighbour
removal resulted in a rule with asymmetric neighbourhood (radius 3/2), it needs
to be balanced back to radius-2, which end up restoring the original radius-2, qua-
ternary rule whose number is shown in the previous paragraph.
Finally, we derive the dynamical equivalence class from that speciﬁc rule, obtain-
ing its reﬂection, its 4! −1 = 23 conjugates and its 23 conjugate reﬂections and, out
of all these 48 rules, take the one with the smallest number as the representative of
the (ECA 50, (1, 1, 1, 1, 1, 1, 2, _)) pair, which happens to be the quaternary radius
2 rule with Wolfram number 1167938939419493182881139784972284004453833
958954939580815289456863800317312510490561837231656326518976574990
818182387733743223235840477628805319198361242533186741532385661038
786012911708793633828875754374907883126687763500679281035092265529
805660588580933399580853996879560368206088391943693088788574270933
667726008040298024978507128053748119145597797799121108979836311266
631386158939731310238944507181101953512669898927185946910332462879
693907167573430333401868317030409303846230992449924385591968243101
577358590143572813836936266900215432345291746858487562202128993531
612627133417844137231690240.
By doing this process to all ECA 50 update schedules, we reach a total of 5429
distinct (up to conjugation and/or reﬂection) synchronous rules (see Table1), that
deﬁne the dynamical class of the ECA 50 with neighbourhood based single updates
per cell.

From Multiple to Single Updates Per Cell in Elementary Cellular …
153
Extending the procedure for the entire elementary space, we obtain the number of
all synchronous rules that describes the overall dynamics of the 255 ECAs (except
ECA 51) with single updates per cell. Those values are presented in the third column
(Single update) in Table1. Highlights include the ECA class represented by ECA
35, which leads to the largest number of synchronous rules (8121), followed by the
ECA class represented by ECA 50 with 5429, as already mentioned.
As shown in the table, the data for 87 dynamical classes are displayed. The only
missing dynamical class is the one represented by ECA rule 51, which has active tran-
sitions (Deﬁnition4) for all its neighborhoods, and demands a considerable amount
of computational resources to conclude its processing. At the time of writing, the
class was still under process.
By summing up the quantities of all 87 dynamical classes, we obtain 26769
synchronous rules. So, the elementary space as a whole has 26769 synchronous
rules, excluding the unprocessed class represented by ECA rule 51.
A comparison of the synchronous rules from both neighbourhood update schemes
(multiple and single updates per cell) can be seen in Table1, where we see that the
rule classes for single updates compare as follows with the case for multiple updates:
• 25 classes have the same number of synchronous rules as the case of multiple
updates: 0, 4, 8, 12, 72, 76, 128, 130, 132, 134, 136, 138, 140, 142, 150, 152, 156,
160, 164, 168, 172, 184, 200, 204 and 232;
• 62 classes have a smaller number of synchronous rules, which are those referring
to the remaining ECAs (except ECA 51).
5
Concluding Remarks
Continuing with the investigation of cellular automata with neighborhood based
priority updates, this time with single updates per cell per iteration, once again the
proposed asynchronous scheme deﬁned by (rule, neighbourhood update) pairs turns
out to be equivalent to the application of a synchronous rule, now with four states.
But now a different dynamic scenario emerges in the analysis of the elementary space
when compared to the previous scheme of multiple updates. This is evident when
looking at the numbers of synchronous rules presented in Table1.
Also, recalling that multiple updates give rise to synchronous rules with radii
from 1 to 8, Table2 makes it evident that there is an absence of rules with radii
larger than 7 in the 26769 rule set of the single update case, which may be due to
the lack of data about elementary rule 51, as it is still being processed, due to its
high computational cost. The point is that ECA rule 51 has active transitions for all
neighborhood conﬁgurations, what can potentially yield rules with larger radii.
Analogously to the analyses carried out in [4], where the issues of number conser-
vation and parity preservation were addressed in the context of the entire ECA space
with neighbourhood priority with multiple updates, here too these are ﬁrm objectives
to be pursued in a follow-up investigation.

154
P. P. Balbi et al.
Table 1 Comparison between both neighbourhood update schemes, with multiple updates per cell, from [4], and single updates per cell. The number of
synchronous rules is pending for the group represented by ECA rule 51, which was still under processing at that time of writing
ECA Class
Representative
Multiple
updates
Single
updates
ECA Class
ECA Class
Representative
Multiple
updates
Single
updates
ECA Class
ECA Class
Representative
Multiple
updates
Single
updates
ECA Class
0
14
14
0, 255
35
24022
8121
35, 49, 59, 115
108
3
2
108, 201
1
172
61
1, 127
36
41
37
36, 219
110
11
6
110, 124, 137, 193
2
214
171
2, 16, 191, 247
37
268
135
37, 91
122
215
130
122, 161
3
2622
918
3, 17, 63, 119
38
408
277
38, 52, 155, 211
126
30
14
126, 129
4
8
8
4, 223
40
52
47
40, 96, 235, 249
128
3
3
128, 254
5
42
19
5, 95
41
396
189
41, 97, 107, 121
130
37
37
130, 144, 190, 246
6
63
54
6, 20, 159, 215
42
325
228
42, 112, 171, 241
132
2
2
132, 222
7
472
210
7, 21, 31, 87
43
1451
661
43, 113
134
13
13
134, 148, 158, 214
8
7
7
8, 64, 239, 253
44
13
11
44, 100, 203, 217
136
2
2
136, 192, 238, 252
9
54
22
9, 65, 111, 125
45
67
33
45, 75, 89, 101
138
8
8
138, 174, 208, 244
10
45
40
10, 80, 175, 245
46
58
39
46, 116, 139, 209
140
1
1
140, 196, 206, 220
11
389
189
11, 47, 81, 117
50
10361
5429
50, 179
142
2
2
142, 212
12
3
3
12, 68, 207, 221
51
60915
Pending
51
146
165
154
146, 182
13
13
6
13, 69, 79, 93
54
1520
894
54, 147
150
21
21
150
14
13
11
14, 84, 143, 213
56
371
262
56, 98, 185, 227
152
11
11
152, 188, 194, 230
15
39
22
15, 85
57
1566
636
57, 99
154
58
55
154, 166, 180, 210
18
1189
817
18, 183
58
2619
1542
58, 114, 163, 177
156
2
2
156, 198
19
13573
4843
19, 55
60
64
41
60, 102, 153, 195
160
26
26
160, 250
(continued)

From Multiple to Single Updates Per Cell in Elementary Cellular …
155
Table 1 (continued)
ECA Class
Representative
Multiple
updates
Single
updates
ECA Class
ECA Class
Representative
Multiple
updates
Single
updates
ECA Class
ECA Class
Representative
Multiple
updates
Single
updates
ECA Class
22
248
189
22, 151
62
357
197
62, 118, 131, 145
162
281
244
162, 176, 186, 242
23
1019
458
23
72
2
2
72, 237
164
8
8
164, 218
22
52
42
24, 66, 189, 231
73
11
4
73, 109
168
11
11
168, 224, 234, 248
25
413
162
25, 61, 67, 103
74
11
9
74, 88, 173, 229
170
24
22
170, 240
26
384
287
26, 82, 167, 181
76
1
1
76, 205
172
3
3
172, 202, 216, 228
27
3379
1451
27, 39, 53, 83
77
2
1
77
178
545
449
178
28
12
9
28, 70, 157, 199
78
3
2
78, 92, 141, 197
184
30
30
184, 226
29
37
15
29, 71
90
39
29
90, 165
200
1
1
200, 236
30
73
53
30, 86, 135, 149
94
8
5
94, 133
204
1
1
204
32
140
119
32, 251
104
11
9
104, 233
232
2
2
232
33
1526
609
33, 123
105
32
15
105
34
2097
1326
34, 48, 187, 243
106
61
43
106, 120, 169, 225

156
P. P. Balbi et al.
Table 2 Distribution of the 26769 synchronous rules, grouped by radii. Notice, that rules with radii
greater than 7 have not been obtained so far, possibly due to the lack of data about ECA 51
Radius
0
1
2
3
4
5
6
7
8
Number of
synchronous
rules
3
85
1812
8404
11094
4520
790
61
?
Other appealing questions to be tackled in the sequence concern the evaluation
of other properties in the 27769 rule set, including the analysis of the basins of
attraction of the (ECA, neighbourhood update) pairs over different lattice sizes; to
analyse the correlation between each of the three rule sets shown in the end of the
last section with the dynamical behaviour of the corresponding ECAs, according to
the four Wolfram classes; to try to correlate the actual dynamics among the 25 ECA
classes that have the same number of synchronous rules in both update schemes;
to probe the consequences of relying on other types of topologies among the cell
connections; and the possibility of devising real-world domains where the application
of the neighbourhood update scheme could be attempted.
Acknowledgements We thank the Brazilian agencies CAPES (Coordenação de Aperfeiçoamento
de Pessoal de Nível Superior) for the projects STIC-AmSud (CoDANet) no. 88881.197456/2018-01
and Mackenzie-PrInt no. 88887.310281/2018-00; and CNPq (Conselho Nacional de Desenvolvi-
mento Cientíﬁco e Tecnológico) for the research grant PQ 305199/2019-6. We also thank SINA-
PAD’s supercomputing facility Santos Dumont for supporting our project DYNACAP, no. 204564,
and T.M. thanks Instituto Presbiteriano Mackenzie for a Ph.D. grant.
References
1. Aburas MM, Ho YM, Ramli MF, Ash’aari ZH (2016) The simulation and prediction of spatio-
temporal urban growth trends using cellular automata models: a review. In J Appl Earth Obs
Geoinf 52:380–389
2. Aracena J, Demongeot J, Fanchon E, Montalva M (2013) On the number of update digraphs and
its relation with the feedback arc sets and tournaments. Discrete Appl Math 161(10):1345–1355
3. Aracena J, Fanchon E, Montalva M, Noual M (2011) Combinatorics on update digraphs in
Boolean networks. Discrete Appl Math 159(6):401–409
4. Balbi PP, de Mattos T, Ruivo E (2022) Characterisation of the elementary cellular automata
with neighbourhood priority based deterministic updates. Commun Nonlinear Sci Numer Simul
104:106018. https://doi.org/10.1016/j.cnsns.2021.106018
5. Bersini H, Detours V (1994) Asynchrony induces stability in cellular automata based models.
In: Artiﬁcial life IV, pp 382–387
6. Fatès N (2014) A guided tour of asynchronous cellular automata. J Cell Autom 9(5–6):387–416
7. Fatès NA, Morvan M (2005) An experimental study of robustness to asynchronism for ele-
mentary cellular automata. Complex Syst 16(1):1–27
8. Hoekstra A, Kroc J, Sloot P (2010) Introduction to modeling of complex systems using cellular
automata. Simul Complex Syst Cell Autom, 1–16
9. Kari J (2005) Theory of cellular automata: a survey. Theor Comput Sci 334(1–3):3–33

From Multiple to Single Updates Per Cell in Elementary Cellular …
157
10. Messinger SM, Mott KA, Peak D (2007) Task-performing dynamics in irregular, biomimetic
networks. Complexity 12(6):14–21
11. Mezo I (2020) Combinatorics and number theory of counting sequences. CRC Press, Taylor
& Francis Group, Boca Raton
12. Mikler AR, Venkatachalam S, Abbas K (2005) Modeling infectious diseases using global
stochastic cellular automata. J Biolog Syst 13(04):421–439
13. Ruivo ELP, Balbi PP, Perrot K (2020) An asynchronous solution to the synchronisation problem
for binary one-dimensional cellular automata. Physica-D, 413
14. Ruivo ELP, de Oliveira PPB (2019) A perfect solution to the parity problem with elementary
cellular automaton 150 under asynchronous update. Inf Sci 493:138–151
15. Ruivo ELP, de Oliveira PPB, Lobos F, Goles E (2018) Shift-equivalence of k-ary, one-
dimensional cellular automata rules. Commun Nonlinear Sci Numer Simul 63:280–291
16. Vielhaber M (2013) Computation of functions on n bits by asynchronous clocking of cellular
automata. Nat Comput 12(3):307–322
17. Wolf-Gladrow DA (2000) Lattice-gas cellular automata and lattice Boltzmann models.
Springer, Berlin
18. Wolfram S (1994) Cellular automata and complexity: collected papers
19. Wolfram S (2002) A new kind of science. Wolfram Media
Pedro Paulo Balbi is a faculty member of the School of Computing and Informatics, Mackenzie
Presbyterian University, São Paulo, Brazil, and of its Postgraduate Programme in Electrical Engi-
neering and Computing. During the last six years he chaired IFIP WG-1.5, the working group
on Cellular Automata and Discrete Complex Systems, of the Technical Committee 1, on Foun-
dations of Computer Science, of the International Federation for Information Processing. His pri-
mary research topics are computational and dynamical aspects of cellular automata and applica-
tions of evolutionary computation.
Thiago de Mattos is a PhD. candidate in Electrical Engineering and Computing at Mackenzie
Presbyterian University, São Paulo, Brazil.
Eurico Ruivo is an Assistant Professor at the School of Computing and Informatics at Macken-
zie Presbyterian University, São Paulo, Brazil. His main research interests are cellular automata
dynamics and bioinspired algorithms.

Game of Life, Athenian Democracy
and Computation
Sukanta Das
Abstract This article revisits John Conway’s Game-of-Life from the view point of
democratic systems. We argue that the democracy followed by Game-of-Life is a kind
of direct democracy, which was ﬁrst successfully practiced in the city state of Athens
of ancient Greece. We compare two apparently dissimilar entities from abstract point
of view - Game-of-Life which is a computational system and Athenian democracy,
and point out their similarities and dissimilarities. To deal with the dissimilarities,
we also outline a model of computation. We also indicate that the Cellular Automata
with Memory can address the dissimilarities to some extent.
1
Introduction
Traditional thought process about computation relies on autocracy - a central pro-
cessing unit (CPU) is the master which processes information/data and controls the
computation, and a set of associated components, such as main memory and I/O
devices, follow the directives of the CPU. In a closer look, one can reveal that there
is a control unit in the CPU which dictates any kind of execution during a computa-
tion.
Can we think of a model of computation which can question this autocratic/
centralized style of computation and can advocate for decentralized computation?
From the decade of 1940, computer scientists and mathematicians have been involved
in search of alternative models of computation, and Neural Network [10] and Cellular
Automata (CAs) [11] have come up as the most prominent development as alterna-
tives. In these models, interconnection among individual components has been given
a great importance, and no central control is respected.
A cellular automaton (CA) consists of a large number of cells which are arranged
as a regular network and do local computation independently in consultation with
their neighbours only. Although the credit of inventing cellular automata commonly
S. Das (B)
Department of Information Technology, Indian Institute of Engineering Science
and Technology, Shibpur, India
e-mail: sukanta@it.iiests.ac.in
© The Author(s), under exclusive license to Springer Nature Switzerland AG 2022
S. Das et al. (eds.), The Mathematical Artist, Emergence,
Complexity and Computation 45, https://doi.org/10.1007/978-3-031-03986-7_7
159

160
S. Das
goes to John von Neumann and Stanislaw Ulam [11], this is John Horton Conway
who brought the CAs to public interest from the close domain of mathematicians and
theoretical computer scientists. And, this was done through the invention of Game-
of-Life (GoL) [6] - a simple two-dimensional cellular automaton where the cells can
either be dead or alive.
Democracy, on the other hand, is a system of governance in which the people
have direct or indirect authority to deliberate and decide legislation. Hence, strictly
speaking, democracy is related to state affairs only. However, the way of running
of a democratic state can also be observed in other classes of systems, including
computing systems. Let us call those systems as democratic systems. And from
that perspective, the Game-of-Life is a democratic system. Because, there is no
central node in GoL to control the computation of others, rather the individual cells
compute together to achieve a goal. The individual cells of GoL are having very
limited capabilities, but when they act together, the system as a whole becomes very
powerful and can even do universal computation. It is indeed the power of collective
effort, and hence the power of democracy.
ThedemocracyfollowedinGoLisakindofdirectdemocracywheretheindividual
actors (here cells) participate in decision making. History shows that the city states of
ancient Greece successfully practised direct democracy [7], and Athens among other
city states in Greece remained the most inﬂuential in practising direct democracy. We
brieﬂyrevisit theproperties of AtheniandemocracyinSect. 3, andthencomparethese
two systems, GoL and Athenian democracy from abstract point of view. We point
out that GoL inherits some of the principles of Athenian democracy. However, some
general conditions, such as slave economy, which were integral part of Athenian
democracy, have no reﬂection in GoL. If a model of computation can mimic the
features of Athenian democracy, at least some of it, which are absent in GoL and
other CAs, then what will be its features and abilities? This question naturally arises.
In this article, we address this question and note down our thoughts. We outline a
model of computation which is very close to cellular automata but can mimic some
properties of Athenian democracy (Sect. 4) which are absent in GoL. In this model,
a cell has a support (like slaves in Athenian democracy) which plays very crucial
role but remains behind-the-screen. We reveal that Cellular Automata with Memory
have some resemblance with this model, where memory plays the role of support.
So we brieﬂy discuss the CAs with memory in Sect. 5 for sake of completeness.
2
Game-of-Life and Direct Democracy
The Game-of-Life (GoL) is a classical example of achieving complexity out of sim-
plicity. This is a mathematician’s artistry to the primary issue of existence of organism
- alive and dead. The cells, organised on a 2-dimensional square grid, follow a simple
rule to evolve. Each cell can be either dead or alive, and at the beginning some cells
are set as alive and the rest as dead. Following is the rule.

Game of Life, Athenian Democracy and Computation
161
t = 1
t = 2
t = 3
t = 4
t = 5
Fig. 1 Movement of a glider: After 4 time steps (at t = 5), initial pattern moves one place diago-
nally. Here, black box represents alive cell and white box as dead cell
1. Birth: a dead cell becomes alive if exactly 3 of its eight neighbours are alive.
2. Death: a cell can die by:
• Overcrowding: if a cell is alive and 4 or more of its neighbours are also alive
at the same time, the cell becomes dead.
• Exposure: if a live cell has 1 or no live neighbour, it dies.
3. Survival: an alive cell survives in next step if and only if 2 or 3 of its neighbours
are alive.
One may appreciate that these rules are simple to follow. But when the cells act
together then this simple rule, followed by each cell, can exhibit a number of pow-
erful phenomena, such as (1) self-reproduction and self-organization, (2) growth of
bacterial colony, (3) computational universality, etc. A well-studied pattern in GoL is
glider, which spatially moves one step after a number of time steps. Figure 1 shows
an example behaviour of glider which moves one step diagonally after four time
steps. It is similar to movement of a living body to another location.
Self-reproduction, another important property of a living body, is also emulated
by GoL, see Fig. 2 as an example. Here, the initial pattern is replicated to generate
two images after 12 iterations and four images after 36 iterations. One can visit
https://www.conwaylife.com/ for many such patterns and behaviour. For a good
reference on GoL, please consult the article by Genaro J. Martinez et al. of this book.
It is, however, obvious that such a range of complex behaviour are shown by GoL
without putting any Central Control on the grid; rather each cell gives its opinion
without considering what others would do. Hence, the environment that GoL creates
is democratic in nature.
In a recent article [5], we have argued that to be an inherently intelligent computing
system, a machine should be a democratic system. The primary support of this
argument came from the assumption that the living systems are more intelligent than
the non-living systems. Since the basic feature of life is to do self-reproduction, a
computing system needs to model biological self-reproduction if it wants to qualify
the ﬁrst step to be an intelligent system. The GoL can do it. In fact, the journey
of CAs was started in 1950s targeting to develop a machine model for biological
self-reproduction [11]. While von Neumann was developing his Theory of Self-
Reproducing Automata, he deeply studied human nervous system and the network

162
S. Das
t = 1
t = 13
t = 25
t = 37
Fig. 2 Example of self-reproduction in GoL: initial pattern (at t = 1) is replicated after some time
steps
of neurons therein. In nervous system, the collective effort of less-powerful neurons
resultsinanamazinghumanbrain.Inourterminology,nervoussystemisademocratic
system, and to model self-reproduction, as done by GoL and other CAs, a computing
system is to be democratic.
It may be noted here that the idea of Artiﬁcial Life has been introduced in the
domain of Artiﬁcial Intelligence (AI) by further nurturing the cellular automata.
It has been dreamt by researchers like Christopher Langton [8] that artiﬁcial and
intelligent life would be created around the principle of CAs. In this case also, the
GoL has remained as the source of inspiration.
Hence, here our point is that a democratic system where the components work
together for achieving a common goal based on interaction and communication
are more coherent as an intelligent system. Such a system needs to have self-
reproducibility, self-organization and fault-tolerance - its universal computation
power can follow as a consequence [5]. The GoL follows all the properties. So
let us claim that GoL is inherently more intelligent than other computing systems,
which can show similar behaviour, but through centralized approach.
However, the GoL practices a form of direct democracy to exhibit complex
behaviour. In case of representative democracy, a set of elected persons legislate
and decide the course of actions on behalf of all. Representative democracy imposes
some policy which may be disliked by many, still they can’t opine. Whereas in direct
democracy, citizens directly participate to decide the policy [7]. In case of GoL, the
individual cells decide about their states independently by looking at their neighbours
only. No external inﬂuence about their policy is admitted by the cells. That is, all cells
are equal, and equally powered to decide overall behaviour of the system. In many
natural phenomena, including growth of organisms and colony, no central control is
observed. So GoL (CAs in general) is considered as natural model of computation.
In fact, the game has great impact on almost every ﬁeld of knowledge.
On the other hand, direct democracy is argued as pure democracy. In the history of
democracy, the city state of Athens of ancient Greece is one of the oldest democratic
states that practised direct democracy. The purpose of the city state was to decide
policy and working principles of the state by involving all the citizens of the state.
We next revisit the intrinsic properties of Athenian democracy, and then point out its
similarities and dissimilarities with the principle of GoL.

Game of Life, Athenian Democracy and Computation
163
3
Athenian Democracy
Athenian democracy refers to the system of democratic government practised in
Athens of ancient Greece from the 5th to 4th century BCE. Under this system, all
male citizens - the d˜emos - had equal political rights, freedom of speech, and the
opportunity to participate directly in the political arena.
In ancient Athens, citizens did participate in a direct democracy whereby they
themselves made the decisions by which they lived. They also actively served in the
institutions that governed them, and so they directly controlled all parts of the political
process. Pericles, who was a prominent Athenian citizen, general and politician,
described that political power of the state was not in the hand of minority but of the
whole people; political life as well as day-to-day life was free and open [7]. But in
private life, the citizens were tolerant to others’ activities. Formally, citizens faced
no obstacles to involvement in public affairs based on rank and wealth.
In The Politics, Aristotle described the properties of ancient democracy and
pointed out that the liberty is the basic principle of democracy (of Athens), one ele-
ment of which is ‘ruling and being ruled in turn’. That is, whatever majority decides is
ﬁnal and constitutes justice. Aristotle observed following features in ancient democ-
racy: (a) election to ofﬁce by all from among all, (b) rule of all over each and of each
by turns over all, (c) ofﬁces ﬁlled by lot, (d) the same man cannot generally hold
the same ofﬁce twice, (e) short terms for all ofﬁces, (f) all to sit on juries, chosen
from all and adjudicating on all matters, etc. [7]. The above features of Athenian
democracy show that no central control was entertained in the state. Since many
were participating in ofﬁces, the dynamics of the state was dominated by the average
wisdom of citizens.
However, this apparent inclusiveness of all citizens in state affairs is not the
whole story. Actually, Athenian political culture was an adult male culture, where
only Athenian men over 20 years age were eligible for active citizenship. Women
had no political rights but forced to provide domestic service. However, the biggest
category of marginalized was the slave population. An estimated ratio of slaves to
free citizens in Athens was atleast 3:2, with estimated slave population of some
80,000–100,000 [4]. Slaves were utilized in nearly all form of agriculture, industry
and mining, and also in domestic settings. Athenian slavery and democracy seem to
have been indivisible.
Hence, the glory of direct democracy and decentralised control in state affairs
stands before a big question. Although there is no hierarchy among citizens, there
was a support of slaves and women to run the democracy. Indeed, this support was the
most crucial to the existence of the democracy. Let us next reproduce the summary
of the Athenian model of democracy from Ref. [7].
1. Principle of justiﬁcation: Citizens should enjoy political equality in order to be
free to rule and be ruled in turn.
2. Key features
• Direct participation of citizens in legislative and judicial functions.

164
S. Das
• Assembly of citizens has sovereign power.
• The scope of sovereign power to include all the common affairs of the city.
• Multiple methods of selection of candidates for public ofﬁce.
• No distinction of privilege to differentiate ordinary citizens and public ofﬁcials.
• With the exception of positions concerned to warfare, the same ofﬁce not to be
held more than twice by the same individual.
• Short terms of ofﬁce for all.
• Payment for public services.
3. General conditions
• Small city state with agricultural hinterland.
• Slave economy creating free time for citizens.
• Domestic service, that is, the labour of women, freeing men for public duties.
• Restriction of citizenship to relatively small number.
It is obvious from the discussion on GoL that many of the above features are
incorporated in the game. The collection of cells of GoL has sovereign power to
compute a function. And, the cells directly participate in the computation.
However, there are also a number of dissimilarities between the principles of
GoL and Athenian democracy. Firstly, the citizens in the democracy can reach a
consensus, but the cells of GoL (and of all CAs) cannot know if consensus has been
reached. In fact, the word consensus is not applicable to the cells of GoL, and so
remains undeﬁned in GoL. Further, whether a decision has been reached in GoL is
generally understood externally. In other word, democratic decision making tends to
be goal oriented, whereas GoL is behavioural. Secondly, the citizens had support of
women and slaves to contribute in and execute the state affairs, but the cells of GoL
(and of all classical CAs) have no such support.
If we want to address the above disagreements in a model of computation, then
it is to be CAs-like networked system in which the cells can reach an agreement
against a proposition. Figure 3 gives an abstract view of the model, which consists of
a large number of independent elements, called cells. Since the cells have to reach a
consensus in ﬁnite time, the model is to be ﬁnite in size. Let us consider for example
that a proposition (p) is given as input. The model decides as ‘yes’ if the members
of the system reaches to a consensus as yes and ‘no’ otherwise. The yes state is
shown in white and no in black in the ﬁgure. Here, the individual cells have limited
computational capability, but due to their collective effort the system achieves a great
computational power. So, a task, which is supposed to be done by the whole system,
cannot be generally completed by an individual cell in ﬁnite time.
Since the above model is abstract and only block diagram of it is presented,
whether it can address the above disagreements is not evident. So, we need to detail
out the working principles of it. We next outline a model of computation for address-
ing the second disagreement.

Game of Life, Athenian Democracy and Computation
165
Fig. 3 An abstract model that reaches to a consensus. Here, p and q are two input propositions
4
A Model of Computation
Let us now think of a CA-like system that can address the second disagreement
between GoL and Athenian democracy as much as possible. As we have seen in
previous section, all the actors of Athens could not participate and opine in the state
policy. Some were playing the role of free citizen and the rest (women and slaves)
were acting behind the screen as support to the free citizens.We argue that these sup-
ports had more effectiveness in the state than the free citizens, because the economy,
backbone of any state, was run by the slaves. Similarly, houses of individuals were
run by women making the men as free citizens. So, we think of a computing system
which consists of many components. And, each of these components is comprised of
two elements - one participates in decision making and opines in an issue depending
on the situation, and the other acts as support to the ﬁrst and does the crucial tasks.
Computationally the support is to be more powerful than the ﬁrst one. Let us now
pen down these thoughts.
The computational model that we are thinking of is similar to a cellular automaton,
where each cell uses a local rule ( f ) to go to its next state depending on the present
states of its neighbours. Unlike classical CAs, however, a cell uses another function,
say g, for additional computation. In the proposed model, this g may be as powerful
as a Push-Down Automaton (PDA).
The model is deﬁned over D dimensional square grid (L), each element of which
is also called as cell. That is, L ⊂ZD. For D = 2, the model, like GoL, is deﬁned
over two-dimensional lattice. Each cell of the model is associated with m nearby
cells and uses a pair of functions f and g. Since we want to get g as computationally
more powerful than f , we allow g to use personal memory. Let S be the set of states
that a cell uses and  be the set of memory symbols, then

166
S. Das
Fig. 4 A typical cell. Here,
st is the present state of the
cell, whereas st
1, . . . , st
m−1
are the present sates of
neighbours. s′ is the internal
state
g :  × S → × S
The other function f takes as input the present states of its neighbours and the internal
state generated by g. Thus,
f : Sm+1 →S
In this model, g takes present state of the cell as input, and considering its memory
symbols, g produces an internal state for the cell and modiﬁes its private memory.
Apart from the neighbour’s present states, this internal state is taken into cognizance
by f to generate cell’s next state. That is, a cell uses a ﬁnite memory which is accessed
and modiﬁed by g. Figure 4 shows the outline of a typical cell. If a cell itself is its
neighbour, then the state of the cell as well as the internal state are the inputs to f .
To get conﬁgurations in this automaton, we need to take the set of memory ele-
ments into consideration, along with the set of states. Hence, here a conﬁguration is
an assignment c : L →S × . Let us deﬁne a projection (cπ) of a conﬁguration c
as cπ : L →S. During computation, observable change occurs in the projections of
conﬁgurations. In traditional CAs, the additional function g is void and projections
are the conﬁgurations.
An initial conﬁguration is given to start the computation, and the output is taken
from a conﬁguration, reachable from the initial conﬁguration. As initial conﬁgura-
tion, the cells are assigned to some states and the memory of each cell is assigned to
some memory symbol. The projections during computations may be interpreted as
guiding patterns in this computation. Hence, in a computation, the function f of the
cells apparently plays the decisive role in computation (like free citizens in Athens),
but the function g plays a crucial role to result in a fruitful computation (like women
and slaves in Athens).
At this stage, however, we keep silence about the size of model and size of conﬁg-
urations. Though, the abstract model of previous section is ﬁnite in size. Generally,
city states were small in size with small or moderate number of free citizens. In fact,
for direct participation in policy making, number of citizens should not be unmanage-

Game of Life, Athenian Democracy and Computation
167
ably high. So for effective computation, we believe, size of a conﬁguration and of the
model are to be ﬁnite. The GoL, note that, practically deals with ﬁnite conﬁgurations.
5
Cellular Automata with Memory
Let us now look at an extension of classical cellular automata, which has similarities
with the outline provided in Sect. 4.
Traditionalcellularautomataarememoryless:acellmovestoitsnextstatedepend-
ing only on the current states of its neighbours. A variant of cellular automata, called
Cellular Automata with Memory has been proposed in [1, 2] where a cell can remem-
ber its previous states. The next state of the cell does not depend only on the current
states of its neighbours but also on its history. That is, a cell uses (a ﬁnite amount
of) memory to store its old states. A memory function φ is used on the history of the
cell to get the mean state
s′
i = φ(st
i , st−1
i
, . . . , st−k+1
i
)
where st
i is the state of cell i at time t. Hence, the memory can store k consecutive
previous states of the cell. The next state (st+1
i
) of the cell is found out by applying
the local rule f on the mean states of the cell’s neighbours.
Memory has also been introduced in GoL [3]. In that work, a cell is featured by its
most frequent state, rather than the latest one. It has been found that the memory of the
past states has an inertial effect on the global behaviour. As a result, the conﬁguration
with greater clusters tend to show higher persistence.
However, it has been shown in a number of works that the memory has great
impact on the dynamics of cellular automata. This dynamics is dependent on the
memory function, which can be implemented in various ways. Genaro J Martinez
et al. have studied the dynamics of ECAs under three memory functions: majority,
minority and parity [9]. They have shown that the use of memory can transform
an ECA class to another, that is, a chaotic ECA can behave like a complex ECA if
memory is incorporated. In short, memory has a powerful impact on the behaviour
of a cellular automaton.
Let us now claim that the cellular automata with memory are special case of the
model proposed in Sect. 4. If the initial conﬁguration contains only empty memory
symbol in each cell, that is, if the memory of each cell initially remains empty, then
the memory of a cell can be used to store the previous states only. And, if g acts as
memory function like φ, f of the model can suitably be modiﬁed to act as local rule
of the automaton.
However, some differences can also be observed. First and foremost, initially
memory of cells in CAs with memory remain empty, whereas we allow initial content
in the memory. Second, as input the local rule takes present states of its neighbours
as well as one component of the output of g.

168
S. Das
6
Conclusion
In this article,we have shown that John Conway used a basic rule of direct democracy
to design his Game-of-Life. In fact, any traditional cellular automaton follows the
principle of direct democracy. The direct democracy was excelled in the city state of
Athens of ancient Greece, where individuals could and should directly participate in
the state affairs. Although the goal of GoL and the city state of Athens is different,
we compare them from abstract point of view.
With similar argument, any distributed system which has decentralized control
can be seen as a democratic system. However, as elements of a distributed system are
also computing elements, computational ability of individual elements and that of
whole system are similar. Precisely, both accept recursively enumerable languages.
In case of GoL and other CAs, on the other hand, computationally less powerful
elements (which are actually ﬁnite automata) can show extraordinary computational
ability (like Turing machine) when they act together. This is in fact the power of
collective effort, hence of democracy. So we have considered cellular automata-like
systems in our discussion.
We have examined some basic properties of Athenian democracy, and then pointed
out the dissimilarities of GoL with it. A major dissimilarity is that the citizens of
Athenshadsupportofslavesandwomen,whowereexcludedfromdemocraticaffairs.
Obviously, the role of the support was more crucial to the existence of the democracy.
Considering this fact, we have outlined a model of computation which has similar-
ities with GoL and can address above limitation. However, this model is actually the
generalization of cellular automata with memory. In future, the work can be extended
in the following direction:
• Computational ability of the model can be explored. The patterns generated by the
model can also be studied and classiﬁed.
• Finiteness of the model can be explored: relationship between size of the model
and ability of g may be studied.
• Whether this ﬁnite model with support of g can attain universal computation can
be studied.
References
1. Alonso-Sanz R (2009) Cellular automata with memory. Springer New York, New York, NY,
pp 823–848. https://doi.org/10.1007/978-0-387-30440-3_55
2. Alonso-Sanz R, Martín M (2002) One-dimensional cellular automata with memory: patterns
from a single site seed. Int J Bifurc Chaos 12(1):205–226
3. Alonso-Sanz R, Martín MC, Martín M (2001) Historic life. Int J Bifurc Chaos 11(6):1665–1682
4. Andrews A (1967) The Greeks. Hutchinson Of London
5. Bhattacharjee K, Das S (2021) Computation with democracy: an intelligent system. In: Pro-
ceedings of the fourth international conference on intelligence science (ICIS2020). Springer,
Cham, pp 273–282

Game of Life, Athenian Democracy and Computation
169
6. Gardner M (1970) The fantastic combinations of John Conway’s new solitaire game ‘Life’.
Sci Am 223:120–123
7. Held D (2006) Models of democracy, 3rd edn. Stanford University Press
8. Langton CG (1986) Studying artiﬁcial life with cellular automata. Physica D 22:120–149
9. Martinez GJ, Adamatzky A, Alonso-Sanz R (2014) Designing complex dynamics in cel-
lular automata with memory. Int J Bifurc Chaos 23(10):1330035. https://doi.org/10.1142/
S0218127413300358
10. McCulloch W, Pitts W (1943) A logical calculus of the ideas immanent in nervous activity.
Bull Math Biophys 5:115–133
11. von Neumann J (1966). In: Burks AW (ed) The Theory of Self-Reproducing Automata. Uni-
versity of Illinois Press, Urbana and London
Sukanta Das currently works as Associate Professor and Head, Department of Information Tech-
nology in Indian Institute of Engineering Science and Technology, Shibpur (formerly known as
Bengal Engineering and Science University, Shibpur). He received his Ph.D. in 2007 from Ben-
gal Engineering and Science University, Shibpur (currently known as IIEST, Shibpur) in Com-
puter Science and Technology. He has been doing research in the different aspects of cellular
automata for more than twenty years. Currently, he is exploring the computational abilities of cel-
lular automata, the non-uniform cellular automata, formal logic of cellular automata, and chaos
and randomness in cellular automata.

Algorithmic Information Dynamics
of Cellular Automata
Hector Zenil and Alyssa Adams
Abstract We illustrate an application of Algorithmic Information Dynamics (AID)
to Cellular Automata (CA) demonstrating how this digital calculus is able to quan-
tify change in discrete dynamical systems. We demonstrate the sensitivity of the
Block Decomposition Method on 1D and 2D CA, including Conway’s Game of
Life, against measures of statistical nature such as compression (such as Lempel-
Ziv-Welch) and Shannon Entropy in two different contexts (1) perturbation analysis
and (2) dynamic-state colliding CA. The approach is interesting because it analyses
a quintessential object native to software space (CA) in software space itself by using
algorithmic information dynamics through a model-driven universal search instead
of a traditional statistical approach e.g. LZW compression or Shannon entropy. The
colliding example of two state-independent (if not three as one is regulating the col-
lision itself) discrete dynamical systems offers a potential proof of concept for the
development of a multivariate version of the AID calculus.
Keywords Algorithmic information dynamics · Algorithmic complexity ·
Elementary cellular automata · Perturbation analysis · Software space · Game of
Life (GoL)
Invited contribution to The Mathematical Artist: A Tribute to John Horton Conway, by WSPC.
H. Zenil (B)
Oxford Immune Algorithmics, Reading RG30 1EU, UK
e-mail: hzenilc@gmail.com
The Alan Turing Institute, British Library, London NW1 2DB, UK
Algorithmic Dynamics Lab, Karolinska Institute, 171 77 Stockholm, Sweden
H. Zenil · A. Adams
Algorithmic Nature Group, LABORES, 76006 Paris, France
A. Adams
Morgridge Institute of Research and Department of Bacteriology, University of
Wisconsin-Madison, Madison, WI 53706, USA
© The Author(s), under exclusive license to Springer Nature Switzerland AG 2022
S. Das et al. (eds.), The Mathematical Artist, Emergence,
Complexity and Computation 45, https://doi.org/10.1007/978-3-031-03986-7_8
171

172
H. Zenil and A. Adams
1
Introduction
In the Summer of 2008, John H. Conway and I (HZ) had the chance to meet each other
as instructors of different Summer Schools held in the same place, the University of
Vermont at Burlington, U.S. One of the main interests of John was the study of rich
dynamics of very simple discrete systems such as cellular automata. We lost John
to complications of COVID-19, a disease I am now trying to ﬁght using the same
kind of mathematical tools he was interested in that I call Algorithmic Information
Dynamics.
Algorithmic Information Dynamics (AID) [24] is an algorithmic probabilistic
framework for causal discovery and causal analysis. It enables a numerical solution
to inverse problems based or motivated on principles of algorithmic probability. AID
studies dynamical systems in software space where all possible computable models
can be found or approximated under the assumption that discrete longitudinal data
such as particle orbits in state and phase space can approximate continuous systems
by Turing-computable means. AID combines perturbation analysis and algorithmic
information theory to guide a search for sets of models compatible with observations
and to precompute and exploit those models as testable generative mechanisms and
causal ﬁrst principles underlying data and systems. AID is an alternative or a comple-
ment to other approaches and methods of experimental inference, such as statistical
machine learning and classical information theory.
One may ask how relevant a purely theoretical framework based on computable
discrete models can be to the real world, but it is never too difﬁcult to ﬁnd simple
arguments allowing algorithmic explanations to complex phenomena [22, 25, 27].
AID connects with and across other parallel ﬁelds of active research such as logical
inference, causal reasoning, and symbolic computation. AID studies how candidate
discrete computable equations as generating mechanisms are affected by changes
in observed phenomena over time as a result of a system evolving (e.g. under the
inﬂuence of noise) or being externally perturbed.
Unlike graphical methods such as Bayesian networks, AID does not rely on graph-
ical representations or (often inaccessible) empirical estimations of mass probability
distributions. AID encompasses the foundations and methods that make the area
of algorithmic information and algorithmic complexity more relevant to scientiﬁc
discovery and causal analysis.
We provide an overview of algorithmic information dynamics and illustrate its
methods in application to elementary cellular automata.
2
Cellular Automata
A cellular automaton (CA) is a tuple ⟨S, (L, +), T, f ⟩with a set S of states, a lattice
L with a binary operation +, a neighbourhood template T , and a local rule f .
The set of states S is a ﬁnite set with elements s taken from a ﬁnite alphabet
Σ with at least two elements. It is common to take an alphabet composed entirely

Algorithmic Information Dynamics of Cellular Automata
173
of integers modulo s: Σ = Zs = {0, . . . , s −1}. An element of the lattice i ∈L is
called a cell. The lattice L can have D dimensions and can be either inﬁnite or ﬁnite
with cyclic boundary conditions.
The neighbourhood template T = ⟨η1, . . . , ηm⟩is a sequence of L. In particular,
the neighbourhood of cell i is given by adding the cell i to each element of the
template T : T = ⟨i + η1, . . . , i + ηm⟩. Each cell i of the CA is in a particular state
c[i] ∈S. A conﬁguration of the CA is a function c : L →S. The set of all possible
conﬁgurations of the CA is deﬁned as SL.
The evolution of the CA occurs in discrete time steps t = 0, 1, 2, . . . , n. The
transition from a conﬁguration ct at time t to the conﬁguration c(t+1) at time t + 1
is induced by applying the local rule f . The local rule is to be taken as a function
f : S|T | →S which maps the states of the neighbourhood cells of time step t in the
neighbourhood template T to cell states of the conﬁguration at time step t + 1:
ct+1[i] = f (ct[i + η1], . . . , ct[i + ηm])
(1)
The general transition from conﬁguration to conﬁguration is called the global map
and is deﬁned as: F : SL →SL.
In the following we will consider 1-dimensional (1-D) CA as introduced by
Wolfram [14, 15]. The lattice can be either ﬁnite, i.e. ZN, having the length N,
or inﬁnite, Z. In the 1-D case it is common to introduce the radius of the neighbour-
hood template which can be written as ⟨−r, −r + 1, . . . ,r −1,r⟩and has length
2r + 1 cells. With a given radius r the local rule is a function f : Z|S|(2r+1)
|S|
→Z|S|
with Z|S|(2r+1)
|S|
rules. The so called Elementary Cellular Automata (ECA) with radius
r = 1 have the neighbourhood template ⟨−1, 0, 1⟩, meaning that their neighbour-
hoods comprise a central cell, one cell to the left of it and one to the right. The
rulespace for ECA contains 223 = 256 rules.
Two-dimensional cellular automata were studied by John Conway [6] of which
his Game Of Life (GoL) is its most popular example. A more comprehensive analysis
of the dynamics of GoL and its persistent particles is provided in [28].
Wolfram introduced [15] an heuristic for classifying computer programs by
inspecting the behaviour of their space-time diagrams. Computer programs behave
differently for different inputs. It is possible, and not uncommon, however, to ana-
lyze the behaviour of a program asymptotically according to an initial condition
metric [16].
3
Algorithmic Information Dynamics (AID)
Based upon or motivated by algorithmic probability in its modern formulation as
introduced by Kolmogorov, Chaitin, Solomonoff and Levin [1, 2, 5, 9], the ﬁeld of
Algorithmic Probability (AP) considers the probability of a (discrete) object being
produced by an algorithm running on a Turing universal system. AP imposes a map-

174
H. Zenil and A. Adams
ping distribution called the universal distribution between input and output. Formally,
a computable process that produces a string s is a program p that when executed on
a universal Turing machine U produces the string s as output and halts.
As p isitselfabinarystring,wecandeﬁnethediscreteuniversalaprioriprobability
m(s) as the probability that the output of an arbitrary binary input of a universal
preﬁx-free Turing machine U is s when this input is provided with fair coin ﬂips on
the input tape. Formally,
m(s) :=

p:U(p)=s
2−l(p)
(2)
where the sum is over all halting programs p for which U outputs the string s. As U is
a preﬁx-free universal Turing machine, the set of valid programs forms a preﬁx-free
set (or self-delimited programming language), and thus the sum is bounded, given
Kraft’s inequality (i.e., it deﬁnes a probability semi-measure).
The methods underpinning AID can be described as a combination of Bayes’
theorem and computability theory, where the default agnostic prior distribution is the
universal distribution instead of some other agnostic distribution such as the uniform
distribution. In this way, any updates to the speciﬁc distribution of the problem
proceed according to algorithmic probability.
Introduced by Ray Solomonoff and Leonid Levin [8, 13], algorithmic probabil-
ity, or the theory of universal inductive inference as he also called it, is a theory of
prediction based on observations that assumes that each individual observed object
is generated by arbitrary computable processes. An example is the prediction of the
next digit in the sequence s = 1234567 . . . . According to algorithmic probability,
the next digit would be 8; if the simplest model (i.e., the shortest self-delimiting pro-
gram) able to generate that sequence is the successor function x0 = 1; xi = xi−1 + 1,
such a model would generate 8 as a predictor of the next digit given the data. The only
assumption is that the prior probability follows a computable probability distribution
even if such a distribution is unknown because as proven by Levin, all computable
distributions converge in what is known as the universal distribution. As one of the
pillars of algorithmic information theory (AIT), the universal distribution that is an
offshoot of the algorithmic coding theorem conjoins algorithmic complexity, uni-
versal a priori probability, and a universal/maximal computably enumerable discrete
semi-measure into a single precise and ubiquitous mathematical formalization of a
necessary “bias toward simplicity” for spaces of computably generated objects. This
is a result that has been called ’miraculous’ in the scientiﬁc literature and been lauded
by the late Marvin Minsky as the most important scientiﬁc theory of relevance to
AI [19, 21].
Algorithmic probability captures (albeit without actually setting out to do so)
longstandingprinciplesonwhichsciencehasbeenfounded:theprinciple(alsoknown
as Occam’s razor) that the simplest explanation (in this case the most algorithmically
probable which turns out to be the shortest algorithmic description) is most likely the
correct one; and the principle of multiple explanations (Epicurus), which mandates
the retention of all explanations consistent with the data; and Bayes’s Rule, requiring

Algorithmic Information Dynamics of Cellular Automata
175
the transformation of the a priori distribution into a posterior distribution according
to the evidence, to keep all hypotheses consistent with the data [19].
3.1
Numerical Methods
AID was conceived and introduced in the early 2010s and is currently an active
area of research, but the methods enabling AID were introduced in the mid-2000s
with the ﬁrst publication of a calculation and systematic study of output probabil-
ity distributions of different types of models of computation appeared in (Delahaye
and Zenil 2007 [3]). While it was not known–no experimental veriﬁcation being
then available–whether the concept of algorithmic probability would empirically
capture the intuition of Occam’s razor other than as established in the theory, Zenil
and colleagues studied the behavior of these probability distributions in an exhaus-
tive fashion [3, 12]. Their results suggested that the output distributions were more
compatible than theoretically expected, and furthermore, met both the theoretical
and empirical expectations entailed in Occam’s razor, as the elements assigned the
highest probability were also found to be the most algorithmically simple accord-
ing to various complementary order parameters, including computable ones, which
converge in value and thus provide further conﬁrmation, while the least frequent
elements were also more random by all measures [19].
The numerical application of AID beyond its theoretical formulation relies
strongly upon numerical methods designed to encompass and expand classical infor-
mation theory to characterize randomness, using measures other than popular com-
pression algorithms, such as Lempel-Ziv, widely used to produce purported approx-
imations to algorithmic complexity [19]. These methods on which AID relies upon
(but is also independent of) are the so-called coding theorem (CTM) and block
decomposition (BDM) methods that have as their main features (1) that can go
beyond entropic and statistical compression approaches by providing the means to
explore and ﬁnd computable models allowing causal discovery (and as opposed to
e.g. obfuscated compressed ﬁles with no state correspondence to a model or evolving
dynamical system), and (2) are sensitive enough to allow (small) perturbation causal
analysis [23, 25, 29].
3.2
The Coding Theorem Method and Causal Discovery
Most attempts to approximate algorithmic complexity have proceeded by way of
popular lossless compression algorithms such as LZ or LZW. However, if we take
the example of the sequence s = 1234567 . . ., an algorithm such as LZ or LZW will
fail at compressing s despite its obvious compressed form (x0 = 1; xi = xi−1 + 1).
This is because algorithms such as LZ and LZW are entropy estimators and they build
a dictionary of most frequent words to assign them shorter codes. For example, if s is a

176
H. Zenil and A. Adams
computable Borel normal number [1], no contiguous subsequence is approximately
represented more frequently than any other of the same length, and the resulting
compressed ﬁle tends to be of about the same size as s itself (modulo change of data
type transformation, which is only a transliteration from, e.g., ASCII to binary) [26].
Because of these limitations of popular lossless compression algorithms, and for
other reasons, Zenil et al. introduced a method based on the so-called algorithmic
coding theorem. Formulated by Levin [8], the algorithmic coding theorem in the
context of algorithmic probability establishes equality between universal a priori
probability m(s) and algorithmic complexity K(s). Formally:
m(s) = 2−K(s) + c
(3)
or equivalently,
−log m(s) = K(s) + c,
(4)
where c is a constant.
Based on this fundamental theorem, and under the assumption of optimality of
the reference Turing machine, the Coding Theorem Method (CTM) is an alternative
to statistical compression algorithms such as Lempel-Ziv (LZW) [20], widely used
to approximate algorithmic complexity. CTM does not rely upon statistical methods
such as those based on the dictionaries on which popular lossless compression algo-
rithms such as LZW are based (being designed to ﬁnd statistical regularities and thus
more closely related to classical information theory than to algorithmic complex-
ity) [4, 11, 12, 18]. The aim of CTM is to embrace Turing universality and explore
the space of computer programs able to capture properties beyond statistical patterns
(as a consequence of which has been overlooked in statistical approaches). Then,
the method pumps it into the generative models that support a natural or artiﬁcial
phenomenon, following the usual scientiﬁc modus operandi–whereas in statistical
and probabilistic approaches the part of the probabilistic content of an object or state
that belongs to the model itself and the part that belongs to the explanation of the
possible explanatory models have traditionally been conﬂated.
For example, when modeling the outcome of throwing a dice, what a statistical
model ends up quantifying is an uncertainty extrinsic to the process itself, the degree
of uncertainty of an observer and its inability to determine the underlying nature
of the generating mechanism (if any). Thus, it quantiﬁes a property of the observer
and not the process undergone by the dice itself. This is because the process of
throwing the dice is deterministic according to the laws of classical mechanics,
which are known to govern the dice trajectory (though quantum ﬂuctuations may be
believed to be probabilistic, at short distances they wouldn’t have any effect). The
probabilistic content of the model describing the dice outcome is thus extrinsic to
the actual process. What an algorithmic-probability-like approach like CTM would
do in principle–and this is its major difference–is to produce a set of deterministic
models describing the dice trajectory and outcome without recourse to probability.
Consequentially, it is in the distribution of possible computable models explaining the

Algorithmic Information Dynamics of Cellular Automata
177
dicethataprobabilityemerges;itisnotassumedbytheindividualmodelsthemselves.
In turn, not only can these models be tested beyond their outcome predictions as
mechanistic(step-by-step)descriptionsoftheprocess,buttheyalsoofferanon-black-
box approach where each model can be followed step-by-step, with model states
corresponding to constructive (e.g. physical) states, as opposed to random variables
withnostate-to-statecorrespondencebetweenthemodelandphenomenologicaldata.
Unlike popular lossless compression algorithms that are guaranteed not to be
able to characterize objects such as s, CTM can in principle do so, because when
running all possible computer programs up to the size of s in bits there is a non-zero
probability that CTM will ﬁnd such a program if it exists. Indeed, this is guaranteed,
as the worst case is when the program in question has the form of print[s] and s is
algorithmically random (i.e., s is incompressible or with an algorithmic complexity
value equal to the length of s, up to a constant). This holds because of the ergodicity
of the algorithmic complexity approximation by the CTM over the software space, if
enough computational resources are expended, which in turn is enabled by the lower
semi-computability of the universal a priori probability [4, 23].
Other measures such as Granger causality and transfer causality are methods
of statistical in nature and used mostly for causal analysis, not causal discovery,
especially because they are unable to deal with models in phase-space corresponding
to possible physical state models. Some relationships between variables, causal or
temporal, can be derived as they can be from intervention analyses similar to Pearl’s
do-calculus, but they don’t produce candidate mechanistic models in the ﬁrst place,
and the causal analysis falls back into the purely classical probabilistic framework
which, though partially circumvented, must be resorted to again when it comes to
testing the associative nature of 2 or more variables.
3.3
The Block Decomposition Method (BDM)
One way to see BDM is as a weighted version of Shannon’s entropy that intro-
duces a local quantiﬁcation of algorithmic complexity into the original formulation
of classical information, a version that is able to help tell apart statistical random-
ness and algorithmic randomness [19, 23, 25]. This is a key epistemological dis-
tinction because (1) a sequence such as s = 123456 . . . would be characterised as
maximally ‘disordered’ by statistical approaches such as Shannon Entropy for an
observer unaware of its deterministic nature (without concept of natural number)
as it is a Borel normal number (Champernowne), unless upon its application one
already had the information that s had been generated by a deterministic process,
which renders the use of the measure redundant (in science this is the rule rather than
the exception when observing data: one investigates the nature of an object when
the nature of that object is as yet unknown); and (2) it is of high empirical value in
application to science.
For example, if we set out to quantify human memory, an experimental subject
would not need to learn s digit by digit in order to generate it, illustrating the algo-

178
H. Zenil and A. Adams
rithmic nature of human cognitive processes, that go beyond statistical patterns. The
sequence s may look very special, but in fact, most sequences are of this type. In
addition to not having any statistical regularity, most sequences–if we consider the
set of all possible sequences–do not even have any short description (low algorith-
mic randomness). That is, most sequences are algorithmically random. Moreover,
the difference between those that do not have a short algorithmic description versus
those that appear statistically random but have a short description is divergent. We
only chose s because it was the most obvious for purposes of illustration (another
example would be the digits of a mathematical constant such as π). Indeed, CTM
and BDM have found many applications in psychometrics and cognition due to this
advantage (see Applications of AID).
What BDM does is to extend the power of CTM to quantify algorithmic random-
ness by implementing a divide-and-conquer approach whereby the data is decom-
posed into pieces small enough that an exhaustive computational search ﬁnds the
set of all computable models able to generate each piece of data [19, 23, 25]. The
sequence of small generators then supports the larger piece of data from which insight
is gained as to their algorithmic properties. Small pieces of data supported by even
smaller programs than those pieces are called causal patches in the context of AID,
as they are the result of a causal relationship between the set of these computable
models and the observed data. On the other hand, models of about the same length
as the data are not causally explained by a shorter generating mechanism and are
therefore considered (algorithmically) random and not causally supported [19].
A sequence of computer programs smaller than their matched patches constitutes a
sufﬁcienttestfornon-randomnessandisthereforeinformativeofitscausalcontent,as
its components can be explained by underlying small computable models shorter than
theoriginalwholedataitself.Thisway,thestrongerthecoarse-grainingoftheoriginal
data (i.e., the weaker the decomposition) the closer the value resulting from the BDM
is to the theoretical optimal value that corresponds to the whole data’s algorithmic
complexity. Hence, the more ﬁne-grained (i.e., the stronger the decomposition), the
more the BDM value can diverge from the whole data’s algorithmic complexity. This
is because the BDM value and the algorithmic complexity are proven to converge (up
to a constant that only depends on the error of the CTM relative to the algorithmic
complexity) as the data partition size tends to the whole data size [23].
3.4
Algorithmic Intervention Analysis
AID, as based on CTM, is a resource-bounded algorithmic complexity measure, as
it takes informed runtime cutoffs (usually very short, to deal with short strings) to
estimate candidate upper bounds of algorithmic complexity under assumptions of
optimality and for the reference universal enumeration chosen.
While AID, MML, and MDL are ultimately related and are based on the principles
of algorithmic probability, these minimum length approaches depart from AID (and
AIT) in fundamental ways. MDL is a model selection principle rather than a model

Algorithmic Information Dynamics of Cellular Automata
179
generating method. As such, AID incorporates the principle of MDL and represents a
generalization, with MDL being a particular case based on learning algorithms using
the statistical notion of information rather than the more general–and powerful–
notion of algorithmic information used by AID that requires Turing-completeness.
In practice, however, MDL and AID can complement each other because AID is
more difﬁcult to estimate while MDL provides some statistical shortcuts, and this
is similar to and mostly already exempliﬁed in the Block Decomposition Method
(BDM), which combines both classical and algorithmic information theories.
In fact, AID is agnostic as regards the underlying method, even if it currently relies
completely on the use of CTM and BDM, as described above. So, for example, when
AID conﬁnes itself to statistical models not produced by CTM, it would collapse
into methods such as MDL or MML, but any methods that introduce attempts to go
beyond the statistical would approximate the spirit (if not the measure, under the
assumption of optimality) of AID as exempliﬁed in CTM and BDM.
AIDcanbeconsideredaspecialcaseorgeneralizationoftheareaofcomputational
mechanics, depending on one’s perspective. They differ in that (1) Crutchﬁeld’s for-
mulation involves the introduction of stochastic processes into the models themselves
(rather than on the probability distribution of the models), while with AID there is
no probabilistic content at the core of the candidate generative model, only at the
level of the universal distribution (the distribution governing all computer programs),
and (2) AID by way of CTM and BDM provides the means to implement other
computational-mechanical approaches, including potentially Crutchﬁeld’s, as the
means to mine the space of computable ﬁnite (deterministic or stochastic) automata
(Fig.1).
Because AID has the potential property (under assumptions of optimality) to dis-
tinguish simple from random and assign them similar values, AID can be considered
a measure of sophistication similar to Bennett’s logical depth. Moreover, a measure
of (re)programmability is a measure of sophistication by design [17], and is based on
AID. Some thermodynamic-like properties associated with reprogramming systems
have been found and reported in the literature [29].
Unlikeotherapproaches,suchasPearl’sdo-calculus[10],algorithmicinformation
dynamicscanhelpintheinitialprocessofcausaldiscoveryandisabletoperformfully
unsupervised hypothesis generation from causal computable models. It also provides
the tools to explore the algorithmic effects that perturbations to systems and data may
have on their underlying computable models, effectively also providing a framework
for causal analysis similar to the do-calculus, but without recourse to traditional
probability distributions. AID can substitute for or complement other approaches to
causal analysis. For example, the methods for causal analysis developed by Judea
Pearl et al. [10] assume the existence of an educated causal model but cannot provide
the means for primary causal discovery (Fig.2).
One can formulate a cause-effect question in the language of the do-calculus as
a probability between a random variable and an intervention P(L|do(D)), and one
can also do so in the context of AID. In one of the typical examples used by Pearl
himself [10], if L represents the human lifespan and do(D) the use of some drug D,
the probability P of D having an effect on L is quantiﬁed by classical probability

180
H. Zenil and A. Adams
Fig. 1 The basic principles of Algorithmic Information Dynamics consist in ﬁnding computable
models or sequences of (short) computable models able to explain a piece of data or an observation
and study the effect that interventions have on such models in the software space. Fully deterministic
systems subject to no noise or no external inﬂuence will ﬁnd an invariant set of candidate models
with description lengths varying by only a logarithmic or sublogarithmic term; any deviation will
suggest noise or external inﬂuence
Fig. 2 Causal intervention matching with AID: Central to AID is the study of the effect of inter-
ventions at the data level to the set of computable candidate models, their changes in program space
being an indication both of the nature of the original data and the nature of the perturbation

Algorithmic Information Dynamics of Cellular Automata
181
to calculate P. What AID does is to substitute AP for P, the algorithmic probability
that D exerts an effect on L, with the chief advantage that not only does one obtain
a probability for the dependency (and direction) between D and L, but also a set
of candidate models explaining such a connection, with no classical probability
involved in the inference or description of each individual model. AP would then
impose a natural non-uniform algorithmic probability distribution over the space
of candidate models connecting D and L based on estimations of the universal
distribution, which in effect introduces a simplicity bias that favors shorter models
as opposed to algorithmically random ones, all of which have already been found
to explain the causal connection between D and L. AID thus removes the need for
classical probability distributions, and more importantly produces a set of generative
models no longer derived from traditional statistics (e.g. regression, correlation),
which even the do-calculus uses to determine the probability of a dependency, thereby
falling back on the methods the do-calculus set out to circumvent.
While perturbation analysis is a major improvement in the area of causal discov-
ery, AID complements it, offering a path to leave the use of classical probability
descriptions out of the models taking a step further towards independence from
other causal confounding statistical methods that introduce probability in the model
description obfuscating ﬁrst principles and preventing generative models. Another
key difference between the original do-calculus and the algorithmic probability cal-
culus is that the do-calculus makes a distinction between P(L|do(D)) and P(L|D),
but in AID both hypotheses AP(L|D) and AP(D|L) can be tested independently,
as they have different meanings under algorithmic probability. AP(L|D) means that
L is the generative mechanism of D and AP(D|L) means that D is the generative
mechanism of L. Each of them would trigger a different explorative process under
AID. The former would look for the set of smaller to larger computable models
denoted by L that can explain D, while the latter would look for all the generative
models {D} that generate L. Intuitively, this means that, for example, an attempt to
explain how a barometer falling (X) could be the cause for a storm would likely not
yield many shorter generative mechanisms to causally explain the occurrence of the
storm (Y), whereas an attempt to do the reverse would, indicating that barometric fall
is effect rather than cause. Clearly, regardless of the result, AP(X|Y) and AP(Y|X)
are not equivalent.
In the language of AID, conforming more to a typical notation in graph and set
theory, the ﬁrst example would be written as AP(L\D) or C(L\D), where C is
the algorithmic complexity of L with intervention D (in the context of AID this is
usually a deletion to a model that includes D), and the second example as AP(X\Y)
or C(X\Y). Alternatively, AP(L\D) would be L with a set of interventions {D}.
Multivariate causal analysis can be achieved by conditional versions of algorithmic
complexity and is currently an area of active research.
In Pearl’s account of causal analysis [10], the so-called causal ladder leading
up to human-grade reasoning consists of three levels, with the ﬁrst being that of
pattern observation covered by traditional statistics and long based on regression and
correlation, the second being interventions such as the one his do-calculus suggests
and that AID allows, and the 3rd level is that of counterfactuals or the power to

182
H. Zenil and A. Adams
imagine what would happen if conditions were different. AID also provides the
most fundamental step in the causal analysis, which is causal discovery, within a
single framework and without the need of resorting to making recourse to different
approaches for different purposes (discovery vs analysis). While the do-calculus
comes with no initial guidelines for how to come up with a ﬁrst testable model,
AID can generate a set of computable models ranked by likelihood and offers a
path towards the full replacement of regression and correlation in the description of
amodel,takingthestatisticalnatureoutofthecausaldescription.Inaddition,AIDcan
also potentially cover all three levels of causality in Pearl’s ladder, and provides the
methodological framework to address each without the need of classical probability,
regression, or correlation.
3.5
Information Deﬁciency as an Algorithmic Information
Calculus
With its ability to quantify the departure of models away from or toward algorithmic
randomness by perturbing a piece of data or a system, AID enables the investigation
of which elements of the data contribute the most to the information necessary for
the underlying causal computable model (the positive information elements) and
which elements would trigger an increase in the system’s algorithmic complexity
(the negative information elements) [25, 29]. This way, the “algorithmic random-
ness control” performed by the algorithmic intervention analysis puts forward new
general methods for studying computable perturbation effects on non-linear sys-
tems, beyond those derived from classical control theory, and without making strong
a priori assumptions of linearity. For example, AID has shown how to reconstruct
the space-time evolution of Elementary Cellular Automata by gathering disordered
states and rearranging by their constructive perturbation value in software space
using AID [25].
Let |S| denote the size of the object S, and not only the number of constitutive
elements. Let N denote the total number of constitutive elements of S.
Let F ̸= ∅be a subset of the set of elements of the object S to be computably per-
turbed. In order to grasp such a formal measure of the algorithmic-informational con-
tribution of each element, one may look into the difference in algorithmic complexity
between the original data S and the perturbed data S\F. We deﬁne the information
difference [25, 29] between S and S\F as,
I (S, F) = K(S) −K(S\F).
(5)
which is analog to randomness deﬁciency but between two not necessarily random
states (Fig.3).

Algorithmic Information Dynamics of Cellular Automata
183
Fig. 3 Perturbation of a single central cell in the 2D Cellular Automaton Game of Life found by
John, H. Conway after running for 1000 steps from an initial random conﬁguration producing its
typical particle structures. The resulting BDM change from the perturbation is showed along with
the change in bytes after compression, along with the entropy differences between the perturbed
(black) and unperturbed cells (grey)
3.6
Study of Dynamical Systems in Software Space
While some theoretical results have connected algorithmic complexity to dynamical
systems, not many applications have done so. One of the main results in AID is
that if a chain of causally connected processes is unaffected and generated from the
same generative mechanism, then its algorithmic complexity remains constant up
to a (double) logarithmic term accounting for the time step when the system is to
be reproduced up to a certain observable time [25]. Anything departing from such
a quantity indicates that the process has been subject to an external perturbation or

184
H. Zenil and A. Adams
interaction which can be pinpointed by AID. Numerical experiments quantifying the
change in the number of attractors in a dynamical system (and therefore the average
depthorshallownessoftheseattractors)demonstratesthat,ontheonehand,removing
elements that reduce the algorithmic complexity of a dynamical system (with respect
to the average length of the models explaining its original description) systematically
reduces the number of attractors [25]. On the other hand, when removing elements
that increase the dynamical system’s algorithmic complexity (thus making it more
algorithmically random), the number of attractors increases. Current open topics
of AID research include multivariable modeling, e.g., describing multiple particles
individually rather than as a system.
ThecomputationalresourcesneededtocomputeCTM,atthecoreofAID,limitthe
size of its application, but BDM extends and combines CTM with other computable
measures, including Shannon entropy itself. One of the most active areas of AID
research is to ﬁnd ways to make the algorithmic measures more relevant and to
ﬁnd possible shortcuts towards the computation of the computable region in the
uncomputable space that is relevant for applications in science.
Similar methods based on AID have been proposed to equip machine intelligence
with an inference engine based on AID, in order to help AI algorithms build com-
putable hypotheses from data that can then be tested against observation [7]. This
would complement other approaches such as statistical machine learning that fail at
tasks such as inference and abstraction.
4
AID Application to Elementary Cellular Automata
We use BDM to approximate −I (S, F) and deﬁne
ΔBDM(S, F) = BDM(S\F) −BDM(S),
where S is the space-time evolution of an ECA and S\F is the same ECA after
perturbation F (e.g. a n pixels in its initial condition). A type of algorithmic mutual
information that can be interpreted as how much information a whole object has
about the information of each of its constituent elements approached by, for example,
perturbation analysis (perturbation or deletion of the elements of interest). To this
end, we take several characteristic ECA examples belonging to different Wolfram
classes.
4.1
ECA Perturbation Analysis
As shown in Fig. 4, BDM is more sensitive to small perturbations and provides ﬁner
grained and often divergent values to those found by statistical means (such as LZW).
The next experiment conﬁrmed this and illustrates the way in which AID quantiﬁes

Algorithmic Information Dynamics of Cellular Automata
185
M
D
B
W
Z
L
50
51
52
53
54
55
1
2
22
30
54
110
Perturbation position
Rule
- 6.2
- 4.2
- 2.1
0
2.0
4.0
6.0
8.0
50
51
52
53
54
55
1
2
22
30
54
110
Perturbation position
Rule
- 16
- 13
- 8
- 4
0
4
9
13
Fig. 4 Left: Perturbation heatmap by compression (LZW). Colour indicates Δ number of bytes
after compression over various perturbation positions on the initial state for 6 characteristic ECA
rules. Right: Perturbation heatmap by BDM. Colour indicates ΔBDM over various perturbation
positions on the initial state for six characteristic ECA rules
change not only in a precise manner but also with an underlying mechanistic expla-
nation in the form of a computable model (in fact, a set of computable models sorted
by likeliness according to algorithmic probability).
To test some of these ideas, we measured the differences in complexity (via BDM)
of ECA evolutions with a single-cell perturbation in the initial state. For simplicity,
we selected a small subset of representative ECA rules (1, 2, 22, 30, 54, and 100)
spanning all Wolfram qualitative behavioural classes to run over random initial states
for some amount of time. All random initial states were 100 cells long, and with
periodic boundary conditions, each space-time ‘image’ was generated by evolving
the initial state over a rule for 80 time steps.
To perturb each space-time evolution, a single cell in the initial state was selected
and “ﬂipped” at a cell position, where a 0 cell would become a 1 and vice versa. The
perturbed state was evolved in the same way as the unperturbed state.
The BDM of each perturbed and unperturbed space-time evolution C were com-
pared as a change in ΔBDM = BDM(Sperturbed) −BDM(Sunperturbed). We also
compared this change in BDM with the measured the change in the number of bytes
after space-time compression between the two evolutions. Figure 4 show the result-
ing change in BDM over various ECA rules and perturbation locations. Since the
initial states are random, these rules show the average results over 1000 different
random initial states.
Figures 5, and 6 shows some examples of a single-cell perturbation on a rule 54
ECA with larger initial state sizes and longer time evolutions.

186
H. Zenil and A. Adams
Fig. 5 Sensitivity to small
perturbations propagating
over time. Single-cell
perturbation on longer
evolutions of Rule 54 with
larger initial states. The
perturbation analysis
suggested by AID and
implemented with BDM is
sensitive enough to pick up
the changes despite the
apparent random
background. The resulting
value suggests the
appearance of a second order
ﬂow of information (on a
particle-like background
already linearly transferring
information) after a
perturbation propagating in
time towards the output
effectively implementing a
logical circuit
Fig. 6 A longer runtime
(and different random initial
condition) of the
perturbation yields
interesting patterns with the
perturbation propagating at
different submaximal speeds
on each side and ﬂipping the
sign of the BDM effectively
indicating a change of
algorithmic information
dynamics from an increasing
orderly circuit-like pattern to
a random-looking pattern
after multiple collisions from
a perturbation that takes over
the original background

Algorithmic Information Dynamics of Cellular Automata
187
4.2
ECA Colliding Event Quantiﬁcation
In addition to single-celled perturbations, we also measured the complexity of ECA
that collide spatially. Each ECA instance shares the same set of 0 cells, but one
ECA operates with 1 cells and the other operates with −1 cells. Because ECA
evolve in a state space consisting of only two types of cells, the interaction rule must
accommodate outcomes for three cell types. This interaction rule that determined the
outcome for a neighborhood of three different cell types was chosen randomly as it is
not important for the proof of concept, the quantiﬁcation of the emergent structures
as a result of the collision as an example of interacting dynamical systems. Since
there are several different types of outcomes that a neighborhood of 3 different cell
types could yield, 1000 different rule outcomes were sampled. The interaction rule
preserves the individual ECA rule outcomes for cells whose neighborhoods consist
of two cell types.
Each ECA were seeded as a single 1 and −1 with 40 cells of state 0 in-between.
This initial state was evolved for 100 time steps under this interaction rule. The BDM
of the resulting image was measured and compared to the BDM of each ECA image
in isolation, without the interaction. The same was measured for the number of bytes
Fig. 7 Lateral collision examples. Time evolutions of ECA rules 30 (grey) and 22 (orange) and
rules 110 (grey) and 30 (orange) on simplest initial state (single black cell) in a collision under an
arbitrary interaction rule

188
H. Zenil and A. Adams
Fig. 8 Top: Elementary CA (ECA) collisions Left: rule 1 v 2. Right: rule 1 v 22. Bottom: Wolfram
Class 3 ECA collisions. Left: rule 30 v 22. Right: rule 30 v 30. Box plots show differences in BDM
and compression during a CA collision, compared to these values in an isolated version of the ECA
rule under a simple (single black cell) initial state
after compression. Figure 8, show the differences in BDM and compression between
ECA in isolation and during a collision event, over 1000 different interaction rules
and for various ECA rule interaction types, by complexity class. For illustrative
purposes, some example state evolutions are shown in Fig. 7.
5
Conclusions
AID grants access to tools able to provide insights into ﬁrst principles and mech-
anistic explanations. It is a tool based on the same kind of simple programs John
Conway thought could help characterise other programs like the Game of Life as
an oversimpliﬁcation of life, for which connections to algorithmic complexity have
also been established [22].
We have here shown that BDM powered by CTM allows the study of dynamical
systems in software space, that is, the effect of a perturbation on the size of the set
of underlying computable candidate models constructively generating each output.

Algorithmic Information Dynamics of Cellular Automata
189
In particular, we have demonstrated an application of AID to (elementary and 2D)
cellular automata. We have shown how AID can be used to study discrete dynamical
systems such as cellular automata and their evolution as an illustration of what
AID can contribute to the study of dynamical systems from a computable-model
perspective (what we call software space).
Based on these results, BDM was more likely to capture small changes from a
perturbation than other measures, such as statistical (LZW) compression. As illus-
trated in Fig. 3, typical statistical measures such as Shannon entropy or LZW and
cognates will be insensitive to small changes (because of lack of granularity, its short-
comings inherited from Shannon entropy, and operating check-sums) specially on a
disordered background, failing at enabling the principles of algorithmic information
dynamics.
Acknowledgements We wish to thank Abicumaran Uthamacumaran for his help with preparing
some parts of this document in the required format.
References
1. Calude CS (2002) Information and randomness. Texts in theoretical computer science. An
EATCS series. Springer, Berlin, Germany
2. Chaitin GJ (1987) Algorithmic information theory. Cambridge University Press
3. Delahaye JP, Zenil H (2007) On the kolmogorov-chaitin complexity for short sequences. Ran-
domness and complexity, from Leibniz to Chaitin. World Scientiﬁc Publishing Press, pp 123–
129
4. Delahaye JP, Zenil H (2012) Numerical evaluation of algorithmic complexity for short strings:
a glance into the innermost structure of randomness. Appl Math Comput 219(1):63–77
5. Downey RG, Hirschfeldt DR (2010) Algorithmic randomness and complexity. Theory and
applications of computability. Springer, New York, New York, NY
6. Gardner M (1970) Mathematical games: the fantastic combinations of john conway’s new
solitaire game ‘life’. Sci Am 223:120–123
7. Hernández-Orozco S, Kiani NA, Zenil H (2018) Algorithmically probable mutations reproduce
aspects of evolution, such as convergence rate, genetic memory and modularity. R Soc Open
Sci 5(8):180399
8. Levin LA (1974) Laws of information conservation (nongrowth) and aspects of the foundation
of probability theory. Probl Inform Transm 10(3):206–210
9. Li M, Vitányi P (2019) An introduction to kolmogorov complexity and its applications. Texts
in computer science. Springer International Publishing, Cham
10. Pearl J (2000) CAUSALITY: models, reasoning, and inference. Cambridge University Press,
Cambridge, UK
11. Soler-Toscano F, Zenil H, Delahaye JP, Gauvrit N (2013) Correspondence and independence
of numerical evaluations of algorithmic information measures. Computability 2(2):125–140
12. Soler-Toscano F, Zenil H, Delahaye JP, Gauvrit N (2014) Calculating kolmogorov complexity
from the output frequency distributions of small turing machines. PLoS One 9(5):e96223
13. Solomonoff RJ (1964) A formal theory of inductive inference. part I. Inf Contr 7(1):1–22
14. Wolfram S (1983) Statistical mechanics of cellular automata. Rev Mod Phys 55(3):601–644
15. Wolfram S (2002) A new kind of science. Wolfram Media, Champaign, IL
16. Zenil H (2013) Asymptotic behaviour and ratios of complexity in cellular automata rule spaces.
Int J Bifurc Chaos 23(9)

190
H. Zenil and A. Adams
17. Zenil H (2014) What is nature-like computation? a behavioural approach and a notion of
programmability. Philos Technol 27(3):399–421
18. Zenil H (2015) Algorithmicity and programmability in natural computing with the game of
life as in silico case study. J Exp Theor Artif Intell 27(1):109–121
19. Zenil H (2020) Compression is comprehension and the unreasonable effectiveness of digital
computation in the natural world. In: Unravelling complexity. World Scientiﬁc Publishing
Press, pp 201–238
20. Zenil H (2020) A review of methods for estimating algorithmic complexity: options, challenges,
and new directions. Entropy 612(22)
21. Zenil H, Badillo L, Hernández-Orozco S, Hernández-Quiroz F (2019) Coding-theorem like
behaviour and emergence of the universal distribution from resource-bounded algorithmic
probability. Int J Parallel Emergent Distrib Syst 34(2):161–180
22. Zenil H, Gershenson C, Marshall JA, Rosenblueth D (2012) Life as thermodynamic evidence
of algorithmic structure in natural environments. Entropy 14(11):2173–2191
23. Zenil H, Hernández-Orozco S, Kiani N, Soler-Toscano F, Rueda-Toicen A, Tegnér J (2018)
A decomposition method for global evaluation of shannon entropy and local estimations of
algorithmic complexity. Entropy 20(8):605. https://doi.org/10.3390/e20080605
24. Zenil H, Kiani NA, Abrahão FS, Tegnér JN (2020) Algorithmic information dynamics. Schol-
arpedia 15(7):53143. https://doi.org/10.4249/scholarpedia.53143.Revision#195807
25. Zenil H, Kiani NA, Marabita F, Deng Y, Elias S, Schmidt A, Ball G, Tegnér J (2019) An
algorithmic information calculus for causal discovery and reprogramming systems. iScience
19:1160–1172
26. Zenil H, Kiani NA, Tegnér J (2017) Low-algorithmic-complexity entropy-deceiving graphs.
Phys Rev E 96(1)
27. Zenil H, Kiani NA, Tegnér J (2018) Symmetry and correspondence of algorithmic complexity
over geometric, spatial and topological representations. Entropy 20(7)
28. Zenil H, Kiani NA, Tegnér J (2019) Algorithmic information dynamics of emergent, persistent,
and colliding particles in the game of life. In: From parallel to emergent computing. Taylor &
Francis/CRC Press, pp 367–383
29. Zenil H, Kiani NA, Tegnér J (2019) The thermodynamics of network coding, and an algorithmic
reﬁnement of the principle of maximum entropy. Entropy 21(6):560. https://doi.org/10.3390/
e21060560
Hector Zenil holds a Ph.D. in Computer Science (Lille 1) and a Ph.D. in Logic and Epistemology
(Paris 1 Sorbonne/ENS Ulm). He is a Senior Research and policy advisor at The Alan Turing Insti-
tute, British Library, London; Lab leader at the Algorithmic Dynamics Lab, Unit of Computational
Medicine, Karolinska Institute in Stockholm, Sweden; and the Head of the Algorithmic Nature
Lab, LABORES in Paris, France. He has held positions at the Behavioural and Evolutionary Lab
at the University of Shefﬁeld and as a Senior Researcher and Faculty Member at the Department
of Computer Science, University of Oxford. He is the Director of Oxford Immune Algorithmics,
an award-winning biotech spinout from Oxford, and the Editor of Complex Systems.
Alyssa Adams received their Ph.D. in Physics at Arizona State University, where they studied the
difference between living systems and non-living ones. Alyssa is currently a postdoctoral fellow
at the Morgridge Institute and the University of Wisconsin-Madison where they study interactions
between viruses and the hosts they infect. These interactions might help us understand how bio-
logical entities co-evolve and together drive new innovative processes.

The Game of Life in Three Dimensions,
and Other Tessellations
Carter Bays
Abstract The game “Life” is deﬁned in a strict sense and three candidates for
three-dimensional versions are presented, along with two dimensional versions in
the triangular and hexagonal grids. One of the versions can be structured to contain
an inﬁnite number of parallel two-dimensional universes, each of which allows for
the evolution of Conway life objects. Various oscillators are described, and a few
interesting collisions between translating oscillators (“gliders”) and other objects are
mentioned.
1
Introduction—Conway’s Game of Life
Most readers are probably familiar with John Conway’s two-dimensional Cellular
Automaton (CA) known as the “Game of Life” [1, 2]. The game is “played” by
zero players on an arbitrarily large grid of square cells, where each cell is either
“alive” or “dead”. Essentially, the game works as follows. Start at generation one
with some pattern of living cells (squares on the grid that are ﬁlled in). To obtain the
next generation, apply the following transition rules concurrently to each cell, C, on
the grid, whether ﬁlled in or not.
Rule One: If C is living and if it touches (i.e. is a neighbor of) two or three living
cells, it remains alive for the next generation; otherwise, C dies (i.e. erase the
ﬁlled-in square) for next generation.
Rule Two: If C is not living and if it touches exactly three living cells, C becomes
alive (i.e., ﬁll C in for next generation).
Readers familiar with the game may recall that with appropriate starting patterns,
wecanobtainahostofstableandoscillatingshapes(called“oscillators”),whichCon-
way and others have given such whimsical names as “beehive”, “blinker”, “clock”,
C. Bays (B)
Distinguished Professor Emeritus, Computer Science and Engineering, University of South
Carolina, Columbia, SC, USA
e-mail: bays@sc.edu
© The Author(s), under exclusive license to Springer Nature Switzerland AG 2022
S. Das et al. (eds.), The Mathematical Artist, Emergence,
Complexity and Computation 45, https://doi.org/10.1007/978-3-031-03986-7_9
191

192
C. Bays
“pulsar”, etc. [3]. Several oscillators translate across the grid with successive gen-
erations; such oscillators are traditionally called gliders, a term which we shall use
throughout this chapter [3–5].
1.1
The Rules of Life
We can formalize (somewhat) the rules for a Life game as follows. Deﬁne environ-
ment E as a set consisting of living neighbor counts required to prevent a currently
living cell from expiring; fertility F as a set consisting of living neighbor counts
required to create a new living cell. A rule can thus be speciﬁed as E/F. For exam-
ple, {4,7}/{5} would specify a CA with E = 4 or 7 (only!) and F = 5. We would
write 4, 7/5 (which is not a Game of Life as deﬁned below). Conway’s Rule would
be written as 2,3/3.
Deﬁnition 1 Arule E/F deﬁnesa“GameofLife”ifandonlyifbothofthefollowing
are true.
• Deﬁne“primordialsoup”asanyﬁnitemassofarbitrarilydenserandomlydispersed
living cells. Then all ﬁnite primordial soup conﬁgurations, when subjected to E/F,
must exhibit bounded growth.
• A glider must exist and must eventually occur “naturally” if we apply E/F repeat-
edly to primordial soup conﬁgurations.
The reason for the ﬁrst part of the deﬁnition is that rules which exhibit expansive
growth would not be suitable for complex forms that, for example, would produce a
glider gun, etc. It is true that some unbounded rule might be found that allowed for
the construction of complex forms, but the beauty of Conway’s rule is that it satisﬁes
Deﬁnition 1, yet allows for the construction of amazing forms that accomplish many
tasks, e.g. simulate a Turing machine, etc. No continually expansive rule would allow
this; most constructs would simply “explode” into a big glob of living cells that would
expand forever. Also, this deﬁnition limits the scope of our search, which must try
out plausible rules to see if they might produce a candidate for Deﬁnition 1.
We have not speciﬁed in our deﬁnition just how many “soup experiments” to
perform before we conclude that a glider does not exist; this question is best answered
by considering the implication of Deﬁnition 1—if a glider does not condense out
of some haphazard arrangement of cells, then there is little hope of creating one by
bombarding some conﬁguration with a (man-made) glider. Thus, the “rarer” a glider
is, the less likely that interesting conﬁgurations (e.g. a “glider gun”—a manufactured
device which produces an endless supply of gliders) may exist.

The Game of Life in Three Dimensions, and Other Tessellations
193
2
Finding a Rule for Three-Dimensional Life
In three dimensions a cell can have from 0 to 26 living neighbors; hence we may
construct a huge variety of rules of the form described above, namely (226 −1) E
rules, and (226 −1) F rules—in excess of 1015 possible rules! Fortunately, if we
are looking for a rule that behaves in a manner similar to Conway’s rule, we can
restrict our scope considerably, since most of the possible combinations yield forms
that expand rapidly and indeﬁnitely or quickly shrink and disappear, or stabilize as
a blob-like oscillator (see Figs. 1 and 2).
Fig. 1 The rule 10, 11, . . ., 21/10, 11, . . ., 21 frequently leads to objects that look similar to the one
shown. This object oscillates with a period in excess of 100. By starting with large initial objects,
we can create oscillators with periods as long as we wish

194
C. Bays
Fig. 2 The rule 4, 5/2, 3, 4,
5, 6 leads to immediate
unbounded growth. Here, the
starting pattern was six
centrally placed cells
2.1
The Best Rules for Three-Dimensional Versions of Life
After applying certain obvious constraints and investigating several rules, we found a
few that satisfy Deﬁnition 1. The best rules are 4, 5/5 and 5, 6, 7/6. Subsequent gen-
erations of most other rules either expand into (sometime stable) blobs or disappear
entirely; a couple support very rare and hard to discover gliders (see Fig. 3).
Fig. 3 Above are some of
the oscillators for 5, 6/5.
With initial random soup, 5,
6/5 produces very little
residue. An exhaustive
search has revealed a
naturally occurring, but very
rare glider

The Game of Life in Three Dimensions, and Other Tessellations
195
Fig. 4 A few of the many small stable forms under Life 5, 6, 7/6. The Glider is shown at the top
Rule 5, 6, 7/6 leads to stable and oscillating forms (see Fig. 4) that are similar in
many ways to Conway’s 2, 3/3 as discussed below. One of the characteristics of Life
5, 6, 7/6 is that the three environment states allow for a large number of small stable
asymmetric objects. For example, if we conﬁne our scope to the stable forms that
can be contained within a 4 × 4 × 4 cube, there are well over 100 varieties. Figure 5
depicts just a few of the many stable shapes that can be created by removing from
one to four cells from a 24-element stable object.
Rule 4, 5/5, although somewhat less proliﬁc than 5, 6, 7/6 may ultimately be a
more interesting rule. For one thing, 4, 5/5 requires more time to “settle down” than
5, 6, 7/6; hence, there is more of a possibility for interesting intermediate reactions.
Moreover, it is formed simply by adding 2 to Conway’s rule, 2, 3/3. Perhaps the
most fascinating feature of 4, 5/5 is that there exist an abundance of small stable
and oscillating forms that usually exhibit symmetry of some sort. This rule will be
discussed in more detail in Sect. 2.3.

196
C. Bays
Fig. 5 Here are just a few of the many stable shapes under 5, 6, 7/6 that can be created by removing
one or more cells from a 24-element symmetric stable object. There are too many such forms to
illustrate
2.2
A Comparison Between Conway’s Life and
Three-Dimensional Life
Before proceeding further, we should examine the relationship between the above
three-dimensional Life rules and Conway’s two-dimensional rule 2, 3/3. Deﬁne a
Conway object as any conﬁguration of cells, stable or not, that exists at some point
during Conway’s game. Cells in Conway objects will have coordinates (xi, yi, 0);
that is, the object lies in the Z = 0 plane. We shall further employ the following
deﬁnitions.
Deﬁnition 2 An expansion of a Conway object is formed in three dimensions by
making copies of all living cells (xi, yi, 0) into the adjacent Z plane, i.e. (xi, yi, 1).

The Game of Life in Three Dimensions, and Other Tessellations
197
Hence, the expansion has twice as many living cells as the original Conway
object. It may or may not behave in an interesting manner when subjected to one of
the three-dimensional Life rules: 5, 6, 7/6 or 4, 5/5.
Deﬁnition 3 A projection of a three-dimensional Life object into two dimensions
exists if and only if both of the following are true.
1. All of the living cells (xi, yi, zi) lie in two adjacent planes. For the sake of
discussion, let these planes be Z = 0 and Z = 1.
2. The pair of cells (xi, yi, 0) and (xi, yi, 1) are either both alive or both dead.
Deﬁnition 4 An analog of a Conway object in three dimensions is an expansion
which, when subjected to the appropriate three-dimensional Life rule, yields after
each and every generation a projection identical to the original Conway object for
the same generation under the two-dimensional rule 2, 3/3.
The above deﬁnitions facilitate statement of the following theorem.
Theorem 1 A Conway object has an analog under the three-dimensional Life rule
5, 6, 7/6 if and only if the Conway object has both the following characteristics at
every (subsequent) generation:
a. A non-living cell in the neighborhood of the object cannot have six living neigh-
bors.
b. A living cell cannot have ﬁve neighbors.
The proof is obtained by examining Tables 1 and 2.
Notice that the behavior of the expansion in Z = 0 and Z = 1 under 5, 6, 7/6
is identical to Conway’s Life. A deviation only occurs in the Z = −1 and Z = 2
planes; these deviations are the restrictions imposed by Theorem 1.
Upon further examination of Tables 1 and 2, we obtain the following corollary.
Corollary 1 The three-dimensional rule 5, 6, 7/6 yields behavior that is more anal-
ogous to Conway’s Life than any other three-dimensional rule that we may construct.
The implications of Corollary 1 are startling. If one examines all the small stable
and oscillating Conway forms, one notices that a great many of them satisfy the
criteria of Corollary 1 (see Fig. 4). Conway’s glider has an analog under 5, 6, 7/6,
as do some of the more complicated oscillators. Unfortunately, many of the more
interesting and important Conway objects do not have analogs; for example, there is
no analog for the “glider gun” and other so-called breeding structures.
Preliminary testing has revealed that collisions between gliders and other objects,
though occasionally analogous, usually yield non-analogous results. Sometimes the
ﬁrst few generations after impact of analogous objects behave nicely, but sooner or
later the conditions of Theorem 1 are usually violated; when this happens, the object,
theretoforeconﬁnedtotwoplanes,almostalwaysformsaroundishthree-dimensional
mass that usually dies rather quickly, but occasionally stabilizes.

198
C. Bays
Table 1 Comparison of the number of neighbors and the status for Conway cells and 5, 6, 7/6
cells. For example, if a Conway cell is alive and has four neighbors (N = 4 in column one of the
table), then next generation it will die, as will the pair of cells in the 5, 6, 7/6 expansion. But when
a cell in the Conway object has ﬁve neighbors, the next generation of 5, 6, 7/6 expansion will have
new live cells in planes adjacent to the expansion, thereby destroying the analog
Conway object
5, 6, 7/6 expansion
Number of neighbors, N, within
N, state of cells at (xi, yi, 0)
N, state of cells at (xi, yi, −1)
cell at (xi, yi, 0) is alive
And (xi, yi, 1)
And (xi, yi, 2)
N
Next state
N
Next state
N
Next state
0
Dead
1
Dead
1
Dead
1
Dead
3
Dead
2
Dead
2
Alive
5
Alive
3
Dead
3
Alive
7
Alive
4
Dead
4
Dead
9
Dead
5
Dead
5
Dead
11
Dead
6
Alive
6
Dead
13
Dead
7
Dead
7
Dead
15
Dead
8
Dead
8
Dead
17
Dead
9
Dead
Table 2 Here we are concerned about next generation status for cells that are not alive, but are in
the immediate vicinity of live cells. When the Conway object contains vacant cells with six live
neighbors, then the next generation of the 5, 6, 7/6 expansion will have new live cells in planes
adjacent to the expansion
Conway object
5, 6, 7/6 expansion
Number of neighbors, N, when
N, state of cells at (xi, yi, 0)
N, state of cells at (xi, yi, −1)
Cell at (xi, yi, 0) is dead
And (xi, yi, 1)
And (xi, yi, 2)
N
Next state
N
Next state
N
Next state
0
Dead
0
Dead
0
Dead
1
Dead
2
Dead
1
Dead
2
Dead
4
Dead
2
Dead
3
Alive
6
Alive
3
Dead
4
Dead
8
Dead
4
Dead
5
Dead
10
Dead
5
Dead
6
Dead
12
Dead
6
Alive
7
Dead
14
Dead
7
Dead
8
Dead
16
Dead
8
Dead

The Game of Life in Three Dimensions, and Other Tessellations
199
Fig.6 AcollisionbetweenobjectsthatareConwayanalogsinLife5,6,7/6—aglideranda“clock”.
Here, however, the glider is attacking from a perpendicular plane. As far as the entire conﬁguration is
concerned, only generations 7 through 10 are analogs of Conway Life. At generation 10, Theorem 1
part b, is violated; hence, growth in the Z direction is initiated. For this particular collision, the
living mass seemed to remain conﬁned to two planes for a short while before suddenly “releasing” a
stable 24-element object. The usual result of a collision is a rather quick annihilation of both objects
Note that analogous behavior is very narrow in scope—it takes place entirely in
two adjacent parallel planes. Obviously, we may alter any three-dimensional glider-
to-object collision by shifting one of the participants in the Z direction. Thus, if the
analogs lie in the Z = 0, Z = 1 planes, we can shift one of the objects by one, two,
or three Z planes and achieve entirely different collision results. Furthermore, we
need not conﬁne our objects to nearby Z planes—a glider can, after all, attack from a
perpendicular plane (see Fig. 6). Hence, analogous behavior is at most a small subset
of 5, 6, 7/6, which is replete with its own objects and collisions.
It is, of course, rather convenient to have an immediate supply of known stable
and oscillating Conway analogs already available for 5, 6, 7/6. Furthermore we
might eventually ﬁnd a three-dimensional glider gun by placing appropriate objects
on either side, most likely in the Z = −2 and Z = 3 planes.

200
C. Bays
2.2.1
Time-Space Barriers
If we build a stable form in the Z = 0 plane and make each living cell have seven
living neighbors, then no births under the rules 5, 6, 7/6 can ever occur in the two
parallel adjacent planes; these planes would remain “dead”. Observe Fig. 7 and note
that every cell in the adjacent planes has 7 neighbors; they are the result of the way
the barrier is constructed. and hence can never be “born” under fertility rule 6. And
placing living objects in the Z = 2 plane can only contribute to the number of living
neighbors. Hence all the cells in the Z = 1 plane will remain dead, no matter what
is going on in Z = 2. A portion of such a form, called a time-space barrier, is shown
in Fig. 7. If the ﬂat part lies in the Z = 0 plane (extending an unspeciﬁed amount
in the positive x and y directions), then no glider or other form approaching from a
higher Z plane can ever penetrate into the Z = 1 plane. Of course, the same is true
on the other side of the barrier, and we have not considered the boundary, which here
has been stabilized with eight-element cubes. Naturally, we might choose to have
our barrier extend to inﬁnity in the x and y directions.
2.2.2
“Nearly 3-D” Life and Conway’s Game as a Subset
Construct two arbitrarily large parallel time-space barriers and place them initially
quite some distance apart. Life forms under 5, 6, 7/6 would behave in their usual
unrestricted fashion insofar as our distant barriers would allow. But now we will move
Fig. 7 The object at the left is a portion of a “time-space barrier”. No life can get within one cell of
the ﬂat portion of this form, which can be made to extend indeﬁnitely. The ﬁnite parallel barriers at
the right have four planes between. Hence, a “mini Conway universe” analog can exist in the two
middle planes as long as no shape wanders too close to the barrier boundaries

The Game of Life in Three Dimensions, and Other Tessellations
201
the barriers closer together. As we do, evolving Life forms would be “squeezed”;
growth in the Z direction becomes more and more inhibited. For example, when
the barriers are separated by six planes, all life is conﬁned to the four planes in
the middle—what we have here is a “nearly 3-D” Life where each spacing of the
barriers exhibits a version of the game whose behavior is distinct from any other
conﬁguration. Now consider what happens when the barriers are four planes apart
(Fig. 7). All life must then be conﬁned to two planes. Recall from Theorem 1 that
the 5, 6, 7/6 analog to Conway’s Life breaks down only because of growth in the Z
direction. But now we have prevented such growth; hence, an analog to the entire
Conway Life universe is contained between the barriers. For that matter, we could
construct an inﬁnite number of parallel Conway Life universes.
Of course, nothing can slip out (in the X or Y directions) from between ﬁnite
barriers—at least as they are constructed. For example, the edges would interact with
any escaping glider, thus ruling out a simple glider gun. Possibly, some oscillators
could be appropriately placed to allow a glider to leave the vicinity unimpaired; this
is undoubtedly the best approach to gun construction.
2.3
The Rule 4, 5/5
We can build charts similar to Tables 1 and 2 for 4, 5/5, showing that Conway’s rule
2, 3/3 has no three-dimensional analog under 4, 5/5. The conclusion is that although
4, 5/5 has an occasional analogous form or two, its “universe” is completely different
from that of Conway and, for that matter, different from the universe of 5, 6,7/6. It
is interesting that although the two three-dimensional Life games behave in totally
different ways, they both seem to stabilize rather quickly, with 4, 5/5 requiring
somewhat more time. For example, if we start with a random conﬁguration in, say, a
70 × 70 × 70 grid, both rules will stabilize after about 30–70 generations, depending
upon the starting density. Collisions between gliders and other small objects usually
die after about 5–20 generations unless they happen to yield debris.
The early discovery of a totally distinct glider (Fig. 8) was the catalyst that led to
the extensive investigation of this rule. The 4, 5/5 glider contains ten elements and,
like Conway’s glider (and its 5, 6, 7/6 analog), has a period of four after which it has
moved a distance of
√
2, in one of twelve directions perpendicular to one coordinate
axis and at an angle of 45◦with the other two.
2.3.1
Additional Shapes of 4, 5/5
The relative low density of stable life (resulting when we start with pseudo-random
primordial soup) is somewhat compensated for by the rich variety and symmetry of
small Life forms. Several of these “naturally” occurring forms are shown in Fig 9.
We may create primordial soup in several ways. Perhaps the easiest method is to
initialize each cell in our ﬁnite universe according to the output of a random number

202
C. Bays
Fig. 8 The 4, 5/5 glider, showing the four states. When state one is encountered again, the glider
will have moved one unit up and one forward (i.e., in the positive Y Z direction)
Fig. 9 A few of the small symmetric forms which occur “naturally” in Life 4, 5/5

The Game of Life in Three Dimensions, and Other Tessellations
203
Table 3 The total cumulative volume of residue objects = 1, 761 after 10 “soup” experiments. Total
volume of the “universe” = 3, 430, 000; approximate density of residue = .00051. Summarized
are the most common Life 4, 5/5 objects at stabilization. The ﬁnal density can vary considerably
depending upon the density of the original primordial soup
Object (see Fig. 9)
Number of Elements in the
object
Occurrences of object at
stability
A
6
124
B
8
37
C (period = 4)
8 or 10
36
D
6
28
E (period = 4)
8 or 10
14
F
12
3
G
6
3
H
10
2
I (period = 2)
7
2
J
10
1
K
10
1
L (period = 4)
10
1
Glider
10
0 (1 observed)
M
9
1
generator. For example, on our exhaustive journey through the universe, as we pass
each cell, generate a random number, r. Then, for some ﬁxed constant, k, if r < k,
let that cell be alive, otherwise not. After all cells have been set we proceed with our
evaluation for subsequent generations.
We can get some idea of the relative paucity of Life forms by examining Table 3.
The entries were found by applying the “soup stirring” rule 4, 5/1, 2 repeatedly
g times to a 70 × 70 × 70 space that had been ﬁlled with about 40 random living
cells. The rule 4, 5/5 was then employed. Ten samples were made with g set to
various values between 14 and 27. All forms were allowed to stabilize; this usually
occurred after about 60 or 70 generations. The stable residue was then tallied. The
lone observed glider was not counted. Perhaps gliders are more common than this
table would indicate, as they may have gone off the screen or collided with something
before being observed.
2.3.2
Glider Collisions in Life 4, 5/5
The huge number of reﬂections and rotations of the small stable forms leads to a
myriad of distinct possible collisions between gliders and other objects. One would
expect (and indeed one ﬁnds) the usual result of such collisions to be the annihilation
of both objects. However, preliminary exploration has revealed a surprising number

204
C. Bays
of interesting interactions. With the low (≈10−3) density of stable life ultimately
settling out from “soup”, the fact that so many Life forms result when a glider (ten
elements) collides with another small object (about ten elements) implies that some
rather mysterious forces are at work. A typical interesting collision result is shown
in Fig. 10.
2.3.3
Manufactured Stable Forms
Although most of the stable Life 4, 5/5 shapes found “in nature” (i.e., as the result of
some evolving population, randomly created or otherwise) rarely contain more than
about a dozen elements, it is possible to construct exotic stable forms (see Fig. 11).
These forms would be highly unlikely to appear as the result of a primordial soup
experiment. One should note that such forms are harder to construct for Life 4, 5/5
than for Life 5, 6, 7/6; this is due to the more limited safe environment range.
3
Another Game of 3D Life
In the two-dimensional hexagonal grid, each cell has six neighbors. If we expand the
hexagonal grid into three dimensions, we can obtain a universe of closely packed
spheres, where each sphere has 12 touching neighbors, which line up in four inter-
secting hexagons (Fig. 12). These hexagons form four non-orthogonal planes which
are parallel to the sides of a regular tetrahedron. This conﬁguration is called “densely
packed spheres” and conforms to certain natural crystal structures.
Notethattherearetwodistinctuniverses,U andUr (seeFig.12).Fortheremainder
of this discussion, we shall deal only with U; Ur is obtained by reﬂecting U in a
vertical plane. Also, we shall use spheres to represent cells, although we could use
hexadecahedrons, or, more simply, points with neighbors connected by lines of equal
length. Although there are 212 −1 possible neighborhood conﬁgurations, it can be
shown that the only possible Life rule would be 3/3, which it turns out to be. This
rule needs to be further investigated (Fig.13 shows some of the small oscillators in
3/3).
4
Additional Games of Life in Two Dimensional Grids
4.1
The Triangular Grid
An entire new universe unfolds when we consider the two dimensional grid of equi-
lateral triangles. Here each cell has 12 touching neighbors (Fig. 14). Many Game of
Life rules have been found for this grid; the gliders for some of the rules are depicted

The Game of Life in Three Dimensions, and Other Tessellations
205
Fig. 10 One of the more interesting Life 4, 5/5 glider collisions. Here a glider collides with an
object called a “blinker”. The original glider and the blinker are destroyed, but a new glider appears.
If the original glider was traveling in the (−Y −Z) direction, then the new one will be heading
toward (−X + Z)

206
C. Bays
Fig. 11 Manufactured Life 4, 5/5 stable forms such as these would likely never be found by
conducting primordial soup experiments; they must be carefully constructed
in Fig. 15. Note the period (given in parentheses) varies considerably. The period 18
glider for 2,7, 8/3 is shown in Fig. 16. Observe that after 9 generations, the initial
glider form reappears at generation 10, but with a different orientation. At generation
19, the original form reappears, having traversed one cell to the right. All the other
debris disappears at generations 10 and 19. The period 80 glider for 2, 7, 8/3 is
rather remarkable; a few of the states for this glider are given (Fig. 17). Most of the
intermediate states spew out lots of cells that rapidly dissipate. Perhaps “ﬂamboy-
ant” would be a good description for this glider, as it spits out much debris while it
moves along. Its exact motion can be traced by observing its position relative to the
black triangle (Fig. 17), which represents a stationary cell in space and is not part of
the glider. Note that the debris tossed behind does not interfere with the eighty-ﬁrst
generation, where the entire process repeats from generation 1, having moved 12
cells to the right. By carefully positioning two of these gliders, one can (without too
much effort) construct a situation where the debris from both gliders interacts in a
manner that produces another glider. This was the basis for the two guns illustrated
in Figs. 18 and 19; hence the rule 2,7,8/3 supports at least two “glider guns”, i.e.
constructs that produce an endless supply of gliders. Unlike Conway’s 2, 3/3 gun,
these guns translate across the grid in the direction indicated. In keeping with the
fanciful jargon for names, translating glider guns are also called “rakes”.

The Game of Life in Three Dimensions, and Other Tessellations
207
Fig. 12 (Clockwise from upper left) The skeleton of a tetrahedron shows the four planes (A −D)
that are parallel to the four hexagonal neighborhoods inU.Ur is obtained by reﬂectingU in a vertical
plane. The little 3/3 glider has two states and travels parallel to an edge (a −f ). By removing any
one of the cells (r,s), we obtain a different orientation; hence, there are 24 different orientations.
The six gliders at generation zero will travel parallel to edges (a −f ); at generation 17 they have
advanced as indicated. As it advances, the 10-element big glider resembles a frog. The 7-element
little glider is the “tadpole”

208
C. Bays
Fig. 13 Here are just a few of the many objects in Life 3/3. All that have been discovered so far
exhibit symmetry of one form or another. Period two oscillators abound, but oscillators with other
periods have been found. Motionless stable objects seem to be quite rare
Fig. 14 In the triangular
grid each cell has 12
touching neighbors. There
are two distinct orientations;
call them “E” and “O” . The
small “e” and “o”
surrounding the capitilized
cell gives the neighbors for
that cell

The Game of Life in Three Dimensions, and Other Tessellations
209
Fig. 15 Various triangular grid Game of Life gliders are shown. The period for each is in paren-
theses; the direction traveled is given by the arrow
Fig. 16 The period 18 glider
for 2, 7, 8/3. The small
horizontal bars have been
placed between the
generations merely to
indicate which cells belong
to a given generation. Note
that generations 10–18
repeat generations 1–10 as
reﬂections. This behavior is
typical for many oscillators

210
C. Bays
Fig. 17 The period 80 glider
for 2, 7, 8/3. The number
below each picture gives the
state of the glider for that
generation. At generation 81
the state at generation 1
reappears 12 cells to the
right; all the other debris
behind it quickly dissipates
Fig. 18 The two glider guns
for 2, 7, 8/3 are shown at
one of their simplest states
But the news is not all good. Although the gliders for two of the rules are by far the
most common oscillator, there is a paucity of small stable forms which unfortunately
exhibit the characteristic of being easily destroyed. Hence it will be difﬁcult to dis-
cover a stable form that remains intact but deﬂects a glider. Conway’s game sports
a plethora of such forms; this greatly contributes to its richness. Moreover, since
these guns themselves translate across space and although there are almost certainly
many more guns, a stationary gun will need to be found. When such a discovery is
made, then it might be possible to construct some of the rather complex forms that
heretofore have only been created for Conway’s original game.

The Game of Life in Three Dimensions, and Other Tessellations
211
Fig. 19 As the glider guns are creating gliders, the guns themselves are traveling upward in the
direction given by the arrow. Each gun releases gliders, which trail behind the gun and are moving
in a downward direction as depicted by the arrows. After 800 generations, the two guns will have
produced the output shown. The gun at the left yields period 18 gliders, one every 80 generations,
and the gun at the right produces a period 80 glider every 160 generations
4.2
The Hexagonal grid
Finally, we come to the hexagonal grid [6]. Past efforts to discover a valid hexagonal
Game of Life rule had yielded no results; but now one such rule, 3/2, has been
discovered (Fig. 20). The glider has a period of 5 and moves in the direction depicted
by the arrow. So far little further investigation of this rule has been done, and it is
unlikely that a “glider gun” and other such complex constructs will be found.
Fig. 20 A glider with a
period of 5 for the hexagonal
Game of Life rule 2/3

212
C. Bays
5
Conclusion
We have explored the game of Three Dimensional Life to some extent, and mentioned
Life in triangular and pentagonal grids. There are at least two more rules in the square
grid that satisfy Deﬁnition 1; i.e. they exhibit bounded growth and support (at least)
one (rare) glider. These rules are 2, 4, 5/3 and 3, 5/3. However it is extremely
unlikely that they will produce any interesting constructions due to the speed with
which primordial soup stabilizes—always with very little residue. The most likely
candidate for productive future research would likely be in the triangular grid, namely
rule 2, 7, 8/3, where two glider guns were easily found. Additional work there might
ﬁnd 2, 7, 8/3 to be as rich as Conway’s original game.
References
1. Gardner M (1971) Mathematical games: on cellular automata, self-reproduction, the garden of
eden and the game life. Sci Am 224:112–117
2. Poundstone W, Wainwright R (1985) The recursive Universe: cosmic complexity and the limits
of scientiﬁc knowledge. Morrow
3. Dewdney AK (1987) The game life acquires some successors in three dimensions. Sci Am
286:16–22
4. Preston K, Duff MJB (1984) Modern cellular automata: theory and applications. Springer, US
5. Bays C The game of three-dimensional life. Unpublished document
6. Bays C (2005) A note on the game of life in hexagonal and pentagonal tessellations. Complex
Syst 15:245–252
Carter Bays is a retired Professor in the Computer Science and Engineering wing of Univer-
sity of South Carolina, Columbia, SC, USA. His research interests include Game of Life Cellular
Automata: Two, Three and Four Dimensions. He is currently on the editorial board of Journal of
Cellular Automata.

