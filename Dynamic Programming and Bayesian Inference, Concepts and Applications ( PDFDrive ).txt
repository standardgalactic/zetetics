 

 
Edited by
 
 
 
 
Mohammad Saber Fallah Nezhad
Concepts and Applications
Dynamic Programming 
and Bayesian Inference,

ISBN-13  978-9535113645
ISBN-10  953511364X
Published by AvE4EvA 
AvE4EvA MuViMix Records
 
 
 
 
 
 
 
 
 
 
 
 
All chapters are Open Access distributed under the Creative Commons Attribution 3.0 
license, which allows users to download, copy and build upon published articles even for 
commercial purposes, as long as the author and publisher are properly credited, which 
ensures maximum dissemination and a wider impact of our publications. After this work 
has been published by InTech, authors have the right to republish it, in whole or part, in 
any publication of which they are the author, and to make other personal use of the 
work. Any republication, referencing or personal use of the work must explicitly identify 
the original source. 
 
As for readers, this license allows users to download, copy and build upon published 
chapters even for commercial purposes, as long as the author and publisher are properly 
credited, which ensures maximum dissemination and a wider impact of our publications. 
 
Notice 
Statements and opinions expressed in the chapters are these of the individual contributors 
and not necessarily those of the editors or publisher. No responsibility is accepted for the 
accuracy of information contained in the published chapters. The publisher assumes no 
responsibility for any damage or injury to persons or property arising out of the use of any 
materials, instructions, methods or ideas contained in the book. 
  
Publishing Process Manager
Technical Editor
Cover Designer
 
 
 
 
D3pZ4i & bhgvld, Dennixxx & rosea (for softarchive)
Stole src from http://avaxho.me/blogs/exLib/
Copyright © 2014
Dynamic Programming and Bayesian Inference, Concepts and Applications 
Edited by Mohammad Saber Fallah Nezhad
Published  29 April, 2014 

 

Preface  
 
 
 
 
 
 
Contents 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Chapter 1 Bayesian Networks for Supporting Model Based 
          Predictive Control of Smart Buildings
        by Alessandro Carbonari, Massimo Vaccarini 
           and Alberto Giretti 
Chapter 2 Integration of Remotely Sensed Images and 
          Electromagnetic Models into a Bayesian Approach 
          for Soil Moisture Content Retrieval: Methodology 
          and Effect of Prior Information
        by Claudia Notarnicola and Romina Solorza 
Chapter 3 Optimizing Basel III Liquidity Coverage Ratios
        by J. Mukuddem-Petersen, M.A. Petersen and M.P. Mulaudzi 
Chapter 4 Risk-Constrained Forward Trading Optimization by 
          Stochastic Approximate Dynamic Programming
        by Miguel Gil-Pugliese and Fernando Olsina 
Chapter 5 Using Dynamic Programming Based on Bayesian 
          Inference in Selection Problems
        by Mohammad Saber Fallah Nezhad 

 

 
 
 
 
 
 
Preface 
 
 
 
 
Dynamic programming and Bayesian inference have been both 
intensively and extensively developed during recent years. 
Because of these developments, interest in dynamic programming 
and Bayesian inference and their applications has greatly 
increased at all mathematical levels. 
The purpose of this book is to provide some applications 
of Bayesian optimization and dynamic programming. 


Chapter 1
Bayesian Networks for Supporting Model Based
Predictive Control of Smart Buildings
Alessandro Carbonari, Massimo Vaccarini and
Alberto Giretti
Additional information is available at the end of the chapter
http://dx.doi.org/10.5772/58470
1. Introduction
Optimal behaviour is one the most desired features of contemporary technological systems.
Challenges like secure operation, energy efficiency, and reliable performance call for the
optimised behaviour of any systems that operate and interact in our living environment. The
challenge in achieving optimised performances resides in the uncertainty that qualifies the
environment surrounding technical systems. Whatever model drives the systems’ behaviour,
it must be able to face unforeseen events, to manage the vagueness of the sensing apparatus
and the errors of the control devices. Bayesian statistics is one of the theoretical backgrounds
that support the construction of systems which are able to act effectively inside complex
environments. Bayesian statistics is grounded on the fundamental premise that all uncertain‐
ties should be represented and measured by probabilities. Then, the laws of probabilities apply
to produce probabilistic inferences about any quantity, or collection of quantities, of interest.
Bayesian inference can provide predictions about probability values pertaining time series or
can model parameters in terms of probability distributions that represent and summarize
current uncertain knowledge and beliefs. Bayesian inference uses a kind of direct causal or
model-based knowledge to provide the crucial robustness needed to make the optimised
behaviour of technical systems feasible in the real world [1]. Once this kind of models have
been built, then theoretically sound evidence propagation algorithms are used to update the
belief set about the external environment and about the system performance, on the basis of
acquired evidence. This is the fundamental mechanism that drives the construction and the
operation of intelligent systems based on Bayesian inference. This chapter describes a sample
engineering application of this approach on a large scale. It concerns the design and the
development of an intelligent building energy management system (smart BEMS) that is able

to optimise the operation of the mechanical air supply systems of the Passeig De Gracia metro
station in Barcelona. To the purpose of this application, predictive models were developed to
support the optimal control of environmental conditions in the station, which was necessary
due to the many interacting variables of the domain.
Building Energy Management Systems (BEMSs) are control systems installed in buildings for
managing the building’s mechanical and electrical equipment, such as ventilation, lighting,
fire and security systems [2]. BEMSs consist of hardware and software components. The
hardware set-up of a BEMS is typically made up of sensor-actuator networks that accurately
monitor the indoor-outdoor environment and the building plants state. The software side of
a BEMS consists of a number of functional layers that implement standard management
functionalities like plant status monitoring, alarm management, demand driven plant
management, reporting, etc. The hardware side of the commercial BEMS technology is at
present a rather mature field. A number of initiatives and associations both at industrial and
public level (e.g. European Building Automation and Controls Association-EU.BAC) are
cooperating to develop open communication and seamless integration standards such as
BACnet, KNX, LonWorks [3], and DALI [4]. The software side of commercial BEMSs is being
standardised as well. Standard EN15232 provides a structured list of controls, building
automation and technical building management functions that make an impact on the energy
performances of buildings. Firstly, it provides a method to define the minimum requirements
concerning the building automation and the building management policies, differentiated
according to the level of complexity of buildings; secondly, it provides detailed methods to
assess the impact of these policies on the energy performance of any given building. Never‐
theless, EN15232 methods are limited to relatively simplified applications, ranging from
simple homeostatic control to demand-driven and time-scheduled policies. The implementa‐
tion of optimised control policies that encompass the complex weather and end-user dynamics
in the energy management of buildings is still missing. The analysis of standard BEMS
applications suggests that only a fraction of the available BEMS energy saving potential of each
specific building is utilized by the implemented management policies, thus missing significant
opportunities for reducing operating costs through better supervisory controls. Frequently,
plant and building set-points follow prescribed schedules and are not optimized in response
to changing dynamic conditions, including weather, internal loads, occupancy patterns, etc.
Nonetheless, there are significant opportunities for optimizing control set points and modes
of operation in response to dynamic forcing functions and utility rate incentives. A number of
studies [5-8] have shown potential savings for optimized controls in the range of 10% to 40%
of the overall cooling cost.
Model Predictive Control (MPC) [9-11] may be used to enhance BEMSs so that they can
improve their control performances getting close to optimal behaviour. MPC is an advanced
control technique [12] that uses the predictions of future building status, obtained by means
of a model of the building’s dynamics, in order to solve the problem of determining the optimal
control policies. The purpose of building management is to guarantee comfort at minimum
operational cost. The MPC integrated approach to building management guarantees perform‐
ance over the full range of conditions which are likely to be encountered. Since the predictions
Dynamic Programming and Bayesian Inference, Concepts and Applications
4

that serve the optimal control are obtained through model simulation of the building future
states, the implementation of MPC requires the development of integrated models capable of
predicting the near future behaviour of the controlled environment under specific conditions,
so that the optimal solution can be sought through scenario analysis [13, 14]. Adaptive and
predictive control strategies would follow from these considerations. The development of
domain models that are able to drive the MPC of a complex set of systems, like the ones
operating in a metro station, is not a trivial task. For example, on one side MPC models must
provide accurate predictions of future states but, on the other side, they must be computa‐
tionally light in order to provide predictions in a time frame compatible with the monitoring
time constraints. Furthermore, MPC models must interoperate with real sensor/actuator
networks that usually, for cost reasons, cannot be larger than few tenths of devices and whose
deployment is constrained by a number of external factors. Nevertheless, the model accuracy
must be granted despite the reduced representation of the physical model and the suboptimal
selection of the parameter set. The fulfilment of such competing requirements compels the
definition of a modelling framework that, by guiding the MPC modeller through a set of
methodological steps, will contribute to design accurate and robust models, which are
sufficiently light to be embedded in real control systems. The Bayesian inference approach,
and its computational counterpart Bayesian Networks, provide the means to manage the
requirements set that compels the development of MPC models.
This chapter will outline the Bayesian Network approach that was followed to develop the
environmental model used to design the line 3 of “Passeig De Gracia” (PdG-L3) metro station
energy control system and the main features of the hybrid modelling solution undertaken to
fulfil its functional requirements. A metro station is a very complex system. It involves, among
others, multi-storey underground spaces having multifaceted thermal behaviour, e.g., intricate
air exchange dynamics with the outside, heat conduction with the surrounding soil and high
variable internal gains due to travelling passengers and trains. Furthermore, a metro station
is usually serviced by various equipment involving cooling, ventilation, safety and security,
lighting, vertical transportation and horizontal passenger transfer, gates and selling machines,
information and auxiliary systems. The research illustrated in this paper is one of the results
of the SEAM4US project funded under EU grant n. FP7-2011-NMP-ENV-ENERGY-ICT-
EeB-285408. The objective of the SEAM4US research is to develop an advanced control system
for the PdG metro station in Barcelona capable of dynamically adjusting the internal environ‐
ment in optimal way, based on forecasts regarding the external environment, in order to
guarantee energy efficiency, comfort and comply with regulations.
2. Literature review about MPC control
As mentioned in the Introduction, the Bayesian networks developed in this chapter were used
to provide forecasts about the future state of the PdG-L3 in Barcelona, given the knowledge
about their current state, in order to support the application of a Model based Predictive
Control (MPC) approach. In fact, MPC is an enhancement of adaptive control.
Bayesian Networks for Supporting Model Based Predictive Control of Smart Buildings
http://dx.doi.org/10.5772/58470
5

It is known that any control in buildings is targeted to minimize power consumption while
keeping required comfort level and guaranteeing robustness of the solution. In order to fit
these specifications, the control system must comply with several features. It must be optimal,
i.e. it finds out the values of a vector of design parameters that yield optimal system perform‐
ance evaluated by a so-called cost function. In addition, the control system must be adaptive,
which is "a special type of nonlinear control system which can alter its parameters to adapt to
a changing environment. The changes in environment can represent variations in process
dynamics or changes in the characteristics of the disturbances. […]" [15]. Robustness is also
required, thus implying that the models used for designing the controller should consider all
process dynamics and must be able to adapt to unknown conditions. Finally, the predictive
feature is another opportunity for achieving high energy efficiencies: prediction gives the
capability of taking soft control actions in advance instead of suddenly reacting to unexpected
deviations from the required state, thus saving energy.
MPC works based on a model of the building dynamics and the solution of an optimization
problem to determine the optimal control inputs. It takes into account the (measured) current
state of the system, future weather conditions and other disturbances (e.g. internal gains), in
order to control actuators (e.g. HVAC, lighting and blind systems), so that energy and money
usage are minimized. At the current point in time, a heating/cooling plan is formulated for the
next several hours to days, based on predictions of the upcoming weather conditions. The
control action is designed by running the model of the process over a given prediction horizon
and evaluating the control sequence that gives the minimum value of the cost function [16].
Based on the results from this computation, the first step of the control policy is applied to the
building, setting all the HVAC components, before moving one step forward and repeating
the process at the next sampling time. This receding horizon approach is what introduces
feedback into the system, since the new optimal control problem solved at the next time will
be a function of the new state at that point in time, and hence of any disturbances that have
meanwhile acted on the building. The final result will be a trajectory of inputs and states into
the future that satisfy the dynamics and constraints of the system while optimizing some given
criteria.
One remarkable survey about the effectiveness of MPC was carried out by means of simula‐
tions and applied to office buildings [17]. First, the authors considered and compared a list of
potential adaptive approaches, among which we cite reduction of the thermal comfort when
the building is not used, widening of the room temperature comfort range, use of Indoor Air
Quality controlled ventilation. Results coming from these approaches were then compared
with the benefits of a model based predictive control. The building was simulated by means
of a single zone, twelfth order, time discrete bilinear building model of coupled thermal, air
quality and light dynamics [18, 19]. Those preliminary simulations showed that the highest
energy savings were determined by predictive control, which was also the best one at reducing
the number of comfort violations encountered during the process.
What makes the application of predictive control to the “Passeig de Gracia” (PdG-L3) metro
station in Barcelona very meaningful is that this is the case of a large underground building
where the interaction with the outdoors is very critical and it can be modelled using very
Dynamic Programming and Bayesian Inference, Concepts and Applications
6

complex analytical approaches and occupancy figures result someway difficult to predict.
Hence, the dynamics of the station cannot be solved –and predicted– though a simplified
thermal model (e.g. of statistical type); so, the reported work focuses on the key problem
regarding the development of predictive models relative to complex domains, which was faced
through the adoption of Bayesian Networks. In fact, they gave back a lumped representation
of a number of sub-systems, involving thousands of variables.
The overall MPC control framework applied to the station is represented in Fig. 1. Inputs u to
the system are the variables that can be driven by the controller (e.g. frequency that drives
injector fans in the case of mechanical air supply). The outputs y are the power consumption
and indicators for comfort and health that must be controlled in order to reach certain desired
reference level r. The relation between inputs and outputs is also significantly affected by a
set of disturbances d, such as weather, train arrival, passenger flows and fans external to the
station: they cannot be manipulated but only “accounted for” by using direct measures,
whenever possible, together with a disturbance model. At each control step, the prediction
model receives candidate input sequences u^ picked out by the controller; disturbance predic‐
tions come from disturbances models d^, measured outputs m from PdG-L3 and the prediction
model estimates the future output sequence y^. The optimal control sequence u * is that one
which minimizes a given cost function while complying with given constraints. Once the
optimization problem has been solved, the first step u of the optimal sequence is applied as
the best control action. The overall procedure is repeated at each step, thus closing the control
loop. The implementation of those systems asks for the development of devices and services:
1.
monitoring systems and intelligent algorithms to interpret occupant’s behaviour [20];
2.
high-level control systems capable of solving optimization problems in real-time;
3.
accurate and fast dynamic models of buildings’ behaviour and their systems, necessary
to feed the high-level control systems (i.e. to generate the predicted output sequence y^);
4.
accurate modelling of disturbances (e.g. occupancy, weather conditions etc..).
The predictive models mentioned by bullet no. 3 above were developed in the form of Bayesian
Networks, because they were able to simulate the complexity of the system under analysis
while keeping the computational effort manageable for real-time applications. To this aim
Section 4 presents the basics on probability inference and Bayesian learning, despite the fact
that this chapter cannot cover all the algorithms related to these topics. In Section 5 the indices
useful to evaluate the quality of the developed networks were shown. In the same section the
problem of network instantiation which includes even uncertainty is unfolded. Section 6 will
report the procedure used to develop the Bayesian Networks object of this chapter, the
validation of their inference capabilities and the cost function implemented by the controller
to search the optimum solutions. Finally, in Section 7 the networks were wrapped within the
whole predictive modelling framework and their capabilities shown through one example.
Conclusions are given in Section 8.
Bayesian Networks for Supporting Model Based Predictive Control of Smart Buildings
http://dx.doi.org/10.5772/58470
7

CONTROLLER
PREDICTION MODEL
STATION
DISTURBANCES 
MODEL
Figure 1. Predictive model based control framework defined for the metro station PdG-L3.
3. Basics of Bayesian Networks
3.1. Inference propagation
According to the framework outlined in Section 2, the current state of a building will be
monitored in real-time by means of a sensor network deployed inside it. However, in order to
limit the number of sensors to be installed in buildings, only a fraction of all the relevant
physical variables are measured, while the remaining variables are derived from models. In
other words, these models allow to estimate indirect measurements from measurements made
directly by sensors. In the case study we are presenting in this Chapter, these models were
developed in the form of Bayesian Networks, mainly because they are suitable to reduce
complex domains into computationally manageable models. This is a key feature when
computations must be performed in real-time. While numerical models (e.g. the DymolaTM
model mentioned in Section 6) take hours to simulate the fluid dynamics and thermal behav‐
iour of the PdG station, Bayesian networks make computations in a matter of seconds or
minutes. Hence they are the most suitable to perform real-time predictions, provided that a
reliable procedure for their development is available.
Other features typical of Bayesian Networks, which might come of advantage in these
applications, are their capability of managing incomplete (e.g. one or a few data are not
available because the corresponding sensors are broken) and uncertain information (e.g. if we
include uncertainty in sensor measurements or if inputs are relative to forecasts of disturbance
actions).
Whenever a Bayesian Network estimates indirect measurements from direct measurements,
in fact it implements inference algorithms. Such inferences are computationally possible,
thanks to the conditional probability relationships defined among the variables of the domain
under analysis. This allows to consider just the most relevant relationships among all the
variables (i.e. nodes), which are kept in the form of conditioned probabilities of the kind
Dynamic Programming and Bayesian Inference, Concepts and Applications
8

P(X2|X1), where X1 is a parent of X2 (which is its child node instead) and X2 is conditionally
independent of any variable in the domain which is not its parent [21]. The “chain rule”
descends from this concept, in that the joint probability of a group of variables in a domain
can be determined by the knowledge of the state of just its parents, thus limiting the database
required for its inference [22]:
P(X1, …, Xn)=∏
i=1
n
P(Xi | X1, …, Xi-1)
(1)
More remarkably, Bayesian Networks allow to perform inferences, in other words any node
can be conditioned upon new evidences, even when they are relative to multiple variables.
This feature is particularly important in case a control system must work in real-time, because
in that case evidences acquired about a state variable (i.e. from sensor measurements) must be
propagated to update the state of the rest of the domain. This process requires conditioning,
and it might be called also probability propagation or belief updating. It is performed via a
flow of information throughout the network, without limitation in the number of nodes [1].
When it is run in the MPC framework, the controller will make queries to a set of nodes
belonging to the networks, whose probability distributions are computed from the state of
other nodes, upon which observations (or evidences) are already available (e.g. the future state
of disturbance variables and the current state of the physical domain). To this purpose the
Bayes theorem is exploited when there is a need to reverse the inference. In particular, if
inference is run from causes to consequences it is called predictive reasoning; otherwise, if
inference is directed from consequences to causes, it is called diagnostic reasoning. Inference
in Bayesian Networks is solved by complex combinations of algorithms [1]. In order to show
how this works in the case of BEMs, a short example will be discussed. The first step towards
the development of any Bayesian Network is defining its graphic structure, which requires all
the variables of the domain to be ordered and causal relationships among them to be defined.
The three elementary structures used to order variables in Bayesian Networks are: causal
chains, causal tress and poly-trees (Fig. 2). Then, other more complex structures may be formed
as a combination or enhancement of these elementary fragments. The computational burden
would change as a consequence.
Figure 2. Graphic representation of a causal chain made up of three nodes (a), a causal tree (b) and a causal poly-tree
(c).
Bayesian Networks for Supporting Model Based Predictive Control of Smart Buildings
http://dx.doi.org/10.5772/58470
9

Just to provide an example, the first structure depicted in Fig. 2-a could be useful to represent
the case of sun radiation hitting and heating up the external surface of an envelope, as a
consequence rising its temperature and making heat flux towards the interior. In case thermal
heat gains cannot be directly measured, an alternative indirect estimation can be made: first
we measure sun radiation hitting the external surface of the wall (e.g. by means of a solar
pyranometer), then a model of the envelope is developed in the form of a Bayesian Network,
which estimates in real-time heat gains by means of inference propagation. These models
would get sun radiation intensity measured by the pyranometer as their input, then inference
would infer the most likely value of internal heat gains (Fig. 3). Such an indirect estimation
needs belief propagation (or probabilistic inference) based on dedicated algorithms. The
notation in Fig. 3 corresponds to the notation in Fig. 2-a, provided that X stands for “sun
radiation”, Y stands for “wall temperature” and Z stands for “heat gain”. In the latter figure
four states were defined for each random variable (or event) and all the probability values
were assumed as a uniform probability function (i.e. all their states are equally likely), because
no learning had been done. The states of the variables were separated into intervals, according
to the knowledge learned about the physical system by the model’s developer, who assumed
sun radiation to be limited between 0 and 400 W/m2, wall temperature between 0 and 65°C,
heat gains between 0 and 4.5 W/m2. Once probability learning is performed as explained in the
next sub-section, the network can be used to evaluate how evidence about the first variable
(i.e. “sun radiation”) is propagated towards the rightmost variable (“heat gain”) passing
through the intermediate one (“wall temperature”).
Figure 3. Example where a Bayesian chain can be used to infer indirect measurements (heat gains) from direct meas‐
urements (sun radiation intensity).
In order to make inference propagation feasible, a conditional probability table must be defined
for each couple of variables in the chain. The model-based knowledge embedded in any
Bayesian Network is represented graphically by a directed link between any variable X (e.g.
“sun radiation”) and Y (e.g. “wall temperature”), which is quantified by a fixed conditional
probability matrix:
Dynamic Programming and Bayesian Inference, Concepts and Applications
10

(
)
(
)
(
)
(
)
(
)
(
)
(
)
1
1
2
1
1
|
1
2
|
|
...
|
|
...
...
...
...
|
|
...
|
n
Y X
m
m
n
m
P y
x
P y
x
P y
x
M
P y x
P y
x
P y
x
P y
x
é
ù
ê
ú
=
= ê
ú
ê
ú
ë
û
(2)
where yi and xi are the generic states of variable nodes Y and X, respectively. In the case in Fig.
3 both X and Y might occur in one of the four possible states. Inference propagation needs to
know first the probability assigned to every state of the second node Y conditioned to each
state of the first node X. A more comprehensive notation is given by the form BEL(x), which
reflects the overall belief accorded to proposition X=x by all evidence so far received, hence
BEL(x)=P(x|ξ). Hence this represents the set of dynamic values obtained as a result of the
updated belief accorded to proposition X=x once all the evidences about its parents is collected
in the event ξ. In the simplest Bayesian topology, which is represented by “chains”, if evidence
ξ={Y=y} is observed, then from Bayes theorem the belief distribution of X (diagnostic reason‐
ing) is given by:
BEL (x)= P(x |ξ)=
P(x) ∙P(ξ | x)
P(ξ)
=β ∙P(x)∙λ(x)
(3)
where the likelihood vector is given by:
λ(x)= P(ξ | x)= P(Y = y | x)=M y|x
(4)
As a consequence, the likelihood of x is the y’s column of the matrix in eq. (2). It is stored as
an input in node Y, so that it can be transmitted as a message to X, thus enabling X to compute
its belief distribution BEL(x), having as many states as the number of rows in matrix My|x.
Propagation is possible even if Y is not observed directly but is supported by indirect obser‐
vation ξ={Z=z} of a descendant Z of Y, which means the chain is of the kind in Fig. 2-a. It can
still be written:
BEL (x)= P(x |ξ)=β ∙P(x)∙λ(x)
(5)
Then, conditioning and summing upon the values of Y:
λ(x)= P(ξ | x)=∑
y P(ξ | y, x)∙P(y | x)=∑
y P(ξ | y)∙P(y | x)=M y|x ∙λ(y)
(6)
where the fact that Y separates X from Z was used. Due to eq. (4), λ(y)=P(ξ|Y)=Mz|y, so in this
case it is derived from the conditional probability matrix between variables Y and Z. To the
purpose of conditional updating in the chain, the state of X is irrelevant to infer the state of
Z, once the state of Y is known, which might be explained by the sentence “Y d-separates X
from Z” [1].
Bayesian Networks for Supporting Model Based Predictive Control of Smart Buildings
http://dx.doi.org/10.5772/58470
11

Starting from these concepts, further and more complex computations can be accomplished,
so as to propagate inference throughout networks with any kind of admissible connections,
but they all need the prior definition of conditional probability tables between linked variables.
3.2. Learning conditional probability tables
In the case of PdG-L3 presented in this chapter, the Bayesian Networks were built in the
HuginTM software environment. This software offers three approaches to learn the entries of
conditional probability tables of the kind in eq. (2): from subjective knowledge; from analytical
equations; from datasets. As the procedure presented in paragraph 6 learned conditional
probability tables from datasets put together through numerical simulations, this is the case
that will be considered in this sub-section. In particular, the algorithm used by HuginTM is
called “EM learning”. In Fig. 4 we depicted two examples of conditional probability tables
required by HuginTM in order to perform the inference propagations explained in sub-section
4.1. The left sided one (Fig. 4-a) is the table needed to define how node Y of the network in
Fig. 2-a is conditionally dependent to node X; while the right sided one (Fig. 4-b) is the table
needed to define the likelihood of each state of the node X with respect to the joint combinations
of the states of nodes U1, U2 and U3 (i.e. X’s parents). It is worth remarking that in this second
case the number of columns is equal to the number of combinations of states of the nodes which
are parents of X.
Figure 4. Conditional probability tables relative to the a node having just one parent with four states (a) and to a
node having three parents with two states each (b).
The case we are considering might be described as a set of discrete variables U={x1, …, xn},
whose multivariate joint probability distribution can be encoded in some particular Bayesian
Network structure Bs. The structure of Bs for our case study was derived from expert knowl‐
edge, hence just probabilities must be inferred from the additional knowledge provided by a
random sample. Also, and according to the references in this field, it is assumed that the
random sample D={C1, …, Cm} contains no missing data [23], which means that each case Cl
consists of the observations of all the variables in U. Also, we can say that D is a random sample
from Bs. Indeed, Bs may be thought as a directed acyclic graph that encodes assertions of
conditional independence. In fact, it orders the variables in domain U such that the joint
probability distribution can be estimated by means of the chain rule in eq. (1). Now, for every
Xi there will be some subset Πi⊆ {X1, …, Xn} such that Xi and {X1, …, Xn} are conditionally
independent given Πi. That is:
Dynamic Programming and Bayesian Inference, Concepts and Applications
12

P(Xi | X1, …, Xn)= P(Xi |Πi)
(7)
As a consequence, a Bayesian Network is made up of a set of local conditional probability
distributions and a set of assertions of conditional independence. These conditional inde‐
pendences can be described like in eq. (7), where the parents of Xi are grouped in the set Πi,
and are useful to “d-separate” any variable (i.e., to make it conditionally independent) from
the rest of Bs.
Given Bs, let ri be the number of states of variable Xi; and let qi = ∏
xl∈Πi
rl be the number of states
of Πi. Let θijk denote the physical probability of Xi=k given Πi=j for i=1,..,n, j=1,..,qi, k=1,..,ri.
Adopting this notation, the following equivalences are valid [23]:
ϑij ≡⋃i=1
n {ϑijk}  ϑBs ≡⋃i=1
n ⋃j=1
qi
{ϑij},
(8)
In other words, eq. (8a) states that the two notations are equivalent and represent the case
where all the physical probabilities of xi =k are grouped, once any xi in domain U is selected
and the states of its parents is fixed at any Πi = j. As a consequence, eq. (8b) represents all the
physical probabilities of the joint space Bs (i.e. the Bayesian Network structure), because it
encompasses all the states of Πi (i.e., parents of xi) and all the variables xi in domain U. Where
“⋃… ” stands for the union of all the states represented by that expression. The probability
distribution of child nodes must be described by a probability distribution, which may be then
updated according to evidence acquired by its parents. The software HuginTM uses the EM
algorithm, which defines a Dirichlet distribution for each variable θij (i.e. one distribution for
any variable of Bs given its parents are in the state j) [23]:
p(ϑij | Bs, ξ)=c ∙∏
k=1
ri ϑijk
N ijk
' -1
(9)
where c is a normalization constant (in the form of a gamma function), N’ijk is the multinomial
parameters of that distribution, limited between 0 and 1, finally ξ is the observed evidence.
The Dirichlet distribution describes the probability of one of the variables xi when it varies all
over its states. One of the advantages provided by using a Dirichlet distribution is that it is
completely defined by its multinomial parameters. In addition, its shape can be easily adapted
to fit various probability density function. Finally, and more importantly, it can be demon‐
strated that the learning process is made easier in this way [23]. In fact, the values N’ijk represent
expert knowledge introduced in the network by the developer themselves. Then, if Nijk is the
number of observations in the database D, in which xi=k and Πi=j, we are able to update that
distribution by adding empirical information meant by the parameter Nijk:
p(ϑij | Bs, ξ)=c ∙∏
k=1
ri ϑijk
N ijk
' +N ijk-1
(10)
Bayesian Networks for Supporting Model Based Predictive Control of Smart Buildings
http://dx.doi.org/10.5772/58470
13

Thanks to this algorithm, which is easily implemented by computer programs, the distribution
re-adjust its shape according to data provided by available sample data. It exploits the notion
of experience, that is quantitative memory which can be based both on quantitative expert
judgment and past cases. The prior parameters in the first version of the network are set with
a particular equivalent sample size based on expert knowledge (by tuning the values N’ijk).
Then subsequent data are added, starting from the given equivalent sample size, so that the
two Dirichlet parameters reshape the probability density function according to observations
included in the dataset, which determine the values of the set of parameters Nijk. Furthermore,
it can be shown that the probability that Xi=k and Πi=j in the next case Cm+1 to be seen in the
database (i.e. expected value) is computed by means of the equation:
P(Cm+1| D, Bs, ξ)=∏
i=1
n
∏
j=1
qi
N ijk
' + N ijk
N ij
' + N ij
(11)
where Nij
' = ∑
k=1
ri Nijk
' , and Nij = ∑
k=1
ri Nijk.
4. Practical implementation of the Bayesian predictor
According to what reported in sub-section 4.2, the conditional probability tables of Bayesian
Networks (BNs) might be defined from a combination of a priori knowledge about the
involved physical processes and a dataset of collected measures. Part of the dataset is usually
used for probability estimation, while the remaining part is usually used for validating the BN.
Such validation may be done according to the following steps:
1.
instantiation of the BN with collected evidences;
2.
evidence propagation through the Bayesian reasoning engine;
3.
evaluation of estimation/prediction performance by computing a proper performance
index.
Once each instantaneous index is computed, a global performance index for the whole
validation dataset might be computed for each node.
4.1. The metrics used for validation
The performance of a prediction model may be evaluated by using different kinds of indices.
As well known, referring to prediction of a variable at a certain time i, the difference between
the predicted value X^
i and the actual value Xi is defined as error Ei ≜X^
i - Xi. Since the
validation of a prediction model is interested just in the magnitude of the error, either its
absolute value called absolute error AEi ≜|Ei| or its squared error SEi ≜Ei
2 can be used.
Percentage error is here defined as the ratio (%) between the error and the actual value of the
variable:  PEi ≜100⋅Ei / Xi. In order to have a global performance index to be evaluated over
Dynamic Programming and Bayesian Inference, Concepts and Applications
14

the whole validation dataset made up of K samples, these instantaneous indices must be
combined into global indices. Therefore, the mean absolute error is defined as:
MAE ≜
1
K ∑1
K |X^
i - Xi|
(12)
and the root mean square error is:
RMSE ≜
1
K ∑1
K (X^
i - Xi)2.
(13)
The indices of the predicted variables are related to different physical quantities with different
units. For this reason, these indices must be normalized with respect to their typical range of
variation. Two more indices are defined and practically used for evaluating prediction models:
NMAE ≜
1
K ∑1
K |X^
i - X i|
|X max - X min|
(14)
NRMSE ≜
1
K ∑1
K (X^
i - X i)2
|X max - X min|
.
(15)
ASHRAE Guideline 14-2002 [24] establishes that for calibrated simulations, the CVRMSE and
NMBE of energy models shall be determined for each calibration parameter by comparing
simulation-predicted data to the utility data used for calibration. The proposed indices are the
coefficients of variation of the root mean square error (CVRMSE) and normalized mean bias
error (NMBE). All these indices are normalized with respect to the arithmetic mean of the
variable. Following this guideline, the RMSE has been selected as the main performance index
for evaluating the accuracy of a BN. However, the mean value of a variable is a good normal‐
ization factor only if the variable is always positive (or always negative). For this reason, the
range of the considered variable has been taken as a normalization factor and the NRMSE has
been selected as final index for the design process of the BN: it includes information about both
bias and variance of the error.
4.2. Instantiation of BNs for MPC
The control block in the framework depicted in Fig. 1 needs to evaluate a cost function for each
candidate control policy. However, since discrete nodes are often used in BNs for describing
nonlinearities, the resulting cost function may also present significant nonlinearities. One of
the main problems in MPC consists in guaranteeing closed-loop stability for the controlled
system. As stated in [25], stability about MPC requires some continuity assumptions. The usual
approach to ensure stability is to consider the value function of the MPC cost as a candidate
Lyapunov function. Even if closed-loop stability is guaranteed in some way without the
continuity assumption, the absence of a continuous Lyapunov function may result in a closed-
loop system that has no robustness. This implies that, whenever possible, a continuous cost
Bayesian Networks for Supporting Model Based Predictive Control of Smart Buildings
http://dx.doi.org/10.5772/58470
15

function is highly recommended in MPC: it implies better stability and robustness and faster
convergence of the optimization algorithm. Moreover, from a modelling point of view, the real
buildings are usually continuous systems, or at least hybrid systems (i.e. mixed discrete-
continuous) but never pure discrete: a discrete approximation would produce a big variance
of the prediction error.
Due to these reasons, the BNs must be continuous with respect to continuous variables. When
BNs contain discrete interval nodes (this is often the case in practice, since it allows to model
more complex relationships between nodes), an instantiation as “hard evidence” (i.e. one state
only of a node is assigned 100% likelihood while the other states are given 0%) produces an
abrupt variation of the outputs only when passing from one interval to the next one, thus
showing a discontinuous behaviour. Therefore, an instantiation must be always done as “soft
evidence” (i.e. more than one state of a node is instantiated, in fact shaping a probability density
function). The idea, with reference to Fig. 5, is to approximate each evidence with nominal
value μ and estimated standard deviation σ as a Gaussian distribution N (μ;σ). This distribu‐
tion is then approximated by an interval discrete distribution that is actually instantiated into
the BN as “soft evidence”. When the evidence has been propagated, the beliefs retrieved by
the network are used to iterate the prediction for an arbitrary number P of steps (see Fig. 7).
The final prediction sequence is then summarized as a sequence of normal continuous
distributions  N(μi;σi),  i =1, …, P.
Technically, the key challenge is approximating a continuous probability density function
by means of a discrete one, as reported in the following. Given mean value and standard
deviation of a normal distribution N( μ
_
i;σ
_
i), and an interval discrete random variable de‐
fined by the values x0, x1, …, xL  (that corresponds to the L + 1 bounds of the L  inter‐
vals), the probabilities of each interval must be found such that mean value and standard
deviation of the discrete distribution are as close as possible to μ
_
 and σ
_
 respectively. As well
known, a normal Gaussian probability density function (pdf) takes the form
f (x)=1/ 2πe -x 2/2,  - ∞< x <∞.
Measure
Gaussian 
approx.
Instantiation 
& 
propagation
Gaussian 
approx.
Discrete 
approx.
Continuous 
distribution
Interval discrete 
distribution
Continuous 
distribution
Interval discrete 
distribution
Singleton 
value
Prediction Loop
Figure 5. Instantiation of a measure as “soft evidence” and corresponding information flow. Instantiation and propa‐
gation is repeated in the prediction loop (dashed), as described in Fig. 7.
Dynamic Programming and Bayesian Inference, Concepts and Applications
16

The cumulative distribution function (cdf) is then given by Φ(x)=1/ 2π∫-∞
x e -t 2/2dt that has no
close form. An effective and sufficiently accurate way for approximating it is provided by [26]:
Φ '(x)≈
e 2z '
1 + e 2z ' ,  where z '=0.7988x(1 + 0.04417x 2)
(16)
In order to consider a general distribution with mean μ and standard deviation σ, the variable
x must be replaced with 
x - μ
σ
:
Φ(x)≈
e 2z
1 + e 2z ,  where z =0.7988( x - μ
σ )(1 + 0.04417( x - μ
σ )2) .
(17)
Given any standard deviation σ
_
>0, and mean value μ
_
>0 to be approximated, the value of
standard deviation must be at least greater than the standard deviation σmin of the interval
xl; xl+1  in which μ
_
 falls:
σ =max(σ
_
,  σmin),  σmin =
xl +1 - xl
12  .
(18)
For each interval of a standard discrete node, probability is given by qi =
qi
'
∑i=0
N -1 qi
'  where:
qi
'=Φ(xi+1) - Φ(xi)
(19)
For a discrete periodic variable (like a direction) defined in the interval x0; xL  (that for a
direction is 0;2π ), the pdf can be split into periodic intervals shifted each other by integer
multiples of period (xL - x0):
x0 + k*(xL - x0); xL + k*(xL - x0) ,  k ∈Z
(20)
If standard deviation is sufficiently smaller than the period σ ≪(xL - x0), this infinite series
can be approximated by the three central intervals, that is for k = - 1,0, 1. Moreover, when
σ ≅(xL - x0), probability is almost equally distributed all over the interval and the approxi‐
mation introduced by neglecting the stubs for k < - 1, k >1 can be simply compensated by
renormalizing the resulting distribution. Thus, in this case, probability of each interval is given
as in the previous algorithm but the right and left stubs of the Gaussian are overlapped in order
to consider periodicity of the discrete variable. For each interval of a periodic discrete node,
probability is given by pi =
pi
'
∑i=0
L -1 pi
'  where:
Bayesian Networks for Supporting Model Based Predictive Control of Smart Buildings
http://dx.doi.org/10.5772/58470
17

pi
'=(Φ(xi+1) - Φ(xi)) + (Φ(xi+1 + (xL - x0)) - Φ(xi + (xL - x0)))+
(Φ(xi+1 - (xL - x0)) - Φ(xi - (xL - x0))) 
 
(21)
The instantiation strategy described above was used according to the scheme in Fig. 5 for
implementing the discrete approximation and smoothing the behaviour of the BNs when
inputting evidences. The first Gaussian approximation of Fig. 5 has mean value equal to the
measure (eventually calibrated) and standard deviation represented by the uncertainty of the
measurement process, that can be determined by the data-sheet of the installed sensor. The
second Gaussian approximation is trivially implemented by computing mean and standard
deviation of the input distribution. Fig. 6 shows examples of Gaussian distributions approxi‐
mated so as to be assigned as evidences of a Bayesian Network.
(a) 
(b) 
0
0.01
0.02
0.03
0.04
-50
-40
-30
-20
-10
0
10
20
30
40
50
Desired normal distribution N(2.5;10)
0
0.2
0.4
0.6
0.8
1
-50
-40
-30
-20
-10
0
10
20
30
40
50
Discrete approximated ditribution (µ=2.5/σ=10.8)
0
0.01
0.02
0.03
0.04
-50
-40
-30
-20
-10
0
10
20
30
40
50
Desired normal distribution N(30;10)
0
0.2
0.4
0.6
0.8
1
-50
-40
-30
-20
-10
0
10
20
30
40
50
Discrete approximated ditribution (µ=27.7/σ=14.9)
Figure 6. Comparison between the desired Gaussian distribution and the approximated one to be instantiated in an
interval discrete chance node of a BN: example of a non-periodic variable (a) and of a periodic variable (b).
5. Development of the Bayesian models and cost function
5.1. The procedure
Basically, the development of both Dynamic Bayesian Networks (DBNs) and regular BNs is
not an easy task and usually consists of three main phases:
1.
definition of the network topology (structural learning);
2.
preparation of the training set and learning of the conditional probability tables;
3.
final assessment of the network.
In the case object of this chapter, the behaviour of the metro station Passeig de Gracia was first
simulated through whole building analyses, which provided datasets encompassing all the
possible environmental conditions, including those which are considered as not very likely,
then that knowledge was transferred into Bayesian Networks. This was deemed necessary
Dynamic Programming and Bayesian Inference, Concepts and Applications
18

because for such complex domains eliciting expert knowledge to learn conditional probability
tables is not feasible. Hence several sets of data were generated through simulations prior to
the application of the EM learning process whose main features were presented in sub-section
4.2. Three datasets were generated:
• the first one was made up of randomly generated data, which means that the inputs (e.g.
weather, heat gains, occupancy figures etc..) were allowed to vary without additional
constraints within their range;
• the second sample, called “likely” dataset, was generated through simulations whose inputs
were allowed to vary within their same ranges cited above, but their differential variations
being constrained: it means that the difference between the value of each variable at the
present time step and the value of the same variable at the previous time step was limited
by a threshold;
• the third “typical” sample was built through simulations, whose inputs were taken from
real measurements, such as real weather conditions in Barcelona, number of people passing
through the station and trains recorded by occupancy surveys, internal heat gains estimated
on the basis of real measurements etc..
As the learning process got information from all these samples, the resulting networks not
only were expected to be able to respond to sudden variations of external actions and to
consider quite unlikely events (which is the case of the first dataset) but to be very sensitive to
the more likely scenarios included in the second and third datasets.
The whole building model used for running simulations was developed within the Seam4us
research as a lumped parameter model in the DymolaTM simulation environment, that is based
on the Modelica language [27]. Starting from a validated library for building simulation
developed by the Lawrence Berkeley National Laboratory [28], a specific library for under‐
ground station was developed, which is so far in its validation phase.
However, such a model cannot be run in real-time when the controller needs to determine the
best candidate control strategies, so it was reduced into the less computationally demanding
form of Bayesian Networks. In order for the PdG-L3 model to predict the environmental status
of the station, it was split into two Bayesian Networks, each relative to a different physical
phenomenon:
• temperature prediction dynamic Network (TP-DBN), which is in the form of a DBN, because
it forecasts expected temperature in the station given inputs about current and past time
steps;
• air flow prediction Bayesian network (AF-BN), which is in the form of a regular BN, because
it estimates variables relative to air flow in the station and energy consumption of the fans,
given its current status.
Once available, the two networks were run according to the scheme outlined in Fig. 7. Here a
portion of the whole process in Fig. 1 is depicted. At every iteration the controller will
opportunely query the two of the networks to get future estimations about the variables
Bayesian Networks for Supporting Model Based Predictive Control of Smart Buildings
http://dx.doi.org/10.5772/58470
19

relevant to select the most opportune control policy to be adopted at each running step. To
this aim, the networks need to be instantiated first: the current temperature in the station’s
platform (PL3) and weather conditions will be provided by the permanent monitoring network
installed in the station, along with candidate fan frequencies. Given these inputs, the controller
is allowed to query the AF-BN in order to estimate fans consumption and air changes in the
station at each time step. Such a prediction step takes a few seconds and is performed by the
software HuginTM through algorithms for belief propagation, of the kind already reported in
sub-section 4.1. Then, the TP-DBN will take these variables as inputs, along with other state
variables (e.g. current PL3 temperature, temperature difference between inside and outside
and forecasted weather, people, train arrival etc..) in order to predict PL3 temperature at the
next time step (which is typically every hour, unless a different control step is required). Again
belief propagation is performed with this second network. Then, the same loop will be repeated
at each iteration. This loop is based on the assumption that temperature variations between
two consecutive hours is so small to be considered constant by the AF-BN without big
prejudice. In other words, to the AF-BN purposes temperature at the next time step (T1) was
considered equal to temperature at the current time step (T0). This assumption did not
compromise the reliability of future estimations, as will be shown by the validation at the end
of this sub-section. Both the networks were built following the same methodology:
1.
first structural learning: it was determined first by the a-priori knowledge from the
researchers, who ordered and connected the variables according to the physical relation‐
ships among them; then statistical analyses were used to improve the assumed structure
and discern the strongest relationships among the variables themselves;
2.
improvement of the network’s structure: this was carried out through analysis of its
performance indices, after learning conditional probability tables from the random
dataset, which was the first set of data generated by running the DymolaTM model without
constraints on all the possible weather conditions and disturbance actions;
3.
final refinement using the two additional datasets: adding more datasets allowed the
developers to quantify even probabilistic relationships among the variables and to define
the final shape of the networks;
4.
final evaluation of the networks: as for the three steps above, also in this final step the
indices defined in paragraph 5.1 were used to evaluate the prediction capabilities of the
networks.
The first step started from the analysis of 81 variables included in the DymolaTM dataset,
properly filtered and re-sampled at a 60 sec rate. Iterative cluster analyses [29] were useful to
group those variables into clusters and determine those which were redundant [30], because
providing the same information given by others (e.g. surface temperatures in PL3 were highly
correlated and grouped in the same level, hence just one of them was kept and the remaining
ones were dropped out).
This first step allowed us to cut down the number of involved variables to 39. Then, a further
reduction was done, where only those variables showing the strongest dependence relation‐
ships were kept, cutting the whole number down to 25, hence finding the minimum number
Dynamic Programming and Bayesian Inference, Concepts and Applications
20

of nodes required to be included in the Bayesian graphs. This final set was naturally grouped
into two sub-clusters of variables: one of them including those related to air flow processes,
and the other one including those related to the environmental temperature dynamics. Finally,
the qualitative relationships among variables (represented by arcs in the networks) were
worked out partly by expert knowledge, and partly using the “structural learning” tool
supplied by HuginTM, which used the information included in the “random” dataset.
AF-BN
TP-DBN
Number of people in station at t+k
Number of trains in station at t+k
Weather data at t+k
Variation of temperature at t+k-1
Temperature at t+k-1
Air change at t+k
Temperature at t+k
Fan driving frequencies at t+k
Weather data at t+k
New Cycle: k=k+1
Fan absorbed power at t+k
PREDICTION MODEL
CONTROLLER
STATION
DISTURBANCES 
MODEL
Figure 7. The basic loop of the predictive cycle adopted for PdG-L3 which involves both Bayesian Networks. It imple‐
ments the prediction model in Fig.1, which starts by setting a counter at 1 and loops until the counter reaches any
desired prediction horizon.
The second step was the most critical in the development process, and helped in several tasks:
• meaning and dependencies between nodes have been reviewed according to the relation‐
ships suggested by physical laws (e.g. PL3 temperature is affected by the amount of outside
air supplied by ventilation and by the temperature difference between indoors and out‐
doors, which became its parents);
• the number of intervals for discretizing the state space pertaining to every node, which was
refined through an iterative process, with the final purpose of minimizing the errors of the
output variables given by the indices outlined in sub-section 5.1;
• a few links have been rearranged, in order to improve the performances of the two networks.
Fig. 8-a depicts the final structure of the dynamic Bayesian network (i.e. TP-DBN), which was
used to predict PL3’s temperature in PdG station in the next step (node TemPL3_p01), starting
from inputs such as: forecasted number of people in the station at the next step (NPeSta_p01),
forecasted internal gains supplied by trains at the next step (GaiTr_p01), current PL3’s
temperature (TemPL3), forecasted outdoor temperature (TOuMet_p01), forecasted air changes
per hour (ACOPL3_p01) and deviation of temperature from the past time step (DTePL3). The
Bayesian Networks for Supporting Model Based Predictive Control of Smart Buildings
http://dx.doi.org/10.5772/58470
21

network’s intermediate variables are useful to perform computations and simplify conditional
probabilistic relationships among variables.
Similarly holds with the AF-BN network (Fig. 8-b), whose inputs are: forecasted frequencies
of fans in the station and tunnels at the next time step (DFreTF1_p01, DFreTF2_p01,
DFreSF1_p01), forecasted internal gains by trains (GaiTr1_p01), forecasted wind direction and
speed (WiDMet_p01, WiSMet_p01), outdoor temperature (TOuMet_p01) and current temper‐
ature (TemPL3). The main outputs are the power consumption of fans – in the station (PElSF1)
and in the tunnels (PElTF1, PElTF2)-and air flow rates expected across the corridors leading
to PL3: AFlCNl_p01 (corridor CNl), AFlCNop_p01 (sum of corridors CNo and CNp),
AFlCNq_p01 (corridoio CNq) and AFlSlb_p01 (station link). These estimated airflows are then
summed up coherently to the Air Mass Balance for computing the overall air change in PL3
(ACOPL3), needed as input from the TP-DBN (Fig. 7).
During this process, whenever expert knowledge deemed more than one structure as reason‐
able for a certain network or fragment of it, the best one was chosen by evaluating which of
them returned the highest performances according to the indices described in sub-section 5.1,
after learning from the random datasets, which is the one where the widest variations and
fastest dynamics of variables were considered. Even the other aforementioned amendments
(e.g. rearrangement of links, optimal discretization of the networks’ nodes etc..) were tested
through optimization of the performances indices defined in sub-section 5.1.
Figure 8. Predictive and dynamic Bayesian Network relative to temperature in PL3 (a) and predictive Bayesian Net‐
work relative to air flow changes in the station (b).
Dynamic Programming and Bayesian Inference, Concepts and Applications
22

The third step was aimed at performing further refinement using the “typical” and “likely”
datasets, which were generated through DymolaTM. Technically, that means that the EM
learning algorithm was performed by adding the information included in these two datasets
to the information already derived from the “random” dataset. This process allowed to include
more information in the networks, mainly about those scenarios which are likely to occur more
often. So it helped make the model more accurate to predict those states which are more likely
to occur.
The refinement was mainly performed in terms of tuning the subdivision into intervals of the
nodes and in terms of converting discrete variable into continuous variables, should they work
better. The steps no. 2 and 3 required many iterations of learning, refining and validating.
Each loop was characterized by either a modification of the structure or of any network’s node
and conditional dependencies. Then the modified network’s version was evaluated to define
whether the modification had to be kept (in case it decreased the errors) or had to be rejected
(in case it increased the errors), being the errors estimated as explained in section 5.1.
On the whole and just to give an example, 140 cycles were made with the TP-DBN (Tab. 1),
which was useful to reduce the error from 4.98 ° to 0.72 °C (in the RMSE case) and from 17%
to 4% (in the NRMSE case). The trend during the refinement process led to a continuous
increment of performances, as shown in Tab. 1. In addition, 82 cycles were needed to optimize
the AF-BN: for the control variable, Station Fan Power (PElSF1) RMSE fell down from 1858 W
to 377 W, whereas NRMSE fell from 10.3% down to 2.3%.
In the TP-DBN all the nodes were represented by discrete variables. In the AF-BN all the
variables were continuous except the following ones: frequencies of fans (DFreTF1_p01,
DFreTF2_p01, DFreSF1_p01) and wind direction (WiDMet_p01).
Cycle no.
TemPL3_p01
RMSE (°C)
NRMSE (%)
1
4.98
17
…
54
3.32
12
…
98
1.81
6
…
114
1.00
4
…
140
0.72
4
Table 1. Gradual improvement of performances during continuous refinement of the TP-DBN network.
Bayesian Networks for Supporting Model Based Predictive Control of Smart Buildings
http://dx.doi.org/10.5772/58470
23

Figure 9. Qualitative comparison between the real temperature plot computed by DymolaTM and forecasts by the
Bayesian Network TP-DBN.
Finally, and as fourth step, the performances of the two networks were verified also through
simulations. Fig. 9 shows the good agreement between the real temperature simulated by
DymolaTM in PL3 and the forecasted plot of PL3 as predicted by TP-DBN. The simulations
performed by the Bayesian Networks in this case were carried out according to what already
described. The input values at the first time step were instantiated as evidences taken by the
Dymola model. Then, the outputs from the networks were used as inputs for the next time
step in the networks and the simulations were iterated in the same way all over the period
shown in the diagram. It’s clear that the predictive and dynamic Bayesian network are able to
accurately model the temperature plot in PL3 and to give the right inputs to the controller, in
order to evaluate the best control policy.
5.2. The cost function
With reference to Fig. 1, the controller unit passes a candidate control policy to the BNs and
uses resulting predictions in order to compute a cost function, which must select the best
output to be used as an input in the next time step. The degrees of freedom (outputs) of the
controller for PdG-L3 station are the frequencies of the station fans (FreSF1,  FreSF2). The
predictions that the controller queries to the Bayesian Networks are the absorbed powers of
tunnel fans and station fans (PElTF1, PElTF2, PElSF1, PElSF2) and the air temperature in the
platform (TemPl3). The future outdoor temperature (TOuWS) is retrieved from a weather
forecast service and the air change in the platform (ACOPl3=amount of clean air entering the
platform) is computed as a proper combination of the air flows predicted by the BNs (derived
by the specific station topology):
ACOPl3≜AFlSFa1+ + AFlSFa2+ + AFlCN l ++
+ (AFlCNop - AFlSLb + AFlCNq)+ - | AFlSL b -| +
(22)
The objective of MPC is to minimize the following cost function with respect to station fan
frequencies:
Dynamic Programming and Bayesian Inference, Concepts and Applications
24

J =∑k=1
H αPT(
|PElTF 1(k) + PElTF 2(k)|
2PT
~
) + αPS(
|PElSF 1(k) + PElSF 2(k)|
2PS
~
)+
+αDT(
TOuWS(k) - TemPl3(k)
DT
~
)
2 + αT(
TemPl3
_
- TemPl3(k)
T
~
)
2
+
+αAC(
ACOPl3
_
- ACOPl3(k)
AC
~
)
2
+ αDF(
FreSF 1(k) - FreSF 1(k - 1)
DF
~
)
2
(23)
Subject to constraints:
ACOPl3(k)> ACOPl3Min
TemPl3(k)<TemPl3Max
FreSFMin < FreSF1(k)= FreSF2(k)< FreSFMax
The variables marked with “tilde” (~) are the normalisation coefficients that corresponds to
the typical values of the corresponding variable. At sampling time t ∈N, PElTF1(k) represents
the estimation of the value of variable PElTF1 at time t + k (k ∈N) evaluated at time t (i.e.
PElTF1(t + k |t)). The design parameters of the MPC controller are the prediction horizon H ,
the desired values denoted with bar notation TemPl3
_
, ACOPl3
_
, the weights of each single
objective in the cost function α…, and the bounds of the given constraints: ACOPl3Min,
TemPl3Max, FreSFMin, FreSFMax.
5.3. The networks and their estimates
The “soft evidence” instantiation strategy presented in section 5.2 has been implemented in a
java library that wraps HuginTM reasoning engine and allows also for other high-level func‐
tionalities, like multiple network iterations and interconnection between different networks
that shares the same variables. This library is able to get the set of variables describing the
current state of the station and to initialize with them the first network to be queried. Then, it
is able to perform probabilistic inference by running the HuginTM application and to extract
the outputs, which will be transferred to the second network to be queried according to the
procedure already shown in Fig. 7. This is done H  times, if H  is the desired prediction horizon.
The same functions has been also integrated in an excel spreadsheet for validating BNs. The
two networks were combined according to the scheme depicted in Fig. 7 and used to simulate
the predictive control. Fig. 10 shows the prediction results for one typical day (in blue), i.e.
prediction horizon H =24 hours, compared with the simulation results achievable from the
Dymola model (shown in red), regarding the main outputs: expected energy consumption by
one of the station’ fans (6a), overall airflows coming from outdoor air (6b) and future temper‐
ature (6c) plots in the platform of Line 3. In order to assess the level of accuracy of such
predictions, Table 2 shows the corresponding RMSE and NRMSE relative to the variables
Bayesian Networks for Supporting Model Based Predictive Control of Smart Buildings
http://dx.doi.org/10.5772/58470
25

plotted on Fig. 10. The agreement between the real plots and the estimated one is very good
at each prediction time, especially for the energy consumption, that is one of the key variables
influencing the cost function described in paragraph 6.2 and, as a consequence, the results of
the loop managed by the controller.
a) 
b) 
c) 
0
2500
5000
7500
10000
12500
15000
PElSF1_p01
BN
Dymola
0
2
4
6
8
10
12
14
16
18
20
22
24
26
ACOPL3_p01
BN
Dymola
10
12
14
16
18
20
TemPL3_p01
Funzione
Dymola
BN
Dymola
Figure 10. Comparison between real energy consumption of station fan PELSF1 and the estimated one by AF-BN (a),
the real air change per hour and the estimation by AF-BN (b) and comparison between the real PL3 temperature and
the estimation by TP-DBN (c).
PElSF1_p01
ACOPL3_p01
TemPL3_p01
RMSE [W]
NRMSE (%)
RMSE [kg/s]
NRMSE (%)
RMSE [°C]
NRMSE (%)
326.28
0.024784
2.24
0.097566
0.91
0.13406
Table 2. Errors obtained for the whole prediction cycle with H =24 hours in the three prediction cases shown in Fig. 10.
Dynamic Programming and Bayesian Inference, Concepts and Applications
26

6. The Passeig de Gracia simulator case study
In this section, we will report the implementation of a Bayesian Network predictor for the
environmental control of the aforementioned test-bed given by Passeig De Gracia (PdG) metro
station in Barcelona, Spain. The purpose of this section is to provide readers with an example
regarding how Bayesian Networks can be embedded within a large MPC control framework,
and how their predictions can be exploited for optimal control. The environmental control has
been based on MPC because of the great complexity of the thermal and airflow dynamics in
the underground environment, and of the time length of their characterising constants. The
metro station underground environment is mainly characterised by huge thermal inertia
caused by the terrain surrounding the station, and by relevant contributions to the indoor
temperature and pollutants levels provided by air flows. Indoor air flows are determined by
a number of sources that influence the station with different time frequencies and during
different daytimes. The outdoor wind flow, quite frequent in a coastal station like Barcelona,
affects directly the shallowest levels of the station, and determine the air pressure configuration
at the interfaces of the deepest levels that may favour or impede the mechanically air supply,
depending on their mutual disposal. The train transit causes the well-known piston effect. The
approaching trains act as pistons compressing the air into the station platform, and leaving
trains act as pulling pistons, reversing the flows. The frequency of this effect depends on the
train schedule and, in our case, can be assumed about 180 sec on the average. The train piston
effect causes relatively high-speed air transients with many local turbulences that affect also
the platform neighbouring spaces. A third relevant source of air exchange, which is usually
neglected in standard analyses, is due to the air buoyancy caused by the temperature difference
between the indoor and the outdoor environments. This effect becomes substantial during the
night, because of the absence of the other sources and of the greater temperature difference.
Buoyancy effect causes relatively slow and laminar airflows that move air form the rail tunnels
to the outside through the station’s spaces.
Within this scenario, the problem of controlling the forced ventilation in an optimal way,
through the fan speed, cannot be approached but with an MPC technology. Within the MPC
framework, the definition of the weighting coefficients of the cost function, that maximize
energy saving without compromising comfort and air quality in different operating conditions
(see section 6.2), and without affecting normal operation of the station (due to safety reasons),
required the development of a co-simulation architecture. Thus, the Bayesian predictor and
the MPC logics has been embedded in a simulation environment that accurately reproduces
the thermal and air-flow dynamics of the outdoor and indoor environments, and the trains
and passenger flows. The development of the models that contribute to the simulation
environment required in depth preliminary analysis by means of Finite Element Modelling,
and a number of on-site surveys, that became necessary to determine the magnitude of the
phenomena and to subsequently calibrate the models. Once they have been calibrated and
included in the simulation architecture, the environmental models resemble the same dynamic
of the measured environment, thus allowing for scenario analysis and control sizing.
Bayesian Networks for Supporting Model Based Predictive Control of Smart Buildings
http://dx.doi.org/10.5772/58470
27

6.1. The SEAM4US simulator
The Simulink (Mathworks©) architecture of the SEAM4US simulator is shown in Fig. 11. The
simulator is made of four main components. The PdG Environmental model, the passenger
flow simulator, the lighting control simulator and the environmental MPC.
Figure 11. The Simulink SEAM4US Simulator architecture: occupancy (green), fan frequencies (blue), dimming level of
lights (orange), measures (violet).
The PdG Model is the one developed in the Modelica language. To this aim, the Buildings
Library 1.3 [28] has been extended in order to represent physical entities and parameters of
the underground environments. At compile time the PdG environmental model results in a
matrix with tenths of thousands of unknowns. The PdG Model is interfaced with a weather
file of Barcelona that provides the hourly external weather parameters, including wind speed
and directions. The PdG Environmental Model receives as inputs the passenger occupancy
levels of each space of the station, the lighting level of the appliances in each space, and the
fan control frequencies. It then outputs all the environmental parameters, like air temperature
and humidity, the pollutants levels, and the energy consumption of the fans. These parameters
are then fed back to the control logics as the basis for the next control step. In the SEAM4US
simulator the large PdG Environmental model acts as the real station. In principle, this model
could be used in the deployed MPC system to provide the necessary and accurate predictions
of the next future in the model predictive controller. This option has revealed unpractical. The
big size of the model produces a large memory footprint and requires significant computation
Dynamic Programming and Bayesian Inference, Concepts and Applications
28

power to get reasonable and effective simulation times. This is in contrast with the model
embedding requirements, which foresees models included in relatively light computational
environment due to deployment constraints and cost reasons. Furthermore, the alignment of
the initial state of such a large model with the actual state of the station is very problematic in
terms of computational time and of the stability of the solution. Therefore, the model that
support the controller by means of predictions on the future status of the station has been
derived from the PdG environmental model through a model reduction process into Bayesian
Networks, as described in Section 6 of this Chapter.
The PdG has been used to produce a large set of control cases that have been analysed to find
out the minimum set of parameters for an effective control of the target performances. The
reduced case set has been then fed into the Bayesian Network, through EM learning algo‐
rithms, in order to get the Bayesian predictor for the MPC control shown in sub-section 5.1.
The size of this predictor is small enough and its computational time short enough to suit the
model embedding requirements. The statistical nature of the predictor avoids any problems
concerning the estimation of the initial state.
The prediction accuracy achieved by the reduced model is good enough to get a reliable control
of the station.
The passenger model simulates the passenger flows and the consequent occupancy distribu‐
tion of the spaces inside the station. It is regulated by the train schedule, by the hour of the day
– either a normal or a rush hour-and by the week day-either a weekend or a working day. The
simulator has been developed in the Modelica language and is based on the bond graph theory.
The passenger flow is simulated as a mass flow occurring among the station spaces. The mass
sources are modulated by train arrivals and hourly scheduled flow rates observed from the
outside. The model calibration has been carried out through observations (i.e. sampling
performed by means of security cameras installed in the metro station) of the flow rates of
passenger entering and exiting the trains and the station entrances at different hours of the
days. The internal flow is then regulated through mass flow delays calculated on the basis of
typical transit speeds.
Finally, the lighting control subsystems regulates the lighting level adaptively in relation to
the occupancy level of each station ambient. It implements a reactive form of control that is
driven by the visual task of each specific situation that may occur in the station ambient, either
rush hour, waiting train arrival, and so on. The outcome of the lighting simulator are the
dimming level of each appliance of the station. This of course influences the station environ‐
ment as a thermal gain and is therefore provided to the PdG environmental model input.
A noteworthy aspect of the SEAM4US simulator is its computational arrangement. In fact, it
implements a co-simulation architecture. The overall container is the Simulink system, which
provides the control clock and a fixed simulation step to all the other subsystems. The
passenger model and the lighting simulator are included in the Simulink framework as
Functional Mock-up Units (FMU) that internally include the solver, through Functional Mock-
up Interfaces (FMI). Interestingly, the FMI protocol provides the necessary interface between
the different solvers, adapting the time varying simulation steps of the FMUs with the Simulink
Bayesian Networks for Supporting Model Based Predictive Control of Smart Buildings
http://dx.doi.org/10.5772/58470
29

fixed one. The inclusion of the large PdG environmental model was not that easy. The Dymola
model did not allow exporting the solver that is uniquely able to simulate the model within
an FMU. Therefore, we have opted for a loosely coupled simulating environment, which runs
the Dymola and the Simulink in parallel and synchronize them through a DDE channel. A
wrapper of the Dymola model, which essentially implements an FMI, provides the necessary
sync and message transfer functionalities.
6.2. How the MPC controller works
The control logics implemented in the SEAM4US simulator is based on a simple particle
filtering mechanism (Fig. 12). The controller randomly generates a number of different control
options that are sent to the predictor. The predictor updates the model with the control
parameters and by means of Bayesian inference calculates the environment and energy
consumption parameters. Then the controller ranks the predictor outcomes according to a cost
function and to constraint satisfaction. The best performer is then selected and used in the next
control step. In the PdG case described in section 6.1, control options are all the driving
frequencies of the fans installed in the station and described by variables FreSF1 and FreSF2,
as explained in section 5.2. The model predictor is made of the two Bayesian Networks AF-BN
and TP-BN described in section 5.1. and depicted in Figs. 7 and 8. Once a set of outcomes (e.g.
expected energy consumption, comfort parameters etc.) is had per each value of the inputs,
the cost function in eq. (23) selects the best control strategy and sends it to the actuation system.
This value is kept constant over one hour, after which another MPC step is run by the controller
to re-adjust actuators for the next hour.
Figure 12. Flowchart showing the procedure adopted by the MPC controller for the PdG case study.
Dynamic Programming and Bayesian Inference, Concepts and Applications
30

 
 
 
(a) 
 
 
 
(b) 
-50
-30
-10
10
30
50
70
1
9
17
25
33
41
49
57
65
73
81
89
97
105
113
121
129
137
145
153
161
169
177
185
193
201
209
217
225
233
241
249
257
265
273
281
289
297
305
313
321
329
337
345
353
361
369
377
385
393
401
409
417
425
433
Bsl_FreSF1
CP0_OM1_FreSF1
CP0_OM2_FreSF1
Hz
secs
Baseline
Discrete Frequencies
Continuous Frequencies
292
294
296
298
300
302
304
1
10
19
28
37
46
55
64
73
82
91
100
109
118
127
136
145
154
163
172
181
190
199
208
217
226
235
244
253
262
271
280
289
298
307
316
325
334
343
352
361
370
379
388
397
406
415
424
433
Bsl_TemPL3
CP0_OM1_TemPL3
CP0_OM2_TemPL3
K°
secs
Baseline
Discrete Frequencies
Continuous Frequencies
Figure 13. Some plots from the simulations in search of optimal control strategies: frequency of the fans in charge of
mechanical air supply according to the control policy (top) and related air temperature plots determined by the most
meaningful control strategies (bottom).
Fig. 13 shows an example of a simulation result of three days of operation, which is relative to
the environmental control. The simulation time is represented along the x axis, while the y axis
represents the fan frequencies in Fig. 13-a. Negative frequencies means that the fan direction
is inverted (extracting air instead of supplying). Three curves are reported. The dashed curve
(Baseline) depicts the current policy used for fan control, as it is actually implemented in the
station, which we assumed as the baseline. The fan is driven at maximum speed for all the
station opening time and it is turned off during the closure time. The second dash-dot curve
represents MPC constrained to only two driving frequencies, while the third (continuous)
curve is related to a continuous frequency driving. In addition to the fact that MPC control
provides an energy saving rate that can rise up to 35%, it is noteworthy to realize why this
happens. Comparing the baseline curve with the MPC controlled, it appears that in many cases
the driving frequencies and the baseline have opposite signs. This means that in the standard
baseline driving the station fans very often are opposed to the air flow induced by the external
sources, and therefore contribute negatively to the air exchange and to the comfort parameters.
This is reflected by the temperature curves that are slightly lower – i.e. more comfortable-for
the MPC controlled environment despite the huge energy saving (Fig. 13-b). Summarizing,
Bayesian Networks for Supporting Model Based Predictive Control of Smart Buildings
http://dx.doi.org/10.5772/58470
31

these results show how the effectiveness of the MPC control of complex environment relies on
the power and on the flexibility of the Bayesian predictor and of the Bayesian Inference
paradigm.
7. Conclusions
In this Chapter we have shown that the role of Bayesian predictors may be critical in order to
implement predictive control of buildings. This kind of control is one of the most effective ones
currently being developed by researchers, because it is able to smooth control actions and to
trigger them in advance. However, it cannot be applied without a reliable predictor of the
expected state of the controlled domain. Such a predictor must be queried in real-time, which
is feasible just in case a reasonable computational effort is required.
In other words, computationally demanding software programs cannot be used to produce
predictions at run time, but they can be run to generate datasets and these datasets may be
used to transfer knowledge into Bayesian Networks. At this juncture, Bayesian inference may
be performed: in fact, inputs by the controller (i.e. input variables describing the current state
of the domain plus candidate arrays of control values) are instantiated in Bayesian Networks
in the form of a set of evidences; then, inference algorithms are propagated and expected future
values describing the energy and thermal state of the domain might be estimated. This
procedure can be repeated thousands of times at each control step and it makes the imple‐
mentation of MPC feasible.
When implemented in a real case, the results from inferences were shown to be very accurate
with low deviations from the values estimated by means of more complex numerical models.
In addition, our testing of the use predictive Bayesian Networks embedded in a wider MPC
framework to support the ranking of concurrent control policies was successful, too. So
Bayesian Networks proved to be able to solve the problem of reducing complex models into
more manageable tools for performing cumbersome inferences through limited computational
efforts, while getting highly accurate results.
8. List of notations
Nomenclature
Meaning
General
BN
Bayesian Network
DBN
Dynamic Bayesian Network
TP-DBN
Temperature Prediction Dynamic Bayesian Network
AF-BN
Air Flow Prediction Bayesian Network
Dynamic Programming and Bayesian Inference, Concepts and Applications
32

MPC
Model based Predictive Control
PdG-L3
Passeig de Gracia – Line 3 station
BEMS
Building Energy Management System
HVAC
Heat, Ventilation, Air conditioning and Cooling
Section 2
y,  y^
Outputs of the controlled building and their predictions respectively
u,  u^
Inputs of the controlled building and their predictions respectively
d,  d^
Disturbances and their predictions respectively
m
Measures from building’s sensor network
Section 3
P(x)
Prior probability
X, Y, Z
Random events or prepositions
M y|x
Conditional probability matrix
P(yi | xi)
Any entry of the conditional probability matrix
ξ
Evidence observed before estimating future values of random variables
BEL (x)
Overall belief accorded to proposition X=x by all evidence so far received by ξ
λ(x)
Likelihood vector
β
1/P(ξ)
U
Domain to be modelled
Bs
Bayesian Network structure ordering a set of variables in domain U
n
Number of variables in Bs
D
Random sample
Ci
Any record of a random sample
Πi
Any set of variables in Bs which are parents of Xi
qi
Number of states of Πi
ri
Number of states of x
 ijk
Physical probability that any variable Xi in a Bs will come out with one of its states k, given
its joint set of parents are in state j
c
Normalization constant in a gamma function
N
Multinomial parameter in a gamma function
Sub-section 4.1
X^
i
Predicted value of any random variable Xi
Xmax
Maximum value of variable Xi
Bayesian Networks for Supporting Model Based Predictive Control of Smart Buildings
http://dx.doi.org/10.5772/58470
33

Xmin
Minimum value of variable Xi
K
Number of samples in a validation data set
Ei
Prediction error at time i
AEi
Absolute error at time i
SEi
Squared error at time i
PEi
Percentage error at time i
MAE
Mean Absolute Error
RMSE
Root Mean Square Error
NMAE
Normalized Mean Absolute Error
NRMSE
Normalized Root Mean Square Error
CVRMSE
Coefficient of Variation of the Root Mean Square Error
NMBE
Normalized Mean Bias Error
Sub-section 4.2
N (μ; σ)
Normal distribution with mean μand standard deviation σ
N(μ
_
; σ
_)
Desired distribution with mean value μ
_
 and standard deviation σ
_
x0, x1, … , xL
L + 1bounds of the L intervals of a Interval Discrete Chance node of a BN
f (x)
Probability density function (pdf) of a random variable X
Φ(x)
Cumulative distribution function (cdf) of a random variable X
σmin
Standard deviation equals to half the interval in which a desired μ
_
 falls
qi
', qi
Probability of interval iof a non-periodic discrete node (not normalized and normalized
respectively)
pi
', pi
Probability of interval iof a periodic discrete node (not normalized and normalized,
respectively)
Sub-section 5.1
ACOPL3
Air changes per hour
AFlCNl, AFlCNop, AFlCNq,
AFlSlb
Air flows in station’s rooms named as CNl, CNop, CNq, Slb
AFlT31, AFlT32, AFlSF1,
AFlSF2
Air flows in tunnels TF1 and TF2 and in station fan ducts SF1 and SF2
WiSMet
Outdoor wind speed
WiDMet
Outdoor wind direction
FreSF1, FreSF2, FreTF1,
FreTF2
Frequencies that drive the two fans in the station and the two fans in the tunnels,
respectively
Dynamic Programming and Bayesian Inference, Concepts and Applications
34

DFreSF1, DFreSF2, DFreTF1,
DFreTF2
Discretized frequencies that drive the two fans in the station and the two fans in the
tunnels, respectively
PElSF1, PElSF2, PElTF1,
PElTF2
Electric power absorbed by the two fans in the station and the two fans in the tunnels,
respectively
TOuMet
Outdoor temperature
GaiTr1
Internal gain supplied by trains approaching on railway 1
NPeSta
Number of people in the station
TemPL3
Temperature in platform PL3
DTePL3
Variation of temperature in platform PL3
DTeOut
Variation of outdoor temperature
HFlOut
Heat flux coming from outdoor air
X_p01
Denotes one step ahead value for a variable X
Sub-section 5.2
J
Cost function to be minimized by MPC
H
Prediction horizon
XMin,  XMax
Minimum and maximum values allowed for a certain variable X
X
_
Desired reference value for a certain variable X
X
~
Normalisation factor for a certain variable X
α
Weights of terms in cost function
X +, X -
Function that gets the absolute value of the positive and negative values of variableX,
respectively
Acknowledgements
This work is part of the EU-funded research SEAM4US. Also, we are very grateful to our
colleagues Engs. Roberta Ansuini and Sara Ruffini, who helped us develop the models.
Author details
Alessandro Carbonari*, Massimo Vaccarini and Alberto Giretti
*Address all correspondence to: alessandro.carbonari@univpm.it
Università Politecnica delle Marche, Department of Civil and Building Engineering and Ar‐
chitecture, Via Brecce Bianche, Ancona, Italy
Bayesian Networks for Supporting Model Based Predictive Control of Smart Buildings
http://dx.doi.org/10.5772/58470
35

References
[1] Pearl J. Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Infer‐
ence, 2nd ed. Morgan Kaufmann Publishers, San Mateo, California; 1998.
[2] Levermore G.J. Building Energy Management Systems: Applications to Low-energy
HVAC and Natural Ventilation Control, E & FN Spon, 2000.
[3] Di Hermann M., Hansemann T., Hơbner C. Building Automation: Communication
systems with EIB/KNX, LON and BACnet, Springer, NY; 2009.
[4] DALI Manual, available on-line at: http://www.dali-ag.org/c/manual_gb.pdf.
[5] Daum D., Morel. N. Assessing the total energy impact of manual and optimized
blind control in combination with different lighting schedules in a building simula‐
tion environment. Journal of Building Performance Simulation, 3(1), p. 1-16, 2010.
[6] Oldewurtel F., Gyalistras D., Gwerder M., Jones C., Parisio A. Increasing energy effi‐
ciency in building climate control using weather forecasts and model predictive con‐
trol. In: Clima-RHEVA World Congress Proceedings, Antalya, Turkey, 2010.
[7] Oldewurtel F., Parisio A., Jones C., Morari M., D. Gyalistras D. Energy Efficient
Building Climate Control using Stochastic Model Predictive Control and Weather
Predictions. In: Proceedings of the American Control Conference, Baltimore, MD,
2010.
[8] Mahdavi A., Orehounig K., Pröglhöf C.A simulation-supported control scheme for
natural ventilation in buildings. In: Proc. of the 11th IBPSA Conference, Glasgow,
Scotland; 2009.
[9] Henze G., Kalz D. Experimental analysis of model-based predictive optimal control
foractive and passive thermal storage inventory, HVAC&R, 11(2); 2005; p. 189-213.
[10] Coffey B., Haghighat F. A software framework for model predictive control with
GenOpt, Energy and Buildings. 42; 2010; p.1084-1092.
[11] Clarke J. A. et al. Control in Building Energy Management Systems: The Role of Sim‐
ulation, In: Proccedings of the Seventh International IBPSA Conference, Rio de Ja‐
neiro, Brazil August 13-15; 2001.
[12] Maciejowsli J. M. Predictive Control with Constraints, Prentice Hall, England; 2002.
[13] Wetter, M. A Modelica-based model library for building energy and control systems.
In: Proc. of the 11th IBPSA Conf., Glasgow, Scotland; 2009.
[14] Wetter M. Modelica Library for Building Energy and Control Systems: Buildings
1.0_build2; 2001. (accessed on: Dec 09, 2011), available on-line at: https://
www.modelica.org/libraries/Buildings/releases/1.0_build2
Dynamic Programming and Bayesian Inference, Concepts and Applications
36

[15] McGraw-Hill, editor. Concise Encyclopedia of Engineering. The McGraw-Hill Com‐
panies, Inc.; 2002.
[16] Qin S.J., Badgwell T.A. A survey of industrial model predictive control technology.
Con. Eng. Practice 2003; 11(7) 733-764; Elsevier.
[17] Gyalistras D., Gwerder M., Oldewurtel F., Jones C.N., Morari M., Lehmann B., Wirth
K., Stauch V. Analysis of Energy Savings Potentials for Integrated Room Automa‐
tion, 2010. Clima-RHEVA World Congress, Antalya, Turkey, May 2010.
[18] Gyalistras D., Gwerder, M. Use of weather and occupancy forecasts for optimal
building climate control (OptiControl): Two years progress report. Terrestrial Sys‐
tems Ecology ETH Zurich, 2010. Switzerland and Building Technologies Division,
Siemens Switzerland Ltd., Zug, Switzerland.
[19] Lehmann B., Wirth K., Carl S. Modeling of buildings and building systems. In: Pro‐
ceedings of the 10th REHVA World Congress Clima 2010, 9-12 May 2010, Antalya,
Turkey.
[20] Rodney A. Brooks The intelligent room project: The Second International Cognitive
Technology Conference, pp. 271-279; 1997.
[21] Korb K.B., Nicholson A.E. Bayesian Artificial Intelligence. Chapman & Hall/CRC Ed‐
ition; 2004.
[22] Spiegelhalter D.J., Dawid A.P., Lauritzen S.L., Cowell R.G. Bayesian analysis in ex‐
pert systems. Statistical Science 1993; 8(3), 219–283.
[23] Heckerman D., Bayesian Networks for Knowledge Discovery (Chapter 11), in
Fayyad U.M., Piatetsky-Shapiro G., Smyth P., Uthurusamy R. Advances in Knowl‐
edge Discovery and Data Mining. MIT Press, Menlo Park/Cambridge/London; 1996.
[24] A.S.H.R.A.E. Guideline 14-2002. Measurement of Energy and Demand Savings.
American Society of Heating, Ventilating and Air Conditioning Engineers, Atlanta,
Georgia; 2002.
[25] Lazar M., Heemels W. P. M. H., Bemporad A., Weiland, S. Discrete-time non-smooth
nonlinear MPC: Stability and robustness. In: Assessment and Future Directions of
Nonlinear Model Predictive Control. Springer Berlin Heidelberg; 2007. p. 93-103.
[26] Aludaat, K. M., Alodat. M.T. A note on approximating the normal distribution func‐
tion. Applied Mathematical Sciences. 2(9); 2008; p. 425-429.
[27] Mattsson S.E., Elmqvist. H. Modelica – An international effort to design the next gen‐
eration modeling language. In: Boullart L., Loccufier M., Sven Erik Mattsson (edi‐
tors). 7th IFAC Symposium on Computer Aided Control Systems Design, Gent,
Belgium, April 1997.
Bayesian Networks for Supporting Model Based Predictive Control of Smart Buildings
http://dx.doi.org/10.5772/58470
37

[28] Wetter M. Modelica Library for Building Energy and Control Systems: Buildings
1.0_build2 (Dec 09, 2011), available at https://www.modelica.org/libraries/Buildings/
releases/1.0_build2.
[29] Lawrence Hubert, Hans-Friedrich Köhn, Douglas Steinley. Cluster Analysis: A Tool‐
box for MATLAB. In: Roger E. Millsap, A. MaydeuOlivares. The SAGE Handbook of
Quantitative Methods in Psychology. SAGE Publications Ltd; 2009. ISBN:
9781412930918.
[30] Ansuini R., Vaccarini M., Giretti A., Ruffini S. Models for the real-time control of sub‐
way stations. Proceedings. of: BS2013, Building Simulation for a Sustainable World,
13th International Conference of the International Building Performance Simulation
Association, Chambery (F), August 2013.
Dynamic Programming and Bayesian Inference, Concepts and Applications
38

Chapter 2
Integration of Remotely Sensed Images and
Electromagnetic Models into a Bayesian Approach for
Soil Moisture Content Retrieval: Methodology and
Effect of Prior Information
Claudia Notarnicola and Romina Solorza
Additional information is available at the end of the chapter
http://dx.doi.org/10.5772/57562
1. Introduction
Remote sensing technologies in the microwave domain have shown the capability to detect
and monitor changes related to Earth’s surface variables, independently of weather conditions
and sunlight.
Among these variables, soil moisture (SM) is one of the most requested ones [1]. This envi‐
ronmental variable is considered important to many ecological processes that occur on Earth's
surface, from its relationship to climate events to its importance in terms of water availability
for agricultural crops. In fact, it is considered an essential climate variable domain for the
Global Earth Observation Climate (GCOS) [2]
At large scale, this biophysical variable is involved in weather and climate, influencing the
rates of evaporation and transpiration. At medium-scale it influences hydrological processes
such as runoff generation, erosion processes and mass movements and from the agriculture
point of view determines the crops growth and irrigation needs. At small or micro-scale it has
an impact on soil biogeochemical processes and water quality [3].
The ability to estimate soil moisture from satellites or airborne sensors is very attractive,
especially in recent decades where the development of these technologies has taken a signifi‐
cant rise. This has led the possibility to have images with different spatial scales and repetition
time. Despite numerous studies of moisture estimation have been developed using optical
imaging, the most promising results have been obtained by using images from microwave
sensors [1,4,5,6].

Satellite and aircraft remote sensing allow estimating soil moisture at large-scale, modeling
the interactions between land and atmosphere, helping to model weather and climate with
high accuracy [7]. In the last years many different approaches have been developed to retrieve
surface soil moisture content from SAR sensors [1].
The estimation of soil moisture from SAR sensors is considered as an ill-posed problem,
because many factors can contribute to the signal sensor response. The backscattering signal
depends greatly on the moisture content, directly related to the dielectric constant of the soil
(ε) and other factors such as soil texture, surface roughness and vegetation cover, being the
latter the factors that may hinder a correct estimation of soil moisture [1].
Several studies have shown that soil moisture can be estimated from a variety of remote sensing
techniques. However, only microwaves have the capability to quantitatively measure soil
moisture under a variety of topography and vegetation [8]. The microwave remote sensing
has demonstrated the ability to map and monitor relative changes in soil moisture over large
areas, as well as the opportunity to measure, through inverse models, absolute values of soil
moisture [1].
The sensitivity of SM in the microwave frequency is a well-known phenomenon, although it
is still being studied by many research groups. Early researches conducted on the subject
[9,10,11], among others, have shown that the sensors which operate at low frequencies of the
electromagnetic spectrum, such as P or L band are capable of measuring soil moisture and
overcome the influence of vegetation.
Currently most SAR systems on board of satellites (RADARSAT-2, COSMO-SkyMed, and
TerraSAR-X) operate at C-and X-band, which are not the most suitable for the estimation of
SM content. Some preliminary studies indicate the feasibility to estimate SM using this type
of sensor, and specifically the new generation of X-band sensor [12]. However, working at such
high frequencies involves dealing with interference effects introduced by the surface rough‐
ness, and especially vegetation coverage as part of the backscatter signal. Therefore, under
these operating conditions, an estimate of the SM spatial variations is still a challenge.
Figure 1 shows the electromagnetic spectrum in the microwave region ordered according to
the variable wavelength (in cm) and frequency (in GHz). In the same figure it is possible to
have an overview of the major satellite missions, past, present and future, whose data have
been used in numerous studies or can be used in the future to estimate SM.
The possibility of having multiple radar configurations was made possible thanks to the
Envisat satellite launched by the European Space Agency (ESA) and its Advanced SAR (ASAR)
sensor, operating in C-band [1]. Envisat/ASAR offered, unlike his predecessors, a great
capacity in terms of coverage, incidence angles, polarizations and modes of operation, giving
a great potential to improve the quality of many applications using SAR data.
Unfortunately, there are no current satellite missions in L band. ALOS, the satellite of Japan
Aerospace Exploration Agency (JAXA), with PALSAR microwave sensor does not work since
May 2011. At C-band, there is available data only from RADARSAT-2 of the Canadian Space
Agency (CSA), because ERS-2 and Envisat from ESA stopped working in September 2011 and
Dynamic Programming and Bayesian Inference, Concepts and Applications
40

April 2012, respectively. For the future nearby, there are expected data from planned L-band
missions, such as Argentinian 1A and 1B SAOCOM, whose first launch is expected between
2014-2015; ALOS-2, which is expected to be launched in 2014. Also the SMAP active/passive
satellite from the National Aeronautics and Space Administration (NASA), expected for end
2015, is very promising. SMAP will use high-resolution radar observations to disaggregate
coarse resolution radiometer observations to produce SM products at 3 km resolution. The SM
has been retrieved from radiometer data successfully using various sensors and platforms and
these retrieval algorithms have an established heritage [7].
The most valuable information for the study of the SM has been obtained through the combi‐
nation of different frequencies, polarizations and angles of incidence, as demonstrated in [11,
13,14,15]. The backscatter coefficient is highly sensitive to the micro roughness of the surface
and vegetation coverage. These studies have been developed to determine the configuration
of "optimal" sensor parameters, in terms of wavelength, frequency, polarization and angle of
incidence to reduce interference of these factors when making an accurate estimate of SM.
In reference to specific studies, Holah et al. (2005) [16] found that an accurate estimate of SM
can be achieved by using low or moderate (between 20° and 37°) incidence angles. Regarding
polarizations, the most sensitive to SM are found to be HH and HV polarization while the less
sensitive is VV. Li et al. (2004) [17] and Zhang et al. (2008) [18] found similar results. Further‐
more Autret et al. (1989) [19] and Chen et al. (1995) [20] reported that the influence of surface
roughness can be minimized by using co-polarized waves (HH/VV). Therefore, using multiple
Figure 1. Main satellite missions (past, recent and future) designed in the microwave region of the electromagnetic
spectrum (based on Richards, 2009).
Integration of Remotely Sensed Images and Electromagnetic Models into a Bayesian Approach for…
http://dx.doi.org/10.5772/57562
41

polarizations should, in theory, improve the SM estimate. The general consensus of the
literature indicates that low incidence angles, long wavelengths (such as L-band) and both HH
and HV polarization settings are the most appropriate sensor for an accurate SM estimate [1].
Another effective approach to mitigate the ambiguity introduced by the vegetation and
roughness is to focus attention on the temporal variations through time series of radar images.
In this case the basis is to assume that the average roughness characteristics and vegetation
remain almost unaltered while variations in moisture content affect backscatter signal along
the time [21, 22]. In this regard, methods have been developed using change detection series,
as in the recent study [23] Hornacek et al. (2012) used data from the wide swath Envisat/ASAR
acquisition mode as part of an evaluation of the potential of algorithms for estimating SM for
Sentinel-1 mission of ESA.
In remote sensing, researchers have to deal with two problems: the direct problem and the
inverse problem. The direct problem refers to the development of electromagnetic models that
can correctly characterize ground backscatter coefficient by using as input the sensor param‐
eters, such as the angle of incidence (θi), the wavelength (λ) and a specified polarization
configuration, as well as soil parameters, such as dielectric constant and roughness.
These models provide a solid physical description of the interactions between the electromag‐
netic waves and the objects on the Earth's surface (e.g., bare soil or vegetation), allowing to
simulate numerous experimental settings in terms of sensor configurations and soil charac‐
teristics. The generality of models is a property essential to avoid dependence on local site
conditions and characteristics of the sensor, a situation that often occurs when working with
evidence-based algorithms.
Once the models have been validated, it is possible to develop algorithms to invert these
models and predict soil surface properties using radar observations as inputs, which is the
solution to the inverse problem [24,25,26].
Numerous backscattering models have been developed in recent decades to help determine
the relationship between the measured signal at the sensor and biophysical parameters, with
particular emphasis on understanding the effects of surface roughness [11, 25, 27]. Considering
the inversion of the direct models many approaches have been developed through numerical
simulations of forward models which include Look Up Tables, Neural Networks, Bayesian
approaches, and minimization techniques.
For example, the potential of some of these approaches to provide accurate maps of SM has
been investigated by Pampaloni et al. (2004) [28]. They conducted a performance comparison
of the three inversion algorithms using time series of Envisat ASAR cross-and co-polarized
images on a farm site in Italy. The algorithms evaluated for accuracy, error rate and compu‐
tational complexity were: multilayer perceptron neural network, a statistical approach based
on the Bayesian theorem and iterative optimization algorithm based on the Nelder-Mead
method.
Among the different methods, the Bayesian approach has been deeply investigated for its
capability to provide an evaluation of the uncertainties on the variable estimates as well as the
possibility to create hierarchical models with different sources of information [11, 21, 29, 30].
Dynamic Programming and Bayesian Inference, Concepts and Applications
42

The objective of this research is to examine the capability and accuracy of a Bayesian approach
to retrieve surface SM setting different roughness and vegetation conditions in view of an
operational use of the algorithm. Several implementations of the main algorithm were
designed to evaluate their different capabilities to reproduce the ground reference data. In
most cases, these approaches are based on the assumption of predefined behavior of some
parameters, such as vegetation and roughness, measured in situ, and then used as conditional
probabilities.
The developed method has been applied to two main test sites, one located in Argentina and
the second in Iowa and exploited during the SMEX´02 campaigns. The comparison over two
test sites is useful to have confirmation on the behavior of the developed algorithms.
The SMEX’02 test site was one of the first exploited to test the proposed methodology that was
later extended to the Argentina test site.
For this reason larger space is given in this chapter to the Argentinean test site, where SM is
being deeply studied because of the near future launch of the first SAOCOM satellite. In fact,
there is a particular demand of SM maps from agricultural farmers of the Pampa region for
monitoring the crop status, possible evaluation of water demand and yield assessment.
2. Remote sensing data and study areas
The proposed analysis is applied to two main datasets. The first dataset derives from an
experiment carried out in Argentina in view of the SAOCOM mission. The second one is
located in the USA and acquired during the SMEX’02 experiments where contemporary to
SAR acquisitions intensively field campaigns were carried out.
2.1. Argentinean study area
The procedure adopted here was applied to data from SARAT L Band active sensor. The
SARAT SAR is an airborne sensor (figure 2) used to simulate the SAOCOM images to be
analyzed in feasibility studies. The SAR Airborne instrument works in L band (λ=23cm) and
is fully polarimetric.
The data set consists of field soil moisture content measurements with the corresponding
backscattering coefficients at HH, HV, VH and VV polarizations and 25° incidence angle
acquired with a L-band SARAT sensor. SARAT project includes an airborne sensor and an
experimental agricultural site. It is part of the SAOCOM mission of Argentinean Space Agency
(CONAE). The main aim of the SARAT project is to provide full polarimetric SAR images to
develop and validate different applications before the launch of the first satellite SAOCOM,
the SAOCOM 1A, estimated for the year 2014. The SAR instrument is installed on a Beechcraft
Super King Air B-200 from the Fueza Aérea Argentina (FAA) which has a nominal range of
flight altitudes between 4000 and 6000 meters above the Earth's surface, resulting in the
formation of images with angles of incidence between 20° and 70°.
Integration of Remotely Sensed Images and Electromagnetic Models into a Bayesian Approach for…
http://dx.doi.org/10.5772/57562
43

Figure 2. SARAT instrument and Aircraft of the FAA.
This SAR system has the same characteristics of the upcoming SAOCOM. These characteristics
are described on Table 1.
Central frequency
1.3 GHz (L band)
Chirp bandwidth
39.8 MHz
Pulse duration
10 μm
Pulse Repetition Frequency
250 Hz
Swath
9 km (nominal to 4200 m of height)
Azimuth resolution
1.2 m (nominal)
Slant Range resolution
5.5 m
Spatial resolution
6 m (nominal)
Polarization
Quad-Pol (HH, HV, VH y VV)
Incidence angle
20° - 70° (nominal to 4200 m of height)
Dynamic Range
45 dB
PSLR
-25 dB
Noise equivalent σ0
-36.9 dB
Table 1. Technical characteristics of the SARAT sensor.
SARAT project also includes a validation sites in agricultural areas. For this study, an area
inside the CETT (Teófilo Tabanera Space Center of CONAE) located in Cordoba province,
Dynamic Programming and Bayesian Inference, Concepts and Applications
44

Argentina, was selected. Its central geographic coordinates are 31°31'15.08''S-64°27'16.32''W.
Figure 3 shows the location of the test site.
Figure 3. Location of the test site at Conae, in Argentina.
The experimental site, chosen for SM, vegetation and surface roughness measurements, has
10 fields with dimension of 50 m x 120 m which contain different kinds of crop and bare soil,
as depicted in Fig. 4. All fields were intensively sampled during the SARAT acquisitions.
Plots with crops contain soybean, sunflower, corn and wheat crops. Figure 5 depicts crops
stage at the moment of the SARAT acquisition time.
Some plots were left without vegetation to better investigate the interaction of microwave
signal with roughness surfaces. The bare soil plots (1N, 2N, 1S and 2S) were ploughed with
two roughness levels (low and high roughness) to evaluate the roughness impact on soil
moisture retrieval at plot level, as shown in Fig. 6.
The roughness parameters, namely standard deviation of heights, s, and correlation length, l,
were calculated as indicated in [31]. These parameters are listed in Table 2.
The SARAT images for this study (resolution: 9 m ground range) were acquired on February
2012 and all the data was provided by CONAE. Soil moisture varied between 4% and 40%,
even though most plots showed medium-dry conditions.
Integration of Remotely Sensed Images and Electromagnetic Models into a Bayesian Approach for…
http://dx.doi.org/10.5772/57562
45

Figure 4. Detail of the sampled plots during SARAT campaign acquisitions. N and S indicate North and South test
fields.
Figure 5. Soybeans, wheat (winter development), corn and sunflower.
Figure 6. Bare plot with induced low (left) and high roughness (right).
Dynamic Programming and Bayesian Inference, Concepts and Applications
46

Parameter
Symbol
High roughness value
Low roughness value
Rms height
s
3.22 cm
1.55 cm
Correlation length
l
8.17 cm
5.03 cm
Table 2. Mean roughness values inside the bare soil plots.
2.2. Iowa study area in the SMEX’02 experiment
SMEX’02 is a remote sensing experiment that was carried out in Iowa in 2002. The main site,
chosen for soil moisture, vegetation and surface roughness measurements, was the Walnut
Creek watershed, where 32 fields, 10 soybean and 21 corn fields, were sampled intensively [32].
The field and sensor data acquired during this experiment are particularly suitable thanks to
the significant number of surveyed fields and wide range of soil conditions. The AirSAR
images (resolution: 8-12 m ground range) were acquired on 1, 5, 7, 8, 9 July 2002. The five P-,
L-and C-band images were processed by the AirSAR operational processor providing
calibrated data sets.
3. Description of the methodology for SM estimation
The retrieval algorithm for SM is based on a Bayesian approach. Bayesian data analysis
determines methods to make inference from data by using probabilities models for quantities.
The main characteristic of Bayesian methods is the explicit use of probability for quantifying
uncertainty in inference based on statistical data analysis.
The process of Bayesian data analysis consists of three main steps:
• Definition of a joint probability model for all variables under evaluation;
• Calculate the posterior distribution which provides information on the unobserved
quantities, given the observed data;
• Evaluation of the fit model.
Prior distributions can express our knowledge and uncertainty about the target variable. In
this case the target variable could be thought as a random realization from the prior distribu‐
tion.
The application of Bayesian approach implies passing from a prior distribution to a posterior
distribution. Based on this concept, a relationship is expected between these two distributions
[29, 30, 33]. A general feature of Bayesian inference is that the posterior distribution is centered
at a point which represents a compromise between the prior information and the data. This
compromise is strongly controlled by the data as the sample size increase.
A prior distribution may not have a population basis and for this reason it is desirable to
have a prior which plays a minor role in the posterior distributions. These prior distribu‐
Integration of Remotely Sensed Images and Electromagnetic Models into a Bayesian Approach for…
http://dx.doi.org/10.5772/57562
47

tions are considered as flat, diffuse or non-informative. The rational to use such types of
distributions is to let the inference being not affected by external information and based
exclusively on data [34].
The proposed Bayesian approach is driven by both experimental data and theoretical electro‐
magnetic models. The theoretical electromagnetic model has the main aim to simulate the
sensor response by considering the characteristics of the soil and vegetation surface.
In order to have a better understanding of the proposed methodology, described in section
3.2, a brief description of the electromagnetic models is presented in the next section.
3.1. Electromagnetic modeling
The development of physical or theoretical models simulating direct backscatter coefficients
in terms of soil attributes as dielectric constant and the surface roughness for an area of known
characteristics is one of the most common approaches for SM estimation (Barrett et al., 2009).
Electromagnetic models allow a direct relationship between the surface parameters and the
backscattered radiation and are useful for understanding the sensitivity of the radar response
to changes in these biophysical variables.
Despite its complexity, only theoretical models can produce a meaningful understanding of
the interaction between electromagnetic waves and the Earth's surface. However, exact
solutions of the equations that govern the rough surface scattering are not yet available and
various approach methods have been developed with different ranges of validity [10]. The
standard backscatter models are known as Kirchhoff Approximation (KA), which includes the
Geometrical Optics Model (GOM), the Physical Optics Model (POM) and the Small Perturba‐
tion Model (SPM). These models can be applied to specific conditions of roughness in relation
to the sensor wavelength. For example, GOM is considered for very rough surfaces, POM
middle roughness surfaces and SPM smooth surfaces.
The  Integral  Equation  Model  (IEM),  based  on  the  radiative  transfer  model,  has  been
developed by Fung and Chen in 1992 [27]. The model unifies the KA and the SPM model,
a condition that makes it applicable to a wide range of roughness conditions. The IEM
requires, as inputs, sensor parameters such as polarization, frequency and incidence angle,
and target parameters such as the real part of the dielectric constant, the RMS height, s,
and the correlation length, l [27].
For the IEM model, the like polarized backscattering coefficients for surfaces are expressed by
this formula:
2
0
2 2
1
( 2k ,0)
exp(
2k
)
,
2
(n)
n
x
pp
z
pp
k=
W
k
σ
=
s
I
n!
¥
-
-
å
(1)
where k is the wave number, θ is the incidence angle, kz=kcosθ, kx=ksenθ and pp refers to the
horizontal (HH) or vertical (VV) polarization state and s is the standard deviation of terrain
Dynamic Programming and Bayesian Inference, Concepts and Applications
48

heights. The term I pp
n  depends on these parameters, k, s and on RH, RV, the Fresnel reflection
coefficients in horizontal and vertical polarizations. The Fresnel coefficients are strictly
related to the incidence angle and the dielectric constant. The symbol W (-2kx,0) is the Fourier
transform  of  the  nth  power  of  the  surface  correlation  coefficient.  For  this  analysis,  an
exponential  correlation  function  has  been  adopted  that  seems  to  better  describe  the
properties of natural surfaces [27].
For vegetated soils, the simple approach, based on the so-called Water Cloud Model (WCM),
developed by [35] has been considered in this analysis. In this radiative transfer model, the
vegetation canopy as a uniform cloud whose spherical droplets are held in place structurally
by dry matter. The WCM represents the power backscattered by the whole canopy σ0 as the
incoherent sum of the contribution of the vegetation σ0
veg and the contribution of the under‐
lying soil σ0
soil, which is attenuated by the vegetation layer through the vegetation transmis‐
sivity parameters τ2. For a given incidence angle the backscatter coefficient is represented by
the following expression:
0
0
2
0 .
veg
soil
σ = σ
σ
t
+
(2)
If the terms related to vegetation and incidence angle are explicitly written in more detailed
way, the backscattering coefficients become:
0
0
cos
(1
exp( 2
/ cos ))
exp( 2
/ cos ),
E
soil
σ = A VWC
B VWC
σ
B VWC
q
q
q
×
×
-
- ×
×
+
×
- ×
×
(3)
where VWC is the vegetation water content (kg/m2), θ the incidence angle, σ0
soil represents the
backscattering coefficient of bare soil that in this case calculated by using the IEM model, τ2 is
the two-way vegetation transmissivity with τ2=exp(-2B VWC/ cosθ). The parameters A, B and
E depend on the canopy type and require an initial calibration phase where they have to be
found in dependence of the canopy type and with the use of ground data.
In this work the model simulation enters directly in the inversion procedure. For the Bayesian
approach, the simulated data are generated in order to compare them to the measured data
and to create the noise probability density function (PDF) as detailed in the section devoted to
this approach. For this reason, it is needed to perform a preliminary validation of the proposed
model as their simulation enters directly the inversion procedure.
Calibration constant values of the WCM, namely A, B and E were taken initially from literature
to take into account the effect of vegetation on the SAR signal [36]. Subsequently through a
Maximum Likelihood approach they were determined to fit the data used in this work from
both test sites. The application of calibration equations considers two different kind of
vegetation, with respect to the sensor response: very dense vegetation (as corn and sunflower)
and less dense vegetation (soybean and grass). This step includes the NDVI calculation from
some SPOT and LANDSAT optical images for the Argentinean and SMEX’02 test site respec‐
Integration of Remotely Sensed Images and Electromagnetic Models into a Bayesian Approach for…
http://dx.doi.org/10.5772/57562
49

tively acquired close in time to the SAR image. Then the NDVI values were transformed in
VWC through empirical approach defined by Jackson et al, 2004 [37].
The free parameters are illustrated in table 3, where also the RMSE of the difference between
measured and simulated backscattering coefficients are reported. Figure 7 depicts the com‐
parison between simulated and measured backscattering coefficients.
Model
A
B
E
RMSE
Soya
0.00119
0.03
0.634
1.7 dB
Corn
0.2
0.003
2.2
2.6 dB
Table 3. Calibration parameters for simulation of L band backscattering coefficients with the Water Cloud Model with
distinction between soybean and corn types.
3.2. Bayesian approach for SM estimation
The objective of this research is to examine the capability and accuracy of a Bayesian approach
to retrieve surface soil moisture under different assumptions for prior information on rough‐
ness and vegetation conditions in view of an operational use of the algorithm.
In the Bayesian approach, the scope is to infer biophysical parameters (e.g. soil moisture), from
a set of backscattering responses measured by the sensor. The proposed algorithm is based on
experimental data and theoretical models. The problem of having a few amounts of experi‐
mental data to build a reliable PDF has been overcome by the use of the simulated data from
theoretical models. The Integral Equation Model (IEM) [27] was selected because it has the
advantage of being applicable to a wide range of roughness scales. The general condition of
validity of the model is ks < 3, where k is the wave number (≈ 0.2732 cm−1 for 1.3 GHz).
Figure 7. Comparison of measured backscattering coefficients (dots) with simulation from Water Cloud Model (surfa‐
ces) after the proper calibration of the free parameters. Two simulated surfaces are reported, one for corn (the red
one) and the other soybean (the blue one).
Dynamic Programming and Bayesian Inference, Concepts and Applications
50

For bare soil, these unknown parameters are the real part of the dielectric constant (ε), the
standard deviation of the height (s) and the correlation length (l), the latter two describing the
morphology of the surface. For vegetated fields, the Bayesian inversion was performed under
two different approaches. In one case the Water Cloud Model (WCM) [35] is used to simulate
the backscattering coefficients from vegetation. In the second case, the PDF parameters are
properly modified to take into account vegetation effect through empirical relation with
vegetation [38]. In both cases, the Vegetation Water Content (VWC) is added as unknown
parameter, and it is derived from optical images. In this way, the approach exploits a synergy
between SAR and optical images.
At the beginning, the conditional probability is assumed as normal distribution. In the training
phase, the conditional PDF is evaluated using measured data (fim) and simulated values from
the IEM model (fith). The distribution assumption is then verified with a chi-squared statistics.
The noise function Nl (eq. 4) and the related PDF parameters (mean and standard deviation)
are calculated from the statistics of the ration between measured and simulated backscattering
coefficients as follows [11, 39]:
.
im
i
ith
f
N
f
=
(4)
Subsequently a joint PDF is obtained as a convolution of single independent PDFs. The joint
PDF is a posterior probability derived from prior probability on roughness and soil moisture
values and to the conditional probability which relates the variations of backscattering
coefficients to variations of soil moisture and roughness. The relationship can be expressed as
follows:
(
)
( )
(
)
( )
(
)
0
0
0
,
prior
i
post
i
i
i
i
prior
i
post
i
i
i
Si
p
S
p
S
p S
p
S
p
S dS
s
s
s
=
ò
(5)
where the term at the denominator is a normalization factor with integration over all variables
Si. The variables Si can be:
• For bare soil: dielectric constant (ε), the standard deviation of the height (s) and the corre‐
lation length (l);
• For vegetated soil: dielectric constant (ε), the standard deviation of the height (s) and the
correlation length (l), vegetation water content (VWC).
The variables σ0
i refer to the input values derived from remote sensing data, which in the
presented approach are:
• Backscattering coefficients at L-band HH and VV pol for the Argentinean test sites;
Integration of Remotely Sensed Images and Electromagnetic Models into a Bayesian Approach for…
http://dx.doi.org/10.5772/57562
51

• Backscattering coefficients at C-band HH and VV pol, L-band HH and VV pol and the
combination of C and L band at HH pol for SMEX’02 test site.
Based on the field data, the integration ranges for Bayesian inference were selected with
different values as is illustrated in the following part. The main aim of using different intervals
was to test the sensitivity of the methods to prior information, Through these integrations, to
each pixel a value of dielectric constant is associated, starting from the corresponding back‐
scattering coefficient values. Finally, with the formula proposed by [40] the dielectric constant
values have been transformed to estimated values of soil moisture. The flowchart in Fig.8
outlines the main steps of the algorithm, including training and test phase.
Figure 8. Flowchart of the Bayesian soil moisture approach applied to the Argentinean test site.
As above mentioned, another version of the Bayesian algorithm was developed to take into
account the effect of vegetation into the PDF. The flowchart of the algorithm is the same as
shown in fig.8, but instead of Water Cloud Model there is an adaptation of the PDF mean to
an empirical function related to VWC as detailed described in Notarnicola et al., 2007 [38]. The
algorithm was developed to work with C, L and combination of C and L band. In this work,
this specific algorithm is applied to SMEX’02 data.
Dynamic Programming and Bayesian Inference, Concepts and Applications
52

4. Results and discussion
The main aim of the work is to verify the sensitivity of the algorithm to prior conditions of
roughness and vegetation in order to optimize the accuracy of the results. Based on this concept
several retrievals were performed for different conditions of surface roughness, with specific
algorithms for each coverage type in the study area. In the following the results on the
Argentinean and SMEX’02 test sites are presented and discussed.
4.1. Argentinean test site
Over the Argentinean test site, the algorithm (fig.8) is divided in two main parts: one to be
used in plots with bare soil or covered with sparse vegetation and another for vegetated soils.
In both cases, two versions of the algorithm were developed: a simplified one working on a
vector of mean values for each plot where the aim is to analyze the backscatter coefficient
behavior using random values within ranges of s and l, and another one to work on the whole
image, on pixel basis, to investigate the SM spatial distributions. Working with average values
of backscattering coefficients has two objectives: to understand the effect on the SM estimates
when the signal noise in the single plot is strongly reduced and to lower the computation
burden when applying a random function for s and l variables.
An extensive analysis was conducted in order to understand the behavior of variables such as
surface roughness and vegetation presence in the final SM estimation through the variability
of the prior information. The different cases analyzed are listed below:
• Case 1: Pixel based algorithm for bare soil with fixed roughness. Three runs were executed:
s=0.3 cm, l=5.0 cm; s=0.5 cm, l=5.0 cm and s=0.9 cm, l=5.0 cm. Then a mean value map is
generated.
• Case 2: Pixel based algorithm for bare soil with an integration over a roughness range: 0.6
cm < s < 1.4 cm; l=5.0 cm.
• Case 3: Pixel based algorithm for bare soil with an integration over a roughness range: 0.6
cm < s < 1.4 cm; l=15.0 cm.
• Case 4: Pixel based algorithm for bare soil with an integration over a roughness range: 1.0
cm< s < 1.5 cm; l=5.0 cm. In this case a very small integration range was considered.
• Case 5: Algorithm applied to backscattering coefficients averaged at plot level with a
random function. Values range: 0.5 cm < s < 1.2 cm; 5.0 cm < l < 10.0 cm.
• Case 6: VWC is calculated using a SPOT image. Fixed roughness and correlation length.
s=0.5 cm; l=5.0 cm.
• Case 7: VWC is calculated using a SPOT image and a random function is implemented for
s and l calculation, considering expected mean and standard deviation values for each
parameter: mean value of s=0.7 cm and standard deviation value of 0.5 cm, mean value of
l=5.0 cm and standard deviation of 5.0 cm. The random function is built as a noise function
Integration of Remotely Sensed Images and Electromagnetic Models into a Bayesian Approach for…
http://dx.doi.org/10.5772/57562
53

added to the mean values of s and l. The pseudo random values are drawn from a standard
normal distribution.
• Case 8: VWC is provided as an input variable and an integration is done over the following
values: 0.01 <VWC < 6 Kg m2.
• Case 9: VWC is calculated using a SPOT image, based on NDVI values, and an integration
is done over roughness and correlation length in the following ranges:0.4 cm< s < 1.2 cm and
3.0 cm < l < 10.0 cm.
In Fig.9, preliminary results are presented where the different analyzed cases based on various
prior conditions are numbered from 1 to 9. In general, for bare soil (fig. 9), the results showed
a sensitivity of the algorithms to the different roughness conditions of each plot with a
variability of around 5-7% (excluding the extreme cases). The highest variability among the
cases is around 40% and is found when the roughness interval is very small (case 2 and 3).
When considering a random function for roughness (case 7) and when performing the retrieval
over average values of backscattering coefficients (case 5), the mean different with respect to
ground measurements is around 15%.
For vegetated areas, due to the limited availability of field measurements (field 5N), the
evaluation of the performances is still under work. More extensive results for vegetation are
presented for the SMEX’02 experiments.
Figure 9. Comparison of SM estimates with measured values. Behavior diagram of the described cases.
Dynamic Programming and Bayesian Inference, Concepts and Applications
54

Case1 and 3 results are reported in the form of SM maps in fig.10. A detailed analysis of the
maps in fig.10 indicated error patterns detected for cases with rows of plots oriented orthog‐
onally to the direction of the sensor observation. As it was observed, the backscattering
coefficients for HH polarization is sensitive to the orientation of lines tillage and no inversion
algorithms consider this factor. Consequently the results show significant errors in plots
perpendicular to the observation.
Figure 10. Soil moisture maps for Case 1 (left) and Case 3 (right) over the selected test site.
Case 1 shows that the northern plots with bare soils (1N and 2N) have moisture values very
similar to the ground truth. On the contrary, southern plots with bare soils (1S and 2S) have
higher moisture values than the measured ones, having the first of them a value of 25%, while
the in situ data shown values around 20%. Case 3 shows that plot 1N and 2N obtained moisture
values around 15%, which represents an over-estimation of the actual value of around 5%. For
plots 1S and 2S, the estimate values are between 22 to 24%. Case 1 could model with good
accuracy plots 1N and 2N losing accuracy in southern plots. On the contrary, Case 3 could
model with relatively accuracy plots 1S and 2S losing precision in northern plots. The factor
of apparent roughness change can be attributed to the orientation of the rows with respect to
the SAR signal [41].
4.2. Results on the SMEX’02 experiments
As illustrated in previous paragraphs, the inversion methodologies based on Bayesian
approach can be applied to different sensors configurations. In this way different polarizations
and/or bands can be exploited to extract soil features. In fact, due to the different way C band
or L band signals interact with soil and the above canopy layer, they are sensitive to different
surface characteristics. Thus a proper combination of the two bands can help disentangle the
Integration of Remotely Sensed Images and Electromagnetic Models into a Bayesian Approach for…
http://dx.doi.org/10.5772/57562
55

effect of vegetation and then improve the estimation of soil moisture. In this paragraph, the
results of the Bayesian methodologies are illustrated and the evaluated in terms of:
• Correlation coefficients, R, between the estimates and the ground truth values
• Root Mean Square Error, RMSE, between the estimates and the ground truth values.
When dealing with the different cases due to the prior information, the retrieved values will
be compared with the measurements through the Taylor plots [42].
The Bayesian approach has been applied to AirSAR data collected during the SMEX’02
experiments considering C band, L band and combination of C and L data.
The results for the estimation of SM are reported in table 4. As expected the estimation of SM
is quite difficult, thus determining values of R varying from 0.47 to 0.80 for the combination
of C and L bands. The highest difficulties are found for the detection and correct estimation of
extreme values of soil moisture.
Configurations
Correlation coefficients
RMSE (cm3/cm3)
C band
0.47
0.10
L band
0.67
0.05
C + L band
0.80
0.02
Table 4. Correlation coefficients (R), RMSE for the comparison between the different estimates and ground truth
values for SM values, excluding extreme values.
The retrieval of low values of SM can be difficult as the signal for soil is small and difficult to
be disentangled from the vegetation signal. For high values, the signal from soil is strong but
in the case of C bands the double bouncing and the effect of absorption from leaves also for L
band, typical of narrow leaf plants such as soybean, determine a lower signal reaching the
sensor [43]. The L band estimates are the only one able to predict highest values of SM.
Similar analyses were also found in Notarnicola et al. 2006 [39]. In this previous analysis, the
methodologies were applied only to few fields of the same data set. With respect to the accuracy
reported in Notarnicola et al., 2006 [39], a worsening in the performance is found. In particular
the data set includes all the fields in the watershed basin and the fields located in the eastern
part which exhibits anomalous values of SM, some very high values around 35% and some
values lower than 5%. Considering the available meteorological information, the eastern and
western parts of the watershed experienced very different intensity for the rain event where
most of the rain event occurred in the western part.
If the watershed is divided in two parts the western and the eastern part the performances of
the algorithm for SM retrieval differ significantly. The correlation coefficients are equal to 0.57
and 0.84, not significantly different from those found in [39].
Furthermore, the performances notably change if in the data set the soybean and corn fields
are considered separately. The results are reported in table 5.
Dynamic Programming and Bayesian Inference, Concepts and Applications
56

Configurations
Corn
Soybean
R
RMSE (cm3/cm3)
R
RMSE (cm3/cm3)
C band
0.36
0.127
0.83
0.032
L band
0.41
0.091
0.42
0.072
C+L band
0.68
0.057
0.82
0.037
Table 5. Correlation coefficients (R), RMSE for the comparison between the different estimates and ground truth
values for SM values and for the Bayesian approach. With respect to table 4, in this case, the soybean and corn fields
are considered separately. In italics, the values significantly different from the one found in whole data sets are
indicated.
Similar characteristics are also found in [44], where it is proved that the RMSE is dependent
on the level of vegetation of the different fields. Furthermore, in the case of C band, the signal
coming from the VWC dominates over the signal coming from soil. In fact, when the vegetation
has low value of VWC such as in the case of soybean fields, the C band is able to provide
acceptable estimates for soil moisture. In the case of corn fields, the best results is obtained
with the combination of C and L band, one sensitive to VWC and the other to the surface
contribution. These discrepancies may be ascribed to the fact that in the Bayesian formulation
the double bouncing between soil and corn trunk effect is not taken into account. This effect
in such kind of plants with broad leaves could dominate [43].
On the SM estimates derived from combination of C and L band, a further analysis has been
carried out by considering the effect of prior information on roughness.
More in details, the range of roughness in the integration of equation which is used to derive
the expected values for soil moisture has been varied as follows:
• Low roughness: s varying between 0.2 and 1.2 cm;
• High roughness: s varying between 1.2 and 5.0 cm;
• Whole range of roughness: s varying between 0.2 and 5.0 cm.
The chosen values for roughness have selected based on prior information on roughness
during field measurements. Along with these fixed ranges of roughness, a variable roughness
interval has been considered based on the values of backscattering roughness. Higher values
of backscattering coefficients on both C and L band have been also associated to high values
of roughness.
The SM estimates derived from C and L band are illustrated in figure 11. When the estimates
under these hypotheses are compared, they show an overall variability of around 25%. The
results in term of correlation coefficients, are presented in the form of Taylor diagram as
showed in fig. 12.
The SM estimates closest due to the ground measurements are those derived from the whole
range of roughness and the adapted intervals. The high roughness and the whole range of
roughness produces very close results both in terms of correlation coefficients and standard
deviations.
Integration of Remotely Sensed Images and Electromagnetic Models into a Bayesian Approach for…
http://dx.doi.org/10.5772/57562
57

Figure 11. Comparison of SM estimates under different roughness hypothesis with ground measurements. “LR” stand
for low roughness, “HR” for high roughness, “Whole” for the whole range of roughness and adaptive for adaptive
values of roughness.
Figure 12. Taylor diagram showing the comparison under different prior hypotheses on roughness. A refers to
ground measurements; B to low roughness; C to high roughness; D to whole range of roughness; E adapted rough‐
ness ranges.
Dynamic Programming and Bayesian Inference, Concepts and Applications
58

5. Conclusions
The main objective of this chapter is to present the capability of Bayesian approach to estimate
SM values starting from SAR backscattering coefficients. Two case studies are presented where
SAR acquisitions took place over agricultural fields. The first case study was related to an
Argentinean test site developed and equipped for acquisitions of airborne L band SAR called
SARAT. The acquisitions were carried out in preparation of the SAOCOM mission. The second
case study was related to the experiment SMEX’02 carried out in IOWA in 2002. In this
experiment airborne AirSAR images were available and for this reason the retrieval was
applied to C band, L band and C+L band data.
Based on the retrieval results, the main goal was then to verify the sensitivity of the SM
estimates from the set prior information on roughness and vegetation. All the prior PDFs are
set a uniform, non-informative but the set limits of the interval in the integration procedure
can determine variation in the final SM estimates. This behavior is expected because the
electromagnetic models used in the retrieval approach contain explicitly the dependence of
backscattering coefficients on roughness and vegetation parameters.
The effect of prior information ranges from few percentages up to 25% where the highest
sensitivity is found in both case studies when too specific and narrow intervals for roughness
are used. The highest performances were found for both case studies when the range of
roughness is large enough to include most roughness measurements. Moreover, if a prelimi‐
nary assessment on the roughness level is available, the algorithm determines the highest
performances with respect to the ground reference data.
An interesting feature observed in the case of Argentinean test site is the reduction of errors
on the SM estimates when the retrieval is performed on average values of backscattering
coefficients from each field. This behavior can be due to the reduction of noise present in the
SAR signal.
As main conclusion of this analysis and suggestions in using the proposed the Bayesian
algorithms for SM estimation, the following considerations emerge:
• The set of prior information has to be selected carefully;
• Even in the case of non-information prior PDF, the range of variability of the prior variable
has an impact on the final estimates;
• It is preferable to integrate over a large interval of roughness and/or vegetation variables in
order to take into account and properly weight all the measured values.
• As the speckle noise can influence the SM estimates, a proper filter over the SAR image
needs to be applied before proceeding to the retrieval approach.
Integration of Remotely Sensed Images and Electromagnetic Models into a Bayesian Approach for…
http://dx.doi.org/10.5772/57562
59

Acknowledgements
The authors wish to thank to CONAE and SAOCOM mission team for SARAT data provision
and field measurements acquired during the remote sensing campaign.
Author details
Claudia Notarnicola1* and Romina Solorza2
*Address all correspondence to: claudia.notarnicola@eurac.edu
1 EURAC Research-Institute for Applied Remote Sensing, Viale Druso, Bolzano, Italy
2 Gulich Institute, CONAE, Falda del Carmen, Córdoba, Argentina
References
[1] Barrett B.W., Dwyer E., Whelan P. Soil Moisture Retrieval from Active Spaceborne
Microwave Observations: An Evaluation of Current Techniques. Remote Sens., 2009;
1 210-242, doi:10.3390/rs1030210.
[2] World Meteorological Observatory, Climate Essential Variable http://www.wmo.int/
pages/prog/gcos/index.php?name=EssentialClimateVariables (access 5 November
2013).
[3] Álvarez Mozos J., Casalí J., González A., López J. Estimación de la Humedad Superfi‐
cial del Suelo mediante Teledetección de Radar en Presencia de una Cubierta de Ce‐
real. Estudios de la Zona No Saturada del Suelo, 2005; VII 313–318.
[4] Engman E.T. Applications of microwave remote sensing of soil moisture for water
resources and agriculture. Remote Sensing of Environment, 1991; 35 213–226,.
[5] Ulaby F.T., Aslam A., Dobson M.C. Effects of vegetation cover on the radar sensivity
to soil moisture. IEEE Transactions on Geoscience and Remote Sensing, 1982; 20(4)
476–481.
[6] Lakshmi V. Remote Sensing of Soil Moisture. Hindawi Publishing Corporation ISRN
Soil Science Volume 2013, Article ID 424178, 33 pages.
[7] Gruhier C., de Rosnay P., Hasenauer S., Holmes T., de Jeu R., Kerr Y., Mougin E.,
Njoku E., Timouk F., Wagner W., Zribi M. Soil moisture active and passive micro‐
wave products: intercomparison and evaluation over a Sahelian site, Hydrol. Earth
Syst. Sci., 2010; 14 141–156.
Dynamic Programming and Bayesian Inference, Concepts and Applications
60

[8] Behari J. Microwave Dielectric Behavior of Wet Soils. Anamaya Publishers, 2005.
[9] Ulaby F. T. Radar measurement of soil moisture content. IEEE Transactions on An‐
tennas and Propagation, 1974; 22(2) 257–265. doi: 10.1109/TAP.1974.1140761.
[10] Ulaby F.T., Moore R.K., Fung A.K. Microwaves Remote Sensing: Active and Passive.,
volume III, Surface Scattering and Emission Theory. Artech House, Dedham, MA,
1986.
[11] Dubois P., Van Zyl J., Engman T. Measuring soil moisture with imaging radars. IEEE
Transactions on Geoscience and Remote Sensing, 1995; 33 (4) 915–926.
[12] Baghdadi N., Aubert M., Zribi M. Use of TerraSAR-X Data to Retrieve Soil Moisture
Over Bare Soil Agricultural Fields. IEEE Geoscience and Remote Sensing Letters,
2012; 9(3) 512–516.
[13] Dobson F.T. Ulaby L.E. Pierce, T.L. Sharik K.M. Bergen J. Kellindorfer J.R. Kendra E.
Li Y.C. Lin A. Sarabandi K., Siqueira P.. Estimation of forest byophysical characteris‐
tics in northern michigancwith sir-c/x-sar. IEEE Transactions on Geoscience and Re‐
mote Sensing, 1995; 33 877–895.
[14] Ferrazzoli P., Paloscia S., Pampaloni P., Schiavon G. The potential of multifrequency
polarimetric sar in assesing agricultural and arboreous biomass. IEEE Transactions
on Geoscience and Remote Sensing, 1997; 35 5–17.
[15] Baronti S., Del Frate F., Ferrazzoli P., Paloscia S., Pampaloni P., Schiavon G.. SAR po‐
larimetric features of agricultural areas. International Journal of Remote Sensing,
1995; 16 2639–2356.
[16] Holah N., Baghdadi N., Zribi M., Bruand A., King C.. Potential of ASAR/Envisat for
the characterization of soil surface parameters over bare agricultural fields. Remote
Sensing of Environment, 2005; 96 78–86.
[17] Li Z., Ren X., Li X., Wang L. Soil moisture measurement and retrieval using Envisat
ASAR imagery. Proceedings of the IEEE International Geoscience and Remote Sens‐
ing Symposium (IGARSS 2004), 3539–3542, Anchorage, USA, 2004.
[18] Zhang T., Zeng Q., Li Y., Xiang Y. Study on relation between InSAR coherence and
soil moisture. Proceedings of the ISPRS Congress, Beijing, China, 2008.
[19] Autret, Bernard R., VidalMadjar D.. Theoretical study of the sensitivity of the micro‐
wave backscattering coefficient to the soil surface parameters. International Journal
of Remote Sensing, 1989; 10 171–179.
[20] Chen K.S., Yen S.K., Huang W.P.. A simple model for retrieving bare soil moisture
from radar scattering coefficients. Remote Sensing of Environment, 1995; 54 121–126.
[21] Pierdicca N., Pulvirenti L., Bignami C.. Soil moisture estimation over vegetated ter‐
rains using multitemporal remote sensing data. Remote Sensing of Environment,
2010; 114 440–448.
Integration of Remotely Sensed Images and Electromagnetic Models into a Bayesian Approach for…
http://dx.doi.org/10.5772/57562
61

[22] Balenzano A, Satalino G., Belmonte A., D’Urso G., Capodici F., Iacobellis V., Gioia A.,
Rinaldi M., Ruggieri S., Mattia F. On the use of multitemporal series of COSMO-
SkyMed data for LANDcover classification and surface parameter retrieval over agri‐
cultural sites. Proceeding of Geoscience and Remote Sensing Symposium (IGARSS),
142–145, July 2011.
[23] Hornacek M, Wagner W, Sabel D, Truong H.L, Snoeij P, Hahmann T, Diedrich E,
Doubkova M. Potential for High Resolution Systematic Global Surface Soil Moisture
Retrieval Via Change Detection Using Sentinel-1. IEEE Journal of Selected Topics in
Applied Earth Observations and Remote Sensing, 2012, 1–9.
[24] Dobson M.C., Ulaby F. T.. Mapping Soil Moisture Distribution With Imaging Radar,
chapter 8, 407–433. John Wiley and Sons Inc., 1998.
[25] Shi J., Wang J., Hsu A.Y., ONeill P.E., Engman E.T.. Estimation of bare surface soil
moisture and surface roughness parameter using l-band SAR image data. IEEE
Transactions on Geoscience and Remote Sensing, 1997; 35 1254–1266.
[26] Oh Y.. Quantitative retrieval of soil moisture content and surface roughness from
multipolarized radar observations of bare soils surfaces. IEEE Transactions on Geo‐
science and Remote Sensing, 2004; 42(3) 596–601.
[27] Fung, A. K. Microwave Scattering and Emission Models and their Application. Ar‐
tech House, Boston; 1994.
[28] Pampaloni P., Santi E., Paloscia S., Pettinato S., Poggi P. Radar Remote Sensing of
Soil Moisture, ENVISNOW Project, SMC algorithms. Technical report, IFAC-CNR,
October 2004.
[29] Notarnicola C., Posa F. Bayesian algorithm for the estimation of the dielectric con‐
stant from active and passive remotely sensed data. IEEE Geoscience and Remote
Sensing Letters, 2004; 1(3) 179–183.
[30] Paloscia S., Pampaloni P., Pettinato S., Santi E. A comparison of algorithms for re‐
trieving soil moisture from ENVISAT/ASAR images. IEEE Transactions on Geosci‐
ence and Remote Sensing. 2008; 46(10) 3274-3284.
[31] Barber M., Grings F., Perna P., Bruscantini C., Karszenbaum H. Análisis de las medi‐
ciones de rugosidad del Centro Espacial Teóﬁlo Tabanera, Córdoba. Technical report,
CONAE-IAFE,Mayo
[32] http://nsidc.org/data/amsr_validation/soil_moisture/smex02/
[33] Barber M., Grings F., Perna P., Piscitelli M., Maas M., Bruscantini C., Jacobo-Berlles J.,
Karszenbaum H. Speckle Noise and Soil Heterogeneities as Error Sources in a Bayesi‐
an Soil Moisture Retrieval Scheme for SAR Data. IEEE Journal Of Selected Topics In
Applied Earth Observations And Remote Sensing, 2012; 5(3).
Dynamic Programming and Bayesian Inference, Concepts and Applications
62

[34] Gelman A., Carlin J.B., Stern H.S., Rubin D. B., Bayesian data analysis, Chap‐
man&Hall/CRC 1995.
[35] Attema E. P, Ulaby F.T.. Vegetation Modeled as a Water Cloud. Radio Science, 1978;
13(2) 357–364.
[36] Dabrowska-Zielinska K., Inoue Y., Kowalik W., Gruszczynska M.. Inferring the effect
of plant and soil variables on C-and L-band SAR backscatter over agricultural fields,
based on model analysis. Advances in Space Research, 2007; 39 139–148.
[37] Jackson T., Chen D., Cosh M., Li F., Anderson M., Walthall C., Doriaswamy P., Ray
Hunt E. Vegetation water content mapping using Landsat data derived normalized
difference water index for corn and soybeans. Remote Sensing of Environment, 2004;
92 475–482.
[38] Notarnicola, C. & Posa, F. Inferring vegetation water content from C and L band im‐
ages, IEEE Transactions on Geoscience and Remote Sensing, 2007; 45(10) 3165-3171.
[39] Notarnicola C., Angiulli M., Posa F. Use of Radar and Optical Remotely Sensed Data
for Soil Moisture Retrieval on Vegetated Areas. IEEE Transactions on Geoscience and
Remote Sensing, 2006; 44(4) 925-935.
[40] Hallikainen M.T., Ulaby F.T., Dobson M.C., El Rayes M.A., Wu L.K.. Microwave die‐
lectric behavior of wet soil-part 1: Empirical models and experimental observations.
IEEE Transactions On Geoscience And Remote Sensing, 1985; GE-23(1) 25–34.
[41] Solorza R., Notarnicola C., Karszenbaum H., Retrieval of soil moisture using a Baye‐
sian approach and electromagnetic models in views of the SAOCOM mission: study
on SARAT images in an agricultural site in Argentina, Proceeding of Igarss 2013, July
2013, Melbourne, Australia.
[42] Taylor, E, K, Summarizing multiple aspects of model performance in a single dia‐
gram, Journal of Geophysical Research, 2001; 106(D7), 7183-7192.
[43] Macelloni G., Paloscia S., Pampaloni P., Marliani F., Gai, M. The relationship between
the backscattering coefficient and the biomass of narrow and broad leaf crops, IEEE
Transaction on Geoscience and Remote Sensing, 2001; 39(4) 873-884.
[44] Lakhankar T., Ghedira H., Temimi M., Sengupta M., Khanbilvar R., Blake, R. Non-
parametric methods for soil moisture retrieval from satellite remote sensing data, Re‐
mote Sensing, 2009; 1, 3-21. doi: 10.3390/rs1010003.
Integration of Remotely Sensed Images and Electromagnetic Models into a Bayesian Approach for…
http://dx.doi.org/10.5772/57562
63


Chapter 3
J. Mukuddem-Petersen, M.A. Petersen and
M.P. Mulaudzi
Additional information is available at the end of the chapter
http://dx.doi.org/10.5772/58395
Optimizing Basel III Liquidity Coverage Ratios
1. Introduction
The recent ﬁnancial crises, viz., the subprime mortgage and 2007-2009 ﬁnancial crises as well
as the sovereign debt crisis, are characterized by too-big-to fail banks that suffered from a
lack of liquidity (see, for instance, [13] and [14]). The actualization of such liquidity risk led
to credit crunches and had negative effects on global ﬁnancial markets. In response to this,
among other things, the Basel Committee on Banking Supervision (BCBS) is proposing that
banks should always have a 30-day liquidity cover for stress scenarios (see, for instance, [2],
[3], [4] and [5]).
In this regard, the level of high-quality liquid assets (HQLAs) is important in order for banks
to function optimally (see, for instance, [6] and [8]). As far as Basel III liquidity proposals
are concerned, the BCBS is suggesting a liquidity coverage ratio (LCR) deﬁned as follows.
The LCR has two components:
(a) total stock of HQLAs; and
(b) total nett cash outﬂows,
and is expressed as
LCR =
Total Stock of High-Quality Liquid Assets (HQLAs)
Total Nett Cash Outﬂows (NCOs) Over the Next 30 Calendar Days ≥1.
(1)
The numerator of the LCR is the stock of HQLA. Under the standard, banks must hold a stock
of unencumbered HQLA to cover the total net cash outﬂows over a 30-day period under the

prescribed stress scenario. In order to qualify as HQLA, assets should be liquid in markets
during a time of stress and, in most cases, be eligible for use in central bank operations.
Certain types of assets within HQLA are subject to a range of haircuts. HQLA are comprised
of Level 1 assets (L1As) and Level 2 assets (L2As). L1As generally include cash, central bank
reserves, and certain marketable securities backed by sovereigns and central banks, among
others. These assets are typically of the highest quality and the most liquid, and there is
no limit on the extent to which a bank can hold these assets to meet the LCR. L2As are
comprised of Level 2A assets (L2AAs) and Level 2B assets (L2BAs). L2AAs include, for
example, certain government securities, covered bonds and corporate debt securities. L2BAs
include lower rated corporate bonds, residential mortgage backed securities and equities that
meet certain conditions. L2As may not in aggregate account for more than 40 % of a bank’s
stock of HQLA. L2BAs may not account for more than 15 % of a bank’s total stock of HQLA
(see, for instance, [1] and [13]).
The denominator of the LCR is the total net cash outﬂows. It is deﬁned as total expected
cash outﬂows, minus total expected cash inﬂows, in the speciﬁed stress scenario for the
subsequent 30 calendar days. Total expected cash outﬂows are calculated by multiplying
the outstanding balances of various categories or types of liabilities and off-balance sheet
commitments by the rates at which they are expected to run off or be drawn down. Total
expected cash inﬂows are calculated by multiplying the outstanding balances of various
categories of contractual receivables by the rates at which they are expected to ﬂow in. Total
cash inﬂows are subject to an aggregate cap of 75 % of total expected cash outﬂows, thereby
ensuring a minimum level of HQLA holdings at all times (see, for instance, [11] and [13]).
The standard requires that, in the absence of ﬁnancial stress, the value of the ratio be no lower
than 100 % (i.e., the stock of HQLA should at least equal total net cash outﬂows). Banks are
expected to meet this requirement on an ongoing basis and hold a stock of unencumbered
HQLA as a defence against the potential onset of liquidity stress. During a period of ﬁnancial
stress, however, banks may use their stock of HQLA, thereby falling below 100 % (see, for
instance, [11]).
1.1. Overview of the literature
Our contribution has strong connections with [7], [10], [12] and [13] that deals with subprime
mortgage funding and liquidity risk and Basel III liquidity regulation, respectively.
The working paper [7] examines large capital injections by U.S. ﬁnancial institutions from
2000 to 2009. These infusions include private as well as government cash injections under
the Troubled Asset Relief Program (TARP). The sample period covers both business cycle
expansions and contractions, and the recent ﬁnancial crisis. Elyasiani, Mester and Pagano
show that more ﬁnancially constrained institutions were more likely to have raised capital
through private market offerings during the period prior to TARP, and ﬁrms receiving a
TARP injection tended to be riskier and more levered. In the case of TARP recipients, they
appeared to ﬁnance an increase in lending (as a share of assets) with more stable ﬁnancing
sources such as core deposits, which lowered their liquidity risk. However, in [7], Elyasiani,
Mester and Pagano ﬁnd no evidence that banks’ capital adequacy increased after the capital
injections. In this book chapter, we regard the LCR as a measure of liquidity risk. We check
the tendencies of this measure over the sample period 2002 to 2012 and make conclusions
about it (see, also, [13]).
Dynamic Programming and Bayesian Inference, Concepts and Applications
68

The technique employed in this book chapter is heavily reliant on the one used in [10]. In that
paper, Mukuddem-Petersen and Petersen consider the application of stochastic optimization
theory to asset and capital adequacy management in banking. The study is motivated by new
banking regulation that emphasizes risk minimization practices associated with assets and
regulatory capital. The analysis in [10] depends on the dynamics of the capital adequacy ratio
(CAR), that we compute by dividing regulatory bank capital (RBC) by risk weighted assets
(RWAs). Furthermore, Mukuddem-Petersen and Petersen demonstrate how the CAR can be
optimized in terms of bank equity allocation and the rate at which additional debt and equity
is raised. In either case, the dynamic programming algorithm for stochastic optimization is
employed to verify the results. Also, in [10], Mukuddem-Petersen and Petersen provide an
illustration of aspects of bank management practice in relation to this regulation. In the
current chapter, the same technique is employed (see, also, [13]).
In [12], we use actuarial methods to solve a nonlinear stochastic optimal liquidity risk
management problem with deposit inﬂow rates and marketable securities allocation as
controls. The main objective in [12] is to minimize liquidity risk in the form of funding
and credit crunch risk in an incomplete market. In order to accomplish this, we construct a
stochastic model that incorporates mortgage and deposit reference processes. However, the
current chapter is an improvement on [12] in that bank balance sheet features play a more
prominent role (see Sections 2, 3 and 5 for more details).
In order to construct our LCR model, we take into account results obtained in [13] in a
discrete-time framework (see, also, [8]). In the aforementioned book, we estimate the LCR
and NSFR by applying approximation techniques to banking data from a cross section of
countries. We ﬁnd that these Basel III risk measures have low information values and are
relatively poor indicators of liquidity risk. Our results, in [13], show that as the LCR increases
(decreases) the probability of failure decreases (increases) for both Class I (internationally
active banks with Tier 1 capital in excess of US $ 4 billion) and II (the rest) banks. Our
contribution is distinct from the aforementioned in the following respects.
Firstly, our
analysis has a heavy reliance on the derivation of a stochastic model for LCR dynamics
that depends mainly on the liquidity provisioning rate, HQLA returns and NCO outﬂows.
Secondly, we obtain an analytic solution of a particular type to our stochastic bank LCR
problem (with a quadratic objective function) that we pose.
Finally, the optimal choices
for the cash injection and asset allocation are both expressed in terms of a LCR reference
process. To our knowledge such processes have not been considered for LCRs before. The
study is particularly signiﬁcant because the Basel III LCR will be implemented on Thursday,
1 January 2015 on a global scale (see, for instance, [2], [3], [4] and [5]). In this book chapter,
we extend the analysis in [13] to continuous time.
1.2. Outline of the book chapter
In short, this book chapter advances our knowledge of Basel III liquidity by investigating
the LCR global liquidity standard (see, for instance, [6] and [14]) in an optimization context.
In particular, in Section 2, a theoretical-quantitative model is constructed by considering the
dynamics of the HQLAs and NCOs. Section 3 produces two parameters that are able to be
controlled, viz., the liquidity provisioning rate and HQLA allocation. The main motivation
for studying LCR dynamics is to show that, in principle, banks are able to control their
liquidity via an appropriate provisioning strategy. This should ensure that the said ratio
Optimizing Basel III Liquidity Coverage Ratios
http://dx.doi.org/10.5772/58395
69

does not move below an acceptable level. The control theoretic liquidity problem is to meet
LCR targets with as little additional liquidity provisioning (essentially corresponding to cash
injections in our chapter) as possible and optimal HQLA allocation.
Section 5 provides
conclusions and future directions. As was mentioned before, the additional provisioning
may arise from an inﬂow of cash injections. We choose examples to illustrate that Basel III
liquidity regulation resulted from both problematic liquidity structures and unexpected cash
outﬂows (see Section 5 for more details).
2. A Liquidity Coverage Ratio Model
In this section, we model HQLAs, NCOs and LCR in a stochastic framework by following
[10] very closely. This is important for solving the optimal LCR control problem outlined
subsequently in Section 3.
2.1. Description of the Liquidity Coverage Ratio Model
Before the 2007-2009 ﬁnancial crisis, banks were prosperous with high liquidity provisioning
rates, low interest rates and soaring cash outﬂows. This was followed by the collapse of the
housing market, exploding default rates and the effects thereafter. The LCR was developed
to promote short-term resilience of a bank’s liquidity risk proﬁle. This standard aims to
ensure that a bank has an adequate stock of unencumbered HQLAs that consist of cash or
assets that can be converted into cash at little or no loss of value in private markets to meet
its liquidity needs for a 30 calendar day liquidity stress scenario (see, for instance, [1], [3] and
[4]). In order to make our analysis tractable, we make the following assumption about our
LCR model.
Assumption 2.1. (Filtered Probability Space and Time Index) Assume that we have a ﬁltered
probability space (Ω, F, P) with ﬁltration {Ft}t≥0 on a time index set T = [t0, t1].
Subsequently, we study a system of stochastic differential equations (SDEs) that value
HQLAs at time t as x1 : Ω× T →R+ (compare with [10]). Here, HQLAs, x1
t , are stochastic
because they are dependent on the stochastic rates of return on L1As and L2As (see [12]
for more details). Also, NCOs at time t, x2
t , with x2 : Ω× T →R+ are stochastic because
their value has a reliance on random cash in- and outﬂows as well as liquidity provisioning.
Furthermore, for x : Ω× T →R2 we use the notation xt to denote
xt =
 x1
t
x2
t

and present the LCR, l : Ω× T →R+, by
lt = x1
t /x2
t = x1
t .(x2
t )−1.
(2)
Dynamic Programming and Bayesian Inference, Concepts and Applications
70

It is important for banks that lt in (2) has to be sufﬁciently high to ensure high LCRs. In fact,
as was mentioned before, Basel III sets the minimum value of the LCR at 1. Obviously, low
values of lt indicate that the bank has decreased liquidity and is at high risk of causing a
credit crunch (see, for instance, [13]).
Bank liquidity has a heavy reliance on liquidity provisioning rates.
This rate should be
reduced for high LCRs and increased beyond the normal rate when bank LCRs are low. In
the sequel, the stochastic process u1 : Ω× T →R+ is the normal rate of liquidity provisioning
per monetary unit of the bank’s NCOs whose value at time t is denoted by u1
t . In this case, u1
t dt
is the normal liquidity provisioning rate per unit of the bank’s NCOs over the time period
(t, t + dt). A related concept is the adjustment to the rate of liquidity provisioning per monetary
unit of the bank’s NCOs for surplus or deﬁcit, u2 : Ω× T →R+, that depends on the LCR. In the
case of liquidity deﬁcit, during stress scenarios, this adjustment rate can correspond to a cash
injection rate. Here the amount of surplus or deﬁcit is reliant on the excess of HQLAs over
NCOs. We denote the sum of u1 and u2 by the liquidity provisioning rate u3 : Ω× T →R+,
i.e.,
u3
t = u1
t + u2
t , for all t.
(3)
The following assumption is made in order to model the LCR in a stochastic framework
(compare with [10]).
Assumption 2.2. (Liquidity Provisioning Rate) The liquidity provisioning rate, u3, is predictable
with respect to {Ft}t≥0 and provides us with a means of controlling bank LCR dynamics (see (3) for
more details).
The closed loop system will be deﬁned such that Assumption 2.2 is met, as we shall see in the
sequel. In times of deﬁcit, for (3), we should choose the cash injection rate, u2, sufﬁciently
large in order to guarantee bank liquidity. In reality, cash injections are subject to more
stringent conditions (see, also, [13]).
Before and during the ﬁnancial crisis, the LCR decreased signiﬁcantly as extensive cash
outﬂows took place with a consequent rising of NCOs.
By contrast, banks predicted
continued growth in the ﬁnancial markets (see, for instance, [14]).
The dynamics of the
outﬂows per monetary unit of the bank’s NCOs, e : Ω× T →R, is given by
det = re
tdt + σe
t dWe
t , e(t0) = e0,
(4)
where et is the outﬂows per NCO monetary unit, re : T →R is the rate of outﬂows per
monetary unit of the bank’s NCOs, the scalar σe : T →R, is the volatility in the outﬂows per
NCO unit and We : Ω× T →R is standard Brownian motion (compare with [10]). Moreover,
we consider
dht = rh
t dt + σh
t dWh
t , h(t0) = h0,
(5)
Optimizing Basel III Liquidity Coverage Ratios
http://dx.doi.org/10.5772/58395
71

where the stochastic processes h : Ω× T →R+ is the investment return on bank HQLAs per
monetary unit of HQLAs, rh →R+ is the rate of HQLA return per HQLA unit, the scalar
σh : T →R, is the volatility in the rate of HQLA returns and Wh : Ω× T →R is standard
Brownian motion. Before the 2007-2009 ﬁnancial crisis, riskier HQLA returns were much
higher than those of riskless reserves, making the former a more attractive but much riskier
investment (see, also, [13]). During and after the crisis, this tendency reversed.
Assumption 2.3. (HQLA Classes) Suppose from the outset that bank HQLAs can be classiﬁed into
n + 1 asset classes. One of these HQLAs is risk free (like Central Bank reserves) while the HQLAs
1, 2, . . . , n have some risk associated with them.
Riskier HQLAs evolve continuously in time and are modeled using a n-dimensional
Brownian motion. In this multidimensional context, the investment returns on bank HQLAs in
the k-th HQLA per monetary unit of the k-th HQLA is denoted by yk
t , k ∈Nn = {0, 1, 2, . . . , n}
where y : Ω× T →Rn+1. Thus, the return per HQLA unit may be given by
y = (R(t), y1
t , . . . , yn
t ),
where R(t) represents the return on reserves and y1
t , . . . , yn
t represent riskier HQLA returns.
Furthermore, we can model y as
dyt = ry
t dt + Σy
t dWy
t , y(t0) = y0,
(6)
where ry : T →Rn+1 denotes the rate of asset returns, Σy
t ∈R(n+1)×n is a covariance
matrix of HQLA returns and Wy : Ω× T →Rn is standard Brownian. We assume that the
investment strategy π : T →Rn+1 is outside the simplex
S = {π ∈Rn+1 : π = (π0, . . . , πn)T, π0 + . . . + πn = 1, π0 ≥0, . . . πn ≥0}.
In this case, short selling is possible. The investment return on bank HQLAs is then h : Ω× R →
R+, where the dynamics of h can be written as
dht = πT
t dyt = πT
t ry
t dt + πT
t Σy
t dWy
t .
This notation can be simpliﬁed as follows. We denote
Dynamic Programming and Bayesian Inference, Concepts and Applications
72

rR(t) = ry0(t), rR : T →R+, the rate of return on riskless assets,
ry
t = (rR(t), ery
t
T
+ rR(t)1n)T, ery : T →Rn,
πt = (π0
t , eπT
t )T = (π0
t , π1
t , . . . , πk
t )T, eπ : T →Rk,
Σy
t =
 0 . . . 0
eΣy
t

, eΣy
t ∈Rn×n,
eCt = eΣy
t f
Σy
t
T
. Then, we have that
(7)
πT
t ry
t = π0
t rR(t) + eπjT
t ery
t + eπjT
t rR(t)1n = rR(t) + eπT
t ery
t ,
πT
t Σy
t dWy
t = eπT
t eΣy
t dWy
t ,
dht = [rR(t) + eπT
t ery
t ]dt + eπT
t eΣy
t dWy
t , h(t0) = h0.
Next, we take i : Ω× T →R+ as the increase of NCOs before outﬂows per monetary unit of
NCOs, ri : T →R+ is the rate of NCO increase before outﬂows per monetary unit of NCOs,
the scalar σi ∈R is the volatility in the NCO increase before outﬂows per monetary unit
of NCOs and Wi : Ω× T →R represents standard Brownian motion (compare with [10]).
Then, we set
dit = ri
tdt + σidWi
t, i(t0) = i0.
(8)
The stochastic process it in (8) may typically originate from NCOs that have recently taken
place or instability in the value of pre-existing NCOs.
Next, we develop a simple stochastic model that replaces a more realistic system that
emphasizes features that are speciﬁc to our particular study (see, also, [13]). In our situation,
we derive models for HQLAs, x1, and NCOs, x2, given by
dx1
t = x1
t dht + x2
t u3
t dt −x2
t det
= [rR(t)x1
t + x1
t eπT
t ery
t + x2
t u1
t + x2
t u2
t −x2
t re
t]dt
(9)
+[x1
t eπT
t eΣy
t dWy
t −x2
t σedWe
t ],
dx2
t = x2
t dit −x2
t det
= x2
t [ri
tdt + σidWi
t] −x2
t [re
tdt + σedWe
t ]
(10)
= x2
t [ri
t −re
t]dt + x2
t [σidWi
t −σedWe
t ].
The SDEs (9) and (10) may be rewritten into matrix-vector form in the following way
(compare with [10]).
Optimizing Basel III Liquidity Coverage Ratios
http://dx.doi.org/10.5772/58395
73

Deﬁnition 2.4. (Stochastic System for the LCR Model) Deﬁne the stochastic system for the
LCR model as
dxt = Atxtdt + N(xt)utdt + atdt + S(xt, ut)dWt,
(11)
with the various terms in this SDE being
ut =

u2
t
eπt

, u : Ω× T →Rn+1,
At =
 rR(t)
−re
t
0
ri
t −re
t

;
N(xt) =
"
x2
t x1
t ery
t
T
0
0
#
; at =

x2
t u1
t
0

;
S(xt, ut) =

x1
t eπT
t eΣy
t −x2
t σe
0
0
−x2
t σe x2
t σi

;
Wt =


Wy
t
We
t
Wi
t

,
where Wy
t , We
t and Wi
t are mutually (stochastically) independent standard Brownian motions. It is
assumed that for all t ∈T, σe
t > 0, σi
t > 0 and eCt > 0 (compare with [10]).
We can rewrite (11) as follows.
N(xt)ut :=

x2
t
0

u2
t +
"
x1
t ery
t
T
0
#
eπt
:=
 0 1
0 0

xtu3
t +
n
∑
j=1
"
x1
tery,j
t
0
#
eπj
t
:= B0xtu0
t +
n
∑
j=1
"
ery,j
t
0
0 0
#
xt eπj
t
:=
n
∑
j=0
[Bjxt]uj
t;
and
Dynamic Programming and Bayesian Inference, Concepts and Applications
74

S(xt, ut)dWt =

[ eπT
t eCt eπt]1/2 0
0
0

xtdW1
t +
+
 0 −σe
0 −σe

xtdW2
t +
 0 0
0 σi

xtdW3
t
=
3
∑
j=1
[Mj(ut)xt]dWj
t,
where Mj(ut) is the matrix notation used to denote matrices with entries related to ut.
Furthermore, W1, W2, and W3 represent Wy, We, and Wi, respectively. From (11) it is evident
that u = (u2, eπ) affects only the SDE of x1
t but not that of x2
t . In particular, for (11) we have
that eπ affects the variance of x1
t and the drift of x1
t via the term x1
t ery
t
T
eπt. On the other hand,
u2 affects only the drift of x1
t . Then (11) becomes
dxt = Atxtdt +
n
∑
j=0
[Bjxt]uj
tdt + atdt +
3
∑
j=1
[Mj(ut)xt]dWj
t.
(12)
2.2. Description of the simpliﬁed LCR model
The model can be simpliﬁed if attention is restricted to the system with the LCR, as stated
earlier, denoted in this section by lt = x1
t .(x2
t )−1 (compare with [10]).
Deﬁnition 2.5. (Stochastic Model for a Simpliﬁed LCR) Deﬁne the simpliﬁed LCR system
by the SDE
dxt = xt[rR(t) + re
t −ri
t + (σe)2 + (σi)2 + ery
t
T
eπt]dt
+[u1
t + u2
t −re
t −(σe)2]dt
(13)
+[(σe)2(1 −xt)2 + (σi)2x2
t + x2
t eπT
t eCt eπt]1/2dWt, x(t0) = x0.
The model is derived as follows. The starting point is the two-dimensional SDE for x =
(x1, x2)T as in the equations (9) and (10). Next, we use the Itô’s formula (see, for instance,
[15]) to determine
Optimizing Basel III Liquidity Coverage Ratios
http://dx.doi.org/10.5772/58395
75

d(x2
t )−1 = −(x2
t )−2dx2
t + 1
22(x2)−3
t
d < x2, x2 > t
= [−(x2)−1
t
(ri
t −re
t) + (x2
t )−1((σe)2 + (σi)2)]dt
−(x2
t )−1 
0 −σe σi 
dWt,
dxt = x1
t d(x2
t )−1 + (x2
t )−1dx1
t + d < x1, (x2)−1 > t
= [rR(t)xt −re
t + u1
t + u2
t + xtery
t eπt
−xt[ri
t −re
t] + xt((σe)2 + (σi)2) −(σe)2]dt
+
 xt eπT
t eΣy
t −σe(1 −xt) −σixt

dWt
= xt[rR(t) + re
t −ri
t + (σe)2 + (σi)2 + ery
t
T
eπt]dt +
+[u1
t + u2
t −re
t −(σe)2]dt
+
h
(σe)2(1 −xt)2 + (σi)2(xt)2 + (xt)2 eπT
t eCt eπt
i1/2
dWt,
for stochastic W : Ω× T →R that is a standard Brownian motion. Note that in the drift of
the SDE (13), the term
−re
t + xtre
t = −re
t(xt −1),
appears because it models the effect of depreciation of both HQLAs and NCOs. Similarly,
the term −(σe)2 + xt(σe)2 = (σe)2(xt −1) appears.
The predictions made by our previously constructed model are consistent with the empirical
evidence in contributions such as [13]. For instance, in much the same way as we do, [13]
describes how NCOs affect LCRs. On the other hand, to the best of our knowledge, the
modeling related to collateral and LCR reference processes (see Section 3 for a comprehensive
discussion) have not been tested in the literature before.
3. Optimal Basel III liquidity coverage ratios
In order to determine an optimal cash injection rate (seen as an adjustment to the normal
provisioning rate) and HQLA allocation strategy, it is imperative that a well-deﬁned objective
function with appropriate constraints is considered. The choice has to be carefully made in
order to avoid ambiguous solutions to our stochastic control problem (compare with [10]).
3.1. The optimal bank LCR problem
As in [10], in our contribution, we choose to determine a control law g(t, xt) that minimizes
the cost function J : GA →R+, where GA is the class of admissible control laws
Dynamic Programming and Bayesian Inference, Concepts and Applications
76

GA = {g : T × X →U|g Borel measurable
(14)
and there exists an unique solution to the closed-loop system},
with the closed-loop system for g ∈GA being given by
dxt = Atxtdt +
n
∑
j=0
Bjxtgj(t, xt)dt + atdt
+
3
∑
j=1
Mj(g(t, xt))xtdWj
t, x(t0) = x0.
(15)
Furthermore, the cost function, J : GA →R+, of the LCR problem is given by
J(g) = E
 Z t1
t0
exp(−r f (l −t0))b(l, xl, g(l, xl))dl
+ exp(−r f (t1 −t0))b1(x(t1))

,
(16)
where g ∈GA, T = [t0, t1] and b1 : X →R+ is a Borel measurable function (compare with
[10]). Furthermore, b : T × X × U →R+ is formulated as
b(t, x, u) = b2(u2) + b3(x1/x2),
for b2 : U2 →R+ and b3 : R+ →R+. Also, r f ∈R is called the NCO forecasting rate, where
b1, b2 and b3 are chosen below. In order to clarify the stochastic problem, the following
assumption is made.
Assumption 3.1. (Admissible Class of Control Laws) Assume that GA ̸= ∅.
We are now in a position to state the stochastic optimal control problem for a continuous-time
LCR model that we solve (compare with [10]).
The said problem may be formulated as
follows.
Problem 3.2. (Optimal Bank LCR Problem) Consider the stochastic system (15) for the LCR
problem with the admissible class of control laws, GA, given by (14) and the cost function, J : GA →
R+, given by (16). Solve
inf
g∈GA
J(g),
Optimizing Basel III Liquidity Coverage Ratios
http://dx.doi.org/10.5772/58395
77

that amounts to determining the value J∗, given by
J∗= inf
g∈GA
J(g),
and the optimal control law g∗, if it exists,
g∗= arg min
g∈GA
J(g) ∈GA.
3.2. Optimal bank LCRs in the simpliﬁed case
In this section, we determine a solution to Problem 3.2 in the case where the term
[t0, t1] is ﬁxed.
In order to ﬁnd the optimal control processes, we use the dynamic
programming algorithm for stochastic optimization where we consider an appropriate
Hamilton-Jacobi-Bellman equation (HJBE). In the sequel, we assume that the optimal control
laws exist, with the objective function, J, given by (16) being continuous twice-differentiable.
Then a combination of integral calculus and Itô’s formula (see, for instance, [15]) shows that
the value function v satisﬁes (20) and (21).
Consider the simpliﬁed system (13) for the LCR problem with the admissible class of control
laws, GA, given by (14) but with X = R (compare with [10]). In this section, we have to solve
inf
g∈GA
J(g),
J∗= inf
g∈GA
J(g),
(17)
J(g) = E
 Z t1
t0
exp(−r f (l −t0))[b2(u2
t ) + b3(xt)]dt
+ exp(−r f (t1 −t0))b1(x(t1))

,
(18)
where b1 : R →R+, b2 : R →R+ and b3 : R+ →R+ are all Borel measurable functions.
For the simpliﬁed case, the optimal cost function (17) is determined with the simpliﬁed cost
function, J(g), given by (18). In this case, assumptions have to be made in order to ﬁnd a
solution for the optimal cost function, J∗(compare with [10]). Next, we state an important
result about optimal bank coverager ratios in the simpliﬁed case.
Theorem 3.3. (Optimal Bank LCRs in the Simpliﬁed Case)
Suppose that g2∗and g3∗are the components of the optimal control law, g∗, that deal with the optimal
cash injection rate, u2∗, and optimal HQLA allocation, πk∗, respectively. Consider the nonlinear
optimal stochastic control problem for the simpliﬁed LCR system (13) formulated in Problem 3.2.
Suppose that the following assumptions hold.
Dynamic Programming and Bayesian Inference, Concepts and Applications
78

1. The cost function is assumed to satisfy
b2(u2) ∈C2( R),
lim
u2→−∞Du2b2(u2) = −∞,
lim
u2→+∞Du2b2(u2) = +∞;
(19)
Du2u2b2(u2) > 0, ∀u2 ∈R,
with the differential operator, D, that is applied in this case to function b2.
2. There exists a function v : T × R →R, v ∈C1,2(T × X ), that is a solution of the HJBE given
by
0 = Dtv(t, x) + 1
2[(σe)2(1 −x)2 + (σi)2(xt)2]Dxxv(t, x)
+x(rR(t) + re
t −ri
t + (σe)2 + (σi)2)Dxv(t, x)
+[u1
t −re
t −(σe)2]Dxv(t, x)
+u2
t
∗Dxv(t, x) + exp(−r f (t −t0))b2(u2
t
∗)
+ exp(−r f (t −t0))b3(x) −[Dxv(t, x)]2
2Dxxv(t, x)
ery
t
T eC−1
t
ery
t ,
(20)
v(t1, x) = exp(−r f (t1 −t0))b1(x),
(21)
where u2∗is the unique solution of the equation
0 = Dxv(t, x) + exp(−r f (t −t0))Du2b2(u2
t ).
(22)
Then the optimal control law is
g2∗(t, x) = u2∗, g2∗: T × X →R+,
(23)
with u2∗∈U2 the unique solution of the equation (22)
eπ∗= −Dxv(t, x)
xDxxv(t, x)
eC−1
t
ery
t ,
(24)
g3,k∗(t, x) = min{1, max{0, eπk∗}}, g3,k∗: T × X →R,
(25)
Furthermore, the value of the problem is
J∗= J(g∗) = E[v(t, x0)].
(26)
Optimizing Basel III Liquidity Coverage Ratios
http://dx.doi.org/10.5772/58395
79

Next, we choose a particular cost functions for which an analytic solution can be obtained
for the value function and control laws (compare with [10]). The following theorem provides
the optimal control laws for quadratic cost functions.
Theorem 3.4. (Optimal Bank LCRs with Quadratic Cost Functions): Consider the nonlinear
optimal stochastic control problem for the simpliﬁed LCR system (13) formulated in Problem 3.2.
Consider the cost function
J(g) = E
 Z t1
t0
exp(−r f (l −t0))[1
2c2((u2)2(l)) + 1
2c3(xt −lr)2]dl
+1
2c1(x(t1) −lr)2 exp(−r f (t1 −t0))

.
(27)
We assume that the cost functions satisfy
b1(x) = 1
2c1(x −lr)2, c1 ∈(0, ∞);
b2(u2) = 1
2c2(u2)2, c2 ∈(0, ∞);
(28)
b3(x) = 1
2c3(x −lr)2, c3 ∈(0, ∞),
(29)
lr ∈R, called the reference value of the LCR
Deﬁne the ﬁrst-order ODE
−˙qt = −(qt)2/c2 + c3 + qt2(rR(t) + re
t −ri
t + (σe)2 + (σi)2)
+qt[−r f −ery
t
T eC−1
t
ery
t + (σe)2 + (σi)2], qt1 = c1;
(30)
−˙xrt = −c3(xr
t −lr)/qt −xr
t[rR(t) + re
t −ri
t + (σe)2 + (σi)2]
−[u1
t −re
t −(σe)2] −(xr
t −1)((σe)2 + (σi)2) −(σi)2, xr(t1) = lr;
(31)
−˙lt = −r f lt + c3(xr
t −lr)2 −qt(σe)2(xr
t −1)2 −qt(σi)2(xr
t)2,
l(t1) = 0.
(32)
The function xr : T →R will be called the LCR reference (process) function. Then we have that
the following hold.
(a) There exist solutions to the ordinary differential equations (30), (31) and (32). Moreover, for all
t ∈T, qt > 0.
Dynamic Programming and Bayesian Inference, Concepts and Applications
80

(b) The optimal control laws are
u2∗
t = −(x −xr
t)qt/c2,
(33)
g2∗(t, x) = u2∗, g2∗: T × X →R+,
eπ∗
t = −(x −xr
t)
x
eC−1
t
ery
t , g3∗: T × X →Rk,
(34)
g3,k∗(t, x) =
 eπk∗,
if eπk∗∈[0, 1],
min{1, max{0, eπk∗
t }}, otherwise,
∀k ∈Zn.
(35)
(c) The value function and the value of the problem are
v(t, x) = exp(−r f (t1 −t0))[1
2(x −xr
t)2qt + 1
2lt],
(36)
J∗= J(g∗) = E[v(t0, x0)].
(37)
For the cost on the cash injection, the function (28) is considered, where the input variable u2
is restricted to the set R+. If u2 > 0 then the banks should acquire additional HQLAs. The
cost function should be such that cash injections are maximized, hence u2 > 0 should imply
that b2(u2) > 0. For Theorem 3.4 we have selected the cost function b2(u2) = 1
2c2(u2)2, given
by (28). Here, both positive and negative values of u2 are penalized equally. An important
reason for this is that an analytic solution of the value function can be determined (compare
with [10]).
The reference process, lr, may be 1 that is the threshold for the LCR standard. The cost on
meeting liquidity provisioning will be encoded in a cost on the LCR. If the LCR, x > lr,
is strictly larger than a set value lr, then there should be a strictly negative cost. If, on the
other hand, x < lr, then there may be a positive cost. We have selected the cost function
b3(x) = 1
2c3(x −lr)2 in Theorem 3.4 given by (29). This is also done to obtain an analytic
solution of the value function and that case by itself is interesting (see, for instance, [10] for
more details). Another cost function that we can consider is
b3(x) = c3[exp(x −lr) + (lr −x) −1],
that is strictly convex and asymmetric in x with respect to the value lr. For this cost function,
it is reasonable that costs with x > lr are penalized lower than those with x < lr. Another
cost function considered is to keep b3(x) = 0 for x < lr (see, for instance, [10]).
4. Numerical results for LCRs
In this section, we provide numerical-quantitative results about LCRs and their connections
with HQLAs and NCOs to supplement the theoretical-quantitative treatment in Sections 2
and 3 (see [13] for more details). More precisely, we describe the LCR data and descriptive
statistics for Class I and II banks for the sample period 2002 to 2012.
Optimizing Basel III Liquidity Coverage Ratios
http://dx.doi.org/10.5772/58395
81

4.1. Description of banking data
In this subsection, we describe the banking data pertaining to LCRs.
4.1.1. Class I and II banks
We investigate liquidity for Class I banks that hold more than US $ 4 billion in Tier 1 capital
(T1K) and are internationally active.
Moreover, we consider Class II banks that violate
one or both of these conditions (see, for instance, [9] and [17]). In reality, some Class II
banks considered could have been classiﬁed as Class I if they were internationally active.
Nevertheless, these banks make a large contribution to the total assets of Class II banks.
Invariably, all Class I banks can also be classiﬁed as large in that their gross total assets (GTA)
exceed US $ 3 billion. Many of the banks in our study come from jurisdictions afﬁliated to
the BCBS and Macro-Economic Assessment Group (MAG).
Our investigation includes 157 Class I and 234 Class II LIBOR-based banks from 38 countries.
These banks (with the number of Class I and Class II banks in parenthesis for each
jurisdiction, as well as * and ’ denoting BCBS and MAG members, respectively) are located in
Argentina* (1,3), Australia*’ (5,2), Austria (2,5), Belgium* (1,2), Botswana (1,1), Brazil*’ (3,1),
Canada*’ (7,3), China*’ (7,1), Czech Republic (4,3), Finland (0,14), France*’ (5,5), Germany*’
(7,24), Hong Kong SAR* (1,8), Hungary (1,2), India* (6,6), Indonesia* (1,3), Ireland (3,1),
Italy*’ (2,11), Japan*’ (14,5), Korea*’ (6,4), Luxembourg* (0,1), Malta (0,3), Mexico*’ (1,8),
Namibia (0,1), the Netherlands*’ (3,13), Norway (1,6), Poland (0,5), Portugal (3,3), Russia*
(0,3), Saudi Arabia* (4,1), Singapore* (5,0), South Africa* (4,5), Spain*’ (2,4), Sweden* (4,0),
Switzerland*’ (3,5), Turkey* (7,1), United Kingdom*’ (8,5) and United States*’ (35,66).
In
order to limit depositor losses, all 38 jurisdictions have explicit deposit insurance schemes or
implicit government protection schemes for banks.
4.1.2. Banking data restrictions
In our study, we did not consider Central Banks, subsidiaries, banks with incomplete
(inconsistent or non-continuous) information nor observations with negative HQLA, NCO,
ASF, RSF or other values (see, for instance, [9] and [17]). Furthermore, we use non-permanent
samples that do not suffer from survivorship bias to study cross sectional patterns. For our
sample, bank failure data for the period 2002 to 2012 was obtained from deposit insurance
schemes or implicit government protection schemes. For instance, for the US, such data was
obtained from the Federal Deposit Insurance Corporation (see [9] and [17] for more details).
We choose the period 2002-2012 because available EMERG global liquidity data does not
allow us to reliably determine the LCR and NSFR prior to 2002 (see, for instance, [9] and
[17]).
4.1.3. Banking data computations
Estimating the LCR and NSFR using available EMERG public data proved to be a challenge.
Firstly, the prescripts for these risk standards are sometimes ambiguous and subject to
frequent regulatory amendment. For instance, the ﬁnal rules relating to the LCR were only
published on Monday, 7 January 2013.
Dynamic Programming and Bayesian Inference, Concepts and Applications
82

Secondly, the EMERG global banking data has several limitations in terms of granularity and
format when compared with the information required to determine the Basel III liquidity
standards (see, for instance, [9] and [17]). In all instances, we had to make difﬁcult choices
when applying Basel III guidelines to such a large diversity of banks.
In the absence of suitable data, we were heavily dependent on the interpolation and
extrapolation techniques discussed below. Firstly, it is clear that the LCR calculation requires
information about liabilities with a remaining maturity of less than 1 month.
However,
quarterly EMERG data provides information about liabilities with a remaining maturity of
less than 3 months. So we had to extrapolate the liabilities with a remaining maturity of 1
month. There are two approaches to doing this. In the ﬁrst instance, we can assume the
maturity schedule is evenly distributed, such that the amount of liabilities with a remaining
maturity of less than 1 month equals 1/3 of the amount of liabilities with a remaining
maturity of less than 3 months. This is the approach adopted in this chapter. Secondly, as a
robustness check, we can assume an extreme case, such that all liabilities with a remaining
maturity within 3 months mature within the ﬁrst month. In this instance, the guidelines
require dividing liabilities into subcategories of retail deposits, unsecured wholesale funding
and secured funding with different run-off rates (see, for instance, [9] and [17]). However,
the information available from the EMERG global data lacks such granularity.
Out of
necessity, we have to make assumptions on the distribution of subcategories within their
primary category. Without additional information, we generally assume equal distribution
of subcategories within the primary category , . Finally, except for unused commitments,
letters of credit and the net fair value of derivatives, we do not have the information required
for calculating the liquidity needs of all other OBS items, such as increased liquidity needs
related to downgrade triggers embedded in ﬁnancing transactions, derivatives and other
contracts. Therefore, our calculations of the LCR and NSFR are partial measures that capture
a bank’s liquidity risk as mainly reﬂected by its BS and to a lesser extent its OBS items (see
[9] and [17] for more information).
4.2. 2002 to 2012 LCRs for class I and II banks
In this subsection, we provide 2002 to 2012 LCRs for Class I and II banks.
Table 1 shows that the LCR has been in a downward trend from 2002 through 2007. The
average LCR had risen sharply from 2007 to 2009 and peaked in 2009. The general impression
from Figure 1 is that the LCR time series is non-stationary.
4.3. Descriptive statistics for LCRs of class I and II banks
In this subsection, we provide 2002 to 2012 LCR descriptive statistics for Class I and II banks.
Table 2 reports the summary statistics of the approximate measures of the LCR for Class
I banks, where the mean for the LCR is 74.96 %. In this table, the LCR displays positive
skewness. The value of the kurtosis for the LCR in Table 2 is equal to or less than 3, that
means that the distribution is ﬂat. The LCR risk measure exhibits normality because the
p-values are greater than 5 %. Nevertheless, the normality test is very sensitive to the number
of observations and may only produce desirable and efﬁcient results if observations are large.
From Table 2, it is clear that, in the absence of empirical evidence, it is hard to conclude that
the Basel III LCR standard had complied with these standards.
Optimizing Basel III Liquidity Coverage Ratios
http://dx.doi.org/10.5772/58395
83

Bank Class
Bank Class
Quarter
Class I
Class II
Quarter
Class I
Class II
02Q1
0.81832
0.84588
02Q2
0.79516
0.82194
02Q3
0.8264
0.85386
02Q4
0.86464
0.89376
03Q1
0.78884
0.77406
03Q2
0.74112
0.76608
03Q3
0.7334
0.7581
03Q4
0.71024
0.73416
04Q1
0.6562
0.6783
04Q2
0.62532
0.64638
04Q3
0.63304
0.65436
04Q4
0.6176
0.6384
05Q1
0.62532
0.64638
05Q2
0.6176
0.6384
05Q3
0.60988
0.63042
05Q4
0.6176
0.6384
06Q1
0.59444
0.61446
06Q2
0.57128
0.59052
06Q3
0.57128
0.59052
06Q4
0.54812
0.56658
07Q1
0.5404
0.5586
07Q2
0.579
0.5985
07Q3
0.55584
0.51456
07Q4
0.54812
0.56658
08Q1
0.72568
0.75012
08Q2
0.74884
0.77406
08Q3
0.74884
0.77406
08Q4
0.74412
0.76608
09Q1
0.88008
0.90972
09Q2
0.95728
1.08114
09Q3
1.02676
1.06134
09Q4
0.91566
0.99753
10Q1
0.93412
0.96558
10Q2
0.95376
0.96184
10Q3
0.96552
0.92568
10Q4
0.97868
0.94962
11Q1
0.98324
0.93366
11Q2
0.99288
0.91566
11Q3
0.99692
0.98578
11Q4
1.02391
1.08113
12Q1
1.07414
1.16982
12Q2
1.10664
1.19376
12Q3
1.16849
1.23778
12Q4
1.19281
1.29002
Table 1. 2002 to 2012 LCRs for Class I and II Banks
Descriptive Statistics of LCR for Class I and II Banks
Parameter
Class I LCR
Class II LCR
Mean
0.748720
0.773430
Median
0.748840
0.774060
Maximum
1.026760
1.061340
Minimum
0.540400
0.514560
Std. Dev.
0.027670
0.143466
Skewness
0.027670
-0.02945
Kurtosis
1.825270
1.855696
Jarque-Bera
2.535599
2.406985
Probability
0.281450
0.300144
Sum
32.94368
34.03091
Sum Sq. Dev.
0.794993
0.885043
Observations
44
44
Table 2. Descriptive Statistics of LCR for Class I and II Banks
Dynamic Programming and Bayesian Inference, Concepts and Applications
84

5. Conclusions and future directions
In this section, we draw conclusions about the LCR modeling and optimization and related
numerical examples. Furthermore, we suggest possible topics for future research.
5.1. Conclusions
In this subsection, we make conclusions about the LCR model, optimal Basel III LCRs and
numerical results for LCRs.
5.1.1. Conclusions about the LCR model
One of the main contributions of this book chapter is the way the LCR dynamics model is
constructed by using stochastic techniques. This model depends on HQLAs, NCOs as well
as the liquidity provisioning rate. We believe that this is an addition to pre-existing literature
because it captures some of the uncertainty associated with LCR variables. In this regard, we
provide a theoretical-quantitative modeling framework for establishing bank LCR reference
processes and the making of decisions about liquidity provisioning rates and asset allocation.
In Subsecdtion 2.1, we mention the possibility of adjusting the cash injection rate depending
on whether the bank is experiencing deﬁcit or surplus liquidity. The latter occurs where
cashﬂows into the banking system persistently exceed withdrawals of liquidity from the
market by the central bank. This is reﬂected in holdings of reserves in excess of the central
bank’s required reserves.
Transitional economies, for example, often attract large capital
inﬂows as the economy opens and undergoes privatization. The effect of these inﬂows on
liquidity is often magniﬁed by central bank intervention in the foreign exchange market when
there is upward pressure on the domestic currency. In the wartime economy, consumption
is restricted and large amounts of involuntary savings accumulate until goods and services
eventually become more widely available. Soviet-style economies have displayed widespread
shortages and administered prices. This creates a situation of repressed inﬂation, whereby
prices are too low relative to the money stock, leaving individuals with excess real balances.
The importance of surplus liquidity for central banks is threefold and lies in its potential
to inﬂuence: (1) the transmission mechanism of monetary policy; (2) the conduct of central
bank intervention in the money market, and (3) the central bank’s balance sheet and income.
5.1.2. Conclusions about optimal basel III LCRs
We obtained an analytic solution to an optimal bank LCR problem with a quadratic objective
function. In principle, this solution can assist in managing LCRs. Here, liquidity provisioning
and HQLA allocation are expressed in terms of a reference process. To our knowledge such
processes have not been considered for LCRs before. This chapter makes a clear connection
between liquidity and ﬁnancial crises in a numerical-quantitative framework.
An interpretation of the control laws given by (33) and (34) follows.
In times of deﬁcit,
the cash injection rate, u2∗, is proportional to the difference between the LCR, x, and the
reference process for this ratio, xr. The proportionality factor is qt/c2 that depends on the
relative ratio of the cost function on u2 and the deviation from the reference ratio, (x −xr).
The property that the control law is symmetric in x with respect to the reference process
xr is a direct consequence of the cost function br(x) =
1
2c3(x −xr)2 being symmetric
Optimizing Basel III Liquidity Coverage Ratios
http://dx.doi.org/10.5772/58395
85

with respect to (x −xr). The optimal portfolio distribution is proportional to the relative
difference between the LCR and its reference process, (x −xr
t)/x. This seems natural. The
proportionality factor is eC−1
t
ery
t that represents the relative rates of asset return multiplied
with the inverse of the corresponding variances. It is surprising that the control law has
this structure. Apparently the optimal control law is not to liquidate ﬁrst all HQLAs with
the highest liquidity provisioning rate, then the HQLAs with the next to highest liquidity
provisioning rate, etc. The proportion of all HQLAs depend on the relative weighting in
eC−1
t
ery
t and not on the deviation (x −xr
t).
The novel structure of the optimal control law is the LCR reference process, xr : T →R. The
differential equation for this reference function is given by (31). This equation is new for the
area of LCR control and therefore deserves discussion. The differential equation has several
terms on its right-hand side that will be discussed separately. Consider the term
u1
t −re
t −(σe)2.
This represents the difference between normal rate of liquidity provisioning per monetary
unit of the bank’s NCOs and NCO outﬂows, where re
t is the rate of outﬂow per monetary
unit of NCOs. Note that if [u1
t −re
t −(σe)2] > 0, then the reference LCR function can be
increasing in time due to this inequality so that, for t > t1, xt < lr. The term c3(xr
t −lr)/qt
models that if the reference LCR function is smaller than lr, then the function has to increase
with time. The quotient c3/qt is a weighting term that accounts for the running costs and for
the effect of the solution of the Riccati differential equation. The term
xr
t[rR(t) + re
t −ri
t + (σe)2 + (σi)2],
accounts for two effects.
The difference re
t −ri
t is the nett effect of the rate of outﬂows
per monetary unit of the bank’s NCOs, re, and rate of NCO increase before outﬂows per
monetary unit of NCOs, ri
t. The term rR(t) + (σe)2 + (σi)2 is the effect of NCO increase due
to the reserves and the variance of riskier liquidity provisioning. The last term
(xr
t −1)((σe)2 + (σi)2) −(σi)2,
accounts for the effect on HQLAs and NCOs. More information is obtained by streamlining
the ODE for xr. In order to accompolish this it is necessary to assume the following.
Assumption 5.1. (Liquidity Parameters): Assume that the parameters of the problem are all
time-invariant and also that q has become constant with value q0.
Then the differential equation for xr can be rewritten as
Dynamic Programming and Bayesian Inference, Concepts and Applications
86

−˙xrt = −k(xr
t −m), xr(t1) = lr;
k = (rR + re −ri + 2((σe)2 + (σi)2)) + c3/q0;
m =
lrc3/q0 −(u1 −re −(σe)2) + (σe)2
(rR + re −ri + 2((σe)2 + (σi)2)) + c3/q0 .
Because the ﬁnite horizon is an artiﬁcial phenomenon to make the optimal stochastic control
problem tractable, it is of interest to consider the long term behavior of the LCR reference
trajectory, xr. If the values of the parameters are such that k > 0 then the differential
equation with the terminal condition is stable. If this condition holds then limt↓0 qt = q0
and limt↓0 xr
t = m where the down arrow prescribes to start at t1 and to let t decrease to 0.
Depending on the value of m, the control law for at a time very far away from the terminal
time becomes then,
u2∗
t
= −(xt −m)q0/c2 =
 > 0, if xt < m,
< 0, if xt > m,
π∗
t = −(xt −m)
xt
eCerj =
 > 0, if xt < m,
< 0, if xt > m, if π∗< 0 then set π∗= 0,
The interpretation for the two cases follows below.
Case 1 (xt > m): Then the LCR x is too high. This is penalized by the cost function hence
the control law prescribes not to invest in riskier HQLAs. The payback advice is due to
the quadratic cost function that was selected to make the solution analytically tractable. An
increase in liquidity provisioning will increase NCOs that, in turn, will lower the LCR.
Case 2 (xt < m): The LCR x is too low. The cost function penalizes and the control law
prescribes to invest more in riskier HQLAs. In this case, more funds will be available and
credit risk on the balance sheet will decrease. Thus higher valued HQLAs should be held.
On the other hand, when banks hold less HQLAs, they should decrease their NCOs that may
lead to higher LCRs.
5.1.3. Conclusions about numerical results for LCRs
We approximate the Basel III standard, LCR, that is a measure of asset liquidity for global
EMERG banking data mentioned earlier This is a challenging task given the nature of the
data available and the ever-changing nature of Basel III liquidity regulation. In the light
of the determined results, our analysis gives us a new understanding of the problem of
approximating liquidity risk measures. From Table 1, we observe that from Q209 to Q412
there was a steady increase in the LCR. This is probably due to banks holding more liquid
assets and restricting cash outﬂows and risky activities.
In this paragraph, we highlight how our research on approximating Basel III and traditional
liquidity risk measures has advanced the knowledge in this ﬁeld of endeavor. For both Class I
and II banks, our research approximates LCRs for a large diversity of banks for an extended
Optimizing Basel III Liquidity Coverage Ratios
http://dx.doi.org/10.5772/58395
87

that amounts to determining the value J∗, given by
J∗= inf
g∈GA
J(g),
and the optimal control law g∗, if it exists,
g∗= arg min
g∈GA
J(g) ∈GA.
3.2. Optimal bank LCRs in the simpliﬁed case
In this section, we determine a solution to Problem 3.2 in the case where the term
[t0, t1] is ﬁxed.
In order to ﬁnd the optimal control processes, we use the dynamic
programming algorithm for stochastic optimization where we consider an appropriate
Hamilton-Jacobi-Bellman equation (HJBE). In the sequel, we assume that the optimal control
laws exist, with the objective function, J, given by (16) being continuous twice-differentiable.
Then a combination of integral calculus and Itô’s formula (see, for instance, [15]) shows that
the value function v satisﬁes (20) and (21).
Consider the simpliﬁed system (13) for the LCR problem with the admissible class of control
laws, GA, given by (14) but with X = R (compare with [10]). In this section, we have to solve
inf
g∈GA
J(g),
J∗= inf
g∈GA
J(g),
(17)
J(g) = E
 Z t1
t0
exp(−r f (l −t0))[b2(u2
t ) + b3(xt)]dt
+ exp(−r f (t1 −t0))b1(x(t1))

,
(18)
where b1 : R →R+, b2 : R →R+ and b3 : R+ →R+ are all Borel measurable functions.
For the simpliﬁed case, the optimal cost function (17) is determined with the simpliﬁed cost
function, J(g), given by (18). In this case, assumptions have to be made in order to ﬁnd a
solution for the optimal cost function, J∗(compare with [10]). Next, we state an important
result about optimal bank coverager ratios in the simpliﬁed case.
Theorem 3.3. (Optimal Bank LCRs in the Simpliﬁed Case)
Suppose that g2∗and g3∗are the components of the optimal control law, g∗, that deal with the optimal
cash injection rate, u2∗, and optimal HQLA allocation, πk∗, respectively. Consider the nonlinear
optimal stochastic control problem for the simpliﬁed LCR system (13) formulated in Problem 3.2.
Suppose that the following assumptions hold.
Dynamic Programming and Bayesian Inference, Concepts and Applications
88

availability of more suitable data of sufﬁcient granularity as well as improved extrapolation
and interpolation techniques.
We have already made several contributions in support of the endeavors outlined in the
previous paragraph. For instance, our journal article [12] deals with issues related to liquidity
risk and the ﬁnancial crisis. Also, the role of information asymmetry in a subprime context
is related to the main hypothesis of the book [14].
Author details
J. Mukuddem-Petersen1, M.A. Petersen1 and MP. Mulaudzi*2
*Address all corespodence to mulaump@unisa.ac.za
Faculty of Commerce and Administration, North West University, South Africa
Department of Decision Sciences, University of South Africa
References
[1] Basel
Committee
on
Banking
Supervision
(January
2013).
Basel
III:
The
liquidity
coverage
ratio
and
liquidity
risk
monitoring
tools.
Bank
for
International Settlements (BIS) Publications.
Retrieved Monday, 25 March 2013
(http://www.bis.org/publ/bcbs238.htm).
[2] Basel Committee on Banking Supervision (October 2011). Progress report on Basel III
implementation. Bank for International Settlements (BIS), Basel, Switzerland. Retrieved
April 25, 2012, from http://www.bis.org/publ/bcbs193.htm.
[3] Basel Committee on Banking Supervision (BCBS). (June 2011).
Basel III: A global
regulatory framework for more resilient banks and banking systems – A revised version
June 2011. June 2011. Bank for International Settlements (BIS) Publications. Retrieved
Monday, 25 March 2013 (http://www.bis.org/publ/bcbs189.htm).
[4] Basel Committee on Banking Supervision (December 2010).
Basel III: International
framework for liquidity risk measurement, standards and monitoring.
Bank for
International Settlements (BIS), Basel, Switzerland.
Retrieved April 25, 2012, from
http://www.bis.org/publ/bcbs188.htm.
[5] Basel
Committee
on
Banking
Supervision
(September
2008).
Principles
for
sound
liquidity
risk
management
and
supervision.
Bank
for
International
Settlements
(BIS),
Basel,
Switzerland.
Retrieved
April
25,
2012,
from
http://www.bis.org/publ/bcbs144.htm.
[6] Demyanyk Y, van Hemert O. Understanding the subprime mortgage crisis. Review of
Financial Studies, 2011; 24(6), 1848-1880.
[7] Elyasiani E, Mester LJ, Pagano MS, Large Capital Infusions, Investor Reactions, and the
Return and Risk-Performance of Financial Institutions Over the Business Cycle (May 3,
Optimizing Basel III Liquidity Coverage Ratios
http://dx.doi.org/10.5772/58395
89

2013). FRB of Philadelphia Working Paper No. 13-23. Retrieved January 28, 2014, from
http://ssrn.com/abstract=2269223 or http://dx.doi.org/10.2139/ssrn.2269223
[8] Gorton GB. Information, liquidity, and the (ongoing) panic of 2007, American Economic
Review, Papers and Proceedings, vol. 99, no. 2 (May 2009), 567-572.
[9] Hong H, Huang J, Wu D. The information content of Basel III liquidity risk measures.
Retrieved Monday, 2 December 2013, from: http://ssrn.com/abstract=2177614.
[10] Mukuddem-Petersen J, Petersen MA (2008). Optimizing Asset and Capital Adequacy
Management in Banking,
Journal of Optimization Theory and Applications 137(1),
205-230.
[11] Petersen MA, De Waal B, Hlatshwayo LNP, Mukuddem-Petersen J (2013). A Note on
Basel III and Liquidity. Applied Economic Letters 20(8), 777–780.
[12] Petersen MA, De Waal B, Mukuddem-Petersen J, Mulaudzi MP. Subprime mortgage
funding and liquidity risk,
Quantitative Finance,
doi: 10.1080/14697688.2011.637076,
2012.
[13] Petersen MA, Mukuddem-Petersen J. Basel III Liquidity Regulation and Its Implications,
Business Expert Press, McGraw-Hill, New York, 2014, ISBN: 978-1-60649-872-9 (print);
ISBN: 978-1-60649-873-6 (ebook).
[14] Petersen MA, Senosi MC, Mukuddem-Petersen J. Subprime Mortgage Models, New
York: Nova, ISBN: 978-1-61728-694-0, 2012.
[15] Soner HM, Fleming WH. (2008). Controlled Markov Processes and Viscosity Solutions,
2nd Edition, New York: Springer Verlag.
[16] van den End JW, Tabbae M. When liquidity risk becomes a systemic issue: Empirical
evidence of bank behaviour,
Journal of Financial Stability, doi:10.1016/j.jfs.2011.05.003,
2012.
[17] Wu D, Hong H. The information value of Basel III liquidity risk measures. Retrieved
Friday, 29 November 2013, from: http://ssrn.com/abstract=2177614.
Dynamic Programming and Bayesian Inference, Concepts and Applications
90

Chapter 4
Risk-Constrained Forward Trading Optimization by
Stochastic Approximate Dynamic Programming
Miguel Gil-Pugliese and Fernando Olsina
Additional information is available at the end of the chapter
http://dx.doi.org/10.5772/57466
1. Introduction
Since the mid-twentieth century, Dynamic Programming (DP) has proved to be a flexible and
powerful approach to address optimal decisions problems. Nevertheless, a decisive drawback
of the conventional DP is the need for exploring the whole state space in order to find the
optimal solution. The immense amount of mathematical operations involved to solve real-scale
problems, constrained the application of DP to small or highly simplified cases. Indeed, state
space grows exponentially with the number of variables when considering multivariate
optimization. The curse of dimensionality is a well-known limitation of conventional DP
algorithms for tackling large-scale problems ubiquitous in real science and engineering
applications.
In the last decades, many new algorithms emerged in different branches of science to overcome
the inherent limitations of conventional DP. Unlike conventional DP, these algorithms avoid
enumerating and calculating every possible state of a system during the optimization process.
Instead, they estimate relevant features of the state space. This approach circumvents the
dimensionality limitations of the conventional DP while retaining many of its advantages.
In this chapter, the application of advanced stochastic dynamic programming techniques to
the optimization of the forward sell strategy of a power generator subjected to delivery risk is
considered. The proposed approach allows rebalancing the portfolio during the period of
analysis. In electricity markets, a power generator can sell in advance part or all its future
energy production at a fixed price, hedging against the high price volatility of the spot market.
The strategy of eliminating the price risk by selling in advance the entire production in the
forward market to a fixed price is often thought as the minimum-risk trading policy. None‐
theless, it can be proven that this is not the case for most generators. The outages of the
generation units and transmission lines, as well as unforeseen limitations in the primary energy

supply expose generators to delivery risk [1]. Delivery risk considerably modifies the proba‐
bility distribution of profits, shifting the optimal trading strategy toward a portfolio mixing
forward contracts and power sold in the spot market. Because of the size of the probability
state space and the limited computing capabilities, the problem of the optimal trading strategy
has not a closed form solution and thus, its determination is matter of current study. The
increase in computing power and recent developments in Operational Research has brought
new insights into the solution of such problems.
In the past decade and by virtue of the ever increasing computational power, many methods
emerged in different scientific fields with several different names: Reinforced Learning, Q-
Learning, Neuro-Dynamic Programming, etc. All these methods were later brought together
in what is currently known as Approximated Dynamic Programming (ADP) [2],[3]. These
algorithms resign the exhaustive enumeration and calculation of the space-state typically
performed by conventional DP. Instead, they iteratively approximate a function of the space
state through stochastic simulation and statistical regression techniques, circumventing the
dimensionality problem of DP.
Although ADP algorithms are being used in several other fields of science, the application to
design optimal trading strategies in power markets has not been proposed so far. In this
chapter, ADP techniques are exploited to optimize the selling strategy of a power generator
trading in a frictional market with transaction costs. Three available products are considered:
selling in the spot market, and/or get involved in quarterly and one-year forward contracts.
The objective of the generator is to maximize the expected profit while limiting financial risk.
Decisions can be made only at the beginning of each month. At each decision stage, the current
trading position can be changed at a cost in order to rebalance the portfolio.
2. Approximate dynamic programming
In the field of decision making, it is often useful to assess what could be expected from each
possible decision given the information available. After evaluating the outcome of each
alternative decision, a simple comparison is enough to take the optimal course of action. This
approach is straightforward but also naive. Real problems often present simply too many
possible options to evaluate. Moreover, if the problem involves sequential decision stages, the
number of possible solution paths scales up exponentially. Finally, outcomes are frequently
subjected to uncertainty. So, several outcomes could present themselves for each decision,
augmenting further the size of the problem.
Therefore, in order to keep the size of the problem within reach, shortcuts and simplifications
areoften necessary. Dynamic Programming (DP) is a clever way to reduce the number of
options based on Bellman´s Principle of Optimality: “An optimal policy has the property that
whatever the initial state and initial decision are, the remaining decisions must constitute an
optimal policy with regard to the state resulting from the first decision” [4]. This leads to the
fact that from any given state there is an optimal decision trajectory that once solved can be
used for every other path containing that state. Therefore for each state is only necessary to
Dynamic Programming and Bayesian Inference, Concepts and Applications
92

hold the information of the best solution until the end, ruling out suboptimal options. This
rule prevents the exponential growth in the decision sequence path, scaling the problem only
linearly.
Yet, other reasons of explosive dimensionality growth remain, namely the number of states,
as well as decision and outcome spaces. For small financial decision problems, conventional
DP algorithms are able to find the optimal policy. For real-scale problems, gross simplifications
are often necessary to keep tractability. Sometimes, these simplifications render the model
unrealistic turning results meaningless.
Finding an appropriate combination of financial instruments in a portfolio can be portrayed
as a Markov Decision Problem (MDP). A MDP is defined as a succession of states that are
reached through decisions (actions) followed by an outcome (reaction) of the system. After
each decision, the system evolves into another state, according probabilities defined by the
previous state and the decision taken. Each transition between states has a cost, usually
dependent on the action taken, and a reward produced by the reaction of the system, as
depicted in Figure 1. In these processes, a decision maker should choose a sequence of actions
so that the expected sum of rewards minus the sum of incurred costs is maximized over a
certain period of time.
 
ݏݐܽݐ݁௧ାଵ 
ݒ݈ܽݑ݁௧ାଵ 
 
ݏݐܽݐ݁௧ 
ݒ݈ܽݑ݁௧ 
ܽܿݐ݅݋݊ 
ܴ݁ݓܽݎ݀െܥ݋ݏݐ
Figure 1. Markov Decision Process depiction
According to the Bellman´s Principle of Optimality, for every MDP can be determined a series
of Value Functions, which represents the continuation value of each state. The continuation
value associated to a given state is the expected sum of rewards that the optimal strategy would
yield from that state until the end of the process (or the expected average reward if the MDP
is infinite).
It is easy to see how the value functions of a MDP can be found using a classic backwards DP
algorithm. Starting from the final states, a DP algorithm exhaustively calculates the continu‐
ation value for a discrete number of states. All these continuation values, collected in a lookup
table, constitute later the Value Functions which are accurate but not very compact or easy to
calculate. After acquiring the Value Functions, it is simple to find an optimal decision for each
state as the one that maximizes the sum of the expected reward and the expected continuation
value of the next state or states. However, the problems that a DP algorithm can address by
this procedure are restricted by the size of their state spaces.
Risk-Constrained Forward Trading Optimization by Stochastic Approximate Dynamic Programming
http://dx.doi.org/10.5772/57466
93

Other forms to represent and/or approximate the Value Functions can then be proposed. These
approaches should not require exhaustive calculation of every state. The Value Functions can
be interpolated between computed states. Approximate Dynamic Programming algorithms are
built on this cornerstone: approximation of the Value Functions in the state space domain. The
estimation methods can be linear regressions, artificial neural networks, etc. Several authors
make detailed analysis of MDPs and the use of ADP and DP algorithms to solve them [2],[3].
For approximating and updating the Value Functions, the proposed algorithm uses linear
regression on Gaussian radial basis functions jointly with Monte Carlo simulations to consider
randomness. An interior-point optimization algorithm is implemented to make decisions.
The ADP algorithm starts with a series of approximations of the value functions, usually
constant. Then taking a Monte Carlo sample, a simulation of the system is conducted. At each
decision stage, the algorithm makes a decision that is optimal regarding to the current state
and the available approximations. Finally, after each Monte Carlo simulation, decisions and
outcomes are used to refine the estimation of the Value Functions and complementary Risk
Functions, denoted by Vt and Rt respectively. The process continues iteratively, until a certain
termination criterion is fulfilled. A simple diagram of this approach is illustrated in Figure 2.
For Monte Carlo sample ݓ
For all periods ݐ
Update approximations ܸ௧ and ܴ௧ for state and strategy
Strategy: max ܸ௧, ܴ௧൑ܴ௠௔௫
Determination of state variables ݏ௧
௪
Simulation period ݐ
Profit (Profit Period t + max ܸ௧ାଵ)
New datapoint
Terminate
Figure 2. Simulation and estimation update as performed by the proposed ADP algorithm
2.1. Regression technique
An approximation of a system involves finding a function that can predict the output values
for a given set of inputs. In this case, the inputs are the state variables and the decision and the
outputs are the continuation value and risk.
Dynamic Programming and Bayesian Inference, Concepts and Applications
94

To approximate the value and risk functions one could use several methods such as linear
regressions, artificial neural networks, splines, etc. In the context of electricity trading, it will
be discussed how to use linear regression with radial basis functions. The same principles and
techniques apply to any regression based on linear parameters.
The main feature of the algorithm is that the approximation is used to make decisions while
collecting new data to further improve the currently available approximation. Thus, it is
necessary that the regressed function fitting the data can be readily updated as new data is
simulated, making the improved approximations immediately available for the next simula‐
tion. To fulfill this requirement, a recursive regression technique can be used.
Let be a set of inputs X  and a set of collected data from outputs Y
1,1
1,2
1,
1,1
1,2
1,
1
1
2,1
2,2
2,
2,1
2,2
2,
2
2
,1
,2
,
,1
,2
,
 ,
¼
é
ù
¼
é
ù
é
ù
é
ù
ê
ú
ê
ú
ê
ú
ê
ú
¼
¼
ê
ú
ê
ú
ê
ú
ê
ú
=
=
=
=
ê
ú
ê
ú
ê
ú
ê
ú
ê
ú
ê
ú
ê
ú
ê
ú
¼
ê
ú
¼
ê
ú
ê
ú
ê
ú
ë
û
ë
û
ë
û
ë
û
M
M
O
M
M
M
M
M
O
M
g
h
g
h
n
n
n h
n
n
n
n
n g
x
x
x
y
y
y
x
x
x
y
y
y
y
y
y
x
x
x
x
y
x
y
X
Y
x
y
(1)
The matrix of inputs X  has n data points and g dimensions and the matrix of outputs Y  has
n data points and h  dimensions. Then, the approximation function is:
Y^ =∑
j=1
k
φj(X )⋅θ j =V (X )=
y^
1,1
y^
1,2
…
y^
1,h
y^
2,1
y^
2,2
…
y^
2,h
⋮
⋮
⋱
⋮
y^
n,1
y^
n,2 …
y^
n,h
=
y^
1
y^
2
⋮
y^
n
=φ(X )⋅θ  
(2)
( )
(
)
(
)
(
)
(
)
(
)
(
)
(
)
(
)
(
)
1
1
1
1
2
1
1
2
2
1
2
2
2
2
1
2
,
 
q
j
j
j
j
j
j
q
j
j
j
q
é
ù
é
ù
¼
é
ù
ê
ú
ê
ú
ê
ú
¼
ê
ú
ê
ú
ê
ú
=
=
=
= ê
ú
ê
ú
ê
ú
ê
ú
ê
ú
ê
ú
ê
ú
¼
ê
ú
ê
ú
ë
û
ë
û
ë
û
M
M
O
M
M
M
k
k
k
n
n
k
n
n
z
x
x
x
z
x
x
x
φ X
Z θ
x
x
x
z
(3)
Where the kernel functions φ(X ) transform the input variables X  into a k-dimensional space
and are in general non-linear. Here, it is important to notice that despite the fact the φ functions
are nonlinear, the approximation is still linear with respect the parameters θ. Therefore, the
regression parameters can easily be found by solving a linear system of equations.
The parameter vector θ that minimizes the mean quadratic error MQE of the estimated outputs
is:
1
T
T
T
 
-
é
ù
=
=
ë
û
θ
Z Z
Z Y
AZ Y
 
(4)
Risk-Constrained Forward Trading Optimization by Stochastic Approximate Dynamic Programming
http://dx.doi.org/10.5772/57466
95

1
T
-
é
ù
= ë
û
A
Z Z
(5)
The dimension of matrices X , Y  and Z increase as new points are simulated, and thus the
estimated parameters change as new data is collected. On the other hand, the algorithm needs
the approximation to get new data. One approach could be calculating the new parameters
after a number of simulations with equation (4) but it soon reveals impractical as an increasing
amount of data need to be stored. Instead, by storing only the matrix A and the parameter
vector θ, the matrix itself can recursively be updated jointly with the parameters, following
the process described in [2]:
In the i-th iteration, a new data point xi, yi is simulated and the matrices X  and Y  become:
1
1
 
,
 
-
-
é
ù
é
ù
=
=
ê
ú
ê
ú
ë
û
ë
û
i
i
i
i
i
i
X
Y
X
Y
x
y
(6)
Also the matrix Z becomes:
(
)
(
)
1
1
 
 
-
-
é
ù
é
ù
=
=
ê
ú
ê
ú
ê
ú
ë
û
ë
û
i
i
i
i
i
Z
φ X
Z
z
φ x
(7)
Replacing these values in (4):
1
T
T
T
 
-
é
ù
=
=
ë
û
i
i
i
i
i
i
i
i
θ
Z
Z
Z
Y
A Z
Y
 
(8)
1
1
1
T
T
T
T
1
1
-
-
-
-
-
é
ù
é
ù
é
ù
é
ù
é
ù
= ê
ú
ê
ú
ê
ú
ë
û
ë
û
ê
ú
ê
ú
ë
û
ë
û
ë
û
i
i
i
i
i
i
i
i
i
Z
Y
θ
Z
z
Z
z
y
z
 
(9)
1
T
T
T
T
1
1
1
1
-
-
-
-
-
é
ù
é
ù
=
+
+
ë
û
ë
û
i
i
i
i
i
i
i
i
i
θ
Z
Z
z
z
Z
Y
z
y
(10)
Using the Sherman-Morrison formula:
1
T
1
1
T
1
1
T
1
-
-
-
-
-
é
ù
+
=
-
ë
û
+
L
L
L
L
L
 u u 
u u
 
u 
 u
(11)
Where L  is a k ×k invertible matrix and u is a k-dimensional row vector:
Dynamic Programming and Bayesian Inference, Concepts and Applications
96

(
)
1
1
T
T
T
1
1
1
1
1
T
T
T
1
1
1
1
1
T
T
1
1
1
 
-
-
-
-
-
-
-
-
-
-
-
-
-
-
æ
ö
é
ù
é
ù
ç
÷
ë
û
ë
û
é
ù
=
-
+
ç
÷
ë
û
ç
÷
é
ù
+
ë
û
è
ø
i
i
i
i
i
i
i
i
i
i
i
i
i
i
i
i
i
Z
Z
z
z
Z
Z
θ
Z
Z
Z
Y
z
y
z
Z
Z
z
  
 
 
(12)
Replacing Zi−1TZi−1
−1= Ai−1
(
)
T
T
T
1
1
1
1
1
T
1
1
 
-
-
-
-
-
-
æ
ö
=
-
+
ç
÷
ç
÷
+
è
ø
i
i
i
i
i
i
i
i
i
i
i
i
i
A
z
z A
θ
A
Z
Y
z
y
z A
z
  
 
 
(13)
Naming ρi =
1
1 + zi  Ai−1  zi T  and distributing:
T
T
T
T
T
T
1
1
1
1
1
1
1
1
1
1
 
 
 
r
r
-
-
-
-
-
-
-
-
-
-
=
+
-
-
i
i
i
i
i
i
i
i
i
i
i
i
i
i
i
i
i
i
i
i
i
θ
A
Z
Y
A
z
y
A
z
z A
Z
Y
A
z
z A
z
y
  
  
(14)
Now, simplifying Ai−1Zi−1TYi−1=θi−1
T
T
T
T
1
1
1
1
1
1
 
 
 
 
r
r
-
-
-
-
-
-
=
-
-
+
i
i
i
i
i
i
i
i
i
i
i
i
i
i
i
i
i
θ
θ
A
z
z θ
A
z
z A
z
y
A
z
y
  
  
(15)
Taking common factor −ρi  Ai−1ziT of the last 3 terms:
T
T
1
1
1
1
1
 
 
r
r
-
-
-
-
é
ù
=
-
+
-
ê
ú
ë
û
i
i
i
i
i
i
i
i
i
i
i
i
i
θ
θ
A
z
z θ
z A
z
y
y
  
  
(16)
Replacing 
1
ρi =1 + zi  Ai−1 ziT:
(
)
T
T
T
1
1
1
1
1
 
 
1
 
r
-
-
-
-
-
é
ù
=
-
+
-
+
ê
ú
ë
û
i
i
i
i
i
i
i
i
i
i
i
i
i
i
i
θ
θ
A
z
z θ
z A
z
y
z A
z
y
  
  
 
(17)
T
T
T
1
1
1
1
1
 
 
 
r
-
-
-
-
-
é
ù
=
-
+
-
-
ë
û
i
i
i
i
i
i
i
i
i
i
i
i
i
i
i
i
θ
θ
A
z
z θ
z A
z
y
y
z A
z
y
  
  
 
(18)
Finally, canceling out we get a formula to update the parameter vector:
T
1
1
1
 
r
-
-
-
=
-
-
é
ù
ë
û
i
i
i
i
i
i
i
i
θ
θ
A
z
z θ
y
  
(19)
Risk-Constrained Forward Trading Optimization by Stochastic Approximate Dynamic Programming
http://dx.doi.org/10.5772/57466
97

Note that in order to update the approximations, it is needed to store and update only the
values of the matrix A and the parameter vector θ. The complete set of update formulas is
then:
T
1
1
1
 
r
-
=
+
i
i
i
i
z A
z
 
(20)
T
1
1
1
 
r
-
-
-
=
-
-
é
ù
ë
û
i
i
i
i
i
i
i
i
θ
θ
A
z
z θ
y
  
(21)
T
1
1
1
 
r
-
-
-
=
-
i
i
i
i
i
i
i
A
A
A
z
z A
  
(22)
By using the equations (20), (21) and (22), it is possible to update a regression while using it to
take decisions within the ADP algorithm without explicitly storing the entire dataset and
performing the matrix inversion after each Monte Carlo simulation. However, an important
issue arises at the start of the recursive process, namely the starting values for both the
parameter vector θ and the matrix A. One possibility is to carry first a number of simulations
with random decisions, and then use the data collected to calculate the starting values for θ
and A. Another option is to use a diagonal matrix:
1,1
2,2
,
0
0
0
0
0
0
 
¼
é
ù
ê
ú
¼
ê
ú
= ê
ú
ê
ú
¼
ê
ú
ë
û
M
M
O
M
i
k k
a
a
a
A
(23)
This option is usually simpler despite the fact that setting the absolute values of the elements
requires care and it is not always clear in the literature. To set suitable values, a closer look at
the regression formulas for matrix A is needed:
1
1
T
T
T
1
1
 
-
-
-
-
é
ù
é
ù
=
=
+
ë
û
ë
û
i
i
i
i
i
i
i
A
Z
Z
Z
Z
z
z
 
(24)
1
1
T
T
T
T
2
2
1
1
 
-
-
-
-
-
-
é
ù
é
ù
=
=
+
+
ë
û
ë
û
i
i
i
i
i
i
i
i
i
A
Z
Z
Z
Z
z
z
z
z
 
(25)
1
1
T
T
1
 
-
-
=
é
ù
ê
ú
é
ù
=
=
ë
û
ê
ú
ê
ú
ë
û
å
i
i
i
p
p
A
Z
Z
z
z
i
p
(26)
Dynamic Programming and Bayesian Inference, Concepts and Applications
98

(
)
(
)
(
)
1
2
,1
,1
,2
,1
,
2
,1
,2
,2
,2
,
1
2
,1
,
,2
,
,
-
=
é
ù
é
ù
¼
ê
ú
ê
ú
ê
ú
ê
ú
ê
ú
ê
ú
¼
= ê
ú
ê
ú
ê
ú
ê
ú
ê
ú
ê
ú
ê
ú
ê
ú
¼
ê
ú
ë
û
ë
û
å
M
M
O
M
p
p
p
p
p k
p
p
p
p
p k
i
p
p k
p
p k
p k
z
z
z
z
z
z
z
z
z
z
z
z
z
z
z
A
i
p
(27)
The matrix Ai is the inverse of a matrix sum whose diagonal elements are positive and
increasing with i. That means that the absolute value of the diagonal elements of A would in
general decrease as i increases. The relation factor between the starting value of all the elements
a j, j and the corresponding expected value of (1 / zp, j)2 controls how new values modify the
parameter vector θ.
(
)
2
,
,
1 /
  
j j
p j
a
z
d
é
ù
=
×
ê
ú
ë
û
E
(28)
Setting starting diagonal elements with a small δ value implies implies a large number of
iterations i. This would mean that the starting parameter vector represents already a large
amount of “fictional” data. In that case, any new real data sample will have little impact on
the parameter vector, and the convergence rate of the approximation might be significantly
slowed. On the other hand, setting initial diagonal values calculated with large δ enables the
algorithm to large modifications on the parameter vector as new data is collected, which could
cause instability of the parameter vector and in the decision computed, again reducing the
overall convergence rate. In practice, the factor δ depends on the problem and it must be
assessed accordingly. From extensive experimentation, values of δ between 1 and 1000 tend
to work most of the time.
For initializing the parameter vector θ0, it is usual to set a constant vector. Values obtained
from the formula Y^
s =φ(E(X ))⋅θ0 produce coherent results. It is important to notice that the
starting values of the parameter vector are important in cases where δ is small, while for a
large δ the starting vector value is lost in the first iterations.
2.2. Kernel functions
The approximations are highly influenced by the type and parameterization of the kernel
functions. These functions transform the original inputs xm,  1≤m≤g into a k-dimensional
space where a linear correlation between outputs and transformed inputs is more accurate.
There are several kernel functions, such as polynomial, trigonometric, logarithmic, radial basis,
etc. The algorithm proposed in this work uses Gaussian radial basis functions, whose general
formula is:
Risk-Constrained Forward Trading Optimization by Stochastic Approximate Dynamic Programming
http://dx.doi.org/10.5772/57466
99

φj(x)=e
−(α x−c j )2
(29)
where c j is 1xg vector called a center or centroid, with g being the number of input variables.
The functions measure the distance of each variable in the input state space to k centers and
then transform each distance using a Gaussian function. The Euclidean norm is typically used
to measure the distance. Nevertheless, any other norm can be considered.
The number and relative position of centers c j are important. The number of centers deter‐
mines the dimension of the matrices in the linear regression, and also the smoothing and over-
fitting properties of the approximation. There must be enough centers and they must be placed
to “cover” the entire state space, avoiding blanks in regions of interest while keeping the
number of centers to a minimum. A random setting of the centers in the state space can serve
in some cases. However, it is usually more appropriate to place the centers using techniques
such as Latin Hyper Cube Sampling, as it is done in the implemented algorithm.
2.3. ADP and linear regressions in the context of distributed computing
In the context of ADP, a large amount of the calculation is attributed to the Monte Carlo
simulations. Consequently, distributed computing techniques can be exploited to dramatically
improve and speed up the optimization. The optimal point between thread opening and result
gathering basically depends on the hardware system, network latency and simulation times.
With time-consuming simulations, it is often useful to parallelize the program after each
approximation update, leaving several threads gather more data in parallel before any update.
But if the simulation time is short, the overhead times to distribute the calculation are usually
larger than the speed up achieved through parallel simulation. In such cases, another approach
should be used. A practical approach is to run parallel ADP algorithms for the same problem
in several threads in order to combine and synchronize all approximations at regular time
intervals. The combination of the results of two or more independent threads is based on the
same mathematical basis as the recursive update, provided that the non-linear parametric
functions are identical for all threads.
As shown in equation (4), the optimal parameter vector is:
1
1
T
T
T
T
1
1
-
-
=
=
é
ù
é
ù
é
ù
ê
ú
ê
ú
=
=
×
ë
û
ê
ú
ê
ú
ë
û
ë
û
å
å
n
n
i
i
i
i
i
i
θ
Z Z
Z Y
z
z
z
y
 
(30)
1
T
T
1
1
,
,
-
=
=
=
=
=
é ù
ë û
å
å
n
n
i
i
i
i
i
i
θ
B
C B
z
z
C
z
y
 
(31)
where each zi and yi represent the transformed inputs and the outputs respectively of the i-th
simulation of a total of n data points. As i increases, the matrices B and C summarize all the
Dynamic Programming and Bayesian Inference, Concepts and Applications
100

regression data collected. The data simulated by several threads of ADP can be easily combined
using these matrices. As parallel ADP threads a and b gather different sets of data, the
parameter vectors that they approximate and update are different
1
1
T
T
1
1
-
-
=
=
é
ù
é
ù
é
ù
ê
ú
ê
ú
=
=
×
ë
û
ê
ú
ê
ú
ë
û
ë
û
å
å
v
v
a
a
a
i
i
i
i
i
i
θ
B
C
z
z
z
y
 
(32)
1
1
T
T
-
-
=
=
é
ù
é
ù
é
ù
ê
ú
ê
ú
=
=
×
ë
û
ê
ú
ê
ú
ë
û
ë
û
å
å
n
n
b
b
b
i
i
i
i
i v
i v
θ
B
C
z
z
z
y
 
(33)
However, saving the matrices B and C allows to recombine all the data later as
1
T
T
T
T
1
1
-
=
=
=
=
é
ù
é
ù
ê
ú
ê
ú
=
+
×
+
ê
ú
ê
ú
ë
û
ë
û
å
å
å
å
v
n
v
n
i
i
i
i
i
i
i
i
i
i v
i
i v
θ
z
z
z
z
z
y
z
y
 
(34)
1
-
é
ù
é
ù
=
+
×
+
ë
û
ë
û
a
b
a
b
θ
B
B
C
C
 
(35)
This result can be generalized to any number of parallel threads.
In general, data gathered from several parallel algorithms can be recombined by updating and
saving the matrices B and C after each simulation i of each thread j. The update formulas are:
T
1
j
j
i
i-
i
i
=
+
B
B
z z
(36)
T
1
-
=
+
j
j
i
i
i
i
C
C
z
y
(37)
After a fixed simulation time, they can be synchronized and recombined, so all the threads
share the same data gathered:
1
=
=å
th
j
j
B
B
 
(38)
1
=
=å
t
j
h
j
C
C
 
(39)
Risk-Constrained Forward Trading Optimization by Stochastic Approximate Dynamic Programming
http://dx.doi.org/10.5772/57466
101

Finally, each thread can restart the simulation process using as starting values for θ and A
1
-
= é ù
ë û
A
B
  
(40)
1
-
= é ù
ë û
θ
B
C
(41)
The final approximation is not as good as the one carried out by a single thread for the same
amount of simulations. This is due to the fact that the decisions taken by the single thread
algorithm have always all the information gathered up to the decision point while the
multithread algorithm lacks the information gathered by other threads since the last synchro‐
nization. Nevertheless, with the correct choice of synchronization and simulation cycles, the
overall optimization process can run much faster.
3. Electricity trading
3.1. Electricity markets
Since about two decades, the power industry had undergone a major restructuring in many
countries. The former vertically-owned and centrally-planned electricity utilities have been
unbundled in separate and independent business segments: the generation, transmission and
distribution sectors. Unlike the latter two segments, which have remained as natural monop‐
olies under regulation, power generation is now a business subject to competition in the open
marketplace [5].
Electricity is a commodity with some very distinctive features. First, modern societies are
exceedingly dependent on a continuous delivery of electrical power, placing a very high value
to supply reliability. Because electrical energy cannot be economically stored in considerable
amounts, production and consumption must be continuously in perfect balance. In addition,
power demand is nearly price irresponsive (inelastic) in the short-run. Therefore, power prices
often escalate to very high quotes (price spikes) when supply/demand conditions are tight.
Most of these circumstances are short-lived, e.g. equipment outages, transmission congestion
climatic events, etc., and price rapidly reverse to normal levels [6].
The exceptionally high volatility of electricity prices imposes high financial risks when trading
electricity and forces generation companies to make decisions and commitments under high
uncertainty. Thus, stochastic modeling and optimal decision making under uncertainty are
key tasks in modern power trading and power risk management [7].
3.2. Trading power in spot markets
Currently, electricity is traded forward on bilateral negotiations and on centrally-run electronic
platforms like power exchanges. Electricity can be traded in anticipation from one to three
Dynamic Programming and Bayesian Inference, Concepts and Applications
102

years (mostly OTC) to several months ahead. Shorter term forward markets negotiating
electricity with delivery horizon of weeks, or even one day in advance in the so-called day-
ahead markets are quite common. Market liquidity is typically higher as the contracting
horizon shortens.
Because of technical requirements of real time system balance, spot power markets are always
centralized and run by entities in charge of the physical operation of the system to keep
reliability and security. Equilibrium spot prices are computed each 5 min, 30 min or in hourly
basis according to the realized power demand and the last bid accepted for keeping the system
balance in real time. Rigorously, locational marginal prices are set in order to account for
transmission constraints. Therefore, spot prices reflect the actual conditions of the system at
the time of delivery.
Though spot prices are subject to high uncertainty, liquidity of this market is warranted as the
generator can always sell its production at real time prices. For this reason, the spot market is
regarded a last-resort market. One advantage of participating only in this market is that
unavailability of the generating unit does not have financial consequences for the generator
other than the opportunity cost of the lost production.
Let pS(t) the prevailing price at the t-th time interval in the spot market, PS(t) the power
delivered by the generating unit and Pmax its generating capacity. Under the hypothesis the
generator is price-taker and its marginal costs of generation, denoted by MC(t), are constant
with the rate of production, the optimal operating policy is:
0     if 
( )
( )
( )
 if 
( )
( ) 
<
ì
= í
>
î
S
S
S
max
p t
MC t
P t
P
p t
MC t
(42)
The operating profit BS(t) the generator obtains in the spot market by implementing this
optimal production policy can be written as:
(
)
( )
max
( )
( )
,0
max
( )
( )
,0
s
s
max
max
s
max
B t
p t P
MC t P
p t
MC t
P
é
ù
é
ù
=
-
=
-
ë
û
ë
û
(43)
This equation shows the operating flexibility of generator to alter its output in response to the
spot price in order to avoid operating losses if prevailing spot prices drop below marginal
costs.
Figure 3 depicts the discontinuous nature of the profit function BS(t) when participating in the
spot market, i.e. BS(t)≥0 for all prices. Indeed, this profit function can be assimilated to a call
option with strike price MC. Figure 3 also schematically illustrates the probability density
function (pdf) of the spot price of electricity f (pS). This function is typically highly right-
skewed and presents strong leptokurtosis.
Risk-Constrained Forward Trading Optimization by Stochastic Approximate Dynamic Programming
http://dx.doi.org/10.5772/57466
103

Figure 3. Profit function of selling power in the spot market
The expected value of the profit in the spot market per unit of generating capacity bS(t) under
the optimal operating policy is described by the following equation:
(
)
0
0
(
)
(
)
¥
é
ù
=
×
+
-
é
ù
é
ù
ë
û
ë
û
ë
û
ò
ò
MC
S
S
S
S
S
S
S
MC
b
p f p
dp
p
MC f p
dp
E
(44)
(
)
(
)
E
¥
é
ù
=
-
³
-
é
ù
é
ù
ë
û
ë
û
ë
û
ò
S
S
S
S
S
MC
b
p
MC f p
dp
p
MC
E
(45)
It is noteworthy to observe that the first term in equation is the probability of obtaining a zero
profit in the spot market. Note also that E pS =MC only if MC =0. By selling the production
in the spot market, the generator never incurs in operating losses, i.e. Pr(bS <0)=0 as it can
immediately stop production if pS <MC.
We consider now the more general case where generating units are unavailable, either for
planned or unplanned reasons, during a fraction of the time. Let p the failure probability and
q =1−p the probability of the unit being available, provided the failure and operating states
are the only two mutually exclusive states in which the generator resides. We further assume
that the price level and the state of the generator are statistically independent. Under these
considerations, the generator cannot always capture de spread pS −MC and thus the proba‐
bility of obtaining a positive profit will decrease accordingly. The expected operating profit
under these conditions is then:
(
)
(
)
¥
é
ù
=
-
é
ù
ë
û
ë
û
ò
S
S
S
S
MC
b
q
p
MC f p
dp
E
(46)
The probability of having zero profit β0=Pr(bS =0) is given by:
Dynamic Programming and Bayesian Inference, Concepts and Applications
104

0
0
0
0
(
)
(
)
(
)
b
¥
=
+
=
+
ò
ò
ò
MC
MC
S
S
S
S
S
S
p
f p
dp
q
f p
dp
p
q
f p
dp
(47)
The resulting probability density function of the hourly operating profit is illustrated in Figure
4. Despite the high variance of the profits, the function clearly shows that the generator cannot
lose money when participating in the spot market, even if the unit is technically unavailable.
 
S
b
(
)
S
f b
(
0)
S
q f p
MC
-
³
0
0
b
Figure 4. Probability density function of the operating profit in the spot market of electricity
3.3. Trading electricity in forward markets
Given the dramatic volatility of real time electricity prices, a major activity of power trading
is structuring hedging strategies by means of tradable derivative instruments like future and
option contracts [8]. A power company owning a set of generating units may decide either to
sell electricity in advance at a fixed price in a forward market, or wait to the time of delivery
and receive the spot price. Deciding on committing production forward or being exposed to
volatility of real-time power prices has however a drastic impact on risk.
By selling forward its production, the generator may hedge against a sudden decline of
electricity spot prices during the delivery horizon, thereby securing an operating margin. This
hedging strategy isolates the generator from the price risk. However, the generator in exchange
resigns the opportunity of selling electricity in the spot market if high prices happen.
Electricity markets are typically arranged under a two-settlement system. This approach
preserves the economy and efficiency of the physical operation of the power system from any
financial commitment the market players have entered into in the past. Under the two-
settlement scheme, only deviations from contractual obligations are negotiated in the spot
market.
The revenue from the forward contracting is given by the volume sold PF times the price pF
agreed in the forward contract, i.e. RF = pF PF. On the other hand, the revenue captured by
selling in the spot market is given by RS = pSΔP = pS(PS −PF). So, the total revenue RF from
forward contracting and delivering power in the spot market is given as:
Risk-Constrained Forward Trading Optimization by Stochastic Approximate Dynamic Programming
http://dx.doi.org/10.5772/57466
105

(
)
(
)
=
+
=
+
-
=
-
+
T
F
S
F
F
S
S
F
F
F
S
S
S
R
R
R
p P
p
P
P
P
p
p
p P
(48)
We can observe the utility of forward contracts by inspecting this equation. If generator
delivers in the spot market an amount equal to its contractual obligation, i.e. PS = PF, the total
revenue is set equal to pF PF irrespective of the fluctuations of the spot price pS.
At the time of delivery, and assuming the generator is price-taker, the term PF(pF −pS) is fixed
and represents the profit of the forward contract against the spot market. Therefore, the profit-
maximizing production policy is the same and given by the spot price, irrespective of the
contractual obligations. The profit the generator can make by selling electricity in forward
markets is given by the expression:
(
)
(
)
( )
max
( )
,0
é
ù
=
-
+
-
ë
û
F
F
F
S
S
S
B
P
p
p t
P
p t
MC
(49)
In Figure 5A, a probability density function of the spot price is depicted. In the following, it is
assumed that the forward market price is an unbiased estimator of the spot price at the time
of delivery. Therefore, the condition pF =E(pS) holds. In the forward contract, the generator
makes a profit for unit of capacity bF = pF −MC, assuming pF >MC. Otherwise, the generator is
better by avoiding entering into a forward obligation with negative profit. For realizing this
profit, the generator must be able to deliver in the spot market the contracted volume in the
exact amount. This profit level is achieved as long as the spot price exceeds the marginal cost,
i.e. the probability of making this profit is Pr(bF = pF −MC)=Pr(pS >MC).
Graphically, this probability is represented by the dark grey area under the pdf of the spot
price (cf. Figure 5A). The generator can make additional profits in the forward contract,
bF = pF −pS > pF −MC, each time the spot price drops below the marginal cost, i.e. pS <MC. In
fact, the generator is better buying replacement power in the spot market than incurring in
fuel costs generating with its own facilities. Figure 5B illustrates the pdf of the profit of a
forward contract. When compared with the profit distribution in the spot market (cf. Figure
5), it is easily noticeable the drastic reduction of the profit variance under forward contracting.
The forward obligation sets a floor for profits, reducing dramatically dispersion of results and
thereby the price risk. In exchange, the generator also foregoes the chance of profiting at times
of high power prices in the spot market. The expected profit of a forward contract in terms of
the pdf of the spot price f (pS) can be expressed as:
(
)
(
)
0
0
E
(
)
(
)
(
)
(
)
MC
F
F
S
S
F
S
S
S
MC
MC
F
S
S
S
S
S
MC
b
p
MC
f p
dp
p
p
f p
dp
p
MC
f p
dp
p f p
dp
¥
¥
é
ù
é
ù =
-
+
-
=
ë
û
ë
û
é
ù
=
-
-
ë
û
ò
ò
ò
ò
(50)
It can be mathematically demonstrated that under rational expectations and efficiency of
forward markets, i.e. the forward price is an unbiased estimator of the spot price pF =E(pS),
Dynamic Programming and Bayesian Inference, Concepts and Applications
106

the condition E(bF)=E(bS) holds [1]. This means that for a risk-neutral generator both policies,
either selling in the spot market or hedging in forward markets, are entirely equivalent.
Nevertheless, for risk-averse players (which is the rule in real market settings), the hedged
strategy is clearly preferred as profit expectation remain unaltered while price risk is elimi‐
nated.
3.4. Delivery risk in forward contracting
If we consider again unplanned outages of generating units, hedging price risk in the forward
markets exposes generating companies to other class of risk, i.e. delivery risk, which also
referred as quantity or volume risk. We further examine this important issue. When a generator
under a contractual obligation is unable to deliver in the spot market the contracted amount,
i.e. PS ≠PF, the generator is forced to buy replacement power in the spot market at the
prevailing price at that time. This may configure a very significant loss if while the generator
is down the spot price is considerable higher than its own marginal costs, i.e. pS ≫MC. Under
this situation, the generator may be compelled to buy very expensive replacement power to
honor the obligation, incurring in a potentially high financial loss. It is interesting to note that
if when the unit is unavailable spot prices are lower or equal than the marginal cost, the
generator can even make an extra profit bF = pF −pS > pF −MC. The probability density function
of the forward position under consideration of positive failure probability and the associated
delivery risk is illustrated in Figure 5C.
The expected profit can be computed as the expected value of the contract under the hypothesis
of fully reliable unit times the probability of being available:
(
)
(
)
0
[
]
(
)
(
)
¥
é
ù
ê
ú
=
-
+
-
ê
ú
ë
û
ò
ò
MC
MC
F
F
S
S
F
S
S
S
b
q
p
MC
f p
dp
p
p
f p
dp
E
(51)
As for modern units q ≅1, the change in the expected profit due to unit unavailability is
typically negligible. However, downside risk increases substantially.
Assuming statistical independence between the unit´s failure and the level of spot prices, the
probability of incurring in losses is given by:
Pr(
0)
Pr(
)
<
=
>
F
S
F
b
p
p
p
(52)
and the conditional expectation on the value of losses can be written as:
(
) (
)
0
¥
=
-
<
ò
F
F
S
S
S
F
p
L
p
p
f
p
dp
b
(53)
Risk-Constrained Forward Trading Optimization by Stochastic Approximate Dynamic Programming
http://dx.doi.org/10.5772/57466
107

A
(
)
S
f p
S
p
=E[
]
F
S
p
p
MC
F
b
F
b
F
p
MC
-
B
(
)
F
f b
( )
S
f b
Pr(
)
S
p
MC
>
(
)
S
f p
MC
<
max
F
F
b
p
=
F
b
C
F
b
(
)
F
f b
F
p
MC
-
max
F
F
b
p
=
Pr(
)
S
q
p
MC
>
(
)
S
q f p
MC
⋅
<
F
b
(
)
S
p f p
MC
⋅
<
(
)
F
S
p f p
p
⋅
-
Pr(
0)
Fb <
VaRd
CVaR
Figure 5. Probability density function of operating profits for a forward contract
From the profit pdf of the forward contract f (bF), the downside risk metrics, namely the value
at risk (VaR) and the conditional value at risk (CVaR) for a δ confidence level can respectively
be computed as:
VaR
Pr(
VaR )
(
)
 
d
d
-
-¥
< -
=
=
ò
F
F
F
b
f b
db
(54)
VaR
CVaR
(
)
d
-
-¥
=ò
F
F
F
b f b
db
(55)
Dynamic Programming and Bayesian Inference, Concepts and Applications
108

4. Problem modeling
4.1. Problem formulation
Let consider a small generation portfolio running in an electricity market. The power company
owning the generation portfolio wants to determine the best-selling strategy of the energy
production, which would maximize the expected profit while financial risk is constrained. Any
trading strategy x is defined by the amount of energy to be sold in each different available
selling instrument i in the electricity market, for example, the spot market, day-ahead obliga‐
tions, annual forward contracts, etc.
It is important to notice that the trading strategy sets the amounts of energy committed in every
forward instrument, but only estimates the amount of energy to be actually sold in the spot
market. Indeed, actual energy production is stochastic and depends on technical availability
of generating units and the spread between spot and fuel prices. Suppose that whatever trading
strategy is decided now, it could be changed in future decision stages in order to rebalance the
portfolio. Composition of the portfolio can be rebalanced only at a cost however, i.e. the
transaction costs. The process is then a sequence of balancing decisions determined by the
trading strategy, each followed by a stochastic reward according to the position taken in the
market. The process is over after a number of periods n.
The optimization of the trading strategy can mathematically be formulated as a stochastic non-
linear problem involving the maximization of the expected profit accrued by the generation
portfolio across all instruments i and time intervals t:
(
)
(
)
,
,
,
1
 
,
-
é
ù
é
ù
é
ù
ê
ú
ê
ú
ê
ú
-
-
ê
ú
ê
ú
ê
ú
ë
û
ê
ú
ë
û
ë
û
å å
å
w
w
w
i t
i t
i t
t
x
t
i
i
max
I
x
T
x
x
C
E
(56)
subject to the following constraints:
,
,
  , 
¹
+
=
"
å
w
w
i h
spot h
h
i spot
x
x
E
h
(57)
,
,  , 
¹
£
"
å
i t
max t
i spot
x
E
t
(58)
,
0 , 
, 
³
"
¹
i t
x
t i
spot
(59)
(
)
(
)
,
,
,
1
,
,
, 
-
é
ù
ê
ú
-
-
£
"
ê
ú
ë
û
å
å
w
W
i t
i t
i t
t
max t
i
i
Risk
I x
T x
x
C
Risk
t
(60)
Risk-Constrained Forward Trading Optimization by Stochastic Approximate Dynamic Programming
http://dx.doi.org/10.5772/57466
109

where:
E: Expected value operator
w: Monte Carlo sample path
W : Total number of Monte Carlo samples
t: Time period beginning after a balancing decision
h : Hourly time step
xi,h : Energy sold and instrument i in hour h
xspot,h
w
: Energy sold in spot market in hour h  and Monte Carlo sample w
Eh
w: Energy generated in hour h  and Monte Carlo sample w
Emax,t: Maximal energy that can be generated in period t
xi,t: Energy to be sold by instrument i in period t
I w(xi,t): Revenue due to energy the sold by instrument i in period t and Monte Carlo sample
w
(
)
,
,
,
,
 ,    
,
    
Î
ì
=
ï
=
×
í
=
ï
î
×
å
w
i t
i t
w
w
i t
i h
h
h t
F
S
x
i
forward
I
x
x
i
spot
p
p
(61)
pF i,t
w : Effective future price of instrument i in period t and Monte Carlo sample w
pS h
w: Spot price in hour h  and Monte Carlo sample w
Ctw: Costs of energy in period t and Monte Carlo sample w
Î
×
=
å
w
w
t
h
h t
C
MC
E
(62)
MC: Constant marginal cost of generation.
T w(xi,t, xi,t−1): Transaction costs due to the change in the amount of instrument i held in the
portfolio after the rebalancing decision at the beginning of period t
(
)
(
)
, 0
,
,
1
,
,
1
3%
 ,    
,
0                                     ,     
-
-
×
×
ì
-
=
ï
= í
=
ïî
t
w h
w
i t
i t
i
i t
i t
F
x
x
i
forward
T
x
x
i
spot
p
(63)
pF i
w,h 0t: Forward price of instrument i and Monte Carlo sample w at the beginning of period t.
Dynamic Programming and Bayesian Inference, Concepts and Applications
110

The constraint (57) represents the hourly energy balance for all Monte Carlo samples and forces
the generator to settle in the spot market differences between the energy sold in forward
markets and actual production. Constraints (58) and (59) are introduced to avoid financial
positions without physical counterpart, i.e. avoid the generator to take speculative positions
by selling in forward markets more energy that the generation portfolio can produce. These
constraints may be replaced by capital restrictions as regulations often allow financial trading
without physical position. Finally, constraint (60) represents the limit to the financial risk
associated to the selling strategy within each period t. In order to limit risk over the horizon
time, the selected risk metric must be coherent [9] ensuring subadditivity. There are several
downside risk measures that fulfill this requirement among which the Conditional Value at
Risk (CVaR) is the most widely used (cf. equation 55).
The equation (61) represents the revenue generated by each forward contract and the revenue
(or cost) due to selling (or buying) differences between energy sold in futures and the real
generation in the spot market forced by restriction (57). The equation (62) represents the costs
of the operating policy, which is independent of the forward obligation for a price taker as
demonstrated in Section 3. Therefore, the three equations (57), (61) and (62) calculated for the
whole Monte Carlo set represent then the profit calculated by equation (49) of Section 3. Finally
the transaction costs in equation (63) are assumed to be the 3% of the total transacted value
only for forward contracts, and not existent for the spot market.
4.2. Modeling stochastic spot and forward electricity prices
The problem formulation relies on Monte Carlo simulations to represent uncertainty on the
future development of key variables. In addition, stochastic simulations are used to confront
the algorithm with mapping scenarios for approximating both, the Value and the Risk
functions.
A synthetic ensemble of 2000 annual realizations of hourly power prices in the spot market
were generated by means of spectral representation techniques [10]. Forward prices and spot
prices are not statistically independent. The forward prices corresponding to each spot price
sample are calculated considering both, the expected value of the spot price and the mean
value of each spot price time series. To simulate the changes in the forward prices accounting
for the correlation to each sample of the spot prices a simple model is introduced.
Under perfect competition and rationality on the expectation formation, the price of a forward
product should converge to the mean expected spot prices for the delivery period. This is
relatively easy to calculate for the first hour of the simulated time. Assuming that the whole
Monte Carlo set of spot prices was simulated taking the same price forecast as the market, the
price of any forward should be the mean spot prices for the delivery period:
(
)
(
)
(
)
(
)
,
,
1
1
1
 
1
1
=
=
=
é
ù
=
=
ë
û
-
-
-
-
å
åå
i
i
d
d
i
i
H
H
W
w h
j
w j
i
d
d
FA
S
S
i
i
i
i
w
j h
j h
p
H
h
W
p
H
p
h
E
(64)
Risk-Constrained Forward Trading Optimization by Stochastic Approximate Dynamic Programming
http://dx.doi.org/10.5772/57466
111

0    
  0
   
  0
£
ì
= í
>
î
i
i
d
i
i
H
if h
H
h
hif h
H
(65)
where:
Hi: delivery period for instrument i
H 0i: first hour of delivery period for instrument i
For the first hour, this model represents the expectation of the market for each delivery period.
However, this expectation should change according to the values that the spot prices take in
each sample and the information gathered by a virtual market taking place in each particular
sample path. If perfect foresight is assumed, each virtual market could calculate without
uncertainty the hourly forward price for its particular spot prices sample path simply as:
(
)
,
,
1
1
=
=
-
- å
i
d
i
H
w h
w j
i
d
i
i
j h
FB
S
p
p
H
h
(66)
The equation (64) represents a model where any additional information that arrives as the spot
price of the particular sample path is different form the forecasted in the first hour is dismissed
by the virtual market. Thus, this model is representative of reality only for the first hour of
simulation where no additional information could have been gathered by the virtual markets.
On the other hand, the equation (66) represents a model where all the additional information
is obtained beforehand for each Monte Carlo sample. Likewise, this model is suitable only for
the last hour of simulation where all information is already known by the virtual market within
each Monte Carlo sample. Finally, the two models can be combined, in order to simulate the
forward price dynamics in correlation to the spot prices of each Monte Carlo sample path. In
this work, it is assumed that the information gathered by each virtual market grows linearly,
augmenting for each hour1. Then, equations (64)2 and (66) are combined by a weighted average:
(
)
(
)
(
)
,
,
,
1
1
=
-
-
-
+
×
×
FC
FA
d
d
i
i
w h
w h
w
i
i
i
i
B
h
F
i
H
p
H
p
h
h
p
H
(67)
(
)
(
)
(
)
(
)
(
)
(
)
,
,
1
,
1
1
 
 
1
1
1
1
=
=
=
=
×
×
-
-
+
-
-
-
+
-
-
åå
å
i
d
i
i
d
i
d
H
W
i
w h
w j
i
d
i
i
i
w
j h
d
H
i
w j
d
i
i
i
FC
S
S
j h
H
h
H
W H
h
h
H
H
p
h
p
p
(68)
1 The assumption that the information is linear with time could be replaced with a more complex information model,
such as a function of the cumulated difference between the initial forecasted spot price and the particular spot prices of
each Monte Carlo sample path.
2 The prices for the first hour in a real market situation should consider the real market prices.
Dynamic Programming and Bayesian Inference, Concepts and Applications
112

Finally, a contango situation is considered in the forward market. A risk premium of 8% in
excess of expected spot prices is considered for the forward prices in the future market to
compensate for the volatility risk. This premium reduces linearly during the delivery period
of the future and becomes zero at the last hour of delivery.
The model for future prices for each instrument i, hour h  and sample w is thus as follows:
(
)
(
)
(
)
(
)
(
)
(
)
,
,
,
1
1
1
1
1
1
 
 
1
1
b
=
=
=
×
æ
ö
-
=
+
ç
÷
ç
÷
è
ø
é
ù
-
-
-
ê
ú
+
ê
ú
-
-
-
-
×
×
ê
ú
ë
×
û
åå
å
i
i
d
d
i
i
d
w h
i
i
i
i
d
d
H
H
W
i
i
w j
w j
d
d
i
i
i
i
i
i
w
j h
h
F
S
j
S
H
h
H
H
h
h
H
H
H
h
p
p
W H
h
p
(69)
where β is the risk premium paid in excess to the expected spot price and set β =8%.
4.3. Reliability model of the generation units
Other relevant source of uncertainty considered is the random failure of the generating units.
The stochastic model of generator outages is built considering that the unit can reside in four
mutually exclusive states: Operation (required), Reserve (not required), Unavailable (required)
and Unavailable (not required), as shown in the diagram of space states in Figure 6 [11].
Reserve 
Operation 
(restrictions) 
Unavailable 
(required) 
Unavailable 
(not required)
Reserve 
FailureRate
Operation 
Failure Rate
Repair 
Rate
Repair 
Rate
Repair 
Rate
Repair 
Rate
Repair 
Rate
Dispatch decision 
spot price < marginal cost ←  → spot price > marginal cost
Figure 6. Four-state stochastic model of the generation units
This unit model accounts for the fact that peaking units exhibit higher availability rates. This
result is explained by the fact the failure probability is typically very small when the unit is in
the stand-by state. A generator is economically called online if its marginal cost of production
Risk-Constrained Forward Trading Optimization by Stochastic Approximate Dynamic Programming
http://dx.doi.org/10.5772/57466
113

is below the prevailing spot prices, following the decision model of equation (42). Variable
costs of generation are assumed linear with power output, i.e. marginal costs are constant.
The operation-failure cycles of the generating unit are obtained from a chronological Marko‐
vian stochastic simulation. For each spot price sample, a time series of power output is
synthesized for every generation unit. The hourly power output is simulated o following three
steps:
1.
Based on failure and repair rates defined by the state the unit resided in the previous hour,
a random failure is simulated [12]. If a failure is in place, the output power is set to zero
for this particular hour.
2.
The dispatch of the unit is simulated, taking into account the marginal cost of generation
and the prevailing sample spot price at that time interval. Here perfect foresight of the
spot price is assumed in order to decide the dispatch and fulfill the minimal generation
times.
3.
If dispatched, other unit’s technical restrictions are fulfilled, e.g. ramping capabilities.
This chronological stochastic model reproduces with accuracy the dynamics involved in
failure and repair cycles of generators, giving the possibility to select different failure rates
depending on whether the unit is generating or is in stand-by.
4.4. Risk constraint formulation
As already mentioned before, the financial decision process can be modeled by means of a
MDP. Naming profit B w for each sample the sum of income, cost and transaction cost over all
instruments, the objective function (56) becomes:
(
)
1
max 
,
-
é
ù
é
ù
ê
ú
é
ù
ê
ú
ë
û
ê
ú
ê
ú
ë
û
ë
û
å
w
t
t
x
t
B
x x
E
(70)
Exchanging the order of the expectation operator and the summation, and expanding the
summation:
(
)
(
)
1
1
0
1
2
max 
,
 
,
-
=
é
ù
é
ù
é
ù
ê
ú
+
ë
û
ë
û
ê
ú
ë
û
å
n
w
w
t
t
t
x
t
x x
x x
B
B
E
E
(71)
where n is the total number of time periods considered.
At this point and considering the first term depends only on the initial market position x0 and
the first strategy decision x1, the maximization can be decomposed using the Bellman´s
Principle of optimality as follows:
Dynamic Programming and Bayesian Inference, Concepts and Applications
114

(
)
(
)
1
2
n
1
1
0
1
2
max 
,
 
max
,
= ¼
-
=
é
ù
é
ù
é
ù
ê
ú
+
ë
û
ë
û
ê
ú
ë
û
å
t
n
w
w
t
t
t
x
x
t
x x
B
B
x x
E
E
(72)
If x is independent of the Monte Carlo sample, the terms inside the summation over all future
periods (t =2…n) are simply the expected profit for the period t after a decision xt−1→xt.
However, the model should take into account that future strategy decisions may be different
for each Monte Carlo sample, accounting for adjustments the decision-maker almost certainly
would execute to face specific scenarios. Then, the expected profit Bt¯ and the decision itself for
future decision stages will depend on a set of variables st, which represent the variables
considered by the decision maker in order to adapt the strategy to a particular situation and
the equation (72) becomes:
(
)
(
)
1
2
n
1
1
0
1
1
2
max   
,
,
 
max
,
,
= ¼
-
=
é
ù
ê
ú
+
ê
ú
ë
û
å
t
n
t
t
t
t
x
x
t
B
x x
s
B
x x
s
(73)
Defining the continuation value functions Vt as:
(
)
(
)
(
)
1
1
1
1
1
1
,
,
,
,
  max
,
,
+
-
-
+
+
+
é
ù
=
+
ë
û
t
t
t
t
t
t
t
t
t
t
t
t
t
x
V
x x
s
B
x x
s
V
x x
s
(74)
The maximization can be solved by a set of recursive maximizations, each one solving only
one decision stage:
(
)
1
max   
,
,
-
é
ù
ë
û
t
t
t
t
t
x
V
x x
s
(75)
With this model, the optimization can be decomposed in steps and the dynamic nature of a
strategy can be accurately replicated. Despite the fact future trading decisions xt=2…n   are
considered and optimized, the practical product of this procedure is the new optimal reba‐
lanced state xt=1 starting from the previous trading position xt=0. The further trading positions
are only optimal given the current information available and should be reconsidered later.
Therefore, each new trading position (xt=2,  xt=3, …, xt=n) should be the product of a similar
optimization incorporating the additional market information available immediately before.
The value functions provide the expected continuation value within a state space defined by
the state variables, xt, xt−1 and st
3. However, the continuation functions, which are essential to
solve the optimization problem, are unknown beforehand. It is here that the ADP approach is
introduced to approximate the value and risk functions for the state space.
3 There are several other decomposition methods, some of which exclude the decision as state space variable defining
the value functions in a post-decision state space. These approaches make the step maximization sometimes harder but
present advantages such as a state space of fewer dimensions. See for example [2].
Risk-Constrained Forward Trading Optimization by Stochastic Approximate Dynamic Programming
http://dx.doi.org/10.5772/57466
115

The set of constraints remains the same as they were already defined for each period t.
Nevertheless, special considerations should be made to calculate de risk and to fulfill the risk-
constrained optimization. As Vt only account for the expected profit, risk functions Rt should
also similarly be calculated for the same state space in order to enforce the risk constraint.
By definition, the linear regression will deliver an approximation that minimizes the mean
square error on the entire dataset. In a stochastic setting where the same inputs leads to several
different outputs, the regression will accurately estimate the expected value for a given set of
inputs, provided the sample size and the approximation order are appropriate. This fits perfect
for the case of the value function but for the approximation of the risk function some problems
arise.
Let suppose that the CVaR is chosen as risk metric. As the algorithm progresses, new data
points are collected, i.e. a set of state variables and its corresponding simulated profits for the
period. For approximating the CVaR associated to a particular point in the state space, one
approach is to select a subset from the dataset whose input variables are “close” to the point.
Then the CVaR is calculated first by sorting the profit values and then taking the mean of those
below the specified α-quantile. Now, let suppose that a new data point is simulated and an
update of the CVaR approximation is needed. To do so, the process described must be repeated,
but now including the new data point. This simple approach has large disadvantages: all the
data points must be stored and the mean is not easily updated as old data may be excluded or
included of the zone below the α-quantile. These drawbacks are caused by the fact that the
CVaR is quantile-based. To solve these difficulties, another solution is envisioned. Instead of
approximating directly the CVaR, another risk measure is used to approximate the CVaR
within the space state. The risk measure used is called Relative Lower Semideviation (RLS)
and it is moment based instead. Hence, it can be updated more easily and without needing to
store the entire dataset. These types of risk measures are described in detail in [13-16] and for
a stochastic profit Pt have the form:
(
)
s
-
= -
+
×
é
ù
é
ù
ë
û
ë
û
t
t
p
t
RLS B
B
a
B
E
(76)
(
)
1
,0
s
-
æ
ö
é
ù
=
-
é
ù
é
ù
ç
÷
ë
û
ë
û
ê
ú
ë
û
è
ø
p
p
p
t
t
t
B
max
B
B
E
E
(77)
where the equation (77) is the negative semideviation of degree p of the stochastic profit Pt.
It can be proven that these moment-based risk measures are coherent if 0≤a≤1 and p ≥1. To
approximate a CVaR with a 5%-quantile, in this work the parameters used are a=1 and
p =9.5. To compute the approximation, two linear regressions were used to calculate the
expectations on the profit and on the negative deviations, which can be updated using the
same method proposed for the value functions. In a Monte Carlo scheme, a large amount of
data is needed to compute reliable risk estimations. Therefore, the risk constraint should not
Dynamic Programming and Bayesian Inference, Concepts and Applications
116

be enforced at the early iterations of the ADP algorithm, simply because the sample size of the
dataset is small to get a consistent and statistically converged risk value.
5. Numerical case study
5.1. Algorithm validation
With the objective of validating the results of the proposed ADP algorithm, a first simple
exemplary case is considered in which a thermal generator sells energy in the spot market and
in a future contract. The results of the ADP algorithm were compared with the results of a
conventional DP algorithm for which the space-state was discretized appropriately.
The fractions of energy sold in the spot market and in a quarter future contract were optimized
considering that the future can be traded during the delivery period. The optimization
determines three decision stages during this period, one at the beginning of each month,
consisting on sell or buy energy in the future market based on the previous state. The space-
state previous to each decision is defined only by the level of future already sold, in order to
keep tractable the DP problem.
5.2. Validation results
The results obtained by solving the problem by means of the ADP and DP algorithms are
presented in Figure 7. The plots represent the expected profit and the downside risk measured
by the CVaR of the optimal strategy as a function of the initial state, i.e. the energy already
committed in the future contract at the initial stage. An excellent agreement between the
optimal strategies obtained by ADP and DP is evidenced, validating the proposed approach.
It can be noticed that the expected profit rises as the amount of energy sold forward increases.
This is caused by the risk premium paid to the generator in the future market, i.e. the mean
future prices are higher than the mean spot prices. Additionally, the transaction costs are not
compensated by the risk premium; therefore the best trading strategy is to maintain similar
involvement in the future market to the initial level without rebalancing the portfolio. This is
illustrated in Figure 8, where the optimal decisions for the first month are practically the same
when solving with a conventional DP and an ADP approach.
It is noteworthy to observe in Figure 7 that financial risk lessens when forward contracting in
the future market increases. This means that for the conventional generator considered, which
present a high availability, the delivery risk is lower than the risk of not being dispatched in
the spot market. The behavior of the risk curve is closely related to the unit’s failure and
reparation rates and to the marginal production costs. Generators with low marginal costs are
in the first places of the dispatch merit order, and hence the risk of not being dispatched is low.
Moreover, high failure rates imply also a higher delivery risk. Out of these relations arise a
broad number of risk curves that differ from one generator to another and suggest that
considerable risk mitigation by aggregating different generators in a portfolio is possible.
Risk-Constrained Forward Trading Optimization by Stochastic Approximate Dynamic Programming
http://dx.doi.org/10.5772/57466
117

Figure 8. Optimal percentage of energy sold in the future market for the first time period – Validation case
Figure 7. Expected benefit and downside risk of the optimal strategy – Validation case.
Dynamic Programming and Bayesian Inference, Concepts and Applications
118

5.3. Optimal policy for portfolio rebalancing
For the base study case, a slightly more complex system was examined. In this case, the
generation portfolio comprises five generation units of 2 MW each with a constant marginal
generation cost of 50$/MWh, failure rate of 1/950h-1, reserve failure rate of 1/9950 h-1 and repair
rate of 1/50 h-1. These rates give a failure probability of 5% while the unit is in operation and
of 0.5% while in standby.
An annual future, four quarterly futures and the spot market were considered together with
12 monthly trading decision stages for rebalancing the portfolio. The space state for this
arrangement is defined by the amount sold forward as well as spot and future prices before
each decision point and for each realization. Therefore, the decisions are chosen taking into
account additional information about the state of the market for each realization. Even though
the simplicity of the example, the additional variables cause a drastic increase in the dimension
of the problem and would force an unacceptable coarse discretization of the space-state in
order to keep the problem tractable with conventional DP. In this case, the maximum admis‐
sible expected loss for the 5%-confidence level is set to CVaR5%=$20000 for each decision stage.
Since the risk measure is coherent, i.e. sub-additive, the annual risk is less or equal to $20000∙12
periods=$240000. Transaction costs are set to 3% of the dollar amount contracted in the forward
market. The optimization problem was solved on a Beowulf cluster comprising 20 multicore
Intel i7 2600K 3.4 GHz processors connected by a Gbit LAN. The 160 available computation
nodes were fully exploited and the total computation time was 5 h.
In Figure 9, the results of the ADP algorithm for the optimal strategy on the first rebalancing
period with a previous trade equal to zero are illustrated. The amount of energy to be com‐
mitted in each market is expressed in terms of a fraction of the maximal energy output the
generation portfolio would generate without failures in the period, i.e. 10MWh per hour of
operation. The prices for the traded futures are also presented in Figure 9 except for the 2nd
quarter future which is 45.63$/MWh and it is not shown as the optimal trade does not include
this contract, presumably because the price is too low and it is better to wait for a better price
in the spot market and sell in subsequent decisions. Likewise, the expected spot prices for each
quarter are displayed, except for the last quarter which is 52.45$/MWh. Finally, the expected
annual profits without considering fixed costs and the risk estimated by the RLS for the first
rebalancing period are shown. Note that the expected profit is calculated considering that the
following trading decisions are made taking into account the particular sample price realiza‐
tion, capturing the adaptation to the market developments. Thus, the rebalancing decisions
for the second up to the last period are not unique.
5.3.1. Sensitivity to unit availability
In order to investigate the sensitivity of the optimal trading strategy to the unit availability, a
second case was considered. Under these conditions, all the parameters are identical to the
described base case, except for the failure and repair rates. Operation failure rate was set to
1/850h-1, a reserve failure rate to 1/9850 h-1 and repair rate of 1/150h-1. With these rates, the
failure probability is 15% in operation and 1.5% in standby.
Risk-Constrained Forward Trading Optimization by Stochastic Approximate Dynamic Programming
http://dx.doi.org/10.5772/57466
119

 
0%
25%
50%
75%
100%
1st Quarter
2nd Quarter
3rd Quarter
4th Quarter
% of maximal energy
Spot
3-months Future
Annual Future
Expected annual profit 
(without fix costs):  
2.92 M$ 
 
CVaR 1
st month: 
$ 20000 
52.57
$/MWh 
52.00
$/MWh
56.64
$/MWh 
51.72
$/MWh
48.68 
$/MWh
42.25 
$/MWh 
48.15 
$/MWh
Figure 9. Optimal trading strategy for a 5x2MW generation portfolio
In Figure 10, the optimal trading strategy delivered by the ADP algorithm for the case of
decreased unit availability is depicted. The differences on the sell strategy are evident for the
annual future and the total amount of energy left to be sold in the spot market. Because of units
have more frequent and longer random failures, a long-term commitment is avoided. How‐
ever, the high prices for the fourth quarter push the sell in future markets up to 100%. In
comparison to the base case results, the expected annual profit is slightly lower. The risk for
the first month is irrelevant, because the forward commitment is around 50% and the proba‐
bility of having more than two units (> 40%) unavailable is very low, leading to almost all unit
failures can be covered by the remaining available units.
0%
25%
50%
75%
100%
1st Quarter
2nd Quarter
3rd Quarter
4th Quarter
% of maximal energy
Spot
3-months Future
Annual Future
52.57
$/MWh
52.00
$/MWh
56.64
$/MWh
Expected annual profit 
(without fix costs):  
2.80 M$ 
 
CVaR 1
st month: 
$ -133 247 
45.63 
$/MWh
51.72
$/MWh 
48.68 
$/MWh
42.25 
$/MWh 
48.15 
$/MWh
Figure 10. Optimal trading strategy for a 5x2MW generation portfolio with reduced availability
Dynamic Programming and Bayesian Inference, Concepts and Applications
120

5.3.2. Sensitivity to transaction costs
The third case of study is identical to the base case but considering a transaction cost of 7% of
the sold amount instead of 3%. The optimal trading policy for the case of increased transaction
costs are shown in Figure 11. In this case, the generator sells only 1.32% of its capacity in an
annual future contract due to the irreversibility introduced by the higher transactions costs
and the larger contracting volume. Under these circumstances, the risk premium offered in
the annual future price render insufficient for attracting the generator to enter in such a long-
lasting commitment. On the other hand, the sell volume in quarterly futures is higher than in
the base case, staying between 62% and 76% in a rather static trading policy. Under higher
transaction fees, it is desirable to be able to rebalance the portfolio in future stages with smaller
changes and hence smaller transaction costs. Expectedly, the expected profit is lower due to
higher costs. The delivery risk for the first month is negligible, due to the fact that the most
likely failures can still be covered by the remaining operative units without buying replace‐
ment power in the spot market.
0%
25%
50%
75%
100%
1st Quarter
2nd Quarter
3rd Quarter
4th Quarter
% of maximal energy
Spot
3-months Future
Annual Future
52.57
$/MWh
52.00
$/MWh 
56.64
$/MWh 
45.63 
$/MWh
51.72
$/MWh
Expected annual profit 
(without fix costs):   
$ 2.67 M$ 
 
CVaR 1
st month: 
$ -8 366 
48.68 
$/MWh
42.25 
$/MWh 
48.15 
$/MWh 
52.45
$/MWh
Figure 11. Optimal trading strategy for a 5x2MW generation portfolio with higher transaction costs
6. Conclusions
Optimal decision-making under uncertainty is a field of active research and uppermost
relevance in science, engineering and computational finance. Conventional optimization
approaches have difficulties and serious limitations for tackling high-dimensional problems
often encountered in real world settings. Recent advances in operation research and compu‐
tation technology opened new possibilities for approaching optimization problems that were
considered intractable until recent times. This chapter presents an efficient Approximate
Dynamic Programming algorithm for solving complex stochastic optimization problems and
amenable for running in a distributed computing environment. The implemented ADP
algorithm has been validated against conventional Dynamic Programming for a simple
problem.
Risk-Constrained Forward Trading Optimization by Stochastic Approximate Dynamic Programming
http://dx.doi.org/10.5772/57466
121

The proposed algorithm uses Monte Carlo simulation techniques combined with linear
regression for successively approximating and refining the continuation and risk functions. A
novel and efficient procedure for updating these functions, combining calculations of inde‐
pendent computing threads and without storing the entire datasets, is proposed. This feature
enables exploiting the currently widespread multicore processor architectures and deploying
the algorithm in large computation clusters.
In order to demonstrate the practicability of the envisioned approach, the proposed algorithm
has been applied to find the optimal trading strategy of a power generation portfolio in forward
and spot electricity markets. Power trading and risk management is currently a central activity
of power companies running in liberalized electricity markets. The probability density
functions of the profits a generator would make by participating in either the spot or the
forward markets are extremely different. The forms and boundaries of these probability
functions have drastic implications for risk when generators get involved in the spot or the
forward markets. Generators can hedge price risk of spot markets by contracting forward, but
by exposing themselves to delivery risk. Hence, the optimization problem is formulated as the
maximization of the expected profit of the trading policy while the downside risk is constrain‐
ed. For doing so, the generator selects and combines a portfolio of annual and quarterly
forward contracts as well as involvement in the spot market. A frictional market with non-
negligible transaction costs is considered.
A detailed chronological 4-state reliability model of generating units has been adopted for
replicating stochastic behavior of random outages. Large stochastic ensembles of spot prices
and forward prices time series have been synthetized for this application. In order to retain
subadditivity, downside risk is measured by CVaR. The approximation of CVaR by a moment-
based risk metric drastically improves computational efficiency while providing accurate and
consistent risk estimations.
Applying ADP-based optimization techniques to electricity markets is a novel undertaking
and opens a prospectively fertile avenue for research. In future works, further algorithmic
enhancement are foreseen. Application of these methods for designing trading strategies that
considers a larger set of available financial contracts as well as generation portfolios comprising
renewable resources would provide results and findings of high practical significance.
Acknowledgements
This work was supported in part by the National Scientific and Technical Research Council
(CONICET) and the Agency for Promotion of Science & Technology (ANPCyT), Argentina.
The financial support of the German Academic Exchange Service (DAAD) is also gratefully
acknowledged. The authors also thank the support of the colleagues at the Institute of Power
Systems and Power Economics (IAEW), RWTH Aachen, Germany, especially Univ.-Prof. Dr.-
Ing. Albert Moser as well as colleagues at Institute of Electrical Energy (IEE), National
University of San Juan, Argentina.
Dynamic Programming and Bayesian Inference, Concepts and Applications
122

Author details
Miguel Gil-Pugliese1* and Fernando Olsina2
*Address all correspondence to: miguel.gil.pugliese@gmail.com
1 Institute of Power Systems and Power Economics (IAEW), RWTH Aachen, Germany
2 Institute of Electrical Energy (IEE), National University of San Juan, Argentina
References
[1] Olsina F, Larisson C, Garcés F. Hedging and volumen risk in forward contracting [in
Spanish]. Proceedings of XII ERIAC de CIGRE, Foz do Iguazu, Brazil, May 2007. pa‐
per C5.02.
[2] Powell WB. Approximate Dynamic Programming: Solving the curses of dimensional‐
ity. Wiley-Blackwell; 2007.
[3] Bertsekas DP,Tsitsiklis JN. Neuro-Dynamic Programming (Optimization and Neural
Computation Series, 3). Athena Scientific; 1996.
[4] Bellman RE. Dynamic Programming. Princeton University Press, Princeton, NJ; 1957
[5] Stoft S. Power System Economics: Designing Markets for Electricity, New York, USA;
IEEE Press/Wiley; 2002.
[6] Hadsell L, Maralhe A, Shawky, HA. Estimating the volatility of wholesale electricity
spot prices in the US. The Energy Journal 2004; 25(4) 23-40.
[7] Bjorgan R, Liu C, Lawarrée J. Financial risk management in a competitive electricity
market. IEEE Transactions on Power Systems 1999; 14(4) 1285-1291.
[8] Stoft S, Belden T, Goldman C, Pickle S. Primer on Electricity Futures and Other De‐
rivatives. Lawrence Berkeley National Laboratory, University of California,
LBNL-41098, 1998.
[9] Artzner P, Delbaen F, Eber JM, Heath D. Coherent measures of risk. Mathematical Fi‐
nance 1999; 9(3) 203-228.
[10] Olsina F, Weber C. Stochastic simulation of spot power prices by spectral representa‐
tion. IEEE Transactions on Power Systems 2009; 24(4) 1710-1719.
[11] Billinton R, Ge J. A comparison of four-state generating unit reliability models for
peaking units. IEEE Transactions on Power Systems 2004; 19(2) 763–768.
Risk-Constrained Forward Trading Optimization by Stochastic Approximate Dynamic Programming
http://dx.doi.org/10.5772/57466
123

[12] Billinton R, Allan R. Reliability evaluation of power systems. Plenum Press, New
York, 1996.
[13] RockafellarR, Uryasev S, Zabarankin M. Generalized deviations in risk analysis. Fi‐
nance and Stochastics 2006; 10(1) 51-74.
[14] Fischer T. Risk capital allocation by coherent risk measures based on one-sided mo‐
ments. Insurance: Mathematics and Economics 2003; 32(1) 135-146.
[15] Pavlo AK. Higher moment coherent risk measures. Taylor & Francis, 2007.
[16] Rockafellar T, Uryasev S, ZabarankinM. Deviation measures in risk analysis and op‐
timization. University of Florida, Department of Industrial & Systems Engineering
Working Paper 2002.
Dynamic Programming and Bayesian Inference, Concepts and Applications
124

Chapter 5
Using Dynamic Programming Based on Bayesian
Inference in Selection Problems
Mohammad Saber Fallah Nezhad
Additional information is available at the end of the chapter
http://dx.doi.org/10.5772/57423
1. Introduction
An important subject in mathematical science that causes new improvements in data analysis
is sequential analysis. In this type of analysis, the number of required observations is not fixed
in advance, but is a variable and depends upon the values of the gathered observation. In
sequential analysis, at any stage of data gathering process, to determine the number of required
observations at the next stage, we analyze the data at hand and with respect to the obtained
results, we determine how many more observations are necessary. In this way, the process of
data gathering is cheaper and the information is used more effectively. In other words, the
data gathering process in sequential analysis, in contrast to frequency analysis, is on-line. This
idea caused some researches to conduct researches in various statistical aspects (Basseville and
Nikiforov[1]).
In this chapter, using the concept of the sequential analysis approach, we develop an innova‐
tive Bayesian method designed specifically for the best solution in selection problem. The
proposed method adopts the optimization concept of Bayesian inference and the uncertainty
of the decision-making method in dynamic programming environment. The proposed
algorithm is capable of taking into consideration the quality attributes of uncertain values in
determining the optimal solution. Some authors have applied sequential analysis inference in
combination with optimal stopping problem to maximize the probability of making correct
decision. One of these researches is a new approach in probability distribution fitting of a given
statistical data that Eshragh and Modarres [2] named it Decision on Belief (DOB). In this
decision-making method, a sequential analysis approach is employed to find the best under‐
lying probability distribution of the observed data. Moreover, Monfared and Ranaeifar [3] and
Eshragh and Niaki [4] applied the DOB concept as a decision-making tool in some problems.

Since the idea behind the sequential analysis modeling is completely similar to the decision-
making process of a human being in his life, it may perform better than available methods in
decision-making problems. In these problems, when we want to make a decision, first we
divide all of the probable solution space into smaller subspaces (the solution is one of the
subspaces). Then based on our experiences, we assign a probability measure (belief) to each
subspace, and finally we update the beliefs and make the decision.
2. An application to determine the best binomial distribution
In the best population selection problem, a similar decision-making process exits. First, the
decision space can be divided into several subspaces (one for each population); second, the
solution of the problem is one of the subspaces (the best population). Finally, we can assign a
belief to each subspace where the belief denotes the performance of the population in term of
its parameter. Based upon the updated beliefs in iterations of the data gathering process, we
may decide which population possesses the best parameter value.
Consider n independent populations P1, P2, ..., Pn, where for each index i =1, 2, ..., n, popu‐
lation Pi is characterized by the value of its parameter of interest pi. Let p 1 ≤...≤p n  denote
the ordered value of the parameters p1, ..., pn. If we assume that the exact pairing between the
ordered and the unordered parameter is unknown, then, a population Pi with pi = p n  is called
the best population.
There are many applications for the best population selection problem. As one application in
supply chain environments, one needs to select the supplier among candidates that performs
the best in terms of the quality of its products. As another example, in statistical analysis, we
need to select a distribution among candidates that fits the collected observations the most.
Selecting a production process that is in out-of-control state, selecting the stochastically
optimum point of a multi-response problem, etc. are just a few of these applications.
The problem of selecting the best population was studied in papers by Bechhofer and Kulkarni
[5] using the indifference zone approach and by Gupta and Panchapakesan [6] employing the
best subset selection approach.
2.1. Belief and the approach of its improvement
Assume that there are n available Binomial populations and we intend to select the one with
the highest probability of success. Furthermore, in each stage of the data gathering process
and for each population, we take an independent sample of size m. Let us define αi,t
'  and βi,t
'
to be the observed number of successes and failures of the ith Binomial population in the tth stage
(sample) and αi,k and βi,k to be the cumulative observed number of successes and failures of
the ith Binomial population up to the kth stage (sample) respectively. In other words,
αi,k =∑
t=1
k
αi,t
' and βi,k =∑
t=1
k
βi,t
' . Then, in the kth stage defining pi,k¯ to be the estimated probability
Dynamic Programming and Bayesian Inference, Concepts and Applications
126

of success of the ith population obtained by 
αi,k
km , referring to Jeffrey’s prior (Nair et al.[7]), for
pi,k¯, we take a Beta prior distribution with parameters αi,0=0.5 and βi,0=0.5. Then, using Bayesian
inference, we can easily show that the posterior probability density function of pi,k¯ is
,
,
0.5
0.5
,
,
,
,
,
,
,
(
1)
(
)
(1
)
(
0.5) (
0.5)
i k
i k
i k
i k
i k
i k
i k
i k
i k
f p
p
p
a
b
a
b
a
b
-
-
G
+
+
=
-
G
+
G
+
(1)
At stage k of the data gathering process, after taking a sample and observing the numbers of
failures and successes, we update the probability distribution function of pi,k¯ for each popu‐
lation. To do this, define B(αi,k, βi,k) as a probability measure (called belief) of the ith population
to be the best one given αi,k and βi,k as
(
)
{
}
th
,
,
,
,
,
Pr
population is the best
,
i k
i k
i k
i k
B
i
a
b
a
b
=
(2)
We then update the beliefs based on the values of (αi,k, βi,k) for each population in iteration k.
If we define B(αi,k−1, βi,k−1) as the prior belief for each population, in order to update the
posterior belief B(αi,k, βi,k), since we may assume that the data are taken independently in each
stage, we will have
(
)
(
)
{
}
(
)
{
}
(
)
{
}
(
)
{
}
(
)
,
,
,
1
,
1
,
,
,
1
,
1
,
,
1
,
1
,
1
,
,
Pr
 Population is the best
,
Pr
,
 Population is the best
Pr
 Population is the best
,
Pr
,
 Population is the best
,
Pr
,
i k
i k
th
th
i k
i k
i k
i k
n
th
th
j k
j k
j k
j k
j
i k
i k
i k
B
i
i
j
j
B
a
b
a
b
a
b
a
b
a
b
a
b
a
-
-
-
-
=
-
-
=
é
ù
ê
ú
ë
û
=
å
(
)
{
}
(
)
(
)
{
}
,
,
1
,
1
,
,
1
 Population is the best
,
Pr
,
 Population is the best
th
i k
n
th
j k
j k
j k
j k
j
i
B
j
b
a
b
a
b
-
-
=
é
ù
ê
ú
ë
û
å
(3)
From equation (3) we see that to update the beliefs, we need to evaluate
Pr{(αi,k, βi,k)|i th Population is the best} ; i =1, 2, ..., n in each decision-making stage. One
way to do this is to use
(
)
{
}
,
,
,
,
1
Pr
,
 Population is the best
i k
th
i k
i k
n
j k
j
p
i
p
a
b
=
=
å
(4)
Using Dynamic Programming Based on Bayesian Inference in Selection Problems
http://dx.doi.org/10.5772/57423
127

Then, the probability given in equation (3) will increase when a better population is selected.
In the next theorem, we will prove that when the number of decision-making stages goes to
infinity this probability converges to one for the best population.
Theorem 1
If the ith population is the best, then Lim
k→∞B(αi,k, βi,k)= Bi =1.
In order to prove the theorem first we prove the following two lemmas.
Lemma 1:
Define a recursive sequence {Rk, j; j =1, 2, ..., l} as
1,
1,
,
1
for
1,2,3,...
for             
0
j
k
j
l
i
k
i
k j
i
j
c R
k
c R
R
P
k
-
-
=
ì
=
ï
ï
= í
ï
ï
=
î
å
(5)
where c1, c2, ..., and cl are different positive constants, ∑
j=1
l
Pj =1 , and Pj >0 Then, if
lj = Lim
k→∞(Rk, j), there exist at most one non-zero lj.
Proof:
Suppose there are two nonzero ls >0 and lt >0. Taking the limit on Rk, j as k goes to infinity we
have
1,
,
1,
1
1
 (
)
 
j
k
j
j j
k j
j
l
l
k
k
i
k
i
i i
i
i
c R
c l
Lim R
l
Lim
c R
c l
-
®¥
®¥
-
=
=
æ
ö
ç
÷
ç
÷
=
=
=
ç
÷
ç
÷
ç
÷
è
ø
å
å
(6)
Now since ls >0 and lt >0, then by equation (6) we have
1
1
1
1
   
   
 and  
   
   
 
l
l
s s
t t
s
s
i i
t
t
i i
l
l
i
i
i i
i i
i
i
c l
c l
l
c
c l
l
c
c l
c l
c l
=
=
=
=
=
Þ
=
=
Þ
=
å
å
å
å
(7)
In other words, we conclude cs =ct, which is a contradiction.
Dynamic Programming and Bayesian Inference, Concepts and Applications
128

Lemma 2:
Sequence Rk, j converges to one for j = g and converges to zero for j ≠g, where g is an index for
the maximum value of cj.
Proof
From equation (6), we know that ∑
j=1
l
lj =1. Then by lemma 1, we have li =1 for only one i. Now
suppose that cg = max
j∈{1...m}{cj} and g ≠i. We will show that this is a contradiction. Consider
Hk,i =
Rk,g
Rk,i . By equation (5), we have Hk,i =
cg
ci Hk−1,i. Since Ho,i >0 we will have
(
)
,
1,
0,
,
   
   
k
g
g
k i
k
i
i
k i
k
i
i
c
c
H
H
H
Lim H
c
c
-
®¥
æ
ö
ç
÷
=
=
Þ
= ¥
ç
÷
è
ø
(8)
That is a contradiction because Lim
k→∞(Hk,i)=
Lim
k→∞(Rk,g)
Lim
k→∞(Rk,i) =
lg
li =0. So lg =1
Now we are ready to prove the convergence property of the proposed method. Taking limit
on both sides of equation (3), we will have
(
)
(
)
(
)
{
}
(
)
(
)
{
}
,
1
,
1
,
,
,
,
,
1
,
1
,
,
1
,
Pr
,
 Population is the best
,
   
,
Pr
,
 Population is the best
th
i k
i k
i k
i k
i k
i k
i
n
k
k
th
j k
j k
j k
j k
j
B
i
LimB
B
Lim
B
j
a
b
a
b
a
b
a
b
a
b
-
-
®¥
®¥
-
-
=
é
ù
ê
ú
ê
ú
=
=
ê
ú
é
ù
ê
ú
ê
ú
ë
û
ê
ú
ë
û
å
(9)
From the law of large numbers, we know that Lim
k→∞p j,k¯ = pj, where pj is the probability of success
of the jth population. Hence, using equation (7) we have  Bi =
Bi pi
∑
j=1
n
Bj pj
. Then assuming population
i is the best, i.e., it possesses the largest value of pj ’s, by lemma 1 and 2 we conclude that Bi =1
and Bj
j≠i
=0. This concludes the convergence property of the proposed method.
In real-world applications, since there is a cost associated with the data gathering process we
need to select the best population in a finite number of decision-making stages. In the next
section, we present the proposed decision-making method in the form of a stochastic dynamic
programming model in which there is a limited number of decision-making stages available
to select the best population.
Using Dynamic Programming Based on Bayesian Inference in Selection Problems
http://dx.doi.org/10.5772/57423
129

2.2. A dynamic programming approach
The proposed dynamic programming approach to model the decision-making problem of
selecting the best Binomial population is similar to an optimal stopping problem.
Let us assume that to find the best population there is a limited number of stages (s) available.
Then, the general framework of the decision-making process in each stage is proposed as:
1.
Take an independent sample of size m from each population.
2.
Calculate the posterior beliefs in terms of the prior beliefs using Bayesian approach.
3.
Select the two biggest beliefs.
4.
Based upon the values of the two biggest beliefs calculate the minimum acceptable belief.
5.
If the maximum belief is more than the minimum acceptable belief, then we can conclude
that the corresponding subspace is the optimal one. Otherwise, go to step 1.
In step 3 of the above framework, let populations i and j be the two candidates of being the
best populations (it means that the beliefs of populations i and j are the two biggest beliefs)
and we have s decision-making stages. If the biggest belief is more than a threshold (minimum
acceptable belief)di, j(s),  (0≤di, j(s)≤1), we select the corresponding subspace of that belief as
the solution. Otherwise, the decision-making process continues by taking more observations.
We determine the value of di, j(s) such that the belief of making the correct decision is maxi‐
mized. To do this suppose that for each population a new observation, (α j,k, β j,k), is available
at a given stage k. At this stage, we define V (s, di, j(s)) to be the expected belief of making the
correct decision in s stages when two populations i and j are the candidates for the optimal
population. In other words, if we let CS denote the event of making the correct decision, we
define Vi, j(s, di, j(s))= E Bi, j{CS} , where Bi, j{CS} is the belief of making the correct decision.
Furthermore, assume that the maximum of Vi, j(s, di, j(s)) occurs at di, j*(s). Then, we will have
(
)
(
)
{
}
{
}
{
}
,
*
,
,
,
,
,
( )
,
( )
,
( )
i j
i j
i j
i j
i j
i j
d
s
V
s d
s
Max V
s d
s
Max E B
CS
é
ù
=
=
ë
û
(10)
We denote this optimal point by Vi, j*(s). In other words, Vi, j*(s)=Vi, j(s, di, j*(s)). Moreover, let
us define Si and Sj to be the state of selecting population i and j as the candidates for the optimal
population, respectively, and N Si, j as the state of choosing neither of these population. Then,
by conditioning on the above states, we have
( )
{
}
{
}
{
}
{ }
{
}
{ }
{
}
{
}
{
}
*
,
,
,
,
,
,
,
,
,
,
i j
i j
i j
i
i j
i
i j
j
i j
j
i j
i j
i j
i j
V
s
Max E B
CS
Max E B
CS S
B
S
B
CS S
B
S
B
CS NS
B
NS
é
ù
=
=
ë
û
é
ù
+
+
ë
û
(11)
In order to evaluateVi, j*(s), in what follows we will find the belief terms of equation (11).
Dynamic Programming and Bayesian Inference, Concepts and Applications
130

a.
Bi, j{CS |Si} and Bi, j{CS |Sj}
These are the beliefs of making the correct decision if population i or j is selected as the optimal
population, respectively. To make the evaluation easier, we denote these beliefs by Bi, j(i) and
Bi, j( j). Then, using equation (2) we have
{
}
(
)
(
)
(
)
,
1
,
1
,
,
,
,
1
,
1
,
,
1
,
1
,
,
( )
  
,
,
i k
i k
k i
i j
i
i j
i k
i k
k i
j k
j k
k j
B
p
B
CS S
B
i
B
p
B
p
a
b
a
b
a
b
-
-
-
-
-
-
=
=
+
(12)
Similarly,
{
}
(
)
(
)
(
)
,
1
,
1
,
,
,
,
1
,
1
,
,
1
,
1
,
,
( )
  
,
,
j k
j k
k j
i j
j
i j
j k
j k
k j
i k
i k
k i
B
p
B
CS S
B
j
B
p
B
p
a
b
a
b
a
b
-
-
-
-
-
-
=
=
+
(13)
b.
Bi, j{Si} and Bi, j{Sj}
These are the beliefs of selecting population i or j as the optimal population, respectively.
Regarding the decision-making strategy, we have:
( )
( )
( )
(
)
( )
( )
*
,
,
,
,
,
max
,
 and 
i j
i j
i j
i j
i j
B
i
B
i
B
j
B
i
d
s
=
³
(14)
Hence, we define event Si as
( )
( )
( )
{
}
( )
( )
{
}
*
,
,
,
,
,
max
,
,
i
i j
i j
i j
i j
i j
S
B
i
B
i
B
j
B
i
d
s
º
=
³
(15)
Since 
Bi, j(i) + Bi, j( j)=1 
and 
that 
the 
beliefs 
are 
not 
negative 
we 
conclude
max{Bi, j(i), Bi, j( j)}≥0.5. Furthermore, since the decision making is performed based upon the
maximum value of the beliefs, without interruption of assumptions, we can change the
variation interval of di, j
* (s) from [0,1] to [0.5,1]. Now by considering di, j
* (s)≥0.5 implicitly, we
have Si ≡{Bi, j(i)≥di, j
* (s)}. By similar reasoning Sj ≡{Bi, j( j)≥di, j
* (s)}. Hence
{ }
( )
( )
{
}
(
)
(
)
(
)
( )
( )
(
)
{
}
( )
(
)
*
,
,
,
,
1
,
1
,
,
*
*
*
,
,
,
,
,
,
,
1
,
1
,
,
1
,
1
,
Pr
,
Pr
Pr
Pr
,
,
i j
j
i j
i j
j k
j k
j k
j k
i j
j k
i j
i k
i j
i k
i k
i k
i k
j k
j k
j k
B
S
B
j
d
s
B
p
p
d
s
p
h d
s
p
h d
s
p
B
p
B
p
a
b
a
b
a
b
-
-
-
-
-
-
=
³
=
ì
ü
ì
ü
ï
ï
ï
ï
³
=
³
=
³
í
ý
í
ý
+
ï
ï
ï
ï
î
þ
î
þ
(16)
Using Dynamic Programming Based on Bayesian Inference in Selection Problems
http://dx.doi.org/10.5772/57423
131

In which, h (di, j
* (s))=
di, j
* (s)B(αi,k −1, βi,k −1)
(1 −di, j
* (s))B(α j,k −1, β j,k −1) .
To evaluate Pr{
p j,k¯
pi,k¯ ≥h (di, j
* (s))} in equation (16), let f 1(p j,k¯) and f 2(pi,k¯) to be the probability
distributions of p j,k¯ and pi,k¯, respectively. Then,
,
,
,
,
0.5
0.5
,
,
2
,
,
,
,
,
0.5
0.5
,
,
1
,
,
,
,
,
(
1)
(
)
(1
)
 
(
0.5) (
0.5)
(
1)
(
)
(1
)
(
0.5) (
0.5)
i k
i k
j k
j k
i k
i k
i k
i k
i k
i k
i k
j k
j k
j k
j k
j k
j k
j k
f
p
p
p
f p
p
p
a
b
a
b
a
b
a
b
a
b
a
b
-
-
-
-
G
+
+
=
-
G
+
G
+
G
+
+
=
-
G
+
G
+
(17)
Hence,
( )
(
)
{
}
(
)
(
)
( )
(
)
( )
(
)
*
,
,
,
,
,
,
*
,
,
1
1
*
,
,
,
1
,
2
,
,
,
0
0.5
0.5
1
1
0.5
0.5
,
,
,
,
,
,
0
Pr
(1
)
(1
)
i j
i k
i k
j k
j k
i k
i j
i k
j k
i j
i k
j k
i k
j k
i k
h d
s
p
i
i k
i k
j
j k
j k
j k
i k
h d
s
p
p
h d
s
p
f
p
f
p
dp
dp
A p
p
A p
p
dp
dp
a
a
b
b
-
-
-
-
³
=
=
-
-
ò ò
ò ò
(18)
where
,
,
,
,
,
,
,
,
(
1)
(
1)
,
.
(
0.5) (
0.5)
(
0.5) (
0.5)
j k
j k
i k
i k
i
j
i k
i k
j k
j k
A
A
a
b
a
b
a
b
a
b
G
+
+
G
+
+
=
=
G
+
G
+
G
+
G
+
(19)
By change of variables technique, we have:
( )
(
)
(
)
( )
(
)
( )
( )
(
)
( )
(
)
(
)
,
,
,
,
,
*
,
,
,
,
1
1
0.5
0.5
0
,
*
*
,
,
0
,
 and 
1
1
Pr
1
1
i k
j k
i k
j k
i k
i j
j k
i k
i k
i
j
h d
s
j k
i j
i j
i k
p
U
V
p
p
f U
A A U
V
V
UV
dV
p
h d
s
f U dU
F h d
s
p
b
b
a
a
a
-
-
+
-
=
=
=
-
-
ì
ü
ï
ï
³
=
-
=
-
í
ý
ï
ï
î
þ
ò
ò
(20)
For Bi, j{Si} we have
{ }
( )
( )
{
}
( )
{
}
( )
{
}
( )
(
)
(
)
*
,
,
,
*
*
*
,
,
,
,
,
Pr
Pr 1
( )
Pr
( )
1
1
i j
i
i j
i j
i j
i j
i j
i j
i j
B
S
B
i
d
s
B
j
d
s
B
j
d
s
F h
d
s
=
³
=
-
³
=
£
-
=
-
(21)
Dynamic Programming and Bayesian Inference, Concepts and Applications
132

c.
Bi, j{CS | N Si, j}
Bi, j{CS | N Si, j}is the belief of making the correct decision when none of the subspaces i and j
has been chosen as the optimal one. In other words, the maximum beliefs has been less than
di, j
* (s) and the process of decision-making continues to the next stage. In terms of stochastic
dynamic programming approach, the belief of this event is equal to the maximum belief of
making the correct decision in (s-1) stages. Since the value of this belief is discounted in the
current stage, using discount factor α,
{
}
*
,
,
, (
1)
i j
i j
i j
B
CS NS
V
s
a
=
-
(22)
Having all the belief terms of equation (11) evaluated in equations (12), (13), (14), (15), and (16),
and knowing that by partitioning the state space we have Bi, j{N Si, j}=1−(Bi, j{Si} + Bi, j{Sj}),
equation (11) can now be evaluated by substituting.
( )
( )
( )
{
}
( )
( )
( )
{
}
{
}
( )
{
}
( )
{
}
(
)}
( )
( )
( )
{
}
{
( )
( )
( )
{
}
(
)
( )
( )
{
}
( )
,
,
*
,
,
,
,
,
,
,
0.5
( ) 1
,
,
,
,
,
,
,
,
,
,
,
,
0.5
( ) 1
*
,
,
,
,
,
( )
max
{
Pr
Pr
1
Pr
( )
Pr
( )
max
Pr
Pr
1 1
Pr
Pr
i j
i j
i j
i j
i j
i j
i j
i j
i j
d
s
i j
i j
i j
i j
i j
i j
i j
i j
i j
i j
i j
i j
d
s
i j
i j
i j
i j
i j
V
s
B
i
B
i
d
s
B
j
B
j
d
s
B
NS
CS
B
i
d
s
B
j
d
s
B
i
B
i
d
s
B
j
B
j
d
s
V
s
B
i
d
s
B
j
d
a
£
£
£
£
=
³
+
³
+
-
³
-
³
=
³
+
³
+
-
-
³
-
³
( )
{
}
(
)}
s
(23)
2.2.1. Making the decision
Assuming that for the two biggest beliefs we have Bi, j(i)≥Bi, j( j), equation (23) can be written
as
( )
(
)
(
)
( )
( )
{
}
( )
(
)
(
)
( )
( )
{
}
(
)
*
*
*
,
,
,
,
,
*
*
*
,
,
,
,
,
( )
1 Pr
1 Pr
1
i j
i j
i j
i j
i j
i j
i j
i j
i j
i j
V
s
B
i
V
s
B
i
d
s
B
j
V
s
B
j
d
s
V
s
a
a
a
=
-
-
³
+
-
-
³
+
-
(24)
For the decision-making problem at hand, three cases may happen
1.
Bi, j(i)<αVi, j
* (s −1) :
In this case, both (Bi, j(i)−αVi, j
* (s −1)) and (Bi, j( j)−αVi, j
* (s −1)) are negative. Since we are
maximizing Vi, j(s, di, j(s)), then the two probability terms in equation (24) must be minimized.
This only happens when we let di, j
* (s)=1, making the probability terms equal to zero. Now
since Bi, j(i)<di, j
* (s)=1, we continue to the next stage.
Using Dynamic Programming Based on Bayesian Inference in Selection Problems
http://dx.doi.org/10.5772/57423
133

2.
Bi, j( j)>αVi, j
* (s −1) :
In this case, (Bi, j(i)−αVi, j
* (s −1)) and (Bi, j( j)−αVi, j
* (s −1)) are both positive and to maximize
Vi, j(s, di, j(s)) we need the two probability terms in equation (24) to be maximized. This only
happens when we let di, j
* (s)=0.5. Since Bi, j(i)>di, j
* (s)=0.5, we select population i as the optimal
subspace.
3.
Bi, j( j)≤αVi, j
* (s −1)≤Bi, j(i) :
In this case, one of the probability terms in equation (24) has positive coefficient and the other
has negative coefficient. In this case, in order to maximize Vi, j(s, di, j(s)) we take the derivative
as follows.
Substituting equations (20) and (21) in equation (24) we have
( )
(
)
( )
(
)
(
)
( )
(
)
(
)
{
}
( )
(
)
(
)
( )
(
)
(
)
{
}
(
)
*
,
,
,
,
,
*
*
,
,
,
,
,
1
1
1
1
1
i j
i j
i j
i j
i j
i j
i j
i j
i j
V
s d
s
B
i
V
s
F h
d
s
B
j
V
s
F h d
s
V
s
a
a
a
=
-
-
-
+
-
-
-
+
-
(25)
Thus following is obtained,
( )
(
)
(
)
( )
(
)
( )
(
)
(
)
( )
(
)
(
)
,
*
*
*
,
,
,
,
,
,
*
*
*
,
,
,
,
,
( )
1 Pr
1
1 Pr
1
j k
i j
i j
i j
i j
i k
j k
i j
i j
i j
i j
i k
p
V
s
B
i
V
s
h
d
s
p
p
B
j
V
s
h d
s
V
s
p
a
a
a
ì
ü
ï
ï
=
-
-
£
-
+
í
ý
ï
ï
î
þ
ì
ü
ï
ï
-
-
³
+
-
í
ý
ï
ï
î
þ
(26)
For determining Pr{
p j,k¯
pi,k¯ ≤h (1−di, j
* (s))}, first using an approximation, we assume that pi,k¯ is a
constant number equal to its mean, then we have:
( )
(
)
( )
(
)
{
}
(
)
( )
(
)
( )
(
)
(
)
( )
(
)
(
)
( )
(
)
( )
(
)
(
)
( )
(
)
(
)
*
,
,
,
*
,
,
1
*
,
,
,
1
,
,
0
*
1
,
,
*
1
,
,
,
1
,
1
*
1
,
,
*
2
*
,
,
,
1
,
1
Pr
1
Pr
1
1
1
,
1
1
,
i k
i j
j k
i j
i k
p
h
d
s
j k
i k
i j
j k
j k
i k
i j
i k
i j
i k
i k
i k
i j
i j
i j
j k
j k
p
h
d
s
p
p
p
h
d
s
f
p
dp
F p
h
d
s
F p
h
d
s
B
f
p
h
d
s
d
s
d
s
B
a
b
a
b
-
-
-
-
-
ì
ü
ï
ï
£
-
=
í
ý
ï
ï
î
þ
£
-
=
=
-
¶
-
=
-
¶
-
ò
(27)
Dynamic Programming and Bayesian Inference, Concepts and Applications
134

Also Pr{
p j,k¯
pi,k¯ ≥h (di, j
* (s))} is obtained as follows,
( )
(
)
( )
(
)
{
}
(
)
( )
(
)
( )
(
)
(
)
( )
(
)
(
)
(
)
( )
(
)
( )
(
)
(
)
( )
(
)
(
)
*
,
,
1
,
*
*
,
,
,
,
1
,
,
,
*
1
,
,
*
1
,
,
,
1
,
1
*
1
,
,
*
2
*
,
,
,
1
,
1
Pr
Pr
1
1
,
,
i k
i j
j k
i j
j k
i k
i j
j k
j k
p
h d
s
i k
i k
i j
i k
i j
i k
i k
i k
i j
i j
i j
j k
j k
p
h d
s
p
p
h d
s
f
p
dp
p
F p
h d
s
F p
h d
s
B
f
p
h d
s
d
s
d
s
B
a
b
a
b
-
-
-
-
ì
ü
ï
ï
³
=
³
=
=
í
ý
ï
ï
î
þ
-
¶
-
-
=
¶
ò
(28)
Now following can be resulted,
( )
(
)
( )
( )
(
)
(
)
(
)
( )
(
)
(
)
( )
(
)
(
)
( )
(
)
(
)
(
)
( )
(
)
(
)
( )
(
)
(
)
( )
(
)
(
)
( )
(
)
(
)
( )
,
,
,
,
1
,
1
*
*
,
,
1
,
,
2
*
,
,
1
,
1 1
,
1
,
1
*
*
,
,
1
,
,
2
*
,
,
1
,
1
*
*
,
,
,
*
,
,
,
,
0
,
1
1
 =
1
,
,
1
,
1
1
1
i j
i j
i j
i k
i k
i j
i j
i k
i j
i j
j k
j k
i k
i k
i j
i j
i k
i j
i j
j k
j k
i j
i j
i j
i j
i j
i j
V
s d
s
d
s
B
B
i
V
s
f
p
h
d
s
d
s
B
B
B
j
V
s
f
p
h d
s
d
s
B
B
i
V
s
d
s
d
B
j
V
s
a
b
a
a
b
a
b
a
a
b
a
a
-
-
-
-
-
-
-
-
¶
=
Þ
¶
-
-
-
-
-
-
-
Þ
-
-
-
=
-
-
-
( )
(
)
( )
( )
(
)
(
)
( )
(
)
(
)
(
)
,
1
,
1
,
1
,
1
2
*
1
,
1
*
2
,
,
*
,
,
1
1
1
1
i k
i k
i k
i k
i j
i j
i j
i j
i j
s
d
s
B
i
V
s
B
j
V
s
a
b
a
b
a
a
-
-
-
-
+
+
æ
ö
ç
÷
Þ
ç
÷
è
ø
=
æ
ö
-
-
ç
÷
+
ç
÷
ç
÷
-
-
-
è
ø
(29)
Now the approximate value of di, j(s) say d 1
i, j(s) is determined.
Second using another approximation, we assume that p j,k¯ is a constant number equal to its
mean thus with similar reasoning, following is obtained:
( )
( )
(
)
(
)
( )
(
)
(
)
(
)
,
1
,
1
2
,
1
*
2
,
,
*
,
,
1
1
1
1
i k
i k
i j
i j
i j
i j
i j
d
s
B
j
V
s
B
i
V
s
a
b
a
a
-
-
+
=
æ
ö
-
-
ç
÷
+
ç
÷
ç
÷
-
-
-
è
ø
(30)
Using Dynamic Programming Based on Bayesian Inference in Selection Problems
http://dx.doi.org/10.5772/57423
135

Therefore the approximate optimal value of di, j
* (s) can be determined from following equation,
( )
( )
( )
{
}
*
1
2
,
,
,
,
i j
i j
i j
d
s
Max d
s
d
s
=
(31)
3. An application for fault detection and diagnosis in multivariate
statistical quality control environments
3.1. Introduction
In this section, a heuristic threshold policy is applied in phase II of a control charting procedure
to not only detect the states of a multivariate quality control system, but also to diagnose the
quality characteristic(s) responsible for an out-of-control signal. It is assumed that the in-
control mean vector and in-control covariance matrix of the process have been obtained in
phase I.
3.2. Background
In a multivariate quality control environment, suppose there are m correlated quality charac‐
teristics whose means are being monitored simultaneously. Further, assume there is only one
observation on the quality characteristics at each iteration of the data gathering process, where
the goal is to detect the variable with the maximum mean shift. Let xki be the observation of
the ith quality characteristic, i =1, 2, ..., m, at iteration k, k =1, 2, ..., and define the observation
vector xk = xk1, xk2...., xkm
T  and observation matrix Ok =(x1, x2, ..., xk). After taking a new
observation, xk, define Bi(xk, Ok-1), the probability of variable i to be in an out-of-control state,
as
(
,
)
Pr{
,
},
i
i
B
OOC
=
k
k-1
k
k-1
x
O
x
O
(32)
where OOC stands for out-of-control. This probability has been called the belief of variable i
to be in out-of-control condition given the observation matrix up to iteration k −1 and the
observation vector obtained at iteration k.
Assuming the observations are taken independently at each iteration, to improve the belief of
the process being in an out-of-control state at the kth iteration, based on the observation matrix
Ok-1 and the new observation vector xk, we have
Pr{
,
}
Pr{
}
i
i
OOC
OOC
=
k
k-1
k
x
O
x
(33)
Dynamic Programming and Bayesian Inference, Concepts and Applications
136

Then, using the Bayesian rule the posterior belief is:
1
1
Pr{
,
,
}
(
,
)
Pr{
,
}
Pr{
,
}
Pr{
}Pr{
,
}
Pr{
,
,
}
Pr{
,
,
}
Pr{
}Pr{
,
}
i
i
i
i
i
i
m
m
j
j
j
j
j
OOC
B
OOC
OOC
OOC
OOC
OOC
OOC
OOC
=
=
=
=
=
=
å
å
k
k-1
k
k-1
k
k-1
k
k-1
k-1
k
k-1
k
k-1
k
k-1
k-1
k
k-1
x
O
x
O
x
O
x
O
O
x
O
x
O
x
O
O
x
O
(34)
Since the goal is to detect the variable with the maximum mean shift, only one quality
characteristic can be considered out-of-control at each iteration. In this way, there are m−1
remaining candidates for which m−1 quality characteristics are in-control. Hence, one can say
that the candidates are mutually exclusive and collectively exhaustive. Therefore, using the
Bayes' theorem, one can write equation (34) as
1
1
Pr{
}Pr{
}
(
,
)Pr{
}
(
,
)
Pr{
}Pr{
}
(
,
)Pr{
}
i
i
i
i
i
m
m
j
j
j
j
j
j
OOC
OOC
B
OOC
B
OOC
OOC
B
OOC
=
=
=
=
å
å
k-1
k
k-1
k-2
k
k
k-1
k-1
k
k-1
k-2
k
O
x
x
O
x
x
O
O
x
x
O
x
(35)
When the system is in-control, we assume the m characteristics follow a multinormal distri‐
bution with mean vector μ = μ1, μ2, ..., μm
T  and covariance matrix
2
1
12
1
2
21
2
2
2
1
2
.
.
.
.
.
.
.
m
m
m
m
m
s
s
s
s
s
s
s
s
s
é
ù
ê
ú
ê
ú
= ê
ú
ê
ú
ê
ú
ë
û
Σ
(36)
In out-of-control situations, only the mean vector changes and the probability distribution
along with the covariance matrix remain unchanged. In latter case, equation (35) is used to
calculate the probability of shifts in the process mean μ at different iterations. Moreover, in
order to update the beliefs at iteration k one needs to evaluate Pr{xk |OOCi}.
The term Pr{xk |OOCi} is the probability of observing xk if only the ith quality characteristic is
out-of-control. The exact value of this probability can be determined using the multivariate
normal density, A exp(−1
2(xk −μ1i)T Σ -1(xk −μ1i)), where μ1i denotes the mean vector in which
only the ith characteristic has shifted to an out-of-control condition and A  is a known constant.
Using Dynamic Programming Based on Bayesian Inference in Selection Problems
http://dx.doi.org/10.5772/57423
137

Since the exact value of the out-of-control mean vector μ1i is not known a priori, two approx‐
imations are used in this research to determine Pr{xk |OOCi}. Note that we do not want to
determine the exact probability. Instead, the aim is to have an approximate probability (a belief)
on each characteristic being out-of-control. In the first approximation method, define ICi to be
the event that all characteristics are in-control, and let Pr{xk | ICi} be the conditional probability
of 
observing 
xk 
given 
all 
characteristics 
are 
in-control. 
Further, 
let
xk
' = μ01, ..., xki, μ0i+1, ..., μ0m
T  in the aforementioned multivariate normal density, so that
Pr{xk | ICi} can be approximately evaluated using Pr{xk | ICi}=Pr{x'k | ICi}, where
Pr{x'k | ICi}= A exp(−1
2(xk
' −μ0)T Σ -1(xk
' −μ0)). Note that this evaluation is proportional to
exp(−1
2(
xki −μ0i
σi )
2), and since it is assumed that characteristic i is under control, no matter the
condition of the other characteristics, this approximation is justifiable.
In the second approximation method, we assume Pr{xk |OOCi}∝
1
Pr{xk | I Ci} . Although it is
obvious that Pr{xk |OOCi} is not equal to 
1
Pr{xk | I Ci} , since we only need a belief function to
evaluate Pr{xk |OOCi} and also we do not know the exact value of out-of-control mean vector,
this approximation is just used to determinePr{xk |OOCi}. Moreover, it can be easily seen that
the closer the value of the ith characteristic is to its in-control mean the smaller is Pr{xk |OOCi}
as expected. We thus let
2
0
1
1
Pr{
}
exp
;
1,2,...,
,
2
Pr{
}
ki
i
i
i
i
x
OOC
R
i
m
IC
m
s
æ
ö
æ
ö
-
ç
÷
µ
=
=
ç
÷
ç
÷
ç
÷
è
ø
è
ø
k
k
x
x
(37)
where R is a sufficiently big constant number to ensure the above definition is less than one.
The approximation to Pr{xk |OOCi} in equation (37) has the following two properties:
• It does not require the value of out-of-control means to be known.
• The determination of a threshold for the decision-making process (derived later) will be
easier.
Niaki and Fallahnezhad [8] defined another equation for the above conditional probability and
showed that if a shift occurs in the mean of variable i, thenLim
k→∞Bi(xk, Ok−1)= Bi =1. They
proposed a novel method of detection and classification and used simulation to compare its
performances with that of existing methods in terms of the average run length for different
mean shifts. The results of the simulation study were in favor of their proposed method in
almost all shift scenarios. Besides using a different equation, the main difference between the
current research and Niaki and Fallahnezhad [8] is that the current work develops a novel
heuristic threshold policy, in which to save sampling cost and time or when these factors are
constrained, the number of the data gathering stages is limited.
Dynamic Programming and Bayesian Inference, Concepts and Applications
138

3.3. The proposed procedure
Assuming a limited number of the data gathering stages, N , to detect and diagnose charac‐
teristic(s), a heuristic threshold policy-based model is developed in this Section. The frame‐
work of the proposed decision-making process follows.
Step I
Define i =1, 2, ..., m as the set of indices for the characteristics, all of which having the potential
of being out-of-control.
Step II
Using the maximum entropy principle, initialize Bi(O0)=1 / m as the prior belief of the ith
variable to be out-of-control. In other words, at the start of the decision-making process all
variables have an equal chance of being out-of-control. Set the discount rateα, the maximum
probability of correct selection when N  decision making stages remainsV (N ), and the
maximum number of decision making stagesN .
Step III
Set k =0
Step IV
Obtain an observation of the process.
Step V
Estimate the posterior beliefs, Bi(Ok) (fori =1, 2, ..., m), using equation (35).
Step VI
Obtain the order statistics on the posterior beliefs Bi(Ok) such that
B(1)(Ok)< B(2)(Ok)<...< B(m)(Ok).
Furthermore, let Bgr(Ok)= B(m)(Ok) and Bsm(Ok)= B(m−1)(Ok).
Step VII
Assume the variables with the indices i = gr and j =sm are the candidates of being out-of-
control, where N  decision-making steps are available. Define V (N , di, j(k)) the probability of
correct choice between the variables i and j, where di, j(k) is the acceptable belief. Also, define
CS the event of correct selection and event Ei, j the existence of two out-of-control candidate
variables i and j. Then, we have:
(
)
,
,
,
,
( )
Pr{
}
Pr {
}
i j
i j
i j
V N d
k
CS E
CS
=
@
(38)
where " ≜ " means "defined as."
Using Dynamic Programming Based on Bayesian Inference in Selection Problems
http://dx.doi.org/10.5772/57423
139

Assuming di, j
* (k) the maximum point of V (N , di, j(k)), called the minimum acceptable belief,
we have
(
)
(
)
{
}
{
}
{
}
,
*
*
,
,
,
,
( )
,
( )
(
)
,
( )
Pr
i j
i j
i j
i j
i j
d
k
V N d
k
V
N
Max V N d
k
Max
CS
=
@
@
(39)
Let Si and Sj be the event of selecting i and j as the out-of-control variables, respectively, and
N Si, j be the event of not selecting any. Then, by conditioning on the probability, we have:
(
)
{
}
{
}
{
}
{ }
{
}
{ }
{
}
{
}
{
}
*
,
,
,
,
,
,
,
,
,
,
x Pr
Pr
Pr
Pr
Pr
Pr
Pr
i j
i j
i j
i
i j
i
i j
j
i j
j
i j
i j
i j
i j
V
N
Ma
CS
Max
CS S
S
CS S
S
CS NS
NS
=
=
+
+
(40)
At the kth iteration, the conditional bi-variate distribution of the sample means for variables gr
and sm, i.e, Xk, j=gr,sm| Xk, j≠gr,sm, is determined using the conditional property of multivariate
normal distribution given in appendix 1. Moreover, knowing E(xk, j)=μj and evaluating the
conditional mean and standard deviation (see appendix 1) results in
(
)
(
)
,
,
,
i
k i
k j
i
k j
j
j
E X
X
X
s
m
r
m
s
=
+
-
(41)
and
(
)
(
)
,
,
,
i
k i
k j
i
k j
j
j
E X
X
X
s
m
r
m
s
=
+
-
(42)
Based on the decomposition method of Mason et al. [9], define statistics Tk, j and Tk,i| j as
,
,
k j
j
k j
j
X
T
m
s
æ
ö
-
ç
÷
= ç
÷
è
ø
(43)
(
)
,
,
,
,
,
,
k i
k j
k i
k i
k j
k i j
X
X
X
E X
X
T
s
æ
ö
-
ç
÷
= ç
÷
ç
÷
è
ø
(44)
Thus, when the process is in-control, the statistics Tk, j and Tk,i| j follow a standard normal
distribution [9].
Dynamic Programming and Bayesian Inference, Concepts and Applications
140

Now, let Bi, j(i; xk, Ok−1) denote the probability of correct selection conditioned on selecting i
as the out-of-control variable. Hence,
2
,
2
2
,
,
2
,
2
2
,
,
(0.5
)
1
,
1
(0.5
)
(0.5
)
1
1
(0.5
)
1
,
1
(0.5
)
(0.5
)
1
1
(
)
( ;
,
)
(
)
(
)
(
)
( ;
,
)
(
)
(
)
k i j
k i j
k j
k j
k i j
k j
T
i
k
i j
k
k
T
T
j
k
i
k
T
j
k
i j
k
k
T
T
j
k
i
k
B O
e
B
i x O
B O
e
B O
e
B O
e
B
j x O
B O
e
B O
e
-
-
-
-
-
-
-
-
=
+
=
+
(45)
Then, the probability measure Pri, j{CS |Si} is calculated using the following equation,
,
,
1
Pr {
}
( ;
,
)
i j
i
i j
k
k
CS S
B
i x O -
=
(46)
The probability measure Pri, j{Si} is defined as the probability of selecting variable i to be out-
of-control. Regarding to the explained strategy, we have:
(
)
(
)
(
)
(
)
( )
,
1
,
1
,
1
,
,
1
;
,
,
;
,
,
;
,
;
,
i
i j
k
k
i j
k
k
i j
k
k
i j
i j
k
k
S
B
i x O
B
i x O
Max
B
i x O
d
k
B
j x O
-
-
-
-
º
ì
ü
ì
ü
ï
ï
ï
ï
=
³
í
í
ý
ý
ï
ï
ï
ï
î
þ
î
þ
(47)
Since Bi, j(i; xk, Ok−1) + Bi, j( j; xk, Ok−1)=1 and the value of beliefs are not negative, we conclude
(
)
(
)
{
}
,
1
,
1
max
;
,
,
;
,
0.5
i j
k
k
i j
k
k
B
i x O
B
j x O
-
-
³
(48)
Without interruption of assumptions, we can change the variation interval of di, j(k) from [0,1]
to [0.5,1]. Hence,
(
)
{
}
,
1
,
;
,
( )
i
i j
k
k
i j
S
B
i x O
d
k
-
º
³
(49)
By similar reasoning, we have:
(
)
{
}
,
1
,
;
,
( )
j
i j
k
k
i j
S
B
j x O
d
k
-
º
³
(50)
The term Pri, j{CS | N Si, j} denotes the probability of correct selection conditioned on excluding
the candidates i and j as the solution. In other words, the maximum belief has been less than
Using Dynamic Programming Based on Bayesian Inference in Selection Problems
http://dx.doi.org/10.5772/57423
141

the threshold (minimum acceptable belief) di, j
* (k) and the decision making process continues
to the next stage. In terms of stochastic dynamic programming approach, the probability of
this event is equal to the maximum probability of correct selection when there are N −1 stages
remaining. The discounted value of this probability in the current stage using the discount
factor α equals to α Vi, j(N −1). Further, since we partitioned the decision space into events
{N Si, j;Si;Sj}, we have:
{
}
{ }
{ }
(
)
,
,
,
,
Pr
1
Pr
Pr
i j
i j
i j
i
i j
j
NS
S
S
=
-
+
(51)
Now we evaluate Vi, j
* (N ) as follows,
(
)
(
)
{
}
(
)
(
)
{
}
{
}
{
}
{
}
,
*
,
,
1
,
,
1
,
,
1
,
,
1
,
0.5
( ) 1
,
,
1
,
,
,
,
1
,
(
)
;
,
Pr
;
,
( )
;
,
Pr
;
,
( )
1
Pr
( ;
,
)
( )
Pr
Pr
( ;
,
)
( )
i j
i j
i j
k
k
i j
i j
k
k
i j
i j
k
k
i j
i j
k
k
i j
d
k
i j
i j
k
k
i j
i j
i j
i j
k
k
i j
V
N
B
i x O
B
i x O
d
k
Max
B
j x O
B
j x O
d
k
B
i x O
d
k
NS
CS
B
j x O
d
k
-
-
-
-
£
£
-
-
=
ì
ü
ï
ï
ï
ï
³
+
ï
ï
ï
ï
³
+
í
ý
ï
æ
ö
ï
-
³
-
ç
÷
ï
ç
÷
ï
ç
÷
³
è
ø
î
(
)
(
)
{
}
(
)
(
)
{
}
(
)
(
)
{
}
(
)
{
}
,
,
1
,
,
1
,
,
1
,
,
1
,
0.5
( ) 1
,
,
1
,
*
,
,
1
,
;
,
Pr
;
,
( )
;
,
Pr
;
,
( )
1
Pr
;
,
( )
1
Pr
;
,
( )
i j
i j
k
k
i j
i j
k
k
i j
i j
k
k
i j
i j
k
k
i j
d
k
i j
i j
k
k
i j
i j
i j
k
k
i j
B
i x O
B
i x O
d
k
Max
B
j x O
B
j x O
d
k
B
i x O
d
k
V
N
B
j x O
d
k
a
-
-
-
-
£
£
-
-
ï
ï
ï
ï
þ
ì
ü
ï
ï
ï
ï
³
+
ï
ï
ï
ï
=
³
+
í
ý
ï
ï
æ
ö
ï
ï
-
³
-
ç
÷
ï
ï
-
ç
÷
ï
ï
ç
÷
³
è
ø
î
þ
(52)
In other words,
(
)
(
)
{
}
(
)
(
)
{
}
(
)
{
}
(
)
{
}
,
,
,
,
,
*
,
,
,
,
,
0.5
( ) 1
,
,
,
*
,
,
,
;
Pr
;
( )
(
)
;
Pr
;
( )
1
Pr
;
( )
(
1)
Pr
;
( )
i j
i j
k
i j
i j
k
i j
i j
i j
k
i j
i j
k
i j
d
k
i j
i j
k
i j
i j
i j
k
i j
B
i O
B
i O
d
k
V
N
Max
B
j O
B
j O
d
k
B
i O
d
k
V
N
B
j O
d
k
a
£
£
ì
ü
ï
ï
ï
ï
³
+
ï
ï
ï
ï
=
³
+
í
ý
ï
ï
æ
ö
ï
ï
-
³
ç
÷
ï
ï
-
ç
÷
ï
ï
ç
÷
-
³
è
ø
î
þ
(53)
The method of evaluating the minimum acceptable belief dgr,sm
*
(k) is given in Appendix 2.
Dynamic Programming and Bayesian Inference, Concepts and Applications
142

Step VIII: The Decision Step
If the belief Bgr,sm(gr; xk, Ok−1) in the candidate set (sm, gr) is equal to or greater than dgr,sm
*
(k)
then choose the variable with index gr to be out-of-control. In this case, the decision-making
process ends. Otherwise, without having any selection at this stage, obtain another observa‐
tion, lower the number of remaining decision-stages to N −1, set k =k + 1, and return to step V
above. The process will continue until either the stopping condition is reached or the number
of stages is finished. The optimal strategy with N  decision-making stages that maximizes the
probability of correct selection would be resulted from this process.
In what follows, the procedure to evaluate Vi, j
* (N ) of equation (53) is given in detail.
3.4. Method of evaluating Vi, j
* (N )
Using di, j
* (k) as the minimum acceptable belief, from equation (53) we have
(
)
(
)
(
)
( )
{
}
(
)
(
)
(
)
( )
{
}
*
*
*
,
,
,
,
,
*
*
*
,
,
,
,
,
(
)
;
(
1) Pr
;
;
(
1) Pr
;
(
1)
i j
i j
k
i j
i j
k
i j
i j
k
i j
i j
k
i j
i j
V
N
B
i O
V
N
B
i O
d
k
B
j O
V
N
B
j O
d
k
V
N
a
a
a
=
-
-
³
+
-
-
³
+
-
(54)
Then, for the decision-making problem at hand, three cases may occur
1.
Bi, j(i;Ok)<αVi, j
* (N −1)
In this case, both (Bi, j(i;Ok)−αVi, j
* (N −1)) and (Bi, j(i;Ok)−αVi, j
* (N −1)) are negative. Since we
are maximizing Vi, j(N , di, j(k)), the two probability terms in equation (54) must be minimized.
This only happens when di, j
* (k)=1, making the probability terms equal to zero. In other words,
since Bi, j(i;Ok)<di, j
* (k)=1, we continue to the next stage.
2.
Bi, j( j;Ok)>αVi, j
* (s −1)
In this case, (Bi, j(i;Ok)−αVi, j
* (N −1)) and (Bi, j(i;Ok)−αVi, j
* (N −1)) are both positive and to
maximize Vi, j(N , di, j(k)) we need the two probability terms in equation (54) to be maximized.
This only happens when di, j
* (k)=0.5. In other words, since Bi, j(i;Ok)>di, j
* (k)=0.5, the variable
with the index i is selected.
3.
Bi, j( j;Ok)<αVi, j
* (N −1)< Bi, j(i;Ok)
In this case, one of the probability terms in equation (54) has a positive and the other a negative
coefficient. Then, in order to maximize Vi, j(N , di, j(k)), the first derivative on di, j(k) must be
equated to zero. To do this, define h (dgr,sm(k)) and r(dgr,sm(k)) as follows:
Using Dynamic Programming Based on Bayesian Inference in Selection Problems
http://dx.doi.org/10.5772/57423
143

(
)
(
)
(
)
(
)
,
1
,
,
1
( )
,
( )
1
( )
,
gr sm
gr
k
gr sm
gr sm
sm
k
d
k B
gr O
h d
k
d
k
B
sm O
-
-
=
-
(55)
(
)
(
)
(
)
(
)
,
1
,
,
1
( )
,
( )
1
( )
,
gr sm
sm
k
gr sm
gr sm
gr
k
d
k B
sm O
r d
k
d
k
B
gr O
-
-
=
-
(56)
We first present the method of evaluating Pr{Bgr,sm(sm;Ok)≥dgr,sm(k)} as follows.
(
)
{
}
(
)
(
)
(
)
( )
(
)
2
,
2
2
,
,
2
2
,
,
,
,
(
)
1
,
(
)
(
)
1
1
(
)
(
)
,
Pr
;
( )
,
Pr
( )
,
,
Pr
k gr sm
k gr sm
k sm
k gr sm
k sm
gr sm
k
gr sm
T
sm
k
gr sm
T
T
sm
k
gr
k
T
T
gr sm
B
sm O
d
k
B
sm O
e
d
k
B
sm O
e
B
gr O
e
e
h d
k
e
-
-
-
³
=
ì
ü
ï
ï
³
í
ý
ï
ï
+
î
þ
ì
ü
=
³
í
ý
î
þ
(57)
Then, the method of evaluating probability terms in equation (57) is given in appendix 2.
With similar reasoning, we have,
(
)
{
}
( )
(
)
2
2
,
,
(
)
(
)
,
,
,
Pr
;
( )
Pr
k gr sm
k sm
T
T
gr sm
k
gr sm
gr sm
B
gr O
d
k
e
r d
k
e
ì
ü
³
=
³
í
ý
î
þ
(58)
The method of determining the minimum acceptable belief is given in appendix 2.
4. An application for fault detection in uni-variate statistical quality control
environments
In a uni-variate quality control environment, if we limit ourselves to apply a control charting
method, most of the information obtained from data behavior will be ignored. The main aim
of a control charting method is to detect quickly undesired faults in the process. However, we
may calculate the belief for the process being out-of-control applying Bayesian rule at any
iteration in which some observations on the quality characteristic are gathered. Regarding
these beliefs and a stopping rule, we may find and specify a control threshold for these beliefs
and when the updated belief in any iteration is more than this threshold, an out-of-control
signal is observed.
In Decision on Beliefs, first, all probable solution spaces will be divided into several candidates
(the solution is one of the candidates), then a belief will be assigned to each candidate consid‐
Dynamic Programming and Bayesian Inference, Concepts and Applications
144

ering our experiences and finally, the beliefs are updated and the optimal decision is selected
based on the current situation. In a SPC problem, a similar decision-making process exits. First,
the decision space can be divided into two candidates; an in-control or out-of-control produc‐
tion process. Second, the problem solution is one of the candidates (in-control or out-of-control
process). Finally, a belief is assigned to each candidate so that the belief shows the probability
of being a fault in the process. Based upon the updated belief, we may decide about states of
the process (in-control or out-of-control process).
4.1. Learning — The beliefs and approach for its improvement
For simplicity, individual observation on the quality characteristic of interest in any iteration
of data gathering process was gathered. At iteration k of data gathering process,
Ok =(x1, x2, ......, xk)was defined as the observation vector where resemble observations for
previous iterations 1, 2, …, k. After taking a new observation, Ok-1 the belief of being in an out-
of-control state is defined as B(xk, Ok−1)=Pr{Out −of −control | xk, Ok−1}. At this iteration, we
want to update the belief of being in out-of-control state based on observation vector Ok−1 and
new observation xk. If we define B(Ok−1)= B(xk−1, Ok−2) as the prior belief of an out-of-control
state, in order to update the posterior belief B(xk, Ok−1), since we may assume that the
observations are taken independently in any iteration, then we will have
{
}
{
}
1
Pr
,
Pr
k
k
k
x Out
of
control O
x Out
of
control
-
-
-
=
-
-
(59)
With this feature, the updated belief is obtained using Bayesian rule:
1
1
1
1
1
1
1
Pr{
,
}
(
,
)
Pr{
,
}
Pr{
}
Pr{
}Pr{
,
}
Pr{
}
k
k
k
k
k
k
k
k
k
k
k
k
k
Out
of
control x O
B x O
Out
of
control x O
x O
Out
of
control O
x Out
of
control O
x O
-
-
-
-
-
-
-
-
-
=
-
-
=
-
-
-
-
=
(60)
Since in-control or out-of-control state partition the decision space, we can write equation
(60) as
1
1
1
1
1
1
1
Pr{
}Pr{
}
(
,
)
Pr{
}Pr{
}
Pr{
}Pr{
}
(
)Pr{
}
(
)Pr{
}
(1
(
))Pr{
k
k
k
k
k
k
k
k
k
k
k
k
k
Out
of
control O
x Out
of
control
B x O
Out
of
control O
x Out
of
control
In
control O
x In
control
B O
x Out
of
control
B O
x Out
of
control
B O
-
-
-
-
-
-
-
-
-
-
-
=
-
-
-
-
+
-
-
-
-
=
-
-
+
-
}
k
x In
control
-
(61)
Assuming the quality characteristic of interest follows a normal distribution with mean μ and
variance σ2, we use equation (61) to calculate both beliefs for occurring positive or negative
shifts in the process mean μ.
Using Dynamic Programming Based on Bayesian Inference in Selection Problems
http://dx.doi.org/10.5772/57423
145

• Positive shifts in the process mean
The values of B +(Ok), showing the probability of occurring a positive shift in the process mean,
will be calculated applying equation (61) recursively. Pr{xk | In −control} is defined by the
following equation,
{
}
Pr
0.5
k
x In
control
-
=
(62)
For positive shift, the probability of being a positive shift in the process at iteration k,
Pr{xk |Out −of −control}, is calculated using equation (63).
(
)
Pr{
}
k
k
x Out
of
control
x
j
-
-
=
(63)
where φ(xk) is the cumulative probability distribution function for the normal distribution
with mean μ and variance σ2. Above probabilities are not exact probabilities and they are a
kind of belief function to ascertain good properties for B +(Ok)
Therefore B +(Ok) is determined by the following equation,
(
)
(
) (
)
(
) (
)
(
)
(
)
1
1
1
0.5 1
k
k
k
k
k
k
B
O
x
B
O
B
O
x
B
O
j
j
+
-
+
+
+
-
-
=
+
-
(64)
• Negative shifts in the process mean
The values of B −(Ok) denotes the probability of being a negative shift in the process mean that
is calculated using equation (61) recursively. In this case, Pr{xk | In −control} is defined by the
following equation,
{
}
Pr
0.5
k
x In
control
-
=
(65)
Also is Pr{xk |Out −of −control} calculated using equation (66).
(
)
Pr{
}
1
k
k
x Out
of
control
x
j
-
-
=
-
(66)
Thus B −(Ok) is determined by the following equation,
(
)
(
)
(
)
(
)
(
)
(
)
(
)
(
)
(
)
1
1
1
1
1
0.5 1
k
k
k
k
k
k
B
O
x
B
O
B
O
x
B
O
j
j
-
-
-
-
-
-
-
-
=
-
+
-
(67)
Dynamic Programming and Bayesian Inference, Concepts and Applications
146

4.2. A decision on beliefs approach
We present a decision making approach in terms of Stochastic Dynamic Programming
approach. Presented approach is like an optimal stopping problem.
Suppose n stages for decision making is remained and two decisions are available.
• A positive shift is occurred in the process mean
• No positive shift is occurred in the process mean
Decision making framework is as follows:
• Gather a new observation.
• Calculate the posterior Beliefs in terms of prior Beliefs.
• Order the current Beliefs as an ascending form and choose the maximum.
• Determine the value of the minimum acceptable belief (d +(n) is the minimum acceptable
belief for detecting the positive shift and d −(n) is the least acceptable belief for detecting the
negative shift)
• If the maximum Belief was more than the minimum acceptable belief, d +(n), select the belief
candidate with maximum value as a solution else go to step 1.
• In terms of above algorithm, the belief with maximum value is chosen and if this belief was
more than a control threshold like d +(n), the candidate of that Belief will be selected as
optimal candidate else the sampling process is continued. The objective of this model is to
determine the optimal values of d +(n). The result of this process is the optimal strategy with
n decision making stages that maximize the probability of correct selection.
Suppose new observation xk is gathered. (k is the number of gathered observations so far).
V (n, d +(n)) is defined as the probability of correct selection when n decision making stages
are remained and we follow d +(n) strategy explained above also V (n) denotes the maximum
value of V (n, d +(n)) thus,
( )
( )
( )
(
)
{
}
,
d
n
V n
Max V n d
n
+
+
=
(68)
CS is defined as the event of correct selection. S1 is defined as selecting the out-of-control
condition (positive shift) as an optimal solution and S2 is defined as selecting the in-control
condition as an optimal decision and NS is defined as not selecting any candidate in this stage.
Hence, using the total probability law, it is concluded that:
( )
(
)
1
1
2
2
,
x{Pr{
}}
Pr{
}Pr{
}
Pr{
}Pr{
}
Pr{
}Pr{
}
V n d
n
Ma
CS
CS S
S
CS S
S
CS NS
NS
+
=
=
+
+
(69)
Using Dynamic Programming Based on Bayesian Inference in Selection Problems
http://dx.doi.org/10.5772/57423
147

Pr{CS |S1} denotes the probability of correct selection when candidate S1 is selected as the
optimal candidate and this probability equals to its belief, B +(Ok), and with the same discus‐
sion, it is concluded that Pr{CS |S2}=1−B +(Ok)
Pr{S1} is the probability of selecting out of control candidate (positive shift) as the solution thus
following the decision making strategy, we should have B +(Ok)=max(B +(Ok), 1−B +(Ok)) and
B +(Ok)>d +(n) that is equivalent to following,
{ }
(
)
( )
{
}
( )
1
Pr
Pr
,
0.5,1
k
S
B
O
d
n
d
n
+
+
+
é
ù
=
>
Î ë
û
(70)
With the same reasoning, it is concluded that,
{ }
(
)
( )
{
}
( )
2
Pr
Pr 1
,
0.5,1
k
S
B
O
d
n
d
n
+
+
+
é
ù
=
-
>
Î ë
û
(71)
1.
Pr{CS | NS} denotes the probability of correct selection when none of candidates has been
selected and it means that the maximum value of the beliefs is less than d +(n) and the
process of decision making continues to latter stage. As a result, in terms of Dynamic
Programming Approach, the probability of this event equals to maximum of probability
of correct selection in latter stage (n-1), V (n −1), but since taking observations has cost,
then the value of this probability in current time is less than its actual value and by using
the discounting factor α, it equals αV (n −1)
2.
Since 
the 
entire 
solution 
space 
is 
partitioned, 
it 
is 
concluded 
that
Pr{CS | NS}=1−(Pr{S1} + Pr{S2})
By the above preliminaries, the function V (n) is determined as follows:
( )
( )
( )
{
}
( )
{
}
( )
{
}
( )
{
}
(
)
( )
( )
{
} (
)
( )
{
}
( )
{
}
( )
{
}
(
)
0.5
1
0.5
1
(
)Pr
(
)
(1
(
))Pr 1
(
)
max
Pr{
} 1
Pr
(
)
Pr 1
(
)
(
)Pr
(
)
1
(
) Pr 1
(
)
max
(
1) 1
Pr
(
)
Pr 1
(
)
k
k
k
k
d
n
k
k
k
k
k
k
d
n
k
k
V n
B
O
B
O
d
n
B
O
B
O
d
n
CS NS
B
O
d
n
B
O
d
n
B
O
B
O
d
n
B
O
B
O
d n
V n
B
O
d
n
B
O
d
n
a
+
+
+
+
+
+
+
+
+
+
+
+
<
<
+
+
+
+
+
+
+
+
+
<
<
=
é
ù
>
+
-
-
>
ê
ú
ê
ú
+
-
>
-
-
>
ê
ú
ë
û
é
>
+
-
-
>
ê
=
ê+
-
-
>
-
-
>
ë
ù
ú
ú
ê
úû
(72)
In terms of above equation, V (n, d +(n)) is obtained as follows:
( )
(
)
( )
{
} (
)
( )
{
}
(
)
( )
{
}
( )
{
}
(
)
(
)Pr
(
)
1
(
) Pr (1
(
))
,
1 1
Pr
(
)
Pr 1
(
)
k
k
k
k
k
k
B
O
B
O
d
n
B
O
B
O
d
n
V n d
n
V n
B
O
d
n
B
O
d
n
a
+
+
+
+
+
+
+
+
+
+
+
é
ù
>
+
-
-
>
ê
ú
= ê
ú
+
-
-
>
-
-
>
ê
ú
ë
û
(73)
Dynamic Programming and Bayesian Inference, Concepts and Applications
148

Calculation method for V (n, d +(n)) :
B +(gr, Ok) and B +(sm, Ok) are defined as follows:
(
)
(
)
(
)
{
}
(
)
(
)
(
)
{
}
,
max
,1
,
min
,1
k
k
k
k
k
k
B
gr O
B
O
B
O
B
gr O
B
O
B
O
+
+
+
-
+
+
=
-
=
-
(74)
Now equation (73) is rewritten as follows:
( )
(
)
(
)
(
)
( )
{
}
(
)
(
)
( )
{
}
(
)
,
(
,
)
1 Pr
(
,
)
(
,
)
1 Pr
(
,
)
1
k
k
k
k
V n d
n
B
gr O
V n
B
gr O
d
n
B
sm O
V n
B
sm O
d
n
V n
a
a
a
+
+
+
+
+
+
+
=
-
-
>
+
-
-
>
+
-
(75)
There are three conditions:
1.
B +(gr, Ok)<αV (n −1)
In this condition, both B +(gr, Ok)−αV (n −1) and B +(sm, Ok)−αV (n −1) are negative, thus we
should have d +(n)=1 in order to maximize V (n, d +(n)). Since B +(gr, Ok)<d +(n)=1, we don’t
select any candidate in this condition and sampling process continues.
2.
B +(sm, Ok)>αV (n −1)
In this condition, both B +(gr, Ok)−αV (n −1) and B +(sm, Ok)−αV (n −1) are positive, thus we
should have d +(n)=0.5 in order to maximize V (n, d +(n)). since B +(gr, Ok)>d +(n)=0.5, we
select the candidate of belief B +(gr, Ok) as the solution.
3.
B +(sm, Ok)<αV (n −1)< B +(gr, Ok)
In this condition, one of the probabilities in equation (10) has positive coefficient and one has
negative coefficient, to maximize V (n, d +(n)), optimality methods should be applied.
• Definition:h (d +(n)) is defined as follows:
( )
(
)
( )
(
)
(
)
( )
(
)
(
)
1
1
1
1
k
k
d
n
B
O
h d
n
d
n
B
O
+
+
-
+
+
+
-
-
=
-
(76)
First the value of Pr{B +(Ok)>d +(n)} is determined as follows:
Using Dynamic Programming Based on Bayesian Inference in Selection Problems
http://dx.doi.org/10.5772/57423
149

( )
{
}
(
)
(
)
(
)
(
)
(
)
(
)
( )
(
)
( )
(
)
{
}
( )
(
)
1
1
1
1
0.5
Pr
(
)
Pr
Pr
0.5
1
0.5
k
k
k
k
k
k
k
x
B
O
x
B
O
B
O
B
O
d
n
d
n
x
h d
n
h d
n
j
j
j
+
-
+
+
+
+
-
-
+
+
+
ì
ü
ï
ï
ï
ï
+
-
>
=
=
í
ý
ï
ï
>
ï
ï
î
þ
>
=
-
(77)
Since φ(xk) is a cumulative distribution function thus it follows a uniform distribution function
in interval [0, 1], thus the above equality is concluded.
With the same reasoning, it is concluded that:
( )
{
}
( )
{
}
( )
(
)
Pr 1
(
)
Pr 1
(
)
0.5
1
k
k
B
O
d
n
d
n
B
O
h
d
n
+
+
+
+
+
-
³
=
-
³
=
-
(78)
Now equation (73) can be written as follows:
( )
(
)
( )
(
)
(
)
(
)
(
)
( )
(
)
(
)
( )
(
)
(
)
( )
(
)
(
)
0.5
1
1
0.5
1
0.5
1
( )
max
1 1
0.5 1
0.5
1
k
k
d
n
B
O
h d
n
B
O
h
d
n
V n
V n
h d
n
h
d
n
a
+
+
+
+
+
+
+
<
<
é
ù
-
+
-
-
ê
ú
=
ê
ú
+
-
-
-
-
-
ê
ú
ë
û
(79)
And equation (79) can be written as follows:
( )
(
)
(
)
(
)
(
)
( )
(
)
(
)
(
)
(
)
(
)
( )
(
)
(
)
,
1
1
0.5
1
1 0.5
1
1
k
k
V n d
n
B
O
V n
h d
n
B
O
V n
h
d
n
V n
a
a
a
+
+
+
+
+
=
-
-
-
+
-
-
-
-
+
-
(80)
Since V *(n)= Max
0.5<d +(n)<1
V (n, d +(n))  thus it is sufficient to maximize the real value function
V (n, d +(n)), therefore; we should find the function value in points where first derivative is
equated to zero as follows,
( )
(
)
( )
(
)
(
)
(
)
(
)
(
)
(
)
( )
(
)
( )
( )
(
)
(
)
(
)
(
)
(
)
(
)
2
2
,
1
1
0
1
1
1
1
1
1
1
k
k
k
k
V n d
n
B
O
V n
d
n
d
n
B
O
V n
d
n
d
n
B
O
V n
B
O
V n
a
a
a
a
+
+
+
+
+
+
+
+
+
¶
-
-
-
=
Þ -
=
¶
-
-
-
Þ
=
-
-
-
+
-
-
-
(81)
Dynamic Programming and Bayesian Inference, Concepts and Applications
150

The optimal threshold d +(n) is determined by the above equation. Since the optimal value of
d +(n) should be in the interval [0.5, 1] thus it is concluded that the optimal value of d +(n) will
be determined as follows:
( )
(
)
(
)
(
)
(
)
(
)
(
)
1
,0.5
1
1
1
1
k
k
d
n
Max
B
O
V n
B
O
V n
a
a
+
+
+
é
ù
ê
ú
ê
ú
ê
ú
=
ê
ú
ê
ú
-
-
ê
ú
-
+
ê
ú
-
-
-
ë
û
(82)
The above method is presented for detecting the positive shifts in the process mean and can
be adapted for detecting the negative shifts with the same reasoning.
The general decision making algorithm is summarized as follows:
1.
Set k=0 and the initial beliefs B +(O0)=0.5, B −(O0)=0.5.
2.
Gather an observation and set k =k + 1, n =n −1.
3.
If n <0, then no shift is occurred in the process mean and decision making stops.
4.
Update the values for the beliefs B −(Ok), B +(Ok) by equation (61).
5.
If Min(B +(Ok), 1−B +(Ok))>αV (n −1), then if Max(B +(Ok), 1−B +(Ok))= B +(Ok), it is
concluded that a positive shift is occurred in the process mean and decision making stops,
also if Max(B +(Ok), 1−B +(Ok))=1−B +(Ok), then no positive shift is occurred in the process
mean and decision making stops.
6.
If Max(B +(Ok), 1−B +(Ok))<αV (n −1), then data is not sufficient for detecting the positive
shift and go to stage 2 after checking the occurrence of negative shift in the rest of the
algorithm.
7.
If Min(B −(Ok), 1−B −(Ok))>αV (n −1) then if Max(B −(Ok), 1−B −(Ok))= B −(Ok) it is con‐
cluded that a negative shift is occurred the process mean and decision making stops and
if Max(B −(Ok), 1−B −(Ok))=1−B −(Ok), then no negative shift is occurred in the process
mean and decision making stops.
8.
If Max(B −(Ok), 1−B −(Ok))<αV (n −1), then data is not sufficient for detecting the negative
shift and go to stage 2.
9.
If Max(B +(Ok), 1−B +(Ok))>αV (n −1)>Min(B +(Ok), 1−B +(Ok)), then determine the value
of d +(n) (minimum acceptable belief for detecting the positive shift) by the following
equation:
Using Dynamic Programming Based on Bayesian Inference in Selection Problems
http://dx.doi.org/10.5772/57423
151

( )
(
)
(
)
(
)
(
)
(
)
(
)
1
,0.5
1
1
1
1
k
k
d
n
Max
B
O
V n
B
O
V n
a
a
+
+
+
=
æ
ö
ç
÷
ç
÷
ç
÷
ç
÷
ç
÷
-
-
ç
÷
-
+
ç
÷
-
-
-
è
ø
(83)
10. If Max(B −(Ok), 1−B −(Ok))>αV (n −1)>Min(B −(Ok), 1−B −(Ok)), then determine the value
of d −(n) (minimum acceptable belief for detecting the negative shift) by the following
equation:
( )
(
)
(
)
(
)
(
)
(
)
(
)
1
,0.5
1
1
1
1
k
k
d
n
Max
B
O
V n
B
O
V n
a
a
-
-
-
=
æ
ö
ç
÷
ç
÷
ç
÷
ç
÷
ç
÷
-
-
ç
÷
-
+
ç
÷
-
-
-
è
ø
(84)
1.
If B +(Ok)>d +(n), then a positive shift is occurred and decision making stops, and if
(1−B +(Ok))>d +(n), then no positive shift is occurred and decision making stops, else go
to stage 2 after checking the occurrence of negative shift in rest of the algorithm.
2.
If B −(Ok)>d −(n), then a negative shift is occurred and decision making stops, and If
(1−B −(Ok))>d −(n), then no negative shift is occurred and decision making stops, else go
to stage 2.
3.
The approximate value of αV (n −1) based on the discount factor α in the stochastic
dynamic programming approach is α nV (0).
5. Conclusion
In this chapter, we introduced a new approach to determine the best solution out of m
candidates. To do this, first, we defined the belief of selecting the best solution and explained
how to model the problem by the Bayesian analysis approach. Second, we clarified the
approach by which we improved the beliefs, and proved that it converges to detect the best
solution. Next, we proposed a decision-making strategy using dynamic programming
approach in which there were a limited number of decision-making stages.
Dynamic Programming and Bayesian Inference, Concepts and Applications
152

Appendix 1
Conditional Mean and Variance of the Variables
Conditional mean of variables gr and sm can be evaluated using the following equation.
(μsm, μgr |(μj) j≠gr,sm)=(μsm, μgr) + b2
'((Xkj) j≠gr,sm−(μ j) j≠gr,sm)
(85)
where, b2
'=ΣxX ΣXX
-1
and
é
ù
ê
ú
ë
û
XX
xX
xX
xx
Σ
Σ
Σ = Σ
Σ
(86)
Σ: The covariance matrix of the process
Σxx: Submatrix of the covariance matrix Σ for variables j = gr, sm
ΣxX : Submatrix of the covariance matrix Σ between variables j = gr, sm and j ≠gr, sm
ΣXX : Submatrix of the covariance matrix Σ for variables j ≠gr, sm
Further, the conditional covariance matrix of variables j = gr, sm on variables j ≠gr, sm, is
obtained as Σxx-ΣxX
T ΣXX
-1 ΣxX .
Appendix 2
Evaluating the Optimal Value of dgr,sm(k)
Assume (μj) j∈{1,2,...,m}=0 and (σj) j∈{1,2,...,m}=1. Then,
( )
(
)
(
)
(
)
{
}
(
)
(
)
{
}
2
2
,
,
,
0.5(
)
0.5(
)
,
2
2
,
,
,
2
2
,
,
Pr
Pr 0.5(
)
ln
( )
0.5(
)
Pr (
)
(
)
2ln
( )
k gr sm
k sm
k sm
T
T
gr sm
gr sm
k sm
k gr sm
gr sm
k gr sm
e
h d
k
e
T
h d
k
T
T
T
h d
k
ì
ü
ì
ü
³
=
íí
ýý
î
þ
î
þ
³
+
=
-
³
(87)
Now 
since 
(Tk,sm, Tk,gr|sm) 
follow 
a 
standard 
normal 
distribution
(μj) j∈{gr,sm}=0 and (σj) j∈{gr,sm}=1, hence (Tk,gr|sm)2 and (T k ,sm)2 follow a χ 2 distribution with one
degree of freedom. Then using an approximation, if we assume that (T k ,sm)2 is approximately
equal to its mean, we have
Using Dynamic Programming Based on Bayesian Inference in Selection Problems
http://dx.doi.org/10.5772/57423
153

(
)
(
)
(
)
,
,
,
,
2
2
2
(
)
1
k sm
k sm
k sm
k sm
T
E T
E T
Var T
µ
=
+
=
(88)
Thus,
(
)
(
)
{
}
(
)
(
)
{
}
(
)
(
)
{
}
(
)
(
)
{
}
,
,
2
2
,
,
2
2
,
,
2
,
,
2
,
,
Pr (
)
(
)
2ln
( )
Pr (
)
(
)
2ln
( )
Pr (
)
1
2ln
( )
Pr (
)
2ln
( )
1
k sm
k sm
gr sm
k gr sm
gr sm
k gr sm
gr sm
k gr sm
gr sm
k gr sm
T
T
h d
k
T
E T
h d
k
T
h d
k
T
h d
k
-
³
µ
-
³
=
-
³
=
³
+
(89)
Now, since (Tk,gr|sm)2∝χ 2(1), we have
(
)
(
)
{
}
(
)
(
)
,
1
2
2
2
,
,
1
2ln
( )
1
2
Pr (
)
2ln
( )
1
1 2
2
gr sm
t
gr sm
k gr sm
h d
k
e
t
T
h d
k
dt
-
-
¥
+
³
+
=
æ
ö
Gç
÷
è
ø
ò
(90)
Hence,
(
)
(
)
{
}
(
)
(
)
,
,
1
2
2
2
2
,
,
1
2ln
( )
1
2
Pr (
)
(
)
2ln
( )
1 2
2
k sm
gr sm
t
gr sm
k gr sm
h d
k
e
t
T
T
h d
k
dt
-
-
¥
+
-
³
æ
ö
Gç
÷
è
ø
ò
;
(91)
Similarly
(
)
{
}
( )
(
)
(
)
(
)
2
2
,
,
,
0.5(
)
0.5(
)
,
,
,
1
2
2
1
2ln
( )
1
2
Pr
;
( )
Pr
1 2
2
k gr sm
k sm
gr sm
T
T
gr sm
k
gr sm
gr sm
t
r d
k
B
gr O
d
k
e
r d
k
e
e
t
dt
-
-
¥
+
ì
ü
³
=
³
í
ý
î
þ
æ
ö
Gç
÷
è
ø
ò
;
(92)
Replacing the above equations in equation (53) results in
(
)
(
)
(
)
(
)
(
)
(
)
(
)
(
)
(
)
(
)
(
)
(
)
(
)
,
,
1
2
2
*
*
,
,
,
1
2ln
( )
1
2
1
2
2
*
*
,
,
,
1
2ln
( )
1
2
(
)
;
1
1 2
2
;
1
1
1 2
2
gr sm
gr sm
t
i j
gr sm
k
i j
r d
k
t
gr sm
k
i j
i j
h d
k
e
t
V
N
B
gr O
V
N
dt
e
t
B
sm O
V
N
dt
V
N
a
a
a
-
-
¥
+
-
-
¥
+
µ
-
-
+
æ
ö
Gç
÷
è
ø
-
-
+
-
æ
ö
Gç
÷
è
ø
ò
ò
(93)
Dynamic Programming and Bayesian Inference, Concepts and Applications
154

Now by solving the equation 
δVi, j(N )
δdgr,sm(k) =0, the following equation is obtained.
(
)
(
)
(
)
(
)
(
)
(
)
(
)
(
)
(
)
(
)
(
)
(
)
*
,
,
,
*
,
,
,
1
;
1
ln
( )
1
1
;
1
ln
( )
1
gr sm
k
gr sm
gr sm
gr sm
k
gr sm
gr sm
B
gr O
V
N
r d
k
B
sm O
V
N
h d
k
a
a
-
-
=
+
-
-
-
+
(94)
Finally, the approximate value of dgr,sm(k) say d 1
gr,sm(k) is determined by solving this equation
numerically or by a search algorithm.
Now using another approximation, if we assume that (T k ,gr)2 is approximately equal to its
mean, the approximate value of dgr,sm(k) say d 2
gr,sm(k) is determined by solving following
equation,
(
)
(
)
(
)
(
)
(
)
(
)
(
)
(
)
(
)
(
)
(
)
(
)
*
,
,
,
*
,
,
,
1
;
1
ln
( )
1
1
;
1
ln
( )
1
gr sm
k
gr sm
gr sm
gr sm
k
gr sm
gr sm
B
sm O
V
N
r d
k
B
gr O
V
N
h d
k
a
a
-
-
=
+
-
-
-
+
(95)
The approximate optimal value of dgr,sm(k) is obtained as follows,
{
}
1
2
,
,
,
( )
( ),
( )
gr sm
gr sm
gr sm
d
k
d
k d
k
=
(96)
Author details
Mohammad Saber Fallah Nezhad*
Address all correspondence to: Fallahnezhad@yazd.ac.ir
Associate Professor of Industrial Engineering, Yazd University, Iran
References
[1] Basseville, M. & Nikiforov, I.V. (1993). Detection of abrupt changes: Theory and ap‐
plication. (Information and System Sciences Series), Prentice-Hall.
Using Dynamic Programming Based on Bayesian Inference in Selection Problems
http://dx.doi.org/10.5772/57423
155

[2] Eshragh-J., A. & Modarres, M. (2009). A New Approach to Distribution Fitting: Deci‐
sion on Beliefs, Journal of Industrial and Systems Engineering, 3(1), 56-71.
[3] Saniee Monfared M.A., Ranaeifar F. (2007), Further Analysis and Developments of
DOB Algorithm on Distribution Fitting; Scientia Iranica, 14(5), 425-434.
[4] Eshragh-J., A. & Niaki, S.T.A. (2006). The application of decision on beliefs in re‐
sponse surface methodology. Proceedings of the 4th International Industrial Engi‐
neering Conference, Tehran, Iran.
[5] Bechhofer, R.E. & Kulkarni, R. (1982). On the performance characteristics of closed
adaptive sequential procedures for selecting the best Bernoulli populations. Communi‐
cation in Statistics – Sequential Analysis, 1, 315-354.
[6] Gupta, S.S. & Panchapakesan, S. (2002). Multiple decision procedures: Theory and
methodology of selecting and ranking populations. Cambridge University Press,
U.K.
[7] Nair, V.N., Tang, B., and Xu, L. (2001). Bayesian inference for some mixture problems
in quality and reliability, Journal of Quality Technology, 33, 16-28.
[8] Niaki, S.T.A., Fallahnezhad, M. (2009), Decision-making in detecting and diagnosing
faults in multivariate statistical quality control environments. International Journal of
Advanced Manufacturing Technology 42, 713-724
[9] Mason, R.L., Tracy, N.D., Young, J.C. (1995).Decomposition of T2 for multivariate
control chart interpretation. Journal of Quality Technology 27, 99-108.
Dynamic Programming and Bayesian Inference, Concepts and Applications
156

