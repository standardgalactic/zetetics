TO APPEAR IN THE IEEE TRANSACTIONS ON IMAGE PROCESSING
1
A Gaussian mixture model representation of
endmember variability in hyperspectral unmixing
Yuan Zhou, Student Member, IEEE, Anand Rangarajan, Member, IEEE, and Paul D. Gader, Fellow, IEEE
Abstract—Hyperspectral unmixing while considering endmem-
ber variability is usually performed by the normal compositional
model (NCM), where the endmembers for each pixel are assumed
to be sampled from unimodal Gaussian distributions. However,
in real applications, the distribution of a material is often not
Gaussian. In this paper, we use Gaussian mixture models (GMM)
to represent endmember variability. We show, given the GMM
starting premise, that the distribution of the mixed pixel (under
the linear mixing model) is also a GMM (and this is shown
from two perspectives). The ﬁrst perspective originates from the
random variable transformation and gives a conditional density
function of the pixels given the abundances and GMM param-
eters. With proper smoothness and sparsity prior constraints
on the abundances, the conditional density function leads to a
standard maximum a posteriori (MAP) problem which can be
solved using generalized expectation maximization. The second
perspective originates from marginalizing over the endmembers
in the GMM, which provides us with a foundation to solve for
the endmembers at each pixel. Hence, compared to the other
distribution based methods, our model can not only estimate the
abundances and distribution parameters, but also the distinct
endmember set for each pixel. We tested the proposed GMM on
several synthetic and real datasets, and showed its potential by
comparing it to current popular methods.
Index Terms—endmember extraction, endmember variability,
hyperspectral image analysis, linear unmixing, Gaussian mixture
model
I. INTRODUCTION
T
HE formation of hyperspectral images can be simpliﬁed
by the linear mixing model (LMM), which assumes that
the physical region corresponding to a pixel contains several
pure materials, so that each material contributes a fraction
of its spectra based on area to the ﬁnal spectra of the pixel.
Hence, the observed spectra yn ∈RB, n = 1, . . . , N (B is
the number of wavelengths and N is the number of pixels)
is a (non-negative) linear combination of the pure material
(called endmember) spectra mj ∈RB, j = 1, . . . , M (M is
the number of endmembers), i.e.
yn =
M
X
j=1
mjαnj + nn, s.t. αnj ≥0,
M
X
j=1
αnj = 1,
(1)
The authors are with the Department of Computer and Information Sci-
ence and Engineering, University of Florida, Gainesville, FL, USA. E-
mail: yuan,anand,pgader@cise.uﬂ.edu. This paper has supplementary down-
loadable material available at http://ieeexplore.ieee.org., provided by the
author. The material includes a proof of Theorem 2 in the paper. Contact
zhouyuanzxcv@gmail.com for further questions about this work.
where αnj is the proportion (called abundance) for the jth
endmember at the nth pixel (with the positivity and sum-
to-one constraint) and nn ∈RB is additive noise. Here,
the endmember set {mj : j = 1, . . . , M} is ﬁxed for all the
pixels. This model simpliﬁes the unmixing problem to a matrix
factorization one, leading to efﬁcient computation and simple
algorithms such as iterative constrained endmembers (ICE),
vertex component analysis (VCA), piecewise convex multiple-
model endmember detection (PCOMMEND) [1], [2], [3] etc.,
which receive comprehensive reviews in [4], [5].
However, in practice the LMM may not be valid in many
real scenarios. Even for a pure pixel that only contains one
material, its spectra may not be consistent over the whole
image. This is due to several factors such as atmospheric
conditions, topography and intrinsic variability. For example,
in vegetation, multiple scattering and biotic variation (e.g.
differences in biochemistry and water content) cause different
reﬂectances among the same species. For urban scenes, the
incidence and emergence angles could be different for the
same roof, causing different reﬂectances. For minerals, the
spectroscopy model developed by Hapke also considers the
porosity and roughness of the material as variable [6].
In
the
ﬁrst
and
third
example
above,
Eq.
(1)
can
be
generalized
to
a
more
abstract
form
yn
=
F ({mj, αnj : j = 1, . . . M}),
which
leads
to
nonlinear mixing models. For example, in [7] the authors
used bilinear models to handle the vegetation case, which was
also investigated using several different nonlinear functions
[8]. In [9], the Hapke model was used to model intimate
interaction among minerals. There are also works that use
kernels for ﬂexible nonlinear mixing [10], [11]. A panoply
of nonlinear models can be found in the review article [12].
We note that in these models, a ﬁxed endmember set is still
assumed while using a more complicated unmixing model.
While nonlinear models abound lately, it is still difﬁcult to
account for all the scenarios. On the contrary, the LMM still
has physical signiﬁcance with the intuitive area assumption. To
model real scenarios more accurately, researchers have taken
another route by generalizing Eq. (1) to
yn =
M
X
j=1
mnjαnj + nn,
(2)
where

mnj ∈RB : j = 1, . . . , M
	
, n = 1, . . . , N could be
different for each n, i.e. the endmember spectra for each
pixel could be different. This is called endmember variability,
and has also received a lot of attention in the community
0000–0000/00$00.00 c⃝2018 IEEE
arXiv:1710.00075v2  [cs.CV]  15 Jan 2018

TO APPEAR IN THE IEEE TRANSACTIONS ON IMAGE PROCESSING
2
[13], [14]. Note that given {yn}, inferring {mnj, αnj} is
a much more difﬁcult problem than inferring {mj, αnj} in
Eq. (1). Hence, in many papers {mnj} are assumed to be
from a spectral library, which is usually called supervised
unmixing [15], [16], [17]. On the other hand, if the endmember
spectra are to be extracted from the image, we call them
unsupervised unmixing models [18], [19], [20]. Obviously,
unsupervised unmixing is more challenging than its supervised
counterpart and hence more assumptions are used in this case,
such as the spatial smoothness of abundances and endmember
variability [21], [22], [23], small mutual distance between the
endmembers [22], small magnitude or spectral smoothness of
the endmember variability [22], [23].
We can also categorize the papers on endmember variability
by how this variability is modeled. In the review paper [14], it
can be modeled as a endmember set [20], [17] or as a distribu-
tion [24], [25], [26]. One of the widely used set based methods
is multiple endmember spectral mixture analysis (MESMA)
[17], which tries every endmember combination and selects
the one with the smallest error. There are many variations to
the original MESMA. For example, the multiple-endmember
linear spectral unmixing model (MELSUM) solves the linear
equations directly using the pseudo-inverse and discards the
solutions with negative abundances [27]; automatic Monte
Carlo unmixing (AutoMCU) picks random combinations for
unmixing and averages the resulting abundances as the ﬁnal
results [28], [29]. Besides MESMA variants, there are also
many other set based methods. For example, endmember
bundles form bundles from automated extracted endmembers,
take minimum and maximum abundances from bundle based
unmixing, and average them as ﬁnal abundances [20]; sparse
unmixing imposes a sparsity constraint on the abundances
based on endmembers composed of all spectra from the
spectral library [30]. A comprehensive review can be found in
[13], [14]. One disadvantage of set based methods is that their
complexity increases exponentially with increasing library size
hence in practice a laborious library reduction approach may
be required [31].
The distribution based approaches assume that the endmem-
bers for each pixel are sampled from probability distributions
[e.g. Gaussian, a.k.a. normal compositional model (NCM)],
and hence embrace large libraries while being numerically
tractable [15], [32]. Here, we give an overview of NCM
because of its simplicity and popularity [19], [18], [16].
Suppose the jth endmember at the nth pixel follows a Gaussian
distribution p (mnj) = N
 mnj|µj, Σj

where µj ∈RB and
Σj ∈RB×B, and the additive noise also follows a Gaussian
distribution p (nn) = N (nn|0, D) where D is the noise
covariance matrix. The random variable transformation (r.v.t.)
(2) suggests that the probability density function of yn can be
derived as
p (yn|αn, Θ, D) = N

yn|
M
X
j=1
αnjµj,
M
X
j=1
α2
njΣj + D

,
(3)
where αn := [αn1, . . . , αnM]T , Θ :=

µj, Σj : j = 1, . . . , M
	.
The conditional density function in (3) is usually embedded
Figure 1.
(a) Original Pavia University image and selected ROI with its
ground truth image. (b) Mean spectra of the identiﬁed 5 endmembers and
histograms of meadows and painted metal sheets (shadow is termed as
endmember to conform with the LMM though the area under shadow can
be any material). PCA is used to project the multidimensional pixels to
single values which are counted in the histograms. Although the histogram
of meadows may appear to be a Gaussian distribution, that of painted metal
sheets is obviously neither a unimodal Gaussian or Beta distribution.
in a Bayesian framework such that we can incorporate priors
and also estimate hyperparameters. Then, NCM uses different
optimization approaches, e.g. expectation maximization [32],
sampling methods [19], [25], [18], particle swarm optimization
[24], to determine the parameters

µj, Σj
	
and {αnj}.
There are few papers that use other distributions. In [15],
Xiaoxiao Du et al. note that the Gaussian distribution may
allow negative values which are not realistic. In addition,
the real distribution may be skewed. Hence, they introduce
a Beta compositional model (BCM) to model the variability.
The problem is that the true distribution may not be well
approximated by any unimodal distribution. Consider the Pavia
University dataset shown in Fig. 1, where the multidimensional
pixels are projected to one dimension to afford better visu-
alization. Among the manually identiﬁed materials, we can
see that although the histogram of meadows may look like a
Gaussian distribution, that of painted metal sheets has multiple
peaks and cannot be approximated by either a Gaussian or Beta
distribution. This is due to different angles of these sheets on
the roof. Since each piece of metal sheet is tilted, it forms
a cluster of reﬂectances which contributes to a peak in the
histogram. This example shows that we should use a more
ﬂexible distribution to represent the endmember variability.
In this paper, we use a mixture of Gaussians to approximate
any distribution that an endmember may exhibit, and solve the
LMM by considering endmember variability. In a nutshell, the
Gaussian mixture model (GMM) models p (mnj) by a mixture

TO APPEAR IN THE IEEE TRANSACTIONS ON IMAGE PROCESSING
3
of Gaussians, say p (mnj) = P
k πjkN
 mnj|µjk, Σjk

, and
then obtains the distribution of yn by the r.v.t. (2), which turns
out to be another mixture of Gaussians and can be used for
inference of the unknown parameters. Here, we brieﬂy explain
how GMM works intuitively by comparing it to the NCM
with the details given later. The maximum likelihood estimate
(MLE) of NCM (using (3)) aims to ﬁnd

µj
	
such that its
linear combination matches yn. Contrary to NCM, GMM aims
to ﬁnd

µjk
	
such that all of its linear combinations match
yn. Suppose we have µ11, µ21, µ22, µ31, µ32, µ33: then there
are 6 combinations as explained in Fig. 2, but with emphasis
weighted by {πjk} which determines the prior probability of
each linear combination.
Based on the GMM formulation, we propose a supervised
version and an unsupervised version for unmixing. The su-
pervised version takes a library as input and estimates the
abundances. The unsupervised version assumes that there are
regions of pure pixels, hence segments the image ﬁrst to get
pure pixels and then performs unmixing. Another advantage
over the other distribution based methods is that we can also
estimate the endmembers for each pixel, which is not achiev-
able by NCM or BCM. Note that estimating endmembers for
each pixel is generally common in non-distribution methods,
both from the signal processing community [22], [21], [23]
or the remote sensing community [17], [27]. But it is often
achieved in the context of least-squares based unmixing [33],
[34], [35], unlike what we propose here using distribution
based unmixing.
Notation: As usual, N (x|µ, Σ) denotes the multivariate
Gaussian density function with center µ and covariance matrix
Σ. Let A
∈
Rm×n be a matrix with m rows and n
columns. The Hadamard product of two matrices (elementwise
multiplication) is denoted by ◦while the Kronecker product
is denoted by ⊗. (A)jk denotes the element at the jth row
and kth column of matrix A. (A)j denotes the jth row of A
transposed (treating A as a vector), i.e. for A = [a1, . . . an]T ,
(A)j = aj. vec (A) denotes the vectorization of A, i.e.
concatenating the columns of A. δjk = 1 when j = k and
0 otherwise. Ex (f (x)) is the expected value of f (x) given
random variable x. We use i = √−1 instead of as an index
throughout the paper.
II. MATHEMATICAL PRELIMINARIES
A. Linear combination of GMM random variables
To use the Gaussian mixture model to model endmember
variability, we start by assuming that mnj follows a Gaussian
mixture model (GMM) and the noise also follows a Gaussian
distribution. The distribution of yn is obtained using the
following theorem.
Theorem 1. If the random variable mnj has a density
function
p (mnj|Θ) := fmj (mnj) =
Kj
X
k=1
πjkN
 mnj|µjk, Σjk

,
(4)
s.t.
πjk
≥
0, PKj
k=1 πjk
=
1,
with
Kj
being
the
number
of
components,
πjk
(µjk
∈
RB
or
Σjk
∈
RB×B)
being
the
weight
(mean
or
covariance
matrix)
of
its
kth
Gaussian
component,
Θ
:=

πjk, µjk, Σjk : j = 1, . . . , M, k = 1, . . . , Kj
	
,
{mnj : j = 1, . . . , M} are independent, and the random
variable nn has a density function p (nn) := N (nn|0, D),
then
the
density
function
of
yn
given
by
the
r.v.t.
yn = PM
j=1 mnjαnj + nn is another GMM
p (yn|αn, Θ, D) =
X
k∈K
πkN (yn|µnk, Σnk) ,
(5)
where K := {1, . . . , K1}×{1, . . . , K2}×· · ·×{1, . . . , KM} is
the Cartesian product of the M index sets, k := (k1, . . . kM) ∈
K, πk ∈R, µnk ∈RB, Σnk ∈RB×B are deﬁned by
πk :=
M
Y
j=1
πjkj, µnk :=
M
X
j=1
αnjµjkj, Σnk :=
M
X
j=1
α2
njΣjkj+D.
(6)
The proof is detailed using a characteristic function (c.f.)
approach.
We ﬁrst consider the distribution of the intermediate variable
zn = PM
j=1 mnjαnj. The c.f. of fmj in (4), φmj (t) : RB →
C, is given by
φmj (t) = Emj

eitT x
=
Z
RB eitT xfmj (x) dx
=
Kj
X
k=1
πjk
Z
RB eitT xN
 x|µjk, Σjk

dx
=
Kj
X
k=1
πjkφjk (t) ,
(7)
where φjk (t) denotes the c.f. of the Gaussian distribution
N
 x|µjk, Σjk

as
φjk (t) := exp

itT µjk −1
2tT Σjkt

.
(8)
Assuming mn1, . . . , mnM are independent, we can obtain the
c.f. of the linear combination of these mnj by multiplying (7)
as
φzn (t) = φmn1αn1+···+mnMαnM (t) =
M
Y
j=1
φmj (αnjt)
=
K1
X
k1=1
· · ·
KM
X
kM=1
π1k1 · · · πMkM φ1k1 (αn1t) · · · φMkM (αnMt) .
Let K, k, πk be deﬁned as in Theorem 1. We can write the
above multiple summations in an elegant way:
φzn (t) =
X
k∈K
πkφnk (t) ,
(9)
where πk ≥0, P
k∈K πk = 1 and
φnk (t) := φ1k1 (αn1t) · · · φMkM (αnMt)
= exp


itT


M
X
j=1
αnjµjkj

−1
2tT


M
X
j=1
α2
njΣjkj

t


,

TO APPEAR IN THE IEEE TRANSACTIONS ON IMAGE PROCESSING
4
Figure 2. Comparison of the mechanisms among LMM, NCM and GMM. We have 3 endmembers represented by the darken gray areas. LMM tries to ﬁnd
a set of endmembers that ﬁt the pixel data. NCM tries to ﬁnd a set of Gaussian centers that ﬁt the pixel data, with error weighted by the covariance matrices.
GMM tries to ﬁnd Gaussian centers such that all their linear combinations ﬁt the pixel data, with each weighted by the prior πk. We may use 6 endmembers
with NCM, but then the prior information is lost.
where (8) is used. Since φnk (t) also has a form of c.f. of
a Gaussian distribution, the corresponding distribution turns
out to be N

x| P
j αnjµjkj, P
j α2
njΣjkj

. Hence, the dis-
tribution of zn can be obtained by the Fourier transform of
(9)
fzn (zn) =
1
(2π)B
Z
RB e−itT znφzn (t) dt
=
1
(2π)B
Z
RB e−itT zn X
k∈K
πkφnk (t) dt
=
X
k∈K
πkN

zn|
M
X
j=1
αnjµjkj,
M
X
j=1
α2
njΣjkj

,
(10)
which is still a mixture of Gaussians.
After ﬁnding the distribution of the linear combination, we
can add the noise term to ﬁnd the distribution of yn. Suppose
the noise also follows a Gaussian distribution, p (nn) :=
fnn (nn) = N (nn|0, D) , where D is the noise covariance
matrix. We assume that the noise at different wavelengths is
independent (σ2
k being the noise variance of the kth band), i.e.
D = diag
 σ2
1, σ2
2, . . . , σ2
B

∈RB×B (if it is not independent,
the noise can actually be easily whitened to be independent
as in [36]). Its c.f. has the following form
φnn (t) = exp

−1
2tT Dt

(11)
by (8). Then the c.f. of yn can be obtained by multiplying (9)
and (11) (as zn and nn are independent)
φyn (t) = φzn (t) φnn (t) =
X
k∈K
πkφnn (t) φnk (t)
=
X
k∈K
πk exp

itT µnk −1
2tT Σnkt

,
where µnk and Σnk are deﬁned in (6). Finally, the distribution
of y can be shown to be (5) by the Fourier transform again
as in (10).
If K = {1}×{1}×· · ·×{1}, i.e. each endmember has only
one Gaussian component, we have π11 = 1, . . . , πM1 = 1,
then πk = π11 · · · πM1 = 1. The distribution of yn becomes
p (yn|αn, Θ, D) = N

yn|
M
X
j=1
αnjµj1,
M
X
j=1
α2
njΣj1 + D

,
(12)
which is exactly the NCM in (3).
B. Another perspective
Theorem 1 obtains the density of each pixel by directly
performing a r.v.t. based on the LMM, which can be used to
estimate the abundances and distribution parameters. Here, we
will obtain the density from another perspective, which pro-
vides a foundation to estimate the endmembers for each pixel.
Again, let the noise follow the density function p (nn) :=
N (nn|0, D). Considering {mnj} and {αnj} as ﬁxed values,
the r.v.t. yn = P
j mnjαnj + nn implies that the density of
yn is given by
p (yn|αn, Mn, D) = N

yn|
X
j
mnjαnj, D


(13)
where Mn = [mn1, . . . , mnM]T ∈RM×B are the endmem-
bers for the nth pixel. We have the following theorem which
gives the same result as in Theorem 1.
Theorem 2. If the random variables {mnj : j = 1, . . . , M}
follow GMM distributions
p (mnj|Θ) :=
Kj
X
k=1
πjkN
 mnj|µjk, Σjk

,
and they are independent, i.e.
p (Mn|Θ) =
M
Y
j=1
p (mnj|Θ) ,
(14)

TO APPEAR IN THE IEEE TRANSACTIONS ON IMAGE PROCESSING
5
Table I
VALUES FOR THE VARIOUS QUANTITIES IN THE SIMPLE EXAMPLE.
k
πk
µnk in (6)
(1, 1, 1, 1)
0.06
αn1µ11 + αn2µ21 + αn3µ31 + αn4µ41
(1, 2, 1, 1)
0.14
αn1µ11 + αn2µ22 + αn3µ31 + αn4µ41
(1, 1, 2, 1)
0.12
αn1µ11 + αn2µ21 + αn3µ32 + αn4µ41
(1, 2, 2, 1)
0.28
αn1µ11 + αn2µ22 + αn3µ32 + αn4µ41
(1, 1, 3, 1)
0.12
αn1µ11 + αn2µ21 + αn3µ33 + αn4µ41
(1, 2, 3, 1)
0.28
αn1µ11 + αn2µ22 + αn3µ33 + αn4µ41
then the conditional density p (yn|αn, Θ, D) obtained by
marginalizing Mn in p (yn, Mn|αn, Θ, D) has the same form
as in Theorem 1:
p (yn|αn, Θ, D) =
Z
p (yn|αn, Mn, D) p (Mn|Θ) dMn
=
X
k∈K
πkN (yn|µnk, Σnk) ,
where p (yn|αn, Mn, D) = N

yn| P
j mnjαnj, D

.
The proof is much more complicated (in terms of algebra)
and therefore relegated to the supplemental material of the
paper.
C. An example
We give an example to illustrate the basic idea of this
paper. Suppose we have M = 4 endmembers with K1 = 1,
K2 = 2, K3 = 3, K4 = 1. Their distributions follow (4) with
µjk, Σjk, j = 1, 2, 3, 4, k = 1, ..., Kj. Let the weights of
these components be π11 = π41 = 1, π21 = 0.3, π22 = 0.7,
π31 = 0.2, π32 = 0.4, π33 = 0.4. Then, K has 6 entries
from the Cartesian product, {1} × {1, 2} × {1, 2, 3} × {1}.
We list the values for πk, µnk in Table I. For example, for
k = (1, 2, 3, 1), πk = π11π22π33π41 = 0.28. The value of
µnk is a linear combination of µjk (pick one component for
each j) based on the conﬁguration k. Hence, the distribution
of yn in (5) is a Gaussian mixture of 6 components with πk,
µnk given in Table I (Σnk can be derived similar to µnk).
Recalling the intuition in Fig. 2, we will show that applying
it to hyperspectral unmixing will force each pixel to match all
the µnks, but with emphasis determined by πnk.
III. GAUSSIAN MIXTURE MODEL FOR ENDMEMBER
VARIABILITY
A. The GMM for hyperspectral unmixing
Based on the analysis in Section II, we can model the
conditional distribution of all the pixels Y := [y1, . . . , yN]T ∈
RN×B given all the abundances A := [α1, . . . , αN]T
∈
RN×M (αn := [αn1, . . . , αnM]T ) and GMM parameters,
which leads to a maximum a posteriori (MAP) problem. Using
the result in (5) and assuming the conditional distributions
of yn are independent, the distribution of Y given A, Θ, D
becomes
p (Y|A, Θ, D) =
N
Y
n=1
p (yn|αn, Θ, D) .
(15)
Based on the hyperspectral unmixing context, we can set the
priors for A. Suppose we use the same prior on A as in [37],
i.e.
p (A)
∝
exp

−β1
2 Tr
 AT LA

+ β2
2 Tr
 AT A

=
exp

−β1
2 Tr
 AT KA

,
(16)
where L is a graph Laplacian matrix constructed from
wnm, n, m = 1, . . . , N with wnm = e−∥yn−ym∥2/2Bη2 for
neighboring pixels and 0 otherwise. We have Tr
 AT LA

=
1
2
P
n,m wnm∥αn −αm∥2), K = L−β2
β1 IN (suppose β1 ̸= 0)
with β1 controlling smoothness and β2 controlling sparsity of
the abundance maps.
From the conditional density function and the priors, Bayes’
theorem says the posterior is given by
p (A, Θ|Y, D) ∝p (Y|A, Θ, D) p (A) p (Θ) ,
(17)
where p (Θ) is assumed to follow a uniform distribu-
tion. Maximizing p (A, Θ|Y, D) is equivalent to minimizing
−log p (A, Θ|Y, D), which reduces to the following form by
combining (5), (15), (16) and (17):
E (A, Θ) = −
N
X
n=1
log
X
k∈K
πkN (yn|µnk, Σnk) + Eprior(A),
(18)
s.t. πk ≥0,
X
k∈K
πk = 1, αnj ≥0,
M
X
j=1
αnj = 1, ∀n
where Eprior(A) = β1
2 Tr
 AT KA

, and µnk, Σnk are deﬁned
in (6).
B. Relationships to least-squares, NCM and MESMA
Let us focus on the ﬁrst term in (18) and call it the data
ﬁdelity term. We can relate it to NCM and the least-squares
term P
n ∥yn −P
j αnjmj∥2 as used in previous research.
The data ﬁdelity term in NCM follows (3) and is based on
minimizing the negative log-likelihood
−log p (Y) = −log
N
Y
n=1
p (yn) = −
N
X
n=1
log N (yn|µn1, Σn1)
(19)
by assuming yns are independent, where µn1 := P
j αnjµj,
Σn1 := P
j α2
njΣj + σ2IB. Expanding (19) using the form
of the Gaussian distribution leads to the objective function
N
X
n=1
log |Σn1| +
N
X
n=1
(yn −µn1)T Σ−1
n1 (yn −µn1) .
(20)
We can see that the least-squares minimization is a special case
of NCM with ∥Σj∥F →0, i.e. when there is little endmember
variability.
The proposed GMM further generalizes NCM from a sta-
tistical perspective. Since πjk represents the prior probability
of the latent variable in a GMM, πk represents the prior
probability of picking a combination. If we see k as a

TO APPEAR IN THE IEEE TRANSACTIONS ON IMAGE PROCESSING
6
(discrete) random variable whose sample space is K, (5) can
be seen as
p (yn|αn, Θ, D) =
X
k∈K
p (k) p (yn|k, αn, Θ, D) ,
where
p (k)
=
πk
and
p (yn|k, αn, Θ, D)
=
N (yn|µnk, Σnk). From this perspective, each pixel is
generated by ﬁrst sampling k, then sampling a Gaussian
distribution determined by k, Θ. Unlike NCM that tries to
make each yn close to µn1 which is a linear combination of
a ﬁxed set

µj
	
, GMM further generalizes it by trying to
make yn close to every µnk which are all the possible linear
combinations of

µjk
	
. It makes sense that the summation
in (18) is weighted by πk in a way that if one combination
has a high probability to appear, i.e. πk is larger for a certain
k, the effort is biased to make yn closer to this particular
µnk. Fig. 2 shows the differences among these.
The widely adopted MESMA takes a library of endmember
spectra as input, tries all the combinations and pick the
combination with least reconstruction error. The philosophy
is similar to our model despite the fundamental difference
that MESMA is explicit whereas we are implicit in terms
of linear combinations. Compared to MESMA, the GMM
approach separates the library into M groups where each
group represents a material and is clustered into several
centers, such that the combination can only take place by
picking one center from each group. Also, the size of each
cluster affects the probability of picking its center. Hence, our
model can adapt to very large library sizes as long as the
number of clusters does not increase too much.
C. Optimization
Estimating the parameters of GMMs has been studied ex-
tensively, from early expectation maximization (EM) from the
statistical community to projection based clustering from the
computer science community [38], [39]. There are simple and
deterministic algorithms, which usually require the centers of
Gaussian be separable. However, we face a more challenging
problem since each pixel is generated by a different GMM
determined by the coefﬁcients αn. Since EM can be seen as
a special case of Majoriziation-Minimization algorithms [40],
which is more ﬂexible, we adopt this approach. Considering
that we have too many parameters A, Θ to update in the M
step, they are updated sequentially as long as the complete
data log-likelihood increases. This is also called generalized
expectation maximization (GEM) [41].
Following the routine of EM, the E step calculates the
posterior probability of the latent variable given the observed
data and old parameters
γnk =
πkN (yn|µnk, Σnk)
P
k∈K πkN (yn|µnk, Σnk).
(21)
The M step usually maximizes the expected value of the
complete data log-likelihood. Here, we have priors in the
Bayesian formulation. Hence, we need to minimize
EM = −
N
X
n=1
X
k∈K
γnk {log πk + log N (yn|µnk, Σnk)}+Eprior.
(22)
This leads to a common update step for πk as
πk = 1
N
N
X
n=1
γnk.
(23)
We now focus on updating

µjk, Σjk
	
and A. To achieve this,
we require the derivatives of EM in (22) w.r.t. µjk, Σjk, αnj.
After some tedious algebra using (6), we get
∂EM
∂µjl
= −
N
X
n=1
X
k∈K
δlkjαnjλnk
(24)
∂EM
∂Σjl
= −
N
X
n=1
X
k∈K
δlkjα2
njΨnk,
(25)
∂EM
∂αnj
= −
X
k∈K
λT
nkµjkj −2αnj
X
k∈K
Tr

ΨT
nkΣjkj

+ β1 (KA)nj ,
(26)
where λnk ∈RB×1 and Ψnk ∈RB×B are given by
λnk = γnkΣ−1
nk (yn −µnk) ,
(27)
Ψnk = 1
2γnkΣ−T
nk (yn −µnk) (yn −µnk)T Σ−T
nk −1
2γnkΣ−T
nk .
(28)
It is better to represent the derivatives in matrix forms for the
sake of implementation convenience. Considering the multiple
summations in (24), (25) and (26), we can write them as
∂EM
∂µjl
= −
X
k∈K
δlkj
 AT Λk

j ,
(29)
∂EM
∂vec (Σjl) = −
X
k∈K
δlkj

(A ◦A)T Ψk

j ,
(30)
∂EM
∂A = −
X
k∈K
ΛkRT
k −2A ◦
X
k∈K
ΨkST
k + β1KA,
(31)
where Λk ∈RN×B, Ψk ∈RN×B2 denote the matrices
formed by {λnk, Ψnk} as follows
Λk := [λ1k, λ2k, . . . , λNk]T ,
Ψk := [vec (Ψ1k) , vec (Ψ2k) , . . . , vec (ΨNk)]T ,
and Rk ∈RM×B, Sk ∈RM×B2 are deﬁned by
Rk :=

µ1k1, µ2k2, . . . , µMkM
T ,
(32)
Sk := [vec (Σ1k1) , vec (Σ2k2) , . . . , vec (ΣMkM )]T .
(33)
The minimum of EM corresponds to
∂EM
∂µjl = 0,
∂EM
∂Σjl = 0,
and ∂EM
∂A = 0 if the optimization problem is unconstrained.
However, since we have the non-negativity and sum-to-one
constraint to αnj and positive deﬁnite constraint of Σjk,
minimizing EM is very difﬁcult. Therefore, in each M step,
we only decrease this objective function by projected gradient
descent (please see Section 2.3 in [42], [43]) using (29), (30)
and (31), where the projection functions for A and {Σjk} are
the same as in [37].
Finally, from the estimated πk, we can recover the sets of
weights as πjl = P
k∈K δlkjπk.

TO APPEAR IN THE IEEE TRANSACTIONS ON IMAGE PROCESSING
7
D. Model selection
The number of components Kj can be speciﬁed or es-
timated from the data. For the latter case, we have some
pure pixels and estimate Kj by deploying a standard model
selection method. Suppose we have Nj pure pixels Yj :=
h
yj
1, yj
2, . . . , yj
Nj
iT
∈
RNj×B
for the jth endmember,
fmj (y|Θj) is the estimated density function with Θj :=

πjk, µjk, Σjk : k = 1, . . . , Kj
	
, gmj (y) is the true density
function. The information criterion based model selection
approach tries to ﬁnd Kj that minimizes their difference, e.g.
the Kullback-Leibler (KL) divergence
DKL
 gmj∥fmj

=
Z
RB gmj (y) log
gmj (y)
fmj (y|Θj)dy
≈
−1
Nj
Nj
X
n=1
logfmj
 yj
n|Θj

+ const,
where the approximation of
R
gmj (y) log fmj (y|Θj) dy by
the log-likelihood is usually biased as the empirical distribu-
tion function is closer to the ﬁtted distribution than the true
one. Akaike’s information criterion is one way to approximate
the bias. Here, we use the cross-validation-based information
criterion (CVIC) to correct for the bias [44], [45]. Let
LYj (Θj) =
Nj
X
n=1
logfmj
 yj
n|Θj

.
(34)
The V-fold cross validation (we use V = 5 here) divides the
input set Yj into V subsets

Y1
j, Y2
j, . . . , YV
j
	
with equal
sizes. Then for each subset Yv
j , v = 1, . . . , V , the remaining
data are used to replace Yj in (34) such that (34) is maximized
by Θv
j. Then LKj = P
v LYv
j
 Θv
j

is evaluated and the
optimal ˆ
Kj = arg maxKj LKj.
E. Implementation details
The algorithm can be implemented in a supervised or
unsupervised manner. In both cases, because of the large com-
putational cost, we project the pixel data to a low dimensional
space by principal component analysis (PCA) and perform
the optimization, the result then projected back to the original
space. Let E ∈RB×d be the projection matrix and c ∈RB
be the translation vector, then
ET (yn −c) =
M
X
j=1
ET (mnj −c) αnj + ET nn.
This means that for the projected pixels, the jth endmember
m′
nj = ET (mnj −c) follows a distribution
p
 m′
nj|Θ

=
Kj
X
k=1
πjkN
 m′
nj|ET  µjk −c

, ET ΣjkE

and the noise n′
n = ET nn follows N
 n′
n|0, ET DE

.
In the supervised unmixing scenario, we assume that a
library of endmember spectra is known. After estimating the
number of components following Section III-D, and calcu-
lating Θ using the standard EM algorithm, we only need
to update γnk by (21) and A by (31) with πk, µjk and
Σjk ﬁxed. The initialization of A can utilize the multiple
combinations of means. For each αn, we ﬁrst set αnk ←
 RkRT
k + ϵIM
−1 Rkyn, then project it to the simplex space,
and ﬁnally set αn
←αnˆk with ˆk = arg mink ∥yn −
RT
k αnk∥2, i.e. choose the αnk that minimizes the reconstruc-
tion error.
In the unsupervised unmixing scenario, we will assume the
resolution is high enough such that the hyperspectral image
can be segmented into several regions where the interior pixels
in each region are pure pixels. The optimization is performed
in several steps, where we ﬁrst obtain a segmentation result,
then use CVIC to determine the number of components, and
ﬁnally estimate A with Θ ﬁxed. The details are given as
follows.
Step 1: Initialization. We start with Kj = 1, ∀j and use
K-means to ﬁnd the initial means R1. The initial A is set
to A ←YRT
1
 R1RT
1 + ϵIM
−1 (by minimizing ∥Y −
AR1∥2
F ), then projected to the valid simplex space as in [37].
The initial covariance matrices are set to Σj1 ←0.12IB, ∀j.
For the noise matrix D, although there is research focused
on noise estimation [46], [47], endmember variability was
not considered and validation was performed only for the
simple LMM assumption. Hence, we use an empirical value
D = 0.0012IB, which is usually much less than the variability
of covariance matrices in (6).
Step 2: Segmentation. Given the initial conditions, we use
the GEM algorithm to iteratively update γnk by (21), πk by
(23), µjk by (29), A by (31) while keeping Σjk ﬁxed. For
γnk and πk, a direct update equation is available. For µjk,
we can use gradient descent. For A, since we have the non-
negativity and sum-to-one constraints, a projected gradient
descent similar to the one used in [37] can be applied. To
ensure a segmentation effect, a large β2 is used in this step.
Step 3: Model selection and abundance estimation. Using
the segmentation-like abundance maps from the previous step,
we can obtain the interior pixels Yj (assumed pure) by
thresholding the abundances (e.g. αnj > 0.99) and performing
image erosion to trim the boundaries with structure element
size rse (can be decreased gradually if large enough to trim
all the pixels). Following Section III-D, we can determine
the number of components Kj and further calculate Θj by
standard EM. Since β2 is relatively large in the previous step,
it is reduced by β2 ←ζβ2 where ζ = 0.05. Then we restart
the optimization to estimate the abundances with Θ ﬁxed.
F. Complexity analysis
The abundance estimation algorithm is an iterative pro-
cess. Since we used projected gradient descent with adaptive
step sizes, the number of iterations is usually not large
as shown in [48], [43]. For each iteration, it starts with
calculating µnk and Σnk in (6), where storing all µnk
(Σnk) requires O (|K| NB) (O
 |K|NB2
), the computation
takes O (|K|NMB) (O
 |K| NMB2
). Suppose the Cholesky
factorization and the matrix inversion of a B by B matrix
both take O
 B3
time, and N ≫B > M. Evaluating
log N (yn|µnk, Σnk) by the Cholesky factorization will take

TO APPEAR IN THE IEEE TRANSACTIONS ON IMAGE PROCESSING
8
O
 B3
, hence updating all the γnk takes O
 |K| NB3
, which
is also the required time for evaluating the objective function
(18). The calculation of λnk, Ψnk (in (27) and (28)) will
be dominated by the inversion of Σnk which takes O
 B3
,
hence the overall calculation takes O
 |K| NB3
with storage
the same as µnk and Σnk. Then if we move to calculating
the derivatives in (29), (30) and (31), it is easy to verify that
the computational costs are O (|K| NMB), O
 |K| NMB2
,
O
 |K| NMB2
respectively (Note that K is a banded matrix
so the computation involving it is linear). Reviewing the above
process, we conclude that the spatial complexity is dominated
by O
 |K| NB2
and the time complexity is dominated by
O
 |K| NB3
.
G. Estimation of endmembers for each pixel
While
the
previous
sections
discuss
the
estimation
of
the
abundances
and
endmember
distribution
param-
eters,
they
do
not
actually
estimate
the
endmembers
{mnj : n = 1, . . . , N, j = 1, . . . , M} for each pixel. In this
Section, we will discuss this additional problem and note its
absence in the previous NCM literature.
Theorem 2 implies that we can view the proposed con-
ditional density (5) as modeling the noise as a Gaussian
random variable followed by marginalizing over Mn, which
is usually achieved by the evidence approximation in the
machine learning literature due to the intractability of the
integral (Section 3.5 in [49]). Since we have A, Θ obtained
from the previous Sections, we can get the posterior of Mn
from this model:
p (Mn|yn, αn, Θ, D) ∝p (yn, Mn|αn, Θ, D)
= p (yn|αn, Mn, D) p (Mn|Θ) .
(35)
Maximizing log p (Mn|yn, αn, Θ, D) gives us another mini-
mization problem
E (Mn)
=
1
2
 yn −MT
nαn
T D−1  yn −MT
nαn

−
M
X
j=1
log
Kj
X
k=1
πjkN
 mnj|µjk, Σjk

(36)
obtained by plugging (13) and (14) into (35). Note that this
objective function has an intuitive interpretation as the ﬁrst
term minimizes the reconstruction error while the second term
forces the endmembers close to the centers of each GMM. The
weight factor between the two terms is the noise. From an
algebraic perspective, since there are also logarithms of sums
of Gaussian functions in this objective, we can also use the
EM algorithm for ease of optimization. In the E step, the soft
membership is calculated by
γnjk =
πjkN
 mnj|µjk, Σjk

P
k πjkN
 mnj|µjk, Σjk
, k = 1, . . . , Kj.
In the M step, the derivative w.r.t. mnj is obtained as
∂E
∂mnj
= −D−1  yn −MT
nαn

αnj
+
Kj
X
k=1
γnjkΣ−1
jk
 mnj −µjk

.
Instead of deploying gradient descent in the M step for
estimating the abundances, combining the derivatives for all j
actually leads to a closed form solution
vec
 MT
n

=

αnαT
n ⊗D−1 + diag (Cn1, . . . , CnM)
	−1

vec
 D−1ynαT
n

+ dn
	
where Cnj ∈RB×B and dn :=
 dT
n1, . . . , dT
nM
T ∈RMB×1
are deﬁned as
Cnj :=
Kj
X
k=1
γnjkΣ−1
jk , dnj :=
Kj
X
k=1
γnjkΣ−1
jk µjk.
In practice, despite the need to estimate a large M × B × N
tensor, the time cost is actually much less than the estimation
of abundances because of the closed form update equation
in the M step. An interesting fact is that γnjk measures the
closeness of estimated endmembers to clusters centers, hence
may provide a clue on which cluster is sampled to generate
an endmember.
IV. RESULTS
In the following experiments, we implemented the algorithm
in MATLAB R
⃝and compared the proposed GMM with NCM,
BCM (spectral version with quadratic programming) [15] on
synthetic and real images. As mentioned previously, for GMM,
the original image data were projected to a subspace with
10 dimensions to speed up the computation for abundance
estimation 1. NCM was implemented as a supervised algorithm
wherein we input the ground truth pure pixels (in the image
with extreme abundances), modeled them by Gaussian distri-
butions, and obtained the abundance maps by maximizing the
log-likelihood. We considered two versions of NCM, one in
the same subspace as GMM (referred to as NCM), the other in
the original spectral space (referred to as NCM without PCA).
Since BCM is also a supervised unmixing algorithm, ground
truth pure pixels were again taken as input and the results
were the abundance maps. For GMM and the two versions
of NCM, using the algorithm in Section III-G we can obtain
the endmembers for each pixel. All the parameters of GMM
(except the structure element size rse) were set to β1 = 5,
β2 = 5 unless speciﬁed throughout the experiments.
For comparison of endmember distributions, we calculated
the L2 distance
 R
|f (x) −g (x) |2dx
1/2 between the ﬁtted
distribution and the ground truth one, where the latter was only
available for the synthetic dataset. For comparison of abun-
dances, we calculated the root mean squared error (RMSE)
  1
N
P
n |αGT
nj −αest
nj |21/2 where αGT
nj
are the ground truth
abundances and αest
nj are the estimated values. Since only some
1The
code
of
GMM
is
available
on
GitHub
(https://github.com/
zhouyuanzxcv/Hyperspectral).

TO APPEAR IN THE IEEE TRANSACTIONS ON IMAGE PROCESSING
9
pure pixels were identiﬁed as ground truth in the real datasets,
we calculated errorj =

1
|I|
P
n∈I |αGT
nj −αest
nj |21/2
given
the pure pixel index set I. For comparison of endmembers,
the same error formula and overall schema were used, i.e. for
an index set Ij of pure pixels for the jth endmember (in the
real datasets), errorj =
1
|Ij|
P
n∈Ij
  1
B ∥mGT
nj −mest
nj ∥21/2.
A. Synthetic datasets
The algorithms were tested for two cases of synthetic
images, a supervised case and an unsupervised case.
Supervised. In this case, a library of ground truth end-
members were input and the abundances were estimated.
The images were of size 60 × 60 with 103 wavelengths
from 430 nm to 860 nm (≤5 nm spectral resolution) and
created with two endmember classes, meadows and painted
metal sheets, whose spectra were drawn randomly from the
ground truth of the Pavia University dataset (shown in Fig. 1,
meadows have 309 samples and painted metal sheets have
941 samples in the ROI). Since painted metal sheets have
multiple modes in the distribution, it should reﬂect a true
difference between GMM and the other distributions. The
abundances were sampled from a Dirichlet distribution so each
pixel had random values. Also, an additive noise sampled from
N (nn|0, D) was added to the mixed spectra, where the noise
was assumed to be independent at different wavelengths, i.e.
D = diag
 σ2
1, . . . , σ2
B

while σk was again sampled from a
uniform distribution on [0, σY ].
We tested the algorithms for different σY . The effects of
priors were all removed in this case, i.e. β1 = 0, β2 = 0.
Fig. 3 shows the box plots of abundance and endmember
errors. We can see that GMM has small errors in general for
different noise levels. NCM also has relatively small errors
in most cases, but tends to produce large errors occasionally
(4 out of 20 runs). NCM without PCA has very good results
except for large noise, where it performed worst among all
the methods. BCM has the largest errors overall. For the
endmembers, although NCM or NCM without PCA sometimes
has less errors than GMM, the difference is less than 0.005
hence negligible.
Unsupervised. We created two synthetic images in this
case, the ﬁrst was used to validate the ability to estimate the
distribution parameters on scenes with regions of pure pixels,
the second was used to validate the segmentation strategy on
images with insufﬁcient pure pixels. They were both of size
60 × 60 pixels and constructed from 4 endmember classes:
limestone, basalt, concrete, asphalt, whose spectral signatures
were highly differentiable. We assumed that the endmembers
were sampled from GMMs following the example in Sec-
tion II-C. The means of the GMMs were from the ASTER
spectral library [50] (see Fig. 4(c) for their spectra) with slight
constant changes, which determined a spectral range from 0.4
µm to 14 µm, re-sampled into 200 values. The covariance
matrices were constructed by a2
jkIB + b2
jkujkuT
jk where ujk
was a unit vector controlling the major variation direction.
For the ﬁrst image, we assumed the 4 materials occupied the
4 quadrants of the square image as pure pixels. Then Gaussian
smoothing was applied on each abundance map to make the
Table II
L2 DISTANCE BETWEEN THE FITTED DISTRIBUTIONS (GMM, NCM) AND
THE GROUND TRUTH DISTRIBUTIONS FOR THE FIRST IMAGE OF THE
UNSUPERVISED SYNTHETIC DATASET.
×106
Limestone
Basalt
Concrete
Asphalt
Mean
GMM
4.45
3.46
3.41
4.28
3.85
NCM
4.27
5.86
4.95
4.02
4.77
Table III
ABUNDANCE ERRORS FOR THE UNSUPERVISED SYNTHETIC DATASET.
×10−4
GMM
NCM
NCM w/o PCA
BCM
Image 1
Limestone
50
107
92
126
Basalt
40
74
67
158
Concrete
41
66
62
186
Asphalt
69
141
123
292
Mean
59
97
86
190
Image 2
Limestone
157
1086
396
231
Basalt
126
445
270
204
Concrete
103
985
229
206
Asphalt
225
170
706
445
Mean
153
671
400
272
boundary pixels of each quadrant be mixed by the neighboring
materials. For the second image, we made the ﬁrst material
as background, the other materials randomly placed on this
background. The procedure of generating the abundance maps
followed [37]: for each material (not as background), 150
Gaussian blobs were randomly placed, whose location and
shape width were both sampled from Gaussian distributions.
Finally, noise produced similar to above with σY = 0.001
was added to the generated pixels. Fig. 4 shows the abun-
dance maps, the original spectra of these materials, and the
resulting color images by extracting the bands corresponding
to wavelengths 488 nm, 556 nm, 693 nm.
The parameters of GMM were rse = 5 for the two images,
β1 = 0.1, β2 = 0.1 for the second image. Fig. 5 shows
the histograms of ground truth pure pixels and the estimated
distributions for the ﬁrst image. The ground truth distribution
is barely visible as most of the time it coincides with GMM.
For limestone and asphalt, all the distributions are similar
since the pure pixels are generated by a unimodal Gaussian.
However, for basalt and concrete, GMM provides a more
accurate estimation while the two NCMs seem inferior due to
the single Gaussian assumption. The quantitative analysis in
Table II implies a similar result by calculating the L2 distance
between the estimated distribution and the ground truth.
Table III shows the comparison of abundance errors from
the two images. Since the second image is much more chal-
lenging than the ﬁrst one, we can expect increased errors from
all the methods. In general, the results of BCM and the two
NCMs show slightly inferior abundances compared to GMM
despite the fact that they have access to pure pixels in the
image to train their models.
B. Pavia University
The Pavia University dataset was recorded by the Reﬂective
Optics System Imaging Spectrometer (ROSIS) during a ﬂight
over Pavia, northern Italy. The dimension is 340 by 610 with
a spatial resolution of 1.3 meters/pixel. It has 103 bands with

TO APPEAR IN THE IEEE TRANSACTIONS ON IMAGE PROCESSING
10
GMM
NCM
NCM w/o PCA
BCM
Y = 0.0001
0.05
0.1
0.15
0.2
0.25
Error of abundances
GMM
NCM
NCM w/o PCA
BCM
Y = 0.001
0.05
0.1
0.15
0.2
Error of abundances
GMM
NCM
NCM w/o PCA
BCM
Y = 0.01
0.05
0.1
0.15
0.2
Error of abundances
GMM
NCM
NCM w/o PCA
Y = 0.0001
0.025
0.03
0.035
0.04
Error of endmembers
GMM
NCM
NCM w/o PCA
Y = 0.001
0.025
0.03
0.035
0.04
Error of endmembers
GMM
NCM
NCM w/o PCA
Y = 0.01
0.04
0.06
0.08
0.1
Error of endmembers
Figure 3. Abundance and endmember error statistics from 20 synthetic images for each noise level in the supervised unmixing scenario.
wavelengths ranging from 430 nm to 860 nm. As Fig. 1
shows, the original image contains several man-made and
natural materials. Considering that the whole dataset contains
many different objects, we only performed experiments on
the exemplar ROI (47 by 106) shown in Fig. 1, in which
5 endmembers, meadows, bare soil, painted metal sheets,
shadows and pavement, are manually identiﬁed.
The parameter of GMM was rse = 2. Fig. 6 shows the
GMM in the wavelength-reﬂectance space, where we can see
the centers and the major variations of the Gaussians. Fig. 7
shows the scatter plot of the results in the projected space.
The scatter plot shows that the identiﬁed Gaussian components
cover the ground truth pure pixels very well. For painted metal
sheets, which has a broad range of pure pixels, it estimated 4
components to cover them. For shadows, only one component
was estimated. Fig. 8 shows the histograms of pure pixels
and the estimated distributions of GMM and NCMs. We can
see that GMM matches the background histogram better than
NCMs.
Fig. 9 shows the abundance map comparison. Comparing
them with the ground truth shown in Fig. 1(a), we can see that
BCM failed to estimate the pure pixels of painted metal sheets,
although ground truth pure pixels were used for training.
For example, the third and fourth abundance maps of BCM
show that the pixels in the lower part of painted metal sheets
are mixed with shadows, while the reduced reﬂectances are
only caused by angle variation. The result of GMM not only
shows sparse abundances for that region, but also interprets the
boundary as a combination of neighboring materials. Since this
dataset has a spatial spacing of 1.3 meters/pixel, we think this
soft transition is more realistic than a simple segmentation.
Although the results of NCMs look good in general, the
abundances in a pure material region are inconsistent. The
errors of abundances and endmembers for these algorithms
are shown in Table IV, which implies that GMM performed
Table IV
ABUNDANCE AND ENDMEMBER ERRORS FOR PAVIA UNIVERSITY.
×10−4
GMM
NCM
NCM w/o PCA
BCM
Meadow
187 \ 44a
405 \ 113
378 \ 114
711
Soil
175 \ 30
581 \ 68
507 \ 66
1049
Metal
476 \ 49
1236 \ 237
917 \ 349
1285
Shadow
44 \ 44
736 \ 48
914 \ 34
1287
Pavement
473 \ 39
1064 \ 114
333 \ 103
612
Mean
271 \ 41
804 \ 116
610 \ 133
989
a the numbers in ".\." denote the abundance and endmember errors.
best overall.
C. Mississippi Gulfport
The dataset was collected over the University of Southern
Mississippis-Gulfpark Campus [51]. It is a 271 by 284 image
with 72 bands corresponding to wavelengths 0.368 µm to
1.043 µm. The spatial resolution is 1 meter/pixel. The scene
contains several man-made and natural materials including
sidewalks, roads, various types of building roofs, concrete,
shrubs, trees, and grasses. Since the scene contains many
cloths for target detection, we tried to avoid the cloths and
selected a 58 by 65 ROI that contains 5 materials [52].
The original RGB image and the selected ROI are shown in
Fig. 10(a) while the identiﬁed materials and the mean spectra
are shown in (b).
The parameter of GMM was rse = 1. Fig. 11 shows
the GMM result in the wavelength-reﬂectance space and
Fig. 12 shows the scatter plot. We can see that the estimated
Gaussian components successfully cover the identiﬁed pure
pixels. Fig. 13 shows the estimated distributions. Although
there are no multiple peaks in any of the histograms, NCMs
still do not ﬁt the histograms of shadow and gray roof. In
contrast, GMM gives a much better ﬁt for these 2 endmember
distributions.

TO APPEAR IN THE IEEE TRANSACTIONS ON IMAGE PROCESSING
11
Figure 4. Unsupervised synthetic dataset. (a) and (b) are abundance maps for
two images. (c) shows original spectra from the ASTER library. (d) and (e)
show the color images.
Fig. 14 shows the abundance maps from different algo-
rithms. We can see that GMM matches the ground truth in
Fig. 10(b) best, followed by NCM without PCA. This is also
veriﬁed in the quantitative analysis in Table V. Although NCM
and BCM take ground truth pure pixels as input, the scattered
dots for trees (fourth abundance map) in both of them and the
incomplete region of grass for NCM (asphalt for BCM) show
their insufﬁciency in this case.
V. DISCUSSION AND CONCLUSION
In this paper, we introduced a GMM approach to represent
endmember variability, by observing that the identiﬁed pure
pixels in real applications usually can not be well ﬁtted by a
unimodal distribution as in NCM or BCM. We solved several
Figure 5. Histograms of pure pixels for the 4 materials (when projected to
a 1-dimensional space determined by performing PCA on the pure pixels of
each material) and the ground truth and estimated distributions (also projected
to the same direction) for the ﬁrst image of the unsupervised synthetic dataset.
The probability of each distribution is calculated by multiplying the value of
the density function at each bin location with the bin size.
0.5
0.6
0.7
0.8
Wavelength (micrometer)
Meadows
0
0.5
1
Reflectance
0.66
0.34
0.5
0.6
0.7
0.8
Wavelength (micrometer)
Bare Soil
0
0.5
1
Reflectance
0.46
0.42
0.12
0.5
0.6
0.7
0.8
Wavelength (micrometer)
Painted Metal Sheets
0
0.5
1
Reflectance
0.3
0.25
0.25
0.2
0.5
0.6
0.7
0.8
Wavelength (micrometer)
Shadows
0
0.5
1
Reflectance
1
0.5
0.6
0.7
0.8
Wavelength (micrometer)
Pavement
0
0.5
1
Reflectance
0.76
0.24
Figure 6. Estimated GMM in the wavelength-reﬂectance space for the Pavia
University dataset. The background gray image represents the histogram
created by placing the pure pixel spectra into the reﬂectance bins at each
wavelength. The different colors represent different components, where the
solid curve is the center µjk, the dashed curves are µjk ± 2σjkvjk (σjk is
the square root of the large eigenvalue of Σjk while vjk is the corresponding
eigenvector), and the legend shows the prior probabilities.

TO APPEAR IN THE IEEE TRANSACTIONS ON IMAGE PROCESSING
12
-1.5
-1
-0.5
0
0.5
1
1.5
2
2.5
3
-1.5
-1
-0.5
0
0.5
1
1.5
2
Pixels
Meadows
Bare Soil
Painted Metal Sheets
Shadows
Pavement
Figure 7.
Scatter plot of the Pavia University dataset with the estimated
GMM. The gray dots are the projected pixels by PCA. The darkened dots
with a color represent the ground truth pure pixels for a material. The ellipses
with the same color represent the projected Gaussian components (twice the
standard deviation along the major and minor axes, covering 86% of the total
probability mass) for one endmember.
-1
0
1
2
Meadows
0
0.1
0.2
Probability
-0.5
0
0.5
1
Bare Soil
0
0.1
0.2
Probability
-4
-2
0
2
Painted Metal Sheets
0
0.1
0.2
Probability
-0.4
-0.2
0
0.2
Shadows
0
0.1
0.2
Probability
-1
-0.5
0
0.5
Pavement
0
0.1
0.2
Probability
GMM
NCM
NCM w/o PCA
Figure 8. Histograms of pure pixels for the Pavia University dataset and the
estimated distributions from GMM and NCM when projected to 1 dimension.
Table V
ABUNDANCE AND ENDMEMBER ERRORS FOR THE GULFPORT DATASET.
×10−4
GMM
NCM
NCM w/o PCA
BCM
Asphalt
205 \ 52a
1693 \ 94
939 \ 59
1420
Grass
169 \ 58
1982 \ 121
558 \ 65
2145
Shadow
499 \ 49
1294 \ 68
921 \ 43
1315
Tree
1029 \ 89
2194 \ 234
1106 \ 185
2279
Roof
908 \ 76
2143 \ 174
1234 \ 104
1657
Mean
562 \ 65
1861 \ 138
952 \ 91
1763
a the numbers in ".\." denote the abundance and endmember errors.
Figure 9. Abundance maps for the Pavia University dataset. The correspond-
ing endmembers from left to right are meadows, bare soil, painted metal
sheets, shadows and pavement.
obstacles in linear unmixing using this distribution, including
(i) deriving the conditional probability density function of
the mixed pixel given each endmember modeled as GMM
from two perspectives; (ii) estimating the abundances and
endmember distributions by maximizing the log-likelihood
with a prior enforcing abundance smoothness and sparsity;
(iii) estimating the endmembers for each pixel given the abun-
dances and distribution parameters. The results on synthetic
and real datasets show superior accuracy compared to current
popular methods like NCM, BCM. Here we have some ﬁnal
remarks.
Complexity. As analyzed in Section III-F, each itera-
tion in the estimation of abundances has spatial complexity

TO APPEAR IN THE IEEE TRANSACTIONS ON IMAGE PROCESSING
13
Figure 10. (a) Original RGB image of the Mississippi Gulfport dataset with
selected ROI and (b) Ground truth materials in the ROI with their mean
spectra.
0.4
0.6
0.8
1
Wavelength (micrometer)
Asphalt
0
0.5
1
Reflectance
1
0.4
0.6
0.8
1
Wavelength (micrometer)
Grass
0
0.5
1
Reflectance
0.42
0.39
0.2
0.4
0.6
0.8
1
Wavelength (micrometer)
Shadow
0
0.5
1
Reflectance
0.83
0.17
0.4
0.6
0.8
1
Wavelength (micrometer)
Tree
0
0.5
1
Reflectance
1
0.4
0.6
0.8
1
Wavelength (micrometer)
Grey Roof
0
0.5
1
Reflectance
0.82
0.18
Figure 11.
Estimated GMM in the wavelength-reﬂectance space for the
Mississippi Gulfport dataset. The background gray image and the curves have
the same meaning as in Fig. 6.
-1
-0.5
0
0.5
1
1.5
2
-2
-1.5
-1
-0.5
0
0.5
Pixels
Asphalt
Grass
Shadow
Tree
Grey Roof
Figure 12. Scatter plot of the Mississippi Gulfport dataset with the estimated
GMM. The ellipses and the dots have the same meaning as in Fig. 7.
-0.5
0
0.5
Asphalt
0
0.1
0.2
Probability
-0.5
0
0.5
1
Grass
0
0.1
0.2
Probability
-0.2
0
0.2
0.4
0.6
Shadow
0
0.2
0.4
Probability
-2
-1
0
1
Tree
0
0.1
0.2
Probability
-1
0
1
2
Grey Roof
0
0.5
Probability
GMM
NCM
NCM w/o PCA
Figure 13.
Histograms of pure pixels for the Gulfport dataset and the
estimated distributions from GMM and NCM when projected to 1 dimension.
O
 |K| NB2
and time complexity O
 |K| NB3
. For compar-
ison, the implemented NCM has the same complexity but with
|K| = 1. For the supervised synthetic dataset which contains
60 images, the total running time of GMM was 9709 seconds,
on a desktop with a Intel Core i7-3820 CPU and 64 GB mem-
ory. For comparison, the running time of NCM, NCM without
PCA, and BCM was 941, 50751, 62525 seconds respectively.
In real applications, running GMM on the Pavia University
and Mississippi Gulfport ROIs required 734 seconds and 97
seconds respectively for abundance estimation (24 seconds and
17 seconds for endmember estimation), compared to 40 and
34 seconds from NCM, 1389 and 396 seconds from NCM
without PCA, 1170 and 616 seconds from BCM. As analyzed,
the main factors affecting the efﬁciency of GMM and NCMs
are |K| and B.
Limitation. The complexity analysis leads to one limitation
of the method. That is, the complexity grows exponentially

TO APPEAR IN THE IEEE TRANSACTIONS ON IMAGE PROCESSING
14
Figure 14.
Abundance maps for the Gulfport dataset. The corresponding
endmembers from left to right are asphalt, grass, shadow, tree and grey roof.
with increasing numbers of components. This could cause
problems for a large amount of pure pixels. To overcome this
shortcoming, there are some empirical workarounds, such as
reducing the number of components by introducing thresholds,
or reducing the number of pure pixels to a ﬁxed number
by random sampling. Another limitation is that the proposed
unsupervised version assumes presence of regions of pure
pixels, which mostly happens in urban scenes. For scenes with
a lot of mixed pixels, this assumption may not hold. Note that
unsupervised unmixing is a very challenging problem. The
previous works for this problem all assume several properties
on the abundances and endmembers [21], [22], [23]. Hence,
this limitation exists more or less in all the works on this
problem. Finally, the method was only evaluated on real urban
datasets with only ground truth on pure pixels: it is therefore
unclear if the abundance estimation on mixed pixels is also
accurate. This is due to lack of datasets and ground truth in
the hyperspectral community. We plan to validate it on a more
comprehensive dataset given in [31] in the future.
Future work. The proposed GMM formulation has several
applications that we can investigate in the future. First, in
target detection, endmember variability may interfere with
the target as well as the background [53]. By modeling the
target or the background as spectra sampled from GMM
distributions, we may devise more sophisticated and accurate
target detection algorithms. Second, in fusion of hyperspectral
and multispectral images, the LMM is usually used to over-
come the underdetermined nature of the problem [54], [55].
However, the LMM does not hold in real scenarios as shown
in this work. If we use the LMM with endmember variability,
which is modeled by samples from GMM distributions, we
may have a fusion algorithm that better ﬁts the data. Finally,
in estimating the noise or intrinsic dimension of hyperspectral
images, simulated data are generated to quantify the results
[46]. When these simulated data are created, usually the LMM
is used without considering the endmember variability. Using
the GMM formulation, we may generate distinct endmembers
for each pixel and create more realistic synthetic data.
REFERENCES
[1] M. Berman, H. Kiiveri, R. Lagerstrom, A. Ernst, R. Dunne, and J. F.
Huntington, “ICE: A statistical approach to identifying endmembers in
hyperspectral images,” IEEE Trans. on Geoscience and Remote Sensing,
vol. 42, no. 10, pp. 2085–2095, 2004.
[2] J. M. Nascimento and J. M. Bioucas Dias, “Vertex component analysis:
A fast algorithm to unmix hyperspectral data,”
IEEE Trans. on
Geoscience and Remote Sensing, vol. 43, no. 4, pp. 898–910, 2005.
[3] A. Zare, P. D. Gader, O. Bchir, and H. Frigui,
“Piecewise convex
multiple-model endmember detection and spectral unmixing,”
IEEE
Trans. on Geoscience and Remote Sensing, vol. 51, no. 5, pp. 2853–
2862, 2013.
[4] J. M. Bioucas-Dias, A. Plaza, N. Dobigeon, M. Parente, Q. Du, P. D.
Gader, and J. Chanussot, “Hyperspectral unmixing overview: Geomet-
rical, statistical, and sparse regression-based approaches,” IEEE Journal
of Selected Topics in Applied Earth Observations and Remote Sensing,
vol. 5, no. 2, pp. 354–379, 2012.
[5] N. Keshava and J. F. Mustard,
“Spectral unmixing,”
IEEE Signal
Processing Magazine, vol. 19, no. 1, pp. 44–57, 2002.
[6] B. Hapke, “Bidirectional reﬂectance spectroscopy: 1. theory,” Journal
of Geophysical Research: Solid Earth (1978–2012), vol. 86, no. B4, pp.
3039–3054, 1981.
[7] A. Halimi, Y. Altmann, N. Dobigeon, and J.-Y. Tourneret, “Nonlinear
unmixing of hyperspectral images using a generalized bilinear model,”
IEEE Trans. on Geoscience and Remote Sensing, vol. 49, no. 11, pp.
4153–4162, 2011.
[8] B. Somers, K. Cools, S. Delalieux, J. Stuckens, D. Van der Zande, W. W.
Verstraeten, and P. Coppin, “Nonlinear hyperspectral mixture analysis
for tree cover estimates in orchards,” Remote Sensing of Environment,
vol. 113, no. 6, pp. 1183–1193, 2009.
[9] R. Heylen and P. D. Gader, “Nonlinear spectral unmixing with a linear
mixture of intimate mixtures model,”
IEEE Geoscience and Remote
Sensing Letters, vol. 11, no. 7, pp. 1195–1199, 2014.
[10] J. Broadwater and A. Banerjee,
“A generalized kernel for areal and
intimate mixtures,” in 2nd Workshop on Hyperspectral Image and Signal
Processing: Evolution in Remote Sensing (WHISPERS). IEEE, 2010, pp.
1–4.
[11] J. Broadwater, R. Chellappa, A. Banerjee, and P. Burlina, “Kernel fully
constrained least squares abundance estimates,” in IEEE International
Geoscience and Remote Sensing Symposium (IGARSS). IEEE, 2007, pp.
4041–4044.
[12] R. Heylen, M. Parente, and P. D. Gader,
“A review of nonlinear
hyperspectral unmixing methods,” IEEE Journal of Selected Topics in
Applied Earth Observations and Remote Sensing, vol. 7, no. 6, pp. 1844–
1868, 2014.
[13] B. Somers, G. P. Asner, L. Tits, and P. Coppin, “Endmember variability
in spectral mixture analysis: A review,” Remote Sensing of Environment,
vol. 115, no. 7, pp. 1603–1616, 2011.
[14] A. Zare and K. Ho, “Endmember variability in hyperspectral analysis:
Addressing spectral variability during spectral unmixing,” IEEE Signal
Processing Magazine, vol. 31, no. 1, pp. 95–104, 2014.
[15] X. Du, A. Zare, P. D. Gader, and D. Dranishnikov,
“Spatial and
spectral unmixing using the Beta compositional model,” IEEE Journal
of Selected Topics in Applied Earth Observations and Remote Sensing,
vol. 7, no. 6, pp. 1994–2003, 2014.
[16] A. Zare and P. D. Gader, “PCE: Piecewise convex endmember detec-
tion,” IEEE Trans. on Geoscience and Remote Sensing, vol. 48, no. 6,
pp. 2620–2632, 2010.
[17] D. A. Roberts, M. Gardner, R. Church, S. Ustin, G. Scheer, and
R. Green, “Mapping chaparral in the Santa Monica Mountains using
multiple endmember spectral mixture models,”
Remote Sensing of
Environment, vol. 65, no. 3, pp. 267–279, 1998.
[18] A. Halimi, N. Dobigeon, and J.-Y. Tourneret, “Unsupervised unmixing
of hyperspectral images accounting for endmember variability,” IEEE
Trans. on Image Processing, vol. 24, no. 12, pp. 4904–4917, 2015.

TO APPEAR IN THE IEEE TRANSACTIONS ON IMAGE PROCESSING
15
[19] O. Eches, N. Dobigeon, C. Mailhes, and J.-Y. Tourneret,
“Bayesian
estimation of linear mixtures using the normal compositional model:
Application to hyperspectral imagery,” IEEE Trans. on Image Process-
ing, vol. 19, no. 6, pp. 1403–1413, 2010.
[20] C. A. Bateson, G. P. Asner, and C. A. Wessman, “Endmember bundles:
A new approach to incorporating endmember variability into spectral
mixture analysis,”
IEEE Trans. on Geoscience and Remote Sensing,
vol. 38, no. 2, pp. 1083–1094, 2000.
[21] L. Drumetz, M.-A. Veganzones, S. Henrot, R. Phlypo, J. Chanussot,
and C. Jutten, “Blind hyperspectral unmixing using an extended linear
mixing model to address spectral variability,”
IEEE Transactions on
Image Processing, vol. 25, no. 8, pp. 3890–3905, 2016.
[22] P.-A. Thouvenin, N. Dobigeon, and J.-Y. Tourneret,
“Hyperspectral
unmixing with spectral variability using a perturbed linear mixing
model,” IEEE Transactions on Signal Processing, vol. 64, no. 2, pp.
525–538, 2016.
[23] A. Halimi, P. Honeine, and J. M. Bioucas-Dias, “Hyperspectral unmixing
in presence of endmember variability, nonlinearity, or mismodeling
effects,” IEEE Transactions on Image Processing, vol. 25, no. 10, pp.
4565–4579, 2016.
[24] B. Zhang, L. Zhuang, L. Gao, W. Luo, Q. Ran, and Q. Du, “PSO-EM:
A hyperspectral unmixing algorithm based on normal compositional
model,” IEEE Trans. on Geoscience and Remote Sensing, vol. 52, no.
12, pp. 7782–7792, 2014.
[25] O. Eches, N. Dobigeon, and J.-Y. Tourneret, “Estimating the number
of endmembers in hyperspectral images using the normal compositional
model and a hierarchical Bayesian algorithm,” IEEE Journal of Selected
Topics in Signal Processing, vol. 4, no. 3, pp. 582–591, 2010.
[26] C. Song, “Spectral mixture analysis for subpixel vegetation fractions
in the urban environment: How to incorporate endmember variability?,”
Remote Sensing of Environment, vol. 95, no. 2, pp. 248–263, 2005.
[27] J.-P. Combe, S. Le Mouelic, C. Sotin, A. Gendrin, J. Mustard, L. Le Deit,
P. Launeau, J.-P. Bibring, B. Gondet, Y. Langevin, et al., “Analysis of
omega/mars express data hyperspectral data using a multiple-endmember
linear spectral unmixing model (melsum): Methodology and ﬁrst re-
sults,” Planetary and Space Science, vol. 56, no. 7, pp. 951–975, 2008.
[28] G. P. Asner and D. B. Lobell,
“A biogeophysical approach for
automated SWIR unmixing of soils and vegetation,” Remote sensing
of environment, vol. 74, no. 1, pp. 99–112, 2000.
[29] G. P. Asner and K. B. Heidebrecht, “Spectral unmixing of vegetation,
soil and dry carbon cover in arid regions: comparing multispectral and
hyperspectral observations,” International Journal of Remote Sensing,
vol. 23, no. 19, pp. 3939–3958, 2002.
[30] A. Castrodad, Z. Xing, J. B. Greer, E. Bosch, L. Carin, and G. Sapiro,
“Learning discriminative sparse representations for modeling, source
separation, and mapping of hyperspectral imagery,” IEEE Transactions
on Geoscience and Remote Sensing, vol. 49, no. 11, pp. 4263–4281,
2011.
[31] E. B. Wetherley, D. A. Roberts, and J. P. McFadden,
“Mapping
spectrally similar urban materials at sub-pixel scales,” Remote Sensing
of Environment, vol. 195, pp. 170–183, 2017.
[32] D. Stein, “Application of the normal compositional model to the analysis
of hyperspectral imagery,” in IEEE Workshop on Advances in Techniques
for Analysis of Remotely Sensed Data, 2003, pp. 44–51.
[33] L. Tits, B. Somers, and P. Coppin, “The potential and limitations of a
clustering approach for the improved efﬁciency of multiple endmember
spectral mixture analysis in plant production system monitoring,” IEEE
Transactions on Geoscience and Remote Sensing, vol. 50, no. 6, pp.
2273–2286, 2012.
[34] M.-D. Iordache, L. Tits, J. M. Bioucas-Dias, A. Plaza, and B. Somers, “A
dynamic unmixing framework for plant production system monitoring,”
IEEE Journal of Selected Topics in Applied Earth Observations and
Remote Sensing, vol. 7, no. 6, pp. 2016–2034, 2014.
[35] L. Tits, B. Somers, W. Saeys, and P. Coppin,
“Site-speciﬁc plant
condition monitoring through hyperspectral alternating least squares un-
mixing,” IEEE Journal of Selected Topics in Applied Earth Observations
and Remote Sensing, vol. 7, no. 8, pp. 3606–3618, 2014.
[36] J. B. Lee, A. S. Woodyatt, and M. Berman,
“Enhancement of high
spectral resolution remote-sensing data by a noise-adjusted principal
components transform,” IEEE Transactions on Geoscience and Remote
Sensing, vol. 28, no. 3, pp. 295–304, 1990.
[37] Y. Zhou, A. Rangarajan, and P. D. Gader, “A spatial compositional model
for linear unmixing and endmember uncertainty estimation,”
IEEE
Trans. on Image Processing, vol. 25, no. 12, pp. 5987–6002, 2016.
[38] D. Achlioptas and F. McSherry, “On spectral learning of mixtures of
distributions,” in Learning Theory, pp. 458–469. Springer, 2005.
[39] N. Vlassis and A. Likas, “A greedy EM algorithm for gaussian mixture
learning,” Neural Processing Letters, vol. 15, no. 1, pp. 77–87, 2002.
[40] K. Lange, Optimization, Springer, 2013.
[41] X.-L. Meng and D. B. Rubin, “Maximum likelihood estimation via the
ECM algorithm: A general framework,” Biometrika, vol. 80, no. 2, pp.
267–278, 1993.
[42] D. P. Bertsekas, Nonlinear programming, Athena Scientiﬁc, 1999.
[43] C.-J. Lin, “Projected gradient methods for nonnegative matrix factor-
ization,” Neural Computation, vol. 19, no. 10, pp. 2756–2779, 2007.
[44] G. J. McLachlan and S. Rathnayake, “On the number of components
in a Gaussian mixture model,” Wiley Interdisciplinary Reviews: Data
Mining and Knowledge Discovery, vol. 4, no. 5, pp. 341–355, 2014.
[45] P. Smyth,
“Model selection for probabilistic clustering using cross-
validated likelihood,” Statistics and Computing, vol. 10, no. 1, pp. 63–
72, 2000.
[46] L. Gao, Q. Du, B. Zhang, W. Yang, and Y. Wu, “A comparative study
on linear regression-based noise estimation for hyperspectral imagery,”
IEEE Journal of Selected Topics in Applied Earth Observations and
Remote Sensing, vol. 6, no. 2, pp. 488–498, 2013.
[47] R. Roger, “Principal components transform with simple, automatic noise
adjustment,” International Journal of Remote Sensing, vol. 17, no. 14,
pp. 2719–2727, 1996.
[48] N. Guan, D. Tao, Z. Luo, and B. Yuan,
“Manifold regularized dis-
criminative nonnegative matrix factorization with fast gradient descent,”
IEEE Trans. on Image Processing, vol. 20, no. 7, pp. 2030–2048, 2011.
[49] C. M. Bishop, Pattern recognition and machine learning, springer New
York, 2006.
[50] A. Baldridge, S. Hook, C. Grove, and G. Rivera, “The ASTER spectral
library version 2.0,” Remote Sensing of Environment, vol. 113, no. 4,
pp. 711–715, 2009.
[51] P. Gader, A. Zare, R. Close, J. Aitken, and G. Tuell, “MUUFL Gulfport
hyperspectral and LiDAR airborne data set,” Tech. Rep. REP-2013-570,
Univ. Florida, Gainesville, FL, USA, 2013.
[52] X. Du and A. Zare, “Technical report: Scene label ground truth map
for MUUFL Gulfport data set,” Tech. Rep. 20170417, Univ. Florida,
Gainesville, FL, USA, 2017.
[53] C. Jiao and A. Zare, “Functions of multiple instances for learning target
signatures,” IEEE Transactions on Geoscience and Remote Sensing, vol.
53, no. 8, pp. 4670–4686, 2015.
[54] N. Yokoya, T. Yairi, and A. Iwasaki,
“Coupled nonnegative matrix
factorization unmixing for hyperspectral and multispectral data fusion,”
IEEE Transactions on Geoscience and Remote Sensing, vol. 50, no. 2,
pp. 528–537, 2012.
[55] Q. Wei, N. Dobigeon, and J.-Y. Tourneret, “Fast fusion of multi-band
images based on solving a sylvester equation,” IEEE Transactions on
Image Processing, vol. 24, no. 11, pp. 4109–4121, 2015.
Yuan Zhou received the B.E degree in Soft-
ware Engineering (2008), the M.E. degree in Com-
puter Application Technology (2011), both from
Huazhong University of Science and Technology,
Wuhan, Hubei, China. Then he worked in Shanghai
UIH as a software engineer for two years. Since
2013, he has been a Ph.D. student in the Department
of CISE, University of Florida, Gainesville, FL,
USA. His research interests include image process-
ing, computer vision and machine learning.
Anand Rangarajan is in the Department of Com-
puter and Information Science and Engineering,
University of Florida, Gainesville, FL, USA. His
research interests are machine learning, computer
vision and the scientiﬁc study of consciousness.

TO APPEAR IN THE IEEE TRANSACTIONS ON IMAGE PROCESSING
16
Paul
Gader
(M’86–SM’09–F’11)
received
the
Ph.D. degree in mathematics for image-processing-
related research from the University of Florida,
Gainesville, FL, USA, in 1986. He was a Se-
nior Research Scientist with Honeywell, a Research
Engineer and a Manager with the Environmental
Research Institute of Michigan, Ann Arbor, MI,
USA, and a Faculty Member with the University
of Wisconsin, Oshkosh, WI, USA, the University of
Missouri, Columbia, MO, USA, and the University
of Florida, FL, USA, where he is currently a Pro-
fessor of Computer and Information Science and Engineering. He performed
his ﬁrst research in image processing in 1984 working on algorithms for
the detection of bridges in forward-looking infrared imagery as a Summer
Student Fellow at Eglin Air Force Base. He has since worked on a wide
variety of theoretical and applied research problems including fast computing
with linear algebra, mathematical morphology, fuzzy sets, Bayesian meth-
ods, handwriting recognition, automatic target recognition, biomedical image
analysis, landmine detection, human geography, and hyperspectral and light
detection, and ranging image analysis projects. He has authored/co-authored
hundreds of refereed journal and conference papers.

